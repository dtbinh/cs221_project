Journal of Artificial Intelligence Research 20 (2003) 405-430

Submitted 10/02; published 12/03

VHPOP: Versatile Heuristic Partial Order Planner
Håkan L. S. Younes
Reid G. Simmons

lorens@cs.cmu.edu
reids@cs.cmu.edu

School of Computer Science, Carnegie Mellon University
Pittsburgh, PA 15213, USA

Abstract
VHPOP is a partial order causal link (POCL) planner loosely based on UCPOP. It
draws from the experience gained in the early to mid 1990’s on flaw selection strategies
for POCL planning, and combines this with more recent developments in the field of domain independent planning such as distance based heuristics and reachability analysis. We
present an adaptation of the additive heuristic for plan space planning, and modify it to
account for possible reuse of existing actions in a plan. We also propose a large set of novel
flaw selection strategies, and show how these can help us solve more problems than previously possible by POCL planners. VHPOP also supports planning with durative actions
by incorporating standard techniques for temporal constraint reasoning. We demonstrate
that the same heuristic techniques used to boost the performance of classical POCL planning can be effective in domains with durative actions as well. The result is a versatile
heuristic POCL planner competitive with established CSP-based and heuristic state space
planners.

1. Introduction
During the first half of the last decade, much of the research in domain independent plan
generation focused on partial order causal link (POCL) planners. The two dominant POCL
planners were SNLP (McAllester & Rosenblitt, 1991) and UCPOP (Penberthy & Weld,
1992), and a large part of the planning research was aimed at scaling up these two planners.
The most promising attempts at making POCL planning practical involved alternative flaw
selection strategies (Peot & Smith, 1993; Joslin & Pollack, 1994; Schubert & Gerevini, 1995;
Williamson & Hanks, 1996; Pollack, Joslin, & Paolucci, 1997). A flaw in POCL planning is
either an unlinked precondition (called open condition) for an action, or a threatened causal
link. While flaw selection is not a backtracking point in the search through plan space for
a complete plan, the order in which flaws are resolved can have a dramatic effect on the
number of plans searched before a solution is found. The role of flaw selection in POCL
planning is similar to the role of variable selection in constraint programming.
There have been dramatic advances in domain independent planning in the past seven
years, but the focus has shifted from POCL planning to CSP-based planning algorithms
(Blum & Furst, 1997; Kautz & Selman, 1996) and state space planning as heuristic search
(Bonet & Geffner, 2001b; Hoffmann & Nebel, 2001). Recently, Nguyen and Kambhampati (2001) showed that with techniques such as distance based heuristics and reachability analysis—largely responsible for the efficiency of today’s best domain independent
planners—can also be used to dramatically improve the efficiency of POCL planners, thereby
initiating a revival of this previously popular approach to domain independent planning. We
c
2003
AI Access Foundation. All rights reserved.

Younes & Simmons

have drawn from their experience, as well as from experience with flaw selection strategies
from the glory-days of POCL planning, when developing the Versatile Heuristic Partial
Order Planner (VHPOP), and the result is a POCL planner that was able to compete
well with CSP-based and heuristic state space planners at the 3rd International Planning
Competition (IPC3).
We have previously (Younes & Simmons, 2002) adapted the additive heuristic—proposed
by Bonet, Loerincs, and Geffner (1997) and used in HSP (Bonet & Geffner, 2001b)—for
plan space search. In this paper we present a variation of the additive heuristic for POCL
planning that accounts for possible reuse of actions that are already part of a plan. We
show that this accounting for positive interaction often results in a more effective plan
ranking heuristic. We also present ablation studies that demonstrate the effectiveness of
a tie-breaking heuristic based on estimated planning effort (defined as the total number
of open conditions, current and future, that need to be resolved in order to complete a
partial plan). The results show that using this tie-breaking heuristic almost always improves
planner performance.
While the heuristics implemented in VHPOP can work with either ground (fully instantiated) or lifted (partially instantiated) actions, we chose to work only with ground actions
at IPC3. We have shown elsewhere (Younes & Simmons, 2002) that planning with lifted
actions can help reduce the branching factor of the search space compared to using ground
actions, and that this reduction sometimes is large enough to compensate for the added
complexity that comes with having to keep track of variable bindings. Further studies are
needed, however, to gain a better understanding of the circumstances under which planning
with lifted actions is beneficial.
VHPOP efficiently implements all the common flaw selection strategies, such as DUnf
and DSep (Peot & Smith, 1993), LCFR (Joslin & Pollack, 1994), and ZLIFO (Schubert &
Gerevini, 1995). In addition to these, we introduce numerous novel flaw selection strategies
in this paper, of which four were used at IPC3. While we do not claim to have resolved
the issue of global versus local flaw selection—manifested by the conflicting claims made
by Gerevini and Schubert (1996) on the one hand, and Pollack et al. (1997) on the other
about the most efficient way to reduce the number of searched plans in POCL planning—
we show that by combining ideas from both ZLIFO and LCFR we can get very efficient
flaw selection strategies. Other novel flaw selection strategies introduced in this paper
are based on heuristic cost, an idea previously explored by Ghallab and Laruelle (1994).
We also introduce “conflict-driven” flaw selection strategies that aim to expose possible
inconsistencies early in the search, and we show that strategies based on this idea can be
effective in domains previously thought to be particularly difficult for POCL planners.
Ideally, we would like to have one single flaw selection strategy that dominates all other
strategies in terms of number of solved problems. We have yet to discover such a universal
strategy, so instead we use a technique previously explored by Howe, Dahlman, Hansen,
Scheetz, and von Mayrhauser (1999) for combining the strengths of different planning algorithms. The idea is to run several planners concurrently, and Howe et al. showed that
by doing so more problems can be solved than by running any single planner. In VHPOP
we use the same basic POCL planning algorithm in all instances, but we use different flaw
selection strategies concurrently.
406

VHPOP

VHPOP extends the capabilities of classical POCL planners by also supporting planning
with durative actions. This is accomplished by adding a simple temporal network (STN)
(Dechter, Meiri, & Pearl, 1991) to the regular plan representation of a POCL planner. The
STN records temporal constraints between actions in a plan, and supersedes the simple
ordering constraints usually recorded by POCL planners. The use of STNs permits actions
with interval constraints on the duration (a feature that was not utilized by any of the
domains at IPC3 that VHPOP could handle). The approach we take to temporal POCL
planning is essentially the same as the constraint-based interval approach described by
Smith, Frank, and Jónsson (2000), and similar techniques for handling durative actions
in a POCL framework can be traced back at least to Vere’s DEVISER (Vere, 1983).
Our contribution to temporal POCL planning is demonstrating that the same heuristic
techniques shown to boost the performance of classical POCL planning can also be effective
in domains with durative actions, validating the feasibility of the POCL paradigm for
temporal planning on a larger set of benchmark problems than has been done before.

2. Basic POCL Planning Algorithm
We briefly review how POCL planners work, and introduce the terminology used throughout
this paper. For a thorough introduction to POCL planning, we refer the reader to the
tutorial on least commitment planning by Weld (1994).
A (partial) plan can be represented by a tuple hA, L, O, Bi, where A is a set of actions,
L a set of causal links, O a set of ordering constraints defining a partial order on the set A,
and B a set of binding constraints on the action parameters (B = ∅ if ground actions are
used). Each action a is an instance of some action schema A in the planning domain, and
q
a plan can contain multiple instances of the same action schema. A causal link, ai −→ aj ,
represents a commitment by the planner that precondition q of action aj is to be fulfilled
by an effect of action ai .
q

An open condition, −→ ai , is a precondition q of action ai that has not yet been linked
q
to an effect of another action. An unsafe link (or threat) is a causal link, ai −→ aj , whose
condition q unifies with the negation of an effect of an action that could possibly be ordered
between ai and aj . The set of flaws of a plan π is the union of open conditions and unsafe
links: F (π) = OC(π) ∪ U L(π).
A POCL planner searches for a solution to a planning problem in the space of partial
plans by trying to resolve all flaws in a plan. Algorithm 1 shows a generic procedure for
POCL planning that given a planning problem returns a plan solving the problem (or failure
if the given problem lacks a solution). A planning problem is a set of initial conditions I
and a set of goals G, and is represented by an initial plan with two dummy actions a0 ≺ a∞ ,
where the effects of a0 represent the initial conditions of the problem and the preconditions
of a∞ represent the goals of the problem. The procedure Make-Initial-Plan used in
Algorithm 1 returns the plan h{a0 , a∞ }, ∅, {a0 ≺ a∞ }, ∅i. A set P of generated, but not
yet visited, partial plans is kept. At each stage in the planning process, a plan is selected
and removed from P, and then a flaw is selected for that plan. All possible refinements
resolving the flaw (returned by the procedure Refinements) are added to P, and the
process continues until P is empty (indicates failure) or a plan without flaws is found.
407

Younes & Simmons

Algorithm 1 Generic POCL planning algorithm as formulated by Williamson and Hanks
(1996).
Find-Plan(I, G)
P ⇐ {Make-Initial-Plan(I, G)}
while P 6= ∅ do
π ⇐ some element of P  plan selection
P ⇐ P \ {π}
if F (π) = ∅ then
return π
else
f ⇐ some element of F (π)  flaw selection
P ⇐ P ∪ Refinements(π, f )
return failure (problem lacks solution)
q

An open condition, −→ ai , can be resolved by linking q to the effect of an existing or
q
new action. An unsafe link, ai −→ aj threatened by the effect p of action ak , can be resolved
by either ordering ak before ai (demotion), or by ordering ak after aj (promotion). If we
use lifted actions instead of ground actions, a threat can also be resolved by adding binding
constraints so that p and ¬q cannot be unified (separation).

3. Search Control
In the search for a complete plan, we first select a plan to work on, and given a plan we
select a flaw to repair. These two choice points are indicated in Algorithm 1. Making
an informed choice in both these cases is essential for good planner performance, and the
following is a presentation of how these choices are made in VHPOP.
3.1 Plan Selection Heuristic
VHPOP uses the A∗ algorithm (Hart, Nilsson, & Raphael, 1968) to search through plan
space. The A∗ algorithm requires a search node evaluation function f (n) = g(n) + h(n),
where g(n) is the cost of getting to n from the start node (initial plan) and h(n) is the
estimated remaining cost of reaching a goal node (complete plan). We want to find plans
containing few actions, so we take the cost of a plan to be the number of actions in it. For
a plan π = hA, L, O, Bi we therefore have g(π) = |A|.
The original implementations of SNLP and UCPOP used hf (π) = |F (π)| as the heuristic cost function, i.e. the number of flaws in a plan. Schubert and Gerevini (1995) consider
alternatives for hf (π), and present empirical data showing that just counting the open conditions (hoc (π) = |OC(π)|) often gives better results. A big problem, however, with using
the number of open conditions as an estimate of the number of actions that needs to be
added is that it assumes a uniform cost per open condition. It ignores the fact that some
open conditions can be linked to existing actions (thus requiring no additional actions),
while other open conditions can be resolved only by adding a whole chain of actions (thus
requiring more than one action).
408

VHPOP

Recent work in heuristic search planning has resulted in more informed heuristic cost
functions for state space planners. We have in previous work (Younes & Simmons, 2002)
adapted the additive heuristic—first proposed by Bonet et al. (1997) and subsequently used
in HSP (Bonet & Geffner, 2001b)—for plan space search and also extended it to handle
negated and disjunctive preconditions of actions as well as actions with conditional effects
and lifted actions. The heuristic cost function used by VHPOP at IPC3 was a variation of
the additive heuristic where some reuse of actions is taken into account, coupled with the
tie-breaking rank (introduced in Younes & Simmons, 2002) based on estimated remaining
planning effort.
3.1.1 The Additive Heuristic for POCL Planning
The key assumption behind the additive heuristic is subgoal independence. We give a
recursive definition of the additive heuristic for POCL planning, starting at the level of
literals and working towards a definition of heuristic cost for a partial plan.
Given a literal q, let GA(q) be the set of ground actions having an effect that unifies
with q. The cost of the literal q can then be defined as

if q unifies with a literal that holds initially
 0
mina∈GA(q) hadd (a) if GA(q) 6= ∅
hadd (q) =
.

∞
otherwise
A positive literal q holds initially if it is part of the initial conditions. A negative literal ¬q
holds initially if q is not part of the initial conditions (the closed-world assumption). The
cost of an action a is
hadd (a) = 1 + hadd (Prec(a)),
where Prec(a) is a propositional formula in negation normal form representing the preconditions of action a. A propositional formula is in negation normal form if negations only
occur at the level of literals. Any propositional formula can be transformed into negation
normal form, and this is done for action preconditions by VHPOP while parsing the domain
description file.
Existentially quantified variables in an action precondition can be treated as additional
parameters of the action. The cost of an existentially quantified precondition can then
simply be defined as follows:
hadd (∃x.φ) = hadd (φ)
We can deal with universally quantified preconditions by making them fully instantiated
in a preprocessing phase, so in order to complete the definition of heuristic cost for action
preconditions we only need to add definitions for the heuristic cost of conjunctions and
disjunctions. The cost of a conjunction is the sum of the cost of the conjuncts:
^

hadd (

φi ) =

X

i

hadd (φi )

i

The summation in the above formula is what gives the additive heuristic its name. The
definition is based on the assumption that subgoals are independent, which can lead to
409

Younes & Simmons

overestimation of the actual cost of a conjunctive goal (i.e. the heuristic is not admissible).
The cost of a disjunction is taken to be the cost of the disjunct with minimal cost:
_
hadd ( φi ) = min hadd (φi )
i

i

The additive heuristic cost function for POCL plans can now be defined as follows:
X
hadd (π) =
hadd (q)
q

−→ai ∈OC(π)

As with the cost function for conjunction, the above definition can easily lead to overestimation of the number of actions needed to complete a plan, since possible reuse is ignored.
We propose a remedy for this below.
The cost of ground literals can be efficiently computed through dynamic programming.
We take conditional effects into account in the cost computation. If the effect q is conditioned by p in action a, we add hadd (p) to the cost of achieving q with a. We only need
to compute the cost for ground literals once during a preprocessing phase, leaving little
overhead for evaluating plans during the planning phase. When working with lifted actions,
there is extra overhead for unification. It should also be noted that all lifted literals are
independently matched to ground literals without considering interactions between open
conditions of the same action. For example, two preconditions (a ?x) and (b ?x) of the
same action can be unified to ground literals with different matchings for the variable ?x.
3.1.2 Accounting for Positive Interaction
The additive heuristic does not take reuse of actions (other than the dummy action a0 )
into account, so it often overestimates the actual number of actions needed to complete
a plan. The need to take positive interaction into account in order to obtain a more
accurate heuristic estimate has been recognized in both state space planning (Nguyen &
Kambhampati, 2000; Hoffmann & Nebel, 2001; Refanidis & Vlahavas, 2001) and plan space
planning (Nguyen & Kambhampati, 2001). For IPC3 we used a slight modification of the
additive heuristic to address the issue of action reuse:

if ∃aj ∈ A s.t. an effect of aj unifies with q
 0
X
hradd (π) =
and ai ≺ aj 6∈ O

q
hadd (q) otherwise
−→ai ∈OC(π)
q

The underlying assumption for this heuristic cost function is that an open condition −→ ai
that can possibly be resolved by linking to the effect of an existing action aj will not give
rise to a new action when resolved. This can of course lead to an overly optimistic estimate
of the number of actions required to complete the plan. The modified heuristic is still not
admissible, however, since the same cost value as before is used for open conditions that
cannot be linked to effects of existing actions. In other words, we only account for possible
reuse of existing actions and not potential actions.
To illustrate the difference between hadd (π) and hradd (π) consider a planning domain
with two action schemas A1 and A2 , where A1 has no preconditions and A2 has a single
410

VHPOP

Problem
DriverLog6
DriverLog7
DriverLog8
DriverLog9
DriverLog10
ZenoTravel6
ZenoTravel7
ZenoTravel8
ZenoTravel9
ZenoTravel10
Satellite6
Satellite7
Satellite8
Satellite9
Satellite10

MW-Loc
hadd
hradd
8.65
0.16
3.66
0.34
0.33
4.13
2.11
0.93
- 15.48
- 86.21
- 26.59
0.36
0.22
0.49
0.37
1.09
2.41
1.53
1.12

MW-Loc-Conf
hadd
hradd
4.41
0.13
0.63
0.17
110.26
1.48
0.28
0.71
0.76
17.41
2.90
37.81
37.99
11.53
21.22
0.37
0.24
0.54
0.84
1.29
0.84
2.11
1.95
1.11

LCFR-Loc
hadd
hradd
87.58
2.01
21.15
1.28
- 177.27
3.79
0.64
25.09
0.95
33.37
21.20
0.32
0.21
0.55
0.51
0.85
0.83
1.84
1.50
1.36

LCFR-Loc-Conf
hadd
hradd
1.16
1.57
0.22
2.05
1.30
0.83
11.24
2.82
33.10
6.45
26.33
9.49
18.22
0.40
0.24
0.62
1.25
0.68
2.50
2.08
1.37

Table 1: Planning times in seconds using different flaw selection strategies for a selection of
problems in the DriverLog, ZenoTravel, and Satellite domains, showing the impact
of taking reuse into account in the plan ranking heuristic. A dash (-) means that
the planner ran out of memory (512 Mb).

precondition q. Assume that q can only be achieved through an action instance of A1 . The
heuristic cost for the literal q is therefore 1 according to the additive heuristic. Consider
now a plan π with two unordered actions a1 and a2 (ai being an instance of action schema
q
Ai ) and a single open condition −→ a2 . We have hadd (π) = hadd (q) = 1 corresponding to
the addition of a new instance of action schema A1 to achieve q, but hradd (π) = 0 because
there is an action (viz. a1 ) that is not ordered after a2 and has an effect that unifies with q.
Table 1 shows that taking reuse into account can have a significant impact on planning time
in practice. The modified additive heuristic hradd clearly dominates hadd in the DriverLog
and ZenoTravel domains despite incurring a higher overhead per generated plan. The results
in the Satellite domain are more mixed, with hadd having a slight edge overall. We show
planning times for the four flaw selection strategies that were used by VHPOP at IPC3.
These and other novel flaw selection strategies are discussed in detail in Section 3.2.2.
Hoffmann and Nebel (2001) describe the FF heuristic that takes positive interaction between actions into account by extracting a plan from the relaxed planning graph1 , and argue
that the accounting of action reuse is one of the contributing factors to FF’s performance
advantage over HSP. The FF heuristic can take reuse of potential actions into account, and
not just existing actions as is the case with our modified additive heuristic. This should
result in a better estimate of actual plan cost, but requires that a plan is extracted from the
1. A relaxed planning graph is a planning graph with no action pairs marked as mutex.

411

Younes & Simmons

relaxed planning graph for every search node, which could be costly. It would be interesting
to see how the FF heuristic performs if used in a plan space planner.
The heuristic cost function used in RePOP (Nguyen & Kambhampati, 2001), a heuristic
partial order planner working solely with ground actions, is defined using a serial planning
graph.2 The heuristic is similar in spirit to the FF heuristic, and can like the FF heuristic
take reuse of potential actions into account. The RePOP heuristic also takes into account
reuse of existing actions, but seemingly without considering ordering constraints, which
is something we do in our modified additive heuristic. Furthermore, our hradd heuristic
always takes reuse of any existing actions that achieves a literal q into account, while the
RePOP heuristic only considers an existing action if it happens to be selected from the
serial planning graph as the the action that achieves q. The results in Table 2 indicate that
the RePOP heuristic may be less effective than the additive heuristic (with and without
reuse) in certain domains.
3.1.3 Estimating Remaining Effort
Not only do we want to find plans consisting of few actions, but we also want to do so
exploring as few plans as possible. Schubert and Gerevini (1995) suggest that the number
of open conditions can be useful as an estimate of the number of refinement steps needed
to complete a plan. We take this idea a bit further.
When computing the heuristic cost of a literal, we also record the estimated effort of
achieving the literal. A literal that is achieved through the initial conditions has estimated
effort 1 (corresponding to the work of adding a causal link to the plan). If the cost of a
literal comes from an action a, the estimated effort for the literal is the estimated effort for
the preconditions of a, plus 1 for linking to a. Finally, the estimated effort of a conjunction
is the sum of the estimated effort of the conjuncts, while the estimated effort of a disjunction
is the estimated effort of the disjunct with minimal cost (not effort).
The main difference between heuristic cost and estimated effort of a plan is that estimated effort assigns the value 1 instead of 0 to literals that can be unified with an initial
condition. To illustrate the difference, consider a plan π with two open conditions p and q
that both hold in the initial conditions. The heuristic cost for π is 0, while the estimated
effort is 2. The estimated effort is basically a heuristic estimate of the total number of open
conditions that will have to be resolved before a complete plan is found, and it is used as a
tie-breaker between two plans π and π 0 in case f (π) = f (π 0 ). Consider an alternative plan
π 0 with the same number of actions as π but with a single open condition p. This plan
has heuristic cost 0 as does the plan π, but the estimated effort is only 1, so π 0 would be
selected first if estimated effort is used as a tie-breaker. Table 2 shows that using estimated
effort as a tie-breaker can have a notable impact on planner performance for both hadd and
hradd . Estimated effort helps reduce the number of generated and explored plans in all cases
but one (when using hradd on problem rocket-ext-a).
Estimated effort is not only useful as a plan ranking heuristic, but also for heuristic flaw
selection as we will soon see.
2. A serial planning graph is a planning graph with every pair of non-noop actions at the same level marked
as mutex.

412

VHPOP

Problem
gripper-8
gripper-10
gripper-12
gripper-20
rocket-ext-a
rocket-ext-b
logistics-a
logistics-b
logistics-c
logistics-d

hadd
1636 / 705
3268 / 1359
5879 / 2359
33848 / 12204
34917 / 25810
27871 / 20034
503 / 301
857 / 488
766 / 422
3039 / 1398

with effort
1089 / 449
1958 / 795
3224 / 1294
14386 / 5558
27846 / 20028
27277 / 19363
481 / 287
713 / 404
630 / 346
2950 / 1384

hradd
*
*
*
*
24507 / 15790
15919 / 9000
621 / 389
694 / 402
629 / 353
2525 / 1300

with effort
*
*
*
*
31213 / 20321
10914 / 6705
530 / 317
584 / 326
438 / 227
1472 / 682

RePOP
*
*
*
*
30110 / 17768
85316 / 51540
411 / 191
920 / 436
4939 / 2468
*

Table 2: The number of generated/explored plans for hadd and hradd both without and with
estimated effort as a tie-breaker. The RePOP column contains the numbers reported by Nguyen and Kambhampati (2001) for RePOP using the serial planning
graph heuristic. These numbers are included only for the purpose of showing that
there seems to be a qualitative difference between the RePOP heuristic and the
heuristics used by VHPOP. An asterisk (*) means that no solution was found
after generating 100000 plans. Flaws were selected in LIFO order.

3.2 Flaw Selection Strategies
In the original implementations of SNLP and UCPOP threats are selected before open
conditions. When there is more than one threat (or open condition) that can be selected,
the one added last is selected first (LIFO order). Several alternative flaw selection strategies
have been proposed in an attempt to improve the performance exhibited by POCL planners.
Peot and Smith (1993) show that the number of searched plans can be reduced by
delaying the resolution of some threats. The most successful of the proposed delay strategies
are DSep, which delays threats that can be resolved through separation, and DUnf, which
delays threats that can be resolved in more than one way.
Joslin and Pollack (1994) suggest that all flaws should be treated uniformly, and that
the flaw with the least number of refinements should be selected first. Their flaw selection
strategy, LCFR, can be viewed as an instance of the most-constrained-variable heuristic used
in simple search rearrangement backtracking (Bitner & Reingold, 1975; Purdom, 1983). The
main disadvantage with LCFR is that computing the repair cost for every flaw can incur a
large overhead for flaw selection. This can lead to longer planning times compared to when
using the default UCPOP strategy, even if the number of search nodes is significantly
smaller with LCFR. A clever implementation of LCFR can, however, reduce the overhead
for flaw selection considerably.
Schubert and Gerevini (1995) argue that a LIFO strategy for selecting open conditions
helps the planner maintain focus on the achievement of a particular high-level goal. Their
ZLIFO strategy is a variation of the DSep strategy, with the difference being that open
conditions that cannot be resolved, or can be resolved in only one way, are selected before
open conditions that can be resolved in more than one way. Gerevini and Schubert (1996)
present results indicating that ZLIFO often needs to generate fewer plans than LCFR
before a solution is found, and has a smaller overhead for flaw selection. These results are
413

Younes & Simmons

disputed by Pollack et al. (1997). They instead attribute much of the power of ZLIFO to
its delaying of separable threats, and propose a variation of LCFR, LCFR-DSep, that also
delays separable threats. Since we chose to work with ground actions at IPC3, separability
was not an issue for us.
3.2.1 Notation for Specifying Flaw Selection Strategies
In order to better understand the differences between various flaw selection strategies, and
to simplify comparative studies, Pollack et al. (1997) proposed a unifying notation for
specifying flaw selection strategies. We adopt their notation with only slight modifications.
A flaw selection strategy is an ordered list of selection criteria. Each selection criterion
is of the form
{flaw types}≤max refinements ordering criterion,
and applies to flaws of the given types that can be resolved in at most max refinements
ways. If there is no limit on the number of refinements, we simply write
{flaw types}ordering criterion.
The ordering criterion is used to order flaws that the selection criterion applies to. LIFO
order is used if the ordering criterion cannot be used to distinguish two or more flaws.
Pollack et al. define the flaw types “o” (open condition), “n” (non-separable threat),
and “s” (separable threat). They also define the ordering criteria “LIFO”, “FIFO”, “R”
(random), “LR”3 (least refinements first), and “New”. The last one applies only to open
conditions, and gives preference to open conditions that can be resolved by adding a new
action. The rest apply to both open conditions and threats.
Flaws are matched with selection criteria, and it is required for completeness that every
flaw matches at least one selection criterion in a flaw selection strategy. The flaw that
matches the earliest selection criterion, and is ordered before any other flaws matching the
same criterion (according to the ordering criterion), is the flaw that gets selected by the
flaw selection strategy. Note that we do not always need to test all flaws. If, for example,
the first selection criterion is {n, s}LIFO, and we have found a threat, then we do not need
to consider any other flaws for selection.
Using this notation, we can specify many different flaw selection strategies in a concise
manner. Table 3 specifies the flaw selection strategies mentioned earlier. A summary of
flaw types recognized by VHPOP, including three new flaw types defined below, is given
in Table 4.
3.2.2 New Flaw Selection Strategies
We now propose several additional flaw types and ordering criteria, and use these in combination with the previous ones to obtain some novel flaw selection strategies. Four of these
new flaw selection strategies were used at IPC3 and contributed to the success of VHPOP
at that event.
3. The original notation for this ordering criterion is LC for “least (repair) cost”, where the repair cost
is defined to be the number of refinements. Because we introduce a new ordering criterion based on
heuristic cost, we choose to rename this ordering criterion.

414

VHPOP

Name
UCPOP
DSep
DUnf
LCFR
LCFR-DSep
ZLIFO

Specification
{n, s}LIFO / {o}LIFO
{n}LIFO / {o}LIFO / {s}LIFO
{n, s}≤0 LIFO / {n, s}≤1 LIFO / {o}LIFO / {n, s}LIFO
{n, s, o}LR
{n, o}LR / {s}LR
{n}LIFO / {o}≤0 LIFO / {o}≤1 New / {o}LIFO / {s}LIFO

Table 3: A few of the flaw selection strategies previously proposed in the planning literature.
Flaw Type
n
s
o
t
l
u

Description
non-separable threat
separable threat
open condition
static open condition
local open condition
unsafe open condition

Table 4: Summary of flaw types recognized by VHPOP.
Early Commitment through Flaw Selection. We have shown (Younes & Simmons,
2002) that giving priority to static open conditions can be beneficial when planning with
lifted actions. Introducing a new flaw type, “t”, representing static open conditions, we can
specify this flaw selection strategy as follows:
Static-First {t}LIFO / {n, s}LIFO / {o}LIFO
A static open condition is a literal that involves a predicate occurring in the initial
conditions of a planning problem, but not in the effects of any operator in the planning
domain. This means that a static open condition always has to be linked to the initial
conditions, and the initial conditions consist solely of ground literals. Resolving a static
q
open condition −→ ai will therefore cause all free variables of q to be bound to specific
objects. Resolving static open conditions before other flaws represents a bias towards early
commitment of parameter bindings. This resembles the search strategy inherent in planners
using ground actions, but without necessarily committing to bindings for all parameters of
an action at once. The gain is a reduced branching factor compared to a planner using
ground actions, and this reduction can compensate for the increased complexity that comes
with having to keep track of variable bindings.
Our earlier results (Younes & Simmons, 2002) indicated that despite a reduction in the
number of generated plans when planning with lifted actions, using ground actions was
still faster in most domains. In the gripper domain, for example, while using lifted actions
resulted in less than half the number of generated plans compared to when using ground
actions, planning with ground actions was still more than twice as fast. We have greatly
improved the implementation of the planner and the handling of variable bindings since
then. When using the latest version of VHPOP in the gripper domain, the planner is
415

Younes & Simmons

roughly as fast when planning with lifted actions giving priority to static preconditions as
when planning with ground actions.
Local Flaw Selection. By retaining the LIFO order for selecting open conditions achievable in multiple ways, Schubert and Gerevini (1995) argue that the planner tends to maintain focus on a particular higher-level goal by regression, instead of trying to achieve multiple
goals in a breadth-first manner. When some of the goals to achieve are independent, maintaining focus on a single goal should be beneficial. The problem with a LIFO-based flaw
selection strategy, however, as pointed out by Williamson and Hanks (1996), is that it is
highly sensitive to the order in which operator preconditions are specified in the domain
description.
It is not necessary, however, to select the most recently added open condition in order
to keep focus on the achievement of one goal. We can get the same effect by selecting any of
the open conditions, but restrict the choice to the most recently added action. We therefore
introduce a new flaw type, “l”, representing local open conditions. A local open condition is
one that belongs to the most recently added action that still has remaining open conditions.
We can use any ordering criterion to select among local open conditions. Using this new
flaw type, we can specify a local variant of LCFR:
LCFR-Loc {n, s, l}LR
One would expect such a strategy to be less sensitive to precondition-order than a simple LIFO-based strategy. We can see evidence of this in Table 5, which also shows that
the maintained goal focus achieved by local flaw selection strategies can help solve more
problems compared to a global flaw selection strategy.
Heuristic Flaw Selection. Distance based heuristics have been used extensively for
ranking plans in state space planners (e.g., HSP and FF). Nguyen and Kambhampati
(2001) show that these heuristics can be very useful for ranking plans in POCL planners as
well. They also suggest that the same heuristics could be used in flaw selection methods,
but do not elaborate further on this subject.
It is not hard to see, however, how many of the plan rank heuristics could be used for
the purpose of selecting among open conditions, since they often are based on estimating
the cost of achieving open conditions as seen in Section 3.1.1. By giving priority to open
conditions with the highest heuristic cost, we can build plans in a top-down manner from
the goals to the initial conditions. We call this ordering criterion “MC” (most cost first).
By using the opposite ordering criterion, “LC”, we would instead tend to build plans in a
bottom-up manner. Note that these two ordering criteria only apply to open conditions,
and not to threats, so we would need to use them in combination with selection criteria for
threats. We can define both global and local heuristic flaw selection strategies:
MC {n, s}LR / {o}MCadd
MC-Loc {n, s}LR / {l}MCadd
The subscript for MC indicates the heuristic function to use for ranking open conditions,
which in this case is the additive heuristic.
416

VHPOP

Problem
DriverLog6
DriverLog7
DriverLog8
DriverLog9
DriverLog10
ZenoTravel6
ZenoTravel7
ZenoTravel8
ZenoTravel9
ZenoTravel10
Satellite6
Satellite7
Satellite8
Satellite9
Satellite10

UCPOP
σ/|µ| n
0.20 20
0.23 20
0.28 17
0.62
7
0.33 16
0.27 20
0.23
8
0.29 11
0.22 17
0.26 18
0.20 19
0.54
9
0.35
8
0.34
7
0.32
9

LCFR
σ/|µ| n
0.01 20
0.10 20
0
0.00 10
0
0.03
7
0
0
0
0
0
0
0
0
0

LCFR-Loc
σ/|µ|
n
0.01
20
0.32
20
0.00
1
0.45
14
0.07
20
0.22
20
0.18
16
0.15
19
0.21
18
0.22
17
0.02
20
0.03
20
0.02
20
0.00
1
0.01
20

MC
σ/|µ| n
0.18 20
0.13 18
0
0
0
0
0
0
0
0
0
0
0
0
0

MC-Loc
σ/|µ| n
0.23 20
0.25 20
0
0.01 20
0.08 20
0.00 20
0.16 16
0.18 20
0.19 20
0.15 19
0.02 20
0.07 20
0.07
4
0.00
1
0

MW
σ/|µ| n
0.02 20
0
0
0
0
0
0
0
0
0
0
0
0
0
0

MW-Loc
σ/|µ|
n
0.02
20
0.05
20
0
0.01
20
0.08
20
0.00
20
0.16
16
0.18
20
0.19
20
0.15
19
0.02
20
0.07
20
0.07
4
0.00
1
0

Table 5: Relative standard deviation for the number of generated plans (σ/|µ|) and the
number of solved problems (n) over 20 instances of each problem with random
precondition ordered. Low relative standard deviation indicates low sensitivity to
precondition order. Results are shown for VHPOP using seven different flaw selection strategies. A memory limit of 512 Mb was enforced, and hradd with estimated
effort as tie-breaker was used as plan ranking heuristic.

In Section 3.1.3, we proposed that we can estimate the remaining planning effort for
an open condition by counting the total number of open conditions that would arise while
resolving the open condition. This heuristic could also be useful for ranking open conditions,
and is often more discriminating than an ordering criterion based on heuristic cost. We
therefore define two additional ordering criteria: “MW” (most work first) and “LW”. With
these, we can define additional flaw selection strategies:
MW

{n, s}LR / {o}MWadd

MW-Loc

{n, s}LR / {l}MWadd

For the planning problems listed in Table 5, we can see that MW-Loc is at most as sensitive
to precondition order as MC-Loc, with MW-Loc never performing worse than MC-Loc and
for the first two problems performing clearly better.
IxTeT (Ghallab & Laruelle, 1994; Laborie & Ghallab, 1995) also uses heuristic techniques to guide flaw selection, but in quite a different way than suggested here. It is our
understanding of the IxTeT heuristic that it estimates, for each possible refinement r resolving a flaw, the amount of change (commitment) that would result from applying r to
the current plan. For open conditions, this estimate is obtained by expanding a tree of
subgoal decomposition, which in principal is a regression-match graph (McDermott, 1999).
This is similar to how heuristic values are computed using the additive heuristic. However,
IxTeT considers not only the number of actions that need to be added to resolve an open
condition but also to what degree current variable domains would be reduced and possible
action orderings restricted. Furthermore, IxTeT uses the heuristic values to choose the
417

Younes & Simmons

flaw in which a single refinement stands out the most as the least “costly” compared to
other refinements for the same flaw. The intended effect is a reduction in the amount of
backtracking that is needed to find a solution, although we are not aware of any evaluation
of the effectiveness of the technique.
Conflict-Driven Flaw Selection. Common wisdom in implementing search heuristics
for constraint satisfaction problems, e.g. propositional satisfiability, is to first make decisions
with maximal consequences, so that inconsistencies can be detected early on, pruning large
parts of the search space.
A flaw selection strategy that follows this principle would be to link unsafe open conditions before other open conditions. We call an open condition unsafe if a causal link to
that open condition would be threatened. By giving priority to unsafe open conditions,
the planner will direct attention to possible conflicts/inconsistencies in the plan at an early
stage. We introduce the flaw type “u” representing unsafe open conditions. Examples of
conflict-driven flaw selection strategies using this new flaw type are the following variations
of LCFR, LCFR-Loc, and MW-Loc:
LCFR-Conf {n, s, u}LR / {o}LR
LCFR-Loc-Conf {n, s, u}LR / {l}LR
MW-Loc-Conf {n, s}LR / {u}MWadd / {l}MWadd
The first two of these conflict-driven strategies are very effective in the link-chain domain
constructed by Veloso and Blythe (1994). The link-chain domain is an artificial domain
specifically constructed to demonstrate the weakness of POCL planners in certain domains.
What makes the domain hard for SNLP and UCPOP with their default flaw selection
strategies is that open conditions can be achieved by several actions but with only one
action being the right choice because of negative interaction. This forces the POCL planner
to backtrack excessively over link commitments, but inconsistencies may not be immediately
detected because of the many link alternatives. We can see in Figure 1 that VHPOP using
the UCPOP flaw selection strategy performs very poorly in the link-chain domain. Using a
more sophisticated flaw selection strategy such as LCFR improves performance somewhat.
However, with the two conflict-driven flaw selection strategies all problems are solved in
less than a second. The number of generated and explored plans is in fact identical for
LCFR-Conf and LCFR-Loc-Conf, but LCFR-Loc-Conf is roughly twice as fast as LCFRConf because of reduced overhead. This demonstrates the benefit of local flaw selection
strategies. Note, however, that LCFR is faster than LCFR-Loc in the link-chain domain,
so local strategies are not always superior to global strategies.
We can also see in Table 1 that conflict-driven flaw selection strategies work well in the
DriverLog and Depots domains, both with hadd and hradd as heuristic function for ranking
plans.

4. Temporal POCL Planning
In classical planning, actions have no duration: the effects of an action are instantaneous.
Many realistic planning domains, however, require actions that can overlap in time and
have different duration. The version of the planning domain definition language (PDDL),
418

VHPOP

t (s)
UCPOP
LCFR
LCFR-Loc
LCFR-Conf
LCFR-Loc-Conf

100
80
60
40
20
0

1

2

3

4

5

6

7
8
9 10
Number of goals

11

12

13

14

15

Figure 1: Average planning time over ten problems for each point with different flaw selection strategies in the link-chain domain. Results are shown for VHPOP using
five different flaw selection strategies. Only points for which a strategy solved
all ten problems without running out of memory (512 Mb) are shown. The hf
heuristic was used to rank plans.

PDDL2.1, that was used for IPC3 introduces the notion of durative actions. A durative
action represents an interval of time, and conditions and effects can be associated with
either endpoint of this interval. Durative actions can also have invariant conditions that
must hold for the entire duration of the action.
We use the constraint-based interval approach to temporal POCL planning described by
Smith et al. (2000), which in essence is the same approach as used by earlier temporal POCL
planners such as DEVISER (Vere, 1983), ZENO (Penberthy & Weld, 1994), and IxTeT
(Ghallab & Laruelle, 1994). Like IxTeT, we use a simple temporal network (STN) to record
temporal constraints. The STN representation allows for rapid response to temporal queries.
ZENO, on the other hand, uses an integrated approach for handling both temporal and
metric constraints, and does not make use of techniques optimized for temporal reasoning.
The following is a description of how VHPOP handles the type of temporal planning
domains expressible in PDDL2.1.
When planning with durative actions, we substitute the partial order O in the representation of a plan with an STN T . Each action ai of a plan, except the dummy actions
a0 and a∞ , is represented by two nodes t2i−1 (start time) and t2i (end time) in the STN
T , and T can be compactly represented by the d-graph (Dechter et al., 1991). The d-graph
is a complete directed graph, where each edge ti → tj is labeled by the shortest temporal
distance, dij , between the two time nodes ti and tj (i.e. tj − ti ≤ dij ). An additional time
419

Younes & Simmons





0
∞ ∞
 −1 0
7 
−4 −3 0








(a)


0 ∞ ∞ ∞ ∞
−1 0
7 ∞ ∞ 

−4 −3 0 ∞ ∞ 

−1 ∞ ∞ 0
4 
−5 ∞ ∞ −4 0
(b)









0 ∞ ∞ ∞ ∞
−1 0
7
2
6 

−6 −3 0 −5 −1 

−1 ∞ ∞ 0
4 
−5 ∞ ∞ −4 0
(c)

Figure 2: Matrix representation of d-graph, with  = 1, for STN after (a) adding action
a1 with duration constraint δ1 ≤ 7 ∧ δ1 ≥ 3, (b) adding action a2 with duration
constraint δ2 = 4, and (c) ordering the end of a2 before the end of a1 . Explicitly
added temporal constraints are in boldface.

point, t0 , is used as a reference point to represent time zero. By default, dij = ∞ for all
i 6= j (dii = 0), signifying that there is no upper bound on the difference tj − ti .
Constraints are added to T at the addition of a new action, the linking of an open
condition, and the addition of an ordering constraint between endpoints of two actions.
The duration, δi , of a durative action ai is specified as a conjunction of simple duration
constraints δi ./ c, where c is a real-valued constant and ./ is in the set {=, ≤, ≥}.4 Each
simple duration constraint gives rise to temporal constraints between the time nodes t2i−1
and t2i of T when adding ai to a plan hA, L, T , Bi. The temporal constraints, in terms of
the minimum distance dij between two time points, are as follows:
Duration
δi
δi
δi

Constraint
=c
≤c
≥c

Temporal Constraints
d2i−1,2i = c and d2i,2i−1 = −c
d2i−1,2i ≤ c
d2i,2i−1 ≤ −c

The semantics of PDDL2.1 with durative actions dictates that every action be scheduled
strictly after time zero. Let  denote the smallest fraction of time required to separate two
time points. To ensure that an added action ai is scheduled after time zero, we add the
temporal constraint d2i−1,0 ≤ − in addition to any temporal constraints due to duration
constraints. Figure 2(a) shows the matrix representation of the d-graph after adding an
action, a1 , with duration constraint δ1 ≤ 7 ∧ δ1 ≥ 3 to a null plan. The rows and columns
of the matrix correspond to time point 0, the start of action a1 , and the end of action a1
in that order. After adding action a2 with duration constraint δ2 = 4, we have the d-graph
represented by the matrix in Figure 2(b). The two additional rows and columns correspond
to the start and end of action a2 in that order.
A temporal annotation τ ∈ {s, i, e} is added to the representation of open conditions.
q@s

The open condition −→ ai represents a condition that must hold at the start of the durative
q@e

q@i

action ai , −→ ai represents a condition that must hold at the end of ai , while −→ ai is an
invariant condition for ai . An equivalent annotation is added to the representation of causal
4. In contrast, Vere’s DEVISER can only handle duration constraints of the form δi = c.

420

VHPOP

q@τ

links. The linking of an open condition −→ ai to an effect associated with a time point tj
gives rise to the temporal constraint dkj ≤ − (k = 2i if τ = e, else k = 2i − 1). Figure 2(c)
shows the representation of the STN for a plan with actions a1 and a2 , as before, and with
an effect associated with the end of a2 linked to a condition associated with the end of a1 .
Unsafe causal links are resolved in basically the same way as before, but instead of
adding ordering constraints between actions we add temporal constraints between time
points ensuring that one time point precedes another time point. We can ensure that time
point ti precedes time point tj by adding the temporal constraint dji ≤ −.
Every time we add a temporal constraint to a plan, we update all shortest paths dij
that could have been affected by the added constraint. This propagation of constraints can
be carried out in O(|A|2 ) time.
Once a plan without flaws is found, we need to schedule the actions in the plan, i.e. assign
a start time and duration for each action. A schedule of the actions is a solution to the STN
T , and a solution assigning the earliest possible start time to each action is readily available
in the d-graph representation. The start time of action ai is set to −d2i−1,0 (Corollary 3.2,
Dechter et al., 1991) and the duration to d2i−1,0 − d2i,0 . Assuming Figure 2(c) represents
the STN for a complete plan, then we would schedule a1 at time 1 with duration 5 and a2
at time 1 with duration 4. We can easily verify that this schedule is indeed consistent with
the duration constraints given for the actions, and that a2 ends before a1 as required.
Each non-durative action can be treated as a durative action of fixed duration 0, with
preconditions associated with the start time, effects associated with the end time, and
without any invariant conditions. This allows for a frictionless treatment of domains with
both durative and non-durative actions.
Let us for a moment consider the memory requirements for temporal POCL planning
compared to classical POCL planning. When planning with non-durative actions, we store
O as a bit-matrix representing the transitive closure of the ordering constraints in O. For a
partial plan with n actions, this requires n2 bits. With n durative actions, on the other hand,
we need roughly 4n2 floating-point numbers to represent the d-graph of T . Each floatingpoint number requires at least 32 bits on a modern machine, so in total we need more than
100 times as many bits to represent temporal constraints as regular ordering constraints
for each plan. We note, however, that each refinement changes only a few entries in the
d-graph, and by choosing a clever representation of matrices we can share storage between
plans. The upper left 3 × 3 sub-matrix in Figure 2(b) is for example identical to the matrix
in Figure 2(a). The way we store matrices in VHPOP allows us to exploit this commonality
and thereby reduce the total memory requirements.
The addition of durative actions does not change the basic POCL algorithm. The
recording of temporal constraints and temporal annotations can be handled in a manner
transparent to the rest of the planner. The search heuristics described in Section 3, although
not tuned specifically for temporal planning, can be used with durative actions. We only
need to slightly modify the definition of literal and action cost in the additive heuristic
because of the temporal annotations associated with preconditions and effects of durative
actions. Let GAs (q) denote the set of ground actions achieving q at the start, and GAe (q)
421

Younes & Simmons

Name
MW-Loc
MW-Loc-Conf
LCFR-Loc
LCFR-Loc-Conf

Specification
{n, s}LR / {l}MWadd
{n, s}LR / {u}MWadd / {l}MWadd
{n, s, l}LR
{n, s, u}LR / {l}LR

Table 6: Flaw selection strategies used by VHPOP at IPC3.
the set of ground actions achieving q at the end. We

 0
mina∈GAt (q) hadd (a@t)
hadd (q) =

∞

define the cost of the literal q as
if q holds initially
if GAt (q) 6= ∅
,
otherwise

with t ∈ {s, e} and the cost of a durative action a at endpoint t defined as
hadd (a@t) = 1 + hadd (Prec t (a)).
Prec s (a) is a propositional formula representing the invariant preconditions of a and preconditions associated with the start of a, while Prec e (a) is a formula representing all preconditions of a.

5. VHPOP at IPC3
VHPOP allows for several flaw selection strategies to be used simultaneously in a roundrobin scheme. This lets us exploit the strengths of different flaw selection strategies concurrently, which was essential for the success of VHPOP at IPC3 since we have yet to find
a single superior flaw selection strategy that dominates all other flaw selection strategies
in terms of the number of solved problems within a given time frame. The technique we
use in VHPOP for supporting multiple flaw selection strategies is in essence the same as
the technique proposed by Howe et al. (1999) for exploiting performance benefits of several
planners at once in a meta-planner. Although the meta-planner is slower than the fastest
planner on any single problem, it can solve more problems than any single planner.
We used four different flaw selection strategies at IPC3 (Table 6), preferring local flaw
selection strategies as they tend to incur a lower overhead than global strategies such as
LCFR and MW and often appear more effective than global strategies because of a maintained focused on subgoal achievement. The four strategies were selected after some initial
experimentation with problems from a few of the competition domains.
The use of multiple flaw selection strategies can be thought of as running multiple
concurrent instances of the planner, as a separate search queue is maintained for each
flaw selection strategy that is used. Similar to HSP2.0 at the planning competition in
2000 (Bonet & Geffner, 2001a), we use a fixed control strategy to schedule these multiple
instances of our planner. The first time a flaw selection strategy is used, it is allowed to
generate up to 1000 search nodes. The second time the same flaw selection strategy is
used, it can generate another 1000 search nodes, making it a total of 2000 search nodes.
At each subsequent round i, each flaw selection strategy is permitted to generate up to
422

VHPOP

Name
MW-Loc
MW-Loc-Conf
LCFR-Loc
LCFR-Loc-Conf

Order
1
2
3
4

STRIPS Limit
10000
100000
200000
∞

Durative Limit
12000
100000
240000
∞

Table 7: Execution order of flaw selection strategies used at IPC3, and also search limits
used with each strategy on domains with and without durative actions.

1000 · 2i−2 additional nodes. The maximum number of nodes generated using a specific flaw
selection strategy is 1000 · 2i−1 after i rounds. An optional upper limit on the number of
generated search nodes can be set for each flaw selection strategy. This is useful for flaw
selection strategies that typically solve problems quickly, when they solve them at all within
reasonable time. Table 7 shows the search limits used by VHPOP at IPC3. These limits
were determined after some initial trials on the competition problems. Note that there was
no set search limit for the last flaw selection strategy. Whenever the other three strategies
all reached their search limits without having found a solution, LCFR-Loc-Conf was used
until physical resource limits were reached.
Table 8 shows the number of plans generated in the STRIPS Satellite domain before a
solution is found for the four flaw selection strategies used at IPC3, and also the number
of generated plans when combining the four strategies using the schedule in Table 7. To
better understand how the round-robin scheduling works, we take a closer look at the
numbers for problem 15. Table 9 shows how the total number of generated plans is divided
between rounds and flaw selection strategies. Note that although MW-Loc is actually the
best strategy for this problem, it is stopped already in round 5. The total number of
generated plans does not exactly match the actual number of generated plans reported in
Table 8. This is because we only consider suspending the use of a flaw selection strategy
after all refinements of the last selected plan have been added, so the limit in a round can
be exceeded slightly in practice. The numbers in Table 9 represent an idealized situation
where flaw selection strategies are switched when the number of generated plans exactly
matches the limit for the current round.
VHPOP solved 122 problems out of 224 attempted at IPC3. The quality of the plans,
in terms of number of steps, generated by VHPOP was generally very high. For plain
STRIPS domains, VHPOP’s plans were typically within 10 percent of the best plans found
by any planner in the competition, with 28 of VHPOP’s 68 STRIPS plans being at least as
short as the best plans found and, being a POCL planner, VHPOP automatically exploits
parallelism in planning domains, generating plans for STRIPS domains with low total plan
execution time (Table 10). Table 11 shows that VHPOP also performed well in terms of
number of solved problems in four of the six STRIPS domains, being competitive with top
performers such as MIPS and LPG (particularly in the Rovers domain).
423

Younes & Simmons

Problem
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
17
18

MW-Loc
118
229
172
738
448
636000†
571
482000†
1245
1172
3517
6241
2352
74738
533000†
2975
1584

MW-Loc-Conf
118
229
172
843
723000†
629000†
745
874
1178
1172
3733
382000†
2352
444000†
529000†
2975
1584

LCFR-Loc
118
249
172
822
1018
720
620
1017
1323
1172
525000†
559000†
2157
107375
3442
3438
1724

LCFR-Loc-Conf
118
249
172
1797
706000†
834
688000†
783
1275
1172
525000†
544000†
2157
465000†
3571
3438
1724

All
118
229
172
738
448
2727
571
1874
4283
4172
9542
18265
8365
281387
13471
8981
4588

Table 8: Number of generated plans in the STRIPS Satellite domain for the four different
flaw selection strategies used by VHPOP at IPC3. The rightmost column is the
number of plans generated by VHPOP before finding a solution when using the
schedule in Table 7. A dagger (†) means that the planner ran out of memory
(800 Mb) after generating at least the indicated number of plans.

Round
1
2
3
4
5
6
7
8
Total

MW-Loc
1000
1000
2000
4000
2000
10000

MW-Loc-Conf
1000
1000
2000
4000
8000
16000
32000
36000
100000

LCFR-Loc
1000
1000
2000
4000
8000
16000
32000
43375
107375

LCFR-Loc-Conf
1000
1000
2000
4000
8000
16000
32000
64000

Total
4000
4000
8000
16000
26000
48000
96000
79375
281375

Table 9: A closer look at the round-robin scheduling for problem 15 in the STRIPS Satellite
domain. Italic entries indicate that the search limit for a flaw selection strategy
was reached in the round.

424

VHPOP

Domain
DriverLog
ZenoTravel
Satellite
Rovers

# Solved
14
13
17
20

# Steps
1.09
1.04
1.07
1.08

# Best
5
7
7
7

Execution Time
1.15
1.20
1.25
1.08

# Best
4
5
5
13

Table 10: Relative plan quality for the STRIPS domains where VHPOP solved more than
half of the problems. There are two plan quality metrics. Number of steps is
simply the total number of steps in a plan, while execution time is the total
time required to execute a plan (counting parallel actions as one time step). The
table shows the average ratio of VHPOP’s plan quality and the quality of the
best plan generated by any planner, and the number of problems in each domain
where VHPOP found the best plan is also shown.

Planner
FF
LPG
MIPS
Simplanner
Stella
VHPOP

Depots
22
21
10
22
4
3

DriverLog
15
18
15
11
10
14

ZenoTravel
20
20
16
20
18
13

Satellite
20
20
14
17
14
17

Rovers
20
12
12
9
4
20

FreeCell
20
18
19
12
0
1

Total
117
109
86
91
50
68

Table 11: Number of problems solved by top performing fully automated planners in
STRIPS domains.

In domains with durative actions5 , total execution time was given as an explicit plan
metric, and the objective was to minimize this metric. The specification of an explicit plan
metric is a feature of PDDL2.1 not present in earlier versions of PDDL. As VHPOP currently ignores this objective function and always tries to find plans with few steps, it should
come as no surprise that the quality of VHPOP’s plans for domains with durative actions
was significantly worse than the quality of the best plans found (Table 12).6 VHPOP
still produced plans with few steps, however, with over 60 percent of VHPOP’s plans for
domains with durative actions having the fewest steps. The plan selection heuristic that
VHPOP uses is tuned for finding plans with few steps, and it would need to be modified in
order to find plans with shorter total execution time. Table 13 shows that LPG solved by
far the most problems in domains with durative actions, but that VHPOP was competitive
with MIPS and clearly outperformed TP4 and TPSYS.
5. There were two types of domains with durative actions at IPC3: “SimpleTime” domains having actions
with constant duration and “Time” domains with durations being functions of action parameters. The
results with durative actions presented in this paper are for “SimpleTime” domains as there is currently
no support for durations as functions of action parameters in VHPOP. It would, in principle, not be
hard to add such support though, and we expect future versions of VHPOP to have it.
6. The poor performance is in part also due to the use of 1 for  (see Section 4) in VHPOP, while most
other planners used 0.01 or less. Using 0.01 for  with VHPOP reduces the total execution time of plans
with about 15 percent.

425

Younes & Simmons

Domain
DriverLog
ZenoTravel
Satellite
Rovers

# Solved
14
13
17
7

# Steps
1.04
1.04
1.04
1.04

# Best
8
10
9
5

Execution Time
1.50
1.54
2.51
1.39

# Best
0
0
0
0

Table 12: Same information as in Table 10, but for domains with durative actions.
Planner
LPG
MIPS
TP4
TPSYS
VHPOP

Depots
20
11
1
0
3

DriverLog
20
15
2
2
14

ZenoTravel
20
14
5
2
13

Satellite
20
9
3
2
17

Rovers
12
9
4
4
7

Total
92
58
15
10
54

Table 13: Number of problems solved by fully automated planners in domains with durative
actions.

While VHPOP was a top performer at IPC3 in terms of plan quality, it was far from
the top in terms of planning time. VHPOP was typically orders of magnitude slower than
the fastest planner. The high planning times for VHPOP can in part be attributed to
implementation details. Improvements to the code (e.g. using pointer comparison instead
of string comparison whenever possible) since the planning competition has resulted in 10 to
20 percent lower planning times when using ground actions and when using lifted actions the
planner is more than twice as fast as before. The reachability analysis is still a bottleneck,
however, and further improvements could definitely be made there. It is important to
remember, though, that we basically run four planners at once by using four flaw selection
strategies concurrently. Table 14 shows the average relative performance of VHPOP at
IPC3 compared to the performance of VHPOP using only the best flaw selection strategy
for each problem. VHPOP with the best flaw selection strategy is on average two to three
times faster than VHPOP with four concurrent strategies. Using several flaw selection
strategies simultaneously helps us solve more problems, but the price is reduced speed. By
more intelligently scheduling the different flaw selection strategies depending on domain and
problem features, and not just using a fixed schedule for all problems, we could potentially
increase planner efficiency significantly.

6. Discussion
McDermott (2000) finds the absence of POCL planners at the first planning competition in
1998 striking, as such planners had been dominating planning research just a few years earlier. “It seems doubtful that the arguments in [POCL planners’] favor were all wrong, and it
would be interesting to see partial-order planners compete in future competitions”, McDermott writes. After two competitions without POCL planners, we believe that VHPOP’s
performance at IPC3 demonstrates that POCL planning—at least with ground actions—
can be competitive with CSP-based and heuristic state space planning. VHPOP also shows
426

VHPOP

Domain
DriverLog
ZenoTravel
Satellite
Rovers

STRIPS
2.52
2.76
1.78
2.32

Durative
2.66
2.86
2.01
3.37

Table 14: Each number in the table represents the average ratio of the planning time for
VHPOP using all four flaw selection strategies concurrently and the planning
time for VHPOP with only the fastest flaw selection strategy.

that temporal POCL planning can be made practical by using the same heuristic techniques
that have been developed for classical planning. The idea of using the POCL paradigm for
temporal planning is not new and goes back at least to Vere’s DEVISER (Vere, 1983), but
we are the first to demonstrate the effectiveness of temporal POCL planning on a larger set
of benchmark problems.
We hope that the success of VHPOP at IPC3 will inspire a renewed interest in plan
space planning, and we have made the source code for VHPOP, written in C++, available
to the research community in an online appendix so that others can build on our effort.7
While VHPOP performed well above our expectations at IPC3, we see several ways in
which we can further improve the planner. Speed, as mentioned in Section 5, is the principal
weakness of VHPOP. The code for the reachability analysis is not satisfactory, as it currently generates ground action instances before performing any reachability analysis. This
often leads to many ground action instances being generated that do not have preconditions
with finite heuristic cost (according to the additive heuristic). We believe that VHPOP
could profit from code for reachability analysis in well-established planning systems such
as FF. We could also improve speed by better scheduling different flaw selection strategies.
We would like to see statistical studies, similar to that of Howe et al. (1999), linking domain
and problem features to the performance of various flaw selection strategies.
We have so far only considered using different flaw selection strategies. However, running multiple instances of VHPOP using different plan selection heuristics could be equally
interesting. We have, for example, noticed that using the additive heuristic without accounting for reuse helps us solve two more problems in the Satellite domain. It would also be
interesting to have the FF heuristic implemented in VHPOP and see how well it performs
in a plan space planner, possibly using local search techniques instead of A∗ . It is not likely,
however, that the results on local search topology for the FF heuristic in state space (Hoffmann, 2001) carry over to plan space. While many of the benchmark planning domains
contain actions whose effects can be undone by other actions, the plan operators causing
transitions in the search space of a plan space planner are different from the actions defined
for a planning domain, and the effects of a plan space operator are generally irreversible.
We would likely need to add transformational plan operators that can undo linking and
ordering decisions. Incidentally, VHPOP started out as a project for adding transformational plan operators to UCPOP, but we got side-tracked by the need for better search
7. The latest version of VHPOP is available for download at www.cs.cmu.edu/˜lorens/vhpop.html.

427

Younes & Simmons

control, and our research on transformational POCL planning was suspended. With the
recent improvements in search control for POCL planners, it may be worthwhile to once
again consider adding transformational plan operators.
In addition to considering different search control heuristics, we could also have instances
of VHPOP working with lifted actions instead of ground actions. Recent improvements
to the code have significantly reduced the overhead for maintaining binding constraints,
making planning with lifted actions look considerably more favorable than was reported in
earlier work (Younes & Simmons, 2002). Planning with lifted actions could be beneficial for
problems with a high branching factor in the search space due to a large number of objects.
We would also like to see support for numeric effects and preconditions in future versions
of VHPOP. This would make VHPOP fully compatible with PDDL2.1. We have also
mentioned the need for plan ranking heuristics better tailored for temporal planning, so
that VHPOP’s performance in terms of plan execution time for domains with durative
actions can approach the performance of the best temporal planners at IPC3.

Acknowledgments
This effort was sponsored by the Defense Advanced Research Project Agency (DARPA)
and the Army Research Office (ARO), under contract no. DAAD19-01-1-0485. The U.S.
Government is authorized to reproduce and distribute reprints for Governmental purposes
notwithstanding any copyright annotation thereon. The views and conclusions contained
herein are those of the authors and should not be interpreted as necessarily representing
the official policies or endorsements, either expressed or implied, of DARPA, ARO, or the
U.S. Government.

References
Bitner, J. R., & Reingold, E. M. (1975). Backtrack programming techniques. Communications of the ACM, 18 (11), 651–656.
Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Artificial
Intelligence, 90 (1–2), 281–300.
Bonet, B., & Geffner, H. (2001a). Heuristic Search Planner 2.0. AI Magazine, 22 (3), 77–80.
Bonet, B., & Geffner, H. (2001b). Planning as heuristic search. Artificial Intelligence,
129 (1–2), 5–33.
Bonet, B., Loerincs, G., & Geffner, H. (1997). A robust and fast action selection mechanism for planning. In Proceedings of the Fourteenth National Conference on Artificial
Intelligence, pp. 714–719, Providence, RI. AAAI Press.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49 (1–3), 61–95.
Gerevini, A., & Schubert, L. (1996). Accelerating partial-order planners: Some techniques
for effective search control and pruning. Journal of Artificial Intelligence Research, 5,
95–137.
428

VHPOP

Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporal
planner. In Hammond, K. (Ed.), Proceedings of the Second International Conference
on Artificial Intelligence Planning Systems, pp. 61–67, Chicago, IL. AAAI Press.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics,
SSC-4 (2), 100–107.
Hoffmann, J. (2001). Local search topology in planning benchmarks: An empirical analysis.
In Nebel, B. (Ed.), Proceedings of the Seventeenth International Joint Conference on
Artificial Intelligence, pp. 453–458, Seattle, WA. Morgan Kaufmann Publishers.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence Research, 14, 253–302.
Howe, A. E., Dahlman, E., Hansen, C., Scheetz, M., & von Mayrhauser, A. (1999). Exploiting competitive planner performance. In Biundo, S., & Fox, M. (Eds.), Proceedings
of the 5th European Conference on Planning, Vol. 1809 of Lecture Notes in Computer
Science, pp. 62–72, Durham, UK. Springer.
Joslin, D., & Pollack, M. E. (1994). Least-cost flaw repair: A plan refinement strategy for
partial-order planning. In Proceedings of the Twelfth National Conference on Artificial
Intelligence, pp. 1004–1009, Seattle, WA. AAAI Press.
Kautz, H., & Selman, B. (1996). Pushing the envelope: Planning, propositional logic, and
stochastic search. In Proceedings of the Thirteenth National Conference on Artificial
Intelligence, pp. 1194–1201, Portland, OR. AAAI Press.
Laborie, P., & Ghallab, M. (1995). Planning with sharable resource constraints. In Mellish,
C. S. (Ed.), Proceedings of the Fourteenth International Joint Conference on Artificial
Intelligence, pp. 1643–1649, Montreal, Canada. Morgan Kaufmann Publishers.
McAllester, D. A., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proceedings
of the Ninth National Conference on Artificial Intelligence, pp. 634–639, Anaheim,
CA. AAAI Press.
McDermott, D. (1999). Using regression-match graphs to control search in planning. Artificial Intelligence, 109 (1–2), 111–159.
McDermott, D. (2000). The 1998 AI planning systems competition. AI Magazine, 21 (2),
35–55.
Nguyen, X., & Kambhampati, S. (2000). Extracting effective and admissible state space
heuristics from the planning graph. In Proceedings of the Seventeenth National Conference on Artificial Intelligence, pp. 798–805, Austin, TX. AAAI Press.
Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning. In Nebel, B.
(Ed.), Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, pp. 459–464, Seattle, WA. Morgan Kaufmann Publishers.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: A sound, complete, partial order planner
for ADL. In Nebel, B., Rich, C., & Swartout, W. (Eds.), Proceedings of the Third
International Conference on Principles of Knowledge Representation and Reasoning,
pp. 103–114, Cambridge, MA. Morgan Kaufmann Publishers.
429

Younes & Simmons

Penberthy, J. S., & Weld, D. S. (1994). Temporal planning with continuous change. In
Proceedings of the Twelfth National Conference on Artificial Intelligence, pp. 1010–
1015, Seattle, WA. AAAI Press.
Peot, M. A., & Smith, D. E. (1993). Threat-removal strategies for partial-order planning.
In Proceedings of the Eleventh National Conference on Artificial Intelligence, pp. 492–
499, Washington, DC. AAAI Press.
Pollack, M. E., Joslin, D., & Paolucci, M. (1997). Flaw selection strategies for partial-order
planning. Journal of Artificial Intelligence Research, 6, 223–262.
Purdom, Jr., P. W. (1983). Search rearrangement backtracking and polynomial average
time. Artificial Intelligence, 21 (1–2), 117–133.
Refanidis, I., & Vlahavas, I. (2001). The GRT planning system: Backward heuristic construction in forward state-space planning. Journal of Artificial Intelligence Research,
15, 115–161.
Schubert, L., & Gerevini, A. (1995). Accelerating partial order planners by improving plan
and goal choices. In Proceedings of the Seventh International Conference on Tools with
Artificial Intelligence, pp. 442–450, Herndon, VA. IEEE Computer Society Press.
Smith, D. E., Frank, J., & Jónsson, A. K. (2000). Bridging the gap between planning and
scheduling. Knowledge Engineering Review, 15 (1), 47–83.
Veloso, M. M., & Blythe, J. (1994). Linkability: Examining causal link commitments in
partial-order planning. In Hammond, K. (Ed.), Proceedings of the Second International
Conference on Artificial Intelligence Planning Systems, pp. 170–175, Chicago, IL.
AAAI Press.
Vere, S. A. (1983). Planning in time: Windows and durations for activities and goals. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 5 (3), 246–267.
Weld, D. S. (1994). An introduction to least commitment planning. AI Magazine, 15 (4),
27–61.
Williamson, M., & Hanks, S. (1996). Flaw selection strategies for value-directed planning.
In Drabble, B. (Ed.), Proceedings of the Third International Conference on Artificial
Intelligence Planning Systems, pp. 237–244, Edinburgh, Scotland. AAAI Press.
Younes, H. L. S., & Simmons, R. G. (2002). On the role of ground actions in refinement
planning. In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of the Sixth
International Conference on Artificial Intelligence Planning and Scheduling Systems,
pp. 54–61, Toulouse, France. AAAI Press.

430


	
 
			 ! #"$ % 
'&)(*,+-(**.0/21 .354'166

789:;  <)*30=
*.!>@?9	%&<A1 (0=
*.

BDCAEFEHGJILKNMPORQ
SUTVTXW

YPZ[A\U]_^,`ba2^Jcd^,egfh)f2i0jAelkmcRZonpjgqr`tsufvh)fvi0jge

wyzNx {}|~dLz)zN

d2d$dA$N

$oL ¡¢£¤0¥
¦¢§©¨§«ª;¬­®¤0¯u°d¨±¥²¨
ª;¨¦0¤
¬´³¤mv¢¥²µ0¯}¡£¨@¶¨µ¢¬¡¸·
¹ · ¹¹º¼» ¨¥5µ5¤¶¬@¡N¨½#¾@®¨¢¡

¿ÁÀ)ÂÃ}ÄÅ2ÆNÃ
ÇvÈ0ÉÊPÊgË8ÌÎÍvÉÌgÍ²ÏËJÐ#Ñ,Ñ)ÒÔÓ}Õ×Ö#Ø-Ù@ÌÚÛÙÚËRÙ@ÌÜgÝÍ5Þ2ÛÞ²ËRÝÌgÍ5ÏË;ßØ-Ù@ÌÌÝ×ÌÚàÈ0ÉÊPßËÍ²ÝÍ²Ý×ÉÌ$áâãÉÈÛÞ²ÝÌÚ
ÉÌäÍ5ÏË;È
ÏÉÝ-È0Ë!ÞdÊ¼ÙÜ}ËåâãÉæ«ÙÈ8È0ÉÊgÊPÉ}ÜÙ@Í²Ý×ÌÚÍ5ÝÊPË;Ù@ÌÜAÈÉÌÈÛæ²æ5ËÌÈ0çÕdÇdÙØ×Þ²É)ÜÝ×Þ5È0ÛÞ5ÞvÞ ÉÊPËåÊPËÍ²ÏÉ}Üè
ÉØÉÚÝ-ÈÙ@ØÝ×Þ5Þ ÛË8ÞÍ²ÏÙ@Í,ÏÙéËàÍ²É´Ü}Émê;ÝÍ²ÏëÍ²ÏËgÊPÉéËàÍ5ÉêåÙæ5Ü´ÊPÉæ5ËäËìßæ²Ë!Þ²Þ²ÝéËàßØ-Ù@ÌÌÝ×ÌÚuØ×ÙÌÚÛÙÚË!Þ
ÙÌÜíÍ5ÏËàîÙØ×ÙÌÈ0ËïÌË8Ë8Ü}Ë!ÜuÝ×ÌbßØ-Ù@ÌÌÝ×ÌÚPæ5Ë8Þ²Ë8Ù@æ
È
ÏmîNË0ÍêåËË8Ì´Þ²ËÊ¼ÙÌÍ5Ý×È8Þ;Ù@ÌÜ´È0ÉÊPßÛ}Í5Ù@Í²Ý×ÉÌ$Õ
ð2ñtòÎó Ã}Äô;õ,öÆNÃ÷ô ó

ùãý	
$û}ü
@ý´û}ü$ýùüÿ8ûãû
@ýù

ùãü¼ùÿû}üãüÿAû}ü$ý $ü$üãü$ÿ

"!#8ý%$5ü&
'ü$ûãùü$û(ãû}üüãüÿ))ù*%+,
'ãùü.-/0
'1û*%
"+324tû}ü3
ú5
@ü$ý
@ý3+6ãû}üüãüÿãû}ü87
ÿ$ûÿ
¼ûùüÿ924 ûuü5*9
',
 ù« ü
'2:+0 ù6
*;û}ü$ý ýùÔ
* ûã ü6<$ û=>$ û?@
 üÿ@
 ý@
 ú8Aã üÿ	+6 û}ü$ü
'>
û}ü$ýB2"AA
'0
 ûã üA1C $ ûA@
 üÿ
;D
%+6ã û}ü$ü
'>¼û	2E
AF-;/4t

 ÿ}ùûJ ù=Amüù
@AGùC ù*3*%@
 ü&
ùüHù*%

 ù0¸

 ý
'?ùü$ ûI2J@
 ü&%ã üK ùL

 ý
ãÿü ù"
M û}üÿ$ ûÿ
O'N øù@úQP þ«ùüÿRESTT!U $WVXA ù0 ÿû}ü6'
Y

C ù*;*%@
 üKZãü& ù[
'
Yd+ û'\B
Y
 ú5@
 ü>ùü û}ü$ý]
@t
* ùAÎ^ û ùü_R0

>$ ùA
=*Ôû}ý
0 ù) û' ù*;t
* ùNýûã üÿA*%ä
 û}ü$ý@ ùü'>@
 ü1NR û}üý3
G
ù.
"ã û}ü$ÿ$ ûÿ
"ã ü;

 ù*%+,
' ùü_
øùúuû}ü$ý´þ«ùüÿ

` ñ3aMb<cedf Ã có Â÷ô ó Â¸Å ó õ Ã b<c ÷ÄYg ô2Ã÷Fvh ÅdÃ÷ ô ó
R
/0
J(ãû}ü$ü6ãüÿ0igù*Ôûãüi
>+ãùümþû}ü$ÿ$ûÿ
R(iGiPþLjR#2ïûRý
'^
ù+,
@ý	ù
@üù8ûÿ
kû>ãüÿ
+0 ùl
*3 û}ü$ý û ÿ}ù>6*3mëû}üý]k*%@
 û}ü üÿD6_ ù*%+ û>?ùüLùn+,
' ù>Ô
* û}ü
m8vR û}ü$ýYt
* ù
9+
'A?7
A ûAA1O ùokp+0 ùq^5 ý¸

 û]Nr ù*3t
* ùül´
U ü$ù0 û ùüs ù3+0 ù6A
*3IãüH
ut"$v(=w&7yxzL(ã û}üüã üÿB)) ùüK
m
NF{Y'i"
' t
* ù'RJSTTTKU -|(JiP
i þ}j3v ù ù~2E@
 ý[D@
 û
9 ùr
* û ü5*9,
'í
 ù
 ú8?ã üÿ+6 û}ü$ü
'>'R1
'
ùüt
1 û	>6
'J ù.
"ã û}üÿ ûÿ
4ï2 û
@ý@ã ü%
 ù*%+,
' ùü.\t
* ùA1
Gw5>A+6;û}ü$ý;tP
i þL7

'Pû ùüÿ@24|15+
-Aø@
 û>
Am

 ûÎú ù*3'R,0ûD
'1C ùü ûã ü&'Rvû}ü$ýu
 ú8+
>ùüY
'Î^ ûA û ùü
2E
'ë

 üù6
@ý.#R û}üý û$ ûA1 ý ý$ü.VÔ
* û
@A	ã üK ù|
;(iGP
i þpýù5'6*%@
 üKm
 ùE
;
 ùü$ý ù*I7
+,
' ùüLNrï û'>5'RlSTTj~U )- øù
G ýM ù*%+,
' ùü_R5ãÿü6 û}ü&J
 ú8@
 üãùüE2J
'
ã ü&0 ù ý@
 ý
ã ü'?$
 ýã üÿ
j-4*%
' AG6@
 ü&Nrã ü¸û}ý$ý6 ùüZ ù3v ùNù@
 û}üZ6@
 ü& U
S5-4t ùü424¸
 ý û ùü
!5-4t"6A û1;+lã û}ü*%
'>A'
-ï) ùüKã ü5 ù4>$ û}üÿ

/0
Mã ü&0 ùNý6 ùü ù4

M@
 û>
´û+6+@
 û>@
 ý[ ùC,ë

 ÿã ý@
 ý[51B)2 ùBÔ
* ûã üe>
'>ã û8\%2"
'
'

I36rF¼
 ù
G
 ú5@
 ü>ùüùã ýM,
0û@
 ýu'@
 û 1 û}ü$ýZ2"
'
'=
'1M,2 ù ý@@
 üû6
G



l

#

(**.åN %% !<5

 #

d		Î&0%% 0<



$


@üù ýãüÿ ù3kp
@ûAA?%+0ù6A
*3m8-u))ù*%+60ûãùü$ûùü>ãý
'ûùü6	
'
*%
@ýùCû^
M+6ãû1
@ý û


'90ùA
-C$
ü$ý
'
@ý_R2"A
ëûI
MA*%
 ù0
Z 9ù*%+,
'ãùü.RJw5>+lmû}ü$ýet"iPþ+lãû}ü$üãü$ÿ
2E
'
2J
?.$ ü$ý
'>ùù ýû}ü$ý
'^
' û_ ù*3+60ûùü$ûû++0ùû 
0$û}ýZ,
'
@ü¸ý
'^
ù+,
@ý.R
ý
 ù*%+,
' ùüLD@
 û@
 ýL
 ú8@
 üãùüG$ ûí

 ûA*%@
 ýL ù+6

@ü&í
 ü
'2D ü ùü$ûAA
4 û
'2) û}üK1

'v+ ù@
 ýI+6 û}ü$ü
'>ùã ýI$ û}ü$ý6
-{ ù
+>
'A
1R246A
J ù*3+60 û ùü$û û+6+0 ùû>
nùJ ý@
 ûAã üÿ
24U
 ü&*3
'>A6@
 üK û}ü$ý û ùü@24U
 ý û ùü63$û^
C,
'@
 ü] ý@
 ýs ù@ù*3
|A*%
eND
- ÿ-R
 ù5

'R	jxxz594ã ü&0 û}ü@
 üP¡ K$ üÿ ùA'R	jxxx5ä¢ ù.Ô
¼
* û}ü$ü_R"STTS5m
 þûv ù>A
CP¤£G$ ûAã û¥R	jxx¦5
w8*3A§P©¨B
ã ý.Rjxxx5I}  ùü>ùü.R4{ ù>A'R{|>
' ùã û8R0P©A ûqª û}ü_RSTTT8g¢ ûA*«P¤£
v ü
'R
STTj~U R_+ ù+ ùûA0ù¼
 ý@
 ûAã üÿ;24 û6 û>1+6ã û}ü|*3
'>A'Pû}ü$ýC ùüKã ü5 ùG $ û}üÿ
%$ û^
I,
'@
 ü
* ù
9 ùü
' ü@
 ý2"
Ô
t
* û}ü&A'0 û}ü24 ù*%+l0 û ùü[ND
- ÿ-R,{|'i
'>t
* ù'R.STT!U w5
' üÿÔü
'2o $ ûA@
 üÿ
4ãüZ
 ù>* ùt
* ù¼

 ÿ@
 ü
' û¥15+,
àù+lã û}ü$üã ü$ÿ90 û80Aäü

0û1
û}ü$ýYv
+ ù^
	 ù
96
ã ý.dR ûA ù ÿY
'u

 û>
 ùPû2E
AF-4t"$+6ã û}ü$ü6ã üÿR6AA
9t"$0
vRlAgû
6 ÿZ¬X
A
'+6$ û}ü&'VR û}ü$ý+ ù}ÿ
0ùä û3>*ÔûA_ ù*3*$ üA1ZAvù$ ü$ýZ ù3,
 ù*%
9ù~y
2 û}ü$ýuû
'>@
 ý
à ùü
M

@û >
'% ùNù5bûb
 ûL
 ÿJR ûY
 ùü$ý û9
M>$ ül;R û}ü$ý ûC ý û9
M0 ûAFÁ
- øù8'IA
A*%v+ ù0 û}ü&'R û}üý; ù5'6Jùü@
4 û>A'J?<
'^@
 üMt
* ù
GA*%v+ ù0 û}ü&"Nr
'

4+ ù}ÿ
EãüMw8tn/§ù^8ã üÿ
ù"
 úû*%+6
,
- ÿ-GE
'
P­w8AÔ
* ùü.RSTT!U -t ùü&ã ü5 ùD4ã ü|
;¬X+60 ù6
*® ù@,
90ù^@
 ý.VR
24?
4ùq24ã üÿ´û´ÿ@
 ü& ü
" ùü
'8 üZ ù=t
* ù
Gv+ ù~2E
'r6t
* ù ý
A)û}ü$ýû++6?A û ùüJ*Ôû1 ûAùbý
'
'

 û''*ã ûã ùütùl üùq24@
 ýÿ
$ û<?;ü

0û1I ù û>6
'^5 üÿùAã ý+0 ù}ÿ>
'-n/0
= û}ü> ùü
ùw8tno
/ û}ü$ý)0w8(Hã ý@
 ûD0 ù*¯
ã û@ ù
@
 û,2 ù ã ý; ùNù;Ô
* û}ü&131@
 û>=l
'1;,2 ù ý@$ û~^

+0 ùd û61I0 û@
 üZÔ
* û}üK13Ô
* ù
R,

G ù*3*9 ü
J$û}ý$ü.VJ
'+) û ù8',ùü;
" û>A0+ ù6
*3
ù3,
	ù^@
 ý_þ
'24A
R8>
 ûA@
 üÿ
Eù*%
ã üëý6°
'>@
 üK='
)û}ü$ýMù*%P

 û
Ô
* ù
"d ûA0 û}ü ù
'>'-{ ù
7
ù~^
'~R¥ù*%
3Ô
* û~1|,
I2J
?°7 ý
' ü@
 ýC
Ô
* û}ü&A ûAA1u6P
 üù ù*%+60 ûã ùü$ûA1-±4- ÿ-R ýùZ2E

 ú8+,


'rv û}ü$ýÿ@
 ü
'8 û_ ù*%+60 ûã ùü$û_*%
' ù ý=$ û424AAl,2 ù>@ ù9²³l´°B3rµ Fq¶C{ ù0A
A1
üù'm
\ û}ü û++0 ùû O0 ûl
I ù	>@
 û>ã ü$ÿt

 ÿ}ùû<24A û*3ã üA** ü&6*,
'¼
 ùà û ùü'RÔ
* û1
üùI,

 ÿ}ùù ýe ù%@
 û ã üÿL

 ÿ}ùû2"*;ã üA**©
ù>
 ùü>*%+ ùü ù%24 ûLÔ
* ûÎú°7
*r
* ü5*9
'¼
 ùà ÿ}ùNù ý'-@/4

;Ô
* û~1B,
; ù*%+6
'
A1 ý
'@
 ü& ù*%+l0 û ùü$û+0 ù6
*;G
'^@
 ü
=
´
 ý
>A+ ùü[?	^
'1O?*3Aã û@ND
- ÿ-R.ª	ã ü ûv ù9
'+6ã û'ã ü$ÿ û}ü û}ýý ùüO>ÿüO51 û
*+6?A û ùü|>ÿüY üY
I ùr$ üã ùü ù) ûZAã ü@
 û+0 ù}ÿ û*MU -	$y, û@+lã û}ü$ü
'G û}üL0 û8
3 
ÿ@

 ü
'>?4+ ù6
*3'RK2J
Gù ý3+0 ùd û61I,
"+
) ûv ù
G·5$ ûAyt
1 ù.
0ùA ùüJd ü$ý'R
û*tùA1@A
A1R8AEA*Ôù~^8ã üÿ0
 ù* ùü
	ùA ùü@ ù%¼

 ü
 ú89¸´¹º8´»²CNrF-
-R24
 üùI
Aë
* û ùü
ù+lã û}üL
 ù U -3w8A*3A û>1R62"A
 ù	>
Pÿ^@
 üL51|
%* ù) û ùüB ù+60 ù~^8ã ýt

 û
A*3+6m

 û}ü$ýÁû++60 ùû>$ ûlu

 ÿ@
 ü
' ûA@ û ùüÁùJ'ã ûA û+6 û}ü$üã üÿdR û}ü û}ü$û ù}ÿ}ùPû}ý$ýA^
>W7

ã ü32"A> û ùüZ ùïý
'+,@
 ü$ýëü$ù, ùüA´
1 ùü@P

 û ùüM6 û?ùuùü@
W¼¼
 ùü@2"A>;

û ùü@A;ýùü
R5Anùüãý
'
 û61Ô
* ùä
 ý½@''-g û*%
1R&
 ý½@'1ã üI ü$ý6ã üÿ+6ã û}ü
ë
* ûã ü
 ü $ û}üÿ@
 ý.R¥6GÔ
$

 ý½@'1Yã üL ü$ý üÿëÿ}ùNùNý ù¼
 ù+AÔ
* û+6 û}üGãü@
 û
Rû24$ ùP
 ÿ}ùù ý
+> üã üÿ>
ïù4
AÔ
* û ù>R$ùü
A=vù$ üý@ ù@ ùüãý
'ä ùü
	 ù*%+6
'
+6ã û}ü¸ûD
'A û}üù
'~,¾ ¿FÀÁÂrÃ zlÄÅ z5Æ@~lÇ#{z&ÆÄ<Èd¥ÉoÊu~d#{KÇ#Îz {Ë
/0
Lû}ýýùü ù¼ü5*%
'>AM6
@üKÔû}üýsA*%
uãüs(JiGigþS5-Aju?ÔûO
@ü>6
Z*tù~^
Y$ûëûA*;%ù
ãü ù>+ ù8 û
0
@û

úA
@ü&ãü ûíü5*,
'Jù.+lãû}ü$ü
'>0ND
-ÿ-Rþ#ûù 
"PÌ£$ûAãû_Rljxx¦5lw8*3
P¨B
 ý.Rjxxx56  ùüùü;
', ûF-RSTTTKU -¨AA
0'VXüùJ+vù6A
ù
ú8+
,û6û>1Iùü6ûãü&
,
'2E
'@
 üÁû ùügû}ü$ýlÍ ùGÎ^ û ã û6
 ûGãüYù*%´

 ùn

+6ã û}ü$ü
'>'R
9 ûAD ü ùü$ûAA¸
1 û}ü$ý
 ù*%+60 û ùü$û< $ ûA@
 üÿ
uû
3
'>
-Mgt üOA*%v+ ù0 û}ü&¼

 ù*3A>ùüBã üO*91L^5A
'2ÎAGë

 ûl
@üë

 ù
>ÏqÐ
Ö

ÑJÒGÒGÓÔ  ÕÖ×äKØ8#Ù}ÚãCÛØ=Ü)lÝqÙ}Úãd

ú8+6AA'@µÞß8µ >à"
'+dûû
Z0ù*FûãùüH+
û}ü$ýe+ùùü$ýùü6'-B0
ù 
%ãüH>
@ý6Aãüÿ
û}ü$ýù*%
;+lã û}ü$üã ü$ÿZ15
*;@ND
- ÿ-Rn¨A8ã ü'Rjxzz5=)=>A
;Páå
/ û
R=jxx8jEï û+A
RR( û+
RP
 ª@
 ü.R8STTj~U û

@ýM ùÔý
'
'>*;ã ü


'^
v ùE Þl'ß8µWµ'l'²M$ ûAïûA ùq2J@
 ý ü û+ ù6
*±0- ÿ-R_AJâ%)2 ù
'>¼ût

 û~Î^ ûA û6
vR û}ü$ýC
'b

 û
9Z0 û8$ ûG
·5
IS;)2 ù
'>
@û .R.@
 üÁû
* ù=P
t
! ù,

"0 û5Eû}ü3,

 ú8
'@
 ýZ ùü'>@
 üK1-ã
'24A
RK
0
ù>
ü
'@
 ý@
 ý3
 ú
'@
 ý

 û+ û'y1-[/0?9A´û}üH
 úû*%+6
 ùA ûC*96°7 û+ û'y1R@
 ü
')2 û6A
@
0ù>
) ù
'I15+
bù

ù>
tû
u ù*3t
* ùüÌND
- ÿ-R= ü$û1O
0ù>
'RE ùüÔ
* ûl
Z
ù>
R
'~U -H5$ üs(JiGgi þäS5-AjR

ù>
Pü
'@
 ýC ùM,
9@
 ü ùNý@
 ý û¼ü5*%
'>?	6@
 ü&'Rvû}ü$ýY
%1Nü&0 ûÎú ù<u

 ù+,
' û ù>G0 ù ÿ
ù*%A

 ûÿ
'@
 ý;v+ ùüI ùü&^@
 üK ùü6Nrt
* ù>ä
 ûv ùnA,
 ùq2U R ý
'
'>*;ã ü

4A
'^
 ù ùü6'@
 ü1
ûA ùq2J@

 ý_-<5$ ü*91Z^5A
'2	RA  ùA
Aü ù>$ ü$û
 ù0
'
	>@
 ûùü'\
û 2ïû1
å§æ ß8µ WrF>´´¹²RE,
û
u
ú5+lAA'
ù 
3û}üQ,
Z
ú5+lù
@ýQù*%+l0ûùü$ûAA1ãü B
û ÿ
@ü
'û#ü&*3
'>A6
@ü&0û}ü.V'R

å  36rF>´´¹²R",
û
C
ú8+6AA';
ù>
M+ù~^8ãý
 û}üoû'ù$ü&ùùü'>
@ü1Q$ûZA
>A*%+6
 û}ü$ý'A
@û}ü.Rnù*%
'ãü$ÿ|$ûIû}ü$üùI,
@0ûý ûvù
@ù>* ù4ùü'>
@ü1Oãü
(JiGigþHS5-AjíùG£û+6+lãû}ü.Rû}ü$ý
å  ÞlWy³rß´D´»²R
û6
%
ú5+lAA'"
ù>
R«ûùüÿ24YA*%
R¥+0ù~^8ãý

tü$û8û#ÿ
@ü
'7
û?@ûùüLû}ü$ý|$ü6ûãùü ù+6û}ü$üãüÿ´û}ü$ýu 
@ý?ãüÿþ¥
'"00û424A
	 4A>
-J4
ù>
Aû
9
@ý ù@
 ùü&0 ù

'^
 ù ùü6'@
 ü1
û*tùüÿB0
 û5'\uA4
 ú8+6AA'A1 û' ù*3t
* ù ý$û@
 ý§ ü
uã û}üÿ$ ûÿ
RE
'1 ýùü.V3$ û~^
u ù û++,@
 û3ã ü
û ùüC+u

 ù"v+ ù ùüý ùüäù üu´

 ÿ}ùûFA- ø$ù>
ù>

@ü ù ý@
 ý û46@
 üK'R´

 ù+v+ ù

A>
-</0
4
JA<$ û'R$ ü6
n
0ù>
ïûA
 û ùÔ
* ûA ûA13 ý@
 üKA@
 ý%5Ô
1 ýùÔ
* ûã ü û}ü$û18A'R
+> üã üÿ=*%
> û}üA*3û}ü$ý ùq2J
'v ù$ ü$ý2ý
'^
ã ù+@
 ý	 ù$ û}ü$ýA üÿJ>
ù>
END
- ÿ-R þûv ù>
RSTT!U
 û}ü.V0,
	
@ý.
þ
'24A
R

 ý
' ü6 ùü ù" ùü'@
 ü61Oã ü[
' *3´ù0
ù 
9A9 û}ü+û@
 ü&'-Ctá
'´
 ù
û ùüJç§
 û}ü;,

 ú5
'@
 ý@ ùü'>@
 üKb
1 û?*%
èAl
>
ù>
,ü
'@
 ý@
 ý%519

äû ùü,ýù
üù

 ú8
'@
 ý9
J ûd+ û'm
1 û~Î^ û?ã û6
 ûè -<P
ã ü
 ù
'$ û}ü$ý.R#ã ü	(JiP
i þS5-AjR ûãü9£ û+l+6ã û}ü.Rq


'^
N ù6 ùü'@
 ü1?åý
' ü@
 ýA*%+6A?'1" ü
'>*;#ùl
" ²6¼Ô
é ù6+)
 û}ü$ýv+ ù ùü$ýã ùü'-¥
$ ü
£ û+l+6ã û}ü.R& ù=
 úû*%+6
R8y,2 ùtù+,
' û ù>û}üZ,
"
 ú5
'@
 ý| ùü'@
 ü&1;A.
'1 ýùü_VEã ü&
'D
'

24O@
 û> ù
'<F-
-Rï ùü
 ýù&
uüùu
 ý

'
;+>
 ùü$ý ùü6Pù9v+ ùA^
%

´ùÔ

 ù
'(iGP
i þS5-Aj	
 ú5@
 ü$ý6Aàý
'd ü ùüMã ü¸ûtü5*,
'ï ù)2 û~15'R60 û5ã ü$ÿ3ã üK ùÔû' ù üK0í

 ý û ùüù
û ùüäû}ü$ýM
	ã ü&
'Î
^ û?ïù~^
'0246A>M+
 ùüý ùü=$û~^
	 ù%,
G+

'^@
 ý_J- øù4A*3+6AA'y1RK$WVXA
ù5' ùüY£ û+6+6ã û}ü.VXàüùã ùüù ùü6'@
 ü1 ùü1RA@
 û^8ã üÿ%


 ú5@
 ü>ùü ûý
) ùü6ãý
'0
= ù5>5"¨ ù>ã ý û}ü$ýuu
)

 û ùü4êuë#ì5íKNrîlï>ðqïñäU û}üýuêuë#ì5í&Nrî6ï>ðqïò5U4$ ût
* ù~^b

 û
6 ù8uîZD0 ù*óðG ùMu
ñ û}ü$ý|òM
+
A^
1-)=@
 û 1R6

uû ùüGû}ü$ü$ù4,u

 ýùü
9 ùü'>@
 üKA1
ûû6 ù8%
 û}ü$üùJ,
0t
* ù~^@
 ý@ ùy,2 ùbý°,
'@
 ü&J ý
ã ü$ûã ùüJû
"0û*%
4A*%
-n/0
't
1 û
4 ü$ý
'@
 ý
*
 ú:ã ü£ û+l+6ã û}ü}'N û}ü$ý(iGP
i þÎS5-Aj~U ûZvù$ û^
 ûe+>
 ùü$ý ùüäNrë#ôNrî6ï>ð'UU@$ û
'1
ý

'
-;õ<
''R24K1Lù6ã ý ý

'ã ü$ÿLû+

 ùü$ý6 ùüÁùà û}ü û ùüîY+6
'^@
 üK´
 û}ü û ùüîKöD0 ù*
,
ã üÿ
 ú8
'@
 ýM ùü'@
 ü&1%ä
 û ùüMîI
v ý

'
J
0+6
 ùü$ýã ùül¶Z/0
ªA6 û ùü
ù4AAüù ùü ù ùü6'@
 ü1u ûäü
'^
',
'@
 üuÔ
* û}ý
9
 ú5+6?A''-E5$ üY£G û+6+6 û}üu0ï2 ûAû}ý$ù+@
 ý
,
 û
;A	@
 ü>
$ ûm
 ûA
'>ã ûAA@ û ùü¼ùà ûu
'u
 ù ùü'@
 ü&'RR û++6AA ûlt

 û ùü	>
Ô
* ûã ü
û++6?A
 û6

 û}ü$ýH18
ã ýH
u0û*3

uNr=A*÷P ø>'RGjxx¦U -Qõ<
''R=24&1Hùã ýe?%0û*%

>
'  ùüZ,

	t
* ù4 ùü&^@
 ü@
 ü&" ü¸ûI>1M ùü'@
 ü&4
' üÿ&¶
>Ï

Ö Ö



$

) ùü6ãý
'å üù~2H)
 û ùüêuë#ì5íKNrîlï>ðqïñåU û}ü$ýêuë#ì8íKNròï>íï>ø_U24A m
)
 ýùgüùã üK
'>
'
}R û}ü$ý95

äý
'
*%
@ý3ùü'>
@üK'-n/06AAJûù
,û*%+6ùüIù*Ôû
4A6
äü5*9,
';ùl0ùvùJû>*;<A
½@'
@üKA1ãûÿ
R&6A<ãü6ù
ù
'24A
-ã.ù 
4
4
@üùNý6ãüÿû}ü@,
0ú8
@ý351+lãû18ãüÿ
24;g

 ù+
'8 û ù>'8
- ÿ-Rã ü3
"+>

@üg
 ù û9>ãüÿä
 û *R&
Gù~èvî5ñ'úûqü6ô¥ù~èvî5ñ'ú3@
 ü6 ùNý üÿ	)2 ùã ý
+0 ùq^5 ý
J
= ù>
J û*3+ ùü´ùl ùü'@
 ü1R2"A
Eã ü
+

@üï
 ùl
'à
 û>*3'Rû>A*3Aã û

@ü ù ýã üÿR&t
* ù
4ã ü&}^ ù^@
 ý.R&,2 ù6ã ý%,
0v+ ùl)
 ûJ2E
AF-5$ üÔû}ü&13 û
R5ä
 û' ù$ ü&) ù, ùü6'@
 ü1
û
@ý ùüû ùüZã ü&
'
'>@
 üg
 ûïý
'd ü@
 ý;ã üZ£ û+6+6ã û}üëû}üý@(JiP
i þOS5-AjG û>A
J
'0 û üM?*%+6AA'A
û6*%+ ùü,û}ü$ýM
G·&
 ùü@?24
'
'J2E
)
2 û}ü&= ùIë
* û
$ ù
gû>*%+ã ùü'Rû}üý@2"
'
'

'¸
1 û
@
 û0ùü$û6í

 ùA üù'/0b

 û' ù üKu
 ùE ùü'@
 ü1Y û
@ý ùüB>
ù>
A*Ôù
% û}ü+dû@
 üK	 üLAG
@ü
åR û}ü$ý
* û
9
>AA9 ü ù Ô
Ô
* û ùüC ù9 ù*%+6ã ü$ÿMD@
 ûl
9+lã û}ü*tù
%
 ú8+6A?''-9/0Ô

 û' ù$ üKu
 ûAù
1
+0 ùq^5 ý
 ûtÿ}ùNùNý ý
 ÿ
'í

 ù
 ú6?A1R û ù$ ÿuã üu
'0 û ü| ùü&
 ú5û}ü$üù0>
'+6ã û
	u

 ü
'@
 ý
ùt
* ù>m

 ÿ@
 ü
' û ùü8 ûã üKIND
- ÿ-R, ùMû1u$ û0 ùv ùA û *34û}ü$ü$ù ùA?ã ý¼

 ùG û}ü$üùg ÿ
'" ùNù
' ù
qU û

ý ñ%þMÿOÿ Å ó õyÃ b<cHþ Å óó ÷ ó ô	
 c Ã÷©Ã÷ô ó
R
/0
uûù>Aù<(iGiPþsS5-Ajuû
I*tù^û
@ýY&1
uÿ}ùûù	k'ãùãüÿ@
mÿû+C,
'2E
'
@üY+lãû}ü$üãü$ÿ


@û >b
 û}ü$ýbû++6A? û ùüm8-wã ü

'1 û}ü$üùã ü6@
 ü,
 û++lAA û ùüR~
'1	+6
Ô
* ûl1*%@
 û}ü
$ û"
'1)2 û}ü&"(JiGgi þsS5-Aj9 ù@$ û~^´

 û}üYã ü6@
 ü¼

 ùü|+lã û}ü$üã ü$ÿ>

@û>>_Rt
* ùq^5 üÿ;ä û~)2 û~1uD0 ù*
ù~1 ýùÔ
* ûã ü6ùq)2 û ýH>@
 ûAAA û++6A? û ùü'-|A ùÁùü
Z û}ü ù8ªp
I ùÁûLt
* ù~^
Z ù~ï2 û ýH@
 û?AA
û++6?A
 û ùü'R51
''R$Jã üR'VX
'r ù%
'
'+|ã üZ*3ã üý@ ûG¬X ù~¸
1 ýùÔ
* ûã ü6'V5 û^

'>^@
 ýZ
	t4$
(< ù6
*©Nw ùA^5ã ü$ÿZ ù*;*9$ ü61L^
'1B2E
AF\wAã ýã ü$ÿ@+6'
ãüB¢"
>?A;w5@
 û> .R
 ü87 
'@
 ü
ã üB)
) ùü8 ûã üKw ûA'û ùü.R.= ù88¨ ù>ã ýLã ü|(Jã û}ü$ü üÿR6
'-	/0
'1u$ û^
I+0 ùq^5 ý@
 ý| ù8''R2û}ü$ý
 ùü
'+ ûA1>A*%+6
M+0 ùl
*3I$ ûÔ

 û
u ù*3+60 û ùü$û?1 $ ûA@
 üÿ üÿ û%2J
?F-s/0AI*3- úHA
 ùü&^@
 ü@
 ü&¥ ù¥ã ý@
 ü&D15ã ü$ÿE?*%+6
6,v+ ù~2E
'rã ý@
 û\¥
>?A
AÔ

* û ù>Rq+ û
'8 ümý$û0 û û
'R
 ùü8 ûã üK+60 ù+ ûÿû ùü¸û}ü$ýÿã ù û, ùü ûã ü&'R$û}ü$ý0ùtùü.-n$,
A
'^
GA=2)ù¸

 û8ã üÿR8D0 ù*
A+,
'>+
A^
R24
'
'J û	 ù~1I+0 ù6A
*A
0= ù88n¨ ù>ã ý3?
ú8$ û6@
 ý.-$yJ'@
 û>1Ô
* û
<ù
û}ý;+
'RK6$ û~^
42E
"@
 û8 ü@
 ý% ù90ù^
0
"+0 ù6
*}2E
AFR5ã ütûmý$ùÔ
* ûã ü87ã üý
'+,@
 ü$ý@
 ü&' û ùü¶
$vP
 ü$ù'R2J
CÔ
* û1s,
|?A0*3A>ãüÿOù*3
|r$ ü$ý$û*%@
 ü&0 û0ã ý@
 û3$ û û
YAA
1H ù[,
 ü
'@
 ý@
 ý§ã ü
>A 
'0
'ã ü$ÿäûAù%D@
 û> üÿ3 ù*%+6
 úã ü&
' û ùü0
'y2J
'@
 ü û ùü+6í

 û}ü$ýv+ ù ùü$ý6 ùü'w8 +0 ùl
*3¸û
[Ô
* ùLùD@
 ü ã ü& û0 û6
R1
'C
[+
'> ù>ë
* û}ü
 ÿû+o,
'2E
'@
 ü ÿ@
 ü
' û
+6ã û}üü
'>û}ü$ý+,
'ã ûAA'@
 ý:0ù^
'>Z
Ô
* û üãû0 ÿ
R
 û++6?A û6AAA1 ù+6ã û}ü$ü üÿ[
 $ üù ù}ÿ1
24A?>
Ô
* ûã üOA?*3@
 ý.-%/05246A
%	A+vùA^Ô

 û}ü$ý ü

>0û1L ùYÔ
* û
;0 ùù*©ã üB(iGP
i þoû}ü$ý

G(ã û}üüã üÿ9)) ù*3+
'A ùü3 ùt
* ù
G ù*%+6
 ú3+6 û}ü$üã üÿ	 û}üÿ$ ûÿ
ïû}ü$ý@0 û5R5$n,
AA
'^
4$ û=
AàûA0ùëü

0û>1M ù@ã ý@
 ü&1 û}ü$ýuÔ
* ûã ü&0 ûã üLûI ù8'àùüuù*3
 ù
 ù*%+l0 û ùü$û.+60 ù6
*3/0
; ù*%+,
' ùü û}ü$ý[9+v+ ù üÿã û}üÿ$ ûÿ
Mùã ý û?ù ÿ^
@

@û> 
'>´û}ü$ýO+6 û°7
 ùü
' àû}üã ý@
 û´ù
	0ûí

 ù¥

ã ý.\24$ û8ã ü$ý ù+0 ù6
*;Eû}üu
t
* ù ý
@
 ýû}ü$ý0ù^@
 ý.R
24$ û"5 ü$ý û}ü$ýC'u

 ù<+0 ùl
*30û}üC,
9ùA^@
 ý|2E
AFRl24$ ûA û+6+0 ùû>
"2)ùu,
gû}ü$ýY24@
 ü.R
û}ü$ý ûA0ùZ$
 ù~2' û¼ù	ùq2
%
ã ýLAG+60 ù}ÿ
üÿ-9(0 ù}ÿ
*%@
 û}ü6,
'
'	ùA ùü6üB

A*%
R û}üý9lã üuû}ýý ùü.R û ù*3*3*%@
 ü& ùPù+AÔ
* ûAA1	A*Ôû}ý
R+60 ù}ÿ
*%@
 û}ü*tù>
Jv+ ù~2E
'r

  "!$#%'&)(+*-,.%0/#2134 65 #%'&7(*8 :9;*<:#=>*?&A@0B54C/:>@D/71EA1F@G*?/ HI@G5 #KJ  @0/<LM/*<%JE/&:*-HN &7
@0/	 A1EA1;5'L;@0&%E*I#2(?9;%D=+2EE'O @G' E@0P1;&:#A@0  C5 #%'&7(*:RQIE8/:*<JE#SI*$P@D@0#2#PE:*<8@G&%E*IHN#2#
54C9"JE)T3-U9;#2@0/#SL'4 6@0/9V&A@GW54C</A@0A1W@0*X@Y/*<%JE/&K@GP1ME:F@G##R@G&%E*?/AZ'J S/ Y 6@0/9[HN#2#
54?/:@0/71A1M@G*N96JET\&
>Ï

Ö ÎÓ

ÑJÒGÒGÓÔ  ÕÖ×äKØ8#Ù}ÚãCÛØ=Ü)lÝqÙ}Úãd
ãý
@û0ù"+>$üüÿû0ÿ
'4+û>àù
9
@û >|+û
90ûD
1û}ü$ý
,
^
1- ( /0
	ù*3+
'Aùü

ã ýIù' û<$ û~^
0 ùüK>A6@
 ýI ù

àÿ}ùû?'Rû}ü$ý%ã ü?2ïû1R5$ û^
" ùüK>A6
@ýIù
=+0ù}ÿ>

ù

ã ýû}ü$ýZ ù;A=
*%+6>?
 û ÿ0 ù ü$ýã üÿ-w5?AFR& û>
ù ý@,
G0 û@
 üuù% û0

	
>ùü
 û}üs,¸


 ý û~ä2 üe0 ù* D
M ù*3+
'A ùütû%2E
AF-etá û?@>
·&A
*%@
 ü&I ü
+

@ü¸

 ù
+vù~2E
'r6t
* ù ý
A üÿ	ã û}üÿ$ ûÿ
=6>ë
 û=(JiP
i þOS5-AjRAù
'd+ û û
"
" û>Ar$ ü ùü$û?
<ãü& ù
ý°,
'@

 ü&0 û>5ù@$ û4+lã û}ü$ü
'>Aûu

 ü$ù4
'ï2 û ý@
 ý ùü1Z51
" ùq^
' ûÿ
R_6ä ûAù@&1u ùq2
2E
A=
'1 ýùOã üH@
 û ]'ã ûÔù"0 û8'-]t=;
u0û*%
u?*%
u%)2 ùã ýH,

'r= ù ýAã üÿA>
 û>5E$ ûE
'
=Ô
* û
"

@û> M0 ù*¯ û>5E$ ûE@
 û
">

@û>>
 ûï û}ü;@
 û 130ûÿ
-gt ü$ý
+û û+l ûãü$ÿ4
G¬ üù7Ô
* ù~^8ã üÿ7¼0 û0 ÿ
'< 
Vã ü
0@
 û}ýbûA'
RK$¥ã ü$ ûn2J
0>ùã ýÔ
* ûã ü&0 ûã ü

3 ù8'íùü[
u¬X û>A%+0 ùl
*3Gù|,
;0ù^@
 ý.V û}ü$ý[
A	
;t"$0 ÿ
3 ùCt
* ù~^
 ùüO ù ü
'2
+0 ùl
*3àû0ùNùüLû4í

 ù> ÿ ü$û+0 ù6
*;=
 ÿ üZ ù; û-

] _c ^pc Ä có

cÂ
ïû'>5'RøE-4NFSTTj~U -s/0
uSTTTOt"$9(Jãû}ü$üüÿLw518
*3;)ïù*%+,
'ùü.-a`µr bJ'F´Cc 6´D´¹ed5lW
f[+dKE gDNR h3hNF!U ïû+A
Rn(-RnR( û+
R)R- þ<-R<Pó ª@
 ü.R¥¨ä-0NFSTTj~U j
- inÞrµp6l km#'>a
º nl æ >ºß8´»DK dKo"`=³³l´¹²K d
inÞWrµD6C p=µDÞ dµII du¼Þ nl æ ºß8´¹K dp=µÞK¸´A -E	A&2J
'~E
'
R i- þ<-R P
wAt
* ùü.R þ<- NFSTT!U /0
 w8t"/7T! ï) ù*%+,
' ùü.&+_\»ÍÍq20242	-X>F-DW4Í qG>At
* ùülÍ# ùü&
T!Íq
6
=A*Rt9-R#P ø>'R#{O-8Npjxx¦U - ø$û+6ã û}üüã üÿE0 ù ÿ	+6ã û}ü$ü üÿïÿ û+6í
 û}ü$ûA15?'-5$ üBpµpÞ~ >>ºDK d
AÞ rscGtIiN`scGkAu\vR++¥-,+j w4! wxl+j w#KS5-¥{ ù0 ÿû}üYí ûrÔ* û}ü$ü.)=>>
Rl3-R¥P­#/ û
R_t9-Npjxx8j~U -;ã"7¼+6ã û}ü.\./0u

 ù+,@
 üL+6ã û}üüã üÿëû >

y
- `GµWr bJ'F	´ c 6'´´¹z k
d5lW8R v4hNpj~U RKx x54z w5øùúRJ{[-R<P
þ«ùüÿRni-4NFSTT!U -H(iGP
i þS5-Aj\gt üe
 ú5@
 ü>ùüH ùB(iGP
i þ ù%
 ú8+
>ãüÿC
*%v+ ù û
+lã û}ü$üã ü$ÿ´ýùë
* ûã ü'-{tÞß8µ l´:Þ rs`sc}|4W'>µ æ -=/0A=A>
¢gûA*R(-RP £
2 ü
'R¢-NFSTTj~U -B¢4
 AA%+lã û}ü$üã ü$ÿ24O?*%
 û}üý[
0ù>
'-u
$ ü~p=µÞ 
ß8µpÞ ³V
 inÞ+ r''µ'l IAÞ rsp=´DK dlWiNp{kD4#R++_-_jS8Gj xlj!S5¢Aù,Ô
* û}üü.R= -NFSTTSU -J± ú5@
 ü$ý6ã üÿ øRø ù ü5*%
'>? û40û
L^ û>ã û6
-5$ üp=µÞ :Þ rC æ 
 \v æ
ß8µpÞ ³V
 inÞ+ r''µ'l IÞ
 `µWr bJr´ c l´D´» d&'l 
 lWiN`scGkA h+qR++_-6¦â5Gj x5¦â¦5  ùü6ùü.Rt-RnL
}
{ ù>>A'R¥(-Rn{|6
' ùã û8Rn-RnP ä ûq0ª û}ü.R3-ENFSTTTKU -B(ã û}üüã üÿuã üã ü&
'+6ã û}ü
'0 û>1
+û
\6/0
 ù>1 û}ü$ýu+ ûA
-<
$ üpµpÞE 	`scAp{n_kh\\R++_-_j~â+â xlj4z w5¼ù5

'Rn -0NpjxxzU -s( û}ü$üã üÿC$ ü$ý
'I
0ù>
 ùü û üK'-5$ üpµpÞE :Þ r æ 
 4 æ =ß8µpÞW³
inÞ+ r''µ'l 3Þ `cWiN`scGkAu4>qR6++_-8Kzx xKKx!5-,¨:AA
'1þûv
 ù>A
R(-4NFSTT!U -]t ÿ}ù>A*3ù;+0 ù+ ûÿûã ü$ÿB
ù>
u ùü6 ûã ü&%ãüst"$+6ã û}üüã üÿÁû}ü$ý
>>@
 ý6Aã üÿC- `µr bE'F$´ c 6'´´¹e d5lW	R 'RRj¦8Gj xljzz5þûv
 ù>A
R#(-RKP£G$ ûA û_R{[-6Npjxx¦U -l(Jã û}ü$ü üÿ424A>$û û6
E
ù>
nùü û üK'-
$ ü%{u
?AA.R
)G-¥Nr± ý.-»U $R pµpÞ~ 8cGtiN`scGk:u\vR++_-_+j w#K! xl+j w#Kx5-_L
{ ù ÿû}üYí
 ûDÔ
* û}üü.Æ

+$UE@De:#SLE/"9;:@G *	P@DX@0-#2:@G*lX%G "%GOE9Y@G#*<%#JE%F*"408O/J EA134E2*?JP@D/7@G':62*? %G? ::1EA1MHN 
 ?%OE9Y@0#2SzL}/:Z+JES/:9;:'*	1/%OEO4A13
Ö>ÏE



$

{Y'i"
' *tù'Ri-.NFSTTTKU -n/0
jxxzIt"$(û}ü$üãüÿIw515
*3=)ïù*%+,
'ùü.-?`GµWr bJ'F´_c 6´D´¹ed5lW
f[+ dKE gDNR hNFSU R.!¦ x54¦ w5{Y'i"
' t
* ù'Ri-JNFSTT!U -;/4
I ù>ë
* ûn
Ô
* û}ü&A'¼ùE+0 ù8

	ãüL(JiP
i þ-%5$ üpµpÞE cPiN`p;n_kDP
YÞ0µ q æ ÞW³HÞ pCMMR8++_-6z+â x5x#4 üK0 û}ü@
 ü_R -RP $ üÿ$ ù'R5¢9-_NpjxxxU -*%
'>A0û
	^ û>ã ûl
JüM ùü6 ûã ü&p7¼ û
@ýZ+6 û}ü$üã üÿ
$ üpµpÞE
 	=ß8µÞ ³>V
 inÞ+ rµ IÞ
 p´°6 dlWiNp;k:u\u>qR++¥-_j'Tx xljS8jw8*3A.Ri-RP ¨B
ã ý.R<i-0NpjxxxU -s/¥
*3+ ù8 ûJ+lã û}ü$üã ü$ÿ|24H*$ ûE
 ú'Aùüe@
 û0ùüã üÿ-O
$ ü
pµpÞ~ 8cGtiN`scGk:u\uR++_-6!4S wx5!!â&¨A8ã ü'R#i9-6NpjxzzU 	- pµp~rr ´ p´°6 d3oRéº d9 æ G'´#>Wr ´ `sc³8µº dI-_{[-í
 ûrÔ
* û}ü$ü.-

>Ï~Ï
Ö

Journal of Arti cial Intelligence Research 20 (2003) 291-341

Submitted 10/02 published 12/03

The Metric-FF Planning System: Translating \Ignoring
Delete Lists" to Numeric State Variables
Jorg Homann

Institut fur Informatik
Georges-Kohler-Allee, Geb. 52
79110 Freiburg
Germany

hoffmann@informatik.uni-freiburg.de

Abstract

Planning with numeric state variables has been a challenge for many years, and was
a part of the 3rd International Planning Competition (IPC-3). Currently one of the most
popular and successful algorithmic techniques in STRIPS planning is to guide search by a
heuristic function, where the heuristic is based on relaxing the planning task by ignoring
the delete lists of the available actions.
We present a natural extension of \ignoring delete lists" to numeric state variables,
preserving the relevant theoretical properties of the STRIPS relaxation under the condition
that the numeric task at hand is \monotonic". We then identify a subset of the numeric
IPC-3 competition language, \linear tasks", where monotonicity can be achieved by preprocessing. Based on that, we extend the algorithms used in the heuristic planning system
FF to linear tasks. The resulting system Metric-FF is, according to the IPC-3 results which
we discuss, one of the two currently most ecient numeric planners.

1. Introduction
The planning community has long been aware of the fact that purely propositional representation languages, in particular STRIPS (Fikes & Nilsson, 1971), are not well suited
for modeling various phenomena that are essential in real-world problems. In particular,
modeling context dependent e	ects, concurrent execution of actions with di	erent duration,
and continuous resources are all awkward, or impossible, within the STRIPS language. To
overcome the 
rst of these limitations, Pednault (1989) de
ned the (nowadays widely accepted) ADL language, which amongst other things allows for conditional e	ects (e	ects
that only occur when their condition holds true in the state of execution). To overcome
(one or both of) the latter two limitations, various proposals have been made (e.g., Ghallab
& Laruelle, 1994 Koehler, 1998 Smith & Weld, 1999). The most recent e	ort in this direction is the PDDL2.1 language de
ned by Fox and Long (2002) as the input language for
the 3rd International Planning Competition (IPC-3). The IPC series is a biennial challenge
for the planning community, inviting planning systems to participate in a large scale publicly accessible evaluation. IPC-3 was hosted at AIPS-2002, and stressed planning beyond
the STRIPS formalism, featuring tracks for temporal and numeric planners. This article
describes the approach behind one of the planners that participated in IPC-3, Metric-FF.
Metric-FF is an extension of the FF system (that can handle ADL) to numeric constructs.
Currently one of the most popular and successful algorithmic techniques in STRIPS
planning is to guide search (forward or backward, state space or plan space) by a heuristic
c 2003 AI Access Foundation. All rights reserved.

Hoffmann

function, where the heuristic is based on relaxing the planning task by ignoring the delete
lists (i.e. the negative e	ects) of the available actions. The heuristic value of a search
state in this framework is (an estimate of) the diculty of extending the state to a solution
using the relaxed actions. This idea was 
rst, independently, proposed by McDermott
(1996) and Bonet et al (1997), and is now widely used in a huge number of variations.
Examples of planners that use the idea are Unpop (McDermott, 1996, 1999), HSP in its
various con
gurations (Bonet & Ge	ner, 1998, 1999, 2001), GRT (Refanidis & Vlahavas,
1999, 2001), MIPS (Edelkamp & Helmert, 2001), STAN4 (Fox & Long, 2001), RePOP
(Nguyen & Kambhampati, 2001), Sapa (Do & Kambhampati, 2001), and FF (Ho	mann,
2000 Ho	mann & Nebel, 2001). The search paradigms used by these planners include
forward and backward state space search as well as partial-order planning. The forward
state space planner FF was especially successful at IPC-2 (Bacchus, 2001). In what follows
we extend the heuristic idea for STRIPS, ignoring delete lists, to numeric state variables
in a way that preserves the relevant theoretical properties of the STRIPS relaxation. We
phrase these properties admissibility, basic informedness, and polynomiality. While the
investigation takes place in the setting of forward state space search as used by FF, it
seems likely that the same ideas will also work in other search schemes such as plan-space
search (some more on this in the outlook, Section 8). The Sapa system also deals with
numeric constructs. The heuristic function, however, completely ignores numeric goals and
thus lacks one of the relevant theoretical properties, basic informedness (we will return to
this later). There are also numeric versions of MIPS and GRT. On the respective MIPS
version there is no publication available at the time of writing but an article (Edelkamp,
2003), which the reader is referred to, is to appear in this same JAIR special issue. The
numeric version of GRT, GRT-R (Refanidis & Vlahavas, 2000), allows only for a restricted
form of numeric variables and expressions, basically a limited form of resource allocation
and consumption. The heuristic function considers resource consumption as another form
of state cost. This, like Sapa's heuristic, lacks basic informedness, as we will see later.
In a numeric planning task, there can be numeric constraints (in action preconditions
and the goal) and numeric e	ects (in action e	ects). Constraints and e	ects can be of
di	erent types. For example, a constraint can require that the value of a variable be either
at least as high as or at most as high as a given constant. The numeric e	ects can, from a
semantic perspective, either increase or decrease the value of the a	ected variable. Now, the
delete e	ects in STRIPS decrease the logical value of the propositional variables, so the idea
we explore is to relax the numeric task by ignoring all decreasing e	ects. The main diculty
with this idea is that ignoring the decreasing e	ects does not necessarily simplify the task.
For example, when the goal requires that x < 0 and x is initially equal to 0, the decreasing
e	ects are needed to solve the task, so the relaxed task is unsolvable. The relaxation is thus
only adequate (preserves the theoretical properties mentioned above) in tasks where it is
always preferable to have higher variable values. We call such tasks monotonic.1 We observe
that tasks that belong to a subset of the numeric IPC-3 competition language, linear tasks
(in which the numeric variables are only used in linear functions), can be brought into a
1. There is a duality here with respect to ignoring the increasing eects or the decreasing eects. If
lower variable values are always preferable then ignoring the increasing eects is an adequate relaxation.
Whether one chooses one or the other does not seem to make much dierence. We choose monotonicity
in the positive sense only because it is conceptually simpler.

292

Translating \Ignoring Delete Lists" to Numeric State Variables

normal form that is monotonic. Based on that, we extend the heuristic algorithms used in
FF, and thereby the whole system, to linear tasks.
FF (Ho	mann & Nebel, 2001) is a close relative of HSP (Bonet & Ge	ner, 2001). Search
takes place forward in the state space, i.e., starting from the initial state new states are
explored until a goal state is found. The search process in FF is guided by a heuristic
function that is based on solving, in each search state s, the relaxed task starting from s.
The heuristic value to s is the number of actions in the respective relaxed plan, i.e., the
number of actions needed to achieve the goal from s when assuming the delete lists are all
empty. States with lower heuristic value are preferred. The main obstacle in the extension
of FF to numeric state variables is to extend the machinery that solves the relaxed task
in each search state. Once this machinery is de
ned, the rest of the system translates
e	ortlessly. We evaluate the resulting planning system Metric-FF by discussing the results
of the numeric domains used in the 3rd International Planning Competition. As it turns out,
Metric-FF and LPG (Gerevini, Saetti, & Serina, 2003a) were the best performing numeric
planners in the competition.2
The article is structured as follows. Throughout the text we refer to related work where
it is relevant. We 
rst give the necessary background in terms of STRIPS notation, and
the techniques that the STRIPS version of FF uses. Section 3 introduces our notation for
numeric state variables, i.e., for the numeric subset of PDDL2.1. Section 4 describes how
the heuristic principle for STRIPS, the relaxation, can be extended to the numeric setting.
Section 5 de
nes our algorithms for solving relaxed numeric tasks. Section 6 then 
lls in
the details on how the relaxed plans are used to implement the Metric-FF planning system,
and we briey describe how ADL constructs can be handled, and how exible optimization
criteria can be taken into account. The IPC-3 results are discussed in Section 7. Section 8
concludes and outlines future work. An appendix contains most proofs.

2. STRIPS Techniques
In this section, we give background on the techniques that the FF system uses in the STRIPS
language. We start by examining the relaxation that underlies FF's heuristic function. We
then proceed to the algorithms that are used to solve relaxed tasks. We 
nally describe
how the relaxed plans are used to implement the actual FF system. The discussion is a
little more detailed than would strictly be necessary to understand the FF workings. This
serves to provide a solid background for what is to come: Sections 4, 5, and 6 will, in turn
for each of the subtopics dealt with in this section, show how these methodologies can be
extended to the numeric setting.
Before we start, we give the notation for the STRIPS language. When we refer to sets we
mean 
nite sets. We consider the propositional STRIPS language, where all constructs are
based on logical propositions. A world state s is a set of (the true) propositions. An action
a is given as a triple of proposition sets, a = (pre(a) e (a)+  e (a); ): a's precondition, add
list, and delete list, respectively (we use the somewhat unusual notation e (a)+ and e (a);
as this makes the extension to numeric variables more readable).
2. The C source code of Metric-FF is available for free download from the FF homepage at
http://www.informatik.uni-freiburg.de/~hoffmann/ff.html.

293

Hoffmann

We 
rst specify the semantics of world states and actions. Throughout the article, we
consider sequential planning only, where a single action at a time is applied to a world
state.3 Actions induce state transitions as follows. Given a world state s and an action
a, the result of executing (the action sequence consisting solely of) a in s, result(s hai), is
result(s hai) := s n e (a); e (a)+ if the action is applicable in s, pre(a)  s. Otherwise,
result(s hai) is unde
ned. The result of executing an action sequence ha1  : : :  am i in a state
is recursively de
ned by result(s ha1  : : :  am i) := result(result(s ha1  : : :  am;1 i) am ), and
result(s hi) = s.
A STRIPS task { we use the word \task" rather than \problem" to avoid confusion
with the complexity theoretic notion of decision problems { is a tuple (P A I G): the
set P of logical propositions used in the task, the set A of actions, the initial state I (a
world state), as well as the goal G (a partial world state, see below). All propositions in
the actions, initial state, and goal are taken from P . Given a task (P A I G), what one
wants to 
nd is a plan. An action sequence ha1  : : :  am i 2 A is a plan for (P A I G) if
G  result(I ha1  : : :  am i). Since the  relation (not equality) is used here, there could be
several goal states in which a plan ends. If there exists at least one plan for a task, then the
task is solvable. Sometimes we refer to optimal plans. In our sequential framework, a plan
is optimal for a task if there is no plan for the task that contains fewer actions.

2.1 Relaxing Strips Tasks

We want to inform the search for a plan by a function that estimates the goal distance of
search states. The idea is to de
ne a relaxation (i.e., a simpli
cation) of planning tasks,
then solve, in any search state, the relaxed task, and take the length of the relaxed solution
as an estimate of how long the solution from the state at hand really is. The relaxation
that was 
rst proposed by McDermott (1996) and Bonet, Loerincs, & Ge	ner (1997), is to
relax STRIPS tasks by ignoring the delete lists of all actions.

Denition 1 Assume a STRIPS task (P A I G). The relaxation a+ of an action a 2 A,
a = (pre(a) e	(a)+  e	(a); ), is dened as
a+ := (pre(a) e	(a)+  ):
The relaxation of (P A I G) is (P A+  I G), where A+ := fa+ j a 2 Ag. An action
sequence ha1  : : :  an i 2 A is a relaxed plan for (P A I G) if ha+1  : : :  a+n i is a plan for
(P A+  I G).

Ignoring the delete lists simpli
es the task because the action preconditions and the goal
are all positive. We identify a number of desirable properties that the relaxation has. We
will later de
ne relaxations for numeric variables that have the same properties.

Denition 2 Let RPLANSAT denote the following problem.

Assume a STRIPS task (P A I G). Is the relaxation of (P A I G) solvable?

3. As opposed to, e.g., Graphplan-based approaches (Blum & Furst, 1997), which nd sets of actions to be
applied in parallel.

294

Translating \Ignoring Delete Lists" to Numeric State Variables

Proposition 1 The relaxation given in Denition 1 is adequate, i.e., the following holds
true.

1. Admissibility: any plan that solves the original task also solves the relaxed task,
i.e., assuming a STRIPS task (P A I G), any plan for (P A I G) is also a relaxed
plan for (P A I G).
2. Basic informedness: the preconditions and goals can trivially be achieved in the
original task if and only if the same holds in the relaxed task, i.e., assuming a
STRIPS task (P A I G), hi is a plan for (P A I G) if and only if hi is a relaxed plan for (P A I G), and for a 2 A, result(I hi)  pre(a) if and only if
result(I hi)  pre(a+ ).
3. Polynomiality: the relaxed task can be solved in polynomial time, i.e., deciding
RPLANSAT is in P.

The proof is trivial { admissibility and basic informedness follow directly from the
de
nitions, and polynomiality was proved earlier by Bylander (1994). The proof can be
found in Appendix A.
If we want to use the length of relaxed plans as a heuristic function, the properties
stated by Proposition 1 are important for the following reasons. Admissibility tells us that
optimal relaxed plan length is an admissible heuristic, since the optimal real plan is also
a relaxed plan.4 Also, we will not mistake a solvable state for a dead end: if there is no
relaxed plan then there is no real plan either (more on this below). The \only if" directions
in basic informedness tell us that the relaxation does not give us any constraints for free
(for example, the heuristic value will be zero only in goal states). If the heuristic does not
have these properties then possibly parts of the problem must be solved in regions where
there is no heuristic information at all (like when the heuristic value is already zero but
no goal state is reached yet).5 Polynomiality tells us that we can compute the heuristic
function eciently.

2.2 Solving Relaxed Tasks

Ideally, given a search state s, we would like to know how many relaxed actions are at least
needed to reach the goal, i.e., we would like to know what the length of an optimal relaxed
plan is (this would be an admissible heuristic, c.f. above). But 
nding optimal relaxed plans
is still intractable (Bylander, 1994). So instead we compute arbitrary, i.e., not necessarily
optimal, relaxed plans. This is done with a Graphplan-style algorithm (Blum & Furst,
1997 Ho	mann & Nebel, 2001). Given a search state s in a STRIPS task (P A I G), we

rst build a relaxed planning graph starting from s, i.e., for the task (P A s G). Then
we extract a relaxed plan from that graph. The graph building algorithm is depicted in
Figure 1.
4. Note that using the term \admissibility" this way slightly abuses notation, as admissibility usually refers
to a property of the heuristic function, not the technique (relaxation, in our case) it is based on.
5. The formulation of basic informedness might seem unnecessarily complicated. We chose the general
formulation at hand so that the denition can easily be transferred to other relaxation techniques, like
the ones we introduce later.

295

Hoffmann

P0 := s
t := 0
while G 6 Pt do
At := fa 2 ASj pre(a)  Pt g
Pt+1 := Pt  a2A e
(a)+
if Pt+1 = Pt then fail endif
t := t + 1
t

endwhile

finallayer := t, succeed

Figure 1: Building a relaxed planning graph for a task (P A s G).
The planning graph in the relaxed case is simply represented as a sequence P0  A0  : : : 
At;1  Pt of proposition sets and action sets. These are built incrementally in the obvious
fashion, starting with P0 = s as the initial layer, and iteratively inserting the add e	ects
of all applicable actions. The algorithm fails if at some point before reaching the goals no
new propositions come in. This only happens when the relaxed task is unsolvable.

Proposition 2 Assume a STRIPS task (P A I G), and a state s. If the algorithm depicted
in Figure 1 fails, then there is no relaxed plan for (P A s G).

The proof is in Appendix A. The main argument is that, if two consecutive proposition
layers are identical, then the same will hold true at all later layers so the graph has reached
a 
xpoint.
In case the goals can be reached at layer finallayer, we call the relaxed plan extraction
mechanism depicted in Figure 2. The level of each proposition p (action a) here is the 
rst
layer in the relaxed planning graph at which p (a) appears, i.e., the minimum t such that
p 2 Pt (a 2 At).
for

t := 1 : : : finallayer do
Gt := fg 2 G j level(g) = tg

endfor
for t := finallayer : : :
for all g 2 Gt do

1 do

select a, level(a) = t ; 1, g 2 e
(a)+
for all p 2 pre(a) do
Glevel(p)  = fpg

endfor
endfor
endfor

Figure 2: Extracting a relaxed plan for a task (P A s G) (levels and finallayer computed
by the algorithm in Figure 1).
Relaxed plan extraction is based on a sequence G1  : : :  Gfinallayer of goal and sub-goal
sets. Goals and sub-goals are always inserted into the set at their respective level, i.e., at the
296

Translating \Ignoring Delete Lists" to Numeric State Variables

position of their 
rst appearance in the relaxed planning graph. The goal sets are initialized
by inserting the respective (top-level) goals. A backwards loop then selects, at each layer,
actions to support the respective goal set. All goals or sub-goals g are supported, and the
preconditions of the respective actions become new sub-goals. This way, upon termination
the selected actions can be used to form a relaxed plan for the state at hand.

Proposition 3 Assume a STRIPS task (P A I G), and a state s for which the algorithm

depicted in Figure 1 reaches the goals. The actions selected by the algorithm depicted in
Figure 2 form a relaxed plan for (P A s G).

As all goals and sub-goals are supported, arranging the actions selected at each layer in
an arbitrary order yields a relaxed plan. The proof is in Appendix A.

2.3 FF

Based on the relaxed plan information, a heuristic state space planner is easily implemented.
Choices must be made on how to use the relaxed plans, and how to arrange the search strategy. We describe the speci
c methods used in FF, which are very ecient in many STRIPS
and ADL benchmarks (Ho	mann & Nebel, 2001). The extended system uses straightforward adaptions of these methods. We de
ne a heuristic function, a search strategy, and a
pruning technique. The heuristic estimates goal distances as relaxed plan length.

Denition 3 Assume a STRIPS task (P A I G), and a state s. The FF heuristic value

h(s) for s is denedPas follows. If the algorithm depicted in Figure 1 fails, h(s) := 1.
Otherwise, h(s) := finallayer
jAt j where At is the set of actions selected at layer t by the
t=1
algorithm depicted in Figure 2.

If there is no relaxed plan for a state, then the heuristic value is set to 1. This is
justi
ed by the 
rst property proved in Proposition 1: when there is no relaxed plan then
there can be no real plan either, i.e., the state is a dead end in the sense that the goals can
not be reached from it. Such states can be pruned from the search. The search scheme we
use is a kind of hill-climbing procedure using a complete lookahead to 
nd better states.
See Figure 3.
Enforced hill-climbing, like (standard) hill-climbing, starts out in the initial state and
performs a number of search iterations trying to improve on the heuristic value, until a
state with zero value is reached. While normally, iterative improvement is done by selecting
one best direct successor of the current search state, enforced hill-climbing uses a complete
breadth 
rst search to 
nd a strictly better, possibly indirect, successor. The search cuts
out states that have been seen earlier during the same iteration, and does not expand states
that the heuristic function recognizes as dead ends. This strategy works well when the
better successors are usually nearby, which is the case in many planning benchmarks when
using the FF heuristic function (Ho	mann, 2001, 2002b). When there is no better successor
below the current search node, the algorithm fails (more on this below).
We 
nally de
ne a pruning technique, selecting a set of the most promising successors to
each search state. The unpromising successors can then be ignored. A promising successor
is a state generated by an action that is helpful in the following sense.
297

Hoffmann

initialize the current plan to the empty plan <>
s := I
while h(s) 6= 0 do
starting from s, perform breadth rst search for a state s0 with h(s0 ) < h(s),
avoiding repeated states using a hash table,
not expanding states s00 where h(s00 ) = 1
if no such state can be found then fail endif
add the actions on the path to s0 at the end of the current plan
s := s0
endwhile

output current plan, succeed

Figure 3: The enforced hill-climbing algorithm, for a task with heuristic h.

Denition 4 Assume a STRIPS task (P A I G), and a state s for which the algorithm
depicted in Figure 1 reaches the goals. The set of helpful actions H (s) to s is dened as

H (s) := fa 2 A j e	+(a) \ G1 6= g
where G1 is the set of sub-goals constructed at layer 1 by the algorithm depicted in Figure 2.

In other words, an action is considered helpful if it achieves at least one of the lowest
level goals in the relaxed plan to the state at hand. The helpful actions information is used
as a pruning technique. During a breadth 
rst search iteration in enforced hill-climbing,
when expanding a state s, only the states generated by actions in H (s) are included into
the search space. Note that states s where the relaxed planning graph does not reach the
goals have h(s) = 1 so do not get expanded anyway.
In general, neither enforced hill-climbing nor helpful actions pruning maintain completeness. The algorithm fails if enforced hill-climbing gets caught in a dead end state. This can
happen because the search does not backtrack over its decisions, and because the heuristic
function can return a value below 1 for a dead end state. The algorithm also fails if helpful
actions pruning cuts out important states, which can happen because the technique is a
non-admissible approximation of usefulness. We deal with this issue by employing a safetynet solution, i.e., if enforced hill-climbing fails then the planner starts from scratch using a
complete heuristic search engine, without any pruning technique. The search engine used is
what Russel and Norvig (1995) term greedy best-rst search. This is a weighted A strategy
where the weight wg of the node cost in the equation f (s) = wg  g(s) + wh  h(s) is wg = 0,
i.e., search simply expands all search nodes by increasing order of goal distance estimation.
Repeated states are avoided in the obvious way by keeping a hash table of visited states.

3. Numeric State Variables

We introduce notation for the numeric part of the PDDL2.1 language (i.e., PDDL2.1 level
2) de
ned by Fox and Long (2002), used at IPC-3. We restrict ourselves to STRIPS for
readability reasons. Extensions to ADL will be summarized in Section 6.2. All sets are
assumed to be 
nite unless stated otherwise.
298

Translating \Ignoring Delete Lists" to Numeric State Variables

In addition to the propositions P , we now have a set V of numeric variables. Notationally, we say V = fv1  : : :  vn g (throughout the article, n will denote the number of numeric
variables). A state s is a pair s = (p(s) v(s)) where p(s)  P is a set of propositions and
v(s) = (v1 (s) : : :  vn (s)) 2 Qn is a vector of rational numbers (the obvious semantics being
that p(s) are the true propositions, and vi (s) is the value of vi ).6
An expression is an arithmetic expression over V and the rational numbers, using the
operators +, ;, , and =. A numeric constraint is a triple (exp comp exp0 ) where exp and
exp0 are expressions, and comp 2 f< 
 =  >g is a comparator. A numeric e ect is a
triple (vi  ass exp) where vi 2 V is a variable, ass 2 f:= += -= = /=g is an assignment operator, and exp is an expression (the e	ect right hand side). A condition is a pair
(p(con) v(con)) where p(con)  P is a set of propositions and v(con) is a set of numeric
constraints. An e ect is a triple (p(e )+  p(e );  v(e )) where p(e )+  P and p(e );  P
are sets of propositions (the add- and delete-list), and v(e ) is a set of numeric e	ects such
that i 6= j for all (vi  ass exp) (vj  ass0  exp0 ) 2 v(e ).7 An action a is a pair (pre(a) e (a))
where pre(a) is a condition and e (a) is an e	ect.
The semantics of this language are straightforward. The value exp(v) of an expression
exp in a variable value vector v (in s, if v is the numeric part v(s) of a state s) is the
rational number that the expression simpli
es to when replacing all variables with their
respective values, or unde
ned if a division by 0 occurs. A constraint (exp comp exp0 ) holds
in a state s, written s j= (exp comp exp0 ), if the values of exp and exp0 are de
ned in s,
and stand in relation comp to each other. A condition con = (p(con) v(con)) holds in a
state s, s j= con, if p(con)  p(s), and all numeric constraints in v(con) hold in s. The
value (vi  ass exp)(v) of a numeric e	ect (vi  ass exp) in a variable value vector v (in s, if
v is the numeric part v(s) of a state s) is the outcome of modifying the value of vi in s
with the value of exp in s, using the assignment operator ass. A numeric e	ect is applicable
in s if its value in s is de
ned. An e	ect e = (p(e )+  p(e );  v(e )) is applicable in s
if all numeric e	ects in v(e ) are applicable in s. For such e and s, e (s) is the state
s0 where p(s0) = p(s) n p(e ); p(e )+ , and v(s0 ) is the value vector that results from
v(s) when replacing vi (s) with (vi  ass exp)(s) for all (vi  ass exp) 2 v(e ). Putting all of
these de
nitions together, the result of executing an action a in a state s is result(s hai) =
e (a)(s) if s j= pre(a) and e (a) is applicable in s, unde
ned otherwise. In the 
rst case, a
is said to be applicable in s. For an action sequence ha1  : : :  an i, result(s ha1  : : :  an i) is
as usual de
ned recursively by result(s ha1  : : :  an i) = result(result(s ha1  : : :  an;1 i) an )
and result(s hi) = s.
A numeric task is a tuple (V P A I G) where V and P are the variables and propositions
used, A is a set of actions, I is a state, and G is a condition. A sequence of actions
ha1  : : :  an i 2 A is a plan if the result of applying it to I yields a state that models G,
result(I ha1  : : :  ani) j= G.
In our algorithmic framework, we make distinctions between di	erent degrees of expressivity that we allow in numeric constraints and e	ects, i.e., between di	erent numeric
6. We ignore, for readability reasons, the possibility given in Fox and Long's original language that a
variable can have an undened value until it is assigned one. Our methodology can be easily extended
{ and is in fact implemented { to deal with this case.
7. Fox and Long (2002) make this assumption implicitly, by requiring that the outcome of an action is
well-dened { note that commutative eects on the same variable can be merged.

299

Hoffmann

languages. A numeric language is a tuple (Cons E -ass E -rh) where Cons is a possibly
in
nite set of numeric constraints, E -ass is a set of assignment operators, and E -rh is a
possibly in
nite set of expressions. A task (V P A I G) belongs to a language if all constraints, assignment operators, and e	ect right hand sides are members of the respective
sets.
The next three sections contain the technical part of this article. They are organized as
follows.

1. Section 4 provides the theory on which Metric-FF's heuristic function is based. The
relaxation, ignoring delete lists as described in Section 2.1, is extended to numeric
variables. Section 4.1 formalizes the key idea in a restricted numeric language, and
states that the extended relaxation ful
lls admissibility, basic informedness, and polynomiality. Section 4.2 abstracts from the restricted language, identifying generalized
semantic properties that make the relaxation work. Section 4.3 then introduces the
language of linear tasks, which can be brought into a linear normal form (LNF) that
has these semantic properties. Metric-FF's core planning algorithms are implemented
for LNF tasks.
2. Section 5 introduces the algorithms implemented in Metric-FF's heuristic function.
The algorithms are extensions to the relaxed Graphplan methods described in Section 2.2. Section 5.1 describes the algorithms for the restricted language, Section 5.2
extends that to LNF tasks. We state formally that the algorithms are complete and
correct. We also see that the algorithms are, in theory, less ecient than they could
be. The number of relaxed planning graph layers built can be exponential in the
size of the task encoding, in contrast to polynomiality of the relaxation as proved
in Section 4. The reason why the implementation lags behind what is theoretically
possible is that the implementation work was done before the theory was fully developed. However, from a practical point of view, it is at least debatable how important
the potential exponentiality is (the number of relaxed planning graph layers built is
bounded by the length of a shortest relaxed plan). Exploring this issue in depth is a
topic for future work. More details are in Sections 4.1 and 5.1.
3. Section 6 details how the relaxed plan information is used to implement the Metric-FF
system. Section 6.1 explains the extension of the basic FF architecture as described
in Section 2.3. Section 6.2 explains the extension to ADL, Section 6.3 describes how
exible optimization criteria can be dealt with.

4. Relaxing Numeric State Variables
We show how the relaxation technique for STRIPS can naturally be extended to the numeric
context. We proceed in the three steps outlined above.

4.1 A Restricted Language

The key idea in our relaxation becomes apparent when one considers the context where
constraints only compare variables to constants via  or >, there are only += and -=
300

Translating \Ignoring Delete Lists" to Numeric State Variables

e	ects, and the e	ect right hand sides are positive constants. More formally, our restricted
language is:
( f(vi  comp c) j vi variable comp 2 f >g c 2 Qg
f+= -=g
fc j c 2 Q c > 0g )
In STRIPS, delete lists are troublesome because they falsify propositions that we might
need for preconditions or the goal. In the restricted numeric language here, the -= e	ects are
troublesome because they diminish the value of the a	ected variables. The idea is therefore
to ignore these e	ects.

Denition 5 Assume a restricted numeric task (V P A I G). The relaxation a+ of an
action a 2 A, a = (pre(a) (p(e	(a))+  p(e	(a));  v(e	(a)))), is dened as
a+ := (pre(a) (p(e	(a))+   f(vi  += exp) j (vi  += exp) 2 v(e	(a))g)):
The relaxation of (V P A I G) is (V P A+  I G), where A+ := fa+ j a 2 Ag. An action
sequence ha1  : : :  an i 2 A is a relaxed plan for (V P A I G) if ha+1  : : :  a+n i is a plan for
(V P A+  I G).

The above relaxation is adequate in the restricted language, in the precise sense introduced in Section 2.1.

Denition 6 Let RESTRICTED-RPLANSAT denote the following problem.

Assume a restricted numeric task (V P A I G). Is the relaxation of (V P A I G)
solvable?

Theorem 1 The relaxation given in Denition 5 is adequate, i.e., the following holds true.
1. Admissibility: assuming a restricted numeric task (V P A I G), any plan for
(V P A I G) is also a relaxed plan for (V P A I G).
2. Basic informedness: assuming a restricted numeric task (V P A I G), hi is a plan
for (V P A I G) if and only if hi is a relaxed plan for (V P A I G), and for a 2 A,
result(I hi) j= pre(a) if and only if result(I hi) j= pre(a+ ).
3. Polynomiality: deciding RESTRICTED-RPLANSAT is in P.

The detailed proof can be found in Appendix A. It is a straightforward extension of the
STRIPS proof, exploiting the correspondence between pre/goal-conditions, add lists, and
delete lists on the one hand, and x  >]c constraints, += e	ects, and -= e	ects on the
other hand. The only tricky part lies in proving polynomiality, precisely in how to handle
repeated increasing e	ects on the same variable. Such e	ects might have to be applied
an exponential number of times. Consider the tasks, for n 2 N0 , where vi is initially 0,
vi  n is the goal, and we have an action e	ect (vi  += 1). For task n, the shortest relaxed
plan comprises n steps, which is exponentially long in the size of a non-unary encoding
301

Hoffmann

of n. The trick one can use to decide relaxed solvability in polynomial time is a simple
1 handling. The polynomial decision process is a forward 
xpoint procedure similar to
building a relaxed planning graph. As soon as there appears an action a that increases a
variable vi , one can assume that vi 's value is 1, reecting the fact that vi 's value can be
made arbitrarily high by applying a a sucient number of times. As indicated earlier, the
current implementation of Metric-FF, which we will describe in Section 5, does not make
use of such an 1 handling technique, and may thus build an exponential number of relaxed
planning graph layers for a search state. More on this in Section 5.1.
A few words on related work are in order here. If one relaxes numeric tasks by ignoring
all the numeric constructs, then one gets admissibility and polynomiality, but not basic
informedness. The heuristic methods used in Sapa (Do & Kambhampati, 2001) and GRT-R
(Refanidis & Vlahavas, 2000) come quite close to this extreme case. In fact, Sapa's heuristic
constructs a relaxed plan that completely ignores the numeric part of the task. Then the
\resource consumption" of the resulting relaxed plan (roughly, the sum of all decreasing
e	ects on numeric variables) is used to estimate the number of actions that would be needed
to re-produce these resources, and that number is added to the heuristic value of the state at
hand. In particular, this method ignores all numeric goals and preconditions and thus lacks
basic informedness. Similarly, the heuristic technique used in GRT-R considers resource
consumption as another form of state cost, but does not take any numeric precondition or
goal constraints into account. The heuristic technique does not make explicit use of relaxed
plans so our de
nitions can not be directly applied. However, as numeric constraints are
not considered, the heuristic value of a purely numeric action precondition is zero even if
the precondition is not true in the current state, and the technique thus also lacks basic
informedness.

4.2 Monotonicity, and a Dynamic Relaxation
We now have a look behind the scenes of the relaxation technique that we used above for
the restricted language. We abstract from the syntax of the numeric constructs, and focus
on their semantics instead. We de
ne an extension of our relaxation to the general context,
and identify a group of semantic properties that make this relaxation adequate. We will
later focus on a syntactically restricted language, linear tasks, where it is easier to see that
the relaxation is adequate. The main intention of the abstract work in this subsection is to
provide some theoretical background on the general characteristics for which our relaxation
works.
Let us 
rst ignore semantic issues, and simply extend the de
nition of our relaxation.
In general, the de
nition is not as easy as for the restricted case in De
nition 5. While our
idea is still to ignore decreasing e	ects, the diculty is that whether an e	ect is decreasing
or not can depend on the context it is executed in.8 As a simple example, say an action a
has a numeric e	ect (vi  += vj ). If vj has a negative value in the state of a's execution,
this e	ect decreases the value of vi instead of increasing it. So we can not statically relax a
8. It is common practice to refer to += eects as \increasing eects", and to -= eects as \decreasing
eects". In contrast to that, we distinguish between syntax and semantics by using += / -= to denote
syntax, and increasing / decreasing to denote semantics (of arbitrary numeric eects).

302

Translating \Ignoring Delete Lists" to Numeric State Variables

by ignoring parts of its speci
cation. Instead, our relaxation now is dynamic: we relax the
state transition function.

Denition 7 Assume a state s and an action a = (pre(a) e	(a)). The relaxed result
of executing a in s is result+ (s a) = s0 such that p(s0 ) = p(s) p(e	(a))+ , and v(s0 ) is

the value vector that results from v(s) when replacing vi (s) with (vi  ass exp)(s) for all
(vi  ass exp) 2 v(e	) such that (vi  ass exp)(s) > vi (s).

For an action sequence ha1  : : :  an i, result+(s ha1  : : :  an i) is de
ned recursively as with
the original result function in Section 2. Note that, in STRIPS and the restricted numeric
language, De
nition 7 comes down to exactly the relaxations we have used before.
Having generalized our relaxation, we now want to know in exactly which situations
this relaxation is adequate. Obviously, ignoring the decreasing e	ects is not adequate in
general. As a simple example, if the value of a variable vi is initially 0, there is an e	ect
(vi  -= 1), and the goal requires that vi < 0, then the \relaxation" renders the task unsolvable. Intuitively, the relaxation is adequate if it is always preferable for the numeric
variables to have higher values. Formalizing this intuition turns out to be a bit tricky.
Recall our three conditions for adequacy of a relaxation: admissibility (any real plan is also
a relaxed plan), basic informedness (the relaxation does not ignore any precondition or goal
constraints), and polynomiality (solvability of the relaxation can be decided in polynomial
time). Basic informedness is obviously given for our relaxation here. Not so admissibility
and polynomiality. Say we want to make sure that each real plan is also a relaxed plan.
Not only must the numeric constraints prefer higher variable values, but the e	ects must
also. As an example, say we have vi = vj = 0 initially, the goal vi  1, an action e	ect
(vi  -= vj ), and an action e	ect (vj  -= 1). If we ignore the decreasing e	ect on vj , we can
not solve the task because for the e	ect (vi  -= vj ) it is better when vj takes on lower values.
Considering polynomiality, to ensure that relaxed solvability can be decided in polynomial
time, all kinds of subtleties must be handled. Say we want to shortcut repeated action
application by an 1 trick, i.e., by assuming that repeated application of increasing e	ects
makes the a	ected variable diverge (as is the case in the restricted language above). Then
we will get in trouble if repeated (relaxed) application of an action makes the value of the
a	ected variable converge.9 Similar diculties arise when an expression in a constraint
does not diverge with its variables. Finally, it might be that the constraint looks correct
when inserting 1, but can never be ful
lled with 
nite values. An example of this is the
constraint vi  vi + 1, which is ful
lled when inserting 1 for vi .
In the following de
nition, we introduce a number of conditions that are sucient to
ensure that none of the diculties described above appear. We will see that in \monotonic"
tasks each real plan is also a relaxed plan, and that in \strictly monotonic" tasks, given their
:= e	ects are acyclic in a certain sense, relaxed plan existence can be decided in polynomial
time.

Denition 8 Assume a numeric task (V P A I G). The task is monotonic if, for all pairs
of states s and s0 with 8vi : vi (s) 
 vi (s0 ), the following holds.
9. As an example, if i is initially 1 and we have an eect ( i += 1 ; v2i ) then repeated application
of the
eect makes the value of i converge to 2 (the value of i after applications is 2 ; 12 n ).
v

v

v

v

303

n

Hoffmann

(1) For all numeric constraints (exp comp exp0 ) occurring in the task:
s j= (exp comp exp0) ) s0 j= (exp comp exp0 ):
(2) For all numeric e ects (vi  ass exp) occurring in the task:
(vi  ass exp)(s) 
 (vi  ass exp)(s0 )
where the 
 relation holds only if both values are dened.
The task is strongly monotonic if the above and the following hold.
(3) For all states s and s0 as above, for all numeric e ects (vi  ass exp) occurring in the
task, with ass 2 f+= -= = /=g:
(vi  ass exp)(s) ; vi (s) 
 (vi  ass exp)(s0 ) ; vi (s0 )
where the 
 relation holds only if both values are dened.
(4) For all expressions exp occurring in the task:
8vi 2 v(exp) : lim exp = 1
vi !1

where v(exp) denotes the set of all variables contained in exp.
(5) For all numeric constraints (exp comp exp0 ) occurring in the task:
9s : s j= (exp comp exp0 ):

Some explanation of this lengthy de
nition is in order. Condition (1) ensures that the
numeric constraints prefer higher variable values. Condition (2) does the same for e	ects,
requiring that the value of an e	ect can only increase with the variables. In particular,
the value does not become unde
ned, i.e., no division by zero occurs when the variables
grow. These two conditions suce to make each real plan a relaxed plan, as higher variable
values are always preferable. Conditions (3) to (5) aim at making relaxed solvability easy
to decide. Condition (3) is a stronger version of condition (2). We require that the value
that the e ect adds to the a ected variable increases with the variables. This ensures that
repeated application of the e	ect causes the value of the a	ected variable to diverge. To
illustrate this, an e	ect (vi  += ;vj + c) ful
lls condition (2) but not condition (3). The
outcome of this e	ect is always c, which is monotonic in its (zero) variables but a	ects
vi more as vi 's own value becomes higher. Condition (4) postulates that all expressions
diverge in all variables, and condition (5) postulates that to all constraints there is a 
nite
variable assignment that makes these constraints true. Together with condition (1) these
requirements ensure that the constraints will eventually be ful
lled when increasing the
values of the variables.10

10. One could weaken conditions (1) to (3) of Denition 8 by exploiting the fact that we are only interested
in reachable states. It does not matter if, e.g., a constraint is not monotonic in a region of variable values
that will never be reached due to the semantics of the task. Metric-FF implements no such analysis
techniques, except throwing away actions { and with them, numeric constraints and eects { whose
preconditions can not be reached in the relaxed planning graph for the initial state, when ignoring all
numeric constructs. Exploring the topic in more depth is future work.

304

Translating \Ignoring Delete Lists" to Numeric State Variables

The := e	ects are separated out from the de
nition of strong monotonicity, i.e., while
we do postulate condition (2) for them, we do not postulate condition (3). Postulating
condition (3) for := e	ects would also suce. But this condition does not hold for even
the simplest form of := e	ects, namely (vi  := c), assigning a constant to a variable. Note
that this is in principle the same e	ect as the example given above, (vi  += ;vj + c).
E	ects of this kind are common even in the limited suits of benchmarks that are currently
available (e.g., when 
lling up a tank, the fuel level is assigned the maximum level). So we
identify a di	erent sucient criterion that makes := e	ects tractable, and that captures the
common forms of these e	ects. Computing the maximum outcome of a set of assignment
e	ects, in the relaxation and under condition (2), becomes easy if the value changes on each
single variable can not be propagated into their own value. The proof argument is that,
if, transitively, a change on vi can not inuence vi 's own value then all one needs to do
is to perform value propagation steps, at each step computing the maximum assignment
available for each variable. After at most as many steps as there are variables, the values
will be 
xed. We formalize the possible value propagations with a straightforward graph
de
nition.

Denition 9 Assume a numeric task (V P A I G). The task has acyclic := e	ects if the
graph (V E ) is cycle-free, where

E = f(vi  vj ) 2 V  V j 9a 2 A (vj  := exp) 2 v(e	(a)) : vi 2 v(exp)g
with v(exp) denoting the set of all variables contained in exp.

We now state in which ways our de
nitions imply adequacy of ignoring decreasing e	ects
as a relaxation. In the notation for the relaxed plan existence decision problem, we abstract
from syntactic issues, and assume that a well-formed input task to the decision procedure
is strongly monotonic and has acyclic := e	ects.

Denition 10 Let STRONGLY-MONOTONIC-RPLANSAT denote the following prob-

lem.
Assume a numeric task (V P A I G). Is there a relaxed plan for (V P A I G), provided
the task is strongly monotonic and has acyclic := e	ects?

Theorem 2 The relaxation given in Denition 7 is adequate for strongly monotonic tasks
with acyclic := e ects. Precisely the following holds true.

1. Admissibility: assuming a monotonic numeric task (V P A I G), any plan for
(V P A I G) is also a relaxed plan for (V P A I G).
2. Basic informedness: assuming a numeric task (V P A I G), hi is a plan for
(V P A I G) if and only if hi is a relaxed plan for (V P A I G), and for a 2 A
result(I hi) j= pre(a) if and only if result+(I hi) j= pre(a).
3. Polynomiality: deciding STRONGLY-MONOTONIC-RPLANSAT is in P.
305

Hoffmann

The proof, given in Appendix A, is basically a straightforward exploitation of the properties ensured by the above de
nitions. Note that Theorem 2 only identi
es sucient criteria
that make our relaxation work. Interesting questions are, are there other, maybe weaker,
criteria? As a concrete example, there seem to be certain cases of cyclic assignment e	ects
that can be easily handled. What exactly are these cases? Answering these questions is a
topic for future work.
Another thing we have not dealt with is how our semantic constraints translate to the
syntax of the arithmetic expressions that are allowed in PDDL2.1. We do not consider the
details of this but base the rest of the article on a subset of PDDL2.1 where the required
semantic properties can easily be achieved { the language for which the Metric-FF system is
actually implemented. Extending the system to richer languages is an open research topic.

4.3 Linear Tasks, and LNF

The Metric-FF system is implemented to deal with what we call linear tasks. This is the
language of numeric tasks where there are no = or /= e	ects, and the numeric variables
are only used in linear expressions. More formally:
( f(exp comp exp0 ) j exp exp0 linear expression comp arbitraryg
f:= += -=g
fexp j exp linear expressiong )
Metric-FF's implementation allows for tasks that are linear after the following preprocessing step. Assume we are given a planning task (V P A I G). A variable vi 2 V is
a task constant if vi is not a	ected by the e	ect of any action in A. An expression is a task
constant if all variables occurring in it are task constants. The pre-process replaces all task
constants with the respective rational numbers resulting from inserting the initial variable
values.11
Linear tasks are, of course, not necessarily monotonic. In fact, all of the illustrative
counter examples we have given above are linear. But linear functions are monotonic, more
precisely strictly monotonic and diverging, in all variables, either in the positive or in the
negative sense. The idea is to introduce, for a variable vi that is used in the negative sense
at some point, an inverted variable ;vi that always takes on the value (;1)  vi . One can
then replace vi with ;vi at the points where vi is used negatively. When this has been done
for all variables, the task is (strictly) monotonic: all variables are only used in the positive
sense (more details below). Introducing inverted variables can be viewed as a shortcut way
of informing the heuristic function about which places to use the variables in the positive or
in the negative sense.12 We will return to this issue when considering Metric-FF's heuristic
algorithms in Section 5.2.
Given a linear task, Metric-FF transforms the task into what we call its linear normal
form (LNF). In an LNF task, the expressions are weighted sums of variables, where the
weights are all greater than 0. The transformation process works as follows. First, a series
of simple steps transforms the task into the following language.
11. If, in a quotient (exp exp ), exp simplies to 0 then the expression is undened and the respective
constraint can never be fullled / the respective action's eects can never become applicable. In this
case one can replace the constraint with \false"/ remove the action.
12. David Smith, personal communication.
=

0

0

306

Translating \Ignoring Delete Lists" to Numeric State Variables

P

( f( j 2X cj  vj + c  >] 0) j cj  c 2 Q cj 6= 0g
f:=
 +=g
P
f j 2X cj  vj + c j cj  c 2 Q cj 6= 0g )

To achieve this language format, one replaces all constraints (exp = exp0 ) with (exp 

 exp0 ) and (exp  exp0), and all e	ects (vi  -= exp) with (vi  += ;exp). The rest is a
matter of normalizing linear functions. The language format di	ers from LNF only in that
the variable weights may be negative. This, of course, makes all the di	erence. Reconsider
the example where a variable vi is initially 0, there is an action a with e	ect (vi  -= 1), and
the goal requires that vi < 0. We take this as the running example in the following. In the
above language format, a's e	ect is (vi  += ;1), and the goal requires that (;1)  vi > 0.
Due to the negative weighting of vi in the goal condition, ignoring decreasing e	ects is not
viable.
The way we introduce inverted variables is an extension to the methodology that eliminates negative preconditions in STRIPS planning (a technique 
rst introduced by Gazen &
Knoblock, 1997). The process works as follows. Initialize the set T of translated variables
to T := . Iterate until there are no more negative weights, otherwise select an (arbitrary) occurrence cj  vj , cj < 0, in a weighted sum.P Introduce a new variable ;vj . Set
;vj (I ) := (;1)  vj (I ). For all e	ects (vj  +=:=] Pj 2X cj  vj + c), introduce (into the
e	ect set of the same action) the e	ect (;vj  +=:=] j 2X ((;1)  cj )  vj + ((;1)  c)). Set
T := T fvj  ;vj g. For all occurrences of c  v in weighted sums such that c < 0 and v 2 T
(where v may be one of the original variables or one of the introduced inverse variables),
replace c  v with ((;1)  c) ;v (where ;v is the respective inverse counterpart to v). After
at most jV j iterations, all weights are positive and the process terminates. The task is then
in the following linear normal form.

P

( f( j 2X cj  vj + c  >] 0) j cj  c 2 Q cj > 0g
f:=
 +=g
P
f j 2X cj  vj + c j cj  c 2 Q cj > 0g )
For our running example, the LNF transformation is the following. There are now two
variables, vj and ;vj , both of which are initially 0. The action a has two e	ects, namely
(vi  += ;1) and (;vi  += 1). The goal condition is now expressed in terms of the value of
;vi , and reads ;vi > 0. A single application of the action achieves the goal, as it also does
under the relaxed transition function because the e	ect on ;vi is increasing.13 In general,
it is easy to see that LNF tasks are strongly monotonic.

Proposition 4 Assume a linear numeric task (V P A I G). If the task is in LNF, then
it is strongly monotonic.

Proof: All conditions in De
nition 8 are trivially ful
lled in LNF tasks. As examples,

condition (1) is true because we only compare expressions that are (positively) monotonic
in all variables to constants via  or >. Condition (3) is true because we only have +=
e	ects whose right hand sides are (positively) monotonic in all variables.
2
13. Note that estimating the maximum value of ; i is the same as estimating the minimum value of i .
More on this in Section 5.2.
v

307

v

Hoffmann

With Proposition 4, if an LNF task (V P A I G) has acyclic := e	ects (remember that
these are separated out from De
nition 8 condition (3)) then the task ful
lls the prerequisites
of Theorem 2, so ignoring the decreasing e	ects is an adequate relaxation. It is thus feasible
to use solutions to the relaxation as a means of heuristic estimation.
For the := e	ects, one can easily translate these into, e.g., += e	ects { (vi  := exp)
translates to (vi  += ((;1)  vi )+exp). So the reader might wonder why we bother treating
:= e	ects at all. The point is that, while the translated e	ects behave equivalently under the
real transition function, they behave di	erently in the relaxation. In our running example
suppose there is a second action a0 with the e	ect (vi  := 10). In the LNF transformation,
the translated version of this e	ect is (vi  += ;vi + 10). Say we execute, under result+ ,

rst a (with e	ects (vi  += ;1) and (;vi  += 1)) then a0 . In the original task, the resulting
value of vi is 10. In the translated task, that value is 11 (because the decreasing e	ect on vi
is ignored). So it does make a di	erence whether we treat := e	ects separately or not. An
open question is whether, or in which situations, that di	erence is important for planner
performance.
We also remark that, while Metric-FF implements the introduction of inverted variables
for LNF tasks only, it seems likely that similar processes will work for richer languages,
when all functions are strictly monotonic and diverging in all variables.

5. Solving Relaxed Tasks

We now concentrate on the algorithms used in FF, more generally algorithms that can be
used to obtain heuristic information in a forward state space search. We explain how to
solve relaxed numeric tasks. We 
rst consider the restricted language, then extend the
methods to LNF tasks. The algorithms form the basis of the Metric-FF implementation.

5.1 Restricted Tasks

The implementation uses a straightforward extension of the Graphplan-style algorithms
introduced in Section 2.2. We still use a two-step process that 
rst builds a relaxed planning
graph then extracts a relaxed plan from that (if the graph succeeds in reaching the goals).
In parallel to the structures that keep track of the progress in logical propositions, we now
have structures that keep track of the progress in terms of maximally possible variable
values. The graph building mechanism is outlined in Figure 4.
The parts of the algorithm concerned with the propositions work exactly as in the
STRIPS case, c.f. Section 2.2. As for the numeric variables, the max value vector at a
layer t speci
es the current maximum value that the variables can take on. The vectors are
updated in the obvious fashion, adding at each layer the total sum of the increasing e	ects
at that layer. The termination condition now checks whether the maximum values of all
variables have either not changed, or are already higher than needed: the mneedi value for
each variable vi is de
ned as the highest requirement on that variable, i.e.,
mneedi := max(;1 fc j (vi   >] c) 2 v(G)
v(pre(a))g):
a2A

Note that the algorithm fails only if there is no relaxed plan for (V P A s G): if the
algorithm fails at a layer m then the termination condition will hold true at all later layers.
308

Translating \Ignoring Delete Lists" to Numeric State Variables

P0 := s, for all vi do maxi0 := vi (s) endfor
t := 0
while p(G) 6 Pt or (v i  >] c) 2 v (G) maxit 6 6>]c do
At := fa 2 A j p(pre(a))  Pt
8(vi  >] c) 2 v(pre(a)) : maxit  >]cg
S
Pt+1 := Pt  a2A p(e
(a))+ P
for all v i do maxit+1 := maxit + a2A (v += c)2v(e
(a)) c endfor
if Pt+1 = Pt and
8vi : maxit+1 = maxit or maxit > mneedi then
t

t

i

fail
endif

t := t + 1

endwhile

finallayer := t

Figure 4: Building a relaxed planning graph for a state s in a restricted numeric task
(V P A I G).
Also, note that there can be only a 
nite number of layers as the numeric variables that do
increase will eventually reach their 
nite mneed values. But, as mentioned in Section 4.1, the
number of layers can be exponential in the task encoding. Reconsider the example where,
for n 2 N0 , vi is initially 0, vi  n is the goal, and we have an action e	ect (vi  += 1). The
number of graph layers built for this example, n, is exponential in a non-unary encoding
of n, whereas one could easily decide solvability with the 1 trick outlined in Section 4.1.
On the other hand, it appears unlikely that an implementation of the provably polynomial
decision procedure would be better in practice. The graph building algorithm is polynomial
in the length of its output (the minimal length of a relaxed plan). Also, the possibly
exponential minimal length of a relaxed plan (exponential in a non-unary encoding of the
variable values) does not seem particularly relevant, at least not in examples that are not
speci
cally constructed to provoke this exponentiality. It remains an open question whether
an implementation of 1 handling can achieve better performance in realistic examples.
We now focus on relaxed plan extraction. This is invoked if the relaxed planning graph
succeeds in reaching the goals. The information that the graph provides us with are the
levels of all actions, propositions, and numeric goals. For actions and propositions the level
is the 
rst graph layer at which they appear, c.f. Section 2.2. For numeric goals (vi   >] c),
the level is the graph layer t where the goal can 
rst be achieved, i.e., where maxit  >]c
holds the 
rst time. The plan extraction mechanism is outlined in Figure 5.
Again, the logical entities are dealt with exactly as in the STRIPS case, c.f. Section 2.2.
In addition to the propositional (sub-)goal set p(Gt ) at each layer t we now have a set v(Gt )
of numeric goals. Like in STRIPS, goals and sub-goals are always inserted into the set at
their 
rst appearance in the relaxed planning graph, and the goal sets are initialized by
inserting the respective (top-level) goals. Then there is a backwards loop from the top to
the bottom layer, selecting actions to support the propositions and numeric variables in the
respective goal sets. The propositions are supported as before, the only di	erence being
309

Hoffmann

for

t := 1 : : : finallayer do
p(Gt ) := fg 2 p(G) j level(g) = tg
v(Gt ) := f(vi  >] c) 2 v(G) j level(vi  >] c) = tg

endfor
for t := finallayer : : : 1 do
for all g 2 p(Gt ) do

select a, level(a) = t ; 1, g 2 p(e
(a))+
for all p 2 p(pre(a)) (v i  >] c) 2 v (pre(a)) do
p(Glevel(p) ) = fpg
v(Glevel(v >] c)) = f(vi  >] c)g
i

endfor
endfor
for all (v i  >] c) 2 v (Gt ) do
while maxit;1 6 6>]c do

select a, level(a) = t ; 1, (vi += c0 ) 2 v(e
(a)),
a not previously selected in this while-loop
c := c ; c0
/* introduce a's preconditions as above */

endwhile
v(Gt;1 ) = f(vi
endfor
endfor

 >] c)g

Figure 5: Extracting a relaxed plan for a state s in a restricted numeric task (V P A I G)
(levels and finallayer computed by the algorithm in Figure 4).
that now also the numeric preconditions of the supporting actions must be inserted into
the goal sets below. When uniting sets of numeric goals that both contain a constraint on
the same variable vi , the stronger one of both constraints is taken. For the numeric goals
(vi   >] c) 2 v(Gt ) it is in general not enough to select a single action as several actions
at t ; 1 might have contributed to vi 's maximum value at t. SoPsupporters are selected until
the goal can be achieved one layer earlier. Note that maxit ; a2A 1 (v += c)2v(e (a)) c =
maxit;1 , so the while loop will always terminate successfully. Note also that one occurrence
of an action can support di	erent logical and numeric goals by di	erent e	ects, but can not
be used to support the same numeric goal twice.
Upon termination of plan extraction, the selected actions can be used to form a relaxed plan: with At denoting the actions selected at layer t, an arbitrary linearization of
A0  : : :  Afinallayer;1 is a relaxed plan for the task. Note that one can apply various simple
heuristics, like selecting += e	ects with maximum right hand side 
rst, to make the relaxed
plans as short as possible.
t;

i

5.2 LNF Tasks
The algorithms for numeric tasks in linear normal form di	er from those for restricted tasks
in that we need to take care of := e	ects, and of the more general expressions in numeric
310

Translating \Ignoring Delete Lists" to Numeric State Variables

constraints and in e	ect right hand sides. As it turns out, integrating these extensions is
not overly dicult. The only issue that becomes slightly involved is the exact termination
criterion for relaxed graph building. In our solution to the issue we assume, as in the
theoretical analysis underlying Theorem 2, that the := e	ects are acyclic. An outline of the
graph building mechanism is shown in Figure 6.
P0 := s, for all vi do maxi0 := vi (s) endfor
t := 0
while p(G) 6 Pt or (exp  >] 0) 2 v (G) exp(maxt ) 6 6>]0 do
At := fa 2 A j p(pre(a))  Pt
S8(exp  >] 0) 2 v(pre(a)) : exp(maxt)  >]0g
Pt+1 := Pt  a2A p(e
(a))+ P
for all v i do maxit+1 := maxit + a2A :(v += exp)2v(e
(a)) exp(max )>0 exp(maxt ) endfor
for all v i do maxit+1 := max(maxit+1 maxa2A (v := exp)2v(e
(a)) exp(maxt )) endfor
if Pt+1 = Pt and
8vi : maxit+1 = maxit or maxit > mneedi (s) then
t

t

i

t

t

i

fail
endif

t := t + 1

endwhile

finallayer := t

Figure 6: Building a relaxed planning graph for a state s in an LNF task (V P A I G).
Compare Figure 6 with Figure 4. We deal with the expressions in constraints and
e	ect right hand sides simply by inserting the respective max values of the variables, and
computing the respective outcome (recall that exp(v) for an expression exp and a variable
value vector v denotes the value of exp when inserting the values v). The += e	ects are
taken into account to obtain the maxt+1 values exactly as before, i.e., by adding their
combined contributions to maxt (except that the value of the right hand sides must now be
computed using the maxt values). The := e	ects are taken into account by determining,
after all += e	ects have contributed to maxt+1 , whether there is a := e	ect in the graph
whose value, when inserting the maxt values, is higher than the hitherto maxt+1 value.
In this case, maxt+1 (for the respective variable) is updated to the maximum assignment
possible.
The only part of the algorithm that becomes somewhat complicated, in comparison to
the algorithm for restricted tasks, is the termination criterion. The dicult part is the
computation of the mneed values, i.e., the values above which the variables can no longer
contribute anything to a relaxed solution. These values can now depend on the state s we
start from. To derive the values, we start with the static (non state-dependent) notion of
solution-relevant variables. A variable vi is solution-relevant if it either occurs in a numeric
constraint, or in the right hand side exp of an e	ect (vj  +=:=] exp) on a solution-relevant
variable vj . Note that solution-relevance thus transfers transitively over the variables. We
denote the set of solution-relevant variables with rV . For the state-dependent aspects of
the relaxed task, we provide notation for the value that a variable vi must at least take
on in a state s in order to raise (or \support") the value of a positively weighted sum
311

Hoffmann

P

exp = j 2X cj  vj + c above a constant c0 .

supvi (s exp c0 ) := (c0 ; c ;

X

i6=j 2X

cj  vj (s)) = ci

Of course, the support value supvi (s exp c0 ) is only de
ned if vi 2 v(exp), i.e., if vi is a
part of the weighted sum. As the reader can easily convince him/herself, if we raise the
value of vi in s above supvi (s exp c0 ) then we know that the value of exp is at least c0 . We
use this concept to determine the point above which a variable vi contributes suciently
to all constraints and e	ect right hand sides that it can contribute to. For constraints
(exp  >] 0) with vi 2 v(exp) this point is reached with vi  supvi (s exp 0) (then the
constraint is ful
lled). For += e	ect right hand sides in (vj  += exp) with vi 2 v(exp)
and vj 2 rV (vj may be needed) this point is reached with vi  supvi (s exp 0) (the e	ect
can then eventually increase vj to arbitrarily high values). As for := e	ect right hand
sides, in an e	ect (vj  := exp) with vi 2 v(exp) and vj 2 rV the value of vi is sucient if
vi  supvi(s exp mneedj (s)): then the e	ect is high enough to assign vj a sucient value.
The main complication here is that we want to use the supv values to de
ne the mneed
values so our de
nition for := e	ects is recursive. That does not constitute a problem given
our assumption that the := e	ects are acyclic. In e	ect, the recursion is guaranteed to
terminate. Altogether, the de
nition is the following.
8> ;1
>< fsupvi(s exp 0) j (exp  >] 0) 2 v(G)  Sa2A v(pre(a)) vi 2 v(exp)g
i
mneed (s) := max >
i (s exp 0) j (v j += exp) 2 S
i
f
supv
) vj 2 rV g
:> fsupvi(s exp mneedj (s) j (vj := expa2)A2vS(e
a2(Aa))v(e
v (2a))v(exp
vi 2 v(exp) vj 2 rV g
Note that, with this de
nition, the variables with mneedi (s) = ;1 are the variables that
are not solution-relevant.

Theorem 3 Assume a linear numeric task (V P A I G) that is in LNF and has acyclic
:= e ects. Assume a state s. If the algorithm depicted in Figure 6 fails, then there is no
relaxed plan for (V P A s G).

The main proof idea is, as before, this: if the algorithm fails at a layer m then the termination condition will hold true at all later layers. The argument concerning the mneed(s)
values follows what is outlined above. The full details are a bit lengthy. See Appendix A.
As discussed before for the restricted language, the number of graph layers built before
termination is 
nite { eventually, all variables either do not increase or reach their 
nite
mneed values { but can be exponential in the encoding length of the task. Again, one
could implement a provably polynomial algorithm along the lines of the method used in
the proof to Theorem 2, and again it is debatable whether such an implementation would,
for realistic examples, achieve any signi
cant performance improvements over the existing
implementation.
It is interesting to consider the role that the inverted variables { as introduced by
Metric-FF during LNF pre-processing, see Section 4.3 { play in the relaxed planning graph
process described above. Estimating the maximum value of an inverted variable is the same
as estimating the minimum value of the respective original variable. More precisely, in
Figure 6, if vj is the inverted variable to vi then (;1)  maxjt is, for all t, an optimistic
312

Translating \Ignoring Delete Lists" to Numeric State Variables

approximation of the minimum value that vi can take on after t steps: the value that
results when one ignores all increasing e	ects on vi , and is optimistic about the decreasing
e	ects. In this sense, the introduction of the inverted variable ;vi = vj can be viewed as
a way of informing the relaxed planner of where, in the numeric constraints and e	ects,
to use the minimum or the maximum possible value of vi , when computing an optimistic
approximation of these maximum and minimum values.14
We now focus on relaxed plan extraction. As justi
ed by Theorem 3, this is invoked only
if the relaxed planning graph succeeds in reaching the goals. Also as before, the information
that the graph provides are the levels of all actions, propositions, and numeric goals. For
actions and propositions the de
nitions stay the same, for numeric goals (exp  >] 0) the
level is the graph layer t where the goal can 
rst be achieved, i.e., where exp(maxt )  >]0
holds the 
rst time. An outline of the plan extraction mechanism is shown in Figure 7.
Compared to the algorithm for restricted tasks, shown in Figure 5, the novelties in
Figure 7 are that complex numeric goals get split up into goals for the individual variables,
that e	ect right hand sides are forced to have a suciently high value, and that := e	ects
are handled. The 
rst issue, given a numeric goal (exp  >] 0), is dealt with simply by
constraining all variables vi 2 v(exp) to take on their respective max value. Similarly,
e	ect right hand sides in (vi  :=+=] exp) are forced to be suciently high by requiring all
vj 2 v(exp) to take on the respective max value. The := e	ects are taken into account as
an alternative way of achieving a numeric goal (vi   >] c) 2 v(Gt ). If there is an e	ect
(vi  := exp) with suciently high value, exp(maxt;1 )  >]c, then the respective action is
selected. Otherwise a set of actions with += e	ects is selected in a similar fashion as for
restricted tasks. As in Figure 5, when uniting sets of numeric goals that both contain a
constraint on the same variable vi , the stronger one of both constraints is taken. It is easy
to see that, upon termination, the selected actions can be used to form a relaxed plan for
the state at hand.

Theorem 4 Assume a linear numeric task (V P A I G) that is in LNF and has acyclic :=

e ects. Assume a state s for which the algorithm depicted in Figure 6 reaches the goals. The
actions selected by the algorithm depicted in Figure 7 form a relaxed plan for (V P A s G).

The (straightforward) proof can be found in Appendix A. We conclude this section with
two additional remarks. One thing that might also have occurred to the reader is that one
does not necessarily need to support a goal (exp  >] 0) by requiring all vi 2 v(exp) to
take on the maximum possible value. Weaker requirements might already be sucient. The
same holds true for e	ect right hand sides. One might be able to 
nd shorter relaxed plans
by using some simple heuristics at these points. It also seems plausible that the algorithms
speci
ed here will work for any strictly monotonic task that uses only += e	ects and acyclic
:= e	ects, assuming the mneed value computation is modi
ed appropriately. Exploring this
idea for richer language classes is left open as a topic for future work. It is also left open if
and how = e	ects and /= e	ects could be taken into account.
14. This insight has been pointed out to the author by David Smith in a comment on the submitted version
of this article. Optimistically estimating maximum and minimum variable values, or more generally
multiple variable values, is an alternative viewpoint to the monotonicity paradigm we explore here.
Investigating the alternative viewpoint in more depth is an open topic.

313

Hoffmann

for

t := 1 : : : finallayer do
p(Gt ) := fg 2 p(G) j level(g) = tg
v(Gt ) := f(vi  >] maxit ) j (exp  >]0) 2 v(G) level(exp  >] 0) = t vi 2 v(exp)g

endfor
for t := finallayer : : : 1 do
for all g 2 p(Gt ) do

select a, level(a) = t ; 1, g 2 p(e
(a))+
for all p 2 p(pre(a)) (exp  >] 0) 2 v (pre(a)) do
p(Glevel(p) ) = fpg
v(Glevel(exp >] 0)) = f(vi  >] maxilevel(exp >] 0)) j vi 2 v(exp)g

endfor
endfor
for all (v i  >] c) 2 v (Gt ) do
if 9a, level(a) = t ; 1, (v i := exp) 2 v (e
(a)),
v(Gt;1 ) = f(vj  maxjt;1) j vj 2 v(exp)g

exp(maxt;1 )  >]c then

/* introduce a's preconditions as above */

else
while maxit;1 6 6>]c do

select a, level(a) = t ; 1, (vi += exp) 2 v(e
(a)), exp(maxt;1 ) > 0
a not previously selected in this while-loop
c := c ; exp(maxt;1 )
/* introduce max constraints for all vars in exp as above */
/* introduce a's preconditions as above */

endwhile
v(Gt;1 ) = f(vi
endif
endfor
endfor

 >] c)g

Figure 7: Extracting a relaxed plan for a state s in an LNF task (V P A I G) (levels and
finallayer computed by the algorithm in Figure 1).

6. Metric-FF
This section details how the theoretical and algorithmic work described so far is used to
implement the heuristic planning system Metric-FF. Section 6.1 speci
es how the relaxed
plan information is used to de
ne the basic architecture of a planner that handles STRIPS
plus linear tasks with acyclic := e	ects. We then describe extensions that are integrated
into the system: Section 6.2 explains how the extension to ADL is handled, Section 6.3
explains how exible optimization criteria can be taken into account.

6.1 Basic Architecture
As in the STRIPS case, once we have the techniques for extracting relaxed plans, a state
space planner is easily implemented. The given linear task is transformed into an LNF
task using the algorithms described in Section 4.3. We de
ne a heuristic function, a search
314

Translating \Ignoring Delete Lists" to Numeric State Variables

strategy, and a pruning technique analogous to that used in the STRIPS version of FF, c.f.
Section 2.3. All methods are straightforward adaptions of the STRIPS techniques. The
heuristic function still estimates goal distance as the number of actions in the relaxed plan.

Denition 11 Assume a linear numeric task (V P A I G) that is in LNF and has acyclic
:= e ects, and a state s. The Metric-FF heuristic value h(s) for s is dened
as follows.
P
finallayer
If the algorithm depicted in Figure 6 fails, h(s) := 1. Otherwise, h(s) := t=1
jAt j
where At is the set of actions selected at layer t by the algorithm depicted in Figure 7.

The search strategy remains exactly the same, namely enforced hill-climbing as depicted
in Figure 3. The only di	erence lies in the the way we avoid repeated states. In the
STRIPS case, this is a simple hash table lookup procedure. The straightforward adaption
would be to store all visited states s, and cut out a new state s0 if an identical state s
has been visited before. We can, however, derive a weaker cuto	 criterion that has an
important performance impact in certain situations. It might be that s0 di	ers from s only
in that some solution-irrelevant numeric variables have other values. For example, the only
di	erence between s and s0 might be that in s0 more execution time has been spent. If we
expand s0 then iteratively we might end up with an in
nite sequence of succeeding states
that do nothing but increase execution time (this phenomenon can be observed in various
benchmark domains). We can avoid such phenomena by cutting out new states s0 that are
dominated by a stored state s. Given a task (V P A I G), a state s0 is dominated by a
state s if the propositions in s and s0 are the same, and for all vi 2 V , either vi is not
solution-relevant, vi 2 V n rV , or vi (s0 ) 
 vi (s) holds.15 If s0 is dominated by s, and the
task at hand is monotonic in the sense of De
nition 8, then all action sequences that achieve
the goal starting from s0 do the same starting from s.

Proposition 5 Assume a numeric task (V P A I G) that is monotonic. Assume two
states s and s0 . If s0 is dominated by s then, for all action sequences P 2 A , if result(s0 P ) j=
G then result(s P ) j= G.
Proof: Say P = ha1  : : :  an i is an action sequence such that result(s0 P ) j= G holds. We
show that, for all solution-relevant variables vi 2 rV and for all 0 
 j 
 n, vi (result(s0  ha1 

: : :  aj i)) 
 vi(result(s ha1  : : :  aj i)) holds. This proves the proposition: the variables in
the goal constraints are all in rV , the goal constraints are monotonic (De
nition 8 condition
(1)), and the goal constraints are ful
lled in result(s0  P ). So with the claim above they
are also ful
lled in result(s P ). We prove the claim on the solution-relevant variable values
by induction over j . Base case j = 0: by prerequisite, vi (s0 ) 
 vi (s) holds for all vi 2 rV .
Inductive case j ! j +1. First, the preconditions of aj +1 are ful
lled in result(s ha1  : : :  aj i)
due to the same argument as used for the goal constraints above. Second, all variables
that are contained in e	ect right hand sides on solution-relevant variables are themselves
solution-relevant by de
nition so the induction hypothesis holds for them. This proves the
claim with monotonicity of numeric e	ects (De
nition 8 condition (2)).
2
15. Recall the denition of the solution-relevant variables , given in Section 5.2: all variables that occur
in a numeric constraint, or in the right hand side exp of an eect ( j ass exp) on a solution-relevant
variable j .
rV

v

v

315

Hoffmann

LNF tasks are monotonic. So with Proposition 5, if there is a solution plan from s0 , then
there is a solution plan from s. Thus cutting s0 out of a search space that already contains
s is solution preserving. Consequently, during each search iteration performed by enforced
hill-climbing, our implementation keeps a hash table of states visited in that iteration, and
skips a new state if it is dominated by at least one of the visited states.16 As indicated
above, in various benchmark examples this prevents the planner from looping when the new
states do nothing but increase the value of some solution-irrelevant variable like execution
time.17
To extend our STRIPS pruning technique, helpful actions now are all those actions
that can support either a propositional or a numeric goal at the lowest layer of the relaxed
planning graph.

Denition 12 Assume a linear numeric task (V P A I G) that is in LNF and has acyclic
:= e ects, and a state s for which the algorithm depicted in Figure 6 reaches the goals. The
set of helpful actions H (s) for s is dened as

H (s) := f a 2 A j p(e	(a))+ \ p(G1 ) 6=  _
9(vi   >]c) 2 v(G1 ) : 9(vi  := exp) 2 v(e	(a)) : exp(v(s))  >]c _
9(vi   >]c) 2 v(G1 ) : 9(vi  += exp) 2 v(e	(a)) : exp(v(s)) > 0 g
where G1 is the set of sub-goals constructed at layer 1 by the algorithm depicted in Figure 7.

Supporting a numeric goal here means: for := e	ects, that the right hand side of the
e	ect is sucient to ful
ll the goal for += e	ects, that the respective right hand side
expression is greater than 0. Note that the right hand side value of an e	ect at the lowest
layer of the relaxed planning graph is exactly its value in the state s at hand. During a search
iteration in enforced hill-climbing, when expanding a state s, only the states generated by
the actions in H (s) are included into the search space. Note that states s where the relaxed
planning graph does not reach the goals have h(s) = 1 so do not get expanded anyway.
As in STRIPS, the algorithm can fail if either enforced hill-climbing gets trapped in
a dead end state or helpful actions pruning cuts out important states. We have observed
that helpful actions pruning is too severe in some numeric domains. So, in case enforced
hill-climbing fails we try again with the pruning technique turned o	, i.e., we continue the
hill-climbing procedure from the point of failure without pruning. If this fails too, then like
in STRIPS we employ a safety net solution: a complete greedy best-
rst strategy trying
to solve the task from scratch. This strategy expands all search nodes by increasing order
of goal distance estimation. New states are cut out if they are dominated by an already
visited state.
16. More precisely, a new state is skipped only if there is a dominant visited state in the same hash
entry. If the value of all solution-relevant variables is the same in and (like when only execution
time has increased), then our implementation ensures that this is the case. Otherwise it is a matter of
chance. It is an open question how the visited states could be indexed in order to provide a fast exact
answer to the query whether they contain a dominant state or not.
17. What we have here is a consequence of the undecidability of numeric planning (Helmert, 2002), which
can be observed even in seemingly benign benchmarks. In a nite state space we of course would not
run the risk of entering an innite loop.
0

s

s

0

s

316

s

Translating \Ignoring Delete Lists" to Numeric State Variables

6.2 ADL

ADL (Pednault, 1989) goes beyond STRIPS in that it allows, in action preconditions and
the goal, arbitrary equation-free 
rst-order logical formulae, and actions with conditional
e	ects { e	ects that only occur when their e	ect condition holds true. The e	ect condition
can be an arbitrary (equation-free) 
rst-order logical formula. In the numeric setting, the
e	ects can contain updates on numeric variables. The numeric constraints can now appear
at any point in a logical formula where a logical atom is allowed.
Like the previous FF version (Ho	mann & Nebel, 2001), Metric-FF compiles quanti
ers
and disjunctions away in a pre-processing phase. Metric-FF does not compile conditional effects away. So Metric-FF's internal language di	ers from STRIPS (with numeric constraints
and e	ects) only in that actions can have conditional e	ects, where the e	ect conditions are
conjunctions of propositions (and numeric constraints). The reason why ADL is compiled
into this language is that the heuristic algorithms (i.e., the relaxed planning graph) can be
implemented very eciently for this more restricted language format. The compilation can
be exponentially costly in general but is feasible when, as one might expect in the formulation of a realistic planning scenario, the logical formulae are not overly complex. The reason
why conditional e	ects are not also compiled away (which could be done in principle) is
that, as Nebel (2000) proved, this would imply another exponential blow up given we want
to preserve solution length. Fortunately the conditional e	ects can easily be dealt with so
there is no need to compile them away. In the following, we give a brief overview of the
compilation process, and of the extended heuristic function implementation. Except for
the heuristic function, the only thing that must be adapted is the state transition function,
which is conceptually trivial.
The compilation process is largely an implementation of ideas that have been proposed
by Gazen and Knoblock (1997), as well as Koehler and Ho	mann (2000b). The extensions
to handle numeric constructs are all straightforward. The process starts with the usual
planner inputs, i.e., with a set of parameterized operator schemata, an initial state, and a
goal formula. The compilation works as follows.
1. Determine predicates and numeric functions that are static in the sense that no operator has an e	ect on them. Such predicates and functions are a common phenomenon
in benchmark tasks. Examples, in a transportation context, would be the connections
between locations as given by a static (connected ?l1 ?l2) predicate, or the distances
between locations as given by a static (distance ?l1 ?l2) function. Static predicates
and functions are recognized by a simple sweep over all operator schemata.
2. Transform all formulae into quanti
er-free DNF. This is subdivided into three steps:
(a) Pre-normalize all logical formulae. Following Gazen and Knoblock (1997), this
process expands all quanti
ers, and translates negations. We end up with formulae that consist of conjunctions, disjunctions, and atoms containing variables
(where the atoms can be numeric constraints).
(b) Instantiate all parameters. This is simply done by instantiating all operator and
e	ect parameters with all type consistent constants one after the other. The
process makes use of knowledge about static predicates, in the sense that the
317

Hoffmann

instantiated formulae can often be simpli
ed (Koehler & Ho	mann, 2000b). For
example, if an instantiated static predicate (p ~a) occurs in a formula, and that
instantiation is not contained in the initial state, then (p ~a) can be replaced with
\false". As another example, if both sides of a numeric constraint are static then
the constraint can be replaced with either \true" or \false".
(c) Transform formulae into DNF. This is postponed until after instantiation, because it can be costly, so it should be applied to the smallest formulae possible.
In a fully instantiated formula, it is likely that many static predicate occurrences
(constant constraint occurrences) can be replaced by \true" or \false", resulting
in a much simpler formula structure.
3. Finally, if the DNF of any formula contains more than one disjunct, then the corresponding e	ect, operator, or goal condition gets split up in the manner proposed by
Gazen and Knoblock (1997).
When all the logical constructs have been normalized, the numeric constructs in the task
are transformed into LNF in a manner analogous to the process described in Section 4.3.
Integrating conditional e	ects into the relaxed planning process is an easy matter. The
relaxed planning graph di	ers from its STRIPS counterpart only in that it now keeps track
of the graph layers at which an action's e	ects 
rst become applicable. The relaxed plan
extraction process di	ers from its STRIPS counterpart only in that it now selects supporting
e ects for the propositional and numeric goals.

6.3 Optimization Criteria

In PDDL2.1, the user can specify an optimization criterion for a task. The criterion consists
of an arbitrary numeric expression together with a keyword \maximize" or \minimize"
saying whether higher or lower values of the expression are preferred. The semantics are
that a solution plan is optimal i	 the state it leads to is a maximal / minimal goal state with
respect to the optimization expression. Metric-FF supports, run in \optimization mode", a
somewhat more restrictive form of optimization. It accepts the optimization criterion only
if the criterion can be transformed, according to a certain schema, into additive action cost
minimization. The heuristic cost of a state is then the summed up cost of the actions in
the respective relaxed plan, and search is a standard weighted A where the weights can
be set via the command line. Note that this methodology can not give a guarantee on
the quality of the returned solution as the heuristic function is not provably admissible.
The methodology is an obvious option given that the cost of a relaxed plan (in an additive
setting) gives us a remaining cost estimation technique for free. It is an open question how
more general optimization criteria can be dealt with. In the following, we describe our
implemented methodology in a little more detail. We start with the STRIPS setting, then
outline the changes made in the extension to ADL.
Metric-FF rejects the optimization expression if it is not linear. Otherwise, if the optimization keyword is \maximize" then the expression isPmultiplied by ;1 so minimization
is required. The expression is then brought into LNF, j 2X cj  vj (the constant part can
obviously be skipped). With this notation, the optimization criterion is accepted (only)
if all action e	ects on variables vj 2 X increase the optimization expression value by a
318

Translating \Ignoring Delete Lists" to Numeric State Variables

constant, i.e., if all e	ects on vj 2 X are of the form (vj  += c) where c 2 Q, c  0. For
each action a, the cost of the action is then de
ned as

cost(a) :=

X

(vj += c)2v(e (a)) vj 2X

cj  c

i.e., as the sum of all increases in cost variables for the action, multiplied by their weight
in the optimization expression. The cost of an action sequence or set is the sum of the
individual costs. It is easy to see that, in this setting, 
nding a goal state that minimizes the
optimization expression value is equivalent to 
nding a plan with minimal cost. The search
algorithm we then use is, as stated above, a standard weighted A algorithm implementing
a best-
rst search on the function f (s) = wg  g(s) + wh  h(s) where g(s) is the cost of the
search path that leads to s, h(s) is the remaining cost estimate (i.e., the cost of the relaxed
plan from s), and the weights wg and wh can be given in the command line. Since the
remaining cost estimate is in general not admissible, the 
rst plan found is not guaranteed
to be optimal. But one would expect that empirically better plans can be found. We will
see below that this is, in fact, the case in some of the IPC-3 testing domains.
In ADL, the cost of an action in a state is the sum of the costs of all e	ects that appear,
the cost of an action sequence is the sum of the costs of the actions in the respective states,
and minimizing the optimization expression is as before equivalent to minimizing plan cost.
Estimating the remaining cost by means of a relaxed plan becomes somewhat less obvious,
since a choice has to be made on which e	ect costs are counted for the result. There
are e	ects that have been selected to support logical or numeric goals during relaxed plan
extraction, and there are e	ects that will get triggered when actually executing the relaxed
plan. We have chosen to only count the costs of the former e	ects. The heuristic search
algorithm remains exactly the same as in the STRIPS case.

7. Competition Results

We briey examine the IPC-3 competition data relevant to Metric-FF. The competition
featured domains spanning the whole range from STRIPS to PDDL2.1 level 3, which permits
a combination of logical, numeric, and temporal constructs. FF participated in the STRIPS
domains and in the numeric domains, demonstrating very competitive performance. We
only discuss the data for the numeric domains. A discussion of the STRIPS results can be
found in the competition overview article by Long and Fox (2003).
There were six numeric domains used in the competition. For each of these domains, we
include a 
gure showing runtime curves, and discuss relative (runtime and solution quality)
performance in the text. Like FF, the MIPS and LPG systems could be con
gured to either
favor speed or quality, i.e., to either 
nd some plan as fast as possible or to search for a
good plan in the sense of the optimization criterion. To make the graphs readable, we only
show the runtime curves of those planners that favor speed. We discuss the solution quality
behavior of these planners in terms of plan length, i.e., number of steps. Note that these
planners do not take account of the optimization criterion anyway. For the planners that
favor quality, we discuss their runtime and solution quality behavior in the text. Given
that the optimization mode in Metric-FF is only a preliminary implementation, we keep
the discussions short. We also give only brief descriptions of the domain semantics. More
319

Hoffmann

details on these can be found in the overview article (Long & Fox, 2003). We focus on the
six domains in turn, then give a short summary of Metric-FF's performance.

7.1 Depots

The Depots domain is a combination of the well-known Logistics and Blocksworld domains.
Objects must be transported with trucks as in Logistics, and must then be arranged in
stacks as in Blocksworld. The numeric constructs de
ne fuel consumption for trucks and
the hoists that lift the objects (in order to stack them somewhere). Objects have weights
and the sum of the weights of the objects loaded onto a truck at any time must be lower
than or equal to that truck's capacity. Figure 8 shows the runtime data on the 22 Depots
instances used in the competition.
10000
"FF.speed"
"LPG.speed"
"MIPS.plain"
"SemSyn"
1000

100

10

1

0.1

0.01
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

Figure 8: Runtime curves on Depots instances for the planners favoring speed. Time is
shown on a logarithmic scale, instance size scales from left to right.
The four planners participating in the numeric version of Depots were Metric-FF, LPG,
MIPS, and SemSyn. At the time of writing, no paper on the numeric version of any of
these planners is published. for LPG and MIPS, the reader is referred to the respective
articles to appear in this same JAIR special issue (Gerevini et al., 2003a Edelkamp, 2003).
As Figure 8 shows, SemSyn can only solve the single smallest instance, and MIPS solves 10
instances scattered across the whole set. Metric-FF and LPG solve most of the instances
and exhibit similar behavior. Metric-FF is the only planner that can solve the two largest
instances. As stated above, we only show the curves for those con
gurations favoring speed.
In the competition data, this version of Metric-FF is called \FF.speed", this version of LPG
is called \LPG.speed", and this version of MIPS is called \MIPS.plain".
320

Translating \Ignoring Delete Lists" to Numeric State Variables

To assess relative plan quality behavior (i.e., plan length or minimization expression
value), we computed quotients as follows. Given planners A and B, measure, for all instances solved by both planners, A's plan quality divided by B's plan quality. Compute
the average quotient. At points where we need an absolute measure of comparison between
the participating planners in a domain, we set the planner B to a hypothetical \Best-of"
planner whose data is obtained by selecting the best (i.e., lowest) results of all planners.
The individual planners in the domain are then all ranked by comparing them to Best-of.
The data obtained concerning plan length in Depots, for the planners shown in Figure 8,
is this. FF.speed's plans are on average 1:23 times as long as Best-of's plans, LPG.speed's
plans are on average 1:25 times as long as Best-of's plans, and MIPS.plain's plans are on
average 1:29 times as long as Best-of's plans. Thus plan lengths are roughly similar here.
For the single instance that SemSyn solves, its plan has 5 steps while FF.speed's has 10
steps, and those of LPG.speed and MIPS.plain have 11 steps.
We next comment on the algorithms used in the planner versions favoring quality. In
MIPS, similar to Metric-FF, in optimization mode the heuristic function becomes a kind
of relaxed plan cost in an A algorithm. In contrast, the LPG optimization method starts
from the 
rst plan, and then continues search for plans that are better. Metric-FF performs
best-
rst search on the function f (s) = wg  g(s)+ wh  h(s). In the competition, the weights
were set to wg = 1 and wh = 5. The quality version of MIPS is simply called \MIPS" in
the competition data. To improve readability we call it \MIPS.quality" here, similar to the
quality-favoring versions of Metric-FF and LPG, called \FF.quality" and \LPG.quality".
The optimization criterion in Depots is to minimize overall fuel consumption. For runtime, the quality versions of MIPS and LPG behave only slightly worse than the speed
versions. In contrast, Metric-FF's quality version solves only the smallest 3 instances. For
solution quality, the fuel consumption of FF.speed on the 
rst 3 instances is 22, 33, and 35,
while that of FF.quality is 22, 33, and 36. Thus no optimization e	ect is observable. On the
same instances, MIPS.quality 
nds more costly plans (32, 63, and 44), and LPG.quality's
plans are slightly better (22, 33, and 29). Across all instances, LPG.quality's plans consume, on average, 1:01 times the fuel that Best-of's plans consume, while that average value
is 1:46 for MIPS.quality.

7.2 Driverlog
The Driverlog domain is a variation of Logistics where the trucks need drivers, and the
underlying map is an arbitrary undirected graph (as opposed to the fully connected graphs
in the standard version of the domain). Drivers can move on di	erent paths than trucks.
The numeric constructs specify the total time driven and walked. Figure 9 shows the
runtime data for the 20 Driverlog instances used in the competition.
As in Depots, the participating planners were Metric-FF, LPG, MIPS, and SemSyn.
Again, SemSyn solved only the smallest instance. LPG.speed is the only planner that
solves all instances. FF.speed solves one more task than MIPS.plain (the respective data
point is almost hidden behind \SemSyn" in the top right corner), and is roughly as fast
as LPG.speed on the tasks that it solves. As for plan length, again none of the planners
is clearly superior. The average quotients versus Best-of are: 1:34 for FF.speed, 1:44 for
LPG.speed, and 1:21 for MIPS.plain. FF.speed's and LPG.speed's plan lengths are thus
321

Hoffmann

100
"FF.speed"
"LPG.speed"
"MIPS.plain"
"SemSyn"

10

1

0.1

0.01
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Figure 9: Runtime curves on Driverlog instances for the planners favoring speed. Time is
shown on a logarithmic scale, instance size scales from left to right.
on average somewhat longer than those of MIPS.plain. The di	erence has no tendency to
grow with instance size, though. On the single instance solved by SemSyn, SemSyn's plan
has 3 steps while those of the other planners have 8.
The optimization criterion in Driverlog is to minimize some (instance-speci
c) linear
combination of total time, driven distance, and walked distance. FF.quality's runtime
behavior is, as in Depots, a lot worse than that of FF.speed, solving only 5 of the smaller
instances. The quality of the plans is slightly better, though, 0:94 times FF.speed's values
on average. MIPS.quality and LPG.quality solve the same instances as their speed-favoring
counterparts. The average comparison of LPG.quality to Best-of is 1:00 (precisely 1:000411),
that of MIPS.quality is 1:31 { on a single instance, MIPS.quality's plan consumes less fuel
(730 units) than LPG.quality's plan (736 units).
The competition also featured a version of Driverlog (\Hard-Numeric") where driving a
truck consumes fuel proportional to the square of its load, and the criterion is to minimize an
instance-speci
c linear combination of total time and fuel consumption. Interestingly, with
this optimization criterion FF.quality is only slightly less ecient than FF.speed, solving
the same instances as the speed-favoring version. We will come back to this phenomenon in
the outlook, when we discuss the e	ect of optimization expressions on runtime performance.
The overall runtime performance of all other planners is similar to that in the domain version
described above. For the optimization expression, FF.quality's values are on average 0:77
times those of FF.speed (so an optimization e	ect can be observed). The comparison to
Best-of is 1:59 for FF.quality, 1:007 for LPG.quality, and 1:72 for MIPS.quality.
322

Translating \Ignoring Delete Lists" to Numeric State Variables

7.3 Zenotravel
The Zenotravel domain, as used in the competition, is a rather classical transportation
domain, where objects must be transported via airplanes. The planes use fuel, and can
y either slow or fast. Fast movement consumes more fuel. In the numeric version of
the domain, the fuel level of a plane and the overall fuel usage are numeric variables. In
addition, a numeric variable counts the passengers on board a plane, and fast movement is
only allowed if the number of passengers is below a certain threshold. A refuel operator can
be used to set the fuel level of a plane back to its maximum capacity. Without durations, the
only di	erence between the e	ects of slow and fast ying lie in the higher fuel consumption,
thus \fast" ying is a useless action. Figure 10 shows the runtime data on the 20 Zenotravel
instances used in the competition.
1000
"FF.speed"
"LPG.speed"
"MIPS.plain"
"SemSyn"
100

10

1

0.1

0.01
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Figure 10: Runtime curves on Zenotravel instances for the planners favoring speed. Time
is shown on a logarithmic scale, instance size scales from left to right.
Again, the participating planners were Metric-FF, LPG, MIPS, and SemSyn. SemSyn solves only the smallest three instances, the other planners solve the whole test set.
FF.speed is an order of magnitude faster than LPG.speed and MIPS.plain. For plan length,
FF.speed and MIPS.plain behave similarly, while LPG.speed 
nds somewhat longer plans.
The quotient values versus Best-of are 1:28 for FF.speed, 1:45 for LPG.speed, and 1:22 for
MIPS. When visualizing the data, one 
nds that the di	erence between LPG.speed's and
FF.speed's plans grows with instance size. SemSyn, again, 
nds the best (shortest) plans
for those instances that it solves. The quotients FF.speed versus SemSyn are 1:00, 2:72,
and 4:50 on the three instances solved by SemSyn.
323

Hoffmann

The optimization criterion in Zenotravel is to minimize some (instance-speci
c) linear
combination of total time and fuel consumption. FF.quality's runtime behavior is worse
than that of FF.speed, solving only the smaller half of the test set. MIPS.quality solves
only the 
rst 16 instances, LPG.quality solves all but the largest instance. The optimization
criterion values of FF.quality are on average 0:82 times those of FF.speed, so an optimization
e	ect can be observed. The quotient values versus Best-of are 1:51 for FF.quality, 1:39 for
LPG.quality, and 1:14 for MIPS.quality.

7.4 Satellite

In Satellite, a number of Satellites must make a number of observations using their installed
instruments. This involves turning the Satellites the right direction, switching the instruments on or o	, calibrating the instruments, and taking images. In the numeric version
of the domain, turning the Satellites consumes (non-replenishable) fuel, the images occupy
data memory, and the Satellites have only limited data memory capacity. Figure 11 shows
the runtime data on the 20 problem instances used in the competition.
1000
"FF.speed"
"LPG.speed"
"MIPS.plain"
"TP4"
100

10

1

0.1

0.01
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Figure 11: Runtime curves on Satellite instances for the planners favoring speed. Time is
shown on a logarithmic scale, instance size scales from left to right.
In this domain, the participating planners were Metric-FF, LPG, MIPS, and TP4
(Haslum & Ge	ner, 2001). TP4 (which 
nds plans with optimal makespan) solves 3 of
the smallest instances, MIPS.plain solves 7 of the smaller instances, LPG.speed solves 10
instances, and FF.speed solves 14. Note, though, that the instances that LPG.speed fails
to solve but FF.speed solves are mainly the smaller ones. As for plan length, the quotients
versus Best-of are 1:11 for FF.speed, 1:04 for LPG.speed and MIPS.plain, and 1:09 for TP4.
324

Translating \Ignoring Delete Lists" to Numeric State Variables

So plan lengths are roughly similar, but LPG.speed and MIPS.plain seem to have a slight
advantage over FF.speed.
The optimization criterion in Satellite is to minimize overall fuel consumption.
FF.quality's (MIPS.quality's) runtime behavior is a lot worse than that of FF.speed
(MIPS.plain), solving only 2 (4) of the smallest instances. LPG.quality solves the same instances as LPG.speed. The fuel consumption of FF.speed on the 2 instances that FF.quality
solves is 109 and 97. That of FF.quality is 109 and 83, so there is a slight optimization
e	ect on one of the two instances. LPG.quality 
nds the best plans for all instances that it
solves (thus the quotient versus Best-of is constantly 1:00), the comparison of MIPS.quality
to Best-of is 2:54.
The competition also featured a version of Satellite (\Hard-Numeric") where there were
no logical or numeric goals at all, and the optimization criterion was to maximize the amount
of stored data (i.e., the memory occupied by the taken images). This is an example of an
optimization criterion that can not be transformed into action costs in the sense explained
in Section 6.3. The actions that take images have negative costs. Metric-FF thus rejects
the optimization criterion and reports, for all instances, that they are trivially solved by the
empty plan. Similarly, the plans returned by MIPS.plain are all empty. The MIPS.quality
version 
nds non-trivial plans for the smaller half of the instances. For LPG there is no
data in the competition results for this domain version.

7.5 Rovers
In Rovers, a number of planetary rovers must analyze a number of rock or soil samples, and
take a number of images. This involves navigating the rovers, taking or dropping samples
(rovers can only hold one sample at a time), calibrating the camera and taking images, and
communicating the data to a lander. In the numeric version of the domain, all the activities
decrease the energy available for the rover by a certain amount, and an energy recharge
operator can be applied when the rover is located in a sunny spot. Figure 11 shows the
runtime data on the 20 Rovers instances used in the competition.
The participating planners in this domain were Metric-FF, LPG, and MIPS. None of
the planners can solve the whole test set, in fact LPG, which scales best, is the only planner
that can solve most of the larger instances.18 The smaller instances are solved quickly by
all three participants. FF.speed might have a slight plan length advantage. The quotients
versus Best-of are 1:02 for FF.speed, 1:26 for LPG.speed, and 1:19 for MIPS.plain.
The optimization criterion in Rovers is to minimize the number of recharge actions
applied in the plan (i.e., the cost of recharging is 1, the cost of all other actions is 0).
With this optimization criterion, FF.quality does not solve a single instance (we will return
to this in the outlook). MIPS.quality and LPG.quality solve the same instances as their
speed-favoring counterparts. LPG.quality's plan quality is 0 in all the 8 instances that
MIPS.quality solves. MIPS.quality's plans contain 0 recharge actions in three cases, 1
recharge action in four cases, and 2 recharge actions in one case.
18. In the actual competition data, LPG failed to solve 8 of the instances due to an implementation bug.
We show the corrected data provided by Alfonso Gerevini.

325

Hoffmann

100
"FF.speed"
"LPG.speed"
"MIPS.plain"

10

1

0.1

0.01
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Figure 12: Runtime curves on Rovers instances for the planners favoring speed. Time is
shown on a logarithmic scale, instance size scales from left to right.

7.6 Settlers
The Settlers domain is about building up an infrastructure in an unsettled area. The things
to be built include housing, railway tracks, sawmills, etc. There are a lot of operator
schemata encoding a complex building process. The raw materials, timber, stone, and ore,
must 
rst be felled, broken, or mined. One can then process timber into wood or coal, and
process ore into iron. Carts, trains, or ships can be built to transport materials. One can
combine materials to build docks, wharfs, rails, housing, etc. The encoding makes a more
intensive use of numeric variables than the other domains. While in the other domains
the numeric constructs mainly encode resource constraints and action costs, in Settlers the
numeric variables play an active part in achieving the goal. Indeed, many of the operator
schemata have no logical e	ects at all. For example, felling timber increases the amount
of timber available at the respective location by one unit. Loading (unloading) a material
unit onto (from) a vehicle is encoded by increasing (decreasing) the respective material
availability in the vehicle while decreasing (increasing) the material's availability at the
respective location. For building a housing unit at least one wood and stone unit must be
available, resulting in increased housing units and decreased wood and stone units. With
the numeric variables playing such an active role in the domain encoding, Settlers is a very
interesting benchmark for numeric planners. Figure 11 shows the runtime data on the 20
Settlers instances used in the competition.
Only Metric-FF and MIPS (in the versions that favor speed) were able to solve some of
the Settlers instances. LPG could not participate in this domain because some operators
326

Translating \Ignoring Delete Lists" to Numeric State Variables

1000
"FF.speed"
"MIPS"

100

10

1

0.1

0.01
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Figure 13: Runtime curves on Settlers instances for the planners favoring speed. Time is
shown on a logarithmic scale, instance size scales from left to right.
make use of universally quanti
ed e	ects, which LPG does not support. MIPS.plain solves
only a single instance while FF.speed solves the 6 smallest instances. It should be noted
here that the instances in this example suite appear to be rather large. FF.speed's plans
on the 6 smallest instances contain 53, 26, 102, 67, 74, and 81 actions respectively. For
comparison, in all of the other domains except Depots FF.speed's longest plan in the 
rst 6
instances contains 26 steps. In Depots the numbers are 10, 15, 35, 34, 75, the 6th instance
isn't solved by any planner. The plan that MIPS.plain 
nds for the second smallest instance
contains 36 steps (as stated above FF.speed's plan for this instance contains 26 steps). No
planner favoring quality solved any of the Settlers instances.

7.7 Performance Summary
In their speed-favoring con
gurations, Metric-FF and LPG perform the best, both in terms
of runtime and solution length. For runtime, in Driverlog and Rovers, LPG scales better
(solves more instances). In Zenotravel, Metric-FF scales better (an order of magnitude
advantage in runtime). In Settlers, LPG could not be run, but Metric-FF can solve some
rather large instances. In Depots and Satellite, there is a slight advantage for Metric-FF,
which solves a few more instances. MIPS lags behind both Metric-FF and LPG in all the
domains except Zenotravel where it scales roughly similar to LPG. As for solution length,
this is roughly similar for LPG and Metric-FF in all of the domains except Zenotravel,
where LPG's plans are longer. In Satellite there might be a slight advantage for LPG, and
327

Hoffmann

in Rovers there might be a slight advantage for Metric-FF. The plan lengths of MIPS are
roughly similar to those of Metric-FF across all the domains.
The results for Metric-FF in optimization mode, FF.quality, are less satisfying, at least
as far as runtime behavior is concerned. FF.quality does not solve a single instance in Rovers
and Settlers, and it solves only very few instances in Depots, Driverlog (with the normal,
i.e. not \hard" optimization expression), and Satellite. FF.quality's runtime behavior is
reasonably good only in Zenotravel and Driverlog (with the \hard" optimization expression).
The solution quality behavior is mixed. In most cases it can be observed that FF.quality's
plans are better in the sense of the optimization criterion than FF.speed's plans are. Better
plan quality is clearly observable in Driverlog (with the \hard" optimization expression) and
Zenotravel. It is also observable in Driverlog (with the normal optimization expression)
and Satellite, although only a small number of instances were solved in these domains.
Compared to LPG.quality and MIPS.quality, FF.quality is the only quality-favoring planner
here that shows dramatically worse runtime behavior than its speed-favoring counterpart.
The reasons for that must lie in the algorithmic di	erences between the systems, concerning
the way they treat optimization expressions. In the outlook we speculate on the reasons for
FF.quality's poor runtime behavior, and what might be done about it.

8. Conclusion and Outlook

We have presented a natural extension of a popular heuristic technique for STRIPS {
ignoring delete lists { to numeric planning. The straightforward implementation of MetricFF based on the technique was one of the two best performing numeric planning systems
at IPC-3.
Let us summarize the contributions of this work in a little more detail. The most
important contribution is the \monotonicity" idea, i.e., a numeric framework in which
the main STRIPS concepts (pre/goal-conditions, add lists, and delete lists) translate very
naturally to the numeric concepts (monotonic constraints, increasing e	ects, and decreasing
e	ects). The monotonicity idea might be useful in many other contexts beside the speci
c
heuristic planner implementation we focus on in this article (some ideas on that are given
in the outlook below). In the heuristic context considered here, we have:
 Abstracted the desirable properties (admissibility, basic informedness, and polynomiality) that ignoring delete lists has as a relaxation in STRIPS.
 De
ned a natural extension of this relaxation to the numeric case and provided suf
cient criteria to identify numeric tasks where the relaxation preserves the desirable
properties.
 De
ned a subset of PDDL2.1 level 2, linear tasks, where the sucient criteria can be
achieved by a pre-processing technique.
 De
ned algorithms that solve relaxed tasks in this language and thus provide a heuristic function.
 Implemented a straightforward extension of FF, and a 
rst technique that takes userspeci
ed optimization criteria into account. The FF extension (FF.speed) shows reasonable performance across a number of benchmark domains. Speci
cally it performed
328

Translating \Ignoring Delete Lists" to Numeric State Variables

best, together with LPG, in the numeric track of the 3rd International Planning Competition, both in terms of runtime and solution length.19 The runtime behavior of the
optimization technique (FF.quality) is unsatisfying, but plan quality improvements
can be observed.
Various research topics have been left open:
 The background theory given in Section 4.2 provides only sucient criteria for the
numeric relaxation to be adequate. The question is, are there weaker sucient criteria, and can one come up with a complete analysis (i.e., 
nd the exact borders
beyond which ignoring decreasing e	ects is no longer adequate)? Also, how do the
identi
ed borderlines translate, syntactically, to the mathematical constructs allowed
in PDDL2.1 level 2?
 The pre-processing algorithm given in Section 4.3 (transforming linear tasks into LNF
tasks) is de
ned for linear tasks only. Can it be extended to richer language classes?
Similarly, the algorithms given in Section 5.2 only work for LNF. Is there an easy
extension to richer language classes?
 As mentioned in Section 4.3, various kinds of numeric e	ects can easily be translated
into each other (e.g., := e	ects into += e	ects or vice versa), but the respective
translations behave di	erently in the relaxation. Can one identify problem classes
where one or the other formulation yields better heuristic performance?
 The current optimization technique, FF.quality, is restricted to optimization criteria
that can be transformed into action cost minimization according to a certain simple
translation schema. How can more general optimization criteria be handled?
 We have seen that the runtime performance of FF.quality is unsatisfying. There
appears to be some interaction (as exempli
ed by the two di	erent quality metrics in
Driverlog) between the form of the optimization (i.e., the action cost minimization)
expression and runtime behavior. An explanation for this might be the degree of \goaldirectedness" of the minimization expression. Intuitively, a minimization expression is
goal-directed if it is closely correlated with goal distance, i.e., the lower the expression
value the nearer the goal and vice versa. The maximally goal-directed minimization
expression is the goal distance itself (i.e., \total-time" in our sequential framework).
In contrast, the minimization expression in Rovers, number of recharge operations, is
only very loosely connected with goal distance. It would be worthwhile to come up
with a good formal notion of goal-directedness, and to investigate its connection with
runtime performance (in Driverlog the connection is less obvious than in Rovers). On
the more practical side, algorithms remain to be found that show better performance
no matter what the form of the optimization expression is. One option is to always
integrate, to some extent, the current goal distance estimate (i.e., the length of the
19. Note that one can easily imagine domains where relaxed plans in the way Metric-FF uses them would
likely yield no good heuristic information. As an example, consider the 15-puzzle, with numeric variables
encoding the positions of the tiles. In this situation, there is a large degree of interaction between the
numeric variables, and relaxed plans will presumably not be able to capture this interaction.

329

Hoffmann

relaxed plan in our case) into the remaining cost estimation. Another option is to use
di	erent search schemes. A branch-and-bound like approach appears possible (
rst

nd some plan quickly then use the cost of this plan as an upper bound during further
exploration of the search space).
It would be exciting to explore the impact of the monotonicity idea, i.e., the correspondence that it brings between pre/goal-conditions and monotonic constraints, add lists
and increasing e	ects, as well as delete lists and decreasing e	ects, in di	erent contexts of
planning research. Examples that spring to mind are other heuristic approaches, Graphplanbased numeric planning, or goal ordering techniques. To stimulate the imagination of the
reader:
 It seems likely that similar methods can be used in other heuristic approaches that
relax the task by ignoring the delete lists. For example, our techniques can presumably be adapted to heuristic estimators in the partial order framework used in RePOP
(Nguyen & Kambhampati, 2001), yielding a heuristic numeric partial-order planner.
Also, it appears feasible to integrate our techniques into Sapa's (Do & Kambhampati, 2001) heuristic function, possibly making that function more accurate in various
numeric situations. As another possible avenue, one might be able to adapt the techniques presented here for use in LPG's heuristic precondition cost estimation process
(Gerevini, Serina, Saetti, & Spinoni, 2003b), making it more sensitive to the numeric
constructs, and thereby { potentially { further improving LPG's performance.
 Koehler's extension of IPP to a numeric context (Koehler, 1998) su	ers from complications in the backward search procedure, which signi
cantly degrade runtime performance. Do the same diculties arise in the monotonic context?
 Koehler and Ho	mann (2000a) argue that there is a reasonable ordering B 
 A
between two goals A and B if, from all states where A is achieved 
rst, one must
delete A in order to achieve B . Under monotonicity, the straightforward translation
of this is that two numeric goals A and B are ordered B 
 A if, once the values
of the variables that participate in A are sucient to achieve A, their values must
be decreased below the necessary value again in order to achieve B . It seems that
Koehler and Ho	mann's techniques to approximate STRIPS goal orderings transfer
easily to this situation. Similarly, it seems that under monotonicity the de
nitions
and approximation techniques given for landmarks (subgoals that will necessarily
arise during planning) by Porteous, Sebastia, and Ho	mann (2001) can directly be
transferred to numeric goals.

Acknowledgments
This article is an extended and revised version of a paper (Ho	mann, 2002a) that has been
published at ECAI-02. Metric-FF was developed and implemented while the author was
visiting the Durham Planning Group, Durham, UK. Thanks go to Maria Fox and Derek
Long for discussions, and for making the stay enjoyable. Thanks also go to Malte Helmert
330

Translating \Ignoring Delete Lists" to Numeric State Variables

for some fruitful remarks on the relaxation theory. I thank David Smith for his insights into
the nature of inverted variables, and for many detailed comments on the language. Finally
I thank the anonymous reviewers for their comments, which helped improve the paper.

Appendix A. Proofs

This appendix presents the proofs to all theorems in detail. There are three di	erent classes
of results, which we focus on in turn: relaxation adequacy, relaxed Graphplan completeness,
and relaxed Graphplan correctness. Within each of these classes, the results are given for
languages of increasing expressivity.

A.1 Relaxation Adequacy

For STRIPS, the restricted numeric language, and numeric tasks in general, we prove that
the respective relaxations are adequate (in the general case, we identify situations where
the relaxation is adequate). The proof for the STRIPS case is trivial.

Proposition 1 The relaxation given in Denition 1 is adequate, i.e., the following holds
true.

1. Admissibility: any plan that solves the original task also solves the relaxed task,
i.e., assuming a STRIPS task (P A I G), any plan for (P A I G) is also a relaxed
plan for (P A I G).
2. Basic informedness: the preconditions and goals can trivially be achieved in the
original task if and only if the same holds in the relaxed task, i.e., assuming a
STRIPS task (P A I G), hi is a plan for (P A I G) if and only if hi is a relaxed plan for (P A I G), and for a 2 A, result(I hi)  pre(a) if and only if
result(I hi)  pre(a+ ).
3. Polynomiality: the relaxed task can be solved in polynomial time, i.e., deciding
RPLANSAT is in P.

Proof: 1. After application of each action in the relaxed action sequence, at least the
propositions are true that are true in the real sequence. So each action precondition, and
the goal, is ful
lled.
2. Holds because we are not dropping any precondition or goal constraints. The empty
plan hi is a plan for (P A I G) if and only if G  I holds. The same is true for (P A+  I G).
Similarly for action preconditions.
3. This was proved by Bylander (1994).
2
The proof for the case of the restricted numeric language is a straightforward extension
to the STRIPS proof, exploiting the correspondence between pre/goal-conditions, add lists,
and delete lists on the one hand, and x  >]c constraints, += e	ects, and -= e	ects on
the other hand.

Theorem 1 The relaxation given in Denition 5 is adequate, i.e., the following holds true.
331

Hoffmann

1. Admissibility: assuming a restricted numeric task (V P A I G), any plan for
(V P A I G) is also a relaxed plan for (V P A I G).
2. Basic informedness: assuming a restricted numeric task (V P A I G), hi is a plan
for (V P A I G) if and only if hi is a relaxed plan for (V P A I G), and for a 2 A,
result(I hi) j= pre(a) if and only if result(I hi) j= pre(a+ ).
3. Polynomiality: deciding RESTRICTED-RPLANSAT is in P.

Proof: 1. After application of each step in the relaxed plan, at least the propositions are

true that are true in the real plan, and the values of all numeric variables are at least as high
as in the real plan. As all action preconditions and the goal only require variable values to
be greater than or equal to a constant, all these constraints remain ful
lled.
2. Holds because we are not dropping any precondition or goal constraints. The empty
plan hi is a plan for (V P A I G) if and only if I j= G holds. The same is true for
(V P A+  I G). Similarly for action preconditions.
3. The following is a polynomial time algorithm that decides RESTRICTED-RPLANSAT.

M := I , m := v(I )

remove, from action preconditions and the goal, all propositions in M and
all numeric constraints that are ful
lled by the mi values (i.e., mi  >]c)
while G 6=  do
A := fa 2 A j pre(a) = g
M 0 := M Sa2A p(e (a))+
m0 := m
for i 2 f1 : : :  ng mi 6= 1 do
if 9a 2 A : (vi += c) 2 v(e (a)) then (m0 )i := 1 endif

endfor
if M 0 = M and m0 = m then fail endif
M := M 0, m := m0

remove, from action preconditions and the goal, all propositions in M and
all numeric constraints that are ful
lled by the mi values

endwhile
succeed

Remember that n denotes the number of numeric variables. Denote by At the action set
in iteration t of this algorithm. We prove that the algorithm succeeds if there is a relaxed
plan, that there is a relaxed plan if the algorithm succeeds, and that the algorithm takes
polynomial time in the size of the task.
If there is a relaxed plan ha1  : : :  ak i for (V P A I G), then at 2 At holds true for
1 
 t 
 k: the set M (the values m) always include (are always at least as high as) the true
facts in the relaxed plan (the variable values in the relaxed plan). The algorithm succeeds
after at most k iterations. It does not fail earlier as this implies a 
xpoint in contradiction
to reachability of the goals.
In the other direction, if the algorithm succeeds in an iteration k then one can construct
a relaxed plan. Simply linearize the (relaxations of the) actions in the sets A1  : : :  Ak in an
332

Translating \Ignoring Delete Lists" to Numeric State Variables

arbitrary order. If an action at a layer t has a += e	ect on a variable xi , then repeatedly
execute the action until all constraints on xi that have been removed in iteration t are
ful
lled (as all the constraints are of the form xi  >]c, this will eventually happen). The
actions applied this way all have their preconditions ful
lled as these were empty at the
respective iteration, and the execution sequence makes the same constraints true as the
algorithm.
As for runtime, each single iteration is polynomial. An upper bound on the number of
iterations is jV j + jP j. In each iteration, to avoid failure, at least one new proposition must
enter M or one new variable value must be set to 1.
2
Generalizing from the restricted language, ignoring the decreasing e	ects is adequate if
all numeric constraints are monotonic, and all numeric e	ects are strongly monotonic (plus
changes due to := e	ects can not propagate into a numeric variable's own value). The proof
generalizes, in this way, from the proof above.

Theorem 2 The relaxation given in Denition 7 is adequate for strongly monotonic tasks
with acyclic := e ects, i.e., the following holds true.

1. Admissibility: assuming a monotonic numeric task (V P A I G), any plan for
(V P A I G) is also a relaxed plan for (V P A I G).
2. Basic informedness: assuming a numeric task (V P A I G), hi is a plan for
(V P A I G) if and only if hi is a relaxed plan for (V P A I G), and for a 2 A
result(I hi) j= pre(a) if and only if result+(I hi) j= pre(a).
3. Polynomiality: deciding STRONGLY-MONOTONIC-RPLANSAT is in P.

Proof: 1. Say ha1  : : :  ani is a plan for (V P A I G). Executing the sequence under result,

all precondition and goal constraints are ful
lled. Denote by vi (t) the value of variable i
after execution of action at , and denote by vi (t)+ the value of variable i after execution of
action at under result+. We show that vi (t) 
 vi (t)+ for all i and t. With monotonicity
of numeric constraints, De
nition 8 condition (1), this suces. The claim is easily shown
by induction over t. With t = 1, vi (1) 
 vi (1)+ holds for all i simply because result+ is
identical to result except that all e	ects that decrease the value of a variable are ignored.
From t to t + 1, if vi (t) 
 vi (t)+ for all i then vi (t + 1) 
 vi (t + 1)+ holds for all i due to
the same argument, plus the monotonicity of the numeric e	ects in the sense of De
nition 8
condition (2): the higher the input numeric variables are, the higher the resulting value of
the a	ected variable becomes.
2. The empty plan hi is a plan for (V P A I G) if and only if I j= G holds. The same
is true for hi as a relaxed plan, as we are not dropping any goal constraints. Similarly for
action preconditions.
3. The following is a polynomial time algorithm that decides relaxed solvability of a
strongly monotonic task with acyclic := e	ects.
1. M := I , m := v(I )
2. remove, from action preconditions and the goal, all propositions in M and
333

Hoffmann

3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.

all numeric constraints that are ful
lled by the mi values
while G 6=  do
A := fa 2 ASj pre(a) = g
M 0 := M a2A p(e (a))+
m0 := m
for i 2 f1 : : :  ng mi 6= 1 do
if 9a 2 A (vi  ass exp) 2 v(e (a)) :
ass 2 f+= -= = /=g (vi  ass exp)(m) > mi then (m0 )i := 1 endif

endfor
for i 2 f1 : : :  ng mi 6= 1 do
if 9a 2 A (vi  := exp) 2 v(e (a)) : (vi  := exp)(m) > mi then
(m0 )i := maxa2A (v := exp)2v(e (a)):(v := exp)(m)>m (vi  := exp)(m)
endif
endfor
if M 0 = M and m0 = m then fail endif
M := M 0 , m := m0
i

i

i

remove, from action preconditions and the goal, all propositions in M and
all numeric constraints that are ful
lled by the mi values

19. endwhile
20. succeed

Here, as above, v(exp) for an expression exp denotes the set of all variables contained
in exp. The value of an expression that contains variables set to in
nity is given as the
limit of the expression in these variables. Note that by assumption the limits are all 1
(De
nition 8 condition (4)) so they can, in particular, be computed eciently. We prove
that the algorithm succeeds if there is a relaxed plan, that there is a relaxed plan if the
algorithm succeeds, and that the algorithm takes polynomial time in the size of the task.
Denote by At the action set in iteration t of the algorithm. If there is a relaxed plan
ha1  : : :  ak i for (V P A I G), then at 2 At holds true for 1 
 t 
 k: the variable updates
on m performed in the algorithm are always at least as high as those performed by the
result+ function. Note here that line 13 takes the maximum over the available := e	ects.
Note also that all e	ects obey De
nition 8 condition (2), so one needs consider only the
maximum input values in order to obtain the maximum output value. In consequence, with
monotonicity of numeric constraints in the sense of De
nition 8 condition (1), the algorithm
reaches the goals and succeeds after at most k iterations. It does not fail earlier as this
implies a 
xpoint in contradiction to reachability of the goals.
If the algorithm succeeds after an iteration k then one can construct a relaxed plan as
follows. Perform an upwards loop from 1 to k. At each iteration t, repeatedly apply all
actions in At until all the constraints that have been removed in line 18, in iteration t,
are ful
lled. We show below that this point will eventually be reached. Once the point
is reached, one can continue with the next higher t value until the step at the succeeding
iteration k has been completed. All the actions applied this way have their preconditions
ful
lled as these were all empty at the iteration t where the actions are applied, as the constructed relaxed plan always ful
lls the same constraints that were removed in an iteration,
and as by De
nition 8 condition (1) constraints can not become false again once they are
334

Translating \Ignoring Delete Lists" to Numeric State Variables

true in a relaxed plan. For the same reason the goals are ful
lled at the end of iteration

k. It remains to show that, at an iteration t, repeatedly applying the actions in At will
eventually ful
ll all the constraints removed in that iteration. Denote by It the set of all
variables that got set, in iteration t, to 1 in line 9, denote by It0 the set of all variables that
got set to 1 in line 13, and denote by Ft the set of all variables that got set to a new value
below 1 in line 13. We show that:

1. After one application of the actions in At the variables in Ft have at least the values
that they had at constraint removal in line 18.
2. With repeated application of the actions in At the variables in It It0 reach arbitrarily
high values.
This suces for the constraints eventually being ful
lled. Assume the two claims hold
true. Then, with monotonicity of the constraints (De
nition 8 condition (1)) the variables in
Ft contribute at least as much to the full
llment of these constraints as they did in iteration
t of the decision algorithm. As for the variables in It It0, there is a 
nite assignment to these
variables, higher than their previous values, that makes the respective constraints true at
this point. This is a simple consequence of De
nition 8 condition (1) (the constraints prefer
higher variable values), condition (4) (the expressions diverge in the variables), condition
(5) (existence of a 
nite ful
lling assignment), and the fact that the constraints were not
true in the previous iteration but became true when setting the variables in It It0 to 1.
The 
rst claim follows from the simple fact that the actions responsible for increasing
the values of the variables in Ft { the actions that ful
ll the condition in line 12 { are,
in particular, contained in At . Their outcome might be higher if other variables in the
respective e	ect right hand side have been increased 
rst there are no negative interactions
with other variables as we are considering the relaxed transition function. The argument
for the second claim is as follows. As for the variables in It , At contains the respective
responsible action ful
lling the condition in lines 8 and 9. Each application of this action
increases, by De
nition 8 condition (3), the variable's value by at least as much as the
previous application, so repeated application diverges. Note that, again, under relaxed
state transition, applying an action can not worsen the situation for other variables. As
for the variables in It0 , At contains the action a ful
lling the condition in line 13, with
(vi  := exp) 2 v(e (a)), exp containing at least one variable v0 2 v(exp) set to 1 at this
point (as (vi  := exp)(m) = 1). Recursively, a responsible action a0 setting v0 to 1 must
have been included in the previous iteration. If the e	ect of a0 on v0 is a := e	ect, a
responsible action must have been included earlier, and so on. At one point, the responsible
action a00 for the respective ancestor variable v00 must have been included in line 9. Repeated
application of a00 causes the value of v00 to diverge (with the same argument as above), and
in e	ect transitively causes the value of vi to diverge.
It 
nally remains to show that the algorithm terminates in polynomial time. Obviously
each single iteration is polynomial. The number of iterations is bounded by the number of
times that M 0 or m0 can be di	erent from M respectively m. Changes to these values occur
in lines 5, 9, and 13. The overall number of changes in line 5 is bound by the number of
logical propositions, jP j. The overall number of changes in line 9 is bound by the number of
numeric variables, jV j. So if there was an exponential number of iterations until termination
335

Hoffmann

then there would be an exponential number of consecutive iterations where changes occur
only in line 13. The number of such consecutive iterations is, however, bound by jV j  jAj.
This can be seen as follows. Throughout the entire sequence of iterations, only := e	ects
contribute to the changes. The := e	ects are acyclic by our assumption so their value
change can not propagate into their own value, and the only possible further change can
occur when a new action comes in. It takes at most jV j iterations to propagate the changes
through all variables (this is the length of the longest possible propagation path), so, if
at least one new action comes in at an iteration t, then another new action comes in at
iteration t + jV j at the latest. The obvious bound on the number of iterations where new
actions come in is jAj, which concludes the argument.
2

A.2 Relaxed Graphplan Completeness

For STRIPS and LNF tasks we prove that the respective relaxed Graphplan mechanisms
are complete, i.e., that they 
nd a relaxed plan if there is one. The proof for the STRIPS
case is trivial.

Proposition 2 Assume a STRIPS task (P A I G), and a state s. If the algorithm depicted

in Figure 1 fails, then there is no relaxed plan for (P A s G).
Proof: We show the contrapositive, i.e., if there is a relaxed plan for (P A s G), then
the algorithm succeeds. Say there is a relaxed plan P = ha1  : : :  am i for (P A s G). The
algorithm applies, at the 
rst layer, all possible actions. In particular, this includes a1 , so
at layer P1 at least the facts are true that are true after executing the 
rst step in P . The
same argument can inductively be applied for all actions in P , implying that at each layer t
we have at 2 At , and Pt contains all facts that are true upon execution of the 
rst t actions
in P . This implies that the goals are true at some layer m0 
 m, G  Pm . Moreover, the
algorithm does not fail at any layer m00 < m0 : if so then it follows that a 
xpoint is reached,
Pi = Pm for all i > m00 , so G 6 Pm , which contradicts our assumptions.
2
0

00

0

The proof for LNF tasks proceeds along the same line, but requires some care with the
details concerning the values beyond which numeric variables can no longer contribute to a
solution.

Theorem 3 Assume a linear numeric task (V P A I G) that is in LNF and has acyclic

:= e ects. Assume a state s. If the algorithm depicted in Figure 6 fails, then there is no
relaxed plan for (V P A s G).
Proof: We show the contrapositive, i.e., if there is a relaxed plan for (V P A s G), then
the algorithm succeeds. Say there is a relaxed plan P = ha1  : : :  am i for (V P A s G).
The algorithm applies, at the 
rst layer, all possible actions. In particular, this includes a1 ,
so at layer P1 at least the facts are true that are true after executing the 
rst step in P ,
and the maxi1 values are at least as high as the respective variable values. Together with
the fact that the e	ect right hand sides are positively monotonic (so inserting the maxt
values can only increase the outcome), the same argument can inductively be applied for
all actions in P , implying that at each layer t we have at 2 At , Pt contains all facts that
are true upon execution of the 
rst t actions in P , and the maxit values are at least as high
336

Translating \Ignoring Delete Lists" to Numeric State Variables

as the respective variable values. This, with the monotonicity of the numeric constraints,
implies that the goals will be reached at some layer m0 
 m, p(G)  Pm and for all
(exp  >] 0) 2 v(G) : exp(maxm )  >]0. Moreover, the algorithm does not fail at any
layer m00 < m0 . Assume it does. Then at m00 no new propositions have come in, and the
maxi values all either have not changed, or are already above their maximum needed value.
Denote by L the set of variables vi whose value is still too low, maxim 
 mneedi (s). Note
that L  rV holds since outside rV the mneed values are ;1. We have Pm +1 = Pm
and, for all vi 2 L, maxim +1 = maxim . We show that Pm +2 = Pm +1 and, for all vi 2 L,
maxim +2 = maxim +1 . This proves the claim: by iterating the argument, the same holds
true at all layers t > m00 + 1, and we get a contradiction to the goals being reached at m0
(note that all constraints in which a variable out of V n L participates are already ful
lled,
so increasing these variables can not reach new goal constraints). The set of propositions
could increase at layer m00 +2 if a new action came in, i.e., if there was a 2 Am +1 , a 62 Am .
The value of a variable vi 2 L could increase at layer m00 + 2 if: a new action came in a
+= e	ect right hand side expression (vi  += exp) became positive in Am +1 as a result of
increasing the V n L variable values from m00 to m00 + 1 a := right hand side expression
(vi  := exp) in Am +1 became higher than maxim +1 as a result of increasing the V n L
variable values from m00 to m00 + 1. None of these three cases can occur by de
nition of
the mneed values (that the variables in V n L have reached). As for the 
rst case, Am +1
can not contain a new action because no new precondition constraints became true from
m00 to m00 + 1 { only the V n L variable values have increased, and the constraints in which
these participate are already ful
lled at m00 . As for the second case, all (vi  += exp) e	ect
right hand sides in which V n L variables participate are already above 0 with the values at
m00 (vi 2 L  rV , so the mneed de
nition for += e	ects applies). As for the third case, if
this occurred then there was at least one variable vj 2 V n L contained in the right hand
side of the responsible e	ect (vi  := exp). This variable would ful
ll maxjm > mneedj (s),
thus exp(maxm ) > mneedi (s) would hold (vi 2 L  rV , so the mneed de
nition for :=
e	ects applies), thus maxim +1 > mneedi (s) would hold (through application of (vi  := exp)
in Am ) in contradiction to our assumptions. This concludes the argument.
2
0

0

00

00

00

00

00

00

00

00

00

00

00

00

00

00

00

00

00

00

00

A.3 Relaxed Graphplan Correctness
For STRIPS and LNF tasks we prove that the respective relaxed Graphplan mechanisms
are correct, i.e., that the actions they select form a relaxed plan. The proof for the STRIPS
case is trivial.

Proposition 3 Assume a STRIPS task (P A I G), and a state s for which the algorithm

depicted in Figure 1 reaches the goals. The actions selected by the algorithm depicted in
Figure 2 form a relaxed plan for (P A s G).

Proof: First, note that at each layer t and for each goal g 2 Gt, there is at least one action
a such that level(a) = t ; 1, g 2 e (a)+, due to the way the levels are computed. Also, an

action's preconditions always have a lower level than the action itself.
The algorithm selects a set At at each layer t. We can arrange the actions in each of
these sets in an arbitrary order to obtain a relaxed plan for (P A+  s G). All goals and
337

Hoffmann

sub-goals at a layer t are achieved by the actions in At;1 . So with delete e	ects being
ignored, at least the propositions are true which are needed.
2
The proof for LNF tasks is a straightforward extension of the STRIPS proof.

Theorem 4 Assume a linear numeric task (V P A I G) that is in LNF and has acyclic :=

e ects. Assume a state s for which the algorithm depicted in Figure 6 reaches the goals. The
actions selected by the algorithm depicted in Figure 7 form a relaxed plan for (V P A s G).

Proof: First, note that at each layer t and for each goal g 2 Gt, there is at least one action
a such that level(a) = t ; 1, g 2 e (a)+ , due to the way the levels are computed. For the
numeric goals (exp  >] 0) 2 v(Gt ), there is always a := e	ect with suciently high right

hand side value, or

maxit ;

X

a2At :(vi += exp)2v(e (a)) exp(maxt 1 )>0

exp(maxt;1 ) = maxit;1

;

holds. In the 
rst case the while loop is not entered, in the second case it terminates
successfully. Note that one occurrence of an action can support di	erent logical and numeric
goals by di	erent e	ects, but can not be used to support the same numeric goal twice.
Denote, for a layer t, by At the set of actions selected by the algorithm at that layer. We
can arrange the actions in each of these sets in an arbitrary order to obtain a relaxed plan
for (A+  s G). All goals and sub-goals at a layer t, both logical and numeric, are achieved
by the actions in At;1 . The expressions in numeric goals and the e	ect right hand sides are
always at least as high as required as we constrain all contained variables to take on their
respective maximum values. With delete e	ects being ignored, at least the propositions are
true which are needed. With decreasing e	ects being ignored and monotonicity of e	ect
right hand sides, the expression values in constraints are at least as high as required. 2

References

Bacchus, F. (2001). The AIPS'00 planning competition. The AI Magazine, 22 (3), 47{56.
Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Articial
Intelligence, 90 (1-2), 279{298.
Bonet, B., & Ge	ner, H. (1998). HSP: Heuristic search planner. In AIPS-98 Planning
Competition, Pittsburgh, PA.
Bonet, B., & Ge	ner, H. (1999). Planning as heuristic search: New results. In Biundo,
S., & Fox, M. (Eds.), Recent Advances in AI Planning. 5th European Conference on
Planning (ECP'99), pp. 60{72, Durham, UK. Springer-Verlag.
Bonet, B., & Ge	ner, H. (2001). Planning as heuristic search. Articial Intelligence, 129 (1{
2), 5{33.
Bonet, B., Loerincs, G., & Ge	ner, H. (1997). A robust and fast action selection mechanism for planning. In Proceedings of the 14th National Conference of the American
Association for Articial Intelligence (AAAI-97), pp. 714{719. MIT Press.
338

Translating \Ignoring Delete Lists" to Numeric State Variables

Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Articial Intelligence, 69 (1{2), 165{204.
Do, M. B., & Kambhampati, S. (2001). Sapa: A domain-independent heuristic metric
temporal planner. In Cesta, A., & Borrajo, D. (Eds.), Recent Advances in AI Planning. 6th European Conference on Planning (ECP'01), pp. 109{120, Toledo, Spain.
Springer-Verlag.
Edelkamp, S. (2003). Taming numbers and durations in the model checking integrated
planning system. Journal of Articial Intelligence Research. This issue.
Edelkamp, S., & Helmert, M. (2001). MIPS: The model checking integrated planning system.
AI Magazine, 22 (3), 67{71.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Articial Intelligence, 2, 189{208.
Fox, M., & Long, D. (2001). STAN4: A hybrid planning strategy based on subproblem
abstraction. AI Magazine, 22 (3), 81{84.
Fox, M., & Long, D. (2002). The third international planning competition: Temporal and
metric planning. In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of
the 6th International Conference on Articial Intelligence Planning and Scheduling
(AIPS-02), pp. 333{335, Toulouse, France. Morgan Kaufmann.
Gazen, B. C., & Knoblock, C. (1997). Combining the expressiveness of UCPOP with
the eciency of Graphplan. In Steel, S., & Alami, R. (Eds.), Recent Advances in
AI Planning. 4th European Conference on Planning (ECP'97), Vol. 1348 of Lecture
Notes in Articial Intelligence, pp. 221{233, Toulouse, France. Springer-Verlag.
Gerevini, A., Saetti, A., & Serina, I. (2003a). Planning through stochastic local search and
temporal action graphs. Journal of Articial Intelligence Research. This issue.
Gerevini, A., Serina, I., Saetti, A., & Spinoni, S. (2003b). Local search techniques for
temporal planning in LPG. In Proceedings of the 13th International Conference on
Automated Planning and Scheduling (ICAPS-03), Trento, Italy. Morgan Kaufmann.
Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporal
planner. In Proceedings of the 2nd International Conference on Articial Intelligence
Planning Systems (AIPS-94), pp. 61{67, Chicago, IL. AAAI Press, Menlo Park.
Haslum, P., & Ge	ner, H. (2001). Heuristic planning with time and resources. In Cesta,
A., & Borrajo, D. (Eds.), Recent Advances in AI Planning. 6th European Conference
on Planning (ECP'01), pp. 121{132, Toledo, Spain. Springer-Verlag.
Helmert, M. (2002). Decidability and undecidability results for planning with numerical
state variables. In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of
the 6th International Conference on Articial Intelligence Planning and Scheduling
(AIPS-02), pp. 44{53, Toulouse, France. Morgan Kaufmann.
Ho	mann, J. (2000). A heuristic for domain independent planning and its use in an enforced hill-climbing algorithm. In Proceedings of the 12th International Symposium
on Methodologies for Intelligent Systems (ISMIS-00), pp. 216{227. Springer-Verlag.
339

Hoffmann

Ho	mann, J. (2001). Local search topology in planning benchmarks: An empirical analysis.
In Nebel, B. (Ed.), Proceedings of the 17th International Joint Conference on Articial
Intelligence (IJCAI-01), pp. 453{458, Seattle, Washington, USA. Morgan Kaufmann.
Ho	mann, J. (2002a). Extending FF to numerical state variables. In Proceedings of the
15th European Conference on Articial Intelligence (ECAI-02), pp. 571{575, Lyon,
France. Wiley.
Ho	mann, J. (2002b). Local search topology in planning benchmarks: A theoretical analysis.
In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of the 6th International Conference on Articial Intelligence Planning and Scheduling (AIPS-02), pp.
92{100, Toulouse, France. Morgan Kaufmann.
Ho	mann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Articial Intelligence Research, 14, 253{302.
Koehler, J. (1998). Planning under resource constraints. In Proceedings of the 13th European
Conference on Articial Intelligence (ECAI-98), pp. 489{493, Brighton, UK. Wiley.
Koehler, J., & Ho	mann, J. (2000a). On reasonable and forced goal orderings and their use
in an agenda-driven planning algorithm. Journal of Articial Intelligence Research,
12, 338{386.
Koehler, J., & Ho	mann, J. (2000b). On the instantiation of ADL operators involving
arbitrary 
rst-order formulas. In Proceedings ECAI-00 Workshop on New Results in
Planning, Scheduling and Design.
Long, D., & Fox, M. (2003). The 3rd international planning competition: Results and
analysis. Journal of Articial Intelligence Research. This issue.
McDermott, D. (1996). A heuristic estimator for means-ends analysis in planning. In
Proceedings of the 3rd International Conference on Articial Intelligence Planning
Systems (AIPS-96), pp. 142{149. AAAI Press, Menlo Park.
McDermott, D. V. (1999). Using regression-match graphs to control search in planning.
Articial Intelligence, 109 (1-2), 111{159.
Nebel, B. (2000). On the compilability and expressive power of propositional planning
formalisms. Journal of Articial Intelligence Research, 12, 271{315.
Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning. In Nebel, B.
(Ed.), Proceedings of the 17th International Joint Conference on Articial Intelligence
(IJCAI-01), pp. 459{464, Seattle, Washington, USA. Morgan Kaufmann.
Pednault, E. P. (1989). ADL: Exploring the middle ground between STRIPS and the situation calculus. In Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), Principles of
Knowledge Representation and Reasoning: Proceedings of the 1st International Conference (KR-89), pp. 324{331, Toronto, ON. Morgan Kaufmann.
Porteous, J., Sebastia, L., & Ho	mann, J. (2001). On the extraction, ordering, and usage
of landmarks in planning. In Cesta, A., & Borrajo, D. (Eds.), Recent Advances in AI
Planning. 6th European Conference on Planning (ECP'01), pp. 37{48, Toledo, Spain.
Springer-Verlag.
340

Translating \Ignoring Delete Lists" to Numeric State Variables

Refanidis, I., & Vlahavas, I. (1999). GRT: a domain independent heuristic for STRIPS
worlds based on greedy regression tables. In Biundo, S., & Fox, M. (Eds.), Recent
Advances in AI Planning. 5th European Conference on Planning (ECP'99), pp. 47{59,
Durham, UK. Springer-Verlag.
Refanidis, I., & Vlahavas, I. (2000). Heuristic planning with resources. In Proceedings of the
14th European Conference on Articial Intelligence (ECAI-00), pp. 521{525, Berlin,
Germany. Wiley.
Refanidis, I., & Vlahavas, I. (2001). The GRT planning system: Backward heuristic construction in forward state-space planning. Journal of Articial Intelligence Research,
15, 115{161.
Russell, S., & Norvig, P. (1995). Articial Intelligence: A Modern Approach. Prentice-Hall,
Englewood Cli	s, NJ.
Smith, D. E., & Weld, D. S. (1999). Temporal planning with mutual exclusion reasoning.
In Proceedings of the 16th International Joint Conference on Articial Intelligence
(IJCAI-99), pp. 326{337, Stockholm, Sweden. Morgan Kaufmann.

341

  	

 	
    


		  !
 

 	
 	 	  
	 	    
 	


 

	 


 	


 	


 	


	 
 	  		  
 
 
 
    !  "


   	
     	 
 
 	 
    	  	  
 	

         
    
 
 ! " # !"$    	 %  % 
	 	 %  
 	  
 %  &   	
	 	
	
 
    
&  	  '	 (
 #'

$ 
  	    	 '
  
 	
   
 	
    
  
 )
  
  !"    
    
  
 
 
	
 	 & % *	 +    
 % 
  
  !"          %  
  

	 & 	
 	


 	
  	 	  	 
  	
  

  	    	  	   
       
        
	 
  Æ 
 	  	  
 ! "
#$% & #'% ( ##% )  * + #,-    	  
  

  	
 
   

 ! .	 *
+ #% / * 0	 	
 1#% 2	 * 34 1#% /	
 * 3
11- .	   
  	
 
  
	 	
   

	  	  
 

5   	   
 	   	 

  

  

      
	 
  

  
   

    $  )
6	
 !)6-     7 !24	 * 8  1#-  
     !3 * . # 11-  

  9   
	         
    	
 !(
-

  
   
 
 
 !:	 * ; #<- &
   
    	 
    	
 
      

          
 !3 . . * .
 1$-  
 	 	= 	
	
    "	
#  
	 $#

   

     $ )6   	 
9     


 > ?  	  !; * 5 1$-
&   	   
       

	     !.	 0@ * 6 #,- &   	
	
        

       
 	
 !&(
-   	
 (
  	      
 
   &(
    	  	
  	
  	   
  	     	
 	
  	   	   
  	
 (      	     	 
   
  	
  	
   >?  
    

&   
 	   	    	 !&(

-           	  
&(
 &    &(
     	 	   

      !  
-  	 	
   	
     	 
      
  
  
    	
     
  )  
	    	
    A   !   	 
 	
   
  -
  $ )6  
 	  
	      

 	  	   
  	
  9       
	
   	 
    	 
   
 	   
 	          	


 	   
 	
& 

  @   . 1 
    
 

   	
    . $       
	    	
  
     	
 
   	
 	        
      	     	 
  

  
 . , 
     
	   
 
 	   $ )6    Æ   

 
 
	
 
 . B    	    
;    

    	  	
  	
          	   
	
 
  . ,

 
 
 
 


      
  
    	
 

         
 
 !:	 * ; #<-
 
   
 

( 
 
      
        
  &            
,-

   
     
  

    (      
   !

-    
  	 
  (      
  



   
    	   	 
     4  
 	   	 
 # &     # 
  
 
      
 
 	 !     	   
   -
      C D  

 !- 
   
 ! -  &    
 
      
 
         7  
 	 
    
  
  C D% 
     
 E# 
  
 4  C D% 
       E#

   4  C D F         
     	   
  		   C D   

  4
&     	  	    
   
    
    !-   4   
!

 
-    
     
   
	  	  ! 
-
& 

     

   	     
 	 

 C D        	 C D  ! 
      	        
  - +       	  	   
      ! 	
  	-  	
3  
 
 	 G  
 
 
    	
     	  #   
	 	 !:	 * ;
#<- & 
     


     


     	   	 &     

   	     	       	 
	 :	  ;          
  > 4?
& 	    
 
 	      
7  	       	         
      
    H   
  & 	    9
    
   


  !; * 5 1-         

+      	         

 
   
  C D         
 
     9  
  4   
  C D  
 9     

I 

  
  
  
       	
 

 
 



   
   	   
 
 	     


















































 





  

 
	 	  




    





 	




 	   
 



   	
      	
  	  	     	
 
 	    	    	

,

   


  	 
  
 
    

  	  



	 	 	

8    
  
   
   
 	  
   	  	 


     
 
   
   
       	   
 
      

    
      !-  
       # 
    !
- 4 C D  !J # ! C D   

    - (  
  

   
     
  	


   
    
    	    
	 	   















  	 
    
  	 
       

  

;  
 
 	     
 
   	

  
 
     	   	  ; 
  
   
     
 	  
  	   (

 ( ( 
	 	
   	

	   
 
  !0 8  24	 * /	

#<-    
  	   	     	
Æ   >? 	    	    9

   
    
 	     	   

 	      	
& 9   
     

    	 
     4       	 

   
   
   
 
      
  

 ! -       
    & 
  
 

   
  
  !3 * . 11-
   	  
    
   9   



   
  
 
 
    	  
	 	   

        	   
  C D  C D    






	



  	   	    
   

 	 
 	   
      		 
  	 	 

 
 





.      

     
  

  
   	 	
   
 ! 	
     



-
 	    
   
 
      

     
       
	   
   
  	 
  	
	 !:	 * ; #<-
	 !; * 5 # -   !0   #<-      
  
   
      	 !0@ * .	
#-   !3 * . #-        	 
 (           
     
   @   
  	    !  

   
     
-
,

   
     
  

 
   
 

& 9    !3 * . 11-     
  
 	     	         9  


 &    	  

   $ )6     
 
      	
 	   	   


  	 
   
 
  
   	
    	
   
H4  	
  
9   !; * 5 1$-   

   	 

  	
 	    
  
	 

    !	- 

   $ )6
   
  
 	
       	

  
 >  ? ! 
  	     
-  4  
 > ? ! 4        
-  . $,        
  
 
4    	   $ )6


  
 
  ! 	   
   	    		  	

  
  
  
    

  


    

  	
             5(
 
 
    
 !
 - 
   	  5(

     
  
      !#- 
 	   !1-  	
       
 

K  9     	     
   
  C D    C D%        4  
  !
    
-  

  
     C D  
 C D &     
  4   	
  	      
 
 ! ( * K 
##% )  * + #1% 8 * 0	 	
 1#-  
   

     	   	  	  
   !	       -      


 	   

; 	
 	      
  	 

  	
     	     
   
    	  
     &    

   	
      !       
	          -
.  5(
    	         
   

 
     
  	 
  (
7
 5(
   
  	
       	
 
 

   9     	
 4 

 	 Æ




















   	    	  	 	        

,

   

 5(
  

  	
       	

      	 
     (   
     	
      
  	
 

          
  

   5(

  Æ    
       
  
        

  	 	  	      	    
 
    	
   	
  	 
 
       9   5(
 !
- 	 
  4     	    	
(          
     9  
        5(
  
  (
 
 @   
   	      5(
   9
   	      
 (
 2   


 	     @  5(
    
 	   
%
;  	     
 
 	
 
	   	            5(
 
   L   
 
    &     
 ! ! -- 
   	  C D 	     
 
 
     L%       
! ! -- 
   	     C D  	 & 	

    	        5(
   
  	     L


 !   
  " 	   
    L 	


 	 





 	 

  

  

 L 






    	#
 

     
  	     
 

   
 
   
 





#

&     &(
    
7   
  	
        
 ! 
 
-  
   	
   
    	   ! 

 
-

  L          
 
     !  -   L     	 
  !       
      -  . $,
             3
 	
   
   
  4  	
 	 








 





 



 



 





 



 

 ! 	
   	 	 "#	    	 	 	   	  	 
 	   	 		  $
       $ %    	

       &    	 	     	
' ( 	  )"#	  	    *	( + 	,
 	
	 	   	 	 	   	 	 	 *	 - .
 $$ 
/  	      	
 	 	 	 	
0

,,

   
     
  

Level 1



Level 2

Level 3

Level 4

(−)



(0)
(50)






(0)

(0)








(50)




mutex



(50)
[50]

(0)







(120)
[70]
(0)





(0)


(−)

(120)













(50)





(−)

(120)

(120)







	 (−)

(220)


(160)







(0)

 





LJ	 




(0)

 %



% 


 

(−)

% 




(220)
[100]
(220)

(220)





(160)
[40]

(120)



mutex



(160)

(50)





% 

  



% 

  

 %






; #7 ( 	
  &(
 /  	   
    
	  K   	
       
 !-     !- & 	    

      >!M-?    
 
   


   ! >?      -      C D 
    C D & 	
           ! -
           
  

 
! 9     			    	
    
 

    	
    
     
 9         	
   	 

  L 
! -       % 
! -   	
      			    	
    

   	
       	 
 
; #   	
   &(
     !  %-  
  
   .  

  
   %   %
  L !	     -       L     

 	 !	        % - & 	
   
   &   9   @          
 
 

  	 @  
!  -       .
!  -     	        			 
    L
  	
    
  !@-  !  - .    $
,.














 	 



 	 





 	 



 	 





 			





 




 

 




 



 	 



 	 





 	 

 



 			









   

 

          

 
    
!   	 
! - J
! -      .  	 
 %
!          %-
! % -   			 

!  -   	
    

 
  ! ' - 
 
  % ;         

   %    .
! ! % -   
!  -      
! % -


 "   
    
 " 	   L 
	 	   


 ! 	     
 

 	 L  	    	 
   L 



    	       
   	 L J   L J  
+       &(
   
   	  

  
        &(
 !    
&(
         	   
 
  - & 
           
  &(
   
     


  
        
 


 	
  
          
      
N  	
   >?      	
   
       &(
 
   
      

 
      L
; 
 	   		@  
 	
 !  >&	?
>.	
&	? >6	
?  	   >8	?  >28	? 	 
  $ )6-  	    
   &(
 ; 	  	
  !  >.
?  >8	? 	    $ )6-   

 	  5(
&
 
 
  #
    		   
       
      
      	
   
         

 .
   
   	  
9   9 >	
 ?  

 
    	
 
9   
  	 
 
9       
 
 	 ( 	
  	

             	   $
)67   
 9          
   ! 
 
	    
9   
-    
       ! 
 
	-
&
 	  
  	 	   	  	
           
 ( 	
   
     	     $ )6    
9  
 
 
      




 	 

 	 









 	 

 	 





 	 

 	 






  	 



 	 



 	 



 













 











 





 



 

 



& " 	 		  	  	
 	  1  )"#	 	  
	  1  "#	 	     2 3 - 4	
 $$ 

,/

   
     
  

& 
 
              
  !- 
9     I 
  
	      	
  	    	 
    	         

  .
$B   A          
   $ )6 
	     	 
  4  	 2
  

       	         
	     
F    
        	 4  
 
5            	  
         
	
    ' 

 	 
9   
 	 
    9 >	? ;
  
 	    
 	    
 	   $
)6 
	   ! " #   " $  %


    	   	  
 	
  9 	   	   
      
 &          
   
 	 
     4    	
  
    
     
9        
 	   ;	         

  4
  H      	     
 &  
 9      4  @    
 
   
	           	 
  8    
   	 
  	
       ! 
  @  
-   	
 
   
     
         
 	
  	  

       " $  %

 &    
     % &  &   
 	 %&   $
)6  #$B'   4      %

   

"   &  '(
 & J '< O , J 1<#1
   	    
  B O 1<#1 J #$B'




















   
     
 
    
 	      +    

     	   
   
 &   
	
  
    
       	
 	
     	  	  &(
 

        
 	    	

      C D         





5 "   	   
  	 	  	    	 ! 
	
 	
        6
    	 	    

	  6    	   	

,0

   

    
        	 ! 




    	  -
 $
  % &'
3  
 
      
    	   (
 
 !  
 
-  	     
 !   
- 
  

  
 	9 	
   
 
 & 
 	9       (
       
    (
  	    !   -( (  

   
  
   (
        
 	  	      
    (

&  	      
 ! 9    - 
  	 
 & 9 
   @       
  (
 &  
     
   
   (

 	   (
 +     (
    ;

     
	  
	 	     	
	 7
 	
 (
 !    
         

  
 -%  	  (
%  (
  

   

     	  	  	 %
  (
   	   
   
   
 & 

  
    
 
	@ 
      


 
 	 !3 * . 1-        
@    	
  
   9
     
  
 ;    @ 
      

 

      
 !3 * . # 1-
I   	
   (
    
   
    (
     

       
!	-          

     	  
          
     
  	     	        	  8
  	      	   !   

   

 
    	- I   
             &
        	   9 	
  
 
	 !          

 
  ) P * ) #<% 3 * .  #'- I

         &   
    $ )6    
	 
  . , 
 


       

3   
        		 ! - 
      (
   	   

  
 	9  




 



 



7 "  	 	  		6  3 	 4	 $$ 
  	   
   	
  	 
 
  	  	2	     	


,1

   
     
  

!G
$ 7 ( 
 
 	 G  			 	    


 			 	    
    !   #-
% 7 (  
 
  
  G  %
#   #

1     (
  	  
 
  G%

$   # 
,

     
 
B
 
'
    %
<
!  -       %


    ! -              

    !   	   
  	 #
 
   
##
   	  ! - 	 
#1
    	  ! -%
#$  %
   	  	   

  	

 	  







  	  



  	



 



 

 

 

 

; 17 3 	         	  
   # &     
      	
    	     
 	9 
   	    

 (  
     	  	      
    	     	     
     
  (
 ! - &    (
 

  	       	      	 	  
 
 
  	         
 

)
  	

3  . !#- 

        7
   	    

       
      $ )6      
	  
  .
,   	  
     	   


9  
 	 !.	   #,% 0@ * .	 #'-    
	       (
    
  
  &  

    (
      
  	
	 5

     
     3  (
     
    	9            	9
 
	    (
      (
%  








8 !  	
 	      	  	       	

 	 	 	  
  	 	2	   "	  	   	 
  		   3 - 4	
 $$ 

,2

   


      
  ! -   	   
   #
  (
      			     
   
       	    
 !  

- 
 (
    

  @     
 
   
9 			 	   	 !  
 
- ; 1   	 
 
  
3  . !11- 

 	      
   (
         
 
	 
    5(
  &(
 &  
	
	       
      $ )6
 (
)  *

   
 
&         5(
      5(

    	       

   	  
 
 !  
   
    



- (  

         
 
        4          
!	    
 
    - &   
    
     
 
.      5(
     	    !
  	 
 
-   	   
	   
   	

>	
? !    
-   5(
  = 	
 
               
      
        


+            	
  5(
  
      	           
   !;   . $,   	
-    	 
  	   5(
    	    


  
   .	   	   

  

      +   
     
	
      
   
 	 
& 	              

	     ! ! - -  	    ! ! - - 
     	   
     
 
   4   H	  7
 ! - J 
!-E 
!-E 
!! - J 
!- J 
!-E 
!-E 
!& 9 	  	     
   !
-
  	   	  !
-    	  


 









































  






  





 

  




	  

 




 	 

 


  



	  

 



 	 

 







	 

	 

 


 

	  

  	 

9 . 	    	    	   	   	 
	

.-

   
     
  

  	    
      
 !
- & 
9   	    	@ 	      	

!	    . $'-
  	
   	     	
 4   I 
     	     
     
 
 I     	
     >? 
     	 	       	
              
	     4     9  


  
	  Æ  	

&    	     	
 
  
 
   
       &(
   
  9       
       
 
    	   9   

	 











 	 	   

.

               
 
&  	    	  	
   
 
 		      !#-  

 
   !1- 
 Q  
       5(
   	 


  !      
 

    

 

- & 
           

      	 4
 	
    ;     
  
 !#-  
  
  
 !1- &   
     
 
 
 ! 
 
  -   7
 &     
    9      
 	 
  
     Q  
    

  
   	
 	   $'$"    




   
   #     
  &
  
   Q  	
 	 $'$" 	9   4 
           
 
 	
  

  
   
     
        

    
  

  
  	  
        
       

 
 
 & 	        
     
      	    
 

 
  
 !#-  !1-         
  	    
    
 !	 
-
































$ . 	
 	       
    	 /"#	   	 	
   	    		# 	 	      	
 : 
  
    	   	 	  

.

   

+   "	 
! -    
       
	 

   !	    
   
        
- N     


 ! ( * K  ##% )  * + #1- "	 
! -  
	 9    
"	 
! - J 	  
! -   	% 
     

8     
  	

!!! -

! -      
; $    	  	
   
 
     
! -     %
! -   
   % ! -   !
- 4  
%
! -     
       
    
 !    -%
! - 
 	 			 	       	
! - !
! -    	 - &   	

   
    . $$
3         $'$"    
  	
    
 	
  
 (  J 
 7
     
 	   
  	 $'$" %   	
  	 
 	       & 9 	  (    
! -   
! -
( 	         . $1$    
        7 9  	
   
  

        
    
  
    ! "	 
! -- & 
         
 
    >?     
     
! -
 	   	
         
   "	 
! -
 
   
 
! -  
      ! -    7 !-   4   % !- 


    	 $'$" % !-      


   			 	    	   			   
			 	      

  

 	 $'$" !

 			 
! -   
  -% !-    			
	   

 
    !  @    "	 
!  -  		-
 	


! - J      
! -E
!  -














 





	 	 









	 	   	 	   	 	 



!  

" 	 




 #$$ 

 	$    



     



 	$    

     



   

%

#



#&  

#

%

#&  



%

#	

'

$

	 '









#

#



'



(	   )

)



)









     













(	   )

#'%* + 
¼ 

* #,
     
   ¼ 

 	  

     
 4      )"* 
   4     
 
-

)

#



   

   	    	     	     	 		 
  
   	   	 		    

.

   
     
  

!
$7 (     ! -            
  &(
 
    !$'$" -  
  	
    ! -%
%7 (       	  	  		    
     	        

#   
! -%
1  
%
 %
$   
! -% 
, 
 !- %
B 

J 
'
   
%
<

! -%

 ! !
-%

  !
#
! -
! -E
!
-%
##
 !
-	

%
#1
 
! -%
! -E
!
-
%
#$

	
#,  

% +  +   #

%



#



%

%

* #,
 	 )
   

%

%

-

+  +  #&  

#

   #$$ 

* #,

 * #,  )
  

%

-

)

%

	 

-

(	   )

'

" 	 	 



 

#&  
-

#$$ 	 

-

$ 	 '

#	

'

 +  +   #&  

!  	 

	 

   #$$ 
* #,  $ 	 '

!  	 

#&  

; $7 (	  	
   
      

	   $'$" 
  
    ! -
! -
  9            	
 
! -         

   
  


'

#	

'

(	   )

$ 	 '
)

J 	     ! -          ! ! -  

8         9     
 
 	  
 &  
! -   
  
  !  -     !  -    
  
     

        
 

K	 !-  !-   9 
   K ! !-       	
	      
      
	        
#



)

#$$ 



" 	 

    

#

(	   )

" 	 

-

" 	 



-

(	  

    	   	     		    
 	
 ; 
 	  	 	    	 	  	   	 
	 	 	  	   
 	         
		 	 	   	 	 ! 	    	   	 
  	

.

   

 
	  
     			
   			
	      

  
        

  	      	      + 
     
    !-    	

! - +  	
9     	
   
	
  
       	  6)N	     


 !    
	    	   
  -
.
 # ,  #$   	   	     
  &   9   			 
!-  	             $'$" !
 #-%
! -  	  	 ! -          4
     )"* !
 ,-%
!-  	  	   	
      

     	   !
 #$-
& 	  ! -  	
  
 M# 	    
  
 	 6  	 	    ! -  
  	 $'$" !
! -  -   	 

J   
		 	 !  #1-     
   	

  	  
	   	        
 
 
	H	
  	 	 
.

          &(
    ;
, ;        	
     ; ,   
   	
  !
  

 
 
 - &
      $'$"  @ &  
     	
     
    ; , .
    
 
       	 
%  
   
  
       
  
% 9       
  

       
;              
  ! - 
"	 
! - 
!! ! -- 
 J
!!
! J
 -
 &        	    	  
!! ! --

  ! -    

 
! -  	 (  + 
! -  	    
     $'$"    9    
 1
	  	  .           
 	 .


              !	   	 
.,


(	  

 	  

%

%



 )

)

(	  

%

%





     



	 



   

   

 	

   





" 	 





#	

" 	   +  +  



#	

 	    +  +   

" 	 

$

	





" 	   +  +  

" 	 

" 	 

  





%











#

   
     
  



 	

!	

















  



Unsupported
precondition

5


mutex



9



















	





$
7$
$$
&$
$
7$
$

"









,

 


!	



.





/

mutex



,

.







/



0






1













r



r







$
7$
$$
$
9$



2



-





.

0















ÁÆÁÌ

; ,7 ( 	
   .  
   
   
  %   
    	 
%
  
   
      
   
%        


! -  
 <- F           
    

   
    &    
    $'$"  K   
   ! % - 

 
%       &       %    

   $'$"      !     
  	
  -
K  
    	        &  ' 
&    		 
 !  -    4  %   
 )"* !       ! ! -- & 

      $'$"  . 
! & - J   
! '- J
#
! -  &  6 !! ! --  	  % & 


  "	 
! -  	 (  + 
6      "	 
! -  !	 

	 %
 (  ) .  

& 
- 

      



4









  !    
%
(
&
..
(	   



























" 	 



 +  +  

 	  



(	   





#	

 	  

" 	   +  +  

  














  +  +      





#

   

 
 	
   
  -  "	 
! ( -  	
   
    

  (          
  	  % & (

"  ,  
!+       	
    ! ! $'$" - (   	
  
9      ; ,   
 
 # 
!  - J 11 (      ! -  
    
   !     -   
% !     % -      
  %   
 #
 ! ! %- $'$" --    B   			   !  
!  -   	   B
     
    
 #  ! ! - $'$" -  
! &- J #<  
  ! ! %- $'$" --   B 

 M#  !  -  BE# !   % -   
 #$   
	#< BE
#
 2      

   
   
 	 % 
 #<   
 #$  ! ! -   
	11 #<E
<
 J 1,
(      9 
   	
     

  
! & - $'$" 	  % 
- 

   

&  &    !
  &  	  %
 #<     
  &    
$'$" !  -        )"* ! % -   !  - J #B

!  - J #<  	  	  &  #< E $ J 1 ( 
 #$ 
! ! -    
	1, 1
   
  	
  	  % &
 1,








   
" 	 

" 	  



 	 

" 	 









" 	 







 	 

 	 





" 	 

 	 

" 	 

 













* #,









" 	   +  +  

* #,







" 	 



 



   










 	 

 



" 	   +  +  

  

* #,





 	 
  



(    	       	
  
  ! -
     
 & 	      
       9   	     
           &(
  	 
!  * 	 
 	  - 8        	  
   	  			 	    
   
  
  
&
	  ! -   	    	   
  	        	   


        
 &
	  ! - 
 	    	   
   	 


 	 	    
   

 
&
	  ! -   	      
  


 
       		   
    ! ! -- &
	  ! -  	 	 










  


 	 







 	 

  



  


	  







& 



	  

  

 / 	2	     	      	 	   		6	 
   	 		     

./

   
     
  

! $ 7 (          &(

%7 ( 
 	        	
  
! ! --%
#

1
 ! ! -%
$  
	
	
!  -  L J   

%
,  
	
! -
%
B
 !
-  	 
%
'
 !
!! - -%
<   ! -  E
! -




 	$    	 	 

+  + 
'

" 	   +  +  

* #,

 * #,  	 

* #,

#

#	

 $





	 '

'



'

 	    +  + 

#	

' 

 	    #

!  

! $ 7 (        &(

%7 ( 
 	        	
  
#

! ! --%
1
 !
!-
$ 





+  + 
'

 	$    	 	 

.       +  +  

'

; B7 (	  	     	
    
 !-  	 !-     
  
 
! -   9    
 9  ! - 
     	
 



  9  . $1#
! -   
 
   	 

  	 	 


#	

'

'

	 '

$

     	$    ! 

 	 

.     


  
      	 

  	
	    
  	  9  7
	

!
J
!    

!-
!-J
!! -
! - J  !! -- E 	     
!  -
	

!
J
! !   

!-
!- J
!! -
! - J  !! -- E 	     
!  -
         9  ; B   
 7      ! -   	    	  
- .	        
   	 !
.0




	  

 




 	 

	 

 


 


 




 	 

	 




 

 

¼

 

$

	

#	

& 







 

 



$ 	

#	

	  

 

¼

¼  



& 





& 

¼  



 	  









 	  




#	

$

	



   

    
   
   	 

 
 	 	     	    	   

  	 

 &   
     
   	
       . $1#
! -  
 1  
(  	
   $'$" 
  	
    
 ! -    
  
  	 $'$"  .
 $M, 	
  	    	  
    			     	     
  
!  - 
! - !  - .
 BM' 	
   
  "	 
! - 
       9   

  	
           
  	   
  

  !
    



   4-   	 


! -  
   
I    	 	   
     	
	   ! 

 
   	 -
.	         

   
  


 
   2       . $# 
 
    
  	
	      
  2          
  	 	   
 >4?  
    

     
      	
  ; , (
  . $11  
  
 
 1    	  % & 
 1,
!   
     ! ! -- ( 
 $  	
 

      1$ !    	
     
   &(
  	 
  1$- .
 ,   
	1$ 1,
  
  !	 
 $'$" 	 
 	  % & 
-  
 '  	  % & ( 

    	
          	   
 4  	  	   &      $  
 
  	  % & ( 
 1, E $
 #
 +)

,   

&      
    	
   
     	    			 	    
     	 $'$" !
! --    	  
 
  
	

! -  J #       
	  			 	       	     

 
 	     ; #
! -   	

     
         &(

!  
 - .   	       	
  	
   	
 
! -  
; '     	     	

! #-       4     	

.1






 	$    



'









$

	 '









.     

'

  



" 	   +  +  



 





* #,

     



       





       







      
     







 




     

    

     

+



   
     
  

 ! $7 &     
 
 	   ! -   
   
 !-%
%7 ( 	   	    !
-     	
!
-      	 
#   34 
    	  	 &% 
   
 43
1

  
! #-  %
! #-  %
! #-  %
$
,

! #-  #%
B
 %
 %  %
' 

J 
<
  %



  J 	   ! -  
   	


     %
#
 ! 
!
! --%
##
 
! #-%
#1
  ! ! #- ! E
! -- 
#$

  

! #-  E
! -%
#,
#B

  

! #- ! E #- 
#'
! #-  E #%
#<
! #-  %
#

 !- %
#
 	 
%
+

+

   

 	  

+





+

    

 	  



#  



    

-

+ - 
- 
-

+ #

#

-  - 

# " 	 



-

#



+  " 	 

* #,  	  
  




#$$ 





- 
 	   
!  
 	   



-

- 

    

    
#$$ 


 



#  

- 
- 
#
#


!  



-

! 
! $7 (         
 %
%7 ( 	   			 	         
	 !)"*-
#
 %
1

%
$ 
 J 
,
  	  %
B

! #-%
'

 	 
% 
<
  !! -%

 !
-
+ %

+

%

%

+

#&  
%

%

+

%

)



%

#  )

#&  
%

%

#&  



" 	 

+

   #$$ 

#&  

; '7 (	  	
  	       


.2

   

 	
 4    & 	 	     !-	

! -    H	%  # ! #   
 
  	 
! --   
! #- 	
    	    
   	 
    	 !
! #--   
! #-   
 	
  ! ! --   

   
   

! - 9     . 11 &    	 
	     	     

 
 
 9   			    	    
 8 
! #-   
      ! 	 	-  
&(

:     	  	
   	 
    	
         
 
 	       (    	

     
	
     

 


 


 	$    



+

 	  

+

    



 	  

 	 





 	 

 	  



 	 

   

	

 	   

;   9     
      
    		   	
 
  
 #M, 
! #-        #  ! 
	 @
   - &  
 BM#         
  	    J   	     
   
    

  	    
 
     &        @    
 
   !
 B-        

 !
 #- &
 
 !
 M#- 

        
  
    
 
 # 
  	
   
 
 
  
 . 	 
  	     9
	   +     !      
  

   -  

    	   4  
  ;  	  			 	       ! 	     ! 
 !
 #- &    
  

! #-   4  !
 #1 #BM#'-   

    
! #- 
 	     E #       
! #-    E #     &   
   	 !
! #--    !
 #<-
;         
! #- 
!
 $- ! 	

 
     
  	  
  
   

 	  

    



+



-

+

-

+

-

-

#

#

- 

- 

-

-

- 

-



#

#

-



" 	 

+



    





    





    







+

#  





# 

#  





'    	  	
   
  	 	   	
 
	
	 	  	  	 	 	 0	 <   	  
   	
&   		 	   
    	
 
   	  	 
  	  1	   = >         	 	    
	
 
   	  	       	
  	
    
! 	  	 	    	    	

/-

   
     
  

 
 ! -      &   	 
    !)"*-       
    
 !
- (          

      	        4  
   !
 <- &	  ! 
    
	     	 
! #-  	
    	 
! #- .
 $  	
  @           &  


       
      	  

  	  

   			    	   
 
 !
 ##- ;  4        ! 
   -     	
    
     
 #$M#,
! #-     !        
 

 	 -
& 	
     
	   	   
    
 	H	   .
 #  	 
 

  	   !- 	           
 @            	 	
  ! 	

  !-     	 	
    
! - 2   
	      ! 
 	
  	  	 	   !   	     
	 
	    - ;         
 	   

    
  4  
  
  	
	    	 
; <   	   	
 .

      
   )         (    
   

        

   	 & 9  
 

         
        
&
   
    @  ! 
 


 	  @    
   	  
   
	   4     
   4    


  .       !   -  
    			 !-  
 #,  #'    	 .  
   
 #, 
! -  # !    -  
 #' 
! -  # !  @- 
!  #-      
 #< & 4
      	
(  
         

      

 	     	     
 
    &   
    

   	 % & ' 
 6  

  % + 
  
 #    1  ! 
! ! % --  )"*  	   

!    
!  #- J  
!  #- J    
  
   - &
! -     !  			 	
 
   
  %  $ 
    %- 
!  -  $ &
4    &  '     	  2    
! &-  9   $   	 &     1  

/
%

%

+

%

# 

%

+

%

+

 	  



    










-



 	  





+

/

/

/

+

 			

 			







-

+

   







   

+



 	  



 	  

    








#   





-

-

-

 

#





- 

  

#





+  " 	 



+

#   

+





    



 	  

#  



 











    

   

'	




.








0












6	

  





























5
..0.111,-



.

0



(2)

(7)

.











	 
  

-





2

.

(2)







(1)

(1)













/



(2)



-




I 



(3)

(1)



(1)

,










(1)

(3)

(0)

-

,



1




(0)

1







.



/

0



1



; <7 ( 	
    & 	   

 
  J 	   ( 
 &  
   

        


   

    000 

	 ' (
! &-  9   #1      
! #-  9   &    ' 
6   
    

   ( ! 
 


  ! ( -  
 #  '    )"*     
   	 %   &  ' 
 .
 ##     

! %- J #1   
    4 (   
    'E#
#1E1  


 	  

#  & 









" 	 

     

 	  



 	  



   

 	   	
	  	

I   	       !    - 	  
    

    	 
  
 !: * 34
1#- !24	 * 8  1#-  		 !/ * 0	 	
 11- + 	

           

       	  
  
  
   !	
  - &  
  
            

 
	    		 	   	 9 4   		
 
/
   



   
     
  

: * 34 

     

   
!-         	          
  			      (   2	  34 !1-
  

	   
	      
 	  
4    
  	     	 
 	
        ! 	 	 -
 	      	  4  : * 34 
 


( 4    
   	  	

: * 34  

  	
     

 
  

  	     

     	 
 ! 	

 Æ  

      


 -
&      Æ      	
    :    
  
 #<  #  	
         
      	
  

    2      
 

    	 	  !-	
 	 	  
( 	
 4        ! 
  

#  	        
    
 			       
   	     
  
  	
   
       	 
  	  &      	 

  ' 
	 	     
  	  
;  4           

+   !-      
   	 : *
34  
  	

  	 &   
     	  

	 
 	 
(    24	 !1#-      	    
 
    
	
     	  
   ( 4  
      
	   
 +        
 
    	     
 
  	 
     
   4  
  
     	 
   

     	
   
		    ! 
    ! 
  	 
    
  
  

     	   
 
      	     - ( 9
4    		   	    	

  	  	   (      
 
 	     !  
     	 
      
     
-      	
     
   


















   





#





%





%

















(	  

5 . 	   	  $    +   	  	     ,
  
 	   1 	     		    	
		 	 	   	 

/

   

              	

 
 ( 	= 	   
	 	
     
   
    	 
 	   	
  9 
       	    
	 6)N	 ! 	 
     . $'-


 -
 .
 #
   /

              
   &(
    
    
   	
 
             
   
    

  
         
 L         	   
!! - 
    L  !
!! --     L   

	 	        	 	 L
& H	      	  
    ! -
 	
          !  - 
      L F  	   
	
        
	  	
  

 
	  4    
     	    !  
 
  4 -     L       
  
   
    4   
     
    
  	
  ! - 	  			 

 	
    !-  
  ! -   

   L 
     & 	    4   
          

  
   
 	
             


 
! -   
! - ;  

     

 

  (  %   &(
  ; #      & 
 , ! ; - &   ##  
  ) .
! )- J
#1
! ( - 	 1$   

  %   4
! % - 	
1< ! -    11 ! !  -- !  -    1< ! ! % -- 
! ) - 	 #1 ! !  --
.	 
   	    $ )6  !
-  

> ?  > ?  4  
 > ? !; * 5 1$-  

  	             4    
           9 
  
  . 11      
  
H4 +
     
   
(    9 
! -
 
!! -  
! - +   9 
!
   
      
   
 






 



	 	   	 	 






  
	 	   	 	 

 




 	 











 	 











 	 



 	 











 	 



 	 

 	 

 	 

 	 

 	 

 	 

 	 

 	 

 	



 	 



!  

 	 

 	 

 	 

7   	 	   	            
 	   	 	
     	   
  
         
 	 
	  	2      	 	        	  

/,

   
     
  

Level 1



Level 2

(0)

(50)
(50)
[50]



(0)








(50)





(0)





(120)
[70]



(0)





(−)







(0)









(−)





(0)





(0)







(270)
[40]
(230)





(120)









(120)









(120)



(220)




(220)


(220)




(220)
[100]

	 (−)



(50)



(220)



Level 5

(120)

(120)



mutex





(50)

(230)
[110]

(0)

(−)



(270)

mutex



Level 4

(50)




Level 3



(−)



(220)

(220)









 

LJ	 


 %

% 


% 

  

% 

 & &

 %

% 


% 

  

  

 % 


; 7 N
   &(
  ; #       &  
,  

  
  (  % /  	   

     	  K   	
 
       !-     !- &
	     
   >!M-?   

     








      4   
     	
! -

  
! -    			   !#-
! -   
 




4



  !1!
! -  

  

   4  
    !$- ! !!   

    	  -
+ 
  
 4 	    4  
 4 	
   
   	 
9  	   	   

 
) &      
   $ )6    

  
   
  	      	
  
              +   
     	   	    


	

 	 	

 	 



 	 

	



	

 	 

	

!  

 	 

!  



8 ! 	
    	   	    	   	     
 	  	  	

  	 	  
  	 	 	  	    	 	     
     	 	      
    	 	     	
  	
   
	   	
  ?
    	  	     
  	  
 	    	   	

/.

   

    
 2    
 	   $ )6  
 
 

 	        
     4  	

   
 9 K     	  	 
     
    	
  & 
     4 
     
 

 	  F
	    .	
&	   
) 	         
     #R
 ! 	  	
-   	
   	
  
     	 
 		   	
 	
     (  
   	
 	  	 
          

 !3 . * . 1$-
! (
  /
)
     A       
  4 
	  +     
  	 
 
4         
 
    
   
   
       	
      
 	  	     

 ! - ! -  ! -      	 !
 -  ! - J  
 
 
   	  
     	        
( 	 
   	 
        
  	  ( 	 
   
 
  
 	 
   	  J  
    
 ( 	
4   
 
        	7J EJ J J J
  
	 
 !  6 -     	 

    	 	       &(
 
    
 
   	   ;    
  
    	        	  

       &  
      
 
! - &     

      
 



	          

 &    	      
!- 
  	     
 	       
 
 
 	   .	       
! --        
 
      !
     9  	  J 
!! - 
   
         

  
( 	 
  
           


  



 



  0 0 0  





1

	 	 	

	


   	

 


1











 

	

	










2



1





	 



 

	



 	$    





 	$       

	 



	 	 	

	



	



	

9 / 	   	 	        	  	   
	  !
  	  	 	  	   	 	 	   	 	
		   
  	 	   	  	  	        4
    	
/"#	
      : ?   	  )"#	  	 	 
   
       	 

//

   
     
  

F 	    H	 H	      

H  	
 4      	     	 	 
     &   

       

/  

    	 
  	 

 


       	   4    
     
     
&  
     

 	 


J
     9       
   
 	

       

  >
?    

   !
  

 -   	
   
         		     ! 
  

 
   

       

- +            


      
       	 

+  A     	
   
    
  	 	 &         
	 
    	
  .     	
   	 
   
 
 	 2     !-    

   
    	 
    9 
! - !
. $1#-
! -  
  #   	 			   
 	 
   # !I       	
 
 	%           
  	
	     
  	 
( 4   9 
! -      	 

       

      
  
      
 	 
&    
 	
       
   4     
  !    

  -   	      			  			 
 
   	  +  	  	   $'$" J

!! -    	      
   
  	 $'$"      			H			
      	        
 &
  	 H        

 .
9  9  
  	 
    
! -   4       
  
@ 
           
 %     
      
  /      

     	 
 J 
  

  

      
    


	 	 	





	

	

	







   

)



(	   )

     

(	   )

)

)

)



 	$       

	 





 






 




	 

Æ

Æ










Æ











Æ

  
 





$ . 	  	  	  	  	  	   	 	  /
	 	 	      	  ! 	
  	  ;    $$
 	 	 
 	 	     	  	 	   	  	
    	  $ 	   	   $
     	   

/0

   

   
  	   	   ! J 
-
   	    			H			    	   
   !              
- .	   
    

" 0
1#

   2
,
(     

  	 4 
   	 
      & Æ     
  
9  . $1       	
 
   	
        	@ 	  
  
  .
9           
  !   ! -  	     -7
!-J
! -E
! -E # 
!

    Æ     	
  
  	
  
 &          
 	  	  
 9  
 	   	@
  
 	 &  #
 #
   	@  	  
       # &  
 9  
E 


! -   			    9 !- 	    &(

     	
   	      
 
%
 9   			  
  
  
H	  	     &    
  	
   9  
	@ 	    
 
	         

   
  !    
!-E 
! - E
! - J   *    
 
E  
!+  	@  9  	    	   
    	 &        
 

 Æ             
	 	
        
	@     


    
 
  	 
I 
  
     
   
   	
	
  
   	   & 9 
     @  
    
       &   
  	
	
     
      

   	   
 
 	
   ! 
      9      - +
     	      &(
 
 

 
    &(
    @   .	 
 	 	       &(
    

   	
  
   
    &    
/1












 




























 

 

3






3

	  








3



 	 








	 



 

3

2

2







3





3





4



	 

4

  


 




    



3

	  

	 






 
0



3

 	 






   
     
  

 	       	 	   
   !#- 
  

  
  !1-      



      & 	         
   
  	 	     
   
 
       
    
     	
   
 	

  $ )6    
 	 	
     9  
      9 6)N	 & 9    
    
  %            I
 9     	
         
	 	 6)N	   9 &  	 
   	

    	    .   	
    
       
       
    	    	 6)N	
 
                !#- 
9       6)N	    
   
         
  !1-    
  
     
   	 6)N	  9 
	             

     6)N	
'

'

3

3

'

3 
 3

 
 
(    	
	   & 	    6    
	 	  **
(*     
 	 
	
   Æ      
 	   $ )6 &

 	    	 	    	   4
   &   	 >.
? >.	
&	? >&	? >6	
?
>8	?  >28	?       
 ;  
 
 	           Æ     $
)6 !'''*
**
+**   *-
(      Æ 	   	
  ( / (
) #E !#B 2@-  # 3   K(  &    
  	
  9    
 	 
& 6)N	 	     B
	   	   8      
 
    	   Æ    	
     	 
       	  Æ 	   	    	 
 2        	     	
 


       	 2 	    @A    	 	  	 
	   	 	  	 	  < 	   	   	
  	  		        	    	
  /"#	
 <  A@%#  	      
  	 	 	   
  	      <  A@%#  	    
 
 	   	 	
        	  
/ 	  5   ''  

/2

   

 	

  

5)3
,,1
,'
,R
;;
1$<
1,
$R
.	
 #
#11
<BR
.


#11
''R
).
$$#
B
'BR
"2)I) #11
11,
B,R
.
B
#1
,R
&),
1'
1,
#$R
&).S.
#,
#1
#1R
.	.
##
#,,
R
&  #7 8	   
 	 	
     
   
  
$ )6      &  	  
 	

   	  Æ     $ )6 &     
  1 
 	  ) 28	      
    
  	
   

	   	
	  ) 6	
      	 
	 
 	        	    
   
 
  9    	

I  	   
 	 	
       
  ,'
!    B 
 	-      ,,R ! 
 	 	

    	
  ,1     <R- ; #   
  	 
   
   	
 &   
       	
 	
 

&         	
     
 	           4 & 	 
   	 9   	
	  !24	 * 8  1#-
&  	    9       ,- & ,

 	    	
   
   1 
 	  ) 8	
  1 
 	  ) 28	 & 9 	  

  9 4          
& 
 	   
 	    	  		@   
  	   
   ! -   
     	
       

  
 
 	      	 
   	
 
  

  @  + 
          
   
 B   	    	 	6	  	   / 
    	  $    
  *	.
 	 	  1	
 	 6 /  #		 	    	   
  	  $  
 " 	 	  
 	     

0-

   
     
  

+     	     
 	 	
 !			
	    
         
 -    	9    &      
 # 8     	    	 H  

   
      	      
 
      	       
9    B  
         
& 
	        	  
 !- 
 	 
9   
 	 	@  
   
#      Æ         


  
 	 ;    	
  
 	     
. 1  Æ     ,     
 	   
,   
 	  
9     B   
& 
	      	   6)N	   9  
 !
-      
 	
 !-   	 9
6)N	   
  ;  # ##  #1       
 	
	 !	
9  	 -%      
  6)N	   	
 !	 -    
  
       

  	   
 	 
   
 
 	

9 8     
      


 
;    
	  
 	
    	
  	
   	%  .  .
      
 
  	 
 	    
 	     .	
&	
 
	   	
  	   	   
 	  
6)N	 ! 
       	 -  ) 6	

  
	     	  
    
 	
;    8	   
	 	   
   
	   
 	 & 
   
	     
	     ; # &      	
 
 
   	            

 & 	  4   ) 6	
  

      	  
 	
    	      
	   

 

    	 
   	
  	
  
      
 +         

  
 >.
)? !   - 6   
	 
   .
)    	    	  
	 
    
    I      
	 






3

3

3

3

3

3

3

 	  	 	   	 1	   	    

 	 	
 	  	 	 	     	 			    	 
 
' A   	  	 	 		 	 			  	
			

0

   

DriverLog-Strips

Milliseconds

LPG-speed (20 solved)
FF (Speed) (15 solved)
MIPS (15 solved)
MIPS (Plan) (15 solved)
SemSyn (1 solved)
Simplanner (11 solved)
Stella (10 solved)
VHPOP (14 solved)

1e+06

100000

ZenoTravel-SimpleTime

Milliseconds
1e+08

LPG-speed (19 solved)
IxTeT (8 solved)
MIPS (14 solved)
MIPS (Plan) (16 solved)
TP4 (5 solved)
TPSYS (2 solved)
VHPOP (13 solved)

1e+07

1e+06

100000
10000
10000
1000
1000
100
100

10

10
0

2

4

6

8

10

12

14

16

18

20

Satellite-Complex

Milliseconds
1e+07

2

4

6

8

10

12

14

16

18

20

14

16

18

20

Rovers-Numeric

Milliseconds

LPG-speed (20 solved)
MIPS (8 solved)
MIPS (Plan) (10 solved)
Sapa (16 solved)
TP4 (3 solved)

1e+06

0

LPG-speed (17 solved)
FF (Speed) (9 solved)
MIPS (8 solved)
MIPS (Plan) (8 solved)

1e+06

100000
100000
10000
10000
1000
1000

100

100

10

10
0

2

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

; 7 6)N	  	   
 	    	 
  
$ )6   	 .  .
   .	
&	 )
6	
    8	
    	
       
   
	
  
& 
  ; ##  #1  	
   )    	
  
 
	 
    	
  6	
  &

     6)N	  
     

   .
)7       
 	    

     	 
        

  
    
 !         

   
 	  4 	  
  
    
0

   
     
  

DriverLog-Strips
Number of steps
1000
LPG-quality (20 solved)
FF (Quality) (15 solved)
MIPS (15 solved)
MIPS (Plan) (15 solved)
SemSyn (1 solved)
Simplanner (11 solved)
Stella (10 solved)
VHPOP (14 solved)

ZenoTravel-SimpleTime

Quality
4500

LPG-quality (19 solved)
IxTeT (8 solved)
MIPS (14 solved)
MIPS (Plan) (16 solved)
TP4 (5 solved)
TPSYS (2 solved)
VHPOP (13 solved)

4000
3500
3000

100

2500
2000
1500
1000

10

500
0
0

2

4

6

8

10

12

14

16

18

20

Satellite-Complex

Quality
700

4

6

8

10

12

14

16

18

20

18

20

Rovers-Numeric

Quality
9

LPG-quality (20 solved)
MIPS (8 solved)
MIPS (Plan) (10 solved)
Sapa (16 solved)
TP4 (3 solved)

600

2

0

LPG-quality (17 solved)
FF (Speed) (9 solved)
MIPS (8 solved)
MIPS (Plan) (8 solved)

8
7

500
6
400

5

300

4
3

200
2
100

1

0

0
0

2

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

; #7 T  
 	
   	 
   $ )6 
 	 .  .
   .	
&	 ) 6	

  &	    8	    	
    
 
. )    	 
  
 	- & 
     
        
 .
)
&        
  	  
   	

  	
  
     	   	   
.
)   .
   .
)     	 
 	
           8	   .
) 
   
 
     K   
 
 ) .
  
 
	 	    .
)
  .
      
 
    

	 
	      
    .
)
6      	
  
   6)N	
         . $'   	
   
0

   

Satellite-Strips

Milliseconds
1e+06

Satellite-Strips

Number of steps

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

100

100000
80

10000
60

1000
40

100

20

10

0
0

2

4

6

8

10

12

14

16

18

20

Satellite-SimpleTime

Milliseconds

2

4

6

8

10

12

14

16

18

20

12

14

16

18

20

12

14

16

18

20

Satellite-SimpleTime

Quality

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (19 solved)
SuperPlanner (Quality) (19 solved)

1e+06

0

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (19 solved)
SuperPlanner (Quality) (19 solved)

200

100000
150
10000
100
1000

50

100

0

10
0

2

4

6

8

10

12

14

16

18

20

Satellite-Time

Milliseconds
1e+07

2

4

6

8

10

Satellite-Time

Quality
700

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

1e+06

0

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

600

500
100000
400
10000
300
1000
200
100

100

10

0
0

2

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

; ##7 )	  
 ! 
-   ! 
- 	

  .
) !
   -  ) .
 .	

&	  &	
0,

   
     
  

Satellite-Complex

Milliseconds
1e+07

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (17 solved)
SuperPlanner (Quality) (17 solved)

1e+06

Satellite-Complex

Quality
700

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (17 solved)
SuperPlanner (Quality) (17 solved)

600

500
100000
400
10000
300
1000
200
100

100

10

0
0

2

4

6

8

10

12

14

16

18

20

Satellite-Numeric

Milliseconds

2

4

6

8

10

12

14

16

18

20

Satellite-Numeric

Quality

LPG-speed (12 solved)
LPG-quality (12 solved)
SuperPlanner (Speed) (14 solved)
SuperPlanner (Quality) (14 solved)

1e+06

0

LPG-speed (12 solved)
LPG-quality (12 solved)
SuperPlanner (Speed) (14 solved)
SuperPlanner (Quality) (14 solved)

800
700
600

100000

500
10000
400
300

1000

200
100
100
0

10
0

2

4

6

8

10

12

14

16

18

0

2

4

6

8

10

12

14

16

18

; #17 )	  
 ! 
-   ! 
- 	

  .
) !
   -  ) 6	
 
8	
 
  	          

   
    
   
  
  
  

      6)N	     	  
 6)N	   
 & 	     	
 
 
 
 ! 6)N	  -  
    
   
.
) ! 6)N	       .
)-
3   	         4  
 
 
 & 	 6)N	  
         
       4 
	      
 9         	
     	
0.

   

Satellite-SimpleTime-pfile15

Quality
180

160

Satellite-Time-pfile6

Quality

LPG (1st run, 8 solutions found)
LPG (2nd run, 9 solutions found)
LPG (3rd run, 12 solutions found)
LPG (4th run, 4 solutions found)
LPG (5th run, 6 solutions found)
SuperPlanner (1 solutions found)

LPG (1st run, 11 solutions found)
LPG (2nd run, 10 solutions found)
LPG (3rd run, 10 solutions found)
LPG (4th run, 11 solutions found)
LPG (5th run, 11 solutions found)
SuperPlanner (2 solutions found)

250

140

200

120
150

100

80
100
60

40
100

1000

10000

100000

1e+06

10

CPU Time

Quality
100

LPG (1st run, 7 solutions found)
LPG (2nd run, 4 solutions found)
LPG (3rd run, 5 solutions found)
LPG (4th run, 6 solutions found)
LPG (5th run, 5 solutions found)
SuperPlanner (3 solutions found)

36

1000

10000

100000

1e+06

CPU Time

Satellite-Strips-pfile9

Number of steps
38

100

Satellite-Numeric-pfile3
LPG (1st run, 4 solutions found)
LPG (2nd run, 3 solutions found)
LPG (3rd run, 3 solutions found)
LPG (4th run, 4 solutions found)
LPG (5th run, 2 solutions found)
SuperPlanner (3 solutions found)

90
80

34
70
60

32

50
30
40
28
30
26

20
10

100

1000
CPU Time

10000

100000

10

100

1000

CPU Time

; #$7 )    
 6)N	 !	 -  
    !9 -   .
)   
 	 
) .
 .	
&	 &	  8	
              	
       	       
  
 .
)       	 6)N	   .
) 
; #$   	 

   	 !     	 
    
    
   

- & 
   9
 6)N	     
    !9 -    .
)
  	 
 	   ) 	  ))%&$ 
)%/ !9  
  ; #$-  9  !
  6)N	   9     .
) I  
    
          
  
    .
) !   
 
  ; ##
0/

   
     
  


  	     	 	   9 - 2 ;
#$      
 	 
   	 
           .
)  
   6)N	      
  ; #$  
 ))%0  )
%1  .
)  
 
   9 	        
  .
)   6)N	   .
)  
.  	    

  	
 
     	
 
  .
)   &	    	
 	 &   
 	
    (

 : (    
   

 

     .
)       	   
 	

      
   
 	    .
)
& 
 	      
   $ )6  
	   
	
 	 !F	
 11- & 
   
 	   

 B#R      .
)  <<BR & 
   
 	
   
    #,R  
       #$<R
K     	      
 

  
  	      
    .
) 
	 9 4        
 	  .
)

	    )   
  
	  I 
 &	     	  
   
 	    


    H    	   
   
 	
  
  H
+   @  
	    
   .
) 
  	  
 	 	
 (

 6  /  		 &
(   &	
 	   .	
&	 
 	   	 
 	  
.
)   
  
 	   
   
	
  .
)      
 
   &	
   8	  .
 
 	   
   Æ 
 .
) &  	      
	   
	 2          .
) 
 	 
  .
    
I   
 	 	
 
 
	 H  
.
)  BBH$#R   
 	   
	 H 
<#H##'R   
 	
;    
  	    
 	      
 
   $ )6   
	      )6 )	
 B 2@  # 3   K(    	   	    	
     
 I     
   

 	 	 Æ    
 & 
	  	 
     	 
 
 	 
; #,  
 	
  
	     	
 
 
    	
       $   , 
 	
& / 	     ) 	 ! $$  	 	 		 		  	 Æ	
    @A

00

   

Rovers-SimpleTime-HandCoded

Milliseconds
1e+07

LPG-speed (20 solved)
LPG-quality (20 solved)
SHOP2 (20 solved)
TALPlanner (20 solved)
TLPlan (20 solved)

1e+06

Rovers-SimpleTime-HandCoded

Quality
450

LPG-speed (20 solved)
LPG-quality (20 solved)
SHOP2 (20 solved)
TALPlanner (20 solved)
TLPlan (20 solved)

400

350
100000
300

10000

250

200
1000
150
100
100

10

50
0

2

4

6

8

10

12

14

16

18

20

Rovers-Time-HandCoded

Milliseconds
1e+07

2

4

6

8

10

12

14

16

18

20

14

16

18

20

Rovers-Time-HandCoded

Quality

LPG-speed (18 solved)
LPG-quality (18 solved)
SHOP2 (20 solved)
TALPlanner (20 solved)
TLPlan (20 solved)

1e+06

0

LPG-speed (18 solved)
LPG-quality (18 solved)
SHOP2 (20 solved)
TALPlanner (20 solved)
TLPlan (20 solved)

800

700

600
100000
500

400
10000
300
1000

200

100
100
0

2

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

; #,7 )	     	
 	    

	
   $ )6      	   	  
	    	      


	
  	  
      
   
    	
    
 
   )
2-      	        
	 
 

  
	    
 !8 ( 	 0
 + * S	 1$-   2-  
   	 
 
 	     
	    	  
   
    
 9    
	   
01

   
     
  

 !

 
 " #$
+  
 	    
   	   	

	    	 ! 	- 
 
 	  

      > 
	   9 ?   $ 
 ) 6	
   
	  
   


      
	   	
I     	
	        
7           	 	  
      % 4     
      
%    5 	
    
 !3 * . 11 1$-
+   	 	     
  	
  
	 &   
     	  	
  
	    	 
   !   	
  

  24	 !1$--         
   
       >  ? !3 * . #-
  
  
 	9 	    	
	   

   !3 * . 11- & 	  
 	
  	

 	 
 
 ( 
  	
	   
 
       	 Æ    	   
  +        
     
  	 
    	
      

  	 
    &      
 
       

   	 

;    	
 	
 
     	
   	
 
   

      
  
       	
      	

   	        (  ( 
!( #$-  .&) !/  * ) ##-
$
%&

& 
	           

   
  & 
   	
	       
 	
  &   	
 +     
 
5@@  . .
 &   ; @   " 5  .
I   

   	
       (   
N  :  	      
= ;    ;
 / 5       @   $ )6  PU 24	
 	       ! 
  	     
    PU -   / .	   	  
 
 		
02

   


 ' ( 
 
  
  #$
 
	
    	    
 
 
 	    
	   ; #B  ! -      
 4   !      4  ! -     
 "#

    	        "
 
	
       &     	 
    = 

   9  	  !:	 * ; #<-
"#
        	   
   
     
 
 	   (  
   
   !
 B-  
       
 	
 !
 <M##-   
    
 	   
  	 !
 #1M#- & 	 	   
  
   !  J -    
 	    
! J - +  	 	     
 	 
  ( 	    

        
 	      
 	   
   	 
         ( 	    9

    
 
  

3         	  
 	   !#-  
	   
 4        4 !
 <M-  !1-   	
  
 4      !
- 	    

 !
 < #  ##- !#-      
@ 	   
   3  .  !#- !1-           
4    ! -   ! -    	       
 	  

             
( 
 	       	   !#-  
       	  
 4 !
 #$M#,-   ! - 
 4      !  -        ! -  !
- 	
   
  !
 #BM#- & 9       
  
       
 4        
        

    
 	     

  !	     
 4  -
8     
  

  0   !#<- 
 
 	          	 	 
    
  ! -   ! -     	 
  4 
 !    ! -  ! -  	-
&  	      	
 "#
  "
   
  


#$$ 

 !	 

" 	 

*

-



-

*

-

*

*



*



















 

" 	 



#$$ 











*









 































 

 

 

 

   
   
  
 
 

 6  "
         

  9  
 	    6  "	
#
  	       
 	   	
1-

   
     
  

"#
! $ 7 (   ! -    
  ! -%
% 7 (   
 	    ! -
#   %  %
1  %   %   %
$ 
 J  J
,
 %  %
B      ! -    !  ! -  ! -   '
! - ! - %
<
  ! 
  !     	! - ! -
% HO ) 	  OH

#
 ! -      ! -   !     	! - ! -
% HO ) 	  OH
##
#1

  
#$
  ! -   ! -  
   	! - ! -
% HO  	  OH
#,
#B
 !! -%

#'
 ! -    
#<

  ! -  !  ! -  ! -   - 
   	! - ! -
% HO  	  OH
#


#
  ! -%
1
  	 
%
1#  
+

+

*

-

+ -

*

*

-

-

#

-

-

*

*

*

*



" 	 

 	5 

#$$ 





" 	 

 

*

!	 
*

    

 

*

*



*

" 	 



!	 

    

#

 

*



 

 	5 

*



-

-

#$$ 

*

#$$ 
 

*

*

-

#

#

*

 	5 



 2 !	 

-

 

    



*



" 	 

 

*

    

 	5 



*

"
! $ 7 (   	    ! -    
  ! -%
% 7 (   
 	    ! -
#  %       
   %
1  ! - 
$    
  ! 
,
      ! B
  	! - ! -
% HO 6	
  OH
'   
<   ! 
      ! 
  	! - ! -
% HO  OH
#   ! ##
      ! #1
  	! - ! -
% HO  4 OH
#$  
*

*





 

*









" 	 





" 	 

    





" 	 










    

#$$ 





!	 





!	 

    



; #B7  	  	
  	 
1

   

   	     
    	   	 
  

     	   
$  
  J         	   
 
  
	      ! J -   	  	 	
           
$ 	 	

  J  .

   	
  
    
	        

   !  #-
$ 
  J E # (	     	
  
 
     	        

    E #
 !             -   *   
    :   	
   

   !-  
   
 4 
*   !-  !  -   4 
*   !  -  

  *    ! -       *  

 6 !-  
  
 #$M#,  "
 K  !-    	
      !-    ! -    *   

 
	   
  *   	   ! -    
	
 ! - !! --     
  M  	   
	   
 	     !  -     	 
      	 	      	   !  - 
 
 #'M#   	  	     	
   
 
 
&	    	        9 	
		 	   4    
 	  ¾
.	  + 

    > 	? !-   	 
 
   	 !.	 * + #- (   9  	 

 	        	  6
	        .	  +    
4 	             
 	
:  34 !1#- 

  	      	 
    	 	   : 	    
@
   
  	     
  	 	    
    
  4    2   
	 9 4 + :  34 	
      
 	 
   
  "#
 	  
9      
 &     
   
   4 	     "#
   !

   
 #-   	     
 
  

   !    
    
	 
-  :  34     
 
;  

    	     9  > 

?        	 
  
; 
 	     	    
	
 	 
  	
  
    
       
   
   
 ! ' -  	
  	  
1
6



6





6

*

+





*



6







*







































 

















 



*







*

*

*

 

*



*











*

*

*

*

*

-

*

*

   
     
  

   	 !        
  

	
- )
   '   	    	 
		    
 	  ;       
  
  		    
	
  	  
  
  &        
 	   $ )6 
  	 
   	   
 	    
 
     	 ) 26     

  6      	  	
 !
	           	 
  	     	 !3 * .  #-  !
!; * 5 #- ( 	 	   

  ;  5 !1-
;  	  	 
  4    	
   	
   	  ; #B    
9  	   	 	   ;  5 !1$-

1

   


 )'  
  

 
   *
  

 

Depots-Time

Milliseconds
1e+07

1e+06

Depots-Time

Quality

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (11 solved)
SuperPlanner (Quality) (11 solved)

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (11 solved)
SuperPlanner (Quality) (11 solved)

2500

2000
100000

1500
10000

1000

1000

500

100

0

10
0

5

10

15

20

DriverLog-Time

Milliseconds
1e+06

0

25

5

10

25

LPG-speed (18 solved)
LPG-quality (18 solved)
SuperPlanner (Speed) (16 solved)
SuperPlanner (Quality) (16 solved)

2500

100000

20

DriverLog-Time

Quality
3000

LPG-speed (18 solved)
LPG-quality (18 solved)
SuperPlanner (Speed) (16 solved)
SuperPlanner (Quality) (16 solved)

15

2000
10000
1500
1000
1000

100

500

10

0
0

2

4

6

8

10

12

14

16

18

20

Rovers-Time

Milliseconds
1e+06

0

2

4

6

8

10

12

14

16

18

20

12

14

16

18

20

Rovers-Time

Quality
1000

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (12 solved)
SuperPlanner (Quality) (12 solved)

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (12 solved)
SuperPlanner (Quality) (12 solved)

100000

800

10000

600

1000

400

100

200

0

10
0

2

4

6

8

10

12

14

16

18

0

20

1,

2

4

6

8

10

   
     
  

ZenoTravel-Time

Milliseconds
1e+07

LPG-speed (19 solved)
LPG-quality (19 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

1e+06

ZenoTravel-Time

Quality
1800

LPG-speed (19 solved)
LPG-quality (19 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

1600
1400

100000

1200
1000

10000
800
1000

600
400

100
200
10

0
0

2

4

6

8

10

12

14

16

18

20

Satellite-Time

Milliseconds
1e+07

2

4

6

8

10

12

14

16

18

20

12

14

16

18

20

Satellite-Time

Quality
700

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

1e+06

0

LPG-speed (20 solved)
LPG-quality (20 solved)
SuperPlanner (Speed) (20 solved)
SuperPlanner (Quality) (20 solved)

600

500
100000
400
10000
300
1000
200
100

100

10

0
0

2

4

6

8

10

12

14

16

18

20

0

1.

2

4

6

8

10

   


 !' !
  + 
  


&      
	  
   .
)   
   	       &  	  	

 	 7 	   
 	  !1  $ 	-% 	   
 	  

  H   .
) !,H' 	-% 	   
 	
  
  	 H   .
) !BH< 	- (
	   	        6)N	   
9       	     +  
  
   9     6)N	   9
+
$
/
,+-

+
$ /
	 !1
+

,+		 	
	 !1
+

,+- 
		 	
	 !1
+

,+0 	
	 !1
+

,+- 
0 	
	 !1
+


	






 2
 2
 2
 2
 &2
2

 2
& (&2
 2
 2
 2
&#2

' (#2
( &2
% 2
' 2
 2
#&2

 2
& &2
 2
 &2
 2
&#2

' (#(2
 '2
% (2
% (2
 2
(%#&2

& #(2
 &2
 &2
 2
 '2
#&2


	






 &#&2
) 2
 2
 2
 &2
'2

 &2
' )2
 &2
 &2
' )2
(#'2

) )#)2
& (&2
( )&2
) 2
) 2
)#%2

% '#'2
' 2
 '2
 '2
 %&2
&#2

 #'2
 &2
 &2
 &2
 &2
)#)2

 2
 2
 &2
 &2
 2
#2


	






 #2
) 2
 2
 2
 &2
&#2

 &2
' )2
 '2
 2
 2
((#&2

% '#'2
( )&2
) 2
 &2
& (&2
)#%2

 &%#&2
' 2
 '&2
 '2
 2
%#2

' (#2
 2
 2
 &2
& &2
#(2

 #2
 2
 &2
 2
 &2
#2


	






 &#&2
) 2
( )&2
 '2
 2
)#'2

 #2
' )2
 %&2
% (2
 2
((#%2

) '#%2
( &2
 &2
 2
 2
'#%2

 #2
 &2
) %2
 2
 2
%#(2

 &%#&2
 &2
( &2
% (2
 2
'#)2

 #2
 &2
 &2
& &2
& &2
(#'2



 2

( )&2

 &2

% (2

 &2

 &2

	



 2
%#'2

' )2
)#2

 '2
&&#)2

& &2
#2

) %2
)#2

 2
#'2

.




	








	

1/

   
     
  


 ,' !
  +-. 
  


&      
	     .
)  
   	       &  	 
	
  	 7 	   
 	  !1  $ 	-% 	  

 	        	
    H  
 	
   .
) !,H' 	-% 	   
 	  
     	 H      .
)
!BH< 	-
(     	   	   

   	 
 	      	       
               !   	
    
 
 	- &    
  	  

 	    
 	 
9 
   .
 
 	 

   9   	      
 	    
   	 
    
 












+
$
/
,+-

+
$ /
	 !1
+

,+		 	
	 !1
+

,+- 
		 	
	 !1
+

,+0 	
	 !1
+

,+- 
0 	
	 !1
+


	






 2
 2
 2
 2
 &2
2

 2
& (&2
 2
 2
 2
&#2

 &%#&2
% (2
 %&2
 '&2
 &2
&2

 2
& &2
 2
 2
 2
%#2

% )#2
 2
 &2
 2
 %&2
#(2

 2
 2
 2
 2
 &2
#2


	






 &#&2
) 2
 2
 2
 &2
'2

 &2
' )2
 &2
 &2
' )2
(#'2

 )'#%2
( )&2
 2
 2
( )&2
#2

 &2
 &2
 &2
( &2
 &2
#2

 %#&2
 &2
 2
 2
 2
#2

 2
 2
 2
 2
 2
2


	






 #2
) 2
 2
 2
 &2
&#2

 &2
' )2
 '2
 2
 2
((#%2

( ((#2
( )&2
) 2
 2
 &&2
)#%2

 %#2
% 2
) %2
& &2
 2
&#&2

 #2
 &2
 2
 2
 %&2
#(2

 2
 2
 2
 2
 &2
#2


	






 &#&2
) 2
( )&2
 '2
 2
)'#2

 #2
' )2
 %&2
% (2
 2
((#%2

 %&#&2
& (&2
) %2
 '2
 %&2
&#2

 %#&2
 2
) %2
( &2
 &2
)#'2

) '#%2
 2
 2
% 2
' 2
(#'2

 %#&2
 2
 2
% 2
 &2
(#)2



 2

( )&2

 &2

 %&2

 &2

 2

	



 2
%#'2

' )2
)#2

) 2
(2

& &2
#2

 &2
#'2

 2
#(2

.





	








	

10

   



( P !#$-     	
  )   	
)- ./0 $1M,$
( P !##- &	
   
  ( 
  + 
 

 #M'
 0	 .  6(
:	 ( * ;  !#<- ; 
  
 
   
$ 12 1#M$
: : * 34 2 !1#- )      $ 0.1 !#
1- BM$$
/ K   * ) P !##- &	
     $
 31 '#MB
/	
 S * 3 ( !11- &	
 
  	  
	
	7  
	 
  +
  	 4		 $   ) 
+
  +   )
  +  )+2.
/  * 0	 	
 . !1#- .
7 ( 	
  	 	


  +
  	 *	 4  )  +  4)+20
& .
 .
 "
/  * 0	 	
 . !11- ) 
     	

 
  *	 $   )    $ + 
 *	 $+*2. 5
	  +   "  + 
F	
 . !11-  

  	 
   	 
 
 	  "	 $   )    $
+   *	 $+*2. 5
	  +   "  6 

;  * 5 / !#- & 	      &  7 
   $ (
 	 7$( 1 $'<M,1#
;  * 5 / !# - FÆ 	
	   ) 3
  .&(8 7 
   $ (
 	 7$( 02 <M##B
;  * 5 / !1- N@ 	    
 
    +
  	 8	 $   )   
$ +   *	 $+*22 

 #1M### ((( )
;  * 5 / !1$- )//51#7    )//5  
 	


 	 7     $ (
 	 7$(  
3 ( . ( * .  !1$- I 	 	
 	  
    5)3  +
  	 4	 )

  	 $  


     $ .
 !586.H58(- ;	
11

   
     
  

3 ( * .  5 !#'- ( )I )7 .	 &
 F4 . 6  ) 7     $ (
 	
7$( 8 BM#$<
3 ( * .  5 !#-     	


  +
  	 08	 '   )  	   

 
   $ $19 

 BM#1 ((( )H& & 

3 ( * .  !#- ; 
    
  +

 	 0/	 '   )  	   

     $
$11 

 B$MB# ((( )H & )
3 ( * .  !1- ; 
 
  
 
7 5
 	    +
  	 8	 $   )
   $ +   *	 $+*22 

 ##1M#1# (((
)H & )
3 ( * .  !11- 5)37 ( 
      
 

    +
  	 /	 $   )    $
 +   *	 $+*2. 

 1#M1 ((( )H & )
3 ( * .  !1$- )  

 6.)7 	 +  
   
 )%'*"($'"* 9 !,-
3 ( .  . ( * .
 . !1$- 5   
	
 
  5)3  +
  	 0:	 $   ) 
  +  ; *	 $)+*2: 

 '1M<# ((( )H & )
2	 ) * 34 2 !1- (	    
	 
  +

 	 8	 $   )    $ +   *	
$+*22 

 #, M #, ((( )H & )
2	 ) * 34 2 !1#- 2 
  	    +

 	 *	 4  )  +  4)+20 & .
 .

"
24	 P !1$- & ;; 
 	7  >  ? 
	    7     $ (
 	 7$(  
24	 P !1#- ;;7 &  
 	 $ -  < .. !$- B<M'1
24	 P * 8  : !1#- & ;; 
 	7 ; 
  
  7     $ (
 	 7$( 03 1B$M$1
0@ 2 * .	 : !#- N .(&   
  
  +

  	 0/	 $   7 )    $ $7)$11


 $#M$1B
12

   

0@ 2 * .	 : !#'- )  
7 ) 

  
   .  2 * . & !F- +
  	 "		
'   )  	   

     $ $
1/ 

 ##,M#1# ((( )
0 P 8  : 24	 P * /	
 S !#<- F 
 

  (/5   & 
   U 	 ;  3	
5 / * ;  !1$- & $  
 	
7 K 
 7     $ (
 	 7$(  
( / * K  / !##- .	  
  +
 
	 '	 '   )    $ $10 

 '$,M'$
8 / ( & 	 I 0 N  P + / * S	 ; !1$- .2I)17
 2&8 
 	 7     $ (
 	 7$( 

8 V * 0	 	
 . !1#- K 
  
  +

 	 0=	 $   7 )    $ $7)$20 


,BM,''
)  P * + / !#1- N6)I)7 (  	
 
  
 
(/5  +
  	 "	 $   )  +
  >
 (
   ( 
 >(?1. 

 #$M##, : (  0
	
)  P * + / !#,- &	
 
     +

  	 "	 '   )  	   

    
$ $13 

 ##M##B . +(  0	
)  P / * )  !#<- ;    


 7     $ (
 	 7$( / 11$M1'1
.	 : 0@ 2 * 6 : !#,- 8   	
  
 +
  	 "	 '   )  	   

  
  $ $13 

 $$<M$,$ . +(  0	
.	 / * + / !#- &	
 
  	   
+
  	 0/	 7 )    $ $7)$11 


$1'M$$<
& F !#'- )    	
 	  +
  	 =	 4 
)    $ !F6('- 

 ,<M,$
" . ( !#$- )  	7 +       $444
" 
 
  +    

  - 	 $ 8 !$- 1,'M1'<

2-

Journal of Artificial Intelligence Research 20 (2003) 149-154

Submitted 9/03; published 12/03

Commentary
The Case for Durative Actions: A Commentary on PDDL2.1
David E. Smith
NASA Ames Research Center
Computational Sciences Division, Mail Stop: 269-2
Moffett Field, CA 94035, U.S.A.

DESMITH@ARC.NASA.GOV

Abstract
The addition of durative actions to PDDL2.1 sparked some controversy. Fox and Long
argued that actions should be considered as instantaneous, but can start and stop processes.
Ultimately, a limited notion of durative actions was incorporated into the language. I argue
that this notion is still impoverished, and that the underlying philosophical position of
regarding durative actions as being a shorthand for a start action, process, and stop action
ignores the realities of modelling and execution for complex systems.

1. Introduction
PDDL2.1 introduces a limited notion of time into the classical STRIPS planning framework.
In particular, it introduces the notion of durative actions, that is, actions that take time. However, the notion of durative action is rather limited, and somewhat begrudging. This reflects
an underlying philosophical position by Fox and Long that actions are really instantaneous,
but can initiate and terminate continuous processes. According to this view, durative actions
are seen as a shorthand for a start action, process, and stop action. As a result, durative
actions lack some important features, namely the ability to require that (pre)conditions hold
over specified intervals, and that effects can take place at arbitrary time points within the
action. Fox and Long have argued that these features can be captured by breaking up a durative action into a series of smaller actions that only have effects at the beginning and end,
and only have preconditions at the beginning, end, and over the entire action. However, this
representation is exceptionally cumbersome, and ignores the fact that an agent may not have
separate control over these actions. In addition, this representation forces a planner to do
additional work in order to connect the actions.

2. An Example
To illustrate the problems with the PDDL2.1 notion of durative action, consider a simple
example of a spacecraft that must turn in order to point an instrument at a particular target. In
order to turn the spacecraft, thrusters in the reaction control system (RCS) are fired in order
to supply angular velocity. The spacecraft then coasts until it is pointing in the correct direction (or nearly so), when the RCS thrusters again fire in order to stop the rotation. Firing the
thrusters consumes propellant, and requires that the controller be dedicated to the task. In
addition, when the thrusters are firing, there is vibration of the spacecraft, so certain other
operations cannot be performed. While the thruster firings are relatively quick, the coasting
phase is not. In general, turning a large spacecraft is a slow process that may take several
minutes. The reason is that speedy turns require greater acceleration and deceleration, and
therefore consume more propellant.

S MITH

The first question we need to answer is, what is the best way to model this complex operation? We could model the turning operation as an initial action to start the spacecraft turning, and another action to stop the turn, interspersed with “processes” that model what the
craft is doing in between. At some level of detail, this seems to be a reasonable model of the
physics. However, it may very well be that turning and guidance have been built in as primitive operations on the spacecraft, and there is no possibility of starting and stopping turns
independently. We could then model the operation as consisting of an instantaneous action to
start the turn, followed by a finite process that terminates when the turn is complete. But why
bother? The fact is, we are interested in the effects of the process, which can only be initiated
by starting the turn. For these reasons, it seems natural and proper to regard this as a “durative action”, with effects that take place throughout the action.
Now let’s suppose that we want to model this operation as a durative action in PDDL2.1.
We could say something like:
(:durative-action turn
:parameters (?current-target ?new-target - target)
:duration
(= ?duration (/ (angle ?current-target ?new-target)1
(turn-rate)))
:condition
(and (at start (pointing ?current-target))
(at start (>= (propellant) propellant-required))
(at start (not (controller-in-use))))
:effect
(and (at start (not (pointing ?current-target)))
(at start (decrease (propellant) propellant-required))
(at start (controller-in-use))
(at start (vibration))
(at end (not (controller-in-use)))
(at end (not (vibration)))
(at end (pointing ?new-target))))

However, this model of the action is quite conservative. It ties up the controller for the entire
turn operation, and specifies that vibration is present for the entire operation. In addition, it
consumes all the required propellant at the beginning of the operation. In reality, the RCS is
only firing at the beginning and end of the turn. As a result, the controller is only needed during those two periods, vibration is only present during those two periods, and the propellant
is consumed during those two periods. This might not matter if the coast phase were relatively quick. However, as we indicated earlier, turning a large spacecraft can take several
minutes. Unfortunately, PDDL2.1 has a rather limited notion of a durative action – we cannot
specify action conditions or effects at times other than the start or end of the action.

3. Decomposition into Sub-actions
Fox and Long have pointed out2 that it is possible to model a durative action with such intermediate conditions and effects by breaking it up into a sequence of sub-actions. For the turn
action we would need three sub-actions as illustrated below: a start-turn action, a coast
action, and a stop-turn action, together with a turn action to bind them all together.

1. Note that this assumes we have precomputed and provided the angles between all possible pairs of targets. If
we do not want to do this, we must provide the (vector) direction for each target and the planner would need the
ability to do vector arithmetic or trigonometry within formulas.
2. Personal communication.

150

T HE C ASE

FOR

D URATIVE A CTIONS : A C OMMENTARY ON PDDL2.1

(:durative-action turn
:parameters (?current-target ?new-target - target)
:duration
(= ?duration (/ (angle ?current-target ?new-target)
(turn-rate)))
:condition
(and (at start (pointing ?current-target))
(at start (>= (propellant) propellant-required))
(at end (finished)))
:effect
(and (at start (not (pointing ?current-target)))
(at start (turning))
(at start (enabled-start-turn))
(at end (not (turning)))
(at end (not (finished-turning)))
(at end (pointing ?new-target))))
(:durative-action start-turn
:parameters ()
:duration
(= ?duration (start-turn-duration))
:condition
(and (at start (not (controller-in-use)))
(at start (>= (propellant) (/ propellant-required 2)))
(over all (turning))
(over all (enabled-start-turn)))
:effect
(and (at start (decrease (propellant) (/ propellant-required 2)))
(at start (controller-in-use))
(at start (vibration))
(at end (not (controller-in-use)))
(at end (not (vibration)))
(at end (not (enabled-start-turn)))
(at end (enabled-coast))))
(:durative-action coast
:parameters ()
:duration
(= ?duration (coast-duration))
:condition
(and (over all (turning))
(over all (enabled-coast)))
:effect
(and (at end (not (enabled-coast)))
(at end (enabled-stop-turn))))
(:durative-action stop-turn
:parameters ()
:duration
(= ?duration (RCS-duration))
:condition
(and (at start (not (controller-in-use)))
(at start (>= (propellant) (/ propellant-required 2)))
(over all (turning))
(over all (enabled-stop-turn)))
:effect
(and (at start (decrease (propellant) (/ propellant-required 2)))
(at start (controller-in-use))
(at start (vibration))
(at end (not (controller-in-use)))
(at end (not (vibration)))
(at end (not (enabled-stop-turn)))
(at start (finished))))

Figure 1 shows graphically how these actions are tied together. If the goal is to be pointing at
a particular target, a turn action will be required. The turn action has an end precondition of
(finished), which can only be satisfied by adding a stop-turn action3. Stop-turn has an “over
151

S MITH

all” condition (enabled-stop-turn) that can only be satisfied by the end effect of a coast action.
Likewise, the coast action has an “over all” condition (enabled-coast) that can only be satisfied by an end effect of a start-turn action. The start-turn action has an “over all” condition
(enabled-start-turn) that can only be satisfied by a start effect of the turn action. As a result, the
turn action forces all three sub-actions into the plan, and each sub-action forces its predecessor sub-actions and a turn action into the plan. All three of these sub-actions have an “over
all” condition (turning) that is only satisfied during a turn action. As a result, the only way that
all of this can be consistently achieved is if all three sub-actions are packed sequentially into
the turn action.
¬ pointing(?current)
turning
enabled-start-turn

pointing(?target)
¬ turning
¬ finished

turn

pointing(?current)

finished

¬ enabled-start-turn
enabled-coast

start-turn
turning
enabled-start-turn

coast
turning
enabled-coast

¬ enabled-coast
enabled-stop-turn

finished

¬ enabled-stop-turn

stop-turn
turning
enabled-stop-turn

Figure 1: Sub-actions for the Turn operation. Start, end, and over-all conditions are
shown below each action. The interconnecting start and end effects are shown above
each action. For simplicity, I have omitted the effects concerning vibration, controller
use, and propellant usage
There are two additional subtleties in this representation. The first is that, although each
of the three sub-actions can only occur during a turn action, there is no obvious requirement
that they occur during the same turn action. Suppose that we tried to place the start-turn
action during a previous turn action. That previous turn action would have its own three subactions, and our wayward start-turn action would conflict with those sub-actions. Thus, in
order to make this work, we would have to push those three sub-actions to an earlier turn
action, and so on. Realizing that this cannot work requires a difficult induction argument. It
seems unlikely that any existing planner could actually infer this, other than by trial and
error. As a result, the process of generating plans involving such actions would incur a significant computational overhead, and engage in needless search.
A second subtlety that we have overlooked in this decomposition is that computing the
durations of the sub-actions is a bit tricky. While it is reasonable to assume that the start and
stop turn actions have fixed duration, the duration of the coast action depends on the current
3. It turns out that the (finished) effect of stop-turn must be a start effect rather than an end effect. The reason is
that if it were to occur as an end effect, the stop-turn action would need to complete prior to the end of the turn
action, since the (finished) effect is mutex with the (not finished) end effect of the turn action. Despite this
asymmetry in the representation, stop turn is still forced to occur wholly within the turn action because of the
overall condition (turning).

152

T HE C ASE

FOR

D URATIVE A CTIONS : A C OMMENTARY ON PDDL2.1

and target orientations of the spacecraft. In fact, the duration of the coast action must be the
duration of the turn action minus the durations of the start and stop turn actions. The only
way to do this is to introduce an additional numeric “turn-duration” function that is set by
the turn action, and used to compute the duration of the coast action.
So why is this process of decomposing an action into sub-actions so complex and convoluted? After all, in the HTN planning paradigm this is done all the time. The reason is that in
generative planning we have adopted the view, for better or worse, that one is not allowed to
directly specify how an action is to be used or how actions are connected with each other. As
a result, in order to force the sub-actions to abut and fit within the turn action, we must do
some tricky things. One might argue that we need this HTN capability in order to model such
actions. Indeed, it would certainly make things easier. However, there is another way.

4. Richer Durative Actions
One approach to dealing with the above modelling problem is to admit a richer language for
modelling durative actions. To make it convenient to model actions like the turn action, we
need to be able to specify conditions that must hold at various points and intervals within the
action, and effects that take place at various points and intervals within the action. There are
many possible ways in which one could express such conditions and effects, but here is one
straw-man possibility:
(:durative-action turn
:parameters (?current-target ?new-target - target)
:duration
(= ?duration (/ (angle ?current-target ?new-target) (turn-rate)))
:condition
(and (at start (pointing ?current-target))
(at start (>= (propellant) propellant-required))
(at start (not (controller-in-use)))
(at (- end RCS-duration) (>= (propellant) (/ propellant-required 2)))
(at (- end RCS-duration) (not (controller-in-use))))
:effect
(and (at start (not (pointing ?current-target)))
(at start (decrease (propellant) (/ propellant-required 2)))
(over [start (+ start RCS-duration)] (controller-in-use))
(over [start (+ start RCS-duration)] (vibration))
(at (- end RCS-duration) (decrease (propellant) (/ propellant-required 2)))
(over [(- end RCS-duration) end] (controller-in-use))
(over [(- end RCS-duration) end] (vibration))
(at end (pointing ?new-target))))

Here we did not need to explicitly construct actions for starting and stopping the turn, or
coasting. For this reason, we did not need to worry about their durations or about connecting
these sub-actions. Instead, we simply specified the effects at the appropriate times during the
turn action. Note that I specified vibration and controller use as interval effects. This seems
less cumbersome than specifying two separate effects stating that the controller is in use at
the beginning of an interval, and no longer in use at the end. However, there is also a more
fundamental difference between the two encodings: in the encoding above, there is no possibility that another independent action could somehow make the controller available during
the interval in which it is in use. Bedrax-Weiss et. al. (2003) have argued for the introduction
of an explicit notion of resource into the PDDL language. If we had such a notion we could
simplify the above encoding even further, by specifying that the controller is a reusable
resource that is required by the turn action over the appropriate intervals. Vibration (or stability) could also be treated as a resource, although it is somewhat less intuitive to do so.
153

S MITH

One final issue that we have avoided is the notion of continuous change. In our spacecraft
example, there is certainly continuous change going on. Propellant is not burned instantaneously, and the orientation of the spacecraft changes continuously. The question is, do we
need to model this? Certainly there are domains where it is necessary to reason about continuous change. As Fox and Long point out, when there are concurrent actions as well as simultaneous consumption and production of resources, it may be necessary to reason about how
these resources change over the course of the actions. For example, a Mars rover receives
energy from the solar panels at the same time it is driving from place to place. Since the battery has both a minimum and maximum capacity, one cannot model this easily using discrete
consumption and production effects. However, if consumption and production do not happen
simultaneously, one can model continuous change as taking place at the start or end of an
action. This is sufficient for our spacecraft example since there are no actions that increase
propellant, and one cannot perform two simultaneous actions that both affect the spacecraft’s
orientation.

5. Conclusion
Durative actions in PDDL2.1 are limited, and expressing complex durative actions by
decomposition into sub-actions is difficult and clumsy. At the same time, it is not clear that
modelling actions like turning a spacecraft in terms of processes is either necessary or useful, particularly when there is no possibility that the process can be deliberately interrupted.
For domains like this, a richer, more expressive notion of durative action seems like the right
modelling tool. Note that I would not argue that the modelling of processes is completely
unnecessary. However, for many practical planning applications it is overkill. It results in a
more complex representation and planning process than is necessary.
Is it cheating to model complex processes as durative actions? Of course it is. All modelling is cheating. In the real world of physics, nothing is instantaneous or indivisible, so it is
cheating to model anything as an instantaneous action. Yet, we are usually content to model
an action like turning on a light switch as instantaneous and indivisible, even though it does
take a small amount of time, and there are complex processes behind it. A durative action is
no different – we are simply choosing not to model the details of the process structure behind
the action, even though it may be necessary to model the fact that the action takes time, and
that the effects take place at different times during the action. For many practical applications, durative actions are an essential modelling tool, and they deserve a richer treatment
than that provided in PDDL2.1.

References
Bedrax-Weiss, T., McGann, C. & Ramakrishnan, S. (2003) Formalizing resources for planning. In Proceedings of the ICAPS-03 Workshop on PDDL.
Fox, M. & Long, D. (2002) PDDL+: Modeling continuous time dependent effects. In Proceedings of the 3rd International NASA Workshop on Planning and Scheduling for Space.
Fox, M. & Long, D. (2003) PDDL2.1: An extension to PDDL for expressing temporal planning domains. Journal of Artificial Intelligence Research, this issue.

154

Journal of Artificial Intelligence Research 20 (2003) 379-404

Submitted 10/02; published 12/03

SHOP2: An HTN Planning System
Dana Nau

nau@cs.umd.edu

Dept. of Computer Science, and Institute for Systems Research
University of Maryland, College Park, MD 20742 USA

Tsz-Chiu Au

chiu@cs.umd.edu

Dept. of Computer Science
University of Maryland, College Park, MD 20742 USA

Okhtay Ilghami

okhtay@cs.umd.edu

Dept. of Computer Science
University of Maryland, College Park, MD 20742 USA

Ugur Kuter

ukuter@cs.umd.edu

Dept. of Computer Science
University of Maryland, College Park, MD 20742 USA

J. William Murdock

murdockj@us.ibm.com

IBM Watson Research Center
19 Skyline Dr.
Hawthorne, NY 10532 USA

Dan Wu

dandan@cs.umd.edu

Dept. of Computer Science
University of Maryland, College Park, MD 20742 USA

Fusun Yaman

fusun@cs.umd.edu

Dept. of Computer Science
University of Maryland, College Park, MD 20742 USA

Abstract
The SHOP2 planning system received one of the awards for distinguished performance
in the 2002 International Planning Competition. This paper describes the features of
SHOP2 which enabled it to excel in the competition, especially those aspects of SHOP2
that deal with temporal and metric planning domains.

1. Introduction
SHOP2, Simple Hierarchical Ordered Planner 2 (Nau, Muñoz-Avila, Cao, Lotem, & Mitchell,
2001), is a domain-independent planning system based on Hierarchical Task Network (HTN)
planning. In the 2002 International Planning Competition, SHOP2 received one of the top
four awards, one of the two awards for distinguished performance. This paper describes
some of the characteristics of SHOP2 that enabled it to excel in the competition.
Like its predecessor SHOP (Nau, Cao, & Muñoz-Avila, 1999), SHOP2 generates the
steps of each plan in the same order that those steps will later be executed, so it knows
the current state at each step of the planning process. This reduces the complexity of
reasoning by eliminating a great deal of uncertainty about the world, thereby making it
easy to incorporate substantial expressive power into the planning system. Like SHOP,
c
2003
AI Access Foundation. All rights reserved.

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

SHOP2 can do axiomatic inference, mixed symbolic/numeric computations, and calls to
external programs.
SHOP2 also has capabilities that go significantly beyond those of SHOP:
• SHOP2 allows tasks and subtasks to be partially ordered; thus plans may interleave
subtasks from different tasks. This often makes it possible to specify domain knowledge in a more intuitive manner than was possible in SHOP.
• SHOP2 incorporates many features from PDDL, such as quantifiers and conditional
effects.
• If there are alternative ways to satisfy a method’s precondition, SHOP2 can sort the
alternatives according to a criterion specified in the definition of the method. This
gives a convenient way for the author of a planning domain to tell SHOP2 which parts
of the search space to explore first. In principle, such a technique could be used with
any planner that plans forward from the initial state.
• So that SHOP2 can handle temporal planning domains, we have a way to translate
temporal PDDL operators into SHOP2 operators that maintain bookkeeping information for multiple timelines within the current state. In principle, this technique
could be used with any non-temporal planner that has sufficient expressive power.
The rest of this paper is organized as follows. Section 2 gives some background on HTN
planning, and Section 3 describes SHOP2’s features and planning algorithm. Section 4
describes how to write domain descriptions for SHOP2: in particular, Section 4.1 discusses
basic problem-solving strategies, and Sections 4.2 and 4.3 describe aspects of SHOP2 that
are specific to handling temporal and metric domain features. Section 5 discusses SHOP2’s
performance in the competition, Section 6 discusses related work, and Section 7 gives a
summary and conclusion. Appendix A contains a SHOP2 domain description for one of the
problem domains in the planning competition.

2. HTN Planning
HTN planning is like classical AI planning in that each state of the world is represented by
a set of atoms, and each action corresponds to a deterministic state transition. However,
HTN planners differ from classical AI planners in what they plan for, and how they plan
for it.
The objective of an HTN planner is to produce a sequence of actions that perform some
activity or task. The description of a planning domain includes a set of operators similar
to those of classical planning, and also a set of methods, each of which is a prescription for
how to decompose a task into subtasks (smaller tasks). Figure 1 gives a simple example.
Given a planning domain, the description of a planning problem will contain an initial state
like that of classical planning—but instead of a goal formula, the problem specification will
contain a partially ordered set of tasks to accomplish.
Planning proceeds by using the methods to decompose tasks recursively into smaller
and smaller subtasks, until the planner reaches primitive tasks that can be performed directly using the planning operators. For each nonprimitive task, the planner chooses an
380

SHOP2: An HTN Planning System

task:
preconditions:

task:

(transport ?p)

(at ?p ?x)
(destination p ?y)
(available-truck ?t)

(transport-two ?p ?q)

preconditions:

subtasks:

(package ?p)
(package ?q)

subtasks:

(dispatch ?t ?x) (load ?t ?p) (move ?t ?x ?y) (return ?t ?x)

task:

(transport ?p) (transport ?q)

task:

(dispatch ?t ?x)

subtasks: (reserve ?t) (move ?t home ?x)

(return ?t ?x)

subtasks: (move ?t ?x home)

(free ?t)

Figure 1: Methods for transporting a package ?p, transporting two packages ?p and ?q,
dispatching a truck ?t, and returning the truck. Arrows are ordering constraints.
The shaded subtasks are primitive tasks that are accomplished by the following
planning operators: (load ?t ?p) loads ?p onto ?t; (move ?t ?x ?y) moves ?t from
?x to ?y; (reserve ?t) deletes (available-truck ?t) to signal that the truck is in use;
(free ?t) adds (available-truck ?t) to signal that the truck is no longer in use.

(transport-two p1 p2)
(package p1)
(package p2)

(transport p1)

(transport p1)
(at p1 l1)
(destination p1 l3)
(available-truck t1)

(dispatch t1 l1)

(dispatch t2 l2)

(load t1 p1)
(reserve t1)

(at p2 l2)
(destination p2 l4)
(available-truck t2)

(return t1 l1)
(load t2,p2)

(move t1 l1 l3)

(reserve t2)

(move t1 home l1)

(move t2 home l2)

(return t2 l2)

(move t2 l2 l4)
(free t1)

(move t1 l3 home)

(free t2)
(move t2 l4 home)

Figure 2: A plan for accomplishing (transport-two p1 p2) from the following initial state:
{(package p1), (at p1 l1), (destination p1 l3), (available-truck t1), (at t1 home),
(package p2), (at p2 l2), (destination p2 l4), (available-truck t2), (at t2 home)}.
381

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

applicable method, instantiates it to decompose the task into subtasks, and then chooses
and instantiates methods to decompose the subtasks even further, as illustrated in Figure 2.
If the plan later turns out to be infeasible, the planning system will need to backtrack and
try other methods.
HTN methods generally describe the “standard operating procedures” that one would
normally use to perform tasks in some domain (e.g., see Figure 1) Most HTN practitioners
would argue that such representations are more appropriate for many real-world domains
than are classical planning operators, as they better characterize the way that users think
about problems.
Like most other HTN planners, SHOP2 is “hand-tailorable:” its planning engine is
domain-independent, but the HTN methods may be domain-specific, and the planner can
be customized to work in different problem domains by giving it different sets of HTN
methods. The ability to use domain-specific problem-solving knowledge can dramatically
improve a planner’s performance, and sometimes make the difference between solving a
problem in exponential time and solving it in polynomial time (e.g., Gupta & Nau, 1992;
Slaney & Thiébaux, 2001). In experimental studies (e.g., Nau et al., 1999, 2001; Bacchus
& Kabanza, 2000), hand-tailorable planners have quickly solved planning problems orders
of magnitude more complicated than those typically solved by “fully automated” planning
systems in which the domain-specific knowledge consists only of the planning operators.

3. Features of SHOP2
This section describes SHOP2’s planning algorithm and some of SHOP2’s distinctive features.
3.1 Basic Elements of a Domain Description
A domain description is a description of a planning domain, consisting of a set of methods,
operators, and axioms. Below we describe each of these briefly; additional details appear
in Section 4.
3.1.1 Tasks
A task represents an activity to perform. Syntactically, a task consists of a task symbol
followed by a list of arguments. A task may be either primitive or compound. A primitive
task is one that is supposed to be accomplished by a planning operator: the task symbol
is the name of the planning operator to use, and the task’s arguments are the parameters
for the operator. A compound task is one that needs to be decomposed into smaller tasks
using a method; any method whose head unifies with the task symbol and its arguments
may potentially be applicable for decomposing the task. The details are discussed in the
following subsections.
3.1.2 Operators
Each operator indicates how a primitive task can be performed. The operators are very
similar to PDDL operators: each operator o has a head head(o) consisting of the operator’s
name and a list of parameters, a precondition expression pre(o) indicating what should be
382

SHOP2: An HTN Planning System

(:method
; head
(transport-person ?p ?c2)
; precondition
(and
(at ?p ?c1)
(aircraft ?a)
(at ?a ?c3)
(different ?c1 ?c3))
; subtasks
(:ordered
(move-aircraft ?a ?c1)
(board ?p ?a ?c1)
(move-aircraft ?a ?c2)
(debark ?p ?a ?c2)))
Figure 3: A SHOP2 method for a simplified version of the ZenoTravel domain.
true in the current state in order for the operator to be applicable, and a delete list del(o)
and add list add(o) giving the operator’s negative and positive effects. Like in PDDL, the
preconditions and effects may include logical connectives and quantifiers. The operators
also can do numeric computations and assignments to local variables (an example appears
later in Figure 11). Just as in PDDL, no two operators can have the same name; thus for
each primitive task, all applicable actions are instances of the same operator.
Each operator also has an optional cost expression (the default value is 1). This expression can be arbitrarily complicated and can use any of the variables that appear in the
operator’s head and precondition. The cost of a plan is the sum of the costs of the operator
instances.
3.1.3 Methods
Each method indicates how to decompose a compound task into a partially ordered set of
subtasks, each of which can be compound or primitive. The simplest version of a method
has three parts: the task for which the method is to be used, the precondition that the
current state must satisfy in order for the method to be applicable, and the subtasks that
need to be accomplished in order to accomplish that task.
As an example, Figure 3 is a simplified version of a SHOP2 method for one of the
domains in the AIPS-2002 Planning Competition, the ZenoTravel domain. This method
gives a way to transport a person ?p by aircraft from one location ?c1 to another location
?c2 if the aircraft is not already at ?c1.1 The :ordered keyword specifies that the subtasks
are totally ordered: first move the aircraft to ?c1, then board the person, then move the
aircraft to ?c2, then debark the person.2 To specify an unordered set of subtasks, we would
1. Any symbol that begins with a question mark is a variable name.
2. The method in the figure would have the same meaning if :ordered were omitted. If the list of subtasks
does not begin with :ordered or :unordered, SHOP2 assumes :ordered.

383

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

(:; head
(enough-fuel ?plane ?current-position ?destination ?speed)
; tail
(and (distance ?current-position ?destination ?dist)
(fuel ?plane ?fuel-level)
(fuel-burn ?speed ?rate)
(eval (>= ?fuel-level (* ?rate ?dist)))))
Figure 4: A SHOP2 axiom for a simplified version of the ZenoTravel domain.
use the keyword :unordered rather than :ordered; more complicated partial orderings can be
specified using nested combinations of :ordered and :unordered.3
More generally, a method m may have the form
(:method head(m) p1 t1 p2 t2 . . .),
where head(m) is a task called the head of m, each pi is a precondition expression and each
ti is a partially ordered set of subtasks. The meaning of this is analogous to an if-then-else:
it tells SHOP2 that if p1 is satisfied then t1 should be used, otherwise if p2 is satisfied then
t2 should be used, and so forth. To keep the descriptions in this paper simple, we will
assume without loss of generality that there is only one precondition expression pre(m) and
one set of subtasks sub(m).
In general, there may be several alternative ways of accomplishing head(m). There may
be more than one method whose head is head(m), more than one set of variable bindings
that satisfy pre(m), more than one ordering consistent with sub(m), or more than one
possible way to accomplish some of the subtasks in sub(m). These alternatives produce
branches in SHOP2’s search space.
3.1.4 Axioms
The precondition of each method or operator may include conjunctions, disjunctions, negations, universal and existential quantifiers, implications, numerical computations, and external function calls. Furthermore, axioms can be used to infer preconditions that are not
explicitly asserted in the current state. The axioms are generalized versions of Horn clauses,
written in a Lisp-like syntax: for example, (:- head tail) says that head is true if tail is true.
The tail of the clause may contain anything that may appear in the precondition of an
operator or method.
As an example, the axiom shown in Figure 4 says that a plane has enough fuel to reach
?destination if the following conditions are satisfied: the distance to travel is ?dist, the fuel
level is ?fuel-level, the burn rate is ?rate, and ?fuel-level is not less than the product of ?rate
and ?distance. The last of these conditions is handled using an external function call, as
described below.
3. This notation does not allow every possible possible partial ordering, but that has not been a problem
in practice; and this notation is less clumsy than those that allow every possible partial ordering.

384

SHOP2: An HTN Planning System

procedure SHOP2(s, T, D)
P = the empty plan
T0 ← {t ∈ T : no other task in T is constrained to precede t}
loop
if T = ∅ then return P
nondeterministically choose any t ∈ T0
if t is a primitive task then
A ← {(a, θ) : a is a ground instance of an operator in D, θ is a substitution that unifies {head(a), t}, and s satisfies a’s preconditions}
if A = ∅ then return failure
nondeterministically choose a pair (a, θ) ∈ A
modify s by deleting del(a) and adding add(a)
append a to P
modify T by removing t and applying θ
T0 ← {t ∈ T : no task in T is constrained to precede t}
else
M ← {(m, θ) : m is an instance of a method in D, θ unifies {head(m), t},
pre(m) is true in s, and m and θ are as general as possible}
if M = ∅ then return failure
nondeterministically choose a pair (m, θ) ∈ M
modify T by removing t, adding sub(m), constraining each task
in sub(m) to precede the tasks that t preceded, and applying θ
if sub(m) 6= ∅ then
T0 ← {t ∈ sub(m) : no task in T is constrained to precede t}
else T0 ← {t ∈ T : no task in T is constrained to precede t}
repeat
end SHOP2
Figure 5: A simplified version of the SHOP2 planning procedure.

If the tail of a clause (or the precondition of an operator or method) contains a negation,
it is handled in the same way as in Prolog: the theorem prover takes (not a) to be true if
it cannot prove a.

3.1.5 External Function Calls
External function calls are useful, for example, to do numeric evaluations (e.g., in the
ZenoTravel domain, to check the requirement that the available fuel must be greater than
or equal to the product of the burn rate and the distance to be traveled). For example, in
the competition, SHOP2 used a graph-algorithm library to compute the shortest paths in
a graph. In principle, it would be possible to implement the graph algorithms as a set of
methods. However, writing them as external functions allows them to run faster, and also
makes it possible to access predefined code libraries.
385

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

3.2 The SHOP2 Algorithm
Figure 5 shows a simplified version of the SHOP2 planning procedure. The arguments
include the initial state s, a partially ordered set of tasks T , and a domain description D.
As we mentioned earlier, SHOP2 plans for tasks in the same order that they will be
executed. In order to do this, it nondeterministically chooses a task t ∈ T that has no
predecessors; t is the first task that SHOP2 will start working on. At this point, there are
two cases.
The first case is if t is primitive, i.e., if t can be accomplished directly using an action
(i.e., an instance of a planning operator). In this case, SHOP2 finds an action a that
matches t and whose preconditions are satisfied in s, and applies a to s (if no such action
exists, then this branch of the search space fails).
The second case is where t is compound, i.e., a method needs to be applied to t to
decompose it into subtasks. In this case, SHOP2 nondeterministically chooses a method
instance m that will decompose t into subtasks (if no such method instance exists, then this
branch of the search space fails).
If there is a solution plan that involves m, then the actions in P will be the leaf nodes
of a decomposition tree DP such as the tree shown in Figure 2. The precondition formula
pre(m) must be true in the state that immediately precedes the first action a in DP that is
a descendant of m. In order to ensure that pre(m) is true in the correct state, SHOP2 needs
to generate the leftmost branch of D all the way down to the bottom, and evaluate pre(m)
in the state just before a. The last three lines of the loop ensure that this will happen, by
telling SHOP2 that if the current method m has any subtasks, SHOP2 should generate one
of those subtasks before generating any other subtasks in the task network.
For example, SHOP2 could begin generating the plan in Figure 2 by first decomposing
(transport-two p1 p2) into (transport p1) and (transport p2), and then nondeterministically
choosing to decompose (transport p1) into {(dispatch t1 l1), (pickup t1 p1), (move t1 l1
l3)}. Having done that, SHOP2 would be required to decompose (dispatch t1 l11) before
decomposing (transport p2), in order to guarantee that (dispatch t1 l1) and (reserve t1)
occur in the same state of the world in which (available t1) was evaluated. The operator
for (reserve t1) makes t1 unavailable, thus ensuring that when (transport p2) is decomposed
later, the decomposition will use truck t2 rather than t1.
3.3 Additional Features
SHOP2 has several additional features in addition to the basic ones described earlier. This
section describes the most significant ones.
3.3.1 Sorting the Variable Bindings
When SHOP2 evaluates a method’s precondition, it gets a list of all of the possible sets
of variable bindings that satisfy the expression in the current state. Each set of variable
bindings can lead to a different branch in SHOP2’s search tree. This nondeterministic choice
is implemented in SHOP2 via depth-first backtracking. For SHOP2 to find a good solution
and to find it quickly, it is important to decide which set of variable bindings to try first.
For this purpose, SHOP2 has a “sort-by” construct that sorts the list of variable bindings by a specified criterion. This is especially useful when the planning problem is an
386

SHOP2: An HTN Planning System

(:method
; head
(transport-person ?p ?c2)
; precondition
(:sort-by ?cost #’<
(and (at ?p ?c1)
(aircraft ?a)
(at ?a ?c3)
(different ?c1 ?c3)
(cost-of ?a ?c3 ?c1 ?cost)))
; subtasks
((move-aircraft ?a ?c1)
(board ?p ?a ?c1)
(move-aircraft ?a ?c2)
(debark ?p ?a ?c2)))
Figure 6: Using sort-by in a SHOP2 method for the simplified ZenoTravel domain.
optimization problem, e.g., a problem in which the objective is to find a plan having the
least possible cost. With the sort-by construct, we can write a heuristic function to estimate
the anticipated cost of each set of variable bindings, and sort the sets of variable bindings
according to their heuristic-function values so that SHOP2 will try most promising one first.
For example, if we have the precondition
(and (at ?here) (distance ?here ?there ?d))
then there may be several different combinations of ?here, ?there, and ?d that satisfy this
precondition. The expression
(:sort-by ?d #’> (and (at ?here) (distance ?here ?there ?d)))
will cause SHOP2 to consider the variable bindings in decreasing order of the value of ?d.
As a more complicated example, recall the precondition of the method in Figure 3.
There may be several sets of variable bindings that satisfy this precondition in the current
state. The reformulation of the precondition in Figure 6 tells SHOP2 to sort the sets of
variable bindings in increasing order of the ?cost variable. This way, SHOP2 will look first
at the alternative that has the lowest ?cost value.
3.3.2 Branch-and-Bound Optimization
SHOP2 allows the option of using branch-and-bound optimization to search for a leastcost plan. This option generally results in spending additional planning time in order to
search for plans of superior quality. When using the branch-and-bound option, one can also
specify a time limit for the search. If the search takes longer than the time limit, SHOP2
terminates the search and returns the best plan it has found so far; this functionality was
partly inspired by anytime algorithms (Boddy & Dean, 1989).
387

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

3.3.3 PDDL Operator Translation
SHOP2’s planning procedure can be proved to be sound and complete across a large set of
planning problems, in the sense that if a set of methods and operators is capable of generating a solution for some problem, then the planning procedure is guaranteed to generate
a correct plan (Nau et al., 2001). However, while such a proof tells us that the planning
algorithm should work correctly if the domain description is correct, it does not tell us
whether our domain description represents the same planning domain as a given set of
PDDL planning operators.
In the AIPS-2000 planning competition, that problem caused difficulty for SHOP2’s
predecessor SHOP. The SHOP team was developing domain descriptions for SHOP purely
by hand, and made some mistakes in writing two of the domains. Thus SHOP found
incorrect solutions for some of the problems in those domains, so the judges disqualified
SHOP from those domains.
While developing SHOP2, we wrote a translator program to translate PDDL operators
into SHOP2 domain descriptions. The domain descriptions produced by the translator
program are not sufficient for efficient planning with SHOP2: they need to be modified by
hand in order to put in the domain knowledge, as described in Section 4. However, the
translator program can at least provide a correct starting point.

3.3.4 Debugging Facilities
SHOP2 also includes several debugging facilities. The most important of these is a tracing
mechanism: one can tell SHOP2 to trace any set of operators, methods, and axioms. For
example, in Figure 8, we have given names (namely Case1 and Case2) to the two different
clauses of a method. We can tell SHOP2 to trace either of these clauses or both of them;
SHOP2 will print messages each time it enters and exits a clause that is being traced.
Depending on the particular tracing options that one selects, the messages may include
things such as the argument list, the current state of the world, and information about
whether the operator, method or axiom succeeds or fails.

3.3.5 Protected Conditions and Anti-Interleaving
SHOP2’s planning operators include a way to specify protected conditions. This feature is
described briefly in Nau et al. (2001), but we will not bother to describe it here because
we did not use it during the planning competition. In cases where we wanted to protect
conditions from possible threats, we found it more convenient either to make use of flags
similar to the available-truck flag in Figure 1, or to use the following “anti-interleaving”
feature of SHOP2.
If a method m has subtasks t1 , . . . , tk , and if any ti begins with the keyword :immediate,
this tells SHOP2 that it should plan to do ti immediately after ti−1 finishes, without trying to
interleave other tasks between ti−1 and ti . Several examples of this appear in the appendix.
388

SHOP2: An HTN Planning System

task for each person: transport the person to his/her destination
(these tasks are unordered; thus their subtasks may be interleaved)
task for each plane: transport the plane to its destination
(these tasks are unordered; thus their subtasks may be interleaved)
method for transporting a person:
if the person is already at their desired destination then do nothing
else
select a plane
if the plane is not at the person’s current position then move it there
hold the plane at the current position
board the person onto the plane
move the plane to the destination
debark the person at the destination
method for transporting a plane:
if the plane is already at its desired destination then do nothing
else move the plane to the destination
Figure 7: Abstract tasks and methods for a simplified version of the ZenoTravel domain.

4. Developing Domain Descriptions for SHOP2
4.1 Basics
The first step in developing a domain description for SHOP2 is to formulate some abstract
tasks and methods that constitute a reasonable problem-solving strategy. As an example, we
will use a simplified version of ZenoTravel (one of the domains in the planning competition).
The problem is to transport people from their current locations to their destination, by the
use of any available airplanes. Figure 7 shows a set of abstract tasks and methods for
transporting people and moving airplanes.
Once we have an abstract strategy like the one in Figure 7, we can implement it as
a SHOP2 domain description consisting of methods, operators and axioms. For example,
the method for transporting a person is shown in Figure 8. There may be more than one
value of ?p that satisfies the precondition (plane ?p). If so, then which plane to use will
be a nondeterministic branching point for SHOP2. At nondeterministic branching points,
the domain description may include some heuristics to guide SHOP2’s search; Section 4.3
discusses some of the ways to write such heuristics.
In the method for the transport-with-plane task, one of the preconditions will be whether
a plane’s fuel level will be enough to get the plane from its current position to its destination.
Figure 4 shows an axiom for this precondition.
Actions, such as boarding people onto planes, debarking them from planes, and refueling
the planes, can be modeled as operators in SHOP2. For example, the SHOP2 operator for
boarding is given in Figure 9.
389

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

(:method
; head
(transport-person ?person ?destination)
Case1 ; a label for use in debugging
; preconditions
(and (at ?person ?current-position)
(same ?current-position ?destination))
; subtasks
()
Case2 ; a label for use in debugging
; preconditions
(and (at ?person ?current-position)
(plane ?p))
; subtasks
((transport-with-plane ?person ?p ?destination)))
Figure 8: A SHOP2 implementation of one of the methods in Figure 7.
(:operator
; head
(board ?person ?plane)
; preconditions
(and (at ?person ?place) (at ?plane ?place))
; delete list
((at ?person ?place))
; add list
((in ?person ?plane)))
Figure 9: A SHOP2 operator for the simplified ZenoTravel domain.

4.2 Writing Temporal Domains
SHOP2’s operators are at least as expressive as Level 2 actions in PDDL, but SHOP2 does
not explicitly support the durative actions in Level 3 of PDDL, nor does SHOP2 have an
explicit mechanism for reasoning about durative and concurrent actions.
However, SHOP2 still has enough expressive power to represent durative and concurrent
actions, because it knows the current state at each step of the planning process and since its
operators can assign values to variables and can do numeric calculations. This has allowed
us to develop a preprocessing technique that we call Multi-Timeline Preprocessing (MTP).
MTP is a technique for translating PDDL operators into SHOP2 operators that keep track
of temporal information in the current state.
The pseudocode in Figure 10 is an algorithmic description of what MTP does. In
principle, MTP could be automated—but in practice, we have always done it by hand,
because it only needs to be done once for each planning domain.
390

SHOP2: An HTN Planning System

for every operator o in the planning domain
add two parameters ?start and ?duration to o
in o’s precondition
add an assignment ?duration ← d
where d is a formula for calculating o’s duration
add an assignment ?start ← s
where s is a formula that takes the maximum of the write times of
all dynamic properties in o’s precondition and the read times of all
dynamic properties in o’s effects
for each dynamic property p in o’s effects
add effects to change the value of write-time(p) to ?start +?duration
for each dynamic property that appears in o
add effects to change read-time(p) to the maximum
of read-time(p) and ?start +?duration
Figure 10: Multi-timeline preprocessing (MTP).
To keep the description of MTP simple, let us suppose that in each state s, every atom
(p c1 . . . cn ) represents a single-valued property, i.e., there is at most one cn such that (p c1
. . . cn−1 cn ) is true in s. A property is dynamic if an operator may change the value of cn .
For example, if the initial state contains (at plane1 city1) but if there is an operator that
moves plane1 to a different location, then the location of plane1 is dynamic.
For each property p that changes over time, MTP modifies the operators to keep track,
within the current state, of the times at which the property changes and the times at which
various preconditions depend on the property. The idea is that for each dynamic property
p, the current state will contain two time-stamps: read-time(p), which is the last time that
any action read the value of p, and write-time(p), which is the last time that any action
modified the value of p. MTP modifies the operators in such a way that whenever an
operator reads (i.e., accesses) a dynamic property, the operator will update the property’s
read-time, and if an operator writes (i.e., modifies) a dynamic property, it will update the
property’s write-time. Thus, instead of a single “global time,” the current state will contain
many “local times,” namely a read-time and a write-time for each dynamic property.
MTP also inserts preconditions into each action to ensure that the action begins on or
after the read-time of each property that it writes and the write-time of each property that
it reads. This prevents two actions from overlapping in time if one of them writes to a
property and the other reads from it. For example, a boarding operator and a fly operator
on the same plane may not overlap, because the boarding operator requires that the plane
be located in a particular city and the fly operator changes the location of the plane.
Figure 11 shows one of the SHOP2 operators produced by MTP for the ZenoTravel
domain. The operator involves two dynamic properties: a vehicle’s fuel level and its location.
The operator reads both of these properties, so it may not start before their write times.
However, it only writes one of them (the fuel level), so it may start before the read time
of the vehicle’s location. Thus refueling may be performed concurrently with any other
actions that depend on the vehicle’s location, but cannot be performed concurrently with
any actions that modify the fuel level or that modify the vehicle’s location.
391

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

(:operator (!refuel ?plane ?city ?start ?duration)
; preconditions
((aircraft ?plane)
(city ?city)
(at ?plane ?city)
(fuel ?plane ?fuel-level)
(capacity ?plane ?fuel-cap)
(refuel-rate ?plane ?rate)
(assign ?duration (/ (- ?fuel-cap ?fuel-level) ?rate))
(write-time fuel ?plane ?t1)
(write-time at ?plane ?t2)
(read-time fuel ?plane ?t3)
(assign ?start (eval (max ?t1 ?t2 ?t3)))
(assign ?end (eval (+ ?start ?duration)))
(read-time at ?plane ?t4)
(assign ?new-value (eval (max ?t4 ?end))))
; delete list
((fuel ?plane ?fuel-level)
(write-time fuel ?plane ?t1)
(read-time fuel ?plane ?t3)
(read-time at ?plane ?t4))
; add list
((fuel ?plane ?fuel-cap)
(write-time fuel ?plane ?end)
(read-time fuel ?plane ?end)
(read-time at ?plane ?new-value)))
Figure 11: A sample SHOP2 operator produced by MTP.
4.3 Writing Domains that Include Optimization
In previous planning competitions, the planning benchmarks compared only the speed of
the planners and the length of the output plans, so domain designers concentrated on trying
to find a reasonably short plan as quickly as possible. In contrast, most of the problems
in this year’s competition included a linear objective function that needed to be optimized:
the best plan was no longer the one that minimizes the number of steps, but instead was the
one that minimized the objective-function value. We tried three approaches for searching
for optimal plans:
1. Structure the SHOP2 methods in such a way as to take SHOP2 more-or-less directly
toward a plan that minimizes the objective function.
2. Write methods, operators, and axioms to generate plans quickly, and use the “sort-by”
feature to tell SHOP2 to sort the alternatives and try the most promising ones first.
3. Assign costs to the operators, and use a branch-and-bound search to find the best
plan within the execution time limit.
392

SHOP2: An HTN Planning System

The first approach works well if it is easy to tell which alternative will be best at each
node of the search space. For example, if you know that in all problem instances the
objective will be to minimize the total fuel used, then a perfect heuristic for the ZenoTravel
domain is to always use the fly action instead of the zoom action. However, this approach
doesn’t work so well if it isn’t immediately obvious which alternative is best. For example,
if the objective is to minimize the total time, then a naive approach would be always to use
the zoom action rather than the fly action, since the zoom action is faster. However, the
zoom action is not always the best choice, because it requires more fuel and thus can cause
delays for refueling.
The second approach is an extension of the first approach. Consider again the example
in ZenoTravel domain where the objective is to minimize the total fuel used. In addition
to making the planes fly instead of zoom; using a closer plane to transport a person also
reduces the total fuel used. We can set this preference using the sort-by feature of SHOP2.
In the precondition of the method for transporting a person we can sort the available planes
according to the fuel they will use in order to pick up this person. This is a greedy approach.
At each decision point we can sort the alternatives by cost, and go with the alternative that
has the lowest objective-function value. Thus, this approach is not guaranteed to find the
optimal solution. However, if combined with suitable heuristics, this approach results in
near-optimal plans. In the competition we used this technique extensively, and it produced
satisfactory plans even for the largest problems.
The third approach makes use of branch-and-bound optimization, as explained in Section
3.3.2. The main idea is to quickly define methods that will let you find a plan which may
be poor in quality and then let SHOP2 perform branch-and-bound search in the plan space
to find the least cost plan or the best plan it can find within the execution time limit.
For the third approach, there is a challenge in setting up the cost of each operator. For
example, if the objective function requires minimizing the total time, then in order to take
concurrency into account, the cost of an action a should not always be equal to its duration.
For example, suppose the latest event in the current partial plan is for a plane to arrive
at an airport at time t, and two passengers need to board the plane. Then we need to
add two boarding actions to the plan. Recall that in the ZenoTravel domain, all boarding
actions take the same amount of time, tb , and can be performed concurrently. However,
SHOP2 needs to add the actions to the plan one at a time. The first boarding action will
increase the total time by tb , so its cost is tb . However, the second boarding action will not
increase the total time of the plan, so its cost is 0. Now, suppose we add a “refuel” action
to the plan. This action can be done concurrently with the boarding actions, so its cost is
max(0, tr − tb ), where tr is the time needed to refuel.
It is possible to combine two or more of the above approaches. However, in our experience, using optimization (the third approach) did not provide much benefit for domain
descriptions that already included the other two approaches. In these situations, SHOP2
would frequently find an optimal or nearly optimal plan even without optimization, which
meant that the additional amount of time needed by branch-and-bound optimization would
produce little or no benefit. Branch-and-bound optimization would perhaps be more useful
in planning domains where the cost of a plan is something other than the sum of the costs
of the operators; however, such domains did not occur in the planning competition.
393

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

In the International Planning Competition, we did not use the optimization approach
in any official competition trial. For all of the competition domains, in our preliminary
testing of SHOP2 with optimization and no time limits, SHOP2 was unable to find solutions
within the amount of time that we were willing to let it run, except on the very smallest
problems. One way to overcome this difficulty would have been to use time limits, but in
our preliminary tests, this never provided significant improvements in cost across an entire
problem set. One reason for this lack of improvement was that we spent a great deal of
effort crafting the methods used in the competition. We think the third approach would
be more useful in cases where it is not immediately clear how to implement the first two
approaches, and one does not want to spend too much time devising a sophisticated domain
description.

5. Competition Results
Fourteen planning systems competed in the 2002 International Planning Competition.
SHOP2 received a “distinguished performance” award, one of the top four awards.
SHOP2 (along with TLPlan and TALPlanner) was one of three planners that solved
problems in both the “hand-tailored” and “fully automated” tracks. SHOP2 was able to
solve problems in the Strips, Numeric, HardNumeric, SimpleTime, Time, and Complex
domains. SHOP2 solved more problems than any other planner in the competition: it
solved 899 out of 904 problems, for a 99% success ratio.
Of the other two hand-tailorable planners, TLPlan solved 894 problems, nearly as many
as SHOP2. Since TALPlanner didn’t do numeric domains, it solved only 610 problems, but
that still was several hundred more problems than the fully-automated planners solved.
In general, SHOP2 tended to be slower than TALPlanner and TLPlanner, although
there was one domain (Satellite-HardNumeric) where SHOP2 was consistently the fastest.
The speeds of the three hand-tailorable planners generally appeared to be polynomially
related to each other, probably because these planners’ domain knowledge enabled them
to find solutions without doing very much backtracking. All three hand-tailorable planners
were generally much faster than most of the fully-automated planners.
None of the three hand-tailorable planners dominated the other two in terms of plan
quality. For each of them, there were situations where its solutions were significantly better
or significantly worse than the other two.

6. Related Work
The following subsections discuss HTN planning, ordered task decomposition, and the other
hand-tailorable planners that participated in the competition.
6.1 HTN Planning
HTN planning was first developed more than 25 years ago (Sacerdoti, 1990; Tate, 1977).
Historically, most of the HTN-planning researchers have focused on practical applications.
Examples include production-line scheduling (Wilkins, 1988), crisis management and logistics (Currie & Tate, 1991; Tate, Drabble, & Kirby, 1994; Biundo & Schattenberg, 2001),
planning and scheduling for spacecraft (Aarup, Arentoft, Parrod, Stader, & Stokes, 1994;
394

SHOP2: An HTN Planning System

Estlin, Chien, & Wang, 1997), equipment configuration (Agosta, 1995), manufacturability
analysis (Hebbar, Smith, Minis, & Nau, 1996; Smith, Hebbar, Nau, & Minis, 1997), evacuation planning (Muñoz-Avila, Aha, Nau, Weber, Breslow, & Yaman, 2001), and the game
of bridge (Smith, Nau, & Throop, 1998a, 1998b).
The development of a formal semantics for HTN planning (Erol, Nau, & Hendler, 1994;
Erol, Hendler, & Nau, 1996) has shown that it is strictly more expressive than classical
AI planning: there are some problems that can be expressed as HTN planning problems
but not as classical planning problems.4 Even if one places restrictions on HTN planning
to restrict its expressive power to that of classical planning, it generally is much easier to
translate classical planning problems into HTN planning problems than vice versa (Lotem,
Nau, & Hendler, 1999).
6.2 Ordered Task Decomposition
Ordered task decomposition (Nau, Smith, & Erol, 1998) is a special case of HTN planning in
which the planning algorithm always builds plans forward from the initial state of the world.
In other words, an ordered-task-decomposition planner plans for tasks in the same order
that the tasks will later be performed. The first applications of ordered task decomposition
were tailor-made for specific application domains. The best known example is the code
for declarer play that helped Bridge Baron win the 1997 world championship of computer
bridge (Smith et al., 1998b).
SHOP2 is based on SHOP (Nau et al., 1999), a previous domain-independent orderedtask-decomposition planner that requires the subtasks of each method, and also the initial
set of tasks for the planning problem, to be totally ordered rather than partially ordered.
Thus in SHOP, subtasks of different tasks cannot be interleaved. SHOP2 extends SHOP by
allowing the subtasks of each method to be partially ordered. Experiments have shown that
this can allow SHOP2 to create plans more efficiently than SHOP, using domain descriptions
simpler than those needed by SHOP (Nau et al., 2001). Both SHOP and SHOP2 are
available as open-source software at hhttp://www.cs.umd.edu/projects/shopi.
6.3 TLPlan and TALPlanner
Like SHOP2, TLPlan (Bacchus & Kabanza, 2000) and TALPlanner (Doherty & Kvarnström, 2001) competed in the “hand-tailored” track of the AIPS-2002 planning competition.
TLPlan and TALPlanner are similar in many respects. Both of them do a forward-chaining
search in which they apply planning operators to the current state to generate its successors. Thus, like SHOP2, they both know the current state of the world at every step of the
planning process. To control their search, both planners use control rules that are written
declaratively in temporal logic. These rules provide domain-specific knowledge to tell the
planner which states are “bad” states, so that the planner can backtrack and try other
4. More specifically, HTN planning is Turing-complete: even undecidable problems can be expressed as
HTN planning problems. It remains Turing-complete even if we restrict the tasks and the logical atoms
to be purely propositional (i.e., to have no arguments at all). In contrast, classical planning only
represents planning problems for which the solutions are regular sets. Planners such as TLPlan (Bacchus
& Kabanza, 2000) and TALPlanner (Doherty & Kvarnström, 2001) overcome this limitation of classical
planning by extending the formalism to include function symbols.

395

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

paths in the search space. One difference between TLPlan and TALPlanner is that TLPlan
uses a linear modal tense logic, while TALPlanner use TAL, a narrative-based linear temporal logic used for reasoning about action and change in incompletely specified dynamic
environments.
The main difference between both of these planners and SHOP2 is the kind of control
knowledge they use: TLPlan and TALPlanner use their temporal formulas to tell which
part of the search space should be avoided, whereas SHOP2 uses its HTN methods to tell
which parts of the search space should be explored. SHOP2’s search space consists only of
those nodes that are reachable using its HTN methods, whereas TLPlan and TALPlanner
can explore any part of the search space that avoids the “bad” states and their successors.
It is hard to say which type of control knowledge is more effective. Bacchus and Kabanza
(2000) argue that the two types are useful in different situations and that combining them
is a useful topic for future research.

7. Summary and Conclusions
The primary difference between SHOP2 and most other HTN planners is that SHOP2 plans
for tasks in the same order that they will be executed, and thus it knows the current state
at each step of the planning process. This reduces the complexity of reasoning by removing
a great deal of uncertainty about the world, which has made it easy for us to incorporate substantial expressive power into SHOP2. In addition to the usual HTN methods
and operators, SHOP2’s domain descriptions may include axioms, mixed symbolic/numeric
conditions, and external function calls. The planning procedure is Turing-complete, and is
sound and complete over a large class of planning problems (Nau et al., 2001).
Like other HTN planning systems, SHOP2 plans by decomposing tasks into subtasks.
A key idea in using any HTN planner is to design a set of methods that encode something
akin to “standard operating procedures” that capture multi-step techniques for refining a
task. Some kinds of domain characteristics are much more natural to express in an HTN
formalism than in action-based formalism; see Lotem et al. (1999) for a description of some
of the issued involved.
As an example, consider the UM-Translog-2 domain, which we wrote for use as a problem
domain in the AIPS-2002 planning competition (Wu & Nau, 2002). UM-Translog-2 is
a straightforward generalization of the UM Translog domain (Andrews, Kettler, Erol, &
Hendler, 1995); the generalizations include numeric information such as distances, fuel
usage, and so forth. It was relatively straightforward to formulate UM-Translog-2 as an
HTN planning domain. However, it was much more difficult to figure out how to formulate
UM-Translog-2 as a PDDL domain for use by other competitors in the planning competition;
that task took several months to accomplish.
As with most other HTN planning systems, SHOP2’s development was originally motivated not by the planning competition but instead to try to solve practical planning
problems. For example, JSHOP (a Java implementation of SHOP2’s predecessor SHOP)
is the generative-planning component of the HICAP system for planning evacuation operations (Muñoz-Avila et al., 2001), and we are currently incorporating SHOP2 into HICAP
as a replacement for JSHOP. We are very pleased that SHOP2’s capabilities also gave it
the ability to excel in the International Planning Competition!
396

SHOP2: An HTN Planning System

Acknowledgments
This work was supported in part by the following grants, contracts, and awards: Air Force
Research Laboratory F30602-00-2-0505, Army Research Laboratory DAAL0197K0135, Naval
Research Laboratory N00173021G005, and the University of Maryland General Research
Board. The opinions expressed in this paper are those of authors and do not necessarily
reflect the opinions of the funders.
We also wish to thank the anonymous reviewers, whose comments helped us to make
significant improvements to this paper.

Appendix A. SHOP2 Domain Description for the ZenoTravel Domain
(Numeric Version)
In the AIPS-2002 Planning Competition, there were four different versions of the ZenoTravel
domain: the Strips version, the Numeric version, the Simple Time version, and the Time
version. We developed SHOP2 domain descriptions for all four versions.
What follows is our domain description for the Numeric version of the ZenoTravel domain. The operators in our domain description are translated from the original PDDL
coding using a rough approximation of the MTP process in Figure 10.
(defdomain ZENOTRAVEL
(
(:- (same ?x ?x) ())
(:- (different ?x ?y) ((not (same ?x ?y))))
(:-(possible-person-in ?city)
((person ?p) (at ?p ?city) (goal ?p ?city2)
(different ?city2 ?city)))
(:operator (!!cost ?end)
((maxtime ?max)
(assign ?newmax (eval (if (< ?max ?end) ?end ?max))))
((maxtime ?max))
((maxtime ?newmax))
(- ?newmax ?max))
(:method (board ?p ?a ?c)
((write-time ?a ?start))
((!board ?p ?a ?c ?start 1)
(:immediate !!cost (call + ?start 1))))
(:operator (!board ?p ?a ?c ?start ?duration)
((person ?p) (aircraft ?a) (city ?c)
(at ?a ?c) (at ?p ?c) (onboard ?a ?num)
(read-time ?a ?pmax) (assign ?new-num (+ ?num 1))
(assign ?newpmax (max ?pmax (+ ?start ?duration 0.01L0))))
((onboard ?a ?num) (read-time ?a ?pmax) (at ?p ?c) (dest ?a ?c))
((onboard ?a ?new-num) (read-time ?a ?newpmax) (in ?p ?a))
397

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

0.001)
(:method (debark ?p ?a ?c)
((write-time ?a ?start))
((!debark ?p ?a ?c ?start 1)
(:immediate !!cost (call + ?start 1))))
(:operator (!debark ?p ?a ?c ?start ?duration)
((person ?p) (aircraft ?a) (city ?c)
(at ?a ?c) (in ?p ?a) (onboard ?a ?num)
(read-time ?a ?pmax) (assign ?new-num (- ?num 1))
(assign ?newpmax (max ?pmax (+ ?start ?duration 0.01L0))))
((onboard ?a ?num) (read-time ?a ?pmax) (in ?p ?a) (dest ?a ?c))
((onboard ?a ?new-num) (read-time ?a ?newpmax) (at ?p ?c))
0.001)
(:method (refuel ?a ?c)
((write-time ?a ?start) (read-time ?a ?pmax)
(capacity ?a ?cap) (fuel ?a ?fuel)
(eval (> ?cap ?fuel))
(assign ?duration 1)
(assign ?end (+ ?start ?duration 0.01L0))
(assign ?newpmax (max ?pmax ?end)))
((!!ra ((read-time ?a ?pmax))
((read-time ?a ?newpmax)))
(:immediate !refuel ?a ?c ?start ?duration)
(:immediate !!cost ?end)))
(:operator (!refuel ?a ?c ?start ?duration)
((aircraft ?a) (city ?c) (at ?a ?c)
(fuel ?a ?fuel) (capacity ?a ?cap))
((fuel ?a ?fuel))
((fuel ?a ?cap))
0.001)
(:method (zoom ?a ?c1 ?c2)
((write-time ?a ?astart) (read-time ?a ?pmax)
(distance ?c1 ?c2 ?dist)
(fuel ?a ?fuel) (fast-burn ?a ?burn)
(eval (>= ?fuel (* ?dist ?burn)))
(assign ?duration 1)
(assign ?start (max ?pmax ?astart))
(assign ?end (+ ?start ?duration 0.01L0)))
((!!ra ((write-time ?a ?astart) (read-time ?a ?pmax))
((read-time ?a 0) (write-time ?a ?end)))
(:immediate !zoom ?a ?c1 ?c2 ?start ?duration)
(:immediate !!cost ?end)))
(:operator (!zoom ?a ?c1 ?c2 ?start ?duration)
((aircraft ?a) (city ?c1) (city ?c2) (onboard ?a ?num)
(zoom-limit ?a ?limit) (eval (<= ?num ?limit))
398

SHOP2: An HTN Planning System

(at ?a ?c1) (distance ?c1 ?c2 ?dist) (fast-burn ?a ?burn)
(total-fuel-used ?total-fuel)
(assign ?new-total (+ ?total-fuel (* ?dist ?burn)))
(fuel ?a ?fuel)
(assign ?new-fuel (- ?fuel (* ?dist ?burn))))
((at ?a ?c1) (total-fuel-used ?total-fuel) (fuel ?a ?fuel) )
((at ?a ?c2) (total-fuel-used ?new-total) (fuel ?a ?new-fuel))
0.001)
(:method (fly ?a ?c1 ?c2)
((write-time ?a ?astart) (read-time ?a ?pmax)
(distance ?c1 ?c2 ?dist)
(fuel ?a ?fuel) (slow-burn ?a ?burn)
(eval (>= ?fuel (* ?dist ?burn)))
(assign ?duration 1)
(assign ?start (max ?pmax ?astart))
(assign ?end (+ ?start ?duration 0.01L0)))
((!!ra ((write-time ?a ?astart) (read-time ?a ?pmax))
((read-time ?a 0) (write-time ?a ?end)))
(:immediate !fly ?a ?c1 ?c2 ?start ?duration)
(:immediate !!cost ?end)))
(:operator (!fly ?a ?c1 ?c2 ?start ?duration)
((aircraft ?a) (city ?c1) (city ?c2)
(at ?a ?c1) (distance ?c1 ?c2 ?dist) (slow-burn ?a ?burn)
(total-fuel-used ?total-fuel)
(assign ?new-total (+ ?total-fuel (* ?dist ?burn)))
(fuel ?a ?fuel)
(assign ?new-fuel (- ?fuel (* ?dist ?burn))))
((at ?a ?c1)(total-fuel-used ?total-fuel)(fuel ?a ?fuel))
((at ?a ?c2)(total-fuel-used ?new-total)(fuel ?a ?new-fuel))
0.001)
(:operator (!!preprocessing ?problem-name)
((totaltime-coeff ?tc) (fuelused-coeff ?fc)
(eval (setf *tc* ?tc))
(eval (setf *fc* ?fc)))
()
()
0)
(:operator (!!assert ?g )
()
()
?g
0)
(:operator (!!ra ?D ?A )
()
?D
?A
0)
399

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

;;;;
;;;;; Main Methods
;;;;;
(:method (transport-person ?p ?c)
Case1 ((at ?p ?c))
())
(:method (transport-person ?p ?c2)
Case2 (:sort-by ?num #’>
((at ?p ?c1)
(at ?a ?c1)
(aircraft ?a)
(onboard ?a ?num)))
((!!assert ((dest ?a ?c1)))
(:immediate board ?p ?a ?c1)
(!!assert ((dest ?a ?c2)))
(:immediate upper-move-aircraft-no-style ?a ?c2)
(:immediate debark ?p ?a ?c2)))
(:method (transport-person ?p ?c2)
Case3 (:sort-by ?cost #’<
((at ?p ?c1)
(aircraft ?a)
(at ?a ?c3)
(different ?c1 ?c3)
(forall (?c) ((dest ?a ?c)) ((same ?c ?c1)))
(imply ((different ?c3 ?c1))
(not (possible-person-in ?c3)))
(travel-cost-info ?a ?c3 ?c1 ?cost ?style)))
((!!assert ((dest ?a ?c1)))
(:immediate upper-move-aircraft ?a ?c1 ?style)
(:immediate board ?p ?a ?c1)
(!!assert ((dest ?a ?c2)))
(:immediate upper-move-aircraft-no-style ?a ?c2)
(:immediate debark ?p ?a ?c2)))
(:method (upper-move-aircraft ?a ?c ?style)
Case1 ((at ?a ?c))
()
Case2 ((at ?a ?somecity))
((move-aircraft ?a ?somecity ?c ?style)))
(:method (upper-move-aircraft-no-style ?a ?c)
Case1 ((at ?a ?c))
()
Case2 (:sort-by ?cost #’<
((at ?a ?somecity)
(travel-cost-info ?a ?somecity ?c ?cost ?style)))
((move-aircraft ?a ?somecity ?c ?style)))
400

SHOP2: An HTN Planning System

(:- (travel-cost-info ?a ?from ?to ?cost slow)
CASE1
((capacity ?a ?cap) (distance ?from ?to ?dist)
(slow-burn ?a ?burn) (eval (< ?cap (* ?dist ?burn)))
(assign ?cost most-positive-fixnum))
CASE2
((distance ?from ?to ?dist) (fuel ?a ?fuel)
(slow-burn ?a ?burn)
(eval (>= ?fuel (* ?dist ?burn)))
(assign ?cost (float (/
(+ *tc*
(* *fc*
(* ?dist ?burn)))
1))))
CASE3
((capacity ?a ?cap)(distance ?from ?to ?dist)
(slow-burn ?a ?burn)
(assign ?cost (float (/
(+ (* *tc* 2)
(* *fc*
(* ?dist ?burn)))
1)))))
(:- (travel-cost-info ?a ?from ?to ?cost fast)
CASE1
((capacity ?a ?cap) (distance ?from ?to ?dist)
(fast-burn ?a ?burn) (eval (< ?cap (* ?dist ?burn)))
(assign ?cost most-positive-fixnum))
CASE2
((distance ?from ?to ?dist) (fuel ?a ?fuel)
(zoom-limit ?a ?limit) (onboard ?a ?num) (eval (< ?num ?limit))
(fast-burn ?a ?burn)
(eval (>= ?fuel (* ?dist ?burn)))
(assign ?cost (float (/
(+ *tc*
(* *fc*
(* ?dist ?burn)))
1))))
CASE3
((capacity ?a ?cap)(distance ?from ?to ?dist)
(fast-burn ?a ?burn)
(zoom-limit ?a ?limit) (onboard ?a ?num) (eval (< ?num ?limit))
(assign ?cost (float (/
(+ (* *tc* 2)
(* *fc*
(* ?dist ?burn)))
1)))))

401

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

(:method (move-aircraft ?a ?c1 ?c2 slow)
((fuel ?a ?fuel) (distance ?c1 ?c2 ?dist)
(slow-burn ?a ?burn)
(eval (> ?fuel (* ?dist ?burn))))
((fly ?a ?c1 ?c2))
()
((refuel ?a ?c1)
(:immediate fly ?a ?c1 ?c2)))
(:method (move-aircraft ?a ?c1 ?c2 fast)
((fuel ?a ?fuel) (distance ?c1 ?c2 ?dist)
(fast-burn ?a ?burn)
(eval (> ?fuel (* ?dist ?burn))))
((zoom ?a ?c1 ?c2))
()
((refuel ?a ?c1)
(:immediate zoom ?a ?c1 ?c2)))
(:method (transport-aircraft ?a ?c)
((not (no-use ?a)))
((!!assert ((no-use ?a)))
(:immediate upper-move-aircraft-no-style ?a ?c)
(:immediate !!ra ((no-use ?a)) ())))

References
Aarup, M., Arentoft, M. M., Parrod, Y., Stader, J., & Stokes, I. (1994). OPTIMUM-AIV:
a knowledge-based planning and scheduling system for spacecraft AIV. In Intelligent
Scheduling, pp. 451–469. Morgan Kaufmann.
Agosta, J. M. (1995). Formulation and implementation of an equipment configuration
problem with the SIPE-2 generative planner. In Proc. AAAI-95 Spring Symposium
on Integrated Planning Applications, pp. 1–10.
Andrews, S., Kettler, B., Erol, K., & Hendler, J. (1995). UM Translog: a planning domain
for the development and benchmarking of planning systems. Tech. rep. CS-TR-3487,
Dept. of Computer Science, University of Maryland.
Bacchus, F., & Kabanza, F. (2000). Using temporal logics to express search control knowledge for planning. Artificial Intelligence, 116.
Biundo, S., & Schattenberg, B. (2001). From abstract crisis to concrete relief. a preliminary
report on flexible integration on nonlinear and hierarchical planning. In Proceedings
of the European Conference on Planning.
Boddy, M., & Dean, T. (1989). Solving time-dependent planning problems. In Sridharan,
N. S. (Ed.), Proceedings of the Eleventh International Joint Conference on Artificial
Intelligence, pp. 979–984, Detroit, MI, USA. Morgan Kaufmann.
Currie, K., & Tate, A. (1991). O-Plan: The open planning architecture. Artificial Intelligence, 52 (1), 49–86.
402

SHOP2: An HTN Planning System

Doherty, P., & Kvarnström, J. (2001). TALplanner: a temporal logic based planner. AI
Magazine, 22 (3), 95–102.
Erol, K., Hendler, J., & Nau, D. (1996). Complexity results for Hierarchical Task-Network
planning. Annals of Mathematics and Artificial Intelligence, 18, 69–93.
Erol, K., Nau, D., & Hendler, J. (1994). HTN planning: Complexity and expressivity. In
AAAI-94.
Estlin, T. A., Chien, S. A., & Wang, X. (1997). An argument for a hybrid HTN/operatorbased approach to planning. In Proc. Fourth European Conference on Planning (ECP97), pp. 184–196.
Gupta, N., & Nau, D. S. (1992). On the complexity of blocks-world planning. Artificial
Intelligence, 56 (2-3), 223–254.
Hebbar, K., Smith, S., Minis, I., & Nau, D. (1996). Plan-based evaluation of designs for
microwave modules. In Proc. ASME Design Technical Conference.
Lotem, A., Nau, D., & Hendler, J. (1999). Using planning graphs for solving HTN problems.
In AAAI-99, pp. 534–540.
Muñoz-Avila, H., Aha, D., Nau, D., Weber, R., Breslow, L., & Yaman, F. (2001). SiN:
Integrating case-based reasoning with task decomposition. In IJCAI-2001.
Nau, D., Cao, Y., & Muñoz-Avila, H. (1999). SHOP: Simple Hierarchical Ordered Planner.
In IJCAI-99, pp. 968–973.
Nau, D., Muñoz-Avila, H., Cao, Y., Lotem, A., & Mitchell, S. (2001). Total-order planning
with partially ordered subtasks. In IJCAI-2001, Seattle.
Nau, D. S., Smith, S. J. J., & Erol, K. (1998). Control strategies in HTN planning: Theory
versus practice. In AAAI-98/IAAI-98 Proceedings, pp. 1127–1133.
Sacerdoti, E. D. (1990). The nonlinear nature of plans. In Allen, J., Hendler, J., & Tate, A.
(Eds.), Readings in Planning, pp. 162–170. Morgan Kaufmann. Originally appeared
in Proc. IJCAI-75, pp. 206-214.
Slaney, J., & Thiébaux, S. (2001). Blocks world revisited. Artificial Intelligence, 125 (1-2),
119–153.
Smith, S. J., Hebbar, K., Nau, D., & Minis, I. (1997). Integrating electrical and mechanical
design and process planning. In Mantyla, M., Finger, S., & Tomiyama, T. (Eds.),
Knowledge Intensive CAD, Vol. 2, pp. 269–288.
Smith, S. J., Nau, D. S., & Throop, T. (1998a). Success in spades: Using AI planning
techniques to win the world championship of computer bridge. In AAAI-98/IAAI-98,
pp. 1079–1086.
Smith, S. J. J., Nau, D. S., & Throop, T. (1998b). Computer bridge: A big win for AI
planning. AI Magazine, 19 (2), 93–105.
Tate, A. (1977). Generating project networks. In IJCAI-77, pp. 888–893.
Tate, A., Drabble, B., & Kirby, R. (1994). O-Plan2: An Architecture for Command, Planning and Control. Morgan Kaufmann.
403

Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman

Wilkins, D. E. (1988). Practical Planning: Extending the Classical AI Planning Paradigm.
Morgan Kaufmann, San Mateo, CA.
Wu, D., & Nau, D. (2002). UM-Translog-2: A planning domain designed for AIPS-2002.
Tech. rep. CS-TR-4402, UMIACS-TR-2002-82, University of Maryland.

404

Journal of Artificial Intelligence Research 20 (2003) 1-59

Submitted 3/03; published 12/03

The 3rd International Planning Competition: Results and
Analysis
Derek Long
Maria Fox

derek.long@cis.strath.ac.uk
maria.fox@cis.strath.ac.uk

Department of Computer and Information Sciences
University of Strathclyde, Glasgow, UK

Abstract
This paper reports the outcome of the third in the series of biennial international planning competitions, held in association with the International Conference on AI Planning
and Scheduling (AIPS) in 2002. In addition to describing the domains, the planners and
the objectives of the competition, the paper includes analysis of the results. The results
are analysed from several perspectives, in order to address the questions of comparative
performance between planners, comparative difficulty of domains, the degree of agreement
between planners about the relative difficulty of individual problem instances and the question of how well planners scale relative to one another over increasingly difficult problems.
The paper addresses these questions through statistical analysis of the raw results of the
competition, in order to determine which results can be considered to be adequately supported by the data. The paper concludes with a discussion of some challenges for the future
of the competition series.

1. Introduction
Beginning in 1998 the international planning community has held a biennial event to support the direct comparison of planning systems on a changing collection of benchmark
planning problems. The benefits of this series of events have been significant: over five
years, planning systems have been developed that are capable of solving large and complex
problems, using richly expressive domain models and meeting advanced demands on the
structure and quality of solutions. The competition series has inspired many advances in
the planning research community as well as an increasingly empirical methodology and a
growing interest in the application of planners to real problems.
In this paper we describe the structure, objectives and outcomes of the third competition,
which took place in Toulouse in 2002. The competition was colocated with the AI Planning
and Scheduling (AIPS) conference. At that conference a brief report was presented of some
of the results achieved by the participating planners. We begin by presenting an overview of
the main results as presented at the conference, showing the number of problems attempted
and solved by each planner and identifying the competition prize-winners. As in previous
years the competition resulted in the collection of a large data set comprising data points
for several different domains. A certain comparative understanding can be obtained by
examining the data for the individual domains, but conclusions drawn on this basis cannot
be generalised across domains. One of the goals of this paper is to try to reveal some
insights that cross the boundaries of the domains and allow some general questions to be
answered. These include: which planners reveal the most consistent, stable performance
c
2003
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Long & Fox

across domains? What benefit is obtained by exploiting hand-coded control knowledge? Is
there any general agreement over what makes a planning problem hard? Are particular
planning approaches best suited to particular kinds of problem domains?
The accepted scientific methodology for addressing such questions is to frame precise
hypotheses prior to the collection of the data sets in order to control for any extraneous
variables that might distort the reality with respect to these questions. To date this has
not been the practice of the planning community with respect to the competitions. In the
third competition we proceeded, as in previous years, by collecting data prior to detailed
consideration of the specific questions we wished to answer. The community has not yet
agreed that the primary role of the competition is to provide a carefully crafted platform for
the scientific investigation of planners: indeed, its main roles so far have been to motivate
researchers in the field, to identify new research goals and thereby push forward the research
horizons, and to publicise progress to the wider community. However, because competitions
have winners there is a natural tendancy to draw conclusions from the competition data
sets about the state of the art. If these conclusions are not scientifically supported they can
be misleading and even erroneous. Therefore there is an argument for trying to combine
the two objectives, although admittedly there is a tension between them that might make
it difficult to combine them successfully.
Because of the way in which the planning competitions are currently conducted, the
analyses we describe in this paper are post hoc. We conducted all of our analyses on the
data collected during the competition period: we did not run any further experiments after
the competition because the participants felt that it was important that the data they
submitted during the competition should comprise the evidence on which they were judged.
We have identified a number of analyses which we think provide interesting information
to the planning community and, in the following sections, we explore each theme in as
rigorous a way as possible within the constraints of the data we have at our disposal. It has
been difficult to work with a fixed data set that was collected without precise experimental
questions in mind, and we were unable to test many of the hypotheses that occurred to us
during our analyses because the data was inappropriate or incomplete. However, despite
the limitations of the data set we believe we have been able to pose and answer some
important questions about the comparative performances revealed in the competition. We
phrase the objectives of our analyses in terms of null and alternative hyptheses because
this is the standard approach when applying statistical tests. Our approach was partly
inspired by the earlier work of Howe and Dahlman (2002). Their work raised the standard
to which evaluation of planners should be done and compels the planning community to
decide whether future planning competitions should be conducted in a way that supports
the goals of scientific investigation of progress in the field.
The rest of this paper is organised as follows. We begin by discussing the context —
the competition series itself and the general form of the third competition, including the
domains, the competitors and the specific challenges raised. We then briefly summarise the
results of the competition before embarking on a detailed post hoc analysis of the competition results. This analysis investigates the relative performances of the planners, the relative
difficulties of the problem sets used and the relative scaling behaviours of the competitors
across domains and levels. We provide an appendix in which we present summaries of the
competing planners and details of the domains used.
2

The 3rd International Planning Competition

2. The International Planning Competition Series
The first event was held in conjunction with the fourth international Artificial Intelligence
Planning and Scheduling conference (AIPS’98). It was organised by Drew McDermott,
together with a committee of senior members of the research community (McDermott,
2000). The event took some time to organise, with evolving agreement on the form of the
event, the kinds of planning systems that should be compared, the basis of comparison and
so on. The final event became a direct comparison of 5 strips-based planners, with two
of the planners also attempting an extended adl-based language (McDermott, 2000; Long,
2000). The systems included three Graphplan-based systems, one forward heuristic search
system and one planning-as-satisfiability satsolver planner. A very important outcome
of the first competition was the adoption of pddl (McDermott & the AIPS’98 Planning
Competition Committee, 1998) as a common representation language for planning.
Although the opportunity was offered for competitors to hand-code control knowledge
for their planners, in fact all of the planners were fully-automated and ran on the problem
instances without any priming. The entire event was staged at the conference over a period
of some four days, involving intensive sessions of generating and checking solutions and
attempting to evaluate the results. One idea that was tried, but that turned out to be
problematic in practice, was to score the planners’ performances using a function that
attempted to take into account the time taken to generate a plan, the length of the plan
and the relative performance of all of the competitors on the problems. For example, a
planner that produced a plan faster than all of its competitors would be rewarded based on
how much faster it was than the average for the problem. This attempt to score planners
using a one-dimensional measure proved difficult, with counter-intuitive results in certain
cases. In the end it was abandoned in favour of two dimensions: length of plan and time
taken to produce it. This decision indicates that, even for only five systems and a relatively
small set of problems, it is impossible to make unequivocal decisions about which system is
best. Nevertheless, the community can (and did) learn much from the data that is gathered,
offering a variety of interpretations of the data, but ultimately being inspired to improve
on it in every way possible.
In the second competition, chaired by Fahiem Bacchus, 17 planners competed. The
increase in participation and the ambitions for larger scale testing required that the event
be spread over a much longer period. In fact, testing was spread over a couple of months,
with only one final test being carried out at the conference site (AIPS’00 in Breckenridge). In
the second competition there was a more formal split between systems, with a small number
using hand-coded control knowledge and others being fully-automated. There was also a
split between strips and adl capable systems. The larger number of competitors included
a wider range of approaches: as well as Graphplan-based systems, forward heuristic search
and a satsolver, there were several planners based on model-checking approaches using
bdds, and one using planning-by-rewriting. Again, it proved difficult to compare planners
unequivocally, but several important observations could be made: the advantages of handcoded control rules in most domains could be seen clearly (as would be expected), although
there remained an important question about the difficulty of generating and writing the
rules. Of the fully-automated planners, the forward heuristic search approach proved to be
particularly successful, dominating performance in most domains. Pure Graphplan-based
3

Long & Fox

planning seemed to have reached its zenith between the first two competitions and no longer
appeared competitive.
The third competition (and most recent at the time of writing) was held in association
with AIPS’02 at Toulouse. Fourteen planners participated. The primary objective of the
competition was to help to push forward research into temporal and resource-intensive
planning. Extensions were made to pddl to support the modelling of temporal and numeric
domain features. These resulted in the pddl2.1 language (Fox & Long, 2003). The extensive
changes to pddl2.1 and the ambitious objectives of the competition help to account for the
fact that fewer people participated in 2002 than in 2000. Once again, the real testing and
gathering of data took place over the two months prior to the conference. Although initial
results were presented at the conference, no detailed analysis took place at the conference
itself. The rest of this paper examines the objectives of the third competition, the results
and some future challenges for the series.

3. Overview: The Third International Planning Competition
As organisers of the Third International Planning Competition we chose to address several
new challenges that we believe are important to the ambitions of the planning community: the management of problems with metric constraints on numerically valued variables,
temporal planning (including managing concurrency and scheduling of activities) and the
construction of plans subject to specified optimisation criteria other than a simple count of
the numbers of steps.
Setting these goals has obvious implications for the potential competitors in terms of
extended expressive power and additional problem-solving required to manage the extensions. In order to control the extent to which competitors would be required to handle
all of these extensions successfully, we constructed variants, or levels, of all of the domains
used in the competition. For most of the domains we included a strips level, a numeric
level (using strips and metric variables only), a simpletime level in which actions have
duration but there are no other metric values in the domain and a full temporal level, time,
using durative actions with durations determined by the context of their usage (so duration
depends on the parameter values and not only on the action name). The simpletime and
time levels did not involve numeric resources other than time. To address this combination
we introduced some additional domain variants, as we discuss below. Each of the four levels
corresponds to a particular degree of expressive power of pddl2.1, and there are different
challenges posed by the versions of each domain at each level.
A secondary goal was to assess the relative effort of generating and encoding control
rules for planners. Unfortunately, we failed to find any way to usefully quantify this effort.
We discuss this question further in the following sections.
3.1 Problem Domains
The problem domains selected for the competitions have been, or have become, benchmark
domains used by much of the community for empirical evaluation. The domains that have
been used have often been chosen to probe some specific detail of performance. This has
sometimes meant that the domains are not representative of general features of planning
4

The 3rd International Planning Competition

and are inappropriate for use in more widespread testing. A description of the domains
used in all of the competitions so far can be found in Appendix A.
In the third competition, eight families of domains were used, broadly divided into
transportation domains (Depots, DriverLog and ZenoTravel), applications-inspired domains
(Rovers and Satellite) and a small collection of others (Settlers, FreeCell and UM-Translog2).
We briefly summarise the collection here and describe them in more detail in Appendix A.
• Depots This domain combines the transportation style problem of Logistics with the
well-known Blocks domain. The Logistics domain exhibits a high degree of parallelism,
since separate vehicles can be utilised concurrently. In contrast, the Blocks domain
is characterised by significant goal interaction. Our intention in doing this was to
discover whether the successes of planners in each of these domains separately could
be brought together when the problems were combined.
• DriverLog This problem involves transportation, but with the twist that the vehicles
must be supplied with a driver before they can move.
• Zeno-travel Another transportation problem, inspired by a domain used in testing
the zeno planner developed by Pemberthy and Weld (1994), in which people must
embark onto planes, fly between locations and then debark, with planes consuming
fuel at different rates according to speed of travel.
• Satellite This domain was inspired by the problem of scheduling satellite observations. The problems involve satellites collecting and storing data using different
instruments to observe a selection of targets.
• Rovers This domain was motivated by the 2003 Mars Exploration Rover (MER)
missions and the planned 2009 Mars Science Laboratory (MSL) mission. The objective
is to use a collection of mobile rovers to traverse between waypoints on the planet,
carrying out a variety of data-collection missions and transmitting data back to a
lander. The problem includes constraints on the visibility of the lander from various
locations and on the ability of individual rovers to traverse between particular pairs
of waypoints.
• Settlers This domain revolves around the management of resources, measured using
metric valued variables. Products must be manufactured from raw materials and used
in the manufacture or transportation of further materials. New raw materials can be
generated by mining or gathering. The objective is to construct a variety of structures
at various specified locations.
• UM-Translog-2 This domain is a pddl2.1 encoding of a new variant of the UMTranslog (Wu & Nau, 2002) domain. This was generated for us by Dan Wu of the
University of Maryland. This is essentially a transportation domain, but one that
is significantly more complex than previous transportation benchmarks. In fact, this
domain was introduced late in the competition and very little data was collected. It
is therefore not discussed further in this paper.
5

Long & Fox

We also reused the Freecell domain from the second competition. This domain presented
a serious challenge to participants in 2000 and we were interested to see whether planning
technology had surpassed this challenge in the intervening two years. Although the domain
produced some interesting data we did not attempt to precisely measure the extent to which
the 2002 performance surpassed that of 2000.
Each domain (other than Settlers, Freecell and UM-Translog-2) was presented to the
competitors for at least the four different levels previously identified: strips, numeric
simpletime and time. The problems presented at each of these levels comprised distinct
tracks and the competitors were able to choose in which tracks they wished to compete.
In addition to the four main tracks we also included two additional tracks, intended to
explore particular ideas. These tracks did not necessitate the use of additional expressive
power but simply allowed existing expressiveness to be combined to produce interesting
planning challenges. For example, the hardnumeric track consisted of problems from the
Satellite domain that had very few logical goals. Plans were evaluated by a metric based on
amount of data recorded rather than by determining whether a specified logical goal had
been achieved. The challenge was for planners to respond to the plan metric and include
actions that would acquire data. The complex track consisted of problems that combined
temporal and numeric features. The challenge was to reason about resource consumption in
parallel with managing temporal constraints. In total, we defveloped 26 domains, with 20
problem instances in each domain (a few, unintentially, ended up with 16 or 22 instances).
In most domains there were an additional 20 instances of large problems intended for the
hand-coded planners. In total there were nearly 1000 problem instances to be solved, of
which about half were intended primarily for the fully-automated planners.
3.2 The Competitors
The population of competing planning systems has changed over the three competitions.
Few systems have competed more than once and no system has appeared in all three competitions. In part, this is a reflection of the speed of development of planning systems, revealing
the extent to which the technology of 1998 has been surpassed by that of 2002. It is also
a reflection of the growing interest in the series, which has encouraged more competitors
to come forward, and of the work involved in taking part which has discouraged previous
competitors from repeating their effort. Entering the competition involves more than generating interesting and efficient approaches to solving the planning problem: it demands
the ability to construct a system that can respond robustly and reliably when confronted
with previously unseen challenges, including domains that were not amongst those used in
development of the system. It must be sufficiently well-engineered that its performance is
not dominated by poor programming rather than by the real algorithmic effort of solving
the problem (careless choice of a data structure can undermine the opportunity to show
off a clever new planning algorithm). For systems that use hand-coded rules to guide the
planning system there is an additional demand: the time required to read and understand
domains sufficiently to construct sensible control knowledge and to then encode and test
the knowledge to achieve good performance. The time-table for the testing was relatively
compressed (the entire problem suite was generated and delivered to the competitors over a
two month period and testing was carried out remotely on a single machine), so those using
6

The 3rd International Planning Competition

hand-coded controls were forced to find time to analyse the domains, hypothesise and test
rules in intense sessions.
Details of the competing systems can be found in Appendix B. To summarise, many
of the fully-automated planners use relaxed plan heuristics to guide a heuristic search.
lpg (Gerevini, Saetti, & Serina, 2003) uses local search to improve candidate plan structures formed in a Graphplan-style plan graph. Several planners (mips, ff and sapa) also
extend the use of relaxed plan heuristics to include numeric features. vhpop is a partialorder planner, demonstrating that partial-order planning can be competitive with the more
recently fashionable heuristic forward state-space search planners. For various reasons,
several planners generated only small collections of results, which are disregarded in the
analysis.
A few competitors used more than one version of their planner, or more than one
parameter setting. We did not attempt to enforce the use of unique versions, but left it to
competitors to ensure that we were informed where variations were used. Multiple versions
of ff, mips and lpg were used. ff submitted almost all data for a version optimised
for speed performance. A small subset of data was submitted for a version optimised for
quality, showing that there are alternative criteria by which performance can be evaluated.
In all of the analyses we report we have used the data generated by ff optimised for
speed exclusively. mips also offered data in two variants, using slightly different parameter
settings. In our analyses we use data for one variant (mips) exclusively, except in the case
of the Satellite hardnumeric problems in which we used the data from the other variant
(mips.plain). lpg submitted data in three versions: one based on earliest plan produced,
one based on best plan produced over a longer time span and a third which represented
a compromise between speed and quality. In fact, since all of the results for the version
optimised for quality were generated within a few minutes at most, we chose to use this data
exclusively in the analyses that follow. This should be borne in mind when reviewing the
results for comparative speed performance of the planners. The performance of lpg relies on
certain parameter settings. In most cases, the parameters used for lpg were automatically
set, but in a few cases some parameters were set by hand. In their paper, appearing in
this issue, Gerevini, Saetti and Serena (2003) give new results of an experiment testing
their planner with all parameters set automatically. In general they observe no significant
difference in the performance of lpg with respect to the data provided for the competition.
The three hand-coded planners that competed represent two alternative approaches to
planning: forward state-space search using control rules to prune bad choices and promote
good choices, and hierarchical task network (htn) planning.
There were 508 problems available to the fully-automated planners and mips was the
only planner to attempt all of them. There were 904 problems available to the hand-coded
planners and shop2 was the only planner to attempt all of these, solving almost all of them
and solving the most problems overall. tlplan and talplanner were the only planners
that solved all problems attempted. Not all planners attempted all problems they were
equipped to handle. In particular, sapa did not attempt strips problems, although it is
capable of solving them.
Although the planning competitions have been a great source of data from the stateof-the-art planners and an encouragement and catalyst for progress in the field, they are
also lively and exciting competition events. This means that there must be “winners”. The
7

Long & Fox

Planner
FF
LPG
MIPS
SHOP2
Sapa
SemSyn
Simplanner
Stella
TALPlanner
TLPlan
TP4
TPSYS
VHPOP

Solved
237 (+70)
372
331
899
80
11
91
50
610
894
26
14
122

Attempted
284 (+76)
428
508
904
122
144
122
102
610
894
204
120
224

Success Ratio
83% (85%)
87%
65%
99%
66%
8%
75%
49%
100%
100%
13%
12%
54%

Tracks entered
S, N, HN
S, N, HN, ST, T
S, N, HN, ST, T, C
S, N, HN, ST, T, C
T, C
S, N
S
S
S, ST, T
S, N, HN, ST, T, C
N, ST, T, C
ST, T
S, ST

Figure 1: Table showing problems attempted and solved by each of the planners in the third
IPC. Tracks are S: strips, N: numeric, HN: hardnumeric, ST: simpletime, T:
time and C: complex. Note that ff attempted 76 additional problems intended
for the handcoded planners and solved 70 of them successfully. IxTeT solved
9 problems with plans accepted by the validator and attempted a further 10
problems producing plans that could not be validated due to differences between
plan syntax used by IxTeT and defined in pddl2.1.

8

The 3rd International Planning Competition

choice of winners is left to the organisers and must be treated with caution. In summarising
the results at the AIPS conference in Toulouse, we presented a table of results in the form
shown in Figure 1, together with a selection of graphs showing relative performance of
planners in terms of speed and quality of plans in several of the problem sets. It was hard
to synthesise a comprehensive view in the short time between final data collection and the
presentation (a matter of a couple of days, during the conference), so our initial assessments
were based on a rather crude evaluation of the evidence. We chose to award a prize to lpg as
the best performer of the fully-automated planners: it solved the most problems of all fullyautomated planners, showing excellent performance in the time tracks. We also awarded a
prize to mips which solved the second most problems and had the widest coverage of all
the fully-automated planners. It is clear that ff produced exceptional performance in the
numeric level problems and could well have been judged worthy of a prize for that. We chose
to acknowledge the great difficulty for newcomers to the competition in building a system
that is sufficiently robust to compete, especially when there is no team of programmers and
researchers to support the effort. For this reason we awarded a prize to vhpop as best
newcomer, with its creditable performance in both strips and simpletime problems.
Turning to the hand-coded planners, we awarded a prize for best performance to tlplan,
which tackled almost all of the problems available, solved all of those it attempted and
produced plans of very high quality with dramatic speed. We also rewarded shop2 for the
fact that it attempted every problem and produced more plans than any other planner.
The quality of its plans was consistently good and its performance highly competitive.
talplanner also performed outstandingly, often producing the highest quality plans and
doing so tremendously efficiently, but its coverage was restricted to the strips and time
tracks. In selecting prize winners we chose to emphasise breadth of coverage, particularly
in the new challenges of handling numeric and temporal planning problems. Competitions
demand a degree of spectacle in the selection of winners, but the more measured evaluation
of planners takes time. In this paper we present various analyses of the data collected during
the competition and leave it to the community to judge the final rankings of the planners.
3.3 Additional Challenges
The hardnumeric and complex problems used in the competition do not easily fit into
the analysis conducted across the other results. These problems raise interesting special
challenges for the planners. We now discuss some of these challenges, presenting data below.
Each of these challenges was explored in only one or two problem sets, so generalisations
about the performance of the planners based on the data collected are inappropriate. We do
not, therefore, perform a statistical analysis of these data, but, instead, present the relevant
data in simple graphical form.
3.3.1 The hardnumeric Satellite Problems
The hardnumeric Satellite problem instances contained logical goals that are almost all
trivial. For example, in most cases the problems involved simply ensuring that each of the
satellites target a specific observation site at the end of the plan. However, the plan metric
used to evaluate the plans was far more informative: the plans were evaluated according
to the data collected by the satellites during their execution. Simply satisfying the explicit
9

Long & Fox

Satellite-HardNumeric
6000
TLPlan (20 solved)
SHOP2 (20 solved)
MIPS (20 solved)
FF (Speed) (20 solved)

5000

Quality

4000

3000

2000

1000

0
0

2

4

6

8
10
12
Problem number

14

16

18

20

Figure 2: Plan quality for the Satellite hardnumeric problems. High values are better
quality plans: quality is the amount of data collected.

goals would generate a correct plan, but a worthless one in terms of the plan metric. Of the
fully-automated planners, only mips and ff tackled these problems. tlplan and shop2
were the hand-coded planners that attempted these problems. It is instructive to compare
the qualities of the plans produced by all four of these planners on this problem set. Figure 2
shows that the quality of the plans produced by the hand-coded planners is significantly
higher than the quality of the plans generated by fully-automated planners. Indeed, ff
generates plans that satisfy only the logical goals and minimise the plan size required to
achieve that, so do not lead to any data collection. With some careful adjustments, mips
has been able to generate plans that collect some data, but this is clearly a rather limited
result. The closeness of the results generated by tlplan and shop2 suggest that they are
both solving the data collection problem at a level close to optimal, or are applying similar
heuristic approaches to the problem and generating similar locally optimal solutions. This
domain very clearly highlights an advantage of hand-coded planners in their exploitation of
the knowledge that their human domain-engineer can bring to bear.
3.3.2 The Complex Satellite Domain
In addition to the hardnumeric Satellite domain, a complex Satellite domain was also
considered. The complexity in this domain arises from the fact that it combines temporal
actions, with durations dependent on the parameters of the action, with the management
of numerically measured resources (in this case, the data store available for acquired data).
The problem has a quality that is similar to a knapsack problem, with data having to be
packed into the limited stores of appropriate satellites. This is combined with the temporal
optimisation problem, which involves ensuring that the satellites are efficiently deployed,
10

The 3rd International Planning Competition

Satellite-Complex
2000
MIPS (8 solved)
TLPlan (20 solved)
SHOP2 (20 solved)
Sapa (16 solved)
LPG (Quality) (20 solved)

1800
1600
1400
Quality

1200
1000
800
600
400
200
0
0

2

4

6

8
10
12
Problem number

14

16

18

20

Figure 3: Plan quality for the Satellite complex problems. Low values represent better
plans, since quality measures makespan, which was to be minimised.

moving between targets and capturing data according to their capabilities, their current
aspects and their available store. As can be seen from Figure 3, the planners — fullyautomated and hand-coded — produced plans of quite widely varying quality (lower values
are better, here, since quality is measured by makespan). In general, tlplan produced
the best quality plans, although lpg also produced some high quality plans for the smaller
problems. As can be seen in problems 13, 16, 19 and 20, particularly, the fully-automated
planners occasionally produced plans with quality diverging very significantly from optimal
(we do not actually know what the optimal values are for these problems, but we can
obviously consider the best value produced as an upper bound on the optimal value).
3.3.3 The Settlers Domain
The Settlers domain is based on resource-management computer games, in which resources
must be accumulated and used to construct new resource centres, with new specialised
production and capabilities. An interesting problem that this domain highlights is that
the pddl2.1 family of languages does not offer a convenient way to name objects that are
created during execution of a plan. In the version used for the competition, we overcame
this problem by having a selection of names available at the outset that are not initially
committed to any role. When an object is constructed, an unallocated name is used to
name it, assigning to the name the properties of the new object and marking the name
as used. An important problem that this approach creates for most current planners is
that the initial grounding of actions involves creating all possible ways in which the names
could be assigned to objects and then used in various roles within the plan. This leads to
a significant explosion in the size of the domain encoding. It is interesting to observe that
11

Long & Fox

only 6 of the 20 problems were solved by any (fully-automated) planner, and that only ff
solved more than one problem. It is clear that this domain remains a challenge to planning
technology, but also to the future development of pddl2.1 in which it will be necessary to
review the way in which object construction is modelled.

4. Analysis of Competition Performance
One of the important roles of a competition is to identify the state of the art in the field,
in terms of a variety of measures, and to attempt to answer broad questions about the
landscape of the research area. Of course, a competition cannot have the last word about
the state of the art. There might be state of the art planning systems that are prevented,
for whatever reason, from taking part in the competition. However, the competition does
provide some useful insights into the capabilities of modern planning systems.
Planning performance can be measured in terms of the speed of solution of the problems
and the number and quality of the solutions found. Other metrics might also be identified.
There are different planning architectures and heuristic evaluation functions as well as
different kinds of domains and problems. The state of the art is represented by specific
exemplars of these architectures and heuristic functions and it is interesting to explore the
suitability of different architectures for use on different domains, the scaling behaviour of
particular approaches, the comparative performance of different planning systems, etc. We
address some of these issues in the following sections.
We perform three collections of analyses to ascertain comparative performance based on
consideration of raw speed and quality data, the extent to which domain influenced planner
behaviour and the scaling behaviour of the planners. The first collection is a comparison
between the planners based on their raw competition performance. We analyse the data
from the point of view of a consumer interested in ranking the planners according to speed
and plan quality. These experiments are aimed at answering coarse level questions of the
form: which planner should I buy? In asking questions such as this we are trying to arrive at
a general basis for comparison. Of course, our investigation of this question is constrained
by the metrics used in the competition. Furthermore, the trade-off one makes between time
and quality depends on the context in which a planner might be deployed. Therefore, we
cannot combine the judgements of relative speed and relative plan quality performance to
determine unequivocally which planner to buy. We take as a basic assumption that potential
users of domain-independent planning technology are interested primarily in broad coverage
with good behaviour across a wide variety of domains, rather than in restricted coverage
with spectacular behaviour in just a few domains. Our raw performance analyses are
based mainly on the Wilcoxon rank-sum matched-pairs test (see Appendix C), as explained
below. An advantage of this test is that it is non-parametric, meaning that it does not rely
on assumptions about the shapes or properties of the underlying population distributions.
It is also robust to outliers.
The second collection of experiments is concerned with identifying whether there were
domains that were significantly easier (or harder). We perform these experiments at each
of the levels of problems used in the competition to determine whether there is agreement
amongst the planners about the difficulty of the problems. In part, this assists us in going
on to explore scalability issues but it also allows us to determine whether the problem
12

The 3rd International Planning Competition

set presented at the competition contained interesting challenges. Our third collection of
experiments compares the way in which planners scale on problem sets in which they agree
about problem difficulty.
4.1 Raw Performance Analysis
We perform pairwise comparisons between planners to ascertain whether any consistent
pattern can be identified in their relative speed and plan quality. We focus first on comparing
the fully-automated planners and, separately, the hand-coded planners. We then perform an
additional set of analyses to try to determine the raw performance benefit obtained from the
use of hand-coded control knowledge. To do this, we perform the Wilcoxon test on pairs
crossing the boundary between the fully-automated and hand-coded planner groupings.
Where the conclusion is that the improvement obtained is significant, all we can say is that
control rules yield an improvement in performance. We cannot account for the price, in
terms of effort to encode the rules, that must be paid to obtain this improvement. The
understanding of what is involved in writing useful control knowledge is still anecdotal and
it remains an important challenge to the community to quantify this more precisely. One
important consequence of the use of hand-crafted control knowledge is that to speak of
“planner” performance blurs the distinction between the planning system itself and the
control rules that have been produced to support its performance in each domain. Where
a planner performs well it is impossible to separate the contributions from the planning
system, the architecture of that system (and the extent that this contributes to the ease
of expressing good control rules) and the sophistication of the control rules that have been
used. We do not attempt to distinguish planner from control rules in the analysis that
follows, but at least one competitor observed that results would have been significantly
worse had there been less time to prepare, while, given more time, results could have
been improved by concentrating on optimisation of plan metrics rather than simply on
makespans. This observation helps to highlight the fact that, for planners exploiting handcoded control knowledge, the competition format should be seen as a highly constrained
basis for evaluation of performance.
To summarise, we now present the hypotheses we are exploring in this section:
Null Hypothesis: There is no basis for any pairwise distinction between
the performances of planners in terms of either time taken to plan or in quality
(according to the specified problem metrics) of plans produced.
Alternative Hypothesis: The planners can be partially ordered in terms
of their time performances and, separately, their quality performances.
4.2 Analytic Framework
We perform pairwise comparisons, between planners in the fully-automated and hand-coded
groups, on the problems in each of the main four problem levels used in the competition. We
do not include analyses of the complex and hardnumeric tracks because these resulted
in too few data points for meaningful statistical conclusions to be drawn. We perform
Wilcoxon rank-sum matched-pairs tests to identify whether the number of times one planner
performed better than the other indicates a significant difference in performance between the
13

Long & Fox

two. Having performed pairwise comparisons between the performances in each of the tracks
we use the results to construct partial orderings on the speed and quality performances of
the planners in these tracks. We use 0.001 as the significance level because we wish to
extrapolate from collections of pairwise comparisons to infer confidence, at the p = 0.05
level, in the transitive relationships between the planners. In the strips track, which was
the largest, we perform 15 pairwise comparisons so that a confidence level of 951/15 = 0.003
was required in the transitive picture. We use a confidence level of 0.001, resulting in a
slightly conservative analysis.
We use sufficiently large samples that the T-distribution, used by the Wilcoxon test,
is approximately normal. We therefore quote Z-values to indicate the significance in the
differences between the mean performances of the paired planners. We do not compare all
pairs of planners: in some cases the superiority of a planner over another is so clear from
examination of the raw data that statistical testing is obviated.
The Wilcoxon test tells us when one planner performs consistently better than another
and whether this consistency is statistically significant. It does not tell us how much better
one planner is than another. It could be that there is very little difference in performance —
perhaps the discrepancy can be accounted for by mere implementation differences. The
consistency with which the difference occurs determines whether there is a statistically
significant discrepancy between the performances of the planners. One planner can perform
consistently better than another even though the other wins some of the time. For example,
in a comparison between A and B, planner A might win more frequently than B because it
is faster at solving a subset of problems in the set even though it is much slower at solving
another subset of the problems. Provided the subset won by B is sufficiently large the
greater number of wins due to A will not emerge as significant. For example, in a set of 10
problems ranked according to the differences in performance, if the first 7 problems in the
ranking are won by A and the last 3 by B, A will obtain a score of 28 and B a score of 27.
In this case no significant difference emerges regardless of the magnitude of the difference
between A and B in the last three problems (see Appendix C). The rank-sum approach has
the benefit of allowing large numbers of small wins to outweigh small numbers of large wins.
This is desirable because a large win in a few problems is not an indication of overall better
performance. We are interested in trying to measure the consistency of domain-independent
behaviour and therefore in comparing the consistency of performance across domains given
that planners perform differently within domains.
The size of the win need not indicate the complexity of the underlying problem so
this does not allow us to make judgements about scalability. Essentially the test reveals
consistent patterns in performance across a range of problems. We consider this to be of
interest because knowing that one planner is significantly consistently better than another
helps us make an objective judgement about which of the two planners is performing better
across a varied problem set. If there is variability in the performances so that no consistent
pattern emerges, it is very hard — perhaps impossible — to make this judgement objectively.
In a few cases, comparison using the Wilcoxon test does not lead to any statistically
significant conclusions, but the proportion of wins by one of the planners is higher than is
consistent with the null hypothesis of equal performance. This can be tested using a Z-test
for a proportion (see Appendix C). Where this test yields a significant result we report it,
14

The 3rd International Planning Competition

as described below. This test is less informative than the Wilcoxon test as it does not take
into account how the wins are distributed through the problem set.
In performing pairwise comparisons we must deal with cases where a planner did not
solve a problem. We assign infinitely bad speed to the planner in these cases, ensuring that
maximum possible benefit is given to planners solving problems, even very slowly. This
methodology is valid because the Wilcoxon test is based on rank so the effect is simply to
push the unsolved cases to the extreme of the ranking. In the case of quality we perform
an initial collection of tests using infinitely bad quality for the unsolved problems. It
is somewhat difficult to decide what it means to compare a true quality result with the
infinitely bad quality assigned when a planner produced no solution. Our conclusion is that
this comparison may not be informative enough, so in addition we perform the Wilcoxon
test on just those cases where both planners produced a plan. We refer to these cases as
double hits.
4.3 Results of Analysis
The results of performing the Wilcoxon tests, in order to compare speed performance between fully-automated planners, are shown in Figure 4. The results of similar tests to
compare plan quality are presented in Figures 5 and 6. The double hits data are presented
in Figure 6. The corresponding tests for the hand-coded planners are shown in Figures 7
and 8.
The tables have rows corresponding to the four problem levels for which the competition
gathered sufficient data for analysis. These are: strips, numeric, simpletime and time.
There are so many results for the fully-automated planners on strips domains that they are
split over two rows, creating five rows in these tables. In the comparisons of plan quality we
report the strips results using sequential plan length and concurrent plan length separately.
The data in the rows are interpreted in the following way. Each cell, representing a pair of
planners being compared, presents the Z-value and corresponding p-value identified from
the Wilcoxon statistical table. The order of the planners’ names in the title of the cell is
significant: the first planner named is the one favoured by the comparison. Underneath
the cell is an entry indicating the size of the sample used. The sample consists of all
problems for which at least one of the planners being compared produced a solution: this
results in there being different sample sizes for different comparisons. If the p-value is no
greater than 0.001 then the difference in the mean performances obtained by the competing
planners is statistically significant and it can be concluded that the planner in that column is
significantly out-performing its competitor. If the p-value is greater than 0.001 the difference
is not significant, in terms of the transitive view in which we are interested, and the null
hypothesis that the planners are performing roughly equally cannot be rejected. We indicate
the absence of significance at the p < 0.001 level by the use of a bold font.
The Wilcoxon test tells us when there is a significant difference in mean behaviour but
it does not identify the planner producing the greater proportion of wins in cases where the
mean behaviour is insignificantly different. Therefore, when the Wilcoxon tests reports that
there is no significant difference between a pair of planners we also report the Z-value of
the proportion (see Appendix C), if significant, to provide this missing information. Where
15

Long & Fox

Strips

FF-LPG
6.2
?
120

LPG-MIPS
5.3
?
118

LPG-Sim
1.9
0.06
118

Sim-MIPS
1.9 (3.1)
0.06 (?)
114

MIPS-VHPOP
3.4
?
98

VHPOP-Stella
0.11
0.92
59

Strips

Sim-Stella
7.2
?
83

LPG-VHPOP
7
?
117

FF-MIPS
8.9
?
117

FF-Sim
7.8
?
117

MIPS-Stella
4.7
?
80

Sim-VHPOP
4.3
?
108

FF-LPG
3.5
?
93

LPG-MIPS
3.8
?
86

Simple
Time

LPG-MIPS
5
?
100

MIPS-VHPOP
2
0.04
68

VHPOP-TP4
5.9
?
54

LPG-TP4
8.4
?
100

MIPS-TPSYS
5.9
?
47

TP4-TPSYS
2.6
< 0.01
14

Time

LPG-Sapa
3.3
?
95

MIPS-Sapa
0.72
0.67
72

LPG-MIPS
3.4
?
96

MIPS-TP4
5.1
?
36

Sapa-TP4
5.2
?
38

Numeric

FF-MIPS
8
?
85

Figure 4: Table showing results of statistical tests for the comparison of speeds of planners.
Bolded results are those that are not significant at p = 0.001 level. Each cell
represents a pair of planners being compared. It presents the Z-value and corresponding p-value identified from the Wilcoxon statistical table. The order of the
planners’ names in the title of the cell is significant: the first planner named is
the one favoured by the comparison. Underneath the cell is an entry indicating
the size of the sample used. ‘?’ indicates a result less than 0.001.

16

The 3rd International Planning Competition

Strips
(Seq)

LPG-FF
0.21
0.84
120

LPG-MIPS
6.9
?
118

LPG-Sim
7.6
?
118

MIPS-Sim
0.38
0.7
114

Strips
(Seq)

Sim-Stella
5.6
?
83

LPG-VHPOP
7.7
?
117

FF-MIPS
7.2
?
117

FF-Sim
8.5
?
117

LPG-FF

MIPS-VHPOP
1.3
0.21
98

VHPOP-Stella
2.1 (3.3)
0.04 (?)
59

MIPS-Stella
5
?
80

Sim-VHPOP
0.45
0.65
108

Strips
(Conc)

6
?
120

LPG-MIPS
5.3
?
118

LPG-Sim
8.6
?
118

MIPS-Sim
2.4 (4.1)
0.01 (?)
114

MIPS-VHPOP
0.69
0.49
98

VHPOP-Stella
0.93
0.35
59

Strips
(Conc)

Sim-Stella
2.1
0.03
83

LPG-VHPOP
5.2
?
117

FF-MIPS
1.4
0.16
117

FF-Sim
8.5
?
117

MIPS-Stella
3.7
?
80

VHPOP-Sim
0.13
0.90
108

Numeric

LPG-FF
3 (4.5)
< 0.01 (?)
93

LPG-MIPS
6.1
?
86

FF-MIPS
3.5
?
85

Simple
Time

LPG-MIPS
8.7
?
100

MIPS-VHPOP
2.4 (3.5)
0.01 (?)
68

VHPOP-TP4
5.4
?
54

LPG-TP4
8.6
?
100

MIPS-TPSYS
5.6
?
47

TP4-TPSYS
2.7
< 0.01
14

LPG-Sapa
6.7
?
95

Sapa-MIPS
0.029
0.99
72

LPG-MIPS
6.6
?
96

LPG-TP4
6.6
?
57

MIPS-TP4

Time

5
?
36

Sapa-TP4
5.2
?
38

Figure 5: Table of results of statistical tests of comparisons of plan quality across problems
solved by at least one planner in each pair. Bolded results are those that are not
significant at the p = 0.001 level. ‘?’ indicates a result less than 0.001.

17

Long & Fox

Strips
(Seq)

LPG-FF
0.24
0.83
114

LPG-MIPS
4.3
?
85

LPG-Sim
5.9
?
90

MIPS-Sim
1.4
0.16
63

VHPOP-MIPS
2.9
< 0.01
56

VHPOP-Stella
4.7
?
39

Strips
(Seq)

Sim-Stella
1.8
0.08
49

LPG-VHPOP
3.6
?
68

FF-MIPS
4.6
?
86

FF-Sim
7.1
?
91

MIPS-Stella
3.1
< 0.01
44

VHPOP-Sim
5.2
?
51

Strips
(Conc)

LPG-FF
6.5
?
114

LPG-MIPS
1.5
0.14
85

LPG-Sim
7.5
?
90

MIPS-Sim
6.3
?
63

VHPOP-MIPS
3.9
?
56

VHPOP-Stella
2.7
< 0.01
39

Strips
(Conc)

Stella-Sim
6
?
49

VHPOP-LPG
3
< 0.01
68

MIPS-FF
4.8
?
86

FF-Sim
7.1
?
91

MIPS-Stella
0.24
0.83
44

VHPOP-Sim
6.1
?
51

LPG-FF
3.8
?
69

LPG-MIPS
3.2
?
46

MIPS-FF
4.2
?
50

Simple
Time

LPG-MIPS
6.6
?
58

MIPS-VHPOP
2.9 (3.8)
< 0.01 (?)
44

TP4-VHPOP
3.4
?
15

LPG-TP4
1.3
0.19
15

TPSYS-MIPS
0.61
0.54
10

TP4-TPSYS
1.8
0.07
10

Time

LPG-Sapa
4.7
?
62

MIPS-Sapa
1.6
0.09
50

LPG-MIPS
4.2
?
55

LPG-TP4
1.9
0.06
5

TP4-MIPS
1.1
0.27
5

TP4-Sapa
1.3
0.19
5

Numeric

Figure 6: Table showing results of statistical tests of comparisons between quality of plans
from pairs of planners considering only problems solved by both planners. Each
cell represents a pair of planners being compared. It presents the Z-value and
corresponding p-value identified from the Wilcoxon statistical table. The order
of the planners’ names in the title of the cell is significant: the first planner named
is the one favoured by the comparison. Underneath the cell is an entry indicating
the size of the sample used. ‘?’ indicates a result less than 0.001.

18

The 3rd International Planning Competition

Small Problems
Strips

Numeric

TL-TAL
6.8
?
102

TAL-SHOP2
0.028
0.99
102

Large Problems
TL-SHOP2
7.2
?
102

TL-SHOP2
6.5
?
102

TAL-TL
5.6
?
98

TAL-SHOP2
8.5
?
98

TL-SHOP2
8.2
?
98

TL-SHOP2
7.9
?
98

Simple
Time

TL-TAL
8.7
?
102

SHOP2-TAL
0.61
0.34
102

TL-SHOP2
7
?
102

TL-TAL
0.77
0.44
98

TAL-SHOP2
6.4
?
98

TL-SHOP2
8.4
?
98

Time

TL-TAL
8.8
?
102

TAL-SHOP2
0.2
0.84
102

TL-SHOP2
7.8
?
102

TL-TAL
3.1
?
98

TAL-SHOP2
7.3
?
98

TL-SHOP2
8
?
98

Figure 7: Table showing results of statistical tests for the comparison of speeds of handcoded planners. ‘?’ indicates a result less than 0.001.

Small Problems

Large Problems

Strips
(Seq)

TL-TAL
2.3
0.01
102

TAL-SHOP2
2
0.04
102

TL-SHOP2
5.3
?
102

TAL-TL
0.89
0.38
98

TAL-SHOP2
4.4
?
98

TL-SHOP2
3.6
?
98

Strips
(Conc)

TAL-TL
8.6
?
102

TAL-SHOP2
4.3
?
102

SHOP2-TL
7
?
102

TAL-TL
8.6
?
98

TAL-SHOP2
7
?
98

SHOP2-TL
7.7
?
98

Numeric

TL-SHOP2
0.18
0.86
102
TL-TAL

Simple
Time

1
0.32
102
TL-TAL
4
?

Time
102

TL-SHOP2
0.15
0.88
98
TAL-SHOP2
4.5
?
102

TL-SHOP2
5.3
?
102

TAL-TL
0.76
0.44
98

TAL-SHOP2
5.5
?
98

TL-SHOP2
5.4
?

SHOP2-TAL
0.26
0.80
102

TL-SHOP2
3.9
?
102

TL-TAL
2.3
0.01
98

TAL-SHOP2
0.54
0.58
98

TL-SHOP2
5.7
?
98

Figure 8: Table showing results of statistical tests on comparative quality of plans produced
by hand-coded planners. This table shows results for problems solved by at least
one of the planners — results restricted to problems solved by both are insignificantly different, since the hand-coded planners all solved almost all problems
attempted. ‘?’ indicates a result less than 0.001.

19

Long & Fox

we do this the Z-value of the proportion, and its p-value, appear in brackets following the
Wilcoxon result.
4.4 Interpretation
Our results show that the null hypothesis can be rejected. Therefore, we adopt the alternative hypothesis and here discuss the resulting partial orders inferred from the data.
The data presented in Figures 4 to 8 can be interpreted in terms of partial orderings on
the speed and quality performances of the fully-automated and hand-coded planners at each
of the four problem levels. This can be done, at each level, simply by putting an ordering
between pairs of planners from A to B when the Wilcoxon value for that pair is reported
in the sub-column associated with A and is significant at the 0.001 level. The results are
shown in Figures 9 to 12. In each of these figures sub-graphs associated with each of the
four problem levels are identified. The presence of an arrow in a graph indicates that a
statistically significant ordering exists. The absence of an arrow from A to B indicates that
no statistically significant relationship between A and B was found at the corresponding
problem level and therefore that no transitive ordering can depend on such a relationship.
4.4.1 Partial orderings based on speed
Figure 9 describes the speed comparisons that can be made between the fully-automated
planners according to the Wilcoxon test. It can be observed that ff is significantly consistently faster than the other fully-automated planners at the strips and numeric levels (the
significance of each of the arrows in the figure is sufficient to support transitive reasoning).
Indeed, at the strips and numeric levels there is an interesting linear ordering between ff,
lpg, mips and vhpop (three of which were the prize-winners amongst the fully-automated
planners) which is maintained between lpg, mips and vhpop at the simpletime level. Despite the observation that simplanner was faster, in a significant proportion of the strips
problems than mips, there is no significant Wilcoxon relationship between them so that
the four prize-winners comprise a spine of performance around which the other planners
competing at these levels are clustered. The relationship breaks down at the time level because only lpg, mips, sapa and tp4 participated. In this data set it can be seen that mips
and sapa are indistinguishable, with respect to the Wilcoxon test, but lpg is significantly
consistently faster than both.
For comparing the hand-coded planners the competition used a collection of small problems and a collection of large problems at each problem level. The large problems were
beyond the capabilities of any of the fully-automated planners. Interestingly, the handcoded planners behaved differently in the small and large problem collections. This is
most marked in Figure 10, at the strips level, where the performances of tlplan and
talplanner are inverted in the small and large problem sets. In the small simpletime
and time problems tlplan is consistently faster than either talplanner or shop2, with
talplanner and shop2 being statistically indistinguishable in these data sets. tlplan is
also consistently faster than talplanner, which is in turn consistently faster than shop2,
in the large time problems.
20

The 3rd International Planning Competition

numeric
LPG

FF

VHPOP

MIPS

SIMPLANNER

TP4

simple time
TPSYS

STELLA

strips

key:

A

B

A is consistently faster than B.

A

B

A is faster than B a significant number
of times.

SAPA
LPG

TP4
MIPS

time

Figure 9: A partial order on the fully-automated planners in terms of their relative speed
performances.

TAL
TL
SHOP2
strips (small)

TL
SHOP2

TAL

TL

SHOP 2
TAL

strips (large)

simple time (large)
TAL
TL
TL
numeric(small,large)

TAL

SHOP2

SHOP2
time (large)

simple time, time (small)

Figure 10: A partial order on the hand-coded planners in terms of their relative speed
performances.

21

Long & Fox

4.4.2 Partial orderings based on quality
The construction of the partial order on quality performance at the strips level for the
fully-automated planners is shown in Figure 11. To interpret the figures depicting quality
performance it should be noted that, at all problem levels except strips, specific quality
metrics were provided and plan quality must be measured in terms of these metrics. At the
strips level no such metrics were provided and quality is a measure of plan length — either
sequential or concurrent. In the figures we have labelled the arrows in the strips graphs
to denote whether the relationship exists in terms of sequential or concurrent ordering, or
both. Where the ordering is for both sequential and concurrent quality the arrow is left
unlabelled. It can be observed that two planners might be ordered in one direction for
sequential length and in the other for concurrent length.
As indicated above, comparison of quality performance is made difficult if one of the
two planners being compared solved many more problems than the other (this problem only
arises for the fully-automated planners because the hand-coded planners failed to solve so
few problems that the proportion of unsolved problems did not affect our tests). Using an
infinite quality measure for unsolved problems the Wilcoxon test concludes that the planner
solving the most problems has overall better quality — in other words, if one is interested
in overall solution quality one should choose the planner that solves the most problems even
if, in some cases, it produces worse quality plans than its competitor. However, we also
want to understand the relationship between the two planners in the double hits case. We
notice that consideration of just these problems sometimes inverts the relationship detected
by the first test. For example, in Figure 11 it can be observed that, at the simpletime
level, vhpop consistently produced better quality plans than tp4 across the whole problem
set but, when only double hits are considered, tp4 produced consistently better plans than
vhpop. This suggests that tp4 is solving problems with higher quality solutions, but that
the price it pays in search to find these solutions is so high that it solves a much smaller
set of problems than other planners, such as vhpop. We depict these results using dotted
arrows in the graphs. Finally, it can arise that the Wilcoxon test detects no significant
relationship between two planners, but that the difference in the proportion of problems
solved by the two planners is significant. We indicate the resulting weaker relationship using
a dashed arrow.
Figure 11 shows that lpg emerges as the fully-automated planner consistently producing
the highest quality plans at all problem levels. The relationship between ff and mips is
more complex because, whilst ff produced plans of better sequential quality than mips,
mips produced better quality concurrent plans than ff when considering only double hits.
The reason for this apparent discrepancy is that mips post-processes sequential plans into
partially ordered plans exploiting some of the available concurrency in the problem, which
ff does not exploit. However, it fails to solve a larger subset of problems than ff, giving
ff the advantage in quality overall.
In the strips problems simplanner solves more problems than stella and hence is
seen to be performing at a consistently higher sequential-plan quality level. When double
hits are considered stella outperforms simplanner in concurrent-plan quality. Also, when
double hits are considered, it can be seen that vhpop consistently outperforms stella for
22

The 3rd International Planning Competition

LPG

FF

MIPS

FF
numeric
conc

LPG

MIPS

TPSYS

seq

LPG
conc

VHPOP

SIMPLANNER

TP4

simple time
MIPS

conc

SAPA

seq
conc

VHPOP

seq

TP4

LPG
MIPS

time

STELLA

key:

B A is consistently better
than B.with confidence
at least 99.9%.

A

seq

strips

A

B A produces better plans
significantly more often
than B.

A

B

A is consistently better
than B when only double.
hits are considered.

Figure 11: The fully-automated planners depicted in terms of their relative quality performances.

strips (small)

seq
TL

TAL

conc

SHOP2

conc

TL

conc
seq

conc
TAL

SHOP2

seq

strips (large)
TL

SHOP2

TL

TAL

TAL
SHOP2
simple time (small, large)

time (small)

Figure 12: The hand-coded planners depicted in terms of their relative quality performances.

23

Long & Fox

sequential-plan quality and simplanner in all cases. Interestingly, vhpop and stella have
no Wilcoxon or proportion test relationship when all problems are considered.
mips outperforms vhpop and tpsys in the simpletime problems, with vhpop consistently better than tp4. When only double hits are considered tp4 outperforms vhpop
demonstrating that tp4 produces better quality solutions for those problems that it solves.
Given the available data it seems that tp4 and tpsys are not performing significantly differently, but it may be that the data set is too small to draw this conclusion with confidence.
In the time data set there is no significant consistent pattern in the relative performances
of sapa and mips. lpg consistently produces better quality plans.
As with the fully-automated planners we find that the speed comparisons that can be
observed do not hold when the planners are compared in terms of quality. Figure 12 shows
the quality comparisons we performed on the three competing hand-coded planners. It
shows that, in the small strips problems tlplan consistently outperformed shop2 in terms
of sequential plan quality. In the small problems talplanner produces shorter makespan
plans than both tlplan and shop2 and shop2 produces shorter makespan plans than
tlplan. tlplan produces sequential strips plans and does not use any post-processing
step to introduce parallelism. As a result it is certain to be outperformed in a makespan
comparison with planners capable of producing parallel plans.
No significant relationships emerged in the numeric problems. talplanner did not
compete in the numeric problems. No significant Wilcoxon result was established.
In the simpletime problems (both small and large) the quality performances of tlplan
and talplanner are indistinguishable, and both are consistently better than shop2. In
the time problems tlplan emerges as consistently better than talplanner and shop2.
4.4.3 Cross-boundary partial orderings
We performed a final collection of comparisons to try to better understand what advantages
can be obtained from the use of hand-coded rather than fully-automated planners, in terms
of speed and quality. We compare the best-performing fully-automated planner with the
best-performing hand-coded planner in both categories: ff with tlplan for speed, at all
levels, and lpg with talplanner at the strips level, shop2 at the numeric level and with
tlplan at the remaining problem levels, for quality.
The tables in Figures 14 and 15 show the results of the tests. Figure 13 summarises the
conclusions. It can be observed that tlplan is consistently faster than ff at all problem
levels in which they both participated, demonstrating that the control knowledge being
exploited by tlplan is giving it a real speed advantage. It remains to be seen exactly why
this should be the case, given that for several strips domains the control knowledge that is
usually described as having been encoded appears to prune no additional states over those
already pruned when an ff-style heuristic measure is used. The reason for this added value
is an interesting question for the community to consider in trying to evaluate the advantages
and disadvantages of the hand-coded approach.
It can also be observed that talplanner produces consistently better concurrent plans
than lpg at the strips level. Again, this result needs to be explained by an in-depth
analysis of the control information being exploited by talplanner. At the simpletime
level lpg produces plans that are consistently better quality than those of tlplan.
24

The 3rd International Planning Competition

TL

LPG

FF

all levels (speed)

simple time (quality)
Key:

TAL

conc

TL

A

B

A is consistently faster/better quality than B

Notes:
There is no significant quality difference between FF and TLplan at the STRIPS level.
There is no significant difference between SHOP2 and LPG at the numeric level.
There is no significant difference between TLPlan and LPG at the time level.

LPG

strips (quality)

Figure 13: A comparison between the best of the fully-automated planners and the best of
the hand-coded planners at each problem level.

Strips

TLPlan-FF
6.7
< 0.001
102

Numeric

SHOP2-LPG
8.2
< 0.001
102

SimpleTime

TLPlan-LPG
8.6
< 0.001
102

Time

TLPlan-LPG
8.7
< 0.001
102

TAL-LPG
7.8
< 0.001
102

TAL-VHPOP
8.5
< 0.001
102

Figure 14: Table of results for comparisons of fully-automated and hand-coded planners
in terms of speed. Each cell represents a pair of planners being compared. It
presents the Z-value and corresponding p-value identified from the Wilcoxon
statistical table. The order of the planners’ names in the title of the cell is
significant: the first planner named is the one favoured by the comparison.
Underneath the cell is an entry indicating the size of the sample used.

25

Long & Fox

Problems solved by at least one

Problems solved by both

Strips
(Seq)

TLPlan-FF
0.57
0.57
102

LPG-TAL
1.8 (3.9)
0.08 (< 0.001)
102

TAL-VHPOP
2.9
< 0.01
102

FF-TLPlan
0.35
0.72
97

LPG-TAL
2.4 (4.2)
0.01 (< 0.001)
99

VHPOP-TAL
4.9
< 0.001
67

Strips
(Conc)

TLPlan-FF
0.57
0.57
102

TAL-LPG
5.9
< 0.001
102

TAL-VHPOP
6.4
< 0.001
102

FF-TLPlan
0.35
0.72
97

TAL-LPG
5.6
< 0.001
99

TAL-VHPOP
2.6
< 0.01
67

Numeric

SHOP2-LPG
1.9
0.06
102

LPG-SHOP2
1.6
0.11
83

Simple
Time

LPG-TLPlan
3.9
< 0.001
102

LPG-TLPlan
4.3
< 0.001
100

Time

TLPlan-LPG
0.093
0.92
102

LPG-TLPlan
1.6
0.11
93

Figure 15: Table of results of comparisons of plan quality between fully-automated and
hand-coded planners.

It is interesting to observe that hand-coding control information does not appear to lead
to any consistent improvement in plan quality across the data sets. It does seem to lead
to a speed advantage which must indicate that, in general, control rules provide a basis
for more efficient pruning than weak general heuristic measures. The Wilcoxon test does
not measure the extent of the speed advantage obtained, nor does it measure the extent of
the quality advantage obtained from using a fully-automated planner in preference. These
trade-offs need further close analysis, but it is interesting to see that there was not in fact a
uniform advantage obtained by the hand-coded planners, at least on the smaller problems
that formed the common foundation for testing. Of course, the development of hand-coded
control knowledge can prioritise different aspects of the solutions generated and it is possible
that further development of control rules might support the construction of more heavily
optimised plans.

5. Tests for Magnitude
To complement the Wilcoxon tests we perform some additional analyses to identify whether,
given two planners being compared, the magnitude of the difference in performance between
the two planners is statistically significant. We perform paired t-tests (see Appendix C)
using a subset of pairs of planners. We focus our attention on those pairs for which consistent significant differences were identified, because we consider it not to be meaningful to
compare magnitude results for planners where no consistent domination is exhibited. We
also restrict our attention to the planners that were, according to the Wilcoxon tests, the
26

The 3rd International Planning Competition

most impressive performers at each of the competition levels. We perform separate tests
for speed and quality.
When investigating the magnitude of differences in performances it is not meaningful
to include problems which were not solved by one of the planners being compared. Using
infinite time or quality measures would result in a magnitude value that would grossly
distort the true picture. For the magnitude tests we therefore consider only double hits.
The price we pay for this is that we give undesirable emphasis to the smaller and easier
problems since these are the ones most frequently solved by both planners. This should be
borne in mind when interpreting the data.
The hypotheses being considered in this section are:
Null Hypothesis: There is no consistent magnitude difference in the performances between planners.
Alternative Hypothesis: Planners that demonstrate significant differences in consistency of performance also demonstrate corresponding magnitudes
in the differences between their performances.
5.1 Analytic Framework
The t-tests are performed using the normalised performances of the two planners. They
find the magnitude of difference between the performances of two planners, p1 and p2 , on a
collection of problem instances. For example, given a collection of n problems, we find the
pairs of results p1ri and p2ri obtained for instances i = 1 to i = n. In each case we normalise
these values by dividing each of them by the mean of the pair. This process establishes
a range of performances between 0 and 2, with 1 standing for equal performance. The
t-test results in a t-value representing the difference in the mean normalised performances
of the two planners. We perform 2-tailed tests at p < 0.05 because we are interested in
the individual results rather than in extrapolated partial orderings based on magnitude.
We want to consider the magnitude information as it is relevant to individual consistency
results.
5.2 Results of Analysis
The tables in Figures 16 to 20 are organised as follows. Tables in Figures 16, 18 and 20
contain the speed results found for the fully-automated, hand-coded and mixed pairs respectively. Tables in Figures 17, 19 and 20 contain the quality results for the same three
groups. In each table there is a row for each of the five competition levels (although empty
rows have been omitted). The columns represent the pairs of planners being compared.
In each cell five pieces of data are reported: the mean normalised performance for each
planner; the t-value computed and the degrees of freedom used (which is derived from the
number of double hits at that level) and the resulting p-value. A positive t-value means that
the magnitude difference is in favour of the planner identified second in the cell. A negative
t-value is in favour of the planner identified first. Where the resulting t-value indicates a
difference in magnitude that is not significant at the p=0.05 level we use a bold font. In
both speed and quality tests, an average performance smaller than 1 is favourable for a
planner. The interpretation of the value is that it represents the average proportion of the
27

Long & Fox

strips

numeric

simpletime

time

FF 0.4
LPG 1.6
-12.26,113
< 0.001
FF 0.23
LPG 1.77
-16.04,68
< 0.001
LPG 1.03
MIPS 0.97
0.35,57
0.73
LPG 1.25
MIPS 0.75
2.64,54
0.008

MIPS 1.21
LPG 0.79
2.69,84
0.007
MIPS 0.8
LPG 1.2
-1.84,45
0.06
MIPS 0.85
VHPOP 1.15
-1.43,43
0.15
LPG 1.16
Sapa 0.84
1.81,61
0.07

FF 0.22
MIPS 1.78
-21.30,85
< 0.001

LPG 0.76
VHPOP 1.24
-2.82,67
0.005

LPG 1.28
Sim 0.72
3.73,89
< 0.001

Sim 0.26
VHPOP 1.74
-15.19,50
< 0.001

MIPS 0.77
Sapa 1.23
-3.41,49
< 0.001

Figure 16: Magnitude comparisons for fully-automated planners in terms of speed.
strips (seq)

strips (conc)

numeric

simpletime

time

MIPS 1.05
LPG 0.95
5.61,84
< 0.001
FF 1.18
LPG 0.82
9.70,113
< 0.001
FF 1.17
LPG 0.83
6.00,68
< 0.001
LPG 0.86
MIPS 1.14
-7.98,57
< 0.001
LPG 0.9
MIPS 1.1
-3.44,54
< 0.001

FF 0.95
MIPS 1.05
-5.39,85
< 0.001
FF 1.13
MIPS 0.87
6.81,85
< 0.001
FF 1.01
MIPS 0.99
0.14,49
0.89
MIPS 0.93
VHPOP 1.07
-3.97,43
< 0.001
LPG 0.86
Sapa 1.14
-4.99,61
< 0.001

LPG 0.98
VHPOP 1.02
-2.73,67
0.006
LPG 0.7
Sim 1.3
-12.95,89
< 0.001
MIPS 1.2
LPG 0.8
4.25,45
< 0.001

LPG 0.91
Sim 1.09
-7.21,89
< 0.001
Sim 1.33
VHPOP 0.67
14.37,50
< 0.001

Sim 1.08
VHPOP 0.92
6.01,50
< 0.001

Figure 17: Magnitude comparisons for fully-automated planners in terms of quality.

mean performances of a pair of planners on each test set. Thus, an average performance of
0.66 for a planner (which will compare with an average performance of 1.34 for the other
planner in the pair being considered) means that the first planner is, on average, twice as
fast as the second.
5.3 Interpretation
The results demonstrate that the null hypothesis can be rejected in almost all pairwisecomparisons of planners for which the Wilcoxon test shows a significant consistent performance difference. There are some cases in which the null hypothesis cannot be rejected,
implying that the consistent performance difference in a pair of planners does not translate
into a statistical significance in their mean relative performances.
28

The 3rd International Planning Competition

strips

numeric

simpletime

time

Small Problems
TLPlan 0.52
TLPlan 0.61
TAL 1.48
SHOP2 1.39
-12.98,101
-8.32,101
< 0.001
< 0.001
TLPlan 0.7
SHOP2 1.3
-6.21,101
< 0.001
TLPlan 0.43
TLPlan 0.67
TAL 1.57
SHOP2 1.33
-21.34,101
-7.79,101
< 0.001
< 0.001
TLPlan 0.44
TLPlan 0.59
TAL 1.56
SHOP2 1.41
-25.00,101
-10.14,101
< 0.001
< 0.001

TLPlan 1.32
TAL 0.68
7.74,97
< 0.001
TLPlan 0.31
SHOP2 1.69
-19.22,92
< 0.001
TLPlan 0.32
SHOP2 1.68
-24.27,97
< 0.001
TLPlan 0.82
TAL 1.18
-5.75,97
< 0.001

Large Problems
TLPlan 0.39
TAL 0.24
SHOP2 1.61
SHOP2 1.76
-17.41,97
-26.04,97
< 0.001
< 0.001

TAL 0.48
SHOP2 1.52
-11.28,97
< 0.001
TLPlan 0.31
SHOP2 1.69
-23.75,95
< 0.001

TAL 0.46
SHOP2 1.54
-12.81,95
< 0.001

Figure 18: Magnitude comparisons for hand-coded planners in terms of speed.
Small Problems
strips (seq)

strips (conc)

simpletime

time

TLPlan 0.96
SHOP2 1.04
-5.48,101
< 0.001
TLPlan 1.38
TAL 0.62
21.10,101
< 0.001
TLPlan 0.89
SHOP2 1.11
-7.66,101
< 0.001
TLPlan 0.9
TAL 1.1
-4.39,101
< 0.001

TLPlan 1.27
SHOP2 0.73
11.81,101
< 0.001
TAL 0.93
SHOP2 1.07
-3.82,101
< 0.001
TLPlan 0.94
SHOP2 1.06
-4.08,101
< 0.001

TAL 0.88
SHOP2 1.12
-5.15,101
< 0.001

TLPlan 0.96
SHOP2 1.04
-3.82,97
< 0.001
TLPlan 1.7
TAL 0.3
48.66,97
< 0.001
TLPlan 0.85
SHOP2 1.15
-6.85,97
< 0.001
TLPlan 0.88
SHOP2 1.12
-6.46,95
< 0.001

Large Problems
TAL 0.98
SHOP2 1.02
-2.13,97
0.033
TLPlan 1.5
TAL 0.75
SHOP2 0.5
SHOP2 1.25
16.58,97
-8.94,97
< 0.001
< 0.001
TAL 0.87
SHOP2 1.13
-4.80,97
< 0.001

Figure 19: Magnitude comparisons for hand-coded planners in terms of quality.
Speed
strips

simpletime

time

TLPlan 0.55
FF 1.45
-7.60,96
< 0.001
LPG 1.9
TLPlan 0.1
38.14,99
< 0.001
LPG 1.9
TLPlan 0.1
26.85,92
< 0.001

Quality
Seq
Conc
TLPlan 1
TAL 1.04
TAL 0.84 TLPlan 1.23
FF 1
LPG 0.96
LPG 1.16
LPG 0.77
0.54,96
3.89,98
-7.16,98
12.54,98
0.589
< 0.001
< 0.001
< 0.001
LPG 0.94
TLPlan 1.06
-3.89,99
< 0.001

Figure 20: Comparisons between fully-automated and hand-coded planners in terms of both
speed and quality.

29

Long & Fox

As shown in tables 16 to 20, a reassuring consistency emerged with the results of the
Wilcoxon tests. That is: where significant consistency differences are identified between two
planners using the Wilcoxon test, the t-test for magnitude generally reveals a significant
magnitude difference as well.

6. Dependence of Performance on Domain
We consider it important to quantify the difficulty of the problems used in the competition
because this provides the basis for a deeper understanding of relative planner performance.
To explore this we investigate whether any of the domains that were used were uniformly
considered easy, or hard, amongst the fully-automated and hand-coded planners. We also
investigate whether, as might be expected to be the case, the strips problems were generally
considered to be easier than the problems at the numeric and temporal levels. These
two questions lead to two related investigations based on bootstrapping techniques. Our
analyses show that different planners experienced different domains and levels as difficult,
within both the fully-automated and the hand-coded categories.
In the first competition, in 1998, it was reported (Long, 2000) that no planner solved
any problem with more than about 25,000 ground actions and that 10,000 ground actions
marked a limit beyond which planner performance was markedly unreliable. A ground
action is formed by replacing action schema parameters with objects of the correct types
selected from those in a problem instance. Any static preconditions — preconditions whose
truth can be ascertained entirely from the initial state — are used to filter the ground
actions, so that only those that are plausibly applicable are counted. Relevant ground
actions are found by applying a reachability analysis from the initial state and a regression
analysis from the goals in order to identify the subset of ground actions that could actually
play any useful role in the plan. It seems plausible that the number of ground actions could
offer a guide to the difficulty of problems. In fact, a brief survey of the largest problems
in the third competition, in Figure 21, reveals that action counts can vary widely across
domains. It is encouraging to observe that the size of problems that can be solved with
reasonable reliability, at least in some domains, has grown significantly, despite the fact that
it is still typical for planners to ground the action set prior to planning. It is also of interest
to observe that the size of problems measured by action counts is not a strong indication
of difficulty — problems from the Rovers and Satellite domains were amongst those found
harder by many of the planners, despite having small action counts.
To summarise, the hypotheses being explored in this section are:
Null Hypothesis: The domains used in the competition were equally challenging to all planners at all levels.
Alternative Hypothesis: Domain/level combinations can be distinguished
in terms of relative difficulty posed to different planners.
For ease of comparison with the results presented in Sections 7 and 8 we observe that,
in this section, we are specifically concerned with a cross-domain analysis and with whether
the planners agreed on which of the domain/level combinations were hard.
30

The 3rd International Planning Competition

Domain
Depots
DriverLog
ZenoTravel
Rovers
Satellite
FreeCell
Settlers

Largest Ground Action Count
332,064
31,140
32,780
7,364
4,437
112,600
5,884

Largest Relevant Action Count
22,924
15,696
32,780
3,976
4,437
25,418
4,503

Figure 21: Counts of ground action instances (generated using FF).

6.1 Analytic Framework
In order to explore the two questions, we used the planners to discover how hard the domains
and levels were. For each planner, domain and problem level we plot the number of problem
instances left to solve against time in milliseconds. This results in a curve, the area under
which can be taken to be a measure of the difficulty experienced by the planner in solving
problems in the given domain at the given problem level. In order to keep the area under
the curve finite we use a cut-off time of thirty minutes. This extended cut-off time (fifteen
minutes was used in the competition) results in a higher penalty being paid by a planner
that fails to solve problems.
In the experiment used to address the first question, the null hypothesis is that the
planner finds all problems at a specific level equally difficult across all domains. To test this
we constructed, using a bootstrapping technique, ten thousand samples of twenty values
from the collection of all timings obtained from domains at the appropriate level. The values
were selected at random from the performances of planners competing in the domains, one
value for each of a collection of randomly selected problems. For example, if problem one
was chosen from DriverLog, problem two from Depots, problem three from Rovers, problem
four from Depots, etc., then the value associated with problem one would be that produced
for that problem by a planner selected at random from those that competed in DriverLog.
Similarly, the value associated with problem two would be chosen from a planner that
competed in Depots, and so on. For each collection of 20 values we plotted the number
of problem instances left to solve against time, as above. This resulted in a sampling
distribution of level-specific areas. Using these bootstrap samples we check whether the
area calculated for the particular planner-domain-level combination lies at the extremes of
this distribution, or not. If it lies in the first 2.5% of the distribution we reject the null
hypothesis on the grounds that the planner found problems at that level, in that domain,
to be significantly easy. If it lies in the top 2.5% of the distribution we reject the null
hypothesis and conclude that those problems were significantly hard for that planner.
In testing the relative hardness of problem levels within a domain (the second question),
we perform similar experiments in which, for each planner, the bootstrapped samples were
obtained by sampling timings from all problem levels within all domains. This resulted in a
new sampling distribution of the level-independent area statistic. The null hypothesis, that
the domain/level combination is not an indicator of difficulty, is tested by seeing whether
31

Long & Fox

Depots
DriverLog
ZenoTravel
Rovers
Satellite
FreeCell
Settlers

strips
[6]
1/3
0/1
3/0
2/1
4/0
1/2
–

Level-dependent
numeric simpletime
[3]
[3]
1/0
0/1
2/0
1/0
2/0
1/0
0/1
0/1
0/2
1/0
–
–
0/2
–

time
[3]
0/1
2/0
1/0
1/1
1/0
–
–

strips
[6]
2/2
1/0
4/0
3/1
4/0
2/2
–

Level independent
numeric simpletime
[3]
[3]
1/1
0/1
0/0
1/0
2/0
0/0
0/2
0/1
0/2
2/0
–
–
0/2
–

time
[3]
0/1
1/0
0/1
0/1
1/0
–
–

Figure 22: Comparisons of performance between domains for fully-automated planners.

the areas computed for planner-domain-level combinations are extreme with respect to the
new sampling distribution.
6.2 Results of Analysis
Figures 22 to 25 report the results of the two experiments described above. Figures 22
and 23 describe the level-specific and level-independent comparisons we made using the
fully-automated planners and the hand-coded planners respectively. The table for the handcoded planners is further divided into two parts: the first five rows correspond to the small
problems, the latter five rows to the large problems. The performance of the hand-coded
planners on the large problems was measured using bootstrapped samples taken from the
large problem collection.
The tables are organised as follows: the rows correspond to domains, as labelled, and
the columns to the levels considered and the number of planners used. The number of
planners varies between columns because different planners participated at the different
domain levels. For example, more planners participated at the strips level than at any of
the others. When planners produced too little data to justify statistical analysis they were
not included in the tests. Thus, of the eleven fully-automated planners in the competition
seven produced enough data for analysis in these experiments.
The cells of the tables contain two integer values separated by a diagonal. The value
on the left of the diagonal indicates the number of planners that found the problems in
the corresponding domain and level significantly easy. The value on the right indicates the
number that found those problems significantly hard. Thus, it can be seen in Figure 22
that of the six fully-automated planners that participated at the strips level of the Depots
domain, one found the problems easy and three found them hard. For the other two
planners the areas calculated using the method explained above were not found to be
sufficiently extreme for rejection of the null hypothesis. Broadly speaking (we discuss the
interpretation of the data in detail below) the four left-hand columns tell us whether the
problems in a particular domain and level were easy or hard relative to other problems at
that level; the four right-hand columns tell us whether they were easy or hard relative to all
other problems. In addition, the rows allow us to compare domains for relative difficulty:
for example, none of the planners found ZenoTravel to be hard at any level relative to other
problems at the same level, whilst Depots and Rovers were found to be hard by at least one
competitor at all levels.
32

The 3rd International Planning Competition

Depots
DriverLog
ZenoTravel
Rovers
Satellite
Depots (large)
DriverLog (large)
ZenoTravel (large)
Rovers (large)
Satellite (large)

strips
[3]
2/0
0/0
3/0
0/2
2/1
2/0
0/1
3/0
1/1
1/0

Level-dependent
numeric simpletime
[2]
[3]
2/0
1/0
2/0
0/0
1/0
3/0
0/1
0/3
0/1
2/1
2/0
2/0
1/0
0/1
1/0
3/0
0/0
1/1
0/1
2/0

time
[3]
3/0
3/0
3/0
0/2
0/1
3/0
1/1
3/0
1/0
0/2

strips
[3]
3/0
3/0
3/0
1/0
2/0
2/0
0/0
3/0
2/0
1/0

Level-independent
numeric simpletime
[2]
[3]
2/0
3/0
1/0
2/0
1/0
3/0
0/1
0/1
0/0
2/1
1/0
2/0
0/0
0/1
1/0
3/0
0/0
2/0
0/1
2/0

time
[3]
3/0
0/0
2/0
0/2
0/1
2/0
0/1
3/0
0/0
0/1

Figure 23: Comparisons of performance between domains using hand-coded planners.
The level-independent tests are reported in exactly the same way in the right-hand halves
of Figures 22 (for the fully-automated comparison) and 23 (for the hand-coded comparison).
These tables tell us whether the problems in a particular domain and level are easy or hard
relative to problems from other domains irrespective of level.
The data presented in Figures 24 and 25 show which planners found which domain-level
combinations easy or hard as discussed with reference to the tables in Figures 22 and 23.
This information might contribute to an understanding about which planning approaches
are likely to be suited to what kinds of problems, although further analysis would be needed
to pursue this question.
The tables are organised as follows. There is a row for each of the individual planners,
indicating which domain-level combinations were found to be easy or hard for the corresponding planner. Associated with the categorization of a combination as easy or hard is
the p-value indicating the statistical significance of this finding. We have presented only the
findings that were significant at the 5% level. Because this is a two-tailed test (we had no
a priori knowledge to help us to determine whether a problem would be easy or hard) the
critical value at the easy end is 0.025. At the hard end the critical value is 0.975. Figure 24
shows our findings for the fully-automated planners. Figure 25 shows the same information
with respect to the hand-coded planners.
6.3 Interpretation
The results allow us to reject the null hypothesis in some cases, but not in others. We are
able to determine significant differences in the relative hardness of domains as determined by
specific planners, but there is also evidence of lack of consistency between the judgements of
different planners. For example, there are some domain/level combinations that are found
hard by certain planners and not by others.
The tables in Figures 22 and 23 allow us to determine which domains presented the
most interesting challenges to the planners participating in the competition. Although it is
difficult to draw firm conclusions from data that is really only indicative, some interesting
patterns do emerge. For example, the level-specific data in Figure 22 shows that none of the
fully-automated planners found ZenoTravel problems, at any levels, to be significantly hard
by comparison with problems drawn from other domains at the same level. The Satellite
33

Long & Fox

FF

LPG

MIPS

Sapa
Simplanner
Stella
VHPOP

Easy
Depots Numeric
Depots Strips
FreeCell Strips
Rovers Strips
Satellite HardNumeric
Satellite Strips
ZenoTravel Numeric
ZenoTravel Strips
Rovers Strips
Satellite SimpleTime
Satellite Strips
DriverLog HardNumeric
DriverLog SimpleTime
DriverLog Strips
DriverLog Time
FreeCell Strips
Satellite HardNumeric
ZenoTravel Numeric
ZenoTravel Strips
Satellite Time
Depots Strips
ZenoTravel Strips
Satellite Strips
ZenoTravel Strips
Rovers Strips
Satellite SimpleTime
Satellite Strips

0.015
0.012
0.017
0
0
0.0007
0.0026
0.0015
0.0007
0.019
0.0001
0.0046
0.0094
0.0088
0.0093
0
0
0.01
0.0021
0.0017
0.0003
0.013
0.016
0
0
0.0006
0.0004

Hard
Rovers Numeric
Settlers Numeric

1
1

Satellite Numeric
ZenoTravel Time

1
0.98

Depots Numeric
Rovers Numeric
Rovers Time
Satellite Complex
Satellite Numeric
Settlers Numeric

0.99
0.98
0.98
0.98
1
1

Depots Time
Rovers Strips
Depots Strips
FreeCell Strips
Depots SimpleTime
Depots Strips
FreeCell Strips
Rovers SimpleTime

Figure 24: Easy/hard boundaries for fully-automated planners.

34

1
1
1
1
1
1
1
0.98

The 3rd International Planning Competition

SHOP2

TALPlanner

TLPlan

Easy
Depots Numeric
Depots SimpleTime
Depots Strips
Depots Time
Depots HC SimpleTime
Depots HC Strips
Depots HC Time
DriverLog HardNumeric
DriverLog SimpleTime
DriverLog Strips
Satellite SimpleTime
Satellite Strips
Satellite HC SimpleTime
Satellite HC Strips
ZenoTravel Numeric
ZenoTravel SimpleTime
ZenoTravel Strips
ZenoTravel Time
ZenoTravel HC Numeric
ZenoTravel HC SimpleTime
ZenoTravel HC Strips
ZenoTravel HC Time
Depots SimpleTime
Depots Strips
Depots Time
Depots HC SimpleTime
Depots HC Strips
DriverLog Strips
Rovers Strips
Rovers HC SimpleTime
Rovers HC Strips
ZenoTravel SimpleTime
ZenoTravel Strips
ZenoTravel HC SimpleTime
ZenoTravel HC Strips
ZenoTravel HC Time
Depots Numeric
Depots SimpleTime
Depots Strips
Depots Time
Depots HC Numeric
Depots HC Time
DriverLog HardNumeric
DriverLog Numeric
DriverLog SimpleTime
DriverLog Strips
Rovers HC SimpleTime
Rovers HC Strips
Satellite SimpleTime
Satellite Strips
Satellite HC SimpleTime
ZenoTravel SimpleTime
ZenoTravel Strips
ZenoTravel Time
ZenoTravel HC SimpleTime
ZenoTravel HC Strips
ZenoTravel HC Time

0.0031
0.0057
0.0001
0.0088
0.0001
0
0.0006
0.015
0.015
0.019
0
0
0
0
0.0018
0.0003
0.0001
0.0043
0.0001
0
0
0.0001
0
0
0.013
0.0029
0
0
0.0026
0.0009
0
0
0
0
0
0.017
0.0009
0.01
0.0009
0.0003
0
0.0084
0.0051
0.0083
0.02
0.0009
0.0037
0.013
0
0
0.0001
0
0
0.0014
0
0
0

Hard
Rovers Numeric
Rovers Time

DriverLog HC SimpleTime
DriverLog HC Time
Rovers SimpleTime
Rovers Time
Satellite SimpleTime
Satellite Time
Satellite HC Time

Satellite HardNumeric
Satellite HC Complex
Satellite HC Numeric

1
1

1
1
0.99
1
0.98
1
1

1
1
1

Figure 25: Easy/hard boundaries for hand-coded planners. Note: HC indicates the larger
problems used only for the hand-coded planners.

35

Long & Fox

strips problems were significantly easy, by comparison with other strips problems, for the
majority of the participating planners, and not hard for any of them. On the other hand
the Satellite numeric problems were found to be challenging relative to other numeric
problems. Figure 23 shows that the hand-coded planners found ZenoTravel problems easy
at all levels, by comparison with problems at similar levels, and this remains true for the
large problem instances. Depots problems were also easy for the hand-coded planners.
When we consider the level-independent picture in the right-hand halves of Figures 22
and 23 we can observe that ZenoTravel emerges as significantly easy for the fully-automated
planners, across all levels, by comparison with other problems irrespective of level. This
pattern is broken by only one full-automated planner (lpg) finding these problems hard
at the time problem level. The Satellite domain is similarly easy for the fully-automated
planners, at all levels except numeric. It can be noted that the number of planners finding
the strips problems easy in the level-independent comparisons is surprisingly high. The
interpretation is that the problems in the population as a whole are much harder, so that
the performance on strips problems is pushed to the extremes of the performance on all
problems. The hand-coded planners found the Depots and ZenoTravel problems to be
uniformly easy at all levels.
Considering both the fully-automated and the hand-coded planners, the DriverLog,
Rovers and Satellite domains present the most varied picture, suggesting that the problems
in these domains presented the greatest challenges overall. All of the hand-coded planners
found the simpletime Rovers problems significantly hard relative to other simpletime
problems, but only one found these problems amongst the hardest that they had to solve
overall. Interestingly, the perceived difficulty of the small Rovers problems does not persist
into the large problems.
An interesting comparison can be made between the results of the analysis for strips
domains and the work of Hoffmann (2003b) analysing the topologies of strips and adl
versions of the common planning benchmark domains. Hoffmann examines the behaviour
of the h+ function, measuring relaxed distances between states in the state spaces for these
problems, in order to determine whether the function offers a reliable guide to navigate
through the state space in search of plans. According to Hoffmann’s analysis, the strips
versions of Depots, DriverLog and Rovers have local minima in the function and can have
arbitrarily wide plateaus (sequences of states with equal values under h+ ). These features
can make problem instances in these domains hard for planners relying on h+ (or approximations of it) to guide their search. This includes most of the fully-automated planners
in the competition. However, interestingly, several of the fully-automated planners found
one or more of these three domains to be easy at the strips level (although in a few cases
they were found to be hard). As Hoffmann points out, the potential hardness of a domain
does not mean that all collections of problem instances from that domain are hard. Our
observations seem to suggest that the competition collections posed instances that tended
towards the easy end of the spectrum. This was unintentional and demonstrates that it
can be difficult to obtain a good spread of challenges, particularly when generating problems automatically. Satellite and ZenoTravel domains have, in contrast, constant-bounded
plateaus and therefore the h+ function is a reliable guide in navigating the state space
for these domains. Interestingly, in our analysis all fully-automated planners found these
domains either easy or neither easy nor hard at the strips level.
36

The 3rd International Planning Competition

7. Scaling Issues
Section 6 addressed the issue of relative difficulty of problems without considering the question of whether planners agree about the difficulty of specific problems. The results of
that section allow us to conclude that there is no overall consensus about which of the
competition domains and levels were found hard, but it does not allow us to determine
which planners agreed or disagreed on particular domains and levels. In order to look at
the relative scaling behaviour of planners we need to identify the extent of such agreement.
This is because to examine scaling behaviour it is necessary to have a scale that measures
performance in a way that is meaningful to both planners in a comparison. The analysis
described in this section therefore seeks to establish statistical evidence of such agreement.
In order to evaluate scaling behaviour we first explore whether the competing planners
agree on what makes a problem, within a particular domain and level, hard. Although it
might seem straightforward to ensure that a problem set consists of increasingly difficult
problems (for example, by generating instances of increasing size) in fact it is not straightforward to achieve this. It appears that problem size and difficulty are not strongly correlated,
whether size is taken as a measure of the number of objects, the number of relations or even
the number of characters in a problem description. Although a coarse relationship can be
observed — very large instances take more time to parse and to ground — small instances
can sometimes present more difficult challenges than large instances. This indicates that
factors other than size appear to be important in determining whether planners can solve
individual instances.
In summary, the hypotheses explored in this section are:
Null Hypothesis: The planners differ in their judgements about which
individual problem instances are hard within a given domain/level combination.
Alternative Hypothesis: The planners demonstrate significant agreement
about the relative difficulties of the problem instances within any given domain/level combination.
In this section we are specifically concerned with a within-domain/level analysis and
with whether planners agree on the relative difficulty of problem instances within a given
domain/level combination.
7.1 Analytic Framework
As discussed in Section 6, we use the planners themselves as judges to determine how
difficult individual problems were. Given that most of the competing planners proceeded
by first grounding the problem instance and then by searching the problem space using some
variation on the theme of a relaxed distance estimate, there seems little reason to believe
that the planners would strongly diverge. If a particular instance, or family of instances,
proved difficult for one planner it might be expected that this same collection would be
challenging for all the competitors. To avoid being distracted by the impact of hand-coded
control rules we separate the judgements of the fully-automated planners from those of the
hand-coded planners. For each domain/level combination the hypothesis is that planners
37

Long & Fox

Fully
Automated
Depots
DriverLog
ZenoTravel
Rovers
Satellite
FreeCell
Settlers

Strips

Numeric

F21,110 = 5.3
F19,100 = 17.1
F19,100 = 21.7
F19,80 = 4.54
F19,100 = 7.36
F19,100 = 6.21

F21,44 = 5.48
F19,40 = 17.4
F19,40 = 14
F18,38 = 9.47
F15,48 = 1.74

HardNumeric

SimpleTime

Time

F19,20 = 11.8

F21,66 = 1.77
F19,60 = 4.44
F19,60 = 9.4
F19,60 = 4.25
F19,60 = 3.6

HardNumeric

SimpleTime

Time

Complex

F21,44 = 4.54
F19,40 = 5.34
F19,40 = 5.54
F19,40 = 28.3
F19,40 = 5

F21,44 = 6.21
F19,40 = 6.52
F19,40 = 4.22
F19,40 = 18
F19,40 = 20.6

F19,20 = 51.3

F19,40 = 4.05

F20,63
F19,60
F17,36
F19,40
F19,60

= 2.14
= 4.63
= 12.1
= 6.92
= 4.19

Complex

F19,60 = 3.78

F5,6 = 1.6

Hand-Coded
(Small)
Depots
DriverLog
ZenoTravel
Rovers
Satellite
Hand-Coded
(Large)
Depots
DriverLog
ZenoTravel
Rovers
Satellite

Strips

Numeric

F21,44 = 2.49
F19,40 = 2.58
F19,40 = 2.93
F19,40 = 4.5
F19,40 = 7.25

F21,22 = 2.19
F19,20 = 3.73
F19,20 = 8.3
F19,20 = 36.5
F19,20 = 38.7

Strips

Numeric

F21,44
F19,40
F19,40
F19,40
F15,32

= 11.4
= 61.4
= 3.14
= 17.2
= 20.8

F21,22
F19,20
F19,20
F19,20
F15,16

= 3.76
= 57.3
= 1.47
= 29.9
= 33.5

F19,20 = 6.45

F19,20 = 9.4
HardNumeric

F19,20 = 66.4

SimpleTime
F21,44 = 13.8
F19,40 = 91.6
F19,40 = 3.54
F19,40 = 33
F15,32 = 43.7

Time
F21,44
F19,40
F19,40
F19,40
F15,32

= 10.8
= 80.5
= 3.37
= 49.4
= 88.5

Complex

F15,16 = 152

Figure 26: F-values for the multiple judgments rank correlation tests.

tend to agree about the relative difficulties of the problems presented within that domain
and level.
To explore the extent to which agreement exists we perform rank correlation tests for
agreement in multiple judgements (Kanji, 1999) (we refer to this test as an MRC). In our
experiment the judges are the planners and the subjects are the problem instances. We
perform a distinct MRC for each domain/level combination, showing in each case how the
planners ranked the instances in that domain and level. We therefore perform 25 MRCs for
the fully-automated planners (there were 25 distinct domain/level pairs in which the fullyautomated planners competed), 23 for the hand-coded planners on the small problems (the
hand-coded planners did not compete in the Freecell strips or Settlers numeric domains)
and 22 for the hand-coded planners on the large problems (amongst which there were no
Satellite hardnumeric instances). The results of these tests are shown in Figure 26. In
each test the n planners rank the k problem instances in order of time taken to solve.
Unsolved problems create no difficulties as they are pushed to the top end of the ranking.
The MRC determines whether the independent rankings made by the n planners agree. The
test statistic follows the F-distribution with (k − 1, k(n − 1)) degrees of freedom determining
whether the critical value is exceeded.
7.2 Results of Analysis
The cells in Figure 26 report the F values obtained (and the degrees of freedom used). In
almost all cases the critical value was exceeded and the null hypothesis of non-agreement
could be rejected for at least the 0.05 level. In just a few cases (those reported in bold
38

The 3rd International Planning Competition

font) the critical value was not exceeded and no statistical evidence was therefore found
of agreement between the planners about the difficulty of instances in the corresponding
domain and level. It is interesting to note that the problematic cases are all within the
numeric level, for both fully-automated and hand-coded planners. Furthermore, the case
that comes closest to the critical boundary (the small Depots numeric problems, in the
hand coded table, with an F-value of 2.19) is also within the numeric level.
7.3 Interpretation
The results support rejection of the null hypothesis in almost all cases. We can therefore
adopt the alternative hypothesis, observing that there are many cases in which planners do
agree on the relative difficulties of problem instances within a given domain/level combination.
During the competition we observed that talplanner is at a disadvantage with respect
to the other hand-coded planners, in terms of comparative speed, when running on small
problems. This is probably because of the java virtual machine start-up time which becomes
significant relative to actual solution time on small instances. We see the effects of this startup time in the tables. Note that, in those domain/level combinations in which talplanner
competed (strips, simpletime and time) we see a low level of agreement amongst the
hand-coded planners on the small problems (except in the case of the Rover domain).
This is not because talplanner disagrees with the other planners about the ranking of
the actual problems, but because the problems are small enough that the variability in
setup time throws noise into the ranking and obscures the true picture of relative problem
difficulty. With the set of large problems we see that this anomaly is removed — the
problems are sufficiently challenging that the java startup time becomes insignificant — and
a high level of agreement over ranking is obtained. Interestingly, the hand-coded planners
show a consistently high level of agreement about the ranking of Rovers problems. The fact
that this does not emerge in the fully-automated set may be due to the larger number of
judges in the fully-automated category.

8. Relative Scaling Behaviours
The MRCs described in Section 7 demonstrate that the planners do agree, as expected,
about the relative difficulty of problem instances within most domain/level combinations.
In these cases it is possible to go on to explore the domain and level specific scaling behaviour
of the planners, and we go on to investigate that in this section. We cannot explore the
scaling behaviour of the planners across domains because, as we discussed in Section 6, there
does not seem to be much across-the-board agreement concerning the relative hardness of
the domains so we would be unlikely to see agreement in multiple judgments across the
domain boundaries.
The ideal basis on which to explore scaling behaviour would be to have a collection
of problems with a canonical scaling of difficulty and then to compare the performance of
planners as they scaled on progressively harder problems within this collection. Unfortunately, many factors contribute to making problems hard and these do not affect planners
uniformly. As a result, there is no canonical measurement of problem difficulty in many domains. Instead, we must determine the relative difficulty of problems by using the planners
39

Long & Fox

themselves as judges. This means that we can only consider the relative scaling behaviours
of planners when the planners agree on the underlying ordering of the difficulty of problems.
Thus, we begin by identifying appropriate sets of problems — those on which a given pair
of planners agree about the relative hardness of problems according to our analysis in Section 7 — and then proceed to compare the way that each of the planners in the pair scales
as the problems increase in difficulty. The first stage of the analysis considers only the order
that the two planners place on the problems within a set, while the second stage examines
how the performance varies between the two planners as they progress from problem to
problem.
The hypotheses explored in this section are:
Null Hypothesis: Where planners agree about the difficulty of problems
for a given domain/level combination, they exhibit the same scaling behaviour.
Alternative Hypothesis: Where planners agree about the difficulty of
problems for a given domain/level combination, they demonstrate different scaling behaviours, where the better scaling performance can be identified from the
data set.
This section is concerned with the question of scaling behaviour within problem sets from
specific domain/level combinations in which there is already determined to be agreement,
as identified in Section 7.
8.1 Analytic Framework
In order to test the different scaling properties of the planners we make pairwise comparisons
of performance using only those domains where both planners agreed about the difficulty
of the problems. That is, we use a domain in a comparison if both planners found it hard,
both found it easy or neither found it hard or easy.
To rank the problems in order of difficulty we use the results obtained from the bootstrapping experiment described in Section 6. Our rankings are level dependent, so we looked
at scaling within the four problem levels and recorded the results separately. We do not
attempt to combine these results into a single overall conclusion about scaling — we recognize that different planners scale better at some problem levels than at others, and that no
single planner can therefore emerge as scaling best overall.
We only compare two planners if they agreed about difficulty in at least two domains.
This gives us, in each case where a comparison is made, a data set of more than 30 points.
Where the planners did not agree in at least two domains we conclude that there is insufficient agreement between them about what constitutes problem difficulty for it to be
possible to measure their relative scaling behaviours in a meaningful way.
To perform a comparison between two planners we rank the problems in the data set
in order of agreed difficulty and then rank the differences between the performances of the
planners on these problems. We then explore whether the ranking of the differences is correlated with the ranking of the problems according to their difficulty. We use ranks because
we cannot make assumptions about the shapes of the underlying problem distributions or
the functions that truly describe the performances of the planners being compared, so our
results are robust with respect to these factors.
40

The 3rd International Planning Competition

FF
strips
FF
LPG
MIPS
Sapa
VHPOP

LPG
numeric

0.36

N

J

strips
0.87
J

N
J

MIPS
numeric simple time
timeN
0.93
0.52
0.51
0.61

N

J
J

Sapa
time

N
0.58
J

VHPOP
strips simple
time
N
0.93
0.44 J 0.48

J
N

N

Figure 27: Table showing correlation values, for fully-automated planners, between problem
N
difficulty and difference in time performance, indicating scaling behaviour.
means that one of the pairs of planners did not produce data so no comparison
J
may be drawn.
means that there was insufficient agreement between the
planners on the difficulty of domains or the ranking of problems in order to
carry out a comparison.

Given two planners, p1 and p2 , a positive correlation between the rankings of the differences in values between p1 and p2 and the problem difficulty ranking means that the
difference in performance between p1 and p2 (that is, performance of p1 minus performance
of p2 ) is increasing as the problems become more difficult. If the curve of p1 is increasing
faster p2 scales better than p1 . A negative correlation means that p1 scales better than
p2 . A zero (or near-zero) correlation means that the scaling behaviour of the two planners
is insignificantly different. We use Spearman’s rank correlation test (see Appendix C) to
identify the critical value required for confidence at the 0.05 level.
We restrict our attention to the planners that solved the most problems overall in the two
categories. Thus, the fully-automated planners we compared were ff, lpg, mips, vhpop
and sapa. We consider all pairs of the hand coded planners. We do not perform any
cross-category tests as it is evident from the raw data that the hand coded planners exhibit
better scaling behaviour than any of the fully-automated planners.
8.2 Results of Analysis
The table in Figure 27 shows the significant scaling differences that we found between pairs
of fully-automated planners at each of the levels. Figure 28 shows the relative scaling of
the hand coded planners. In both sets of tests, two planners could only be compared at the
levels at which both competed, and on domains in which they both agreed were either easy,
hard, or neither easy nor hard. We report the results so that the planner indexed by row
is the one showing the superior scaling behaviour. Where planners did not compete in the
N
same tracks we indicate this with the symbol denoting incomparable. Where no significant
difference in scaling was found we indicate this with a zero correlation. Where no agreement
J
was found to support a comparison we use the symbol
denoting disagreement. To avoid
duplication of data, we place entries as positive correlations only in the cell corresponding
to the row for the planner favoured by the comparison and omit the corresponding negative
correlation in the cell for which row and column planners are reversed.
41

Long & Fox

TLPlan
strips time
TLPlan
SHOP2
TALPlanner

strips
0.77

0

0

0.86

SHOP2
numeric simple
time
0.93
0.85

N

0.46

time
0.83

TALPlanner
strips simple time
time
0
0.25
0

0.76

Figure 28: Table showing correlation values, for hand-coded planners, between problem
N
difficulty and difference in time performance, indicating scaling behaviour.
means that one of the pairs of planners did not produce data so no comparison
may be drawn.

8.3 Interpretation
In almost all cases in which a comparison could be performed, a significant difference in
scaling behaviour was found, supporting rejection of the null hypothesis.
Because we used only those domains where there was agreement about the relative
difficulty of the problems it is not necessary to restrict our conclusions to be domaindependent. However, we had only a restricted collection of data points at our disposal
so we must be careful how we generalise this picture. On the basis of our analyses we
believe we can make some tentative judgements about how planners are scaling in pairwise
comparisons within the four competition levels.
For the fully-automated planners it can be observed informally that there is a high degree of consistency between the scaling behaviours of particular planners across the problem
levels in which they competed. Although we cannot draw overall conclusions from the data
set with a high level of confidence we can observe that ff exhibits the best scaling behaviour
in the levels at which it competed and lpg exhibits the best scaling behaviour at the temporal levels. It should be remembered that we did not perform single-domain comparisons,
although these might be interesting from the point of view of exploring domain-specific scaling behaviour and might produce some interesting results. We felt that these results would
be interesting curiosities rather than anything that could support general conclusions.
The hand coded planners also show a high degree of cross-level consistency. It can be
observed informally that tlplan scales much better than shop2 across all levels, whereas it
scales only marginally better than talplanner in the strips domains and not significantly
in any other level. talplanner scales better than shop2 at all levels in which they both
competed. It can be seen that shop2 is not scaling well relative to its competitors, although
it should be remembered that the quality of plans produced by shop2 is superior in some
domains.
Formally the tables allow us to draw specific conclusions about the relative scaling
behaviours of specific pairs of planners, within specific problem levels, at the 0.05 level.

9. Conclusions
The 3rd International Planning Competition focussed on the issue of temporal planning
and numeric resource handling. The competition was structured around two categories:
42

The 3rd International Planning Competition

fully-automated and hand-coded planning systems, and four main problem levels: strips,
numeric, simpletime and time. There were eight domains, one of which was intended
for the hand coded planners only (the um-translog domain), and two solely for the
fully-automated planners (the FreeCell and Settlers domains). Fourteen competitors took
part, eleven in the fully-automated track and three in the hand coded track. The domain
description language used was pddl2.1, an extension of the pddl standard designed for
modelling temporal and resource-intensive domains. pddl2.1 is described in another paper
in this issue (Fox & Long, 2003).
We collected a data set of some five and a half thousand data points distributed over
the domains and levels. An initial plotting of these points, in terms of the relative time
and quality performances of the planners in the different domains, revealed a number of
interesting patterns. These suggest some characteristics of the relative performances of the
competitors within the competition domains. These patterns were presented and discussed
at the AIPS conference with which the final competition events were co-located. However,
other patterns, such as those indicating relative performances across domains and those
showing the perceived difficulty of the competition domain/level combinations, were invisible in the data presented in this way. This paper presents the results of some detailed
statistical analyses of the competition data, aimed at identifying some of these deeper patterns.
This paper explores three experimental themes. The first theme is aimed at answering
the question: which planner should I buy? This question is concerned with which planner
emerges as the strongest overall performer, rather than which produced the best results
in a particular domain/level combination, and it can be asked from the point of view of
both speed and quality criteria. To answer it we performed comparisons, based on the
Wilcoxon rank-sum matched-pairs test, enabling the construction of partial orders on the
competing planners in terms of their time and quality performances in the four levels of
the competition. From these partial orders it can be concluded that, if a potential user
is interested in good behaviour across a broad range of temporal and numeric problems
then lpg, amongst the fully-automated planners, and tlplan, amongst the hand-coded
planners, are the best choices. Of course, if more specialised coverage is required and speed
of solution is paramount then other choices might be made.
The second theme considers the dependence of planner performance on domain structure. We were interested in exploring the extent to which the competing planners agree
about which domain/level combinations were hard and which were easy. The analysis we
performed in addressing the first of these issues is a statistical complement to the theoretical
analysis of domain topologies being carried out by Hoffmann (2003b). We considered the
competition domains at all four levels used in the competition, whilst Hoffmann considers
only the strips subset of the competition domains (he also considers adl domains, but we
did not use any of these in the competition). It is interesting to note that our findings were
broadly consistent with his conclusions.
The third theme considered the scaling behaviour of the competing planners. We considered two related issues: the extent to which the competing planners agreed on the relative
difficulty of the problem instances within domain/level combinations and the extent to
which the planners scaled similarly in domain/level combinations where there was agreement. Our intentions in pursuing the first issue were to provide an objective scale that
43

Long & Fox

would support our efforts to investigate the relative scaling behaviours of the planners. Because we found relatively little agreement over the perceived difficulty of problems within
domain/level combinations we were able to perform only a restricted comparison of relative
scaling behaviour. However, we consider the results we obtained to make an interesting
contribution to a deeper comparison of planner performances than is available from the raw
domain-specific data.
There are many other questions that it would be interesting to be able to answer.
Amongst these are questions about the extent to which hand-coding of domain knowledge
really benefits a planner and the amount (and value) of effort involved in encoding such
knowledge. This is a pressing question for the community and one that the competition
series might be well-suited to try to answer. However, in order to pursue these in future
competitions it will be necessary to carefully design controlled experiments aimed at exploring the precise hypotheses. We have been restricted in this paper to the post hoc analysis
of the competition data, and this has clearly restricted the kinds of questions we have been
able to ask and answer. However, we hope that both the results and the methodologies
presented here will be of interest to the planning community and that they will help to
encourage further scientific evaluation of performance in the field.

Acknowledgements
We would like to thank all the competitors in the 3rd International Planning Competition
for contributing their time and enthusiasm to the event we report and for providing the
data that has made this paper possible. We would also like to thank Adele Howe who
has contributed invaluable advice, comments and huge support and made it possible for
this paper to go far further than we could have hoped. We would like to thank David
Smith for undertaking the unenviable task of coordinating and editing this special issue of
the Journal of Artificial Intelligence Research and doing so with immense patience, good
humour and generous support. Finally, we would like to thank Martha Pollack who first
proposed the idea of publishing the assembled work in a special issue of the Journal of
Artifical Intelligence Research. Her whole-hearted commitment to the project has been
vital to its successful conclusion.

44

The 3rd International Planning Competition

Appendix A. Problem Domains
A.1 The First International Planning Competition
The first competition used the following domains:
• Logistics A transportation problem involving aircraft and trucks, with trucks constrained to movement within cities and aircraft constrained to movement between
(inter-city) airports. This domain allows considerable parallelism.
• Mystery A transportation domain with vehicles having limited capacity and consuming limited stocks of fuel.
• MPrime A variant of the Mystery domain in which it is also possible to pipe fuel
between locations in order to allow vehicles to have different movement options.
• Grid A problem in which a single robot moves between locations on a grid shaped
map. Locations may be locked and there are keys that must be collected to gain access
to these locations. The objectives of the problem instances involve transporting the
keys to particular locations.
• Gripper A simple domain, originally designed to demonstrate the limitations of
Graphplan, in which a collection of identical balls must be transported by a robot
with two grippers from one room to an adjacent room.
• Movie A simple domain intended to explore use of conditional effects. A collection
of snacks must be assembled prior to rewinding a video and then watching the movie.
• Assembly A complex adl domain with a challenging use of quantified and conditional
effects.
A.2 The Second International Planning Competition
The second competition introduced several new domains:
• Blocks The classic blocks-world problem, encoded without an explicit reference to a
gripper. This domain has significant goal interaction.
• Job-Schedule A problem involving the machining of parts. This problem exercises
the adl features involving conditional and quantified effects, although it is less complex than the Assembly domain.
• Freecell This is the classic solitaire card game that is widely available as a computer
game. The encoding as a strips domain represents a larger problem than most
previous benchmarks and includes the awkward addition of an encoded set of integers.
• Miconics Elevator This domain was inspired by the problem of planning an efficient call sequence for an elevator car travelling between floors of a large building.
There were several variants, with the most complex including numeric preconditions
as well as purely logical constraints. An adl version offered complex preconditions
involving several different connectives and a strips version offered a relatively simple
transportation problem.
45

Long & Fox

In addition, the Logistics domain was reused to provide some calibration of performance
in comparison with the first competition.
A.3 The Third International Planning Competition
A.3.1 The Depots Domain
The domain consists of actions to load and unload trucks, using hoists that are available at
fixed locations. The loads are all crates that can be stacked and unstacked onto a fixed set
of pallets at the locations. The trucks do not hold crates in a particular order, so they can
act like a table in the Blocks domain, allowing crates to be reordered.
This domain was devised with the foremost intention of testing strips planners. The
second competition had demonstrated that the Logistics domain was no longer a serious
challenge, and that, for planners using hand-coded controls, the Blocks domain was also
solved. For fully-automated planners the Blocks domain still represents a challenge, although the second competition showed that some planners can solve quite large problems
(up to twenty blocks) with reasonably efficient plans within a few minutes. However, performance can vary widely and there are problems in this range that can prove unsolvable
for these planners. We wanted to see whether the performance that had been achieved in
these domains could be successfully brought together in one domain. We were interested
to see for fully-automated planners, where the interaction between the problems creates an
additional family of choice points in addition to those that appear in the transportation and
the block-tower-construction sub-problems. We were also interested to see this for handcoded planners where the rules for each of the sub-problems are obviously well-understood,
but it is not obvious whether the rules can be combined into a single collection without any
problems of interaction.
The metric version of the domain adds weight attributes to the crates and weight capacities to the trucks. In addition, trucks consume fuel in their travels and the plans must
minimise fuel use. Fuel use is constant and not dependent on the locations. Fuel is also consumed in lifting crates, so there is a tradeoff to be considered when crates must be restacked
at a location. Either a truck can be brought in to act as a “table” or more complex lifting
and stacking can be performed using the locally available pallets as transfer space.
The temporal versions allow for concurrent activities of the trucks and the hoists (at all
locations). The full temporal variant makes the time for driving dependent on the truck and
the distance between the locations, and makes the time to load or unload a crate dependent
on the weight of the crate and the power of the hoist. The objective in both is to minimise
make-span (the overall duration of the plan).
A.3.2 The DriverLog Domain
This domain has drivers that can walk between locations and trucks that can drive between
locations. Walking requires traversal of different paths from those used for driving, and
there is always one intermediate location on a footpath between two road junctions. The
trucks can be loaded or unloaded with packages (with or without a driver present) and
the objective is to transport packages between locations, ending up with a subset of the
packages, the trucks and the drivers at specified destinations.
46

The 3rd International Planning Competition

This domain was produced to explore the power of strips solutions to transportation
problems when the transportation involves a sub-problem of acquiring a driver. The problem
is one that offers significant opportunity for concurrency in the use of drivers and vehicles,
so we were also interested to see how the temporal variants were handled.
The metric variant of the domain adds costs for walking and driving and problem instances required that the planner optimise some linear combination of the total walking
cost and the total driving cost.
The full temporal variant makes time spent driving or walking between locations dependent on the path being traversed, but other durations are only dependent on the actions
(as with the simple temporal version). In both of these variants the plan quality depends
on the make-span.
An additional variant, the hard numeric variant, complicates the cost of driving by
making it dependent on the load being carried: each additional package added to a truck
increases the fuel consumption rate of the truck by its current value, making the consumption increase as a quadratic function of the load.
A.3.3 The Zeno-Travel Domain
This domain has actions to embark and disembark passengers onto aircraft that can fly
at two alternative speeds between locations. The strips variant is rather uninteresting
because the two speeds do not offer meaningful alternatives. In the metric variant the
planes consume fuel at different rates according to the speed of travel (two alternatives)
and distances between locations vary. Problem instances require plans to minimise some
linear combination of time and fuel use.
The temporal versions are closer to the original zeno problem. They involve durations
for the different means of travel and different levels of fuel consumption. In contrast to
the original zeno problem the fuel consumption is not described by a continuous function,
but by discrete step functions applied at the end points of durative actions. The fact that
the fuel in an aircraft cannot be affected by multiple different concurrent actions and its
value is not relevant to satisfying the precondition of any actions that could begin during
the continuous consumption or replenishment of fuel means a discrete model of fuel use is
sufficient, demanding less expressive power of the planners that use the model.
A.3.4 The Satellite Domain
The satellite domain was developed following discussions with David E. Smith and Jeremy
Franks at nasa Ames Research Center. It is intended to be a first model of the satellite
observation scheduling problem. The full problem involves using one or more satellites to
make observations, collecting data and downlinking the data to a ground station. The
satellites are equipped with different (possibly overlapping) collections of instruments, each
with different characteristics in terms of appropriate calibration targets, data productions,
energy consumption and requirements for warming up and cooling down. The satellites
can be pointed at different targets by slewing them between different attitudes. There
can be constraints on which targets are accessible to different satellites due to occlusion
and slewing capabilities. Instruments generate data that must be stored on the satellite
and subsequently downlinked when a window of communication opportunity opens with a
47

Long & Fox

ground station. Communication windows are fixed. Data takes time to downlink and it
could be impossible to downlink an entire satellite store in a given time frame, so downlinks
must be scheduled around the storage capacity, the production of data by observations and
the opportunities to downlink data as they arise. In the real problem there are additional
difficulties such as the management of energy and the use of solar power and the maintenance of operational temperatures during periods in shadow. In order to make the problem
accessible to the planners in the competition (given the time scales for encoding the domain,
writing a problem generator and testing competing planners) several important features of
the real problem are simplified. Perhaps most important of these is that in the real problem
targets are only visible during particular time-windows, although the elimination of the
problem of downlinking data is also a significant simplification. Representing the windows
of opportunity is possible in pddl2.1, but not entirely straight-forward and this remains an
area in which there is need for development. Management of power and temperature were
also simplified away.
The strips version of the problem involves deciding on the most efficient covering of the
observations given the satellite capabilities. This is an interesting combinatorial problem if
the satellites are assumed to be free to operate concurrently (in a Graphplan-style parallel
activity), but otherwise the problem offers few interesting choice points. The strips version
was based on an earlier Satellite domain contributed by Patrik Haslum.
The metric version of the problem introduces data capacities into the satellites and fuel
use in slewing between targets. The plans are expected to minimize fuel use in obtaining
the data. This problem combines a constrained bin-packing problem (getting the data into
the limited stores of the satellites, subject to the constraints that only certain satellites are
equipped to obtain certain data) with a kind of route planning problem (finding fuel-efficient
paths between targets while also considering the combined costs of the fuel consumption by
all of the satellites).
The temporal versions introduce duration and make concurrency important. The full
temporal problem includes different slew times between different pairs of targets. These
problems both involve minimising make-span times for the data acquisition. A complex
version of the domain combines the temporal and metric features so that planners are
required to manage the problem of storing different sized data blocks in limited capacity
satellite data stores.
A further variant of the Satellite domain, called the hardnumeric version, represents
an important departure from traditional planning problems: the logical goals describing
the intended final state are trivial (either empty or a few simple final positions for the
satellites), but the metric by which the plans are declared to be evaluated is the quantity
of data collected. The problem is interesting because a null (or nearly null) plan will solve
all the instances, but the quality of these plans will be zero. To produce a good plan it is
necessary to ensure that the satellites are used to collect data and this, in turn, requires
that the planner constructs reasonable data collection goals. This is a hard problem for
most current planners — particularly the fully-automated planning systems. Nevertheless,
it is a realistic demand for many problems that a planner might be required to face: it is
not uncommon for the specific final state to be less important than the effects of the actions
carried out in reaching it.
48

The 3rd International Planning Competition

A.3.5 The Rovers Domain
The Rovers domain was constructed as a simplified representation of the problem that
confronts the nasa Mars Exploration Rover missions launched in 2003, the Mars Science
Laboratory mission planned for 2009 and other similar missions that are expected as part of
the ESA AURORA project. The strips version of the problem involves planning for several
rovers, equipped with different, but possibly overlapping, sets of equipment to traverse a
planet surface. The rovers must travel between waypoints gathering data and transmitting
it back to a lander. The traversal is complicated by the fact that certain rovers are restricted
to travelling over certain terrain types and this makes particular routes impassable to some
of the rovers. Data transmission is also constrained by the visibility of the lander from the
waypoints.
The metric version of the domain introduces an energy cost associated with actions and
an action allowing rovers to recharge, provided they are in the sun. The problems sought
solutions that minimised numbers of recharges, so the use of energy was required to be as
efficient as possible.
In the metric temporal variant the domain involves both energy and time management,
although the instances require planners to optimise total duration. This demand implies
the need for efficient energy use, since recharging is an action that consumes a considerable
amount of time and, in our model, requires the recharging rover to remain in one place
during the period of recharging. The opportunity for careful division of labour between the
rovers makes both temporal variants complex and interesting problems.
A.3.6 The Settlers Domain
This domain exists only as a metric problem. The problem is inspired by the multitude of
computer games that involve managing resources, accumulating raw resources and slowly
combining them into more and more advanced processing plants and other structures to
achieve more sophisticated objectives. The problem was proposed by Patrik Haslum. An
interesting difficulty that the problem presents is that it is a problem that involves constructing new objects out of resources. This is not easily represented in pddl2.1. In fact,
the only way to capture the domain in pddl2.1 is to name the objects that could be constructed and to give them an attribute indicating whether or not they have actually been
constructed. This leads to a very cumbersome encoding and, moreover, represents a particular problem for planners that ground actions prior to planning, since a multitude of
potential objects must be considered in the process, leading to a huge collection of actions.
Many of these actions are uninterestingly different, since the specific choice of names for
objects that are created in solving an instance is clearly irrelevant, but each alternative is
constructed and considered in the planning process.
A.3.7 The UM-Translog-2 Domain
The UM-Translog-2 (Wu & Nau, 2002) domain was used only for the hand-coded planners
and only an incomplete set of results was collected due to time constraints at the conclusion
of the testing period. This domain is a significant challenge because of its size and should be
seen as a useful benchmark problem for fully-automated planners because of the challenges
in both grounding and searching a domain with so many action schemas.
49

Long & Fox

Appendix B. The Competitors
B.1 The Fully Automated Planners
There were eleven competitors in this category, representing at least four distinct planning paradigms (forward search, model-checking, local search and partial order planning).
Fully-automated planners accept the pddl2.1 specifications of domain, initial state and
goal and compute solutions solely on the basis of these specifications. No additional control
knowledge or guidance is supplied. Fully-automated planners therefore depend on sophisticated search control heuristics and the efficient storage of alternative search branches. A
popular current approach to search control is to make use of variants of the relaxed plan
idea originally proposed by McDermott (1996) and subsequently exploited by Bonet and
Geffner (1997) and Hoffmann (2000).
IxTeT (Laborie & Ghallab, 1995) entered as a fully-automated planner, but in retrospect
it might have been better classified as a hand-coded planner. The ability to hand-code
domain representations might have alleviated some of the problems that arose in making
the competition domains accessible to IxTeT. IxTeT does not currently accept domains or
problems in pddl format, so it was necessary to translate the competition domains into
its own representation language. No automatic translator between pddl and the IxTeT
input language yet exists and it is not clear that such a translation can be automated.
Furthermore, the plan representation of IxTeT is more general than that insisted upon
for use in the competition but this was not an advantage given the need to automate the
plan validation process. In fact, several plans produced by IxTeT could not be validated.
The combination of these difficulties made it impossible to offer any real insights into the
performance of IxTeT on the competition domains. Nevertheless, we were pleased that an
attempt was made to enter IxTeT: it is important that the competition should not cause
a fracture between the members of the research community who are interested in entering
and those who have long-established alternative planning technology that cannot be easily
reengineered to meet the assumptions underlying the competition.
B.1.1 FF
ff has been an extremely successful and influential planner since 2000 (Hoffmann & Nebel,
2000). It is based on forward state space search using relaxed plans to give heuristic guidance
in its choice between possible steps through the space. Hoffmann extended the original ff
system (Hoffmann, 2003a) to include a treatment of metric domains by relaxing the metric
dimensions of the problem as well as the logical dimensions.
B.1.2 IxTeT
IxTeT (Laborie & Ghallab, 1995) is well known for having been one of the first planners to
reason about time and resource intensive domains. The version that participated in parts
of the competition is a reimplementation of the original system described by Ghallab and
Laruelle (Ghallab & Laruelle, 1994). As mentioned above, IxTeT experienced a number of
difficulties in the competition making it difficult to evaluate its performance. However, seen
in the broader context of planning research and application IxTeT has made many important
contributions to the development of temporal and resource-intensive planning approaches
50

The 3rd International Planning Competition

and, with its powerful plan representation language, is suited to certain applications for
which the simplified plan representation used in the competition is inadequate.
B.1.3 LPG
lpg (Gerevini et al., 2003) is based on a local-search strategy applied to plan graphs (Blum
& Furst, 1995). The approach has been generalised to accommodate both metric and
temporal structure, making it a powerful and flexible planner. The use of local search
allows the planner to be configured to trade-off time and plan quality. Indeed, the planner
exhibits any time behaviour in the sense that plans can be reported as they are found and,
if the search is allowed to run longer, better quality plans might be discovered.
B.1.4 MIPS
mips (Edelkamp, 2003) uses a variety of techniques, but at the core is a model-checker
based on ordered binary decision diagrams (obdds), which is used to generate reachable
states. The planner uses a powerful technique to compress state representations in order
to make the obdds more compact. Exhaustive search of the state space is impractical in
large problems and mips uses a heuristic evaluation function based on relaxed plans in order
to restrict the space of explored states. mips tackles concurrency in temporal planning by
lifting partial orders from the totally ordered plans that are produced by its forward search.
mips has also been extended to manage metric quantities, also using a relaxation heuristic
to predict the behaviours of metric quantities.
B.1.5 SAPA
sapa (Do & Kambhampati, 2003) is a forward search planner using a relaxed temporal
plan heuristic (based on the use of a relaxed tgp-style (Smith & Weld, 1999) plan graph)
to guide its search. The heuristic is supplemented with a heuristic estimate of resource
usage allowing the planner to handle metric quantities. Temporal structure is managed
using delayed effects, so that, when a durative action is executed, its end effects are queued
in an event queue, pending application when time is advanced to the point at which they
are triggered. The focus of sapa development has been in the management of metric and
temporal structure. sapa did not attempt to compete in strips or simpletime problems,
but performed well in the more complex problems.
B.1.6 SEMSYN
semsyn (Parker, 1999) is a Graphplan-based planner, with extensions to handle metric and
adl features. In general, Graphplan-based approaches have, with the exception of lpg,
proven unequal to the challenge of scaling to meet the latest sets of benchmark problems.
This suggests that the search strategy of Graphplan must be abandoned if large problems
are to be solved, but that the underlying plan graph structure need not be a source of
scaling problems (in fact ff, vhpop, sapa and lpg all use plan graph structures in the
planning process).
51

Long & Fox

B.1.7 SIMPLANNER
simplanner (Onaindı́a, Sapena, Sebastia, & Marzal, 2001) is a forward search planner
using a relaxed plan heuristic. The heuristic evaluation uses separate relaxed plans for each
of the top level goals, combining them to identify a useful first action to apply from the
current state. This variant on the idea of relaxed plans appears to represent a reinforcement
of the notion of helpful actions developed in ff, where actions that are selected in the first
layer of a relaxed Graphplan-style plan are favoured as appropriate candidates for the next
step in a plan.
B.1.8 STELLA
stella (Sebastia, Onaindı́a, & Marzal, 2001) uses a forward heuristic search architecture,
but with the modification that plans are built using landmarks (Porteous, Sebastia, &
Hoffmann, 2001). The idea is to identify key states in the path of a plan before planning
begins and then to use these as “stepping stones” to progress from the initial state to the
goal state.
B.1.9 TP4
tp4 (Haslum & Geffner, 2001) is a development of the hsp (Bonet et al., 1997) planning
approach, which was one of the first of the current generation of rather successful heuristic
state-space search planners based on relaxed plan heuristics. tp4 extends the use of the
heuristic to manage temporal plan structure. The planner is intended to find optimal
plans (although, for minor technical reasons, some of the plans it produces are slightly suboptimal), by using an admissible heuristic, and this requires a far greater search effort than
in planners constructing plans that are merely heuristically good.
B.1.10 TPSYS
tpsys (Garrido, Onaindı́a, & Barber, 2001; Garrido, Fox, & Long, 2002) is a temporal
planner based on Graphplan. There are technical differences between tpsys and tgp (Smith
& Weld, 1999), but the central use of a temporal plan graph is similar, using the graph
to represent the passage of time, with actions having associated durations. As with other
Graphplan-based approaches, the search machinery appears to scale badly.
B.1.11 VHPOP
Partial order planners have suffered a period of being unfashionable, supplanted by Graphplan and, more recently, relaxed-plan-based heuristic state-space search planners. vhpop (Younes & Simmons, 2003) represents an interesting indication that partial order
planning is far from defunct. In particular, the partial order framework offers a powerful way to handle temporal constraints. In vhpop a simple temporal network is used to
manage the temporal constraints between the end points of durative actions and this allows
the planner to successfully treat concurrency and other features of temporal plan structure.
Within the framework of a partial-order planner, vhpop makes use of plan graph distance
estimates to guide its search.
52

The 3rd International Planning Competition

B.2 The Hand-coded Planners
There were three entrants in the category of planners requiring hand-coded control knowledge. As in the 2000 competition the teams competing with these planners were allowed
time to reformulate domain descriptions to include domain-specific control knowledge. As
the results show, control knowledge can dramatically improve planner performance. However, it is difficult to assess the cost-effectiveness of hand-coding control knowledge. Fahiem
Bacchus (2001) observed the need to quantify the time and effort required to identify and
encode useful control knowledge in order to be better able to judge the trade-off between
the fully-automated and hand-coded approaches. However, it is very difficult to measure
the effort involved. In principle it should be possible to bound the time allowed for domain
reformulation, but then differences in team sizes and in the experience of team members
become very important in comparing what has been achieved by different participants. The
third competition, like those before it, did not explore these factors, so it is impossible to
make judgements about the relative effectiveness of the solutions to these problems offered
by each of the hand-coded planning systems. This remains a very important open issue for
future competitions to address.
B.2.1 SHOP2
shop2 (Nau, Au, Ilghami, Kuter, Murdoch, Wu, & Yaman, 2003) is a Hierarchical Task
Network (htn) planner. Like most other htn planners, shop2 allows tasks and subtasks
to be partially ordered. Thus plans may interleave subtasks from different tasks during
expansion of tasks. However, unlike most other htn planners, shop2 generates the steps
of each plan in the same order that those steps will later be executed and it can therefore
maintain a representation of the current state at each stage in the planning process. This
makes it much easier to incorporate substantial expressive power into the htns used by
shop2. For example, they might include axioms, mixed symbolic and numeric computation,
or even calls to external programs.
B.2.2 TALPLANNER
The most successful of the hand-coded planners in 2000, talplanner (Kvarnström &
Magnusson, 2003) uses a temporal action logic as a language for describing planning domains
and uses control rules that guide the planner in making intelligent choices while constructing
plans in a forward search — an idea originally developed in tlplan. The rules can act to
prune away search branches that are predicted (by the human encoding the rules) to lead
to no solutions. Using this idea, it is possible to arrive at a collection of rules that, by
examination of a given state, can guide the planner to choose actions so effectively that
virtually no search is required at all.
B.2.3 TLPLAN
tlplan (Bacchus & Kabanza, 2000) also uses a temporal logic language to support the
construction of control rules to guide plan search. tlplan preceded talplanner in its
use of this idea. tlplan adopts a slightly different approach to the management of tem53

Long & Fox

poral structure than talplanner, and is also capable of handling metric quantities. The
extensions of tlplan that allow it to handle time are described by Bacchus and Ady (2001).

54

The 3rd International Planning Competition

Appendix C. Statistical Techniques
The analysis conducted in this paper makes use of several standard statistical tests. These
are the Wilcoxon matched-pairs rank-sum test, the proportion test, the matched-pairs t-test,
Spearman’s rank correlation test and the rank correlation test for agreement in multiple
judgements. For the benefit of readers who are unfamiliar with these tests, we briefly
summarise them here. This appendix was constructed using Gopal K. Kanji’s 100 Statistical
Tests (1999).
C.1 The Proportion Test
This test is also known as the binomial distribution test. The test is used to consider the
proportion of a sample for which a particular qualitative observation has been made. For
example, the proportion of rolls of a die that have come up 6. The test examines how far
from the expected proportion is the observed proportion, given an assumed probability for
the observation. In its use in this paper, we adopt a null hypothesis that two planners
should win with equal likelihood and test the proportion of observed wins for one planner
against this hypothesis. If the deviation of observed proportion from expected proportion
is sufficiently high, then the null hypothesis can be rejected.
C.2 The t-test
The t-test is a parametric test: it is founded on an assumption that the underlying population from which the samples are drawn is nearly normally distributed. It is reasonably
robust to failures in this assumption, but should be treated with caution as the true distribution deviates from normal. The test considers means of two samples and tests the
null hypothesis that the two samples are drawn from populations with the same mean.
Variants are available according to what is known about variance in the underlying populations. The t-test is a more conservative version of the Z-test, which relies on the effect
confirmed by the Central Limit Theorem that, for large samples, the sampling ditribution
of the mean is normal. The t-test can be applied with smaller samples, compensating for
the distortion of the distribution that this creates. In this paper, we use a variant of the
t-test in which observations are drawn in matched pairs: each element of a pair is a test
result conducted under close to identical circumstances, but for a different test subject (in
this case, a different planner).
For n pairs of observations, where di is the difference for pair i and d is the mean
difference, the variance, s, of the differences is given by:
2

s =

n
X
(di − d)2
i=1

n−1

If x1 and x2 are the means of the samples from each of the two populations, then the
statistic is:
x1 − x2
√
t=
s/ n
with n − 1 degrees of freedom.
55

Long & Fox

C.3 The Wilcoxon Matched-Pairs Rank-Sum Test
The use of ranks releases statistical tests from the parametric assumptions about underlying
distributions by replacing actual observed values with their rank within the ordered set of
observed values. The Wilcoxon matched-pairs test is analogous to the matched-pairs t-test,
but uses the sum of the ranks of the values associated with each of the two test subjects.
The pairs are ordered according to the absolute values of their differences and then the sum
of the ranks of the positive values is compared with the sum of the ranks of the negative
values. If the two subjects exhibit no particular pattern in their relative behaviours then
the positive and negative values should be distributed roughly evenly through the ranks and
thus the rank-sums should be approximately equal. A distortion between the rank-sums
indicates that one or other subject has a consistently superior performance over the other.
The test is defined as follows. Given a collection of n pairs of data items, the differences
between the pairs are found and ranked according to absolute magnitude. The sum of the
ranks is then formed for the negative and positive differences separately. T is the smaller
of these two rank sums. For sufficiently large samples the following value is approximately
normally distributed:
n(n + 1)/4) − T
p
n(n + 1)(2n + 1)/24
C.4 Spearman’s Rank Correlation Test
This is a test for correlation between a sequence of pairs of values. Using ranks eliminates
the sensitivity of the correlation test to the function linking the pairs of values. In particular,
the standard correlation test is used to find linear relations between test pairs, but the rank
correlation test is not restricted in this way.
Given n pairs of observations, (xi , yi ), the xi values are assigned a rank value and,
separately, the yi values are assigned a rank. For each pair (xi , yi ), the corresponding
difference, di between the xi and yi ranks is found. The value R is:
R=

n
X

d2i

i=1

For large samples the test statistic is then:
Z=

6R − n(n2 − 1)
√
n(n + 1) n − 1

which is approximately normally distributed.
C.5 Rank Correlation Test for Agreement in Multiple Judgements
This tests the significance of the correlation between n series of rank numbers, assigned by
n judges to K subjects. The n judges give rank numbers to the K subjects and we compute:
S=

nK(K 2 − 1)
12
56

The 3rd International Planning Competition

and SD , the sum of squares of the differences between subjects’ mean ranks and the overall
mean rank. Let:
D1 =

SD
D1
D2
, D2 = S − D1 , S12 =
, S22 =
n
K −1
K(n − 1)

The test statistic is:
F =

S12
S22

which follows the F distribution with K − 1, K(n − 1) degrees of freedom.

57

Long & Fox

References
Bacchus, F. (2001). The AIPS’00 planning competition. AI Magazine, 22(3), 47–56.
Bacchus, F., & Ady, M. (2001). Planning with resources and concurrency: A forward chaining approach. In Proceedings of IJCAI-01, pp. 417–424.
Bacchus, F., & Kabanza, F. (2000). Using temporal logic to express search control knowledge
for planning. Artificial Intelligence, 116(1-2), 123–191.
Blum, A., & Furst, M. (1995). Fast Planning through Plan-graph Analysis. In Proceedings
of IJCAI-95.
Bonet, B., Loerincs, G., & Geffner, H. (1997). A robust and fast action selection mechanism
for planning. In Proceedings of AAAI-97, pp. 714–719. AAAI/MIT Press.
Do, M. B., & Kambhampati, S. (2003). Sapa: A scalable, multi-objective, heuristic, metric,
temporal planner. Journal of Artificial Intelligence Research, this issue.
Edelkamp, S. (2003). Taming numbers and durations in the model-checking integrated
planning system. Journal of Artificial Intelligence Research, this issue.
Fox, M., & Long, D. (2003). pddl2.1: An extension to pddl for expressing temporal
planning domains. Journal of Artificial Intelligence Research, this issue.
Garrido, A., Fox, M., & Long, D. (2002). Temporal planning with PDDL2.1. In Proceedings
of ECAI-02.
Garrido, A., Onaindı́a, E., & Barber, F. (2001). Time-optimal planning in temporal problems. In Proceedings ECP-01.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning through stochastic local search and
temporal action graphs in LPG. Journal of Artificial Intelligence Research, this issue.
Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporal
planner. In Proceedings of AIPS-94.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings
of ECP-01, Toledo.
Hoffmann, J. (2003a). The Metric-FF planning system: Translating “ignoring delete lists”
to numerical state variables. Journal of Artificial Intelligence Research, this issue.
Hoffmann, J. (2003b). Where ignoring delete-lists works: local search topology in planning
benchmarks. Tech. rep. 185, Institut für Informatik, Albert-Ludwigs Universität,
Freiburg.
Hoffmann, J., & Nebel, B. (2000). The FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence Research, 14, 253–302.
Howe, A., & Dahlman, E. (2002). A critical assessment of benchmark comparison in planning. Journal of Artificial Intelligence Research, 17, 1–33.
Kanji, G. (1999). 100 Statistical Tests. Sage Publications.
Kvarnström, J., & Magnusson, M. (2003). Talplanner in the 3rd international planning
competition: Extensions and control rules. Journal of Artificial Intelligence Research,
this issue.
58

The 3rd International Planning Competition

Laborie, P., & Ghallab, M. (1995). Planning with sharable resource constraints. In Proceedings of IJCAI-95. Morgan Kaufmann.
Long, D. (2000). The AIPS’98 Planning Competition: Competitors’ perspective. AI Magazine, 21 (2).
McDermott, D. (2000). The 1998 AI planning systems competition. AI Magazine, 21 (2).
McDermott, D., & the AIPS’98 Planning Competition Committee (1998). PDDL–the planning domain definition language. Tech. rep., Available at: www.cs.yale.edu/homes/dvm.
McDermott, D. (1996). A heuristic estimator for means ends analysis in planning. In
Proceedings of AIPS-96, pp. 142–149. AAAI Press.
Nau, D., Au, T.-C., Ilghami, O., Kuter, U., Murdoch, J., Wu, D., & Yaman, F. (2003).
SHOP2: An HTN planning environment. Journal of Artificial Intelligence Research,
this issue.
Onaindı́a, E., Sapena, O., Sebastia, L., & Marzal, E. (2001). SimPlanner: an executionmonitoring system for replanning in dynamic worlds. In Proceedings of EPIA-01.
Parker, E. (1999). Making graphplan goal-directed. In Proceedings of ECP-99, pp. 333–346.
Penberthy, J., & Weld, D. (1994). Temporal planning with continuous change. In Proceedings
of AAAI-94. AAAI/MIT Press.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). On the extraction, ordering, and usage
of landmarks in planning. In Proceedings of ECP-01.
Sebastia, L., Onaindı́a, E., & Marzal, E. (2001). SteLLa: An optimal sequential and parallel
planner. In Proceedings of EPIA-01.
Smith, D. E., & Weld, D. S. (1999). Temporal planning with mutual exclusion reasoning.
In Proceedings of IJCAI-99, pp. 326–337.
Wu, D., & Nau, D. (2002). um-translog-2: a planning domain designed for AIPS-02. Tech.
rep. CS-TR-4402, University of Maryland.
Younes, H., & Simmons, R. (2003). vhpop: Versatile heuristic partial order planner. Journal
of Artificial Intelligence Research, this issue.

59

Journal of Artificial Intelligence Research 20 (2003) 195-238

Submitted 6/03; published 12/03

Taming Numbers and Durations in the Model Checking
Integrated Planning System
Stefan Edelkamp

stefan.edelkamp@cs.uni-dortmund.de

Baroper Straße 301
Fachbereich Informatik, GB IV
Universität Dortmund
44221 Dortmund
Germany

Abstract
The Model Checking Integrated Planning System (MIPS) is a temporal least commitment heuristic search planner based on a flexible object-oriented workbench architecture.
Its design clearly separates explicit and symbolic directed exploration algorithms from the
set of on-line and off-line computed estimates and associated data structures.
MIPS has shown distinguished performance in the last two international planning competitions. In the last event the description language was extended from pure propositional
planning to include numerical state variables, action durations, and plan quality objective
functions. Plans were no longer sequences of actions but time-stamped schedules.
As a participant of the fully automated track of the competition, MIPS has proven to be
a general system; in each track and every benchmark domain it efficiently computed plans
of remarkable quality. This article introduces and analyzes the most important algorithmic
novelties that were necessary to tackle the new layers of expressiveness in the benchmark
problems and to achieve a high level of performance.
The extensions include critical path analysis of sequentially generated plans to generate
corresponding optimal parallel plans. The linear time algorithm to compute the parallel
plan bypasses known NP hardness results for partial ordering by scheduling plans with
respect to the set of actions and the imposed precedence relations. The efficiency of this
algorithm also allows us to improve the exploration guidance: for each encountered planning
state the corresponding approximate sequential plan is scheduled.
One major strength of MIPS is its static analysis phase that grounds and simplifies
parameterized predicates, functions and operators, that infers knowledge to minimize the
state description length, and that detects domain object symmetries. The latter aspect is
analyzed in detail.
MIPS has been developed to serve as a complete and optimal state space planner,
with admissible estimates, exploration engines and branching cuts. In the competition
version, however, certain performance compromises had to be made, including floating point
arithmetic, weighted heuristic search exploration according to an inadmissible estimate and
parameterized optimization.

1. Introduction
Practical action planning and model checking appear to be closely related. The MIPS
project targets the integration of model checking techniques into a domain-independent
action planner. With the HSF-Spin experimental model checker (Edelkamp, Leue, & LluchLafuente, 2003) we are looking towards the integration of planning technology into an
c
2003
AI Access Foundation. All rights reserved.

Edelkamp

existing model checker. Additional synergies are exploited in the automated compilation of
protocol software model checking problems into planner inputs (Edelkamp, 2003).
Model checking (Clarke, Grumberg, & Peled, 1999) is the automated process to verify if
a formal model of a system satisfies a specified temporal property or not. As an illustrative
example, take an elevator control system together with a correctness property that requires
an elevator to eventually stop on every call of a passenger or that guarantees that the door is
closed, while the elevator is moving. Although the success in checking correctness is limited,
model checkers have found many errors in current hardware and software designs. Models
often consist of many concurrent sub-systems. Their combination is either synchronous, as
often seen in hardware design verification, or asynchronous, as frequently given in communication and security protocols, or in multi-threaded programming languages like Java.
Model checking requires the exploration of very large state spaces containing all reachable system states. This problem is known as the state explosion problem and occurs even
when the sets of generated states is much smaller than the set of all reachable states.
An error that shows a safety property violation, like a deadlock or a failed assertion,
corresponds to one of a set of target nodes in the state space graph. Roughly speaking,
something bad has occured. A liveness property violation refers to a (seeded) cycle in the
graph. Roughly speaking, something good will never occur. For the case of the elevator
example, eventually reaching a target state where a request button was pressed is a liveness
property, while certifying closed doors refers to a safety property.
The two main validation processes in model checking are explicit and symbolic search.
In explicit-state model checking each state refers to a fixed memory location and the state
space graph is implicitly generated by successive expansions of state.
In symbolic model checking (McMillan, 1993; Clarke, McMillan, Dill, & Hwang, 1992),
(fixed-length) binary encodings of system states are used, so that each state can be represented by its characteristic function representation. This function evaluates to true if
and only if all Boolean state variables are assigned to bit values with respect to the binary
encoding of the system state. Subsequently, the characteristic function is a conjunction of
literals with a plain variable for a 1 in the encoding and a negated variable for a 0. Sets of
states are expressed as the disjunction of all individual characteristic functions.
The unique symbolic representation of sets of states as Boolean formulae through binary
decision diagrams (BDDs) (Bryant, 1992) is often much smaller than the explicit one. BDDs
are (ordered) read-once branching programs with nodes corresponding to variables, edges
corresponding to variable outcomes, and each path corresponding to an assignment to the
variables with the resulting evaluation at the leaves. One reason for the succinctness of
BDDs is that directed acyclic graphs may express exponentially many paths. The transition
relation is defined on two state variable sets. It evaluates to true, if and only if an operator
exists that transforms a state into a valid successor. In some sense, BDDs exploit regularities
of the state set and often appear well suited to regular hardware systems. In contrast, many
software systems inherit a highly asynchronous and irregular structure, so that the use of
BDDs with a fixed variable ordering is generally not flexible enough.
For symbolic exploration, a set of states is combined with the transition relation to
compute the set of all possible successor states, i.e. the image. Starting with the initial
state, iteration of image computations eventually explores the entire reachable state space.
196

Taming Numbers and Durations in MIPS

To improve the efficiency of image computations, transition relations are often provided in
partitioned form.
The correspondence between action and model checking (Giunchiglia & Traverso, 1999)
can be roughly characterized as follows. Similar to model checkers, action planners implicitly generate large state spaces, and both exploration approaches are based on applying
operators to the current state. States spaces in model checking and in planning problems are
often modelled as Kripke structures, i.e. state space graphs with states labelled by propositional predicates. The satisfaction of a specified property on the one side corresponds to
a complete exploration, and an unsolvable problem on the other side. In this respect, the
goal in action planning can be cast as an error with the corresponding trail interpreted as a
plan. In the elevator example, the goal of a planning task is to reach a state, in which the
doors are open and the elevator is moving. Action planning refers to safety properties only,
since goal achievement in traditional and competition planning problems have not yet been
extended with temporal properties. However, temporally extended goals are of increasing
research interest (Kabanza, Barbeau, & St-Denis, 1997; Pistore & Traverso, 2001; Lago,
Pistore, & Traverso, 2002).
In contrast to model checkers that perform either symbolic or explicit exploration, MIPS
features both. Moreover, it combines symbolic and explicit search planning in the form of
symbolic pattern databases (Edelkamp, 2002b). The planner MIPS implements heuristic
search algorithms like A* (Pearl, 1985) and IDA* (Korf, 1985) for exploration, which include
state-to-goal approximation into the search process to rank the states to be expanded next.
Heuristic search has brought considerable gains to both planning (Bonet & Geffner, 2001;
Refanidis & Vlahavas, 2000; Hoffmann & Nebel, 2001; Bertoli, Cimatti, & Roveri, 2001a;
Jensen, Bryant, & Veloso, 2002; Feng & Hansen, 2002) and model checking (Yang & Dill,
1998; Edelkamp et al., 2003; Groce & Visser, 2002; Bloem, Ravi, & Somenzi, 2000; Ruys,
2003).
Including resource variables, like the fuel level of a vehicle or the distance between two
different locations, as well as action duration are relatively new aspects for competitive
planning (Fox & Long, 2003). The input format PDDL2.1 is not restricted to variables of
finite domain, but also includes rational (floating-point) variables in both precondition and
effects. Similar to a set of atoms described by a propositional predicate, a set of numerical
quantities can be described by a set of parameters. Through the notation of PDDL2.1, we
refer to parameterized numerical quantities as functions. For example, the fuel level might
be parameterized by the vehicle that is present in the problem instance file description.
In the competition, domains were provided in different tracks according to different layers of language expressiveness: i) pure propositional planning, ii) planning with numerical
resources, iii) planning with numerical resources and constant action duration, iv) planning
with numerical resources and variable action duration, and, in some cases, v) complex problems usually combining time and numbers in more interesting ways. MIPS competed as a
fully automated system and performed remarkably well in all five tracks; it solved a large
number of problems and was the only fully automated planner that produced solutions in
each track of every benchmark domain.
In this paper the main algorithmic techniques for taming rational numbers, objective
functions, and action duration are described. The article is structured as follows. First,
we review the development of the MIPS system and assert its main contributions. Then
197

Edelkamp

we address the object-oriented heuristic search framework of the system. Subsequently, we
introduce some terminology that allows us to give a formal definition of the syntax and
the semantics of a grounded mixed numerical and propositional planning problem instance.
We then introduce the core contributions: critical path scheduling for concurrent plans,
and efficient methods for detecting and using symmetry cuts. PERT scheduling produces
optimal parallel plans in linear time given a sequence of operators and a precedence relation
among them. The paper discusses pruning anomalies and the effect of different optimization
criteria. We analyze the correctness and efficiency of symmetry detection in detail. The
article closes with related work and concluding remarks.

2. The Development of MIPS
The competition version of MIPS refers to initial work (Edelkamp & Reffel, 1999a) in
heuristic symbolic exploration of planning domains with the µcke model checker (Biere,
1997). This approach was effective in sample puzzle solving (Edelkamp & Reffel, 1998) and
in hardware verification problems (Reffel & Edelkamp, 1999).
For implementing a propositional planner, we first used our own BDD library called
StaticBdd, in which large node tables are allocated prior to their use. During the implementation process we changed the BDD representation mainly to improve performance for
small planning problems. We selected the public domain c++ BDD package Buddy (LindNielsen, 1999), which is more flexible. The planning process was semi-automated (Edelkamp
& Reffel, 1999b); variable encodings were provided by hand, while the representations of
all operators were established by enumerating all possible parameter instances. Once the
state space encoding and action transition relation were fixed, exploration in the form of
a symbolic breadth-first search of the state-space could be executed. At that time, we
were not aware of any other work in BDD-based planning such as the work of Cimatti et al.
(1997), which is likely the first link to planning via symbolic model checking. The team used
the model checker (nu)SMV as the basis with an atom-to-variable planning state encoding
scheme on top of it.
Later on, we developed a parser and a static analyzer to automate the inference of state
encodings, the generation of the transition relations, and the extraction of solution paths.
In order to minimize the length of the state encoding, the new analyzer clustered atoms into
groups (Edelkamp & Helmert, 1999). As confirmed by other attempts (Weismüller, 1998),
who started experimenting with PDDL specification in µcke, state minimization is in fact
crucial. The simple encoding using one variable for each atom appears not to be competitive
with respect to Graphplan-based (Blum & Furst, 1995) and SAT-plan based planners (Kautz
& Selman, 1996). Subsequently, MIPS was the first fully automated planning system based
on symbolic model checking technology that could deal with large domain descriptions.
In the second international planning competition MIPS (Edelkamp & Helmert, 2001)
could handle the STRIPS (Fikes & Nilsson, 1971) subset of the PDDL language (McDermott, 2000) and some additional features from ADL (Pednault, 1989), namely negative
preconditions and (universal) conditional effects. MIPS was one of five planning systems to
be awarded for “Distinguished Performance” in the fully automated track. The competition
version (Edelkamp & Helmert, 2000) already included explicit heuristic search algorithms
based on a bit-vector state representation and the relaxed planning heuristic (RPH) (Hoff198

Taming Numbers and Durations in MIPS

mann & Nebel, 2001) as well as symbolic heuristic search based on the HSP heuristic (Bonet
& Geffner, 2001) and a one-to-one atom derivative of RPH. In the competition, we used
breadth-first bi-directional symbolic search whenever the single state heuristic search engine
got stuck in its exploration.
In between the planning competitions, explicit (Edelkamp, 2001c) and symbolic pattern
databases (Edelkamp, 2002b) were proposed as off-line estimators for completely explored
problem abstractions. Roughly speaking, pattern database abstractions slice the state vector of fluents into pieces and adjust the operators accordingly. The completely explored
subspaces then serve as admissible estimates for the overall search and are competitive with
the relaxed planning heuristic in several benchmark domains.
For the third planning competition new levels of the planning domain description language (PDDL) were designed. Level 1 considers pure propositional planning. Level 2 also
includes numerical resources and objective functions to be minimized. Level 3 additionally
allows the specification of actions with durations. Consequently, MIPS has been extended
to cope with these new forms of expressiveness.
First results of MIPS in planning PDDL2.1 problems are presented in (Edelkamp,
2001b). The preliminary treatment illustrates the parsing process in two simple benchmark domains. Moreover, propositional heuristics and manual branching cuts were applied
to accelerate sequential plan generation. This work was extended in (Edelkamp, 2002a),
where we presented two approximate exploration techniques to bound and to fix numerical
domains, first results on symmetry detection based on fact groups, critical path scheduling,
an any-time wrapper to produce optimal plans, and a numerical extension to RPH.

3. Architecture of MIPS
Figure 1 shows the main components of MIPS and the data flow from the input definition
of the domain and the problem instance to the resulting temporal plan in the output. As
shown shaded in light gray, MIPS is divided into four parts: pre-compilation, heuristics,
search algorithms, and post-compilation (scheduling). Henceforth, the planning process
will be coarsely grouped into three stages, pre-compilation, heuristic search planning, and
the construction of temporal plans. The problem and domain description files are fed into
the system, analyzed and grounded. This fixes the state space problem to be solved. The
intermediate result is implicit, but can be saved in a file for use by other planners and model
checkers. The basics of pre-compilation are covered in Section 3.2.
The next stage defines the planning process. The object-oriented workbench design
of the planner allows different heuristic estimates to be combined with different search
strategies and access data structures. Possible choices are listed in Sections 3.3 and 3.4.
Temporal planning is based on (PERT) scheduling. This issue of rearranging sequential
(relaxed) plans is addressed in detail in Section 4.3.
The planning system was developed in the spirit of the heuristic search framework,
HSF for short (Edelkamp, 1999), which allows attachment of newly implemented problem
(puzzle) domains to an already compiled system. Similar to the approach that we took
in model checking within HSF-Spin, we kept the extensible and general design. In fact
we characterized both action planning and protocol validation as single-agent challenges.
In contrast to the model checking approach, for planning we devised a hierarchy of system
199

Edelkamp

domain.pddl

problem.pddl

Precompiler
static analyzer
ground

symmetry

cluster

intermediate representation
Heuristics
explicit PDBs

symbolic PDBs

numerical
RPH

Search Algorithms

relaxed plan

symbolic search

explicit search
RPH

BDDA*, BDD-BFS

A*, IDA*, EHC
scheduling
RPH

sequential plan

relaxed
temporal plan

Scheduler
Critical Path

temporal plan

PERT

Figure 1: Architecture of MIPS.

states: the implementation for numerical states is a derived class of the one for propositional
states.
Similarily, the heuristic search algorithms are all based on an abstract search class. The
main procedures that have to be provided to the search algorithm are a state expansion
procedure, and a heuristic search evaluation function, both located in one of the hierarchically organized heuristic estimator classes. In this sense, algorithms in MIPS are general
node expanding schemes that can be adapted to very different problems. Additional data
structures for the horizon list Open and the visited list Closed are constructed as parameters of the appropriate search algorithms. As a result, the implementations of the heuristic
search algorithms and the associated data structures in the planner MIPS almost match
those in our model checker.
3.1 Example Problem
The running example for the paper is an instance of a rather simple PDDL2.1 problem in
Zeno-Travel. It is illustrated in Figure 2. The initial configuration is drawn to the left of
200

Taming Numbers and Durations in MIPS

A

Scott

B

Dan

C

1000

A

C

D

600

B

800

1000

800

1000

Ernie

600

1000

D

Scott
Ernie

Dan

Figure 2: An instance for the Zeno-Travel domain with initial state (left) and goal state(s)
(right).

the figure and the goal configuration to its right. Some global and local numeric variable
assignments are not shown.
Figures 3 and 4 provide the domain and problem specifications1 . The instance asks for
a temporal plan to fly passengers (dan, scott, and ernie) located somewhere on a small
map (including the cities city-a, city-b, city-c, and city-d) with an aircraft (plane)
to their respective target destinations. Boarding and debarking take a constant amount of
time. The plane has a fixed fuel capacity. Fuel and time are consumed according to the
distances between the cities and the travel speed. Fuel can be restored by refueling the
aircraft. As a result, the total amount of fuel is also maintained as a numerical quantity.
3.2 Precompiler
The static analyzer takes the domain and problem instance as an input, grounds its propositional state information and infers different forms of planner independent static information.
Parsing Our simple Lisp parser generates a tree of Lisp entities. It reads the input files
and recognizes the domain and problem name. To cope with variable typing, we temporarily assert constant typed predicates to be removed together with other constant
predicates in a further pre-compilation step. Thereby, we infer a type hierarchy and
an associated mapping of objects to types.
Indexing Based on the number of counted objects, indices for the grounded predicates,
functions and actions are devised. Since in our example problem we have eight objects and the predicates at and in have two parameters, we reserve 2 · 8 · 8 = 128
index positions. Similarly, the function distance consumes 64 indices, while fuel,
1. [...] denotes that source fragments were omitted for the sake of brevity. In the given example these
are the action definitions for passenger debarking and flying the airplane.

201

Edelkamp

(define (domain zeno-travel)
(:requirements :durative-actions :typing :fluents)
(:types aircraft person city)
(:predicates (at ?x - (either person aircraft) ?c - city)
(in ?p - person ?a - aircraft))
(:functions (fuel ?a - aircraft) (distance ?c1 - city ?c2 - city)
(slow-speed ?a - aircraft) (fast-speed ?a - aircraft)
(slow-burn ?a - aircraft) (fast-burn ?a - aircraft)
(capacity ?a - aircraft)
(refuel-rate ?a - aircraft)
(total-fuel-used) (boarding-time) (debarking-time))
(:durative-action board
:parameters (?p - person ?a - aircraft ?c - city)
:duration (= ?duration boarding-time)
:condition (and (at start (at ?p ?c))
(over all (at ?a ?c)))
:effect (and (at start (not (at ?p ?c)))
(at end (in ?p ?a))))
[...]
(:durative-action zoom
:parameters (?a - aircraft ?c1 ?c2 - city)
:duration (= ?duration (/ (distance ?c1 ?c2) (fast-speed ?a)))
:condition (and (at start (at ?a ?c1))
(at start (>= (fuel ?a) (* (distance ?c1 ?c2) (fast-burn ?a)))))
:effect (and (at start (not (at ?a ?c1)))
(at end (at ?a ?c2))
(at end (increase total-fuel-used
(* (distance ?c1 ?c2) (fast-burn ?a))))
(at end (decrease (fuel ?a)
(* (distance ?c1 ?c2) (fast-burn ?a))))))
(:durative-action refuel
:parameters (?a - aircraft ?c - city)
:duration (= ?duration (/ (- (capacity ?a) (fuel ?a)) (refuel-rate ?a)))
:condition (and (at start (< (fuel ?a) (capacity ?a)))
(over all (at ?a ?c)))
:effect (at end (assign (fuel ?a) (capacity ?a))))
)

Figure 3: Zeno-Travel domain description in PDDL2.1.

slow-speed, fast-speed, slow-burn, fast-burn, capacity, and refuel-rate each
reserve eight index positions. For the quantities total-fuel-used, boarding-time,
debarking-time only a single fact identifier is needed. Last but not least we model
duration as an additional quantity total-time. This special variable is the only one
that is overwritten in the least commitment planning approach when scheduling plans
as described in Section 4.
202

Taming Numbers and Durations in MIPS

(define (problem zeno-travel-1)
(:domain zeno-travel)
(:objects plane - aircraft
ernie scott dan - person
city-a city-b city-c city-d - city)
(:init (= total-fuel-used 0) (= debarking-time 20) (= boarding-time 30)
(= (distance city-a city-b) 600) (= (distance city-b city-a) 600)
(= (distance city-b city-c) 800) (= (distance city-c city-b) 800)
(= (distance city-a city-c) 1000) (= (distance city-c city-a) 1000)
(= (distance city-c city-d) 1000) (= (distance city-d city-c) 1000)
(= (fast-speed plane) (/ 600 60)) (= (slow-speed plane) (/ 400 60))
(= (fuel plane) 750)
(= (capacity plane) 750)
(= (fast-burn plane) (/ 1 2))
(= (slow-burn plane) (/ 1 3))
(= (refuel-rate plane) (/ 750 60))
(at plane city-a) (at scott city-a) (at dan city-c) (at ernie city-c))
(:goal (and (at dan city-a) (at ernie city-d) (at scott city-d)))
(:metric minimize total-time)
)

Figure 4: Zeno-Travel problem instance.
Flattening Temporal Identifiers We interpret each action as an integral entity, so that
all timed propositional and numerical preconditions can be merged. Similarly, all
effects are merged, independent of time at which they happen. Invariant conditions
like (over all (at ?a ?c)) in the action board are added into the precondition set.
We discuss the rationale for this step in Section 4.1.
Grounding Propositions Fact-space exploration is a relaxed enumeration of the planning
problem to determine a superset of all reachable facts. Algorithmically, a FIFO fact
queue is compiled. Successively extracted facts at the front of the queue are matched
to the operators. Each time all preconditions of an operator are fulfilled, the resulting
atoms according to the positive effect (add) list are determined and enqueued. This
allows us to separate off constant facts from fluents, since only the latter are reached
by exploration.
Clustering Atoms For a concise encoding of the propositional part we separate fluents
into groups, so that each state in the planning space can be expressed as a conjunction of (possibly trivial) facts drawn from each fact group (Edelkamp & Helmert,
1999). More precisely, let #pi (o1 , . . . , oi−1 , oi+1 , . . . , on ) be the number of objects oi
for which the fact (p o1 . . . on ) is true. We establish a single-valued invariant at i
if #pi (o1 , . . . , oi−1 , oi+1 , . . . , on ) = 1. To allow for a better encoding, some predicates
like at and in are merged. In the example, three groups determine the unique position
of the persons (one of five) and one group determines the position of the plane (one
of four). Therefore, 3 · dlog 5e + 1 · dlog 4e = 11 bits suffice to encode the total of 19
fluents.
203

Edelkamp

Grounding Actions Fact-space exploration also determines all grounded operators. Once
all preconditions are met and grounded, the symbolic effect lists are instantiated. In
our case we determine 98 instantiated operators, which, by some further simplifications
that eliminate duplicates and trivial operators (no-ops), are reduced to 43.
Grounding Functions Simultanous to fact space exploration of the propositional part of
the problem, all heads of the numerical formulae in the effect lists are grounded. In
the example case only three instantiated formulae are fluent (vary with time): (fuel
plane) with initial value 750 as well as total-fuel-used and total-time both initialized with zero. All other numerical predicates are in fact constants that can be
substituted in the formula-bodies. In the example, the effect in (board dan city-a)
reduces to (increase (total-time) 30), while (zoom plane city-a city-b) has
the numerical effects (increase (total-time) 150),(increase (total-fuel-used)
300)), and (decrease (fuel plane) 300). Refuelling, however, does not reduce to
a single rational number, for example the effects in (refuel plane city-a) only
simplify to (increase (total-time) (/ (- (750 (fuel plane)) / 12.5))) and
(assign (fuel plane) 750). To evaluate the former assignment especially for a forward chaining planner, the variable (total-time) has to be instantiated on-the-fly.
This is due to the fact that the value of the quantity (fuel plane) is not constant
and itself changes over time.
Symmetry Detection Regularities of the planning problem with respect to the transposition of domain objects is partially determined in the static analyzer and is addressed
in detail in Section 5.
The intermediate textual format of the static analyzer in annotated grounded PDDLlike representation serves as an interface for other planners or model checkers, and as an
additional resource for plan visualization. Figures 5 and 6 show parts of the intermediate
representation as inferred in the Zeno-Travel example.
3.3 Heuristics
MIPS incorporates the following heuristic estimates.
Relaxed planning heuristic (RPH) Approximation of the number of planning steps
needed to solve the propositional planning problem with all delete effects removed (Hoffmann & Nebel, 2001). The heuristic is constructive, that is it returns the set of
operators that appear in the relaxed plan.
Numerical relaxed planning heuristic (numerical RPH) Our extension to RPH to
deal with with numbers is a combined propositional and numerical approximation
scheme allowing multiple operator application.
Pattern database heuristic (explicit PDB) Different planning space abstractions are
found in a greedy manner, yielding a selection of pattern databases that fit into main
memory. In contrast to RPH, pattern database can be designed to be disjoint yielding
an admissible estimate as needed for optimal planning in A* (Edelkamp, 2001c).
204

Taming Numbers and Durations in MIPS

(define (grounded zeno-travel-zeno-travel-1)
(:fluents
(at dan city-a)
(at dan city-b)
(at dan city-c)
(at dan city-d)
(at ernie city-a) (at ernie city-b) (at ernie city-c) (at ernie city-d)
(at plane city-a) (at plane city-b) (at plane city-c) (at plane city-d)
(at scott city-a) (at scott city-b) (at scott city-c) (at scott city-d)
(in dan plane)
(in ernie plane) (in scott plane))
(:variables (fuel plane) (total-fuel-used) (total-time))
(:init
(at dan city-c)
(at ernie city-c) (at plane city-a) (at scott city-a)
(= (fuel plane) 750) (= (total-fuel-used) 0) (= (total-time) 0))
(:goal (at dan city-a)
(at ernie city-d) (at scott city-d))
(:metric minimize (total-time) )
(:group dan
(at dan city-a)
(at dan city-b)
(at dan city-c)
(at dan city-d)
(in dan plane))
(:group ernie
(at ernie city-a) (at ernie city-b) (at ernie city-c) (at ernie city-d)
(in ernie plane))
(:group plane
(at plane city-a) (at plane city-b) (at plane city-c) (at plane city-d))
(:group scott
(at scott city-a) (at scott city-b) (at scott city-c) (at scott city-d)
(in scott plane))

Figure 5: Grounded representation of Zeno-Travel domain.
Symbolic pattern database heuristic (symbolic PDB) Symbolic PDBs apply to explicit and symbolic heuristic search engines (Edelkamp, 2002b). Due to the succinct
BDD-representation of sets of states, symbolic PDBs are often orders of magnitudes
larger than explicit ones.
Scheduling relaxed plan heuristic (scheduling RPH) Critical-path analysis through
scheduling guide the plan finding phase. Like RPH, which computes the length of the
greedily extracted sequential plan, scheduling RPH also takes the relaxed sequence
of operators into account, but searches for a suitable parallel arrangement, which in
turn defines the estimator function.
3.4 Exploration Algorithms
The algorithm portfolio includes three main explicit heuristic search algorithms.
A* The A* algorithm (Hart, Nilsson, & Raphael, 1968) is a variant of Dijkstra’s singlesource shortest path exploration scheme executed on a re-weighted state space graph.
For lower bound heuristics, A* can be shown to generate optimal plans (Pearl, 1985).
Weighting the influence of the heuristic estimate may accelerate solution finding, but
also affects optimality (Pohl, 1977).
205

Edelkamp

(:action board dan plane city-a
:condition
(and (at dan city-a) (at plane city-a))
:effect
(and (in dan plane) (not (at dan city-a))
(increase (total-time) (30.000000))))
[...]
(:action zoom plane city-a city-b
:condition
(and
(at plane city-a)
(>= (fuel plane) (300.000000)))
:effect
(and (at plane city-b) (not (at plane city-a))
(increase (total-time) (60.000000))
(increase (total-fuel-used) (300.000000))
(decrease (fuel plane) (300.000000))))
[...]
(:action refuel plane city-a
:condition
(and
(at plane city-a)
(< (fuel plane) (750.000000)))
:effect
(and
(increase (total-time) (/ (- (750.000000) (fuel plane)) (12.500000)))
(assign (fuel plane) (750.000000))))
[...]
)

Figure 6: Grounded representation of Zeno-Travel domain (cont.).

Iterative-Deepening A* (IDA*) The memory-limited variant of A* is suited to large
exploration problems with evaluation functions of small integer range and low time
complexity (Korf, 1985). IDA* can be extended with bit-state hashing (Edelkamp &
Meyer, 2001) to improve duplicate detection with respect to ordinary transposition
tables (Reinefeld & Marsland, 1994).
(Enforced) Hill Climbing (HC) The approach is another compromise between exploration and exploitation. Enforced HC searches with an improved evaluation in a
breadth-first manner and commits established action selections as final (Hoffmann,
2000). Enforced HC is complete in undirected problem graphs.
MIPS also features the following two symbolic search algorithms2 .
2. For non-deterministic domains, we have started implementing the weak, strong and strong cyclic exploration algorithms of (Cimatti, Roveri, & Traverso, 1998).

206

Taming Numbers and Durations in MIPS

Bidirectional Symbolic Breadth-First-Search (BDD-BFS) The implementation performs bidirectional blind symbolic search, choosing the next search direction to favor
the faster execution from the previous iterations (Edelkamp & Helmert, 1999).
Symbolic A* (BDDA*) The algorithm (Edelkamp & Reffel, 1998) performs guided symbolic search and takes a (possibly partitioned) symbolic representation of the heuristic
as an additional input.
3.5 Composition of the Competition Version
In Figure 1 we have shaded the parts that were actually used in the competition version of
MIPS in dark gray. We used the relaxed planning heuristic for sequential plan generation.
The scheduling relaxed planning heuristic was used in temporal domains. Only in Level 2
problems did we use the numerically extended RPH, since it was added to the system in the
final weeks of the competition. We experimented with (symbolic) pattern databases with
mixed results. Since pattern databases are purely propositional in our implementation and
do not provide the retrieval of operators in the optimal abstract plan, we did not include
them in the competition version.
Our approach to extend the relaxed planning heuristic with numerical information helps
to find plans in challenging numerical domains like Settlers and was influenced by Hoffmann’s work on his competing planner Metric-FF (Hoffmann, 2002a). It builds a relaxed
planning graph by computing a fixed-point of a state vector restricted to monotonically
increasing propositional and numerical variables. Our version for integrating numbers into
the relaxed planning heuristic is not as general as Hoffmann’s contribution: it is restricted
to variable-to-constant comparisons and lacks the ability to simplify linear constraints.
Therefore, we omit the algorithmic details in this paper.
We decided not to employ (enforced) hill climbing for explicit plan generation as is done
in Metric-FF and probably LPG. Instead we applied A* with weight 2, that is the merit for
all states S ∈ S was fixed as f (S) = g(S) + 2 · h(S). The more conservative plan generation
engine was chosen to avoid unrecognized dead-ends, which we expected to be present in
benchmark problems. Our objective was that, at least, completeness should be preserved.
We also avoided known incomplete pruning rules, like action relevance cuts (Hoffmann &
Nebel, 2001) and goal ordering cuts (Koehler & Hoffmann, 2000).
In MIPS, (weighted) A* accesses both a Dial and a Weak-Heap priority queue data
structure. The former is used for propositional planning only, while the latter applies to
general planning with scheduling estimates. A Dial priority queue (Dial, 1969) has linear
run time behavior, if the maximal value w(u, v) + h(v) − h(u) of all edges (u, v) in the
weighted state space graph (labelled with heuristic h) is bounded by a constant. WeakHeaps (Edelkamp & Stiegeler, 2002) are simple and efficient relaxations to ordinary heaps.
Priority queues have been implemented as dynamic tables that double their sizes if they
become filled. Moreover, MIPS stores all generated and expanded states in a hash table
with chaining 3 . As a further compression of the planning state space, all variables that
appear in the objective function are neglected from hash address calculations and state
3. An alternative storage structure is a collection of persistent trees (Bacchus & Kabanza, 2000), one for
each predicate. In the best case, queries and update times for the structure are logarithmic in the number
of represented atoms.

207

Edelkamp

comparisons. In general, this may lead to a sub-optimal pruning of duplicates. However,
for most benchmark domains this will not destroy optimality, since variables addressed in
the objective function are frequently monotonic and synonyms found later in the search
refer to worse solutions.
The price to be paid for selecting A*, especially in planning problems with large branching factors, is that storing all frontier nodes is space consuming. Recent techniques for
partial expansion of the horizon list (Yoshizumi, Miura, & Ishida, 2000) or reduced storage
of the visited list (Korf & Zhang, 2000; Zhou & Hansen, 2003) have not been included to
the system. In most cases, the number of expanded nodes was often not that large, while
computing the relaxed planning estimate appeared to be the computational bottleneck.
In retrospect, in the domains that were chosen, dead-ends were not central, so that hill
climbers appeared to be more effective at finding solutions.
In temporal domains we introduced an additional parameter δ to scale the influence
between propositional estimates (fp (S) = gp (S) + 2 · hp (S)) and scheduled ones (fs (S) =
gs (S) + 2 · hs (S)). More precisely, we altered the comparison function for the priority queue,
so that a comparison of parallel length priorities was invoked if the propositional difference
of values was not larger than δ ∈ IN0 . A higher value of δ refers to a higher influence of the
scheduling RPH, while δ = 0 indicates no scheduling at all. In the competition we produced
data with δ = 0 (pure MIPS), and δ = 2 (optimized MIPS). In most comparisons of MIPS
to other planners the plain version is used, since it produces more solutions.
In (Edelkamp, 2002a) we experimented with an enumeration approach to fix numerical
variables to a finite domain, and with an any-time wrapper for optimization of objective
functions. These options were excluded from the competition version because of their
unpredictable impact on the planner’s performance.
3.6 Visualization
Visualization is important to ease plan understanding and to quickly detect inefficiencies
in the plan generation module. For visualization of plans with MIPS we extended the
animation system Vega (Hipke, 2000); a Client-Server architecture that runs an annotated
algorithm on the server side, which is visualized on the client side in a Java frontend. The
main purpose of the server is to make algorithms accessible through TCP/IP. It is able to
receive commands from multiple clients at the same time. We have extended Vega in two
ways (cf. Figures 7 and 8).
Gannt Chart Visualization Gannt Charts are representations for schedules, in which
horizontal bars are drawn for each activity, indicating estimated duration/cost. The
user selects any planner to be executed and the domain and problem file, which are
interpreted as command line options. Alternatively, established plans can be sent
directly to the visualizer with a void planner that merely mirrors the solution file.
Benchmark Visualization The second extension is a program suite to visualize all competition domains. At the moment, only sequential plans are shown. For temporal
plans, a refined simulation is required, like the one produced by the PDDL2.1 plan
validator. Fortunately, in MIPS each temporal plan is a rescheduling of a sequential
one.
208

Taming Numbers and Durations in MIPS

Figure 7: Visualization of a plan in Gannt Chart format.
The images that represent domain objects were collected with an image web search
engine4 . To generalize from specific instances, we advised the MIPS planner to export
propositional and numeric state infomation of an established plan in c-like syntax,
which in turn is included as a header by the domain visualizer.

4. PDDL2.1 Planning
In this section we elaborate on metric and temporal planning in MIPS. We give a formal
description on grounded planning instances and introduce the temporal model that we have
4. We used Google (cf. www.google.de) and searched for small GIFs

209

Edelkamp

Figure 8: Visualization of a planning problem instance of Settlers.

chosen. Next we look at operator dependency and the resulting action precedence relation.
We discuss optimality of the approach and some anomalies that can occur during state
space pruning. Last but not least, we turn to the treatment of arbitrary plan objective
functions.
Table 1 displays the basic terminology for sets used in this paper. As in most currently
successful planning system, MIPS grounds parameterized information present in the domain
description. For each set we infer a suitable index set, indicated by a bijective mapping φ
from each set to a finite domain. This embedding is important to deal with unique identifiers
of entities instead of their textual or internal representation. The arrays containing the
corresponding information can then be accessed in constant time.
210

Taming Numbers and Durations in MIPS

Set
OBJ
T YPE
PRED
FUN C
ACT
O
F
V

Descriptor
objects
object types
predicates
functions
actions
operators
fluents/atoms
variables

Example(s)
dan, city-a, plane, . . .
aircraft, person, . . .
(at ?a ?c), (in ?p ?a), . . .
(fuel ?a), (total-time), . . .
(board ?a ?p), (refuel ?a), . . .
(board plane scott), . . .
(at plane city-b), . . .
(fuel plane), (total-time), . . .

Table 1: Basic set definitions.

Consequently, like several other planning systems, MIPS refers to grounded planning
problem representations.
Definition 1 (Grounded Planning Instance) A grounded planning instance is a quadruple
P = hS, I, O, Gi, where S is the set of planning states, I ∈ S is the initial state, G ⊆ S is
the set of goal states. In a mixed propositional and numerical planning problem the state
space S is given by
S ⊆ 2F × IR|V| ,
where 2F is the power set of F. Therefore, a state S ∈ S is a pair (Sp , Sn ) with propositional
part Sp ∈ 2F and numerical part Sn ∈ IR|V| .
For the sake of brevity, we assume the operators are in normal form, which means that
propositional parts (preconditions and effects) satisfy standard STRIPS notation (Fikes &
Nilsson, 1971) and numerical parts are given in the form of arithmetic trees t taken from
the set of all trees T with arithmetic operations in the nodes and numerical variables and
evaluated constants in the leaves. However, there is no fundamental difference for a more
general representation of preconditions and effects. The current implementation in MIPS
simplifies ADL expressions in the preconditions and takes generic precondition trees for the
numerical parts, thereby including comparison symbols, logical operators and arithmetic
subtrees5 .
Definition 2 (Syntax of Grounded Planning Operators) An operator o ∈ O in normal form
o = (α, β, γ, δ) has propositional preconditions α ⊆ F, propositional effects β = (βa , βd ) ⊆
F 2 with add list βa and delete list βd , numerical preconditions γ, and numerical effects δ. A
numerical precondition c ∈ γ is a triple c = (hc , ⊗, tc ), where hc ∈ V, ⊗ ∈ {≤, <, =, >, ≥},
and tc ∈ T , where T is an arithmetic tree. A numerical effect m ∈ δ is a triple m =
(hm , ⊕, tm ), where hm ∈ V, ⊕ ∈ {←, ↑, ↓} and tm ∈ T . In this case, we call hm the head of
the numerical effect.
5. In newer versions of MIPS mixing numerical and logical preconditions of the form (or P (< F 3)), with
P ∈ F and F ∈ V is in fact feasible. Boolean expressions are put into negational normal form and a
disjunction in the precondition will produce different action instantiations.

211

Edelkamp

Obviously, ⊗ ∈ {≤, <, =, >, ≥} represents the associated comparison relation, ← denotes an assignment to a variable, while ↑ and ↓ indicate a respective increase or decrease
operation.
Definition 3 (Constraint Satisfaction and Modifier Update) Let φ be the index mapping
for variables. A vector Sn = (S1 , . . . , S|V| ) of numerical variables satisfies a numerical
constraint c = (hc , ⊗, tc ) ∈ γ if Sφ(hc ) ⊗ eval(Sn , tc ) is true, where eval(Sn , tc ) ∈ IR is
obtained by substituting all v ∈ V in tc by Sφ(hc ) followed by a simplification of tc .
0 ) by modifier
A vector Sn = (S1 , . . . , S|V| ) is updated to the vector Sn0 = (S10 , . . . , S|V|
m = (hm , ⊕, tm ) ∈ δ, if
0
• Sφ(h
= eval(Sn , tm ) for ⊕ = ←,
m)
0
• Sφ(h
= Sφ(hm ) + eval(Sn , tm ) for ⊕ = ↑, and
m)
0
• Sφ(h
= Sφ(hm ) − eval(Sn , tm ) for ⊕ = ↓.
m)

We next formalize the application of planning operators to a given state.
Definition 4 (Semantics of Grounded Planning Operator Application) An operator o =
(α, β, γ, δ) ∈ O applied to a state S = (Sp , Sn ), Sp ∈ 2F and Sn ∈ IR|V| , yields a successor
state S 0 = (Sp0 , Sn0 ) ∈ 2F × IR|V| as follows.
If α ⊆ Sp and Sn satisfies all c ∈ γ then Sp0 = (Sp \ βd ) ∪ βa and the vector Sn is updated
for all m ∈ δ .
The propositional update Sp0 = (Sd \ βd ) ∪ βa is defined as in standard STRIPS. As an
example take the state S = (Sp , Sn ) with
Sp = {(at ernie city-d), (at plane city-a), (at scott city-d), (in dan plane)}
Sn = {(fuel plane) : 83.3333, (total-fuel-used) : 1666.6667, (total-time) : 710}.
The successor Sn0 = (Sp0 , Sn0 ) of S due to action (debark dan plane city-a) with
Sp0 = {(at dan city-a), (at ernie city-d), (at plane city-a), (at scott city-d)}
Sn0 = {(fuel plane) : 83.3333, (total-fuel-used) : 1666.6667, (total-time) : 730}.
In some effect lists the order of update operations is important. For example when
refuelling the aircraft in ZenoTravel, cf. Figure 6, the fuel level has to be reset after variable
total-time is updated.
The set of goal states G is often given as G = (Gp , Gn ) with a partial propositional state
description Gp ⊂ F, and Gn as a set of numerical conditions c = (hc , ⊗, tc ). Moreover,
the arithmetic trees tc usually collapses to simple leaves labelled with numerical constants.
Hence, only for the sake of simplifying the complexity analysis for object symmetry we
might assume that |Gn | ≤ |V|. Complex goal description are no limitation to the planner,
since they can easily transformed to preconditions of an goal-enabling opererator.
212

Taming Numbers and Durations in MIPS

4.1 Temporal Model
The simplest approach for solving a temporal planning problem is to generate a sequential
plan. Of course, this option assumes that the temporal structure contributes only to the
value of the plan and not to its correctness. That is, it assumes that there is no necessary
concurrency in a valid plan. In cases in which actions achieve conditions at their start
points and delete them at their end points, for example, concurrency can be a necessary
part of the structure of a valid plan.
Definition 5 (Sequential Plan) A solution to a planning problem P = hS, I, O, Gi in the
form of a sequential plan πs is an ordered sequence of operators Oi ∈ O, i ∈ {1, . . . , k},
that transforms the initial state I into one of the goal states G ∈ G, i.e., there exists a
sequence of states Si ∈ S, i ∈ {0, . . . , k}, with S0 = I, Sk = G such that Si is the outcome
of applying Oi to Si−1 , i ∈ {1, . . . , k}.
The time stamp ti for a durational operator Oi , i ∈ {1, . . . , k} is its starting time. If
Pi−1
d(Oj ).
d(Oi ) is the duration of operator Oi , then ti = j=1
For sequential plans, time stamps are calculated in MIPS using the extra variable
total-time. This variable is updated when scheduling operators. An example of a sequential plan with time stamps is shown in Figure 12.
Minimizing sequential plan length was the only objective in the first and second planning competitions. Since Graphplan-like planners (Blum & Furst, 1995) like IPP (Koehler,
Nebel, & Dimopoulos, 1997) and STAN (Long & Fox, 1998) already produced parallel plans
(assuming action duration 1), this was indeed a limiting factor in evaluating plan quality.
The most important reason for this artificial restriction was that total-ordered plans were
easier to automatically validate, a necessity for checking correctness in a competition.
PDDL 2.1 domain descriptions include temporal modifiers at start, over all, and at end,
where the label at start denotes the preconditions and effects at invocation time of the
action, over all refers to an invariance condition and at end to the finalization conditions
and consequences of the action.
In Figure 9 we show two different options for flattening this information to simple
preconditions and effects in order to derive the semantic for sequential plans. In the first
case (top right), the compound operator is split into three smaller parts, one for action
invocation, one for invariance maintenance, and one for action termination. This is the
semantics suggested by (Fox & Long, 2003).
In PDDL2.1 there are no effects in the invariance pattern, i.e. B 0 = ∅. As in action
board, it is quite natural to code invariance in the form of conditions (B) that perform no
actual status change: when a person boards an aircraft in a city the aircraft is required to
remain at the city throughout the action. When moving through a corridor, the status of
being in the corridor that could be encoded in the invariant would change at the starting
time of the action execution.
Moreover, we found that in the benchmarks it is uncommon that new effects in at-start
are preconditioned for termination control or invariance maintenance, i.e. A0 ∩ (B ∪ C) = ∅.
Even though the intersection of conditions and effects are not formally defined yet, this can
be interpreted as executing one construct does not interfere with the other one. This reflects
213

Edelkamp

pre: eff: pre: eff: pre: eff:
at-start

over-all

at-end

cond:

A

B

C

eff:

A0

B0

C0

A A0

pre:

B B0

C C0

eff:

ABC

A0 B 0 C 0

Figure 9: Compiling temporal modifiers into operators.
a possible partition of an operator into sub-operators A, B, C, A0 , B 0 , and C 0 . Dependence
and transposition of such separated conditions and effects are considered in Section 4.2.
If we consider the example problem once more, we observe, that in the action board, A0
consists of the at (person airplane) predicate. As seen above, B requires the plane to stay
at the city of boarding, while C is empty. In action zoom, A0 contains the effect that the
plane is no longer at the location where the flight started, and B and C are both empty. In
all cases we have A0 ∩ (B ∪ C) = ∅.
If B 0 = ∅ and A0 ∩ (B ∪ C) = ∅ then the sequential execution of the sequence of
sub-operators (A, A0 , B, B 0 , C, C 0 ) is equal to the execution sequence (A, B, C, A0 , B 0 , C 0 ).
The reasoning is as follows. Since B 0 = ∅ we have (A, A0 , B, B 0 , C, C 0 ) = (A, A0 , B, C, C 0 ).
Conditions A0 ∩ B = ∅ and A0 ∩ C = ∅ allows us to exchange the order of the corresponding
items, so that (A, A0 , B, C, C 0 ) = (A, B, C, A0 , C 0 ). Once more, we apply B 0 = ∅ to derive
(A, B, C, A0 , C 0 ) = (A, B, C, A0 , B 0 , C 0 ). The consequence remains valid if the condition
B 0 = ∅ is weakened to B 0 ∩ C = ∅.
In MIPS the operator representation at the bottom right of Figure 9 was chosen. Note
that the intermediate format of the example problem in Figures 5 and 6 implicitly assumed
this temporal model. For sequential planning in the competition benchmark domains we
have not observed many deficiencies with this model6 .
However, the applicability of the model for exploiting parallelism is limited. For example
consider two people that lift a table from two sides at once, which could not be done with
just one person alone. In this case we have a parallel execution of a set of actions that
cannot be totally ordered. This is not allowed in MIPS. It may be argued that defining
such an action that requires two different persons to be at a certain place would require
the equality construct in PDDL or some form of numerical maintenance of the number of
people in the room, but we found another (artificial) example of a planning problem with
no total order. Consider the simple STRIPS planning problem domain with I = {B},
G = {{A, C}}, and O = {({B}, {A}, {B}), ({B}, {C}, {B})}. Obviously, both operators
are needed for goal achievement, but there is no sequential plan of length 2, since B is
deleted in both operators. However, a parallel plan could be devised, since all precondition
are fulfilled at the first time step.
6. In current versions of MIPS we have refined the model, where at-start, over all, and at-end information
is preserved through the grounding process and is attached to each action. The approach does allow
dependent operators to overlap and minimizes the number of  gaps, between start-start, start-end and
end-end exclusions. In some of the domains, this improvement yields much better solutions.

214

Taming Numbers and Durations in MIPS

4.2 Operator Dependency
The definition of operator dependency enables computing optimal schedules of sequential
plans with respect to the generated action sequence and its causal operator dependency
structure. If all operators are dependent (or void with respect to the optimizer function),
the problem is inherently sequential and no schedule leads to any improvement.
Definition 6 (Dependency/Mutex Relation) Let L(t) denote the set of all leaf variables in
the tree t ∈ T . Two grounded operators O = (α, β, γ, δ) and O0 = (α0 , β 0 , γ 0 , δ 0 ) in O are
dependent/mutex, if one of the following three conflicts hold.
Propositional conflict The propositional precondition set of one operator has a nonempty intersection with the add or the delete list of the other, i.e., α ∩ (βa0 ∪ βd0 ) 6= ∅
or (βa ∪ βd ) ∩ α0 6= ∅.
Direct numerical conflict The head of a numerical modifier of one operator is contained
in some condition of the other one, i.e. there exists a c0 = (h0c , ⊗, t0c ) ∈ γ 0 and an
m = (hm , ⊕, tm ) ∈ δ with hm ∈ L(t0c ) ∪ {h0c } or there exists a c = (hc , ⊗, tc ) ∈ γ and
an m0 = (h0m , ⊕, t0m ) ∈ δ 0 with h0m ∈ L(tc ) ∪ {hc }.
Indirect numerical conflict The head of the numerical modifier of one operator is contained in the formula body of the modifier of the other one, i.e., there exists an
m = (hm , ⊕, tm ) ∈ δ and m0 = (h0m , ⊕, t0m ) ∈ δ 0 with hm ∈ L(t0m ) or h0m ∈ L(tm ).
As an example, the operators (board scott plan city-a) and (fly plane city-a
city-c) have a propositional conflict on the fluent (at plane city-a), while (refuel
plane-a city-a) and (fly plane city-a city-c) have a direct numerical conflict on
the variable (fuel plane). Indirect conflicts are more subtle, and do not appear in the
example problem.
We will use dependency to find an optimal concurrent arrangement of the operators in
the sequential plan. If O2 is dependent on O1 and O1 appears before O2 in the sequential
plan, O1 has to be invoked before O2 starts. The dependence relation is reflexive, i.e. if O
is in conflict with O0 then O0 is in conflict with O. Moreover, it appears restrictive when
compared to the PDDL 2.1 guidelines for mutual exclusion (Fox & Long, 2003), which
allows operators to be partially overlapping even if they are dependent.
However, it is possible to generalize our approach. If, according to the model of Fox
and Long, the two actions Oi are represented as (Ai , A0i , Bi , Bi0 , Ci , Ci0 ), i ∈ {1, 2}, the
dependency violation between O1 and O2 can be located by identifying the sub-operators
that interact. In fact we may identify eight possible refined conflicts in which (A1 ∪ A01 )
interacts with (A2 ∪ A02 ), (A1 ∪ A01 ) interacts with (B2 ∪ B20 ), (A1 ∪ A01 ) interacts with
(C2 ∪ C20 ), (B1 ∪ B10 ) interacts with (A2 ∪ A02 ), (B1 ∪ B10 ) interacts with (C2 ∪ C20 ), (C1 ∪ C10 )
interacts with (A2 ∪ A02 ), (C1 ∪ C10 ) interacts with (A2 ∪ A02 ), or (C1 ∪ C10 ) interacts with
(A2 ∪ A02 ). By asserting duration zero for the pair (Ai , A0i ), d(A) for (Bi , Bi0 ), and again zero
for the pair (Ci , Ci0 ), one can fix the earliest start and end time of O2 with respect to O1 .
In the competition version of MIPS, we stick to the simplified temporal model. For
the competition domains, improving sequential plans according to this dependency relation
turned out to produce plans of sufficient quality.
215

Edelkamp

In our implementation, the dependence relation is computed beforehand and tabulated
for constant time access. To improve the efficiency of pre-computation, the set of leaf
variables is maintained in an array, once the grounded operator is constructed.
The original Graphplan definition of the propositional mutex relation is close to ours.
It fixes interference as βd0 ∩ (βa ∪ α) 6= ∅ and (βa0 ∪ α0 ) ∩ βd 6= ∅.
Lemma 1 If βd ⊆ α and βd0 ⊆ α0 , operator inference in the Graphplan model is implied
by the propositional MIPS model of dependence.
Proof: If βd ⊆ α and βd0 ⊆ α0 , for two independent operators o = (α, β) and o0 = (α0 , β 0 ):
α ∩ (βa0 ∪ βd0 ) = ∅ implies βd ∩ (βa0 ∪ βd0 ) = ∅, which in turn yields βa ∩ βd0 = ∅. The condition
βa0 ∩ βd = ∅ is inferred analogously.
The notion of dependency is also related to partial order reduction in explicit-state model
checking (Clarke et al., 1999), where two operators O1 and O2 are independent if for each
state S ∈ S the following two properties hold:
1. Neither O1 or O2 disable the execution of the other.
2. O1 and O2 are commutative, i.e. O1 (O2 (S)) = O2 (O1 (S)) for all S.
The next result indicates that both state space enumeration approaches refer to the
same property.
Theorem 1 (Commutativity) Two independent (STRIPS) operators O = (α, β) and O0 =
(α0 , β 0 ) with βd ⊆ α and βd0 ⊆ α0 are commutative and preserve the enabled property (i.e.
if O and O0 are enabled in S then O is enabled in O0 (S) and O0 is enabled in O(S)).
Proof: Since βd ⊆ α and βd0 ⊆ α0 , we have βa ∩βd0 = ∅ and βa0 ∩βd = ∅ by Lemma 1. Let
be the state ((S \ βd ) ∪ βa ) and let S 00 be the state ((S \ βd0 ) ∪ βa0 ). Since (βa0 ∪ βd0 ) ∩ α = ∅,
O is enabled in S 00 , and since (βa ∪ βd ) ∩ α0 = ∅, O0 is enabled in S 0 . Moreover,
S0

O(O0 (S)) = (((S \ βd0 ) ∪ βa0 ) \ βd ) ∪ βa
= (((S \ βd0 ) \ βd ) ∪ βa0 ) ∪ βa
= S \ (βd0 ∪ βd ) ∪ (βa0 ∪ βa )
= S \ (βd ∪ βd0 ) ∪ (βa ∪ βa0 )
= (((S \ βd ) \ βd0 ) ∪ βa ) ∪ βa0
= (((S \ βd ) ∪ βa ) \ βd0 ) ∪ βa0 = O0 (O(S)).

As a consequence, operator independence indicates possible transpositions of two operators O1 and O2 to prune exploration in sequential plan generation. A less restrictive
notion of independence, in which several actions may occur at the same time even if one
deletes an add-effect of another is provided in (Knoblock, 1994). To detect domains for
which parallelization leads to no improvement, we utilize the following sufficient criterion.
216

Taming Numbers and Durations in MIPS

Definition 7 (Inherent Sequential Domains) A planning domain is said to be inherently
sequential if each operator in any sequential plan is either instantaneous (i.e. with zero
duration) or dependent on its immediate predecessor.
The static analyzer checks this by testing each operator pair. While some benchmark domains like DesertRats and Jugs-and-Water are inherently sequential, others like ZenoTravel
and Taxi are not.
Definition 8 (Parallel Plan) A solution to a planning problem P = hS, I, O, Gi in the
form of a parallel plan πc = ((O1 , t1 ), . . . , (Ok , tk )) is an arrangement of operators Oi ∈ O,
i ∈ {1, . . . , k}, that transforms the initial state I into one of the goal states G ∈ G, where
Oi is executed at time ti ∈ IR≥0 .
An example of a parallel plan for the ZenoTravel problem is depicted in Figure 12.
Backstöm (1998) clearly distinguishes partially ordered plans (O1 , . . . , Ok , ), with the
relation  ⊆ {O1 , . . . , Ok }2 being a partial order (reflexive, transitive, and antisymmetric), from parallel plans (O1 , . . . , Ok , , #), with # ⊆ ( ∪ −1 ) (irreflexive, symmetric)
expressing, which actions must not be executed in parallel.
Definition 9 (Precedence Ordering) An ordering d induced by the operators O1 , . . . , Ok
is defined by
Oi d Oj : ⇐⇒ Oi and Oj are dependent and 1 ≤ i < j ≤ k.
Precedence is not a partial ordering, since it is neither reflexive nor transitive. By computing
the transitive closure of the relation, however, precedence could be extended to a partial
ordering. A sequential plan O1 , . . . , Ok produces an acyclic set of precedence constraints
Oi d Oj , 1 ≤ i < j ≤ k, on the set of operators. It is also important to observe, that the
constraints are already topologically sorted according to d with the index order 1, . . . , k.
Definition 10 (Respecting Precedence Ordering in Parallel Plan) For O ∈ O let d(O) ∈
IR≥0 be the duration of operator O in a sequential plan. In a parallel plan πc = ((O1 , t1 ),
. . . , (Ok , tk )) that respects d , we have ti + d(Oi ) ≤ tj for Oi d Oj , 1 ≤ i < j ≤ k.
For optimizing plans (Bäckström, 1998) defines parallel execution time as max{ti +
d(Oi ) | Oi ∈ {O1 , . . . , Ok }}, so that if Oi  Oj , then ti + d(Oi ) ≤ tj , and if Oi #Oj , then
either ti + d(Oi ) ≤ tj or tj + d(Oj ) ≤ ti . These two possible choices in # are actually not
apparent in our approach, since we already have a precedence relation at hand and just
seek the optimal arrangement of operators. Consequently we assert that only one option,
namely ti + d(Oi ) ≤ tj can be true, reducing # to d . In order to find optimal schedules
of sequential plans an approach similar to (Bäckström, 1998) would be necessary. This
would dramatically increase the computational complexity, since optimal scheduling of a
set of fixed-timed operators is NP-hard. Therefore, we decided to restrict the dependency
relation to d .
Definition 11 (Optimal Parallel Plan) An optimal parallel plan with respect to a sequence
of operators O1 , . . . , Ok and precedence ordering d is a plan π ∗ = ((O1 , t1 ), . . . , (Ok , tk ))
with minimal parallel execution time OP T = max{ti + d(Oi ) | Oi ∈ {O1 , . . . , Ok }} among
all parallel plans πc = ((O1 , t01 ), . . . , (Ok , t0k )) that respect d .
217

Edelkamp

Procedure Critical-Path
Input: Sequence of operators O1 , . . . , Ok , precedence ordering d
Output: Optimal parallel plan length max{ti + d(Oi ) | Oi ∈ {O1 , . . . , Ok }}
for all i ∈ {1, . . . , k}
e(Oi ) ← d(Oi )
for all j ∈ {1, . . . , i − 1}
if (Oj d Oi )
if e(Oi ) < e(Oj ) + d(Oi )
e(Oi ) ← e(Oj ) + d(Oi )
return max1≤i≤k e(Oi )

Figure 10: Algorithm to compute critical path costs.
Many algorithms have been suggested to convert sequential plans into partially ordered
ones (Pednault, 1986; Regnier & Fade, 1991; Veloso, Pérez, & Carbonell, 1990). Most
of them interpret a totally ordered plan as a maximal constrained partial ordering  =
{(Oi , Oj ) | 1 ≤ i < j ≤ k} and search for less constrained plans. However, the problem of
minimum constraint “deordering” has also been proven to be NP-hard, unless the so-called
validity check is polynomial (Bäckström, 1998), where deordering maintains validity of the
plan by lessening its constrainedness, i.e. 0 ⊆ for a new ordering 0 .
Since we have an explicit model of dependency and time, optimal parallel plans will not
change the ordering relation d at all.
4.3 Critical Path Analysis
The Project Evaluation and Review Technique (PERT) is a critical path analysis algorithm
usually applied to project management problems. A critical path is a sequence of activities
such that the total time for activities on this path is greater than or equal to any other
path of operators. A delay in any tasks on the critical path leads to a delay in the project.
The heart of PERT is a network of tasks needed to complete a project, showing the order
in which the tasks need to be completed and the dependencies between them.
As shown in Figure 10, PERT scheduling reduces to a variant of Dijkstra’s shortest
path algorithm in acyclic graphs (Cormen, Leiserson, & Rivest, 1990). As a matter of fact,
the algorithm returns the length of the critical path and not the inferred partially ordered
plan. However, obtaining the temporal plan is easy. In the algorithm, e(Oi ) is the tentative
earliest end time of operator Oi , i ∈ {1, . . . , k}, while the earliest starting times ti for all
operators in the optimal plan are given by ti = e(Oi ) − d(Oi ).
Theorem 2 (PERT Scheduling) Given a sequence of operators O1 , . . . , Ok and a precedence ordering d , an optimal parallel plan π ∗ = ((O1 , t1 ), . . . , (Ok , tk )) can be computed in
optimal time O(k + | d |).
Proof: The proof is by induction on i ∈ {1, . . . , k}. The induction hypothesis is that
after iteration i the value e(Oi ) is correct, e.g. e(Oi ) is the earliest end time of operator
218

Taming Numbers and Durations in MIPS

Oi . This is clearly true for i = 1, since e(O1 ) = d(O1 ). We now assume that the hypothesis
is true 1 ≤ j < i and look at iteration i. There are two choices. Either there is a j ∈
{1, . . . , i − 1} with Oj d Oi . For this case after the inner loop is completed, e(Oi ) is
set to max{e(Oj ) + d(Oj ) | Oj d Oi , j ∈ {1, . . . , i − 1}}. On the other hand, e(Oi ) is
optimal, since Oi cannot start earlier than max{e(Oj ) | Oj d Oi , j ∈ {1, . . . , i − 1}}, since
all values e(Oj ) are already the smallest possible by the induction hypothesis. If there is
no j ∈ {1, . . . , i − 1} with Oj d Oi , then e(Oi ) = d(Oi ) as in the base case. Therefore, at
the end, max1≤i≤k e(Oi ) is the optimal parallel path length.
The time and space complexity of the algorithm Critical-Path are clearly in O(k 2 ),
where k is the length of the sequential plan. Using an adjacency list representation these
efforts can be reduced to time and space proportional to the number of vertices and edges
in the dependence graph, which are of size O(k + | d |). The bound is optimal, since the
input consists of Θ(k) operators and Θ(| d |) dependencies among them.
Can we apply critical path scheduling, even if we consider the temporal model of Fox
and Long, allowing overlapping operator execution of dependent operators? The answer is
yes. We have already seen that when considering two dependent operators Oi and Oj in the
Fox and Long model, we can determine the earliest start (and end) time of Oj with respect
to the fixed start time of Oi . This is all that we need. The proof of Theorem 2 shows that
we can determine the earliest end time for the operators sequentially.
4.4 On the Optimality of MIPS
Since MIPS optimally schedules sequential plans, the question remains, will the system
eventually find an optimal plan? In the competition, the system terminates when the
first sequential plan is found. Since the relaxed planning heuristic is not admissible, all
A* variants cannot guarantee optimal (sequential or parallel) plans. However, computing
optimal plans is desirable, even if – due to limited computational resources – finding optimal
plans is hard.
According to our temporal model, in an optimal parallel plan, each operator either starts
or ends at the start or end time of another operator. Therefore, at least for a finite number
of actions in the optimal plan, we have a possibly exponential but finite number of possible
parallel plans.
This immediately leads to the following naive plan enumeration algorithm: For all |O|i
operator sequences of length i, i ∈ IN, generate all possible parallel plans, check for each
individual schedule if it transforms the initial state into one of the goals, and take the
sequence with smallest parallel plan length. Since all parallel plans are computed, this yields
a complete and optimal algorithm. As seen in the example of two persons lifting a table,
this approach can be more expressive than applying any algorithm that finds sequential
plans first. However, the algorithm is very inefficient.
In practice, the natural assumption is that each parallel plan corresponds to at least one
(possible many) sequential one(s). Conversely, each partially ordered plan can be established
by generating a totally ordered plan first and then applying a scheduling algorithm to it to
find its best partial-order.
The algorithm in the Figure 11 indicates how to wrap a forward chaining planner so
that it has any-time performance and gradually improves plan quality. The general state
219

Edelkamp

Procedure Any-Time
Input: Planning Problem hS, I, O, Gi
Output: Optimal parallel plan length α
α←∞
Open ← I
while (Open 6= ∅)
S ← Extract(Open)
for all S 0 ∈ expand(S)
if (S 0 ∈ G)
cp ← Critical-Path (path(S 0 ), d )
if (cp < α)
α ← cp
else
Change(Open, S 0 )
return α
Figure 11: General any-time search algorithm.
expanding scheme maintains the search horizon in the list Open. For simplicity the maintenance of stored nodes in the list Closed is not shown. In the algorithm, the current best
critical path cost α bounds the upcoming exploration process. In turn α is updated each
time a plan is found with a shorter critical path.
As in the CriticalPath procedure above, the algorithm returns the execution time only,
and not the established plan. To compute the plan that meets the returned value α, we also
store the schedule of the generating sequence path(S 0 ) in a global record. In most cases,
storing S 0 is sufficient, since the path and its PERT scheduling can be restored by calling
procedure CriticalPath at the end of the procedure.
Assuming that each optimal parallel plan is a schedule of a sequential plan and the state
space is finite, the any-time extension for a cycle-avoiding enumeration strategy is indeed
complete and optimal. The reason for completeness in finite graphs is that the number of
acyclic paths in G is finite and with every node expansion, such an algorithm adds new
links to its traversal tree. Each newly added link represents a new acyclic path, so that,
eventually, the reservoir of paths must be exhausted.
Are there also valid parallel plans that cannot be produced by PERT scheduling of a
sequential plan? The answer is no. If a partial ordering algorithm terminates with an
optimal schedule, we can generate a corresponding sequential plan while preserving the
dependency structure. Optimal PERT-scheduling of this plan with respect to the set of
operators and the imposed precedence relation will yield the optimal parallel plan. If all
sequential plans are eventually generated, the optimal parallel plan will also be found by
PERT scheduling.
The problem of enumeration in infinite state spaces is that there can be infinite plateaus
where the plan objective function has a constant value. Normally increasing the length of
a plan increases the cost. However, this is not true in all benchmark problems, since there
220

Taming Numbers and Durations in MIPS

may be an infinite sequence of events that do not contribute to the plan objective. For
example, loading and unloading tanks in the pre-competition test domain DesertRats does
not affect total-fuel consumption, which has to be minimized in one of the instances.
Enumeration schemes do not contradict known undecidability results in numerical planning (Helmert, 2002). If we have no additional information like a bound on the maximal
number of actions in a plan or on the number of actions that can be executed in parallel, we
cannot decide whether a cycle-free enumeration will terminate or not. On the other hand
if there is a solution, the any-time algorithm will eventually find it.
4.5 Pruning Anomalies
Acceleration techniques like duplicate detection in sequential plan generation have to be
chosen carefully to maintain parallel plan length optimality. This approach does affect
parallel optimality, as the following example shows. In the ZenoTravel problem consider
the sequences
(zoom city-a city-c plane), (board dan plane city-c),
(refuel plane city-c), (zoom city-c city-a plane),
(board scott plane city-a), (debark dan plane city-a), (refuel plane city-a),
and
(board scott plane city-a), (zoom city-a city-c plane),
(board dan plane city-c), (refuel plane city-c),
(zoom city-c city-a plane), (debark dan plane city-a), (refuel plane city-a)
The two sets of operators are the same and so are the resulting (sequentially generated)
states. However, the PERT schedule for the first sequence is shorter than the schedule for
the second one, because boarding scott can be done in parallel with the final two actions
in the plan.
For small problems, such anomalies can be avoided by omitting duplicate pruning. As
an example Figure 12 depicts a sequential plan for the example problem instance and its
PERT schedule, which turns out to be the overall optimal parallel plan. Another option is
to store the resulting parallel plan for state caching instead of the sequential one. Note that
in order to ease generation of sequential solutions for large planning problem instances, in
the competition version of MIPS we used sequential state pruning.
4.6 Heuristic Search
The main drawback of blind path enumeration is that it is seemingly too slow for practical
planning. Heuristic search algorithms like A* and IDA* reorder the traversal of states,
and (assuming no state caching) do not affect completeness and optimality of the anytime wrapper. The efficiency of the wrapper directly depends on the quality of the path
enumeration. In the competition version of MIPS we omitted any-time wrapping, since
optimal solutions were not required and the practical run-time behavior is poor.
Instead we used an A* search engine, that terminates on the first established solution.
The question remains: is there still hope of finding near optimal parallel plans? A general
result also applicable for infinite graphs was established by (Pearl, 1985): If the cost of every
221

Edelkamp

0:
100:
130:
160:
200:
300:
320:
350:
390:
490:
530:
630:
650:

(zoom plane city-a city-c) [100]
(board dan plane city-c)
[30]
(board ernie plane city-c) [30]
(refuel plane city-c)
[40]
(zoom plane city-c city-a) [100]
(debark dan plane city-a)
[20]
(board scott plane city-a) [30]
(refuel plane city-a)
[40]
(zoom plane city-a city-c) [100]
(refuel plane city-c)
[40]
(zoom plane city-c city-d) [100]
(debark ernie plane city-d) [20]
(debark scott plane city-d) [20]

0: (zoom plane city-a city-c) [100]
100: (board dan plane city-c)
[30]
(board ernie plane city-c) [30]
100: (refuel plane city-c)
[40]
140: (zoom plane city-c city-a) [100]
240: (debark dan plane city-a)
[20]
(board scott plane city-a) [30]
(refuel plane city-a)
[40]
280: (zoom plane city-a city-c) [100]
380: (refuel plane city-c)
[40]
420: (zoom plane city-c city-d) [100]
520: (debark ernie plane city-d) [20]
(debark scott plane city-d) [20]

Figure 12: A sequential plan for Zeno-Travel (left) and its PERT schedule (right).

infinite path is unbounded, A*’s cost function f = g + h will preserve optimality. This is
additional rationale for choosing an A*-like exploration in MIPS instead of hill climbing or
best-first. As in breadth-first search, the rising influence of the g-value is crucial.
To find an adequate heuristic estimate for parallel plans is not easy. In fact we have
not established a competitive and admissible heuristic, which is required for optimal plan
finding in A*. Our choice was a scheduling extension to RPH. In contrast to the RPH, the
new heuristic takes the relaxed sequence of operators and searches for a suitable parallel
arrangement, which in turn defines the estimator function.
We found that adding PERT-schedules for the path to a state and for the sequence of
actions in the relaxed plan is not as accurate as the PERT-schedule of the combined paths.
Therefore, the classical merit function of A*-like search engines f = g +h of generating path
length g and heuristic estimate h has no immediate correspondence for parallel planning.
Consequently, we define the heuristic value of scheduling RPH as the parallel plan length
of the combined path minus the parallel plan length of the generating path.
4.7 Arbitrary Plan Objectives
In PDDL 2.1 plan metrics other than minimizing total (parallel) execution time can be
specified. This influences the inferred solutions. In Figure 13 we depict two plans found
by MIPS for the objective functions of minimizing total-fuel-used, and minimizing the
compound (+ (* 10 (total-time)) (* 1 (total-fuel-used))).
For the first case we computed an optimal value of 1,333.33, while for the second case we
established 7,666.67 as the optimized merit. When optimizing time, the ordering of board
and zoom actions is important. When optimizing total-fuel we reduce speed to save fuel
consumption to 333.33 per flight but we may board the first passenger immediately. We
also save two refuel actions with respect to the first case.
When increasing the importance of time we can trade refueling actions for time, so that
both zooming and flight actions are chosen for the complex minimization criterion.
The first attempt to include arbitrary plan objectives was to alter the PERT scheduling
process. However, the results did not match the ones produced by the validator (Long &
222

Taming Numbers and Durations in MIPS

0: (zoom plane city-a city-c) [100]
100: (board dan plane city-c)
[30]
(board ernie plane city-c) [30]
(refuel plane city-c)
[40]
140: (zoom plane city-c city-a) [100]
240: (debark dan plane city-a)
[20]
(board scott plane city-a) [30]
(refuel plane city-a)
[40]
280: (fly plane city-a city-c) [150]
430: (fly plane city-c city-d) [150]
580: (debark ernie plane city-d) [20]
(debark scott plane city-d) [20]

0: (board scott plane city-a) [30]
30: (fly plane city-a city-c) [150]
180: (board ernie plane city-c) [30]
(board dan plane city-c)
[30]
210: (fly plane city-c city-a) [150]
360: (debark dan plane city-a) [20]
(refuel plane city-a)
[53.33]
413.33: (fly plane city-a city-c) [150]
563.33: (fly plane city-c city-d) [150]
713.33: (debark ernie plane city-d)[20]
(debark scott plane city-d)[20]

Figure 13: Optimized plans in Zeno-Travel according to different plan objectives.
Fox, 2001), in which the final time is substituted in the objective function after the plan
has been built.
The way MIPS evaluates objective functions with time is as follows. First it schedules the
(relaxed or final) sequential plan. Variable total-time is temporarily substituted for the
critical path value and the objective formula is evaluated. To avoid conflicts in subsequent
expansions, afterwards value total-time is set back to the optimal one in the sequential
plan.

5. Object Symmetries
An important feature of parameterized predicates, functions and action descriptions in the
domain specification file is that actions are transparent to different bindings of parameters
to objects. Disambiguating information is only present in the problem instance file.
In the case of typed domains, many planners, including MIPS, compile all type information into additional predicates, attach additional preconditions to actions and enrich the
initial states by suitable object-to-type atoms.
As a consequence, a symmetry is viewed as a permutation of objects that are present in
the current state, in the goal representation, and transparent to the set of operators.
There are n!, n = |OBJ |, possible permutations of the set of objects. Taking into
account all type information reduces the number of all possible permutation to
n
t1 , t 2 , . . . , t k

!

=

n!
.
t1 !t2 ! . . . tk !

where ti is the number of objects with type i, i ∈ {1, . . . , k}. In a moderate sized logistic
domain with 10 cities, 10 trucks, 5 airplanes, and 15 packages, this results in 40!/(10! · 10! ·
5! · 15!) ≥ 1020 permutations.
To reduce the number of potential symmetries to a tractable size we restrict symmetries
to object transpositions, for which we have at most n(n − 1)/2 ∈ O(n2 ) candidates. Using
type information this number reduces to
k
X
ti
i=1

2

!

=

k
X

ti (ti − 1)/2.

i=1

223

Edelkamp

In the following, the set of typed object transpositions is denoted by SYMM. For the
Logistics example, we have |SYMM| = 45 + 45 + 10 + 105 = 205.
5.1 Generating Object Symmetries for Planning Problems
In this section we compute the subset of SYMM that includes all object pairs for which the
entire planning problem is symmetric. We start with object transpositions for the smallest
entities of a planning problem.
Definition 12 (Object Transpositions for Fluents, Variables, and Operators) A transposition of objects (o, o0 ) ∈ SYMM applied to a fluent f = (p o1 , . . . , ok(p) ) ∈ F, written as
f [o ↔ o0 ], is defined as (p o01 , . . . , o0k(p) ), with o0i = oi if oi ∈
/ {o, o0 }, oi = o0 if oi = o,
and oi = o if oi = o0 , i ∈ {1, . . . , k(p)}. Object transpositions [o ↔ o0 ] applied to a variable
v = (f o1 , . . . , ok(f ) ) ∈ V or to an operator O = (a o1 , . . . , ok(a) ) ∈ O are defined analogously.
For example, in the ZenoTravel problem we have (at scott city-a)[scott ↔ dan] =
(at dan city-a).
Lemma 2 For all f ∈ F, v ∈ V, O ∈ O, and (o, o0 ) ∈ SYMM: f [o ↔ o0 ] = f [o0 ↔ o],
v[o ↔ o0 ] = v[o0 ↔ o], and O[o ↔ o0 ] = O[o0 ↔ o], as well as f [o ↔ o0 ][o ↔ o0 ] = f ,
v[o ↔ o0 ][o ↔ o0 ] = v, and O[o ↔ o0 ][o ↔ o0 ] = O.
The brute-force time complexity for computing f [o ↔ o0 ] ∈ F is of order O(k(p)), where
k(p) is the number of object parameters in p. However, by pre-computing a O(|SYMM| ·
|F|) sized lookup table, containing the index of f 0 = f [o ↔ o0 ] for all (o, o0 ) ∈ SYMM,
this time complexity can be reduced to O(1).
Definition 13 (Object Transpositions for States) Let φ be the mapping from set T to
{1, . . . , |T |}. An object transposition [o ↔ o0 ] applied to state S = (Sp , Sn ) ∈ S with
Sn = (v1 , . . . , vk ), k = |V|, written as S[o ↔ o0 ], is equal to (Sp [o ↔ o0 ], Sn [o ↔ o0 ]) with
Sp [o ↔ o0 ] = {f 0 ∈ F | f ∈ Sp ∧ f 0 = f [o ↔ o0 ]}
and Sn [o ↔ o0 ] = (v10 , . . . , vk0 ) with vi = vj0 if φ−1 (i)[o ↔ o0 ] = φ−1 (j) for i, j ∈ {1, . . . , k}.
In the initial state of the example problem we have I[dan ↔ ernie] = I. The definition
for variables is slightly more difficult than for predicates, since, in this case, the variable
contents, not just their availability, must match.
The time complexity to compute Sn [o ↔ o0 ] is O(k), since testing φ−1 (i)[o ↔ o0 ] =
φ−1 (j) is available in time O(1) by building another O(|SYMM| · |V|) sized pre-computed
look-up table. Note that these times are worst-case. We can terminate the computation of
an object symmetry if a fluent or variable is contradictory. We summarize the complexity
results as follows.
Lemma 3 The worst-case time complexity to compute S[o ↔ o0 ] for state S = (Sp , Sn ) ∈ S
and (o, o0 ) ∈ SYMM is O(|Sp | + |V|) using O(|SYMM| · (|F| + |V|)) space.
The next step is to lift the concept of object transposition to planning problems.
224

Taming Numbers and Durations in MIPS

Definition 14 (Object Transpositions for Domains) A planning problem P = hS, O, I, Gi
is symmetric with respect to the object transposition [o ↔ o0 ], abbreviated as P[o ↔ o0 ], if
I[o ↔ o0 ] = I and ∀ G ∈ G: G[o ↔ o0 ] ∈ G.
Since goal descriptions are partial, we prefer writing G[o ↔ o0 ] ∈ G instead of ∀ G ∈ G:
G[o ↔ o0 ] ∈ G. Moreover, we assume the goal description complexity for G to be bounded
by O(|Gp | + |V|).
For the ZenoTravel problem, the goal descriptor is purely propositional, containing three
facts for the target location of dan, ernie, and scott. In the initial state of the running
example the planning problem contains no object symmetry, since I[scott ↔ ernie] 6= I
and G[dan ↔ ernie] 6= G.
Applying Lemma 3 for all (o, o0 ) ∈ SYMM yields the time complexity needed to establish all object symmetries.
Theorem 3 (Time Complexity for Object Symmetry Detection) The worst-case run-time to
determine the set of all object transpositions for which a planning problem P = hS, O, I, Gi
is symmetric is O(|SYMM| · (|Gp | + |Ip | + |V|)).
5.2 Including Goal Symmetry Conditions
Symmetries that are present in the initial state may vanish or reappear during exploration in
a forward chaining planner like MIPS. In the DesertRats domain, for example, the initial set
of supply tanks is indistinguishable so that only one should be loaded into the truck. Once
the fuel levels of the supply tanks decrease or tanks are transported to another location,
previously existing symmetries are broken. However, when two tanks in one location become
empty, they can once again be considered symmetric.
Goal conditions, however, do not change over time, only the initial state I transforms
into the current state C. Therefore, in a pre-compiling phase we refine the set SYMM to
SYMM0 ← (o, o0 ) ∈ SYMM | G[o ↔ o0 ] = G .


	

Usually, |SYMM0 | is much smaller than |SYMM|. For the ZenoTravel problem instance,
the only object symmetry left in SYMM0 is the transposition of scott and ernie.
Therefore, we can efficiently compute the set
SYMM00 (C) ← {(o, o0 ) ∈ SYMM0 | C[o ↔ o0 ] = C}
of symmetries that are present in the current state. In the initial state I of the example
problem of Zeno-Travel we have SYMM00 (I) = ∅, but once scott and ernie share the
same location in a state C this object pair would be included in SYMM00 (C).
The definition requires C[o ↔ o0 ] = C. This does not include symmetric paths from
different states. Let C = {(at ernie city-c), (at scott city-d)}. It is possible that
there is a symmetric plan for {(at ernie city-d), (at scott city-c)} to a common
goal. Viewed differently, complex object symmetries of the form [o1 ↔ o01 ][o2 ↔ o02 ] are not
detected. For the example we observe C[scott ↔ ernie][city-c ↔ city-d] = C.
With respect to Theorem 3 this additional restriction reduces the time complexity to
detect all remaining object symmetries to O(|SYMM0 | · (|Cp | + |V|)).
225

Edelkamp

5.3 Pruning Operators
If a planning problem with current state C ∈ S is symmetric with respect to the operator
transposition [o ↔ o0 ] then either the application of operator O ∈ O or the application
of operator O[o ↔ o0 ] is neglected, significantly reducing the branching factor. Lemma 4
indicates how symmetry is used to reduce exploration.
Lemma 4 If operator O is applicable in S and S = S[o ↔ o0 ] then O[o ↔ o0 ] is applicable
in S and
O(S)[o ↔ o0 ] = O[o ↔ o0 ](S).
Proof: If O is applicable in S then O[o ← o0 ] is applicable in S[o ← o0 ]. Since S =
S[o ↔ o0 ], O[o ↔ o0 ] is applicable in S, and
O[o ↔ o0 ](S) = O[o ↔ o0 ](S[o ↔ o0 ]) = O(S)[o ↔ o0 ].

By pre-computing an O(|SYMM| · |O|) sized table the index φ(O0 ) of operator O0 =
O[o ↔ o0 ] can be determined in time O(1) for each (o, o0 ) ∈ SYMM0 .
Definition 15 (Pruning Set) Let φ be the index mapping from set T to {1, . . . , |T |} and let
Γ(C) be the set of operators that are applicable in state C ∈ S. The pruning set ∆(C) ⊂ Γ(C)
is defined as the set of all operators that have a symmetric counterpart and that are not of
minimal index. The symmetry reduction Γ0 (C) ⊆ Γ(C) is defined as Γ(C) \ ∆(C).
Theorem 4 (Correctness of Operator Pruning) Reducing the operator set Γ(C) to Γ0 (C)
during the exploration of planning problem P = hS, O, I, Gi preserves completeness7 .
Proof: Suppose that for some expanded state C, reducing the operator set Γ(C) to Γ0 (C)
during the exploration of planning problem P = hS, O, I, Gi does not preserve completeness.
Furthermore, let C be the state with this property that is maximal in the exploration order.
Then there is a sequential plan π = (O1 . . . , Ok ) in PC = hS, O, C, Gi with associated
state sequence (S0 = C, . . . , Sk ⊆ G). Obviously, Oi ∈ Γ(Si−1 ), i ∈ {1, . . . , k}. By the
choice of C we have O1 ∈ Γ(S0 ) \ Γ0 (S0 ) = ∆(S0 ). By the definition of the pruning set
∆(S0 ) there exists O10 = O1 [o ↔ o0 ] of minimal index that is applicable in S0 .
Since PC = hS, O, C, Gi = PC [o ↔ o0 ] = hS, O, C[o ↔ o0 ] = C, G[o ↔ o0 ] = Gi , we have
a sequential plan O1 [o ↔ o0 ], . . . , Ok [o ↔ o0 ] with state sequence (S0 [o ↔ o0 ] = S0 , S1 [o ↔
o0 ], . . . , Sk [o ↔ o0 ] = Sk ) that reaches the goal G. This contradicts the assumption that
reducing the operator set Γ(C) to Γ0 (C) does not preserve completeness for all C.
Since the plan objective refers to instantiated predicates and objects, similar to the
initial and goal state, it can be symmetry breaking. In order to preserve optimality, one
has to additionally check, to see if the object exchange will influence the plan objective.
In practice, objective functions are often based on non-parameterized predicates, in which
case an optimal planning algorithm will not be affected by symmetry cuts.
7. Generally completeness means that a planner can find any legal plan. This is not what is intended here.
We use completeness here in terms of discarding legal plans in favor to equally good symmetric plans.

226

Taming Numbers and Durations in MIPS

5.4 Symmetry Reduction in MIPS
The main purpose of the restricted implementation in MIPS is to further reduce the run
time for object symmetry detection by losing some but not all of its effectiveness. Especially
the impact of quantity O(|SYMM0 | · |Cp |) for the running time can be considerable.
The key observation is that symmetries are also present in fact groups according to their
group representatives. As shown in Figure 5, the fact group of dan consists of the facts
(at dan city-a), (at dan city-b), (at dan city-c), (at dan city-d), and (in dan
plane). Similarily, ernie’s group has facts (at ernie city-a), (at ernie city-b), (at
ernie city-c), (at ernie city-d), and (in ernie plane). The ordering of the facts in
the groups can be chosen in a way that, except for the change in the group representative,
corresponding facts match. Together with the facts in the groups, the operators that change
facts of the groups, are stored in an efficient dictionary.
Therefore, we restrict object transpositions to group representatives. This reduces the
set of objects OBJ that MIPS considers to a considerably smaller subset OBJ 0 . In the
example problem we have |OBJ | = 7, and |OBJ 0 | = 4. Many objects, e.g. the objects of
type city in ZenoTravel, were not selected as representatives for a single attribute invariance
to build a group.
The idea is to obtain a possible transposition of fact group representatives, followed by
looking at the respective fact positions of the current and goal state. It may happen, that
more than one group has fixed representative o ∈ OBJ 0 . In this case, we link groups that
have representative o in common. For symmetry detection we test the group chains of both
objects for a matching current and goal position.
As above, symmetries based on non-matching goal predicates can be excluded beforehand. Let RSYMM be the number of remaining symmetries of object representatives.
Assume that one representative per group yields a running time for propositional object
symmetry detection in state C of O(RSYMM + |Cp |). The remaining comparisons of variables v ∈ V are implemented as described in the previous section, but are to be performed
only for those object pairs that pass the propositional check.
For pruning operators, MIPS marks all groups that correspond to an object symmetry
and that have larger index as visited. This guarantees that an operator of at least one
group is executed. For each expanded state S and each matching operator O ∈ Γ(S) the
algorithm checks, whether an applied operator is present in a visited group, in which case
it is pruned. The time complexity is O(|Γ(S)|), since operator group containment can be
preprocessed and checked in constant time.
Figure 14 shows the effectiveness of symmetry reduction of the planner MIPS in the DesertRats domain, which scales with respect to the total distance d, d ∈ {300, 400, 500, 600},
that has to be passed (x-axis). In the y direction, the number of expanded states in an A*
search of MIPS with object symmetry reduction (right bars) and without symmetry reduction (left bars) is shown on a logarithmic scale. As expected, for larger problems symmetry
reduction yields performance gains of more than one order magnitude (d = 500). It also
yields solutions to problems where all algorithms without symmetry reduction fail due to
memory restrictions (d = 600)8 .
8. The memory bound we used for this example was set to 1/2 GByte.

227

Edelkamp

Figure 14: Results in symmetry pruning in Desert Rats. Bars show the number of states
expanded without/with symmetry detection.

6. Related Work
STRIPS problems have been tackled with different planning techniques, most notably
by SAT-planning (Kautz & Selman, 1996), IP-planning (Kautz & Walser, 1999), CSPplanning (Rintanen & Jungholt, 1999), graph relaxation (Blum & Furst, 1995), and heuristic
search planning (Bonet & Geffner, 2001).
Solving planning problems with numerical preconditions and effects as allowed in Level 2
and Level 3 problems is undecidable in general (Helmert, 2002). However, the structures
of the provided benchmark problems are simpler than the general problem class, so these
problems are in fact solvable.
6.1 Temporal Planning Approaches
The system Metric-FF (Hoffmann, 2002a) extends FF (Hoffmann & Nebel, 2001) as a
forward chaining heuristic state space planner for Level 2 problems. Although, MIPS’ plan
generator shares several ideas with Metric-FF, Hoffmann’s system has not yet been extended
to deal with temporal domains.
Planner TP4 (Haslum & Geffner, 2001) is in fact a scheduling system based on grounded
problem instances. For these cases all formula trees in numerical conditions and assignments
reduce to constants. Utilizing admissible heuristics, TP4 minimizes the plan objective of
optimal parallel plan length. Our planner has some distinctive advantages: it handles
numerical preconditions, instantiates numerical conditions on the fly and can cope with
complex objective functions. Besides its input restriction, in the competition, TP4 was
somewhat limited by its focus on producing only optimal solutions.
The SAPA system (Do & Kambhampati, 2001) is a domain-independent time and resource planner that can cope with metrics and concurrent actions. SAPA’s general expressivity can be judged to be close to that of MIPS. It adapts the forward chaining algorithm
of (Bacchus & Ady, 2001). Both planning approaches instantiate actions on the fly and
228

Taming Numbers and Durations in MIPS

can therefore, in principle, be adapted to handle flexible mixed propositional and numerical planning problems. The search algorithm in SAPA extends partial concurrent plans
instead of parallelizing sequential plans. It uses a relaxed temporal planning graph for the
yet unplanned events for different heuristic evaluation functions. As an additional feature,
SAPA provides the option of specifying deadlines.
The planner LPG (Gerevini & Serina, 2002) is based on local search in planning graphs.
It uses a variant of the FF planner for grounding and initial plans are generated through random walk. The subsequent search space of LPG consists of so-called action graphs (Gerevini
& Serina, 1999). The temporal module performs action graph modifications transforming
an action graph into another one. The fast plan generation algorithm in LPG seems to be
the best explanation for the speed advantage that LPG has with respect to MIPS, and the
higher number of problems LPG solved in some domains. Optimization in LPG is governed
by Lagrange multipliers. In temporal domains, actions are ordered using a precedence graph
that is maintained during search, which uses a more refined dependency relation than ours.
This may partly explain why plan quality was in fact consistently better than in MIPS.
IxTeT (Laborie & Ghallab, 1995) is a general constraint-based planning system with its
own input format. The planner searches in the space of partial plans and allows general
resource and temporal constraints to be posed. The internal representation consists of
chronicles, with time as a linearly ordered discrete set of instants, and multi-valued state
variables that are either rigid or flexible (contingent, controllable, resources), predicates as
temporally qualified expressions (events, assertions, resources), and temporal and atemporal
constraints. It is not clear how to compare the expressivity of chronicles with PDDL2.1
constructs. This makes it difficult to link the different temporal models and to determine if
the technique of critical path scheduling will be applicable to IxTeT or not. In our opinion
this is unlikely, since IxTeT is partial-order. Note that IxTeT further allows conjunction
of predicates, subtasks, constraints and conditional expressions, which are not available in
PDDL2.1. The analysis of partial plans that drives the planning process is divided into
three different modules: feasibility, satisfiability and resource conflict resolution. In the
competition domains IxTeT was not able to compete with local search and heuristic search
planners.
HSTS (Muscettola, 1994) is a constraint-based planning system based on temporal activity networks, written in LISP and CRL. At NASA it has been used in many projects
like Deep-Space One. It can already represent and reason about metric resources, parallel
activities, and general constraints. As in IxTeT the input format is significantly different
from PDDL2.1. HSTS has not yet been adapted to represent or reason with conditional
branches. However experiences with the HSTS planner showed partial-order planning to be
attractive for metric/temporal problems, but with a need for better search control.
Although the PDDL2.1 guidelines in fact do allow infinite branching, the 2002 competition consisted only of finite branching problems. As we indicated earlier, this paper
also concentrates on finite branching problems. With finite branching, execution time of an
action is fixed, while with infinite branching, a continous range of actions is available.
These problems have been confronted by (real-time) model checking for a long time.
Some subclasses of infinite branching problems like timed automata exhibit a finite partitioning through a symbolic representation of states (Pettersson, 1999). By the technique
of shortest-path reduction a unique and reduced normal form can be obtained. We have
229

Edelkamp

implemented this temporal network structure, since this is the main data structure when
exploring timed automata as done by the model checker Uppaal (Pettersson, 1999). For
this to work, all constraints must have the form xi − xj ≤ c or xi ≤ c. For example, the
set of constraints x4 − x0 ≤ −1, x3 − x1 ≤ 2, x0 − x1 ≤ 1, x5 − x2 ≤ −8, x1 − x2 ≤ 2,
x4 − x3 ≤ 3, x0 − x3 ≤ −4, x1 − x4 ≤ 7, x2 − x5 ≤ 10, and x1 − x5 ≤ 5 has the shortest-path
reduction x4 − x0 ≤ −1, x3 − x1 ≤ 2, x5 − x2 ≤ −8, x0 − x3 ≤ −4, x1 − x4 ≤ 7, x2 − x5 ≤ 10,
and x1 − x5 ≤ 5. If the constraint set is over-constrained, the algorithm will determine
unsolvability, otherwise a feasible solution is returned.
Critical path analysis for timed precedence networks is one of the simpler cases for
scheduling. We have achieved a simplification by solving the sequential path problem first.
Note that many other scheduling techniques apply the presented critical path analysis as a
subcomponent (Syslo, Deo, & Kowalik, 1983).
6.2 Symmetry Detection in Planning and Model Checkers
Most previous results in symmetry reduction in planning, e.g. (Guéré & Alami, 2001),
neglect the combinatorial explosion of possible symmetries or at least assume that the
information on existing symmetries in the domain is supplied by the user.
In contrast, our work shares similarities with the approach of Fox & Long (1999,2002) in
inferring object symmetry information fully automatically. Fox and Long’s work is based on
similarities established by the TIM inference module (Fox & Long, 1998). During the search
additional information on the current symmetry level in the form of an object transposition
matrix is stored and updated together with each state. Our approach is different in the sense
that it efficiently computes object symmetries for each state from scratch and it consumes
no extra space per node expansion.
Model checking research has a long tradition in symmetry reduction (Clarke et al., 1999).
In recent work, Rintanen (2003) connects symmetry detection in planning to model checking
approaches for transition systems and SAT solving. Experiments are provided for SAT
encodings of the Gripper domain; a prototypical example for symmetry detection. In (LluchLafuente, 2003), our model checker HSF-Spin is extended to effectively combine heuristic
search with symmetry detection. It also reflects the fact that (HSF-)Spin’s exploration can
be modelled using (labelled) transition systems. Positive empirical results are given for
non-trivial examples like Peterson’s mutual exclusion algorithm and the Database Manager
protocol.
We briefly review the fundamental difference between object symmetries (as considered
here) and state space symmetries (as considered in model checking).
The latter approach constructs a quotient state space problem (P/∼) based on a congruence relation, where an equivalence relation ∼ of S is called a congruence if for all
s1 , s2 , s1 ∈ S with s1 ∼ s2 and operator O ∈ O with O(s1 ) = s01 there is an s02 ∈ S with
s01 ∼ s02 and an operator O0 ∈ O with O0 (s2 ) = s02 . We have [O][s] = [s0 ] if and only if there
is an operator O ∈ O mapping s to s0 so that s ∈ [s] and s0 ∈ [s0 ].
A bijection φ : S → S is said to be a symmetry if φ(I) = I, φ(G) ∈ G for all G ∈ G
and for any s, s0 ∈ S with transition from s to s0 there exist a transition from φ(s) to
φ(s0 ). Any set A of symmetries generates a subgroup g(A) called a symmetry group. The
subgroup g(A) induces an equivalence relation ∼A on states, defined as s ∼A s0 if and only
230

Taming Numbers and Durations in MIPS

if φ(s) = s0 and φ ∈ g(A). Such an equivalence relation is called a symmetry relation on
P induced by A. The equivalence class of s is called the orbit of s, denoted as [s]A . Any
symmetry relation on P is a congruence on P. Moreover, s is reachable if and only if [s]A
is reachable from [I]A . This reduces the search for goal G ∈ G to finding state [G].
To explore a state space with respect to a state (space) symmetry, a function Canonicalize is needed. Each time a new successor node is generated, it determines a representative
element for each equivalence class. Fixing the canonical element is not trivial, so that many
systems approximate this normal form. Automatically finding symmetries in this setting
is also difficult and can be cast as a computationally hard graph isomorphism problem.
Therefore all approaches expect information on the kind of symmetry that is present in
the state space graph. One example is a rotational symmetry, defined by a right shift of
variables in the state vector.
6.3 Model Checking Planners
In the 2000 competition, two other symbolic planners took part: PropPlan (Fourman,
2000), and BDDPlan (Hölldobler & Stör, 2000). Although they did not receive any awards
for performance, they show interesting properties. PropPlan performs symbolic forward
breadth first search to explore propositional planning problems with propositions for generalized action preconditions and generalized action effects. It performed well in the full
ADL Miconic-10 elevator domain (Koehler, 2000). ProbPlan is written in the Poly/ML
implementation of SML. BDD-Plan is based on solving the entailment problem in the fluent calculus with BDDs. At that time the authors acknowledged that the concise domain
encoding and symbolic heuristic search used in MIPS were improvements.
In the Model-Based Planner MBP the paradigm of planning as symbolic model checking (Giunchiglia & Traverso, 1999) has been implemented for non-deterministic planning
domains (Cimatti et al., 1998), which can be classified into weak, strong, and strong-cyclic
planning, with plans that are represented as state-action tables. For partially observable
planning, a system is faced with exploring the space of belief states; the power set of the
original planning space. Therefore, in contrast to the successor set generation based on action application, observations introduce “And” nodes into the search tree (Bertoli, Cimatti,
Roveri, & Traverso, 2001b). Since the approach is a hybrid of symbolic representation of
belief states and explicit search within the “And”-“Or” search tree, simple heuristics have
been applied to guide the search. The need for heuristics that trade information gain for
exploration effort is also apparent in conformant planning (Bertoli et al., 2001a). Recent
work (Bertoli & Cimatti, 2002) proposes improved heuristics for belief space planning.
The UMOP system parses a non-deterministic agent domain language that explicitly
defines a controllable system in an uncontrollable environment (Jensen & Veloso, 2000).
The planner also applies BDD refinement techniques such as automated transition function
partitioning. New results for the UMOP system extend weak, strong and strong cyclic
planning to adversarial planning, in which the environment actively influences the outcome
of actions. In fact, the proposed algorithm combines aspects of both symbolic search and
game playing. UMOP has not yet participated in a planning competition.
More recent developments in symbolic exploration are expected to influence automated
planning in the near future. With SetA*, (Jensen et al., 2002) provide an improved imple231

Edelkamp

mentation of the symbolic heuristic search algorithm BDDA* (Edelkamp & Reffel, 1998)
and Weighted BDDA* (Edelkamp, 2001a). One improvement is that SetA* maintains finer
grained sets of states in the search horizon. These are kept in a matrix according to matching g- and h- values. This contrasts with the plain bucket representation of the priority
queue based on f -values. The heuristic function is implicitly encoded with value differences
of grounded actions. Since sets of states are to be evaluated and some heuristics are state
rather than operator dependent it remains to be shown how general this approach is. As
above, the planning benchmarks considered are seemingly simple for single-state heuristic search exploration (Hoffmann, 2002b; Helmert, 2001). (Hansen, Zhou, & Feng, 2002)
also re-implemented BDDA* and suggest that symbolic search heuristics and exploration
algorithms are probably better implemented with algebraic decision diagrams (ADDs). Although the authors achieved no improvement to (Edelkamp & Reffel, 1998) in solving the
(n2 − 1)-Puzzle, the established generalization to guide a symbolic version of the LAO* exploration algorithm (Hansen & Zilberstein, 2001) for probabilistic (MDP) planning results
in a remarkable improvement in the state-of-the-art (Feng & Hansen, 2002).

7. Conclusions
With the competition planning system MIPS, we have contributed a flexible system for a
heuristic forward chaining, explicit and symbolic search planner that finds plans in finitebranching numerical problems. The planner parses, pre-compiles, solves, and schedules
problem instances, including complex ones with duration, resource variables and different
objective functions. The main contributions of the planner are
• The object-oriented workbench architecture to choose and combine different heuristics with different search algorithms and storage structures. The design includes the
static analyzer that applies efficient fact-space exploration to distinguish constant
from fluent quantities, that clusters facts into groups, and that infers static object
symmetries. The static analyzer produces the intermediate format of grounded and
simplified planning domain instances.
• Optimal temporal planning enumeration algorithms, based on a precedence relation
and PERT scheduling of sequentially generated plans together with a concise analysis
of correctness and optimality, as well as the integration of PERT scheduling in MIPS
for computing a refined heuristic estimate. This guides the search phase, favoring
states with smaller parallel plan length. MIPS instantiates numerical pre- and postconditions on-the-fly and produces optimized parallel plans.
• The detection of dynamic object symmetries, the integration of different pruning
methods such as hash and transposition cuts, as well as different strategies for optimizing objective functions and further implementation tricks that made the system
efficient.
The paper analyzes theoretical properties of the contributions, sometimes by slightly
abstracting from the actual implementation.
Essentially planning with numerical quantities and durative actions is planning with
resources and time. The given framework of mixed propositional and numerical planning
232

Taming Numbers and Durations in MIPS

problems and the presented intermediate format can be seen as a normal form for temporal
and metric planning. The paper presents a novel temporal planning scheme that generates
sequential (totally ordered) plans and efficiently schedules them with respect to the set of
actions and the imposed causal structure, without falling into known NP-hardness traps for
optimized partial-ordering of sequentially generated plans. For smaller problems the complete enumeration approach guarantees optimal solutions. To improve solution quality in
approximate enumeration, the (numerical) estimate for the number of operators is replaced
by scheduling the relaxed plan in each state. We addressed completeness and optimality of
different forms of exploration. A novel study of the time and space complexity of dynamic
object symmetry detection is given.
Model checking has always influenced the development of MIPS, e.g in the static analysis to minimize the state description length, in symbolic exploration and plan extraction, in
the dependence relation for PERT schedules according to a given partial order, in bit-state
hashing for IDA*, in the importance of symmetry detection, an so forth. Moreover, the
successes of planning with MIPS can be exported back to model checking, as the development of heuristic search state model checkers and parsing of Promela protocol specifications
indicate.

Acknowledgments
The author would like to thank Derek Long and Maria Fox for helpful discussions concerning
this paper and Malte Helmert for his cooperation in the second planning competition. The
list of editor’s and anonymous reviewers’ comments helped a lot to improve the text.
The work is supported by Deutsche Forschungsgemeinschaft (DFG) in the projects
Heuristic Search (Ed 74/3) and Directed Model Checking (Ed 74/2).

References
Bacchus, F., & Ady, M. (2001). Planning with resources and concurrency: A forward chaning
approach. In Proceedings of IJCAI-01, pp. 417–424.
Bacchus, F., & Kabanza, F. (2000). Using temporal logics to express search control knowledge for planning. Artificial Intelligence, 116, 123–191.
Bäckström, C. (1998). Computational aspects of reordering plans. Journal of Artificial
Intelligence Research, 9, 99–137.
Bertoli, P., & Cimatti, A. (2002). Improving heuristics for planning as search in belief space.
In Proceedings of AIPS-02, pp. 143–152.
Bertoli, P., Cimatti, A., & Roveri, M. (2001a). Heuristic search symbolic model checking =
efficient conformant planning. In Proceedings of IJCAI-01, pp. 467–472.
Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001b). Planning in nondeterministic
domains under partial observability via symbolic model checking. In Proceedings of
IJCAI-01, pp. 473–478.
Biere, A. (1997). µcke - efficient µ-calculus model checking. In Proceedings of CAV-97, pp.
468–471.
233

Edelkamp

Bloem, R., Ravi, K., & Somenzi, F. (2000). Symbolic guided search for CTL model checking.
In Proceedings of DAC-00, pp. 29–34.
Blum, A., & Furst, M. L. (1995). Fast planning through planning graph analysis. In
Proceedings of IJCAI-95, pp. 1636–1642.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129 (12), 5–33.
Bryant, R. E. (1992). Symbolic boolean manipulation with ordered binary-decision diagrams. ACM Computing Surveys, 24 (3), 142–170.
Cimatti, A., Giunchiglia, E., Giunchiglia, F., & Traverso, P. (1997). Planning via model
checking: A decision procedure for AR. In Proceedings of ECP-97, pp. 130–142.
Cimatti, A., Roveri, M., & Traverso, P. (1998). Automatic OBDD-based generation of
universal plans in non-deterministic domains. In Proceedings of AAAI-98, pp. 875–
881.
Clarke, E. M., Grumberg, O., & Peled, D. A. (1999). Model Checking. MIT Press.
Clarke, E. M., McMillan, K. L., Dill, D. L., & Hwang, L. J. (1992). Symbolic model checking:
1020 states and beyond. Information and Computation, 98 (2), 142–170.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction to Algorithms. The
MIT Press.
Dial, R. B. (1969). Shortest-path forest with topological ordering. Communication of the
ACM, 12 (11), 632–633.
Do, M. B., & Kambhampati, S. (2001). Sapa: a domain-independent heuristic metric temporal planner. In Proceedings of ECP-01, pp. 109–120.
Edelkamp, S. (1999). Datenstrukturen und Lernverfahren in der Zustandsraumsuche. Ph.D.
thesis, University of Freiburg. DISKI, Infix.
Edelkamp, S. (2001a). Directed symbolic exploration and its application to AI-planning. In
Proceedings of AAAI-01 Spring Symposium on Model-based Validation of Intelligence,
pp. 84–92.
Edelkamp, S. (2001b). First solutions to PDDL+ planning problems. In Proceedings of
PlanSIG-01, pp. 75–88.
Edelkamp, S. (2001c). Planning with pattern databases. In Proceedings of ECP-01, pp.
13–24.
Edelkamp, S. (2002a). Mixed propositional and numerical planning in the model checking integrated planning system. In Proceeding of AIPS-02 Workshop on Temporal
Planning, pp. 47–55.
Edelkamp, S. (2002b). Symbolic pattern databases in heuristic search planning. In Proceedings of AIPS-02, pp. 274–283.
Edelkamp, S. (2003). Promela planning. In Proceedings of SPIN-03, pp. 197–212.
Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge in planning problems to minimize state encoding length. In Proceeding of ECP-99, pp. 135–147.
234

Taming Numbers and Durations in MIPS

Edelkamp, S., & Helmert, M. (2000). On the implementation of MIPS. In Proceedings of
AIPS-00 Workshop on Model Theoretic Approaches to Planning, pp. 18–25.
Edelkamp, S., & Helmert, M. (2001). The model checking integrated planning system MIPS.
AI-Magazine, 67–71.
Edelkamp, S., Leue, S., & Lluch-Lafuente, A. (2003). Directed explicit-state model checking
in the validation of communication protocols. International Journal on Software Tools
for Technology (STTT), to appear.
Edelkamp, S., & Meyer, U. (2001). Theory and practice of time-space trade-offs in memory
limited search. In Proceedings of KI-01, Lecture Notes in Computer Science, pp.
169–184. Springer.
Edelkamp, S., & Reffel, F. (1998). OBDDs in heuristic search. In Proceedings of KI-98, pp.
81–92.
Edelkamp, S., & Reffel, F. (1999a). Deterministic state space planning with BDDs. In
Proceedings of ECP-99, Preprint, pp. 381–382.
Edelkamp, S., & Reffel, F. (1999b). Deterministic state space planning with BDDs. Tech.
rep. 121, University of Freiburg.
Edelkamp, S., & Stiegeler, P. (2002). Implementing HEAPSORT with n log n − 0.9n and
QUICKSORT with n log n + 0.2n comparisons. ACM Journal of Experimental Algorithms, 7 (5).
Feng, Z., & Hansen, E. (2002). Symbolic heuristic search for factored markov decision
processes. In Proceedings of AAAI-02.
Fikes, R., & Nilsson, N. (1971). Strips: A new approach to the application of theorem
proving to problem solving. Artificial Intelligence, 2, 189–208.
Fourman, M. P. (2000). Propositional planning. In Proceedings of AIPS-00 Workshop on
Model-Theoretic Approaches to Planning, pp. 10–17.
Fox, M., & Long, D. (1998). The automatic inference of state invariants in TIM. Journal
of Artificial Intelligence Research, 9, 367–421.
Fox, M., & Long, D. (1999). The detection and exploration of symmetry in planning
problems. In Proceedings of IJCAI-99, pp. 956–961.
Fox, M., & Long, D. (2002). Extending the exploitation of symmetries in planning. In
Proceedings of AIPS-02.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning domains. Journal of Artificial Intelligence Research, this issue.
Gerevini, A., & Serina, I. (1999). Fast planning through greedy action graphs. In Proceedings
of AAAI-00.
Gerevini, A., & Serina, I. (2002). LPG: a planner based on local search for planning graphs
with action costs. In Proceedings of AIPS-02.
Giunchiglia, F., & Traverso, P. (1999). Planning as model checking. In Proceedings of
ECP-99, pp. 1–19.
235

Edelkamp

Groce, A., & Visser, W. (2002). Model checking Java programs using structural heuristics.
In Proceedings of ISSTA-02.
Guéré, E., & Alami, R. (2001). One action is enough to plan. In Proceedings of IJCAI-01.
Hansen, E., & Zilberstein, S. (2001). LAO*: A heuristic search algorithm that finds solutions
with loops. Artificial Intelligence, 129, 35–62.
Hansen, E. A., Zhou, R., & Feng, Z. (2002). Symbolic heuristic search using decision
diagrams. In Proceedings of SARA-02.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). A formal basis for heuristic determination
of minimum path cost. IEEE Transactions on on Systems Science and Cybernetics,
4, 100–107.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings
of ECP-01, pp. 121–132.
Helmert, M. (2001). On the complexity of planning in transportation domains. In Proceedings of ECP-01, pp. 349–360.
Helmert, M. (2002). Decidability and undecidability results for planning with numerical
state variables. In Proceedings of AIPS-02, pp. 44–53.
Hipke, C. A. (2000). Verteilte Visualisierung von Geometrischen Algorithmen. Ph.D. thesis,
University of Freiburg.
Hoffmann, J. (2000). A heuristic for domain independent planning and its use in an enforced
hill climbing algorithm. In Proceedings of ISMIS-00, pp. 216–227.
Hoffmann, J. (2002a). Extending FF to numerical state variables. In Proceedings of ECAI02.
Hoffmann, J. (2002b). Local search topology in planning benchmarks: A theoretical analysis.
In Proceedings of AIPS-02, pp. 92–100.
Hoffmann, J., & Nebel, B. (2001). Fast plan generation through heuristic search. Journal
of Artificial Intelligence Research, 14, 253–302.
Hölldobler, S., & Stör, H.-P. (2000). Solving the entailment problem in the fluent calculus using binary decision diagrams. In Proceedings of AIPS-00 Workshop on ModelTheoretic Approaches to Planning, pp. 32–39.
Jensen, R. M., Bryant, R. E., & Veloso, M. M. (2002). SetA*: An efficient BDD-based
heuristic search algorithm. In Proceedings of AAAI-02.
Jensen, R., & Veloso, M. M. (2000). OBDD-based universal planning for synchronized
agents in non-deterministic domains. Journal of Artificial Intelligence Research, 13,
189–226.
Kabanza, F., Barbeau, M., & St-Denis, R. (1997). Planning control rules for reactive agents.
Artificial Intelligence, 95 (1), 67–113.
Kautz, H., & Selman, B. (1996). Pushing the envelope: Planning, propositional logic, and
stochastic search. In Proceedings of AAAI-96, pp. 1194–1201.
Kautz, H., & Walser, J. (1999). State-space planning by integer optimization. In Proceedings
of AAAI-99.
236

Taming Numbers and Durations in MIPS

Knoblock, C. (1994). Generating parallel execution plans with a partial order planner. In
Proceedings of AIPS-94, pp. 98–103.
Koehler, J. (2000). Elevator control as a planning problem. In Proceedings of AIPS-00, pp.
331–338.
Koehler, J., & Hoffmann, J. (2000). On reasonable and forced goal orderings and their use
in an agenda-driven planning algorithm. Journal of Artificial Intelligence Research,
12, 338–386.
Koehler, J., Nebel, B., & Dimopoulos, Y. (1997). Extending planning graphs to an ADL
subset. In Proceedings of ECP-97, pp. 273–285.
Korf, R. E. (1985). Depth-first iterative-deepening: An optimal admissible tree search.
Artificial Intelligence, 27 (1), 97–109.
Korf, R. E., & Zhang, W. (2000). Divide-and-conquer frontier search applied to optimal
sequence alignment. In Proceedings of AAAI-00, pp. 910–916.
Laborie, P., & Ghallab, M. (1995). Planning with sharable resources constraints. In Proceedings of IJCAI-95, pp. 1643–1649.
Lago, U. D., Pistore, M., & Traverso, P. (2002). Planning with a language for extended
goals. In Proceedings of AAAI-02.
Lind-Nielsen, J. (1999). Buddy: Binary decision diagram package, release 1.7. Technical
Univeristy of Denmark. Available from jln@itu.dk.
Lluch-Lafuente, A. (2003). Symmetry reduction and heuristic search for error detection in
model checking. In Proceedings of the Workshop on Model Checking and Artificial
Intelligence (MoChart).
Long, D., & Fox, M. (1998). Efficient implementation of the plan graph in STAN. Journal
of Artificial Intelligence Research, 10, 87–115.
Long, D., & Fox, M. (2001). Encoding temporal planning domains and validating temporal plans. In Workshop of the UK Planning and Scheduling Special Interest Group
(PlanSIG).
McDermott, D. (2000). The 1998 AI Planning Competition. AI Magazine, 21 (2).
McMillan, K. L. (1993). Symbolic Model Checking. Kluwer Academic Press.
Muscettola, N. (1994). HSTS: integrating planning and scheduling. In Zweben, M., & Fox,
M. S. (Eds.), Intelligent Scheduling, pp. 168–212. Morgan Kaufmann.
Pearl, J. (1985). Heuristics. Addison-Wesley.
Pednault, E. (1986). Formulating multiagend, dynamic-world problems in the classical
framework. In Reasoning about Action and Plans, pp. 47–82. Morgan Kaufmann.
Pednault, E. (1989). ADL: Exploring the middleground between Strips and situation calculus. In Proceedings of KR-89, pp. 324–332. Morgan Kaufman.
Pettersson, P. (1999). Modelling and Verification of Real-Time Systems Using Timed Automata: Theory and Practice. Ph.D. thesis, Department of Computer Systems, Uppsala University.
237

Edelkamp

Pistore, M., & Traverso, P. (2001). Planning as model checking for extended goals in nondeterministic domains. In Proceedings of IJCAI-01.
Pohl, I. (1977). Practical and theoretical considerations in heuristic search algorithms.
Machine Intelligence, 8, 55–72.
Refanidis, I., & Vlahavas, I. (2000). Heuristic planning with ressources. In Proceedings of
ECAI-00, pp. 521–525.
Reffel, F., & Edelkamp, S. (1999). Error detection with directed symbolic model checking.
In Proceedings of FM-99, pp. 195–211.
Regnier, P., & Fade, B. (1991). Détermination du parallélisme maximal et optimisation
temporelle dans les plans d’actions linéaires. Revue d’Intelligence Artificielle, 5 (2),
67–88.
Reinefeld, A., & Marsland, T. (1994). Enhanced iterative-deepening search. IEEE Transactions on Pattern Analysis and Machine Intelligence, 16 (7), 701–710.
Rintanen, J. (2003). Symmetry reduction for SAT representations of transition systems. In
Proceedings of ICAPS-03.
Rintanen, J., & Jungholt, H. (1999). Numeric state variables in constraint-based planning.
In Proceedings of ECP-99, pp. 109–121.
Ruys, T. C. (2003). Optimal scheduling using branch and bound with SPIN 4.0. In Proceedings of SPIN-03, pp. 1–17.
Syslo, M. M., Deo, N., & Kowalik, J. S. (1983). Discrete Optimization Algorithms with
Pascal Programs. Prentice-Hall.
Veloso, M. M., Pérez, M. A., & Carbonell, J. G. (1990). Nonlinear planning with parallel
resource allocation. In Innovative Approaches to Planning, Scheduling and Control,
pp. 207–212.
Weismüller, M. (1998). Planen mit einem Modellprüfer im µ-Kalkül . Master’s thesis,
Universität Ulm.
Yang, C. H., & Dill, D. L. (1998). Validation with guided search of the state space. In
Proceedings of DAC-98, pp. 599–604.
Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* with partial expansion for large branching
factor problems. In Proceedings of AAAI-00, pp. 923–929.
Zhou, R., & Hansen, E. (2003). Sparse-memory graph search. In Proceedings of IJCAI-03.

238

Journal of Artificial Intelligence Research 20 (2003) 125–132

Submitted 09/03; published 12/03

Commentary
The Power of Modeling—a Response to pddl2.1
Fahiem Bacchus

fbacchus@cs.toronto.edu

Department. of Computer Science
6 King’s College Road
University Of Toronto
Toronto, Ontario
Canada, M5S 3H5.

Abstract
In this commentary I argue that although pddl2.1 is a very useful standard for the
planning competition, its design does not properly consider the issue of domain modeling.
Hence, I would not advocate its use in specifying planning domains outside of the context
of the planning competition. Rather, the field needs to explore different approaches and
grapple more directly with the problem of effectively modeling and utilizing all of the
diverse pieces of knowledge we typically have about planning domains.

1. Introduction
Fox and Long did a terrific job of organizing the 2002 Planning Competition. A non-trivial
component of that work was specifying an extension of pddl so that a much more interesting
range of problems could be addressed in the competition. Although the extension represents
a very useful standard for the competition, its design ignores both the power and reality of
domain modeling. I will argue that some of the new features of pddl2.1 are unnecessary:
similar effects can just as easily be captured by more robust modeling of the planning
domain.
My own Tlplan planning system competed in the 2002 planning competition. Despite
the fact that Tlplan’s specification language had no direct support for some features of
pddl2.1, we were still able to encode all of the competition domains. Tlplan utilizes
a language that is designed to be suitable for robustly modeling planning domains.1 We
found that many of the new features of pddl2.1 used in the competition were in fact easy
to capture simply by more robust modeling of the planning domain.
That pddl2.1 takes the approach of adding new features to the language, rather than
requiring that the domain be more robustly modeled, is perhaps not surprising given the
dichotomy that still persists in the AI planning field. That dichotomy is between work on
“domain-independent” planning and “control-intensive” planning. Just as work on controlintensive planning tends to ignore the applicability and power of state-of-the-art search
algorithms for planning, work on domain-independent planning tends to ignore the power to
be gained, and the requirements imposed, by domain modeling. Most planning researchers
freely acknowledge the importance of both components, however, one rarely finds work at
1. Tlplan also includes constructs for expressing domain specific control information, but I am not referring
here to that component of the language.

c
2003
AI Access Foundation. All rights reserved.

Bacchus

(:durative-action load-truck
:parameters (?t - truck)
(?l - location)
(?o - cargo)
(?c - crane)
:duration (= ?duration 5)
:precondition (and (at ?t ?l)
(at ?o ?l)
(empty ?c))
:effect
(and (loading ?t)
(at end (not loading ?t))
...
)
(:action move-truck
:parameters (?t - truck)
...
:precondition (and (not (loading ?t))
...)
)

Figure 1: Converting (over all) conditions
the interface of these two issues, nor are there many researchers who work on both of these
issues.2
In the rest of this commentary I will elaborate on my argument by presenting examples of
features and approaches appearing in pddl2.1 that demonstrate its insensitivity to domain
modeling.

2. Coordinating Concurrent Actions
In Section 5 of the pddl2.1 document various constructs are presented to support durative
actions. These are actions whose effects can either be immediate (like ordinary non-durative
actions) or can occur at the end of some fixed duration. The duration can be either a
constant or specified by some functional term. The obvious extension, used, e.g., by Bacchus
& Ady (2001), where an action could have a range of effects each at a different future
timepoint, was not included in pddl2.1.3 Without this extension the (at start) and (at
end) specifiers are reasonable ways of specifying delayed effects.
With non-instantaneous actions concurrency control becomes an issue. To achieve this
kind of control pddl2.1 provides the :condition constructs (at start), (at end), and
(over all). Tlplan does not provide the (at end) and (over all) constructs ((at
start) is simply an ordinary precondition). Yet we were still able to model all of the
planning domains without them. I would argue that in general these constructs are not
necessary.
2. I am just as guilty of this as most of my colleagues.
3. Instead one must ascend to the much more complex specification of continuous effects (presented in
Section 5.3 of the pddl2.1 document) to achieve this degree of flexibility.

126

A Response to pddl2.1

2.1 (over all):
Consider the load-truck action given in Figure 6 of the pddl2.1 article. It contains the
condition (over all (at ?t ?l)): i.e., the truck must stay at the same location through
out the load. Why must it not be moved? Because we are not allowed to move a vehicle while
it is being loaded. Similarly, we should not drive a car while it is being refueled, we should
not turn off the oven while it is being used to bake a cake, we should not attempt to tie our
shoelaces while running, etc. Our knowledge abounds with such common sense conditions.
In natural language we use progressive tenses to refer to ongoing activities. Similarly, the
most natural way to model an (over all) condition is simply to have the action assert that
an activity is ongoing, and use the negation of that activity as a precondition for actions
that could interfere. The resulting transformation of the load-truck action is given in
Figure 1.
In Figure 1 the load-truck action advertises that it has initiated an on-going loading of
the truck by adding a loading predicate to the state. At the end of the action this predicate
is deleted. Actions like move-truck that could interfere with loading are blocked by adding
(not loading) to their preconditions. Using this technique we were able to replace all
(over all) conditions used in the competition domains. Interestingly the replacements
made the domain more sensible and more readable.
Consider in brief the advantages of modeling (over all) effects by adding “progressive
predicates” to the state.
1. The method can be realized without extending the standard strip/adl semantics.
2. An action’s preconditions still encapsulates all of its interactions with the other actions. In the presence of (over all) conditions, one would have to examine every
other action to see if any of its (over all) conditions are interfered with by one of
the action’s effects. Put another way, the action’s activation condition continues to
be Markovian, i.e., dependent only on the current state. The current state continues
to carry all of the information needed to determine if an action can be applied; with
(over all) conditions, one also needs to examine all currently active actions—the
state no longer encapsulates all of the necessary information.
3. Finally, it seems to me that the resulting domain models are more natural and easier
to understand.
2.1.1 Modularity
One concern with the above approach to avoiding (over all) conditions, is that it appears
to make adding new actions to the domain non-modular.4 Non-modularity potentially arises
both from adding new actions that could be interfered with by previous actions, and from
adding new actions that could interfere with previous actions.
The first case arises when we add new actions like refuel, repair, change-tire, etc.,
all of which can be interfered with by the existing action move-truck. Our solution of
adding non-interference preconditions would seem to require modifying the description of
4. Thanks to David Smith and Martha Pollock for pointing out that I needed to address the issue of
modularity.

127

Bacchus

move-truck to add (not (refueling)), (not (repairing)), (not (changing-tire)),
etc., preconditions—a new precondition for every new action added.
The second case arises when we add a new action like tow-truck that also changes
the location of the truck. We would then have to ensure that we add to its preconditions
all progressives required to block it from interfering with previously defined actions. This
second case is perhaps not as problematic, since it does not require modifying any of the
old actions. However, the first case is an issue since one might not want to modify the
definition of previous actions that had already been debugged.
When using (over all) conditions we need not make any changes to old actions nor
worry about the effects of the new actions on the old. However, I would argue that this
modularity exists only at the syntactic level—it is syntactically easy to modify the domain
description to accommodate new actions. There is no corresponding modularity at the
semantic level: the interferences between the new action and the old still exists. In most
cases we cannot simply ignore these interactions, leaving it up to the planner and the (over
all) conditions to resolve. As we have found when developing domains, in many cases
when a new action is added to the domain a bug in the domain specification appears. For
example, plans one would expect to find are no longer found by the planner. Often the bug
lies in the new action, but just as often a bug is found in the specification of the old actions.
If the domain no longer operates as expected, one is still left with the task of unraveling the
interactions of the specification. In general, specifying a rich domain requires understanding
the possible interactions in the domain, and in that task the (over all) conditions do not
help.
It could be argued that it is the job of the planner to unravel the interactions in the
domain. But this argument, I believe, trivializes the job of specifying a planning domain.
The planner’s job is to compute the interactions between actions in a sequence (or more
complex composition) of actions. Getting the domain correctly specified is a difficult task,
and requires at least understanding how actions interact statically, even if one can leave the
dynamic interactions up to the planner.
Fortunately, in most systems the interactions between actions are relatively local: there
is typically a relatively structured way in which actions can interfere with each other. This
is what makes specifying planning domains feasible.
One can take advantage of this structure to build robust domain models that provide
the advantages of semantic as well as syntactic modularity. A critical component of building
good domain models is the ability to use definitions (axioms), a feature that is not provided
by pddl2.1. In Tlplan, e.g., one can define a new predicate symbol using a first-order
formula over previous defined symbols. By defining the right high level constructs one
can typically provide a more explicit representation of the structure of interactions in the
domain. The advantage of doing this is that one also obtains a declarative representation of
this structure, thus achieving a more natural and easier to understand domain specification.
In the example above, one could define a new predicate (must-be-stationary ?t) to
be the disjunction
(or (loading ?t) (changing-tire ?t) (repairing ?t) (refueling ?t)).
Now the (move-truck ?t ?l1 ?l2) action need only have a single precondition (not
(must-be-stationary ?t)), and any new action that requires that the truck be station128

A Response to pddl2.1

(:durative-action load-truck
:parameters (?t - truck)
(?l - location)
(?o - cargo)
(?c - crane)
:duration (= ?duration 5)
:precondition (and (at ?t ?l)
(at ?o ?l)
(empty ?c))
:effect
(and (loading ?t)
(at end (not loading ?t))
(holding ?c ?o)
(not (at ?o ?l))
(at end (when (holding ?c ?o) (in ?o ?t)))
(at end (when (holding ?c ?o) (not (holding ?c ?o))))
(at end (when (not (holding ?c ?o)) (load-failed))))
)

Figure 2: Converting (at end) conditions
ary can be accommodated by simply adding a new disjunct to the definition of must-bestationary. This approach has the advantage of explicitly introducing a new concept
must-be-stationary, which helps in understanding and structuring the domain. In contrast, with (over all) conditions one only has the concept of “not changing at”. In this
simple example the difference appears to be trivial, but the key idea is that once we have
a new concept like must-be-stationary in the domain, we can use it to build up more
complicated concepts.
Using explicit progressive preconditions also allows for the coordination of far more complex shared uses of a resource. For example, we can specify that both refueling and driving
require exclusive use of the truck, and that changing a tire can be done concurrently with
repairing the truck but not concurrently with loading. These conditions can be accommodated by having each action explicitly mention the excluded activities in its precondition,
or through axioms grouping and structuring these activities into more complex conditions
and then using those conditions in the action preconditions. In either case the result is a
more explicit description of the domain that is easier to understand, debug and modify.
2.2 (at end):
(at end) is a very strange condition. In fact, it did not appear in any of the competition
domains. I would argue that it also is not needed; not because it is easily captured by
other constructs, but rather because it is unnatural and would never appear in a reasonable
domain model. (at end) is intended to support the flexibility whereby an action can
“release” a condition so that other actions might delete that condition, as long as the
condition is subsequently restored on time. Like the (over all) condition it has the effect
of breaking the Markovian nature of normal action specifications. A more natural way to
model such a situation, I would claim, is simply to use conditional (at end) effects: if the
required condition holds at the end, the desired effect will be created, otherwise some bad
effect will occur. The so modified load-truck action is given in Figure 2.

129

Bacchus

(:durative-action burnMatch
:parameters (?m - match ?l - location)
:duration (= ?duration 5)
:precondition (and (have ?m)
(at ?l))
:effect
(and (when (no-other-light-source ?l)
(and (not (dark ?l)) (light ?l)))
(not (have ?m))
(burning ?m)
(at end (when (burning ?m) (not (burning ?m))))
(at end (when (and (no-other-light-source ?l)
(burning ?m))
(and (not (light ?l))
(dark ?l))))))
)
(:action blowOutMatch
:parameters (?m - match ?l - location)
:precondition (and (at ?l)
(burning ?m))
:effect
(and (not (burning ?m))
(when (no-other-light-source ?l)
(and (not (light ?l))
(dark ?l)))))
)

Figure 3: Alternate model of burn-match
In this modification, instead of a (at end (holding ?c ?o)) condition, we have simply
changed the effects of the action. If (holding ?c ?o) holds at the end of the action, the
action has its normal effects. Otherwise, it adds to the state a marker indicating that a
load has failed. If we add (not (load-failed)) to the goal, then the planner would search
for ways of falsifying the antecedent of the effect (assuming that (load-failed) cannot be
undone), i.e., the planner would search for ways of ensuring that (holding ?c ?o) is true
at the end of the action. Note that this is exactly what the planner would do to ensure
that an ordinary precondition holds. That is, again we can reduce the construct down to
standard features.

3. Unspecified Durations
Another feature of pddl2.1 is the ability to specify ranges of durations for actions. The
intent here is that the actual duration of the action might be affected by other actions.
The burnMatch and heat-water actions (Figures 10 and 12 of the pddl2.1 document) are
examples where a range is utilized as the duration.
I find flexible durations to be strange, they again make the action dependent on future
actions. Furthermore, I am not convinced that they are necessary. Rather I think that a
more natural way to model such situations would be to introduce two actions, one to start
the action (light the match, or start heating the liquid), and one to end the action (blow out
the match, or take the liquid off the heat). Figures 3 and 4 present these alternate models.
The burnMatch starts the match burning (toggling the lighting status of the location
if there was no other light at that location). It also posts a “default” completion of the

130

A Response to pddl2.1

(:durative-action heat-water
:parameters (?p - pan)
:duration (= ?duration (/ (- 100 (temperature ?p)) (heat-rate)))
:precondition (and (full ?p)
(onHeatSource ?p)
(byPan))
:effect (and (heating ?p)
(heating-start ?p (current-time))
(at end (when (and (byPan) (heating ?p)) (not (heating ?p))))
(at end (when (heating ?p)) (assign (temperature ?p) 100))
(at end (when (and (not (byPan)) (heating ?p)) (burn-pot ?p)))))
(:action take-off-heat
:parameters (?p - pan)
(?startt - time)
:precondition (and (heating ?p)
(heating-start ?p ?startt)
(byPan))
:effect (and (not (heating ?p))
(when (not (burn-pot ?p))
(increase (temperature ?p)
(* (- (current-time) ?startt) (heat-rate))))))

Figure 4: Alternate model of heat-water
match burning at the maximum duration. If the match is still burning at the end of this
maximum duration it is extinguished and the lighting status is toggled (if the match was
the only source of light). On the other hand, the match can be extinguished earlier by a
blowOutMatch action.
The heat-water action starts the water heating, and like burn-match has a default
maximum duration. If the pan is still being heated at the end of that time it raises the
temperature of the pan to 100 degrees, and, if the agent is by the pan, it takes the pan
off the heat, otherwise pan continues to be heated causing it to become burnt (this is in
keeping with our previous discussion about not wanting (at end) preconditions). Note the
pan’s temperature never rises above 100 (we are assuming that the water keeps on boiling).
It also marks the time that heating started ((current-time) is the time that the action
was executed). take-off-heat is an action that can take the pan off the heat at any time.
It uses the start time of the heating to calculate the temperature of the water (if the pot is
burnt, its temperature remains at 100, as set by heat-water).
I am not suggesting that these alternate action specifications are the “right” models
(e.g., the heat-water cannot account for putting the pot back on the heat after taking it
off). What I am suggesting is that the case for variable durations has not been made. Is it
really necessary or even natural for domain modeling?

4. Conclusions
I could list a few other components of pddl2.1 that seem to me to be unnecessary, but I
believe that the point has been made. pddl2.1 is essential for the planning competition,
and I am certainly a strong supporter of the usefulness of the competition for furthering
planning research. However, I would suggest that outside of the context of the competition,
131

Bacchus

the issue of which features should be included in a planning domain specification language
needs to be more grounded in the application of these languages. Planning domains, even
simplified ones designed for research, can be modeled in many different ways, and I believe
that it is better to produce more robust models with simpler languages than to develop
languages with features that are not really needed.
I do think that many of the ideas contained in pddl2.1 are useful, e.g., the way in
which continuous change is treated. Nevertheless, I would not encourage anyone to try to
construct planning algorithms for dealing with these features. Rather I would encourage
the development of planning algorithms inspired by the issues that arise from interesting
domains. That is, I think that the incorporation of new features into planning languages
needs to be motivated by compelling examples.

References
Bacchus, F., & Ady, M. (2001). Planning with resources and concurrency, a forward chaining
approach. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp. 417–424.

132

Journal of Artificial Intelligence Research 20 (2003) 145-148

Submitted 9/03; published 12/03

Commentary
PDDL2.1 — The Art of the Possible?
Commentary on Fox and Long
Drew McDermott

drew.mcdermott@yale.edu

Dept of Computer Science, Yale University,
PO Box 208285, New Haven, CT 06520–8285

Abstract
PDDL2.1 was designed to push the envelope of what planning algorithms can do, and
it has succeeded. It adds two important features: durative actions, which take time (and
may have continuous effects); and objective functions for measuring the quality of plans.
The concept of durative actions is flawed; and the treatment of their semantics reveals
too strong an attachment to the way many contemporary planners work. Future PDDL
innovators should focus on producing a clean semantics for additions to the language, and
let planner implementers worry about coupling their algorithms to problems expressed in
the latest version of the language.

All things considered, Fox and Long have done a terrific job producing PDDL2.1. I know
from experience that getting a committee to agree on a language requires a delicate combination of diplomacy and decree. The language extensions that emerged from the 2002
competition are not exactly what anyone wanted, but apparently everyone can live with
them. PDDL2.1 is serving as a sturdy basis for evaluating and comparing planning algorithms, which is the prime purpose of the language in the first place. It appears that for
the next competition only minor extensions, and no revisions, will be necessary.
On top of their work negotiating the syntax of the language, Fox and Long also produced a semantics, on display in their paper, plus a more elaborate semantics for fully
autonomous processes, which did not make it into PDDL2.1, unfortunately. (I was on the
2002 competition committee, and, as I explain below, I am not as enthusiastic as others on
the committee about the concept of “durative actions.”)
Probably the most important innovation in PDDL2.1 is the introduction of objective
functions for plans, thus making plan quality as important as plan existence. So far few
planners have been able to do much with objective functions, which indicates how thoroughly we’ve all been conditioned by the classical-planning framework. Objective functions
should become much more important in the future.
The main defect in PDDL2.1 is that its syntax and semantics are tailored too closely
to a currently popular style of planner. For example, functions are allowed, but of exactly
one kind, namely, those that take non-numeric arguments and denote time-varying numeric
quantities. That is, in (f ---args--- ), each arg must be an identifier and the overall value
must be a number that can change from situation to situation. A paradigmatic example
is (amount-in tank1), which might denote the volume of fuel in tank1. A term such as
(object-at-distance 3) is not allowed. Why these restrictions? Because many planners
eliminate all variables at the outset of a solution attempt by instantiating terms with all
c
2003
AI Access Foundation. All rights reserved.

McDermott

possible combinations of the objects mentioned in the problem statement. This tactic may
sound unpromising, but for many problems of a reasonable size it works surprisingly well.
However, as soon as the universe of objects becomes infinite the tactic stops working, and
that means numbers can’t be treated like ordinary objects. It also means that general
functions can’t be part of the language. If we had a function midpoint: Location ×
Location −→ Location, then it would generate an infinite set of terms such as (midpoint
loc-a (midpoint loc-b loc-a)).
In PDDL 1.0, such problems did not arise because there were no functions in the language. The main goal in designing it was to agree on a lowest-common-denominator notation that many planners could obviously cope with, so that it could become a standard for
problem statement. The language succeeded quite well in that regard,1 which is why it is
also the standard framework for discussions about where to go next. In those discussions,
there are several relevant considerations:
1. What real-world problems need to be solved?
2. What problems lie just beyond the solvable fringe of the current state of the art?
3. What constructs can be given a clean semantics? Or any coherent semantics at all?
4. What constructs can current planning algorithms cope with?
I have listed these in declining order of importance, although I grant that they are
all important. I believe that PDDL2.1 gives too much weight to consideration 4, and the
example of functions is a good case in point. Functions can play several different roles in a
logical theory, which is what PDDL domains are, when you get down to it. In an assemblyplanning domain, someone might want a function top such that (top cylinder-3) denotes
the top of a piece being worked on. How do the considerations above come into play?
1. Assembly planning is a real-world problem.
2. It lies well beyond what is currently solvable, probably too far beyond.
3. The semantics of functions in mathematical logic are well understood, and we can use
the same solutions here.
4. Current planning algorithms can’t cope with all functions, but they can easily be
extended to handle functions like top, which can’t be recursively nested.
Given these answers, and considering other examples, it seems clear that adding functions to PDDL is a good idea: it would make the language easier to use in realistic problems,
and in many cases would impose a minimal burden on current planners. If the presence
of functions makes some set of problems unsolvable by a planning system, then the system
should detect when such a problem is encountered and go on to the next one. If we wanted
to, we could add a :functions requirements flag to the language, but it hardly seems worth
the trouble. But, as I said above, so much weight was attached to the abilities of current
planners that PDDL2.1 ended up with a function declaration whose syntax of functions is
needlessly restricted and whose semantics is needlessly complex.
1. To be precise, it succeeded well for action-based planners, and went nowhere for hierarchical planners.

146

PDDL2.1 — The Art of the Possible?

We see the same phenomenon again with “durative actions,” that is, actions that require
a specified amount of time to execute. The committee had to thrash out a compromise about
these things, mainly revolving around how far to go beyond the state of the art. A minority
(including me, as well as Fox and Long) thought that the obvious next step was to be
able to model autonomous processes, which differ from actions in two respects: they have
continuous effects, and they run whenever their conditions are true (“precondition” is not
quite the right term), no matter what the “target agent” (the one executing the plans) does.
An example is boiling water: as long as there is water in a pot, and the water is at 100
degrees Celsius, the water will boil away, continuously decreasing in volume. The agent can
make use of processes by making their conditions true or false at appropriate times.
Unfortunately, a majority of the committee thought putting processes into PDDL was
too big a leap, and that we should instead add durative actions. As Fox and Long’s paper
shows, the term “durative action” really refers to two completely different species: actions
that take a fixed amount of time no matter what, such as traveling from New York to
London;2 and actions whose duration is partly under the control of the planner, such as
boiling water. The difference is flagged syntactically by whether the :duration field of a
durative action is an equality (species 1) or an inequality (species 2). If an agent executes
an action of species 1, it loses some of its “freedom” for the duration of the action. If
the agent is sitting in an airplane, it’s not out taking a hike. That seems unproblematic,
but consider cleaning a warehouse, which might be modeled as taking an amount of time
proportional to the “messiness” of the warehouse. It is a weird idealization to imagine that
a robot might commit itself to cleaning the warehouse, and then essentially be a prisoner
of this decision until the warehouse is clean.
Duratives of species 2 avoid this problem, by essentially sneaking autonomous processes
into the theory in a strange form. We are allowed to use autonomous processes, just so
long as we pretend the target agent is “executing” them. Rather than connect the process
directly to its condition, we suppose that the agent can decide to stop the process at any
point consistent with the constraints on ?d, the duration of the action. So, in Figure 14
of Fox and Long’s paper, rather than having an autonomous process that is started and
stopped by changing the truth value of (onHeatSource pot ), we say that (onHeatSource
pot ) becomes true or false when the agent starts or stops the heat-water action. No
turn-on or turn-off actions are required.
The first remark to make is that the difference between an action the target agent can
stop and one it must just wait to end should not be marked syntactically. Suppose it is
possible for the agent to get locked out of the kitchen while it is boiling water. Then it
can no longer stop the boiling. In PDDL2.1, it is impossible for this sort of thing to be
expressed. The closest we can come is to make (over all (in agent kitchen)) be a
condition of the durative action, but then as soon as the agent leaves the kitchen it must
bring the heat-water action to a close, or its plan will be invalid.
My impression is that most planners that can handle duratives can handle only species
1, which is why the committee decided to include duratives. It seems clear to me that
species 2 is headed for extinction in favor of straightforward autonomous processes.
2. Assuming flight time is fixed may seem too extreme an idealization, but allowing the time to vary
(probabilistically?) would push PDDL far beyond its classical-planning roots; none of the controversies
mentioned here ever question the knowability of the future.

147

McDermott

Fox and Long define the semantics of duratives in terms of ordinary actions plus “monitoring actions” that make sure that conditions remain true over the intervals in which
they’re supposed to be true. It is possible to know exactly where these monitoring actions
are supposed to be inserted because all changes in fluents are linear. This way of specifying semantics, has, unfortunately, just about run its course. As Fox and Long point out,
future increases in the complexity of temporal constructs will make it harder to express the
semantics of PDDL, and harder to verify that a plan is correct.
The details of durative semantics echo the issues that arose in connection with the
semantics of functions. The tricky part about the semantics of actions is incorporating the
STRIPS assumption that actions can be represented in terms of add lists and delete lists,
which in turn requires assuming that situations can be represented as finite lists of atomic
formulas. One might suppose that numbers would complicate this picture because there
are an infinite number of them, but fortunately numbers in themselves don’t compromise
the STRIPS world view. If we specify a block’s location in numerical coordinates, it still
has only one location, and moving it involves deleting the assertion stating its old location
and adding a new one.
Why, then, do Fox and Long work so hard to keep numerical assertions strictly separate
from non-numeric? Why do they “flatten” action definitions before assigning them a semantics? Why are quantifiers handled by substituting all possible terms for the variables?
The answer to all these questions is the same as for the odd restrictions on functions: Many
current planners depend on generating all possible instances of an action.
It usually clarifies the semantics of a language greatly if it is defined without any direct
connection to the implementation of a reasoning system for the language. In (McDermott,
2003) I sketch a formal semantics for an extension of PDDL containing true autonomous
processes. The fulcrum of the framework is a set of truth conditions for process definitions.
There is no obvious link to the requirements of a planning algorithm, and in fact the
semantics allows processes that would be quite difficult to cope with or exploit. However, it
is not hard to find subsets of process definitions, including those corresponding to durative
actions, that current planners, with slight extensions, could handle.
One of the key goals of PDDL from the beginning has been to put pressure on the
automated-planning community to make planners handle a more realistic class of planning
problems. When new versions of PDDL are restricted in ways congenial to existing planners,
it sends a mixed message, urging us into new territory, and at the same time reassuring us
that our algorithms might still be basically correct. The planning community doesn’t really
need so much reassurance; we should opt for a domain-definition language with clear syntax
and clean semantics and then find algorithms that can solve problems in the domains the
language describes.

References
McDermott, D. (2003). The formal semantics of processes in PDDL. In Proceedings of the
ICAPS-03 Workshop on PDDL.

148

Journal of Artificial Intelligence Research 20 (2003) 343–377

Submitted 12/02; published 12/03

TALplanner in the Third International Planning
Competition: Extensions and Control Rules
Jonas Kvarnström
Martin Magnusson

jonkv@ida.liu.se
marma@ida.liu.se

Department of Computer and Information Science
Linköping University
SE-581 83 Linköping, Sweden

Abstract
TALplanner is a forward-chaining planner that relies on domain knowledge in the shape
of temporal logic formulas in order to prune irrelevant parts of the search space. TALplanner recently participated in the third International Planning Competition, which had a
clear emphasis on increasing the complexity of the problem domains being used as benchmark tests and the expressivity required to represent these domains in a planning system.
Like many other planners, TALplanner had support for some but not all aspects of this increase in expressivity, and a number of changes to the planner were required. After a short
introduction to TALplanner, this article describes some of the changes that were made
before and during the competition. We also describe the process of introducing suitable
domain knowledge for several of the competition domains.

1. Introduction
Like most planners, TALplanner (Kvarnström & Doherty, 2000; Doherty & Kvarnström,
1999; Kvarnström, Doherty, & Haslum, 2000; Doherty & Kvarnström, 2001; Kvarnström &
Doherty, 2003; Kvarnström, 2002) allows the user to specify a goal in the shape of a set of
atemporal logic formulas that must be satisfied in the final state that results from executing
a plan. Unlike most planners TALplanner also allows the specification of a set of temporal
logic formulas that must be satisfied by the entire state sequence generated by a plan.
Obviously, these formulas can be used to specify temporally extended goals, such as
safety and maintenance goals that must be upheld throughout the execution of a plan.
However, it is also possible to specify constraints related to traditional measures of plan
quality, such as constraints that forbid certain “stupid” actions from taking place, as in the
Blockhead blocks world planner by Kibler and Morris (1981) or TLplan by Bacchus and
Kabanza (2000), which initially inspired the development of TALplanner. For example, in
a logistics domain one may specify a temporally extended goal stating that once a package
is at its destination, it is never picked up again, and a goal stating that trucks driving
between two locations always use the shortest path. Such constraints can then be processed
by TALplanner in order to automatically extract control knowledge that can be used during
a forward-chaining search process, as opposed to being used as a filter after a candidate plan
has been generated. Given sufficiently strong constraints, the planner can efficiently prune
most of the search tree, making it easier to find a plan among the remaining nodes. Often
(as in this article) the search control aspect is in fact the primary reason for introducing a
temporally extended goal, in which case the goal is usually referred to as a control rule.
c
2003
AI Access Foundation. All rights reserved.

Kvarnström & Magnusson

Although forward-chaining planners may sometimes suffer from a lack of goal-directedness
when compared to other types of planners, the use of explicitly represented domain-dependent
knowledge is one way of compensating for this deficiency. More significantly, a forward
chaining planner always has a complete description of the past and current states, which
facilitates the use of complex operator types with complex preconditions and conditional
effects. This expressivity was useful when TALplanner participated in the third International Planning Competition (IPC-20021 ), which had a clear emphasis on increasing the
complexity of the problem domains used as benchmark tests and the expressivity required
to represent these domains in a planning system. In fact, TALplanner already had support
for several new features that had not been present in IPC-20002 , such as the use of numeric
state variables and temporally extended actions with variable duration.
Nevertheless, several extensions and changes had to be implemented before and during
the competition in order to accommodate the semantics of PDDL2.1, the new version of
PDDL (Planning Domain Definition Language, Fox & Long, 2003) which was used to specify
problem domains and problem instances. These extensions and changes are the first topic
of this article, and after an introduction to TALplanner (Sections 2 and 3), the extensions
will be discussed in Section 4. The second topic is that of describing the domain-dependent
control rules that were used for the six benchmark problem domains in the hand-tailored
track of the competition, and more importantly, the process of generating those rules and
the reasoning behind them (Section 5). We will also describe some new changes that have
been made to TALplanner after the competition (Section 6). Finally, we will conclude
with a discussion of the positive and negative sides of using search control knowledge in
TALplanner together with some pointers towards possible future research topics.
Please see Long and Fox (2003) for further information about the basic setup of the
competition, detailed descriptions of the planning domains being used, and timing and plan
quality results.

2. Representation: Using TAL in TALplanner
The semantics of TALplanner is based on an extended version of TAL-C (Karlsson &
Gustafsson, 1999; Doherty, Gustafsson, Karlsson, & Kvarnström, 1998), a member of the
TAL (Temporal Action Logics) family of narrative-based non-monotonic linear discrete
metric time logics for reasoning about action and change. TAL-C has been developed for
modeling domains that may include the use of incomplete information, delayed effects of
actions, finite or infinite chains of indirect effects, interacting concurrent actions, and independent processes not directly triggered by action invocations. Consequently, it was seen as
an ideal choice not only for the initial version of TALplanner but also for most extensions
that could conceivably be implemented in the foreseeable future.
A TAL narrative consists of a set of labeled statements in a high-level macro language
L(ND), where the basic language has a number of statement classes for observations of fluent
values (labeled obs), action descriptions (acs), action occurrences (occ), domain constraints
(dom), and dependency constraints modeling causal relations and indirect effects (dep).
The formal semantics of L(ND) is defined by a translation into an order-sorted first-order
base language L(FL) and by a circumscription policy providing a solution to the frame and
ramification problems (Doherty, 1994; Gustafsson & Doherty, 1996; Doherty et al., 1998).
1. http://www.dur.ac.uk/d.p.long/competition.html
2. http://www.cs.toronto.edu/aips2000/

344

TALplanner in IPC-2002: Extensions and Control Rules

The L(ND) language is designed to be easily extended for different tasks, such as planning. An extension may take the shape of a new specialized macro or a new type of
statement. As illustrated in Figure 1, a TALplanner goal narrative uses a version of L(ND)
called L(ND)∗ , which contains some of the standard classes of L(ND) statements together
with several new types of planning-related statements. These extensions are accompanied
by extensions to the translation function, so that the new variation of TAL can still share
the same base language L(FL).
However, TALplanner does not use
L(ND)*
L(ND)
this
translation directly during the planTALPlanner
TAL
TAL
ning
process. Instead, it makes direct use
Plan Narrative
Goal Narrative
of the higher level L(ND)∗ goal narrative
in a forward-chaining search process and
L(FL)
L(FL)
generates a plan narrative where a set of
1st−order
1st−order
timed action occurrences (corresponding
theory T’
theory T
to a plan) has been added, and where the
+ Circ(T)
+ Circ(T)
goal is entailed in the final state.
L(FL)
+ Quantifier Elimination
L(FL)
+ Q.E.
In this section, we will attempt to
1st−order
1st−order
provide an intuitive understanding of TAL
theory
theory Goal
and how it is used in domain specifications using concrete examples from the
Figure 1: TAL/TALplanner relation
standard logistics planning domain, where
a set of objects (packages) can be transported by truck between locations in the same city
and by airplane between airports in different cities. The next section contains further information about the search process and the use of control rules. See Doherty et al. (1998)
for a more detailed description of TAL, and see Kvarnström and Doherty (2000) for more
information about TALplanner.
Notation. All formulas and L(ND) statements below will be shown using the input syntax
for TALplanner, with the exception of some connectives and quantifiers that may be written
using the ordinary logical symbols for increased clarity. All free variables are implicitly
universally quantified.
2.1 Types, Objects and State Variables
Although some planners are restricted to declaring an unstructured set of objects and
representing types as unary predicates, TAL is order-sorted and allows the user to specify a
hierarchy of object types (sorts). The logistics domain can be modeled using the standard
sort boolean = {true, false} together with the seven user-specified types: loc (location) has
the subtypes airport and city, while thing has the subtypes obj and vehicle, the latter of
which has the subtypes truck and plane.
TALplanner also allows the use of numeric types. In order to keep the semantics of these
types clear, only integers and fixed point numbers (that is, numbers with a fixed number
of decimals) are allowed, and lower and upper bounds must be declared for each numeric
type. All of the standard arithmetic operators are available for the numeric types and are
given an interpretation through semantic attachment.
State variables are represented using TAL fluents, which are not restricted to being

345

Kvarnström & Magnusson

predicates but can take values from an arbitrary user-specified sort. For the logistics domain,
one could use two boolean fluents, at(thing, loc) and in(obj, vehicle), together with a cityvalued fluent city of(loc) denoting the city containing the location loc.
2.2 The Initial State
Given the fluents that were defined above, the initial state of a logistics problem instance
can be specified using L(ND) observation statements:
#obs [0] city of(pos1) =
ˆ city1 ∧ city of(pos2) =
ˆ city2 ∧ . . .
#obs [0] at(obj11, pos1) ∧ at(truck1, pos1) ∧ . . .
These observations consist of TAL-C fixed fluent formulas, formulas of the form [τ ] φ denoting the fact that the fluent formula φ holds at time τ . A fluent formula is a boolean
combination of elementary fluent formulas of the form f =
ˆ v (f==v in input notation),
denoting the fact that the fluent f takes on the value v. For boolean fluents, as in the
second observation, the shorthand notation f or ¬f (!f in input notation) is allowed. The
notation is also extended for open, closed, and semi-open temporal intervals. In addition
to these formulas, the function value(τ, f ) denotes the value of f at time τ .
2.3 The Goal: Goal Statements and Goal Expressions
A statement class for goals (labeled goal) has been added to L(ND)∗ . A goal statement
consists of a fluent formula that must hold in any goal state:
#goal at(obj11, airport1) ∧ at(obj23, pos1) ∧ . . .
The ability to test whether a formula is entailed by the (state-based) goal is very useful in
temporally extended goals and domain-dependent control rules. Therefore, a new macro is
added: The goal expression goal(φ) holds iff the goal of this problem instance (the conjunction of all goal statements) entails the fluent formula φ. Stated differently, goal(φ) is true
if φ must be true in every goal state. The translation into L(FL) is somewhat complex;
see Kvarnström and Doherty (2000) for further information.
Note that a valid plan must end in a goal state. It is not sufficient to visit a goal state
temporarily, which could be the case when an operator has effects at multiple timepoints
– first satisfying the goal and then destroying it – or when concurrent plans are being
created. (If such plans were desired for some reason, it would of course be easy to modify
the definition and the planner accordingly.)
2.4 Operator Definitions
Since TAL-C is a logic for reasoning about action and change, it has a notion of actions
that can be used for modeling planning operators. Although TALplanner does use the
same semantics, the extended planning language L(ND)∗ contains a new operator macro
providing a syntax which facilitates the use of resource constraints and other planningoriented concepts that are not present in standard TAL-C. This is in line with the standard
TAL practice of preserving the logical base language L(FL) and its semantics but providing
different variations of the high-level macro language L(ND) that are adapted to special
tasks.
346

TALplanner in IPC-2002: Extensions and Control Rules

The examples below demonstrate the operator definition syntax using three of the six
logistics operators. Further examples will be shown when the IPC-2002 benchmark domains
are discussed.
#operator load-truck(obj, truck, loc) :at s
:precond [s] at(obj, loc) ∧ at(truck, loc)
:effects
[s+1] at(obj, loc) := false, [s+1] in(obj, truck) := true
#operator unload-truck(obj, truck, loc) :at s
:precond [s] in(obj, truck) ∧ at(truck, loc)
:effects
[s+1] in(obj, truck) := false, [s+1] at(obj, loc) := true
#operator drive(truck, loc1 , loc2 ) :at s
:precond [s] at(truck, loc1 ) ∧ city of(loc1 ) =
ˆ city of(loc2 ) ∧ loc1 6= loc2
:effects
[s+1] at(truck, loc1 ) := false, [s+1] at(truck, loc2 ) := true
Although not used in the simple logistics operators above, TALplanner also allows the
use of context-dependent and quantified effects as well as prevail conditions. Unlike pure
preconditions, prevail conditions are not limited to the invocation state of an operator but
can refer to the entire interval during which the operator is executed. The interval at which
each prevail condition must hold is explicitly specified, which provides additional flexibility
compared to requiring that a precondition must always hold throughout the execution of
an action.
2.5 Resources
If TALplanner was limited to generating sequential plans, resource consumption and production could be handled using plain operator effects. For example, if loading a truck
requires one unit of space, the amount of available space could be decreased as follows:
#operator load-truck(obj, truck, loc) :at s
:precond [s] at(obj, loc) ∧ at(truck, loc)
:effects
[s+1] space(truck) := value(s, space(truck)) – 1, . . .
With concurrent planning, this is clearly not sufficient, since multiple parallel invocations
of load-truck would still only consume one unit of space. For this reason, TALplanner has
explicit support for resources (Kvarnström et al., 2000).
Resources can be declared in a manner similar to ordinary fluents: They can have
parameters and can take values in an arbitrary integer or fixed point domain. Unlike some
planners, TALplanner only provides one type of resource, but provides several types of
resource effects. Resources can be produced and consumed. They can also be borrowed
(and automatically returned), either exclusively, meaning that the borrower has exclusive
use of the resource during the specified interval, or non-exclusively, where multiple actions
can borrow the same units of a certain resource concurrently. The latter case may appear
strange, but can be useful when one wants to use a resource as a semaphore or mutex.
Finally, resources can be assigned a completely new value.

347

Kvarnström & Magnusson

In the following example, loading a truck always consumes one unit of space.
#operator load-truck(obj, truck, loc) :at s
:precond [s] at(obj, loc) ∧ at(truck, loc)
:effects
[s+1] at(obj, loc) := false, [s+1] in(obj, truck) := true
:resources [s+1] :consume space(truck) :amount 1
Unlike ordinary fluents, a resource res has multiple aspects that can be queried and used in
formulas such as operator preconditions or control rules. At any timepoint, there is an initial amount available, $init(res). A certain amount may be consumed during this time
step ($consumed(res)), produced ($produced(res)), borrowed exclusively ($borrowed(res))
and borrowed non-exclusively ($borrowed-nonex(res)). This results in a remaining amount
available ($available(res)), which must be between the minimum ($minimum(res)) and the
maximum ($maximum(res)) allowed. The ability to refer to these aspects directly allows
the user to specify more complex resource constraints than a simple minimum or maximum value for a resource, such as a control rule defining a maximum amount that may be
consumed per time step.
This concludes the description of planning domain definitions in TAL. The following
sections will show the structure of TALplanner’s forward-chaining search tree and how the
search process is constrained using control rules.

3. Search and Control Rules
Like any forward-chaining planner, TALplanner searches for a plan in a tree where the root
corresponds to the initial state and where each outgoing edge corresponds to one of the
operators applicable in its source node. Two trivial examples are shown in Figure 2, where
the notation [s,t] A means that the action A is executed between time s and time t. For
sequential planning (Figure 2a), a new action is always added at the time step where the
previous action ended. For concurrent planning (Figure 2b), TALplanner still adds a single
action at a time to the plan, but the constraint on the time where the action is executed
is relaxed: The action must not start before the start of an existing action in the current
plan prefix or after the end of an existing action. When searching the tree, preference is
given to actions invoked at earlier timepoints. In other words, TALplanner tries to add
as many applicable actions as possible at the same timepoint before stepping to the next
timepoint, so in Figure 2b the subtree starting in [0,4] A3, executing the action A3 between
time 0 and time 4, would have been explored before backtracking to the subtree starting
with [2,5] A3, where A3 happens to take slightly less time to execute due to differences in
the state where the action is invoked. The search process ends as soon as the planner has
found a plan ending in a state satisfying the goal. The exact definition of the search tree
is available in Kvarnström and Doherty (2000) for sequential TALplanner and Kvarnström
et al. (2000) for concurrent TALplanner.
Although it is common to view each node in a search tree as consisting of a single state,
and an operator as a function from states to states, this is not sufficient for TALplanner,
for several reasons: A single operator may generate multiple new states, the evaluation of
a temporally extended goal or domain-dependent control rule may require access to the
entire state history beginning in the initial state, and during concurrent planning a future

348

TALplanner in IPC-2002: Extensions and Control Rules

Initial
node

[0,1] A1

[3,4] A1
[4,7] A3

[0,3] A2
[0,2] A3

0

1

Initial
node

[0,3] A2

3

4

[3,4] A1

[0,1] A1

[0,3] A2

[1,12] A4

[0,4] A3
[2,5] A3

[0,2] A3

Goal
node

2

[0,1] A1

0

5

Goal
node

1

2

3

4

5

[0,3] A2

[4,7] A3

[0,1] A1

[0,3] A2

(a) Sequential

[2,5] A3

(b) Concurrent

Figure 2: Forward-Chaining Search Space
state may be modified by several operators before it reaches its final configuration. For
these reasons, it is more convenient to view each node as consisting of a state sequence, or
(equivalently) a logical model, as indicated in the figure.
A simple forward-chaining planner can be implemented by searching this tree using a
standard search algorithm, such as iterative deepening or depth first search. But although
using a complete search algorithm is clearly enough to make the planner complete, it is
equally clear that a certain degree of goal-directedness is required to make the search process
efficient. This is achieved using domain-dependent control rules.
3.1 Using Domain-Dependent Control Rules
In fully automated planning, the planner is generally only supplied with an initial state, a
set of acceptable goal states (often specified using propositional or first-order formulas that
must hold in any goal state), and a set of operators to be used in the plan. It is up to
the planner to determine how to search for a plan efficiently, with the possible exception of
various command line options that can be fine-tuned by the user.
However, in some cases the user has additional information about a planning domain that
could be of use to the planner, and this information may be difficult to extract mechanically
from a simple domain specification. If this is the case, it would make sense to allow the user
to supply this information to the planner. Although it entails somewhat more work for the
user, it may also lead to finding plans more quickly or finding plans of higher quality.
There are of course many different kinds of additional information that could be given
to the planner. TALplanner (inspired by TLplan, Bacchus & Kabanza, 2000) allows the
user to specify a set of first-order TAL formulas that must be entailed by the final plan.
This serves two separate purposes. First, it allows the specification of complex temporally
extended goals such as safety conditions that must be upheld throughout the execution of
a plan, and second, the additional constraints on the final plan often allow the planner to
prune entire branches of the search tree, since it can be proven that any leaf on the branch
will violate at least one such goal. In many cases this pruning is the main reason for the
use of the formula, in which case it is often called a control rule. (Allowing the planner to
prune branches efficiently requires some additional analysis, as described in Kvarnström,
2002.)
349

Kvarnström & Magnusson

3.2 Control Rules for the Logistics Domain
The following are some of the control rules we use for the logistics domain. Further control
rule examples will be given when the IPC-2002 benchmark domains are discussed.
First, a package should only be loaded onto a plane if a plane is required to move it,
i.e., if the goal requires it to be at a location in another city. Second, if we have unloaded a
package from a plane, the package must have arrived in the correct city satisfying the goal.
Third, if a package is at its destination, it should not be moved.
#control :name ”only-load-when-necessary”
[t] ¬in(obj, plane) ∧ at(obj, loc) ∧
¬∃loc’ [ goal (at(obj, loc’)) ∧ [t] city of(loc) =
6 ˆ city of(loc’) ] →
[t+1] ¬in(obj, plane)
#control :name ”only-unload-when-necessary”
[t] in(obj, plane) ∧ at(plane, loc) ∧
¬∃loc’ [ goal (at(obj, loc’)) ∧ [t] city of(loc) =
ˆ city of(loc’) ] →
[t+1] in(obj, plane)
#control :name ”objects-remain-at-destinations”
[t] at(obj, loc) ∧ goal (at(obj, loc)) → [t+1] at(obj, loc)
Note that these rules could of course be expressed on various other logically equivalent
forms. Most such variations would have identical performance, since TALplanner internally
normalizes many aspects of control formulas during its domain analysis phase.

4. The Third International Planning Competition
In the second international planning competition (IPC-2000), the planning domains used
mainly STRIPS expressivity. Support for typed objects was not required, and for those
domains that could use ADL-style quantified and conditional effects, restricted STRIPS
versions were also provided.
Although we did expect some increase in expressivity in the third competition (IPC2002), we were quite surprised by the extent of the changes. Fortunately, TALplanner
already supported many of the new requirements, and some of the others were easily implemented. Despite this we did make some rather significant changes in order to handle the
combination of all these extensions more efficiently. Below we will discuss how each of the
new requirements affected TALplanner together with a few other improvements that have
been prompted by the domains used in the competition.
4.1 ADL-style Operator Definitions
Though there were STRIPS versions of most planning domains in IPC-2002, the more
complex versions of the domains required the use of quantified conditional effects. Like
most other current planners, TALplanner is not limited to STRIPS expressivity and already
had support for this.

350

TALplanner in IPC-2002: Extensions and Control Rules

4.2 Numeric Types and Arithmetic
All IPC-2000 domains that required numeric values emulated these values using ordinary
objects. In the Miconic-10 elevator domain, for example, floor numbers were emulated using
objects named f0, f1, and so on. The next floor was not calculated as f + 1 but by using
an explicitly defined predicate above(floor, floor).
The same approach was taken in the simplest versions of the IPC-2002 domains, but
there were also “Numeric” versions of these domains where numeric types were required
and where arithmetic operators were used. This was already supported by TALplanner,
but unfortunately there was not enough time to write control rules for these domains.
4.3 Concurrency
Despite the fact that some IPC-2000 domains provided the potential for using concurrent
actions, such as driving several trucks concurrently in the logistics domain, there was no
reward for exploiting this potential. Plan quality was measured in terms of the number
of operators in a plan, not in terms of the amount of time required to execute the plan.
Consequently, several planners (including TALplanner) only generated sequential plans,
even for highly concurrent domains.
In IPC-2002, plan quality was mainly measured in terms of the timepoint at which the
last operator finished executing (the “makespan” of the plan, in scheduling terms), and any
planner generating sequential plans would have been severely handicapped. Fortunately a
concurrent version of TALplanner had already been implemented, together with support
for resources (Kvarnström et al., 2000), and could be used in the competition.
Although concurrent TALplanner had already been applied to a number of domains,
the competition provided us with a more varied set of domains that sometimes exploited
concurrency in slightly different ways. This provided us with new ideas for improvements to
TALplanner, and several minor enhancements to TALplanner’s formula analysis algorithms
were implemented during the first phase of the competition, allowing it to handle certain
types of control formulas more efficiently when doing concurrent planning.
4.4 Operators with Non-Unit and Context-Dependent Duration
In IPC-2000, each plan operator used a single time step. In the SimpleTime and Timed
versions of the IPC-2002 planning domains, operators could have a non-unit duration, so
that (for example) walking requires more time than driving. This was already supported
by TALplanner, and no changes were required.
In the Timed versions of the IPC-2002 planning domains, the durations of some operators could also be context-dependent, and could be specified using arithmetic expressions,
requiring support for numeric types as already discussed above. For example, the time
required to drive a truck between two locations could be specified as the distance between
the locations divided by the speed of this particular truck. This was also already supported
by TALplanner.
TALplanner also permits effects to take place at multiple timepoints within the duration
of an action, although this was not used in the competition.

351

Kvarnström & Magnusson

4.5 Non-Integer Time
Some of the IPC-2002 contest domains required operator durations to be calculated with a
precision of at least three decimals, which posed a problem for us. The underlying TAL-C
logic is based on integer time, and therefore the same is true for TALplanner. Introducing
non-integer time properly would have required changes to the underlying TAL semantics,
which could not be done in the time that was available, and therefore we simply multiplied
durations by a thousand. When printing a plan, all time values were divided by a thousand.
4.6 Operators with Extended Duration
In the initial implementation of TALplanner (in 1998–1999), it was assumed that although
operators might have extended durations, something interesting would be happening at a
significant proportion of the discrete time steps within that duration. For example, an
operator invoked at t might have a duration of 5 time steps, where some effects take place
at time t + 1, some at time t + 4, and some at time t + 5. This assumption influenced some
of the algorithms and data structures in TALplanner, and appeared reasonable at the time,
since most planning domains in the literature only used single-step operators.
Nevertheless, it was always our intention to extend these algorithms and structures to
handling plans with sparse effects, where most discrete time steps contain no effects at all.
Doing this would not have been difficult, but partly for that very reason – there were more
interesting research issues to be tackled instead – it was continuously postponed.
IPC-2002 finally provided us with a compelling reason to change the data structures,
together with a number of example domains that could be used to test the changes. For
example, an operator in a timed domain from IPC-2002 might have a duration of (say)
89.237, requiring 89237 discrete time steps, where all effects take place at the beginning
or at the end of the action. This led us to implement a new sparse state structure and
change a few algorithms whose time complexity accidentally depended on the duration of
an operator rather than the number of time steps where something actually happened. The
current version of TALplanner allows both state structures to be used depending on the
characteristics of each planning domain.
4.7 The “No Moving Targets” Rule
As already mentioned, TALplanner’s semantics is based on the use of TAL, while the planning competition uses PDDL2.1. While the semantic differences between these two approaches are usually not a major problem, we did have some trouble with the way the
effects of durative actions are modeled in PDDL2.1. In essence, PDDL2.1 predicates or
numerical fluents that are affected by the effects of an action are considered to be “moving
targets”, and the preconditions of another action are not allowed to refer to them at the
same timepoint. Instead, a certain intermediate interval (arbitrarily chosen to be 0.001
units of time) is required between the assertion of a fact and the subsequent use of that
fact, even at the beginning of the plan where actions cannot begin exactly at time 0. In
TAL, effects taking place at time t are assumed to give fluents their new values exactly at
that timepoint, and those values can immediately be used. If there is some uncertainty in
the exact time when the effect takes place, one can for example explicitly state that the

352

TALplanner in IPC-2002: Extensions and Control Rules

value is unknown during the inner part of a certain interval but is known at the end of that
interval (though this is not yet implemented in TALplanner).
Changing TALplanner to use the exact PDDL2.1 semantics was out of the question,
since this would change some of the most fundamental assumptions in the planner. Instead
it was necessary to come up with a workaround that let us simulate this semantics. There
are several ways this could be done. One method would involve making minor changes to
the action definitions in order to assert the final effects of each action slightly later (0.001
units of time later, to be exact). During the competition we instead implemented a trivial
modification to the way a plan is printed: At any timepoint where something happens in the
plan (for example, where an operator is invoked), an additional delay of 0.001 is inserted.
This ensures that all plans are safe according to PDDL2.1 semantics but sometimes leads
to generating slightly worse plans than necessary.
4.8 Finding Shortest Paths
In the Rover and DriverLog domains, vehicles and/or people must travel along road networks, where different roads may have different costs (lengths) and where it is essential to
take the shortest path between any two points.
Although it is possible to define a shortest path algorithm using TALplanner’s input
language, the formulas become somewhat complicated. Finding the shortest path between
two locations in a weighted graph of places and roads seems to be useful in many domains,
and therefore such an algorithm was implemented directly in the planner.
In fact, two algorithms were implemented: One for finding the cost of the shortest
path between two given locations, and one for finding the distance to the closest location
satisfying a given formula (for example the closest location which is a reasonable destination
for a certain truck in the DriverLog domain). These functions can be called from control
rules in order to ensure that each step one takes leads to a location which is on some shortest
path to the current destination.

5. Modeling the Competition Domains
Of the eight planning domains in the third International Planning Competition, six were intended for hand-tailored planners. Except for the final domain, UMTranslog-2, all domains
exist in at least four different variations: STRIPS, Numeric (where numeric quantities are
involved), SimpleTime (where operators take constant non-unit time), and Timed (where
operator durations may depend on the actual parameters in a specific operator invocation).
TALplanner participated in all six domains, but due to lack of time for creating control
rules, we limited our participation to the STRIPS, SimpleTime, and Timed versions of the
domains.
In this section we will describe how the domains were translated from PDDL2.1 to
TALplanner, and discuss some of the control rules that were created to handle the domains
more efficiently. The main focus will be on two domains: ZenoTravel and Satellite. For these
domains we will describe most of the control rules that were used in the competition as well
as the incremental process of creating the rules, omitting only a few technical details and a
couple of complex rules that turned out to have minimal impact on planner performance and
plan quality. For the remaining domains (Depots, DriverLog, Rovers, and UMTranslog-2)
353

Kvarnström & Magnusson

we will describe the general intuitions behind our control rules, omitting the actual formulas
due to space restrictions. First, though, we will begin with a few comments on the process
of formalizing planning domains.
5.1 Using Pre-defined PDDL Domains: Half the Work in Twice the Time?
In order to create a formal description of a real-world planning domain, it is of course always
necessary to have a thorough understanding both of the domain itself and of how plans for
the domain are eventually going to be used. There are several reasons why this is required,
and most of these reasons are equally valid regardless of whether the formalization will
eventually be used as the input to a fully automated planner or to a hand-tailored planner
like TALplanner.
First, understanding the domain is required in order to determine what aspects of the
domain truly need to be modeled (as types, predicates and functions) and what aspects
can be abstracted away. For example, the standard formalization of the logistics domain
does not model distances between locations, but allows trucks to move between any two
locations in one time step. This is sufficient for some purposes, but a plan that is optimal
given this abstraction may be extremely suboptimal if actually carried out by real trucks,
which usually lack teleportation abilities. Similarly, it does not model package sizes or
weights, or cargo capacities for trucks or airplanes. Neither does it model truck drivers,
acceptable working hours for drivers, the additional costs incurred by overtime pay, or time
required for maintenance activities such as changing to winter tires once a year. Which of
these aspects need to be modeled depends very much on the particular application one has
in mind.
Second, a detailed understanding of the domain is required in order to determine what
operators are available to the planner and exactly how their preconditions and effects should
be represented within the abstract logical model of the domain.
And finally, for hand-tailored planners, the domain must be understood in order to be
able to guide a search algorithm using domain-dependent heuristics or control rules.
Usually all of these aspects of a domain are modeled at the same time, and much of the
information and knowledge about the domain that was gathered in order to find a suitable
set of predicates and operators – which is needed even for a fully automated planner – can
be reused in the development of control rules or heuristics for a hand-tailored planner.
In the planning competition, however, the task is divided into two parts: The organizers
define a set of domains using PDDL2.1, and then it is up to the competitors in the handtailored track to find suitable ways of guiding their planners. In one way, one could say
that the competitors only need to do half the work, since the formalization is already done
and only the task of finding control rules remains. Unfortunately it is still necessary to
understand the domain just as thoroughly in order to write control rules. For the more
complex domains, doing this half of the work in isolation might easily take twice the time,
since all the constraints involved in the domain have to be understood from a PDDL2.1
formalization rather than by talking to domain experts. This is especially true for the
complex UMTranslog-2 logistics domain, where a significant amount of time was spent
trying to determine exactly how packages were allowed to move and how they can be
loaded into and unloaded from various kinds of vehicle.

354

TALplanner in IPC-2002: Extensions and Control Rules

Figure 3: A ZenoTravel problem instance (STRIPS problem 6)
Another problem caused by having to use a predefined formalization of a planning
domain is that the degree of detail used in the model is determined in advance. In the real
world there would more likely be a minimum level of detail required, and anything above
this level would be acceptable. It may not seem like this should be a problem – intuitively,
adding new details to a planning problem ought to make it harder, and so it would be best
to remain at the minimum level of detail. But this is not always true, especially not when
control rules are involved. This will be seen in the timed ZenoTravel domain, for example,
where some control rules would be both simpler and more effective if it was possible to refuel
to a specific level, just like in the real world, rather than just having a simple abstract refuel
operator that unconditionally fills the tank completely.
This should not be taken as a complaint against the organization of the competition
– allowing different planners to use different formalizations would of course be completely
infeasible. Nevertheless, it does present some additional problems that are not encountered
to the same degree in real-world domains and that deserve to be mentioned here.
5.2 The ZenoTravel Domain
In the ZenoTravel domain, there are a number of aircraft that can fly people between cities.
There are five actions available: Persons may board and debark aircraft, and aircraft may fly,
zoom (fly quickly, using more fuel), and refuel. There are no restrictions on how many people
an aircraft can carry. Flying and zooming are equivalent except that zooming is generally
faster and uses more fuel. Figure 3 shows an example problem, with arrows pointing out
goal locations.
5.2.1 ZenoTravel: STRIPS
Below we show the operator definitions for the STRIPS version of the ZenoTravel domain.
These operators have been more or less directly translated from the PDDL representation.
The main difference is that the PDDL representation uses PDDL2.1 level 1, with single-

355

Kvarnström & Magnusson

step actions, which has a stricter concept of mutual exclusion than TALplanner does and
automatically enforces certain invariants, such as the fact that an aircraft should not leave
if a person is boarding, because the location of the aircraft is modified by fly and used in
the precondition of board. The TAL-C semantics used by TALplanner is more similar to
PDDL2.1 level 3 (with durative actions), where such invariant conditions must be stated
explicitly. This is done using prevail conditions, which are considered to be separate from
true pre-conditions. Note that in the STRIPS formalization fly and zoom take the same
amount of time, since only single-step actions are possible.
#operator
:precond
:prevail
:effects

board(person, aircraft, city ) :at t
[t] at(person, city ) ∧ at(aircraft, city )
[t+1] at(aircraft, city )
[t+1] at(person, city ) := false, [t+1] in(person, aircraft) := true

#operator
:precond
:prevail
:effects

debark(person, aircraft, city ) :at t
[t] in(person, aircraft) ∧ at(aircraft, city )
[t+1] at(aircraft, city )
[t+1] in(person, aircraft) := false, [t+1] at(person, city ) := true

#operator fly(aircraft, city1 , city2 , flevel1 , flevel2 ) :at t
:precond [t] at(aircraft, city1 ) ∧ fuel-level(aircraft, flevel1 ) ∧ next(flevel2 , flevel1 )
:effects
[t+1] at(aircraft, city1 ) := false, [t+1] fuel-level(aircraft, flevel1 ) := false,
[t+1] at(aircraft, city2 ) := true, [t+1] fuel-level(aircraft, flevel2 ) := true
#operator zoom(aircraft, city1 , city2 , flevel1 , flevel2 , flevel3 ) :at t
:precond [t] at(aircraft, city1 ) ∧ fuel-level(aircraft, flevel1 ) ∧
next(flevel2 , flevel1 ) ∧ next(flevel3 , flevel2 )
:effects
[t+1] at(aircraft, city1 ) := false, [t+1] fuel-level(aircraft, flevel1 ) := false,
[t+1] at(aircraft, city2 ) := true, [t+1] fuel-level(aircraft, flevel3 ) := true
#operator
:precond
:prevail
:effects

refuel(aircraft, city , flevel, flevel1 ) :at t
[t] fuel-level(aircraft, flevel) ∧ next(flevel, flevel1 ) ∧ at(aircraft, city )
[t+1] at(aircraft, city )
[t+1] fuel-level(aircraft, flevel) := false, [t+1] fuel-level(aircraft, flevel1 ) := true

After translating the operator definitions, it is time to create a set of control rules. There
are basically two ways of doing this: First, one can sit down and think about suitable
properties for a plan, and then write control rules that ensure that these properties will
hold. Second, one can instruct the planner to show each branch that is explored in the
search tree, and by observing the output one can identify “obviously stupid” choices made
by the planner, such as choosing an action instance that inevitably leads to backtracking
or performing actions that are useless given the goals. Control rules can then be written to
prevent these branches of the tree from being explored. Both of these approaches will be
covered here.
We begin with the first method, attempting to find a number of reasonable control rules
simply by thinking about the properties of the ZenoTravel domain. Given some experience
from other planning domains, this is in fact quite easy. For example, in many domains
there are certain goals such that once they are satisfied, one should never allow them to be
356

TALplanner in IPC-2002: Extensions and Control Rules

destroyed. In the ZenoTravel domain, people who are at their destinations never need to
board an aircraft, which gives rise to the following control rule:
#control :name ”only-board-when-necessary”
[t] ¬in(person, aircraft) ∧ [t+1] in(person, aircraft) →
∃city , city2 [ [t] at(person, city ) ∧ goal(at(person, city2 )) ∧ city 6= city2 ]
This TAL formula states that if we have a state transition from the person not being in the
aircraft at time t to the person being in the aircraft at time t + 1, (that is, if the person just
boarded the aircraft), then there must be a reason why this is allowed: The person must
be in a certain city and there must be a goal that the person should be in another city.
As noted previously control formulas can usually be written in many different forms.
For example, it would have been equally valid to state that if a person is at a city (and
therefore not in an aircraft), and is not required to be somewhere else, then at the next
timepoint that person should still not be on board an aircraft:
#control :name ”only-board-when-necessary”
[t] at(person, city ) ∧ ¬∃city2 [ goal(at(person, city2 )) ∧ city 6= city2 ] →
[t+1] ¬in(person, aircraft)
Note that although it may at first glance appear that a planner would have to be extraordinarily stupid to destroy goals that have already been satisfied, there are also many cases
where temporarily destroying a goal is necessary in order to satisfy other goals. For example, if there is a goal that a certain aircraft should be at a certain location and it has already
reached that destination, it might still have to fly a number of people to their destinations
before it can return to its own destination.
Another natural idea (since aircraft do not follow predetermined routes in ZenoTravel,
as they usually do in real life) would be to say that people should only debark when they
have reached their final destination:
#control :name ”only-debark-when-in-goal-city”
[t] in(person, aircraft) ∧ [t+1] ¬in(person, aircraft) →
∃city [ [t] at(aircraft, city ) ∧ goal(at(person, city )) ]
There is a potential problem with this rule: In some cases an optimal plan might require a
number of people to debark one plane and then board a number of other planes, which could
fly them to their destination concurrently, and this is strictly forbidden by only-debark-whenin-goal-city. This is a common problem that occurs for many planning domains, and it is
up to the user to determine what to do depending on the requirements of the application
for which the planner is being used.
There are a number of possible choices: We could ignore this problem and accept suboptimal plans, skip the rule completely and let the planner search through a vastly greater
search space in order to find a plan which is guaranteed to be optimal, or as a compromise,
attempt to create a weaker rule that does cut down the search space to some degree but
gives optimal or closer-to-optimal plans. During the planning competition the conditions
were somewhat artificial and were not clearly stated – would it be beneficial for a planner
to spend ten times as much effort finding a plan if this plan was only five percent better, on
average? We guessed that this would not be the case, and consequently we chose to include
the control rule as stated above.
357

Kvarnström & Magnusson

In the future, a better solution would most likely be to prefer those plans where a person
does not debark before reaching his destination but still allow other plans. This alternative
will be discussed in more detail in the conclusions.
Given these two rules, we might now continue with the second approach to finding
control rules. We run TALplanner on a simple problem instance and consider the operator
sequences the planner examines during the depth-first search process. This is the beginning
of such a sequence for the problem instance in Figure 3. The complete plan generated by the
planner contains 123 operators and requires 60 time steps. It is shown here in the IPC-2002
STRIPS result format where the timepoint at which an action is invoked is followed by the
action instance.
0:
0:
1:
1:
2:
2:
3:
3:

(board person4 plane2 city1)
(board person5 plane1 city2)
(fly plane1 city2 city0 fl5 fl4)
(fly plane2 city1 city0 fl3 fl2)
(board person1 plane1 city0)
(board person2 plane2 city0)
(fly plane1 city0 city1 fl4 fl3)
(fly plane2 city0 city1 fl2 fl1)

4:
4:
5:
5:
6:
6:
7:
7:

(debark person2 plane2 city1)
(debark person5 plane1 city1)
(fly plane1 city1 city0 fl3 fl2)
(fly plane2 city1 city0 fl1 fl0)
(fly plane1 city0 city1 fl2 fl1)
(refuel plane2 city0 fl0 fl1)
(fly plane1 city1 city0 fl1 fl0)
(fly plane2 city0 city1 fl1 fl0)

8: (refuel plane1 city0 fl0 fl1)
8: (refuel plane2 city1 fl0 fl1)
9: (fly plane1 city0 city1 fl1 fl0)
9: (fly plane2 city1 city0 fl1 fl0)
10: (refuel plane1 city1 fl0 fl1)
11: (fly plane1 city1 city0 fl1 fl0)
11 : (refuel plane2 city0 fl0 fl1)
...

The beginning of the operator sequence appears to be reasonable, but after time 4, airplanes
seem to be flying around randomly. There are no control rules guiding them, so apparently
it was mainly luck that caused the planes to find reasonable cities to fly to at time 1 and 3.
To make airplanes more goal-directed, we identify three important reasons why an airplane
should move from city to city2: that the goal asserts that the aircraft must end up in city2
when the plan is complete, that one of its passengers wants to go to city2, or that there is a
person waiting to be picked up by an airplane in city2. The following rule formalizes these
three intuitions:
#control :name ”planes-always-fly-to-goal”
[t] at(aircraft, city ) ∧ [t+1] ¬at(aircraft, city ) →
∃city2 [ [t+1] at(aircraft, city2 ) ∧
(goal(at(aircraft, city2 )) ∨
∃person [ [t] in(person, aircraft) ∧ goal(at(person, city2 )) ] ∨
∃person [ [t] at(person, city2 ) ∧ goal(¬at(person, city2 )) ]) ]
With these control rules, TALplanner can quickly produce a set of plans for the 20 “handcoded” problems from the IPC-2002 competition, and although the plans will not be optimal, they will not be nearly as bad as the example given above. Together, the plans require
a total of 7164 operators and 618 time steps. The plan for the example in Figure 3 requires
20 operators and 7 time steps.
Nevertheless, there are still some improvements that can be made. The first criterion
is too admissible: It allows a plane to visit its destination even if it still needs to pick up
or drop off passengers. One way of preventing this would be to add the condition that all
passengers must have reached their destinations:
#define [t] all-persons-arrived:
∀person, city [ goal(at(person, city )) → [t] at(person, city ) ]

358

TALplanner in IPC-2002: Extensions and Control Rules

#control :name ”planes-always-fly-to-goal”
[t] at(aircraft, city ) ∧ [t+1] ¬at(aircraft, city ) →
∃city2 [ [t+1] at(aircraft, city2 ) ∧
([t] all-persons-arrived ∧ goal(at(aircraft, city2 )) ∨
∃person [ [t] in(person, aircraft) ∧ goal(at(person, city2 )) ] ∨
∃person [ [t] at(person, city2 ) ∧ goal(¬at(person, city2 )) ]) ]
This improves plan quality slightly, and TALplanner now requires 7006 operators and 575
time steps. But the new control rule is in fact too strict, which can be seen in the following
plan tail for handcoded STRIPS problem number 3:
14:
14:
14:
14:
15:
15:
15:

(fly plane2 city4 city7 fl2 fl1)
(fly plane4 city8 city9 fl3 fl2)
(refuel plane1 city6 fl2 fl3)
(refuel plane3 city9 fl4 fl5)
(debark person24 plane4 city9)
(debark person28 plane4 city9)
(debark person34 plane2 city7)

15:
15:
15:
15:
16:
16:

(refuel plane1 city6 fl3 fl4)
(refuel plane2 city7 fl1 fl2)
(refuel plane3 city9 fl5 fl6)
(refuel plane4 city9 fl2 fl3)
(fly plane1 city6 city8 fl4 fl3)
(fly plane3 city9 city4 fl6 fl5)

In this example, plane1 and plane3 had to wait until all passengers had debarked from
several other planes until they could go to their final destinations, even though we can
clearly see that there was no real reason for them to wait, because all potential passengers
had already been picked up and plane1 and plane3 already had enough fuel. We once again
alter the control rule according to this new insight: A plane can go to its final destination
if all passengers on board the plane are headed towards the same destination and there is
no person left to be picked up (that is, all persons have already arrived or are currently on
board planes).
#define [t] all-persons-arrived-or-in-planes:
∀person, city [ goal(at(person, city )) → [t] at(person, city ) ∨ ∃aircraft [ in(person, aircraft) ] ]
#control :name ”planes-always-fly-to-goal”
[t] at(aircraft, city ) ∧ [t+1] ¬at(aircraft, city ) →
[t+1] at(aircraft, city2 ) ∧
((goal(at(aircraft, city2 )) ∧ [t] all-persons-arrived-or-in-planes ∧
∀person [ [t] in(person, aircraft) → goal(at(person, city2)) ]) ∨
∃person [ [t] in(person, aircraft) ∧ goal(at(person, city2 )) ] ∨
∃person [ [t] at(person, city2 ) ∧ goal(¬at(person, city2 )) ])]
This yields another minor improvement, and TALplanner now requires 6918 operators and
564 time steps. For the example used above, the end of the plan now looks as follows:
14:
14:
14:
14:

(fly plane1 city6 city8 fl2 fl1)
(fly plane2 city4 city7 fl2 fl1)
(fly plane4 city8 city9 fl3 fl2)
(refuel plane3 city9 fl4 fl5)

15:
15:
15:
15:

(debark person24 plane4 city9)
(debark person28 plane4 city9)
(debark person34 plane2 city7)
(fly plane3 city9 city4 fl5 fl4)

We once more study the plans generated by the current set of rules and quickly identify
another obvious problem: Any number of airplanes may fly to the same location to pick up
the same person. Once again, it is necessary to find a reasonable balance between finding
optimal plans and finding plans quickly. In the contest, we attempted to find a high quality
359

Kvarnström & Magnusson

(but probably non-optimal) plan as quickly as possible. This was done by ensuring that no
more than one airplane may go to any given place at the same time, if the sole purpose for
going there is to pick up a person who is waiting:
#control :name ”planes-always-fly-to-goal”
[t] at(aircraft, city ) ∧ [t+1] ¬at(aircraft, city ) →
∃city2 [ [t+1] at(aircraft, city2 ) ∧
((goal(at(aircraft, city2 )) ∧ [t] all-persons-arrived-or-in-planes ∧
∀person [ [t] in(person, aircraft) → goal(at(person, city2 )) ]) ∨
∃person [ [t] in(person, aircraft) ∧ goal(at(person, city2 )) ] ∨
∃person [ [t] at(person, city2 ) ∧ goal(¬at(person, city2 )) ] ∧
¬∃aircraft2 [ [t+1] at(aircraft2, city2) ∧ aircraft2 6= aircraft ])]
This rule provides a major improvement, and the complete set of plans now requires 5075
operators and 434 time steps.
So far, we have controlled where airplanes fly, when people board an airplane, and when
they debark. There are no rules governing refueling, and a quick look at a plan for one of
the larger problem instances reveals that whenever an aircraft has nothing else to do, it will
refuel. This seems a little bit wasteful, but we are satisfied with adding a rule stating that
airplanes must only refuel when their tanks are empty. This rule is not perfect, since an
airplane may miss an opportunity to “pre-emptively” refuel and it can still refuel one fuel
level even if it is not going to fly, but it does provide a significant improvement, bringing
the number of operators down to 4234. The number of time steps is still 434.
A few minor adjustments were made to these rules before they were used in the competition. These adjustments include a modification to only-board-when-necessary to ensure
that a person who must travel from city to city2 will choose a plane that already needs
to visit both city and city2 , if this is possible, since this is less likely to increase the total
number of flights.
One final change is prompted by the fact that the intended differences in timing between
fly and zoom cannot be modelled correctly in the STRIPS version of the domain. Since
all operators must take the same amount of time, the only difference between these two
operators is that zoom uses twice as much fuel. Although it would have been possible to
add a control rule ensuring that zoom was not used, it was easier to simply remove the
zoom operator from the domain definition.
5.2.2 ZenoTravel: SimpleTime
The SimpleTime version of ZenoTravel is quite similar to the STRIPS version, the only
difference being that actions may have non-unit duration and that certain preconditions
must hold throughout the execution of an action. The TALplanner operator definitions are
changed accordingly. For example, the board and fly operators can be changed as follows:
#operator board(person, aircraft, city ) :at t
:precond [t] at(person, city ) ∧ at(aircraft, city )
:prevail
[t+1, t+20] at(aircraft, city )
:duration 20
:effects
[t+1] at(person, city ) := false, [t+20] in(person, aircraft) := true

360

TALplanner in IPC-2002: Extensions and Control Rules

Figure 4: A ZenoTravel problem instance (SimpleTime problem 3)
#operator fly(aircraft, city1 , city2 , flevel1 , flevel2 ) :at t
:precond [t] at(aircraft, city1 ) ∧ fuel-level(aircraft, flevel1 ) ∧ next(flevel2 , flevel1 )
:duration 180
:effects
[t+1] at(aircraft, city1 ) := false, [t+1] fuel-level(aircraft, flevel1 ) := false,
[t+180] at(aircraft, city2 ) := true, [t+180] fuel-level(aircraft, flevel2 ) := true
If we run the planner on a set of SimpleTime problem instances, we get almost immediate
results: The planner claims that there is no plan for any of the instances. The reason for
this is, of course, that the control rules must be satisfied in any valid plan, and those rules
were designed with the underlying assumption that actions had unit duration. For example,
consider planes-always-fly-to-goal, which states that if a plane leaves a city at time t, it should
be at a meaningful destination at t+1. When the fly action is invoked the plane must be
at some city city1 , but beginning at the next time step there will be an interval where the
aircraft is not present in any city at all, until it finally arrives in city2 180 time steps later.
In other words, planes-always-fly-to-goal now ensures that the fly operator cannot be used
at all, which is not quite what was originally intended.
One way of solving this problem would be to alter planes-always-fly-to-goal to say that if
a plane leaves a city at time t, it should be at a meaningful destination at t+180. Unfortunately, the duration of the flight would then be encoded directly in the control rule instead
of only in the operator, and so it would not work in the Timed version, where operators
have variable durations – in fact, it would not even work in SimpleTime, because the zoom
operator must also be taken into account.
Instead, the domain model is augmented with a new fluent flying-to(aircraft, city) which
keeps track of whether a plane is flying, and if so, what its destination is. To ensure that this
fluent is kept up-to-date, the following is added to the effects of the fly and zoom operators:
[t+1] flying-to(aircraft, city2 ) := true, [t+180] flying-to(aircraft, city2 ) := false // for fly
[t+1] flying-to(aircraft, city2 ) := true, [t+100] flying-to(aircraft, city2 ) := false // for zoom
The planes-always-fly-to-goal rule above can now be changed as follows, stating that if an
aircraft ceases to be at city , then it must be flying to a reasonable destination:
#control :name ”planes-always-fly-to-goal”
[t] at(aircraft, city ) ∧ [t+1] ¬at(aircraft, city ) →
∃city2 [ [t+1] flying-to(aircraft, city2 ) ∧ . . . ]
The same problem arises for boarding, and a new fluent boarding(person, aircraft) is added
and used whenever necessary. Given these changes, the following are the first steps of the
361

Kvarnström & Magnusson

plan generated by TALplanner for the problem instance in Figure 4, shown in the IPC-2002
timed result format where the timepoint at which an action is invoked is followed by the
action instance and the duration of the action:
0: (board person1 plane1 city0) [20]
20: (fly plane1 city0 city1 fl4 fl3) [180]
20: (zoom plane1 city0 city1 fl4 fl3 fl2) [100]
Intuitively, flying and zooming plane1 at the same time should be impossible, but we have
forgotten to specify this to the planner. Both actions have their preconditions satisfied at
time 20, there are no prevail conditions, and the effects of the actions do not contradict
each other since they take place at different timepoints: fly ends at time 200, while zoom
ends at time 120.
There are several ways of specifying that fly and zoom are mutually exclusive. For
example, it would be possible to introduce an interval effect stating that flying-to(aircraft,
city2 ) must hold throughout the inner execution intervals of these actions, and become false
at the end of each action:
[t+1,t+179] flying-to(aircraft, city2 ) := true, [t+180] flying-to(aircraft, city2 ) := false // for fly
[t+1,t+ 99] flying-to(aircraft, city2 ) := true, [t+100] flying-to(aircraft, city2 ) := false // zoom
It would also be possible to use a semaphore resource: An aircraft-specific resource with an
initial value of 1, which can be borrowed exclusively by the fly and zoom actions. When
one of these solutions is used, TALplanner finally rewards us with a short and correct plan:
0: (board person1 plane1 city0) [20]
20: (fly plane1 city0 city1 fl4 fl3) [180]
200: (board person3 plane1 city1) [20]
200: (debark person1 plane1 city1) [30]
230: (fly plane1 city1 city0 fl3 fl2) [180]
410: (debark person3 plane1 city0) [30]
;; Plan length 6, maxtime 440
Can it be improved? Remember that the STRIPS version never made use of the zoom
operator. But in the SimpleTime version, flying takes 180 time steps and uses one unit
of fuel, zooming takes 100 time steps and uses two units of fuel, and refueling one unit
takes 73 time steps. 180 + 73 is more than 100 + 2 · 73 and therefore we have the opposite
situation: zoom is always better than fly. Commenting out the unwanted fly operator yields
the following plan:
0: (board person1 plane1 city0) [20]
20: (zoom plane1 city0 city1 fl4 fl3 fl2) [100]
120: (board person3 plane1 city1) [20]
120: (debark person1 plane1 city1) [30]
150: (zoom plane1 city1 city0 fl2 fl1 fl0) [100]
250: (debark person3 plane1 city0) [30]
;; Plan length 6, maxtime 280

362

TALplanner in IPC-2002: Extensions and Control Rules

5.2.3 ZenoTravel: Timed
The Timed version further complicates the timing of the actions. Boarding and disembarking times are constant but problem-specific and are defined in the respective problem
definition as two new functions, boarding-time and debarking-time. Refueling always fills the
plane to its maximum capacity, but consumes time relative to the amount of fuel received
and the refuel-rate of the aircraft. Each aircraft also has a fast-speed and a slow-speed with
corresponding fast-burn and slow-burn fuel consumption. The distances between cities are
specified using the distance(city1, city2 ) function.
In the Timed version, operator durations have to be correctly calculated with a precision
of three decimals, prompting the TALplanner changes discussed in Sections 4.5 and 4.6.
Once these extensions to TALplanner had been implemented, few changes were needed to
transform the SimpleTime domain to the Timed version.
The most important difference was perhaps the fact that depending on the speed and fuel
consumption values defined in each problem and the situation where the operator is used, it
is sometimes better to use the fly operator and sometimes better to use the zoom operator,
unlike the STRIPS version where fly was always better and the SimpleTime domain where
zoom was always better.
So when is zooming better than flying? It may seem like it would be easy to answer
this question, given that we are only interested in minimizing time: Just check whether
refueling the aircraft sufficiently to be able to zoom, followed by zooming to the destination,
would be faster than only refueling enough to be able to fly and then flying more slowly to
the destination. This is handled by the first clause in use-fly-instead-of-zoom below. The
precondition of fly is then altered to require that use-fly-instead-of-zoom be true, and the
precondition of zoom requires that use-fly-instead-of-zoom be false. If we had been interested
in minimizing a combination of time and fuel usage, then this could also have been taken
into account.
This is not quite sufficient to handle all problems, though. An airplane has a maximum
fuel capacity, so if its destination is too distant, it may not be able to zoom. This is handled
by the second clause in use-fly-instead-of-zoom.
Yet another problem is that it is not possible to tie one refueling action to each flight,
as one would expect in the real world. There are two reasons for this problem.
First, airplanes may already have some fuel in the initial state, so in some situations a
plane might zoom to its destination without incurring any additional cost, again assuming
that the time required for executing the plan is the only metric being used – the plane
already had enough fuel anyway and never had to refuel.
Second, unlike the SimpleTime version, an airplane cannot refuel “just enough” – the
refuel operator always fills the tank completely. This change was most likely introduced in
order to make the planning task easier by reducing the number of possible actions to choose
from (for example, a planner that needs to create all ground instances of each operator
might have some trouble if the refuel operator would take the amount of fuel as a floating
point argument). But despite the probable intention behind this change, it introduces new
problems for our control formulas. If a plane’s tank is half full and this is enough fuel to
zoom from A to B, it might then have to fill the entire tank before continuing to C, while
if it used the fly operator, it might be able to continue to C without refueling at all. This

363

Kvarnström & Magnusson

means that one would have to take all possible future flights into account when determining
whether to fly or zoom. If the domain had been modeled in more detail, this problem would
not have existed.
Given these two complications, guaranteeing an optimal or near-optimal plan using a
control rule is not easy, which is indeed only to be expected. For the competition we decided
to be satisfied with a heuristic compromise, adding a third clause to use-fly-instead-of-zoom
ensuring that if zooming would require refueling immediately but flying would not, the fly
operator would be used.
// Fly is (probably) better than zoom if:
#define [t] use-fly-instead-of-zoom(aircraft, city1, city2):
// If fly is faster wrt speed and refueling.
([t] (10000 / slow-speed(aircraft) + 10000 * slow-burn(aircraft) / refuel-rate(aircraft)) <
(10000 / fast-speed(aircraft) +10000 * fast-burn(aircraft) / refuel-rate(aircraft))) ∨
// If zoom is impossible across the given distance.
([t] distance(city1 , city2 ) * fast-burn(aircraft) > capacity(aircraft)) ∨
// If zoom has to refuel immediately but fly does not.
([t] fuel(aircraft) >= distance(city1 , city2 ) * slow-burn(aircraft) ∧
fuel(aircraft) < distance(city1 , city2 ) * fast-burn(aircraft))
5.2.4 ZenoTravel: Discussion
Finding control rules that yield good (but usually suboptimal) plans is not too difficult in
the ZenoTravel domain. There are no risks involved in flying a plane to pick up passengers
since all the passengers will always fit in the plane and refueling is possible in any city. In
other words, it is not really possible to get stuck while looking for a solution. Also, since
the graph of cities is fully connected, no route planning is necessary.
A fourth version of ZenoTravel, called Numeric, was available in the contest but due to
lack of time we decided not to compete in this domain.
Among other things, the numeric version contains an additional constraint on the number of passengers that an aircraft can carry. At a first glance, this constraint may seem to
introduce new problems. However, it is only enforced in the zoom operator, and since the
numeric domain does not make use of durational operators, it suffers from the same problem
as the STRIPS domain: The zoom operator consumes more fuel and limits the number of
passengers, but does not deliver any advantages because it is no faster than flying.
The real difficulty in the Numeric version comes from the use of problem-specific metrics
that measure the quality of a solution. For example, for one problem the planner may be
required to minimize total-time + 3 * total-fuel-used, while for another problem it may be
required to minimize total-time only. Until now, we have usually been satisfied with finding
plans of good but not optimal quality, and this has been done by tuning control rules,
for example by introducing the use-fly-instead-of-zoom function to determine whether fly or
zoom should be used, as discussed above. This tuning is naturally done on the domain level
rather than the problem level. An optimizing version of TALplanner is under development.

364

TALplanner in IPC-2002: Extensions and Control Rules

Figure 5: A Depots problem instance (STRIPS problem 7)
5.3 The Depots Domain
The Depots domain (illustrated in Figure 5) contains locations, trucks, hoists, movable
crates, and pallets whose locations are fixed. Trucks move crates between any two locations
and can carry any number of crates at the same time. Hoists are distributed among the
locations and load crates into trucks or stack crates on surfaces (pallets or other crates).
The goal is always to bring the crates into a certain configuration of stacks, where each
stack is placed on a specific pallet.
STRIPS. The Depots domain is a combination of two other well-known planning domains,
the logistics domain and the blocks world. Therefore it seems natural to start by taking a
look at existing control rules for those two domains, and to see whether those rules can be
combined easily or whether more complex rules are required due to interactions between
moving and stacking blocks.
We begin with the blocks world part of the problem. The unbounded blocks world was
used as a benchmark domain in IPC-2000, and there TALplanner used a modified version
of the rules in Bacchus and Kabanza (2000) which ensure that the planner only adds blocks
to “good towers”, stacks that are already in their final position and will not have to be
dismantled later in order to remove a block at a lower level. Can these rules be reused in
the Depots domain? One prerequisite is the availability of temporary storage for all crates,
since in the worst case every single stack of crates must be torn down completely before it
is possible to start stacking crates on top of each other. Fortunately, although there is only
a limited number of pallets, trucks can (somewhat counter-intuitively) contain any number
of crates, and the planner can use them as storage. Only minor changes were required in
order to handle the two separate types of surfaces: Pallets and crates.
Continuing with the logistics part, one simple rule can be reused from the standard
logistics domain: Only unload a crate at its goal location. Its dual rule, “only load a crate
if it needs to be moved”, is not required. The blocks world rules ensure that a hoist does
not lift a block unless it needs to be moved, and therefore it is already impossible to load
such blocks into a truck.
It remains to ensure that vehicles only drive to those locations where they can be of use.
In the standard logistics domain, a truck can drive to another location if there is a package
365

Kvarnström & Magnusson

Figure 6: A DriverLog problem instance (STRIPS problem 5)
that needs to be picked up or delivered there, but due to the use of stacks of crates in the
depots domain, the rule must be modified: A vehicle may drive to a location if (1) there is
a crate there that must be moved to another location, (2) there is a crate there that must
be stacked differently, or (3) there is a crate in the truck that needs to be at the location,
its destination is ready, and there is no other crate that should also be at the same location
that the truck has not yet picked up.
SimpleTime. In the SimpleTime version, lifting and dropping crates still takes one unit of
time, loading takes three units, unloading four, and driving ten. A few changes were made
to ensure mutual exclusion. For example, hoists can only lift one crate at a time. Also, a
driving-to fluent was introduced to keep track of where trucks are headed, similar to flying-to
in ZenoTravel.
Timed. In the Timed domain, the time required for loading and unloading a crate depends on how powerful the hoist is and on the weight of the crate. The time required for
driving between two locations depends on the speed of the truck and the distance between
the locations. Again, only minor changes were required to handle the domains, although
higher quality plans could certainly have been produced by taking timing into account when
determining which hoists and trucks to use.
5.4 The DriverLog Domain
DriverLog (illustrated in Figure 6) is yet another logistics domain, this time introducing
the concept of truck drivers and road maps. A number of packages are transported between
locations by trucks. There are two sets of routes connecting the locations: Links, where
trucks travel, and paths, which drivers can walk along when not driving a truck. A truck
can only have one driver at a time but can load as many packages as is needed.
STRIPS. Several control rules used in previous logistics domains were useful for DriverLog
with minor modifications. For example, packages should only be loaded into trucks if they
need to be moved, and should not be unloaded until they have reached their final destination.
On the other hand, a number of changes were necessary due to the use of road maps.
Most importantly, vehicles were previously only allowed to drive to locations that were immediately useful because there were packages to be picked up or delivered. In the DriverLog
366

TALplanner in IPC-2002: Extensions and Control Rules

domain there may only be direct roads between some locations (specified by a predicate
link(from, to)), and a truck may have to move through several intermediate locations in
order to reach its destination. Consequently the control rules must be relaxed to allow
trucks to visit locations that are not useful in themselves. Nevertheless, some degree of
goal-directedness is still required. One possible method is to identify for each vehicle the
set of locations where the vehicle might be useful, and to require that it chooses one such
location and then takes the shortest path to its chosen destination. This method was used
in the competition with the help of the built-in shortest path algorithm discussed in Section 4.8 and a control rule stating that each step (each invocation of drive or walk) must
decrease the distance to the current destination. The following definitions will be explained
below:
#define [t] reasonable-truck-location(truck, location):
// Omitted due to space constraints
#distfeature driving-distance-between(from, to) :domain integer :link link
#mindistfeature driving-distance-to-location-satisfying-formula
:distfeature driving-distance-between :domain integer
#define [t] driving-distance-to-reasonable-destination(truck, location):
driving-distance-to-location-satisfying-formula(location, to,
[t] reasonable-truck-location(truck, to))
A boolean fluent reasonable-truck-location(truck, loc) is defined in terms of a logic formula,
which specifies whether the given location is a reasonable destination for a given truck at the
timepoint when it is evaluated. The driving-distance-between function accesses the shortest
path algorithm to find the length of the shortest path between from and to, given that
the road links are specified by the link predicate. The driving-distance-to-location-satisfyingformula function accesses another version of the shortest path algorithm and is used in
driving-distance-to-reasonable-destination in order to find the shortest distance from location
to any location to that satisfies reasonable-truck-location. Since all links have the same cost,
it is then sufficient to require that whenever a truck moves, its driving-distance-to-reasonabledestination decreases.
Further changes were required due to the use of drivers. There may not be drivers for
all trucks, so packages should not be loaded into a truck until the planner knows the truck
will have a driver. Drivers should not disembark if there are still packages in the truck, or
if there is a goal that the truck must be somewhere else. Drivers may have to walk along
paths in order to reach a truck, so just like trucks, drivers must select one useful destination
and then take the shortest path to their chosen destinations.
Additional control rules ensure that multiple trucks do not choose the same destination
unnecessarily, and that multiple drivers do not choose to walk to the same location.
SimpleTime. In the SimpleTime version, loading and unloading objects takes two units
of time, driving takes ten units, and walking takes twenty units. The operators are changed
accordingly, and a going-to fluent is introduced to keep track of drivers and trucks that are
moving towards a new location but have not yet arrived. A few minor adjustments must
be made to the control rules.
Timed. In the Timed version, the time required to walk or drive between two locations is
367

Kvarnström & Magnusson

determined by a pair of functions specified in each problem instance. Since individual road
segments can have different lengths, the method we used to ensure drivers and trucks used
the shortest path to their current destination is no longer sufficient, and must be modified
slightly. Other than this, there are no major changes for the Timed version.
5.5 The Rovers Domain
The Rovers domain simulates a simplified planetary exploration expedition. A lander vessel
carries a number of rovers to the planet surface and provides a communication link back to
Earth. Each rover has a subset of the general capabilities, retrieving soil samples, retrieving
rock samples and capturing images using cameras that support different imaging modes.
The cameras are mounted on the rovers, as are storage compartments, one for each rover,
which can hold one soil sample or one rock sample. Data from a sample must be sent to
the lander by a communication link. All missions revolve around navigating waypoints on
the planets surface to collect samples and take images of specified objectives that are only
visible from certain waypoints. The terrain may prevent rovers from going directly between
two waypoints and different rovers handle different terrain so a list of routes each rover can
use is provided.
STRIPS. Following a control scheme similar to the one used in DriverLog, we limit the
movements of rovers to locations where they can perform some useful action like collecting
a rock sample or capturing an image. The problem of finding a path from one waypoint to
another is also solved in the same way as in DriverLog, except that each rover has its own
set of routes between waypoints.
SimpleTime. The changes in the SimpleTime version are trivial: Operator durations are
changed, a few mutual exclusion relations need to be enforced, and a new fluent calibrating(camera) keeps track of whether a certain camera is being calibrated.
Timed. The Timed version introduces the concept of energy, where each rover has a limited
amount of energy and each action it does consumes some of the energy. This is similar to the
use of fuel in the ZenoTravel domain, but there is also a major difference: The rovers have
been equipped with solar panels that recharge the rover, but only some of the waypoints
that a rover can go to are directly exposed to the sun, which is a requirement for the solar
panels to work. The airplanes in the ZenoTravel domain can refuel anywhere, and so fuel
usage is only relevant in terms of minimization of resource usage, whereas a rover that uses
its energy unwisely can get stuck in the shade, unable to do anything or go anywhere. To
prevent this we can either let the planner backtrack and search for a better plan, or we
can introduce stricter rules that keep energy levels in mind when deciding what a rover is
allowed to do. The latter approach is taken below.
The critical point is when a rover does not have enough energy to reach a waypoint in
the sun and recharge. Using the shortest path algorithm it is possible for a control rule to
determine the distance to the closest waypoint that is exposed to the sun. In addition to all
waypoints that were previously allowed, it is also reasonable for a rover to go to a waypoint
that is exposed to the sun if the rover does not have enough energy to perform an action
and then go recharge, or if there do not exist any other waypoints that are both affordable
and reasonable to visit.

368

TALplanner in IPC-2002: Extensions and Control Rules

Figure 7: A Satellite problem instance (STRIPS problem 4)
5.6 The Satellite Domain
In the Satellite domain a number of satellites orbit the Earth, each equipped with a set of
scientific imaging instruments. The satellites turn in space, targeting stars, planets and interesting phenomena to capture images of them using different instrument operation modes.
These modes can include regular or infrared imaging and spectrographic or thermographic
readings but are different for each problem. The planner’s task is to schedule a series of observations so that the satellites are used efficiently. Figure 7 shows a small example problem
instance, with arrows showing the directions in which the satellites are pointing.
Directions are not represented as explicit coordinates. Instead, satellites can turn to
a new direction by giving the turn to operator an argument specifying the star, planet or
phenomenon that the satellite should point to. Instruments first need to be activated using
switch on, then calibrated at a calibration target with the calibrate operator before they
can capture images using take image. Each satellite has only enough power to operate one
instrument at a time, so switching active instruments is always initiated by the switch off
operator to deactivate the first instrument.
5.6.1 Satellite: STRIPS
Since the task consists of collecting a number of images, we begin by restricting the use of
take image to images that are mentioned in the goal.
#control :name ”only-take-pictures-of-goals”
[t] ¬have image(direction, mode) ∧ [t+1] have image(direction, mode) →
goal(have image(direction, mode))
The next step is to restrict the directions in which satellites turn to those that may actually help in collecting the images. The task is split into a control rule, only-point-ingoal-directions, and a definition of goal directions. A satellite is allowed to turn towards a
direction to take a picture, to calibrate an instrument or if a goal specifies that the satellite

369

Kvarnström & Magnusson

should point in the direction and there is no more work left to do.
#define [t] goal direction(satellite, direction):
[t] take image possible(satellite, direction) ∨
∃instrument [
[t] power on(instrument) ∧ ¬calibrated(instrument) ∧
[t] calibration target(instrument, direction) ∧ on board(instrument, satellite) ] ∨
goal(pointing(satellite, direction)) ∧ [t] all images collected
The take image possible function checks not only if an image is to be collected but also
that it has not already been taken and that the satellite has the necessary instrumentation
ready. If the active instrument is not calibrated, the satellite may first have to turn towards
another direction and calibrate it.
#define [t] take image possible(satellite, direction):
∃mode [ goal (have image(direction, mode)) ∧
[t] ¬have image(direction, mode) ∧
∃instrument [
[t] power on(instrument) ∧ calibrated(instrument) ∧
[t] on board(instrument, satellite) ∧ supports(instrument, mode) ]]
The switch on and switch off operators are still not regulated by control rules and the
planner quickly takes up the habit of repeatedly flipping the power to different instruments
on and off. Once an instrument has been powered on and calibrated, using it as much as
possible before switching to another instrument seems reasonable. A usefulness function,
putting a value on the usefulness of a particular instrument, helps decide which instrument
to power on first.
#define [t] usefulness(instrument):
value(t, $sum(<mode>, [t] supports(instrument, mode) ∧ mode needed for goal(mode), 1))
#define [t] mode needed for goal(mode):
∃direction [ goal(have image(direction, mode)) ∧ [t] ¬have image(direction, mode) ]
Add one to the usefulness score of an instrument for each imaging mode that it supports
and that is needed in some goal. This score is then used in a control rule that chooses a
satellite’s most useful instrument, if it has any.
#control :name ”use-the-most-useful-instrument”
[t] ¬power on(instrument) ∧ [t+1] power on(instrument) →
[t] usefulness(instrument) > 0 ∧
¬∃satellite, instrument2 [
[t] usefulness(instrument2 ) > usefulness(instrument) ∧
[t] on board(instrument, satellite) ∧ on board(instrument2 , satellite) ]
Switching off an instrument is only allowed if the instrument is no longer required.
#control :name ”don’t-switch-instrument-off-if-you-don’t-have-to”
[t] power on(instrument) ∧ [t+1] ¬power on(instrument)) →
[t] ¬∃mode [ supports(instrument, mode) ∧ mode needed for goal(mode) ]

370

TALplanner in IPC-2002: Extensions and Control Rules

We have run out of more or less obvious improvements, but analyzing the planner output
reveals one remaining inefficiency: The satellites often simultaneously decide to turn to the
same direction because a picture needs to be taken in that direction, despite the fact that
only one satellite needs to take the picture. This is similar to the situation in the ZenoTravel
domain where a number of aircraft may concurrently choose to pick up the same passenger,
but there are some differences due to the fact that the only reason for a satellite to point
in a certain direction is in order to calibrate itself or take an image, which makes the task
somewhat easier.
Therefore this problem can be solved in a different way, using a resource for mutual
exclusion. This resource, called point towards(direction) and having a capacity of 1, can be
borrowed temporarily by turn to for the duration of the turn. If one satellite turns towards a
specific direction d, no other satellite can turn towards d without causing a resource conflict.
This still leaves one problem: When the first satellite has finished turning, it no longer
owns the point towards(d) resource and therefore another satellite can immediately start
turning towards d. It is no longer possible for more than one satellite to turn towards the
same direction at once, but while the first satellite is taking pictures, other satellites can
turn to that direction one by one, until finally all the desired pictures have been taken
in that direction and goal direction sees that there is no longer any valid reason to point
towards d. This can be solved either by changing the definition of goal direction or by letting
take image borrow the same resource.
Clearly, this type of “swarming” problem occurs quite often in concurrent domains and
a more principled solution should be investigated in the future.
5.6.2 Satellite: SimpleTime
The SimpleTime version changes the duration of some operators. Turning takes five time
units, switching an instrument on takes two units, calibrating it takes five units and taking a picture takes seven units. A couple of helper fluents, turning towards, calibrating,
have image generalized (an image exists or is being taken) and power on generalized (power
is on or a switch on action is being executed) keep track of actions that have begun but not
completed. The affected control rules are updated accordingly.
5.6.3 Satellite: Timed
The Timed version of the Satellite domain includes two new functions. The calibration time
specifies the time required to calibrate, while the slew time function represents the time
required for a satellite to turn between two directions. Neither of these changes prompts
any significant changes to the SimpleTime control.
5.6.4 Satellite: Discussion
The Satellite domain does not provide a real challenge as long as the planner is only trying
to find a correct plan. Finding a short plan is harder, especially in the Timed version, and
would require additional analysis to determine in which order images should be collected
and which satellites should be used for each image. Doing this using control rules seemed
a bit like overkill, especially since we had not yet created control rules for the complex
UMTranslog-2 domain. For this reason, we decided to be satisfied with what we had done
371

Kvarnström & Magnusson

so far, and were surprised when the plans we generated turned out to be of considerably
lower quality than those produced by some other planners.
After the contest, we were informed of the reason, or at least the main reason: The
automatic problem generator that created the problem instances randomized the slew times
between every pair of directions and did not check for geometrical consistency that would be
present in a real world situation. We had subconsciously assumed that the problem instances
satisfied the triangle inequality, but this was not the case, and the other planning teams had
discovered this. For example, in handcoded problem 14, turning a satellite directly between
phenomenon86 and groundstation4 takes 82.860 units of time, while turning it through two
carefully selected intermediate directions requires 1.183 units of time.
Initial testing shows that taking this into consideration and once again using the built-in
shortest path algorithm yields significantly shorter plans when plan length is measured by
the time point at which the goals have been satisfied.
Another potential improvement would be to change the last clause in goal direction to
allow satellites to turn towards a direction specified in the goals as soon as one has started
taking the last picture, rather than waiting until one has finished taking the last picture.
5.7 The UMTranslog-2 Domain
The UMTranslog-2 domain is another logistics domain, but with 14 types, 38 predicates,
24 functions and 38 operators, its size and complexity is incomparable to the previously
encountered logistics domains in the contest.
Since the formal domain definition was the only information provided about the domain
and there was no high-level description, we had to work out all the information about
the domain from the PDDL definition. This was not a major problem for the previous
domains, since they were generally quite simple and easy to understand, but it did give
us some problems in UMTranslog-2. A significant amount of time was spent trying to
determine exactly how packages were allowed to move and how they can be loaded into and
unloaded from various kinds of vehicles. In retrospect, it would probably have been better
to do as some other teams did: Skip the UMTranslog-2 domain completely and spend that
time on the Numeric and Complex versions of the other domains.
The domain. Trucks, trains or aircraft transport packages between locations but they
must follow strict movement patterns. A few locations are transportation hubs, some are
transportation centers while the rest are ordinary locations. A package is only allowed to
move up and down through this hierarchy once and only move between two locations in the
same layer once. The longest possible route for a package is thus from an ordinary location
to a transportation center to a hub to another hub to a transportation center and finally to
another ordinary location.
The domain groups locations into cities, which are then grouped in regions. Trucks
travel between any two locations in the same city or by an existing road route between
two cities. Trains and planes always use predefined routes between transportation centers
and hubs. A great number of restrictions further complicate movements. Packages must be
compatible with the vehicle they are loaded into, the vehicle must have enough free space,
not be loaded too heavily and not be wider, longer or higher than the route and destination
location accepts. Finally, the locations, vehicles and routes must all be available for use.
372

TALplanner in IPC-2002: Extensions and Control Rules

Control rules. As in previous domains, we specify what a reasonable location is and limit
vehicle movements to destinations that are reasonable. A truck might want to pick up
or deliver a package at the location or, if the truck cannot reach the goal location of the
package, unload the package at a transportation center to be picked up by another vehicle.
Our control rules do not allow trucks to pick up several packages. This makes finding
optimal solutions impossible in the general case but simplifies the search for acceptable
solutions a great deal. There is an imminent risk that any other packages the truck is
carrying will end up at the wrong location if it is allowed to travel about, picking up more
packages along the way. Since all packages must move according to the specified pattern of
transportation centers and hubs, moving a package that has once arrived at a location that
is not a transportation center is not allowed and the package will be stuck there. Restricting
trucks to picking up one package at a time avoids this problem.
There is also a large group of loading and unloading rules controlling, among other
things, the opening or closing of valves and doors and loading or unloading of packages.
Finally, packages are only loaded into vehicles that are actually able to take them to a useful
location.
Creating control rules and meeting the contest deadline left no time to get the domain
working with concurrent planning. Instead, we had to make do with sequential planning.
Given more time, the set of control rules could definitely be improved. If planning speed
is less of an issue, more search can be allowed and higher quality plans generated. More
and better problem instances would be needed as guidelines when developing better control
rules since the contest problems did not make full use of the intended transportation scheme
with transportation centers and hubs.

6. Improvements After the Competition
Though the planning competition ended during the AIPS-2002 conference in April, 2002,
our work on TALplanner naturally did not cease there. There are still many improvements
that can be made, and a couple of them that are related to the development of new domains
and control rules have been implemented during the summer of 2002.
6.1 Domain Visualization
As was discussed in the description of the ZenoTravel domain, the process of creating control
rules for a planning domain often involves incremental improvements. TALplanner is run on
a number of problem instances using one set of control rules, or possibly without any control
rules at all, and the beginning of the resulting search tree is analyzed in order to determine
where bad choices were made and how they can be avoided using new or improved control
rules. This is repeated until the planner consistently finds plans of good quality.
During this process, one must study not only the output of the planner but also the
structure of the particular problem instance being solved. For example, in a DriverLog
problem it may be necessary to draw the road network being used in each problem instance
using pen and paper, and then study the paths taken by trucks, people, and packages
through the road network, in order to discover whether improvements would be possible.
But often a particular inefficiency only appears in one or a few out of a large set of problem
instances, and tracing the execution of each plan by hand is obviously a tedious and time
373

Kvarnström & Magnusson

consuming task that ought to be automated as far as possible.
This led to the development of TPVis, a generic graphical visualization framework for
TALplanner. The TPVis framework was used to generate the domain images in this article,
and provides an animated display consisting of a set of nodes, where each node can be
a container or an atomic object. Containers may represent vehicles (which can contain
packages), locations (since there can be vehicles, packages or other objects at a location)
or other similar concepts, while atomic nodes may be used for packages, instruments on a
satellite, or any other type of object which should be displayed. Edges between nodes can
indicate any form of relationship between objects, the most obvious interpretation being that
two location nodes are connected by some transportation route. A built-in layout engine
can generate a layout automatically, or you can manually adjust the visual coordinates of
each node.
The visualization framework is then used by concrete plugins adapted to specific planning domains. The DriverLog plugin, for example, displays locations as container nodes,
linked by paths where drivers can walk and links where trucks can drive. Trucks are also
containers, contained within a specific location, as shown in Figure 6 on page 366.
As a plan is being generated, TPVis animates the actual movements of objects between
locations. This creates a better instinctive feel for the domain, and the two-dimensional
graph display gives an overview that is difficult to provide using only text output. In
addition to animating a graph, TPVis simultaneously lists the partial plan leading up to
the current state and the problem goals that the planner tries to satisfy. TPVis also provides
a limited form of interactive planning since it, at any point in the planning process, allows
the user to force the planner to backtrack and explore a different search branch.
The development of TPVis was not initiated until after the planning contest. If this
graphical visualization had been available during the work on the contest domains, it would
have saved a lot of time, and possibly a tree or two.
6.2 Automatic translation from PDDL to TALplanner
Although it was obvious that there should be an automatic translator from PDDL to TALplanner’s input format, there were always more urgent features to be implemented, and we
instead decided to translate the IPC-2002 domains by hand. In retrospect this was a mistake. The risk of making an error somewhere in the translation becomes imminent when
dealing with complex domains such as UMTranslog-2, with 38 operators, some of which
had highly complex preconditions. Also, translating long formulas by hand is quite time
consuming. A semi-automatic translator was therefore implemented to decrease the amount
of work involved in the translation process and reduce the risk of introducing errors in the
definition.

7. Discussion and Conclusions
The third International Planning Competition was a major step forward in terms of the
expressibility required to represent the benchmark domains, and it provided a number of
interesting challenges for any planner that wanted to participate in the competition. In this
article we have described how these challenges affected TALplanner and shown a number
of extensions that were made in order to meet the challenges. The article also includes a
374

TALplanner in IPC-2002: Extensions and Control Rules

number of domain-dependent control rules for the competition domains, but rather than
presenting an exhaustive list of pre-packaged control rules, we have attempted to place more
emphasis on explaining the incremental analysis process that eventually leads to the final
formulas, going into particular detail for the ZenoTravel domain.
As could be seen in the examples shown in this paper, control rules are often simple,
natural common-sense rules, and not very difficult to generate given some basic knowledge about the planning domain. Some rules are more complex, but still not difficult to
understand or verify once someone has spent the effort to generate them. And then, unfortunately, there are a few rules that are quite unintuitive, rules that are too complex to be
easily understood, and rules that occasionally forbid optimal plans.
To some extent, such rules might be avoided by gaining more experience in good practices
for writing control rules, or by extending the expressivity of the language in which control
rules are written so that complex conditions can be expressed more succinctly or in a more
natural manner, or simply by spending a little bit more time on the control rules than
was available during the planning competition when much of our time was spent teaching
or working on the planner implementation. However, another important cause for the
complexity of certain rules is probably that we are attempting to express all search control
knowledge in the same way: As control rules that prune the search tree to such a great
extent that even a simple depth-first search algorithm is sufficient for efficiently finding good
plans in the remainder of the tree.
Not all search control knowledge can easily be expressed in this manner, but this certainly does not mean that control rules should be abandoned altogether. Instead, what we
learn from this experience is that control rules might not be the one and only multi-purpose
planning tool that will efficiently and easily solve all our planning problems. Instead, just
like one would expect, they are one very useful tool that deserves a place in our toolbox but
should be combined with other approaches to planning. Just to mention one rather obvious
example, it would be possible to devise a heuristic forward-chaining planner whose search
tree would be pre-pruned using control rule techniques from TALplanner. Control rules
could be written to exclude plans where the heuristic gives a suboptimal result, potentially
providing plans that are closer to optimal, and even for domains where the heuristic search
function provides good plans it may often be more efficient to state a number of constraints
as explicit control rules.
Such extensions to TALplanner have been considered at least since some time before
the second planning competition in 2000, and it has long been clear to us that this approach should eventually be examined and explored. Before we could start working on this,
though, the strengths and weaknesses of control rules had to be explored in more depth.
Up to now, our work has therefore focused mostly on investigating how far it is possible to
take TALplanner in its current shape, with explicit control rules being the only means for
controlling the search process. This work has proved rather fruitful in itself, and TALplanner did well in IPC-2000 as well as in IPC-2002. The planner is now becoming reasonably
mature, and after a few more improvements have been made and the planner has been
released for general use, it might be time to take a step back and consider its relation to
other approaches in more depth than has been done previously in order to investigate the
possible advantages of hybrid approaches.
Of course, this does not mean that there is nothing more to be done within the “pure”
375

Kvarnström & Magnusson

TALplanner framework. On the contrary, there are many additional topics to be pursued,
including investigating the application of TALplanner to plan optimization problems (where
the very simplest approaches might involve applying standard optimal graph search algorithms to the pruned search tree generated by TALplanner) and extending the planner to
handle incomplete knowledge and non-deterministic operators. Which of these many topics
will be the next focus of our research has not yet been determined.

Acknowledgements
This research is supported in part by the WITAS Project under the Wallenberg Foundation.

References
Bacchus, F., & Kabanza, F. (2000). Using temporal logics to express search control knowledge for planning. Artificial Intelligence, 116 (1–2), 123–191.
Doherty, P. (1994). Reasoning about action and change using occlusion. In Cohn, A. G.
(Ed.), Proceedings of the 11th European Conference on Artificial Intelligence (ECAI94), pp. 401–405. John Wiley and Sons. Available at ftp://ftp.ida.liu.se/pub/labs/
kplab/people/patdo/ecai94.ps.gz.
Doherty, P., Gustafsson, J., Karlsson, L., & Kvarnström, J. (1998). TAL: Temporal Action
Logics – language specification and tutorial. Electronic Transactions on Artificial
Intelligence, 2 (3–4), 273–306. Available at http://www.ep.liu.se/ej/etai/1998/009/.
Doherty, P., & Kvarnström, J. (1999). TALplanner: An empirical investigation of a temporal
logic-based forward chaining planner. In Dixon, C., & Fisher, M. (Eds.), Proceedings of
the 6th International Workshop on Temporal Representation and Reasoning, pp. 47–
54. IEEE Computer Society. Available at ftp://ftp.ida.liu.se/pub/labs/kplab/people/
patdo/time99-final.ps.gz.
Doherty, P., & Kvarnström, J. (2001). TALplanner: A temporal logic-based planner. AI
Magazine, 22 (3), 95–102.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning domains. Journal of Artificial Intelligence Research, this issue.
Gustafsson, J., & Doherty, P. (1996). Embracing occlusion in specifying the indirect effects
of actions. In Aiello, L. C., Doyle, J., & Shapiro, S. C. (Eds.), Proceedings of the 5th
International Conference on Principles of Knowledge Representation and Reasoning
(KR-96), pp. 87–98, San Francisco. Morgan Kaufmann Publishers. Available at ftp:
//ftp.ida.liu.se/pub/labs/kplab/people/patdo/final-kr96.ps.gz.
Karlsson, L., & Gustafsson, J. (1999). Reasoning about concurrent interaction. Journal of
Logic and Computation, 9 (5), 623–650.
Kibler, D., & Morris, P. (1981). Don’t be stupid. In Hayes, P. J. (Ed.), Proceedings of the
7th International Joint Conference on Artificial Intelligence (IJCAI-81), pp. 345–347.
Kvarnström, J., & Doherty, P. (2003). TALplanner project page. http://www.ida.liu.se/
∼patdo/aiicssite1/kplab/projects/talplanner/.

376

TALplanner in IPC-2002: Extensions and Control Rules

Kvarnström, J., & Doherty, P. (2000). TALplanner: A temporal logic based forward chaining
planner. Annals of Mathematics and Artificial Intelligence, 30, 119–169.
Kvarnström, J., Doherty, P., & Haslum, P. (2000). Extending TALplanner with concurrency
and resources. In Horn, W. (Ed.), Proceedings of the 14th European Conference on
Artificial Intelligence (ECAI-2000), Vol. 54 of Frontiers in Artificial Intelligence and
Applications, pp. 501–505, Amsterdam. IOS Press. Available at ftp://ftp.ida.liu.se/
pub/labs/kplab/people/patdo/www-ecai.ps.gz.
Kvarnström, J. (2002). Applying domain analysis techniques for domain-dependent control
in TALplanner. In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of
the Sixth International Conference on Artificial Intelligence Planning and Scheduling
(AIPS-2002), pp. 101–110. AAAI Press, Menlo Park, California.
Long, D., & Fox, M. (2003). The 3rd international planning competition: Results and
analysis. Journal of Artificial Intelligence Research, this issue.

377

Journal of Artificial Intelligence Research 20 (2003) 155-194

Submitted 10/2002; published 12/2003

Sapa: A Multi-objective Metric Temporal Planner
Minh B. Do
Subbarao Kambhampati

BINHMINH @ ASU . EDU
RAO @ ASU . EDU

Department of Computer Science and Engineering
Arizona State University, Tempe AZ 85287-5406

Abstract
Sapa is a domain-independent heuristic forward chaining planner that can handle durative actions, metric resource constraints, and deadline goals. It is designed to be capable of handling
the multi-objective nature of metric temporal planning. Our technical contributions include (i)
planning-graph based methods for deriving heuristics that are sensitive to both cost and makespan
(ii) techniques for adjusting the heuristic estimates to take action interactions and metric resource
limitations into account and (iii) a linear time greedy post-processing technique to improve execution flexibility of the solution plans. An implementation of Sapa using many of the techniques
presented in this paper was one of the best domain independent planners for domains with metric
and temporal constraints in the third International Planning Competition, held at AIPS-02. We describe the technical details of extracting the heuristics and present an empirical evaluation of the
current implementation of Sapa.

1. Introduction
The success of the Deep Space Remote Agent experiment has demonstrated the promise and importance of metric temporal planning for real-world applications. HSTS/RAX, the planner used in
the remote agent experiment, was predicated on the availability of domain- and planner-dependent
control knowledge, the collection and maintenance of which is admittedly a laborious and errorprone activity. An obvious question is whether it will be possible to develop domain-independent
metric temporal planners that are capable of scaling up to such domains. The past experience has
not been particularly encouraging. Although there have been some ambitious attempts–including
IxTeT (Ghallab & Laruelle, 1994) and Zeno (Penberthy & Well, 1994), their performance has not
been particularly satisfactory.
Some encouraging signs however are the recent successes of domain-independent heuristic planning techniques in classical planning (c.f., Nguyen, Kambhampati, & Nigenda, 2001; Bonet, Loerincs, & Geffner, 1997; Hoffmann & Nebel, 2001). Our research is aimed at building on these
successes to develop a scalable metric temporal planner. At first blush search control for metric
temporal planners would seem to be a very simple matter of adapting the work on heuristic planners in classical planning (Bonet et al., 1997; Nguyen et al., 2001; Hoffmann & Nebel, 2001). The
adaptation however does pose several challenges:
• Metric temporal planners tend to have significantly larger search spaces than classical planners. After all, the problem of planning in the presence of durative actions and metric resources subsumes both classical planning and a certain class of scheduling problems.

c
2003
AI Access Foundation. All rights reserved.

D O & K AMBHAMPATI

• Compared to classical planners, which only have to handle the logical constraints between
actions, metric temporal planners have to deal with many additional types of constraints that
involve time and continuous functions representing different types of resources.
• In contrast to classical planning, where the only objective is to find shortest length plans,
metric temporal planning is multi-objective. The user may be interested in improving either
temporal quality of the plan (e.g. makespan) or its cost (e.g. cumulative action cost, cost of
resources consumed etc.), or more generally, a combination thereof. Consequently, effective
plan synthesis requires heuristics that are able to track both these aspects in an evolving plan.
Things are further complicated by the fact that these aspects are often inter-dependent. For
example, it is often possible to find a “cheaper” plan for achieving goals, if we are allowed
more time to achieve them.
In this paper, we present Sapa, a heuristic metric temporal planner that we are currently developing to address these challenges. Sapa is a forward chaining planner, which searches in the
space of time-stamped states Sapa handles durative actions as well as actions consuming continuous resources. Our main focus has been on the development of heuristics for focusing Sapa’s
multi-objective search. These heuristics are derived from the optimistic reachability information
encoded in the planning graph. Unlike classical planning heuristics (c.f., Nguyen et al., 2001)),
which need only estimate the “length” of the plan needed to achieve a set of goals, Sapa’s heuristics
need to be sensitive to both the cost and length (“makespan”) of the plans for achieving the goals.
Our contributions include:
• We present a novel framework for tracking the cost of literals (goals) as a function of time.
These “cost functions” are then used to derive heuristics that are capable of directing the
search towards plans that satisfy any type of cost-makespan tradeoffs.
• Sapa generalizes the notion of “phased” relaxation used in deriving heuristics in planners
such as AltAlt and FF (Nguyen et al., 2001; Hoffmann & Nebel, 2001). Specifically, the
heuristics are first derived from a relaxation that ignores the delete effects and metric resource
constraints, and are then adjusted subsequently to better account for both negative interactions
and resource constraints.
• Sapa improves the temporal flexibility of the solution plans by post-processing these plans to
produce order constrained (o.c or partially-ordered) plans. This way, Sapa is able to exploit
both the ease of resource reasoning offered by the position-constrained plans and the execution flexibility offered by the precedence-constrained plans. We present a linear time greedy
approach to generate an o.c plan of better or equal makespan value compared to a given p.c
plan.
Architecture of Sapa: Figure 1 shows the high-level architecture of Sapa. Sapa uses a forward
chaining A* search to navigate in the space of time-stamped states. Its evaluation function (the
“f (.)” function is multi-objective and is sensitive to both makespan and action cost. When a state
is picked from the search queue and expanded, Sapa computes heuristic estimates of each of the
resulting children states. The heuristic estimation of a state S is based on (i) computing a relaxed
temporal planning graph (RTPG) from S, (ii) propagating cost of achievement of literals in the
156

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Planning Problem
Select state with
lowest f -value

Generate
start state

Queue of Time Stamped states

f can have both
Cost & Makespan
components

Satisfies
Goals?

Yes

No
Partialize the
p.c. plan

Expand state
by applying
actions

Build RTPG
Propagate Cost
functions
Extract relaxed plan
Adjust for
Mutexes ; Resources

Return
o.c and p.c plans
Heuristic
estimation

Figure 1: Architecture of Sapa
RTPG with the help of time-sensitive cost functions (iii) extracting a relaxed plan P r for supporting
the goals of the problem and (iv) modifying the structure of P r to adjust for mutex and resourcebased interactions. Finally, P r is used as the basis for deriving the heuristic estimate of S. The
search ends when a state S 0 selected for expansion satisfies the goals. In this case, Sapa postprocesses the position-constrained plan corresponding to the state S to convert it into an order
constrained plan. This last step is done to improve the makespan as well as the execution flexibility
of the solution plan.
A version of Sapa using a subset of the techniques discussed in this paper performed well in
domains with metric and temporal constraints in the third International Planning Competition, held
at AIPS 2002 (Fox & Long, 2002). In fact, it is the best planner in terms of solution quality and
number of problems solved in the highest level of PDDL2.1 used in the competition for the domains
Satellite and Rovers. These domains are both inspired by NASA applications.
Organization: The paper is organized as follows: in Section 2 we discuss the details of the action
and problem representation, and the forward state space search algorithm used to produce concurrent
metric temporal plans with durative actions. In Section 3, we address the problem of propagating
the time and cost information over a temporal planning graph. Section 4 shows how the propagated
information can be used to estimate the cost of achieving the goals from a given state. We also
discuss in that section how the mutual exclusion relations and resource information help improve
the heuristic estimation. To improve the quality of the solution, Section 6 discusses our greedy

157

D O & K AMBHAMPATI

approach of building a precedence-constrained plan from the position-constrained plan returned
by Sapa. Section 7 discusses the implementation of Sapa, presents some empirical results where
Sapa produces plans with tradeoffs between cost and makespan, and analyzes its performance in the
2002 International Planning Competition (IPC 2002). We present a discussion of the related work
in Section 9 and conclude in Section 10.

2. Handling Concurrent Actions in a Forward State Space Planner
Sapa addresses planning problems that involve durative actions, metric resources, and deadline
goals. In this section, we describe how such planning problems are represented and solved in
Sapa. We first describe the action representation, and then present the forward chaining state search
algorithm used by Sapa.
2.1 Action Representation & Constraints
Planning is the problem of finding a set of actions and the start times of their execution to satisfy all
causal, metric, and resource constraints. In this section, we will briefly describe our representation,
which is an extension of the action representation in PDDL2.1 Level 3 (Fox & Long, 2001), the
most expressive representation level used in the third international competition. Our extensions to
PDDL2.1 are: (i) interval preconditions; (ii) delayed effects that happen at time points other than
action’s start and end time points; (iii) deadline goals.
We shall start with an example to illustrate the action representation in a simple temporal planning problem. This problem and its variations will be used as the running examples throughout the
rest of the paper. Figure 2 shows graphically the problem description. In this problem, a group of
students in Tucson need to go to Los Angeles (LA). There are two car rental options. If the students rent a faster but more expensive car (Car1), they can only go to Phoenix (PHX) or Las Vegas
(LV). However, if they decide to rent a slower but cheaper Car2, then they can use it to drive to
Phoenix or directly to LA. Moreover, to reach LA, the students can also take a train from LV or a
flight from PHX. In total, there are 6 movement actions in the domain: drive-car1-tucson-phoenix
c1
c1
(Dt→p
, Dur = 1.0, Cost = 2.0), drive-car1-tucson-lv (D t→lv
, Dur = 3.5, Cost = 3.0), drive-car2c2
c2
tucson-phoenix (Dt→p , Dur = 1.5, Cost = 1.5), drive-car2-tucson-la (D t→la
),Dur = 7.0, Cost =
6.0, fly-airplane-phoenix-la (Fp→la , Dur = 1.5, Cost = 6.0), and use-train-lv-la (T lv→la , Dur = 2.5,
Cost = 2.5). Each move action A (by car/airplane/train) between two cities X and Y requires the
precondition that the students be at X (at(X)) at the beginning of A. There are also two temporal
effects: ¬at(X) occurs at the starting time point of A and at(Y ) at the end time point of A. Driving
and flying actions also consume different types of resources (e.g fuel) at different rates depending
on the specific car or airplane used. In addition, there are refueling actions for cars and airplanes.
The durations of the refueling actions depend on the amount of fuel remaining in the vehicle and
the refueling rate. The summaries of action specifications for this example are shown on the right
side of Figure 2. In this example, the costs of moving by train or airplane are the respective ticket
prices, and the costs of moving by rental cars include the rental fees and gas (resource) costs.
As illustrated in the example, unlike actions in classical planning, in planning problems with
temporal and resource constraints, actions are not instantaneous but have durations. Each action
A has a duration DA , starting time SA , and end time (EA = SA + DA ). The value of DA can
be statically defined for a domain, statically defined for a particular planning problem, or can be
dynamically decided at the time of execution. For example, in the traveling domain discussed
158

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Train
Las Vegas
LA

Tucson
Car1
Car2

Phoenix
Airplane

Figure 2: The travel example
above, boarding a passenger always takes 10 minutes for all problems in this domain. Duration of
the action of flying an airplane between two cities depends on the distance between these two cities
and the speed of the airplane. Because the distance between two cities will not change over time, the
duration of a particular flying action will be totally specified once we parse the planning problem.
However, refueling an airplane has a duration that depends on the current fuel level of that airplane.
We may only be able to calculate the duration of a given refueling action according to the fuel level
at the exact time instant when the action will be executed.
An action A can have preconditions P re(A) that may be required either to be instantaneously
true at the time point SA or EA , or required to be true starting at S A and remain true for some
duration d ≤ DA . The logical effects Eff(A) of A are divided into two sets E s (A), and Ed (A)
containing, respectively, the instantaneous effects at time points S A , and delayed effects at SA +
d, d ≤ DA . In PDDL2.1, d must be equal to DA for durative preconditions and delayed effects.
Actions can also consume or produce metric resources and their preconditions may also depend
on the values of those resources. For resource related preconditions, we allow several types of
equality or inequality checking including ==, <, >, <=, >=. For resource-related effects, we allow
the following types of change (update): assignment(=), increment(+=), decrement(-=), multiplication(*=), and division(/=). In essence, actions consume and produce metric resources in the same
way that is specified in PDDL2.1.
2.2 A Forward Chaining Search Algorithm for metric temporal planning
Variations of the action representation scheme described in the previous section have been used
in partial order temporal planners such as IxTeT (Ghallab & Laruelle, 1994) and Zeno (Penberthy
& Well, 1994). Bacchus and Ady (2001) were the first to propose a forward chaining algorithm
capable of using this type of action representation and still allow concurrent execution of actions in
the plan. We adopt and generalize their search algorithm in Sapa. The main idea here is to separate
the decisions of “which action to apply” and “at what time point to apply the action.” Regular
progression search planners apply an action in the state resulting from the application of all the
actions in the current prefix plan. This means that the start time of the new action is after the end
time of the last action in the prefix, and the resulting plan will not allow concurrent execution. In
contrast, Sapa non-deterministically considers (a) application of new actions at the current time

159

D O & K AMBHAMPATI

stamp (where presumably other actions have already been applied; thus allowing concurrency) and
(b) advancement of the current time stamp.
Sapa’s search is thus conducted through the space of time stamped states. We define a time
stamped state S as a tuple S = (P, M, Π, Q, t) consisting of the following structure:
• P = (hpi , ti i | ti ≤ t) is a set of predicates pi that are true at t and ti is the last time instant
at which they were achieved.
• M is a set of values for all continuous functions, which may change over the course of planning. Functions are used to represent the metric-resources and other continuous values. Examples of functions are the fuel levels of vehicles.
• Π is a set of persistent conditions, such as durative preconditions, that need to be protected
during a specific period of time.
• Q is an event queue containing a set of updates each scheduled to occur at a specified time in
the future. An event e can do one of three things: (1) change the True/False value of some
predicate, (2) update the value of some function representing a metric-resource, or (3) end the
persistence of some condition.
• t is the time stamp of S
In this paper, unless noted otherwise, when we say “state” we mean a time stamped state. Note
that a time stamped state with a stamp t not only describes the expected snapshot of the world at time
t during execution (as done in classical progression planners), but also the delayed (but inevitable)
effects of the commitments that have been made by (or before) time t.
The initial state Sinit has time stamp t = 0 and has an empty event queue and empty set of
persistent conditions. It is completely specified in terms of function and predicate values. The goals
are represented by a set of 2-tuples G = (hp 1 , t1 i...hpn , tn i) where pi is the ith goal and ti is the
time instant by which pi needs to be achieved. Note that PDDL2.1 does not allow the specification
of goal deadline constraints.
Goal Satisfaction: The state S = (P, M, Π, Q, t) subsumes (entails) the goal G if for each hp i , ti i ∈
G either:
1. ∃hpi , tj i ∈ P , tj < ti and there is no event in Q that deletes p i .
2. ∃e ∈ Q that adds pi at time instant te < ti , and there is no event in Q that deletes p i .1
Action Applicability: An action A is applicable in state S = (P, M, Π, Q, t) if:
1. All logical (pre)conditions of A are satisfied by P.
2. All metric resource (pre)conditions of A are satisfied by M. (For example, if the condition to
execute an action A = move(truck, A, B) is f uel(truck) > 500 then A is executable in S
if the value v of f uel(truck) in M satisfies v > 500.)
1. In practice, conflicting events are never put on Q

160

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

3. A’s effects do not interfere with any persistent condition in Π and any event in Q.
4. There is no event in Q that interferes with persistent preconditions of A.
Interference: Interference is defined as the violation of any of the following conditions:
1. Action A should not add any event e that causes p if there is another event currently in Q that
causes ¬p. Thus, there is never a state in which there are two events in the event queue that
cause opposite effects.
2. If A deletes p and p is protected in Π until time point t p , then A should not delete p before tp .
3. If A has a persistent precondition p, and there is an event that gives ¬p, then that event should
occur after A terminates.
4. A should not change the value of any function which is currently accessed by another unterminated action2 . Moreover, A also should not access the value of any function that is
currently changed by an unterminated action.
At first glance, the first interference condition seems to be overly strong. However, we argue that it is necessary to keep underlying processes that cause contradicting state changes from
overlapping each other. For example, suppose that we have two actions A 1 = build house,
A2 = destroy house and Dur(A1 ) = 10, Dur(A2 ) = 7. A1 has effect has house and A2
has effect ¬has house at their end time points. Assuming that A 1 is applied at time t = 0 and
added an event e = Add(has house) at t = 10. If we are allowed to apply A 2 at time t = 0 and
add a contradicting event e0 = Delete(has house) at t = 7, then it is unreasonable to believe that
we will still have a house at time t = 10 anymore. Thus, even though in our current action modeling, state changes that cause has house and ¬has house look as if they happen instantaneously
at the actions’ end time points, there are underlying processes (build/destroy house) that span the
whole action durations to make them happen. To prevent those contradicting processes from overlapping with each other, we employ the conservative approach of not letting Q contain contradicting
effects.3
When we apply an action A to a state S = (P, M, Π, Q, t), all instantaneous effects of A will be
immediately used to update the predicate list P and metric resources database M of S. A’s persistent
preconditions and delayed effects will be put into the persistent condition set Π and event queue Q
of S.
Besides the normal actions, we will have a special action called advance-time which we use to
advance the time stamp of S to the time instant t e of the earliest event e in the event queue Q of S.
The advance-time action will be applicable in any state S that has a non-empty event queue. Upon
2. Unterminated actions are the ones that started before the time point t of the current state S but have not yet finished
at t.
3. It may be argued that there are cases in which there is no process to give certain effect, or there are situations in which
the contradicting processes are allowed to overlap. However, without the ability to explicitly specify the processes
and their characteristics in the action representation, we currently decided to go with the conservative approach. We
should also mention that the interference relations above do not preclude a condition from being established and
deleted in the course of a plan as long as the processes involved in establishment and deletion do not overlap. In the
example above, it is legal to first build the house and then destroy it.

161

D O & K AMBHAMPATI

State Queue: SQ={Sinit }
while SQ6={}
S:= Dequeue(SQ)
Nondeterministically select A applicable in S
/* A can be advance-time action */
S’ := Apply(A,S)
if S’ satisfies G then PrintSolution
else Enqueue(S’,SQ)
end while;
Figure 3: Main search algorithm
applying this action, the state S gets updated according to all the events in the event queue that are
scheduled to occur at te . Note that we can apply multiple non-interfering actions at a given time
point before applying the special advance-time action. This allows for concurrency in the final plan.
Search algorithm: The basic algorithm for searching in the space of time stamped states is shown in
Figure 3. We proceed by applying each applicable action to the current state and put each resulting
state into the sorted queue using the Enqueue() function. The Dequeue() function is used to take
out the first state from the state queue. Currently, Sapa employs the A* search. Thus, the state queue
is sorted according to some heuristic function that measures the difficulty of reaching the goals from
the current state. Next several sections of the paper discuss the design of these heuristic functions.
Example: To illustrate how different data structures in the search state S = (P, M, Π, Q, t) are
maintained during search, we will use a (simpler) variation of our ongoing example introduced at
the end of Section 2.1. In this variation, we eliminate the route from Tucson to Los Angeles (LA)
going through Las Vegas. Moreover, we assume that there are too many students to fit into one car
and they had to be divided into two groups. The first group rents the first car, goes to Phoenix (Phx),
and then flies to LA. The second group rents the second car and drives directly to LA. Because
the trip from Tucson to LA is very long, the second car needs to be refueled before driving. To
further make the problem simpler, we eliminate the boarding/un-boarding actions and assume that
the students will reach a certain place (e.g. Phoenix) when their means of transportation (e.g. Car1)
arrives there. Figure 4 shows graphically the plan and how the search state S’s components change
as we go forward. In this example, we assume the ref uel(car) action refuels each car to a maximum
of 20 gallons. Drive(car, T ucson, P hoenix) takes 8 gallons of gas and Drive(car, T ucson, LA)
takes 16 gallons. Note that, at time point t 1 , event e1 increases the fuel level of car2 to 20 gallons.
However, the immediately following application of action A 3 reduces f uel(car2) back to the lower
level of 4 gallons.

3. Propagating Time-sensitive Cost Functions in a Temporal Planning Graph
In this section, we discuss the issue of deriving heuristics, that are sensitive to both time and cost,
to guide Sapa’s search algorithm. An important challenge in finding heuristics to support multiobjective search, as illustrated by the example below, is that the cost and temporal aspects of a
plan are often inter-dependent. Therefore, in this section, we introduce the approach of tracking the

162

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Init: at(Car1,T), at(Car2,T), at(Plane,Phx), fuel(Car1)=10, fuel(Car2)=10
Activate: e1
Apply: A3

Activate: e2
Apply: A4

Activate: e4
Apply:

Activate: e3
Apply:

P: {(at(Car2,T),0),
(at(Plane,Phx),0)}

{(at(Plane,Phx),0)}

{(at(Car1,Phx),t2)}

{(at(Car1,Phx),t2),
(at(Plane,LA),t3)}

{(at(Car1,Phx),t2),
(at(Plane,LA),t3),
(at(Car2,LA),t4)}

M: {fuel(Car1)=2,
fuel(Car2)=10}

{fuel(Car1)=2,
fuel(Car2)=4}

{fuel(Car1)=2,
fuel(Car2)=4}

{fuel(Car1)=2,
fuel(Car2)=4}

{fuel(Car1)=2,
fuel(Car2)=4}

3: {(fuel(Car1),t2),
(fuel(Car2),t1),
(at(Car2,T)}

{(fuel(Car1),t2),
(fuel(Car2),t4}

{(fuel(Car2),t4)}

{(fuel(Car2),t4)}

{(fuel(Car2),t4)}

Q: {e1:(fuel(Car2)=20,t1),
e2:(at(Car1,Phx),t2)}

{e2:(at(Car1,Phx),t2),
e3:(at(Car2,LA),t4)}

{e3:(at(Car2,LA),t4), {e3:(at(Car2,LA),t4)}
e4:(at(Plane,LA),t3)}

Activate:
Apply: A1, A2

A1 = Refuel(car2)

A3 = Drive(car2,Tucson,LA)

A2 = Drive(car1,Tucson,Phx)

t=0

{}

t1

A4 = Fly(Phx,LA)

t2

t3

t4

Figure 4: An example showing how different datastructures representing the search state S =
(P, M, Π, Q) change as we advance the time stamp, apply actions and activate events.
The top row shows the initial state. The second row shows the events and actions that are
activated and executed at each given time point. The lower rows show how the search
state S = (P, M, Π, Q) changes due to action application. Finally, we show graphically
the durative actions in this plan.

costs of achieving goals and executing actions in the plan as functions of time. The propagated cost
functions can then be used to derive the heuristic values to guide the search in Sapa.
Example: Consider a simpler version of our ongoing example. Suppose that we need to go from
Tucson to Los Angeles and have two transport options: (i) rent a car and drive from Tucson to Los
Angeles in one day for $100 or (ii) take a shuttle to the Phoenix airport and fly to Los Angeles in
3 hours for $200. The first option takes more time (higher makespan) but less money, while the
second one clearly takes less time but is more expensive. Depending on the specific weights the
user gives to each criterion, she may prefer the first option over the second or vice versa. Moreover,
the user’s decision may also be influenced by other constraints on time and cost that are imposed on
the final plan. For example, if she needs to be in Los Angeles in six hours, then she may be forced
to choose the second option. However, if she has plenty of time but limited budget, then she may
choose the first option.

163

D O & K AMBHAMPATI

The simple example above shows that makespan and execution cost, while nominally independent of each other, are nevertheless related in terms of the overall objectives of the user and the
constraints on a given planning problem. More specifically, for a given makespan threshold (e.g.
to be in LA within six hours), there is a certain estimated solution cost tied to it (shuttle fee and
ticket price to LA) and analogously for a given cost threshold there is a certain estimated time tied
to it. Thus, in order to find plans that are good with respect to both cost and makespan, we need to
develop heuristics that track cost of a set of (sub)goals as a function of time.
Given that the planning graph is an excellent structure to represent the relation between facts and
actions (c.f., Nguyen et al., 2001), we will use a temporal version of the planning graph structure,
such as that introduced in TGP (Smith & Weld, 1999), as a substrate for propagating the cost
information. In Section 3.1, we start with a brief discussion of the data structures used for the cost
propagation process. We then continue with the details of the propagation process in Section 3.2,
and the criteria used to terminate the propagation in Section 3.3.
3.1 The Temporal Planning Graph Structure
We now adapt the notion of temporal planning graphs, introduced by Smith and Weld (1999), to our
action representation. The temporal planning graph for a given problem is a bi-level graph, with
one level containing all facts, and the other containing all actions in the planning problem. Each
fact has links to all actions supporting it, and each action has links to all facts that belong to its
precondition and effect lists.4 Actions are durative and their effects are represented as events that
occur at some time between the action’s start and end time points. As we will see in more detail
in the later parts of this section, we build the temporal planning graph by incrementally increasing
the time (makespan value) of the graph. At a given time point t, an action A is activated if all
preconditions of A can be achieved at t. To support the delayed effects of the activated actions (i.e.,
effects that occur at the future time points beyond t), we also maintain a global event queue for
the entire graph, Q = {e1 , e2 , ...en } sorted in the increasing order of event time. The event queue
for the temporal graph differs from the event queue for the search state (discussed in the previous
section) in the following ways:
• It is associated with the whole planning graph (rather than with each single state).
• It only contains the positive events. Specifically, the negative effects and the resource-related
effects of the actions are not entered in to the graph’s queue.
• All the events in Q have event costs associated with each individual event (see below).
Each event in Q is a 4-tuple e = hf, t, c, Ai in which: (1) f is the fact that e will add; (2) t is the
time point at which the event will occur; and (3) c is the cost incurred to enable the execution of
action A which causes e. For each action A, we introduce a cost function C(A, t) = v to specify
the estimated cost v that we incur to enable A’s execution at time point t. In other words, C(A, t)
is the estimate of the cost incurred to achieve all of A’s preconditions at time point t. Moreover,
each action will also have an execution cost (C exec (A)), which is the cost incurred in executing A
4. The bi-level representation has been used in classical planning to save time and space (Long & Fox, 1998), but as
Smith & Weld (1999) show, it makes even more sense in temporal planning domains because there is actually no
notion of level. All we have are a set of fact/action nodes, each one encoding information such as the earliest time
point at which the fact/action can be achieved/executed, and the lowest cost incurred to achieve them.

164

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Function Propagate Cost
Current time: tc = 0;
Apply(Ainit , 0);
while Termination-Criteria 6= true
Get earliest event e = hfe , te , ce , Ae i from Q;
tc = t e ;
if ce < C(f, tc ) then
Update: C(f, t) = ce
for all action A: f ∈ P recondition(A)
N ewCostA = CostAggregate(A, tc );
if N ewCostA < C(A, tc ) then
Update: C(A, t) = N ewCost(A), tc ≤ t < ∞;
Apply(A, tc );
End Propagate Cost;
Function Apply(A, t)
For all A’s effect that add f at SA + d do
S
Q = Q {e = hf, t + d, C(A, t) + Cexec (A), Ai};
End Apply(A, t);

Figure 5: Main cost propagation algorithm
(e.g. ticket price for the fly action, gas cost for driving a car). For each fact f , a similar cost function
C(f, t) = v specifies the estimated cost v incurred to achieve f at time point t (e.g. cost incurred
to be in Los Angeles in 6 hours). We also need an additional function SA(f, t) = A f to specify the
action Af that can be used to support f with cost v at time point t.
Since we are using a “relaxed” planning graph that is constructed ignoring delete effects, and
resource effects, the derived heuristics will not be sensitive to negative interactions and resource
restrictions. In Sections 5.1 and 5.2 we discuss how the heuristic measures are adjusted to take
these interactions into account.
3.2 Cost Propagation Procedure
As mentioned above, our general approach is to propagate the estimated costs incurred to achieve
facts and actions from the initial state. As a first step, we need to initialize the cost functions C(A, t)
and C(f, t) for all facts and actions. For a given initial state S init , let F = {f1 , f2 ...fn } be the set
0 , t )}, be a set of outstanding positive
of facts that are true at time point t init and {(f10 , t1 ), ...(fm
m
0
events which specify the addition of facts f i at time points ti > tinit . We introduce a dummy action
Ainit to represent Sinit where Ainit (i) requires no preconditions; (ii) has cost C exec (Ainit ) = 0 and
(iii) causes the events of adding all f i at tinit and fi0 at time points ti . At the beginning (t = 0),
the event queue Q is empty, the cost functions for all facts and actions are initialized as: C(A, t) =
∞, C(f, t) = ∞, ∀0 ≤ t < ∞, and Ainit is the only action that is applicable.
Figure 5 summarizes the steps in the cost propagation algorithm. The main algorithm contains
two interleaved parts: one for applying an action and the other for activating an event representing
the action’s effect.

165

D O & K AMBHAMPATI

Action Introduction: When an action A is introduced into the planning graph, we (1) augment
the event queue Q with events corresponding to all of A’s effects, and (2) update the cost function
C(A, t) of A.
Event Activation: When an event e = hf e , te , Ce , Ae i ∈ Q, which represents an effect of A e
occurring at time point te and adding a fact fe with cost Ce is activated, the cost function of the fact
fe is updated if Ce < C(fe , te ). Moreover, if the newly improved cost of f e leads to a reduction in
the cost function of any action A that f e supports (as decided by function CostAggregate(A, t) in
line 11 of Figure 5) then we will (re)apply A in the graph to propagate f e ’s new cost of achievement
to the cost functions of A and its effects.
At any given time point t, C(A, t) is an aggregated cost (returned by function CostAggregate(A, t))
to achieve all of its preconditions. The aggregation can be done in different ways:
1. Max-propagation:
C(A, t) = M ax{C(f, t) : f ∈ P recond(A)} or
2. Sum-propagation:
P
C(A, t) = {C(f, t) : f ∈ P recond(A)} or
The first method assumes that all preconditions of an action depend on each other and the cost
to achieve all of them is equal to the cost to achieve the costliest one. This rule leads to the underestimation of C(A, t) and the value of C(A, t) is admissible. The second method (sum-propagation)
assumes that all facts are independent and is thus inadmissible when subgoals have positive interactions. In classical planning scenarios, sum combination has proved to be more effective than the
admissible but much less informed max combination (Nguyen et al., 2001; Bonet et al., 1997).
When the cost function of one of the preconditions of a given action is updated (lowered), the
CostAggregate(A, t) function is called and it uses one of the methods described above to calculate
if the cost required to execute an action has improved (been reduced). 5 If C(A, t) has improved,
then we will re-apply A (line 12-14 in Figure 5) to propagate the improved cost C(A, t) to the cost
functions C(f, t) of its effects.
The only remaining issue in the main algorithm illustrated in Figure 5 is the termination criteria for the propagation, which will be discussed in detail in Section 3.3. Notice that the way we
update the cost functions of facts and actions in the planning domains described above shows the
challenges in heuristic estimation in temporal planning domains. Because an action’s effects do
not occur instantaneously at the action’s starting time, concurrent actions overlap in many possible
ways and thus the cost functions, which represent the difficulty of achieving facts and actions are
time-sensitive.
Before demonstrating the cost propagation process in our ongoing example, we make two observations about our propagated cost function:
Observation 1: The propagated cost functions of facts and actions are non-increasing over time.
Observation 2: Because we increase time in steps by going through events in the event queue,
the cost functions for all facts and actions will be step-functions, even though time is measured
continuously.
5. Propagation rule (2) and (3) will improve (lower) the value of C(A, t) when the cost function of one of A’s preconditions is improved. However, for rule (1), the value of C(A, t) is improved only when the cost function of its costliest
precondition is updated.

166

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Figure 6: Timeline to represent actions at their earliest possible execution times in the relaxed temporal planning graph.

Figure 7: Cost functions for facts and actions in the travel example.

167

D O & K AMBHAMPATI

From the first observation, the estimated cheapest cost of achieving a given goal g at time point
tg is C(g, tg ). We do not need to look at the value of C(g, t) at time point t < t g . The second
observation helps us in efficiently evaluating the heuristic value for an objective function f involving
both time and cost. Specifically, we need compute f at only the (finite number of)time points where
the cost function of some fact or action changes. We will come back to the details of the heuristic
estimation routines in Section 4.
Returning to our running example, Figure 6 shows graphically the earliest time point at which
each action can be applied (C(A, t) < ∞) and Figure 7 shows how the cost function of facts/actions
change as the time increases. Here is an outline of the update process in this example: at time point
c1
c2
c1
c2
t = 0, four actions can be applied. They are D t→p
, Dt→p
, Dt→lv
, Dt→la
. These actions add 4 events
c1
c2
i,
into the event queue Q = {e1 = hat phx, t = 1.0, c = 2.0, Dt→p i, e2 = hat phx, 1.5, 1.5, Dt→p
c1
c2
e3 = hat lv, 3.5, 3.0, Dt→lv i, e4 = hat la, 7.0, 6.0, Dt→la i}. After we advance the time to t =
1.0, the first event e1 is activated and C(at phx, t) is updated. Moreover, because at phx is a
precondition of Fp→la , we also update C(Fp→la , t) at te = 1.0 from ∞ to 2.0 and put an event
e = hat la, 2.5, 8.0, Fp→la i, which represents Fp→la ’s effect, into Q. We then go on with the
c2
second event hat phx, 1.5, 1.5, Dt→p
i and lower the cost of the fact at phx and action F p→la . Event
e = hat la, 3.0, 7.5, Fp→la i is added as a result of the newly improved cost of F p→la . Continuing
the process, we update the cost function of at la once at time point t = 2.5, and again at t = 3.0 as
the delayed effects of actions Fp→la occur. At time point t = 3.5, we update the cost value of at lv
and action Tlv→la and introduce the event e = hat la, 6.0, 5.5, T lv→la i. Notice that the final event
c2
c2
i representing a delayed effect of the action D t→la
applied at t = 0
e0 = hat la, 7.0, 6.0, Dt→la
will not cause any cost update. This is because the cost function of at la has been updated to value
c = 5.5 < ce0 at time t = 6.0 < te0 = 7.0.
Besides the values of the cost functions, Figure 7 also shows the supporting actions (SA(f, t),
defined in Section 3.1) for the fact (goal) at la. We can see that action T lv→la gives the best cost of
C(at la, t) = 5.5 for t ≥ 6.0 and action F p→la gives best cost C(at la, t) = 7.5 for 3.0 ≤ t < 5.5
and C(at la, t) = 8.0 for 2.5 ≤ t < 3.0. The right most graph in Figure 7 shows similar cost
functions for the actions in this example. We only show the cost functions of actions T lv→la and
Fp→la because the other four actions are already applicable at time point t init = 0 and thus their
cost functions stabilize at 0.
3.3 Termination Criteria for the Cost Propagation Process
In this section, we discuss the issue of when we should terminate the cost propagation process. The
first thing to note is that cost propagation is in some ways inherently more complex than makespan
propagation. For example, once a set of literals enter the planning graph (and are not mutually
exclusive), the estimate of the makespan of the shortest plan for achieving them does not change
as we continue to expand the planning graph. In contrast, the estimate of the cost of the cheapest
plan for achieving them can change until the planning graph levels off. This is why we need to
carefully consider the effect of different criteria for stopping the expansion of the planning graph
on the accuracy of the cost estimates. The first intuition is that we should not stop the propagation
when there exist top level goals for which the cost of achievement is still infinite (unreached goal).
On the other hand, given our objective function of finding the cheapest way to achieve the goals, we
need not continue the propagation when there is no chance that we can improve the cost of achieving

168

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

the goals. From those intuitions, following are several rules that can be used to determine when to
terminate propagation:
Deadline termination: The propagation should stop at a time point t if: (1) ∀ goal G : Deadline(G) ≤
t, or (2) ∃ goal G : (Deadline(G) < t) ∧ (C(G, t) = ∞).
The first rule governs the hard constraints on the goal deadlines. It implies that we should not
propagate beyond the latest goal deadline (because any cost estimation beyond that point is useless),
or we can not achieve some goal by its deadline.
With the observation that the propagated costs can change only if we still have some events
left in the queue that can possibly change the cost functions of a specific propositions, we have the
second general termination rule regarding the propagation:
Fix-point termination: The propagation should stop when there are no more events that can decrease the cost of any proposition.
The second rule is a qualification for reaching the fix-point in which there is no gain on the cost
function of any fact or action. It is analogous to the idea of growing the planning graph until it
levels-off in classical planning.
Stopping the propagation according to the two general rules above leads us to the best (lowest
value) achievable cost estimation for all propositions given a specific initial state. However, there are
several situations in which we may want to stop the propagation process earlier. First, propagation
until the fix-point, where there is no gain on the cost function of any fact or action, would be too
costly (c.f., Nguyen et al., 2001). Second, the cost functions of the goals may reach the fixpoint long before the full propagation process is terminated according to the general rules discussed
above, where the costs of all propositions and actions stabilize.
Given the above motivations, we introduce several different criteria to stop the propagation
earlier than is entailed by the fix-point computation:
Zero-lookahead approximation: Stop the propagation at the earliest time point t where all the
goals are reachable (C(G, t) < ∞).
One-lookahead approximation: At the earliest time point t where all the goals are reachable,
execute all the remaining events in the event queue and stop the propagation.
One-lookahead approximation looks ahead one step in the (future) event queues when one path
to achieve all the goals under the relaxed assumption is guaranteed and hopes that executing all
those events would explicate some cheaper path to achieve all goals. 6
Zero and one-lookahead are examples of a more general k-lookahead approximation, in which
extracting the heuristic value as soon as all the goals are reachable corresponds to zero-lookahead
and continuing to propagate until the fix-point corresponds to the infinite (full) lookahead. The
rationale behind the k-lookahead approximation is that when all the goals appear, which is an indication that there exists at least one (relaxed) solution, then we will look ahead one or more steps to
see if we can achieve some extra improvement in the cost of achieving the goals (and thus lead to a
lower cost solution).7
6. Note that even if none of those events is directly related to the goals, their executions can still indirectly lead to better
(cheaper) path to reach all the goals.
7. For backward planners where we only need to run the propagation one time, infinite-lookahead or higher levels of
lookahead may pay off, while in forward planners where we need to evaluate the cost of goals for each single search
state, lower values of k may be more appropriate.

169

D O & K AMBHAMPATI

Coming back to our travel example, zero-lookahead stops the propagation process at the time
point t = 2.5 and the goal cost is C(in la, 2.5) = 8.0. The action chain giving that cost is
c1
{Dt→p
, Fp→la }. With one-lookahead, we find the lowest cost for achieving the goal in la is
c2
C(in la, 7.0) = 6.0 and it is given by the action (D t→la
). With two-lookahead approximation, the
lowest cost for in la is C(in la, 6.0) = 5.5 and it is achieved by cost propagation through the action
c1
set {(Dt→lv
, Tlv→la )}. In this example, two-lookahead has the same effect as the fix-point propagation (infinite lookahead) if the deadline to achieve in la is later than t = 6.0. If it is earlier, say
Deadline(in la) = 5.5, then the one-lookahead will have the same effect as the infinite-lookahead
c2
option and gives the cost of C(in la, 3.0) = 7.5 for the action chain {D t→phx
, Fphx→la }.

4. Heuristics based on Propagated Cost Functions
Once the propagation process terminates, the time-sensitive cost functions contain sufficient information to estimate any makespan and cost-based heuristic value of a given state. Specifically,
suppose the planning graph is grown from a state S. Then the cost functions for the set of goals
G = {(g1 , t1 ), (g2 , t2 )...(gn , tn )}, ti = Deadline(gi ) can be used to derive the following estimates:
• The minimum makespan estimate T (P S ) for a plan starting from S is given by the earliest
time point τ0 at which all goals are reached with finite cost C(g, t) < ∞.
• The minimum/maximum/summation estimate of slack Slack(P S ) for a plan starting from S
is given by the minimum/maximum/summation of the distances between the time point at
which each goal first appears in the temporal planning graph and the deadline of that goal.
• The minimum cost estimate, (C(g, deadline(g))), of a plan starting from a state S and achieving a set of goals G, C(PS , τ∞ ), can be computed by aggregating the cost estimates for
achieving each of the individual goals at their respective deadlines. 8 Notice that we use τ∞ to
denote the time point at which the cost propagation process stops. Thus, τ ∞ is the time point
at which the cost functions for all individual goals C(f, τ ∞ ) have their lowest value.
• For each value t : τ0 < t < τ∞ , the cost estimate of a plan C(PS , t), which can achieve goals
within a given makespan limit of t, is the aggregation of the values C(g i , t) of goals gi .
The makespan and the cost estimates of a state can be used as the basis for deriving heuristics.
The specific way these estimates are combined to compute the heuristic values does of course depend on what the user’s ultimate objective function is. In the general case, the objective would be
a function f (C(PS ), T (PS )) involving both the cost (C(PS )) and makespan (T (PS )) values of the
plan. Suppose that the objective function is a linear combination of cost and makespan:
h(S) = f (C(PS ), T (PS )) = α.C(PS ) + (1 − α).T (PS )
If the user only cares about the makespan value (α = 0), then h(S) = T (P S ) = τ0 . Similarly,
if the user only cares about the plan cost (α = 1), then h(S) = C(P S , τ∞ ). In the more general
8. If we consider G as the set of preconditions for a dummy action that represents the goal state, then we can use any
of the propagation rules (max/sum) discussed in Section 3.2 to directly estimate the total cost of achieving the goals
from the given initial state.

170

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

case, where 0 < α < 1, then we have to find the time point t, τ 0 ≤ t ≤ τ∞ , such that ht (S) =
f (C(PS , t), t) = α.C(PS , t) + (1 − α).t has minimum value.9
In our ongoing example, given our goal of being in Los Angeles (at la), if α = 0, the heuristic value is h(S) = τ0 = 2.5 which is the earliest time point at which C(at la, t) < ∞. The
c1
heuristic value corresponds to the propagation through action chain (D t→p
, Fp→la ). If α = 1
and Deadline(AtLA ) ≥ 6.0, then h(S) = 5.5, which is the cheapest cost we can get at time
c1
point τ∞ = 6.0. This heuristic value represents another solution (D t→lv
, Tlv→la ). Finally, if
0 < α < 1, say α = 0.55, then the lowest heuristic value h(S) = α.C(P S , t) + (1 − α).t is
h(S) = 0.55 ∗ 7.5 + 0.45 ∗ 3.0 = 5.47 at time point 2.5 < t = 3.0 < 6.0. For α = 0.55, this
heuristic value h(S) = 5.47 corresponds to yet another solution involving driving part way and
c2
flying the rest: (Dt→p
, Fp→la ).
Notice that in the general case where 0 < α < 1, even though time is measured continuously, we
do not need to check every time point t: τ 0 < t < τ∞ to find the value where h(S) = f (C(PS , t), t)
is minimal. This is due to the fact that the cost functions for all facts (including goals) are step
functions. Thus, we only need to compute h(S) at the time points where one of the cost functions
C(gi , t) changes value. In our example above, we only need to calculate values of h(S) at τ 0 = 2.5,
t = 3.0 and τ∞ = 6.0 to realize that h(S) has minimum value at time point t = 3.0 for α = 0.55.
Before we end this section, we note that when there are multiple goals there are several possible
ways of computing C(PS ) from the cost functions of the individual goals. This is a consequence of
the fact that there are multiple rules to propagate the cost, and there are also interactions between the
subgoals. Broadly, there are two different ways to extract the plan costs. We can either directly use
the cost functions of the goals to compute C(P S ), or first extract a relaxed plan from the temporal
planning graph using the cost functions, and then measure C(P S ) based on the relaxed plan. We
discuss these two approaches below.
4.1 Directly Using Cost Functions to Estimate C(P S )
After we terminate the propagation using any of the criteria discussed in Section 3.3, let G =
{(g1 , t1 ), (g2 , t2 )...(gn , tn )}, ti = Deadline(gi ) be a set of goals and CG = {c1 , ...cn |ci =
C(gi , Deadline(gi )} be their best possible achievement costs. If we consider G as the set of preconditions for a dummy action that represents the goal state, then we can use any of the propagation
rules (max/sum) discussed in Section 3.2 to directly estimate the total cost of achieving the goals
from the given initial state. Among all the different combinations of the propagation rules and
the aggregation rules to compute the total cost of the set of goals G, only the max-max (maxpropagation to update C(gi , t), and cost of G is the maximum of the values of C(g i , Deadline(gi ))
is admissible. The sum-sum rule, which assumes the total independence between all facts, and the
other combinations are different options to reflect the dependencies between facts in the planning
problem. The tradeoffs between them can only be evaluated empirically.

171

D O & K AMBHAMPATI

Goals: G = {(g1 , t1 ), (g2 , t2 )...(gn , tn )}
Actions in the relaxed-plan: RP = {}
Supported facts: SF = {f : f ∈ InitialStateS}
While G 6= ∅
Select the best action A that support g1 at t1
RP = RP + A
tA = t1 − Dur(A)
Update makespan value T (RP ) if tA < T (RP )
For all f ∈ Ef f ect(A) added by A after
duration tf from starting point of A do
S
SF = SF {(f, tA + tf )}
For all f ∈ P recondition(A) s.t C(f, tA ) > 0 do
S
G = G {(f, tA )}
If ∃(gi , ti ) ∈ G, (gi , tj ) ∈ SF : tj < ti Then
G = G \ {(gi , ti )}
End while;

Figure 8: Procedure to extract the relaxed plan
4.2 Computing Cost from the Relaxed Plan
To take into account the positive interactions between facts in planning problems, we can do a
backtrack-free search from the goals to find a relaxed plan. Then, the total execution cost of actions
in the relaxed plan and its makespan can be used for the heuristic estimation. Besides providing
a possibly better heuristic estimate, work on FF (Hoffmann & Nebel, 2001) shows that actions in
the relaxed plan can also be used to effectively focus the search on the branches surrounding the
relaxed solution. Moreover, extracting the relaxed solution allows us to use the resource adjustment
techniques (to be discussed in Section 5.2) to improve the heuristic estimations. The challenge here
is how to use the cost functions to guide the search for the best relaxed plan and we address this
below.
The basic idea is to work backwards, finding actions to achieve the goals. When an action is selected, we add its preconditions to the goal list and remove the goals that are achieved by that action.
The partial relaxed plan is the plan containing the selected actions and the causal structure between
them. When all the remaining goals are satisfied by the initial state S, we have the complete relaxed
plan and the extraction process is finished. At each stage, an action is selected so that the complete
relaxed plan that contains the selected actions is likely to have the lowest estimated objective value
f (PS , TS ). For a given initial state S and the objective function h(S) = f (C(P S ), T (PS )), Figure 8 describes a greedy procedure to find a relaxed plan given the temporal planning graph. First,
let RP be the set of actions in the relaxed plan, SF be the set of time-stamped facts (f i , ti ) that are
currently supported , and G be the set of current goals. Thus, SF is the collection of facts supported
by the initial state S and the effects of actions in RP , and G is the conjunction of top level goals
9. Because f (C(PS , t), t) estimates the cost of the (cheapest) plan that achieves all goals with the makespan value
T (PS ) = t, the minimum of f (C(PS , t), t) (τ0 ≤ t ≤ τ∞ ) estimates the plan P that achieves the goals from state
S and P has a smallest value of f (C(PS ), T (PS )). That value would be the heuristic estimation for our objective
function of minimizing f (C(PS ), T (PS )).

172

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

and the set of preconditions of actions in RP that are not currently supported by facts in SF . The
estimated heuristic value for the current (partial) relaxed plan and the current goal set is computed
as follows: h(S) = h(RP ) + h(G) in which h(RP ) = f (C(RP ), T (RP )). For the given set of
goals G, h(G) = minτ0 <t<τ∞ f (C(G, t), t) is calculated
according to the approach discussed in
P
the previous section (Section 4). Finally, C(RP ) = A∈RP Cexec (A) and T (RP ) is the makespan
of RP , where actions in RP are aligned according to their causal relationship (see below). We will
elaborate on this in the example shown later in this section.
At the start, G is the set of top level goals, RP is empty and SF contains facts in the initial state.
Thus C(RP ) = 0, T (RP ) = 0 and h(S) = h(G). We start the extraction process by backward
search for the least expensive action A supporting the first goal g 1 . By least expensive, we mean that
A contributes the smallest amount to the objective function h(S) = h(RP ) + h(G) if A is added
to the current relaxed plan. Specifically, for each
S action A that supports g 1 , we calculate the value
hA (S) = h(RP + A) + h((G \ Ef f ect(A)) P recond(A)) which estimates the heuristic value
if we add A to the relaxed plan. We then choose the action A that has the smallest h A (S) value.
When an action A is chosen, we put its preconditions into the current goal list G, and its effects
into the set of supported facts SF . Moreover, we add a precedence constraint between A and the
action A1 that has g1 as its precondition so that A gives g 1 before the time point at which A1 needs
it. Using these ordering relations between actions in RP and the mutex orderings discussed in
Section 5.1, we can update the makespan value T (RP ) of the current (partial) relaxed plan.
In our ongoing example, suppose that our objective function is h(S) = f (C(P S ), T (PS )) =
α.C(PS )+(1−α).T (PS ), with α = 0.55 and the infinite-lookahead criterion is used to stop the cost
propagation process. When we start extracting the relaxed plan, the initial setting is G = {at la},
c2
RP = ∅ and SF = {at tucson}. Among the three actions D t→la
, Tlv→la and Fp→la that support
the goal at la, we choose action A = Fp→la because if we
S add it to the relaxed plan RP , then the
estimated value hA (S) = h(RP + A) + h((G \ at la) at phx) = (α ∗ Cexec (Fp→la ) + (1 −
α) ∗ Dur(Fp→la )) + mint (f (C(at phx), t)) = (0.55*6.0 + 0.45*1.5) + (0.55*1.5 + 0.45*1.5) =
5.475. This turns out to be the smallest among the three actions. After we add F p→la to the relaxed
plan, we update the goal set to G = {at phx}. It is then easy to compare between the two actions
c2
c1
c2
Dt→phx
and Dt→phx
to see that Dt→phx
is cheaper for achieving at-phx given the value α = 0.55.
The final cost C(PS ) = 6.0 + 1.5 = 7.5 and makespan of T (PS ) = 1.5 + 1.5 = 3 of the final
relaxed plan can be used as the final heuristic estimation h(S) = 0.55 ∗ 7.5 + 0.45 ∗ 3 = 5.475 for
the given state.
Notice that in the relaxed-plan extraction procedure, we set the time points for the goal set
to be the goal deadlines, instead of the latest time points where the cost functions for the goals
stabilized. The reason is that the cost values of facts and actions monotonically decrease and the
costs are time-sensitive. Therefore, the later we set the time points for goals to start searching for
the relaxed plan, the better chance we have of getting the low-cost plan, especially when we use
the k-lookahead approximation approach with k 6= ∞. In our ongoing example, if we use the
zero-lookahead option to stop the propagation, we find that the smallest cost is C(in la) = 8.0 at
t = 2.5. If we search back for the relaxed plan with the combination (in la, 2.5) then we would
c1
find a plan P1 = (Dt→p
, Fp→la ). However, if we search from the goal deadline, say t = 7.0, then
we would realize that the lowest cost for the precondition in phx of F p→la at t = 7.0 − 1.5 = 5.5
c2
at time point t = 2.0) and thus the final plan is P 2 =
is C(in phx, 5.5) = 1.5 (caused by Dt→p
c2
(Dt→p , Fp→la ) which is cheaper than P1 .

173

D O & K AMBHAMPATI

4.3 Origin of Action Costs
In all our preceding discussion of cost-based heuristics, we have implicitly assumed that the individual action costs are specified directly as part of the problem specification. While this is a reasonable
assumption, it can also be argued that unlike the duration, the cost of an action is implicitly dependent on what the user is interested in optimizing. For example, suppose, in a transportation domain,
the user declares the objective function to be optimized as: 10
4 ∗ T otalT ime + 0.005 ∗ T otalF uelU sed
without providing any additional explicit information about action costs. It is possible to use the
objective function to assess the costs of individual actions (in terms of how much they contribute to
the cost portion of the objective). Specifically, the cost each action can be set equal to the amount
of fuel used by that action. The α value (for combining cost and makespan) can be set based on the
coefficients in the objective function. Of course, this type of “de-compilation” of the objective function into action costs is only possible if the objective function is a linear combination of makespan
and resource consumption.

5. Adjustments to the Relaxed Plan Heuristic
Until now, the heuristic estimates have been calculated by relaxing certain types of constraints
such as negative effects and metric resource consumptions. In this section, we discuss how those
contraints can then be used to adjust and improve the final heuristic values.
5.1 Improving the Relaxed Plan Heuristic Estimation with Static Mutex Relations
When building the relaxed temporal planning graph (RTPG), we ignored the negative interactions
between concurrent actions. We now discuss a way of using the static mutex relations to help improve the heuristic estimation when extracting the relaxed plan. Specifically, our approach involves
the following steps:
1. Find the set of static mutex relations between the ground actions in the planning problem
based on their negative interactions. 11
2. When extracting the relaxed plan (Section 4.2), besides the orderings between actions that
have causal relationships (i.e one action gives the effect that supports the other action’s preconditions), we also post precedence constraints to avoid concurrent execution of actions that
are mutex. Specifically, when a new action is added to the relaxed plan, we use the precalculated static mutexes to establish ordering between mutually exclusive action pairs so
that they can not be executed concurrently. The orderings are selected in such a way that they
violate the least number of existing causal links in the relaxed plan.
By using the mutex relations in this way, we can improve the makespan estimation of the relaxed plan, and thus the heuristic estimation. Moreover, in some cases, the mutex relations can also
help us detect that the relaxed plan is in fact a valid plan, and thus can lead to the early termination
10. In fact, this was the metric specified for the first problem in the Zeno-Travel domain in IPC 2003.
11. Two actions are static mutex if the delete effects of one action intersect with the preconditions or add effects of the
other.

174

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Relaxed solution with mutex:

B

move(package1,airplane1,A,B)

package 1

move(package2,airplane1,A,C)

Plane 1
Plane 2

Relaxed solution with no mutex:

A
move(package1,airplane1,A,B)
package 1
package 2

move(package2,airplane2,A,C)

C
package 2

Figure 9: Example of mutex in the relaxed plan
of the search. Consider the example of the Logistics domain illustrated in Figure 9. In this example, we need to move two packages from cityA to cityB and cityC and there are two airplanes
(plane1 , plane2 ) at cityA that can be used to move them. Moreover, we assume that plane 1 is 1.5
times faster than plane2 and uses the same amount of resources to fly between two cities. There are
two relaxed plans
P1 = {move(package1 , plane1 , cityA, cityB), move(package2 , plane1 , cityA, cityC)}
P2 = {move(package1 , plane1 , cityA, cityB), move(package2 , plane2 , cityA, cityC)}
that both contain two actions. The first one uses the same plane to carry both packages, while
the second one uses two different planes. The first one has a shorter makespan if mutexes are
ignored. However, if we consider the mutex constraints, then we know that two actions in P 1
can not be executed concurrently and thus the makespan of P 1 is actually longer than P2 . Moreover, the static mutex relations also show that even if we order the two actions in P 1 , there is
a violation because the first action cuts off the causal link between the initial state and the second one. Thus, the mutex information helps us in this simple case to find a better (consistent)
relaxed plan to use as a heuristic estimate. Here is a sketch of how the relaxed plan P 2 can be
found. After the first action A1 = move(package1 , plane1 , cityA, cityB) is selected to support
the goal at(package1 , cityB), the relaxed plan is RP = A1 and the two potential actions to support the second goal at(package2 , cityC) are A2 = move(package2 , plane1 , cityA, cityC) and
A02 = move(package2 , plane2 , cityA, cityC). With mutex information, we will be able to choose
A02 over A2 to include in the final relaxed plan.
5.2 Using Resource Information to Adjust the Cost Estimates
The heuristics discussed in Section 4 have used the knowledge about durations of actions and deadline goals but not resource consumption. By ignoring the resource related effects when building the
relaxed plan, we may miss counting actions whose only purpose is to provide sufficient resourcerelated conditions to other actions. In our ongoing example, if we want to drive a car from Tucson
to LA and the gas level is low, by totally ignoring the resource related conditions, we will not realize
that we need to refuel the car before drive. Consequently, ignoring resource constraints may reduce
the quality of the heuristic estimate based on the relaxed plan. We are thus interested in adjusting
the heuristic values discussed in the last two sections to account for the resource constraints.

175

D O & K AMBHAMPATI

In many real-world problems, most actions consume resources, while there are special actions
that increase the levels of resources. Since checking whether the level of a resource is sufficient for
allowing the execution of an action is similar to checking the predicate preconditions, one obvious
approach is to adjust the relaxed plan by including actions that provide that resource-related condition to the relaxed plan. However, for many reasons, it turns out to be too difficult to decide which
actions should be added to the relaxed plan to satisfy the given resource conditions (Do & Kambhampati, 2001, gives a more detailed discussion of these difficulties). Therefore, we introduce an
indirect way of adjusting the cost of the relaxed plan to take into account the resource constraints.
We first pre-process the problem specifications and find for each resource R an action A R that can
increase the amount of R maximally. Let ∆ R be the amount by which AR increases R, and let
C(AR ) be the cost value of AR . Let Init(R) be the level of resource R at the state S for which we
want to compute the relaxed plan, and Con(R), P ro(R) be the total consumption and production
of R by all actions in the relaxed plan. If Con(R) > Init(R) + P ro(R), then we increase the cost
by the number of production actions necessary to make up the difference. More precisely:
X  (Con(R) − (Init(R) + P ro(R))) 
C←C+
∗ C(AR )
∆R
R

We shall call this the adjusted cost heuristic. The basic idea is that even though we do not know
if an individual resource-consuming action in the relaxed plan needs another action to support its
resource-related preconditions, we can still adjust the number of actions in the relaxed plan by reasoning about the total resource consumption of all the actions in the plan. If we know the resources
R consumed by the relaxed plan and the maximum production of those resources possible by any
individual action in the domain, then we can infer the minimum number of resource-increasing actions that we need to add to the relaxed plan to balance the resource consumption. In our ongoing
example, if the car rented by the students at Tucson does not have enough fuel in the initial state to
make the trip to Phoenix, LA, or Las Vegas, then this approach will discover that the planner needs
to add a refuel action to the relaxed plan.
Currently, our resource-adjustment technique discussed above is limited to simple consumption
and production of resources using addition and subtraction. These are the most common forms, as
evidenced by the fact that in all metric temporal planning domains used in the competition, actions
consume and produce resources solely using addition (increase) and subtraction (decrease). Modifications are needed to extend our current approach to deal with other types of resource consumption
such as using multiplication or division.

6. Post-Processing to Improve Temporal Flexibility
To improve the makespan and execution flexibility of the plans generated by Sapa, we post-process
and convert them into partially ordered plans. We discuss the details of this process in this section.
We will start by first differentiating between two broad classes of plans.
Position and Order constrained plans: A position constrained plan (p.c.) is a plan where the
execution time of each action is fixed to a specific time point. An order constrained (o.c.) plan is a
plan where only the relative orderings between the actions are specified.
Note that the p.c. vs. o.c. distinction is orthogonal to whether or not concurrency is allowed
during execution. Indeed, we can distinguish two subclasses of p.c. plans–serial and parallel. In

176

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

{Q}

{G}
A1:

{G}

R
R

S

Q
G

S

A3:

T1

R
R

G

R

~R

T3

{Q}

A2:

Q

S

T4

R

~R

A4:

S

T2

Figure 10: Examples of p.c. and o.c. plans
a serial position constrained plan, no concurrency of execution is allowed. In a parallel position
constrained plan, actions are allowed to execute concurrently. Examples of the serial p.c. plans
are the ones returned by classical planners such as HSP (Bonet et al., 1997), AltAlt (Nguyen et al.,
2001), FF (Hoffmann & Nebel, 2001), or GRT (Refanidis & Vlahavas, 2001b). The parallel p.c.
plans are the ones returned by Sapa (Do & Kambhampati, 2001), TP4 (Haslum & Geffner, 2001).
Graphplan-based planners (STAN, Long & Fox, 1998; IPP, Koehler et al. 1997) and their temporal
cousins (TGP, Smith & Weld, 1999; TPSYS, Garrido, Onaindia & Barber, 2001) also return parallel
p.c plans. Examples of planners that output order constrained (o.c.) plans are Zeno (Penberthy
& Well, 1994), HSTS (Muscettola, 1994), IxTexT (Laborie & Ghallab, 1995), RePOP (Nguyen &
Kambhampati, 2001), and VHPOP (Younes & Simmons, 2003).
As mentioned above, the plans returned by Sapa are position-constrained (p.c.). Searching in
the space of these p.c. plans has some advantages in the presence of metric resources (viz., it
is easy to compute the amount of consumed resources at every point in a partial plan). Position
constrained plans are however less desirable from the point of view of execution flexibility and
human comprehension. For these latter uses, an order (precedence) constrained plan (o.c plan) is
often better.
Figure 10 shows a valid parallel p.c. plan consisting of four actions A 1 , A2 , A3 , A4 with their
starting time points fixed to T1 , T2 , T3 , T4 and an o.c plan consisting of the same set of actions and
achieving the same goals. For each action, the shaded regions show the durations over which each
precondition or effects should hold during each action’s execution time. The darker ones represent
the effect and the lighter ones represent preconditions. For example, action A 1 has a precondition
Q and effect R; action A3 has no preconditions and two effects ¬R and S. The arrows show the
relative orderings between actions. Those ordering relations represent the o.c plan and thus any
execution trace that does not violate those orderings will be a consistent p.c plan.
Given a p.c plan Ppc , we are interested in computing an o.c. plan P oc that contains the same
actions as Ppc , and is also a valid plan for solving the original problem. In general, there can
be many such o.c. plans. In the related work (Do & Kambhampati, 2003), we discuss how this
conversion problem can be posed as an optimization problem subject to any variety of optimization
metrics based on temporal quality and flexibility. In the following we discuss a greedy strategy that
was used in the competition version of Sapa, which finds an o.c plan biased to have a reasonably
good makespan. Specifically, we extend the explanation-based order generation method outlined
by Kambhampati and Kedar (1994) to first compute a causal explanation for the p.c plan and then
construct an o.c plan that has just the number of orderings needed to satisfy that explanation. This
strategy depends heavily on the positions of all the actions in the original p.c. plan. It works based
on the fact that the alignment of actions in the original p.c. plan guarantees that causation and
preservation constraints are satisfied. The following notation helps in describing our approach:
177

D O & K AMBHAMPATI

• For each (pre)condition p of action A, we use [st pA , etpA ] to represent the duration in which p
should hold (stpA = etpA if p is an instant precondition).
• For each effect e of action A, we use et eA to represent the time point at which e occurs.
• For each resource r that is checked in preconditions or used by some action A, we use
[strA , etrA ] to represent the duration over which r is accessed by A.
• The initial and goal states are represented by two new actions A I and AG . AI starts before
all other actions in the Ppc , it has no precondition and has effects representing the initial
state. AG starts after all other actions in Ppc , has no effect, and has top-level goals as its
preconditions.
• The symbol 00 ≺00 is used throughout this section to denote the relative precedence orderings
between two time points.
Note that the values of stpA , etpA , eteA , strA , etrA are fixed in the p.c plan but are only partially
ordered in the o.c plan. The o.c plan P oc is built from a p.c plan Ppc as follows:
Supporting Actions: For each precondition p of action A, we choose the earliest possible action
A0 in the p.c plan that can support p:
1. p ∈ Effect(A0 ) and etpA0 < stpA in the p.c. plan Ppc .
p
2. There is no action B such that: ¬p ∈ Effect(B) and et pA0 < et¬p
B < stA in Ppc .

3. There is no other action C that also satisfies the two conditions above and et pC < etpA0 .
p

When A0 is selected to support p for A, we add the causal link A 0 →
− A between two time points
etpA0 and stpA to the o.c plan. Thus, the ordering et pA0 ≺ stpA is added to Poc .
Interference relations: For each pair of actions A, A 0 that interfere with each other, we order them
as follows:
T
¬p
p
1. If ∃p ∈ Delete(A0 ) Add(A), then add the ordering etpA ≺ et¬p
A0 to Poc if etA < stA0 in
¬p
p
Ppc . Otherwise add etA0 ≺ etA to Poc .
T
¬p
p
2. If ∃p ∈ Delete(A0 ) P recond(A), then add the ordering et pA ≺ et¬p
A0 to Poc if etA < etA
¬p
¬p
p
in Ppc . Otherwise, if etA0 < stA in the original plan Ppc then we add the ordering etA0 ≺ stpA
to the final plan Poc .
Resource relations: For each resource r that is checked as a (pre)condition for action A and used
by action A0 , based on those action’s fixed starting times in the original p.c plan P pc , we add the
following orderings to the resulting P oc plan as follows:
• If etrA < strA0 in Ppc , then the ordering relation etrA ≺ strA0 is added to Poc .
• If etrA0 < strA in Ppc , then the ordering relation etrA0 ≺ strA is added to Poc .

178

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

This strategy is backtrack-free due to the fact that the original p.c. plan is correct. All (pre)
conditions of all actions in Ppc are satisfied and thus for any precondition p of an action A, we can
always find an action A0 that satisfies the three constraints listed above to support p. Moreover,
one of the temporal constraints that lead to the consistent ordering between two interfering actions
(logical or resource interference) will always be satisfied because the p.c. plan is consistent and no
pair of interfering actions overlap each other in P pc . Thus, the search is backtrack-free and we are
guaranteed to find an o.c. plan due to the existence of one legal dispatch of the final o.c. plan P oc
(which is the starting p.c. plan Ppc ). The final o.c. plan is valid because there is a causal-link for
every action’s precondition, all causal links are safe, no interfering actions can overlap, and all the
resource-related (pre)conditions are satisfied. Moreover, this strategy ensures that the orderings on
Poc are consistent with the original Ppc . Therefore, because the p.c plan Ppc is one among multiple
p.c plans that are consistent with the o.c plan P oc , the makespan of Poc is guaranteed to be equal or
better than the makespan of Ppc .
The algorithm discussed in this section is a special case of the partialization problem in metric
temporal planning. In our related work (Do & Kambhampati, 2003), we do a systematic study of
the general partialization problem and give CSOP (Constraint Satisfaction Optimization Problem)
encodings for solving them. The current algorithm can be seen as a particular greedy variable/value
ordering strategy for the CSOP encoding.

7. Implementation of Sapa
The Sapa system with all the techniques described in this paper has been implemented in Java. The
implementation includes:
1. The forward chaining algorithm (Section 2).
2. The cost sensitive temporal planning graph and the routines to propagate the cost information
and extract the heuristic value from it (Section 3).
3. The routines to extract and adjust the relaxed plan using static mutex and resource information
(Section 4.2).
4. Greedy post-processing routines to convert the p.c. plan into an o.c plan with better makespan
and execution flexibility (Section 6).
By default Sapa uses the sum-propagation rule, infinite lookahead termination, resource-adjusted
heuristics, and converts the solutions into o.c. plans. Besides the techniques described in this paper,
we also wrote a JAVA-based parser for PDDL2.1 Level 3, which is the highest level used in the
Third International Planning Competition (IPC3).
To visualize the plans returned by Sapa and the relations between actions in the plan (such
as causal links, mutual exclusions, and resource relations), we have developed a Graphical User
Interface (GUI)12 for Sapa. Figure 11 and 12 shows the screen shots of the current GUI. It displays
the time line of the final plan with each action shown with its actual duration and starting time in the
final plan. There are options to display the causal relations between actions (found using the greedy
approach discussed in Section 6), and logical and resource mutexes between actions. The specific
times at which individual goals are achieved are also displayed.

179

D O & K AMBHAMPATI

Figure 11: Screen shot of Sapa’s GUI: PERT chart showing the actions’ starting times and the
precedence orderings between them.

Figure 12: Screen shots of Sapa’s GUI: Gant chart showing different logical relations between a
given action and other actions in the plan.

180

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Makespan Variation

60

31

50

29
27

40

Makespan

Total Cost

Cost variation

30
20
10

25
23
21
19
17

0

15

0.1

0.2

0.3

0.4

0.5

0.6

0

0.8

0.9

0.95

1

0.1

Alpha

0.2

0.3

0.4

0.5

0.6

0

0.8

0.9

0.95

1

Alpha

Figure 13: Cost and makespan variations according to different weights given to them in the objective function. Each point in the graph corresponds to an average value over 20 problems.

Our implementation is publicly available through the Sapa homepage 13 . Since the planner as
well as the GUI are in JAVA, we also provide web-based interactive access to the planner.

8. Empirical Evaluation
We have subjected the individual components of the Sapa implementation to systematic empirical
evaluation (c.f. Do & Kambhampati, 2001, 2002, 2003). In this section, we will describe the experiments that we conducted (Do & Kambhampati, 2001) to show that Sapa is capable of satisfying a
variety of cost/makespan tradeoffs. Moreover, we also provide results to show the effectiveness of
the heuristic adjustment techniques, the utility of different termination criteria, and the utility of the
post-processing. Comparison of Sapa with other systems in the International Planning Competition
is provided in the next section.
8.1 Component Evaluation
Our first test suite for the experiments, used to test Sapa’s ability to produce solutions with tradeoffs
between time and cost quality, consisted of a set of randomly generated temporal logistics problems
provided by Haslum and Geffner (2001). In this set of problems, we need to move packages between
locations in different cities. There are multiple ways to move packages, and each option has different
time and cost requirements. Airplanes are used to move packages between airports in different cities.
Moving by airplanes takes only 3.0 time units, but is expensive, and costs 15.0 cost units. Moving
packages by trucks between locations in different cities costs only 4.0 cost units, but takes a longer
time of 12.0 time units. We can also move packages between locations inside the same city (e.g.
between offices and airports). Driving between locations in the same city costs 2.0 units and takes
2.0 time units. Loading/unloading packages into a truck or airplane takes 1.0 unit of time and costs
1.0 unit.
We tested the first 20 problems in the set with the objective function specified as a linear combination of both total execution cost and makespan values of the plan. Specifically, the objective
12. The GUI was developed by Dan Bryce
13. http://rakaposhi.eas.asu.edu/sapa.html

181

D O & K AMBHAMPATI

function was set to
O = α.C(P lan) + (1 − α).T (P lan)
We tested with different values of α : 0 ≤ α ≤ 1. Among the techniques discussed in this
paper, we used the sum-propagation rule, infinite look-ahead, and relax-plan extraction using static
mutex relations. Figure 13 shows how the average cost and makespan values of the solution change
according to the variation of the α value. The results show that the total execution cost of the
solution decreases as we increase the α value (thus, giving more weight to the execution cost in
the overall objective function). In contrast, when α decreases, giving more weight to makespan,
the final cost of the solution increases and the makespan value decreases. The results show that
our approach indeed produces solutions that are sensitive to an objective function that involves both
time and cost. For all the combinations of {problem, α}, 79% (173/220) are solvable within our
cutoff time limit of 300 seconds. The average solution time is 19.99 seconds and 78.61% of the
instances can be solved within 10 seconds.
8.1.1 E VALUATION

OF

D IFFERENT T ERMINATION C RITERIA

Figure 14 shows the comparison results for zero, one, and infinite lookahead for the set of metric
temporal planning problems in the competition. We take the first 12 problems in each of the four
temporal domains: ZenoTravel-Time, DriverLog-Time, Satellite-Time, and RoversTime. We set
α = 1 in the objective function, making it entirely cost-based. The action costs are set to 1 unit. As
discussed in Section 3.3, zero-lookahead stops the cost propagation process at the time point where
there is a solution under the relaxed condition. K-lookahead spends extra effort to go beyond that
time point in hope of finding better quality (relaxed) solution to use as heuristic values to guide the
search. The running condition is specified in the caption of the figure.
For most of the problems in the three domains ZenoTravel-Time, DriverLog-Time, and SatelliteTime, infinite-lookahead returns better quality solutions in shorter time than one-lookahead, which
in turn is generally better than zero-lookahead. The exception is the Rovers-Time domain, in which
there is virtually no difference in running time or solution quality between the different look-ahead
options.
The following is a more elaborate summary of the results in Figure 14. The top three figures
show the running time, cost, and makespan comparisons in the ZenoTravel domain (Time setting).
In this domain, within the time and memory limit, infinite-lookahead helps to solve 3 more problems
than one-lookahead and 2 more than zero-lookahead. In all but one problem (problem 10), infinitelookahead returns equal (three) or better (eight) cost solution than zero-lookahead. Compared to
one-lookahead, it’s better in five problems and equal in six others. For the makespan value, infinitelookahead is generally better, but not as consistent as other criteria. The next three lower figures
show the comparison results for the DriverLog-Time domain. In this domain, infinite and onelookahead solve one more problem than zero-lookahead, infinite-lookahead is also faster than the
other two options in all but one problem. The costs (number of actions) of solutions returned by
infinite-lookahead are also better than all but two of the problems (in which all three solutions are the
same). One-lookahead is also equal to or better than zero-lookahead in all but two problems. In the
Satellite-Time domain, while infinite and one-lookahead solve three more (of twelve) problems than
zero-lookahead, there is no option that consistently solves problems faster than the other. However,
the solution quality (cost) of infinite and one-lookahead is consistently better than zero-lookahead.
Moreover, the solution cost of plans returned by infinite-lookahead is worse than one-lookahead in

182

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

ZenoTime

Time (ms)

3000
2500

La 0
La 1
La Inf

2000
1500
1000
500

40

60

30

50

20
10
0

0

1

1 2 3 4 5 6 7 8 9 10 11 12

2

3

6

7

8

1

2

3

2

3

4

4

5

7

8

9

10 11 12

DriverLog Time

6

7

8

1

9 10 11 12

2

3

4

5

6

7

8

9 10 11 12

8

9 10 11 12

Problems

SatelliteTime

50

600

40

500

Makespan

Cost (#Action)

La 0
La 1
La Inf

6

800
700
600
500
400
300
200
100
0

SatelliteTime

SatelliteTime

5

Problem

Problems

Problems

30
20
10

400
300
200
100
0

0

Problems

10
1

Makespan

La 0
La 1
La Inf

1 2 3 4 5 6 7 8 9 10 11 12

20

0

9 10 11 12

35
30
25
20
15
10
5
0

1 2 3 4 5 6 7 8 9 10 11 12

Time (ms)

5

30

DriverLog Time

Cost (#Action)

Time (ms)

DriverLog Time

400000
350000
300000
250000
200000
150000
100000
50000
0

4

40

Problem

Problem

180000
160000
140000
120000
100000
80000
60000
40000
20000
0

ZenoTime

Makespan

3500

Cost (#Action)

ZenoTime

1

2

3

4

5

6

7

Problems

8

9 10 11 12

1

2

3

4

5

6

7

Problems

Figure 14: Comparison of the different lookahead options in the competition domains. These experiments were run on a Pentium III-750 WindowsXP machine with 256MB of RAM.
The time cutoff is 600 seconds.

183

D O & K AMBHAMPATI

ZenoTime

Resadj
no-resadj

1000
100
10

40

Makespan

10000

Cost (#Action)

50

100000

Time (ms)

ZenoTime

ZenoTime

1000000

30
20
10
0

1
1

3

5

7

9

11 13

Problems

1

3

5

7

9

11

13

Problems

140
120
100
80
60
40
20
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14

Problems

Figure 15: Utility of the resource adjustment technique on ZenoTravel (time setting) domain in the
competition. Experiments were run on a WindowsXP Pentium III 750MHz with 256MB
of RAM. Time cutoff is 600 seconds.

only one problem while being slightly better in 6 problems. In this domain, it seems that there is big
improvement from zero to one look-ahead, while infinite-lookahead is a slight improvement over
one-lookahead. (The plots for the Rovers domain are not shown in the figure as all the different
look-ahead options seem to lead to near identical results in that domain.) Finally, since the heuristic
is based completely on cost (α =1), we do not, in theory, expect to see any conclusive patterns in
the makespan values of the solutions produced for the different lookahead options.
8.1.2 U TILITY

OF THE

R ESOURCE A DJUSTMENT T ECHNIQUE

In our previous work (Do & Kambhampati, 2001), we show that the resource adjustment technique
can lead to significant quality and search speed improvements in problems such as the metric temporal logistics domain in which there are several types of resource consumption objects like trucks
and airplanes.
In the competition, there are two domains in which we can test the utility of the resource adjustment technique discussed in Section 5.2. The ZenoTravel domain and the Rovers domain have
actions consuming resources and other (refueling) actions to renew them. Of these, the resource
adjustment technique gives mixed results in the ZenoTravel domain and has no effect in the Rovers
domain. Therefore, we only show the comparison for the ZenoTravel domain in Figure 15. In
the ZenoTravel domain, Sapa with the resource adjustment runs slightly faster in 10 of 14 problems, returns shorter solutions in 5 problems and longer solutions in 3 problems. The solution
makespan with the resource adjustment technique is also generally better than without the adjustment technique. In conclusion, the resource adjustment technique indeed helps Sapa in this domain.
In contrast, in the Rovers domain, this technique is of virtually no help. Actually, in the Rovers
domain, the number of search nodes with and without the resource adjustment is the same for all
solved problems. One reason maybe that in the Rovers domain, there are additional constraints on
the recharge action so that it can only be carried out at a certain location. Therefore, even if we
know that we need to add a recharge action to the current relaxed plan, we may not be able to add it
because the plan does not visit the right location.

184

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

DriverLog Time

Zeno Time (+Resource)
Total-Dur
Orig-MS
PP-MS

80

makespan

makespan

100

60
40
20
0
1

2

3

4

5

6

7

8

800
700
600
500
400
300
200
100
0
1

9 10 11 12

2

3

4

Problems

6

7

8

9 10 11 12

Rovers Time (+Resource)

Satellite Complex (time+resource)
300

1000

250

800

makespan

makespan

5

Problems

600
400
200

200
150
100
50
0

0
1

2

3

4

5

6

7

8

1

9 10 11 12

Problems

2

3

4

5

6

7

8

9 10 11 12

Problems

Figure 16: Utility of the greedy post-processing approach for problems in domains ZenoTravelTime, DriverLog-Time, Satellite-Complex, and Rovers-Time in the IPC3.

8.1.3 U TILITY

OF

P OST- PROCESSING P.C. P LANS

TO

O.C. P LANS

Figure 16 shows the utility of the greedy post-processing technique discussed in Section 6. The
test suite contains the same set of problems used in the first test, which are the first 12 problems in
the ZenoTravel-Time, DriverLog-Time, Satellite-Complex, and Rovers-Time domain. The graphs
in Figure 16 show the comparisons of makespan values of (i) total duration of all actions in the
plan (makespan of a serial plan); (ii) original parallel position-constrained (p.c) plans returned by
Sapa, and (iii) order-constrained (o.c) plans returned after post-processing. The graphs show that the
greedy post-processing approach helps improving the makespan values in all domains. On average,
it improves the makespan values of the original plans by 32.4% in the ZenoTravel-Time domain,
27.7% in the DriverLog-Time domain, 20.3% in the Satellite-Complex domain, and 8.7% in the
RoversTime domain. Compared to the serial plans, the greedily partialized o.c plans improved the
makespan values 24.7%-38.9%.
The CPU times for greedy partialization are very small. Specifically, they were less than 0.1 seconds for all problems with the number of actions ranging from 1 to 68. Thus, using our partialization
algorithm as a post-processing stage essentially preserves the significant efficiency advantages of
position constrained planners such as Sapa, GRT and MIPS, that search in the space of p.c. plans,
while improving the temporal flexibility of the plans generated by those planners.
In our related work (Do & Kambhampati, 2003), we present additional results for the SimpleTime setting of those domains and do a comparison with an optimal post-processing technique
discussed in the same paper.

185

D O & K AMBHAMPATI

8.2 Sapa in the 2002 International Planning Competition
We entered an implementation of Sapa, using several of the techniques discussed in this paper, in the
recent International Planning Competition. The specific techniques used in the competition version
of Sapa are infinite look-ahead termination of cost propagation (Section 3.3), resource adjustment
(Section 5.2), and greedy post-processing (Section 6). In the competition, we focused solely on the
metric/temporal domains.
The sophisticated support for multi-objective search provided by Sapa was not fully exploited
in the competition, since action cost is not part of the standard PDDL2.1 language used in the
competition.14 The competition did evaluate the quality of solution plans both in terms of number of
actions and in terms of the overall makespan. Given this state of affairs, we assumed unit cost for all
actions, and ran Sapa with α = 1, thus making the search sensitive only to the action costs. Infinitelookahead was used for cost propagation. This strategy biased Sapa to produce low cost plans (in
terms of number of actions). Although the search was not sensitive to makespan optimization, the
greedy post processing of p.c. plans to o.c. plans improved the makespan of the solutions enough
to make Sapa one of the best planners in terms of the overall quality of solutions produced. 15
The competition results were collected and distributed by the IPC3’s organizers and can be
found at the competition website (Fox & Long, 2002). Detailed descriptions of domains used in
the competition are also available at the same place. The temporal planning domains in the competition came in two sets, one containing two domains, Satellite and Rovers (adapted from NASA
domains), and the other containing three domains: Depots, DriverLogistics and Zeno Travel. In the
planning competition, each domain had multiple versions–depending on whether or not the actions
had durations and whether actions use continuous resources. Sapa participated in the highest levels
of PDDL2.1 (in terms of the complexity of temporal and metric constraints) for the five domains
listed above.
Figures 17 and 18 show that five planners (Sapa, LPG, MIPS, TP4, and TPSYS) submitted
results for the timed setting and only three (Sapa, MIPS, and TP4) were able to handle the complex
setting of the Satellite domain. In the timed setting, action durations depend on the setting of
instruments aboard a particular satellite and the direction it needs to turn to. The “complex” setting
is further complicated by the fact that each satellite has a different capacity limitation so that it can
only store a certain amount of image data. Goals involve taking images of different planets and stars
located at different coordinate directions. To achieve the goals, the satellite equipped with the right
set of instruments should turn to the right direction, calibrate and take the image.
For the timed setting of this Satellite domain, Figure 17 shows that among the five planners,
Sapa, LPG and MIPS were able to solve 19 of 20 problems while TP4 and TPSYS were able to
solve 2 and 3 problems respectively. For quality comparison, LPG with the quality setting was able
to return solutions with the best quality, Sapa was slightly better than LPG with the speed setting
and was much better than MIPS. LPG with the speed setting is generally the fastest, followed by
MIPS and then Sapa and LPG with the quality setting. For the complex setting, Figure 18 shows
that, among the three planners, Sapa was able to solve the most problems (16), and generated plans
of higher quality than MIPS. TP4 produced the highest quality solutions, but was able to solve only
14. Some of the competition problems did have explicit objective functions, and in theory, we could have inferred the
action costs from these objective functions (see the discussion in Section 4.3). We have not yet done this, given that
the “plan metric” field of PDDL2.1 had not been fully standardized at the time of the competition.
15. To be sure, makespan optimal planners such as TP4 can produce much shorter plans–but their search was so inefficient
that they were unable to solve most problems.

186

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Satellite Time
700

500

1.E+06

Speed (milisecs)

600

Quality (Makespan)

Satellite Time
1.E+07

Sapa (19 solved)
LPG.Quality (19 solved)
LPG.Speed (19 solved)
MIPS (19 solved)
TP4 (2 solved)
TPSYS (3 solved)

400
300
200

1.E+05
1.E+04
1.E+03
1.E+02
1.E+01

100

1.E+00

0
1

2

3

4

5

6

7

8

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

9 10 11 12 13 14 15 16 17 18 19 20

Problems

Problems

Figure 17: Results for the time setting of the Satellite domain (from IPC3 results).

Satellite Complex

Satellite Complex

700

1.E+07

MIPS (10 solved)

500

TP4 (3 solved)

1.E+06

Speed (milisecs)

Quality (Makespan)

Sapa (16 solved)
600

400
300
200
100

1.E+05
1.E+04
1.E+03
1.E+02
1.E+01

0

1.E+00

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

1

Problems

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

Problems

Figure 18: Results for the complex setting of the Satellite domain (from IPC3 results).

187

D O & K AMBHAMPATI

Rovers Time

Rovers Time
300

1.E+06

Sapa (11 solved)
1.E+05

MIPS (9 solved)

Speed (milisecs)

Quality (Makespan)

250
200
150
100
50

1.E+04
1.E+03
1.E+02
1.E+01

0

1.E+00
1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16

1

Problems

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16

Problems

Figure 19: Results for the time setting of the Rover domain (from IPC3 results).

Depots Time
2000

1600
1400

1.E+06

Speed (milisecs)

1800

Quality (Makespan)

Depots Time
1.E+07

Sapa (5 solved)
LPG.Quality (18 solved)
LPG.Speed (18 solved)
MIPS (11 solved)
TP4 (1 solved)

1200
1000
800
600
400

1.E+05
1.E+04
1.E+03
1.E+02
1.E+01

200

1.E+00

0

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

Problems

Problems

Figure 20: Results for the time setting of the Depots domain (from IPC3 results).
the three smallest problems. The solving times of Sapa are slightly higher than MIPS, but are much
better than TP4.
The “timed” version of the Rover domain requires that a set of scientific analyses be done using
a number of rovers. Each rover carries different equipment, and has a different energy capacity.
Moreover, each rover can only recharge its battery at certain points that are under the sun (which
may be unreachable). Figure 19 shows that only Sapa and MIPS were able to handle the constraints
in this problem set. Sapa again solved more problems (11 vs. 9) than MIPS and also returned better
or equal quality solutions in all but one case. The solving time of MIPS is better than Sapa in 6 of
9 problems where it returns the solutions.

188

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

In the second set of problems, which come with temporal constraints, there are three domains:
Depots, DriverLogistics and Zeno Travel. Sapa participated at the highest level, which is the
“timed” settings for these three domains. Figure 20 shows the comparison between Sapa and three
other planners (LPG, MIPS, and TP4) that submitted results in the Depots domain. In this domain,
we need to move crates (packages) between different places. The loading actions that place the
crates into each truck are complicated by the fact that they need an empty hoist. Thus, the Depot
domain looks like a combination of the original logistics and blockworlds domains. Drive action
durations depend on the distances between locations and the speed of the trucks. Time for loading
the crates depends on the power of the hoist that we use. There is no resource consumption in this
highest level. In this domain, Sapa was only able to solve five problems, compared to 11 by MIPS
and 18 by LPG. TP4 solved only one problem. For the five problems that Sapa was able to solve,
the solution quality is as good as other planners. For the speed comparison, LPG with speed setting
is clearly faster than the other planners. We speculate that the poor performance of Sapa in this domain is related to two factors: (i) negative interactions between subgoals, largely ignored by Sapa,
are an important consideration in this domain and (ii) the number of ground actions in this domain
is particularly high, making the computation of the planning graph quite costly.
Figure 21 shows how Sapa performance compares with other planners in the competition on the
time setting of the DriveLog domain. This is a variation of the original Logistics domain in which
trucks rather than airplanes move packages between different cities. However, each truck requires a
driver, so a driver must walk to and board a truck before it can move. Like the Depot domain, there
is no resource consumption. The durations for walking and driving depend on the specified timeto-walk and time-to-drive. In this domain, Sapa solved 14 problems compared to 20 by LPG, 16
by MIPS and 1 by TP4. The quality of the solutions by different planners are very similar. For the
speed comparison, LPG with speed setting is fastest, then MIPS, then Sapa and LPG with quality
setting.
Finally, Figure 22 shows the performance of Sapa in the ZenoTravel domain with time setting.
In this domain, passengers travel between different cities by airplanes. The airplanes can choose
to fly with different speeds (fast/slow), which consume different amounts of fuel. Airplanes have
different fuel capacity and need to refuel if they do not have enough for each trip. In this domain,
Sapa and LPG solved 16 problems while MIPS solved 20. The solution quality of Sapa and MIPS
are similar and in general better than LPG with either speed or quality setting. LPG with speed
setting and MIPS solved problems in this domain faster than Sapa which is in turn faster than LPG
with quality setting.
In summary, for problems involving both metric and temporal constraints in IPC3, Sapa is competitive with other planners such as LPG or MIPS. In particular, Sapa solved the most problems
and returned the plans with best solution quality in the highest setting for the two domains Satellite
and Rovers, which are adapted from NASA domains. A more detailed analysis of the competition
results is presented by Long and Fox (2003).

9. Related Work and Discussion
Although there have been several recent domain-independent heuristic planners aimed at temporal
domains, most of them have been aimed at makespan optimization, ignoring the cost aspects. For
example, both TGP (Smith & Weld, 1999) as well as TP4 (Haslum & Geffner, 2001) focus on
makespan optimization and ignore the cost aspects of the plan. As we have argued in this paper,

189

D O & K AMBHAMPATI

DriverLog Time
Sapa (14 solved)
LPG.Quality (20 solved)
LPG.Speed (20 solved)
MIPS (16 solved)
TP4 (2 solved)
TPSYS (1 solved)

6000
5000

1.E+06

Speed (milisecs)

7000

Quality (Makespan)

DriverLog Time
1.E+07

8000

4000
3000
2000

1.E+05
1.E+04
1.E+03
1.E+02
1.E+01

1000
0

1.E+00
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

1

2

3

4

5

6

7

Problems

8

9 10 11 12 13 14 15 16 17 18 19 20

Problems

Figure 21: Results for the time setting of the DriverLog domain (from IPC3 results).

ZenoTravel Time

ZenoTravel Time

1600

1.E+06

Sapa (15 solved)
LPG.Quality (16 solved)
LPG.Speed (16 solved)
MIPS (20 solved)

1200

1.E+05

Speed (milisecs)

Quality (Makespan)

1400

1000
800
600
400

1.E+04
1.E+03
1.E+02
1.E+01

200
0

1.E+00
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

Problems

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

Problems

Figure 22: Results for the time setting of the ZenoTravel domain (from IPC3 results).

190

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

ultimately, metric temporal planners need to deal with objective functions that are based on both
makespan and cost. One recent research effort that recognizes the multi-objective nature of planning
is the MO-GRT system (Refanidis & Vlahavas, 2001a). On one hand, the MO-GRT approach is
more general than our approach in the sense that it deals with a set of non-combinable quality
metrics. The MO-GRT approach however treats time similar to other consumable resources (with
infinite capacity). Temporal constraints on the planning problems (such as when an effect should
occur during the course of action), goal deadlines, or concurrency are ignored in order to scale
down the problem to the classical planning assumptions. Metric-FF (Hoffmann, 2002) and MIPS
(Edelkamp, 2001) are two other forward state space planners that can handle resource constraints.
Both of them generate sequential plans. MIPS handles durative actions by putting in the action
duration and post-processing the sequential p.c plans. Multi-Pegg (Zimmerman, 2002) is another
recent planner that considers cost-time tradeoffs in plan generation. Multi-Pegg is based on the
Graphplan approach, and focuses on classical planning problems with non-uniform cost actions.
ASPEN (Chien et al., 2000) is another planner that recognizes the multi-attribute nature of plan
quality. ASPEN advocates an iterative repair approach for planning, that assumes the availability
of a variety of hand-coded plan repair strategies and their characterization in terms of their effects
on the various dimensions of plan quality. LPG (Gerevini & Serina, 2002) is another planner that
employs local search techniques over the action-graph. Unlike ASPEN, LPG considers domain
independent repair strategies that involve planning graph-based modifications.
Although we evaluated our cost-sensitive heuristics in the context of Sapa, a forward chaining
planner, the heuristics themselves can also be used in other types of planning algorithms. For
example, TGP can be made cost-sensitive by making it propagate the cost functions as part of
planning graph expansion. These cost functions can then be used as a basis for variable and value
ordering heuristics to guide its backward branch-and-bound search. A similar approach in classical
planning has been shown to be successful by Kambhampati and Nigenda (2000).
Besides Graphplan-based approaches, our framework can also be used in both forward and
backward state-space and partial order planners to guide the planning search. It is possible due to
the fact that directional searches (forward/backward) all need to evaluate the distances between an
initial state and a set of temporal goals.
Our work is also related to other approaches that use planning graphs as the basis for deriving
heuristic estimates such as Graphplan-HSP (Kambhampati & Nigenda, 2000), AltAlt (Nguyen et al.,
2001), RePOP (Nguyen & Kambhampati, 2001), and FF (Hoffmann & Nebel, 2001). In the context
of these efforts, our contribution can be seen as providing a way to track cost as a function of time on
planning graphs. An interesting observation is that cost propagation is in some ways inherently more
complex than makespan propagation. For example, once a set of literals enter the planning graph
(and are not mutually exclusive), the estimate of the makespan of the shortest plan for achieving
them does not change as we continue to expand the planning graph. In contrast, the estimate of the
cost of the cheapest plan for achieving them can change until the planning graph levels off. This is
why we needed to carefully consider the effect of different criteria for stopping the expansion of the
planning graph on the accuracy of the cost estimates (Section 3.3).
Another interesting point is that within classical planning, there was often a confusion between
the notions of cost and makespan. For example, the “length of a plan in terms of number of actions”
can either be seen as a cost measure (if we assume that actions have unit costs), or a makespan
measure (if we assume that the actions have unit durations). These notions get teased apart naturally
in metric temporal domains.
191

D O & K AMBHAMPATI

In this paper, we concentrated on developing heuristics that can be sensitive to multiple dimensions of plan quality (specifically, makespan and cost). An orthogonal issue in planning with
multiple criteria is how the various dimensions of plan quality should be combined during optimization. The particular approach we adopted in our empirical evaluation–namely, considering a
linear combination of cost and time–is by no means the only reasonable way. Other approaches
involve non-linear combinations of the quality criteria, as well as “tiered” objective functions (e.g.
rank plans in terms of makespan, breaking ties using cost). A related issue is how to help the user
decide the “weights” or “tiers” of the different criteria. Often the users may not be able to articulate their preferences between the various quality dimensions in terms of precise weights. A more
standard way out of this dilemma involves generating all non-dominated or Pareto-optimal plans 16 ,
and presenting them to the user. Unfortunately, often the set of non-dominated plans can be exponential (c.f., Papadimitriou & Yannakakis, 2001). The users are then expected to pick the plan that
is most palatable to them. Unfortunately, the users may not actually be able to judge the relative
desirability of plans when the problems are complex and the plans are long. Thus, a more practical
approach may involve resorting to other indirect methods such as preference elicitation techniques
(c.f. Chajewska, Getoor, Norman, & Shahar., 1998).

10. Conclusion
In this paper, we presented Sapa, a domain-independent heuristic forward chaining planner that can
handle durative actions, metric resource constraints, and deadline goals. Sapa is a forward-chaining
planner that searches in the space of time-stamped states. It is designed to be capable of handling
the multi-objective nature of metric temporal planning. Our technical contributions include (i) a
planning-graph based method for deriving heuristics that are sensitive to both cost and makespan
(ii) an easy way of adjusting the heuristic estimates to take the metric resource limitations into
account and (iii) a way of post-processing the solution plans to improve their execution flexibility.
We described the technical details of extracting the heuristics and presented an empirical evaluation
of the current implementation of Sapa. An implementation of Sapa using a subset of the techniques
presented in this paper was one of the best domain independent planners for domains with metric
and temporal constraints in the third International Planning Competition, held at AIPS-02.
We are extending Sapa in several different directions. To begin with, we want to make Sapa
support more expressive domains, including exogenous events and a richer set of temporal and resource constraints (e.g a rover can not recharge the battery after sunset). Another direction involves
extending our multi-objective search to involve other quality metrics. While we considered cost of
a plan in terms of a single monetary cost associated with each action, in more complex domains,
the cost may be better defined as a vector comprising the different types of resource consumption.
Further, in addition to cost and makespan, we may also be interested in other measures of plan
quality such as robustness and execution flexibility of the plan. Our longer term goal is to support
plan generation that is sensitive to this extended set of tradeoffs. To this end, we plan to extend our
methodology to derive heuristics sensitive to a larger variety of quality measures. Finally, we also
plan to consider the issues of planner-scheduler interactions in the context of Sapa (c.f., Srivastava,
Kambhampati, & Do, 2001).
16. A plan P is said to be dominated by P 0 if the quality of P 0 is strictly superior to that of P in at least one dimension, and is better or equal in all other dimensions (Dasgupta, Chakrabarti, & DeSarkar., 2001; Papadimitriou &
Yannakakis, 2001).

192

S APA : A M ULTI -O BJECTIVE M ETRIC T EMPORAL P LANNER

Acknowledgments
We thank Daniel Bryce for developing the GUI for Sapa. We specially thank David E. Smith for
his many insightful and detailed comments on the paper. We also thank the JAIR reviewers for their
very helpful comments. This research is supported in part by the NSF grant IRI-9801676, and the
NASA grants NAG2-1461 and NCC-1225.

References
Bacchus, F., & Ady, M. (2001). Planning with resources and concurrency: A forward chaining
approach. In Proceedings of IJCAI-01.
Bonet, B., Loerincs, G., & Geffner, H. (1997). A robust and fast action selection mechanism for
planning. In Proceedings of AAAI-97.
Chajewska, U., Getoor, L., Norman, J., & Shahar., L. (1998). Utility elicitation as a classification
problem. In Proceedings of UAI-98.
Chien, S., Rabideau, G., Knight, R., Sherwood, R., Engelhardt, E., Mutz, D., Estlin, T., Smith, B.,
Fisher, F., Barrett, T., Stebbins, T., & Tran, T. (2000). ASPEN - automating space mission
operations using automated planning and scheduling. In Proceedings of SpaceOps-2000.
Dasgupta, P., Chakrabarti, P., & DeSarkar., S. (2001). Multiobjective Heuristic Search. Vieweg and
Son/Morgan Kaufmann.
Do, M., & Kambhampati, S. (2001). SAPA: A domain independent heuristic metric temporal planner. In Proceedings of ECP-01.
Do, M., & Kambhampati, S. (2002). Planning graph-based heuristics for cost-sensitive temporal
planning. In Proceedings of AIPS-02.
Do, M., & Kambhampati, S. (2003). Improving the temporal flexibility of position constrained
metric temporal planning. In Proceedings of ICAPS-03.
Edelkamp, S. (2001). First solutions to PDDL+ planning problems. In PlanSIG Workshop.
Fox, M., & Long, D. (2001). PDDL2.1: An extension to PDDL for expressing temporal planning
domains. Journal of Artificial Intelligence Research, this issue.
Fox, M., & Long, D. (2002).
Third International Planning Competition website:
http://www.dur.ac.uk/d.p.long/competition.html.
Garrido, A., Onaindia, E., & Barber, F. (2001). Time-optimal planning in temporal problems. In
Proceedings of ECP-01.
Gerevini, A., & Serina, I. (2002). LPG: A planner based on local search for planning graphs. In
Proceedings of AIPS-02.
Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporal planner. In
Proceedings of AIPS-94.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings of
ECP-01.
Hoffmann, J. (2002). Extending FF to numerical state variables. In Proceedings of ECAI-02.

193

D O & K AMBHAMPATI

Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research, 14, 253–302.
Kambhampati, S., & Kedar, S. (1994). An unified framework for explanation-based generalization
of partially ordered and partially instantiated plans. Artificial Intelligence, 67, 29–70.
Kambhampati, S., & Nigenda, R. (2000). Distance based goal ordering heuristics for Graphplan. In
Proceedings of AIPS-2000.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs to an
ADL subset. In Proceedings of ECP-97.
Laborie, P., & Ghallab, M. (1995). Planning with sharable resource constraints. In Proceedings of
IJCAI-95.
Long, D., & Fox, M. (1998). Efficient implementation of the plan graph in STAN. Journal of
Artificial Intelligence Research, 10, 87–115.
Long, D., & Fox, M. (2003). The 3rd International Planning Competition: results and analysis.
Journal of Artificial Intelligence Research, this issue.
Muscettola, N. (1994). HSTS: Integrating planning and scheduling. In Mark Fox & Monte Zweben
(Eds.), Intelligent Scheduling. Morgan Kaufman.
Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning. In Proceedings of IJCAI01.
Nguyen, X., Kambhampati, S., & Nigenda, R. (2001). Planning graph as the basis for deriving
heuristics for plan synthesis by state space and CSP search. Artificial Intelligence, 135, 73–
123.
Papadimitriou, C., & Yannakakis, M. (2001). Multiobjective query optimization. In Proceedings of
ACM Conference on Principles of Database Systems.
Penberthy, S., & Well, D. (1994). Temporal planning with continuous change. In Proceedings of
AAAI-94.
Refanidis, I., & Vlahavas, I. (2001a). A framework for multi-criteria plan evaluation in heuristic
state-space planning. In Proceedings of Workshop on Planning with Resources, IJCAI-01.
Refanidis, I., & Vlahavas, I. (2001b). The GRT planner: Backward heuristic construction in forward
state space planning. Journal of Artificial Intelligence Research, 15, 115–161.
Smith, D., & Weld, D. (1999). Temporal planning with mutual exclusion reasoning. In Proceedings
of IJCAI-99.
Srivastava, B., Kambhampati, S., & Do, M. (2001). Planning the project management way: Efficient
planning by effective integration of causal and resource reasoning in RealPlan. Artificial
Intelligence, 131(1-2), 73–134.
Younes, H., & Simmons, R. (2003). VHPOP: Versatile heuristic partial order planner. Journal of
Artificial Intelligence Research, this issue.
Zimmerman, T. (2002). Generating parallel plans satisfying multiple criteria in anytime fashion. In
Proceedings of Workshop on Planning and Scheduling with Multiple criteria, AIPS-02.

194

Journal of Artificial Intelligence Research 20 (2003) 133-137

Submitted 09/03; published 12/03

Commentary
Imperfect Match: PDDL 2.1 and Real Applications
Mark Boddy

mark.boddy@adventiumlabs.org

Adventium Labs
111 Third Avenue S.
Minneapolis, MN 55401 USA

Abstract
pddl was originally conceived and constructed as a lingua franca for the International
Planning Competition. pddl2.1 embodies a set of extensions intended to support the
expression of something closer to “real planning problems.” This objective has only been
partially achieved, due in large part to a deliberate focus on not moving too far from
classical planning models and solution methods.

1. Introduction
Fox and Long (2003) describe a set of extensions to pddl. They claim that with these
extensions “PDDL2.1 begins to bridge the gap between basic research and applicationsoriented planning by providing the expressive power necessary to capture real problems.”
While the expressive extensions embodied in pddl2.1 represent a step in the right direction,
the authors’ claim is true only in a limited sense. The rest of this commentary will attempt
to make the qualifying reservations clear.

2. Planning and Real Applications
There is no such thing as a “real planning problem,” any more than there is such a thing
as a “real mathematical programming problem.” There are real problems, for which people
have found it useful to construct models and apply solution techniques that are generally
viewed as planning models and techniques (or math programming techniques, or something
else entirely). Examples of problems for which planning models may be useful can be
drawn from manufacturing (e.g., batch manufacturing operations), or from the high-level
control of complex mechanisms such as spacecraft. For math programming, to continue the
comparison, there are disciplines such as Chemical Engineering, a major branch of which is
concerned with how to model and solve problems in chemical manufacturing using various
flavors of mathematical optimization. There is no equivalent discipline for planning, and so
it is more difficult to characterize “planning applications” in the same sense in which control
of chemical processes may be described as an application for mathematical optimization.
This lack of an extensive history of applications makes it difficult to assess the relevance
of particular modeling or solution techniques, including those developed within the planning
research community. The International Planning Competition (IPC), held at AIPS-98,
AIPS-00 and AIPS-02, has been attempting to provide the data necessary to make these
assessments. Unfortunately, the approach taken gets things backwards, implicitly asking

c
2003
AI Access Foundation. All rights reserved.

Mark Boddy

“how can we extend the models everybody in a particular community is comfortable working
with, so that they are closer to what we think is needed for a real application?”
If planning research is to be viewed as a discipline akin to mathematics, this kind of
extension from known theoretical constructs makes sense. If planning is engineering and
real applications are the point, theoretical work should emerge from, or at the very least be
tested against, generalization and abstractions of real applications. The classical planning
approach grew out of work on theorem-proving and dynamic logics, and ever since has
most fruitfully been applied in domains involving minimal interaction with the physical
world, which describes some planning domains (softbots and other software agent-based
applications, for example), but not the vast majority of them. Of the systems cited in Fox
and Long’s Introduction as having been applied to real planning problems (SIPE, O-Plan,
HSTS, and IxTeT), none are conventional classical planners constructing totally-ordered
sequences of operators. All of them use some combination of methods drawn from temporal
network planning and HTN (task decomposition) planning. Other work applying planning
methods to real applications, for example ASPEN (Fukunaga et al., 1997), does not make
much use of classical planning techniques, either. Perhaps classical planning is addressing
the wrong problem, or the wrong parts of the problem, for most real applications.

3. Evaluating the Language Itself
As argued by a long line of people going back at least to Hendrix (1973), a point-based
temporal model in which instantaneous events effect changes in the world state can be used
to build very expressive models of system dynamics, simply by treating those events as
the starting or ending points of intervals over which propositions hold or processes change
the world state. Over the past decade or so, Reiter (2001) and others have extended the
semantics of the Situation Calculus (McCarthy & Hayes, 1969) to encompass overlapping
actions, metric quantities, continuous change, exogenous actions, limited knowledge, contingent action effects, and actions with uncertain effects, among other things. As presented
by Fox and Long, pddl2.1 can be used to express many of the things one might want to
represent for a real problem. However, there is a difference between saying that something
can be expressed in a given language, and that that expression is natural, intuitive, or easy
to use.
Take the modeling of resources as an example: pddl2.1 is expressive enough to represent unary resources (trucks, tools), capacity resources (power, weight), and consumable
resources (fuel). But there is no easy way in the language to refer to properties of the
resource itself. Everything is encoded in the action representation, as for example in the
modeling of total-fuel-used in the example of Figure 5. In many real domains, resources
are primary, in the sense that the hard part of the problem is figuring out how to resolve
resource conflicts, within the other constraints in the problem statement.
3.1 Form Follows Function
The significance of the distinction between what can expressed and how easily it can be
expressed or manipulated depends on what roles the language is intended to fill. pddl2.1
is in its origins and current use a language for the planning competition. As long as
the current language permits the (not necessarily terribly natural) expression of required
134

Imperfect Match

features of the domain and planning problem, perhaps there is no problem. Competitors
who wish to construct special-purpose data structures such as explicit representations of
resources are free to do so.
If pddl2.1 is to be employed beyond the IPC, what role(s) are intended? A high-level
modeling language for real applications has very different requirements from a competition
standard, different again from a language used to pass planning problems and solutions
in machine-readable forms, different yet again from a modular, locally-extensible language
used as a research tool, permitting researchers to exchange example domains so as to be
able to compare results using different techniques on the same data.1
3.2 Specific Problems with the Language
Finally, there are some specific problems with the current semantics of pddl2.1, which
should be addressed pretty much whatever use it is to be put to.
3.2.1 Holdovers From the Classical Model
Fox and Long are explicit about having made choices in both syntax and semantics to keep
a familiar feel to the language for the classical planning community. This makes good sense
if the objective is to use the language to push the boundaries of what can be done using or
extending the models and methods currently popular in the research community, but does
little to support, and may in some cases actively hinder, the introduction of features drawn
from real applications.
There are several problems resulting from this stance. First, the language is explicitly
restricted to ensure a finite set of ground actions, specifically because some planning algorithms require this. This precludes the modeling of a number of different kinds of domain
features, for example the explicit creation and destruction of objects (e.g., intermediate data
products, in an image-processing application), or flexible solution for continuous parameters
(for example, trajectory optimization) within an existing or evolving plan. Shouldn’t the
models and methods be following the requirements of the problems to be solved, rather
than the other way round?
A second problem is the treatment of durative actions as atomic, rather than treating
activities like heating water or lighting matches as starting processes that may proceed on
their own, until the agent decides again to intervene. Consider the heat-water action
defined in Figure 12 of Section 5.3, whose duration is defined to be precisely that required
to raise the water to 100 C. This has the curious result that in any well-defined plan,
the duration of heat-water must be exactly the time required, taking into account any
overlapping actions that may also affect the temperature of the water, where those actions
may not be specified until after the heat-water action is added to the plan.
Finally, the authors define a semantics for durative actions in which preconditions are
required to be true at the beginning or through the extent of, and postconditions are
asserted at the end of, intervals of non-zero width open on the right. This is clean, clear,
and requires no special constraints to have a well-defined semantics, at least for totallyordered begin and end-points. at-end preconditions mess this up, and furthermore are the
wrong solution for what the authors appear to be trying to support, which I take to be the
1. For a summary of previous attempts to construct a shared ontology for planning, see Tate (1998).

135

Mark Boddy

implicit expression of complex structure within a durative action (“this action requires p to
be true for 2 minutes, from the start of the action”). See Dave Smith’s commentary, also
in this issue, for a discussion of what a more complete model of complex durative actions
might look like, if one were less concerned with staying close to the classical planning model.
3.2.2 Problems with the Definition of the Continuous Model
In Section 5.3, Fox and Long introduce a notation for specifying durative actions with continuous effects, claiming that using their #t notation, it is possible to express a variety of
different nonlinear functions of time. At least as presented in that section, the #t construction does not appear to permit the definition, implicit or otherwise, of nonlinear continuous
functions. In their example of expressing the effect of acceleration on position by making
velocity vary over time, evaluating position at #t by multiplying #t by a time-varying velocity also evaluated at #t will result in an incorrect answer. The required operation is
integration, not composition.
Also in that section, the authors say that continuous durative actions don’t support
exogenous events. I don’t understand why they can’t, as long as the endpoints of those
exogenous events also appear in the plan. Incorporating this capability would significantly
increase the range of real (or realistic) problems that could be represented.
3.2.3 Other Issues
Two other matters are worth pointing out as well. First is the restriction to numeric domains
for functions, for which a primary motivation cited is the previously-discussed objective of
making it possible to construct finite extensional models of the set of possible actions. Nonnumeric functions are frequently useful in real domains, for example to refer to the current
state of an object (the current configuration of a piece of communication equipment, say).
Finally, the authors’ decision to support “Undefined” values for numeric fluents is by
their statement intended to allow actions to determine fluent values by setting them, prior
to which the value would be unknown. Representing incomplete information, including
unknown propositional and continuous states, is an important capability, and one that
should be addressed directly. It might deliberately be left as a later extension but I do not
understand the merits of addressing it incompletely in this way.

4. Summary and Conclusions
The extensions embodied in pddl2.1 are a definite step in the direction of a language in
which complex planning problems can be expressed. Fox and Long have done the planning
community a considerable service, first, in designing and implementing those extensions, and
second, in presenting and motivating them in the current paper. The focus on backward
compatibility with classical planning is problematic, given their expressed desire to address
real (or at least more realistic) applications, and there are some other necessary cleanups
to the language, noted above.
Any further extensions to pddl2.1 will have to address the very likely fragmenting of
the field into mutually incompatible sub-fields. The logical end of this process can be seen
in the survey of scheduling problems compiled by Graham et al. (1977), in which minor

136

Imperfect Match

differences in problem statement lead to very different complexity classes. Classification by
complexity class may be less relevant in a field where almost every interesting problem is
at least NP-hard, but a similar phenomenon will arise from the fact that some problems
require different expressive capabilities than others (resource constrained project scheduling
problems, versus manuever planning for satellite constellations, for example), or are hard
to solve in very different ways (finding a correct ordering on plan steps, versus resolving
conflicts on a unary resource).
Ultimately, techniques developed in the classical planning literature will probably prove
useful in addressing complex, real-world applications. However, I do not believe that they
will in most cases be central to those solutions. The classical planning focus is on individual
actions, rather than organizing or synchronizing with operations in the larger environment,
on discrete state changes, rather than multiple, interacting asynchronous processes, and
on propositional representations, rather than constraints on continuous quantities. Other
methods will have to be brought to bear to address the core complexities of most real
“planning” problems, which involve complex resources and other forms of synchronized
behavior, exogenous events, temporal uncertainties in both the agent’s own actions and
other events, and in some cases, significant continuous dynamics.
As a final comment, my reservations regarding the current state of pddl2.1 should not be
taken as an argument against the utility of “toy” problems and abstract languages, especially
for such purposes as the IPC. However, the simplifications and abstractions employed should
preserve the appropriate structure, such that research results and understanding gained in
working with them can translate to real problems. This is where I believe that continued
focus on classical planning models and methods will be problematic.

References
Fox, M., & Long, D. (2003). Pddl2.1: An extension to pddl for expressing temporal planning
domains. Journal of Artificial Intelligence Research, ??
Fukunaga, A., Rabideau, G., Chien, S., & Yan, D. (1997). Aspen: A framework for automated planning and scheduling of spacecraft control and operations. In Proc. International Symposium on AI, Robotics and Automation in Space.
Graham, R., Lawler, E., Lenstra, J., & Rinnooy Kan, A. (1977). Optimization and approximation in deterministic sequencing and scheduling: A survey. In Proceedings Discrete
Optimization.
Hendrix, G. (1973). Modeling simultaneous actions and continuous processes. Artificial
Intelligence, 4, 145–180.
McCarthy, J., & Hayes, P. J. (1969). Some philosophical problems from the standpoint of
artificial intelligence. Machine Intelligence, 4.
Reiter, R. (2001). Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamic Systems. MIT Press, Cambridge, Mass.
Tate, A. (1998). Roots of spar - shared planning and activity representation. Knowledge
Engineering Review, 13, 121–128.

137

Journal of Artificial Intelligence Research 20 (2003) 61-124

Submitted 09/02; published 12/03

pddl2.1 : An Extension to pddl for Expressing Temporal
Planning Domains
Maria Fox
Derek Long

maria.fox@cis.strath.ac.uk
derek.long@cis.strath.ac.uk

Department of Computer and Information Sciences
University of Strathclyde, Glasgow, UK

Abstract
In recent years research in the planning community has moved increasingly towards
application of planners to realistic problems involving both time and many types of resources. For example, interest in planning demonstrated by the space research community
has inspired work in observation scheduling, planetary rover exploration and spacecraft
control domains. Other temporal and resource-intensive domains including logistics planning, plant control and manufacturing have also helped to focus the community on the
modelling and reasoning issues that must be confronted to make planning technology meet
the challenges of application.
The International Planning Competitions have acted as an important motivating force
behind the progress that has been made in planning since 1998. The third competition
(held in 2002) set the planning community the challenge of handling time and numeric
resources. This necessitated the development of a modelling language capable of expressing
temporal and numeric properties of planning domains. In this paper we describe the
language, pddl2.1, that was used in the competition. We describe the syntax of the
language, its formal semantics and the validation of concurrent plans. We observe that
pddl2.1 has considerable modelling power — exceeding the capabilities of current planning
technology — and presents a number of important challenges to the research community.

1. Introduction
In 1998 Drew McDermott released a Planning Domain Description Language, pddl (McDermott, 2000; McDermott & the AIPS-98 Planning Competition Committee, 1998), which
has since become a community standard for the representation and exchange of planning
domain models. Despite some dissatisfaction in the community with some of the features
of pddl the language has enabled considerable progress to be made in planning research
because of the ease with which systems sharing the standard can be compared and the
enormous increase in availability of shared planning resources. The introduction of pddl
has facilitated the scientific development of planning.
Since 1998 there has been a decisive movement in the research community towards application of planning technology to realistic problems. The propositional puzzle domains
of old are no longer considered adequate for demonstrating the utility of a planning system — modern planners must be able to reason about time and numeric quantities. Although several members of the community have been working on applications of planning
to real domains of this nature for some time (Laborie & Ghallab, 1995; Ghallab & Laruelle,
1994; Muscettola, 1994; Drabble & Tate, 1994; Wilkins, 1988) there has always been a gap
c
2003
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Fox & Long

between the modelling requirements of such domains and what can be expressed in pddl.
Application-driven planners come equipped with their own modelling conventions and black
arts and, as a consequence, it is difficult to reproduce their results and to make empirical
comparisons with other approaches, both of which are essential for scientific progress to be
made.
The pddl language provides the foundation on which an expressive standard can be
constructed, enabling the domain models of the applications-driven community to be shared
and motivating the development of the planning field towards realistic application. The
third International Planning Competition, which took place in 2002, had the objective
of closing the gap between planning research and application. As organisers of the third
competition the authors therefore took the first step in defining an expressive language
capable of modelling a certain class of temporal and resource-intensive planning domains.
This had to be done both with an eye to the future and with awareness of the current
capabilities of planners (it had to be possible for the language to be used by members of
the community, or there would be no competitors). In this paper we describe the resulting
language, pddl2.1, in terms of its syntax, semantics and modelling capabilities.
pddl2.1 has been designed to be backward compatible with the fragment of pddl
that has been in common usage since 1998. This compatibility supports the development
of resources which help to establish a scientific foundation for the field of AI planning.
Furthermore, McDermott’s original pddl provides a clean and well-understood basis for
development and embodies a number of design principles that we considered it important
to retain. pddl2.1 extends pddl in principled ways to achieve the additional expressive
power following, as far as possible, McDermott’s maxim “physics, not advice” (McDermott,
2000). We take this maxim to mean that a language should focus on expressing the physical
properties of the world, not advice to the planner about how to search the associated
solution spaces. Of course, any model of physical systems makes simplifying assumptions
and abstracts behaviours at some level, so no model can be claimed to be purely physics
and free of decisions that could influence the use of the model. We do not attempt to
make strong judgements about what constitutes advice but try to implement the maxim
by keeping the language as simple as possible. We make the following two guarantees of
backward compatibility:
1. All existing pddl domains (in common usage) are valid pddl2.1 domains. This is
important to enable existing libraries of benchmark problems to remain valid.
2. Valid pddl plans are valid pddl2.1 plans.
An important contribution made in the development of pddl2.1 is a means by which
domain designers can provide alternative objective functions that can be used to judge
the value of a plan. The use of numbers in a domain provides a platform for measuring
consumption of critical resources and other parameters. An example of a metric that can be
modelled is that energy consumption must be minimized. This is very important for many
practical applications of planning in which plan quality might be dependent on a number
of interacting domain-dependent factors.
The organisation of the paper is as follows. In Section 2 we introduce non-specialist
readers to the pddl domain description language used in the planning research community.
62

pddl2.1: Expressing Temporal Planning Domains

This background is given in order to provide the foundations for the numeric and durative
extensions made in developing pddl2.1. The paper then focusses on the specific extensions
introduced: numeric expressions and durative actions. In Section 3 we start by explaining
the syntax of numeric expressions and their use in action descriptions. We then explain,
in Section 4, how metrics can be provided as part of the problem description so that the
quality of a plan involving numeric change can be evaluated in terms appropriate to the
problem domain. We present the syntax in which metrics are expressed and give examples.
In Section 5 the paper introduces the notion of durative action as a way of modelling the
temporal properties of a planning domain. Both discretised and continuous durative actions
are considered. The syntax is described and examples of modelling power and limitations are
presented in both cases. Having given examples of the syntactic representation of durative
actions we present a formal semantics for both discretised and continuous actions and for
plans. Sections 6, 7, 8 and 9 provide the details. The semantics gives us a way of tackling
the problem of confirming plan validity — something that becomes an important issue
in the face of concurrent activity. In Section 10 we describe the process by which plans
were validated in the competition and discuss the complexity of the validation question
for pddl2.1. Finally, Section 11 describes some related work in the temporal reasoning
community, in order to put the contributions made by pddl2.1 into a wider context. A full
bnf description of pddl2.1 can be found in the appendix.
pddl2.1 was developed for use in the third International Planning Competition in which
competing planners demonstrated that many discretized temporal and metric models can
now be efficiently handled by both domain-independent planners and those using handtailored control rules. For ease of reference in the competition we identified the features of
pddl2.1 with a series of levels of increasing expressive power. Thus, the strips fragment of
pddl2.1 was referred to as level 1, the numeric extensions comprised level 2, the addition
of discretised durative actions resulted in level 3, continuous durative actions resulted in
level 4 and a final level, level 5, comprised all of the extensions of pddl2.1 and additional
components to support the modelling of spontaneous events and physical processes. Level 5
is not discussed in this paper but details can be found in earlier work by Fox and Long (2002).
The competition focussed on the use of levels 1, 2 and 3 and did not use levels 4 or 5 because
the planning technology was not at that stage sufficiently advanced to handle the additional
complexities. Despite the fact that level 4 was not used in the competition we devote some
discussion to it in this paper. We feel that level 4 presents some important immediate
challenges for the planning community that affect the extent to which planning can be
applied to real problems.
The purpose of this paper is to provide an overview of the new features introduced
in pddl2.1, discuss the rationale for our language choices and explain some of the issues that have arisen in trying to extend pddl. Although we have provided the bnf
for pddl2.1 as an appendix, this paper is not intended to be either a language manual or a tutorial on the use of the language. For examples of the use of the language
and other relevant materials, readers should consult archived resources currently held at
http://www.dur.ac.uk/d.p.long/competition.html.
63

Fox & Long

2. pddl Background
pddl is an action-centred language, inspired by the well-known strips formulations of
planning problems. At its core is a simple standardisation of the syntax for expressing this
familiar semantics of actions, using pre- and post-conditions to describe the applicability
and effects of actions. The syntax is inspired by Lisp, so much of the structure of a domain
description is a Lisp-like list of parenthesised expressions. An early design decision in
the language was to separate the descriptions of parameterised actions that characterise
domain behaviours from the description of specific objects, initial conditions and goals that
characterise a problem instance. Thus, a planning problem is created by the pairing of
a domain description with a problem description. The same domain description can be
paired with many different problem descriptions to yield different planning problems in
the same domain. The parameterisation of actions depends on the use of variables that
stand for terms of the problem instance — they are instantiated to objects from a specific
problem instance when an action is grounded for application. The pre- and post-conditions
of actions are expressed as logical propositions constructed from predicates and argument
terms (objects from a problem instance) and logical connectives.
Although the core of pddl is a strips formalism, the language extends beyond that.
The extended expressive power includes the ability to express a type structure for the objects
in a domain, typing the parameters that appear in actions and constraining the types of
arguments to predicates, actions with negative preconditions and conditional effects and
the use of quantification in expressing both pre- and post-conditions. These extensions are
essentially those proposed as adl (Pednault, 1989).
Although the original definition of the pddl syntax was not accompanied by a formal semantics, the language was really a proposal for a standard syntax for a commonly accepted
semantics and there was little scope for disagreement about the meaning of the language
constructs. Two parts of the original language proposal for which this claim fails are an
attempt to offer a standard syntax for describing hierarchical domain descriptions, suitable
for htn planners and the subset of the language concerned with expressing numeric-valued
fluents. The former was an ambitious project to construct a syntax in which the entire structure of domains using hierarchical action decompositions could be expressed. In contrast to
strips-based planning, the differences between planners using hierarchical decomposition
appear to be deeper, with domain descriptions often containing structures that go beyond
the description of domain behaviours (for example, shop (Nau, Cao, Lotem, & MuñozAvila, 1999) often uses mechanisms that represent goal agendas and other solution-oriented
structures in a domain encoding). This diversity undermined the efforts at standardisation
in hierarchical domain descriptions and this part of the language has never been successfully
explored.
The syntax proposed for expressing numeric-valued fluents was not tested in the first
use of the language (in the 1998 competition) and, indeed, it underwent revision in the early
development of the language. The second competition in 2000 also avoided use of numericvalued fluents, so a general agreement about the syntax and semantics of the numericexpressivity of the language remained unnecessary. McDermott’s original pddl provides
support for numbers by allowing numeric quantities to be assigned and updated. The syntax
of numeric-valued fluents changed between the pddl manuals 1.1 and 1.2 (McDermott &
64

pddl2.1: Expressing Temporal Planning Domains

(define (domain jug-pouring)
(:requirements :typing :fluents)
(:types jug)
(:functors
(amount ?j -jug)
(capacity ?j -jug)
- (fluent number))
(:action empty
:parameters (?jug1 ?jug2 - jug)
:precondition (fluent-test
(>= (- (capacity ?jug2) (amount ?jug2))
(amount ?jug1)))
:effect (and (change (amount ?jug1) 0)
(change (amount ?jug2)
(+ (amount ?jug1) (amount ?jug2)))))
)

Figure 1: Pouring water between jugs as described in the AI Magazine article (McDermott,
2000).

the AIPS-98 Planning Competition Committee, 1998) and the later AI Magazine article
on pddl (McDermott, 2000). McDermott presented a version of numeric fluents used in
pddl in the article in AI Magazine (2000) which could be taken as a definitive statement of
the syntax. An example using numeric fluents, presented by McDermott (2000), is shown
in Figure 1. This action models an action from the well-known jugs-and-water problem,
allowing the water in one jug to be emptied into a second jug provided that the space in
the second jug is large enough to hold the water in the first. The effect is a discrete update
of the values of the current contents of the jugs by an assignment (denoted here by the
change token).
Even without the numeric extensions, pddl is an expressive language, capable of capturing a wide variety of interesting and challenging behaviours. Figure 2 illustrates how
pddl can be used to capture a domain in which a vehicle can move between locations,
consuming fuel as it does so.
It can be seen in the example that pddl includes a syntactic representation of the level
of expressivity required in particular domain descriptions through the use of requirements
flags. This gives the opportunity for a planning system to gracefully reject attempts to
plan with domains that make use of more advanced features of the language than the
planner can handle. Syntax checking tools can be used to confirm that the requirements
flags are correctly set for a domain and that the types and other features of the language
are correctly employed. An example of a problem description to accompany the vehicle
domain is shown in Figure 3. The example illustrates that the description of an initial
state requires an exhaustive listing of all the (atomic) propositions that hold. Symmetric or
transitive relations must be modelled by exhaustive and explicit listing of the propositions
that hold. The use of domain axioms to simplify the description of domains that use such
relationships has been considered, but remains an untested part of pddl and therefore
65

Fox & Long

(define (domain vehicle)
(:requirements :strips :typing)
(:types vehicle location fuel-level)
(:predicates (at ?v - vehicle ?p - location)
(fuel ?v - vehicle ?f - fuel-level)
(accessible ?v - vehicle ?p1 ?p2 - location)
(next ?f1 ?f2 - fuel-level))
(:action drive
:parameters (?v - vehicle ?from ?to - location
?fbefore ?fafter - fuel-level)
:precondition (and (at ?v ?from)
(accessible ?v ?from ?to)
(fuel ?v ?fbefore)
(next ?fbefore ?fafter))
:effect (and (not (at ?v ?from))
(at ?v ?to)
(not (fuel ?v ?fbefore))
(fuel ?v ?fafter))
)
)

Figure 2: A domain description in pddl.
an unstable part of the syntax. pddl domains are not case-sensitive, which is somewhat
anachronistic in the light of standard practice in modern programming languages.
In the following sections we review the extensions made to pddl in its development into
pddl2.1, the version of the language used in the third International Planning Competition.

3. Numeric Expressions, Conditions and Effects
One of the first decisions we made in the development of pddl2.1 was to propose a definitive
syntax for the expression of numeric fluents. We based our syntax on the version described
in the AI Magazine article (McDermott, 2000), with some minor revisions (discussed below).
Numeric expressions are constructed, using arithmetic operators, from primitive numeric
expressions, which are values associated with tuples of domain objects by domain functions. Using our proposed syntax for expressing numeric assignments and updates we can
express the jug-pouring operator originally described in the pddl1.2 manual and in the AI
Magazine article (see Figure 1), in pddl2.1, as presented in Figure 4. In this example the
functions capacity and amount associate the jug objects with numeric values corresponding to their capacity and current contents respectively. As can be seen in the example,
we have used a prefix syntax for all arithmetic operators, including comparison predicates,
in order to simplify parsing. Conditions on numeric expressions are always comparisons
between pairs of numeric expressions. Effects can make use of a selection of assignment
operations in order to update the values of primitive numeric expressions. These include
direct assignment and relative assignments (such as increase and decrease). Numbers
are not distinguished in their possible roles, so values can represent, for example, quantities
of resources, accumulating utility, indices or counters.
66

pddl2.1: Expressing Temporal Planning Domains

(define (problem vehicle-example)
(:domain vehicle)
(:objects
truck car - vehicle
full half empty - fuel-level
Paris Berlin Rome Madrid - location)
(:init
(at truck Rome)
(at car Paris)
(fuel truck half)
(fuel car full)
(next full half)
(next half empty)
(accessible car Paris Berlin)
(accessible car Berlin Rome)
(accessible car Rome Madrid)
(acessible truck Rome Paris)
(accessible truck Rome Berlin)
(accessible truck Berlin Paris)
)
(:goal (and (at truck Paris)
(at car Rome))
)
)

Figure 3: A problem instance associated with the vehicle domain.

(define (domain jug-pouring)
(:requirements :typing :fluents)
(:types jug)
(:functions
(amount ?j - jug)
(capacity ?j - jug))
(:action pour
:parameters (?jug1 ?jug2 - jug)
:precondition (>= (- (capacity ?jug2) (amount ?jug2)) (amount ?jug1))
:effect (and (assign (amount ?jug1) 0)
(increase (amount ?jug2) (amount ?jug1)))
)

Figure 4: Pouring water between jugs, pddl2.1 style.

67

Fox & Long

The differences between the pddl2.1 syntax and the AI Magazine syntax are in the
declaration of the functions and in the use of assign instead of change. We decided
to only allow numeric-valued functions, making the declaration of function return types
superfluous. We therefore simplified the language by requiring only the declaration of the
function names and argument types, as is required for predicates. We felt that change was
ambiguous when used alongside the operations increase and decrease and that assign
would be clearer.
Numeric expressions are not allowed to appear as terms in the language (that is, as
arguments to predicates or values of action parameters). There are two justifications for
this decision — a philosophical one and a pragmatic one. Philosophically we take the
view that there are only a finite number of objects in the world. Numbers do not exist as
unique and independent objects in the world, but only as values of attributes of objects.
Our models are object-oriented in the sense that all actions can be seen as methods that
apply to the objects given as their parameters. The object-oriented view does not directly
inform the syntax of our representations, but is reflected in the way in which numbers are
manipulated only through their relationships with the objects that are identified and named
in the initial state. Pragmatically, many current planning approaches rely on being able
to instantiate action schemas prior to planning, and this is only feasible if there is a finite
number of action instances. The branching of the planner’s search space, at choice points
corresponding to action selection, is therefore always over finite ranges. The use of numeric
fluent variables conflicts with this because they could occur as arguments to any predicate
and would not define finite ranges.
Our decision not to allow numbers to be used as arguments to actions rules out some
actions that might seem intuitively reasonable. For example, an action to fly at a certain
altitude might be expected to take the altitude as a number-valued argument. This is only
possible in pddl2.1 if the range of numbers that can be used is finite. From a practical
point of view we think that this is unlikely to be an arduous constraint and that the benefits
of keeping the logical state space finite compensates for any modelling awkwardness that
results.
Functions in pddl2.1 are restricted to be of type Objectn → R, for the (finite) collection of objects in a planning instance, Object and finite function arity n. Later extensions
of pddl might introduce functions of type Objectn → Object, allowing Object to be extended by the application of functions to other objects. The advantage of this would be
to allow objects to be referred to by their relationships to known objects. (For example,
(onTopOf ?x) could be used to refer to the object currently on top of an object instantiating ?x). Unfortunately, such functions present various semantic problems. In particular,
the interpretation of quantified preconditions becomes significantly harder, since the collection of objects is no longer necessarily finite, so extensional interpretations are not possible.
A further difficulty is the identity problem — as objects are manipulated by actions, the
functional expressions that refer to them are also affected, but implicitly. For example, as
objects are moved, (onTopOf A) can change without any action manipulating it explicitly.
Managing the way in which functional terms map to specific objects in the domain (which
might or might not have specific names of their own) appears to introduce considerable
complication into the semantics. We believe that it is important to avoid extending pddl
with elements that are still poorly understood.
68

pddl2.1: Expressing Temporal Planning Domains

4. Plan Metrics
The adoption of a stable numeric extension to the pddl core allowed us to introduce a
further extension into pddl2.1, namely a new (optional) field within the specification of
problems: a plan metric. Plan metrics specify, for the benefit of the planner, the basis
on which a plan will be evaluated for a particular problem. The same initial and goal
states might yield entirely different optimal plans given different plan metrics. Of course,
a planner might not choose to use the metric to guide its development of a solution but
just to evaluate a solution post hoc. This approach might lead to sub-optimal, and possibly
even poor quality plans, but it is a pragmatic approach to the handling of metrics which
was quite widely used in the competition. This issue is discussed further in the companion
paper analysing the results of the 3rd IPC in this issue (Long & Fox, 2003b).
The value total-time can be used to refer to the temporal span of the entire plan.
Other values must all be built from primitive numeric expressions defined within a domain
and manipulated by the actions of the domain. As a consequence, plan metrics can only
express non-temporal metrics in pddl2.1 domains using numeric expressions. Any arithmetic expression can be used in the specification of a metric — there is no requirement
that the expression be linear. It is the domain designer’s responsibility to ensure that plan
metrics are well-defined (for example, do not involve divisions by zero). An example of use
of a plan metric is shown in Figure 5.
The implications of having introduced this extension are far-reaching and have already
helped to demonstrate some important new challenges for planning systems — particularly
fully-automated systems. An enriched descriptive power for the evaluation of plans is a
crucial extension for the practical use of planners, since it is almost never the case that real
plans are evaluated solely by the number of actions they contain.
Metrics are described in the problem description, allowing a modeller to easily explore
the effect of different metrics in the construction of solutions to problems for the same
domain. In order to define a metric in terms of a specific quantity it is necessary to
instrument that quantity in the domain description. For example, if the metric is defined in
terms of overall fuel use a fuel-use quantity can be initialised to zero in the initial state and
then updated every time fuel is consumed. In the domain shown in Figure 5 it is possible
to minimise a linear combination of fuel used by each of the vehicles such as:
(:metric minimize (+ (* 2 (fuel-used car)) (fuel-used truck)))

However it is not possible to minimise distance covered since distance is not instrumented. It
would be straightforward to instrument it if desired, simply by adding the appropriate initial
value and incrementing effects to the domain description. Since actions cause quantities to
change, instrumenting a value requires modification of the domain description itself, not
just a problem file.
The use of plan metrics is subtle and can have dramatic impact on the plans being
sought. Perhaps the simplest case is where all actions increase a metric that must be
minimised, or decrease one that must be maximised. This is the case in the example shown
in Figure 5, where any use of the drive action can only worsen the value of the plan metric
(whether we use the metric shown in the figure or the maximising metric described in the
last paragraph). This situation might appear to be relatively straightforward: a planner
69

Fox & Long

(define (domain metricVehicle)
(:requirements :strips :typing :fluents)
(:types vehicle location)
(:predicates (at ?v - vehicle ?p - location)
(accessible ?v - vehicle ?p1 ?p2 - location))
(:functions (fuel-level ?v - vehicle)
(fuel-used ?v - vehicle)
(fuel-required ?p1 ?p2 - location)
(total-fuel-used))
(:action drive
:parameters (?v - vehicle ?from ?to - location)
:precondition (and (at ?v ?from)
(accessible ?v ?from ?to)
(>= (fuel-level ?v) (fuel-required ?from ?to)))
:effect (and (not (at ?v ?from))
(at ?v ?to)
(decrease (fuel-level ?v) (fuel-required ?from ?to))
(increase (total-fuel-used) (fuel-required ?from ?to))
(increase (fuel-used ?v) (fuel-required ?from ?to)))
)
)
(define (problem metricVehicle-example)
(:domain metricVehicle)
(:objects
truck car - vehicle
Paris Berlin Rome Madrid - location)
(:init
(at truck Rome)
(at car Paris)
(= (fuel-level truck) 100)
(= (fuel-level car) 100)
(accessible car Paris Berlin)
(accessible car Berlin Rome)
(accessible car Rome Madrid)
(accessible truck Rome Paris)
(accessible truck Rome Berlin)
(accessible truck Berlin Paris)
(= (fuel-required Paris Berlin) 40)
(= (fuel-required Berlin Rome) 30)
(= (fuel-required Rome Madrid) 50)
(= (fuel-required Rome Paris) 35)
(= (fuel-required Rome Berlin) 40)
(= (fuel-required Berlin Paris) 40)
(= (total-fuel-used) 0)
(= (fuel-used car) 0)
(= (fuel-used truck) 0)
)
(:goal (and (at truck Paris)
(at car Rome))
)
(:metric minimize (total-fuel-used))
)

Figure 5: An example of a domain and problem instance describing a plan metric.
70

pddl2.1: Expressing Temporal Planning Domains

must attempt to use as few actions to solve a problem as possible. In fact, even this case
is a little more complex than it appears — there can be rival plans in which one uses
more actions but has lower overall cost than the other. A more complex case arises when
some actions improve the quality metric while others degrade it. For example, if we use the
maximising metric but also add a refuel action to the domain then driving will degrade plan
quality (by reducing the fuel level of a vehicle) but refuelling will improve plan quality (by
increasing the fuel level of a vehicle). In this case, a planner can attempt to use actions to
improve the plan quality without those actions actually contributing to achieving the goals.
For example, refuelling might not be necessary to get the vehicles to their destinations,
but adding refuelling actions would improve the quality of a solution. This process could
involve trading off finite and irreplaceable resources for the increased value of the plan.
This would be the case if, for example, refuelling a vehicle took fuel from a finite reservoir.
Alternatively a domain could allow plans of arbitrarily high value to be constructed by
using more and more actions. This would occur in the metric vehicles domain using the
maximising vehicle’s fuel level metric if refuelling were not constrained, since the domain
does not impose a limit on the fuel capacities of the vehicles.
The case in which plans are constrained by finite availability of resources, is an important
and interesting form of the planning problem, but the case in which plans of arbitrarily
high utility can be constructed, is obviously an ill-defined problem, since an optimal plan
does not exist. It is non-trivial to determine whether a planning problem provided with a
metric is ill-defined. In fact, as Helmert shows (Helmert, 2002), the introduction of numeric
expressions, even in the constrained way that we have adopted in pddl2.1, makes the
planning problem undecidable. The problem of finding a collection of actions which does
not consume irreplaceable resources and has an overall beneficial impact on a plan metric
is at least as hard as the planning problem. Therefore it is clear that determining whether
a planning problem is even well-defined is undecidable. This does not make it worthless to
consider planning with metrics, of course, but it demonstrates that the modelling problem,
as well as the planning problem, becomes even more complex when metrics are introduced.
One strategy available to planners working with problems subject to plan metrics is to
ignore the metric and simply produce a plan to satisfy the logical goals that a problem
specifies. In this case, the plan quality will simply be the value, according to the metric, of
the plan that happens to be constructed. This strategy is unsophisticated and it is obviously
better for a planner to construct a plan guided by the specified metric. How best to use a
metric to expedite the search process in a fully-automated planner is still a research issue.

5. Durative Actions
Most recent work on temporal planning (Smith & Weld, 1999; Bacchus & Kabanza, 2000;
Do & Kambhampati, 2001) has been based on various forms of durative action. In order
to facilitate participation in the competition we therefore developed two forms of durative
action allowing the specification only of restricted forms of timed conditions and effects
in their description. Although constrained in certain ways, these durative actions are,
nevertheless, more expressive than many of the proposals previously explored, particularly
in the way that they allow concurrency to be exploited. The two forms are discretised
durative actions and continuous durative actions.
71

Fox & Long

(:durative-action load-truck
:parameters (?t - truck)
(?l - location)
(?o - cargo)
(?c - crane)
:duration (= ?duration 5)
:condition (and (at start (at ?t ?l))
(at start (at ?o ?l))
(at start (empty ?c)
(over all (at ?t ?l))
(at end (holding ?c ?o))
:effect (and (at end (in ?o ?t))
(at start (holding ?c ?o))
(at start (not (at ?o ?l)))
(at end (not (holding ?c ?o)))
)

Figure 6: A durative action for loading a truck. We assume no capacity constraints.

Both forms rely on a basic durative action structure consisting of the logical changes
caused by application of the action. We always consider logical change to be instantaneous,
therefore the continuous aspects of a continuous durative action refer only to how numeric
values change over the interval of the action. Figure 6 depicts a basic durative action,
load-truck, in which there is no numeric change.
The modelling of temporal relationships in a discretised durative action is done by means
of temporally annotated conditions and effects. All conditions and effects of durative actions
must be temporally annotated. The annotation of a condition makes explicit whether the
associated proposition must hold at the start of the interval (the point at which the action
is applied), the end of the interval (the point at which the final effects of the action are
asserted) or over the interval from the start to the end (invariant over the duration of the
action). The annotation of an effect makes explicit whether the effect is immediate (it
happens at the start of the interval) or delayed (it happens at the end of the interval). No
other time points are accessible, so all discrete activity takes place at the identified start
and end points of the actions in the plan.
Invariant conditions in a durative action are required to hold over an interval that is
open at both ends (starting and ending at the end points of the action). These are expressed
using the over all construct seen in Figures 6 and 8. If one wants to specify that a fact p
holds in the closed interval over the duration of a durative action, then three conditions are
required: (at start p), (over all p) and (at end p).
We considered adopting the convention that over all constraints should apply to the
start and end points as well as the open interval inside the durative action, but decided
against this because it would then be impossible to express conditions that are actually
only required to hold over this open interval. Examples of actions in which conditions are
invariant only over the open interval include the action of loading a truck. The truck must
remain at the loading location throughout the loading interval, but it can start to move
away simultaneously with the loading being completed. The reason is that the start of the
72

pddl2.1: Expressing Temporal Planning Domains

drive action is non-mutex with the end of the load so there is a reasonable interpretation of
any plan in which driving starts at the instant that loading is completed. Actions that affect
an invariant condition (such as the location of the truck) can be executed simultaneously
with the end point of a durative action only if the invariant is not constrained to hold true
at the end point itself. This highlights an important difference between (over all) and (over
all and at end). If a condition is required as an end precondition as well as an invariant
condition the meaning is that any action that affects the invariant must start after the end
of the action requiring that invariant. For example, if we make (at truck location) an end
precondition of the load operator as well as an invariant, the consequence is that the truck
cannot drive away until after the instant at which the load has completed.
Note that, in our definition of the load-truck action in Figure 6, we have chosen to make
the condition (holding ?c ?o) be a start effect and an end precondition but not an invariant
condition. This means that the crane could temporarily cease to hold the cargo at some
time during the interval, as long as it is holding the cargo in time to deposit it at the end
of the loading interval. This makes the action quite flexible, enabling the exploitation of
concurrent uses of the crane where applicable.
The load-truck example shows how logical change can be wrapped up into durative
actions that encapsulate much of the detail involved in achieving an effect by a sequence
of connected activities. Naturally it would be useful to be able to combine such actions
concurrently within a plan. In the next section we consider the extent to which concurrency
is allowed and the ways in which concurrent plans are interpreted.
5.1 The Interpretation of Concurrent plans
When time is introduced into the modelling of a domain it is possible for concurrent activity
to occur in a plan. Prior to the introduction of time into pddl all plans were interpreted
as sequential — even Graphplan-concurrent plans were sequenced before being validated —
so concurrency was never an issue. In pddl2.1 plan validity can depend on exploiting
concurrency correctly. Actions can overlap and co-occur, giving rise to questions over
the interpretation of synchronous behaviour. We discuss the problems arising in precise
synchronization in Section 10. We now explain under what constraints actions can occur
concurrently within a plan involving durative actions and numeric conditions and effects.
The key difference, between durative actions in pddl2.1 and those used by planners prior
to the competition, is that we distinguish between the conditions and effects at the start
and end points of the durative interval and the invariant conditions that might be specified
to hold over the interval. That is, actions can have pre- and postconditions that are local
to the two end-points of the action, and a planner can choose to exploit a durative action
for effects it has at its start or at its end. Conditions that are invariant are distinguished
from pre-conditions, enabling the exploitation of a higher degree of concurrency than is
possible if preconditions are not distinguished from invariants, as in tgp (Smith & Weld,
1999), tpsys (Garrido, Onaindı́a, & Barber, 2001) and tp4 (Haslum & Geffner, 2001).
We discuss the consequences of these design decisions, together with several examples of
durative actions, in the following sections.
It is important to observe that our view of time is point-based rather than interval-based.
That is, we see a period of activity in terms of intervals of state separated by time points
73

Fox & Long

at which state-changing activities occur. All logical state change occurs instantaneously, at
the start or end point of a durative action. Propositions are true over half-open intervals
that are closed on the left and open on the right. Activities might change logical state
or they might update the values of numeric variables. In the discretised view of time we
allow for only a finite number of activities (which we call happenings) between any two time
points, although time itself is considered continuous and actions can be scheduled to begin
at any time point.
For a plan to be considered valid, no logical condition can be both asserted and negated
at the same instant. We impose the further constraint that no logical condition can both
be required to hold and be asserted at the same instant. Although this might seem overly
strong we claim that a plan cannot be guaranteed to be valid if the instant at which a
proposition is required is exactly the instant at which it is asserted. We require that, for an
action with precondition P to start at time t, there must be a half open interval immediately
preceding t in which P holds. This is mathematically inconsistent with P being asserted
at the instant at which it is required. We are conservative in our view of the validity of
simultaneous update of and access to a state proposition. For example, if we have two
instantaneous actions, A and B, where A has precondition P and effects (not P ) and Q,
while B has precondition P ∨ Q and effect R, we consider that an attempt to apply A and
B simultaneously in a state in which P holds is ill-defined. The reason is that, although
A switches the state from one in which P holds into one in which Q holds so one might
suppose the precondition of B to be secure, A is an abstraction of a model in which the
values of P and Q are changing and, we argue, any reliance on their values at this point of
change is unstable. We adopt a rule we call no moving targets, by which we mean that no
two actions can simultaneously make use of a value if one of the two is accessing the value
to update it — the value is a moving target for the other action to access. This rule creates
a behaviour for propositions in a planning state that is very much like the behaviour of
variables in shared memory protected by a mutex lock (such as those in POSIX threads),
with a difference between read and write access to the variable.
Validity also requires that no numeric value be accessed and updated simultaneously at
the start or end point of a durative action. In the case of discretised durative actions, all
numeric change is modelled in terms of step functions so numeric values can be accessed,
or updated, during the interval of another durative action acting on that value (we provide
examples in the following section) provided that any updates are consistent with all invariant
properties dependent on the value. In the case of continuous durative actions, values can
be simultaneously accessed and updated during the continuous process of change occurring
in the interval of an action. In both the discretised and continuous cases we allow multiple
simultaneous updates provided the update operations are commutative.
In order to implement the mutual exclusion relation we require non-zero-separation
between mutually exclusive action end points. In our view, when end points are nonconflicting they can be treated as though it is possible to execute them simultaneously
even though precise synchronicity cannot be achieved in the world. However, when end
points are mutually exclusive the planner should buffer the co-occurrence of these points
by explicitly separating them. In this way we ensure that the concurrency in the plan is at
least plausible in the world.
74

pddl2.1: Expressing Temporal Planning Domains

(:durative-action heat-water
:parameters (?p - pan)
:duration (= ?duration (/ (- 100 (temperature ?p)) (heat-rate)))
:condition (and (at start (full ?p))
(at start (onHeatSource ?p))
(at start (byPan))
(over all (full ?p))
(over all (onHeatSource ?p))
(over all (heating ?p))
(at end (byPan)))
:effect (and
(at start (heating ?p))
(at end (not (heating ?p)))
(at end (assign (temperature ?p) 100)))
)

Figure 7: A simple durative action for boiling a pan of water.

Planners can exploit considerable concurrency in a domain by ensuring only that conflicting start and end points of actions are separated by a non-zero amount. A detailed
specification of the mutual exclusion relation of pddl2.1 is given in Section 8. We further
discuss the implications of non-zero separation in Section 10.
5.2 Numeric Change within Discretised Durative Actions
This section explains how continuous change can sometimes be modelled in pddl2.1 using
durative actions with discrete effects. This is achieved by using step functions to describe
instantaneous changes at the beginnings or ends of the durations of actions. Appendix A
details the language constructs involved.
An example of a durative action, illustrating the use of numeric update operations, is
shown in Figure 7. In this example showing a water heating action, the conditions (full ?p)
and (onHeatSource ?p) must hold at the start of the interval as well as during the interval.
To model this we enter these conditions as both at start and over all constraints. The
action achieves as its start effect that the water is heating, and this condition is maintained
invariant over the whole interval of the action. This is an example of an operator that
achieves its own invariant condition, and draws attention to the fact that over all conditions
hold over an interval that is open on the left (as well as on the right).
It should be noted that the actions in Figures 7 and 8 use fixed duration specifications.
In the case of the water-boiling example this means that it is impossible to adjust the length
of time over which the pan is heated and this has an impact on the context in which the
action can be used. In particular, when an assign construct is used to update a numeric
value, it is not possible for concurrent activity to affect the same value or else the model
will be flawed. Because the water heating example uses an assign construct no concurrent
activity should affect the temperature of the water. It is the responsibility of the modeller
to ensure that the temperature is neither accessed nor updated during the interval over
which the action is executing.
75

Fox & Long

(:durative-action navigate
:parameters (?x - rover ?y - waypoint ?z - waypoint)
:duration (= ?duration (travel-time ?y ?z))
:condition (and (at start (available ?x))
(at start (at ?x ?y))
(at start (>= (energy ?x)
(* (travel-time ?y ?z) (use-rate ?x))))
(over all (visible ?y ?z))
(over all (can_traverse ?x ?y ?z)))
:effect (and (at start (decrease (energy ?x)
(* (travel-time ?y ?z) (use-rate ?x))))
(at start (not (at ?x ?y)))
(at end (at ?x ?z))))
(:durative-action recharge
:parameters (?x - rover ?w - waypoint)
:duration (= ?duration (recharge-period ?x))
:condition (and (at start (at ?x ?w))
(at start (in-sun ?w))
(at start (<= (energy ?x) (capacity ?x)))
(over all (at ?x ?w)))
:effect (at end (increase (energy ?x) (* ?duration (recharge-rate ?x)))))

Figure 8: Discretised durative actions for a rover to move between locations and to recharge.

We decided to leave it to the modeller to ensure correct behaviour of the assign construct because we did not want to forbid the modelling of truly discontinuous updates. For
example, a durative action that models the deposit of a cheque in a bank account might
have a duration of three days, with a discontinuous update to the account balance at the
end of that interval — it would be inappropriate to prevent actions from accessing the
balance during the three day period. In general, modelling continuous change with discrete
effects is open to various pitfalls. This is the price that is paid for the convenience of not
having to specify the details of the continuous processes.
The use of discretised durative actions in combination with numeric (step-function)
updates requires care in modelling. In particular, it relies on the notion of conservative
resource updating. The updating of resource levels is conservative if the consumption of
a resource is modelled as if it happens at the start of a durative action, even though it
actually happens continuously over the duration of the action, and production of a resource
is modelled as if it happens at the end of the durative action even though, again, it might
actually be produced continuously over the interval.
As an example of a discretised durative action, Figure 8 shows how the action of a
rover navigating between two points is modelled. The local precondition of the start of
the period is that the rover be at the start location. Local effects include that the rover
consumes an appropriate amount of energy and that it is at the destination. The first of
these is conservative and therefore immediate, while the second is a logical effect that occurs
at the end point. This organisation ensures that no parallel activities will consume energy
that has already been committed to the navigation activity. Similarly, the recharge action
76

pddl2.1: Expressing Temporal Planning Domains

Projected energy production
Actual energy profile
Initial Energy

Energy changing
by production and
consumption

Step function model
of energy consumption
by dig action

Final stage of digging action
Final Energy
Step function model
of energy produced
by recharge action

Zero Energy
Recharge Action
Dig Action

Figure 9: Using discrete actions to model the production and consumption of a resource. In
reality, the recharge activity produces energy continuously and the concurrent dig
activity continuously consumes it. The conservative model using step functions
requires that the energy consumed by digging must be available at the start of
that action, despite not having yet updated the model to show the additional
energy accumulated because of the part of the recharge action so far executed.
The final energy level is consistent with having used a continuous model.

only makes new charge available at the conclusion of the action, so that charge gained
cannot be exploited until after the recharging is complete. The use of conservative updates
ensures that a model does not support invalid concurrency.
Figure 9 illustrates how a recharging and a digging action (that consumes energy) would
interact under a conservative energy consumption model. This model would allow concurrent actions to consume energy provided they did not consume more energy than was left
under the conservative assumption that the dig action consumed all of its demands at
the start and the recharge action produced nothing until the end. Note that the example
assumes energy constraints but no capacity constraint.
The use of conservative updates is subtle. If there were a capacity constraint on the
energy level of the rover then one would need to consider two separate resources: the energy
itself and the space available for storage of energy. The dig action would consume energy at
the start and only produce space at the end, while the recharge action would consume space
at the start and produce charge at the end. Using this combination it would be possible to
ensure that plans did not consume either resource before it was available.
Durative actions can have conditional effects. The antecedents and consequents of a
conditional effect are temporally annotated so that it is possible to specify that the condition
be checked at start or at end, and that the effect be asserted at either of these points. The
77

Fox & Long

(:durative−action burnMatch
:parameters (?m − match ?l − location)
:duration (and (< ?duration 5) (> ?duration 0))
:condition (and (at start (have ?m))
(at start (at ?l)))
:effect (and (when (at start (dark ?l))
(and (at start (not (dark ?l)))
(at start (light ?l))))
(at start (not (have ?m)))
(at start (burning ?m))
(at end (not (burning ?m)))
(when (at start (dark ?l))
(and (at end (not (light ?l)))
(at end (dark ?l))))))
Actions

(:action pickUp
:parameters (?l − location ?o − object)
:precondition (and (at ?l)
(onFloor ?o ?l)
(light ?l))
:effect (and (not (onFloor ?o ?l))
(have ?o)))

Initial state: (onFloor coin) (have aMatch) (at basement) (dark basement)
Goal: (have coin)
Problem
Plan: 0.1 (burnMatch aMatch basement) [0.2]
0.2 (pickUp basement coin)
pickUp coin

Start burnMatch
dark basement

End burnMatch
light basement

0.1

0.2

dark basement

0.3

Plan

Figure 10: An example of a problem with a durative action useful for its start effects. The
burning match produces the light necessary to pick up the coin.

semantics makes clear that a well-formed durative action with conditional effects cannot
require the condition to be checked after the effect has been asserted. Conditional effects
arise in all pddl2.1 variants. We discuss how their occurrence in discretized durative actions
is interpreted in Section 8.1.
pddl2.1 allows the specification of duration inequalities enabling actions to be described
in which external factors can be involved in determining their temporal extent. In the
match-burning example shown in Figure 10 it can be seen that the effect at the start point
is the only one of interest, so a planner would exploit this action for its start rather than its
end effect. The duration inequality specifies that the match will burn for no longer than a
specified upper bound. The model shows that the match can be put out early if the planner
considers it appropriate. We discuss the use of duration inequalities further in Section 5.3.
78

pddl2.1: Expressing Temporal Planning Domains

5.3 Durative Actions with Continuous Effects
The objective of discrete durative actions is to abstract out continuous change and concentrate on the end points of the period over which change takes place. The syntax allows
precise specification of the discrete changes at the end points of durative actions. However,
when a plan needs to manage continuously changing values, as well as discretely changing
ones, the durative action language and semantics need to be more powerful. General durative actions can have continuous as well as discrete effects. These increase, or decrease,
some numeric variable according to a specified rate of change over time for that variable.
When determining how to achieve a goal a planner must be able to access the values of these
continuous quantities at arbitrary points on the time-line of the plan. We use #t to refer
to the continuously changing time from the start of a durative action during its execution.
For example, to express the fact that the fuel level of a plane, ?p, decreases continuously,
as a function of the consumption rate of ?p, we write:
(decrease (fuel-level ?p) (* #t (consumption-rate ?p)))

This is distinctly different from:
(at end (decrease

(fuel-level ?p)
(* (flight-time ?a ?b) (consumption-rate ?p))))

because the latter is a single update happening at the end point of the flight action, whilst
the former allows the correct calculation of the fuel level of the plane at any point in that
interval. The former is a continuous effect, whilst the latter is a discrete one. Continuous
effects are not temporally annotated because they can be evaluated at any time during the
interval of the action. #t is local to each durative action, so that each durative action
has access to a purely local “clock”. Another way to interpret the expression representing
continuous change is as a differential equation:
d
(fuel-level ?p) = (consumption-rate ?p)
dt
We chose to use the #t symbol instead of a differential equation because it is possible for two
concurrent actions to be simultaneously modifying the same quantity. In that case, the use
of differential equations would actually form an inconsistent pair of simultaneous equations,
rather than having the intended effect of a combined contribution to the changing value of
the quantity. Although all of the expressions describing continuous change take the form of a
product of #t and some quantity, it is possible to express complex change using them with
interdependent concurrent effects. For example, acceleration arises by simply increasing
distance using a quantity describing velocity, while at the same time increasing velocity
using a quantity describing acceleration. When dependencies between the changing terms
include mutual dependencies between terms then the differential equations that arise can
lead to continuous change dictated by exponential, logarithmic and exponential functions.
A plan containing continuous durative actions can assign to, consult, and continuously
modify the same numeric variables concurrently (see Example 1).
In Figures 12 and 14 the discrete and continuous actions for heating a pan of water are
presented (this simple model ignores heat loss). The discrete action presented in Figure 12
modifies the version presented in Figure 7 by the use of a duration inequality constraint.
79

Fox & Long

Example 1 In the flying and refuelling example shown in Figure 11 it can be seen
that the invariant condition, that the fuel-level be greater than (or equal to) zero
during the flight, has to be maintained whilst the fuel is continuously decreasing. This
could be expressed with discrete durative actions by abstracting out the continuous
decrease and making the final value available at the end point of the flight. However,
if a refuel operation happens during the flight time (in mid-air) then the fuel level
after the flight will need to be calculated by taking into account both the continuous
rate of consumption and the refuel operation. A discrete action could not calculate
the fuel-level correctly because it would only have access to the distance between
the source and destination of the flight, together with the rate of consumption, to
determine the final fuel level. In order to calculate the fuel level correctly it is
necessary to determine the time at which the refuel takes place, and to use the
remaining flight-time to calculate the fuel consumed. Discrete durative actions do
not give access to time points other than their own start and end points.
Discrete durative actions can be used to express the desired combinations of flying
and refuelling by providing additional durative actions, such as fly-and-refuel, that
encapsulate all of the interactions just described and end up calculating the fuel level
correctly. However, this approach requires more of the domain designer than it does
of the planner — the domain designer must anticipate every useful combination of
behaviours and ensure that appropriate encapsulations are provided.
In contrast with the discrete form, the continuous action, in which the fuel consumption effect is given in terms of #t, is powerful enough to express the fact that the
mid-flight refuelling of the plane affects the final fuel level in a way consistent with
maintaining the invariant of the fly action.

(:durative-action fly
:parameters (?p - airplane ?a ?b - airport)
:duration (= ?duration (flight-time ?a ?b))
:condition (and (at start (at ?p ?a))
(over all (inflight ?p))
(over all (>= (fuel-level ?p) 0)))
:effect (and (at start (not (at ?p ?a)))
(at start (inflight ?p))
(at end (not (inflight ?p)))
(at end (at ?p ?b))
(decrease (fuel-level ?p)
(* #t (fuel-consumption-rate ?p)))))
(:action midair-refuel
:parameters (?p)
:precondition (inflight ?p)
:effect (assign (fuel-level ?p) (fuel-capacity ?p)))

Figure 11: A continuous durative action for flying.

80

pddl2.1: Expressing Temporal Planning Domains

(:durative-action heat-water
:parameters (?p - pan)
:duration (at end (<= ?duration (/ (- 100 (temperature ?p))
(heat-rate))))
:condition (and (at start (full ?p))
(at start (onHeatSource ?p))
(at start (byPan))
(over all (full ?p))
(over all (onHeatSource ?p))
(over all (heating ?p))
(at end (byPan)))
:effect (and
(at start (heating ?p))
(at end (not (heating ?p)))
(at end (increase (temperature ?p)
(* ?duration (heat-rate)))))
)

Figure 12: A discrete durative action for heating a pan of water, using a variable duration.

Duration inequalities add significant expressive power over duration equalities. Duration
constraints that express inequalities are associated with an additional requirements flag
because of the extended expressiveness over fixed-duration discrete durative actions.
In both actions, the logical post-condition of the start of the period is that the pan is
heating. The conditions that the pan be heating, full and on the heat source are invariant,
although the presence of the agent (by the pan) is only a local precondition of the two
end-points and is not invariant. In the first action the duration is modelled by expressing
the following duration inequality constraint:
(at end (<= ?duration (/ (- 100 (temperature ?p)) (heat-rate))))

and the effect at the end-point of the discrete durative action is that the temperature
of the pan is increased by (* ?duration (heat-rate)) (where heat-rate is a domain
constant). In the continuous action of Figure 14 the duration constraint is unnecessary
since the invariant
(over all (<= (temperature ?p) 100))

is added to ensure that the pan never exceeds boiling.
The durative action in Figure 12 models the heating pan in the face of possible concurrent activities affecting the temperature. The duration inequality allows the planner to
adapt the duration to take account of other temperature-affecting activity in a way that
is not possible when the duration is specified using an equality constraint. The duration
constraint ensures that the temperature never exceeds boiling by checking, as a precondition for the updating activity, that the computed temperature increase can be executed
without exceeding the boiling point. If this temperature increase would exceed boiling the
plan is invalid. The temperature at the end of the interval of execution is computed from
the current temperature and the heating rate, together with the duration over which the
heating action has been active (see further discussion in Example 2).
81

Fox & Long

Example 2 If a plan attempts to further heat the pan (say by applying a blowtorch
to the pan), during the heat-water interval then, provided that the concurrent action
ends before the end of the heat-water action, the duration constraint will be seen
to have been violated if the duration has been chosen so that the overall increase
in temperature would exceed boiling. If the concurrent activity ends simultaneously
with the heat-water action then the no-moving-targets rule would be violated because
the duration constraint would attempt to access the temperature at the same time
point as the concurrent action attempted to update it.
Figure 13 depicts these two situations. In this figure, apply-blowtorch is a durative
action that applies heat to an object (in this case, the pan). In part (a) of the figure
the duration constraint will be violated if the duration of the heat-water action is
sufficient to cause the temperature to increase beyond boiling when combined with
the heat increase caused by the blowtorch — in that case that the plan will be invalid.
The planner can choose a value for duration that avoids this violation. In part (b)
the plan will be determined invalid regardless of the duration of the action because
of the no-moving-targets rule. Notice that this model does not attempt to model the
consequences of continued heating of the pan after the boiling point, so plans with
actions that cause this to occur are simply invalid. However, pddl2.1 can be used
to model more of the physical situation, so that the consequences are explicit and the
planner can choose to exploit them or avoid them accordingly.

(a)

(b)

heat−water

apply−blowtorch

heat−water
check duration
constraint

apply−blowtorch

increase temperature
of pan

Simultaneous change to
and consultation of
temperature

Figure 13: Heating a pan with a discrete durative action, concurrently with another heating
activity.

82

pddl2.1: Expressing Temporal Planning Domains

(:durative-action heat-water
:parameters (?p - pan)
:duration ()
:condition (and (at start (full ?p))
(at start (onHeatSource ?p))
(at start (byPan))
(over all (full ?p))
(over all (onHeatSource ?p))
(over all (heating ?p))
(over all (<= (temperature ?p) 100))
(at end (byPan)))
:effect (and
(at start (heating ?p))
(at end (not (heating ?p)))
(increase (temperature ?p) (* #t (heat-rate))))
)

Figure 14: A continuous durative action for heating a pan of water.
The use of duration inequalities adds significant expressive power even when using discrete durative actions. For example, the plan depicted in part (a) of Figure 13, which
illustrates the use of the water-heating action shown in Figure 12 while concurrently heating the pan with a blowtorch, will be considered valid provided that there is a duration
value that satisfies the duration constraint in the water-heating action. This brings us very
close to the expressive power available with continuous durative actions because it gives
the planner the power to exploit concurrent interacting activities enacting changes on the
same numeric valued variable (see Example 3). Attempting to express continuous change
using only duration inequalities does not give precisely equivalent behaviour, because the
discretisation forces actions that access changing numeric values to be separated, by some
small temporal interval, from the actions that change those values in order to resolve their
mutual exclusion. In a continuous model this is not necessary because the true value of a
numeric variable is available for consultation at any time during the continuous process of
change.
In the discrete semantics presented in Section 8 we exploit the fact that the only changes
that can occur when a plan is executed are at points corresponding to the times of happenings, so the plan can be checked by looking at the activity focussed in this finite happening
sequence. In fact, provided continuous effects are restricted to linear functions of time
with only first order effects (which requires that no continuous effects can affect numeric
expressions contributing to the rate of change of another numeric valued variable), and invariants are restricted to linear functions of changing quantities, it is still possible to restrict
attention to the happening sequence even when using continuous actions.
Non-linear effects and higher-order rates of change create difficulties since it is possible
for an invariant to be satisfied at the end points of an interval, without having necessarily
been satisfied throughout the interval. In these cases it is no longer sufficient to insert
invariant checking actions at fixed mid-points in the happening sequence of a plan in order
to validate its behaviour. However, provided that effects are first-order and linear, and
invariants are linear in continuously changing values, then, despite the fact that arbitrary
83

Fox & Long

Example 3 It is possible with discrete durative actions, with duration inequalities,
to model the effects of adding an egg to the heating water when the water is at, say,
90 degrees. We do this by applying two heat-water actions, around an add-egg action, in such a way that the overall duration of the two heat-water actions is exactly
the duration required to boil the water from its original temperature. However, the
way the heat-water action is currently modelled means that the heat will be turned
off before the egg is added, and then turned on again to complete the heating, since
the temperature is only updated when the durative action terminates. With continuous durative actions the egg can be added whilst the single heat-water action is in
progress since the temperature of the pan is continuously updated. So, discrete durative actions with duration inequalities allow us to approximate continuous activity
by appending a finite sequence of discrete intervals in an appropriate way. The no
moving targets rule means that the end points of these intervals will be separated by
non-zero, arbitrarily small, time gaps. This is not required when using continuous
actions because, in contrast to the step-function effects of discrete actions, continuous effects are not localised at a single point.

time points within action intervals are accessible to the planner, it is only necessary to gain
access to numeric values at the start- and end-points of the actions in the plan that refer
to them, together with finitely many mid-points for invariant-checking actions. The values
are not required at all other points. This is so because continuous durative actions do not
support the modelling of exogenous events, so it is not necessary to take into account the
exogenous activity of the environment in determining the validity of a plan.
5.4 Related Approaches
Time is an important numerically varying quantity. The simplest way to reason about time
is to adopt a black box durative action model in which change happens at the ends of their
durative intervals. This is the approach taken in the language used by TGP (Smith &
Weld, 1999), for example, in which durative actions encapsulate continuous change so that
the correct values of any affected variables are guaranteed only at the end points of the
implied intervals. All of the logical and numeric effects of a durative action are enacted at
the end of the action and are undefined during the interval of its execution. All undeleted
preconditions must remain true throughout the interval. There is no syntactic distinction
between preconditions and invariant conditions in this action representation. A simplistic
way of ensuring correct action application is to prevent concurrent actions that refer to the
same facts, but this excludes many intuitively valid plans.
A more sophisticated approach allows preconditions to be annotated with time points,
or intervals, so that the requirement that a condition be true at some point, or over some
interval, within the duration of the action can be expressed. This is the approach taken in
Sapa (Do & Kambhampati, 2001). For example, using such an annotated precondition it
would be possible to express the requirement that some chemical additive be added within
two minutes of the start of a tank-filling action. If effects can also be specified to occur at
arbitrary points within the duration of the action then it is possible to express effects that
84

pddl2.1: Expressing Temporal Planning Domains

occur before the end of the specified duration. It is also possible to distinguish between
conditions that are local to specific points in the duration of the action and those that are
invariant throughout the action.
Allowing reference to finitely many time points between the start and end of actions
makes the language more complex without adding to its expressive power. Where time
points are strictly scheduled relative to the start of the action the effect can be achieved
through the use of a sequence of linked durative actions. We decided to keep pddl2.1
simple by restricting access to only the end points of actions.
In TLPlan (Bacchus & Ady, 2001) a similar, but more constrained, approach is adopted
in which actions are applied instantaneously but can have delayed effects. The delays for
effects can be arbitrary and different for each effect. However, invariants cannot be specified
because the preconditions are checked at the instant of application and subsequent delayed
effects are separated from the action which initiated them.
Several planners have been developed to use networks of temporal constraints (Ghallab
& Laruelle, 1994; Jonsson, Morris, Muscettola, & Rajan, 2000; El-Kholy & Richards, 1996)
to handle temporal structure in planning problems. Efficient algorithms exist for handling
such constraints (Dechter, Meiri, & Pearl, 1991) which make them practical for managing
large networks. The domain models constructed using pddl2.1 certainly lend themselves
to treatment by similar techniques, but are not constrained to be handled in this way.

6. Introduction to the Semantics of pddl2.1
In Sections 7 and 8 we provide a formal semantics for the numeric extension and temporal
extension of pddl2.1. Together these sections contain 20 definitions. The lengthy treatment
is necessary because the semantics we have developed adds four significant extensions over
classical planning and the semantics Lifschitz developed for strips (Lifschitz, 1986). These
are:
• the introduction of time, so that plans describe behaviour relative to a real time line;
• related to the first extension, the treatment of concurrency — actions can be executed
in parallel, which can lead to plans that contain concurrent interacting processes
(although these processes are encapsulated in durative actions in pddl2.1);
• an extension to handle numeric-valued fluents;
• the use of conditional effects, both alone and in conjunction with all of the above
extensions.
The semantics is built on a familiar state-transition model. The requirements of the semantics can be reduced to four essential elements.
1. To define what is a state. The introduction of both time and numeric values complicate
the usual definition of a state as a set of atoms.
2. To define when a state satisfies a propositional formula representing a goal condition
or precondition of an action. An extension of the usual interpretation of a state as a
valuation in which an atom is true if and only if the atom is in the state (the Closed
World Assumption) is required in order to handle the numeric values in the state.
85

Fox & Long

3. To define the state transition induced by application of an action. The update rule
for the logical state must be supplemented with an explanation of the consequences
for the numeric part of the state.
4. To define when two actions can be applied concurrently and how their concurrent
application affects the application of those actions individually.
The structure of the definitions is as follows. Definitions 1 to 15, given in Section 7,
define what it means for a plan to be valid when the plan consists of only non-durative
actions. Definitions 1 to 6 set up the basic terminology, the foundational structures and
the framework for handling conditional effects and primitive numeric expressions. Definition 2 meets the first requirement identified above, defining states. Definition 9 meets the
second requirement, defining when a goal description is satisfied in a state. Definition 11
defines a simple plan, extending the classical notion of a sequence of actions by adding
time. Definitions 12 meets the fourth requirement, by defining when two actions cannot be
executed concurrently. Definition 13 meets the third requirement, defining what we mean
by execution of actions, including concurrent execution of actions. Definitions 14 and 15
define the execution of a plan and what it means for a plan to be valid, given the basis laid
in the previous definitions.
In Section 8 the semantics is extended to give meaning to durative actions. We begin
with Definition 16, which defines ground durative actions analogously to Definition 6 for
simple (that is, non-durative) actions. Similarly, Definition 17 parallels the definition of a
simple plan (Definition 11) and Definitions 19 and 20 parallel those for the execution and
validity of simple plans (Definitions 14 and 15). Definition 18 is the critical definition for
the semantics of plans with durative actions, supplying a transformation of temporal plans
into simple plans, whose validity according to the semantics of purely simple plans, can be
used to determine the validity of the original temporally structured plans.

7. The Semantics of Simple Plans
The semantics we define in this section extends the essential core of Lifschitz’ strips semantics (1986) to handle temporally situated actions, possibly occurring simultaneously,
with numeric and conditional effects.
Definition 1 Simple Planning Instance A simple planning instance is defined to be a
pair
I = (Dom, P rob)
where Dom = (F s, Rs, As, arity) is a 4-tuple consisting of (finite sets of ) function symbols,
relation symbols, actions (non-durative), and a function arity mapping all of these symbols
to their respective arities. P rob = (Os, Init, G) is a triple consisting of the objects in the
domain, the initial state specification and the goal state specification.
The primitive numeric expressions of a planning instance, P N Es, are the terms constructed from the function symbols of the domain applied to (an appropriate number of )
objects drawn from Os. The dimension of the planning instance, dim, is the number of
distinct primitive numeric expressions that can be constructed in the instance.
86

pddl2.1: Expressing Temporal Planning Domains

The atoms of the planning instance, Atms, are the (finitely many) expressions formed
by applying the relation symbols in Rs to the objects in Os (respecting arities).
Init consists of two parts: Initlogical is a set of literals formed from the atoms in Atms.
Initnumeric is a set of propositions asserting the initial values of a subset of the primitive
numeric expressions of the domain. These assertions each assign to a single primitive
numeric expression a constant real value. The goal condition is a proposition that can
include both atoms formed from the relation symbols and objects of the planning instance
and numeric propositions between primitive numeric expressions and numbers.
As is a collection of action schemas (non-durative actions) each expressed in the syntax
of pddl. The primitive numeric expression schemas and atom schemas used in these action
schemas are formed from the function symbols and relation symbols (used with appropriate
arities) defined in the domain applied to objects in Os and the schema variables.
The semantics shows how instantiated action schemas can be interpreted as state transitions, in a similar way to the familiar state transition semantics defined by Lifschitz. An
important difference is that states can no longer be seen as simply sets of propositions, but
must also account for the numeric expressions appearing in the planning instance and the
time at which the state holds. This is achieved by extending the notion of state.
Definition 2 Logical States and States Given the finite collection of atoms for a planning instance I, AtmsI , a logical state is a subset of AtmsI . For a planning instance
with dimension dim, a state is a tuple in (R, P(AtmsI ), Rdim
⊥ ) where R⊥ = R ∪ {⊥} and
⊥ denotes the undefined value. The first value is the time of the state, the second is the
logical state and the third value is the vector of the dim values of the dim primitive numeric
expressions in the planning instance.
The initial state for a planning instance is (0, Initlogical , x) where x is the vector of values
in R⊥ corresponding to the initial assignments given by Initnumeric (treating unspecified
values as ⊥).
Undefined values are included in the numeric ranges because there are domains in which
some terms start undefined but can nevertheless be initialised and exploited by actions.
To interpret actions as state transition functions it is necessary to achieve two steps.
Firstly, since (in pddl2.1) plans are only ever constructed from fully instantiated action
schemas, the process by which instantiation affects the constructs of an action schema must
be defined and, secondly, the machinery that links primitive numeric expressions to elements
of the vector of real values in a state and that allows interpretation of the numeric updating
behaviours in action effects must be defined. Since the mechanisms that support the second
of these steps also affect the process in the first, the treatment of numeric effects is described
first.
Definition 3 Assignment Proposition The syntactic form of a numeric effect consists
of an assignment operator (assign, increase, decrease, scale-up or scale-down), one
primitive numeric expression, referred to as the lvalue, and a numeric expression (which
is an arithmetic expression whose terms are numbers and primitive numeric expressions),
referred to as the rvalue.
87

Fox & Long

The assignment proposition corresponding to a numeric effect is formed by replacing
the assignment operator with its equivalent arithmetic operation (that is (increase p q)
becomes (= p (+ p q)) and so on) and then annotating the lvalue with a “prime”.
A numeric effect in which the assignment operator is either increase or decrease
is called an additive assignment effect, one in which the operator is either scale-up or
scale-down is called a scaling assignment effect and all others are called simple assignment
effects.
A numeric effect defines a function of the numeric values in the state to which an action
is applied determining the value of a primitive numeric expression in the resulting state.
For the convenience of a uniform treatment of numeric expressions appearing in pre- and
post-conditions, we transform the functions into propositions that assert the equality of the
post-condition value and the expression that is intended to define it. That is, rather than
writing an effect (increase p q) as a function f (p) = p + q, we write it as the proposition
(= p0 (+ p q)). The “priming” distinguishes the postcondition value of a primitive numeric
expression from its precondition value (a convention commonly adopted in describing state
transition effects on numeric values). The binding of the primitive numeric expressions to
their values in states is defined in the following definition.
Definition 4 Normalisation Let I be a planning instance of dimension dimI and let
indexI : P N EsI → {1, . . . , dim}
be an (instance-dependent) correspondence between the primitive numeric expressions and
I
.
integer indices into the elements of a vector of dimI real values, Rdim
⊥
The normalised form of a ground proposition, p, in I is defined to be the result of substituting for each primitive numeric expression f in p, the literal XindexI (f ) . The normalised
form of p will be referred to as N (p). Numeric effects are normalised by first converting
them into assignment propositions. Primed primitive numeric expressions are replaced with
their corresponding primed literals. X is used to represent the vector hX1 . . . Xn i.
In Definition 4, the replacement of primitive numeric expressions with indexed literals
allows convenient and consistent substitution of the vector of actual parameters for the
vector of literals X appearing in a state.
With the machinery supporting treatment of numeric expressions complete, it is now
possible to consider the process of instantiating action schemas. This process is managed
in two steps. The first step is to remove constructs that we treat as syntactic sugar in the
definition of a domain. These are conditional effects and quantified formulae. We handle
both of these by direct syntactic transformations of each action schema into a set of action
schemas considered to be equivalent. The transformation is similar to that described by
Gazen and Knoblock (1997). Although it would be possible to give a semantic interpretation
of the application of conditional effects directly, the transformation allows us to significantly
simplify the question of what actions can be performed concurrently.
Definition 5 Flattening Actions Given a planning instance, I, containing an action
schema A ∈ AsI , the set of action schemas f latten(A), is defined to be the set S, initially
containing A and constructed as follows:
88

pddl2.1: Expressing Temporal Planning Domains

• While S contains an action schema, X, with a conditional effect, (when P Q), create
two new schemas which are copies of X, but without this conditional effect, and conjoin
the condition P to the precondition of one copy and Q to the effects of that copy, and
conjoin (not P) to the precondition of the other copy. Add the modified copies to S.
• While S contains an action schema, X, with a formula containing a quantifier, replace
X with a version in which the quantified formula ( Q ( var1 . . . vark ) P) in X is
replaced with the conjunction (if the quantifier, Q, is forall) or disjunction (if Q is
exists) of the propositions formed by substituting objects in I for each variable in
var1 . . . vark in P in all possible ways.
These steps are repeated until neither step is applicable.
Once flattened, actions can be grounded by the usual substitution of objects for parameters:
Definition 6 Ground Action Given a planning instance, I, containing an action schema
A ∈ AsI , the set of ground actions for A, GAA , is defined to be the set of all the structures,
a, formed by substituting objects for each of the schema variables in each schema, X, in
f latten(A) where the components of a are:
• Name is the name from the action schema, X, together with the values substituted for
the parameters of X in forming a.
• Prea , the precondition of a, is the propositional precondition of a. The set of ground
atoms that appear in Prea is referred to as GPrea .
• Adda , the positive postcondition of a, is the set of ground atoms that are asserted as
positive literals in the effect of a.
• Dela , the negative postcondition of a,is the set of ground atoms that are asserted as
negative literals in the effect of a.
• NPa , the numeric postcondition of a, is the set of all assignment propositions corresponding to the numeric effects of a.
The following sets of primitive numeric expressions are defined for each ground action,
a ∈ GAA :
• La = {f |f appears as an lvalue in a}
• Ra = {f |f is a primitive numeric expression in an rvalue in a or appears in P rea }
• L∗a = {f |f appears as an lvalue in an additive assignment effect in a}
Some comment is appropriate on the last definition: an action precondition might be
considered to have two parts — its logical part and its numeric expression-dependent part.
Unfortunately, these can be interdependent. For example:
(or (clear ?x) (>= (room-in ?y) (space-for ?z)))
89

Fox & Long

might be a precondition of an action. In order to handle such conditions, we need to check
whether they are satisfied given not only the current logical state, but also the current
values of the domain numeric expressions. The inclusion of a numeric component in the
state makes it necessary to ensure the correct substitution of the numeric values for the
expressions used in the action precondition. This is achieved using the normalisation process
from Definition 4 in Definition 9. In contrast, the postcondition of an action cannot contain
interlocked numeric and logical effects, so it is possible to separate the effects into the
distinct numeric and logical components.
Definition 7 Valid Ground Action Let a be a ground action. a is valid if no primitive
numeric expression appears as an lvalue in more than one simple assignment effect, or in
more than one different type of assignment effect.
Definition 7 ensures that an action does not attempt inconsistent updates on a numeric
value. Unlike logical effects of an action which cannot conflict, it is possible to write
a syntactic definition of an action in which the effects are inconsistent, for example by
assigning two different values to the same primitive numeric expression.
Definition 8 Updating Function Let a be a valid ground action. The updating function
for a is the composition of the set of functions:
dim
{NPFp : Rdim
⊥ → R⊥ | p ∈ N P a }

such that NPFp (x) = x0 where for each primitive numeric expression x0i that does not appear
as an lvalue in N (p), x0i = xi and N (p)[X0 := x0 , X := x] is satisfied.
The notation N (p)[X0 := x0 , X := x] should be read as the result of normalising p and
then substituting the vector of actual values x0 for the parameters X0 and actual values x
for formal parameters X.
Definition 8 defines the function describing the update effects of an action. The function
ensures that all of the reals in the vector describing the numeric state remain unchanged if
they are not affected by the action (this is the numeric-state equivalent of the persistence
achieved for propositions by the strips assumption). For other values in the vector, the
normalisation process is used to substitute the correctly indexed vector elements for the
primitive numeric expressions appearing as lvalues (which are the primed vector elements
corresponding to values in the post-action state) and rvalues (the unprimed values appearing
in the pre-action state). The tests that must be satisfied in order to ensure correct behaviour
of the functions in the composition simply confirm that the arithmetic on the rvalues is
correctly applied to arrive at the lvalues. The requirement that the action be valid ensures
that the composition of the functions in Definition 8 is well-defined, since all of the functions
in the set commute, so the composition can be carried out in any order.
The various sets of primitive numeric expressions defined in the Definition 6 allow us
to conveniently express the conditions under which two concurrent actions might interfere
with one another. In particular, we are concerned not to allow concurrent assignment to the
same primitive numeric expression, or concurrent assignment and inspection. We do allow
concurrent increase or decrease of a primitive numeric expression. To allow this we will
90

pddl2.1: Expressing Temporal Planning Domains

have to apply collections of concurrent updating functions to the primitive numeric expressions. This can be allowed provided that the functions commute. Additive assignments do
commute, but other updating operations cannot be guaranteed to do so, except if they do
not affect the same primitive numeric expressions or rely on primitive numeric expressions
that are affected by other concurrent assignment propositions. It would be possible to make
a similar exception for scaling effects, but additive assignment effects have a particularly
important role in durative actions that is not shared by scaling effects, so for simplicity
we allow concurrent updates only with these effects. We use the three sets of primitive
numeric expressions to determine whether we are in a safe situation or not. Within a single
action it is possible for the rvalues and lvalues to intersect. That is, an action can update
primitive numeric expressions using current values of primitive numeric expressions that
are also updated by the same action. All rvalues will have the values they take in the state
prior to execution and all lvalues will supply the new values for the state that follows.
Definition 9 Satisfaction of Propositions Given a logical state, s, a ground propositional formula of pddl2.1, p, defines a predicate on Rdim
⊥ , Num(s, p), as follows:
Num(s, p)(x)

iff

s |= N (p)[X := x]

where s |= q means that q is true under the interpretation in which each atom, a, that is not
a numeric comparison, is assigned true iff a ∈ s, each numeric comparison is interpreted
using standard equality and ordering for reals and logical connectives are given their usual
interpretations. p is satisfied in a state (t, s, X) if Num(s, p)(X).
Comparisons involving ⊥, including direct equality between two ⊥ values are all undefined, so that enclosing propositions are also undefined and not satisfied in any state.
Definition 10 Applicability of an Action Let a be a ground action. a is applicable in
a state s if the P rea is satisfied in s.
7.1 Semantics of a Simple Plan
A simple plan, in pddl2.1, is a sequence of timed actions, where a timed action has the
following syntactic form:
t : (action p1 . . . pn )
In this notation t is a positive rational number in floating point syntax and the expression
(action p1 . . . pn ) is the name and actual parameters of the action to be executed at that
point in time. In more complex plans simple and durative actions, with or without numericvalued effects or preconditions, can co-occur — the semantics of such plans is discussed in
Section 8. No special separators are required to separate timed actions in the sequence
and the actions are not required to be presented in time-sorted order. It is possible for
multiple actions to be given the same time stamp, indicating that they should be executed
concurrently. It should be emphasised that the earliest point at which activity occurs within
a plan must be strictly after time 0. This constraint follows from the decision to make the
initial state be the state existing at time 0, together with the decision, in the semantics,
that actions have their effects in the interval that is closed on the left, starting at the time
when the action is applied, while preconditions are tested in the interval that is open on the
right that precedes the action.
91

Fox & Long

In order to retain compatibility with the output of current planners the following concession is made: if the plan is presented as a sequence of actions with no time points, then
it is inferred that the first action is applied at time 1 and the succeeding actions apply in
sequence at integral time points one unit apart.
A simple plan is a slight generalisation of the more familiar strips-style classical plan,
since actions are labelled with the time at which they are to be executed.
Definition 11 Simple Plan A simple plan, SP , for a planning instance, I, consists of a
finite collection of timed simple actions which are pairs (t, a), where t is a rational-valued
time and a is an action name.
The happening sequence, {ti }i=0...k for SP is the ordered sequence of times in the set
of times appearing in the timed simple actions in SP . All ti must be greater than 0. It is
possible for the sequence to be empty (an empty plan).
The happening at time t, Et , where t is in the happening sequence of SP , is the set of
(simple) action names that appear in timed simple actions associated with the time t in SP .
A plan thus consists of a sequence of happenings, each being a set of action names applied
concurrently at a specific time, the sequence being ordered in time. The times at which these
happenings occur forms the happening sequence. It should be noted that action names are
ambiguous when action schemas contain conditional effects — the consequence of flattening
is to have split these actions into multiple actions with identical names, differentiated by
their preconditions. However, at most one of each set of actions with identical names can
be applicable in a given logical state, since the precondition of each action in such a set
will necessarily be inconsistent with the precondition of any other action in the set, due to
the way in which the conditional effects are distributed between the pairs of action schemas
they induce.
In order to handle concurrent actions we need to define the situations in which the
effects of those actions are consistent with one another. This issue was first discussed in
Section 5.1. The mutual exclusion rule for pddl2.1 is an extension of the idea of action
mutex conditions for GraphPlan (Blum & Furst, 1995). The extension handles two extra
features: the extended expressive power of the language (to include arbitrary propositional
connectives) and the introduction of numeric expressions. We make a very conservative
condition for actions to be executed concurrently, which ensures that there is no possibility
of interaction. This rules out cases where intuition might suppose that concurrency is
possible. For example, the actions:
(:action a
:precondition (or p q)
:effect (r))
(:action b
:precondition (p)
:effect (and (not p) (s)))

could, one might suppose, be executed simultaneously in a state in which both p and q hold.
The following definition asserts, however, that the two actions are mutex. The reason we
have chosen such a constrained definition is because checking for mutex actions must be
92

pddl2.1: Expressing Temporal Planning Domains

tractable and handling the case implied by this example would appear to require checking
the consequence of interleaving preconditions and effects in all possible orderings. The
condition on primitive numeric expressions has already been discussed — it determines
that the update effects can be executed concurrently and that they do not affect values
which are then tested by preconditions (regardless of whether the results of those tests
matter to the satisfaction of their enclosing proposition). This is the rule of no moving
targets: no concurrent actions can affect the parts of the state relevant to the precondition
tests of other actions in the set, regardless of whether those effects might be harmful or
not. It might be considered odd that the preconditions of one action cannot refer to literals
in the add effects of a concurrent action. We require this because preconditions can be
negative, in which case their interaction with add effects is analogous to the interaction
between positive preconditions and delete effects. The no moving targets rule makes the
cost of determining whether a set of actions can be applied concurrently polynomial in the
size of the set of actions and their pre- and post-conditions.
Definition 12 Mutex Actions Two grounded actions, a and b are non-interfering if
GP rea ∩ (Addb ∪ Delb ) = GP reb ∩ (Adda ∪ Dela ) = ∅
Adda ∩ Delb = Addb ∩ Dela = ∅
La ∩ Rb = Ra ∩ Lb = ∅
La ∩ Lb ⊆ L∗a ∪ L∗b
If two actions are not non-interfering they are mutex.
The last clause of this definition asserts that concurrent actions can only update the
same values if they both do so by additive assignment effects.
We are now ready to define the conditions under which a simple plan is valid. We can
separate the executability of a plan from whether it actually achieves the intended goal.
We will say that a plan is valid if it is executable and achieves the final goal. Executability
is defined in terms of the sequence of states that the plan induces by sequentially executing
the happenings that it defines.
Definition 13 Happening Execution Given a state, (t, s, x) and a happening, H, the
activity for H is the set of grounded actions
AH = {a|the name for a is in H, a is valid and P rea is satisfied in (t, s, x)}
The result of executing a happening, H, associated with time tH , in a state (t, s, x) is
undefined if |AH | =
6 |H| or if any pair of actions in AH is mutex. Otherwise, it is the state
0
0
(tH , s , x ) where
[
[
s0 = (s \
Dela ) ∪
Adda
a∈AH

and

x0

a∈AH

is the result of applying the composition of the functions {NPFa | a ∈ AH } to x.

Since the functions {NPFa | a ∈ AH } must affect different primitive numeric expressions,
except where they represent additive assignment effects, these functions will commute and
93

Fox & Long

therefore the order in which the functions are applied is irrelevant. Therefore, the value of
x0 is well-defined in this last definition. The requirement that the activity for a happening
must have the same number of elements as the happening itself is simply a constraint that
ensures that each action name in the happening leads to a valid action that is applicable in
the appropriate state. We have already seen that conditional effects induce the construction
of families of grounded actions, but that at most one of each family can be applicable in
a state. If none of them is applicable for a given name, then this must mean that the
precondition is unsatisfied, regardless of the conditional effects. In this case, we are asserting
that the attempt to apply the action has undefined interpretation.
Definition 14 Executability A simple plan, SP , for a planning instance, I, is executable
if it defines a happening sequence, {ti }i=0...k , and there is a sequence of states, {Si }i=0...k+1
such that S0 is the initial state for the planning instance and for each i = 0 . . . k, Si+1 is
the result of executing the happening at time ti in SP .
The state Sk+1 is called the final state produced by SP and the state sequence {Si }i=0...k+1
is called the trace of SP . Note that an executable plan produces a unique trace.
Definition 15 Validity of a Simple Plan A simple plan (for a planning instance, I) is
valid if it is executable and produces a final state S, such that the goal specification for I is
satisfied in S.

8. The Semantics of Durative Actions
Plans with durative actions with discrete effects can be given a semantics in terms of the
semantics of simple plans. Handling durative actions that have continuous effects is more
complex — we discuss this further in Section 9.
Durative actions appearing in a plan must be given with an additional field indicating
the duration. This is given with the syntax:
t : (action p1 . . . pn ) [d]
where d is a rational valued duration, written in floating point syntax.
Durative actions are introduced into the framework we have defined so far by generalising
Definition 1 to include durative action schemas. The definition of the grounded action must
now be extended to define the form of grounded durative actions. However, this definition
can be given in such a way that we associate with each durative action two simple (nondurative) actions, corresponding to the end points of the durative action. These simple
actions can, together, simulate almost all of the behaviour of the durative action. The only
aspects that are not captured in this pair of simple actions are the duration of the durative
action and the invariants that must hold over that duration. These two elements can,
however, be simply handled in a minor extension to the semantics of simple plans, and this
is the approach we adopt. By taking this route we avoid any difficulties in establishing the
effects of interactions between durative actions — this is all handled by the semantics for the
concurrent activity within a simple plan. As we will see, one difficulty in this account is the
handling of durative actions with conditional effects that contain conditions and effects that
are associated with different times or conditions that must hold over the entire duration of
94

pddl2.1: Expressing Temporal Planning Domains

the action. Since these cases complicate the semantics we will postpone treatment of them
until the next section and begin with durative actions without conditional effects.
The mapping from durative actions to non-durative actions has the important consequence that the mutex relation implied between non-durative actions is (advantageously)
weaker than the strong mutex relation used in, for example, TGP (Smith & Weld, 1999).
Two durative actions can be applied concurrently provided that the end-points of one action
do not interact either with the end-points (if simultaneous) or the invariants of the other
action.
Definition 16 Grounded Durative Actions Durative actions are grounded in the same
way as simple actions (see Definition 6), by replacing their formal parameters with constants from the planning instance and expanding quantified propositions. The definition of
durative actions requires that the condition be a conjunction of temporally annotated propositions. Each temporally annotated proposition is of the form (at start p), (at end p)
or (over all p), where p is an unannotated proposition. Similarly, the effects of a durative action (without continuous or conditional effects) are a conjunction of temporally
annotated simple effects.
The duration field of DA defines a conjunction of propositions that can be separated into
DA and DC DA , the duration conditions for the start and end of DA, with terms being
DCstart
end
arithmetic expressions and ?duration. The separation is conducted in the obvious way,
DA and at end conditions into DC DA .
placing at start conditions into DCstart
end
Each grounded durative action, DA, with no continuous effects and no conditional effects
defines two parameterised simple actions DAstart and DAend , where the parameter is the
?duration value, and a single additional simple action DAinv , as follows.
DAstart (DAend ) has precondition equal to the conjunction of the set of all propositions, p, such that (at start p) ((at end p)) is a condition of DA, together with
DA (DC DA ), and effect equal to the conjunction of all the simple effects, e, such that
DCstart
end
(at start e) ((at end e)) is an effect of DA (respectively).
DAinv , is defined to be the simple action with precondition equal to the conjunction of
all propositions, p, such that (over all p) is a condition of DA. It has an empty effect.
Every conjunct in the condition of DA contributes to the precondition of precisely one
of DAstart , DAend or DAinv . Every conjunct in the effect of DA contributes to the effect of
precisely one of DAstart or DAend . For convenience, DAstart (DAend , DAinv ) will be used
to refer to both the entire (respective) simple action and also to just its name.
The actions DAstart and DAend are parameterised by ?duration and this parameter
must be substituted with the correct duration value in order to arrive at the two simple
actions corresponding to the start and end of a durative action.
Definition 17 Plans A plan, P , with durative actions, for a planning instance, I, consists
of a finite collection of timed actions which are pairs, each either of the form (t, a), where t is
a rational-valued time and a is a simple action name – an action schema name together with
the constants instantiating the arguments of the schema, or of the form (t, a[t0 ]), where t is
a rational-valued time, a is a durative action name and t0 is a non-negative rational-valued
duration.
95

Fox & Long

Definition 18 Induced Simple Plan If P is a plan then the happening sequence for P
is {ti }i=0...k , the ordered sequence of time points formed from the set of times1
{t | (t, a) ∈ P or (t, a[t0 ]) ∈ P or (t − t0 , a[t0 ]) ∈ P }
The induced simple plan for a plan P , simplify(P ), is the set of pairs defined as follows:
• (t, a) for each (t, a) ∈ P where a is a simple (non-durative) action name.
• (t, astart [?duration := t0 ]) and (t + t0 , aend [?duration := t0 ]) (these expressions are
simple timed actions – the square brackets denote substitution of t0 for ?duration in
this case) for all pairs (t, a[t0 ]) ∈ P , where a is a durative action name.
• ((ti + ti+1 )/2, ainv ) for each pair (t, a[t0 ]) ∈ P and for each i such that t ≤ ti < t + t0 ,
where ti and ti+1 are in the happening sequence for P .
The process of transforming a plan into a simple plan involves introducing actions to
represent the end points of the intervals over which the durative actions in the plan are
applicable. Duration constraints convert into simple preconditions on start or end actions,
requiring the substitution of a numeric value for the ?duration field to complete the conversion into simple actions. The complication to this process is that invariants cannot
be associated with the end points, but must be checked throughout the interval. This is
achieved by adding to the simple plan a collection of special actions responsible for checking the invariants. These actions are added between each pair of happenings in the original
plan lying between the start and end point of the durative action. Because the semantics of
simple plans requires that the preconditions of actions in the plan be satisfied, even though
they might have no effects, the consequence of putting these monitoring actions into the
simple plan is to ensure that the original plan is judged valid only if the invariants remain
true, firstly, after the start of the durative action and, subsequently, after each happening
that occurs throughout the duration of the durative action. One possibility is to make these
monitoring actions occur at the same times as the updating actions, but this would require
values to be accessed at the same time as they might be being updated, violating the no
moving targets rule. In order to avoid this problem the monitoring actions are interleaved
with the updating actions by inserting them midway between pairs of successive happenings
in the interval over which each durative action is executed. Only happenings in the original plan need be considered when carrying out this insertion, since the invariant-checking
actions themselves cannot have any effect on the states in which they are checked.
Alternative treatments of invariants are possible, but an important advantage of the
approach we have taken is that the semantics rests, finally, on a state-transition model in
a form that is familiar to the planning community. That is, plans can be seen as recipes
for state-transition sequences, with each state-transition being a function from the current
state of the world to the next. However, durative actions complicate this picture because
they rely on a commitment, once a durative action has been started, to follow it through to
completion. That commitment involves some sort of communication across the duration of
the plan. The communication can be managed by structures outside the plan, that examine
1. Care should be taken in reading this definition — the last disjunct allows the time corresponding to the
end of execution of a durative action to be included as a happening time.

96

pddl2.1: Expressing Temporal Planning Domains

the trace, or by artificial modification of the plan itself to ensure that states carry extra
information from the start to the end of the durative action. The latter approach has the
disadvantage that as durative actions become more complex the artificial components that
must be added to the plan become more intrusive. This is particularly apparent in the
treatment of conditional effects that require conditions tested at the start of a durative
action, or across its duration, but effects that are triggered at the end, since these cases
require some sort of “memory” in the state to remember the status of the tested conditions
from the start of the durative action to the end point. These memory conditions allow
us to avoid embedding an entire execution history in a state by substituting an ad hoc
memory of the history for just those propositions and at just those times it is required. The
management of conditional effects of this form, in the mapping from durative actions to
simple actions, is discussed further in Section 8.1.
We can now conclude the definitions supporting the validity of a plan with durative
actions.
Definition 19 Executability of a Plan A plan, P (for a planning instance), is executable if the induced simple plan for P , simplify(P ) is executable, producing the trace
{Si = (ti , si , vi )}i=0...k .
Definition 20 Validity of a Plan A plan, P (for a planning instance), is valid if it is
executable and if the goal specification is satisfied in the final state produced by its induced
simple plan.
8.1 Durative Actions with Conditional Effects
We now explain how the mapping described in the previous section is extended to deal with
durative actions containing conditional effects.
First, we observe that temporally annotated conditions and effects can be accumulated,
because the temporal annotation distributes through logical conjunction. Therefore, we
can convert conditional effects so that their conditions are simple conjunctions of at most
one at start condition, at most one at end condition and at most one over all condition. It
should be noted that we do not allow logical connectives other than conjunction in combining temporally annotated propositions. Allowing other connectives would create significant
further complexity in the semantics and create potentially paradoxical opportunities for
communication from future states to earlier states. Similarly to conditions, durative action
effects can be reduced to a conjunction of at most one at start effect and at most one at end
effect. Treatment of conditional effects then divides into three cases. The first case is very
straightforward: any effect in a durative action of the form (when (at t p) (at t q)),
where the condition and the effect bear the same single temporal annotation, can be transformed into a simple conditional effect of the form (when p q) attached to the start or end
simple action according to whether t is start or end. Since this case is straightforward we
will not explicitly extend the previous definitions to cope with it. The second case is one in
which the condition of a condition effect has at start conditions and the effect has at end
effects.
Note that we consider conditional effects in which the effects occur at the start, but
with conditions dependent on the state at the end or over the duration of the action, to be
97

Fox & Long

meaningless. This is because they reverse the expected behaviour of causality, where cause
precedes effect. In any attempt to validate a plan by constructing a trace such reversed
causality would be a huge problem, since we could not determine the initial effects of applying a durative action until we had seen what conditions held over the subsequent interval
and conclusion of its activity, but, equally, we could not see what the effects of activity during the interval would be without seeing the initial effects of applying the durative action.
This paradox is created by the opportunity for an action to change the past.
To handle this second case we need to modify the state after the start of the durative action to “remember” whether the start conditions were satisfied and communicate this to the
end of the durative action where it can then be simply looked up in the (then) current state
to determine whether the conditional effect should be applied. We apply a transformation to
conditional effects of the form (when (and (at start ps) (at end pe)) (at end q))
into a conditional effect added to the start simple action, (when ps (Mps )), and a conditional effect added to the end simple action, (when (and pe (Mps )) q), where Mps is a
special new proposition, unique to the particular conditional effect of the particular application of the durative action being transformed. By ensuring that this proposition is unique
in this way, there is no possibility of any other action in the plan interfering with it, so it
represents an isolated memory of the fact that ps held in the state at which the durative
action was started. If a conditional effect does not have at end conditions, the same transformation can be applied, simply ignoring pe in the previous discussion. Figure 15 depicts
the transformation of a single durative action, A, with a conditional effect, into a collection
of level 2 actions, complete with the appropriate “memory” proposition (in this case called
P ∗ ).
The importance of the memory introduced in this transformation is explained in Figures 16 and 17. Figure 16 shows the ambiguity that results from not remembering how a
state, on the trajectory of a plan, was reached. The figure illustrates that if one is in a
state (P, Q, ¬R) at the point when durative action A (as described in Figure 15) ends, it is
impossible to determine from the state alone whether R should be added or not. This is
because it is possible to have reached the state (P, Q, ¬R) by at least two different paths,
with at least one path having seen A started in a state in which P held and at least one path
having seen A started in a state in which P did not hold (using an action, achieve-P , with P
as its only effect). The state (P, Q, ¬R) does not contain any information to disambiguate
which path was used to reach it, and hence cannot determine the correct value of R after
A ends.
The third, and final, case is where the durative action has conditional effects of the form:
(when (and (at start ps) (over all pi) (at end pe)) (at end q)).

Again, if the effect has no at start or at end conditions the following transformation can be
applied simply ignoring ps or pe as appropriate. In this case we need to construct a transformation that “remembers” not only whether ps held in the state at which the durative
action is first applied, but also whether pi holds throughout the interval from the start to
the end of the durative action. Unlike the invariants of durative actions, these conditions
are not required to hold for the plan to be valid, but only determine what effects will occur at
the end of the durative action. The idea is to use intervening monitoring actions, rather as
we did for invariants in definition 18. This is achieved by adding a further effect to the start
98

pddl2.1: Expressing Temporal Planning Domains

Initial Durative Action
(:durative-action A
:parameters ()
:duration (= ?duration 2)
:condition ()
:effect (when (and (at start P) (at end Q))
(at end R)))

Transformation to simple actions
(:action A-start
:parameters ()
:precondition ()
:effect (when P P*))

(:action A-end
:parameters ()
:precondition ()
:effect (when (and P* Q) R))

Expansion of conditional effects
(:action A-start
:parameters ()
:precondition (P)
:effect (P*))

(:action A-start
:parameters ()
:precondition (not P)
:effect ())

(:action A-end
:parameters ()
:precondition (and P* Q)
:effect (R))

(:action A-end
:parameters ()
:precondition (or (not P*) (not Q))
:effect ())

Transformation of Plan to Simple Plan
Plan

Plan

1:A[2]

1:A-start
3:A-end

Figure 15: Conversion of a durative action into non-durative actions and their grounded
forms.

99

Fox & Long

P,Q,~R

1:A-start
3:A-end
P,Q,~R

P,Q
R?

1:A-start
~P,Q

2:achieve-P

~P,Q
~R

~R

Figure 16: Flawed state space resulting from failure to record the path traversed when conditional effects span the interval of a durative action. The arc labelled achieve-P
indicates the possible application of some action that achieves the proposition
P.
1:A-start
P,Q
~R,~P*

P*,P
Q,~R

3:A-end

2:achieve P
~P,Q
~R,~P*

1:A-start

~P,Q
~R,~P*

P,Q
R,P*
3:A-end
P,Q,
~R,~P*

P,Q
~R,~P*

Figure 17: Correct state space showing use of “memory” proposition P*. The arc labelled
achieve P indicates the possible application of some action that achieves the
proposition P.

action: (Mpi ). Then, the monitoring (simple) actions that are required have no precondition, but a single conditional effect: (when (and (Mpi ) (not pi)) (not (Mpi ))). Once
again, Mpi is a special new proposition unique to the conditional effect for the application
instance of the durative action being transformed. The monitoring actions are added at all
the intermediate points that are used for the monitoring actions in Definition 18. The same
transformation used in the second case above is required again for the at start condition,
ps, so (when ps (Mps )) is added as a conditional effect to the start simple action. Finally,
we add a conditional effect to the end (simple) action: (when (and (Mps ) (Mpi ) pe) q).
The effect of this machinery is to ensure that if the proposition pi becomes false at any time
between the start and end of the durative action then Mpi will be deleted, but otherwise at
the end of the durative action Mps will hold precisely if ps held at the start of the action
and Mpi will hold precisely if pi has held over the entire duration of the durative action.
Therefore, the conditional effect of the end action achieves the intuitively correct behaviour
of asserting its conditional effect precisely when the at start condition held at the start of
the durative action, the at end condition holds at the end of the durative action and its
over all condition has held throughout the duration of the action.
The addition of these new memory-checking actions means that it is no longer true
to claim that the added actions cannot change the state. However, memory propositions
are unique to the task of communication for a single action instance, so the effects that
memory-checking actions might have on these have no implications for other invariants.
100

pddl2.1: Expressing Temporal Planning Domains

9. The Semantics of Continuous Durative Actions
The introduction of continuous durative actions complicates the semantics. It is no longer
possible to handle invariants by insertion of simple actions between other happenings in a
plan to test their continued satisfaction. In fact, continuous effects can, in principle, cause
an invariant to be satisfied over some parts of an interval and not over others. Ignoring
invariants for a moment, updates to numeric values caused by continuous effects can be
applied as discrete updates at time points within the interval over which they apply. These
updates behave slightly differently to the discrete updates we have seen in durative actions
with discrete effects, since it is possible for a continuous update to affect a variable that is
concurrently affected by a discrete update, or examined by a precondition, without creating
an inconsistency. For example, if the water heating action in Figure 14 is applied with the
concurrent addition of an egg to the pan with a precondition that the temperature of the
water is between 90 and 95 degrees then the value of the temperature can be examined at
the moment of application of the action adding the egg. This is because the temperature
change is actually happening over the interval between the start of the heating and the
point at which the egg is added, rather than as a discrete update at the point the egg is
added. The temperature is not actually changed at the instant of the addition of the egg.
In this section we summarise the semantics for continuous actions. Where the semantics
for discrete durative actions is defined in terms of the familiar state-transition semantics,
the continuous semantics introduces a different formulation.
Definition 21 A Continuous Durative Action A continuous effect is an effect expression that includes the symbol #t. A continuous durative action is a durative action with at
least one continuous effect.
Definition 22 Continuous Update Function Let C be a set of ground continuous effects
for a planning instance, I, and St = (t, S, X) be a state. The continuous update function
defined by C for state St is the function fC : R → Rn , where n is dimI , such that:
dfC
=g
dt
and
fC (0) = X
where g is the update function generated for an action a with:
N Pa = { (<op> P Q) | (<op> P (* #t Q)) ∈ C}
Definition 22 shows how the continuous effects of several continuous durative actions can
be combined to create a single system of simultaneous differential equations whose solution,
given an appropriate starting point, defines the evolution of the continuously varying values.
Definition 23 Induced Continuous Plan Let I be a planning instance that includes
continuous durative actions and P be a plan for I. The induced continuous plan for P is a
triple, (S, Invs, Cts), where S is simplif y(P ), Invs is the set of invariant constraints:
Invs = {(Q, t, t + d) | (t, a[d]) ∈ P and (over all Q) is an invariant for A}
101

Fox & Long

Let ti and ti+1 be two consecutive times in the happening sequence for simplif y(P ). The
set of active continuous effects over (ti , ti+1 ) is:
{Q | (t, a[d]) ∈ P, (ti , ti+1 ) ⊆ [t, t + d] and Q is a continuous effect of a}
and Cts is the set of systems of continuous effects:
Cts = {(C, ti , ti+1 ) | C is the set of active continuous effects over (ti , ti+1 )}
The components of a continuous plan separate out the invariant conditions and continuous effects from the rest of the simple plan in order to allow correct application of the
continuous updates and to allow confirmation that the invariants hold in the face of the
continuous effects.
Definition 24 Trace Let I be a planning instance that includes continuous durative actions, P be a plan for I, (SP, Inv, Cts) be the induced continuous plan for P , {ti }i=0...k
be the happening sequence for S and S0 be the initial state for I. The trace for P is the
sequence of states {Si }i=0...k+1 defined as follows:
• If there is no element (C, ti , ti+1 ) ∈ Cts then Si+1 is the state resulting from applying
the happening at ti in the simple plan SP to the state Si .
• If (C, ti , ti+1 ) ∈ Cts then let Ti be the the state formed by substituting f (ti+1 − ti ) for
the numeric part of state Si , where f is the continuous update function defined by C
for state Si . Then Si+1 is the state resulting from applying the happening at ti in the
simple plan SP to the state Ti . If f is undefined for any element in Cts then so is
the trace.
Definition 24 defines a trace in a similar fashion to the traces for simple plans and plans
with durative actions. The key difference is the need to apply the continuous updates. These
are handled by solving the systems of simultaneous differential equations across each interval
in which they are active and then applying the result to update the numeric values across
that interval. Of course, this is easier to describe than it is to do, since solving arbitrary
simultaneous differential equations algorithmically is not generally possible. Under certain
constraints this semantics can be implemented in order to confirm the validity of a plan
automatically.
Definition 25 Invariant Safe Let I be a planning instance that includes continuous durative actions, P be a plan for I, (S, Inv, Cts) be the induced continuous plan for P and
{Si }i=0...k+1 be the trace for P . For each (C, ti , ti+1 ) ∈ Cts let fi be the continuous update
function defined by C for Si . P is invariant safe if, for each fi that is defined and for each
(Q, t, u) ∈ Inv such that [(ti , ti+1 )] = I ⊆ (t, u), then ∀x ∈ I, Num(s, Q)(fi (x)) where s is
the logical state in Si .
In this definition, the symbols [(..)] are used to mean that the interval I can be closed or
open at either end.
102

pddl2.1: Expressing Temporal Planning Domains

From a semantic point of view, invariants must be checked at every point in the interval over which they apply. When the interval contains only finitely many discrete changes
then the obligation can be met by considering only the finite number of points at which
change occurs (a fact that is exploited for discrete durative action plan semantics in Definition 18). When there is continuous change the obligation is much harder to meet. In
practice, the invariants can be checked by examining the possible roots of the function describing continuous change, but finding those roots can be very difficult in general. Again,
suitable constraints on the forms of differential equations expressed in a domain can make
the validation problem tractable.
The last two definitions simply assemble the components to arrive at analogous definitions to those for executability and validity of simple plans and plans with durative actions.
Definition 26 Executability of a Plan A plan P containing continuous durative actions,
for planning instance I, with induced continuous plan (S, Invs, Cts). P is executable if the
trace for P is defined, {Si }i=0...k+1 , and it is invariant safe.
Definition 27 Plan Validity A plan P containing durative actions, for planning instance
I is valid if it is executable, with trace {Si }i=0...k+1 and Sk+1 satisfies the goal in I.

10. Plan Validation
Plan validation is an important part of the use of pddl, particularly in its role for the
competition. With approximately 5000 plans to consider in the competition in 2002, it can
be seen that automation is essential. The validation problem is tractable for propositional
versions of pddl because plans are finite and can be validated simply by simulation of their
execution. The issue is more complicated for pddl2.1 because the potential for concurrent
activity, possibly in the face of numeric change, makes it necessary to ensure that invariant
properties are protected and that concurrent activity is non-interfering.
When durative actions are used there is a question over whether a plan should be
considered valid if it does not contain all of the end points of the actions initiated in the
plan. When an action is exploited in a plan for the effect it has at the end of its duration
it is clear that that end point will be present in the plan, but when an action was selected
for its start effect this is less clear. A match-striking action is performed for its start effect,
not in order to have a burned out match at the end of a brief interval. It could be argued
that, having obtained the desired start effect the end of the action is irrelevant and the
plan can terminate (as soon as all goals are achieved) without ensuring that all initiated
actions end safely. Indeed, the plan search process in Sapa (Do & Kambhampati, 2001) can
terminate whilst there are still queued events awaiting the advancement of time. However,
it is possible to conceive of situations in which the end point of an action, incorporated
only for its start effect, introduces inconsistencies in the plan so that its inclusion would
make the plan invalid. In these cases it seems that plan validity could be compromised by
ignoring end effects.
In order to avoid having to resolve these complexities, we have taken the view that a
pddl2.1 plan is valid only if all action start and end points are explicit within the plan.
Having identified that this is the case we then proceed to confirm that all happenings within
the plan are mutex-free.
103

Fox & Long

Plan validation is decidable for domains including discretized and, under certain constraints, continuous durative actions because all activity is encapsulated with the durative
actions explicitly identified by a plan. This makes the trace induced by a plan finite and
hence checkable. We therefore observe that the validation problem for pddl2.1 is decidable
even when actions contain duration inequalities. This is because the work in determining
how the duration inequalities should be solved has already been completed in the finished
plan so validation of the plan can proceed by simulation of its execution, as is the case
for pddl plans. The problem is tractable for domains without continuous effects, but the
introduction of continuous effects can, in principle, allow expression of domains with very
complex functions describing numeric change (Howey & Long, 2002). Under the assumption
that continuous effects are restricted to description in terms of simple linear or quadratic
functions, without any interactions between concurrent continuous effects, plan validity is
tractable. The cost in practice is increased however, since it may be necessary to solve
polynomials in order to check invariants. Validation of plans containing more complex
expressions of change is being explored.
Although plan validity checking is tractable, there is a subtlety that arises because of
the need to represent plans syntactically and the difficulties involved in expressing numbers with arbitrary precision. In principle, all of the values that are required to describe
valid plans are algebraic (assuming we constrain continuous effects as indicated above),
and therefore finitely representable. In practice, expecting planners to handle numbers as
algebraic expressions seems unnecessarily complicated and it is far more reasonable to assume that numbers will be represented as finite precision floating point values. Indeed, the
syntax we have adopted for the expression of plans restricts planners to expressing times
as finite precision floating point values. With this constraint, and because of limitations on
the precision of floating point computations in implementations of plan validation systems,
it is necessary to take a more pragmatic view of the validation process and accept that
numeric conditions will have to be evaluated to a certain tolerance. Otherwise, it can occur
that there is no way to report a plan to the necessary degree of accuracy for it to have a
valid interpretation under the semantics we defined in Section 8. In most cases, a plan that
specifies time points to, for example, four significant digits, is a reasonable abstraction of the
execution time activity that will be needed to control the flow system. No plan can specify
time points absolutely precisely, so abstraction is forced upon the planner by the fact that
it is working with models of the world and not the physical world itself. The problem, then,
is one of the relationship between the theoretical semantics and the pragmatic concerns of
automated validation.
In Figure 18 this relationship is depicted in terms of what kinds of plans can be automatically validated. The left side of the picture describes the theoretical semantics, with
the arrow indicating the link between plans and their interpretation under the theoretical
semantics. For example, it is possible to construct
a domain and problem for which a plan
√
that requires an action to happen at time 2 is a meaningful semantic object, but for which
a plan that specifies that the√action happen at time 1.41 is not a meaningful semantic object
because 1.41 is not equal to 2. These two plans are distinct, and only one is correct (under
the assumed constraints). The right side of the picture depicts the pragmatic validation of
syntactic plan objects. The two control plans, though distinct in the semantics, can map to
the same syntactic object if we assume that the validation is subject to a tolerance of 0.01.
104

pddl2.1: Expressing Temporal Planning Domains

Semantic interpretation of plans

Validation of plans

mapping semantics to pragmatic
realisation in automated validation process

Semantic plan objects


	
	
	  
	
	
	  





		   
	
	  



	 
	


mapping semantic plans to their syntactic
counterparts.



Syntactic plan objects

A specific pair of mappings

Figure 18: The pragmatic mapping between semantics of plans and their validation by
automated computational processes. The shaded area contains plans that cannot
be interpreted within the theoretical semantics. It can be seen that a plan in
this collection is indistinguishable from a meaningful plan when mapped to the
syntactic side of the picture.
√
These plans both map to the syntactic object in which 1.41 approximates the value 2.
This syntactic plan can be validated using the pragmatic validation processes necessary for
automatic validation of describable syntactic plans, which will check for validity subject
to the tolerance of 0.01. The pragmatic constraints on the representations of plans, the
expectations about representations of numeric values in planners and validators and their
consequences are all reasonable assumptions given that the models against which we check
validity are, in any case, abstractions, at some non-zero tolerance, of the world. In practice,
it is a problem to accept plans at specified tolerance levels only in pathological cases, while
arithmetic precision in computer representations of floats has an immediate and negative
impact if one tries to take the stronger line that plans should only be accepted if they are
strictly valid according to the formally precise evaluation of expressions.
Finally, there is an interesting philosophical issue that arises and is discussed by Henzinger and his co-authors (1997, 2000). It is, in fact, not possible to achieve exact precision
in the measurement of time or other continuous numeric quantities. Henzinger et al. have
considered this problem through the development of robust automata. Robust automata
only accept a trace if there exists a tube of traces within a distance  > 0 of the original
trace, all of which are acceptable by the original acceptance criteria. These are called fuzzy
tubes indicating that time is fuzzily, rather than precisely, detectable. This idea offers a path
to a formal semantics that is closer to defining plans that are robust to the imprecision in
an executive’s ability to measure time. Unfortunately, checking fuzzy tubes is intractable.
We currently compromise by adopting an  value, used as the tolerance in checking that
numeric values fulfil numeric constraints during plan execution, to also represent the minimum separation of conflicting end points within plans. This is consistent with the idea that
if the planner assumes that an executive is willing to abstract to the indicated tolerance
level in the checking of preconditions for actions then it is unreasonable to suppose that a
plan can make use of finer grained measurements in determining when actions should be
105

Fox & Long

applied. At the moment the value of  is set in the validation process, and only communicated informally to planner-engineers, but it might be better to allow a domain designer
to define an  appropriate for use in the particular domain. There remain several issues
concerning the correct management of the buffers during validation (particularly the usual
problem concerning the transitivity of “fuzzy closeness”) which are important issues for
temporal reasoning as a whole and are not restricted to the planning context. We do not
yet have solutions to all of these problems.

11. Related Work: Representing and Reasoning about Time
Representation of, and reasoning with, statements about time and the temporal extent of
propositions has long been a subject of research in AI including planning research (Allen,
1984; McDermott, 1982; Sandewall, 1994; Kowalski & Sergot, 1986; Laborie & Ghallab,
1995; Muscettola, 1994; Bacchus & Kabanza, 2000). Important issues raised during the
extension of pddl to handle temporal features have, of course, already been examined by
other researchers, for example in Shanahan’s work (1990) on continuous change within the
event calculus, in Shoham’s work (1985) and Reichgelt’s work (1989) on temporal reasoning and work on non-reified temporal systems (Bacchus, Tenenberg, & Koomen, 1991).
Vila (1994) provides an excellent survey of work in temporal reasoning in AI. In this section
we briefly review some of the central issues that have been addressed, and their treatment
in the literature, and set pddl2.1 in the context of research in temporal logics.
Several researchers in temporal logics have considered the problems of reasoning about
concurrency, continuous change and temporal extent. These works have focussed on the
problem of reasoning about change when the world is described using arbitrary logical
formulae, and most have been concerned with making meta-level statements (such as that
effect cannot precede cause). The need to handle complex logical formulae makes the
frame problem difficult to resolve, and an approach based on circumscription (McCarthy,
1980) and default reasoning (Reiter, 1980) is typical. The strips assumption provides a
simple solution to the frame problem when states are described using atomic formulae.
The classical planning assumption is that states can be described atomically but this is
not a general view of the modelling of change. Although simplifying, this assumption is
surprisingly expressive. The bench mark domains introduced in the third International
Planning Competition suggest that atomic modelling is powerful enough to capture some
complex domains which closely approximate real problems. The temporal reasoning issues
we confront are not simplified as a consequence of having made a simplifying assumption
about how states are updated. We remain concerned with the major issues of temporal
reasoning: concurrency, continuous change and temporal extent.
In the development of pddl2.1 we made a basic decision to consider the end points of
durative actions as instantaneous state transitions. This allows us to concentrate on the
truth of propositions at points instead of over intervals. The decision to consider actions in
this way is similar to that made by many temporal reasoning researchers (Shanahan, 1990;
McCarthy & Hayes, 1969; McDermott, 1982). In the context of pddl2.1 the approach has
the advantage of smoothly integrating with the classical planning view of actions as state
transitions. Nevertheless, Allen has shown that a temporal ontology based on intervals
can be a basis for planning (Allen, 1984, 1991) and several planning systems have been
106

pddl2.1: Expressing Temporal Planning Domains

strongly influenced by the intervals approach (Muscettola, 1994; Rabideau, Knight, Chien,
Fukunaga, & Govindjee, 1999). Allen later moved away from his initial position that instants
are not required, introducing the notion of moments (Hayes & Allen, 1987), which are a
concept that attempts to reconcile the stance that nothing is instantaneous (so there should
only be intervals) and the observation that changes in values of discrete-valued variables,
such as propositional variables, apparently cannot avoid changing at instants. This view is
consistent with the approach we take in the modelling of continuous durative actions, and
with the view of change as consisting of both discrete and continuous aspects (Henzinger,
1996).
In the remainder of this section we compare the pddl extensions that we propose with
previous work in temporal reasoning by considering the three central issues identified above.
Our objective is not to claim that our extensions improve on previous work, but instead to
demonstrate that the implementation of solutions to these three problems within the pddl
framework makes their exploitation directly accessible to planning in a way that they are
not when embedded within a logic and accompanying proof theory.
11.1 Continuous change
Several temporal reasoning frameworks began with consideration of discrete change and,
later, were extended to handle continuous change. For example, Shanahan (1990) extended
the event calculus of Kowalski and Sergot (1986) to enable the modelling of continuous
change. This process of extension mirrors the situation faced in extending pddl, where a
system modelling discrete change already existed. It is, therefore, interesting to compare
the use of pddl2.1 with the use of systems such as the extended event calculus.
In his sink-filling example Shanahan (1990) discusses the issues of termination of events
(self-termination and termination by other events), identification of the level of water in the
sink during the filling process and the effect on the rate of change in the level of water in
a sink when it is being filled from two sources simultaneously. The behaviour of the filling
process and its effects on the state of the sink over time are modelled as axioms which would
allow an inference engine to predict the state of the sink at points during the execution of
the process.
pddl2.1 allows the representation of the complex interactions that arise when a sink is
filled from multiple independently controlled water sources by means of concurrent durative
actions with continuous effects that encapsulate the initiation of the filling process, from
a single water source, the change in the level of water in the sink and the termination
of the process when the water source is turned off. This model is robust, since it easily
accommodates multiple water sources, simply modifying the rate of flow appropriately by
commutative updates. Since the actions have additive effects and the model provides the
rate at which water enters the tank from a source, it is possible to compute the level of
water in the sink at any point in the filling interval at which a concurrent action might
consult the level. In contrast to Shanahan’s extension to the event calculus, this approach
does not require that the filling process be (at least from the point of view of the logical
axiomatisation) terminated and restarted at a new rate when a water source is opened or
closed, since the process simply remains active throughout. The change in rate of filling is
107

Fox & Long

then reflected in a piecewise-linear profile for the depth of water in the sink, just as it is in
Shanahan’s model.
It is not possible to model the multiple water sources situation if the filling process is
completely encapsulated within a discretized durative action. In the discretized action the
true level of water is not accessible during the filling process but only at its end or its start.
Step-function behaviour only coarsely approximates true behaviour, so the consequence is
that complex interactions cannot be properly modelled.
One of the important consequences of continuous behaviour is the triggering of events. In
Shanahan’s extensions this is achieved through the axiomatisation of causal relationships —
events are not distinguished syntactically from actions, but only by the fact that their
happening is axiomatically the consequence of certain conditions. In pddl2.1 some events
(such as the flooding of the sink if the filling continues after its capacity has been reached)
can be modelled by using a combination of conditional effects and duration inequalities.
However, not all events can be modelled in this way, since it is not always possible to predict
when spontaneous events will occur. pddl2.1 could be extended to allow the expression
of causal axioms, but an alternative approach is to modify the language to enable the
representation of events within the action-oriented tradition. This can be achieved by
breaking up continuous durative actions into their instantaneous start and end points and
the processes they encapsulate. This would enable the execution of a process to be initiated
by a start action and ended by an instantaneous state transition that is either an action
under the control of the planner or an event. A simple extension to the language is needed
to distinguish actions from events and to prevent the planner from deliberately selecting
an event. We refer to this approach as the start-process-stop model, and we have extended
pddl2.1 to support it (Fox & Long, 2002). The resulting language, pddl+, is more difficult
to plan with than pddl2.1, and there are still open questions, concerning the complexity
of the plan validation problem for this language, which remain topics for future work.
11.2 Concurrency
The opportunity for concurrent activities complicates several aspects of temporal reasoning.
Firstly, it is necessary to account for which actions can be concurrent and secondly it is
necessary to describe how concurrent activities interact in their effects on the world.
In most formalisms the first of these points is achieved by relying on the underlying logic
to deliver an inconsistency when an attempt is made to apply two incompatible actions simultaneously. For example, the axioms of the event calculus will yield the simultaneous
truth and falsity of a fluent if incompatible actions are applied simultaneously and consequently yield an inconsistency. Unfortunately, recognising inconsistency is, in general,
undecidable, for a sufficiently expressive language. In pddl2.1 we adopt a solution that
exploits the restricted form of the action-centred formalism, defining the circumstances in
which two actions could lead to inconsistency and rejecting the simultaneous application
of such actions. We favour a conservative restriction on compatibility of actions (the no
moving targets rule), in order to support efficient determination of incompatibility, rather
than a more permissive but elusive ruling. An alternative approach, adopted by Bacchus in
TLplan (2001), for example, is to allow multiple actions to occur at the same instant, but
nevertheless to be executed in sequence. We find this solution counter-intuitive and, more
108

pddl2.1: Expressing Temporal Planning Domains

importantly, consider that it would be impossible to use a plan of this sort as an instruction
to an executive — no executive could be equipped to execute actions simultaneously and yet
in a specified order. Our view is that if the order of execution matters then the executive
must ensure that the actions are sequenced and can only do so within the limitations of its
capability to measure time and react to its passing.
Shanahan (1999) discusses Gelfond’s (1991) example of the soup bowl in which the
problem concerns raising a soup bowl without spilling the soup. Two actions, lift left and
lift right, can be applied to the bowl. If either is applied on its own the soup will spill, but,
it is argued, if they are applied simultaneously then the bowl is raised from the table and
no soup spills. Shanahan considers this example within the event calculus, where he uses
an explicit assertion of the interaction between the lift left and lift right actions to ensure
that the spillage effect is cancelled when the pair is executed together. The assumption is
that the two actions can be executed at precisely the same moment and that the reasoner
can rely on the successful simultaneity in order to exploit the effect.
In pddl2.1 we take the view that precise simultaneity is outside the control of any
physical executive. A plan is interpreted as an instruction to some executive system and
we hold that no executive system is capable of measuring time and controlling its activity
at arbitrarily fine degrees of accuracy. In particular, it is not possible for an executive to
ensure that two actions that must be independently initiated are executed simultaneously.
If a plan were to rely on such precision in measurement then, we claim, it could not be
executed with any reliable expectation of success and should not, therefore, be considered
a valid plan.
pddl2.1 supports the modelling of the soup bowl situation in the following way. Two
durative actions, lift left and lift right, both independently initiate tilting intervals which,
when complete, will result in spillage of the soup if their effects have not been counteracted.
Provided that the two lift actions start within an appropriate tolerance of one another the
tilting will be corrected and the spillage avoided without the need to model cancellation
of effects. We argue that an executive can execute the two actions to within a fine but
non-zero tolerance of one another, and can therefore successfully lift the bowl. The event
calculus model presented by Shanahan insists on precise synchronization of the two actions,
incorrectly allowing it to be inferred that the soup will be spilled even if the time that
elapses between the two lifts is actually small enough to allow for correction of the tilting
of the bowl. Worse, Shanahan’s axioms would allow lack of precise synchronization to be
exploited to achieve spillage, using an amount of time smaller than that correctly describing
the physical situation being modelled.
If one considers it unnecessary to model the precise interaction between the two lifts,
one has the alternative in pddl2.1 to abstract out the interaction and see the soup-bowl
lifting action as a single discretized action that achieves the successful raising of the bowl.
11.3 Temporal extent
A common concern in temporal reasoning frameworks, discussed in detail by Vila and
others (Vila, 1994; van Bentham, 1983), is the divided instant problem. This is the problem
that is apparent when considering what happens at the moment of transition from, say,
truth to falsity of a propositional variable. The question that must be addressed is whether
109

Fox & Long

the proposition is true, false, undefined or inconsistently both true and false at the instant
of transition. Clearly the last of these possibilities is undesirable. The solution we adopt is
a combination of the pragmatic and the philosophically principled. The pragmatic element
is that we choose to model actions as instantaneous transitions with effects beginning at the
instant of application. Thus, the actions mark the end-points of intervals of persistence of
state which are closed on the left and open on the right. This ensures that the intervals nest
together without inconsistency and the truth values of propositions are always defined. The
same half-open-half-closed solution is adopted elsewhere. For example, Shanahan (1999)
observes that a similar approach is used in the event calculus, although there the intervals
are closed on the right. Although the two choices are effectively equivalent, we slightly
prefer the closed-on-the-left choice since this allows the validation of a plan to conclude
with the state at the point of execution of its final action, making the determination of the
temporal span of the plan unambiguous.
From a philosophical point of view the truth value of the proposition at the instant of
application of an action cannot be exploited by any other action, by virtue both of the
no moving targets rule and our position, outlined above, that a valid plan cannot depend
on precise synchronisation of actions. This forces actions that require a proposition as a
precondition to sit at the open end of a half-open interval in which the proposition holds.
11.4 Planning with Time
In classical planning models, time is treated as relative. That is, the only temporal structuring in a plan, and in reasoning about a plan, is in the ordering between actions. This is most
clearly emphasised by the issues that dominated planning research in the late 1980s and
early 1990s, when classical planning was mainly characterised by the exploration of partial
plan spaces, in planners such as tweak (Chapman, 1987), snlp (McAllester & Rosenblitt,
1991) and ucpop (Penberthy & Weld, 1992). Partial plans include a collection of actions
representing the activity thus far determined to be part of a possible plan and a set of
temporal constraints on those actions. The temporal constraints used in a partial plan are
all of the form A < B where A and B are time points corresponding to the application of
actions.
Classical linear planners (Fikes & Nilsson, 1971; Russell & Norvig, 1995) rely on the
simple fact that a total ordering on the points at which actions are applied can be trivially
embedded into a time line. Again, the duration between actions is not considered. The role
of time in planning becomes far more significant once metric time is introduced. With metric
time it is possible to associate specific durations with actions, to set deadlines or windows
of opportunity. The problems associated with relative time have still to be resolved in a
metric time framework, but new problems are introduced. In particular, durations become
explicit, so it is necessary to decide what the durations attach to: actions or states. Further,
explicit temporal extents make it more important to confront the issue of concurrency in
order to best exploit the measured temporal resources available to a planner.
In contrast to the simple ordering constraints required for relative time, metric time
requires more powerful constraint management. Most metric time constraint handlers are
built around the foundations laid by Dechter, Meiri and Pearl (1991). For example, IxTeT
uses extensions of temporal constraint networks (Laborie & Ghallab, 1995). The language
110

pddl2.1: Expressing Temporal Planning Domains

that IxTeT uses to represent planning domains is similar to pddl2.1 as described in this
paper, but more expressive because it allows access to time points within the interval of a
durative action. This added expressive power is obtained at the cost of increased semantic
complexity and, consequently, increased difficulty in the validation of plans. However, there
are many similarities between the modelling of discretised durative actions in pddl2.1 and
in IxTeT, and similar modelling conventions are also found in the languages of Sapa (Do &
Kambhampati, 2001) and Oplan (Drabble & Tate, 1994).
One of the earliest planners to consider the use of metric time was Deviser (Vere, 1983),
which was developed from nonlin (Tate, 1977). In Deviser, metric constraints on the times
at which actions could be applied and deadlines for the achievements of goals were both
expressible and the planner could construct plans respecting metric temporal constraints
on the interactions between actions. Cesta and Oddi (1996) have explored various developments of temporal constraint network algorithms to achieve efficient implementation
for planning and Galipienso and Sanchis (2002) consider extensions to manage disjunctive
temporal constraints efficiently, which is a particularly valuable expressive element for plan
construction as was observed above, since constraints preventing overlap of intervals translate into disjunctive constraints on time points. hsts (Muscettola, 1994) also relies on a
temporal constraint manager.
In systems that use continuous real-valued time it is possible to make use of linear
constraint solvers to handle temporal constraints. In particular, constraints dictated by
the relative placement of actions with durations on a timeline can be approached in this
way (Long & Fox, 2003a). An alternative timeline that is often used is a discretised line
based on integers. The advantage of this approach is that it is possible to advance time
to a next value after considering activity at any given time point. The next modality can
be interpreted in a continuous time framework by taking it to mean the state following the
next logical change, regardless of the time at which this occurs (Bacchus & Kabanza, 1998).
In planning problems in which no events can occur other than the actions dictated by the
planner and no continuous change is modelled, plans are finite structures and therefore
change can occur at only a finite number of time points during its execution. This makes
it possible to embed the execution of the plan into the integer-valued discrete time line
without any loss of expressiveness.
Various researchers have considered the problem of modelling continuous change. Pednault (1986) proposes explicit description of the functions that govern the continuous change
of metric parameters, attached to actions that effect instantaneous change to initiate the
processes. However, his approach is not easy to use in describing interacting continuous
processes. For example, if water is filling a tank at a constant rate and then an additional
water source is added to increase the rate of filling then the action initiating the second
process must combine the effects of the two water sources. This means that the second
action cannot be described simply in terms of its direct effect on the world — to increase
the rate of flow into the tank — but with reference to the effects of other actions that
have already affected the rate of change of the parameter. Shanahan (1990) also uses this
approach, with the consequence that processes are modelled as stopping and then restarting
with new trajectories as each interacting action is applied.
In Zeno (Penberthy & Weld, 1994), actions have effects that are described in terms of
derivatives. This approach makes it easier to describe interacting processes, but complicates
111

Fox & Long

the management of processes by making it necessary to solve differential equations. The
complication has not deterred other authors from taking this approach: McDermott (2003)
takes this approach in his process planner.
The introduction of continuous processes into the planning problem represents a considerable complication, even over a model that includes temporal features and supports
concurrency. It is an area of active research and the community has not yet agreed on
matters of representation, let alone semantics. There remain many open problems for the
planning community to address, both in the development of languages and planning algorithms and also in in the development of plan verification tools that can embody a widely
accepted semantics.

12. Conclusions
Recent developments in AI planning research have been leading the community closer to
the application of planning technology to realistic problems. This has necessitated the
development of a representation language capable of modelling domains with temporal and
metric features. The approach we have taken towards the development of such a language
is to extend McDermott’s pddl domain representation standard to support temporal and
metric models.
The development of the pddl sequence towards greater expressive power is important
to the planning community because pddl has provided a common foundation for a great
deal of recent research effort. The problems involved in modelling the behaviour of domains
with both discrete and continuous behaviours have been well explored in the temporal logic
and model checking communities but there have been no widely adopted models within
the planning community. Our work on pddl2.1 provides a way of making the relevant
developments in these communities accessible to planning. Furthermore, pddl2.1 begins
to bridge the gap between basic research and applications-oriented planning by providing
the expressive power necessary to capture real problems.
pddl2.1 has the expressive power to represent a class of deterministic mixed discretecontinuous domains as planning domains. The language introduces a form of durative action
based on three connected parts: the initiation of an interval in which numeric change
might occur and its explicit termination by means of an action that produces the state
corresponding to the end of the durative interval. This form of action allows the modelling
of both discrete and continuous behaviours — discretized change can be represented by
means of step functions, whilst continuous change can be modelled using the #t variable.
The language provides solutions to the critical issues of concurrency, continuous change
and temporal extent. The semantics of the language is derived from the familiar state
transition semantics of strips, extended to interpret invariants holding over intervals in
which continuous functions might also be active. Our semantics allows us to interpret more
plans than we can efficiently validate. We describe the criteria that a plan must satisfy in
order to be practically verifiable.
This paper has focussed primarily on a discussion of the numeric and discretised temporal features of pddl2.1. However, the modelling capability of discretized durative actions
is in some respects limited and it is important for the planning community to address the
challenges presented by continuous change. Indeed, even using the continuous actions of
112

pddl2.1: Expressing Temporal Planning Domains

pddl2.1 it is not possible to model episodes of change being terminated by spontaneous
events in the world rather than by the deliberate choice of the planner. The future goals
of the community should include addressing domains that require the continuous actions of
pddl2.1, then confronting the challenges of planning within more dynamic environments in
which intervals of change can be terminated by the world as well as by the deliberate action
of the planner. This will constitute an important step towards planning within dynamic
and unpredictable environments.

Acknowledgements
We would like to thank the members of the committee for the third International Planning
Competition. In particular, discussions with Drew McDermott, Fahiem Bacchus, David
Smith and Hector Geffner in turns infuriated, intrigued and delighted us and contributed
immeasurably to the strengths of this paper. Many others have offered comments and
insights that have allowed us to develop the work we present here. We would like to thank
Jörg Hoffmann, Malte Helmert, Antonio Garrido, Stefan Edelkamp, Nicola Muscettola,
Mark Boddy, Keith Golden, Jeremy Frank, Ari Jónsson, Julie Porteous, Alex Coddington,
Stephen Cresswell, Luke Murray, Keith Halsey and Richard Howey for the many helpful
discussions we have shared.

113

Fox & Long

Appendix A. BNF Specification of pddl2.1
This appendix contains a complete BNF specification of the pddl2.1 language. This is not
a strict superset of pddl1.x. For example, the use of local variables within action schemas
has been left out of this specification. It is not a widely used part of the language and has
not been used in any of the competition domains. The interpretation of local variables as
proposed by McDermott is subtle, since it demands confirmation that a unique instantiation
exists for each such variable. It is non-trivial to confirm that this is the case during plan
validation for domains with significant expressive power and the fact that it has been largely
ignored suggests that it is poorly understood. Other changes are discussed in the following
sections.
A.1 Domains
Domain structures remain essentially as specified in pddl1.x. The main alterations are
to introduce a slightly modified syntax for numeric fluent expressions and to remove the
syntax for hierarchical expansions. The latter is not necessarily abandoned, but it has not,
to the best of our knowledge, been used in any publicly available planning systems or even
domains. In the original pddl specification, a distinction was drawn between strict pddl
and non-strict pddl, where strict pddl must follow the ordering of the fields specified below,
while non-strict pddl is not restricted in this way. In practice, there are relatively few fields
that it is intuitive to accept in arbitrary orders — it is natural to expect declarations to
precede use of symbols and for preconditions to precede effects. However, declarations of
constants, predicates and function symbols are not naturally ordered, so in the current
definition of pddl the ordering of all fields must follow the specification below, with the
exception of these three fields which are legal in any order with respect to one another,
although the group must follow types (if there are any) and precede action specifications.
<domain>

::= (define (domain <name>)
[<require-def>]
[<types-def>]:typing
[<constants-def>]
[<predicates-def>]
[<functions-def>]:fluents
<structure-def>∗ )
<require-def>
::= (:requirements <require-key>+ )
<require-key>
::= See Section A.5
<types-def>
::= (:types <typed list (name)>)
<constants-def>
::= (:constants <typed list (name)>)
<predicates-def>
::= (:predicates <atomic formula skeleton>+ )
<atomic formula skeleton>
::= (<predicate> <typed list (variable)>)
<predicate>
::= <name>
<variable>
::= ?<name>
<atomic function skeleton>
::= (<function-symbol> <typed list (variable)>)
<function-symbol>
::= <name>
<functions-def>
::=:fluents (:functions <function typed list
(atomic function skeleton)>)
<structure-def>
::= <action-def>
<structure-def>
::=:durative−actions <durative-action-def>

114

pddl2.1: Expressing Temporal Planning Domains

A slight modification has been made to the type syntax – it is no longer possible to
nest either expressions (a possibility that was never exploited, but complicates parsing).
Numbers are no longer considered to be an implicit type – the extension to numbers is now
handled only through functional expressions. This ensures that there are only finitely many
ground action instances. A desirable consequence is that action selection choice points need
never include choice over arbitrary numeric ranges. The use of finite ranges of integers
for specifying actions is useful (see Mystery or FreeCell for example) and an extension of
the standard syntax to allow for a more convenient representation of these cases could be
useful. The syntax of function declarations allows functions to be declared with types. At
present the syntax is restricted to number types, since we do not have a semantics for other
functions, but the syntax offers scope for possible extension. Where types are not given for
the function results they are assumed to be numbers.
<typed list (x)>
<typed list (x)>
<primitive-type>
<type>
<type>

::= x∗
::=:typing x+ - <type> <typed list(x)>
::= <name>
::= (either <primitive-type>+ )
::= <primitive-type>

<function typed list (x)> ::= x∗
<function typed list (x)> ::=:typing x+ - <function type>
<function typed list(x)>
<function type>
::= number

A.2 Actions
The BNF for an action definition is given below. Again, this has been simplified by removing
generally unused constructs (mainly hierarchical expansions). It should be emphasised that
this removal is not intended to be a permanent exclusion — hierarchical expansion syntax
has proved a difficult element of the language both to agree on and to exploit. As the other
levels of the language stabilise we hope to return to this layer and redevelop it.
<action-def>

::= (:action <action-symbol>
:parameters ( <typed list (variable)> )
<action-def body>)
<action-symbol>
::= <name>
<action-def body> ::= [:precondition <GD>]
[:effect <effect>]

Goal descriptions have been extended to include fluent expressions.
<GD>
<GD>
<GD>
<GD>

::= ()
::= <atomic formula(term)>
::=:negative−preconditions <literal(term)>
::= (and <GD>∗ )

115

Fox & Long

<GD>
<GD>
<GD>
<GD>
<GD>
<GD>
<f-comp>
<literal(t)>
<literal(t)>
<atomic formula(t)>
<term>
<term>
<f-exp>
<f-exp>
<f-exp>
<f-exp>
<f-head>
<f-head>
<binary-op>
<binary-op>
<binary-op>
<binary-op>
<binary-comp>
<binary-comp>
<binary-comp>
<binary-comp>
<binary-comp>
<number>

::=:disjunctive−preconditions (or <GD>∗ )
::=:disjunctive−preconditions (not <GD>)
::=:disjunctive−preconditions (imply <GD> <GD>)
::=:existential−preconditions
(exists (<typed list(variable)>∗ ) <GD> )
:universal−preconditions
::=
(forall (<typed list(variable)>∗ ) <GD> )
:fluents
::=
<f-comp>
::= (<binary-comp> <f-exp> <f-exp>)
::= <atomic formula(t)>
::= (not <atomic formula(t)>)
::= (<predicate> t∗ )
::= <name>
::= <variable>
::= <number>
::= (<binary-op> <f-exp> <f-exp>)
::= (- <f-exp>)
::= <f-head>
::= (<function-symbol> <term>∗ )
::= <function-symbol>
::= +
::= −
::= ∗
::= /
::= >
::= <
::= =
::= >=
::= <=
::= Any numeric literal
(integers and floats of form n.n).

Effects have been extended to include functional expression updates. The syntax proposed here is a little different from the syntax proposed in the earlier version of pddl. The
syntax of conditional effects proposed by Fahiem Bacchus for AIPS 2000 has been adopted,
in which the nesting of conditional effects is not supported. The assignment operators are
prefix forms. Simple assignment is called assign (previously this was change) and operators corresponding to C update assignments, + =, − =, ∗ = and / = are given the names
increase, decrease, scale-up and scale-down respectively. The prefix form has been
adopted in preference to an infix form in order to preserve consistency with the Lisp-like
syntax and the non-C names to help the C and C++ programmers to remember that the
operators are to be used in prefix form). We prefer assign to the original change because
the introduction of increase and so on makes the nature of a change more ambiguous.
<effect>
<effect>
<effect>
<c-effect>
<c-effect>
<c-effect>
<p-effect>
<p-effect>
<p-effect>

::= ()
::= (and <c-effect>∗ )
::= <c-effect>
::=:conditional−effects (forall (<variable>∗ ) <effect>)
::=:conditional−effects (when <GD> <cond-effect>)
::= <p-effect>
::= (<assign-op> <f-head> <f-exp>)
::= (not <atomic formula(term)>)
::= <atomic formula(term)>

116

pddl2.1: Expressing Temporal Planning Domains

<p-effect>
<cond-effect>
<cond-effect>
<assign-op>
<assign-op>
<assign-op>
<assign-op>
<assign-op>

::=:fluents (<assign-op> <f-head> <f-exp>)
::= (and <p-effect>∗ )
::= <p-effect>
::= assign
::= scale-up
::= scale-down
::= increase
::= decrease

A.3 Durative Actions
Durative action syntax is built on a relatively conservative extension of the existing action
syntax.
<durative-action-def> ::= (:durative-action <da-symbol>
:parameters ( <typed list (variable)> )
<da-def body>)
<da-symbol>
::= <name>
<da-def body>
::= :duration <duration-constraint>
:condition <da-GD>
:effect <da-effect>

The conditions under which a durative action can be executed are more complex than for
standard actions, in that they specify more than the conditions that must hold at the point
of execution. They also specify the conditions that must hold throughout the duration of the
durative action and also at its termination. To distinguish these components we introduce a
simple temporal qualifier for the preconditions. The use of the name “precondition” would
be somewhat misleading given that the conditions described can include constraints on what
must hold after the action has begun. This has motivated the adoption of :condition
to describe the collection of constraints that must hold in order to successfully apply a
durative action. The logical form of conditions for durative actions has been restricted
to conjunctions of temporally annotated expressions, but there is clearly scope for future
extension to allow more complex formulae.
<da-GD>
<da-GD>
<da-GD>
<timed-GD>
<timed-GD>
<time-specifier>
<time-specifier>
<interval>

::=
::=
::=
::=
::=
::=
::=
::=

()
<timed-GD>
(and <timed-GD>+ )
(at <time-specifier> <GD>)
(over <interval> <GD>)
start
end
all

The duration (?duration) of a durative action can be specified to be equal to a given
expression (which can be a function of numeric expressions), or else it can be constrained
with inequalities. This latter allows for actions where the conclusion of the action can
be freely determined by the executive without necessarily having further side-effects. For
example, a walk between two locations could be made to take as long as the executive
117

Fox & Long

considered convenient, provided it was at least as long as the time taken to walk between
the locations at the fastest walking speed possible. Constraints that do not specify the
exact duration of a durative action might prove harder to handle, so we have introduced a
label (:duration-inequalities) to signal that a domain makes use of them. A duration
constraint is supplied to dictate or limit the temporal extent of the durative action. The
duration is an implicit parameter of the durative action and must be supplied in a plan
that uses durative actions. To denote this, a durative action is denoted in a plan by
t:(name arg1...argn)[d] where d is the (non-negative, rational valued) duration in
floating point format (n.n). Duration constraints can be explicitly temporally annotated to
indicate that they should be evaluated in the context of the start or end point of the action,
or else they can be left unannotated, in which case the default is that they are evaluated in
the context at the start of the action (as indicated in Definition 16).
<duration-constraint>
<duration-constraint>
<duration-constraint>
<simple-duration-constraint>
<simple-duration-constraint>
<d-op>
<d-op>
<d-op>
<d-value>
<d-value>

::=

:duration−inequalities

(and <simple-duration-constraint>+ )
()
<simple-duration-constraint>
(<d-op> ?duration <d-value>)
(at <time-specifier>
<simple-duration-constraint>)
::=:duration−inequalities <=
::=:duration−inequalities >=
::= =
::= <number>
::=:fluents <f-exp>
::=
::=
::=
::=

In addition to logical effects, which can occur at the start or end of a durative action,
durative actions can have numeric effects that refer to the literal ?duration. More sophisticated durative actions can also make use of functional expressions describing effects that
occur over the duration of the action. This allows functional expressions to be updated by
a continuous function of time, rather than only step functions.
<da-effect>
<da-effect>
<da-effect>
<da-effect>
<da-effect>
<da-effect>
<timed-effect>
<timed-effect>
<timed-effect>
<f-assign-da>
<f-exp-da>
<f-exp-da>
<f-exp-da>
<f-exp-da>

::= ()
::= (and <da-effect>∗ )
::= <timed-effect>
::=:conditional−effects (forall (<variable>∗ ) <da-effect>)
::=:conditional−effects (when <da-GD> <timed-effect>)
::=:fluents (<assign-op> <f-head> <f-exp-da>)
::= (at <time-specifier> <a-effect>)
::= (at <time-specifier> <f-assign-da>)
::=:continuous−effects (<assign-op-t> <f-head> <f-exp-t>)
::= (<assign-op> <f-head> <f-exp-da>)
::= (<binary-op> <f-exp-da> <f-exp-da>)
::= (- <f-exp-da>)
::=:duration−inequalities ?duration
::= <f-exp>

Note that the ?duration term can only be used to define functional expression updating
effects if the duration constraints requirement is set. This is because in other cases the
duration value is available as an expression, whereas when duration constraints are provided
the duration can, sometimes, be freely selected within constrained boundaries.
118

pddl2.1: Expressing Temporal Planning Domains

<assign-op-t>
<assign-op-t>
<f-exp-t>
<f-exp-t>
<f-exp-t>

::=
::=
::=
::=
::=

increase
decrease
(* <f-exp> #t)
(* #t <f-exp>)
#t

The symbol #t is used to represent the period of time that a given durative action has
been active. It is therefore a local clock value for each duration, independent of similar
clocks for each other duration. There has been discussion with members of the committee
about the use of the expression using #t: it was proposed that an expression declaring
the rate of change alone could be used. We decided against this on the grounds that the
assertion of a rate of change suggests that the rate of change is determined by one process
effect alone. In fact, it is intended that if multiple active processes affect the same fluent
then these effects are accumulated. Using the expression that directly defines the amount
by which each process contributes to the change in a fluent value over time we do not appear
to assert (inconsistently) that a fluent has multiple simultaneous rates of change.
A.4 Problems
Planning problems specifications have been modified to exclude several generally unused
constructs (named initial situations and expansion information). We have removed the
length specification because it is at odds with the intention to supply physics, not advice.
Furthermore, the advice this field offers over-emphasises a very coarse plan metric. Instead,
we have introduced an optional metric field, which can be used to supply an expression that
should be optimized in the construction of a plan. The field states whether the metric is
to be minimized or maximized. Of course, a planner is free to ignore this field and make
the assumption that plans with fewest steps will be considered good plans. However, we
consider this extension to be a crucial one in the development of a more widely applicable
planning language. We have provided the variable total-time that takes the value of the
total execution time for the plan. This allows us to conveniently express the intention to
minimize total execution time.
We anticipate that extensions of the plan metric syntax will prove necessary in the
longer term, but believe that this version already provides a significant new challenge to
the community. Problem specifications are still somewhat impoverished in terms of the
ability to easily specify temporal constraints on goals and other non-standard features of
initial and goal states. Again, we anticipate the need for extension, but have chosen to leave
a clean sheet for future developments.
<problem>

::= (define (problem <name>)
(:domain <name>)
[<require-def>]
[<object declaration> ]
<init>
<goal>
[<metric-spec>]
[<length-spec> ])
<object declaration> ::= (:objects <typed list (name)>)
<init>
::= (:init <init-el>∗ )
<init-el>
::= <literal(name)>

119

Fox & Long

<init-el>
<goal>
<metric-spec>
<optimization>
<optimization>
<ground-f-exp>
<ground-f-exp>
<ground-f-exp>
<ground-f-exp>
<ground-f-exp>
<ground-f-exp>
<length-spec>

::=:fluents (= <f-head> <number>)
::= (:goal <GD>)
::= (:metric <optimization> <ground-f-exp>)
::= minimize
::= maximize
::= (<binary-op> <ground-f-exp> <ground-f-exp>)
::= (- <ground-f-exp>)
::= <number>
::= (<function-symbol> <name>∗ )
::= total-time
::= <function-symbol>
::= (:length [(:serial <integer>)]
[(:parallel <integer>)])
The length-spec is deprecated.

A.5 Requirements
Here is a table of all requirements in pddl2.1. Some requirements imply others; some are
abbreviations for common sets of requirements. If a domain stipulates no requirements, it
is assumed to declare a requirement for :strips.
Requirement
:strips
:typing
:negative-preconditions
:disjunctive-preconditions
:equality
:existential-preconditions
:universal-preconditions
:quantified-preconditions
:conditional-effects
:fluents
:adl

:durative-actions
:duration-inequalities
:continuous-effects

Description
Basic STRIPS-style adds and deletes
Allow type names in declarations of variables
Allow not in goal descriptions
Allow or in goal descriptions
Support = as built-in predicate
Allow exists in goal descriptions
Allow forall in goal descriptions
= :existential-preconditions
+ :universal-preconditions
Allow when in action effects
Allow function definitions and use of effects using
assignment operators and arithmetic preconditions.
= :strips + :typing
+ :negative-preconditions
+ :disjunctive-preconditions
+ :equality
+ :quantified-preconditions
+ :conditional-effects
Allows durative actions.
Note that this does not imply :fluents.
Allows duration constraints in durative
actions using inequalities.
Allows durative actions to affect fluents
continuously over the duration of the actions.

120

pddl2.1: Expressing Temporal Planning Domains

References
Allen, J. (1984). Towards a general theory of action and time. Artificial Intelligence, 23,
123–154.
Allen, J. (1991). Planning as temporal reasoning. In Proceedings of KR-91, pp. 3–14.
Bacchus, F., & Ady, M. (2001). Planning with resources and concurrency: A forward chaining approach. In Proceedings of IJCAI’01, pp. 417–424.
Bacchus, F., & Kabanza, F. (1998). Planning for temporally extended goals. Annals of
Mathematics and Artificial Intelligence, 22, 5–27.
Bacchus, F., & Kabanza, F. (2000). Using temporal logic to express search control knowledge
for planning. Artificial Intelligence, 116(1-2), 123–191.
Bacchus, F., Tenenberg, J., & Koomen, J. (1991). A non-reified temporal logic for AI.
Artificial Intelligence, 52, 87–108.
Blum, A., & Furst, M. (1995). Fast Planning through Plan-graph Analysis. In Proceedings
of IJCAI-95.
Cesta, A., & Oddi, A. (1996). Gaining efficiency and flexibility in the simple temporal problem. In Chittaro, L., Goodwin, S., Hamilton, H., & Montanari, A. (Eds.), Proceedings
of TIME’96.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 29, 333–377.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49.
Do, M. B., & Kambhampati, S. (2001). Sapa: a domain-independent heuristic metric temporal planner. In Proceedings of ECP-01.
Drabble, B., & Tate, A. (1994). The use of optimistic and pessimistic resource profiles to
inform search in an activity based planner. In Proceedings of AIPS-94. AAAI Press.
El-Kholy, A., & Richards, B. (1996). Temporal and resource reasoning in planning: the
ParcPlan approach. In Proceedings of ECAI’96.
Fikes, R., & Nilsson, N. (1971). STRIPS: A new approach to the application of theoremproving to problem-solving. Artificial Intelligence, 2 (3), 189–208.
Fox, M., & Long, D. (2002). PDDL+ : Planning with time and metric resources. Tech.
rep. Department of Computer Science, 21/02, University of Durham, UK. Available
at: http://www.dur.ac.uk/d.p.long/competition.html.
Galipienso, M., & Sanchis, F. (2002). Representation and reasoning with disjunction temporal constraints. In Proceedings of TIME’02.
Garrido, A., Onaindı́a, E., & Barber, F. (2001). Time-optimal planning in temporal problems. In Proceedings of ECP’01.
Gazen, B., & Knoblock, C. (1997). Combining the expressivity of UCPOP with the efficiency
of Graphplan. In Proceedings of ECP-97, pp. 221–233.
Gelfond, M., Lifschitz, V., & Rabinov, A. (1991). What are the limitations of the situation
calculus?. In Boyer, R. (Ed.), Essays in honor of Woody Bledsoe, pp. 167–179. Kluwer
Academic.
121

Fox & Long

Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporal
planner. In Proceedings of AIPS’94.
Gupta, V., Henziner, T., & Jagadeesan, R. (1997). Robust timed automata. In HART-97:
Hybrid and Real-time Systems, LNCS 1201, pp. 331–345. Springer-Verlag.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings
of ECP’01, Toledo.
Hayes, P., & Allen, J. (1987). Short time periods. In Proceedings of IJCAI-87, pp. 981–983.
Helmert, M. (2002). Decidability and undecidability results for planning with numerical
state variables. In Proceedings of AIPS-02.
Henzinger, T. (1996). The theory of hybrid automata. In Proceedings of the 11th Annual Symposium on Logic in Computer Science. Invited tutorial., pp. 278–292. IEEE
Computer Society Press.
Henzinger, T., & Raskin, J.-F. (2000). Robust undecidability of timed and hybrid systems.
In Proceedings of the 3rd International Workshop on Hybrid Systems: Computation
and Control. LNCS 1790., pp. 145–159. Springer-Verlag.
Howey, R., & Long, D. (2002). Validating plans with continuous effects. Tech. rep., Dept.
Computer Science, University of Durham.
Jonsson, A., Morris, P., Muscettola, N., & Rajan, K. (2000). Planning in interplanetary
space: theory and practice. In Proceedings of AIPS-00.
Kowalski, R., & Sergot, M. (1986). A logic-based calculus of events. New Generation
Computing, 4, 67–95.
Laborie, P., & Ghallab, M. (1995). Planning with sharable resource constraints. In Proceedings of IJCAI-95. Morgan Kaufmann.
Lifschitz, E. (1986). On the semantics of STRIPS. In Proceedings of 1986 Workshop:
Reasoning about Actions and Plans.
Long, D., & Fox, M. (2003a). Exploiting a graphplan framework in temporal planning. In
Proceedings of ICAPS’03.
Long, D., & Fox, M. (2003b). An overview and analysis of the results of the 3rd International
Planning Competition. Journal of Artifical Intelligence Research, this issue.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proceedings of
AAAI’91, Vol. 2, pp. 634–639, Anaheim, California, USA. AAAI Press/MIT Press.
McCarthy, J. (1980). Circumscription — a form of non-monotonic reasoning. Artificial
Intelligence, 13, 27–39.
McCarthy, J., & Hayes, P. (1969). Some philosophical problems from the standpoint of
artificial intelligence. In Meltzer, B., & Michie, D. (Eds.), Machine Intelligence 4, pp.
463–502. Edinburgh University Press.
McDermott, D. (1982). A temporal logic for reasoning about processes and plans. Cognitive
Science, 6, 101–155.
McDermott, D. (2000). The 1998 AI planning systems competition. AI Magazine, 21 (2).
122

pddl2.1: Expressing Temporal Planning Domains

McDermott, D. (2003). Reasoning about autonomous processes in an estimated-regression
planner. In Proceedings of ICAPS-03.
McDermott, D., & the AIPS-98 Planning Competition Committee (1998).
PDDL–the planning domain definition language.
Tech. rep., Available at:
www.cs.yale.edu/homes/dvm.
Muscettola, N. (1994). HSTS: Integrating planning and scheduling. In Zweben, M., & Fox,
M. (Eds.), Intelligent Scheduling, pp. 169–212. Morgan Kaufmann, San Mateo, CA.
Nau, D., Cao, Y., Lotem, A., & Muñoz-Avila, H. (1999). SHOP: Simple hierarchical ordered
planner. In Proceedings of IJCAI’99.
Pednault, E. (1986). Formulating multiagent, dynamic-world problems in the classical planning framework. In Georgeff, M., & Lansky, A. (Eds.), Proceedings of the Timberline
Oregon Workshop on Reasoning about Actions and Plans.
Pednault, E. (1989). ADL: Exploring the middle ground between STRIPS and the situation
calculus. In Proceedings of KR-89, pp. 324–332.
Penberthy, J., & Weld, D. (1994). Temporal planning with continuous change. In Proceedings
of AAAI-94. AAAI/MIT Press.
Penberthy, J., & Weld, D. (1992). UCPOP: a sound, complete, partial-order planner for
ADL. In Proceedings of KR’92, pp. 103–114, Los Altos, CA. Kaufmann.
Rabideau, G., Knight, R., Chien, S., Fukunaga, A., & Govindjee, A. (1999). Iterative repair
planning for spacecraft operations in the ASPEN system. In International Symposium
on Artificial Intelligence Robotics and Automation in Space (i-SAIRAS).
Reichgelt, H. (1989). A comparison of first order and modal theories of time. In Jackson,
P., Reichgelt, H., & van Harmelen, F. (Eds.), Logic-based knowledge representation,
pp. 143–176. MIT Press.
Reiter, R. (1980). A logic for default reasoning. Artificial Intelligence, 13, 81–132.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: a Modern Approach. Prentice Hall.
Sandewall, E. (1994). Features and fluents: the representation of knowledge about dynamical
systems, volume I. Oxford University Press.
Shanahan, M. (1990). Representing continuous change in the event calculus. In Proceedings
of ECAI’90, pp. 598–603.
Shanahan, M. (1999). The event calculus explained. In Wooldridge, M., & Veloso, M.
(Eds.), Artificial Intelligence Today, pp. 409–430. Springer Lecture Notes in Artificial
Intelligence no. 1600.
Shoham, Y. (1985). Ten requirements for a theory of change. New Generation Computing,
3, 467–477.
Smith, D., & Weld, D. (1999). Temporal planning with mutual exclusion reasoning. In
Proceedings of IJCAI-99, Stockholm, pp. 326–337.
Tate, A. (1977). Generating project networks. In Proceedings of IJCAI’77.
van Bentham, J. (1983). The logic of time. Kluwer Academic Press, Dordrecht.
123

Fox & Long

Vere, S. (1983). Planning in time: Windows and durations for activities and goals. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 5.
Vila, L. (1994). A survey on temporal reasoning in artificial intelligence. AI Communications, 7, 4–28.
Wilkins, D. (1988). Practical Planning: Extending the Classical AI Planning Paradigm.
Morgan Kaufmann Publishers Inc., San Francisco, CA.

124

