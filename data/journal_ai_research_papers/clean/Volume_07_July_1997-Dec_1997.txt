	
	fffi	
	

	!"$#%$&('*),+--.'/1023%+465

789:;<>=.?6-.'A@B9
#&	<C-.?-.'

DFEHGJILK>MONQPSR.TVUXW.YZR.TQD[T(I]\^GJE_K>`

acbd%begfihVjlknmCo

prqtsVu!vtwyx%z8x|{ v}~

8.A%8%!|6Vr	_XHH8%8L]8r
"1,8]	8 .8%
1.__,|O
AH"	r]

[Vl!
OrV_8.|$$A$$rZ1,	8_AL%	">rr
$r]	.;$[r$r.18n$$.r	;
r$8A!%	$$	r|$	"!.6	y$	!	$6.;r%$$18|r
$8VO1	"rr,V	$66	$ryAC	tCO$6,.1.
8l%$8	1$Vrt!	$		!	$6	$$rCr8;"Cr
rrA1$	$	!.c!;O!.$.rOt_8!	$1
	8(1A.	!	$1$.y*r	r$!18
	$O$$6r.O$rr,r>	rL;$A	A
r|r	,;!	;r	CCr8	$$.t
Vr$.6tH
 1rCr!	$$L$y$	8OO$$ZOO$O(1r,r
	r;$	1|".t!VrC	l$rl		$$.A
$	!	1r	r$,	$,r$._6$8	
$r_1$Z	$		.l!	$FAr1Or|$	Z%	$
$6C;V$,8r	8|l,HHr8g$.C	$tA
rVg(;,y111$O$.C	$rVlH.,(,r8rr_C
		l.!._rVlQ.	r$.r,r_$,,|
$rOt	rVrr$_%$(18|$XH8>H|. y$r!A
l,..	
 	81$$	$	rOrVl(A !C>$.Z ;!r,r
8.88%	A$	$181V1$. 1.$|$>r.rA	r1	$,C	 
18.$rVlQ$$.r$	6	1,$_	8.rV$. 
C	$1;,y$$r$$8r8"r.C;($6_r|68
rVg( (,$	1r8r(6	16r	.8ryr8|.8,
$$.

 
	fiffV!
	 
 ojlkfi !#"
$&%(')&*+
!$+,.-/$102)334,56!578:94";$&"<3=$&;"
.02%16'>"/
33
?
@ 6"<ACBED>FHGJI.K#L(M.NOQPRI.K#LTSNU
IWVRL(MS#LTX
OYNZK\[
]^I6NG_X
K\`aL(bcYI6MX<GLTOdULTOYMK\I6N
beLTOdUfT[QMK:LCS:LgM.NhfLTO;G>NOi[)GjifCS:LCkNZU
I.O2SI.Oil
LTK\X<OdG)I.O2Sb.mYb#jYM5noN
b.m
l<LCK5S\jYNfYS\KNhLCOiLTOdUJpq]ENZG8crIsI.SsNftTmru6v
v
wyxhz{NZX|I.SsNftTmdu6v
v
} ~m.LTOiS\I.KN
MS:LCl<I{I6ijYM.NS#LTX
O/pX
K^LTOYb#SNOYMI
mZLTO
l<LCK5S\jYNffiniLgb:S\X
K#L(M.Nfb#I.S5S#LTOdU2b.mLTG)I.OiS\Ifs]ILdILCKNdmsu6v<vd~miLTOiS\I.K\OdI.S\k&cYN<b#I6LCOi&X
K\GNS#LTX
O;LTO2S\I.U<KNk
S#LTX
OpLffLgNZG>b#X
Om^
[ M.NZKNdmdV+I6M\`<I.K6mu6v
v
i~m2zX
crXdsjd;K\X
cYX<S#L(M|NOY/b#[iO2S\ndI.S:LgM|b:X M.MI.K|p#RLCSNOdX
I.SNhftgmYu6v
v<wdmdu6v
vi<~m.LTOiS\I.KN
MS:LCl<IHI.OiS\I.K\SNhLCOdGJI.O2SRpqPHN[
I6b:kzX
S\nm
K\X_{OYb#S5X
Om2+I.OmYu6v<v
wdx2zILffT[
m
u6v
v<i~mfiNOYYX<S\I.O2S:LgNhfGjifTS#LTk&K\X
crX
S#L(Mob:YN
MI/GL(b\beLTX
OYb.t]I6NZG8_X
K5`LTOb#jYM\nMX<G)ifTImi[2OYNZGL(M
iX
G>NhLCOYbL(b+G)X
K\I|S5nYNOQNbeLTG)ifTIjdOiLCX<OQXZbeLTGjifTSNOdI.X
jYb|MXiX
K<LTOYNS5I6QN<MS#LTl
LTS#[
tFHOLffTjYb#S5KNS#LTl
I
 +--A'>fitfi"$##d	<	<8slff:Vs19
#&	#	fi

r%&##&<


fidsi

Y)iT{d\<gi642s
d.)YJ.
6\<d|6<d.r
\\a\.Y6:Cdr
T
.)5Yfi\d{<.5
.YY.#..QeT)iT)i
<TY#T
Y\6
\(R5.odY
52dT6i
6To5d|T\.\d5

dY#6a
\d<g:#TY#T
r.q..<<TY\\)Yi#T
TdTo
i

;{<TY\
\hR(|eT8iTZd.
Y|Yoi
<TY56oi\aeT
Y.rdd{TR(+d
<Ye(i.\6;\6
\
 #T<CdT/<2

rd.<.6r(|yJiCJs\6
\|d)<.\.Y4C\dq>qC5d
#T
Y(+\Y+{iT)\6
\>ii6RT2<T
)2
<CYZ#T
rT<d<C:C<TZ{T6
#RT2<T
6|

)J
/\6
2h^ZYoi
Y.Z#T
o)
dJ\6).r..
igJ\#(5T/& Y:6
\doi.
T
dJ.2)Z;
.d.hH)diZ\6Z8
5Q5Q.YZiC
\6\Q<4<d.\.2:C
h<.
Tdo5d>dY.\T2#T6ZR<)iTsiiY(.i
T\<d).2.
 Y\#(i(6C\d6#.i
T\<d).2.\6Z).Y.5.Q.Y<d2\.<.:CdrTY
)iT.\
Yr2\eTiTTY
Ye(#\.i)<C.+H\d/
:gYJ.2hW#\)+
\d.)
.i.^


d.\.i#T
\6).r.+Y#+Y2TiT
)di(.\)\/
((\i
<TY:C<>dd5\d.\
)
5
#Y5.i<C5
d).i>.Z&\..ZY#oY5#(igZ>\6Z).Y.J\dddY656<C
T&idTd\6#r
YeTiC:C6fi
|\/<(\
.WdddY6\6
dY
5\diT#T6.)6Z>+Y#H52Y+r
.YiTas)
iT\
:CdJY.#&
\>ZY
YJYiTiTQ5.
\2iTTd/Y\6T .Z#Td/\6#
d6R\
)..HZ2><2#Td
.Y5T6.{Ri&
\\dY5C
 CJiC.J.2\6iC:CZ
.2+# :\.>&\.Jh\d\

<gia\dWd665\\JY2TiTq;TQi
<TY:C<QY;
)di(.#T
/&
{
d.\.i+\6
\aT
#Y5i
>TY#.diTd2.6
r6

   Y5#(igZ6T\d6:>#d#\.>.
.i|54:ddiT6

iTT\/d\.i(dd6i
>Td#r65i
<TY#T
d.<6T\/\d+&id\d2dd
.\hCi#T6+s
)iTi2Y4gi
TY.Y5d|TiY2Ti(##Y5od\.i(dd6i
<TY:C<
T6
dfi5Wi
##(Cd56T(seT)iT><iT\Wi#(5CYZ\HYad\.i(J<Y2\qCiT|
d
#Td
.Y5T6.Wyd\\d.\J
\
yC\.hTd;dQ5)TY\6
qCdZC
JiC\6
\/eT\Y#T
Y\d6#
i
<TY#T
Td\6)
i#T2YhT\6d6  
d<T#T
eTYo2
<CYZ#T
i(YJ\/i
>T
#r65i\d..dd
fir{\.Y#6T)
\d.si<>TY.  Y#56
2i
<TY#T
JY
5|Y{\6i6qC<d6
&
{6
5/d.i
>hC
dQ.i\HiiY
\d6qgJT\i(\#(5T;g5Y)d\<g<Td<.24T\
.d.H)di
|\6
\.YiT6\d.\
di\65>#Y5<iT#T6.
Y5)diH.YiT6/<.2J\
d\<d
)
YeT)56
#
>ZY
d{i
<TY#T
oY
)di(.#T
yd\
(<Td)\d.\d+\6<igqC5
YiCiT#T\6Z8
5
Y5
.d.J i((#T\.Y#\6
\.YZiT#T6

\i\|i
>TY.{<|
iTii6W:Y\5.Y#>\
aT)iT.).i#T

\6ddC(#/.Y#d\6

Ye(#5.YT\6Z8
5
\25)di(.#T
Y;q(5gid.W6
 
d
5\dY\T
\6.i
\d.
:C6Y\6
\|Y
r.
d)\+d\
(i{5d56
iT\6J)dig<YiTiC|56
#
iTdWr
d
\6
\
YTr.
1Y|1Y&6r&(<d\s
d. .
65
d
|6<d.
 s.<6\
d
Rs
d.Rdd6.
6

 i
 
	ffq fi	< +\2#
6<
 H\2:
 +Y.+6

 H52#/gid.H6<
 iZY
 qTi
\6#r
YeTiC# q.diTd2.a6

iZ\o#
)|\d/d\
4Cd.i)
d6J)
d5d6#

 {.
.6
)2:856#65
\aY
C6 \diTT#Y556<\\d.
#T6aTdi(<Tdd<#(.
di(.#T
YaqZ.diCdi.E
Y6
<i
ig+\:g5Td\6#.i+ !"# 6r&$ fia
.d.hE)dis56<\d.T62&
 %('*) qeT)
iT
Y,
 +d&

 -/.1032<\Y5 46'{T
\
r2&
 %('*) gY
#6J
>5d 
1Yfi1Y&Y&1
d\d.
\
q.<6\
da.HT6

 rs
d.o .
6\<d
E6<d.Y
d6i 
ddRC+(#)YhT(|YJTQ:
)
.
#6Y
5\HR5
\d3
 7
	ff#$ fi89:	
d+\d.
\ H52#
s

 (H\2:4;
 +Y.6

 (H\i#>
(id.6Y

 iiY.{iT|2&
 %<'=)Y#67
 #TiCi\.i#T
Ys<\dY
qgdi(<Td)iT 5WY56)

\

^T)\d|
YZ\6
 >(\d.
\
56).Y.digJd>a
)iT)iC.5ig.h#\5Y\d\
?
 qTi+T2\.i#T
Y.TY<C<(iY{Ti\.2:C<YWY;YT8ZY
d|
5d.A @rT25.2#T
Y  2&
 %('*)

BC"DAEGFIHKJMLONAPRQ&SUTWV5XZY1P#NAL\[R]9Q\^AX`_aX V5N$^bXZc`_aL\Q\d`e?V5d<_\f$_gVih_jkh5Ql_d?_^1N$^khiV5^#QH?m#mQ\^#PAV5nC
oAp

fiq9rtsvuwxWy{z|#}~
|R}q}uvs=rw

6tA\U&t\UAt36UAt$A67U#U\U
tAt\UA#
 A6AR6tARU6Rl7:&t:Ut:U\UOUt

U
aA
\Uk
A\U
6UtAt\U6t
<=\UaUtU#Z$A6#\tU
7*6tA8\UWUOt"A8
1tUt:U\{
&<=R\,`a:U$8#=ta\U
#7A\Z,
t8gt:aUaA#\At$\U89#
R=t8A{ZU
UtR1#gUtU98\t*g$\(R:Ut:::U&#\7Ut::gAW:vA
$g=aA#U8g8OA
9a#A67A$={Zt::aA
#A
tU#\UAARA
tU#\U9:l#AZ`R:a#U
AA$1R\tgAt#\UtU
At\UA

<=?A$8\UR:U#\U{UtU
a#RUZ9\t{RU&\t#\U#,U{l&\#
\UWWAA6A1UGtAU,A
<1t#Ua$tG#8a\#<\#,
`/g3U#
<=t#/g$\ARv\#kG/t#\#Ua#693A
\U#A&A3::U\$8\U1U
&<=5=tA$R:U#aA
ga,tAgAa#
ggA&tA7Ot"A8
#
&<=U
aA$#=t#aUaAA\,tAg
\U#\U\ A
${t:UA$a76tA\U##Og#\`ZUAAU
#6W&t=t#aUAA\$8A{
1A8t#Ua#3tUt:U\U6
tA\U#\7\/a7##a#UAtUA
RGU\UA
&7A$\UUUAA$R<t1<#6W\a1
&<=##aU$#A3U
"A\U*U6tA\UUAt/$atU##k/1At/$ata##=\a
8/OA:
# $v=\a
 #t $vv*O&A{R`U R $9  \lR#\`AR`U # v
OO?:W R R&\(\#,6UUtR<At#5ttU=7A#U$#a
t\\a6U,A
$,#\U&tk3$atU#$"#at\A#{=7
A#ZttUa#69"?gtR"t:aU/Aa#\A
\U3v6R7U`A
#gZ$t&8{#
R#a\A
g=gRG\
7#v6U,A
$kgttU
Z/{#t#WRA#3A67U#U8$tU#a#=1:,a\a
$atU#$t\U
kAt$G8vtU&altUUvAA$t?#6W=#\
7*6tA8\Ut$U\U=t1UA1U1
\, # $t&g$#
kAt::g##6A/{$a#/6\t#U#Ua
\$8$
&A\UR:U#\U=
&<=g#AA,A
$3a3
6$ata#
OA` # $?tU3\A/  t UtA7At#t
tU#AA:AAt
#{vR=7AAtAU7#\#{3tA$gR:#8\Uv
&(*#g=#R
,t\a3=#`\a#tUA$8$tU#A17A$tUAtaAt$
 U#<\laAA$aU,A$aR:U
`tAU7#UtgAtU,A
6Z
$tUt=\aU#\At$1tA$R:U#A\UAt$R#\tU$Z#\/a#AI:U\a$\U
=7A$&89
&(*Ua=tAUAt#

<={O\{AA;UtUAAt#AA$Rl,t,/#6W&A
tUaUtAtU
AA7v\AAk :  Z$A6*v&
 g\aAOAtU
A
# v`\#8t`tAt\UAa$t3a3tA#
 &	
 
W=*Oafi
 ff t
A# #t W`\#/al8#??AA?a/7A$(,ttRUA?t:U
#\U  ::9=a#\=Ua#AltA$`(
&<=Ut:"At\UA$Z#\
Z$AA,U$13:AA
6\atUtAAlgA=v#6A8t:U\U#
1\\=UtRUU#8v=3\ZA/8A
AU/,t#
ttU#\URGtUA$8$tU#AW{U$\AR?A6tA\U
\$A


fi

"!$#&%'!(*)&!,+.-(/021354&+063$7+0!8)9-:#;63-:5!2<=#;!"+0>&)&!"+0#;6%#;?#A@B,)&C-(>;+)D)9E-:"+0F!"+0#;6
#&%?G;5HI!)&<87#;GJF(#;1/05<K$+06L)M/0N7#;"/EKE#A<K)M+063OP;-:!,+Q#A6SRT:UP;-:!"+0#;6WVJEA+-:@3,!(5#;"+0#&%
!)&<87#;GD)&63EJ"GA5!C-
!:+0$+0<=F/X+-5)&!"+0#;63$%#;PY[Z\]^UAP;-:!"+0#;6I_	6:`!aE(-:"+013PY[Z\]^bc#;@
+0<=F/05<=56!Ed<e#'E:/#&%*!)f<g7#;(GhU8P;-:!,+Q#A6jiWEA+-:@3,=PY[Z\]^kl":/0-:!"+0>;S-:#A<=<8@6+.-5)f!"+0#;6?U
P;-:!"+0#;6nmfiF("56Y!:=)dE5!C)M+X/0Eo:`F35,+Q<e56Y!C)p/q5>&)M/0@3)&!"+0#;6?UnP;-:!"+0#;6srtEA+-:@3"e:/)&!Eu7#;(GhU
v
+063)M/X/0H;b$P;-:!"+0#;6twIF"56!CD"@<=<K)fHK)&63ES%x@!@(7*#AGhU

yBz8{&|}|}~2MfA3;Bdd?shL;;}

+[+06Y>A"!"+04Y)&!"+0#;6%#'-:@3,9#;6!(5g"5F3)&:)&!gE#A<K)M+0635U7#=#&%!=E#;<L)M+063	)&(J13);"E#;6)
)M/0N7#;"/EuEA+"!"+01@!Eb+06Y!5:);-:!"+0>;W+0<g@/)&!(#;=-:#;<=<=5C-(+)M/X/0HoE5>;:/0#;F3E%#;8<8+X/X+Q!:)&Hd!:)M+06+Q64
O*)p/.E5e5!K)M/}U0bD;;VT:Ujfi+0<g@/)&!(#;=563)&1/0e

>A+.)65!"7#;GA+Q64#&%J"5>;5:)M/	-:#;<=F@!5C

-:)&!,+Q#A6=#&%/)&4;5N}-5)p/Q;bV;n"H6!5!"+-13)&!!,/Q:3:/E5b7959@<K)&635b);7:/X/)A$Y@63EE2#;25>;56
!#;@3()&63E2#&%?+06Y!(://X+04;56!	)&63EW"5<+QN+06!:/X/X+Q4A56Y!)&4;56!C-5)&6W-:#;NF3)&!"+-(+0F3)&!IO$)&<813D5!9)M/}U0b;;iT:U
3C"!E#;<L)M+06?bY\[!!C);-(G=Ov
+04;@(qfTCb&+06>;#&/0>;F+X/0#;!9)&4;56!C
%#;*)-:#A<=F3)&6Hg#f%aO@F=!#:+04;!5T
"H6Y!(5!"+-J)&!!:);-Ge:/+-:#;F!(5C5UJ-:#;<=F3)&6HW"!C)&!:*)f!9!#;<=5N13)A";b795I!J-:#;<=<L)&63E5
F+X/0#;!fi)&4;56!I3C"!W"563E=#ACE5C=)&63Ej+063"!@3-:!"+0#;63L!(#d!t-:#A<=F3)&6H^<=5<815C5Unt-:#;<eF3)&6YH
F#-:"8!("W#;CE5Ce)&63Eu!56o1354f+Q633HA+Q64u!#&79)&CEI!:+0K"F-(+X3E(;X8&5;3ba+U;U0b
!)&)%x#A<79+-n!-:#;<=F3)&6Ho7+X/X/g)&!!C)A-Gu!fi565<8H;Us+X/0d56#A@!fi!#!13)&!!"/05N
F3#+0!"+0#;6?bhE5F563EA+064fi#;6!#;CE5Ccb!g-:#A<=F3)&6HK<=5<815C9<L)He3HL!#;4;5!5[#;	EH63)&<8+-5)M/X/0H
"F/X+0!8+06Y!(#tF(5N}E5!5<8+06Eo"@1!)f<K5U963-:W!S-:#A<=F3)&6Ht();-8)Y;X;Ye;3b
+0!g3)p/Q!:5U
96d#;L!"7#o:;D:/+-:#;F!(5CL3H%x#;(7)fCE)&63E3C,!S-:#A@!W!fi13)&!(!"/0tF#Y+0!"+0#;6?U);"E#;6
-:#;<=<8@6+-5)&!"+0#;6e%#;<!(	-:#;@!Ccb;#;!5-:#;<=F3)&6H8<=5<8135Ca3H8%#;79)&CEI!#!D13)&!!,/Q[F3#Y+0!"+0#;6?U
[5;bM+063EA+Q>A+E@3)M/?F+X/Q#A!C5F)&!EA/0H8<K);"GO}+E&T?!:+0:/X+-:#;F!5C2)&63EI@6<K);"GI!#q,#Y#;!$<8++X/0
)&!D565<8Ht!:)&4;5!CcUJ963-:e!=)&!!C);-(Gfi-:#;<=F/05!cb!=:/X+-:#;F!5C54;#;@Fd)&63E5!(@6!#K!(:+Q
#;<=5N13)A";Udn+X/0fi56#;@!(K!#!W#A<=5N13);"O}#;I+06+0!"+)M/X/QH!#&79)&CE!(K13)&!(!"/05NF3#Y+0!"+0#;6T:b+X%
)&6Hg-:#;<eF3)&6YH8<=5<815*"F#;!C$565<8H8>;5+-(/QF3#Y+0648)D!)&!!#I!9-:#;<=F3)&6H;b&+0!)M/05!C#A!5C5U
-:#;<=F3)&6Ho!56n5>p);EW)f63Eo1HYF3);("=!(t565<8Ho>;5+-(/05bD79+X/0^)M/"#uF#;!-:!,+Q64+0!C":/X%
@3+064J4A@635Un56=!	-:#A<=F3)&6HJ5!@(63)M%:/0H8!##;<=5N13);,;b&+0!)f<K)&63E8(:%x@:/5bA);EHA+Q64
+0!C":/X%%x#A!=6:`!<8++0#;6?U=\D6d#&>;5>A+057#&%*!(=#&>;5C)M/X/")fC-d)&63EE5>;:/0#;F<=56!J:?#;![+06
!+E#A<K)M+06?b+0<g@/)&!,+Q#A6=+06%C);"!(@3-:!@;b;<+/0"!(#;65b)&63E=)&4A56Y!153)>A+0#;C+F,56Y!E+06WO+X//
5!	)M/}U0b
;r;T:U

HOLDING
POINT
HOME
BASE

BATTLE
POSITION

RIDGE

ENEMY
VEHICLES

v
+Q4A@=;\9!(!C);-(GKE#;<K)M+06?-:#A<=F3)&6H=3HA+064=+06t,@1!)&<K

6!K"-:#;63EE#;<L)M+06?bB
C)&63"F#;!8Ov
+04;@=RT:bh"H6!5!"+-8!C)f63"F3#;(!	:/X+-:#;F!5CIF#A!-:!E
1Hfi-:#;(!:/+-:#;F!(5CD3H"HY6!5!"+-8!(#Y#AF39!#L/)&63EUI}6u)L!HF+-5)M/<8++0#;6?b?!"7#L#;D%x#A@	-:#A!
:/X+-:#;F!5C8)&63E%#;@!#W!"7:/Q>Ag!(C)&63"F#;!D:/+-:#;F!(5CI!C)&G;8#&d%#;<,5F3)&C)&!="+0F3I)&!q,)W!#
563E55>;#A@39)&!*)/X+06GYN@FF3#&+06!U(-:#;!C!56WF#&>;+EJ)F#;!-:!"+0>;J-:#&>;52!#8!D!C)&63"F#;!
:/X+-:#;F!5CE@"+064W!56!"+0+Q4AY!D!#K)&63ES%x(#;<!:+0DF5N}"F3-(+X3E/)&63EA+064W5#;6eO}795I!



fi*L?;.YM^2;

"Y(5";3A"e;YcC;KpQeKM0YA&0;	(&K$&?=J55W"Y5,.0;
&;5C[}D&(;"9f3A53:;Y(5C3M0A;fi
0;g8"&	:0;;

LANDING ZONE
SEA
ESCOR

T

LAND

ESCOR

T

TRANS

ESCOR

PORTS

T

TRANS

PORTS
ESCOR

T


0;(J
C&3";	;LM0W0t"5":A9&3W:&3"3A::;(5C5


0C;LM0nfi;"Y5,."'5:5[0C&o5M}08;;:A3

.

&0Y5(3&"0;3M	"5:5=;(3&=5;8;3ACJ&3o,Y5"W&;5C5M0=ofJ;e;"0
"fCQeg0"





&A5Y"',5K5

e	"Y(5"9&;5C;&pA5fK$XXh3&,.(03&(

0K(
	3C,*;fiff 	;(3&=5*&

 
   ff D0



&3&?	"3&3"A0W
0;8"&	

":A=35"0L&Kc[0;;:0Y"3$;B;5:"3;
9:;%;KpQI
XXQ3,C&"0;[&3(&8*A%q(3MX05;5



!"&fi$#
 Y
&'(

8;?00"M}

0=05=5C&"0;?(K:X:;5=X0;Kf;5Y:5K5;:0;u0u);&05;C&(^&A5Y
&C(0:+*[5*:X};9Y"50YA



5WM}0D;&:,&;(oX0;Sf;5YeA83;";

"53&:&t:AYu&-;Y&M;=A"3(X0;D&;5C&A=05C&C(Y9;=.	3
0;

/

,pDW3A"0;d&9Q5:&C(Yo"B&8;0Y(Y9&8?1

Y"50Y;*M;;C



5C&AC

&;5(08X.ffioA:"0;.f3W:;==;0n3"0;5W&;5fi&C(0:c	"3(;
W&C(0:8:"0Q2;:,QA;3&;(^A35C&(;J:;3"CI&:;3A0"0;o(Q
;K":0:"0;?IXg(Q;K&X5&"0;

d:A=0:;5C&;="AYM:CD&3nXXg(Qe;

5Q3f"0;?49afYI;&0YA;0J;3&(JA;8$Q5:&C(Y.A:"0;;M} ;0M0;&;53
&03AQA3M5ff L353MA0;dAg(&8*A%t&e;Q3A0A3M59;KM0



"(6	ht:;CA03&,QA

&325	;;:;e=;0K;0L;5"3L.7?;C
0L"3D&;LM0fi[98":
&M?;;323&;;:0;":}fi=<9:0?>5;;A"@?M0C
;;CQ3(03A0;L&9"B&8fi5fiM}0A;C



;5AB*Q:"5?M;

/

2;C;(}

;e03"C&3:;DMx(5S:A"0o3&"0

30"0;?h8:A9:':(98&fi(J0;(Y"DpQ,Qe35033&93f"03YQ,QAL.
:;(};	"&9L0
QA



0"MXQ;0K"



/

C

(5*X0;9&;5C&355588;5(QcXQQ(L353M;0;:&3L:;



f0u&;5D0Y5:;:"0;?5&:XQu5&o:;CA03&"0;u9;;DCA3&=(t5=;3,C&
0353MA0;C5E<9&5;53A9IY85C9f*&;5C9&3;5(Qq03:;":0D353M



0;C5I5"&3;KM0W:35C}K&WX0;C:35&fiL"3(Xfi:;=0:fi80;35
0;6	h5&	835C&B3&"(03&fif;5YQ5CA:"0;39""};:;:L0WDXB

FHGJI.KMLON+P Q RSTN5UWVYX.X.Z\[JRE]TP%R^2_%`1a.S5RbDcdR]TP
eT]TcObDPL\]Te
R%]f]TUDPghLH`i_jST^
R]kKM_jLlIHNmKMP+LONP+enghLOeT]kKM]TcD]TP oigTI\gTp0U9R%e;qr_KMLDPb
KMLsKML`icOST]TUDPS0STPeTPYRSTN5U-RLDbs^tRYKML\]TPLdRLDNPE_%`fi]TUDPgTI\g4]TP%R%^EGuWU\KwvMPE]TUDP
RcD]TUD_.SN_.L\]kKML\cDPe]T_x9PSTPeTy9_jLOekKMx\vMP
`i_jSf]TUDP
]TP%R^zA_jST{|KML-]TUDPny\v}R~.PStRa.P+L\]Te[_j]TUOP+STefUdR.PE^tRbDPnekKMajLHKwdN%R%L\]EN_jL\]TSkKMxOcD]kKM_.LDe
]T_EKMLOb\KM.KMbOcRYvR%a.PL\]
x9P+U9R.KM_.STeG
D

fiA?

;i?%?.?%?\h?\.\WOifi

EXECUTEMISSION
Flyflightplan
Prepareto
returntobase

Engage

Fly
cntrl
route

High
level

Low
level



Select
point

Select
route

Mask



Initialize Maintain
hover
masked

Contour
NOE

Unmask

position

Employ
weapons

Initialize
hover

return
to
control
point

Dip
Select
Mask

Goto
newmask
location

Popup

Employmissile
............

;i?%1n%jlldfi4%Yl96i 9\DMf"\.9%i\j9j

9%?s?".\%jOiiDEi%h .-i.fifi"9s\i%?-\OA%?\9.r6i"9"5.DA;?%\
h9??D.ji"9iiD%99i\9
%D9%W5O6i?%Dsi?-d9Y"\"%ji"
9"W.?\jhDfiO951;i?%|6hj
-YlO61%9-i 91? %D9%sd}i?%DH?%?ii
%? .\
%?\W:\ \".?\%DA
 ?-9???D%E%?Ds5O6?DEh r?%?\(?Y9tlOi?5"D6JW.ji
"9ih9"\
9"i"\DAs
s%?"j9??%:9%\-?%DA
9\\D;%?\%9%
\\.O1}.YDH:;ijO?\%Eh?d\j9ji?Tj9\:%%"9hW\"9i9Yi"9Y
90%D9%5O6i?%D\%? %D9%O6i?%D'+"Y9?"D
%l9YY??.?"D.%Di
 
DiD
D

fi:??AWfiD?Of? ??

D0D \O5\6605%m6\m6%d\O%d065E50%% d.mDs\9Ds\9%?55mj
5EDsH5H}OD9\H9O6s% %54\A}m0\0OH9\45
\5m6:Dm656D"
0DmjDm65lOi96)\mjf5OHd3H65j?'06}W56O6-+O5\5mj96
hDmH+?
'9hDm5\5}95 D:.5j})Y+\mjW695}665i9O\
?5E55
H15
Ds\90500\6mjs}96m%6EhD0m+Oj D56 5+HDD

66D\O%9jY5j96W555.W}m665iH?D+%5
hO5
O55jTf5-5\0\+
5H556D56m}O"9066650mj\sH5%fi4%m
6h0%6\0mDsH5D
}s+OED6
m-5sDi96-H5jWT\6fiO5%E%6iO5%m(Y+\mj D
 
OD
mD 9\0  
45
D0+O5j5H556fO5656D\99\
\ 0\65j|69}m%6 h O16m1OT}m5%9
Ds\9E5 
 O4hDmH+?

%m 665i\D+%5Ejmj96rH6}.5lH6}%H5E5 D56-mD6 55.\

% %mj

5
OHdE %m10\6mjs}96m%6 0%-m%mjDm.5nDi96
D69j

	fT5m5m6D45%949mDsH9%6}Ofi\Dd;5
mD0OHdn% %5A4%5f6D5.\j%\5
51YD\%.5j}n5%9A506};5fis% %5?4%5;5n0}mD5%A+\ff9

 j0
fi %YD
5%m
 %m14%m:\65 m%6j\mDmi\5
O56Dj

661DO96H %% O%i6Ddm%5.5O5D9O%6YDm%1}6O HD%9fi.5j}
9%5m5\Oj-mD
 i69|D5Dfi0\4Dj?m6:}6O\Dd
9iD69hDm O55jA\-md
\j5+H59?6+6mDfd9H50mDm
H1Hj

fTl\-Ym5%s%H5D?0%H6JOHds% %m0+\Df\HE656\"9mOHd|r\66j
5E}h%05\05%6065m}ODsOD9m}9O

01E5%\+H5YD\6%4\A%6iDm%5f15
D%Y%9+\66H6}\4jEm 5
m+HD96 m\

%6j.6jD}050695%h%50\6O5?\H:66mH\%m+HDh5OOfiHm1OH9Ds\9%5
 }mDs\9E9 6965%69

"!$#&%'()+*+*-,/.10.2435687-0()9:*;,<'=?>;0A@CB:'DEFEG.H;0(IDJ'5@LK
M ':'1B5E-0./'EF9:*N0E-,O-0;35J.H'">-0BB:;B)'5EP0 M 0,2QR>TS:Q M 0,/>-05,ffN,VUW0"B5+X M :*.&9' M ;,H,Y,ffE M =Z0[+*Q
;,O-0[3\.'P>]\^-1,/.E M 'E:.;B_E`0 M .-0a*?E-,K"$.O(b'Y0,.HOc,2SC,/.H( M 'E:./E:;,.'
, M 0[*9F.'\E M ;0,ffE*S M '()9:*87d.H;0(IDJ'5@), M E-0/'T,Y,/ M Ob=e0[+*;, M '5ET./E:-0[*+*Sf M ;KVg&O:-,Y
0F*N0H)E:(6>]I'=h,/9- M N0[* M 0,/ M 'T'8B54E-0A./'E`9:*N0E-,I0H)9-'.HET./N0[*+*SiE M ;,,0SKj4E-0a*k*SYl.mn,
B5+X M :*..'I-,/I,/ M Of9:*N0E-,oEG'.HOhB:'(P0[E-,K
p 3Eq.O;,/rB5+X M :*./;,YD&GO-0[3s91,/;Bq0Et0[*.HE-0./3r099'T0 M OuU
9H'a35NB:`0E:.1,
D&.Os0IE10[*v()'B:8*V'=w.H;0(IDJ'5@LKlg&O60AET.8, M 0AEf.OEG.O(F,/8*3;,H;0,/'EG0>]'..O8 M 'Q
'1B5E-0.24'5Ex M '()(IE: M 0./'Ef;,29-'E-,ff>:+*+./a,0,DJ8*+*v0,&0ET.2 M 9-0.Hy0E-BF0[3'NB_zZ'{H M 'a35V=R'(f|
.;0(ID&'@<=Z0[+*4H;,K&% M Oc0AEc0A99'T0 M O60[*N,/'H;}:;,V0EI879:*+ M .&9;,2ET.10A./'EI'=L0E:.1,~[.;0(
'T0a*n,\0E-Bs.;0A(9:*N0E-,l=R'.O-0A.N,\.O)3Ss>-0,n,y='5";0,2'E:E0>]'.".;0A(6D&'H@LK)<E:='5.Q
E-0.8*SY:.Oh0AET.[~,v'59-10.H'VO:10 M OTSF,/O'DE\4Ef\9;,/E:.1,w4.8,V'DE)0 M ./354.24;,K{g&O:-,Y
0[*.O'5OP.O0E:.lN,&9'35nB:;BcE:='5(P0./'Ef0>]'.V.1,.;0(b(P0.;,Y5.O8&9-0./ M 9-0./'EFEF9-0Q
./ M :*N0h0 M .2435./;,n,oE'.{879:*+ M .\zZ>.{80.O;YA4(b9:*k M .<4Ef.HO M ':'1B5E-0./'EF9:*N0E-,8|1Ky,&0H;,/:*.;Y
.O0E:.v(F0[E-,45E'10E:.w05,v.'DO: M O6'59-10.H'1,.:*SET3'A*435J.H;0(IDJ'5@y0AE-B".HO{.;0(b(P0.;,
ET35'*3;BsEi.O(GKF'm4E-,2.10E M Y&1[TRI8Nj0E-B[T5;"0AIE`H;0[*+4./Ss.;0(0 M ./354.24;,
ET35'*3Ef.OE:./ M '5()9-0E:SL]DO:+*dI8y0AE-Br:-I8ET35'*3"E'F.;0(ID&'@KV.OH()'Y
EP,/'(b{.;0(.10,2@C,'E:*S6,/>.H;0(P,V0ET3'A*435;BYT0BB5E".H'h.OB5+X M :*./SI'=-8*SE\'E()9:*+ M .
;

fi{:

;2T1A/-ff-8PH6H;)PH;&:;jr;A1/aH6s)I:PA/N

 ):+NHI;/:1/rH6H;8/H6H6H;b6]1-  HN:T/N[
8/5/;)<-/1-8l8-ffN:"H;8//-rIR/[;+N:P5;;8VRGZH65c2
;1[8N:+{5?HoA1;1&VvlTkHRR+lCRNb1:R8Z<J851
8VH-/]Tff/F:+h<Z81l[8vZf/-H)12C"4A4:V-  HP
\;8//-fo4No)-H1:hb;/:yA-f;2]68I:;s8
/54/f-AJH;/:1&&:Nh5+d8:/FH;/:1/FN<h/];HkL\bIThA1:;8H
\T24H  ckf  1H:;8;o)T245;Fr;8/i
 H&)-H1:/-8-8I1AT&&f8:+NH4H;T[N&-F:N-Hy88[G8)
I):1-s8:15-/;/-5-ff:k+/;I1<I;j--2;sGH)1[V):8
  ;I&b:4;Z)-/-8<  -b8:kNH;/:1/b  ;ATan-
:N-l&8+J8)c4H)T8-s;/]-ff:++424;bj-:;V:1I    18;
j8rrb:P/Nf:F[Z/-;H+LG8:15-245`:N-;5rs  ):/;
;I&  [+;
V)V-fff"h]Pv5
1aL;I&\/;&-[<-f]T/;cf+1A\{f;5L[v
 HT/)1-;vA:4:&;v<:s6[ZV;5:1"o)/;H)TH-:;
j-f54H;8/r):):;[jNsf51vIj-F-/;`5"G2-;H+L/
 G:G:;ffvo   ;8/-i1ae1AG-A :5P[Z/-;H+LI;5/:
8;/;/N//N  {;A6&HL   v:{/T];  -1A/-[LH;IJ5"):8N&8:N
-5T2nak)  5 ;/s24;
 
H/-8s  /-Hq)C:8NbP[-F-  :+
8:45;r-_-:1/:CmZr:8:rT
   ]&"-[  8-/;js	
 --R[-R
Hf{G ;5v;vC;5h[Z;ff
 
$-d ;5?;5;:1A45
1G:8[+4;  P["/];HkLA/-;8//i-&;&
 fi:FT:/-_un

/ -f5J;bs;8/
 T
 
:/P8f:+N
 fi/:{::/-\[)-
-1ak8N<
 ]T/8
 J+fT8 \  :/h n:[?;5ff
 
  T/];$  HT/h 1A-;:8
&j-;
 wnA-IjNIH24 -i5J;q;8/
 $j;8/
  j/1H;\




):+N/-I )5/; IT
 
ff"/+;\)1A/-[ P:;ff:;HNff-
T
    qjC8;Hf/ -8)-A;)H-:++/;f5N:;:
 fi:

THT/-A-s-;
 wNs/;\T
 
N<N;/:;d4r:1akVi;8/-
 f-

"!$#&%('*),+.-0/1+2-43.+.-5)6'"+"798:*3;'*<1=

&>fi/:THT/-  8)&s`5;&;5vV;$;v;HF"[Z{[ff
:
C
 8-/;oGI;@?Afi:):1[?/1A[+4;jN]{-R[-R-A;ACBDfiA4:/b4:-
; 8/f  ;A)I-1<Efi/T/G8bI;fHP8):/F-;A8/v<:k
I-[+)-8+54b-VI&h:m4[F
 Gfi/T&8)IbTlFIN{:8-;FH
 fi:



-8ffN/:T[lff
 
1:&;I
 B?ff
 
6H:
 JT<
 Jr/1A- 8):/f  

; 8/v$n:5;Gff
 
 B"(
K
 J.
 Ll1E
 LsNfH84-8PHN-/M
  h:;H8/-;j-8"]

-:;I;HP:fIff
 
/:NfHPI-[+f-8+0
 L I-  [N/&ff
   K B".
 J.
 Ll
NoN rH68-5/-"A/Nff-;(
 O
P5QHRTSSUWVYX[Z\ZV]Z>^_VK`baFZ>cdUWc_X[SNSe	^;VKSfVKg5VhUWi_X[UFj@fNaTklcff`W`bVKmUWSe>noX[SaWV5Q

p5q

firts;uTvwx(y{z"|5}ff~6_|1}rH}ffvTu>sw

ffHTWY[MK>;KW_5E4WdKT>ffb_4;54$5$ 5dWffKM>ffW;4ff4GW_[Wff]4b
_EK1KW_[N>bWff5
ffHT_bY4K>;KWA>ffW_[Nh_KK1TW;4ffW0>ffb_4Eff4b;	5bffK5ff_1WdN]5
4ff"1.WbKK54.bffKE>ffb_4_]NK1Fb_42Wff]t5bd5E["Y4E54d9T	] "9T"
ffff]ffffKb	{NThW4&K>;K"9NMffK"W;45dt[*bffE1N4ffEff1Y

_]NK1KDN>ffbWKbNo4b4_[bW{_K1KW_[N{Wbff5Ao 5(D@_4][


5l]]>K5Y[ Kd5
ffffb54W]N945KbY{b;5bffK1Y2ff_1WdN]54ff	1	WW]N]54;YK4dW

G

o4WK{_4T1MNbWYhW>;ffWdNdW54bT;KNl;Y1	 >ffW_[_;K

dEKd;5{.ffb{K.ffMG;K5Kbff45]4b.9>;ffK5CYffH
]K4K9ff]ff*{ffEff.Y;K45hK.K594.4Y4ff;5d9>_lNTGK.1
.4ff5]9.9ff];4ff5(..dK;4;ff	K]4;5	Effb41ffFffK.H(TK5d;K5K5
94.4EK5ff]0@ffEE50ff];4ff494;	ff_FW>MYff>MW_H(Y;	4K>6
MK594.4HK5d;K5E@K9ff;ff	ffYEff;1.E2N4ff5K2,1ffH	E4ff45
ff;]@.4ff9K.G.dEK4K.]5{Wff6.hK4dK;4ff5(2.ff];4;
ffMKK4_



.t25ff9

dE]T9dKd5(T



].1".l

MoEKff9]94_K.1ff{K;

"5Y;K.2K2

EKEK59{K5E.d	KYK.EF]K5Yd



0ff9K4_MK

.E;;64Nff9;4K

H

]Y1K.1T2N>GK9K4K.ffh



6M@ff4ff.5M

ff ;6hff9K94;E4.K5HK.HK594.4tlY1*K5.dt]K.FK5
ffd54_.]_.;d"55KKlNMWffTAff"	ffK]9ffd(.Y.ffffff.6;4



K



.YHW1]K54;K5


	

ff5ff

;	4]Kd90.;4EK4K]59Kff.ffl1ffff



..;d;YEK590K5HKMWff;bK.ff"

fiff

ff9]94_hDff

ff.]W1K54.1ff;5{ff4@K

WGff>.9;ffK0ff0.;4>Eff;.1ff9ff9;4K5EK

YEK590K5HK5Y;K.F.2ff	K>]4K.ff@]>4_ff494;5



AG4_K4_]




;ff9K94;@ffEM



K

.Y{;6dff1>K5

5Y;NDKdK{].1T.,.d9K94;Y4{

!"$#

.

245KdYMff{1K.K5

%

'&)(

.d9K94;YM ffK

"*,+$+.- /

Td4"

{ffEEE]o4KhK

;Y

4Dff];4d

.];6



94.4Y{.

 

;]0.].ff9



]ffK{K.1t2W

].ff5d>K@5Y;94;

102354687:9;2=<?>=@$ABAB9C35AB0,D!3E2

oNEff	]

F

t]ffKW

HG

Eff4

K{K;KffK">.4Y6lK4_>E5dK;4ff494;ff_1E>MY>M dW*H">;4dK5
ff9]94_@K5

KJ

IG

94.4

ff ;K5hKKdK

O

QP



!Gfi* LG MG

$c

d



M5Y;N;D

fiN

ff dW ;"K52ff.

[Z\X=X=S^] fiX _ ` ba
ec

5"5]]4W44

WT;5b5bffK1F44_h_1[N d15ff

`

YffG\ffKK0]5

h;NMYEK590K5

FRTS VUfiS$WYX

5H ffW]t

d]YK5



1" ( "K

(T d$Y5E]



_

_4"5" ffW[W5[ M

4FK1KY[(ffTl5MWW

F`
fd
_
"RgS VUfiS$W%X
d
h ic
[j8kl!mn] nS,opUWYS qfkVl!mn]
1Z\X=XrS] fiX
c
d
s8tvugwyx{z}|Y~rELYL^|QK:B%|KLBu1x{L/C$=H~5H|QtLv%=r=$,:|%555Hgugwx{LCL5Bfi=,.
Q==rt
tv,ugwyx|QL~5L,L,~|YL55LH=|%H:|Y,~5,fizfizfiKK$,=!L,L,L5y5~ELKKF5YKL%zfiL
,~5EL,EL=$t
W

dKW

Wff

ff

"5b

ff

Kff5bKT5bffKff	>dW_[ff_]N.GW_["9_[Fbff
1051ffWbff

ff2WKb_1_	

ff;_4bff

(TDW5bffK5

((W

(T>
1





(TDW1bffK5E

$O

[W[



5WM5bffKWhW_[

fifi"V
$Ev5$$,pI^\5\$Cpr
,rVCV1$fi%VC\%.%=VvY%$V,B[gv%C=VC,b%%VC\%$%=p

  v=  V=$vV%BV%IV1=    Y^F=[=%YY,  $=.H
 V
%$;/%v'%Vv=1%85V='rBEv%.%=   v.%rV
vv.$r=.v%rVr\%gV5$r=,
VQI ,=$$C/%[	
 ggpYff
 
$%B$V$fi
$	
 g   V,%vg5%B% .,v  ^%='!=:$,/%v  CB$%V$,fi
v$YV^Vi$\%%=  vQ\V5$  rg%,  %,8
  %%  .%$!
 '!=.,B%v
%  V  =    
 C$$YV.,fi  v[Y%%
 p$Kv;fi  ,%%$I.;{$$
%%.$i  vF%Yrv  \%  ,%%$ r
 $%ff
 I  ; =.v%rv%, )   vr
 ."%
Ve.  $%rv$  v %
%Y$$
 gB% ?v.;%,f%,     vr  v
=$vV,!$Ci=$" !v  $!%I%[,=V;Q  gf1$#  $ ;\.,=V;Q,f
$B$V%=5v,
 $F.$C$v\  $/%, )   vr  iv Qv%1$Q %v$,
%v%  vi.viC%Qg5$5%%g$' &fi
(*),+.-0/21435687:9;1=<*>?@/25"A23B

p=$Yr$\%IHV\Y$v8yY =.v=[DC!EGFIHfJKLCg$\v$, $HV
 %\%$ 
NONP%\%R
 QTS\=vL
NNPU%%QQVCV,D
NONW"rpvY,$fiX
 VrfY%vVM
%=,\$ /$=V%Q.v%%vV$, v5 4F$, ZYIE$5!FVCY
C\  Cg%1$V [L.  
, v5 !5CO
 i5Vi$=$ \f.,/v.$CVv"$V [L] !5 v5E iE.CF.%,=%,IY^F=
rg=Cv.r%$ [L.=$v\$\%rFI$%.* [LV$=Q.
 ^Gv5 v5E E$CgV !v,.Ci
B V  %v$VCV
v..;Vv^[%
rI &$1$=$v8vYv.= / VCQ.?$=Q.v
%vvV. .Y:rYgr%,  %,%,  $F%,  %vQe$  $%$,r$_ &
 %\%
Q`S\=v=
 
NNPar
\b
  Cg=%:
 cedVE CvV EG FH 	fX
 F$[h
 g E=5E$ C! EG FIHf L L =v/:F!
%iV !vV$ff
 Xfiv%5 %{=f%  ' &gv$[IL = \ X%
V i %%,Vr%v$'F%i$Y $Qv,=gIHV1$=Q.j
 i CeVV%  ,fi
kVCIvYvV,  %v[!==iv $Y  I Y=  V%Y,Y!j
 lnmYVo
 iT
 lDm ;
'!,Yp !$ i$=$vr
 q*sFFVCY F  ,=%, vV Qv,Yt !v, =.v%rVr
=$vQY%,\v5$  v=Bu i":
 XL
 'H* vMw
* i* kXx* k m * l m V$%,g/$%.o
 yLz[L\VC 7
g  r
 k x %
V $=Q. igQ  
 kDmv%,YvM
 lDmfi
 {% |v$} XL KHf~ vw i k x 
kDmfi
 lDm;t %\5^i=$v.$v\%[%C !v,= 
,X
 }t,%J
 Ypv8Z , hIJ
 "tt' '  Z#$' G , \: %n
 Z2$0 $p pt p,
 !en
 F
 $ 5 , ZJ0%   ,% [ }!
  }.0
$X
 }t[%J
 V%D
 0 J
 OZptDV' ' ,L Z}X[ $prt VFE,  
$L
 $yG   ' y
  
 "} 
 =$C    $ rt V
   G 0\
 F tJ
  , TG 0:y0
[p  Z5
 $ ' 8p,Vt J
 $ *",u LK;ZG]Zt$" 
 Z : $2 =$C
:Vt ^ "rK
 Yp8u 0V' ' ,L Z0$YpF_ $ } \prQp V  RZ0  K 
 $p JV O
 $%%J
:
 Zu 8@
 =$C ] O $%"%J
 V%p
 F. $ b  C%
2G0KGX'4_]ZL_f0p'u*n0__J;b,~J}K,==
K_D;,';t4'K}f_J:]0GL0K_"'GG


fiu"}=r*Z X}J

}	ff
fiff	 !	fi#"%$'&"
ff!
 fi#ff()+*	#,
-/.'021.436570#8'9:;36<>=.'0?57@A3BDC	EF50#B=7?G8	0#B7HI5DEFJ402=7.'0K0<	=DEF50MLN0JA?POQ3R=0#36S2TUBVEF<	=0<=)EW?X<4BY36<48
J40I:EF0IOffBYL.'0<>0<'Z	36Z0#8GEW<>=70#36SL[?X5\^]`_ff<>=.	E;B0<48	0#3ba?5bcd3P<fe19g50C'570#BD0<=IBh3`:EFSEF=DEF<'ZfH3XBD0i
j B j 3b::F@c'L.'0<k0<'Z36ZX0#8EF<M3=0#36Sl3HI=DEFaXEW=D@c'3=70#36Sm?<	:F@Y.43XB[3VC4365=DE;3b:1.43650#8'9d:n3P<2op9/19Nq(]	-N.'0
9N19rEnBs3MBD<436C4BD.'?X=?6O[=.'0=0#3PS2TUBtSY0<=I3b:uB)=(36=0sEF<A3kC4365=)EnH j :;365B EF= j 36=DEF?<REF<v=.'0IEF5s=0#36SLN?5\wc
36<48RO j 5=.'05HI?XSYS j <	EnH3P=DEF?<A36<48xC	:;36<'<	EF<'ZRE;B?6Oy=0< j BD0#8z=?{O j :|'::=.'0KHI?<48XEF=DEF?<4Bs?6O36<ve19
op3b:F=.'? j Z.}c~EF<G8	@	<436SE;HY8	?XSK3bEF<4Bcw=.'0=0#36SSK3b@M<'0a053HI= j 3b::W@ROy?5S36<e19/q(]~v0sO?'H j B?<
=.'50050I:F0a636<=3P50<43BtEF<xL.	E;H.vC43P5=DE;3b:EF=p@RSK3b@M0IE;BD=VEF<G3M9/19]^eEF5(BD=bcw=.'050#H7EFC40KRSK3b@MJ~0
?<	:F@vC43657=DE;3b::W@BDC40#H7E|40#8w]x057=(3bEF<	:F@c}EF<>8	@<43PSE;HY0<	aEF5?X<'SY0<=IBcB j H7.>3B=.'0Y?<'0#BV?6ONEF<=0570#BD=
EF<>? j 5YLN?5\wc50#H7EFC40#BkHI? j :;8>J~02HI?<4B E;8	050#8>=7?0aX?6:Fa0K?6a05=DEFSY0cN3Bs=0#36SkB570#3HI=DEFa0I:F@f8	0#H7E;8	0
=.'0k<'0I=YBD=70CAJ43B)0#8J4?=.?<=.'0MHI?<=70I=Y36<48z=.'0MH j 550<	=BpEW= j 36=DEF?<}]ve'?X5EF<4BD=(36<4HI0cuEF<>=.'0
 ==I3H\8	?SK3bEF<}c=.'0M.'0I:EnHI?XC'=052HI?SYC436<	@vSK3b@50#3HI==?v0<'0S@a0.	E;H7:F0#BMBD00<>0<'5? j =0c=. j B
0a?6:FaXEF<'ZM=.'0IEF550#H7EFC40]  HHI?5I8XEW<'ZR=?R19=7.'0?5@cw=0#36SSY0SJ405S j BD=3655)EWaX0h36=S j = j 3b:%J40I:EF0IO
EF<2=.'0IEF5<'0I=BD=0CwoDBIq}D][e?50#3H7.B)=0CM}EF<2=.'0s50#H7EFC40cw=.'0s50I:F0a36<	=B j J'Z5? j CMS j BD=/O?57S3
1.43650#8'9d:;36<}]
10#HI?X<48wc=.'0R=0#36S2TUB=(3BD\3b::F?'H36=DEF?<SK3b@>J40>	4D(I~#+Ic%0]Z4]FcN=.'0x36Z0<	=K?5kZ5? j C=?
C405)O?57SC4365=)EnH j :;365=(3XBD\xSK3b@<'?X=J40M8	0=05SEW<'0#8w]`_ff<>=.	E;BBpEW= j 36=DEF?<}c%=0#3PSSY0SJ405(BVEF<=70<48
=.436=t=.'0500I	E;BD=BD?SY0VEW<48XEFaXE;8 j 3b:[?5B j J'Z5? j CR=?K8	?k=.'0=I3BD\w]  SY?<'ZK3XHI=DEF?<4BHI?X<4B E;8	050#8x3B
350#B j :W=?6O%=.'0EF<=70<48XEW<'ZM=7.436=#cXEF<48XEWaXE;8 j 3b:BVSK3b@Ya?6: j <	=005=7?YC405DOy?5S=.'0 j <'50#HI?<4H7E:F0#8x=(3B)\^c
?5C~05(B j 38	06b?5(8	05?=7.'05(BN=?Y=I36\0?aX05[=7.'0=(3B)\^]
-/.	EW5I8wcwEF<48XEFaE;8 j 3b:;B{?5B j J'Z5? j C4BSK3b@2<'?X=.43#aX0K36==(3EW<'0#8x36C'C'57?C'5DE;36=0YS j = j 3:J40I:EF0IOBsOy?5
Oy?5SEF<'Z>36<re19c:F0#38XEF<'Z=7?AHI?SYS j <	E;H36=DEF?<LNEF=.	EF<=.'02=70#36S2]?SYS j <	E;H36=DEF?<SK3b@>3b:;BD?
365DE;BD0M8 j 0M=?v36Z0<	=(BTN7EF<=70<=DEF?<=.436=I236==)EW= j 8	0KJ~?=.>=?6L365(8'B=.'0IEF5Y=70#36SZ?	3b:/36<48=7?L365I8'B
=0#36S{SK36=0#BT3HI=)EWaXEF=DEF0#B]%e'?5EW<4B)=(36<4HI0c63N=0#36SS{0ShJ~05#TUBEF<=70<=DEF?<s=.436=wEF=(B=0#36S8	?3P<3HI=DEF?<}Dc
36<48sEF=(BuJ40I:EF0IOd=7.436=HI?SYS j <	E;H36=DEF?<k?6OB)?SY0C43657=DE;H j :n3P5%EF<	O?X5SK36=DEF?<{LNE:+:}0<436J	:F0=.'0=0#3PS=?8	?
}Dc6LNE::':W0#3X8sEF==?HI?SYS j <	E;H36=0N=.43P=}EF<	Oy?5SK36=)EW?X<h=7?=.'0=0#36Sop3B:F?<'Z3BB j H.YHI?S{S j <	E;H36=)EW?X<
8	?	0#B<'?=HI?<	'E;HI=LNEF=.2C'570aEF? j BHI?SYSEF=S{0<=(Bq(]
}Fl^vb~[w4}6R4	wv^b^	^6n{}sM
_ff<1-  c	p?6EF<	=EF<=0<	=DEF?<4B3650 j BD0#8z3BJ j E:n8XEF<'ZvJ	:F?'H\'B?PO[=0#36SLN?5\w]{10a05(3b:[38	a636<	=(36Z0#B
3HHI5 j 0x8 j 0x=?v=.	E;B j BD0]eEF5(BD=#cN=.'0xHI?SYSEF=S{0<=(BhEW<3kD?6EF<	=YEF<	=0<=)EW?X<rJ~0Z6EF<=?vC'5?6aXEn8	0x3
C'5DEF<4H7EFC	:F0#8>Oy5(36S{0L[?X5\MOy?550#3BD?X<	EW<'Zv36J~? j =YHI??X5(8XEF<436=DEF?<>36<48>HI?SYS j <	E;H36=DEF?<zEF<>=0#36SLN?5\w]
-N. j Bc6=.	E;BOy5(36SY0LN?5\J40ZPEW<4Bu=?38'8	50#BB=0#3PShLN?57\Off3bE: j 50#BB j H7.Y3B=.'?BD0EF<YeEWZ j 50']%10#HI?<48wc
=.'0%D?6EF<	=[HI?SYSEW=7SY0<=IBEW<sD?6EF<=uEW<	=0<	=DEF?<4B%C'57?aXE;8	0Z j En8'3P<4HI0Oy?5%SY?<	EF=?X5DEF<'Zh36<48Sk3bEF<=0<43P<4HI0
?6O3M=70#36S3HI=)EWaXEF=D@c}Eff]0]nc36Z0<	=(BsBD.'? j :;8vS{?<	EF=?5hHI?X<48XEW=)EW?X<4B=.436=H3 j B)0K=.'0{=0#36S3XHI=DEFaEF=D@v=?
J403XH.	EF0a0#8k?5 j <43H7.	EF0a36J	:F0?5uEW5750I:F0a36<	=#cw36<48YSk3bEF<=(3EW<M=7.'0=0#3PS3XHI=DEFaEF=D@K36=:F0#3BD= j <	=DE:?<'0
?6ON=.'0#BD0YHI?<48XEF=DEF?<4B3P5DE;BD0#B]-N.	EF5(8wc3Vp?PEW<	=EF<=70<=DEF?<G:W0#3X8'B=?M36<x0IC	:E;H7EF=Y50C'50#B)0<=(3P=DEF?<x?6O[3
=0#36Sl3HI=DEFaXEW=D@c'36<48{=. j BOff3H7E:+EF=(3P=0#BN50#3B)?<	EF<'Zh36J~? j =N=0#36SLN?5\w]w_ff<MC4365=)EnH j :;365bc3XBBD.'?6L<:;36=705#c
36Z0<	=(BH36<K570#3BD?<K3PJ4? j ==.'0570I:n3P=DEF?<4BD.	EFCMJ40=DLN00<K=7.'0IEW5N=0#3PS3HI=DEFaXEF=p@k36<48K3P<EF<48XEWaXE;8 j 3b:ffTUBt?5
B j J'=0#3PS2TUBHI?<	=5DEFJ j =DEF?<4Bt=?sEF=#]
t?6LN0a05#cw3MB EF<'Z6:F0p?PEW<	=EF<=70<=DEF?<GO?53k.	EFZ.':F0a0I:N=0#36SZ?	3b:ufE;BEF<4B j	 H7EF0<	=h=7?KC'5?6aXE;8	0
3b::[?PO/=7.'0#BD0K38	a636<=I36Z0#B]M-?2Z j 365I36<=700HI?X.'050<=s=0#36SLN?5\wc~O? j 5h38'8XEF=DEF?<43b:NE;BB j 0#BsS j BD=J~0
38'8	50#B7BD0#8w]Kt050c}=7.'0K1.43P50#8'9:;36<4Bs=.'0?57@2.'0I:FC4BVEW<36<43b:F@BpEnBs?6O1-  TUB36C'C'5?	3H.}c}3P<48REF<
?<'0H3B)0c41-t  8XEF50#HI=D:F@MJ4?X55?6LBOy5?S1.436570#8'9:;36<4B]  \0@k?J4BD05a636=DEF?<kE;BN=.43P=[36<43b:F?ZX? j B
#

fiw'	

R46D;b46#';64N%'	;'Y'>D464D'X(6'k#6RUY	(b/)(6''hX;
 6 FNF		DF4
/'4ID;D'NF	6F#IX'4IFY7#6[X#6Y4Ih4)%''(D'I{Y
D6F'DFz46RFfD7;IY6N'IF  6FF		DFxy'	F'FI#6u 4	#w%
 '	F'
 	X4D#bNF''%D47YI4DIbF#b#6gY4II	;s''(D'bF746DF
D6F'DFx46744PQ64II%#7x'#wDk'K'X#/;K	76I'N'k46#'dnP
'ff 
2'	#D#D47I'74Ihfi
 
2D'	F'M~ 
4M7'#6Y4I
 (W		DF4t46 
66(' GX'XW)WX}%46#'d;64KP4'6#th'74bd~IWItWKI{Y27#7W~
 M
46)n P446#'dnP4yF4XWX;	4bD4
 %Fv'kIYYx#7F~74'I6DF'2
#I'(pWX	F(6(7fi
 
K{4D'hIX'4I
t%A 6''77Y'46IbWI;46%P46#'d;64 	'6[X#bF'	;'X  PW	F7'
DF4(P'46z46#';64YN46tn%uQ 4)#  6FF	)WX4k'	nXF'x	F7
s	WI6(7	n+ 
M'	;M'k'YIb67DF4	P^F4XFXn	4d#PmY4I'64Y4)'46
#6Y4IY''()'GzIYYD6F'DF46}ff46D;I	;6#Y{DF'##6)+F#/F
fi 
	46;	kbF44PWXM#IDFs	nP44#7F~
 MK 
YPWXhDMfi
 
MD	')W'k '#I'
DF}tff%4t'#7F46F#'/kD   7 !	F# '#I'DFx"
 
M7'	DF#62
uQ  !X	F#467'DFs#6PX#
 pw64{y  6F	F	)WX4{ #I'VF#
 '#I')'4DY6
 DX'  6FuF	DF46NyY#wPF#XF'h7	F(6(7fi
 
%
 $'DF'
's 464pWXP	;	WI6(7"
 
/kDMF	6F#	 
xYD''#6'x46D''#64D
y   6FtF	DFM{4Dy 746D}uy%	 
26kF4XWX;	4b;F	6F# WR'h)}	F
4D%ymPF	DFk	746[D7} KX'(bff't#D	FDF'F7DF{	WI6(7"
 
YX6F#
fi 
	46;b 
}	44XF'MM' F46DF4N7'#6l4I'	(
#IX4w'
 &7) ([P4+
 *I64,
 .-fiX;I47%'N(X	0 /wF'6{'6'F	yK6)WXY#6
Y4I4DKbF	(bFv64'#6{K6#~IDFFDF#46D;I	;6D 
x'xKD71
 2W	6F#
	 
ARD''#62PvF4XF;	4bff3
 &) (KP44
 *(64'	#7	;s(	5 /AF46#';64
D'6RFG)4
 66RW#IDF4
 6'8 7'~ !X	W)W'R46#6Y4(	'6	 
24PQ{#7F4
 	n)(x46	FG#6YKP0 px4Dy F(YI)WX4''{''2	(b;YP'M#7F4
6F;6D 
t% !	F#s4PFfXDK2)4
 N;s4)7Y#xfi
 
GRD''#69
 ffX  4D6
F4XF;	4b%#6lY4: (kbF	W'{#6lY4(I'D''#P2U  6F	F		DF;
 ff
'Y7IW66	h7#6Y4# F7DF<
 M4)7'K)}KN	;VF7DFz(7F'R'#
'VW	6F2	IbW#	;6#IX	W)WX}%4FVFA''XF4sN3
 p64=
 >
 -fiI
ff4)#wk7#6{h~4D	 
x4K6	FY7kW	y746F(V#6Yk6#/W	43
 QP''
K	z'F74?
 v '#I'27'2D@
 /	nF	WkbVIX4D(bF	;Y'#I#76A 
4#64)
'7N;D#PmY4I%K 
4'4P	W7Y	F'I'	[)(646}'t#6XIDFF) 

4n%46'IFY#P IDFXW) 
4sffbFr6467#v r'XFDF}NDYkF	yKPDF64X'Y'
	44	4 
kI;6DF4)	WM6YX'#6Y4II)WX4;%4DIy	4FY{	FDF'4	%X;I4D#
Fv#IDF B48 7'
	F({;D';'64bF'67'
 I''7#I47W#'
 kDtFx46#'dnP4t%yK
  6FW		DF>v7	nP''kx#62   6F	F	DFyKv)@
 tn{Dx~
'47	F6	F;
 N	;6'	F'AK 
RF#z'Y#6 k4(D64b 
fi(K'k64Dk6'F	FD;b''
7	F6	FC 
RY'M's47 F	+FDF#'K64) I	;z4Y7'K64D4Ik6 F'{6
MD''(XDM2kD''#6F4XFXn	4u7'ffbF'Y6N'IF6	F4XF;	4bXQD''7#6
FA~DyF'x'KD''IDwK f)4>MD#7A7#6Y4YI(V2	W'k'M6'
'')nP26	KD''#PyY~DyF'v'M7IW66	K(XD^zQ{x#D	F#N66	Y6
6F'	%F()I+	D'X#DX'%F4XF;	4b;tD''#PK%~Dym7''4 F'#{()^

DE

fiFHGfiI%J'K'L<MONPQR'SUT"PQVF,QJ'W%IXG'K'Y
Z=[\]^'_`)abficAd'ae^'fhg.\Adfiiajkg5lfiinmoipc)q#rsgqtl?aXcAd'au_Aa`)^fimc=]0[v]cAd'a_w\g0^h`xa`%l?a`yipzfia`,mpg\ff{s]0[vg`ff`yi|f'rtaffic}
_Aa~fimpg0f'ffiif'|#r^h`)cwcAd'afg.z'zfi_Aa`A`=cAdfiip`]cAd'a_e\g5^h`)a[^'_AcAd'a_ez.ip`A\^h`A`Ci].fifa\c)i]fhfi
hfhgm<ip`A`)^'aiU`|af'a_gkmnig0cxi].f]0[="w>X38`=\]rtr^'ffiip\g0c)i]f;\g0~hg0lfiiomoicxia`uj.ipgtgdfiq"l'_xiUz g0~'
~'_A]"g.\Ad cAdhg0ce\]rlfiif'a`cAd'a~'_Aa`ff\_)i~'c)i]fh`X]0[>cAd'aC]0ifficwifficAaffic)i]fh`eg5~'~'_A]"g\ffd=icAd;`)]rtag`)~?a\c`
]0[>dhg0_Aaz'mpg0fh`>{.aq+].lh`)a_Ajkg5c)i]fslhg.`)azt].f#Ae_ff]"`)eu_g0^h`b<	<iU`,cAdhg5c%cAd'ae\].rtr^'ffiiU\g5
c)i]f ifOC]0ifficuif"cAaffic)i]fh`X\]^fimpz ~h].cAaf"cxiUgkmnmq;lhaOg0_A_)ijaz g0cwif@dhg5_Aaz'mpg0fh`uj.ipg#g"i]rO`ezfiahffiif'|
h?p.4" O']_uifh`)cg5fh\ab\].fh`yipzfia_cAdhg0cgOcffag0rrtarlha_dhg`u]l'cgif'az~'_)ijkg0cffaiffi[]_ffrsg0
c)i]f4g0l?]^'cecffd'a+g\ffdfiiajartafficX]0[%cAd'acffag0r8`u\^'_A_Aafficecffag0rg.\c)i]fv0fO)]0if"cuifficAaf"cxi].fh`b<cAdfiip`
cAag0rrar+l?a_=iomom`xaa{1cff]g0cAcgif4r^'cA^hgkm%lhamoia[wifVcAd'aOg\Adfiiajaraf"c]0[Hv0bmagz.if'|1cff]\]rt
r^'ffiip\g0c)i]f#yfV\]fficA_g`)cb?ifdhg0_Aaz'mpg0fh`b>cAd'acAag0rrar+l?a_8`X\]rr+^'ffiip\g0cxi].fV=]^fimpz3g0_)ip`)a
lha\g5^h`)awiic hh0X" cAd'aXcffag0rzfi]`x]rtaXg\c)i]f#vuwdfiip\ffdO[]5mnm]0e`=0b	g5fhz ioi,cAd'aXcAag0r
\g0f'f']czfi]#X=icAd']^'cgkmnm%cffag0rrar+l?a_`ulhaif'|4gwg0_AaX]0[wg\Adfiiajaraf"cX]0[%0=dfi^h`b?[^'_ffcAd'a_
h_`)cX~'_xifh\ffi~fima`_Aag.`)]ffiif'|hblhg.`)az;]f;ifficAa_A_Aampg0cxi].fh`)dfii~h`+g5rt]f'|g\c)i]fh`:b<ip`X_Aa.^fii_Aaz;cA]zfia_xij.a
_Aamajkg5f"ct\]rtr^'ffiip\g0c)i]fifdhg5_Aaz'mpg0fh`},l'^'cifVcAdfiip`ifh`)cg0fh\ab?)]0if"cifficAaf"cxi].fh`~'_ff]kj.ipzfiat[]_
`)^h\ffd1\]rr+^'ffiip\g0cxi].f#=icAd']^'cucAd'aX_Aag`)].ffiif'|?
yft|af'a_gkmb5io[cffd'aHcffag0r8`cAa_ffrifhg0c)i]f]0[].f'aeg\c)i]ft>ip`a`A`)affic)ipgm'[]._>cAd'a=cAag0rcA]X~?a_)[]._Ar
`)]raX[]0mom]0=if'|;g\c)i]f  b<cAd'a~'_Aa`ff\_)i~'c)i]f;if#)]0if"cif"cAaffic)i]fh`cff]g0cffcgifr^'cA^hgmlhamoia[wif
cAa_Arifhg5c)i]f]0[%cffag0rg\c)i]fh`ip`Xgzfia.^hg0cAa[]._w_Aamajkg0fficX\]rtr^'ffiip\g0c)i]fe]0=aja_bfiif1`x]rta
\g`)a`:begz'z.ic)i]fhgmt\]rtr^'ffiip\g0c)i]flhg.`)az]f`)~ha\ffio\iffi[]_ArOg0c)i]f'zfia~hafhzfiafh\q_Aampg0c)i]fh`)dfii~h`
g0rt].f'|g.\c)i]fh`iU`gmp`)]4a`A`)affic)ipgmV]_ifh`)cg0fh\ab,cAd'a`A\]^'c`Xif@cAd'a#cAcg\ff{4zfi]rsgif@f']c]ffimq
iffi[]._Argkmnm>\]rt~hg0ffiq#rtarlha_`]0[%\]rt~fimac)i]f;]0[>cAd'ai_`ff\]^'c)if'|g.\c)ijic)q;C`)]tcffd'a\]rt~hg0ffiq\g0f
rt]0ja[]_ffg5_z?b?l'^'cgmp`)]#cAd'a~'_Aa\ffip`)as\]fi]_z.ifhg0cAa`u]5[Haf'arq#m]'\g0c)i]f4cA]Oafhg0lfimatcAd'at\]r~hg0f"q
cA]O]	\\^'~fiq#|]fi]	z;g0cffcg\ff{if'|t~?]"`yic)i]fh`iffi[]_Arsg0cxi].f'zfia~hafhzfiafh\q?^h\ffd\].rtr^'ffiiU\g5c)i]f4\]^fimpz
gmp`)];lha#~?]cAaffic)ipgmomqzfia_)ijaz[_A]rcAd'a#g"i]rO`]5[ hh@" ifdhg0_Aaz'mUg5fh`b%l'^'ctg0ccAd'a
\]"`)c]0[[^'_AcAd'a_w_Aag.`)]ffiif'|h
">Xzfi]fia`f']c_ffamq]fcffd'a>h_`)cff~'_)ifh\ffi~fima`_Aag`)]ffiif'|[_ff]rifficAaffic)i]fcAdhg5c[]_<ic`\]rtr^'
ffiip\g0c)i]fbfi_Aamq.if'|]ftcAd'au~'_Aa`A\_)i~'c)i]fh`,]0[')]0if"c,ifficAaf"cxi].fh`>ifh`)cffagz<>w]0=aja_b"w>Xa	~fim]0ic`
a'~fimnip\ffictzfia\ffmpg0_g0c)i]f;]0[>iffi[]_Arsg5c)i]f'zfia~hafhzfiafh\q4_ffamUg5c)i]fh`)dfii~h`g0r]f'|g.\c)i]fh`b?[]_g.z'z.icxi].fhgm
\]rtr^'ffiip\g0c)i]f==dfi^h`b'wd'af;\]rtr^'ffiip\g0c)if'|OcAd'aXcAa_Arifhg0cxi].f]0[%gcAag0rg\c)i]f#)b<"w
\ffd'a\A{'`[]_%g0ffiqXiffi[a_A_Aaz]_%zfia\ffmpg0_Aaziffi[]_ArOg0c)i]f'zfia~hafhzfiafh\q#_ffamUg5c)i]fh`)dfii~h`,=icAdsg0ffiqX[]0mom]kif'|
g\c)i]f3<k;=d'aiffi[]_ffrsg0c)i]f3_Aamajkg0ffic[]._<ip`tgmp`)];\]rtr^'ffiip\g0cAaz3wd'af@g0cAcgkiffiif'|;r^'cA^hgm
lhamoia[wif;cAd'acAa_Arifhg0cxi].f1]5[H)XX`egO_Aa`x^fimcb<lhg`)az ]f;cAd'at`)~ha\ffio\iffi[]_Arsg5c)i]f'zfia~hafhzfiafh\q
_Aampg0c)i]fh`xdfii~@`)~?a\ffinhaz<b>z.ioa_AafficXcCqfi~ha`u]5[%iffi[]._Arsg0c)i]f4g0_ffa+\]rtr^'ffiip\g0cAaz<b2wd'af4cAa_ffrifhg0c)if'|
  #=d"^h`:bvcffd'as`A\]^'c`\g0fV\]rr+^'ffiip\g0cffascAd'am]'\g0c)i]f3]0[waf'arq4^'ffiic`Xd'af\]rr+^'ffiip\g0cxif'|
cAd'a\]rt~fimac)i]f;]0[>cAd'ai_`A\].^'c)if'|t#|0ijafcffd'aXiffi[]._Arsg0c)i]f'zfia~?afhzfiafh\q;_Aampg0c)i]fh`)dfii~4=icAd cAd'a
~fimpg0f'ffiif'|s]5[2g5cAcg\ff{if'|~h]fi`yic)i]fh`>[vf']t`)^h\Ad#_ffamUg5c)i]fh`)dfii~Oip`w`)~ha\ffiohaz<b?]_>io[>]cAd'a_,_Aampg0c)i]fh`)dfii~h`
g0_Aa`x~ha\ffiohaz<b<cAd'a`A\]^'c`==]^fimpz\]rtr^'ffiip\g0cAaz.ioa_Aafficwiffi[]_Arsg5c)i]f
">Xcffd"^h`O`)cg0_ffc`=icAd4)]0if"cif"cffaf"c)i]fh`:b=l'^'cscAd'afl'^fiiomUz'`^'~dfiia_g0_\Adfiip\gm`)cA_A^h\cff^'_Aa`
cAdhg0c~hg0_gmomamwcAd'a dhg0_Aaz'mpg0fh`cAd'a]._Aqb~hg0_Ac)ip\^fimpg0_)mqb>~hg0_ffc)ipgmedhg0_ffaz'mpg0fh`;=d'aO_Aa`)^fimct\]^fimpz
lhat\]fh`CiUzfia_ffaz4gOd"qfil'_)ipz rt]'zfiam%]0[%cAag0r=]_A{<b'cAdhg0culh]._A_A]0e`[_A].rcAd'at`)cff_Aaf'|cAdh`]0[%lh].cAdOC]0iffic
if"cffaf"c)i]fh`[]_ArOgmoig5c)i]fs]5[\]rtricAraf"c`if#l'^fiinmpz.if'|#g0fhztrOgif"cgkiffiif'|X)]0iffic%ifficAaffic)i]fh`%g0fhz
dhg0_Aaz'mpg0fh`Czfiacgiomaz;cA_ffag0cArtafficw]0[%cAag5r8`ug0cAc)icA^hzfia`ifV\]rt~fima1cg`){'`bg.`w=amomg.`w^'f'_Aa\].f'
\ffiomaz4cg.`){	`X=dfiip`uip`u]0[\].^'_`)af']cXcAd'a]ffimq~?]"`A`yilfimaOd"qfil'_)ipz<X`urtaffic)i]f'az;ag0_xmnia_b[^'_ffcAd'a_
a'~fim]._g0c)i]fif cAd'a`)~hg\a]0[vcAag5r+=]_ff{trt]'zfiamU`ip`e\ffmag0_xmq#a`ff`)af"cxiUgkm


fi<'%fi
>O>s;
"w38hypU3	')'4fi5AfipuA)tfip0h:tt=A5AfiAff'A
tfi)'@)@X=''0.)hu5w"w>XAp0AAuA0= #0h0fioo)
=' 'k. u#"wU 
	fiff
	fifiyA)=A0 fip0h
  't0fifih
4"w)A5h0A,=	')A' th)0"xU5A
 
	fiff  "!#$!%!#" !
20?0A.X'fioUff)& @''AA#ff08( ')0"tx.)>'fio& #A'tfffip0*
 )ffh..pfih
?0A +wfipA 	'Affw00fi8,0wx.)( ,ff'Xfi0ff- /
 .2'A1
 0'h5A
)'0w 
 243u)hA5
 28>'"5 3e0A A09h0A:%wfio;A'O0Ah..pfih+.h0ff
20x.)w)hff.6
 	fi798"8:$!-;<fi79>=?	 @AXB
 =?	 "$!-;C=A-"8:1D	fi8:(EF$"fi!G@
fiH-
Ie5Aw'0
yo& ;	'ffA)4A0.h0ff<X)'0wJ
 .2.'AK
 0'<=AVx.)X0>h..Ufihk
)''A5su	'ffA)4ufffinpfiA30=A')h0A:L
 C20h0As0  =AM
 )9NO+O0A
 "fipo& ''A #)''A0O,Afipufis: 
Q
Q

R

[ EXECUTEMISSION ]

R

[ Flyflightplan ]

............

Q

R

[ Engage ]

............

S

[ Waitwhile
battlepositionscouted ]

[Flycontrol
]
route
Q P

[ Travelling
Overwatch ]

[ Travelling ]

High
level

Low Contour
NOE
level

P

High
level

............

P

[Travelling
] [Travelling
Lead
Cover ]
*

Low Contour
NOE
level

............

&
Scout
]
[ Mask
Observe ]
* [ forward *

Employ
weapons

P

R

Unmask

*

Mask

............

waitfor
scouting
............

Employ
missile
............

popup

Initialize Maintain Select Gotonew
masklocation Dip
hover
position Mask

2'ffT0UwAOfisVUWff)#0>t	.:Xhh5Awfi0AYsffZ
	fiff[
	fifi
.

X==AOh..Ufihk%h5AfiA5.h0ffwp)Ohyp)w0 U( %'Ah.);Afi \]o^ 
0'fiop0)3Afi\>0hJooXAAh0)AfiK'A'0h5AUOA5h5Au
0Oh.pfih=h0A=puY "h5po_ ;fiAA'< ,yh0AxUfip0hw';015"a
 `." 
0Oh0A,	'x.'A'w?0A.>pw0''0A=A#0b
 )'')'5"
 +'wfipff#s9 
hOY "h0Ukn& 4fiAA'AOhs5h..Ufihkx''A0<A0 c
 ,=A'*
 )	'x'
0fi> +peh0A)pfip0uA0u)''A0A'Xh0A=pufiAA' AhA0 h5A
,wA'
 )	'x'40."> +pA's0fiT
 `.>xnA>A'30;h.pfihe.h0ffXA)fiO=fih
'Affp)A0 	')'#tff0 h5A=p'etfio ?''e0?c
 dhfifi_ 4fiAff'
0='')#)t .2'A1
 0Afih,ooh)A0ff=A'Y Xh'0)O0v?0A%ffh0,Ue fifip<
A'Xwff sfis
fs0s5AfiA0
 A0 h5A gBW"o<A0th>h)HCfi0'.hy& s)a
 gBW
AO)0fiop)Vh
 ')0""Afi)J
 &')0"ufiAfi) <
 gBW=ooHhtfi'ff1.1
 2:gBWi3"jia
 ,b
 .2'A
0'fi0=A'efi'x%'ff'eA5As,6
 ')0fi>"ff")Oa
 2 	'ff kpAy 3"jl ,y)A.pe0
Afip ')0",fiA"x.'A'uA0 s9 ff m
 ')0",fiA"x.b
 2 '"0 3 j ? ,xApX0 2 '"0 3 j 
h.pfihwA0+?XoH)Xh..Ufihk.h0ffA#tfiF -k=0?h<Afih.A'
h.pfih,fiAfi)h,e "xfffi0ffY #0n ')0fi0hh..pfih%fiAfi)h=pAfih,.At
w';00fi=h0A)pffh0AA0= <
op

fiqsrYtuvwyxGzV{|fi}~-{9|Zq(|fiutcrv

-6?c%fibfi-cG9&->O_%&>cF6&O><^ficFY:"F&fiJF&>_% &
  Y%Ofi#>F >F%*
F><FY&Ffi%>fi>>Fa"m1FfiY
 F%>fi
KY
F6LF*aT%9#
:_
KF#ficKfiyfi4%&#&bV
F%% 1Yfi
9&V F>?&%&%Y6
Yfi> &%FiFn("F% &Lfifi?6
F("?%%9:&
&Y&"9:_G_1&Yfi&fiTF#fi?(F*fi%KfiKL#>&TsF*9%-e_Y&
%9OO"FY&L
fiKLY"F&fi/%F
"mficF*cY_&fiY
F%KfiVa-6?cF/9"G9&Y>9&bF>(fiB%F"_%&fiVc
"6i
fi
1%FCKfifi%%G-%mfiF[CT#BG9&->O_%&>F6*
fiYF?
F>FfiVF%FYbF>FmficF&1%F&%Fa&VKV T
fi
"%


 yF[>Ffi- cfi"
&fiG"(&K#-Gfi6CE :nF&fi%m<&fiY&

c %>Ffi>-_C%F  yF*F&-&YY&fi%BKE :K&(-%
>B
fi%fi% &KT1F[MFGfiY&G%aKE :%C&c
fiY
E(FlmeF&Y?&Y-_ 
:Bi" 
-%?FLL&Y&L*m-6?c Y&LCF:_F&bCE :nF&fi%**>Y&

%/fifi-F%    aF%Gfi>K-_ &fi
&fic#fi6FLs n  fi
>9:&F&fiF?fi%>fi>   
&ficY"F%
LYBFfi%>fi>   
&ficF[Y"F%>
 :?Y>F&fiGFlFF%#9fisF[>F-F%
:nF&fi%

 ::^("
&fi%fiKF[
F6KY

  Y_J JF "F*Ffi#>Ffi

>JY&F %>Ffi>KF%F

>LF/Tfi%F&fiFL-6iJfiCfi>9aKEY
aFFLs n-6?c9"
&- F&fifi-

fiK_K-
<&MFLfiy?K Y_fi&%Y"FY&MF%FY::&&cF%
KfifiZaF>Y&&bY"LY&Tfi/CEY
B_Y_FfiY>Y&
K
fiY"#fi
Y"9:&J_ J
F_ &_FfiYL%%9fi&fi
J% y-6iKY

9&Y>9&fiKbY 9&$&%Y%%YYafi#>F&fi%9aKEYY&  fi4#&&G^ F1Y&
L
fiY"Y*FfiY>%%9 _ ><&FLfiyKfifi"FGfi>O&F_ %KFa
F%FY::&&1
fiY"5%F&*K%h_Yfi
FC&/F -6F>Y&

G^F:&F&%
&fi%GF "
%Cfifi%

KFL-6i&Y>Ofi
&fi%&
 "
%aF[fi#>Ffim
E
&fi&b-m?cZ]fi
&fi%LY
&%-6?cJ6F%Y:&&
fiKKfiY& &MF%Y"FY&%a>O&%%Yfi
YfiK

&-6?c

F#F>&

a%% :/L
l(YyKE9nmVYy&
K
E
TL[fi%
FfiF ->T%%
6>Y"&Bfimae_Ym_YY&fiV-%-m

L $L 	% $
ff
&>
fi		!	"#%$!&'$()*#$!$+,	&!-&!./&'102&'3$!&4%5$!.6879(:;&!-	<=#4%&!	>/68?@A#
B CD#$'&4E5$'.#$F6G79(:HIKJ(LM>F6NPO B 	&$!&4%5$!.*C5&!.5 B &!5Q5E*5&R'#<S&(!TA"#%$!&
U/VW=	4X5 B &!$ZY5[5 B &!.*&!%\C5&/W B &!5]&'.#^_'"+#5`	aA#b $-Q#$'$4%,		a. B R[&'W B T^c&!W B R
!	"#%$!&&'Q0d#$'&4E5$'.Q B &eJ[6879(:;Jf	(>/6g= B h#$!&+5$!.687i9(:H
j7k5&[W B &!5=lmY5nRY5@#$!&+5$!.6879(:oJf	(>/6g#$!&+5$!._LM>/6pNfOe
&Y"cY:&
maL
 "L 	# yfi
F%F ->9fiF"G Y_GF?c-#c6%
fi6CT#
q _(
r <6%F_m%-&&fi  _s
 =t _ 3Yu >K%F"
Y"FhFCT#
FfiG%_

&*&fi&fiL%>
FY:Y_GF&-C&-Y&fi  
E

L"&fi Kv a&L
E
&fi]T-:&
aL
 $T A% #fi
F  Hcw fiYsfi>9
cCT#6
&
>6cFfi%>fi?fi(
E
&fiVE_(%>

1Y:&


fiE
FlY
_#%
&F

 &YY%
G&bfi
_ 

x	y

fiz8{@|(}=~
 =+@	h Z23fh	d=	8]@#=TX=_H##TXS*@+Q#D3f
=G=n1#	Xm#	%e)#@(=+@	(#/Af+H@=#	#+	8M%*E[3@
=+fAP#	c/##@	=	/_/=##@	=	c@#=@+#	#@XP
p#'D@A!e#	+X@DP#=a@_#	ipHf_@+f+P*
'==H#	+	#_@#=T_+S*#(=@+F#/##[	==)=f#f@
@=#	+	S)Z2e!+	8(@##=+S)H#	id#		=k=+f##@
#	@	+	Xc#S#	+aP#=
#3	=f+=@ffh4=-S#=+d3f(8c#	p#-=ka#a#	S
@@X+@ff@m#	X+X#c!a@#AFp!/=f*#	+#P#	Q#a+
Af@/++fA]a@=f+c!A@#	/]@3+=-)@#H#@HmX=F#@#@	i#a@
+/A@+#	8SG]@=##	mX#	p)@a##a+@-#	
 @#@#8/#D	D#	p#A8=+=_##X++hmAkc+		8
!M/+i#mX_#@_p#=	8/@=T=D*##SAQe
=	@+T#D+#k=Acm#im@	a/##	Xp#	a#a+
+[/2+#Hf+=*2*#	X+X#e#@Dm	#	aki@=f
ST!M)da@=f+p#	1/=fcp#m@#=@+i#@#2#@#	k
@@X+@m#@H	+X#@c#@k#a+@c#@H#	\	
HS@	k	X+A[=@+@_#	a/#8Xff=-mAmpi#P=-D+Ap4=
SS+%]+iHS@k@=+#a#	[+*=ff_+@@#	XkQ/=8D=3mA_p
#P@c-4X==#=+_=@_@HS+#a=8+#HM@	@#af#4@f/
/E(-@hSX@++Hm+@@	k8+#D*Mm+S!X=+#K]@ff@#a
+d+d3k	c#	X#Hfa#P4	8(S)Z	S*/E3A#
#Aa@#Aec=#@-#TXS/+@@#	#	XkMpA#S/#m+=!=
+fmAm=caa@=f#	@mh
 @@_@@S@+HX(#@a@=f+D	#eS)Z@	#@n-=#c+@
==#f+=c/#S/@2+@EQ@k=P/#TXSc=#m2P
@##	n##@H@##=/F+fm+#3i@#S@+F//@)=#mX+@!==
#f+=mAp+p		_P=TffpZ	*##a++[  /+
+@@pS+mc=kipQ=k+	H+i@a@@-#@a#@#*)=i@#c@
+!)#	=	)#X)#=f!3+	#@H#	k)@##=+S/=#=+ =K@=#=f@f
#aH@#=TX=/=PFf/+=/_#@-#	\+S@ka@=PX+_#
f*	@#	8#	+=+@o	#@S@+hPX+@D##a)#@*)A)EXSK8E
#		H'@+[SH+	h#@a=f+o		=#mX+@!==
#f+=_k-/@)	A/#a@##@/[MaX+Xm#	+[#@
@8eZ-a#	=A@#@-/@_a@=f+P@X#	8
@kAaK%!=32)	)EXSKA	i@	S+K@QkEXS
 =P	#Hf==+	-#@+	XQ+=@=nm)	ip###X#m =
@=#=f@  d=Q#T=_@8k/==_=#m*#@e=S	*@*T=c@@
-)[3@X#HF=	#Q)3-#@a_/	S+f@/fH=@#c#@
=n#m+@!=p=k#f+=[F/=f=n#m+i#@GQ@+kc#	+_
#@-@*=	/#	a#Q=Q@@#@PX#/@a@#@=#c+@


fi	ff
fffiffff	ff
ff

!#"$!#%$!#%$&(')&(*+,"$*-%ff!#%./0%1.32/5476984:2/0*%;"ff<3*>=-/!4?8ff-/0.:/0*%$8@A&(*+7+ABff%/5&#8>.C/D*-%FE$!(G/0H/I@J/K.L'MN84
!(Gff"@8O/D%ff!?!8><C@J/0!#<P/0%RQ!&(.:/0*%RSffTUSVTXW
Y[ZK\^])_a`cbd#_fe>bg`fhji`ck;l7monqpi`[`br`h
st%ff!u+v8>w:*<v4C*Bff<x&(!y*z6{.3!8>+}|~*<3u698/I@0Bff<3!4#M84}*Bff.C@J/0%ff!/0%)Q!&(.:/0*%1ffM/548>!#%.x4#/D%$8zH/J@I/0.:'1.3*
+,*%/0.3*-<{.3!8>+"!#<:6r*<3+v8>%$&(!TQt698&/I@J/0.x8z.3!4}4:B$&32+,*%/0.3*<:/0%ff?H'u!(Gff"@D*z/D.C/D%ff/D.(4!(Gff"@J/5&/0.
<3!#"ff<3!4C!#%.x8z.:/0*%y*>6.3!8>+*"$!#<x8z.3*<x4#T9%y"$8z<3.:/5&(B@58><MaQt8@I@D*>|48>%!(Gff"@I/&/0.}4:"$!&/If&#8>.:/0*%u*>6
+,*%/0.3*-<:/0%ff&(*-%$-/D.C/D*-%$4~.3*A!#.!#<3+}/0%ff!8-&32/0!#=!#+,!#%.MBff%$8&2/0!#=O8>H/I@I/5.:'*</0<3<!(@D!#=>8>%$&('*>6.3!8>+*"ff
!#<x8>.*<x4#Tq9%u8ff-/0.:/0*%MQt698&/I@I/D.(8>.3!4P!(Go"@I/5&/0.A4:"!&/Jf&#8z.:/0*%u*>6.2ff!<3!(@58>.:/0*%$4:2/0"uH$!#.:|~!#!#%y8
.3!8>+*"$!#<(8>.3*<	8>%$A/D%$-/0=-/5B$8@54#$*-<	4:BffHff.3!8>+y4	&(*%.3<:/0HffBff.:/0*%$4.3*/0.T~QPB$4:!4.32ff!4C!4:"$!&/I$
&#8>.:/0*%$4.3*/0%6!#<~.32ff!8&2/D!#=-!#+,!#%.~*<Bff%$8&2/D!#=>8>H/I@I/5.:'*>6[8.3!8>+*"!#<x8>.3*-<T[~2ff!4C!4:"!&/If&#8>.:/0*%$4
8><3!H$8-4:!*%.2ff!{%ff*.:/0*%?*>6	8:IT<3*z@D!/548>%y8zH$4:.3<x8&(.t4:"!&/If&#8>.:/0*%R*>6.32ff!{4:!#.*>6	8&(.:/0=-/D.C/D!4
8>%7/0%$-/D=-/5B$8@[*<t8N4:BffHff.3!8>+Bff%$!#<3.x8z!4q/0%y4:!#<3=-/5&(!*z6[.32ff!t.3!8z+yU4*>=!#<(8@I@c8&(.:/0=-/0.L'T~2B$4M8N<3*>@0!
&(*%$4:.<x8/0%$4{8.3!8>++7!#+AH!#<A-/9*<{8y4CBffHff.3!8>+t.3*4:*-+,!v4:BffH*"$!#<x8z.3*<#L4t*"$#t*z6.32ff!.3!8>+
*"!#<x8>.3*<}Is5~TAV*</0%$4:.x8>%$&(!Mq4:Bff"ff"$*4:!v84:BffHff.3!8z+)/548434/0%ff!.32ff!,<3*>@0!}*>6t8?(q/0%R.32ff!
t.3.(8&3,*+8/0%T~2/54~<*>@0!{&(*%$4:.3<x8O/D%$4.32ff!4CBffHff.3!8>+.3*}!(Gff!&(Bff.3!{.32ff!4:BffH*"$!#<x8z.3*<#L4.*4&(*Bff.
.32ff!H$8>..:@0!"$*4/0.:/0*%/0%u4:!#<3=-/&(!N*>6[.32ff!*>=!#<(8@I@c.!8>+*"$!#<x8z.3*<KKLqKI#CrrI#o>#Kr5V9#x-r(
L4:!#!{a/0Bff<!AxT
 84C!j*%F.32ff!?%ff*.:/0*%*>6{<*>@0!4#M	.2ff<3!#!y"ff<:/0+}/0.:/0=!u<3*z@D!#r<!(@8z.:/0*%$4:2/0"$4ur/rA:x,5r5-
r/I/r~tL(,#K$rK}8>%$r/I/J/r~-JLCo$$t&#8z%v&(Bff<3<3!#%.:@0',H$!4:"!&/J$!/0%yQtjT~2ff!4:!
"ff<:/0+}/0.:/0=!j<3*>@0!#r<3!(@58>.:/0*%$4C2/D"$4
&#8@I@0!^:I#:}$Kr(5F(ff#r:K$K}
/0+,"@0'1.32ff!?6r*>@I@0*O|/D%ff
<3!(@58>.:/0*%$4C2/D"$4H!#.:|!#!#%y8.3!8>+*"!#<x8>.3*-<Ds[8>%$7/0.x44:BffH*"$!#<x8z.3*<x4#
~~	L:#30(r5#X~5y0  
N[L:05X~5y0 



  	  

P#Ir33#a  3 K 

ff




2ff!4:!y"ff<:/0+}/0.:/0=!u<3*z@D!#r+7*%/0.3*<:/0%ffF&(*%$4:.<x8/0%.(4}+v8'H!R&(*+}H/D%ff!MP.3*4:"!&/I6';+,*<!y&(*+,
"@0!(GR<3!(@58>.:/0*%$4:2/0"$4#Tff*</0%$4:.x8z%$&(!M6r*<.32ff<3!#!,8>!#%.x4-/9M[w{8>%$uM|~/0.32<3*>@0!4*"  Ma*"  8>%$
*"$ Mff8}&(*+}H/0%$8>.:/0*%
:s
<3*>@0!<!(@8z.:/0*%$4:2/0"&#8>%H$!{4C"$!&/I$!u84~3*"$#  *"$   *"$ -xT
Qt?rH$84:!j8>!#%.x4}&#8>%j%ff*>|/0%6!#<7.32$8>.}.32ff!<3*>@0!v%ff*-%ffr"$!#<:6r*<3+v8z%$&(!*>6 *-"$ -+v8>!4
s	 Bff%$8&32/0!#=>8>H@0! ~HffBff.{.32ff!<3*>@0!%ff*%ffr"$!#<:6r*<3+8>%$&(!,*>6w:B$4:.{*%ff!*>6-/*-<Aw/54{%ff*-.A&(<:/0.:/5&#8@t.3*
s  TQ>/0+}/I@58><:@0'Mq6r*<.:|~*8z!#%.(4-/8>%$Rw#MH$*-.328>%js ~9&(*+}H/0%$8>.:/0*%"@0B$4<3*>@0!#9!#"$!#%$!#%$&('
+v8'yH!v4:"!&/J$!j84N3*"$#  *-"$   *"$#
*"$ O3(T ~*>@0!,+,*-%/D.*<:/0%ff&(*%$4C.3<x8/0%.x4+v8'
H$!}4:"$!&/I$!/0%y.3!#<+v4~*>6q/0%$-/D=-/5B$8@54#<*>@0!4#Mff*<t4:BffHff.3!8z+yU4~<3*z@D!4T
2ff!A+7!&32$8>%/54:+46r*<.<x8&/0%ff.3!8>+7+v8>.3!4#<3*>@0!}"$!#<C6*<+v8>%$&(!,*<P/0%6!#<<:/0%ffy.32ff!(/0<{<*>@0!,%ff*%ff
"$!#<C6*<+v8>%$&(!N/54"$8><3.C@D'R*+8/0%!#"!#%$!#%.T,4+,!#%.C/D*-%ff!?/0%Q!&(.:/0*%SffTSffM/0%4:*+,!,*+8/0%$4#M
8>%u8>!#%.t%ff!#!?%ff*.t%ff*O| /0.x4P.3!8>+,+v8z.3!U4~!#.x8/I@0!?"@8z%*-<.3<(8&3.32$8>./D%u!#.x8/I@9MHffBff.+8'<3!(@0'
*%2/02ffK@0!#=!(@*H$4:!#<3=>8>.:/0*%$4#Tff*</0%$4:.x8>%$&(!Mo/D%.2ff!t.3.x8&,*+v8/0%M/I6	8}2ff!(@I/5&(*"ff.3!#<P/4P!4:.3<3*>'!M
.3!8>+ +,!#+}H$!#<x4/0%6!#<}<3*>@0!%ff*%ffr"$!#<C6*<+v8>%$&(!76*<.2ff!8 !&(.3!.3!8>++,!#+}H$!#<T9%R*-.32ff!#<A&#84C!4#M
4:B$&2 8-4{.2ff! ~*-H$* 	Bff"Q*ff&#&(!#<*-+v8/0%M%ff*R4:B$&22/02ffK@0!#=!(@t/0%$-/5&#8>.:/0*% /54A8=>8/I@8zH@D!T9%$4:.!8M



 





fffi



fi

fi






fi 


 "!
#$&%('*),+-/.10),02,-3),45-6'789:-<;=?>"@5AB(8C7ED,-6F7EGH-6'ff),D&),45I64J*JK0'L:I7),-5M/L:),+*'4H'BN;ff=?>O@<ABP8C7ED,-QF7EGH-6'ff),D63C7RG-6'-62PL:I
I64HJ*JK0'ffL:I7E)PL:4H'S9T7E'G0C7EG-UJV76WX8-K'-QI6-6D,DY7E2,WH$RZ[+L\9:-VG-Q'-62Y7)PL:'G'7),02Y769"9T7E'G0C7EGH-]L:D?I602,2,-6'ff)P9:W40),DPL:F-V),+D,I64H^-/4.;ff=?>O@<A_3H;=?>"@5A`F4ff-6D"'4)^2,-6IY9:0F-D,0IY+*7/^4HD,DPL:8L\9:L:)PWH$@a9:),-62,'C7E)PL:bH-c9:W3C7E'K72,)PL\dIcLT769I64HJ*Je0'ffL:I7E)PL:4H'
9T7'GH07G-3D,0IY+7ED5f(;L:F'-6263"gihhEjk/JV76WX8-50D,-6F$
ll

fim/n"oKprq
stuffvrwHxXv"uffuy`wz{z}|"wHs~1vz1uuff6,z[sv&u~vr,zsw6~1zv~(s{stuffvwwEHsE~1v"tcrsvuztvr~1w6~1zv/
QRsS|&u5}"Rr&u\t1~(xsr(suffstuffvrwX~1vw"u[*z}|&z"K"xc~1r(swi~z}vy"sx6r~1v"ts"usywz
uu~1us&sxxKz}S"vr~ffsw6~1zv{[s|usv"zw"uffx6z}"HuSz?~1vr,z[sw6~1zvufftsHy}~1v"tz1uSv"zv"
&uffiNzE[sv&u5a~1Hx6wrsx5y}~(x&xx6uy|uzOV51usy"x~1v&y}~}~(yr&s(xVwEzsv"v"z"v&uVzuffYE&sv"tux
wzw"uSwus{?sv&ywr&xz}w"uffwusuffS|uffHx~1v&y}~Euw61~1vr,uffz1uff,uff6Nz}[sv&uS~1vr,z[sw6~1zv
uzv&y/&s}xUy}~(x&xEx6uy~vuwi~z}v"1}"V[s_1usy~1v&y}~1~(yr&s(xwzy}~Euw61{zS"vr~(ffswu
w"u~1Xz1uv"zv",&uffiNzE[sv&u5y"y}~1w6~1zv&s1?s_,uffyrz[sC~v"P~1v&yruffuffv&yruffvw_u&svr~xi[x*,ze~1vrNuffE
6~1v"tSz1uX&uff6,z[sv&usEuV"z~(yruy~1vV5*r&xffrz1uXv"zv",&uff6,zsv&uV~(x~1vrNuffEuy~?v"z
~1v&y}~1~(yr&s*zxi"|"wus~xXx6uE~T&uyNzX&uffiNzE[sv&uzsz1u6sxe~1v~wEuff"&a~1t"uSrH*xiz&
~]s5~1v&y}~1~(yr&s(xS]~wEr~vs[x6"|"wEussuNz"v&y~1v&ffs&s|r1uzK&uffiNzES~1v"tw"u~1z1uxffRV
~1vrNuffxVw"uuffvrw6~1uSx6"|"wusffsv"v"zwV&uffiNzE~1wHx*z1u
 i}|&sx6uySz}vw"u*z1uff,zvr~1wz}6~1v"tz}v&x6wHs~1vrwHx5sv&ySwE"uVz1uVuff6Nz}[sv&u*~1vr,z[sw6~1zv[s|z"w
wus[swuxffr5~vr,uffHxewusz&uffswzX5(wz_|&uX"v&sEr~uffs|r1u"~1we~1v}zuxVuff&s~1(,z
uffr(sv"vr~1v"t&effsx6w6~1v"t{Euff&s~1sx_swusz}&uffHswEzstuffvrwHxs"wEz[sw6~(ffs1uffv&x6"uw"uSuffvwi~Eu
wus:xz}S~1wuffvrwXNz}w"u~1_uffr(sv"vr~1v"tcw"uSuffvw6~1uSwus~xsCuwEuy~(~(x"v&s}r~1uffr
s|r1uH""Ew"uffzEu?stuffvrwHx~1vr,zwEus[swEuxXv"zwzvr1s|z"wzxxc~1|r1uuff&s~1Eux6r1wHxffR|""w
s(x6zuff&s~1X"v&sr~1uffs|r~T~PwQz~1u1uffCsv&]"usw6~1zv&xwHs}uffv~1vx6uff}~uSzV\uff&sC~E  yruff&uffv&y
zvw"uzvrwuw  [\Euff&s~1(Vsx~1vz}uyyr"uwz(Kxyrz[s~1v"Yx6uE~"v&sEr~uffs|r~~(w6
zv&y}~1w6~1zv&xffyrz}[s~1v"Yx6&uE~SEuff&s~1X~xw6~1tt}uffuy/  vzvrwHsxiw}~T\uff&s~1P]s}xe~1vz}uy{yr"uSwz
z1uff,z}vr~wEz6~1v"tzv&x6wEHs~1vw_Ys~1"uxffV51usy"xusEst}uffvwSwz&Hx6wsv&sCrffuw"usC~T1"u
*"uSsv&s1xQ~x[suff}us<sHP,(6eff(r6*sxc~1v"t1uEz1uYs~"Euffs&xc~1v"tw"u"v&s}r~1uffr
s|r~~1wQz](Vr~(E[s[z"ff"*~1vsvXXYzS|r~v&sw6~1zv~Usvr[stuffvrwVzVx6"|"wEusYs~x
~1v~1wHxz1uVz}[sv]YzS|r~v&sw6~1zvV"uffvswEusuffS|&uffx[sEuz1uffYyruff&uffv&yruffvrwzvs`xc~1v"
t1uS~1v&y}~1~(yr&szsxc~1v"t1u{x6"|"wEus{[OzX~1v&x6wHsv&uRV"uffvstuffvrwHxsuS&}~1v"t~vNzE[sw6~1zv}~(s
\ws}uT~1v"t(*YzS|r~1v&sw6~1zv/HRuffuffEzv"u~xz1uffYyruff&uffv&yruffvrwzvw"uS1usy"u~(z"wuff{*r&xff
x6"zr(yw"uX1usy{Hs}x6&s6~1w6~(ffs5z1uXYs~1"uz"ff"Hxff
]"usw6~1zvwHs}uffv~vffsx6uxz<si~wi~ffsC<zuXYs~1"u_~(xVwusEuzvr&t"Hswi~z}v"wz[yruffwuffES~1v"u
swusuffS|&uff/zx6"|"wus{/wzx6"|&x6w6~1w"wu_,zXw"u6~1w6~(ffs*z1uXxXuffvw6~1zv"uyusiT~1uffawr~(x
xc~1w&swi~z}vz}ux6zv&y"xXwzw"u "v"Euzv&E~uyffsx6u~1v&suy"<(sv&xffy}~(x&xx6uy~vuw6~1zv":"
*"ux6wEuff&xVwHsuffv~1v`V5~vwr~(xffs}x6ususxUNz1zxff
]iEX16ff(Y6Kffi i6N,NPff 
	fiff
ffff 	!#"$ff#%&('fi)"+*+"+ff"+
%,-ff	%%.#%,ff	!/0'1ff-%,2!ff/-&("+ff	3ff
	42"+
/'1ff
%.5ff	!67"+ff"8*(%,*+:
 9;ff 	!"$'!0
 2
'1ff*+<3
*+"+%'>=1%?"$'A@B
)7"CD-EF'!%&(*$G=10,:
 H(. %,2!IJ0'1ff%
2ffG/-ff	ffff	
2
%.Kff	 
"+ff"8*L%*$M.B"+*$2!5N''%ff('=1"8=ffO.P%,2!ff"+ff
2ff"+%,'
Q
 RKS6 TKffE,(6 U&6ffN V?(i,11 W6X,EP7 HM' /';0,'1ff5=Aff
/"+'M)%
"$!*$'=1"8=ff
XP YI
"$' *+2=1"+'0-"$ff
*Z.[I!"+ff\	!
EFO.P%,\7%,'1]"8 ff
\&("+ff	;'=1"8=ff,^ \7_A"+
ff"+'0/ %//"+ff
'1ffff
%ff	ff
K
 `a.
ff	
/ %,/"+ff-'1ff\*+G,=1<; 
"$ff
"8*bIff	'=1"8=ff
"+#*+"+/"+'ff=c.P%d %,'
"8=1[ff"+%,'
 e%

"$'!ff[' ,I"Z.ff	-'=A"f=!ffg"$\-)ff
"8 "+)'1ff\"+';-ffGh%,) ff%\&(	"8
	"+5'i#j\kO@l7%,"+'ff"+%,'mI
"$ff
J
)%,'!"+"+*+"$ff
"+Jff
%ff
	\ff
n*$
,=A</ "+ff"8*opNq,'"Z.m"+ff)%

#*+q,'Fff()"+*+"+ff"+GI
"$ff''!%,ff(ff[E,M%q,ff	M%*$M"+'?42
ff"+%,&
' rA"$"+*f*+<,IGff	!sN'=1"8=ffM"$2!*$G=%,2!ffJ"Z.t*+*%,ff
	(ffG
/g%,*+ @=1)'=A'1ff\%,'"+Hff 

u#v*ff6QU w,iQ,,N(YPS6x#y('=A"f=!ffXP[YM'%ff#2*+=%2ff#"+';ff
)zQ'{2!ff
"$ff
2ff
.P%,ff	g%,*+ }|(	"+~7%,2*8=/'?'?"+'=A"$q1"8=12*q%,*+2'1ffN"+'0"+ff
*Z.[I1%,\-ff
n*+,=A(q,%*$2!'Fff

"$'!0
"$ff
K2ff
.P%,Kff	!5 
"$ff
"8*
%,*+ Kr1"+' - 
)"$lP"+J#ffG%)N[ff
%,GI'=g"+' M%*$7@B
2ff
"+ff2ff
"$%'
"$)*+"+"+ff(,
	"+q/'1ffGI'1</
%,*+ @b2
ff"+ff2!ff"+%,'"+~''%2' =6ff%/X

,

fi5\DDK{,DMD\DD

gsN$7lO1[N+bP [P b81 --+BN1PDOPNJ
$!\!JN>
,+$-!(,7+1$b1
#N$N,1(+1+1fA,(
Gn/(1+
!+(,8
,+\/8/ //+
1

 3DNNz{8m,A;LA3b1+81D1m1DDG,DD,G1 8D
bG7f7F518lF$8D, mN-8{8}8DDfi#DN~[fmG3:GD 8D DD,1
D# m,N+m,KK1m;NDG8F1L1!(Pa a$7Nbb+1PbabG818,#1{c--
G8m1 8A?DNGD 8DAf#8DD!DGDG 8 P18+8DDGD
 DD,A8D/N, A\D?Gm1{Pg8D1,:;L ,-ND?1m1++8 8,1ONGD 8Dm#D
8,/A5P DD,A6fD, m1g8?118D87DD,1 b/GD 8DmAm1D
DDmG,-PNm1D818ND?N, A\D,13:mg1\P DD,A DGfN
GDPG 8DG8; 8b+8bm1 8bm
8 8DGD,
	nPDF fiff,GDN, #8P
DAf
8D,18mG? mNfiDN18/
8D;A/GmD,fiN?ND8F~Gfiff#1
8m!8Pm,1 !m1NK1m
8mG7{fiff+PN8  ND,Dgb/G 8 PsG!DGGD
D#8, ;118mF~
Pbfi,G
sD\ 8\mFfDDG,D1m1\A8!,-8D#GNfiffA  DD,11D}m1
D{,1/fi P  Nm8 #++m8!, / ,1p!m1N,O! b1+81
1  P/mFf{DDG,D#8 Pfi fim1+8D8m!8PmP:7DD DD,1 1
1\mA PGP1G 8 PJN18,\DDND;N1;m8G;DP1 8fiDN-g1DA P+"
, N PG,fi#88

 D;+8D{DD# +fi D,L,L%$'&P+# ,!" 3
8D18fimm1)(!
P/!P18,b Afm bAmG*m,Am ;,+.-'/10 ,+324G657(!5m -8D11D!D
16( 7m m1,+.-/10 !,+%89#18>Lmmfi+8D3GP 8183 DD,1:;8m , 1\1{8m!f!Pm=<J1m{ND/ DD,1sD1-8>AfiP7F~mFf
l+fDNfi>mP{P?# +&a$# ,D1/L B! 818@<\N G1P 8m1Af
P-
8m1 8L#8 Dz7Dm  8D 8:P1+Afb;G 8 P\187 m8
	s8 G+
DmN8F18A1fmG-DNm8\1BCEDB	zP8 G+DmNf118m/G!;8#+fDN#P\7D;,K
1mZG;8a+fDN 	 PfiD1 8!,KD!{fm71mG-8DNFfGfN
+fDNfi8;+8,{D8DDfim GF? 7 8D G!;8alF$8D3N,1 mA,
O!m7D,Nm1,1n;mG#++DDJfiffD,GD# m;!  P\G7f!m#8D!D~Gm7f7fD
,11,}b(z DDN,1H 1fm!8!PmI(!mGDNG;8a+8DLD8B
8m1++fJ:;m7BNDG8N18,M83D,AK)LC#Db!18DG 8!fJ

MONQPBRTSVUWKXAPZY,[\Y,]^@_a`7YbTcedfdhgjij_\]lkm^n_\cei
O! 1-G;DP1;{, A$P 1m:6fmA,1 L1GVo8DA
D?L;1,1 L1G8 >m1P !8D;,MP;G;DP1 8 
8
+ 1/1D,p[q,G 8Grfi D1-;8 P+,G\77s
 m8L8 D  +8;8D3
#DGbt(fG1,,NP
8DbD! P;G;DP1 8 G8,G 88J5g1O!
1!,L8Gm
PA 8?G?DP17f!6G 1m mDGmK#G+tD+vuF,+,aK@w
# ,+%xmgPy& @#fiwbaGw@$>Nfi# z${wba$ N,+a%xV| +8NDA1 P;ADDN:
, m!m ;D;Gm N8G#1\,8b# PFfmD8-PD!D,G,N1 + !fAA 81\D
D,G7fD7f!m1D} 1887f!mb15!  m1 PGP1,Dq} 18 f 8m BG1;
#fi,sD{1mD1/G?DP17f!mDDG1D;G!;8;N1FffiDmFtLG+fG
~g8,NP
8DbND PfiG;DP1 8 G8,G 8!8>?O! 1N;D#{b1+81hD; 
G Nbfit,G7f!;DDfi1~A88DDmFtLG+fG#G8F1gf}[Af#87f!m
@

fi1lj

@lV!l%Jfi;l)%\@'a@;l)%\@6fi@6VlV=@fiE;z,zJl
lV,J@*I"EB?B;l,QfiJfiIn6%@Jl%6Vl%{l@",zz,.=
;lJ;V,>"V@fiJ@,'=lzfiz6Vlvn@,fiJ?@'>fi@6Vl@lfiI.
a;l6@fiJ@TmJ;T@lfifi@6%'V,\"@qhl@,>y=mh@'fi@66z"
 l4Ap.@7,lT%nKV%a@VV,JlGEjhsl@,"JG1
l;@%1@Al@  lee,,'lqVfi@z,J@"V,JlE=@,v
J@@fiz6)  l@Q'A@,,.J?j7a@Evfi@fiz",nJ@e1l
%,fi%;Ifi j 7Ol@fiJ@v!T@JlVlVfivn"Vfi@6VlJ@e,v  le
Rewards
(1

NC

)

Cost: 0

B

(F unknown) B  Cmt

Decision node
Chance node

(F known)

C
Cost: Cc

B

1

(F known)

0

(F unknown) B  Cmt

@l6Z'%\@'@fi@l"ze
?6@lEfil,%fi%lJ"J*7@lJ@Tzv!Ifij)?j>6B7@lJ@*';?% ? 
6T.V)fil,%fi%lJ>@1{zfi@6Vl%sj6?>6z=@j
qI?jj
 ,ya@e,Jfi,fi@Vl;z  @T.elq,zl;V"zz\
>@@j@7

l@"a@@ltz@6;.,B@lfiI@l@@\,fi)q7f\"z6  fill
Ifi@6@  l4"%zn, j A4am,.J,A;@%llQa@K@lm@l
lV{n  '@lVzl@e\,fi4"l@l@v!4q7 j @eV;lTfi@l"zfiJ
Iqfi@4{,,zl@l\,nJ@@;fi=O,%6V,'Q%Q,fi%,fi
a,fi%@fiz6VlvnJ@6OlEfiJ",fi%@J%'>%fi%@J%fiBlJllfi";%n@fiJz>@=
%JJl@ze@T\l!n@7Z"fiaB*'%{V@,B,n,V,@l)fi@l"z
l%fi%@
Zm%fi%*lJT.""%nJ@v'.JQ,J%zEJfi%fiJ@J*lQav*zV
aV%,

l@fi=aGl*l@,nJG@  jJQfi@6V6?, ; l*m,.>a@
fil%filJlsEh;l@l;J)fi@V6A@Hl6%{mlsnn@)fiz6Vlvn%
sj6Ef?>6z=@j
Qj I 
at.1 ) 	l
  fiffQ1l
  
lllEzl.%J@fi@6VlJ@A
@%,,zl,fi.JQl)V,
J@*fiJJzeJ"J@,j @B,Jfi,fi@,% 6VmqT.V,l,fi4"Q,;
lV  JlzlT,J% ,
l"zal
f*mTl,z4n" l6fi  'l%
T.*l@m%fifil%
 Blz)fi@6VlJl{fi@,"z"J  @V;l6%v>"zs)a@
fi@6VlJ@vlfia@Vfil,%6,,
 elVl,fi4"J@  'l%
l>6J@f>@l!
 #
 ",fis@VQ%lzl@,\Ga@ %6Tn%V
",n%z,@lV,fifiJ?qv,fi%1

$&%
'

fi(*)+-,/./02134
576/8:9;45<(=57,/>-+?)/./@

B

(1

)

A NC

Cost: 0

A C

Cost: Cc

(1 

1

C0

B

(1 

D

B

(Terminates)

) (Not Terminate) 0
(Terminates)

BCmt

(Not Terminate) 0

)

(1 

Rewards
B

B

)

(Terminates)

B

(Not Terminate)

Cn

[Irrelevant]

EGFH7I/JLKMON-PRQ/SLKUTVK
VVK
WXFZY[F\7T]SLJXKUK?^_FSL`ab
c H;dFTe	d	TfdgH7KUT;ShWi\7jkjlI/TFZWUd	SLK
YmFonpP-qsrLtkuRv<P-qsrxwytku&eiFzb{K7be|Fonpa}~}7-=vrL*W=firiUzauL-T2u&b
*afF:YleFzb{K7be2dkSLK
dgj\7KUJ&d	SL\J`d7YSLKUJLjlFTd	SLK
V2eSL`FZYK
7Id	SF\T!JXK
VIWiK
YSL\l ~}7-=v_W
YKUKUT/JLKUF\7IY[7ba?eRFzb{K7beh`FH7`I/TWiKUJLS&dFTSxd	\7I/SkSLKUJLjFTdgSF\7Te-T/\Wi\7jjfI/TFZWUd	SF\T
JLK
YIS&YFok-TFZY`FH7`b_`/KUJXKi\7JXK7e-SL`/K]VK
WXFZY[F\7TSLJLKUKFZYI/JLSL`/KUJkKiQ/SLKUTVK
VSL\]FTWXIVK<dT/KU^
jkK
YLYXd	H7KS;K SL`/JLK
d	SlSL\x\	FTSlFT;SXKUT;SF\7T ^`/KUJLK]-TFZYUKUJL\eh/I/SKUT/KiSiYd7WUWiJXI/K
Vd	JLK
\	^*KUJsrx_*u&b=_`FZYSL`/JXK
d	S_jkK
YLYLd	HK?jdQFjFUK
YKiQ/K
WiSLK
VI/SFooFSx^`/KUT!a?7eFbK7beF=TF:Y
`FH7`\7J_Wi\7jkjlI/TFZWUd	SFT/HkSLKUJXjlFTd	SF\7Te/d?SLK
dgjjkKUjlKUJWi\7jjfI/TFZWUd	SXK
Y*dsSL`/JLK
d	SbEO\7JhFTYSid	TWiK7e
d]SL`/JXK
d	SljkK
YLYLd	HKkFZYIYK
VFod	Tfid	H7KUTSdFoZYFTFS&Yl\	^TJL\	K7e-^`F:WX`FZYdSL`/JLK
d	SkSX\!SX`/Klx\	FTS
FT;SXKUT;SF\7Tb\	^*KUKUJ
e*dYkKi\7JXK7e_SLKUJLjlFTd	SF\7TjkK
YXYLd	H7K
Yd	JLKIYK
V^`/KUTa7e_^`/KUJLK]SL`/KU
jdQFjlFUKKiQ/K
WiSLK
VI/SFooFS7b
U
</

2;U/	Lh ~  a
c Yd=J&YSRYSLKUe;P c? \7T?IYK
YG7IdoFS&d	SFKr\	^e`FH`e
jkK
VFI/ju2d	J&dgjkKUSLKUJ	dI/K
YUb=;P c?
K
YSFjdgSLK
YoF7KioF`/\;\/V\	_Zd7WX]\	hx\	FTSfWi\7jjlFSLjkKUTS&Y  eF:dSLK
d	jSLJ&d7WX7FT/HrxdgjfK7e-
7u_
VTd	jlFZWUdoFTKUJLJFT/HdSLK
d	jYjKUT;S&d*YS&d	SLKJL\7j\7YKUJLd	SF\TY?\	_SLK
d	jjKUjfKUJ&YUd7WiSF\TYUb
E/\JLSLI/Td	SLKi7eJ&d	SL`/KUJhSL`dgTkSLJ&d7WXFT/H?K
dWL`kSXK
d	jkjd	SXKYKUd	J&d	SLKi7ed	Td	H7KUTS-FWUd	TkJXKi\7TFSiYh\	^T
SLK
d	j\KUJ&d	SX\7JKiQ/K
WiI/SF\7T]\7J?SLK
dgjSLJ&d7WX7FT/HbzTd	JLSFZWiIZd	J
eRYI//\;YKF-`d7Y?YKiK
WiSLK
VdSLK
d	j
\7KUJ&d	SL\7J#\JKiQ/K
WiI/SF\7Te-d	TVyFSfT/KUK
V/YSL\K
YSFjd	SXK  \7J\KUJ&d	SX\7JlRedgTV]FS&YSLK
d	jb
\^e/FoF*YKiK
WiSLK
VdgSJ&dgTV\7jJX\7jdWX`/\	FZWiKk\	*K
Ido]/JLKiKUJid	KWUd	TVFZV/d	SLK
YUeGSL`/KUTFS&Y
SLK
d	jjd	SLK
YsjdyVFonKUJlFTSL`FZYlYKiK
WiSF\7Tb<`;IYUeSL`/KUJLKF:YWXK
dgJd\	^oF7KioF`/\;\/V\	dx\	FTS
Wi\7jkjFSXjkKUT;S=FK
YSFjd	SLK
Y  SL\K?`FH7`b-\^_KU7KUJe	Fo-FZY=SL`/K\TWX`/\	FZWiKddFZd	K7eSL`/KUT
 VKUKUTV/Y\T!SX`/Kk/JLK
WiK
VFT/Ho-	SL`dgSF_KiQK
WiI/SLK
Vy^_FSL`SL`/KlSLK
d	jsbkrxjd
K?IYSd
Y[FT/H	KUSL\7TeFbK7be-?jd
K?d	TkFTVFF:VId\7KUJ&d	SL\J-SL`d	S_FKiQK
WiI/SLK
Vd\T/K	u&bh_`/KUJLK?d	JLKSL`/JLKUK
WUd7YK
YSX\pWi\7TYxF:VKUJbkEGFJiYS
eOF?rLFZY?YI//SLK
dgj\	u_\7Jl?edo-jkKUjlKUJiY\	^_KUJLK
\	FT;SKiQK
WiI/SFT/H]o=	ZRbhE/I/JLSL`/KUJXjk\7JLK7e2o=	Z]Wi\7IZV\7TK?SLKUJXjlFTd	SLK
VF:djfI/SXIdKioFKi
d	jk\T/Hlb`;IYUeF:YoFKiSL\Kh\	FT;SkWi\7jkjFSXSLK
VSL\?KiQK
WiI/SFT/HSL`/K\7TT/KiQS_WL`/\	FZWiK?y
 FZY_K
YSFjd	SLK
V\^b_7K
Wi\7TV2eFo-eY\7jkKjkKUjlKUJ&Y*FT]^_KUJLKT/\7SR\	FT;Sd	JLSFZWXFd	SFT/HFT
SLK
d	j\7KUJ&dgSL\7JKiQK
WiI/SF\7T]K
d	JFKUJ
`/KUTWiK  F:YK
YSFjd	SLK
V`FH`b_`FJ&V2eFo-T/\\7KUJ&dgSL\7J/JLK
WiK
VK
Y
Re/K7b{Hb:eFZY=J&YS_FT!dkYI//H\;dze/SL`/KUT  FZYK
YSFjd	SLK
V\	^b
`FoKd	H7KUTS&Y=IYIdoFTKUJjd	S&WX`FT/HK
YSFjd	SLK
Y=\	  eY\7jkKUSFjK
YUe/K
YSFjdgSLK
Y_V\fjF:Yjd	S&WX`b
_`/KUJLKi\7JLK7e;P c? FTSLKUH7J&d	SXK
YfY\7jkKKUJLJL\7JJLK
Wi\	7KUJLJL\I/SFT/K
YUbE/\7JFTYS&dgTWiK7ehFod	Td	H7KUTSkF
&


fi2/-


gL
_Lk/
	7ff/
fii-
	Lh&fiLih//	ff/?X
	
fi&gLfi
 	 	Z	L
 fifiL ii 7
k
LL 
" ! fiR
&	 oZ#  	$x	 	% i7klL
 	;&' &( fiL i 7
fi&R fL  	
fifffiL
 	 i 
 	)fiL
 *
&	 oZ#  	+i7lLk
 	&
 &,-	.i 	;/ fi&7 g0 !1lZ# *
	L
_Ll
 % 		/ i
LL2 fi0 3)&4 ! fihk
LL2 7
5 ! fih
&g Z#  	6iklLk
 	&
 &1789:<; 	!
 fi&_# /
?:= *
	 	):>
 fiL i
 / 	 !	/ ? iL k
LX 7

 @g=ff /
 	Ai 	i&-B
 ; C	 /
 
 fiD/
L6
 UgD ffAA/ L
		L

 &
8Gl
	XB
 EGFzff /
 fiL7	0 o# ff g>
 !z ihZH
 	/I
 ikk 	)C	/ H7 J789:<;7L= /k

K
 	;L U s
 	 fiffMU gN o
O
 ! filL
	kUl
 fi&' - &PQ&GN !7R
 !z ilZS
 Z[ L 	fi 7
 	 
ff /
 	Z?T ZA
 Z[ kLT 01i U	L L
		L

 &U _
 7
fi2	
 fiL

 	 7 	.C	/ I
ZkT ZV
 fiX W fiL L]k?  3	! fiL	 	k Z# fffiX
 fii M
 ff2 		/ :'=3 	
	3 	YE"&MZ
ff /)
 fiL7	0 o# < !? 	<
 
	; [ ?ff fiL
gfX!O
 $xg3 	 	;L
 	 	RZl
	L ]\N !?A
 !z i	D //

#  XN ^ L
 fiLl 		_ 	Mi 	 	
 &a`ff /
 fiff_Z)
 fiL k 	L fi3 	Vi 	ff fi& 	& fiXR
  "R &P&m 	
 	b`dcH*eif 		_ 	Z?Z 	7
fii .fiL  fiL 	 mXkff /X
 	/l
 fi2 !L
gkUl
 fi&' &f8H/X
 i
 fi&gkUL
 fi&
 Qg%hjiff"g%hHk
 	lgf?2 fiL7L# / LlS
 7 	lC	/ H7 &

mnRopq"res%qQtuev4w
7891:B;Z<
 fifffiX
 	;# R
 Uk
 	L b_ff  	x77 fi:A
 i_ 	7
	 	I
 !_ fi
 	i  	 
 fi&gL fi& 	
 &gL

5]Uk2!Byz{lfiff

&Y9-L
	ZT0ff/
Afiff
S/
	i?ff/p3fiff/	|:*

	0A:}@7kL	Rfiff
*2fiLHfiL

	Ll	):d
	0G~&789:<;7hU
	o	ff/
fffiLUX
  	
 	; 	/ 
 fi#o
 fij:L& /C"?84fi& 	=  fiL 	lc_7 g%&H8	 )\<fiL 7K
7k
	!_ fiL	 		 /ff /kff fiXU6
 7 	
 &lg-2 3/O
 	\oZ&ff /k/ fiLU6
 73 	' &.g= /R
 	yOoZ&
ff /kT ;S
 /
 	/l
 fi ! 7
 	&>
 
 fiX
	 	
 ffx73 	&lg-2 3/O
 	{# / ?ff /O
 ;Lx 
2fiZ	 	 	]ff /f[ U
 !-/ /L
	l
 &8H' / 	]ff /X
 :L& /Cp2 	.84fi& 	#  fiL<
 7 	
 ff /lL
	
[ U
_T S2fiffk# /& 	ZT 0@O /f
 	/*s3 	.c7 gj&Hg- /R
 	)k# / hff /
 	/l
 fi_ !4
:
	]ff /L
g fi/; 	 
	 	l
 fii fiD/aFz &P&Off /L
gR
 *z# //L
	O
 *3 	 KT 
 fii fiD/Z?ff fiLU

7
 fi& fiD/JD&jg-2 3/O
 	6= / Rff /_T S
 /
 	/l
 fih !# //L
	h_ i 7	2 	 	/_k &
 7 	 ]
; TL
g
	 	
[ U
: L&/C

z
84&fi 	 # fiL
\
c 7g%
_
\\

8
g[U
	&fi 		
y*ez
{*ff\T
\\

2
:	
L
g 
&fi 2fiDff
{

{

;!;S/	/
#/ /X
	
y



8	)\8H/fi/;	
		T
fi&fiff	ff/?fffiXUX7	
&
789:<;M[ oKU 	
	 
	 ff/ 
ffLfi UR 7	 >Lfi 7K 
7kl
7K 
	i -! &>7 
/	 
&fi To#&
,e	bfiXK:2fi	/7	//
R7	<0
fi3	ff/lL
	&7#C/
fi#!fiLk"2/78R	
\ 003ff&fi 	L
'2 ff/ R 7	 X 0 


fi #/ i;	 :N]
	 ff/ lL
	[U 
?	]
 fffi/i ffLfi &X8H/ SLfi 
!
ff Z_i 	A/	 | 
-// ffXfi UB 7	 h	. U&N
 
	T	
	 !7891:B; [	f
 // Bfi L
fi :
_
! 
&fi T0%
fi#! Lfi 	i 5Lfi 
 L	0oR L
g}_ fi/C) ; 0oZ#%i 7kS	 KU 	
	 +X 
	- 7_ 0
7_
 Xfi -
	 
	i ? 	
 	
 k 0! 	
 X
	S* _fiffC6U  	0o

&
D


fif%")LTMj%<
S"?TfTe"V"
R
b
T#x#ff
#bK</R
DT0%
ffffQ
#_ff6SV_<ffff
6)T

 3=3)ff<1Bl=|
Rff26SS#6#
/-0
R0K#ff)D#
jHff
ffR
x
_3/R
D
Qffx+/
#|M_
DffMIL}LO_0+AffN
G
T0(ff/
X6T
Hj
ffDTff</D/2AD2#/I_6THXO3.#/
#K
S00Dff?
D/K#4Hffff52?/
(
D
5ffff
/RffSff#%_6T
ffH6T

ffDl-?Q
ffA)N6Vffb0Aff6'%SKff3_beD_#?D%ff
)ffff

Q
D
1Bl#G03_<ff6HTX=S2d#
ff-0O
ff}/T0
bff#
63 /
MT.#
/-0|2ff#K/ff|R_%A_.V#/|#/
#K

D/K#
"
ffff}_6T.
ffT>L/#GT<#ffff
bA
/T(
=/6

32#

 Rff<HQ%A6T_%KT
%ff2S#f_R
ff=3_3)T#jff6j

Qblff
<ff=D/
DH#KHKX<ffS#RSf=3=3lffK<ff#K/_<LT
ff
-0RHjT#jffH
%2/ff
eHQ%_XRQ
##%f
_
T0ff6j
#<ffS
Off#D/
DH#</XK)
=K##K
ff)ff26
j<
Rff=%
T0%ffff6IVffX2ff/XKffSHQ%R/ffR
<d/  ff
ff2#Tf
%
ff
Ad/#0/L  ff00
A  %  DQd_2.#XT
O
l<j"VaX
1BYB3ff
ffe_6T2lffe6TYff
ff00#bK}2ffT6/3aR#ff3x5
	 j%RVX2T)0L=DHffffff
X_0
ff
d6Tj%<M f2NK
=3_%23O
	 NK#)ff.ff_DTSQ
AB/3)Q
.
R
A63] Kff]/Mfflff)ff

6ffA63aHAff 
_3/aff_ 6TY?Q
ffDX_<H0_< ff
003=ffD#VRb%/2

HR=XHRS
<< /3=
.ff=X6TjKj0K#ff+3a%R
 fij%R
 RR_#ffHQ
D
ff
#<H</3
ffffS6T
]bff
#AKR=V<M <#R6TjffD/QDMH
/)LG
ff
#.#_ffePLS
D_# _RSL
2#AffHH
ff#ffff
O >6 #
ffT_3Ob
?_AffK6TdIjlDH#KTf#
_HH
ff
#
ff"
ffSHff13.=#KTff#_3R)/D/
D T0(/Xff_ 
ff
jff.jKT


bbffR)ff
 NffePLV#)/DQR
=3lffRff
=}2fff
ff
R_3/#.#ffTD'ff
3X2Affff2B
ff=3_
 ]3/ARffb#=L ff_#
b/D/4ff
#R6TG3Off3YffSffff)jR
 )0K#D>ffRff_DTS
ff
Q
Dff#/0AQ
6T_0N#/D#6-0
jffe6T)ff
# ff#
#KT0
/Aff_
D/Q<Yj
=3/XffSHffR
2N0#X2ff<ffffSQ
 6T  Tff
/D/
 
#_ff
 fififi
Ij
 


5

1Bff
	 fi
	  fi



	"!

< /
#
D=ff#
 
fi  

<ff
/0N#2D
#%$&

2
ffD

ff


fi'(")+*,

-/.1032546798:8;48<%=>8@?BA+6CDFEHGJILK
MONPQHRTSUWVYXN[Z\]\_^_\1`bac\def^1S dbN[^1acUWN[^P`fNgRY\1`Whi`Wh"N+QjNPdbk"UWNdSl"SmNffU%PL^_^ noNffUblpSUWQqPre[NYPrgsUWNffkdWPt]\u^1v
\1`bawyx\re[Nzx M5{}|~ydNffr`b\1UWN`WNPtQRYSUfVeffPnP]\_^_\1`b\1NdPUWN]"UWSk"h`c`fS]oNPUi\1rN[ZNe[k"`b\1r"y`WNPQ
SnoNffU%P`WSU[d\1rPL^_^}Sl`fh"NgSQqP\rd"`Wh"NffUWNHPUWNcd\1r\_JeffPr`s\1Qjn"UWSmNffQjNffr`%d\1r`WNPQHRYSUWVHXN[Z\1]\_^u\1`baw
"SU\1rdb`%Pre[N\ry]Nffrefh"QqPUfVFUWk"rdiSl5|5`W`%PeWV/PL^1QjS db`HPL^_^5Sl5`Wh"Nj`WNPQHRYSUWVl@P\u^1k"UWNdlpUWSQSk"U
NPUb^_\1NffU\Qn^NffQNffr `%Pt`b\1SrFPUWNcPLmS\gNgwY+NffUf`%PL\1r^1aPL^_^9Sl}`Wh"NlPL\_^1k"UWNd\rO\1k"UWNcjPUfNcPg"gUWNdWdbNg
y W` NffQqdPrgPUfNPg"gUWNdWdbNg]NeffPkdNPNffr`%dHQHkdb`Hr"SRP`f`%PL\1rQHk"`WkPL^5]N[^_\1N[lH\r`Wh"N
PeWh\1NffmNffQNffr `Ok"rPefh\NffmP]\_^_\`baSUs\1UWUfN[^NffmPre[aySlT`WNPtQSnNffU%Pt`WSU%dffwjMh kdff\1r\1`WNffQO`Wh"N
e[SQjQqPrgNffUYr"SR>P`W`%P\rdQHk"`WkPL^/]oN[^u\1N[lY`WhP`Y`Wh"Nsh"N[^u\e[Sn"`fNffUe[SQnPr ahPdYe[SQjn^1Nff`WNg\1`%d
Nffr" PNffQjNffr`HRY\1`Wh`Wh"NNffr"NffQHaJYR5h\_^1N\1ry\1`WNffQ}`Wh"N\UfUWN[^1NffmPre[aSln^Pr"r\1r"P]a nPdWd
UWSk"`WN\de[SQQk"r\effP`fNg`WSH`Wh"NHe[SQjnPraw
y W` NffQqdPrgPUWNPg"gUWNdWdbNg]NeffPtkdbNFPNffr`%djr"SRPe[`HbS\1r `b^1a] ayU%d`qNffrdbk"U\r"`Wh"N
Ndb`%P]^_\dbh"QjNffr`YSl bS\1r `Ye[SQjQH\1`WQNffr `%d]N[lpSUWNsN[ZNe[k"`\r"H`Wh"N[\1UYUWS^1Ndffw}SU}\1rdb`%Ptre[NP`WNPQ
QjNffQH]NffUgSNdYr"S`5]oNff\1rN[Z"Ne[k"`b\1r"q`fh"NQH\dWd\1SrPd5dbSSrPd\1`n"UWS"e[NdWdbNdT\`[dYSU%gNffU%dp\1`WNffQ
%U[P`Wh"NffUt\`5Pe[`[dbS\1r `b^1ajR\`fhq`Wh"Ns`WNPQ PLlp`WNffU+`fh"N`WNPtQNdb`%Pt]^u\dbh"NdS\1r`Te[SQQH\1`WQjNffr`%d
`WSHN[ZNe[k"`WNi`Wh"NQH\dWd\1Sr/w
y W` NffQqds"oPtrgPUWNHPg"gUWNdWdNg]NeffPtkdbNj`Wh"Ni`WNPQSnNffU%Pt`WSUH};b ;ufpp_ffffp;
[p%\ddnNef\_Ng`WS]NPr>|ssve[SQH]\rPt`b\1Sr>SlH`Wh"NFUWS^1NFStl`fh"Ndfe[Sk"`%dPtrg`Wh"N
r"Sr"vdWe[Sk"`%dwMYh kdk"rPeWh\1NffmPt]\u^_\1`baStl`WNPQSnNffU%P`fSU%d\dgNff`WNe[`fNgcd\1re[NN[\1`Wh"NffU`Wh"N
dWe[Sk"`%dSUY`Wh"Nr"Sr"vdfe[Sk"`%dYeffPr"r"S`5noNffUblpSUWQ3`Wh"N[\1U5UWS^1N"SUT`fh"NcdWe[Sk"`b\1r"vpUWSt^NcPdWd\1r"QjNffr`\d
k"rdbnNef\_Ngw  rz\1`WNffQqdcPtrgr"SUWNffnP\U[dPUWNjnoS dWd\1]^1N]"k"`P``Wh"N^NPdb`c`Wh"Nje[SQnPr a
\rlpNffU%dPffe[SQjn^1Nff`WNffv;lPL\_^1k"UWNPtrgUWNff`Wk"Ufrd5`WSh"SQjNi]PdbNo\1rdb`WNPgStl+RP\`\r"\1rgN[r\1`WN[^1aw
 rz\`fNffQ9`fh"Nqk"rPdfd\1r"NgyUWS^1NP PL\1rz^NPg"dH`WSk"rPeWh\1NffmPt]\u^_\`baY]"k"`HUWNffnPL\1Ui\dinS dWd\]^1N
]NeffPkdbNiSr"NSl}`Wh"NUWNffQqP\r\1r"dbk"]"`WNPQd5effPr`[PVNsSmNffU5`Wh"NUWS^1NSl}`Wh"NcdWe[Sk"`w
y W` NffQ\dPg"gUWNdWdbNgzd\1re[Nj`Wh"NHUWN[^1NffmPr`SnoNffU%P`WSUH\dr"SRN[Z"n^_\ef\1`b^1agN[r"NgFPdsP
`WNPQSnNffU%Pt`WSUsRY\1`WhPrzYve[SQH]\1rP`b\1SrySlTQjNffQH]oNffU%dffoUWS^1NdffwHMYh kd]PdbNgSrFe[SQjQHk"v
r\effPt`b\1SrlpUWSQ3`WNPQQjNffQH]NffU%dff`WNPQQjNffQH]oNffU%dff"effPr\1rlpNffU5\1`%dk"rPeWh\1NffmP]\_^u\;`aw
y W` NffQ\djPg"gUWNdWdNgF]oNeffPkdbN\1r`Wh"NNdb`%Pt]^u\dbh"ve[SQjQH\1`WQjNffr`%dHn"UWS`WSe[St^@`Wh"Nj^1NPgNffURY\_^u^
UWNffnNP`\1`%dQjNdWdWPN\_lPUWNdbnoSrdbNi\dsr"S`5h"NPU%gRY\1`Wh\1r`b\1QjNi^_\1QH\1`wcSRYNffmNffUL\1rNffr"NffU%PL^
P`W`%PL\1r\1r"QHk"`WkPL^}]N[^_\1N[l\1mNffr`Wh"NHnSdWd\1]\_^u\1`baFSlYk"re[NffUW`%PL\1re[SQjQHk"r\effPt`b\1SrFeWhPr"r"N[^d\d
Pjr"S`fSUb\1Skd^1ag\_e[k^1`HeWhPL^_^1Nffr"NbPL^1noNffUWr3~S dbNdff%Prg`Wh\dsUWNffQqP\rdPtr\dWdk"N
lSUlpk"`Wk"UWNRYSUWVw
|dYPlk"UW`fh"NffU+\_^_^1kdb`WU%Pt`b\1SrSl`WNPQHRYSUWViXN[Z \1]\_^_\1`a\1rx M5{}|~y RYNe[UWNP`WNgd\_ZmPUb\P`\Srd\1r
`Wh"NNffr m\1UWSr"QjNffr`%PL^e[Srg\`\SrdlPef\1r"`Wh"N|5`W`%PeWVe[SQjnPraSlh"N[^_\e[Sn"`WNffUn\_^S`%dffw}{+Pefhe[Srg\`\Sr
UWNk\1UWNg`Wh"NFn\_^1S``WNPQ`WSzXN[Z \1]^1a>QjS"g\_la\1`%de[SQjQHk"r\effP`b\1Sr>`WSyQqPL\1r`%PL\1re[Sh"NffUfNffre[N\1r
`WNPQHRYSUWVw9Mh"Nd\_ZmPUb\P`\SrdPUfN
wH+p;t+MYh\dY\d`Wh"N]PdbN[^_\1r"N[r"SUWQPL^je[Srg\1`b\1Sr/w
wH+p;jO|5^1`Wh"Sk"hjd\1QH\_^PtU+`WSe[Srg\`\SrRYNTPdfdbk"QjN}\1rqPg"g\`\Sr`fhP`e[NffUf`%PL\1rHU%Pg\1S
lUWNk"Nffref\1Nd[efhPr"r"N[^dHR5h\efhRYNffUWNjn"UfNffm\1Skd^1adbNffnPU%Pt`WNg9PUfNjr"SRe[SQjQSr/w  rynPUW`b\e[v
k^PtU/QjNdfdWPNdsn"UWNffm\1Skd^1aFPdWdbk"QNg`WS]Nn"Ub\1mP`WN[^1agN[^_\1mNffUWNgz`WSSr^1a`Wh"Nje[SQjQPrgNffU
PNffr`+lpUWSQ\`[d5dbk"nNffU\SU%dffPUWNsr"SRPL^dbSjQqPgNcPLmPL\_^Pt]^NH`WS`Wh"NS`Wh"NffU5`fNPQQjNffQH]NffU[dffw
%

fiT+""/" L"+""

H+;	ff
fi
 fi"!#$&%fi'$()fi*!#+$,!-.fi'$/!#,'fi01#2'*3%54
6 
87:9;fi< 6 +*3%"9"
=oH+;?>@"ff
fiA
."fi<?!#$&%fi'$ @)B70*'+*5$A%%fi'$Cfi&fiDfi<*E*-F

G!#Hfi<*-"fi*3I&$,
JCK*3%LMHNL'fiOJP4+*-$&''$Q,
Lfi#.$*-&5.fifiR!<ST$Qfi*
*-$*-DJ 
UH+;WV.1Xff*-*)Y70*;$&!#*.Z2$W'fiR.<fi170fifi<*;[&'*#
$*5.4\!#$&%LfiNL$C])^[fi_<'+*
H&,0`[,
fi'JE$%%fi'/
$ 0a0Z&b)c*-$Zfi#	53JK$fid!-!#Rfi*#
J"*3'fiNL5.fi*:fi*#_%'fiR$&!#*3ff 
eH+;Cf.5gh$C%%LfiNL$QfiW!#$&%fi'$iU)\*-*)Bfi*!#KH&.$ZJP&'+*Kj&*#kZ[,
fiOJl$
*3!<,L$5fi*[&.fifiN
L*mH&ZOLfiNL/
$ ;a0*+!#+H&.$,J51H<8`%,*3%70finfi*Hfi'$4	&2
fi'$/.fi
!#*-fiR2$ES*-JK
c!-.fiNL$&-)&#.fi*-1fi&$!#$ZfiNL$,,$"fi<;j&J
a *D%,*3!<$Ffi*-<*-fi'!4R.+*-70<S+$TpZa1qB rs*-$&.[,
*3 .*-$,fiR1fi<+j&*#k,[,
LJ*3NH&$&%nfi5fi*
o
.[^8`*;!#$&%fi'$&ff0tuL*;vH,
fiR0fi<* $Z[&*-ff.4wK*3.*3o*#k@!<&.$*3%E.K$fi*3.x+*-[^*-R
4 *3!</4	fi*"ky!#$&%LfiNL$&ff +a0*+fifiR2
z$,[&*-;4	+*3.*3ffL$Pfi*-*fi*3."ff{ [&2
.$&!#*3%Y)
!-.fi'&m.$&%*3!<S
L*3< { .*"!#KH&.*3
% +|02
.$&!#*3%Q.*-$,fiRff4,

LJP*#kcH,
.fifi*"%,*3!<$Tfi*-J
4R.+*-70SY).$&%Efi<Z&}

&'fiRfi*5pZa1qB rT~}j&*#k,L[,
fi'J ;0.fi'&:.*-$,fiR12
712Jc1!#+$,!-fi*)
$'$fi*"%,*3!<$Qfi<*-Jn4#.+*-70
S +0*3!<S
*3+*-$Zfi# !#+$,!-.fi*5`*-JE
fifi'
*h$,
LJn4
,		')B	0-[ 504ff!#R'*)fi<,
JW*3!<S
*3m.*-$,fiR:70,
%n
LS*#
LJT$fi;!#KD$,!-.fi<*".fi;2

h)B'
fi,;%,*#&$,fi'$P *#
2k*3%*-* K1

	fi<*-*+fi*3.":70<SE70fi%,*-$ZfiN!-8
o!#Z'fi Kc%,*#
-)}!.)\ 	 )
.$&%P 0 a0*$Z[^*-;.41.*-$,fiR170*-*mk*3%n$Wfi, *#kH&*-NLK*-$Zfimfi543)'2

	fi*-*Kfi*3."
{ !-.fiNL&-)Y[&2
.$&!#*3%T.$&%n*3!S
*3:{ !#,
%[^*+$Q'd%!#&<'*3%$Wfi<*D$*#kfi;'*3!#fi'$)fi:
%!#,
fi fi$fi<*;!-.fi'&fffi*3.70fiE4fi*-oL$&!#<*3'* $nfi*3.x-*.%
t@c!#&OL$y&R'fi;$Qfi*"[&8
$&!#*3%Tfi*3.)fi71;[,
L*Efi</H^*-'4fiRm$Q$&%,*-"2

dk
!#$&%fi'$&-)[,Jnj&*#kZ[,
J%,*3!#<*3$:$&!#*3$fi*+$,[&*-.4K*3.*3ff$T*3'H^$&'* Ea0*
&R'fi0'*-fi0.4w!#$&%fi'$&_O!#$&%fi'$&0(mfiK=G

&'fi#.fi* fi&.fi}fi*:[&2
.$&!#*3%5fi*3.!-.$"<*3%,&!#*
fiR1!#KD$,!-.fiNL$E$*3NH&$&'*mfi+fi*;OLfi<&.fi'$E4h!#*3%Y)* 
 )$&!#*3'*L$!#+$,!-.fi'$!#Z'fi 
Xff870*-`*-2)$&%,*-d!#$&%fi'$&:U;$&%Ee),fi*d[&8
$&!#*3%5fi*3.x!-.$E2
'$&!#*3'*:fiR0!#KD$,!-.fiNL$
fi%%,*3fi*+$&!#*-fiR8L$,fi'*3ff t@ $&'fi#.$&!#*)70fi!#$&%LfiNL$U)S,$.70
*3%,*+.41H&,m`[,
fi'J
.fi".fi'!-2

JQ
*3%5fi*3+*-[^*-R5fiW*#kH,
!<fi'
J!#+$,!-.fi*W!<,*-`*-+*-$,fi".4713J,H&L$,fiR
$Tfi*#fi* 5gh$C%%LfiNL$)B70fiQ!#$&%fi'$Ce)fi*+fi*3&mfi!#+$,!-.fi*5fi*3'fi#.[,
N
!#+Lfi<+*-$Zfi#071*-$/%,*3!<%$Efi&2
fi:0fij&JK4<7oR%
ao*;!-.fi'&0fi*37102
'5.[,
*;fiH&*-N4<fi<* $$&%,*- 2

wk!#$&%fi'$&-)^[fi0fi
*#
*3:$5.$ZJEK* +*3<.*31.$&%*-"2$&ff$&'*-$&fi'`*Kfi"!#$&%fi'$& (.F=Kfi&.fi ',
%n*3',
fi
$Q4*-70*-DK*3.*3 ?g$&%,*-*3%Y)}fiR*#k&!&.$*E.4]2.Fh(4
%TK*E+*3<.*3mfi&.$Qfi*E[&8
$&!#*3%
fi*3.fimH&*-'4x.$5%,*-$,fi'!-2
zfiR'Smo$fi0$,
Jm71'fi*ff.4zH*3!<&1!#+$,!-fi'$E*3'#!#*3-)
[fi1!-.$E!#*3.fi*1NNSc}4}fi*dfi<*3.$EZ'fiNG
*:*-$Z`$+*-$,fiRff oOa0*:$*#kcfi1'[&'*3!#fiNL$"70

w%!#&
fi*ff'* .4z!#+$,!-.fi'$5*#!<*-$&!#J5$"K* %,*-fiR2
 Da0*:*3!<S
*3}fi*3.x%,,*30!#+$,!-.fi*
4*-7*-+*3<.*3-)}[fifi4h2
fiWH^*-'4Lfi#[&!E</
$ QqB`*-$T$Cfi<*5&R'fi$"8
ff!-'*)
fi,ff*#
G!#Hfi<*-_!#KH&.$ZJ5*-fiRff'fi&!<S"$Efi<* 7o2J5fifi* [&.fifiN
L*mH&ZOLfiNL$)$&!#*+*3* 70fi
+*3%	}[fi,+ffu$fiz!#+$,!-fi*3
% gh$,fi*-*3'fi'$.
J)fi*B$Z[^*-z.4+*3<.*3^$&!#*3N*
$Wfi**3!<S
*3fi*3.$&%,*-!#$&%fi'$&;(.Fo
= Da0,ff [^*3!-.&'*"!#$&%LfiNL$(E2

.7d:fi**3!<S
*3
fi*3.fi+2`.%*-fifiNL$+'fi<&!S+[^*#4*d<*3!,$fi*:[&.fifi'
*:H&ZOLfiNL/
$ 1hg$+4h!#fi3)fi,1!#$&%fi'$E71
%,*3$*3%fi<d*-fifi*}*3!S
*3fi*3.$&'fi&!<
S p.L$&!#*fffi*	*3!<S
L*3<Bfi*3.!-.$$87TH&*-N4<+*	.4
R3

fiY	,

Number of messages

350
300
250
200

"balanced-u"
"cautious-u"
"reckless-u"

150
100
50
0
1

2
3
4
5
Types of uncertainties

6

u<;0	&.:L#+,-.'n0/'&8z&#-R2,'3-
:K<3,mR}&.':&ZOLNL5+1+3<.3	1#&&.3Y	1,<&.#
'K+-+33 ."N'G1m#@<&.3Yu323.K-D^-R;NR.&,3y?K&.'
&,'
;uC.3oC^.
	KD,-.NL;#<-&#:z#NLN-8Z;<3.#&.<'#,' 0D-8L-m;<3.-.#N
#+,-.'T.-3 -?-.&'"OL,G-Z+,-R.'T3.&-N<".&#Eu
3 .&  -+:+3'0:#+,-.'+.-3 .Y3.0Y8.&mff&'#,3
.0Z1B T0,3<--NK#+,-.'/N#L3#NL'5L80-'5 .-3Y@&.'#
,.'E "<-2-3.- }<;&3d#+&.m;R2z,&- .B+33
 -m3."oZ<c,&#3.^8:&2.&#3Y-.NL&d.&3<3o 0E&#3OL
,D^-R:.	.-,Rff&- 3.n0hmZ-<3'dh2_#+&.''Y<;#2w#+#.'&2
3'R#3"2.2,LP33.I0-E-#&NR.,EOW.TZ:0R . QA,W,
R K"2,L3-+<&.;#,&KY+3N,L# '.1&#..+',E<L-,'
L&NR.'m<-"}.	-2-
u< 3 c#&'3ffEm1R","2:3<<--''#3#''-&,L3:< &2
.&#353&-N<0#0K-A+3<.3\<,o3.0<-,.'+&#,3LE',Z<-'
#-R<'3-doD-.'&ff3.#&&.3 3 "  .E1+m+330&.n;&8&#3
3.+'&NR.,'2w#+,-.'.-3YBh&,-3YY^-&/.-,R-,D,.NL
0C-.NL&+3#,l+^ETC32:'+0335.-,RL,+-',P
#&&.;.Z5+3<.31.:2
u<  c#&N3:+R&'&<_,52&#+.Z8LW#K&.'E;^-'".&#.
-.'&b&&2.&#3.&n3<L3<13"00&#3EZ&-#:.\-Z#}/<;3.n:1&#
.Z8L1,3<<--''#3#''C-&,L35<&2.&#3l3.IP&-'0#G:0Q-
+3<.3ff ,3.m-,.'n&#,3Q'Z,-'#-R<'3-E0+-.NL& 3.&#
.Z8LT&#RK/OL,G-Z5.-3P. 3 W  .T+"K3.3m&?E&8&#3

	fiffffff !"#%$ &(')ffff*+')-,."#*ff/	fi0#ff1
	fi324"35	fi1!
	fi*"#*
	

!"6*7981ff*(:ff
	;<#

=6>?

fiNumber of messages

@ACB/DFEFG)HJIKLNMFOQPRKSLT@LNDFU/B:AFEFV

500
450
400
350
300
250
200
150
100
50
0

"balanced"
"cautious"
"reckless"

2

3
4
5
6
7
Number of agents in team

8

WYX[ZN\F]
^`_acbdfe
e6gNhfii jCkml%gSX[nb/o^#p[^h#eX[qN^:h#kNl`l+\FnCX<hgeX[kNnr/st^h
imp[^o
oe
^glu^#vhfiwgnFZN^o1nFkxl`^o
o
gyZN^o
gnjzwF^nh#^xe
wge{Cp[kNe|kqN^]}pQgy{o~X[e
wze
wF^-v4gSvCX<or

e
^glrf^]
^N(^Nkmnjo}^qN^ngZm^nRe6oe
wF^oX[l+\Cp<geX[kNn~X[e
we
wF^hg\FeX[kN\oJe
^glh#kN\Cp<jnFkme%^
]
\FnX[n]fi^gSp/eX[l`^Nr+nCe
^]
^o}eX[nFZp[NX[nefiwF^`e
^oe9o
h#^ngy]X[kJkN]:efiwCXQo-^#v4{^]X[l`^nCee
wF^+]
^h
imp[^o
oxe
^gl
X<ozgCp[^e
k{^]kN]
lefiwF^l+X<o
oX[kNng{F{F]
kN{F]X<gefi^#p.^qN^ne
wFkm\FZNwe
wCX<oe
^gl^#vchfiwgnFZN^ox\oe_
l`^o
ofigZN^oCg]^~^]fe
wgnzefiwF^9gSp<gnh#^je
^glr/Ykzg`h#^]
e6gSX[n^#v4e
^nCeFefiwCXQot]
^o\Cp[efXpp[\oe
]6gye
^o3e
wF^
{kme
^nRe}XQg5p/kN]:X[l`{F]
kqmX[nFZefiwF^%jC^hfiX<oX[kNnFe
wF^kN]
^e}XQho^#p[^h#eX[qNX[eX[ne
wF^`g5pQgynh#^je
^glrJfk~^qN^]
~fwF^nze
wF^:efi^oefo
h#^ng]X[kxkm]efiwCXQot^#v4{^]X[l`^nRe3~fgNoh
wgynFZN^j)Fok+e
wgee
wF^:e
]6gyno{kN]fie6o/g]fi]X[qN^jp<ge
^
gexe
wF^`]
^njC^qNkm\o+{kX[nCee
wF^JgSp<gnh#^jefi^gl~fgNoxgCp[^%e
kh#kNnCeX[nR\F^Je
k{^]kN]
lefiwF^%l+X<o
oX.kmn
g{F{F]
km{F]X<ge
^#p[Nr(k~^qN^]NefiwF^:]
^h
imp[^o
oe
^gylnFk~{^]kN]
l`^jX[ng{F{F]
km{F]X<ge
^#p[NwCX[ZNwCpX[ZNwCeX[nFZze
wF^
]X<oiJX[nefiwF^:]
^h
imp[^o
o3g{F{F]
kRgNhfiwr

Number of messages

300
250
200
150
"balanced-m"
"cautious-m"
"reckless-m"

100
50
0
3

4
5
6
7
Number of agents in team

8

WYX[ZN\F]fi^%_N_Nb1Y]6gno{kN]
e|jCkml%gSX[nb/o^#p[^h#eX[qN^+h#kNl`l+\FnCX<hgeX[kNnr
WYX[ZN\F]fi^ _-Xpp[\oe
]6gefi^oe
wF^:jmX^]X[nFZ%h#kml`l+\FnCXQhgyeX[kNnz{ge
e
^]fino1X[nze
wF^:hg\FeX[kN\ognjJg5pQgynh#^j
e
^glJokN]:e
wF^+dfe
e#gNh
ijCkml%gSX[n)e
kge
efi^l`{Fe|efik%\FnjC^]6o}e6gnje
wF^`jmX^]
^nh#^+X[ne
wF^#X[]xe
kNe6gSp1h#kNl`
6

fi)F/C

+FC<[N|Y[NFfi%C[N6(
F9
m[FCNfi y#<N6[NCSC<#tCF}.Fm
C
FN4SC<#)[+
Ff
6Nfi9CN%5.13Nfi/#QyN6y[NxQ`NFfi m
F6#R#N

N#
N6[:C[NN6
NC[66fiRfC<
z#N<#/yfi[m[N<CS1NF
6fiN6#6)[6#C6m[`C.[CNfiy#<m6[NzxN<#3N6
cF|}Q [F
C[N6
F5m6SCN
fy#<m6[N[`
Ff
y6m[F:[Rfi9N#NFCS
m6fiN6
F:FNF[F3[mQy

F:CN
:#<N6[Nzt.fiFNFf#NFR}.F+
yuN6
N#1#F
#F
R
C</C[N|yNRS/FFfi
F3m[F`y


[%
F3:[F<y`[m<[N

F`m[FCNfi`FF
yN#[N[Nx
<#C<Y
F+[F9N[`3N<
FF`6y
%mF +N
Fx[`[m<[F
F#R[C.S<C[z

F}FF
F
N6SCN
:y#<N6[NJ<t[5[zFNxm+NyRC`6mfF
9mR6FRyN:
F
F+NTY[NF
STC[N#+
FJ4S6Sm93
N6Sf#N`+FC<[N`FNNmyF[N
S<#zfi%1Fm/[##NC
F9F[N
#
yFN:[6
m6S`
fiN[
FN:NF/m`+FCQy[Nz6#C6mf<f#Nfi
#<

+
FCm
|y#<N#[Nz(FN
N:
F%F}.m:
#R#fi[C FNC6FF9FN3N:
FS<#fi#C#fi[RxFF#
 fiR}Q5[NFC.m9
F:F[NfiC
F3S<#z
yCCFNf#N FC<fi|fC[9fiF#.
#<m6[NF
4#F3`CN
C[N
25

Percentage of messages

90



Degree of Collaboration

80
70
60



50
40
30
20

"team"
"team-without-subteam"

10

"cautious"
"balanced"

20
15
10
5
0

0
0

5

10 15 20 25
Phase Number

C/3Nfi:#y<N6}.m

30

0

35

5

10 15 20 25
Phase Number

30

35

)f#SNf#N`+FC<[N

Y[NF
%SFf
6Nfi%CNJS[1

fiz#m`+FCQy[N
u-y)
	fiffQ/
 FSS[[N#}.fi<xF#NJ
F:#N
[RNy.m.#4m[Fz`4mN[FzNC6


+N
`yC[[(#N`[F`fiF:#m
1[R   [
S[

}.m/F3NzS[


[N3<fiF
4Cfi[FzS
 R  
 C[[3N<`fi<S[N`#Rm6m[[NzC<)N[
NF-.C[<S[`C[`C6[N [TfiF`f
6m
CN%S[
  `[%fi`
+
#N
:NC<


 mC[
[NC CNFm[[NS3#4m[F#N
FN+#`C[N"
 !`

Ffi4C##
 R  
 
#[#[N%#m`+FCQy[NyC[[NF([C.}Q51.C.R6y[N#NC<NfiR<S[SNx

mC.fi9CFC
Ffi<Sm/N6
m61N<C1NFY.C[<S[`C[`R#[Nx[`
F/(
6Nfi
CN%5.%
 $f
Nm
F9
 &ffiuN6
m6Y['
 R  
  fC<fi`NC<`mC.+f[m[N<CSN6y
N6
[`
F[C[<S[`C[`C6[N)#NNC<+Nfi+

 NC[
36fi#N`+FC<[NN6y
N6 
N6
N#/m
z
`[N5Y#m`+[
`C63fi
 NFfz#m(
 
zJmF:
`[NS
fi+[[N
#N+[
`C61Y<1S[
NC (
N#SR
 )F(6
 &cC#FFfi
F
`NfiN
3
F
FC#|#[#[m[N
NFm[[NS/fiQ5N}fNC<z9F#
.#
J [
Fx#4
fi`9NNNfi#N+C.y[N
55.Fy+ *)N%
 ,.-
+S)N0 /1.
 ,1N+S65#mCQx

 mC[
f|}6
/}fi<SNN#
N

2243

fi576(8.9:;=<?>@ACBDFEG@AH5%AC9I.86:J

K+LMNPORQCO4STVUWQCXZY([]\^SO_[]QC\^`baST]cRdSCe(f'XQCcgdhORi^S\SZi(j\^e(cRdelk4monpjcRORidqcRXrQCcRdCa^`_dqs^Stc4SORduQCs^dqc4StORQCc4`
XvSf?Y^dhcgdwCj([]cRdee(dqs^dq\^ex[]\yzQC\P{|idqOgidqc|ORid}UWQxXXZj\([FUqStO_[]QC\Q~UqUWjc4`{[]ORiORiddq\GO[ficgdhORdSXQCc
QC\(T]fvSZ`_jYORdStXPm%UWQCjc4`_dCax[]O{QCj(Te'Sss^dScORi^StO7ST TV`_j^Ugi`_sldUg[STVUqSC`_d`UWQCj(Te?Y^ddUWQC\QxXZ[]qde
[]\QCjc[]\([]O_[ST[]Xs(T]dqXdq\GOWSO_[]QC\#YGfex[F`gUWQxdqc_[]\yPyCdq\dqc4ST[]SO[fiQx\^` YjOORidq\G|dq\^UWQ~e(d`
scRdUg[`_dWT]f`j^URizyCdq\dqc4ST []SO_[]QC\^`ORQvSCQ[erORidhX?S\Gf?`_s^dUg[ST.UqSC`_d`qm
\HSCeex[]O_[]QC\^ST7s^Qt[fi\(OhQt7dqSTfij^StO_[]QC\[`dSC`_fPQtXrQ~ex[ SY([ T []O+fQoSyCdq\(OORdSXY^dqi^Sx[]QCc4`qmZ\
QCjc"dWNs^dqc_[]dq\^UWdCae(QCXvS[fi\rG\Q{T]de(yCdoSxUqwCj([]cRdeucRQCXdWNs^dqcRO4`[`\QCO.`_O4SO[FUc4SOgidqc[fiO"j\^e(dqcgyCQGd`
Sh`+TfiQ{dqCQT]jO_[]QC\m"\vORid|OROWSCURZe(QCXvS[]\axQCc"[]\^`_O4St\^UWdCaGcgdST]{7Qxc_TeXZ[ T []O4ScRf?e(Q~UWORc[fi\dUWQC\(O_[]\Gjd`
ORQZdqCQT]CdCa(cRdwxj([]c_[]\yXQex[ UqSO_[]QC\^`%[]\'QCjc|`_f(\GOgidqO_[Us([T]QCOORdSXY^dqi^Sx[fiQxc4`qm"\`_j^UgiP`[]ORj^SO[fiQx\^`qa
G|Stss^dSc4`OgQ0SCUg[ T [fiOWSORdv`_j^UgiXQex[UqStO_[]QC\^`h`_jyxyCd`_ORdezY(fPe(QCXvS[]\dWN~sldqcRO4`qSOTfidSx`_Oal[]O
[`|QtORdq\z\QCO|\dUWd`R`gScRf'ORQvSxee'\dq{UWQGQCcWex[fi\^StO_[]QC\Ps(TS\^`qmnQCc[fi\^`O4S\^UWdCap[fi\ORidORO4SCUge(QxXvS[]\a
e(QCXvS[fi\'dWNs^dqcgO4`%dSc_T []dqc`_jyxyCd`_ORde?SuXQ~ex[ UqSO[fiQx\aORi^SOORididWT [FUWQxsORdqcUWQxXs^S\(fv`_iQCj(Te?dqSxe(d
dq\dqXZfHxdqi([FUgT]d`'`_dqdq\dq\cRQCjORdCa%c4SOgidqcORi^S\#^fx[]\yHQCdqcmdqcRdCa|SCeex[]\ySP\dq{j\^SCUgi([]dqSY([ T]
[]O_fUWQC\^ex[]O_[]QC\QxcoORidrORdSXQCs^dqc4StORQCc ^f([]yCiGOgs(TFSt\{Sx``_j(Ug[]dq\GO.G"ORidq\dq\^`_jcgde
ORi^SOORids([ T]QCOoSyCdq\(O4`%UWQGQCcWex[fi\^StORde?ORidORdqcRX[fi\^StO_[]QC\vQt7 ^f([fiyxiGORs(TS\|a(dqCdq\r[=_j^`_OQC\dStcRY([]
ORc4StcRfORdSXXdqXZYldqcoe(dqORdUWORde?ORiddq\dqXZf?Cdqi([UgT]d`qmKRUWQCjcW`_dCaORiddqSC`[]QC\'XvS\dqjxdqc4`qaYldW[fi\y
e(QCXvS[fi\0`s^dUg[ Ua=i^SCe'OgQ}Yld}SCee(de=mfik
V^ltl
x
`Xdq\GO[fiQx\dehdStc_T [fidqcaCXQG`O[]Xs(T]dqXdq\(O4SO_[]QC\^`QXZj(T]O_[]0SyCdq\(O.UWQT TSY^Qxc4SO_[]QC\UWQC\(O_[]\GjdORQocgdWTfifuQC\
e(QCXvS[fi\0`s^dUg[ UZUWQGQCcWex[fi\^StO_[]QC\?[]\`_dqcRx[UWdQVORdStX}{QCcgvK_dq\\([]\yG`qaMx^a^MCCL(k4m"zQCcRdcRdUWdq\GOTfifCa
iQ{dqCdqcaCSdq{dq\^UWQCjc4Sy[]\ydWN^UWdqsO_[]QC\^`"i^SCddqXdqcgyCde?K+dq\\([]\yG`ba^MCxLC%[URi?[e(\dqca=MC(CkWm
 d^c4`O|Yc_[]dW^f'cRdqx[fidq{ORid`_dZ`_f`_ORdqXv`S\^eORidq\PUWQC\(ORc4SC`_OORidqX{[]ORiG|#m
tdq\\([fi\y(`q`KWMCCL(kl[]Xs(T]dqXdq\(O4SO_[]QC\?QXZj(TfiO[fi0StyCdq\GOUWQT TSY^QCcWSO_[]QC\Z[]\?ORidoe(QCXvS[fi\rQdWT]dUWORc_[UW
[]O_fhORc4St\^`_s^QCcgO4SO_[]QC\ZXvS\^StyCdqXdq\(O[F`%ST`_QY^SC`_deQC\_Q[]\GO[]\(ORdq\GO[fiQx\^`[]O"[`T[]CdWT]fQx\d|QOgid.^cW`_O
[]Xs(T]dqXdq\(O4SO_[]QC\^`[]\SUWQCXrs(TfidWNe(QxXvS[]\PY^SC`de?QC\PSZyCdq\dqc4STVXQe(dWTVQ"ORdSXZ{QCcR=mVdscRd`_dq\(O4`
Szc4SXdq{QCcgHUqST T]deqClh_q~xqb ZY^SC`_de#QC\
S_Q[]\(OvUWQCXXZ[]ORXrdq\GOOgQORid'ORdSXz`+Q[]\(O
yCQGST#S\^eS_Q[]\(OcRdUg[]s^dvUWQCXrXZ[]ORXdq\(OORQS'UWQxXXQC\zcRdUg[]s^d'omu{Qex[`_O_[]\^UWOuO+f(s^d`Qt+Q[]\(O
UWQCXX[fiOgXdq\GOW`" SuXQ~ex[ UqSO[fiQx\PORQZORid_Q[]\GO[fi\(ORdq\(O_[]QC\^`%c4SXdq{QCcgZScRdUgTS[]Xdez\dUWd`R`RScRf
Y^dUqStj^`_dex[ dqcRdq\(OSCUWO_[]QC\^`hStcRdZ[]\GxQCCde{|idq\P_Q[]\(O}UWQCXX[fiOgXdq\GOW`hScRd?e(cRQCss^de=mQ{dqCdqcaSC`
SrcRd`_j(T]Oa(_Q[]\GOcRd`s^QC\^`[]Y([ T []O+f{7Qxj(TFeSssldScORQvYldZT []XZ[]ORdeORQ'SO_{QCT]dqCdWT"i([]dqc4Sc4UgiGfzQ7S+Q[]\(O
yCQGST7S\^eHS+Qt[fi\(OZs(TS\a"ST]ORiQCjyCi[]\^ex[fix[e(j^ST`'UWQCj(TedWNdUWjORd'UWQCXs(T]dWNSCUWO_[]C[]O_[]d`u[]\`_dqcRx[UWdvQ
ORid_Q[]\GOs(TFSt\m7id_Q[]\(O|cRd`_slQC\^`[]Y([ T[]O_fzcWSXdq{QCcRu[`[]Xs(T]dqXdq\(ORde[]\PORidZ.|}`_f`_ORdqXPa
{|i([UgiSssldSc4`ORQQ~UWj^`%QC\?SORdSXQtOgicRdqdoSyCdq\(O4`qm\P.|(aCORdSXZ{QCcRscgQ~UWdqde`%{[]ORi'S\
CCx^F7Syxdq\GOoe(dqOgdUWO_[]\yvORidu\dqde?QCc"_Q[]\GOSCUWO_[]QC\p[fiO[`|Ogidq\'cRd`_s^Qx\^`[]Y(TfidQCcd`_O4SY(T [`_i([]\yPS
ORdSXS\^e'dq\^`_jc[fi\y'XrdqX}Yldqc4`q^UWQxXXZ[]ORXdq\(O4`|SC`cRdwCj([]cRdezY(f'ORid_Q[]\GOcRd`_slQC\^`[]Y([ T[]O_fXdqORiQe=m
 i([ TfidZORidscgQ~UWde(jcRduQCc|d`_OWSY(T [F`i([fi\yZ_Q[]\(OoUWQCXXZ[]ORXrdq\GO4`7[fi\G|"[``[]XZ[ TFStcoORQ.|
 [fi\^UgT]j^ex[]\y#ORidv`[]XZ[ TSc_[]O_fHQt7ORidgT]dSCe(dqc4[fi\G|ORQzORidWQxcRyGS\([]qdqc4[fi\.|?
G|e(Q(d`Y^dq\dW^OcRQCXSCe(QCsO[fi\y'  `qaC{i([FUgiPscgQx[e(d`[]OSCeex[]O_[]QC\^ST^dWN([]Y([ T[]O_fCm
G"[`ST`_Q?cRdWTSORdeORQz|o=.K+7[FUgi[Fe(\dqca"MC(CkWa~SrscRQCOgQCO_fGsldhORQ(QT]C[]OSs
s(T []deZORQ|Yj([ TeS|UWQT TSYlQCc4SO_[]Cd%[]\(ORdqc_0SCUWd7Syxdq\GO=QCcVStss(T[UqSO[fiQx\^`"`_j^URiSC`S[]cRORc4SCdWTGScRcWS\yCdqXdq\(O4`qm
|o%h`QCc_[]y[]\^`"Scgd"[]\ORidCi^ScRdeTS\^`OgidqQCcRfCm|T]ORiQxjyCiZORid||o=%#[]Xs(T]dqXdq\
O4SO[fiQx\e(Q(d`\QxOdWN~s(T [Ug[]O_T]fHcRdSx`_QC\zcgQCXOgidPll'GC.SOgO_[]ORj^e(du[fi\Ci^ScRdeTS\^`[]\(ORcRQe(j^UWde
[]\KRocgQG`_oc4Sj^`qa=MxC(k4a[]O|e(QGd`7[fi\^UWQxcRs^QCcWSORdex[F`gUWQCjc4`_dyCdq\dqcWSO_[]QC\'S\^eZ[]\(ORdqcRscRdqOWSO_[]QC\'ST]yCQC


fi=.(

_]Rvg^"C_]]^R%]v_gZRC_x(fi=R^
	fffifig_]R(qC]Cq("C
  l  	"!$#%&('*),+.-0/0 g1 ]4RR2

 x3 Wx4_4
 lq 57qqZ(vP^qo 'g6
 F7 3^ 
](R8 1]Cq(Cq(9 :C9 ;Cq4 $!<#%&('6)6+.-=/tRR> z]H_ g](Rq4 W_]C&
 	_ gHCv](R9 ?
^ Wu /Z_qxqGg@ ?]Ggq4 W_]C'(_Rx3 
:<+A'6BCWCGg4C_4D
 5figE
 !$#%"('6),+F-GH%> gEIG:> (q@ 	Dff@fifiJot K)6HL'.$+LMNOq(]G9 	
ff@fifi7P] _9 ;CqW o]R
 QlCR4tGS
 5| ~T VU]4_@ 	*:$+A'6B (W >CY
 X+](?]GRq(_]C^N
 Z5fig C
] [^q W /:C^R@ \]Ft^8 	4gqvR^tR^
 :C^g@ \  QQRG7 R#]_
 !$#%&('*),+.-xR
X_]G%R Q^x^ (W   P QQgG g /A),HL'.<+LMA\"R` Wa bfi

 WxGRWC_A
 5]Rc
 X+tfi(R QlC^ (1 ] 	
:$+d',Be W] 5oR
 5C3 f^C_@ Cg
 (q9 QfX_]GC( ih@QP(]q48 R(]9 c:C@ WC (	:$+d',B ^C
R%
 qjQ^ (1 ] /C"g ]9 ?C(]RC_]R
 WC^_g4]GW" ZR ]_ ^__]Rfix]?R9 Q^]_]ZR  W_ ;x ?
_]9 	(C%R8 ]9 ;(]vgoCgq. 5} _RqvT k(] (	(:<+A'6B^CRRqR
 Qg@ 3 q]9 ? Q?]'R
 lq 
(^9 	d:$+A'6B^C](RR ( W@g@ R(> mx
 ^CgRPg@ ( WvRt2
 5C 'e ;xqR 9 	   	
(@ g]C ?RqCgq_> SWCZ(> q_]C_8 ]@ W_ ;C] 	.C*
 578 1|CR

 (e n5]R?(]q4 g /|Rv
 _ gv9 	"xR8 ]9 ;(Z] v 1]q3 ?03 q]Pgv9 o:$+A'6B  _1 1fi^R4RrRq^_P7 WRGR
(Cvfi^T 	=Ch_qqz]RZCRq 57' _RqvT ,U]^ 1	4RqR^p
 (1 >x]S
 WjW lC4fix
 Cq"CR7 Q}j /8 (__]R
 (Cv] ?q]9 ;C8  ~RqCA
  l@ Ssrfi(G_D
 WC Q fi t	u:$+A'6B^C
QR QlG_@ _]CGgq%
 WC Q ]v
 ;x x1 wxq_]C^Rv_ QQlCR|g
 57x3 Z]PRhtCqG g(fig@ WRR
]4_8 1/3	   	5figv8 Q ` g]RCGe F% rR 4R9 	( ? 9WCR
 Q^ xfiR
 WCrZ]Rq(49 A
(qRqRfi(]p
 /0 WRxhqRf
 5C >H QQlZRp
 ^?R?_]CGgRu /%W1Fj ^C4t_]C&
 	"   `	N
 (q9 Q
_R@ (	uG^` yX+tfi(|C( (fiqW gP_x `z/  ;Cx_]CGgq%
 WC Q ] 
{ vx.
 QR9 ;x]C^F
 57x3 R
 ^ 	uff@fifiJ(k5$
 QR_q(R@ ?Z](]_ ]R
 Q]qq(4_]C? /VgR
 ?
5C3 # (8 |	 _^
 ^C@ C}
 X+](](Rq(_]C^9 ~^
 57x3 ]a bo> gPCRx 57x3 ^/C
:$+d',BY	Y(8 w^(fi#R Qlq4Rx49 	" #8  ^x4_]C#RW]8 QRR ;Cqg9 K| 59 ;Cq@ 	
:$+d',B5|CF
 Rq6
 (9 ;C8 ] Ql@ 
l@ q^_u /n  |_9 ;CqW kQR ]qv]PR^t$
 5C3 rfip
 WC(_]G@ N(9 ?
;C8 ] Qq( /VRt2
 5C 2qQ^ (1  ]_]]'RD
 '|RW 3(Cv]&
 	( i "RD
 QR_q W /9 5V(xv]^
_ gC<
 4t^ Q^Cg@ 	 p  i o]C(1 wxq(3 qefi9 ? Qz]Pg lq9 D:] Wf:$+A'6B^Cg'8 ~Rq 
 ?_ ^_4tG_ 1?R9 ;C_%R^t.  ]q$
 5C3 (	]%F
 ^_RuRR<
 :$+A'6B C%Z_9 Q^4go _Rq

 	
4gqoR^tt8 Rq^]C /7R^toa bp5C3 (c:$+A'6B _S
 QR ;C> (S
 WC W9Qg^ 7 ;t W
]HS
 ]RqZ^ ~+FZ  Ql@ g1wxq_]C /RD
 X+](q(4 7Rfig (h]c
 (W >Z Qz]?R

 
{Y
 Q^R` W 	&;xF8 Q ` g]vt^ ]C RS
 Q^RFe %:C^R@ \]^
 3)RG lRIG4^9 	Fff@fifi	=R(
R` ]Z^C Q^8 1]@ Cog}g@ mC(]Rqq(D
 /C|R?o _ gvRR
 (1 > Qr(fiqW g' /
X_]G](Rq(_]C^9 	(^8  ]8 /0 ^CCRqRq
 lq49 (](RqGfix^9 	t X_]G]GRq(_]C^y
 /x|R
rWR@ Wx
 gW]@ ^qx_@ t$(^  _
 fi@ zR?CqqW  b lt_]C /nWCZ(> q_]Cp
 ^C_@ C
] /xRv_]C ?Z(9 Qlq (q 8
.
 / 1] 5]h 5KQR_q(4"6
 (q41 ]@ fWCR
 Q^__xR
 ^q 5qqS
 :$+d',B uR|a ]qF
 57x3 

 ^ 	&fffifiJ@("]zRqRvj /RW]6
 qQ^ (1  ]_]9 6R
 lq]p
 5]R&
 	&:<+A'6B] ] (htP8 Q> g]
@ g^(_Rz_4  _}
 X+](R
 WCZ]Rq(4c
 ^C_@ CE
 \dg'*)9 	"5|(> RK5|Cu^ (Rg_@ ]
QR9 ;x]C^6
 5C3  _'a ]q@ 	Cq(4D
 5C >z]R
 Q > gfia b	 zq W'_Cq_]] WCgR@ W	"C ?
_zR8 G_gq Wj /$X+](z
 WxZ]Rq(49 '<_ 	]
  ]qS
 5C3 (	.rC(]RC_] R9 Q^]
5|C(]C  Ql@ g  b lq@ ( { Y
 Q^R_> W@ 	%R?@ R^t(F
 QR ;C> (@ /x}rC(]RC_]p
 5|Cc
 ^C_@ 
CE
 WC
 Q^_] 7 R(]9 ;Cqq(S
 WC x]_]C^j / Qlq4Rx49 R(Z@ g^(_
 5|Cc
 Rqv
 x3 W;Cqg@ 
Rf
 ^c
  ]Z]R@ R?C(]RCfi' zR9 Q^] /&X_^_C4
 Qg9 ?Z(qRqRZ]@ # Q^@ g  _hg ]2
 QlqR
 Qlq4RC %UgRqRCg 	RZR ]9 ?0_ ^_fig_]C^
 5|C$
 (8 w^@ p;xv'a Q^@ g .QR W@(RZ8 ~@ Wg@ 
_9 Q^WR8 4] x ;C> (^ 9  { v
 WC(R4C@ 	:<+A'6B^C"+fix(W wxqtG xqq4   lq@ ZC(]RCfiZ 
R9 Q^]L
 ;xF]4%8 Q> g]R ]9 ?C(]RCfiR
 WC^R4](49 	(R^%q^ ]ox(figC_]Z /Z gvxRRq
@

fin.(f&@`F.6

ej9SjkZ13@9(`z9u@>1`af>d<29a6^1k.36@N39iR3ab
84872ab794393R$A6@jW>@*jbD9}3v@R1
Z1b@939A3jR38RR@>&9$38@3@9FL>>FAR938R4889
86S393fL]f39j3@R3@3R9Lk39eb$L@&98&R1>9
~37`7~7c811_97@_3^8R3R9393>F393
R$A6YD39479919@3
3@jv9&3@@63978>9y87R3R99
cL81<74eW93@o9NZK393f6%88>9%88939d39n73K
@ (&>@3L>3Dk8R>9f>f1D973R99na@3@v
9>><9eab7S 82>9ab7z8aAu989D998x3u$@3>$
>L<A6"1@f3LL3cb8.@>f3939>Fi9n7363AE8>9
ejF893@973in8@8487R`9j
AL81 7A989R9FS8R
>9&6<>u1b7
$d,Y76@196n73z7>p7,@AL3^8R8p3@RZ@
9@9yR@3j`av$7>fL99194a3@v9A"1&<A6G>L@
fL3v91@f89R9(3@L7,q$]811>z39D833A7v91
`c3438u4A36397<n73x
<A6_>ke`a$38>3@*3$887bj6iR9L(4Liqu$137n1uqL,y
Di9n(@39 @ 8@N$@u@198$Liqu$137LW7qj3,y,yD@9k(@3a9@
@7 (<bk97>$397@8jW>uab7&3@L877c8R9L3(>
3ab743$Lveb99986Lc@196L3fgy,Yi8@$7gR39G.8
u9K9*f8>39R393398K4Ni3^7>33@97R9n73
Di9
 @39@ @ K$93$a7g9f@}8N38R7>47>
N>6jy8&cD3@}94Z(S937>9DvS3@89RD7b7>
>D.71 9969LR8>zj3>Ak>Yy,L v9eW@pu@9RL6.
7RR2pR9666@8@33aW^1yj986Zj3>1gjb7iL 937>8
,}8RRY37ZL
y,_>RN`2>E87E8ab79$}
vf43@f3R87bj3@Li$7`j84N8@8Nb77>n89<y,
9
987RR367W&939Lu@Lk@LFL81|bv6L,oD@9$(@39  
37`@D998&9994877pRb@TxS9D]<`
f@f8@
v@a$3487f9@F *c973R9@366L,}3R9v1>93
f839S4L,3N
6.c998xR8&k3@j2Lx$d,9jv37>46@
9ab7v8&3
3@aR.jb@7.RL(3$877vu@1@SL,j98&L>@81`a
*$39
3$y3281@8R7&^RL6xR`j338,82>9ab7
7`f@>i399>4@LLL>9uL,_98R1@D7R6A3497S3@
NK$d,Ykjp3$d,C8>}3>v77bab7L811bYK887bj&
.9a`eW(L6N6L6K27ya93D$87fS3@L3ci3887bj
bN99FgL7>vf89319@p887bj39d,D3@@u39fZ1k3R863
3@u11babSK8RbR984j%3@L3NK1`7KE8738>9
DDRN43p99487~L,N,y,`f798@Ki
$d,Yf986987v38>ab7%f$A6S6L6}`<f39@3
g@SF3RL3(RL93>S1>R38>abY9L99K$d,Cjp3S$6%
87YiR9Lnj38@E  @7 Y$6%0>N8@K799$3
,87ab7SR8b7v7vab7.jk1$jR2j989A$L99@jbL81`
3@86R^j]4e`cf8R39TRZcL>^@j43*7b7>
@

fi


	fiffffff
!	fi"#%$'&()(*+$-,fi"(*./0*fi$$1-23/45	fiff!2-*.ff'!	fi12678	+ff(*9&"
: "12281!	fi126;<-
-22*=12>/"($1?5?*.($+/4@281
#;*=5/	fi(58/7A*.ff	fi4BC*.($EDF<GIHJLK
M '2-*.ffN21?*fi6fi/4'OPFQ*.ff'&(fi9R-SfiS+TU?9VWKXfiK/9Y/ : 121Z4[2-*.ff]\^_5	.//5/	fi(V9fi28!
`712-23/afi-2
:	 2-*.ffb	fi7(1?*=2	fi1?<8(*fic&(d
`e7#/	./2-$Kf<	.ga+1-9%2Z"-	 : -5
*.&#h;Z84B_5	./i
	+ffff'/2ff?9

	fiffff'"%*.5/	fij9Qff	+	fi15/4k*.($l127(*Y/1m*.1	fii*fi$$12-5-$K0F!8 : 	fi1ff0*Y#g*.7712	*fi28E2	@-*.ffn
!	fi126/oODfi	fi&p124E-Kq*r#WK;9gRYSfiS.sU21
*.( : 	fi12ff0c2-*=fft7#%*.(u/2	k57(*=1?*.2B12	.#/nv7#%*.( : 	+1i
`n

"5/	fiC&>w/($+a+%$"(*Y#x9y!/28A1Z4=;$+#/>Aff'&p-$$-$z
	fiffff'"%*.5/	fi(KwDFGIHJ{7"127(	5
#/>L*Yafi	.%$
5"(8]21
*.( : 	fi12ff0*.Z	+(9(5	0*=4fi
*.@|(
`/&#/>k1-*fi5	fi!/28AOvvU!
`e7#h%/i2-*=ff}4fi	*Y#%
~-7#%*.(*.($
OvhvU5
#/-
5/afi@
	fiffff'"%*.5/	fiOP5E2	&('/ff7p	fi12?*=c/C71?*fi
5%
.U?K M zO2ff'>21?*fiP);
fi9Qc"12n
: fi9bA8fi9cR-SfiSR.U
9q$-%3/	fio8	fi12>E%*.77#h/-$ : 	+1iff-2*.4fiB715/	fi15/5/-*.5/	fio
		fi1?$+/(*.Z	+
&(*fi5-$l	fiE28*.4fi?\p12-
"1?3/afiff	e$
#h/4E	 : -*fi8E	fi281?V\j*fi
5/	fi(KDFGIHJ{*.77#h-'$-%3/	fi
28	fi1> : 	fi1
	fiffffm"%*.Z	+k5
#/-
5/a+5>E*.($@8(*.(
ff?V9(&"!/A*'afi1>$+hj12
	fi2
`!
71?*fi
Z;*r#(	fi7(1?*=5/	fi(*Y#h/-*.5/	fiB	 : 4fi1
*Y#9$	fiff0*rn/($7p($-2-*.ff'!	fi126ff	$
#(&(*fi5-$	fic_P	./
/5/	fi(VK
IBI.IIfiyfiC}jfi
F -*.ff'g	+126'%!&(-
	+ff'/4B(
1-*fi3/4.#/>k
15/5%*Y#E*'ar*=15/P>B	 : ff'"#Zn*=4fi<a+/12	fiff?91
*.4fin

/4 : 12	fiffafi/122"(*r#afi/12	+ff
 : 	+121?*Y//4o*.($-$"(*.5/	fij9!2	E/2122nv&(*+5-$ : 	fi12ffB*.5/	fi
/4fi1?*.5/	fij92	'7p	fi25%*Y#jffm"#/5/nv12	+&(	fi5%[57(*fi
cff'%23/	fi(cOPFQ*.ff'&(c*Y#K/9R-S+Sfi<*.	')*r#WK;9RYSfiSfi
 /ff2
#F
h`e
/1?*9QR-SfiS=s(h##h%*.ff0Z	fiE*Y#K/9R-SfiSfiT</?*.	B*Y#K/9jR-SfiSe(fc*->+-5n!	fi28@c*Y#K/9
R-SfiS+fi!
h#h#>fi9R-SfiSfiTU
K M 712afi/	fi"(/ff7#/ff
*.5/	fi(y	 : ff'"#/5/n*.4figZ>e5ff09Y/(#/"($+4B	fi"1I	.j9
2-*.ff'!	fi126[8(*fiy	 : 2&(@&(*+5-$B	fi712n$
(-$9$	fiff0*rnZ7(-h7#%*.( : 	fi1!
		fi1
$+(*=5/	fijKg<n
: 	fi122"(*.
#>fi98-5i7#%*.([*.12/|(
`/&#@*.($28"(c	0ffB*.?8 : 	fi18m"(
1?*Y/Z-c	 : 
	fiff7#/
`9
$>(*.ff'%Ba+/12	fiff?KwH'*@1-5"#/-9*.4fi?\Q
	fi812i2-*=ffm!	fi16k*.z,fi"%6fi#/>z$+%25	.#/afiB/2	
ff'%2
		fi1?$+/(*.2-$[ff'%5&p8(*Yafi/	fi1-Ky"12281ff	fi12fi9Y28g
		fi1?$+/(*.Z	+m7#%*.(I*=	fiq&p!12"(5-$u/m	+281
$	fiff0*r(VK!Dfi"(2812"(5c%y/ff7p	fi12?*.!8	.ga+1-9&(	fi28@	*-a+/ff7#/ff?*.5/	fi
j	fi12*.($B : 	fi1?


	fi(3%5(
>]*fi
12	2<*.77#h;*=5/	fi(K
J	fiZa.*.2-$w&>28
15/5%*Y#g-$ : 	fi12-*.ff'!	fi126|(
`/&h#h/P>C*.($12"(2*.&h#h/P>fi9Q28%*.15%#8(*fi
712-52-$dDFGHJC9*B4fi1?*Y#Iff	$
#	 : 2-*.ff'!	fi126K!8#/DFGIHJC\c$afi
#/	fi7ffc;$1Za+
&>i71?*fi
Z;*r#(-$I	 : 2-*.ff'!	fi126*.77#h;*=5/	fi(9+/?
	fi1%Q&(*fiZ-$'	fi'715/(/7#-$B8	fi15/-I	 : -*.ffn
!	fi126KIDFGHJ%!	fic	 : _P"(5* : z/ff7#/ff2-$]5>52ffB8(*.8(*Yafi&p4fi"@2	[&15%$4fi28c4*.7
&(5!k
	=##%*.&p	fi1?*.Z	+k8	fi15/-*.($@71
*fi
5%
fiKDFGHJ
	fiff'&-c5afi1
*Y#6+>0	.afi
# : -*=2"12-
OvvU"(5'	 : _5	./</5/	fi(*+*&"h#%$+/4k&#/	26 : 	fi1*2-*=ff]\_P	./ff?*r#*.5/2"($OPafi-2,+"
*Y#K/9!R-SfiSfiy	fi8bafi-,fi"fi9RYSfiSR&U< 28@*.12Z;#/h##/"(51?*.2-'8(*.DFGHJ&"h#;$"7
*'8/1?*.1
28%*Y#g512"(
2"12	 : _5	./!/25/	fi(*.($/($+a+%$"(*Y#/25/	fi(9*.(*Y#/	fi4fi	fi"()2	28[7(*.12n
5%*Y#iDfi8(*=12-$  #%*.(wO21	5@c1?*."(V9R-S+SfiTU?<OvhvU/24+1?*.5/	fi	 : 	.afi
#2-8%,fi"- : 	fi1
`7#%/
-5?*=&#%58ffB	 : _5	./25/	fi(wO2Dfiff'/28o	fi8j9cR-SfiS+TU?!OvhhvUm71Z(/7#/-$
	fiffffm"%*.Z	+
&(*fi5-$l	fiL
	fiffffff
c/]_5	./c25/	fi(!OWapU"(Z	 : 
`e7#h%/12	.#/nvff	+	fi15/4k
	fi(Z21?*Y/?
*fi[!
#h#*fi[127(*Y/1ff8	e$'&(*+5-$C	fiE_5	./[/5/	fi(VcOa(Ui*.77#h%*.5/	fi	 : $-;P	+nv28	fi125%
2-8%,fi"- : 	fi1!
	fiffff'"%*.5/	fi@5
#/-
5/afi/5>*=($8(*.(
ff?V9)8@8
	fi2
`ey	 : 28y_P	./
/5/	fi( : 1?*.ff!	fi16KBFj	E*-a.*Yh#	 : 287(	.!1i	 : *wff	$
#<Z"(28z*fi'DF<GIHJL9j* : "($*.ff?*Y#
8(*.4fi<E*.4fig*.1
28/2-
2"1-y%!-255%*Y#*.1?8/2-
2"12-!ff'"(5!712	.a+%$
`7#h;/i5"77p	fi12 : 	fi1
12712-Z?*=5/	fiL	 : *.($C12-*fiZ	fi/4k)8z2-*.ff4fi	*Y#%9yO1-*fi
5/afi.U2-*.ff7#%*.(*.($d2-*.ff5
*.2-K
DFGHJ8(*fic&(C*.77#h-$C*.($ar*r#"(*=2-$/A2812
	fiff7#
`L$	fiffB*Y/(KiF!!	B	 : 28$	fiffB*Y/(9
-2

figBj-fi;YLyfi

2
fi2@.(j?=(5(fi-(.2[(fi5-wfik2-Y/v!fi5%E3/';=5/fiE+/2fivfi?Y//(j.(
2+qh/fig=fiI-.0(-+g(=25%/(.2-[%.2+2Y/55%!
e
;Z-I!/2'(2-I.
fi2!52Z;=fi
j3@2
0fiBY/je)fi(yjfi%Yfi.fi-.;y.o(
fi
/fi<xfi!(.5%(=5/fi@/]cxfi2(
fi'/05Z-<.!P3/'%.2-pg5
2+2(.?
(=/].<Pce
!
fi?5fi!<I;mW.[v2fik
+/20e
.-.'g+2Q.(C5fi?Y0=P+c;Z
5-'0Y/ofipCx+'x2@!fi2z]+E%25@%/fi-Z5/.5/zCm2?+
5/fi(
!/2C/-.2/(C3Z;r
ep5/?)+/o5!
h-+fii5@vfi2.c
e%.(.Z+
(fi5-/-.2/o5@/?
hc
h/-c-.25g.p
h'-fi+2/ I 2fi-Y(.0.fi?

fi%z.2+0.5  B2fi5/B2-.'!fi2k+
5/fi/5/-y?.2[2(.zY/--fi5fi/L.pfii]
fi(- Yh/fiyv2fiCfiBY/(p(2-fiZfi/l=(fi[2-.'!fi2.+?</-.
3/2(.Z+5(- B
fi
+(=5/fiA2/-
 fi<(Z?.(
fiE2[vfi20.Z+@/-fii
?fiZ-j.
fi2Q.fi/-.2(Q3/2(.5/fi5p- !2/-j?.fiI.fijfivfi20.Z+/-fi'.(
fim%.fiq
!
hv
fi
5%
-B2-.'pg
fi%'2(I55/i
fi[-=2--x+
 
2fi5/	 [fi
5/fi/5/-
<WYhI(fi@fiCI2/-<y/(
fi?=@(.5%/(.2-E3/2(.Z+(c+/5/fi(Yh/fi
C'.!/-fi/(3/fiE2-=2/o.2fio
fi%o
+/@
22'/((
5/fi
/-.2/@.2fi-yvfi'/5/.fi
fi?+/(.5/fid2fijqYfifi?
pYh/22-
5/fi0.([2-
.fic;Ir;Zifi[2fi%x+jv22!!fi2-(=25%
%.5/['fi/2+
?y!/2B2
h;=
fim%.Z+j!.fi
.fi0
/./?.fi?fifi/BPQ.'(
)5fi]-fiff 
fiQ.'(fijYfifiI2'/v-.0.-fi/fi/fi
fiY%.(B/25/fi(!vfi

fi(=5%5fiB!/2.fiY%g=([/25/fi(
 < j2(
-/@fir;y.(25/fi(y0Y/(+%.2

fi?+/(.5/fiwWYh/2-jP(
'2-=0.2-y.v2E.22Bfi!%5%Yfi2
%.-@?fiZe
 .!fi-
./fiC2.fi2-+.5(L.L=2fij/'(fi](@.2
vh/A(Y%.(
-d!/2=L.fi?
fi2y2fi5/fi
5/+Z-VI/5%Yj2-5/?y.j2%y.2fi0.2(+22-P..'q=mpfi
-fiefi?
5%2/CC
fim%.Z+L.(.hh/5/-'/Lw5/(/-WfiZ+E%fii.+2
fifi%<xfix2!fi2Ifi(@5%2-
fi'%.5/fi@0Y[x+2 2(+3%!.q'/5/.fi

.h%.(+?.5/fifi+5%.5/fi25g.22=jg.2p22fip-fifi
I25/fi<Ib2
h-<fiB2
2-. fi!52-. -+B2-5./+@+%2.fi
(.25%
%.5/B]-%+@

fi
5/fij
 h/c-+?5/B/2-.'!fi2u;[/?5
h='/2-55/'fi(=/fi-55/=5/fij
(.h/o.fi?'2dfifi5%.2@
B%.(B!/2fiB/-fi@!fi%oY%5E/r+AC
(
hh/5fi
 A@fip]2(=+2-23/z5(2%25-g+;C/5/0=2
/z/-fi<I r.

/2.fi-
 (
/h%5w2-.'!fi2
ff!#"%$'&()$'*$+-,ff.

!%<2-5-.?]fi!5pfi22-Efi)(.2.
fi2?fi
cfi+fiff
=5fi	/xfi 10p2-i);
.2Z;/;Q.
2(-+?3/fi.(!2+/fi(q
+x2(
y(.(yPQ.'(fifiYfir
(2(..fi
jQ.fi4
 3c?.?jj.(5
 )h.(5
 0I.!5/+vfic2
/m
fi
.(A5pfi2vfi
2[g+22pfi22-E2%c.25%/fi1
 <%2
(23/fi(<!/2E!%]./(Yfi
/(-w/2.fi[2
6 (Yh5E.!2.25%/fir;Z]2(.2fic2-. 'p?c!fi2+fiE2!fipA7 jfi2cvfi
2
/]5pfi2B.i2]!fiL2pfi22-/ ;@=25%/fi8
 cfi0r
ep25%5Evfi;B!fiLfi
2.+;-d9
 Y+%Cfih/..o.(:
 32]fi+25fiA=<
 ;!
 3(./I.(
 LY@fi[.1
 
= fi=;
+j
>	>@?

fiACBDEGF

HII1J'KLMON8HQPSR5JTffUCM%VWJ+LYXZ\[]H^

X_I1J'`MOab`U'TffM%c-K

dSefSg+hifkj+lGmffn%o7mlGfplGf	hqo7risut+f	lt+f7vumxw4yOmxvvumzw{h|qef1lGf	hqo7risug|isumff}~mxy)d1pgrqmxffslGf	lsu}|qeGshxrq|isovufff
%|sht+hif	l5m}5f7f	o7j|sm}mxy1eGsufkr@xr7oqeGsokv1mffg'fkr@x|qmffr7hkCmffrrf	ffo7|isufffgGvx}+hk1vv1mffg+fkr7x|qmffr@hsu}Q|qef
eGsufkr@xr@oeG#f7f	o7j|qfs}g+xr7vvf7v%x}+lefk}+o7f]|qef#su}g+xr@vvuf7vo7mff}+hi|qrj+o7|	dSefo7mfffk}|7hSsu}|qef
g+hifkj+lGmo7mlGfxrfpfk}+ovmGhif	lsu}5ff~ffSdSef|qfkrq]su}mxvumffff~sh<+r@hi|plGf	hqo7risut+f	l9t+f7vumxw+|m\ovxrisy|qef
g+hifkj+lGmffn%o7mlGfff

z7	GOk+@7Offqi
mffg+fkr@|qmffr

{\	CffS!uuuu}CffplGfk}mff|qf	h|qeff7f	o7j|isumff}mxyQ|qf	x

tG|qf	!xsufffk}|qefo7mff}G|qf7|bmy|qefo7jrqrqfk}G|su}|qfk}G|isumff}eGsfkr7xr@oe\x}+l


wSsu|qeg+xr@xfk|qfkr@hSCffG!uuG})

d)fkrq~hSS	CSox+C'xrfvvf7!o7|ivu#ffhsu}5fff	o7|isumff}


)

lGfk}mff|f	hS|qefp|qf	xhimxsu}|Ssu}G|qfk}G|isumff}#|qmf7f	o7j|qf

C

4kkx)x@-









lGfk}mff|qf	h|qefh|@x|qj+hmxy|qef1imxsu}|su}|fk}|isumff}

@SO

-

+wefk|qefkr

s|<sh]j|qj+vvut+f7vsufkfff	l|qmt'fffoeGsufkfff	lCj}+ffoeGsufkzxtGvufmffr<srrqf7vufkzx}G|	

4k	7 oeGsufkfffkfk}G|qn%o7mff}+lsu|isumff}+h i
fk}|So7mff}+lsu|isumff}+hSmxy)|qef{|qf	xmffg+fkr7x|qmffr

@G7blGfk}mff|f	h1|qe+|1|qefpy%ffo7|hx|ishW+f	hS|qef]ffoeGsfkfkn


hWsu]svxrivuwSsu|qe~rqf	hig'f	o7|b|mj}+ffoeGsufkzxtGsvs|i#x}+l

srrqf7vufkzx}+o7o7mff}+lsu|isumff}+hk

Yff]]'7ffOk |qfkrq]su}+x|qfknig

4

gClx|qfkn%hi|@|qf

@7kp_lGfk}m|qf	hSo7mff]j}Gsokx|isumff}~|qm|qef|qf	x|qm|qfkrq]sun



}+x|qf]himxsu}G|o7mff]su|qfk}|1|m


+lGjf|qm|qef{y%ffo7|Syq

%kCQqkkk' p@@lGfk}mff|f	hp|qef]jgl|isu}myb|qef]|qf	xh|@x|qf]mxy{wSsu|qe

|qef{yo7|Sy

4

gClx|qfkn%hi|@|qj+h @-

]lGfk}mff|qf	h]|qefjgClx|isu}Qmxy|ef|qf	xmffg'fkr@x|qmr


wSsu|qe:s|7ho7jrqrqfk}G|

hi|@x|qj+hmxyffoeGsufkfffkfk}G|	j}+ffoeGsufkzxtGsvs|i#mffr<srrqf7vufkzx}+o7ff

4~+'+x

Q+x	u-

sh|qef{su}+lsuffslGj+vbxfk}|1mrb|f	xf7f	o7j|isu}\mffg'fkr@x|qmr

<lGfk}mff|fp|qefffo7|isumff}+hmxy|qefmffg+fkr7x|qmffr

Csh{]|qf	hi|Smxyw1efk|qefkr1|efxfffk}G|

QkC57'

4ku

)sh|qf	hi|1mxyw1efk|qefkr{|qefxfffk}G|

Q+'+kqkkx)kqCC+'%
mffr1hijt|qf	x

z7	GOki












sh]|qf	xmrj+h|bm}fpsu}+lsuffslGj+v%

lGfk}m|qf	h1hif7vyq


<lGfk}m|qf	h1oe+x}fffs}|qefprqmxvufpg'fkriymrq\x}+o7fpokxg+xtGsvsu|my

xfk}|



 	  7Offqi

s}+lsuslGj+vmffg+fkr7x|qmffr


hif7vyq1~ff

uuu}CfflGfk}mff|qf	h|qeff7f	o7j|isumff}

myx}

thif7vyqxsufffk}#|efo7mff}|f7|1my_|qefo7jrrqfk}|<s}G|qfk}G|isumff}#eGsufkr@r@oqeG\

x}+l~wSsu|qe#g+r@xfk|qfkr7hCffGuuG})

!mffrf7g+mGhWsu|qmffrq5gjrg+mhif	h kf	o7j|qfknO|qf	nOmffg+fkr7x|qmffr@x}+lkf	o7j|qfknsu}+lsuffslGjzvnOmg+f	r7x|qmffr@
xrqflGf7+}f	l5hhifkg+r@x|qf]grqmo7f	lGjrqf	hkpW}5rqf	vsu|iffd1p
|iwSm+

	
	fiff

lGmf	h{}mff|pls)fkrqfk}|s|qft+fk|iwSfkfk}|qef

fi
"!#$%&'()

*&+#,-/.102+3$,4657398;:+<=74
>"5?
@A
BDCFE$GHBDIfiJBDK6L;IFMNOBQPRKSGUTVPDWYX2Z\[]Z_^`Z_afibc
Z\bedZfgffZ b
hi6j
a
c
f&kFlHmongprq6moksutv
wyx\kFk]x\k{zDmHn|
h}fw
v
df&n~s#w(2zkDkfizDmHkBDGUK$FD1CDT6LyL]GYL(BFOGo|
mo|Oz|
t
v
w;lHkFk]xOkfizDmHn|$hfc~|$kDq6h#qVmHn|
hf7w$v
f&kFlHmDq6nlHD|$ngh\mUYnh\mHkFh\mong|$hXt
#f&nk&WYQfifiVWRX_"Ze{\OjQfifiVWRX_"Z#{e\j7F{{VWRX_Z\F66\
e\Sjoj&|
a
Wq
jn~WFfiDWzonkF$kFpkFh\mUUzD|$h#\nmHn|$hlFWX7jQZfiojQ{YWYh#q
zonkF
qVnngm$HzD|
h\nmHn|
hlQWYXjFZ
Hj



QfiWHokFkF
q6hzDkDHzD|
h#Ongmon|
hlQWYXjFZ$HjHj

v
wynlnlmok]zFqVlHkkQHk;~Yq
zDm~ngl2~|
h#mo|lRqVmHnl~mHkmHkFopnh#qVmHn|
hrzD|
h#Ongmon|
hr|6~X2f2k
zFq6lokkFok~7nl|
hgq;mHHkfiqVmmH|XWlHkFk(x\kfizmHn|
h}fc{jnlq6hq6|
$|
l{f7w$v

a
nf&kFlHmongprq6moktv$wlokFk]lokfizDmong|$h}fw
v
nnf&n~w22z;o|
|
lHkY|$#kFDq6mo|
TVL]LyE\CDK{GHBDWmHkFopnh#qVmHkDDWYXjFZ\FZu[j&nmHn

Hn|
onmt
v
wyx\kFk]x\k{zDmHn|
h}(qVh#(fgc{w
v
nnnYfn~h|y|
mHkFn$kFong|$Hnm(|
kFDq6mH|$fiZngh#q6Dq6kF
@AVBDCQE$GUBIH#Vfi6EK6IRTDNBFPDK{GHT6PDW{T6LyL]E\CDKSGUBWmokFHpnghq6mHkDWYXjQZeQZ7[jFZfiBF FZuX^`Zafibc
Z
bedZfffiSjFt
nfq6mokDYlomRqVmHk(Wfi\9DF{{#W[jFZ{HjFt
fq6mokDYlomRqVmHlQWRX_ 

jFt

i
W#jn~efiDF{{FD{u#WujFZ{kFok[
a
nf
q6#qVmHko|
kDp|$hnmH|
onhzD|
hlomHDq6nh\mHlfitv
w(x\kQkxOkfizDmHn|$h#fdfw
v
nnf&n~\H|$gkYp|
hnmH|$Hnhz|
hlomHRqVnhem~q6nHk{lHzH;mH#qVmWYQfiWYhq
zonkF
q6ngnm$Uz|
h#\nmong|$hlFWXjFZ
{RjmHkFhq6mHkYlomRq6molFWDX  jQt

i
WYzQjn~HkfizkFn
k]zD|$pp(hnzQq6mHn|6hy|6~mHkQHpnh#qVmHkDDWYXjqVh#~Yq
zDm
a
n~WFfiDWzonkF$kFpkFh\mUUzD|$h#\nmHn|$hlFWX7jQZfioj



Q{YWYh#q
zonkF
qVnngm$HzD|
h\nmHn|
hlQWYXjFZ

HjQfiWHokFkF
q6hzDkDHzD|
h#Ongmon|
hlQWYXjFZ$HjHj
a
nfq6mokDYlomRqVmHk(Wfi\9DF{{#W[jFZ{HjFt
nnfq6mokDYlomRqVmHlQWRX_ 

jFt

i
i
Wjq6mokDYlomRqVmHk6Wfi\9DF{{#W[jFZ6{6WX7jojFt
v
w;kDkfizDmok`\|$pqVnghOYlo#kfiznzq
zmHn|
hlmo|]p|\n~]mokfiq6plHmDq6mok|V~[w
v

c
cfi

fi

  6
	o
ffofififfQ6#\VHff

{oOHFr
FD6H$






ffHQg{D#ffH{ 
 !"$#&%'($H*) $+-,.#&%'($HooF#6D6F
/0214357681:96814;2<=9?>:@A1B?;C68>2B +DE	GF'HI'JE JK6
$2 !"
 $#&%'($ H ) $#L%E($ o4MN
+ 2HQ#VR6F

O  /G0214356P1:96814;fi<Q9?>4@1B?;6P>fiB #&%'($ 	GF'HI'JE JK6 
V $H
o
W D
off HD6\PffX
R TS UHff RV\H6oo
4

Y&
 Z[]F\ $#L%E($ ouoF#6D6F

O  /G0214356P1:9P^`_Eafi^]bX^a25;ficd9?>:@A1B?;C68>2B fe 1c g 	GF'HIUJE 
V $H
o
W D
off HD6\PffX
R TS UHff RV\H6oo
4

 &

 &2



ih7j&k#mlnffHD6oVF\popj7h
V #6otDs $e2\HF\H$ ud	fv]wG
q &HFr
x &Zy6Z 4u 	fvw*zm(*E{|*}~*[ 

2$	d, 1@;fi^`B hjQ
S G
	 
ff $PHff QF6njh

/0214357681:96814;2<=9?>:@A1B?;C68>2B P 18@;fi^`B +D'H&fi	
 Qfiffo4YV`#
oY
2gS
hjn
 F#Vg7ff :O Vfi;gy\FRVeO fiDH$&oEd
 2Hff :Y V`$ #
o
Y 2 gD#fiffrffHfi(2ff#VRfiVFHQ
H
 F#Vg
V m# yH$4$
V 
o
H(
W D$Hff oR6\T\Y g$6H$12
ff gFfioff &o $o\r
V 6Hff fiD 
 #
o
Y 2 g(

 D$#\H
UffX*jh
 Foff &

/0214357681:96814;2<=9?>:@A1B?;C68>2B X >2<n@'c1:681:9f;2^`cK5B41 +D'HIfC	 FfiUHff 4 6` #$o
Y fi K6 
hjQS 
 Q#6
ff PHff Q* #$Hg
Y fi  D7
V Fo4 Y6 H&Hffr Pff# fi
ff \ fiH
oEdDjh


=hy
j Q#HDfiA Hy4 fi4 o4 Hfi2V& 
FRVH
Tjh
7
]
*D7fitQ'*`G
/0143576P149P^`_'afi^`b^afi5;2cd9*@A1B?;C68>2B $Hff Q4'HIfXJE7JU J
6

&Hff Dfi Hff  fi
ff V#O\Y # V#\HQeo


 i
 $ZXy6Z #p{|*}~' ZyVZ $Ezm(*E{|*}~*[ZyZ6'fifi[~(6H




ZUX}Z4
Z  O o$Y 
V Qe8U 
#\og$Fff   g 
ZX}Z:&
Z 
 #$Hg
Y fi H D$#\H
UFff $
 
Z S HoF
Y 6D4H D
#Ogo
Qff $  g H
g 
ZX}Z:

T
 6o4$off RVH(Z# Hff FF g 
X

fi'n*]E7Nn&

Tfir4$r?2P$


Efir4$r?2PfiEP'fi'fiP
 4X4rI72A$rEX:Kn:PrmUPfirnP4fir 
$K*rAP'4fiP7=   2P7E7PX

P4EP   
Q 
	fiffffff	fi4$  !#
 "$& %E  

i7 EmnP4firp'
 & 7
 *m*E ,*+ - .0/
( K )fi+

K$2
 14365#ffP

 
	fiffffff	fi47 5#8ff9P? $&fiEfir4$2`Er2K  
;
 : E2 4`fiTI?fi7=
 <X:P?
 >'4 &A @2P4fi]$'rfiUn =fiP'X4
Er2&47EP A BEfirPX2nDEfi4fimPP&rE2 7
 r&
 
	fiffffff	fi4 CDEFG
fi	8HAffIJr? $IfC'fiUP4fi`E7rfiK  
L
 K  : EfiPPK*E7PUfi47pr4$fiPPrPEfi'
 <X:PM
 >E4 & 


 Emr4Xr:A4P:$E`E2K'4fiP7 
NPO;O?QSR;TFU8VXWPYLZ#[]\MN_^

Za`cbdO;efiQgf_hFefiQSi

jlknm=opJq'r smutv smwolx mwoytz{Amwx]{Sms}|J~8|Jss}|J~6knmx mwoytzrnz||Jaj?a=rnt|Jz9x mwxzk zolpJtzysm
pJAx]mwoo
mzpssknmsrmAy|x mknmps|tzknqx mwoytz{AmwxzurnrAmAxz_MAjlknm=tv s}mwocpoF~lzkknm
ps|t
z}knqzMrnrSmAxzJpJtmF{Apomwx|mnmwyvnz|'|JAk zmtptyk zypsA|rAmtpJ|to|tDtmwpyzmlr s9pAo
6k zs}mknmopq'r smtv s}mwou{Sms|+~ptmx mwoyt
z}{Smwxzo7zq'r szGAmwxz8knm8|tqnknm'pyvApstv smwo=pJtm
mAy|nx mwxzg|pJtwnpJAxpJtmpwJpzspJ{ smpo?pJ| sznmMrnrSmAxzG
?lG * l $ FLa $u 

*M$ l       $?   ;

  BP4rn774firp47p&UfiP7D7fi
Kfi PfirTP?2P=474finD'4PE2
4fiP8E
P=r7p47EP2QPX2 7E4fir
 4lS
<TPX:P'
 >' 

Kfi
 aU P2PTP4fiP=47?finQ4 
;
$4  fi4PUnfir7p47EP;@
fiDrXfi '?2Pu4c 
;
$4  7n4rPP&rEfi='X
;
47p&UfiP7D7 fi'  n2PX7= U?2PX
B;;



fi0n; 

fifi? w7fi?w=fiwwJAa7w=fiw;fi=7
 fiufififi=4lSD





?lG=Ml?FLauM?ll'MM a 
afilafi0fi= lw?w

w+  fiwfilfifi?J;L8w;


	
ff



	




fi 

	

	







w;]M  ;M w 
w J7G F
 u7dw  fiwu4c9





=}fiD+
 





w;]a;7fiJfi M=7 ? Gw

=wfi

waaw;fi

fifi? w7fi?w=fiwwJAa7w=fiw;fi=7
 fiufififi=4lSD

!

?lG=MlG  l?a7Ma a====M ll=
afilfi77
 0wa 
w=Gfiw
wwM=w=fi D+ Jfiu lwfi=}7w
7G 

a;? w7fi?w=fiwwJnfi
w=7;7=fi
 fiufififi=4lS 


	

"  $#&%
(

+* 

)

ff

	

'


 #&% D7fifi,.-0/,

" afi77210354
=
 
 fi7GM7=wG;0w6'=}fi?
7986:;-0<.7
>=
A@ 	
+* 

?lG=Ml Mlln=uM?ll
fiGaM 0 lw=7w J7G=fiL fi=

fi

fiw 

a;? w7fi?w=fiwwJnfi
w=7;7=fi
 fiufififi=4lS

?
	
ff

)

	



CB 	 "  $ #$%=a


 fi7GM7=wG;0w6'=}filw;a 
7986:;-0<.7

 fi7GM7=
 wG;w=fiwLwaa&10354
 

fi;a ;=w=fiawJ fi=fiafi=7
 fiufififi=4lS

D

E

CF

G=

HLMll

?lG=MlG=uMM  L G u
afi?  Jaaw wG u0fiG wfifi
w7fiJfiaJwwJ
=7wA ?fifiw  




	

	 I@

	

? '



M LN

J'
)

GK L

fiOPRQSUTUV.WYX[Z\5]U^`_Z\aO?\5SUbQ2PUTUc
dfe
g h!j5kfkIlnmoqp!rsmto$smoflnmofsrmvuxwCy;z|{9sm}r~}lnmGgfh!r2s>mRAofsrm
i
g
 sRsln2lk&Rlnk0rkfsm5kfr~loIr2l!5lh!j5oIlfjrlkAoIrk?r
g
m5rrof5lkEl2lnk  ps>
A~Ir2lnk|rkIEsm5kIr~lCofr2l!5lhJj5oflIj5rRlnkofrkr
g
 sUhnAmm5ro
Rlnk0rkfkfr~l
 
$j5kfkIlnmoqp!rs>mo[smoflmtoIsrm9uxwyqz { s&j5mRhI5sln}A~>l5j5loIrEh!kIsofshnA~;kfr~>lAs~j5kIl
rA  sRs>mGRlnk0rkfsm5r
UnU;
CnUR[Ga`U[E255RCUi6nRnUna65ARUR|UJU>fI
6`RJ`R5qRA.U&G;5.U;|5[C50;5Gn[A
!AE0 |5;;0>E5;A[5UJUAn
A!|.|RA$AnY5
 |RAC2CC5Gn[U?  5UnAvU5
?UC6UCC`  AUC|5G&
5 qUUn&;A55IGR|!56v5Rnn6fC	5|Rff
2fi5

5qR[5!A25fi05!5Cffq!505
 RU  n$U[  nAn5
$55R  5!U|RAnJ nJU!5a6>|;5J"
R`6URU;iIiR|R!|R55RAUC&6;5C!UAC|5C;0
5Rn [!225E|92 C05;|5E5A 5U!U5An
A!|.`R;An
Anv65
 5UA[$#&;2&%.5('U5qU 5UR  5!)nvJ+*6R25!5[
I,!|Rff

fi;5|5$-U5|;.
A!;2592 05.0>;
 5UA[$#&;2/%.('5U5.U.5UA.$[6C510q?255A[326
 55RnR?5!4+ R|I5H+R|! En5J" 56na65AA9[[
nA[U65 7%q805RU:9R;5AI!5ff%;|A!|CUI|
<105A3=G`>%.n!A 55R?<I5RU 6G &56!5t5!nUvA.I@C!	
|R2ff
EfiG;505;5A5
A!25CBR>`CAD?EEA
<U!A5
F%.!ACG5UG#
nJ`tD6R|URUHR5!5 +AC5(05
`Jn!UUn9R|URU1IJIJI !5UA505 5CD?EAKB55LENM|$O P5R
nR55URQ745535J!!52n5!;5CR|URU+5 RvR5YAUfC	5|R
ff
EfiG25055R5
A!2592 |0>;S0UT6
GRn5AD`5$#&.U$<U!A5; AU5V<G$=G.5 $R|I5nUA5nA!|UUn5
n+55!UYGRJf65AA5!5A?fW!506ff
2;505;5$- 505 

E592 05;;0>5
!5U.5R  `656!U!U!nAYA
22G5YXA0[U PZR
[\[

fi]?^8_J`!a
bdc1e3fffghKikj;hAlnmkcoYpfhJqjRrs6ttu!vjwJeYxyxzoY{$ecoY|ff};~!xzoYfec	e!x;	Gc(ep8Go	|}"efjU z
 Uzyy  hYhut78j
bdc1e3fffghdikj.8jh.lqY}z!8c6hwdjjr	s6tt!v	jxzoYfec@}f1	ep8cfffj/wJe8hAj.j;hk@ec(3oYh
8j;hdlAeYxyxzo1Vhkj.rPL8fjyvh 	 U  Uz 8  /   z	U  h8j$sY3!8jJCPRc(6f(fh
woY{8cff}z!h8Cj
 ox;c(h8jj;hl@e!fff6fh?jArs6tt7vjmk8eYx;6!oY,	ee38eYx;6!};Go}zfff|(cff};{8p8|(6
3~};c(e8!|6j8!  ff3  h?rP!v	h7N3t773j
 o66fffe|(h8ikj;hiLc(eY.f|(eh8j;hl&bkhj8j?rstt!vjACp!x"|}oN3|k	eYxyxoN{ecoN|ff};e};};c(6	|16
}"8c(eY~}zf(oY|}"ej3ff	    ff.3  U  U      6ff  	  3yU  $V  U6 
 6R 1Nj
 }xyxhKj;h?wJ8h8jh?bdcoN|(h$8j;h?e3fff!{!x;e3eChVAj;h?lAoY{h?j?rs6tt7vj3|(	xyxy};!|oY!|fUec
|(8:f3!|(8|ff}z{oY|(|x"		xz?@o	eoY3WeYdc(e|	oYc(};8Go};c	co|6jff6		    ff@!
 6U6kVyz	U 8 ffU z  U6y  	6j
Y8!};83fhkjrs6ttY8vjwJe};|(!|foY	e3~3|ff};ef@|(8Uep88oY|}"eeY	e!ec};oY|ff};e};
p!x;|ff};oY3|df7fff|1fj+3+  y	6+    	6	  +66hKNj
Y8!};83fh+jkrs6tt7vjwJe!|(c(eNxxy};8	e!e$coY|ff};~,8c1e{!x;fffeYx;~};8};};!pfff|(cff}zoxp!x;|ff};oY!|
fff7f|(fLpf};8ffeY};!|};3|(!|ff};efj	U 6  Uzyy  	6h6Yj
moY};8Yo8h?bj!j;h8l/KoN{$h8Gj$rstt!vjAqe81}zox	eoYcff}zfffeUecLo}x;p8c(+e!};|(ec}"8oYc16	e~!
c(C}"p!x;|ff};oY!|fff|(|}"8!fjff6		    ff!U      6ff    U z
 Uzyy  hYj?r(q|(p!!|doY{f|(co	|v	j
m};83hj;h.7Pp88{$c(hkGjh..oYehj;hkqe8!{c($hd.jh.L}z!oYc?hbj;h.l,c(8c6h.j.r	s6tt!v	j
AxzoY886|(6oYo	|}"~};|ffj,wofff|(	xyUcoY1!}hwdj;hAl,c(8c6hL.jLrPJ8fjyvhJ	U 6RV6z
V  U A U3ff  U      Yj?q8c}"8c6hVj
m};|oY8eh  j;hf(o8o8h8Gjh7mkp8!};e!fff!}h?j;h8e78oh8j;h$l&df(ooh7j?rs6tt!vjAe{e8	p88c(e{e|
ecffxzG	p8}"!};|ff}zoY|}"~jff6		          (1  3	    UU      
  y 6j
m};|oY8eh  jhKAoY{hKj;hAq|1e8hKAj;h	x"e!fffehKj;he88o8h	j;hdf(o.o8hj;hKlf(o8ohGjAr	s6tt!v	j
8c1e{e8	p8fff!3|(8|}oN3|	f K1oxyx;8jff	    ff3  U6  U  8  
   6ff  	  U z 	 U6y         Nj
o};c?h.jJ.j;hLYe86fhjJj;hJl};	xzfffhdAjJjJr	s6ttY8v	jwJe!ec};oY|(6{$o~};eceN	e8p8|(c
8coY|(6WUec	6f };|oo};c(fffe!oYc6j ff	    ff3
 !     ff  	@  +
V3U
 .  6ffU	
 ff    
 3zffLffVff    UU  jR.cffxzoY!e
h 	x"ecff}z8o8fff|ff};|(p8|1
eckqY};p!xzoY|ff};e,oYco};!};8fih ff!};~cf};|ffeYwJ!|(cox 	x;ecff}z8o8j
?~6f p8h  j8j;hwJe8hAj?j;hl.p886fh8jr	s6tt!v	j.,o	|ff};8|(e|(8cjdff6		    ff
3+U       ff  	  	U 6  U6y  	6jC!x;eoYc(?hwoxy}(j;kkd8c(6f(fj
?e8(!{oYp8@hmj.jLrs6ttY8v
j     	zy 1ffU6 Vy 8 U63@  U  U    U	!6U!Pff
  	3  6jj j!|(86fP}fh  oYc(~YoYc
 ff!}"~cf};|ffj


fi!!"$#&%(')+*!,.-'/)01)+!23!!4

57698:<;!=?>@>A(B3C$5DC9A!EF=?>G>9=HAJI3C$50C.ALKMEF=N!OPHQSROPTL=?>@>@6AVULC$B3C$WX/Y+Z+[\C1]J^!_>.Oa`LOP8S69b+`!QcTLO+dS=Nfe+=`!=H?O/>9Q
6hgOa8S69b+`(iVjlk!`6@monp69`!erqp69=stCvuxw+y{z|~}?w+?}L|}pAL$WXa\A!!!Z+!C
v=s=?>@>AjC$W?XY+Y+\?CtJ}L| ?(z?+?|~{S&p}L|c|~p}LCFOPH<qPOPHNv`69qfiC$VH<=ddA$ROPT!HS6~Ne+=+A!5O+d<d{C
J69=`8<=?>ArEC.AKB=?6G^!=?69HO!A&ECWXY+Ya!\C

J|~?cw+?w+@|ca(zpazz}@a|}D+@wP?C

69`LN!:?H<=d85:/HO/sQ6@>@>A$>9k!=I16~Ne+=U+k!698A$LjC
JbP>@>~O+:fiAL5DC$W?XY+Y+\?CB
;!=3kLdS=dbPm_>~OP`Ld{C3?c| y|w+}cG|@+/}Ly?AL!{AL[+Z!C
IOa_!k!8ApULC9APKE3OPHHA+RFCI3CpWXYpY+\CpRbb+_L=HOa8S69q+=T=;LOqp69b+HJ69`bN!dO/mC+B=:;(CH<=_(C/<UBQSRI
QY+PQp!A
`LdS8S698<k!8=Fmob+HFd69k>~OP86hbp`xOP`LN78<HO/69`69`!eLALv`69q+=Hd698SnbPm
R=`8HO/>>9b+HS6~N!O!C
IOPbAVjC1ULC9A1$kL:O+dA1jC.A5fb+HS>9=n+AC9A
U+=?>9q+=d8<H<=?>A5DC9A1K5k!HHO/n+AC1WXY+Y+\CjFe+=`8<Qcb+HS69=`8<=N
OPH:;6h8=:?8<k!H<=Fmcb+HO/69H<Q:?b+TLOP8d69k>~OP8S69b+`(CB=:;(CLH<=_(C!B=:<;!`6~:O/>vb+8<=3!A!B
;!=3jFkLdS8<H?O/>@6.Oa`
jH<86Gfi:6~O/>J`8<=?>@>G69e+=`L:?=`LdS8S698<k!8=+C
I
=?6@>@>9n+AtlC
ULCFWX/Y+Y+[\C/G|/w@f+c|+}w+wp}LDfi/y|w+
p}C;(CC8;!=d6~dA3U:;!bba>bPm
Rb+_!k!8<=HFU:69=`L:?=+AJROPH`!=eP69=5f=?>@>hbp`xv`6hqp=Hd698Sn+C
I16~:;(A3RC9AVKUP6.N`!=H/AFRC
WXYpY+\CR(j3]1tiV;!=`OPe+=`8d:?bP>@>~OPTLbpHOP8<=fs
698<;_L=b+_>9=+C`
Sy??+|}az}c?}Lw+c|+}Lwp1+}S}y+}3c+}L++p
+/}L~
+/}L! aC
I
bd=`T>9bb+AJCpULC9A+(O/69HN$A+C+]C9AP=s
=?>@>A+jC9A!A+K5:/ROPHS>API3CWXY+YXP\CPj_!H=?>G6969`LOPHnOa`LO/>9nd6~dJbPm
8<;!=dSbOPHOPH?:<;698<=:?8<k!H=OpdVOFTLO+d6~dJmcb+HVe+=`!=HO>!6h`8<=?>@>@69e+=`L:?=+C3?c| y|w+}c@|Gp}Ly?A/(!W?XQ\A
+Z+Y/p+!C
U+=`(AULCWXYpY+[\CpSy??+|}aSzpfi|}fiPvP|~l+}F+w?ficw+c|+}1/+@c|+}wp}L3(?w+?}!
|~}+CJj=HS6~:OP`j3d<dSb!:6~OP8S69b+`mcb+H
jFH<8S6@fi:6~O/>`8=?>G>@69e+=`L:?=+AJ5=`>9brVOaH<fiARjC
UP6~N`!=HARC!W?XY+YP!\?CjF`OPH<8S6@fi:6~O/>Np6~d<:?bpk!HdS=v>.Oa`!e+kLOPe+=
mcb+H:?bP>@>~OPTb+HOP8S69q+=F`!=e+b+86.Oa8S69b+`(C$`
Sy??P
|~}P3Stz3w+c|+}Lw++}S/}Ly?3+}3c| y/|~wpL?}Lc@|Gp}yFcaC
U+698<;(AJC.AKRb+;!=`(AVJCVWXYpY+[\CBbPsOaHN!d3dS=rOP`8S6~:dFmcb+HOP`0OPe+=`8:?bpk!`6.:Oa8S69b+`>~OP`!epkLOPe+=
TLO+dS=N&b+`dS_==:<;O+:?8dCJ`S/y?p|~}PStzwpc|~+}w+Vp}S}y3+}3?c| y|w+}cG|.
+}y&~FF3c+C
U+b+`!=`TL=H<eA]C.AB16~N;LOPHN$A3C9A
=H<`!=H/A]C.AEv6h`!`n+AC.Ak!`!epTL=H<eLAF5DC9AKIOPbLA
jCW?XY+YP!\?C
J>~OP`!`!=N8=OPO+:?8S69qp698n+C1B(=:;(C!H<=_(CLp[!AjkLdS8HO/>@6~OP`jF
`LdS8S698<k!8=+C
U+8<b+`!=+A
JC9AKV=?>hbdSbLA5DC1WXY+Y+[\CB(bPsOPHN!d:?bP>@>~OPTLbpHOP8S69q+=OP`LNO+Nqp=Hd<OPHS6~O/>
>9=OPH<`69`!eLiO:O+dS=
dS8<kLNnf69`0H<bpTLb+8S6~:&dSb!::?=HC&`U+=`(AULCW]N$Ch\AFtpfi?|~}ffiPvP|~p}pw?ficw+c|+}!
/+@c|~+}fw+}L&(?w+?}L|}|}x@c|9Sw+/}LV/c/C
BJOPTL=+A5DCJWX/Y+Y+\CI
=:?k!Hd6hqp=OPep=`8tOP`LNOPe+=`8<Qce+H<b+k!_8<H?O+:<p69`!e69`O&H<=O/>9Qc8S69=Nn`LOP6.:=`!Q
q+69H<b+`!=`8CD`S/y?p|~}PSzf}c?}Lw+c|+}Lwp1+}S}yp}ux@c|9Sw+/}L/c
cu++C
BJOPTL=+A(5DCJWXY+Yp[\C3B(H?O+:<p69`!eNn`LOa6~:8<=OPO+:?86hqp698Sn+Ct`Sy??+|}atSz&3w+c|~p}Lw+1+}
//}Ly?t+}3?c| y|w+}cG|@+/}Ly?~FF3c+C



fi$!

JPL+LD++
	fiff<ff	<	L99+	ff!"ff#$<P&%'	($)*,+.-!/#0fi11fi243"56879/!:

;=< 1?>A@ ; 3=/5B@CEDF/5G:H1#-!15I01J/5LKJ- ; 3 M'03=@CNfi5 ; 1C=CO3P6415I01&Q"KK9KRNS+

JPL+!DL?+?)T9!8+F<aUVW,XYLa&"ffFZ![8p\4W	!fiEK']B^

]_CO3"12ZKR- ; 3 M.0#3"@CBNfi5 ; 1C=CO3P6415I01J`8L8	G

JPL+3D9Ja8I!(Rb

d
c 9Ja8!
  f
e 9Jg f

h .9(
c #	fi$
X ?!
a 9v
i 9Je'S 
 + ffJ
j L
k 9fl
kff%P(mgVpnJ)`PO+8+fiop4	W<	4ff!\+U`9&~8!D\4	!fiqKJN
rs@64@8tH3=5I/1 mu$
v ?8

JPL+!D9lwe'SpIjJkLpnedi'kxy8	ffzp		<#[!9+IXYLP&"ff38p

	ff(L#)*z+.-!/011fi23=56
7{/!: ;=< 1'Nfi5 ; 1-5I@ ; 3=/5I@4C8|}/43"5 ; DF/5G:H1#-!15I01F/45fKJ- ; 3 M'03=@C8Nfi5 ; 1C=CP3O61#5I01
QN|D{KRNS+

JPL+3D9kff%P(9g9Jl~e'+fjJkLFpnOX4PO+Ofiq	

`9Z~8X	8	YL%WW	ff	#d)`+.-!/011fi23=56
7A/: ;=< 1TF3 : ;=< D/5:1-!15B0fi1&/5DF/o]_ ; 1 15I1#-!@ ; 1fi2/4-017J@5B2Td1 < @3=/-!@C.1!]-1G7H1#5 ; @ ; 3=/
5 

"XL8	?9Jk+\+!	<tD99lv+TxF/+n


X O PU&
 8IX< P? ff!"ffz
%d89#	3&"`TXOL(ff(	<((ff"ff#.o<T('!&9I!	#O~8,9	P_ff~#
)*< OP+ I?ff z)*I!! +

bOPO~PU(D9'kYff8	!Fg.FlFff(p	Fg1+4,i$!ff!Xff"`[!4	<!"ff.
I?
Z!
[ 8p 

 \	!
 fi{ {)`,+.-!/011fi23=56
7d/!: ;=< 19KKKJNdm@C=C8d]/873"/5+.CO@5L1G^
0 ; 3"/5o+.-!/GCP1#?7A@5B2TN7fi71G7

fi

fiJournal of Artificial Intelligence Research 7 (1997) 283-317

Submitted 8/97; published 12/97

Bidirectional Heuristic Search Reconsidered
Hermann Kaindl
Gerhard Kainz

hermann.kaindl@siemens.at
gerhard.kainz@siemens.at


Siemens AG Osterreich,
PSE
Geusaugasse 17
A{1030 Vienna, Austria

Abstract

The assessment of bidirectional heuristic search has been incorrect since it was first
published more than a quarter of a century ago. For quite a long time, this search strategy
did not achieve the expected results, and there was a major misunderstanding about the
reasons behind it. Although there is still wide-spread belief that bidirectional heuristic
search is aicted by the problem of search frontiers passing each other, we demonstrate
that this conjecture is wrong. Based on this finding, we present both a new generic approach
to bidirectional heuristic search and a new approach to dynamically improving heuristic
values that is feasible in bidirectional search only. These approaches are put into perspective
with both the traditional and more recently proposed approaches in order to facilitate a
better overall understanding. Empirical results of experiments with our new approaches
show that bidirectional heuristic search can be performed very eciently and also with
limited memory. These results suggest that bidirectional heuristic search appears to be
better for solving certain dicult problems than corresponding unidirectional search. This
provides some evidence for the usefulness of a search strategy that was long neglected. In
summary, we show that bidirectional heuristic search is viable and consequently propose
that it be reconsidered.

1. Background and Introduction
When a problem is represented as a state space graph, solutions to such a problem are
paths from a given start node s to some goal/target node t. Finding such a solution can
be attempted by searching this graph. If the search is guided by heuristic information, it
is called a heuristic search. Most of the work on heuristic search for problem solving deals
with unidirectional approaches, that start from s heading towards some node t (see, e.g.,
Pearl, 1984).
When there is one goal node t explicitly given and the search operators are reversible,
bidirectional search is possible, which proceeds both in the forward direction from s to t and
in the backward direction from t to s (see, e.g., Nilsson, 1980). Strictly speaking, it is not
even required that operators have inverses. It is just necessary that for a given node n the
set of parent nodes pi can be determined for which there exist operators that lead from pi
to n. Searching backwards means generating parent nodes successively from the goal node t
(see, e.g., Russell & Norvig, 1995). In other words, backward search implements reasoning
about the operators in the backward direction.
As an illustrating example of a class of problems where bidirectional search can be
usefully applied, consider finding find a shortest path between two given places s and t
using a given map of some city. In case of one-way streets, bidirectional search implements
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiKaindl & Kainz

reasoning like the following: \in order to arrive at t, some one-way street leading towards
t may be used". In a slightly adapted problem class, the cost of driving some street may

be different, depending on the driving direction. A steep street to the top of a mountain
may serve as an example. Bidirectional search works also correctly in such a case: the
backward search implements reasoning in the backward direction but takes account of the
cost of driving in the forward direction. More formally, k1(m; n) = k2(n; m) is the cost of an
optimal path from m to n. k2 is used for notational convenience only.1 All the bidirectional
search algorithms dealt with in this paper work correctly under these conditions and do
not require that the operators are reversible or that the cost of a path is the same in either
direction.
Bidirectional search was shown to be more ecient than its unidirectional counterpart
when heuristic knowledge is unavailable, but the inverse result was originally found in
experiments for bidirectional heuristic search by Pohl (1971). Since this kind of search did
not work as expected, there was consensus about the conjecture that bidirectional heuristic
search is aicted by the problem of search frontiers passing each other without intersecting.
This situation was metaphorically compared by Pohl to missiles that pass each other, and
illustrated in a figure that was reprinted by Nilsson (1980, Fig. 2.11). Nilsson conjectured
that in such a case the bidirectional search may expand twice as many nodes as would a
unidirectional one.
While the original algorithm BHPA proposed by Pohl (1971) may actually show such
inecient performance, the missile metaphor is wrong and misleading. We demonstrate
that bidirectional heuristic search is actually not aicted by the problem of search frontiers
passing each other. The performance of BHPA is much worse than originally expected
because of two very different reasons:
1. BHPA's search frontiers typically go through each other.
2. The major effort is spent after the search frontiers have already met: for finding
better solutions than the one found at the first meeting of the search frontiers up to
an optimal one; and finally for proving that there is indeed no better solution possible.
The first reason is specific for BHPA and was incidentally resolved by some of the technical improvements introduced in the related algorithm BS* by Kwa (1989). The second
issue, however, is also the major obstacle for eciency of BS* and actually for any bidirectional search algorithm that performs heuristic front-to-end evaluations, i.e., evaluations
that estimate the minimal cost of some path from the evaluated node on the search front to
t. Note, that this is the kind of evaluations also performed by typical unidirectional search.
Because of the common belief in the missile metaphor, however, so-called wave-shaping
algorithms were developed by de Champeaux (1983), de Champeaux and Sint (1977), and
Politowski and Pohl (1984), with the idea to steer the search \wave-fronts" together. In
contrast to BHPA and BS*, these algorithms perform front-to-front evaluations, i.e., evaluations that estimate the minimal cost of some path from the evaluated node on one search
front to the nodes in the opposing front. In fact, these algorithms achieve large reductions
in the number of nodes searched compared to algorithms that perform front-to-end evaluations. However, they are either excessively computationally demanding, or they have no
1. The notation is explained in the Appendix.

284

fiBidirectional Heuristic Search Reconsidered

restriction on the solution quality. Still, where do these reductions in the number of nodes
searched using front-to-front evaluations come from? After all, the algorithms performing
front-to-end evaluations do not suffer from the problem of search frontiers passing each
other.
In order to answer this important question, let us shortly focus on a common property
of heuristic evaluation functions that estimate the minimal cost of some path by applying
heuristic knowledge to the static information encoded in the state information of the node
evaluated. Such static evaluation functions typically evaluate with some error, i.e., the
difference between the minimal cost of a path and its heuristic estimate is in most cases
greater than zero. An approach to improve the accuracy of a given static evaluation function
is to perform a search and to utilize its results. Since this involves dynamic changes, we call
it a dynamic evaluation function. Dynamic evaluations through bounded look-ahead search
were studied in various contexts by Kaindl and Scheucher (1992).
The static evaluation errors are typically smaller for paths with smaller cost, as also
observed by Pearl (1984). Front-to-front evaluations are therefore typically more accurate
than front-to-end evaluations. In addition, the costs of the paths from the nodes on the
opposing search frontier to t (or s, respectively) are known, and so the overall evaluations by
the front-to-front algorithms are much more accurate than front-to-end evaluations. Since
the former utilize the results of the search in the opposing direction, we may view this as an
approach to dynamically improving heuristic values from the static evaluation function. Due
to this asset, wave-shaping algorithms achieve large reductions in terms of nodes generated
since they perform front-to-front evaluations. However, they are quite expensive in terms
of running time (per node examined), which calls for finding an appropriate balance. In
fact, Dillenburg and Nelson (1994) as well as Manzini (1995) developed a more recent nontraditional approach to bidirectional search called perimeter search that achieves exactly
this.
We devised a new and computationally much cheaper approach to dynamic improvements that we call difference approach. It utilizes differences of known costs and their
heuristic estimates from a given evaluation function to improve other heuristic estimates
from this function. This difference approach can be applied in bidirectional heuristic search
algorithms that perform heuristic front-to-end evaluations. It is exemplified in two new
methods for dynamic improvements of heuristic evaluations during search.
We also devised a new approach to bidirectional heuristic search that performs heuristic
front-to-end evaluations, where these dynamic improvements of heuristic evaluations during
search can be embedded eciently and effectively. This approach is generic in the sense
that it encompasses a whole class of (non-traditional) bidirectional search algorithms. As
we show in this paper, it can be instantiated for the case of the availability of sucient
memory as well as for the case of limited memory.
Our results from experiments suggest that bidirectional heuristic search can improve
on unidirectional heuristic search with respect to both generated nodes and running time
(for certain problems of finding optimal solutions). Since the missile metaphor is wrong,
bidirectional heuristic search can do so using our approach without the very time-consuming
front-to-front evaluations. So, bidirectional heuristic search is viable and we propose that
it be reconsidered.
285

fiKaindl & Kainz

This paper is organized in the following manner. First, we discuss previous work and
present some new theoretical and empirical results on existing approaches to bidirectional
heuristic search. Then we describe our new generic approach to non-traditional bidirectional
search and two of its instantiations. Thereafter we propose a new approach to dynamically
improving heuristic values that is based on differences between known costs and heuristic
estimates. After the presentation of experimental results from applying these approaches,
we discuss them in the context of the various approaches to bidirectional heuristic search
that were previously proposed.

2. Previous Work

In order to make this paper self-contained, we sketch here the essentials of previous work
on heuristic search algorithms with a focus on bidirectional heuristic search, without going
into more detail than necessary to understand both our new results on this previous work
and our new approaches.

2.1 Unidirectional Heuristic Search Algorithms

Many unidirectional search algorithms have been presented, so it would be prohibitive to
review all of them here. Rather, we focus on those unidirectional algorithms that form the
basis of bidirectional search as discussed in this paper. First, we review the traditional
best-first search algorithm A* (Hart, Nilsson, & Raphael, 1968). Then, we shortly explain
the linear-space algorithm IDA* (iterative-deepening-A*) proposed by Korf (1985). Finally,
we review an algorithm called Trans (Reinefeld & Marsland, 1994) that implements a form
of enhanced iterative-deepening search.
A* maintains the set Open of so-called open nodes that have been generated but not
yet expanded, i.e., the frontier nodes. Much as any best-first search algorithm, it always
selects a node from Open with minimum estimated cost, one of those it considers \best".
This node is expanded and moved from Open to Closed. A* specifically estimates the
cost of some node n with an evaluation function of the form f (n) = g (n)+ h(n), where g (n)
is the (sum) cost of a path found from s to n, and h(n) is a heuristic estimate of the cost
of reaching a goal from n, i.e., the cost of an optimal path from s to some goal t. If h(n)
never overestimates this cost (it is said to be admissible) and if a solution exists, then A* is
guaranteed to return an optimal (minimum-cost) solution (it is also said to be admissible).
Under certain conditions, A* is optimal over admissible unidirectional heuristic search
algorithms using the same information, in the sense that it never expands more nodes than
any of these (Dechter & Pearl, 1985). We emphasize here that this optimality result of
A* only compares it with unidirectional competitors, so a bidirectional approach may well
improve on the performance of A*. The major limitation of A* is its memory requirement,
which is proportional to the number of nodes stored and therefore in most practical cases
exponential.
IDA* was designed to address this memory problem, while using the same heuristic
evaluation function f (n) as A*. IDA* performs iterations of depth-first searches. Consequently, it has linear-space requirements only. Although performing depth-first searches
iteratively deeper and deeper has been heavily used in computer chess programs in the
context of alpha-beta minimax search since the sixties and is still in use (see Kaindl, 1990),
286

fiBidirectional Heuristic Search Reconsidered

B1
k1(A,B1)

A

k1(A,B2) B2
h1(B2)

g1(A)

h1(B1)

k1(A,B3)
h1(A)

B3
s

h1(B3)

H1(A) = max( h1(A), min( k1(A,Bi) + h1(Bi) ) )

t

i

Figure 1: An illustration of the back-up idea.
the application of this approach in problem-solving searches marked a breakthrough for
solving more dicult problems. IDA*'s depth-first searches are guided by a threshold that
is initially set to the estimated cost of s; the threshold for each succeeding iteration is the
minimum f -value that exceeded the threshold on the previous iteration.
While IDA* shows its best performance on trees, one of its major problems is that in its
pure form it cannot deal with duplicate nodes in the sense of transpositions. A transposition
arises, when several paths lead to the same node, and such a search space is represented
by a directed acyclic graph (DAG). This disadvantage of IDA* relates to its advantage of
requiring only linear space.
Fortunately, most computers have more memory available than needed for IDA*. This
memory can be utilized for recognizing duplicate nodes in two ways, using a finite state machine (Taylor & Korf, 1993), or a transposition table implemented as a hash table (Reinefeld
& Marsland, 1994). Due to its more general applicability in a wider variety of domains, and
since our bidirectional algorithms partly make use of it, we focus on the latter technique.
The algorithm Trans proposed by Reinefeld and Marsland (1994) uses a transposition
table for IDA*. Since the size of such a table can be deliberately parameterized, this is an
approach to utilizing limited memory. Analogously to earlier applications of transposition
tables in computer chess programs, Trans utilizes its table actually for two purposes:

 for recognizing transpositions;
 for caching the best heuristic values acquired dynamically.
Since the latter use is more dicult to understand, we explain its underlying idea in
more depth. This back-up idea is illustrated in Fig. 1. When during the normal search the
nodes Bi are statically evaluated but not stored, these values can still be used by backing
them up to some node A that is stored | in the case of Trans in its transposition table. The
dynamic value of A is the minimum of the estimated costs of the best paths found through
the nodes Bi . Unless the static evaluator is consistent, it is useful to store the maximum
of the dynamic and the static value of a node. When such a cached node is re-searched,
an improved value can often be used instead of the value assigned directly by the static
evaluation function.
Apart from its use in Trans, this back-up idea is actually widely applied in many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC (Sen & Bagchi,
1989), RTA* (Korf, 1990), SMA* (Russell, 1992) and ITS (Ghosh, Mahanti, & Nau, 1994).
287

fiKaindl & Kainz

Its advantages are very little overhead and steady (though often modest) improvement with
increasing memory size. In addition, this idea also works when a goal condition instead of a
goal node is specified, i.e., it does not require that a goal node is explicitly given. However,
it is only applicable for re-searched and cached nodes, and we cannot see how it could make
sense in the context of traditional best-first search like A*.

2.2 The Traditional Approach to Bidirectional Heuristic Search
First, we look at the older approach to bidirectional heuristic search where forward and
backward searches alternate. We call this the traditional approach. It encompasses both
algorithms performing front-to-end and others performing front-to-front evaluations.
2.2.1 Front-to-end Evaluations

Since the first proposed algorithm on bidirectional heuristic search called BHPA (Pohl, 1971)
performed front-to-end evaluations, let us begin with this approach. It employs heuristic
evaluation functions hd (n) that estimate the cost of an optimal path from the evaluated
node n to t or s, respectively, depending on the search direction d. More precisely, h1 (n)
estimates the cost of an optimal path from n to t in the forward search, and h2 (n) from
s to n in the backward search. Note, that always an optimal path from s to t is to be
found (i.e., not from t to s) and therefore also the cost of such a path is estimated by the
evaluation function fd that uses hd as its heuristic component. From the viewpoint of the
backward search that targets node s, however, it may seem that the cost from its frontier to
s is estimated heuristically, while it is more precisely the cost from s to the frontier. This
issue matters when the cost of some path is not the same in either direction.
We can view a BHPA search essentially as two A*-type searches in opposite directions,
i.e., traditional best-first searches.2 These are performed quasi-simultaneously, i.e., on a
sequential machine one node is expanded after another, but the search direction is changed
(at least) from time to time. The decision for searching in the forward or backward direction
is made anew for each node expansion according to the cardinality criterion (Pohl, 1971):

if jOpen1j  jOpen2j then d 1 else d 2
Whenever the search frontiers meet at some node n, a solution is found. Its cost is
g1(n) + g2(n), i.e., the cost of the path found by the forward search from s to n, plus the
cost of the path found by the backward search from n to t. Even when the two parts of such
a solution of the forward and the backward search are optimal, however, the concatenated
solution path is not necessarily optimal. Therefore, such an algorithm requires a special
termination condition for guaranteeing optimal solutions. The termination condition of
2. More precisely, BHPA can be viewed to consist of two HPA searches (Pohl, 1970) in opposing directions.
As long as the heuristic function used is consistent and its values are weighted equally as the gd -values,
the only relevant difference is a check whether Open has become empty. For admissible but not consistent
heuristic functions, the option to move nodes back from Closed to Open is important, if a new better
gd -value is found. A heuristic function is consistent if hd (m)  hd (n) + kd (m; n) for all nodes m and n.
This implies that hd is admissible, i.e., the heuristic function never overestimates the real cost.

288

fiBidirectional Heuristic Search Reconsidered

BHPA is as follows:

Lmin  max[ min f1(x); min f2 (x)]
x2Open1

x2Open2

(1)

This condition essentially means that the cost Lmin of the best (least costly) complete
path from s to t found so far is not larger than an estimate computed from the fd -values
in both search frontiers. If the heuristic used for these estimates is admissible, this path
must already be an optimal solution in order to satisfy this termination condition. Since
understanding this condition is important for this paper, we elaborate it in more depth
below.
Implicitly this is also the condition for successful termination of the improved algorithm
BS* (Kwa, 1989), which removes all nodes n whose fd -values are  Lmin and terminates
when Open1 or Open2 is empty. This technique of removing nodes is called trimming in
BS*, and such newly generated nodes are not placed into the sets of open nodes at all,
which is called screening. While these techniques improve on BHPA \just" with respect to
saving memory, BS* additionally includes improvements that reduce the number of nodes
generated. These major improvements are the following:

 nipping: if a node is selected for expansion which is already in Closed in the opposite search tree, it can just be put into Closed in the current search tree without
expansion;
 pruning: in the same situation, descendants of this node in Open in the opposite
search tree can be removed.

Both BHPA and BS* are admissible if fd is consistent. However, BHPA's results were
clearly less ecient than those of A* for finding optimal solutions, and also BS* was never
shown to be really more ecient than A*.
Koll and Kaindl (1993) were the first to conjecture that the missile metaphor is misleading as an explanation and provided some (preliminary) evidence for this finding. Based on
it and realizing that fulfilling the termination condition (1) is a key issue, they developed
ecient "-admissible search algorithms, that typically find solutions with a known error
bound faster and generate fewer nodes than a corresponding derivative of A* that guarantees the same error bound. These algorithms provided, however, no improvements for
finding optimal solutions, and they require exponential space like BHPA, BS* and A*.
Based on the same approach, Kaindl and Khorsand (1994) showed that bidirectional
heuristic search using limited memory is possible through using a unidirectional search
algorithm that can cope with limited memory | SMA* (Russell, 1992). However, the
runtime eciency was insucient.
2.2.2 Front-to-front Evaluations

Since for a long time there was consensus about the belief that the search frontiers would
pass each other, research focused on algorithms that would force the \wavefronts" to meet
through \wave-shaping" techniques: BHFFA (de Champeaux & Sint, 1977), BHFFA2
(de Champeaux, 1983), d-node retargeting (Politowski & Pohl, 1984) and a generalized
algorithm (encompassing BHPA and BHFFA2) (Davis, Pollack, & Sudkamp, 1984). These
289

fiKaindl & Kainz

A
h(A,B1)

g1(A)
B1

h1(A)

k2(t,B1)
h(A,B2)

t
s

h(A,B3)

B2 k2(t,B2)
k2(t,B3)

H1(A) = max( h1(A), min( h(A,Bi) + k2(t,Bi) ) )
i

B3

Figure 2: An illustration of the front-to-front idea.
algorithms perform front-to-front evaluations and they show that bidirectional heuristic
search can be ecient in terms of the number of nodes generated.
Since the basic idea of front-to-front evaluations is important for understanding this
paper, we illustrate it using Fig. 2. When for the evaluation of some node A the nodes Bi
on the opposite search front are available in storage, the costs of optimal paths from A to
every Bi can be estimated. Adding these to known costs of paths from Bi to the goal node
t, normally more accurate dynamic estimates can be gained than from a static front-to-end
evaluator that directly estimates the cost from A to t.
However, the algorithms performing front-to-front evaluations are either excessively computationally demanding, or they have no restriction on the solution quality. They have to
compute heuristic estimates between all nodes in one search frontier and all nodes in the
other, in order to estimate all the paths going through all nodes in the opposite frontier
and vice versa. So, their effort for the evaluations needed for a single node selection and
expansion may even seem to be proportional to the cross product of the numbers of nodes
in both frontiers. Through the use of appropriate data structures, this effort can be reduced to become proportional to the number of descendants of the expanded node times
the size of the opposite search frontier.3 Still, this is excessively computationally demanding for frontiers that may contain in the order of millions of nodes. For keeping this effort
practical for non-trivial problems, such an algorithm may either restrict this computation
to a certain (small) number of nodes with promising values or keep the search direction
focused on a single target node of the opposing frontier for several steps before retargeting
it. Both approaches typically terminate with non-optimal solutions and therefore obviously
lose admissibility, i.e, the guarantee for finding optimal solutions.

2.3 The Non-traditional Approach to Bidirectional Heuristic Search

So, the traditional approaches did not succeed to improve on unidirectional search for
finding and guaranteeing optimal solutions. In particular, all these algorithms are based
on traditional best-first search that has exponential storage requirements. It may seem
that bidirectional search needs to store nodes of at least one frontier so that the search
from the opposing side can recognize meeting this frontier (typically implemented through
some hashing scheme). Instead of storing both frontiers for having forward and backward
searches alternate, it is possible to search in one direction first storing nodes, and then to
3. According to personal communication with Dennis de Champeaux.

290

fiBidirectional Heuristic Search Reconsidered

search in the other direction. We call this here the non-traditional approach to bidirectional
heuristic search.
Such an approach is the perimeter search (Dillenburg & Nelson, 1994; Manzini, 1995).
In perimeter search, a breadth-first search generates and stores all the nodes around t up to
a predetermined (and fixed) perimeter depth. The final frontier of this breadth-first search
is called perimeter. After this search is finished and the nodes are stored, a forward search
starts from s, targeting all of the perimeter nodes. Depending on the given problem and
the available storage, this forward search can be performed in an A* or IDA* fashion. The
former is implemented in PS* (Dillenburg & Nelson, 1994), and the latter both in IDPS*
(Dillenburg & Nelson, 1994) and in BIDA* (Manzini, 1995). For the same perimeter depth,
IDPS* and BIDA* search exactly the same nodes. However, BIDA* temporarily removes
from the perimeter the nodes that cannot affect the computation of its evaluation function
and consequently reduces the number of heuristic front-to-front evaluations compared to
IDPS*. Due to this improvement, BIDA* is far more ecient in terms of running time than
IDPS*.
BIDA* achieves very good results in the (sliding-tile) Fifteen Puzzle domain. We investigate below why this is the case in contrast to the traditional approaches to bidirectional
heuristic search. In particular, we show the results of experiments with varying perimeter
depth, i.e., varying perimeter size or storage use.

3. Some New Results on the Previous Approaches

Still, it seems that these previous approaches to bidirectional heuristic search are not understood properly. Therefore, we present some new results about them before we propose
our new approaches.

3.1 Theoretical Results

We present some new theoretical results on bounds on the number of nodes expanded by
traditional bidirectional heuristic search with front-to-end evaluations. Since its runtime
performance is proportional to the number of nodes expanded, these are bounds on the
potential eciency. We assume the availability of a consistent heuristic evaluation function
hd in both directions.
First we make explicit a principally known result in the form of a lemma, since we need
this particular result for proving the new results. In addition, understanding it is important
for understanding these results. Note, however, that this termination condition for bidirectional search is significantly different from termination conditions for unidirectional search
like A* as given by Pearl (1984).

Lemma 3.1 (a sucient condition for successful termination of BHPA or BS*):

If there is a solution path from s to t, BHPA or BS* terminate successfully (i.e., by
finding such a path) iff both the following conditions are satisfied:
(i) in at least one of the search frontiers d of BHPA or BS* the minimum f -value must
have been raised at least to the value of an optimal solution C  , that is, minx2Opend fd (x) 
C ; and
(ii) an optimal solution must have been found, that is, Lmin = C  .
291

fiKaindl & Kainz

Proof: We need not be concerned about whether these algorithms indeed find optimal

solutions, since the corresponding proofs were given by Pohl (1971) and Kwa (1989), respectively. We only focus here on how exactly the termination condition in Formula (1)
is fulfilled | for BHPA this is the explicit termination condition, for BS* it is implicit as
explained above. The minimum f -values of Opend are at first the values f1 (s) and f2 (t),
respectively. Since fd is consistent they do not exceed C  . The minimum f -values of Opend
increases only gradually until all the nodes with f -values < C  of at least one search frontier
are expanded (or nipped or pruned by BS*). Since the maximum of the minimum f -values
of Opend is used, only one but at least one of them must become  C . During the search,
Lmin  C  always holds, and when an optimal solution is found, Lmin = C .
2
In order to establish bounds on the number of node expansions, let us first focus on an
upper bound on the number of nodes expanded by BHPA.

Theorem 3.1 The number of node expansions of BHPA can be bounded from above by
#(BHPA) < #(A )1 + #(A)2

Proof: In the worst case, BHPA may have to perform its A*-type searches in both
directions completely, with the exception of at least one node expansion. Even when Lmin =
C  is achieved only in the last node expansion in one direction, immediately thereafter the
termination condition is fulfilled according to Lemma 1. Therefore, in the opposite direction
at least one node expansion can be saved.
2
In some sense, this bound may look quite weak, but actually Nilsson (1980) conjectured that a bidirectional heuristic search may expand twice as many nodes as would a
corresponding unidirectional one. This conjecture was based on the assumption originally
published by Pohl (1971) that the search frontiers may pass each other without intersecting.
More recently, however, some empirical evidence was found by Koll and Kaindl (1993)
that this assumption is invalid, i.e., the frontiers typically meet rather early even without
using wave-shaping techniques. So, the question may arise as to whether and under which
conditions the result of Theorem 3.1 is reasonable and useful. In order to show such conditions, we define a strong symmetry property of search spaces. Although this may seem
to be a completely unrealistic assumption, it is not too dicult to imagine a search space
with this property. Searches for optimal solutions to TSP (traveling salesman problem)
instances need to generate nodes that represent visiting all the neighboring cities of the
start city. Since this same city is also the final city to be visited, a reverse search in the
opposing direction needs to generate nodes for exactly the same cities, etc. So, at least a
straight-forward implementation of bidirectional search for the TSP works in a symmetric
space. For symmetric TSP instances (where the arc costs are the same independent of
the direction) and for usual heuristic evaluations functions for the TSP (like the minimum
spanning tree heuristic), it turns out to be a perfectly A*-symmetric search space.
Definition 3.1 Let f11 = h1(s); f12; : : :; f1k,1; f1k = C  be the different f -values of expanded

nodes in the forward direction and analogously f21 = h2 (t); f22; : : :; f2k,1; f2k = C  in the
backward direction. A search space is perfectly A*-symmetric iff A* expands the same
number of nodes for each f -value in the forward direction as in the backward direction, that
is, #j (A)1 = #j (A )2 for each j = 1 : : :k.
2
292

fiBidirectional Heuristic Search Reconsidered

Theorem 3.2 If the search space is perfectly A*-symmetric and the f -values are all distinct
in each direction, then

#(BHPA) = 2  #(A) ,  with 1    3

Proof: In a perfectly A*-symmetric search space, the numbers of nodes expanded in both
directions by the A*-type searches within BHPA is strictly the same up to the last but 2
f -values, because no termination is possible up to this point; and since these are all distinct
in each direction, this amounts to 2 nodes each for the remaining 2 f -values:
#(A )1 , 2 = #(A)2 , 2
Depending on when Lmin = C  is achieved, 1 up to 3 more nodes must be expanded to
fulfill the termination condition. Summing up proves the theorem.
2
Since in practice the f -values are normally not all distinct (in each direction), we show
the consequence of a more realistic assumption | the occurrence of many different f -values.
This is meant in the sense that the number of nodes with the same f -value is small compared
to the number of nodes expanded.

Corollary 3.1 If the search space is perfectly symmetric and there are many different f values, then

#(BHPA)  2  #(A)

Proof: Since there can be several nodes with the same f -value, the expansion of more
than 3 nodes may be saved when an optimal solution has already been found. Because the
number of nodes with the same f -value is small compared to the number of nodes expanded,
however,   #(BHPA).
2
So, under this strong assumption on symmetry BHPA expands close to twice as many
nodes as A*. How is it possible that this conjecture of Nilsson (1980) is supported although
its original assumption appears not to be valid?
The point is that the search frontiers of BHPA meet early, i.e., they do not pass each
other without intersecting, but they go through each other! So, there is a possibly large
region of the search space explored twice (as illustrated in Fig. 3).
BS* avoids such double exploration (see again Fig. 3). Unfortunately, it appears to be
dicult to quantify the size of this region. So, we cannot determine a tighter upper bound
on the number of nodes expanded by BS* without further assumptions.
Fig. 3 also illustrates that the search frontiers of BS* are typically \ragged". This
means that the meetings occur in the \middle" as well as near s or t (as observed in our
experiments).
Now let us have a look at lower bounds on the number of nodes expanded by BHPA.
We do not need the assumption on symmetry here but we can show more general results.
Theorem 3.3 The numbers of nodes expanded by BHPA can be bounded from below by
min(X1; X2) + 1  #(BHPA)
293

fiKaindl & Kainz

A*

t

s

BHPA

t

s

region of search space explored twice

BS*

t

s

nipping

pruning

Figure 3: An illustration of traditional bidirectional heuristic search with front-to-end evaluations.
where Xd = #d (A ) , #kd (A) is the number of nodes that A would expand in search
direction d minus the number of nodes with value fdk = C .
Proof: This lower bound represents the case of earliest termination according to Lemma
1. (At least 1 node is expanded in each direction.)
2
Corollary 3.2 If the f -values are all distinct in each direction, then the number of nodes
expanded by BHPA can be bounded from below by
min(#1 (A); #2(A))  #(BHPA)
Proof: Xd = #d (A) , 1 since there is only 1 node n with fd(n) = C .
2
Corollary 3.3 The maximal improvement of BHPA over A is given by
#(A) , min(X1; X2) , 1:
Proof: min(X1; X2) + 1 is the minimum number of nodes expanded by BHPA.
2
In essence, we have shown that under certain conditions traditional bidirectional heuristic search with front-to-end evaluations as exemplified by BHPA can expand close to twice
as many nodes as A*. While the original conjecture for such a result was based on an
apparently wrong assumption, we found that another | even more obvious | effect is
(partly) responsible.
In addition, we have shown that BHPA cannot be much more ecient than A* with
respect to node expansions even in the best case. For a variant of BS* without the pruning
technique, the same lower bound on the number of nodes expanded applies. In general, the
major problem of traditional bidirectional heuristic search with front-to-end evaluations is
the cost of satisfying the termination condition.
294

fiBidirectional Heuristic Search Reconsidered

3.2 Empirical Results

In order to provide evidence that the missile metaphor is misleading, we present some new
empirical data on the performance of BS*. Since perimeter search seems to become more
and more ecient with increasing perimeter depth (Manzini, 1995), we have investigated its
behavior through experiments in two different domains. We present new empirical results
from these experiments and provide some explanation why perimeter search works so well
in the Fifteen Puzzle domain.
3.2.1 BS*

BS* is a classical best-first search algorithm and requires exponential memory. So, we are
not aware of any BS* implementation yet that is able to solve dicult problem instances
of the Fifteen Puzzle, given no domain-specific knowledge about the puzzle other than the
Manhattan distance heuristic. In our experiments, BS* was able to solve 59 of the 100
instances used by Korf (1985), having available up to 256 Mbytes of main storage (on a
Convex C3220).
We gathered some data during these runs of BS* which provide empirical evidence that
the missile metaphor is misleading (in addition to the data already given by Koll and Kaindl
(1993)). In the average, BS* found the first solution after the generation of 7.2 percent of
the total number of nodes generated. The quality of this solution is on average just 6.3
percent worse than that of an optimal solution. After continuing its searches, BS* found
optimal solutions after the generation of 22.4 percent of the total number of nodes generated
(again on average). That is, most of the search effort of BS* was spent to verify optimality.
That means that the search frontiers of BS* meet relatively early without the use of
wave-shaping techniques, and even optimal solutions are found rather quickly. However,
even when BS* has already found an optimal solution to some problem instance, it does
not \know" that this solution is optimal. So, it must continue the search and generate the
remaining nodes in order to prove that there is in fact no better solution available.
Relatively to its overall higher effort, BHPA would find a first solution even \earlier"
than BS*. Of course, BHPA needs exactly the same number of nodes as BS* for having
its search frontiers meet. After this first meeting, however, it would have to generate more
nodes than BS* because its search frontiers go through each other. If the search frontiers
would, however, pass each other as illustrated by the missile metaphor, solutions could not
be found that early.
3.2.2 Perimeter Search

Perimeter search achieved very good results in the Fifteen Puzzle domain, where it can solve
any Fifteen Puzzle problem instance relatively fast and with limited memory. However, this
approach to bidirectional heuristic search also seems not to be understood suciently yet.
So, we made experiments with increasing perimeter depth in two different domains. The
results may seem to be quite surprising. While we cannot yet explain them theoretically,
they are important in their own right, and we try to explain them intuitively.
For these experiments, it was feasible to use the complete set of 100 Fifteen Puzzle
problem instances as used by Korf (1985). Fig. 4 shows that in this domain BIDA* works
very well, especially in terms of the number of nodes generated. The data are normalized
295

fiResults relative to Korfs IDA* in %

Kaindl & Kainz

50

Nodes generated

45

Running time

40

35.3

42.0

34.2

35

32.7

30.7

29.7

30

28.0

27.8

29.1

27.4

25
20
15
10
5

4.1

3.2

2.5

1.9

1.5

1.1

0.9

0.7

0.5

0.4

0
10

11

12

13

14

15

16

17

18

19

BIDA* Perimeter Depth

Figure 4: Comparison of BIDA* for different perimeter depths on the Fifteen Puzzle (100
instances) | time optimum.
to the respective search effort of IDA* (in Korf's implementation), since it was the first
algorithm able to solve random instances of the Fifteen Puzzle.4 Also the running times
are very good.5
Consistently with (Manzini, 1995, Table 1), Fig. 4 shows a steady decrease of both the
number of nodes generated and the required running time for increasing perimeter depth
until it reaches 16. At this perimeter depth, however, BIDA* achieves its minimum running
time. The exact perimeter depth where such an optimum occurs may depend on several
factors such as the machine used and the eciency of the implementation. The new and
important finding is, however, that such an optimum actually exists for BIDA*. While an
optimum perimeter depth was shown to exist for PS* by Dillenburg and Nelson (1994),
the data presented by Manzini (1995) suggested that for increasing perimeter depth the
number of evaluations performed by BIDA* even decreases. For larger perimeter depths,
however, the savings in terms of node generation are obviously outweighed by the larger cost
of the front-to-front evaluations. Note, that the data presented by Manzini (1995) did not
show this optimum because of the amount of memory required for storing the perimeter for
depths greater than 14 that exhausted the resources available for the experiments reported
there.
4. Just to give an idea of the overall diculty of the given problem set, note that IDA* generates some 363
million nodes on average, which needs slightly less than half an hour on a Convex C3220.
5. BIDA*'s result here is worse than the data reported by Manzini (1995). This is primarily due to the use
of a different machine and a different implementation that is based on the very ecient code of IDA* for
the puzzle provided to us by Korf that we are using. In such an implementation the overhead especially
of wave shaping shows up more clearly even when using the runtime optimizations described by Manzini
(1995). While we had no access to the implementation by Manzini, in E-mail communication with him
we were given some hints about it, and there was agreement about the overall effect on the relative
running times due to the different implementations of IDA*.

296

fiBidirectional Heuristic Search Reconsidered

Knowing about the existence of such an optimum helps us better understand the improvement of perimeter search over the traditional approach to bidirectional heuristic search
based on front-to-front evaluations as exemplified, e.g., by BHFFA. The advantage of improved evaluation accuracy is to be balanced with the large overhead in time consumption
for node evaluations. While BIDA* can be tuned towards this optimum, an algorithm like
BHFFA is typically out of balance in this regard. While BHFFA can for this reason only
find optimal solutions to quite easy problems, perimeter search is comparably much cheaper
per node searched, since a much smaller frontier is \targeted".
Although the performance of perimeter search cannot be improved deliberately through
using more and more memory, the optimum running time of BIDA* for the Fifteen Puzzle
problems is very good. So, we wanted to see whether and how such results can also be
achieved in another domain which we used for experimenting with our own algorithms.
We made experiments of finding optimal solutions to a set of maze problems.6 For these
problems, BIDA* based on IDA* is inecient due to the high number of iterations. So, we
used here PS* (Dillenburg & Nelson, 1994) which implements the common underlying idea
| perimeter search | based on A*. While A* works very well for such maze problems, it
seems that the runtime optimization of BIDA* cannot be practically used in an A*-based
algorithm due to excessive storage requirements, since for every node in Open information
about every perimeter node would have to be stored that may affect the computation of
the front-to-front evaluations. In fact, Manzini (1995) only states that his technique can be
applied to any depth-first search algorithm.
Based on these experiments, the perimeter search approach appears not to work satisfactorily as illustrated in Fig. 5 | neither in terms of generated nodes nor in terms of
running time. The data are normalized to the respective search effort of A*, since it seems
to be the most ecient algorithm for such problem instances that fit into memory (see also
the optimality result of A* over unidirectional competitors by Dechter & Pearl, 1985).7
Even for comparably larger perimeter depths (50, 100, : : : , 250), the numbers of generated
nodes only marginally improve (up to 93.9 percent of the number of nodes generated by A*
as shown in this figure), while the running time becomes quite high (up to 358.7 percent).
The running time can be reduced for perimeter depths smaller than 25, but for these no
real savings in the number of nodes generated and therefore no improvement over A* can
be observed.
When considering these very different performances of perimeter search in these domains, the question arises, why it works so well for the Fifteen Puzzle and why not satisfactorily for the maze. Let us consider a reason for the good results first, having a closer look
at the case of perimeter depth 1. This minimal perimeter around the node t in the Fifteen
6. Our use of this domain was inspired through its use by Rao et al. (1991). Problem instances in this
domain model the task of navigation in the presence of obstacles. 100 instances were drawn randomly
using the approach behind the Xwindows demo package Xmaze. As a heuristic evaluator, we use the
Manhattan distance like Rao et al. (1991).
For our experiments, we made the following adaptations. In order to allow transpositions, we do not
\install" a wall in three percent of the cases. This leads to roughly the same \density" of transpositions
as in the Fifteen Puzzle. Moreover, we use much larger mazes | 2000  2000, and in order to focus on
the more dicult instances of these, we only use instances with h1 (s)  2000.
7. Just to give an idea of the overall diculty of the given problem set, note that A* generates some 2.7
million nodes on average, which needs less than two minutes on a Convex C3220.

297

fiKaindl & Kainz

358.7
350

Nodes generated

Results relative to A* in %

303.0

Running time

300

244.0

250
185.1

200
150
100

139.0
119.8
99.3

98.7

97.4

96.2

95.0

93.9

50
0
25

50

100

150

200

250

PS* Perimeter Depth

Figure 5: Comparison of PS* for different perimeter depths on the maze problems (100
instances).
Puzzle just contains two nodes. Still, the perimeter approach saves about half of the node
generations of IDA*.
This major improvement can be explained quite simply when looking at an approach
to improving the heuristic evaluation function. Perimeter search \discovers" during the
search an analogous improvement of the Manhattan distance heuristic to that presented by
Korf and Taylor (1996, p. 1203) under the name \last moves heuristic" (more precisely the
part dealing exactly with the very last move).8 More precisely, in most cases the dynamic
values increase h1 (n) by two units, i.e., twice the (unit) cost of either of the arcs from the
two perimeter nodes.9 Through such improved evaluations, many node generations can be
saved even when using just very few perimeter nodes.
Still, the question remains why such improvements are not observed in the maze domain.
While in both domains the arcs have unit costs, we found some major differences that help us
explain this phenomenon. Fifteen Puzzle problems have relatively short (optimal) solutions,
and due to the unit costs of the arcs the overall cost of a solution is also relatively small (53.1
on average). In comparison, maze problems (in mazes of the size we used) have relatively
long (optimal) solutions and relatively high cost of such a solution (5262 on average). These
8. This heuristic is based on the last move of a solution, which must return the blank to its goal position.
In order to allow the blank to this position, those tiles next to the blank in the goal position must be in
certain places. If they are not then the Manhattan distance will not accommodate a corresponding path
and can therefore be increased by two units.
9. This also relates to a property of the Manhattan distance heuristic itself. In most cases, the increase of
the cost through the known arc (with cost 1) is added to an increase of the heuristic estimate from the
evaluated node to the perimeter node (also by 1) compared to the estimate to t. In the remaining cases,
the heuristic estimate from the evaluated node to the perimeter node reduces (by 1) compared to the
estimate to t, which cancels out the cost through the known arc.

298

fiBidirectional Heuristic Search Reconsidered

differences are also reected in differences of the heuristic values (although we used in both
domains more or less the same heuristic). For the given set of Fifteen Puzzle problem
instances, h1 (s) = 37:1 is on average much smaller than h1 (s) = 2361 for the given set of
problem instances in the maze domain. While we do not have data on the heuristic values in
the \Think-A-Dot" problems as used by Dillenburg and Nelson (1994), note that the mean
path length was given there as 18.4, i.e., even much smaller than for the Fifteen Puzzle.
Let us assume now that in both the Fifteen Puzzle and the maze domain with the
same number of perimeter nodes twice the cost of an arc (i.e., two units) can be added.
This means that the resulting dynamic evaluation improves on the static evaluation by the
same absolute amount, but by a quite different relative amount: 5.4 percent for the Fifteen
Puzzle compared to 0.08 percent in the maze domain. So, the dynamic improvement of the
heuristic is in effect much higher for the Fifteen Puzzle, which leads to much larger savings
in terms of node generations for the same effort through front-to-front evaluations.
In summary, for the Fifteen Puzzle just some few perimeter nodes improve the static
evaluation, since twice the (unit) costs of their arcs or even more is in most cases simply
added. This has a large effect in this domain where the heuristic values are typically smaller
than about 40. In the maze instances of the size we experimented with, the heuristic values
are two orders of magnitude larger, and therefore many more perimeter nodes would be
required to achieve much effect. These, however, make perimeter search very expensive
both in terms of running time and probably also in storage requirement.
From these considerations, it should be clear that the effect of front-to-front evaluations
is not so much steering the frontiers together, but rather to improve the heuristic evaluations
dynamically. In particular, the example of having just two perimeter nodes illustrates both
that \wave shaping" is not the real effect, but rather improvement of evaluation accuracy.

4. A Generic Approach to Non-Traditional Bidirectional Search
We developed a new generic approach to bidirectional heuristic search that integrates various
search algorithms and typically leads to hybrid combinations. Since this approach does not
allow for changing the search direction more than once, it can be viewed as a non-traditional
form of bidirectional search.
The major steps of our generic approach are:10
1. Assign a search direction and some or even nearly all of the available memory to the
traditional best-first search.
2. Perform traditional best-first search in the assigned direction using the given memory.
3. Unless the best-first search has already found an optimal solution, perform a search
in the reverse direction. Use the memory structure built up by the previous best-first
search, possibly together with additional memory that is still available, but compute
and use front-to-end evaluations.
It would not be too dicult to perceive an even more general approach that subsumes
perimeter search. Because of the expensive front-to-front evaluations, however, we wanted
10. This approach is different from the one that we proposed earlier (Kaindl, Kainz, Leeb, & Smetana, 1995).

299

fiKaindl & Kainz

transpositions

linear-space search

s

best-first search
t

Figure 6: A specialization of our generic approach.
to devise an approach that avoids the need to find a balance between the cost of such
evaluations and their beneficial effect.
A useful specialization of our generic approach that uses memory on both sides of the
search space is illustrated in Fig. 6. The traditional best-first search uses its assigned
memory as usual, e.g., in A*, and the linear-space search uses as much memory as still
available in a transposition table (Reinefeld & Marsland, 1994). The former first of all orders
the sequence of node generations and finds transpositions. The latter uses its memory for
finding transpositions in another part of the search space, and for caching more accurate
heuristic evaluations closer to t.
When limited memory is available, this approach is very exible. For instance, when
no memory for a transposition table is assigned, this approach combines linear-space search
with conventional best-first search in a bidirectional style. While this may look quite similar
to BIDA*, note that our approach in contrast performs front-to-end evaluations. The
memory of the best-first search is used to find solutions earlier by meeting its frontier
(rather than t).
When sucient memory is available even for solving the most dicult problem instances
in a domain, also the search in the reverse direction may be performed as a traditional bestfirst search like A*. After all, A* is under certain conditions and in a certain sense optimal
with respect to node expansions (Dechter & Pearl, 1985).

4.1 Instantiating for Limited Memory
First we show how our generic approach can be instantiated when only limited memory is
available. Of course, any such instantiation should make use of any available domain-specific
information. In particular, it should combine those unidirectional search algorithms that
best suit the properties of the domain (see, e.g., Rao et al., 1991; Zhang & Korf, 1993). For
example, in some domains IDA* is the choice, while in others depth-first branch-and-bound
(Lawler & Wood, 1966) is much better. In the case of limited memory, either of them is to
be preferred over A*.
Below we will present experimental results on the Fifteen Puzzle, a domain that is
characterized by having only few distinct cost values. Under this condition, it is reasonable
to select IDA* as a linear-space search algorithm, since dicult problem instances of the
Fifteen Puzzle require too much memory using A*, when only the Manhattan distance
heuristic is used. Since A* makes good use of consistent heuristics like this one (Dechter &
Pearl, 1985), we select it for the part of the best-first search.
300

fiBidirectional Heuristic Search Reconsidered

Based on the key idea of bidirectional search, we let A* and IDA* search in opposite
directions in steps 2 and 3 of our generic approach, respectively. This instantiation of our
generic approach leads to BAI (Bidirectional A* { IDA*).
Optionally, we may also give the IDA* search some part of the available memory as a
transposition table. Fig. 6 illustrates this instantiation. We call this variant of BAI due to
the use of this table BAI-Trans.
If A* cannot find a solution using the given memory, then IDA* searches in the reverse
direction towards the frontier of the prior search. Since we consider the case of finding
optimal solutions, this search cannot always terminate immediately after a solution is found.
A better solution may exist, and the algorithm must find an optimal one and subsequently
prove that it is optimal.
More technically, the IDA* part must be changed slightly. Instead of having to find
the goal node, a solution is found whenever the depth-first search meets the frontier of the
opposing A* search. If the cost of this solution is smaller than the cost of the best solution
found so far (or if it is the first solution found) then its value is stored. Of course, the cost of
the best solution found so far may be sub-optimal, or the algorithm does not yet know that
it is already optimal. However, if the stored value does not exceed the non-overestimating
threshold of the IDA* part, then its depth-first search is exited successfully with an optimal
solution.
In addition to these necessary changes, the IDA* part has the advantage to start with
an increased initial threshold based on an admissible estimate of the optimal solution cost
as determined by the A* part. Since we assume a consistent heuristic h, the minimum of
f = g + h for all nodes in Open is always an admissible estimate. Therefore, if this estimate
is higher than the usual initial threshold of IDA*, then it can be used here instead.
Moreover, it is not necessary to have the IDA* part search again in the space already
explored by A*. More technically, when the depth-first search invoked by IDA* meets a
closed node of the opposing A* search frontier, this branch can be cut off (meeting an open
node is in general insucient). We call this nipping according to the analogous method
described by Kwa (1989).
In an ecient implementation of the Fifteen Puzzle even the effort of hashing at every
node causes an overhead that cannot be ignored. Therefore, we implemented BAI in such
a way that it avoids hashing at those nodes where | based on the heuristic estimate | it
knows that the frontier of the opposing A* search is still out of reach.
According to step 1 of our generic approach, the search directions must be assigned to
the A* and the IDA* part, respectively. For traditional bidirectional search, Pohl (1971)
proposed and used a cardinality criterion for the problem of determining the frontier from
which to select a node for expansion: continue searching from the frontier with fewer open
nodes. While this is utilized for each node expansion in traditional bidirectional search
algorithms, BAI has to decide this issue once at the very beginning of the whole search.
When the search space is suciently symmetric, the initial search direction can be
determined at random. When the search space is at least slightly asymmetric and no
specific knowledge for determining the search direction is available, it seems reasonable to
make shallow probes into the search space from both sides and to use the idea behind the
cardinality criterion. Since BAI incorporates IDA*, using this algorithm also for probing
is consistent with the overall approach. For example in the Fifteen Puzzle, the first few
301

fiKaindl & Kainz

iterations of IDA* are searched from both sides, and the direction with fewer generated
nodes is assigned to the IDA* part of the overall search, since especially for dicult problems
it will have to search much deeper than the A* part.
Let us shortly discuss the behavior of BAI. In the best case, it would seem to be the
same as A*. In fact, BAI can even be better than pure A*. BAI assigns the search direction
dynamically, which can lead to better results than systematically going in one direction.
In the worst case, BAI has to perform the part of A*, without savings in the IDA* part
(except the effect of nipping).
A key question is how BAI saves effort without having enough memory available for
completing the A* search. Primarily, it can save one or more of IDA*'s iterations. Due
to the better initial threshold, some of the early iterations can be saved. Since the earlier
iterations are comparably cheap, this helps much less than saving the last iteration. The
search can also be terminated after a complete iteration of IDA* if the cost of the best
solution already found is not larger than the new increased threshold. Therefore, large
savings are possible when BAI terminates earlier than pure IDA*.

4.2 Instantiating for Sucient Memory
Now let us sketch how our generic approach can be instantiated for the case that sucient
memory is available in the sense that even for solving the most dicult problem instances
in a domain, traditional best-first search can terminate successfully with the given memory.
This case is of interest in order to see whether bidirectional search can be better than A*,
which is in some sense optimal over unidirectional algorithms.
When sucient memory is available, instead of IDA* (or depth-first branch-and-bound)
the reverse search can employ A*. In fact, it is easy to construct such an algorithm analogously to BAI as described above, just by using A* instead of IDA*. This instantiation
of our generic approach leads to BAA (Bidirectional A* { A*). This algorithm changes
the search direction only once in contrast to BS*. For a better utilization of our approach
to dynamically improving heuristic values based on differences, we will introduce a slight
variation of this algorithm below.

5. An Approach to Dynamically Improving Heuristic Values based on
Differences
Our new approach to dynamic improvements of heuristic evaluations during search is based
on differences between known costs and heuristic estimates. Such differences are utilized
by two concrete methods as presented below. The basic idea common to these methods
is that for many nodes during the search, the actual cost of a path to or from them is
already known. Since the static heuristic values can normally be gained rather cheaply, the
differences can be computed that signify the error made in their evaluation compared to the
cost of the known path. These differences are utilized to improve other heuristic estimates
during the same search.
In order to be able to compute such differences, the search must be bidirectional. We
focus here on the context of our non-traditional approach to bidirectional heuristic search
described above. Actually, application is also possible in the context of traditional bidirec302

fiBidirectional Heuristic Search Reconsidered

A
B1
h1(A)

g1(A)

Search
frontier

s

g2*(B1)

Diff1*(B1)
h1(B1)

t
B2 Diff1*(B2)

Diff1*(Bi) = g2*(Bi) - h1(Bi)

Diff1*(B3)

Mindiff1 = min( Diff1*(Bi) )

B3

i

H1(A) = h1(A) + Mindiff1

Figure 7: An illustration of the Add idea.
tional search like BS*. This involves, however, intricacies that are beyond the scope of this
paper. So, the interested reader is referred to (Kainz, 1996).

5.1 The Add Method

The first method instantiates this approach by adding a constant derived from such differences to the heuristic values of the static evaluation function. Therefore, we call it the Add
method.
Note, that adding a constant to all evaluations does not change the order of node
expansions in a unidirectional search algorithm like A*. So, the benefit from this approach
may not be immediately obvious. However, in bidirectional search algorithms using frontto-end evaluations, estimates are compared to the cost of the best solution found so far
(which is not necessarily already an optimal one), and having better estimates available for
such comparisons improves the eciency due to earlier termination. We explain in more
detail below how we apply this approach in the context of our non-traditional approach to
bidirectional heuristic search.
See Fig. 7 for the key idea of this method. We assume consistency of the static heuristic
evaluator hd . Around the goal node t, a search has examined a part of the graph and stored
all the optimal paths from nodes Bi on its closed fringe to t. For each node Bi , its heuristic
value h1 (Bi ) is computed and subtracted from the optimal path cost g2(Bi ) = g2(Bi ) =
h1 (Bi ), resulting in Diff1 (Bi ). This is actually the error made by the heuristic evaluation
of node Bi . The minimum of Diff1(Bi ) for all nodes Bi on the fringe is computed | we
call it Mindiff1 .
The point of the Add method is that any consistent heuristic value h1 (A) for some
node A outside this stored graph underestimates h1 (A) by at least Mindiff1 . We prove this
precisely below, but first we need to show a result about Diff1.

Lemma 5.1 If the heuristic h1 is consistent, then on any optimal path from some node n
to t with an intermediary node m

Diff1(m)  Diff1(n)
holds, i.e., Diff1 can only decrease on an optimal path with decreasing distance to the goal
node t.
303

fiKaindl & Kainz

Proof: If the heuristic h1 is consistent, then we have
h1 (n)  h1 (m) + k1 (n; m)
From this we simply obtain

g2(m) , h1 (m)  g2(m) + k1(n; m) , h1 (n)
Since n and m are on one optimal path to t, we know that

g2(n) = g2(m) + k1 (n; m)
After substitutions we obtain

g2(m) , h1 (m)  g2(n) , h1 (n)
and equivalently
Diff1(m)  Diff1(n)

2

which proves the lemma.

Theorem 5.1 If the heuristic h1 is consistent, then it is possible to compute an admissible

heuristic H1 for some node A outside the search frontier around t by

H1(A) = h1(A) + Mindiff1  h1 (A)

Proof: When some path exists from node A to t, also an optimal path must exist, and
let it go through the frontier node Bj . (If no such path exists, h1 (A) is infinite and the
theorem holds.) From Lemma 1 and the definition of Mindiff1 we know that
Mindiff1  Diff1(Bj )  Diff1 (A)

Since Diff1 is the error made by the heuristic h1 , we can write

h1 (A) + Diff1(A) = h1 (A)
After substitution we obtain

h1(A) + Mindiff1  h1 (A)

2

which proves the theorem.

Corollary 5.1 H1(A) is also an admissible estimate if A is a frontier node.
Proof: We can replace A by Bj in the proof of Theorem 3.1 without changing its validity.
2

304

fiBidirectional Heuristic Search Reconsidered

Theorem 5.2 If the heuristic h1 is consistent, then H1 is consistent.
Proof: If the heuristic h1 is consistent, then we have
h1 (n)  h1 (m) + k1 (n; m)
Adding the constant Mindiff1 on both sides leads to

h1 (n) + Mindiff1  h1 (m) + Mindiff1 + k1(n; m)
This means that

H1(n)  H1(m) + k1(n; m)
which proves the theorem.
2
Now let us sketch how this Add method can be utilized in the context of our nontraditional approach to bidirectional heuristic search. When using it in BAA, for example,
the first A* search must be used to compute some value Mindiff1 (we assume that it starts
from node t). Optimal paths to all nodes within the search frontier are guaranteed but not
to all frontier nodes themselves. If a suboptimal path was found to some frontier node,
however, it is known that an optimal path leads through another frontier node with an
optimal path to t. So, this does not change fmin, since the costs of suboptimal paths
cannot inuence the minimum. Mindiff1 is during the reverse A* search just a constant to
be added to h1 . We call the resulting algorithm Add-BAA.
Of course, a larger value of Mindiff1 is to be preferred for a given amount of search.
So, the search starting around t should be better guided by expanding always one of those
nodes n with minimal Diff1 (n). We call this variant here Add-BDA.11
It is also necessary to check, whether a node to be evaluated is outside or on the fringe of
the graph around t. This is simply achieved in Add-BAA and Add-BDA through hashing,
which is to be done anyway. When a node on the fringe of the first A* search is matched, a
solution is already found, and when the first node of a path inside the stored graph around
t is matched, this path need not be pursued any further, since its optimal continuation is
already known. So, only the evaluator H1 is actually used, which is consistent, and therefore
A* does not have to re-open nodes (Pearl, 1984). The search terminates when it selects
some node n for expansion with f1 (n) = g1 (n) + H1 (n) not being smaller than the cost of
the best solution found so far, which is proven this way to be an optimal one.
For more details on this method and its theoretical properties we refer the interested
reader to (Kainz, 1994).

5.2 The Max Method

The second method computes its own estimate based on such differences and uses the
maximum of this and the static estimate. Therefore, we call it the Max method.
See Fig. 8 for the key idea of this method. We assume consistency of the static heuristic
evaluator hd , and that a path from s to A with cost g1(A) is known. So we know for its
evaluation of node A: h2 (A)  g1(A). The difference is Diff2 (A) = g1 (A) , h2 (A). We
use this difference for the construction of an admissible estimate F1 (A) of the cost of an
11. Earlier we called it Add-A* (Kainz & Kaindl, 1996).

305

fiKaindl & Kainz

A

k1(A,B1)

g1(A)
h1(A)

Diff2(A)
h2(A)

B1

h2(B1)

g*
2(B1)

h2(B2)

s

h2(B3)

Diff2(A) = g1(A) - h2(A)
fmin2 = min( g*2 (Bi) + h2(Bi) )

*
B2 g2(B2)

t
g*2(B3)

B3

i

H1(A) = max( h1(A), fmin2 - h2(A) )
F1(A) = max( f1(A), fmin2 + Diff2(A) )

Figure 8: An illustration of the Max idea.
optimal path from s to t that is constrained to go through A. Note, that g1(A) = g1(A) is
not necessary, so we call the difference used here Diff2(A) instead of Diff2 (A).
In addition, we assume that a search has been performed from t in the reverse direction.
From this search, we assume that from all nodes Bi on its closed fringe optimal paths to t
are known, with cost g2(Bi ). Therefore, it is possible to compute
fmin2 = min
(g (B ) + h2 (Bi ))
i 2 i

Based on these assumptions, we can again construct a dynamic evaluation function as
follows.
Theorem 5.3 If the heuristic h1 is consistent, then it is possible to compute an admissible
heuristic h01 for some node A outside the search frontier around t by
h01(A) = fmin2 , h2(A)  h1 (A)
Proof: Every path from A to t must go through some frontier node Bj . The cost Cj of
any such path is bounded from below as follows:
Cj  k1(A; Bj ) + g2(Bj )
If h1 is consistent, it is possible to estimate the optimal cost of a path between two nodes
through
k1(A; Bj )  h2 (Bj ) , h2 (A)
Therefore, we can write
Cj  h2(Bj ) , h2 (A) + g2(Bj )
Since fmin2 = min
(g (B ) + h2 (Bi )), we can also write
i 2 i

Cj  fmin2 , h2 (A)
This is valid for the cost of any path from A to t including an optimal one, and so we can

conclude

which proves the theorem.

h1(A)  fmin2 , h2 (A)
306

2

fiBidirectional Heuristic Search Reconsidered

Corollary 5.2 h01(A) is also an admissible estimate if A is a frontier node.
Proof: We can replace A by Bj in the proof of Theorem 3.3 without changing its validity.
2

This dynamic evaluation function is not necessarily better for all nodes than the static
function, and so it is useful to combine these functions:

H1(A) = max(h1(A); fmin2 , h2 (A))
Since both are admissible the resulting function is also admissible. When the value fmin2
changes during the search, however, H1 is not consistent.
Since in the formula for computing H1 the originally derived difference Diff2 (A) =
g1(A) , h2 (A) is not included, we also derive here the overall evaluation function

F1 (A) = max(f1(A); fmin2 + Diff2 (A))
Now let us sketch how this Max method can be utilized in the context of our nontraditional approach to bidirectional heuristic search. When using it in BAI, for example,
the A* search starting first must be used to compute some value fmin2 (we assume that
it starts from node t). Again, like in the Add method, it is not necessary that optimal
paths from t to all frontier nodes are known. For getting values fmin2 that are as large as
possible for a given amount of search, the usual strategy of selecting a node with minimal
f2 is appropriate here.
The subsequent IDA* search within BAI must perform hashing in the graph stored
around t in order to check, whether a node to be evaluated is outside or on the fringe of the
graph around t. In the latter case a new solution is found. We call the resulting algorithm
Max-BAI. When a transposition table (Reinefeld & Marsland, 1994) is used in addition as
in BAI-Trans, we call it Max-BAI-Trans.
Most interestingly, IDA* can also utilize the Max method without additional storage
requirements. Let us sketch the basic approach for such a linear-space application of this
method here. While IDA* normally searches in one direction only, we let it alternate the
search direction after each iteration until a solution is found. Actually, this procedure is
outside our generic approach to bidirectional search as presented above. But we include it
here since a linear-space approach is of special interest. fmini is computed in one iteration
to be used in the subsequent iteration, which must search in the alternate direction so that
it can use this value. For example, in an iteration searching from t to s, the adapted IDA*
computes hmax1 = max(h1 (Bi )) for all nodes Bi . This value is used as an estimate in
the subsequent iteration for checking, whether a node A to be evaluated is \outside": if
h1 (A) > hmax1 is true, then node A cannot be \inside" and H1(A) can be safely used. This
check substitutes hashing in a stored graph. Since the static heuristic function normally
underestimates, however, for some nodes the heuristic H1 is not used although it would
theoretically be correct to use it. We call the resulting algorithm that is based on this idea
Max-IDA*.
For more details on this method and its theoretical properties we refer the interested
reader to (Kainz, 1996).
307

fiKaindl & Kainz

Results relative to Korf's IDA* in %

100.0 100.0

Nodes generated

100

Running time
76.1

80

67.1

66.7 66.7
54.4

60

50.8

40

30.1

27.6

27.4

24.5
15.4

13.9

20

4.3

0.9
0
MaxIDA*

IDA*

IDA*Probing

IDPS*
Depth=2

Trans

BIDA*
Depth=16

BAITrans

Max-BAITrans

Figure 9: Comparison on the Fifteen Puzzle (100 instances).

6. Results of Experiments with these New Approaches

In order to provide some empirical evidence for the effectiveness and the eciency of our
new approaches, we made experiments in two different domains: Fifteen Puzzle and mazes.

6.1 Fifteen Puzzle

First let us have a look on specific experimental results for finding optimal solutions to a
set of Fifteen Puzzle problems, once again the complete set of 100 instances used by Korf
(1985). We compare algorithms that achieve the previously best results in this domain with
our new algorithms. All the compared algorithms use no domain-specific knowledge about
the puzzle other than the Manhattan distance heuristic.12 The main storage available on
the Convex C3220 used was up to 256 Mbytes.
Fig. 9 shows a comparison of several algorithms in terms of the average number of node
generations and their running times. The data are normalized to the respective search
effort of IDA* (in Korf's implementation). As already noted above, IDA* needs on average
slightly less than half an hour on the machine that we used to find an optimal solution to
one problem instance. So, even slight improvements mean notable savings in time.
IDA*, Max-IDA* and IDA*-Probing are linear-space algorithms that use no additional
storage, and so their performance cannot compete with the algorithms that use up to 256
Mbytes. Max-IDA* generates only 54.4 percent of the number of nodes generated by IDA*
due to its dynamic improvements of the heuristic evaluations according to our difference
approach. Since these, however, imply some overhead per node searched, it needs 76.1
percent of IDA*'s running time. IDA*-Probing is a variant of IDA* that just uses our
probing idea for selecting the search direction. Although the search space of the sliding-tile
puzzle appears to be quite symmetric, it is interesting to see how much can be gained here
just by selecting the search direction dynamically. Since IDA*-Probing has no overhead in
running time, it is even faster than Max-IDA*. In order to see how well probing via three
iterations already indicates the better search direction, we compared its result with that
12. With much improved heuristic functions, much more ecient searches result (Culberson & Schaeffer,
1996) and even solving Twenty-Four Puzzle instances has become feasible (Korf & Taylor, 1996).

308

fiBidirectional Heuristic Search Reconsidered

of a perfect oracle. Using it would still generate 64 percent of IDA*'s nodes, i.e., IDA*Probing with an overhead in generated nodes for determining the search direction of only
less than 0.1 percent is overall just 3 percent worse than this. Systematically searching in
the backward direction, however, is not significantly better than systematically searching
in the forward direction due to high standard deviations, although it saves 17 percent.
IDPS* uses just some few nodes of additional storage for its perimeter. Due to the
related overhead of the front-to-front evaluations, it needs about the same running time as
IDA*-Probing, although it generates much fewer nodes.13
Trans (using 256 Mbytes of memory) achieves savings of about half of the running time
compared to IDA*. It saves even much more node generations with this amount of memory,
but the effort for hashing slows it down.14
Another technique to prune duplicate nodes was proposed by Taylor and Korf (1993),
using a finite state machine. Its results are not included in Fig. 9, since we lack data on
the running time (no such data are given by Taylor and Korf (1993), and we did not reimplement this technique). IDA* employing this pruning technique generated 100.7 million
nodes on the same set of instances as reported by Taylor and Korf (1993), which means
27.7 percent of the number of nodes generated by pure IDA*. The finite state machine that
achieved this result contained 55,441 states, requiring only a modest amount of storage.
Of course, the finite state machine must be built in a pre-processing stage first. But its
use during the search involves only a small and constant overhead in running time. So,
for the sliding-tile puzzles, this approach seems to be better than transposition tables for
eliminating duplicates. It actually appears to represent the most successful approach yet
to solving Fifteen Puzzle problems using unidirectional search.
In principle, we have provided all the available storage to BIDA* (Manzini, 1995), the
most ecient algorithm of the perimeter approach. In the given 256 Mbytes of storage,
BIDA* can store a maximum of 1 million perimeter nodes. This would correspond to a
perimeter depth of 19, where BIDA* generates just 0.4 percent of the number of nodes
generated by IDA*, but needs 42 percent of IDA*'s running time. So, as shown in Fig.
4 above it can use more memory for further savings in the number of nodes generated,
but it has an optimum in running time for a smaller perimeter size (16), that we show in
Fig. 9. Also with the reduced perimeter, BIDA* achieves the best result in terms of nodes
13. The results reported by Dillenburg and Nelson (1994) are based on runs using a different sample set of
the Fifteen Puzzle, and a different perimeter depth. Using the same perimeter depth (4), the results on
Korf's set with our re-implementation are even better in terms of the number of node generations, but
very much slower in terms of running time (even slower than IDA*). In personal communication with
John Dillenburg it turned out that their implementation of IDA* is slower than Korf's one (which we are
using) by a factor of about 60 per generated node. In such an implementation the overhead especially
of wave shaping does not show up that clearly as it does in an ecient one. Since smaller perimeter
depth means fewer stored nodes and therefore less overhead through wave shaping, the perimeter depth
2 results in better running time, and consequently we show these data in our figure.
14. The data in the figure were gained using a re-implementation of Trans based on ecient code provided
by Jonathan Shaeffer. Note the different way of presenting the results: absolute data in our figure vs.
relative to problem diculty by Reinefeld and Marsland (1994). We had to re-implement Trans, since no
data about the performance of Trans with the amount of memory that we used were available, and since
we integrate this technique into some of our algorithms. Actually, Trans+Move is the best algorithm
described by Reinefeld and Marsland (1994), but its absolute results are less than one percent better
than those of Trans. Therefore, we did not re-implement Trans+Move and cannot include it into the
figure.

309

fiKaindl & Kainz

generated | just 0.9 percent of the number of nodes generated by IDA*. While BIDA*'s
overhead for computing front-to-front evaluations is smaller than that of IDPS*, BIDA*
needs 27.4 percent of IDA*'s running time.15
Our algorithms BAI-Trans and Max-BAI-Trans can store a maximum of 5 million nodes
in our implementation of these algorithms in the given 256 Mbytes of storage. BAI-Trans
generates clearly more nodes (13.9 percent of IDA*) than BIDA*, but since its overhead
per node is much smaller, its running time is even slightly better (24.5 percent). Max-BAITrans | additionally utilizing our new difference approach | achieves the fastest searches,
needing just 15.4 percent of the time needed by IDA*. For achieving this result, it uses
4 million nodes for the Max method (and BAI) and 1 million nodes for Trans. In order
to see the inuence of Trans, we compare this result with that of Max-BAI (not shown in
Fig. 9 in order not to clutter it) that uses just the 4 million nodes for the Max method
(and BAI). Needing 19.2 percent of the time used by IDA*, it is just slightly slower than
Max-BAI-Trans, which shows the comparably modest inuence of Trans.
In summary, our new approach to bidirectional heuristic search enhanced by our Max
method achieves the fastest searches for finding optimal solutions on the Fifteen Puzzle of
all those using the Manhattan distance heuristic as the only knowledge source. The superiority of Max-BAI-Trans in terms of running time over previous algorithms is statistically
significant. For example, the probability that the improvement of the running time over
BIDA* is due to chance uctuation is smaller than 0.15 percent according to a test that
compares the means of the paired samples of the absolute running times, and it is even much
smaller according to the same test for the data relative to the diculty of each instance as
well as according to the sign test.16 When using less ecient implementations of IDA* as
the basis, the difference would become smaller, since our approach has less overhead per
node searched and therefore \gains" less compared to pure IDA*. However, we prefer to
compare the algorithms using the most ecient implementation that we have available. For
more details on these results see (Kainz, 1996).

6.2 Mazes

In order to get a better understanding of the usefulness of our new approach, we made
also experiments in a second domain | finding shortest paths in a maze. These are the
same maze problems as described above in Subsection 3.2. In addition to these 2000  2000
mazes, we also made experiments with much smaller 1000  1000 mazes, in order to see
whether the size inuences the relative performance of the various algorithms. We compare
known algorithms that achieve the best results in this domain (as far as we found) with our
algorithms Add-BAA and Add-BDA. The traditional shortest-path algorithm by Dijkstra
(1959) corresponds to A* without using heuristic knowledge, so we need not explicitly
include it in our experiments. Also in these experiments, all the compared algorithms use
no domain-specific knowledge other than the Manhattan distance heuristic, and the main
storage available on the Convex C3220 used was up to 256 Mbytes.
15. As noted already above in Subsection 3.2, BIDA*'s result here is worse than the data reported by Manzini
(1995), which is primarily due to using a different machine and a different implementation that is based
on the very ecient code of IDA* for the puzzle provided to us by Korf that we are using.
16. For more details on the statistic tests used we refer the interested reader to (Kaindl, Leeb, & Smetana,
1994; Kaindl & Smetana, 1994).

310

fiBidirectional Heuristic Search Reconsidered

Results relative to A* in %

160

Nodes generated

144.2

Running time

140
120

119.8
103.5

99.3

100 100

99.3
87.5

100

70.7 71.7

80
60
40
20
0
BS*

PS*
Depth=25

A*

Add-BAA

Add-BDA

Figure 10: Comparison on the maze problems (100 instances).
Fig. 10 shows a comparison of several algorithms in terms of the average number of
node generations and their running times. The data are normalized to the respective search
effort of A*. As already noted above, A* needs on average less than two minutes on the
machine that we used to find an optimal solution to one problem instance.
BS* generates slightly more nodes for solving these problems than A* (103.5 percent),
and its running time is even worse. While it may seem that the implementation of BS*
could be further optimized, it is clear that there is some overhead as compared to A*. So,
BS* can certainly not improve on A* here.
PS* (Dillenburg & Nelson, 1994) | using perimeter search, i.e., the front-to-front
method | generates 99.3 percent of the number of nodes of A*, but it needs 119.8 percent
of the time used by A*. These data correspond to a perimeter depth of 25, and they are the
best results of those shown in Fig. 5 above in terms of running time (see also the discussion
in Subsection 3.2). So, also PS* cannot really improve on A* here.
Our algorithms Add-BAA and Add-BDA generate clearly fewer nodes than A* (87.5
and 70.7 percent, respectively). The better performance of Add-BDA reects the higher
Mindiff1 value that is achieved through guiding the first of the two best-first searches by
expanding always one of those nodes n with minimal Diff1(n). More precisely, Add-BDA
achieved Mindiff1 = 1174 (from a reverse search of 750k nodes), while Add-BAA achieved
only Mindiff1 = 811 (from a reverse search of even 1000k nodes). The performance of AddBAA in terms of running time is, however, still much the same as that of A* (at least in this
implementation as derived from BS*). Add-BDA achieves the fastest searches, needing just
71.7 percent of the time needed by A*. So, the application of our approach to dynamically
improving heuristic values is feasible here with very little overhead.
The superiority of Add-BDA over previous algorithms is statistically significant. For
example, the probability that the improvement in terms of running time over A* is due
to chance uctuation is smaller than 0.005 percent according to all the three statistic tests
that we made analogously to those for the Fifteen Puzzle data. The same significance result
holds for the improvement with respect to the number of node generations. Both Add-BDA
and A* as well as the other algorithms compared here generate all child nodes at once
in node expansions, and the superiority of Add-BDA over these algorithms is statistically
311

fiKaindl & Kainz

Table 1: Overview of approaches to bidirectional heuristic search.
front-to-front
front-to-end
traditional
BHFFA, BHFFA2 BHPA, BS*
non-traditional PS*, IDPS*, BIDA* Max-BAI-Trans, Add-BDA
significant also in this respect. This is particularly interesting, since the optimality result
of A* over unidirectional algorithms is stated in the sense that A* never expands a node
that could be skipped by some other (unidirectional) algorithm (Dechter & Pearl, 1985).
Since the relative results on the 1000  1000 mazes are very similar, we do not show
them explicitly here (see, however, Kainz, 1996). They provide some empirical evidence
that the performance of these algorithms is not just peculiar for a certain size of mazes.

7. Discussion
After this presentation of our new approach to bidirectional heuristic search and its experimental results, let us put it into perspective. Table 1 provides an overview of the existing
approaches according to the way of evaluating and the way of organizing the change(s)
of search direction. The algorithms that instantiate our new generic approach fall into the
category of non-traditional bidirectional heuristic search algorithms (that change the search
direction only once) and that perform front-to-end evaluations. While this approach allows
coping with limited memory (e.g., in Max-BAI and Max-BAI-Trans), it is also useful in the
case of sucient memory (e.g., Add-BDA).
Due to avoiding expensive front-to-front evaluations, our approach to dynamically improving heuristic evaluations is less effective than perimeter search in saving node generations (at least in the Fifteen Puzzle domain). However, it has less overhead and is therefore
more ecient per node searched in terms of running time.
From the viewpoint of Table 1, our approach somehow \completes" the picture of bidirectional heuristic search. (Note, however, that the non-traditional approach was found
independently of the work on perimeter search.) Still, there should be ample opportunity
for further research on bidirectional search, especially when looking at it from other perspectives. Another issue is, e.g., whether linear-space search is involved or not. We propose
in this paper Max-IDA*, an algorithm that alternates the search direction before every
iteration in order to be able to use information from the previous iteration for improving
the heuristic evaluations dynamically. Yet another perspective is whether an algorithm is
designed to find optimal solutions or not. In this paper, we only focused on admissible
search algorithms. As discussed above, however, there also exist "-admissible bidirectional
search algorithms that guarantee solutions with a known error bound, as well as others that
find solutions without any guarantee about their quality (e.g., d-node retargeting).
When contrasting the traditional and the non-traditional approaches to bidirectional
heuristic search, it may appear to be strange that the less exible approach delivers the
better results. Why should it be \better" to change the search direction just once? While
it is dicult to provide a generally convincing answer to this question, let us summarize
some observations:
312

fiBidirectional Heuristic Search Reconsidered

 Traditional bidirectional search typically requires exponential space. Kaindl and

Khorsand (1994) showed that such a search is possible using limited memory, but
because of the complexity of such algorithms the runtime eciency was insucient.

 For the perimeter depths where perimeter search is successful, its perimeters are

much smaller than the frontiers of traditional front-to-front algorithms. Through
parameterizing the perimeter depth it is possible to balance the effort for front-tofront evaluations with their effect of improving heuristic evaluations dynamically.

 The runtime optimizations of BIDA* over IDPS* are only feasible when the perimeter
stays constant (at least for each iteration).

 The Mindiff value of the Add method becomes higher when the search for computing

it generates more nodes. So, in the context of a traditional bidirectional search it is
initially small.

 Applying the Max idea becomes much more complex, e.g., in BS* where both search
frontiers change (Kainz, 1996).

In general, one of the major problems of heuristic search is how to use available but
limited memory effectively. Pure unidirectional approaches to utilizing limited memory led
to less convincing results (Chakrabarti et al., 1989; Sen & Bagchi, 1989; Russell, 1992;
Ghosh et al., 1994; Reinefeld & Marsland, 1994) than the non-traditional approaches to
bidirectional search as shown in Table 1. In particular, our generic approach allows very
exible and effective use of available memory. This is, however, partly due to its integration
of various unidirectional strategies. Future work may investigate the direct use of such unidirectional approaches to utilizing limited memory in instantiations of our generic approach
to bidirectional search.
In addition, bidirectional search allows the use of memory for dynamically improving
heuristic evaluations in ways that are infeasible for strictly unidirectional search. This is
demonstrated by the front-to-front approach as well as by our difference method. The
following simple idea implicitly behind these approaches may further illustrate this. Given
a breadth-first (uniform-cost) search to some depth d, any node outside its frontier must
be at least d + 1 steps away from its start s. A reverse search towards s may use this
fact to compute an estimate for any node outside this frontier that is at least d + 1. This
idea cannot be used in a strictly unidirectional search. Note, however, that the approaches
discussed here are much more complex and useful than this simple idea. Since they take
known costs and heuristic estimates as well as differences of these into account, they can
provide much better estimates especially for nodes that are far outside the already given
opposite search frontier.
In some sense, it is also possible to view our difference approach as learning, since also
there differences between predicted and actual outcomes are important. Usual machine
learning research, however, strives for using the results from one problem instance for solving
subsequent instances, which we did not attempt. An in-depth discussion of this relationship
is outside the scope of this paper. Note, however, that also the approaches using front-tofront evaluations could be considered from this viewpoint.
313

fiKaindl & Kainz

8. Conclusion

Based on new insights about previous approaches to bidirectional heuristic search, we propose in this paper

 a new generic approach to non-traditional bidirectional search with front-to-end evaluations, and

 a new approach to dynamically improving heuristic values in this context.
We showed how to successfully instantiate this generic approach for the very important
case when available memory is limited. This memory can also be utilized for eciently
improving heuristic values. For certain problems where sucient memory is available, we
proposed an instantiation in the form of an algorithm that challenges A*, which is in a
certain sense optimal over unidirectional search algorithms. The optimality result of A* over
unidirectional competitors by Dechter and Pearl (1985) does not imply that bidirectional
search cannot be more ecient, and in our experiments we found some empirical evidence
that our new algorithm can be more ecient than A* both in terms of node expansions and
running time. We also showed that our approach was more ecient in terms of running time
than any other bidirectional or unidirectional search approach using the same information
in two different domains. These results are statistically significant.
While traditional bidirectional search did not yet achieve improvements over admissible unidirectional search, the non-traditional way of performing the opposing searches in
sequence | as exemplified by perimeter search and by our approach | seems to have
great potential. In this sense, we show that bidirectional heuristic search is viable and
consequently propose that this search strategy be reconsidered.

Acknowledgements

Over the years, several people cooperated with the first author on research in heuristic
search and in particular bidirectional search: Aliasghar Khorsand, Andreas Koll, Angelika
Leeb, Harald Smetana and Roland Steiner. Some of their work served as a basis for the work
presented in this paper. For our experiments we had a Convex C3220 at the computing
center of the TU Vienna available. Our implementations are based on the very ecient
code of IDA* and A* for the puzzle made available by Richard Korf and an ecient hashing
schema by Jonathan Shaeffer. Finally, we acknowledge the useful comments on earlier drafts
by Andreas Auer, Dennis de Champeaux, Stefan Kramer, Giovanni Manzini, Ira Pohl and
Roland Steiner. Parts of this paper already appeared in Proc. Fourteenth International
Joint Conference on Artificial Intelligence (IJCAI-95) and in Proc. Thirteenth National
Conference on Artificial Intelligence (AAAI-96).

Appendix. Glossary of Notation
s; t
d

C

Start node and goal/target node, respectively.
Current search direction index; when search is in the forward
direction d = 1, and when in the backward direction d = 2.
Cost of an optimal path from s to t.
314

fiBidirectional Heuristic Search Reconsidered

kd (m; n)
gd(n)
hd (n)
gd(n); hd(n)
fd (n)
fdj
Hd(n)
Fd (n)
Lmin
Opend
Closedd
jOpendj

#(a)
#d (a)
#jd (a)

Cost of an optimal path from m to n if d = 1, or from n to m if d = 2.
Cost of an optimal path from s to n if d = 1, or from n to t if d = 2.
Cost of an optimal path from n to t if d = 1, or from s to n if d = 2.
Estimates of gd(n) and hd (n), respectively.
Static evaluation function: gd (n) + hd (n).
One of the f -values of expanded nodes in search direction d.
Dynamic estimate of hd (n).
Dynamic evaluation function: gd (n) + Hd (n).
Cost of the best (least costly) complete path found so far from s to t.
The set of open nodes in search direction d.
The set of closed nodes in search direction d.
Number of nodes in Opend .
Number of nodes expanded by algorithm a.
Number of nodes expanded by algorithm a in search direction d.
Number of those nodes with value fdj expanded by algorithm a in
search direction d.

References

Chakrabarti, P., Ghose, S., Acharya, A., & DeSarkar, S. (1989). Heuristic search in restricted memory. Artificial Intelligence, 41 (2), 197{221.
Culberson, J., & Schaeffer, J. (1996). Searching with pattern databases. In McCalla, G.
(Ed.), Advances in Artificial Intelligence, pp. 402{416. Springer-Verlag, Berlin.
Davis, H., Pollack, R., & Sudkamp, T. (1984). Towards a better understanding of bidirectional search. In Proc. Fourth National Conference on Artificial Intelligence (AAAI84), pp. 68{72. Menlo Park, CA: AAAI Press / The MIT Press.
de Champeaux, D. (1983). Bidirectional heuristic search again. J. ACM, 30 (1), 22{32.
de Champeaux, D., & Sint, L. (1977). An improved bidirectional heuristic search algorithm.
J. ACM, 24 (2), 177{191.
Dechter, R., & Pearl, J. (1985). Generalized best-first strategies and the optimality of A.
J. ACM, 32 (3), 505{536.
Dijkstra, E. (1959). A note on two problems in connexion with graphs. In Numerische
Mathematik 1, pp. 269{271.
Dillenburg, J., & Nelson, P. (1994). Perimeter search. Artificial Intelligence, 65 (1), 165{178.
Ghosh, S., Mahanti, A., & Nau, D. (1994). ITS: an ecient limited-memory heuristic
tree search algorithm. In Proc. Twelfth National Conference on Artificial Intelligence
(AAAI-94), pp. 1353{1358. Menlo Park, CA: AAAI Press / The MIT Press.
Hart, P., Nilsson, N., & Raphael, B. (1968). A formal basis for the heuristic determination of
minimum cost paths. IEEE Transactions on Systems Science and Cybernetics (SSC),
SSC-4 (2), 100{107.
315

fiKaindl & Kainz

Kaindl, H. (1990). Tree searching algorithms. In Marsland, T., & Schaeffer, J. (Eds.),
Computers, Chess, and Cognition, pp. 133{158. Springer-Verlag, New York.
Kaindl, H., Kainz, G., Leeb, A., & Smetana, H. (1995). How to use limited memory in
heuristic search. In Proc. Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), pp. 236{242. San Francisco, CA: Morgan Kaufmann Publishers.
Kaindl, H., & Khorsand, A. (1994). Memory-bounded bidirectional search. In Proc. Twelfth
National Conference on Artificial Intelligence (AAAI-94), pp. 1359{1364. Menlo Park,
CA: AAAI Press / The MIT Press.
Kaindl, H., Leeb, A., & Smetana, H. (1994). Improvements on linear-space search algorithms. In Proc. Eleventh European Conference on Artificial Intelligence (ECAI-94),
pp. 155{159. Chichester, England: Wiley.
Kaindl, H., & Scheucher, A. (1992). Reasons for the effects of bounded look-ahead search.
IEEE Transactions on Systems, Man, and Cybernetics (SMC), 22 (5), 992{1007.
Kaindl, H., & Smetana, H. (1994). Experimental comparison of heuristic search algorithms.
In AAAI-94 Workshop on Experimental Evaluation of Reasoning and Search Methods,
pp. 11{14.
Kainz, G. (1994). Heuristische Suche in Graphen mit der Differenz-Methode. Diplomarbeit,
Technische Universitat Wien, Vienna, Austria.
Kainz, G. (1996). Neue Algorithmen fur die bidirektionale heuristische Suche. Doctoral
dissertation, Technische Universitat Wien, Vienna, Austria.
Kainz, G., & Kaindl, H. (1996). Dynamic improvements of heuristic evaluations during
search. In Proc. Thirteenth National Conference on Artificial Intelligence (AAAI-96),
pp. 311{317. Menlo Park, CA: AAAI Press / The MIT Press.
Koll, A., & Kaindl, H. (1993). Bidirectional best-first search with bounded error: Summary
of results. In Proc. Thirteenth International Joint Conference on Artificial Intelligence
(IJCAI-93), pp. 217{223. San Francisco, CA: Morgan Kaufmann Publishers.
Korf, R. (1985). Depth-first iterative deepening: An optimal admissible tree search. Artificial Intelligence, 27 (1), 97{109.
Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2{3), 189{212.
Korf, R., & Taylor, L. (1996). Finding optimal solutions to the Twenty-Four Puzzle. In Proc.
Thirteenth National Conference on Artificial Intelligence (AAAI-96), pp. 1202{1207.
Menlo Park, CA: AAAI Press / The MIT Press.
Kwa, J. (1989). BS : An Admissible Bidirectional Staged Heuristic Search Algorithm.
Artificial Intelligence, 38 (2), 95{109.
Lawler, E., & Wood, D. (1966). Branch-and-bound methods: a survey. Operations Research,
14 (4), 699{719.
316

fiBidirectional Heuristic Search Reconsidered

Manzini, G. (1995). BIDA*: an improved perimeter search algorithm. Artificial Intelligence,
75 (2), 347{360.
Nilsson, N. (1980). Principles of Artificial Intelligence. Tioga, Palo Alto, CA.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies for Computer Problem Solving.
Addison-Wesley, Reading, MA.
Pohl, I. (1970). First results on the effect of error in heuristic search. In Meltzer, B., &
Michie, D. (Eds.), Machine Intelligence 5, pp. 219{236. Edinburgh University Press,
Edinburgh.
Pohl, I. (1971). Bi-directional search. In Machine Intelligence 6, pp. 127{140 Edinburgh.
Edinburgh University Press.
Politowski, G., & Pohl, I. (1984). D-node retargeting in bidirectional heuristic search. In
Proc. Fourth National Conference on Artificial Intelligence (AAAI-84), pp. 274{277.
Menlo Park, CA: AAAI Press / The MIT Press.
Rao, V., Kumar, V., & Korf, R. (1991). Depth-first vs best-first search. In Proc. Ninth
National Conference on Artificial Intelligence (AAAI-91), pp. 434{440. Menlo Park,
CA: AAAI Press / The MIT Press.
Reinefeld, A., & Marsland, T. (1994). Enhanced iterative-deepening search. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 16 (12), 701{709.
Russell, S. (1992). Ecient memory-bounded search methods. In Proc. Tenth European
Conference on Artificial Intelligence (ECAI-92), pp. 1{5. Chichester, England: Wiley.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: A Modern Approach. Prentice Hall,
Englewood Cliffs, NJ.
Sen, A., & Bagchi, A. (1989). Fast recursive formulations for best-first search that allow
controlled use of memory. In Proc. Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), pp. 297{302. San Francisco, CA: Morgan Kaufmann
Publishers.
Taylor, L., & Korf, R. (1993). Pruning duplicate nodes in depth-first search. In Proc.
Eleventh National Conference on Artificial Intelligence (AAAI-93), pp. 756{761.
Menlo Park, CA: AAAI Press / The MIT Press.
Zhang, W., & Korf, R. (1993). Depth-first vs. best-first search: new results. In Proc.
Eleventh National Conference on Artificial Intelligence (AAAI-93), pp. 769{775.
Menlo Park, CA: AAAI Press / The MIT Press.

317

fiJournal of Artificial Intelligence Research 7 (1997) 249-281

Submitted 7/1997; published 12/1997

When Gravity Fails: Local Search Topology

Jeremy Frank

frank@tiziano.arc.nasa.gov

Caelum Research Corp.
NASA Ames Research Center
Mail Stop N269-1
Moffett Field, CA 94035-1000

Peter Cheeseman

cheesem@ptolemy.arc.nasa.gov

RIACS
NASA Ames Research Center
Mail Stop N269-1
Moffett Field, CA 94035-1000

John Stutz

stutz@ptolemy.arc.nasa.gov

NASA Ames Research Center
Mail Stop N269-1
Moffett Field, CA 94035-1000

Abstract

Local search algorithms for combinatorial search problems frequently encounter a sequence of states in which it is impossible to improve the value of the objective function;
moves through these regions, called plateau moves, dominate the time spent in local search.
We analyze and characterize plateaus for three different classes of randomly generated
Boolean Satisfiability problems. We identify several interesting features of plateaus that
impact the performance of local search algorithms. We show that local minima tend to be
small but occasionally may be very large. We also show that local minima can be escaped
without unsatisfying a large number of clauses, but that systematically searching for an
escape route may be computationally expensive if the local minimum is large. We show
that plateaus with exits, called benches, tend to be much larger than minima, and that
some benches have very few exit states which local search can use to escape. We show that
the solutions (i.e., global minima) of randomly generated problem instances form clusters,
which behave similarly to local minima. We revisit several enhancements of local search algorithms and explain their performance in light of our results. Finally we discuss strategies
for creating the next generation of local search algorithms.

1. Introduction
Local search algorithms have been heavily studied as an alternative to complete search
for NP -Hard problems. A typical local search algorithm, such as gradient descent or
greedy search, employs an objective function to rank states, and picks a \neighboring"
state maximizing the improvement to the objective function. A compelling (if inexact)
analogy is that of dropping a marble on a smooth surface and observing it roll downhill into
a local valley. The typical greedy objective function acts like gravity, pulling the current
state downhill. This procedure can result in the algorithm becoming trapped in a local
minimum. Local search algorithms tend to find solutions to satisfiable decision problems
more quickly than complete search algorithms. However, these algorithms may terminate

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiFrank, Cheeseman, & Stutz

procedure GSAT(,MaxFlips, MaxTries)

#  is the problem instance to be solved
# A is the current variable assignment
for i=1 to MaxTries
A = N -bit string selected uniformly at random
for j = 1 to MaxFlips
if solved problem(A; )

return A
else

PossFlips = neighbors of A minimizing the number of unsatisfied clauses
A = one element of Possips selected uniformly at random

end else
end for
end for
return FAIL
end

Figure 1: GSAT Algorithm Sketch
either without finding a solution when one exists or guaranteeing that a problem instance
does not have a solution.
GSAT is a local search procedure for the Boolean Satisfiability problems (Selman,
Levesque, & Mitchell, 1992) that has proven to be effective at quickly finding solutions
to satisfiable problem instances. A sketch of GSAT appears in Figure 1. In the figure, 
refers to the problem instance GSAT is to solve. GSAT's search space is the space of all
complete assignments of values to variables. The GSAT algorithm is typically given a fixed
number of tries (denoted in the figure as MaxTries) and a fixed number of moves per try
(denoted MaxFlips) to solve a problem instance. During each move, GSAT examines all
states reachable by changing the value of a single variable, and selects moves that minimize
the number of unsatisfied clauses. GSAT typically encounters a sequence of states where
the best move available at each state leaves the number of unsatisfied clauses unchanged.
These moves are referred to as plateau moves or sideways moves, studied in (Gent & Walsh,
1993a) and (Hampson & Kibler, 1995). Plateau moves dominate the time GSAT spends doing search (Gent & Walsh, 1993a). It is believed that all combinatorial search problems with
discrete objective functions have plateaus that cause plateau moves during local search, but
it is unlikely that search problems with real-valued objective functions have plateaus. When
GSAT encounters a plateau, it randomly searches until it either runs out of ips or finds a
neighboring state with fewer unsatisfied clauses, thereby exiting the plateau. Returning to
the marble analogy, there is no gravity on the plateaus, and hence the marble simply rolls at
random until it finds an exit or runs out of momentum. Numerous variants of GSAT have
been developed to avoid random plateau search and improve GSAT performance (Gent &
Walsh, 1993b; Selman & Kautz, 1993; Gent & Walsh, 1995).
The nature of plateau behavior of local search algorithms is not well understood. Some
researchers suggest that algorithms like GSAT become trapped in local minima, i.e., parts
250

fiWhen Gravity Fails: Local Search Topology

of the search space from which there is no escape to a better part of the search space. If this
is true, local minima detection and avoidance is the most important problem in local search
algorithm development. Other researchers have suggested that local search could become
trapped in \at" regions of the search space that have exits to better states, which we call
benches. This may happen because benches are large, or because they contain few exits and
random plateau search has a small probability of finding an exit. Rather than designing
algorithms and testing them on problem classes, we undertook an empirical examination of
the nature of plateaus for a variety of 3-SAT problems.
This paper presents several surprising discoveries concerning the topological structures
leading to plateau behavior and their impact on local search. We define plateaus as a feature
of the search space and break plateaus into two classes: local minima and benches. Plateaus
are defined as any maximally connected region of the local search space over which the
objective function is constant. Local minima are plateaus surrounded by regions of the
search space where the objective function takes on values exceeding that of the plateau,
with the result that purely greedy local search cannot escape once finding a state on the
local minimum. Benches are defined as plateaus with exits to regions of the search space
with lower values of the objective function. Our results show that local minima are more
common than benches when the number of unsatisfied clauses is close to 1, but local minima
also occur frequently at higher numbers of unsatisfied clauses. Most local minima tend to be
small, but their size exhibits high variability; often the largest local minima exceeds 10,000
states in a problem instance containing 100 variables. Also surprising was the behavior
of solutions: solutions are grouped together into global minima of highly variable size.
Our results also show that benches tended to be much larger than local minima. Most
benches have a large number of exits, but a small fraction have very few exits, with the
result that local search can spend a large amount of time trying to escape them. Plateau
characteristics are dependent on many features of a problem instance; we found differences in
plateau characteristics based on the ratio of clauses to variables, solvability of the problem
instances, and problem classes. The results on plateau characteristics allowed us to reinterpret the success of many modifications to local search, including history lists (Gent &
Walsh, 1993b), random walk (Kautz & Selman, 1996) and tabu search (Glover, 1989).
The paper is organized as follows: In Section 2 we present some definitions used throughout the rest of the paper. Next in Sections 3 and 4 we present an empirical analysis of
properties of plateaus for several problem spaces. In Section 5 we present an analysis of
previous results in light of our findings. We then suggest how to apply our work to the
creation of new local search algorithms in Section 6, and finally in Section 7 we conclude
and discuss ideas for future work.

2. Definitions
In this section we will define some terms used throughout the paper. We restrict our discussion to the Boolean Satisfiability problems in conjunctive normal form with three distinct
literals per clause, abbreviated 3-SAT, but many of the concepts presented here translate
to other discrete combinatorial search problems. We first present informal definitions, and
provide more formal definitions at the end of the section.
251

fiFrank, Cheeseman, & Stutz

A way of visualizing the local search space for 3-SAT is by mapping each full variable
assignment to a node of an N dimensional hypercube, where N is the number of variables
in the problem instance. If two assignments differ by one variable assignment they are
adjacent nodes in the hypercube. Each problem instance I defines a function on nodes of
the hypercube, mapping the node to the number of unsatisfied clauses of the instance under
the assignment of values corresponding to the node. We refer to the number of unsatisfied
clauses under an assignment as the level of the assignment. A plateau is a maximal connected
region of the assignment space where all states have the same level, and the level of the
plateau is the level of the states in the plateau. Even a single state can be a plateau, if all of
its neighbors are of a different level than the state itself. We define the border of a plateau
to be the set of nodes in the hypercube that are neighbors of some state on the plateau but
have a different level than the plateau. A plateau is a minimum if all states on the border
have a higher level than the plateau. If a plateau is not a minimum, then there is some
state on the border with a lower level than the states on the plateau; states on the plateau
that are adjacent to these lower level states are called exits. Plateaus with exits are called
benches. Some benches consist entirely of exits; a local search algorithm may then explore
only one state of such a bench before moving off of it. We call these benches contours. For
3-SAT, a plateau is a global minimum if it is of level 0, but unsatisfiable problem instances
can have global minima of levels higher than 0.
Plateau
No exits

Exits

Minima

Bench

Lowest Level

Global Minima

Higher Level

Local Minima

All States Exits

Contour

Figure 2: A Taxonomy of Plateaus
In summary: A plateau is a part of the space that is \at" from the perspective of the
objective function. All the states neighboring the plateau are of a different level from the
plateau. If all the neighboring states are at a higher level, the plateau is a local or global
minimum, otherwise it is a bench. If every state on the plateau is a neighbor of a state of
lower level, the bench is a contour. Figure 2 shows a taxonomy of different types of plateaus.
A further illustration of these definitions using a simple problem instance is presented in
Appendix A.
We realize that there are different ways of defining topological structures of local search
spaces. Our definition of plateaus includes structures which do not lead to plateau behavior;
local search will not exhibit plateau behavior as it passes a contour, for example. These
definitions show that the observed plateau behavior of local search can be caused by a variety
of structures in the local search topology. In retrospect, it is clear that a definition of benches
that specifically excludes contours would better serve to characterize the plateau behavior
of greedy algorithms. We caution the reader that our results for benches are contingent
upon our current definition of benches, and that there is at least one reasonable alternate
252

fiWhen Gravity Fails: Local Search Topology

definition that is expected to give somewhat different results. This will be discussed further
in Section 7.
We end this section by providing more formal definitions of these ideas. Throughout
the following definitions, let H be an N dimensional hypercube representing the possible
assignments of a 3-SAT problem instance I . Two vertices of the hypercube h1 ; h2 are
neighbors, i.e., have an edge between them, if they correspond to assignments differing in
exactly 1 variable.

Definition 2.1 (Level) Let I : H ! Z + be a function mapping assignments to integers
such that I (h) = z if and only if the assignment corresponding to h results in z unsatisfied
clauses in problem instance I . Then z is defined as the level of the assignment.
Definition 2.2 (Plateau) Let P be a connected subgraph of H and let z 2 Z + be a constant. Then P is a plateau if P is a maximal connected subgraph of H such that I (p) = z
for all p 2 P . Further, z is defined to be the level of the plateau.
Definition 2.3 (Border) Let P be a plateau in a hypercube H . Let N (p) be the set of

neighboring vertices of vertex p in the hypercube. Let V (P ) be a function that returns the
vertex set of a graph P . Define B (P ) = ([p2P N (p)) , V (P ), i.e., the set B (P ) contains b
if b is a neighbor of a vertex p 2 P and b is not in P itself. Then B (P ) is the border of
the plateau.

Definition 2.4 (Minimum, Local Minimum, Global Minimum) Let P be a plateau
in a hypercube H . Then P is a minimum if all vertices in B (P ) have higher level than the
level of P . Also, P is a local minimum if P is a minimum and there is another minimum

Q such that the level of Q is smaller than the level of P . If P is a minimum that is not a
local minimum then P is a global minimum.

Definition 2.5 (Bench, Exit, Contour) Let P be a plateau of a hypercube H . Then P
is a bench if P is not a minimum, and hence there exists b 2 B (P ) such that the level
of b is smaller than the level of P . Also, p is an exit from the bench if p 2 P and p is a
neighbor of b 2 B (P ) such that the level of b is smaller than the level of P . Finally, P is a
contour if every state of P is an exit from P .

3. Probabilistically Painting Plateaus

Armed with the definitions from the previous section we examined the landscape of plateaus
for randomly generated 3-SAT problem instances. We generated problem instances for
which the ratio of the number of clauses C to the number of variables N ranged from
3.8 to 4.6 according to the Uniform3-SAT problem generation model (Selman et al., 1992;
Crawford & Auton, 1993); the algorithm for generating these instances is presented in
Appendix B. Problems in this region straddle the \phase transition" in satisfiability, for
which the satisfiability of randomly generated problems exhibits a rapid transition with
respect to the ratio of clauses to variables, and for which complete search and GSAT require
the longest time on the average to find solutions (Cheeseman, Kanefsky, & Taylor, 1991;
Crawford & Auton, 1993; Clark, Frank, Gent, MacIntyre, Tomov, & Walsh, 1996). Problem
253

fiFrank, Cheeseman, & Stutz

instances with NC < 4:3 are referred to as \under-constrained" since they lie below the
observed transition in satisfiability, while problem instances with NC > 4:3 are called \overconstrained." We guaranteed that each problem instance used in this set of experiments
was satisfiable by finding a solution using a complete search algorithm.
Local search seems to have the most diculty when the level of the assignment becomes
close to 0; consequently, we decided to analyze plateaus at these levels. It is quite dicult to
randomly sample plateaus of a fixed level for a problem instance; the probability of randomly
generating an assignment with one unsatisfied clause, for instance, is very small for problem
instances with 100 variables. We used GSAT to find the plateaus analyzed in this paper.
This biases our investigation of plateaus to those found by one local search method, but
hopefully provides a first picture of the plateau structure of local search spaces. Due to the
clumsiness of language, we do not remind the reader throughout the text that our findings
are dependent on our plateau sampling methodology. Further, because GSAT employs
random starting points, the bias of our results depends only on the gradient following
procedure. To sample plateaus we first used GSAT to find a state of a pre-determined level.
That is, we generated an initial state and ran a single try of GSAT until it encountered a
state with the specified number of unsatisfied clauses. We then used Breadth-First Search to
find all of the states on the plateau found by GSAT. Naturally Breadth-First Search records
each state found so that redundant states are not double-counted. We then recorded the
size of the plateau (i.e., the number of states on the plateau), and the number of exits the
plateau contained.

3.1 Characterizing Plateaus
We first analyzed the relative proportions of benches and minima of satisfiable problem
instances for plateaus whose level was close to 0. We generated problem instances of 100
variables and 380-460 clauses in increments of 10 clauses. For each problem size we generated
1000 problem instances and guaranteed each instance had a solution using a complete search
algorithm. Using the procedure described above, for each problem instance generated we
found one plateau of each level from 0 to 5 and measured the proportion of these plateaus
that are local minima and benches. This analysis does not provide any idea of the number
of benches or local minima in these problem instances. Note that all plateaus of level 0 are
global minima of satisfiable problem instances.
Figure 3 shows the proportion of plateaus that are local minima graphed against the
number of clauses in the problem instances. As described above, we used GSAT to find
plateaus and Breadth-First Search to determine whether the plateaus were local minima
or benches. Here we see that the proportion of plateaus that are minima grows with the
number of clauses in the problem instance for plateaus of levels 2-5; hence there are more
local minima of identical levels in over-constrained problems than in under-constrained
problems. The rate of growth diminishes as the plateau level decreases, until it is roughly
at for plateaus of level 1. About 85% of plateaus of level 1 are minima for 100 variable
problem instances over all numbers of clauses investigated.
Figures 4 shows the same data, except in this case we have graphed against the level
of the plateau. As the level grows the proportion of local minima declines for problem
instances of all numbers of clauses. However, plateaus at level 5 may still be local minima
254

fiWhen Gravity Fails: Local Search Topology

1
0.9

Proportion of Plateaus which are Minima

0.8
0.7
0.6
0.5
0.4
0.3
Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.2
0.1
0
380

390

400

410

420
430
Number of Clauses

440

450

460

Figure 3: Proportion of Plateaus that are Local Minima vs. Number of Clauses for Randomly Generated 100 Variable Problem Instances

1

Proportion of Plateaus which are Minima

0.9

460 Clauses
450 Clauses
440 Clauses
430 Clauses
420 Clauses
410 Clauses
400 Clauses
390 Clauses
380 Clauses

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1

2

3

4

5

Plateau Level

Figure 4: Proportion of Plateaus that are Local Minima vs. Plateau Level for 100 Randomly
Generated Variable Problem Instances With Varying Numbers of Clauses

255

fiFrank, Cheeseman, & Stutz

even for problems with 100 variables and 380 clauses. Hence local minima are a fact of life
even for under-constrained problems, and become more likely for over-constrained problems.
Finally, we note that between plateaus of level 1 and 2 there is a reordering of the proportion
of local minima. For example, problems with 450 clauses have the lowest proportion of local
minima of level 1, but the highest proportion of local minima of level 2. We do not have an
explanation for this result.
1
0.9

Proportion of Plateaus which are Minima

0.8
0.7
0.6
0.5
0.4

Level 0 Plateaus
Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.3
0.2
0.1
0
25

50

75

100
Problem Size

125

150

175

Figure 5: Proportion of Plateaus that are Local Minima vs. Plateau Level for Variable
Sized Randomly Generated Problem Instances with C/N=4.3
We also analyzed how the relative proportions of benches to minima changed as problems
grew larger. We found one plateau each of levels 1-5 for each of 1000 problem instances
with 25 to 175 variables in increments of 25, with NC = 4:3. Figure 5 shows the proportion
of plateaus of levels 1-5 that are local minima for NC = 4:3 graphed against the problem
size. We see that, for each level, the proportion of minima grows with the problem size,
which bodes ill for the performance of local search on larger problem instances. We see
that the proportion of local minima of higher level decreases less rapidly for these larger
problems. We conjecture that, for larger problems, the proportion of local minima decreases
significantly for plateaus of levels higher than 5, but we cannot predict the exact behavior
from the data at hand.
The cost of detecting local minima is proportional to the size of the local minima, so
understanding the size distribution of local minima is important. The cost of escaping
benches is dependent on the size of the bench and the proportion of the states on a bench
that are exits, and so understanding these properties is also important. In the next two
sections we analyze these characteristics of benches and minima. To do so, we generated
statistics from the plateaus we found in the experiment used to generate Figure 4. For
instance, 60% of the plateaus of level 2 for problem instances of 380 clauses are local
256

fiWhen Gravity Fails: Local Search Topology

minima, so we had 600 local minima and 400 benches to analyze the characteristics of
plateaus. In all cases we had over 100 data points available for analysis.

3.2 Minima Characteristics
300
100 variables, 430 clauses

250

Number of Minima

200

150

100

50

0
0

100

200

300

400

500
600
Size of Minima

700

800

900

1000

Figure 6: Histogram of Sizes of Level 1 Minima for Randomly Generated Problem Instances
of 100 Variables, 430 Clauses. Note that some minima exceeded 1000 states.
In this section we analyze the size distribution of local minima. Figure 6 shows the
distribution of the size of the level 1 minima for problem instances with 100 variables and
430 clauses. The median minima size is 48, yet the tail shows that some minima are larger
than 1000 states. In fact, 35 of the 900 minima are larger than 1000 states and some had
as many as 10,000 states. We examined the distribution of minima sizes for levels other
than 1 and found similar results; the main differences are in the lengths of the tails of the
histograms. A consequence of this discovery is that escaping local minima by explicit local
minima detection is normally very easy, but occasionally can be very expensive. Figure 7
shows the distribution of sizes of minima that are smaller than 100 states. We see here that
there are fewer minima of size 0-5 than of size 5-10; a detailed analysis reveals that there
are three minima of size 1, and fifteen minima of size 2.
Due to the long tails of the distribution of minima size, the median provides a more
stable summary statistic than the mean. We therefore examined the median size of local
minima of levels 0-5 for different numbers of clauses to determine how the size of local
minima varies. Figure 8 shows the median size of local minima plotted against the number
of clauses in the problem instances. The most striking feature of these results is that most
minima tend to be quite small. This suggests it is possible to devise local search algorithms
to detect local minima using exhaustive search and then propel themselves into a more
fruitful part of the search space. While the distribution shown in Figure 6 indicates that
257

fiFrank, Cheeseman, & Stutz

100
100 variables, 430 clauses
90
80

Number of Minima

70
60
50
40
30
20
10
0
0

5

10

15

20

25

30

35

40

45 50 55 60
Size of Minima

65

70

75

80

85

90

95 100

Figure 7: Histogram of Sizes of Level 1 Minima Smaller than 100 States for Randomly
Generated Problem Instances of 100 Variables, 430 Clauses

150
Level 0 Minima
Level 1 Minima
Level 2 Minima
Level 3 Minima
Level 4 Minima
Level 5 Minima

125

Median Minima Size

100

75

50

25

0
380

390

400

410

420
430
Number of Clauses

440

450

460

Figure 8: Median Size of Minima vs. Problem Size for 100 Variable Randomly Generated
Problem Instances with Varying Numbers of Clauses

258

fiWhen Gravity Fails: Local Search Topology

some local minima can be very large, explicit detection of minima below a fixed size (the
median, for instance) may be a successful addition to local search. The second feature of
note is that the median size of level 0 minima (i.e., solutions) follows the same pattern
as local minima, but that level 0 minima tend to be smaller than local minima. The last
feature of note is that the median size of local minima decreases for minima of level 0-3 as
the number of clauses in the problem instances increases. The median size of local minima
of level 4 and 5 increases for problems with 450-460 clauses. One possible explanation for
this is that the sampled problem instances were guaranteed to have solutions, which means
that the added clauses must contribute to larger minima and benches at higher levels. If
this is true it is not clear why the minima of levels 0-3 do not increase in size. Another
possible explanation is the small amount of data for plateaus of levels 4 and 5 relative to
the amount available for the other plateau sizes as indicated in Figure 4.
120
Level 1 Minima
Level 2 Minima
Level 3 Minima
Level 4 Minima
Level 5 Minima

100

Median Minima Size

80

60

40

20

0
25

50

75

100
Problem Size

125

150

175

Figure 9: Median Size of Minima vs. Plateau Level for Variable Sized Randomly Generated
Problem Instances with C/N=4.3
We also examined the median size of local minima of levels 1-5 as the number of variables
in the problem instances increases. Figure 9 shows the median minima size for the various
levels of minima graphed against problem size for problem sizes from 25 to 175 variables for
C
N = 4:3. We observe that, as problem sizes grow large (beyond 100 variables), the median
size of minima of lower levels appears smaller than that of minima of higher levels. We
also observe that for fixed minima level, there appears to be a problem instance size that
maximizes the median minima size. We do not have an explanation for the large number
of minima of level 1 for problem instances of 50 variables.
Recall that a global minima for a satisfiable problem instance is a plateau where all
states are solutions. How many global minima are there in satisfiable problem instances?
Is there only one, or are the solutions broken into multiple global minima? If there is more
259

fiFrank, Cheeseman, & Stutz

than a single global minima, can the size of the global minima tell us anything about how
likely it is that local search will encounter a particular solution? To answer these questions
we used GSAT to find 1000 global minima for a single problem instance with 100 variables
and 430 clauses, and determined which minima were distinct. We found that 436 of the
1000 minima were unique, and that the global minima for this instance ranged in size from
1 to 2880 states. Furthermore, we found that the vast majority of the minima are small,
with the median size being around 48. We repeated the experiment for 20 more problem
instances and found that solutions for these problem instances are typically divided into
separate global minima and that the global minima vary widely in size. Due to space
considerations we do not present this data in the paper.
Assuming we could detect local minima, how dicult is it for local search to escape
minima in order to explore a new part of the search space? If local search is in a local
minimum it must temporarily move to states of higher level in order to find a more promising
part of the search space. Two sources of computational complexity contribute to the cost
of escaping minima: the cost of detecting the minimum, and the cost of finding a path to
a better part of the search space. The size of the minimum is a measure of the detection
cost; we chose the minimum increase in level as a measure of the diculty of escaping local
minima. To understand this idea, consider all sequences of neighboring states out of a
minimum such that the level increases, then decreases. We are interested in the minimum
increase required before the level decreases again. To determine this we generated 1000
problem instances of 50 variables and 215 clauses each, generated an initial state, and then
ran GSAT for 1000 ips. This was sucient to reach a local or global minimum. 1 In order
to find the minimum level required to escape, we used Breadth-First Search. We begin
with the states of the local minimum. We then explore a state on the border, queuing all
those states not explored before in increasing order of level. This ensures states of lower
level are explored first. Once we encounter a state of lower level than its neighbor, we have
found a path out of the local minimum; the level of the state with a neighbor of lower
level is the minimum level required to escape the local minimum. Our results indicate
that local minima can usually be escaped by increasing the level by only 1, that is, only
unsatisfying one additional clause. However, it is not obvious which border state to use
to escape; Breadth-First Search may expand tens of thousands of states before finding an
escape route, and so this may not always be an effective escape strategy.
In summary, the data presented in Figures 6 to 9 shows that local minima tend to be
very small much of the time, and therefore may be easily detectable and escaped. Local
minima can typically be escaped by unsatisfying only a single additional clause, but it is
still not clear how to escape local minima effectively. Further, the size distribution of global
minima behaves much like the size distribution of local minima. Instances tend to have
many global minima of highly variable size, and there is evidence that local search is more
likely to encounter small sized local minima and global minima than large ones.

3.3 Bench Characteristics
1. The local minima ranged in level from 1 to 6; we did not measure the level required to escape from
benches or global minima.

260

fiWhen Gravity Fails: Local Search Topology

80
100 variables, 430 clauses
70

Number of Benches

60

50

40

30

20

10

0
0

1000

2000

3000

4000

5000
6000
Size of Benches

7000

8000

9000

10000

Figure 10: Histogram of Bench Sizes of Level 1 for Randomly Generated Problem Instances
of 100 Variables, 430 Clauses

Recall that a bench is a plateau that has exits to other states of lower level. Two
important characteristics of benches that impact the performance of local search are the
size of the benches and the number of exits. We first analyzed the distribution of the size of
benches; Figure 10 shows the distribution of bench sizes of level 1 for problem instances of
100 variables and 430 clauses. Again we found long tails, implying that while most benches
are small, some can be very large. The distributions tend to be much atter than those for
minima.
We next analyzed how median bench size varies with the number of clauses in the
problem. The appearance of long tails of the distribution of bench sizes again indicates
that the median is a more stable measure than the mean. Figure 11 shows how the median
size of benches varies with the number of clauses in problems for different levels of benches.
The most interesting feature is the very large median size of the benches when compared
to the size of local minima. Benches are typically 10-30 times as large as local minima,
depending on the level and number of clauses in the problem instance. Problem instances
with more clauses tend to have smaller benches, while for some of the under-constrained
instances the median bench size begins growing rapidly with bench level even for the small
range of plateau levels analyzed here.
We also examined how bench size depends on problem size. For small problems, i.e., 2550 variables, benches tended to be much larger than for problems with more variables. Our
explanation for this is that there are so few clauses that they do not adequately distinguish
between assignments when we examine states at low enough levels. Problems with 100
261

fiFrank, Cheeseman, & Stutz

7000
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

6000

Median Bench Size

5000

4000

3000

2000

1000

0
380

390

400

410

420
430
Number of Clauses

440

450

460

Figure 11: Median Size of Benches vs. Problem Size for 100 Variable Randomly Generated
Problem Instances
variables have few benches with more than 10,000 states; we exclude these benches from
our analysis. 2
Large benches may be dicult to escape if the number of exits is small, or if exits are
clustered together. Some benches have very few exits, while others have many exits. We
used the ratio of exits from benches to the bench size as a measure of the diculty of
escaping from benches. We did not investigate whether or not exits from benches are close
together, which may also have an impact on the diculty of escaping benches.
Figure 12 shows the distribution of proportion of exits to bench size for benches of level
1 for problems with 100 variables and 430 clauses. The distribution of these proportions
indicates that plateaus have highly variable numbers of exits. We note that some benches
are in fact contours; in Figure 12 contours show up as benches whose ratio of exits to bench
size is 1. We observed that all six of the benches with ratio of exits to bench size at least
0.95 in Figure 12 are in fact contours. Figure 13 shows the distribution of the proportion of
exits for benches of level 5; there are proportionally more contours (65 of the 78 benches in
the rightmost column of the histogram are contours), and the mean ratio of exits to bench
size has increased. The difference between these two plots indicates that benches of lower
levels tend to have fewer exits than benches of higher level, even if we exclude contours
from the measurements.
To further understand how to escape benches of different levels, we next present plots
of the mean proportion of the number of exits to bench size graphed against problem size
2. Breadth-First Search stores an enormous number of states, and as such we terminated the program if
the bench size exceeded 10,000 states. Since we had so few large benches and used the median statistic,
this caused few diculties in the analysis.

262

fiWhen Gravity Fails: Local Search Topology

15
100 Variables, 430 Clauses, Level 1 Benches

Number of Occurences

10

5

0
0

0.1

0.2

0.3

0.4
0.5
0.6
Proportion of Exits to Bench Size

0.7

0.8

0.9

1

Figure 12: Exits from Level 1 Benches for Randomly Generated Problem Instances of 100
Variable, 430 Clauses

80
100 Variables, 430 Clauses, Level 5 Benches

75
70
65
60

Number of Occurences

55
50
45
40
35
30
25
20
15
10
5
0
0

0.1

0.2

0.3

0.4
0.5
0.6
Proportion of Exits to Bench Size

0.7

0.8

0.9

1

Figure 13: Exits from Level 5 Benches for Randomly Generated Problem Instances of 100
Variables, 430 Clauses

263

fiFrank, Cheeseman, & Stutz

in Figure 14. When taken in consideration with the histograms in Figure 12, we hope this
will create an accurate picture of how benches tend to look.
We see in Figure 14 that the proportion of exits from benches increases with the level of
the benches. For problems with 430 to 460 clauses the mean number of exits of benches of
level 1 increases sharply, indicating that for over-constrained solvable problems benches of
level 1 are less of an obstacle to finding solutions. We should point out that our inclusion
of contours in the definition of benches may artificially inate these proportions, in some
cases considerably.
0.8
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

Mean Proportion of Exits to Bench Size

0.7

0.6

0.5

0.4

0.3

0.2
380

390

400

410

420
430
Number of Clauses

440

450

460

Figure 14: Mean Proportion of Exits From Benches vs Problem Size for Randomly Generated Problem Instances of 100 Variables
We analyzed benches to determine whether or not there was some relationship between
the number of exits from a bench and its size, but found no such relationship for all clause
sizes and benches of all levels we investigated. This lack of relationship is unfortunate, since
it tells us little about how to escape large benches.
In summary, the data presented in figures 10 to 14 shows that benches are occasionally
very large, but there are often many exits from benches. As a result, only occasionally
will local search become trapped on a very large bench from which there is little chance
to escape. We also found that benches of higher level have more exits than benches of
lower level. We showed that contours are common for benches of level 5 but may also occur
at level 1. Finally, we found no obvious relationship between bench size and the number
of exits. We conclude that local minima are more often a problem for local search than
benches since most benches seem to be easy to escape.
264

fiWhen Gravity Fails: Local Search Topology

4. Plateau Characteristics Across Problem Classes

In the previous section we analyzed plateaus for satisfiable 3-SAT problem instances from
one problem instance class. There is little reason to suspect that plateaus behave similarly
across problem instance classes. There may also be differences between satisfiable and
unsatisfiable instances of the same class. In recent years numerous algorithm designers
have begun testing algorithms on random problem classes that have pre-specified desirable
properties. Among these are problem instances that have guaranteed solutions (Tsuji &
Gelder, 1993), and problems that have some structure that is hidden from the algorithm.
A class of \cluster" problems was presented by Kask and Dechter (1995); these problems
consist of a number of satisfiability problems over independent sets of variables with some
number of clauses connecting the clusters. We repeated our experiments on these problem
distributions to determine if plateaus in these instances exhibit different properties than
the Uniform3-SAT class, and how this might alter the effectiveness of local search. We also
repeated the experiments on unsatisfiable instances of the Uniform3-SAT distribution. Due
to space considerations we do not repeat in full the analysis performed above, but discuss
some differences between the characteristics of the classes we investigated.

4.1 Unsatisfiable Problems
1
Satisfiable Problems
Unsatisfiable Problems

Proportion of Plateaus which are Minima

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1

2

3

4

5
6
Plateau Level

7

8

9

10

Figure 15: Proportion of Plateaus that are Local Minima for Randomly Generated Satisfiable and Unsatisfiable Problems of 100 Variables, 430 Clauses
A major drawback to local search is its inability to distinguish satisfiable problem instances from unsatisfiable problems. We analyzed the plateau structure of unsatisfiable
problem instances from the Uniform3-SAT instance distribution to determine whether there
are differences which would allow local search to determine that a problem instance is unsatisfiable. We repeated the previous empirical studies and collected data on the proportion
265

fiFrank, Cheeseman, & Stutz

and size of plateaus but limited our investigation to problems with 100 variables and 430
clauses. We first present data on the proportion of plateaus that are local minima for unsatisfiable problem instances of 100 variables and 430 clauses. We generated 1000 unsatisfiable
instances using the same problem generation technique used in the previous set of experiments and guaranteed the problem instances were unsatisfiable using a complete search
algorithm. We used GSAT to find states of level 1-10, then generated the corresponding
plateaus. We contrast this data with the same data for satisfiable problem instances of 100
variables and 430 clauses in Figure 15.
Figure 15 shows that the proportion of plateaus that are local minima is similar for
satisfiable and unsatisfiable problems as the plateau level decreases, except that for plateaus
of levels 0 to 5 the proportion is shifted to the right by ome level. A possible interpretation
of this result comes from noting that frequently adding a single randomly generated clause
can turn a random satisfiable instance into an unsatisfiable instance. Hence local search
may become trapped at a higher level in local minima for unsatisfiable problems than for
satisfiable problems.
70

60

Satisfiable Problems
Unsatisfiable Problems

Median Minima Size

50

40

30

20

10

0
0

1

2

3

4

5

Plateau Level

Figure 16: Median Size of Local Minima for Randomly Generated Satisfiable and Unsatisfiable Problems of 100 Variables, 430 Clauses
Next we analyzed the median size of local minima of unsatisfiable problem instances for
minima of levels 1 to 5. Again we analyzed the data from the plateaus found to generate
Figure 15. Since the number of minima is very small for minima of levels 6-10, we could
not gather sucient data for analysis in a reasonable amount of time. However, as Figure
16 shows, local minima for unsatisfiable problems tend to be much smaller than local minima for satisfiable problems. Figure 17 shows the median size of benches for unsatisfiable
problem instances. We found that the median bench size for unsatisfiable instances tended
to be smaller than benches for satisfiable problems. We conjecture that local search may
converge to local minima faster for unsatisfiable problems and that the minima tend to be
266

fiWhen Gravity Fails: Local Search Topology

at a higher level; since minima and benches are smaller and there are more minima at higher
levels, local search should be able to descend faster on the average and become stuck earlier.
Unfortunately, the differences are slight enough that there seems little hope of using these
results to improve the ability of local search to identify unsatisfiable problem instances.
1000
Satisfiable Problems
Unsatisfiable Problems

Median Bench Size

800

600

400

200

0
1

2

3
Plateau Level

4

5

Figure 17: Median Size of Benches for Randomly Generated Satisfiable and Unsatisfiable
Problems of 100 Variables, 430 Clauses

4.2 Instances With Guaranteed Solutions

We next present data on problems with guaranteed solutions as described in (Tsuji &
Gelder, 1993). This generator is the HardSolvable3-SAT generator presented in Appendix
B. Briey, this generator selects an assignment to be a guaranteed solution, then during
generation rejects both clauses that are not satisfied by the assignment and a set of additional clauses that enforce an even distribution of signs for each variable. As before, we
generated 1000 problem instances, each with 100 variables and 380-460 clauses. For each
problem instance we used GSAT to find a state with 1-5 unsatisfied clauses, then determined
whether the corresponding plateau was a bench or a local minimum. Figure 18 shows the
proportion of plateaus that are minima graphed against the number of clauses in problem
instances of 100 variables. The proportion of local minima for these problems is similar but
not identical to the proportions of local minima for the Uniform3-SAT class as shown in
Figure 3. One difference is that local minima appear more prevalent for over-constrained
problems from the HardSolvable3-SAT class than for the Uniform3-SAT class. The second
difference is in the data for plateaus of level 1. The proportion of minima rises slightly from
380 clauses to 430 clauses, then dips sharply; hence there are more benches of level 1 in
Figure 18 than in Figure 3. A detailed analysis of the reasons for the differences is beyond
the scope of this paper, but the generation process seems to eliminate clause combinations
267

fiFrank, Cheeseman, & Stutz

1
0.9

Proportion of Plateaus which are Minima

0.8
0.7
0.6
0.5
0.4
0.3
Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.2
0.1
0
380

390

400

410

420
430
Number of Clauses

440

450

460

Figure 18: Proportion of Plateaus that are Local Minima vs. Number of Clauses for 100
Variable Problem Instances With Guaranteed Solutions
that make for level 1 local minima at the expense of making more minima of higher levels.
The higher percentages of local minima for over-constrained problem instances indicate that
local search may have a harder time solving these problems.
We analyzed the median size of local minima of different levels for the HardSolvable3SAT class and found results similar to those reported for the Uniform3-SAT class in Figure
8. The median minima size for most levels of the HardSolvable3-SAT class are larger than
those of the Uniform3-SAT class for under-constrained instances and somewhat smaller
for over-constrained instances. We also found that the bench size distribution for the
HardSolvable3-SAT class matched that of the Uniform3-SAT class. The median bench size
is somewhat smaller for HardSolvable3-SAT instances than for Uniform3-SAT instances
as the number of clauses in the problem instances grows. We also found that problems
that were guaranteed to have solutions had a higher proportion of exits to bench size than
randomly generated problems. It should not be surprising that this problem class is very
similar to the previously investigated class since the problem generation algorithms are
similar.

4.3 Cluster Problem Instances
We next present an analysis of plateaus for cluster problem instances; the generation
procedure Cluster3-SAT is presented in Appendix B. These instances were created by generating 10 clusters of 10 variables and 34-40 clauses such that no variables are shared between
clusters. The clusters are then linked with 20 connecting clauses such that each linking
clause contains variables from distinct clusters. The total number of clauses in these instances ranges from 360 to 420. As in the earlier experiments, we guaranteed each instance
268

fiWhen Gravity Fails: Local Search Topology

1
0.9

Proportion of Plateaus which are Minima

0.8
0.7
0.6
0.5
0.4
0.3
0.2

Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.1
0
360

370

380

390
Number of Clauses

400

410

420

Figure 19: Proportion of Plateaus that are Local Minima vs. Number of Clauses for 100
Variable Cluster Problem Instances
had a solution using complete search. For each number of clauses in the clusters, we generated 1000 instances and again used GSAT to find plateaus at different levels. We found
these instances took considerably longer to solve than the previous classes, similar to the
results reported in Kask and Dechter (1995) (CPU times are not shown in this paper).
Figure 19 shows the proportion of plateaus that are local minima graphed against the
total number of clauses for cluster problem instances of 100 variables. The proportion of
plateaus that are local minima are less dependent on the number of clauses in comparison
to Figures 3 and 18. As a result there tend to be proportionally fewer local minima for overconstrained cluster problem instances in comparison to Uniform3-SAT instances. Figure 20
shows the median local minima size plotted against the number of clauses in the problem
instances. The local minima for these problem instances are larger than the minima of
Uniform3-SAT instances analyzed by a factor of about 5-10, as seen in Figure 8. We were
unable to collect data for level 0 minima due to the excessive CPU requirements.
Figure 21 shows the median bench sizes plotted against the number of clauses in the
problem instances. When compared to the median bench size of Uniform3-SAT instances
in Figure 11, we see that the median size of benches for cluster problems is dramatically
different. Cluster problem instances with fewer clauses per cluster resulted in enormous
benches, in some cases larger than benches for Uniform3-SAT instances by a factor of 10.
The increase in the size of benches of cluster problem instances over randomly generated
instances is accompanied by a decrease in the proportion of exits to bench size. Figure 22
shows the mean proportion of exits to bench size versus total number of clauses for cluster
problem instances. In comparison to the same measure for Uniform3-SAT instances, shown
in Figure 14, we see that benches for cluster problems have fewer exits than benches for
Uniform3-SAT instances for all bench sizes from 1 to 5. The increase in bench size coupled
269

fiFrank, Cheeseman, & Stutz

1500
Level 1 Minima
Level 2 Minima
Level 3 Minima
Level 4 Minima
Level 5 Minima

1250

Median Minima Size

1000

750

500

250

0
360

370

380

390
Number of Clauses

400

410

420

Figure 20: Median Size of Local Minima vs. Total Number of Clauses for 100 Variable
Cluster Problem Instances

10000
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

9000
8000

Median Bench Size

7000
6000
5000
4000
3000
2000
1000
0
360

370

380

390
Number of Clauses

400

410

420

Figure 21: Size of Benches vs. Total Number of Clauses for 100 Variable Cluster Problem
Instances

270

fiWhen Gravity Fails: Local Search Topology

with the decrease in exits means that local search is likely to have a much harder time
escaping benches for cluster problems than for the other problem classes. This counters the
good news that there are fewer minima for these problems.
0.8
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

Mean Proportion of Exits to Bench Size

0.7

0.6

0.5

0.4

0.3

0.2
360

370

380

390
Number of Clauses

400

410

420

Figure 22: Mean Proportion of Exits to Bench Size vs. Size of Benches for 100 Variable
Cluster Problem Instances

4.4 Summary

In summary, we see that the behavior of plateaus in unsatisfiable Uniform3-SAT problem
instances differs from the behavior of satisfiable instances from the same class. Unsatisfiable instances have proportionally more local minima, smaller minima and smaller benches
than satisfiable instances. Problems from the HardSolvable3-SAT class have more minima
than those from the Uniform3-SAT class, and benches in the HardSolvable3-SAT class instances have more exits than benches in the Uniform3-SAT instances. As a result we expect
problems in the HardSolvable3-SAT class to be harder for local search because local search
algorithms will be more frequently trapped in local minima. Cluster problem instances
have fewer local minima than Uniform3-SAT instances, but tend to have larger benches
with fewer exits. We expect these problems to be harder because local search will have
more trouble escaping benches.

5. Previous Work

Numerous researchers have studied local search techniques for NP -Hard problems, addressing plateau behavior and local minima and how to escape them. However, the research has
largely centered on analyzing the performance of the algorithms and less on the structure
of the problem. Hence, improvements in algorithms are credited to a mechanism without
271

fiFrank, Cheeseman, & Stutz

a clear understanding of the properties of the problem that make the mechanism work. In
this section we review some previous analysis of both algorithms and properties of local
search spaces in light of our new discoveries. While this discussion focuses on GSAT and
similar local search algorithms for the 3-SAT problem, we discuss the potential impact of
our work on local search for other algorithms in the next section.

5.1 Analyzing Properties of Problem Spaces

Clark et al. (1996) studied how the number of solutions affected local search algorithm performance for both 3-SAT problems and for Constraint Satisfaction Problems. They showed
that both the number of solutions and number of constraints play a role in determining
how well GSAT works. Our work complements this study by adding to the understanding
of how local search is affected by problem instance structure. We also add to their results
by showing that solutions tend to occur in disconnected subgraphs of variable size.
Hampson and Kibler (1995) studied how plateaus affect local search's ability to solve
3-SAT problem instances and showed how a local search algorithm could be modified by
performing complete search when a plateau is encountered. They analyzed the ratio of the
number of exits off of benches versus the size of the benches for randomly generated problem
instances at NC =4.25. They found that benches at higher levels are easier to escape on the
average, which is consistent with our findings. However, they failed to mention the high
variance in the proportion of exits of benches, and also failed to report the existence of local
minima. They also report that local search, augmented with complete search of plateaus,
generally performed worse than the original local search. We believe that large plateaus,
while rare, contributed to the large CPU times reported in their paper.
Gent and Walsh (1993a) investigated how GSAT solved problem instances by aggregating statistics of GSAT performance. They collected information on the number of satisfied
clauses as a function of GSAT's ip number, the number of best ips as a function of ip
number, and other statistics averaged over many runs and problem instances. Their study
indicates that GSAT satisfies an average of 99% of the clauses after 2N ips on instances
with NC = 4:3. This works out to be 425 clauses for instances with 100 variables. Our evidence that there are local minima and hard-to-escape benches at level 5 (i.e., 425 satisfied
clauses) is consistent with these results. Gent and Walsh also report that the number of
ips GSAT spends on benches before escaping is highly variable during the second half of
search, when the number of satisfied clauses is very high (Gent & Walsh, 1993a). This is
consistent with our finding that benches can be either very easy or very hard to escape.

5.2 Revisiting Local Search Algorithms

When GSAT encounters a plateau it randomly searches the plateau. If the plateau is a
bench, then GSAT can escape; however it may take a very long time if the bench has very
few exits relative to its size, or if the exits are highly clustered in one region of the bench.
If GSAT encounters a local minimum it will never escape; even if it made a move off the
minimum to a state of higher level, GSAT will simply move back to the minimum, because
every state on the minimum looks better than every state leading away from it. We should
point out that GSAT can escape a local minimum of size 1 because it is forced to make
a move. However, either GSAT will return immediately to this minimum or to another
272

fiWhen Gravity Fails: Local Search Topology

adjacent to the neighbor; as we found so few minima of size 1 and since GSAT doesn't
exhibit such cycling behavior this is a minor consideration.
HSAT (Gent & Walsh, 1993b) augments GSAT with a heuristic designed to break ties.
If HSAT has several ips that are equally good in terms of the number of satisfied clauses,
then it ips the variable ipped longest ago. HSAT will explore benches more effectively
than GSAT by ensuring that variables are ipped \fairly"; as long as HSAT remains on a
bench it will not ip a variable that keeps HSAT on the bench until all other such variables
are ipped. Therefore, HSAT's improved performance may be due to its ability to escape
benches faster than GSAT. However, HSAT is still unable to escape local minima.
Tabu search (Glover, 1989; Mazure, Sais, & Gregoire, 1997) augments local search with
a fixed length list of previously made moves. The algorithm is not allowed to reverse a move
that is on the tabu list. Local search augmented with tabu lists may escape local minima.
The memory structure will either explicitly or implicitly store states on the plateau and
force local search to make moves away from that part of the space. However, due to the
nature of the tabu list, it is possible that local search with one of these variants will ignore
a move which reduces the objective function simply because it is on the Tabu list. This is
because Tabu search frequently stores moves, not states. As a result, different tabu search
implementations allow moves to states with fewer unsatisfied clauses than ever detected to
date, even if the required move is on the tabu list, and thus can avoid this problem. This can
result in tabu search missing exits from benches; whether this results in poor performance
is unknown.
GSAT with random walk (Gent & Walsh, 1995) ips a randomly selected variable with
probability p and uses the standard criteria to select ips with probability 1 , p. This feature
will allow GSAT to escape either local minima or benches, but does not guarantee that the
next move will not simply bring GSAT back into the minima it escaped from This will not
happen if there are multiple, equivalently good moves available. Gent and Walsh (1993a)
report that, when the number of unsatisfied clauses is very small, the number of available
moves leading to a reduction in level for GSAT tends to be 1. However, the effectiveness
of random walk suggests that a random ip will move GSAT into a place where it can
proceed to a solution. Also, if p is large, then two random walk steps can follow each other
in succession, improving the chances of escaping local minima. The fact that this variant
results in substantial improvements even when used with other modifications to GSAT such
as tie-breaking heuristics (Gent & Walsh, 1995) complements our discovery in Section 3
that local minima tend to be shallow; random walk may effectively promote escape from
these local minima into other parts of the search space.
WalkSAT (Kautz & Selman, 1996) does not examine all possible neighbors before moving. Instead, WalkSAT randomly selects an unsatisfied clause and only investigates states
reachable by ipping variables in the selected clause. As a result the neighborhood examined changes from ip to ip, and the reverse move may not be in the next neighborhood
examined. WalkSAT performs much of its search blind to the features we have uncovered.
WalkSAT can escape local minima by simply not choosing a neighborhood containing moves
back onto the minima, or it may take a series of worse moves to escape a bench with many
exits simply because its neighborhood did not contain them.
Simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) only examines a single neighbor of the current assignment. Moves leading to improvements in the objective function are
273

fiFrank, Cheeseman, & Stutz

always accepted, while moves that worsen the objective function are accepted probabilistically; the probability is based on how much worse the move is and how long the search
has progressed. Like WalkSAT, simulated annealing conducts much of its search blind to
plateau features. Simulated annealing can make a backwards move on a bench or minimum
even if a neighboring state results in a forward move; while this can help escape minima
and large benches, it may be a sub-optimal strategy early in search.

6. Next Generation Local Search Algorithms
We have identified and analyzed a number of features of local search topology that may
inuence the success of local search. How can our results be used to improve local search
algorithms? One contribution of this study is to identify features of the local search space
that are worth investigating before beginning construction of a local search algorithm to
solve a new problem. A rapid exploration of the properties of benches and local minima
can be undertaken to determine which local search tactics are likely to work best for this
search problem class. For instance, such an examination might reveal that for one problem
local minima are very prevalent but uniformly small, indicating that explicit local minima
detection and avoidance is likely to be an effective tactic. Also, it is possible to use results
such as those in Figure 3 to determine an adaptive schedule for resetting the probability of
random walk or optimizing the size of the tabu list, as is done in Mazure et. al. (1997). It is
also possible that new classes of local search algorithms could learn which tactics work best
in a manner similar to MultiTac (Minton, 1996). Our study provides a first step towards
identifying features that should be tracked by these self-modifying local search algorithms.
When a local search algorithm starts exhibiting plateau behavior, it may be on a small
minima, a large minima, a bench with many exits, or a bench with few exits. (We ignore
the case of a small bench, since it is not too hard to escape in these cases.) The problem
is to identify which case the search process is stuck in, and then choose the proper tactic
to handle it. Standard tactics include continuing search as normal, invoking a special
detection procedure, randomly ipping one variable as in random walk, randomly ipping
a small number of variables as in Jump-SAT (Gent & Walsh, 1995) or randomly generating
new values for all variables as in randomly restarting.
Small minima can be detected easily using an algorithm such as Breadth-First Search,
as was done by Hampson and Kibler (1995). Once a local search algorithm has detected
and escaped a local minima, it is desirable to prevent it from revisiting the minima it
has escaped. Local search could proceed by \filling in" local minima as they are found
in order to prevent revisiting them. This is approximately how tabu search works, and
other schemes can be used as well. The small size of most local minima indicates that
memory requirements for such a scheme are small as long as only small numbers of minima
are encountered. An algorithm using this mechanism could then explore numerous local
minima that are close together in the solution space without restarting.
Large benches and minima are more dicult to recognize and escape. The question
becomes one of determining the utility of continuing to search versus changing tactics. The
studies we have done provide algorithm designers the information required to implement
the utility computation so that a local search algorithm can intelligently choose from among
its tactics. For instance, knowing that a problem instance is a cluster problem is indicative
274

fiWhen Gravity Fails: Local Search Topology

that large benches with few exits are more likely to inhibit local search than local minima.
Hence explicit local minima detection is not a good strategy for this problem class; jumping
or random restart might be a better strategy.
We should point out that while many enhancements like those proposed above are in
place for local search algorithms to solve 3-SAT problems, these enhancements have not been
applied to other problem classes such as Graph k-Coloring. We expect these extensions to be
successful at improving the performance of local search algorithms to solve these problems.
One way to approach new problems is to spend time gathering information on the topology
of the search space, as we have done in this paper. A second option, as we mentioned
above, is to use knowledge of the local search topology to learn the best tactics while
solving instances. Detailed information on the appearance of local minima, distribution of
local minima size, bench size, and prevalence of exits from benches can then be used to
construct very good local search procedures that explicitly take these factors into account.

7. Conclusions and Future Work
We have presented an analysis of important properties of plateau structures in local search
spaces that can be used by local search algorithm designers to construct better local search
algorithms. We have defined a set of topological structures of local search spaces and shown
how they affect local search. We have provided conclusive evidence of the existence of local
minima in search spaces, and shown that they become more prevalent as the number of
unsatisfied clauses becomes close to 0. We have also shown that plateau behavior in local
search is caused by both local minima and benches. Our results show that both local minima
and benches vary widely in size; while both are most often small, large local minima and
benches may defy detection and avoidance by local search algorithms. We also show how
the characteristics of these structures change with different problem classes. Our analysis
has made it possible to interpret previous work on improving local search in terms of the
search space structure, illuminating the importance of escaping benches early in search and
detecting local minima later in search.
We have made suggestions in the previous section that might be used to create new
versions of local search that are better than the current crop of algorithms. An obvious
next step is to implement these algorithms and analyze their performance, especially in
comparison to existing algorithms that already attempt to escape plateaus.
We have barely begun analyzing the topology of plateaus. While we have some empirical
evidence that local minima of low level (i.e., near 0) can be escaped by unsatisfying only
one additional clause, this may not be true for more structured problem classes. The
evidence that benches may have many exits does not always imply they are easy to escape;
highly clustered exits may make benches hard to escape. Further analysis of the topology
of plateaus for a variety of problem instances will lead to more concrete results that can
inuence local search algorithm development.
It is clear that the nature of plateaus is highly dependent on the problem class being
tested. Extending this form of analysis to other problem classes might reveal differences
in plateau structure that motivate substantially different GSAT variants. Furthermore,
plateaus in Graph Coloring Problem and the Traveling Salesperson Problem may manifest
themselves in different ways than those for 3-SAT, and local search algorithms for these
275

fiFrank, Cheeseman, & Stutz

problems will explore plateaus differently. These differences must be studied in order to
determine how best to apply a new understanding of local search topology. It is also unclear
how this study will extend to such problems as Traveling Salesperson Problem where the
search space may be much \smoother."
While we have collected a large amount of data on local search spaces, we have not
had much success in modeling the features we defined. While it is possible to compute the
probability that an individual state in a search space is on a local minima or is on a bench
with exits, it is very dicult to compute the expected size of a bench or minimum without
making horrendous independence assumptions. Further work on such modeling may result
in a better understanding of local search topology.
As mentioned in Section 2, it is possible to alter our definition of benches to specifically
exclude contours as a type of bench. The rationale is that contours provide no impediment
to greedy local search, and very little impediment to the semi-greedy variations. One
possibility is to change the definition of plateau to only include states without neighbors of
both higher and lower level. There are several predictable effects of this change. First, we
know that some of our reported benches are pure contour regions. These would be eliminated
from consideration in reporting proportions of plateaus that are benches. Second, the size
of the benches would exclude these states, and so we expect to find smaller benches under
the exclusive bench definition. Third, the measurements of the mean proportion of states
on benches that are exits would also change, because excluding contours reduces the mean.
Fourth, these states provide a potential means of linking bench regions that would be disjoint
under the exclusive definition. Thus it is possible that use of the exclusive definition will
cause a dramatic reduction in average bench size, accompanied by an increase in bench
numbers. It might even eliminate the large size tails in the bench size distributions that
we observed using the inclusive definition. This would significantly alter our conclusions
regarding how benches impede local greedy search, and our recommendations regarding
how to deal with such benches. Exploring the impact of such revised definitions in the
explanation of plateau behavior is worth investigating.
Finally, our analysis of topological structures is geared towards analyzing local search
algorithms with greedy objective functions based on the number of unsatisfied constraints.
Many local search algorithm designers are experimenting with new objective functions that
are modified continuously throughout search, as in clause weighting schemes (Selman &
Kautz, 1993). Work of this type may lead to more innovations in the design of objective
functions. Since plateau behavior is rooted in the objective function used, our analysis is
not suitable for analyzing these methods, but may provide insight into how to conduct a
similar study for self-modifying algorithms of this type.

Acknowledgements
We gratefully acknowledge the comments of the JAIR reviewers and editors; we also acknowledge the comments of Phil Rogaway and Chip Martel, both of U.C. Davis.
276

fiWhen Gravity Fails: Local Search Topology

Appendix A. Sample Problem

This section illustrates some of the terms defined in Section 2. Consider the following 4
variable, 14 clause 3-SAT problem instance:
(A _ B _ C )^ (A _ B _ C )^ (A _ B _ C )^
(A _ B _ C )^ (A _ B _ C )^ (A _ B _ C )^
(A _ B _ C )^ (A _ B _ D)^ (A _ B _ D)^
(A _ C _ D)^ (A _ B _ D)^ (A _ B _ D)^
(A _ C _ D)^ (A _ C _ D)
For the duration of this section we will abbreviate assignments of values to variables in
the following way: 0 is False, 1 is True, and hence a string of 0s and 1s of length 4 encodes
an assignment to the variables ABCD in order.
This problem instance has a global minimum comprised of a single solution at 1111.
The single state 0000 is local minimum of size 1 and level 1, i.e., has one unsatisfied clause.
The border of this local minimum consists of the states 1000,0100,0010,0001; states 0001
and 1000 have level 3 and the other two states have level 2.
The following states constitute a bench of level 1: 1001, 1101 and 1011. 1101 is an exit
since ipping C results in 1111, the solution. Similarly, 1011 is also an exit since ipping B
results in the solution. The neighbors of 1001 that are not on the bench are 0001 and 1000;
each of these has level three, so 1001 is not an exit.
State Comment
Level Unsatisfied Clauses
1111 Solution
0
0000 Local Minimum
1
(A _ B _ C )
0010 Border of Minimum 2
(A _ B _ C ); (A _ C _ D)
0100 Border of Minimum 2
(A _ B _ C ); (A _ B _ D)
0001 Border of Minimum 3
(A _ B _ C ); (A _ B _ D); (A _ C _ D)
1000 Border of Minimum 2
(A _ B _ C ); (A _ B _ D)
1001 Bench
1
(A _ B _ C )
1011 Bench
1
(A _ B _ C )
1101 Bench
1
(A _ B _ C )
1111 Border of Bench
0
0001 Border of Bench
3
(A _ B _ C ); (A _ B _ D); (A _ C _ D)
1000 Border of Bench
2
(A _ B _ C ); (A _ B _ D)
0010 Contour
2
(A _ B _ C ); (A _ C _ D)
1010 Contour
2
(A _ B _ D); (A _ B _ C )
0011 Contour
2
(A _ B _ C ); (A _ B _ D)
0000 Border of Contour 1
(A _ B _ C )
1110 Border of Contour 1
(A _ B _ D)
0111 Border of Contour 1
(A _ B _ C )
Figure 23: Some Topological Structures of the Sample Problem Instance
The states 0010, 1010 and 0011 form a level 2 bench which also is a contour. 0010 is a
neighbor of the local minimum at level 1, 1010 is adjacent to 1110 which is at level 1, and
0011 is adjacent to 0111 which is at level 1.
277

fiFrank, Cheeseman, & Stutz

The states 1000 and 1100 form a bench of level 3 which is a contour. Each of the states
0110, 0001 are also contours of level 3 by themselves. Since there are no states unsatisfying
more than three clauses these contours are in fact local maxima.
These features are summarized in Figure 23.

Appendix B. Random Problem Generation
This appendix contains pseudo-code for the random problem classes studied in this paper.
First we present the Uniform3-SAT class. Parameters to this generator are C the number
of clauses and N the number of variables. In this class the procedure selects three literals
without replacement from N and assigns each a negative sign with probability 21 . This
procedure was first presented in Crawford and Auton (1993) and appears in Figure 24.
procedure Uniform3-SAT(C ,N )
=;
for (i=1 to C )

Clause= 3 distinct variables selected uniformly from 1..N
Negate each variable in Clause with probability 12
 =  [ Clause

end for
return 
end

Figure 24: Random Problem Generation Algorithm Sketch
Next we present the Cluster3-SAT problem generator. The parameters are the number of
clauses C , the number of variables N per cluster, the number of clusters M , and the number
of linking clauses L. This generator builds instances by first creating M independent subproblems of C clauses and N variables each, using the Uniform3-SAT generation procedure
described above. The variables of these sub-problems are relabeled so that no sub-problem
shares variables with any other sub-problem; sub-problems are then linked by generating
L linking clauses. Each linking clause contains variables from three distinct sub-problems.
Kask and Dechter generate these problems using the HardSolvable3-SAT procedure defined
below as described in Kask and Dechter (1995). The procedure appears in Figure 25.
Finally we present the HardSolvable3-SAT generator. The parameters are the number
of clauses C and the number of variables N . Instances are generated by first selecting
an assignment S to be a guaranteed solution. Clauses are generated as in Uniform3-SAT,
however if a clause has either zero or two satisfied literals under the selected assignment it is
rejected. For instance, the clause (A _ B _ C ) would be rejected if the assignment S was 110
since it has two satisfied literals under this assignment. This preserves a uniform balance of
signs for each variable in the limit, resulting in little information about the solution being
present in sign balances in the problem instance. This method is discussed further in Tsuji
and Van Gelder (1993) and the algorithm is given in Figure 26.
278

fiWhen Gravity Fails: Local Search Topology

procedure Cluster3-SAT(C ,N ,M ,L)

# First generate M sub-problems with distinct variables
for i=1 to M
,i =Uniform3-SAT(,,C ,N )
Re-label literals in ,i so that no sub-problem shares variables
 = [M
i=1 ,i
end for

# Next generate linking clauses
for i = 1 to L
Randomly select 3 distinct sub-problems ,a ; ,b ; ,c from the ,i s
Clause= one variable randomly selected from each of ,a ; ,b ; ,c
Negate each variable in Clause with probability 21
 =  [ Clause

end for
return 
end

Figure 25: Cluster Problem Generation Algorithm Sketch

procedure HardSolvable3-SAT(C ,N )
=;

S = randomly generated assignment to the variables
while (i < C )

Clause= 3 distinct variables selected uniformly from 1..N
Negate each variable in Clause with probability 21
# Check to make sure Clause allowed in formula under S
if (1 or 3 literals of Clause true under S )
 =  [ Clause
i++

end if
end while
return 
end

Figure 26: \Hard" Guaranteed Satisfiable Problem Generation Algorithm Sketch

279

fiFrank, Cheeseman, & Stutz

A final note on random problem instance generation is in order. None of these procedures
guarantees that the resulting problem instance will contain all the variables. If a large
number of variables and a small number of clauses are used as parameters, then the resulting
problem may not contain all variables. However, for the ranges of clauses and variables used
in this work all problem instances had the full range of variables.

References
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). Where the really hard problems are.
12th International Joint Conference on Artificial Intelligence, 163{169.
Clark, D., Frank, J., Gent, I., MacIntyre, E., Tomov, N., & Walsh, T. (1996). Local
search and the number of solutions. Proceedings of the 2d International Conference
on Principles and Practices of Constraint Programming, 119{133.
Crawford, J., & Auton, L. (1993). Experimental results on the crossover point in satisfiability problems. Proceedings of the 11th National Conference on Artificial Intelligence,
21{27.
Gent, I., & Walsh, T. (1993a). An empirical analysis of search in GSAT. Journal of Artificial
Intelligence Research, 1, 47{59.
Gent, I., & Walsh, T. (1993b). Towards an understanding of hill-climbing procedures for
SAT. Proceedings of the 11th National Conference on Artificial Intelligence, 28{33.
Gent, I., & Walsh, T. (1995). Unsatisfied variables in local search. In Hallam, J. (Ed.),
Hybrid Problems, Hybrid Solutions, pp. 73{85. IOS Press.
Glover, F. (1989). Tabu search part I. ORSA Journal on Computing, 1 (3), 190{206.
Hampson, D., & Kibler, S. (1995). Large plateaus and plateau search in boolean satisfiability problems: When to give up searching and start again. In Johnson, D., & Trick,
M. (Eds.), DIMACS Series in Discrete Mathematics and Theoretical Computer Science: Cliques, Colors and Satisfiability, Vol. 26, pp. 437{456. American Mathematical
Society.
Kask, K., & Dechter, R. (1995). GSAT and local consistency. Proceedings of the 14th
International Conference on Artificial Intelligence, 616{622.
Kautz, H., & Selman, B. (1996). Pushing the envelope: Planning, propositional logic and
stochastic search. Proceedings of the 13th National Conference on Artificial Intelligence, 1194{1201.
Kirkpatrick, S., Gelatt, C., & Vecchi, M. (1983). Optimization by simulated annealing.
Science, 220 (4598), 671{680.
Mazure, B., Sais, L., & Gregoire, E. (1997). Tabu search for GSAT. Proceedings of the 14th
National Conference on Artificial Intelligence, 281{286.
280

fiWhen Gravity Fails: Local Search Topology

Minton, S. (1996). Automatically configuring constraint satisfaction programs: A case
study. Constraints, 1 (2), 7{43.
Selman, B., & Kautz, H. (1993). Domain independent versions of GSAT: Solving large
structured satisfiability problems. 13th International Joint Conference on Artificial
Intelligence, 290{295.
Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satisfiability
problems. Proceedings of the 11th National Conference on Artificial Intelligence, 440{
446.
Tsuji, Y., & Gelder, A. V. (1993). Incomplete thoughts about incomplete satisfiability
procedures. Proceedings of the 2d DIMACS Challenge.

281

fiJournal of Artificial Intelligence Research 7 (1997) 161-198

Submitted 5/97; published 11/97

Storing and Indexing Plan Derivations through
Explanation-based Analysis of Retrieval Failures
Laurie H. Ihrig
Subbarao Kambhampati

Department of Computer Science and Engineering
Arizona State University
Tempe, AZ 85287-5406

ihrig@asu.edu
rao@asu.edu

Abstract

Case-Based Planning (CBP) provides a way of scaling up domain-independent planning
to solve large problems in complex domains. It replaces the detailed and lengthy search
for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch)
planning. However, the performance improvements it provides are dependent on adequate
judgements as to problem similarity. In particular, although CBP may substantially reduce planning effort overall, it is subject to a mis-retrieval problem. The success of CBP
depends on these retrieval errors being relatively rare. This paper describes the design and
implementation of a replay framework for the case-based planner dersnlp+ebl. dersnlp+ebl extends current CBP methodology by incorporating explanation-based learning
techniques that allow it to explain and learn from the retrieval failures it encounters. These
techniques are used to refine judgements about case similarity in response to feedback when
a wrong decision has been made. The same failure analysis is used in building the case
library, through the addition of repairing cases. Large problems are split and stored as
single goal subproblems. Multi-goal problems are stored only when these smaller cases fail
to be merged into a full solution. An empirical evaluation of this approach demonstrates
the advantage of learning from experienced retrieval failure.

1. Introduction
Case-Based Planning improves the eciency of plan generation by taking advantage of previous problem-solving experiences. It has been shown to be an effective method for scaling
up domain-independent planning to solve large problems in complex domains (Kambhampati & Hendler, 1992; Veloso, 1994). CBP involves storing information about the particular
planning episodes in which problems are successfully solved. This information may include
the goals that were achieved, the world state conditions which were found to be relevant
to their achievement, the final plan and the decisions that were taken in arriving at this
plan. Whenever a new problem is encountered, a judgment is made about its similarity to
these previous experiences. Similar cases are then reused and extended in the search for a
solution to the new problem. For example, the previous plan may be transformed into a
skeletal plan which is then further refined into a new solution (Friedland & Iwasaki, 1985;
Kambhampati & Hendler, 1992; Hanks & Weld, 1995). Multiple cases, each corresponding
to a small subproblem, may be combined and extended in solving a single larger problem
(Redmond, 1990; Ram & Francis, 1996). Alternatively, plan derivations may be replayed
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiIhrig & Kambhampati

to provide guidance to a new search process (Veloso, 1994; Ihrig & Kambhampati, 1994a).
CBP improves problem-solving in that problems are solved in less time in comparison to
generative planning.
One of the most challenging tasks in CBP is in determining which cases to store and how
to match these cases to a new problem-solving context. In a complex domain, it is unlikely
that the same problem will be seen more than once. Moreover, if every problem solved
is stored, the library will be large and the cost associated with retrieval may overshadow
any gains that it provides (Koehler, 1994; Francis & Ram, 1995). Ultimately, we would
like to retain in the library a minimum number of cases such that all new problems are
solved through the ecient retrieval and adaptation of the cases that are stored (Smyth &
Keane, 1995). However, in complex domains, the planner's theory of problem similarity is
incomplete (Barletta & Mark, 1988). It does not have information about all of the relevant
features of a new situation which determine if a stored case will be applicable. Sometimes
a new problem will contain extra goals and/or changed initial state conditions. These
changes may mean that a solution cannot be found which is consistent with the earlier
planning decisions made in a stored episode. If the planner cannot predict ahead of time
that these previous choices are wrong for the current situation, it will experience a retrieval
error.
In this paper, we introduce dersnlp+ebl (DERivational Systematic NonLinear Planner
+ Explanation-Based Learning), a CBP system which like priar (Kambhampati & Hendler,
1992) and spa (Hanks & Weld, 1995) is based on a sound and complete domain-independent
planner. dersnlp+ebl deals with the mis-retrieval problem by allowing the planner to
learn from its planning failures so that it may anticipate future errors. Failure explanations
are automatically generated from the search process which is used in extending the case to
the new problem-solving situation. These are used in building the case library through the
addition of repairing cases.
Although earlier systems such as chef (Hammond, 1990) have exploited EBL techniques, their use is restricted to reasoning about the correctness of the plans generated by
the case-based planner. In contrast, dersnlp+ebl starts with a sound and complete plan
synthesis strategy. The emphasis here is on improving the performance of the base-level
planner through the guidance of the retrieved cases. This guidance is considered to succeed
if it leads the planner down a search path leading to a solution to the new problem. A
retrieval error occurs when the planner is directed down a wrong path in its search for a
solution, that is, a path that does not lead to a solution. dersnlp+ebl extends current
CBP methodology through EBL techniques which are employed in the automatic generation of reasons for a retrieval failure. Analytical failures that occur in the leaf nodes of
the search tree are explained in terms of subsets of conicting plan constraints. These leaf
node failure explanations are regressed up the failing search paths to form a reason for the
retrieval failure.
dersnlp+ebl builds and indexes the case library based on this failure analysis. The
failure reason is used in the construction of a new repairing case. For example, if a retrieved
case fails due to the presence of an extra interacting goal which is not covered in the retrieved
episodes, an explanation for the failure is formed which identifies the subset of new input
goals which are negatively interacting. The failure reason is used to construct a new case
which solves those goals alone. The same failure analysis is also employed in refining the
162

fiStoring and Indexing Plan Derivations

Retriever

Library

Cases Problem

Planning
Problem

Storer

Plan Derivation
Case Failure Reason

Case-Based Planner
Replay/Extension[Recovery]

Problem
Solution

Domain Operators

Figure 1: A schematic diagram illustrating the approach of dersnlp+ebl.
indexing in the case library to both censor the retrieval of the failing case whenever the
interacting goals are present again, and to direct the retriever to a new repairing case which
avoids the failure.
dersnlp+ebl's failure-based storage strategy limits the size of the case library. Library
size is reduced by splitting problems into single goal subproblems, and storing these separately. Large problems are then solved through the retrieval and adaptation of multiple
instances of these smaller cases. Multi-goal problems are stored only when the retrieved
cases fail to be merged and extended into a full solution. We will describe empirical studies
which demonstrate substantial improvements in performance with this novel approach to
multi-case adaptation.
The remainder of the paper is organized as follows: Section 2 describes how dersnlp+ebl learns from case failure to improve its case retrieval. It also reports some
preliminary experiments testing this learning component. Section 3 provides ecient techniques used to store, retrieve and adapt multiple cases. It describes experiments to test
dersnlp+ebl's method of plan merging. Section 4 describes an evaluation of the full dersnlp+ebl system when solving large problems drawn from a complex domain. Section 5
relates our work to previous case-based planners, including chef and prodigy/analogy.
Section 6 provides a summary.

2. Learning from Case Failure
As stated earlier, dersnlp+ebl is based on a complete and correct domain-independent
planning strategy. Like priar (Kambhampati & Hendler, 1992) and spa (Hanks & Weld,
1995), it is implemented on a partial-order planner. In this aspect it differs from statespace systems such as prodigy/analogy (Veloso & Carbonell, 1993a; Veloso, 1994) and
paris (Bergmann & Wilke, 1995). Like prodigy/analogy, it employs the case adaptation
strategy, derivational replay which stores planning experience in the form of successful plan
derivations. Previous decisions made in earlier planning episodes become instructions to
guide the search process in solving the new problem. Derivational replay includes all of the
following elements, as illustrated in Figure 1 (Veloso, 1994; Veloso & Carbonell, 1993a): a
facility within the underlying planner to generate a trace of the derivation of a plan, the
163

fiIhrig & Kambhampati

null
plan

skeletal
plan
e1

final
plan

X
e2 X e3 X
- - - - - - - - - - - - - - - - - - - -depth limit
X

Figure 2: Multiple derivation traces (each a sequence of decisions shown in the figure as
rectangles) are used to guide the new search process. In the figure, a solution
could be reached only by backtracking over the skeletal plan, which now lies
outside the new plan derivation (shown as filled circles).
indexing and storage of the derivation trace in a library of previous cases, the retrieval of
multiple cases in preparation for solving a new problem, and finally, a replay mechanism
by which the planner employs the retrieved plan derivations as a sequence of instructions
to guide the new search process.
dersnlp+ebl's methodology depends on aspects that it has in common with molgen
(Friedland & Iwasaki, 1985) and priar (Kambhampati & Hendler, 1992). It requires an
eager case adaptation strategy, so that a skeletal plan will be constructed which contains
all of the constraints added on the advice of the retrieved cases, and only those constraints.
This is to separate the failure resulting from the previous guidance from any subsequent
planning effort. In eager case adaptation, the planning decisions which are encapsulated
in the retrieved cases are greedily adopted before these decisions are extended to solve any
extra goals not covered. Multiple retrieved plan derivations are replayed in sequence to
produce the skeletal plan which then contains all of the recommended plan constraints.
The planner returns to from-scratch planning only after all of the previous decisions in
the retrieved cases have been visited. The skeletal plan is then further refined to achieve
any goals left open. Previous work has demonstrated the effectiveness of this approach to
plan-space replay as well as its advantage over state-space replay (Ihrig & Kambhampati,
1994a, 1994b).
Eager case adaptation can also be described as extension-first. The skeletal plan is
first extended in the search for a solution, and, only after this extension fails, is the plan
backtracked over, discarding the plan constraints which were added on the advice of previous
episodes. The general approach to case adaptation therefore involves three distinct phases:
case replay, case extension, and, if extension fails, recovery. During the search process
employed in extending the skeletal plan, the planner constructs an explanation for the
plan's failure which becomes a reason for the case retrieval failure. Explanations are formed
for the analytical failures that occur in the leaf nodes directly under the skeletal plan (See
Figure 2). An analytical failure is explained by a set of inconsistent plan constraints. These
failure explanations are immediately regressed up the search paths as they are encountered.
The regressed explanations are collected at the root of the tree to form a reason for the
164

fiStoring and Indexing Plan Derivations

l1

l1

OB1

ld

ld

lp

lp

l2

OB2

l2

(b) New Problem with Extra
Goal

(a) Previous Plan

Figure 3: (a) A plan to accomplish the transport of a single package, ob1, to the destination
airport ld . (b) A new problem contains an extra goal which involves the additional
transport to ld of a second package, ob2.
retrieval error. dersnlp+ebl detects that a retrieval error has occurred when all ways
of refining the skeletal plan have been tried, and the planner is forced to backtrack over
this plan. At this point the failure reason is fully constructed. Performing skeletal plan
extension as a separate process prior to recovery allows the planner to identify the retrieval
error in terms of the failure of the skeletal plan, and to construct a reason for the failure.
This reason is then communicated to the Storer to be used in augmenting the library with
a new repairing case.
Consider a simple example illustrated in Figure 3 which is taken from the Logistics
Transportation domain shown in Figure 4. The goal is to have package ob1 located at the
destination location ld. The package is initially at location l1 . There is a plane located at
lp which can be used to transport the package. Figure 3a illustrates a previous plan which
contains steps that determine the plane's route to the destination airport as well as steps
which accomplish the loading of the package at the right place along this route. Eagerly
replaying these earlier step addition decisions for a new problem in which there is an extra
package to transport produces a skeletal plan which may readily be extended to include
the loading and unloading of the extra package as long as this package lies along the same
route. However, if the new package is off the old route, the planner may not be able to
solve the extra goal without backtracking over some of its previous step addition decisions.
(See Figure 3b).
A case failure reason is shown in Figure 5. It gives the conditions under which a future
replay of the case will again result in failure. These conditions refer to the presence in
the new problem of a set, C , of negatively interacting goals, as well as some initial state
conditions, contained in E . A summary of the information content of the failure reason is:
There is an extra package to transport to the same destination location, and that package
is not at the destination location, is not inside the plane, and is not located on the plane's
route.
165

fiIhrig & Kambhampati

action
precond
add
delete

(LOAD-TRUCK ?O ?T ?L)
(AT-OB ?O ?L)
(AT-TR ?T ?L)
(INSIDE-TR ?O ?T)
(AT-OB ?O ?L)

action
precond
add
delete

(LOAD-PLANE ?O ?P ?L)
(AT-OB ?O ?L)
(AT-PL ?P ?L)
(INSIDE-PL ?O ?P)
(AT-OB ?O ?L)

action
precond
add
delete

(UNLOAD-TRUCK ?O ?T ?L)
(INSIDE-TR ?O ?T)
(AT-TR ?T ?L)
(AT-OB ?O ?L)
(INSIDE-TR ?O ?T)

action
precond
add
delete

(UNLOAD-PLANE ?O ?P ?Li)
(INSIDE-PL ?O ?A)
(AT-PL ?P ?Li)
(AT-OB ?O ?Li)
(INSIDE-PL ?O ?A)

action
precond
add
delete
equals

(DRIVE-TRUCK ?T ?Li ?Lg)
(AT-TR ?T ?Li)
(SAME-CITY ?Li ?Lg)
(AT-TR ?T ?Lg)
(AT-TR ?T ?Li)
(NOT (?Li ?Lg))

action
precond
add
delete
equals

(FLY-PLANE ?P ?Li ?Lg)
(IS-A AIRPORT ?Lg)
(AT-PL ?P ?Li))
(AT-PL ?P ?Lg)
(AT-PL ?P ?Li)
(NOT (?Li ?Lg))

Figure 4: The specification of the Logistics Transportation Domain adapted for our experiments
Subsequent to backtracking over the skeletal plan, the planner continues its search, and
will go on to find a solution to the full problem if one exists. This new solution achieves
all of the negatively interacting goals identified in the failure reason. Moreover, since these
goals represent a subset of the problem goals, the new derivation may be used to construct
a case covering these goals alone. dersnlp+ebl stores the new case directly beneath the
failing case so as to censor its retrieval. This is to ensure that whenever the failure reason
holds (for example, whenever there is an extra package which is off the plane's route), the
retriever is directed away from the failing case and toward the case that repairs the failure.
We are now in a position to describe in more detail dersnlp+ebl's eager derivation
replay strategy, as well as how it learns the reasons underlying a case failure.

2.1 Eager Derivation Replay

The derivation trace contains a sequence of instructions representing the choices that lie
along the derivation path leading from the root of the search tree to the final plan in the leaf
node. The trace is fitted to the context of the new search process by validating each choice
in the new context, and replaying the decision if valid. In order to understand the validation
process, we must first describe the decision steps that the planner takes in arriving at a
solution to a planning problem. A planning problem is a 3-tuple hI; G; Ai, where I is a
complete description of the initial state, G is the description of the goal state, and A is
the set of operators in strips representation (Fikes & Nilsson, 1971). A ground operator
sequence is said to be a solution for a planning problem if it can be executed from the initial
state, and the resulting state of the world satisfies the goal.
dersnlp+ebl is a refinement planner that solves a planning problem by navigating a
space of potential solutions, each represented as a partly constructed plan1 . Syntactically, a
1. For a more formal development of the refinement search semantics of partial plans, we refer the reader
to the work of Kambhampati, Knoblock, and Yang (1995).

166

fiStoring and Indexing Plan Derivations

Case Failure Explanation:
C = f h(AT-OB OB1 ld); tG i; h(AT-OB OB2 ld); tG i g
E = f htI ; (:AT-OB OB2 ld)i; htI ; (:INSIDE-PL OB2 ?PL )i;
htI ; (:AT-OB OB2 l1)i; htI ; (:AT-OB OB2 lp)i g

Figure 5: An Example of a case failure reason
plan in this space P can be seen as a set of constraints (see below). Semantically, a partial
plan is a shorthand notation for the set of ground operator sequences that are consistent
with its constraints. The latter is called the candidate set of the partial plan, and is denoted
by hhPii. In particular, a partial plan is represented as a 6-tuple, hS ; O; B; L; E ; Ci, where
1. S is the set of actions (step names) in the plan, each of which is mapped onto an
operator in the domain theory. S contains two dummy steps: tI whose effects are the
initial state conditions, and tG whose preconditions are the input goals, G.
2. B is a set of codesignation (binding) and non-codesignation (prohibited binding) constraints on the variables appearing in the preconditions and post-conditions of the
operators which are represented in the plan steps, S .
3. O is a partial ordering relation on S , representing the ordering constraints over the
steps in S .
4. L is a set of causal links of the form hs; p; s0 i where s; s0 2 S .
5. E contains step effects, represented as hs; ei, where s 2 S .
6. C is a set of open conditions of the partial plan, each of which is a tuple hp; si such
that p is a precondition of step s and there is no link supporting p at s in L.
Planning consists of starting with a null plan (denoted by P;) , whose candidate set
corresponds to all possible ground operator sequences, and successively refining the plan by
adding constraints until a solution is reached. Each planning decision represents a choice as
to how to resolve an existing aw in the plan, which is either an open condition (unachieved
goal) or a threat to a causal link. To understand how these choices are validated during
the replay process it is useful to think of a planning decision as an operator acting on
a partly-constructed plan. The possible choices available to dersnlp+ebl are shown in
Figure 6.
Planning decisions have preconditions which are based on the existence of a aw in
the current active plan and have effects which alter the constraints so as to eliminate the
aw. For example, the precondition of an establishment choice is specified in terms of the
existence of an unachieved subgoal. The effect is the addition of a causal link that achieves
this open condition. The precondition of a resolution decision is a threat in that one step
is clobbering an existing causal link. A threat is resolved by adding a step ordering which
either promotes or demotes the clobberer relative to the causal link.
167

fiIhrig & Kambhampati

Type : ESTABLISHMENT
Kind : NEW STEP
Preconditions
:
hp0 ; s0 i 2 C
Effects
:
S 00 = S [ fsg 0
O0 = O [ fs  s g 0
B 0 = B [ unify(p;0 p )
L = L [ fhs; p;s ig
E 0= E [ effects
(s)
C = C , fhp0 ; s0 ig
[ preconditions(s)

Type : ESTABLISHMENT
Kind : NEW LINK
Preconditions
:
hp0 ; s0 i 2 C
Effects
:
O00 = O [ fs  s0 g 0
B 0 = B [ unify(p;0 p )
L0 = L [ fhs;p;
s ig
C = C , fhp0 ; s0 ig

Type : RESOLUTION
Kind : PROMOTION
Preconditions
:
0
0

hs; p ; s i 2 L
ht; :p i 2 E
ft  sg; fs  tg 62 O
Effects :
O = O [ ft  sg
0

0

0

Type : RESOLUTION
Kind : DEMOTION
Preconditions
:
0
0

hs; p ; s i 2 L
ht; :p i 2 E
ft  sg; fs  tg 62 O
Effects :
O = O [ fs  tg
0

0

0

0

Figure 6: Planning decisions are based on the active plan hS ; O; B; L; E ; Ci and have effects which alter the constraints so as to produce the new current active plan
hS 0 ; O0 ; B0 ; L0 ; E 0 ; C 0 i.
Before a decision is replayed, it is first compared with the current active plan to determine whether its precondition holds in the new context. Invalid decisions, those whose
preconditions don't match, are skipped. Establishment decisions are ignored if the goals
they achieve are not present as open conditions in the current active plan. Threat resolutions are skipped if the threat is not present. Previous choices which are justified in the
current situation are used as guidance to direct the new search process. Replaying a valid
decision involves selecting a match for that decision from the children of the current active
plan, and making this child the next plan refinement.
dersnlp+ebl's eager derivation replay strategy replays all of the applicable decisions
in the trace in sequence. This replay strategy can be contrasted with that of
prodigy/analogy (Veloso, 1994) where replay is alternated with from-scratch planning
for extra goals not covered by a case. In eager derivation replay each previous decision
is eagerly adopted if justified in the current context. Since invalid instructions have been
skipped, the skeletal plan which is the end result of replay is comparable to the product of
the fitting phase in plan reuse (Kambhampati & Hendler, 1992; Hanks & Weld, 1995). In
contrast to plan reuse, derivation replay does not alter the underlying planning strategy.
Replay merely provides search control, directing the search as to which node to visit next.
This means that dersnlp+ebl inherits all of the properties of snlp, including soundness,
completeness, and systematicity.
A sample trace of snlp's decision process is shown in Figure 7. The trace corresponds
to a simple problem from the logistics transportation domain of (Veloso, 1994) adapted for
snlp as in Figure 4. This problem contains the goal of getting a single package, ob1, to a
designated airport, ld . The derivation trace contains the choices that were made along the
path from the root of the search tree to the final plan in the leaf node. Instructions contain
a description of both the decision taken and its basis for justification in a new context.

2.2 Eager Case Extension and Recovery
The decisions in the trace that are skipped during replay are only those that are known a
priori to be unjustified. This does not guarantee that the skeletal plan which is left will
168

fiStoring and Indexing Plan Derivations

Goal : (AT-OB OB1 ld )
Initial : ((IS-A AIRPORT ld ) (IS-A AIRPORT li ))
(IS-A AIRPORT lp ) (AT-PL PL1 lp )
(AT-OB OB1 li ) ...
Name : G1
Name : G7
Type : START-NODE
Type : ESTABLISHMENT
Name : G2
Kind : NEW LINK
Type : ESTABLISHMENT
New Link: (0 (IS-A AIRPORT ld ) 2)
Kind : NEW STEP
Open Cond: ((IS-A AIRPORT ld ) 2)
New Step: (UNLOAD-PL OB1 ?P1 ld )
Name : G8
New Link: (1 (AT-OB OB1 ld ) GOAL)
Type : ESTABLISHMENT
Open Cond: ((AT-OB OB1 ld ) GOAL)
Kind : NEW STEP
Name : G3
New Step: (LOAD-PL OB1 PL1 ?A4)
Type : ESTABLISHMENT
New Link: (4 (INSIDE-PL OB1 PL1) 1)
Kind : NEW STEP
Open Cond: ((INSIDE-PL OB1 PL1) 1)
New Step: (FLY-PL ?P1 ?A2 ld )
Name : G9
New Link: (2 (AT-PL ?P1 ld ) 1)
Type : ESTABLISHMENT
Open Cond: ((AT-PL ?P1 ld ) 1)
Kind : NEW LINK
Name : G4
New Link: (3 (AT-PL PL1 li ) 4)
Type : ESTABLISHMENT
Open Cond: ((AT-PL PL1 ?A4) 4)
Kind : NEW STEP
Name : G10
New Step: (FLY-PL ?P1 ?A3 ?A2)
Type : RESOLUTION
New Link: (3 (AT-PL ?P1 ?A2) 2)
Kind : PROMOTION
Open Cond: ((AT-PL ?P1 ?A2) 2)
Unsafe-link : ((3 (AT-PL PL1 li ) 4)
Name : G5
Effect : 2 :(AT-PL PL1 li ))
Type : ESTABLISHMENT
Name : G11
Kind : NEW LINK
Type : ESTABLISHMENT
New Link: (0 (AT-PL PL1 lp ) 3)
Kind : NEW LINK
Open Cond: ((AT-PL ?P1 ?A3) 3)
New Link: (0 (AT-OB OB1 li ) 4)
Name : G6
Open Cond: ((AT-OB OB1 li ) 4)
Type : ESTABLISHMENT
Key to Abbreviations:
Kind : NEW LINK
PL = PLANE
New Link: (0 (IS-A AIRPORT li ) 3)
OB = OBJECT
Open Cond: ((IS-A AIRPORT ?A2) 3)
Final Plan: (FLY-PL PL1 lp li ) Created 3
(LOAD-PL OB1 PL1 li ) Created 4
(FLY-PL PL1 li ld ) Created 2
(UNLOAD-PL OB1 PL1 ld ) Created 1
Ordering of Steps: ((4 < 2) (3 < 4) (4 < 1) (3 < 2) (2 < 1))

Figure 7: An Example solution trace for dersnlp+ebl

169

fiIhrig & Kambhampati

2 DmS 1 :
(Affi precond : fIi; Pff g add : fgig delete : fIj jj < ig)
(Afii precond : fIi Pfi g add : fgig delete : fIj jj < ig)
(Aff precond : fg add : fgff g delete : fPfi g [ fgij8ig)

Figure 8: The specification of Barrett and Weld's Transformed Dm S 1Domain
ultimately be refined into a solution for the current problem. Without actually completing
the search there is no way of predicting whether the constraints that are left in the skeletal
plan are consistent with a complete solution. Whenever the skeletal plan is not complete
(whenever there are extra goals or unsatisfied initial state conditions) the planner must
undergo further planning effort to extend the plan and there is a possibility that this effort
may fail, necessitating a recovery phase.
For dersnlp+ebl, the skeletal plan is extended first, prior to recovery. This plan is
backtracked over only after the search process fails to refine it into a full solution to the new
problem. This strategy requires a depth limit to be placed on the search tree2 . Otherwise
skeletal plan extension may continue indefinitely, and the planning algorithm becomes incomplete. An eager extension strategy is not, however, linked to a particular search method.
For example, it may be used with best-first, depth-first or iterative deepening search. These
different search methods are used in the exploration of the subtree under the skeletal plan,
prior to backtracking over this plan. Once the skeletal plan is found to fail, the recovery
phase that is initiated merely involves exploring the siblings of the replayed path. Like
extension, recovery is not linked to a particular search strategy.

2.3 Analyzing the Failure of Case Extension

In order for the skeletal plan to be successfully extended to achieve any conditions left open,
the sequence of decisions that were adopted through the guidance of a previous trace must
be concatenated with further choices to arrive at a solution. For this to occur, the replayed
path must be decision-sequencable with respect to the new problem, which is defined as
follows:

Definition 1 (Decision-Sequencable Search Path) A search path which contains a sequence of decisions D is decision-sequencable with respect to a new problem, hI 0 ; G0 ; Ai , if
and only if there exist two decision sequences E and E 0 such that E  D  E 0 (where \" is
the decision sequencing operator) will produce a plan which is correct for hI 0 ; G0 ; Ai.
One of the primary reasons a replayed path may not be decision sequencable is the goal
interactions that occur between the input goals of the new problem. In particular, the extra
goals not achieved by a case may interact with those that are covered, making the retrieved
case inapplicable. It has long been recognized that the relative diculty of problem-solving
is linked to the level of interaction between the various input goals of the problem (Korf,
1987; Joslin & Roach, 1990; Barrett & Weld, 1994; Veloso & Blythe, 1994; Kambhampati,
2. In practice, this limit is actually a bound placed on the number of steps contained in the plan.

170

fiStoring and Indexing Plan Derivations

Ihrig, & Srivastava, 1996a). Goal interaction has been formalized by Korf (1987) in terms
of the problem search space. Barrett and Weld (1994) extend Korf's analysis into plan
space. For the plan-space planner, the order in which goals are achieved is not as crucial.
Goals that are laboriously serializable for a state-space planner (in that there exist few goal
orderings for which the goals may be solved in sequence) may be trivially serializable for a
plan-space planner (meaning that the goals can be solved in any order).
However, goals are not always trivially serializable for the plan-space planner (Veloso &
Blythe, 1994). For example, consider the 2Dm S 1 domain (Barrett & Weld, 1994) shown
in Figure 8. Notice that if gff is one of a set of problem goals, and it is not true initially,
then any other goal, gi , that is present in the set must be achieved by the operator Affi, and
not by Afii . This means that any time a case is replayed that previously solved a goal, gi ,
through an action Afii , and gff is an extra goal not covered by the case, replay will fail.
In CBP, however, we are not so much concerned with the general properties of the
domain, as we are with properties of the particular search paths which are stored in the
case library. It is not required that the input goals of every problem be trivially serializable
for CBP to be beneficial to planning performance. If it were, there would be very few
domains in which CBP was effective. Trivial serializability is not a requirement since it
is not necessary that every plan for every subset of the input goals be consistent with a
solution to the full problem. It is only the particular plans that are retrieved from the
library that we are concerned with.
Even if the goals of the problem are not trivially serializable, replay may be decision
sequencable, depending on which cases are actually retrieved from the library. In the
2 Dm S 1 domain, if the single-goal cases that are retrieved solve gi through the action Afii ,
then these will not be decision-sequencable with any new multi-goal problem which contains
the goal gff . However if the stored cases are solved through Affi , then replay of these cases
will be sequencable. In fact, the aim of the dersnlp+ebl's learning component is to achieve
an indexing within the case library such that all of the new problems encountered by the
planner may be solved through sequenced replay of the cases retrieved from that library.
The next section describes how dersnlp+ebl is able to work towards this objective through
its learning component which learns from replay failures.

2.4 Constructing Reasons for Retrieval Failure
dersnlp+ebl constructs explanations for retrieval failures through the use of explanationbased learning techniques which allow the planner to explain the failures of individual plans
in the planner's search space. A leaf node plan represents an analytical failure when it
contains a set of inconsistent constraints which prevent the plan from being further refined
into a solution. An analytical failure is explained in terms of these constraints (Kambhampati, Katukam, & Qu, 1996b). Leaf node failure explanations identify a minimal set of
constraints in the plan which are together inconsistent. dersnlp+ebl forms explanations
for each of the analytical failures that occur in the subtree directly under the skeletal plan.
These are regressed up the failing search paths and are collected at the root of the tree to
form a reason for the retrieval failure (See Figure 9a). The regressed explanation is in terms
of the new problem specification. It contains a subset of interacting goals, as well as initial
state conditions relevant to those goals.

171

fiIhrig & Kambhampati

null
plan

e11

< (AT-OB OB2 ld), tG >
<tI ,  (AT-OB OB2 ld ) >

e1f-1
df-1
e1f
df
e1

null
plan

< (AT-OB OB2 ld), tG >
<tI ,  (AT-OB OB2 ld) >

skeletal
plan

df-1
df

skeletal
plan

X

X
e2

X

e3

X

< tI , (AT-OB OB2 ld ), tG >
< tI ,  (AT-OB OB2 ld) >

(a) The Regression Process

(b) A Detailed Example

Figure 9: The path failure explanation at the root of the tree is computed as e11 = d,1 1 (d,2 1 
  (d,f 1(e1 ))  ).
Since a plan failure is explained by a subset of its constraints, failure explanations are
represented in the same manner as the plan itself. Recall that dersnlp+ebl represents
its plans as a 6-tuple, hS ; O; B; L; E ; Ci (See Section 2). The explanation for the failure
occurring at a leaf node contains only the constraints which contribute to an inconsistency.
These inconsistencies appear when new constraints are added which conict with existing
constraints. As discussed in Section 2, dersnlp+ebl makes two types of decisions, establishment and resolution. Each type of decision may result in a plan failure. An establishment
decision represents a choice as to a method of achieving an open condition, either through
a new/existing step, or by adding a causal link from the initial state. When an attempt is
made to achieve a condition by linking to an initial state effect, and this condition is not
satisfied in the initial state, the plan then contains a contradiction. An explanation for the
failure is constructed which identifies the two conicting constraints:

h;; ;; ;; fhtI ; p; sig; fhtI ; :pig; ;i

The precondition of a resolution decision is a threat to a causal link. dersnlp+ebl
uses two methods of resolving a threat, promotion and demotion, each of which adds a step
ordering to the plan. When either decision adds an ordering which conicts with an existing
ordering, an explanation of the failure identifies the conict:

h;; fs  s0 ; s0  sg; ;; ;; ;; ;i

Each of the conicting constraints in the failure explanation is regressed through the final
decision, and the results are sorted according to type to form the new regressed explanation.
This process is illustrated graphically in Figure 9b. In this example, a new link from the
initial state results in a failure. The explanation, e1 is:
h;; ;; ;; fhtI ; (AT,OB OB 2 ld ); tG ig; fhtI ; :(AT,OB OB 2 ld)ig; ;i
172

fiStoring and Indexing Plan Derivations

When e1 is regressed through the final decision, df , to obtain a new explanation, the initial
state effect regresses to itself. However, since the link in the explanation was added by the
decision, df , this link regresses to the open condition which was a precondition of adding
the link. The new explanation, ef1 , is therefore

h;; ;; ;; ;; fhtI ; :(AT,OB OB 2 ld)ig; fh(AT,OB OB 2 ld ); tG igi

The regression process continues up the failing path until it reaches the root of the search
tree. When all of the paths in the subtree underneath the skeletal plan have failed, the
failure reason at the root of the tree provides the reason for the failure of the retrieved
cases. It represents a combined explanation for all of the path failures. The case failure
reason contains only the aspects of the new problem which were responsible for the failure.
It may contain only a subset of the problem goals. Also, any of the initial state effects that
are present in a leaf node explanation, are also present in the reason for case failure3 .

2.5 An Empirical Evaluation of the Utility of Case Failure Analysis

A preliminary study was conducted with the aim of demonstrating the advantage of storing
and retrieving cases on the basis of experienced retrieval failure. Domains were chosen in
which randomly generated problems contained negatively interacting goals, and planning
performance was tested when dersnlp+ebl was solving multi-goal problems from scratch
and through replay of single cases covering a smaller subset of goals. Replay performance
was tested both with and without case failure information.
2.5.1 Domains

Experiments were run on problems drawn from two domains. The first was the artificial
domain, 2 DmS 1, originally described in (Barrett & Weld, 1994) and shown in Figure 8.
Testing was done on problems which were randomly generated from this domain with the
restriction that they always contain the goal gff . The Logistics Transportation domain of
(Veloso, 1994) was adopted for the second set of experiments. Eight packages and one
airplane were randomly distributed over four cities. Problem goals represented the task of
getting one or more packages to a single destination airport4. The fly operator was augmented with a delete condition which prevented planes from visiting the same airport more
than once. This meant that replay failed if there was an extra package to be transported
which was off the previous route taken by the plane.
2.5.2 Retrieval Strategy

Cases were initially retrieved on the basis of a static similarity metric which takes into
account the goals that are covered by the case as well as all of their relevant initial state
conditions (Kambhampati, 1994; Veloso, 1994). Prior studies show it to be a reasonably
3. dersnlp+ebl's EBL component explains only analytical failures. Depth limit failures are ignored. This
means that the failure explanations that are formed are not sound in the case of a depth limit failure,
and that the retriever may reject a case when it is applicable. Rejecting an applicable case may lead to
the storage of duplicate cases and a larger library size. However, our empirical work has not shown this
to be of practical importance for reasons outlined in Section 3.2.2.
4. For a more comprehensive evaluation over an unbiased problem set see Section 4.

173

fiIhrig & Kambhampati

effective metric. In learning mode, cases were also retrieved on the same basis. However,
in this mode, the failure reasons attached to the case were used to censor its retrieval.
Each time that a case was retrieved in learning mode, these failure conditions were also
tested. If each failure reason was not satisfied in the new problem specification, the retrieval
mechanism returned the case for replay. If, on the other hand, a failure reason was found to
be true in the new problem context, then the case that repaired the failure was retrieved.
Following retrieval, the problem was solved both by replay of the retrieved case as well as
by planning from scratch.
2.5.3 Experimental Setup

Each experiment consisted of three phases, each phase corresponding to an increase in
problem size. Goals were randomly selected for each problem, and, in the case of the
logistics domain, the initial state was also randomly varied between problems. In an initial
training session that took place at the start of each phase n, 30 n-goal problems were solved
from scratch, and each derivation trace was stored in the library. Following training, the
testing session consisted of generating problems in the same manner but with an additional
goal. Each time that a new (n +1) goal problem was tried, an attempt was made to retrieve
a similar n-goal problem from the library. If during the testing session, a case that was
similar to the new problem was found which had previously failed, then the problem was
solved in learning, static and from-scratch modes, and it became part of the 30-problem
set. With this method, we were able to evaluate the improvements provided by failurebased retrieval when retrieval on the static metric alone was ineffective, and when failure
conditions were available.
2.5.4 Experimental Results

The results of the experiments are shown in Tables 1 and 2. Each table entry represents
cumulative results obtained from the sequence of 30 problems corresponding to one phase of
the experiment. The first row of Table 1 shows the percentage of problems correctly solved
within the time limit (550 seconds). The average solution length is shown in parentheses
for the logistics domain (solution length was omitted in 2 DmS 1 since all of the problems
generated within a phase have the same solution length). The second and third rows of
Table 1 contain respectively the total number of search nodes visited for all of the 30 test
problems, and the total CPU time (including case retrieval time).
These results are also summarized in Figure 10. dersnlp+ebl in learning mode was
able to solve as many of the multi-goal problems as in the other two modes and did so
in substantially less time. Case retrieval based on case failure resulted in performance
improvements which increased with problem size. Comparable improvements were not
found when retrieval was based on the static similarity metric alone. This should not be
surprising since cases were retrieved that had experienced at least one earlier failure. This
meant that testing was done on cases that had some likelihood of failing if retrieval was
based on the static metric.
Table 2 records three different measures which reect the effectiveness of replay. The first
is the percentage of sequenced replay. Recall that replay of a trace is considered here to be
sequenced if the skeletal plan is further refined to reach a solution to the new problem. The
174

fiStoring and Indexing Plan Derivations

2 DmS 1

Static

Scratch

Learning

Logistics
Static

Scratch

100%
90
1

100%
240
4

100%
300
2

100% (6.0)
1773
30

100% (6.0)
1773
34

100% (6.0)
2735
56

% Solved
nodes
time(sec)

100%
120
2

100%
810
15

100%
990
8

100% (8.2)
6924
146

100% (8.2)
13842
290

100% (8.2)
20677
402

% Solved
nodes
time(sec)

100%
150
3

100%
2340
41

100%
2533
21

100% (10.3)
290
32

100% (10.3)
38456
916

100% (10.3)
127237
2967

Phase

Learning

%Solved
nodes
time(sec)

(1) Two Goal

(2) Three Goal

(3) Four Goal

Table 1: Performance statistics in 2 DmS 1 and Logistics Transportation Domain (Average
solution length is shown in parentheses next to %Solved for the logistics domain
only)

(a) 2Dm S 1

(b) Logistics

Figure 10: Replay performance in the 2 DmS 1and Logistics Transportation domain.
175

fiIhrig & Kambhampati

2 DmS 1

Logistics
Learning
Static

Phase

Learning

Static

% Seq
% Der
% Rep

100%
60%
100%

0%
0%
0%

53%
48%
85%

53%
48%
85%

% Seq
% Der
% Rep

100%
70%
100%

0%
0%
0%

80%
63%
89%

47%
50%
72%

% Seq
% Der
% Rep

100%
94%
100%

0%
0%
0%

100%
79%
100%

70%
62%
81%

Two Goal

Three Goal

Four Goal

Table 2: Measures of effectiveness of replay.
results point to the greater eciency of replay in learning mode. In the 2 Dm S 1 domain,
replay was entirely sequenced in this mode. In the transportation domain, retrieval based
on failure did not always result in sequenced replay, but did so more often than in static
mode.
The greater effectiveness of replay in learning mode is also indicated by the two other
measures contained in the subsequent two rows of Table 2. These are respectively, the percentage of plan refinements on the final derivation path that were formed through guidance
from replay (% Der), and the percentage of the total number of plans created through replay that remain in the final derivation path (% Rep). The case-based planner in learning
mode showed as much or greater improvements according to these measures, demonstrating the relative effectiveness of guiding retrieval through a learning component based on
replay failures. These results indicate that dersnlp+ebl's integration of CBP and EBL is
a promising approach when extra interacting goals hinder the success of replay.
In Section 4 we report on a more thorough evaluation of dersnlp+ebl's learning component. This was conducted with the purpose of investigating if learning from case failure
is of benefit for a planner solving random problems in a complex domain. For this evaluation we implemented the full case-based planning system along with novel case storage
and adaptation strategies. In the next section, we describe the storage strategy that was
developed for this evaluation.

3. Improving Case Storage and Adaptation
The aim of case-based planning is to eciently solve large problems in complex domains.
A complex domain means a great variety in the problems encountered. When problem size
(measured in terms of the number of goals, n) is large, it is unlikely that the same n-goal
problem will have been seen before. It is therefore an advantage to be able to store cases
covering smaller subsets of goals, and to retrieve and adapt multiple cases in solving a single
large problem.
176

fiStoring and Indexing Plan Derivations

Before implementing this strategy, decisions had to be made as to which goal combinations to store. In previous work within state-space planning Veloso (1994) has developed an
approach to reducing the size of the library by first transforming a totally ordered plan into
a partially ordered graph, separating out connected components of the graph, and storing
these subplans individually. Goals which interact in that their respective plans must be
interleaved in order to form a complete solution are stored together as a single case. When
replay is based on a plan-space planner such as snlp, a component subplan may be further
subdivided, since the planner has the ability to first piece plans together, and later add step
orderings to interleave these subplans (Kambhampati & Chen, 1993; Ihrig & Kambhampati,
1994a). Replay of these smaller cases will be sequenced as long as their individual subplans
may be interleaved by the addition of step orderings to form a full solution. The plan-space
planner therefore has a greater capability of reducing the size of the problems stored in the
library, and, as a consequence, the number of cases stored.
dersnlp+ebl's storage strategy makes use of the plan-space planners' ability to piece
small plans together, then add step orderings to interleave these plans. As in earlier approaches, such as priar (Kambhampati & Hendler, 1992), prodigy/analogy (Veloso,
1994) and caplan (Munoz-Avilla & Weberskirch, 1996), the cases that are stored cover
smaller subsets of the original set of input goals achieved in the successful problem-solving
episode. dersnlp+ebl differs from these earlier approaches in that the division into goal
subsets is not based on the structure of the final plan alone, but on the sequence of events
making up the problem-solving episode. A new repairing case is stored if the cases which
were retrieved from the library in solving the new problem fail to be extended into a new
solution. The storer constructs a new case based on the failure explanation which was obtained through the extension phase as well as the new successful plan derivation obtained
during recovery.
The failure explanation identifies the set of negatively interacting goals responsible for
the failure. These goals form a subset of the input goals which are achieved in the new
solution. Before the repairing case is stored, the new plan derivation is stripped of any
decisions that are irrelevant to the achievement of these interacting goals. The new case
then covers only the negatively interacting goals.
Note that we define negative interaction based on the failure of the skeletal plan. An
interaction occurs when a set of input goals cannot be solved by refining the skeletal plan,
causing the planner to have to backtrack over this plan. Moreover, we cannot determine
whether two goals are negatively interacting merely by analyzing the final solution. It does
not include information about the planning failures which were encountered in generating
the solution. In particular, the final solution does not tell us whether an additional goal was
achieved by extending the replayed path, or by backtracking over that path. Approaches
to case storage which determine goal interaction from the final plan alone (Veloso, 1994;
Munoz-Avilla & Weberskirch, 1996) therefore ignore the retrieval failures that have been
encountered during the planning episode.
Retrieval failures provide important guidance as to how the library may be improved to
avoid similar failures. For dersnlp+ebl, they are used to dynamically improve the storage
in the library through the addition of new goal combinations. Multi-goal problems are
stored when retrieved cases corresponding to single-goal subproblems fail to be merged and
177

fiIhrig & Kambhampati

Case Failure Explanation:

C = fhgff; tG i; hg8 ; tG ig
E = fhtI ; i8 i; htI ; Pfi ig
Figure 11: An Example of a case failure reason
extended into a new solution. Repairing cases are constructed which achieve the negatively
interacting goals which are responsible and which are identified in the failure explanation.

3.1 An Example of a Negative Interaction
Figure 11 provides an example of an explanation for failure encountered when solving a
problem from Barrett and Weld's 2Dm S 1 domain shown in figure 8. The problem contains
three goals, gff , g6 and g8 , and has been attempted through replay of a case which solves
two of these goals, gff and g6 , and a second case, which achieves only g8 . In the latter,
the goal was achieved through the action Afi8 which represents an incorrect operator choice
when the input goals of the problem include the goal gff .
The failure explanation shown in Figure 11 identifies a subset of interacting goals, made
up of g8 and gff . Note that this interaction is not evident in the final plan shown in Figure 12.
In this plan, the three input goals of the problem are achieved through the same connected
component. If we base storage solely on the plan graph represented by the successful plan,
then all three input goals will be stored in a single case. Moreover, each new problem
representing a novel combination of goals will be stored in the library, causing the library
size to increase exponentially with problem size. For example, suppose the domain includes
the goals, fgi j1 < i < ng and gff . Then the number of problems of size three will be the
number of 3-goal subsets of these n + 1 goals. dersnlp+ebl's strategy of storing cases
based on explanations of retrieval failure will result in a maximum of 2n + 1 cases stored.
Each goal fgi j1 < i < ng appears in only two cases, one representing the single-goal problem
and one representing a two goal problem which also achieves gff .
Storing only negatively interacting goals as multi-goal problems may therefore result
in a substantial reduction in the size of the case library. It also represents a tradeoff, as
the replayed cases must be extended by from-scratch planning to solve conicts between
the individual plans recommended by separate cases. Moreover, in more complex domains,
there may be goals which interact positively in that they may be solved through common
steps (Ihrig & Kambhampati, 1996; Munoz-Avilla & Weberskirch, 1997). If these goals are
stored as separate cases, then replay may result in unnecessary redundancy in the plan.
In dersnlp+ebl, these positive interactions are handled through the replay process itself,
which merges the subplans provided by multiple cases. In Section 3.3 we describe how
this merging is accomplished. The next section provides more detail as to the case storage
strategy which has been implemented for our empirical study.
178

fiStoring and Indexing Plan Derivations

tI

1: A

2: A

3: A

tG

Figure 12: A Solution to the example problem.

3.2 Building the Case Library
The following deliberative strategy was adopted for building the case library. When a new
problem contains n goals, the first goal is attempted, and, if solved, the case covering this
goal alone is stored in the library. Problem-solving continues by increasing the problem size
by one goal at a time. For example, if the problem just attempted contained the goal set,
G = hg1 ; g2 ; :::; gi i and was solved through a decision sequence Di then a second decision
sequence, Di+1 , is stored whenever Di cannot be replayed and extended to achieve the next
goal gi+1 . Whenever the replayed derivation path fails, and the recovery phase is successful
in producing a new solution, the explanation for the case retrieval failure is used to identify
a subset of negatively interacting input goals, N = hgj :::gj +m i, that are responsible for the
failure. If the replayed path fails to be extended, and is backtracked over to reach a solution
to the new problem, then the new successful derivation is passed to the storer along with
the failure explanation. The explanation is used to delete from the derivation any decisions
which are not relevant to the set of negatively interacting goals, N . This reduced derivation
is then stored in the library as the repairing case. Alternatively, whenever the next goal
in the set is solved through simple extension of the previous decision sequence, no case is
stored which includes that goal.
This storage strategy entails two important properties. (1) Each new case corresponds to
either a new single-goal problem or to a multi-goal problem containing negatively interacting
goals. (2) All of the plan derivations arising from a single problem-solving episode are
different in that no decision sequence stored in the library is a prefix of another stored case.
This is because no case is added to the library when a new problem is solved by extending
a retrieved case. New cases are stored only when some of the previous decisions need to be
backtracked over in the search for a new solution.
dersnlp+ebl's strategy of restricting multi-goal cases to those with goals which are
negatively interacting serves to ameliorate the mis-retrieval problem. The more experience
that the planner has in problem-solving, the more of these interactions are discovered, and
the less likely it is that the planner has to backtrack over its replayed paths. The aim is
to eventually have in the library a minimal number of cases such that all of the problems
encountered may be achieved by successfully merging multiple instances of stored cases. The
approach is therefore to retain cases based on their competence as well as their performance
(Smyth & Keane, 1995).
3.2.1 An Example of dersnlp+ebl's Storage Strategy

As an example of how a multi-goal problem is stored, consider the problem contained in
Figure 13 where three packages, ob1, ob2 and ob3, are to be transported to the same
destination location, ld . Initially the goal set contains the goal of transporting ob1 alone,
represented as (at-ob ob1 ld ), and the successful derivation is stored as Case A. The
second goal is then added to the set. Since the problem just attempted achieves the first
179

fiIhrig & Kambhampati

OB1

A

OB3

A B
B

ld

B
lp

OB2

l2

Figure 13: A logistics transportation example illustrating multi-case storage. The figure
shows two plans produced by two stored derivations. Case A achieves the goal
of having a single packages, ob1, transported to the destination airport, ld . Case
B achieves the goal of having ob1 and ob2 located at the same airport.
goal through a decision sequence which has to be backtracked over in order to solve the
additional goal, a second derivation, Case B , is stored. This new derivation then solves
the mutually interacting goals, (at-ob ob1 ld ) and (at-ob ob2 ld ). Problem-solving then
continues with the addition of the third goal. This goal is solved through simple extension of
the previous decision sequence. No case is stored which includes this goal. This means that
we have two cases stored in the library: Case A corresponding to a single-goal problem and
Case B corresponding to a multi-goal problem containing two negatively interacting goals.
Multi-goal problems are stored only when the problem goals are mutually interacting, that
is, only when their individual derivations cannot be sequenced and extended to solve the
full problem.
With dersnlp+ebl's storage strategy, the size of the library is limited by the amount of
interaction in the domain. For example, if there is no negative interaction, then only single
goal cases will be stored. In the logistics transportation domain, there is a potential for all
problem goals to interact negatively. However, since there are also a significant percentage
of non-interacting goals, this strategy reduces the size of the library in comparison to one in
which all of the multi-goal problems which are successfully solved are stored. This storage
strategy also represents a tradeoff since effort must be expended in merging the retrieved
cases into a full solution (See Section 3.3).
3.2.2 Indexing on the Basis of Replay Failure

Multi-goal cases are stored in the library so as to censor the retrieval of their corresponding
single-goal subproblems. This library organization differs from earlier work which stores
all cases in a common fashion on a single level, first indexing each case by all of the goals,
then by all of the success conditions relevant to these goals (Veloso, 1994; Munoz-Avilla &
Weberskirch, 1996). In contrast, dersnlp+ebl indexes its cases through a discrimination
net similar to the one depicted in Figure 14. This figure shows one fragment of the case
library which includes all of the cases which solve a single input goal. Individual planning
episodes which achieve this goal are represented one level lower in the net. Each is labeled by
180

fiStoring and Indexing Plan Derivations

G0
input goals:

initial conditions:

(AT-OB OB1 ld )
(AT-PL PL1 lp)

(AT-OB OB1 l1)

G1

G2

derivation 1
r1

failure reasons:

(AT-PL PL1 lq)

derivation 2
r2

G3

G4

derivation 3

derivation 4

Figure 14: A Library fragment indexing stored cases which solve a single input goal, (at-ob
ob1 ld ).
its relevant initial state conditions, otherwise known as the footprinted initial state (Veloso,
1994). Together, the goal and initial state conditions make up the static success conditions
on which cases are first retrieved. When one of these cases is retrieved for replay and replay
fails, the derivation corresponding to the extra interacting goals is added to the library
and indexed directly under the failing case. On future retrievals of the case, the failure
conditions are checked to see whether the extra goals responsible for the failure are present
under the same conditions. If so, the retrieval process returns the repairing case which
achieves these conicting goals. The case failure reason is thus used to direct retrieval away
from the case which will repeat a known failure, and towards the case that avoids it.
One might question this hierarchical organization in instances where failures are due to
interacting goals alone. Why not just store all cases on a single level first indexing each
case by all of its goals, then by the conditions relevant to all of these goals? The answer
lies in the need to censor cases when failure conditions are satisfied. This type of error will
be found when retrieving multiple cases. As an example, consider that our new problem
contains three goals, g1 , g2 and g3 . Suppose further that the goal g2 negatively interacts
with both g1 and g3 . If a case is retrieved from the library which achieves both g1 and g2 ,
then one goal, g3 , is left open. However, if a case is then retrieved which solves g3 alone, it
will fail because of the presence of g2 . This type of retrieval error is handled by prioritizing
cases. A repairing case is stored as a subclass of the case that failed. Failing cases are
annotated with the failure reason which directs the retriever to the case that avoids the
failure.
Prioritizing cases on the basis of negatively interacting goals alone is not sucient to
capture all of the retrieval failures that may be encountered. If cases are retrieved on the
basis of a partial match of the relevant initial state conditions, then retrieval errors may
occur because of unmatched conditions (Veloso, 1994). For example, just as a failure might
occur in our logistics transportation example if there is an extra package off the plane's
route, a similar failure will occur if a package is moved off the plane's route. The strategy
that is adopted to deal with both types of failure information is to annotate the case with
181

fiIhrig & Kambhampati

OB1

OB3

A

l1
ld

A B B
B

B

B
lp

OB2

B

l2

Figure 15: A logistics transportation example illustrating multi-case retrieval.
the failure reason (whether it is an extra goal or an unmatched initial state condition) and
use the failure reasons to prioritize cases. The EBL techniques that we have employed in
the construction of failure explanations may be used for both types of failures.
dersnlp+ebl's method of storing multi-goal cases only when goals are negatively interacting limits the size of the case library. Other aspects of dersnlp+ebl's storage strategy
also serve to lower library size. The planner always uses its current library in solving new
problems. New derivations are stored only when there is no applicable case, or when the
retrieved cases fail. This strategy avoids the storage of duplicate cases, but may not be
entirely effective since the soundness of failure explanations is not guaranteed. If failure
explanations are not sound, pointers to repairing cases may eventually lead to a duplicate
case, causing the library to continue to grow indefinitely. However, this is easily checked
by putting a depth limit on the number of repairing cases in the discrimination net. Also,
failures which are due to interacting goals will not result in unchecked growth of the library
since the number of interacting goals is limited by the maximum problem size.
3.2.3 A Detailed Example of Case Retrieval

An example of case retrieval is illustrated in Figure 15. The figure contains three subplans
corresponding to two separate cases stored in the library. Case A achieves the goal of having
a single package, ob1, located at destination ld . Case B achieves the goal of having both
ob1 and ob2 located at ld.
Assume that a new problem which is to be attempted through replay contains three
goals, (at-ob ob1 ld), (at-ob ob2 ld ), and (at-ob ob3 ld ). The second goal negatively
interacts with both of the other goals. The retriever will first attempt to find a case that
solves the first goal alone. Case A solves this goal. However, this case is annotated with a
failure reason which is satisfied in the new problem situation, and A is therefore censored
in favor of the repairing case, Case B . Once the retriever returns Case B , it will then have
one open goal not covered, that is, (at-ob ob3 ld ). It will seek out a case which solves
this goal alone, and will again find Case A. However, A's failure reason is again satisfied
in the new problem state and will be rejected in favor of a second copy of B (which we
now call Case B 0), which solves the problem of transporting both ob3 and ob2. There will
then be two instances of Case B that will be retrieved to solve the three goal problem,
Case B and Case B 0 . Together they cover the new problem goals. dersnlp+ebl replays
182

fiStoring and Indexing Plan Derivations

Figure 16: New linking opportunities indicated by an increase in the number of siblings of
the step addition decision.
both copies of B in sequence to obtain a solution to the full problem, thereby merging their
respective subplans. Notice, however, that the union of these plans will contain redundant
steps. For example, both plans have the plane y to location l1 . Section 3.3 describes how
dersnlp+ebl deals with these positive goal interactions.

3.3 Multi-case Merging

We say that two plans are mergeable with respect to a problem, hI 0; G0 ; Ai, if there exists
a solution to the problem which contains all of their combined constraints.

Definition 2 (Mergeability) A plan P1 for achieving goal g1 is mergeable with a plan P2
for the goal g2 with respect to a problem, hI 0 ; G0 ; Ai , if there is a plan P 0 which is correct
for hI 0; G0 ; Ai and hhP 0ii  hhP1ii\hhP2 ii. (Thus syntactically, P 0 contains all the constraints
of P1 and P2 ).

Multi-case replay accomplishes plan merging, but may result in lower quality plans if
care is not taken to avoid redundant step additions (Ihrig & Kambhampati, 1996; MunozAvilla & Weberskirch, 1997). These occur when goals covered by separate cases positively
interact in that they may be solved through common steps. Replaying each case in sequence
then results in unneeded steps in the plan5 .
In multi-case replay, if an open condition is the only justification for adding a new step,
some steps may be added which already exist in the plan due to the earlier replay of another
case. When the first retrieved derivation is replayed, none of its replayed step additions
will result in redundancy. However, when subsequent goals are solved through replay of
additional cases, some step additions may be unnecessary in that there are opportunities
for linking the open conditions they achieve to earlier established steps. The planner has
no way of determining a priori that these steps may be represented by a single step in the
plan6 .
dersnlp+ebl's replay framework handles redundant step additions by skipping over
step addition establishments whenever the open condition may be achieved by a new link.
It thus strengthens or increases the justification for replaying step addition decisions in that
the open condition is no longer the only basis for validating the decision. The justification for replay is strengthened to add the condition that no new linking opportunities are
5. An analogous decrease in plan quality occurs in state-space plan reuse, when sequencing macro-operators
results state loops (Minton, 1990a).
6. Consider, for example, a domain in which the plane may transport two packages in one trip, or not,
depending on its capacity.

183

fiIhrig & Kambhampati

dersnlp+ebl

dersnlp+ebl-ij

87%(6) 67%(5)
2465
5796

87%(7) 67% (5)
2198
5810

replay
%Solved
time(sec)

scratch

replay

scratch

Table 3: Percentage problems solved, total CPU time in seconds on all 30 problems for
problems in the Logistics Transportation Domain. Average solution length is
shown in parentheses next to %Solved.
present. These may be detected as an increase in the number of siblings of the prescribed
step addition choice (See Figure 16). The siblings of the stored step addition decision are
recorded as annotations on the derivation trace. When new links are available which are
not contained within these siblings, the step addition decision is skipped. After replay,
the alternative new links are explored through the normal course of plan refinement. This
means that the same step may eventually be added if the new links fail.
Increasing the justification for the step addition decisions improves the quality of plans
in terms of the number of steps they contain. For example, Case B and B 0 would normally
produce subplans which are shown in Figure 15. When these cases are replayed in sequence
in solving a single problem, their plans are merged so that the plane moves to each city
only once. Plan merging through increasing the justification for replay accomplishes the
retracting out of redundant action sequences, which may cause a planning failure. It thus
deals with the action-merging interactions defined in (Yang, Nau, & Hendler, 1992). In
the next section we describe an empirical study testing the effectiveness of this merging
strategy.
3.3.1 An Empirical Test of dersnlp+ebl's Plan Merging Strategy

A preliminary study was conducted to test the effectiveness of dersnlp+ebl's method
of plan merging through replay. This experiment compared dersnlp+ebl both with and
without increasing the justification for replay. The experimental setup consisted of training
dersnlp+ebl on a set of 20 randomly generated 4-goal training problems, and testing on
a different set of 30 4-goal test problems. The initial state of each problem contained 12
locations (6 post oces and 6 airports) and 12 transport devices (6 planes and 6 trucks). In
the training phase, the planner solved problems and stored the successful plan derivations
in the case library. During the testing phase, the planner retrieved multiple stored plan
derivations and used these as guidance in solving the test problems. dersnlp+ebl was
tested on the same 30 problems in both replay and from-scratch modes. Replay was either
with (dersnlp+ebl) or without (dersnlp+ebl-ij) increased justification. The results are
shown in Table 3.
Although overall performance was poorer, the quality of plans in terms of number of
steps improved with dersnlp+ebl's strategy of increasing the justification for step addition. This result suggests that that dersnlp+ebl's method of plan merging serves to reduce
184

fiStoring and Indexing Plan Derivations

the redundancy in the plans produced through multi-case replay. Recently, Munoz-Avilla
and Weberskirch (1997) have tested this non-redundant merging strategy in a process planning domain and have found a similar improvements in plan size. The next section describes
an evaluation of the full dersnlp+ebl system.

4. Experimental Evaluation of the Complete System

The experiments reported in this section tested the full dersnlp+ebl system using the
dynamic multi-case storage and retrieval strategy described in Section 3. The aim was to
evaluate the replay system in a more complex domain. Our hypothesis was that performance
would improve over problem solving experience as more negative interactions are discovered
and stored. In addition, we predicted that dersnlp+ebl's method of storage would result
in a low library size and low retrieval costs.
The Logistics Transportation domain (Veloso, 1994) has become somewhat of a benchmark in the CBP literature. A scaled up version was therefore chosen for this purpose. We
tested large multi-goal problems drawn from the domain shown in Figure 4 scaled up to
first 6 and then 15 cities. This size of domain is unusual in the current literature.

4.1 Experimental Setup

The experiment was run in phases, each phase corresponding to an increase in problem
size. Thirty test problems of each size were randomly generated. Since it is not possible
to obtain a truly random distribution within a nonartificial domain, the following strategy
was adopted for problem generation. First, the initial state was constructed by fixing the
number objects of each type contained in the domain description. For example, in the first
experiment, there were six cities (12 locations within cities), six planes, and six trucks. The
initial state of each problem was constructed by first including filter conditions (nonachievable conditions). These defined the layout of the cities. For example, the condition (is-a
airport ap1) identified ap1 as an airport. The condition (same-city ap1 po1) indicated
that ap1 and po1 were located in the same city. Second, the achievable (non-filter) conditions that are present in the add clauses of the domain operators were varied for each
problem by choosing object constants randomly from those available with the restriction
that no two initial state conditions were inconsistent. For example, each plane and package
was assigned to a single randomly-chosen location. Goals were chosen from among these
achievable conditions in the same manner. Although no attempt was made to create interacting goals, goal interaction was common in the multi-goal problems. This was because
a limit was imposed on the number of steps in the plan. It meant that multi-goal problems often could not be solved by concatenating subplans for individual subgoals. In these
instances, the planner could take advantage of linking opportunities and achieve multiple
goals through common steps. It also meant that often the planner had to backtrack over a
derivation for one goal in order to solve an additional goal.
The first experiment used the 6-city domain and was run in 6 phases. The size of the
test problems (which ranged from 1 to 6 goals) was increased for each phase. Prior to each
phase n of the experiment, the case library was emptied and the planner was retrained
on randomly generated problems of size n. Training problems were solved by attempting
single-goal subproblems from scratch, storing a trace of the derivation of the solution to the
185

fiIhrig & Kambhampati

Phase

0

20

%Solved
time(sec)

100%(3)
15

% Solved
time(sec)

Logistics (Best-first

CPU limit: 500sec)
80
100

40

60

100%(3)
14(.1)

100%(3)
13(.1)

100%(3)
4(.0)

100%(3)
5(.10)

100%(3)
3(.13)

100%(3)
3(.13)

90%(4)
1548

93%(4)
1069(.2)

100%(5)
22(1.0)

100%(5)
23(.2)

100%(5)
25(.28)

100%(5)
15(.28)

100%(5)
11(.26)

% Solved
time(sec)

53%(5)
7038

87%(7)
93%(7)
93%(7)
93%(7) 100%(8)
2214(.55) 1209(.49) 1203(.54) 1222(.52) 250(.54)

100%(8)
134(.58)

% Solved
time(sec)

43%(5)
8525

100%(8)
563(.99)

100%(8)
395(.79)

100%(8)
452(.91)

100%(9)
24(.97)

100%(9)
22(.89)

100%(9)
22(.88)

% Solved
time(sec)

0%
15000

70%(11)
5269(2)

90%(11)
2450(1)

93%(11)
1425(2)

93%(11)
1479(1)

93%(11) 100%(12)
1501(1) 375(1)

% Solved
time(sec)

0%
15000

50%(12)
7748(3)

70%(13)
4578(5)

87%(14)
2191(5)

93%(14)
1299(3)

93%(14)
1319(3)

One Goal

Two Goal

Three Goal

Four Goal

Five Goal

Six Goal

120

93%(14)
1244(3)

Table 4: Performance statistics in Logistics Transportation Domain. Average solution
length is shown in parentheses next to %Solved. Case retrieval time is shown
in parentheses next to CPU time.
problem if one was not already present in the library, and then successively adding an extra
goal. Multi-goal problems were stored only when retrieved cases used in solving the problem
failed. Whenever a problem could not be solved through sequenced replay of previous cases,
the negatively interacting goals contained in the failure reason were identified and a new
case achieving these goals alone was stored in the library. In each phase of the experiment,
the planner was tested on the same 30 randomly generated test problems after varying
amounts of training. The problems were solved both in from-scratch mode and with replay
of multiple cases retrieved from the library which had been constructed during training.
A second experiment which tested the planner on a more complex 15 city domain employed a stable case library formed when dersnlp+ebl was trained on 120 (6 city, 6 goal)
logistics transportation problems. This library of smaller problems was then used when the
planner was tested on the larger (15 city) problems ranging from 6 to 10 goals.

4.2 Experimental Results

In the first experiment on the 6 city domain dersnlp+ebl showed substantial improvements with multi-case replay as evident from the results in Table 4. Moreover, replay
performance improved with problem-solving experience. The plans that were produced
showed only a slight increase in number of steps over the solutions which were obtained
in from-scratch mode. The same results are plotted in Figure 17 which graphs cumulative
CPU time on all test problems over the six experiments. This figure illustrates how CPU
time decreased with the number of training problems solved. The insert shows total CPU
186

fiStoring and Indexing Plan Derivations

Figure 17: Replay performance in the Logistics Transportation Domain with increasing
amounts of training. Thirty problems were tested for each problem size (1 to
6 goals). The amount of time needed to solve all test problems up to that size
(including case retrieval time) is shown when problems were solved from scratch
(level 0) and with replay after increasing levels of training (after solving 20 ...
120 randomly generated problems). The insert shows the amount of time taken
to solve all test problems after increasing amounts of training. A time limit of
500 seconds was placed on problem solving.

187

fiIhrig & Kambhampati

Figure 18: Replay performance in the Logistics Transportation Domain scaled up to 15
cities. A case library was formed as 120 training problems (6 cities, 6 goals)
were solved. This library was then used in solving test sets containing larger
problems (15 cities, 6 to 10 goals). None of the problems were solved within the
time limit (500 sec) in from-scratch mode. For replay mode, average solution
length is shown in parentheses next to problem size.

Figure 19: Replay performance in the logistics transportation. The percentage of test problems solved within the time limit (500 sec) is plotted against number of training
problems solved. Percentage solved is shown for problems of increasing size (1,
3, and 5 goals).

188

fiStoring and Indexing Plan Derivations

Figure 20: Figure shows the size of the case library with increased number of training
problems solved. Library size increases with training problem size (1, 3, and 5
goals). 5' shows the number of single-goal subproblems contained in the 5-goal
training problems.
time (including case retrieval time) for all of the test problems in the six experiments. As
evident in this insert, planning performance improves with increased experience on random
problems. However, relatively little experience (20 problems solved) was enough to show
significant performance improvements.
Replay raised the problem-solving horizon, as illustrated in Figure 19. It is more effective
with larger problem size, when from-scratch planning tends to exceed the time limit imposed
on problem-solving. Figure 20 shows the increase in the size of the library with increasing
amounts of training. This figure also indicates that library size is determined more by the
amount of interaction in the domain, as opposed to the number of training problems solved.
The rate at which the case library grows tapers off and is higher when the planner is trained
on larger problems7 .
In the second experiment, a library formed over the course of training on 6-goal problems
was used to solve larger problems (6 to 10 goals) in a more complex domain (15 cities) (See
Figure 18). None of the larger problems were solved in from-scratch mode within the time
limit of 500 sec 8 . The planner continued to maximum time on all problems, indicated in
the figure by the linear increase in CPU time. Its performance was substantially better
with replay, however. Since library size was relatively small, the improvements in planning
performance more than offset the cost of retrieving and adapting previous cases. This finding
suggests that the replay strategy employed in these experiments represents an effective
method for improving planning performance in complex domains.
7. There is more opportunity for interaction in larger problems. For example, a 6-goal problem could
contain 6 goals that mutually interact, whereas a 5-goal problem has a maximum of 5 interacting goals.
8. dersnlp+ebl in from-scratch mode used a best-first strategy. In replay, this best-first strategy is biased
so that the subtree under the replayed path is explored first, before the siblings of this path.

189

fiIhrig & Kambhampati

action (Put-On ?X ?Y ?Z)
precond (On ?X ?Z)
(Clear ?X)
(Clear ?Y)
add
(On ?X ?Y)
(Clear ?Z)
delete (On ?X ?Z)
(Clear ?Y)

action (New-Tower ?X ?Z)
precond (On ?X ?Z)
(Clear ?X)
add
delete

(On ?X Table)
(Clear ?Z)
(on ?X ?Z)

Figure 21: The specification of the Blocks World Domain adapted for our experiments.

4.3 An Empirical Comparison of dersnlp+ebl with Rule-Based EBL
Case-based planning and explanation-based learning offer two differing approaches to improving the performance of a planner. Prior research (Kambhampati, 1992) has analyzed
their tradeoffs. The hybrid learning approach of dersnlp+ebl is designed to alleviate
the drawbacks associated with both pure case-based planning, and rule-based EBL. Prior
to this work, EBL has been used to construct generalized search control rules which may
be applied to each new problem-solving situation. These rules are matched at each choice
point in the search process (DeJong & Mooney, 1986; Minton, 1990b; Mostow & Bhatnagar,
1987; Kambhampati et al., 1996b). This approach is known to exhibit a utility problem since
the rule base grows rapidly with increasing problem-solving experience and even a small
number of rules may result in a high total match cost (Minton, 1990b; Tambe, Newell, &
Rosenbloom, 1990; Kambhampati, 1992; Francis & Ram, 1995). In contrast, the empirical
results discussed here (see Table 4) indicate that dersnlp+ebl has a low case retrieval and
match cost.
To demonstrate how dersnlp+ebl reduces match cost, we conducted an empirical study
which compared its performance with ucpop+ebl, a rule-based search control learning
framework (Kambhampati et al., 1996b). This framework constructs reasons for planning
failures in a manner similar to dersnlp+ebl. However, its approach is similar to that of
Minton (1990b) in that it employs these explanations in the construction of search control
rules which are matched at each node in the search tree. The planners were tested on a
set of problems ranging from 2 to 6 goals which were randomly generated from the blocks
domain shown in Figure 21. Testing was performed on the same set of thirty problems after
increasing amounts of training.
As illustrated in Figure 22, dersnlp+ebl improved its performance after only 10 training problems solved. ucpop+ebl failed to improve significantly. The reason is evident
in ucpop+ebl's match time (ucpop-match) also graphed in Figure 22. For ucpop+ebl,
time spent in matching rules increases with training, wiping out any improvements that
may have been gained through the use of those rules. When rules are matched at each
choice point in the search tree, a small number of rules is sucient to substantially increase
the total match cost.
190

fiStoring and Indexing Plan Derivations

Figure 22: Total CPU Time on 30 blocks world problems after increased amounts of training.
It is also possible to improve the performance of rule-based EBL by reducing the number
of rules through the use of utility monitoring strategies (Gratch & DeJong, 1992), or by
using a more sophisticated match algorithm (Doorenbos, 1995). For example, Doorenbos
(1995) employs an improved rule matcher based on the Rete algorithm. dersnlp+ebl, on
the other hand, aims at alleviating the utility problem by reducing the number of times rules
are matched. Similar to rule-based EBL, its learning component is employed to generate
rules. However, the rules that are generated govern the retrieval of the cases stored in
the library. These are compiled into its indexing structure. dersnlp+ebl exhibits low
match cost by applying retrieval rules at only one point in the search process. Specifically,
it retrieves cases only at the start of problem-solving. Each case represents a sequence of
choices (a derivation path) thus providing global control as opposed to local. The results
shown in Table 4 indicate that the cost of retrieving cases is significantly lower in comparison
to time spent in problem-solving.

5. Related Work and Discussion
dersnlp+ebl's storage strategy relies on the capability of the case-based planner to replay
multiple cases, each covering a small subset of goals, and then add step orderings to interleave their respective plans. This strategy differs from earlier approaches such as priar
(Kambhampati & Hendler, 1992), prodigy/analogy (Veloso, 1994), paris (Bergmann
& Wilke, 1995), and caplan (Munoz-Avilla & Weberskirch, 1996), in that the division
into goal subsets is not based on the structure of the final plan alone, but on the sequence
of events making up the problem-solving episode. Retrieval failures are treated as an opportunity by which the planner stores a new repairing case. In this aspect it is similar
to Hammond's chef (Hammond, 1990) which also learns to improve its retrieval strategy
based on failures. Despite this surface similarity, there are important differences in our

191

fiIhrig & Kambhampati

Transformational
PRIAR
SPA
MPA
Plan-Space

State-Space
DERSNLP

PRODIGY/ANALOGY
PARIS

Derivational

Figure 23: Some different approaches to case-based planning where case adaptation is accomplished by an underlying generative planner.
approach. dersnlp+ebl learns from case extension failures, whereas chef concentrates on
learning from execution failures. Specifically, chef assumes an incomplete domain model,
consisting of stored cases, and a domain-specific modification theory of patches. Given a
new problem, chef retrieves a previous case, and modifies the retrieved plan using domain
specific modification rules to generate a candidate solution for the current problem. The
correctness of this solution is then tested with respect to an external causal simulator of the
domain. If the solution is found to be incorrect, the explanation of incorrectness (supplied
by the simulator) is used to modify the case-library to censor the retrieval of the case in
similar situations in the future. This in effect improves the correctness of chef's domain
theory. In contrast, dersnlp+ebl assumes complete knowledge of the domain, in the form
of domain operators. It also has access to a sound and complete plan synthesis strategy.
The aim of case-based reasoning in dersnlp+ebl is to improve the performance of the
base-level planner. To this end, dersnlp+ebl analyzes case extension failures to predict
when a case cannot be extended to solve a new problem.
Fox and Leake (1995) have taken an approach similar to that of chef, but use introspective reasoning to explain failures and find repairing cases. Similar to chef, introspective
reasoning is used to revise indexing in the case library (Fox & Leake, 1995; Ram & Cox,
1994). Other approaches employ domain-specific techniques to improve storage and retrieval from a case library (Munoz-Avilla & Weberskirch, 1996; Smyth & Keane, 1995).
dersnlp+ebl differs in that it automatically generates new indices through a well defined
and domain-independent methodology (Kambhampati et al., 1996b) which is incorporated
into the underlying planning strategy.
Since EBL is employed in explaining case failure as well as success, dersnlp+ebl complements and extends earlier approaches to case retrieval (Barletta & Mark, 1988; Kambhampati & Hendler, 1992; Hendler, Stoffel, & Mulvehill, 1996; Veloso, 1994; Bergmann
& Wilke, 1995; Munoz-Avilla & Weberskirch, 1996; Ram & Francis, 1996). Although it
192

fiStoring and Indexing Plan Derivations

exhibits low retrieval and match cost, as with any CBP system, this eciency may degrade with larger domain size. dersnlp+ebl's approach is compatible with others aimed
at improving match cost (Doorenbos, 1995; Ram & Francis, 1996; Hendler et al., 1996).
For example, mpa (Ram & Francis, 1996) is built around a retrieval engine which performs
asynchronous memory retrieval. caper (Hendler et al., 1996) uses a structure matching
algorithm which parallelizes the process by which the plan's success conditions represented
as a retrieval probe are matched with a large knowledge base of world facts. This process
expands binary predicates which match the success conditions into a larger structure containing implicitly specified relations in the knowledge base. This structure acts as a filter,
eliminating matches which fail to line up with the probe.
dersnlp+ebl is similar to case-based systems which employ a complete and correct
domain-independent planner to generate cases to be stored (Hanks & Weld, 1995; Kambhampati & Hendler, 1992; Koehler, 1994; Veloso, 1994; Ram & Francis, 1996). In surveying
this literature, it is possible to distinguish these approaches on two orthogonal scales as
shown in Figure 23. In the horizontal direction, the CBP frameworks are ranked as to
how the underlying planning strategy falls on a continuum whose end extremes represent
the state-space vs plan-space dichotomy. Towards the state-space end of the spectrum is
prodigy/analogy, which employs the means-ends analysis (MEA) planner, nolimit, to
extend a previous case. nolimit is here classed as a state-space planner since it applies
actions to the plan based on the current world state and thereby advances the world state.
The priar framework (Kambhampati & Hendler, 1992; Kambhampati, 1994) is based
within nonlin (Tate, 1977). nonlin creates its plans through hierarchical task reduction.
It is also a partial-order (plan-space) planner which constructs plans by protecting their underlying causal structure. Like dersnlp+ebl, it extends a case through the normal course
of plan refinement defined by an underlying plan-space strategy. However, dersnlp+ebl is
implemented within the partial-order, causal-link planner, snlp (McAllester & Rosenblitt,
1991; Barrett & Weld, 1994). In this aspect it is similar to the spa system developed by
Hanks and Weld (1995).
The different CBP systems may also be distinguished according to their case adaptation strategy. These can be roughly categorized as either transformational or derivational
(Carbonell, 1983; Veloso & Carbonell, 1993b), according to whether they transform a previous plan or replay a previous plan derivation. In the transformational strategies of priar
and spa, the final plan which is the product of the planning episode is stored in the case
library. When a case is retrieved this plan is fitted to adapt to the new problem-solving situation by retracting the irrelevant or redundant subparts. Early CBP systems (Carbonell,
1983; Hammond, 1990) also employ transformational techniques to adapt a previous solution. Causal-link planners such as snlp are ready-made for plan reuse since the causal
structure which is employed in plan adaptation is a part of the plan itself. priar and spa
use the plan's causal structure both in fitting the plan to the new problem context, and
in extending the fitted plan to solve the new problem. priar differs from spa in that it
employs an extension-first strategy. The skeletal plan is first refined through the addition
of plan constraints before undertaking any further retraction of constraints. spa, on the
other hand, alternates the retraction of the plan constraints with the further addition of
new constraints. mpa (Ram & Francis, 1996) extends spa's transformational strategy to
accomplish multi-case retrieval and adaptation.
193

fiIhrig & Kambhampati

As mentioned earlier, derivational analogy is a case-based planning technique which
was introduced by Carbonell (Veloso & Carbonell, 1993b). This model was developed by
Veloso in prodigy/analogy (Veloso, 1994), which employed the case fitting strategy called
derivational replay. Case fitting based on replay is similar to fitting in plan reuse, in that
it is based on the plan's underlying causal structure. The justification for each planning
decision which is stored in the derivation trace reects the causal dependencies between plan
steps. Only justified choices are replayed in solving the new problem. Replay thus serves
the same purpose as retraction in plan reuse. Replay may have an advantage in multi-case
reuse since it allows the planner to readily merge small subplans to solve large problems.
dersnlp can be contrasted to prodigy/analogy in that it employs a case fitting
methodology called eager derivation replay (Ihrig & Kambhampati, 1994a, 1996). With
this replay strategy, the applicable cases are replayed in sequence before returning to fromscratch planning. Eager replay simplifies the replay process by avoiding the decision as to
how to alternate replay of multiple cases. The effectiveness of this approach is dependent
on the underlying plan-space planning strategy (Ihrig & Kambhampati, 1994a). dersnlp's
eager case adaptation strategy allows case failure to be defined in terms of the failure of
a single node in the search tree. In particular, case failure is defined as the failure of the
skeletal plan, which contains all of the constraints that have been adopted on the advice
of the previous cases. Eager case adaptation means that explanations of case failure may
be constructed through the use of EBL techniques which have been developed to explain
analytical failures occurring in the planner's search space.

6. Summary and Conclusion
In this paper we have described the design and implementation of the case-based planner,
dersnlp+ebl. The dersnlp+ebl framework represents an integration of eager case adaptation with failure-based EBL. EBL techniques are employed in building the case library
on the basis of experienced retrieval failures. This approach improves on earlier treatments of case retrieval (Barletta & Mark, 1988; Kambhampati & Hendler, 1992; Ihrig &
Kambhampati, 1994a; Veloso & Carbonell, 1993a). As a partial-order case-based planner,
dersnlp has the ability to solve large problems by retrieving multiple instances of smaller
subproblems and merging these cases through sequenced replay (Ihrig & Kambhampati,
1994a). The dersnlp+ebl framework extends this approach through the use of new EBL
techniques which are employed in the construction of the case library. These techniques are
used to explain a plan merging failure and to identify a set of negatively interacting goals.
The library is then augmented with a new repairing case covering these interacting goals.
dersnlp+ebl's method of storing multi-goal cases only when goals are negatively interacting results in a small library size and low retrieval costs. However, multi-case adaptation
also involves a tradeoff since effort is expended in merging multiple instances of stored cases.
dersnlp+ebl accomplishes this merging by increasing the justification for replay of step addition decisions. This strategy avoids the addition of redundant steps when goals positively
interact. dersnlp+ebl is therefore aimed at domains such as the Logistics Transportation
domain where there is a significant amount positive interaction. It is also aimed at domains
where there is negative interaction. It is of course futile to spend effort in explaining case
failure if none are encountered.
194

fiStoring and Indexing Plan Derivations

Section 4 describes an evaluation of the overall eciency of this storage and retrieval
strategy when solving large problems in a complex domain. dersnlp+ebl shows an improvement in planning performance which more than offsets the added cost entailed in
retrieving on failure conditions. The amount of improvement provided by replay shown in
these experiments should be seen as a lower bound since a random problem distribution
may mean less problem similarity than is found in real world problems.
In conclusion, this paper has described a novel approach to integrating explanationbased learning techniques into case-based planning. This approach has been aimed at issues
associated with both pure case-based planning, and with rule-based EBL. In particular, it
addresses the mis-retrieval problem of CBP, as well as the utility problem. The results
demonstrate that eager case adaptation when combined with dersnlp+ebl's dynamic case
retrieval is an effective method of improving planning performance.

Acknowledgements
The authors wish to thank Amol D. Mali, Eric Lambrecht, Eric Parker, and the anonymous
reviewers for their helpful comments on earlier versions of this paper. Thanks are due
to Terry Zimmerman for providing insight into ucpop+ebl. This research is supported
in part by NSF Research Initiation Award IRI-9210997, NSF Young Investigator award
IRI-9457634, and the ARPA Planning Initiative grants F30602093-C-0039 (phase II) and
F30602-95-C-0247 (phase III).

References

Barletta, R., & Mark, W. (1988). Explanation-based indexing of cases. In Proceedings
AAAI-88.
Barrett, A., & Weld, D. (1994). Partial order planning: evaluating possible eciency gains.
Artificial Intelligence, 67, 71{112.
Bergmann, R., & Wilke, W. (1995). Building and refining abstract planning cases by change
of representation language.. Journal of Artificial Intelligence Research, 3, 53{118.
Carbonell, J. (1983). Learning by analogy: Formulating and generalizing plans from past
experience. In Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine Learning:
an Artificial Intelligence approach, Vol. 1. Palo Alto, CA: Tioga Press.
DeJong, G., & Mooney, R. (1986). Explanation-based learning: An alternative view. Machine Learning, 1 (2), 145{176.
Doorenbos, R. (1995). Production Matching for Large Learning Systems. Ph.D. thesis,
Computer Science Department, Carnegie Mellon University.
Fikes, R., & Nilsson, N. (1971). A new approach to the application of theorem proving to
problem solving. Artificial Intelligence, 2, 189{208.
Fox, S., & Leake, D. (1995). Using introspective reasoning to refine indexing. In Proceedings
IJCAI-95.
195

fiIhrig & Kambhampati

Francis, A., & Ram, S. (1995). A comparative utility analysis of case-based reasoning
and control-rule learning systems. In Proceedings of the 8th European Conference on
Machine Learning, ECML-95.
Friedland, P., & Iwasaki, Y. (1985). The concept and implementation of skeletal plans.
Journal of Automated Reasoning, 1 (2), 161{208.
Gratch, J., & DeJong, G. (1992). Composer: A probabilistic solution to the utility problem
in speed-up learning. In Proceedings AAAI-92.
Hammond, K. (1990). Explaining and repairing plans that fail. Artificial Intelligence, 45,
173{228.
Hanks, S., & Weld, D. (1995). A domain-independent algorithm for plan adaptation. Journal
of Artificial Intelligence Research, 2, 319{360.
Hendler, J., Stoffel, K., & Mulvehill, A. (1996). High performance support for case-based
planning applications. In Technological Achievements of the Arpa/Rome Laboratory
Planning Initiative: Advanced Planning Technology. AAAI Press.
Ihrig, L., & Kambhampati, S. (1994a). Derivation replay for partial-order planning. In
Proceedings AAAI-94.
Ihrig, L., & Kambhampati, S. (1994b). Plan-space vs state-space planning in reuse and
replay. Tech. rep. 94-006, Department of Computer Science and Engineering. Arizona
State University. Also available at http://rakaposhi.eas.asu.edu/yochan.html.
Ihrig, L., & Kambhampati, S. (1996). Design and implementation of a replay framework
based on a partial order planner. In Proceedings AAAI-96.
Joslin, D., & Roach, J. (1990). A theoretical analysis of conjunctive goal problems. Artificial
Intelligence, 41, 97{106.
Kambhampati, S. (1992). Utility tradeoffs in incremental modification and reuse of plans. In
Proceedings AAAI Spring Symposium on Computational Considerations in Supporting
Incremental Modification and Reuse.
Kambhampati, S. (1994). Exploiting causal structure to control retrieval and refitting
during plan reuse. Computational Intelligence, 10.
Kambhampati, S., & Chen, J. (1993). Relative utility of ebg based plan reuse in partial ordering vs total ordering planning. In Proceedings AAAI-93, pp. 514{519. Washington,
D.C.
Kambhampati, S., & Hendler, J. A. (1992). A validation structure based theory of plan
modification and reuse. Artificial Intelligence, 55, 193{258.
Kambhampati, S., Ihrig, L., & Srivastava, B. (1996a). A candidate set based analysis of
subgoal interactions in conjunctive goal planning. In Proceedings of the 3rd Intl. Conf.
on AI Planning Systems.
196

fiStoring and Indexing Plan Derivations

Kambhampati, S., Katukam, S., & Qu, Y. (1996b). Failure driven dynamic search control
for partial order planners: An explanation-based approach. Artificial Intelligence, 88,
253{315.
Kambhampati, S., Knoblock, C., & Yang, Q. (1995). Planning as refinement search: a
unified framework for evaluating design tradeoffs in partial-order planning. Artificial
Intelligence, 76, 167{238.
Koehler, J. (1994). Avoiding pitfalls in case-based planning. In Proceedings of the 2nd Intl.
Conf. on AI Planning Systems.
Korf, R. (1987). Planning as search: a qualitative approach. Artificial Intelligence, 33,
65{68.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proceedings
AAAI-91.
Minton, S. (1990a). Issues in the design of operator composition systems. In Proceedings of
the International conference on Machine Learning.
Minton, S. (1990b). Quantitative results concerning the utility of explanation-based learning. Artificial Intelligence, 42, 363{392.
Mostow, J., & Bhatnagar, N. (1987). Failsafe: A oor planner that uses ebg to learn from
its failures. In Proceedings IJCAI-87.
Munoz-Avilla, H., & Weberskirch, F. (1996). Planning for manufacturing workpieces by
storing, indexing and replaying planning decisions. In Proceedings of the 3rd Intl.
Conf. on AI Planning Systems. AAAI-Press.
Munoz-Avilla, H., & Weberskirch, F. (1997). A case study on mergeability of cases with a
partial-order planner. In Proceedings of the 4th European Conf. on Planning.
Ram, A., & Cox, M. (1994). Introspecive reasoning using meta-explanations for multistrategy learning. In Michalski, R., & Tecuci, G. (Eds.), Machine Learning: A multistrategy
approach Vol. IV. Morgan Kaufmann.
Ram, S., & Francis, A. (1996). Multi-plan retrieval and adaptation in an experience-based
agent. In Leake, D. B. (Ed.), Case-Based Reasoning: experiences, lessons, and future
directions. AAAI Press/The MIT Press.
Redmond, M. (1990). Distributed cases for case-based reasoning:facilitating use of multiple
cases. In Proceedings AAAI-90.
Smyth, B., & Keane, M. (1995). Remembering to forget: A competence-preserving deletion
policy for cbr. In Proceedings IJCAI-95.
Tambe, N., Newell, A., & Rosenbloom, P. (1990). The problem of expensive chunks and its
solution by restricting expressiveness. Machine Learning, 5, 299{349.
Tate, A. (1977). Generating project networks. In Proceedings IJCAI-77.
197

fiIhrig & Kambhampati

Veloso, M. (1994). Planning and learning by analogical reasoning. Springer Verlag. Number
886 in Lecture Notes in Artificial Intelligence.
Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments in partialorder planning. In Proceedings of the 2nd Intl. Conf. on AI Planning Systems.
Veloso, M., & Carbonell, J. (1993a). Derivational analogy in prodigy: Automating case
acquisition, storage and utilization. Machine Learning, 10, 249{278.
Veloso, M., & Carbonell, J. (1993b). Toward scaling up machine learning: A case study with
derivational analogy in prodigy. In Minton, S. (Ed.), Machine Learning methods for
planning. Morgan Kaufmann.
Yang, Q., Nau, D., & Hendler, J. (1992). Merging separately generated plans with restricted
interactions. Computational Intelligence, 8 (2), 648{676.

198

fiJournal of Artificial Intelligence Research 7 (1997) 1{24

Submitted 2/97; published 7/97

Defining Relative Likelihood in Partially-Ordered
Preferential Structures
Joseph Y. Halpern

Cornell University, Computer Science Department
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

halpern@cs.cornell.edu

Abstract

Starting with a likelihood or preference order on worlds, we extend it to a likelihood
ordering on sets of worlds in a natural way, and examine the resulting logic. Lewis earlier
considered such a notion of relative likelihood in the context of studying counterfactuals,
but he assumed a total preference order on worlds. Complications arise when examining
partial orders that are not present for total orders. There are subtleties involving the exact
approach to lifting the order on worlds to an order on sets of worlds. In addition, the
axiomatization of the logic of relative likelihood in the case of partial orders gives insight
into the connection between relative likelihood and default reasoning.

1. Introduction
A preference order  on a set W of worlds is a reexive, transitive relation on W . Various
readings have been given to the  relation in the literature; u  v has been interpreted as \u
at least as preferred or desirable as v" (Kraus, Lehmann, & Magidor, 1990; Doyle, Shoham,
& Wellman, 1991) (it is this reading that leads to the term \preferential structure"), \u at
least as normal (or typical) as v" (Boutilier, 1994), and \u is no more remote from actuality
than v" (Lewis, 1973). In this paper, we focus on one other interpretation, essentially also
considered by Lewis (1973). We interpret u  v as meaning \u is at least as likely as v".1
Interestingly, all these readings seem to lead to much the same properties.
In the literature, preference orders have been mainly used to give semantics to conditional logics (Lewis, 1973) and, more recently, to nonmonotonic logic (Kraus et al., 1990).
The basic modal operator in these papers has been a conditional !, where p ! q is interpreted as \in the most preferred/normal/likely worlds satisfying p, q is the case". However,
if we view  as representing likelihood, then it seems natural to define a binary operator
 on formulas such that '  is interpreted as \' is more likely than ". Lewis (1973)
in fact did define such an operator, and showed how it related to !. However, he assumed
that  was total; that is, he assumed that for all worlds w; w0 2 W , either w  w0 or
w0  w. But in many cases in preferential or likelihood reasoning, it seems more appropriate to allow the preference order to be partial. It may well be that an agent finds two
1. There is a tradition, starting with Lewis (1973), of taking u  v, rather than u  v, to mean that u
is as preferred or as desirable as v. This last reading historically comes from the interpretation of the
preferred world as being less far from actuality. Since there seems to be a split in the reading in the
literature, and  has traditionally been taken to mean \at least as likely" in the literature on qualitative
probability (Fine, 1973; Gardenfors, 1975), we take this reading here.

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiHalpern

situations incomparable as far as normality or likelihood goes. For example, one situation
may be better in one dimension but worse in another.
As we show in this paper, there are some subtleties involved in starting with a partial
preference order on worlds. What we are ultimately interested is not an ordering on worlds,
but an ordering on sets of worlds. To make sense of a statement like '  , we need to
compare the relative likelihood of the set of worlds satisfying ' to that of the set satisfying
. Unfortunately, there are many possible ways of extending a preference order on worlds
to one on sets of worlds. We focus here on two particular choices, which both agree with the
definition given by Lewis in the case that the preference order on worlds is total, but differ
in general. We define  using the definition that allows us to make the most interesting to
work in default reasoning.
We then turn our attention to axiomatizing the likelihood operator. Lewis provided an
axiomatization for the case where the preference order is partial. The key axioms used by
Lewis were transitivity:
('1  '2 ) ^ ('2  '3 ) ) ('1  '3 );
and the union property:
('1  '2 ) ^ ('1  '3 ) ) ('1  ('2 _ '3 )):
This latter property is characteristic of possibility logic (Dubois & Prade, 1990). In the
partially ordered case, these axioms do not suce. We need the following axiom:
(('1 _ '2 )  '3 ) ^ (('1 _ '3 )  '2 ) ) ('1  ('2 _ '3 )):
It is not hard to show that this axiom implies transitivity and the union property (in the
presence of the other axioms), but it is not equivalent to them. Interestingly, it is the
property captured by this axiom that was isolated in (Friedman & Halpern, 1997) as being
the key feature needed for a likelihood ordering on sets to be appropriate for doing default
reasoning in the spirit of (Kraus et al., 1990). Thus, by considering preference orders that
are partial, we are able to clarify the connections between , !, and default reasoning.
The rest of this paper is organized as follows. In Section 2, we consider how to go from
an ordering on worlds to one on sets of worlds, focusing on the differences between total
and partial preference orders. In Section 3, we present a logic for reasoning about relative
likelihood and provide a natural complete axiomatization for it. In Section 4, we relate
our results to other work on relative likelihood, as well as to work on conditional logic and
nonmonotonic reasoning. We conclude in Section 5. Proofs of the technical results can be
found in Appendix A.

2. From Preorders on Worlds to Preorders on Sets of Worlds

We capture the likelihood ordering on a set W of possible worlds by a partial preorder |that
is, a reexive and transitive relation| on W .2 We typically write w0  w rather than

2. A partial order R is typically assumed to be reexive, transitive, and anti-symmetric (so that if (a; b) 2 R
and (b; a) 2 R, then a = b). We are not assuming that  is anti-symmetric here, which is why it is a
preorder.

2

fiRelative Likelihood in Partially-Ordered Preferential Structures

(w0 ; w) 2 . As usual, we often write u  v rather than v  u, and take u  v to be an
abbreviation for u  v and not(v  u), and u  v to be an abbreviation for v  u. The
relation  is a strict partial order , that is, it is an irreexive (for all w, it is not the case that
w  w) and transitive relation on W . We say that  is the strict partial order determined
by .
As we said in the introduction, we think of  as providing a likelihood, or preferential, order on the worlds in W . Thus, w  w0 holds if w is at least as likely/preferred/normal/close
to actuality as w0 . Given this interpretation, the fact that  is assumed to be a partial
preorder is easy to justify. For example, transitivity just says that if u is at least as likely
as v, and v is at least as likely as w, then u at least as likely as w. Notice that since 
is a partial preorder, there may be some pairs of worlds w and w0 that are incomparable
according to . Intuitively, we may not be prepared to say that either one is likelier than
the other. We say that  is a total preorder (or connected, or a linear preorder) if for all
worlds w and w0 , either w  w0 or w0  w.
Since we have added likelihood to the worlds, it seems reasonable to also add likelihood
to the language, to allow us to say \' is more likely than ", for example. But what
exactly should this mean? Although having  in our semantic model allows us to say that
one world is more likely than another, it does not immediately tell us how to say that a set
of worlds is more likely than another set. But, as we observed in the introduction, this is
just what we need to make sense of \' is more likely than ".
How should we extend a likelihood ordering on worlds to one on sets of worlds? Clearly
we want to do so in a way that preserves the ordering on worlds. That is, using > to
denote the ordering sets, we would certainly expect that u  v would imply fug > fvg. We
could impose a few other minimal requirements, but they certainly would not be enough to
uniquely determine an ordering on sets. For example, here are two general approaches; to
distinguish them, we put subscripts on >.
1. Define >1 so that U >1 V if for all u 2 U and all v 2 V , we have u  v. We can
define a strict partial order in this spirit in two distinct ways.
(a) By considering the analogous procedure to that used to get  from : We define
>2 so that U >2 V if U >1 V and not(V >1 U ). We call this the standard method
below.
(b) By replacing  in the definition of >1 by : We define >3 so that U >3 V if
for all u 2 U and all v 2 V , we have u  v. We call this the alternative method.
2. Define >4 so that U >4 V if for all v 2 V , U , there is some u 2 U , V such that
u  v. Note that this approach focuses on the symmetric difference between U and
V . There are again two ways of getting a strict partial order.
(a) The standard method gives us U >5 V if U >4 V and not(V >4 U ).
(b) The alternative method gives us U >6 V if for all v 2 V , U there is some
u 2 U , V such that u  v.
The first approach ( >1 ) was used by Doyle, Shoham, and Wellman (1991) in defining
a logic of relative desire, starting with a preference order on worlds. Unfortunately, as
3

fiHalpern

they themselves point out, these relations are too weak to allow us to make important
distinctions. They go on to define other notions of comparison, but these are more tuned
to their applications, and not in the spirit of the notions we are considering here.
The second approach (typically >4 and >5 ) has been widely used in various applications
in the literature. For example,
 Dershowitz and Manna (1979) use it to define on ordering on multisets, which is then
used to provide a technique for proving program termination.
 Przymusinski (1987) uses it to order models of a database.
 Brass (1991), Cayrol, Royer, and Saurel (1992), Delgrande (1994), and Geffner (1992)
all use it to help model various aspects of default reasoning.
In this paper, we focus on a variant of the second approach, essentially due to Lewis
(1973), which has interesting connections to default reasoning. Roughly speaking, we take
U to be more likely than V if for every world in V , there is a more likely world in U .
To make this precise, if U; V  W , we write U s V if for every world v 2 V , there is a
world u 2 U such that u  v. It is easy to check that s is a partial preorder, that is, it is
reexive and transitive. (The superscript s is for \set".) Moreover, if  is a total preorder,
then so is s . Finally, as we would expect, we have u  v iff fug s fvg, so the s relation
on sets of worlds can be viewed as a generalization of the  relation on worlds.
We can then apply both the standard method and the alternative method to define a
strict partial order. The standard method gives us the relation 0 , where U 0 V holds
if U s V and not(V s U ). The alternative method gives us the relation s defined on
finite sets by taking U s V to hold if U is nonempty, and for every world v 2 V , there is
a world u 2 U such that u  v. (The reasons that U is taken to be nonempty and that the
definition is restricted to finite sets are discussed below.)
How do these various approaches compare? Clearly U >1 V implies U s V , although
the converse does not hold in general; >1 is a very weak ordering. As a consequence, >2
and 0 are incomparable, as are >3 and s. Similar remarks apply to >4 . Again, it is easy
to see that U >4 V implies U s V . On the other hand, the two notions are not equivalent.
For example, suppose v  v0 . Then fvg s fv; v0 g, but we do not have fvg >4 fv; v0 g.
Why are we focusing on s , 0 , and s here, rather than >1 { >6 (or some other notion)? From a likelihood viewpoint, they all seem to be reasonable; our intuitions regarding
extending likelihood from worlds to sets of worlds do not seem to be that well developed. It
may be possible to motivate s as the finest relation extending  that has certain properties, but that was not in fact our motivation here. Rather, our interest is motivated by the
deep connections between 0 and s and certain approaches to nonmonotonic reasoning.
Having said that, many of the questions that we consider here could perfectly well be explored using >1 { >6 . With that apology, we do not discuss >1 { >6 further in this paper,
except for the odd remark.
We have explained that there are two methods for getting a strict partial order on sets
of worlds from a partial order on worlds. But are the standard method and the alternative
method really so different? It is easy to see that u  v iff fug s fvg iff fug 0 fvg. (This
is true for >2 , >3 , >5 , and >6 as well.) Thus, s and 0 agree on singleton sets and
extend the  relation on worlds. Moreover, both s and 0 are strict partial orders on
4

fiRelative Likelihood in Partially-Ordered Preferential Structures

finite sets. (The requirement that U must be nonempty in the definition of U s V is there
to ensure that we do not have ; s ;; strictly speaking, we should have also added it to
the definitions of >3 and >6 to ensure that they were strict partial orders.) As shown in
Lemma 2.9, 0 and s are in fact identical if the underlying preorder  on worlds is a total
preorder. However, as the following example shows, s and 0 are not identical in general.

Example 2.1: Suppose W = fw1 ; w2 g, and  is such that w1 and w2 are incomparable.
Then it is easy to see that fw1 ; w2 g 0 fw1 g. However, it is not the case that fw1 ; w2 g s
fw1 g, since there is no element of fw1 ; w2 g that is strictly more likely than w1 .3
Notice that we were careful to define  as we did only on finite sets. The following

example illustrates why:

Example 2.2: Let W1 = fw0 ; w1 ; w2 ; : : :g, and suppose that  is such that
w0  w1  w2  : : :
Then it is easy to see that if we were to apply the definition of s to infinite sets, then we
would have W1 s W1 , and s would not be irreexive.4
The approach for extending the definition of s to infinite sets is essentially due to

Lewis (1973) (who did it for the case of total preorders). The idea is to say that in order
to have U s V , it is not enough that for every element v in V there is some element u in
U that is more likely than v. This definition is what allows W1  W1 in Example 2.2.
Notice that in the finite case, it is easy to see that if U s V , then for every element v in
V , there must some u 2 U such that, not only do we have u  v, but u dominates V in
that for no v0 2 V do we have v0  u. It is precisely this domination condition that does
not hold in Example 2.2. This observation provides the motivation for the ocial definition
of s, which applies in both finite and infinite domains.

Definition 2.3: Suppose  is a partial preorder on W , U; V  W , and w 2 W . We say
that w dominates V if for no v 2 V is it the case that v  w. (Notice that if  is a total
preorder, this is equivalent to saying that w  v for all v 2 V .) We write U s V if U is
nonempty and, for all v 2 V , there exists u 2 U such that u  v and u dominates V .
It is easy to see that this definition of s agrees with our earlier definitions if U and V
are finite.
We now collect some properties of s , 0 , and s . To do this, we need a few definitions.
We say that a relation > on 2W (not necessarily a preorder) is qualitative if (V1 [ V2 ) > V3
and (V1 [ V3 ) > V2 implies V1 > (V2 [ V3 ). We say that > satisfies the union property if
V1 > V2 and V1 > V3 implies V1 > (V2 [ V3). We say that > is orderly if U > V , U 0  U ,
and V 0  V implies U 0 > V 0 . We provide some intuition for these properties following
Proposition 2.5, after showing how they help us characterize s , 0 , and s .
3. We remark that similar results hold for >5 and >6 . They are identical if the underlying order on worlds
is a total preorder, and this example can also be used to show that they differ if the underlying order is
partial.
4. Similar problems arise for >6 when dealing with infinite sets, and the solution for s described in
Definition 2.3 can be applied to >6 as well.

5

fiHalpern

Lemma 2.4: If > is an orderly qualitative relation on 2W , then > is transitive and satisfies

the union property.

Proof: See Appendix A.
The converse to Lemma 2.4 does not hold. Indeed, an orderly strict partial order on
2W may satisfy the union property and still not be qualitative. For example, suppose
W = fa; b; cg, and we have fa; bg > fcg, fa; cg > fbg, fa; b; cg > fbg, fa; b; cg > fcg, and
fa; b; cg > fb; cg. It can easily be checked that > is an orderly strict partial order that
satisfies the union property, but is not qualitative.
With these definitions in hand, we can state the key properties of the relations we are
interested in here.

Proposition 2.5:
(a) If  is a partial preorder on W , then s is an orderly partial preorder on 2W that
satisfies the union property.

(b) If  is a partial preorder on W , then 0 is an orderly strict partial order on 2W .
(c) If  is a strict partial order on W , then s is an orderly qualitative strict partial
order on 2W .

Proof: See Appendix A.
We can now discuss how to interpret the properties we have been considering in light of
this result.
To the extent that we think of > as meaning \more likely than", then orderliness is a
natural property to require. If U is more likely than V , then certainly any superset of U
should be more likely than any subset of V . It is thus not surprising that all three of the
relations we have defined are orderly.
Clearly the union property generalizes to arbitrary finite unions. That is, if > satisfies
the union property and A > Bi , i = 1; : : : ; n, then A > B1 [ : : : [ Bn . In particular, if
u  vj for j = 1; : : : ; N , then fug s fv1 ; : : : ; vN g, no matter how large N is, and similarly
if we replace  by  (since the fact that s is qualitative means that it satisfies the union
property, by Lemma 2.4). This is very different from probability, where suciently many
\small" probabilities eventually can dominate a \large" probability. This suggests that
u  v should perhaps be interpreted as \u is much more likely than v". More generally,
if > satisfies the union property, then U > V can be interpreted as meaning that U is
much more likely than V . In this sense, the notion of likelihood corresponding to s or s
is closer to possibility (Dubois & Prade, 1990) than probability, since the relation \more
possible than" satisfies the union property.
Note that, in general, 0 does not satisfy the union property. In Example 2.1, we have
fw1 ; w2 g 0 fw1 g and fw1 ; w2 g 0 fw2 g, but we do not have fw1 ; w2 g 0 fw1 ; w2 g.
The qualitative property is somewhat more dicult to explain intuitively. Of the three
relations we are considering, only the s relation satisfies it. The fact that 0 does not
satisfy it follows from Lemma 2.4, together with the observation that 0 does not satisfy
the union property. Example 2.1 also shows that s is not qualitative, since if it were,
6

fiRelative Likelihood in Partially-Ordered Preferential Structures

we could conclude from fw1 ; w2 g s fw2 g (taking V1 = fw1 g and V2 = V3 = fw2 g in the
definition of qualitative) that fw1 g s fw2 g, a contradiction. Our interest in the qualitative
property stems from the fact that, in a precise sense, it is the property that characterizes
s. It first arose in (Friedman & Halpern, 1997), where it was shown to be the key property
required of a generalization of probability called plausibility to capture default reasoning.
This is discussed in more detail in Section 4.
If  is a total preorder, then we get further connections between these notions. Before
we discuss the details, we need to define the analogue of total preorders in the strict case.
A relation > on an arbitrary set W 0 (not necessarily of the form 2W ) is modular if w1 >w2
implies that, for all w3 , either w3 > w2 or w1 > w3 . Modularity is the \footprint" of a total
preorder on the strict order determined by it. This is made precise in the following lemma.
Lemma 2.6: If  is a total preorder, then the strict partial order  determined by  is
modular. Moreover, if > is a modular, strict partial order on W , then there is a total
preorder  on W such that > is the strict partial order determined by .
Proof: See Appendix A.
Modularity is preserved when we lift the preorder from W to 2W .
Lemma 2.7: If  is a modular relation on W , then s is a modular relation on 2W .
Proof: See Appendix A.
Although we showed that the converse to Lemma 2.4 does not hold in general for strict
partial orders, it does hold for orders that are modular.
Lemma 2.8: If > is a modular strict partial order and satisfies the union property, then
> is qualitative.
Proof: See Appendix A.
As shown in (Friedman & Halpern, 1997), there is a connection between nonmonotonic
reasoning, conditional logic, and the qualitative property. (This is discussed in Section 4.)
This relationship is best understood by considering s, rather than s or 0 , which is why
we focus on s here. Lewis (1973) was able to use 0 because he focused on total preorders.
The following lemma makes this precise.
Lemma 2.9: If  is a total preorder, then s and 0 agree. In general, U s V implies
U 0 V , but the converse does not hold.
Proof: See Appendix A.
We close this section by considering when a preorder on 2W can be viewed as being
generated by a preorder on W . This result turns out to play a key role in our completeness
proof, and emphasizes the role of the qualitative property.
Theorem 2.10: Let F be a finite algebra of subsets of W (that is, F is a set of subsets of
W that is closed under union and complementation and contains W itself) and let > be an
orderly qualitative relation on F .
7

fiHalpern

(a) If > is a total preorder on F , then there is a total preorder  on W such that > and
s agree on F (that is, for U; V 2 F , we have U > V iff U s V ).
(b) If > is a strict partial order and each nonempty set in F has at least 2log(jFj)
elements, then there is a partial preorder  on W such that > and s agree on F .

log(jF j)

Proof: An atom of F is a minimal nonempty element of F . Since F is finite, it is easy to
see that every element of F can be written as a union of atoms, and the atoms are disjoint.
Part (a) is easy: for each w 2 W , let Aw be the unique atom in F containing w. Define 
on W so that v  w iff Av > Aw . It is easy to see that if > is a total preorder on F , then
 is a total preorder on W and > agrees with s on F . The proof of (b) is considerably

more dicult; see Appendix A for details.
It is not clear that the requirement that the sets in F have at least 2log(jFj)
elements
is necessary. However, it can be shown that Theorem 2.10(b) does not hold without some
assumptions on the cardinality of elements in F . For example, suppose that the atoms of
F are A, B , and C . Let > be defined so that (B [ C ) >A, W >A, X > ; for all nonempty
X 2 F , and these are the only pairs of sets that are in the > relation. It is easy to see
that > is an orderly, qualitative, strict partial order. However, if W = fa; b; cg, A = fag,
B = fbg, and C = fcg, there is no ordering  on W such that s and > agree on F : it is
easy to see that such an ordering  must make a, b, and c incomparable. But if they are
incomparable, we cannot have fb; cg s fag. On the other hand, if we allow C to have two
elements, by taking W = fa; b; c; dg, A = fag, B = fbg, and C = fc; dg, then there is an
ordering  such that s = >: we simply take a  c and b  d.
log(jF j)

3. A Logic of Relative Likelihood

We now consider a logic for reasoning about relative likelihood. Let  be a set of primitive
propositions. A basic likelihood formula (over ) is one of the form '  , where ' and
are propositional formulas over . We read '  as \' is more likely than ". Let L
consist of Boolean combinations of basic likelihood formulas. Notice that we do not allow
nesting of likelihood in L, nor do we allow purely propositional formulas. There would no
diculty extending the syntax and semantics to deal with them, but this would just obscure
the issues of interest here.
A preferential structure (over ) is a tuple M = (W; ;), where W is a (possibly
infinite) set of possible worlds,  is a partial preorder on W , and  associates with each
world in W a truth assignment to the primitive propositions in . Notice that there may be
two or more worlds with the same truth assignment. As we shall see, in general, we need to
have this, although in the case of total preorders, we can assume without loss of generality
that there is at most one world associated with each truth assignment.
We can give semantics to formulas in L in preferential structures in a straightforward
way. For a propositional formula ', let [ '] M consist of the worlds in M whose truth
assignment satisfies '. We then define

M j= '  if [ '] M s [ ] M .
We extend j= to Boolean combinations of basic formulas in the obvious way.
8

fiRelative Likelihood in Partially-Ordered Preferential Structures

Notice that M j= :(:'  false) iff [ :'] M = ; iff [ '] M = W . Let K' be an abbreviation for :(:'  false). It follows that M j= K' iff ' is true at all possible worlds.5
With these definitions, we can provide a sound and complete axiomatization for this
logic of relative likelihood. Let AX consist of the following axioms and inference rules.
L1.
L2.
L3.
L4.
Gen.
MP.

All substitution instances of tautologies of propositional calculus
:('  ')
(('1 _ '2 )  '3 ) ^ (('1 _ '3 )  '2 ) ) ('1  ('2 _ '3 ))
(K (' ) '0 ) ^ K ( 0 ) ) ^ ('  )) ) '0  0
K', for all propositional tautologies ' (Generalization)
From ' and ' ) infer (Modus ponens)

L2, L3, and L4 just express the fact that s is irreexive, qualitative, and orderly,
respectively; this is made precise in the proof of the following result. The axiom Gen is the
analogue of the inference rule \From ' infer K'", typically known as generalization. We
do not have this inference rule here, since our language does not allow nested occurrences
of . Thus, for an arbitrary formula ', the formula K' is not in our language. It is in our
language only if ' is propositional; the axiom takes care of this case.

Theorem 3.1: AX is a sound and complete axiomatization of the language L with respect
to preferential structures.

Proof: The validity of L1 is immediate. It is clear that the fact that s is irreexive and

qualitative, as shown in Proposition 2.5, implies that L2 and L3 are valid. To see that L4
corresponds to orderliness, note that if M j= K (' ) '0 ) ^ K ( 0 ) ) and '  , then
[ '] M  [ '0 ] M , [ 0 ] M  [ ] M , and [ '] M s [ ] M . Since s is orderly, it follows that
[ '0 ] M s [ 0 ] M , so M j= '0  0 . Thus, L4 is valid. It is also clear that MP and Gen
preserve validity. Thus, the axiomatization is sound.
The completeness proof starts out, as is standard for completeness proofs in modal logic,
with the observation that it suces to show that a consistent formula is satisfiable. That
is, we must show that every formula ' for which it is not the case that :' is provable
from AX is satisfiable in some preferential structure M . However, the standard modal
logic techniques of constructing a canonical model (see, for example, (Hughes & Cresswell,
1968)) do not seem to work in this case. Finding an appropriate partial preorder on worlds
is nontrivial. For this we use (part (b) of) Theorem 2.10. See Appendix A for the details.
What happens if we start with a total preorder? Let AXM consist of AX together with
the obvious axiom expressing modularity:
L5. ('1  '2 ) ) (('1  '3 ) _ ('3  '2 ))
We say that a preferential structure is totally preordered if it has the form (W; ; ),
where  is a total preorder on W .
5. K was defined by Lewis (1973), although he wrote 2 rather than K .

9

fiHalpern

Theorem 3.2: AXM is a sound and complete axiomatization of the language L with respect
to totally preordered preferential structures.

Proof: For soundness, we just have to check that L5 is valid in totally ordered preferential

structures. This is straightforward and left to the reader. The completeness proof uses
Theorem 2.10 again, but is simpler than the proof of completeness in Theorem 3.1. We
leave details to Appendix A.
We remark that in light of Proposition 2.8, we can replace L4 in AXM by axioms saying
that  is transitive and satisfies the union property, namely:
L6. ('1  '2 ) ^ ('2  '3 ) ) ('1  '3 )
L7. (('1  '2 ) _ ('1  '3 )) ) ('1  ('1 _ '2 ))
The result is an axiomatization that is very similar to that given by Lewis (1973).
In the proof of Theorem 3.1, when showing that a consistent formula ' is satisfiable, the
structure constructed may have more than one world with the same truth assignment. This
is necessary, as the following example shows. (We remark that this observation is closely
related to the cardinality requirements in Theorem 2.10(b).)

Example 3.3: Suppose  = fp; qg. Let ' be the formula (p  (:p ^ q)) ^ :((p ^ q) 
(:p ^ q)) ^:((p ^:q)  (:p ^ q)). It is easy to see that ' is satisfied in a structure consisting
of four worlds, w1 ; w2 ; w3 ; w4 , such that w1  w3 , w2  w4 , p ^ q is true at w1 , p ^:q is true
at w2 , and :p ^ q is true at both w3 and w4 . However, ' is not satisfiable in any structure
where there is at most one world satisfying :p ^ q. For suppose M were such a structure,
and let w be the world in M satisfying :p ^ q. Since M j= p  (:p ^ q), it must be the
case that [ p] M s fwg. Thus, there must be a world w0 2 [ p] M such that w0  w. But w0
must satisfy one of p ^ q or p ^ :q, so M j= ((p ^ q)  (:p ^ q)) _ ((p ^ :q)  (:p ^ q)),
contradicting the assumption that M j= '.
It is not hard to see that the formula ' of Example 3.3 is not satisfiable in a totally
preordered preferential structure. This is not an accident.

Proposition 3.4: If a formula is satisfiable in a totally preordered preferential structure,

then it is satisfiable in a totally preordered preferential structure with at most one world per
truth assignment.

Proof: See Appendix A.
The results of this and the previous section help emphasize the differences between
totally preordered and partially preordered structures.

4. Related Work

The related literature basically divides into two groups (with connections between them):
(a) other approaches to relative likelihood and (b) work on conditional and nonmonotonic
logic.
10

fiRelative Likelihood in Partially-Ordered Preferential Structures

We first consider relative likelihood. Gardenfors (1975) considered a logic of relative
likelihood, but he took as primitive a total preorder on the sets in 2W , and focused on
connections with probability. In particular, he added axioms to ensure that, given a preorder
s on 2W , there was a probability function Pr with the property that (in our notation)
U s V iff Pr(U )  Pr(V ). Fine (1973) defines a qualitative notion  of comparative
probability, but like Gardenfors, assumes that the preorder on sets is primitive, and is
largely concerned with connections to probability.
Halpern and Rabin (1987) consider a logic of likelihood where absolute statements about
likelihood can be made (' is likely, is somewhat likely, and so on), but there is no notion
of relative likelihood.
Of course, there are many more quantitative notions of likelihood, such as probability,
possibility (Dubois & Prade, 1990), ordinal conditional functions (OCFs) (Spohn, 1988),
and Dempster-Shafer belief functions (Shafer, 1976). The ones closest to the relative likelihood considered here are possibility and OCFs. Recall that a possibility measure Poss on
W associates with each world its possibility, a number in [0; 1], such that for V  W , we
have Poss(V ) = supfPoss(v) : v 2 V g, with the requirement that Poss(W ) = 1. Clearly a
possibility measure places a total preorder on sets, and satisfies the union property, since
Poss(A [ B ) = max(Poss(A); Poss(B )). The same is true for OCFs; we refer the reader
to (Spohn, 1988) for details. Fari~nas del Cerro and Herzig (1991) define a logic QPL
(Qualitative Possibilistic Logic) with a modal operator , where '  is interpreted as
Poss([['] )  Poss([[ ] ). Clearly, '  essentially corresponds to  '. They provide
a complete axiomatization for their logic, and prove that it is equivalent to Lewis' logic.6
Not surprisingly, an analogue of AX M is also complete for the logic. Further discussion of
the logic can be found in (Bendova & Hajek, 1993). We discuss other connections between
possibility measures, OCFs, and our logic below, in the context of conditionals.
We now turn our attention to conditional logic. Lewis's main goal in considering preferential structures was to capture a counterfactual conditional !, where ! ' is read
as \if were the case, then ' would be true" as in \if kangaroos had no tails, then they
would topple over". He takes this to be true at a world w if, in all the worlds \closest" to
w (where closeness is defined by a preorder ) where kangaroos don't have tails, it is the
case that kangaroos topple over.7
More abstractly, in the case where W is finite, for a subset V  W , let best(V ) = fv 2
V : v0  v implies v0 2= V g. Thus, best(V ) consists of all worlds v 2 V such that no world
v0 2 V is considered more likely than v. (We take best(;) = ;.)
If W is finite, we define
(M; w) j= ! ' if best([[ ] M )  [ '] M .
Thus,
true.

! ' is true exactly if ' is true at the most likely (or closest) worlds where ' is

6. Actually, the axiomatization given in (Fari~nas del Cerro & Herzig, 1991) is not quite complete as stated;
to get completeness, we must replace their axiom QPL4|true  '|by the axiom '  false [Luis Fari~nas
del Cerro, private communication, 1996].
7. To really deal appropriately with counterfactuals, we require not one preorder , but a possibly different
preorder w for each world w, since the notion of closeness in general depends on the actual world. We
ignore this issue here, since it is somewhat tangential to our concerns.

11

fiHalpern

For infinite domains, this definition does not quite capture our intentions. For example,
in Example 2.2, we have best(W1 ) = ;. It follows that if M = (W1 ; ; ), then M j=
true ! :p even if  makes p true at every world in W1 . We certainly would not want to
say that \if true were the case, then p would be false" is true if p is true at all the worlds in
W1 ! The solution here is again a generalization of Lewis's definition in the case of totally
ordered worlds, and is much like that for s in infinite domains. We say M j= ! ' if
for all u 2 [ :' ^ ] M , there exists a world v 2 [ ' ^ ] M such that v  u and v dominates
[ :' ^ ] M . This definition agrees with the definition given above for the case of finite W .

Lemma 4.1: If W is finite, then best([[ ] M )  [ '] M iff for all u 2 [ :' ^ ] M , there exists
a world v 2 [ ' ^ ] M such that v  u and v dominates [ :' ^ ] M .
Proof: See Appendix A.
Lewis (1973) argues that this definition of ! captures many of our intuitions for counterfactual reasoning. We can give ! another interpretation, perhaps more natural if we are
thinking in terms of likelihood. We often want to say that ' is more likely than not|in L,
this can be expressed as '  :'. More generally, we might want to say that relative to ,

or conditional on being the case, ' is more likely than not. By this we mean that if we
restrict to worlds where is true, ' is more likely than not, that is, the worlds where ' ^
is true are more likely than the worlds where :' ^ is true.
Let us define !0 ' to be an abbreviation for K : _ (' ^  :' ^ ). That is,
!0 ' is true vacuously in a structure M if does not hold in any world in M ; otherwise,
it holds if ' is more likely than not in the worlds satisfying .
Although the intuition for !0 seems, on the surface, quite different from that for !,
especially in finite domains, it is almost immediate from their formal definitions that they
are equivalent. (This connection between ! and !0 was already observed by Lewis (1973)
in the case of total proeorders.)

Lemma 4.2: For all structures M , we have M j= ! ' iff M j= !0 '.
Proof: This is almost immediate from the definitions. See Appendix A for details.
Given Lemma 4.2, we can write ! for both ! and !0 . The lemma also allows us to

apply the known results for conditional logic to the logic of relative likelihood defined here.
In particular, the results of (Friedman & Halpern, 1994) show that the validity problem for
the logic of Section 3 is co-NP complete, no harder than that of propositional logic, for the
case of both partial and total preorders.8
More recently, ! has been used to capture nonmonotonic default reasoning (Kraus et al.,
1990; Boutilier, 1994). In this case, a statement like Bird ! Fly is interpreted as \birds
typically y", or \by default, birds y". The semantics does not change: Bird ! Fly is
true if in the most likely worlds satisfying Bird , Fly holds as well. Dubois and Prade (1991)
have shown that possibility can be used to give semantics to defaults as well, where ! '
8. We remark that there are also well known axiomatizations for various conditional logics (Burgess, 1981;
Friedman & Halpern, 1994; Lewis, 1973). These do not immediately give us a complete axiomatization
for the logic of relative likelihood considered here, since we must find axioms in the language with ,
not in the language with !.

12

fiRelative Likelihood in Partially-Ordered Preferential Structures

is interpreted as Poss( ) = 0 or Poss(' ^ ) > Poss(' ^ : ). Of course, this is just the
analogue of the definition of ! in terms of s. Goldszmidt and Pearl (1992) have shown
that a similar approach works if we use Spohn's OCFs.
These results are clarified and unified in (Friedman & Halpern, 1997). Suppose we start
with some mapping Pl of sets to a partially ordered space with minimal element ? (such
a mapping is called a plausibility measure in (Friedman & Halpern, 1997)). Define ! '
as Pl(') = ? or Pl( ^ ') > Pl( ^ :'). Then it is shown that ! satisfies the KLM
properties|the properties isolated by Kraus, Lehmann, and Magidor (1990) as forming the
core of default reasoning|if and only if Pl is qualitative, at least when restricted to disjoint
sets.9 Since s, Poss, and OCFs give rise to qualitative orders on 2W , it is no surprise that
they should all lead to logics that satisfy the KLM properties.
We remark we can also start with !, and then define  in terms of !. There are, in
fact, three related ways of doing so. Define ' 0 to be an abbreviation for ((' _ ) ! (' ^
: )) ^:((' _ ) ! ); define ' 00 to be an abbreviation for :(' ! ) ^ ((' _ ) ! : );
define ' 000 to be an abbreviation for :(' ! false) ^ ((' _ ) ! (' ^ : )).

Proposition 4.3: For all structures M , the following are equivalent:
(a) M j= ' 
(b) M j= ' 0
(c) M j= ' 00 .
(d) M j= ' 000 .
The first translation is essentially due to Kraus, Lehmann, and Magidor (1990), the second is essentially due to Freund (1993), and the third is due to Lewis (1973). Since the
equivalences are so close to those already in the literature, we omit the proof of this result
here. Using these equivalences and results of (Kraus et al., 1990), Daniel Lehmann [private
correspondence, 1996] has provided an alternate proof for Theorem 3.1. See the remarks
after the proof of that theorem in Appendix A for a few more details.

5. Conclusion

We have investigated a notion of relative likelihood starting with a preferential ordering on
worlds. This notion was earlier studied by Lewis (1973) in the case where the preferential
order is a total preorder; the focus of this paper is on the case where the preferential order is
a partial preorder. Our results show that there are significant differences between the totally
ordered and partially ordered case. By focusing on the partially ordered case, we bring out
the key role of the qualitative property (Axiom L3), whose connections to conditional logic
were already observed in (Friedman & Halpern, 1997).
9. That is, if V1 , V2 , and V3 are disjoint sets, we require that if Pl(V1 [V2 ) > Pl(V3 ) and Pl(V1 [V3 ) > Pl(V2 ),
then Pl(V1 ) > Pl(V2 [ V3 ). The result also requires the assumption that if Pl(U ) = Pl(V ) = ?, then
Pl(U [ V ) = ?.

13

fiHalpern

Acknowledgements
Many interesting and useful discussions on plausibility with Nir Friedman formed the basis
for this paper; Nir also pointed out the reference (Doyle et al., 1991). Daniel Lehmann,
Emil Weydert, and the referees of the paper also provided useful comments. A preliminary
version of this paper appears in Uncertainty in Artificial Intelligence, Proceedings of the
Twelfth Conference, 1996, edited by E. Horvitz and F. Jensen. Most of this work was
carried out while the author was at the IBM Almaden Research Center. IBM's support
is gratefully acknowledged. The work was also supported in part by NSF under grants
IRI-93-03109 and IRI-96-25901, and by the Air Force Oce of Scientific Research under
contract F49620-96-1-0323.

Appendix A. Proofs

We repeat the statements of the results we are proving here for the convenience of the
reader.

Lemma 2.4: If > is an orderly qualitative relation on 2W , then > is transitive and

satisfies the union property.
Proof: Suppose > is an orderly qualitative relation. To see that > is transitive, suppose
V1 > V2 and V2 > V3. Since > is orderly, it follows that (V1 [ V3 ) > V2 and (V1 [ V2 ) > V3 .
Since > is qualitative, it follows that V1 > (V2 [ V3 ). From the fact that > is orderly, we
get that V1 > V3 . Thus, > is transitive, as desired.
To see that > satisfies the union property, suppose V1 > V2 and V1 > V3 . Since > is
orderly, we have that (V1 [ V3) >V2 and (V1 [ V2) >V3 . Using the fact that > is qualitative,
we get that V1 > (V2 [ V3 ). Hence, > satisfies the union property.

Proposition 2.5:
(a) If  is a partial preorder on W , then s is an orderly partial preorder on 2W that
satisfies the union property.
(b) If  is a partial preorder on W , then 0 is an orderly strict partial order on 2W .
(c) If  is a strict partial order on W , then s is an orderly qualitative strict partial
order on 2W .

Proof: We prove part (c) here; the proof of parts (a) and (b) is similar in spirit, and is
left to the reader. The fact that s is an orderly strict partial order is straightforward,
and is also left to the reader. To see that s is qualitative, suppose V1 [ V2 s V3 and
V1 [ V3 s V2 . Let v 2 V2 [ V3 . We must show that there is some v0 2 V1 that dominates
V2 [ V3 such that v0  v. Suppose without loss of generality that v 2 V2 (an identical
argument works if v 2 V3 ). Since V1 [ V3 s V2 , there is some u 2 V1 [ V3 that dominates
V2 such that u  v. If u dominates V3 , then it clearly dominates V2 [ V3 and it must be

in V1 , so we are done. Thus, we can assume that u does not dominate V3 , so there is some
element u0 2 V3 such that u0  u. Since V1 [ V2 s V3 , there must be some v0 2 V1 [ V2
14

fiRelative Likelihood in Partially-Ordered Preferential Structures

such that v0 dominates V3 and v0  u0 . Since u dominates V2 and u0  u, it follows that u
dominates V2 . Since v0  u0 , we have that v0 dominates V2 . Hence, v0 dominates V2 [ V3 .
It follows that v0 cannot be in V2 , so it must be in V1 . Thus, we have an element in V1 ,
namely v0 , such that v0  v and v0 dominates V2 [ V3 , as desired.

Lemma 2.6: If  is a total preorder, then the strict partial order  determined by 
is modular. Moreover, if > is a modular, strict partial order on W , then there is a total
preorder  on W such that > is the strict partial order determined by .
Proof: Suppose  is a total preorder. To see that  is modular, suppose that w1  w2 .
Given an arbitrary w3 , if w3  w1 , it follows from the transitivity of  that w3  w2 . On
the other hand, if it is not the case that w3  w1 , then w1  w3 . Thus, we have that either
w3  w2 or w1  w3 , so  is modular.
Now suppose that > is a modular strict partial order on W . Define  so that w  v
either if w > v or if neither w > v nor v > w hold. Clearly,  is reexive. To see that it
is transitive, suppose that v1  v2 and v2  v3 . There are three cases: (1) If v1 > v2 , then
since > is modular, we have that either v1 > v3 or v3 > v2 . We cannot have v3 > v2 , for
then we would not have v2  v3 . Thus, we must have v1 > v3 , and hence v1  v3 . (2) If
v2 > v3 , then using modularity again, we get that either v1 > v3 or v2 > v1. Again, we
cannot have v2 > v1 , so we must have v1 > v3 , and so we also have v1  v3 . (3) If neither
v1 >v2 nor v2 >v3 hold, then we claim that neither v1 >v3 nor v3 >v1 hold. For if v1 >v3 ,
then by modularity, we must have either v1 > v2 or v2 > v3 . And if v3 > v1 , then either
v3 > v2 or v2 > v1 , which contradicts the assumption that v1  v2 and v2  v3 . Thus, we
can again conclude that v1  v3 . Thus,  is transitive. Finally, it is almost immediate from
the definition that > is the strict partial order determined by .
Lemma 2.7: If  is a modular relation on W , then s is a modular relation on 2W .
Proof: Suppose  is modular. We want to show that s is modular. So suppose that
V1 s V2 , and it is not the case that V1 s V3. We must show that V3 s V2 . Since it is not
the case that V1 s V3 , there must be some v 2 V3 such that for all u 2 V1 , we do not have
u  v . Now suppose v 2 V2. We claim that v  v. To see this, note that since V1 s V2 ,
there must be some u 2 V1 such that u  v. Since  is modular, we have that either
u  v or v  v. Since, by choice of v , we do not have u  v , we must have v  v. It
follows that V3 s V2 .
Lemma 2.8: If > is a modular strict partial order and satisfies the union property, then

> is qualitative.
Proof: Suppose that > is modular strict partial order that satisfies the union property.
To see that > is qualitative, suppose that (V1 [ V2 ) > V3 and (V1 [ V3 ) > V2 . Since > is
modular, it follows that either (V1 [ V2 ) > V1 or V1 > V3 . If (V1 [ V2 ) > V1 , then, using the
fact that > satisfies the union property and (V1 [ V2 ) >V3 , we get that (V1 [ V2 ) > (V1 [ V3 ).
Using transitivity, it follows that (V1 [ V2 ) > V2 . Using the union property again, we get
that (V1 [ V2 ) > (V1 [ V2 ). This contradicts the assumption that > is irreexive. Thus, we
15

fiHalpern

must have that V1 >V3 . A similar argument shows that V1 >V2 . Using the union property,
we get that V1 > (V2 [ V3 ), as desired.

Lemma 2.9: If  is a total preorder, then s and 0 agree. In general, U s V implies
U 0 V , but the converse does not hold.
Proof: It is immediate from the definitions that U s V implies U 0 V , and the fact that
the converse does not hold is shown by Example 2.1. To show that s and 0 are equivalent
if  is a total preorder, suppose U 0 V . Clearly U is nonempty, since V s ; for all V .
We want to show that U s V , so we must show that for all v 2 V , there is some u 2 U
that dominates V such that u  v. We actually show that there is some u 2 U such that
u  v0 for all v0 2 V . Suppose not. Then for every u 2 U , there is some vu such that we do
not have u  vu . Since  is a total order, this means that vu  u. But this, in turn, means
that V s U , contradicting our assumption that U s V . Since there is a u 2 U such that
u  v for all v 2 V , it easily follows that u dominates V and that U s V , as desired.
Theorem 2.10: Let F be a finite algebra of subsets of W (that is, F is a set of subsets

of W that is closed under union and complementation and contains W itself) and let > be
an orderly qualitative relation on F .
(a) If > is a total preorder on F , then there is a total preorder  on W such that > and
s agree on F (that is, for U; V 2 F , we have U > V iff U s V ).
(b) If > is a strict partial order and each nonempty set in F has at least 2log(jFj)
elements, then there is a partial preorder  on W such that > and s agree on F .

log(jF j)

Proof: Part (a) was already proved in the main text, so we prove part (b) here.

We proceed as follows. We say that a pair (A; X ) is minimal pair of > if X > A and
there is no X 0  X (\" is used here to denote strict subset) such that X 0 > A. The
minimal pairs in an ordered relation determine it. Indeed, the following stronger result
holds.

Lemma A.1: If > and >0 are two orderly qualitative relations on F such that for each

minimal pair (A; X ) of > we have X > A, and for each minimal pair (A0 ; X 0 ) of >0 we
have X 0 >0 A0 , then > = >0 .

Proof: Suppose the assumptions of the lemma holds and that X > Y ; we must show that
X >0 Y . Suppose A is an atom such that A  Y . Since > is orderly, we must have X >A.
Let X 0 be a minimal subset of X such that X 0 > A. Since F is finite, such an X 0 must

exist. Thus, (A; X 0 ) is a minimal pair of >. By assumption, we have X 0 >0 A. Since >0
is orderly, we also have X >0 A. Thus, we have X >0 A for each atom A  Y . Since
>0 is qualitative, it also satisfies the union property, and hence X >0 Y as desired. By
symmetry, it follows that > = >0 .
A minimal-pair tree for > is a rooted tree whose nodes are labeled by atoms such that
the following conditions are satisfied:
16

fiRelative Likelihood in Partially-Ordered Preferential Structures

1. If a node in the tree labeled B is an immediate successor of a node labeled A, then
there must be a minimal pair (A; X ) of > such that B  X .
2. If there is a node t in the tree labeled A and a minimal pair of > of the form (A; X ),
then there must be some atom B  X such that a node labeled B is an immediate
successor of t.
3. There does not exist a path in the tree such that two nodes in the path have the same
label.
4. A node does not have two distinct successors with the same label.
A minimal-pair tree is rooted at A if the root of the tree is labeled by the atom A.
Since a subset of F can be written in a unique way as the union of atoms, there is
a 1-1 correspondence between subsets of F and sets of atoms. Thus, there are exactly
log(jFj) atoms. Because of the third condition, a path in the tree can have length at
most log(jFj). Since all the atoms on the path must be distinct, it follows that there
are at most log(jFj)!  log(jFj)log(jFj) (= jFjlog log(jFj) ) possible paths in a tree rooted at
A. We can identify a tree with the set of its paths, which means that there are at most
2log(jFj)!  2log(jFj)
possible trees rooted at an atom A.
We now label each element in W with a minimal-pair tree in such a way that every
element of atom A is labeled by a tree rooted at A, and every minimal-pair tree rooted at A
is the label of some element of A. Since we have assumed that A has at least 2log(jFj)
elements, there is such a labeling. Let L(w) be the label of node w. We define  on W so
that w0  w iff L(w0 ) is a proper subtree of L(w). Clearly  is a strict partial order.
We claim that > agrees with s. By Lemma A.1, it suces to show that if (A; X ) is a
minimal pair of >, then X s A, and if (A; X ) is a minimal pair of s , then X > A. So
suppose (A; X ) is a minimal pair of >. We want to show that X s A. Let w 2 A, and
suppose that L(w) = T . Thus, T is a minimal-pair tree rooted at A. The construction of
minimal-pair trees guarantees that there is a successor of the root in tree T labeled B for
some atom B  X . Consider the subtree of T rooted at B . This is a minimal-pair tree
rooted at B , and hence must be the label of some w0 2 B  X . Thus, w0  w. It follows
that X s A.
Now suppose that (A; X ) is a minimal pair of s . We want to show that X > A.
Suppose not. As we show below, this means that there exists a minimal-pair tree T rooted
at A such that no node in T is labeled by an atom contained in X . Let w be an element of
A with L(w) = T . By construction, there is no element w0 of X such that w0  w. Thus,
we do not have X s A, contradicting our initial assumption.
It remains to show that there exists a minimal-pair tree T rooted at A such that no
node in T is labeled by an atom contained in X . Clearly, we cannot have X 0 > A for some
X 0  X , for then, by the preceding argument, we would have X 0 s A, and (A; X ) would
not be a minimal pair of s. It follows that if (A; Y ) is a minimal pair of >, then we must
have Y , X 6= ;.
Two general fact about orderly, qualitative relations will be useful in our construction:
log(jF j)

log(jF j)

Lemma A.2: If >0 is a qualitative relation on F and Y >0 X , then (Y , X ) >0 X .
17

fiHalpern

Proof: Notice that (Y , X ) [ X >0 X . Since >0 is qualitative, it follows that (Y , X ) >0 X

(take both V2 and V3 in the definition of qualitative to be X ).
Lemma A.3: If >0 is an orderly, qualitative relation such that (X1 [ X2 ) >0 X3 and
X 0 >0 X2 , then (X1 [ X 0 ) >0 X3 .
Proof: Since >0 is orderly, our assumptions imply that (X1 [ X 0 [ X2 ) >0 X3 and that
(X1 [ X 0 [ X3 ) >0 X2 . Since >0 is qualitative, it follows that (X1 [ X 0 ) > (X2 [ X3 ). The
result follows using the fact that >0 is orderly again.
We start by constructing a tree whose nodes are labeled by atoms and whose root is
labeled by A. We proceed in log(jFj) + 1 stages. At each stage, we have a tree whose nodes
are labeled by atoms. At stage 0, we just take a single node labeled by A. Suppose we
have constructed a tree whose nodes are labeled by atoms and whose root is labeled by A
at stage k < log(jFj). For stage k + 1, for each leaf t in the stage-k tree, if t is labeled by
B , then for each atom C , if there is a minimal pair (B; Y ) of > with C  Y , we add a
successor to t labeled C . We call the tree constructed at the end of stage log(jFj) the full
tree for A.
We next mark nodes in the full tree in stages. At the kth stage, for each atom B , we
mark an unmarked node t labeled B if one of the following three conditions holds: (1)
B  X , (2) there is an ancestor of t in the tree also labeled B , (3) there is a minimal pair
(B; Y ) of > and all the successors of t with a label contained in Y were marked at an earlier
stage. If there are no unmarked nodes satisfying one of these three conditions at stage k,
then the marking process stops. Otherwise, we continue to stage k +1. Since there are only
finitely many nodes, this marking process is guaranteed to terminate.
Our goal is to show that, at the end of the marking process, the root of the full tree
is unmarked. For if this is the case, let T be the subtree of the full tree consisting of all
the unmarked nodes all of whose ancestors are unmarked. It is easy to check that T is a
minimal-pair tree and our marking procedure guarantees that no node in T is labeled by
an atom contained in X , so we are done.
To see that the root of the full tree is unmarked, we proceed as follows: Define a 0-cover
for a node t in the full tree to be just t itself. Suppose we have defined a k-cover for t. A
set Z of nodes is a (k + 1)-cover for t if there exists a k-cover Z 0 for t such that for some
node t0 in Z 0 labeled B and some minimal pair (B; Y ) of >, we have that Z consists of all
the nodes in Z 0 except for t0 , together with all the successors of t0 that are labeled by an
atom contained in Y . An easy argument by induction on k shows the following.
Lemma A.4: If Z is a k-cover for a node t labeled C and k > 0, then there exist a set Y
such that (C; Y ) is a minimal pair of >, successors t1 ; : : : ; tm of t in the full tree, atoms
D1 ; : : : ; Dm such that Y = [mi=1Di and Di is the label of ti , i = 1; : : : ; m, and a partition
Z1 ; : : : ; Zm of Z into disjoint subsets such that Zi is a ki -cover for ti, i = 1; : : : ; m, for
some ki < k.
Given a set Z , let UZn consist of the union of the atoms labeling the nodes of Z still
unmarked at the nth stage (we take UZ0 to be the union of the atoms labeling the nodes in
Z ); given a node t, let Vt consist of the union of the atoms D labeling ancestors of t such
that t or some descendent of t has the label D.
The key fact is the following result.
18

fiRelative Likelihood in Partially-Ordered Preferential Structures

Lemma A.5: If Z is a k-cover for a node t labeled C and k > 0, then (UZn [ Vt [ X ) > C .
Proof: We proceed by induction on k, with a subinduction on n. If k = 1, then there is
some set Y such that (C; Y ) is a minimal pair of > and the nodes in Z are labeled by the
atoms contained in Y . Since (C; Y ) is a minimal pair of >, we have that Y > C . Since >
is orderly, (Y [ Vt [ X ) > C . By definition, UZ0 = Y , so this takes care of the case n = 0.
Suppose n > 0 and (UZn,1 [ Vt [ X ) > C . For the inductive step, it suces to show that
that if
(Y 0 [ V t [ X ) > C
(1)
and D is the label of a node t0 in Z marked at stage n, then
((Y 0 , D) [ Vt [ X ) > C:

(2)

So suppose that (1) holds and D is the label of t0 . We must consider how t0 was marked.
If D  X then (2) is immediate. If there is an ancestor of t0 also labeled D, then D  Vt ,
and, since k = 1, we have Vt  Vt [ C . Thus, since > is orderly, it follows that
0

0

((Y 0 , D) [ Vt [ X [ C ) > C;

(3)

so (2) follows from Lemma A.2. Finally, suppose there is some minimal pair (D; Y 00 ) of
> such that all the successors of t0 labeled by an atom in Y 00 are marked by stage n , 1.
Let Z 0 consist of the successors of t0 labeled by atoms contained in Y 00 . Z 0 is a 1-cover for
t0 . Since UZn,1 = ;, it follows from the induction hypothesis that (Vt [ X ) > D. Again,
since Vt  Vt [ C , (3) follows orderliness and Lemma A.3, and the desired (2) follows from
Lemma A.2.
Now suppose k > 1. Let Y; D1 ; : : : ; Dm ; Z1 ; : : : ; Zm ; t1 ; : : : ; tm be the sets and nodes
guaranteed to exist by Lemma A.4. Since Zi is a ki -cover for ti for some ki < k, by
the induction hypothesis, (UZn [ Vt [ X ) > Di . Since UZn  UZn and Vt  Vt [ C , by
orderliness, we have that (UZn [ Vt [ X [ C ) > Di . Since > is qualitative, we have that
(UZn [ Vt [ X [ C ) > ([i Di ). Since [iDi = Y and Y > C , (3) now follows, and again (2)
follows from Lemma A.2.
Finally, suppose, by way of contradiction, that the root r of the full tree is marked, say
at stage n of the marking process. Lemma A.2 assures us that A \ X = ;, since (A; X )
is a minimal pair of s, so condition (1) of the marking process does not apply. Since r
has no ancestors, condition (2) does not apply either. Thus, there must be some minimal
pair (A; Y ) of > such that all the nodes in the set Z consisting of the successors of r in
the full tree that are labeled by atoms contained in Y are marked by stage n , 1. Thus, we
UZn,1 = ;. Since Vr = ; and Z is a 1-cover for r, by Lemma A.5, it follows that X > A,
contradicting our original assumption.
0

0

0

i

i

i

i

For the completeness theorems (Theorems 3.1 and 3.2) it is convenient to start by proving Theorem 3.2, since it is simpler, and contains the key ideas for the proof of Theorem 3.1.

Theorem 3.2: AXM is a sound and complete axiomatization of the language L with
respect to totally preordered preferential structures.
19

fiHalpern

Proof: Soundness was proved in the main text, so we just consider completeness here.

Suppose that ' is consistent with AXM . We want to show that that ' is satisfiable in a
totally preordered preferential structure. Let '1 ; : : : ; 'm be the basic likelihood formulas
that are subformulas of '. By definition, ' is a Boolean combination of these formulas.
Define an atom over ' to be a conjunction of the form 1 ^ : : : ^ m , where i is either 'i or
:'i. Using straightforward propositional reasoning (L1 and MP), it is straightforward to
show that ' is provably equivalent to the disjunction of the consistent atoms over '. Thus,
since ' is consistent, some atom over ', say , is consistent. We now construct a totally
ordered preferential structure satisfying . Clearly this structure will satisfy ' as well.
Let p1 ; : : : ; pn be the primitive propositions in  that appear in '. Let  consist of
all the N = 2n truth assignments to these primitive propositions. We take W =  and
let F consist of all subsets of . We define a total preorder > on F as follows. Notice
that to each set V in F , there corresponds a propositional formula 'V that is made true
precisely by the truth assignments in the subset V 0 of  that corresponds to V . To be
precise, given a truth assignment ff, let 'ff consist of the conjunction q1 ^ : : : ^ qn, where qi
is pi if ff(pi ) = true, and :pi otherwise. Let 'V be the disjunction of the formulas 'ff for
ff 2 V 0 . (We take the empty disjunction to be the formula false.) Notice for future reference
that 'V [V is provably equivalent to 'V _ 'V . Conversely, for every propositional formula
that mentions only the primitive propositions in fp1 ; : : : ; pn g, there is a corresponding
subset A in F that consists of all truth assignments that make true.
We define a binary relation > on F as follows: V > V 0 iff AX `  ) ('V  'V ).
We claim that > is a modular, qualitative, strict partial order on F . The fact that > is
irreexive follows easily from L2; the fact that it is orderly follows from L4; the fact that
it is qualitative follows from L3; transitivity follows from the fact that > is qualitative and
orderly, by Lemma 2.4; modularity follows from L5. All these arguments are straightforward. We prove the fact that > is qualitative here, and leave the remaining arguments to
the reader.
Suppose V1 ; V2 ; V3 2 F , (V1 [ V2 ) > V3 , and (V1 [ V3 ) > V2 . Our assumptions and
the definition of F imply that AX `  ) (('V _ 'V )  'V ) and that AX `  )
(('V _ 'V )  'V ). By L3 and straightforward propositional reasoning, we get that
AX `  ) ('V  ('V _ 'V )), so that V1 > (V2 [ V3), as desired.
By Lemma 2.6, there is a total preorder >0 on F such that > is the strict partial order
determined by >0 . By Theorem 2.10(a), there is total preorder  on W such that >0 and
s agree on F . Since 0 is the strict partial order determined by s, it follows that 0 and
> agree. Since  is a total preorder, by Lemma 2.9, s and > agree. Let M = (W; ; ).
We now claim that for each formula 'j that is one of the basic likelihood formulas that is a
subformula of ', we M j= 'i iff 'j is a conjunct of . For suppose 'j is of the form  0 .
If 'j is a conjunct of , then clearly AX `  ) (  0 ). Thus, A > A by definition,
so A s A by construction. Since A and A consist of the worlds in W where and
0 , respectively, are true, it follows that (M; w) j=  0 . On the other hand, if :'j is a
conjunct of , then we have AX `  ) :(  0 ). We must have (M; w) j= :(  0 ),
for if (M; w) j=  0 , the same arguments as those above would imply that A > A ,
and so AX `  )  0 , contradicting the consistency of .
Thus, M satisfies , and hence '.
1

2

1

2

0

1

1

3

2

3

2

1

2

2

0

0

0

0

20

fiRelative Likelihood in Partially-Ordered Preferential Structures

Theorem 3.1: AX is a sound and complete axiomatization of the language L with respect

to preferential structures.
Proof: Again, soundness is proved in the main text, so we just consider completeness. The
ideas are much in the spirit of the proof of Theorem 3.2. We again take  to consist of all
the N = 2n truth assignments to these primitive propositions. However, since we plan to
apply part (b) of Theorem 2.10, we no longer take W = . Rather, we take W to consist
of 2n copies of the truth assignments in . More precisely, let W consist of the N 2n
worlds of the form wffi , such that i = 1; : : : ; 2n and ff 2 . Let F consist of all subsets of
W that correspond to subsets of ; that is, V 2 F iff there exists some V 0   such that
V = fwffi : i = 1; : : : ; 2n ; ff 2 V 0 g. Clearly, F is a finite algebra with N elements, and
each nonempty set in F has at least 2log(jFj)
elements.
We define a strict partial order > on F just as in the proof of Theorem 3.1: V > V 0 iff
AX `  ) 'V  'V . As before, > is an orderly qualitative strict partial order on F . It
is not necessarily modular, since we no longer have L5.
By Theorem 2.10(b), there is a partial preorder  on W such that > and s agree on
F . Let M = (W; ; ), where (wffi ) = ff. Just as in the proof of Theorem 3.2, we can now
show that M j= . .
n

n

n

n

log(jF j)

0

As we noted earlier, Daniel Lehmann has found another proof for Theorem 3.1, using
results from (Kraus et al., 1990). To show that a formula in L that is consistent with AX
is satisfiable, he first translates it to a formula of conditional logic (using Proposition 4.3).
It then follows from the representation theorem of (Kraus et al., 1990) that this translated
formula is satisfiable in a preferential structure. The original formula is then satisfiable in
the same structure. This proof allows us to avoid using Theorem 2.10 altogether. However,
we feel that Theorem 2.10 gives insight into the connection between partial orders on worlds
and partial orders on sets of worlds, and thus is of interest in its own right.

Proposition 3.4: If a formula is satisfiable in a totally preordered preferential structure,
then it is satisfiable in a totally preordered preferential structure with at most one world per
truth assignment.
Proof: This follows immediately from the completeness proof of Theorem 3.2; the structure
constructed in that proof has one world per truth assignment.
Lemma 4.1: If W is finite, then best([[ ] M )  [ '] M iff for all u 2 [ :' ^ ] M , there
exists a world v 2 [ ' ^ ] M such that v  u and v dominates [ :' ^ ] M .
Proof: Suppose best([[ ] M )  [ '] M . If u 2 [ :' ^ ] M , then we cannot have u 2
best([[ ] M ), since best([[ ] M )  [ '] M . Since W is finite, there exists a world v 2 best([[ ] M )
such that v  u. Since v 2 best([[ ] M ), we have that v dominates [ :' ^ ] M . Conversely,
suppose that for all u 2 [ :' ^ ] M , there exists a world v 2 [ ' ^ ] M such that v  u
and v dominates [ :' ^ ] M . If u 2 best([[ ] M ), then we must have u 2 [ '] M , for if not,
there exists a world v 2 [ ' ^ ] M such that v  u, contradicting the assumption that
u 2 best([['] M ).
21

fiHalpern

Lemma 4.2: For all structures M , we have M j= ! ' iff M j= !0 '.
Proof: Suppose M j= ! '. By definition, this means that for all u 2 [ :' ^ ] M , there
exists a world v 2 [ ' ^ ] M such that v  u and v dominates [ :' ^ ] M . It immediately
follows that (a) if [ ' ^ ] M = ; then [ :' ^ ] M = ; and (b) if [ ' ^ ] M 6= ;, then by
definition we have M j= ' ^  :' ^ . It follows from (a) that if [ ' ^ ] M = ; then
[ ] M = ;, so M j= K : , and from (b) that if [ ' ^ ] M 6= ; then M j= ' ^  :' ^ .
Thus, M j= K : _ (' ^  :' ^ ); i.e., M j= !0 .
The converse follows equally easily. Suppose M j= !0 '. Clearly if M j= K : then
we trivially have that for all u 2 [ :' ^ ] M , there exists a world v 2 [ ' ^ ] M such that
v  u and v dominates [ :' ^ ] M . On the other hand, if M j= ' ^  :' ^ , then it
follows by definition that for all u 2 [ :' ^ ] M , there exists a world v 2 [ ' ^ ] M such
that v  u and v dominates [ :' ^ ] M . Either way we have M j= ! '.

References
Bendova, K., & Hajek, P. (1993). Possibilistic logic as tense logic. In Carrete, N. P., &
Singh, M. G. (Eds.), Qualitative Reasoning and Decision Technologies, pp. 441{450.
Boutilier, C. (1994). Conditional logics of normality: a modal approach. Artificial Intelligence, 68, 87{154.
Brass, S. (1991). Deduction with super-normal defaults. In Proceedings of 2nd International
Workshop on Nonmonotonic and Inductive Logics, Lecture Notes in AI, Vol. 659, pp.
153{174 Berlin/New York. Springer-Verlag.
Burgess, J. (1981). Quick completeness proofs for some logics of conditionals. Notre Dame
Journal of Formal Logic, 22, 76{84.
Cayrol, C., Royer, R., & Saurel, C. (1992). Management of preferences in assumptionbased reasoning. In IPMU '92 (4th International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems), Lecture Notes in
Computer Science, Vol. 682, pp. 13{22 Berlin/New York. Springer-Verlag.
Delgrande, J. P. (1994). A preference-based approach to default reasoning. In Proceedings,
Twelfth National Conference on Artificial Intelligence (AAAI '94), pp. 902{908.
Dershowitz, N., & Manna, Z. (1979). Proving termination with multiset orderings. Communications of the ACM, 22 (8), 456{476.
Doyle, J., Shoham, Y., & Wellman, M. P. (1991). A logic of relative desire. In Proc. 6th
International Symposium on Methodologies for Intelligent Systems, pp. 16{31.
Dubois, D., & Prade, H. (1990). An introduction to possibilistic and fuzzy logics. In
Shafer, G., & Pearl, J. (Eds.), Readings in Uncertain Reasoning, pp. 742{761. Morgan
Kaufmann, San Francisco, Calif.
22

fiRelative Likelihood in Partially-Ordered Preferential Structures

Dubois, D., & Prade, H. (1991). Possibilistic logic, preferential models, non-monotonicity
and related issues. In Proc. Twelfth International Joint Conference on Artificial Intelligence (IJCAI '91), pp. 419{424.
Fari~nas del Cerro, L., & Herzig, A. (1991). A modal analysis of possibilistic logic. In
Symbolic and Quantitative Approaches to Uncertainty, Lecture Notes in Computer
Science, Vol. 548, pp. 58{62. Springer-Verlag, Berlin/New York.
Fine, T. L. (1973). Theories of Probability. Academic Press, New York.
Freund, M. (1993). Injective models and disjunctive relations. Journal of Logic and Computation, 3 (3), 231{247.
Friedman, N., & Halpern, J. Y. (1994). On the complexity of conditional logics. In Principles
of Knowledge Representation and Reasoning: Proc. Fourth International Conference
(KR '94), pp. 202{213. Morgan Kaufmann, San Francisco, Calif.
Friedman, N., & Halpern, J. Y. (1997). Plausibility measures and default reasoning. Journal
of the ACM. Accepted for publication. A preliminary version of this work appeared
in Proc. National Conference on Artificial Intelligence (AAAI '96), 1996, pages 1297{
1304.
Gardenfors, P. (1975). Qualitative probability as an intensional logic. Journal of Philosophical Logic, 4, 171{185.
Geffner, H. (1992). High probabilities, model preference and default arguments. Mind and
Machines, 2, 51{70.
Goldszmidt, M., & Pearl, J. (1992). Rank-based systems: A simple approach to belief
revision, belief update and reasoning about evidence and actions. In Principles of
Knowledge Representation and Reasoning: Proc. Third International Conference (KR
'92), pp. 661{672. Morgan Kaufmann, San Francisco, Calif.
Halpern, J. Y., & Rabin, M. O. (1987). A logic to reason about likelihood. Artificial
Intelligence, 32 (3), 379{405.
Hughes, G. E., & Cresswell, M. J. (1968). An Introduction to Modal Logic. Methuen,
London.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models and cumulative logics. Artificial Intelligence, 44, 167{207.
Lewis, D. K. (1973). Counterfactuals. Harvard University Press, Cambridge, Mass.
Przymusinski, T. (1987). On the declarative semantics of stratified deductive databses and
logic programs. In Minker, J. (Ed.), Foundations of Deductive Databases and Logic
Programming, pp. 193{216. Morgan Kaufmann, San Francisco, Calif.
Shafer, G. (1976). A Mathematical Theory of Evidence. Princeton University Press, Princeton, N.J.
23

fiHalpern

Spohn, W. (1988). Ordinal conditional functions: a dynamic theory of epistemic states.
In Harper, W., & Skyrms, B. (Eds.), Causation in Decision, Belief Change, and
Statistics, Vol. 2, pp. 105{134. Reidel, Dordrecht, Netherlands.

24

fiJournal of Artificial Intelligence Research 7 (1997) 231-248

Submitted 7/97; published 11/97

Dynamic Non-Bayesian Decision Making
Dov Monderer
Moshe Tennenholtz

dov@ie.technion.ac.il
moshet@ie.technion.ac.il

Industrial Engineering and Management
Technion { Israel Institute of Technology
Haifa 32000, Israel

Abstract

The model of a non-Bayesian agent who faces a repeated game with incomplete information against Nature is an appropriate tool for modeling general agent-environment
interactions. In such a model the environment state (controlled by Nature) may change arbitrarily, and the feedback/reward function is initially unknown. The agent is not Bayesian,
that is he does not form a prior probability neither on the state selection strategy of Nature,
nor on his reward function. A policy for the agent is a function which assigns an action to
every history of observations and actions. Two basic feedback structures are considered.
In one of them { the perfect monitoring case { the agent is able to observe the previous
environment state as part of his feedback, while in the other { the imperfect monitoring
case { all that is available to the agent is the reward obtained. Both of these settings
refer to partially observable processes, where the current environment state is unknown.
Our main result refers to the competitive ratio criterion in the perfect monitoring case.
We prove the existence of an ecient stochastic policy that ensures that the competitive
ratio is obtained at almost all stages with an arbitrarily high probability, where eciency
is measured in terms of rate of convergence. It is further shown that such an optimal
policy does not exist in the imperfect monitoring case. Moreover, it is proved that in the
perfect monitoring case there does not exist a deterministic policy that satisfies our long
run optimality criterion. In addition, we discuss the maxmin criterion and prove that a
deterministic ecient optimal strategy does exist in the imperfect monitoring case under
this criterion. Finally we show that our approach to long-run optimality can be viewed as
qualitative, which distinguishes it from previous work in this area.

1. Introduction
Decision making is a central task of artificial agents (Russell & Norvig, 1995; Wellman,
1985; Wellman & Doyle, 1992). At each point in time, an agent needs to select among
several actions. This may be a simple decision, which takes place only once, or a more
complicated decision where a series of simple decisions has to be made. The question of
\what should the right actions be" is the basic issue discussed in both of these settings, and
is of fundamental importance to the design of artificial agents.
A static decision-making context (problem) for an artificial agent consists of a set of actions that the agent may perform, a set of possible environment states, and a utility/reward
function which determines the feedback for the agent when it performs a particular action
in a particular state. Such a problem is best represented by a matrix with columns indexed
by the states, rows indexed by the actions and the rewards as entries. When the reward
function is not known to the agent we say that the agent has payoff uncertainty and we
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiMonderer and Tennenholtz

refer to the problem as a problem with incomplete information(Fudenberg & Tirole, 1991).
When modeling a problem with incomplete information one must also describe the underlying assumptions on the knowledge of the agent about the reward function. For example, the
agent may know bounds on his rewards, or he may know (or partially know) an underlying
probabilistic structure1 . In a dynamic (multistage) decision-making setup the agent faces
static decision problems over stages. At each stage the agent selects an action to be performed and the environment selects a state. The history of actions and states determines
the immediate reward as well as the next one-shot decision problem. The history of actions
and states also determines the next selected state. Work on reinforcement learning in artificial intelligence (Kaelbling, Littman, & Moore, 1996) has adopted the view of an agent
operating in a probabilistic Bayesian setting, where the agent's last action and the last state
determine the next environment state based on a given probability distribution. Naturally,
the learner may not be a-priori familiar with this probability distribution, but the existence
of the underlying probabilistic model is a key issue in the system's modeling. However, this
assumption is not an ultimate one. In particular, much work in other areas in AI and in
economics have dealt with non-probabilistic settings in which the environment changes in
an unpredictable manner2 . When the agent does not know the inuence of his choices on
the selection of the next state (i.e., he is not certain about the environment strategy), we
say that the agent has strategic uncertainty.
In this paper we use a general model for the representation of agent-environment interactions in which the agent has both payoff and strategic uncertainty. We deal with a
non-Bayesian agent who faces a repeated game with incomplete information against Nature.
In a repeated game against Nature the agent faces the same static decision problem at
each stage while the environment state is taken to be an action chosen by his opponents.
The decision problem is called a game to stress the fact that the agent's action and the
state are independently chosen. The fact that the game is repeated refers to the fact
that the set of actions, the set of possible states, and the one shot utility function do not
vary with time3 . As we said, we consider an agent that has both payoff uncertainty and
strategic uncertainty. That is, he is a-priori ignorant about the utility function (i.e., the
game is of incomplete information) as well as about the state selection strategy of Nature.
The agent is non-Bayesian in the sense that he does not assume any probabilistic model
concerning nature's strategy and in the sense that he does not assume any probabilistic
model concerning the reward function, though he may assume lower and upper bounds4 .
We consider two examples to illustrate the above-mentioned notions and model. Consider
1. For example, the agent may know a probability distribution on a set of reward functions, he may assume
that such a probability exists without any assumption on its structure, or he may have partial information
about this distribution but be ignorant about some of its parameters (e.g., he may believe that the reward
function is drawn according to a normal distribution with an unknown covariance matrix).
2. There are many intermediate cases where it is assumed that the changes are probabilistic with a nonMarkovian structure.
3. In the most general setup, those sets may vary with time. No useful analysis can be done in a model
where those changes are completely arbitrary.
4. Repeated games with complete information, or more generally, multistage games and stochastic games
have been extensively studied in game theory and economics. A very partial list includes: (Shapley,
1953; Blackwell, 1956; Luce & Raiffa, 1957), and more recently (Fudenberg & Tirole, 1991; Mertens,
Sorin, & Zamir, 1995), and the evolving literature on learning (e.g., Fudenberg & Levine 1997). The
incomplete information setup in which the player is ignorant about the game being played was inspired

232

fiDynamic Non-Bayesian Decision Making

an investor, I , who is investing daily in a certain index of the stock market. His daily profits
depends on his action (selling or buying in a certain amount) and on the environment state
{ the percentage change in the price of the index. This investor has complete information
about the reward function because he knows the reward which is realized in a particular
investment and a particular change, but he has strategic uncertainty about the changes
in the index price. So, he is playing a repeated game with complete information against
Nature with strategic uncertainty.
Consider another investor, I 1, who invests in a particular mutual fund. This fund invests
in the stock market with a strategy which is not known to the investor. Assume that each
state represents the vector of percentage changes in the stocks, then the investor does not
know his reward function. For example, he cannot say in advance what would be his profit
if he would buy one unit of this fund and all stock prices increase in 1 percent. Thus, I 1
plays a repeated game with incomplete information. If in addition I 1 does not attempt to
construct a probabilistic model concerning his reward function or market behavior, then he
is non-Bayesian and our analysis may apply to him. For another example, assume that Bob
has to decide on each evening whether to prepare tea or coffee for his wife before she gets
home. His wife wishes to drink either tea or coffee and he wishes to have it ready for her.
The reaction of Bob's wife to tea or coffee may depend on her state that day, which can not
be predicted based on the history of actions and states in previous days. As Bob has just
got married he cannot tell what reward he will get if his wife is happy and he makes her
a cup of tea. Of course he may eventually know it, but his decisions during this learning
period are precisely the subject of this paper.
As an example for the generality of the above-mentioned setting, consider the model of
Markov decision processes with complete or incomplete information. In a Markov decision
process an agent's action in a given state determines (in a probabilistic fashion) the next
state to be obtained. That is, the agent has a structural assumption on the state selection
strategy. A repeated game against Nature without added assumptions captures the fact
that the transition from state to state may depend on the history in an arbitrary way.
When the agent performs an action at in state st , part of his feedback would be u(at; st ),
where u is the reward function. We distinguish between two basic feedback structures. In
one of them { the perfect monitoring case { the agent is able to observe the previous
environment state as part of his feedback, while on the other { the imperfect monitoring
case { all that is available to the agent is the reward obtained5 . Notice that in both of
these feedback structures, the current state is not observed by the agent when he is called
to select an action6 . Both investors I and I 1 face a repeated game with perfect monitoring
because the percentage changes become public knowledge after each iteration.
In the other example, when Bob has to make his decision, if the situation is of imperfect
monitoring, Bob would be only able to observe the reward for his behavior (e.g., whether
by (Harsanyi, 1967). See Aumann and Maschler (1995) for a comprehensive survey. Most of the above
literature deals with (partially) Bayesian agents. Some of the rare exceptions are cited in Section 6.
5. Notice that the former assumption is very popular in the related game theory literature (Aumann &
Maschler, 1995). Many other intermediate monitoring structures may be interesting as well.
6. Such is also the case in the evolving literature on the problem of controlling partially observable Markov
decision processes (Lovejoy, 1991; Cassandra, Kaelbling, & Littman, 1994; Monahan, 1982). In contrast,
Q-learning theory (Watkins, 1989; Watkins & Dayan, 1992; Sutton, 1992) does assume a knowledge of
the current state.

233

fiMonderer and Tennenholtz

she says \thanks", \that's terrible", \this is exactly what I wanted", etc.). In the perfect
monitoring case, Bob will be able to observe his wife's state (e.g., whether she came home
happy, sad, nervous, etc.) in addition to his reward. In both cases Bob (like the investors)
is not able to observe his wife's state before making his decision in a particular day.
Consider the case of a one stage game against Nature, in which the utility function
is known, but the agent cannot observe the current environment state when selecting his
action. How should the agent choose his action? Work on decision making under uncertainty
has suggested several approaches (Savage, 1972; Milnor, 1954; Luce & Raiffa, 1957; Kreps,
1988). One of these approaches is the maxmin (safety-level) approach. According to this
approach the agent would choose an action that maximizes his worst case payoff. Another
approach is the competitive ratio approach (or its additive variant, termed the minmax
regret decision criterion (Milnor, 1954). According to this approach an agent would choose
an action that minimizes the worst case ratio between the payoff he could have obtained
had he known the environment state to the payoff he would actually obtain.7 Returning
back to our example, if Bob would have known the actual state of his wife, he could choose
an action that maximizes his payoff. Since he has no hint about her state, he can go ahead
and choose the action that minimizes his competitive ratio. For example, if this action leads
to a competitive ratio of two, then Bob can guarantee himself that the payoff he would get
is at most half the payoff he could have gotten had he known the actual state of his wife.
Given a repeated game with incomplete information against Nature, the agent would
not be able to choose his one stage optimal action (with respect to the competitive ratio or
maxmin value criteria) at each stage, since the utility function is initially unknown. So, if
Bob does not initially know the reward he would receive for his actions as a function of his
wife's state, then he will not be able to simply choose an action that guarantees the best
competitive ratio. This calls for a precise definition of a long-run optimality criterion. In
this paper we are mainly concerned with policies (strategies) guaranteeing that the optimal
competitive ratio (or the maxmin value) is obtained in most stages. We are interested in
particular in ecient policies, where eciency is measured in terms of rate of convergence.
Hence in Bob's case, we are interested in a policy that if adopted by Bob would guarantee
him on almost any day, with high probability, at least the payoff guaranteed by an action
leading to the competitive ratio. Moreover, Bob will not have to wait much before he will
start getting this type of satisfactory behavior.
In Section 2 we define the above mentioned setting and introduce some preliminaries. In
Sections 3 and 4 we discuss the long-run competitive ratio criterion: In Section 3 we show
that even in the perfect monitoring case, a deterministic optimal policy does not exist.
However, we show that there exists an ecient stochastic policy which ensures that the
long-run competitive ratio criterion holds with a high probability. In Section 4 we show
that such stochastic policies do not exist in the imperfect monitoring case. In Section 5 we
prove that for both the perfect and imperfect monitoring cases there exists a deterministic
ecient optimal policy for the long-run maxmin criterion. In Section 6 we compare our
notions of long-run optimality to other criteria appearing in some of the related literature.
In particular, we show that our approach to long-run optimality can be interpreted as
7. The competitive ratio decision criterion has been found to be most useful in settings such as on-line
algorithms (e.g., Papadimitriou & Yanakakis, 1989).

234

fiDynamic Non-Bayesian Decision Making

qualitative, which distinguishes it from previous work in this area. We also discuss some of
the connections of our work with work in reinforcement learning.

2. Preliminaries
A (one-shot) decision problem (with payoff certainty and strategic uncertainty) is a 3-tuple
D =< A; S; u >, where A and S are finite sets and u is a real-valued function defined on
A  S with u(a; s) > 0 for every (a; s) 2 A  S . Elements of A are called actions and those
of S are called states. u is called the utility function. The interpretation of the numerical
values u(a; s) is context-dependent8 . Let nA denote the number of actions in A, let nS
denote the number of states in S and let n = max(nA ; nS ).
The above-mentioned setting is a classical static setting for decision making, where
there is uncertainty about the actual state of nature (Luce & Raiffa, 1957). In this paper
we deal with a dynamic setup, in which the agent faces the decision problem D, without
knowing the utility function u, over an infinite number of stages, t = 1; 2; : : :. As we
have explained in the introduction, this setting enables us to capture general dynamic nonBayesian decision-making contexts, where the environment may change its behavior in an
arbitrary and unpredictable fashion. As mentioned in the introduction, this is best captured
by means of a repeated game against Nature. The state of the environment at each point
plays the role of an action taken by Nature in the corresponding game. The agent knows
the sets A and S , but he does not know the payoff function u.9 A dynamic decision problem
(with payoff uncertainty and strategic uncertainty) is therefore represented for the agent
by a pair DD =< A; S > of finite sets10. At each stage t, Nature chooses a state st 2 S .
The agent, who does not know the chosen state, chooses at 2 A, and receives u(at; st). We
distinguish between two informational structures. In the perfect monitoring case, the state
st is revealed to the agent alongside the payoff u(at; st). In the imperfect monitoring case,
the states are not revealed to the agent. A generic history available to the agent at stage t +1
is denoted by ht . In the perfect monitoring case, ht 2 Htp = (A  S  R+ )t , where R+ denotes
the set of positive real numbers. In the imperfect monitoring case, ht 2 Htimp = (A  R+ )t.
In the particular case t = 0 we assume that H0p = H0imp = feg is a singleton containing
p
imp = [1 H imp . The symbol H will be
the empty history e. Let H p = [1
t=0 Ht and let H
t=0 t
used for both H p and H imp . A strategy11 for the agent in a dynamic decision problem is
a function F : H ! (A) , where (A) denotes the
P set of probability measures over A.
That is, for every ht 2 H , F (ht ) : A ! [0; 1] and a2A F (ht )(a) = 1. In other words, if
the agent observes the history ht then he chooses at+1 by randomizing amongst his actions,
with the probability F (ht )(a) assigned to the action a. A strategy F is called pure if F (ht )
is a probability measure concentrated on a singleton for every t  0.
In Sections 2{4 the strategy recommended to the agent is chosen according to a \longrun" decision criterion which is induced by the competitive ratio one-stage decision criterion.
8. See the discussion at Section 6.
9. All the results of this paper remain unchanged if the agent does not initially know the set S , but rather
an upper bound on nS .
10. Notice that there is no need to include an explicit transition function in this representation. This is due
to the fact that in the non-Bayesian setup every transition is possible.
11. Strategy is a decision theoretic concept. It coincides with the term policy used in the control theory
literature, and with the term protocol used in the distributed systems literature.

235

fiMonderer and Tennenholtz

The competitive ratio decision criterion, that is described below, may be used by an agent
who faces the decision problem only once, and who knows the payoff function u as well as
the sets A and S . There are other \reasonable" decision criteria that could be used instead.
One of them is the maxmin decision criterion to be discussed in Section 5, while another
is the minmax regret decision criterion (Luce & Raiffa, 1957; Milnor, 1954). The latter is
a simple variant of the competitive ratio (and can be treated similarly), and therefore will
not be treated explicitly in this paper.
For every s 2 S let M (s) be the maximal payoff the agent can get when the state is s.
That is
M (s) = max
u(a; s):
a2A
For every a 2 A and s 2 S define

c(a; s) = uM(a;(ss)) :

Denote c(a) = maxs2S c(a; s), and let





CR = min
c(a) = min
max c(a; s) :
a2A
a2A s2S
CR is called the competitive ratio of D =< A; S; u >. Any action a for which CR = c(a)
is called a competitive ratio action, or in short a CR action. An agent which chooses a
1 fraction from what it could have gotten, had it
CR action guarantees receiving at least CR
1
known the state s. That is, u(a; s)  CR M (s) for every s 2 S . This agent cannot guarantee
a bigger fraction.
In the long-run decision problem, a non-Bayesian agent does not form a prior probability
on the way Nature is choosing the states. Nature may choose a fixed sequence of states or,
more generally, use a probabilistic strategy G, where G : Q ! (S ), and Q = [1
t=0 Qt =
t. Nature can be viewed as a second player that knows the reward function. Its
[1
(
A

S
)
t=0
strategy may of course refer to the whole history of actions and states until a given point
and may depend on the payoff function.
A payoff function u and a pair of probabilistic strategies F; G, where G can depend on u,
generate a probability measure  = F;G;u over the set of infinite histories Q1 = (A  S )1
endowed with the natural measurable structure. For an event B  Q1 we will denote the
probability of B according to  by (B ) or by Prob (B ). More precisely, the probability
measure  is uniquely defined by its values for finite cylinder sets: Let At : Q1 ! A and
St : Q1 ! S be the coordinate random variables which contain the values of the actions
and states selected by the agent and the environment in stage t (respectively). That is,
At(h) = at and St(h) = st for every h = ((a1; s1); (a2; s2); : : :) in Q1 . Then for every T  1
and for every ((a1; s1); : : :; (aT ; sT )) 2 QT ,

Prob ((At; St) = (at; st) for all 1  t  T ) =
where

0

T
Y
t=1

F ('t,1)(at )G( t,1)(st );

and '0 are the empty histories, and for 2  t  T we have
t,1 = ((a1; s1 ); : : :; (at,1; st,1)) ;

236

fiDynamic Non-Bayesian Decision Making

while the definition of 't,1 depends on the monitoring structure. In the perfect monitoring
case,
't,1 = ((a1 ; s1; u(a1; s1)); : : :; (at,1; st,1; u(at,1; st,1))) ;
and in the imperfect monitoring case
't,1 = ((a1; u(a1; s1)); : : :; (at,1; u(at,1; st,1))) :
We now define some auxiliary additional random variables on Q1 . P
Let Xt = 1 if c(At ; St)  CR and Xt = 0 otherwise, and let NT = Tt=1 Xt .12 Let  > 0.
A strategy F is  -optimal if there exists an integer K such that for every payoff function u
and every Nature's strategy G

Prob (NT  (1 ,  )T for every T  K )  1 , 
(1)
where  = F;G;u . A strategy F is optimal if it is  -optimal for all  > 0.
Roughly speaking, NT measures the number of stages in which the competitive ratio (or
a better value) has been obtained in the first T iterations. In an  -optimal strategy there
exists a number K , such that if the system runs for T  K iterations we can get with high
probability that NT is close to 1 (i.e., almost all iterations are good ones). In an optimal

strategy we guarantee that we can get as close as we wish to the situation where all iterations
are good ones, with a probability that is as high as we wish. Notice that we require that the
above-mentioned useful property will hold for every payoff function and for every strategy
of Nature. This strong requirement is a consequence of the non-Bayesian setup; since we do
not have any clue about the reward function or about the strategy selected by Nature (and
this strategy may yield arbitrary sequences of states to be reached), the best policy would
be to insist on good behavior against any behavior adopted by Nature. Notice however that
two other relaxations are introduced here; we require successful behavior in most stages,
and that the whole process would be successful only with some (very high) probability.
The major objective is to find a policy that will enable (1) to hold for every dynamic
decision problem and every Nature strategy. Moreover, we wish (1) to hold for small enough
K . If K is small then our agent can benefit from obtaining the desired behavior already in
an early stage. 13 This will be the subject of the following section. We complete this section
with a useful technical observation. We show that a strategy F is  -optimal if it satisfies
the optimality criterion (1) for every reward function and for every stationary strategy of
nature, where a stationary strategy is defined by a sequence of states z = (st )1
t=1 . In this
strategy Nature chooses st at stage t, independent of the history. Indeed, assume that F is
a strategy for which (1) holds for every reward function and for every stationary strategy
of Nature, then we show that F is  -optimal.
Given any payoff function u and any strategy G,  -optimality with respect to stationary
strategies implies that for  = F;G;u ,
Prob (NT  (1 , )T for every T  K )jS1; S2; : : :)  1 , ;
12. Note that the function c(a; s) depends on the payoff function u and therefore so do the random variables
Xt and Nt .
13. The interested reader may wish to think of our long-run optimality criteria in view of the original work
on PAC learning (Valiant, 1984). In our setting, as in PAC learning, we wish to obtain desired behavior,
in most situations, with high probability, and relatively fast.

237

fiMonderer and Tennenholtz

with probability one. Therefore

Prob(NT  (1 ,  )T for every T  K )  1 , :
Roughly speaking, the above captures the fact that in our non-Bayesian setting we
need to present a strategy that will be good for any sequence of states chosen by Nature,
regardless of the way in which it has been chosen.

3. Perfect Monitoring

In this section we present our main result. This result refers to the case of perfect monitoring, and shows the existence of a  -optimal strategy in this case. It also guarantees that the
desired behavior will be obtained after polynomially many stages. Our result is constructive. We first present the rough idea of the strategy employed in our proof. If the utility
function was known to the agent then he could use the competitive ratio action. Since the
utility function is initially unknown then the agent will use a greedy strategy, where he
selects an action that is optimal as far as the competitive ratio is concerned, according to
the agent's knowledge at the given point. However, the agent will try from time to time to
sample a random action.14 Our strategy chooses a right tradeoff between these exploration
and exploitation phases in order to yield the desired result. Some careful analysis is needed
in order to prove the optimality of the related strategy, and the fact it yields the desired
result after polynomially many stages.
We now introduce our main theorem.

Theorem 3.1: Let DD =< A; S > be a dynamic decision problem with perfect monitoring.

Then for every  > 0 there exists a  -optimal strategy. Moreover, the  -optimal strategy
can be chosen to be ecient in the sense that K (in (1)) can be taken to be polynomial in
max(n; 1 ).

Proof: Recall that nA and nS denote the number of actions and states respectively, and
that n = max(nA ; nS ). In this proof we assume for simplicity that n = nA = nS . Only
slight modifications are required for removing this assumption. Without loss of generality,
 < 1. We define a strategy F as follows: Let M = 8 . That is,

1 
M = 8:
At each stage T  1 we will construct matrices UTF ; CTF and a subset of the actions WT in
the following way: Define U1F (a; s) =  for each a; s. At each stage T > 1, if aT ,1 has been
performed in stage T , 1, and sT ,1 has been observed, then update U by replacing the 
in the (aT ,1; sT ,1) entry with u(aT ,1; sT ,1). At each stage T  1, if UTF (a; s) = , define
F b;s)
CTF (a; s) = 1. If UTF (a; s) =
6 , CTF (a; s) = maxfb:UTF (b;s)6=g UUTTF ((a;s
) . Finally WT is the set
of all a 2 A at which minb2A maxs2S CTF (b; s) is obtained. We refer to elements in WT as
the temporarily good actions at stage T . Let (Zt)t1 be a sequence of i.i.d. f0; 1g random
14. We use a uniform probability distribution to select among actions in the exploration phase. Our result
can be obtained with different exploration techniques as well.

238

fiDynamic Non-Bayesian Decision Making

variables with Prob(Zt = 1) = 1 , M1 . This sequence is generated as part of the strategy,
independent of the observed history. That is at each stage, before choosing an action, the
agent ips a coin, independently of his past observations. At each stage t the agent observes
Zt. If Zt = 1, the agent chooses an action from Wt by randomizing with equal probabilities.
If Zt = 0 the agent randomizes with equal probabilities amongst the actions in A. This
complete the description of the strategy F . Let u be a given payoff function, and let (st)1
t=1
be a given sequence of states. We proceed to show that (1) holds with K being the upper
integer value of ff = max(ff1 + 2; ff2 + 2), where


256
ff1 = 128
2 ln 3

n2 (n 8 + 1) ln
and ff2 =
3
4



 2
2n + 1


:
P

Recall that Xt = 1 if c(At; st )  CR and Xt = 0 otherwise, and that NT = Tt=1 Xt . By
a slight change of notation, we denote by P = Prob the probability measure induced by
F , u and the sequence of states on (A  S  f0; 1g)1 (where f0; 1g corresponds to the Zt
values).
Let " = 8 . Define

BK =

(T
X

t=1

)


1
Zt  1 , M , " T for all T  K :


Roughly speaking, BK captures the cases where temporarily good actions are selected
in most stages.
By (Chernoff, 1952) (see also (Alon, Spencer, & Erdos, 1992)), for every T ,

P

T
X
t=1

!

2
Zt < (1 , 1 , ")T  e, " 2T :

M

Recall that given a set S , S denotes the complement of S .
Hence,
!
1
T
1
2
X
X
X
1
Zt < (1 , , ")T 
e, " 2T :
P (BK )  P
Therefore
Since K > ff1 ,
Define:

T =k

P (BK ) 

t=1
Z1

k ,1

M

e, " 2T dT = "22 e,
2

P (BK ) < 2

T =K

"2 (K ,1)

2

:
(2)

LK = fNT  (1 ,  )T for every T  K g:
Roughly speaking, LK captures the cases where competitive ratio actions (or better

actions in this regard) are selected in most stages.
In order to prove that F is  -optimal (i.e., that (1) is satisfied), we have to prove that

P (LK ) < 
239

(3)

fiMonderer and Tennenholtz

By (2) it suces to prove that

(4)
P (LK jBK )  2
We now define for every t  1, s 2 S and a 2 A six auxiliary random variables, Yt ; Rt; Yts ; Rst; Yts;a ; Rs;a
t .
Let Yt = 1 whenever Zt = 1 and Xt = 0, and Yt = 0 otherwise. Let

RT =

T
X
t=1

Yt :

For every s 2 S let Yts = 1 whenever Yt = 1 and st = s, and Yts = 0 otherwise. Let
T
X
Yts :
t=1
Yts;a = 1

RsT =

For every s 2 S and for every a 2 A, let
whenever Yts = 1 and At = a, and
s;a
Yt = 0 otherwise. Let
T
X
Rs;a
=
Yts;a :
T
t=1

Let g be the integer value of 34 K . We now show that

P (LK jBK )  P(9T  K ; RT  gjBK )

(5)

In order to prove (5) we show that

LK \ BK  f9T  K ; RT  g g \ BK :
Indeed, if w is a path in BK such that for every T  K RT < g , then, at w, for every
T  K,
T
X
X
NT 
Xt  VT , Yt;
1tT;Zt=1

t=1

where VT denotes the number of stages 1  t  T for which Zt = 1. Since w 2 BK ,
N  (1 , 1 , ")T , R > (1 , 1 , ")T , g
T

M

T

M

for every T  K . Since M1 = " = 8 and g  34 K , NT  (1 ,  )T for every T  K . Hence,
w 2 LK .
(5) implies that it suces to prove that

P(9T  K ; RT  gjBK )  2
Therefore it suces to prove that for every s 2 S ,


P 9T  K; RsT  ng jBK  2n :
Hence it suces to prove that for every s 2 S and every a 2 A,
240

(6)

fiDynamic Non-Bayesian Decision Making



 = P 9T  K;

g
Rs;a
T  n2 jBK



 2n 2

(7)

g
In order to prove (7) , note that if the inequality Rs;a
T  n2 is satisfied at gw, then
c(a; s) > CR and a is nevertheless considered to be a good action in at least n2 stages
b;s) > CR. If b is
1  t  T (w.l.o.g. assume that ng2 is an integer). Let b 2 A satisfy uu((a;s
)
ever played in a stage t with st = s, then a 62 Wt for all t  t. Therefore




  P 9T  K; b is not played in the first ng2 stages at which st = sjBK :
Hence
As (1 , x1 )x+1  e,x for x  1,

ut



  1, 1

nM

 g2
n

:

g
  e, n2 (nM +1) < 2n 2 :

Theorem 3.1 shows that ecient dynamic non-Bayesian decisions may be obtained by
an appropriate stochastic policy. Moreover, it shows that  -optimality can be obtained in
time which is a (low degree) polynomial in max(n; 1 ). An interesting question is whether
similar results can be obtained by a pure/deterministic strategy. As the following example
shows, deterministic strategies do not suce for that job.
We give an example in which the agent does not have a  optimal pure strategy.

Example 1: Let A = fa1; a2g and S = fs1; s2g. Assume in negation that the agent has a
 optimal pure strategy f .

Consider the following two decision problems whose rows are indexed by the actions and
whose columns are indexed by the states:

D1 =

1 10
30 2

D2 =

1 30
10 2

with the corresponding ratio matrices:

C1 =

30 1
1 5

C2 =

10 1
1 15
241

!

!

!
!

fiMonderer and Tennenholtz

Assume in addition that in both cases Nature uses the strategy g , defined as follows:
g (ht) = si if f (ht) = ai , i = 1; 2. That is, for every t, (at; zt ) = (a1; s1) or (at; zt) = (a2; s2),
where at and zt denote the action and state selected at stage t, respectively. Let  < 0:25.
Let NTi denote NT for decision problem i. Since f is  -optimal, there exists K such that
for every T  K , NT1  (1 ,  )T and NT2  (1 ,  )T . Note also that the same sequence
((at; zt))t1 is generated in both cases. NK1  (1 ,  )K implies that (a2 ; s2) is used at more
than half of the stages 1; 2; : : :; K . On the other hand, NK2  (1 ,  )K implies that (a1; s1)
is used at more than half of the stages 1; 2; : : :; K . A contradiction.
ut
For analytical completeness, we end this section by proving the existence of an optimal
strategy (and not merely a  -optimal strategy). Such an optimal strategy is obtained by
utilizing m -optimal strategies (whose existence was proved in Theorem 3.1) for intervals of
stages with sizes that converge to infinity, when m ! 0.

Corollary 3.2: In every dynamic decision problem with perfect monitoring there exists
an optimal strategy.

Proof: For m  1, let Fm be a

sequence with limm!1 m = 0. Let
that for every m  1

m -optimal strategy, where (m )1 is a decreasing
m=1
2
(Km )1
be
an
increasing
sequence
of integers such
m=1





m
Prob NT  (1 , 2 )T for every T  Km  1 , 2m ;

and

Pm
K
Km+1  2 j=1 j :
m
Let F be the strategy that for m  1 utilizes Fm at the stages K0 + : : : + Km,1 + 1  t 
K0 + : : : + Km,1 + Km, where K0 = 0. It can be easily verified that F is optimal.

ut

4. Imperfect Monitoring

We proceed to give an example for the imperfect monitoring case, where for suciently
small  > 0, the agent does not have a  -optimal strategy.

Example 2 (Non-existence of -optimal strategies in the imperfect monitoring case)

Let A = fa1; a2g, and S = fs1 ; s2; s3g. Let  < 0 , where 0 is defined at the end
of this proof. Assume in negation that there exists a  -optimal strategy F . Consider the
following two decision problems whose rows are indexed by the actions and whose columns
are indexed by the states:
!
2
a
2
b
2
c
D1 = a b c
242

fiDynamic Non-Bayesian Decision Making

!

2a 2b 2c

D2 =

b c a

where a; b and c are positive numbers satisfying: a > 4b > 16c. For i = 1; 2, let
Ci = (ci (a; s))a2A;s2S be the ratio matrices. That is:

C1 =

1 1 1
2 2 2

!

1 1 2ac
2a 2b 1
b c

C2 =

!

Note that a1 is the unique CR action in D1 and a2 is the unique CR action in D2.
Assume that Nature uses strategy G which randomizes at each stage with equal probabilities
(of 13 ) amongst all 3 states. Given this strategy of Nature, the agent cannot distinguish
between the two decision problems, even if he knows Nature's strategy and he is told that
one of them is chosen. This implies that if 1 and 2 are the probability measures induced
by F and G on (A  S )1 in the decision problems D1 and D2 respectively, then for every
i 2 f1; 2g, the distribution of the stochastic process (NTi )1
T =1 with respect to j , j 2 f1; 2g,
does not depend on j . That is, for every T  1








Prob1 Nti 2 Mt for all t  T = Prob2 Nti 2 Mt for all t  T ; i 2 f1; 2g (8)
for every sequence (Mt )Tt=1 with Mt  f0; 1; : : :; tg for all 1  t  T .
We do not give a complete proof of (8), rather we illustrate it by proving a representing
case. The reader can easily derive the complete proof. We show that

Prob1 (N21 = 0) = Prob2 (N21 = 0)

(9)

Indeed, for j = 1; 2,

Probj (N21 = 0) = 31

3
X

k=1

F (e)(a2)F (a2 ; uj (a2 ; sk ))(a2)

(10)

Let  : f1; 2; 3g ! f1; 2; 3g be defined by  (1) = 3,  (2) = 1, and  (3) = 2. Then

u1(a2 ; sk ) = u2 (a2; s(k) )
for every 1  k  3. Therefore (10) implies (9).
As F is  -optimal, then there exists an integer K such that with a probability of at least
1 ,  with respect to 1 , and hence with respect to 2 , NT1  (1 ,  )T for every T  K .
This implies that with a probability of at least 1 ,  , a1 is played at least at 1 ,  of the
stages up to time T , for all T  K , and in particular for T = K . We choose the integer K
to be suciently large such that according to the Law of Large Numbers, Nature chooses
243

fiMonderer and Tennenholtz

s3 in at least 31 ,  of the stages up to stage K with a probability of at least 1 ,  . Let CR2
and c2t denote CR and ct of decision problem 2, respectively. Then
a > CR = max( 2a ; 2b ):
2
2c
b c
Therefore, if At = a1, then C2(At ; St)  CR2 if and only if St =
6 s3. Hence, with a
2
probability of at least 1 , 2 , in at most  + (1 ,  )( 3 +  ) of these stages c2t  CR2.
Therefore F cannot be  -optimal, if we choose 0 such that 20 < 1 , 0 and

ut

0 + (1 , 0)( 23 + 0 ) < 1 , 0 :

5. Safety Level

For the sake of comparison we discuss in this section the safety level (known also as maxmin)
criterion. Let D =< A; S; u > be a decision problem. Denote

v = max
a min
s u(a; s)
v is called the safety level of the agent (or the maxmin value). Every action a for which
u(a; s)  v for every s is called a safety level action. We consider now the imperfect
monitoring model for the dynamic decision problem < A; S >. Every sequence of states
z = (st)1
t=1 with st 2 S for every t  1 and every pure strategy f of the agent induce
z;f 1
a sequence of actions (at)1
t=1 and a corresponding sequence of payoffs (ut )t=1 , where
z;f
uz;f
t = u(at ; st) for every t  1. Let NT denote the number of stages up to stage T at
which the agent's payoff exceeds the safety level v . That is,
NTz;f = #f1  t  T : uz;f
t  vg

(11)

We say that f is safety level optimal if for every decision problem and for every sequence of
states,
lim 1 N z;f = 1;
T !1 T T

and the convergence holds uniformly w.r.t. all payoff functions u and all sequences of states
in S . That is, for every  > 0 there exists K = K ( ) such that NTz;f  (1 ,  )T for every
T  K for every decision problem < A; S; u > and for every sequence of states z .
Proposition 5.1: Every dynamic decision problem possesses a safety level optimal strategy
in the imperfect monitoring case, and consequently in the perfect monitoring case. Moreover,
such an optimal strategy can be chosen to be strongly ecient in the sense that for every
sequence of states there exists at most nA , 1 stages at which the agent receives a payoff
smaller than his safety level, where nA denotes the number of actions.
Proof: Let n = nA . Define a strategy f as follows: Play each of the actions in
A in the first n stages. For every T  n + 1, and for every history h = hT ,1 =
244

fiDynamic Non-Bayesian Decision Making

((a1; u1); (a2; u2; : : :; (aT ,1; uT ,1)) we define f (h) 2 A as follows: For a 2 A, let vTh (a) =
min ut , where the min ranges over all stages t  T , 1 for which at = a. Define f (h) = aT ,
where aT maximizes vTh (a) over a 2 A. It is obvious that for every sequence of states
1
z = (st )1
t=1 there are at most n , 1 stages at which u(at ; st) < v , where (at )t=1 is the
z;f
sequence of actions generated by f and the sequence of states. Hence NT  T , n, where
NTz;f is defined in (11). Thus for K () = n , T1 NTz;f  1 ,  for every T  K ( ).

ut

6. Discussion

Note that all the notations established in Section 5, and Proposition 5.1 as well, remain
unchanged if we assume that the utility function u takes values in a totally pre-ordered
set without any group structure. That is, our approach to decision making is qualitative
(or ordinal). This distinguishes our work from previous work on non-Bayesian repeated
games, which used the probabilistic safety level criterion as a basic solution concept for the
one shot game15. These works, including (Blackwell, 1956; Hannan, 1957; Banos, 1968;
Megiddo, 1980), and more recently (Auer, Cesa-Bianchi, Freund, & Schapire, 1995; Hart
& Mas-Colell, 1997), used several versions of long-run solution concepts, all based on some
optimization of the average of the utility values over time. That is, in P
all of these papers
the goal is to find strategies that guarantee that with high probability T1 Tt=1 u(At; St) will
be close to vp .
Our work is, to the best of our knowledge, the first to introduce an ecient dynamic
optimal policy for the basic competitive ratio context. Our study and results in sections 2-4
can be easily adapted to the case of qualitative competitive ratio as well. In this approach,
the utility function takes values in some totally pre-ordered set G and in addition we assume
a regret function, that maps G  G to some pre-ordered set H . For g1 ; g2 2 G, (g1; g2)
is the level of regret when the agent receives the utility level g1 rather than g2. Given an
action a and a state s, the regret function will determine the maximal regret, c(a; s) 2 H
of the agent when action a is performed in state s. That is,

c(a; s) = max (u(a; s); u(b; s));
where b ranges over all actions.
The qualitative regret of action a will be the maximal regret of this action over all states.
The optimal qualitative competitive ratio will be obtained by using an action for which the
qualitative regret is minimal. Notice that no arithmetic calculations are needed (or make
any sense) for this qualitative version. Our results can be adapted to the case of qualitative
competitive ratio. For ease of exposition, however, we used the quantitative version of this
model, where a numerical utility function represents the regret function.
15. The probabilistic safety value, vp , of the agent in the decision problem D =< A; S; u > is his maxmin
value when the max ranges over all mixed actions. That is

vp = maxq2(A) mins2S

X

a2A

u(a; s)q(a);

where (A) is the set of all probability distributions q on A.

245

fiMonderer and Tennenholtz

Our work is relevant to research on reinforcement learning in AI. Work in this area,
however, has dealt mostly with Bayesian models. This makes our work complementary to
this work. We wish now to briey discuss some of the connections and differences between
our work and existing work in reinforcement learning.
The usual underlying structure in the reinforcement learning literature is that of an environment which changes as a result of an agent's action based on a particular probabilistic
function. The agent's reward may be probabilistic as well.16 In our notation, a Markov
decision process (MDP) is a repeated game against Nature with complete information and
strategic certainty, in which Nature's strategy depends probabilistically on the last action
and state chosen17 . Standard partially observable MDP (POMDP) can be described similarly by introducing a level of monitoring in between perfect and imperfect monitoring. In
addition, bandit problems can be basically modeled as repeated games against Nature with
a probabilistic structural assumption about Nature's strategy , but with strategic uncertainty about the values of the transition probabilities. For example, Nature's action can
play the role of the state of a slot machine in a basic bandit problem. The main difference between the classical problem and the problem discussed in our setting is that the
state of the slot machine may change in our setting in a totally unpredictable manner (e.g.,
the seed of the machine is manually changed at each iteration). This is not to say that
by solving our learning problem we have solved the problem of reinforcement learning in
MDP, in POMDP, or in bandit problems. In the later settings, our optimal strategy behave
poorly relative to strategies obtained in the theory of reinforcement learning, that take the
particular structure into account.
The non-Bayesian and qualitative setup call for optimality criteria which differ from
the ones used in current work in reinforcement learning. Work in reinforcement learning
discusses learning mechanisms that optimize the expected payoff in the long run. In a
qualitative setting (as described above) long-run expected payoffs may not make much
sense. Our optimality criteria expresses the need to obtain a desired behavior in most
stages. One can easily construct examples where one of these approaches is favorite to the
other one. Our emphasis is on obtaining the desired behavior in a relatively short run.
Though, most analytical results in reinforcement learning have been concerned only with
eventual convergence to desired behavior, some of the policies have been shown to be quite
ecient in practice.
In addition to the previously mentioned differences between our work and work in reinforcement learning, we wish to emphasize that much work on POMDP uses information
structures which are different from those discussed in this paper. Work on POMDP usually
assumes that some observations about the current state may be available (following the presentation by Smallwood & Sondik, 1973), although observations about the previous state
are discussed as well (Boutilier & Poole, 1996). Recall that in the case of perfect monitoring
the previous environment state is revealed, and the immediate reward is revealed in both
prefect and imperfect monitoring. It may be useful to consider also situations where some
16. The results presented in this paper can be extended to the case where there is some randomness in the
reward obtained by the agents as well.
17. Likewise, stochastic games (Shapley, 1953) can be considered as repeated games against Nature with
partial information about Nature's strategy. For that matter one should redefine the concept of state in
such games. A state is a pair (s; a), where s is a state of the system and a is an action of the opponent.

246

fiDynamic Non-Bayesian Decision Making

(partial) observations about the previous state or the current state are revealed from time
to time. How this may be used in our setting is not completely clear, and may serve as a
subject for future research.

References

Alon, N., Spencer, J., & Erdos, P. (1992). The Probabilistic Method. Wiley-Interscience.
Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. (1995). Gambling in a rigged
casino: The adversial multi-armed bandit problem. In Proceedings of the 36th Annual
Symposium on Foundations of Computer Science, pp. 322{331.
Aumann, R., & Maschler, M. (1995). Repeated Games with Incomplete Information. The
MIT Press.
Banos, A. (1968). On pseudo games. The Annals of Mathematical Statistics, 39, 1932{1945.
Blackwell, D. (1956). An analog of the minimax theorem for vector payoffs. Pacific Journal
of Mathematic, 6, 1{8.
Boutilier, C., & Poole, D. (1996). Computing optimal policies for partially observable
decision processes using compact representations. In Proceedings of the 13th National
Conference on Artificial Intelligence, pp. 1168{1175.
Cassandra, A., Kaelbling, L., & Littman, M. (1994). Acting optimally in partially observable stochastic domain. In Proceedings of the 12th National Conference on Artificial
Intelligence, pp. 1023{1028.
Chernoff, H. (1952). A measure of the asymptotic eciency for tests of a hypothesis based
on the sum of observations. Annals of Mathematical Statistics, 23, 493{509.
Fudenberg, D., & Levine, D. (1997). Theory of learning in games. miemo.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Hannan, J. (1957). Approximation to bayes risk in repeated play. In Dresher, M., Tucker,
A., & Wolfe, P. (Eds.), Contributions to the Theory of Games, vol. III (Annals of
Mathematics Studies 39), pp. 97{139. Princeton University Press.
Harsanyi, J. (1967). Games with incomplete information played by bayesian players, parts
i, ii, iii. Management Science, 14, 159{182.
Hart, S., & Mas-Colell, A. (1997). A simple adaptive procedure leading to correlated
equilibrium. Discussion paper 126, Center for Rationality and Interactive Decision
Theory, Hebrew University.
Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: A survey. Journal
of Artificial Intelligence Research, 4, 237{258.
Kreps, D. (1988). Notes on the Theory of Choice. Westview press.
247

fiMonderer and Tennenholtz

Lovejoy, W. (1991). A survey of algorithmic methods for partially observed markov decision
processes. Annals of Operations Research, 28 (1{4), 47{66.
Luce, R. D., & Raiffa, H. (1957). Games and Decisions- Introduction and Critical Survey.
John Wiley and Sons.
Megiddo, N. (1980). On repeated games with incomplete information played by nonbayesian players. International Journal of Game Theory, 9, 157{167.
Mertens, J.-F., Sorin, S., & Zamir, S. (1995). Repeated games, part a. CORE, DP-9420.
Milnor, J. (1954). Games Against Nature. In Thrall, R. M., Coombs, C., & Davis, R.
(Eds.), Decision Processes. John Wiley & Sons.
Monahan, G. (1982). A survey of partially observable markov decision processes: Theory,
models and algorithms. Management Science, 28, 1{16.
Papadimitriou, C., & Yannakakis, M. (1989). Shortest Paths Without a Map. In Automata,
Languages and Programming. 16th International Colloquium Proceedings, pp. 610{
620.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: A Modern Approach. Prentice Hall.
Savage, L. (1972). The Foundations of Statistics. Dover Publications, New York.
Shapley, L. (1953). Stochastic games. Proceeding of the National Academic of Sciences
(USA), 39, 1095{1100.
Smallwood, R., & Sondik, E. (1973). The optimal control of partially observable markov
processes over a finite horizon. Operations Research, 21, 1071{1088.
Sutton, R. (1992). Special issue on reinforcement learning. Machine Learning, 8 (3{4).
Valiant, L. G. (1984). A theory of the learnable. Comm. ACM, 27 (11), 1134{1142.
Watkins, C., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning, 8 (3{4),
279{292.
Watkins, C. (1989). Learning With Delayed Rewards. Ph.D. thesis, Cambridge University.
Wellman, M., & Doyle, J. (1992). Modular utility representation for decision-theoretic
planning. In Proceedings of the first international conference on AI planning systems.
Morgan Kaufmann.
Wellman, M. (1985). Reasoning about preference models. Tech. rep. MIT/LCS/TR-340,
Laboratory for Computer Science, MIT.

248

fiJournal of Artificial Intelligence Research 7 (1997) 47-66

Submitted 10/96; published 9/97

A New Look at the Easy-Hard-Easy Pattern of
Combinatorial Search Diculty
Dorothy L. Mammen

mammen@cs.umass.edu

Tad Hogg

hogg@parc.xerox.com

Department of Computer Science
University of Massachusetts
Amherst, MA 01003, U.S.A.
Xerox Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, CA 94304, U.S.A.

Abstract

The easy-hard-easy pattern in the diculty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in
number of solutions and increased pruning. We test the generality of this explanation by
examining one of its predictions: if the number of solutions is held fixed by the choice
of problems, then increased pruning should lead to a monotonic decrease in search cost.
Instead, we find the easy-hard-easy pattern in median search cost even when the number of
solutions is held constant, for some search methods. This generalizes previous observations
of this pattern and shows that the existing theory does not explain the full range of the
peak in search cost. In these cases the pattern appears to be due to changes in the size of
the minimal unsolvable subproblems, rather than changing numbers of solutions.

1. Introduction

Recently, many authors have shown that the solution cost for various kinds of combinatorial
search problems follows a pattern of easy-hard-easy as a function of how tightly constrained
the problems are. For example, this pattern appears for graph coloring as a function of
the average graph connectivity (Cheeseman, Kanefsky, & Taylor, 1991; Hogg & Williams,
1994), for propositional satisfiability (SAT) as a function of the ratio of number of clauses to
number of variables (Cheeseman et al., 1991; Mitchell, Selman, & Levesque, 1992; Crawford
& Auton, 1993; Gent & Walsh, 1994b), and for constraint satisfaction problems (CSPs) as a
function of the number of nogoods (Williams & Hogg, 1994) and constraint tightness (Smith,
1994; Prosser, 1996).
This regularity raises the possibility of determining, prior to search, the likely diculty
of problems. Unfortunately, this is not yet possible because of the high variance associated with the observations. This is compounded by the fact that a single problem can be
viewed as belonging to a variety of problem classes, each with somewhat different transition points. Thus one important direction for improvement is to investigate whether there
are simple additional parameters that can reduce this variance and allow predictions with
higher confidence.
One approach to this question is based on the explanation of the easy-hard-easy pattern
as a competition between changes in the number of solutions and pruning of unproductive
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiMammen & Hogg

search paths as a function of some measure of the degree to which the problems are constrained. In particular this predicts that problems with many solutions tend to be easier,
on average, than those with fewer for a given number of constraints. Thus, at least one
aspect of the high variance in search cost appears to be due to the variance in number of
solutions in the problems of a fixed degree of constraint. This observation has motivated
the introduction of additional parameters describing problem structure based on a more
precise specification of the number of solutions (Hogg, 1996).
In this paper we investigate the generality of this explanation by examining problems for
which the number of solutions is restricted, including cases where the number is specified
exactly to be either zero or one. If the peak in search cost in fact arises generally from a
competition between changes in the number of solutions and pruning, cases with a fixed
number of solutions should not show a peak. However, we find that a peak continues to
appear in these cases for some sophisticated search algorithms, while it fails to appear in
other cases. This calls into question the generality of the explanation based on number of
solutions, and also suggests that a search for additional problem structure parameters based
solely on reducing the variance in the number of solutions is not likely to be sucient to
accurately predict search cost. However, some structural aspect of problems is likely to be
involved. Specifically, we present data showing that the smallest of the problem's minimal
unsolvable subproblems correlates well with search cost.
In the next section we describe some classes of search problems. We then review the
pattern of search behavior and the current theoretical explanation for it. In the following
section we uncover some limitations of this explanation by examining problems with some
specification on their number of solutions. This shows the easy-hard-easy pattern is a more
general phenomenon than suggested by current explanations. We then suggest an alternative explanation related to problem structure, and present data for unsolvable problems
showing a positive relationship between this problem structure parameter, the minimum
size of minimal unsolvable subproblem, and search cost. This same problem structure parameter may explain differences in search cost among solvable problems with equal numbers
of solutions, as well. Finally, we discuss some of the implications of these observations and
make suggestions for obtaining a better understanding and greater predictability for hard
search problems.

2. Some Classes of Search Problems

In common with many previous studies of the transition phenomenon, we use random binary
CSPs and graph coloring as example classes of search problems. This section describes how
the problems were generated and searched.

2.1 Random CSPs

The constraint satisfaction problems used in most of our experimental results consist of 10
variables with three possible values for each one, and in some cases, we repeated experiments
with problems of 20 variables. Problem constraints are specified by a number of binary
nogoods, i.e., assignments to a pair of variables that are considered to be inconsistent.
The search problem is then to find a consistent complete assignment, i.e., a value for each
variable that does not include any of the inconsistent pairs.
48

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

We generated problems in a number of ways to fully sample the range of behaviors. In
the first method (\generate-select") we generate CSPs by randomly selecting the specified
number of binary nogoods. To produce classes of problems with restrictions on their number
of solutions, we determine the number of solutions of these randomly generated problems
and retain only those satisfying these restrictions. For example, to produce a class of
solvable problems, only those with a solution are included. Similarly, to produce a class of
problems with a fixed number of solutions, only those problems with exactly the specified
number of solutions are retained.
This random generation method gives a simple, uniform selection from the various problem classes. However, it can also be very inecient in generating problems. For instance,
with few nogoods, most randomly generated problems are solvable, hence requiring a large
number of random trials to obtain even a few unsolvable cases.
To address this problem, we also used more ecient (\hill-climbing") methods. Specifically, for generating solvable problems with many nogoods, starting with a randomly generated unsolvable problem, we removed constraints at random until the problem became
solvable, then restored the number of constraints removed with constraints chosen randomly,
but with the requirement that the problem not become unsolvable again.
For generating unsolvable problems with few nogoods, the hill-climbing method started
with a randomly generated solvable problem, removed the constraint that constrained the
problem the least (the one whose removal increased the number of solutions the least), and
added a randomly chosen constraint that resulted in a problem with fewer solutions than
the problem had before the constraint removal. If, having removed one constraint, no other
constraint could decrease the number of solutions, the constraint that increased the number
of solutions the least was chosen { a slightly backwards step. To speed this process up, we
checked only one third of the possible constraints before giving up, choosing the one that
increased the number of solutions the least, and starting another iteration.
Other methods for generating problems with specified requirements on the number of
solutions have also been studied. One popular method for solvable problems is to randomly
select an assignment to all of the variables (a pre-specified solution) and then, during the
random selection of nogoods, avoid any that are inconsistent with this pre-specified solution.
This tends to emphasize problems with many solutions and results in instances that are
somewhat easier than uniform random selection. Cha & Iwama (1995) have also used the
approach of generating problems with specific attributes, for SAT problems, using the AIM
generators (Asahiro, Iwama, & Miyano, 1993).
We solved these problems using dynamic backtracking (Ginsberg, 1993) in most cases,
using random variable and value ordering. For comparison, we also did some searches with
simple chronological backtrack instead. The search cost is measured as the number of nodes
explored.

2.2 Graph Coloring

We also experimented with the 3-coloring problem. This constraint satisfaction problem
consists of a graph and the requirement to assign each node one of three colors so that no
pair of nodes linked by an edge have the same color. Each edge in the graph defines some
binary nogoods for the problem, namely all pairs of assignments giving the same color to the
49

fiMammen & Hogg

two nodes connected by the edge. Thus each edge in the graph gives three binary nogoods.
A convenient measure of the number of constraints is  , the connectivity or average degree
of the nodes in the graph. This is equal to twice the number of edges in the graph divided
by the number of nodes, because each edge is incident on two nodes. For the 100-node
graphs we studied, the number of binary nogoods is given by 150 .
In this case, we used a simple chronological backtrack search in combination with the
Brelaz heuristic for variable and value ordering (Johnson, Aragon, McGeoch, & Schevon,
1991). This heuristic assigns the most constrained nodes first (i.e., those with the most
distinctly colored neighbors), breaking ties by choosing nodes with the most uncolored
neighbors, and with any remaining ties broken randomly. The colors are considered in a
fixed ordering for all of the nodes in the search. As a simple optimization, the search never
changes the colors selected for the first two nodes. Any such changes would amount to
unnecessarily repeating the search with a permutation of the colors for unsolvable cases.
Search cost is measured by the number of nodes explored.

3. The Easy-Hard-Easy Pattern

In this section, we present an example of the how search cost varies with the tightness
of constraints for a class of problems, and describe how this behavior can be understood
in terms of changes in the structure of the problems, independent of particular search
algorithms. This review and summary of previous studies of the transition then forms a
basis for comparison with the new results presented in subsequent sections.

3.1 An Example

Figure 1 shows a typical example of the easy-hard-easy pattern as a function of the constrainedness of the problem. Problems with few or many constraints tend to be easy to
solve while those with an intermediate number are more dicult. The fraction of solvable
problems is also shown in Figure 1, scaled from 1.0 on the left to 0.0 on the right. This
illustrates that the hard problems are concentrated in the so-called \mushy region" (Smith
& Dyer, 1996) where the probability of a solution is changing from 1.0 to 0.0. In particular,
the peak in search cost is near the \crossover point," the point at which half the problems
are solvable and half unsolvable. For this problem class, the crossover point occurs at just
over 75 binary nogoods, and the peak in dynamic backtracking solution cost occurs at about
85 binary nogoods.
In all of our results in this paper, we include 95% confidence intervals (Snedecor &
Cochran, 1967). These intervals for the estimate of the p
median obtained from our samples
are given approximately by the percentiles 50  100= N of the data, where N is the
number
of samples. For the estimate of fractions the intervals are given approximately by
p
of the fraction. Finally, for the estimate
f  2 f (1 , f )=N , where f is the estimated value p
of means the intervals are approximately x  1:96= N where x is the estimate of the mean
and  the standard deviation of the sample. In many cases in this paper, there are sucient
samples to make these intervals smaller than the size of the plotted points.
A key point from examples such as this is that the dicult instances within a class of
search problems tend to be concentrated near a particular value of the constraint tightness
(here measured by the number of binary nogoods). Because this behavior is seen for a
50

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

Cost
200

150

100

50

20

40

60

80

100

120

140

Nogoods

Figure 1: Typical transition pattern. Median solution cost for dynamic backtracking (solid line)

and probability of a solution (dashed line) as a function of number of nogoods. Each
point represents 1000 problems of 10 variables and domain size 3, each solved 100 times.
Error bars showing 95% confidence intervals are included, but are in some cases smaller
than the size of the plotted points.

variety of search methods, it indicates this concentration does not depend much on the
details of the search algorithm. Instead, it appears to be associated with a change in the
properties of the problems themselves, namely their solvability.

3.2 An Explanation

These observations raise a number of questions, such as why a peak in search cost exists,
why the peak occurs near the transition from mostly solvable to mostly unsolvable problems
and is thus independent of the particular search algorithm, and why this behavior is seen
for a large variety of constraint satisfaction problems.
The existing explanation for the concentration of hard problems relies on a competition
between changes in the number of solutions and the amount of pruning provided by the
problem constraints (Williams & Hogg, 1994). With few constraints, there are many solutions so the search is usually easy. As constraints are added the number of solutions drops
rapidly, making problems harder. But the new constraints also increase the pruning of unproductive search choices, tending to make search easier. When there are few constraints,
the decrease in the number of solutions overwhelms the increase in pruning, giving harder
problems on average. Eventually the last solution is eliminated and all that remains is the
increased pruning from additional constraints, leading to easier problems. Thus the phase
transition, the point at which there is a precipitous change from solvability to unsolvability, more or less coincides with the peak in solution cost. All these effects become more
pronounced as larger problems are considered, leading to sharper peaks and more abrupt
51

fiMammen & Hogg

transitions. This qualitative description explains many features of the observed behavior.
This pruning explanation was also offered by Cheeseman et al. (1991) with respect to
finding Hamiltonian circuits in highly constrained problems.
This explanation can also be used to obtain a quantitative understanding of the behavior.
For instance, the location of the transition region can be understood by an approximate
theory predicting that the cost peak occurs when the expected number of solutions equals
one (Smith & Dyer, 1996; Williams & Hogg, 1994). In our example
there are 310 possible
,10 2
assignments to the 10 variables in the problem. There are 2 3 = 405 possible binary
nogoods for the problem, which counts the number of ways to select a pair of variables and
the different assignments for that pair. A given complete assignment for the 10 variables will
be a solution provided each of the selected binary nogoods does not use the, same
assignment

for its pair of variables as in the given complete assignment. This leaves 102 (32 , 1) = 360
possible choices for the binary nogoods. Thus the expected number of solutions is given by
,360
10
m
3  ,405
m

for problems with m randomly selected binary nogoods. This expression equals one at
m = 82:9, the location of the observed cost peak. Furthermore, because the expected
number of solutions grows exponentially with the number of variables when m is smaller
than this threshold value and decreases exponentially to zero when m is larger, the range
of m values over which the expected number of solutions is near one rapidly decreases as
variables are added. This accounts for the observed sharpening of the transition for larger
problems.
A further quantitative success of relating the search cost peak to transition phenomena
is the evaluation of scaling behavior of the transition and search cost peak (Kirkpatrick &
Selman, 1994; Gent, MacIntyer, Prosser, & Walsh, 1995).

4. Search Diculty and Solvability

In this section we take a closer look at the behavior of the search cost, specifically, by
examining how the behavior depends on whether the problem has a solution and, if so, the
number of solutions.

4.1 Search Behavior

Figure 2 shows the median dynamic backtracking solution cost for solvable and unsolvable
random CSPs generated as described above, for problems with number of variables n = 10
and n = 20, with domain size three. Except where specified otherwise in the figure caption,
for problems of 10 variables we generated 1000 solvable and 1000 unsolvable problems for
each point, and for problems of 20 variables we generated 500 solvable and 500 unsolvable
problems for each point, using the \generate-select" method. We also generated unsolvable
problems of 10 variables with 10 to 70 nogoods using the \hill-climbing" method. We
overlap the range of problems generated by the two methods to show how the different
generation methods affect search cost.
This figure clearly shows the easy-hard-easy pattern of solution cost for both solvable
and unsolvable problems, for both problem sizes. The two methods of generating unsolvable
52

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

Cost

3
10

2
10

2

4

6

8

10

12

14

m/n

Figure 2: Median solution cost using dynamic backtracking for solvable (solid lines) and unsolvable
(dashed and dotted lines) problems with number of variables n = 10 (black lines) and
n = 20 (gray lines) as a function of number of nogoods divided by problem size, m=n.

All problems were generated using the \generate-select" method except for the unsolvable problems shown by the dotted line, which were generated using the \hill-climbing"
method. For problems of size 10, each point is the median of 1000 problems solved 100
times, except for unsolvable problems generated by \generate-select" at m=n = 3 (30
nogoods) and solvable problems at m=n = 14 (140 nogoods), which are based on 100
problems. For problems of size 20, each point is the median of 500 problems solved 100
times, except for unsolvable problems at m=n = 5 (100 nogoods) and solvable problems
at m=n = 12 (240 nogoods), which are based on 15 and 35 problems, respectively. Error
bars showing 95% confidence intervals are included, but in most cases are smaller than
the size of the plotted points.

problems give distinct curves: the unsolvable problems generated by the \hill-climbing"
method are harder than those generated by the \generate-select" method. Nonetheless,
both sets of problems show the same easy-hard-easy pattern.
Another example with the same behavior is shown in Figure 3 for the median search
cost for instances of 3-coloring of random graphs. In contrast to Figure 2, the solvable
and unsolvable cases have similar median search costs near the peaks. This is because, as
described above, the graph coloring searches for unsolvable cases used the symmetry with
respect to permutations of the colors to avoid unnecessary search. Without this optimization, the costs for unsolvable cases would be six times greater than the values shown in the
figure. Similar peaks are seen for other classes of graphs, such as connected ones, although
at somewhat different values of  .
These data show that both random CSPs and graph coloring problems exhibit an easyhard-easy pattern for solvable and unsolvable problems considered separately.
53

fiMammen & Hogg

Cost
250
200
150
100
50
0

1

2

3

4

5

6

7



Figure 3: Median solution cost for 3-coloring random graphs with 100 nodes as a function of connectivity  using backtrack search with the Brelaz heuristic. The solid and dashed curves

correspond to solvable and unsolvable cases respectively. These results started with
100,000 random graphs at each value of  , and additional samples were generated at
the extremes to produce at least 100 samples for each point. For random graphs, the
crossover from mostly solvable to mostly unsolvable occurs around a connectivity of 4.5.
Error bars showing 95% confidence intervals are included.

4.2 Solvable Problems

A peak in search cost for solvable problems such as we observed has also been seen extensively in studies of local-repair search methods and for problems generated with a prespecified solution (Yugami, Ohta, & Hara, 1994; Kask & Dechter, 1995; Williams & Hogg,
1994). These search methods start with some assignment to all of the variables in the
problem and then attempt to adjust them until a solution is found. Generally, such methods are not systematic searches: they can never determine that a problem has no solution.
Thus empirical studies of these methods are restricted to consider solvable problems and
incidentally provide a useful examination of the properties of solvable problems.
Furthermore, a study of satisfiability problems with backtracking search is consistent
with a peak in cost for solvable problems (Mitchell et al., 1992), but there were insucient
highly constrained solvable problems to make a definite conclusion for the behavior with
many constraints.
How does the existence of a peak for solvable problems fit with the explanation given
above? Certainly an explanation based on a transition from solvable to unsolvable problems
cannot apply directly to the class of solvable problems. However, the competition between
increased pruning and decreased number of solutions still applies. As shown in Figure 4,
the number of solutions for solvable random CSPs of size 10 at first decreases rapidly as
constraints are added but then nears its minimum value of one, giving a slower decrease.
54

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

Solutions
4
10

1
10
0

20

40

60

80

100

120

140

Nogoods

Figure 4: Mean (solid) and median (dashed) number of solutions on a log scale as a function of the

number of binary nogoods, for solvable problems with 10 variables, 3 values each, based
on 1000 problems generated by the \generate-select" method at each multiple of 10 binary
nogoods, except for 140 nogoods, which is based on 100 problems. At 0 nogoods there
are 310 = 59049 solutions. Error bars showing 95% confidence intervals are included.

Except for the change in minimum value from 0 to 1 solution, this behavior for the number
of solutions is qualitatively similar to that for the general case including both solvable
and unsolvable problems. The additional constraints continue to increase the pruning of
unproductive search paths. Thus the explanation given above might continue to apply but
now predicts the peak will be at the point where solutions can drop no further (i.e., one
solution) rather than becoming unsolvable (i.e., zero solutions).
Figure 5 evaluates this idea. This figure shows how the fraction of problems with at
least two solutions changes as a function of the number of nogoods divided by the problem
size for random CSPs with 10 and 20 variables. For problems of size 10, the second to
last solution disappears, on average, between 90 and 100 nogoods: the median number
of solutions has dropped to 2 by 90 nogoods, and to 1 by 100 nogoods (Figure 4). The
peak in solution cost for solvable problems is slightly lower than this, at between 80 and
90 nogoods, close to the crossover point of Figure 5 where half the solvable problems have
only one solution. This is perhaps close enough to be consistent with the explanation given
above. However, this relationship does not hold for problems of size 20. For this class of
problems, the cost peak of solvable problems is at around 180 nogoods (m=n = 9), whereas
the point at which half the problems have just one solution has still not been reached by
240 nogoods (m=n = 12). At 180 nogoods, the median number of solutions is 4 (mean is
10.0), and at 240 nogoods, the median is still 2 (mean is 1.83). This is inconsistent with
the explanation that the cost peak for solvable problems is due to the increasing effect of
pruning given no possible further decrease in number of solutions.
55

fiMammen & Hogg

Fraction
1
0.8
0.6
0.4
0.2

2

4

6

8

10

12

14

m/n

Figure 5: Fraction of problems with at least two solutions as a function of number of nogoods di-

vided by problem size, for problems of size 10 (black line) and size 20 (gray line). Data for
problems of size 10 are based on 1000 solvable problems created by the \generate-select"
method at each point, except for 100 solvable problems at m=n = 14 (140 nogoods).
Data for problems of size 20 are based on 500 solvable problems at each point, except for
20 solvable problems at m=n = 12 (240 nogoods), also created by the \generate-select"
method. Error bars showing 95% confidence intervals are included.

Since the explanation depending on a change to insolubility does not apply, and the
pruning versus number of solutions explanation does not fit the data, some other factors
must be at work to produce the easy-hard-easy pattern for solvable problems. We suspect the explanation is related to the idea of minimal unsolvable subproblems. A minimal
unsolvable subproblem is a subproblem that is unsolvable, but for which any subset of variables and their associated constraints is solvable; Gent & Walsh (1996) have referred to
this aspect of SAT problems as the minimal unsatisfiable subset. The idea is that once a
few bad choices have been made initially, such that the remainder of the problem becomes
unsolvable, unsolvability is much harder to determine for some problems than for others.
In particular, the more variables that are involved in a minimal unsolvable subproblem,
the harder it is to determine that the subproblem is unsolvable. We make the conjecture
that the cost peak for solvable problems is tied to the average size of the minimal unsolvable subproblem once a choice has been made that results in the remaining problem being
unsolvable.

4.3 Problems With a Fixed Number of Solutions

A more interesting case is the behavior of the problems with no solutions shown in Figures
2 and 3. As a further example, Figure 6 shows the solution cost for problems with exactly
one solution. This also shows a peak. These observations on problems with zero or one
56

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

Cost
160
140
120
100
80
60
40

60

80

100

120

140

Nogoods

Figure 6: Median solution cost as a function of number of nogoods for problems of 10 variables,

3 values each, with exactly one solution, generated using the \generate-select" method
(solid line), and by hill-climbing down to one solution starting from solvable problems
with many solutions produced using \generate-select" (dotted line), solved using dynamic
backtracking. Each point is the median of 1000 problems each solved 100 times, except
for hill-climbing generated problems at 25, 30 and 35 nogoods and \generate-select"
generated problems at 140 nogoods, of which there are 100. Error bars showing 95%
confidence intervals are included.

solution show that even with the number of solutions held constant, problems exhibit an
easy-hard-easy pattern of solution cost.
According to the explanation of the transition, if the number of solutions is held constant
then the increase in pruning will be the only factor, giving rise to a monotonic decrease
in search cost as constraints are added. Instead, we see in Figures 2, 3 and 6 that even
when the number of solutions is held fixed at zero or one, there is still a peak in solution
cost, and at a smaller number of nogoods. Thus the existing explanation does not capture
the full range of behaviors. Instead, it appears that there are other factors at work in
producing hard problems. By focusing more closely on these factors we can hope to gain
a better understanding of the structure of hard problems, which may lead to more precise
predictions of search cost.
We also investigated the effect of algorithm on the pattern of solution cost in unsolvable
problems by repeating the search of random CSPs using chronological backtrack. A comparison of chronological backtracking search with our previous dynamic backtrack search
results for unsolvable problems is shown in Figure 7. In this figure, the curves for dynamic backtracking are the same as those for the unsolvable problems shown in Figure 2,
except that here the cost curves are shown on a logarithmic scale. Interestingly, we do not
see a peak in search cost for unsolvable problems using the less sophisticated method of
chronological backtrack.
57

fiMammen & Hogg

Cost
4
10

3
10

2
10
20

40

60

80

100

120

140

Nogoods

Figure 7: Comparison of median solution cost on a log scale using the same sets of unsolvable

problems for chronological backtracking (black) and dynamic backtracking (gray). Dotted
lines are for problems generated using the \hill-climbing" method, solid lines for the
\generate-select" method. Each point is the median of 1000 problems each solved 100
times, except for the \generate-select" method at 30 nogoods, which is based on 100
problems. Error bars showing 95% confidence intervals are included, but are smaller
than the size of the plotted points.

This observation raises an important point: the easy-hard-easy pattern is not a universal
feature of search algorithms for problems restricted to a fixed number of solutions. This
suggests that the competition between number of solutions and pruning, when it occurs,
is suciently powerful to affect most search algorithms (very simple methods, such as
generate-and-test, do not make use of pruning and show a monotonic increase in search
cost as the number of solutions decreases), but that only some algorithms are able to
exploit the features of weakly constrained problems with a fixed number of solutions that
make them easy.
In contrast to our observations, a monotonic decrease in cost has been reported for
unsolvable binary random constraint problems (Smith & Dyer, 1996) and for unsolvable
3SAT problems (Mitchell et al., 1992). In the case of 3SAT, the explanation may well be
choice of algorithm. Indeed, Bayardo & Schrag (1996) recently found that incorporating
conict-directed backjumping and learning into the Tableau algorithm made a difference of
many orders of magnitude in problem diculty specifically for rare, \exceptionally hard,"
unsatisfiable problems in the underconstrained region. It would be interesting to see whether
the easy-hard-easy pattern for unsolvable problems would appear using their algorithm.
With respect to Smith & Dyer's (1996) observations, the difference may be due to the
range of problems generated, resulting from different problem generation methods. Smith
and Dyer used a method akin to our \random" generation method, that is, generating
58

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

problems without regard for solvability, then separating out the unsolvable ones. With this
method, the \hit rate" for unsolvable problems in the underconstrained region is very low.
It is possible that Smith and Dyer's data do not extend down to the point at which the cost
of unsolvable problems begins to decrease simply because they stopped finding unsolvable
problems before that point.
There are two possible reasons why we might have found unsolvable problems using
random generation further into the underconstrained region, where Smith and Dyer did
not. One possibility is that since we were specifically interested in unsolvable problems as
far into the underconstrained region as possible, we may have spent more computational
effort generating in that region. Indeed, at 40 nogoods, unsolvable problems occurred with
frequency 4:5  10,5 , and at 30 nogoods, with frequency 7:75  10,7 . At that rate, problems
at 30 nogoods took about six hours apiece to generate.
A second possibility relates to the details of the generation methods. In Smith and
Dyer's random generation method, every pair of variables had exactly the same number
of inconsistent value pairs between them. This implies a degree of homogeneity in the
distribution of the nogoods. On the other hand, in our random generation method, each
variable-value pair had an equal probability of being selected as a nogood, independent of
one another. Thus it was at least possible in our generation method, though still of low
likelihood, for the nogoods to occasionally clump, and to produce an unsolvable problem.
This idea is discussed further in Section 5.
The difference in our observation and Smith & Dyer's (1996) reinforces an important
point: that a relatively subtle difference in generation methods can affect the class of
problems generated. While the nogoods will be more or less evenly distributed on average
using our generation method, they will also be clumped with some probability, whereas
with Smith and Dyer's generation method, a homogeneous distribution over variable pairs
is guaranteed. These types of problems could be different enough to sometimes produce
different behavior.

5. Minimal Unsolvable Subproblems

Our observations on classes of problems with restrictions on the number of solutions they
may have shows that the common identification of the peak in solution cost with the
algorithm-independent transition in solvability seen in general problem classes does not
capture the full generality of the easy-hard-easy pattern.
For solvable problems, this explanation could be readily modified to use a transition
in the existence of solutions beyond those specified by the construction of the class of
problems and symmetries those problems might have that constrain the allowable range of
solutions. This modification is a simple generalization of the existing explanation based
on the competition between the number of solutions and pruning. However, our data
for solvable problems do not support this explanation, in that the search cost peak and
disappearance of the second to last solution coincide only roughly for n = 10, and not at
all for n = 20.
Furthermore, when the number of solutions is held constant, competition between increased pruning and decreasing number of solutions cannot possibly be responsible for a
peak in solution cost. The decrease in search cost for highly constrained problems (to
59

fiMammen & Hogg

the right of the peak) is adequately explained by the prevailing explanation, based on the
increase in pruning with additional constraints. But this does not explain why weakly constrained problems are also found to be easy, at least for some search methods. The low cost
of unsolvable problems in the underconstrained region is a new and unexpected observation
in light of previous studies of the easy-hard-easy pattern and its explanation. This raises
the question of whether there is a different aspect of problem structure that can account
for the peak in search cost for problems with a fixed number of solutions.
One possibility that is often mentioned in this context is the notion of critically constrained problems. These are problems just on the boundary between solvable and unsolvable problems, i.e., neither underconstrained (with many solutions) nor overconstrained
(with none). This notion forms the basis for another common interpretation of the cost
peak. That is, these critically constrained problems will typically be hard to search (because most of the constraints must be instantiated before any unproductive search paths
can be identified) and, since they are concentrated at the transition (Smith & Dyer, 1996),
give rise to the search peak. This explanation does not include any discussion of the changes
in pruning capability as constraints are added. Taken at face value, this explanation would
predict no peak at all for solvable problems or when the number of solutions is held constant,
because such classes have no transition from solvable to unsolvable problems. Moreover,
this description of critically constrained problems is not simply a characteristic of an individual problem but rather is partly dependent on the class of problems under consideration
because the exact location of the transition depends on the method by which problems
are generated. This observation makes it dicult to characterize the degree to which an
individual problem is critically constrained purely in terms of structural characteristics of
that problem. By contrast, a measure such as the number of solutions is well defined for
individual problem instances, which facilitates using its average behavior for various classes
of problems to approximately locate the transition region. Thus, as currently described,
the notion of critically constrained problems does not explain our observations nor does it
give an explicit way to characterize individual problems.
A more precisely defined alternative characteristic is the size of minimal unsolvable subproblems. As we mentioned in Section 4.2, a minimal unsolvable subproblem is a subproblem
that is unsolvable, but for which any subset of variables and their associated constraints is
solvable.
Some problems have more than one minimal unsolvable subproblem. For example, a
problem might have one minimal unsolvable subproblem of five variables, and another, different one, of say, six. We computed all minimal unsatisfiable subproblems for all of the
10-variable unsolvable problems we had generated. We found a monotonic positive relationship between mean number of minimal unsolvable subproblems and number of nogoods. For
example, problems with 140 nogoods have an average of 35 minimal unsolvable subproblems
(range 4 to 64, standard deviation 8.7); those with 90 nogoods have about six (range 1 to
23, standard deviation 3.6); and problems with 50 or fewer nogoods rarely have more than
one minimal unsolvable subproblem. Similarly, Gent & Walsh (1996) observed that unsatisfiable problems in the underconstrained region tend to have small and unique minimal
unsatisfiable subsets.
The behavior of the size of the smallest minimal unsolvable subproblem as a function of
the number of nogoods is shown in Figure 8. Comparing with Figure 2, we see that the peak
60

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

Size
10
9
8
7
6
5
4
3

20

40

60

80

100

120

Nogoods
140

Figure 8: Mean size of smallest minimal unsolvable subproblem as a function of number of nogoods, for unsolvable problems generated using the \hill-climbing" (dotted line) and
\generate-select" (solid line) methods. Each point is based on 1000 problems, except for
the \generate-select" method at 30 nogoods, which is based on 100 problems. Error bars
showing 95% confidence intervals are included.

in the minimum size of minimal unsolvable subproblems matches the location of the search
cost peak for unsolvable problems. This result is independent of whether we plot the smallest
minimal unsolvable subproblem size, as shown in Figure 8, or medians or means, which we
have not shown here. Moreover, the location of the peaks in minimal unsolvable subproblem
size for the different generation methods correspond to the location of their respective
search cost peaks. The peak in both search cost and minimal unsolvable subproblem size
occurs at around 40 nogoods for problems generated using the \hill-climbing" method,
and significantly higher, around 60 nogoods, for problems generated using the \generateselect" method. The strong correspondence between minimal unsolvable subproblem size
and search cost is very suggestive that minimal unsolvable subproblem size is a structural
characteristic of problems that plays an important role in search cost. By contrast, number
of minimal unsolvable subproblems does not match the pattern of search cost. As mentioned
above, it increases monotonically with number of nogoods, suggesting that it does not play
a primary role in explaining search cost for unsolvable problems.
The behavior of the minimal unsolvable subproblem size as a function of the number
of constraints has a simple explanation. Unsolvable weakly constrained problems will generally need to concentrate most of the available constraints on a few variables in order to
make all assignments inconsistent. This will tend to give one small minimal unsolvable
subproblem. As more constraints are added, this concentration is no longer required and,
since problems where most of the randomly selected constraints happen to be concentrated
on a few variables are rare, we can expect more and larger minimal unsolvable subproblems.
61

fiMammen & Hogg

Cost
350

300

250

200

150

4

6

8

10

Size

Figure 9: Mean solution cost as a function of size of smallest minimal unsolvable subproblem, for
unsolvable problems with 60 nogoods generated using the \generate-select" method. Each
point is the mean of the median solution costs, based on solving each problem 100 times,
for the set of problems with the corresponding smallest minimal unsolvable subproblem
size. The points are based on following numbers of problems for each smallest minimal
unsolvable subproblem size, totaling 1000 problems: 3 { 1; 4 { 17; 5 { 71; 6 { 156; 7 {
253; 8 { 283; 9 { 165; 10 { 54. Error bars showing 95% confidence intervals are included,
except for the single problem at size 3 for which confidence intervals cannot be calculated.

Finally, as more and more constraints are added, the increased pruning is equivalent to the
notion that instantiating only a few variables is all that is required to find an inconsistency.
This means we can expect a large number of small unsolvable subproblems. This qualitative
description corresponds to what we observe in Figure 8.
Our observations of weakly constrained problems suggest that some search algorithms,
such as dynamic backtracking, are able to rapidly focus in on one of the unsolvable subproblems and hence avoid the extensive thrashing, and high search cost, seen in other methods.
In such cases, one would expect that the smaller the unsolvable subproblem, the easier it
will be for the search to determine there are no solutions.
In order to examine the role of minimal unsolvable subproblem in search cost more
closely, we plotted mean search cost versus size of smallest minimal unsolvable subproblem
for unsolvable problems of 10 variables at each multiple of 10 nogoods from 30 to 140
nogoods. In every case, mean search cost increased as a function of size of smallest minimal
unsolvable subproblem. Figure 9 shows an example of one of these plots, at the peak
in solution cost for this class of problems, 60 nogoods. It makes sense that the smallest
minimal unsolvable subproblem, being the easiest to detect, would play a significant role
in search cost. However, the situation is surely more complicated than this, suggested by
the fact that there is still variation among problems with the same size smallest minimal
62

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

unsolvable subproblem. This could be due, for example, to one problem having several
small minimal unsolvable subproblems, while another might have one minimal unsolvable
subproblem, even smaller. Number and size of minimal unsolvable subproblems are both
likely to play a role in search cost.
Number of minimal unsolvable subproblems does not seem to play as significant a role
as size of smallest minimal unsolvable subproblem, but its effect can also be demonstrated.
For the same sets of unsolvable problems as above, for each multiple of 10 nogoods from
80 to 140 nogoods, search cost correlates negatively with number of minimal unsolvable
subproblems. However, for unsolvable problems with 30 to 70 nogoods, where variance in
number of minimal unsolvable subproblems is lower (but variance in search cost is higher),
there is no relationship between search cost and number of minimal unsolvable subproblems. Additional clarification of the role in search cost of both size and number of minimal
unsolvable subproblems is left for further investigation. But size of smallest minimal unsolvable subproblem, which correlates strongly with search cost for (1) unsolvable problems
taken as a whole (see Figures 2 and 8) and (2) unsolvable problems with a fixed number of
nogoods over the full range of number of nogoods, appears to have the more primary effect.
This discussion of minimal unsolvable subproblems is also relevant to solvable problems:
once a series of choices that precludes a solution is made during search, the remaining subproblem is now an unsolvable one. For example, in a 10-variable CSP, suppose values are
given to the first two variables that are incompatible with all solutions to the problem. This
means that in the context of these two assignments, the remaining eight variables constitute an unsolvable subproblem. The number of search steps required to determine that this
subproblem is in fact unsolvable will be the cost added to the search before backtracking to
the original two variables and trying a new assignment for one of them. Thus, the cost of
identifying unproductive search choices for solvable problems is determined by how rapidly
the associated unsolvable subproblem can be searched. As described above, when there are
few constraints we can expect that such unsolvable subproblems will themselves have small
minimal unsolvable subproblems and hence be easy to search with methods that are able
to focus on such subproblems. While the unsolvable subproblems associated with incorrect
variable choices in solvable problems may have a different structure, this argument suggests that changes in minimal unsolvable subproblems may explain the behavior of solvable
problems with a fixed number of solutions as well. This could also explain observations of
thrashing behavior for rare exceptionally hard solvable problems in the underconstrained
region (Gent & Walsh, 1994a; Hogg & Williams, 1994); we would expect such problems
to have a relatively large unsolvable subproblem to detect given the initial variable assignments. Finally, it would be interesting to study the behavior of local repair search methods
for problems with a single solution to see if they also are affected by the change in minimal
subproblem size.

6. Conclusions

We have presented evidence that the explanation of the easy-hard-easy pattern in solution
cost based on a competition between changes in the number of solutions and pruning is
insucient to explain the phenomenon completely for sophisticated search methods. It
does explain the overall pattern for problems not restricted by solvability or number of
63

fiMammen & Hogg

solutions. However, the explanation fails when the number of solutions is held constant
and sophisticated search methods are used. In these cases the solution cost peak does not
disappear as would be predicted. Alternatively, we can view this explanation as adequate for
less sophisticated methods that are not able to readily focus in on unsolvable subproblems
encountered during the search.
By considering relatively small search problems, we are able to exhaustively examine
the properties of the search space. This allowed us to definitively demonstrate the importance for search behavior of an aspect of problem structure: the size of minimal unsolvable
subproblems. Our approach contrasts with much work in this area that involves solving
problems as large as feasible within reasonable time bounds. While the latter approach
gives a better indication of the asymptotic behavior of the transition, it is not suitable
for exhaustive evaluation of the nature of the search spaces encountered, nor for detailed
analysis of aspects of individual problem structure.
We believe that detailed examination of the structure of combinatorial problems can
yield information about why certain types of problems are dicult or easy. As a class, graph
coloring or random CSPs are NP-complete, yet in practice many such problems are actually
very easy. In addition, while theoretical work in this area has produced predictions that are
asymptotically correct on average, the variance among individual problems in a predicted
class is enormous. Increased understanding of the relationships between problem structure,
problem solving algorithm, and solution cost is important to determining whether, and if so,
how, we can determine prior to problem solving which problems are easy versus infeasibly
hard. In contrast to previous theoretical studies that focus on the number of solutions, this
work suggests that the size of minimal unsolvable subproblems is an alternate characteristic
to study with the potential for producing a more precise characterization of the transition
behavior and the nature of hard search problems.

Acknowledgements
Much of this research was carried out while the first author was a summer intern at Xerox
Palo Alto Research Center. This research was also partially supported by the National
Science Foundation under Grant No. IRI-9321324 to Victor R. Lesser. Any opinions,
findings, and conclusions or recommendations expressed in this material are those of the
authors and do not necessarily reect the views of the National Science Foundation.

References

Asahiro, Y., Iwama, K., & Miyano, E. (1993). Random generation of test instances with
controlled attributes. In Second DIMACS Challenge Workshop.
Bayardo, Jr., R. J., & Schrag, R. (1996). Using CSP look-back techniques to solve exceptionally hard SAT instances. In Freuder, E. C. (Ed.), Principles and Practice of
Constraint Programming { CP96, pp. 46{60 Cambridge, MA. Springer.
Cha, B., & Iwama, K. (1995). Performance test of local search algorithms using new
types of random CNF formulas. In Proceedings of the Fourteenth International Joint
64

fiThe Easy-Hard-Easy Pattern of Combinatorial Search Difficulty

Conference on Artificial Intelligence, pp. 304{310 Montreal, Quebec, Canada.

Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). Where the really hard problems are. In
Proceedings of the Twelfth International Joint Conference on Artificial Intelligence,
pp. 331{337 Sydney, Australia.
Crawford, J. M., & Auton, L. D. (1993). Experimental results on the cross-over point
in satisfiability problems. In Proceedings of the Eleventh National Conference on
Artificial Intelligence, pp. 21{27 Washington, DC, USA.
Gent, I. P., MacIntyre, E., Prosser, P., & Walsh, T. (1995). Scaling effects in the CSP phase
transition. In Montanari, U., & Rossi, F. (Eds.), Proc. of Principles and Practices of
Constraint Programming PPCP95, pp. 70{87. Springer-Verlag.
Gent, I. P., & Walsh, T. (1994a). Easy problems are sometimes hard. Artificial Intelligence,
70, 335{345.
Gent, I. P., & Walsh, T. (1994b). The SAT phase transition. In Cohn, A. (Ed.), Proceedings
of the ECAI-94, pp. 105{109. John Wiley and Sons.
Gent, I. P., & Walsh, T. (1996). The satisfiability constraint gap. Artificial Intelligence,
81 (1-2), 59{80.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal of Artificial Intelligence Research,
1, 25{46.
Hogg, T. (1996). Refining the phase transitions in combinatorial search. Artificial Intelligence, 81, 127{154.
Hogg, T., & Williams, C. P. (1994). The hardest constraint problems: A double phase
transition. Artificial Intelligence, 69, 359{377.
Johnson, D. S., Aragon, C. R., McGeoch, L. A., & Schevon, C. (1991). Optimization by
simulated annealing: An experimental evaluation; part II, Graph coloring and number
partitioning. Operations Research, 39 (3), 378{406.
Kask, K., & Dechter, R. (1995). GSAT and local consistency. In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, pp. 616{622 Montreal,
Quebec, Canada.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior in the satisfiability of random
boolean expressions. Science, 264, 1297{1301.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard and easy distributions of SAT
problems. In Proceedings of the Tenth National Conference on Artificial Intelligence,
pp. 459{465 San Jose, CA, USA.
Prosser, P. (1996). An empirical study of phase transitions in binary constraint satisfaction
problems. Artificial Intelligence, 81, 81{109.
65

fiMammen & Hogg

Smith, B. M. (1994). Phase transition and the mushy region in constraint satisfaction
problems. In Cohn, A. (Ed.), Proceedings of the ECAI-94, pp. 100{104. John Wiley
and Sons.
Smith, B. M., & Dyer, M. E. (1996). Locating the phase transition in binary constraint
satisfaction problems. Artificial Intelligence, 81, 155{181.
Snedecor, G. W., & Cochran, W. G. (1967). Statistical Methods (6th edition). Iowa State
Univ. Press, Ames, Iowa.
Williams, C. P., & Hogg, T. (1994). Exploiting the deep structure of constraint problems.
Artificial Intelligence, 70, 73{117.
Yugami, N., Ohta, Y., & Hara, H. (1994). Improving repair-based constraint satisfaction
methods by value propagation. In Proceedings of the Twelfth National Conference on
Artificial Intelligence, pp. 344{349 Seattle, WA, USA.

66

fiJournal of Artificial Intelligence Research 7 (1997) 125-159

Submitted 5/97; published 10/97

Analysis of Three-Dimensional Protein Images
Laurence Leherte

Laboratoire de Physico-Chimie Informatique
Facultes Universitaires Notre-Dame de la Paix
Namur, Belgium

Laurence.Leherte@scf.fundp.ac.be

Janice Glasgow
Kim Baxter

janice@qucis.queensu.ca
baxter@qucis.queensu.ca

Department of Computing and Information Science
Queen's University, Kingston, Ontario, Canada, K7L 3N6

Evan Steeg

steeg@qucis.queensu.ca

Molecular Mining Corp., PARTEQ Innovations
Queen's University , Kingston, Ontario, Canada, K7L 3N6

Suzanne Fortier

fortiers@qucdn.queensu.ca

Departments of Computing and Information Science and Chemistry
Queen's University, Kingston, Ontario, Canada, K7L 3N6

Abstract

A fundamental goal of research in molecular biology is to understand protein structure.
Protein crystallography is currently the most successful method for determining the threedimensional (3D) conformation of a protein, yet it remains labor intensive and relies on an
expert's ability to derive and evaluate a protein scene model. In this paper, the problem
of protein structure determination is formulated as an exercise in scene analysis. A computational methodology is presented in which a 3D image of a protein is segmented into a
graph of critical points. Bayesian and certainty factor approaches are described and used
to analyze critical point graphs and identify meaningful substructures, such as ff-helices
and fi -sheets. Results of applying the methodologies to protein images at low and medium
resolution are reported. The research is related to approaches to representation, segmentation and classification in vision, as well as to top-down approaches to protein structure
prediction.

1. Introduction
Crystallography plays a major role in current efforts to characterize and understand molecular structures and molecular recognition processes. The information derived from crystallographic studies provides a precise and detailed depiction of a molecular scene, an essential
starting point for unraveling the complex rules of structural organization and molecular
interactions in biological systems. However, only a small fraction of the currently known
proteins have been fully characterized.
The determination of molecular structures from X-ray diffraction data belongs to the
general class of image reconstruction exercises from incomplete and/or noisy data. Research
in artificial intelligence and machine vision has long been concerned with such problems.
Similar to the concept of visual scene analysis, molecular scene analysis is concerned with
the processes of reconstruction, classification and understanding of complex images. Such

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

analyses rely on the ability to segment a representation of a molecule into its meaningful
parts, and on the availability of a priori information, in the form of rules or structural
templates, for interpreting the partitioned image.
A crystal consists of a regular (periodic) 3D arrangement of identical building blocks,
termed the unit cell. A crystal structure is defined by the disposition of atoms and molecules
within this fundamental repeating unit. A given structure can be solved by interpreting an
electron density image of its unit cell content, generated { using a Fourier transform { from
the amplitudes and phases of experimentally derived diffraction data. An electron density
map is a 3D array of real values that estimate the electron density at given locations in the
unit cell; this information gives access to the structure of a protein1 . Unfortunately, only
the diffraction amplitudes can be measured directly from a crystallographic experiment; the
necessary phase information for constructing the electron density image must be obtained
by other means2 . This is the classic phase problem of crystallography.
In contrast to small molecules (up to 150 or so independent, non-hydrogen atoms), the
determination of protein structures (which often contain in excess of 3000 atoms) remains a
complex task hindered by the phase problem. The initial electron density images obtained
from crystallographic data for these macromolecules are typically incomplete and noisy. The
interpretation of a protein image generally involves mental pattern recognition procedures
where the image is segmented into features, which are then compared with anticipated
structural motifs. Once a feature is identified, this partial structure information can be
used to improve the phase estimates resulting in a refined (and eventually higher-resolution)
image of the molecule. Despite recent advances in tools for molecular graphics and modeling,
this iterative approach to image reconstruction is still a time consuming process requiring
substantial expert intervention. In particular, it depends on an individual's recall of existing
structural patterns and on their ability to recognize the presence of these motifs in a noisy
and complex 3D image representation.
The goal of the research described in this paper is to facilitate the image reconstruction processes for protein crystals. Towards this goal, techniques from artificial intelligence,
machine vision and crystallography are integrated in a computational approach for the interpretation of protein images. Crucial to this process is the ability to locate and identify
meaningful features of a protein structure at multiple levels of resolution. This requires a
simplified representation of a protein structure, one that preserves relevant shape, connectivity and distance information. In the proposed approach, molecular scenes are represented
as 3D annotated graphs, which correspond to a trace of the main and side chains of the
protein structure. The methodology has been applied to ideal and experimental electron
density maps at medium resolution. For such images, the nodes of the graph correspond
to amino acid residues and the edges correspond to bond interactions. Initial experiments
using low-resolution electron density maps demonstrate that the image can be segmented
into protein and solvent regions. At medium resolution the protein region can be further
segmented into main and side chains and into individual residues along the main chain.
1. Strictly speaking, the diffraction experiment provides information on the ensemble average over all of
the unit cells.
2. Current solutions to the phase problem for macromolecules rely on gathering extensive experimental
data and on considerable input from experts during the image interpretation process.

126

fiAnalysis of Three-Dimensional Protein Images

Furthermore, the derived graph representation of the protein can be analyzed to determine
secondary structure motifs within the protein.
The paper presents a brief overview of protein structure and the problem of analyzing
a molecular scene. The processes of protein segmentation and secondary structure identification are described, along with experimental results. Related and ongoing research issues
are also presented.

2. Protein Structure

A fundamental goal of research in molecular biology is to understand protein structure and
function. In particular, structure information is essential for medicine and drug design. In
this section we review some of the concepts involved in protein structure. These concepts will
be used later in describing our computational approach to protein structure determination.
A protein is often characterized as a linear list of amino acids called the primary structure, or sequence, for the protein. All of the naturally occurring amino acids have a similar
backbone structure, consisting of a central carbon atom (Cff ), an amino group (NH2 ) and
a carboxyl group (COOH ). They are distinguished from one another by their varying side
chains that are connected to the Cff atom. Figure 1 illustrates alternative representations
for the amino acid alanine, where Figure 1(c) displays its side chain consisting of a carbon
and three hydrogen atoms. Associated with the side chain of an amino acid are properties
such as hydrophobicity (dislikes water), polarity, size and charge.
side chain
H
C

CH 3

N
+

C H NO
3

7

H3 N

2

C

COO

-

O

H
(a) 1D chemical formula

(b) 2D structural formula

(c) Ball and stick model

Figure 1: Representations of the amino acid alanine.
Adjacent amino acids in the primary structure for a protein are linked together by
peptide bonds to form a polypeptide main chain, or backbone, from which the various side
chains project (see Figure 2). The carboxyl group of one amino acid joins with the amino
group of another to eliminate a water molecule (H2 O) and form the peptide bond.
A secondary structure of a protein refers to a local arrangement of a polypeptide subchain
that takes on a regular 3D conformation. There are two commonly recurring classes of
secondary structure: the ff-helix and the fi -sheet. An ff-helix occurs as a corkscrew-shaped
conformation, where amino acids are packed tightly together; fi -sheets consist of linear
strands (termed fi -strands) of amino acids running parallel or antiparallel to one another
(see Figure 3). These secondary structure motifs are generally linked together by less
127

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

amino acid n
H

O
H
C

N
C

R

H

C

N

N

C
H

R

H

O

H
C

O
C

R

peptide bond

side chain

Figure 2: Proteins are built by joining together amino acids using peptide bonds.
regular structures, termed loops or turns. As will be discussed later in the paper, the
characterization of a subsequence of amino acids as an ff-helix or fi -sheet can be determined
by a geometric analysis of the distance and angle relations among local subsequences of
amino acids.
The global conformation of a protein is referred to as its tertiary structure. The way in
which proteins adopt a particular folding pattern depends upon the intramolecular interactions that occur among the various amino acid residues, as well as upon the interaction of
the molecule with solvent (water). Two types of intramolecular interactions are often referred to in order to describe the secondary or tertiary structure of a protein. The first type
is a hydrogen bond, which results from the sharing of a hydrogen atom between residues.
ff-helices and fi -sheets can both be described in terms of regular and specific hydrogen bond
networks. Figure 3 illustrates a portion of a fi -sheet in which hydrogen bond interactions
link together parallel fi -strands. Additional stability to the 3D structure of a protein is
provided by disulfide bridges. This second type of interaction is a result of a chemical bond
occurring between two sulfur atoms carried by cysteine amino acid residues. These bonds
are energetically stronger than hydrogen bonds and contribute to stability under extreme
conditions (temperature, acidity, etc.).
Molecular biology is concerned with understanding the biological processes of macromolecules in terms of their chemical structure and physical properties. Crucial to achieving
this goal is the ability to determine how a protein folds into a 3D structure given its known
sequence of amino acids. Despite recent efforts to predict the 3D structure of a protein from
its sequence, the folding problem remains a fundamental challenge for modern science. Since
the 3D structure of a protein cannot as yet be predicted from sequence information alone,
the experimental techniques of X-ray crystallography and nuclear magnetic resonance currently provide the only realistic routes for structure determination. In the remainder of the
paper we focus on a computational approach for the analysis of protein images generated
from crystallographic data.
128

fiAnalysis of Three-Dimensional Protein Images

O
O
O

O

O

O

O

O

O

C

C

O

C

O
N

C

O

H

N

C

C
H

H

O
O
O

H

C

O

N

C

O
N

O

N

C

C

N
C

O

N

C

H

C
C

O

C

C

C

O

H

N
O
O
O

C

H

N

H

O
O
O

Figure 3: Hydrogen bonds (dotted lines) link three individual fi -strands (linear sequences
of amino acids in the main chain of the protein) to form a parallel fi -sheet.

129

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

3. Scene Analysis
Research in machine vision has long been concerned with the problems involved in automatic image interpretation. Marr (1982) defines computational vision as \the process of
discovering what is present in the world, and where it is". Similar to visual scene analysis, molecular scene analysis is concerned with the processes of reconstruction, classification
and understanding of complex images. This section presents the problem of molecular scene
analysis in the context of related research in machine vision and medical imaging.
Early vision systems generally include a set of processes that determine physical properties of 3D surfaces from 2D arrays. These input arrays contain pixel values that denote
properties such as light intensity. Considerable research has been carried out on extracting
3D information from one or more 2D images. A review of the application of stereo vision
to sets of 2D images can be found in (Faugeras, 1993). The principles of stereo vision
have also been applied to moving images (Zhang & Faugeras, 1992). Range data provides
explicit depth information about visible surfaces in the form of a 2D array (depth map).
Depending on the application, both surface or/and volume fitting techniques are applied
to these images. A more complete review of vision techniques can be found elsewhere (e.g.,
(Arman & Aggarwal, 1993; Besl & Jain, 1986; Jain & Flynn, 1993)).
Similar to the crystallography problem, medical imaging techniques require genuine
3D data: magnetic resonance imaging (MRI) provides detailed high-resolution information
about tissue density; emission computed tomography (ECT), which includes positron emission tomography (PET) and single photon emission computed tomography (SPECT), gives
noisy, low-resolution information about metabolic activity. X-ray computed tomography
(CT) and ultrasound also provide 3D density data. These methods can be used to obtain a
series of 2D images (slices) which, when properly aligned, provide a 3D grid. Because the
interslice spacing may be much larger than the spacing between grid points in each slice,
alignment of the slices followed by interpolation between the slices is one area of research.
The low-level segmentation of medical images typically uses 3D extensions of 2D techniques. Edge detection becomes surface detection, region growing defines volumes instead
of areas. Many applications typically do not require detailed, high-level models. Surface
information can be used to construct models for simulations, volumes and surfaces provide
structural measurements. Higher-level models are used in the construction of \templates"
for pattern matching. One interesting aspect of medical imaging is the availability of a priori
knowledge, either from a database of similar structures, or from images of the same region
in different modalities (e.g. MRI images of a brain can be used to guide segmentation of a
lower-resolution PET image). One modality may also provide information that is not clear
in another modality. There is considerable research on \registration" of images { aligning
or overlaying two 3D images to combine information. Segmentation and identification of
matching \landmarks" is important for such image representations.
Unlike input for the vision and medical imaging problems, the crystallographic experiment yields data that define a 3D function, which allows for the construction of a 3D array
of voxels of arbitrary size3 . An interpretation of the 3D atomic arrangement in a crystal structure is readily available for small molecules using the data generated from X-ray
3. Comparatively, machine vision techniques generally provide 2D image representations and range data
only provide surface information. Medical imaging techniques may result in a 3D grid, but the spacing

130

fiAnalysis of Three-Dimensional Protein Images

diffraction techniques. Given the magnitudes of the diffracted waves and prior knowledge
about the physical behavior of electron density distributions, probability theory can be applied to retrieve phase information. Once magnitudes and phases are known, the spatial
arrangement of atoms within the crystal can be obtained by a Fourier transform. The electron density function that is obtained, (x; y; z ), is a scalar field visualized as a 3D grid of
real values called the electron density map. High-density points in this image are associated
with the atoms in the small molecule.
The construction of an interpretable 3D image for a protein structure from diffraction
data is significantly more complex than for small molecules, primarily due to the nature of
the phase problem. It generally involves many iterations of calculation, map interpretation
and model building. It also relies extensively on input from an expert crystallographer.
We have previously proposed that this process could be enhanced through a strategy that
integrates research in crystallography and artificial intelligence and rephrases the problem
as a hierarchical and iterative scene analysis exercise (Fortier et al., 1993; Glasgow et al.,
1993). The goal of such an exercise is to reconstruct and interpret images of a protein
at progressively higher resolution. For an initial low-resolution map, where the protein
appears as a simple object outlined by its molecular envelope, the goal is to locate and
identify protein and solvent regions. At medium-resolution, the goal involves locating amino
acid residues along the main chain and identifying secondary structure motifs. At higher
resolution, the analysis would attend to the identification of residues and, possibly, the
location of individual atoms.
A primary step in any scene analysis (whether vision, medical or crystallographic data
are used) is to automatically partition an image representation into disjoint regions. Ideally,
each segmented region corresponds to a semantically meaningful component or object in the
scene. These parts can then be used as input to a high-level classification task. The processes
of segmentation and classification may be interwoven; domain knowledge, in the form of a
partial interpretation, is often useful for assessing and guiding further segmentation.
Several approaches to image segmentation and classification have been considered in the
vision literature. Of particular interest for the molecular domain is an approach described
by Besl and Jain (1986) , where the surface curvature and sign of a Gaussian is derived for
each point on the surface of a range image. Image segmentation is then achieved through
the identification of primitive critical points (peaks, pits, ridges, etc.). Haralick et al. (1983)
defined a similar set of topographic features for use in 2D image analysis, Wang and Pavlidis
(1993), and later Lee and Kim (1995), extended this work to extract features for character
recognition. Gauch and Pizer (1993) also identify ridge and valley bottoms in 2D images,
where a ridge is defined as a point where the intensity falls off sharply in two directions
and a valley bottom is a point where the intensity increases sharply in two directions. They
further examined the behavior of the ridges and valleys through scale space; the resulting
resolution hierarchies could be used to guide segmentation. Maintz et al. (1996) and Guziec
and Ayache (1992) use 3D differential operators through scale space to define ridges and
troughs. These provide landmarks which can be used to register images. Leonardis, Gupta
and Bajcsy (1993, 1995)) use an approach where surface fitting (using iterative regression)
and volume fitting (model recovery) are initiated independently; the local-to-global surface
along the third axis may be large, and, in such a case, it is necessary to align and interpolate over
multiple 2D slices.

131

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

fitting is used to guide multiple global-to-local volume fittings, and is used in the evaluation
of possible models.
As will be discussed in the next section, a topological approach is being used for the
segmentation and classification of molecular scenes. Similar to the method of Gauch and
Pizer, critical points are used to delineate a skeletal image of a protein and segment it into
meaningful parts. These critical points are considered in the analysis of the segmented
parts. This approach can also be compared to a skeletonization method, which has been
described by Hilditch (1969) and applied in protein crystallography by Greer (1974) . Unlike
Greer's algorithm, which \thins" an electron density map to form a skeleton that traces
the main and secondary chains of the molecule, our proposed representation preserves the
original volumetric shape information by retaining the curvatures of electron density at the
critical points. Furthermore, rather than thinning electron density to form a skeleton, our
approach reconstructs the backbone of a protein by connecting critical points into a 3D
graph structure.
Critical points in an image have also been considered in the medical domain. Higgins et
al. (1996) analyze coronary angiograms from CT data by thresholding to define \bright"
regions that correspond to the area around peak critical points. These seed regions are then
grown along ridges until there is a steep dropoff. Post-processing removes cavities and spurs.
The resulting volume is a tree-like structure, which is then skeletonized and further pruned
to provide axes. The axes are converted to sets of line segments with some minimum length.
This is similar to BONES (Jones, Zou, Cowan, & Kjeldgaard, 1991), a graphical method
which has been developed and applied to the interpretation of medium- to high-resolution
protein maps. This method incorporates a thinning algorithm and postprocessing analysis
for electron density maps. Also worth mentioning is a previously described methodology
for outlining the envelope of a protein molecule in its crystallographic environment (Wang,
1985).
A distinct advantage of molecular scene analysis, over many applications in machine
vision, is the regularity of chemical structures and the availability of previously determined
molecules in the Protein Data Bank (PDB) (Bernstein, Koetzle, Williams, & Jr., 1977). This
database of 3D structures forms the basis of a comprehensive knowledge base for template
building and pattern recognition in molecular scene analysis (Conklin, Fortier, & Glasgow,
1993b; Hunter & States, 1991; Unger, Harel, Wherland, & Sussman, 1989); although the
scenes we wish to analyze are novel, their substructures most likely have appeared in previously determined structures. Another significant difference between molecular and visual
scene analysis is that diffraction data resulting from protein experiments yield 3D images,
simplifying or eliminating many of the problems faced in low-level vision (e.g., occlusion,
shading). The complexity that does exist in the crystallographic domain relates to the
incompleteness of data due to the phase problem.

4. Segmentation and Interpretation of Protein Images
The use of artificial intelligence techniques to assist in crystal structure determination, particularly for the interpretation of electron density maps, was first envisioned by Feigenbaum,
Engelmore and Johnson (1977) and pursued in the Crysalis project (Terry, 1983). In conjunction with this earlier project, a topological approach to the representation and analysis
132

fiAnalysis of Three-Dimensional Protein Images

Figure 4: Depictions of electron density maps viewed at (a) 1 
A, (b) 3 
A, and (c) 5 
A
resolution
of protein electron density maps was implemented in a program called ORCRIT (Johnson,
1977). Recent studies suggest that this approach can also be applied to the segmentation
of medium-resolution protein images (Leherte, Baxter, Glasgow, & Fortier, 1994a; Leherte,
Fortier, Glasgow, & Allen, 1994b). In this section we describe and further support the
feasibility of a topological approach for the analysis of low and medium-resolution electron
density maps of proteins.
The information stored in an electron density map for a protein may be represented
and analyzed at various levels of detail (see Figure 4)4 . At high-resolution (Figure 4(a))
individual atoms are observable; at medium-resolution (Figure 4(b)) atoms are not observable, but it is possible to differentiate the backbone of the protein from its side chains and
secondary structure motifs may be discernerable. A clear segmentation between the protein
molecular envelope (region in which the atoms of the protein reside) and the surrounding
solvent region can still be seen at low-resolution (Figure 4(c)).
4. Resolution in the electron density images of proteins is often measured in terms of angstrom (
A) units,
where 1 
A=10,10 meters.

133

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Methods from both machine vision and crystallography were considered in the development of our computational approach to the analysis of protein structures. Among those
studied, a topological analysis provided the most natural way to catch the uctuations of
the density function in the molecular image. In this section we overview such a method
for mapping a 3D electron density map onto a graph that traces the backbone of the protein structure. We present results of applying the method for the segmentation of low and
medium-resolution maps of protein structures reconstructed using the Protein Databank of
Brookhaven. As well, we show how critical point graphs constructed for medium resolution
maps can be further analyzed in order to identify ff-helix and fi -sheet substructures.

4.1 Representation of Protein Structure

Crucial to a molecular scene analysis is a representation that will capture molecular shape
and structure information at varying levels of resolution; an important step in a molecular
scene analysis is the parsing of a protein, or protein fragments, into shape primitives so as
to allow for their rapid and accurate identification. Shape information can be extracted
from several depictive representations { for example, van der Waals surfaces, electrostatic
potentials or electron density distributions. Since molecular scene analysis is primarily
concerned with images reconstructed from crystallographic experiments, electron density
maps provide a natural and convenient choice for the input representation.
As mentioned earlier, an electron density map is depicted as a 3D array of real, nonnegative values corresponding to approximations of the electron density distribution at
points in the unit cell of a crystal. For the task of segmenting this map into meaningful
parts, we also consider the array in terms of a smooth and continuous function , which maps
an integer vector r = (x; y; z ) to a value corresponding to the electron density at location
r in the electron density map. Similar to related formalisms in vision5, the information
in an electron density map is uninterpreted and at too detailed a level to allow for rapid
computational analysis. Thus, it is essential to transform this array representation into a
simpler form that captures the relevant shape information and discards unnecessary and
distracting details. The desired representation should satisfy the three criteria put forward
by Marr and Nishihara concerning: 1) accessibility { the representation should be derivable
from the initial electron density map at reasonable computing costs; 2) scope and uniqueness
{ the representation should provide a unique description of all possible molecular shapes
at varying levels of resolution; and 3) stability and sensitivity { the representation should
capture the more general (less variant) properties of molecular shapes, along with their finer
distinctions.
Several models for the representation and segmentation of protein structures were considered. These included a generalized cylinder model (Binford, 1971), and a skeletonization
method (Greer, 1974; Hilditch, 1969). We choose a topological approach, which has been
previously applied in both chemistry and machine vision. In chemistry, the approach has
proven useful for characterizing the shape properties of the electron density distribution
through the location and attributes of its critical points (points where the gradient of the
electron density is equal to zero) (Johnson, 1977).
5. The level of representation of the electron density map is comparable to a 3D version of the primal sketch
in Marr and Nishihara's formalism (1978) .

134

fiAnalysis of Three-Dimensional Protein Images

In the following section, we describe the representation of a protein structure in terms
of a set of critical points obtained through a topological analysis.

4.2 Deriving Critical Point Graphs

In the proposed topological approach to protein image interpretation, a protein is segmented
into its meaningful parts through the location and identification of the points in the electron
density map where the gradients vanish (zero-crossings). At such points, local maxima and
minima are defined by computing second derivatives which adopt negative or positive values
respectively. The first derivatives of the electron density function  characterize the zerocrossings, and the second derivatives provide information on the zero-crossings; in particular,
they identify the type of critical points for the map. For each index value r = (x; y; z ) in
the electron density map, we define a function (r).
Candidate grid points (those that are a maximum or a minimum along three mutually
orthogonal axes) are chosen and the function (r) is evaluated in their vicinity by determining three polynomials (one along each of the axes) using a least square fitting. (r) is
the tensor product of these three polynomials. The location of a critical point is derived
using the first derivative of (r). The second derivatives are used to determine the nature
of the critical point. For each critical point, we construct a Hessian matrix:

@ 2 =@x2 @ 2 =@x@y @ 2 =@x@z
H(r) = @ 2 =@y@x @ 2 =@y2 @ 2=@y@z
@ 2 =@z@x @ 2 =@z@y @ 2 =@z2
This matrix is then put in a diagonal form in which three principal second derivatives are
computed for the index value r:

H'(r) =

@ 2 =@ (x0 )2
0
0

0

@ 2 =@ (y0 )2
0

0
0

@ 2 =@ (z0 )2

The three non-zero diagonal elements of array H'(r) { the eigenvalues { are used to determine the type of critical points of the electron density map. Four possible cases are
considered depending upon the number of negative eigenvalues, nE . When nE = 3, the
critical point r corresponds to a local maximum or peak; a point where nE = 2 is a saddle
point or pass. nE = 1 corresponds to a saddle point or pale, while nE =0 characterizes r as
a pit. Figure 5 depicts a 2D graphical projection of potential critical points.
High density peaks and passes are the only critical points currently being considered in
our study. Low density critical points are less significant since they are often indistinguishable from noise in experimental data.
The use of the critical point mapping as a method for analyzing protein electron density
maps was first proposed by Johnson (1997) for the analysis of medium to high-resolution protein electron density maps. Within the framework of the molecular scene analysis project,
the use of critical points is being extended for the analysis of medium and low-resolution
maps of proteins. The topological approach to the segmentation of proteins was initially
implemented by Johnson in the computer program ORCRIT (Johnson, 1977). By first locating and then connecting the critical points, this program generates a representation that
135

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Peak

Pass

Peak



Y
X

Figure 5: Graphical illustration of critical points in 2D (X and Y) plotted against density
function .
captures the skeleton and the volumetric features of a protein image. The occurrence probability of a connection between two critical points i and j is determined by following the
density gradient vector r(r). For each pair of critical points, the program calculates a
weight wij , which is inversely proportional to the occurrence probability of the connection.
The collection of critical points and their linkage is represented as a set of minimal spanning
trees (connected acyclic graphs of minimal weight)6 .

4.3 Results of Segmentation at Medium and Low Resolution

This section presents experimental studies that have been carried out on electron density
maps at 3 
A resolution. Computations were first performed on calculated maps reconstructed from available structural data in order to generate a procedure for the further
analysis of experimental maps. Three protein structures: Phospholipase A2 (1BP2), Ribonuclease T1 complex (1RNT) and Trypsin inhibitor (4PTI), retrieved from the PDB (Bernstein
et al., 1977), were considered. These structures are composed of 123, 104 and 53 amino acid
residues, respectively, and were chosen because of the quality of the data sets. The electron
density images for the proteins were constructed using the XTAL program package (Hall &
Stewart, 1990), and were then analyzed using a version of ORCRIT which was extended and
enhanced to construct and interpret critical point graphs for low- and medium-resolution
electron density maps.
Applying ORCRIT to electron density maps generated at medium resolution provides
for a detailed analysis of the protein structures (Leherte et al., 1994b). As illustrated in
Figure 6, the topological approach produces a skeleton of a protein backbone as a sequence
6. As will be discussed in Section 4, this part of the program is currently being modified to allow for cycles
in the graph.

136

fiAnalysis of Three-Dimensional Protein Images

of alternating peaks (dark circles) and passes (light circles). The results obtained from
the analysis of calculated electron density maps at 3 
A resolution led to the following
observations:

 A peak in the linear sequence is generally associated with a single residue of the
primary sequence for the protein.

 A pass in the sequence generally corresponds to a bond or chemical interaction that
links two amino acid residues (peaks).

Thus, the critical point graph can be decomposed into linear sequences of alternating
peaks and passes corresponding to the main chain or backbone of the protein. For larger
residues, side chains may also be observed in the graph as side branches consisting of a
peak/pass motif. These observations are featured in Figure 7, which illustrates a critical
point graph and an electron density contour for the unit cell of a protein crystal.
In practice, we found that the critical point graph included some arcs originating from
the presence of connections between critical points associated with non-adjacent residues.
This is illustrated in Figure 6 and in the bottom left corner of Figure 7; in the main chain of
both graphs there is a jump that occurred as a result of a disulfide bridge between nearby
residues. These bonds can often be identified, however, through further analysis of the
critical point graphs. For example, disulfide bridges are discerned from the representation
through the higher density values of their associated cysteine residues. To overcome the
problem of errors in the critical point graph due to ambiguous data we plan to generate
multiple possible models for a protein, corresponding to different hypothesized backbones
resulting from the critical point graph. Thus, several alternative hypotheses will be considered and used to refine the image in an iterative approach to scene analysis.
Experiments were also carried out at low (5 
A) resolution, where the following was
observed:

 Secondary structure motifs, such as ff-helices and fi -strands, correspond to linear
(or quasi-linear) sequences of critical points. In the case of helices, these sequences
trace the central axis of the structure (see Figure 8), whereas they tend to catch the
backbone itself for fi -strands. The average distance between observed critical points
and a model of the protein backbone was 1:68  0:59 
A.

 Other non-linear sequences of critical points were sometimes found to be representative
of irregular protein motifs such as loops.

 Highly connected, small graphs of critical points appear in other regions of the maps:
in the solvent region, at the disulfide bridges and between close protein segments.

Although the results of segmenting protein images using the topological approach has
proved promising, there is ongoing research being carried out to improve and enhance
ORCRIT. In particular, we are redeveloping the code for building the graph of critical points.
The new version of the code will incorporate more domain knowledge in order to find
multiple possible backbone traces. It will also incorporate a spline (rather than polynomial)
fitting function to interpolate the critical points for constructing the function (r).
137

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

side chain

(pass) (peak)

disulphide bridge

peptide bond

amino acid

Figure 6: Planar representation of a critical point sequence obtained from a topological
analysis of an electron density map at 3 
A resolution.

138

fiAnalysis of Three-Dimensional Protein Images

Figure 7: 3D contour and critical point graph for a unit cell of protein 4PT1 (58 residues)
constructed at 3 
A resolution. The critical point graph in this figure was generated
using the output of the ORCRIT program.

139

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Figure 8: Critical point graph of Cff chain (black) for an helix motif at 3 
A (white) and 5

A (gray) resolution.
Currently, we are investigating the relationships between critical points at varying resolutions. Figure 8 illustrates the superimposition of critical point representations of an
helix motif at low and medium resolution obtained using ORCRIT. As this figure shows, the
linear segment of critical points derived at 5 
A resolution approximates the more detailed
critical point graph of a helix derived at 3 
A. More careful analysis suggests that there
exists a hierarchy between the peaks and passes at 5 
A and those at 3 
A. This relationship
between critical points at medium and low-resolution is illustrated in Figure 9, where individual critical points at 5 
A resolution are associated with individual or multiple points at
medium-resolution.

5. Methods for Secondary Structure Identification

Once a critical point graph is constructed, it can be analyzed to classify substructures
in the protein. A statistical analysis of the conformation of critical point sequences in
terms of geometrical parameters of motifs consisting of four sequential peak critical points
(pi ; pi+1 ; pi+2 ; pi+3 ) suggests that the most useful parameters for the identification of ffhelices and fi -strands are the distance between peaks pi and pi+3 , and the individual and
planar angles among critical points. We describe how these criteria were used to formulate
rules for the identification of secondary structure motifs in a medium-resolution electron
density map of a protein.
In a previous paper (Leherte et al., 1994a), we described an approach to secondary
structure identification in which the geometrical constraints in a critical point subgraph
140

fiAnalysis of Three-Dimensional Protein Images

amino
acid 13

234*
147+
244*
106+
191*
122+
309*
74+
172*
38+
224*
76+
282*
77+
227*
132+
212*
52+

113*

4+

33+

24*
23+

71*

37*
34+
36*
38+
2+

48*
5 A Resolution

109*
98+
349*
316*
83+
259*
123+
283*
49+
216*
137+
210*
125+
235*
23+
167*
43+
278*

amino
acid 29

3 A Resolution

Figure 9: Relationship between critical points at 3 and 5 
A resolution for amino acids 13
to 29 in protein structure 1RNT. `+' and `*' denote peaks and passes in the main
chain. The numeric values correspond to the critical points location in an ordered
list (based on electron density) of all points. The correspondence between points
at different levels in the hierarchy is based on their interdistance (must be less
than 2 
A).

141

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

were treated in a boolean fashion, i.e., they were either satisfied or not depending upon
whether or not their values fell within predetermined ranges. The procedure described in
the current paper relies on probabilistic belief measures based on statistics derived from
the PDB. Following, we describe alternative approaches based on the comparison of critical
point graphs with idealized secondary structure motifs. The templates we used consisted
of local subsequences of critical points, each point denoting a residue in an idealized model
of a protein.

5.1 Estimating Probabilities and Combining Evidence
To construct our model templates, we first performed a statistical analysis of 63 nonhomologous protein structures retrieved from the PDB. A set of occurrence probability
distributions f (ssmjg) were estimated for given secondary structure motifs (ssm) and geometric constraints (g). We derived these values for the ff-helix, and fi -sheet and turn motifs
and for geometric constraints based on torsion and bond angles and on relative distance
between residues.
In building procedures for structure recognition and discrimination, two important issues must be faced: first, how does one compute the primitive marginal and conditional
probability estimates such as f (ssmjg); and, second, how does one combine the information from the several different pieces of geometric evidence for or against each class, as in
f (ssmjg1 ; g2 )? There are many tradeoffs to consider.
For the single-attribute probability estimations, f (ssmjg), one can use discrete categories and estimate probabilities from frequency counts. If only a few \bins" are employed
for, e.g., ranges of critical point inter-distance values, then achieving sucient sample sizes
for bin counts presents little diculty. As the number of bins grows and the \width" of
each bin correspondingly shrinks, the resulting histogram becomes a better and better approximator of an underlying continuous distribution, but here problems with small counts
lead to larger sampling error (variance). If one chooses to fit continuous distributions to
the data, the bias/variance dilemma manifests itself in the choice of distribution types and
the number of parameters for parameterized models.
In combining the individual terms representing secondary structure evidence, one must
address the issue of inter-attribute dependencies and the accuracy and eciency tradeoffs it
poses. Put most simply, how do we compute f (ssmjg1; g2) from f (ssmjg1) and f (ssmjg2)?
A pure Bayesian approach without underlying independence assumptions requires exponentially many terms, and we therefore seek heuristic shortcuts.
Two methods for determining confidence values for secondary structure assessment were
studied and applied to the problem of secondary structure identification: 1) a Bayesian, or
Minimum Message Length (MML) approach, similar to that previously used in protein
substructure classification in (Dowe, Allison, Dix, Hunter, Wallace, & Edgoose, 1996), and
2) an approach similar to that used in expert systems such as MYCIN (Shortliffe, 1976). We
should emphasize here that the primary goal of our described research is the construction of
effective structure recognition systems, rather than the comparison of alternative methods
of machine learning and classification per se.
142

fiAnalysis of Three-Dimensional Protein Images

5.2 A Bayesian/MML Approach

In adopting a Bayesian latent class analysis approach to the problem, we decided to treat the
estimation and combination issues together by fitting mixtures of continuous distributions
to the data for each class, under the conditional independence assumption commonly used
in mixture model approaches to classification and clustering (McLachlan & Basford, 1988).
In a latent class analysis approach to finding structure in a set of datapoints, one begins
with an underlying parameterized model. For example, one might posit that a set of points
represented by a 2D scatterplot was generated by a 2D Gaussian (normal) distribution,
with means 1 ; 2 and covariance matrix V12 . Or the data might be better explained by
a mixture, or weighted sum, of several Gaussian distributions, each with its own 2D mean
vector and covariance matrix. In this approach, one tries to find an optimal set of parameter
values for the representation of each datapoint x = (x1 ; x2 ). Optimality may be defined
in terms of maximum likelihood, Bayes optimality, or, as in our case, minimum message
length (MML)7 .
In the case at hand, we have 11 dimensions instead of 2, and not all of the dimensions
are best modeled by simple Gaussians. It is generally accepted that angular data should
be modeled by one of the circular distributions such as the von Mises distribution (Fisher,
1993).
Two independence assumptions, crucial to computational eciency and data eciency,
underlie this approach:
1. Within a given class, the attributes characterizing a segment are mutually independent.
2. The separate datapoints, each corresponding to a segment, are mutually independent.
Although neither of these assumptions is strictly true in this application, these assumptions are commonly made in such circumstances, and the methods based on them work
well in practice. Where dependence on these assumptions proves untenable, one can employ more elaborate models that incorporate explicit dependencies, such as Bayes Nets and
graphical models (Buntine, 1994).

5.3 A MYCIN-Like Approach

We determined that a method similar to the one used for the diagnosis system MYCIN (Rich
& Knight, 1991) was also effective for our application. Frequency distribution values provide
measures of belief and disbelief for secondary structure assignments based on individual
geometric constraints:

MB (ssm; g) = f (ssm; g)
MD(ssm; g) = f (not ssm; g)

(1)
(2)

where MB (ssm; g) is a measure of belief in the hypothesis that a given peak is associated
with a secondary structure ssm given the evidence g, whereas MD(ssm; g) measures the
7. However, we use the general term \Bayesian" informally for Bayesian, Minimum Description Length and
MML approaches to distinguish them jointly from other, especially \frequentist" approaches.

143

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

the extent to which evidence g supports the negation of hypothesis ssm for the peak. Figure
10 illustrates the computed probability distributions for each geometric constraint (bond
angle, distance and torsion angle) and each secondary structure motif (helix, strand).
Like the modified Bayesian mixture modeling approach described in the previous section,
the MYCIN methodology represents another heuristic approximation to a pure \naive" Bayes
approach. In this case, the initial primitive probability terms are simple frequency counts
and the rules for combining probabilities assume implicitly that different evidence sources
are independent. This can be shown to lead to nonsensical classifications in extreme cases,
though in practice the approach often works quite well.
When two or more pieces of evidence are considered, the confidence measures are computed using the following formulae:
MB (ssm; g1 ^ g2 ) = MB (ssm; g1 ) + MB (ssm; g2)(1 , MB (ssm; g1 ))
(3)
MD(ssm; g1 ^ g2 ) = MD(ssm; g1 ) + MD(ssm; g2 )(1 , MD(ssm; g1 ))
(4)
Given these measures, an overall certainty factor, CF , can be determined for each peak p
in the critical point graph as the difference between the belief and disbelief measures:
CF (ssm; g) = MB (ssm; g) , MD(ssm; g)
(5)
where g corresponds to the geometric constraints associated with peak p.
A result of the application of this method to the interpretation of an ideal critical point
graph is illustrated in Figure 11. This graph shows that broad bands of positive CF s are
indeed representative of regular secondary structure motifs such as ff-helices and fi -strands.
In practice, for each critical point, our approach constructs a CF value for each secondary
structure hypothesis. At the end of the procedure, the hypothesis with the highest CF
value is selected. The final results are thus a set of sequences of CF values characterized by
subsequences of various lengths with identical secondary structure selection.
When two or more pieces of evidence are considered, the confidence measures are computed using the following formulae:
MB (ssm; g1 ^ g2 ) = MB (ssm; g1 ) + MB (ssm; g2 )(1 , MB (ssm; g1 ))
(6)
MD(ssm; g1 ^ g2 ) = MD(ssm; g1 ) + MD(ssm; g2 )(1 , MD(ssm; g1 ))
(7)
Given these measures, an overall certainty factor, CF , can be determined for each peak p
in the critical point graph as the difference between the belief and disbelief measures:
CF (ssm; g) = MB (ssm; g) , MD(ssm; g)
(8)
where g corresponds to the geometric constraints associated with peak p. A result of the
application of this method to the interpretation of an ideal critical point graph is illustrated
in Figure 11. This graph shows that broad bands of positive CF s are indeed representative
of regular secondary structure motifs such as ff-helices and fi -strands.

5.4 Results

Following we demonstrate how the two methods of analysis described in the previous section
can be applied to the identification of secondary structure in critical point graphs. We
consider graphs constructed from both ideal and experimental electron density maps.
144

fiAnalysis of Three-Dimensional Protein Images
0.45

0.18
MB(helix,torsion angle)
MD(helix,torsion angle)

0.35
0.3
0.25
0.2
0.15
0.1
0.05

0.1
0.08
0.06
0.04

150

-150 -100 -50
0
50 100
Torsion angle (degrees)

0.8

150

0.4
MB(helix,distance 1-4)
MD(helix,distance 1-4)

MB(strand,distance 1-4)
MD(strand,distance 1-4)

0.35

Probability Distributions

0.7

Probability Distributions

0.12

0
-150 -100 -50
0
50 100
Torsion angle (degrees)

0.6
0.5
0.4
0.3
0.2
0.1

0.3
0.25
0.2
0.15
0.1
0.05

0

0
0

2

4
6
8
10 12
Distance 1-4 (Angstroms)

14

0

0.6

2

4
6
8
10 12
Distance 1-4 (Angstroms)

14

0.3
MB(helix,angle)
MD(helix,angle)

Probability Distributions

Probability Distributions

0.14

0.02

0

0.5

MB(strand,torsion angle)
MD(strand,torsion angle)

0.16

Probability Distributions

Probability Distributions

0.4

0.4
0.3
0.2
0.1
0

0.25

MB(strand,angle)
MD(strand,angle)

0.2
0.15
0.1
0.05
0

-150 -100 -50
0
50
Angle (degrees)

100

150

-150 -100 -50
0
50
Angle (degrees)

100

Figure 10: Probability distributions computed for measures of belief (MB) and disbelief
(MD) for a given secondary structure motif and geometric constraint.

145

150

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

80
helix
strand

Certainty Factor

60
40
20
0

3-10

strand

turn

strand

a-helix

-20
-40
-60
-80
3

6

16

23

27
28
35
Residue #

47

56

Figure 11: Certainty factors obtained for ff-helix and fi -strand hypotheses for an ideal critical point representation of protein 4PTI (58 residues) at medium-resolution.
The figure also denotes the correct interpretation for residues 16-23 (strand),
23-27 (turn), 28-35 (strand) and 47-56 (helix).

5.5 Application to Ideal Data
Two Bayesian/MML and one MYCIN-based analyses were applied to the secondary structure
identification of ideal critical point trees. The first Bayesian module (Bayes1 ) was trained
using 60 out of the 63 ideal protein structure representations that were previously used to
generate occurrence frequency distribution functions for torsion angles, distances and planar
angles (Figure 10). The second Bayesian module (Bayes2 ) was trained using 46 ideal critical
point trees and 18 critical point representations obtained from the ORCRIT analysis of 3 
A
resolution reconstructed electron density maps. Three ideal critical point representations
were kept for testing: Cytochrome C2 (2C2C { 112 residues) is characterized by helices
and turns only; Penicillopepsin (3APP { 323 residues) contains short helices (8 residues or
less), turns, and fi -strands up to 14 residues long; and the photosynthetic reaction centre
of Rhodobacter Sphaeroides (4RCR { 266 residues) is a rich ff-helix structure with regular
segments of up to 24 residues.
The statistical Bayesian modules allow the classification of critical points for which 11
geometrical attributes can be calculated: except for the first three and the last three points
of a critical point sequence, all points participate in four torsion angles, four distances
(pi to pi+3 ), and three planar angles. The Bayesian module can thus be applied to the
secondary structure recognition of segments which contain 7 peak critical points or more,
while the MYCIN-based module is applicable to 4-point (or longer) sequences. However, for
comparison purposes, only points for which all 11 geometrical attributes could be calculated
were considered for recognition. Results are presented in Table 1. This table reports
146

fiAnalysis of Three-Dimensional Protein Images

the number of segments8 which have been correctly or incorrectly identified by either the
Bayesian approaches or the MYCIN-based module. All modules were designed to classify
recognized secondary structure motifs among four different classes: `helix', `strand', `turn',
and `other'. Regarding the class `helix', a distinction between ff-helices and helices 310 was
made a posteriori to help in the interpretation of the results.
Two types of percentage values are given in Table 1. The first type, i.e., the percentage
of actual secondary structure information that was identified, was computed over the total
number of actual secondary structure motifs present in the three test protein structures: 25
ff-helices, 25 fi -strands, 10 310 helices, and 42 turns. Higher percentage values observed for
the MYCIN-based results versus the Bayesian results come from the fact that longer segments
are recognized as potential helices or strands. A better overlap with the actual secondary
structure motifs is thus more likely to occur using the MYCIN approach. This is illustrated by
the first two examples described in Figure 12. Selected secondary structure motifs of proteins
2C2C and 3APP are compared with the hypotheses generated by the MYCIN-based and Bayes
modules. It is observed that, in these two cases, the longer identifications provided using
MYCIN are closer to the actual secondary structure of the amino acid sequences.
The percentage of correctly identified points within the ideal critical point segments was
computed over the total number of assigned critical point segments reported in Table 1.
Regarding the class `helix', the longer segments discovered by the MYCIN-based module, as
well as the larger number of incorrectly recognized segments, lead to lower percentage values
for this particular method. This is shown in the third example displayed in Figure 12. The
MYCIN-based module associates a long ff-helix with this particular amino acid sequence of
protein 4RCR which deviates from ideality by five residues, while the Bayes modules provides
reasonable solutions.
It is worthwhile to not that even if all of the segments are correctly assigned, the
percentage of correctly identified peaks is not 100%. This is due to the fact that most of
the recognized segments (sequences of peaks) are shifted by one residue with respect to the
definition given in the PDB file.
From the results reported in Table 1, it is clear that the first Bayesian module allows a
finer differentiation between helices and turns (turns are four or five residue long segments
whose geometry may be similar to the helix geometry) than the MYCIN-based approach. The
MYCIN-based approach tends to assign a label `helix' to actual turns as shown in Example
(4) in Figure 12. On the other hand, 310 helices are correctly identified by the MYCINderived rules, but less often discerned using the first Bayesian approach (See Example (5)
in Figure 12). The MYCIN-based module actually has a strong tendency to exaggerate the
helical character of a segment that is distorted with respect to the ideal case. This raises
identification ambiguities for 27 (51-24) short segments. No wrong identification is made
using the first Bayesian approach, except for one fi -strand. This segment was also identified
as a possible strand using the MYCIN-based module, but the hypothesis was later rejected
by a post-processing stage which checks for parallelism with other discovered fi -strands.
8. In this table a segment denotes a sequence (length  2) of adjacent peak critical points which belong to
the same secondary structure class (helix, fi -strand, turn). When comparing results, it should be noted
that the PDB data set is, itself, not strictly consistent since varying secondary structure definitions and
assignment methods are used to assess the structure of proteins.

147

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

MYCIN

Bayes1 Bayes2

ff-Helices (actual no = 25)
No of (correctly) assigned segments

(24) 51 (24) 24 (21) 22

% of correctly recognized actual motifs

98

87

88

% of correctly identified peaks

63

83

82

fi -Strands (actual no = 25)
No of (correctly) assigned segments

(24) 24 (20) 21 (24) 30

% of correctly recognized actual motifs

89

71

84

% of correctly identified peaks

82

82

81

(10) 10

(7) 7

(7) 7

% of correctly recognized actual motifs

97

56

47

% of correctly identified peaks

70

70

61

310 Helices (actual no = 10)
No of (correctly) assigned segments

Turns (actual no = 42)
No of (correctly) assigned segments

(4) 4

(12) 12 (21) 28

% of correctly recognized actual motifs

7

34

41

% of correctly identified peaks

46

77

59

Table 1: Results from the application of two Bayesian approaches and a MYCIN-based
method to the recognition of secondary structure motifs in ideal protein backbones constructed from Cff CO centres of mass. Note that the numbers in brackets
denote the number of correctly assigned, versus total number of assigned, segments
(sequences of peaks).
148

fiAnalysis of Three-Dimensional Protein Images

The application of the second Bayesian approach trained with more realistic critical
point representations generated a larger number of identified fi -strands and turns. This
however went with a number of incorrect identifications which are, in the case of fi -strands,
all associated with very short segments (2 or 3 points). In the case of turns, the percentage
of correctly identified critical points is lower (59% with respect to 77%) due to one particular
motif containing seven points.
The analysis of ideal critical point trees allows to conclude that the second Bayesian
module is more accurate in detecting fi -strand and turn structures (there is an increased
number of recognized motifs); but the use of noisy data in the training stage leads to a
less acute ability of the module to distinguish short helix-like motifs (there is an increased
number of incorrectly identified motifs).

5.6 Application to Experimental Data
Above we presented results obtained in applying methods for secondary structure identification to critical point graphs constructed from ideal electron density maps. Following,
we describe an application of our methods to the recognition of motifs in a critical point
representation constructed by applying ORCRIT to an electron density map generated from
experimental data. We also show how our structure recognition approaches can be improved
through a postprocessing analysis of the representation. The experiment was carried out
using a 3 
A resolution experimental map of Penicillopepsin, a protein composed of 323
amino acid residues (Hsu, Delbare, James, & Hofmann, 1977; James & Sielecki, 1983).
Neglecting the passes located between the peaks, geometrical parameters were computed
for short fragments composed of seven adjacent peaks in the main branch of the graph for
the protein. Before achieving this geometrical analysis, some preprocessing work was done
in order to fit the critical point graphs to an ideal model as described above. Distances were
computed for sets of adjacent peaks, and peaks separated by a distance smaller than 1.95 
A
were merged into a single point situated at their center of mass. The critical point linkage
was then checked: if two adjacent peaks were separated by a distance  5 
A then the peaks
were assumed to be connected. Considering connected sequences of three peaks at a time,
if the distance between the first and third peak was smaller than 4 
A, then the middle peak
was not considered to be part of the backbone of the protein (i.e., the middle peak probably
denotes a side chain). Finally, all resulting sequences of peaks (which are thus likely to be
representative of the protein backbone) were submitted to our three secondary structure
analysis methods.
Initially poor results observed from the MYCIN-like method motivated the development
of a post-processing procedure which was imposed to eliminate all helical segments with
negative torsion angle values and all isolated fi -strand segments, i.e., extended segments
that are not parallel to other similar motifs. This postprocessing step analyses the global
properties of the structure, while the measures of belief/disbelief focus only on the local
geometric properties of a motif. Postprocessing drastically reduces the number of incorrectly
recognized motifs and consequently increases the quality of the recognition procedure (Rost,
Casadia, & Farisellis, 1996).
Table 2 presents a comparison of results of applying the three methods for identifying
secondary structure motifs to the experimental electron density map of penicillopepsin.
149

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

(1) 2c2c
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

4
H
H
H
H

5
H
H
H
-

6
H
H
H
H

7
H
H
H
H

8
H
H
H
H

9
H
H
T
H

10
H
H
T
H

11
310
H
H
H

12
310
H
H
H

13
310
H
H
H

14
310
H
H
H

15
H
T
H

16
H
H

17
H
-

4

17

(2) 3app
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

203
S
S
T
S

204
S
S
-

205
S
S
S
-

206
S
S
-

207
S
S
-

208
S
S
-

209
S
S
S
S

210
S
S
S
S

211
S
S
S
S

212
S
S
S
S

(3) 4rcr
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

149
H
T
T

150
H
S
-

151
H
-

152
H
H
H

153
H
T
T

154
H
H
H
H

155
H
H
H
H

156
H
H
H
H

157
H
H
H
H

158
H
H
H
H

203

212

159
H
H
H
H

160
H
H
H
H

31
-

(5) 3app
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

126
-

127
310
H
H
-

128
310
H
H
-

(6) 3app
cp no.
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

71
139
H
-

199
140
H
H
T
H

1370
141
H
H
S
H

32
T
H
T
T

33
T
H
T
T

34
T
H
T
T

35
T
H
T
T

129
310
H
-

506
142
H
H
H
H

36
T
H
T
T

37
T
H
T

130
H
-

131
-

75
143
H
H
-

38
T
T
-

162
H
H
H
H

163
H
H
H

163

149

39

31

(4) 2c2c
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

161
H
H
H
H

39
T
T

131
126

388
144
H
H
T
T

144
139

129

(7) 3app
cp no.
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

188
129
H
H
T

482
H
-

205
135
H
H

235
134
H
T

905
133
H
H
H

320
132
H
T
T

756
131
H
T
-

581
132
H
T

122
H
-

422
H
H
-

1431
103
H
-

42
102
H
H
H

630
H
H

904
85
H
-

825
86
H
H

131
135
102
103

86
85

Figure 12: Selected amino acid secondary structure motifs and their identifications (`cp',
`aa', and `ss' stand for `critical point', `amino acid', and `secondary structure',
respectively. `H', `T', `S', and `-' denote the secondary structure classes: `helix',
`turn', `sheet', and `other'.)
150

fiAnalysis of Three-Dimensional Protein Images

MYCIN

Bayes1 Bayes2

ff-Helices (actual no = 3)
No of (correctly) assigned segments

(3) 7

(0) 0

(2) 3

% of correctly recognized actual motifs

91

9

45

% of correctly identified peaks

26

-

57

fi -Strands (actual no = 15)
No of (correctly) assigned segments

(12) 12 (12) 12

(9) 9

% of correctly recognized actual motifs

70

41

30

% of correctly identified peaks

73

91

96

(1) 1

(0) 0

(0)0

% of correctly recognized actual motifs

50

17

0

% of correctly identified peaks

75

-

-

(0) 0

(1) 3

(1) 2

% of correctly recognized actual motifs

0

33

27

% of correctly identified peaks

-

100

43

310 Helices (actual no = 2)
No of (correctly) assigned segments

Turns (actual no = 1)
No of (correctly) assigned segments

Table 2: Results from the application of two Bayesian approaches and a MYCIN-based
method to the recognition of secondary structure motifs in minimal spanning trees
constructed from a critical point analysis of an experimental electron density map
of penicillopepsin at 3 
A resolution. Note that the numbers in brackets denote
the number of correctly assigned, versus totally assigned, segments (sequences of
peaks).
151

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

According to Table 2, the MYCIN-based approach appears to have greater success in
recognizing helical motifs in experimental maps. Example (6) in Figure 12 depicts one
of the three helix motifs that was correctly recognized using the MYCIN-based approach.
However, this approach also misidentifies several motifs as helices. Among the four incorrectly identified helices, two four-point segments are actual turns, one four-point segment
is characterized by negative torsion angles, and a 15-point sequence of critical points is a
succession of three jumps (a jump is a connection occurring between non-adjacent amino
acid residues) (See Example (7) in Figure 12). The Bayes modules incorrectly identify a
turn in this same region of the electron density map. Jumps are problematic and may
seriously hinder the recognition rate, especially in experimental maps blurred by noise and
errors.
Table 2 illustrates that the consideration of noisier data in the training set (module
Bayes2 ) leads to an improvement in the number of identified ff-helices with respect to the
first Bayesian module (Example (6) in Figure 12). However, this also leads to a number of
incorrectly identified segments. One segment of length two is wrongly identified as helix. It
actually corresponds to a jump between non-adjacent amino acid residues; this jump also
generates an interpretation error with the MYCIN-based algorithm. The poor accuracy in
turn recognition (43 %) is due to this wrongly identified segment.

6. Related Research
The interpretation of protein images has been greatly facilitated in recent years by the
advent of powerful graphics stations coupled with the implementation of highly ecient
computer programs, most notably FRODO (Jones, 1992) and O (Jones et al., 1991). Although
these programs were designed specifically for the visual analysis of electron density maps
of proteins, they still require a significant amount of expert intervention and interpretation
and require considerable time investment. Unlike these systems ORCRIT was designed as a
more automated approach to protein model building and interpretation.
The research presented in this paper is a component of an ongoing research project in
the area of molecular scene analysis (Fortier et al., 1993; Glasgow et al., 1993). The primary
objective of this research is the implementation and application of computational methods
for the classification and understanding of complex molecular images. Towards this goal,
we have proposed a knowledge representation framework for integrating existing sources of
protein knowledge (Glasgow, Fortier, Conklin, Allen, & Leherte, 1995). Representations
for reasoning about the visual and spatial characteristics of a molecular scene are captured
in this framework using techniques from computational imagery (Glasgow, 1993; Glasgow
& Papadias, 1992). This paper extends previous publications in molecular scene analysis
by placing the research in an artificial intelligence framework and relating it to work in
machine vision. As well, it focuses on the use of uncertain reasoning for secondary structure
interpretation in the critical point representation and provides further experimental results
supporting our approaches to protein image interpretation.
Two kinds of image improvement procedures are being considered in conjunction with
the information stored in a critical point representation. The first one consists of improving phase information at a given resolution. This is a necessary, but dicult, step in a
protein structure determination carried out from experimental data. Structural informa152

fiAnalysis of Three-Dimensional Protein Images

tion retrieved from a topological analysis might be injected into a so-called direct methods
procedure, which has previously been successfully applied to the structure determination of
small molecules at high resolution (Hauptman & Karle, 1953), and more recently to macromolecules as well. However, these methods are presently not applicable to protein images at
low- and medium-resolution data, and time-consuming experimental methods are generally
used for phase recovery in protein structure elucidation.
The second set of procedures for protein image enhancement involves the construction
and interpretation of increasingly higher-resolution maps. This is presently carried out
visually by crystallographers who have access to a well-phased medium- or high-resolution
map. The highest density regions are fitted with fragments retrieved from a database of
chemical templates, eventually allowing for the determination of the protein's 3D structure
(Jones et al., 1991). These two protein image reconstruction procedures are interrelated:
improved phases lead to a more reliable map in which further motif identification can take
place. Under such considerations, secondary structure motifs detected in a low-resolution
map are regions of interest to generate medium-resolution information, which would further
give access to the the amino acid residue locations.
These procedures give rise to an iterative approach to molecular scene analysis. In
an iterative refinement process, if some portion of the image can be interpreted then this
information is applied (via an inverse Fourier transform) to adjust the current phases. The
modified phases are then used to generate a new image. This approach to scene analysis thus
proceeds from an initial coarse (low-resolution) image through progressively more detailed
(higher-resolution) images in which further substructures are identifiable9.
What this implies is that at any particular resolution, it is not necessary that our analysis
identify all substructures. The recognition of any parts of the scene can be used to improve
phases, giving rise to an overall improvement to the image. The new image can then be
further analyzed leading to additional interpretations. This process is iteratively applied
(within a heuristic search strategy) until the protein structure is fully determined.
The critical point representation described in this paper is just one component of the
knowledge representation scheme for computational imagery. A second component of the
scheme involves a spatial logic, which has been used to represent and reason with the
concepts and qualitative spatial features associated with a protein molecule (Conklin et al.,
1993b; Conklin, Fortier, Glasgow, & Allen, 1996). Associated with the spatial representation
is a knowledge discovery technique, called IMEM (Conklin & Glasgow, 1992), based on
a theory of conceptual clustering. This system has been used to discover recurrent 3D
structural motifs in molecular databases (Conklin, Fortier, & Glasgow, 1993a; Conklin
et al., 1996). We anticipate that this and other machine learning/discovery techniques
(e.g., (Hunter, 1992; Lapedes, Steeg, & Farber, 1995; Unger et al., 1989)) could be applied
to aid in a top-down analysis of novel molecular scenes in order to anticipate and classify
structural motifs. This would be complementary to the bottom-up scene analysis provided
by the topological approach described in this paper.
Molecular scene analyses can further benefit from research in protein structure prediction. In particular, we are currently investigating formulations derived for the inverse folding
problem (Bowie, Luethy, & Eisenberg, 1991). Given an amino acid sequence and a set of
9. The resolution of the image depends both on the number of experimental reections available as well as
on the amount of phase information.

153

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

core segments (pieces of secondary structure forming the tightly packed internal protein
core), this approach to prediction evaluates each possible alignment (threading) of a known
primary sequence of amino acids onto possible core templates. The problem of identifying
individual residues in a critical point map at medium to high-resolution can be addressed in
a similar manner, i.e., by attempting to thread a sequence onto a protein structure derived
from our topological analysis. This problem is significantly simpler than protein structure
prediction since it involves threading a sequence onto its own experimentally determined
structure, rather than onto templates retrieved from a library of possible models. In the
threading approach proposed by Lathrop and Smith (1994), a scoring function is used to
derive the statistical preference of a residue for a given environment. Modifications to the
current scoring function, to incorporate properties available in the electron density map and
critical point graph representations, are being implemented in order to customize this approach to the information available from our topological analysis (Baxter, Steeg, Lathrop,
Glasgow, & Fortier, 1996).

7. Conclusions
It was reported in this paper that a topological approach can effectively be applied to the
segmentation of protein images into their meaningful parts at low- and medium-resolution.
Furthermore, it was shown that secondary structure motifs could be identified in mediumresolution images through a geometric analysis of the image representation; the application
of geometric rules and probabilities yields a measure of confidence that a given peak is a
component of a known secondary structure motif.
Three secondary structure identification modules were applied to the interpretation of
ideal and experimental critical point graphs. Two probabilistic Bayesian approaches and
a MYCIN-based method all revealed that geometric components such as torsion angles,
distances and planar angles are useful in that they differentiate between helices, strands,
and turns.
Both the Bayesian and MYCIN-derived approaches were relatively successful in assigning
secondary structure identifications to sequences of critical points that are geometrically well
resolved. In the case of noisy experimental data, their accuracy decreased. We anticipate
that the accuracy could be further improved through the use of larger training sets and
training for 3-10 helix and other subclasses. However, we do not expect to achieve a full
secondary structure recognition for a protein { rather we expect to interpret good (less
noisy) portions of an electron density map and use this information to iteratively improve
our image in order to carry out further analyses.
The protein structures used to compose the training and test sets all contain backbone
information only. These structures are free of heteroatoms and/or small solvent molecules.
The prior knowledge of the chemical composition of a crystallographic cell would certainly
help in anticipating problems such as connections between non-adjacent residues through
high density peaks. Additional experimental data would permit us to extend the scope of
the three approaches described in the present paper.
Modern crystallographic studies remain at the forefront of current efforts to characterize and understand molecular recognition processes. A long-term goal of our research in
molecular scene analysis is to assist these studies through a computational methodology for
154

fiAnalysis of Three-Dimensional Protein Images

aiding expert crystallographers in the complex imagery processes required to fully interpret
the 3D structure of a protein. The topological approach presented here is an important
component of this methodology. Further research is required, however, to extend it for the
analysis of multi-resolution maps, and to incorporate more domain knowledge into these
analyses.

Acknowledgements
The authors wish to thank Carroll Johnson for providing the ORCRIT program and for
his ongoing collaboration with the project, and Marie Fraser for providing access to the
experimental electron density map for penicillopepsin. Financial support for this research
was provided by the Natural Science and Engineering Research Council (NSERC) of Canada
and the Belgian National Council for Scientific Research (FNRS). LL also thanks the FNRS
for her \Charge de Recherches" position.

References
Arman, F., & Aggarwal, J. (1993). Model-based object recognition in dense-range images
- a review. ACM Computing Survery, 25 (1), 5{43.
Baxter, K., Steeg, E., Lathrop, R., Glasgow, J., & Fortier, S. (1996). From electron density
and sequence to structure: Integrating protein image analysis and threading for structure determination. In Proceedings of the 4th International Conference on Intelligent
Systems for Molecular Biology, pp. 25{33. AAAI/MIT Press, Menlo Park, California.
Bernstein, F., Koetzle, T., Williams, J., Meryer, E., Brice, M., Rodgers, J., Kennard, O.,
Shimanouchi, T., & Tasumi, M. (1977). The Protein Data Bank: A computer{based
archival file for macromolecular structures. Journal of Molecular Biology, 112, 535{
542.
Besl, P., & Jain, R. (1986). Invariant surface characteristics for 3D object recognition in
range images. CVGIP, 33, 33{80.
Binford, T. (1971). Visual perception by a computer. In Proceedings of IEEE Conference
on Systems and Control Miami, Florida.
Bowie, J., Luethy, R., & Eisenberg, D. (1991). A method to identify protein sequences that
fold into a known three-dimensional structure. Science, 253, 164{170.
Buntine, W. (1994). Operations for learning with graphical models. Journal of Artificial
Intelligence Research, 2, 159{225.
Conklin, D., Fortier, S., & Glasgow, J. (1993a). Knowledge discovery in molecular databases.
IEEE Transactions on Knowledge and Data Engineering, 985{987. Special Issue on
Learning and Discovery in Knowledge-Based Databases.
155

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Conklin, D., Fortier, S., & Glasgow, J. (1993b). Representation for discovery of protein
motifs. In Hunter, L., Searls, D., & Shavlik, J. (Eds.), Proceedings of the First International Conference on Intelligent Systems for Molecular Biology. AAAI/MIT Press,
Menlo Park, California.
Conklin, D., Fortier, S., Glasgow, J., & Allen, F. (1996). Conformational analysis from
crystallographic data using conceptual clustering. Acta Crystallographica, B52, 535{
549.
Conklin, D., & Glasgow, J. (1992). Spatial analogy and subsumption. In Sleeman, &
Edwards (Eds.), Machine Learning: Proceedings of the Ninth International Conference
ML(92), pp. 111{116. Morgan Kaufmann.
Dowe, D., Allison, L., Dix, T., Hunter, L., Wallace, C. S., & Edgoose, T. (1996). Circular clustering of protein dihedral angles by minimum message length. In Pacific
Symposium on Biocomputing '96, pp. 242{255.
Faugeras, O. (1993). Three-dimensional computer vision: a geometric viewpoint. MIT Press.
Feigenbaum, E., Engelmore, R., & Johnson, C. (1977). A correlation between crystallographic computing and artificial intelligence research. Acta Crystallographica, A33,
13{18.
Fisher, N. (1993). Statistical Analysis of Circular Data. Cambridge University Press, Melbourne, Australia.
Fortier, S., Castleden, I., Glasgow, J., Conklin, D., Walmsley, C., Leherte, L. & Allen, F.
(1993). Molecular scene analysis: The integration of direct methods and artificial
intelligence strategies for solving protein crystal structures. Acta Crystallographica,
D49, 168{178.
Gauch, J., & Pizer, S. (1993). Multiresolution analysis of ridges and valleys in grey-scale
images. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI15 (6), 635{646.
Glasgow, J., Fortier, S., Conklin, D., Allen, F., & Leherte, L. (1995). Knowledge representation tools for molecular scene analysis. In Proceedings of the Hawaii International
Conference on Systems Sciences, Biotechnology Computing Track.
Glasgow, J. (1993). The imagery debate revisited: A computational perspective. Computational Intelligence, 9 (4), 309{333. Taking issue paper.
Glasgow, J., Fortier, S., & Allen, F. (1993). Molecular scene analysis: crystal structure determination through imagery. In Hunter, L. (Ed.), Artificial Intelligence and Molecular
Biology, pp. 433{458. AAAI Press, Menlo Park, California.
Glasgow, J., & Papadias, D. (1992). Computational imagery. Cognitive Science, 16 (3),
355{394.
156

fiAnalysis of Three-Dimensional Protein Images

Greer, J. (1974). Three-dimensional pattern recognition: An approach to automated interpretation of electron density maps of proteins. Journal of Molecular Biology, 82,
279{301.
Gupta, A., & Bajcsy, R. (1993). Volumetric segmentation of range images of 3d objects
using superquadric models.. CVGIP: Image Understanding, 58 (3), 302{326.
Guziec, A., & Ayache, N. (1992). Smoothing and matching of 3-d space curves. Visualization
in Biomedical Computing, Proc. SPIE, 1808, 259{273.
Hall, S., & Stewart, J. (Eds.). (1990). XTAL 3.0 User's Manual. Universities of Western
Australia and Maryland.
Haralick, R., Watson, L., & Laffey, T. (1983). The topographic primal sketch. International
Journal of Robotics Research, 2, 50{72.
Hauptman, H., & Karle, J. (1953). Solution of the Phase Problem, 1. The Centrosymmetric
Crystal, ACA Monograph No. 3. Wilmington:Polycrystal Book Service.
Higgins, W., Spyra, W., Karwoski, R., & Ritman, E. (1996). System for analyzing highresolution three-dimensional coronary angiograms. IEEE Transactions on Medical
Imaging, 15 (3), 377{385.
Hilditch, C. J. (1969). Linear skeletons from square cupboards. Machine Intelligence, 4,
403{420.
Hsu, I.-N., Delbare, L., James, M., & Hofmann, T. (1977). Penicillopepsin from penicillium
janthinellum. crystal structure at 2.8 a and sequence homology with porcine pepsin.
Nature, 266, 140{145.
Hunter, L. (1992). Artificial intelligence and molecular biology. In Proceedings of the
Tenth National Conference on Artificial Intelligence, pp. 866{868. AAAI, Menlo Park,
California.
Hunter, L., & States, D. (1991). Applying Bayesian classification to protein structure. In
Proceedings of the Seventh IEEE Conference on Artificial Intelligence Applications
Miami, Florida.
Jain, A., & Flynn, P. (Eds.). (1993). Advances in Three Dimensional Object Recognition
Systems, volume 1. Elsevier.
James, M., & Sielecki, A. (1983). Structure and refinement of penicillopepsin at 1.8 a
resolution. Journal of Molecular Biology, 163, 299{361.
Johnson, C. (1977). ORCRIT. The Oak Ridge critical point network program. Tech. rep.,
Chemistry Division, Oak Ridge National Laboratory, USA.
Jones, T. (1992). FRODO. A graphics fitting program for macromolecules. In Sayre, D.
(Ed.), Crystallographic Computing. Clarendon Press, Oxford.
157

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Jones, T., Zou, J., Cowan, S., & Kjeldgaard, M. (1991). Improved methods for building
protein models in electron-density maps and the location of errors in those models.
Acta Crystallographica, A47, 110{119.
Lapedes, A., Steeg, E., & Farber, R. (1995). Use of adaptive networks to evolve highly
predictable protein secondary-structure classes. Machine Learning, 21, 103{124.
Lathrop, R., & Smith, T. (1994). A branch and bound algorithm for optimal protein threading with pairwise (contact potential) interaction preferences. In L., H., & B., S. (Eds.),
Proc. 27th Hawaii Intl. Conf. on System Sciences, pp. 365{374. IEEE Computer Society Press, Los Alamitos, California.
Lee, S., & Kim, Y. (1995). Direct extraction of topographic features for gray scale character
recognition. IEEE Trans. Patt. Anal. Mach. Intell., PAMI-17 (7), 724{729.
Leherte, L., Baxter, K., Glasgow, J., & Fortier, S. (1994a). A computational approach to the
topological analysis of protein structures. In Altman, R., Brutlag, D., P.Karp, Lathrop, R., & Searls, D. (Eds.), Proceedings of the Second International Conference on
Intelligent Systems for Molecular Biology. MIT/AAAI Press, Menlo Park, California.
Leherte, L., Fortier, S., Glasgow, J., & Allen, F. (1994b). Molecular scene analysis: A
topological approach to the automated interpretation of protein electron density maps.
Acta Crystallographica D, D50, 155{166.
Leonardis, A., Gupta, A., & Bajcsy, R. (1995). Segmentation of range images as the search
for geometric parametric models. International Journal of Computer Vision, 14, 253{
277.
Maintz, J., van den Elsen, P., & Viergever, M. (1996). Evaluation of ridge seeking operators
for multimodality medical image matching. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 18 (4), 353{365.
Marr, D. (1982). Vision. W.H. Freeman and Company: San Francisco.
Marr, D., & Nishihara, H. (1978). Representation and recognition of the spatial organisation
of three-dimensional shapes. Proceedings of the Royal Society of London, B200, 269{
294.
McLachlan, G., & Basford, K. (1988). Mixture Models. Inference and Applications to Clustering. Marcel Dekker, Inc.
Rich, E., & Knight, K. (1991). Artificial Intelligence. McGraw-Hill, Inc. Second Edition.
Rost, B., Casadia, R., & Farisellis, P. (1996). Refining neural network predictions for helical
transmembrane proteins by dynamic programing. In Fourth International Conference
on Intelligent Systems for Molecular Biology (ISMB '96), pp. 192{200. AAAI Press,
Menlo Park, California.
Shortliffe, E. (1976). Computer-Based Medical Consultations: MYCIN. Elsevier, New York.
158

fiAnalysis of Three-Dimensional Protein Images

Terry, A. (1983). The Crysalis Project: Hierarchical Control of Production Systems. Ph.D.
thesis, Stanford Heuristic Programming Project, Stanford University, California, USA.
Unger, R., Harel, D., Wherland, S., & Sussman, J. (1989). A 3D building blocks approach
to analyzing and predicting structure of proteins. Proteins, 5, 355{373.
Wang, B. (1985). Resolution of phase ambiguity in macromolecular crystallography. In
Wyckoff, H., Hirs, C., & Timasheff, S. (Eds.), Diffraction Methods for Biological
Macromolecules. Academic Press, New York.
Wang, L., & Pavlidis, T. (1993). Direct gray scale extraction of features for character
recognition. IEEE Trans. Patt. Anal. Mach. Intell., PAMI-15 (10), 1053{1067.
Zhang, Z., & Faugeras, O. (1992). 3D Dynamic Scene Analysis. Springer-Verlag.

159

fiJournal of Artificial Intelligence Research 7 (1997) 199-230

Submitted 5/97; published 11/97

A Model Approximation Scheme for Planning in Partially
Observable Stochastic Domains
Nevin L. Zhang
Wenju Liu

Department of Computer Science
Hong Kong University of Science and Technology
Hong Kong, China

lzhang@cs.ust.hk
wliu@cs.ust.hk

Abstract
Partially observable Markov decision processes (POMDPs) are a natural model for
planning problems where effects of actions are nondeterministic and the state of the world
is not completely observable. It is dicult to solve POMDPs exactly. This paper proposes a new approximation scheme. The basic idea is to transform a POMDP into another
one where additional information is provided by an oracle. The oracle informs the planning agent that the current state of the world is in a certain region. The transformed
POMDP is consequently said to be region observable. It is easier to solve than the original POMDP. We propose to solve the transformed POMDP and use its optimal policy to
construct an approximate policy for the original POMDP. By controlling the amount of additional information that the oracle provides, it is possible to find a proper tradeoff between
computational time and approximation quality. In terms of algorithmic contributions, we
study in details how to exploit region observability in solving the transformed POMDP.
To facilitate the study, we also propose a new exact algorithm for general POMDPs. The
algorithm is conceptually simple and yet is significantly more ecient than all previous
exact algorithms.

1. Introduction
In a completely observable and deterministic world, to plan is to find a sequence of actions
that will lead an agent to achieve a goal. In real-world applications, the world is rarely completely observable and effects of actions are almost always nondeterministic. For this reason,
a growing number of researchers concern themselves with planning in partially observable
stochastic domains (e.g., Dean & Wellman, 1991; Cassandra et al., 1994; Parr & Russell,
1995; Boutilier & Poole, 1996). Partially observable Markov decision processes (POMDPs)
can be used as a model for planning in such domains. In this model, nondeterminism in
effects of actions is encoded by transition probabilities, partial observability of the world
by observation probabilities, and goals and criteria for good plans by reward functions (see
Section 2 for details).
POMDPs are classified into finite horizon POMDPs and infinite horizon POMDPs depending on the number of time points considered. Infinite horizon POMDPs are usually
used for planning because one typically does not know beforehand the number of steps
it takes to achieve a goal. This paper is concerned with how to solve an infinite horizon
POMDP.
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiZhang & Liu

1.1 Diculties in Solving POMDPs
When the world is fully observable, a POMDP reduces to a Markov decision process (MDP).
MDPs have been studied extensively in the dynamic-programming literature (e.g., Puterman, 1990; Bertsekas, 1987, White, 1993). Recent works have concentrated on how to deal
with large state spaces (Dean et al., 1993; Boutilier et al., 1995; Dean & Lin, 1995).
We are concerned with the partially observable case. This case is considerably more
dicult than the fully observable case for two related reasons. First, when the agent knows
exactly in which state the world currently is, information from the past (past observations
and actions) is irrelevant to the current decision. This is the Markov property. On the
other hand, when the agent does not fully observe the state of the world, past information
becomes relevant because it can help the agent to better estimate the current state of the
world. The problem is that the number of possible states of past information increases
exponentially with time.
Second, in MDPs the effects of an action are fully observed at the next time point. In
POMDPs, on the other hand, the effects of an action are not fully observed at the next
time point. Hence one cannot clearly tell the effects of the current action from those of the
agent's future behaviors. To properly evaluate the effects of an action, one needs to look
into the future and consider the combination of the action with each of the agent's possible
behaviors in a, possibly large, number of future steps. The problem is that the number of
ways the agent can behave is exponential in the number of future steps considered.

1.2 Previous Work
Previous methods for solving POMDPs are usually classified into exact methods and approximate methods (Lovejoy, 1991a). They can also can be classified according to which of the
aforementioned two diculties they directly address. Most previous methods address the
diculty of exponential number of future behaviors (Sondik, 1971; Sondik & Mendelssohn,
1979; Monahan, 1982; Cheng, 1988; Lovejoy, 1991b; and Cassandra et al., 1994). They
prune from consideration behaviors that can never be optimal no matter what the information state is (Section 4). Other methods deal with the problem of exponential number
of past information states either by aggregating them (Platzman, 1977; White & Schere,
1994) or by considering only a subset of them (Lovejoy, 1992; Brafman, 1997; Hauskrecht,
1997). They are approximation methods in nature.

1.3 Model Approximation
In previous approximation methods, approximation takes place in the process of solving
a POMDP. We advocate model approximation methods. Such a method approximates a
POMDP itself by another one that is easier to solve and uses the solution of the latter to
construct an approximate solution to the original POMDP.
Model approximation can be in the form of a more informative observation model, or
a more deterministic action model, or a simpler state space, or a combination of two or all
of the three alternatives. Cassandra et al. (1996) proposed to approximate POMDPs by
using MDPs. This is an example of model approximation in the form of a more informative
observation model. There is also some work on reducing the size of the state spaces of MDPs
200

fiModel Approximation for Planning under Uncertainty

by aggregation (e.g., Bertsekas & Castanon, 1989; Dean & Lin, 1995; Dean & Givan, 1997).
Such work can be conceivably extended to POMDPs, leading to model approximation in
the form of a simpler state space. We are not aware of any model approximation schemes
in the form of a more deterministic action model.

1.4 Our Proposal
This paper proposes a new model approximation scheme in the form of a more informative
observation model. It is a generalization of the idea of approximating POMDPs by using
MDPs.
We transform a POMDP by assuming that, in addition to the observations obtained by
itself, the agent also receives a report from an oracle who knows the true state of the world.
The oracle does not report the true state itself. Instead, it selects, from a predetermined
list of candidate regions, a region that contains the true state and reports that region. The
transformed POMDP is said to be region observable because the agent knows for sure that
the true state is in the region reported by the oracle.
When all candidate regions are singletons, the oracle actually reports the true state of
the world. The region observable POMDP reduces to an MDP. MDPs are much easier to
solve than POMDPs. One would expect the region observable POMDP to be solvable when
all candidate regions are small.
In terms of approximation quality, the larger the candidate regions, the less additional
information the oracle provides and hence the more accurate the approximation. In the
extreme case when there is only one candidate region and it consists of all possible states
of the world, the oracle provides no additional information at all. Consequently, the region
observable POMDP is identical to the original POMDP.
A method for determining approximation quality will be described later in this paper.
It allows one to make the tradeoff between approximation quality and computational time
as follows: start with small candidate regions and increase their sizes gradually until the
approximation becomes accurate enough or the region observable POMDP becomes untractable.
Due to problem characteristics, accurate approximation can usually be achieved with
small candidate regions. In many applications the agent often has a good idea about the
state of the world (e.g., Simmons & Koenig, 1995). Take robot path planning as an example.
Observing a landmark, a room number for instance, would imply that the robot is at the
proximity of that landmark. Observing a feature about the world, a corridor T-junction for
instance, might imply the robot is in one of several regions. Taking history into account, the
robot might be able to determine a unique region for its current location. Also, an action
usually moves the state of the world to only a few \nearby" states. Thus if the robot has a
good idea about the current state of world, it should continue to have a good idea about it
in the next few steps.
When the agent has a good idea about the state of the world at all times, the oracle
does not provide much additional information even with small candidate regions and hence
approximation is accurate. Region observable POMDPs with small candidate regions are
much easier to solve than general POMDPs.
201

fiZhang & Liu

1.5 Organization

We will first show how POMDPs can be used as a model for planning in partially observable
stochastic domains (Section 2) and give a concise review of the theory of POMDPs (Sections
3 and 4). We will then propose a new method for dynamic-programming updates, a key
step in algorithms that solve POMDPs via value iteration (Section 5). Thereafter, we will
formally introduce the concept of region observable POMDPs (Section 6) and develop an
algorithm for solving region observable POMDPs (Sections 7, 8, and 9). In Section 10,
we will discuss decision making for the original POMDPs based on the solutions of their
region observable approximations, followed by a method for determining approximation
quality (Section 11) and a method to make the tradeoff between approximation quality and
computational time (Section 12). Finally, empirical results will be reported in Section 13
and conclusions will be provided in Section 14.

2. Planning in Stochastic Domains and POMDPs

To specify a planning problem, one needs to give a set S of possible states of the world,
a set O of possible observations, and a set A of possible actions. The sets O and A are
always assumed to be finite in the literature, while the state space S can be continuous as
well as finite. In this paper, we consider only finite state space. One needs also to give an
observation model which describes the relationship between observations and the state of
the world, and an action model which describes effects of actions.
As a background example, consider path planning for a robot who acts in an oce
environment. Here S is the set of all location-orientation pairs, O is the set of possible
sensor readings, and A consists of actions move-forward, turn-left, turn-right, and
declare-goal.
The current observation o depends on the current state of the world s. Due to sensor
noise, this dependency is uncertain in nature. The observation o sometimes also depends
on the action that the robot has just taken a- . The minus sign in the subscript indicates
the previous time point. In the POMDP model, the dependency of o upon s and a- is
numerically characterized by a conditional probability P (ojs; a- ), which is usually referred
to as the observation probability. It is the observation model.
In a region observable POMDP, the current observation also depends on the previous state of the world s- . The observation probability for this case can be written as
P (ojs; a- ; s-).
The state s+ the world will be in at the next time point depends on the current action a
and the current state s. The plus sign in the subscript indicates the next time point. This
dependency is again uncertain in nature due to uncertainty in the actuator. In the POMDP
model, the dependency of s+ upon s and a is numerically characterized by a conditional
probability P (s+ js; a), which is usually referred to as the transition probability. It is the
action model.
On many occasions, we need to consider the joint conditional probability P (s+ ; o+ js; a)
of the next state of the world and the next observation given the current state and the
current action. It is given by

P (s+; o+js; a) = P (s+ js; a)P (o+ js+; a; s):
202

fiModel Approximation for Planning under Uncertainty

Knowledge about the initial state, if available, is represented as a probability distribution

P0 over S . When the agent knows the initial state with certainty, P0 is 1 at the initial state

and 0 everywhere else. The planning goal is encoded by a reward function such as the
following:
(
a=declare-goal and s=goal,
r(s; a) = 10 ifotherwise.
The preference for short plans is encoded by discounting future rewards with respect to the
current reward (see the next section).
In summary, a POMDP consists of a set of possible states of the world, a set of possible
observations, a set of possible actions, a observation probability, a transition probability,
and a reward function. An MDP has the same ingredients as an POMDP except that it has
no observation probability. This is because the state of the world is completely observed in
an MDP.

3. Basics of POMDPs

This section reviews several concepts and results related to POMDPs.

3.1 Belief States

In a POMDP, an agent chooses and executes an action at each time point. The choice
is made based on information from the past (past observations and past actions) and the
current observation. The amount of memory required to store past observations and actions
increases linearly with time. This makes it dicult to maintain past information after a
long period of time.
The standard way to overcome this diculty is to maintain, instead of past information,
the agent's belief state | the probability distribution P (st jot ; at,1 ; ot,1 ; : : : ; a1 ; o1 ; P0 ) of the
current state st of the world given past information and the current observation. It is well
known that the belief state is a sucient statistic in the sense that it captures all the
information contained in past information and the current observation that is useful for
action selection. Hence the agent can base its decision solely on the belief state.
Compared with maintaining past information, maintaining the belief state is desirable
because the number of possible states of the world is finite. One needs only to maintain a
fixed and finite number of probability values1 .
The initial belief state is P0 . One question is how the agent should update its belief
state as time goes by. Following Littman (1994), we use b to denote a belief state. For any
state s, b(s) is the probability that the world is in state s. The set of all possible belief
states will be denoted by B.
Suppose b is the current belief state, and a is the current action. If the observation o+
is obtained at the next time point, then the agent should update its belief state from b to
a new belief state b+ given by
X
b+ (s+) = k P (s+; o+ js; a)b(s);
(1)
s

1. Storing these values exactly could require unbounded precision. Approximations are implicitly being
made due to the fact that machine precision is bounded.

203

fiZhang & Liu

where k=1=

P

s;s+ P (s+ ; o+

js; a)b(s) is the normalization constant (e.g., Littman, 1994).

3.2 POMDPs as MDPs

For any belief state b and any action a, define

r(b; a) =

X
s

b(s)r(s; a):

(2)

It is the expected immediate reward for taking action a in belief state b.
For any belief state b, any action a, and any observation o+ , define

P (o+ jb; a) =

X

s;s+

P (s+; o+ js; a)b(s):

(3)

It is the probability of observing o+ at the next time point given that the current belief state
is b and the current action is a. Let b+ be the belief state given by equation (1). P (o+ jb; a)
can also be understood as the probability of the next belief state being b+ given that the
current action is a and the current belief state is b.
A POMDP over world state space S can be viewed as an MDP over the belief state
space B. The the reward function and the transition probability of the MDP are given by
Equations (2) and (3) respectively.

3.3 Optimal Policies

At each time point, the agent consults its belief state and chooses an action. A policy 
prescribes an action for each possible belief state. Formally it is a mapping from B to A.
For each belief state b, (b) is the action prescribed by  for b.
Suppose b0 is the current belief state. If an agent follows a policy , then its current
action is (b0 ) and the immediate reward is r0 (b; (b0 )); with probability P (o+ jb0 ; (b0 )),
the agent's next belief state b1 will be as given by Equation (1), the next action will be
(b1 ), and the next reward will be r1 (b1 ; (b1 )); and so on and so forth. The quality of
a policy is measured by the expected discounted rewards it garners. Formally the value
function of a policy  is defined for each belief state b0 to be the following expectation:
1
X

V  (b0 ) = Eb0 [

i=0

 i ri (bi ; (bi ))];

(4)

where 0<1 is the discount factor.
A policy 1 dominates another policy 2 if for each belief state b2B

V 1 (b)  V 2 (b):

(5)

Domination is a partial ordering among policies. It is well known that there exists a policy
that dominates all other policies (e.g., Puterman, 1990). Such a policy is called an optimal
policy. The value function of an optimal policy is called the optimal value function and is
denoted by V  .
204

fiModel Approximation for Planning under Uncertainty

3.4 Value Iteration

Value iteration is a standard way for solving infinite horizon MDPs (Bellman, 1957). It
begins with an arbitrary initial function V0 (b) and improves it iteratively by using the
following equation

Vt(b) = maxa [r(b; a) + 

X
o+

P (o+ jb; a)Vt,1 (b+ )];

(6)

where b+ is the belief state given by equation (1). If V0 =0, then Vt is called the t-step
optimal value function. For any belief state b, Vt (b) is the optimal expected reward the
agent can get in t steps starting from b.
The following theorem (Puterman, 1990, page 361) tells one when to terminate value
iteration and how to construct a \good enough" policy.

Theorem 1 Let  the policy given by
(b) = arg maxa [r(b; a) + 

X
o+

P (o+ jb; a)Vt (b+ )]:

(7)

If maxb2B jVt (b) , Vt,1 (b)j  , then

maxb2B jV  (b) , V  (b)j  12, :2

(8)

The quantity maxb2B jVt (b) , Vt,1 (b)j is sometimes called the Bellman residual and the
policy  is called the greedy policy based on Vt .
Algorithms for POMDPs are classified into exact or approximation algorithms depending
on whether they compute the t-step optimal value function Vt exactly (Lovejoy, 1991a).
In the next two sections, we discuss the theoretical foundations of exact algorithms and
develop a new exact algorithm. Thereafter, we propose a new approximation algorithm.

4. Piecewise Linearity and Implicit Value Iteration

Since the belief space is continuous, exact value iteration cannot be carried out explicitly.
Fortunately, it can be carried out implicitly due to the piecewise linearity of the t-step
optimal value functions. To explain piecewise linearity, we need the concept of policy trees.

4.1 Policy Trees

A t-step policy tree pt (Littman, 1994) prescribes an action for the current time point
and an action for each possible information scenario (o1 ; : : : ; oi ; a0 ; : : : ; ai,1 ) at each of the
next t,1 time points i. Figure 1 shows a 3-step policy tree. The tree reads as follows.
Move-forward at the current time point. At the next time point, if o1 =0 is observed then
turn-left. Thereafter if o2 =0 is observed then turn-left again; else if o2 =1 is observed
then declare-goal; else if o2 =2 is observed then move-forward. And so on and so forth.
To relate back to the introduction, a t-step policy tree prescribes a way the agent might
behave at the current and the next t,1 time points.
205

fiZhang & Liu

turn-left

a

2

0
turn-left

a1

O2

1

a2

declare-goal

2
a2

0

forward

declare-goal

a2
0
forward

a0

O1

1

turn-right

O
2

a1

1

turn-right

a
2

2
turn-left

a
2

2

declare-goal

a2
0
a1

forward

O
2

1

turn-left

a2

2

declare-goal

a
2

Figure 1: A 3-step policy tree.
When t>1, the subtree rooted at the o1 node will be called a o-rooted t,1-step policy
tree, and will be denoted by t,1 . It is a mapping from the set of possible observations O
to the set of all possible t,1-step policy trees; it prescribes a t,1 step policy tree t,1 (o)
for each possible observation o. In our example, 2 (o1 =0) is the 2-step policy tree rooted
at the uppermost a1 node.
When t>1, a t-step policy tree pt has two components: an action a for the current time
point and an o-rooted t,1-step policy tree t,1 for the next t,1 time points. For this
reason, we shall sometimes write pt as a pair (a; t,1 ) and call a the first action of pt .
By altering the actions on the edges out of the a-nodes, one obtains different t-step
policy trees. The set of all possible t-step policy trees will be denoted by Pt . A 1-step
policy tree is simply an action, and hence P1 is the same as the set of possible actions A.

4.2 State Value Functions of Policy Trees

For any state s and any t-step policy tree pt =(a; t,1 ), recursively define

Vp (s) = r(s; a) + 
t

XX
o+ s+

V ,1 (o+) (s+ )P (s+ ; o+ js; a);
t

(9)

where the second term is to be understood as 0 when t=1. It is the expected discounted
total reward the agent receives at the current time and during the next t,1 time points if
the world is currently in state s and the agent behaves according to the policy tree pt . We
call Vp the state value function of the t-step policy tree pt .
Without mentioning the policy tree, we shall sometimes call Vp a t-step state value
function. The collection of all t-step state value functions will be denoted by Vt , i.e.
Vt = fVp jpt 2Pt g:
For convenience, we let V0 consist of one single function of s that is zero for all s.
t

t

t

206

fiModel Approximation for Planning under Uncertainty

4.3 State Space Functions and Belief Space Functions

It is worthwhile to point out that a t-step state value function is a state space function, i.e.
a function over the state space S , while the t-step optimal value function is a belief space
function, i.e. a function over the belief space B. We often use notations such as ff or fi to
refer to state space functions. A state space function ff(s) induces a belief space function
through
X
ff(b) = ff(s)b(s):
s

Regarding b as a vector with one component b(s) for each s, the induced belief space function
is a linear combination of the components of b. For convenience, we simply say that ff(b) is
linear in b.
A collection V of state space functions induces a belief space function through

V (b) = maxff2V ff(b):

(10)

Note that we are using V to denote both a set of state space functions and the belief space
function it induces. When V is empty, V (b) is 0 by definition.
The induced belief space function V (b) is piecewise linear in b in the sense that, for each
ff2V , it equals ff(b) in the region fbjff(b)fi (b) for any other fi 2Vg of the belief space B and
hence is linear in b in that region.

4.4 Piecewise Linearity of Optimal Value Functions

The following theorem was first proved by Sondik (1971). It first appeared in its present
form in Littman (1994).

Theorem 2 (Piecewise Linearity) The t-step optimal value function Vt is the same as
the belief space function induced by the collection of all t-step state value functions Vt , i.e.
for any belief state b

Vt (b) = Vt (b):2

The theorem is true for the following reasons. Vt (b) is the reward the agent receives if it behaves optimally and for any policy tree pt , Vp (b) is the reward the agent gets if it behaves according to pt . Because one of the policy trees must be optimal, Vt (b) = maxp Vp (b)=Vt (b).
Due to this theorem, we say that the collection Vt of state value functions is representation
of Vt .
t

t

t

4.5 Parsimonious Representations
The size of Vt increases exponentially with t. As a matter of fact, the total number of t-step
policy trees (Cassandra, 1994) is:

jOj ,1
t

jPt j = jAj jOj,1 :
There are potentially the same number of t-step state value functions. Fortunately, many of
the state value functions can be pruned without affecting the induced belief space function.
Let us make this property more explicit.
207

fiZhang & Liu

Let W and X be two sets of state space functions. We say that W covers X if it induces
the same belief space function as X does, i.e. if
W (b) = X (b)
for any belief state b. We say that W parsimoniously covers X if W covers X and none
of its proper subsets do. When W covers or parsimoniously covers X , we refer to W as a
covering or a parsimonious covering of X .
Theorem 3 All parsimonious coverings of a set of state space functions consist of the same
number of state space functions. 2
The theorem has been known for sometime (e.g., Littman, 1994). Due to this theorem, one
can also define a parsimonious covering as a covering that contains the minimum number
of state space functions.
A parsimonious covering V^t of Vt is also a representation of Vt in the sense that V^t (b) =
Vt (b) for any belief state b. This representation is parsimonious because it consists of the
fewest number of state space functions among all the representations of Vt .

4.6 Dynamic-Programming Updates

The question now is how to obtain a parsimonious covering of Vt . As will be shown in
the next section, it is possible to obtain a parsimonious covering of Vt by starting from a
parsimonious covering of Vt,1 . The process of computing a parsimonious covering of Vt
from a parsimonious covering of Vt,1 is called dynamic-programming updates (Littman et
al., 1995). It is a key step in algorithms that solve POMDPs via value iteration.
Previous algorithms for dynamic-programming updates include the enumeration and
pruning algorithms by Monahan (1992), Eagle (1984), and Lark (White, 1991), the onepass algorithm by Sondik (1971), the linear support and relaxed region algorithms by Cheng
(1988), and the witness algorithm by Cassandra et al. (1994) and Littman (1994). The
witness algorithm has been empirically proved to be the most ecient among all those
algorithms (Littman et al., 1995).

4.7 Implicit Value Iteration

The procedure solvePOMDP shown in Figure 2 carries out value iteration implicitly: instead
inductively computing the t-step optimal value function Vt itself, it computes a parsimonious covering of Vt | a set of state space functions that represents Vt . In the procedure,
the subroutine update(V^t,1) takes a parsimonious covering V^t,1 of Vt,1 and returns a parsimonious covering V^t of Vt . It can be implemented using any of the algorithms mentioned in
the previous subsection. The subroutine stop(V^t; V^t,1 ; ) determines whether the Bellman
residual has fallen below the threshold  from the parsimonious coverings V^t,1 and V^t of
Vt,1 and Vt. See Littman (1994) for an implementation of this subroutine.
Procedure solvePOMDP terminates when the Bellam residual falls below the threshold
 and return a set of state space functions. The set V^t of state space functions returned
represents the t-step optimal value function Vt . It is the solution to the input POMDP.
The planning agent keeps V^t in its memory. When it needs to make a decision, the agent
consults its belief state b and chooses an action using (7) with Vt (b+ ) replaced by V^t (b+ ).
208

fiModel Approximation for Planning under Uncertainty

||||||||||||||||||||||
Procedure solvePOMDP(M; ):
 Input: M | A POMDP,
 | A positive number.
 Output: A set of state space functions.
1. t 0, V^0 f0g.
2. Do
 t=t+1.
 V^t update(V^t,1 ):
while stop(V^t; V^t,1 ; ) = no.
3. Return V^t .
||||||||||||||||||||||
Figure 2: Implicit value iteration.

5. A New Algorithm for Dynamic-Programming Updates
This section proposes a new algorithm for dynamic-programming updates. There are four
subsections. In the first three subsections, we show that a parsimonious covering of Vt can
be obtained by starting from a parsimonious covering of Vt,1 and, while doing so, introduce
concepts and results that are necessary for the development of the new algorithm.

5.1 Relationship Between Vt,1 and Vt
L
Suppose W and X are two sets of state space functions. The cross sum W X of W and
X is the following set of state space functions:
M
W X = fff+fi jff2W ; fi 2Xg:
It is evident that the cross sumLoperation is commutative and associative. Consequently, we
can talk about the cross sum Ni=0 Wi of a list of sets W0 , . . . , WN of state space functions.
For any action a and any observation o+, define

Qa;o+ = f

X
s+

ff(s+)P (s+ ; o+ js; a)jff2Vt,1 g:

P

(11)

Note that since a and o+ are given, each member  s+ ff(s+ )P (s+ ; o+ js; a) of the above
set is a function of s, in other words, a state space function. Hence Qa;o+ is a set of state
space functions. Let 0, 1, . . . , N beL an enumeration of all possible values of o+. We use
L
N
o+ Qa;o+ to denote the cross sum i=0 Qa;i .

Proposition 1 Vt = [a[fr(s; a)gL(Lo+ Qa;o+ )]:
209

fiZhang & Liu

Proof: By the definition of the set Vt and Equation (9), a state space function ff is in Vt
if and only if there exist action a and fio+ 2 Vt,1 for each o+ 2 O such that
ff(s) = r(s; a) +

X X
 fio+ (s+)P (s+; o+ js; a):
o+

s+

The proposition follows. 2

5.2 Properties of Coverings
Lemma 1 Suppose W , X , and Y are three sets of state space functions. If W parsimoniously covers X and X covers Y , then W parsimoniously covers of Y . 2
Lemma 2 Let W , W 0 , X , and X 0 be four sets of state space functions. If W 0 covers W
and X 0 covers X , then
L
L
1. W 0 X 0 covers W X .
2. W 0 [X 0 covers W[X .2
5.3 Coverings of Vt from Parsimonious Coverings of Vt,1
Let V^t,1 be a parsimonious covering of Vt,1 . For any action a and any observation o+ ,
define

Q0a;o+ = f

X
s+

ff(s+)P (s+ ; o+ js; a)jff2V^t,1 g:

Note that the definition of Q0a;o+ is the same as that of Qa;o+ except that Vt,1 is replaced
by V^t,1 . Also define
MM
Vt0 = [a [fr(s; a)g ( o+ Q0a;o+ )]:

Proposition 2 The set Vt0 covers Vt.
Formal proof of this proposition is given in Appendix A. Informally, the fact that V^t,1
covers Vt,1 implies that Q0a;o+ covers Qa;o+ , which in turn implies that Vt0 covers Vt due to
Proposition 1 and Lemma 2.
According to Proposition 2 and Lemma 1, one can obtain a parsimonious covering of
Vt by finding a parsimonious covering of Vt0 and Vt0 is defined in terms of a parsimonious
covering V^t,1 of Vt,1 . This is why we said that a parsimonious covering of Vt can be
obtained by starting from a parsimonious covering of Vt,1 .
Monahan's exhaustive method finds a parsimonious covering of Vt0 by enumerating all
the state space functions in Vt0 one by one and detecting those that can be pruned by solving
linear programs. Lark's algorithm works in a similar fashion except that its linear programs
have fewer constraints. Since Vt0 consists of jAjjV^t,1 jjOj state space functions, enumerating
them one by one is very expensive. Other algorithms (Sondik, 1971; Cheng, 1988; Littman,
1994) avoid this diculty by exploiting the structures of Vt0 .
210

fiModel Approximation for Planning under Uncertainty

|||||||||||||||||||||||
Procedure incrPruning(fW0; W1 ; : : : ; WN g):
1. W W0 .
2. For i = 1 to N ,

W

M

W Wi):

purge(

3. Return W .
Procedure update(V^t,1):
 Input: V^t,1 | a parsimonious covering of Vt,1.
 Input: a parsimonious covering of Vt.
1. For each a2A,
(a) Compute the sets Q0a;0 , Q0a;1 , . . . , and Q0a;N .
(b) Wa incrPruning(fQ0a;0 ; Q0a;1 ; : : : ; Q0a;N g).
L
2. Return purge([a [fr(s; a)g Wa ]).
|||||||||||||||||||||||
Figure 3: Incremental pruning and dynamic-programming updates.

5.4 A New Algorithm for Dynamic-Programming Updates
Let purge(W ) be a subroutine that takes a set W of state space functions and returns a
parsimonious covering of W . An implementation of purge can be found in the appendix.
Let W0 , . . . , WN be sets of state space functions. Consider the procedure incrPruning

shown in Figure 3. Let n be a number between 0 and N . Using Lemmas 1 and 2, one can
easily show by induction that,
at the end of the nth pass through the for-loop, the set W is
L
n
a parsimonious
L covering of i=0 Wi. Consequently, the procedures returns a parsimonious
covering of Ni=0 Wi . The procedure is named incremental pruning because pruning takes
place after each cross sum.
Let 0, 1, . . . , N be an enumeration of all the possible observations, i.e. possible instantiations of o+ . For any action a, suppose the sets Q0a;0 , Q0a;1 , . . . , and Q0a;N have
been computed. Applying incrPruning to those sets, we get a parsimonious
covering of
L
N Q0 . Denote it by W . According to Lemma 2, [ [fr (s; a)gLW ] covers V 0 . Due
a
a
a L
t
i=0 a;i
to Lemma 1, this fact implies that a parsimonious covering of [a [fr(s; a)g Wa ] is also a
parsimonious covering of Vt0 and hence of Vt . Thus, a parsimonious covering of Vt can be
found from a parsimonious covering of Vt,1 using the procedure update shown in Figure 3.
We also use the term incremental pruning to refer to the above algorithm for dynamicprogramming updates. It has been shown elsewhere (Cassandra et al., 1977) that incremental pruning has the same asymptotic complexity as the witness algorithm and empirically
it significantly outperforms the latter.
211

fiZhang & Liu

6. Region-Based Model Approximation
We have so far been concerned with exact algorithms. Experiments with incremental pruning, presently the most ecient exact algorithm, have revealed that it can solve only small
POMDPs (Cassandra et al., 1997). One needs to resort to approximation in order to solve
large real-world problems.
Most previous approximation methods solve a POMDP directly; they approximate the
t-step optimal value function of the POMDP. In the rest of this paper, we develop a new
method that approximates a POMDP itself by another that has a more informative observation model and is hence easier to solve. The latter POMDP is solved and its solution is
used to construct a solution to the original POMDP.

6.1 The Basic Idea

We make the following assumption about problem characteristics. in a POMDP M, even
though an agent does not know the true state of the world, it often has a good idea about
the state. Justifications for this assumption were given in the introduction and empirical
evidence is presented by Simmons & Koenig (1995).
Consider another POMDP M0 that is the same as M except that in addition to the
observation made by itself, the agent also receives a report from an oracle who knows the
true state of the world. The oracle does not report the true state itself. Instead it selects,
from a predetermined list of candidate regions, a region that contains the true state and
reports that region.
More information is available to the agent in M0 than in M; additional information
is provided by the oracle. Since in M the agent already has a good idea about the true
state of the world, the oracle might not provide much additional information even when the
candidate regions are small. Consequently, M0 could be a good approximation of M.
In M0 , the agent knows for sure that the true state of the world is in the region reported
by the oracle. For this reason, we say that it is region observable. The region observable
POMDP M0 can be much easier to solve than M when the candidate regions are small. For
example, if the oracle is allowed to report only singleton regions, then it actually reports
the true state of the world and hence M0 is an MDP. MDPs are much easier to solve than
POMDPs. One would expect the region observable POMDP M0 to be solvable when the
candidate regions are small.

6.2 Spectrum of Approximations
If the region reported by the oracle is always the set of all possible states, then no additional
information is provided, because the report that the true state of the world is one of the
possible states has no information content. In this case, M0 has the same solution as M
and solving M0 is equivalent to solving M directly. This is one extreme of the spectrum.
At the other extreme, if all the candidate regions are singletons, the oracle reports the
true state of the world. Maximum amount of additional information is provided and M0
is actually an MDP. The MDP might not be a good approximation of M but it is much
easier to solve than M.
212

fiModel Approximation for Planning under Uncertainty

Previous methods for solving a POMDP either solve it directly or to approximate it
by using a MDP. By allowing the oracle to report regions that are neither singletons nor
the set of all possible states, this paper opens up the possibility of exploring the spectrum
between those two extremes. One way to explore the spectrum is to start with singleton
candidate regions and increase their sizes gradually. Approximation quality and computational time both increase as one goes along. One stops when the approximation is accurate
enough or the region observable POMDP becomes intractable. A method for determining
approximation quality will be described later.
We now set out to make these ideas more concrete by starting with the concept of region
systems.

6.3 Region Systems
A region is simply a subset of states of the world. A region system is a collection of regions
such that no region is a subset of another region in the collection and the union of all regions
equals the set of all possible states of the world. We use R to denote a region and R to
denote a region system.
Region systems are used to restrict the regions that the oracle can choose to report. The
choice of a region system determines the computational complexity of the region observable
POMDP M0 and approximation quality. How to choose regions so as to make proper
tradeoff between computational time and approximation quality is an open research issue.
Here is a preliminary approach. The idea is to create a region for each state by including
its \nearby" states. We say a state s0 is ideally reachable in one step from another state s
if after executing a certain action in state s, the probability of the world ending up in state
s0 is the highest. A state sk is ideally reachable in k steps from another state s0 if there are
state s1 , . . . , sk,1 such that si+1 is ideally reachable from si in one step for all 0ik,1.
Any state is ideally reachable from itself in 0 step.
For any non-negative integer k, the radius-k region centered at a state s is the set of
states that are ideally reachable from s in k or less steps. A radius-k region system is the one
obtained by creating a radius-k region for each state and then removing, one after another,
regions that are subsets of others.
When k is 0, the radius-k region system consists of singleton regions. On the other
hand, if each state is reachable from any other state in k or less steps, there is only one
region in the radius-k region system | the set of all possible states.

6.4 Region Observable POMDPs
Given a region system R and a POMDP M, we construct a region observable POMDP M0

by assuming that at each time point the agent not only obtains an observation by itself but
also receives a report from an oracle who knows the true state of the world. The oracle does
not report the true state itself. Instead it chooses from R one region that contains the true
state and reports that region.
The amount of additional information provided by the oracle depends not only on the
region system used but also on the way the oracle chooses regions. For example, if the
213

fiZhang & Liu

oracle always reports the region centered at the true state, then it implicitly reports the
true state itself.
In order to provide as little additional information as possible, the oracle should consider
what the agent already knows. However, it cannot take the entire history of past actions
and observations into account because if it did, M0 would not be a POMDP. The current
observation would depend on the entire history.
For any non-negative state space function f (s) and any region R, we call the quantity
supp(f; R)= Ps2R f (s)= Ps2S f (s) the degree of support of f by R. Note that when f is a
probability distribution, the denominator is 1. If R supports f to degree 1, we say that R
fully supports f .
We suggest the following region-selection rule for the oracle. Let s- be the previous true
state of the world, a- be the previous action, and o be the current observation. The oracle
should choose, among all the regions in R that contain the true state of the world, one that
supports the function P (s; ojs- ; a- ) of s to the maximum degree. Where there is more than
one such regions, choose the one that comes first in a predetermined ordering among the
regions.
Here are some arguments in support of the rule. If the previous world state s- were
known to the agent, then its current belief state b(s), a function of s, would be proportional
to P (s; ojs- ; a- ). In this case, the rule minimizes additional information in the sense that
the region reported supports the current belief state to the maximum degree. If the previous world state is known to be around s- , the same is roughly true. Also if the current
observation is informative enough, being a landmark for instance, to ensure that the world
state is in a certain region, then the region chosen using the rule fully supports the current
belief state. In such a case, no additional information is provided. Despite those arguments,
we do not claim that the rule described above is optimal. Finding a rule that minimizes
additional information is still an open problem.
The probability P (Rjs; o; s- ; a- ) of a region R being chosen under the above scheme is
given by

8
>
< 1 Pif R is the0 first regionPs.t. s2R 0and for any other region R0
P (Rjs; o; s-; a-) = >
s0 2R P (s ; ojs- ; a- ) s0 2R0 P (s ; ojs- ; a- )
: 0 otherwise.

The region observable POMDP M0 differs from the original POMDP M only in terms
of observation; in addition to the observation o made by itself, the agent also receives a
report R from the oracle. We shall denote an observation in M0 by z and write z =(o; R).
The observation model of M0 is given by

P (zjs; a- ; s-) = P (o; Rjs; a- ; s- ) = P (ojs; a- )P (Rjs; o; s- ; a- ):
The joint conditional probability P (s+ ; z+ js; a) of the next state s+ of the world and the
next observation z+ given the current state s and the current action a is

P (s+; z+js; a) = P (s+ js; a)P (z+ js+ ; a; s):
214

fiModel Approximation for Planning under Uncertainty

7. Solving Region Observable POMDPs

In principle, the region observable POMDP M0 can be solved in the same way as general
POMDPs using the procedure solvePOMDP. It is not advisable to do so, however, since
solvePOMDP does not automatically exploit region observability. This section and the next
two sections develop an algorithm for solving M0 that takes advantage of region observability.

7.1 Restricted Value Iteration
For any region R, let BR be the set of belief states that are fully supported by R. Let R be
the region system underlying the region observable POMDP M0 . Define BR = [R2R BR .
It is easy to see that, in M0 , no matter what the current belief state b is, the next belief
state b+ must be in BR . We assume that the initial belief state is in BR . Then all possible
belief states the agent might encounter are in BR . This implies that policies for M0 need
only be defined over BR and value iteration for M0 can be restricted to the subset BR of B.
We restrict value iteration for M0 to BR for the sake of eciency. Doing so implies
that the t-step optimal value function of M0 , denoted by Ut , is defined only over BR and
the Bellman residual is now maxb2BR jUt (b) , Ut,1 (b)j. To avoid confusion, we call it the
restricted Bellman residual and call Ut the restricted t-step optimal value function.
Since BR is continuous, restricted value iteration cannot be carried out implicitly. The
next subsection shows how it can be carried implicitly.

7.2 Implicit Restricted Value Iteration
Let W and X be two sets of state space functions and let R be a region. We say that W
covers X in region R if, for any b2BR ,
W (b) = X (b):
We say that W parsimoniously covers X in region R if W covers X in region R and none
of its proper subsets do. When W covers or parsimoniously covers X in a region, we refer
to W as a regional covering or a parsimonious regional covering of X .
Let Ut be the set of all t-step state value functions of M0 . According to Theorem 2,
Ut (b) = Ut (b)
for any belief state b2BR .
For each region R, suppose U^t;R is a set of state space functions that parsimoniously
covers Ut in region R. Then the collection fU^t;R jR2Rg is a representation of Ut in the sense
that for any b2BR ,
Ut (b) = U^t;R (b);
(12)
where Rb is such that b2BR , i.e. such that Rb fully supports b.
As will be shown in the next section, parsimonious regional coverings of Ut can be obtained from parsimonious regional coverings of Ut,1 . Let ROPOMDPupdate(R; U^t,1;R+ jR+ 2Rg)
be a procedure that takes a region R and parsimonious regional covering fU^t,1;R+ jR+ 2Rg
b

215

fiZhang & Liu

|||||||||||||||||||||||||||
Procedure solveROPOMDP(M0; )
 Input: M0 | A region observable POMDP,
 | A positive number.
 Output: A list of sets of state space functions.
1. t 0.
2. For R2R, U^0;R f0g.
3. Do
 t t+1.
 For each R2R,
U^t;R ROPOMDPupdate(R; fU^t,1;R+ jR+2Rg):

while ROPOMDPstop(fU^t;RjR2Rg; fU^t,1;R+ jR+2Rg; ) = no.
4. Return fU^t;R jR2Rg.

|||||||||||||||||||||||||||

Figure 4: Implicit restricted value iteration for region-observable POMDPs.
of Ut,1 and returns a set of state space functions that parsimoniously covers Ut in region R
Let ROPOMDPstop be a procedure that determines, from parsimonious regional coverings
of Ut,1 and Ut , whether the restricted Bellman residual has fallen below a predetermined
threshold.
The procedure solveROPOMDP shown in Figure 4 carries out restricted value iteration
implicitly: instead inductively computing the restricted t-step optimal value function Ut
itself, it computes parsimonious regional coverings of Ut . In other words, it computes sets
of state space functions that represent Ut in the sense of (12).
Let 0 be the greedy policy for M0 based on Ut . For any b2BR , 0 (b) is defined by
Equation (7) with o+ replaced by z+ =(o+ ; R+ ) and Vt replaced by Ut . Since the list
fU^t;R jR2Rg of sets of state space functions returned by solveROPOMDP represents Ut in the
sense of (12), we have that for any b2BR
2.

0 (b) = arg maxa[r(b; a) + 

X
o+ ;R+

P ((o+ ; R+ )jb; a)U^t;R+ (b+ )]:

The next two sections show how to implement the procedures

ROPOMDPstop.

ROPOMDPupdate

2. The string \ROPOMDP" in ROPOMDPupdate stands for region-observable POMDP.

216

(13)
and

fiModel Approximation for Planning under Uncertainty

8. Dynamic-Programming Updates for Region Observable POMDPs

This section shows how the incremental pruning algorithm developed in Section 5 can
be adapted to compute parsimonious regional coverings of Ut from parsimonious regional
coverings of Ut,1 .

8.1 Properties of Regional Coverings
Lemma 3 Let R be a region and let W , X , and Y be three sets of state space functions. If
W parsimoniously covers X in region R and X covers Y in region R, then W parsimoniously
covers Y in region R. 2
Lemma 4 Let R be a region and let W , W 0 , X , and X 0 be four sets of state space functions.
If W 0 and X 0 respectively cover W and X in region R, then
L
L
1. W 0 X 0 covers W X in region R.
2. W 0 [X 0 covers W[X in region R. 2
8.2 Regional Coverings of Ut from Parsimonious Regional Coverings of Ut,1
From parsimonious regional coverings U^t,1;R+ (R+ 2R) of Ut,1 , this subsection constructs,
for each region R2R, a set Ut;R of state space functions and shows that it covers Ut in region

R.

For any action a and any observation z+ =(o+ ; R+ ) of M0 , let Qa;z+ ;R be the set of all
state space functions fi that are of the following form:

( P
fi (s) =  s+ ff(s+ )P (s+ ; z+ js; a) if s2R
0

otherwise.

where ff 2 U^t,1;R+ . Define

MM

Ut;R = [a [fr(s; a)g (

(14)

Q

)]:
z+ a;z+ ;R

Proposition 3 The set Ut;R covers Ut in region R.
Formal proof of this proposition can be found in Appendix A. Informally, the fact that

U^t,1;R+ covers Ut,1 in region R+ implies that Qa;z+;R covers Qa;z+ in region R, where Qa;z+
is given by (11) with o+ and Vt,1 replaced by z+ and Ut,1 . This fact in turn implies that
Ut;R covers Ut in region R because of Proposition 1 and Lemma 4.

8.3 Possible Observations at the Next Time Point
In the definition of Ut;R , the cross sum is taken over all possible observations. This subsection
shows that some of the possible observations can be skipped.
For any action a and any region R, define

Za;R = fz+ j

X
s+

P (s+; z+ js; a) > 0 for some s2R g:
217

fiZhang & Liu

||||||||||||||||||||||||||||||||||
Procedure ROPOMDPupdate(R; U^t,1;R+ jR+ 2Rg):
 Inputs: R | A region, and for any region R+,
U^t,1;R+ parsimoniously covers Ut,1 in region R+.
 Output: A set of state space functions that parsimoniously covers Ut in
region R.
1. For each action a,
(a) Compute the set Za;R and enumerate its members as 0; 1; : : : ; M .
(b) For i=0 to M , compute the set Qa;i;R .
(c) Wa restrictedIncrPruning(fQa;0;R ; Qa;1;R ; : : : ; Qa;M;R g; R):
L
2. Return purge([a [fr(s; a)g Wa ]; R).
Subroutine restrictedIncrPruning(fW0; W1 ; : : : ; WM g; R):
1. Let W W0 .
2. For i=1 to M ,
M
W purge(W Wi; R):
3. Return W .
||||||||||||||||||||||||||||||||||
Figure 5: Dynamic-programming updates for region observable POMDPs.
It is the set of observations that the agent can possibly receive at the next time point given
that the current state of the world lies in region R and the current action is a. There are
many observations outside this set. As a matter of fact, an observation z+ =(o+ ; R+ ) is not
in the set if it is not possible to reach regionPR+ from region R in one step.
For any z+ =(o+ ; R+ ), if z+ 2= Za;R , then s+ P (L
s+; z+ js; a) = 0 for all s2R. In such a
case, Qa;z+;R = f0g according to (14). Since, f0g W =W for any set W of state space
functions, we have

MM

Ut;R = [a[fr(s; a)g (

8.4 Parsimonious Regional Covering of Ut

Q

)]:
z+ 2Za;R a;z+ ;R

Proposition 3 and Lemma 3 imply that, for any region R, a set of state space functions
parsimoniously covers Ut in region R if and only if it parsimoniously covering Ut;R in region
R. According to Lemmas 3 and 4, a set of state space functions that parsimoniously covers
Ut;R in region R can be found using the procedure ROPOMDPupdate shown in Figure 5 (c.f.
Section 5.4). In the procedure, the subroutine purge(W ; R) takes a set W of state space
218

fiModel Approximation for Planning under Uncertainty

|||||||||||||||||||||||||||
Procedure ROPOMDPstop(fU^t;RjR2Rg; fU^t,1;R jR2Rg; )
 Inputs:  | A positive number, and for any region R
U^t;R covers Ut in region R, and
U^t,1;R covers Ut,1 in region R.
 Outputs: yes | If the restricted Bellman residual  ,
no | Otherwise.
1. For each region R,
(a) ag yes.
(b) For each ff2U^t,1;R ,
ag no if dominate(ff; U^t;R ; R; ) 6= nil:
(c) For each ff2U^t;R ,
ag

no

if dominate(ff; U^t,1;R ; R; ) 6= nil:

(d) Return no if ag = no.
2. Return yes.
|||||||||||||||||||||||||||
Figure 6: Procedure for determining whether the restricted Bellman residual has fallen
below a threshold.
functions and region R, and returns a set of state space functions that parsimoniously covers
W in region R. An implementation of this subroutine can be found in Appendix B.

9. The Stopping Condition

This section shows how to determine whether the restricted Bellman residual has fallen
below a predetermined threshold  from regional coverings of Ut and Ut,1 . For any region
R, let U^t;R and U^t,1;R be two sets of state space functions that respectively cover Ut and
Ut,1 in region R. By the definition of regional coverings, we have
Lemma 5 The restricted Bellman residual is no larger than  if and only if for any region
R and any belief state b2BR ,
1. For any ff2U^t;R ,
ff(b)  U^t,1;R (b)+; and
2. For any ff2U^t,1;R ,
ff(b)  U^t;R (b)+:2
219

fiZhang & Liu

Let dominate(ff; W ; R; ) be a procedure that returns a belief state b in BR such that
ff(b) > W (b)+. If such a belief state does not exist, it returns nil. An implementation

of this procedure can be found in Appendix B. The procedure ROPOMDPupdate shown in
Figure 6 returns yes if the restricted Bellman residual has fallen below  and no otherwise.
A couple of notes are in order. First, when the reward function r(s; a) is non-negative, Ut
increases with t. In this case, the restricted Bellman residual becomes maxb2BR (Ut (b),Ut,1 (b)).
Consequently, step (c) can be skipped. Second, when r(s; a) takes negative values for some
s and some a, a constant can be added to it so that it becomes non-negative. Adding a constant to r(s; a) does not affect the optimal policy. However, it makes it easier to determine
whether the restricted Bellman residual has fallen below a threshold.

10. Decision Making for the Original POMDP

Suppose we have solved the region observable POMDP M0 . The next step is to construct
a policy  for the original POMDP M based on the solution for M0 .
Even though it is our assumption that in the original POMDP M the agent has a good
idea about the state of the world at all times, there is no guarantee that its belief state are
always in BR . There is no oracle in M. A policy should prescribe actions for belief states
in BR as well as for belief states outside BR . One issue here is that the policy 0 for M0 is
defined only for belief states in BR . Fortunately, 0 can be naturally extended to the entire
belief space by ignoring the constraint b2BR in Equation (13). We hence define a policy 
for M as follows: for any b2B,
X
(b) = arg maxa [r(b; a) + 
P ((o+ ; R+)jb; a)U^t;R+ (b+ )]:
(15)
o+ ;R+

Let k be the radius of the region system underlying M0 . The policy  given above will
be referred to as the radius-k approximate policy for M. The entire process of obtaining
this policy, including the construction and solving of the region observable POMDP M0 ,
will be referred to as region-based approximation.
It is worthwhile to compare this equation with Equation (7). In Equation (7), there are
two terms on the right hand side. The first term is the immediate reward for taking action
a and the second term is the discounted future reward the agent can expect to receive if it
behaves optimally. Their sum is the total expected reward for taking action a. The action
with the highest total reward is chosen.
The second term is dicult to obtain. In essence, Equation (15) approximates the
second term using the optimal expected future reward the agent can receive with the help
of the oracle, which is easier to compute.
It should be emphasized that the presence of the oracle is assumed only in the process
of computing the radius-k approximate policy. The oracle is not present when executing
the policy.

11. Quality of Approximation and Simulation

In general, the quality of an approximate policy  is measured by the distance between its
value function V  (b) and the optimal value function V  (b). This measurement does not
220

fiModel Approximation for Planning under Uncertainty

consider what an agent might know about the initial state of the world. As such, it is not
appropriate for a policy obtained through region-based approximation. One cannot expect
such a policy to be of good quality if an agent is very uncertain about the initial state of
the world because it is obtained under the assumption that an agent has a good idea about
the state of the world at all times.
This section describes a scheme for determining the quality of an approximate policy in
cases where an agent knows the initial state of the world with certainty. The scheme can
be generalized to cases where there is a small amount of uncertainty about the initial state;
for example, cases where the initial state is known to be in some small region.
An agent might need to reach a goal from different initial states at different times. Let
P (s) be the frequencyPit will start from state s3 . The quality of an approximate policy 
can be measured by s jV  (s) , V  (s)jP (s), where V  (s) and V  (s) denote the rewards
the agent can expect to receive starting from state s if it behaves optimally or according to
 respectively.
By definition V  (s)V  (s) for all s. Let U  be the optimal value function of the
region observable POMDP M0 . Since
more information is available to the agent
in M0 ,
P
P




U (s)V (s) for all s. Therefore, s [U (s) , V (s)]P (s) is an upper bound on s [V  (s) ,
V  (s)]P (s).
Let 0 be the policy for M0 given by (13). When the 0restricted Bellman residual is small,
P0 is close
to optimal for M0 and the value function
V  of 0 is close to U  . Consequently,
P
0




s [V (s) , V (s)]P (s) is an upper bound on s [V (s) , V (s)]P (s) when the restricted
Bellman residual is small enough. P 0
One way to estimate the quantity s [V  (s) , V  (s)]P (s) is to conduct a large number
of simulation trials. In each trial, an initial state is randomly generated according to P (s).
The agent is informed of the initial state. Simulation takes place in both M and M0 . In
M, the agent chooses, at each step, an action using  based on its current belief state. The
action is passed to a simulator which randomly generates the next state of the world and the
next observation according to the transition and observation probabilities. The observation
(but not the state) is passed to the agent, who updates its belief state and chooses the next
action. And so on and so forth. The trial terminates when the agent chooses the action
declare-goal or a maximum number of steps is reached. Simulation in M0 takes place in a
similar manner except that the observations and the observation probabilities are different
and actions are chosen using 0 .
If the goal is correctly declared at the end of a trial, the agent receives a reward in the
amount Pn , where
n is the number of steps. Otherwise, the agent receive no reward. The
0

quantity s [V (s) , V  (s)]P (s) can be estimated using the difference between the average
reward received in the trials for M0 and the average reward received in the trials for M.

12. Tradeoff Between Quality and Complexity

Intuitively, the larger the radius of the region system, the less the amount of additional
information
the0 oracle provides.
Hence the closer M0 is to M and the narrower the gap
P
P


between s V (s)P (s) and s V (s)P (s). Although we have not theoretically proved this,
3. This is not to be confused with the initial belief state P0 , which represents the agent's knowledge about
the ninitial state at a particular trial.

221

fiZhang & Liu

P

empirical results (see the next section)
do0 suggest that s V  (s)P (s) increases with the
P
radius of the region system while s V  (s)P (s) decreases with it. In the extreme case
when there is one region in the region system that
possible states of the
P contains all the P
world, M and M0 are identical and hence so are s V 0 (s)P (s) and s V  (s)P (s).
These discussions lead to the following scheme for making the tradeoff between complexity and quality:P Start0 with the radius-0 region system and increase the radius gradually
until the quantity s [V  (s) , V (s)]P (s) becomes suciently small or the region observable
POMDP M0 becomes untractable.

13. Simulation Experiments
Simulation experiments have been carried out to show that (1) approximation quality increases with radius of region system and (2) where there is not much uncertainty, a POMDP
can be accurately approximated by a region-observable POMDP that can be solved exactly.
This section reports on the experiments.

13.1 Synthetic Oce Environments
Our experiments were conducted using two synthetic oce environments borrowed from
Cassandra et al. (1996) with some minor modifications. Layouts of the environments
are shown in Figure 7, where squares represent locations. Each location is represented as
four states in the POMDP model, one for each orientation. The dark locations are rooms
connected to corridors by doorways.
In each environment, a robot needs to reach the goal location with the correct orientation. At each step, the robot can execute one of the following actions: move-forward,
turn-left, turn-right, and declare-goal. The two sets of action models given in Figure
7 were used in our experiments. For the action move-forward, the term F-F (0.01) means
that with probability 0.01 the robot actually moves two steps forward. The other terms are
to be interpreted similarly. If an outcome cannot occur in a certain state of the world, then
the robot is left in the last state before the impossible outcome.
In each state, the robot is able to perceive in each of three nominal directions (front,
left, and right) whether there is a doorway, wall, open, or it is undetermined. The two
sets of observation models shown in Figure 7 were used in our experiments.

13.2 Complexity of Solving the POMDPs
One of the POMDPs has 280 possible states while the other has 200. They both have 64
possible observations and 4 possible actions. Since the largest POMDPs that researchers
have been able to solve exactly so far have less than 20 states and 15 observations, it is safe
to say no existing exact algorithms can solve those two POMDPs.
We were able to solve the radius-0 and radius-1 approximations (region observable
POMDPs) of the two POMDPs on a SUN SPARC20 computer. The threshold for the
Bellman residual was set at 0.001 and the discount factor at 0.99. The amounts of time it
took in CPU seconds are collected in the following table.
222

fiModel Approximation for Planning under Uncertainty

N

N
Goal
(south)
Enviroment B

Goal
(east)
Environment A

Transition Probabilities
Action

move-forward
turn-left
turn-right
declare-goal

Standard outcomes
N (0.11), F (0.88), F-F (0.01)
N (0.05), L (0.9), L-L (0.05)
N (0.05), R (0.9), R-R (0.05)
N (1.0)

Noisy outcomes
N (0.2), F (0.7), F-F (0.1)
N (0.15), L (0.7), L-L (0.15)
N (0.15), R (0.7), R-R (0.15)
N (1.0)

Observation Probabilities
Actual case Standard observations
wall
wall (0.90), open (0.04), doorway
(0.04), undetermined (0.02)
open
wall (0.02), open (0.90), doorway
(0.06), undetermined (0.02)
doorway
wall (0.15), open (0.15), doorway
(0.69), undetermined (0.01)

Noisy observations
wall (0.70), open (0.19), doorway
(0.09), undetermined (0.02)
wall (0.19), open (0.70), doorway
(0.09), undetermined (0.02)
wall (0.15), open (0.15), doorway
(0.69), undetermined (0.01)

Figure 7: Synthetic Oce Environments.
Environment
A
B

Standard models
Noisy models
Radius-0 Radius-1 Radius-0 Radius-1
1.26
3373
1.35
5984
0.61
2437
0.72
3952

We see that the radius-1 approximations took much longer time to solve than the radius-0
approximations. Also notice that the region observable POMDPs with noisy action and
observation models took more time to solve that those with the standard models. This suggests that the more nondeterministic the actions and the less informative the observations,
the more dicult it is to solve a POMDP.
223

fiZhang & Liu

We were unable to solve the radius-2 approximations. Other approximation techniques
need to be incorporated in order to solve the approximations based on region systems with
radius larger than or equal to 2.

13.3 Approximation Quality for Standard Models

To determine the quality of the radius-0 and radius-1 approximate policies for the POMDPs
with standard action and observation models, 1000 simulation trials were conducted using
the scheme described in Section 11. It was assumed that the agent is equally likely to start
from any state. Average rewards obtained in the original POMDPs M (i.e. without the
help of the oracle) and in the corresponding region-observable POMDPs M0 (i.e. with the
help of the oracle) are shown in the following table.
Environment A
radius-0 radius-1
Average reward in M 0.806535 0.815695
Average reward in M0 0.827788 0.818534
Difference
0.021253 0.002839

Environment B
radius-0 radius-1
0.866118 0.868533
0.883271 0.876356
0.017153 0.007823

We see that, when the radius-0 policies were used, the differences between the rewards
obtained in M and those obtained in M0 are very small in both environments. This indicates
that the radius-0 region observable POMDPs (i.e. MDPs) are accurate approximations of
the original POMDPs. The radius-0 approximate policies are close to optimal for the
original POMDPs. When the radius-1 policies were used, the differences are even smaller;
the rewards obtained in M and those obtained in M0 are essentially the same.
Consider the rewards obtained in the original POMDPs. We see that they are larger
when radius-1 policies were used than when radius-0 policies were used. This supports our
claim that approximation quality increases with radius of region system.
There is a another fact worth mentioning. The differences between rewards obtained in
M and those obtained in M0 are larger in Environment B than in Environment A. This is
because Environment B is more symmetric and consequently observations are less effective
in disambiguating uncertainty in the agent's belief about the state of the world.

13.4 Approximation Quality for Noisy Models

One thousand trials were also conducted for the POMDPs with noisy action and observation models. Results are shown in the following table.
Environment A
radius-0 radius-1
Average reward in M 0.596670 0.634934
Average reward in M0 0.812898 0.722441
Difference
0.214228 0.087507
224

Environment B
radius-0 radius-1
0.445653 0.565099
0.871903 0.818365
0.426250 0.253266

fiModel Approximation for Planning under Uncertainty

We see that the differences between rewards obtained in M and rewards obtained in
M0 are significantly smaller when the radius-1 policies were used than when the radius-0

policies were used. This is the case especially in Environment A. Also the rewards obtained
in M are larger when the radius-1 policies were used than when the radius-0 policies were
used. Those again support our claim that approximation quality increases with radius of
region system.
As far as absolute approximation quality is concerned, the radius-0 POMDPs (i.e.
MDPs) are obviously very poor approximations of the original POMDPs; when the radius-0
policies were used, the rewards obtained in M are significantly smaller than the rewards obtained in M0 . For Environment A, the radius-1 approximation is fairly accurate. However,
the radius-1 approximation remains poor for Environment B. The radius of region system
needs to be increased.
Tracing through the trials step by step, we observed some interesting facts. In Environment B, the agent, under the guidance of the radius-1 approximate policy, was able to
quickly get to the neighborhood of the goal even when starting from far way. The fact
that the Environment around the goal is highly symmetric was the cause of the poor performance. Often the agent was not able to determine whether it was at the goal location
(room), or in the opposite room, or in the left most room, or in the room to the right of
the goal location. The performance would be close to optimal if the goal location had some
distinct features.
In Environment A, the agent, again under the guidance of the radius-1 approximate
policy, was able to reach and declare the goal successfully once it got to the neighborhood.
However, it often took many unnecessarily steps before reaching the neighborhood due to
uncertainty in the effects of the turning actions. For example, when the agent reached
the lower left corner from above, it was facing downward. The agent executed the action
turn_left. Fifteen percent of the time, it ended up facing upward instead of to the right.
The agent then decided to move-forward, thinking that it was approaching the goal. But
it was actually moving upward and did not realize this until a few steps later. The agent
would perform much better if there were informative landmarks around the corners.

14. Conclusions
We propose to approximate a POMDP by using a region observable POMDP. The region
observable POMDP has more informative observations and hence is easier to solve. A
method for determining approximation quality is described, which allows one to make the
tradeoff between approximation quality and computational time by starting with a coarse
approximation and refining it gradually. Simulation experiments have shown that when
there is not much uncertainty in the effects of actions and observations are informative,
a POMDP can be accurately approximated by a region observable POMDP that can be
solved exactly. However, this becomes infeasible as the degree of uncertainty increases.
Other approximate methods need to be incorporated in order to solve region observable
POMDPs whose radiuses are not small.
225

fiZhang & Liu

Acknowledgements

The paper has benefited from discussions with Anthony R. Cassandra and Michael Littman.
We also thank the associate editor Thomas L. Dean and the three anonymous reviewers
for their insightful comments and suggestions and pointers to references. Research was
supported by Hong Kong Research Council under grants HKUST 658/95E and Hong Kong
University of Science and Technology under grant DAG96/97.EG01(RI).

Appendix A: Proofs of Propositions 2 and 3

Lemma 6 Suppose W and X are two sets of state space functions. If W covers X , then
for any non-negative function f (s),

maxff2W

X
s

ff(s)f (s) = maxfi2X

X
s

fi (s)f (s):2

Proof of Proposition 2: Because of Proposition 1 and Lemma 2, it suces to show that
Q0a;o+ covers Qa;o+ . By the definition of Qa;o+ and Equation (10), we have, for any belief
state b, that

X X

Qa;o+ (b) = maxff2V ,1 [

ff(s+ )P (s+; o+ js; a)]b(s)
X
X
=  maxff2V ,1 ff(s+ )[ b(s)P (s+ ; o+ js; a)]
t

s

t

s+

s+

s

Since V^t,1 covers Vt,1 and the term within the square brackets is a non-negative function
of s+, by Lemma 6 we have

X
ff(s+ )[ b(s)P (s+; o+ js; a)]
Xs+ X s
= maxff2V^ ,1 [ ff(s+ )P (s+ ; o+ js; a)]b(s)

Qa;o+ (b) =  maxff2V^ ,1

X

t

t

= Q0a;o+ (b);

s

s+

where the last equation is due to the definition of Q0a;o+ and Equation (10). So, Q0a;o+ does
cover Qa;o+ . The proposition is proved. 2
Lemma 7 For any observation z+=(o+; R+) of the region observable POMDP M0,
P (s+; z+ js; a) = 0;
for any s+ 2= R+ . 2
Informally, this lemma says that the true state of the world must be in the region reported
by the oracle.
Lemma 8 Let W and X be two sets of state space functions and R be a region. If W covers
X in region R, then for non-negative function f (s) that is 0 when s=2R, we have
X
X
maxff2W ff(s)f (s) = maxfi2X fi (s)f (s):2
s

s

226

fiModel Approximation for Planning under Uncertainty

Proof of Proposition 3: Because of Proposition 1 and Lemma 4, it suces to show that
Qa;z+;R covers Qa;z+ in region R, where Qa;z+ is given by (11) with o+ and Vt,1 replaced
by z+ and Ut,1 .
Let b be any belief state in BR . Similar to the proof of Theorem 2, we have
X
X
Qa;z+ (b) =  maxff2U ,1 ff(s+)[ b(s)P (s+; z+js; a)]
t

s+

s

X
ff
(
s
)[
b(s)P (s+ ; z+ js; a)]
+
+ s+
s
X X
= maxff2U^ ,1 + [ ff(s+ )P (s+ ; z+ js; a)]b(s)
s2R s+
X
= maxfi2Q +
fi (s)b(s)
=  maxff2U^ ,1
t

t

a;z

X

;R

;R

;R

s

= Qa;z+ ;R (b);
where the second equation is true because of the fact that U^t,1;R+ covers Ut,1 in region R+
and of Lemma 8. The term within the square brackets is a non-negative function of s+ and
it is 0 when s+2= R+ because of Lemma 7. The fourth equation is true because that b(s)=0
when s=2R. The proposition is proved. 2

Appendix B: Domination and Pruning

This appendix describes implementation of the procedures dominate(ff; W ; R; ), purge(W ; R),
and purge(W ). They were not given in the main text because they are minor adaptations
of existing algorithms.
The procedure dominate(ff; W ; R; ) takes, as inputs, a state space function ff, a set of
state space functions W , a region R, and a nonnegative number . It returns a belief state
b in BR such that ff(b)>W (b)+. If such a belief state does not exist, it returns nil. It can
be implemented as follows.
Procedure dominate(ff; W ; R; )
 Inputs: ff | A state space function,
W | A set of state space functions,
R | A region,  | A nonnegative number.
 Output: A belief state in BR or nil.
1. If W =;, return an arbitrary belief state in BR .
2. Solve the following linear program:
Variables: x, b(s) for each s2R.
Maximize: x
Constraints:
X
X
ff(s)b(s)  x + fi (s)b(s) for all fi 2W ;
s2 R

X

s2R

b(s) = 1

s2 R

b(s)  0 for all s2R:
227

fiZhang & Liu

3. If x, return nil, else return b.
The procedure purge(W ; R) takes a set of state space functions W and a region R
and returns a set of state space functions that parsimoniously covers W in region R. To
implement it, we need two subroutines.
A state space function ff pointwise dominates another state space function fi in a region
R if ff(s)fi (s) for all s2R. The subroutine pointwisePurge(W ; R) returns a minimal
subset W 0 of W such that each state space function in W is pointwise dominated in the
region R by at least one state space function in W 0 . Implementation of this subroutine is
straightforward.
P
The
subroutine
best(b; W ; R) returns a state space function ff in W such that s2R b(s)ff(s) 
P b(s)fi (s) for any other state space function fi in W . Implementation of the subroutine
s2R
is straightforward except for the issue of tie breaking. If the ties are not broken properly,
purge(W ; R) might return a regional covering of W that is not parsimonious. A correct way
to break ties is as follows: Fix an ordering among states in R. This induces a lexicographic
ordering among all state space functions. Among the tied state space functions, chose the
one that is the largest under the lexicographic ordering (Littman, 1994).
The following implementation of purge is based on Lark's algorithm (White, 1991).
Procedure purge(W ; R)

 Inputs: W | A set of state space functions,
R | A region.

 Output: A set of state space functions that parsimoniously covers W in
region R.

1. W pointwisePurge(W ; R).
2. X ;.
3. While W6=;,
(a) Pick a state space function ff from W .
(b) b dominate(ff; X ; R; 0).
(c) If b =nil, remove ff from W .
(d) Else remove best(b; W ; R) from W and add it to X .
4. Return X .
Finally, the procedure purge(W ) takes a set of state space functions W and returns a
parsimonious covering of W . It can be implemented simply as follows.
Procedure purge(W ):



W ; S ).

purge(

Here, S is the set of all possible states of the world.
228

fiModel Approximation for Planning under Uncertainty

References

Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bertsekas, D. P. (1987). Dynamic Programming: Deterministic and Stochastic Models.
Prentice-Hall.
Bertsekas, D. P., & Castanon, D. C. (1989). Adaptive Aggregation for Infinite Horizon
Dynamic Programming. IEEE trans. on auto. control, vol 34, No 6.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structures in policy
construction. In Proceedings of IJCAI-95, 1104-1111.
Boutilier, C., & Poole, D. (1996). Computing optimal policies for partially observable
decision processes using compact representations. In Proceedings of AAAI-96, 11681175.
Brafman, R. I. (1997). A heuristic variable grid solution method for POMDPs. In Proceedings of AAAI-97, 727-733.
Cassandra, A. R. (1994). Optimal polices for partially observable Markov decision processes. TR CS-94-14, Department of Computer Science, Brown University, Providence, Rhode Island 02912, USA.
Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally in partially
observable stochastic domains. In Proceedings of AAAI-94, 1023-1028.
Cassandra, A. R., Kaelbling, L. P., & Kurien, J. (1996). Acting under uncertainty: Discrete Bayesian models for mobile-robot navigation. In Proceedings of IEEE/Robotics
Society of Japan Conference on Intelligent Robotics and Systems (IROS-96).
Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: A simple,
fast, exact method for partially observable Markov decision processes. In Proceedings
of Thirteenth Conference on Uncertainty in Artificial Intelligence, 54-61.
Cheng, H. T. (1988). Algorithms for partially observable Markov decision processes. PhD
thesis, University of British Columbia, Vancouver, BC, Canada.
Dean, T. L., Givan, R., & Leach, S. (1997). Model reduction techniques for computing
approximately optimal solution for Markov decision processes. In Proceedings of the
Thirteenth Conference on Uncertainty in Artificial Intelligence, 124-131.
Dean, T. L., Kaelbling, L. P., Kirman, J., & Nicholson A. (1993). Planning with deadlines
in stochastic domains. In Proceedings of AAAI-93, 574-579.
Dean T. L., & Lin, S. H. (1995). Decomposition techniques for planning in stochastic
domains. TR CS-95-10, Department of Computer Science, Brown University, Providence, Rhode Island 02912, USA.
Dean, T. L., & Wellman, M. P. (1991). Planning and Control. Morgan Kaufmann.
229

fiZhang & Liu

Eagle, J. N. (1984). The optimal search for a moving target when the search path is
constrained. Operations Research, 32(5), 1107-1115.
Hauskrecht, M. (1997). Incremental methods for computing bounds in partially observable
Markov decision processes. In Proceedings of AAAI-97, 734-739.
Littman, M. L. (1994). The witness algorithm: Solving partially observable Markov decision processes. TR CS-94-40, Department of Computer Science, Brown University,
Providence, Rhode Island 02912, USA.
Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Ecient dynamic-programming
updates in partially observable Markov decision processes. TR CS-95-19, Department
of Computer Science, Brown University, Providence, Rhode Island 02912, USA.
Lovejoy, W. S. (1991a). A survey of algorithmic methods for solving partially observable
Markov decision processes. Annals of Operations Research, 28 (1), 47-65.
Lovejoy, W. S. (1991b). Computationally feasible bounds for partially observed Markov
decision processes. Operations Research, 39 (1), 162-175.
Monahan, G. E. (1982). A survey of partially observable Markov decision processes: theory, models, and algorithms. Management Science, 28 (1), 1-16.
Parr, R., & Russell, S. (1995). Approximating optimal polices for partially observable
stochastic domains. In Proceedings of IJCAI-95, 1088-1094.
Platzman, L. K. (1977). Finite-memory estimation and control of finite probabilistic systems. Ph.D. Thesis, Department of Electrical Engineering and Computer Science,
Massachusetts Institute of Technology.
Puterman, M. L. (1990). Markov decision processes. In D. P. Heyman and M. J. Sobel
(eds.), Handbooks in OR & MS., Elsevier Science Publishers, Vol. 2, 331-434.
Sondik, E. J. (1971). The optimal control of partially observable Markov processes. PhD
thesis, Stanford University, Stanford, California, USA.
Sondik, E. J., & Mendelssohn, R. (1979). Information seeking in Markov decision processes,
Southwest Fisheries Center Administrative Report H-79-13, National Marine Fisheries
Service, Honolulu, Hawaii.
White III, C. C. (1991). Partially observed Markov decision processes: A survey. Annals
of Operations Research, 32.
White, D. J. (1993). Markov Decision Processes. John Wiley & Sons.
White III, C. C., & Scherer, W. T., (1994). Finite-memory suboptimal design for partially
observed Markov decision processes. Operations Research, 42(3), 440-455.

230

fiJournal of Artificial Intelligence Research 7 (1997) 6782

Submitted 5/97, published 9/97

Identifying Hierarchical Structure in Sequences:
A linear-time algorithm
Craig G. Nevill-Manning
Ian H. Witten
Department of Computer Science
University of Waikato, Hamilton, New Zealand.

CGN@CS.WAIKATO.AC .NZ
IHW@CS.WAIKATO.AC .NZ

Abstract
S EQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols
by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing
this process recursively. The result is a hierarchical representation of the original sequence, which
offers insights into its lexical structure. The algorithm is driven by two constraints that reduce the
size of the grammar, and produce structure as a by-product. S EQUITUR breaks new ground by
operating incrementally. Moreover, the methods simple structure permits a proof that it operates
in space and time that is linear in the size of the input. Our implementation can process 50,000
symbols per second and has been applied to an extensive range of real world sequences.

1. Introduction
Many sequences of discrete symbols exhibit natural hierarchical structure. Text is made up of
paragraphs, sentences, phrases, and words. Music is composed from major sections, motifs, bars,
and notes. Records of user interface behavior encode the hierarchical structure of tasks that users
perform. Computer programs constitute modules, procedures, and statements. Discovering the
natural structure that underlies sequences is a challenging and interesting problem that has a wide
range of applications, from phrase discovery to music analysis, from programming by
demonstration to code optimization.
The search for structure in sequences occurs in many different fields. Adaptive text
compression seeks models of sequences that can be used to predict upcoming symbols so that
they can be encoded efficiently (Bell et al., 1990). However, text compression models are
extremely opaque, and do not illuminate any hierarchical structure in the sequence. Grammatical
inference techniques induce grammars from a set of example sentences, possibly along with a set
of negative examples (Gold, 1967; Angluin, 1982; Berwick and Pilato, 1987). However, it is
crucial to their operation that the input is not a continuous stream but is segmented into sentences,
which are, in effect, independent examples of the structure being sought. A brief review of
pertinent systems appears in Section 8. Techniques of Markov modeling and hidden Markov
modeling make no attempt to abstract information in hierarchical form (Rabiner and Juang, 1986,
Laird and Saul, 1994). Sequence learning also occurs in areas such as automaton modeling
(Gaines, 1976), adaptive systems (Andreae, 1977), programming by demonstration (Cypher,
1993), and human performance studies (Cohen et al., 1990), but generally plays only a peripheral
role.
In this paper we describe SEQUITUR, an algorithm that infers a hierarchical structure from a
sequence of discrete symbols. The basic insight is that phrases which appear more than once can
be replaced by a grammatical rule that generates the phrase, and that this process can be
continued recursively, producing a hierarchical representation of the original sequence. The result
 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved

fiNEVILL-MANNING & WITTEN

is not strictly a grammar, for the rules are not generalized and generate only one string. (It does
provide a good basis for inferring a grammar, but that is beyond the scope of this paper.) A
scheme that resembles the one developed here arose from work in language acquisition (Wolff,
1975, 1977, 1980, 1982), but it operated in time that is quadratic with respect to the length of the
input sequence, whereas the algorithm we describe takes linear time. This has let us investigate
sequences containing several million tokensin previous work the examples were much smaller,
the largest mentioned being a few thousand tokens. Another difference, which is of crucial
importance in some practical applications, is that the new algorithm works incrementally. We
return to Wolffs scheme, and compare it with SEQUITUR, in Section 8.
The ability to deal easily with long sequences has greatly extended the range of SEQUITURs
application. We have applied it to artificially-generated fractal-like sequences produced by Lsystems, and, along with a unification-based rule generalizer, used it to recover the original Lsystem. The same method has inferred relatively compact deterministic, context-free grammars
for million-symbol sequences representing biological objects obtained from stochastic, contextsensitive, L-systems, which has in turn greatly speeded the graphical rendering of such objects.
We have applied SEQUITUR to 40 Mbyte segments of a digital library to generate hierarchical
phrase indexes for the text, which provides a novel method of browsing (Nevill-Manning et al.,
1997). The algorithm compresses multi-megabyte DNA sequences more effectively than other
general-purpose compression algorithms. Finally, with some post-processing, it has elicited
structure from a two million word extract of a genealogical database, successfully identifying the
structure of the database and compressing it much more efficiently than the best known
algorithms. We touch on some of these applications in Section 3 below; Nevill-Manning (1996)
describes them all.
This paper describes the SEQUITUR algorithm and evaluates its behavior. The next section
gives a concise description of the algorithm in terms of constraints on the form of the output
grammar. Section 3 gives a taste of the kind of hierarchies that SEQUITUR is capable of inferring
from realistic sequences. Section 4 describes the implementation in more detail, with particular
emphasis on how it achieves efficiency. Section 5 shows that the run time and storage
requirements are linear in the number of input symbols, while Section 6 discusses the algorithms
behavior on extreme input strings. We end with a quantitative analysis of SEQUITURs
performance on several example sequences, and a review of related research.

2. The SEQUITUR Algorithm
SEQUITUR forms a grammar from a sequence based on repeated phrases in that sequence. Each
repetition gives rise to a rule in the grammar, and the repeated subsequence is replaced by a nonterminal symbol, producing a more concise representation of the overall sequence. It is this
pursuit of brevity that drives the algorithm to form and maintain the grammar, and, as a byproduct, provide a hierarchical structure for the sequence.
At the left of Figure 1a is a sequence that contains the repeating string bc. Note that the
sequence is already a grammara trivial one with a single rule. To compress it, SEQUITUR forms
a new rule A  bc, and A replaces both occurrences of bc. The new grammar appears at the right
of Figure 1a.
The sequence in Figure 1b shows how rules can be reused in longer rules. The longer
sequence consists of two copies of the sequence in Figure 1a. Since it represents an exact

68

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

repetition, compression can be achieved by forming the rule A  abcdbc to replace both halves
of the sequence. Further gains can be made by forming rule B  bc to compress rule A. This
demonstrates the advantage of treating the sequence, rule S, as part of the grammarrules may
be formed from rule A in an analogous way to rules formed from rule S. These rules within rules
constitute the grammars hierarchical structure.
The grammars in Figures 1a and 1b share two properties:
p 1 : no pair of adjacent symbols appears more than once in the grammar;
p 2 : every rule is used more than once.
Property p 1 requires that every digram in the grammar be unique, and will be referred to as
digram uniqueness. Property p2 ensures that each rule is useful, and will be called rule utility.
These two constraints exactly characterize the grammars that SEQUITUR generates.
Figure 1c shows what happens when these properties are violated. The first grammar contains
two occurrences of bc, so p1 does not hold. This introduces redundancy because bc appears twice.
In the second grammar, rule B is used only once, so p 2 does not hold. If it were removed, the
grammar would become more concise. The grammars in Figures 1a and 1b are the only ones for
which both properties hold for each sequence. However, there is not always a unique grammar
with these properties. For example, the sequence in Figure 1d can be represented by both of the
grammars on its right, and they both obey p 1 and p2 . We deem either grammar to be acceptable.
Repetitions cannot overlap, so the string aaa does not give rise to any rule, despite containing two
digrams aa.
SEQUITURs operation consists of ensuring that both properties hold. When describing the
algorithm, the properties act as constraints. The algorithm operates by enforcing the constraints
on a grammar: when the digram uniqueness constraint is violated, a new rule is formed, and when
the rule utility constraint is violated, the useless rule is deleted. The next two subsections describe
how this occurs.
2.1 Digram Uniqueness
When SEQUITUR observes a new symbol, it appends it to rule S. The last two symbols of rule S
the new symbol and its predecessorform a new digram. If this digram occurs elsewhere in the
grammar, the first constraint has been violated. To restore it, a new rule is formed with the digram
on the right-hand side, headed by a new non-terminal symbol. The two original digrams are
replaced by this non-terminal symbol.
Sequence

Grammar

a

S  abcdbc

S  aAdA
A  bc

c

S  abcdbcabcdbc

S  AA
A  abcdbc

Sequence

Grammar

b

S  abcdbcabcdbc

S  AA
A  aBdB
B  bc

d

S  aabaaab

S  AaA
A  aab

S  CC
A  bc
B  aA
C  BdA

S  AbAab
A  aa

Figure 1 Example sequences and grammars that reproduce them: (a) a
sequence with one repetition; (b) a sequence with a nested repetition; (c)
two grammars that violate the two constraints; (d) two different grammars
for the same sequence that obey the constraints.

69

fiNEVILL-MANNING & WITTEN

Table 1 shows the grammars that result when successive symbols of the sequence
abcdbcabcd are processed. The second column shows the sequence observed so far, the third
column gives the grammar created from the sequence, and the fourth column notes constraints
that have been violated, and actions that are taken to resolve the violations.
When SEQUITUR adds the final c at symbol 6, the digram bc appears twice. SEQUITUR creates
the new rule A, with bc as its right-hand side, and replaces the two occurrences of bc by A. This
illustrates the basic procedure for dealing with duplicate digrams.
The appearance of a duplicate digram does not always result in a new rule. If the new digram
appears as the right-hand side of an existing rule, then no new rule need be created: the nonterminal symbol that heads the existing rule replaces the digram. After symbol 9 in Table 1, a
third bc appears, and the existing non-terminal symbol A replaces the third occurrence of bc. This
results in a new pair of repeating digrams, aA, shown in the next line of Table 1. SEQUITUR
accordingly forms a new rule B, which replaces the two occurrences of aA. SEQUITUR creates and
maintains the hierarchy by an iterative process: the substitution of A for bc results in the new
digram aA, which is itself replaced by B. For larger sequences, these changes ripple through the
grammar, forming and matching longer rules higher in the hierarchy.
symbol
number

the string so
far

resulting
grammar

remarks

1

a

Sa

2

ab

S  ab

3

abc

S  abc

4

abcd

S  abcd

5

abcdb

S  abcdb

6

abcdbc

S  abcdbc

bc appears twice

S  aAdA
A  bc

enforce digram uniqueness

7

abcdbca

S  aAdAa
A  bc

8

abcdbcab

S  aAdAab
A  bc

9

abcdbcabc

S  aAdAabc
A  bc

bc appears twice

S  aAdAaA
A  bc

enforce digram uniqueness.
aA appears twice

S  BdAB
A  bc
B  aA

enforce digram uniqueness

S  BdABd
A  bc
B  aA

Bd appears twice

S  CAC
A  bc
B  aA
C  Bd

enforce digram uniqueness.
B is only used once

S  CAC
A  bc
C  aAd

enforce rule utility

10

abcdbcabcd

Table 1 Operation of the two grammar constraints,
digram uniqueness and rule utility

70

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

2.2 Rule Utility
Until now, the right-hand sides of rules in the grammar have been only two symbols long. Longer
rules are formed by the effect of the rule utility constraint, which ensures that every rule is used
more than once. In Table 1, symbol 10 demonstrates this idea. When d is appended to rule S, the
new digram Bd causes a new rule, C, to be formed. However, forming this rule leaves only one
appearance of rule B, violating the second constraint. For this reason, B is removed from the
grammar, and its right-hand side is substituted in the one place where it occurs. Removing B
means that rule C now contains three symbols. This is the mechanism for forming long rules:
form a short rule temporarily, and if subsequent symbols continue the match, allow a new rule to
supersede the shorter one and delete the latter. Although this creation and deletion of rules
appears inefficient at first glance, it can be performed efficiently with the appropriate data
structures. More importantly, it keeps track of long matches within the grammar, obviating the
need for external data structures. This simplifies the algorithm considerably, permitting a concise
proof of its linear time complexity (see Section 5).

3. Structures Inferred From Realistic Sequences
Having described the mechanism by which SEQUITUR builds a grammar, and before embarking
on efficiency issues, it is instructive to consider the structures that this simple technique can infer
from realistic sequences. In each case we applied SEQUITUR to a large sample and then excerpted
part of the structure for illustrative purposes.
Figures 2a, 2b and 2c show parts of three hierarchies inferred from the text of the Bible in
English, French, and German. The hierarchies are formed without any knowledge of the preferred
structure of words and phrases, but nevertheless capture many meaningful regularities. In
Figure 2a, the word beginning is split into begin and ninga root word and a suffix. Many words
and word groups appear as distinct parts in the hierarchy (spaces have been made visible by
replacing them with bullets). The same algorithm produces the French version in Figure 2b,
where commencement is split in an analogous way to beginninginto the root commence and the
suffix ment. Again, words such as Au, Dieu and cieux are distinct units in the hierarchy. The
German version in Figure 2c correctly identifies all words in the sentence, as well as the phrase
die Himmel und die. In fact, the hierarchy for the heaven and the in Figure 2a bears some
similarity to the German equivalent.
The London/Oslo-Bergen corpus (Johansson et al., 1978) contains 1.2 million words tagged
with word classes. For example, the sentence Most Labour sentiment would still favour the
abolition of the House of Lords is tagged with the classes determiner noun noun auxiliary adverb
verb article noun preposition article noun preposition noun. The hierarchy that SEQUITUR infers
from the word classes corresponds to a possible parse of each sentence in the corpus, because it is
a tree expressed in terms of parts of speech. Figure 2d shows part of the inferred hierarchy, where
the tags have been replaced by the actual words from the text. SEQUITUR identifies the middle
part of the sentence, sentiment would still favour the abolition as a large block, and this part could
stand on its own as a grammatical sentence. The adjectival phrase of the House of Lords also
appears as a distinct unit, as does Most Labour, an adjectival phrase that precedes the subject.
Figure 2e shows two Bach chorales from which SEQUITUR has detected both internal
repetitionsthe light gray boxes show that the two halves of the first chorale are almost
identicaland repetitions between chorales, as denoted by the gray box in the second half of the

71

fiNEVILL-MANNING & WITTEN

a

I n  t h e  b e g i n n i n g  G o d  c r e a t e d  t h e  h e a v e n  a n d  t h e  e a r t h

b

 A u  c o m m e n c e m e n t ,  D i e u  c r  a  l e s  c i e u x  e t  l a  t e r r e

c

xx

 I m  A n f a n g  s c h u f  G o t t  d i e  H i m m e l  u n d  d i e  E r d e

d

Most Labour sentiment would still favour the abolition of the House of Lords

e

imperfect

perfect

Figure 2 Hierarchies for various sequences: Genesis 1:1 in (a) English, (b) French, and (c) German;
(d) grammatical parse inferred from a sequence of word classes; and (e) repetitions within and
between two chorales harmonized by J.S. Bach.
second chorale. The section in the white box occurs in all four halves. Also, by detecting repeated
motifs between many chorales, SEQUITUR identifies the imperfect and perfect cadences at the end
of the first and second halves, respectively. In general, SEQUITUR is capable of making plausible
inferences of lexical structure in sequences, so that the hierarchies it produces aid comprehension
of the sequence.

4. Implementation Issues
The SEQUITUR algorithm operates by enforcing the digram uniqueness and rule utility constraints.
It is essential that any violation of these constraints be detected efficiently, and in this section we
will describe the mechanisms that fulfill this requirement.
The choice of an appropriate data structure depends on the kind of operations that need to be
performed to modify the grammar. For SEQUITUR these are:
 appending a symbol to rule S;
 using an existing rule;
 creating a new rule; and
 deleting a rule.
Appending a symbol involves lengthening rule S. Using an existing rule involves substituting a
non-terminal symbol for two symbols, thereby shortening the rules containing the digrams.
Creating a new rule involves creating a new non-terminal symbol for the left-hand side, and
72

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

A

B

c

B

a

b

d
cd
digram
Bc
index
ab

Figure 3 Data structures for rules and digram index
inserting two new symbols as the right-hand side. After creating the rule, substitutions are made
as for an existing rule by replacing the two digrams with the new non-terminal symbol. Deleting a
rule involves moving its contents to replace a non-terminal symbol, which lengthens the rule
containing the non-terminal symbol; the left-hand side of the rule must then be deleted.
To ensure that rules can be lengthened and shortened efficiently, SEQUITUR represents a rule
using a doubly-linked list whose start and end are connected to a single guard node, shown for
two rules A and B in Figure 3. The guard node also serves as an attachment point for the left-hand
side of the rule, because it remains constant even when the rule contents change. Each nonterminal symbol also points to the rule it heads, shown in Figure 3 by the pointer from the nonterminal symbol B in rule A to the head of rule B. With these pointers, no arrays are necessary for
accessing rules or symbols, because operations only affect adjacent symbols or rules headed by a
non-terminal.
The rule utility constraint demands that a rule be deleted if it is referred to only once. Each
rule has an associated reference count, which is incremented when a non-terminal symbol that
references the rule is created, and decremented when the non-terminal symbol is deleted. When
the reference count falls to one, the rule is deleted.
The digram uniqueness constraint is more difficult to enforce. When a new digram appears,
SEQUITUR must search the grammar for any other occurrence of it. One simple solution would be
to scan the entire grammar each time looking for a match, but this is inefficient and leads to a
quadratic-time algorithm. A better solution requires an index that is efficient to search.
The data structure for storing the digram index must permit fast access and efficient addition
and deletion of entries. A hash table provides constant-time access, and adding and deleting
entries requires little extra work. Because no digram appears more than once, the table need only
contain a pointer to the first symbol of the single matching digram in the grammar data structure,
as shown in Figure 3. The hash table consists of a simple array of pointers, and collisions are
handled by open addressing to avoid the allocation of memory that chaining requires (Knuth,
1968).
Every time a new digram appears in the grammar, SEQUITUR adds it to the index. A new
digram appears as a result of two pointer assignments linking two symbols together in the doublylinked list (one forward pointer and one back pointer). Thus updating the index can be
incorporated into the low-level pointer assignments. A digram also disappears from the grammar
when a pointer assignment is madethe pointer value that is overwritten by the assignment
represents a digram that no longer exists.
To demonstrate the mechanism for updating the hash table when a new rule is created, Table
2 shows the example in Figure 1a, with the addition of the contents of the digram index. When
the second c is appended to rule S, the digram table shows that bc already exists in the grammar,
so the rule A  bc is created. Creating the link between b and c in the right-hand side for rule A
updates the entry in the index for bc to point to its new locationthe hash table now contains a
pointer to the symbol b at the start of rule A. Next, the first bc is removed. This breaks the link
between the b in the digram and the preceding symbol a, so ab is removed from the index. It also
73

fiNEVILL-MANNING & WITTEN

Action

grammar

observe symbol c

S  abcdbc

change in digrams

digram index

make new rule A

S  abcdbc
A  bc

bc updated

{ab, bc, cd, db}

substitute A for bc

S  aAdbc
A  bc

ab, cd removed,
aA, Ad added

{bc, db, aA, Ad}

substitute A for bc

S  aAdA
A  bc

db removed,
dA added

{bc, dA, aA, Ad}

{ab, bc, cd, db}

Table 2 Updating the digram index as links are made and broken
breaks the link between c and the following d, so cd is removed from the index. Next, A replaces
bc, creating links between a and A, as well as between A and d, adding these digrams to the index.
This process continues, resulting in a correct index of digram pointers, but costing just one
indexing operation per two pointer operations.
Next, SEQUITUR requires an efficient strategy for checking the digram index. Rechecking the
entire grammar whenever a symbol is added is infeasible, and inefficient if large portions of the
grammar are unchanged since the last check. In fact, the only parts that need checking are those
where links have been made or broken. That is, when any of the actions that affect the
maintenance of the digram table are performed, the newly created digrams should be checked in
the index. Of course, every time a link is created, the digram is entered into the index, and this is
the very time to check for a duplicate. If an entry is found to be already present while attempting
to add a new digram to the index, a duplicate digram has been detected and the appropriate
actions should be performed. Therefore, only one hash table lookup is required for both accessing
and updating the digram index.

5. Computational Complexity
In this section, we show that the SEQUITUR algorithm is linear in space and time. The complexity
proof is an amortized oneit does not put a bound on the time required to process one symbol,
but rather bounds the time taken for the whole sequence. The processing time for one symbol can
in fact be as large as O( n ), where n is the number of input symbols so far. However, the
pathological sequence that produces this worst case requires that the preceding O( n ) symbols
involve no formation or matching of rules.
The basic idea of the proof is that the two constraints both have the effect of reducing the
action
1

As each new input symbol is observed, append it to rule S.

1

2
3
4
5
6
7
8
9

Each time a link is made between two symbols
if the new digram is repeated elsewhere and the repetitions do not overlap,
if the other occurrence is a complete rule,
replace the new digram with the non-terminal symbol that heads the rule,
otherwise,
form a new rule and replace both digrams with the new non-terminal symbol
otherwise,
insert the digram into the index

2

10
11
12

Each time a digram is replaced by a non-terminal symbol
if either symbol is a non-terminal symbol that only occurs once elsewhere,
remove the rule, substituting its contents in place of the other non-terminal symbol

Table 3 The SEQUITUR algorithm

74

3
4

5

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

number of symbols in the grammar, so the work done satisfying the constraints is bounded by the
compression achieved on the sequence. The savings cannot exceed the original size of the input
sequence, so the algorithm is linear in the number of input symbols.
Table 3 gives pseudo-code for the SEQUITUR algorithm. Line 1 deals with new observations
in the sequence, lines 2 through 9 enforce the digram utility constraint, and lines 10 through 12
enforce rule utility. The on-line appendix contains an implementation of SEQUITUR in Java, which
requires about 400 lines for the algorithm.
The numbers at the right of Table 3 identify the main sections of the algorithm, and the proof
will demonstrate bounds on the number of times that each of them executes. Action 1 appends
symbols to rules S and is performed exactly n times, once for every symbol in the input. Link
creation triggers action 2. Action 3 uses an existing rule, action 4 forms a new rule, and action 5
removes a rule.
Table 4 shows examples of actions 3, 4, and 5, and the associated savings in grammar size.
The savings are calculated by counting the number of symbols in the grammar before and after
the action. The non-terminal symbols that head rules are not counted, because they can be
recreated based on the order in which the rules occur. Actions 3 and 5 are the only actions that
reduce the number of symbols. There are no actions that increase the size of the grammar, so the
difference between the size of the input and the size of the grammar must equal the number of
times that both these actions have been taken.
Now that we have set the stage, we can proceed with the proof. More formally, let
n be the size of the input string,
o be the size of the final grammar,
r be the number of rules in the final grammar,
a 1 be the number of times new symbol is seen (action 1),
a 2 be the number of times a new digram is seen (action 2),
a 3 be the number of times an existing rule is used (action 3),
a 4 be the number of times a new rule is formed (action 4), and
a 5 be the number of times a rule is removed (action 5).
According to the reasoning above, the reduction in the size of the grammar is the number of times
actions 3 and 5 are executed. That is,
(1)
n  o = a3 + a5.
Next, the number of times a new rule is created (action 4) must be bounded. The two actions that
affect the number of rules are 4, which creates rules, and 5, which deletes them. The number of
rules in the final grammar must be the difference between the frequencies of these actions:
r = a4  a5.
In this equation, r is known and a5 is bounded by equation (1), but a 4 is unknown. Noting that a1 ,
the number of times a new symbol is seen, is equal to n, the total work is
action

before

after

saving

Matching existing rule

3

...ab...
A  ab

...A...
A  ab

1

Creating new rule

4

...ab...ab...

...A...A...
A  ab

0

Deleting a rule

5

...A...
A  ab

...ab...

1

Table 4 Reduction in grammar size for the three grammar operations

75

fiNEVILL-MANNING & WITTEN

a 1 + a 2 + a 3 + a 4 + a 5 = n + a 2 + (n  o) + (r + a 5 ) .
To bound this expression, note that the number of rules must be less than the number of symbols
in the final grammar, because each rule contains at least two symbols, so that
r < o.
Also, from expression (1) above, we have
a5 = n  o  a3 < n.
Consequently,
a 1 + a 2 + a 3 + a 4 + a 5 = 2n + (r  o) + a5 + a 2 < 3n +a 2 .
The final operation to bound is action 2, which checks for duplicate digrams. Searching the
grammar is done by hash table lookup. Assuming an occupancy less than, say, 80% gives an
average lookup time bounded by a constant (Knuth, 1967). This occupancy can be assured if the
size of the sequence is known in advance, or by enlarging the table and recreating the entries
whenever occupancy exceeds 80%. The number of entries in the table is just the number of
digrams in the grammar, which is the number of symbols in the grammar minus the number of
rules in the grammar, because symbols at the end of a rule do not form the left hand side of any
digram. Thus the size of the hash table is less than the size of the grammar, which is bounded by
the size of the input. This means that the memory requirements of the algorithm are linear. In
practice, the linear growth of memory poses a problem. One strategy that we are currently
investigating is to break the input into small segments, form grammars from each of them, and
merge the resulting grammar.
As for the number of times that action 2 is carried out, a digram is only checked when a new
link is created. Links are only created by actions 1, 3, 4 and 5, which have already been shown to
be bounded by 3n, so the time required for action 2 is also O(n).
Thus we have shown that the algorithm is linear in space and time. However, this claim must
be qualified: it is based on a register model of computation rather than a bitwise one. We have
assumed that the average lookup time for the hash table of digrams is bounded by a constant.
However, as the length of the input increases, the number of rules increases without bound, and
for unstructured (e.g., random) input, the digram table will grow without bound. Thus the time
required to execute the hash function and perform addressing will not be constant, but will
increase logarithmically with the input size. Our proof ignores this effect: it assumes that hash
function operations are register-based and therefore constant time. In practice, with a 32-bit
architecture, the linearity proof remains valid for sequences of up to around 109 symbols, and for
a 64-bit architecture up to 1019 symbols.

6. Exploring the Extremes
Having described SEQUITUR algorithmically, we now characterize its behavior in a variety of
domains. This section explores how large or small a grammar can be for a given sequence length,
as well as determining the minimum and maximum amount of work the algorithm can carry out
and the amount of work required to process one symbol. Figure 4 summarizes these extreme
cases, giving part of an example sequence and the grammar that results. Bounds are given in
terms of n, the number of symbols in the input.
The deepest hierarchy that can be formed has depth O( n ), and an example of a sequence
that creates such a hierarchy is shown in Figure 4a. In order for the hierarchy to deepen at every
rule, each rule must contain a non-terminal symbol. Furthermore, no rule need be longer than two

76

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

symbols. Therefore, to produce a deep hierarchy from a short string, each rule should be one
terminal symbol longer than the one on which it builds. In order to create these rules, the string
represented must appear in two different contexts; otherwise the rule will be incorporated into a
longer rule. One context is the deepest hierarchy, in which it must participate. The other context
should not be in any hierarchy, to reduce the size of the input string, so it should appear in rule S.
Note that every rule in Figure 4a appears both in the hierarchy and in rule S. At each repetition of
the sequence, one terminal symbol is appended, producing a new level in the hierarchy. There is
no point in including a repetition of length one, so the mth repetition has length m + 1. This
repetition gives rise to the mth rule (counting rule S). The total length of the sequence for a
hierarchy of depth m is therefore
n = 2 + 3 + 4 + ... + (m + 1) = O(m2)
and the deepest hierarchy has depth m = O( n ).
At the other end of the spectrum, the grammar with the shallowest hierarchy, shown in
Figure 4b, has no rules apart from rule S. This grammar is also the largest possible one for a
sequence of a given length, precisely because no rules can be formed from it. The sequence that
gives rise to it is one in which no digram ever recurs. Of course, in a sequence with an alphabet of
size ||, there are only O(||2) different digrams, which bounds the length of such a sequence.
This kind of sequence produces the worst case compression: there are no repetitions, and
therefore SEQUITUR detects no structure.
bound

example sequence

example grammar

a

deepest hierarchy

O(n)

ababcabcdabcdeabcdef

S  ABCDDf
A  ab
B  Ac
C  Bd
D  Ce

b

largest grammar;
shallowest hierarchy

n

aabacadae...bbcbdbe...

S  aabacadae...

c

smallest grammar

O(log n)

aaaaaaaaaaaaaa...

S  DD
A  aa
B  AA
C  BB
D  CC

d

largest number of rules

n/4

aaaaababacacadad...

S  AABBCCDD
A  aa
B  ab
C  ac
D  ad

e

maximum processing for
one symbol

O(n)

yzxyzwxyzvwxy

S  ABwBvwxy
A  yz
B  xA

f

greatest number of rule
creations and deletions

n new rules
n deleted rules

abcdeabcdeabcde...

S  AAA...
A  abcde

Figure 4 Some extreme cases for the algorithm

77

fiNEVILL-MANNING & WITTEN

Turning from the largest grammar to the smallest, Figure 4c depicts the grammar formed
from the most ordered sequence possibleone consisting entirely of the same symbol. When four
contiguous symbols appear, such as aaaa, a rule B  aa is formed. When another four appear,
rule S contains BBBB, forming a new rule C  BB. Every time the number of symbols doubles, a
new rule is created. The hierarchy is thus O(log n) deep, and the grammar is O(log n) in size. This
represents the greatest data compression possible, although it is not necessary to have a sequence
of only one symbol to achieve this logarithmic lower boundany recursive structure will do.
To produce the grammar with the greatest number of rules, each rule should only include
terminal symbols, because building a hierarchy will reduce the number of rules required to cover
a sequence of a given size. Furthermore, no rule should be longer than two symbols or occur
more than twice. Therefore each rule requires four symbols for its creation, so the maximum
number of rules for a sequence of length n is n/4, as shown in Figure 4d.
Having discussed the size of grammars, we can now consider the effort involved in
maintaining them. We have shown that the upper bound for processing a sequence is linear in the
length of the sequence. However, it is still useful to characterize the amount of processing
involved for each new symbol. Figure 4e shows a sequence where the repetition is built up as yz,
then xyz, then wxyz, and so forth. Just before the second occurrence of wxyz appears, no matches
have been possible for the w, x, and y. When z appears, yz matches rule A, then xA matches rule B.
Finally, SEQUITUR forms a new rule for wB. This cascading effect can be arbitrarily large if the
repetitions continue to build up in this right-to-left fashion. The amount of processing required to
deal with the last z is proportional to the depth of the deepest hierarchy, as the matching cascades
up the hierarchy. The maximum time to process one symbol is therefore O( n ). The fact that w,
x, and y fail to match means that they require little time to process, preserving the overall linear
time bound.
Although the bound is linear, sequences certainly differ in the proportion of work to sequence
length. The sequence in Figure 4b, where no repetitions exist and no grammar is formed,
minimizes this ratio. The sequence in Figure 4f, which consists of multiple repetitions of a multisymbol sequence, maximizes it. Each time the repetition appears there are several rule deletions
and creations as the match lengthens. In fact, every symbol except a incurs a rule creation and a
subsequent deletion, so there are O(n) creations and deletions. If m is the length of the repetition,
the proportion of symbols that do not incur this work is 1/m, which tends toward zero as the
repetition length approaches infinity.

7. Behavior in Practice
To give an idea of how SEQUITUR behaves on realistic sequences, we turn from artificial cases to
a sequence of English text. Figure 5a plots the number of rules in the grammar against the number
of input symbols for a 760,000 character English novel, and shows that the increase is
approximately linear. Figure 5b shows the approximately linear growth of the total number of
symbols in the grammar. The growth of the number of unique words in the text, shown in
Figure 5c, is high at the start and drops off toward the end. Zobel, et al. (1995) have observed in
much larger samples of English text thatsurprisinglynew words continue to appear at a fairly
constant rate, corresponding not just to neologisms but to names, acronyms, and typographical
errors. In this example, the number of rules grows linearly because, once words have been
recognized, multi-word phrases are constructed, and the number of such phrases is unbounded.

78

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

The nearly linear growth of the number of symbols in the grammar seems disappointing, but is in
fact an inevitable consequence of the information content of English. Since symbols at the end of
the text convey a similar amount of information as symbols at the beginning, there is a lower
bound on the achievable compression rate. For English text, this corresponds to the entropy of
English.
S EQUITUR operates very quicklyas shown in Figure 5d, the 760,000 character novel is
processed in 16 seconds: a rate of 50,000 symbols per second, or 3 Mb per minute. The figure
also illustrates SEQUITURs linear-time behavior in practice. The sequence in Figure 4b, where no
repetitions exist and no rules are formed, should be fast to process, and indeed it is processed at a
rate of 150,000 symbols per secondthree times faster than the novel. The sequence in Figure 4f,
which consists of multiple repetitions of a multi-symbol sequence, slows performance to 14,000
symbols per seconda ten-fold decrease from the fastest sequence. The sequence in Figure 4c,
which consists of many repetitions of a single character and forms a concise grammar, comes in
at 50,000 symbols per second; about the same as the novel. All measurements were performed on
a Silicon Graphics Indigo 2.
S EQUITUR is an effective data compression scheme that outperforms other schemes that
achieve compression by factoring out repetition, and approaches the performance of schemes that
a

b

200000

symbols in grammar

rules in grammar

30000

20000

10000

150000

100000

50000

0

0
0

c

200000

400000 600000
input symbols

800000

d

10000

5000

200000

400000 600000
input symbols

800000

0

200000

400000 600000
input symbols

800000

15

time (seconds)

vocabulary size

15000

0

10

5

0

0
0

200000

400000 600000
input symbols

800000

Figure 5 Growth rates on English text: (a) rules in the grammar; (b) symbols in the
grammar; (c) vocabulary size in the input; and (d) time

79

fiNEVILL-MANNING & WITTEN

compress based on probabilistic predictions. SEQUITURs implementation and evaluation as a
compression scheme is described by Nevill-Manning and Witten (1997).

8. Related Work
As mentioned in the introduction, this research resembles work by Wolff (1975). Having
described SEQUITUR, it is now possible to contrast it with Wolffs system, MK10, which processes
a sequence from left to right, and forms a chunk (equivalent to a SEQUITUR rule) whenever a
digram is seen more than 10 times. When this happens, all occurrences of the digram are replaced
with a non-terminal symbol, and the system either carries on in the sequence, or restarts from the
beginning. In either case, digram frequencies are discarded and the process starts over. The worst
case for this algorithm corresponds to the sequence in Figure 4f, where there are long exact
repetitions. Each symbol in the repeated segment gives rise to a chunk, and the process starts
over. In Figure 4f, the length of the repetition is linear in the length of the sequence, and the
number of restarts is the length of the repetition, so the algorithm is quadratic in the length of the
sequence. This makes processing of million-symbol sequences impractical.
A number of systems, by Langley (1994), Stolcke and Omohundro (1994), and Cook et al.
(1976), form new grammar rules from repeated sequences, and also merge rules to generalize
grammars. However, they operate in a different domainas input, they expect a set of sentences
drawn from a language, rather than a single long sequence. This allows them to make inferences
based on directly comparing corresponding parts of different sequences. Furthermore, the small
size of the training data means that efficiency is of lesser concern. The performance of these
algorithms is measured by their ability to accept test sentences from the language, and to reject
new sentences that are not in the target languages. In SEQUITURs case, where there is only one
sequence available, this metric does not apply.
VanLehn and Ball (1987) also infer grammars from sets of sentences. Their algorithm
enforces three constraints on grammars for the purpose of making a version space finite. They
are: (1) no rule has an empty right side, (2) if a rule has just one symbol on its right side, the
symbol is a terminal, and (3) every non-terminal appears in a derivation of some string. These
constraints are reminiscent of SEQUITURsfor example, the third constraint is a weaker form of
SEQUITURs rule utilitybut serve a different purpose. In SEQUITUR, they are operational; they
drive the formation of the grammar. In VanLehn and Balls work, they make the version space
tractable by providing sensible restrictions on the form of the grammar, and the algorithm itself is
a search through the space.

9. Conclusion
This paper has presented S EQUITUR , an algorithm for identifying hierarchical structure in
sequences. Based on the idea of abstracting subsequences that occur more than once into rules
and continuing this operation recursively, the algorithm works by maintaining two constraints:
every digram in the grammar must be unique, and every rule must be used more than once.
S EQUITUR operates incrementally and, subject to a caveat about the register model of
computation used, in linear space and time. This efficiency has permitted its application to long
sequencesup to 40 Mbytein many different domains.
We have not evaluated the prediction accuracy of S EQUITUR in this paper. Evaluating
prediction accuracy is a fairly complex business. It is not adequate simply to give a count of
80

fiI NFERRING SEQUENTIAL STRUCTURE FROM SEQUENCES

correct versus incorrect predictions, because doing this begs the question of the likelihood of
different ones occurring. Prediction schemes can assign probabilities to all the predictions they
might offer, and should be judged on the discrepancy between their probabilistic predictions and
the true upcoming symbols. The whole question of accurate probabilistic prediction of sequences
is tantamount to the compression of sequences, a substantial field in its own right (Bell et al.,
1990). We have in fact evaluated SEQUITURs performance in compression and found that it vies
with the best compression algorithms, particularly when a large amount of text is available
(Nevill-Manning and Witten, 1997). But the point of the present paper is a different one: that
SEQUITUR re-represents a sequence in a way that exposes its underlying structure. It is fair to say
that no other compression algorithm produces a representation that is in any way perspicuous.
Perhaps the greatest drawback to the SEQUITUR algorithm is its memory usage, which is
linear in the size of grammar. Linear memory complexity is ordinarily considered intractable,
although in practice S EQUITUR works well on sequences of rather impressive size. There is
clearly room for approximate versions of the algorithm that partition the input and re-merge the
grammars formed from them, and this could perhaps be applied recursively to create an algorithm
with logarithmic memory requirements. We conjecture, however, that while such approximations
will no doubt turn out to be very useful in practice, they will inevitably sacrifice the property of
digram uniqueness that is an appealing feature of the original algorithm.

Acknowledgments
We are grateful for many detailed suggestions from Pat Langley and the anonymous referees.

References
Andreae, J.H. (1977) Thinking with the teachable machine. London: Academic Press.
Angluin, D. (1982) Inference of reversible languages, Journal of the Association for Computing
Machinery, 29, 741765.
Bell, T.C., Cleary, J.G., and Witten, I.H. (1990) Text compression. Englewood Cliffs, NJ:
Prentice-Hall.
Berwick, R.C., and Pilato, S. (1987) Learning syntax by automata induction, Machine Learning,
2, 938.
Cohen, A., Ivry, R.I., and Keele, S.W. (1990) Attention and structure in sequence learning,
Journal of Experimental Psychology, 16(1), 1730.
Cook, C.M., Rosenfeld, A., & Aronson, A. (1976). Grammatical inference by hill climbing,
Informational Sciences, 10, 59-80.
Cypher, A., editor (1993) Watch what I do: programming by demonstration, Cambridge,
Massachusetts: MIT Press.
Gaines, B.R. (1976) Behaviour/structure transformations under uncertainty, International Journal
of Man-Machine Studies, 8, 337365.
Gold, M. (1967) Language identification in the limit, Information and Control, 10, 447474.
Johansson, S., Leech, G., and Goodluck, H. (1978) Manual of Information to Accompany the
Lancaster-Oslo/Bergen Corpus of British English, for Use with Digital Computers,
Oslo: Department of English, University of Oslo.

81

fiNEVILL-MANNING & WITTEN

Knuth, D.E. (1968) The art of computer programming 1: fundamental algorithms. AddisonWesley.
Laird, P. & Saul, R. (1994) Discrete sequence prediction and its applications, Machine Learning
15, 4368.
Langley, P. (1994). Simplicity and representation change in grammar induction. Unpublished
manuscript, Robotics Laboratory, Computer Science Department, Stanford University,
Stanford, CA.
Nevill-Manning, C.G. & Witten, I.H. Compression and explanation using hierarchical grammars,
Computer Journal, in press.
Nevill-Manning, C.G. (1996) Inferring sequential structure, Ph.D. thesis, Department of
Computer Science, University of Waikato, New Zealand.
Nevill-Manning, C.G., Witten, I.H. & Paynter, G.W. (1997) Browsing in digital libraries: a
phrase-based approach, Proc. Second ACM International Conference on Digital
Libraries, 230236, Philadelphia, PA.
Rabiner, L.R. and Juang, B.H. (1986) An introduction to hidden Markov models, IEEE ASSP
Magazine, 3(1), 416.
Stolcke, A., & Omohundro, S. (1994). Inducing probabilistic grammars by Bayesian model
merging. Proc. Second International Conference on Grammatical Inference and
Applications, 106118, Alicante, Spain: Springer-Verlag.
VanLehn, K., & Ball, W. (1987). A version space approach to learning context-free grammars.
Machine Learning, 2, 3974.
Wharton, R. M. (1977). Grammar enumeration and inference. Information and Control, 33, 253272.

Wolff, J.G. (1975) An algorithm for the segmentation of an artificial language analogue, British
Journal of Psychology, 66, 7990.
Wolff, J.G. (1977) The discovery of segments in natural language, British Journal of Psychology,
68, 97106.
Wolff, J.G. (1980) Language acquisition and the discovery of phrase structure, Language and
Speech, 23(3), 255269.
Wolff, J.G. (1982) Language acquisition, data compression and generalization, Language and
Communication, 2(1), 5789.

82

fi	
	fffi	
	

	!"$#%$&('*),+--.'/!01$2,3.1

@BA.CEDGFIH

456789:';<-=>?6
#&	98';-.'

JLKMANOJQPSRUTVJXW8FVJXYZP.[]\_^_Y`WLP.JXabab[LadcGe

fgPP.[Xh`iajfgP.CQ[LYkTVJmlnAFoDpH

[qFVToA.WnRrANO[

s_tbuVvUw"xzy`{	w"|~}~b{}"


"~bX,: 	:

}!}{_buxxuV

X,: 	:

5:!5XQ5.%_5%!<Vb,V S"5
	_	E,V !,V:

Ub!
8!!:b:L!	$"$.$o$.$_G$!	$	!"$
 !
 X	$,$8"q5" 5		!Q:$.$	X8$
$5!	"%_"(($G$<$Gq5" (5	
`M$.L	$m$z	S$$.$Z.
8	X%($,L<	$$X	z$	V$$_	L!k!	.
$kQ%o	$kL`q"8k8ok_	Q$	$	
.55%!oz$	5  L$$	5	$X!	$k	!$	
$,8$	
V_ !	


 ffff "!#$&%(')fi%ff*ff+,,*-.#/103245&%67ff8%1%1ff ,28ff9!!%152 /,:,*
fi
;ff ##ff< =>/,24;?!%5A@	BC%1%7ff D=FEG<GEH$=,#$I%>%5,ffJ,*ff #$/$K,*<7L@MN,*
O ;ff D=PEG<QQHR,*F?%ff28%SK#>%T@VUff W ff #=PEG<XGYZ[K%7F52\,*M;,KF#=,EG<G]H$^`_>)fiff aff #=
b,28ffcff aff d;ff\#ff/#/528ff*d!#4%ff eKfR#ff/<7F)fi;d!#ff(g<,&%1$/affc/"ffCB>%1%ff Dhiff #a&%
&%ff #$j@	B>%1%ff D=EGQ<]HS`k\lm	28"!%ff ffC@	nCo%5&Fff R&%	^=EGQ<GH$=8#ff/ff#82;c;,3fp28,/ff*c<\S*ff /1fqT
24%5/ffrfR!#%ff sC)>;ff #ff\#ffF5fi#$288%ffF@Vt\#$'ff <#ff -K,*su<,/D=DE&GGvYwZ[%F52
,*?M;,F#=EGG]wYxcW>,*FyD*'<D=,EG<GEYkCff ,ff8%D,*FUcz #82'ff #4={E&GGXY&aI"Uff ff '|K,* O ;ff D=
EGG<}YaI~Uff ff 'P=REG<QGYaUff ff 'P=DEGG<H$^
C/1%[#ff28ff /%T=>!!#{24;ffF;,&aff"//%TN,ff ff ff874;ff #s"ff 4#/52#sg<,&%1$/aff=fi)r74;Jfqff )
ff8,28ff !/,J@VxcW:,*9y*'D=6EGGEY~ff8#/	=6EGGEYrZ[ff #ff a<jff &%	^=cEGG<]H$^_>)fiff aff #=;ff
!!#2;Jfu,/<K,*~U\z 24'/4#z @$E&GGvHfi@V&%5/*ff aff8%!ff*J,*ff !,ff ,*ff /%T+{T~x\<,#$'<5 =
EGG<vH>s,<ff\~1fqT&%"{/cff a<ff #T+!!#{24;+4#$28$%ff"#4ff/+,<("ff #S2/"ff=
g<,&%178/aff(7?ff|,*d;ff{ff <#$ff*!!#4{24;ff~ff\fq#$"ff )fi#4'3=;,Cfc$ {q
 5$<[/  qw>@V_C#m	tcyD
>H$=~)>;524;~;ffc#4ff/d!#%ff 2 K,ff|%aff*?~!,K%7TF5&%
/"ff^M7,28ffJ$?ff8!#4ffbaff ff-7ff #s?f(g,I%o$K/affJ7fq#d/,/"ffd;,?f(;ff
s&s&%#$288%ff +F 
>t\m	_C#I%7<ff #$@/k>ff ff8%,*:Ucz #82'ff #4=RE&GGXH$=7(2 Kff"a<7ff )fiff*:\
s&s&%>#$<28$%ff~/,&%ff #$f[BC%o%ff Dhi{4ff #aI&%c&%ff #$=!#4Ia<5*ff*N)fi;N?ff #/52dff "!#$&%
fp<#s/D^
#$=;5!,!,ff #>28/{ff;ff>)fi#'F0,,*<7FsI{s&%P#$288%ffr,&%ff #$fDBC%o%ff Dhi
&%ff #$J/$#4ff*J{T:k>ff ff8%CK,*+Ucz #$2'<ff #F@$EGG<XHrK,*+28/{ff*:T+t\#$'ff <#ff +,*+u,4/
@$EG<GvH$=TdS*ff /1fqTff8;["<#ffcs&s&%#$28$K%7ff(324%5/ff\KfB>%1%ff Dhic&%ff #$w^>Mff28,*P=
)fiff[28Fff>;5)fi;";ffC)<#'(fDu,s,*"U\z 24'/#z @8EGGvH8=TF!#a5*<F;ff>s&s&%
8,DI4Pi/iPi`q	4V	4 i8&cfi8q/Rq	4/	ii$/&	>qqi/i\V8 	i`i/
 +--'Vfi~fi"$##	9:	9L5bff76
#&	#		fi

%&##q9


fi,,8$w

R	fib 	1&
F /5b[
(5	 
F 4	
  q (
  4	 
c &	q  (
" b1(
c1{/ {  
 	/ b	
cbV b	 IF
	 1ff

  <off
 F(
  o







`,"

,,K7$



,9w

I

I



I
I
I

I


fi 


I

I
I



 

 

fi

I

 

 

P+9w,fi
  9 
P9w
  9 
     
,9
     
  9 
     
,  

   F
  F
   4  ,<b85/, 
  ,{	85/,c 

4 I &15"!p>&1#85/, $ 
   ~74%

A 

,: 



 

  

&&'$<#(fi  " )/fi4 ",8&*!p4s/?s  +!p4 !-,>4. /10> *(  />8'b 
32',32?>  K>!  54607.98:,C:&&'$'7;<2'  w  (sI{s&13=>32\!   /|&&'8
/ 7?  ?@2//!(s&s&13=N!|/":&&'$A.9$B< '& 9,DC,4/FEGIHHJ*K8
bL8~  /4d7L42,  (IM&<'$F' {    (fi+N!j  d&{sIj&&8
'$	 +8'6  d/+N!POQGRIS*QITLUWVYXZ[VYUW\] ^(fi  {_I&5)`<P",@$ !q(8,"?
'&-2[87<E)a{,(>&1	bIHHc'K8d(  |87<,[4c^= &1=e2"?fG2'C
/I?@2 L8  F2'B{(fi*&w  /c\  9gL$/>32L  IM&<'$  C174$)2'c  >c&5/
'<S"(fi  " )h\4 ",8&P7*!qd/1jik=d  9! @8  (] K-&5/l85(/$N/'&F
 ,<'&:,$ *=,Cm. /n0> 1(fi  $">8,/oE:(fi  )/8/, !+82'8/K[!fi  
8'b C!  4607.98:,C:&&'$,K,d  >!/I?@2 {SIo3=
+ ))2L8)2'6!  |,K,\5(+!q17([p5aI8/rqF)*2L8 sCo 1tij{_I&&&'8
aI8/u\Gg,`  78L8 $` >&$Kv?@2,&1$/[K,(? )/k/'&,4&   
(fi    >S^g31o3="&&/  JI,laI8/lc[' {$  fi(Ns&s&)$88&&'$< 
,  (96'5\  /9(fi  ? )/>4 ",8&*!p4s/1#wbxaI87<zyF,"aI8/>J(fi
'6  c  "&&7   S 8@)I8(,J  \  "&&'$<cFs&s&:{;,&1=#aI87<}|
,~aI8/"<5)G2,c,>8<L4M2,F  c,K,I
-5:ffLlnN1%6:nLj@
sCo 1ti|7)&rIM&<'$E:s>1 D7IH@u*Kfi5	,/:  "</N!3Q$ZX@UWVT<O)Q$UW#QQ$T>'XV_O3
VYTLUWQIGIX@ZO7s\J{_I& 5  '4/ {4<[?)2x	 8,!j4& *2,$9(r7     ,
 /'&+  d7G!q",r/&  F ,,$"N![  ?7)&	j4/,I8/8=>,r48SK/,, 3(fi  
pL1_*3WI3j3G:3WI%Wff)YGIbW-ffIW-ff$W>-ffI"-ffI~-ff$~>-ff_IWIjIIWff_W3IjWff_Y@
)$ ))9WIb3IW3W-W)WY%jW3Web^3$1 W3I3$^3$
I

fi-YL'''j'"j'f*'*I~'f*$L_d	'I$-]*'x h'''~kj

d_)$k)7G5d3I5#@Y3'LG3Lkj)Y6YLW$$'3I[WY'I*h__v_'d3kzb*
 L_x@h ^'LG3L N)6_')I3*)I>9IY#Lff9)G3Lp''7Lff	'@3>3L_>)LI
W5ff
L5*9)'@Y3'LG3D])'fiLff"M*))$  L 53))

*LL$7)LN   !    535I)'6@Y3'LG3j"Lff)G3Lh
73)_$#}L _'vl'&%9)G3	b73)_$'(:)* h#he6L3IWb)G3L)L3]*))$
L*LNM*b*'3	+*$7"%f9)eh&, *.-xL/*G'L)N30, *.-'%)I3IG3G1%2ff5'5$1	3' h
')@h*I+M_)'LN3LkvGL$I_54-WI_GIWY26l798'YWY]@5*))hp:''
3L$[#'I~*1%>)'{G*e LN3xff
'*[h_31%]+'{G*3 @LeM@x;@I7>*))$
)G3<b)	7G*3<  ''$'I=%5*)3	I_>Lff9)G3"M?<_*@*ff
L)L	NM	
A NL?B M~)' L*LNM*9)G3L93'7b*$
CD%)' :G7_L7)')) )*)_?Lff)G3L	FEHGJILKNM"OE	Ld)^P*)G3L
L3 d)_$lD)'~ *[]$1	3'Q*'))'e{9d_)$]_GhN3L:%/R
  __3I #)'	W*j$1	3')	'$'Ifi=%xGLff*3	3Le7NR$6+'){_SETGVUWLX
.Y WVZ\[\[ 3L_53 _)eI3]#)eIb)L#)7_d3I'L*k)'LN3Lb'd_3IG31*Gd@3
L>GlLdff3)])h")^5`_p3a
b )'	~)'))]3G$G5''G3L$#')*9)3'_)I") b [Mdc 9d_)$#$1e
	3'<)*#L#WfGL3I)'7')H*M -WhgfdY[ihj\k\lnmpo1  3#NLd_)$%ehq*MI
)~)G3LLL3x_'x'@h *I_@	x7'_'6)'_]ff
*he x)^P	@'5d9#*))h
5_'6)I''9Wj_'7*)) N3*IL3L__Lj$[1 )'9)G3LD^5_'7*))h
)]_30,LIrQ*ff,L'])*9 N63
stHuwvdx1y.x{zdv}|~i}3k\lnmpow\
%Lxe]d_)$)G3L3 b L3GLG5k\lmogh	GI @M_IG)I	@'
 K0:*7')]_' 'f*Ik N)9d)_$-3*I9L> 9{eL36N^+^ b
LG[II=	^0dff? 5INL)L~L>) )G)I:%>=
b W'LG3^ q;	 9d)_$'ehq*M)*))$f_')I3'eM@S&K A  A 
) A   A  ? NL A  A  fh)$>){YLW$i8 3$WW@5  
b lMLeLG  K0L7_$)L	Whfvdp)')9ff
d35*))')G3> 3L_
)L @vI@)@dffd?:&r&&1''*@*)'9L*L*7)G3L+).*)I=%$p^3
b*$vN)P_30,LI>=%)'{_ff1	'5*L>#' 6_$>)L>7.6$*  
Q )G ))'51jL3LG  `>5NP
'@R' L$9)' W[	)Ie*M"
"zrz.x{y.x{zdv|r~|k\lnmpo@R^#Le:G5*)
"zrz2ff  7[$6.OMOn
?r0iqr@$0
QL,Le'3ff2%>)I*)*))')e@)DW)3

NL)3xNL>C@ \;'3).@ ff.OO=ff

stHuwvdx1y.x{zdvd~i}xvt=2>"tn{y.x1z)vs>x@vdy.x1rtxivrt:2>"t1y.x{zdv
%K A .."\ A= L3 j)IPeW$'I3*IbLr'I	L1%*'$ffL1%=e
G
'$]*3	)'^ )DeM@L$PG*ffz_d5 b [@>^$[W@^ 
_'3$-ff
'')I)^M@x#)' W)"j7')  .5KK
 ".   b 6hg3*LIWYI[Y
G]3I[WYfi&dFv h @Y3'LG3#'95)9['I]_GhN3L3 b d 6_$
)^P@ }5d37@' -@h ^'LG+7'@7-)' @)!K(
 
.

fi

w2 

ff	 
fi !#"$&% fi(')*%$+,-&fi.fi(0/1%)324%$,6587:9;+=<fi(,%>fi?<A@CBEDCF:GIHKJMLONPRQ/TSU
Vf
jfi 58VW 7: ,94XZ[Y4 ,k
fi(/l
fi($[$fi.
fi($fi\fi]^fi?<6 [,k_n,6m[og X,
k'Ifi(,p,;_q_`%&):fab<A$%h fi?fihKA ,#rhcds?tuf%ev$%fi?)+f/wC,^myg'hx fi($=ig V 
6

V
z4{:|C}~3
I>IM^
Z ,fi?$\$fi %,:U
Q I\ SpQ A    S
<>g, V  afi-,fi?$8$fi %,:U,<
Q I\ SpQ     S
2;%$&,p<>g, V  afi-,fi?$8$fi %,:m;x
.fC~??:3 y	[
fi($fi4h"% !,%'hf * 'Ifi#b-X>%$ 
')*%$\@B+DF3GIH0J8L(NPQ/Sm
.fC\ofi(fi.%,i%,k,<A\ V&W $?% '1Q f SE%$;\%g$ W Q ?> Sm0x
,h"$ , V  " fiU
fiK)$'Ifi(Y[%$ W %)58739;'# W fi? Eg,,fi V fi?$&!8%M<>i-,X>gi
#fi(Y[fi(fi(,hgf i-a>fi
,<e'Ifi($i V -,)*%$'6 %,:mE;fi(a>fi($
fi fi?(U>Y;
fi(,h  V %'Ifi?%4<fi(,^i)*!>-,Xh$ V  fi;g V &fi?(U
fi
<> , V  %,i V %,^a>fi(,-fi(,?m
	ff
fiff24%$,58739""$% V 
Igig'Ifi?[f 'I%^0f"$fi(a> %g ! W ,%Y;,I""$%^ V 
fi?%8$ V  fi
'Ifi($i V ,<>gf  afifi('"%$b$fi?%>,-,XU[fimXm[Q4fi(fi.,<8g $ VW fi($&?U ? \%>g$ W (U
?  5\fi 
^fi($Afi(pbmU ?= fi $U ?>[ fi($fi(a> ,Zfi(Afm U ? Sm66Y[%$
'Ifi(,^i-%>,-,X

e 
fiIV'#b]^ '#f[$ V  fi#f Xfi($M)%>g,<T!T5\$ W fi(,X$&fi(,,<T %>,%,Q ?> S V ,,%.fi
fi]"$fi?fi?<;24%$,p587:9;Om
  
%gX
h"% !^,%'bU
fi;f X%>$ 
'"$fi?fi(,fi?<e ,#%>,%,I,<h\ &$?% 'nQ ? SE>g-&fi
fi]"fi(, afiAQ-\$fi fi?8%,h ,fi?$*"$&%X$''h ,Xpf X%$ 
'AS;%6Y;
fi(,Y[fi.V&W
fafi.,%6,fi(fi?<%)="fi V 
)!> ,Xp'Ifi(&$ V  ,)*%$'# %,:UC
fie)% %Y[ ,XpY[fi  W ,%Y;,wg V %)0
fiIfi(8%)=24%$,T587:94\Y[
$fi?g 4 ,ke %Y[fi($ V %'I" fi]-!Af X%$ 
'm
6>=: ?::nhC~C*I| f|C
	[
fis>Ivu(TQ;f ,:U f S8
fiTg %)24%$,y587:94 %,i-,X%).
fiTfi(A%)
fi]"$fi? %, 8 UY;
fi($fi  ,<   $fi8ab$i-fi?OV U,<  ;%,fi8%)j
fi8$&V fi %,.8U  U  U  U
,<  mx
	[
fiTi !"$&% fi(')%$6
Ag V >A<fi(,%fi?<E.L(NPQ/SU+)%$Awfi(/q%)M"% ,^
f Xfi($Z)%$&'Zgfim
.fC~??:3yE.L(NPQ/S:\% ab fie ,A ,fi?$\ 'Ifi8 ,p&
fi. (fi.%)0/wm
.fChofi(fi  fi($fi(a ,[fi(MfmQ f  S\Q*)*%$"$ V  V f0"g$"%^fi?\
fi#b-X>%$ 
'd%)=5\fi X$,<fi#,<
 g"U ?> U V %g<fi."$&fi)fi($$&fi?<Sm;x
4fi]?UY[fiI<fi,fiZ&
fiZ"$&% fi('d%)E ,^fi($&fi?; ,T&
\""fi($4q&
fi. ,fi($af+& !"$%>-fi('
Y[ 
'Ifi($ V fi('I"%$fC ,)*%$'#i-%>,:m
?

fiR6 00?f&^e#4?fR.4b8#K 0
 
	fiff	

fi!"$#&%'
(*),+&-/.&0132546)798;:fi8=<>+7?8=@A)B?CDEF&"G#&%=798=HJIK7ML=8N:fi+)<>),+OB9C=PQ(
RS<*B9T5),UV+WE)<>),+YX[Z]\M0Z_^a`,Zb.!c
B9CdT[79Ue:7?4Nfg)<ihDZ ^ Uj),kEU)<>),8N+>:fi8Ela<>+A79U+>:fi8Elmk6B9:fi8]+<n798=HZ \ ),8=H:fi8Elk=B9:fi8N+<nB9Co:fi8N+),UT97pfG<qZ6r
s 8:fi8=<>+798=@A)JB9Cd+WE)tkEUB4Nfg),uvB9CSwGx6y{z|A}~5~5y{w$~]iwGw$y{dw$y$Fzy{|AwG3wGxi5|AF~5y{w$5xFC{B5Uq7m<e),+#
B9CO:fi8]+),UjT[7pfoUj)Af7?+>:fiB58=<,h=HN),8EB5+j)H/EF&"G#&%h:<n7F+EkNffi)-/.&0A10I2{r
s 8wGx6y{z|D|>zy{~5y{w$5x CBU:G<Q798:fi8N+),UkEU),+7?+>:fiB58CB5Um-.&0132r!9:g8=@A)&)F8EB[8E),)H+BU)AC{),U
+BF<>+79U+e:g8Elm798=H3),8=H:fi8Elmk=B?:g8N+<&B?CD:fi8N+),UT97pfG<,hE&)q)AE+),8=H+WE);8EB5+7?+>:fiB58a<e=@W+W=79+&"Z ^ %B4E+7p:fi8=<
+WE)t<>+A79U+>:fi8Elmk6B9:fi8]+;B9Co+WE):fi8]+),UjT[7pf"Z_%hE798=H<:fiuF:fG79U>ffiC{B5Uq"Z \ %Ar
s 83:g8=<e+798=@A)t:G<&<7p:GHm+jB46)t,~5y{wG&~],zY:+WE),U);)AN:<e+<S7Qu3BHN)AfoB9C&-/.&0132D<>=@jW+W=79+M+WE)
PQ(
RS<:g8I79U)t<7?+>:G<L=)H*hN&:fi+WT[7pffiE)<CBU7[ffoZ ^ 7?8=HZ \ 4N"Z ^ %Y7?8=H"Z \ %h5U)<ek=)@A+>:fiT5)Affi5r

9:fi8=@A)q),T),U s ffg),83:fi8]+j),UT[7pf=Uj)Af7?+>:fiB58@,798m46)S)AEkEU)<<>)Hm7<d7QPQ(
R"/4EE+8EB+o8E)@A)<<j79U>:ffi75<d7QnB5U8
PQ(
R;%Ah=&)m@AB5NfGH:g8=<e+)75HW=7pT5)JCB5UjuNfG79+j)H+WE)JkEUB54Nffi),u75<;73kEEU)m<79+>:G<LD794N:f:fi+>kEUjB54Nffi),uB9C7
<>),+MB9CoPQ(
RS<,hN4EE+<:g8=@A);&)q79U):g8N+),U)<e+)HF:fi8+WE)Sk=79Uj+>:G@ANf7?U<e+U=@A+EU):gu3k=B]<>)HB8m+WE)SkEUB4Nfg),u
4Nm:fi8N+),UT[7[foU)AfG79+>:fiB58=<;<>k=)@j:LD@,7pfffi&)QkEU)AC),Un+WN:G<&C{B5UuFNfG79+>:fiB58
r
5),T),U7pf@AB58=@A),kE+A<o79Uj)8E),)HN)H:fi8tB5UHN),UO+BSkEUj)<>),8]+O+WE)ny{~5|Ay{w$x]Q~5x6Qzx65wGxNY5w$x=y*~55z9,|>~9,h,C{B5U
SWN:G@jW&)t<>W=7pffdkEUB9T5:GHN)tk6B9ffi]8EBuF:G7pffi{+>:fium)m7pffil5B5U>:fi+WEu<ir&WE)@AEUe:gB=<SU)7HN),USuF:fil5WN+S+),umk6B5U79U>:ffi
>Eumk+B5)@A+e:gB8CBUq+WE)F)AEkNf:@j:fi+FkEU)<>),8N+79+e:gB8B?C+WE)m7pffil5),4EU7<SSWN:G@jW&:ff46)kEUjB[T)H+jB46)
<>+7?U+>:fi8ElmB5U&),8=H:fi8Elk=B9:fi8N+<S7pffil5),4EUA75<,r
WE)FCB?fffiB9&:fi8ElHN)AL=8N:fi+>:fiB58=<379U)m8E),)HN)H+B+U7?8=<C),U;:fi8NC{B5Uu7?+>:fiB58C{UB5uv:fi8]+j),UT[7pf&U)AfG79+>:fiB58=<J+B
k=B?:g8N+;U)AfG79+>:fiB58=<,r

	fiff	

$,/D|>zp{"%Mz>D|>z"%dD|>z \ "%zeD|>z ^ "%'
O795)F+WE)FU)AfG79+>:fiB58bh6ffi),+F798=HZ46)F:fi8]+),UjT[7pfT979U>:G794Nffi)<,hd798=H@AB58=<:GHN),Ut+jWE)F:fi8=<>+798=@A)B9C
EF&"X[c5%nWN:@jWU)AfG79+j)<Q7?8=HZ&:fi+W+WE)FU)AfG79+>:fiB58FB58Nffi5rFP;)AL=8E)F+WE)FU)AfG79+>:fiB58/*|zp{"%&B58
U)7pf*8]EuF46),U<M+Bt46)q+WE)Q<>NuF4=B9f6CB5UM+WE)&:fiumkNf:fi)HU)AfG79+e:gB846),+&),),8+WE)Q<>+79U+e:g8ElJk=B9:fi8N+<MB9Co798=H
Z6rW=79+&:G<,hNC{B5US4=75<:@U)AfG79+>:fiB58=<;HN)AL=8E)
D|>z{"jQ% pq
D|>z{"A;% 9S
/*|zp{"% 9S
D|>z"/E% 9S
D|>z$"% 9S
D|>z"/A% pq
/D|>zp{"{,% 9S
/*|zp$"93% "D|>z"%% ^= 0
798=HCB5UH:G<$>E8=@A+>:fiB58=<D|>z"%Q:G<+WE)U)AfG79+e:gB8<e]uF4=B?f@AB5UU)<ek=B58=H:fi8El+jBQ[V/*|zp{"p%ArEB5U
)A=79umkNffi)5h*D|>z{"j";%%dNq _r5Numum),+jU>:G@,7pffg5h6&)tHN)AL=8E)zeD|>z{">5%d+BF46)Q+WE);:fiumkNf:g)HU)AfG79+e:gB8
4=),+>&),),8),8=H:fi8Elk=B9:fi8N+<;l9:fiT5),8Nr;SB5+j)t+W=79+/D|>zp{"%S798=HzeD|>z{">5%&W=7pT5)Q+B4=)F)A:fi+WE),UQB9CqQhOQh
th
Qh
QhYt hoB5UJQr
_EU+WE),Uh;&)HN)AL=8E)<>k=)@j:G7pf:G<79+e:gB8=<B9Cm+WE)<>)5h;4ND|>z \ "%D|>z{">S"j&j3%%798=H
z>*|zp ^ "%SKz>D|>zp{"n"n  %%Ah6:r)5rfih*+WE)F:fiumkNf:fi)HUj)Af7?+>:fiB58=<QB58<>+A79U+>:fi8El"/),8=H:fi8ElE%Sk6B9:fi8]+<4]
NhEl9:fiT5),8+W=7?+S+WE)Q),8=H:fi8El"><>+79U+e:g8El_%k6B9:fi8]+A<q79Uj)Q]8EB9S8+BF46)t)=7pf/r 


fiEE65=6E55E=A_

fi
	ff
fi$5,p{6O{fiOD=pE
 

!"#%$'&)(+*-,/.10325476+498;:5< =;>=?@#7< =A7"B CEDGFIH9JLKNMffO$5P7*< =QRA7BS=?@#9TVUA7#W#VX">=?@#	<Y=A7"Z,\[ff.
0325476498 [ :]B C^DF3HVJLK_M5O$`P-acb?@"#9#d>e=f
8 [ .g8ihjlkmon3pqsrutvOswxPsyzm|{0Ik4	w 47y:}~6c
5X"=, [ >??9<l>Q|#9B;a"Bxa#	<u>="QRCT9BS,/acb_  nSq7vcpLSvq@rtSvSnrVptu;"
Q"=BS#9"%#VX>?, [ abr9pt m Os,_P7
 b"#VT@>A<uebS*U?I>=f~rdpq@rt<Y=Q"=Qx>=fB >=c#7?]>=?@#9"<SQB C-nIpq@rt<Y=Q?@#	< T9#d>e=f_B >=c#	?*, [ >?
?9<u>Q#9B_a"Bxa#	<u>="Q+CT9BS,acb_ lvc+ruSvcpLSvvnr9ptvv*LQ"=Bx#9"Q;r9ptv]Os,_P	
3#`>?"<S?@b+#9B?d""%#9X< #5BS=bB >=#<lefx"aT	<CBST9_U< "< T9"<SQQ"Q#9B8R
T	< =?sC"T9Td>e=fN>e=CBST9+< #@>BS=CT9BS>=#9"T9l<lT9"7< #d>eBx=?ff#9B_B >=c#T9"7< #@>BS=?QBc"?=BS#EAVX< =fS"_?9< #9
>?I< a>>#sbS*<x?5"7L"A7#9"Q
p Ofi  
g!"#E$&(< =Q,< =>e=?d#	< =A7"B CffDGFIH9JLKNM5O$5P	_5X"=,>??9< #@>?I< a"_>
rVpt m O@,_P>?E?9<Y#@>?I< a"%>gr9ptv]Os,_P>?E?V< #@>?I< a"S
p *7]b+#9X"C3<SA7#5#9X< #5#9X"<SQQ"Q?@#7< T9#@>=f< =Q+"=Qx>=fB >=c#T9"7< #@>BS=?ff< TV"<uT9"<xQbfSU<YT	< =
#9""Q+#9BXB Q+>=< =b+BLQ"7B C^,ff
;"o@U<YX"<SQab_T9"?@"=#@>=fW<?9< #@>?I< a>>#@bZ<ufSBxT@>#9XO3fSBST@>#9X'LP< =QaT@>"7bQx>?9A7U?9?
#9X">=c#9U>#@>BS=a"X>=Q>e#>=RBST	Q"T_#9B+>=Qx>A< #9"ffX< #S>=QRB CE<ufS"aT7<S?\>e#5BST9?CBST5X>?5>
XBS"7CUb~<YS">#ff"<S?I>"T#9B< T9"AV>< #V""7=>e#d>eBx=z
>T	?d#<S?9?@U"#9X< #8BS=bgA7Bx=c#	<l>e=?ffBSTV=g%!ff?*5ffX>A9XBS=bT9"7< #9"?d#	< T9#@>=f;B >=c#7?B C
>=c#V"T9l<u?!>="<YS"?5#9X"\>e=#9"T9 <uoT9"7< #@>BS=?"7L>AV>#W<S??@#	< TV#@>=fB >=#ETV"7<Y#@>BS=?%< =Q+>="
AVX"A9?%?9< #@>?I<Ya>>#@b~B C-#VX"WTV"?@U#@>=f~?@"#EBYC?@#	< T9#d>e=f+BY>e=#%T9"7< #@>BS=?!>e="?\#VBS_A7B "A7#>=
#VX"ET9"7< #d>eBx=?ffk m .gy m *?@UAVX+#9X< #]>=~< =cbBLQ"7#9X"?d"?@#7< T9#@>=f_B >=#	?]X<uS"E#VBa"%"xU<u3oI=
<SQQx>#@>BS=*CBST	A7"?%<u-?@#	< TV#@>=fB >=#	?#9B+a"Qx>?@#@>=A7#*#9X< #%< T9"_=BS#CBST	A7"Q#9B+a""xU<u3%I#>?
AV"< To#9X< ##9X"5"xU<u>e#@b\CBSTVWU< "]>=QB%=BS#o<u"A7#?V< #@>?I< a>>#sbS]ffB 5"S"T*>#>?"?9?]AV"< To#9X< #
#9X"Qx>?@"xU<u>#sb+CBST9_U< ">=~A< ==BS#5< x"%#9X"ff>=?@#7< =A7"W, [[ .0I254	6+498 [ hZ:oU=?9< #@>?I<Yae"S
5X>?C3<SA7#>=Q""QCB B E?CT9BS<+T9BS"T9#@b~B CffffBxT9=;%!ff?*ffX>AVX>?%T9B S"Q>=5X"BSTV"
ff#^>="z* "c=B #VX< #-#9X"TV"E< T9"ff=B#@B%BLQ"7?^CBxT, [[ *SffX"TV"ffCBST-?@BS"Ek47y}~2*Lk m .gy m
>=Bx="ffBQ"7*< =Q+k m.g y m >=#9X"BS#9X"ToBLQ"7355X>?>?]#9X"5>=c#VU>e#d>eBx=a"X>=Q"7=>#@>BS=~Sx
Bl*>="~+A9X"AV?5CBST%?9< #@>?I< a>>#@bBYC-#9X""=Qx>=f~B >=c#7?B C-#9XBc?@"\>=c#9"TVl<u?ffXBc?d"N?d#	< T9#@>=f
BY>e=#	?5X<uS"%#VBWa""xU<u>=<Y=cbBLQ"73]Co#9X"W<ufSBxT@>#9XT9"@@"A7#	?5< #5>="*#9X"=#9X">=?@#	<Y=A7"
>?5BSaS>BSU?seb=BS#ff?9< #@>?I< a"S5ff#VX"T95>?@"%5"E=""Q<_A7BS=Qx>#@>BS=Bx=#9X"%<ufS"aT	<$ff*A7BSTVT9"?@Bx=Qx>e=f
#9B"7=>#@>BS=z*S>=BST	Q"Tff#9B_fSU<YT	< =#9""?9< #@>?I<Ya>>#@bS
`X"CBSTV<u<SAVX>="T9b+CBYB E?

fi
*   =o Ofi D=V 5&,
!"#$&(* < =Q%,.0325476498:c< =>=?@#7< =A7"-B CDGFIH9JLKNMffO$5P	`X"o>=?@#	< =A7"5, [ .0325476498h8 [ :
B CDF3H9JK_M5O$5P>?5?9<l>Q#9Ba"_nSq	vcpSvSr5vr%oq	3,>#9X"T9""7c>?@#	?5<CU=A7#@>BS=~c6
jS.4 .% \?dUA9X+#9X< #ff8 [ .jlk m Os Psy m {03k4	w 4	yz:}~6c;"%Q"=BS#9"%#9X>?5T9"7< #d>eBx=acb~xr m Os,4	, [ P	
5X>?"< =?#9X< #`CBST"<SA9XT9"7< #d>eBx=*"7>#9X"T%#9X"_?@#	< TV#@>=fB >=#	?B C-T9"7< #V"Q+>=c#V"T9l<u?%< TV"%CBST	A7"Q
#9Ba""xU<u>e=<uBLQ"7?*BST#9X"bZ<YT9"%CBST	A7"Q+#9B+a"_Qx>?@#@>=A7#>=<uoBLQ"7?5CoCBxTE?@BS"_,G5"
X<uS"Sr m Os,47,%[P	*z#9X"=~,%[>?E?V<u>Q#9B_a"nxq	vc\pLx-Srvr
 >_>< T@bS*ab"7zAVX< =f >=f?@#	<YT9#@>=f<Y=Q"=Qx>=fB >=c#	?*ff5"~fS"##9X< #, [ >?rxpSv
Srvroq73,*Q"=BS#9"QSr  Os,47, [ P	


fiv+--L LuV	ff
ufi
lS%S]-
!#"%$&(')+*-,/.10325476987:1;
=<?>A@CBEDFHGIDJLKMONQPER7STCS1UWV
X
i
~








X
X X
Xi
X~
X-
X

MZY[NQPER7SLTCSUY\V^]`_ba1cd/ef6gMh:
jkD	lGnmoqpsrutwv^xzyb{	|f6gU Y :^}[<
}--}	
 ]
jEsKIJ1+PEuSLSV?T
jD	lGZmoApsrutvxzy-{	|f6gU Y  eN
: }[<
  e ^



 e N e 
 ] 
}3-}
 ]    e N
  e 
}<uj
}[<?#jEs
N  e U Y  
 ]  7_csg_d e 6g:gsP/uSSL	VuT e 
jkD	lGnqnyb{	|f6  :q}[<
}--}	
 }	>#



[D	K X~ lqlHG	

~	X J1	KJ3FG1	Kll7D	sIF77KZFIAFHK-K 

C}<uu<u"%$	('qu  Q  L  }j/C-  %<s'1}<u=<su;>f=<;
sK-GM(NQP/R7STCSUV[KzIFGI1GHD	lDGkKLDG1KDFGIDJLKl)O,E.10	2h4698:u%lFlK^8ff	ID
JLlDFG1JLGMZYsNQPER7SLTYSUWVFHJ1G1IGTY[N  PE#SSLVT	 e N e U    K  ffJLlDF/9K-D	
lD1KL9IGlDFCJlJLKG1	KFHGI1GD	+lDGFwG1lKKI  lM9FF1I9G1lKdLdd
 %  -d_-  %%c3  M Y FwF1IG9F/IK  l	KLkF1IG9F/%D	M Y 9FFI9+G1ldLdd
 %  -M  %%zc3  
 h9IfKLJ1ID	D	FGIGD	IDK-DD	[lDGFbM9FFI9G1lKdd9d  %  bd_
_[c	9[  M Y 9FZF1IG9F/IKfIDIl	KLF1IGHFgD	M Y 9FZF1I9G1ldLd9d  %  hMO
_[c	   
KZD	lQKLD	KG1	KIK-	LIlJlG1	

~	X FHlKFF1IGHFgIG 

 }<uu<u"%$O'-s  =<s'1}<u=<su;>f=<  }    ;
C
QF	IK-	IZ8(FF1I9CG1lhKI  %%zc3qd _bg%lIDhDFGIDJLKMONQPER7SLTCS1UV
l)O,E.032h47698:G1	K%ll7D		l9	F-f%lIDNQP/R7STCS1U Y V^FJ1GIGk_= e 6L_-a1csd e 6gMh:SZ:
9Fl	J-IF1IG9F/IKZ%lFGIGD	lDGF-	G	K-D9FF1IG9F/IK 
 K-G9J-IKLJ1ID	D	K-DD	[lDGLF^IDFHGI1GD	lDGF-7Kl	GIDID_[97c	
d_-  
7	KF1IG9F/IG	1lK-ffFl7G1	KFHKIK-	IFI1KKLD	KIF%llkF 


fi
	fffi
	ffffff

 !#"%$&(')+*,-/.103254768:9<;=>,?@.A0324B6<8C9<;3D
EGF/HI9JFLKBMNHKPO3HNQ RSLT
UVQ RWHXKZY SF/JOK[]\<^F`_bac(d#_:eaWf@dCghd:c(i<jlkNmWf@gonZprqbmks_/c(akc(dCtvuwj5md:tcIag unxf@kyaP_{zId:c:|
pBn!c(kdC}d:t/q/mkpBac(d:mt~QCMsH3^FMNF/HUV]Q RMNHKVRF!MA<3IUVX,.10325476<8C9<;<X^F/O3FH3^FEwMUVX
KVO3F`O3F!MNH3OQ#HF!Q RHN<UXK!M/OMNH!GKZURvY URvHKZQ RwUO3REXMKVRMF!URGKZRUH
URvHKZQ RKVRvVKVONQCKVJvY F!MsWvX^F/O3F5Q[F[ QHsKZURvY O3FYCKVH3FLMNHKVO3HNQ RST
UVQ RWHMUVQ RWHF/O3xKZYCM/[
 vF/HONQC/KZYhY
JvF^KVRSVQ RSMNHKVOHNQ RS7KPRF/RQRSTUPQRvHM/v<FSF/H<H3^FB_/ac(d#_Ce<aWf/d:ghdCc(iwjlkNmWfb.
ghn!p%q/mk`n!tdCtvusj5mdCt
c]agunVf/kNaV_zIdCc:|pBnZc(kd:}d:t/q/mkpBac(d:mt
[
IsGvlAA
]G
FRUVTO3F!MF/RWHXH^FLKZY SF/JOKMwX^vQC3^KVO3FLMNHKVO3HNQ RS8AF/RQ RS;<TUVQ RvH{KZY SF/JOKM/[
 !#"r)>&('*BGPI Z/]8yZ;<G8yZ;D
 F/H - 8v%/;KVR ?< 8B;[]XUH3FH^KVHX - URvHKZQ RM<KZYhY>JKMyQ#sOFY#KPHNQ URMX
MN^H3^KPHXX^F/RF/F/Os5Z(UO<Q RWHF/O3xKZYIxKPONQCKVJvY F!Msl
I
%^KMH3U^UVYC~Q RKVRvU5vFY]KVR
MNvF/H3OQ#/KxYoY G ? QCMwF!vQ VKZY F/RWHH3UB%^UPY#Q RSQ RKPRWUvFY[
Q OMH!UOsW B 5vFRF]8yZ;IH3UBJ
FLH3^FLMNF/HwUVOFY#KPHNQ URMvMN^H3^KPHFQ H3^F/OsUVIH3^F
(UVYhYUV<Q RS^UVYCM/
8N  
; 
8yZ;
8N  ;







 - 8<  ;
 -3 83X  ;
8X3;






\<^F/RvJvMN<Q H^vQ RSMNHKVOHNQ RSKVRF/RQ RSTUVQ RvHM<UVGQ RvH3F/O3xKxY#M@vUOsW3  8NZ;GQ#MwvFRF!
H3UJ
FH3^FMF/HXUV>O3FYCKVHQURMvMN^H3^KVHwFQH^F/OUVH3^F(UVYhY UxQRS^UVYCM/
8N  
; 
8yZ;
8N  ;











 ? 8<  ;
 ?3 83X  ;
83<  ;



 !#"r)>&:*BGPI Z/`GB@D
EGF/HL - KVR ? JFKMwQ RsFRvQHQUR[ GKVRvFRF  H3UJ
FH3^FBMNF/HUV]O3FYCKVHNQ URMvMN^H3^KVH
FQ H3^F/OsUVH^FsUVYhY UV<Q RS^UPY#M@
83<  ;
8(<  ;
8/;
83;
8(/;
8(  ;
8;

























!

 -  - 
 - 83<  ;
 -   83X3;
! -
83w  ;


fi>:	
fiff	

 !#"$

%'&()"$
x*,+-#.ff	

/012123547698.:5;<=<0>?635@<-;A:8CBDEGF0IH JK;BLfi47M3N86O8BP356Q93QNRN>?J7S
\ 3]D354O47M3)Q_^F`:<.;Q7QGacbdfe

HOH7TRUF0J7SVE$ETWR>X;BLYZ$F0,Y[5>

g 8=<3Qh:NiB4;8B8BD47M3);<D35F6;QG;673]Q9^@@<=83Lj;QO;kBIiBlm<=8CB32;@@*35BLA8=no47ic47M8.QG;67498.:<3d
p 4c8.Q23;AQ90q4iqQ9353I47M;4W47M3,;<D35F6;Q;673,;r<s<]:NiBQt8.L356;F<0u<.;6D356247M;B?>wvxi623Nn;12@<3>U47M3
yhzO{Gl}|$i67B;<D35F6;> \ M8-:Mo:NiAB4;r8CBQ$~~ 3N<351235B4NQ5d
)X`--? M3QK8snj;<D35F6;Q	J9R;BL,aWJKR	:NiB4;8Bc3N<351235B4QG3;:Mo;kBL b ;BL
a b :NiAB4;r8CBj 3N<351235B4NQO3;:M?d
)XNU Q_476;8DM49vxi6 \ ;6L2:NiA1F8B;4i698.;<'3Nn356:8.Q93;A:5:Ni6LA8BD#4i4M3L3NB8498iBQ5dGe
3 ;<.Q9iQ_353)47M;4G47M3W	JKR	;BLaWJKR	;<D35F6;Q$3;:Mo:NiB4;8BfiP3)F;QK8-: 673N<.;4_8CiABQ5>`;kBLI47M;4  b
 c
;BLacb:NiAB4;r8CB47M67353F;Qt8.:W673N<.;498iBQc3;A:7M?d  Q9^FQ9^12@498iB673Q9^<4#;kBLj;BiBQ9^FQ9^12@4_8CiAB
673Q9^<4$vik<s<i \ d
)X`--?= M3O4 \ 3N<P3h;<D35F6;AQ@673Q935B473LcF02{G6;35BDA6735B2;BL2iBQQ9iBIJR> \ M8.:M
\ 35673]Bi4h:<.;QQt8=3Lo;AQU1#;n81#;<?476;:N4N;F<3>;673]3;:M8B:<^L3L8B,iB3 iv4M3);<D35F6;QGJKR	;BL
aWJKRd
)XNO 0Qt812@<0,:M3:7A8BD8B:<C^QK8CiAB,vx67i147M3)L3NB8498iBQ5d]e
)X`--?mp Bu;<=<ivU47M3I;<D35F6;Q	JKR>XaWJKR> b ;kBLja b >47M35673;6732673N<.;4_8CiABQ \ M8.:M
;673]BiA4O3Nn@63Q7Qt8F<3F0I|Oi6B,{]?zOQG;<iB3d
 GR>
)XN]p 4G8.Q3;Qt8=<0oPA35698=3L47M;4]47M3c@*i8B4]673N<.;4_8CiABQG8BL^:N3LjF0,4M3  <=<35Bq673N<.;4_8CiABQ J
JK2 T R>XJ}c T R>JE T R;BLJHNR;k673]Bi4h|$i67B,{]?z$Q5dOe
p 4 \ ;Q iFQ93567PA3LuF0{G6;35BD635B;BLuiBQ7Q_iBJR]47M;4W47M3yhzO{Gl}|$i67B;<D35F6;j:5;kBBi4
3Nn@673Q7Q47M3UBi498iBciv?5Nxm=mxr>;BL 47M^QQt8B:N3U848.Q1#;n8C1;<46;:N4;F<3> \ 3:5;kBBi4	;LL 47M3
673N<.;498iBJfGR47i]84 \ 847Mi^4<iQt8BDc476;:N4N;F8=<s8490d	|$i \ 35PA356> \ 3h:5;BiF4;r8CBI; \ 3;356	0A354	^Q93Nvx^<
673Q9^<4 F047M3cvxi<=<Ci \ 8BDiFQ93567P;498iB?  3cBi \ v67iA147M3c673Q9^<4Q]ikviBQQ9iBq;BL G; :Q_476 i 1
JARO47M;4c47M33Nn@673Q7Qt8PA8C490iv|$i67Bu{]?zOQcQ9^FQ9^1W3Qc47M;4civO47M3yhzO{Gl}|$i67Bu;<D35F6;>F0
3Nn@673Q7Qt8BDj47M3yhzO{Gl}|$i67Bu673N<.;4_8CiABQ2;Q)LA8.Qm9^B:N498iBQWivh@*i8B4c673N<.;498iBQ8CBu4M3Q94N;67498BDj;BL
35BLA8BD@*i8B4Qikv47M38B43567Pr;<.Q5d  M^Q>hQt8B:N3j47M3jQ7;k498.Qt`;F8=<=8C490@6iF<351vi6IQ94;k67498BDq@*i8B4
;<D35F6;AQJK;BL35BLA8BD@*i8B4,;r<CDA35F6;Q5> \ M8.:Mvik<s<i \ QF0Q901212354670R2;<=<i \ ;67F8476N;670|$i67B
{]?zOQW673N<.;498BDqQ_4;67498BDj@*i8B4NQ5> \ 3:5;B:NiBP356742;B0qB354 \ i67j3Nn@673Q7Q_3L8B47M3yhz${Gl}|Oi6B
;<D35F6;8B4iq;B3A^8Pr;<35B4I8BQ94;kB:N3,iv ZN}c J.R]viA6Q9iA123Iiv]47M3,476N;:N4;F<3oQ_^F`:<.;Q7Q93Q
;F*irPA3> \ M35673#iAB<C0Q94;674_8CBD@i8B4Q ivU8B47356Pr;<.Q2;632673N<.;473LXd  M3I;LLA8498iB;<O3Nn@63Q7Qt8P8490jiv
47M3cQ94;674_8CBDW@i8B4;<D35F6N;QO:5;B47M35B,F*3)^Q93L47ic3Nn@673Q7Q$3d(DdQ93A^35B498.;<=8C490J}^Qt8BD#iAB3)iv47M3
;<D35F6;AQG	JGRi6Ga2JNGR7Ri6Oi47M356U673N<.;4_8CiABQOF*354 \ 3535Bfi8CB473567P;<.Q5d
 i \ 848.Q498123$47i]P35698=vx04M;447M3O@673Q_35B473L;<D35F6;AQ;673U8BL353LQ94;674_8CBD);kBLc35BLA8BD@*i8B4
;<D35F6;AQ5>673Q9@*3:N498P3N<0d  vx3 \ ;^n8=<=8-;k670,L3NB8498iBQ];BLI63Q9^<4QO;673]B353L3LXd
A?-?'5-?u7?'
g iA6jU>*<C354c7JKR]]F3c47M35sA#ikv?>*47M;4$8-Q>*8svOjf>4M35Bq7JKXRO]A>8=v
fi 47M35Bj7JKXR>*;BLW8=v,>4M35Bj7XJKRdfe
*o'm X354Uf}UNa#NF3G;)Q94;k67498BD]@i8B4L3NB8473$8BQ94;B:N3Oikv Z5t7 JmUR> \ M8.:M
8.QU<i:5;<=<0oQ7;4_8-QK`;F<3)vxi6hQ_4;67498BD2@*i8B4NQOF0,Q9i123]1WiL3N<>X;BL<354]XF3c;BI8B473567@67354N;498iB
vxi6hQ_^:7MI47M;k4


fi**	


fffi !#"$%&
fffi'(
)*+,'  -!+,   .
/10324'56879:5 ;  #/1032 " ,'5687< " :56;
=
>@?:ACBD?9EFHGJIKML;?GJLN " EOGQPRI%SLNT3AVUWFYX[Z\X;SE] A^I_L;?%F`A^IaLDFYX;b%X;FYL
GJL1AcS3IdSeZfK,L
GJX;L1AcI%gRbhSJA^IaL	KY=GJIT
Z\SX@FYIT3A^I%gRbSJA^I:L
KY=4GJI:PB;?GJI%g3FNACKiGkjlj^SJ>FHT4=G3Kj^SI%gRGKL;?%F	A^XNX;F	jCGJL1Acm3FnSX
T:FYXMZ\SX@X;F	jCGJL,A^SIKM>@?:ACBD?
?GQmFNL;?%FnK;GeEF[A^IaL;FYXDb%X;FYL
GJL,A^SIKoSJZ6K1L
GJX;L,A^I%gbhSJA^IaL	K-ACK@L;?%FnKDGJEFprq?%FYI_ " GQjCK,SsjcS%BYGQjVj^PdK;GeL,ACKutFHK
v Z\SXiK1L
GJX;L,A^I%g)bSeAcI:L
KYp
wnxQy4yz	{N| bGJX;LMZ}X;S3E~BD?%FHB;3A^I%gRL;?%FN@KMA^I<=jcS%BYGQjfK;GeL,ACKutGJ:AVjVAcL,P*Z\SXK1L
GJX;L,A^I%gbSJA^I:L
KNBD?%FHB;%K
SI:j^P9X;F	jCGJL1AcS3IKn>M?%FYX;FOLD?%F)A^IaL;FYXDmkGQjCK)L;?%FYP_X;F	jCGJLDFGJXDF)Z}S3X
B	FHT_L;S*?GHm3FL;?%FRK;GJEFOK1L
GJX;L,A^I%g*bSJA^I:LHp
 A^IB	FT:SaFHKMI%SL@XDF	jGeL;FnFYIT3A^I%gRbSeAcI:L
K[SJZ&A^IaLDFYX;mkGQjCKY=4LD?%FnSI:j^PRL;?:A^I%gL;?GJLNGQUFHB	L
K@K;GJL1AKtGJ:AVjlA^L,P
SJZrL;?%FHK1FnX;F	jCGJL,A^SIKMACK[L;?%F`X;F	jCGJL,A^mF)SX
T:FYX[SJZrFYIT3A^I%gbhSJA^IaL	KY=geAcm3FYIGst%%FHTdK1L
GJX;L,A^I%gbSJA^I:LHp  A^IB	F
L;?:ACKMSX
T:FYXACKL;?%F)K;GJEF=%GJITR GeITR " B	SJA^IBDACT:F)SIK,L
GJXDL,A^I%gbSJA^I:L
KY=%LD?%FNX;FHK,:j^L@Z\SJjVj^SJ>iKYp@
 hd_8^ 4FYL v (	O(;%F[GNK,L
GJX;L1AcI%gNbhSJA^IaLT:F	tI:A^L;F@A^IK,L	GJIB	F@SJZ<	u;s@C	=J>@?%FYX;F
Z\SXOI%Su'(
J(	%=@)D
O;
 GJIT7;
;<
 %p+q?%FYI v ACKRK;GJL1AKtFHT
v
:P9L;?%FRES%T:F	ji AVU# jcS%BYGQjVj^PK;GJL,ACKutFHK
Z}SXK,L	GJX;L,A^I%g_bSJA^I:L
KGJIT K;GJL,ACKutFHK(	 " 
=&Z\SX
`"%au'(
J(	%]:M;f; :ap
wnxQy4yz	{
  | K;K,%E)A^I%gLD?GJLi K;GeL,ACKutFHK v =L;?%F[jCGJL;L;FYX@B	SIT3A^L,A^SIAK[G)T3A^X;FHB	LB	S3IK,FH%FYIB	F`SJZ8L;?%FnT:F	tI:A^
L,A^SIKYp
 8-P)L;?%FX;FHK,L;X,ACB	L,A^SISI v =aKDGJL,ACKutGJ:AVjVA^LP)SJZ4FYmFYX;P)X;F	jCGJL,A^SIoACKrBD?%FHB;FHTsaP`L;?%F@L,>SB	SIT3A^L,A^SIK
L;Sg3FYL;?%FYXH=aGeITL;?%FKDGJL,ACKutGJ:AVjVA^LPRSeZ~ACK-A^IBDjcT:FHTA^IRL;?%FMj^SBYGQj8K;GeL,ACKutGJ:AVjVAcL,PB	SIT3A^L,A^SIpq?:K v
ACKiKDGJL,ACKutGJ:j^Fp@
 hd_8^ 4FYL v (
(;8hFsGeIA^IK,L	GJIB	F)SJZf+u;s@C	=GJITj^FYLN+(	(; " fhF
K,BD?L;?GeL3\   v (;N	p rSIK1L;X;B	L@@"h(	`"l(	"V-aPRK,FYL;L,A^I%g
    
 !
 !
    
 Sk> " ACK@K;GJL,ACKutGe:jcF[AVU_ACKYprq?%FNGJIGQj^SgS3KrXDFHK,:j^L@?%SJjCT%K-Z\SXFYIT3AcI%gbSeAcI:L
KY=:>@?%FYIRXDF	Z}FYX;FYIB	FHK
L;SOK1L
GJX;L,A^I%g)bSeAcI:L
K[GJX;FnBD?GJI%gFHTL;SFYIT3AcI%gbSeAcI:L
KY=hGJIT_;f  6AKMB;?GJI%g3FHTRL;SRDM  
p
wnxQy4yz	{ MA^X;FHB	L1jcPZ\X;SEL;?%FnT:F	tI:A^L,A^SIKpfq?%FNXDFHK,L;X,ACB	L,A^SIK-A^EbhSaK,FHTSIRL;?%Fn3GQjVAcL	GJL,A^mFNX;F	jCGJL,A^SIK
GJX;FGQj^X;FHGT:P9gGeX
GJI:L;FYFHT_L;S*?%SJjCT_A^IGJIaP_ES%T:F	j= :PdLD?%FOX;FHK1L;X,ACB	L,A^SIK`SI< " p  SL;FL;?GJLn " AK
>F	jVjcT:F	tI%FHT*KuA^IB	F3\G3T%T%KrLDSnF	A^L;?%FYXFH3GQjVAcL,PS3X&AcI%FH3GQjVA^L,PZ\SXrGQjVjA^I:L;FYX;mJGQj8K,L
GJX;L1AcI%gNbhSJA^IaL	KYp
qo?%FNb%X;SbFYXDLPSJZ FYIT3A^I%gObhSJA^IaL
KoZ\SJjVjcSJ>iKoaPRK,P:EEFYL;X;Pp
3f^Hy8\a
R&Yy4Yd%4
 S3XiR=T:FYI%S3L;Fn:Pd:	/J4-L;?%FnGJK,SJj^%L;F`mkGQj^%F`SJZ6=3ApFpJ/10324W
p
n"

a'(
-*;;
(
o
a'(
7;  
(
o

q?%FNEOGkAcI*X;FHK,:j^L
KoZ}Sejlj^SJ>np
) :yxQ8\h q?%FGQj^gFY%X	GK)-QoGeX;FK,L
GJX;L1AcI%gRbhSJA^IaL)GQj^gFY%X
GK=8GJIT_LD?%FsGkjcg3FY%X
GKnQGJX;F
FYIT3A^I%gObhSJA^IaLNGQj^gFY%X
G3KYp
wnxQy4yz	{ 4FYL v (	(;9&FGJIAcIK1L
GJIB	FSJZf  u;sfDrQ;	=GJITj^FYLN+u(
(;*"@>A^L;?
  
YD   v 
(DN
p-P4FYEEOGhp%=>FdBYGJIGKDK,%EFLD?GJLZ\SXFYmFYX;P'(
J(	%OO=F	A^L;?%FYX
; );NSX`9; );%=rKAcIB	F*AKK,L
GeX;L,A^I%g_bSJA^I:LOT:F	tI:A^L;Fpq?aK=rL;?%FSI:j^P
X;F	jCGJL,A^SIK[`>@?:ACB;?_GJX;F[j^F	Z\LiGJX;FNL;?%S:K,FnK;GJL,ACKuZ\P3AcI%g
Y

fi8$%_%%r%	:J
fffi
	ffQfifi

k

% N%_fi%&-fi

!" #fi
ff %$

')(*(,+.-0/

1

/

12435126+

')(-7/

1

/

12

')(,+8-0/

1

/

126+

1

/

'69;:<: +

-=

>?@ffACBDD?AFE<G6HIJGLKNM&A4O?P,IOQORA6IJGCM&ATSEUWVX?YAFGIJY6GCMZ[\D#?JMZGA4]ffR^I*_^?UffE`Obadce>JMZP`EfKgHIhALE`iDffOjM&PMG
ACGIkY6GCMZ["D#?JMZGAl@	ImOjOnY6E`O&IJGFMo?hZAeVXY?_pOQMZE\q^IJY6E\A6IJGCM&ATSEU8MZ%adc4rOsAF?@ATMZP`E"a;M_^D?AFEA<ItP`E,Y6GIMZ
?YUffE,Y?ZgACGIJY6GFMoZ[D?JMZffGA?JVuMZG6E,YvmIO&A,@LwuE^xffZ?JwdG6HIkG"wuMG6H?BGO?A6Ay?JV<[E,ZE,YIOQMGCR@LY6E`O&IJGCM?ZA
1{|12

?ZNOQMZEgz%P,IJZg]EY6E,DffO&IP`EUg]ffRNE`MoGHE,Y

18{}12+

?hY

12

@uATMZP`E

IkZU

126+

1

M_^D?ffACE}UhM&A~C?JMZG

?YUffE,YFMoZ[ffA\?ZAFGIJY6GCMZ[D?JMZffGA,cuHffBA,@nwuMG6H?hBG\O?A6A?JVu[E,ZE,YIOQMGCR@LwuEWG`IJxE^K?ZffOR}G?}P`?ZffGIMZ
Y6E`O&IJGCM?ZAVXY?_OQMZEAtIJZUq@#MZffvE,Y6GCMZ[Y6E`O&IJGCM?ZA"P`?hZGImMoZffMZ[OjMZEY6E`O&IJGCM?ZAyw<HffMQOoEP6HIJZ[kMoZ[
G6HE`MY<UhMY6EP`GCM?ZnceV

wuE\P`?BffO&U^_^?UhMQVXRaMZG6?^IJZ.MZGE,Y6DY6E,GIJGFMo?hZ5aACBPHG6HIkGGHEfP`?ZUhMGCM?ZAu?JV



E,_^_ItqcQ"IJY6E\A6IJGFMsA)SEU@IJZUG6HE\Y6E`O&IJGFMo?hZAu?JV4OjMZEt^IJZUG6HE`MYuMZffvE,YACEA<IkY6E"A6IJGCM&ATSEU@G6HE,Z]R


E,_^_I"q#c@A)MoZP`E\GHEACE\Y6E`O&IJGCM?ZAuUff?tZ?Gu?JvE,YCO&IJDwuMG6H

'90:e: +

- @awu?BffO&U.]E"I_^?UffE`On?JVnK"@

IJZUG6HE\YEACBffOG<wu?BffO&U.VX?JOQO?Jw"cLTZUffE,EU@wuE\ACHIOQOA6IJGFMsA)VXR.OQMoZEttY6E`O&IJGCM?ZAwuMG6HG6HE\]IATM&P*Y6E`O&IJGFMo?hZ
(

?ZE,vE,YR5IJY`PJc
' a

rVXE,wIJBffiffMjOQM&IJY6R|UffE`SZffMGCM?ZA^IkY6EtZE,EUffEUV?Y\G6HE^P`?ZACGY6BP`GCM?Znc^*E`SZE%
OEIACG*Z?Z,E,Y6?_^E,_t]E,Y*?JVLG6HEWACE,G ' a

'C4-


a

')

UhM&ACGIJZP`E]E,GCwuE,E,Z}ACG`IJY6GCMZ[tD?JMZffGAMoZadc<MvE,Z%I^



') 

 ^% a

-L

' 

@ffOE,Gt


' 
a

-

G6?]#E^G6HE

-6-\^. @ffMc!Ec@#G6HEyOoEIhACGfZ?hZ,E,Y6?
-

]#E"G6HEtACE,G

-6ff

Mc!Ec@eG6HE}AFE,G^?JV<MZffG6E,Y6vmImOsAwH?ACE?YUffE,Y.?JVE,ZUhMZ[ND?JMZffGA.HIAtG6?|]#ESiEU@G?|_IMZffGIMZgO?P,IO
A6IJGFMsA)SbIJ]ffMQOjMGCR@L]ffR


 Ja

V?YI[JMvE,Z"@hOE,G<#

')ff-ff^

wuMG6HffMZA`[hY6?BD - @JIJZUgt

' 

Fh
t

?G6E\G6HIJGeV?Y<E,vE,YR
E,GW

 ma

') 

')



t

' 

-



' 

- @

t%

ACBPH%G6HIkGV?Y<E,vhE,Y6R

Fh



(

>BDD?ACEG6HIJG

' a

')




-

UhM&ACGCMZP`G*E,ZUhMoZ[.D?JMZffGAMoZ%a

G6HELVBZP`GCM?ZtBZffM&BE`ORUffE,G6E,Y_tMZEU

MZ}a@ACBPHG6HIJGuV?YuE,vE,Y6R
--L

Fh

'  

- c^rOsAF?@

')-n

n`^

t

' 

- @

'C-6-`=

 

c




%

M&A"\ce?Y<E,vhE,Y6R

a

>BDD?ACEG6HIJG







(

 'C 

M&Afc?YE,vE,Y6R

a

 'C 

Nd 

G6?]E^G6HEBZffM&BE`ORgUffE,G6E,Y6_tMZEUVXBZP`GFMo?hZ

@

MGuM&AfI8_^?	UffE`O4?JVKcMYACG@ACE,Gf



') 



J

EtP`?ZACG6Y6BP`G*G6HEMZGE,Y6DY6E,GIJGFMo?hZ}a



-

' 

M&A\BZffM&hBE`OoRgUffE,G6E,Y6_8MoZEUN]ffR}a

% 

m

a

-

-6	h' G6HEfZffB_t]E,Yu?JV

-8g^ @#Mc!Ec@nGHE^ZB_t]#E,Y"?JVfUhM&ACGCMZP`G^ACGIJYGCMZ[D?JMZffGA*MZgadc?hY6Y6E,

ACD#?ZUhMZ[}G?}@LUffE`SZE5y





' a

' 

t

-

]ffRG6HE\?hYUffE,YCMZ[?hZE,ZUhMoZ[D#?JMZG`Au?JVW



' 

E,_^_IqcQc^?G6EtG6HIJG"t

-e
a

') 

') 
a

--L

'  ')-n

Fh

 ' 

IAVX?JOQO?JwfA,@UffE,DE,ZUhMZ[?Z
' a

- @IJZU.V?YfIOQO

.%

-L

') 
a

z

( @IJZUIVXGE,Y6w<IJYUAuDY6?JvEG6HIJG

@	AFE,Gfa ') 

-L
a

@#ACE,G

^%

-

.%

-6-=

-n


q

' z



 ')-

-=





@ACE,G

h ' 





 ')-n

z -n



'

 'C#



z -=

'C 

- c

fi##Nd`

`

`

`m

`J



C6`C",C,y	N6^6ffJuJff
u,fi

6^f`J.ffoJu6`

  

6,








   oC\, C6gJ "!#%$%&(')*    *L,+6
.hJff-*C,0/213!#045$5&/6!#879$;:   <<+,>=?@*C,

 C6J

-

sk6 Cu,

A!#?F$E:
'

/ 1 !A? 4 $B&C/D!# 7 $E:



:



!HG,I

'

!#?F$
J I

)




$LK

M NO*5P= `C6`C;*%^Q.ff`R6kCTS=Tg<+,U= J  66,6^h6*L.ff,^J

.h JffLu6ffWVYX!#?F$t6,`-.E*k. 6|.ff,C2C`J6CgkoffLJ6
.ff,Fs,m Z/
k.[/\1  u

 ffff/\#
1 	,Q]=^JC`_-ba XhffCJC^JffLb=[c,. ed *J.
P=f
c ,. hg *i/ 1 ft.iff. ` kja 

 \6k kVl!#,4

$ bA=.^,6C&, 0m
,

]=*\`	<J4<t^6"`h+,ff,ff 

h66J6`


 < |5}.~Ck6C#J%moh<Q*fk.VY}J ,.hog#J
nYoEpPqsr,ptvuxwzyF{ u
<
  
 r,qEq \6N+\ff]=6| } ,C*T`"OV } ,CykA=ff^^,6C&, 
 6C`]= yg66ffJfJ
,6,  *9u` JNCJ`a&N#`Qo-.ff]=~=

6`&JC0Y6JCTzh
= o
!z  
$ 
!$
!zL$
!>%$
L














&



-9- 
 
->
!>k  $
%K

>C^6k a  8	,mj]=6JC`_-.RC`J6CJffLl=TC^.i.ff`/  `/
PL.
FJ6CJffL*Jeoff6,>+J<*;uNp6J*6`&JC%.Q%

 C

^ C "`,6|h ff,fh

-

fix3Q	QQ]BQBQiPNQP-@QiP,LUQRb-,xObHPQ[%QRQQ@]B

QN<N~RUAQ->@]>Q<8[-%O%[-UR5`]	>NA]T-NZ,>]"
3AN]LP<"QPBRALNUA]QOPL<Qj]R>Q0Q>PN;NxQ<><]xP<UQQP>5N
<Q<LH]AQ%LNff2ULHPUA]z>eQ-%YN	P]<UA]QYeQ>NA]
kPe]O>QN]Q>Q]kU-A]>NA]z>D]QORNk<<>Y]ANffQUNA`sNP]NLZ
A,e;AQNT>N5T,]k,i5>A`sNP]kPA>>A]QY%QP\j]L"BA<\]#F9B
D#  0S <<>2<R~RH]R,ffAUT>ND#  Lj]B~YUQN>-A
AL>A]QRN]8]YQ<ZA<O  #k6	Cz%<<>[~	kP]#SO;L@l
kQ<Q<<k  #  B  A  LUQ<fz<#8>A`-l]f  jF5e]QO>NA]PPkQ<fN
]ffk>	QN@>Nff  #    #  LEN>bP[A>>"^  A    A  LEN[
ffUNA`-EBPk  0YQPxN5N	UQ%>-AP]kzNe]Nff<k
><R,]>OAQNT>Nb]A]>Q
P%,]<QL<

Q]%U>-A]AN]-5>N"#sNPe]AlSB"LN>A]QON<Q

	ff
fifi
 "!$#
%fi&'(
) < <LHj<QLk>%Q<-P-S>QY>>-UQ->Q>PN>
*	+,.-/10/32-5476'859;:2-<+=?>@2ACBD/'-EF0/32-GH:2-<7+=I
J ]<;L
K "MDN PORQSTUWVXOLQY[Z;\]S^_'\]Q
S NPY
K 0N`"MDN	NjUQ%z>baNLdceafK
kQ<>hgiaj2
g 
 A<lk?mnM N >,l>OXOLQSTU;
2
V p^
o NPRPRYPA]R]<<PL]"[
k ,]>-P
]e
k 
*	+,.-/10/32-5476]qr9RstuD+Fvuw3E-7+I
yx{z}|~U|7p^S
U ]CM N ffYQFz <QAfA<0PQ-^
 [M Ne AEB
zff8eQ-%N]PQY,  ]^N> N N%PM

*	+,.-/10/32-547619Rw'A"27W0>@2-<+=I
 "<kimMD
N %U,[UR^YjQ;_HORQSTUWV0SNP[;LK kEN0AbP]>]RNPNB>Q
P[YPA]k@NR
K >%Q]e
k 2
l=EAuDw3+46p QYA<
k MDdc  #;LK LP`   RK R
Z
` D

ffHlAkPb

v2uD27/30/32-46]4 ffPlP><L"-A]N;P]>][	N	,]AkPfA<k,]AkP;
v22L <dk7N U;k7HlARA<BN]<k k7EjAk7P59NffRKkxQ<
;L[
K nk
 S%<<>	ggE YP0P]>]ZR@N>QPZYPA]%NkZNeK
N>0Q"k  
 Qk`]%k]P><LA-P]R8P]>%PQY<NjA<<P]lP]>]RNP
YP]NA]0N>%U]P-z>
k N	>Q%>-"PbzNeNff k
 Q	zNe]HQl[<Q<L,e>NA]NE<	T-@NN>AN  UiAU vLP%kPU

%`]Pee-Z<L`][B>QOQ>PNBP[;>";ONLbP;ZLFS>P[>R,]PA
P[A<L<



fi.FFF FLR
 C 71r;jD[e1[{LLe;;j[Rh[{;F;j'
i 1     FF;}F;L{Lde	i} i
L[L1?;}1   1     X  }F[11[[ 1L
ff  [	
 F PFj1F@3F ff
.fi
He F
rpff7%F;
F;PL{LffP b 
 }i  
 dFF{  
      1H

  
   F;"Fj1'p1 
{	1L1
 l	pir  7 dp
     
F   d  7  1}11PFF;F1H'p 
W  {;FF{  % !#"".
$"ff%
 !"P[ F 3f 1 &("
' [ 
 !$"
' ff)
 
d3lF;	1 ;
* ;}Fp1Fff+ [;{	
 ,. -1 /"0
 !1 
l3}PFXLLCLj11@ 
2
 !4
 3;{;FL1F;XL{Rfi
 , ;R LR5
 ,n1 [{ Fj1[l [
  LR15
 ,lDF;6
  !2"   D11 "Fff}FL	7
 (
 !8
 H{
 , 1{};RL {
{;Fd  1@[{:
 9}L	ffj1R;[}F{}dFd1[h;X;R@ff ,(
d}
;[d14
    ;
 1Ljh{.L{L}F; 1< 91L1ff1{R  ,2
l3} 1
	FH[;j;R {h{;Fj  ~L{LL1 [H ;ff11 ;L
F=
 HF1l p1 
;?
 >
F"ffF@[	1	FF	;; pffA9hF$
.CB;[F;  XLR1D
1"1< 91L1	{ L{L Lj11} 1[L1;[;{L;FFhF; F
 F
E}{f 
 FFG Ffi
HF [F 
@

 C 7IH;?J"[A97@Kd/LNMh1;
POQJSR T " 2U J"A9{WV
F;d@ p  1F1d}XJYHF; POQJSR1[{L{L
L5
 Z "F[9 .Kl2LNM  hL{Le;5[bP{;F  W
H



 OQJSR  [  \    [  ]   
P
1 
1 
D BX
 % !8" P
 OQJSRR ' % !8"[h}F;;;L{LCLX1 C@:
 "0
 !hH1 P
 OAJRF
LLP [[7
 !2"^
' [Of0
 L1F;12
 [ F+ RRF;2
 !0" 4
 _ [4
 `;5
 ,
Fp1FX+ [;{d. -11 
 !P
 HF{;}3@FX4
 _L1F;LR1?
 , 1;RLL?
 , 1
[{lFj1d;FFL{L1
 ,d1L
 !0"e
'  _ba }{ _ ;R LR7
 ,el[{F
@@	F};ff11 ff1{R  , h;X;R  4
 _~@	{H}[;j;R HP
 OQJSRRY
 >
 C 7dcr; X[@A971X;l:Kl/LffMd;h1;
PO2R T $"  U ;;8J" @A9&eV
F;d@ p  1F1d} P F;"POf(RD1[dL{L
L?
 Ll1L1	 }b;[ff4FgfXE 11FFhFF=>
HF'p1
 hd}F	B;ff}1d'dFL1L}LFHDFXd1F

 7 7dk; XhA971j;dPKd/LNMd;h1;l1m  F@dD
1l	1C Sl3 9FF;7n Kl/LNMld
ij

n T 

  '   U T    '   V   d}A971oV
prq

fistIu1vw0x8yztd{Py|}P~y<wy<|r$o<|.y1fi|r|.o5|u%o<~y/	twv0xow~tb$};td{P

=+0&<do
5.W1o1<41	/(b	o	<do.dofibAC<oW+%4+
Pddo1=C:^o?<1r&0W+4#GY;&<1<ddoN%5+:ddo1=o<b
  <5 (b78o4<d+4+<	 o#	<1+<b8 h 7=<1+%X+7 ddo1
b6 I   h  Nr<d.d+<40 I   I  4;2W+4$GS.d4<5o<oeS1
<W+48hN4Wo	o4fi<1+<b4	;7+^0&#  Wo88o
o4doN1185r<d=gd7+?
=<1+%db+oo0r/fio<bfidoo.glCbA<ggo=4orr
<Y5.doodgd7+
W  1< dood)dr2orddorbA<ggdd%d.do++
o<44+b+.gdo=<611Cdd21^+1d6%d  doodr)Sdor
dorbA<ggdo=+1%d	.do++
5.W1=o1<71PbPCbA<doP=++SgdoobPbA<do<Y1Addo8G
=<1fi 8+oo+5r4d0YAd1/  1	$1/1r0oX  $1bAC<o
 o1<+#.d	C	gd6 ;1+4$ 
 2;^
  	
  
fiff 	
  
  
o11do/C: ddr
 oo1Y4<b?P  1r	8	o<bfi:^  
+r<1Ad=+o+ )G518lo11doY6$. $b=.bbA<do11#<1
  5 b bA<do
 5o<l11do8^gd4r	<#r:bdo1;?<b81.o
b#d<44<
   &
 18<1?+o=rrAd15+/  =o<b8o=%
<do  1ro+<do.doodo+++
o%	1C  b=o?bAC<oW1#1;d7o++ 4r<d41C d+	r
;gdr
 l.X1++rW  ;gd
   b= bA<do%:o%Addo/G)  Pgd 1  
<doC15<?o11do4N  dr!
 Po =1.o#
 "o% $&!'( )*/ &
 ,+
gd4 ;	4?o4+<PoP%oo$l bPbA<d	Sg4) o1Ad=+o+G
-#
   .
 ?=+fid+.g2CbA<do5d%d N+/
 01  
 ? <$%
<do1Ad1
 2(b?dX%d.do+1#<1?  =o<b815bA<do1o<C4
o74doN;=13
   
 Yb==d+.gdbA<do
d1fiX.dod <<r=o?r=dgd4 1<+
  & .  '879+  & ff   7:    <;   =     
6
bbA<d=	o#P4<
> @?( .dro<	<21ff+P<bS=4<
A o$I^?2
1.gPo11l8d<++doB>  o	> C1CA ?<b$d+.g2CbA1rDE  &
4o<N
e+  1d<d.P1$1=o7o4   4   >fi'  & +<Qo%.gdr+1%d
dB> 11&+#
 F#1.<d.1/1 oo4   8G
 F  A'   +oQo%brld
1C<=dB
 A^H
 fioo=+o+   41+I
 >  '   +  A'   +P1J
 >  '  & +  >fi'  & +N L
 K F K o
?25+	1I
 >Wgg:CbA1r
 51Ad15	<+?o8+1d%d b;b<++NdB
 > 1J
 >I
1(1fid4bA1r  06;Ad1C
 > 1M
 >  d1<$o0%d .
 +4oo
+
  6
 P
    7:     ffN  O
      &
0    .
 b01rdQ
 >  5Ad1   16
 5 o	1Ad1o11do
>fi'   +SRT>U'  & +#bA1r(o5++   42;4<bfibfi/#&o >  d+.gb, V
odW
   &
 W18<b7ob? o1?5od <ro?rr==
r<dCd7+
5

XY

fiZ\[^]^_a`cbGda[^`cbMegfch^bGi0ih
b

j m
k lNnpo)lGqsrptvuauxwzy|{c}c~,|^	
|L~^GG}:y|N^}c ()y*c
 o)nmnG0\^~0:GEv}c~1:}9D|y|^S(y|:~,y|1a}:y|P^}9 ()y:G N1~}cG}NE|,|}c
^P}#(y|^
^S^y}N}c.a4,\44y|^ }.cL(300^Mc1P,|SDc^4~1:~S:~04z/@:G
y|^I#}#0:cI}cNy|Sa}:y|P^}9 ()y@,|ScNPG^zy}N}c:cG}:y|N^}c ()y@,|ScH^zGG)y@,
}cy|^JL(y}1a}:y|P^}cyv*1E4c4Jy|^:~4aN~}cG}NE|,|}cB^^^:GJ^#~,Ny|Iv}:yy|}4

 nmonm(Go)6rmtvu^=M4E(^v}c~@,:~,|^{IG}:|Ny{94^~c4::GDM0E\^v}c~@4G9|^{a}:|P
 y|{c4^~94N(I,}:y|::Ny|D|G}:y|N^}c ()yH,|Sc
)
 o)nmnG0I^~}9^4}c~4	^ :GC^4}9~4	^|9c 
^}9~D|G,0:G010WII^4~C}cNy|x0}cN)|G G}N1)y|{c4^~0}9~ NycHC4:/G,
HD4^ |G,c}:IppS 4^ y|^DJ:GW^mE|G0Cp%H8 Ic^^}cNy|Ca}:|PDy{94^~
v}c~ Ny(:S}C:GMwzy{9}c~,|^^|Jy}B0}cN)|G#}9NyG}:|Ny{94^~v}c~ Ny(:c1N
)yy|}:!v}c~  GJG44~z\}9~,4c0}c*Ny0N|,cpc\DG)yy,4c
 nmonm(Go)6rmtvuPO%wIy|{c}c~^^|LG, HD4^ |G,9J}:Ipm@S! 4^ y^L1GC^
| I0}c*Ny0N|,JG0}cS|BJ0
 o)nmnG0I^#G~0,~:GEv}c~1,|}cy|:~yJ0:cIJH,|Sc^#|N|,()y\:G*GG)yH,0:c
 4JI,|ScHNH~}cG}P8}9^^H:G.^Sy|}N}cM(D0^0^6Ja,|SHcc|^{. 
,|ScPG4
^#~,Ny|,|^{C0}cSNy|0N|8(IJ  0 
 }cG:N}#^}cG)cI^~}P}:GG:^,I)y|{c4^~cH:~^cG)y|{c4^~0cIN(S:~:~,|^{
}c~L4G9^{G}:|Ny{94^~c|/wzyy4@#|N4~:)y)y|{c4^~^JE,44#y|c0y|MG:D^4~^}cNy(.a
S}c~C)y|{c4^~c*|O^C:*B,~G0^~cI^B9N:N:{c}:#^C~Ny0S^~4P|ON(
G:a4~*G:*}cG0.,0:~,|^{.}c~4G9|^{/G}:|NC)y|{c4^~( v}c^G 8:G^~}:cM}MGW}c^:
G}9a}:y|P^}cyv*B)y|{c}c~^v}c~ :,(Ep:Ny|,:G^J0^4GE|}cM}WS4~,(*4Sa}c~)y
|N}9~1:,|}cC~#}c^)|^}c~~4c

	ff
fi
ff!#"%$&'()*)*!+)
,

04N,y|c@^ ,:~Jv}c~I~c0:Ny| ,^G)y|{c4^~c}wIyy|4@z|P4~)y)y|{c4^~G9Ia0}cSD*}c~
, ^,41,(:@NCv}^0GE|^{B}9WGG9|^{B~c0:Ny|1y{94^~c#G::~.-0/:*12-0/c|^1,4G,G:
^}C)y|{c4^~,~0y.0}cN)|N|^{|(~c0NycL^DN|}c^44~,|^{W}c~JN  4a0y\:G436^
5 ~94~
8 797cNHIc!} GGC1)N)y~90:Ny|D,^py(c#0}cP0)|N^{J)yy^LN|~44GcE(#~0y(:}9G4
^;
 :=<'> ?#
 @0S)y|{c4^~^
IN(|Cc^9|,|}c^
 AN+
 1CB8ANI)P|1yy{94^~ 0}cP0)|N^{)yy^
GcE(3~0y(:,|}cG4I^* ,'D  Ez}c~By{94^~S0}cN)|G
 Fc
 F ~0y(:}9G4H
 G}c~#~04Pyc D ~0:c4^{c~4
:GJ
 I}cG,}c 8 797cNG9 (N4P,GN^S}c~S1)N|1)y\~c0:Ny|1y{94^~c40|{cND}:IIN(
:~z}:EL K4#^*
 MNF
c:G }c^I}EL K4
 OP
 7MPP
 EI}:4c4~:^y(:4~}9^GS}#aI}:@^}DGcPE|G0#:P
|G,:G0#}:,(EpNy|,Sv}c~G:)y|{c4^~3(I)y|I)!:,(Ep:Ny|c^^Ny||I0}cP0)|G^~0y(:}9
Q ^3}9~S4~I)y|{c4^~ccC0}9P^~4#Gc83~0y(:,|}cG4
E6H~}ca}PE|,|}c
 OGR OM.)	G1^W,0y|cC^}c^)P|1y3)y|{c4^~0c}: D ~0:c4^{c~4O:G
I:}cG,}c/S 77cN\~ |Gy|GN^1)y|{c4^~9}:\^0^~~4N#G:G4~
 Ez}:4c4~a|D~4)|G#}
^I^4^4~^4J:~#1)N|1)y}9~\^}9
I^L}:H^D1}N}:y(!}9~:G)y|^E|^{11P|1)y~c0Ny|,(;
 T)*
 UVA@, 0S
 @W/9X1(c}cC^^
y(c,z}:^)y|{c4^~
^IN(^~,4~9~c00:Ny|,c

YNZ

fi[]\C^+_(`4acb(d(\Leffb(fhgffi(bkj`*b(lf8monp(lkjfSb+qrqsmtqvu(wyxzf8fSm{]|Rq}xzfN^	mli(b~6\`(_4aym`(i(\2jog&\Leffm
c9HL8L*S+
0c(=(0 s(.S*V6*'(+0r	Lr8L*+4
 LLPRLP(L8(+SL(rzsv(29(s0L(8	}tSL(=]zs
sLt8h(+(6s(}  r*L+
=(6;s8L=9'ksr   L(r*L;8LrHz(*LN(	
}SP88CJc=(sk0=&02  (02SLL(0= }*+
(0=ffP2  L6(0= 2
}S+}'	+6( rsr89r=
 (ySL;*2&9  *L(0Lr*L*6s(*L*=L(.9  L(+N9(rz*%c
c9HL8Lr6*Pt4++(]S+v.*;008
Lr=L

  	ff
 fi 	fi
 +(

; 
         
 
*+

; 
         
   
  .
 +(
0           

   fi !"

}SP88$#k =2;Sr	k HC.S=*+ok =W0SH*}S%9  L
}S+J(6;;*+.*&z+}*+6( rs;rSr*+y N=&%*L(0o*+
+*0Lvr8 'rff
zk8 H  sN9yNtLySL;*(}(SL(r9
}SP88)(=(N9(r&*Sr+*S(-,S.+/,*6ySLySr9r*L
}S+&;((L(;(v(L&
 021"34oWz+H*+o6( s88 'r'24(*8=0LLyS
(+L+*H(s28 t(9L(42* 9+9  (L(;(sLt (*ff+s2  
(+L+6H(8SL(6rSL4s(}*=(  LySL(=;*+;v}0*
(68 z**t;  tLL6
 5(8 7(=
&L 9+HJ(* +*;(48 2L+*c=((;  s8;r*sL( *+ +9L(  *Lt
L9y*L*0(s*;Lh82S'9(rSLL( r*LW=9+=;'*tJ
 :< > =z4SL(r(
(rWv( ;
 :< >=z;SL(r((*+
}SP88L  +sc+*'o2&('}(+=*( ;
 ?	6(6=*L+r*+8A@ !BDC fi+fiEGF+*-HJI(0'sffr*'(sKE ySrSL;L <  : 
.
L.M O
 NQP  L fi N/RSC ff=(o(}* *L  L 96.?  L
}S+H& +LL+9trNc'sL;(r2( ;:< >=z;SL(r ff*L+
(0  8L L M !
 E+=*4  8z(0+2v2*LT
 ;t*+4s(
 N P 26SL*=8;L&
UV

fiWYX[Z[\^]`_.a^X[]`_cbed`f[_.ggfQ_

hi.j2hlkmhAkonYkqp.rtsmu.v"wxvykmpGzY{}|>hk~nAwxj`nDk$sm	`wk$.wxv	hti.j2h `;rphjkqp.nAjs$shi[w.j`nDk~rws~j2hkm`p.n>u.nDkmp[
w`{.{hi[wu[hk$skmhy`Q"w^wsjp.v	[
u r`wthx.x`"`jp.vhi"u.n zrphjkqp.njs$s.j`nDk~rws~j2hkqp.n{
 kmp.rwj2pSnu[rts~j`nnA2Assmwp8njsqw[jrphjkqp"kmp[	js$s-hti[wK.j`nDk~rws~j2hkm`p.nAi.j`nht.w/r`phjkmp[wxv
kmphti[wS;>A`pcjsm`w[jkmp`v"wKhy.whj`rhj"sqw`}j2p.vkon/>r`"sqwhtw`hti[wk~nwyw^ws
j2p.v	u[
 rt`whxx``">r`"smwhwp[wxntnA2s$sm2;n{
wxn"kmhwhi"k~nwxnu"sqh`kmhnwwn^nnDkm"smwhw[[wxnnlr`p.nhjkqp"hn`pS`"`~K2kmp"hwjsonkqhti[`u[h
wxnhtk~rhkmp[Khi[wkmYj.n2smu[hw^nDkmhkm`p/kmphkmw`j2p.vnhk$s$s.`[hjkmpj^2smp[`kojsqhkqwKjsm``kmhi[S[u[h
hi"k~nkonYsqwhA`lu[hu[wY{
A2K[`p[w/km`i"hK`u[wxnhkqpShi[w/wsmwjp.rw2hi"k~nYphti[wK`u[p.v[nhi.jh;hi"k~nA/km`i"h;^w
 .
u nhwkm`i"h}`u[hhi[u.nj2p.v[nl>``w2..hj`rhj"sqwnu[.jsm`w[jn{i.j2hk~n2w`u"s~vs$km`whi.j`w
jwxnu"smhnDkm/k$s~j2h/hi[wu[p"k~`u[wjkmjs$kmhtwxnu"smhYhi[w;>prts~j`ntn[ni[2kmp[hti.j2hhi[wxnw
j sm`w[jnYjwhi[w`p"smjsm`w[j`nnj2hk~nD`kmp[n`wn.wxrtk$r/rkmhwkm`p	2}wsmwj2p.rw`{l|>p>j`rhx"wxrwp"h

wxnu"smhn"hi[wYj2u[hti[`n}j2`wp[`wpKjp.vK2`p.ntn`p[x``.nhj2hwhti.j2hj2p"hj`rhj2"smwYnu[rtsojnn}hi.j2h
k~np[`h`wh"p[Ap	kmp&hi[wskmhwj2hu[wrj2p[p[`hr`p"hjkmpS`wKhti.j2pShi[twwK.j`nDk~rws~j2hkm`pykmp.rtsmu.vkmp[
r`p"`wnwxn>htwxri[p"k~rjs$sm`kmhrj2p[p[`hr`p"hjkmpc.j`nDk~rws~j2hkm`p.n`hti[whti.j2pT;j2p.v;`
	[t.`{i"k~nwxj2p.n-`kmp.nhj2p.rw`hti.j2hKhi[whSjsm`w[j`nzj2p.vc;j2whi[w
`p"sm6j"kmjshjrhj2"smwjsm`w[j`nr`phjkmp"kqp[yhi[w/ws~j2hkm`p}j2p.v6hi.jhKj2py`whu[p[[u["s$k~ni[wxv
hjrhj2"smwnu[rts~j`nni.jnh.wsmwxnnw[[wxnnDkm`wkmp&hwtnhi[wKp"u[/.w2.j`nkorws~j2hkqp.nhi.j2p
hi[w[wxnwph;jsqw[j`nr`phjkmp"kqp[.`w.j`nkorws~j2hkm`p.n{
&D2[22>
|>hnwwnlj2[[`[k~j2htwYhtnu[j2k~nwhi[w;nhj2hu.n}2hi[w;nwxj2ri/`jkmjs.htj`rhj2"smw;nu[rts~j`nnwxn
2s$smwp8nAkmp"hwjs-jsm`w[j[i[wwkqihp[wj"kmjshtj`rhj2"smwKnu[.jsqw[j`nA[wxnwp"hwxvkmp6hi"k~n
.j2^w/kmp.rwxj`nw	hi[wp"u[^w/2ru[wp"hsm&"p[2pjkmjshtj`rhj2"smw	nu[rts~j`ntnwxn/hywkqihwwp
kmp.rtsmu.vkqp[yhi[w;>prts~j`nnw^ws-j2p.v	[
u rt`whxx`""j2p.vhi[wp"kmp[wjsm`w[j`nl`u[p.v
j2wp[`wpSj2p.v	2p.nn`p6``"{
p[wjp[hwhi.j2hhti[wwk~njr`p.nDk~v"wj2"smw2`wsoj	.whwwpShi[wxnw`nDkmp.rwKhti[wnDkmwxn2hi[w
jsm`w[jnj2w``>p[w2`[2>wkm`i"h"`[x>wkm`i"h`j2p.v/"`">`p[w22hi[wnu[2hti[wnkqwxnl^wkqp[
/u.ri`twhi.j2p	[x`Q{[kmp.nhj2p.rw`QYwni[2YwxvkqpSj2`wp[`wpj2p.v`p.nn`pyx`"hi.j2hlhi[w
`p"sm/ws~j2hkm`p.n2hi[w;>A`pjsm`w[jhi.j2h}k~np[`h}kmp.rtsqu.v"wxvkmpjp2hi[wjsm`w[j`nvk~nru.nnwxv
kmpShi.jh.j2.wj2whi[wws~j2hkqp.nj2p.vy  {
r`u[nw`}hi[wu"smhkmj2hw`jslk~nKhtrts~j`nnDk$hti[wSnwhK;j"kmjsYhtj`rhj2"smwnu[[
j sm`w[jn[u[hSnDkmp.rw&hi[ww&j2w&2Snu[rts~j`nnwxnhckmpwxnhkmj2hw`Ahi"k~nk~nSrtsmwxj2sqffjcp[`p"hkmk~js

hj`n{wxrwphwxnu"sqhn`pShti[w
	`fiff`;n.j2hk~jswxjn`p"kmp[S2`p.nnpSj2p.vSj`wp[`wp
x``;ni[2ehi.jhK[u[hw)`rwwhi[[v[nrjp&i.j`wnu.rrwxnnkmprti.j2j`rhwkonkqp[6hi[wr`"smwhw	nwh
2hjrhj2"smwnu[rtsojnnwxn{Si[w[wxnwp"hK["sqw k~ni.j2v"wkmhi nw`wjs`v"wn2j`p"kmhu.v"w`
i[2w`wxnkqp.rwhi[w	>Sjsqw[jSr`p"hjkmp.n`p"sm& twsojhkm`p.n{	wwhi[wsmwxnn}kmhk~nwp.r`u[t
j 2kmp[hp[`htwhi.j2hhi[wtwj2w`p"smu[j"kmjshj`rhj2"smwnu[rts~j`nnwxn-hi[w/>jsm`w[j[
2
`u[h2hi[wj[[kmj2htwsq6 [x  nu[rts~j`ntnwxn{ynwphkqp[wxvTj2.2`w`wxrwph/wxnu"sqhn"&hi[w
j2u[hi[nj`wp[`wp	j2p.v	2`p.ntn`px"`js~n[2`k~v"wKj/.j2thk~js-rts~j`nnDk$rj2hkqp-hj`rhj2"k$s$kmh
kmpSAs$sqwp njsm`w[j["u.nDkmp[	nDkm/k$sojwhi[[v[n{
l`p.rwp"kmp[whkorhkqw`"kmh;nhk$s$swjkqp.nh/[2`k~v"wKhti[w;p"kmp[wKjkmjs htj`rhj2"smwKjsm`w[j`n
2j`wp[`wp/j2p.v/2`p.nnpx``"^kmhin`wkqp.v2.whk~rlhw^`js"kmp"j2hkm`p{}nDkm"smw
w.j2/kmp.j2hkm`pni[2;nhi.j2hYw	rj2p[p[`h/u.nwhi[w[wxnwp"h/hwxri[p"k~u[w`Ynkqp.rw	hti"kon`u"s~vGj2`whi[w


fi "!$# % '&(# )+*(, #.-/# 0/)214365 0.-/)7#8891:8<; =?>)2)716@Afi8B>)C160/, #EDF "!?16 , G-4*H'&(1

I
J2KML/N'OMP'Q RES7N'R6JUT IVS6KWYX[Z]\V^6_`/N'JUO
J$a'bMLKMOS6c c4O
d JfegLS7NhP'OSOMP'i6JI
JVNGSOMP'^6QKP'Qc/L\VJ2cjT:klI9JVNFSmOMP'^6QKn^6Q
MK OSmI
OMP'Q R^6IJUQcgP'Q Rl`C^P'Q:OKpoI
L "
Q q/r6s:tvu:w$axWJUTJVN(SQcEy{zL I\9|6JUI
O7o~}266.o:SQc+i6JUIMPhklO
dSOYSONJ2SgKMO
^6Q J^mO
d JYWnXZ]\V^g_`/N'JUO
JYS7N'R6JUT I SgK^~XI
^6`C^:KP'OMP'^6Ql fiPGKP'Q\9N'Lc/J2cCoK^n^6IO9d/PFKpo:KM^6_J^6O
d JUI|gP'Qc
^JV.` I
J2K9KP'i6P'OMklPGKQ JUJ2c/J2c6J2SI\9d/P'Q Rl^6In^6O
d JUIBKMOSmI
OMP'Q R?^gIJUQcgPQ R4`^P'Q/OBS7N'R6JUT IS6K\V^gL/NFcjS7NGKM^
TJ<I
L/P'OML/NvL I
O
d JUI2ovP'OKMJUJU_$K`C^:K
KP'T/N'JO
dSOnO
d J<O
J2\
d Q/PGegL J2K` I
J2KJUQ:O
J2c+d JUI
J\USQSNFK^?TCJfLKJ2c
^6IJV O
JUQcgP'Q R?O
d J`C^P'Q:O9ZPQ/O
JUI
iS7N(S7N'R6JUT IS$a]PhNGS7P'Q~o}266/P'O
dl_JUO
IMPG\OMP'_J6
$?~H ]H~(


J"dS7i6Jl^6L QcJVP'R6d/OlQ JU_?S7/P_$S7NO9IS6\VOST/N'JKML T\9NFSgK
KMJ2Kl^mBNhN'JUQ~K$P'Q/O
JUI
iS7NfS7N'R6JUT IS onSQc
` 
I ^igPFc/J2c4O
d JU_P'O
d4_JUO
IMPG\O9JU_`^6IVS7N~P'Q/^gI
_?SOMP'^6Q4^6QKOSI
OMP'Q R$^6IJUQcgP'Q Rl`^mPQ/OKn^P'Q:O9JUI
iS7NGKUo
LKP'Q RO
d J[^6I9_?S7NhPGKM_^^6I9Qf~KHaM^6QK
KM^gQfSQcynS6
z \9|.KMO9I2^6
z _Eo6}766/n`SI
OI
^6_I
JU` I9J2KMJUQ:OPQ R
` I
^6RgI
J2K
KP'Q$O
d JnI
J2KMJ2SI\9d?S7P'_P'Q RSOSB\V^6_`/N'JUO
J\9dSIS6\VO
JUIPFK9SOMP'^6Q$^~O
d JO
ISg\VOST/N'JKL T\9NGS6K
KMJ2KH^
NN'JUQ~KPQ/O
JUI
iS7NS7N'R6JUT IS g
o O
d/PGKH^6`JUQKH^6ISB\V^6_T/P'QSOMP'^6Q$TJUOMJUJUQ?O9d JYJV ` I
J2K
KP'igP'Oxk^O
d JYnZ
^6I
QlS7N'R6JUT ISSQc$S7N'R6JUT I S6Kd/PF\9dE\USQ$JV.` I9J2K
KV2/2CG6hTJUOMJUJUQ$P'Q:O
JUI9iS7NGKUo ` I9^igPGc/J2c$O
dSO
^6Q/N'kEKMOSmI
OMP'Q R^6IJUQcgP'Q R?`C^P'Q:OVK^P'Q:O9JUI
iS7NGKnSI
JI
JVNGSO9J2clP'O
d"YnZ]^6I
Q4I
JVNGSOMP'^6QKU


6(vE]C(~C6
 dSQ | KHO
^Hd IMPGKMO
JUIynS6
z \
| KMO
I7^6
z _Eo:JUQ I
klSL O
6o SQcO
d JnOx^SQ ^6Q/k:_^gLKI
JUigP'JUJUIVK^6Id JVN'`/L/N



\V^6__JUQ:OKp
 
g( C
nYn]Z]v}a}76 }/M2VV6:M:766Gg6(gUU2M2CH6f{ 7G6gC2h67V
Yn{
6monQSd JVP'_EoH(o{6fY_JUIPF\USmQK
KM^ \9PGSOMP'^6Qj^6InI
OMPh\9PGS7N]Q/O
JVNhNhP'R6JUQ\VJ6o(nnY
X[I
J2K
KV4  X[I
J2K
KU
nYn]Z]g4a}266.<M2VV6:mBM:E67~g66C6(6p7x7V6{ 7G6C2F
g2V?nY{
g9mo/X^6I
OMNGSQcoYo{6 Y_JUIMPG\USQEK
KM^ \9PGSOMP'^6Ql^6InI
OMPh\9PGS7NQ:O9JVNNhP'R6JUQ\VJ6
NhNJUQ~o  Ca}26g/~"S7P'Q:OVS7P'Q/PQ R$|/Q ^NJ2c/RgJBST^6L OO
JU_`^6ISNP'Q/O
JUI
iS7NGKU(6/66vM
:[o 6/a}g}6g7.7: 
NhNJUQ~o 
 ~aV}26 }V  U
J _`^6ISN(I
J2S6KM^6Q/P'Q R"SQc"`/NGSQ Q/P'Q RQNN'JUQ~o(v'o~SL O
6oB'oXJVNGS2igP'Q~o
FoSQc  U
J Q JUQ/TJUI9Ro '
o J2cgP'O
^6IVKUonVU6:":96/<h6 Uo(\9dS` O
JUI"}6oH`SR6J2Kl}V /:4^6I
R:SQ
SL/_?SQ Q~
yHJUQ UJUI2oHa}766/4QO
d J$O
^6`^mN^gR6k"^YO
d J$R6JUQ JUOMPG\Q JEKMO
I
L\VO
L I9J6l]Qx7VV6G/M/
666CYV667M7G7VU'og`SR6J2K}2/U}2g 

nJ2\9d:O9JUI2o'o4JVP'IMP]on'oSQcXJ2SINovna}26 }m

 JU_`C^6IS7NB\V^6QKMO
IVS7P'Q:O$Q JUOM^gI
|.Kp 7Gg

C2hg2V2o/  }V 6 
nJVN'R6ISmQc/J6o XSQcYL ` OSvo:a}766/I
JU` I
J2KMJUQ/OSOP^gQ$^6IJ\9P'JUQ:OnO
JU_`C^6IS7N~I
J2S6K^6Q/P'Q R
Qa]nYn]Z]g o}266/Vo:`SmR6J2K6 }.66 
nISm|6JUQ R6I
JUQ~o  ~SQc"^6QK9KM^6Q~oXa}766/"S7/P'_?S7NO
IS6\VOSmT/NJKML T\9NGS6K
KMJ2K<^(NhNJUQ~KP'Q/O
JUI
iS7N
S7N'R6JUT IVS (XI9JVNP'_P'QSI9klI
JU`^6I9O2]Qja]nYn]Z]6vo}766/o/`SRgJ2K667 6

	

fi
fiffff

 "!#%$&'#%$)(+*-,+.$/10.2$34352$)()67,)89;::=<>,?*@2.AB./3BDC2EGF=HI#%J4#KC4HL3'3NMPOQC%.J5MR2$S2.TfiJ'CJ.U=MPHPMRJWV

MR$YXZHPHR#%$)[\3]	HI&#%U,7^_$S`fia5b;cddefhgji"klbnmpohqjdsrt.ohqDugovd;agwovfLbgwxybfhgoZz{bg%m%d;a5d|gcd-bgD}-aovf ~fic|fLwx
ugovd;xhxPfid;gcd%+u'y+z}uK%,{*@2K.FF#;.;,
 #%'#%MR$=M_(X,R(jC'=U#%4J;({,R(.$/jC4.#)#%;(,89;::=>,D*)#%EGF2	Hfi'#;3n2$=MR$&YMR$*MREs#%&.F
^ j^5^,Zu;{}-l=xhxd|ovfLg(=8W=>9,
 2.HREpU=MLC.(+,+],.$/.EMR;(+-,+89|::=>,l{2EsF=HR#=MIJ5VY.$/|HR&25MRJ'E3T2B'#;352$=MI$&D.U2J
J5MREs#X&.FvJ'#%2'#%JnMC.FF'2jC'),ybjagwx)b5mpohq=d?}z(=j=85=>R99||Q99%,
0.2$3'352$)(+67,Q.$/C 4!3nJ';2 EY(],+89;::=>,XHPMR$#;.'vF'2&.EsEMI$&Y"FF'2jC4YJ'2J'#%EsF2|H7'#;.
352$=MI$&,^_$S8_X]XX^__:(@9;::=>(F.&#;39;|+9;.j,
0.2$3'352$)(=6,=.$/.!#%$&4#%$)(*-,89|::=<>,XC2EsF=HR#%J'#?C4HL343NMPOQC%.J5MR2$D2.T)J'CJ.U=MPHPMIJ5VMR$DZB{_,
yb=agwx)b5m]}-aovf ~fic;fhwx+ugovd;xhxPfid;gcdd%k%dwa5cqj(j999,
-.J4(,.$/1@/=!MR$)(67,789;::9.>,^_$=J'#%&.JnMI$&Es#%J'5MLCs"$/J'#%EsF2|Hfi|HPMRJ.J5MR#J'#%EsF2|H
'#;352$=MR$&,^N$18_XX]X^__:9(+9;::9.>(jF"&#;3B.9.j,
2U".!M3({,89;::=>,D#%$35#J5MREs#Y.$/SJ'#%EsF2|HBC2$35J'	MI$=J3AMRJ'  ,Y^N$AB.'J'2J|(,
.$/Z#%U#H_(,R(#;/MRJ'23%(`a5b;cddefhgji.k-b5msohqjda5eDugovd;agwovfhbgwx{zbg%m%d;a5d;gcdbgS`fiafhgc;fQxPd%kbg
gbxde;idfidnQa5d%k%d;govwovfLbgwgeDfidw.k%bgfhgji-Bn""(@F.&#;3-."(@fi.EU5ML/=&#()X()-X,
2'&=.$-"=TEK"$$),
2U".!M3(B,89|::=>,*@CJ"U=HI#/ML3hW$CJnMI2$32.T]HPMR$#;.YC2$3nJ'|MR$=J3%,^N$`fia5b|cddefLg=i.kKb5m
ohqjd-geugovd;agwovfhbgwx+z{bgmd|aWd|gcdBbg`fiafLgc;fQxPd%kBwge`aWwc;ovfhcd7m%baz{bgk%ova5wfhgo+`aWbia5wfLg=i(
F.&#;3B:=<%=<j(fi.EU5ML/=&#(Xp,
)3'35#%(0,_,=.$/CXZHR2j2$)(,89;::=>,XC%"$2$=MLC%|H+T24ETv2{&#%$#%|HPMI%#;/GHPMR$#;.]C2$35J'|MR$=J3%,
yb=agwx)b5m-+	s4bxPfLcz{bB+jovwovfhbg()9;R9Q9%,
#MR5M_(^,89|::9.>,=2EU=MI$=MR$&|HPMRJ.JnMI#l"$/p.$=J5MRJ.J5MR#BC2$3nJ'|MR$=J3+MR$J'#%EsF2|H'#;3n2$=MR$&,
^N$18_XX]X^__:9(+9;::9.>(jF"&#;3B	=<j,
Z#%U#H_(],.$/- C4!#%'J;(,_0,89;::=>,2.TvJ5AB.'#T2pEC'=MR$#Y343NML35J'#;/.$|HRV3WM32.T]XZHHR#%$)[\3
MR$=J'#%'		H|HR&#%U,.X].|MPHL.U=HR#T42EJ'#.J'23UjV.$2$jV=Es23TvJ'FT'2E.+.fi5=+j)j|l5
3?;=j+|Q|Q.j.j+	.j"=j@%)N.{5,
Z#%U#H_(],7.$/- C'!#%4J;(,_0,89;::=>,D#;3n2$=MR$&.U2JJ'#%EsF2|H'#HL.J5MR2$3%GXEK|=MREK|H
J'CJ.U=HR#35U+C4H3'3B2"TXZHPHI#%$)[3MR$=J'#%'		H|HR&#%U,yb=agwx7b5mohqjd}z(j=89.>j|,
j.$/=#%AB|HPH_(+B,89;::">,)dwov=aWdkwgeG{xPjd|gohk%,=T2/YZ$=MR#%3NMRJ5V6'#;3'3%,
2$&(fi,{"$/{2#%$)(B-,89;:=>,*l#DMR$jJ4#%'F'#%J.JnMI2$2.T?J4#%EsF2|H]'#HL.J5MR2$3MR$$.4.J5MR#,
^N$1`fia5b|cddefLg=i.k-b5mpohqjd%ohq;@-wovfLbgwxz{bgmd|aWd|gcdbgD}-aovf ~fic;fhwx+ugovd;xhxPfid;gcdL}}]}u'4(
F.&#;3B<|j|<	(J;,6.=H_((Xp,X]Es#%nMC%"$DX?3'3n2C4ML.J5MR2$Tv2X'J5MPOQC4ML|H^N$jJ4#HHPMR&#%$C#()2'
&j"$Y-.=TE.$$),
..$p#%#%!+(	67,89;::>,%XFF'2|jMREK.JnMI2$p|HR&2nMIJ4EK3Tv2)J'#%EsF2|H='#;352$=MR$&,.^N$5ML/=..$)(.,",R(
#;/MRJ'2|(B`aWb|cddefLg=i.kKbnmYohqjd1rr.ohqugovd;agwovfhbgwxybfLgosz{bg%m%d;a5d;gcdDbg}-aovf ~fic;fhwxugovd;xhxfPid|gcd
u'y+z}-u4 4(F"&#;3-9;:9Q9;:(#%J''2.MRJ;(^(-X,2'&j"$-.=TvEK.$$),



fi
	fiff	 !"$#%!&'(')"*',+-/.0&"1
23'4.05ff6"!879	:/"	;$<	"
= > ?8@<ABABCEDFHGJILKMMNOLGQPRA>SUT?V?WX> YT[Z\^][Z>&_`V\(> \UV=A,\ABacb6Td(>&_JV?efT[da/> \UVT?QGhg9iLjlk monkfipq6r(s6jltqfiquk:v
w[tsnLtDxyz{N[M|B}~N[G
= > ?@<ABABCJDoFHGh> ?TAB?QDPGILKMMOLG8H>L\c> ?> bbdT&Va/> \Acd)A>SUT?V?W> Y6TZ\\ABacb6Td(>&_
dAL_;> \VT[?SBG90Ejlpjlkfisp[qQr(s6jltqfiq`kuw[tsnLtDI~O(zK&~N&}EKB[G
 V`_:>5V?QDQG@GQILKMyNOLGQSUSU\ABaelTdd)A>SUT?V?W/> Y6TZ\\UVacAGh?Ri&n(tLtLk;sw 4jfi*tcs6&Q[
 pjlkfispqst&it&snLtsg9i(jlk mon&k;p[qr(sjlt&q;q`k`wts6n(t,;gggrv LD b> WASK&M|B}NKDFHV\\(SYZdWQD*F6D
 GacABdV:B>?89SSUT)V:>\UVT?XelTdRd)\UV`E)V:>5_?*\AL_`_`VWAB?LAG
 V`_:>5V?QDG@GD59>Z\D5,GBGD > ?9= > ?@<ABABCJDF
GG I(K&MyMO(G[T?S\d(>&V?\QbdTb> W> \UVT?4>&_WTdV\)a/S
elTdc\ABabTd(>5_dA>SUT[?V?W6zdAB=[V;SUAdABbT[d\G?otLpkfis*w8k;spq`k;jlpjlkfitotLp [skfis*wp*)j
<*&kfin(p[qJ&jlt&4BDb> WAS~|5~&}~yKG*$TdW> ?9>Zefa/>??QD  > ?8> \ABTD6G

5

fi