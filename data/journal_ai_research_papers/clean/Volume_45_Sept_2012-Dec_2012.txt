Journal of Artificial Intelligence Research 45 (2012) 565600

Submitted 6/12; published 12/12

Replanning in Domains with Partial Information and Sensing Actions
Ronen I. Brafman

BRAFMAN @ CS . BGU . AC . IL

Department of Computer Science
Ben-Gurion University of the Negev

Guy Shani

SHANIGU @ BGU . AC . IL

Department of Information Systems Engineering
Ben-Gurion University of the Negev

Abstract
Replanning via determinization is a recent, popular approach for online planning in MDPs.
In this paper we adapt this idea to classical, non-stochastic domains with partial information and
sensing actions, presenting a new planner: SDR (Sample, Determinize, Replan). At each step
we generate a solution plan to a classical planning problem induced by the original problem. We
execute this plan as long as it is safe to do so. When this is no longer the case, we replan. The
classical planning problem we generate is based on the translation-based approach for conformant
planning introduced by Palacios and Geffner. The state of the classical planning problem generated
in this approach captures the belief state of the agent in the original problem. Unfortunately, when
this method is applied to planning problems with sensing, it yields a non-deterministic planning
problem that is typically very large. Our main contribution is the introduction of state sampling
techniques for overcoming these two problems. In addition, we introduce a novel, lazy, regressionbased method for querying the agents belief state during run-time. We provide a comprehensive
experimental evaluation of the planner, showing that it scales better than the state-of-the-art CLG
planner on existing benchmark problems, but also highlighting its weaknesses with new domains.
We also discuss its theoretical guarantees.

1. Introduction
In many real world scenarios an agent must complete a task where some required features are
unknown, but can be observed through special sensing actions. Consider for example a Mars rover
that must collect rock samples (Smith & Simmons, 2004). The rover does not know which of
the rocks surrounding it contains an interesting mineral, but it can move closer to the rocks and
then activate a sensor that detects such minerals. Such domains can be modeled as planning under
partially observability with sensing actions (PPOS).
Planning under partial observability with sensing actions is one of the hardest problems for
automated planning. Its difficulty stems from the large number of contingencies that can occur,
and the need to take them into account while planning. To address these contingencies, the planner
must generate a conditional plan, or plan tree, rather than a linear plan. This plan tree can grow
exponentially in the number of propositions in the problem description, making offline generation
of a complete plan tree impossible for even moderately complex problems. This difficulty can be
overcome, to some extent, by using an online planner which generates the next action only, given
its current state. One technique for online planning is replanning (Zelinsky, 1992), made popular by
the FF-replan planner (Yoon, Fern, & Givan, 2007). In replanning, at each state, the agent finds a
c
2012
AI Access Foundation. All rights reserved.

fiB RAFMAN & S HANI

plan based on a partial, possible inaccurate model, or using a simpler planning problem. It executes
some prefix of it, replanning when new information arrives.
The key component of any replanning algorithm is a method for generating and solving such
simpler problems. Recent replanners focus on generating fully-deterministic classical planning
problems and solving them using off-the-shelf (Yoon et al., 2007), or modified (Albore, Palacios, &
Geffner, 2009) classical planners. This approach is particularly beneficial given the large array of existing classical planners, and the ability to immediately enjoy any progress made in this intensively
studied area. However, this still leaves open the key question of how to generate an appropriate classical planning problem given the agents current state. In the context of probabilistic planning with
full observability, current planners use multiple samples of classical planning problems obtained by
transforming stochastic actions into deterministic actions by selecting a single effect for each action
instance (Yoon et al., 2007; Yoon, Fern, Givan, & Kambhampati, 2008; Kolobov, Mausam, & Weld,
2010).
In the context of PPOS a more sophisticated translation scheme was introduced in the CLG
planner (Albore et al., 2009). This translation is based on techniques introduced by Palacios and
Geffner (2009) for solving conformant planning by representing the agents belief state within the
classical planners state. This is achieved by extending the language with propositions of the form
Kp, and Kp, denoting the fact that the agent knows that p is true and false, respectively. These
ideas can be extended to PPOS, but result in non-deterministic planning problems because the effect
of a sensing action on an agents belief state cannot be known offline. CLG handles this problem
by further relaxing this problem in a number of ways, using a more complex translation. A key
aspect of this translation is that, if a is an action that has a precondition p, and the value of p can
be sensed, CLG will plan as-if p is true (and thus, a can be executed), provided that an action a
that senses p is executed before a. Thus, it makes optimistic assumptions regarding future outcomes
of sensing actions. This, however, does not imply that CLG will actually execute a, because if the
actual outcome of a differs from the expected one, CLG will replan using its new information.
The SDR planning algorithm we propose in this paper follows a similar high-level approach
based on replanning. At each state, we generate a classical planning problem that reflects information about the agents belief state. The specifics of our approach, are, however a bit different, and
our main aim is to provider better scalability, which requires generating smaller classical planning
problems. We achieve this by using state sampling. That is, instead of planning for all possible
initial states, we sample a small subset of states, and plan as if they are the only possible initial
states. We also use sampling to remove the optimistic bias of CLG: we sample an arbitrary initial
state sI , and assume that observation values are those obtained when sI is the true initial state. This
use of sampling leads to much smaller classical planing problems, and hence, to better scalability.
Because our planner operates under assumptions that are not alway true (i.e., it considers only
a subset of initial states and one possible set of observations), it is possible that the preconditions
of actions it selected, as well as the goal, do not hold in all possible worlds. Thus, the agent must
maintain some representation of its current set of possible states, also known as the belief state, in
order to verify these conditions. There are many methods for maintaining a belief state (Albore
et al., 2009; To, Pontelli, & Son, 2011; To, Son, & Pontelli, 2011a; To, Pontelli, & Son, 2009), all
of which work well for problems with certain structure, and not as well on other problem structures.
In general, belief state maintenance is difficult, but because our use of the belief state is limited,
we suggest a lazy belief state querying mechanism in the spirit of CFF (Hoffmann & Brafman,
2006) that does not require an explicit representation or update of the belief state following each
566

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

action. We maintain a symbolic representation of the initial belief state, only. To determine if
some literal holds in the current belief state, we regress the literal through the history of actions and
observations, and check the consistency of the regressed formula with the initial belief state. We
augment the regression process with a caching mechanism, which we call partially-specified states,
that allows us to keep the regressed formulas compact.
The resulting planner  SDR (Sample, Determinize, Replan)  compares favorably with CLG
(Albore et al., 2009), which is the current state-of-the-art contingent planner. On most existing
benchmarks it generates plans faster and can solve problems that CLG cannot solve, and its plans
have similar or slightly worse size.
Our paper contains a comprehensive experimental evaluation aimed at identifying the strengths
and especially the weaknesses of SDR and the replanning approach. To this end, we formulated a
number of new benchmark domains, including domains where sensing requires performing actions
that are off the path to the goal, and domains with dead-ends. In addition, we also evaluate the
effectiveness of our new regression-based method for maintaining information on the belief state
by comparing it to the closest lazy approach  that of CFF (Hoffmann & Brafman, 2006). Finally,
we describe some theoretical guarantees associated with SDR. First, we show that the translation
scheme we use is sound and complete whenever the sampled initial state is the true initial state.
Then, we show that, under certain assumptions on the connectivity of the domain, SDR with a
complete description of the initial belief state will reach the goal, if the goal is reachable.
The paper is organized as follows: In the next section we describe the problem of contingent
planning with partial observability and sensing. Then, we describe an idealized version of the
SDR planner that ignores efficiency problems that arise when the belief state is large  it uses the
entire belief state to generate the classical planning problem. We provide a theoretical analysis of
the correctness and convergence properties of this idealized algorithm. Next, we describe the full
SDR algorithm. This algorithm uses state sampling to manage the size of the belief state as well as a
regression mechanism for querying the belief state. This is followed by an overview and comparison
to related work, followed by an empirical evaluation analyzing the strengths and weakness of SDR.

2. Problem Definition
We focus on planning problems with partial observability and sensing actions (PPOS). We shall
assume that actions are deterministic throughout the paper.
Formally, PPOS problems can be described by a quadruple: P, A, I , G, where P is a set
of propositions, A is a set of actions, I is a propositional formula over P that describes the set of
possible initial states, and G  P is the set of goal propositions. In what follows we will often abuse
notation and treat sets of literals as a conjunction of the literals in the set, as well as an assignment
of values to propositions appearing in this set. For example, {p, q} is also treated as p  q and as
an assignment of true to p and false to q.
A state of the world, s, assigns a truth value to all elements of P , and is usually represented
using the closed-world assumption via the set of propositions assigned true in s. A belief-state is a
set of possible states, and the initial belief state, bI = {s : s |= I } defines the set of states that are
possible initially.
An action, a  A, is a three-tuple, {pre(a),effects(a),obs(a)}. The action preconditions, pre(a),
is a set of literals that must be valid before the action can be executed. The action effects, effects(a),
567

fiB RAFMAN & S HANI

is a set of pairs, (c, e), denoting conditional effects, where c is a set (conjunction) of literals and e
is a single literal.
Finally, obs(a) is a set of propositions, denoting those propositions whose value is observed
following the execution of a. We assume that a is consistent, that is, if (c, e)  effects(a) then
cpre(a) is consistent, and that if both (c, e), (c , e )  effects(a) and s |= c  c for some state s,
then e  e is consistent.
In current benchmark problems, either the set effects or the set obs are empty. That is, actions
either alter the state of the world but provide no information, or they are pure sensing actions that
do not alter the state of the world, but there is no reason for this to be the case in general.
We use a(s) to denote the state that is obtained when a is executed in state s. If s does not
satisfy all literals in pre(a) then a(s) is undefined. Otherwise, a(s) assigns to each proposition p
the same value as s, unless there exists a pair (c, e)  effects(a) such that s |= c and e assigns p a
different value than s. If a is a sequence of actions, we use a(s) to denote the resulting state, defined
analogously.
Observations affect the agents belief state. We assume that all observations are deterministic
and accurate, and reflect the state of the world prior to the execution of the action.1 Thus, if
p obs(a) then the agent will observe p if p holds now (i.e., prior to as effect), and otherwise
it will observe p. Thus, if s is the true state of the world, and b is the current belief state of the
agent, then ba,s , the belief state following the execution of a in state s is defined as:
ba,s = {a(s )|s  b, s and s agree on obs(a)}
That is, the progression through a of all states where the agent would receive, following the execution of a, the same observation as if it was at state s. Extending the definition to sequences of
actions, if a is a sequence of actions, then ba,s denotes the belief state reached from b when executing
a starting at state s  b.
Alternatively, we can define the belief progression without an explicit world state s using:
ba,o = {a(s )|s  b, and the observation of a when s is the world state is o}.
A contingent plan for a PPOS problem is an annotated tree  = (N, E). The nodes, N , are
labeled with actions, and the edges, E, are labeled with observations. A node labeled by an action
with no observations has a single child, and the edge leading to it is labeled by the null observation
true. Otherwise, each node has one child for each possible observation value, i.e., one child for
each possible assignment to the observed propositions. The edge leading to this child is labeled by
the corresponding observation. The plan is executed as follows: the action at the root is executed,
an observation (possibly null) is made, and the execution continues recursively from the child that
corresponds to the edge labeled with this observation. As we assume that actions and observations
are deterministic, there is a single possible execution path along this tree for each initial state. We
use  (s) to denote the state obtained when  is executed starting in state s.  is a solution plan (plan
for short) for PPOS P = P, A, I , G if  (s) |= G for every s |= I .
Complete contingent plans that consider all possible future observations, can be prohibitively
large for problems of practical interest. In this paper, thus, we are concerned with online planning
in PPOS. That is, at each stage, the planner selects only the next action to execute, executes it, and
reconsiders.
1. One can choose to have the observations reflect the state of the world following the execution of the action at the
price of a slightly more complicated notation below.

568

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

Figure 1: The 4  4 Wumpus Domain

Example 1. We illustrate these definitions using a 4  4 simplified Wumpus domain (Albore et al.,
2009), which will serve as our running example. In this domain, illustrated in Figure 1, an agent
navigates on a 4  4 grid from the bottom-left corner to the top-right corner (the goal) by moving
in any of the four directions. The squares around the top two squares of the diagonal of this grid
contain monsters called Wumpus  one for every pair of squares adjacent to the diagonal (e.g.,
theres either a Wumpus in square 3,4 or in 4,3). An agent can only move into a square if it is safe.
That is, if it contains no Wumpus, specified as a precondition to the move action. Thus, the agent
can never enter a square with a Wumpus and die, and there are no dead-ends in this domain.2 At the
initial state the agent does not know the location of the Wumpuses, nor can it directly observe their
location. However, a Wumpus emits a stench that drifts to all the adjacent squares. Hence, when the
agent is at an adjacent square to a Wumpus it can smell the stench, although it cannot determine on
which adjacent square the Wumpus is hiding. Thus, measurements in a few different locations may
be required to determine the precise position of a Wumpus. This domain demonstrates a complex
hidden state with multiple sensing actions, but with no conditional effects.
We formalize this problem as follows:
 The set of propositions is at-x-y for 1  x, y  4, wumpus-at-2-3, wumpus-at-3-2, wumpusat-3-4, wumpus-at-4-3 and stench-at-x-y for 1  x, y  4.
 The actions are move-from-x1 -y1 -to-x2 -y2 for all adjacent x1 , y1 , x2 , y2  pairs, and smell.
 The initial state is: at-1-1  at-1-2     at-4-4  (oneof wumpus-at-2-3 wumpus-at-3-2)
 (oneof wumpus-at-4-3 wumpus-at-3-4).
2. Later on, we introduce a more natural formalization of this domain that does not require a square to be safe to move
into it, and thus, contains dead-ends.

569

fiB RAFMAN & S HANI

 The goal is at-4-4.
 The initial belief state consists of four possible world-states, corresponding to the four possible truth assignments to (wumpus-at-2-3  wumpus-at-3-2)  (wumpus-at-4-3  wumpus-at3-4) in addition to the known literals, such as at-1-1 and the adjacency propositions.

3. The Idealized SDR Planner
We now describe an idealized version of the Sample Determinize Replan (SDR) planner. It samples
a single distinguished state s from the current belief, and creates a deterministic classical problem,
where observations correspond to those derived from initial state s . After solving the classical problem using any classical planner, it applies the resulting plan until some sensing action is performed.
Then, the belief state is updated, removing all states that do not agree on the observed value, and
the process is repeated. In this idealized version of SDR a complete and explicit description of the
agents belief state is maintained and used to generate the classical planning problem. The actual
algorithm modifies this version by using a sampled belief state and lazy belief-state maintenance; it
is described in Section 5.
3.1 Replanning using Complete Translations
The central component of SDR is a translation from PPOS to a classical planning problem. It is
well known that planning under uncertainty can be reduced to planning in belief space, i.e., where
we move between sets of possible states of the world, modeling our current knowledge. When
there are no sensing actions, as in conformant planning, this results in a classical, deterministic
planning problem in belief space. When sensing actions exist, however, the resulting problem is
non-deterministic, because the effect of sensing actions on the agents state of knowledge depends
on the values observed online, which depend on the true state of the world, hidden from the agent.
Since we want to generate a deterministic classical planning problem that can be solved by
an off-the-shelf classical planner, we need to determinize the non-deterministic problem described
above, simplifying it in the process. We do this by selecting one possible initial state s and assuming
that observation values correspond to those obtained when s is the true initial state. Note that this
does not imply that the planner plans as if s was the actual initial state of the world (which would
yield a very simple classical planning problem over a standard state space) because the planner
actually reasons about its belief state online when s is the true initial state, and attempts to reach a
belief state in which the goal is known, i.e., where all possible states are goal states.
In most cases, the assumption that s is the true initial state turns out to be incorrect. The
planner learns this online when it executes a sensing action and discovers that its outcome was
different from what is expected if s was the true initial world state. At this point, we have learned
that s (and possibly some other initial states) cannot possibly be the true initial world state. Thus,
our uncertainty is reduced, and we replan using the new belief state and a new initial state sampled
from it.
The algorithm terminates when we cannot find a solution to the classical problem generated,
which implies that the goal cannot be achieved from the set of states indistinguishable from the
selected state s , or, when our belief state indicates that the goal, G is known, i.e., for every state
s  b, s |= G.
The high-level SDR algorithm with a complete initial belief state is described in Algorithm 1.
570

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

Algorithm 1 SDR (Complete Translation)
Input: PPOS Problem: P = P, A, I , G, Integer: size
1: b0 := the initial belief state bI = {s : s |= I }
2: i := 0
3: while G does not hold in all states in bi do
4:
Select a state s  bi
5:
Generate a deterministic planning problem C given P, bi , s
6:
Find a solution plan  for C
7:
if no solution exists then
8:
return failure
9:
end if
10:
while  =  do
11:
a :=first()
12:
Execute a, observe o
13:
bi+1  bia,o  update the belief given a, o
14:
ii+1
15:
Remove a from 
16:
if o is inconsistent with s then
17:
break
18:
end if
19:
end while
20: end while

3.2 Generating a Classical Planning Problem
Given the input PPOS P = P, A, I , G, the current belief state b, and the selected state s  b (hypothesized to be the current true system state), we generate a classical planning problem Pc (b, s ) =
Pc (b), Ac (b), Ic (b, s ), Gc . Notice that s influences the definition of the classical initial state only,
while b influences all elements except for the goal. Pc (b, s ) is defined as follows:
Propositions Pc (b) = P  {Kp, Kp|p  P }  {p/s|p  P, s  b}  {Ks|s  b} :
1. P  The set of propositions that appear in the original problem. Their value is initialized
according to the distinguished state s and are updated to reflect the current state of the
world given that s is the true initial state.
2. {Kp, Kp|p  P }  Propositions encoding knowledge obtained by the agent. Kp
holds if the agent knows p is true, i.e., if p holds in all possible states. This knowledge
can be obtained through a sensing action in which p was observed to be true or as a
necessary consequence of an action. The agent can know that p is true (denoted Kp),
know that p is false (Kp), or not know the value of p (denoted by both Kp and
Kp).
3. {p/s|p  P, s  b}  Propositions that capture the value of p given that s is the true
initial state. We can use them to rule out certain states. For example, if we observed p
to be true, we can rule out any state s as the true initial state if p/s holds.
571

fiB RAFMAN & S HANI

4. {Ks|s  b}  Propositions that capture which states have been ruled out. When
concluding that a certain state s was not the initial state of the system, we acquire Ks.
Below we shall use Kc as a shorthand notation for Kl1      Klm , where c = l1      lm ,
and Kc as a shorthand notation for Kl1      Klm . We also note that the number
of propositions generated in the idealized translation can be exponentially large, and this is
why the actual SDR planner, described in Section 5, uses various approximations.
Actions For every action a  A, Ac (b) contains an action ac defined as follows:
pre(ac ) = pre(a) {Kp|p  pre(a)}. That is, the precondition of the action must hold and the
agent must know this to be true prior to applying the action.
For every (c, e)  effects(a), effects(ac ) contains the following conditional effects:
1. (c, e)  the original effect. These conditions update the state that is assumed to be the
true state of the world.
2. {(c/s, e/s)|s  b}  the above, conditioned on the states consistent with b. These
conditions update the values of propositions given the possible states in b.
3. (Kc, Ke)  if we know that the condition c holds prior to executing a, we know that its
effect holds following a. This condition allows us to gain knowledge.
4. (Kc, Ke)  if c is not known to be false prior to executing a, e will not be known
to be false afterwards.
5. {(p, Kp), (p, Kp)|p  obs(a)}  when observing the value of p, we gain knowledge
in the form of either Kp or Kp, depending on the value of p in the state that is assumed
to be the true world state.
6. {(p  p/s, Ks), (p  p/s, Ks)|p  obs(a), s  b}  rule out possible states in b
if they are inconsistent with the observation. This is sometimes known as the refutation
of states.
In addition, for each literal l (w.r.t. P ) we have a merge action that allows us to conclude absolute
knowledge from knowledge conditional on the states in b. That is, if all states agree on the
value of some proposition, then we know the value of that proposition. We exclude states that
were already refuted, i.e., found to be inconsistent with some observation.
 pre(merge(l)) = {l/sKs|s  b}  for each state s, either it agrees on l, or it was previously
refuted.
 effects(merge(l)) = {(true,Kl)}.




Initial State Ic (b, s ) = l:s |=l l
sb Ks:
sb,s|=l l/s
pP Kp  Kp
1. {l : s |= l}  The set of propositions P that appear in the original problem, initialized
to their value in the distinguished state s . Notice that this is the only element of the
translation affected by the choice of the hypothesized initial state.
2. {Kp  Kp : p  P }  Knowledge propositions Kp and Kp are initialized to
false, denoting no initial knowledge over the value of propositions.
572

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

3. {l/s : s  b, s |= l}  Propositions of the form p/s are initialized to the value of p in
the corresponding state s.
4. {Ks : s  b}  Propositions Ks are initialized to false, as we do not know any
initial state in b to be impossible before observing the value of some proposition.
Goal Gc = KG, that is, all goal literals are known to be true.
The above translation is similar to, and inspired by the KS0 translation introduced by Palacios
and Geffner (2009) for conformant planning. To adapt it to PPOS, we chose to determinize observation actions by sampling a distinguished initial state, s , whose value we track throughout the
plan, and use to select the outcome of observation actions. Albore et al. (2009) provide a different
translation that contains propositions that encode the fact that the value of some proposition was
sensed (denoted Ap). This does not imply that p is true, but that the agent knows the value of p.
Instead of requiring Kp to hold prior to executing an action with precondition p, they require Ap to
hold. This results in an optimistic choice of values for sensed propositions.
A natural extension of the idea of conditioning the value of propositions on the initial state, as
capture by the p/s propositions we use, it to condition their value on multiple initial states from
which p progresses identically. That is, suppose that s and s differ only on the value of some
proposition r, and that r does not appear in actions that affect the value of p. In that case, p/s
and p/s will always have the same value. Consequently, we can simply maintain a single proposition, p/{s, s }. This, indeed, is the approach taken by Palacios and Geffner (2009) and Albore
et al. (2009), and such sets of states are called tags. The larger the set of states denoted by a tag, the
fewer tags needed, and the smaller the representation. In fact, Palacios and Geffner show that most
conformant planning problems require a very small set of tags, linear in the number of proposition.
The use of tags is an important optimization, that can lead to an exponential reduction in the size
of the generated planning problem. We decided not to introduce tags here as this would further
complicate the description of translation, and because our primary technique for reducing problem
size is state sampling  discussed in Section 5. Nevertheless, SDR could be further optimized by
using tags instead of states.
Example 2. We now demonstrate the above translation using a small toy example of identifying and
treating a disease. There are n possible diseases, each of which can be uniquely identified using a
single test, and cured using a unique treatment. Before applying the treatment, we must identify the
disease, so as to avoid applying the wrong treatment, causing further damage. The PPOS is hence
defined as follows:
 We have one proposition per disease, diseasei for i  {1..n}, and a proposition for the result
of the test test-passed.
 We need n test actions testi , with no preconditions and conditional effect (diseasei ,testpassed), and n treatment actions treati with precondition diseasei and effect diseasei . We
also have one sensing action observe-test-result allowing us to sense the value of test-passed.
 The initial state is: (oneof disease1 , ..., diseasen ) test-passed. The initial belief state
consists of n possible world-states, corresponding to the n possible diseases.

 The goal is i[1,n] diseasei .
573

fiB RAFMAN & S HANI

We will denote the possible states using si where i  {0, 1..n}, such that in si the patient has
disease i and in state s0 the patient has no disease. Let us choose sk as our s , that is, we choose to
assume that the patient has the k th disease.
The set of propositions in the translation is:
 The original propositions diseasei and test-passed.
 Propositions representing unconditional knowledge:
 Kdiseasei , Kdiseasei for i  {1..n}.
 Ktest-passed, Ktest-passed.
 Propositions representing knowledge conditional upon the initial states:
 diseasei /sj , for i  {1..n}, j  {0..n}.
 test-passed/sj , for j  {0..n}.
 Ksj for j  {0..n}.
The set of actions is:
 Test: for each testi action we have:
 No preconditions.
 effects:





(diseasei , test-passed).
(diseasei , test-passed).
(diseasei /sj , test-passed/sj ), for j  {0..n}.
(diseasei /sj , test-passed/sj ), for j  {0..n}.

 Treat: for each treati action we have:
 precondition: diseasei
 effects: diseasei  Kdiseasei .
 Observing the test result:
 No preconditions:
 Effects:
 (test-passed, Ktest-passed)  positive observations.
 (test-passed  test-passed/sj ), Ksj , for j  {0..n}  refuting states that do not
agree with the positive observation.
 (test-passed, Ktest-passed)  negative observations.
 (test-passed  test-passed/sj , Ksj ), for j  {0..n}  refuting states that do not
agree with the negative observation.
 Merge: we need merges only for the diseasei proposition (see the implementation note below):
574

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

 preconditions:



j[0..n] diseasei /sj

 Ksj

 effects: Kdiseasei
 and actions for merging diseasei :

 preconditions: j[0..n] diseasei /sj  Ksj
 effects: Kdiseasei
The initial state is a conjunction of the following conjuncts (we omit negations for simplicity of
presentation):
 The distinguished initial state: diseasek
 Uncertainty about the current state: Ksj , for j  {0..n}.
 Conditional knowledge:diseasei /si , diseasei /sj , for i  {1..n}, j  [0..n], i = j.

Finally, the goal is i[1..n] Kdiseasei .
3.3 Notes on Efficient Implementation
While the above translation is correct, some of the propositions can be removed. In many problems,
some of the original propositions are always known. For example, in the Wumpus example, the
location of the agent is always known, and it is identical in all possible current states. If the value
of p is always known, we can remove the propositions Kp, Kp, p/s, and use proposition p only.
These propositions do not require merge actions, either.
The refutation effect of actions (item 6 in the list of action effects above) can be moved out to an
independent action, similar to the merge actions. We create for each proposition p that is observable
by some action a (i.e., p  obs(a) for some a  A) and each state s two refutation actions, with
preconditions p  p/s or p  p/s, and an identical effect Ks. This reduces the number of
conditions in each action which poses a difficulty for current classical planners.

4. Theoretical Guarantees
We now prove two important properties of our algorithm when applied to a deterministic PPOS P.
Our first result is a proof of the correctness of the translation. We show that a plan exists for the
original problem iff a plan exists for the classical problems we generate, assuming we guessed the
correct initial state. We then show that, under standard assumptions, our algorithm will eventually
reach the goal. We note that an understanding of these results is not required for the following
sections.
We begin this section with some definitions of notations that will be used in the theorems below:
 Classical planning notations: if b is a belief state and s  b is a (world) state then recall that
Ic (b, s) denotes the initial state of the classical planning problem SDRs translation would
generate when s is selected as distinguished initial state. If  is a plan for P and b is the initial
belief state then c is the corresponding plan for the classical planning problem Pc (b, s),
where each action a in  is replaced by the corresponding action in the generated classical
problem. In addition, prior to the first action of c , and following all the translated actions,
575

fiB RAFMAN & S HANI

all merge actions are inserted. We will assume a modified version of the merge actions that
has no preconditions and instead, its current precondition replaces the condition part of the
conditional effect which was previously empty (i.e., = true). This allows us to insert arbitrary
merge actions without risking making the plan undefined. Adding all merges, the plan c is
forced to make all possible inferences following every action.
 Sensing and non-sensing actions: without loss of generality, we will assume that each action
either makes an observation or changes the state of the world, but not both. Actions that do
both can be modeled as a consecutive pair of actions; first, one that changes the world, and
then one that makes observations.
 Indistinguishable states: we say that s, s are indistinguishable by  if  is applicable to s
iff it is applicable to s , and the observations generated when executing  from s and s are
identical. Note that s, s may be indistinguishable by  but distinguishable by some other
plan   .
 Applicability of actions and plans: we say that an action a is applicable in state s if s
satisfies all the preconditions of a. We say that an action a is applicable in a belief state b
if each s  b satisfies all the preconditions of a. Applicability is generalized to plans in the
natural manner. That is, given a plan  = a1 , ..., an  and a state s, the plan is applicable for
s if a1 is applicable to s and   = a2 , ..., an  is applicable to a1 (s).
We begin by showing that if c achieves Kl for some literal l, then the belief resulting from
executing the plan  in belief space will satisfy l.
Theorem 1. Let b be a belief state and s  b the true initial state. Let  be a sequence of actions in
the original problem. Then for every literal l, b,s |= l iff c (Ic (b, s)) |= Kl.
Proof. We prove by induction on || that the following conditions hold:
1.  is applicable in b and s iff c is applicable on Ic (b, s)
2. For every s  b that is indistinguishable from s by  and every literal l: (s ) |= l iff
c (Ic (b, s)) |= l/s
3. For every s  b, s is distinguishable from s by  iff c (Ic (b, s)) |= Ks
4. For every literal l: b,s |= l iff c (Ic (b, s)) |= Kl
Base case. In the base case  =  and c includes all merge actions. Conditions 1, 2, and 3 are
immediate by construction. That is, the empty plan is always applicable (because it contains no
actions), and there are no distinguishable states. Condition 4 is a consequence of the definition of
the merge action.
Inductive step. For the inductive step, we assume that conditions 1-4 hold for   and consider a
sequence  =    a. We consider two cases:
 a is not a sensing action: For condition 1, observe that given the induction hypothesis,
we need only show that a is applicable following   iff ac is applicable following c . (If
some prefix is inapplicable in one case, we know by the induction hypothesis that it is also
576

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

inapplicable in the other). Suppose that a is applicable, i.e., b ,s |= p for every precondition
p of a. From condition 4 we conclude that c (Ic (b, s)) |= Kp which is the corresponding
precondition of ac . The additional merge actions have no preconditions. The other direction
is similar.
For conditions 2 and 3 notice that indistinguishable states become distinguishable only by observing some literal that holds in one but not in the other. Thus, a non-sensing action a cannot
cause two states that were indistinguishable given   to become distinguishable following .
Hence, Condition 3 follows immediately from the induction hypothesis and the fact that a
non-sensing action does not have any effect of the form Ks. For Condition 2: If l was not
affected by the last action in , then this follows from the induction hypothesis. Otherwise,
l is added by a under some condition c that holds in s . By construction, (c/s , l/s ) is a
conditional effect of ac . Given the induction hypothesis, c held prior to the execution of a
iff c/s held prior to the execution of ac and all the merge actions that follow c (Ic (b, s)) in
c (Ic (b, s)). Consequently, l/s holds if l holds.
Finally, for Condition 4, b,s |= l iff for every s that is indistinguishable from s given ,
(s ) |= l. From Condition 2 above, this happens iff c (Ic (b, s)) |= l/s for every such s .
Condition 3 guarantees that c (Ic (b, s)) |= Ks for every s that is distinguishable from
s. Thus, a suitable merge action, included by definition in c will conclude Kl. For the
other direction, if Kl holds, we know that this was either true before and not affected by any
action, or a consequence of a merge action. In the former case, we know using the induction
hypothesis that b ,s |= l. Since l was not influenced by a, we conclude that b,s |= l. In the
latter case of a merge action, we use Condition 2 and 3 to conclude that b,s |= l.
 a is a sensing action: For states s that remain indistinguishable from s, conditions 1,2 are
immediate: the only effect of a is to deduce Kl for some literal l. For Condition 1 note that
sensing actions are always applicable. For Condition 2 note that sensing actions do not affect
the state.
For Condition 3; if s is distinguishable from s given  then either it was distinguishable
before, in which case it is distinguishable following a, because Ks is never removed once
deduced (Ks is not an effect of any action in the translation). If s just became distinguishable after a is executed, then by construction ac has Ks as an effect. For the other
direction, if s is indistinguishable from s given , it must have been indistinguishable given
  . Hence, by the induction hypothesis, c (Ic (b, s)) |= Ks . Since s and s are indistinguishable now, the sensing action has the same effect for s and s , and so ac does not add
Ks , by construction.
For Condition 4, first suppose that b ,s |= l. From the induction hypothesis this happens iff
c (Ic (b, s)) |= Kl. However, b ,s |= l and c (Ic (b, s)) |= Kl are not affected by a, and thus
remain true under  as well. Therefore, we need consider only the case that b ,s |= l and
c (Ic (b, s)) |= Kl.
Suppose that b ,s |= l and b,s |= l. This implies that all state s  b such that (s ) |= l
are distinguishable from s by . Thus, we have that c (Ic (b, s)) |= Ks for all such s and
using the merge action, we conclude c (Ic (b, s)) |= Kl.
577

fiB RAFMAN & S HANI

Next, suppose b ,s |= l and b,s |= l. Thus, there exists some s  b that is indistinguishable
from s given  such that (s ) |= l. Since b ,s |= l and no merge action can be applied, we
conclude that b,s |= l.

This result provides a local soundness and completeness proof (i.e., per replanning phase). Applying the theorem to the goal G we get the following corollary:
Corollary 1. Let b be a belief state, s a state in it, and G the goal. SDR (with a sound and complete
underlying classical planner) will find a (standard, sequential) plan that when executed from s with
initial belief state b will reach a belief state satisfying G, iff one exists.
Proof. From Theorem 1 we have that b,s |= l iff c (Ic (b, s)) |= Kl for any literal l. Thus,
b,s |= G iff c (Ic (b, s)) |= KG. Thus, a plan exists for the original problem iff a plan exists for
the translated problem. (Recall that KG is a shorthand for Kg1      Kgm , where gi are literals
and G = g1      gm .)
We can also use the theorem to deduce that the belief state is reduced in every replanning
episode:
Corollary 2. Let  be a plan generated by SDR (with a sound and complete underlying classical
planner) for belief state b and initial state s  b. Let s be the real initial state. If we execute  from
b and we do not reach a belief state satisfying G, then s = s.
Proof. Given Theorem 1, we know that SDR will generate a correct plan for b and s. Thus, if
 does not reach the goal then s and s are not indistinguishable, and consequently, they must be
different.
What we show next is a more global version of correctness. We will show that under standard,
but admittedly strong assumptions, our algorithm will reach the goal within a finite number of steps.
As above, we assume that a complete representation of the belief state is maintained (as opposed to
using a sample, as we do later).
Dead-ends are a well known pitfall for replanning algorithms, but also for most online algorithms that do not generate a complete solution to the problem, which is unlikely to be feasible in
practice, and may require exponential space. Thus, to provide reasonable guarantees, our analysis
focuses on domains with no dead-ends. More formally, we say that a PPOS problem defines a connected state-space, or is connected3 , if a state satisfying G is reachable from every state s reachable
from I.
Another problem in the case of partial observability is the inability to recognize that the goal
has been reached. Consider the following simple example; there is a single proposition p, which is
unobservable and whose value is unknown in the initial state. We have a single action, flip, which
flips its value. The goal is p, and evidently it can be reached from any state. Yet, we can never know
that p holds. That is, we can never reach a belief state in which all states satisfy p.
Thus, having no deadends is not enough, and we must also require no belief dead-ends, i.e.,
belief states from which a belief state satisfying the goal is not reachable. We say that a PPOS
3. The analogous term in the context of RL algorithms and MDPs is ergodic.

578

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

is belief-connected if given any belief state b reachable from the initial belief state, bI , and any
world-state s consistent with b (i.e., s  b), there exists a sequence of actions a that, when s is
the true starting state, leads from b to b , such that b |= G. In notation: ba,s |= G. Clearly,
belief-connectedness implies connectedness.
Theorem 2. Given a belief-connected PPOS problem, SDR with a sound and complete underlying
classical planner and a set of tags that corresponds to all possible initial states, will reach the goal
after a finite number of steps.
Proof. The proof is based on ideas from the PAC-RL algorithms E 3 (Kearns & Singh, 2002) and
Rmax (Brafman & Tennenholtz, 2003) and follows immediately from Corrolary 2. Consider a plan
 generated under the assumption that s is the true initial state. This plan will be successful from
every initial state s that is indistinguishable from s given . If the plan fails, we will recognize this
fact because we maintain a sound and complete description of the current belief state. We will also
conclude that neither s nor any other initial state indistinguishable from s given  is possible, and
hence, our belief state will be reduced by at least one state. Because of belief-connectedness, we
can still reach the goal. We can continue this process at most a number of times that is equal to the
size of the initial belief state, at which point our belief state is a singleton, and we are left with a
classical planning problem, that our underlying classical planner will solve.
The above proof makes it apparent that in many cases, only a polynomial number of replanning
phases is required, because the number of initial states ruled out could be very large, e.g., if in each
iteration we learn the initial value of a single proposition. Bonet and Geffner (2011) identify one
such case, which, consequently, requires only a linear number of replanning phases to succeed.

5. SDR with Belief State Sampling and Belief Tracking
The size of the classical problem generated by the translation method suggested in Section 3.2
depends on the cardinality of the belief state, i.e., the number of possible initial states: We generate
one proposition for each original proposition and possible initial state, and for each conditional
effect of every action we generate a conditional effect for each possible initial state. This can lead to
an exponential (in the size of P) larger classical planning problem. Thus, the generated problems
size may become too large for current classical solvers to handle. In addition, the belief state itself
can be exponentially large, and an explicit representation of it is impractical. We address these
issues by using only a sampled subset of the current belief state to generate the classical planning
problem, and by using an implicit description of the belief state.
5.1 Sampling the Belief State
To address the problem of a large belief state we suggest using a sampled subset of the belief state
to generate the classical planning problem. Conceptually and technically, the change required to
the method described in Section 3.2 is minor: select a subset S  of b and generate the classical
planning problem as if S  is the true belief state. This also implies that the distinguished initial
state s is chosen from S  . Thus given a PPOS P = P, A, I , G, the sampled set of state S  such
that S  |= I , and the distinguished initial state s  S, we simply generate the classical planning
problem Pc (S  , s ).
579

fiB RAFMAN & S HANI

While the sampling translation method is similar to the complete translation, there is an important semantic difference. While in the complete translation Kp denoted knowing that p is true in all
possible states, in the sampling translation Kp denotes knowing that p is true only in all sampled
states. Thus, upon execution, when the agent intends to execute an action, there might be some preconditions whose value is not known to be true in all possible states. We call such actions unsafe.
We must ensure that unsafe actions are never executed.
The new translation that uses S  instead of b cannot guarantee that no action in the resulting
plan is unsafe. For this reason, we must maintain a representation of the true belief state throughout
execution. We use this information to check whether some possible state exists for which some
precondition of the next action does not hold. We call such state a witness state. If a witness state is
found, we must sample again and replan. To ensure that we do not generate another plan that is not
executable from the witness state, we add it to the set of sampled states, S  . The new plan will either
learn to distinguish between the witness state and the rest of the states in S  , or choose a different
path that is valid in both S  and the witness state.
Example 3. Returning to our Wumpus example, we show how this sampled translation reduces the
size of the translation. In the example, there are four possible initial states, which we will denote
by sll , slr , srl , srr , where sll denotes the initial state in which both Wumpus are to the left of the
diagonal, etc. We will select sll , slr as our sampled belief state S  , and sll as our distinguished initial
state s .
The set of propositions is:
 The original propositions:
 at-x-y for 1  x, y  4  as we explained above, the proposition at is always known
and does not require conditional or knowledge propositions.
 wumpus-at-2-3, wumpus-at-3-2, wumpus-at-3-4, wumpus-at-4-3
 stench-at-x-y for 1  x, y  4.
 Propositions representing unconditional knowledge:
 Kwumpus-at-2-3, Kwumpus-at-3-2, Kwumpus-at-3-4, Kwumpus-at-4-3.
 Kwumpus-at-2-3, Kwumpus-at-3-2, Kwumpus-at-3-4, Kwumpus-at-4-3.
 Kstench-at-x-y for 1  x, y  4.
 Kstench-at-x-y for 1  x, y  4.
 Propositions representing conditional knowledge:
 sll conditional propositions:
 wumpus-at-2-3/sll , wumpus-at-3-2/sll , wumpus-at-3-4/sll , wumpus-at-4-3/sll .
 stench-x-y/sll for 1  x, y  4.
 slr conditional propositions:
 wumpus-at-2-3/slr , wumpus-at-3-2/slr , wumpus-at-3-4/slr , wumpus-at-4-3/slr .
 stench-at-x-y/slr for 1  x, y  4.
 Ksll , Kslr  propositions for denoting refuted states.
580

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

The set of actions is:
 Move: for each move-from-x1 -y1 -to-x2 -y2 actions we have:
 preconditions: at-x1 -y1  wumpus-at-x2 -y2  Kwumpus-at-x2 -y2 )
 effects 4 :
 at-x1 -y1
 at-x2 -y2
 Smell: for each smell-stench-at-x-y action we have:
 preconditions: at-x-y
 effects:







stench-at-x-y , Kstench-at-x-y
stench-at-x-y  stench-at-x-y/sll , Ksll
stench-at-x-y  stench-at-x-y/slr , Kslr
stench-at-x-y , Kstench-at-x-y
stench-at-x-y  stench-at-x-y/sll , Ksll
stench-at-x-y  stench-at-x-y/slr , Kslr

 Merge: we illustrate merges using the stench-at-x-y proposition:
 preconditions:(stench-at-x-y/sll  Ksll )  ( stench-at-x-y/slr  Kslr )
 effects: Kstench-at-x-y
The initial state is a conjunction of the following conjuncts (we omit most negations for simplicity of presentation):
 The distinguished initial state:

 at-1-1 x=1..4,y=1..4,x=1y=1  at-x-y
 wumpus-at-2-3  wumpus-at-4-3  wumpus-at-3-2  wumpus-at-3-4
 stench-at-1-3  stench-at-2-2  stench-at-2-4  stench-at-3-3  stench-at-4-2  stenchat-4-4
 Uncertainty about the current state: Ksll  Kslr .
 Conditional knowledge:
 For the state sll
 wumpus-at-3-2/sll  wumpus-at-2-3/sll  wumpus-at-4-3/sll  wumpus-at-3-4/sll .
 stench-at-1-3/sll  stench-at-2-2/sll  stench-at-2-4/sll  stench-at-3-3/sll  stenchat-4-2/sll stench-at-4-4/sll  stench-at-x-y/sll in all other x  y locations.
 For the state slr
4. As in this domain there are no conditional effects, we list the effect e directly rather than writing (true, e).

581

fiB RAFMAN & S HANI

 wumpus-at-2-3/slr  wumpus-at-3-2/slr  wumpus-at-3-4/slr  wumpus-at-4-3/slr .
 stench-at-1-3/sll  stench-at-2-2/sll  stench-at-2-4/sll  stench-at-3-3/sll  stenchat-4-4/sll  stench-at-x-y/sll in all other x-y locations.
Finally, the goal is Kat-4-4.
5.2 A Note on Theory
The theoretical guarantees in Section 4 do not hold for the sampled translation. Specifically, as can
be expected, the translation is no longer sound: a plan that works for some states may not work for all
states. However, since we never apply an illegal action (because we maintain a complete description
of the belief state during plan execution), if we maintain the assumption of belief-connectedness,
then the goal always remains reachable. The question is whether we can ensure progress towards the
goal. Unfortunately, our planner may always come up with an unsound plan, even if we have beliefconnectedness, and so progress cannot be guaranteed without additional assumptions. For example,
if we assume that the sample size grows each time our plan is unsound, i.e., we accumulate the
witness states discussed above, then we can ensure progress is made, and that eventually the goal
will be reached, i.e., we are assured completeness.
5.3 Belief State Maintenance through Regression
As noted above, we must maintain information about the true belief state. Belief state maintenance
is a difficult task  various representations such as CNF, DNF, Prime Implicates, Prime Implicants,
and more (To et al., 2009; To, Son, & Pontelli, 2010, 2011b; To et al., 2011, 2011a), all work well
in some domains and poorly in other domains. That is, each representation method is suitable for
a family of domains with some special features, but does not work well on domains where these
features do not exist. However, we require our belief state only in order to answer two types of
queries: (1) Sampling a subset of the current possible states  executed before each replanning
episode for constructing the classical problem, and (2) Checking whether a literal l holds in all
currently possible states  executed prior to each action execution to ensure that it is not unsafe, and
in order to check whether the goal has been reached.
We propose a method for answering such queries without maintaining an explicit representation
of the belief space, by regressing queries through the execution history towards the initial belief
state. This approach requires that we maintain the initial belief state formula and the execution
history only, somewhat similarly to the situation calculus (McCarthy & Hayes, 1969; Reiter, 1991).
To answer a query about the current state, we regress this query through the entire history and
compare it to the initial state. To improve performance, we also cache limited information about
intermediate belief states.
The main benefit of this approach is that it is focused on the querys condition only, and therefore
yields small formulas for which it is easier to check satisfiability than, e.g., a formula describing the
complete history in conjunction with the initial belief (Hoffmann & Brafman, 2006). However, this
process must be repeated for every query.
5.3.1 Q UERYING FOR C URRENT S TATE P ROPERTIES
Throughout the online process we maintain the symbolic initial state formula and the history of
actions and observations made. We use this information to check, prior to applying any action a,
582

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

whether its preconditions hold in the current state, that is, whether the action is safe. We must also
check whether the goal conditions hold in the current state to determine whether the goal has been
achieved. To check whether a condition c holds, we regress c through the current history, obtaining
cI . A world state currently satisfies c iff it is the result of executing the current history in an initial
state satisfying cI . cI is inconsistent with I iff c holds in all states currently possible.
More specifically, when checking whether a literal l (or a set of literals) holds at the current
belief state, we regress its negation through the current history, resulting in a formula . Next, we
check, using a SAT solver, whether I   is satisfiable. If it is not satisfiable, we know that l is
valid.
Recall that c = regress(c, a) is the weakest condition on a state s such that executing a in s
yields a state satisfying c. We can compute regress(c, a) using the following recursive procedure:
 regress(l, a) = false if (true, l) is in effects(a).
 regress(l, a) = pre(a) if (true, l) is in effects(a). In our case pre(a) can be eliminated from
the regression, because the preconditions of a were already regressed and proven to be valid
prior to applying a. Thus, if (true, l) is in effects(a) then regress(l, a) = true.


 regress(l, a) = pre(a) (l (c,l)effects(a) c) (c,l) c. That is, either l existed prior to the
action executed, or it was added by one of the conditions that has l as its effect. It is also
impossible for any of the conditions removing l to apply. As above, pre(a) can be eliminated
from the regression.
 regress(c1  c2 , a) = regress(c1 , a)  regress(c2 , a)
 regress(c1  c2 , a) = regress(c1 , a)  regress(c2 , a)5
Applying regression to histories  sequences of actions, we extend the meaning of the regress operator:
 regress(c, ) = c
 regress(c, h  a) = regress(regress(c, a),h)
To maintain a correct description of the set of initial world states, we must also update the initial
belief-state formula whenever we make an observation. Thus, we regress every obtained observation
through h, obtaining a regressed formula , and we conjoin  to bI . Thus, the updated set of initial
state is now described by I = I  . To optimize, we apply unit propagation on I and maintain
it in semi-CNF form  a conjunction of disjunctions and xor (oneof ) statements. That is, convert
the newly added  to CNF form. In all the current benchmarks we find that maintaining the initial
belief formula as a CNF is easy.
5.3.2 S AMPLING THE B ELIEF S TATE
SDR samples the belief state to generate a subset of possible states when computing a translation
to a classical problem. Using the regression mechanism, we maintain only a formula I describing
the possible set of initial states given the initial constraints on possible states and the current history,
i.e., the actions that were executed and the observations that were sensed.
5. Recall that effects are deterministic and that the effect condition is a conjunction.

583

fiB RAFMAN & S HANI

To sample n states from the current belief state, we begin by finding n possible satisfying
assignments to the initial belief formula I . We do so by running our own simple SAT solver,
which picks propositions randomly from the set of unassigned propositions in the formula, sets a
value to them, and propagates that value through the formula. When the formula is unsolvable, we
backtrack. In all current benchmarks the structure of the initial belief formula is very simple, e.g., a
disjunctive set of oneof statements, or or clauses, and our simple SAT solver finds solutions very
rapidly.
The n satisfying assignments to I represent a set of initial states that are consistent with our
current information (i.e., the initial belief state and the observations made so far). To obtain a sample
of states from the current belief state, we progress them through the history.
5.3.3 O PTIMIZATION : PARTIALLY-S PECIFIED S TATES
For each step of execution of the current plan we maintain a list of literals known to hold at that
belief state. All propositions that do not appear among the literals in this list are currently unknown.
We call this construct a partially-specified belief state (PSBS), and it serves as a cache. When we
execute an action a, we propagate this set forward and update it as follows:
 If (c, l) is an effect of a, and c must be true before as execution, we add l and remove l.
 If l and l may both be true (that is, l is unknown in the PSBS), a deletes l if l holds (possibly
conditional on other conditions that necessarily hold), and a does not add l when l (and some
other conditions possible) holds, we can conclude that l must be true after the execution of a.
 While performing regression for some condition c, we may learn that some literal l is valid in
some intermediate PSBS. We update this PSBS and its successors, accordingly.
For instance, when observing a test-passed in Example 2, we add this to the last PSBS. Then,
after the regression of the action testi , we obtain diseasei , and add it to the previous PSBS, and
so forth. Following the regression, and the simplification techniques over I mentioned above, we
may learn that some literal l was true initially. We then progress l through the history to add more
information into PSBSs. In Example 1, for instance, when regressing a stench observation to the
initial state formula, we may learn that wumpus-at-3-4 holds, we then progress this through the
history and add the learned information to all PSBS.
The PSBS may reduce the formulas constructed through the regression. For example, suppose
our regressed formula at an intermediate belief state b has the form   l, where l is a literal that
belongs to the current PSBS, i.e., it is known to hold at b. Then, we need only regress  back from
b. Or, if we know that l holds in b, we can immediately conclude that the regressed formula will
be inconsistent with the initial belief state.
To conclude, our belief state representation uses the initial belief, represented as a symbolic
formula (initialized as given in the PPOS definition), and sets of literals that were shown to hold
for each time step. We update the initial belief by adding more formulas resulting from regressing
observations, thus adding more constraints on the set of possible states, and reducing the cardinality
of the initial belief state. Whenever we discover that a literal holds at any time step, either through
an action (unconditional) effect, or while regressing an observation, we cache this. The regression
mechanism uses these cached facts whenever possible to reduce the size of the regressed formula.
584

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

5.4 The Complete SDR Planner Algorithm
After explaining all the essential components of the SDR planner, i.e., sampling, translation, and
regression-based belief maintenance, we can now present the complete SDR algorithm (Algorithm 2).
Algorithm 2 SDR (Sampling Translation)
Input: PPOS Problem: P = P, A, I , G, Integer: size  the number of states in the sampled SI
1: h := , the empty history
2: while G is not known at the current belief state do
3:
Select a distinct set of states SI consistent with bI , by finding satisfying assignments to I
s.t. |S  | size
4:
Select the distinguished state sI  SI
5:
Propagate SI and sI through h, resulting in S  and s
6:
Generate the deterministic planning problem Pc (S  , s )
7:
Find a solution  for C
8:
if no solution exists then
9:
return failure
10:
end if
11:
while  =  do
12:
a :=first()
13:
Regress pre(a) through h obtaining pre(a),h
14:
if pre(a),h is inconsistent with bI then
15:
break
16:
end if
17:
Execute a, observe o
18:
Append a, o to h
19:
Regress o through h obtaining o,h
20:
Update the initial belief state formula I given o,h : I  I  o,h
21:
Remove a from 
22:
if o is inconsistent with s then
23:
break
24:
end if
25:
Update the current state: s  a(s )
26:
end while
27: end while
The algorithm begins by querying if the goal state has already been reached (line 2). This is
done by regressing the negation of the goal conditions through the current history, and checking
whether the negation is consistent with the initial belief state. If the latter is true, we know that there
is some state for which the goal conditions do not apply.
We then choose a sub-sample SI of bI (the initial belief state) and sI  SI (lines 3 and 4). We
propagate the states in SI through the history by applying the executed actions in h to all states in
SI (line 5). Lines 3-5 are thus equivalent to sampling S  and s from the current belief state.
Once we obtain S  and s , we use the translation in Section 3.2 (replacing b with S  ) to generate
the classical problem Pc (S  , s ), and solve it using any classical planner (lines 6 and 7). If there
585

fiB RAFMAN & S HANI

is no solution to this problem, then that means that the goal cannot be obtained if s is the current
state, and that thus there is no solution to the PPOS.
We now execute the obtained plan; We first check if the preconditions of the current action hold
in the current belief state. This is done by regressing the negation of the preconditions through the
history, and checking if the regressed formula is consistent with bI (line 13-16). If it is consistent,
i.e., if there is a state in bI for which the (regressed) negation of the preconditions hold, then we
must choose a new SI and replan.
Finding that the preconditions hold in the current belief state, we execute the current action, observing some observation o. We regress o through the history and update the initial belief state using
the regressed formula (lines 19 and 20). If o is inconsistent with s (that is, if o,h is inconsistent
with sI ) then we must sample again and replan (lines 22-24). Otherwise, even if o is inconsistent
with some other state sI  SI , sI = sI , we continue executing the plan.
When the execution of the plan terminates we check again to see if the goal has been met, and
if it was not obtained, we sample and replan again.
5.4.1 B IAS FOR O BSERVATION AND K NOWLEDGE .
It is possible to bias the SDR planner to make observations. A crude and simple method is to execute
any sensing action that can sense an unknown value without affecting the state. In the context of
current benchmarks this improves the planners run-time performance. We refer to this version of
SDR as SDR-Obs.
A more focused method is to augment the goal state with the requirement to prove that the
distinguished initial state is correct. We refer to this version as SDR with state-refutation (SDR-SR).
Recall that the distinguished state determines the value of all propositions in the initial state, but it
does not affect our knowledge. Thus, in the Wumpus domain, with sll as the distinguished state we
have that wumpus-at-2-3 holds, but Kwumpus-at-2-3 does not. If we change the goal to Kat-4-4
Kslr  Ksrl  Ksrr then the planner will generate a plan that has the knowledge effects as
well. That is, a valid plan must prove, e.g., that the initial state srr , where both Wumpuses are on
the right, is invalid. As state refutation can be achieved only by actions whose effects are s, and
such effects are obtained only following a differentiating observation, this method encourages the
planner to take sensing actions.
As the distinguished initial state is unlikely to be the true initial state, plans generated with
this modified goal are likely to more quickly identify this fact. This, in turn, will cause replanning
to trigger sooner, and with more information. Of course, we do not necessarily need to know the
identity of the initial state to succeed, and so this may also add sensing actions that may not be
required in an optimal plan.

6. Related Work
SDR borrows and extends ideas from various related planners, most notably: replanning/online
planning, translation-based techniques, and lazy belief state representation. We briefly discuss them
here.
Replanning has recently become popular for online planning under uncertainty by the FFReplan (Yoon et al., 2007) MDP solver. Replanning is a technique for planning under uncertainty
online, where at each stage, the planner solves a simplified problem that typically removes the uncertainty, e.g., by making assumptions about the value of unknown variables or the effects of actions.
586

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

The planner executes the obtained solution until it receives information that contradicts its assumptions, updates the model with the new information, and repeats the process. For example, FF-Replan
assumes certain deterministic effects for stochastic actions, obtaining a classical planning problem.
Because replanning essentially ignores certain aspects of the model, it runs the risk of getting stuck
at dead-ends, or regions of the state space from which it is difficult to reach the goal. However, combined with smart sampling techniques recently developed for stochastic planning problems, such as
UCT (Kocsis & Szepesvari, 2006) , replanning becomes a powerful technique. For example, FFReplan was later improved using the idea of hindsight optimization (Yoon et al., 2008; Yoon, Ruml,
Benton, & Do, 2010), where multiple, non-stationary determinizations of the MDP are examined.
The choice of the next action is guided by the solution to the multiple resulting classical planning
problems, enabling the planner to account for different possible future dynamics.
As noted above, an essential element of replanning is the reduction of the current problem into
a simpler problem. SDR builds on the the translation-based approach to conformant planning introduced in Palacios and Geffner (2009) to generate a classical planning problem, specifically, their
KS0 translation. In conformant planning, the resulting classical planning problem is equivalent to
the original problem (has the same set of solutions), but may be much larger in size. Applied to
contingent planning, this translation methods generates a non-deterministic, fully observable, planning problem. To make the problem deterministic, SDR simplifies it by assuming that observations
conform to those of some specific initial state. To reduce its size, SDR samples a subset of the initial
states.
Palacios and Geffner (2009) suggest a different technique for controlling the problem size.
While SDR maintain the value of propositions conditioned on each initial state, their planner maintains the value of each proposition conditioned on sets of initial states, called tags. Ideally, the tags
for proposition p contain initial states that differ only on the value of propositions whose initial
value does not affect the future value of p. Such sets can be quite large, implying that fewer tags are
required. This, in turn, leads to considerable savings in the size of the generated problem. When the
set of tags required for a complete translation is large, one may use tags that are not deterministic
in the following sense: a proposition may have different values in different states belonging to this
tag. While soundness can still be maintained in this case, one must sacrifice completeness.
The CLG planner (Albore et al., 2009) takes a different approach to extending the ideas of Palacios and Geffner to contingent planning. If P is the original contingent planning problem, denote by
X(P ) the fully-observable non-deterministic problem obtained by using the transformation of Palacios and Geffner. CLG solves X(P ) by obtaining heuristics from a relaxed version of the problem
that moves each precondition as a condition in all the effects of the action in a similar way as done
in CFF (Hoffmann & Brafman, 2006), drops non-deterministic effects, and introduces propositions
of the form Ap, which roughly say that p was observed. The effect of a sensing action that senses
p is thus Ap, rather than Kp (which would erroneously imply that offline we know what value will
be sensed). Actions that require p as a precondition, require Ap in the classical problem generated.
This forces the classical solver to insert a sensing action that senses p before it can insert an action
that requires p. Of course, the actual value sensed online may not correspond to the assumptions
made by the rest of the plan. This is why, following every sensing action, CLG (in its online version) replans. Thus, each plan is executed until the first sensing action. If the initial belief state is
correctly computed, the translation ensures that this fragment of the plan can be executed. Thus,
both CLG and SDR use replanning and a translation to classical planning in each replanning phase.
However, SDR uses a translation that is simpler in two ways. It does not use the Ap type proposi587

fiB RAFMAN & S HANI

tions, but instead uses sampling to determinize sensing actions. In addition, SDR uses sampling to
select only a subset of possible initial states. This leads to much smaller classical planning problems
that are faster to generate and solve, but are less informed. Consequently, often SDR takes more
steps to reach the goal, but is able to scale up better than CLG.
Recently, Bonet et. al. introduced a replanning-based contingent planner (Bonet & Geffner,
2011) called K-planner, which is very similar to SDR, but focuses on a special class of domains that
can be handled more efficiently. In these domains the hidden variables are static, i.e., the value of
all hidden propositions does not change throughout the execution of the plan. For example, in the
Wumpus domain, Wumpuses do not move, and the location of the Wumpuses along the diagonal is
static. In the Localize domain, however, the hidden current wall configuration changes with every
move action. Thus, K-planner is unsuitable for this domain. In addition, K-planner assumes that
the value of observable variables is always observed following any action  i.e., there are no explicit
sensing actions.
K-planner and SDR were developed in parallel, share many ideas, and provide similar theoretical guarantees. K-planner uses replanning and a translation into classical planning very much
like SDR (and CLG). Whereas SDRs translation assumes that sensed value will correspond to the
sampled initial state, K-planner has actions that correspond to making assumptions about the sensed
values. That is, real sensing actions are translated into multiple classical actions that lead to knowledge of different values of the sensed variable. Thus, the classical planner may choose what value
it would like the sensor to sense. This essentially allows the planner to make optimistic assumptions while ensuring goal focused sensing. However, multiple sensing actions in the plan may have
assumed effects that cannot be realized by any initial state. This may affect the quality of the
classical plan generated, but does not lead to unsound behavior because, online, the plan is executed
only until the first sensing action, after which the belief state is updated and replanning takes place.
SDRs use of a select initial state ensures that the sensed values are consistent, but may be more
pessimistic because it cannot conceive of sensed value being different from those dictated by the
special initial state selected.
As noted above, K-planner makes certain assumptions about the nature of uncertainty in the
domain, and one important contribution it makes is showing how these properties can be leveraged
to provide a more efficient representation and stronger guarantees. Essentially, the static hidden
variable assumption made by K-planner can be viewed as saying that the uncertainty in the domain
is essentially about the value of a multi-value variable, and conditional effects do not depend on the
value of this variable. In that case, one can represent the belief state more compactly and one can
generate very compact translations to classical planning. Bonet and Geffner prove the soundness
and completeness of K-planner under similar assumptions to those made here, but they also show
that under their additional assumption about the nature of uncertainty in the domain discussed above,
they achieve these properties while generating classical planning problems that are linear in the size
of the original planning problem.
Like most planners that operate under uncertainty, SDR maintains some form of a belief state.
SDR has taken the lazy approach to belief state maintenance to an extreme. The lazy, or implicit
approach to belief state maintenance was introduced in CFF (Hoffmann & Brafman, 2006). CFF
maintains a single complete formula that describes both the history and the initial state jointly. This
requires using a different copy of the state variables for each time point. An action applied at step
t is conjoined with this formula as clauses that describe the value of variables in time t + 1 as a
function of their value in time t. To determine whether condition c holds at the current belief state,
588

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

the current formula is conjoined with c. If the resulting formula is consistent, we know that there
are possible states in which c holds. Otherwise, we know that c is valid. For example, if c is
the goal condition, we know that a plan was found. If c is the precondition to some action a, we
know that a can be applied safely. CFF also caches such information discovered by simplifying
the formula whenever such a conclusion is obtained, via unit propagation. The regression method
that we use can be thought of as constructing, for each query, only the part of the CFF formula
that is needed for answering the current query. The downside of this approach is that we could, in
principle, reconstruct the same formula, or parts of a formula repeatedly. The advantage is that the
formulas that we construct are much smaller and easier to satisfy than the complete CFF formula.
Many other belief state representations were explored in literature, including binary decision
diagrams (Bryce, Kambhampati, & Smith, 2006), DNF and CNF representations, and Prime Implicates and Prime Implicants (To et al., 2011b, 2011, 2011a, 2009, 2010). Overall, To (2011)
concludes that different domains require different representations. That is, each belief representation method works well on domains with a certain structure of actions, and not as well on other
domains. It would be interesting to compare the various belief representation methods to our lazy
regression based technique on a large set of benchmarks, and we leave this to future research.
To et al. also suggest a number of contingent planners, built using the above belief representations and an AND/OR forward search algorithm, that generate complete plan trees for contingent
problems. Other planners such as CFF, POND (Bryce et al., 2006), and CLG in offline mode also
compute such complete plan trees. In general, these plan trees are exponential, and must produce
different plans for each possible initial state in the worst case. Thus, offline contingent planning is
inherently difficult to scale up to larger domains with many possible initial states.

7. Experimental Results
To demonstrate the power of our replanning approach we compared SDR to the state of the art
contingent planner CLG (Albore et al., 2009). We use CLG in its so-called execution mode, where
it becomes an online planner. We compare SDR to CLG on domains from the CLG paper:
 Wumpus: in this grid-based navigation problem, the agent must move from the lowest left
corner to the upper right corner. The diagonal of the grid is surrounded by squares containing
either monsters called Wumpuses, or pits. The agent must ensure that a square is safe, i.e. no
monster or pit, before entering it. Squares cannot be directly checked for safety. Instead, in
squares surrounding a Wumpus the agent can smell its stench, and in squares surrounding a
pit the agent can feel the breeze. The agent does not know, though, given a breeze or a stench
which of the neighboring squares is unsafe. To ensure safety the agent must use information
collected from various squares around the suspected squares. This domain demonstrates a
complex hidden state with multiple sensing actions, but no conditional effects, which are
the key bottleneck for the CLG translation. Thus, in this domain the unknown features of
the environment are fixed, and the uncertainty does not propagate to other propositions , i.e.
known features do not become unknown. This is the type of domains that K-planner can
handle.
 Doors: this is again a grid-based navigation task, where the agent must move from the left
of the grid to the right. Along the way there are walls with a passage (unlocked door) only
in a single location. To sense whether a door is unlocked the agent must try it. The naive
589

fiB RAFMAN & S HANI

strategy is hence to move along the wall and try all doors until the unlocked one is found.
Then, the agent has to start over with the new wall. This domain exhibits simple strategies
and no conditional effects. Like the Wumpus domain, the uncertainty is not propagated here.
 Color-balls: in this domain several colored balls are hidden in a grid, and the agent must find
the balls and transfer them to a bin of the appropriate color. This domain has a very large state
space, and multiple sensing actions, but no conditional effects. Here, again, the propositions
whose values are known cannot become unknown.
 Unix: in this domain the agent must find a file in a folder tree and transfer it to the root.
There is no smart technique for searching the tree and the agent must exhaustively check
every subfolder. This domain does not contain any conditional effects. In this domain too the
uncertainty does not propagate.
 Localize: this is yet another grid-based navigation problem, where the agent must reach the
top right corner of a grid. However, the agent is unaware of its position within the grid. The
agent can sense nearby walls, and hence deduce its position within the grid. This domain
presents the most complex conditional effects of all domains, and is thus the most difficult
for scaling up using the CLG translation. In this domain, due to the conditional effects over
unknown features, the uncertainty can propagate, i.e. known features may change their value
depending on the value of variables whose value is unknown, causing them, in turn, to become
unknown. For example, we can sense a wall to the right, but then move and the knowledge of
observing a wall to the right is lost. This domain is unsuitable for the K-planner.
It is clear from the description above that the benchmark domains are somewhat limited. Specifically, most of the domains do not use conditional effects, which are challenging under partial
observability. Nor are there dead-ends. We come back to these issue in Section 7.5. Nevertheless,
to assess the performance of SDR in comparison to current state of the art, we evaluate it on these
domains, all of which allow for scaling up using larger grids, more balls and so forth.
We implemented our SDR algorithm using C#. The experiments were conducted on a Windows
Server 2008 machine with 24 2.66GHz cores (although each experiment uses only a single core)
and 32GB RAM. We used FF (Hoffmann & Nebel, 2001) compiled under a Cygwin environment
for solving the deterministic problems, and we used the Minisat SAT solver (Een & Sorensson,
2003) to search for satisfying assignments (or lack there of). As Minisat does not provide random
assignments, we also implemented a naive solver that generates random assignments for the true
environment states.
7.1 Comparing Plan Quality and Execution Time
We begin by comparing SDR variants to CLG on a number of benchmarks. We compute the average
number of actions and average time over several (25) iterations for each problem instance, where
in each iteration an initial state is uniformly sampled. Arguably, computing averages in the case of
contingent planning is perhaps an incorrect estimation, as averages assume a uniform sampling of
conditions (initial states in our case), which is not a part of a PPOS formalism. Indeed, defining a
reasonable comparison metric for online contingent planners is still an open question, but for lack
of a better measure, we report measured averages.
590

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

Name
clog
huge
elog
7
ebtcs
70
CB
9-1
CB
9-3
CB
9-5
CB
9-7
doors
5
doors
7
doors
9
doors
11
doors
13
doors
15
doors
17
localize
3
localize
5
localize
9
localize
11
localize
13
localize
15
localize
17

#Actions
82.42
( 0.64 )
22.08
( 0.05 )
33.96
( 0.8 )
244
( 6.16 )
841.44
( 7.23 )
1068.6
( 4.44 )
Failed
21.6
( 0.22 )
47.76
( 0.52 )
97.76
( 1.1 )
148.44
( 1.3 )
229.04
( 1.7 )
343.26
( 2.77 )
519.13
( 4.7 )
8
( 0.12 )
14.56
( 0.24 )
28.52
( 0.42 )
34.67
( 0.61 )
37.52
( 0.62 )
40.08
( 0.61 )
45
( 0.86 )

SDR
Time(secs)
321.28
( 9.32 )
1.81
( 0.02 )
17.4
( 0.38 )
214.1
( 7.65 )
912.73
( 18.7 )
1356
( 10.7 )

3.76
( 0.05 )
18
( 0.26 )
72.5
( 0.87 )
216.52
( 4.4 )
524.03
(7)
1086
( 20 )
1582
( 26 )
1.77
( 0.03 )
7.12
( 0.1 )
72.69
( 1.43 )
155.6
( 3.87 )
396.76
( 10.72 )
667.22
( 19.7 )
928.56
( 33.2 )

SDR-obs
#Actions Time(secs)
61.17
117.13
( 0.44 )
( 4.19 )
21.76
0.85
( 0.07 )
( 0.01 )
35.52
3.18
( 0.75 )
( 0.07 )
124.56
71.02
( 2.49 )
( 1.57 )
247.28
245.87
( 2.91 )
( 4.03 )
392.16
505.48
( 2.81 )
( 8.82 )
487.04
833.52
( 2.95 )
( 15.82 )
18.04
2.14
( 0.18 )
( 0.03 )
35.36
9.29
( 0.41 )
( 0.1 )
51.84
28
( 0.55 )
( 0.31 )
88.04
79.75
( 0.91 )
( 1.04 )
120.8
158.54
( 0.93 )
( 2.01 )
143.24
268.16
( 1.36 )
( 3.78 )
188
416.88
( 1.64 )
( 6.16 )
8.88
0.81
( 0.11 )
( 0.01 )
15.32
2.87
( 0.21 )
( 0.04 )
29.44
26.61
( 0.47 )
( 0.48 )
41.2
77.11
( 0.83 )
( 1.97 )
56.96
159.53
( 0.69 )
( 4.18 )
68.44
352.36
( 0.9 )
( 9.72 )
81.24
527.53
( 1.16 )
( 15.25 )

SDR-SR
#Actions Time(secs)
82
786.17
( 0.42 )
( 31.19 )
21.52
1.67
( 0.05 )
( 0.02 )
35
25.18
( 0.64 )
( 0.39 )
264.24
140.64
( 5.65 )
( 5.21 )
665.4
565
( 6.37 )
( 18.1 )
918.07
716
( 4.72 )
( 15.3 )
Failed
16.64
( 0.23 )
40.52
( 0.45 )
77.68
( 0.92 )
125.08
(1)
185.64
( 1.88 )
252.24
( 2.04 )
299.28
( 2.78 )
8.88
( 0.14 )
13.08
( 0.22 )
22.12
( 0.43 )
31.12
( 0.6 )
39.96
( 0.54 )
50.63
( 0.59 )
59.48
( 0.81 )

3.05
( 0.04 )
17.87
( 0.22 )
61.57
( 0.9 )
174.04
( 1.75 )
383.88
( 5.42 )
725.76
( 8.52 )
1089
( 17 )
1.95
( 0.02 )
8.24
( 0.16 )
81.44
( 1.12 )
199.35
( 3.84 )
387.75
( 7.01 )
721.53
( 13.33 )
1031
( 25 )

#Actions
51.76
( 0.33 )
20.12
( 0.05 )
36.52
( 0.86 )
94.36
( 1.83 )
252.76
( 2.66 )
PF

CLG
Time(secs)
8.25
( 0.08 )
1.4
( 0.08 )
73.96
( 0.14 )
129.3
( 0.26 )
819.52
( 0.47 )

TF
16.44
( 0.18 )
30.4
( 0.24 )
50.48
( 0.5 )
71.68
( 0.79 )
105.48
( 0.89 )
PF

2.4
( 0.1 )
20.44
( 0.02 )
38.52
( 0.06 )
126.59
( 0.1 )
330.73
( 0.21 )

PF
CSU
CSU
CSU
PF
PF
PF
PF

Table 1: Comparing CLG (execution mode) to the various SDR methods. For domains with conditional actions
(localize) CLG execution cannot be simulated. TF denotes that the CLG translation failed; CSU denotes that
CLG cannot run a simulation with a uniform distribution; PF denotes that the CLG planner failed, either due to
too many propositions or due to timeout.

Table 1 and Table 2 lists the results for the various SDR methods and CLG. We report results
for pure SDR, SDR with observation bias (denoted SDR-obs), and SDR with state refutation added
to the goal (denoted SDR-SR). For each method we report the average number of actions and the
591

fiB RAFMAN & S HANI

Name
unix
1
unix
2
unix
3
unix
4
wumpus
5
wumpus
10
wumpus
15
wumpus
20

SDR
#Actions Time(sec)
9.4
0.46
( 0.16 )
( 0.01 )
31.04
2.01
( 0.79 )
( 0.05 )
78.48
9.61
( 2.23 )
( 0.28 )
195.8
53.1
( 4.73 )
( 1.38 )
27.19
9.8
( 0.39 )
( 0.16 )
45.18
102.08
( 1.57 )
( 2.17 )
61.2
464.74
( 1.01 )
( 10.05 )
80.33
1296
( 1.47 )
( 21 )

SDR-obs
#Actions Time(sec)
12.2
0.48
( 0.16 )
( 0.01 )
26.44
1.41
( 0.72 )
( 0.03 )
56.32
5.47
( 1.72 )
( 0.18 )
151.72
35.22
( 4.12 )
( 0.94 )
34.72
6.51
( 0.3 )
( 0.07 )
70.64
65.89
( 1.13 )
( 1.13 )
120.14
324.32
( 2.4 )
( 7.14 )
173.21
773.01
( 3.4 )
( 20.78 )

SDR-SR
#Actions Time(sec)
9.32
5.28
( 0.18 )
( 0.95 )
29.28
2.33
( 0.7 )
( 0.05 )
100
21.19
( 2.12 )
( 1.04 )
202.24
78.81
( 6.02 )
( 2.38 )
26.48
9.37
( 0.24 )
( 0.1 )
39.72
54.21
( 0.49 )
( 0.72 )
72.32
368.53
( 1.04 )
( 12.48 )
112.33
952.52
( 3.12 )
( 17.62 )

CLG
#Actions Time(sec)
11.68
0.35
( 0.23 )
( 0.01 )
19.88
2.69
( 0.47 )
( 0.01 )
51.32
18.56
( 0.97 )
( 0.05 )
90.8
189.41
( 2.12 )
( 0.6 )
24.12
2.38
( 0.1 )
( 0.09 )
40.44
36.29
( 0.18 )
( 0.04 )
101.12
330.54
( 0.67 )
( 0.25 )
155.32
1432
( 0.95 )
( 0.47 )

Table 2: Comparing CLG (execution mode) to the various SDR methods. The results are averaged over 25
executions, and the standard error is reported in brackets.

Name
logistics
CB
doors
localize
unix
Wumpus
Overall
Largest

SDR
#Actions Time
1
0
0
0
0
0
0
0
1
0
2
0
4
0
2
0

SDR-obs
#Actions Time
0
2
3
4
3
7
0
7
0
3
0
2
6
25
4
10

SDR-SR
#Actions Time
0
0
0
0
1
0
6
0
1
0
1
0
9
0
2
0

CLG
#Actions Time
2
1
1
0
5
0


3
1
1
2
12
4
3
1

Table 3: Counting the number of times that each method performed the best in each category. The bottom row
shows results for the two largest problems in each category (except for the first category where only cloghuge
was considered  11 problems overall).

average time (seconds) until the goal is reached over 25 iterations (standard error reported in brackets). Different executions correspond in our case to different selections of initial states, because in
deterministic PPOS, the initial state governs the complete observation behavior. In SDR variants,
various executions also correspond to different possible samplings of states from the current belief
state.
In offline contingent planners that compute a complete plan tree, execution time (as opposed to
planning time) is negligible. In the case of online replanning algorithms, however, execution time
encapsulates various important aspects of performance, such as the belief update computation, and
the time required for replanning episodes. In real applications, such as controlling robots, this would
translate into the time required for the system before deciding on the next action. When this time
is considerable, it is possible that the robot would stop operating for a while in order to compute
its next action. Thus, execution time is an important factor in deciding which online replanning
approach is most appropriate.
592

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

Execution time for CLG includes translation time for the domain, CLG execution, and plan verification time in our environment, which adds only a few seconds to each execution. The translation
timeout was 20 minutes, and CLG execution was also stopped after 30 minutes. We allowed FF a
timeout of 2 minutes for each replanning episode, but that timeout was never reached. In most cases
FF solves the deterministic plan in a few seconds. In some domains CLGs simulator does not support uniform sampling of initial states (denoted CSU in Table 1). As in these domains SDR scales
up to larger instances than CLG, this problem is not crucial to the comparison. For each domain we
bolded the shortest plan and the fastest execution.
As we can see in Table 3, SDR and SDR-obs are typically faster than CLG, and the difference
grows as we scale to larger instances. SDR variants also scale up to larger problems where CLG
fails. In most benchmark domains, the observation bias in SDR-obs resulted in faster execution,
because it is typically beneficial for SDR variants to learn as much as they can concerning the
hidden state as early as possible, and replan accordingly.
In domains that all planners can solve, the efficiency (in terms of avg. steps to reach the goal) is
mixed. CLG clearly generates shorter plans on Unix and Doors, but in many other instances SDRobs is better, and on the larger Wumpus instances, SDR and SDR-SR are better. It is not surprising
that in general CLG produces shorter plans, because it considers all contingencies (the complete
belief state), but this is also the reason for its difficulty in scaling up to larger domains. When CLG
produces plans of lesser quality, we speculate that this is because of the heuristic search in belief
space embedded in CLG, not due to problems in the translation approach.
SDR also computes much smaller translated domain descriptions, ranging from 10KB to 200KB.
However, a direct comparison with CLG is impossible because SDR generates parameterized domains while CLG generates grounded translations, and we hence do not provide detailed results for
model sizes.
In conclusion, as expected, when one is interested in shorter plans, CLG seems to be a more
appropriate candidate, but when one wishes to scale up to larger domains, SDR variants are a better
choice.
7.2 K-Planner
K-Planner (Bonet & Geffner, 2011) is a state of the art planner that handles PPOS problems with
only static hidden variables and does not use explicit sensing actions, but assumes that all possible
observations are immediately available upon entering a state. In such domains the maintenance of
a belief state is especially simple, and a translation is relatively easy to generate. Thus, it is no
surprise that K-Planner performs much better than SDR and CLG on these domains.
Looking at Table 4 one can see that the differences are especially pronounced in the case of the
Wumpus domains, where SDR-OBS has a significant overhead in updating the belief. Furthermore,
K-Planner employs an optimistic heuristic, which is especially appropriate for the Wumpus domain.
K-Planner simply assumes that the top-right square is safe, and goes there immediately. When the
square is not safe, it traces back until it finds a passage to the top-left square, and goes there directly.
In other domains, the optimistic heuristic is not as successful.
To conclude, K-Planner is by far the best approach for domains with static hidden variables, but
it is difficult to see a direct extension of K-Planner that handles other types of PPOS problems.
593

fiB RAFMAN & S HANI

Name
CB-9-1
CB-9-3
CB-9-5
CB-9-7
doors5
doors7
doors9
doors11
doors13
doors15
doors17
unix1
unix2
unix3
unix4
Wumpus05
Wumpus10
Wumpus15
Wumpus20

SDR-obs
#Actions
Time(secs)
124.56 ( 2.49 ) 71.02 ( 1.57 )
247.28 ( 2.91 ) 245.87 ( 4.03 )
392.16 ( 2.81 ) 505.48 ( 8.82 )
487.04 ( 2.95 ) 833.52 ( 15.82 )
18.04 ( 0.18 )
2.14 ( 0.03 )
35.36 ( 0.41 )
9.29 ( 0.1 )
51.84 ( 0.55 )
28 ( 0.31 )
88.04 ( 0.91 )
79.75 ( 1.04 )
120.8 ( 0.93 )
158.54 ( 2.01 )
143.24 ( 1.36 ) 268.16 ( 3.78 )
188 ( 1.64 )
416.88 ( 6.16 )
12.2 ( 0.16 )
0.48 ( 0.01 )
26.44 ( 0.72 )
1.41 ( 0.03 )
56.32 ( 1.72 )
5.47 ( 0.18 )
151.72 ( 4.12 ) 35.22 ( 0.94 )
34.72 ( 0.3 )
6.51 ( 0.07 )
70.64 ( 1.13 )
65.89 ( 1.13 )
120.14 ( 2.4 )
324.32 ( 7.14 )
173.21 ( 3.4 )
773.01 ( 20.78 )

K-Planner
#Actions
Time(secs)
117.04 ( 10.99 ) 34.83 ( 3.9 )
219.6 ( 10.09 )
60.63 ( 3.05 )
358.08 ( 15.8 )
94.18 ( 3.31 )
458.36 ( 14.64 ) 116.63 ( 3.24 )
17 ( 1.05 )
4.57 ( 0.35 )
33.2 ( 1.67 )
9.01 ( 0.55 )
52.12 ( 2.61 )
15.04 ( 0.95 )
80.8 ( 3.04 )
25.82 ( 1.2 )
109.72 ( 4.76 )
37.96 ( 1.72 )
150.88 ( 4.7 )
55.24 ( 2 )
188.8 ( 5.79 )
79.24 ( 2.62 )
9.68 ( 0.85 )
3.71 ( 0.25
22.04 ( 2.27 )
8.13 ( 0.71 )
45.48 ( 4.59 )
16.87 ( 1.56 )
87.04 ( 8.54 )
38.81 ( 3.53 )
35.76 ( 1.53 )
2.45 ( 0.21 )
90.52 ( 6.4 )
5.39 ( 0.61 )
107.64 ( 4.6 )
7.17 ( 0.6 )
151.52 ( 6.29 )
16.03 ( 1 )

Table 4: Comparing SDR-OBS and K-Planner, on domains with static hidden variables.

7.3 Effects of |SI |
An important parameter of our algorithm is the size of SI  the number of initial states that the
deterministic planner recognizes. As this number grows, the plan must distinguish between the
various states and hence becomes more accurate. However, the more states we use the larger is the
translation to the deterministic problem, and the more difficult it is for FF to handle. To examine
the impact of this parameter we tested the performance of SDR as a function of the size of SI . As
we show in Figure 2, the plan quality (the number of actions to reach the goal) of SDR does not
change considerably with the number of states. The only domain where there is a significant benefit
from adding more states is Wumpus, and there one sees no farther significant improvement beyond
8 states. As expected, the running time grows with the growth in the number of states. We can
conclude, hence, that, at least in current domains, there is no need to use more than a handful of
states.
7.4 Belief Maintenance
We now examine the efficiency of our proposed lazy belief maintenance method. A natural candidate to compare against is the belief maintenance method of CFF (Hoffmann & Brafman, 2006,
2005) which introduced a lazy belief-state maintenance method motivated by the same considerations that guided us. CFF maintains a propositional formula over a sets of propositions that represent
the value of each original proposition at every time point, thus, p(t) represents the value of proposition p at time t. Initially, the formula contains the formula describing the initial belief state I
using propositions of the form p(0). CFF updates this formula following the execution of an action.
If a is executed at time t then certain constraints between propositions at time t and t + 1 must
be satisfied. These constraints capture the add and delete effects of a, as well as the frame axiom.
Given this formula, to check whether some literal l holds at all possible states at time t, CFF checks
594

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

Figure 2: Effect of |SI |  the number of initial states (tags) on the number of actions (solid) and the execution
time (dashed) for Wumpus10, doors 9, localize 9, unix 2.

whether l(t) is a consequence of the current formula. Such conclusions are cached by adding them
to the formula and simplifying it using unit propagation.
Although the update process used by CFF is quite simple, it still needs to maintain a potentially
large formula and perform satisfiability checks on it. SDRs method is even lazier and reconstructs
a formula for every query. This formula is focused on the literal in question, and can be much
smaller but is reconstructed for each query, although as noted above, some information is cached. It
is natural to ask which approach provides a better trade-off.
To compare the two methods we ran SDR once with the belief maintenance method of CFF and
once with our new method. As the rest of the algorithm remains the same, and the two experiments
were executed using the same random seeds, the differences in runtime stem only from the different
belief maintenance method. We experimented on all the domains, but report below only the domains
that the belief maintenance of CFF could solve.
As Table 5 shows, the belief maintenance method of CFF scales poorly compared to our lazy
formula construction method. The only domain where the differences are not as substantial is localize, and this is mainly because in this domain the planner quickly learns the value of propositions
that quickly decouple the formula into a set of formulas over disjoint sets of propositions.
To (2011) suggests a number of approaches to belief state maintenance and update. Unfortunately, while his planners are available online6 the belief update mechanism is deeply tied into the
planning mechanism, and we are currently unable to independently measure the performance of the
various belief update methods and compare them to our lazy regression approach, although such a
comparison is very interesting.
6. http://www.cs.nmsu.edu/sto/

595

fiB RAFMAN & S HANI

Domain
cloghuge
ebtcs-70
elog7
doors5
doors7
doors9
localize3
localize5
localize9
localize11
localize13
localize15
unix1
unix2
unix3
Wumpus05
Wumpus10

CFF
410.39 (4.94)
481.27 (15.89)
6.88 (0.94)
4.28 (0.06)
41.05 (1.02)
283.93 (6.86)
2.32 (0.04)
7.54 (0.18)
78.08 (1.69)
109 (1.53)
458.89 (10.06)
909.12 (32.91)
0.81 (0.01)
6.29 (0.19)
427.73 (13.22)
21.07 (0.27)
688.84 (29.46)

SDR
321.28 (9.32)
17.4 (0.38)
1.81 (0.02)
3.76 (0.05)
18 (0.26)
72.5 (0.87)
1.77 (0.03)
7.12 (0.1)
72.69 (1.43)
155.6 (3.87)
396.76 (10.72)
667.22 (19.7)
0.46 (0.01)
2.01 (0.05)
9.61 (0.28)
9.8 (0.16)
102.08 (2.17)

Table 5: Comparing the belief maintenance methods of CFF and SDR. We report the time (in seconds) of
solving the domains with each of the different methods. The reported models of each type are the largest that
the belief maintenance method of CFF could handle within the given timeout.

7.5 New Domains
We noted earlier that existing benchmark problems for contingent planning focus on problems with
limited features. First, there are no dead-ends, which, as noted by Little and Thiebaux (2007), are
problematic for replanning based methods. Second, the fact that we perform well with a sampled
initial belief state of size 2 seems to imply that the solution is not too sensitive to the identity of
the initial state. This is related to the fact that the type and amount of conditional effects we see in
current domains is quite limited. Finally, the success of the sensing bias suggests that we should
investigate domains in which sensing actions carry a cost, and where sensing is not necessarily
separate from action. Domains where sensing actions require substantial effort to attain their preconditions may also provide interesting insights. Many of the domains above, such as colorballs,
doors, and unix are also problematic because there isnt any smart exploration method that reduces
the belief space faster. In all these domains the agent must move to each location independently and
query for the object of interest (door, ball, or file). The agent cant, for example, sense whether the
door is above or below its current position, thus cutting the belief space in half.
We thus suggest here a number of new benchmark domains, which are either variations of
current domains, or adaptations of domains from the POMDP community. These new domains
are especially designed to expose the difficulties of current planners, and point towards needed
improvements. As such, SDR and CLG do not perform well on many of them, and sometimes fail
utterly.
We first explore variations of the interesting Wumpus problem. Wumpus requires a smart exploration and sensing policy, and is thus one of the more challenging benchmarks. The original
Wumpus definition requires that a cell will be safe before entering it. By removing this precondition, and changing the move action so that the agent is not alive if a wumpus or a pit exist in a cell,
we create a domain with deadends. We experimented with this domain and, as expected, SDR and
all its variations fail utterly to handle it. CLG, however, solves these domains without failing. It suc596

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

ceeds because it fully represents the belief state and hence detects that for some possible states the
agent would be dead, and would avoid such consequences. SDR, even with a complete belief representation, makes the strong assumption of a single initial state, and plans for that state specifically.
As in that state the agent will not be dead in the resulting plan, it will execute it without bothering
to sense for deadends. When the true world state is not the assumed state, it will eventually enter an
unsafe cell and would die.
Name
Wumpus 4
Wumpus 8
Wumpus 16

SDR

SDR-OBS

SDR-SR

Fail
Fail
Fail

Fail
Fail
Fail

Fail
Fail
Fail

CLG
#Actions
Time (secs)
17.7 (0.04)
0.17 (0.001)
40.5 (0.31)
2.8 (0.01)
119.7 (0.91) 182.5 (1.73)

Table 6: Wumpus domains with deadends

We then experimented with a Wumpus variation where if the agent enters an unsafe cell, it runs
back to the start cell (at 1,1). There is thus a cost for not sensing a wumpus. This cost introduces an
interesting tradeoff  when the agent is close to the start cell, it is better to just enter a cell without
verifying its safety. However, when the agent is far from the beginning, it is better to sense for
safety rather than pay the price for going back. Here, CLG fails utterly  the underlying revised FF
is unable to solve the translation within the given timeout. SDR and its variations solve this model,
but we can see that the sensing bias reduces performance in this case. Still, closely looking at the
plans that SDR executes, we observe that they are suboptimal  SDR does not weigh the costs of
sensing vs. entering a possibly unsafe square and causing a restart. Instead, it always enters the
possibly unsafe square and pays the restart price.
Name
Wumpus 4
Wumpus 8
Wumpus 16

#Actions
13.1
(1.13)
34.84
(0.67)
67.08
(1.1)

SDR
Time (secs)
3.2
(0.04)
50.3
(1.14)
178.9
(7.6)

SDR-OBS
#Actions Time (secs)
22.2
3.4
(0.1)
(0.03)
69.12
59.23
(0.7)
(0.74)
Fail

SDR-SR
#Actions Time (secs)
17
5.4
(0.14)
(0.1)
37.9
51.5
(0.7)
(1.15)
74.8
450.1
(1.14)
(14.2)

CLG
Fail
Fail
Fail

Table 7: Wumpus domains with restarts

Next, we introduce a domain from the POMDP community, known as RockSample (Smith &
Simmons, 2004), and motivated by the Mars rover task. An agent (the rover) has to sample minerals
from a set of nearby visible rocks. The agent knows where the rocks are, but in order to know
whether a rock should be sampled, it must activate its sensors. In our version of the problem, the
agent has a sensor that senses the presence of nearby minerals, set on an antenna. When the agent
extends the antenna higher, the sensor senses minerals that are farther of. When the antenna is
completely folded, the agent senses only minerals in its immediate vicinity. Solving this problem
smartly, without visiting rocks that do not contain minerals, requires a smart sensing strategy, involving raising and lowering the antenna in order to know which rocks contain minerals. While
SDR currently solves this problem, it does not do so smartly. For example, SDR with observation
bias (SDR-OBS) has no significant advantage because it does not get additional observations, as
getting long-range observations requires preparation actions.
597

fiB RAFMAN & S HANI

Name
RockSample 4
RockSample 8
RockSample 12
RockSample 14

#Actions
42.2
(0.4)
85.08
(0.65)
127.24
(0.68)
142.08
(0.8)

SDR
Time (secs)
37.2
(0.36)
109.3
109.3 (1.15)
113.4
(0.79)
146.75
(1.19)

SDR-OBS
#Actions Time (secs)
45.3
32.12
(0.41)
85.5
92
(0.62)
(0.93)
125.36
101.2
(0.81)
(0.75)
145.04
128.2
(0.63)
(0.8)

SDR-SR
#Actions Time (secs)
45.6
37.2
(0.39)
(0.38)
89.12
106.04
(0.63)
(1.12)
120.72
111.66
(0.64)
(0.79)
146.84
139.3
(0.86)
(1.14)

CLG
CSU
CSU
CSU
CSU

Table 8: RockSample domains with an 8  8 board and 4 through 14 rocks. CLG does not properly simulate
the underlying world state for observations given the conditional effects and thus its performance cannot be
evaluated, even though it manages to solve these domains (denoted CSU).

Finally, we also experiment with another domain that was explored in the POMDP community
 the well-known MasterMind game, where the agent must guess correctly the order and color of k
hidden pegs out of n possible colors. The agent guesses a configuration, and then receives feedback
in the form of the number of correctly guessed colors and the number of correctly guessed locations.
This problem is interesting because the agent never directly observes the crucial features of the state,
i.e., which peg is currently correctly guessed. Furthermore, there exists an optimal sensing strategy
that provably solves the game in five guesses or less for 4 pegs and 6 colors (MasterMind 6 4)
(Koyama & Lai, 1993). CLG cannot solve this problem because it has a problem-width of more
than 1. SDR and SDR-SR do poorly on this task because they use the simplest possible strategy 
guess a setting and see if the guess was correct, i.e., whether the result was n location hits, ruling
out only a single state with each guess. SDR with observation bias does better, because it observes
the number of location and color hits, thus ruling out many more states with each guess. It is
noteworthy that the underlying FF planner does particularly badly on the translations generated for
this task, executing many guesses without observing the results for no obvious reason.

Name
MasterMind 2 4
MasterMind 3 4
MasterMind 4 6

#Actions
25.6
(0.52)
63.5
(1.5)

SDR
Time (secs)
8.2
(0.16)
46.07
(1.09)
Fail

SDR-OBS
#Actions Time (secs)
14.48
2.68
(0.134)
(0.02)
26.76
9.44
(0.47)
(0.12)
52.72
74.18
(1.08)
(0.68)

SDR-SR
#Actions Time (secs)
28.48
8.2
(0.6)
(0.2)
66.8
52.9
(1.42)
(1.22)
Fail

CLG
TF
TF
TF
TF
TF
TF

Table 9: MasterMind color guessing game. MasterMind n k stands for MasterMind with n pegs and k colors.
CLG cannot translate this problem because it has a width above 1.

8. Conclusion
We described SDR, a new contingent planner that extends the replanning approach to domains
with partial observability and uncertainty about the initial state. SDR also introduces a novel, lazy
method for maintaining information and querying the current belief state, and has nice theoretical properties. Our empirical evaluation shows that SDR improves the state of the art on current
598

fiR EPLANNING WITH PARTIAL I NFORMATION AND S ENSING ACTIONS

benchmark domains, scaling up much better than CLG. However, the success of its current simple
sampling techniques also highlights the weakness of current benchmark problems. To highlight this,
we generated new problem domains that are challenging for current contingent planners, and can
serve to measure progress in this area.
Acknowledgments
The authors are grateful to Alexander Albore, Hector Geffner, Blai Bonet, and Son To for their help
in understanding and using their systems and to the anonymous referees for many useful suggestions
and corrections. Ronen Brafman is partially supported by ISF grant 1101/07, the Paul Ivanier Center for Robotics Research and Production Management, and the Lynn and William Frankel Center
for Computer Science.

References
Albore, A., Palacios, H., & Geffner, H. (2009). A translation-based approach to contingent planning.
In IJCAI, pp. 16231628.
Bonet, B., & Geffner, H. (2011). Planning under partial observability by classical replanning: Theory and experiments. In IJCAI, pp. 19361941.
Brafman, R. I., & Tennenholtz, M. (2003). Learning to coordinate efficiently: A model-based approach. Journal of Artificial Intelligence Research (JAIR), 19, 1123.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics for belief space
search. JOURNAL OF AI RESEARCH, 26, 3599.
Een, N., & Sorensson, N. (2003). An extensible sat-solver. In SAT, pp. 502518.
Hoffmann, J., & Brafman, R. I. (2005). Contingent planning via heuristic forward search with
implicit belief states. In ICAPS, pp. 7180.
Hoffmann, J., & Brafman, R. I. (2006). Conformant planning via heuristic forward search: A new
approach. Artif. Intell., 170(6-7), 507541.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. JAIR, 14, 253302.
Kearns, M. J., & Singh, S. P. (2002). Near-optimal reinforcement learning in polynomial time.
Machine Learning, 49(2-3), 209232.
Kocsis, L., & Szepesvari, C. (2006). Bandit based monte-carlo planning. In ECML, pp. 282293.
Kolobov, A., Mausam, & Weld, D. S. (2010). Classical planning in MDP heuristics: with a little
help from generalization. In ICAPS, pp. 97104.
Koyama, M., & Lai, T. (1993). Circumscription: A form of non-monotonic reasoning. Journal of
Recreational Mathematics, 25, 251256.
Little, I., & Thiebaux, S. (2007). Probabilistic planning vs. replanning. In ICAPS Workshop on IPC:
Past, Present and Future.
McCarthy, J., & Hayes, P. J. (1969). Some philosophical problems from the standpoint of artificial
intelligence. In Meltzer, B., & Michie, D. (Eds.), Machine Intelligence, Vol. 4, pp. 463502.
599

fiB RAFMAN & S HANI

Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning problems
with bounded width. JAIR, 35, 623675.
Reiter, R. (1991). The frame problem in the situation calculus: a simple solution (sometimes) and a
completeness result for goal regression. In Lifshitz, V. (Ed.), AI and Mathematical Theory of
Computation: papers in honour of John McCarthy, pp. 359380.
Smith, T., & Simmons, R. (2004). Heuristic search value iteration for POMDPs. In UAI 2004,
Banff, Alberta.
To, S. T. (2011). On the impact of belief state representation in planning under uncertainty. In
IJCAI, pp. 28562857.
To, S. T., Pontelli, E., & Son, T. C. (2009). A conformant planner with explicit disjunctive representation of belief states. In ICAPS.
To, S. T., Pontelli, E., & Son, T. C. (2011). On the effectiveness of cnf and dnf representations in
contingent planning. In IJCAI, pp. 20332038.
To, S. T., Son, T. C., & Pontelli, E. (2010). On the use of prime implicates in conformant planning.
In AAAI.
To, S. T., Son, T. C., & Pontelli, E. (2011a). Conjunctive representations in contingent planning:
Prime implicates versus minimal cnf formula. In AAAI.
To, S. T., Son, T. C., & Pontelli, E. (2011b). On the effectiveness of belief state representation in
contingent planning. In AAAI.
Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: A baseline for probabilistic planning. In
ICAPS.
Yoon, S. W., Fern, A., Givan, R., & Kambhampati, S. (2008). Probabilistic planning via determinization in hindsight. In AAAI, pp. 10101016.
Yoon, S. W., Ruml, W., Benton, J., & Do, M. B. (2010). Improving determinization in hindsight for
on-line probabilistic planning. In ICAPS, pp. 209217.
Zelinsky, A. (1992). A mobile robot exploration algorithm. IEEE Trans. on Robotics and Automation, 8(6).

600

fiJournal of Artificial Intelligence Research 45 (2012) 685-729

Submitted 08/12; published 12/12

The Time Complexity of A with Approximate Heuristics on
Multiple-Solution Search Spaces
Hang Dinh

htdinh@iusb.edu

Department of Computer & Information Sciences
Indiana University South Bend
1700 Mishawaka Ave. P.O. Box 7111
South Bend, IN 46634 USA

Hieu Dinh

hieu.dinh@mathworks.com

MathWorks
3 Apple Hill Drive
Natick, MA 01760-2098 USA

Laurent Michel
Alexander Russell

ldm@engr.uconn.edu
acr@cse.uconn.edu

Department of Computer Science & Engineering
University of Connecticut
371 Fairfield Way, Unit 2155
Storrs, CT 06269-2155 USA

Abstract


We study the behavior of the A search algorithm when coupled with a heuristic h satisfying
(1  1 )h  h  (1 + 2 )h , where 1 , 2  [0, 1) are small constants and h denotes the optimal
cost to a solution. We prove a rigorous, general upper bound on the time complexity of A search
on trees that depends on both the accuracy of the heuristic and the distribution of solutions. Our
upper bound is essentially tight in the worst case; in fact, we show nearly matching lower bounds
that are attained even by non-adversarially chosen solution sets induced by a simple stochastic
model. A consequence of our rigorous results is that the effective branching factor of the search
will be reduced as long as 1 + 2 < 1 and the number of near-optimal solutions in the search tree
is not too large. We go on to provide an upper bound for A search on graphs and in this context
establish a bound on running time determined by the spectrum of the graph.
We then experimentally explore to what extent our rigorous upper bounds predict the behavior
of A in some natural, combinatorially-rich search spaces. We begin by applying A to solve the
knapsack problem with near-accurate admissible heuristics constructed from an efficient approximation algorithm for this problem. We additionally apply our analysis of A search for the partial
Latin square problem, where we can provide quite exact analytic bounds on the number of nearoptimal solutions. These results demonstrate a dramatic reduction in effective branching factor of
A when coupled with near-accurate heuristics in search spaces with suitably sparse solution sets.

1. Introduction
The classical A search procedure (Hart, Nilson, & Raphael, 1968) is a method for bringing heuristic
information to bear on a natural class of search problems. One of A s celebrated features is that
when coupled with an admissible heuristic function, that is, one that always returns a lower bound
on the distance to a solution, A is guaranteed to find an optimal solution. While the worst-case
behavior of A (even with an admissible heuristic function) is no better than that of, say, breadthfirst search, both practice and intuition suggest that availability of an accurate heuristic should
decrease the running time. Indeed, methods for computing accurate admissible heuristic functions
for various search problems have been presented in the literature (see, e.g., Felner, Korf, & Hanan,
2004). In this article, we investigate the effect of such accuracy on the running time of A search;
2012 AI Access Foundation. All rights reserved.

fiDinh, Dinh, Michel, & Russell

specifically, we focus on rigorous estimates for the running time of A when coupled with accurate
heuristics.
The initial notion of accuracy we adopt is motivated by the standard framework of approximation algorithms: if f () is a hard combinatorial optimization problem (e.g., the permanent of
a matrix, the value of an Euclidean traveling salesman problem, etc.), an algorithm A is an efficient -approximation to f if A runs in polynomial time and (1  )f (x)  A(x)  (1 + )f (x),
for all inputs x, where f (x) is the optimal solution cost for input x and A(x) is the solution cost
returned by algorithm A on input x. The approximation algorithms community has developed
efficient approximation algorithms for a wide swath of NP-hard combinatorial optimization problems and, in some cases, provided dramatic lower bounds asserting that various problems cannot be
approximated beyond certain thresholds (see Vazirani, 2001; Hochbaum, 1996, for surveys of this
literature). Considering the great multiplicity of problems that have been successfully addressed in
this way (including problems believed to be far outside of NP, like matrix permanent), it is natural to
study the behavior of A when coupled with a heuristic function possessing such properties. Indeed,
in some interesting cases (e.g., Euclidean travelling salesman, matrix permanent, knapsack), hard
combinatorial problems can be approximated in polynomial time to within any fixed constant  > 0;
in these cases, the polynomial depends on the constant . We remark, also, that many celebrated
approximation algorithms with provable performance guarantees proceed by iterative update methods coupled with bounds on the local change of the objective value (e.g., basis reduction in Lenstra,
Lenstra, & Lovasz, 1981, and typical primal-dual methods in Vazirani, 2002).
Encouraged both by the possibility of utilizing such heuristics in practice and the natural question
of understanding the structural properties of heuristics (and search spaces) that indeed guarantee
palatable performance on the part of A , we study the behavior of A when provided with a heuristic
function that is an -approximation to the cost of a cheapest path to a solution. As certain natural
situations arise where approximation quality is asymmetric (i.e., the case of an admissible heuristic),
we slightly refine the notion of accuracy by distinguishing the multiplicative factors in the two sides
of an approximation: we say that a heuristic h is an (1 , 2 )-approximation to the actual cost
function h , or simply (1 , 2 )-approximate, if (1  1 )h  h  (1 + 2 )h . In particular, admissible
heuristics with -approximation are (, 0)-approximate. We will call a heuristic -accurate if it is
(1 , 2 )-approximate and  = 1 + 2 . A detailed description appears in Section 2.1.
1.1 A Sketch of the Results
We initially model our search space as an infinite b-ary tree with a distinguished root. A problem
instance is determined by a set S of nodes of the treethe solutions to the problem. The cost
associated with a solution s  S is simply its depth. The search procedure is equipped with (i.) an
oracle which, given a node n, determines if n  S, and (ii.) an heuristic function h, which assigns
to each node n of the tree an estimate of the actual length h (n) of the shortest (descending) path
to a solution. Let S be a solution set in which the first (and hence optimal) solution appears at
depth d. We establish a family of upper bounds on the number of nodes expanded by A : if h is an
(1 , 2 )-approximation of h , then A finds a solution of cost no worse than (1 + 2 )d and expands
no more than 2b(1 +2 )d + dN1 +2 nodes, where N denotes the number of solutions at depth less
than (1 + )d. See Lemma 3.1 below for stronger results. We emphasize that this bound applies to
any solution space and can be generalized to search models with non-uniform branching factors and
non-uniform edge costs (see Section 5).
We go on to show that this upper bound is essentially tight; in fact, we show that the bound is
nearly achieved even by non-adversarially determined solution spaces selected according to a simple
stochastic rule (see Theorems 3.1 and 4.1.). We remark that these bounds on running time fall off
rapidly as the accuracy of the heuristics increases, as long as the number of near-optimal solutions
is not too large (although it may grow exponentially). For instance, the effective branching factor
of A guided by an admissible -accurate heuristic will be reduced to b if N = O(bd ). However,
686

fiThe Time Complexity of A with Approximate Heuristics

in the worst cases, which occur when the search space has an overwhelming number of near-optimal
solutions, A still has to expand almost as many nodes as brute-force does, regardless of heuristic
accuracy. Likewise, strong guarantees on  < 1 are, in general, necessary to effect appreciable
changes in average branching factor. This is discussed in Theorem 4.2.
After establishing bounds for the tree-based search model, we examine the time complexity of
A on a graph by unrolling the graph into an equivalent tree and then bounding the number of
near-optimal solutions in the tree which are a lift of a solution in the original graph. This appears
in Section 6. Using spectral graph theory, we show that the number N of lifted solutions on the
tree corresponding to a b-regular graph G is O((1+)d ), assuming the optimal solution depth d is
O(logb |G|) and the number solutions in G is constant, where  is the second largest eigenvalue (in
absolute value) of the adjacency matrix of G. In particular,for almost all b-regular graphs in which
b does not grow with the size of graphs, we have   2 b, which yields the effective branching
factor of A search on such graphs is roughly at most 8b(1+)/2 if the heuristic is -accurate. We
also experimentally evaluate these heuristics.
Experimental Results and the Relationship to A in Practice. Of course, these upper
bounds are most interesting if they reflect the behavior of search problems in practice. The bounds
above guarantee, in general, that E, the number of nodes expanded by A with a -accurate heuristic,
satisfies
E 2bd + dN .
Under the plausible condition that N  bd , we have simply E  cbd node expansions for a
constant c that does not depend on  (c may depend on k and/or other properties of the search
space). This suggests the hypothesis that for hard combinatorial problems with suitably sparse
near-optimal solutions,
E  cbd

or, equivalently,

log E  log c + d log b .

(1)

In particular, this suggests a linear dependence of log E on .
To explore this hypothesis, we conducted a battery of experiments on the natural search-tree
presentation of the well-studied Knapsack Problem. Here we obtain an admissible -accurate heuristic by applying the Fully Polynomial Time Approximation Scheme (FPTAS) for the problem due
to the work of Ibarra and Kim (1975) (see also Vazirani, 2001, p. 70), which provides us with a
convenient method for varying  without changing the other parameters of the search. We remark
that the natural search space for the problem is a quite irregular edge-weighted directed graph on
which A can avoid reopening any node. Thus, this search space is equivalent to one of its spanning
subtrees in terms of A s behaviors. In order to focus on computationally nontrivial examples, we
generate Knapsack instances from distributions that are empirically hard for the best known exact
algorithms (Pisinger, 2005). The results of these experiments yield remarkably linear behavior (of
log E as a function of ) for a quite wide window of values: indeed, our tests yield R2 correlation
coefficients (of the least-square linear regression model) in excess of 90% with  in the range (.5, 1)
for most Knapsack instances. See Section 7.1 for details.
While the experimental results discussed above for the Knapsack problem support the linear
scaling of (1), several actual parameters of the search are unknown: for example, we cannot rule
out the possibility that the approximation algorithm, when asked to produce an -approximation,
does not in fact produce a significantly better approximation. While this seems far-fetched, such
behavior could provide spurious evidence for linear scaling. To explore the hypothesis in more
detail, we additionally explore a more artificial search space for the partial Latin square completion
(PLS) problem in which we can provide precise control of  (and, in fact, N ). The PLS problem is
featured in a number of benchmarks for local search and complete search methods. Roughly, this
is the problem of finding an assignment of values to the empty cells of a partially filled n  n table
so that each row and column in the completed table is a permutation of the set {1, . . . , n}. In our
formulation of the problem, the search space is a 2n-regular graph, thus the brute-force branching
687

fiDinh, Dinh, Michel, & Russell

factor is 2n. On this search space, by controlling N , we prove an asymptotic upper bound of

(1 + ) (1 + 1/) n on the effective branching factor of A coupled with any -accurate heuristic.
We also experimentally evaluate the effective branching factor of A with the admissible -accurate
heuristic (1)h , with which A expands more nodes than with any admissible -accurate heuristic
strictly larger than (1  )h .
We remark that while the PLS problem itself is well-studied and natural, we invent specific search
space structure on the problem that allows us to analytically control the number of near-optimal
solutions. Unlike the Knapsack problem, where we can construct an efficient admissible -accurate
heuristic for every fixed  thanks to the given FPTAS, known approximation algorithms for the PLS
problem are much weakerthey provide approximations for specific constants (1/e). To avoid this
hurdle, we construct instances of PLS with known solution, from which we extract the heuristics
(1  )h . Despite these planted solutions and contrived heuristics, the infrastructure provides
an example of a combinatorially rich search space with known solution multiplicity and a heuristic
of known quality, and so provides a means for experimentally measuring the relationship between
heuristic accuracy and running time. Our empirical data results in remarkable agreement with the
theoretical upper bounds. More subtly, by empirically analyzing the linear dependence of log E on
, we see that the effective branching factor of A using the heuristic (1  )h on the given PLS
search space is roughly (2n)0.8 ; see Section 7.2.
As far as we are aware, these are the first experimental results that explore the relationship
between  and E. Understanding heuristic accuracy and solution space structure in general (and
the ensuing bounds on A running time) for problems and heuristics of practical interest remains
an intriguing open problem. We remark that for problems such as the (n2  1)-puzzle, which have
been extensively used as test cases for A , it seems difficult to find heuristics with accuracy sufficient
to significantly reduce average branching factor. The best rigorous algorithms can only give rather
large constant guarantees (Ratner & Warmuth, 1990; Parberry, 1995): in particular, Parberry (1995)
shows that one can quickly compute solutions (and hence approximate heuristics) that are no more
than a factor 19 worse than optimal; the situation is somewhat better for random instances, where
he establishes a 7.5-factor. See Demaines (2001) work for a general discussion.
Observe that any search algorithm not privy to heuristic information requires (bd ) running
time, in general, to find a solution. High probability statements of the same kind can be made if the
solution space is selected from a sufficiently rich family. Such pessimistic lower bounds exist even
in situations where the search space is highly structured (Aaronson, 2004). Our results suggest that
accurate heuristic information can have a dramatic impact on A search, even in face of substantial
solution multiplicity.
This article expands the conference article (Dinh, Russell, & Su, 2007) where the complexity of
A with an -approximate heuristic function was studied over trees. In this article, we generalize this
to asymmetric approximation, develop analogous bounds over general search spaces, establishing a
connection to algebraic graph theory, and report on a battery of supporting experimental results.
1.2 Motivation and Related Work
The A algorithm has been the subject of an enormous body of literature, often investigating its
behavior in relation to a specific heuristic and search problem combination, (e.g., Zahavi, Felner,
Schaeffer, & Sturtevant, 2007; Sen, Bagchi, & Zhang, 2004; Korf & Reid, 1998; Korf, Reid, &
Edelkamp, 2001; Helmert & Roger, 2008). Both space complexity (Korf, 1985) and time complexity
have been addressed at various levels of abstraction. Abstract formulations, involving accuracy
guarantees like those we consider, have been studied, but only in tree models where the search
space possesses a single solution. In this single solution framework, Gaschnig (1979) has given
exponential lower bounds of (bd ) on the time complexity for admissible -accurate heuristics, where
def
b = b/(2)  b (see also Pearl, 1984, p. 180), while Pohl (1977) has studied more restrictive
(additive) approximation guarantees on h which result in linear time complexity. Average-case
688

fiThe Time Complexity of A with Approximate Heuristics

analysis of A based on probabilistic accuracy of heuristics has also been given for single-solution
search spaces (Huyn, Dechter, & Pearl, 1980). These previous analysis suggested that the effect of
heuristic functions would reduce the effective branching factor of the search, which is consistent with
our results when applied to the single-solution model (the special case when N = 1 for all  > 0).
The single solution model, however, appears to be an inappropriate abstraction of most search
problems featuring multiple solutions, as it has been recognized that . . . the presence of multiple
solutions may significantly deteriorate A s ability to benefit from improved precision. (Pearl, 1984,
p. 192) (emphasis added).
The problem of understanding the time complexity in terms of structural properties of h on
multiple-solution spaces has been studied by Korf and Reid (1998), Korf et al. (2001), and Korf
(2000), using an estimate based on the distribution of h() values. In particular, they studied an
abstract search space given by a b-ary tree and concluded that the effect of a heuristic function is
to reduce the effective depth of a search rather than the effective branching factor (Korf & Reid,
1998; Korf et al., 2001). For the case of accurate heuristics with controlled solution multiplicity, this
conclusion directly contradicts our findings, which indicate dramatic reduction in effective branching
factor for such cases. To explain this discrepancy, we observe that their analysis relies on an equilibrium assumption that fails for accurate heuristics (in fact, it fails even for much weaker heuristic
guarantees, such as h(v)  h (v) for small  > 0). The basic structure of their argument, however,
can be naturally adapted to the case of accurate heuristics, in which case it yields a reduction in
effective branching factor. We give a detailed discussion in Section 8.
As a follow-up to Korf and Reid (1998), Korf et al. (2001), and Korfs (2000) work, Edelkamp
(2001) examined A (indeed, IDA ) on undirected graphs, relying on the equilibrium assumption.
Edelkamps new technique is the use of graph spectrum to estimate the number n(`) of nodes at
certain depth ` in the brute-force search tree (same as our cover tree). However, unlike our spectral
analysis, which is of the original search graph G, Edelkamp analyzed the spectrum of a related
equivalence graph, which has quite different structural properties. Specifically, Edelkamp found
that the asymptotic branching factor, defined by the ratio n(`) /n(`1) for large `, equals the largest
eigenvalue of the adjacency matrix of the equivalence graph for certain Puzzle problems. To compare,
our spectral analysis depends on the second largest eigenvalue of the adjacency matrix AG of the
original search graph G, while the largest eigenvalue of AG always equals the branching factor,
assuming G is regular.
Additionally, the analyses of Korf and Reid (1998), Korf et al. (2001), and Korf (2000) (and
therefore, of Edelkamp, 2001) focus on a particular subclass of admissible heuristics, called consistent
heuristics. We remark that the heuristics used in our experiments for the Knapsack problem are
admissible but likely inconsistent. Zhang, Sturtevant, Holte, Schaeffer, and Felner (2009) and Zahavi
et al. (2007) discuss usages of inconsistent heuristics in practice.
Our work below explores both worst-case and average-case time complexity of A search on
both trees and graphs with multiple solutions when coupled with heuristics possessing accuracy
guarantees. We make no assumptions regarding consistency or admissibility of the heuristics, though
several of our results can be naturally specialized to this case. In addition to studying the effect of
heuristic accuracy, our results also shed light on the sensitivity of A to the distribution of solutions
and the combinatorial structure of the underlying search spaces (e.g., graph eigenvalues, which
measure, among other things, the extent of connectedness for graphs). As far as we are aware, these
are the first rigorous results combining search space structure and heuristic accuracy in a single
framework for predicting the behavior of A .

2. Preliminaries
A typical search problem is defined by a search graph with a starting node and a set of goal nodes
called solutions. Any instance of A search on a graph, however, can be simulated by A search on
a cover tree without reducing running time; this is discussed in Section 6.1. Since the number of
689

fiDinh, Dinh, Michel, & Russell

expansions on the cover tree of a graph is larger than or equal to that on the original graph, it is
sufficient to upper bound the running time of A search on the cover tree. With this justification,
we begin with considering the A algorithm for search problems on a rooted tree.
Problem Definition and Notations. Let T be a tree representing an infinite search space, and
let r denote the root of T . For convenience, we also use the symbol T to denote the set of vertices
in the tree T . Solutions are specified by a nonempty subset S  T of nodes in T . Each edge on T
is assigned a positive number called the edge cost. For each vertex v in T , let
 SubTree(v) denote the subtree of T rooted at v,
 Path(v) denote the path in T from root r to v,
 g(v) denote the total (edge) cost of Path(v), and
 h (v) denote the cost of the least costly path from v to a solution in SubTree(v). (We write
h (v) =  if no such solution exists.)
The objective value of this search problem is h (r), the cost of the cheapest path from the root r
to a solution. The cost of a solution s  S is the value of g(s). A solution of cost equal to h (r) is
referred to as optimal.
The A algorithm is a best-first search employing an additive evaluation function f (v) = g(v) +
h(v), where h is a function on T that heuristically estimates the actual cost h . Given a heuristic
function h : T  [0, ], the A algorithm using h for our defined search problem on the tree T is
described as follows:
Algorithm 1 A search on a tree
1. Initialize Open := {r}.
2. Repeat until Open is empty:
(a) Remove from Open a node v at which the function f = g + h is minimum.
(b) If v is a solution, exit with success and return v.
(c) Otherwise, expand node v, adding all its children in T to Open.
3. Exit with failure.
It is known (e.g., Dechter & Pearl, 1985, Lemma 2) that at any time before A terminates, there
is always a vertex v present in Open such that v lies on a solution path and f (v)  M , where M is
the min-max value defined as follows:


def
M = min
max f (u) .
(2)
sS

uPath(s)

This fact leads to the following node expansion conditions:
 Any vertex v expanded by A (with heuristic h) must have f (v)  M . (cf., Dechter & Pearl,
1985, Thm. 3). We say that a vertex v satisfying f (v)  M is potentially expanded by A .
 Any vertex v with
max

f (u) < M

uPath(v)

must be expanded by A (with heuristic h) (cf., Dechter & Pearl, 1985, Thm. 5). In particular,
when the function f monotonically increases along the path from the root r to v, the node v
must be expanded if f (v) < M .
690

fiThe Time Complexity of A with Approximate Heuristics

The value of M will be obtained on the solution path with which A search terminates (Dechter &
Pearl, 1985, Lemma 3), which implies that M is an upper bound for the cost of the solution found
by the A search.
We remark that if h is a reasonable approximation to h along the path to the optimal solution,
this immediately provides some control on M . In particular:
Proposition 2.1. (See also Davis, Bramanti-Gregor, & Wang, 1988) Suppose that for some   1,
h(v)  h (v) for all vertices v lying on an optimal solution path; then M  h (r).
Proof. Let s be an optimal solution. For all v  Path(s),
f (v)  g(v) + h (v) = g(v) + (g(s)  g(v))  g(s) .
Hence M 

max

f (v)  g(s) = h (r).

vPath(s)

In particular, M = h (r) if the heuristic function satisfies h(v)  h (v) for all v  T , in which
case the heuristic function is called admissible. The observation above recovers the fact that A
always finds an optimal solution when coupled with an admissible heuristic function (cf., Pearl,
1984, Thm. 2, 3.1). Admissible heuristics also possess a natural dominance property (Pearl, 1984,
Thm. 7, p. 81): for any admissible heuristic functions h1 and h2 on T , if h1 is more informed than
h2 , i.e., h1 (v) > h2 (v) for all v  T \S, then A using h1 dominates A using h2 , i.e., every node
expanded by A using h1 is also expanded by A using h2 .
2.1 Approximate Heuristics
Recall from the introduction that we shall focus on heuristics providing an (1 , 2 )-approximation to
the actual optimal cost to reach a solution:
Definition. Let 1 , 2  [0, 1]. A heuristic function h is called (1 , 2 )-approximate if
(1  1 )h (v)  h(v)  (1 + 2 )h (v)

for all v  T .

An (1 , 2 )-approximate heuristic is simply called -approximate if both 1   and 2  . If a
heuristic function h is (1 , 2 )-approximate, we shall say that h has a heuristic error 1 + 2 , or h is
(1 + 2 )-accurate.
As we will see below, these two approximation factors control the performance of A search
in rather different ways: while 1 only effects the running time of A , 2 has impact on both the
running time and the quality of the solution found by A . Particularly, the special case 2 = 0
corresponds to admissible heuristics, with which A always finds an optimal solution. In general, by
Proposition 2.1, we have:
Fact 1. If h is (1 , 2 )-approximate, then M  (1 + 2 )h (r).
Hence, the solution found by A using an (1 , 2 )-approximate heuristic must have cost no more
than (1 + 2 )h (r) and thus exceeds the optimal cost by no more than a multiplicative factor equal
2 .
Definition. Let   0. A solution of cost less than (1 + )h (r) is called a -optimal solution.
Assumptions. To simplify the analysis for now, we assume that the search tree T is b-ary and
that every edge is of unit cost unless otherwise specified. In this case, the cost g(v) is simply the
depth of node v in T and h (v) is the shortest distance from v to a solution that is a descendant of v.
Throughout, the parameters b  2 (the branching factor of the search space) and 1  (0, 1], 2  [0, 1]
(the quality of the approximation provided by the heuristic function) are fixed. We rule out the case
1 = 0 for simplicity.
691

fiDinh, Dinh, Michel, & Russell

3. Upper Bounds on Running Time of A on Trees
We are now going to establish upper bounds on the running time of A search on the tree model.
We will first show a generic upper bound that applies to any solution space. We then apply this
generic upper bound to a natural stochastic solution space model.
3.1 A Generic Upper Bound
As mentioned in the introduction, we begin with an upper bound on the time complexity of A
search depending only on the weight distribution of the solution set, in addition to the heuristics
approximation factors. We shall, in fact, upper bound the number of potentially expanded nodes,
which is clearly an upper bound on the number of nodes actually expanded by A :
Lemma 3.1. Let S be a solution set whose optimal solutions lie at depth d. Then, for every   0,
the number of nodes expanded by A search on the tree T with an (1 , 2 )-approximate heuristic is
no more than
2b(1 +2 +1)d + (1  1 )dN1 +2
nodes, where N is the number of -optimal solutions.
The presence of the independent parameter  offers a flexible way to apply the upper bound in
Lemma 3.1. In particular, applying Lemma 3.1 with  = 1 and using the fact that 1  1  1, we
arrive at the upper bound of 2b(1 +2 )d + dN1 +2 mentioned in the introduction. This bound works
best when1 N1 +2 = (b(1 +2 )d ). In general, if N1 +2 = O(b(1 +2 )d ), we should choose the least
  1 for which N1 +2 = O(b(1 +2 )d ). In the opposite case, if N1 +2 = (b(1 +2 +c)d ) for some
positive constant c  1  1 , we can obtain a better bound by choosing  = 1  c/(1  1 ) < 1, since
N1 +2 dominates both terms (b(1 +2 +1)d ) and N1 +2 given such a choice of .
Proof of Lemma 3.1. Let d = h (r) and let  = 1 + 2 . Consider a node v which does not lie on
any path from the root to a -optimal solution, so that h (v)  (1 + )d  g(v). Then
f (v)  g(v) + (1  1 )[(1 + )d  g(v)] = (1  1 )(1 + )d + 1 g(v) .
Recall that a node is potentially expanded by A if its f -value is less than or equal to M . Since
M  (1 + 2 )d, the node v will not be potentially expanded if
(1  1 )(1 + )d + 1 g(v) > (1 + 2 )d .

(3)

Since 1 > 0, the inequality (3) is equivalent to
g(v) > (2 /1  /1 + 1 + )d = (1 + 2 + 1  )d .
In other words, any node at depths in the range

(1 + 2 + 1  )d, (1 + 2 )d
can be potentially expanded only when it lies on the path from the root to some -optimal solution.
On the other hand, on each -optimal
solution path, there are at most (1  1 )d nodes at depths

in (1 + 2 + 1  )d, (1 + 2 )d . Pessimistically assuming that all nodes with depth no more than
(1 + 2 + 1  )d are potentially expanded in addition to those on paths to -optimal solutions
P`
yields the statement of the lemma. (Note that as b  2, i=0 bi  2b` and that every potentially
expanded node v must have depth g(v)  f (v)  M  (1 + 2 )d.)
1. Recall some asymptotic notations: f (n) = (g(n)) means there exist constants c1 , c2 > 0 such that c1 g(n) 
f (n)  c2 g(n) for sufficiently large n; f (n) = (g(n)) means there exists a constant c > 0 such that cg(n)  f (n)
for sufficiently large n.

692

fiThe Time Complexity of A with Approximate Heuristics

3.2 An Upper Bound on a Natural Search Space Model
While actual time complexity will depend, of course, on the precise structure of S and h, we show
below that this bound is essentially tight for a rich family of solution spaces. We consider a sequence
of search problems of increasing difficulty, expressed in terms of the depth d of the optimal solution.
A Stochastic Solution Space Model. For a parameter p  [0, 1], consider the solution set S
which is obtained by independently placing each node of T into S with probability p. In this
setting, S is a random variable and is written Sp . When solutions are distributed according to Sp ,
observe that the expected number of solutions at depth d is precisely pbd and that when p = bd an
optimal solution lies at depth d with constant probability. For this reason, we focus on the specific
values pd = bd and consider the solution set Spd for each d > 0. Recall that under this model, it
is likely for the optimal solutions to lie at depth d and, more generally, we can see that with very
high probability the optimal solutions of any particular subtree will be located near depth d (with
respect to the root of the subtree). We make this precise below.
Lemma 3.2. Suppose the solutions are distributed according to Spk . Then for any node v  T and
t > 0,
td
1  2btd  Pr[h (v) > t]  eb .
Pt
Proof. In the tree SubTree(v), there are n = i=0 bi = (bt+1  1)/(b  1) nodes at depths t or less,
so Pr[h (v) > t] = (1  bd )n . We have

1  nbd  (1  bd )n  exp nbd .
The first inequality is obtained by applying Bernoullis inequality, and the last one is implied from
the fact that 1  x  ex for all x. Observing that
bt 

bt+1  1
 2bt
b1

for b  2 completes the proof.
Observe that in the Spd model, conditioned on the likely event that the optimal solutions appear
at depth d, the expected number of -optimal solutions is (bd ). In this situation, according to
Lemma 3.1, A expands no more than O(b(1 +2 +1)d ) + O(db(1 +2 )d ) vertices in expectation,
for any   0. The leading exponential term in this bound is equal to
max {(1 + 2 + 1  )d, (1 + 2 )d} ,
which is minimal when  = 1. This suggests the best upper bound that can be inferred from the
family of bounds in Lemma 3.1 is poly(d)b(1 +2 )d (for Spd ).
Before discussing the average-case time complexity of A search, we record the following wellknown Chernoff bound, which will be used to control the tail bounds in our analysis later.
Lemma 3.3 (Chernoff bound, Chernoff, 1952). Let Z be the sum of mutually independent indicator
random variables with expected value  = E [Z]. Then for any  > 0,


e
Pr[Z > (1 + )] <
.
(1 + )1+
A detailed proof can be found in the book of Motwani and Raghavan (1995). In several cases
below, while we do not know exactly the expected value of the variable to which we wish to apply
the tail bound in Lemma 3.3, we can compute sufficiently good upper bounds on the expected value.
In order P
to apply the Chernoff
in such a case, we actually require a monotonicity argument:
Pbound
n
n
0
0
If Z =
X
and
Z
=
X
i=1 i
i=1 i are sums of independent and identically distributed (i.i.d.)
indicator random variables so that E [Xi ]  E [Xi0 ], then Pr[Z > ]  Pr[Z 0 > ] for all . With this
argument and by applying Lemma 3.3 for  = e  1, we obtain:
693

fiDinh, Dinh, Michel, & Russell

Corollary 3.1. Let Z be the sum of n i.i.d. indicator random variables so that E [Z]    n, then
Pr[Z > e] < e .
Adopting the search space whose solutions are distributed according to Spd , we are ready to
bound the running time of A on average when guided by an (1 , 2 )-approximate heuristic:
3

Theorem 3.1. Let d be sufficiently large. With probability at least 1  ed  e2d , A search on the
tree T using an (1 , 2 )-approximate heuristic function expands no more than 12d4 b(1 +2 )d vertices
when solutions are distributed according to the random variable Spd .
Proof. Let X be the random variable equal to the total number of nodes expanded by the A with
an (1 , 2 )-approximate heuristic. Of course the exact value of, say, E [X] depends on h; we will prove
upper bounds achieved with high probability for any (1 , 2 )-approximate h. Applying Lemma 3.1
with  = 1, we conclude

X  2b(1 +2 )h (r) + (1  1 )h (r)N1 +2 .
Thus it suffices to control both h (r) and the number N1 +2 of (1 + 2 )-optimal solutions.
We will utilize the fact that in the Spd model, the optimal solutions are unlikely to be located
far from depth d. To this end, let Efar be the event that h (r) > d +  for some  < d to be set

later. Lemma 3.2 immediately gives Pr[Efar ]  eb .
Observe that conditioned on Efar , we have h (r)  d+ and N1 +2  Z, where Z is the random
variable equal to the number of solutions with depth no more than (1 + 1 + 2 )(d + ). We have
d
(1+1 +2 )(d+)
= 2b(1 +2 )d+(1+1 +2 ) < 2b(1 +2 )d+3
E[Z]  b  2b

and, applying the Chernoff bound in Corollary 3.1 to control Z,
h
i


3
Pr Z > 2eb(1 +2 )d+3  exp 2b(1 +2 )d+3  e2b .
Letting Ethick be the event that Z  6b(1 +2 )d+3 , observe
h
i
3
Pr[Ethick ]  Pr Z > 2eb(1 +2 )d+3  e2b .
To summarize: when neither Efar nor Ethick occurs,
X  2b(1 +2 )(d+) + (1  1 )(d + )6b(1 +2 )d+3
 6(d + )b(1 +2 )d+3
 12db(1 +2 )d+3 .
Hence,
h
i

3
Pr X > 12db(1 +2 )d+3  Pr[Efar  Ethick ]  eb + e2b .
To infer the bound stated in our theorem, set b = d so that b(1 +2 )d+3 = d3 b(1 +2 )d , completing
the proof.
Remark By similar methods, other trade-offs between the error probability and the resulting bound
on the number of expanded nodes can be obtained.
694

fiThe Time Complexity of A with Approximate Heuristics

4. Lower Bounds on Running Time of A on Trees

We establish that the upper bounds in Theorem 3.1 are tight to within a O(1/ d) term in the
exponent. We begin by recording the following easy fact about solution distances in this discrete
model.
Fact 2. Let   h (r) be a nonnegative integer. Then for every solution s, there is a node v 
Path(s) such that h (v) = .
Proof. Fix a distance   h (r). We will prove the lemma by induction on the depth of solutions.
The lemma clearly holds for optimal solutions. Consider a solution s which may not be optimal,
and let v  Path(s) be the node which is  level far from s so that h (v)  . If h (v) < , there
must be another solution s0  SubTree(v) that is closer to v. By the induction assumption, there
is a node v 0  Path(s0 ) with h (v 0 ) = . This node v 0 must be an ancestor of v, since the distance
between v and s0 is less than  while the distance between v 0 and s0 is at least , completing the
proof.
We proceed now to the lower bound.
Theorem 4.1.Let d be sufficiently large. For solutions distributed according to Spd , with probability
at least 1  b d , there exists an (1 , 2 )-approximate heuristic function 
h so that the number of
vertices expanded by A search on the tree T using h is at least b(1 +2 )d4 d /8.
Proof. Our plan is to define a pathological heuristic function that forces A to expand as many
nodes as possible. Note that the heuristic function here is allowed to overestimate h . Intuitively,
we wish to construct a heuristic function that overestimates h at nodes close to a solution and
underestimates h at nodes far from solutions, leading A astray whenever possible. Recall that for
every vertex v, it is likely to have a solution lying at depth d of SubTree(v). Thus we can use the
quantity h (v)  d   to formalize the intuitive notion that the node v is close to a solution, where
the quantity  < d will be determined later. Our heuristic function h is formally defined as follows:
(
(1 + 2 )h (v) if h (v)  d  ,
h(v) =
(1  1 )h (v) otherwise.
Observe that the chance for a node to be overestimated is small since, by Lemma 3.2,
Pr[v is overestimated] = Pr[h (v)  d  ]  2b

(4)

for any node v. Also note that if a node v does not have any overestimated ancestor, then the f
values will monotonically increase along the path from root to v.
Naturally, we also wish to ensure that the optimal solution is not too close to the root. Let Eclose
be the event that h (r)  d  . Again by Lemma 3.2,
Pr[Eclose ]  2b .
We then will see that conditioned on the event Eclose , which means h (r) > d  , every
solution will be obscured by an overestimated node that is not too close to a solution. Concretely,
up to issues of integrality, Fact 2 asserts that for every solution s, there must be a node v on the
path from the root to s with h (v) = d  , as long as d   < h (r).
Assume Eclose : then whenever h (v) = d  , we have g(v)  h (r)  (d  ) > 0 and h(v) =
(1 + 2 )(d  ), and thus f (v) > (1 + 2 )(d  ). Since every solution is obscured by some
overestimated node whose f value is larger than (1 + 2 )(d  ), we have M > (1 + 2 )(d  ), where
M is the min-max value defined in (2). It follows that a node v must be expanded if Path(v) does
695

fiDinh, Dinh, Michel, & Russell

not contain any overestimated node and f (v)  (1 + 2 )(d  ). When Path(v) does not contain
an overestimated node, we have f (v) = g(v) + (1  1 )h (v), so
f (v)  (1 + 2 )(d  )  (1  1 )h (v)  (1 + 2 )(d  )  g(v) ,
since 1 < 1. Therefore, we say a node v is required if there is no overestimated node in Path(v) and
(1  1 )h (v)  (1 + 2 )(d  )  g(v). To recap, conditioned on Eclose , the set of required nodes is
a subset of the set of nodes expanded by A search using our defined heuristic function. We will use
the Chernoff bound to control the size of R` which denotes the set of non-required nodes at depth
`.
Let v be a node at depth ` < (1 + 2 )d. Equation (4) implies
Pr[ an overestimated node in Path(v)]  2`b < 1/16 .
The last inequality holds for sufficiently large d, as long as  = poly(d). On the other hand, if
1 < 1, we have




(1 + 2 )(d  )  `
Pr v  R` = Pr h (v) >
1  1


(1+2 )(d)`
d
11
 exp b
(by Lemma 3.2)


(1 +2 )d(1+2 )`
11
.
(5)
= exp b
Now set ` = (1 + 2 )d  (1 + 2 )  logb 4. Then Equation (5) implies
 logd 4 


Pr v  R`  exp b 11  e4  1/16 .
In the case 1 = 1, the event (1  1 )h (v) > (1 + 2)(d  )  ` never
given the value
fi
fi happens
of ` that has been set. Hence, in any case, Pr v  R`  1/8 so that E fiR` fi  b` /8. Applying the
Chernoff bound in Corollary 3.1 again yields
fi fi

Pr fiR` fi > eb` /8  exp(b` /8) .
fi fi
Let Ethin be the event that fiR` fi  b` /2. Since b` /2 > eb` /8,
Pr[Ethin ]  exp(b` /8) .
Putting the pieces together, we have


`
Pr A expands less than b` /2 nodes  Pr[Eclose  Ethin ]  2b + eb /8 .


Setting  = 2 d we have ` = (1 + 2 )d  2(1 + 2 ) d  logb 4, and thus
h
i


Pr A expands less than b(1 +2 )d4 d /8 nodes  b d
for sufficiently large d.
For contrast, we now explore the behavior of A with an adversarially selected solution set; this
achieves a lower bound which is nearly tight (in comparison with the general upper bound on the
worst-case running time of A obtained by setting  = 0 in the bound of Lemma 3.1 above).
696

fiThe Time Complexity of A with Approximate Heuristics

Theorem 4.2. For any d > 1, there exists a solution set S whose optimal solutions lie at depth d
and an (1 , 2 )-approximate heuristic function h such that the A on the tree T using h expands at
least b(1+2 )d12 /1 nodes.
Proof. Consider a solution set S in which all 2 -optimal solutions share an ancestor u lying at depth
1. Furthermore, S contains every node at depth (1 + 2 )d that is not a descendant of u, where
d = h (r).
Now define an (1 , 2 )-approximate heuristic h as follows: h(u) = (1 + 2 )h (u) and h(v) =
(1  1 )h (v) for all v 6= u. With this heuristic, every 2 -optimal solution is hidden from the search
procedure by its ancestor u. Precisely, since f (u) = 1 + (1 + 2 )(d  1) = (1 + 2 )d  2 , every
2 -optimal solution s (which is a descendant of u) will have
max
vPath(s)

f (v)  f (u) = (1 + 2 )d  2 .

Thus M  (1 + 2 )d  2 , where M is the min-max value defined in Equation (2).
Let v be any node at depth `  (1 + 2 )d that does not lie inside of SubTree(u). Note that the
f values monotonically increase along the path from root r to v, which implies that the node v must
be expanded if f (v) < M . On the other hand, since every non-descendant of u at depth (1 + 2 )d is
a solution, we have ` + h (v)  (1 + 2 )d, and thus
f (v)  ` + (1  1 )[(1 + 2 )d  `] = (1  1 )(1 + 2 )d + 1 ` .
Hence, the node v must be expanded if (1  1 )(1 + 2 )d + 1 ` < (1 + 2 )d  2 , which is equivalent
to ` < (1 + 2 )d  2 /1 . It follows that the number of nodes expanded by A is at least
(1+2 )d12 /1

X
`=0

(1+2 )d22 /1

b` 

X

b` = b(1+2 )d12 /1 .

`=0

According to Theorem 4.2, if we set 2 = 0 and let 1 be arbitrarily small provided 1 > 0, then
we can obtain a near-accurate heuristic which forces A to expand at least as many as bd1 nodes.
This lower bound partially explains why A can perform so poorly, even with an almost perfect
heuristic, in certain applications (Helmert & Roger, 2008): The adversarially-chosen solution set
given in the proof of Theorem 4.2 has an overwhelming number of near-optimal solutions. Indeed,
N+2  b(1+2 )d  b(1+2 )d1  b(1+2 )d1
for any  > 0.

5. Generalizations: Non-uniform Edge Costs and Branching Factors
In this section, we discuss how the generic upper bounds of Lemma 3.1 can be generalized to apply
to more natural search models such as those with non-uniform branching factors and non-uniform
edge costs; in Section 6, we show how these can be extended to general graph search models.
Now we consider a general search tree without the assumptions of uniform branching factor and
uniform edge costs. From the same argument given in the proof of Lemma 3.1, we derive the assertion
that when the heuristic is (1 , 2 )-approximate, any node of cost more than (1 + 2 + 1  )c will
not be potentially expanded if it does not lie on a (1 + 2 )-optimal solution path, where  is an
arbitrary nonnegative number and c = h (r) is the optimal solution cost.
Hence, the number of nodes potentially expanded by A with an (1 , 2 )-approximate heuristic
is bounded by


F (1 + 2 + 1  )c + R (1 + 2 + 1  )c , 1 + 2 .
(6)
697

fiDinh, Dinh, Michel, & Russell

Here F () is the number of nodes with cost no more than , which we call free nodes; R(, ) is the
number of nodes with cost in the range (, (1 + 2 )c ] that lie on a -optimal solution path, which
we call restricted nodes.
To bound the number of free and restricted nodes, respectively, we assume that the branching
factors are upper bounded and edge costs are lower bounded. Let B  2 be the maximal branching
factor and let m be the minimal edge cost. Since any node with cost no more than  must lie at
depth no larger than /m, we have
F ()  2B /m .
On each -optimal solution path, there are at most ((1 + 2 )c  )/m nodes of cost in the range
(, (1 + 2 )c ]. Thus,
(1 + 2 )c  
 N .
R(, ) 
m
Letting  = (1 + 2 + 1  )c ,  = 1 + 2 , and applying the bounds for F () and R(, ) to the
bound in (6), we obtain another upper bound on the number of expanded nodes when the heuristic
is (1 , 2 )-approximate:


2B (1 +2 +1)c

/m

+ N1 +2 (1  1 )c /m

(7)

for any   0. This equation (7) is a generalized version of the bound in Lemma 3.1. Substituting
 = 1 in (7), we arrive at the following simpler upper bound on the number of expanded nodes:
2B (1 +2 )c



/m

+ N1 +2 (1  1 )c /m .

(8)

6. Bounding Running Time of A on Graphs
In previous parts, we have established bounds on the running time of A on the tree model. Now
we will apply those bounds to A on the graph model. In order to do that, we will first unroll the
graph into a cover tree, and then bound the number of solutions lifted to the cover tree.
6.1 Unrolling Graphs into Trees
The preceding generic upper bounds are developed for tree-based models; in this section we discuss
a natural extension to general graph search models. The principal connection is obtained by unrolling a graph into a tree on which A expands at least as many nodes as it does on the original
graph (including repetitions). More specifically, given a directed graph G and starting node x0 in G,
we define a cover tree T (G) whose nodes are in one-to-one correspondence with finite-length paths
in G from x0 . We shall write a path (x0 , . . . , x` ) in G as a node in T (G). The root of T (G) is
(x0 ). The parent of a node (x0 , x1 , . . . , x` ) in T (G) is the node (x0 , x1 , . . . , x`1 ), and the edge cost
between the two nodes (x0 , x1 , . . . , x`1 ) and (x0 , x1 , . . . , x` ) in T (G) equals the cost of the edge
(x`1 , x` ) in G. Hence, for each node P in T (G), the cost value g(P ) is equal to the total edge
cost on the path P in G. A node (x0 , . . . , x` ) in T (G) is designated as a solution whenever x` is a
solution in G.
A node in T (G) that corresponds to a path ending at node x  G will be called a copy of x.
Observe that a solution in G may lift multiple times to solutions in T (G), as each node in G may
have multiple copies in T (G). Figure 1 illustrates an example of unrolling a graph into a cover tree.
In this example, node s is a solution in the graph and its first two copies in the cover tree correspond
to the paths (0, 3, s) and (0, 5, 3, s), where 0 is the starting node in the given graph.
The A search on graph G is described in Algorithm 2 below, in which h(x) is the heuristic
at node x, g(x) is the cost of the current path from x0 to x, and c(x, x0 ) denotes the cost of the
edge (x, x0 ) in G. We assume the value of h(x) depends only on x, i.e., h(x) does not depend on
a particular path from x0 to x. Unlike A search on a tree, for each node x in Open or Closed,
698

fiThe Time Complexity of A with Approximate Heuristics

0
1
6

1

3

5

2

2

s

3

6

1

1

5

2

s

2
0

5

3
s

Figure 1: Unrolling a graph into a cover tree.
Algorithm 2 also keeps track of the current path P from x0 to x through the pointers, and the
current f -value of x is equal to g(P ) + h(x). This current path is the cheapest path from x0 to x
that passes only nodes that have been expanded.
Algorithm 2 A search on a graph (Pearl, 1984, p. 64)
1. Initialize Open := {x0 } and g(x0 ) := 0.
2. Repeat until Open is empty.
(a) Remove from Open and place on Closed a node x for which the function f = g + h is
minimum.
(b) If x is a solution, exit with success and return x.
(c) Otherwise, expand x, generating all its successors. For each successor x0 of x,
i. If x0 is not on Open or Closed, estimate h(x0 ) and calculate f (x0 ) = g(x0 ) + h(x0 )
where g(x0 ) = g(x) + c(x, x0 ), and put x0 to Open with pointer back to x.
ii. If x0 is on Open or Closed, compare g(x0 ) and g(x) + c(x, x0 ). If g(x) + c(x, x0 ) <
g(x0 ), direct the pointer of x0 back to x and reopen x0 if it is in Closed.
3. Exit with failure.
Now consider A search on the cover tree T (G) of graph G using the same heuristic function h:
for each node P in T (G), set the heuristic value h(P ) to be equal to h(x) if P is a copy of node
x  G, i.e., P is a path in G from x0 to x. Observe that the cover tree T (G) and the graph G share
the same threshold M (defined in Equation (2)). Hence, whenever a node x  G is expanded with
current path P , we must have g(P ) + h(x)  M , which implies that P is potentially expanded by
A search on the cover tree T (G). This shows the following fact:
Fact 3. The number of node expansions by A on G is no more than the number of nodes potentially
expanded by A on T (G) using the same heuristic.
Here, by node expansion, we mean an execution of the expand step of A , i.e. Step (2c). Note
that, in general, a node in G can be expanded many times along different paths.
Remark The running time of A on the cover tree can also be used to upper bound the running time
of iterative-deepening A (IDA ) on the graph. Recall that the running time of IDA is dominated
by its last iteration. On the other hand, the last iteration of IDA on G is merely depth-first search
699

fiDinh, Dinh, Michel, & Russell

on the cover tree T (G) up to the cost threshold M . Hence, the number of expansions in the last
iteration of IDA is no more than the number of nodes potentially expanded by A on the cover
tree.
So, to upper-bound time complexity of A or IDA on a graph, it suffices to unroll the graph
into the cover tree and apply upper bounds on the number of nodes potentially expanded by A on
the cover tree. In particular, the bound in Equation (7) can be applied directly to the A search on
G.
Note that while these bounds can be applied directly, the problem of determining exactly how
solutions in G lift to solutions in the cover tree depends on delicate structural properties of G
specifically, it depends on the growth of the number of distinct paths from x0 to a solution as
a function of the length of these paths. In particular, in order to obtain general results on the
complexity of A in this model, we must invoke some measure of the connectedness of the graph G.
Below we show how to bound the complexity of A in terms of spectral properties of G. We choose
this approach because it offers a single parameter notion of connectedness (the second eigenvalue)
that is both analytically tractable and can actually be analyzed or bounded for many graphs of
interest, including various families of Cayley graphs and combinatorial graphs by methods such as
conductance.
6.2 An Upper Bound via Graph Spectra
We shall consider an undirected2 graph G on n vertices as the search space. Let x0 be the starting
node and let S be the set of solutions in G. For simplicity, assume G is b-regular (2 < b  n) and
the edge costs are uniformly equal to one, so the cover tree T (G) is b-ary and has uniform edge cost.
We assume, additionally, that |S| is treated as a constant when n  .
By Fact 3 and Lemma 3.1, the number of node expansions by A on G with an (1 , 2 )approximate heuristic is at most 2b(1 +2 )d + dN1 +2 , where d is the optimal solution cost, which
equals the optimal solution depth in T (G), and N is the number of -optimal solutions in T (G).
Our goal now is to upper bound N (of the cover tree T (G)) in terms of spectral properties of G.
We introduce the principal definitions of spectral graph theory below, primarily to set down
notation. A more complete treatment of spectral graph theory can be found in the work of Chung
(1997).
Graph Spectra. For a graph G, let A be the adjacency matrix of G: A(x, y) = 1 if x is adjacent
to y, and 0 otherwise. This is a real, symmetric matrix (AT = A) and thus has real eigenvalues
b = 1/b  A
b = 1  2  . . .  n  b, by the spectral theorem (Horn & Johnson, 1999). Let A
b
denote the normalized adjacency matrix of G; then A has eigenvalues 1 = 1  2  . . .  n  1,
which are referred to as the spectrum of G, where i = i /b. These eigenvalues, along with their
associated eigenvectors, determine many combinatorial aspects of the graph G. In most applications
def
of graph eigenvalues, however, only the critical value  = (G) = max {|2 |, |n |} is invoked
and, moreover, the real parameter of interest is the gap between  = /b and the largest eigenvalue
1 = 1 of the normalized adjacency matrix. Intuitively,  measures the connectedness of G.
Sparsely connected graphs have   1; for the n-cycle, for example,  = 1  O(1/n). The hypercube
on N = 2n vertices has  = 1  (1/ log N ). Similar bounds on  and , are known for many
families of Cayley graphs. Random graphs, even of constant degree b  3, achieve  = o(1) with
high probability. In fact, a recent result of Friedman (2003) strengthens this:
Theorem 6.1. (Friedman, 2003) Fix a real c > 0 and an integer b  2. Then with probability
1  o(1) (as n  ),

(Gn,b )  2 b  1 + c
2. While one can produce an analogous cover tree in the directed case, the spectral machinery we apply in the next
section is somewhat complicated by the presence of directed edges. See the work of Chung (2006) and Horn and
Johnson (1999, Perron-Frobenius theorem) for details.

700

fiThe Time Complexity of A with Approximate Heuristics

where Gn,b is a random b-regular graph on n vertices.
We remark that for any non-bipartite connected graph with diameter D, we always have  
b  1/(Dn). Under stronger conditions, when the graph is vertex-transitive (which is to say that
for any pair v0 , v1 of vertices of G there is an automorphism of G sending v0 to v1 ), one has
  b  (1/D2 ) (Babai, 1991). While vertex transitivity is a strong condition, it is satisfied by
many natural algebraic search problems (e.g., 15-puzzle-like search spaces and the Rubiks cube).
The principal spectral tool we apply in this section is described in Lemma 6.1 below. We begin
with some notation.
Notations. Any function  on G can be viewed as a column vector indexed by the vertices in G
and vice versa. For each vertex x  G, let 1x denote the function on G that has value 1 at x and
0 at everyPvertex other than x. For any real-valued functions ,  on G, define the
pinner product
h, i = xG (x)(x). We shall use k  k to denote the L2 -norm, i.e., kk = h, i for any
function  on G.
b is symmetric and real, by spectral theorem (Horn & Johnson, 1999), there
Recall that since A
exist associated eigenfunctions 1 , . . . , n that form an orthonormal basis for the space of real-valued
b In particular,
functions on G, where i is the eigenfunction associated with the eigenvalue i of A.
b
we have
Pn Ai = i i and ki k = 1 for all i, and hi , j i = 0 for all i 6= j. In this basis, we can write
 = i=1 h, i i i for any real-valued function  on G.
Lemma 6.1. Let G be an undirected b-regular graph with n vertices, and  = (G)/b. For any
probability distributions p and q on vertices of G, and any integers s, t  0,
fi
fiD


E
fi
fi s
b p, A
bt q  1 fi  s+t kpk  kqk  1 .
fi A
fi
nfi
n
Pn

Pn
ai i and q = j=1 bj j where ai = hp, i i , bj = hq, j i. Then
+
* n
n
n
n
D
E
X
X
X
X
t
s
t
s
b p, A
bq =
s+t
ai bi .
ai bj si tj hi , j i =
bj j j =
A
ai i i ,
i

Proof. Write p =

i=1

i=1

i,j=1

j=1

i=1

By the Cauchy-Schwartz inequality,
n
X

v
!
! n
u n
X
u X
2
2
t
|ai bi | 
bi = kpk  kqk .
ai

i=1

i=1

i=1
1/n

Without loss of generality, assume 1 (x) =
for all vertices x  G. Since p is a probability
distribution,
X
1
1 X
p(x) =  .
a1 = hp, 1 i =
p(x)1 (x) = 
n
n
xG

Similarly, b1 =

1 .
n

Thus, a1 b1 =

xG

1
n.

So we have
fi n
fi
fiD
fi
E 1 fifi fiX
fi s
fi
fi
s+t
b p, A
bt q  fi = fi
fi A

a
b
fi
i
i
i
fi
fi
nfi fi
i=2

 s+t

n
X

|ai bi |

(as  = max |i |)
2in

i=2



 s+t kpk  kqk 
completing the proof of the lemma.
701

1
n


,

fiDinh, Dinh, Michel, & Russell

With Lemma 6.1 in hand, we establish the following bound on the number of paths of a prescribed
length ` connecting a pair of vertices. We then apply this to control the number of -optimal solutions
in the cover tree of G. Let P` (u, v) denote the number of paths in G of length ` from u to v.
Lemma 6.2. Let G be an undirected b-regular graph with n vertices, and  = (G). For any vertices
u, v in G and `  0,
fi
fi


`fi
fi
fiP` (u, v)  b fi  ` 1  1 < ` .
fi
nfi
n
Proof. Since P` (u, v) is the number of `-length paths from u to v, we have P` (u, v) = b` p(`) (v), where
p(`) (v) is the probability that a natural random walk on G of length
` starting
from u ends up at
D
E


ff
P` (u,v)
`
(`)
`
(`)
(`)
b
b
= 1v , A 1u . Applying Lemma 6.1
v. Since p = A 1u and p (v) = 1v , p , we have
`
b

yields
fi
fi fi




E 1 fifi
fi P` (u, v)
1 fifi fifiD
`
b
fi
fi  ` k1v k  k1u k  1 = ` 1  1 .
1
,
A
1


=
v
u
fi b`
nfi fi
nfi
n
n
As  = /b, multiplying both sides of the last inequality by b` completes the proof for the lemma.
The major consequence of Lemma 6.2 in our application is the following bound on the number
of -optimal solutions in T (G).
Theorem 6.2. Let G be an undirected b-regular graph with n vertices, and  = (G). For sufficiently
large n and any   0, the number of -optimal solutions in T (G) is
 (1+)d

b
N < 2|S|
+ (1+)d ,
n
where d is the depth of optimal solutions in T (G), and S is the set of solution nodes in G.
Proof. For each solution s  S, the number of copies of s at level ` in T (G) equals P` (x0 , s), which
is less than b`/n + ` by Lemma 6.2. Hence, the number of solutions at level ` in T (G) is
 `

X
b
P` (x0 , s) < |S|
+ ` .
(9)
n
sS

Summing up both sides of (9) for ` ranging from d to (1 + )d, we have


(1+)d
(1+)d
(1+)d
X X
X
X
1
N =
P` (x0 , s) < |S| 
b` +
`  .
n
`=d sS

`=d

`=d

When n is sufficiently large, we have   2. Thus,


1 (1+)d
N < |S|
2b
+ 2(1+)d .
n

Note that b(1+)d
/n = O(1) if d =O(logb n). As mentioned earlier (Theorem 6.1), most b-regular
graphs have   2 b  1 + o(1)  2 b. Assuming G has this spectral property and d = O(logb n),
Theorem 6.2 gives


N = O((1+)d ) = O 2(1+)d b(1+)d/2 .
In such cases, the number of node expansions by A on G using an (1 ,   1 )-approximate heuristic
is O(d2(1+)d b(1+)d/2 ), which implies the effective branching factor of A is roughly bounded by
21+ b(1+)/2 < 8b(1+)/2 .
702

fiThe Time Complexity of A with Approximate Heuristics

7. Experimental Results
As discussed in the introduction, the bounds established thus far guarantee that E, the number of
nodes expanded by A using a -accurate heuristic, satisfies
E  2bd + dN  cbd
under the assumption that N  bd . (Here, as before, b is the branching factor, d is the optimal
solution depth, and c is some constant.) This suggests the hypothesis that for hard combinatorial
problems with suitably sparse near-optimal solutions,
log E  d log b +  .

(10)

where  is a constant determined by the search space and heuristic but independent from . In
particular, this suggests a linear dependence of log E on . We experimentally investigated this
hypothesized relationship with a family of results involving the Knapsack problem and the partial
Latin square problem. As far as we are aware, these are the first experimental results specifically
investigating this dependence.
We remark that in order for such an experimental framework to really cast light on the bounds we
have presented for A , one must be able to furnish a heuristic with known approximation guarantees.
7.1 A Search for Knapsack
We begin with describing a family of experimental results for A search coupled with approximate
heuristics for solving the Knapsack problem. This problem has been extremely well-studied by a
wide variety of fields including finance, operations research, and cryptography (Kellerer, Pferschy,
& Pisinger, 2004). As the Knapsack problem is NP-hard (Karp, 1972), no efficient algorithm can
solve it exactly unless NP = P. Despite that, this problem admits an FPTAS (Vazirani, 2001, p.
70), an algorithm that will return an -approximation to the optimal solution in time polynomial in
both 1/ and the input size. We use this FPTAS to construct approximate admissible heuristics for
the A search, which yields an exact algorithm for Knapsack that may expand far fewer nodes than
straightforward exhaustive search. (Indeed, the resulting algorithm is, in general, more efficient than
exhaustive search.)
7.1.1 A Search Model for Knapsack
Consider a Knapsack instance given by n items, and let [n] = {1, . . . , n}. Each item i  [n] has
weight wi > 0 and profit pi > 0. The knapsack has capacity c > 0. The task is to find a set of items
with maximal total profit such that its total weight is at most c. This Knapsack instance will be
denoted as a tuple h[n], p, w, ci. The Knapsack instance restricted to a subset X  [n] is denoted
hX, p, w, ci. For each subset X  [n], we will let w(X) P
and p(X) denote the P
total weight and the
total profit, respectively, of all items in X, i.e., w(X) = iX wi and p(X) = iX pi .
Search Space. We represent the Knapsack instance h[n], p, w, ci as a search space as follows. Each
state (or node) in the search space is a nonempty subset X  [n]. A move (or edge) from one state
X to another state is taken by removing an item from X. The cost of such a move is the profit of
the removed item. A state X  [n] is designated as a solution if w(X)  c. The initial state is the
set [n]. See Figure 2 for an example of the search space with n = 4.
This search space is an irregular directed graph whose out-degrees span in a wide range, from 2
to n  1. Moreover, for any two states X1 , X2 with X2  X1  [n], there are |X1 \ X2 |! paths on
this search graph from X1 to X2 . Moreover, every path from X1 to X2 has the same cost equal to
p(X1 )  p(X2 ). This feature of the search graph makes A behave like it does on a spanning subtree
of the graph: no state in this search graph will be reopened. Hence, for any state X  [n], the cost
703

fiDinh, Dinh, Michel, & Russell

{1, 2, 3, 4}

{1, 2, 3}

{1, 2}

{1, 2, 4}

{1, 3}

{1, 3, 4}

{1, 4}

{1}

{2, 3}

{2}

{2, 3, 4}

{2, 4}

{3}

{3, 4}

{4}

Figure 2: The search space for a Knapsack instance given by the set of 4 items {1, 2, 3, 4}. Solution
states and edge costs are not indicated in this figure.
of any path from the starting state to X is
g(X) = p([n] \ X) = p([n])  p(X) ,
and the cheapest cost to reach a solution from a state X  [n] is
h (X) = p(X)  Opt(X) ,
where Opt(X) is the total profit of an optimal solution to the Knapsack instance hX, p, w, ci, i.e.,
Opt(X) = max {p(X 0 ) | X 0  X and w(X 0 )  c} .
def

Observe that a solution state X   [n] on the search space h[n], p, w, ci is optimal if and only if
g(X  ) is minimal, or equivalently, p(X  ) is maximal, which means that X  is an optimal solution
to the Knapsack instance h[n], p, w, ci.
Heuristic Construction. Fix a constant   (0, 1). In order to prove the linear dependence of
log E on , we wish to have an efficient -accurate heuristic H on the aforementioned Knapsack
search space h[n], p, w, ci. Moreover, in order to guarantee that the solution returned by the A
search is optimal, we insist that H be admissible, so H must satisfy:
(1  )h (X)  H (X)  h (X) X  [n] .
The main ingredient for constructing such a heuristic is an FPTAS described in the book of Vazirani
(2001, p. 70). This FPTAS is an algorithm, denoted A, that returns a solution with total
 profit
at least (1  )Opt(X) to each Knapsack instance hX, p, w, ci and runs in time O |X|3 / , for any
  (0, 1). For each nonempty subset X  [n], let A (X) denote the total profit of the solution
returned by algorithm A with error parameter  to the Knapsack instance hX, p, w, ci. Then we
have for any   (0, 1),
(1  )Opt(X)  A (X)  Opt(X) ,
which implies
p(X) 

A (X)
 h (X)  p(X)  A (X) .
1

(11)

 (X)
Thus we may work with the heuristic H (X) = p(X)  A1
, which guarantees admissibility.
However, this definition of H does not guarantee -approximation for H : with this definition, the
condition (1  )h (X)  H (X) is equivalent to

(1  )h (X)  p(X) 
704

A (X)
,
1

(12)

fiThe Time Complexity of A with Approximate Heuristics

which does not always hold. Since h (X)  p(X)  A (X), the condition of (12) will be satisfied if
(1  )(p(X)  A (X))  p(X) 

A (X)
.
1

(13)

 (X)
if Equation (13) holds. Otherwise, we will define
Hence, we will define H (X) = p(X)  A1
H (X) differently, still ensuring that it is -approximate and admissible. Note that if X is not a
solution, at least one item in X must be removed in order to reach a solution contained in X, thus
h (X) = p(X)  Opt(X)  m, where m is the smallest profit of all items. This gives another option
to define H (X) that will guarantee the admissibility. In summary, we define the heuristic function
H as follows: for all non-solution state X,
(
 (X)
if (13) holds
p(X)  A1
def
(14)
H (X) =
m
otherwise,

where  will be determined later so that H is -approximate. If X is a solution, we simply set
H (X) = 0, because h (X) = 0 in this case. Then H is admissible, regardless of .
To make sure that H is -approximate, it remains to consider the case when (13) does not hold,
 (X)
i.e., p(X)  A1
< (1  )(p(X)  A (X)), for any non-solution state X. In such a case, we have
p(X)  A (X) 



A (X) 
(p([n])  m) .
(1  )
(1  )

(15)

The last inequality is due to the assumption that X is not a solution. Now we want to choose  such
that

m
(p([n])  m) 
(16)
(1  )
1
which, combining with (11) and (15), will imply (1  )h (X)  m = H (X). Therefore, we will
choose  such that

1 = 1 +  1  1 (p([n])/m  1) .

3 1
Since the running time to
compute
A
(X)
is
O
|X|

, the running time to compute H (X)


3 1
will be O |X|  p([n])/m , which is polynomial in both n and  1 if all the profits are bounded
some range [m, poly(n)m]. The A search using the heuristic H for the given Knapsack space
h[n], p, w, ci is described in Algorithm 3 below.
7.1.2 Experiments
In order to avoid easy instances, we focus on two families of Knapsack instances identified and studied
by Pisinger (2005) that are difficult for existing exact algorithms, including dynamic programming
algorithms and branch-and-bound algorithms:
Strongly Correlated: For each item i  [n], choose its weight wi as a random integer in the
range [1, R] and set its profit pi = wi + R/10. This correlation between weights and profits
reflects a real-life situation where the profit of an item is proportional to its weight plus some
fixed charge.
Subset Sum: For each item i  [n], choose its weight wi as a random integer in the range [1, R]
and set its profit pi = wi . Knapsack instances of this type are instances of the subset sum
problem.
For our tests
P we set the data range parameter R := 1000 and choose the knapsack capacity as
c = (t/101) i[n] wi , where t is a random3 integer in the range [30, 70].
3. In the paper of Pisinger (2005), t is a fixed integer between 1 and 100, and the average runtime of all tests
corresponding to all values of t was reported.

705

fiDinh, Dinh, Michel, & Russell

Algorithm 3 A Search for Knapsack
Input: hn, p, w, c, i; where n is the number of items, pi and wi are the profit and weight of item
i  [n], c is the capacity of the knapsack, and   (0, 1) is an error parameter for the heuristic.
Oracle: The FPTAS algorithm A for the Knapsack problem
(2001, p. 70).
P described by Vazirani
P
Notation: For each subset X  [n] of items, let p(X) = iX pi , w(X) = iX wi .
Output: a subset X   [n] of items such that w(X  )  c and p(X  ) is maximal.
1. Put the start node [n] on Open. Let m = min1in pi . Set  such that

1 = 1 +  1  1 (p([n])/m  1) .
2. Repeat until Open is empty:
(a) Remove from Open and place on Closed a node X for which g(X) + h(X) is minimum.
(b) If w(X)  c, exit with success and return X, an optimal solution.
(c) Otherwise, expand X: For each item i  X, let X 0 = X \ {i},
i. If X 0 is not on Open or Closed, set g(X 0 ) := g(X) + p(i) = p([n])  p(X 0 ), and
compute the heuristic h(X 0 ) as follows:
A. If X 0 is a solution, set h(X 0 ) := 0.
B. Otherwise, run algorithm A on the Knapsack input hX 0 , p, w, ci with error parameter , and let A(X 0 ) denote the total profit of the solution returned by algorithm
A. Then set
(
0
0
)
)
0
0
if p(X 0 )  A(X
p(X 0 )  A(X
0
1
1  (1  )(p(X )  A(X ))
h(X ) :=
m
otherwise.
Then put X 0 to Open with pointer back to X.
ii. Otherwise (X 0 is on Open or Closed, so g(X 0 ) has been calculated), if g(X)+p(i) <
g(X 0 ), direct the pointer of X 0 back to X and reopen X 0 if it is in Closed.
[Remark: Since all paths from the starting node to X 0 have the same cost, the
condition g(X) + p(i) < g(X 0 ) never holds. In fact, this step can be discarded.]
3. Exit with failure.

706

fiThe Time Complexity of A with Approximate Heuristics

After generating a Knapsack instance h[n], p, w, ci of either type described above, we run a series
of the A search using the given heuristic H , with various values of , as well as breath first search
(BFS), to solve the Knapsack instance. When each search finishes, the values of E and d are reported,
where E is the number of nodes (states) expanded by the search, and d is the depth of the optimal
solution found by the search. In this Knapsack search space, k equals the number of items removed
from the original set [n] to obtain the optimal solution found by the search. The overall runtime for
each search, including the time for computing the heuristic, is also reported. In addition, we report
the optimal value h ([n]) and the minimal edge cost m (i.e., minimal profit) of the search space for
each Knapsack instance tested.
To specify appropriate size n for each Knapsack instance type, we ran a few exploratory experiments and identified the largest possible value of n for which most search instances would finish
within a few hours. Then we chose those values of n (n = 23 for the Strongly Correlated type, and
n = 20 for the Subset Sum type) for our final experiments. Observing that the optimal solution
depths resulted from Knapsack instances of these sizes are fairly small, ranging from 5 to 15, we
selected sample points for  in the high interval [0.5, 1) with a distance between two consecutive
points large enough so that the sensitiveness of E to  can be seen. In particular, we selected eight
sample points for  from 8/16 = 0.5 to 15/16 = 0.9375 with the distance of 1/16 = 0.0625 between
two consecutive points. In our final experiments, we generated 20 Knapsack instances of each type
with the selected parameters for n and .
Experimental Results. Results for our final experiments are shown in Tables 1, 2, 3, 4, 5, and 6,
in which the rows corresponding to breath first search are indicated with BFS under the column
of . These data show, as expected, that A search outperforms breath first search in terms of
the number of nodes expanded and, naturally, that the smaller , the fewer nodes A expands. As
a result, the effective branching factor of A will decrease as  decreases (as long as all optimal
solutions in the given search space are located at the same depth). Recall that if A expands E
nodes and finds a solution at depth d, then its effective branching factor is the branching factor of a
uniform tree of depth d and E nodes (Russell & Norvig, 1995, p. 102), i.e., the number b satisfying
E = 1 + b + (b )2 +    + (b )d . Clearly, (b )d  E and, if b  2, we have E  2(b )d . As we shall
focus solely on values of b  2, we simply use E 1/d as a proxy for effective branching factor, content
that this differs from the actually quantity by a factor no more than 21/d . (Of course, as b grows
this error decays even further). The effective branching factors, calculated as E 1/d , of A search
and breath first search for Knapsack instances of type Strongly Correlated are shown in Tables 1,
2, and 3. Note that for Knapsack instances of the Subset Sum type, one cannot directly compare
effective branching factors, as the optimal solutions found by different search instances can appear
at different depths.
Our primary goal in these experiments is to investigate the proposed linear dependence which,
in this case of non-uniform branching factors and non-uniform edge costs, we may express
log E  d log bBFS +  ,

(17)

where d is the average optimal solution depth, bBFS is the effective branching factor of breath first
search, and  is a constant not depending on . To examine to what extend our data supports
this hypothesis, we calculate the least-squares linear fit (or linear fit for short) of log E (for
each Knapsack instance, varying ) using the least-squares linear regression model, and measure
the coefficient of determination R2 . In our experiments, 17 out of 20 Knapsack instances of type
Strongly Correlated and all 20 Knapsack instances of type Subset Sum have the R2 value at least
0.9. For these instances, over 90% of the variation in log E depends linearly on , a remarkable fit.
See Figure 5 for detailed histograms of R2 values for our Knapsack instances. The median R2 is
0.9534 for Knapsack instances of type Strongly Correlated, and is 0.9797 for those of type Subset
Sum. Graphs of log E and its linear fit for Knapsack instances with the median R2 among those of
the same type are shown in Figures 3 and 4. Note that as there are an even number of instances of
707

fiDinh, Dinh, Michel, & Russell

each type, there is no single instance with the median value. The instances shown in these graphs
actually have the R2 value below the median.
Knapsack instance of type Strongly Correlated with median R2
Instance 17
Linear fit
BFS

log10 E

6
5
4
3
2
0.5

0.6

0.7
0.8
0.9
Heuristic error 

1

Figure 3: Graph of log10 E and its least-squares linear fit for the Knapsack instance of type Strongly
Correlated with the median R2 (see data in Table 3).

Knapsack instance of type Subset Sum with median R2
5.3

Instance 14
Linear fit
BFS

log10 E

5.25

5.2

5.15
0.5

0.6

0.7
0.8
0.9
Heuristic error 

1

Figure 4: Graph of log10 E and its least-squares linear fit for the Knapsack instance of type Subset
Sum with the median R2 (see data in Table 5).

Remark Of course, there may be instances that poorly fit our prediction of linear dependence, such
as instance #20 of Strongly Correlated type whose R2 value is only 0.486, though those instances
708

fiThe Time Complexity of A with Approximate Heuristics

rarely show up in our experiments. In such an instance, the A search using heuristic function H
may explore even fewer nodes than the A search using H does, for some small  > 0. This
phenomenon can be explained by the degree to which we can control the accuracy of our heuristic
function H . In particular, we can only guarantee that H is admissible and -approximate, while
in reality it may provide an approximation better than  to all nodes that are opened. Note that H
is not proportional to (1  ). Hence, H may be occasionally more accurate than H for some
small  > 0, resulting in fewer nodes expanded.

Frequency

Histograms of R2 values for Knapsack instance families
Strongly correlated
Subset Sum

10

5

[0.97, )

[0.93, )

[0.90, )

[0.87, )

[0.83, )

[0.80, )

[0.77, )

[0.73, )

[0.70, )

[0.67, )

[0.63, )

[0.60, )

[0.57, )

[0.53, )

[0.50, )

[0.47, )

[0.43, )

[0.40, )

0

R2 value bin limits
Figure 5: Histograms of the R2 values for Knapsack instances.
To analyze more deeply how our data fit the model of Equation (17), we calculate the slope of
the least-squares linear fit of log10 E for each Knapsack instance of type Strongly Correlated. Note
that for such an instance, every search has the same optimal solution depth, denoted d, and thus,
d = d. Our data, given in Figure 6, show that for all but one instance with the worst R2 value, the
slope a of the linear fit of log10 E is fairly close to d log10 bBFS , which is the slope of the hypothesized
line given in Equation (17). Specifically, for any Knapsack instance of type Strongly Correlated,
except instance #20,
0.73d log10 bBFS  a  1.63d log10 bBFS .

7.2 A Search for Partial Latin Square Completion
The experimental results discussed above for the Knapsack problem support the hypothesis of linear
scaling (cf., Equation (1) or (10)). However, several structural features of the search space and
heuristic are unknown: for example, we cannot rule out the possibility that the approximation
algorithm, when asked to produce an -approximation, does not in fact produce a significantly
better approximation; likewise, we have no explicit control on the number of near-optimal solutions.
In order to explore the hypothesis in more detail, we experimentally and analytically investigate a
search space for the partial Latin square completion problem in which we can provide precise analytic
control of heuristic error  as well as the number of -optimal solutions N .
7.2.1 The Partial Latin Square completion (PLS) Problem
A Latin square of order n is an n  n table in which each row and column is a permutation of the
set [n] = {1, . . . , n}. If only a few cells in an n  n table are filled with values from [n] in such a
709

fiDinh, Dinh, Michel, & Russell

Knapsack instance type: Strongly Correlated
Instance
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

Optimal
solution
depth d
11
9
6
7
7
6
7
8
6
9
7
5
7
5
6
9
7
8
7
7

Effective branching
factor of breath first
search bBFS
4.2092
5.3928
10.8551
8.2380
8.0194
10.6780
8.7068
6.7742
11.4102
5.5412
8.3260
18.0486
8.0308
15.0964
10.0070
5.7863
8.3155
6.9106
8.3602
7.0964

Slope
of
linear fit a

a/(d log10 bBFS )

Coefficient of
determination R2

7.6583
4.8966
10.1038
6.4279
5.0882
6.4511
7.9087
6.5616
8.6847
6.3690
9.7685
7.7848
6.0376
7.3004
4.4219
7.1815
9.1738
9.2837
7.1807
1.0055

1.1154
0.7435
1.6260
1.0027
0.8040
1.0454
1.2021
0.9872
1.3690
0.9517
1.5161
1.2392
0.9533
1.2385
0.7368
1.0466
1.4247
1.3823
1.1123
0.1688

0.9395
0.9183
0.9647
0.9710
0.9161
0.9696
0.9436
0.9782
0.9571
0.9461
0.9689
0.9314
0.9646
0.9676
0.8788
0.8698
0.9498
0.9729
0.9770
0.4860

Figure 6: Slopes of the least-squares linear fits of log10 E (varying ) for the Knapsack instances of
type Strongly Correlated. Details of these least-squares linear fits are given in Tables 1, 2, and 3.
The R2 values for these Knapsack instances are also included in this figure.
way that no value appears twice in a single row or column, then the table is called a partial Latin
square. A completion of a partial Latin square L is a Latin square that can be obtained by filling
the empty cells in L, see Figure 7 for an example. Note that not every partial Latin square has a
completion. Since the problem of determining whether a partial Latin square has a completion is
NP-complete (Colbourn, 1984), its search version (denoted PLS), i.e., given a partial Latin square
L find a completion of L if one exists, is NP-hard.
1

2
5

3
1
4

1
2

1
2
3
4
5

4
3

2
3
5
1
4

3
5
4
2
1

4
1
2
5
3

5
4
1
3
2

Figure 7: A 5  5 partial Latin square (right) and its unique completion (left).
The PLS problem (also known as partial quasi-group completion) has been used in the recent
past as a source of benchmarks for the evaluation of search techniques in constraint satisfaction
and Boolean satisfiability (Gomes & Shmoys, 2002). Indeed, partially filled Latin squares carry
embedded structures that are the trademark of real-life applications in scheduling and time-tabling.
Furthermore, hard instances of the partially filled Latin square trigger heavy-tail behaviors in
backtrack search algorithms which are common-place in real-life applications and require randomization and or restarting (Gomes, Selman, & Kautz, 1998). Additionally, the PLS problem exhibits
a strong phase transition phenomena at the satisfiable/unsatisfiable boundary (when 42% of the
cells are filled) which can be exploited to produce hard instances. We remark that the underlying
710

fiThe Time Complexity of A with Approximate Heuristics

structure of Latin squares can be found in other real-word applications including scheduling, timetabling (Tay, 1996), error-correcting code design, psychological experiments design and wavelength
routing in fiber optics networks (Laywine & Mullen, 1998; Kumar, Russell, & Sundaram, 1996).
7.2.2 A Search Model for PLS
Fix a partial Latin square L of order n with c > 0 completions. We divide the cells of the n  n table
into two types: the black cells, those that have been filled in L, and the white cells, those that are
left blank in L. Let k be the number of white cells. The white cells are indexed from 0 to k  1 in a
fixed order, e.g., left to right and top to bottom of the table. The task of A search now is to find a
completion of L. Hard instances are obtained when the white cells are uniformly distributed within
every row and every column and when the density of black cells is (n2  k)/n2  42% to tap into
the phase transition. We further insure that the number of completions is c = O(1) (c is exactly 1
for the experiments).
To structure the search space for this problem, we place the white cells on a virtual circle so that
the white cells of index i and (i + 1) mod k are adjacent. We can move along the circle, each step is
either forward (from a white cell of index i to the cell of index (i + 1) mod k) or backward (from a
white cell of index i to the cell of index (i  1) mod k) and may set the content of the current cell.
Formally, we define the search graph, denoted GL , for the PLS instance given by L as follows: Each
state (or node) of GL is a pair (, p), in which p  {0, . . . k  1} indicates the index of the current
white cell, and  : {0, . . . , k  1}  {0, . . . , n} is a function representing the current assignment of
values to the white cells (we adopt the convention that (j) = 0 means the white cell of index j
has not been filled). There is a directed link (or edge) from state (, p) to state (, q) in the search
graph GL if and only if q = (p  1) mod k, (q)6= 0, and (j) = (j) for all j 6= q. In other words,
the link from state (, p) to state (, q) represents the step consisting of moving from the white
cell of index p to the white cell of index q, and setting the value (q) to the white cell of index q.
Figure 8 illustrates the links from one state to another in GL . The cost of every link in GL is a unit.
Obviously, this search graph is regular and has (out-)degree of 2n.
The starting state is (0 , 0) where 0 (j) = 0 for all j. A goal state (or solution) is of the form
( , p), where  is the assignment corresponding to a completion of L, and p  {0, . . . , k  1}. So,
a solution on the cover tree of GL is a path in the search graph GL from the starting state to a
goal state, and the length of an optimal solution is equal to k. We will show that the number of
-optimal solutions in the cover tree of GL is not too large.
Lemma 7.1. Let L be an n  n partial Latin square with k white cells. Let  be the assignment
corresponding to a completion of L. For any 0  t < k, the number of paths
 of length k + t in GL

from the starting state to a goal state of the form ( , ) is no more than 2 t + 2 + t k+t
nt .
t
Proof. We represent a path in GL of length k + t from the starting state as a pair hP, ~v i, in which
P is a (k + t)-length path in the circle of white cells starting from the white cell of index 0, and
~v = (v1 , . . . , vk+t ) is a sequence of values in [n] with vi being the value assigned to the white cell
visited at the ith step of the path P . Consider a pair hP, ~v i that represents a path in GL ending up at
a goal state ( , ). Since  (j) 6= 0 for all j, every white cell must be visited at some non-zero step
of P . Let sj > 0 be the last step at which the white cell of index j is visited. Then we must have
vsj =  (j) for all j  {0, . . . , k  1}. Given such a path P , there are nt ways of assigning values to
the white cells in order to eventually obtain the assignment  . Thus, the number of (k + t)-length
paths in GL from the starting state to a goal state ( , ) is equal to |Pt |nt , where Pt is the set of
(k + t)-length paths on the circle of white cells that start at white cell of index 0 and visit every
white cell.
It remains to upper bound |Pt |. Consider a path P  Pt ; our strategy is to bound the number of
backward (or forward) steps in P . As t < k, there are at least k  t  1 white cells visited exactly
711

fiDinh, Dinh, Michel, & Russell

0

k1

5

k2

2

1

4

2

3

3

1
0

k1

5

k2

2

1

4

3

1, v
h

2

3

4

i

3

2

3

2

2

3

5

1

5

5

2

1

0

k1
k2

5

5
3

p

4
2

p

4

1

1

p1

v

4

3

h+

1, v
i

1

4

2

3

4

1

1

3

p

v

2

p+1

2

5
3

5

1

Figure 8: The links connecting states in a PLS search graph. The label h+1, vi (resp., h1, vi) on
the links means moving forward (resp., backward) and setting value v  [n] to the next white cell.

once in P . Let w be the index of a white cell that is visited exactly once in P and let s be the step
at which the white cell w is visited.
Assume the step s is a forward step, i.e., the white cell visited at step s  1 is (w  1) mod k.
Let w0 be the farthest white cell from w in the backward direction that is visited before step s.
Precisely, w0 = (w  `) mod k, where ` is the maximal number in {0, . . . , k  1} for which the white
cell (w  `) mod k is visited before step s. Let wj = (w0 + j) mod k, for j = 0, . . . , k  1. Note that
w` = w. Then the set of white cells visited at the first s steps is {w0 , w1 , . . . , w` }, and by deleting
some steps among the first s steps in P we will obtain the path (w0 , w1 , . . . , w` ) from w0 to w` in
the forward direction. Each of the white cells w`+1 , . . . , wk1 must be visited at a step after step
s and also in the forward direction because the white cell w` is visited only once and at a forward
step. Thus, by deleting t steps from P we obtain a path visiting the white cells w0 , w1 , . . . , wk1 in
the forward direction. Let s0 , . . . , sk1 be the steps in P that are not deleted, where wj is visited
at step sj in P , and 1  s0 < s1 < . . . < sk1  k + t. Then steps s1 , . . . , sk1 are all forward steps
(step s0 can be forward or backward). Moreover, the number of backward steps and the number of
forward steps between sj1 and sj must be equal for all j = 1, . . . , k  1. Let  be the number of
deleted steps before s0 and after sk1 so that there are exactly (t  )/2 backward steps between
s0 and sk . This shows there are at most
 + 1 + (t  )/2 = 1 + (t + )/2  t + 1 backward steps

in P . Note that there at most k+t
paths in Pt that have exactly j backward steps. Path P has
j
t + 1 backward steps only when  = t (and thus sj = sj1 + 1 for all j = 1, . . . , k  1) and every
step from 1 to s0 and after sk1 is backward. There are t + 1 such paths in Pt , each corresponding
to a choice of s0  {1, . . . , t + 1}.
Similarly, if the step s is a backward step, then there are at most t + 1 forwardsteps in P . Also,
there are t + 1 paths in Pt that have exactly t + 1 forward steps, and at most k+t
paths in Pt that
j
712

fiThe Time Complexity of A with Approximate Heuristics

have exactly j forward steps. Hence,

|Pt |  2 t + 1 +


t 
X
k+t
j=0

The last inequality holds since the coefficient

j






2 t+2+t k+t
.
t

k+t
j



increases as j increases for j < (k + t)/2.

The upper bound in Lemma 7.1 is achieved when t = 0. In fact, there are four ways to visit
every white cell in k steps starting from the white cell 0: taking either k forward steps or k backward
steps or one backward step followed by k  1 forward steps or one forward steps followed by k  1
backward steps. So the number of optimal solutions in the cover tree of GL is equal to 4c, since
there are c completions of the initial partial Latin square.
Theorem 7.1. Let L be an n  n partial Latin square with k white cells and c completions. For
any 0 <  < 1, the number of nodes expanded by A search on GL with a -accurate heuristic is no
more than B(), where
B() =

(
2(2n)k + 4ck 
2(2n)

k

if k < 1 ,

+ 4ck bkc + 2 + bkc

k+bkc
bkc



n

bkc

if k  1 .

Proof. By Lemma 3.1, the number of nodes expanded by A search on GL with a -accurate heuristic
is upper-bounded by 2(2n)k + kN , where N is the number of -optimal solutions in the cover tree
of GL . So, we only need to bound N .
If k < 1, then N equals the number of optimal solutions, which implies the upper bound of
2(2n)k + 4ck on the number of expanded nodes by A .
In the general case, let ` = bkc. Since k < k, by Lemma 7.1, we have



`
X
k+t
2 t+2+t
nt
t
t=0
!

 X
`
`
X
k+`
t
t
 2c
(t + 2)n + 2c
tn
`
t=0
t=0


k+`
`
 4c(` + 2)n + 4c
`n` .
`

N  c



The second inequality holds because k+t
 k+`
for all t  `. The last inequality is obtained by
t
`
P`
P`
t
`
applying the fact that t=0 tn  2`n and t=0 nt  2n` for all integers n  2 and `  0, which
can be proved easily by induction on `. Hence, the number of nodes expanded by A is no more
than



k+`
2(2n)k + 4ck ` + 2 + `
n` .
`

Corollary 7.1. Suppose 0 <  < 1. Then the number of nodes expanded by A search on GL with
a -accurate heuristic is


k
k
O k 3/2 (1 + ) (1 + 1/) nk .

Proof. By Theorem 7.1, all we need is an upper bound on the binomial coefficient k+`
for large k,
`
where ` = bkc. Since both k and ` are large, we will bound this binomial coefficient using Stirlings
713

fiDinh, Dinh, Michel, & Russell



n
formula, which asserts that n!  2n ne . More precisely, write n! = 2n
as n  . We have


k+`
(k + `)!
=
`
k!`!
p
k+`
2(k + `) k+`
k+`
e
=


`
k
2k ke k  2` e` `

k + ` (k + `)k+`
k+`

.
 
=
k `
k k ``
2k`


n n
e

n , then n  1

By Stirlings formula, the term k+` /k ` is O(1). Since
k+`
k
k
=1+
1+
 1 + 2/
`
bkc
k  1



for k > 2/, the term k + `/ 2k` is O(1/ k). The remaining term is
(k + `)k+`
=
k k ``


k 
`

k
`
k
1
k
1+
1+
 (1 + ) 1 +
k
`

x

since `  k and the function g(x) = (1 + k/x) monotonically increases for x > 0. Hence,



k !
k+`
1
1
= O  (1 + )k 1 +
.
`

k
From Theorem 7.1, the number of nodes expanded by A is no more than
 
 
k + ` k
B() = 2(2n)k + O k 2
n
`
!

k
1
3/2
k
k
= O k (1 + ) 1 +
n
.


It follows from the above corollary that the effective branching factor of A using a -accurate

heuristic on GL is asymptotically at most (1 + ) (1 + 1/) n , which is significantly smaller than

the brute-force branching factor of 2n, since both (1 + )n and (1 + 1/) converge to 1 as   0.
7.2.3 Experiments
Given the search model for the PLS problem described above, we provide experimental results of
A search on a few PLS instances, each of which is determined by a large partial Latin square with
a single completion. For each PLS instance in our experiments, we run A search with different
heuristics of the form (1  )h given by various values of   [0, 1). We emphasize that by the dominance property of admissible heuristics, the number of nodes expanded by A using any admissible
-accurate heuristic strictly larger than (1  )h is less than or equal to that by the A using the
heuristic (1  )h . In other words, the heuristic (1  )h is worse than most admissible -accurate
heuristics.
To build the oracle for the heuristic (1  )h on a search graph GL , we use the information
about the completion of the partial Latin square L to compute h . Consider a partial Latin square
L with k white cells, and an arbitrary state (, p) in GL . We will show how to compute the optimal
714

fiThe Time Complexity of A with Approximate Heuristics

cost h (, p) to reach a goal state in GL from state (, p). Let X() be the set of white cells at
which  disagrees with the completion of L, then h (, p) is equal to the length of the shortest
paths on the cycle starting from p and then visiting every point in X(). The case in which
|X() \ {p} |  1 is easy to handle, so we shall assume |X() \ {p} |  2 from now on. In particular,
suppose X() \ {p} = {p1 , . . . , p` } with ` > 1, where pj is the j th point in X() \ {p} that is visited
when moving forward (clockwise) from p; see Figure 9. There are two types of paths on the cycle
starting from p and visiting every point in X() \ {p}: type I includes those that do not visit p, type
II includes those visiting p. Let `1 and `2 be the length of the shortest paths of type I and type II,
respectively. Then
(
min {`1 , `2 }
if p 6 X() ,

h (, p) =
min {`1 + 2, `2 } if p  X() .
So now we only need to compute `1 and `2 . Computing `1 is straightforward: it is realized by either
moving forward from p to p` or moving backward from p to p1 . That is
`1 = min {p`  p, p  p1 }
def

where z = z mod k for any integer z. To compute `2 , we consider two options for each j: option
(a) moving forward from p to pj and then moving backward from pj to pj+1 , option (b) moving
backward from p to pj+1 and then moving forward from pj+1 to pj . Thus,


`2 = min min {pj  p, p  pj+1 } + pj  pj+1 .
1j<`

moving forward
p1

p

p+1

p1

pm

p2

pm1
pj+1

pj

Figure 9: Layout of the points in X().
Now we describe our experiments in detail. We generate six partial Latin squares with orders
from 10 to 20 in the following way. Initially, we generate several partial Latin squares obtained at or
near the phase transition with white cells uniformly distributed within every row and column. Each
instance is generated from a complete Latin square with a suitably chosen random subsets of its
cells cleared. Each candidate partial Latin square is solved again with an exhaustive backtracking
search method to find all completions. The subset of candidates with exactly one completion is
retained for the experiments. For each partial Latin square L and each chosen value of , we record
the total number E of nodes expanded by A on the search graph GL with the (1  )h heuristic.
Then, as in the Knapsack experiments, the effective branching factor of A is calculated as E 1/k ,
since the optimal solution depth in GL equals the number of white cells in L. Our first purpose is to
compare these effective branching factors obtained from experiments to our upper bound obtained
715

fiDinh, Dinh, Michel, & Russell

from theoretical analysis. Recall from Theorem 7.1 that E  B(), where in this case
B() =

(
2(2n)k + 4k 
2(2n)

k

if k < 1 ,

+ 4k bkc + 2 + bkc

k+bkc
bkc



n

bkc

if k  1 .

1/k

Therefore, we calculate the theoretical upper bound B()
on the effective branching factor E 1/k .
1/k
For deeper comparison, we calculate the multiplicative gap B() /E 1/k between our theoretical
bound and the actual values. In our empirical results given in Tables 7 and 8, these multiplicative
gaps are close to 1 when  is small and k is large. Notice that for each given k, the upper bounds
of B() are almost the same for the s with the same value of bkc. This is why the multiplicative
gaps for those s sometimes increase when  decrease. However, the multiplicative gaps decrease
as bkc decreases, for each fixed k. Our upper bounds in the cases with k < 1 are much tighter
than in the others (with the same k) because in the cases of k < 1 we can compute the number of
-optimal solutions exactly. Also observe that, for each fixed , the multiplicative gaps decrease as k
increases. Finally, the experiments show a dramatic gap between the effective branching factors and
the corresponding brute-force branching factor, which equals 2n. In fact, for each instance, both the
1/k
effective branching factor E 1/k and our theoretical upper bound B()
approach 1 as  approaches
0.
As in the experiments for the Knapsack problem, our data for the partial Latin square problem
also support the linear dependance of log E on . In particular, all but one partial Latin square
instances have the R2 larger than 0.9 (the worst one has R2 value equal to 0.8698). The median R2
value for our partial Latin square instances is 0.9304. The graph for the instance with the median
R2 is shown in Figure 10.
Partial Latin Square instance with median R2
Instance 4
Linear fit

6

log10 E

5
4
3
2
0

0.5

1
1.5
2
Heuristic error 

2.5

3
102

Figure 10: Graph of log10 E and its least-squares least-squares linear fit (or Linear fit) for the
partial Latin square instance with the median R2 (see data in Table 8).
We also investigate how the slope of the least-squares linear fit of log E approximates the slope
of d log b in the hypothesized linear dependence of Equation (10). Recall that in this case, the
branching factor is b = 2n and the optimal solution depth is d = k. Figure 11 shows that, for every
PLS instance in our experiment, the slope  of the least-squares linear fit of log10 E approximates
716

fiThe Time Complexity of A with Approximate Heuristics

to k log10 (2n) by a factor of 0.8, i.e.,   0.8k log10 (2n). In other words, our experimental results
for the PLS indicate the following relationship:
log10 E    0.8k log10 (2n) +  ,

or equivalently, E  (2n)0.8k .

Thus, empirically, the effective branching factor of A search using the heuristic (1)h on the given
PLS search space approximates to (2n)0.8 . By the dominance property of admissible heuristics,
this is also an empirical upper bound on the effective branching factor of A using any admissible
-accurate on the same search space.
Instance #

n

k

1
2
3
4
5
6

10
12
14
16
18
20

44
63
86
113
143
176

Slope of linear
fit line 
43.3901
73.7527
98.3613
142.7056
179.1665
225.4152

/(k log10 (2n))
0.7580
0.8482
0.7903
0.8390
0.8050
0.7995

Figure 11: Slopes of the least-squares linear fits of log10 E for the partial Latin square instances.

8. Reduction in Depth vs. Branching Factor; Comparison with Previous
Work
In this section we compare our results with those obtained by Korf et al. (Korf & Reid, 1998; Korf
et al., 2001). As mentioned in the introduction, they concluded that the effect of a heuristic function
is to reduce the effective depth of a search rather than the effective branching factor. Considering
the striking qualitative difference between their findings and ours, it seems interesting to discuss
why their conclusions do not apply to accurate heuristics.
They study the b-ary tree search model, as above, and permit multiple solutions. However, their
analysis depends critically on the following equilibrium assumption:
Equilibrium Assumption: The number of nodes at depth i with heuristic value not exceeding `
is bi P (`), where P (`) is the probability that h(v)  ` when v is chosen uniformly at random among
all nodes of given depth, in the limit of large depth.
We remark that while the equilibrium assumption is a strong structural requirement, it holds in
expectation for a rich class of symmetric search spaces. To be specific, for any state-transitive
search space,4 like the Rubiks cube, the quantity bi P (`) is precisely the expected number of vertices
at depth i with h(v)  ` if the goal state (or initial state) is chosen uniformly at random. Korf
et al. (2001) observe that under the equilibrium assumption, one can directly control the number
of expanded
P nodes of total weight no more than `, a quantity we denote E(`): indeed, in this case
E(`) = i` bi P (`  i). With this in hand, they consider the ratio
P`
P`
i
bi1 P (`  i)
E(`)
i=0 b P (`  i)
= P`1
= b  Pi=0
 b,
(18)
`
i
i1 P (`  i)
E(`  1)
i=0 b P (`  1  i)
i=1 b
and conclude that E(d)  bd1 E(1); thus the effective branching factor is
q
p
d
bd1 E(1)  b d E(1)
4. We say that a search space is state-transitive if the structure of the search graph is independent of the starting
node. Note that any Cayley graph has this property, so natural search spaces formed from algebraic problems
like the Rubiks cube or 15-puzzle, with the right choice of generators, have this property.

717

fiDinh, Dinh, Michel, & Russell

if the optimal solution lies at depth d.
A difficulty with this approach is that even in the presence of a mildly accurate heuristic satisfying, for example,
h(v)  h (v) for small, constant,  > 0 ,
the actual values of these quantities satisfy
E(1) = E(2) =    = E(t) = 0
for all t  d. (Even the root of the tree has h(root)    d.) Observe,
then, that 
if E(d) = 1 the
p
d
argument above actually results in an effective branching factor of d bdd E(d) = b(1)d = b1 ,
yielding reduction in the branching factor. Indeed, applying this technique to infer estimates on
the complexity of A , even assuming the equilibrium
P i assumption, appears to require control of
the threshold quantity `0 at which the quantities
b P (`0  i) become non-negligible. Of course,
the equilibrium assumption may well apply to heuristics with weaker or, for example, nonuniform
accuracy.
One perspective on this issue can be obtained by considering the case of search on a b-regular
(non-bipartite, connected) graph G = (V, E) and observing that the selection of a node uniformly
at random from all nodes of a given depth, in the limit of large depth is, in this case, equivalent
to selection of a random node in the graph. If we again consider a mildly accurate heuristic h for
which, say, h(v)  h (v) for a small constant , we have bi P (`)  bi Prv [  dist(v, S)  `], where v
is chosen uniformly at random in the graph, S is the set of solution nodes, and dist(v, S) denotes
the length of the shortest path from v to a node of S. As
|S|  b`
|{v | dist(v, S)  `/}|

Pr[dist(v, S)  `/] =
v
|V |
|V |

1

in any b-regular graph, we can only expect the relation of equation (18) to hold past the threshold
value `0   logb (|S|/|V |).

Acknowledgments
We wish to thank anonymous reviewers for their constructive comments. Author Hang Dinh was
supported by IU South Bend Faculty Research Grant. Author Laurent Michel was supported by
the NSF under grant #0642906. Author Alexander Russell was supported by the NSF under grant
#1117426.

718

fiThe Time Complexity of A with Approximate Heuristics

Appendix A: Tables of Experimental Results
#

n

Heuristic
error 

1

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

Total
node
expansions
E
5627
5882
167660
211946
772257
1470135
6118255
7154310
7347748

2

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

3

23
23
23
23
23
23
23
23
23

4

Optimal
solution
depth d

Search
time
(seconds)

11
11
11
11
11
11
11
11
11

125
101
858
744
1341
1318
2025
1653
1101

10887/200
10887/200
10887/200
10887/200
10887/200
10887/200
10887/200
10887/200

44481
45537
372163
474221
1358735
2508134
3508255
3569052
3857597

9
9
9
9
9
9
9
9
9

622
507
1497
1293
1751
1734
1469
1047
566

7820/157
7820/157
7820/157
7820/157
7820/157
7820/157
7820/157
7820/157

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

94
125
5528
9002
31800
109080
879884
1477032
1636093

6
6
6
6
6
6
6
6
6

6
7
98
105
206
301
707
560
224

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

3696
21847
44166
53464
253321
760792
1975195
2317663
2574876

7
7
7
7
7
7
7
7
7

5

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

23645
30501
72597
308417
968504
1681026
1833872
1833644
2132977

6

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

7

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

h ([n])/m

Effective
branching

d
factor
E
2.192473
2.201325
2.985026
3.049315
3.42966
3.636376
4.139674
4.198968
4.209164

log10 E

Linear
fit to
log10 E

3.7503
3.7695
5.2244
5.3262
5.8878
6.1674
6.7866
6.8546
6.8662

3.7956
4.2742
4.7529
5.2315
5.7102
6.1888
6.6674
7.1461

3.284459
3.293033
4.158822
4.272327
4.802412
5.140898
5.336203
5.3464
5.392783

4.6482
4.6584
5.5707
5.6760
6.1331
6.3994
6.5451
6.5526
6.5863

4.7018
5.0078
5.3139
5.6199
5.9259
6.2320
6.5380
6.8441

5991/121
5991/121
5991/121
5991/121
5991/121
5991/121
5991/121
5991/121

2.132331
2.236068
4.204955
4.560962
5.628654
6.912326
9.788983
10.671652
10.855121

1.9731
2.0969
3.7426
3.9543
4.5024
5.0377
5.9444
6.1694
6.2138

1.9674
2.5989
3.2304
3.8619
4.4934
5.1248
5.7563
6.3878

86
256
303
258
553
788
957
694
383

6343/154
6343/154
6343/154
6343/154
6343/154
6343/154
6343/154
6343/154

3.233523
4.16786
4.608759
4.73628
5.914977
6.921191
7.93182
8.115082
8.23801

3.5677
4.3394
4.6451
4.7281
5.4037
5.8813
6.2956
6.3651
6.4108

3.7471
4.1489
4.5506
4.9524
5.3541
5.7558
6.1576
6.5593

7
7
7
7
7
7
7
7
7

305
285
429
754
1074
1047
823
585
306

6785/205
6785/205
6785/205
6785/205
6785/205
6785/205
6785/205
6785/205

4.215217
4.371357
4.947855
6.083628
7.164029
7.751179
7.848145
7.848005
8.019382

4.3737
4.4843
4.8609
5.4891
5.9861
6.2256
6.2634
6.2633
6.3290

4.3803
4.6983
5.0163
5.3343
5.6523
5.9703
6.2883
6.6064

1981
12316
21699
26575
131561
395118
1080314
1282206
1482293

6
6
6
6
6
6
6
6
6

46
139
151
131
290
431
547
409
219

5012/148
5012/148
5012/148
5012/148
5012/148
5012/148
5012/148
5012/148

3.543894
4.80557
5.281289
5.462761
7.131615
8.566192
10.129585
10.423006
10.677978

3.2969
4.0905
4.3364
4.4245
5.1191
5.5967
6.0336
6.1080
6.1709

3.4645
3.8677
4.2709
4.6741
5.0773
5.4805
5.8837
6.2869

1834
1956
2039
23275
30974
173886
675468
3440759
3793204

7
7
7
7
7
7
7
7
7

51
43
36
159
138
332
526
984
568

6187/122
6187/122
6187/122
6187/122
6187/122
6187/122
6187/122
6187/122

2.925499
2.952538
2.970119
4.20573
4.380978
5.605434
6.80457
8.586333
8.706789

3.2634
3.2914
3.3094
4.3669
4.4910
5.2403
5.8296
6.5367
6.5790

2.8110
3.3053
3.7996
4.2939
4.7882
5.2825
5.7768
6.2711

R2

0.9395

0.9183

0.9647

0.9710

0.9161

0.9696

0.9436

Table 1: Results for the Knapsack instances of type Strongly Correlated.

719

fiDinh, Dinh, Michel, & Russell

#

n

Heuristic
error 

8

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

Total
node
expansions
E
8299
8741
58455
93500
216413
536713
2569955
4096150
4434697

9

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

10

23
23
23
23
23
23
23
23
23

11

Optimal
solution
depth d

Search
time
(seconds)

8
8
8
8
8
8
8
8
8

129
105
335
332
479
558
1066
1027
655

6400/153
6400/153
6400/153
6400/153
6400/153
6400/153
6400/153
6400/153

430
460
5313
9507
11268
88158
790402
2008558
2206805

6
6
6
6
6
6
6
6
6

19
16
84
91
75
229
646
673
334

5835/121
5835/121
5835/121
5835/121
5835/121
5835/121
5835/121
5835/121

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

14162
15321
178178
214332
872080
2128661
3942938
4543001
4924992

9
9
9
9
9
9
9
9
9

192
162
669
574
1052
1306
1379
1118
721

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

315
330
974
22374
26883
199464
783863
2579423
2773773

7
7
7
7
7
7
7
7
7

12

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

1029
1163
1310
3968
14820
75333
363263
1710935
1915195

13

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

14

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

h ([n])/m

Effective
branching

d
factor
E
3.089429
3.109533
3.943235
4.181686
4.644195
5.202568
6.327624
6.707288
6.7742

log10 E

Linear
fit to
log10 E

3.9190
3.9416
4.7668
4.9708
5.3353
5.7297
6.4099
6.6124
6.6469

3.7753
4.1854
4.5955
5.0056
5.4157
5.8258
6.2359
6.6460

2.747334
2.778388
4.177245
4.602643
4.734867
6.671297
9.615562
11.232611
11.410219

2.6335
2.6628
3.7253
3.9780
4.0518
4.9453
5.8978
6.3029
6.3438

2.3749
2.9177
3.4605
4.0033
4.5461
5.0889
5.6317
6.1745

6762/171
6762/171
6762/171
6762/171
6762/171
6762/171
6762/171
6762/171

2.892252
2.917641
3.832024
3.911497
4.571533
5.048042
5.405911
5.491674
5.541159

4.1511
4.1853
5.2509
5.3311
5.9406
6.3281
6.5958
6.6573
6.6924

4.1618
4.5599
4.9579
5.3560
5.7541
6.1521
6.5502
6.9482

19
15
29
232
195
514
751
880
406

6465/106
6465/106
6465/106
6465/106
6465/106
6465/106
6465/106
6465/106

2.274582
2.289748
2.672619
4.182076
4.293214
5.716412
6.950792
8.240087
8.326044

2.4983
2.5185
2.9886
4.3497
4.4295
5.2999
5.8942
6.4115
6.4431

2.1619
2.7724
3.3830
3.9935
4.6040
5.2146
5.8251
6.4356

5
5
5
5
5
5
5
5
5

35
29
25
50
92
212
380
589
283

5073/106
5073/106
5073/106
5073/106
5073/106
5073/106
5073/106
5073/106

4.003899
4.103136
4.201983
5.244624
6.826053
9.449244
12.943277
17.646017
18.048562

3.0124
3.0656
3.1173
3.5986
4.1708
4.8770
5.5602
6.2332
6.2822

2.5015
2.9880
3.4746
3.9611
4.4477
4.9342
5.4208
5.9073

6701
7084
43514
71911
85427
376321
1441947
1963475
2154280

7
7
7
7
7
7
7
7
7

154
127
379
383
313
573
862
655
324

6072/122
6072/122
6072/122
6072/122
6072/122
6072/122
6072/122
6072/122

3.520395
3.548459
4.598978
4.941148
5.064232
6.259049
7.583154
7.925079
8.030775

3.8261
3.8503
4.6386
4.8568
4.9316
5.5756
6.1589
6.2930
6.3333

3.6957
4.0730
4.4504
4.8277
5.2050
5.5824
5.9597
6.3371

418
3629
7016
8503
51480
178163
550403
668276
784088

5
5
5
5
5
5
5
5
5

15
63
74
62
162
258
352
246
110

4636/140
4636/140
4636/140
4636/140
4636/140
4636/140
4636/140
4636/140

3.343761
5.151781
5.877842
6.108217
8.756443
11.22441
14.064884
14.621475
15.096385

2.6212
3.5598
3.8461
3.9296
4.7116
5.2508
5.7407
5.8250
5.8944

2.8386
3.2949
3.7512
4.2075
4.6637
5.1200
5.5763
6.0326

R2

0.9782

0.9571

0.9461

0.9689

0.9314

0.9646

0.9676

Table 2: Results for the Knapsack instances of type Strongly Correlated.

720

fiThe Time Complexity of A with Approximate Heuristics

#

n

Heuristic
error 

15

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

Total
node
expansions
E
15713
17658
126261
172936
511397
809884
814774
814389
1004228

16

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

17

23
23
23
23
23
23
23
23
23

18

Optimal
solution
depth d

Search
time
(seconds)

6
6
6
6
6
6
6
6
6

218
184
536
466
647
600
435
291
140

5825/211
5825/211
5825/211
5825/211
5825/211
5825/211
5825/211
5825/211

1851
1870
2504
2551
22976
43228
267829
2798746
7270715

9
9
9
9
9
9
9
9
9

44
36
35
29
113
122
283
842
1104

7275/117
7275/117
7275/117
7275/117
7275/117
7275/117
7275/117
7275/117

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

656
665
711
17143
28608
190546
844063
2558990
2749381

7
7
7
7
7
7
7
7
7

33
26
21
192
194
514
813
895
405

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

683
772
18190
24869
136138
308550
2311528
4805568
5201719

8
8
8
8
8
8
8
8
8

19

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

2854
3140
11500
38170
51667
270043
1107776
2600747
2854529

20

23
23
23
23
23
23
23
23
23

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

158012
505837
589456
700571
682245
682583
682855
682455
906305

h ([n])/m

Effective
branching

d
factor
E
5.004682
5.102977
7.082907
7.464159
8.942515
9.654663
9.664355
9.663593
10.007034

log10 E

Linear
fit to
log10 E

4.1963
4.2469
5.1013
5.2379
5.7088
5.9084
5.9110
5.9108
6.0018

4.3104
4.5868
4.8631
5.1395
5.4159
5.6922
5.9686
6.2450

2.306987
2.309606
2.385756
2.390691
3.052011
3.274048
4.009547
5.203904
5.786254

3.2674
3.2718
3.3986
3.4067
4.3613
4.6358
5.4279
6.4470
6.8616

2.7061
3.1549
3.6038
4.0526
4.5015
4.9503
5.3992
5.8480

6501/102
6501/102
6501/102
6501/102
6501/102
6501/102
6501/102
6501/102

2.525892
2.530814
2.555112
4.025961
4.331527
5.679181
7.024655
8.23073
8.315545

2.8169
2.8228
2.8519
4.2341
4.4565
5.2800
5.9264
6.4081
6.4392

2.3428
2.9162
3.4895
4.0629
4.6363
5.2096
5.7830
6.3564

14
13
114
107
280
323
889
1083
790

6012/164
6012/164
6012/164
6012/164
6012/164
6012/164
6012/164
6012/164

2.261011
2.295896
3.407839
3.543703
4.382757
4.854737
6.244352
6.842552
6.910641

2.8344
2.8876
4.2598
4.3957
5.1340
5.4893
6.3639
6.6817
6.7161

2.7250
3.3052
3.8855
4.4657
5.0459
5.6262
6.2064
6.7866

7
7
7
7
7
7
7
7
7

65
56
121
210
185
412
682
772
415

5503/119
5503/119
5503/119
5503/119
5503/119
5503/119
5503/119
5503/119

3.116279
3.159085
3.802767
4.51369
4.713203
5.969239
7.302863
8.249784
8.360249

3.4555
3.4969
4.0607
4.5817
4.7132
5.4314
6.0445
6.4151
6.4555

3.2041
3.6529
4.1017
4.5505
4.9993
5.4481
5.8969
6.3457

7
7
7
7
7
7
7
7
7

866
1173
965
797
631
484
357
235
123

6592/295
6592/295
6592/295
6592/295
6592/295
6592/295
6592/295
6592/295

5.529298
6.52918
6.673447
6.840134
6.814281
6.814763
6.815151
6.814581
7.096418

5.1987
5.7040
5.7705
5.8455
5.8339
5.8342
5.8343
5.8341
5.9573

5.5119
5.5748
5.6376
5.7005
5.7633
5.8262
5.8890
5.9518

R2

0.8788

0.8698

0.9498

0.9729

0.9770

0.4860

Table 3: Results for the Knapsack instances of type Strongly Correlated.

721

fiDinh, Dinh, Michel, & Russell

Linear fit
to log10 E
5.8687
5.8803
5.8919
5.9036
5.9152
5.9268
5.9384
5.9500

#

n

Total
node
expansions E
731425
761013
782339
805295
828252
845545
865626
885943
900630

Optimal
soln. depth d
11
15
12
12
12
10
11
14
13

Search time,
seconds
1090
878
716
579
463
360
267
179
80

log10 E

20
20
20
20
20
20
20
20
20

Heuristic
error 
0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

h ([n])/m

1

5509/28
5509/28
5509/28
5509/28
5509/28
5509/28
5509/28
5509/28

5.8642
5.8814
5.8934
5.9060
5.9182
5.9271
5.9373
5.9474
5.9545

2

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

67164
71824
76627
80614
84553
90166
96506
99536
104144

6
9
7
8
8
9
7
7
8

259
208
168
136
107
82
58
35
10

2984/28
2984/28
2984/28
2984/28
2984/28
2984/28
2984/28
2984/28

4.8271
4.8563
4.8844
4.9064
4.9271
4.9550
4.9846
4.9980
5.0176

4.8311
4.8558
4.8804
4.9050
4.9297
4.9543
4.9790
5.0036

3

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

222293
232989
244871
256250
266235
274056
279890
283160
291239

11
12
8
9
9
8
11
9
9

533
432
353
285
226
173
126
81
28

3687/26
3687/26
3687/26
3687/26
3687/26
3687/26
3687/26
3687/26

5.3469
5.3673
5.3889
5.4087
5.4253
5.4378
5.4470
5.4520
5.4642

5.3552
5.3706
5.3861
5.4015
5.4170
5.4324
5.4479
5.4633

4

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

290608
304974
313598
323477
331235
336665
340874
342644
360837

10
10
9
9
9
10
9
9
8

329
272
225
185
151
121
92
64
33

3883/56
3883/56
3883/56
3883/56
3883/56
3883/56
3883/56
3883/56

5.4633
5.4843
5.4964
5.5098
5.5201
5.5272
5.5326
5.5348
5.5573

5.4734
5.4834
5.4935
5.5035
5.5136
5.5237
5.5337
5.5438

5

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

851515
873968
893378
912734
927408
940724
950209
958343
967863

11
14
12
14
13
12
12
13
12

740
609
498
410
335
267
206
142
88

7731/77
7731/77
7731/77
7731/77
7731/77
7731/77
7731/77
7731/77

5.9302
5.9415
5.9510
5.9603
5.9673
5.9735
5.9778
5.9815
5.9858

5.9348
5.9421
5.9494
5.9567
5.9641
5.9714
5.9787
5.9860

6

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

75858
81410
88494
94585
100329
106409
110656
114601
117496

10
8
6
9
7
5
9
9
4

488
363
287
225
177
134
94
55
11

2327/11
2327/11
2327/11
2327/11
2327/11
2327/11
2327/11
2327/11

4.8800
4.9107
4.9469
4.9758
5.0014
5.0270
5.0440
5.0592
5.0700

4.8895
4.9155
4.9416
4.9676
4.9936
5.0197
5.0457
5.0717

7

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

712138
748095
778565
799378
823236
844925
870175
897407
909075

11
12
15
11
13
13
13
12
14

1178
947
765
618
490
378
280
185
80

6456/33
6456/33
6456/33
6456/33
6456/33
6456/33
6456/33
6456/33

5.8526
5.8740
5.8913
5.9028
5.9155
5.9268
5.9396
5.9530
5.9586

5.8590
5.8727
5.8864
5.9001
5.9138
5.9275
5.9412
5.9549

R2

0.9918

0.9959

0.9649

0.9369

0.9687

0.9833

0.9895

Table 4: Results for the Knapsack instances of type Subset Sum.

722

fiThe Time Complexity of A with Approximate Heuristics

Linear fit
to log10 E
5.4113
5.4416
5.4719
5.5023
5.5326
5.5629
5.5932
5.6236

#

n

Total
node
expansions E
252054
279643
299328
324182
340530
361756
385942
423848
454094

Optimal
soln. depth d
10
12
9
11
9
10
10
9
9

Search time,
seconds
2274
1607
1159
878
666
494
344
201
42

log10 E

20
20
20
20
20
20
20
20
20

Heuristic
error 
0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

h ([n])/m

8

3514/7
3514/7
3514/7
3514/7
3514/7
3514/7
3514/7
3514/7

5.4015
5.4466
5.4761
5.5108
5.5322
5.5584
5.5865
5.6272
5.6571

9

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

284146
301301
318308
330924
338590
345335
351027
356374
369094

9
8
7
9
9
9
10
10
8

628
507
412
334
263
203
146
92
34

4494/34
4494/34
4494/34
4494/34
4494/34
4494/34
4494/34
4494/34

5.4535
5.4790
5.5028
5.5197
5.5297
5.5382
5.5453
5.5519
5.5671

5.4677
5.4812
5.4947
5.5083
5.5218
5.5353
5.5489
5.5624

10

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

812828
852539
881657
903389
923450
941277
954861
970871
985526

11
13
15
12
15
11
14
14
12

1078
874
711
579
466
356
266
180
88

6963/39
6963/39
6963/39
6963/39
6963/39
6963/39
6963/39
6963/39

5.9100
5.9307
5.9453
5.9559
5.9654
5.9737
5.9799
5.9872
5.9937

5.9193
5.9298
5.9403
5.9508
5.9613
5.9717
5.9822
5.9927

11

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

872387
892404
907719
920529
930373
939495
945766
948094
961185

12
13
12
12
12
13
12
11
11

527
441
366
306
260
214
169
125
85

7270/102
7270/102
7270/102
7270/102
7270/102
7270/102
7270/102
7270/102

5.9407
5.9506
5.9580
5.9640
5.9687
5.9729
5.9758
5.9769
5.9828

5.9456
5.9507
5.9558
5.9609
5.9660
5.9711
5.9762
5.9813

12

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

544749
572592
596732
622826
644836
662145
682257
705866
720827

13
8
12
9
11
12
11
11
13

997
804
656
528
420
329
242
158
64

5752/35
5752/35
5752/35
5752/35
5752/35
5752/35
5752/35
5752/35

5.7362
5.7578
5.7758
5.7944
5.8094
5.8210
5.8339
5.8487
5.8578

5.7422
5.7579
5.7736
5.7893
5.8050
5.8207
5.8364
5.8521

13

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

592766
628513
662306
684651
713728
745263
781953
824260
861415

10
10
11
13
12
10
11
11
11

1824
1319
1040
828
645
487
344
216
74

7445/30
7445/30
7445/30
7445/30
7445/30
7445/30
7445/30
7445/30

5.7729
5.7983
5.8211
5.8355
5.8535
5.8723
5.8932
5.9161
5.9352

5.7767
5.7963
5.8159
5.8355
5.8552
5.8748
5.8944
5.9140

14

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

137368
148933
157793
165368
172383
179983
186068
191426
197634

8
7
10
9
9
7
9
8
10

561
450
363
289
226
173
123
73
18

3509/22
3509/22
3509/22
3509/22
3509/22
3509/22
3509/22
3509/22

5.1379
5.1730
5.1981
5.2185
5.2365
5.2552
5.2697
5.2820
5.2959

5.1513
5.1713
5.1913
5.2113
5.2314
5.2514
5.2714
5.2914

R2

0.9925

0.9282

0.9593

0.9409

0.9901

0.9963

0.9761

Table 5: Results for the Knapsack instances of type Subset Sum.

723

fiDinh, Dinh, Michel, & Russell

Linear fit
to log10 E
4.5311
4.5760
4.6209
4.6658
4.7107
4.7556
4.8006
4.8455

#

n

Total
node
expansions E
34937
38617
41757
45036
49231
54428
62409
75602
84284

Optimal
soln. depth d
9
6
10
9
10
7
9
7
8

Search time,
seconds
1022
772
529
353
272
186
128
72
8

log10 E

20
20
20
20
20
20
20
20
20

Heuristic
error 
0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

h ([n])/m

15

3124/9
3124/9
3124/9
3124/9
3124/9
3124/9
3124/9
3124/9

4.5433
4.5868
4.6207
4.6536
4.6922
4.7358
4.7952
4.8785
4.9257

16

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

476547
498939
523867
558927
592373
626403
668497
725325
768536

10
11
10
10
9
10
12
12
13

3224
2097
1536
1181
911
675
468
281
71

5442/11
5442/11
5442/11
5442/11
5442/11
5442/11
5442/11
5442/11

5.6781
5.6980
5.7192
5.7474
5.7726
5.7969
5.8251
5.8605
5.8857

5.6718
5.6976
5.7235
5.7493
5.7751
5.8010
5.8268
5.8527

17

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

641544
666837
702032
737893
772405
810089
852271
902227
964897

15
11
12
14
14
14
14
12
14

3751
2791
1991
1495
1124
827
570
337
86

7157/11
7157/11
7157/11
7157/11
7157/11
7157/11
7157/11
7157/11

5.8072
5.8240
5.8464
5.8680
5.8878
5.9085
5.9306
5.9553
5.9845

5.8045
5.8256
5.8468
5.8679
5.8891
5.9102
5.9313
5.9525

18

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

321490
338267
358571
379827
399061
419052
443204
486366
508524

9
10
9
10
9
10
9
10
10

1215
952
760
600
466
356
252
157
47

4631/20
4631/20
4631/20
4631/20
4631/20
4631/20
4631/20
4631/20

5.5072
5.5293
5.5546
5.5796
5.6010
5.6223
5.6466
5.6870
5.7063

5.5047
5.5293
5.5540
5.5786
5.6033
5.6279
5.6525
5.6772

19

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

104698
110845
116893
122710
128398
131887
133658
134205
142348

7
8
10
8
6
9
10
5
8

251
206
169
137
110
84
60
37
13

3373/44
3373/44
3373/44
3373/44
3373/44
3373/44
3373/44
3373/44

5.0199
5.0447
5.0678
5.0889
5.1086
5.1202
5.1260
5.1278
5.1534

5.0322
5.0482
5.0641
5.0800
5.0959
5.1119
5.1278
5.1437

20

20
20
20
20
20
20
20
20
20

0.5
0.5625
0.625
0.6875
0.75
0.8125
0.875
0.9375
BFS

275501
286961
296924
305914
315286
322234
324077
324471
348398

10
9
9
7
9
8
9
10
9

352
292
240
196
159
126
94
65
32

5262/94
5262/94
5262/94
5262/94
5262/94
5262/94
5262/94
5262/94

5.4401
5.4578
5.4726
5.4856
5.4987
5.5082
5.5106
5.5112
5.5421

5.4489
5.4594
5.4699
5.4804
5.4909
5.5013
5.5118
5.5223

R2

0.9739

0.9947

0.9988

0.9932

0.9349

0.9299

Table 6: Results for the Knapsack instances of type Subset Sum.

724

fiThe Time Complexity of A with Approximate Heuristics

Effective
branching
factor
E 1/k
1.10682761
1.10682761
1.10682761
1.10682761
1.10682761
1.10682761
1.10682761
1.10682761
1.10682761
1.10682761
1.11793532
1.12483883
1.13029527
1.13481129
1.13744262
1.13983570
1.14203051
1.14306342
1.14405770
1.15327789
1.19493326
1.20344942
1.21724042
1.22842928
1.23335496
1.24222170
1.24615895
1.24988516
1.25689894
1.26697571
1.28154406
1.28838000
1.29446689
1.29905304
1.30420852
1.30895150
1.31267920
1.31682768
1.32748452
1.34592652

Upper
bound
B(d)1/k

B(d)1/k

0
0.0025
0.005
0.0075
0.01
0.0125
0.015
0.0175
0.02
0.0225
0.025
0.0275
0.03
0.0325
0.035
0.0375
0.04
0.0425
0.045
0.0475
0.05
0.0525
0.055
0.0575
0.06
0.0625
0.065
0.0675
0.07
0.0725
0.075
0.0775
0.08
0.0825
0.085
0.0875
0.09
0.0925
0.095
0.0975

Total
node
expansions
E
87
87
87
87
87
87
87
87
87
87
135
177
219
261
289
317
345
359
373
531
2530
3458
5709
8539
10183
13956
16041
18293
23400
33251
54989
69492
85507
99904
118924
139520
158117
181666
258998
475269

1.12498287
1.12509476
1.12524953
1.12546320
1.12575740
1.12616102
1.12671203
1.12745936
1.12846421
1.12980027
1.29413023
1.29413756
1.29414775
1.29416190
1.29418158
1.29420890
1.29424685
1.29429954
1.29437264
1.48549510
1.48549548
1.48549601
1.48549674
1.48549775
1.48549917
1.48550113
1.48550386
1.48550766
1.68167021
1.68167024
1.68167029
1.68167036
1.68167046
1.68167059
1.68167077
1.68167103
1.68167138
1.88726770
1.88726771
1.88726771

0
0.0025
0.005
0.0075
0.01
0.0125
0.015
0.0175
0.02
0.0225
0.025
0.0275
0.03
0.0325
0.035
0.0375
0.04
0.0425
0.045
0.0475
0.05
0.0525
0.055
0.0575
0.06
0.0625
0.065
0.0675
0.07

125
125
125
125
125
125
125
295
599
789
979
1093
1207
1759
8006
18159
31829
39898
53605
63934
151470
240217
418262
569663
823942
1.03E+06
1.39E+06
3.35E+06
6.43E+06

1.07965322
1.07965322
1.07965322
1.07965322
1.07965322
1.07965322
1.07965322
1.09446915
1.10684330
1.11169422
1.11550813
1.11746021
1.11922136
1.12593198
1.15334431
1.16843520
1.17889026
1.18312592
1.18868491
1.19201428
1.20844644
1.21732463
1.22808758
1.23412462
1.24137536
1.24580697
1.25172483
1.26929396
1.28251719

1.09187259
1.09196102
1.09210593
1.09234240
1.09272569
1.09334029
1.09430956
1.21404534
1.21404945
1.21405622
1.21406738
1.21408579
1.21411611
1.34843434
1.34843446
1.34843466
1.34843500
1.34843555
1.34843647
1.34843797
1.48271141
1.48271142
1.48271144
1.48271147
1.48271152
1.48271161
1.62031036
1.62031036
1.62031037

#

n

k

Heuristic
error 

1

10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10

44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44
44

2

12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12
12

63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63
63

log10 E

Linear
fit to
log10 E

1.01640297
1.01650406
1.01664390
1.01683694
1.01710275
1.01746741
1.01796524
1.01864044
1.01954830
1.02075541
1.15760743
1.15050932
1.14496431
1.14042036
1.13779944
1.13543461
1.13328571
1.13230772
1.13138755
1.28806345
1.24316189
1.23436514
1.22038072
1.20926599
1.20443766
1.19584220
1.19206612
1.18851532
1.33795181
1.32731056
1.31222199
1.30525960
1.29912203
1.29453574
1.28941863
1.28474663
1.28109852
1.43319261
1.42168717
1.40220709

1.9395
1.9395
1.9395
1.9395
1.9395
1.9395
1.9395
1.9395
1.9395
1.9395
2.1303
2.2480
2.3404
2.4166
2.4609
2.5011
2.5378
2.5551
2.5717
2.7251
3.4031
3.5388
3.7566
3.9314
4.0079
4.1448
4.2052
4.2623
4.3692
4.5218
4.7403
4.8419
4.9320
4.9996
5.0753
5.1446
5.1990
5.2593
5.4133
5.6769

1.2674
1.3758
1.4843
1.5928
1.7013
1.8097
1.9182
2.0267
2.1352
2.2436
2.3521
2.4606
2.5691
2.6775
2.7860
2.8945
3.0030
3.1114
3.2199
3.3284
3.4369
3.5454
3.6538
3.7623
3.8708
3.9793
4.0877
4.1962
4.3047
4.4132
4.5216
4.6301
4.7386
4.8471
4.9555
5.0640
5.1725
5.2810
5.3894
5.4979

1.01131786
1.01139977
1.01153399
1.01175301
1.01210802
1.01267728
1.01357504
1.10925497
1.09685756
1.09207747
1.08835368
1.08646892
1.08478640
1.19761616
1.16915170
1.15405173
1.14381723
1.13972277
1.13439352
1.13122636
1.22695666
1.21800824
1.20733363
1.20142768
1.19441030
1.19016159
1.29446211
1.27654461
1.26338296

2.0969
2.0969
2.0969
2.0969
2.0969
2.0969
2.0969
2.4698
2.7774
2.8971
2.9908
3.0386
3.0817
3.2453
3.9034
4.2591
4.5028
4.6010
4.7292
4.8057
5.1803
5.3806
5.6214
5.7556
5.9159
6.0134
6.1431
6.5244
6.8080

1.3953
1.5797
1.7641
1.9485
2.1328
2.3172
2.5016
2.6860
2.8704
3.0547
3.2391
3.4235
3.6079
3.7923
3.9767
4.1610
4.3454
4.5298
4.7142
4.8986
5.0829
5.2673
5.4517
5.6361
5.8205
6.0049
6.1892
6.3736
6.5580

E 1/k

R2

0.9482

0.9693

Table 7: Results for partial Latin square instances.

725

fiDinh, Dinh, Michel, & Russell

Effective
branching
factor
E 1/k
1.06161017
1.06161017
1.06161017
1.06161017
1.06161017
1.06615920
1.07302532
1.07624311
1.07854600
1.07979831
1.10835983
1.12621485
1.13582148
1.14198131
1.14598774
1.15596951
1.16381138
1.16872905
1.17320907
1.17776024

Upper
bound
B(d)1/k

B(d)1/k

0
0.0025
0.005
0.0075
0.01
0.0125
0.015
0.0175
0.02
0.0225
0.025
0.0275
0.03
0.0325
0.035
0.0375
0.04
0.0425
0.045
0.0475

Total
node
expansions
E
171
171
171
171
171
247
429
555
667
737
6959
27506
57104
90923
122879
259053
463344
665871
925306
1.29E+06

1.07034588
1.07042098
1.07057335
1.07087962
1.07148429
1.16291112
1.16291347
1.16291827
1.16292811
1.16294821
1.26274158
1.26274166
1.26274182
1.26274214
1.36083647
1.36083648
1.36083648
1.36083649
1.36083651
1.45985179

113
113
113
113
113
113
113
113
113
113
113
113
113

0
0.0025
0.005
0.0075
0.01
0.0125
0.015
0.0175
0.02
0.0225
0.025
0.0275
0.03

225
225
225
225
799
1719
2317
2731
50236
144797
258735
516942
1.97E+06

1.04909731
1.04909731
1.04909731
1.04909731
1.06092884
1.06814635
1.07097198
1.07253118
1.10053004
1.11088842
1.11660964
1.12346988
1.13686805

18
18
18
18
18
18
18
18
18

143
143
143
143
143
143
143
143
143

0
0.0025
0.005
0.0075
0.01
0.0125
0.015
0.0175
0.02

285
285
285
743
2579
3659
39137
246338
535932

20
20
20
20
20
20
20

176
176
176
176
176
176
176

0
0.0025
0.005
0.0075
0.01
0.0125
0.015

351
351
351
2425
4125
107153
619190

#

n

k

Heuristic
error 

3

14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14
14

86
86
86
86
86
86
86
86
86
86
86
86
86
86
86
86
86
86
86
86

4

16
16
16
16
16
16
16
16
16
16
16
16
16

5

6

log10 E

Linear
fit to
log10 E

1.00822873
1.00829948
1.00844300
1.00873150
1.00930108
1.09074810
1.08377077
1.08053493
1.07823691
1.07700503
1.13928848
1.12122626
1.11174321
1.10574676
1.18747908
1.17722523
1.16929298
1.16437295
1.15992669
1.23951526

2.2330
2.2330
2.2330
2.2330
2.2330
2.3927
2.6325
2.7443
2.8241
2.8675
3.8425
4.4394
4.7567
4.9587
5.0895
5.4134
5.6659
5.8234
5.9663
6.1109

1.4986
1.7445
1.9904
2.2363
2.4822
2.7281
2.9740
3.2199
3.4658
3.7117
3.9576
4.2035
4.4494
4.6953
4.9412
5.1871
5.4330
5.6789
5.9248
6.1707

1.05563497
1.05570312
1.05588217
1.05634285
1.12838087
1.12838284
1.12838808
1.12840202
1.20572650
1.20572656
1.20572671
1.28088203
1.28088203

1.00623170
1.00629666
1.00646733
1.00690645
1.06357828
1.05639348
1.05361121
1.05209251
1.09558708
1.08537144
1.07981041
1.14011248
1.12667607

2.3522
2.3522
2.3522
2.3522
2.9025
3.2353
3.3649
3.4363
4.7010
5.1608
5.4129
5.7134
6.2952

1.6772
2.0340
2.3907
2.7475
3.1042
3.4610
3.8178
4.1745
4.5313
4.8881
5.2448
5.6016
5.9584

1.04031952
1.04031952
1.04031952
1.04731385
1.05646789
1.05905525
1.07675277
1.09069423
1.09663904

1.04542550
1.04549145
1.04572413
1.10463010
1.10463134
1.10463580
1.16693654
1.16693656
1.16693665

1.00490809
1.00497148
1.00519515
1.05472691
1.04558912
1.04303887
1.08375532
1.06990257
1.06410278

2.4548
2.4548
2.4548
2.8710
3.4115
3.5634
4.5926
5.3915
5.7291

1.8665
2.3144
2.7623
3.2103
3.6582
4.1061
4.5540
5.0019
5.4498

1.03386057
1.03386057
1.03386057
1.04527681
1.04843662
1.06802045
1.07871841

1.03797380
1.03804139
1.03837263
1.08739144
1.08739402
1.13899860
1.13899862

1.00397851
1.00404389
1.00436428
1.04029040
1.03715761
1.06645766
1.05588132

2.5453
2.5453
2.5453
3.3847
3.6154
5.0300
5.7918

1.9462
2.5098
3.0733
3.6368
4.2004
4.7639
5.3275

E 1/k

R2

0.9335

0.9274

0.9120

0.8698

Table 8: Results for partial Latin square instances.

726

fiThe Time Complexity of A with Approximate Heuristics

References
Aaronson, S. (2004). Lower bounds for local search by quantum arguments. In Proceedings of the
36th Annual ACM Symposium on Theory of Computing (STOC). ACM Press.
Babai, L. (1991). Local expansion of vertex-transitive graphs and random generation in finite groups.
In Proceedings of the 23rd annual ACM symposium on Symposium of Theory of Computing,
pp. 164174.
Chernoff, H. (1952). A measure of asymptotic efficiency for tests of hypothesis based on the sum of
observations. Annals of Mathematical Statistics, 23, 493507.
Chung, F. (2006). The diameter and Laplacian eigenvalues of directed graphs. Electronic Journal
of Combinatorics, 13 (4).
Chung, F. R. K. (1997). Spectral Graph Theory. American Mathematical Society.
Colbourn, C. J. (1984). The complexity of completing partial Latin squares. Discrete Applied
Mathematics, 8 (1), 2530.
Davis, H., Bramanti-Gregor, A., & Wang, J. (1988). The advantages of using depth and breadth
components in heuristic search. In Ras, Z., & Saitta, L. (Eds.), Proceedings of the Third
International Symposium on Methodologies for Intelligent Systems, pp. 1928, North-Holland,
Amsterdam. Elsevier.
Dechter, R., & Pearl, J. (1985). Generalized best-first search strategies and the optimality of A*. J.
ACM, 32 (3), 505536.
Demaine, E. D. (2001). Playing games with algorithms: Algorithmic combinatorial game theory.
In Proc. 26th Symp. on Math Found. in Comp. Sci., Lect. Notes in Comp. Sci., pp. 1832.
Springer-Verlag.
Dinh, H., Russell, A., & Su, Y. (2007). On the value of good advice: The complexity of A* with
accurate heuristics. In Proceedings of the Twenty-Second Conference on Artificial Intelligence
(AAAI-07), pp. 11401145.
Edelkamp, S. (2001). Prediction of regular search tree growth by spectral analysis. In Proceedings
of the Joint German/Austrian Conference on AI: Advances in Artificial Intelligence, KI 01,
pp. 154168, London, UK, UK. Springer-Verlag.
Felner, A., Korf, R. E., & Hanan, S. (2004). Additive pattern database heuristics. Journal of
Artificial Intelligence Research, 22, 279318.
Friedman, J. (2003). A proof of Alons second eigenvalue conjecture. In STOC 03: Proceedings of
the thirty-fifth annual ACM symposium on Theory of computing, pp. 720724, New York, NY,
USA. ACM.
Gaschnig, J. (1979). Perfomance measurement and analysis of certain search algorithms. Ph.D.
thesis, Carnegie-Mellon University, Pittsburgh, PA.
Gomes, C., & Shmoys, D. (2002). Completing quasigroups or Latin squares: A structured graph
coloring problem. In Johnson, D. S., Mehrotra, A., & Trick, M. (Eds.), Proceedings of the
Computational Symposium on Graph Coloring and its Generalizations, pp. 2239, Ithaca, New
York, USA.
Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial search through randomization. In AAAI 98/IAAI 98: Proceedings of the fifteenth national/tenth conference on Artificial intelligence/Innovative applications of artificial intelligence, pp. 431437, Menlo Park,
CA, USA. American Association for Artificial Intelligence.
Hart, P., Nilson, N., & Raphael, B. (1968). A formal basis for the heuristic determination of minimum
cost paths. IEEE Transactions on Systems Science and Cybernetics, SCC-4 (2), 100107.
727

fiDinh, Dinh, Michel, & Russell

Helmert, M., & Roger, G. (2008). How good is almost perfect?. In Proceedings of AAAI-08.
Hochbaum, D. (1996). Approximation Algorithms for NP-hard Problems. Brooks Cole.
Horn, R., & Johnson, C. (1999). Matrix Analysis. Cambridge University Press, Cambridge, UK.
Huyn, N., Dechter, R., & Pearl, J. (1980). Probabilistic analysis of the complexity of A*. Artificial
Intelligence, 15, 241254.
Ibarra, O. H., & Kim, C. E. (1975). Fast approximation algorithms for the knapsack and sum of
subset problems. Journal of the ACM, 22 (4), 463468.
Karp, R. M. (1972). Reducibility among combinatorial problems. In Miller, R. E., & Thatcher,
J. W. (Eds.), Complexity of Computer Computations, p. 85103. New York: Plenum.
Kellerer, H., Pferschy, U., & Pisinger, D. (2004). Knapsack problems. Springer.
Korf, R. (1985). Depth-first iterative deepening: An optimal admissible tree search. Artificial
Intelligence, 27, 97109.
Korf, R., & Reid, M. (1998). Complexity analysis of admissible heuristic search. In Proceedings of
the National Conference on Artificial Intelligence (AAAI-98), pp. 305310.
Korf, R., Reid, M., & Edelkamp, S. (2001). Time complexity of iterative-deepening-A*. Artificial
Intelligence, 129 (1-2), 199218.
Korf, R. E. (2000). Recent progress in the design and analysis of admissible heuristic functions. In
AAAI/IAAI 2000, pp. 11651170. Also in SARA 02: Proceedings of the 4th International
Symposium on Abstraction, Reformulation, and Approximation.
Kumar, R., Russell, A., & Sundaram, R. (1996). Approximating Latin square extensions. In COCOON 96: Proceedings of the Second Annual International Conference on Computing and
Combinatorics, pp. 280289, London, UK. Springer-Verlag.
Laywine, C., & Mullen, G. (1998). Discrete Mathematics using Latin Squares. Interscience Series in
Discrete mathematics and Optimization. Wiley.
Lenstra, A. K., Lenstra, H. W., & Lovasz, L. (1981). Factoring polynomials with rational coefficients.
Tech. rep. 82-05, Universiteit Amsterdam.
Motwani, R., & Raghavan, P. (1995). Randomized Algorithms. Cambridge University Press.
Parberry, I. (1995). A real-time algorithm for the (n2  1)-puzzle. Inf. Process. Lett, 56, 2328.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies for Computer Problem Solving. AddisonWesley, MA.
Pisinger, D. (2005). Where are the hard knapsack problems?. Computers and Operations Research,
32, 22712284.
Pohl, I. (1977). Practical and theoretical considerations in heuristic search algorithms. In Elcock,
W., & Michie, D. (Eds.), Machine Intelligence, Vol. 8, pp. 5572. Ellis Horwood, Chichester.
Ratner, D., & Warmuth, M. (1990). The (n2  1)-puzzle and related relocation problems. Journal
for Symbolic Computation, 10 (2), 111137.
Russell, S., & Norvig, P. (1995). Artificial Intelligence - A Modern Approach. Prentice Hall, New
Jersey.
Sen, A. K., Bagchi, A., & Zhang, W. (2004). Average-case analysis of best-first search in two
representative directed acyclic graphs. Artif. Intell., 155 (1-2), 183206.
Tay, T.-S. (1996). Some results on generalized Latin squares. Graphs and Combinatorics, 12, 199
207.
Vazirani, V. (2001). Approximation Algorithms. Springer-Verlag.
728

fiThe Time Complexity of A with Approximate Heuristics

Vazirani, V. (2002). Primal-dual schema based approximation algorithms. In Theoretical Aspects of
Computer Science: Advanced Lectures, pp. 198207. Springer-Verlag, New York.
Zahavi, U., Felner, A., Schaeffer, J., & Sturtevant, N. (2007). Inconsistent heuristics. In Proceedings
of AAAI-07, pp. 12111216.
Zhang, Z., Sturtevant, N. R., Holte, R., Schaeffer, J., & Felner, A. (2009). A* search with inconsistent
heuristics. In Proceedings of the 21st international jont conference on Artifical intelligence,
IJCAI09, pp. 634639, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.

729

fiJournal of Artificial Intelligence Research 45 (2012) 165-196

Submitted 06/12; published 10/12

Coalition Structure Generation over Graphs
Thomas Voice

tdv@ecs.soton.ac.uk

School of Electronics and Computer Science,
University of Southampton, UK

Maria Polukarov

mp3@ecs.soton.ac.uk

School of Electronics and Computer Science,
University of Southampton, UK

Nicholas R. Jennings

nrj@ecs.soton.ac.uk

School of Electronics and Computer Science,
University of Southampton, UK
Department of Computing and Information Technology,
King Abdulaziz University, Saudi Arabia

Abstract
We give the analysis of the computational complexity of coalition structure generation over
graphs. Given an undirected graph G = (N, E) and a valuation function v : P(N )  R over
the subsets of nodes, the problem is to find a partition of N into connected subsets, that
maximises the sum of the components values. This problem is generally NPcomplete;
in particular, it is hard for a defined class of valuation functions which are independent
of disconnected membersthat is, two nodes have no effect on each others marginal contribution to their vertex separator. Nonetheless, for all such functions we provide bounds
on the complexity of coalition structure generation over general and minorfree graphs.
Our proof is constructive and yields algorithms for solving corresponding instances of the
problem. Furthermore, we derive linear time bounds for graphs of bounded treewidth.
However, as we show, the problem remains NPcomplete for planar graphs, and hence,
for any Kk minorfree graphs where k  5. Moreover, a 3-SAT problem with m clauses
can be represented by a coalition structure generation problem over a planar graph with
O(m2 ) nodes. Importantly, our hardness result holds for a particular subclass of valuation
functions, termed edge sum, where the value of each subset of nodes is simply determined
by the sum of given weights of the edges in the induced subgraph.

1. Introduction
Coalition structure generation (CSG) is the equivalent of the complete set partitioning
problem (Yeh, 1986)one of the fundamental problems in combinatorial optimisation, that
has applications in many fields, from political sciences and economics, to operations research
and computer science. In a CSG problem, we have a set N of n elements and a valuation
function v : P(N )  R, where P(N ) denotes the power set of N , and the problem is to
divide the given set P
into disjoint exhaustive subsets (or, coalitions) N1 , . . . , Nm so that the
total sum of values, m
i=1 v(Ni ), is maximised. Thus, we seek a most valuable partition (or,
a coalition structure) over N .
c
2012
AI Access Foundation. All rights reserved.

fiVoice, Polukarov, & Jennings

Partitioning structure problems arise in a wide range of practical domains including delivery management, scheduling, routing and location problems, where one wishes to assure
that every customer is served by one (and only one) location, vehicle or person (server).
Commonly cited problems of this kind include the crew-scheduling problem where every flight
leg of an airline must be scheduled by exactly one cockpit crew, the political districting problem whereby regions must be divided into voting districts such that every citizen is assigned
to exactly one district, and the coalition formation problem of political parties (Balas &
Padberg, 1976). Recently, CSG has become a major research topic in artificial intelligence
and multi-agent systems, as a tool for autonomous agents to form effective teams. For
example, in electronic commerce buyer agents may pool their demands in order to obtain
group discounts (Tsvetovat, Sycara, Chen, & Ying, 2001); in e-business coalitions may form
in order to satisfy certain market niches as they can respond to more diverse orders than
individual agents (Norman, Preece, Chalmers, Jennings, Luck, Dang, Nguyen, Deora, Gray,
& Fiddian, 2004); and in distributed vehicle routing coalitions of delivery companies can
reduce the transportation costs by sharing deliveries (Sandholm & Lesser, 1997). Other important applications include information gathering where several information servers come
together to answer queries (Klusch & Shehory, 1996), multi-sensor networks where sensors
form dynamic coalitions in wide-area surveillance scenarios (Dang, Dash, Rogers, & Jennings, 2006), and grid computing where multi-institution virtual organisations are viewed
as being central to coordinated resource sharing and problem solving (Yong, Li, Weiming,
Jichang, & Changying, 2003).
However, the classic CSG model assumes no structure on the primitive set of elements.
This is a considerable shortcoming, as in various contexts of interest to computer scientists,
these elements represent agents (either human or automated) or resources (e.g., machines,
computers, service providers or communication lines), which are typically embedded in a
social or computer network. Moreover, in many such scenarios those elements which are
disconnected have no effect on each others performance and potential contribution to a
coalition, and if not connected by intermediaries, may not be able to cooperate at all. For
example, consider a communication network where each edge is a channel, with capacity
indicating the amount of information that can be transmitted through it. Thus, in the
aforementioned contexts of e-commerce, multi-sensor networks or grid computing, such a
network connects between sellers and buyers, sensors or agents working on computational
tasks, respectively. Any subset of nodes in this network produces a value proportional to
the total capacity of the subnetwork induced by these nodes. In such a scenario, any two
nodes that are not connected by a direct link in the network, will not affect each others
marginal contribution to any coalition of nodes that separates them. Or, as is also typical
in e-commerce and e-business domains, assume that an edge represents a trust link in a
reputation system, so that two nodes will only participate in the same coalition if the trust
distance given by the length of a path between them, is finite (that is, a coalition induces
a connected subgraph of the trust network). Suppose that a value of a coalition is given
by the number of pairs of its mutually trusted membersi.e., the edges in the induced
subgraph. Then, a contribution of a particular node i will not depend on another node
j who trusts some members of the coalition but does not trust i directly, as there is no
edge between i and j. Additional natural examples arise in multi-agent systems domains,
where agents come together to complete tasks. Typically, a pair of agents can be associ166

fiCoalition Structure Generation over Graphs

ated with a weight indicating their potential mutual (in)efficiency in the task execution
(e.g., due to skill/expertise or equipment complementarity, interpersonal (in)compatibility,
(dis)agreements, spatial or other constraints). The value of a coalition is then measured by
the total coalitional weight as given by the sum of weights on the links whose both ends participate in the coalition. Importantly, these weights can be positive or negative, representing
different relations among the agents, and thus having corresponding effects on a coalitional
value. Note that agents with zero weight links do not affect each others contribution to
a coalition. Finally, correlation clusteringa well-known clustering technique motivated
by the problem of clustering a large corpus of objects, such as documents (e.g., web pages
and weblog data with given content/access patterns), customers and service providers (with
given properties and past buying/selling records) or biological species (plants and animals
given their features)operates in a setting where the elements which need to be partitioned into clusters (by topic, location, behaviour etc.) are characterised by similarity
(and/or difference) relations among them. The aim is usually to maximise the overall
agreementi.e., correlationof clusters. For example, given a signed graph where the edge
label indicates whether two nodes are similar (+) or different (), the task is to cluster the
nodes so that similar objects are grouped together, and different onesseparately. Thus,
the value of a cluster C is given by the total sum of its positive intra-cluster edges and negative inter-cluster edges with one end in C. In such cases, only connected (either positively
or negatively) members have an impact on the cluster values.
Against this background, in this paper we extend the CSG problem to connected sets.
More precisely, we introduce the independence of disconnected members and consider coalition structures over the node set of a graph, endowed with a valuation function that has this
property. This is formally defined in Section 2 below, where we also give necessary graph
theoretic notation and summarise our main contributions. Then, in Sections 3, 4 and 5, we
discuss our results in great detail and present all the proofs. Specifically, Section 3 provides
computational bounds on coalition structure generation over general graphs, and Section 4
introduces our technique for solving the problem using tree decompositions. This technique,
in particular, allows us to show linear time solvability for graphs with bounded treewidth.
In Section 5, we apply it to derive upper bounds for graphs with separator theorems and,
in particular, planar graphs and minorfree graphs. We also present our negative result
showing the NPhardness of the problem over planar graphs and hence, all Kk minorfree
graphs, even for a simple, so called edge sum, valuation function. We discuss the related
literature in Secion 6. Finally, Section 7 concludes the paper.

2. Coalition Structure Generation over Graphs
In this section, we formalise the concepts of independence of disconnected members and
graph coalition structure generation, and list our main contributions. For completeness,
we first provide some graphtheoretic definitions and notation necessary for presentation of
our results in following sections.
2.1 GraphTheoretic Definitions and Notation
Let N be a set of elements and let Pk (N ) stand for the set of all k-element subsets of the
set N . A simple undirected graph G is a pair G = (N, E) where N is a finite set of elements,
167

fiVoice, Polukarov, & Jennings

called the vertices (or, nodes) of G, and E is a subset of P2 (N )i.e., E is a collection of
two-element subsets of N representing connections between nodes, called the edges of G.
A complete graph is a graph in which each pair of nodes is connected by an edge. The
complete graph with n nodes is denoted Kn . A graph G is a bipartite graph if its vertices
can be divided into two disjoint sets N1 and N2 such that every edge connects a vertex in
N1 to one in N2 . A complete bipartite graph, G = (N1  N2 , E), is a bipartite graph such
that for any two vertices, n1  N1 and n2  N2 , {n1 , n2 } is an edge in G. The complete
bipartite graph with |N1 | = m and |N2 | = n, is denoted Km,n .
An undirected graph H is called a minor of the graph G if H can be obtained from G
by a series of vertex deletions, edge deletions and/or edge contractions (removing an edge
from a graph while simultaneously merging together the two vertices it used to connect). A
graph G is H minorfree if H is not a minor of G. A graph G is planar if it is K5 minorfree
and K3,3 minorfree. An important property of a planar graph is that it can be embedded
in the plane, i.e., it can be drawn in such a way that no edges cross each other. A familiar
special case of planar graphs is the class of grids: in a finite grid graph, the vertices are
associated with two indices 1  i  r and 1  j  c, and there is an edge connecting
each node ni,j to nodes ni+1,j and ni,j+1 (if such exist)thus, there are r rows and c
columns in such a graph, and the number of nodes is n = rc.
A subgraph H of the graph G is induced if for any pair of nodes x and y of H, {x, y} is
an edge of H if and only if it is an edge of G. In other words, H is an induced subgraph of
G if it has exactly the edges that appear in G over the same vertex set. If the vertex set of
H is the subset S  N of the vertex set of G, then H can be said to be induced by S.
A path in a graph is a sequence of nodes such that from each node there is an edge to
the next node in the sequence, and a path is called simple if it contains no repeated nodes.
A graph is said to be connected if there is a path between every pair of nodes in the graph.
A tree is a graph in which any two nodes are connected by exactly one simple path.
Many algorithms on graphs become easy if the input graph is a tree or tree-like. The
notion of being tree-like can be formalised using the concept of treewidth: if the treewidth
of a graph is small, then it is tree-likein particular, a tree has treewidth 1. Treewidth
is defined using the concept of tree decompositiona mapping of a graph into a tree.
Formally, a tree decomposition of G = (N, E) is a pair (X, T ), where X = {X1 , . . . , Xm } for
m  n = |N | is a family of subsets of N , and T is a tree whose nodes are the subsets Xi ,
satisfying the following properties: (i) the union of all sets Xi equals N that is, each graph
vertex is associated with at least one tree node; (ii) for every edge {x, y} in the graph, there
is a subset Xi that contains both x and y; (iii) if Xi and Xj both contain a vertex x, then
all nodes Xk of the tree in the (unique) path between Xi and Xj contain x as welli.e.,
the nodes associated with vertex x form a connected subset of T (equivalently, if Xi , Xj
and Xk are nodes, and Xk is on the path from Xi to Xj , then Xi  Xj  Xk ). The width
of a tree decomposition is the size of its largest set Xi minus one. Finally, the treewidth of
a graph G is the minimum width among all possible tree decompositions of G.
Given this notation, we can now formally define the problem of coalition structure
generation over graphs.
168

fiCoalition Structure Generation over Graphs

2.2 Model
Recall that a coalition structure over a set of elements N is defined by a collection of
its disjoint exhaustive subsets N1 , . . . , Nm where Ni  Nj =  for all 1  i, j  m and
m
i=1 Ni = N . Given the setting with a finite set of elements N in a connected undirected
graph G = (N, E) and a coalition valuation function v : P(N )  R over subsets of N ,
where v() = 0, we consider a class of coalition structure generation problems over N .
Accordingly, we make the following definitions.
Definition 1 For a graph G = (N, E), a function v : P(N )  R is independent of disconnected members (IDM) if for all i, j  N with (i, j) 
/ E, and coalition C with i, j 
/ C,
v(C  {i})  v(C) = v(C  {i, j})  v(C  {j}).

This means that agent i contributes to a coalition C exactly the same amount as to a
coalition C  {j} if i and j are not directly connected. That is, the presence of agent j
does not affect the marginal contribution of agent i to a separating coalition. Note that
Definition 1 generally does not restrict the effects the agents may have on each other if they
are connected.
To give an example, suppose that each edge {i, j}  E is associated with a constant
weight vi,j  R. Then, the coalition valuation function
v(C) =

X

vi,j

{i,j}E:i,jC

has the IDM property. We shall term such a function an edge sum coalition valuation function. This function is important as it naturally arises in many application scenarios (e.g.,
communication networks, information and multi-agent systems) and has simple representation. In the work of Deng and Papadimitriou (1994), this function is studied in the context
of complexity of cooperative game-theoretic solution concepts.
Other functions of this type arise in some familiar clustering settings. For example,
suppose that each edge {i, j} is labeled by + or  depending of whether i and j have
been deemed to be similar or different. For a coalition (or, cluster) C  N , let E + (C) =
{{i, j} = + | i, j  C} denote the set of its positive intra-cluster edges, and let E  (C) =
{{i, j} =  | i  C, j 
/ C} be the set of negative inter-cluster edges with one end in C.
Then, the correlation coalition valuation function defined as
v(C) = |E + (C)| + |E  (C)|

satisfies the IDM condition. Note that this function takes into account both intra- and
intercoalitional connections, and thus is different from the edge sum, which only considers
intracoalitional links. Maximising the sum of coalitional values over all coalition structures,
produces a partition of the nodes that agrees as much as possible with the edge labels. This
objective is pursued in the paper by Bansal, Blum and Chawla (2003) where they show
NP-completeness of the problem over complete graphs and provide several approximation
results.
Yet another example of an IDM function is found in multi-agent scenarios where coalitions of agents work on different parts of a global project. In such settings, members of a
coalition must make joint decisions and communicate them to other coalitions of agents to
coordinate their actions. Furthermore, when collaboration and communication is possible
169

fiVoice, Polukarov, & Jennings

only between closely connected agents, it is important that the coalition includes agents who
have mutual neighbours outside the coalition, so that decisions can be made and coordinated
with other coalitions. Given this, the coalition valuation function
v(C) =

X

ni (C)

iC

where ni (C) is the number of agent pairs (j, k)  N  N so that j  C, k 
/ C and
{i, j}, {i, k}  E, has the IDM property. We shall term this function a coordination coalition
valuation function. Obviously, by considering intercoalitional links, this function is different
from the edge sum. However, note also the difference between the coordination and the
correlation functions. By the latter, the effect of a link between any two agents on the value
of a coalition is determined by the link label and by whether or not both of these agents
belong to the coalition. In contrast, the coordination function accounts in fact for 3-agent
cliques, where two agents are members of the coalition and one is an outsider.
Our analysis, however, is not restricted to a particular valuation function but rather
covers the class of functions characterised by Definition 1. We define a graph coalition
structure generation (GCSG) problem as follows.
Definition 2 Given a connected undirected graph G = (N, E) and a coalition valuation
function v : P(N )  R which is independent of disconnected members,
the graph coalition
P
structure generation problem over G is to maximise v(C) = CC v(C) for C a coalition
structure over N .
GCSG can be posed as a clustering or a graph partitioning problem where the sum of cluster
values, which are given by some IDM valuation function, is to be maximised. For instance,
the aforementioned correlation clustering is a special case of GCSG. Note, however, that
clustering problems in general do not necessarily fit in our model: indeed, some of them
have objectives that do not admit the IDM property; on the other hand, some clustering
problems have additional restrictions on feasible graph partitions. For example, one of
the natural objectives in this domain is to maximise the modularity of clusters (Brandes,
Delling, Gaertler, Gorke, Hoefer, Nikoloski, & Wagner, 2008) given by the sum of clus
2
|(E(C)|+|E(C)|
ter values defined as follows. For each cluster C, let v(C) = |E(C)|

,
|E|
2|E|
where E(C) = {{i, j)}  E : i, j  C} is the set of intra-cluster edges of C and E(C) =
{{i, j}  E : i  C, j 
/ C} is the set of its inter-cluster edges. Notice that the second term
of the valuation funciton is squared, which implies the violation of the IMD property. Another related setting is the weighted graph partitioning problem where nodes and edges have
(non-negative) weights and the aim is to divide the graph into k disjoint parts such that the
parts have approximately equal weight and the size of the edge cut is minimised. Crucially,
unlike in our model, in this case the number of subsets in a feasible partition is fixed.
2.3 Our Main Results
Here, the main results of this paper are summarised. We start by observing that the
GCSG problem is NPcomplete on general graphs, even for edge sum valuation functions
(Section 3). Alongside the hardness result, we show thata general instance with |N | = n
nodes and |E| = e edges can be solved in time O n2 e+n
(see Theorem 3).
n
170

fiCoalition Structure Generation over Graphs

In order to improve the time required for solving the problem, we make use of tree
decompositions. We show that for a graph of n nodes with a tree decomposition of width
w, the GCSG problem is O(ww+O(1) n). This allows us to derive an upper bound on the
computational complexity of GCSG for certain classes of graphs, namely graphs of bounded
treewidth, graphs with separator theorems and, in particular, planar graphs and minorfree
graphs. We also show that the subclass of edge sum GCSG problems is NPhard over planar
graphs and hence, all Kk minorfree graphs for k  5 (see Section 5.1).
Planar graphs are an exceptional family where each graph can be drawn in the plane
without any edge crossing. Apart from some interesting mathematical properties such as,
for example, 4colourability and 3path separability, planar graphs have many practical
applications, including design problems for circuits, subways and utility lines. If a network
has crossing connections, it usually means that the edges must be run at different heights.
While this is not a big issue for electrical wires, it would create extra expenses for some
other types of linese.g., burying one subway tunnel under another (and therefore deeper
than one would normally need). Circuits, in particular, are easier to manufacture if their
connections live on fewer layers. Importantly, one may determine a graphs planarity using
the so called forbidden minor characterisation, by which a graph is planar if and only
if it does not contain the complete graph K5 nor the complete bipartite graph K3,3 as a
minor (Wagner, 1937).1 Remarkably, such forbidden minor characterisations exist for several graph families that vary in the nature of what is forbidden, and have been utilised in
combinatorial algorithms, often for identifying a structure (Robertson & Seymour, 1983,
1995, 2004). This motivates our particular interest in classes of minorfree graphs.
The next theorem is our main technical result.
Theorem 1 A general instance of a graph coalition structure generation problem over
a graph G with n nodes and a known tree decomposition of width w can be solved in
O(ww+O(1) n) computational steps.
This gives us the immediate corollary.
Corollary 1 For any fixed w, the GCSG problem over a graph G with n nodes and maximum treewidth w can be solved in O(n) computational steps.
The proof of these results is presented in Section 4. Coupled with known results regarding
separator theorems this gives the base to the following contributions (see Section 5 for
proofs).
Corollary 2 For any graph H with k vertices, an instance of the graph coalition structure

 n+O(1) )
generation problem over an Hminorfree
graph
G
with
n
nodes
requires
O(n
p
computation steps for  = 0.5k k/(1  2/3).
Corollary 3 A general instance of a graph coalitionstructure generation problem over a
 n+O(1) ) computation steps, for  =
planar
graph
p G with n nodes can be solved in O(n

2/(1  2/3).
1. This characterisation by Wagners theorem is closely related (but not equivalent) to Kuratowskis theorem, which states that a graph is planar if and only if it does not contain as a subgraph a subdivision of
K5 or K3,3 (Kuratowski, 1930).

171

fiVoice, Polukarov, & Jennings

However, for planar graphs we also prove the following hardness result.
Theorem 2 The class of edge sum graph coalition structure generation problems over planar graphs is NPcomplete. Moreover, a 3-SAT problem with m clauses can be represented
by a GCSG problem over a planar graph with O(m2 ) nodes.
Note that Theorem 2 holds for all Kk minorfree graphs where k  5, as planar graphs

are a special case. This means we should expect it to take time exponential in n to solve
a GCSG problem over such graphs of size n. This suggests that the methods given in

Corollaries 2 and 3, which solve these problems in time exponential in log(n) n, are close
to the best possible.
Against this background, the main contribution of our work is that it shows significant
improvement in complexity of exact algorithms for a general class of coalition structure generation problems characterised by a single assumption of the independence of disconnected
members on the valuation functions. In particular, our results are especially valuable for
graphs for which a tree decomposition of (low) width can be assessed.
The remaining sections describe our main results and techniques in more detail and
contain the proofs.

3. General Graphs
In this section, we examine the complexity of coalition structure generation over general
graphs. As a first step, we make a technical observation showing that without loss of
generality the problem can be restricted to a subset of coalition structures as follows.
Definition 3 For a graph G = (N, E), a coalition structure C over N is connected if the
induced subgraph of G over C is connected for all C  C.
Lemma 1 will then imply that the GCSG problem is equivalent to maximising the same
objective function over all connected coalition structures as in Definition 3. We note that
the lemma follows directly from Definition 1 of the IDM property and provide the full proof
in the appendix.
Lemma 1 Given a graph G = (N, E) and a coalition valuation function v() with the IDM
property, for any A, B  N if there are no edges in G between A \ B and B \ A, then
v(A)  v(A  B) = v(A  B)  v(B).
Note, under Definition 1, if v() is IDM and we have two coalitions B and C which are
disconnected, then by Lemma 1, v(B  C) = v(B) + v(C). So, for any coalition C, its value
v(C) is equal to the sum of v() over all its connected components. We can deduce that, for
any coalition structure C there exists a coalition structure D such that v(C) = v(D) and all
coalitions in D are connected subgraphs. Thus, without loss of generality, we can restrict
our attention to connected coalition structures. Moreover, if G is not a connected graph,
then we can solve any coalition structure problem over G with an IDM coalition valuation
function by finding the optimal coalition structure over each connected component of G
and combining the results. The operation of testing connectivity and finding connected
172

fiCoalition Structure Generation over Graphs

components is computationally tractable in polynomial time (Hopcroft & Tarjan, 1973),
and so, without loss of generality, we restrict our attention to connected graphs G.
For a (connected) graph G = (N, E) with a set of nodes N and a set of edges E, we
denote |N | = n and |E| = e. Next, we present a simple algorithm for constructing optimal
coalition structures over N , which is based on the following observation. Note that every
connected coalition structure over N can be expressed as the connected components of some
subgraph G0 = (N, E 0 ) of G, where E 0  E. Moreover, each connected component has a
spanning subtree, so we can restrict our attention to acyclic subgraphs of G. Given this,
Algorithm 1 below runs through all acyclic subgraphs of G and their connected components,
that correspond to connected coalition structures over the set of nodes N . We would like
to remark that the order in which the subgraphs of G are checked, has no effect on the
outcome, and so can be chosen arbitrarily. Thus, w.l.o.g., we initialise the procedure with
a coalition structure C = ({n1 }, . . . , {nn }) that corresponds to connected components of
subgraph G0 = (N, ) of G.
Algorithm 1 An algorithm for coalition structure generation over general graphs.
1:
INPUT: a connected undirected graph G = (N, E);
2:
an IDM coalition valuation function v : P(N )  R
3:
OUTPUT: an optimal connected coalition structure over N w.r.t. v
4:
C  ({n1 }, . . . , {nn })
5:
for all E 0  E such that G0 = (N, E 0 ) is acyclic
6:
find C(G0 ) = ({C1 }, . . . , {Ck0 })the collection of all connected components of G0
P 0
7:
if v (C(G0 )) = ki=1 v(Ci ) > v(C) then
8:
C  C(G0 )
9:
end if
10: end for
We show the following.
Theorem 3 Algorithm 1 solves a general instance of a GCSG problem in O n2
steps, using O(n log n) sized memory.

e+n
n



0
0
0
Proof : An acyclic subgraph
most
and
  E,a has
 ata+1
 n1aedges,


Pn1 e G = (N, E ) of G, where E
a
a+1
so there are at most k=0 k such subgraphs. Since b + b1 = b and b  b ,

2
this sum is bounded by e+n
determine the connected
n . Now, it takes at most O(n ) steps to 
e+n
2
components of a subgraph, and, thus, there are at most O n n
steps needed to check
each coalition structure. Finally, it takes at most O(n log n) sized memory to store each
coalition as it is checked.
2

Coupled with Corollary 2.3 in the paper by P. Stanica (2001), Theorem 3 implies the
following result for sparse graphs.
Corollary 4 For sparse graphs with e = cn edges, where c is a constant, the GCSG problem

c+1
.
is O n3/2 y n with a constant y = (c+1)
cc
This is an easy and not particularly promising result, as it may be exponential in n log(n)
and is exponential in n even for sparse graphs. Indeed, the class of graph coalition structure
173

fiVoice, Polukarov, & Jennings

generation problems is NPhard: it contains the subclass of GCSG problems over complete
graphs, which is equivalent to the NPcomplete class of standard coalition structure generation problems over node sets. Importantly, the problem remains hard even for simple
coalition valuation functions, such as the correlation function (Bansal et al., 2003). We note
that the same holds for the edge sum function as well: this result can be seen as a corollary
of Theorem 2 showing the hardness of the edge sum GCSG over planar graphs.

4. Tree Decompositions
We now consider solving the GCSG problem over graphs with known tree decompositions.
Specifically, we prove our main technical result (Theorem 1) giving a general bound for
the GCSG on these graphs, and then derive Corollary 1 regarding graphs with bounded
treewidth. The proof follows by recursively calculating the potential marginal contributions to total coalition structure valuation for each branch of a tree decomposition (see
Algorithm 2). To build the intuition, we first derive two technical lemmas. For brevity of
exposition, their proofs are presented in the Appendix.
Lemma 2 Let G = (N, E) be a graph with a tree decomposition (X, T ), where X =
{X1 , . . . , Xm } for m  n = |N | and T is a tree over X. Suppose further that the Xi are
numbered in order of shortest distance in T from X1 , where X1 may be chosen arbitrarily.
Then, for any C  N ,
v(C) =

m
X

v(C  Xi )  v C  Xi 

i=1

[


Xj .

j<i

Lemma 2 above will allow us to calculate the value of a total coalition structure from local
structures defined on branches of a tree decomposition. We now discuss how to construct
such a total structure from the local ones. We need the following notation.
For any graph G = (N, E), for any P, Q  N , if P is a coalition structure over P and
Q is a coalition structure over Q, then we define
U (P, Q) = {A  P : A  (P \Q)}{B  Q : B  (Q\P )}{AB : A  P, B  Q, AB 6= }.
That is, U (P, Q) is a collection of subsets of P  Q that agrees with P over P \ Q and with
Q over Q \ P , and contains all pairwise unions of subsets A  P and B  Q with non-empty
intersections. Note that U (P, Q) is not necessarily a coalition structure over P  Q, as the
union coalitions A  B, A  P, B  Q, need not be disjoint.
Furthermore, for a graph G = (N, E) and a coalition structure P over some subset of
nodes P  N , for any further subset P 0  P we will denote by P(P 0 ) a coalition structure
over P 0 defined as follows:
P(P 0 ) = {C  P 0 : C  P}.
That is, for any x, y  P 0  P , they belong to the same coalition in P(P 0 ) if and only if
they belong to the same coalition in P.
For illustration, consider the following example. Let N = {1, 2, 3, 4, 5}, take two subsets
P = {1, 2, 3} and Q = {3, 4, 5} of N , and define coalition structures P = {{1}, {2, 3}}
and Q = {{3, 4}, {5}} over P and Q, respectively. Note that {1}  P is a subset of
174

fiCoalition Structure Generation over Graphs

P \ Q, {5}  Q is a subset of Q \ P , and ({2, 3}  P)  ({3, 4}  Q) = {3}. Then,
U (P, Q) = {{1}, {5}, {2, 3}  {3, 4}} = {{1}, {5}, {2, 3, 4}}. Now, let P 0 = {1, 2}  P
and Q = {4, 5}  Q. Then, P(P 0 ) = {{1}  {1, 2}, {2, 3}  {1, 2}} = {{1}, {2}} and
Q(Q0 ) = {{3, 4}  {4, 5}, {5}  {4, 5}} = {{4}, {5}}.
Lemma 3 For any graph G = (N, E), for any P, Q  N , if P is a coalition structure over
P and Q is a coalition structure over Q, and if P(P  Q) = Q(P  Q), then E = U (P, Q)
is a coalition structure over P  Q and for any P 0  P , and Q0  Q, E(P ) = P(P 0 ) and
E(Q) = Q(Q0 ).
We are now ready to prove Theorem 1. To this end, below we present Algorithm 2 that,
given a graph with a known tree decomposition, finds best coalition structure over the node
set by recursively calculating the potential marginal contributions to total coalition structure valuation for each branch of a given tree decomposition. Lemma 4 below proves its
validity and computational bounds.

Algorithm 2 An algorithm for coalition structure generation over graphs with known tree
decompositions.
1:
INPUT: a connected undirected graph G = (N, E);
2:
a tree decomposition (X, T ) of G, where X = {X1 , . . . , Xm } for m  n,
3:
T is a tree over X, and 1  i < j  m  dT (Xi , X1 )  dT (Xj , X1 ), where
4:
for any 1  i  m, dT (Xi , X1 ) is the distance of Xi from X1
5:
an IDM coalition valuation function v : P(N )  R
6:
OUTPUT: an optimal connected coalition structure over N w.r.t. v
7:
for all 1  i  m
8:
Yi  Xi \ j<i Xj
9:
Zi  Xi \ Yi
10:
Di  {j > i : (Xi , Xj )  T }
11: for i = m, m  1, . . . , 1
12:
for all Ccoalition
P structures over Zi  P
13:
vi (C)  maxE CE v(C)  v(C \ Yi ) + jDi vj (E(Zj )),
14:
where E are coalition structures over Xi such that E(Yi ) = C
15: end for
16: C0  arg maxC v1 (C) where C are colition structures over Z1
17: for k = 1, . . . , m
18:
Ck  U (Ck1 , Ek ),
19:
where Ek is any coalition
 that
P structure over Xk such
P Ek (Zk ) = Ck1 (Zk )
20:
and vk (Ck1 (Zk )) = CEk v(C)  v(C \ Yk ) + jDk vj (Ek (Zj ))
21: end for
22: output Cm
Lemma 4 Algorithm 2 solves a general instance of a graph coalition structure generation problem over a graph G with n nodes and a known tree decomposition of width w in
O(ww+O(1) n) computational steps.
175

fiVoice, Polukarov, & Jennings

Proof : We are given a graph G = (N, E) with a tree decomposition (X, T ), where
X = {X1 , . . . , Xm } for m  n = |N | and T is a tree over X. Suppose for some w, |Xi | < w
for all i. We assume without loss of generality that the Xi are numbered in order of shortest
distance in T from X1 , where X1 may be chosen arbitrarily. Thus, for each i > 1, Xi has
exactly one link in T that connects to an Xj with j < i. For each i we define Yi to be
Xi \ j<i Xj and Zi to be Xi \ Yi . Note, for each i > 1 there exists a single j < i such that
Zi  Xj , and hence Zi = (Xj  Xi ). Since every node must be in at least one Xi , we have
that the union of the Yi is N . Finally, for each i, Di is the set of j > i such that (Xi , Xj )
is an edge in T .
Now, for each i = m, m  1, . . . , 1, the algorithm recursively define functions vi () which
give real values for each coalition structure over Zi . For C, a coalition structure over Zi , we
let vi (C) be the maximum of
X
 X
vj (E(Zj )),
v(C)  v(C \ Yi ) +
jDi

CE

over all coalition structures E over Xi such that E(Yi ) = C. Note for any j  Di , Zj =
(Xi Xj ), and hence, for any coalition structure E over Xi , E(Zj ) forms a coalition structure
over Zj .
Now, suppose C is a coalition structure over G. We will show that v(C)  v1 (C(Z1 )).
We do this by showing inductively that, for all k  1,
v1 (C(Z1 )) 

k
X
X

(v(C)  v(C \ Yi )) +

i=1 CC(Xi )

X

vj (C(Zj )).

(1)

jDi :j>k

For k = 1 this follows from the definition of v1 (), as C(X1 ) is a coalition structure over X1 .
Now it is sufficient to show that the right hand side of (1) does not increase as k increases.
For general k the change in the right hand side of (1) from the preceeding iteration is
X
X
(v(C)  v(C \ Yk )) +
vj (C(Zj ))  vk (C(Zk )).
jDk

CC(Xk )

It follows from the definition of vk () that this value is non-positive, as (C(Xk )) is a coalition
structure over Xk . Hence, the inductive proof is complete. Thus, we have shown that
v1 (C(Z1 )) 

m
X
X

(v(C)  v(C \ Yi )) = v(C),

i=1 CC(Xi )

by Lemma 2. So, the maximum of v1 (E) for coalition structures E over Z1 is greater than
or equal to the maximum value of v(C) over all coalition structures C over G.
Now, let C0 be a coalition structure over Z1 that maximises v1 (C). The algorithm
recursively defines coalition structures C1 , C2 , . . . Cm by setting, for all 1 < k  m, Ck =
U (Ck1 , Ek ), where Ek is any coalition structure over Xk such that Ek (Zk ) = Ck1 (Zk ) and
X
 X
vk (Ck1 (Zk )) =
v(C)  v(C \ Yk ) +
vj (Ek (Zj )).
CEk

jDk

176

fiCoalition Structure Generation over Graphs

We now want to show that
v1 (C(Z1 )) =

k
X

X

(v(C)  v(C \ Yi )) +

i=1 CCk (Xi )

X

vj (Ck (Zj )).

(2)

jDi :j>k

Again, we use induction. For k = 1, this follows from the definition of v1 (), by noting that
since C1 = U (C0 , E1 ), Lemma 3 implies that C1 (X1 ) = E1 (X1 ), but since both are coalition
structures over X1 , we must have C1 = E1 .
Now, for general k, since Ck = U (Ck1 , Ek ), we must have, for all i < k, Ck (Xi ) =
Ck1 (Xi ), and for all j  Di such that j  k, since Zj  Xi , we have, Ck (Zj ) = Ck1 (Zj ).
Thus, the change in the right hand side of (2) from the previous increment is equal to
X
X
(v(C)  v(C \ Yi )) +
vj (Ck (Zj ))  vk (Ck (Zk ))
=

CCk (Xk )

jDk

X

X

(v(C)  v(C \ Yi )) +

vj (Ek (Zj ))  vk (Ck1 (Zk )) = 0,

jDk

CEk (Xk )

by the definition of Ck and Ek . This completes this inductive proof.
So we have shown that
v1 (C(Z1 )) =

m
X

X

(v(C)  v(C \ Yi )) = v(Cm ).

i=1 CCm (Xi )

Since v1 (C(Z1 )) is an upper bound for v() over all coalition structures on N , we must have
that Cm is a solution to our coalition valuation problem.
Finally, in order to solve the coalition valuation problem, all that needs to be done is to
fully calculate vk () for each k from m down to 1, recording corresponding optimal coalition
structures for each value, and then optimise v1 (). To do this, for each k, we can go through
each coalition structure E over Xk , and then calculate
X
 X
v(C)  v(C \ Yi ) +
vj (E(Zj )).
CE

jDi

If this is greater than the currently held value for vk (E(Zk )), then replace that value and also
record E. This requires polynomial (in w) calculations for each possible coalition structure
over each node Xk , which gives O(ww+O(1) ) calculations for each Xk and thus O(ww+O(1) n)
calculations in total.
2
Theorem 1 follows immediately from Algorithm 2 and Lemma 4. Now, given any w,
for the class of graphs of maximum treewidth w, a tree decomposition with width at most
w may be found in linear time (Bern, Lawlerand, & Wong, 1987). Given this, Corollary 1
below is directly implied by Theorem 1.
Corollary 1 For any fixed w, the GCSG problem over a graph G with n nodes and maximum treewidth w can be solved in O(n) computational steps.

177

fiVoice, Polukarov, & Jennings

If we set w = 1, then this result applies to acyclic graphs, and is related to results of Demange (2004) regarding coalition structure generation over trees. However, Demange (2004)
does not make the IMD assumption. Their resulting algorithm is more complex than ours
and has potentially exponential running time. This is to be expected, as without the independence of disconnected members, the coalition structure generation problem over star
networks is necessarily exponential.
Note, if we set w = 2, then the class of graphs under consideration becomes the class
of K4 minorfree graphs. Likewise, the class of graphs of treewidth 1 may be characterised
as K3 minorfree. These results are in sharp contrast to Theorem 2 which shows NPcompleteness for the edge sum GCSG problem over planar graphs, which are a subset of
the class of K5 minorfree graphs. We give a proof of Theorem 2 in the next section.

5. Separator Theorems
In this section, we prove computational bounds for the GCSG problem over minorfree and
planar graphs. These graphs are guaranteed to contain vertex separators, as formalised by
Definition 4 below. Intuitively, this means that graphs in the corresponding class can be
split into smaller pieces by removing a small number of vertices. In general,
Definition 4 A class of graphs G satisfies an f (n)-separator theorem with constant  < 1
if for all G = (N, E)  G with |N | = n there exists a subset S  N such that |S|  f (n)
and N \ S = A  B for disjoint A and B where, |A|  n, |B|  n, and there exists no
x  A and y  B such that (x, y)  E.
To illustrate this, consider for example a grid graph G with r rows and c columns, where
n = rc is the number of nodes. If r is odd, then there is a single central row, and otherwise,
there are two rows equally close to the center; similarly, if c is odd, then there is a single
central column, and otherwise, there are two columns equally close to the center. Let a
node subset S be any of these central rows or columns. Removing S from the graph will
divide it into two smaller disjoint components, A and B, each of which has at most n/2

vertices. If r  c, then a central column defines a separator S with r  n vertices, and

similarly, if c  r, then a central row is a separator with at most n vertices. Thus, any

grid graph has a separator S of size at most n, the removal of which splits the graph
into two connected components, each of size at most n/2. That is, the class of grid graphs

satisfy a n-separator theorem with constant  = 1/2.
We now use Theorem 1 to derive Algorithm 3 and Lemma 5, which provide us with
a general result for classes of graphs that satisfy separator theorems. We will then apply
this result to the classes of minorfree and planar graphs, coupled with their corresponding
separator theorems, to obtain computational bounds on coalition structure generation over
these graphs.
Suppose we have a class of graphs G that is closed under taking subgraphs and satisfies
an f (n)-separator theorem with constant  < 1, where f (n) = nc for some constants
, c, and there exists an algorithm to find such a separator for any G  G with n nodes
in polynomial time. Given this, for any such graph G  G, Algorithm 3 below finds a
tree decomposition with treewidth w  nc /(1  c ) in polynomial time. Our procedure
is based on the proof of Theorem 20 in the work of Bodlaender (1998), which states that
178

fiCoalition Structure Generation over Graphs

for any such class of graphs G, the treewidth of any G  G with n nodes is O(f (n)). We
then apply Algorithm 2 to solve the GCSG problem for G with this tree decomposition in
O(ww+O(1) n) computational steps, which finally provides us with a computational bound
c

of O(n 1c n

c +O(1)

) time, as stated in Lemma 5 below.

Algorithm 3 An algorithm for coalition structure generation over graphs with separator
theorems.
1:
INPUT: a graph G = (N, E)  G; an IDM coalition valuation function v : P(N )  R
2:
OUTPUT: an optimal connected coalition structure over N w.r.t. v
3:
if n = 1 then
4:
X  ({x}), where x  N is the only node of G
5:
T0  G
6:
otherwise
7:
find S, a nc separator of G with N \ S = A  B where |A|  n and |B|  n
c nc
8:
find tree decompositions (X A , T A ) of A and (X B , T B ) of B, both of width  
1c
9:
T 0  T A  T B  {e0 } where e0 = {x, y}  E, x  A, y  B
10:
X A  {X  S : X  X A }
11:
X B  {X  S : X  X B }
12:
X  X A  X B
13: end if
14: apply Algorithm 2 to G with tree decomposition (X, T 0 )

Lemma 5 Let G be a class of graphs that is closed under taking subgraphs and satisfies an
f (n)-separator theorem with constant  < 1, where f (n) = nc for some constants , c, and
there exists an algorithm to find such a separator for any G  G with n nodes in polynomial
time. Then, Algorithm 3 solves a GCSG problem over a graph G  G with n nodes in
c
O(nn +O(1) ) time, for
c
=
.
1  c
Proof : Suppose we have a class of graphs G satisfying the statement of this lemma. There
must exist constants K and d >  log (2) such that for any G  G with n nodes, we can find
a nc separator, with constant , in Knd computational steps. Our proof then proceeds
by showing that, for any graph G  G with n nodes, Algorithm 3 (steps 313) finds a tree
decomposition with width less than or equal to nc /(1  c ) in at most Knd /(1  2d )
computational steps. We prove the result by induction.
For n = 1 no computational steps are required as G is already in tree form. For the nth
inductive step, suppose we have a G = (N, E) in G with |N | = n. In Knd computational
steps we can find S, a nc separator of G with N \ S = A  B where |A|  n and
|B|  n. By the inductive hypothesis, we can apply steps 313 of Algorithm 3 to find tree
decompositions (X A , T A ) and (X B , T B ) of the subgraphs A and B respectively, taking a
total time of 2Kd nd /(1  2d ), where (X A , T A ) and (X B , T B ) both have maximal width
c nc /(1  c ). Now, let X A = {X  S : X  X A }, let X B = {X  S : X  X B }, and
let T 0 be any tree formed by connecting T A and T B by a single edge. Then, we claim
179

fiVoice, Polukarov, & Jennings

(X A  X B , T 0 ) is a tree decomposition of G. For any a  A \ S, the set of elements of
X A that a appears in, forms a subtree of T A , and thus, the set of elements of X A  X B
that a appears in, must form a subtree of T 0 . By symmetry, the same holds for a  B \ S.
Further, for a  S, a appears in every element of X A  X B . Lastly, for each pair of nodes
connected by an edge in G, if those nodes both lie inside A or B, then they will both be
in some element of X A or X B respectively, otherwise at least one of those nodes must lie
in S, and so must be a member of every element of X A  X B . This proves our claim. The
tree decomposition (X A  X B , T 0 ) took at most
Knd +

2Kd nd
Knd
=
1  2d
1  2d

computational steps to find and has width at most
nc +

c nc
nc
=
,
1  c
1  c

as required. This completes our inductive proof.
Thus, for any G  G with n nodes, we can find a tree decomposition for G with treewidth
at most nc /(1  c ) in polynomial time. We can now apply Algorithm 2, to solve the
GCSG problem for a graph G  G with n nodes in O(ww+O(1) n) computational steps,
where w = nc /(1  c ). However,
ww =


c
c
c
ncn /(1 ) = O(nn ),
1  c
2

and so the statement of the lemma follows.

This result allows us to obtain computational bounds for the GCSG problem over minor
free and planar graphs as follows.
Corollary 2 For any graph H with k vertices, an instance of the graph coalition
 struc n+O(1) )
ture generation problem over anH minorfree
graph
G
with
n
nodes
requires
O(n
p
computation steps for  = 0.5k k/(1  2/3).
Proof : We apply Lemma 5 using the main result in the paper by Alon,Seymour and
Thomas (1990) where it was shown that the class of such graphs satisfies a k kn-separator

 n+O(1) )
theorem with
p Thus, we can solve a general instance of the problem in O(n
  = 2/3.
for  = k k/2(1  2/3), as required.
2
It should
 be noted that Proposition 4.5 of Alon, Seymour and Thomas (1990) gives a
bound of k kn on the treewidth of this class of graphs, but it is not constructive, so cannot
be combined with Theorem 1 as this requires a tree decomposition to be available.
For planar graphs, Corollary 3 provides a stronger result.
Corollary 3 A general instance of a graph coalition structure
generation problem over

a planar graph G with n nodes can be solved in O(n n+O(1) ) computation steps, for
180

fiCoalition Structure Generation over Graphs

=



2/(1 

p
2/3).

Proof : We apply Lemma 5 using the main result in the workof Lipton and Tarjan (1979)
where it was shown that the class of such graphs satisfies a 2 2n-separator theorem
with


n+O(1)
 =2/3. Thus,
) for
p we can solve a general instance of the problem in O(n
 = 2/(1  2/3), as required.
2
Recall that the class of planar graphs is equivalent to the class of K3,3 and K5 minorfree
graphs. For these graphs, Theorem 2 shows that the graph coalition structure generation
problem is NPcomplete, even for simple, edge sum, coalition valuation functions (the proof
of the theorem is presented in 5.1 below). However, as mentioned in the previous section,
the GCSG over smaller minorfree instances can be solved in linear time.
5.1 Planar Graphs
Here we prove NP-hardness result for planar graphs. Since planar graphs are K5 minor free,
the same hardness result must hold for the class Kk minorfree graphs for all k  5. The
proof proceeds by finding a representation of a general 3-SAT problem as a GCSG problem
over a planar graph.
Theorem 2 The class of edge sum graph coalition structure generation problems over planar graphs is NPcomplete. Moreover, a 3-SAT problem with m clauses can be represented
by a GCSG problem over a planar graph with O(m2 ) nodes.
Proof : Suppose we have a 3-SAT problem with clauses C1 , . . . Cm . We will construct an
edge sum graph coalition structure generation problem over a planar graph of O(m2 ) nodes
which, when solved, reveals a solution to the 3-SAT problem if one exists. We will use a
series of diagrams to define some components from which we can construct an appropriate
edge sum graph. Our diagrams will denote edge values using the symbols given in the key
in Figure 1.
The first component is given in Figure 2. We will use the symbol in Subfigure 2b to
represent three nodes that surround a subgraph with edge values given in Subfigure 2a. If
this is a subgraph of an edge sum problem graph, then the contribution these edge values
make to the valuation of a coalition structure is at most 2, with equality only if the induced
structure over the three outer nodes is as shown in one of Subfigure 2c, Subfigure 2d or
Subfigure 2e. If the induced coalition structure over these three nodes is not one of these
two structures, then the contribution will be less than 2. We similarly describe two more
triangular components in Figures 2, 4 and 5. The planar graph edge sum problem we
construct will be created from these components, some of which will be connected by edges
with value 1, others of which will overlap, in the sense that they will share nodes. We will
have components sharing nodes with each other, but they will not share edges. Moreover,
components can only share those nodes that form the triangle which borders the component.
If two components share a pair of such nodes, we will represent this symbolically by drawing
their symbols as being adjacent to each other along the corresponding side of the triangular
181

fiVoice, Polukarov, & Jennings

1
0
-2

(a) Edge values
Figure 1: Edge
value key.

(b) Symbol

(c) Optimum 1

(d) Optimum 2

(e) Optimum 3

Figure 2: Edge sum problem component.

(a) Edge values (b) Symbol (c) Optimum 1 (d) Optimum 2

(a) Edge values

(b) Symbol

(c) Optimum

Figure 4: Edge sum problem component.

Figure 3: Edge sum problem component.

symbols. So, the edges of the symbols of components will touch, but this does not mean
that those components share an edge within the graph.
For a graph consisting of these components, constructed in this way, we will say that
a coalition structure is locally optimal if the induced structure over every component is
optimal for that component and every connecting edge that is not part of a component
lies inside a coalition. For every coalition structure, for each component, the contribution
that the edges of that component make to the value of the coalition structure is bounded
by the local optimum. Thus, if a coalition structure is locally optimal then it must be
optimal. Furthermore, the coalition value of such a coalition structure is straightforward to
calculate - simply sum the local optimums of each component and connecting edge. Note,
the value obtained by doing this always represents an upper bound on the total valuation of
any coalition structure, thus if a locally optimal structure exists, then all optimal coalition
structures must be locally optimal. However, it is not guaranteed that a locally optimal
structure will exist.
With this in mind, it is now possible to provide some intuition regarding our components.
The component in Figure 5 is such that a coalition structure can not be locally optimal
unless the three nodes that form its outer triangle either all lie in the same coalition or all
in different coalitions. The component in Figure 3 is such that a coalition structure can not
be locally optimal unless exactly one of the bottom two nodes is in the same coalition as
the top node. The component in Figure 2 is similar to that in Figure 3, except it allows
the addition possibility that a locally optimal coalition structure has all three outer nodes
in different coalitions. For the component in Figure 4, a coalition structure can only be
locally optimal if the bottom two node are in the same coalition, and this coalition does
not contain the top node. We will now describe some constructs which are made from the
above described components. The first is given in Figure 6. It is such that in any locally
optimal coalition structure, nodes X and Y are always in the same coalition and the pair
of nodes labelled A lie in the same coalition as each other if and only if the pair of nodes
182

fiCoalition Structure Generation over Graphs

A

A

Y

X

(a)

Construc-

Y

X

B

B

(b) Symbol
(a) Construction

tion

(b) Optimum 1
A

Y

X

(c) Optimum 1

(d) Optimum 2

Figure 5: Edge sum problem
component.
B

(c) Optimum 2
Figure 6: Edge sum problem construct.

labelled B lie in the same coalition as each other. In our reduction of 3-SAT problems, we
will be representing logical states by whether or not certain pairs of agents lie in the same
coalition in a locally optimal coalition structure. This construct allows us to enforce that
two pairs represent the same logical state whilst also allowing a coalition to passes between
them in the plane.
The second and third constructs are given in Figures 7 and 8. In the second construct,
under a locally optimal coalition structure, if the pair of nodes labelled A are together in
the same coalition, then the pair of nodes labelled B are in the same coalition, and similarly
for the pair of nodes labelled C. If the pair of nodes labelled A are not in the same coalition,
then the pair of nodes labelled B are not in the same coalition, and similarly for the pair
of nodes labelled C. Thus, in our representation of a 3-SAT problem, in a locally optimal
solution the pairs of nodes labelled A, B and C will always represent the same logical state.
The third construct is similar, except that under a locally optimal coalition structure, the
state of whether or not the pair of nodes labelled C are in the same coalition as each other
is the opposite to the state of the other two pairs of nodes. Thus, in our representation
of a 3-SAT problem, in a locally optimal solution the pairs of nodes labelled A and B will
represent the same logical state, while C will represent the negation of that state. The last
construct is given in Figure 9. It is more complex than the other constructs, so we shall
first examine three subgraphs of it. The first part, AX, consists of the subgraph of the three
components from the pair of nodes labelled A to the pair of nodes labelled X, the second, BY
covers the three components from Y to B and CZ consists of the bottom two components.
Note the middle triangle in the diagram with edges X, Y, Z, is not a component, it is merely
183

fiVoice, Polukarov, & Jennings

A

A

A

B

B

B

C

C
(a) Construction

C

(b) Optimum 1

(c) Optimum 2

Figure 7: Edge sum construct.

B
A

B
A

B
A

C

C

(a) Construction

(b) Optimum 1

C
(c) Optimum 2

Figure 8: Edge sum construct.

empty space. Subfigures 9b9h show all the locally optimal coalition structures for each of
these three parts (with only the outer nodes for each component being shown). Since the
construct is the union of these three parts, if a coalition structure is locally optimal over
each of these subgraphs, then it is locally optimal over the whole construct. However, not
every combination of these local optimums is possible. For, if a coalition structure induces
Subfigure 9b over AX and Subfigure 9d over BY then the three node in triangle XYZ must lie
in the same coalition, and it is not possible for that coalition structure to induce Subfigure 9f.
For a locally optimal coalition structure, it cannot be true that each node in A, B and C lies
in a different coalition than the node it is paired with. Suppose we think of a pair of nodes
as representing a false state if they lie in the same coalition and a true state if they are in
different coalitions. Then, for a locally optimal coalition structure over this construct, at
least one of A, B and C must represent a true state. It is straightforward to check that
there exist locally optimal coalition structures over this construct that induce every possible
combination of states besides that where A, B and C are all represent falsehood. Thus, this
construct enforces a logical OR within our 3-SAT solution representation. We construct
our edge sum problem to represent a general 3-SAT problem as follows. We create a copy
of the construct in Figure 9 for each clause of the problem. The three pairs labelled A, B, C
are identified with the three literals in the corresponding clause. We identify a coalition
structure over these constructs with a set of logical values for the literals in the clauses by
saying that the literal associated with a pair of node is set as true if and only if those nodes
lie inside a single coalition. For each variable we create a path of copies of the constructs
184

fiCoalition Structure Generation over Graphs

X

A

Y

B

Z

X

A

A

X

C
(a) Construction

(b) AX: Optimum 1

(c) AX: Optimum 2

Z

Y
(d) BY: Optimum 1

B

Z

Z

B

Y

C

(e) BY: Optimum 2

C

C

(f) CZ: Optimum 1 (g) CZ: Optimum 2 (h) CZ: Optimum 3

Figure 9: Edge sum construct.

in Figures 7 and 8, where the pair of nodes labelled B for one component are shared and
labelled A in the following component. This path should include a copy of the construct
in Figure 7 for each literal representation of the variable, and a copy of the construct in
Figure 8 for each literal representation of the variables negation. We then connect each
pair of nodes that represents a literal representation of the variable or its negation to the
pair of nodes labelled C on its corresponding construct in the path, using a parallel pair of
connecting edges, each of value 1. This ensures that any locally optimal coalition structure
has to assign consistent logical values to literal representations of each variable and its
negative. To ensure that the resulting graph is planar, we can replace any two parallel
pairs of connecting edges which cross over each other with two copies of the construct in
Figure 6. For, if there are two copies of the construct in Figure 6 where the first copy shares
the nodes labelled B with the nodes labelled A in the second copy, then, under a locally
optimal coalition structure, the logical value represented by the nodes labelled A in the
first construct will equal the logical value represented by the nodes labelled B in the second
construct. Furthermore the logical value represented by the nodes labelled X in the two
constructs will equal the logical value of the nodes labelled Y in the two constructs. This
allows logical values to pass each other in the plane.
By construction, if a locally optimal coalition structure exists, then the original 3-SAT
problem must be satisfiable. Furthermore, if the 3-SAT problem is satisfiable, then we
can simply set each construct to the locally optimal coalition structure that agrees with
the logical value of the variables and their literals, and create a coalition structure for the
entire graph by taking the union of any overlapping coalitions. Note, this is always possible
by construction. The constructs in Figures 7 to 9 are designed so that under the induced
optimums, the nodes in A are never in the same coalition as a node from B or C, and the
nodes in B are never in the same coalition as a node from C. Moreover, the construct in
Figure 6 is such that in a locally optimal structure, coalition XY is always disjoint from the
nodes in A and B. This means that combining two locally optimal coalition structures that
agree across such pairs will only create coalitions that are local to the two pairs of nodes
being connected and the edges used to connect them. Thus, combining over several such
connections is always possible without contradiction.
185

fiVoice, Polukarov, & Jennings

B

B

A
!A

B

B

B

B

!B
B

!A
!A

C

!B
!C
!C

C
C

C
B

!A
C

C

Figure 10: Reduction of (A  B  B)  (!A!B!C)  (!A  B  C).

So, a locally optimal coalition structure exists if and only if the original 3-SAT problem
is satisfiable, and given any locally optimal coalition structure, we can identify a solution
to the 3-SAT problem. Furthermore, if a locally optimal coalition structure exists, then
a coalition structure is optimal if and only if it is locally optimal. The size of this graph
is O(m2 ) and thus the result follows. An example of this reduction process is shown in
Figure 10 for the 3-SAT problem (A  B  B)  (!A!B!C)  (!A  B  C).
2

6. Related Work
In this section, we give an overview of the related work, that can be broadly classified
under two main categories: clustering algorithms and algorithms for coalition structure
generation (CSG). The former is relevant to this work because it deals with partitioning
graph structures into subgraphs; however, unlike in our case, the values of such partitions
are determined by a certain, problemspecific valuation function. The latter, on the other
hand, considers more general valuation functions, but allows no structure on the primitive
set of elements.
In more detail, clustering is one of the primery tools in machine learning that deals
with finding a structure in a collection of unlabeled data. The goal is to organise objects
into groupsclusterswhose members are similar between them and are dissimilar to
the objects belonging to other clusters. In certain relevant scenarios, instead of the actual description of the objects, the relationships between them are known. Thus, like in
our work, the objects are typically represented by the node set of a signed graph, where
the edge labels indicate whether two connected nodes are similar or different. However,
clustering algorithms are usually designed for solving problems associated with particular
objectives (and hence, valuation functions)e.g., correlation or modularity that we mentioned in previous sections. In contrast, our work is concerned with a general class of
valuation functions, characterised by a single assumption of the independence of disconnected members. Thus, in particular, our Corollary 1 can be viewed as a generalisation of
the result by Xin (2011) providing a linear time algorithm for correlation clustering over
graphs with bounded treewidth. In this sense, the literature on the CSG problem that we
survey below, is perhaps more relevant to our research, as it deals with designing universal
186

fiCoalition Structure Generation over Graphs

algorithms, for which a valuation function is part of an input. However, on the other hand,
most of these works assume no structure on the primitive set of elements.
There have been several algorithms developed for CSG. Sandholm, Larson, Andersson,
Shehory and TohmeIn (1999), proposed an anytime procedure with worst case guarantees;
however, it only reaches an optimal solution after checking all possible coalition structures,
and so runs in time O(nn ). Specifically, given a graph where the node set represents coalition
structures, which are connected by an edge if and only if they belong to two consequtive
levels such that a coalition structure in level (i  1) can be obtained from the one in level i
by merging two coalitions into one, the algorithm firstly searches the two bottom levels, and
then explores the remaining levels one by one, starting from the top and moving downwards.
A similar algorithm was proposed by Dang and Jennings (2004): after searching the two
bottom and one top level, the algorithm goes through certain subsets of all remaining
levels (as determined by the sizes of coalitions present in their corresponding structures),
instead of searching the levels one by one. On the other hand, algorithms based on dynamic
programming (DP) (Yeh, 1986; Rothkopf, Pekec, & Harstad, 1998) work by iterating over
all coalition structures of size 1, and then over all those of size 2, and so on until size n: for
every such coalition C, the value of the coalition is compared to the value that could possibly
be obtained by splitting C into two coalitions. Visualising such a process with the graph of
coalition structures as before, we start from the bottom node and move upwards through a
series of connected nodes (a path) until an optimal node is reached. Importantly, if there
are multiple paths that lead to the same optimal node, then DP can reach it through any
of these paths. Based on this observation, an improved dynamic programming algorithm
(IDP) was developed by Rahwan and Jennings (2008b). The main idea of IDP is to remove
edges in the coalitions structure graph so that to disregard as many splittings of coalitions
as possible, yet without losing the guarantee of having a path that leads to every node
in the graph. This avoids counting approximately 2/3 of the operations compared to DP
that evaluates every edge in the coalition structure graph, meaning IDP can find an optimal
solution in O(3n ) time. However, DP and IDP algorithms are not anytimethat is, they do
not allow to trade computation time for solution quality. To this end, Rahwan, Ramchurn,
Giovannucci and Jennings (2009) developed the integer partition (IP) algorithm, which is
anytime. It works by dividing the search space into regions, according to the coalition
structure configurations based on the sizes of coalitions they contain, and then performing
branch-and-bound search. Although this procedure has the worst case complexity of O(nn ),
in practice, it is much faster than the DP based algorithms. Furthermore, the IP algorithm
was improved upon, by using DP for preprocessing (Rahwan & Jennings, 2008a). To date,
this combined algorithm, termed IDP-IP, is the fastest anytime algorithm, that is capable
of finding an optimal solution in O(3n ) time.
The CSG problem has also been tackled with heuristic methods. In particular, Sen and
Dutta (2000) gave a genetic algorithm that starts with an initial, randomly generated, set
of coalition structures, called a population, and then repeatedly evaluates every member
of the current population, selects members based on their evaluation, and constructs new
members from the selected ones by exchanging and/or modifying their contents. Keinnen (2009), based the process on Simulated Annealinga generic, stochastic local search
technique: at each iteration, the algorithm explores different neighbourhoods of a certain
coalition structure, where every neighbourhood is defined according to a different criterion.
187

fiVoice, Polukarov, & Jennings

On the other hand, Shehory and Kraus (1998) proposed a decentralised greedy procedure
where at each iteration, the best of all candidate coalitions (those that do not overlap with
coalitions currently present in the coalition structure) is added to the structure, and the
search is done in a distributive fashioni.e., the agents negotiate over which one of them
searches which coalitions. A significantly improved distribution mechanism was later on
proposed by Rahwan and Jennings (2007). Another greedy algorithm (Mauro, Basile, Ferilli, & Esposito, 2010) is based on GRASPa general purpose greedy algorithm that, after
each iteration, performs a quick local search to try and improve its solution (Feo & Resende,
1995). In the CSG version of GRASP, a coalition structure is constructed iteratively, where
every iteration consists of two steps: the first is to add the best candidate coalition to the
structure, and the second is to explore different neighbourhoods of the current structure.
These two iterations are repeated until the whole set of agents is covered, and then the whole
process is repeated to achieve better solutions. However, all these heuristic techniques do
not guarantee that the optimal value will be reached at any point, nor do they give the
means of evaluating the quality of the coalition structure selected.
An alternative approach to the CSG problem is to utilise compact representation schemes
for valuation functions proposed (Ohta, Conitzer, Ichimura, Sakurai, Iwasaki, & Yokoo,
2009). Indeed, in practice, these functions often display significant structure, and there
have been several methods developed to represent them concisely (e.g., by a set of rules
to compute the function or in terms of skills possessed by the agents or their types determining their possible contribution to a coalition). Thus, for marginal contribution nets,
or MC-nets (Ieong & Shoham, 2005), the CSG problem was formulated as a mixed integer
program (MIP) (Ohta et al., 2009), which can be solved reasonably well compared to the
IP algorithm, which does not make use of compact representations. However, in general
the problem stays NP-hard, which was also shown for other compact representations such
as synergy coalition groups (Conitzer & Sandholm, 2006) and skill games (Ohta, Iwasaki,
Yokoo, Maruono, Conitzer, & Sandholm, 2006; Bachrach, Meir, Jung, & Kohli, 2010) (for
the latter, the authors were also able to define a subclass of instances in which the problem
can be solved in time polynomial in the number of agents n and the number of skills k). For
agent-type representation, two dynamic programming algorithms were proposed to solve the
CSG problem (Aziz & de Keijzer, 2011; Ueda, Kitaki, Iwasaki, & Yokoo, 2011), and both
run in O(n2t ) time, where t is the number of different types.
Another interesting direction was to look at coalition structure generation in the framework of distributed constraint optimisation problems (DCOPs) that has recently become
a popular approach for modeling cooperative agents (Modi, 2003). Thus, Ueda, Iwasaki,
Yokoo, Silaghi and Matsui (2010) consider the CSG problem in a multi-agent system represented as one big DCOP, where every coalitions value is computed as the optimal solution
of the DCOP among the agents of that coalition. Instead of solving O(2n ) DCOPs, the
authors suggest modifying the big DCOP and solving it using existing algorithms, e.g.,
ADOPT (Modi, 2003) or DPOP (Petcu & Faltings, 2005).
On the other hand, Rahwan, Michalak, Elkind, Faliszewski, Sroka, Wooldridge and Jennings (2011) proposed the constrained coalition formation (CCF) framework, where there
are constraints on the coalition structures that can be formed. In particular, a CCF problem is given by a set of agents, the set of feasible coalition structures and the characteristic
function assigning values to coalitions that appear in some feasible coalition structures.
188

fiCoalition Structure Generation over Graphs

Although in the general case, the notion of feasibility is defined for coalition structures, in
many settings of interest the constraints implied on coalition structures can be reduced to
constraints on individual coalitionssuch settings are termed locally constrained. To represent the constraints succinctly, the authors propose the use of propositional logic. They
then define a natural subclass of locally constrained CCF problems for which they develop
an algorithm to solve the CSG problem which is based on divide-and-conquer techniques.
Finally, a couple of recent papers considered the problem of coalition structure generation on combinatorial structuresi.e., graphs. Thus, Aziz and de Keijzer (2011) showed
polynomial time bounds for coalition structure generation in contexts of spanning tree
games, edge path coalitional games and vertex path coalitional games, where the value of
a coalition of nodes is either 1 or 0, depending on whether or not it contains a spanning
tree, an edge path or a vertex path, respectively. The authors also prove NP-hardness of
the GCSG problem on general graphs with the edge sum valuation function. In this paper, we present a stronger result showing the hardness of the problem for planar graphs.
Independently, Bachrach, Kohli, Kolmogorov and Zadimoghaddam (2011) showed that the
coalition structure generation problem is intractable for planar graphs with the edge sum
valuation function, and also provided algorithms with constant factor approximations for
planar, minorfree and bounded degree graphs. However, in both aforementioned papers,
like in the classic literature on clustering, the problem is considered in a particular context
(i.e., is associated with a specific valuation function). In contrast, the results presented here
apply to a general class of valuation functions, characterised by a single assumption of the
independence of disconnected members.

7. Conclusions
A key organisational form in multi-agent systems involves members of the same coalition
coordinating their actions to achieve common goals. If the agents are organised effectively,
their cooperation can significantly improve the performance of each individual and a system
as a whole, especially in cases where single agents have insufficient skills or resources to complete the given tasks on their own. For this reason, generating good coalitional structures
is one of the fundamental problems studied in AI.
However, in many real-life scenarios, only certain subsets of agents are able to cooperate
and apply joint actions. Indeed, to act collectively, a group of agents has to 1) find a (most)
beneficial plan of action, 2) agree on it, and 3) coordinate actions among the members of
the group. Now, this may not be achievable by an arbitrary subset of agents which are
not connected or related to each other. Therefore, the study of coalition formation while
taking into consideration the social (or, communication) structure of the set of participants,
besides being a most natural and interesting research direction, may provide a key to many
positive results in terms of the problem tractability, as well as the quality and stability
of solutions. Moreover, this approach is obviously much more appealing from a practical
perspective than that of considering agents as interacting in a vacuum.
To this end, this paper studies the problem of coalition structure generation over graphs
(GCSG) and provides the foundation for analysis of its computational complexity. Our
work stands out from the existing literature on graph partitioning (or, clustering) in that
it does not focus on a specific coalition valuation function, but rather looks at a general
189

fiVoice, Polukarov, & Jennings

class of functions characterised by a single assumption of the independence of disconnected
members (IDM).
Our results show that in certain important cases it is indeed valuable to identify that the
valuation function satisfies the IDM property, as this significantly reduces the complexity
of the GCSG problem one faces. In particular,
Algorithm 1 uses a simple search procedure

with a guaranteed bound of O n2 e+n
computational
steps for general graphs with n
n
nodes and e edges. Hence, whenever the graph is sparse so that this bound gets lower
than 3n the number of steps required to solve the coalition structure generation problem
over an unstructured set of elementsutilising the graph structure is beneficial. For a
graph with n nodes and a known tree decomposition of width w, Algorithm 2 requires
O(ww+O(1) n) computational steps, implying that the problem can be solved in linear time
for bounded treewidth graphs! In addition, coupling Algorithm 2 with existing separator
theorems for minorfree and planar graphs, provides improved computational bounds for
coalition structure generation over these important graph classes, although, as we show in
Theorem 2, the problem remains NPcomplete even for planar graphs with simple edge sum
valuation functions.
Our work suggests several directions for future research on this topic. First, although the
theoretical bounds we give on complexity of the problem on minorfree and planar graphs
are close to best possible, they are not tight. Closing this gap would complete our results.
Second, and perhaps the main direction in this study, is exploring the approximability of the
GCSG problem for these and other interesting graph classes, and developing approximation
schemes where applicable. In this line, partial results are provided by Bachrach, Kohli,
Kolmogorov and Zadimoghaddam (2011) that give algorithms with constant factor approximations for planar, minorfree and bounded degree graphs endowed with the edge sum
valuation function. It is a challenging task to see if and how these results extend to a more
general class of the IDM functions. Finally, it would be interesting to incorporate the ideas
of compact representation (Ohta et al., 2009) and constrained coalition formation (Rahwan
et al., 2011) into graph coalition structure generation.

Appendix A
Lemma 1 Given a graph G = (N, E) and a coalition valuation function v() with the IDM
property, for any A, B  N if there are no edges in G between A \ B and B \ A, then
v(A)  v(A  B) = v(A  B)  v(B).

(3)

Proof : If B \ A =  then A  B = B and A  B = A, so the result holds. Now, let us
show that it holds when kB \ Ak = 1. Suppose otherwise, then let A and B be such that
kA \ Bk is minimal over A and B where kB \ Ak = 1 and (3) is violated. We cannot have
A \ B = , for otherwise A  B = A and A  B = B, which would imply that (3) holds. Let
x be some element of A \ B. Then, from the IDM property,
v(A)  v(A \ {x}) = v(A  B)  v((A  B) \ {x}),
190

(4)

fiCoalition Structure Generation over Graphs

but, by choice of A and B, the set A \ {x} must satisfy (3), and since x is not in B, we
then have
v(A \ {x})  v(A  B) = v((A  B) \ {x})  v(B).
(5)
Adding up (4) and (5) gives us that v(A)  v(A  B) = v(A  B)  v(B), a contradiction.
Now we will show that the result holds in general. Suppose otherwise, then let A and
B be such that kB \ Ak is minimal over A and B where (3) is violated. Let x be some
element of B \ A and let A0 = A  (B \ {x}). Now, A0  B = B \ {x} and A0  B = A  B.
Furthermore, B \ A0 = {x}, and so applying the results proven so far for the pair A0 , B, we
get
v(A0 )  v(A0  B) = v(A0  B)  v(B),
meaning
v(A  (B \ {x}))  v(B \ {x}) = v(A  B)  v(B).
Furthermore, by choice of A and B, and since x is not in A,
v(A)  v(A  B) = v(A  (B \ {x}))  v(B \ {x}).
These two relations prove that the result holds for A and B, which is a contradiction. This
completes the proof.
2
Lemma 2 Let G = (N, E) be a graph with a tree decomposition (X, T ), where X =
{X1 , . . . , Xm } for m  n = |N | and T is a tree over X. Suppose further that the Xi are
numbered in order of shortest distance in T from X1 , where X1 may be chosen arbitrarily.
Then, for any C  N ,
v(C) =

m
X

v(C  Xi )  v C  Xi 

i=1

[


Xj .

(6)

j<i

Proof : Towards a contradiction, let us suppose this result does not hold for some G.
Let (X, T ) be the tree decomposition with minimal m = kXk such that (6) is violated. If
m = 1, then X = {N } and equation (6) becomes
v(C) = v(C  N )  v(C  N  ),
which is trivially true. So we must have m > 1. From the choice of numbering, Xm must
be a leaf node in T . Let k be such that Xk is the only node Xm is connected to in T . Since
Xm \ Xk is disjoint from all Xi with i 6= m, there can be no edges in G between elements of
Xm \ Xk and S
Xk \ Xm . Furthermore, for any i < m such that i 6= k, Xm  Xi  Xm  Xk ,
and so Xm  j<m Xj = Xm  Xk and
Xk 

[

Xj = (Xm  Xk ) 

j<k

[
j<k

191

Xj .

fiVoice, Polukarov, & Jennings

Thus, for any C  N ,
v(C  Xm )  v(C  Xm 

[

Xj ) + v(C  Xk )  v(C  Xk 

j<m

[

Xj )

j<k

= v(C  Xm )  v(C  Xm  Xk ) + v(C  Xk )  v(C  (Xm  Xk ) 

[

Xj )

j<k

= v(C  (Xm  Xk ))  v(C  (Xm  Xk ) 

[

Xj ),

j<k

by Lemma 1. Furthermore, for all i < k,
[
[ 
Xi 
Xj = Xi  Xm 
Xj ,
j<i

j<i

and so,
m
X

v(C  Xi )  v C  Xi 

i=1

=

m1
X

[

Xj



j<i

v(C  Yi )  v C  Yi 

i=1

[


Yj ,

j<i

where Yi = Xi for i 6= k and Yk = Xk  Xm . However, these Yi form a tree decomposition
of G that has only m  1 nodes, (with the tree topology of T with the Xm leaf removed),
and thus this sum must equal v(C) by the choice of m. Since C was chosen arbitrarily, this
leads us to a contradiction, and the result must hold in general.
2
Lemma 3 For any graph G = (N, E), for any P, Q  N , if P is a coalition structure
over P and Q is a coalition structure over Q, and if P(P Q) = Q(P Q), then E = U (P, Q)
is a coalition structure over P  Q and for any P 0  P , and Q0  Q, E(P ) = P(P 0 ) and
E(Q) = Q(Q0 ).
Proof : Firstly, for all A  P, either A  (P \ Q) or there is some B  Q such that
A  B 6= . Thus, the union of all sets in E covers all of P . By symmetry, the union of all
sets in E must then also cover all of Q.
Now, for any P 0  P ,
E(P 0 ) = {(A  P 0 ) : A  P, A  (P \ Q)}  {(A  B)  P 0 : A  P, B  Q, A  B 6= }.
However, for any A  P, B  Q with A  B 6= , since P(P  Q) = Q(P  Q) is a coalition
structure over P  Q, we must have that A  (P  Q) = B  (P  Q). As B  Q, B  P 0 is
equal to (B  (P  Q))  P 0  A  P 0 . Thus,
E(P 0 ) = {(A  P 0 ) : A  P} = P(P 0 ).
By symmetry, for any Q0  Q, E(Q0 ) = Q(Q0 ).
192

fiCoalition Structure Generation over Graphs

It remains to show that E is a coalition structure. Towards a contradiction, suppose we
have some A, B  E such that A  B 6=  and A 6= B. Then, since E(P ) = P, and P is a
coalition structure, we must have either A  P = B  P or A  P and B  P are disjoint.
Likewise, either A  Q = B  Q or A  B  Q = . Now, if A  P = B  P and A  Q = B  Q,
then A = B and if A  B  P =  and A  B  Q = , then A  B = , both contradictions.
Suppose A  P = B  P and A  B  Q = . This implies that A  P = B  P is non-empty,
as A  B 6= , but it also implies that A  P  Q = B  P  Q = , which means, A  P is
an element of P that is a subset of P \ Q. However, the only element of E that would have
A  P as a subset would be A  P itself, meaning A = B = A  P , another contradiction.
By symmetry, having A  Q = B  Q and A  B  P =  also leads to a contradiction, and
therefore this scenario is impossible. Thus, we have shown that E is a coalition structure,
as required.
2

References
Alon, N., Seymour, P., & Thomas, R. (1990). A separator theorem for graphs with an
excluded minor and its applications. In Proceedings of 22nd ACM Symposium on
Theory of Computing, pp. 293299.
Aziz, H., & de Keijzer, B. (2011). Complexity of coalition structure generation. In In
10th International Joint Conference on Autonomous Agents and Multi-Agent Systems
(AAMAS), pp. 191198.
Bachrach, Y., Kohli, P., Kolmogorov, V., & Zadimoghaddam, M. (2011). Optimal coalition
structures in graph games. http://arxiv.org/abs/1108.5248.
Bachrach, Y., Meir, R., Jung, K., & Kohli, P. (2010). Coalitional structure generation
in skill games. In In 24th AAAI Conference on Artificial Intelligence (AAAI), pp.
703708.
Balas, E., & Padberg, M. W. (1976). Set partitioning: A survey. SIAM Rev., 18 (4), 710760.
Bansal, N., Blum, A., & Chawla, S. (2003). Correlation clustering. Machine Learning
Journal, 56 (1-3), 89113.
Bern, M. W., Lawlerand, E. L., & Wong, A. L. (1987). Linear-time computation of optimal
subgraphs of decomposable graphs. Journal of Algorithms, 8 (2), 216235.
Bodlaender, H. L. (1998). A partial k-arboretum of graphs with bounded treewidth. Theoretical Computer Science, 209 (1-2), 145.
Brandes, U., Delling, D., Gaertler, M., Gorke, R., Hoefer, M., Nikoloski, Z., & Wagner,
D. (2008). On modularity clustering. IEEE Transactions on Knowledge and Data
Engineering, 20 (2), 172188.
Conitzer, V., & Sandholm, T. (2006). Complexity of constructing solutions in the core
based on synergies among coalitions. Artificial Intelligence, 170 (6), 607619.
Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition
formation for efficient data fusion in multi-sensor networks. In AAAI-06, pp. 635
640.
193

fiVoice, Polukarov, & Jennings

Dang, V. D., & Jennings, N. R. (2004). Generating coalition structures with finite bound
from the optimal guarantees. In In 3rd International Joint Conference on Autonomous
Agents and Multi-Agent Systems (AAMAS), pp. 564571.
Demange, G. (2004). On group stability in heirarchies and networks. Journal of Political
Economy, 112 (4), 754778.
Deng, X., & Papadimitriou., C. (1994). On the complexity of cooperative solution concepts.
Mathematics of Operations Research, 19 (2), 257266.
Feo, T. A., & Resende, M. G. (1995). Greedy randomized adaptive search precedures.
Journal of Global Optimization, 6, 109133.
Hopcroft, J., & Tarjan, R. (1973). Efficient algorithms for graph manipulation. Communications of the ACM, 16 (6), 372378.
Ieong, S., & Shoham, Y. (2005). Marginal contribution nets: A compact representation
scheme for coalitional games. In Proceedings of the 6th ACM Conference on Electronic
Commerce (ACM EC), pp. 193202.
Keinanen, H. (2009). Simulated annealing for multi-agent coalition formation. In In 3rd
KES International Symposium on Agent and Multi-Agent Systems (KES-AMSTA),
pp. 3039.
Klusch, M., & Shehory, O. (1996). A polynomial kernel-oriented coalition formation algorithm for rational information agents. In In 2nd International Conference on MultiAgent Systems (ICMAS), pp. 157164.
Kuratowski, K. (1930). Sur le probleme des courbes gauches en topologie. Fundamenta
Mathematicae, 15, 271283.
Lipton, R. J., & Tarjan, R. E. (1979). A separator theorem for planar graphs. Journal of
Applied Mathematics, 36 (2), 177189.
Mauro, N. D., Basile, T. M. A., Ferilli, S., & Esposito, F. (2010). Coalition structure
generation with grasp. In In 14th International Conference on Artificial Intelligence:
Methodology, Systems, and Applications (AIMSA), pp. 111120.
Modi, P. J. (2003). Distributed constraint optimization for multiagent systems. Ph.D. thesis,
University of Southern California, Los Angeles, CA, USA.
Norman, T. J., Preece, A. D., Chalmers, S., Jennings, N. R., Luck, M., Dang, V. D., Nguyen,
T. D., Deora, J. S. V., Gray, W. A., & Fiddian, N. J. (2004). Agent-based formation
of virtual organisations. International Journal of Knowledge Based Systems, 17 (2-4),
103111.
Ohta, N., Conitzer, V., Ichimura, R., Sakurai, Y., Iwasaki, A., & Yokoo, M. (2009). Coalition structure generation utilizing compact characteristic funciton representations. In
Proceedings of the 15th International Joint Conference on Principles and Practice of
Constraint Programming, pp. 623638.
Ohta, N., Iwasaki, A., Yokoo, M., Maruono, K., Conitzer, V., & Sandholm, T. (2006). A compact representation scheme for coalitional games in open anonymous environments.
In In 21st National Conference on Artificial Intelligence (AAAI), pp. 697702.
194

fiCoalition Structure Generation over Graphs

Petcu, A., & Faltings, B. (2005). A scalable method for multiagent constraint optimization.
In In 19th International Joint Conference on Artificial Intelligence (IJCAI), pp. 266
271.
Rahwan, T., & Jennings, N. R. (2007). An algorithm for distributing coalitional values
calculations among cooperative agents. Artificial Intelligence, 171 (8-9), 535567.
Rahwan, T., & Jennings, N. R. (2008a). Coalition structure generation: Dynamic programming meets anytime optimisation. In In 23rd AAAI Conference on Artificial
Intelligence (AAAI), pp. 156161.
Rahwan, T., & Jennings, N. R. (2008b). An improved dynamic programming algorithm for
coalition structure generation. In Proceedings of the 7th International Conference on
Autonomous Agents and Multi-Agent Systems, pp. 14171420.
Rahwan, T., Michalak, T. P., Elkind, E., Faliszewski, P., Sroka, J., Wooldridge, M., &
Jennings, N. R. (2011). Constrained coalition formation. In In 25th AAAI Conference
on Artificial Intelligence (AAAI), pp. 719725.
Rahwan, T., Ramchurn, S. D., Giovannucci, A., & Jennings, N. R. (2009). An anytime
algorithm for optimal coalition structure generation. Journal of Artificial Intelligence
Research (JAIR), 34, 521567.
Robertson, N., & Seymour, P. (1983). Graph minors. i. excluding a forest. Journal of
Combinatorial Theory, Series B 35 (1), 3961.
Robertson, N., & Seymour, P. (1995). Graph minors. xiii. the disjoint paths problem.
Journal of Combinatorial Theory, Series B 63 (1), 65110.
Robertson, N., & Seymour, P. (2004). Graph minors. xx. wagners conjecture. Journal of
Combinatorial Theory, Series B 92 (2), 325357.
Rothkopf, M. H., Pekec, A., & Harstad, R. M. (1998). Computationally manageable combinatorial auctions. Management Science, 44 (8), 11311147.
Sandholm, T., Larson, K., Andersson, M., Shehory, O., & Tohme, F. (1999). Coalition
structure generation with worst case guarantees. Artificial Intelligence, 111 (1-2),
209238.
Sandholm, T., & Lesser, V. R. (1997). Coalitions among computationally bounded agents.
Artificial Intelligence, 94 (1-2), 99137.
Sen, S., & Dutta, P. (2000). Searching for optimal coalition structures. In In 6th International Conference on Multi-Agent Systems (ICMAS), pp. 286292.
Shehory, O., & Kraus, S. (1998). Methods for task allocation via agent coalition formation.
Artificial Intelligence, 101 (1-2), 165200.
Stanica, P. (2001). Good lower and upper bounds on binomial coefficients. Journal of
Inequalities in Pure and Applied Mathematics, 2 (3), Art. 30.
Tsvetovat, M., Sycara, K. P., Chen, Y., & Ying, J. (2001). Customer coalitions in the
electronic market place. In AA-01, pp. 263264.
Ueda, S., Iwasaki, A., Yokoo, M., Silaghi, M. C., & Matsui, T. (2010). Coalition structure
generation based on distributed constraint optimization. In In 24th AAAI Conference
on Artificial Intelligence (AAAI), pp. 197203.
195

fiVoice, Polukarov, & Jennings

Ueda, S., Kitaki, M., Iwasaki, A., & Yokoo, M. (2011). Concise characteristic function
representations in coalitional games based on agent types. In In 22nd International
Joint Conference on Artificial Intelligence (IJCAI), pp. 393399.
Wagner, K. (1937). Uber eine eigenschaft der ebenen komplexe. Mathematische Annalen,
114 (1), 570590.
Xin, X. (2011). An FPT algorithm for the correlation clustering problem. Key Engineering
Materials, Advanced Materials and Computer Science(474-476), 924927.
Yeh, D. Y. (1986). A dynamic programming approach to the complete set partitioning
problem. BIT Numerical Mathematics, 26 (4), 467474.
Yong, G., Li, Y., Weiming, Z., Jichang, S., & Changying, W. (2003). Methods for resource
allocation via agent coalition formation in grid computing systems. In In Proceedings of IEEE International Conference on Robotics, Intelligent Systems and Signal
Processing, Vol. 1, pp. 295300.

196

fiJournal of Artificial Intelligence Research 45 (2012) 443-480

Submitted 3/12; published 11/12

A New Look at BDDs for Pseudo-Boolean Constraints
Ignasi Abo
Robert Nieuwenhuis
Albert Oliveras
Enric Rodrguez-Carbonell

iabio@lsi.upc.edu
roberto@lsi.upc.edu
oliveras@lsi.upc.edu
erodri@lsi.upc.edu

Technical University of Catalonia (UPC), Barcelona.

Valentin Mayer-Eichberger

mayereichberger@gmail.com

Abstract
Pseudo-Boolean constraints are omnipresent in practical applications, and thus a significant effort has been devoted to the development of good SAT encoding techniques for
them. Some of these encodings first construct a Binary Decision Diagram (BDD) for the
constraint, and then encode the BDD into a propositional formula. These BDD-based approaches have some important advantages, such as not being dependent on the size of the
coefficients, or being able to share the same BDD for representing many constraints. We
first focus on the size of the resulting BDDs, which was considered to be an open problem
in our research community. We report on previous work where it was proved that there
are Pseudo-Boolean constraints for which no polynomial BDD exists. We also give an alternative and simpler proof assuming that NP is different from Co-NP. More interestingly,
here we also show how to overcome the possible exponential blowup of BDDs by coefficient decomposition. This allows us to give the first polynomial generalized arc-consistent
ROBDD-based encoding for Pseudo-Boolean constraints. Finally, we focus on practical
issues: we show how to efficiently construct such ROBDDs, how to encode them into
SAT with only 2 clauses per node, and present experimental results that confirm that our
approach is competitive with other encodings and state-of-the-art Pseudo-Boolean solvers.

1. Introduction
In this paperwe study Pseudo-Boolean constraints (PB constraints for short), that is, constraints of the form a1 x1 +    + an xn # K, where the ai and K are integer coefficients,
the xi are Boolean (0/1) variables, and the relation operator # belongs to {<, >, , , =}.
We will assume that # is  and the ai and K are positive since other cases can be easily
reduced to this one (see Een & Sorensson, 2006).
Such a constraint ( with positive coefficients) is a Boolean function C : {0, 1}n  {0, 1}
that is monotonic decreasing in the sense that any solution for C remains a solution after
flipping inputs from 1 to 0. Therefore these constraints can be expressed by a set of
clauses with only negative literals. For example, each clause could simply define a (minimal)
subset of variables that cannot be simultaneously true. Note however that not every such
a monotonic function is a PB constraint. For example, the function expressed by the two
clauses x1  x2 and x3  x4 has no (single) equivalent PB constraint a1 x1 +    + a4 x4  K
(since without loss of generality a1  a2 and a3  a4 , and then also x1  x3 is needed).
Hence, even among the monotonic Boolean functions, PB constraints are a rather restricted
class (see also Smaus, 2007).
c
2012
AI Access Foundation. All rights reserved.

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

PB constraints are omnipresent in practical SAT applications, not just in typical 0-1
linear integer problems, but also as an ingredient in new SAT approaches to, e.g., cumulative scheduling (Schutt, Feydy, Stuckey, & Wallace, 2009), logic synthesis (Aloul, Ramani,
Markov, & Sakallah, 2002) or verification (Bryant, Lahiri, & Seshia, 2002), so it is not
surprising that a significant number of SAT encodings for these constraints have been proposed in the literature. Here we are interested in encoding a PB constraint C by a clause
set S (possibly with auxiliary variables) that is not only equisatisfiable, but also generalized
arc-consistent (GAC): given a partial assignment A, if xi is false in every extension of A
satisfying C, then unit propagating A on S sets xi to false.
To our knowledge, the only polynomial GAC encoding so far was given by Bailleux,
Boufkhad, and Roussel (2009). Some other existing encodings are based on building (forms
of) Binary Decision Diagrams (BDDs) and translating these into CNF. Although the approach of Bailleux et al. is not BDD-based, our main motivation to revisit BDD-based
encodings is the following:
Example 1. Let us consider two Pseudo-Boolean constraints: 3x1 + 2x2 + 4x3  5 and
30001x1 + 19999x2 + 39998x3  50007. Both are clearly equivalent: the Boolean function
they represent can be expressed, e.g., by the clauses x1  x3 and x2  x3 . However, encodings
like the one of Bailleux et al. (2009) heavily depend on the concrete coefficients of each
constraint, and generate a significantly larger SAT encoding for the second one. Since,
given a variable ordering, ROBDDs are a canonical representation for Boolean functions
(Bryant, 1986), i.e., each Boolean function has a unique ROBDD, a ROBDD-based encoding
will treat both constraints equivalently.
Another reason for revisiting BDDs is that in practical problems numerous PB constraints exist that share variables among each other. Representing them all as a single
ROBDD has the potential of generating a much more compact SAT encoding that is moreover likely to have better propagation properties.
As we have mentioned, BDD-based approaches have already been studied in the literature. A good example is the work of Een and Sorensson (2006), where a GAC encoding
using six three-literals clauses per BDD node is given. However, when it comes to study
the BDD size, on page 9 they cite the work of Bailleux, Boufkhad, and Roussel (2006)
to say It is proven that in general a PB-constraint can generate an exponentially sized
BDD. In Section 7 we explain why the approach of Bailleux et al does not use ROBDDs,
and prove that the example they use to show the exponentiality of their method turns out
to have polynomial ROBDDs. Somewhat surprisingly, probably due to the different names
that PB constraints receive (0-1 integer linear constraints, linear threshold functions, weight
constraints, knapsack constraints), the work of Hosaka, Takenaga, and Yajima (1994) has
remained unknown to our research community. In that paper, it is proved that there are
PB constraints for which no polynomial-sized ROBDDs exist. For self-containedness of this
article, and to bring this interesting result to the knowledge of our research community, we
include this family of PB constraints and prove that, regardless of the variable ordering,
the corresponding ROBDD will always have exponential size.

444

fiA New Look at BDDs for Pseudo-Boolean Constraints

Main contributions and organization of this paper:
 Subsection 3.2: We reproduce the family of PB constraints proposed by Hosaka et al.
(1994), for which no polynomial-size ROBDD exist. For self-containedness, we give a
clearer alternative proof than in the original paper.
 Subsection 3.3: A very simple proof that, unless NP=co-NP, there are PB constraints
that admit no polynomial-size ROBDD, independently of the variable order.
 Subsection 4.1: A proof that PB constraints whose coefficients are powers of two do
admit polynomial-size ROBDDs.
 Subsections 4.2 and 4.3: A GAC and polynomial (size O(n3 log amax )) ROBDD-based
encoding for PB constraints.
 Section 5: An algorithm to construct ROBDDs for Pseudo-Boolean constraints in
polynomial time w.r.t. the size of the final ROBDD.
 Section 6: A GAC SAT encoding of BDDs for monotonic functions, a more general
class of Boolean functions than PB constraints. This encoding uses only one binary
and one ternary clause per node (the standard if-then-else encoding for BDDs used
in, e.g., Een & Sorensson, 2006, requires six ternary clauses per node). Moreover, this
translation works for any BDD variable ordering.
 Section 7: A related work section, summarizing the most important ingredients of the
existing encodings of Pseudo-Boolean constraints into SAT.
 Section 8: An experimental evaluation comparing our approach with other encodings
and tools.
This article extends the shorter preliminary paper BDDs for Pseudo-Boolean Constraints  Revisited (Abo, Nieuwenhuis, Oliveras, & Rodrguez-Carbonell, 2011), which
was presented at the SAT 2011 conference. Extensions include: (i) proofs of all technical
results, (ii) multiple examples illustrating the various concepts and algorithms presented,
(iii) the PB constraint family by Hosaka et al. (1994) for which no polynomial ROBDD exists, (iv) an algorithm to efficiently construct ROBDDs for Pseudo-Boolean constraints, (v)
a detailed related work section, (vi) extensive experimental results comparing our encoding
to other approaches and (vii) a brief report of our experience trying to take advantage of
the sharing potential of BDDs.

2. Preliminaries
Let X = {x1 , x2 , . . .} be a fixed set of propositional variables. If x  X then x and x are
positive and negative literals, respectively. The negation of a literal l, written l, denotes x
if l is x, and x if l is x. A clause is a disjunction of literals x1  . . .  xp  xp+1  . . .  xn ,
sometimes written as x1 . . . xp  xp+1 . . . xn . A CNF formula is a conjunction of clauses.
A (partial) assignment A is a set of literals such that {x, x}  A for no x, i.e., no
contradictory literals appear. A literal l is true in A if l  A, is false in A if l  A, and
is undefined in A otherwise. Sometimes we will write A as a set of pairs x = v, where v
445

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

x1

x1
1

0

0

x2
0

x3
0

x2
1

x3

1
0

1

1 0

x3
1

x2
1

0

0

0

x2
0

1

x3
1

0

x1

x3
0

1

1 0

x3

x2
1

0

1

1

0

0

x2
1

0

x3

x2

1
1

0

x3
0

1

0

x1
1

0

1

1

x3

1

0

0

1

1

0

Figure 1: Construction of a BDD for 2x1 + 3x2 + 5x3  6

is 1 if x is true in A and 0 if x is false in A. A clause C is true in A if at least one of
its literals is true in A. A formula F is true in A if all its clauses are true in A. In that
case, A is a model of F . Systems that decide whether a formula F has any model are called
SAT-solvers, and the main inference rule they implement is unit propagation: given a CNF
F and an assignment A, find a clause in F such that all its literals are false in A except
one, say l, which is undefined, add l to A and repeat the process until reaching a fixpoint.
Pseudo-Boolean constraints (PB constraints for short) are constraints of the form a1 x1 +
   + an xn # K, where the ai and K are integer coefficients, the xi are Boolean (0/1)
variables, and the relation operator # belongs to {<, >, , , =}. We will assume that #
is  and the ai and K are positive, since other cases can be easily reduced to this one 1 :
(i) changing into  is straightforward if coefficients can be negative; (ii) replacing ax by
a(1  x)  a; (iii) replacing (1  x) by x. Negated variables like x can be handled as positive
ones or, alternatively, replaced by a fresh x0 and adding the clauses x  x0 and x  x0 . A
particular case of Pseudo-Boolean constraints is the one of cardinality constraints, in which
all coefficients ai are equal to 1.
Our main goal is to find CNF encodings for PB constraints. That is, given a PBconstraint C, construct an equisatisfiable clause set (a CNF) S such that any model for
S restricted to the variables of C is a model of C and viceversa. Two extra properties
are sought: (i) consistency checking by unit propagation or simply consistency: whenever a
partial assignment A cannot be extended to a model for C, unit propagation on S and A
produces a contradiction (a literal l and its negation l); and (ii) generalized arc-consistency
or GAC (again by unit propagation): given an assignment A that can be extended to a
model of C, but such that A  {x} cannot, unit propagation on S and A produces x. More
concretely, we will use ROBDDs for finding such encodings. ROBDDs are introduced by
means of the following example.
Example 2. Figure 1 explains (one method for) the construction of a ROBDD for the PB
constraint 2x1 + 3x2 + 5x3  6 and the ordering [x1 , x2 , x3 ]. The root node has as selector
variable x1 . Its false child represents the PB constraint assuming x1 = 0 (i.e., 3x2 +5x3  6)
and its true child represents 2+3x2 +5x3  6, that is, 3x2 +5x3  4. The two children have
the next variable in the ordering (x2 ) as selector, and the process is repeated until we reach
1. An =-constraint can be split into a -constraint and a -constraint. Here we consider (generalized
arc-)consistency for the latter two isolatedly, not for the original =-constraint.

446

fiA New Look at BDDs for Pseudo-Boolean Constraints

the last variable in the sequence. Then, a constraint of the form 0  K is the True node
(1 in the figure) if K  0 is positive, and the False node (0) if K < 0. This construction
(leftmost in the figure), is known as an Ordered BDD. For obtaining a Reduced Ordered
BDD (ROBDD for short in the rest of the paper), two reductions are applied until fixpoint:
removing nodes with identical children (as done with the leftmost x3 node in the second BDD
of the figure), and merging isomorphic subtrees, as done for x3 in the third BDD. The fourth
final BDD is a fixpoint. For a given ordering, ROBDDs are a canonical representation of
Boolean functions: each Boolean function has a unique ROBDD. BDDs can be encoded into
CNF by introducing an auxiliary variable a for every node. If the selector variable of the
node is x and the auxiliary variables for the false and true child are f and t, respectively,
add the if-then-else clauses:
x  f
x  f

 a
 a

x  t  a
x  t  a

f
f

 t  a
 t  a

In what follows, the size of a BDD is its number of nodes. We will say that a BDD represents a PB constraint if they represent the same Boolean function. Given an assignment
A over the variables of a BDD, we define the path induced by A as the path that starts at
the root of the BDD and at each step, moves to the false (true) child of a node if and only
if its selector variable is false (true) in A.

3. Exponential ROBDDs for PB Constraints
In this section we study the size of ROBDDs for PB constraints. We start by defining the
notion of the interval of a PB constraint. Then, in Section 3.2 we consider two families of PB
constraints and study their ROBDD size: we first prove that the example given by Bailleux
et al. (2006) has polynomial ROBDDs, and then we reproduce the example of Hosaka et al.
(1994) that has exponential ROBDDs regardless of the variable ordering. Finally, we relate
the ROBDD size of a PB constraint with the well-known subset sum problem.
3.1 Intervals
Before formally defining the notion of interval of a PB constraint, let us first give some
intuitive explanation.
Example 3. Consider the constraint 2x1 + 3x2 + 5x3  6. Since no combination of its
coefficients adds to 6, the constraint is equivalent to 2x1 + 3x2 + 5x3 < 6, and hence to
2x1 + 3x2 + 5x3  5. This process cannot be repeated again since 5 can be obtained with the
existing coefficients.
Similarly, we could try to increase the right-hand side of the constraint. However, there
is a combination of the coefficients that adds to 7, which implies that the constraint is not
equivalent to 2x1 + 3x2 + 5x3  7. All in all, we can state that the constraint is equivalent
to 2x1 + 3x2 + 5x3  K for any K  [5, 6]. It is trivial to see that the set of valid Ks is
always an interval.
Definition 4. Let C be a constraint of the form a1 x1 +    + an xn  K. The interval of C
consists of all integers M such that a1 x1 +    + an xn  M , seen as a Boolean function, is
equivalent to C.
447

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

Similarly, given a ROBDD representing a PB constraint and a node  with selector
variable xi ,we will refer to the interval of  as all the integers M such that the constraint
ai xi +    an xn  M is represented (as a Boolean function) by the ROBDD rooted at .
In the following, unless stated otherwise, the ordering used in the ROBDD will be
[x1 , x2 , . . . , xn ].
Proposition 5. If [, ] is the interval of a node  with selector variable xi then:
1. There is an assignment {xj = vj }nj=i such that ai vi +    + an vn = .
2. There is an assignment {xj = vj }nj=i such that ai vi +    + an vn =  + 1.
3. There is an assignment {xj = vj }i1
j=1 such that K a1 v1 a2 v2   ai1 vi1  [, ]
4. Take h < . There exists an assignment {xj = vj }nj=i such that ai vi +    + an vn > h
and its path goes from  to True.
5. Take h > . There exists an assignment {xj = vj }nj=i such that ai vi +    + an vn  h
and its path goes from  to False.
6. The interval of the True node is [0, ).
7. The interval of the False node is (, 1]. Moreover, it is the only interval with
negative values.
Proof.

1. Since   1 does not belong to the interval of , the constraints
ai xi + ai+1 xi+1 +    + an xn    1
ai xi + ai+1 xi+1 +    + an xn  

are different. This means that there is a partial assignment satisfying the second one
but not the first one.
2. The proof is analogous to the previous one.
3. Take a partial assignment {x1 = v1 , . . . , xi1 = vi1 } whose path goes from the root
to . Therefore, by definition of the ROBDD,  is the ROBDD of the constraint
ai xi + ai+1 xi+1 +    + an xn  K  a1 v1      ai1 vi1 .
Therefore, by definition of the interval of ,
K  a1 v1  a2 v2      ai1 vi1  [, ].
4. Intuitively, this property states that, if h is not in the interval of , there is an
assignment that satisfies the ROBDD rooted at  but not the constraint ai xi +    +
an xn  h.
Since h does not belong to the interval of , the ROBDD of
C 0 : ai xi +    + an xn  h
is not . Therefore, there exists an assignment that either
448

fiA New Look at BDDs for Pseudo-Boolean Constraints

[5, 6]

[5, 6]

x1

x1

0

[5, 7]

0
1

x2
0

[0, )

1

0

0

x3 [0, 4]
0

x2

[5, 7]

1

[5,) x
3

1

(, 1]

1

[0, )

x2

1

[3, 4]

1

0

x3 [0, 4]
1

0

0

1

1

0

(, 1]

Figure 2: Intervals of the ROBDD for 2x1 + 3x2 + 5x3  6
(i) goes from  to False but satisfies C 0 ; or
(ii) goes to True but does not satisfy C 0 .
We want to prove that the assignment satisfies (ii). Assume that it satisfies (i). Since
it goes from  to False and  belongs to the interval of , it holds
ai vi +    + an vn > .
Since  > h, the assignment does not satisfy C 0 , which is a contradiction. Therefore,
the assignment satisfies (ii).
5. Take the assignment of the second point of this proposition. Since  + 1 does not
belong to the interval, the path of the assignment goes from  to False. Moreover,
ai vi +    + an vn =  + 1  h.
6. The True node is the ROBDD of the tautology. Therefore, it represents the PB
constraint 0  h for h  [0, ).
7. The False node is the ROBDD of the contradiction. Therefore, represents the PB
constraint 0  h for h  (, 1]. Moreover, ai xi +    + an xn < 0 is also a
contradiction, hence that constraint is also represented by the False node. Therefore,
there is no other node with an interval with negative values.
We now prove that, given a ROBDD for a PB constraint, one can easily compute the
intervals for every node bottom-up. We first start with a motivating example.
Example 6. Let us consider again the constraint 2x1 + 3x2 + 5x3  6. Assume that all
variables appear in every path from the root to the leaves (otherwise, add extra nodes as in the
rightmost BDD of Figure 2). Assume now that we have computed the intervals for the two
children of the root (rightmost BDD in Figure 2). This means that the false child of the root
is the BDD for 3x2 +5x3  [5, 7] and the true child the BDD for 3x2 +5x3  [3, 4]. Assuming
x1 to be false, the false child would also represent the constraint 2x1 +3x2 +5x3  [5, 7], and
assuming x1 to be true, the true child would represent the constraint 2x1 +3x2 +5x3  [5, 6].
Taking the intersection of the two intervals, we can infer that the root node represents
2x1 + 3x2 + 5x3  [5, 6].
449

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

More formally, the interval of every node can be computed as follows:
Proposition 7. Let a1 x1 + a2 x2 +    + an xn  K be a constraint, and let B be its ROBDD
with the order [x1 , . . . , xn ]. Consider a node  with selector variable xi , false child f (with
selector variable xf and interval [f , f ]) and true child t (with selector variable xt and
interval [t , t ]), as shown in Figure 3. The interval of  is [, ], with:
 = max{f + ai+1 +    + af 1 , t + ai + ai+1 +    + at1 },
 = min{f , t + ai }.
..

.
xi [, ]
0

xf
[f , f ]

1

xt
[t , t ]

Figure 3: The interval of a node can be computed from its childrens intervals.
Before moving to the proof, we want to note that if in every path from the root to the
leaves of the ROBDD all variables were present, the definition of  would be much simpler
( = max{f , t + ai }). The other coefficients are necessary to account for the variables
that have been removed due to the ROBDD reduction process.
Proof. Let us assume that [, ] is not the interval of . One of the following statements
should hold:
1. There exists h  [, ] that does not belong to the interval of .
2. There exists h <  belonging to the interval of .
3. There exists h >  belonging to the interval of .
We will now prove that none of these cases can hold.
1. Let us define
C 0 : ai xi +    + an xn  h.
If h does not belong to the interval, there exists an assignment {xj = vj }nj=i that
either satisfies C 0 and its path goes from  to False or it does not satisfy C 0 and its
path goes to True. Assume that the assignment satisfies C 0 and its path goes from 
to False (the other case is similar). There are two possibilities:
 The assignment satisfies vi = 0. Since h  , it holds
h  ai+1 vi+1      af 1 vf 1    ai+1 vi+1      af 1 vf 1
   ai+1      af 1  f .
450

fiA New Look at BDDs for Pseudo-Boolean Constraints

On the other hand, since h  ,
h  ai+1 vi+1      af 1 vf 1  h    f .
Therefore, h  ai+1 vi+1      af 1 vf 1 belongs to the interval of f . Since the
assignment {xf = vf , . . . , xn = vn } goes from f to False, we have:
af vf +    + an vn > h  ai+1 vi+1      af 1 vf 1
ai+1 vi+1 +    + af vf +    an vn > h
Hence, adding ai vi to the sum one can see that the assignment does not satisfy
C 0 , which is a contradiction.
 The case vi = 1 gives a similar contradiction.
2. By definition of , either h < f + ai+1 +    + af 1 or h < t + ai + ai+1 +    +
at1 . We will only consider the first case, since the other one is similar. Therefore,
h  ai+1      af 1 < f . Due to point 4 of Proposition 5, there exists an assignment
{xf = vf , . . . xn = vn } such that
af vf +    an vn > h  ai+1      af 1
and its path goes from f to True. Hence, the assignment
{xi = 0, xi+1 = 1, . . . , xf 1 = 1, xf = vf , . . . , xn = vn }
does not satisfy the constraint ai xi +    + an xn  h and its path goes from  to True.
By definition of interval, h cannot belong to the interval of .
3. This case is very similar to the previous one.

This proposition gives a natural way of computing all intervals of a ROBDD in a bottomup fashion. The procedure is initialized by computing the intervals of the terminal nodes
as detailed in Proposition 5, points 6 and 7.
Example 8. Let us consider again the constraint 2x1 + 3x2 + 5x3  6. Its ROBDD is
shown in the left-hand side of Figure 2, together with its intervals. For their computation,
we first compute the intervals of the True and False nodes, which are [0, ) and (, 1]
in virtue of Proposition 5. Then, we can compute the interval of the node having x3 as
selector variable with the previous propositions formula: 3 = max{0,  + 5} = 0, 3 =
min{, 1 + 5} = 4. Therefore, its interval is [0, 4].
In the next step, we compute the interval for the node with selector variable x2 : 2 =
max{0 + 5, 0 + 3} = 5, 2 = min{, 4 + 3} = 7. Thus, it its interval is [5, 7]. Finally, we
can compute the roots interval: 1 = max{5, 0 + 2 + 3} = 5, 1 = min{7, 4 + 2} = 6, that
is, [5, 6].
451

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

3.2 Some Families of PB Constraints and their ROBDD Size
We start by revisiting the family of PB constraints given by Bailleux et al. (2006), where
it is proved that, for their concrete variable ordering, their non-reduced BDDs grow exponentially for this family. Here we prove that ROBDDs are polynomial for this family, and that this is even independent of the variable ordering. The family is defined
P
by considering a, b and n positive integers such that ni=1 bi < a. The coefficients are
i = a + bi and the right-hand side of the constraint is K = a  n/2. We will first prove
that the constraint C : 1 x1 +    + n xn  K is equivalent to the cardinality constraint
C 0 : x1 +    + xn  n/2  1. For simplicity, we assume that n is even.
 Take an assignment satisfying C 0 . In this case, there are at most n/2  1 variables xi
assigned to true, and the assignment also satisfies C since:
1 x1 +    + n xn 

n
X
i=n/2+2

i = (n/2  1)a +

n
X
i=n/2+2

bi < K  a +

n
X

bi < K.

i=1

 Consider now an assignment not satisfying C 0 . In this case, there are at least n/2
true variables in the assignment and it does not satisfy C either:
1 x1 +    + n xn 

n/2
X
i=1

i = (n/2)  a +

n/2
X
i=1

bi > (n/2)  a = K.

Since the two constraints are equivalent and ROBDDs are canonical, the ROBDD representation of C and C 0 are the same. But the ROBDD of C 0 is known to be of quadratic
size because it is a cardinality constraint (see, for instance, Bailleux et al., 2006).
In the following, we present a family of PB constraints that only admit exponential
ROBDDs. This example was first given by Hosaka et al. (1994), but a clearer alternative
proof is given next. First of all, we prove a lemma that, under certain technical conditions,
gives a lower bound on the number of nodes of the ROBDD for a PB constraint.
Lemma 9. Let a1 x1 +    + an xn  K be a PB constraint, and let i be an integer with
1  i  n. Assume that every assignment {x1 = v1 , x2 = v2 , . . . , xi = vi } admits an
extension {x1 = v1 , . . . , xn = vn } such that a1 v1 +    + an vn = K. Let M be the number
of different results we can obtain adding some subset of the coefficients a1 , a2 , . . . , ai , i.e.,
M = |{

i
X

j=1

aj bj : bj  {0, 1}}|. Then, the ROBDD size with ordering [x1 , x2 , . . . , xn ] is at

least M .
Proof. Let us consider a PB constraint that satisfies the conditions of the lemma. We will
prove that its ROBDD has at least M distinct nodes by showing that any two assignments
of the form {x1 = v1 , . . . , xi = vi } and {x1 = v10 , . . . , xi = vi0 } with a1 v1 +    + ai vi 6=
a1 v10 +    + ai vi0 lead to different nodes in the ROBDD.
Assume that it is not true: there are two assignments {x1 = v1 , . . . , xi = vi } and
{x1 = v10 , . . . , xi = vi0 } with a1 v1 +    + ai vi < a1 v10 +    + ai vi0 such that their paths end
at the same node. Take the extended assignment A = {x1 = v1 , . . . , xn = vn } such that
a1 v1 +    an vn = K. Since A satisfies the PB constraint, the path it defines ends at the
452

fiA New Look at BDDs for Pseudo-Boolean Constraints

true node. However, the assignment A0 = {x1 = v10 , . . . , xi = vi0 , xi+1 = vi+1 , . . . , xn = vn }
does not satisfy the constraint, since
a1 v10 +    ai vi0 + ai+1 vi+1 +    an vn > a1 v1 +    + an vn = K.
However, the nodes defined by {x1 = v1 , . . . , xi = vi } and {x1 = v10 , . . . , xi = vi0 } were the
same, so the path defined by A0 must also end at the true node, which is a contradiction.
We can now show a family of PB constraints that only admits exponential ROBDDs.
Theorem 10. Let n be a positive integer, and let us define ai,j = 2j1 + 22n+i1 for all
1  i, j  2n; and K = (24n  1)n. Then, the PB constraint
2n X
2n
X
i=1 j=1

ai,j xi,j  K

has at least 2n nodes in any variable ordering.
Proof. It is convenient to describe the coefficients in binary notation:
2n

z

}|

2n

{

 0 1
 0 1

z

0 0
0 0

}|

 0
 1
.
..

1
0

{

a1,1 = 0
a1,2 = 0

0
0


a1,2n1 = 0
a1,2n = 0

0
0

 0 1
 0 1

0 1
1 0

 0
 0

0
0

a2,1 = 0
a2,2 = 0

0
0

 1 0
 1 0

0 0
0 0

1
0


a2,2n1 = 0
a2,2n = 0

 0
 1
.
..

0
0

 1 0
 1 0
.
..

0 1
1 0

 0
 0

0
0

a2n,2n = 1 0

 0 0

1 0

 0

0

K/n = 1 1

 1 1

1 1

 1

1



First of all, one can see that the sum of all the as is 2K.
Let us take an arbitrary bijection

F = (F1 , F2 ) : {1, 2, . . . , 4n2 }  {1, 2, . . . , 2n}  {1, 2, . . . , 2n},
and consider the ordering defined by it: [xF (1) , xF (2) , . . . , xF (4n2 ) ], where xF (k) = xF1 (k),F2 (k)
for every k. We want to prove that the ROBDD of the PB constraint with this ordering
has at least 2n nodes.
The proof will consist in showing that the hypotheses of Lemma 9 hold. That is, first
we show that for any variable ordering, we can find an integer s such that any assignment
453

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

to the first s variables can be extended to a full assignment that adds K. Then, we prove
that there are at least 2n different values we can add with the first s coefficients, as required
by Lemma 9.
Let us define bk with 1  k  2n as the position of the k-th different value of the tuple
(F1 (1), F1 (2), . . . , F1 (4n2 )). More formally,
bk =


1

if k = 1,

n
o
min r : F1 (r) 6 {F1 (b1 ), F1 (b2 ), . . . , F1 (bk1 )}

if k > 1.

Analogously, let us define c1 , . . . , c2n as
ck =


1

if k = 1,
n

o

min s : F2 (s) 6 {F2 (c1 ), F2 (c2 ), . . . , F2 (ck1 )}

if k > 1.

Let us denote by ir = F1 (br ) and js = F2 (cs ) for all 1  r, s  2n. Notice that
{i1 , i2 , . . . , i2n } and {j1 , j2 , . . . , j2n } are permutations of {1, 2, . . . , 2n}. Assume that bn  cn
(the other case is analogous), and take an arbitrary assignment {xF (1) = vF (1) , xF (2) =
vF (2) , . . . , xF (cn ) = vF (cn ) }. We want to extend it to a complete assignment such that
2

4n
X

aF (k) vF (k) = K.

k=1

Figure 4 represents the initial assignment. All the values are in the top-left square since
the assignment is undefined for all xir ,js with r > n or s > n. Extending the assignment so
that the sum is K amounts to completing the table in such a way that there are exactly n
ones in every column and row.
The assignment can be completed in the following way: first, complete the top left
square in any way, for instance, adding zeros to every non-defined cell. Then, copy that
square to the bottom-right square and, finally, add the complementary square to the other
two squares (i.e., write 0 instead of 1 and 1 instead of 0). Figure 5 shows the extended
assignment for that example.
More formally, the assignment is completed as follows:

vir ,js =



0




v

irn ,js


vir ,jsn






virn ,jsn

if
if
if
if

r, s  n and vir ,js was undefined,
r > n and s  n,
s > n and r  n,
r, s > n,

where 0 = 1 and 1 = 0.
Now, let us prove that it satisfies the requirements, i.e., the coefficients corresponding
to true variables in the assignment add exactly K. Let us fix r, s  n. Denote by i = ir ,
j = js , i0 = ir+n and j 0 = js+n .
 If vi,j = 0, by definition vi0 ,j = vi,j 0 = 1 and vi0 ,j 0 = 0. Therefore,
ai,j vi,j + ai0 ,j vi0 ,j + ai,j 0 vi,j 0 + ai0 ,j 0 vi0 ,j 0

= ai0 ,j + ai,j 0
0

0

= 22n+i 1 + 2j1 + 22n+i1 + 2j 1
ai,j + ai0 ,j + ai,j 0 + ai0 ,j 0
=
.
2
454

fiA New Look at BDDs for Pseudo-Boolean Constraints

i1

i2

j1

1

1

j2

0

...

jn

1

...

in

in+1

in+2

...

i2n

0

1

jn+1

jn+2

...

j2n

Figure 4: An arbitrary assignment. There is a 0, 1 or nothing at position (ir , js ) depending
on whether xir ,js is false, true or unassigned.

455

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

i1

i2

...

in

in+1

in+2

...

i2n

j1

1

1

0

0

0

0

1

1

j2

0

0

0

0

1

1

1

1

...

0

1

0

0

1

0

1

1

jn

0

0

1

0

1

1

0

1

jn+1

0

0

1

1

1

1

0

0

jn+2

1

1

1

1

0

0

0

0

...

1

0

1

1

0

1

0

0

j2n

1

1

0

1

0

0

1

0

Figure 5: Extended assignment. There are exactly n ones in every column and row.

 Analogously, if vi,j = 1,
ai,j vi,j + ai0 ,j vi0 ,j + ai,j 0 vi,j 0 + ai0 ,j 0 vi0 ,j 0 =

ai,j + ai0 ,j + ai,j 0 + ai0 ,j 0
.
2

Therefore,
2

2

4n
X
k=1

aF (k) vF (k)

4n
1X
a
= K.
=
2 k=1 F (k)

By Lemma 9, the number of nodes of the ROBDD is at least the number of different
results we can obtain by adding some subset of the coefficients aF (1) , aF (2) , . . . , aF (cn ) . Consider the set aF (c1 ) , aF (c2 ) , . . . , aF (cn ) . We will now see that all its different subsets add
different values, and hence the ROBDD size is at least 2n .
The sum of a subset of {aF (c1 ) , aF (c2 ) , . . . , aF (cn ) } is
S = aF (c1 ) v1 + aF (c2 ) v2 +    + aF (cn ) vn ,

vr  {0, 1}.

Let us look at the 2n last bits of S in binary notation: all the digits are 0 except for
the positions F2 (c1 ), F2 (c2 ), . . . , F2 (cn ), which are v1 , v2 , . . . , vn . Therefore, if two subsets
add the same, the 2n last digits of the sum are the same. This means that the values of
(v1 , . . . , vn ) are the same, and thus they are the same subset.
456

fiA New Look at BDDs for Pseudo-Boolean Constraints

3.3 Relation between the Subset Sum Problem and the ROBDD Size
In this section, we study the relationship between the ROBDD size for a PB constraint and
the subset sum problem. This allows us to, assuming that NP and co-NP are different,
give a much simpler proof that there exist PB constraints that do not admit polynomial
ROBDDs.
Lemma 9 and the exponential ROBDD example of Theorem 10 suggest that there is
a relationship between the size of ROBDDs and the number of ways we can obtain K by
adding some of the coefficients of the PB. It seems that if K can be obtained in a lot of
different ways, the ROBDD will be large.
In this section we explore another relationship between the problem of adding K with
a subset of the coefficients and the size of the ROBDDs. In a sense, we give a proof that
the converse of the last paragraph is not true: if NP and co-NP are different, there are
exponentially-sized ROBDDs of PB constraints with no subsets of their coefficients adding
K. Let us start by defining one version of the well-known subset sum problem.
Definition 11. Given a set of positive integers S = {a1 , . . . , an } and an integer K, the
subset sum problem of (K, S) consists in determining whether there exists a subset of
{a1 , . . . , an } that sums to exactly K.
It is well-known that the subset sum problem is NP-complete when K  2n , but there
are polynomial algorithms in n when K is also a polynomial in n. For a given subset
sum problem (K, S) with S = {a1 , . . . , an }, we can construct its associated PB constraint
a1 x1 +  +an xn  K. In the previous section we have seen one PB constraint family whose
coefficients can add K in an exponential number of ways, thus generating an exponential
ROBDD. Now, assuming that NP and co-NP are different, we will see that there exists a
PB constraint family with exponential ROBDDs in any ordering such that their coefficients
cannot add K. First, we show how ROBDDs can act as unsatisfiability certificates for the
subset sum problem.
Theorem 12. Let (K, S) be an UNSAT subset sum problem. Then, if a ROBDD for its
associated PB constraint has polynomial size, it can act as a polynomial unsatisfiability
certificate for (K, S).
Proof. We only need to show how, in polynomial time, we can check whether the ROBDD
is an unsatisfiability certificate for (K, S). For that, we note that the subset sum problem
is UNSAT if and only if the PB constraints
a1 x1 +    + an xn  K,

a1 x1 +    + an xn  K  1

are equivalent, and this happens if and only if their ROBDDs are the same. Therefore, we
have to show, in polynomial time, that the given ROBDD represents both constraints. It
can be done, for instance, by building the ROBDD (using Algorithm 1 of Section 5) and
comparing the ROBDDs.
The key point now is that, if we assume NP to be different from co-NP, there exists a
family of UNSAT subset sum problems with no polynomial-sized unsatisfiability certificate.
Hence, the family consisting of the associated PB constraints does not admit polynomial
ROBDDs.
457

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

Hence, PB constraints associated with difficult-to-certify UNSAT subset sum problems
will produce exponential ROBDDs. However, subset sum is NP-complete if K  2n . In
PB constraints from industrial problems usually K  nr for some r, so we could expect
non-exponential ROBDDs for these constraints.

4. Avoiding Exponential ROBDDs
In this section we introduce our positive results. We restrict ourselves to a particular class
of PB constraints, where all coefficients are powers of two. As we will show below, these
constraints admit polynomial ROBDDs. Moreover, any PB constraint can be reduced to
this class by means of coefficient decomposition.
Example 13. Let us take the PB constraint 9x1 + 8x2 + 3x3  10. Considering the binary
representation of the coefficients, this constraint can be rewritten into (23 x3,1 + 20 x0,1 ) +
(23 x3,2 ) + (21 x1,3 + 20 x0,3 )  10 if we add the binary clauses expressing that xi,r = xr for
appropriate i and r.
4.1 Power-of-two PB Constraints Do Have Polynomial-size ROBDDs
Let us consider a PB constraint of the form:
C : 20  0,1  x0,1 + 20  0,2  x0,2 +    + 20  0,n  x0,n
21  1,1  x1,1 + 21  1,2  x1,2 +    + 21  1,n  x1,n
...
m
m
2  m,1  xm,1 + 2  m,2  xm,2 +    + 2m  m,n  xm,n

+
+
+
 K,

where i,r  {0, 1} for all i and r. Notice that every PB constraint whose coefficients are
powers of 2 can be expressed in this way. Let us consider its ROBDD representation with
the ordering [x0,1 , x0,2 , . . . , x0,n , x1,1 , . . . , xm,n ].
Lemma 14. Let [, ] be the interval of a node with selector variable xi,r . Then 2i divides
 and 0   < (n + r  1)  2i .
Proof. By Proposition 5.1,  can be expressed as a sum of coefficients all of which are
multiples of 2i , and hence  itself is a multiple of 2i . By Proposition 5.7, the only node
whose interval contains negative values is the False node, and hence   0. Now, using
Proposition 5.3, there must be an assignment to the variables {x0,1 , . . . , xi,r1 } such that
20 0,1 x0,1 +    + 2i i,r1 xi,r1 belongs to the interval. Therefore:
  20 0,1 x0,1 +    + 2i i,r1 xi,r1  20 + 20 +    + 2i

= n20 + n21 +    + n2i1 + (r  1)  2i = n(2i  1) + 2i (r  1)

< 2i (n + r  1)

Corollary 15. The number of nodes with selector variable xi,r is bounded by n + r  1. In
particular, the size of the ROBDD belongs to O(n2 m).
458

fiA New Look at BDDs for Pseudo-Boolean Constraints

Proof. Let 1 , 2 , . . . , t be all the nodes with selector variable xi,r . Let [j , j ] the interval
of j . Note that such intervals are pair-wise disjoint since a non-empty intersection would
imply that there exists a constraint represented by two different ROBDDs. Hence we can
assume, without loss of generality, that 1 < 2 <    < t . Due to Lemma 14, we know
that j  j1  2i . Hence 2i (n + r  1) > t  t1 + 2i      1 + 2i (t  1)  2i (t  1)
and we can conclude that t < n + r.
4.2 A Consistent Encoding for PB Constraints
Let us now take an arbitrary PB constraint C : a1 x1 +    an xn  K and assume that aM
is the largest coefficient. For m = log aM , we can rewrite C splitting the coefficients into
powers of two as shown in Example 13:
C :

20  0,1  x0,1
21  1,1  x1,1
2m  m,1  xm,1

20  0,2  x0,2 +    + 20  0,n  x0,n
21  1,2  x1,2 +    + 21  1,n  x1,n
...
+ 2m  m,2  xm,2 +    + 2m  m,n  xm,n

+
+

+
+
+
 K,

where m,r m1,r    0,r is the binary representation of ar . Notice that C and C represent
the same constraint if we add clauses expressing that xi,r = xr for appropriate i and r. This
process is called coefficient decomposition of the PB constraint. A similar idea was given
by Bartzis and Bultan (2003).
The important remark is that, using a consistent SAT encoding of the ROBDD for C
(e.g. the one given in Een & Sorensson, 2006, or the one presented in Section 6) and adding
clauses expressing that xi,r = xr for appropriate i and r, we obtain a consistent encoding
for the original constraint C using O(n2 log aM ) auxiliary variables and clauses.
This is not difficult to see. Take an assignment A over the variables of C which cannot
be extended to a model of C. This is because the coefficients corresponding to the variables
true in A add more than K. Using the clauses for xi,r = xr , unit propagation will produce
an assignment to the xi,r s that cannot be extended to a model of C. Since the encoding
for C is consistent, a false clause will be found. Conversely, if we consider an assignment A
over the variables of C that can be extended to a model of C, this assignment can clearly
be extended to a model for C and the clauses expressing xi,r = xr . Hence, unit propagation
on those clauses and the encoding of C will not detect a false clause.
Example 16. Consider the PB constraint C : 2x1 + 3x2 + 5x3  6. For obtaining the
consistent encoding we have presented, we first rewrite C by splitting the coefficients into
powers of two:
C 0 : 1x0,2 + 1x0,3 + 2x1,1 + 2x1,2 + 4x2,3  6.

Next, we encode C 0 into a ROBDD and finally encode the ROBDD into SAT and add clauses
for enforcing the relations xi,j = xj . Or, instead of that, we can replace xi,j by xj into the
ROBDD, and encode the result into SAT. Figure 6 shows the decision diagram after the
replacement.
4.3 A Generalized Arc-consistent Encoding for PB Constraints
Unfortunately, the previous approach does not result in a GAC encoding. The intuitive
idea can be seen in the following example:
459

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

x2
0

0

x3

1
1

x1 1

0

x1
1

0

0

x2

1

0

1

x3
1

0

Figure 6: Decision Diagram of 2x1 + 3x2 + 5x3  6 after decomposing the coefficients into
powers of two.

Example 17. Let us consider the constraint 3x1 + 4x2  6. After splitting the coefficients
into powers of two, we obtain C 0 : x0,1 + 2x1,1 + 4x2,2  6. If we set x2,2 to true, C 0 implies
that either x0,1 or x1,1 have to be false, but the encoding cannot exploit the fact that both
variables will receive the same truth value and hence both should be propagated. Adding
clauses stating that x0,1 = x1,1 does not help in this sense.
In order to overcome this limitation, we follow the method presented by Bessiere, Katsirelos, Narodytska, and Walsh (2009) and Bailleux et al. (2009). Let C : a1 x1 +  +an xn 
K be an arbitrary PB constraint. We denote as Ci the constraint a1 x1 +    + ai  1 +    +
an xn  K, i.e., the constraint assuming xi to be true. For every i with 1  i  n, we
encode Ci as in Section 4.2 and, in addition, we add the binary clause ri  xi , where ri is
the root of the ROBDD for Ci . This clause helps us to preserve GAC: given an assignment
A such that A  {xi } cannot be extended to a model of C, literal ri will be propagated
using A (because the encoding for Ci is consistent). Hence the added clause will allow us
to propagate xi .
Example 18. Consider again the PB constraint C : 2x1 + 3x2 + 5x3  6. Let us define the
constraints C1 : 3x2 + 5x3  4, C2 : 2x1 + 5x3  3 and C3 : 2x1 + 3x2  1. Now, we encode
these constraints into ROBDDs as in the previous section, with coefficient decomposition.
Figure 7 shows the resulting ROBDDs. Finally, we need to encode them into SAT consistently, and then add the clauses ri  xi , assuming that the variable associated with the root
of the ROBDD for Ci is ri .
This encoding is GAC: take for instance the assignment A = {x1 = 1}. Constraint C3 is
not satisfied. Hence, by consistency, r3 is propagated. Therefore, clause r3  x3 propagates
x3 , as wanted. The propagation with other assignments is similar.
All in all, the suggested encoding is GAC and uses O(n3 log(aM )) clauses and auxiliary
variables, where aM is the largest coefficient.
460

fiA New Look at BDDs for Pseudo-Boolean Constraints

r1
x2

r2
x3

0

0

1

x3
0

x2

1

0

0
0

1

1

1

1

x2

1

0

1

0

x3
0

1

r3
x1

1

0

Figure 7: ROBDDs2 of C1 , C2 and C3 with coefficient decomposition.

5. An Algorithm for Constructing ROBDDs for Pseudo-Boolean
Constraints
Let us fix a Pseudo-Boolean constraint a1 x1 +    + an xn  K and a variable ordering
[x1 , x2 , . . . , xn ]. The goal of this section is to prove that one can construct the ROBDD of
this constraint using this ordering in polynomial time with respect to the ROBDD size and
n.
This algorithm builds standard ROBDDs, but it can be used to build ROBDDs with
coefficient decomposition: we just need to first split the coefficients and, secondly, apply
the algorithm. Forthcoming Example 21 shows in detail the overall process. A very similar
version of this algorithm was described by Mayer-Eichberger (2008).
The key point of the algorithm will be to label each node of the ROBDD with its
interval. In the following, for every i  {1, 2, . . . , n + 1}, we will use a set Li consisting
of pairs ([, ], B), where B is the ROBDD of the constraint ai xi +    + an xn  K 0 for
every K 0  [, ] (i.e., [, ] is the interval of B). All these sets will be kept in a tuple
L = (L1 , L2 , . . . , Ln+1 ).
Note that by definition of the ROBDDs intervals, if ([1 , 1 ], B1 ) and ([2 , 2 ], B2 ) belong
to Li then either [1 , 1 ] = [2 , 2 ] or [1 , 1 ]  [2 , 2 ] = . Moreover, the first case holds if
and only if B1 = B2 . Therefore, Li can be represented with a binary search tree-like data
structure, where insertions and searches can be done in logarithmic time. The function
search(K, Li ) searches whether there exists a pair ([, ], B)  Li with K  [, ]. Such a
tuple is returned if it exists, otherwise an empty interval is returned in the first component
of the pair. Similarly, we will also use function insert(([, ], B), Li ) for insertions. The
overall algorithm is detailed in Algorithm 1 and Algorithm 2:
Theorem 19. Algorithm 1 runs in O(nm log m) time (where m is the size of the ROBDD)
and is correct in the following sense:
2. Actually, the diagram after replacing the variables xi,j by xj is not a ROBDD. However, we will denote
them as ROBDDs for simplicity.

461

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

Algorithm 1 Construction of ROBDD algorithm
Require: Constraint C : a1 x1 + . . . + an xn  K 0
Ensure: returns B the ROBDD of C.
1: for all insuch that 1  i  n + 1 do

 
o
2:
Li 
(, 1], F alse , [ai + ai+1 +    + an , ), T rue
3: end for
4: L  (L1 , . . . , Ln+1 ).
5: ([, ], B)  BDDConstruction(1, a1 x1 + . . . + an xn  K 0 , L).
6: return B.

Algorithm 2 Procedure BDDConstruction
Require: integer i  {1, 2, . . . , n + 1}, constraint C : ai xi + . . . + an xn  K 0 and set L
Ensure: returns [, ] interval of C and B its ROBDD
1: ([, ], B)  search(K 0 , Li ).
2: if [, ] 6=  then
3:
return ([, ], B)
4: else
5:
([F , F ], BF ) := BDDConstruction(i + 1, ai+1 xi+1 + . . . + an xn  K 0 , L).
6:
([T , T ], BT ) := BDDConstruction(i + 1, ai+1 xi+1 + . . . + an xn  K 0  ai , L).
7:
if [T , T ] = [F , F ] then
8:
B  BT
9:
[, ]  [T + ai , T ]
10:
else
11:
B  ite(xi , BT , BF ) // root xi , true branch BT and false branch BF .
12:
[, ]  [F , F ]  [T + ai , T + ai ]
13:
end if
14:
insert(([, ], B), Li )
15:
return ([, ], B)
16: end if

462

fiA New Look at BDDs for Pseudo-Boolean Constraints

1. K 0 belongs to the interval returned by BDDConstruction(ai xi +  +an xn  K 0 , L).
2. The tuple ([, ], B) returned by BDDConstruction consist of a BDD B and its
interval [, ].
3. If BDDConstruction returns ([, ], B), then the BDD B is reduced.
Proof. Let us first start with the three correctness statements:
1. If K 0 is found in Li at line 1 of Algorithm 2 the statement is obviously true. Otherwise
let us reason by induction on i. The base case is when i = n + 1, and since Ln+1
contains the intervals (, 1] and [0, ], the search call at line 1 will succeed and
hence the result holds. For i < n + 1 we can assume, by induction hypothesis, that
K 0  [F , F ] and K 0 ai  [T , T ]. If the two intervals coincide the result is obvious,
otherwise it is also easy to see that K 0  [F , F ]  [T + ai , T + ai ].
2. Let us prove that in every moment all the tuples of L are correct, i.e., they contain
BDDs with their correct interval. Since the returned value is always an element of
some Li , this proves the statement.
By Proposition 5.6 and 5.7, initial tuples of L are correct. We have to prove that if
all the previously inserted intervals are correct, the current interval is also correct. It
follows in virtue of Proposition 7.
3. Let us prove that all the tuples of L contain only reduced BDDs. As before, all the
initial BDDs in L are reduced. Let B be a BDD computed by the algorithm, with
children BT and BF . By induction hypothesis, they are reduced, so B is reduced if
and only if its two children are not equal. The algorithm creates a node only if its
childrens intervals are different. Therefore, BT and BF do not represent the same
Boolean constraint, so they are different BDDs.
Regarding runtime, since the cost of search and insertion in Li is logarithmic in its size, the
cost of the algorithm is O(log m) times the number of calls to BDDConstruction. Hence,
it only remains to show that there are at most O(nm) calls.
Every call (but the first one) to BDDConstruction is done when we are exploring an
edge of the ROBDD. Notice that no edge is explored twice, since the edges are only explored
from the parent node and whenever we reach an explored node there are no recursive calls
to BDDConstruction. On the other hand, for every edge of the ROBDD we make 2k  1
calls, where k is the length of the edge (if the nodes joined by the edge have variables xi
and xj we say that its length is |i  j|). Since the ROBDD has O(m) edges and their length
is O(n), the number of calls is O(nm).
Let us illustrate the algorithm with an example:
Example 20. Take the constraint C : 2x1 + 3x2 + 5x3  6, and let us apply the algorithm
to obtain the ROBDD in the ordering [x1 , x2 , x3 ]. Figure 8 represents the recursive calls to
BDDConstruction and the returned parameters (the ROBDD and the interval).
463

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

1. BDDConstruction(1, 2x1 + 3x2 + 5x3  6, L)
x1 [5, 6]
0

1

x2
0

1

x3
0

1

1

0

2. BDDConstruction(2, 3x2 + 5x3  6, L)

7. BDDConstruction(2, 3x2 + 5x3  4, L)

x2 [5, 7]
0

x3 [2, 4]

1
0

x3
0

1

1

3. BDDConstruction(3, 5x3  6, L)

1

1

0

0

4. BDDConstruction(3, 5x3  3, L)
x3
0

1 [5, )
1

5. BDDConstruction(4, 0  3, L)

8. BDDConstruction(3, 5x3  4, L)

[0, 4]

x3
0

1

1

0

9. BDDConstruction(3, 5x3  1, L)

[0, 4]

0

6. BDDConstruction(4, 0  2, L)

1 [0, )

0 (, 1]

Figure 8: Recursive calls to BDDConstruction, with the returned values.

464

x3 [0, 4]
0

1

1

1

0

fiA New Look at BDDs for Pseudo-Boolean Constraints

 In calls number 3, 5, 6, 8 and 9, the search function returns true and the interval and
the ROBDD are returned without any other computation.
 In call number 7, the two recursive calls return the same interval (and, therefore, the
same ROBDD). Hence, that ROBDD is returned.
 In call number 1 the two recursive calls return two different ROBDDs, so it adds a
node to join the two ROBDDs into another one, which is returned. The same happens
in calls number 2 and 4.
The overall process with coefficient decomposition would work as in the following example:
Example 21. Let us take the constraint C : 2x1 + 3x2 + 5x3  6. If we want to build the
ROBDD with coefficient decomposition using Algorithm 1, we proceed as follows:
1. Split the coefficients and obtain C 0 : 1y1 + 1y2 + 2y3 + 2y4 + 4y5  6, where x1 = y3 ,
x2 = y1 = y4 and x3 = y2 = y5 .
2. Apply the algorithm to C 0 and obtain a ROBDD B 0 .
3. Replace y1 for x2 , y2 for x3 , etc. in the nodes of B 0 .

6. SAT Encodings of BDDs for Monotonic Functions
In this section we consider a BDD representing a monotonic function F and we want to
encode it into SAT. As expected, we want the encoding to be as small as possible and GAC.
The encoding explained here is valid with any type of BDDs, so, in particular, it is valid
with ROBDDs. The main differences with the Minisat+ encoding (Een & Sorensson, 2006)
is the number of clauses generated (6 ternary clauses per node versus one binary and one
ternary clauses per node) and that our encoding is GAC with any variable ordering.
As usual, the encoding introduces an auxiliary variable for every node. Let  be a node
with selector variable x and auxiliary variable n. Let f be the variable of its false child and
t be the variable of its true child. Only two clauses per node are needed:
f n

t  x  n.

Furthermore, we add a unit clause with the variable of the True node and another one with
the negation of the variable of the False node.
Theorem 22. The encoding is consistent in the following sense: a partial assignment A
cannot be extended to a model of F if and only if r is propagated by unit propagation, where
r is the root of the BDD.
Proof. We prove the theorem by induction on the number of variables of the BDD. If the
BDD has no variables, then the BDD is either the True node or the False node and the
result is trivial.
Assume that the result is true for BDDs with less than k variables, and let F be a
function whose BDD has k variables. Let r be the root node, x1 its selector variable and
465

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

f, t respectively its false and true children (note that we abuse the notation and identify
nodes with their auxiliary variable). We denote by F1 the function F|x1 =1 (i.e., F after
setting x1 to true) and by F0 the function F|x1 =0 .
 Let A be a partial assignment that cannot be extended to a model of F .
 Assume x1  A. Since A cannot be extended, the assignment A \ {x1 } cannot
be extended to a model of F1 . By definition of the BDD, the function F1 has t
as a BDD. By induction hypothesis, t is propagated, and since x1  A, r is also
propagated.
 Assume x1 6 A. Then, the assignment A \ {x1 } cannot be extended to a model
of F0 . Since F0 has f as a BDD, by induction hypothesis f is propagated, and
hence r also is.
 Let A be a partial assignment, and assume r has been propagated. Then, either f
has also been propagated or t has been propagated and x1  A (note that x1 has not
been propagated because it only appears in one clause which is already true).
 Assume that f has been propagated. Since f is the BDD of F0 , by induction
hypothesis the assignment A \ {x1 , x1 } cannot be extended to a model of F0 .
Since the function is monotonic, neither can A \ {x1 , x1 } be extended to a model
of F . Therefore, A cannot be extended to a model of F .
 Assume that t has been propagated and x1  A. Since t is the BDD of F1 , by
induction hypothesis A \ {x1 } cannot be extended to a model of F1 , so neither
can A be extended to a model of F .

For obtaining a GAC encoding, we only have to add a unit clause.
Theorem 23. If we add a unit clause forcing the variable of the root node to be true, the
previous encoding becomes generalized arc-consistent.
Proof. We will prove it by induction on the variables of the BDD. The case with zero
variables is trivial, so let us prove the induction case.
As before, let r be the root node, with x1 its selector variable and n its auxiliary variable,
and f, t its false and true children. We denote by F0 and F1 the functions F|x1 =0 and F|x1 =1 .
Let A be a partial assignment that can be extended to a model of F . Assume that
A  {xi } cannot be extended. We want to prove that xi will be propagated.
 Let us assume that x1  A. In this case, t is propagated due to the clause t  x1  n
and the unit clause n. Since x1  A and A  {xi } cannot be extended to a model of F ,
A \ {x1 }  {xi } neither can be extended to an assignment satisfying F1 . By induction
hypothesis, since t is the BDD of the function F1 , xi is propagated.
 Let us assume that x1 6 A and xi 6= x1 . Since F is monotonic, A  {xi } cannot be
extended to a model of F if and only if it cannot be extended to a model of F0 . Notice
that f is propagated thanks to the clause f  n and the unit clause n. By induction
hypothesis, the method is GAC for F0 , so xi is propagated.
466

fiA New Look at BDDs for Pseudo-Boolean Constraints

 Finally, assume that x1 6 A and xi = x1 . Since A  {x1 } cannot be extended to a
model of F , A cannot be extended to a model of F1 . By Theorem 22, t is propagated
and, due to t  x1  n and n, also is x1 .

We finish this section with an example illustrating how the suggested encoding of BDDs
into SAT can be used in the different PB encoding methods we have presented in this paper.
Example 24. Consider the constraint C : 2x1 + 3x2 + 5x3  6. We will encode this constraint into SAT with three methods: with the usual ROBDD encoding; with the consistent
approach of ROBDDs and splitting of the coefficients, explained in Section 4.2; and with
the GAC approach of ROBDDs and splitting of the coefficients explained in Section 4.3.
1. BDD-1: this method builds the ROBDD for C and then encodes it into SAT. Hence we
start by building the ROBDD of C, which can be seen in the last picture of Figure 1.
Now, we need to encode it into SAT. Let y1 , y2 and y3 be fresh variables corresponding
to the nodes of the ROBDD of C having respectively x1 , x2 and x3 as selector variable.
For node y1 , we have to add the clauses y2  y1 and x1  y3  y1 .

For y2 , we have to add the clauses >  y2 and x2  y3  y2 , where > is the tautology
symbol.
For y3 , we have to add the clauses >  y3 and x3    y3 , where  is the contradiction symbol.
Moreover, we have to add the unit clauses >,  and y1 . All in all, after removing the
units and tautologies, the clauses obtained are y1 , y2 , x1  y3 , x2  y3 and x3  y3 .
2. BDD-2: we build the ROBDD of C with coefficient decomposition as in Example 21.
Figure 6 shows the resulting ROBDD. We introduce variables y1 , y2 , . . . , y6 for every
node of the ROBDD. More precisely, the first x2 node (starting top-down) receives
variable y1 , the next x2 node gets y5 . The first x3 receives y2 and the other one y6 .
Finally the leftmost x1 node gets variable y3 and the other one y4 . We have to add the
following clauses: y2  y1 , y4 x2  y1 , y3  y2 , y4 x3  y2 , >  y3 , y5 x1  y3 ,
y5  y4 , y6  x1  y4 , >  y5 , y6  x2  y5 , >  y6 ,   x3  y6 , and the unit
clauses >,  and y1 .
After removing the units from the clauses and tautologies, we obtain y1 , y2 , y3 , y4 x2 ,
y4  x3 , y5  x1 , y5  y4 , y6  x1  y4 , y6  x2  y5 and x3  y6 .

Notice that this encoding is consistent: if we have the assignment A = {x2 , x3 }, then
y4 is propagated by the clause y4  x2 , which in turn propagates y5 due to clause y5  y4
and finally y6 is propagated by the clause y6  x2  y5 . A contradiction is found with
clause x3  y6 .

However, the encoding is not GAC: the partial assignment A = {x1 } can only propagate y5 . However, x3 should also be propagated.

3. BDD-3: let C1 , C2 and C3 be the constraints setting respectively x1 , x2 and x3 to true.
Figure 7 shows the ROBDDs of these constraints. We have to encode these ROBDDs
467

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

as usual, as in BDD-2, but replacing the unit clause r of the root by r  xi . In this
case the variables associated with the roots of C1 , C2 and C3 will be y1 , z1 and w1
respectively.
After removing the units and tautologies, clauses from C1 are y1 x1 , y2 y1 , y4 x2 y1 ,
y3  y2 , y4  x3  y2 , y4  x2  y3 and x3  y4 .
Clauses from C2 are z1  x2 and x3  z1 .
Finally, clauses from C3 are w1  x3 , w2  w1 , x1  w1 and x2  w2 .
This encoding is GAC. Take, for instance, the assignment A = {x1 }. In this case, w1
is propagated in virtue of x1  w1 and x3 is propagated by clause w1  x3 .

7. Related Work
Due to the ubiquity of Pseudo-Boolean constraints and the success of SAT solvers, the problem of encoding those constraints into SAT has been thoroughly studied in the literature.
In the following we review the most important contributions, paying special attention to the
basic idea on which they are based, the encoding size, and the propagation properties the
encodings fulfill. To ease the presentation, in the remaining of this section we will always
assume that the constraint we want to encode is a1 x1 + . . . + an xn  k, with maximum
coefficient amax .
The first encoding to mention is the one proposed by Warners (1998). In a nutshell, the
encoding uses several adders for numbers in binary representation. First of all, the left hand
side of the constraint is split into two halves, each of which is recursively treated to compute
the corresponding partial sum. After that, the two partial sums are added and the final
result is compared with k . The encoding uses O(n log(amax )) clauses and variables and
is neither consistent nor GAC. This is not surprising, since adders for numbers in binary
make extensive use of xors, which do not have good propagation properties.
Bailleux et al. (2006) introduced an encoding very close to those using a BDD and
translating it into clauses. In order to understand the differences between their construction and BDDs let us introduce it in detail. First of all, the coefficients are ordered from
small to large. Then, the root is labeled with variable Dn,k , expressing that the sum of
the first n terms is no more than k. Its two children are Dn1,k and Dn1,kan , which
correspond to setting xn to false and true, respectively. The process is repeated until nodes
corresponding to trivial constraints are reached, which are encoded as true or false. For
each node Di,b with children Di1,b and Di1,bai , the following four clauses are added:
Di1,bai  Di,b
Di1,bai  xi  Di,b

Di1,b  Di,b
Di1,b  xi  Di,b

Example 25. The encoding proposed by Bailleux et al. (2006) on 2x1 +    + 2x10 + 5x11 +
6x12  10 is illustrated in Figure 9. Node D10,5 represents 2x1 + 2x2 +    + 2x10  5,
whereas node D10,4 represents 2x1 + 2x2 +    2x10  4. The method fails to identify that
these two PB constraints are equivalent and hence subtrees B and C will not be merged,
yielding a much larger representation than with ROBDDs.
468

fiA New Look at BDDs for Pseudo-Boolean Constraints

D12,10
0

1

D11,10
0

D11,4
1

0

D10,10

D10,5

D10,4

A

B

C

1

D10,1
 false

Figure 9: Tree-like construction of Bailleux et al. (2006) for 2x1 +  +2x10 +5x11 +6x12  10

The resulting encoding is GAC, but an example of a PB constraint family is given for which
their kind of non-reduced BDDs, with their concrete variable ordering is exponentially large.
However, as we have shown in Section 3.2, ROBDDs for this family are polynomial.
Several important new contributions were presented in the paper by the MiniSAT
team (Een & Sorensson, 2006). The paper describes three encodings, all of which are
implemented in the MiniSAT+ tool. The first one is a standard ROBDD construction for
Pseudo-Boolean constraints. This is done in two steps: first, they suggest a simple dynamic
programming algorithm for constructing a non-reduced BDD, which is later reduced. The
result is a ROBDD, but the first step may take exponential time even if the final ROBDD
is polynomial. Once the ROBDD is constructed, they suggest to encode it into SAT using
6 ternary clauses per node. The paper showed that, given a concrete variable ordering, the
encoding is GAC. Regarding the ROBDD size, the authors cite the work of Bailleux et al.
(2006) to state the BDDs are exponential in the worst case. As we have seen before, the
citation is not correct because Bailleux et al do not construct ROBDDs.
The second method is similar to the one of Warners (1998) in the sense that the construction relies on a network of adders. First of all coefficients are decomposed into binary
representation. For each bit i, a bucket is created with all variables whose coefficient has bit
i set to one. The i-th bit of the left-hand side of the constraint is computed using a series of
full adders and half adders. Finally, the resulting sum is lexicographically compared to k.
The resulting encoding is neither consistent nor GAC and uses a number of adders linear
in the sum of the number of digits of the coefficients.
The last method they suggest is the use of sorting networks. Numbers are expressed in
unary representation and coefficients are decomposed using a mixed radix representation.
The smaller the number in this representation, the smaller the encoding. In this setting,
sorting networks are used to play the same role of adders, but with better propagation
properties. If N is smaller than the sum of the digits of all coefficients in base 2, the size
of the encoding is O(N log2 N ). Whereas this encoding is not GAC for arbitrary PseudoBoolean constraints, generalized arc-consistency is obtained for cardinality constraints.
469

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

Encoding
Warners
Non-reduced BDD
ROBDD
Adders
Sorting Networks
Watch Dog (WD)
Gen. Arc-cons. WD

Reference
(Warners, 1998)
(Bailleux et al., 2006)
(Een & Sorensson, 2006)
(Een & Sorensson, 2006)
(Een & Sorensson, 2006)
(Bailleux et al., 2009)
(Bailleux et al., 2009)

Clauses
O(n log amax )
Exponential
Exponential (6 per node)
P
O( log ai )
P
P
O(( log ai ) log2 ( log ai )
O(n2 log n log amax )
O(n3 log n log amax )

Consist.
NO
YES
YES
NO
YES
YES
YES

GAC
NO
YES
YES
NO
NO
NO
YES

Table 1: Summary comparing the different encodings.
The first polynomial and GAC encoding for Pseudo-Boolean constraints, called WatchDog, was introduced by Bailleux et al. (2009). It uses O(n2 log n log amax ) variables and
O(n3 log n log amax ) clauses. Again, numbers are expressed in unary representation and
totalizers are used to play the role of sorting networks. In order to make the comparison
with the right hand side trivial, the left-hand side and k are incremented until k becomes
a power of two. Then, all coefficients are decomposed in binary representation and each
bit is added independently, taking into account the corresponding carry. In the same paper, another encoding which is only consistent and uses O(n log n log amax ) variables and
O(n2 log n log amax ) clauses is also presented.
Finally, it is worth mentioning the work of Bartzis and Bultan (2003). The authors
deal with the more general case in which the variables xi are not Boolean, but bounded
integers 0  xi < 2b . They suggest a BDD-based approach very similar in flavor to our
method of Section 4, but instead of decomposing the coefficients as we do, they decompose
the variables xi in binary representation. The BDD ordering starts with the first bit of
x1 , then the first bit of the x2 , etc... After that, the second bit is treated in a similar
P
fashion, and so on. The resulting BDD has O(n  b  ai ) nodes and nothing is mentioned
about propagation properties. For the case of Pseudo-Boolean constraints, i.e. b = 1, their
approach amounts to standard BDDs.
Table 1 summarizes the different encodings of PB constraints into SAT.

8. Experimental Results
The goal of this section is to assess the practical interest of the encodings we have presented
in the paper. Our aim is to evaluate to which extent BDD-based encodings are interesting
from the practical point of view. For us, this means to study whether they are competitive
with existing techniques, whether they show good behavior in general or are only interesting
for very specific types of problems, or whether they produce smaller encodings.
For that purpose, first of all, we compare our encodings with other SAT encodings in
terms of encoding time, number of clauses and number of variables. After that, we also
consider total runtime (that is, encoding time plus solving time) of these encodings and we
compare it with the runtime of state-of-the-art Pseudo-Boolean solvers. Finally, we briefly
report on some experiments with sharing, that is, trying to encode several Pseudo-Boolean
constraints in a single ROBDD.
470

fiA New Look at BDDs for Pseudo-Boolean Constraints

All experiments were performed on a 2Ghz Linux Quad-Core AMD with a time limit of
1800 seconds per benchmark. The benchmarks used for these experiments were obtained
from the Pseudo-Boolean Competition 2011 (http://www.cril.univ-artois.fr/PB11/),
category no optimization, small integers, linear constraints (DEC-SMALLINT-LIN). For
compactness and clarity, we have grouped benchmarks that come from the same source into
families. However, individual results can be found at http://www.lsi.upc.edu/~iabio/
BDDs/results.ods.
8.1 The Bergmann-Hommel Test
In order to summarize the experiments and make it easier to extract conclusions, every experiment is accompanied with a Bergmann-Hommel non-parametric hypothesis test
(Bergmann & Hommel, 1988) of the results with a confidence level of 0.1.
The Bergmann-Hommel test is a way of comparing the results of n different methods
over multiple independent data sets. It gives us two interesting pieces of information. First
of all, it sorts the methods by giving them a real number between 1 and n, such that the
lower the number the better the method. Moreover, it indicates, for each pair of methods,
whether one method significantly improves upon the other. As an example, Figure 10 is the
output of a Bergmann-Hommel test. BDD-1 is the best method but there is not significant
difference between this method and BDD-2 (this is illustrated by a thick line connecting
the methods). On the other hand, the Bergmann-Hommel test indicates that BDD-1 is
significantly better than Adder, since there is no thick line connecting BDD-1 and Adder.
The same can be said for BDD-1 and WD-1, BDD-1 and BDD-3, BDD-1 and WD-2, BDD-2
and Adder, etc.
We will now give a quick overview of how a Bergmann-Hommel test is computed. The
remaining of this section can be skipped if the reader is not interested in the details of the
test. On the other hand, for more detailed information, we refer the reader to the work
of Bergmann and Hommel (1988).
Let us assume we have n methods and m data sets, and let Ci,j be the result (time,
number of variables or any other value) of the i-th method in the j-th benchmark. For
every data set, we assign a number to every method: the best method in that data set has
a 1, the second has a 2, and so on. Then, for every method, we compute the average of
these values in the different data sets. The obtained value is denoted by Ri and is called
the average rank of the i-th method. A method with smaller average rank is better than a
method with a bigger one.
These average ranks make it possible to rank the different methods. However, we are
also interested in detecting whether the differences between the methods are significant or
not: this is computed in the second part of the test. Before that, we need some previous
definitions.
R R
Given i, j  N = {1, 2, . . . , n}, we denote by pi,j the p-value3 of zi,j =  i j
with
n(n1)/(6m)

respect a normal distribution N (0, 1). A partition of N = {1, 2, . . . , n} is a collection of sets
P = {P1 , P2 , . . . , Pr } such that (i) the Pi s are subsets of N , (ii) P1  P2      Pr = N and
3. The p-value of z with respect to a normal distribution N (0, 1) is the probability p[ |Z| > |z| ], where the
random variable Z  N (0, 1).

471

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

(iii) Pi  Pj =  for every i 6= j. Given P a partition of N , we define
L(P ) =

r
X
|Pi |(|Pi |  1)
i=1

2

and p(P ) as the minimum pi,j such that i and j belong to the same subset Pk  P .
The Bergmann-Hommel test ensures (with a significance level of ) that the methods i
and j are not significantly different if and only if there is a partition P with p(P ) > L(P )
such that i and j belong to the same subset Pk  P . Hence, it is a time-consuming test
since the number of partitions can be very large.
In our case, the data sets are the families of benchmarks. We have to use the families
instead of the benchmarks because the data sets must be independent.
8.2 Encodings into SAT
We start by comparing different methods for encoding Pseudo-Boolean constraints into
SAT. We have focused on the time spent by the encoding, the number of auxiliary variables
used and the number of clauses. Moreover, for each benchmark family, we also report the
number of PB-constraints that were encoded into SAT.
The encodings we have included in the experimental evaluation are: the adder encoding as presented by Een and Sorensson (2006) (Adder), the consistent WatchDog encoding
of Bailleux et al. (2009) (WD-1), its GAC version (WD-2), the encoding into ROBDDs without coefficient decomposition, using Algorithm 1 and the encoding from Section 6 (BDD1); the encoding into ROBDDs after coefficient decomposition as explained in Section 4.2
(BDD-2), with Algorithm 1 and the encoding from Section 6; and the GAC approach from
Section 4.3 (BDD-3 ), also with Algorithm 1 and the encoding from Section 6. Notice that
BDD-1 method is very similar to the ROBDDs presented by Een and Sorensson (2006).
However, since Algorithm 1 produces every node only once, BDD-1 should be faster. Also,
the encoding of Section 6 only creates two clauses per BDD node, as opposed to six clauses
as suggested by Een and Sorensson.
Table 2 shows the number of problems that the different methods could encode without
timing out. The first column corresponds to the family of problems. The second column
shows the number of problems in this family. The third and fourth columns contain the average number of SAT and Pseudo-Boolean constraints in the problem. For the experiments,
we considered a constraint to be SAT if it is a clause or has at most 3 variables. Small PB
constraints do not benefit from the above encodings and hence for these constraints a naive
encoding into SAT was always used. The remaining columns correspond to the number of
encoded problems without timing out. Time limit was set to 1800 seconds per benchmark.
Table 3 shows the time spent to encode the benchmarks by the different methods. As
before, the first columns correspond to the family of problems, the number of problems in
this family and the average number of SAT and Pseudo-Boolean constraints in the problems. The remaining columns correspond to the average encoding time (in seconds) per
benchmarks of each method. Timeouts are counted as 1800 seconds in the average computation.
Table 4 shows the average number of auxiliary variables required for encoding the PB
constraints (SAT constraints are not counted). The meaning of the first 4 columns is
472

fiA New Look at BDDs for Pseudo-Boolean Constraints

Family
lopes
army
blast
cache
chnl
dbstv30
dbstv40
dbstv50
dlx
elf
fpga
j30
j60
j90
j120
neos
ooo
pig-crd
pig-cl
ppp
robin
13queen
11tsp11
vdw

Pr
200
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

TOTAL

669

SAT
502,671
192
6,510
181,100
0
326,200
985,200
2,552,000
20,907
46,446
0
13,685
30,832
50,553
104,147
1,451
95,217
0
161,150
29,846
0
8
2,662
8,978

PB
592,715
451
1,253
4,507
125
2,701
4,801
7501
857
1,399
687
270
309
337
516
3,831
4,487
113
58
1,023
761
93
45
267,840

Adder
188
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

WD-1
188
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

WD-2
118
12
8
9
21
0
0
0
3
5
36
17
18
8
11
4
19
18
20
6
2
100
100
5

BDD-1
197
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

BDD-2
197
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

BDD-3
188
12
8
9
21
0
0
0
3
5
36
17
18
11
18
4
19
20
20
6
6
100
100
5

657

657

540

666

666

626

Table 2: Number of problems encoded (without timing out) by the different methods.
6

5

4

3

WD2

2

1

BDD1
BDD2

BDD3
WD1

Adder

Figure 10: Statistical comparison of the results of Table 3, time spent by the different
methods in encoding.

the same as before, and the others contain the average number of auxiliary variables (in
thousands) of the benchmarks that did not time out.
Finally, Table 5 contains the average number (in thousands) of clauses needed to encode
the problem. As before, we have only considered the benchmarks that have not timed out,
and clauses due to the encoding of SAT constraints are not counted.
Figures 10, 11 and 12 represent the Bergmann-Hommel tests of these tables. They
show that BDD-1, BDD-2 and Adders are the best methods in terms of time, variables and
clauses. It is worth mentioning that BDD-1 and BDD-2 are faster and use significantly less
clauses than Adder. However, Adders uses significantly less auxiliary variables than BDD-2.
Notice that BDD-1 is GAC, BDD-2 is only consistent and Adder is not consistent, so at
least theoretically BDD-1 clauses have more unit propagation power than BDD-2 clauses,
and BDD-2 clauses are better than Adder clauses. Hence, BDD-1 is the best method using
these criteria and BDD-2 is better than Adder. Regarding the other methods, it seems clear
473

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

Family
lopes
army
blast
cache
chnl
dbstv30
dbstv40
dbstv50
dlx
elf
fpga
j30
j60
j90
j120
neos
ooo
pig-crd
pig-cl
ppp
robin
13queen
11tsp11
vdw

Pr
200
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

SAT
502,671
192
6,510
181,100
0
326,200
985,200
2,552,000
20,907
46,446
0
13,685
30,832
50,553
104,147
1,451
95,217
0
161,150
29,846
0
8
2,662
8,978

PB
592,715
451
1,253
4,507
125
2,701
4,801
7,501
857
1,399
687
270
309
337
516
3,832
4,487
113
58
1,024
761
93
45
267,840

Average

Adder
335.23
0.37
3.89
23.08
0.54
57.77
211.51
547.30
3.73
7.37
1.90
3.64
6.85
14.81
19.25
10.43
13.48
0.97
7.73
6.13
12.03
0.19
0.46
170.33

WD-1
292.14
0.43
2.45
18.74
1.05
97.21
210.25
552.99
3.05
6.53
2.46
4.62
10.69
31.02
47.62
12.65
9.67
3.29
8.78
5.09
67.41
0.45
0.51
109.42

WD-2
996.07
39.98
40.41
81.65
87.08



8.41
21.68
69.90
81.03
466.07
1,277.28
1,305.55
257.97
71.20
517.51
284.15
33.26
1,315.96
100.29
24.42
441.21

BDD-1
165.75
0.19
2.20
16.19
0.13
45.85
105.62
272.02
2.76
5.19
0.30
3.13
8.19
28.20
21.68
3.46
7.76
0.22
7.35
3.17
2.94
0.14
0.30
47.15

BDD-2
163.66
0.19
1.89
15.74
0.13
83.09
165.96
468.51
2.75
5.90
0.30
3.67
8.77
27.76
25.50
5.32
7.88
0.21
7.31
3.23
2.82
0.17
0.33
46.32

BDD-3
316.35
10.26
23.15
47.78
2.68



6.19
13.42
3.75
42.44
252.69
1,155.18
967.10
77.04
26.35
9.52
10.79
9.83
301.11
18.48
6.30
125.91

110.57

99.79

510.40

55.90

57.66

223.41

Table 3: Average time spent on the encoding by the different methods.

Family
lopes
army
blast
cache
chnl
dbstv30
dbstv40
dbstv50
dlx
elf
fpga
j30
j60
j90
j120
neos
ooo
pig-crd
pig-cl
ppp
robin
13queen
11tsp11
vdw
Average

Pr
200
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

SAT
502,671
192
6,510
181,100
0
326,200
985,200
2,552,000
20,907
46,446
0
13,685
30,832
50,553
104,147
1,451
95,217
0
161,150
29,846
0
8
2,662
8,978

PB
592,715
451
1,253
4,507
125
2,701
4,801
7,501
857
1,399
687
270
309
337
516
3,832
4,487
113
58
1,024
761
93
45
267,840

Adder
1,744.05
4.63
27.77
145.66
8.39
219.82
2,468.45
6,135.13
10.4
20.37
21.15
18.15
37.03
65.4
159.43
73.74
118.15
15.26
7.68
57.13
171.67
2.2
3.37
1,895.39

WD-1
3,566.11
10.96
62.22
339.18
24.55
709.73
6,564.44
16,365.39
21.62
42.78
53.96
50.8
112.35
217.01
540
185.59
273.54
50.75
25.25
141.49
628.45
6.17
8.83
3,356.94

WD-2
5,478.81
245.49
1,394.5
2,393.97
1,007.9



247.79
571.38
1,074.03
1,190.59
4,775.72
6,543.52
5,713.75
3,542.94
2,248.34
2,966.58
1,984.06
623.58
3,634.13
461.54
170.59
12,818.51

BDD-1
2,393.97
6.36
36.74
201.18
6.76
441.86
4,282.16
11,111.06
12.40
24.62
13.27
44.96
157.92
553.8
612.13
79.33
162.25
11.93
4.01
81.57
158.55
5.63
5.71
1,391.65

BDD-2
2,394
6.36
39.67
210.83
6.76
1,695.87
7,225.63
19,723.37
13.89
28.13
13.27
59.82
180.05
553.76
806.08
122.53
168.61
11.93
4.01
82.86
158.55
7.08
6.51
1,391.65

BDD-3
7,734.65
479.83
761.29
1,503.19
184.59



126.81
306.76
242.03
1,153.51
7,285.69
19,793.49
22,246.82
2,003.95
1,315.77
632.33
310.03
382.67
16,565.75
791.43
221.21
5,875.58

591.35

1,266.23

1,876.33

892.62

998.44

3,807.34

Table 4: Average number of auxiliary variables (in thousands) used.

474

fiA New Look at BDDs for Pseudo-Boolean Constraints

Family
lopes
army
blast
cache
chnl
dbstv30
dbstv40
dbstv50
dlx
elf
fpga
j30
j60
j90
j120
neos
ooo
pig-crd
pig-cl
ppp
robin
13queen
11tsp11
vdw
Average

Pr
200
12
8
9
21
5
5
5
3
5
36
17
18
17
28
4
19
20
20
6
6
100
100
5

SAT
502,671
192
6,510
181,100
0
326,200
985,200
2,552,000
20,907
46,446
0
13,685
30,832
50,553
104,147
1,451
95,217
0
161,150
29,846
0
8
2,662
8,978

PB
592,715
451
1,253
4,507
125
2,701
4,801
7,501
857
1,399
687
270
309
337
516
3,832
4,487
113
58
1,024
761
93
45
267,840

Adder
10,643.63
26.09
184.95
980.51
56.82
1,497.41
17,184.62
42,797.38
65.25
129.05
139.45
121.56
253.16
450.49
1,102.86
471.47
793.36
104.68
52.41
392.6
1,185.92
14.73
23.31
10,885.96
3,675.7

WD-1
7,471.89
34.5
102.07
550.68
116.97
3,367.75
16,916.6
44,310.83
35.68
71.28
175.66
164.78
494.83
1,286.17
3,803.28
594.72
442.47
367.03
180.33
271.66
6,916.35
38.91
25.35
6,564.14
2,970.54

WD-2
22,082.47
2,155.7
2,108.48
3,651.91
4,936.16



377.76
881.02
3,615.21
3,889.58
22,843.05
34,136.7
26,205.19
12,410.1
3,378.16
20,711.11
14,641.26
1,804.29
19,694.86
5,068.35
1,335.6
24,274.21
8,297.1

BDD-1
3,049.06
10.87
70.9
272.27
11.23
857.39
5,526.6
14,400.14
23.04
46.3
15.65
89.53
311.15
1,106.22
1,186.55
139.26
219.41
19.86
4.07
100.89
281.42
10.84
7.76
1,662.73
1,174.38

BDD-2
3,049.02
10.87
65.46
275.26
11.23
3,282.22
11,259.29
31,279.2
22.59
46.07
15.65
116.04
351.01
1,095.12
1,570.73
220.45
227.61
19.86
4.07
103.24
281.42
13.73
9.35
1,662.73
1,380.41

BDD-3
9,746.32
924.93
1,264.83
2,418.77
285.67



208.92
507.46
278.37
2,244.021
14,355.2
39,112.08
44,068.97
3,681.26
2,126.42
958.65
314.05
654.48
28,875.61
1,573.89
433.59
7,262.88
5,843.53

Table 5: Average number of clauses (in thousands) used.

6

5

4

3

2

WD2
BDD3

1

Adder
BDD1
WD1

BDD2

Figure 11: Statistical comparison of the results of Table 4, number of auxiliary variables
used by the different encodings.

6

5

4

3

WD2

2

1

BDD1
BDD2

BDD3
WD1

Adder

Figure 12: Statistical comparison of the results of Table 5, number of clauses used by the
different methods.

475

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

Family
lopes
army
blast
cache
chnl
dbstv30
dbstv40
dbstv50
dlx
elf
fpga
j30
j60
j90
j120
neos
ooo
pig-crd
pig-cl
ppp
robin
13queen
11tsp11
vdw
TOTAL

Adder
42
9
8
9
3
5
0
0
3
5
25
17
17
17
14
2
15
2
2
4
3
100
100
1

WD-1
54
12
8
9
3
5
5
5
3
5
36
17
17
17
16
2
19
2
1
3
3
100
100
1

WD-2
40
7
8
9
2
0
0
0
3
5
36
17
17
7
9
2
16
2
2
4
2
100
96
1

BDD-1
56
10
8
9
5
5
5
5
3
5
36
17
17
17
16
2
18
2
1
3
3
100
100
1

BDD-2
57
11
8
9
5
5
5
5
3
5
36
17
17
17
16
2
19
2
1
4
3
100
100
1

BDD-3
61
5
8
9
3
0
0
0
3
5
36
17
17
8
11
2
17
1
2
4
6
100
75
1

bsolo
39
6
8
7
21
5
5
5
3
5
36
17
17
17
13
2
14
19
3
4
3
100
72
1

MiniSAT
66
6
8
8
3
5
5
5
3
5
33
17
17
17
12
2
15
2
2
4
3
100
90
1

SAT4J
23
6
8
6
1
5
5
5
3
5
36
17
17
17
16
2
14
2
2
4
4
100
93
1

Wbo
63
6
8
6
3
5
5
5
3
5
36
17
17
17
16
2
15
2
2
3
3
100
100
1

borg
37
10
8
6
21
5
5
5
3
5
36
17
17
17
16
2
14
20
5
5
3
100
100
1

SMT
43
5
8
9
0
5
5
5
3
5
36
17
17
17
16
2
17
0
0
4
4
100
100
1

VBS
77
12
8
9
21
5
5
5
3
5
36
17
17
17
17
2
19
20
5
6
6
100
100
2

403

443

385

444

448

391

422

429

392

440

458

419

514

Table 6: Number of problems solved by different methods.
that encoding n different constraints in order to obtain GAC, as it is done in WD-2 and
BDD-3, is not a good idea in terms of variables and clauses.
8.3 SAT vs. PB
In this section we compare the state-of-the-art solvers for Pseudo-Boolean problems and
some encodings into SAT. For the SAT approach, once the encoding has been done, the
SAT formula is given to the SAT Solver Lingeling (Biere, 2010) version 276. We have
considered the same SAT encodings as in the previous section. Regarding Pseudo-Boolean
solvers, we have considered MiniSAT+ (Een & Sorensson, 2006) and the best non-parallel
solvers in the No optimization, small integers, linear constraints category of the PseudoBoolean Competition: borg (Silverthorn & Miikkulainen, 2010) version pb-dec-11.04.03,
bsolo (Manquinho & Silva, 2006) version 3.2, wbo (Manquinho, Martins, & Lynce, 2010)
version 1.4 and SAT4J (Berre & Parrain, 2010) version 2.2.1. We have also included the
SMT Solver Barcelogic (Bofill, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Rubio, 2008)
for PB constraints, which couples a SAT solver with a theory solver for PB constraints.
Table 6 shows the number of instances solved by each method. Table 7 shows the average
time spent by all these methods. For the SAT encodings, times include both the encoding
and SAT solving time. As before, a time limit of 1800 seconds per benchmark was set, and
for the average computation, a timeout is counted as 1800 seconds. Both tables include a
column VBS (Virtual Best Solver), which represents the best solver in every instance. This
gives an idea of which speedup we could obtain with a portfolio approach.
Figure 13 shows the result of the Bergmann-Hommel test: SMT is the best method,
whereas Adder, BDD-3 and WD-2 are the worst ones. There are no significant difference
between the other methods. The main conclusion we can infer is that BDD encodings are
definitely a competitive method. Also, there is no technique that outperforms the others
in all benchmark families, and hence portfolio strategies would make a lot of sense in this
476

fiA New Look at BDDs for Pseudo-Boolean Constraints

Family
lopes
army
blast
cache
chnl
dbstv30
dbstv40
dbstv50
dlx
elf
fpga
j30
j60
j90
j120
neos
ooo
pig-crd
pig-cl
ppp
robin
13queen
11tsp11
vdw

Adder
1,515
660
6.12
253
1,543
1,049


7.06
13.87
586
16.7
137
24.18
978
1,023
479
1,620
1,624
631
938
47.52
28.36
1,645

WD-1
1,420
139
2.56
123
1,543
128
366
935
4.88
10.14
5.27
7.79
114
36.63
854
936
190
1,620
1,715
1,001
921
1.64
8.29
1,568

WD-2
1,561
1,141
46.78
396
1,716



25.72
44.09
113
116
551
1,303
1,364
1,405
493
1,680
1,693
656
1,353
264
428.6
1,545

BDD-1
1,408
543
2.42
75.49
1,508
91.66
198
629
4.29
7.97
0.92
5.94
113
39.72
839
910
151
1,620
1,718
906
913
4.63
23.86
1,493

BDD-2
1,401
469
1.99
115
1,508
192
324
792
4.34
9
0.92
8.42
116
39.46
851
915
176
1,620
1,718
858
913
4.51
18.32
1,493

BDD-3
1,435
1,298
27.63
375
1,681



19.58
30.03
37.64
77.88
398
1,233
1,262
1,073
488
1,725
1,721
646
719
643
731
1,612

bsolo
1,509
1,028
0.12
653
0.55
59.28
187
200
3.47
28.58
0.27
6.53
110
0.9
967
1,106
645
114
1,658
605
936
54.82
855
1,478

MiniSAT
1,344
913
0.51
395
1,551
32.6
72.25
430
1.29
2.97
242
4.6
115
3.96
1,031
1,276
453
1,626
1,623
919
971
238
369
1,448

SAT4J
1,661
1,127
0.84
670
1,751
99.81
9.74
21.22
1.6
2.31
1.47
14.57
105
1.42
849
1,038
575
1,749
1,705
602
778
18.92
503
1,596

Wbo
1,364
1,084
0.08
606
1,673
1.54
5.69
16.13
0.55
1.42
5.17
0.53
101
0.41
839
901
486
1,685
1,742
901
920
5.9
229
1,441

borg
1,555
438
2.13
636
3.78
9.87
45.33
121
3.15
11.61
3.04
1.93
104
3.32
841
976
512
3.92
1,369
390
963
20.35
27.64
1,450

SMT
1,464
1,066
0.03
266

1.28
4.44
11.36
0.17
0.69
0.1
0.28
101
0.15
814
925
259


601
605
1.92
1.81
1,441

VBS
1,249
86
0.03
63.95
0.47
1.28
4.44
11.36
0.17
0.69
0.07
0.28
101
0.15
756
901
126
1.92
1,367
210
444
1.28
1.51
1,186

783

669

958

667

667

1,003

764

772

849

710

613

696

475

Av.

Table 7: Time spent by different methods on solving the problem (in seconds).

12

11

10

9

8

7

6

5

4

WD2

3

2

SMT
BDD3

Wbo
Adder
SAT4J
MiniSAT
bsolo

borg
BDD1
BDD2
WD1

Figure 13: Statistical comparison of the results of Table 7, runtime of the different methods.

477

1

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

area, as witnessed by the performance of Borg, which implements such an approach. Finally,
we also want to mention that the possible exponential explosion of BDDs rarely occurs in
practice and hence, coefficient decomposition does not seem to pay off in practical situations.
Regarding the Best Virtual Solver, SMT contributes to 52% of the problems. In 25% of
the cases the best solution was given by a specific PB solver. Among them, Wbo contributes
with 10% of the problems and bsolo with 8%. Finally, encoding methods give the best
solution in the 23% of the cases: 14% of the times due to Watchdog methods and 8% of the
times due to BDD-based methods.
8.4 Sharing
One of the possible advantages of using ROBDDs to encode Pseudo-Boolean constraints is
that ROBDDs allow one to encode a set of constraints, and not just one. It would seem
natural to think that if two constraints are similar enough, the two individual ROBDDs
would be similar in structure, and merging them into a single one would result in a ROBDD
whose size is smaller than the sum of the two individual ROBDDs. However, the main
difficulty is to decide which constraints should be encoded together, since a bad choice could
result in a ROBDD whose size is larger than the sum of the ROBDDs for the individual
constraints.
We performed initial experiments where the criteria of similarity between constraints
only took into account which variables appeared in the constraints. We first fixed an
integer k and chose the constraint with the largest set of variables. After that, we looked
for a constraint such that all but k variables appeared in the first constraint. The next step
was to look for another constraint such that all but k variables appeared in any of the two
previous constraints and so on, until reaching a fixpoint. Finally, all selected constraints
were encoded together.
We tried this experiment on all benchmarks with different values of k and it rarely gave
any advantage. However, we still believe that there could be a way of encoding different
constraints into a single ROBDD, but different criteria for selecting the constraints should
be studied. We see this as a possible line of future research.

9. Conclusions and Future Work
Both theoretical and practical contributions have been made. Regarding the theoretical
part, we have negatively answered the question of whether all PB constraints admit polynomial BDDs by citing the work of Hosaka et al. (1994) which, to the best of our knowledge,
is largely unknown in our research community. Moreover, we have given a simpler proof
assuming that NP is different from co-NP, which relates the subset sum problem and the
ROBDDs size of PB constraints.
At the practical level, we have introduced a ROBDD-based polynomial and generalized
arc-consistent encoding of PB constraints and developed a BDD-based generalized arcconsistent encoding of monotonic functions that only uses two clauses per BDD node. We
have also presented an algorithm to efficiently construct all these ROBDDs and proved
that the overall method is competitive in practice with state-of-the-art encodings and tools.
As future work at the practical level, we plan to study which type of Pseudo-Boolean
478

fiA New Look at BDDs for Pseudo-Boolean Constraints

constraints are likely to produce smaller ROBDDs if encoded together rather than being
encoded individually.

Acknowledgments
All UPC authors are partially supported by Spanish Min. of Educ. and Science through
the LogicTools-2 project (TIN2007-68093-C02-01). Abo is also partially supported by FPU
grant.

References
Abo, I., Nieuwenhuis, R., Oliveras, A., & Rodrguez-Carbonell, E. (2011). BDDs for pseudoboolean constraints: revisited. In Proceedings of the 14th international conference on
Theory and application of satisfiability testing, SAT 11, pp. 6175, Berlin, Heidelberg.
Springer-Verlag.
Aloul, F. A., Ramani, A., Markov, I. L., & Sakallah, K. A. (2002). Generic ILP versus
specialized 0-1 ILP: an update. In Proceedings of the 2002 IEEE/ACM international
conference on Computer-aided design, ICCAD 02, pp. 450457, New York, NY, USA.
ACM.
Bailleux, O., Boufkhad, Y., & Roussel, O. (2006). A Translation of Pseudo Boolean Constraints to SAT. Journal on Satisfiability, Boolean Modeling and Computation, JSAT,
2 (1-4), 191200.
Bailleux, O., Boufkhad, Y., & Roussel, O. (2009). New Encodings of Pseudo-Boolean Constraints into CNF. In Kullmann, O. (Ed.), 12th International Conference on Theory
and Applications of Satisfiability Testing, SAT 09, Vol. 5584 of Lecture Notes in
Computer Science, pp. 181194. Springer.
Bartzis, C., & Bultan, T. (2003). Construction of efficient bdds for bounded arithmetic
constraints. In Proceedings of the 9th international conference on Tools and algorithms for the construction and analysis of systems, TACAS 03, pp. 394408, Berlin,
Heidelberg. Springer-Verlag.
Bergmann, B., & Hommel, G. (1988). Improvements of general multiple test procedures
for redundant systems of hypotheses. In Bauer, P., Hommel, G., & Sonnemann,
E. (Eds.), Multiple Hypothesenprfung - Multiple Hypotheses Testing, pp. 100115.
Springer-Verlag.
Berre, D. L., & Parrain, A. (2010). The Sat4j library, release 2.2. Journal on Satisfiability,
Boolean Modeling and Computation, JSAT, 7 (2-3), 596.
Bessiere, C., Katsirelos, G., Narodytska, N., & Walsh, T. (2009). Circuit complexity and
decompositions of global constraints. In Proceedings of the 21st international jont
conference on Artifical intelligence, IJCAI 09, pp. 412418, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.
Biere, A. (2010). Lingeling, Plingeling, PicoSAT and PrecoSAT at SAT Race 2010. Tech.
rep., Institute for Formal Models and Verification, Johannes Kepler University, Al479

fiAbo, Nieuwenhuis, Oliveras, Rodrguez-Carbonell, & Mayer-Eichberger

tenbergerstr. 69, 4040 Linz, Austria. Technical Report 10/1, August 2010, FMV
Reports Series.
Bofill, M., Nieuwenhuis, R., Oliveras, A., Rodrguez-Carbonell, E., & Rubio, A. (2008). The
Barcelogic SMT Solver. In Computer-aided Verification (CAV), Vol. 5123 of Lecture
Notes in Computer Science, pp. 294298.
Bryant, R. E. (1986). Graph-Based Algorithms for Boolean Function Manipulation. IEEE
Transactions on Computers, 35 (8), 677691.
Bryant, R. E., Lahiri, S. K., & Seshia, S. A. (2002). Deciding CLU Logic Formulas via
Boolean and Pseudo-Boolean Encodings. In Proceedings of the International Workshop on Constraints in Formal Verification, CFV 02. Associated with International
Conference on Principles and Practice of Constraint Programming (CP 02).
Een, N., & Sorensson, N. (2006). Translating Pseudo-Boolean Constraints into SAT. Journal
on Satisfiability, Boolean Modeling and Computation, 2, 126.
Hosaka, K., Takenaga, Y., & Yajima, S. (1994). On the Size of Ordered Binary Decision
Diagrams Representing Threshold Functions. In Algorithms and Computation, 5th
International Symposium, ISAAC 94, pp. 584592.
Manquinho, V. M., Martins, R., & Lynce, I. (2010). Improving Unsatisfiability-Based Algorithms for Boolean Optimization. In Strichman, O., & Szeider, S. (Eds.), 13th
International Conference on Theory and Applications of Satisfiability Testing, Vol.
6175 of SAT 10, pp. 181193. Springer.
Manquinho, V. M., & Silva, J. P. M. (2006). On Using Cutting Planes in Pseudo-Boolean
Optimization. Journal on Satisfiability, Boolean Modeling and Computation, JSAT,
2 (1-4), 209219.
Mayer-Eichberger, V. (2008). Towards Solving a System of Pseudo Boolean Constraints
with Binary Decision Diagrams. Masters thesis, New University of Lisbon.
Schutt, A., Feydy, T., Stuckey, P. J., & Wallace, M. G. (2009). Why cumulative decomposition is not as bad as it sounds. In Proceedings of the 15th international conference
on Principles and practice of constraint programming, CP09, pp. 746761, Berlin,
Heidelberg. Springer-Verlag.
Silverthorn, B., & Miikkulainen, R. (2010). Latent class models for algorithm portfolio
methods. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence.
Smaus, J. (2007). On Boolean Functions Encodable as a Single Linear Pseudo-Boolean
Constraint. In Hentenryck, P. V., & Wolsey, L. A. (Eds.), 4th International Conference
on the Integration of AI and OR Techniques in Constraint Programming, CPAIOR
07, Vol. 4510 of Lecture Notes in Computer Science, pp. 288302. Springer.
Warners, J. P. (1998). A Linear-Time Transformation of Linear Inequalities into Conjunctive
Normal Form. Information Processing Letters, 68 (2), 6369.

480

fiJournal of Artificial Intelligence Research 45 (2012) 601-640

Submitted 8/12; published 12/12

Irrelevant and Independent Natural Extension
for Sets of Desirable Gambles
Gert de Cooman

gert.decooman@ugent.be

Ghent University, SYSTeMS Research Group
Technologiepark 914, 9052 Zwijnaarde, Belgium

Enrique Miranda

mirandaenrique@uniovi.es

University of Oviedo, Dept. of Statistics and O.R.
C-Calvo Sotelo, s/n, Oviedo 33007, Spain

Abstract
The results in this paper add useful tools to the theory of sets of desirable gambles, a
growing toolbox for reasoning with partial probability assessments. We investigate how to
combine a number of marginal coherent sets of desirable gambles into a joint set using the
properties of epistemic irrelevance and independence. We provide formulas for the smallest
such joint, called their independent natural extension, and study its main properties. The
independent natural extension of maximal coherent sets of desirable gambles allows us to
define the strong product of sets of desirable gambles. Finally, we explore an easy way to
generalise these results to also apply for the conditional versions of epistemic irrelevance and
independence. Having such a set of tools that are easily implemented in computer programs
is clearly beneficial to fields, like AI, with a clear interest in coherent reasoning under
uncertainty using general and robust uncertainty models that require no full specification.

1. Introduction
In reasoning and decision making under uncertainty, there is little doubt that probabilities play the leading part. Imprecise probability models provide a well-founded extension
to probabilistic reasoning, that allow us to deal with incomplete probability assessments,
indecision and robustness issues.1
Early imprecise probability models (going back to, amongst others, Bernoulli, 1713;
Boole, 1952, 1961; Koopman, 1940) centered on lower and upper probabilities for events
or propositions. In later stages (see for instance Smith, 1961; Williams, 1975b and, for
the clearest statement, Walley, 1991, Section 2.7), it became apparent that the language
of events and lower probabilities is lacking in power of expression, and that a much more
expressive theory can be built using random variables and lower previsions (or lower expectations), instead.2 However, even though it has been quite successful, and is by now
quite well developed, there are a number of problems with the lower prevision approach.
Its mathematical complexity is fairly high, especially when conditioning and independence
1. To get a good idea of what the field of imprecise probabilities is about, and how it is evolving, browse
through the online proceedings of the biennial ISIPTA conferences, to be found on the web site (www.
sipta.org) of the Society for Imprecise Probability: Theories and Applications.
2. In contrast, for precise probability models, the expressive power of probabilities and expectations is
the same: a linear prevision or expectation on the set of all (bounded) real-valued maps is uniquely
determined by its restriction to events (a finitely additive probability), and vice versa.
c
2012
AI Access Foundation. All rights reserved.

fiDe Cooman & Miranda

enter the picture. Also, the coherence requirements, which specify basic rules for proper
inference using (conditional) lower previsions, are quite cumbersome, and rather harder to
chop down into intuitive elementary building blocks than their precise-probabilistic counterparts, even though the latter turn out to be special instances of the former. Finally, as
is the case with many other approaches to probability, and as we will see further on, the
theory of coherent lower previsions has issues with conditioning on sets of probability zero.
A very attractive solution to these problems was offered by Walley (2000), in the form
of sets of desirable gambles. Walleys work was inspired by earlier ideas by Smith (1961)
and Williams (1975b), but previous work along these lines was also done by Seidenfeld,
Schervish, and Kadane (1995). On this approach, the primitive notions are not probabilities
of events, nor expectations of random variables. Rather, the starting point is the question
whether a gamble, or a risky transaction, is desirable to a subject, i.e. strictly preferred to
the zero transaction, or status quo. A basic belief model is then not a probability measure,
nor a lower prevision, but a set of desirable gambles.
Let us briefly summarise here why we believe working with sets of desirable gambles as
basic belief models deserves more attention in the AI community:
Primo, as a number of examples in the literature have shown (Couso & Moral, 2011;
De Cooman & Quaeghebeur, 2012; Moral, 2005), and as we shall see further on (look for
instance at Examples 1 and 2), working with and making inferences using a set of desirable
gambles as a subjects uncertainty model is more general and more expressive. It is also
arguably simpler and more elegant from a mathematical point of view, and it has a very
intuitive geometrical interpretation (Quaeghebeur, 2012b).
Secundo, we shall see in Sections 4 and 5 that the approach to coherent marginalisation
and conditioning is especially straightforward, and there are no issues with conditioning on
sets of probability zero.
Tertio, as we will argue in Section 2.3, because of the similarity between accepting a
gamble on the one hand, and accepting a proposition to be true on the other, working with
sets of desirable gambles leads to an account of probabilistic inference with a very logical
flavour; see the work by Moral and Wilson (1995) for an early discussion of this idea.
Quarto, working with sets of desirable gambles encompasses and subsumes as special
cases both classical (or precise) probabilistic inference and inference in classical propositional logic; see Sections 2 and 5.
And finally, quinto, as will be made clear by the discussion throughout, sets of desirable
gambles are eminently suited for dealing with partial probability assessments, in situations
where experts express their beliefs, preferences or behavioural dispositions using finitely
many assessments that need not determine a unique probability measure. In particular, we
will discuss the connection with partial preferences in Section 2.1.
Let us try and present a preliminary defense of these sweeping claims with a few examples. One particular perceived disadvantage of working with lower previsionsor with
previsions and probabilities for that matteris that conditioning a lower prevision need not
lead to uniquely coherent results when the conditioning event has lower or upper probability
zero; see for instance the work of Walley (1991, Section 6.4). For precise probabilities, this
difficulty can be circumvented by using full conditional measures (Dubins, 1975). As we
have already mentioned, in an imprecise-probabilities context, working with the more informative coherent sets of desirable gambles rather than with lower previsions provides a very
602

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

elegant and intuitively appealing way out of this problem, as it has already been suggested
by Walley (1991, Section 3.8.6 and Appendix F), and argued in much more detail in his
later work (Walley, 2000). The connection between full conditional measures and maximal
coherent sets of desirable gambles was recently explored by Couso and Moral (2011): the
latter are still more general and expressive.
The work by De Cooman and Quaeghebeur (2012) has shown that working with sets
of desirable gambles is especially illuminating in the context of modelling exchangeability
assessments: it exposes the simple geometrical meaning of the notion of exchangeability,
and leads to a simple and particularly elegant proof of a significant generalisation to de
Finettis representation theorem for exchangeable random variables (de Finetti, 1931).
Exchangeability is a structural assessment, and so is independence, quite common in
the context of probabilistic graphical models, such as Bayesian (Pearl, 1985) or credal networks (Cozman, 2000). Conditioning and independence are, of course, closely related. In a
recent paper (De Cooman, Miranda, & Zaffalon, 2011), we investigated the notions of epistemic independence of finite-valued variables using coherent lower previsions, thus adding
to the literature where assessments of epistemic irrelevance and independence are studied
for graphical models (De Cooman, Hermans, Antonucci, & Zaffalon, 2010; Destercke & De
Cooman, 2008), as an alternative to the more often used notion of strong independence.
The above-mentioned problems with conditioning, and the fact that the coherence requirements for conditional lower previsions are, to be honest, quite cumbersome to work with,
have turned this into a quite complicated exercise. This is the reason why, in the present
paper, we intend to show that looking at independence using sets of desirable gambles leads
to a more elegant theory that avoids some of the complexity pitfalls of working with coherent lower previsions. In doing this, we build on the strong pioneering work on epistemic
irrelevance by Moral (2005). While we focus here on the symmetrised notion of epistemic
independence, much of what we do can be seen as an application and continuation of his
ideas.
Our goal in this paper is to show how local models for some variables, together with
independence assessments, can be combined in order to produce a joint model. This joint
model can then be used to draw inferences, as is done for instance in the context of Bayesian
or credal networks (Antonucci, de Campos, & Zaffalon, 2012; Cozman, 2000; Pearl, 1985).
One of the core ideas of such probabilistic graphical models is to provide a representation
of this joint model that is less taxing from a computational point of view.
There are three main novelties to our approach: the first is that we allow for imprecision
in the local modelsalthough precise models are a particular case; the second is that we
model local probability assessments by means of sets of desirable gambles, because of the
above-mentioned advantages they possess over coherent lower previsions; and the third
is that we stress epistemic irrelevance and independence rather than the more common
assessment strong independence, for reasons that will become clear further onalthough
we also discuss strong independence.
With the results in this paper we are adding useful tools to the growing toolbox for
reasoning with partial probability assessments that sets of desirable gambles constitute,
something already started in our work on exchangeability (De Cooman & Quaeghebeur,
2012) and the work on epistemic irrelevance and credal networks by Moral (2005). In this
regard, it is also interesting to mention that algorithms for making inferences with sets
603

fiDe Cooman & Miranda

of desirable gambles have been recently established (Couso & Moral, 2011; Quaeghebeur,
2012a). Having such a set of tools that are easily implemented in computer programs is
clearly beneficial to a field like AI, which should surely be interested in coherent reasoning
under uncertainty with general and robust uncertainty models that require no full specification. This paper constitutes a further step in that direction, and it also allows us to
see more clearly which are the main difficulties faced when working with sets of desirable
gambles. There remain, however, a number of important situations to be dealt with, and
future lines of research are discussed in a number of places in the paper, as well as in the
Conclusion.
In Section 2 we summarise relevant results in the existing theory of sets of desirable
gambles. After mentioning useful notational conventions in Section 3, we recall the basic
marginalisation, conditioning and extension operations for sets of desirable gambles in Sections 4 and 5. We use these to combine a number of marginal sets of desirable gambles into
a joint satisfying epistemic irrelevance (Section 6), and epistemic independence (Section 7).
In Section 8, we study the particular case of maximal coherent sets of desirable gambles,
and derive the concept of a strong product. Section 9 deals with conditional independence
assessments.

2. Coherent Sets of Desirable Gambles and Natural Extension
Let us begin by explaining what our basic uncertainty models, coherent sets of desirable
gambles, are about (more details can be found in Augustin, Coolen, De Cooman, & Troffaes,
2012; Couso & Moral, 2011; De Cooman & Quaeghebeur, 2012; Moral, 2005; Walley, 2000).
Consider a variable X taking values in some possibility space X, which we assume in this
paper to be finite.3 We model information about X by means of sets of desirable gambles.
A gamble is a real-valued function on X, and we denote the set of all gambles on X by G(X ).
It is a linear space under point-wise addition of gambles, and point-wise multiplication of
gambles with real numbers. For any subset A of G(X ), we denote by posi(A) the set of all
positive linear combinations of gambles in A:
posi(A) :=

X
n
k=1


k fk : fk  A, k > 0, n > 0 .

We call A a convex cone if it is closed under positive linear combinations, meaning that
posi(A) = A.
For any two gambles f and g on X, we write f  g if (x  X )f (x)  g(x), and
f > g if f  g and f 6= g. A gamble f > 0 is called positive. A gamble g  0 is called
non-positive. G(X )6=0 denotes the set of all non-zero gambles, G(X )>0 the convex cone of
all positive gambles, and G(X )0 the convex cone of all non-positive gambles.
3. All the results in this section remain valid when working with more general, possibly infinite, possibility
spaces, and in that case gambles are assumed to be bounded real-valued functions. We make this finiteness assumption here to avoid having to deal with the controversial issue of conglomerability (Miranda,
Zaffalon, & De Cooman, 2012; Walley, 1991), because it will make the discussion of independence in
later sections significantly easier, and because most practically implementable inference systems in AI
are finitary in any case.

604

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

2.1 Coherence and Avoiding Non-positivity
Definition 1 (Avoiding non-positivity and coherence). We say that a set of desirable gambles D  G(X ) avoids non-positivity if f 6 0 for all gambles f in posi(D), or
in other words if G(X)0  posi(D) = . It is called coherent if it satisfies the following
requirements:
D1. 0 
/ D;
D2. G(X )>0  D;
D3. D = posi(D).
We denote by D(X) the set of all coherent sets of desirable gambles on X.
Requirement D3 turns D into a convex cone. Due to D2, it includes G(X )>0 ; due to D1D3,
it excludes G(X)0 , and therefore avoids non-positivity:
D4. if f  0 then f 
/ D, or equivalently G(X )0  D = .
The set G(X )>0 is coherent, and it is the smallest such subset of G(X ). This set represents
minimal commitments on the part of the subject, in the sense that if he knows nothing
about the likelihood of the different outcomes he will only prefer to zero those gambles
which are sure to never decrease his wealth and have a possibility of increasing it. Hence,
it is usually taken to model complete ignorance, and it is called the vacuous model.
One interesting feature of coherent sets of desirable gambles is that they are linked to the
field of decision making with incomplete preferences (Aumann, 1962; Dubra, Maccheroni,
& Ok, 2004; Shapley & Baucells, 1998), because they are formally equivalent to the strict
versions of partial preference orderings (Buehler, 1976; Giron & Rios, 1980). Given a
coherent set of desirable gambles D, we can define a strict preference relation  between
gambles by
f  g  f  g  D for any gambles f and g in G(X ).
Indeed, due to the linearity of the utility scale, exchanging a gamble g for a gamble f is
a transaction with reward function f  g, and strictly preferring f over g means that this
exchange should be strictly preferred to the status quo (zero). The relation  satisfies the
following conditions:
SP1. f  f for all f  G(X )

[irreflexivity]

SP2. f > g  f  g for all f, g  G(X )

[monotonicity]

SP3. f  g and g  h  f  h for all f, g, h  G(X )

[transitivity]

SP4. f  g  f + (1  )h  g + (1  )h for all   (0, 1] and f, g, h  G(X ) [mixture
independence]
Conversely, any preference relation satisfying the above axioms determines a coherent set of
desirable gambles. Partial preference orderings provide a foundation for a general decision
theory with imprecise probabilities and imprecise utilities (Fishburn, 1975; Seidenfeld et al.,
1995; Seidenfeld, Schervish, & Kadane, 2010). See also the work by Moral and Wilson
(1995), Walley (1991, 2000) and Quaeghebeur (2012b, Section 2.4) for more information.
605

fiDe Cooman & Miranda

2.2 Natural Extension
If we consider anyTnon-empty family of coherent sets of desirable gambles Di , i  I, then
their intersection iI Di is still coherent. This is the idea behind the following result,
which brings to the fore a notion of coherent inference. If a subject gives us an assessment,
a set A  G(X ) of gambles on X that he finds desirable, then it tells us exactly when this
assessment can be extended to a coherent set of desirable gambles, and how to construct
the smallest such set.
Theorem 1 (De Cooman & Quaeghebeur, 2012). Consider A  G(X ), and define
its natural extension by:4
\
E(A) :=
{D  D(X) : A  D} .

Then the following statements are equivalent:
(i) A avoids non-positivity;

(ii) A is included in some coherent set of desirable gambles;
(iii) E(A) 6= G(X );
(iv) the set of desirable gambles E(A) is coherent;
(v) E(A) is the smallest coherent set of desirable gambles that includes A.
When any (and hence all) of these equivalent statements hold, then

E(A) = posi G(X )>0  A .

This shows that if we have an assessment A with a finite description, we can represent
its natural extension on a computer by storing a finite description of its extreme rays.
Although in general our assessments A need not have a finite description (for instance
those considered in Eq. (3) further on can but need not have one), they will be of interest
in a vast range of practical situations. For a description of the many cases where partial
probability assessments can be given a finite description, and for efficient algorithms for
verifying the coherence or computing the natural extension of a set of gambles, we refer to
the work by Couso and Moral (2011) and Quaeghebeur (2012a).
2.3 Connection with Classical Propositional Logic
The definition of a coherent set of desirable gambles, and Theorem 1, make clear that inference with desirable gambles bears a formal resemblance to deduction in classical proposition
logic: D3 is a production axiom that states that positive linear combinations of desirable
gambles are again desirable. The exact correspondences are listed in the following table:
Classical propositional logic
logical consistency
deductively closed
deductive closure
4. As usual, in this expression, we let

T

 = G(X ).

606

Sets of desirable gambles
avoiding non-positivity
coherent
natural extension

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

We shall see that this inference with sets of desirable gambles has (precise-)probabilistic
inference, and in particular Bayess Rule, as a special case. But it is easy to see that it also
generalises (includes as a special case) classical propositional logic: a proposition p can be
identified with a subset Ap of the Stone space X , and accepting a proposition p corresponds
to judging the gamble IAp  1 +  to be desirable for all  > 0.5 Here IAp is the so-called
indicator (gamble) of Ap , assuming the value 1 on Ap and 0 elsewhere. See the work by De
Cooman (2005) for a more detailed discussion.
2.4 Helpful Lemmas
In order to prove a number of results in this paper, we need the following lemmas, one of
which is convenient version of the separating hyperplane theorem. They rely heavily on the
assumption of a finite space X , and are not easily extended to a more general case.
Lemma 2. Assume that X is finite, and consider a finite subset A of G(X ). Then 0 
/
posi(G(X )>0  A) ifPand only if there is some probability mass function p such that p(x) > 0
for all x  X and xX p(x)f (x) > 0 for all f  A.

Proof. It clearly suffices to prove necessity. Since 0 
/ posi(G(X )>0  A), we infer from a
version of the separating hyperplane theorem (Walley, 1991, Appendix E.1) that there is a
linear functional  on G(X ) such that
(x  X)(I{x} ) > 0 and (f  A)(f ) > 0.

P
Then (X ) = xX (I{x} ) > 0, and if we let p(x) := (I{x} )/(X
P ) > 0 for all x  X,
then p is a probability mass function on X for which (f )/(X ) = xX p(x)f (x) > 0 for
all f  A.
Our second lemma implies that if we consider a coherent set of desirable gambles that
does not include a gamble nor its opposite, we can always find a coherent superset that
includes one of the two:
Lemma 3. Consider a convex cone A of gambles on X such that max f > 0 for all f  A.
Consider any non-zero gamble g on X. If g 
/ A then 0 
/ posi(A  {g}).
Proof. Consider a non-zero gamble g 
/ A, and assume ex absurdo that 0  posi(A  {g}).
Then it follows from the assumptions that there are f  A and  > 0 such that 0 =
f + (g). Hence g  A, a contradiction.
2.5 Maximal Coherent Sets of Desirable Gambles
An element D of D(X) is called maximal if it is not strictly included in any other element of
D(X), or in other words, if adding any gamble f to D makes sure we can no longer extend
the set D  {f } to a set that is still coherent:
(D   D(X))(D  D   D = D  ).
5. This is not equivalent to judging the gamble IAp  1 to be desirable, as in that case we do not obtain
a coherent set of desirable gambles; the gamble IAp  1 is only almost-desirable in the sense of Walley
(1991, Section 3.7.3).

607

fiDe Cooman & Miranda

M(X ) denotes the set of all maximal elements of D(X).
The following proposition provides a useful characterisation of such maximal elements.
Proposition 4 (De Cooman & Quaeghebeur, 2012). Consider any D  D(X ). It is
a maximal coherent set of desirable gambles if and only if
(f  G(X )6=0 )(f 
/ D  f  D).
As is the case for classical propositional logic (see, for instance, De Cooman, 2005),
coherence and inference can be described completely in terms of such maximal elements.
This is the essence of the following important result, which continues to hold for infinite X,
but for which a constructive proof can be given in case X is finite, based on the argument
suggested by Couso and Moral (2011).
Theorem 5 (Couso & Moral, 2011; De Cooman & Quaeghebeur, 2012). A set A
avoids non-positivity if and only if there is some maximal M  M(X ) such that A  M.
Moreover
\
E(A) =
m(A),
where we let

m(A) := {M  M(X ) : A  M} .

(1)

This shows that (coherent) sets of desirable gambles are instances of the so-called strong
belief structures described and studied in detail by De Cooman (2005), into which the strong
belief structures of classical propositional logic can be embedded. This guarantees amongst
other things that an AGM-like (De Cooman, 2005; Gardenfors, 1988) account of belief
expansion and revision is possible for these objects.
2.6 Coherent Lower Previsions
We conclude this section by shedding some light on the connection between coherent sets
of desirable gambles, coherent lower previsions, and probabilities.
Given a coherent set of desirable gambles D, the functional P defined on G(X ) by
P (f ) := sup { : f    D}

(2)

is a coherent lower prevision (Walley, 1991, Thm. 3.8.1), that is, it corresponds to taking
the lower envelope of the expectations associated with a set of finitely additive probabilities.
The conjugate upper prevision P is defined by P (f ) := inf { :   f  D} = P (f ).
Many different coherent sets of desirable gambles induce the same coherent lower prevision P , and they typically differ only in their boundaries. In this sense, we can say that
sets of desirable gambles are more informative than coherent lower previsions: although
a gamble with positive lower prevision is always desirable and one with a negative lower
prevision is not desirable, a lower prevision does not generally provide information about
the desirability of a gamble whose lower prevision equal to zero. This is the reason why we
need to consider the sets of desirable gambles if we want to have this additional information.
To see this more clearly, consider the following adaptation of an example by Moral (2005,
Example 1):
608

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

Example 1. Consider X 1 = X 2 = {a, b}, and let P be the coherent lower prevision on
G(X 1  X 2 ) given by


f (b, a) + f (b, b) f (b, a) + 3f (b, b)
:=
P (f )
,
min
for all gambles f on X 1  X 2 .
2
4
This coherent lower prevision is induced by each of the following coherent sets of desirable
gambles by means of Eq. (2):
D := {f : f > 0 or P (f ) > 0}
D  := D  {f : f (b, a) = f (b, b) = 0 and f (a, a) + f (a, b) > 0} .
However, these two sets encode different preferences, as the gamble g given by g(a, a) = 2,
g(a, b) = 1, g(b, a) = g(b, b) = 0, with P (g) = 0, is considered desirable for D  but not for
D. This is because coherent lower previsions are not able to distinguish between preferences
and weak preferences, while sets of desirable gambles can. We shall see in Section 5 that
these differences come into play when considering conditioning. 
The smallest set of desirable gambles that induces a given coherent lower previsionan
open coneis called the associated set of strictly desirable gambles, and is given by
D := {f  G(X ) : f > 0 or P (f ) > 0} .

(3)

This is for instance the case of the set D in Example 1. Sets of strictly desirable gambles
are in a one-to-one relationship with coherent lower previsions, and as such they suffer from
the same problems when conditioning on sets of (lower) probability zero, in the sense that
in the conditional models they determine in that caseby means of Eqs. (8) and (10) in
Section 5are always vacuous (Zaffalon & Miranda, 2012; Quaeghebeur, 2012b). This is
one of the reasons why in this paper we are considering the more general model of coherent
sets of (not necessarily strictly) desirable gambles. For additional discussion about why
sets of desirable gambles are more informative than coherent lower previsions, we refer to
Walley (2000) and Quaeghebeur (2012b).
When the lower and the upper prevision coincide on all gambles, then the functional
P defined on G(X ) by P(f ) := P (f ) = P (f ) for all f  G(X ) is a linear prevision, i.e., it
corresponds to the expectation operator with respect to a finitely additive probability. This
happens in particular if D is a maximal coherent set of desirable gambles M:
P (f ) = sup { : f    M} = inf { : f   
/ M} = inf { :   f  M} = P (f );
to see why the second equality holds, observe that if f    M then also f    M for
all  < , and as a consequence the set { : f    M} is an interval that is unbounded
below. The third equality follows from Proposition 4. Thus, up to boundary behaviour,
precise probability models correspond to a maximal coherent sets of desirable gambles; see
the work by Couso and Moral (2011, Section 5), Miranda and Zaffalon (2010, Proposition 6)
and Williams (1975a) for more information. Moreover, any coherent lower prevision P is
the lower envelope of the credal set M(P ) it induces, given by
M(P ) := {P linear prevision : (f  G(X ))P(f )  P (f )} .
We can conclude at this point that at least in its basic representational aspects, models
involving coherent sets of desirable gambles generalise both classical propositional logic and
precise probability in its finitary approach championed by de Finetti (1937, 1975).
609

fiDe Cooman & Miranda

3. Basic Notation
Now that we have highlighted the basic facts about this more general approach to uncertainty modelling, we are ready to turn to independence. In order to talk about this, we need
to be able to deal with models involving more than one variable. In the present section, we
introduce the notational devices we will use to make this discussion as elegant as possible.
From now on, we consider a number of variables Xn , n  N , taking values in the
respective finite sets X n . Here N is some finite non-empty index set.6
For every subset R of N , we denote by XR the tuple of variables (with one component
:= rR X r . This Cartesian
for each r  R) that takes values in the Cartesian
S product X R
product is the set of all maps xR from R to rR X r such that xr := xR (r)  X r for all
r  R. Elements of X R are generically denoted by xR or zR , with corresponding components
xr := xR (r) or zr := zR (r), r  R.
We will assume that the variables Xn are logically independent, which means that for
each subset R of N , XR may assume all values in X R .
We denote by G(X R ) the set of gambles defined on X R . We will frequently resort to
the simplifying device of identifying a gamble on X R with a gamble on X N , namely its
cylindrical extension. To give an example, if K  G(X N ), this trick allows us to consider
KG(X R ) as the set of those gambles in K that depend only on the variable XR . As another
example, this device allows us to identify the gambles I{xR } and I{xR }X N\R , and therefore
also the events {xR } and {xR }  X N \R . More generally, for any event A  X R , we can
identify the gambles IA and IAX N\R , and therefore also the events A and A  X N \R .
We must paySparticular attention to the case R = . By definition, X  is the set of all
maps from  to r X r = . It contains only one element x : the empty map. This means
that there is no uncertainty about the value of the variable X : it can assume only one
value (the empty map). Moreover IX  = I{x } = 1. Also, we can identify G(X  ) with the
set of real numbers R. There is only one coherent set of desirable gambles on X  : the set
R>0 of positive real numbers.
One final notational convention that is very handy and will be used throughout: if n
is an index, then we identify n and {n}. So we take X {n} , G(X {n} ), D{n} to also refer to
X n , G(X n ) and Dn , respectively. This trick, amongst other things, allows us to consider
two disjoint index sets N1 and N2 , and consider each of these sets to constitute an index in
themselves, leading to a new index set {N1 , N2 }. The variables XN1 and XN2 can then be
combined into a joint variable X{N1 ,N2 } , which can of course be identified with the variable
XN1 N2 : joint variables can be considered as single variables, and combined to constitute
new joint variables.

4. Marginalisation and Cylindrical Extension
Suppose that we have a set DN  G(X N ) of desirable gambles modelling a subjects information about the uncertain variable XN .
6. The assumption of finiteness of the spaces X n is essential for the proofs of some of the results established
later on, such as Theorem 13 and Proposition 18. It also allows us to simplify some of the expressions of
the sets of gambles derived by an assumption of epistemic irrelevance or independence, from which we
derive for instance Lemma 11 and Proposition 14.

610

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

We are interested in modelling the information about the variable XO , where O is some
subset of N . This can be done using the set of desirable gambles that belong to DN but
only depend on the variable XO :
margO (DN ) := {g  G(X O ) : g  DN } = DN  G(X O ).

(4)

Observe that if DN is coherent we obtain marg (DN ) = G(X  )>0 , which can be identified
with the set of positive real numbers R>0 . Also, with O1  O2  N :

	
margO1 (margO2 (DN )) = g  G(X O1 ) : g  margO2 (DN )
= {g  G(X O1 ) : g  G(X O2 )  DN }

= {g  G(X O1 ) : g  DN } = margO1 (DN ).

(5)

Coherence is trivially preserved under marginalisation.
Proposition 6. Let DN be a set of desirable gambles on X N , and consider any subset O
of N .
(i) If DN avoids non-positivity, then so does margO (DN ).
(ii) If DN is coherent, then margO (DN ) is a coherent set of desirable gambles on X O .
We now look for a kind of inverse operation to marginalisation. Suppose we have a
coherent set of desirable gambles DO  G(X O ) modelling a subjects information about the
uncertain variable XO , and we want to extend this to a coherent set of desirable gambles
on X N , representing the same information. So we are looking for a coherent set of desirable
gambles DN  G(X N ) such that margO (DN ) = DO and that is as small as possible: the
most conservative coherent set of desirable gambles on X N that marginalises to DO . It
turns out that such a set always exists and is not difficult to find.
Proposition 7. Let O be a subset of N and let DO  D(X O ). Then the most conservative
(smallest) coherent set of desirable gambles on X N that marginalises to DO is given by
extN (DO ) := posi(G(X N )>0  DO ).

(6)

It is called the cylindrical extension of DO to a set of desirable gambles on X N , and clearly
satisfies
margO (extN (DO )) = DO .
(7)
This extension is called weak extension by Moral (2005, Section 2.1).7
Proof. It is clear from the coherence requirements and Eq. (4) that any coherent set of
desirable gambles that marginalises to DO must include G(X N )>0 and DO , and therefore
also posi(G(X N )>0 DO ) = extN (DO ). It therefore suffices to prove that posi(G(X N )>0 DO )
is coherent, and that it marginalises to DO .
7. The main difference between our result and Morals is that we are excluding the zero gamble from any
coherent set of desirable gambles, while Moral is including it.

611

fiDe Cooman & Miranda

To prove coherence, it suffices to prove that DO avoids non-positivity, by Theorem 1.
But this is obvious because DO is a coherent set of desirable gambles on X O .
We are left to prove that margO (extN (DO )) = DO . Since for any g  DO it is obvious
that both g  extN (DO ) and g  G(X O ), we see immediately that DO  margO (extN (DO )),
so we concentrate on proving the converse inclusion. Consider f  margO (extN (DO )),
meaning that both f  G(X O ) and f  extN (DO ). The latter means that there are g  DO ,
h  G(X N )>0 , and non-negative  and  such that max{, } > 0 for which f = g + h.
Since we need to prove that f  DO , we can assume without loss of generality that  > 0.
But then h = (f  g)/  G(X O ) and therefore also h  G(X O )>0 , whence indeed f  DO ,
by coherence of DO .

5. Conditioning
Suppose that we have a set DN  G(X N ) of desirable gambles modelling a subjects information about the uncertain variable XN .
Consider a subset I of N , and assume we want to update the model DN with the
information that XI = xI . This leads to an updated, or conditioned, set of desirable gambles:

	
DN |xI := f  G(X N ) : f > 0 or I{xI } f  DN .
(8)

For technical reasons, and mainly in order to streamline the proofs as much as possible, we
also allow the admittedly pathological case that I = . Since I{x } = 1, this amounts to not
conditioning at all.
Eq. (8) introduces the conditioning operator | essentially used by Walley (2000) and
Moral (2005). We prefer the slightly modified version , introduced by De Cooman and
Quaeghebeur (2012). Since I{xI } f = I{xI } f (xI , ), we can characterise the updated model
DN |xI through the set

	
DN xI := g  G(X N \I ) : I{xI } g  DN  G(X N \I ),
in the specific sense that for all g  G(X N \I ):

g  DN xI  I{xI } g  DN  I{xI } g  DN |xI ,

(9)

and for all f  G(X N ):
f  DN |xI  (f > 0 or f (xI , )  DN xI ).
As the above equation shows, there is a one-to-one correspondence between DN |xI and
DN xI . We prefer this second operator because we find it more intuitive that conditioning
a gamble on some xI  X I produces a gamble that depends only on the remaining N \ I
variables. This will be useful for instance when combining conditional sets of gambles, as
in Proposition 24 later on.
It is immediate to prove that conditioning preserves coherence:
Proposition 8. Let DN be a coherent set of desirable gambles on X N , and consider any
subset I of N . Then DN xI is a coherent set of desirable gambles on X N \I .
612

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

The order of marginalisation and conditioning can be reversed, under some conditions:
Proposition 9. Let DN be a coherent set of desirable gambles on X N , and consider any
disjoint subsets I and O of N . Then for all xI  X I :
margO (DN xI ) = margIO (DN )xI .
Proof. Consider any h  G(X N ) and observe the following chain of equivalences:
h  margO (DN xI )  h  G(X O ) and h  DN xI
 h  G(X O ) and I{xI } h  DN
 h  G(X O ) and I{xI } h  margIO (DN )
 h  G(X O ) and h  margIO (DN )xI
 h  margIO (DN )xI .
To end this section, let us briefly look at the consequences of this type of updating for
the coherent lower previsions associated with coherent sets of desirable gambles. This will
allow us to further back our claim that standard probability theory can be recovered as a
special case of the theory of coherent sets of desirable gambles, as it also allows us to derive
Bayess Rule.
Let us denote by P N the lower prevision induced by the joint model DN , and by P (|xI )
the conditional lower prevision on G(X N \I ) induced by the updated set DN xI . Then for
any gamble g on X N \I :

	
P (g|xI ) = sup { : g    DN xI } = sup  : I{xI } [g  ]  DN .
(10)

This allows us to clarify further that sets of desirable gambles are indeed more informative than coherent lower previsions, again using the example by Moral (2005):
Example 2. Consider again the lower prevision P and the coherent sets of desirable gambles D and D  from Example 1. Consider the event that X1 = a, which has (upper) probability zero in both D and D  . When conditioning on this event, we obtain two different
updated sets: on the one hand,
D(X1 = a) = {g  G(X 2 ) : g > 0} = G(X 2 )>0
whereas
D  (X1 = a) = {g  G(X 2 ) : g(a) + g(b) > 0} .
This means that there sets represent different information when conditioning on the event
of probability zero X1 = a. Indeed, if we apply Eq. (10) we see that the first one induces the
vacuous lower prevision P (g|X1 = a) = min{g(a), g(b)} for any gamble g on X 2 , while the
second one induces the uniform linear prevision: P (g|X1 = a) = g(a)+g(b)
. 
2
The lower previsions P N and P (|xI ) then satisfy a condition called the Generalised
Bayes Rule (this follows from Williams, 1975b and Miranda & Zaffalon, 2010, Thm. 8):
P N (I{xI } [g  P (g|xI )]) = 0.
613

(11)

fiDe Cooman & Miranda

We refer to the work by Walley (1991, 2000) for more information about this rule. It leads
to Bayess Rule in the special case that the joint model DN induces a precise prevision PN .
Indeed, if we let g = I{xN\I } and generically denote probability mass by p, we infer from
Eq. (11) and the linearity of PN that PN (I{xI } I{xN\I } ) = P (I{xN\I } |xI )PN (I{xI } ), or in other
words that p(xN ) = p(xN \I |xI )p(xI ). See Section 2.6 for more details on the relationship
between coherent lower (and linear) previsions and sets of desirable gambles.
Remark 1. A lower prevision P is also in a one-to-one correspondence with a so-called
set of almost desirable gambles, namely
D := {f : P (f )  0} .
This set corresponds to the uniform closure of any coherent set of desirable gambles D that
induces P by means of Eq. (2). Although sets of almost-desirable gambles are interesting,
and allow us work with non-strict preference relations (Walley, 1991, Section 3.7.6), we have
opted for considering the more general model of coherent sets of desirable gambles for two
(admittedly related) reasons. Like sets of strictly desirable gambles, sets of almost-desirable
gambles do not permit to elicit boundary behaviour, which may be important when updating, as we have discussed in Example 2. Moreover, conditioning a set of almost desirable
gambles may produce incoherent models when sets of probability zero are involved (Miranda
& Zaffalon, 2010, Proposition 5 and Example 2): if we take for instance X 1 = X 2 = {0, 1}
and the linear prevision P with mass function p(0, ) = 0 and p(, 1) = 12 , then its associated
set of almost desirable gambles is:
D = {f : f (1, 0) + f (1, 1)  0} ,
and if we use Eq. (8) to condition this set D on X1 = 0, we get G(X 1,2 ), which is an
incoherent set. This means that for such sets of almost desirable gambles, and more generally
for sets of gambles associated with non-strict preferences, the conditioning operation must
be modified in order to avoid producing incoherences. It turns out there is no unique way
of doing this; see the work by Hermans (2012) for more details. 

6. Irrelevant Natural Extension
We are now ready to look at the simplest type of irrelevance judgement.
Definition 2. Consider two disjoint subsets I and O of N . We say that XI is epistemically
irrelevant to XO when learning the value of XI does not influence or change our subjects
beliefs about XO .
When does a set DN of desirable gambles on X N capture this type of epistemic irrelevance? Observing that XI = xI turns DN into the updated set DN xI of desirable gambles
on X N \I , we come to the following definition:
Definition 3. A set DN of desirable gambles on X N is said to satisfy epistemic irrelevance
of XI to XO when
margO (DN xI ) = margO (DN ) for all xI  X I .
614

(12)

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

As before, for technical reasons we also allow I and O to be empty. It is clear from
the definition above that the variable X , about whose constant value we are certain,
is epistemically irrelevant to any variable XO . Similarly, we see that any variable XI is
epistemically irrelevant to the variable X . This seems to be in accordance with intuition.
We refer to Levi (1980) and Walley (1982, 1991) for related notions in terms of coherent
lower previsions or credal sets.
The epistemic irrelevance condition can be reformulated trivially in an interesting and
slightly different manner.
Proposition 10. Let DN be a coherent set of desirable gambles on X N , and let I and O
be any disjoint subsets of N . Then the following statements are equivalent:
(i) margO (DN xI ) = margO (DN ) for all xI  X I ;
(ii) for all f  G(X O ) and all xI  X I : f  DN  I{xI } f  DN .
Proof. It suffices to take into account that f  margO (DN ) if and only if f  DN and
f  G(X O ), while f  margO (DN xI ) if and only if f  G(X O ) and I{xI } f  DN .
Irrelevance assessments are most useful in constructing sets of desirable gambles from
other ones. Suppose we have a coherent set DO of desirable gambles on X O , and an assessment that XI is epistemically irrelevant to XO , where I and O are disjoint index sets. Then
how can we combine DO and this structural irrelevance assessment into a coherent set of
desirable gambles on X IO , or more generally, on X N , where N  I  O? To see how this
can be done in a way that is as conservative as possible, we introduce the following sets

	
Airr
I{xI } g : g  DO and xI  X I
(13)
IO := posi
= {h  G(X IO )6=0 : (xI  X I )h(xI , )  DO  {0}} .

(14)

irr
Clearly, and this will be quite important in streamlining proofs, Airr
O = DO and AI =
G(X I )>0 . The intuition behind Eq. (13) is to consider the cylindrical extensions of the
gambles in DO to the space X IO , and to take the natural extension of the resulting set.
The alternative expression (14) shows that this is equivalent to selecting a gamble in DO
for a finite number of xI in X I , and to derive from them a gamble on X IO .
Let us give two important properties of these sets:

Lemma 11. Consider disjoint subsets I and O of N , and a coherent set DO of desirable
gambles on X O . Then Airr
IO is a coherent set of desirable gambles on X IO .
Proof.PD1. Assume ex absurdo that there are n > 0, real k > 0 and fk  Airr
IO such
that nk=1 k fk = 0. It follows from the assumptions that there
are


{1,
.
.
. , n} and
Pn
xI  X I such that f (xI , ) 6= 0. This implies that in the sum k=1 k fk (xI , ) = 0 not all
the gambles k fk (xI , ) are zero. Since the non-zero ones belong to DO , this contradicts the
coherence of DO .
D2. Consider any h  G(X IO )>0 . Then clearly h(xI , )  0 and therefore h(xI , ) 
DO  {0} for all xI  X I . Since h 6= 0, it follows that indeed h  Airr
IO .
D3. Trivial, using that posi(posi(D)) = posi(D) for any set of desirable gambles D.
615

fiDe Cooman & Miranda

Lemma 12. Consider disjoint subsets I and O of N , and a coherent set DO of desirable
gambles on X O . Then margO (Airr
IO ) = DO .
Proof. It is obvious from Eq. (14) that indeed:
irr
margO (Airr
IO ) = AIO  G(X O ) = {h  G(X O )6=0 : (xI  X I )h  DO  {0}}

= {h  G(X O )6=0 : h  DO  {0}} = DO .
Theorem 13. Consider disjoint subsets I and O of N , and a coherent set DO of desirable gambles on X O . Then the smallest coherent set of desirable gambles on X N that
marginalises to DO and satisfies the epistemic irrelevance condition (12) of XI to XO is
irr
given by extN (Airr
IO ) = posi(G(X N )>0  AIO ).
Proof. Consider any coherent set DN of desirable gambles on X N that marginalises to DO
and satisfies the irrelevance condition (12). This implies that margO (DN xI ) = DO for any
xI  X I , so g  DN xI , and therefore I{xI } g  DN for any g  DO , by Eq. (9). So we infer
irr
by coherence that Airr
IO  DN , and therefore also that posi(G(X N )>0  AIO )  DN . As
a consequence, it suffices to prove that (i) extN (Airr
IO ) is coherent, (ii) marginalises to DO ,
and (iii) satisfies the epistemic irrelevance condition (12). This is what we now set out to
do.
(i). By Lemma 11, Airr
IO is a coherent set of desirable gambles on X IO , so Proposition 7
irr
implies that posi(G(X N )>0  Airr
IO ) = extN (AIO ) is a coherent set of desirable gambles
on X N .
(ii). Marginalisation leads to:
irr
irr
margO (extN (Airr
IO )) = margO (margIO (extN (AIO ))) = margO (AIO ) = DO ,

where the first equality follows from Eq. (5), the second from Eq. (7), and the third from
Lemma 12.
(iii). It follows from Proposition 9 and Eq. (7) that
irr
irr
margO (extN (Airr
IO )xI ) = margIO (extN (AIO ))xI = AIO xI ,

and we have just shown in (ii) that margO (extN (Airr
IO )) = DO , so proving the equality
irr )) amounts to proving that Airr x = D .
margO (extN (Airr
)x
)
=
marg
(ext
(A
I
N
O
O
IO
IO
IO I
irr x , so we concentrate on the
It is obvious from the definition of Airr
that
D

A
O
I
IO
IO
irr
converse inclusion. Consider any h  Airr
IO xI ; then I{xI } h  AIO , so we infer from
Eq. (14) that in particular h  DO  {0}. But since Airr
IO is coherent by Lemma 11, we see
that h 6= 0 and therefore indeed h  DO .
Theorem 13 is mentioned briefly, with only a hint at the proof, by Moral (2005, Section 2.4).
We believe the result is not so trivial and have therefore decided to include our version of
the proof here. Our notion of epistemic irrelevance is called weak epistemic irrelevance by
Moral. For his version of epistemic irrelevance he requires in addition that DN should be
equal to the irrelevant natural extension of DO , and therefore be the smallest model that
satisfies the (weak) epistemic irrelevance condition (12). While we feel comfortable with
616

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

his reasons for doing so, we have decided not to follow his lead in this. Our main reason
for not doing so is tied up with the philosophy behind partial assessments (or probability
specifications). Each such assessment, be it local (e.g. stating that all gambles in some set
A are desirable) or structural (e.g. imposing symmetry or irrelevance), serves to further
restrict the possible models, and at each stage the most conservative (smallest possible)
model is considered to be the one to be used, and possibly further refined by additional
assessments. Only calling a model irrelevant when it is the smallest weakly irrelevant model
would, we believe, conflict with approach: larger models obtained later on by adding, say,
further symmetry assessments, would no longer deserve to be called irrelevant (but would
still satisfy all the relevant conditions).
We infer from Theorem 13 and Eq. (13) that extreme rays of the irrelevant natural
extension have the form I{xI } g, where g is some extreme ray of DO , so representing or
finding this extension on a computer has a computational complexity that is linear in the
number of extreme rays of DO and linear in the number of elements of the product set X I 
and therefore essentially exponential in the number |I| of irrelevant variables Xi , i  I. More
generally, this will also be the case in the fairly general situation where DO is generated by
a finite number of so-called generalised extreme rays, as described in detail in by Couso
and Moral (2011, Section 4) and Quaeghebeur (2012a, Section 3).

7. Independent Natural Extension
We now turn to independence assessments, which constitute a symmetrisation of irrelevance
assessments.
Definition 4. We say that the variables Xn , n  N are epistemically independent when
learning the values of any number of them does not influence or change our beliefs about the
remaining ones: for any two disjoint subsets I and O of N , XI is epistemically irrelevant
to XO .
When does a set DN of desirable gambles on X N capture this type of epistemic independence?
Definition 5. A coherent set DN of desirable gambles on X N is called independent if
margO (DN xI ) = margO (DN ) for all disjoint subsets I and O of N , and all xI  X I .
In this definition, we allow I and O to be empty too, but doing so does not lead to any
substantive requirement, because the condition margO (DN xI ) = margO (DN ) is trivially
satisfied when I or O are empty.
Independent sets have an interesting factorisation property, which means that a product
of two desirable gambles that depend on different variables should again be desirable, provided one of the gambles is positive; we refer to the work by De Cooman et al. (2011) for another paper where factorisation is considered in this somewhat unusual form. Factorisation
follows from the characterisation of epistemic irrelevance we have given in Proposition 10
and the properties of coherence.

617

fiDe Cooman & Miranda

Proposition 14 (Factorisation of independent sets). Let DN be an independent coherent set of desirable gambles on X N . Then for all disjoint subsets I and O of N and for
all f  G(X O ):
f  DN  (g  G(X I )>0 )(f g  DN ).
(15)
Proof. Fix arbitrary disjoint subsets I and O of N and any f  G(X O ); we show that
Eq. (15) holds. The  part is trivial. For the  part, assume P
that f  DN and consider
any g  G(X
)
.
We
have
to
show
that
f
g

D
.
Since
g
=
N
xI X I I{xI } g(xI ), we see
P I >0
that f g = xI X I g(xI )I{xI } f . Now since f  margO (DN ), we infer from the independence
of DN and Proposition 10 that f  DN xI and therefore I{xI } f  DN for all xI  X I . We
conclude that f g is a positive linear combination of elements I{xI } f of DN , and therefore
belongs to DN by coherence.
Independence assessments are useful in constructing joint sets of desirable gambles from
marginal ones. Suppose we have coherent sets Dn of desirable gambles on X n , for each n  N
and an assessment that the variables Xn , n  N are epistemically independent. Then how
can we combine the Dn and this structural independence assessment into a coherent set of
desirable gambles on X N in a way that is as conservative as possible? If we call independent
product of the Dn any independent DN  D(X N ) that marginalises to the Dn for all n  N ,
this means we are looking for the smallest such independent product.
Further on, we are going to prove that such a smallest independent product always exists.
Before we can do this elegantly, however, we need to do some preparatory work involving
particular sets of desirable gambles that can be constructed from the Dn . Consider, as a
special case of Eq. (14), for any subset I of N and any o  N \ I:

	
I{xI } g : g  Do and xI  X I
(16)
Airr
I{o} := posi

	
= h  G(X I{o} )6=0 : (xI  X I )h(xI , )  Do  {0} ,
(17)
and use these sets to construct the following set of gambles on X N :


 [

[
irr
nN Dn := posi G(X N )>0 
Airr
=
posi
A
N \{n}{n}
N \{n}{n} ,
nN

(18)

nN

where the second equality holds because the set G(X N )>0 is included in Airr
N \{n}{n} for every
n  N . The set nN Dn gathers the subsets of G(X N ) we can derive from the different Dn
by means of an assumption of epistemic irrelevance, and considers the natural extension of
their union, which is the minimal coherent superset (we shall show that it is indeed coherent
in Proposition 15 below). Observe that, quite trivially, Airr
{n}\{n}{n} = Dn and therefore
m{n} Dm = Dn . We now prove a number of important properties for nN Dn .
Proposition 15 (Coherence). Let Dn be coherent sets of desirable gambles on X n , n 
N . Then nN Dn is a coherent set of desirable gambles on X N .
S
Proof. Let, for ease of notation, AN := nN Airr
N \{n}{n} . It follows from Theorem 1
that we have to prove that AN avoids non-positivity. So consider any f  posi(AN ), and
assume ex absurdo that f  0. Then there are n  0 and fn  Airr
N \{n}{n} such that
618

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

P
irr
f =
nN n fn and maxnN n > 0 [recall that the AN \{n}{n} are convex cones, by
Lemma 11]. Fix arbitrary m  N . Let

	
AN
m := fm (xN \{m} , ) : xN \{m}  X N \{m} , fm (xN \{m} , ) 6= 0 ,
then it follows from Eq. (17) that AN
m is a finite non-empty subset of Dm , so the coherence
of Dm , Theorem 1 and Lemma 2 imply that there is some mass function pm on X m with
expectation operator Em such that (xm  X m )pm (xm ) > 0 and
(xN \{m}  X N \{m} )(fm (xN \{m} , ) 6= 0  Em (fm (xN \{m} , )) > 0).
So if we define the gamble gN \{m} on X N \{m} by letting
gN \{m} (xN \{m} ) := Em (fm (xN \{m} , ))
for all xN \{m}  X N \{m} , then gN \{m} > 0.
Since weQcan do this for all m  N , we can define the mass function pN on X N by letting
pN (xN ) := mN pm (xm ) > 0 for all xN  X N . The corresponding expectation operator
EN is of course the product operator of the marginals
Em . But thenPit follows from the
P
reasoning and assumptions above that EN (f ) = mN m EN (fm ) = mN m EN (gm ) >
0, whereas f  0 leads us to conclude that EN (f )  0, a contradiction.
Lemma 16. Consider any disjoint subsets I, R and any o  N \ (I  R). Then f (xR , ) 
irr
Airr
I{o}  {0} for all f  AIR{o} and all xR  X R .
:= f (xR , ) on X I{o} . It
Proof. Fix f  Airr
IR{o} and xR  X R and consider the gamble g
follows from the assumptions that for all xI  X I :
g(xI , ) = f (xR , xI , )  Do  {0},
whence indeed g  Airr
I{o}  {0}.
Proposition 17 (Marginalisation). Consider coherent marginal sets of desirable gambles Dn for all n  N . Let R be any subset of N , then margR (nN Dn ) = rR Dr .
Proof. Since we are interpreting gambles on X R as special gambles on X N , it is clear from
irr
Eq. (17) that for any r  R, Airr
R\{r}{r}  AN \{r}{r} . Eqs. (6) and (18) now tell us that
extN (rR Dr )  nN Dn . If we invoke Eq. (7), this leads to
rR Dr = margR (extN (rR Dr ))  margR (nN Dn ),
so we can concentrate on the converse inequality.
Consider therefore any f  margR (nN Dn ) = (nN Dn )  G(X R ), and assume ex
absurdo that f 
/ rR Dr .
It follows from the coherence of nN Dn that f 6= 0 [see Proposition 15]. Since f 
nN Dn , there are S  N , fs  Airr
N \{s}{s} , s  S and g  G(X N ) with g  0 such that
P
f = g + sS fs . Clearly S \ R 6= , because S \ R =  would imply that, with xN \R any
619

fiDe Cooman & Miranda

P
element of X N \R , f = f (xN \R , ) = g(xN \R , ) + sSR fs (xN \R , )  rR Dr , since we
infer from Lemma 16 that fs (xN \R , )  Airr
R\{s}{s}  {0} for all s  S  R.
It follows from the coherence of rR Dr [Proposition 15], f 
/ rR Dr and Lemma 3
that 0 
/ posi({f }  rR Dr ). Let, for ease of notation,
	

AN
SR := fs (zN \R , ) : s  S  R, zN \R  X N \R , fs (zN \R , ) 6= 0 .

Then AN
SR is clearly a finite subset of rR Dr [to see this, use a similar argument as above,
involving Lemma 16], so we infer from Lemma 2 that there is some mass function pR on
X R with associated expectation operator ER such that


 (xR  X R )pR (xR ) > 0
(s  S  R)(zN \R  X N \R )ER (fs (zN \R , ))  0


ER (f ) < 0.
P
P
We then infer from f = f (zN \R , ) = g(zN \R , ) + sSR fs (zN \R , ) + sS\R fs (zN \R , )
that for all zN \R in X N \R :
0 > ER (f )  ER (g(zN \R , )) 

X

ER (fs (zN \R , ))

sSR

=

X

sS\R

ER (fs (zN \R , )) =

X

X

pR (xR )fs (zN \R , xR ).

sS\R xR X R

The gambles fs (, xR ) on X N \R [where xR  X R and s  S \ R] can clearly not all be zero.
The non-zero ones all belong to sN \R Ds for all s  N \ R and all xR  X R , by Lemma 16,
so the coherence of the set of desirable gambles
sN \R Ds [Proposition 15] guarantees
P
P
that their positive linear combination h := sS\R xR X R pR (xR )fs (, xR ) also belongs to
sN \R Ds . This contradicts h  0. Hence indeed f  rR Dr .
Proposition 18 (Conditioning). Consider coherent marginal sets of desirable gambles
Dn for all n  N , and define nN Dn by means of Eq. (18). Then nN Dn is independent:
for all disjoint subsets I and O of N , and all xI  X I ,
margO (nN Dn xI ) = margO (nN Dn ) = oO Do .
This could probably be proved indirectly using the semi-graphoid properties of conditional epistemic irrelevance, proved by Moral (2005); it appears we need reverse weak
union, reverse decomposition, and contraction. Here we give a direct proof. Proposition 17
can also be seen as a special case of the present result for I = .
Proof. Fix arbitrary disjoint subsets I and O of N , and arbitrary xI  X I . The second
equality follows from Proposition 17, so we concentrate on proving that margO (nN Dn xI )
coincides with oO Do . The proof is similar to that of Proposition 17.
We first show that oO Do  nN Dn xI . Consider any gamble f  oO Do , then we
have to show that I{xI } f  nN Dn . By assumption, there are non-negative reals
P o and
, gambles fo  Airr
for
all
o

O
and
g

G(X
)
such
that
f
=
g
+
O >0
oO o fo
O\{o}{o}
620

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

and max{, maxoO o } > 0. Fix o  O and let fo := I{xI } fo  G(X N ). Then it follows

from the definition of Airr
O\{o}{o} that fo (zN \{o} , ) = I{xI } (zI )fo (zO\{o} , )  Do  {0} for all

irr
zN \{o}  X N \{o} . Since fo 6= 0, the definition of Airr
N \{o}{o} tells us that fo  AN \{o}{o} .
:= I{xI } g  G(X N ), then g > 0. So it follows from Eq. (18) that
Similarly, if we let g  P
indeed I{xI } f = g  + oO o fo  nN Dn .
We now turn to the converse inclusion, nN Dn xI  oO Do . Consider any gamble
f  G(X O ) such that I{xI } f belongs to nN Dn and assume ex absurdo that f 
/ oO Do .
Let, for the sake of notational simplicity, C := N \ (I  O).
It follows from the coherence of nN Dn that f 6= 0 [see Proposition 15]. Since I{xI } f 
nN Dn , there are S  N , fs  Airr
N \{s}{s} , s  S and g  G(X N ) with g  0 such that
P
I{xI } f = g + sS fs . Clearly S \ OP6= , because S \ O =  would imply that, with xC any
element of X C , f = g(xI , xC , ) + sSO fs (xI , xC , )  oO Do , since Lemma 16 shows
that fs (xI , xC , )  Airr
O\{s}{s} for all s  S  O.
It follows from the coherence of oO Do [Proposition 15], f 
/ oO Do and Lemma 3
that 0 
/ posi({f }  oO Do ). Let, for ease of notation,
AN
SO := {fs (xI , zC , ) : s  S  O, zC  X C , fs (xI , zC , ) 6= 0} .
Then AN
SO is clearly a finite subset of oO Do [to see this, use a similar argument as above,
involving Lemma 16], so we infer from Lemma 2 that there is some mass function pO on
X O with associated expectation operator EO such that


 (xO  X O )pO (xO ) > 0
(s  S  O)(zC  X C )EO (fs (xI , zC , ))  0


EO (f ) < 0.
Since f = g(xI , zC , )+
we see that:

P

sSO fs (xI , zC , )+

0 > EO (f )  EO (g(xI , zC , )) 

P

sS\O

X

fs (xI , zC , ) for any choice of zC  X C ,

EO (fs (xI , zC , ))

sSO

=

X

X

EO (fs (xI , zC , )) =

X

pO (xO )fs (xI , zC , xO )).

sS\O xO X O

sS\O

Similarly,
for any zC PX C and any zI  X I \ {xI } we then infer from 0 = g(zI , zC , ) +
P
sSO fs (zI , zC , ) +
sS\O fs (zI , zC , ) that:
0  EO (g(zI , zC , )) 

X

EO (fs (zI , zC , ))

sSO

=

X

EO (fs (zI , zC , )) =

X

X

pO (xO )fs (zI , zC , xO )).

sS\O xO X O

sS\O

Hence
h :=

X

X

pO (xO )fs (, , xO )  0.

sS\O xO X O

621

fiDe Cooman & Miranda

The gambles fs (, , xO ) on X IC [where xO  X O and s  S \ O] can clearly not all be
zero. The non-zero ones all belong to sIC Ds , by Lemma 16. But then the coherence of
the set of desirable gambles sIC Ds [Proposition 15] guarantees that their positive linear
combination h is an element of cC Dc for which h  0, a contradiction. Hence indeed
f  oO Do .
Theorem 19 (Independent natural extension). Consider the coherent sets Dn of desirable gambles on X n , n  N . Then nN Dn is the smallest coherent set of desirable
gambles on X N that is an independent product of the coherent sets of desirable gambles Dn ,
n  N.
We call nN Dn the independent natural extension of the marginals Dn .
Proof. It follows from Propositions 15, 17 and 18 that nN Dn is an independent product
DN of the Dn . To prove that it is the smallest one, consider any independent product DN of
the Dn . Fix n  N . If we consider any xN \{n}  X N \{n} , then margn (DN xN \{n} ) = Dn , by
assumption. If we therefore consider any g  Dn , this in turn implies that g  DN xN \{n} ,
and therefore I{xN\{n} } g  DN , by Eq. (9). So we infer by coherence that Airr
N \{n}{n}  DN ,
and therefore also that nN Dn  DN .
One of the most useful properties of the independent natural extension, is its associativity: it allows us to construct the extension in a modular fashion.
Theorem 20 (Associativity of independent natural extension). Let N1 and N2 be
disjoint non-empty index sets, and consider Dnk  D(X nk ), nk  Nk , k = 1, 2. Then given
DN1 := n1 N1 Dn1 and DN2 := n2 N2 Dn2 , it holds that
DN1  DN2 = nN1 N2 Dn .
Proof. We first prove that DN1  DN2  nN1 N2 Dn . Fix any gamble h  Airr
{N1 }{N2 }
and any xN1  X N1 , so h(xN1 , )  DN2  {0} by Eq. (17). It follows from Eq. (18) that
there are gambles hnxN2  Airr
N2 \{n2 }{n2 }  {0} for all n2  N2 such that
1

h(xN1 , ) 

X

hnxN2 .
1

n2 N2

Define, for any n2  N2 , the gamble gn2 on X N by letting gn2 (xN \{n2 } , ) := hnxN2 (xN2 \{n2 } , )
1
for all xN  X N . Then it follows from Eq. (17) that gn2 (xN \{n2 } , )  Dn2  {0} for all
xN  X N , and therefore gn2  Airr
N \{n2 }{n2 }  {0}. Moreover,
h=

X

I{xN1 } h(xN1 , )

X

I{xN1 }

xN1 X N1



xN1 X N1

X

n2 N2

hnxN2 =
1

X

X

n2 N2 xN1 X N1

I{xN1 } hnxN2 =
1

X

gn2 ,

n2 N2

It therefore follows from Eq. (18) that h  nN1 N2 Dn , since clearly h 6= 0 because of
Eq. (17). We conclude that Airr
{N1 }{N2 }  nN1 N2 Dn . Similarly, we can prove the
622

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

inclusion Airr
{N2 }{N1 }  nN1 N2 Dn , and therefore also DN1  DN2  nN1 N2 Dn , again
by Eq. (18).
Next, we prove the converse inclusion nN1 N2 Dn  DN1  DN2 . Consider any gamble
h  nN1 N2 Dn , then by Eq. (18) there are hn  Airr
N1 N2 \{n}{n}  {0} for all n  N1  N2
such that
X
X
X
h
hn = h1 + h2 , where h1 :=
hn1 and h2 :=
hn2 .
n1 N1

nN

n2 N2

Fix any xN1  X N1 . For any n2  N2 , hn2  Airr
N1 N2 \{n2 }{n2 }  {0} implies that
irr
hn2 (xN1 , )  AN2 \{n2 }{n2 }  {0} by Lemma 16. Hence h2 (xN1 , )  DN2  {0} by Eq. (18),
irr
and therefore h2  Airr
{N1 }{N2 }  {0} by Eq. (17). Similarly, h1  A{N2 }{N1 }  {0}, and
therefore h  DN1  DN2 by Eq. (18), since clearly h 6= 0.
To conclude this section, we establish a connection between independent natural extension for sets of desirable gambles and the eponymous notion for coherent lower previsions,
studied in detail by De Cooman et al. (2011). Given coherent lower previsions P n on G(X n ),
n  N , their independent natural extension is the coherent lower prevision given by


X
E N (f ) := sup
min f (zN ) 
[hn (zN )  P n (hn (, zN \{n} ))]
(19)
hn G(X N ) zN X N
nN

nN

for all gambles f on X N . It is the point-wise smallest (most conservative) joint lower
prevision that satisfies the property of coherence by Walley (1991, ch. 7) with the marginals
P n given an assessment of epistemic independence of the variables Xn , n  N .
The correspondence between coherent lower previsions and sets of desirable gambles has
been mentioned in Section 2.6; we show next that if we have such a correspondence between
the marginals, it also holds between their associated independent natural extensions.
Theorem 21. Let Dn be coherent sets of desirable gambles on X n for n  N , and let
nN Dn be their independent natural extension. Consider the coherent lower previsions
P n on G(X n ) given by P n (fn ) := sup {  R : fn    Dn } for all fn  G(X n ). Then the
independent natural extension E N of the marginal lower previsions P n , n  N satisfies
E N (f ) = sup {  R : f    nN Dn } for all f  G(X N ).
Proof. Fix any gamble f in G(X N ). First, consider any real number  < E N (f ), then
it
Pfollows from Eq. (19) that there are  > 0 and hn  G(X N ), n  N such that f   
nN gn , where we defined the gambles gn on X N by gn (zN ) := hn (zN )P n (hn (zN \{n} , ))+
 for all zN  X N . But it follows from the definition of P n that
gn (zN \{n} , ) = hn (zN \{n} , )  P n (hn (zN \{n} , )) +   Dn for all zN \{n}  X N \{n} .
Since clearly gn 6= 0, Eq. (17) then tells us that gn  Airr
N \{n}{n} , and we infer from
P
Eq. (18) that nN gn  nN Dn , and therefore also f    nN Dn . This guarantees
that E N (f )  sup {  R : f    nN Dn }.
623

fiDe Cooman & Miranda

To prove the converse inequality, consider any real number  such that f   nN Dn .
We infer using Eq. (18) that there are gambles hn  Airr
N \{n}{n} , n  N such that f   
P
nN hn . For all n  N and zN \{n}  X N \{n} , it follows from Eq. (17) that hn (zN \{n} , ) 
Dn  {0}, and therefore P n (hn (zN \{n} , ))  0, whence
X

nN

 X
hn (zN )  P n (hn (zN \{n} , )) 
hn (zN )  f (zN )  .
nN

We then infer from Eq. (19) that E N (f )   and so we find that indeed also E N (f ) 
sup {  R : f    nN Dn }.
In a similar way as for the irrelevant natural extension, we infer from Eqs. (16) and (18)
that the computational complexity of finding or representing the independent natural extension of a number of marginal models Dn is linear in the number of extreme rays of the
Dn , and linear in the number of elements of the sets X N \{n} and therefore essentially exponential in the number |N | of independent variables Xn , n  N . Similar results will hold
in the more general case that the marginal sets of desirable gambles can be characterised
using a finite number of generalised extreme rays, as described by Couso and Moral (2011)
and Quaeghebeur (2012a).

8. Maximal Coherent Sets of Desirable Gambles and Strong Products
We have seen that for any collection Dn , n  N of marginal coherent sets of desirable gambles, there always is a smallest independent product, which we have called the independent
natural extension nN Dn . We have proceeded in this way because we had no way of
excluding that there may be other, larger, independent products. Indeed, we show in this
section that such is the case. Using the notions of independent natural extension and maximal coherent sets of desirable gambles, we can consistently define a specific independent
product that typically strictly includes the independent natural extension. We call it the
strong product, because it is very close in spirit to the strong product used in coherent lower
prevision theory (Couso, Moral, & Walley, 2000; Cozman, 2000, 2005; De Cooman et al.,
2011), as we shall see in Theorem 28.
8.1 Independent Products of Maximal Coherent Sets of Desirable Gambles
We begin by mentioning a number of interesting facts about maximal coherent sets of desirable gambles, and their independent products. The following result was already (essentially)
proved by Couso and Moral (2011): updating a coherent set of desirable gambles preserves
its maximality.
Proposition 22. Let MN  M(X N ), and consider any disjoint subsets I and O of N .
Then margO (MN xI )  M(X O ) for all xI  X I .
Proof. Suppose there is some xI in X I for which margO (MN xI ) is not maximal. This
means that there is some f  G(X O ) for which neither f nor f belong to MN xI , which
in turn implies that neither I{xI } f nor I{xI } f belong to MN . But this contradicts the
maximality of MN .
624

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

On the other hand, taking the independent natural extension does not necessarily preserve maximality: if Mn  M(X n ) for all n  N , then it does not necessarily hold that
nN Mn  M(X N ), as the counterexample in Section A.1 shows. Interestingly, that example does not present an isolated case: when we consider two binary variables, the independent natural extension of two maximal coherent sets of desirable gambles is never maximal,
as we can see in our next proposition. It is an open problem whether this negative result
can be extended to any finite set of (not necessarily binary) variables.
An intuitive explanation of this result is that each of the maximal sets of gambles is a
half-space where we are excluding one of the two rays determining its boundary, so as not
to have the zero gamble as desirable; and when we apply the notion of independent natural
extension we end up missing three of the four parts of the boundary of the set of gambles
in the product space, preventing this product from being maximal.
Proposition 23. Consider X 1 = X 2 = {0, 1}, and let M1 and M2 be any maximal coherent sets of desirable gambles on X 1 and X 2 , respectively. Then their independent natural
extension M1  M2 is not a maximal coherent set of desirable gambles.
Proof. Let pk be the mass function of the linear prevision Pk determined by Mk , k = 1, 2.
We deduce from Theorem 21 that the lower prevision determined by M1  M2 is the independent natural extension of the linear previsions P1 and P2 , and therefore equal to the
independent product P{1,2} of these linear previsions [see Proposition 25 in De Cooman
et al., 2011]. This is the linear prevision on G(X {1,2} ) with mass function defined by
p{1,2} (x1 , x2 ) := p1 (x1 )p2 (x2 ) for all (x1 , x2 )  X {1,2} .
Before we really get the proof on the tracks, we make a useful observation. Any maximal
Mk is a semi-plane through the origin that excludes the origin, includes its boundary on
one side of the origin, and excludes the boundary on the other side. This means that
there is unique element ak of X k where all the elements fk of the included boundarythose
elements fk of Mk for which Pk (fk ) is zeroare positive fk (ak ) > 0. We denote the single
other element of X k by bk . In other words, if we express
Mk = {fk : Pk (fk ) > 0}  {fk : Pk (fk ) = 0, fk  Mk },
and consider fk  Mk with Pk (fk ) = pk (ak )fk (ak ) + pk (bk )fk (bk ) = 0, then if fk (ak ) > 0
there cannot be any gk  Mk with Pk (gk ) = 0 and gk (bk ) > 0: otherwise, the zero gamble
k)
would be a convex combination of fk and gk [it would be 0 = fk  fgkk (b
(bk ) gk ] and it would thus
belong to Mk , a contradiction with its coherence. Note that in this reasoning we assume
implicitly that pk (ak )  (0, 1); otherwise, if for instance pk (ak ) = 0, a gamble fk satisfies
Pk (fk ) = 0 if and only if fk (bk ) = 0, and then fk can only belong to Mk if fk (ak ) > 0.
We are now ready to turn to the proof. There are a number of possibilities.
First, assume that both pk (ak ) > 0 and pk (bk ) > 0 for k = 1, 2. Consider any gamble h
on X {1,2} such that h(a1 , a2 ) = h(b1 , b2 ) = 0, min h < 0, max h > 0 and
P{1,2} (h) = p1 (a1 )p2 (b2 )h(a1 , b2 ) + p1 (b1 )p2 (a2 )h(b1 , a2 ) = 0.
Of course, there always is such a gamble, and we are going to show that it does not belong
to M1  M2 .
625

fiDe Cooman & Miranda

Assume ex absurdo that it does, meaning that there are h1  Airr
{2}{1} and h2 
irr
A{1}{2} such that h  h1 + h2 . By definition, h1 (, x2 )  M1  {0} and therefore
P1 (h1 (, x2 ))  0 for all x2  X 2 . Similarly, P2 (h2 (x1 , ))  0 for all x1  X 1 . Hence
0 = P{1,2} (h)  P{1,2} (h1 ) + P{1,2} (h2 )  0, taking into account that
X
X
P{1,2} (h1 ) =
p2 (x2 )P1 (h1 (, x2 ))  0 and P{1,2} (h2 ) =
p1 (x1 )P2 (h2 (x1 , ))  0.
x2 X 2

x1 X 1

As a consequence, P{1,2} (h1 ) = P{1,2} (h2 ) = 0. But this in turn implies that P1 (h1 (, x2 )) =
0 for all x2  X 2 and that P2 (h2 (x1 , )) = 0 for all x1  X 1 . Given the observations
made at the start of the proof, we therefore come to the conclusion that h1 (a1 , x2 )  0
for all x2  X 2 and h2 (x1 , a2 )  0 for all x1  X 1 . But then h(a1 , a2 ) = 0 implies
that h1 (a1 , a2 ) = h2 (a1 , a2 ) = 0, which in turn implies that h1 (b1 , a2 ) = h2 (a1 , b2 ) = 0,
because both 0 = P1 (h1 (, a2 )) = p1 (a1 )h1 (a1 , a2 ) + p1 (b1 )h1 (b1 , a2 ) and 0 = P2 (h2 (a1 , )) =
p2 (a1 )h1 (a1 , a2 ) + p2 (b1 )h1 (a1 , b2 ). So we eventually find that
h(b1 , a2 )  h1 (b1 , a2 ) + h2 (b1 , a2 )  0 and h(a1 , b2 )  h1 (a1 , b2 ) + h2 (a1 , b2 )  0,
which contradicts min h < 0.
Now, if any non-zero h such that h(a1 , a2 ) = h(b1 , b2 ) = 0 = P{1,2} (h) with min h < 0
and max h > 0 does not belong to M1 M2 , neither does h, and this means that M1 M2
is not maximal.
Next we consider the cases where one of the marginal linear previsions are degenerate.
Assume for instance that p1 (a1 ) = 0 and p2 (a2 )  (0, 1) [the other cases where only one of
the marginals is degenerate are similar]. Consider a non-zero gamble h2 
/ M2 such that
P2 (h2 ) = 0 [always possible]. Then h2  M2 and it follows from the observations made
in the beginning of this proof that h2 (a2 ) < 0. Now consider the gamble h defined by
h(b1 , a2 ) := h2 (a2 ) < 0,

h(b1 , b2 ) := h2 (b2 )  0,

h(a1 , a2 ) = h(a1 , a2 ) := 1.

It follows that P{1,2} (h) = P2 (h2 ) = 0. To see that h 
/ M1  M2 , assume that there
irr
are f1  Airr
and
f

A
such
that
h

f
2
1 + f2 . But then 0 = P{1,2} (h) 
{2}{1}
{1}{2}
P{1,2} (f1 ) + P{1,2} (f2 )  0 and therefore 0 = P{1,2} (f1 ) = p2 (a2 )f1 (b1 , a2 ) + p2 (b2 )f1 (b1 , b2 ).
On the other hand, f1  Airr
{2}{1} also implies that P1 (f1 (, x2 ))  0 for all x2  X 2 , and
therefore f1 (b1 , a2 )  0 and f1 (b1 , b2 )  0. Hence f1 (b1 , ) = 0, and therefore f2 (b1 , ) 
h(b1 , ) = h2 and since h2 
/ M2 , it follows that f2 (b1 , ) 
/ M2 . Because we must have by
definition that f2 (b1 , )  M2  {0}, this can only mean that f2 (b1 , ) = 0, whence h2  0,
contradicting h2 (a2 ) < 0. This implies that h cannot belong to M1  M2 .
Similarly, if h belongs to M1  M2 , then there must be g1  Airr
{2}{1} and g2 
irr
A{1}{2} such that h  g1 + g2 . But then 0 = P{1,2} (h)  P{1,2} (g1 ) + P{1,2} (g2 ) 
0, whence 0 = P{1,2} (g1 ) = p2 (a2 )g1 (b1 , a2 ) + p2 (b2 )g1 (b1 , b2 ). But g1  Airr
{2}{1} also
implies that P1 (g1 (, x2 ))  0 for all x2  X 2 , and therefore g1 (b1 , a2 )  0 and g1 (b1 , b2 ) 
0. Hence g1 (b1 , ) = 0, and therefore we find that g1 (a1 , a2 )  0 and g1 (a1 , b2 )  0 [if,
say, g1 (a1 , a2 ) < 0 then g1 (, a2 ) < 0 because also g1 (b1 , a2 ) = 0, which contradicts that
irr
g1 (, a2 )  M1  {0}, a consequence of g1  Airr
{2}{1} ]. Since, moreover, g2  A{1}{2}
implies that 0  P2 (g2 (a1 , )) = p2 (a2 )g2 (a1 , a2 ) + p2 (b2 )g2 (a1 , b2 ) and therefore also that
626

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

g2 (a1 , a2 )  0 or g2 (a1 , b2 )  0, it follows that h(a1 , a2 )  0 or h(a1 , b2 )  0, which
contradicts h(a1 , a2 ) = h(a1 , b2 ) = 1 < 0. Hence, h does not belong to M1  M2
either, so M1  M2 is not maximal.
Finally, we turn to the cases where all marginals are degenerate. Assume for instance
that p1 (a1 ) = p2 (a2 ) = 0 [the other cases where both marginals are degenerate, are similar].
Consider the gamble h given by
h(a1 , a2 ) = h(b1 , b2 ) = 0,

h(b1 , a2 ) = 1,

h(a1 , b2 ) = 1,

then P{1,2} (h) = p1 (b1 )p2 (b2 )h(b1 , b2 ) = 0. To see that h 
/ M1  M2 , assume ex absurdo
irr
that there are u1  Airr
and
u

A
such
that
h
 u1 + u2 . Then u1  Airr
2
{2}{1}
{1}{2}
{2}{1}
implies that
u1 (b1 , b2 ) = P1 (u1 (, b2 ))  0 and u1 (b1 , a2 ) = P1 (u1 (, a2 ))  0,
and similarly u2  Airr
{1}{2} implies that u2 (b1 , b2 ) = P2 (u2 (b1 , ))  0 and u2 (a1 , b2 ) =
P2 (u2 (a1 , ))  0. Now it also follows from P{1,2} (h) = 0, P{1,2} (u1 )  0 and P{1,2} (u2 )  0
that u1 (b1 , b2 ) = P{1,2} (u1 ) = 0 and u2 (b1 , b2 ) = P{1,2} (u2 ) = 0, and as a consequence we
find that u1 (a1 , b2 )  0 and u2 (b1 , a2 )  0 [if, say, u1 (a1 , b2 ) < 0 then u1 (, b2 ) < 0 because
also u1 (b1 , b2 ) = 0, which contradicts u1 (, b2 )  M1  {0}, a consequence of u1  Airr
{2}{1} ].
As a consequence, 1 = h(a1 , b2 )  u1 (a1 , b2 ) + u2 (a1 , b2 )  0, a contradiction. Hence
indeed, h does not belong to M1  M2 .
irr
Finally, assume ex absurdo that there are v1  Airr
{2}{1} and v2  A{1}{2} such that
h  v1 + v2 . Then v1  Airr
{2}{1} implies that
v1 (b1 , b2 ) = P1 (v1 (, b2 ))  0 and v1 (b1 , a2 ) = P1 (v1 (, a2 ))  0,
and similarly v2  Airr
{1}{2} implies that v2 (b1 , b2 ) = P2 (v2 (b1 , ))  0 and v2 (a1 , b2 ) =
P2 (v2 (a1 , ))  0. Now it also follows from P{1,2} (h) = 0, P{1,2} (v1 )  0 and P{1,2} (v1 )  0
that v1 (b1 , b2 ) = P{1,2} (v1 ) = 0 and v2 (b1 , b2 ) = P{1,2} (v2 ) = 0, and as a consequence we find
that v1 (a1 , b2 )  0 and v2 (b1 , a2 )  0 [if, say, v1 (a1 , b2 ) < 0 then v1 (, b2 ) < 0 because also
v1 (b1 , b2 ) = 0, which contradicts v1 (, b2 )  M1  {0}, a consequence of v1  Airr
{2}{1} ]. As
a consequence, 1 = h(b1 , a2 )  v1 (b1 , a2 ) + v2 (b1 , a2 )  0, a contradiction. This shows
that h does not belong to M1  M2 either, and therefore this set is not maximal.
On the other hand, the Example A.2 in the Appendix shows that there are independent
products of maximal coherent sets of desirable gambles that are maximal; hence, the independent natural extension of maximal coherent sets is not their only independent product.
Indeed, we can establish the following result:
Proposition 24. Consider maximal coherent sets of desirable gambles M1  M(X 1 ) and
M2  M(X 2 ).
(i) Let D{1,2} be any coherent set of desirable gambles on X {1,2} such that M1  M2 
D{1,2} . Then D{1,2} is independent with marginals M1 and M2 .
(ii) As a consequence, a maximal set of gambles M{1,2} is an independent product of its
marginals if and only if M{1,2} x2 is the same for all x2  X 2 and M{1,2} x1 is the
same for all x1  X 1 .
627

fiDe Cooman & Miranda

Proof. (i). We have for every x1  X 1 that M2 = (M1  M2 )x1  D{1,2} x1 , where
the equality follows from Proposition 18. Since M2 is maximal, this implies that M2 =
D{1,2} x1 for all x1  X 1 , and a similar argument shows that M1 = D{1,2} x2 for all
x2  X 2 . On the other hand, it follows from Proposition 17 that M2 = marg2 (M1  M2 ) 
marg2 (D{1,2} ). Since M2 is maximal, this implies that M2 = marg2 (D{1,2} ), and a similar
argument shows that M1 = marg1 (D{1,2} ). In summary, we see that marg1 (D{1,2} ) =
D{1,2} x2 for all x2  X 2 , and marg2 (D{1,2} ) = D{1,2} x1 for all x1  X 1 , showing that
D{1,2} is indeed independent.
(ii). It follows from the definition of an independent product that it is necessary that
M{1,2} x2 and M{1,2} x1 should be the same for all x2 and x1 , respectively. To see that
this is also a sufficient condition for M{1,2} to be an independent product, note that in
that case M{1,2} x1  M{1,2} x2  M{1,2} , and that the sets M{1,2} x1 and M{1,2} x2 are
maximal, by Proposition 22. On the other hand, Proposition 17 implies that
marg1 (M{1,2} x1  M{1,2} x2 ) = M{1,2} x1  marg1 (M{1,2} ),
so both sets are equal. Similarly, we deduce that
marg2 (M{1,2} x1  M{1,2} x2 ) = M{1,2} x2  marg2 (M{1,2} ),
and therefore marg1 (M{1,2} )  marg2 (M{1,2} )  M{1,2} . Invoking the first part of the
proposition, we find that M{1,2} is an independent product of its marginals.
The first part of this proposition provides us with a simple characterisation of the
independent products of two maximal sets: they are simply those coherent supersets of
the independent natural extension; in particular, this means that any maximal superset of
this independent natural extension will be an independent product, so two maximal sets
always have maximal products (although these will differ from the independent natural
extension). The second part implies that if the sets of conditional gambles coincide for all
the conditioning events, then they automatically agree with the marginal sets of gambles,
and as a consequence the set is an independent product.
8.2 The Strong Product and Its Properties
Now consider the case where we have coherent marginal sets of desirable gambles Dn for
all n  N . We define their strong product nN Dn as the set of desirable gambles on the
product space X N given by:8
\
nN Dn :=
{nN Mn : Mn  m(Dn ), n  N } ,
where m(Dn ) is given by Eq. (1). This strong product corresponds is the set of desirable
gambles determined by a notion of independence that is more restrictive than those of epistemic irrelevance and independence considered so far: that of strong independence (Couso
et al., 2000; Cozman, 2012), sometimes called type-3 independence (de Campos & Moral,
8. As this paper focusses on independent natural extension, because that has a much more direct behavioural
justification, we will forgo discussing the complexity of computing this strong product, which, on the
face of it, appears to be significantly higher than that for independent natural extension.

628

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

1995). Strong independence means that the associated joint credal set is the convex hull of
the set of linear previsions that are the stochastic independent products of linear previsions
that dominate the marginals; or, equivalently, that the associated lower prevision is the
lower envelope of the products of the linear previsions that dominate the marginals. This
will be clearer after Theorem 28.
For maximal coherent sets of desirable gambles Mn  M(X n ), n  N the strong product and the independent natural extension coincide: nN Mn = nN Mn , as clearly
m(Mn ) = {Mn }. Taking into account Proposition 23, we deduce that the strong product
of maximal coherent sets of desirable gambles is not necessarily maximal; Example A.2 in
the Appendix shows that there are other independent products that may strictly include
the strong product.
The marginalisation properties of the strong product follow directly from those of the
independent natural extension.
Proposition 25 (Marginalisation). Consider coherent sets of desirable gambles Dn for
all n  N . Let R be any subset of N , then margR (nN Dn ) = rR Dr .
Proof. Consider any f  G(X R ) and observe the following chain of equivalences:
f  nN Dn  (Mn  m(Dn ), n  N )f  nN Mn
 (Mn  m(Dn ), n  N )f  rR Mr
 (Mr  m(Dr ), r  R)f  rR Mr
 f  rR Dr ,
where the second equivalence follows from Proposition 17.
Next, we show that the strong product of some coherent marginal sets of desirable gambles
Dn is an independent product of these marginals. In order to do so, we first establish the
following simple yet powerful result:
j
, j  J be any non-empty family of independent coherent sets
Proposition 26. Let DN
T
j
of desirable gambles on X N . Then their intersection DN := jJ DN
is an independent
coherent set of desirable gambles on X N .

Proof. Consider any disjoint subsets I and O of N , and any xI  X I . Then
j
xI )
h  margO (DN xI )  (j  J)h  margO (DN
j
 (j  J)h  margO (DN
)

 h  margO (DN ).
Proposition 27. Consider coherent marginal sets of desirable gambles Dn for all n  N .
Then their strong product nN Dn is an independent product of these marginals.
Proof. Taking into account Proposition 26, all we need to show is that the sets Dn are the
marginals of the strong product nN Dn . This is an immediate consequence of Proposition 25.
629

fiDe Cooman & Miranda

The strong product may strictly include the independent natural extension, as we can
see from the example in Section A.3. It is an open question whether, like the independent natural extension, the strong product is associative. Although we have not been
able to prove associativity in general, it is not difficult to show that it suffices to establish it for maximal sets of desirable gambles, and that one of the inclusions, namely
nN1 N2 Mn  (nN1 Mn )  (nN2 Mn ) holds because the strong product always includes the independent natural extension. We suspect, but have not been able to prove,
that the converse inclusion also holds, and that the strong product is associative, taking into
account that in its definition we are taking the intersection of sets of gambles determined
by an associative operator (the independent natural extension).
To conclude this section, we establish a connection between the strong product of sets
of desirable gambles and the eponymous notion for coherent lower previsions, studied for
instance by De Cooman et al. (2011) (see also Cozman, 2012 for comments on the corresponding notion in terms of credal sets, which is sometimes called the strong extension).
Given coherent lower previsions P n on G(X n ), n  N , their strong product is the coherent
lower prevision defined by
S N (f ) := inf {nN Pn (f ) : (n  N )Pn  M(P n )}
for all gambles f on X N ; the intuition behind this notion, taking into account the correspondence between coherent lower previsions and sets of desirable gambles discussed in
Section 2.6, is that the intersection of a family of sets of desirable gambles is closely related
to taking the lower envelope of the associated family of coherent lower previsions.
If we start from linear previsions Pn on G(X n ), their strong product corresponds to their
linear product nN Pn , and it coincides also with their independent natural extension EN .
If we begin with coherent lower previsions P n on G(X n ), their strong product S N is the
lower envelope of the set of strong products determined by the dominating linear previsions.
Theorem 28. Let Dn be coherent sets of desirable gambles in G(X n ) for all n  N , and
let nN Dn be their strong product. Consider the coherent lower previsions P n on G(X n )
given by P n (f ) := sup {  R : f    Dn }. Then the strong product S N of the marginal
lower previsions P n , n  N satisfies
S N (f ) = sup {  R : f    nN Dn } .
Proof. Assume first of all that Dn is a maximal coherent set of desirable gambles for all n in
N . Then it follows that P n is a linear prevision, which we denote by Pn , for all n  N . The
strong product of the linear previsions Pn , n  N coincides with their linear independent
product nN Pn , which is also their independent natural extension (use Proposition 10
from De Cooman et al., 2011). Since we have proved in Theorem 21 that this is the
coherent lower prevision associated with nN Dn = nN Dn , we conclude that the strong
product nN Dn is associated with the strong product of the linear previsions Pn .
We move next to the general case. Fix any gamble f on X N . Consider any real number
 < S N (f ). For any n  N , consider any maximal coherent set of desirable gambles
Mn  m(Dn ), and the associated linear prevision Pn , then clearly Pn  M(P n ). Hence
nN Pn (f )  S N (f ) > , and we infer from the arguments above that then necessarily
630

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

f    nN Mn . Hence f    nN Dn . This leads to the conclusion that S N (f ) 
sup {  R : f    nN Dn }.
Conversely, consider any real number  such that f    nN Dn . Consider arbitrary
Pn  M(P n ), n  N , then there are maximal coherent sets of desirable gambles Mn 
m(Dn ) inducing them: let Dn be the set of strictly desirable gambles that induces Pn , given
by Eq. (3). This set is coherent by Walley (1991, Thm. 3.8.1). Consider the set Dn Dn , and
let us show that it is coherent. Condition D2 holds trivially because it is satisfied by Dn . To
see that D3 holds, taking into account that both Dn and Dn are coherent sets of gambles,
and in particular cones, it suffices to show that for any gamble f  Dn and any g  Dn , their
sum f + g belongs to Dn  Dn . Consider thus such gambles f, g. If f  G(X n )>0 , then it also
belongs to Dn and as a consequence f + g  Dn ; on the other hand, if f  Dn \ G(X n )>0 ,
it follows that Pn (f ) > 0, whence Pn (f + g) = Pn (f ) + Pn (g)  Pn (f ) + P n (g) > 0,
and therefore f + g  Dn . Since both Dn and Dn are coherent, we deduce from this that
condition D1 also holds, and as a consequence the set Dn  Dn is indeed coherent.
Now, Theorem 5 implies that there is some maximal coherent set of desirable gambles
Mn  m(Dn  Dn )  m(Dn ), and from Walley (1991, Thm. 3.8.3) we deduce that Dn
and Mn induce the same Pn by means of Eq. (2). But then f    nN Mn , and
therefore nN Pn (f )  , using the argumentation above. Hence S N (f )  , and therefore
S N (f )  sup {  R : f    nN Dn }.
Together with Theorem 21 and the fact that the strong product of lower previsions may
strictly dominate their independent natural extension (see Example 9.3.4 in Walley, 1991),
this also shows that the strong product of marginal sets of desirable gambles may strictly
include their independent natural extension. An explicit example will be given in Appendix A.3.

9. Conditional Irrelevance and Independence
The final step we take in this paper, consists in extending our results from irrelevance and
independence to a simple but common form of conditional irrelevance and independence.
Next to the variables XN in X N , we now also consider another variable Y assuming values
in a finite set Y.
Consider two disjoint subsets I and O of N . We say that XI is epistemically irrelevant
to XO when, conditional on Y , learning the value of XI does not influence or change our
beliefs about XO .
When does a set D of desirable gambles on X N  Y capture this type of conditional
epistemic irrelevance? Clearly, we should require that:
margO (DxI , y) = margO (Dy) for all xI  X I and all y  Y.
As before, for technical reasons we also allow I and O to be empty. It is clear from
the definition above that the variable X , about whose constant value we are certain,
is conditionally epistemically irrelevant to any variable XO . Similarly, we see that any
variable XI is conditionally epistemically irrelevant to the variable X . This seems to be
in accordance with intuition.
631

fiDe Cooman & Miranda

Also, if Y is a singleton, then there is no uncertainty about Y and conditioning on Y
amounts to not conditioning at all: epistemic irrelevance can be seen as a special case of
conditional epistemic irrelevance.
We now want to argue that, conversely, there is a very specific and definite way in which
conditional epistemic irrelevance statements can be reduced to simple epistemic irrelevance
statements. The crucial results that allow us to establish this, are the following conceptually
very simple theorem and its corollary.
Theorem 29 (Sequential updating). Consider any subset R of N , and any coherent set
D of desirable gambles on X N  Y. Then
(Dy)xR = (DxR )y = DxR , y

for all xR  X R and y  Y.

(20)

Proof. Fix any xR in X R and any y  Y. Clearly, all three sets in Eq. (20) are subsets of
G(X N \R ). So take any gamble f on X N \R , and consider the following chains of equivalences:
I{y} I{xR } f  D  I{xR } f  Dy  f  (Dy)xR
I{y} I{xR } f  D  I{y} f  DxR  f  (DxR )y
I{y} I{xR } f  D  f  DxR , y.
Corollary 30 (Reduction). Consider any disjoint subsets I and O of N , and any coherent set D of desirable gambles on X N  Y. Then the following statements are equivalent:
(i) margO (DxI , y) = margO (Dy) for all xI  X I and all y  Y;
(ii) margO ((Dy)xI ) = margO (Dy) for all xI  X I and y  Y.
This tells us that a model D about (XN , Y ) represents epistemic irrelevance of XI to XO ,
conditional on Y if and only if for each possible value y  Y of Y , the model Dy about XN
represents epistemic irrelevance of XI to XO .
Now suppose we have marginal conditional models Dn Y on X n , n  N . The notation
Dn Y is a concise way of representing the family of conditional models Dn y, y  Y. Then
if we combine Corollary 30 and Theorem 19, we obtain the following:
Corollary 31. The smallest conditionally independent product DY of the marginal models
Dn Y is given by nN (Dn Y ), meaning that for each y  Y, Dy = nN (Dn y).
This also shows that calculating the conditionally independent natural extension has, in
comparison with independent natural extension, an additional factor in the computational
complexity that its simply linear in the number of possible values for the conditioning
variable Y .

10. Conclusions
Sets of desirable gambles are more informative than coherent lower previsions, as we have
shown in Section 2.6, and they are helpful in avoiding problems involving zero probabilities.
Moreover, they have a simple axiomatic definition, as we have seen in Section 2.1. They
632

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

have been overlooked for much of the development of the theory of imprecise probabilities,
and it is only in the last five or six years that more effort is being devoted to bringing this
simplifying and unifying notion to the fore.
Working with sets of desirable gambles allows us to show that the computational complexity of checking whether a gamble belongs to the independent natural extension compares favourably to that of computing the strong product, which has a complexity that is
exponential in the number of variables.
Our results here also show that we can model assessments of epistemic independence
easily using sets of desirable gambles, and that we can derive from them existing results for
lower previsions.
Moreover, the results in Section 7 indicate that constructing global joint models (i.e. coherent sets of desirable gambles) from local ones is something that can be easily and efficiently done for the some types of credal networks (Cozman, 2000, 2005). The interpretation
of the graphical structure in credal networks is usually taken to be the following: for any
node (variable), conditional on its parents, the non-parent non-descendants are strongly
independent of it (Cozman, 2000, 2005). But we can replace the assumption of strong independence with the weaker one of epistemic irrelevance, as in the work by De Cooman et al.
(2010), and this tends to produce more conservative independent products.9
If we consider a credal network made up of n unconnected nodes X1 , . . . , Xn , their interpretation is then very simple: for any variable Xk , the remaining variables X1 , . . . , Xk1 ,
Xk+1 , . . . Xn are epistemically irrelevant to it. The expression (18) for the independent
natural extension nk=1 Dk , and the reasoning behind it in Section 7, show that nk=1 Dk is
the smallest (most conservative) coherent joint set of desirable gambles that expresses the
epistemic irrelevancies in the graph.
Interestingly, we can make the network slightly more complicated by looking at the developments in Section 9, which tell us that the conditionally independent natural extension
nk=1 Xk Y is the most conservative (conditional) joint model that reflects the independence
conditions embedded in the following graphical structure:
Y
...
X1

X2

Xn1

Xn

for any variable Xk , the remaining variables X1 , . . . , Xk1 , Xk+1 , . . . Xn are epistemically
irrelevant to Xk , conditional on Y .
Now, any tree can be built up recursively using simple networks like the one above
as building blocks: similarly to what is done by De Cooman et al. (2010, Section 4), we
can use recursion from the leaves to the root, so that at any step we have a conditional
model that we put together into a joint one using the epistemic irrelevance/independence
assessments and the marginal extension theorem (Miranda & De Cooman, 2007), that allows
us to combine hierarchical information. This suggests that the developments in this paper
9. See also Section 8 for more details about strong independence; we surmise that the computational
complexity of dealing with strong products is worse than that for computing the independent natural
extension.

633

fiDe Cooman & Miranda

can be used to good advantage in finding efficient algorithms for inference in credal trees
under epistemic irrelevance, using sets of desirable gambles as uncertainty models. This
approach could build on the ideas proposed by De Cooman et al. (2010) and Destercke and
De Cooman (2008) in the context of credal trees with lower previsions as local uncertainty
models, but make them more general and also more directly amenable to simple assessment
and elicitation for the local models. This would have interesting applications in dealing
with hidden Markov models with imprecise transition and emission models, which are, of
course, special credal trees.
We expect that generalising those algorithms towards more general credal networks
(polytrees, . . . ) will be more difficult, and will have to rely heavily on the pioneering work
of Moral (2005) on graphoid properties for epistemic irrelevance. In this sense, it would
be interesting to model other assumptions of independence between variables using sets
of desirable gambles, for instance intermediate assumptions between epistemic irrelevance
and independence (that is, epistemic irrelevance for some pairs of sets of variables only).
Moreover, algorithms for computing the irrelevant and the independent natural extension,
as well as the strong product, need to be devised.
Other open problems would be to generalise our work to infinite sequences of random
variables, which would allow us to deal with unbounded trees, and, as we have already
discussed in the paper, to establish the associativity of the strong product and to extend
our results to variables taking values on infinite spaces.

Acknowledgments
This work was supported by SBO project 060043 of the IWT-Vlaanderen, and by project
MTM2010-17844. We would like to thank the reviewers for their helpful comments.

Appendix A. Examples
In this appendix, we have gathered a number of examples and counterexamples.
A.1 Independent Natural Extension Need Not Preserve Maximality
Let X = {0, 1} and let M be the subset of G(X ) given by
M := {f  G(X ) : f (0) + f (1) > 0 or f (0) = f (1) > 0} .
Then it is easy to see that M is a coherent set of desirable gambles. It is
1
moreover maximal: if some non-zero f 
/ M, then either f (0) + f (1) < 0,
whence f (0)  f (1) > 0 and then f > 0, or f (0) = f (1) < 0 and
M
then f (0) = f (1) > 0, which means that f  M.
Let N = {1, 2}, X 1 = X 2 = X and M1 = M2 = M. The independent
natural extension of M1 and M2 is given by


irr
M1  M2 := posi G(X {1,2} )>0  Airr
{1}{2}  A{2}{1}
n
o
irr
= h1 + h2 : h1  Airr

{0},
h

A

{0}
\ {0},
2
{1}{2}
{2}{1}
634

0

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

irr
taking into account that all non-negative gambles belong to both Airr
{1}{2} and A{2}{1}
irr
irr
and that Airr
{1}{2} {0} and A{2}{1} {0} are convex cones. Recall that h1  A{1}{2} {0}
iff h1 (0, )  M  {0} and h1 (1, )  M  {0}, and similarly that h2  Airr
{2}{1}  {0} iff
h2 (, 0)  M  {0} and h2 (, 1)  M  {0}. This means that any gamble h in M1  M2
can be expressed as

h(0, 0) =  + ,

h(0, 1) =  + ,

h(1, 0) =  + ,

h(1, 1) =  + ,

where , . . . ,  are real numbers satisfying the following constraints:
 +  > 0 or  =   0
 +  > 0 or  =   0
 +  > 0 or  =   0
 +  > 0 or  =   0
max{, , , } > 0.
Then the gamble h given by h(0, 0) = h(1, 1) = 1 and h(0, 1) = h(1, 0) = 1 does not belong
to M1  M2 : since h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = 0, we should have  =   0,
 =   0,  =   0 and  =   0, and this implies that h(0, 0)  0, a contradiction.
But h does not belong to M1  M2 either, because h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = 0
similarly implies that h(1, 1)  0. Hence, the independent natural extension of M1 and
M2 is not maximal.
A.2 A Maximal Independent Product of Maximal Sets
Next, we construct an example of an independent product of maximal sets that is again
maximal.
Consider the spaces X 1 and X 2 , and the maximal marginal coherent sets of desirable
gambles M1 and M2 as in Section A.1. Now consider the set of desirable gambles M
defined by
M := {h  G(X N ) : h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) > 0}
 {h  G(X N ) : h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = 0 and
[h(0, 0) > 0 or h(0, 0) = 0, h(0, 1) > 0 or h(0, 0) = h(0, 1) = 0, h(1, 0) > 0]}.
We first show that M1  M2  M . According to the discussion in Section A.1, any gamble
h in M1  M2 satisfies h(0, 0) =  + , h(0, 1) =  + , h(1, 0) =  + , and h(1, 1) =  + ,
where in particular
min{ + ,  + ,  + ,  + }  0,
whence
h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = ( + ) + ( + ) + ( + ) + ( + )
= ( + ) + ( + ) + ( + ) + ( + )  0.
If h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = 0, this implies that  +  =  +  =  +  =  +  = 0,
and therefore, again looking at the characterisation of M1  M2 in Section A.1, that
635

fiDe Cooman & Miranda

 =   0,  =   0,  =   0 and  =   0 This implies in particular
that h(0, 0) =  +   0. So we see that either h(0, 0) > 0, and in that case h  M , or
h(0, 0) = 0. But this implies that  =  =  =  = 0. And then h(0, 1) =   0, so again
we have either h(0, 1) > 0, in which case h  M , or h(0, 1) =  =  = 0. But now it
follows from the conditions imposed on the , . . . ,  in Section A.1 that h(1, 0) =  > 0,
which again means that h belongs to M . So, indeed, M1  M2  M .
We now show that M is a maximal coherent set of desirable gambles. It is easy to
see that M is coherent. To show that it is maximal, consider any non-zero gamble h in
G(X {1,2} ); then there are three possibilities. If h(0, 0) + h(1, 0) + h(0, 1) + h(1, 1) > 0, then
h  M and h 
/ M . If h(0, 0) + h(1, 0) + h(0, 1) + h(1, 1) < 0, then h  M and h 
/ M .
And if h(0, 0) + h(1, 0) + h(0, 1) + h(1, 1) = 0, then exactly one of h, h belongs to M .
To conclude, note that M is an independent product of M1 and M2 because of Proposition 24.
A.3 The Strong Product May Strictly Include The Independent Natural
Extension
The following is an adaptation of an example by Walley (1991, Example 9.3.4).
Consider X = {0, 1} and let P be the coherent lower prevision determined by P ({0}) =
2/5 and P (1) = 1/2, so we have for all f  G(X ) that:


1
1
2
3
P (f ) = min
f (0) + f (1), f (0) + f (1) .
2
2
5
5
With P we can associate the coherent set of (strictly) desirable gambles by Eq. (3):
D := {f : f > 0 or P (f ) > 0} .
Now let N = {1, 2}, X 1 = X 2 = X and D1 = D2 = D. Consider the gamble h on X {1,2}
determined by
51
49
h(0, 0) = h(1, 1) =
, h(0, 1) = h(1, 0) = 
.
100
100
To see that D1  D2 is strictly included in D1  D2 , we will show that h belongs to D1  D2
but not to D1  D2 .
irr
For the latter claim, consider any gambles h1  Airr
{1}{2} and h2  A{2}{1} , and assume
ex absurdo that h  h1 +h2 . Then we see that (h1 +h2 )(0, 0) = +, (h1 +h2 )(0, 1) =  +,
(h1 + h2 )(1, 0) =  +  and (h1 + h2 )(1, 1) =  + , where the real numbers , . . . ,  must
satisfy the following constraints:


1
1 2
3
max{, } > 0 and min
 + ,  +   0
2
2 5
5


1
1 2
3
max{, } > 0 and min
 + ,  +   0
2
2 5
5


1
1 2
3
max{, } > 0 and min
 + ,  +   0
2
2 5
5


1
1 2
3
max{, } > 0 and min
 + ,  +   0.
2
2 5
5
636

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

As a consequence,
3
2
( + ) + ( +  +  +  +  + )
5
5
2
3
2
3
6 1
1
6 1
1
= (  + ) + (  + ) + (  + ) + (  + )  0,
5
5
5
5
5 2
2
5 2
2
but on the other hand
2
3
( + ) + ( +  +  +  +  + )
5
5


2
3
39
h(0, 0) + (h(0, 1) + h(1, 0) + h(1, 1)) = 
,
5
5
500

a contradiction. This implies that h does not belong to D1  D2 .
For the former claim, consider arbitrary maximal coherent set of desirable gambles
M1  m(D1 ) and M2  m(D2 ). Then it follows from the discussion in Section 2.6 that
M1 induces a linear prevision P1  P 1 , and that M2 induces a linear prevision P2  P 2 .
But then it follows from the discussion in Example 9.3.4 by Walley (1991) that
(P1  P2 )(h) 

1
> 0,
100

which tells us that h belongs to the set of strictly desirable gambles that induces P1  P2 ,
because of Eq. (3). Since that is the smallest coherent set of desirable gambles that induces
P1  P2 , and since M1  M2 is another such set, by Theorem 28, we deduce that h 
M1  M2 . It follows that indeed h  D1  D2 .

References
Antonucci, A., de Campos, C., & Zaffalon, M. (2012). Probabilistic graphical models. In
Coolen, F., Augustin, T., De Cooman, G., & Troffaes, M. C. M. (Eds.), An introduction
to imprecise probabilities, chap. 10. John Wiley & Sons. In press.
Augustin, T., Coolen, F. P. A., De Cooman, G., & Troffaes, M. C. M. (Eds.). (2012).
Introduction to Imprecise Probabilities. John Wiley & Sons. In press.
Aumann, R. J. (1962). Utility theory without the completeness axiom. Econometrica, 30,
445462.
Bernoulli, J. (1713). Ars Conjectandi. Thurnisius, Basel.
Boole, G. (1847, reprinted in 1961). The Laws of Thought. Dover Publications, New York.
Boole, G. (2004, reprint of the work originally published by Watts & Co., London, in 1952).
Studies in Logic and Probability. Dover Publications, Mineola, NY.
Buehler, R. J. (1976). Coherent preferences. The Annals of Statistics, 4, 10511064.
Couso, I., & Moral, S. (2011). Sets of desirable gambles: conditioning, representation, and
precise probabilities. International Journal of Approximate Reasoning, 52 (7), 1034
1055.
637

fiDe Cooman & Miranda

Couso, I., Moral, S., & Walley, P. (2000). A survey of concepts of independence for imprecise
probabilities. Risk Decision and Policy, 5, 165181.
Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120, 199233.
Cozman, F. G. (2005). Graphical models for imprecise probabilities. International Journal
of Approximate Reasoning, 39 (2-3), 167184.
Cozman, F. G. (2012). Sets of probability distributions, independence, and convexity. Synthese, 186, 177200.
de Campos, L. M., & Moral, S. (1995). Independence concepts for convex sets of probabilities. In Besnard, P., & Hanks, S. (Eds.), Eleventh Conference on Uncertainty in
Artificial Intelligence, pp. 108115. San Francisco, CA.
De Cooman, G. (2005). Belief models: an order-theoretic investigation. Annals of Mathematics and Artificial Intelligence, 45 (12), 534.
De Cooman, G., Hermans, F., Antonucci, A., & Zaffalon, M. (2010). Epistemic irrelevance in
credal nets: the case of imprecise Markov trees. International Journal of Approximate
Reasoning, 51 (9), 10291052.
De Cooman, G., Miranda, E., & Zaffalon, M. (2011). Independent natural extension. Artificial Intelligence, 175 (1213), 19111950.
De Cooman, G., & Quaeghebeur, E. (2012). Exchangeability and sets of desirable gambles.
International Journal of Approximate Reasoning, 53 (3), 363395. Special issue in
honour of Henry E. Kyburg, Jr.
de Finetti, B. (1931). Sul significato soggettivo della probabilita. Fundamenta Mathematicae, 17, 298329.
de Finetti, B. (1937). La prevision: ses lois logiques, ses sources subjectives. Annales de
lInstitut Henri Poincare, 7, 168. English translation in (Kyburg Jr. & Smokler,
1964).
de Finetti, B. (1970). Teoria delle Probabilita. Einaudi, Turin.
de Finetti, B. (19741975). Theory of Probability: A Critical Introductory Treatment. John
Wiley & Sons, Chichester. English translation of (de Finetti, 1970), two volumes.
Destercke, S., & De Cooman, G. (2008). Relating epistemic irrelevance to event trees. In
Dubois, D., Lubiano, M., Prade, H., Gil, M., Grzegiorzewski, P., & Hryniewicz, O.
(Eds.), Soft Methods for Handling Variability and Imprecision, pp. 6673. Springer.
Dubins, L. E. (1975). Finitely additive conditional probabilities, conglomerability and disintegrations. The Annals of Probability, 3, 8899.
Dubra, J., Maccheroni, F., & Ok, E. (2004). Expected utility theory without the completeness axiom. Journal of Economic Theory, 115 (1), 118133.
Fishburn, P. C. (1975). A theory of subjective expected utility with vague preferences.
Theory and Decision, 6, 287310.
Gardenfors, P. (1988). Knowledge in Flux  Modeling the Dynamics of Epistemic States.
The MIT Press, Cambridge, MA.
638

fiIrrelevant and Independent Natural Extension for Sets of Desirable Gambles

Giron, F. J., & Rios, S. (1980). Quasi-Bayesian behaviour: A more realistic approach to
decision making?. In Bernardo, J. M., DeGroot, M. H., Lindley, D. V., & Smith, A.
F. M. (Eds.), Bayesian Statistics, pp. 1738. Valencia University Press, Valencia.
Hermans, F. (2012). An operational approach to graphical uncertainty modelling. Ph.D.
thesis, Faculty of Engineering and Architecture.
Koopman, B. O. (1940). The Axioms and Algebra of Intuitive Probability. The Annals of
Mathematics, Second Series, 41 (2), 269292.
Kyburg Jr., H. E., & Smokler, H. E. (Eds.). (1964). Studies in Subjective Probability. Wiley,
New York. Second edition (with new material) 1980.
Levi, I. (1980). The Enterprise of Knowledge. MIT Press, London.
Miranda, E., & De Cooman, G. (2007). Marginal extension in the theory of coherent lower
previsions. International Journal of Approximate Reasoning, 46 (1), 188225.
Miranda, E., & Zaffalon, M. (2010). Notes on desirability and coherent lower previsions.
Annals of Mathematics and Artificial Intelligence, 60 (34), 251309.
Miranda, E., Zaffalon, M., & De Cooman, G. (2012). Conglomerable natural extension.
International Journal of Approximate Reasoning, 53 (8), 12001227.
Moral, S. (2005). Epistemic irrelevance on sets of desirable gambles. Annals of Mathematics
and Artificial Intelligence, 45 (12), 197214.
Moral, S., & Wilson, N. (1995). Revision rules for convex sets of probabilities. In Coletti,
G., Dubois, D., & Scozzafava, R. (Eds.), Mathematical Models for Handling Partial
Knowledge in Artificial Intelligence, pp. 113128. Plenum Press, New York.
Pearl, J. (1985). Bayesian netowrks: a model for self-activated memory for evidential reasoning. In Proceedings of the 7th Conference of the Cognitive Science Society, pp.
329334, Irvine, CA. University of California.
Quaeghebeur, E. (2012a). The CONEstrip algorithm. In Proceedings of SMPS 2012, pp.
4554. Springer.
Quaeghebeur, E. (2012b). Desirability. In Coolen, F., Augustin, T., de Cooman, G., &
Troffaes, M. C. M. (Eds.), An Introduction to Imprecise Probabilities, chap. 2. John
Wiley & Sons. In press.
Seidenfeld, T., Schervish, M. J., & Kadane, J. B. (1995). A representation of partially
ordered preferences. The Annals of Statistics, 23, 21682217. Reprinted in (Seidenfeld,
Schervish, & Kadane, 1999), pp. 69129.
Seidenfeld, T., Schervish, M. J., & Kadane, J. B. (1999). Rethinking the Foundations of
Statistics. Cambridge University Press, Cambridge.
Seidenfeld, T., Schervish, M. J., & Kadane, J. B. (2010). Coherent choice functions under
uncertainty. Synthese, 172 (1), 157176.
Shapley, L. S., & Baucells, M. (1998). A theory of multiperson utility. Discussion paper,
department of economics 779, UCLA.
Smith, C. A. B. (1961). Consistency in statistical inference and decision. Journal of the
Royal Statistical Society, Series A, 23, 137.
639

fiDe Cooman & Miranda

Walley, P. (1982). The elicitation and aggregation of beliefs. Tech. rep., University of
Warwick, Coventry. Statistics Research Report 23.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
London.
Walley, P. (2000). Towards a unified theory of imprecise probability. International Journal
of Approximate Reasoning, 24 (23), 125148.
Williams, P. M. (1975a). Coherence, strict coherence and zero probabilities. In Proceedings
of the Fifth International Congress on Logic, Methodology and Philosophy of Science,
Vol. VI, pp. 2933. Dordrecht. Proceedings of a 1974 conference held in Warsaw.
Williams, P. M. (1975b). Notes on conditional previsions. Tech. rep., School of Mathematical
and Physical Science, University of Sussex, UK. Revised journal version: (Williams,
2007).
Williams, P. M. (2007). Notes on conditional previsions. International Journal of Approximate Reasoning, 44 (3), 366383. Revised journal version of (Williams, 1975b).
Zaffalon, M., & Miranda, E. (2012). Probability and time. Submitted for publication.

640

fiJournal of Artificial Intelligence Research 45 (2012) 363-441

Submitted 03/12; published 10/12

Transforming Graph Data for Statistical Relational Learning
Ryan A. Rossi

rrossi@purdue.edu

Department of Computer Science, Purdue University
West Lafayette, IN 47907 USA

Luke K. McDowell

lmcdowel@usna.edu

Department of Computer Science, U.S. Naval Academy
Annapolis, MD 21402, USA

David W. Aha

david.aha@nrl.navy.mil

Navy Center for Applied Research in Artificial Intelligence
Naval Research Laboratory (Code 5514)
Washington, DC 20375, USA

Jennifer Neville

neville@purdue.edu

Department of Computer Science, Purdue University
West Lafayette, IN 47907 USA

Abstract
Relational data representations have become an increasingly important topic due to
the recent proliferation of network datasets (e.g., social, biological, information networks)
and a corresponding increase in the application of Statistical Relational Learning (SRL)
algorithms to these domains. In this article, we examine and categorize techniques for
transforming graph-based relational data to improve SRL algorithms. In particular, appropriate transformations of the nodes, links, and/or features of the data can dramatically
affect the capabilities and results of SRL algorithms. We introduce an intuitive taxonomy
for data representation transformations in relational domains that incorporates link transformation and node transformation as symmetric representation tasks. More specifically,
the transformation tasks for both nodes and links include (i) predicting their existence, (ii)
predicting their label or type, (iii) estimating their weight or importance, and (iv) systematically constructing their relevant features. We motivate our taxonomy through detailed
examples and use it to survey competing approaches for each of these tasks. We also discuss general conditions for transforming links, nodes, and features. Finally, we highlight
challenges that remain to be addressed.

1. Introduction
In this article, we examine and categorize techniques for transforming relational data to improve Statistical Relational Learning (SRL) algorithms. Below, Section 1.1 first introduces
relational data and SRL. We summarize the primary types of representations for relational
data, and explain that we focus on data represented as graphs. Section 1.1 also describes
how transforming the content (rather than the type) of this representation can improve SRL
analysis. For instance, predicting new links in a graph can increase accuracy for relational
node classification. Section 1.2 then identifies the scope of this article. Finally, Section 1.3
summarizes the organization and approach of this article, and includes a description of our
taxonomy for relational representation transformation.
c
2012
AI Access Foundation. All rights reserved.

fiRossi, McDowell, Aha, & Neville

1.1 Relational Data, SRL, and Representation Choices
The majority of research in machine learning assumes independently and identically distributed data. This independence assumption is often violated in relational data, which encode dependencies among data instances. For instance, people are often linked by business
associations, and information about one person can be highly informative for a prediction
task involving an associate of that person. More generally, relational data can be described
as a set of nodes, which can be connected by one or more types of relations (or links).
Relational information is seemingly ubiquitous; it is present in domains such as the Internet
and the world-wide web (Faloutsos, Faloutsos, & Faloutsos, 1999; Broder et al., 2000; Albert, Jeong, & Barabasi, 1999), scientific citation and collaboration (McGovern et al., 2003;
Newman, 2001b), epidemiology (Pastor-Satorras & Vespignani, 2001; Moore & Newman,
2000; May & Lloyd, 2001; Kleczkowski & Grenfell, 1999) communication analysis (Rossi
& Neville, 2010), metabolism (Jeong, Tombor, Albert, Oltvai, & Barabasi, 2000; Wagner
& Fell, 2001), ecosystems (Dunne, Williams, & Martinez, 2002; Camacho, Guimera, &
Nunes Amaral, 2002), bioinformatics (Maslov & Sneppen, 2002; Jeong, Mason, Barabasi,
& Oltvai, 2001), fraud and terrorist analysis (Neville et al., 2005; Krebs, 2002), and many
others. The links in these data may represent citations, friendships, associations, metabolic
functions, communications, co-locations, shared mechanisms, or many other explicit or implicit relationships.
Statistical relational learning (SRL) methods have been developed to address the problems of reasoning and learning in domains with complex relations and probabilistic structure
(Getoor & Taskar, 2007). In particular, SRL algorithms leverage relational information in
an attempt to learn models with higher predictive accuracy. A key characteristic of many
relational datasets is a correlation or statistical dependence between the values of the same
attribute across linked instances (e.g., two friends are more likely to share political views
than two randomly selected people). This relational autocorrelation provides a unique opportunity to increase the accuracy of statistical inferences (Jensen, Neville, & Gallagher,
2004). Similarly, relational information can be exploited for many other reasoning tasks
such as identifying useful patterns or optimizing systems (Easley & Kleinberg, 2010).
Representation issuesincluding knowledge, model, and data representationhave been
at the heart of the artificial intelligence community for decades (Amarel, 1968; Minsky, 1974;
Russell & Norvig, 2009). All of these are important, but here we focus on data representation issues, simple examples of which include the choices of whether to discretize continuous
features or to add higher-order polynomial features. Such decisions can have a significant
effect on the accuracy and efficiency of AI algorithms. They are especially critical for the
performance of SRL algorithms because, in relational domains, there is an even larger space
of potential data representations to consider. The complex structure of relational data can
often be represented in a variety of ways and the choice of specific data representation
can impact both the applicability of particular models/algorithms and their performance.
Specifically, there are two categories of decisions that need to be considered in the context
of relational data representation.
First, we have to consider the type of data representation to use (cf., the hierarchy
of De Raedt, 2008, ch. 4). For instance, relational data can be propositionalized for the
application of standard, non-relational learning algorithms. More often, in order to fully
364

fiTransforming Graph Data for Statistical Relational Learning

exploit the relational information, SRL researchers have chosen to represent the data either
using an attributed graph in a relational database (see e.g., Friedman, Getoor, Koller, &
Pfeffer, 1999), or via logic programs (see e.g., Kersting & De Raedt, 2002).1 Each choice
has different strengths. In this article, we focus on the graph-based representation, which
has been a common choice for addressing the growing interest in network data and applications for analyzing electronic communication and online social networks such as Facebook,
Twitter, Flickr, and LinkedIn (Mislove, Marcon, Gummadi, Druschel, & Bhattacharjee,
2007; Ahmed, Berchmans, Neville, & Kompella, 2010). Specifically, we assume a graphbased data representation G = hV, E, XV , XE i where the nodes V are entities (e.g., people,
places, events) and the links E represent relationships among those entities (e.g., friendships, citations). XV is a set of features about the entities in V . Likewise, the set of features
XE provides information about the relation links in E.
Next, given the type of representation, we must consider the specific content of the data
representation, for which there is a large space of choices. For instance, features for the nodes
and links of a graph can be constructed using a wide range of aggregation functions, based on
multiple kinds of links and paths. SRL researchers have already recognized the importance
of such data representation choices (e.g., Getoor & Diehl, 2005), and many separate studies
have examined techniques for feature construction (Neville, Jensen, Friedland, & Hay, 2003),
node weighting (Tang, Musolesi, Mascolo, & Latora, 2009), link prediction (Taskar, Wong,
Abbeel, & Koller, 2003), etc. However, this article is the first to comprehensively survey
approaches to relational representation transformation for graph-based data.
Given a set of (graph-based) relational data, we define relational representation transformation as any change to the space of links, nodes, and/or features used to represent
the data. Typically, the goal of this transformation is to improve the performance of some
subsequent SRL application. For instance, in Figure 1 the original graph representation G
is transformed into a new representation G where links, nodes, and features (such as link
weights) have been added, and some links have been removed. Some SRL algorithm or
analysis is then applied to the new representation, for instance to classify the nodes or to
identify anomalous links. The particular transformations that are used to produce G will
vary depending upon the intended application, but can sometimes substantially improve
the accuracy, speed, or complexity of the final application. For instance, Gallagher, Tong,
Eliassi-Rad, and Faloutsos (2008) found that adding links between similar nodes could increase node classification accuracy by up to 15% on some tasks. Similarly, Neville and
Jensen (2005) demonstrated that adding nodes which represent underlying groups enabled
both simpler inference and increased accuracy.
1.2 Scope of this Article
This article focuses on examining and categorizing various techniques for changing the
representation of graph-based relational data. As shown in Figure 1, we typically view
these changes as a pre-processing step that enables increased accuracy or speed for some
other task, such as object classification. However, an output of these techniques can itself
be valuable. For instance, the administrators of a social network may be interested in
1. In the latter case, the applicable SRL algorithms are often referred to as probabilistic inductive logic
programming (ILP) (De Raedt & Kersting, 2008).

365

fiRossi, McDowell, Aha, & Neville

C	 

C	 
SRL	 Analysis	 /	 
Application	 

Representation	 
Transformation	 

L	 
L	 

L	 

G	 


G	 
	 

Result	 

Figure 1: Example Transformation and Subsequent Analysis: The original relational representation G is transformed into G where dotted lines represent predicted links, squares represent predicted nodes, and bold links represent link
weighting. Changes may be based on link structure, link features, and node features (here, similar node shadings indicate similar feature values). Some SRL
analysis is then applied to the new representation. In this example, the SRL
analysis produces a label (C or L) for each node, as with the example task discussed in Section 2.1. This article focuses on the representation transformation
(left side of the figure), not the subsequent analysis.

link prediction so that predicted links can be presented to their users as potential new
friendship links. Alternatively, these techniques may also be applied to improve the
comprehensibility of a model. For example, the prediction of protein-protein interactions
provides insights into protein function (Ben-Hur & Noble, 2005). Thus, the techniques
we survey may be used for multiple purposes, and relevant publications may have used
them in different contexts. Regardless of the original context, we will examine the general
applicability and benefits of each technique. After such techniques have been applied, the
transformed data can be used as is (e.g., for friendship suggestions), examined for greater
understanding, used for some other task (e.g., for object classification), or used recursively
as the input for another representation change (e.g., as in object/node prediction followed
by link prediction).
We do not attempt to survey the many methods that could be used for SRL analysis
(e.g., the right side of Figure 1), although the relevant set of methods for such analysis
overlaps with the set of methods that facilitate the transformations we consider. For instance, collective classification (Neville & Jensen, 2000; Taskar, Abbeel, & Koller, 2002) is
an important SRL application that we define in Section 2 and use as a running example
of an SRL analysis task. The output of such classification could also be used to create
new attributes for the nodes (a data representation change). We discuss this possibility in
Section 6.2, but focus on a few cases where such node labeling is particularly useful as a
pre-processing step (e.g., before applying certain stacked algorithms), rather than surveying the wide range of possible classification algorithms, whether collective or not. Likewise,
we do not survey issues in model and knowledge representation, such as whether the sta366

fiTransforming Graph Data for Statistical Relational Learning

tistical dependencies between nodes, links, and features should be modeled with Structural
Logistic Regression (Popescul, Popescul, & Ungar, 2003b) or with a Markov Logic Network
(Domingos & Richardson, 2004). We consider such issues only briefly, in Section 8.4.
Furthermore, we focus on transformations that change the content of the graph data
representation. In particular, we examine transformations to graph data that modify the
set of links or nodes, or modify their features. We do not consider changing the graph data
to a different type of representation, e.g., by propositionalizing the data or by changing to
a logic program. However, some of the transformations we discuss, such as node or link
feature aggregation, are a form of propositionalization. In addition, Section 6.3.3 describes
a number of techniques for structure learning of logic programs, because these techniques
are closely related to the analogous problem of feature construction for graph-based representations. Finally, many of the other techniques that we discuss are also applicable to
logical representations. For instance, link weighting could be applied to weight the known
relations before using a logic program to detect anomalous objects. We focus, however, on
the methods most useful for transforming graph-based representations.
1.3 Approach and Organization of this Article
There are many dimensions of relational data transformation, which complicate the task of
understanding and selecting the most appropriate techniques. To assist in this process, we
introduce a simple and intuitive taxonomy for representation transformation that identifies link transformation and node transformation as symmetric representation tasks. More
specifically, the transformation tasks for both nodes and links include (i) predicting their
existence, (ii) predicting their label or type, (iii) estimating their weight or importance, and
(iv) constructing their relevant features. In addition, we propose a taxonomy for constructing both link and node features that consists of non-relational features, topology features,
relational node-value features, and relational link-value features. For each relational transformation task, we survey the applicable techniques, examine necessary conditions, and
provide detailed examples and comparisons.
This article is organized as follows. The next section presents our taxonomy for relational
representation transformation and discusses a motivating example. In Section 3, we review
the algorithms for link prediction, while Section 4 examines the task of link interpretation
(i.e., constructing link labels, link weights, and link features). Sections 5 and 6 consider
the corresponding prediction and interpretation tasks for nodes instead of links. In Section
7, we summarize algorithms that jointly transform nodes and links. Section 8 discusses
methods for evaluating representation transformations and challenges for future work, and
Section 9 concludes.

2. Overview and Motivating Example
In this section we first introduce a running example based on the classification of data
from Facebook, then describe how relational algorithms could be used to perform this task.
Next, we introduce a taxonomy for relational representation transformation and explain
how each type of transformation could aid the Facebook classification task. Finally, we
formally define each type of relational representation transformation.
367

fiRossi, McDowell, Aha, & Neville

2.1 Motivating SRL Analysis Example: A Classification Task
As an example, we consider hypothetical data inspired by Facebook (www.facebook.com),
one of the most popular online social networks. We assume that we are given a graph
G = hV, E, XV , XE i where the nodes V are users 2 and the links E represent friendships in
Facebook. XV is a set of features about the users in V such as their gender, relationship
status, school, favorite movies, or musical preference (though information may be missing
for some users). Likewise, the set of features XE provides information about the friendship
links in E such as the time of formation or possibly the contents of the message that was
sent when the link formation was requested by one of the users.
The example SRL analysis task (see Figure 1) is to predict the political affiliation (liberal,
moderate, or conservative) of every node (person) in G. We assume that this affiliation,
which we call the class label of a node, is known for some but not all of the people in G.3
Moreover, we assume that a users political affiliation is likely to be correlated with the
characteristics of that user and (to a lesser degree) that users friends. The next section
summarizes how these correlations can be used for classification.
For this example, we assume that links are simple, binary friendship connections. However, other link types could be used to represent other kinds of relationships. For instance,
a link might indicate that two people have communicated via a wall-post message, or that
two people have chosen to join the same Facebook group. In addition, the notion of friendship in Facebook is very weak and thus a significant portion of a persons friends are often
only casual acquaintances. Thus, representation changes such as link deletion or weighting
may have a significant impact on classification accuracy. For notational purposes, we add a
tilde to the top of each graph components symbol to indicate that it has undergone some
transformation (e.g., the modified link set E is denoted by E).
2.2 Background: Features and Methods for Classification
To predict the political affiliation of Facebook users, conventional classification approaches
would ignore the links and classify each user using only information known about that user,
such as their gender or location. We assume that such information is represented in the
form of non-relational features, which are those features that can be computed directly
from XV without considering the links E. We refer to classification based only on these
features as non-relational classification. Alternatively, in relational classification, the links
are explicitly used to construct additional relational features to capture information about
each users friends. For instance, a relational feature could compute, for each user, the
proportion of friends that are male or that live in a particular region. Using such relational
information can potentially increase classification accuracy, though may sometimes decrease
accuracy as well (Chakrabarti, Dom, & Indyk, 1998). Finally, even greater (and usually
more reliable) increases can occur when the class labels (e.g., political affiliations) of the
linked users are used instead to derive relevant features (Jensen et al., 2004). For instance,
2. In general, there may be more than one type of node. For instance, nodes in a citation network may
represent papers or authors.
3. Later, we discuss the representation change of node labeling, which also constructs an estimated label
for every node. As discussed in Section 1.2, representation changes can sometimes resemble the output
of SRL analysis, but we focus on changes that are particularly useful as pre-processing before some
subsequent SRL analysis.

368

fiTransforming Graph Data for Statistical Relational Learning

a class-label relational feature could compute, for each user, the proportion of friends
that have liberal views. However, using such features is challenging since some or all of
the labels are initially unknown, and thus typically must be estimated and then iteratively
refined in some way. This process of jointly inferring the labels of interrelated nodes is
known as collective classification (CC).
CC requires both models and inference procedures that use inferences about one user to
affect inferences about related users. Many such algorithms have been considered for CC,
including Gibbs Sampling (Jensen et al., 2004), relaxation labeling (Chakrabarti, Dom, &
Indyk, 1998), belief propagation (Taskar et al., 2002), ICA (Neville & Jensen, 2000; Lu &
Getoor, 2003), and weighted neighbor techniques (Macskassy & Provost, 2007). See the
work of Sen et al. (2008) for a survey.
As a concrete example of SRL analysis, we explain many of the techniques in this survey
in terms of the Facebook classification task, with a special emphasis on CC. However, the
features and the transformation techniques apply to many other SRL tasks and data sets
such as relationship classification, anomalous link detection, entity resolution, or group
discovery (Getoor & Diehl, 2005).
2.3 Representation Transformation Tasks for Improving SRL
Figure 2 shows our proposed taxonomy for relational representation transformation. The
two main tasks in this taxonomy are link transformation and node transformation. We
find that there is a powerful and elegant symmetry between these two tasks. In particular,
the link and node representation transformation tasks can be decomposed into prediction
and interpretation tasks. The former task involves predicting the existence of new nodes
and links. The latter task of interpretation involves three parts: constructing the weights,
labels, or features of nodes or links. Together, this yields eight distinct transformation tasks
as shown in the leaves of the taxonomy in Figure 2. Underneath these eight tasks in the
figure, we list the primary graph component that is modified by each task (i.e., V , E, XV ,
or XE ), followed by an illustration of a possible representation change for that task. In
the text below, we summarize Figure 2, organized around the four larger categories of link
prediction, link interpretation, node prediction, and node interpretation.
First, link prediction adds new links to the graph. The sample graph for this task
(Figure 2A) shows a link being predicted where the similarity between two nodes has been
used to predict a new link between them. Intuitively, Facebook users that share the values
of many non-relational features may also share the same political affiliation. Thus, adding
links between such people should increase autocorrelation and improve the accuracy of collective classification. There are many simple link prediction algorithms based on similarity,
neighbor properties, shortest path distances, infinite sums over paths (i.e. random walks),
and other strategies. Section 3 provides more detail on these techniques.
Second, there are several types of link interpretation, which involves constructing
weights, labels, or features for the existing links. For instance, in many graphs (including
our Facebook data), not all links (or friendships) are of equal importance. Thus, Figure 2B
shows the result of performing link weighting. In this case, weights are based on the similarity between the feature values of each pair of linked nodes, under the assumption that
high similarity may indicate stronger relationships. (Link prediction techniques may also
369

fiRossi, McDowell, Aha, & Neville

Relational
Representation
Transformation

input	 

	 
E 	 

weighted	 link	 

labeled	 link	 

predicted	 node	 

weighted	 node	 

labeled	 node	 

Node	 Transformation	 

Link	 Interpretation	 

Node	 Prediction	 

Link	 Weighting	 

Link	 Labeling	 

Link	 Feature	 
Construction	 

X	 E	 

X	 E	 

X	 E	 

V	 	 

Node	 Interpretation	 

Node	 Weighting	 

Node	 Labeling	 

Node	 Feature	 
Construction	 

X	 V	 

X	 V	 

X	 V	 

p	 
p	 

B.	 

C	 
w	 

w	 

A.	 

p	 

L	 

Link	 Transformation	 

Link	 Prediction	 

predicted	 link	 

2	  	 

+	 

3	  	 

3	  	 

p	 

C.	 

-	 

C	 

M	 

D.	 

E.	 

F.	 

L	 
G.	 

.1	  	  B	 

.2	  	  A	 

L	 

-	 

.3	  	  B	 

.5	  	  A	 

.3	  	  A	 

H.	 

Figure 2: Relational Representation Transformation Taxonomy: Link and node
transformation are formulated as symmetric tasks leading to four main transformation tasks: predicting links, interpreting links, predicting nodes, and interpreting nodes. Each task yields a modified graph component: E, XE , V , or
XV , respectively. Interpretation is further divided into weighting, labeling, or
constructing features. Examples of each of the tasks in relational representation
transformation are shown under the leaves of the taxonomy. In these example
graphs, nodes with similar shadings have similar feature values.

370

fiTransforming Graph Data for Statistical Relational Learning

use such similarity measures, but for identifying probable new links, rather than weighting
existing links.) Alternatively, link labeling may be used to assign some kind of discrete label
to each link. For instance, Figure 2C shows how links might be labeled as either personal
(p) or work (w) related, e.g., based on known feature values or an analysis of communication events between the linked users. On the other hand, links might instead be labeled
as having positive or negative influence (i.e., labeled as +/). Finally, Figure 2D shows
how link feature construction can be used to add more general kinds of feature values to
each link. For instance, a link feature might count the number of communication events
that occurred between two people or the number of friends in common. Link weighting
and labeling could perhaps be viewed as special cases of link feature construction, but we
separate them because later sections will show how the most useful techniques for each task
differ. All three of these link interpretation tasks could help with our example classification
problem. In particular, a model learned to predict political affiliation might choose to place
special emphasis on links that are highly weighted or that are labeled as personal. Other
link features might be used to represent more complex dependencies, for instance modeling influence from a users work friendships, but only for friendship links between nodes
where there are a large number of friends in common. More details on these techniques are
provided in Section 4.
Third, node prediction adds additional nodes (and associated links) to the graph.
For instance, Figure 2E shows the result after relational clustering has been applied to
discover two latent groups in the graph, where each user is now connected to one latent
group node. A discovered node in Facebook might represent types of social processes,
influences, or a tightly knit group of friends. The clustering or other techniques used to
identify the new nodes could be designed to identify people that are particularly similar
with respect to a relevant characteristic, such as their political affiliation. The new nodes
and associated links could then be used in several ways. For instance, though not present
in the small example of Figure 2E, some nodes that were far away (in terms of shortest
path length) in the original graph may be much closer in the new graph. Thus, links to a
latent node may allow influence to propagate more effectively when an algorithm such as
CC is applied. Alternatively, identification of distinct latent groups may even enable more
efficient or accurate algorithms to be applied separately to each group (Neville & Jensen,
2005). Node prediction is discussed further in Section 5.
Finally, there are several types of node interpretation, which involves constructing
weights, labels, or feature values for existing nodes. For instance, as with links, some
nodes may be more influential than others and thus should have more weight. Figure 2F
demonstrates node weighting, where the weights might be assigned based on the numbers
of friends or via the PageRank/eigenvector techniques. See Section 6.1 for more details.
Alternatively, Figure 2G shows an example of node labeling. Here the graph represents
a training graph, and each node has been given an estimated label of conservative (C),
liberal (L), or moderate (M). Such labels might be estimated using only the non-relational
features or via textual analysis. While most classification algorithms learn a model based
on true labels in the training graph, some approaches instead first compute such estimated
labels, then learn a model from this new representation (Kou & Cohen, 2007). Section 6.2
discusses how this can simplify inference. Finally, Figure 2H shows the result of node feature
construction, where arbitrary feature values are added to each node. For instance, suppose
371

fiRossi, McDowell, Aha, & Neville

we find that users with relatively few Facebook friends are often moderate while those with
many friends are often liberal. In this case, a feature counting the number of friends for each
node would be useful. To more directly exploit autocorrelation, a different feature might
count the proportion of a users friends that are conservative, or the most common political
affiliation of a users friends. Any feature that is correlated with political affiliation could
be used to improve the performance of a classification algorithm for our example problem.
Identifying and/or computing such features is essential to the performance of most SRL
algorithms but can be very challenging; Section 6.3 considers this process.
In Table 2.3, we summarize some of the most prominent techniques for performing
these tasks of link prediction, link interpretation, node prediction, and node interpretation.
Sections 3-6 provide more detail about each category in turn.
2.4 Relational Representation Transformation: Definitions and Terminology
We assume that the initial relational data is represented as a graph G = hV, E, XV , XE i
such that each vi  V corresponds to node i and each edge eij  E corresponds to a
(directed) link between nodes i and j. XV is a set of features about the nodes in V , and
XkV  XV is the k th such feature. Likewise, XE is a set of features about the links in
E, and XkE  VE is the k th such feature. The features XE could refer to link weights,
distances, or types, among other possibilities. The preceding notation lets us identify, for
instance, the values of a particular feature XkV for all nodes. Alternatively, xvi refers to a
vector containing all of the feature values for a particular node vi , and xeij contains all of
the feature values for a particular edge eij . Table 2.3 summarizes this notation.
Relational representation transformation is the process of transforming the original
graph G into some new graph G = hV , E, XV , XE i by an arbitrary set of transformation techniques. During this process, nodes, links, weights, labels, and general features may
be added, and nodes and links may be removed. In theory, the transformation seeks to
optimize some objective function (for instance, to maximize the autocorrelation), although
in practice the objective function may not be completely specified or guaranteed to be improved by the transformation. We now define more specifically the four primary parts of
relational representation transformation:
Definition 2.1 (Link Prediction) Given the nodes V , observed links E and/or the feature
set X = (XE , XV ), the link prediction task is defined as the creation of a modified link set
E such that E 6= E. Usually, this involves adding new links that were not present in E,
but links may also be deleted.
Definition 2.2 (Link Interpretation) Given the nodes V , observed links E and/or the
feature set X = (XE , XV ), the link interpretation task is defined as the creation of a new
link feature XkE where XkE 
/ XE . This task may estimate a feature value for every link.
Alternatively, the values of XkE may be only partially estimated, for example, if the original
features have missing values or if additional links are also introduced during link prediction.
Definition 2.3 (Node Prediction) Given the nodes V , links E and/or the feature set
X = (XE , XV ), node transformation is defined as the creation of a modified node set V
such that V  V . In addition, many node prediction tasks simultaneously create new links,
372

fiTransforming Graph Data for Statistical Relational Learning

Relational Representation Transformation
Links
?

Prediction

?
?

?

Weighting

?

?

?
?

Labeling

?
?

Feature

Nodes

Adamic/Adar (Adamic &
Adar, 2001), Katz (Katz, 1953),
and others (Liben-Nowell &
Kleinberg, 2007)
Text or Feature Similarity
(Macskassy, 2007)
Classification
via
RMN
(Taskar et al., 2003) or SVM
(Hasan, Chaoji, Salem, & Zaki,
2006)
Latent Variable Estimation (Xiang, Neville, & Rogati,
2010)
Linear Combination of Features (Gilbert & Karahalios,
2009)
Aggregating Intrinsic Information (Onnela, Saramaki,
Hyvonen, Szabo, Lazer, Kaski,
Kertesz, & Barabasi, 2007)
LDA (Blei et al., 2003), PLSA
(Hofmann, 1999),
Link Classification via Logistic Regression (Leskovec, Huttenlocher, & Kleinberg, 2010),
Bagged Decision Trees (Kahanda & Neville, 2009),
Link
Feature
Similarity
(Rossi & Neville, 2010)
Link Aggregations (Kahanda
& Neville, 2009)

?

Graph Features (Lichtenwalter, Lussier, & Chawla, 2010)

?

?
?

?

Betweenness (Freeman, 1977),
Closeness (Sabidussi, 1966)

?

HITs (Kleinberg, 1999), Prob.
HITs (Cohn & Chang, 2000),
SimRank (Jeh & Widom, 2002)
PageRank (Page, Brin, Motwani, & Winograd, 1999), Topical PageRank (Haveliwala, 2003;
Richardson & Domingos, 2002)
LDA (Blei et al., 2003), PLSA
(Hofmann, 1999),
Node
Classification
via
Stacked Model (Kou & Cohen, 2007) or RN (Macskassy &
Provost, 2003)

?

?
?

?
?

Construction
?

Spectral Clustering (Neville
& Jensen,
2005),
MixedMembership
Relational
Clustering (Long et al., 2007)
LDA (Blei, Ng, & Jordan, 2003),
PLSA (Hofmann, 1999),
Hierarchical Clustering via
Edge-betweenness (Newman &
Girvan, 2004)

MLN Structure Learning (Kok
& Domingos, 2009, 2010)
Database
Query
Search
(Popescul et al., 2003b), RPT
(Neville, Jensen, Friedland, et al.,
2003)
FOIL, nFOIL (Landwehr, Kersting, & De Raedt, 2005), kFOIL
(Landwehr, Passerini, De Raedt,
& Frasconi, 2010), Aleph (Srinivasan, 1999),

Table 1: Summary of Techniques: A summary of prominent graph transformation techniques for the tasks of predicting the existence of nodes and links and interpreting
them by weighting, labeling, and constructing general features.

373

fiRossi, McDowell, Aha, & Neville

Symbol

Description

G

Initial graph

G

Transformed graph

E

Initial link set

V

Initial node set

E

Initial set of link features

V

Initial set of node features

X
X

XkE
XkV
xeij
xvi
Other symbols
A
(vi )


Initial link feature k (XkE XE ) (for one feature, values for all links)
Initial node feature k (XkV XV ) (for one feature, values for all nodes)
Initial feature vector for eij (for one link, values for all link features)
Initial feature vector for vi (for one node, values for all node features)
Description
Adjacency matrix of the graph
Neighbors of vi
Cut-off value

Table 2: Summary of Notation used in this Survey: The top half of the table shows
symbols that are sometimes written with a tilde on top of the symbol, indicating
the result of some transformation. For conciseness, the table demonstrates this
notation only for G and G.

e.g., between an initial node vi  V and a predicted node vj  V . Thus, this task may also
produce a modified link set E.
Definition 2.4 (Node Interpretation) Given the nodes V , observed links E and/or the
feature set X = (XE , XV ), the node interpretation task is defined as the creation of a new
/ XV . As with link interpretation, the values of XkV may be
node feature XkV where XkV 
estimated for only some of the nodes. The node feature XkV could represent node weights,
labels, or other general features.
Section 2.2 introduced the notion of a non-relational feature, which is a node feature
XkV that can be constructed without making use of the links (i.e., without using E or XE ).
Such features are sometimes referred to in other articles as attributes or intrinsic features.
Other important terms can also be referred to in multiple different ways. To aid the reader,
Table 2.4 summarizes the key synonyms for the terms that are found most often in the
literature.

3. Link Prediction
This section focuses on predicting the existence of links while Section 4 considers link
interpretation. Given the initial graph G = hV, E, XV , XE i, we are interested in creating
a modified link set E, usually through the prediction of new links that were not present
374

fiTransforming Graph Data for Statistical Relational Learning

Term

Potential synonyms

Nodes

Vertices, points, objects, entities, individuals, users, constants, ...

Links

Edges, relationships, ties, arcs, events, interactions, predicates

Topology

Link/network/graph structure, relational information

Features

Attributes, variables, co-variates, queries, predicates, ...

Graph Measures

Topology-based metrics (such as proximity, centrality, betweenness, ...)

Similarity

Distance (the inverse of similarity), likeness

Clusters

Classes, communities, groups, roles, topics

Non-relational Features

Intrinsic attributes/features, local attributes/features, ...

Relational Features

Features, link-based features, graph features, aggregates, queries, ...

Structure Learning

Feature generation/construction, hypothesis learning

Parameter Learning

Model selection, function learning

Table 3: Synonyms in the Literature: A summary of possible synonyms found in the
literature for important terms related to relational data.

in E. This task can be motivated in several ways. For instance, there may be a need
to predict missing links that are not present in E because of incomplete data collection
or other problems. Similarly, we may be interested in predicting hidden links, where we
assume that there exists some unobservable interactions and the goal is to discover and
model these interactions. For example, in a network representing criminals or terrorist
activity, we may seek to predict a link between two people (nodes) that are not directly
connected but whose actions share some common motivation or cause. For both missing
and hidden links, predicting such links may improve the accuracy of a subsequent learned
model. Alternatively, we may seek to predict future links in an evolving network, such as
new friendships or connections that will be formed next year. We might also be interested in
predicting links between objects that are spatially related. Finally, we may wish to predict
beneficial links, for instance, predicting pairs of individuals that are likely to be successful
working together.
Figure 3 summarizes one general approach that is often used for these link prediction
tasks. In summary, scores or weights are computed for every pair of nodes in the graph, as
shown in Figure 3(b). Predicted links with a weight greater than some threshold , along
with the original links, are used to create the new link set E + (shown in Figure 3(e)). (At
this step, original links with very low weight could also be deleted if appropriate.) As a
final step, the weights of the predicted links are often discarded, yielding a new graph with
uniform link weights as shown in Figure 3(f).
The key challenge in this approach is how to compute a weight or score for each possible
link. The information used for this computation provides a natural way to categorize
the link prediction techniques. Below, Section 3.1 describes techniques that use only the
non-relational features of the nodes (ignoring the initial links), while Section 3.2 describes
topology-based techniques that use only the graph structure (i.e., the links or relations).
375

fiRossi, McDowell, Aha, & Neville

(a) Initial Graph G = hE, V i

(b) Weighted Links wij  E

(c) Predicted Links (E  E)

(d) Pruning Predicted Links
(E > )

(e) E + := E > + E

(f) E + with Uniform Link
Weights

Figure 3: Example Demonstrating a General Approach to Link Prediction:
The initial graph (a) is used as input to a link predictor, yielding a complete
graph (b) where the weights wij are estimated between all pairs of nodes. The
next step shows the removal of the initial (observed) links from consideration (c),
followed by a pruning of all predicted links with a weight below some cut-off value
 (d). The remaining predicted links are then combined with the initial links (e).
Often, the estimated weights on the initial and predicted links are then discarded,
leaving a uniform weight graph (f).

Finally, Section 3.3 describes hybrid techniques that exploit both the node features and the
graph structure.
3.1 Non-relational (Feature-Based) Link Prediction
In this section, we consider link predictors that do not exploit the graph structure or relational features derived using the graph structure. We are given an arbitrary pair of nodes
376

fiTransforming Graph Data for Statistical Relational Learning

vi and vj from the graph such that each node is represented by a feature vector xvi and
xvj , respectively. Feature-based link prediction is defined as using an arbitrary similarity
measure S(xvi , xvj ) as a means to estimate the likelihood that a link should exist between vi
and vj . Typically, a link is created if the similarity exceeds some fixed cut-off value; another
strategy is to predict links among the n% of all such node pairs with highest similarity.
A traditional approach is to simply define a measure of similarity between two objects,
possibly based on knowledge of the application and/or problem-domain. There are many
similarity metrics that have been proposed such as mutual information, cosine similarity,
and many others (Lin, 1998). For instance, Macskassy (2007) represents the textual content
of each node as a feature vector and uses cosine similarity to create new links between nodes
in a graph. Macskassy showed that the combination of the initial links with the predicted
text-based links increased classification accuracy compared to using only the initial links
or the text-based links. In addition to leveraging textual information to predict links, we
might use any arbitrary set of features combined with a proper measure of similarity for
link prediction. For instance, many recommender systems implicitly predict a link between
two users based on the similarity between their ratings of items such as movies or books
(Adomavicius & Tuzhilin, 2005; Resnick & Varian, 1997). In this case, cosine similarity or
correlation are commonly used as similarity metrics.
Alternatively, a similarity measure can be learned for predicting link existence. The link
prediction problem can be transformed into a standard supervised classification problem
where a binary classifier is trained to determine the similarity between two nodes based on
their feature vectors. One such approach from the work of Hasan et al. (2006), who have used
Support Vector Machines (SVMs) for link prediction and found that a non-relational feature
(keyword match count) was most useful for predicting links in a bibliographic network.
There are many link prediction approaches (Taskar et al., 2003; Getoor, Friedman, Koller,
& Taskar, 2003) that apply traditional machine learning algorithms. However, most of them
use features based on the graph structure as well as the non-relational features that are the
focus of this section. Thus, we discuss such techniques further in Section 3.3.
Finally, variants of topic models can be used for link prediction. These types of models
traditionally use only the text from documents (non-relational information) to infer a mixture of latent topics for each document. Inter-document topic similarity can then be used as
a similarity metric for link prediction (Chang & Blei, 2009). However, because many topic
models are capable of performing joint transformation of the nodes and links, we defer full
discussion of such techniques to Section 7.
3.2 Topology-Based Link Prediction
Topology-based link prediction uses the local relational neighborhood and/or the global
graph structure to predict the existence of unobserved links. Table 3.2 summarizes some
of the most common metrics that have been used for this task. Below, we discuss many of
these approaches, starting from the simplest local metrics and moving to the more complex
techniques based on global measures and/or supervised learning. For a systematic study of
many of these approaches applied to social network data, see the work of Liben-Nowell and
Kleinberg (2007).
377

fiRossi, McDowell, Aha, & Neville

Local Node Metrics

Description

Common Neighbors

Number of common neighbors between x and y, w(x, y) = |(x)(y)| (Newman,
2001a)

Jaccards Coefficient

Probability that x and y share common neighbors (normalized),
|(x)(y)|
(Jaccard, 1901; Salton & McGill, 1983)
|(x)(y)|

Adamic/Adar

Similar toPcommon neighbors, but assigns more weight to rare neighbors,
1
w(x, y) = z(x)(y) log |(z)|
(Adamic & Adar, 2001)

RA

Essentially equivalent to Adamic/Adar if |(z)| is small,
P
1
w(x, y) = z(x)(y) |(z)|
(Zhou, Lu, & Zhang, 2009)

Preferential Attachment

Probability of a link between x and y is the product of the degree of x and y,
w(x, y) = |(x)|  |(y)| (Barabasi & Albert, 1999)

Cosine Similarity

|(x)(y)|
w(x, y) = 

(Salton & McGill, 1983)

Sorensen Index

w(x, y) =

(Green, 1972; Zhou et al., 2009)

Hub Index

Nodes with large degree are likely to be assigned a higher score,
w(x, y) =

|(x)||(y)|
2|(x)(y)|
|(x)|+|(y)|

|(x)(y)|
min{|(x)|,|(y)|}

w(x, y) =

(Ravasz, Somera, Mongru, Oltvai, & Barabasi, 2002)
|(x)(y)|
max{|(x)|,|(y)|}

(Ravasz et al., 2002)

Hub Depressed Index

Analogous to Hub Index, w(x, y) =

Leicht-Holme-Newman

Assigns large weight to pairs that have many common neighbors, normalized
|(x)(y)|
by the expected number of common neighbors, w(x, y) = |(x)||(y)| (Leicht,
Holme, & Newman, 2006)

Global Graph Metrics

Description

Graph Distance

Length of the shortest path between x and y

Katz

Number of all paths between x and y, exponentially damped by length thereby
assigning more weight to shorter paths, w(x, y) = [(I  A)1 ]xy (Katz, 1953)

Hitting time

Number of steps required for a random walk starting at x to reach y (Brightwell
& Winkler, 1990)

Commute Time

Expected number of steps to reach node y when starting from x and then returning
+
+
back to x, defined as w(x, y) = L+
xx + Lyy  2Lxy where L is the Laplacian matrix
(Gobel & Jagers, 1974)

Rooted PageRank

Similar to Hitting time, but at each step there is some probability that the random
walk will reset to the starting node x, w(x, y) = [(IP)1 ]xy where P = D1 A
(Page et al., 1999)

SimRank

x and y are similar to the extent that they are joined with similar neighbors,
P

w(x, y) =

P

v(y) sim(u,v)
|(x)||(y)|

u(x)

(Jeh & Widom, 2002)

K-walks

Number of walks of length k from x to y, defined as w(x, y) = [Ak ]xy

Meta-Approaches

Description

Low-rank Approximation

Compute the rank-k matrix Ak that best approximates A (hopefully reducing
noise), then compute similarity over Ak using some local or global metric
(Eckart & Young, 1936; Golub & Reinsch, 1970)

Unseen Bigrams

Compute initial scores using some local or global metric, then augment the scores
w(x, y) using values from w(z, y) for nodes z that are similar to x (Essen &
Steinbiss, 1992; Lee, 1999)

Clustering

Compute initial scores using some local or global metric, discard links with the
lowest scores, and then re-compute the scores on the modified graph (Johnson,
1967; Hartigan & Wong, 1979)

Table 4: Topology Metrics: Summary of the most common metrics for link prediction.
Notation: Let (x) be the neighbors of x and A be the adjacency matrix of G.
378

fiTransforming Graph Data for Statistical Relational Learning

3.2.1 Metrics Based on the Local Neighborhood of Nodes
The simplest approaches use only the local neighborhood of nodes in a graph to devise a
measure of topology similarity, then use pairwise similarities between nodes to predict the
most likely links. As shown in Table 3.2, there are numerous such metrics, often based
on the number of neighbors that two nodes share in common, with varying strategies for
normalization.
Zhou et al. (2009) compares nine such local similarity measures on six datasets and finds
that the simplest link predictor, common neighbors, performs the best overall. They also
propose a new metric, RA, that outperforms the initial nine metrics on two of the datasets.
This new metric is very similar to the Adamic/Adar metric, but uses a different normalization factor that yields better performance in networks with higher average degree. They
also propose a method that uses additional two-hop information to avoid degenerate cases
where links are assigned the same similarity score. Their results highlight the importance
of selecting the appropriate metrics for specific problems and datasets. In another related
investigation, Clauset, Moore, and Newman (2008) evaluate a hierarchical random graph
predictor against local topology metrics such as common neighbors, Jaccards coefficient and
the degree product on three types of networks: a metabolic, ecology and a social network.
They find that a baseline measure based on shortest paths performs best for the metabolic
network, where the relationships are more homogeneous, but that their hierarchical metric
performs best when the links create more complex relationships, as in the predator-prey
relationships found in the ecology network.
Liu and Lu (2010) proposed a local random-walk algorithm as an efficient alternative to
the global random-walk predictors for large networks. This method is evaluated alongside
other metrics (i.e., common neighbors, local paths, RA, and a few random-walk variants)
and shown to perform better on most of the networks and more efficiently than the global
random-walk models.
3.2.2 Metrics Based on the Global Graph Structure
More sophisticated similarity metrics are based on global graph properties, often involving
some weighted computation based on the number of paths between a pair of nodes. For
instance, the Katz measure (1953) counts the number of paths between a pair of nodes,
where shorter paths count more in the computation. Rattigan and Jensen (2005) demonstrated that even this fairly simple metric could be effective for the task of anomalous link
prediction, which is the identification of statistically unlikely links from among the links
in the initial graph.
A related measure is the hitting time metric, which is the average number of steps
required for a random walk starting at node x to reach node y. Gallagher et al. (2008)
use such random walks with restart to estimate the similarity between every pair of nodes.
They focus on sparsely labeled networks where unlabeled nodes may have only a few labeled
nodes to support learning and/or inference in relational classification. The prediction of
new links improves the flow of information from labeled to unlabeled nodes, leading to an
increase in classification accuracy of up to 15%. Note that adding teleportation probabilities
to this random walk approach roughly yields the PageRank algorithm which is said to be
at the heart of the Google search engine (Page et al., 1999).
379

fiRossi, McDowell, Aha, & Neville

The SimRank metric (Jeh & Widom, 2002) proposes that two nodes x and y are similar
if they are linked to neighbors that are similar. Interestingly, they show that this approach
is equivalent to a metric based on the time required for two backwards, random walks
starting from x and y to arrive at the same node. As with the other approaches based
on random walks, this metric could be computed via repeated simulations, but is more
efficiently computed via a recursive set-point approach.
3.2.3 Meta-approaches and Supervised Learning Approaches
The metrics above can be modified or combined in multiple ways. Liben-Nowell and Kleinberg (2007) consider several such meta-approaches that use some local or global similarity
metric as a subroutine. For instance, the metrics discussed above can each be defined in
terms of an arbitrary adjacency matrix A. Given this formulation, we can imagine first
computing a low-rank approximation Ak of this matrix using a technique such as singular
value decomposition (SVD), and then computing a local or global graph metric using the
modified Ak . The idea is that Ak retains the key structure of the original matrix, but noise
has been reduced. Liben-Nowell and Kleinberg also propose two other meta-approaches
based on removing spurious links suggested by a first round of similarity computation (the
clustering approach) or based on augmenting similarity scores for a node x based on the
scores for other nodes that are similar to x (the unseen bigrams approach). They compare the performance of these three meta-approaches vs. multiple local and global metrics
on the task of predicting future links in a social network. The Katz measure and metaapproaches based on clustering and low-rank approximation perform the best on three of the
five arXiv datasets, but simple local measures such as common neighbors and Adamic/Adar
also perform surprisingly well.
Supervised learning methods can also be used to combine or augment the similarity
metrics that we have discussed. For instance, Lichtenwalter et al. (2010) investigate several
supervised methods for link prediction in sparsely labeled networks, using many of the metrics from Table 3.2. These metrics are used as features in simple classifiers such as C4.5,
J48, and naive Bayes. They find the supervised approach leads to a 30% improvement in
AUC over the simple unsupervised link prediction metrics. Similarly, Kashima and Abe
(2006) propose a supervised probabilistic model that assumes that a biological network
has evolved over time, and uses only topological features to estimate the model parameters. They evaluate the proposed method on protein-protein and metabolic networks and
report increased precision compared to simpler metrics such as Adamic/Adar, Preferential
Attachment, and Katz.
3.2.4 Discussion
In general, the local topology metrics sacrifice an amount of accuracy for computational
gains while the global graph metrics may perform better but are costly to estimate and
infeasible on huge networks. Where appropriate, supervised methods that combine multiple
local metrics may offer a promising alternative. The next subsection discusses additional
work on link prediction that has used supervised methods.
Link prediction using these metrics is especially sensitive to the characteristics of the
domain and application. For instance, many networks in biology, where the identification of
380

fiTransforming Graph Data for Statistical Relational Learning

links is costly, contain missing or incomplete links, while the removal of insignificant links is
a more significant issue for social networks. For that reason, researchers have analyzed and
proposed many different metrics when working in the domains of web analysis (Kleinberg,
1999; Broder et al., 2000), social network analysis (Zheleva, Getoor, Golbeck, & Kuter,
2010; Xiang et al., 2010; Koren, North, & Volinsky, 2007), citation analysis (Borgman &
Furner, 2002), ecology communities (Zhou et al., 2009), biological networks (Jeong et al.,
2000), and many others (Barabasi & Crandall, 2003; Newman, 2003).
3.3 Hybrid Link Prediction
In this subsection, we examine approaches that perform link prediction using both the
attributes and the graph topology. For such approaches, there are two key questions. First,
what kinds of features should be used? Second, how is the information from multiple
features combined into a single measure or probability to be used for prediction?
We first consider the mix of non-relational and relational features that should be used.
As expected, the best features vary based on the domain and specific network. For instance,
Taskar et al. (2003) studied link prediction for a network of web pages and found that simple
local topology metrics (which they called transitivity and similarity) were more important
than non-relational features based on the words presents in the pages. Similarly, Hasan
et al. (2006) found that another topology metric (shortest distance) was the most useful for
predicting co-authorship links in a bibliographic network based on DBLP.
If only a single metric/feature, such as hitting time, will be used for link prediction,
then we must ensure that the metric works well for all nodes and yields a consistent ranking.
However, if multiple feature values will be combined in some way, then it may be more
acceptable to use a wider range of features, especially if a supervised learner will later select
or weight the most important features based on the training data. Thus, hybrid systems
for link prediction tend to have a more diverse feature set. For instance, Zheleva et al.
(2010) propose new features based on combining two different kinds of networks (social
and affiliation networks). Features based on the groups and topology are constructed from
the combined network and are used along with descriptive non-relational features, yielding
an improvement of 15-30% compared to a system without the combined-network features.
A second example of more complex features is provided by Ben-Hur and Noble (2005),
who design a new pairwise kernel for predicting links between proteins (protein-protein
interactions). The pairwise kernel is a tensor-product of two linear kernels on the original
feature space, and is especially useful in domains where two nodes might have only a few
common features. This approach has also been applied for user preference prediction and
recommender systems (Basilico & Hofmann, 2004). Vert and Yamanishi (2005) propose
a related approach, where supervised learning is used to create a mapping of the original
nodes into a new euclidean space where simple distance metrics can then be used for link
prediction.
Given the great diversity of possible features for link prediction, an interesting approach
is a system that automatically searches for relevant features to use. For example, Popescul,
Popescul, and Ungar (2003a) propose a unique link prediction approach that systematically
generates and searches over a space of relational features to learn potential link predictors. They use logistic regression for link prediction and consider the search space covering
381

fiRossi, McDowell, Aha, & Neville

equi-joins, equality selections, and aggregation operations. In their approach, the model selection algorithm continues to add one feature at a time to the model as long the Bayesian
Information Criterion (BIC) score over the training set can be improved. They find that the
search algorithm discovers a number of useful topology-based features, such as co-citation
and bibliographic coupling, as well as more complex features. However, the complexity of
searching a large feature space and avoiding overfitting present challenges.
We next consider the second key question: how should the information from multiple
features be combined into a single measure to be used for link prediction? Most prior
work has taken a supervised learning approach, where both non-relational and topologybased metrics are used as features that describe each possible link. As with the supervised
techniques discussed in Section 3.2, a model is learned from training data which can then
be used to predict unseen links.
Most of these supervised approaches apply the classifier separately to each possible link,
using a classifier such as a support vector machine, decision tree, or logistic regression
(Popescul et al., 2003a; Ben-Hur & Noble, 2005; Hasan et al., 2006). In these approaches,
a flat feature representation for each link is created, and the prediction made for each
possible link is independent of the other predictions.
In contrast, early work on Relational Bayesian Networks (RBNs) (Getoor et al., 2003)
and Relational Markov Networks (RMNs) (Taskar et al., 2003) involved a joint inference
computation for link prediction, where each prediction could be influenced by nearby link
predictions (and sometimes also by newly predicted node labels). Using a webpage network
and a social network, Taskar et al. demonstrated that joint inference using belief propagation could improve accuracy compared to the independent inference approach. However, this
approach is computationally intensive, and they noted that getting the belief propagation
algorithm to converge was a significant problem. A possible solution to this computational
challenge is the simpler approach presented by Bilgic, Namata, and Getoor (2007). Their
method involved repeatedly predicting labels for each node, predicting links between the
nodes using all available features (including predicted labels), then re-predicting the labels
with the new links, and so forth. The link prediction was based on an independent inference
step using logistic regression, as with the simpler approaches discussed above. However, the
repeated application of this step allows the possibility of link feature values changing in
between iterations based on the intermediate predictions, thus allowing link predictions to
influence each other.
Recently, Backstrom and Leskovec (2011) proposed a novel approach that is supervised,
but where the final predictions are based on a random walk rather than directly on the
output of some learned classifier. Given a particular target node v in a social network,
along with nodes that are known to link to v, they study how to predict which other
links from v are likely to arise in the future (or should be recommended). They define
a few simple link features based on node profile similarity and messaging behavior, then
use these features to estimate initial link weights. They show how to learn these weights
(or transition probabilities) in a manner that optimizes the likelihood that a subsequent
random walk, starting at v, will arrive at nodes already known to link to v. Because the
random walk is thus guided by the links that are already known to exist, they call this
process a supervised random walk. They argue that this learning process greatly reduces
the need to manually specify complex graph-based features, and show that it outperforms
382

fiTransforming Graph Data for Statistical Relational Learning

other supervised approaches as well as unsupervised approaches such as the Adamic/Adar
measure.
A final approach for link prediction is to use some kind of unsupervised dimensionality
reduction that yields a new matrix that in some way reveals possible new links. For instance,
Hoff, Raftery, and Handcock (2002) propose a latent space approach where the initial link
information is projected into a low-dimensional space. Link existence can then be predicted
based on the spatial representation of the nodes in the new latent space. These models
perform a kind of factorization of the link adjacency matrix and thus are often referred to
as matrix factorization techniques. An advantage of such models is that the spatial representation enables simpler visualization and human interpretation. Related approaches have
also been proposed for temporal networks (Sarkar & Moore, 2005), for mixed-membership
models (Nowicki & Snijders, 2001; Airoldi, Blei, Fienberg, & Xing, 2008), and for situations
where the latent vector representing each node is usefully constrained to be binary (Miller,
Griffiths, & Jordan, 2009). Typically, these models have the capability of including the
attributes as covariates that affect the link prediction but are not directly part of the latent
space representation. However, Zhu, Yu, Chi, and Gong (2007) demonstrated how such attributes can also be represented in a related but distinct latent space. More recently, Menon
and Elkan (2011) showed how a matrix factorization technique for link prediction can scale
to much larger graphs by training with stochastic gradient descent instead of MCMC.
3.4 Discussion
Link prediction remains a challenge, in part because of the very large number of possible
links (i.e., N 2 possible links given N observed nodes), and because of widely varying data
characteristics. Depending on the domain, the best approach may use only a single nonrelational metric or topology metric, or it may use a richer set of features that are evaluated
by some learned model. Future work may also wish to consider using an ensemble of link
predictors to yield even better accuracy.
Our discussion of link prediction has focused on predicting new links based on existing
links and properties of the nodes. In the context of the web, however, link prediction
has sometimes taken other forms. For instance, Sarukkai (2000) used web server traces to
predict the next page that a user will visit, given their recent browsing history. In particular,
they use Markov chains, which are related to the random walks discussed in Section 3.2,
for this task that they also call link prediction. More recently, DuBois and Smyth (2010)
model relational events (i.e., links) using latent classes where each event/link arises from
a latent class and the properties of the event (i.e. sender, receiver, and type) are chosen
from distributions over the nodes conditioned on the assigned class. In this work, the local
community of a node influences the distribution computed for each node, in a way related
to the computations of stochastic block modeling (Airoldi et al., 2008). DuBois & Smyths
task is also a form of link prediction, but where the goal is not to predict the presence or
absence of a static link, but the frequency of occurrence for each possible event/link.
One might also be interested in deleting or pruning away noisy, less informative links.
For instance, friendship links in Facebook are usually extremely noisy since the cost of
adding friendship links is insignificant. Most of the techniques used in this section could
383

fiRossi, McDowell, Aha, & Neville

also be used to remove existing links wherever the link prediction algorithm yields a very
low score (or weight) for an observed link in the original graph.
Indeed, since most link prediction algorithms effectively assign a score to every possible
link, they could also be used to assign a weight to just the set of initial links in G. This
link weighting is one of the three subtasks of link interpretation shown in the taxonomy
of Figure 2. However, in practice if weights are needed only for the initial links, different
features and algorithms will often be possible and/or more effective. The next section
discusses such link weighting algorithms, as well as link interpretation in general. Also,
in Section 7 we discuss some additional methods for link prediction that seek to jointly
transform both nodes and links.

4. Link Interpretation
Link interpretation is the process of constructing weights, labels, or general features for the
links. These three tasks of link interpretation are related and somewhat overlapping. First,
link weighting is the task of assigning some weight to each link. These weights may represent
the relevance or importance of each link, and are typically expressed as continuous values.
Thus the weights provide an explicit order over the links. Second, link labeling is similar,
except that it usually assigns discrete values to each link. This could represent a positive
or negative relationship, or could be used, for instance, to assign one of five topics to email
communication flows. Finally, link feature construction is the process of generating a set of
discrete or continuous features for the links. For instance, these features might count the
frequency of particular words that appeared in messages between the two nodes connected
by some link, or simply count the number of such messages.
In a sense, link feature construction subsumes link weighting and labeling, since the
weights and labels can be viewed simply as possible link features to be discovered. However, for many tasks it makes sense to compute one particular feature that summarizes the
relevance of each link (the weight) and/or one particular feature that summarizes the type
of each link (the label). Such weights and labels may be especially useful to later processing, for example with collective classification. Moreover, the techniques used for general
feature construction tend toward simpler approaches such as aggregation and discretization, whereas the best techniques for computing weights and labels may involve much more
complexity, including global path computations or supervised learning. For this reason, we
treat link weighting (Section 4.1) and link labeling (Section 4.2) separately from general
link feature construction (Section 4.3).
4.1 Link Weighting
Given the initial graph G = hV, E, XV , XE i, the task is to assign a continuous value (the
weight) to each existing link in G, representing the importance or influence of that link. As
previously discussed, link weighting could potentially be accomplished by applying some link
prediction technique and simply retaining the computed scores as link weights. For instance,
Lassez, Rossi, and Jeev (2008) perform link prediction and weighting by applying singular
value decomposition to the adjacency matrix, then retaining only the k most significant
singular-vectors (similar to the low-rank approximation techniques discussed in Section 3.2).
384

fiTransforming Graph Data for Statistical Relational Learning

They show that querying (e.g., with PageRank) on the resultant weighted graph can yield
more relevant results compared to an unweighted graph.
Unlike with link prediction, however, most link weighting techniques are designed to
work only with links that already exist in the graph. These techniques dont work for
predicting unseen links because they weight links based on known properties/features of
the existing links, or because they compute some additional link features that only yield
sensible results for links that already exist.
In the simplest case, link weighting can be just aggregating an intrinsic property of links.
For example, Onnela et al. (2007) defines link weights based on the aggregated duration of
phone calls between individuals in a mobile communication network. In other cases, simply
counting the number of interactions between two nodes may be appropriate.
Thus, when link features like duration, direction, or frequency are known, they can be
aggregated in some way to generate link weights. If actual link weights are already known
for some of the links, then supervised methods can be used for weight prediction, using
the known weights as training data. For instance, Kahanda and Neville (2009) predict link
strength within a Facebook dataset, where stronger relationships are identified based on
a users explicit identification of their top friends via a popular Facebook application.
Gilbert and Karahalios (2009) also predict link strength for Facebook, but form their training data from survey data collected from 35 participants (yielding strength ratings for about
2000 links). Both of these algorithms generate a large number (50-70) of features about
each link in the network, then learn a predictive model via regression or some other technique such as bagged decision trees, which Kahanda and Neville finds performs best among
several alternatives. Gilbert and Karahalios generate features based on profile similarity
(e.g., do two users have similar education levels?) and based on user interactions (e.g.,
how frequently and about what topics do two users communicate?). They find the interaction features to be most helpful, especially a feature based on the number of days since
the last communication event. Kahanda and Neville use similar kinds of features, which
they term attribute-based and transactional features, and also add topological features (such
as the Adamic/Adar discussed in Section 3.2) and network-transactional (NTR) features.
NTR features are those that are based on communications between users (e.g., the number
of email messages exchanged) but moderated in some way by the larger network context.
This moderation often takes the form of normalization, for instance to dampen the influence
of a node that has sent a large number of messages to many different friends. They find
that these NTR features are by far the most helpful for prediction, but that many other
features also contribute to the overall predictive accuracy.
When training data with sample link weights is not available, approaches based on a
parameterized probabilistic model are still possible. However, since candidate link features
can no longer be evaluated against the training data, these approaches must (manually)
choose the features that they use much more carefully. For instance, Xiang et al. (2010)
examine link weight prediction on two social network datasets (Facebook and LinkedIn), but
use only 5-11 features for each link. They hypothesize that relationship strength is a hidden
cause of user interactions, and propose a link-based latent variable model to capture this
dependence. For inference, they use a coordinate ascent optimization procedure to predict
the strength of each link. Since the actual strength of each link is not known, prediction
tasks in this domain cannot directly evaluate accuracy. However, Xiang et al. demonstrate
385

fiRossi, McDowell, Aha, & Neville

that using the link strengths produced by their method leads to higher autocorrelation and
higher collective classification accuracy when predicting user attributes such as gender or
relationship status.
A number of researchers have considered the importance of recency in evaluating link
weight, under the assumption that events or interactions that occurred more recently should
have more weight. For instance, Roth et al. (2010) propose the Interactions Rank metric
for weighting a link based on the messages between two nodes. The formula separately
weights incoming and outgoing messages for each link, and imposes an exponential decay
on the importance of each message based on how old it is. Roth et al. use this metric to
weight the links in what they call the implicit social network, where each node represents
a group of users. They demonstrate that this metric can be used to accurately predict users
that are missing from an email distribution list. However, the basic metric is simple to
compute and could be applied to many other tasks.
The Interactions Rank metric weights a link more heavily if it connects two nodes that
have frequently and/or recently communicated. Alternatively, Sharan and Neville (2008)
have considered how to weight links in a graph where the links (such as hyperlinks or
friendships) may themselves appear or disappear over time. In particular, they construct a
summarized graph where all nodes and links that have ever existed in the past are present.
Each link in this new graph is weighted based on a kernel function that can provide more
weight to links that have been present more often or more recently in the past. They explain
how to modify standard relational classifiers to use these weighted links, and demonstrate
that a variety of kernels (including exponential and linear decay kernels) produce weighted
links that yield higher classification accuracy compared to a non-weighted graph. More
recently, Rossi and Neville (2012) have extended this work to handle time-varying attribute
values, which may serve as a basis for incorporating temporal dynamics into additional
tasks.
4.2 Link Labeling
Given the initial graph G = hV, E, XV , XE i, the task is to construct some discrete label for
one or more links in G. These labels can be used to describe the type of relationship that
each link represents. For instance, in the Facebook example, a link labeling algorithm may
create labels representing work or personal relationships. Such labels would enable
subsequent classification models to separately account for the influence of these different
kinds of relationships.
Most prior work on link labeling has assumed that some text (such as a message) describes each link, and has been based on unsupervised textual analysis techniques such
as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), Latent Semantic Analysis (LSA)
(Deerwester, Dumais, Furnas, Landauer, & Harshman, 1990), or Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999). Traditionally, these techniques have been used
to assign one or more latent topics to each document in a collection of documents. The
topics that are formed are defined implicitly by a probability distribution over how likely
each word is to appear, given that the topic is associated with a document. These topics
will not always be semantically meaningful, but often manual inspection reveals that most
prominent topics do represent sensible concepts such as advertising or government re386

fiTransforming Graph Data for Statistical Relational Learning

lations. However, even when such semantic associations are not obvious, inferring such
topics for a set of links can still aid further analysis, since the topics identify which links
represent similar kinds of relationships.
These textual analysis techniques were developed with independent documents in mind,
not inter-linked nodes, but they can be adapted to label links in several ways. For instance,
Rossi and Neville (2010) examined messages between developers contributing to an opensource software project. They treat each message as a separate document, and use LDA to
infer the single most likely latent topic for each message (i.e., a link label). This technique
could be used for any graph with textual content associated with the links. Rossi and Neville
also go further, to consider the impact of time-varying topics and time-varying topic/word
associations, by running multiple iterations of LDA, one per time epoch. Using this model,
they study the problem of predicting the effectiveness of different developers (nodes) in the
network. They demonstrate that the accuracy of predictions is significantly improved by
modeling the temporal evolution of the communication topics.
McCallum, Wang, and Corrada-Emmanuel (2007) describe an alternative way of extending LDA-like approaches for link labeling. LDA is essentially a Bayesian network that
models the probabilistic dependencies between documents, associated topics, and words associated with those topics. They propose to extend this model with the Author-RecipientTopic (ART) model, where the choice of topic for each document (message) depends on
both the author and the recipient of the message. Once parameters are learned for the
model, inference (e.g., with Gibbs sampling) can be used to infer the most likely latent
topics for each message. They make use of these topics to assign roles to people in an email
communication network, and demonstrate that it outperforms simpler models.
Supervised techniques can also be used for link labeling. For instance, Taskar et al.
(2003) study an academic webpage network and consider how to predict node labels (such
as Student or Professor) while simultaneously predicting link labels (such as adviserof). Given a labeled training graph, they learn a complex Relational Markov Network
(RMN) that can predict these labels and the existence of new links. To make the link
prediction tractable, only some candidate new links are considered, such as those links
suggested by a textual reference, inside a page, to some other entity in the graph. The
RMN utilizes text-based features, for instance based on the anchor text for known links
or the heading for the HTML section in which a possible link reference is found. They
demonstrate that the RMNs joint inference over nodes and links improves performance
compared to separate inference. However, learning and inference with RMNs can often be
a significant challenge, which in practice limits the number and types of feature that can
be considered.
The RMN approach learns from some training data and then uses joint inference over
the entire graph. A simpler supervised approach is to create a set of features for each link
and use these features for learning and inference with an arbitrary classifier that treats each
link separately. Leskovec, Huttenlocher, and Kleinberg (2010) study a particular form of
this approach where there are only two link labels, representing a positive or negative relationship (such as friendship vs. animosity). They create link features based on the (signed)
degree of the nodes involved in each link and also based on transitivity-like properties computed from the known labels of nearby links. They demonstrate this approach using data
from Epinions, Wikipedia, and Slashdot, where users have manually indicated positive or
387

fiRossi, McDowell, Aha, & Neville

negative relationships to other users. Given a network with almost all edges labeled, the
label classifier is able to predict the label (positive or negative) of a single unlabeled edge
with high accuracy. Interestingly, they show that a classifiers predictive accuracy for a
particular dataset decreases only slightly when the classifier is trained on a different dataset
vs. being trained on the same dataset that is used for predictions. They argue that theories
of balance and status from social psychology partially explain this ability of their predictive
models to generalize across datasets. Unlike most of the other techniques discussed in this
section, this work does not make use of text-based features. However, the general problem
of predicting the sign of a link is related to sentiment analysis (or opinion mining) in
natural language processing (Godbole, Srinivasaiah, & Skiena, 2007; Pang & Lee, 2008).
These sentiment analysis algorithms could be reformulated to predict the label (such as
positive or negative) of a link given its associated text.
Because a link between two nodes can be established based on many different kinds of
relationships, there are many other types of algorithms that could potentially be used for
labeling links, even if the original algorithm was not designed for this purpose. For instance,
Markov Logic Networks (MLNs) have been used to extract semantic networks from text,
yielding a graph where the nodes represent objects or concepts (Kok & Domingos, 2008).
This process produces relations such as teaches that or is written in between the nodes,
which could be used as link labels in further analysis. Another example is the Group-Topic
(GT) model proposed by McCallum, Wang, and Mohanty (2007), which, like the previously
mentioned ART model, is a Bayesian network. The model is intended for graphs where two
nodes (such as people) become connected when they both participate in the same event,
such as both voting yes for the same political bill. Rather than directly labeling links (like
ART), the GT model clusters these nodes (such as people) into latent groups based on
textual descriptions of the events/votes. However, the GT model also simultaneously infers
a set of likely topics for each event, which could be used to label the implicit links between
the nodes. The results of the model could also be used to add new nodes to the graph that
represent the latent groups that were discovered.
4.3 Link Feature Construction
Link feature construction is the systematic construction of features on the links, typically for
the purpose of improving the accuracy or understandability of SRL algorithms. Link feature
construction can be important for many prediction tasks, but has received considerably
less attention than node feature construction in the literature. Fortunately, many of the
computations that have been developed for node feature construction can also apply to link
features. To avoid redundancy, we defer most of our analysis of feature construction to the
discussion of node feature construction in Section 6.3. This section briefly discusses how
such techniques for node feature construction can be applied to links, then summarizes the
major types of link features that can be computed.
Section 6.3 will later describe how feature values for relational data are often based on
aggregating values from multiple nodes. For instance, such a feature might compute the
average or the most common feature value among all of the neighbors of a particular node.
Such aggregation-based features help to account for the varying number of neighbors that a
node may have. For links, aggregation is less essential, since (usually) each link has precisely
388

fiTransforming Graph Data for Statistical Relational Learning

(a) Before link-aggregation

(b) After link-aggregation

Figure 4: Link Feature Aggregation Example: The figure demonstrates how an unknown link feature value can be computed by aggregating the link feature values
of surrounding links. Here the aggregation operator is Mode.

two endpoint nodes. However, aggregation can still be useful for computing features that
collect information from a larger area of the graph. For instance, in Figure 4, a link feature
value is being computed for the link in the center of the subgraph (the target link). The
computation considers the feature values (positive or negative signs) for all of the links that
are adjacent to the target link. In this case, the aggregation operator is Mode, and the
result is the new link feature value. This example used link features as the input, but node
feature values (e.g., of the lightly-shaded nodes in Figure 4) could also be aggregated to
form a new link feature. In this way, all of the aggregation operators discussed for nodes in
Section 6.3 can also be applied to links.
Figure 5 summarizes the kinds of features that can be constructed for a link. This figure
is organized around the sources of information that go into computing a single link feature
(i.e., the inputs), rather than the details of the feature computation (such as the type of
aggregation or other function used). The bottom of the figure shows the four types of link
features, each represented by a subgraph. In each case, the emphasized link at the bottom
of the subgraph is the target link for which a new feature value is being computed. Each
of the subgraphs shows varying amounts of information because each displays only those
features, nodes, and/or links that can be used as inputs for that kind of link feature.
The simplest type is the non-relational link feature, which can be computed for each
link solely from information that is already known about that link. Thus, Figure 5A shows
only the feature values which are already known for the target link, which can be used to
construct a new feature value. For instance, if a message is associated with each link, then
a link feature could count the number of times that a certain word occurs, or the number
of distinct words. Alternatively, if a date is associated with the link, then a feature might
compute the number of months since the link was formed. Onnela et al. (2007) computed
this kind of feature when they aggregated the duration of all phone calls between two people
to form a new link feature (which they also used as a link weight).
The remaining feature types are all relational, meaning that they depend in some way
on the graph (not just a single link). First, topology features (Figure 5B) are those that
can be computed using only the topology of the graph. Such a feature might, for instance,
compute the total number of links that are adjacent to the target link. Likewise, Kahanda
and Neville (2009) computed the clustering coefficient of a pair of linked nodes, which
measures the extent to which the two nodes have neighbors in common (Newman, 2003), as
well as other topological features such as the Adamic/Adar measure discussed in Section 4.1.
389

fiRossi, McDowell, Aha, & Neville

input	 

V,E,XV,XE	 

target	 link	 

Link	 Feature	 	 
Construction	 
	 
E	 
X

link-value	 

p	 

V,E,XV,XE	 

node-value	 	 	 	 	 

L	 
Non-relational	 
Link	 Features	 

Relational	 Features	 

V,E	  V,E,XE	  V,E,XV	 
Topology	 
Features	 

Link-value	 
Features	 

Node-value	 
Features	 

C	 
p	 

w	 

C	 
L	 

w	 

L	 
A.	 

B.	 

	 E	 

C.	 

L	 
D.	 

X

Figure 5: Link Feature Taxonomy: The link feature classes are non-relational features,
topology features, relational link-value features, and relational node-value features.
In the subgraphs at bottom, only the information that is potentially used by
that class of link feature (i.e., nodes V , links E, node features X V , and/or link
features X E ) is shown. The emphasized link represents where the feature value
is computed (i.e., the target link).

They used these link features to help predict link strength, but they could also be used for
other tasks.
Next, relational link-value features are those that are computed using the feature values
of nearby links. For instance, Figure 5C shows how link labels of personal (p) or work
(w) might be identified from links adjacent to the target link. A new link feature could
be formed by representing the distribution of these labels, by taking the most common
label, or (when the link features are numeric) by averaging. Leskovec, Huttenlocher, and
Kleinberg (2010) used such link-value features when working with graphs where each link
had a sign feature of positive or negative (as with Figure 4). They computed features
based on the signed-degree of the two nodes connected by the target link as well as more
complex measures based on other paths between these two nodes (e.g., to measure sign
transitivity).
390

fiTransforming Graph Data for Statistical Relational Learning

Finally, relational node-value features are those that are computed using the feature
values of the nodes that are close to or are attached to the target link. For instance,
Figure 5D shows how node labels of conservative (C) or liberal (L) might be identified for
nodes close to the target link. As with link-value features, these labels could be used to
create a new feature value by summarization or aggregation. Often, only the two nodes
that are directly attached to the target link are used. For instance, both the work of Gilbert
and Karahalios (2009) and Kahanda and Neville (2009) construct link features based on the
similarity of two nodes social network profiles. However, the feature values of more distant
nodes could also be used, for instance to compute a new link feature based on how similar
the friends of two people (nodes) are.

5. Node Prediction
Node transformation includes node prediction (e.g., predicting the existence of new nodes)
and node interpretation (e.g., constructing node weights, labels, or features). This section
focuses on node prediction, while Section 6 considers node interpretation.
Given a graph with existing nodes V , node prediction can be used in two distinct ways.
First, a node prediction algorithm could be used to discover additional nodes that are of
the same type as those that are already present in V . For instance, given a set of people
that communicate via email, a simple algorithm might be used to create new nodes that
represent email recipients that are implied by the messages, but not explicitly represented in
the original graph. Alternatively, supervised or unsupervised machine learning techniques
could be used to discover, for instance, new research papers or people from information
available on the web (Craven et al., 2000; Cafarella, Wu, Halevy, Zhang, & Wang, 2008).
These techniques are valuable, and can certainly be used to add new nodes to a graph.
However, most such work has been examined in the context of general knowledge base
construction, rather than relational learning.4
We focus on the second type of node prediction, which involves predicting nodes of a
different type than those that are already present in the graph. These new nodes might
represent locations, communities (Kleinberg, 1999), roles (McCallum, Wang, & CorradaEmmanuel, 2007; Rossi, Gallagher, Neville, & Henderson, 2012), shared characteristics,
social processes (Tang & Liu, 2009; Hoff et al., 2002), functions (Letovsky & Kasif, 2003),
or some other kind of relationship. For instance, in the running Facebook example, a
newly discovered node may represent a common interest or hobby that multiple people
share. These nodes are usually referred to as latent nodes (and the nodes connected to
each such node form a latent group).5 The meaning of these nodes will depend upon
what features and/or links were included as input to the node prediction algorithm. For
instance, including work-based friendships will lead to very different groups than if only
personal friendships are considered.
4. The recent work of Kim and Leskovec (2011) is an exception. Their technique uses EM to infer the
existence of missing nodes and links based on only the known topology of the graph.
5. Prior work sometimes refers to such nodes as hidden nodes, especially when they are thought to
represent concrete characteristics, such as geographic location, that could be measured but were, for
some reason, not observed in the data.

391

fiRossi, McDowell, Aha, & Neville

Figure 6: Alternative Representations for Newly Predicted Groups: The left
figure shows how a new feature (with value X or Y) could be added to each node,
while the right figure demonstrates the creation of two new nodes to represent
the groups.

There are many advantages of this type of representation change with regards to accuracy and understandability. For instance, nodes that are not directly connected in the
original graph but are similar in some way become, because of the links to the new nodes,
closer in graph space. Intuitively, nodes connected to a high level concept should share some
latent properties and representing that latent structure can directly impact classification,
network analysis, and many other tasks. For instance, reducing the path length between
similar nodes enables influence from these nodes to propagate more effectively if collective
classification (CC) is performed on these nodes. A model can still learn about and exploit
these new nodes and relationships, even if the semantic meaning of the new nodes is not
precisely understood.
The most popular methods for predicting new nodes are based on clustering, which in
our context means the grouping of nodes such that nodes within a group are more similar
to each other than they are to the nodes in other groups. Typically, one new node is created
for each group, and then links are added between each existing node and its corresponding
group node (see right side of Figure 6). Some techniques may also associate each node with
multiple groups, with link weights representing the affinity to each group.
When new groups are discovered, whether via clustering or via some other technique, an
alternative to creating new nodes and links is to simply add new feature(s) to each node that
represent the group information. The left side of Figure 6 demonstrates this alternative.
For instance, a new node feature might represent having running as hobby, or it may simply
represent belonging to discovered group #17, which is of unknown meaning. Popescul and
Ungar (2004) use the CiteSeer dataset to demonstrate that this technique can derive features
that can improve predictive accuracy. An advantage of this approach, as opposed to adding
new nodes, is that it potentially enables simpler, non-relational algorithms to make use of
the new information. A potential disadvantage, though, is that it also does not allow for
algorithms such as CC to propagate influence between newly connected nodes, as discussed
above. However, some such methods use this general strategy to generate much larger
392

fiTransforming Graph Data for Statistical Relational Learning

numbers of latent features that can be used for classification (Tang & Liu, 2009; Menon &
Elkan, 2010). Tang & Liu demonstrate that, in some cases, the resultant large number of
link-based features may make collective inference unnecessary for obtaining good accuracy.
Naturally, whether the information discovered from these clusterings is best represented
via new nodes or new features will depend upon the dataset and the inference task. In
this section, for simplicity we will discuss each algorithm assuming that new nodes will be
created (even if the algorithm was originally described in terms of creating new features).
As with our discussion of link prediction, we organize our discussion around the kinds
of information that are used for prediction. Section 5.1 discusses non-relational (attributebased) node prediction, Section 5.2 discusses topology-based node prediction, and Section 5.3 discusses hybrid approaches that use both the node feature values and the topology
of the graph.
5.1 Non-relational (Attribute-Based) Node Prediction
There are many clustering algorithms that can be used to cluster existing nodes using only
their non-relational features (attributes), which can then be used to add new nodes to a
graph. The two primary types are hierarchical clustering algorithms (e.g., agglomerative or
divisive clustering) and partitioning algorithms such as k-means, k-medoids (Berkhin, 2006;
Zhu, 2006), EM-based algorithms, and self-organizing maps (Kohonen, 1990). We do not
discuss these algorithms further since they have been well studied for non-relational data
and can be easily applied to relational data if clustering based only on attribute values is
desired.
5.2 Topology-Based Node Prediction
The techniques described in this section link existing nodes to one or more new nodes (i.e.,
latent groups), based only on the original link structure of the graph. In most cases, finding
this grouping depends upon computing some kind of similarity metric between every pair
of nodes. Two key questions thus serve to identify these techniques. First, what kind
of similarity metric should be used? Second, how should the metric be used to predict
groupings? We address each question in turn.
5.2.1 Types of Metrics for Group Prediction
Any type of topology-based link weighting metric (see Table 3.2) could conceivably be used
for latent node prediction. A metric will be suitable so long as it produces high values
for pairs of nodes that should belong to the same group and lower values for other pairs.
For instance, a high value of the Katz metric (see Section 3.2) indicates that two nodes
have many short paths between them, and thus may belong to the same group. Metrics
representing distance rather than similarity can also be used after negating the metric. For
instance, Girvan and Newman (2002) focus on detecting community structure by extending
the concept of node-betweenness to links. Intuitively, if a network contains latent groups
that are only loosely connected by a few intergroup links, then all shortest paths between
different groups must go along these links. These links that connect the different groups
are assigned a high link-betweenness value (which corresponds to a low similarity value).
393

fiRossi, McDowell, Aha, & Neville

The underlying group structure can then trivially be revealed by removing the links with
highest betweenness.
This idea of using link-betweenness for relational clustering has been extended in a
number of directions. For instance, Newman and Girvan (2004) introduced random-walk
betweenness, which is the expected number of times that a random walk between a pair of
nodes will pass down a particular link. In addition, Radicchi, Castellano, Cecconi, Loreto,
and Parisi (2004) proposed using a link-based clustering coefficient metric. They showed
that this metric performs comparably to the original link-betweenness metric of Girvan and
Newman, but is much faster because it is a local graph measure instead of a global graph
measure.
Zhou (2003) describes a new metric, the dissimilarity index, which can be computed
as follows. For each node i, compute a vector di where each value dij represents the
distance from node i to node j (Zhou measures distance based on the average number of
steps needed for a random walk starting at node i to reach node j, but any distance metric
could be used). If nodes i and k are very similar, they should have very similar distance
vectors. Thus, the dissimilarity index for nodes i and k is defined based on a Euclidean-like
distance computation between vectors di and dk . Zhou demonstrates that this technique
outperforms the link-betweenness approach of Girvan & Newman for some random modular
networks.
Relatively simple metrics can often lead to useful results. For instance, Ravasz et al.
(2002) used a simple clustering coefficient metric to study metabolic networks. Their study
reveals that the metabolic networks of forty-three organisms are organized into many small,
highly-connected modules. Furthermore, they find that for E. coli, the hidden hierarchical
modularity closely overlaps with known metabolic functions.
5.2.2 Using the Metrics for Group Prediction
The simplest techniques for identifying new groups is to perform some kind of hierarchical
clustering. For instance, after similarities or weights have been computed for every pair of
nodes, all links can be removed from the graph. Next, the weighted links are placed between
the nodes one by one, ordered by their weights. The intuition is that varying degrees of
clusters are formed as more links are added. In particular, this approach forms a hierarchical
tree where the leaves represent the finest granularity of clustering where every node is a
separate cluster. As we move up the tree larger clusters are formed, until we reach the top
where all the nodes are joined in one large cluster. This type of hierarchical approach was
used in the work of Zhou (2003). Girvan and Newman (2002) use a similar strategy, but
start instead with the original graph and iteratively remove the less similar links from the
graph to reveal the underlying community structure. A challenge with these approaches,
as with clustering in general, is to select the appropriate number of final clusters, which
corresponds to selecting a level in the clustering tree.
Spectral clustering (Dhillon, 2001; Ng, Jordan, & Weiss, 2001; Kamvar, Klein, & Manning, 2003) can also be used for group identification. Spectral clustering relies upon computing a similarity matrix S that describes all the data points, then transforming the matrix
in a way that yields a new matrix U where clustering the rows of U using a simple clustering
algorithm (such as k-means) can trivially identify the interesting groups in the data. The
394

fiTransforming Graph Data for Statistical Relational Learning

matrix transformation has several variants, but involves computing some kind of Laplacian
of S, then computing the eigenvectors of the resultant matrix and using those eigenvectors to represent the original data. The motivation for this transformation can be seen
as identifying good graph cuts in the original graph (those that yield good separations of
highly-connected nodes into groups) or as identifying those nodes that are closely related
in terms of random walks; see the work of von Luxburg (2007) for an overview. Spectral
clustering was originally applied to non-relational data, but, as with the hierarchical techniques described above, it can be applied to relational data by using link-based metrics
for computing the similarity matrix. For instance, Neville and Jensen (2005) use the node
adjacency matrix and the spectral clustering technique described by Shi and Malik (2000)
to identify latent groups in their graphs. They show that this technique enables simpler
inference (since each group can be handled separately), and ultimately yields more accurate
classification compared to approaches that ignore the group structure. Tang and Liu (2011)
also use spectral clustering on the link graph, but do so in order to create a much larger
number of latent features that are then used to learn a supervised classifier. Unlike the
latent groups from the work of Neville and Jensen, this technique allows each node to be
associated with more than one cluster in the output of the spectral clustering, which Tang
& Liu claim leads to improved classification accuracy. Spectral clustering can also be used
with more complex similarity metrics, as described in the next subsection.
Techniques borrowed from web search can also be useful for node prediction. For instance, given the adjacency matrix A for a webpage graph, the Hits algorithm (Kleinberg,
1999) computes the first few eigenvectors of AAT and AT A, which represent the most
authoritative nodes (the authorities) as well as prominent nodes that point to them (the
hubs). Normally, this algorithm is used to find only the single most prominent community of authorities and hubs (to assist with a web search), but secondary communities can
be discovered by also considering the non-principal eigenvectors of AAT and AT A (Gibson, Kleinberg, & Raghavan, 1998). A node prediction algorithm could then treat each
such community as a latent group and add a new node and links to represent this group.
These techniques may be especially useful for detecting patterns of influence in a graph and
adding more explicit links to represent this influence.
5.3 Hybrid Node Prediction
The techniques in the previous section added new nodes to the graph, often based on
clustering, using only the topology of the graph. In principle, a technique that also used
the nodes attributes should produce more meaningful latent groups/nodes. This section
considers how to add such attribute information to techniques for node prediction.
A simple approach is to define some kind of similarity metric that combines nonrelational and topology-based similarity into a single value, then provide that similarity
metric to one of the previously mentioned clustering algorithms. For instance, Neville,
Adler, and Jensen (2004) use a weighted combination of attribute and link information
1X
S(i, j) =  
sk (i, j) + (1  )  l
k
k

as a metric, where sk (i, j) = 1 iff nodes i and j have the same value for the kth attribute,
and l = 1 iff a link exists between i and j. Here the constant  controls the relative
395

fiRossi, McDowell, Aha, & Neville

importance of the attributes vs. the links. They use this metric with the NCut spectral
clustering technique to add new nodes to the graph, and demonstrate that these additional
nodes increase the performance of relational classification. A similar weighted combination
of attribute and link-based similarity is used by Bhattacharya and Getoor (2005) for entity
resolution.
Attribute-based information can also be incorporated on an ad-hoc basis. For instance,
Adibi, Chalupsky, Melz, Valente, et al. (2004) describe a group finding algorithm where an
initial seed set of clusters is formed based on a handcrafted set of logical rules, and then
these clusters are refined using a probabilistic system based on mutual information. In their
system, the logic-based component primarily uses the attributes about each node (person),
while the probabilistic system primarily uses the links that describe connections between
the people. However, both components make some use of both attributes and links.
A more principled approach is to define some kind of generative model that represents
the dependence of the observed attributes and links on some latent group nodes, then use
that model to estimate group membership. For instance, Kubica, Moore, Schneider, and
Yang (2002) define a generative model where each node belongs to one or more groups, and
group members tend to link to each other. In particular, they use a group membership
chart to track whether each node belongs to each group, and do a local search over possible
states of the chart (using stochastic hill climbing) to try to identify membership changes
that would better explain the known data. At each step, maximum likelihood is used to
estimate the parameters of the model. They demonstrate the usefulness of their technique
on news articles, webpages, and some synthetic data.
Generative models can also be used with more sophisticated inference. For example,
Taskar, Segal, and Koller (2001) treat group membership as a latent variable and then uses
loopy belief propagation to implicitly perform a clustering of the nodes. Likewise, Mixed
Membership Relational Clustering (MMRC) (Long et al., 2007) uses EM variants to estimate group memberships. In particular, it uses a first round of hard clustering (where each
object is assigned to exactly one cluster), following by a round of soft clustering where continuous strength values are associated with each membership assignment. Mixed membership stochastic blockmodels (Airoldi et al., 2008) also assign continuous group membership
values to each node, but use only topological information (not attributes) for their group
assignments and use variational inference techniques with the generative model. Finally,
Long, Zhang, Wu, and Yu (2006) demonstrate how node clustering can be performed instead using spectral clustering, and focuses particularly on how to simultaneously cluster
multiple types of nodes (e.g., to simultaneously cluster web pages and web users into two
distinct sets of groups).
Most group prediction algorithms assume that links are more likely to connect nodes
that belong to the same group. An exception is the work of Anthony and desJardins (2007),
who also use a generative model where the links and attributes depend on some latent group
memberships, but where some types of links are more likely to occur between nodes that
do not belong to the same group. For instance, they note that if groups in a social network
are defined by gender, then a link representing dating is more likely to connect two nodes
from different groups.
396

fiTransforming Graph Data for Statistical Relational Learning

Figure 7: Lifted Graph Representation: The initial graph G is clustered and transformed into a lifted graph representation G. The lifted graph representation is
created by clustering nodes, links, or both.

5.4 Discussion
Most of the techniques described above produce a single clustering of the nodes, usually
based on assigning every node to a single group. In contrast, multi-clustering is an emerging
research area that aims to provide multiple orthogonal clusterings of complex data (Strehl
& Ghosh, 2003; Topchy, Law, Jain, & Fred, 2004). For instance, individuals in Facebook
might be clustered in multiple ways where latent node types might represent friend groups,
work relations, socioeconomic status, locations, or family circles. A type of multi-clustering
is performed by McCallum, Wang, and Corrada-Emmanuel (2007) where latent nodes are
created based on roles and topics. In addition, Kok and Domingos (2007) propose Statistical Predicate Invention (SPI), a node transformation approach based on Markov Logic
Networks (Richardson & Domingos, 2006). SPI clusters nodes, features and links forming the basis for the prediction of predicates (or potential nodes). SPI considers multiple
relational clusterings based on the observation that multiple distinct clusterings may be
necessary to, for instance, group individuals based on their friendships and their work relationships. They demonstrate that MLN inference can estimate these clusters and improves
performance compared to two simpler baselines. A similar node prediction approach applies
MLNs for role labeling (Riedel & Meza-Ruiz, 2008).
Node deletion may also be useful in some cases. For instance, node deletion might be
beneficial for removing outdated or spurious nodes from the graph. Alternatively, there
may be multiple nodes that represent the same real-world object or concept, in which case
deletion for the purposes of entity resolution can be important (Pasula, Marthi, Milch,
Russell, & Shpitser, 2003; Bhattacharya & Getoor, 2007; Singla & Domingos, 2006).
Finally, node representation changes can be used to not only to improve accuracy, but
also to yield graphs that can be processed more efficiently or that have other desirable
properties. Section 5.2 already discussed how Neville and Jensen (2005) used the addition of
latent nodes to enable simpler inference. Another possibility is the creation of super-nodes
that represent more than one of the original nodes. For instance, Figure 7 demonstrates how
five original nodes can, after clustering, be collapsed into three super-nodes, yielding a lifted
graph representation. This kind of representation change can be used for more efficient
397

fiRossi, McDowell, Aha, & Neville

inference in Markov Logic Networks (see Section 6.3) and for network anonymization (see
Section 8.6).

6. Node Interpretation
Node interpretation is the process of constructing weights, labels, or general features for
the nodes. As with the symmetric tasks for link interpretation, node weighting seeks to
assign a continuous value to each node, representing the nodes importance, while node
labeling seeks to assign a discrete value to each link, representing the type, group, or class
of a node. Likewise, node feature construction is the process of systematically generating
general-purpose node features based on, for instance, aggregation, dimensionality reduction,
or subgraph patterns.
As discussed in Section 4 for links, node feature construction could be viewed as subsuming node weighting and node labeling, since general feature construction could always
be used to construct feature values that are treated as weights or labels for the nodes. In
practice, however, the techniques used tend to be rather different. For instance, PageRank
is often used for node weighting and supervised classification is often used for node labeling,
but these techniques are rarely used for general feature construction. Nonetheless, for node
interpretation (more so than with link interpretation) there is some substantial overlap between the techniques actually used for weighting and labeling vs. those used for general
feature construction. Below, we first discuss node weighting in Section 6.1 and labeling in
Section 6.2. Section 6.3 then discusses node feature construction, mentioning only briefly
the relevant techniques that were previously discussed for weighting and labeling.
6.1 Node Weighting
Given the initial graph G = hV, E, XV , XE i, the task is to assign a continuous value (the
weight) to each existing node in G, representing the importance or influence of that node.
Node weighting techniques have been used for information retrieval, search engines, social
network analysis, and many other domains as a way to discover the most important nodes
with respect to some defined measure. As with node prediction they can be classified based
on whether they use only the node attributes, only the graph topology, or both to construct
a weighting.
6.1.1 Non-relational (Attribute-Based) Node Weighting
The simplest node weighting techniques use only the node features XV (i.e., the attributes).
For instance, nodes representing documents might be weighted based on the number of
query-relevant words they contain, while nodes representing companies might be ranked
based on their gross annual sales. Many more sophisticated strategies have also been considered. For instance, Latent Semantic Indexing (Deerwester et al., 1990) can be used to
identify the most important semantic concepts in a corpus of text, then nodes can be ranked
based on their connection to these concepts. These methods have been extensively applied
to quantify or rank the importance of scientific publications (Egghe & Rousseau, 1990).
However, because these techniques have been extensively studied elsewhere and also ignore
graph structure (such as citations), we do not discuss them further here.
398

fiTransforming Graph Data for Statistical Relational Learning

6.1.2 Topology-Based Node Weighting
Several node weighting algorithms that use only the topology of the graph were developed
to support early search engines. Examples of this kind of algorithm include PageRank
(Page et al., 1999), Hits (Kleinberg, 1999), and SALSA (Lempel & Moran, 2000). Each
of these algorithms rank the relative importance of web sites, conceptually based on some
kind of eigenvector analysis (Langville & Meyer, 2005), though in practice iterative computation may be used. For instance, PageRank models the web as a Markov Chain and is
implemented by systematically computing the principal eigenvector of limk Ak e where
A is the adjacency matrix and e is the unit vector. Hits, as previously described, instead computes the principal eigenvectors of AAT and AT A. These algorithms continue
to be very important for webpage ranking, but can also be applied to many other kinds of
graphs (Kosala & Blockeel, 2000).
In social network analysis, the objective of topology-based node weighting is typically
to identify the most influential or significant individuals in a social network. There have
been a variety of centrality measures devised that use the local and global network structure to characterize the importance of individuals (Wasserman & Faust, 1994). Examples
of these metrics include node degree, clustering coefficient (Watts & Strogatz, 1998), betweenness (Freeman, 1977), closeness (i.e., distance/shortest paths), eigenvector centrality (Bonacich & Lloyd, 2001), and many others (Jackson, 2008; Newman, 2010; Sabidussi,
1966). In addition, White and Smyth (2003) considered how to compute relative node
rankings, i.e., rankings relative to a set of particularly interesting nodes. They show how
to compute such relative rankings both for metrics based on shortest paths as well as for
Markov chain-based techniques (e.g., to produce PageRank with priors). In addition,
some of the similarity metrics described in Table 3.2 can alternatively be formulated for
computing weights on nodes.
More recently, node weighting techniques have been extended to measure the relative
importance of nodes in temporally-varying data. For instance, both Kossinets, Kleinberg,
and Watts (2008) and Tang et al. (2009) define notions of temporal distance based on an
analysis of how frequently information is exchanged between nodes. This information can
be used to define a range of new graph metrics, such as global temporal efficiency, local temporal efficiency, and the temporal clustering coefficient (Tang et al., 2009). More recently,
Tang, Musolesi, Mascolo, Latora, and Nicosia (2010) define notions of temporal betweenness
and temporal closeness. They argue that incorporating temporal information with these
metrics provides both a better understanding of dynamic processes in the network and more
accurately identifies the most important nodes (people). All of these metrics primarily concern networks that have time-varying interactions (e.g., communications between people),
but they could also be applied to other types of data with intermittent interactions between
nodes or where nodes/link join and leave the network over time. Some of these metrics also
apply to links, and could possibly be used to improve link prediction algorithms.
6.1.3 Hybrid Node Weighting
There are also hybrid node weighting approaches that use both the attributes and the graph
topology (Bharat & Henzinger, 1998; Cohn & Hofmann, 2001). For instance, there are
various approaches that modify Hits (Chakrabarti, Dom, Raghavan, et al., 1998; Bharat
399

fiRossi, McDowell, Aha, & Neville

& Henzinger, 1998) and PageRank (Haveliwala, 2003) to construct node weights based on
both content and links. Topic-Sensitive PageRank (Haveliwala, 2003) seeks to compute a
biased set of PageRank vectors using a set of representative topics. Alternatively, Kolda,
Bader, and Kenny (2005) propose TOPHITS, a hybrid approach that adds anchor text (i.e.,
the clickable text on each hyperlink) to the adjacency matrix representation used by Hits.
They then use a higher-order analogue of SVD known as Parallel Factors (PARAFAC)
decomposition (Harshman, 1970) to identify both the key topics in the graph as well as the
most important nodes. Other hybrid approaches have been proposed such as SimRank (Jeh
& Widom, 2002), Topical methods (Haveliwala, 2003; Nie, Davison, & Qi, 2006; Kolda
& Bader, 2006), Probabilistic HITs (Cohn & Chang, 2000), and many others (Richardson
& Domingos, 2002; Lassez et al., 2008). Section 7 discusses further relevant work in the
context of joint node and link transformation techniques.
Recently, node weighting approaches have been applied in Adversarial Information Retrieval (AIR) to detect or moderate the influence of spam web sites. Typically, these techniques produce weights using both the topology of the graph and some other information,
but not necessarily the kind of attribute information that is used by the techniques discussed
above. For instance, TrustRank (Gyongyi, Garcia-Molina, & Pedersen, 2004) is based on
PageRank and uses a set of trusted sites evaluated by humans to propagate the trust to
other locally reachable sites. On the other hand, SpamRank (Benczur, Csalogany, Sarlos, &
Uher, 2005) measures the amount of undeserved PageRank by analyzing the backlinks of a
site. There are other algorithms that try to identify link farms and link spam alliances (Wu
& Davison, 2005), given a seed set of known link farm pages. Among these AIR methods,
TrustRank is the most widely known but suffers from biases where the human-selected set
of trustworthy sites may favor certain communities over others.
6.2 Node Labeling
Given the initial graph G = hV, E, XV , XE i, the task is to assign some discrete label for
some or all of the nodes in G. We first discuss labeling techniques based on classification,
then consider unsupervised textual analysis techniques.
In many cases, node labeling may be considered an end in itself. For instance, in our
running Facebook example, the stated goal is to predict the political affiliation of each
node where that label is not already known. In other cases, however, node labeling is
more properly understood as a representation change that supports the desired task. For
instance, for some definitions of anomalous link detection (Rattigan & Jensen, 2005), having
estimated node labels would allow us to identify links between nodes whose labels indicate
they should rarely, if ever, be connected. Alternatively, for some datasets estimating node
labels may enable us to subsequently partition the data based on node type, enabling us to
learn more accurate models for each type of node.
Even when node labeling is the final goal, as with our Facebook example, intermediate
label estimation may still be useful as a representation change. In particular, Kou and Cohen
(2007) describe a stacked model for relational classification that relabels the training set
with estimated node labels using a non-relational classifier. They then use these estimated
labels to learn a new classifier (one that uses both attributes and relational features), and
use the new classifier to perform relational classification on the test graph. This approach
400

fiTransforming Graph Data for Statistical Relational Learning

yields high accuracy, comparable to that of much more complex algorithms for collective
classification (CC). Fast and Jensen (2008) analyze this result and discuss how it can be
explained by a natural bias in most CC algorithms: training is performed with the given
node labels but the inference depends in part on estimated labels (McDowell, Gupta, &
Aha, 2009). Stacked models compensate for this bias by instead training with the relabeled
(estimated) training set. In addition, inference with the new classifier needs only a single
pass over the test graph, yielding much faster inference than CC techniques like Gibbs
sampling or belief propagation. More recently, Maes, Peters, Denoyer, and Gallinari (2009)
extend these ideas of node relabeling in order to generate a larger training set via multiple
simulated iterations of classification. They show that in some cases this approach can
outperform stacked models and other CC algorithms like Gibbs sampling.
Thus, there are multiple reasons for creating new labels for the nodes in a graph. This
labeling can be accomplished by relational-aware algorithms like those described above as
well as by earlier algorithms used for relational or collective classification (Chakrabarti,
Dom, & Indyk, 1998; Neville & Jensen, 2000; Taskar et al., 2001; Lu & Getoor, 2003;
Macskassy & Provost, 2003). Node labeling can of course also be done by traditional,
non-relational algorithms such as SVM, decision trees, kNN, logistic regression, and Naive
Bayes, among various others (Lim, Loh, & Shih, 2000; Michie, Spiegelhalter, Taylor, &
Campbell, 1994; Burges, 1998; Cristianini & Shawe-Taylor, 2000; Joachims, 1998). These
methods simply use features XV and do not exploit topology or link-structure.
The above techniques all assign new labels via supervised learning. Labels can also
be assigned via unsupervised techniques for textual analysis. There are many networks in
the real-world that contain textual content such as social networks, email/communication
networks, citation networks, and many others. Traditional textual analysis models such as
LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999) and LDA (Blei et al., 2003) can be
used to assign each node a topic representing an abstraction of the textual information.
More recent techniques such as Link-LDA (Erosheva, Fienberg, & Lafferty, 2004) and LinkPLSA (Cohn & Hofmann, 2001) aim to incorporate the link structure into the traditional
techniques in order to more accurately discover a nodes type.6 In particular, the work
of Cohn and Hofmann demonstrate that their technique can produce more accurate node
labels than techniques that use only the node attributes or only the link topology. There
have also been more sophisticated topic models that have been developed for specific tasks
such as social tagging (Lu, Hu, Chen, & ran Park, 2010) or temporal data (Huh & Fienberg,
2010; He & Parker, 2010).
6.3 Node Feature Construction
Node feature construction is the systematic construction of features for the nodes, typically
for the purpose of improving the accuracy or understandability of SRL algorithms. Feature
construction is the most common relational representation change, and is very frequently
done before performing a task such as classification. For instance, before performing CC to
classify the nodes in our example Facebook political affiliation task, we are likely to compute
6. The names for Link-LDA and Link-PLDA come from the work of Nallapati, Ahmed, Xing, and Cohen
(2008), not from the original papers describing the techniques.

401

fiRossi, McDowell, Aha, & Neville

some new features representing the information about each node (e.g., age bracket?) and
the known information about each nodes neighbors (e.g., how many are liberal?).
Different techniques for node feature construction have been described by many previous
investigations, though feature construction was not necessarily the focus of many of those
investigations. In this section, we summarize and explain the different aspects of feature
construction. In particular, Section 6.3.1 presents and discusses a taxonomy of features
based on what kinds of inputs, such as topology information or link feature values, they
use for computing the new feature values. Next, Section 6.3.2 describes the possible operators, such as aggregation or discretization, that can be applied to these inputs. Finally,
Section 6.3.3 examines how to perform automatic feature search and selection to support a
desired computational task.
6.3.1 Relational Feature Inputs
A node feature can be categorized according to the types of information that it uses for
computing feature values. The possible information to use includes the set of nodes V or
links E, the node features XV , and the link features XE . Figure 8 shows our taxonomy of
node features based on which of these sources of information (the inputs) they use. This
taxonomy is consistent with some distinctions that have been previously made in the literature (e.g., between non-relational and relational features), but to the best of our knowledge
this more complete taxonomy has never been previously described. The taxonomy consists
of four basic types: non-relational features and three types of relational features (topology features, relational link-value features, and relational node-value features). Below we
describe and give examples of each.
 Non-relational Features: A node feature is considered a non-relational feature if
the value of the feature for a particular node is computed using only the non-relational
features (i.e., attributes) of that node, ignoring any link-based information. For instance, Figure 8A shows a node and the corresponding nodes feature vector. A new
feature value might be constructed from this vector using some kind of dimensionality reduction, by adding together several feature values, by thresholding a particular
value, etc.
 Topology Features: A feature is considered a topology-based feature if values of
the feature are computed using only the nodes V and links E, ignoring any existing
node and link feature values. For instance, in Figure 8B, a new feature value is being
computed for the node in the bottom left of the figure (the target node), using only
the topological information shown. In particular, the new feature value might count
the number of adjacent nodes, or count how many shortest paths in the graph pass
through the target node.
 Relational Link-value Features: A feature is considered a relational link-value
feature if the feature values of the links that are adjacent to the target node are
used for computing the new feature. Typically, some kind of aggregation operator is
applied to these values, such as count, mode, average, proportion, etc. For instance,
in Figure 8C, the values on the links shown represent communication topics (work or
personal), and a new link-value feature might compute the mode of these values (p).
402

fiTransforming Graph Data for Statistical Relational Learning

input	 

V,E,XV,XE	 

target	 node	 

Node	 Feature	 	 
Construction	 

XV	 

	 

link-value	 

p	 

V,E,XV,XE	 

node-value	 	 	 	 	 

L	 

Non-relational	 
Node	 Features	 

Relational	 Features	 

V,E	  V,E,XE	  V,E,XV	 
Topology	 
Features	 

Link-value	 
Features	 

Node-value	 
Features	 

C	 
p	 

L	 

p	 

.5	  	  P	 

A.	 

w	 

B.	 

	 V	 

C.	 

L	 
D.	 

X

Figure 8: Node Features Taxonomy Based on Inputs Used: The classes of node
features are non-relational features, topology features, relational link-value features, and relational node-value features. These classes are defined with respect
to the relational information used in the construction of the features (i.e., nodes
V , links E, node features XV , link features XE ). The double-lined target node
represents where the new feature value is being computed. Parts C and D show
only a single feature value for each link or node for simplicity, but in general more
than one such feature may exist and be used.

Usually this computation will include only the links directly connected to the target
node, but links a few hops away could also be used.
 Relational Node-value Features: A feature is considered a relational node-value
feature if the feature values of nodes linked to the target node are used in the construction. Links are used only for identifying these nodes, although nodes more than
one hop away from the target node may also be included. For instance, Figure 8D
shows the feature values of adjacent nodes (C or L) which could, for instance, be
used to compute a new node-value feature based on the mode (L) of those values.
Alternatively, one feature might count the number of adjacent C nodes and another
might count the number of adjacent L nodes.
403

fiRossi, McDowell, Aha, & Neville

Feature computation may also be applied recursively. For instance, the ReFeX system (Henderson, Gallagher, Li, Akoglu, Eliassi-Rad, Tong, & Faloutsos, 2011) first computes features for every node based on their degree (a topology-based feature), then considers recursive combinations of these features (such as the mean out-degree of a nodes
neighbors). Henderson et al. show that such recursive features can often improve classification accuracy for datasets where the network structure is predictive. Alternatively, a
topology-based feature such as betweenness might be computed, then a relational nodevalue feature might compute the average betweenness of the nodes that are neighbors of
the target and have a label of C. This is an example of a hybrid feature that uses both
node-value and topology-based information.
Another interesting aspect of relational features is the potential for feature value recomputation. In particular, many techniques for collective classification involve computing
a node feature (such as the number of neighbors currently labeled C) where that feature
depends on other feature values that are estimated (e.g., the predicted node labels) and
thus may change (Jensen et al., 2004; Sen et al., 2008). In addition, McDowell, Gupta,
and Aha (2010) describe features that have a similar need for recomputation, because the
meta-features they use depend upon the estimated label probabilities for each node in the
neighborhood of the target node. In contrast, this kind of feature re-computation has much
less applicability for non-relational data, where the nodes are assumed to be independent
of each other. However, it can occur with techniques such as semi-supervised learning or
co-learning.
6.3.2 Relational Feature Operators
The previous section described features according to the different kinds of inputs that they
use during feature value computation, whereas this section describes the different operators
that can be used for this computation. Table 5 summarizes these operators. In some
cases, an operator can be used for many different types of relational input. For instance,
aggregation operators can be computed using the graph topology, relational node-value
inputs, and/or relational link-value inputs, as indicated by the appropriate checkmarks in
Table 5. In contrast, path or walk-based operators generally use only the graph topology; for
these operators, the lighter colored checkmarks in Table 5 indicate that path/walk-based
operators could sensibly be used in conjunction with relational link-value or node-values
inputs, but this has been rarely if ever done. Below we discuss each of the operators from
Table 5 in more detail.
Relational Aggregates: Aggregation refers to a function that returns a single value
from a collection of input values such as a set, bag, or list. The most classical statistical
aggregation operators are Average, Mode, Exists, Count, Max, Min, and Sum (Neville
& Jensen, 2000; Lu & Getoor, 2003). For SRL, another frequent operator is Proportion,
which computes, for instance, the fraction of a nodes neighbors that meet some criteria
such as having the label C (McDowell, Gupta, & Aha, 2007). These operators may also
be combined with thresholds, e.g., to evaluate whether the Count of a nodes neighbors
labeled C is at least 3. The thresholding turns the numerical aggregate into a Boolean
feature, which is needed for tree-based algorithms (Neville, Jensen, Friedland, et al., 2003).
Perlich and Provost (2003) describe a set of more complex relational aggregates that depend
404

fiTransforming Graph Data for Statistical Relational Learning

Relational aggregates

Mode, Average, Count, Proportion, Degree, ...

Temporal aggregates

Exponential/linear decay, union, ...

X

Set operators

Union, intersection, multiset, ...

X

Clique potentials

Direct link cliques, co-citation cliques, triads, ...

Subgraph patterns

Two star, three-star, triangle (i.e., transitivity), ...

Dimensionality reduction

PCA, SVD, Factor Analysis, Principal Factor Analysis, Independent Component Analysis, ...

Path/walk-based measures

Betweenness, common neighbors, Jaccards coefficient, Adamic/Adar, shortest paths, random-walks,
...

Textual analysis

LSA, LDA, PLSA, Link-LDA, Link-PLSA, ...

X

Relational clustering

Spectral partitioning, Hierarchical clustering, Partitioning relocation methods (k-means, k-medoids),
...

X

X

Relational Node-value

Example Techniques

Relational Link-value

Relational Operators

Topology

Non-relational

Inputs

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

Table 5: Relational Feature Operators: Summary of the most popular types of relational feature operators. A check is used to indicate the classes of inputs (see
Section 6.3.1) that each operator most naturally uses for constructing feature values, while a lighter check indicates that the operator could sensibly be used with
that input but that this combination has rarely if ever been used.

405

fiRossi, McDowell, Aha, & Neville

on the distribution of attribute values that are associated with each node (e.g., via links or a
relational join). For instance, these aggregates may use a function such as the edit distance
to compare each nodes distribution to a reference distribution computed from the training
data. Perlich and Provost demonstrate that these aggregations can in some cases improve
performance compared to simpler alternatives. There are also aggregate operators that use
only topology-based information. For instance, the operator Degree, which simply counts
the number of adjacent links, can be a predictive feature, but should be applied carefully
to relational data to avoid bias (Jensen, Neville, & Hay, 2003).
Temporal Aggregates: Relational information might also contain temporal information
in the form of timestamps or durations for the links, node, or features. In general, such data
can be handled by defining special temporal-aggregation features computed over the raw
data (McGovern, Collier, Matthew Gagne, Brown, & Rodger, 2008) or by defining a graph
that summarizes all of the temporal information (usually by decreasing the importance of
less recent information) (Sharan & Neville, 2008; Rossi & Neville, 2010). Rossi and Neville
discuss an example of the latter approach, where they explore the impact of using various
temporal-relational information and various kernels for summarization. Alternatively, Section 6.1 discusses how notions of temporal distance can be used to modify path/walk-based
metrics such as node betweenness and closeness.
Set Operators: The traditional domain-independent set operators such as set union,
intersection, and difference can be applied to construct features (Kohavi & John, 1997).
For instance, if there are two attributes that both represent the presence of some word
in a page (node), a new feature might represent the case where a page contains both
of those words (i.e., feature intersection). For relational data, more complex set-based
features are possible. For instance, a feature for collective classification might represent the
union of all the class labels of the nodes adjacent to the target node. Neville, Jensen, and
Gallagher (2003) propose a more complex approach where the feature value is a multiset
that represents the complete distribution of adjacent nodes labels (e.g., {3C, 2M, 5L} to
indicate the labels of ten adjacent nodes). Using this feature representation, they show
that the independent-value approach that assumes that the labels are independently
drawn from the same distribution yields the most effective relational classification. Recently,
McDowell et al. (2009) showed that, for CC, this multiset approach usually outperformed
other types of features such as the proportion or count-based aggregates discussed above.
Clique Potentials: Some probabilistic models such as Relational Markov Networks (RMNs)
(Taskar et al., 2002) perform inference over related nodes without computing aggregates.
Instead, they use clique-specific potential functions to represent the probabilistic dependencies, and a product term in the probability computation naturally expands to accommodate
a varying number of neighbors for each node. In one sense, this is a featureless approach,
since there is no need to choose a relational aggregation function. However, different kinds
of dependencies can still be represented by different cliques. For instance, Taskar et al.
consider different sets of cliques for webpage classification: one based only on hyperlinks,
the other including information based on where links appear within a page. Likewise, later
work added additional types of cliques to enable link prediction (Taskar et al., 2003). Thus,
even with these models there remain important feature choices to be made.
406

fiTransforming Graph Data for Statistical Relational Learning

Figure 9: Subgraph Patterns with Link Labels. Each subgraph represents a possible
pattern that a particular feature could look for in relation to the target node (the
bottom-left node in each case).

Other probabilistic models also use link-based information without computing explicit
features, such as the random walk-based classifier of Lin and Cohen (2010) or the weightedneighbor approach of Macskassy and Provost (2007). Even in these cases, however, choices
remain about what types of links to use. For instance, in webpage graphs, co-citation
links may be more predictive of class labels than direct links (Macskassy & Provost, 2007;
McDowell et al., 2009).
Subgraph Patterns: A subgraph pattern feature is one that is based on the existence of a
particular pattern in the graph adjacent to the target node. Such a feature might count how
many times a particular pattern exists for the target node, or produce a value of true if at
least one such pattern exists. The simplest such pattern is called reciprocity; it is true when
the target node i links to node j and j links back to i. In most cases, however, the patterns
are more complex and involve more nodes. Robins, Pattison, Kalish, and Lusher (2007)
define many such patterns including two-star (a node with at least two links), three-star (a
node with at least three links), and triangle (also known as transitivity, where i  j  k
and i  k). Most such patterns can be defined for both directed and undirected links.
Many other patterns are possible. For instance, Robins, Snijders, Wang, and Handcock
(2006) use subgraph patterns for probabilistically modeling graphs. They argue that using
more complex patterns such as the alternating k-triangle (based on finding k triangles that
all share a common side) can help to avoid degeneracy that might otherwise arise during
graph generation. Furthermore, subgraph patterns can also be extended to exploit labels
on the links and/or nodes. For instance, assume some links are labeled with 1 or 2 (representing different topics) and some links are labeled with a plus or minus sign (representing
positive or negative relationships). Figure 9 demonstrates three possible subgraph patterns,
based on different link labelings, relative to the target node shown at the bottom left of
each subgraph. A subgraph feature could compute, for each node, the number of matches
for one of these patterns, and this feature could be used for later analysis.
Dimensionality Reduction The goal of dimensionality reduction is to find a lower kdimensional representation of the initial n features (Sarwar, Karypis, Konstan, & Riedl,
2000; Fodor, 2002). More formally, given an initial n-dimensional feature vector x =
{x1 , x2 , ..., xn }, find a lower k-dimensional representation x such that x = {x1 , x2 , ..., xk }
with k  n where the most significant information of the original data is captured, according to some criterion. There are many dimensionality reduction methods such as Principal
407

fiRossi, McDowell, Aha, & Neville

Component Analysis (PCA), Principal Factor Analysis (PFA), and Independent Component
Analysis (ICA).
Dimensionality reduction techniques can be applied on the adjacency matrix A of the
graph G to create a low-dimensionality graph representation; Section 3.3 explained how this
can be used for link prediction. These techniques can also be useful for feature computation.
For instance, Bilgic, Mihalkova, and Getoor (2010) investigate active learning to improve
the accuracy of collective classification. Their technique involves both non-relational and
relational features, but they demonstrate that first applying dimensionality reduction (with
PCA) to the non-relational features simplifies learning, leading to substantial gains in accuracy.
Other Operators: We mention only briefly those operators that have already been discussed extensively elsewhere. Path-based measures (such as betweenness and distance)
and walk-based measures (such as PageRank) were discussed in Sections 6.1. These
types of measures have been used as features in a classifier to predict links (Lichtenwalter
et al., 2010) as well as for validating relational sampling techniques (Leskovec, Chakrabarti,
Kleinberg, Faloutsos, & Ghahramani, 2010; Moreno & Neville, 2009; Ahmed, Neville, &
Kompella, 2012a, 2012b). These measures typically use only the topology (not the features), but one could easily imagine computing metrics based, for instance, only on paths
where each edge had a particular label or type. Textual analysis techniques were discussed
in Sections 4.2 and 6.2, and relational clustering techniques were discussed in Section 5.
These operators were used specifically for node/link prediction, weighting, or labeling, but
can also be used for more general feature construction.
Finally, there are operators based on similarity measures. Similarity between two
nodes is often computed, for instance for link prediction (Section 3) or weighting (Section 4.1). Such computations can easily lead to a feature value for a link, since the link
obviously refers to two endpoint nodes that can be compared. However, for computing a
node feature value, there is usually no obvious other node for comparison, so similarity measures are not typically used for node feature values. Such measures can, however, be used for
node prediction, and Section 5 discusses how in some cases newly discovered nodes/groups
can be used to create new node features. As a particular instance of relational similarity
functions, graph kernels for structured data (Gartner, 2003) can also be used. Such kernels
can be used either between the nodes of a single graph (Kondor & Lafferty, 2002) or to
compute the similarity between two graphs (Vishwanathan, Schraudolph, Kondor, & Borgwardt, 2010). For instance, the former type of kernel is another technique that could also
be used for link or group prediction.
Discussion: Many of the feature operators discussed can naturally be used to compute feature values for links in additions to nodes. For instance, textual analysis can be applied to
links if there is text associated with each link, and most node-centered path-based measures
have analogous formulations for links. One difference is that nodes naturally may link to
many other nodes, whereas we assume links with just two endpoints. Thus, relational aggregates such as Count do not initially seem as useful for computing link features. However,
Figure 4 previously demonstrated how link-aggregation can be accomplished by broadening the computation to include the multiple links or nodes that are logically connected to
each endpoint node of the target link. Naturally, some feature inputs and operators are
408

fiTransforming Graph Data for Statistical Relational Learning

better suited for computing node features vs. for computing link features. The next section
examines how to select the most appropriate features for a given task.
6.3.3 Searching, Evaluating, and Selecting Relational Features
Given the large number of possible features that could be used for some task (such as the
example Facebook classification task), which features should actually be used to learn a
model? In some cases, such selection is done manually based on prior experience or trial
and error. In many situations, though, more automatic feature selection is desirable. For
non-relational data, this has been a widely studied topic in machine learning (Guyon &
Elisseeff, 2003; Koller & Sahami, 1996; Yang & Pedersen, 1997; Dash & Liu, 1997; Jain
& Zongker, 1997; Pudil, Novovicova, & Kittler, 1994), but selecting relational features has
received considerably less attention. Given the large number of possible features, efficient
strategies for searching over and evaluating the possible features is needed. In this section,
we first summarize these two key problems of feature search and feature evaluation, then
give examples of how these issues have been resolved in actual SRL systems.
Search: The first step in searching over the relational features is to define the possible
relational feature space by specifying the possible raw feature inputs (e.g., node and link
feature values) and operators to consider. The possible operators can include domainindependent operators (e.g., mode, count) and/or problem-specific operators (e.g., count the
number of friends divided by the number of groups). Domain-independent operators are
obviously more general and easier to apply, while the problem-specific operators can reduce
the number of possibilities that must be considered but require more effort and expert
knowledge. However, both approaches are vulnerable to selection biases (Jensen et al., 2003;
Jensen & Neville, 2002). The second step is to pick an appropriate search strategy, usually
either exhaustive, random, or guided. An exhaustive strategy will consider all features
that are possible given the specified inputs and operators, while a random strategy will
consider only a fraction of this space. A guided strategy will use some heuristic or subsystem to identify the features that should be considered. In all three cases, each feature
that is considered is subjected to some evaluation strategy that assesses it usefulness; these
strategies are described next.
Evaluation and Selection: Each feature that is considered must be evaluated in some
way to determine if it will be retained for use in the final model. For instance, a candidate
feature may be evaluated by adding it to the current classification model; if it improves
accuracy on a holdout set, then it is immediately (and greedily) added to the set of retained
features (Davis, Burnside, Castro Dutra, Page, & Costa, 2005; Davis, Ong, Struyf, Burnside,
Page, & Costa, 2007). In other cases, every candidate feature is assigned some score and
then only the best scoring feature is retained (Neville, Jensen, Friedland, et al., 2003), or
features are added to the model based on decreasing score, so long as the new features
continue to improve the model (Mihalkova & Mooney, 2007). Simpler techniques that do
not require evaluating the overall model can also be used. For instances, metrics such as
correlation or mutual information can be used to estimate how useful the feature is for the
desired task. Other metrics or strategies that could be used include Akaikes information
criterion (AIC) (Akaike, 1974), Mallows Cp (Mallows, 1973), Bayesian information criterion
(BIC) (Hannan & Quinn, 1979; Schwarz, 1978) and many others (Shao, 1996; George &
409

fiRossi, McDowell, Aha, & Neville

Proposed System

Search method

Feature Evaluation

Exhaustive

Chi-square statistic/p-value

RDN-Boosting (Natarajan, Khot, Kersting, Gutmann, & Shavlik, 2012; Khot,
Natarajan, Kersting, & Shavlik, 2011)

Exhaustive

Weighted variance

ReFeX (Henderson et al., 2011)

Exhaustive

Log-binning disagreement

Random

Chi-square statistic/p-value

SAYU (Davis et al., 2005)

Aleph

AUC-PR

nFOIL (Landwehr et al., 2005)

FOIL

Conditional Log-Likelihood

SAYU-VISTA (Davis et al., 2007)

Aleph

AUC-PR

ProbFOIL (De Raedt & Thon, 2010)

FOIL

m-estimate

kFOIL (Landwehr et al., 2010)

FOIL

Kernel target alignment

Greedy hill-climbing

Bayesian model selection

Beam search

WPLL

Template-based

WPLL

Level-wise search

Pseudo-likelihood

Aleph++

m-estimate

RPT (Neville, Jensen, Friedland, et al.,
2003)

Spatiotemporal

RPT

(McGovern

et al., 2008)

PRM struct. learning (Getoor, Friedman, Koller, & Taskar, 2001)

TSDL (Kok & Domingos, 2005)
BUSL (Mihalkova & Mooney, 2007)
PBN

Learn-And-Join

(Khosravi,

Tong Man, Xu, & Bina, 2010)

Discriminative MLN structure
learning (Huynh & Mooney, 2008; Biba,
Ferilli, & Esposito, 2008)

Table 6: Systems for Searching for and Selecting Node Features: A summary
of some of the systems that can be used to automatically search for and select the
most appropriate features for a given task. Note that, depending on the context,
these papers may be describe their function in terms of learning the best rules for
a system or of learning the structure (e.g., of a MLN). Only some of the MLNbased systems are described; for some of these, WPLL is the weighted pseudo
log-likelihood.

McCulloch, 1993). Frequently, a possible feature may have a particular parameter whose
value must be set (such as a threshold); selecting the best value for a given feature can
use the same evaluation metrics or may use a simpler estimation technique, e.g., based on
maximum likelihood.
Examples: Table 6 summarizes the strategies used by a number of SRL systems that automatically search for features. The columns of the table describe how each system searches
410

fiTransforming Graph Data for Statistical Relational Learning

for features and how the features are evaluated. For instance, Relational Probability Trees
(RPTs) (Neville, Jensen, Friedland, et al., 2003) are an extension of probability estimation
trees for relational data that use an exhaustive search strategy for feature selection. In particular, RPT learning involves automatically searching over the space of possible features
using aggregation functions such as Mode, Average, Count, Proportion, Min, Max,
Exists, and Degree. These aggregations can involve node and link feature values (e.g.,
for Average) or just topology information (e.g., for Degree). These features are used
for classification tasks, such as predicting the class label for a document. Each feature is
evaluated based on using the chi-square statistic to measure the correlation between the
feature and the class label; this yields a feature score and an associated p-value. Features
with p-values below the level of statistical significance are discarded, then the remaining
feature with the highest score is chosen for inclusion in the model. This selection process
has also been extended to use randomization tests to adjust for biases that are common in
relational data (Jensen et al., 2003; Jensen & Neville, 2002). RPTs have also been extended
for temporal domains (Sharan & Neville, 2008; Rossi & Neville, 2012).
RPTs represent the conditional probability distributions using a single tree. In contrast,
Natarajan et al. (2012) propose using gradient boosting (Friedman, 2001) such that each
conditional probability distribution is represented as a weighted sum of regression trees
grown in a stage-wise optimization. The features for each tree are selected via a depthlimited, exhaustive search, though they note that domain knowledge could also be used to
guide this search. Natarajan et al. argue that the resultant set of multiple, relatively shallow
trees allows efficient learning of complex structures, and demonstrate that this technique
can outperform alternatives based on single trees or the Markov Logic Networks discussed
below.
Another system that uses exhaustive search is ReFeX (Henderson et al., 2011), which
uses aggregates of Sum and Mean operators to recursively generate features based on the
degree of a node and its local neighborhood. To prune the resultant large set, ReFeX uses
logarithmic binning of the feature values, clusters features based on their similarity in the
binned space, and then retains only one feature from each cluster. The logarithmic binning
is chosen because it favors features that are more discriminative for high-degree nodes.
This recursive approach has also been modified for constructing features over dynamic
networks (Rossi, Gallagher, Neville, & Henderson, 2012).
Alternatively, spatiotemporal RPTs (McGovern et al., 2008) use a random search strategy. In particular, these RPTs add temporal and spatial-based features to the set of possible
features. The resultant feature space is too large for exhaustive search, so instead random
sampling is used. After a pre-defined number of features have been considered, the best
scored feature is added to the model.
The remaining systems that we will discuss all use a guided search strategy, where
some heuristic or sub-system provides candidate features that are considered. For instance,
several such systems (Davis et al., 2005; Landwehr et al., 2005) use an ILP system to
generate candidate features, then evaluate those features and select some for ultimate use.
In particular, SAYU (Davis et al., 2005) uses the ILP system Aleph (Srinivasan, 1999) to
generate a candidate feature (which they consider to be a new view on the original data).
Aleph creates candidates features based on positive examples, from the training data, of
the concept which is being predicted. Each proposed feature is evaluated by learning a
411

fiRossi, McDowell, Aha, & Neville

new model that includes the feature and then computing the area under the precision-recall
curve (AUC-PR). If a feature improves the AUC-PR score, it is permanently added to
the model and the feature search continues. SAYU-VISTA (Davis et al., 2007) retains this
same general approach but extends the types of features that can be considered, in particular
adding the ability to dynamically link together objects of different types and to recursively
build new features from other constructed features. Davis et al. demonstrate that the link
connections are especially helpful in improving performance compared to the original SAYU
system. Landwehr et al. (2005) describe the nFOIL system which is very similar to SAYU
but was developed independently, while De Raedt and Thon (2010) describe how ProbFOIL
upgrades a deterministic rule learner like FOIL to be probabilistic. Landwehr et al. (2010)
describe the related kFOIL system which integrates FOIL with kernel methods. They also
consider the impact of several different feature scoring functions.
A number of systems have considered how to perform structure learning for Probabilistic Relational Models (PRMs) (Getoor et al., 2001) or for Markov Logic Networks
(MLNs) (Domingos & Richardson, 2004), which is a more general case of the feature selection problems described above. For instance, a MLN is a weighted set of first-order formulas;
structure learning corresponds to learning these formulas while weight learning corresponds
to learning the associated weights. The first MLN structure learning approaches systematically construct candidate clauses by starting from an empty clause, greedily adding literals
to it, and testing the resulting clauses fit to the training data using a statistical measure (Kok
& Domingos, 2005; Biba et al., 2008). However, these top-down approaches are inefficient
because the initial proposal of clauses ignores the training data, resulting in a large number
of possible features being considered and possible problems with local minima. In response,
a number of bottom-up approaches have been proposed. In particular, Mihalkova and
Mooney (2007) use a propositional Markov network structure learner to construct template
networks to guide the construction of features based on the training data. More recent
work has examined how to enable bottom-up approaches to learn longer clauses based on
constraining the search to only consider features consistent with certain patterns or motifs (Kok & Domingos, 2010), or by clustering the input nodes to create a lifted graph
representation, enabling feature search over a smaller graph (Kok & Domingos, 2009).
Khosravi et al. (2010) perform MLN structure learning by first learning the structure of
a simpler Parametrized Bayes Net (PBN) (Poole, 2003), then converting the result into a
MLN. For data that contains a significant number of descriptive attributes, they show that
this approach dramatically improves the runtime of structure learning and also improves
predictive accuracy. Schulte (2011) has given a theoretical justification for this approach.
Another alternative, proposed by Khot et al. (2011), is to extend the previously mentioned
work of Natarajan et al. (2012) on gradient boosting to MLNs. Essentially, the problem
of learning MLNs is transformed into a series of relational regression problems where the
functional gradients are represented as clauses or trees. For several datasets they demonstrate faster MLN structure learning that is as accurate or better than baselines including
the algorithms of Mihalkova and Mooney (2007) and Kok and Domingos (2010).
The above techniques for MLNs all seek to learn a network structure that best explains
the training data as a whole. In contrast, for situations where the prediction of a specific predicate is desired (e.g., to predict the political affiliation in our Facebook example),
Huynh and Mooney (2008) and Biba et al. (2008) both propose discriminative approaches
412

fiTransforming Graph Data for Statistical Relational Learning

to MLN structure learning. For instance, Huynh and Mooney use a modified version of
Aleph (Srinivasan, 1999) to compute a large number of candidate clauses, then use a form
of L1 -regularization to force the weights that are subsequently learned for these clauses to
be zero when the clause is not very helpful for predicting the predicate. This regularization,
in conjunction with an appropriate optimization function, effectively leads to selecting a
smaller set of features that are useful for the desired task.
Discussion: We focus in this article on graph-based data representations (see Section 1.2).
However, many of the examples discussed above use a logical representation instead. We
include them in this section because the techniques used for constructing and searching
for features or rules are very similar in both settings. For instance, both RPTs (a graphbased approach) and RDN-Boosting (a logical approach) use an exhaustive search over
probabilistic decision trees, with different feature scoring strategies.
Popescul et al. (2003a) examine how to automatically learn new relational features for
links (to support link prediction), but their techniques could also be applied to constructing
node features. In particular, they treat each feature as a relational database query, and use
the concept of refinement graphs (Shapiro, 1982) to consider refining an initial query with
equi-joins, equality selections, and statistical aggregates. After each refinement, further
refinements can be considered; this search is guided by sampling over some possible further refinements and proceeding only if the results of a particular refinement or type seems
promising. The features chosen are combined with a logistic regression classifier. For evaluation of the specific features, they use the Bayesian Information Criterion (BIC) (Schwarz,
1978), which includes a term than penalizes feature complexity to reduce the danger of
overfitting.
We discussed multiple systems that include notions of aggregation including RPTs,
SAYU-VISTA, and the work of Popescul et al. (2003a) discussed above. There are also
other aggregate-based learning approaches such as Crossmine (Yin, Han, Yang, & Yu, 2006),
CLAMF (Frank, Moser, & Ester, 2007), Multi-relational Decision Trees (MRDTL) (Leiva,
Gadia, & Dobbs, 2002), Confidence-based Concept Discovery (C2 D) (Kavurucu, Senkul, &
Toroslu, 2008), and many others (Perlich & Provost, 2006; Krogel & Wrobel, 2001; Knobbe,
Siebes, & Marseille, 2002). There are also other possibilities for feature evaluation. For
instance, GleanerSRL (Goadrich & Shavlik, 2007) uses Aleph (Srinivasan, 1999) to search
for clauses and then uses a metric of precision  recall for evaluating the clauses.

7. Jointly Transforming Nodes and Links
In the previous sections, we primarily discussed relational representation transformation
techniques that are applied independently of one another. For instance, one technique
might be used to predict links, while another builds on the transformed representation by
applying a node labeling technique. This section instead examines joint transformation
tasks that combine node and link transformation in some way, for instance to label the nodes
and weight the links simultaneously. Such techniques may enable each subtask to influence
the other in helpful ways, and avoids any bias that might be introduced by requiring the
serialization of two tasks (such as link weighting and node labeling) that might usefully be
performed jointly.
413

fiRossi, McDowell, Aha, & Neville

One recent approach proposed by Namata, Kok, and Getoor (2011) collectively performs link prediction, node labeling, and entity resolution (which can be seen as a form
of node deletion/merging). They present an iterative algorithm that solves all three tasks
simultaneously by propagating information among solutions to the above three tasks. In
particular, they introduce the notion of inter-relational features, which are relational features for one task that depend upon the predicted values for another. Their results show
that using such features can improve accuracy, and that inferring predicted values for all
three tasks simultaneously can significantly improve accuracy compared to performing the
three tasks in sequence, even if all possible orderings are considered.
Techniques that model the full distribution across links and attributes such as RMNs
(Taskar et al., 2002), PRMs (Friedman et al., 1999), and MLNs (Domingos & Richardson,
2004) can also be used in this scenario, for instance to jointly predict node and link labels.
In this section, however, we focus particularly on recent techniques that all presume the
existence of some textual content that is associated with the nodes or links of the graph
(although the basic algorithms would also work with other kinds of features). We consider
three types of techniques, based on what kind of input text they use: stand-alone text
documents (e.g., legal memos with no links), text documents connected by links (e.g.,
webpages with hyperlinks), or entities connected by links that have associated text (e.g.,
people connected by email messages). Table 7 lists some of the most prominent models,
grouped according to these three types. The columns of this table indicate what kinds of
input the models use (middle section) and the types of transformation they can perform
(right-hand section). The text documents corresponds to node features in this table, while
text associated with links yields link features. Below we discuss each of the three types of
techniques in more detail.
7.1 Using Text Documents with No Links
First, many techniques can be used to assign topics or labels to the nodes when those nodes
(such as documents) have associated text. For instance, the first row of Table 7 indicates
that LDA and PLSA use only the nodes and node features and can perform node prediction,
weighting, and labeling. Section 6 already mentioned how these techniques can be used to
label each node with one or more discovered topics, which is their more typical use. However,
these techniques can also perform node weighting (using the weights associated with the
topics) and/or node prediction (by converting the discovered topics to new latent nodes
as discussed in the introduction to Section 5). In Table 7, we use lighter checkmarks to
represent these kind of situations where a transformation task could be performed by a
particular model but is not its primary use/output.
LDA and PLSA treat each document as a bag of words and seek to assign one or more
topics (labels) to each document based on the words. In contrast, Nubbi (Chang, BoydGraber, & Blei, 2009) designs an approach based on LDA where a graph is defined based on
objects (nodes) that are referenced in a set of documents, then links are predicted based on
the relationships that are implied in the text of the documents. In addition, the nodes and
links are associated with their most likely topic(s) based on these relationships. Thus, this
model simultaneously performs link prediction, link labeling, and node labeling. A similar
414

fiTransforming Graph Data for Statistical Relational Learning

Link Labeling

Node Prediction

Node Weighting

Node Labeling

E

XE

XE

V

XV

XV

V

XV

LDA/PLSA

X

X

Nubbi

X

X

X

Joint Transformation Model

E

XE

Link Weighting

Input

Nodes

Link Prediction

Links

X

X

X

X

X

X

X

Link-LDA, Link-PLSA

X

X

X

X

X

X

X

X

Pairwise-Link-LDA

X

X

X

X

X

X

X

X

Link-PLSA-LDA

X

X

X

X

X

X

X

X

Relational Topic Model (RTM)

X

X

X

X

X

X

X

X

Topic-Link LDA

X

X

X

X

X

X

X

X

Group-Topic (GT)

X

X

X

X

X

X

X

X

Author-Recipient-Topic (ART)

X

X

X

X

X

Block-LDA

X

X

X

X

X

X
X

X

X

Table 7: Summary of the Joint Transformation Models: The middle section of the
table indicates what types of graph features are used as inputs to the model, while
the right side of the table indicates what types of link or node transformation can
be performed by the model. Lighter checkmarks indicate that the output of the
model can be transformed to perform a particular transformation task (e.g., to
use the node labels to create new latent group nodes), but where that task was
not the primary goal of the specified model.

415

fiRossi, McDowell, Aha, & Neville

result is produced by the semantic network extraction of Kok and Domingos (2008) that
was discussed in Section 4.2.
7.2 Using Text Document with Links
The second type of joint transformation also uses text documents, but adds known links
between the documents to the model. For instance, Section 6 discussed how Link-LDA and
Link-PLSA add link modeling to LDA and PLSA in order to perform node labeling; as
discussed above for LDA and PLSA this can be modified to also achieve node prediction
and weighting. As shown in Table 7, Link-LDA and Link-PLSA can also be used for link
prediction and weighting by learning a model from a training graph and then using it to
predict unseen links on a new test graph (Nallapati et al., 2008).
Link-LDA and Link-PLSA model links in a way that is very similar to how they model
the presence of words in a document (node). For instance, in Link LDAs generative model,
to generate one word, each document chooses a topic, then chooses a word from a topicspecific multinomial. The identical process (using a topic-specific multinomial) is used to
generate, for a particular document, one target document to link to. Thus, Link-LDA and
Link-PLSA directly extend the original LDA and PLSA models to add links.
Nallapati et al. (2008) argue that Link-LDAs and Link-PLSAs extensions for links,
while pragmatic, do not adequately capture the topical relationship between two documents
that are linked together. Instead, they propose two alternatives. The first, Pairwise LinkLDA, replaces the link model of Link-LDA with a model based on mixed membership
stochastic blockmodels (Airoldi et al., 2008), where each possible link is modeled as a
Bernoulli variable that is conditioned on a topic chosen based on the topic distributions of
each of the two endpoints of the link. The second approach, Link-PLSA-LDA, retains the
link generation model of Link-LDA, but changes the word generation model for some of the
documents (the ones with incoming links) so that the words in such a document depend on
the topics of other documents that link to it. The downside of this latter approach is that
it only works when the nodes can be divided into a set with only outgoing links and a set
with only incoming links. However, Nallapati et al. argue that this limitation can be largely
overcome by duplicating any nodes that have both incoming and outgoing links. Moreover,
this approach is much faster and more scalable than Pairwise Link-LDA. Nallapati et al.
demonstrate that both models outperform Link-LDA on a likelihood ranking task, and that
Link-PLSA-LDA also outperforms Link-LDA on a link prediction task. They also show
that Link-PLSA-LDA and Link-LDA were comparable in terms of execution time, but that
Pairwise Link-LDA was much slower.
Changes to the generative model used by each of these approaches encode different assumptions about the data and can lead to significant performance differences. For instance,
Chang and Blei (2009) introduce the Relational Topic Model (RTM) and compare it to the
Pairwise Link-LDA model discussed above. Both models allow similar flexibility in terms
of how links are defined, but Chang and Blei argue that their model forces the same topic
assignments that are used to generate the words in the documents to also generate the
links, which is not true of Pairwise Link-LDA. They then demonstrate that RTM provides
more accurate predictions and link suggestions than Pairwise Link-LDA and several other
baselines.
416

fiTransforming Graph Data for Statistical Relational Learning

Another possible change to the model is to add other types of objects. For instance,
Topic-Link LDA (Liu, Niculescu-Mizil, & Gryc, 2009) models not only documents, links,
and the most likely topics associated with each document, but also explicitly considers the
author of each document and clusters these authors into multiple communities. Creating
this new clustering is not equivalent to finding per-document topics because each author
is associated with more than one document. They argue that this approach is analogous
to unifying the separate tasks of (1) assigning topics to documents and (2) analyzing the
social network of authors. They show that their approach can in some cases outperform
LDA and Link-LDA.
7.3 Using Text Associated with Links
The final type of joint transformation techniques form link features based on text associated
with links, such as the text of email messages (McCallum, Wang, & Corrada-Emmanuel,
2007) or scientific abstracts that relate to a particular protein-protein interaction (Balasubramanyan & Cohen, 2011). Several such techniques were discussed previously in the
context of link interpretation. For instance, Section 4.2 discussed how models such as the
Author-Recipient-Topic (ART) model (McCallum, Wang, & Corrada-Emmanuel, 2007) and
the Group-Topic (GT) model (McCallum, Wang, & Mohanty, 2007) extend LDA to perform
link labeling; the strength of these predicted labels (topics) can also be used to weight the
links. In addition, the GT model directly assigns nodes to groups (i.e., node labeling), while
the labels that ART associates with each link could also be used to label the associated
nodes. The RART model (McCallum, Wang, & Corrada-Emmanuel, 2007) extends ART
by allowing a node to have multiple roles. More recently, Block-LDA (Balasubramanyan
& Cohen, 2011) merges the ideas from these latent variables models with stochastic blockmodels. More specifically, the Block-LDA shares information through three components:
the link model shares information with a block structure which is then shared by the topic
model. Unlike GT and ART, however, Block-LDA focuses on labeling the nodes rather
than the links. Balasubramanyan and Cohen evaluate Block-LDA on a protein dataset and
the Enron email corpus and demonstrate that it outperforms Link-LDA and several other
baselines on the task of protein functional category prediction.
7.4 Discussion
Most of the techniques discussed above are variants of latent group models that focus on
node and/or link label prediction, but they can also be used for node prediction where the
new nodes represent newly discovered topics or latent groups. These models have also been
extended to incorporate notions of time (Dietz, Bickel, & Scheffer, 2007; Wang, Blei, &
Heckerman, 2008; Wang & McCallum, 2006), topic hierarchies (Li & McCallum, 2006), and
correlations between topics (Blei & Lafferty, 2007). In addition, links are usually assumed
to be generated based on the overall topic(s) of a node or link. In contrast, the Latent
Topic Hypertext Model (LTHM) (Gruber, Rosen-Zvi, & Weiss, 2008) models each link as
originating from some specific word in a document. Somewhat surprisingly, they show
that this approach leads to a model with fewer parameters than models like Link-LDA,
and demonstrate that their approach outperforms both Link-LDA and Link-PLSA when
evaluated on a link prediction task.
417

fiRossi, McDowell, Aha, & Neville

(a) Initial Graph

(b) Joint Transformation

Figure 10: Example of Joint Transformation: In this example, new latent nodes
are added to represent discovered topics, and weighted links are added from
each original node to a new latent node. In addition, weighted links are added
between the latent nodes, representing connection strength between these topics.
Finally, new links between the original nodes may be also be predicted. Note
this example is adapted from results found in the work of Nallapati et al. (2008).

If new nodes are added to the graph to represent discovered topics, then links are
invariably added to connect existing nodes to the new nodes. However, some models may
also learn information about how the discovered topics are related to each other. For
instance, Figure 10 shows how two new topics are discovered in a graph and how they are
connected to the existing nodes. In addition, the topics are connected to each other with
new links where the weight of each link represents how frequently a document from that
topic cites a document representing a different topic. Adding these additional links to the
graph lets the original nodes be connected more closely not only to their primary topics but
also to related topics.

8. Discussion and Challenges
In this section we discuss additional issues that are related to relational representation
transformation and highlight important challenges for future work.
8.1 Guiding and Evaluating Representation Transformation
The goal of representation transformation is often to improve the data representation in
some way that leads to better results for a subsequent task or possibly to a more understandable representation. How can we evaluate whether a particular transformation technique
has accomplished this goal? We first address this question, then consider when the final
goal can be used to more directly guide the initial transformation.
For some tasks, representation evaluation is straightforward provided that ground truth
values are known for a hold-out data set. For instance, to test if a technique for link
418

fiTransforming Graph Data for Statistical Relational Learning

prediction is effective, accuracy can be measured for links predicted for the hold-out set
(Taskar et al., 2003; Liu et al., 2009). The particular evaluation metric can be modified as
appropriate for the domain. For instance, Chang and Blei (2009) evaluate the precision of
the twenty highest-ranked links suggested for each document, while Nallapati et al. (2008)
consider a custom metric called RKL that measures the rank of the last true link suggested
by the model. Likewise, if the desired task involves classification, then a classification
algorithm can be run on the hold-out data, with and without the representation change, to
see if the change increases classification accuracy.
In other cases, it may be difficult to directly measure how well a representation change
has performed, but classification can be used as a surrogate measure: if accuracy increases,
the change is assumed to be beneficial. For instance, classification has been used to evaluate link prediction (Gallagher et al., 2008), link weighting (Xiang et al., 2010), link labeling (Rossi & Neville, 2010; Macskassy, 2007), and node prediction (Neville & Jensen,
2005). In addition, node labeling is naturally a classification problem, while node weighting
is usually evaluated in other ways, e.g., based on query relevance.
Other techniques can be used when direct evaluation is not feasible, but there exists
some other metric that is believed to be related. For instance, higher autocorrelation in a
graph can be associated with the presence of more sensible links, and algorithms such as
collective classification typically perform better when the level of autocorrelation is higher.
Thus, Xiang et al. (2010) demonstrate the success of their technique for estimating relationship strengths (link weights) based in part on showing an increase in autocorrelation when
measured for several attributes in a social network. Likewise, increased information gain
for some of the attributes could be used to demonstrate an improved representation (Lippi,
Jaeger, Frasconi, & Passerini, 2009), or link perplexity could be used to assess topic labelings (Balasubramanyan & Cohen, 2011). Naturally, the most appropriate evaluation
techniques vary based upon the task, and a comparison of transformation techniques may
yield different results depending upon what metric is chosen.
Ideally, representation transformation would be guided more directly by the final goal
as it is executed, rather than only being evaluated when the transformation is complete.
This is often the case for the feature selection and structure learning algorithms discussed
in Section 6.3: task accuracy (or a surrogate measure) is evaluated with a particular feature
added, and it is retained if accuracy has improved. In other cases, the transformation is
even more directly specified by the desired end goal. For instance, the supervised random
walk approach discussed in Section 3.3 uses a gradient descent method to obtain new link
weights such that links predicted by a subsequent random walk (their final goal) will be
more accurate. Likewise, Menon and Elkan (2010) show how to add supervision to methods
for generating latent features (see introduction to Section 5) so that the features learned
would be more relevant to their final classification task. They show, however, that adding
such supervision is not always helpful. As a final example, Shi, Li, and Yu (2011) use a
quadratic program to optimize a linear combination of link weights such that the final link
weights will lead directly to more accurate classification via a label propagation algorithm.
In general, ensuring that a particular transformation will improve performance on the
final SRL task remains challenging. Many transformations cannot be directly guided by the
final goal, either because suitable supervised data is not available, or because it is not clear
419

fiRossi, McDowell, Aha, & Neville

how to modify the transformation algorithms to use such information (e.g., with the latent
topic models of Section 7 or the group detection algorithms of Section 5).
8.2 Causal Discovery
Causal discovery refers to identifying cause-and-effect relationships (i.e., smoking causes
cancer) from either online experimentation (Aral & Walker, 2010) or from observational
data. The challenge is to distinguish true causal relationships from mere statistical correlations. One approach is to use quasi-experimental designs (QEDs), which take advantage of
circumstances in non-experimental data to identify situations that provide the equivalent of
experimental control and randomization. Jensen, Fast, Taylor, and Maier (2008) propose a
system to discover knowledge by applying QEDs that were discovered automatically. More
recently, Oktay, Taylor, and Jensen (2010) apply three different QEDs to demonstrate how
one can gain causal understanding of a social media system. There is also another causal
discovery technique for linear models proposed by Wang and Chan (2010). The challenge
remains of how to extend these techniques to apply to a broader range of relational data.
8.3 Subgraph Transformation and Graph Generation
The majority of this article focused on transformation tasks centered around the nodes or
links of the graphs. However, there are also useful tasks for subgraph transformation which
seek to identify frequent/informative substructures in a set of graphs or to create features
or classify such subgraphs (Inokuchi, Washio, & Motoda, 2000; Deshpande, Kuramochi,
Wale, & Karypis, 2005). For instance, Kong and Yu (2010) consider how to use semisupervised techniques to perform feature selection for subgraph classification given only a
few labeled subgraphs. As with nodes and links, for subgraphs the tasks of prediction,
labeling, weighting, and feature generation can all be described. Many of the techniques
that we described for node-centered features can also be used in this context, but a full
discussion of subgraph transformation is beyond the scope of this article.
Recently, graph generation algorithms have attracted significant interest. These algorithms use some model to represent a family of graphs, and present a way to generate multiple samples from this family. Two prominent models are Kronecker Product Graph Models
(KPGMs) (Leskovec, Chakrabarti, et al., 2010) and those based on preferential attachment
(Price, 1976; Barabasi & Albert, 1999). These graph generation methods take advantage
of global (with KPGMs) and local (with preferential attachment models) graph properties
to generate a distribution of graphs that can potentially include attributes. Sampling from
these models can be useful for creating more robust algorithms, for instance by training a
classifier on a family of related graphs instead of on a single graph. Newman (2003) surveys
additional network models and properties that are relevant to graph generation.
8.4 Model Representation
In SRL there is also the notion of model representation: what kind of statistical model is
learned to represent the relationship between the nodes, links, and their features? Some of
the most prominent models for SRL are Probabilistic Relational Models (PRMs) (Friedman
et al., 1999), Relational Markov Networks (RMNs) (Taskar et al., 2002), Relational Depen420

fiTransforming Graph Data for Statistical Relational Learning

dency Networks (RDNs) (Neville & Jensen, 2007), Structural Logistic Regression (Popescul
et al., 2003b), Conditional Random Fields (CRFs) (Lafferty, McCallum, & Pereira, 2001),
and Markov Logic Networks (MLNs) (Domingos & Richardson, 2004; Richardson & Domingos, 2006); full discussion of these models is beyond the scope of this article. In many cases
techniques for relational representation transformation, such as link prediction, can be performed regardless of what kind of statistical model will be subsequently used. However, the
choice of statistical model does strongly interact with what kinds of node and link features
are useful (or even possible to use); Section 6.3 describes some of these connections. While
a number of relevant comparisons have already been published (Jensen et al., 2004; Neville
& Jensen, 2007; Macskassy & Provost, 2007; Sen et al., 2008; McDowell et al., 2009; Crane
& McDowell, 2011), more work is needed to evaluate the interaction between the choice of
statistical model and feature selection, and to evaluate which statistical models work best
in domains with certain characteristics.
8.5 Temporal and Spatial Representation Transformation
Where appropriate, we have already discussed multiple techniques that can incorporate
temporal information from graph data (see especially Sections 4.2, 6.1, and 6.3). These
techniques focused on solving particular problems such as node classification, but dealing
with such data invariably requires studying how to represent the time-varying elements.
However, more work is needed to examine the general tradeoffs involved with different
temporal representations. For instance, Hill, Agarwal, Bell, and Volinsky (2006) provide a
generic framework for modeling any temporal dynamic network where the central goal is to
build an approximate representation that satisfies pre-specified objectives. They focus on
summarization (representing historical behavior between two nodes in a concise manner),
simplification (removing noise from both edges and nodes, spurious transactions, or stale relationships), efficiency (supporting fast analysis and updating), and predictive performance
(optimizing the representation to maximize predictive performance). This work provides a
number of useful building blocks, but more comparisons are needed to, for instance, evaluate the merits of using summarized networks with general-purpose algorithms vs. using
more specialized algorithms with data that maintains the temporal distinctions.
Temporal data is one particular kind of data that can be represented as a relational
sequence. Kersting, De Raedt, Gutmann, Karwath, and Landwehr (2008) survey the area
of relational sequence learning and explains multiple tasks related to such data, such as
sequence mining and alignment. These tasks often involve the need to identify relevant
features or structure, such as identifying frequent patterns or useful similarity functions.
Thus, the set of useful techniques for feature construction and search in this domain overlap
with those discussed in Section 6.3.
8.6 Privacy Preserving Representation
There is sometimes a desire to make private graph-based data publicly available (e.g., to
support research or public policy) in a way that preserves the privacy of the individuals
described by the data. The goal of privacy preserving representation is to transform the
data in a way that minimizes information loss while maximizing anonymization, e.g., to
prevent individuals in the anonymized network from being identified. Naive approaches to
421

fiRossi, McDowell, Aha, & Neville

anonymization operate by simply replacing an individuals name (or other attributes) with
arbitrary and meaningless unique identifiers. However, in social networks there are many
adversarial methods through which the true identity of a user can often be discovered from
such an anonymized network. In particular, the adversarial methods can use the network
structure and/or remaining attributes to discover the identities of users within the network
(Liu & Terzi, 2008; Zhou, Pei, & Luk, 2008; Narayanan & Shmatikov, 2009).
An early approach by Zheleva and Getoor (2007) examines how a graph may be modified
to prevent sensitive relationships (a particular kind of labeled link) from being disclosed.
They describe their approach in terms of node anonymization and edge anonymization.
Node anonymization clusters the nodes into m equivalence classes based on node attributes
only, while most of the edge anonymization approaches are based on cleverly removing
sensitive edges. Backstrom, Dwork, and Kleinberg (2007) address a related family of attacks
where an adversary is able to learn whether an edge exists between targeted pairs of nodes.
More recently, Hay, Miklau, Jensen, Towsley, and Weis (2008) study privacy issues in
graphs that contain no attributes. Their goal is to prevent structural re-identification
(i.e., identity reconstruction using graph topology information) by anonymizing a graph via
creating an aggregate network model that allows for samples to be drawn from the model.
The approach generalizes a graph by partitioning the nodes and then summarizing the graph
at the partition level. This approach differs from the other approaches described above
because it drastically changes the representation as opposed to making more incremental
changes. However, this method enforces privacy while still preserving enough of the network
properties to allow for a wide variety of network analyses to be performed.
In each of these investigations the key factors are the information available in the graph,
the resources of the attacker, and the type of attacks that must be defended against. In
addition, if an attacker can possibly obtain additional information related to the graph
from other sources, then the challenges are even more difficult. More work is needed to
provide strong privacy guarantees while still enabling partial public release of graph-based
information.

9. Conclusion
Given the increasing prevalence and importance of relational data, this article has surveyed
some of the most significant current issues in relational representation transformation. After presenting a new taxonomy of important transformation tasks in Section 2, we next
discussed the four primary tasks of link prediction, link interpretation, node prediction,
and node interpretation. Section 7 considered how some of these tasks can be accomplished
simultaneously via techniques for joint transformation. Finally, Section 8 considered how
to perform representation evaluation and key challenges for future work.
There are additional possible representation transformations that we have not had space
to discuss, or that do not fit cleanly in the taxonomy of Figure 2. For instance, in a bipartite
graph of customers and products, it may be useful to eliminate all product nodes, replacing
their information content with new links among the customers that purchased the same
product. This is somewhat related to the group discovery techniques of Section 5. We
have also not considered in any depth the potential for transforming nodes into edges or
422

fiTransforming Graph Data for Statistical Relational Learning

vice versa (though the representation choices of Figure 6 are also relevant here), and this
technique can sometimes be a useful pre-processing step.
The taxonomy presented in Section 2 highlighted the symmetry between the possible
transformation tasks for links and those for nodes. This symmetry helped to organize this
survey, and also suggests areas where techniques developed for one of these entities can
be used for an analogous task with the other. For instance, Liben-Nowell and Kleinberg
(2007) reformulated traditional node weighting algorithms to weight links. Likewise, topic
discovery techniques based on LDA can be used both for node labeling and for link labeling.
Finally, many of the techniques used to create node features can also be used to create link
features, and vice versa, although node features have been studied much more thoroughly.
As discussed in Section 8, there remains much work to do. For instance, link prediction
remains a very difficult problem, especially for the general case where any two arbitrary
nodes might be connected together. Even more significantly, while we have described a
wide range of techniques that can address each of the transformation tasks, at the end of
the day the practitioner is left with a wide range of choices without many guarantees about
what might work best. For instance, node weighting may improve classification accuracy
for one dataset but decrease it on another. This challenge is made all the more difficult
because the techniques that we have described come from a wide range of areas, including
graph theory, social network analysis, numerical linear algebra (e.g., matrix factorization),
metric learning, information theory, information retrieval, inductive logic programming,
statistical relational learning, and probabilistic graphical models. While the breadth of
techniques relevant to relational transformation is a wonderful resource, it also means that
evaluating the representation change techniques that are relevant to a particular task is
a time-consuming, technically challenging, and incomplete process. Therefore, much more
work is needed to establish a theoretical understanding of how different representation
changes affect the data, how different data characteristics interact with this process, and
how the combination of these techniques and the data characteristics affect the final results
of an analysis with relational data.

Acknowledgments
We thank all the reviewers for many helpful suggestions and feedback. The majority of this
work was completed at the Naval Research Laboratory, where Ryan Rossi was supported
by an ASEE/ONR NREIP summer internship in 2010 and by a NSF Graduate Research
Fellowship (at Purdue University). Luke McDowell was supported in part by NSF award
number 1116439 and by a grant from ONR. This research was also partly supported by
the NSF under the contract number IIS-1149789. The views and conclusions contained
herein are those of the authors and should not be interpreted as necessarily representing
the official policies or endorsements, either expressed or implied, of ONR, NSF, or the U.S.
Government.

References
Adamic, L. A., & Adar, E. (2001). Friends and neighbors on the web. Social Networks,
25 (3), 211230.
423

fiRossi, McDowell, Aha, & Neville

Adibi, J., Chalupsky, H., Melz, E., Valente, A., et al. (2004). The KOJAK group finder:
Connecting the dots via integrated knowledge-based and statistical reasoning. In
Proceedings of the 16th Conference on Innovative Applications of Artifical Intelligence,
pp. 800807.
Adomavicius, G., & Tuzhilin, A. (2005). Toward the next generation of recommender
systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions
on Knowledge and Data Engineering, 17 (5), 734749.
Ahmed, N., Neville, J., & Kompella, R. (2012a). Network sampling designs for relational
classification. In Proceedings of the 6th International AAAI Conference on Weblogs
and Social Media.
Ahmed, N., Neville, J., & Kompella, R. (2012b). Space-efficient sampling from social activity
streams. In BigMine, pp. 18.
Ahmed, N., Berchmans, F., Neville, J., & Kompella, R. (2010). Time-based sampling of
social network activity graphs. In Proceedings of the 8th Workshop on Mining and
Learning with Graphs, pp. 19.
Airoldi, E. M., Blei, D. M., Fienberg, S. E., & Xing, E. P. (2008). Mixed membership
stochastic blockmodels. Journal of Machine Learning Research, 9, 19812014.
Akaike, H. (1974). A new look at the statistical model identification. IEEE Transactions
on Automatic Control, 19 (6), 716723.
Albert, R., Jeong, H., & Barabasi, A. (1999). Internet: Diameter of the world-wide web.
Nature, 401 (6749), 130131.
Amarel, S. (1968). On representations of problems of reasoning about actions. Machine
Intelligence, 3, 131171.
Anthony, A., & desJardins, M. (2007). Data clustering with a relational push-pull model.
In Proceedings of the Seventh IEEE International Conference on Data Mining Workshops, ICDMW 07, pp. 189194.
Aral, S., & Walker, D. (2010). Creating Social Contagion through Viral Product Design: A
Randomized Trial of Peer Influence in Networks. In Proceedings of the 31st International Conference on Information Systems.
Backstrom, L., & Leskovec, J. (2011). Supervised random walks: predicting and recommending links in social networks. In Proceedings of the 4th International Conference
on Web Search and Data Mining, pp. 635644.
Backstrom, L., Dwork, C., & Kleinberg, J. M. (2007). Wherefore art thou r3579x?:
anonymized social networks, hidden patterns, and structural steganography. In Proceedings of the 16th International World Wide Web Conference, pp. 181190.
Balasubramanyan, R., & Cohen, W. (2011). Block-LDA: Jointly modeling entity-annotated
text and entity-entity links. In Proceedings of the 7th SIAM International Conference
on Data Mining.
Barabasi, A., & Albert, R. (1999). Emergence of scaling in random networks. Science,
286 (5439), 509512.
424

fiTransforming Graph Data for Statistical Relational Learning

Barabasi, A., & Crandall, R. (2003). Linked: The new science of networks. American journal
of Physics, 71 (4), 409410.
Basilico, J. B., & Hofmann, T. (2004). Unifying collaborative and content-based filtering.
In Proceedings of the 21st International Conference on Machine Learning, pp. 6572.
Ben-Hur, A., & Noble, W. (2005). Kernel methods for predicting protein-protein interactions. Bioinformatics, 21 (Suppl. 1), 3846.
Benczur, A., Csalogany, K., Sarlos, T., & Uher, M. (2005). Spamrankfully automatic link
spam detection. In Adversarial Information Retrieval on the Web, pp. 2538.
Berkhin, P. (2006). Survey of clustering data mining techniques. Grouping Multidimensional
Data: Recent Advances in Clustering, 10, 2571.
Bharat, K., & Henzinger, M. (1998). Improved algorithms for topic distillation in a hyperlinked environment. In Proceedings of the 21st International SIGIR Conference on
Research and Development in Information Retrieval, pp. 104111.
Bhattacharya, I., & Getoor, L. (2005). Relational clustering for multi-type entity resolution.
In Proceedings of the 4th International workshop on Multi-relational Mining, pp. 312.
Bhattacharya, I., & Getoor, L. (2007). Collective entity resolution in relational data. Transactions on Knowledge Discovery from Data, 1 (1), 136.
Biba, M., Ferilli, S., & Esposito, F. (2008). Discriminative structure learning of Markov
logic networks. Inductive Logic Programming, 5194, 5976.
Bilgic, M., Mihalkova, L., & Getoor, L. (2010). Active learning for networked data. In
Proceedings of the 27th International Conference on Machine Learning.
Bilgic, M., Namata, G. M., & Getoor, L. (2007). Combining collective classification and link
prediction. In Proceedings of the 7th IEEE International Conference on Data Mining
Workshops, pp. 381386.
Blei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet allocation. Journal of Machine
Learning Research, 3, 9931022.
Blei, D., & Lafferty, J. (2007). A correlated topic model of science. The Annals of Applied
Statistics, 1 (1), 1735.
Bonacich, P., & Lloyd, P. (2001). Eigenvector-like measures of centrality for asymmetric
relations. Social Networks, 23 (3), 191201.
Borgman, C., & Furner, J. (2002). Scholarly communication and bibliometrics. Annual
Review of Information Science and Technology, 36, 372.
Brightwell, G., & Winkler, P. (1990). Maximum hitting time for random walks on graphs.
Random Structures & Algorithms, 1 (3), 263276.
Broder, A., Kumar, R., Maghoul, F., Raghavan, P., Rajagopalan, S., Stata, R., Tomkins,
A., & Wiener, J. (2000). Graph structure in the web. Computer networks, 33 (1-6),
309320.
Burges, C. (1998). A tutorial on support vector machines for pattern recognition. Data
mining and knowledge discovery, 2 (2), 121167.
425

fiRossi, McDowell, Aha, & Neville

Cafarella, M. J., Wu, E., Halevy, A., Zhang, Y., & Wang, D. Z. (2008). Webtables: Exploring
the power of tables on the web. In Proceedings of VLDB, pp. 538549.
Camacho, J., Guimera, R., & Nunes Amaral, L. (2002). Robust patterns in food web
structure. Physical Review Letters, 88 (22), 228102: 14.
Chakrabarti, S., Dom, B., & Indyk, P. (1998). Enhanced hypertext categorization using
hyperlinks. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 307318.
Chakrabarti, S., Dom, B., Raghavan, P., Rajagopalan, S., Gibson, D., & Kleinberg, J.
(1998). Automatic resource compilation by analyzing hyperlink structure and associated text. Computer Networks and ISDN Systems, 30 (1-7), 6574.
Chang, J., & Blei, D. (2009). Relational topic models for document networks. In The
9th International Conference on Artificial Intelligence and Statistics (AISTATS), pp.
8188.
Chang, J., Boyd-Graber, J., & Blei, D. (2009). Connections between the lines: augmenting
social networks with text. In Proceedings of the 15th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 169178.
Clauset, A., Moore, C., & Newman, M. (2008). Hierarchical structure and the prediction
of missing links in networks. Nature, 453 (7191), 98101.
Cohn, D., & Chang, H. (2000). Learning to probabilistically identify authoritative documents. In Proceedings of the 17th International Conference on Machine Learning, pp.
167174.
Cohn, D., & Hofmann, T. (2001). The missing link-a probabilistic model of document content and hypertext connectivity. Advances in Neural Information Processing Systems,
13, 430436.
Crane, R., & McDowell, L. K. (2011). Evaluating markov logic networks for collective
classification. In Proceedings of the 9th MLG Workshop at the 17th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining.
Craven, M., DiPasquo, D., Freitag, D., McCallum, A., Mitchell, T., Nigam, K., & Slattery,
S. (2000). Learning to construct knowledge bases from the World Wide Web. Artificial
Intelligence, 118 (1-2), 69113.
Cristianini, N., & Shawe-Taylor, J. (2000). An Introduction to Support Vector Machines
and other kernel-based learning methods. Cambridge University Press.
Dash, M., & Liu, H. (1997). Feature selection for classification. Intelligent data analysis,
1 (3), 131156.
Davis, J., Burnside, E., Castro Dutra, I., Page, D., & Costa, V. (2005). An integrated
approach to learning Bayesian networks of rules. In Proceedings of the European
Conference on Machine Learning, pp. 8495.
Davis, J., Ong, I., Struyf, J., Burnside, E., Page, D., & Costa, V. S. (2007). Change of representation for statistical relational learning. In Proceedings of the 20th International
Joint Conference on Artificial Intelligence, pp. 27192725.
426

fiTransforming Graph Data for Statistical Relational Learning

De Raedt, L. (2008). Logical and relational learning. Springer.
De Raedt, L., & Kersting, K. (2008). Probabilistic inductive logic programming. SpringerVerlag.
De Raedt, L., & Thon, I. (2010). Probabilistic rule learning. Inductive Logic Programming,
6489, 4758.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).
Indexing by latent semantic analysis. Journal of the American Society for Information
Science, 41, 391407.
Deshpande, M., Kuramochi, M., Wale, N., & Karypis, G. (2005). Frequent substructurebased approaches for classifying chemical compounds. IEEE Transactions on Knowledge and Data Engineering, 13, 10361050.
Dhillon, I. (2001). Co-clustering documents and words using bipartite spectral graph partitioning. In Proceedings of the seventh ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 269274.
Dietz, L., Bickel, S., & Scheffer, T. (2007). Unsupervised prediction of citation influences. In
Proceedings of the 24th International Conference on Machine Learning, pp. 233240.
Domingos, P., & Richardson, M. (2004). Markov logic: A unifying framework for statistical
relational learning. In Proceedings of the ICML Workshop on Statistical Relational
Learning, pp. 4954.
DuBois, C., & Smyth, P. (2010). Modeling Relational Events via Latent Classes. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, pp. 803812.
Dunne, J., Williams, R., & Martinez, N. (2002). Food-web structure and network theory:
the role of connectance and size. Proceedings of the National Academy of Sciences of
the United States of America, 99 (20), 12917.
Easley, D., & Kleinberg, J. (2010). Networks, Crowds, and Markets: Reasoning About a
Highly Connected World. Cambridge University Press.
Eckart, C., & Young, G. (1936). The approximation of one matrix by another of lower rank.
Psychometrika, 1 (3), 211218.
Egghe, L., & Rousseau, R. (1990). Introduction to informetrics. Elsevier Science Publishers.
Erosheva, E., Fienberg, S., & Lafferty, J. (2004). Mixed-membership models of scientific
publications. Proceedings of the National Academy of Sciences of the United States of
America, 101 (Suppl 1), 5220.
Essen, U., & Steinbiss, V. (1992). Cooccurrence smoothing for stochastic language modeling. In Proceedings of the International Conference on Acoustics, Speech, and Signal
Processing, pp. 161164.
Faloutsos, M., Faloutsos, P., & Faloutsos, C. (1999). On power-law relationships of the
internet topology. In Proceedings of the ACM SIGCOMM International Conference
on Applications, Technologies, Architectures, and Protocols for Computer Communication, pp. 251262.
427

fiRossi, McDowell, Aha, & Neville

Fast, A., & Jensen, D. (2008). Why stacked models perform effective collective classification.
In Proceedings of the IEEE International Conference on Data Mining, pp. 785790.
Fodor, I. (2002). A Survey of Dimension Reduction Techniques. US DOE Office of Scientific
and Technical Information, 18.
Frank, R., Moser, F., & Ester, M. (2007). A method for multi-relational classification
using single and multi-feature aggregation functions. Proceedings of the Principles
and Practice of Knowledge Discovery in Databases, 1, 430437.
Freeman, L. C. (1977). A set of measures of centrality based on betweenness. Sociometry,
40, 3541.
Friedman, J. (2001). Greedy function approximation: A gradient boosting machine.. The
Annals of Statistics, 29 (5), 11891232.
Friedman, N., Getoor, L., Koller, D., & Pfeffer, A. (1999). Learning probabilistic relational models. In Proceedings of the 16th International Joint Conference on Artificial
Intelligence, pp. 13001309. Springer-Verlag.
Gallagher, B., Tong, H., Eliassi-Rad, T., & Faloutsos, C. (2008). Using ghost edges for
classification in sparsely labeled networks. In Proceedings of the 14th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, pp. 256264.
Gartner, T. (2003). A survey of kernels for structured data. ACM SIGKDD Explorations
Newsletter, 5 (1), 4958.
George, E., & McCulloch, R. (1993). Variable selection via Gibbs sampling. Journal of the
American Statistical Association, 88, 881889.
Getoor, L., Friedman, N., Koller, D., & Taskar, B. (2003). Learning probabilistic models of
link structure. Journal of Machine Learning Research, 3, 679707.
Getoor, L., & Taskar, B. (Eds.). (2007). Introduction to Statistical Relational Learning.
MIT Press.
Getoor, L., & Diehl, C. P. (2005). Link mining. SIGKDD Explorations, 7, 312.
Getoor, L., Friedman, N., Koller, D., & Taskar, B. (2001). Learning probabilistic models of
relational structure. In Proceedings of International Conference on Machine Learning,
pp. 170177.
Gibson, D., Kleinberg, J., & Raghavan, P. (1998). Inferring web communities from link
topology. In Proceedings of the 9th ACM Conference on Hypertext and Hypermedia,
pp. 225234.
Gilbert, E., & Karahalios, K. (2009). Predicting tie strength with social media. In Proceedings of the 27th CHI International Conference on Human Factors in Computing
Systems, pp. 211220.
Girvan, M., & Newman, E. J. (2002). Community structure in social and biological networks.
Proceedings of the National Academy of Sciences, 99 (12), 78217826.
Goadrich, M., & Shavlik, J. (2007). Combining clauses with various precisions and recalls
to produce accurate probabilistic estimates. In Proceedings of the 17th International
Conference on Inductive Logic Programming, pp. 122131.
428

fiTransforming Graph Data for Statistical Relational Learning

Gobel, F., & Jagers, A. (1974). Random walks on graphs. Stochastic processes and their
applications, 2 (4), 311336.
Godbole, N., Srinivasaiah, M., & Skiena, S. (2007). Large-scale sentiment analysis for news
and blogs. In Proceedings of the International Conference on Weblogs and Social
Media.
Golub, G., & Reinsch, C. (1970). Singular value decomposition and least squares solutions.
Numerische Mathematik, 14 (5), 403420.
Green, J. (1972). Latitudinal variation in associations of planktonic Rotifera. Journal of
zoology, 167 (1), 3139.
Gruber, A., Rosen-Zvi, M., & Weiss, Y. (2008). Latent topic models for hypertext. In
Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, pp. 230
239.
Guyon, I., & Elisseeff, A. (2003). An introduction to variable and feature selection. Journal
of Machine Learning Research, 3, 11571182.
Gyongyi, Z., Garcia-Molina, H., & Pedersen, J. (2004). Combating web spam with trustrank.
In Proceedings of VLDB, pp. 576587.
Hannan, E., & Quinn, B. (1979). The determination of the order of an autoregression.
Journal of the Royal Statistical Society. Series B (Methodological), 41, 190195.
Harshman, R. (1970). Foundations of the PARAFAC procedure: Models and conditions
for an explanatory multi-modal factor analysis. UCLA Working Papers in Phonetics,
16 (1), 84.
Hartigan, J., & Wong, M. (1979). A k-means clustering algorithm. Journal of the Royal
Statistical Society. Series C, Applied statistics, 28, 100108.
Hasan, M. A., Chaoji, V., Salem, S., & Zaki, M. (2006). Link prediction using supervised
learning. In Proceedings of the SDM Workshop on Link Analysis, Counterterrorism
and Security.
Haveliwala, T. (2003). Topic-sensitive pagerank: A context-sensitive ranking algorithm for
web search. IEEE transactions on knowledge and data engineering, 15, 784796.
Hay, M., Miklau, G., Jensen, D., Towsley, D., & Weis, P. (2008). Resisting structural reidentification in anonymized social networks. In Proceedings of VLDB, pp. 102114.
He, D., & Parker, D. (2010). Topic Dynamics: an alternative model of Bursts in Streams
of Topics. In Proceeding of the 16th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 443452.
Henderson, K., Gallagher, B., Li, L., Akoglu, L., Eliassi-Rad, T., Tong, H., & Faloutsos,
C. (2011). Its Who You Know: Graph Mining Using Recursive Structural Features.
In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 110.
Hill, S., Agarwal, D., Bell, R., & Volinsky, C. (2006). Building an effective representation
for dynamic networks. Journal of Computational and Graphical Statistics, 15 (3),
584608.
429

fiRossi, McDowell, Aha, & Neville

Hoff, P., Raftery, A., & Handcock, M. (2002). Latent space approaches to social network
analysis. Journal of the American Statistical Association, 97 (460), 10901098.
Hofmann, T. (1999). Probabilistic latent semantic analysis. In Proceedings of Uncertainty
in Artificial Intelligence, pp. 289296.
Huh, S., & Fienberg, S. (2010). Discriminative Topic Modeling based on Manifold Learning.
In Proceeding of the 16th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 653661.
Huynh, T., & Mooney, R. (2008). Discriminative structure and parameter learning for
markov logic networks. In Proceedings of the 25th International Conference on Machine Learning.
Inokuchi, A., Washio, T., & Motoda, H. (2000). An apriori-based algorithm for mining
frequent substructures from graph data. In Principles of Data Mining and Knowledge
Discovery, pp. 1323.
Jaccard, P. (1901). Etude comparative de la distribution florale dans une portion des Alpes
et du Jura. Impr. Corbaz.
Jackson, M. (2008). Social and economic networks. Princeton Univ Press.
Jain, A., & Zongker, D. (1997). Feature selection: Evaluation, application, and small sample performance. IEEE Transactions on Pattern Analysis and Machine Intelligence,
19 (2), 153158.
Jeh, G., & Widom, J. (2002). SimRank: A measure of structural-context similarity. In
Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 538543.
Jensen, D., & Neville, J. (2002). Linkage and autocorrelation cause feature selection bias in
relational learning. In Proceedings of the 19th International Conference on Machine
Learning, pp. 259266.
Jensen, D., Neville, J., & Gallagher, B. (2004). Why collective inference improves relational
classification. In Proceedings of the 10th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 593598.
Jensen, D., Neville, J., & Hay, M. (2003). Avoiding bias when aggregating relational data
with degree disparity. In Proceedings of the 20th International Conference on Machine
Learning, pp. 274281.
Jensen, D., Fast, A., Taylor, B., & Maier, M. (2008). Automatic identification of quasiexperimental designs for discovering causal knowledge. In Proceeding of the 14th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pp. 372380.
Jeong, H., Mason, S., Barabasi, A., & Oltvai, Z. (2001). Lethality and centrality in protein
networks. Nature, 411 (6833), 4142.
Jeong, H., Tombor, B., Albert, R., Oltvai, Z., & Barabasi, A. (2000). The large-scale
organization of metabolic networks. Nature, 407 (6804), 651654.
430

fiTransforming Graph Data for Statistical Relational Learning

Joachims, T. (1998). Text categorization with support vector machines: Learning with many
relevant features. In Proceedings of the European Conference on Machine Learning,
pp. 137142.
Johnson, S. (1967). Hierarchical clustering schemes. Psychometrika, 32 (3), 241254.
Kahanda, I., & Neville, J. (2009). Using transactional information to predict link strength in
online social networks. In Proceedings of the 4th International Conference on Weblogs
and Social Media, pp. 106113.
Kamvar, S., Klein, D., & Manning, C. (2003). Spectral learning. In Proceedings of the 18th
International Joint Conference On Artificial Intelligence, pp. 561566.
Kashima, H., & Abe, N. (2006). A parameterized probabilistic model of network evolution
for supervised link prediction. In Proceedings of the IEEE International Conference
on Data Mining, pp. 340349.
Katz, L. (1953). A new status index derived from sociometric analysis. Psychometrika,
18 (1), 3943.
Kavurucu, Y., Senkul, P., & Toroslu, I. (2008). Aggregation in confidence-based concept discovery for multi-relational data mining. In Proceedings of IADIS European Conference
on Data Mining, pp. 4352.
Kersting, K., & De Raedt, L. (2002). Basic principles of learning Bayesian logic programs.
Tech. rep. 174, Institute for Computer Science, University of Freiburg.
Kersting, K., De Raedt, L., Gutmann, B., Karwath, A., & Landwehr, N. (2008). Relational
sequence learning. Probabilistic inductive logic programming, 4911, 2855.
Khosravi, H., Tong Man, O., Xu, X., & Bina, B. (2010). Structure learning for markov logic
networks with many descriptive attributes. In Proceedings of the 24th Conference on
Artificial Intelligence, pp. 487493.
Khot, T., Natarajan, S., Kersting, K., & Shavlik, J. (2011). Learning markov logic networks via functional gradient boosting. In Data Mining (ICDM), 2011 IEEE 11th
International Conference on, pp. 320329. IEEE.
Kim, M., & Leskovec, J. (2011). The network completion problem: Inferring missing nodes
and edges in networks. In Proceedings of the SIAM International Conference on Data
Mining.
Kleczkowski, A., & Grenfell, B. (1999). Mean-field-type equations for spread of epidemics:
the small worldmodel. Physica A: Statistical Mechanics and its Applications, 274 (12), 355360.
Kleinberg, J. (1999). Authoritative sources in a hyperlinked environment. Journal of the
ACM, 46 (5), 604632.
Knobbe, A., Siebes, A., & Marseille, B. (2002). Involving aggregate functions in multirelational search. In Principles of Data Mining and Knowledge Discovery, pp. 145
168.
Kohavi, R., & John, G. (1997). Wrappers for feature subset selection. Artificial intelligence,
97 (1-2), 273324.
431

fiRossi, McDowell, Aha, & Neville

Kohonen, T. (1990). The self-organizing map. Proceedings of the IEEE, 78 (9), 14641480.
Kok, S., & Domingos, P. (2005). Learning the structure of Markov logic networks. In
Proceedings of the 22nd International Conference on Machine Learning, pp. 441448.
Kok, S., & Domingos, P. (2007). Statistical predicate invention. In Proceedings of the 24th
International Conference on Machine Learning, pp. 433440.
Kok, S., & Domingos, P. (2008). Extracting semantic networks from text via relational clustering. In Proceedings of the European Conference on Machine Learning and Principles
and Practice of Knowledge Discovery in Databases, pp. 624639.
Kok, S., & Domingos, P. (2009). Learning markov logic network structure via hypergraph
lifting. In Proceedings of the 26th International Conference on Machine Learning, pp.
505512.
Kok, S., & Domingos, P. (2010). Learning markov logic networks using structural motifs.
In Proceedings of the 27th International Conference on Machine Learning.
Kolda, T. G., Bader, B. W., & Kenny, J. P. (2005). Higher-order web link analysis using
multilinear algebra. In Proceedings of the IEEE International Conference on Data
Mining, pp. 242249.
Kolda, T., & Bader, B. (2006). The TopHITS model for higher-order web link analysis.
In Proceedings of the SIAM Data Mining Conference Workshop on Link Analysis,
Counterterrorism and Security, pp. 2629.
Koller, D., & Sahami, M. (1996). Toward optimal feature selection. In Proceedings of the
13th International Conference on Machine Learning, pp. 284292.
Kondor, R., & Lafferty, J. (2002). Diffusion kernels on graphs and other discrete structures.
In Proceedings of the 19th International Conference on Machine Learning, pp. 315
322.
Kong, X., & Yu, P. (2010). Semi-supervised feature selection for graph classification. In Proceeding of the 16th ACM SIGKDD International Conference on Knowledge Discovery
in Data Mining, pp. 793802.
Koren, Y., North, S., & Volinsky, C. (2007). Measuring and extracting proximity graphs
in networks. Transactions on Knowledge Discovery from Data (TKDD), 1 (3), 12:1
12:30.
Kosala, R., & Blockeel, H. (2000). Web Mining Research: A Survey. ACM SIGKDD
Explorations Newsletter, 2 (1), 115.
Kossinets, G., Kleinberg, J., & Watts, D. (2008). The structure of information pathways in a
social communication network. In Proceeding of the 14th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 435443.
Kou, Z., & Cohen, W. (2007). Stacked graphical models for efficient inference in markov
random fields. In Proceedings of the 7th SIAM International Conference on Data
Mining, pp. 533538.
Krebs, V. (2002). Mapping networks of terrorist cells. Connections, 24 (3), 4352.
432

fiTransforming Graph Data for Statistical Relational Learning

Krogel, M., & Wrobel, S. (2001). Transformation-based learning using multirelational aggregation. Inductive logic programming, 2157, 142155.
Kubica, J., Moore, A., Schneider, J., & Yang, Y. (2002). Stochastic link and group detection.
In Proceedings of the 18th AAAI Conference on Artificial Intelligence, pp. 798806.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th
International Conference on Machine Learning, pp. 282289.
Landwehr, N., Kersting, K., & De Raedt, L. (2005). nFOIL: Integrating nave bayes and
FOIL. In Proceedings of the 20th AAAI Conference on Artificial Intelligence, pp.
275282.
Landwehr, N., Passerini, A., De Raedt, L., & Frasconi, P. (2010). Fast learning of relational
kernels. Machine learning, 78 (3), 305342.
Langville, A., & Meyer, C. (2005). A Survey of Eigenvector Methods for Web Information
Retrieval. SIAM Review, 47 (1), 135161.
Lassez, J.-L., Rossi, R., & Jeev, K. (2008). Ranking links on the web: Search and surf
engines. In IEA/AIE, pp. 199208.
Lee, L. (1999). Measures of distributional similarity. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,
pp. 2532.
Leicht, E., Holme, P., & Newman, M. (2006). Vertex similarity in networks. Physical Review
E, 73 (2), 026120.
Leiva, H. A., Gadia, S., & Dobbs, D. (2002). Mrdtl: A multi-relational decision tree learning
algorithm. In Proceedings of the 13th International Conference on Inductive Logic
Programming, pp. 3856.
Lempel, R., & Moran, S. (2000). The stochastic approach for link-structure analysis
(SALSA) and the TKC effect. Computer Networks, 33 (1-6), 387401.
Leskovec, J., Chakrabarti, D., Kleinberg, J., Faloutsos, C., & Ghahramani, Z. (2010). Kronecker graphs: An approach to modeling networks. Journal of Machine Learning
Research, 11, 9851042.
Leskovec, J., Huttenlocher, D., & Kleinberg, J. (2010). Predicting positive and negative
links in online social networks. In Proceedings of the 19th International World Wide
Web Conference, pp. 641650.
Letovsky, S., & Kasif, S. (2003). Predicting protein function from protein/protein interaction
data: a probabilistic approach. Bioinformatics, 19 (Suppl 1), i197.
Li, W., & McCallum, A. (2006). Pachinko allocation: DAG-structured mixture models of
topic correlations. In Proceedings of the 23rd International Conference on Machine
Learning, pp. 577584.
Liben-Nowell, D., & Kleinberg, J. (2007). The link-prediction problem for social networks.
Journal of the American Society for Information Science and Technology, 58 (7), 1019
1031.
433

fiRossi, McDowell, Aha, & Neville

Lichtenwalter, R., Lussier, J., & Chawla, N. (2010). New Perspectives and Methods in Link
Prediction. In Proceeding of the 16th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 243252.
Lim, T., Loh, W., & Shih, Y. (2000). A comparison of prediction accuracy, complexity, and
training time of thirty-three old and new classification algorithms. Machine Learning,
40 (3), 203228.
Lin, D. (1998). An information-theoretic definition of similarity. In Proceedings of the 15th
International Conference on Machine Learning, pp. 296304.
Lin, F., & Cohen, W. W. (2010). Semi-supervised classification of network data using
very few labels. In Proceedings of the International Conference on Advances in Social
Network Analysis and Mining.
Lippi, M., Jaeger, M., Frasconi, P., & Passerini, A. (2009). Relational information gain.
Machine Learning, 83 (2), 121.
Liu, K., & Terzi, E. (2008). Towards identity anonymization on graphs. In Proceedings of
the ACM SIGMOD International Conference on Management of Data, pp. 93106.
Liu, W., & Lu, L. (2010). Link prediction based on local random walk. Europhysics Letters,
89, 58007.
Liu, Y., Niculescu-Mizil, A., & Gryc, W. (2009). Topic-link LDA: joint models of topic and
author community. In Proceedings of the 26th International Conference on Machine
Learning, pp. 665672.
Long, B., Zhang, Z., & Yu, P. (2007). A probabilistic framework for relational clustering.
In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 470479.
Long, B., Zhang, Z., Wu, X., & Yu, P. S. (2006). Spectral clustering for multi-type relational
data. In Proceedings of the 23rd International Conference on Machine Learning, pp.
585592.
Lu, C., Hu, X., Chen, X., & ran Park, J. (2010). The Topic-Perspective Model for Social
Tagging Systems. In Proceeding of the 16th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 683692.
Lu, Q., & Getoor, L. (2003). Link-based classification. In Proceedings of the 20th International Conference on Machine Learning, pp. 496503.
Macskassy, S., & Provost, F. (2003). A simple relational classifier. In Proceedings of the
SIGKDD 2nd Workshop on Multi-Relational Data Mining, pp. 6476.
Macskassy, S., & Provost, F. (2007). Classification in networked data: A toolkit and a
univariate case study. Journal of Machine Learning Research, 8, 935983.
Macskassy, S. A. (2007). Improving learning in networked data by combining explicit and
mined links. In Proceedings of the 22nd AAAI Conference on Artificial Intelligence,
pp. 590595.
Maes, F., Peters, S., Denoyer, L., & Gallinari, P. (2009). Simulated iterative classification a new learning procedure for graph labeling. Machine Learning and Knowledge
Discovery in Databases, 5782, 4762.
434

fiTransforming Graph Data for Statistical Relational Learning

Mallows, C. (1973). Some comments on Cp . Technometrics, 42 (1), 8794.
Maslov, S., & Sneppen, K. (2002). Specificity and stability in topology of protein networks.
Science, 296 (5569), 910913.
May, R., & Lloyd, A. (2001). Infection dynamics on scale-free networks. Physical Review
E, 64 (6), 66112.
McCallum, A., Wang, X., & Corrada-Emmanuel, A. (2007). Topic and role discovery in
social networks with experiments on enron and academic email. In Journal of Artificial
Intelligence Research, pp. 249272.
McCallum, A., Wang, X., & Mohanty, N. (2007). Joint group and topic discovery from
relations and text. In Statistical Network Analysis: Models, Issues and New Directions,
Lecture Notes in Computer Science 4503, pp. 2844.
McDowell, L., Gupta, K., & Aha, D. (2009). Cautious collective classification. Journal of
Machine Learning Research, 10, 27772836.
McDowell, L., Gupta, K., & Aha, D. (2007). Cautious inference in collective classification.
In Proceedings of the 22nd AAAI Conference on Artificial Intelligence.
McDowell, L., Gupta, K., & Aha, D. (2010). Meta-Prediction for Collective Classification.
In Proceedings of the 23rd International FLAIRS Conference.
McGovern, A., Friedland, L., Hay, M., Gallagher, B., Fast, A., Neville, J., & Jensen, D.
(2003). Exploiting relational structure to understand publication patterns in highenergy physics. SIGKDD Explorations, 5 (2), 165172.
McGovern, A., Collier, N., Matthew Gagne, I., Brown, D., & Rodger, A. (2008). Spatiotemporal Relational Probability Trees: An Introduction. In Eighth IEEE International
Conference on Data Mining, ICDM., pp. 935940.
Menon, A., & Elkan, C. (2011). Link prediction via matrix factorization. In Proceedings of
the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, pp. 437452.
Menon, A., & Elkan, C. (2010). Predicting labels for dyadic data. Data Mining and
Knowledge Discovery, 21 (2), 327343.
Michie, D., Spiegelhalter, D., Taylor, C., & Campbell, J. (1994). Machine Learning, Neural
and Statistical Classification. Ellis Horwood Limited.
Mihalkova, L., & Mooney, R. (2007). Bottom-up learning of Markov logic network structure.
In Proceedings of the 24th International Conference on Machine Learning, pp. 625
632.
Miller, K., Griffiths, T., & Jordan, M. (2009). Nonparametric latent feature models for link
prediction. Advances in Neural Information Processing Systems (NIPS), 10, 1276
1284.
Minsky, M. (1974). A framework for representing knowledge. Tech. rep., Massachusetts
Institute of Technology, Cambridge, MA, USA.
Mislove, A., Marcon, M., Gummadi, K., Druschel, P., & Bhattacharjee, B. (2007). Measurement and analysis of online social networks. In Proceedings of the 7th ACM SIGCOMM
Conference on Internet measurement, pp. 2942.
435

fiRossi, McDowell, Aha, & Neville

Moore, C., & Newman, M. (2000). Epidemics and percolation in small-world networks.
Physical Review E, 61 (5), 56785682.
Moreno, S., & Neville, J. (2009). An investigation of the distributional characteristics
of generative graph models. In Proceedings of the 1st Workshop on Information in
Networks.
Nallapati, R., Ahmed, A., Xing, E., & Cohen, W. (2008). Joint latent topic models for text
and citations. In Proceeding of the 14th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 542550.
Namata, G., Kok, S., & Getoor, L. (2011). Collective graph identification. In Proceedings of
the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, pp. 8795. ACM.
Narayanan, A., & Shmatikov, V. (2009). De-anonymizing social networks. In Proceedings
of the 30th IEEE Symposium on Security and Privacy, pp. 173187.
Natarajan, S., Khot, T., Kersting, K., Gutmann, B., & Shavlik, J. (2012). Gradient-based
boosting for statistical relational learning: The relational dependency network case.
Machine Learning, 86, 2556.
Neville, J., Adler, M., & Jensen, D. (2004). Spectral clustering with links and attributes.
Tech. rep. 04-42, Dept of Computer Science, University of Massachusetts Amherst.
Neville, J., & Jensen, D. (2000). Iterative classification in relational data. In Proceedings of
the Workshop on SRL, 17th AAAI Conference on Artificial Intelligence, pp. 4249.
Neville, J., & Jensen, D. (2005). Leveraging relational autocorrelation with latent group
models. In Proceedings of the 5th IEEE International Conference on Data Mining,
pp. 322329.
Neville, J., & Jensen, D. (2007). Relational dependency networks. Journal of Machine
Learning Research, 8, 653692.
Neville, J., Jensen, D., Friedland, L., & Hay, M. (2003). Learning relational probability
trees. In Proceedings of the 9th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 625630.
Neville, J., Jensen, D., & Gallagher, B. (2003). Simple estimators for relational Bayesian
classifers. In Proceedings of the 3rd IEEE International Conference on Data Mining,
pp. 609612.
Neville, J., Simsek, O., Jensen, D., Komoroske, J., Palmer, K., & Goldberg, H. (2005). Using
relational knowledge discovery to prevent securities fraud. In Proceedings of the 11th
ACM SIGKDD International Conference on Knowledge Discovery in Data Mining,
pp. 449458.
Newman, M. (2010). Networks: An Introduction. Oxford Univ Press.
Newman, M. E. J. (2003). The structure and function of complex networks. SIAM Review,
45, 167256.
Newman, M. (2001a). Clustering and preferential attachment in growing networks. Physical
Review E, 64 (2), 025102.
436

fiTransforming Graph Data for Statistical Relational Learning

Newman, M. (2001b). The structure of scientific collaboration networks. Proceedings of the
National Academy of Sciences, 98 (2), 404409.
Newman, M., & Girvan, M. (2004). Finding and evaluating community structure in networks. Physical review E, 69 (2), 26113.
Ng, A., Jordan, M., & Weiss, Y. (2001). On spectral clustering: Analysis and an algorithm.
In Advances in Neural Information Processing Systems, pp. 849856.
Nie, L., Davison, B., & Qi, X. (2006). Topical link analysis for web search. In Proceedings
of the 29th International ACM SIGIR Conference on Research and Development in
Information Retrieval, p. 98.
Nowicki, K., & Snijders, T. (2001). Estimation and prediction for stochastic blockstructures.
Journal of the American Statistical Association, 96, 10771087.
Oktay, H., Taylor, B., & Jensen, D. (2010). Causal Discovery in Social Media Using QuasiExperimental Designs. In Proceedings of the ACM SIGKDD 1st Workshop on Social
Media Analytics (SOMA-KDD).
Onnela, J.-P., Saramaki, J., Hyvonen, J., Szabo, G., Lazer, D., Kaski, K., Kertesz, J., &
Barabasi, A.-L. (2007). Structure and tie strengths in mobile communication networks.
Proceedings of the National Academy of Sciences, 104, 73327336.
Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). The pagerank citation ranking:
Bringing order to the web. Tech. rep., Technical Report, Stanford Digital Library
Technologies Project.
Pang, B., & Lee, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends
in Information Retrieval, 2 (1-2), 1135.
Pastor-Satorras, R., & Vespignani, A. (2001). Epidemic spreading in scale-free networks.
Physical Review Letters, 86 (14), 32003203.
Pasula, H., Marthi, B., Milch, B., Russell, S., & Shpitser, I. (2003). Identity uncertainty
and citation matching. In In NIPS. MIT Press.
Perlich, C., & Provost, F. (2003). Aggregation-based feature invention and relational concept classes. In Proceedings of the 9th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 167176.
Perlich, C., & Provost, F. (2006). Acora: Distribution-based aggregation for relational
learning from identifier attributes. Machine Learning, 62, 65105.
Poole, D. (2003). First-order probabilistic inference. In International Joint Conference on
Artificial Intelligence, pp. 985991.
Popescul, A., Popescul, R., & Ungar, L. H. (2003a). Statistical relational learning for
link prediction. In Proceedings of the Workshop on Learning Statistical Models from
Relational Data at IJCAI.
Popescul, A., Popescul, R., & Ungar, L. H. (2003b). Structural logistic regression for link
analysis. In Proceedings of the Second International Workshop on Multi-Relational
Data Mining, pp. 92106.
437

fiRossi, McDowell, Aha, & Neville

Popescul, A., & Ungar, L. H. (2004). Cluster-based concept invention for statistical relational learning. In Proceedings of the 10th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 665670.
Price, D. (1976). A general theory of bibliometric and other cumulative advantage processes.
Journal of the American Society for Information Science, 27 (5), 292306.
Pudil, P., Novovicova, J., & Kittler, J. (1994). Floating search methods in feature selection.
Pattern recognition letters, 15 (11), 11191125.
Radicchi, F., Castellano, C., Cecconi, F., Loreto, V., & Parisi, D. (2004). Defining and
identifying communities in networks. Proceedings of the National Academy of Sciences,
101 (9), 26582663.
Rattigan, M. J., & Jensen, D. (2005). The case for anomalous link discovery. SIGKDD
Explorations Newsletter, 7 (2), 4147.
Ravasz, E., Somera, A., Mongru, D., Oltvai, Z., & Barabasi, A. (2002). Hierarchical organization of modularity in metabolic networks. Science, 297 (5586), 15511555.
Resnick, P., & Varian, H. (1997). Recommender systems. Communications of the ACM,
40 (3), 5658.
Richardson, M., & Domingos, P. (2002). The intelligent surfer: Probabilistic combination
of link and content information in pagerank. In Advances in Neural Information
Processing Systems, pp. 14411448.
Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine Learning, 62 (1),
107136.
Riedel, S., & Meza-Ruiz, I. (2008). Collective semantic role labelling with markov logic. In
Proceedings of the Twelfth Conference on Computational Natural Language Learning,
pp. 193197.
Robins, G., Pattison, P., Kalish, Y., & Lusher, D. (2007). An introduction to exponential
random graph (p*) models for social networks. Social Networks, 29, 173191.
Robins, G., Snijders, T., Wang, P., & Handcock, M. (2006). Recent developments in exponential random graph (p*) models for social networks. Social Networks, 29, 192215.
Rossi, R., Gallagher, B., Neville, J., & Henderson, K. (2012). Dynamic behavioral mixedmembership model for large evolving networks. In Arxiv preprint arXiv:1205.2056,
pp. 117.
Rossi, R., & Neville, J. (2010). Modeling the evolution of discussion topics and communication to improve relational classification. In Proceedings of the ACM SIGKDD 1st
Workshop on Social Media Analytics (SOMA-KDD), pp. 110.
Rossi, R., Gallagher, B., Neville, J., & Henderson, K. (2012). Role-Dynamics: Fast Mining
of Large Dynamic Networks. In LSNA-WWW, pp. 19.
Rossi, R., & Neville, J. (2012). Time-evolving relational classification and ensemble methods.
In Proceedings of the 16th Pacific-Asia Conference on Knowledge Discovery and Data
Mining, pp. 112.
438

fiTransforming Graph Data for Statistical Relational Learning

Roth, M., Ben-David, A., Deutscher, D., Flysher, G., Horn, I., Leichtberg, A., Leiser, N.,
Merom, R., & Mattias, Y. (2010). Suggesting Friends Using the Implicit Social Graph.
In Proceeding of the 16th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 233242.
Russell, S. J., & Norvig, P. (2009). Artificial Intelligence: A Modern Approach (3rd International Edition edition). Prentice Hall.
Sabidussi, G. (1966). The centrality index of a graph. Psychometrika, 31 (4), 581603.
Salton, G., & McGill, M. (1983). Introduction to modern information retrieval, Vol. 1.
McGraw-Hill New York.
Sarkar, P., & Moore, A. (2005). Dynamic Social Network Analysis using Latent Space
Models. SIGKDD Explorations Newsletter, 7 (2), 3140.
Sarukkai, R. R. (2000). Link prediction and path analysis using markov chains. In Proceedings of the 9th International World Wide Web Conference on Computer Networks: The
International Journal of Computer and Telecommunications Networking, pp. 377386.
Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2000). Application of dimensionality
reduction in recommender systema case study. In ACM WebKDD 2000 Web Mining
for E-Commerce Workshop.
Schulte, O. (2011). A tractable pseudo-likelihood function for bayes nets applied to relational
data. In SDM, pp. 462473.
Schwarz, G. (1978). Estimating the dimension of a model. The annals of statistics, 6 (2),
461464.
Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., & Eliassi-Rad, T. (2008). Collective classification in network data. AI Magazine, 29 (3), 93.
Shao, J. (1996). Bootstrap model selection. Journal of the American Statistical Association,
91 (434), 655665.
Shapiro, E. (1982). Algorithmic Program Debugging. ACM Distinguished Dissertation..
Sharan, U., & Neville, J. (2008). Temporal-relational classifiers for prediction in evolving
domains. In Proceedings of the 8th IEEE International Conference on Data Mining,
pp. 540549.
Shi, J., & Malik, J. (2000). Normalized cuts and image segmentation. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 22 (8), 888905.
Shi, X., Li, Y., & Yu, P. (2011). Collective prediction with latent graphs. In Proceedings
of the 20th ACM Conference on Information and Knowledge Management, pp. 1127
1136.
Singla, P., & Domingos, P. (2006). Entity resolution with markov logic. In Proceedings of
the 6th IEEE International Conference on Data Mining, pp. 572582.
Srinivasan, A. (1999). The aleph manual. Computing Laboratory, Oxford University, 1.
Strehl, A., & Ghosh, J. (2003). Cluster ensemblesa knowledge reuse framework for combining multiple partitions. Journal of Machine Learning Research, 3, 583617.
439

fiRossi, McDowell, Aha, & Neville

Tang, J., Musolesi, M., Mascolo, C., & Latora, V. (2009). Temporal distance metrics for
social network analysis. In Proceedings of the 2nd ACM workshop on Online social
networks, pp. 3136.
Tang, J., Musolesi, M., Mascolo, C., Latora, V., & Nicosia, V. (2010). Analysing information
flows and key mediators through temporal centrality metrics. In Proceedings of the
3rd Workshop on Social Network Systems, pp. 16.
Tang, L., & Liu, H. (2009). Relational learning via latent social dimensions. In Proceedings
of the 15th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, pp. 817826.
Tang, L., & Liu, H. (2011). Leveraging social media networks for classification. Journal of
Data Mining and Knowledge Discovery, 23, 447478.
Taskar, B., Abbeel, P., & Koller, D. (2002). Discriminative probabilistic models for relational
data. In Eighteenth Conference on Uncertainty in Artificial Intelligence, pp. 485492.
Taskar, B., Segal, E., & Koller, D. (2001). Probabilistic classification and clustering in
relational data. In Proceedings of the 17th International Joint Conference on Artificial
Intelligence, pp. 870878.
Taskar, B., Wong, M., Abbeel, P., & Koller, D. (2003). Link prediction in relational data.
In Advances in Neural Information Processing Systems.
Topchy, A., Law, M., Jain, A., & Fred, A. (2004). Analysis of consensus partition in cluster
ensemble. In Proceedings of the 4th IEEE International Conference on Data Mining,
pp. 225232.
Vert, J., & Yamanishi, Y. (2005). Supervised graph inference. Advances in Neural Information Processing Systems, 17, 14331440.
Vishwanathan, S., Schraudolph, N., Kondor, R., & Borgwardt, K. (2010). Graph kernels.
Journal of Machine Learning Research, 11, 12011242.
von Luxburg, U. (2007). A tutorial on spectral clustering. Statistics and Computing, 17 (4),
395416.
Wagner, A., & Fell, D. (2001). The small world inside large metabolic networks. Proceedings
of the Royal Society of London. Series B: Biological Sciences, 268 (1478), 18031810.
Wang, C., Blei, D., & Heckerman, D. (2008). Continuous time dynamic topic models. In
Proceedings of Uncertainty in Artificial Intelligence.
Wang, X., & McCallum, A. (2006). Topics over time: a non-Markov continuous-time model
of topical trends. In Proceedings of the 12th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 424433.
Wang, Z., & Chan, L. (2010). An efficient causal discovery algorithm for linear models.
In Proceeding of the 16th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 11091118.
Wasserman, S., & Faust, K. (1994). Social network analysis: Methods and applications.
Cambridge University Press.
440

fiTransforming Graph Data for Statistical Relational Learning

Watts, D., & Strogatz, S. (1998). Collective dynamics of small-worldnetworks. Nature,
393 (6684), 440442.
White, S., & Smyth, P. (2003). Algorithms for estimating relative importance in networks.
In Proceedings of the ninth ACM SIGKDD International Conference on Knowledge
Discovery and Data mining, pp. 266275.
Wu, B., & Davison, B. (2005). Identifying link farm spam pages. In Special interest tracks
and posters of the 14th International Conference on World Wide Web, pp. 820829.
Xiang, R., Neville, J., & Rogati, M. (2010). Modeling relationship strength in online social
networks. In Proceedings of the 19th International World Wide Web Conference, pp.
981990.
Yang, Y., & Pedersen, J. (1997). A comparative study on feature selection in text categorization. In Proceedings of the 14th International Conference on Machine Learning,
pp. 412420.
Yin, X., Han, J., Yang, J., & Yu, P. (2006). Crossmine: Efficient classification across multiple
database relations. Transactions on Knowledge and Data Engineering, 18 (6), 770783.
Zheleva, E., Getoor, L., Golbeck, J., & Kuter, U. (2010). Using friendship ties and family
circles for link prediction. In Advances in Social Network Mining and Analysis, pp.
97113.
Zheleva, E., & Getoor, L. (2007). Preserving the privacy of sensitive relationships in graph
data. In PinKDD, pp. 153171.
Zhou, B., Pei, J., & Luk, W. (2008). A brief survey on anonymization techniques for privacy
preserving publishing of social network data. SIGKDD Explorations, 10 (2), 1222.
Zhou, H. (2003). Distance, dissimilarity index, and network community structure. Physical
review e, 67 (6), 61901.
Zhou, T., Lu, L., & Zhang, Y. (2009). Predicting missing links via local information. The
European Physical Journal B-Condensed Matter and Complex Systems, 71 (4), 623
630.
Zhu, S., Yu, K., Chi, Y., & Gong, Y. (2007). Combining content and link for classification
using matrix factorization. In Proceedings of the 30th Annual International ACM
SIGIR Conference on Research and Development in Information Retrieval, pp. 487
494. ACM.
Zhu, X. (2006). Semi-supervised learning literature survey. Computer Science Tech Reports,
1530, 160.

441

fiJournal of Artificial Intelligence Research 45 (2012) 257-286

Submitted 6/12; published 10/12

Generating Approximate Solutions to the Traveling
Tournament Problem using a Linear Distance Relaxation
Richard Hoshino
Ken-ichi Kawarabayashi

richard.hoshino@gmail.com
k keniti@nii.ac.jp

National Institute of Informatics and
JST ERATO Kawarabayashi Project
2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan

Abstract
In some domestic professional sports leagues, the home stadiums are located in cities
connected by a common train line running in one direction. For these instances, we can
incorporate this geographical information to determine optimal or nearly-optimal solutions
to the n-team Traveling Tournament Problem (TTP), an NP-hard sports scheduling problem whose solution is a double round-robin tournament schedule that minimizes the sum
total of distances traveled by all n teams.
We introduce the Linear Distance Traveling Tournament Problem (LD-TTP), and solve
it for n = 4 and n = 6, generating the complete set of possible solutions through elementary
combinatorial techniques. For larger n, we propose a novel expander construction that
generates an approximate solution to the LD-TTP. For n  4 (mod 6), we show that our
expander construction produces a feasible double round-robin tournament schedule whose
total distance is guaranteed to be no worse than 43 times the optimal solution, regardless
of where the n teams are located. This 34 -approximation for the LD-TTP is stronger than
the currently best-known ratio of 35 +  for the general TTP.
We conclude the paper by applying this linear distance relaxation to general (nonlinear) n-team TTP instances, where we develop fast approximate solutions by simply
assuming the n teams lie on a straight line and solving the modified problem. We
show that this technique surprisingly generates the distance-optimal tournament on all
benchmark sets on 6 teams, as well as close-to-optimal schedules for larger n, even when
the teams are located around a circle or positioned in three-dimensional space.

1. Introduction
In this paper, we introduce a simple yet powerful technique to develop approximate solutions
to the Traveling Tournament Problem
(TTP), by assuming the n teams are located on a
n
straight line, thereby reducing the 2 pairwise distance parameters to just n  1 variables,
and then solving the relaxed problem.
The Traveling Tournament Problem (TTP) was inspired by the real-life problem of
optimizing the regular-season schedule for Major League Baseball. The goal of the TTP
is to determine the optimal double round-robin tournament schedule for an n-team sports
league that minimizes the sum total of distances traveled by all n teams. Since the problem
was first proposed (Easton, Nemhauser, & Trick, 2001), the TTP has attracted a significant
amount of research (Kendall, Knust, Ribeiro, & Urrutia, 2010), with numerous heuristics
developed for solving hard TTP instances, such as local search techniques as well as integer
and constraint programming.
c
2012
AI Access Foundation. All rights reserved.

fiHoshino & Kawarabayashi

In many ways, the TTP is a variant of the well-known Traveling Salesman Problem
(TSP), asking for a distance-optimal schedule linking venues that are close to one another.
The computational complexity of the TSP is NP-hard; recently, it was shown that solving
the TTP is strongly NP-hard (Thielen & Westphal, 2010).
In the Linear Distance Traveling Tournament Problem (LD-TTP), we assume the n
teams are located on a straight line. This straight line relaxation is a natural heuristic
when the n teams are located in cities connected by a common train line running in one
direction, modelling the actual context of domestic sports leagues in countries such as Chile,
Sweden, Italy, and Japan. For example, Figure 1 illustrates the locations of the six home
stadiums in Nippon Pro Baseballs Central League, all situated in close proximity to major
stations on Japans primary bullet-train line.

Figure 1: The six Central League teams in Japanese Pro Baseball.

In Section 2, we formally define the TTP. In Section 3, we solve the LD-TTP for n = 4
and list all 18 non-isomorphic tournament schedules achieving the optimal distance. In
Section 4, we solve the LD-TTP for n = 6 and show that there are 295 non-isomorphic
tournament schedules that can attain one of the seven possible values for the optimal
distance. In Section 5, we provide an expander construction to produce a feasible double
round-robin tournament schedule for any tournament on n = 6m  2 teams, and prove
that it is a 34 -approximation of the distance-optimal schedule, for any m  1. In Section 6,
we apply our theories to all known (non-linear) 6-team benchmark sets (Trick, 2012), and
show that in all cases, the optimal solution appears in our list of 295. We also apply our
expander construction to various benchmark sets on 10 and 16 teams, showing that this
optimality gap is actually far lower than the theoretical maximum of 33.3%. In Section 7,
we do an in-depth analysis of the optimality gap, and conclude the paper in Section 8 with
some open problems and directions for future research.

2. The Traveling Tournament Problem
Let {t1 , t2 , . . . , tn } be the n teams in a sports league, where n is even. Let D be the n  n
distance matrix, where entry Di,j is the distance between the home stadiums of teams ti
and tj . By definition, Di,j = Dj,i for all 1  i, j  n, and all diagonal entries Di,i are zero.
We assume the distances form a metric, i.e., Di,j  Di,k + Dk,j for all i, j, k.
258

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

The TTP requires a tournament lasting 2(n  1) days, where every team has exactly one
game scheduled each day with no byes or days off (this explains why n must be even.) The
objective is to minimize the total distance traveled by the n teams, subject to the following
conditions:
(a) each-venue: Each pair of teams plays twice, once in each others home venue.
(b) at-most-three: No team may have a home stand or road trip lasting more than three
games.
(c) no-repeat: A team cannot play against the same opponent in two consecutive games.
When calculating the total distance, we assume that every team begins the tournament
at home and returns home after playing its last away game. Furthermore, whenever a team
has a road trip consisting of multiple away games, the team doesnt return to their home
city but rather proceeds directly to their next away venue.
To illustrate with a specific example, Table 1 lists the distance-optimal schedule (Easton
et al., 2001) for a bechmark set known as NL6 (six teams from Major League Baseballs
National League). In this schedule, as with all subsequent schedules presented in this paper,
home games are marked in bold.
Team
Florida (FLO)
Atlanta (ATL)
Pittsburgh (PIT)
Philadelphia (PHI)
New York (NYK)
Montreal (MON)

1
2
3
4
5
ATL PHI NYK PIT NYK
FLO NYK PIT
PHI MON
NYK MON ATL FLO PHI
MON FLO MON ATL PIT
PIT ATL FLO MON FLO
PHI PIT
PHI NYK ATL

6
MON
PIT
ATL
NYK
PHI
FLO

7
8
PIT PHI
PHI MON
FLO NYK
ATL FLO
MON PIT
NYK ATL

9
MON
NYK
PHI
PIT
ATL
FLO

10
ATL
FLO
MON
NYK
PHI
PIT

Table 1: An optimal TTP solution for NL6.
For example, the total distance traveled by Florida is DFLO,ATL +DATL,PHI +DPHI,FLO +
DFLO,NYK + DNYK,MON + DMON,PIT + DPIT,FLO . Based on the NL6 distance matrix (Trick,
2012), the tournament schedule in Table 1 requires 23916 miles of total team travel, which
can be shown to be the minimum distance possible.

3. The 4-Team LD-TTP

Figure 2: The general instance of the LD-TTP for n = 4.
In the Linear Distance TTP, we assume the n home stadiums lie on a straight line, with
t1 at one end and tn at the other. Thus, Di,j = Di,k + Dk,j for all triplets (i, j, k) with
259

fiHoshino & Kawarabayashi

1  i < k < j  n. Since the Triangle
Inequality is replaced by the Triangle Equality, we

no longer need to consider all n2 entries in the distance matrix D; each tournaments total
travel distance is a function of n  1 variables, namely the set {Di,i+1 : 1  i  n  1}. For
notational convenience, denote di := Di,i+1 for all 1  i  n  1.
Team
t1
t2
t3
t4

1
t4
t3
t2
t1

2
t3
t4
t1
t2

3
t2
t1
t4
t3

4
t4
t3
t2
t1

5
t3
t4
t1
t2

6
t2
t1
t4
t3

Table 2: An optimal LD-TTP solution for n = 4.

Table 2 gives a feasible solution to the 4-team LD-TTP. We claim that this solution is
optimal, for all possible 3-tuples (d1 , d2 , d3 ). To see why this is so, define ILBti to be the
independent lower bound for team ti , the minimum possible distance that can be traveled
by ti in order to complete its games, independent of the other
teams schedules. Then a
P
trivial lower bound for the total travel distance is T LB  ni=1 ILBti .
Recall that when calculating ti s travel distance, we assume that ti begins the tournament at home and returns home after playing its last away game. Since ti must play a road
game against each of the other three teams, ILBti = 2(d1 + d2 + d3 ) for all 1  i  4. This
implies that T LB  8(d1 + d2 + d3 ). Since Table 2 is a tournament schedule whose total
distance is the trivial lower bound, this completes the proof.
We remark that Table 2 is not the unique solution - for example, we can generate another
optimal schedule by simply reading Table 2 from right to left. Assuming the first match
between t1 and t2 occurs in the home city of t2 , a straightforward computer search finds 18
different schedules with total distance 8(d1 + d2 + d3 ), which are provided in Table 3 below.
(For readability, we have replaced each occurrence of ti by the single index i.) Thus, by
symmetry, there are 36 optimal schedules for the 4-team LD-TTP. For the interested reader,
Appendix A provides the actual Maplesoft code that generated these optimal schedules.
234234
143143
412412
321321

234243
143134
412421
321312

234342
143431
412124
321213

243234
134143
421412
312321

243243
134134
421421
312312

243432
134341
421214
312123

342342
431431
124124
213213

342432
431341
124214
213123

432342
341431
214124
123213

432432
341341
214214
123123

342342
431431
124124
213213

342432
431341
124214
213123

342342
431431
124124
213213

342432
431341
124214
213123

432342
341431
214124
123213

432432
341341
214214
123123

432342
341431
214124
123213

432432
341341
214214
123123

Table 3: The eighteen non-isomorphic optimal LD-TTP solutions for n = 4.
This completes the analysis of the 4-team Linear Distance TTP.
260

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

4. The 6-Team LD-TTP
Unlike the previous section, the analysis for the 6-team LD-TTP requires more work.

Figure 3: The general instance of the LD-TTP for n = 6.
Any 6-team instance of the LD-TTP can be represented by the 5-tuple (d1 , d2 , d3 , d4 , d5 ).
We define S = 14d1 + 16d2 + 20d3 + 16d4 + 14d5 . We claim the following:
Theorem 1. Let  be a 6-team instance of the LD-TTP. The optimal solution to  is a
schedule with total distance S + 2 min{d2 + d4 , d1 + d4 , d3 + d4 , 3d4 , d2 + d5 , d2 + d3 , 3d2 }.
We will prove Theorem 1 through elementary combinatorial arguments, thus demonstrating the utility of this linear distance relaxation and presenting new techniques to attack
the general TTP in ways that differ from integer/constraint programming. Our proof will
follow from several lemmas, which we now prove one by one.
Lemma 1. Any feasible schedule of  must have total distance at least S.
Proof. For each 1  k  5, define ck to be the total number of times a team crosses the
bridge of length dk , connecting the home stadiums of teams
Pt5k and tk+1 . Let Z be the
total travel distance of this schedule. Since  is linear, Z = k=1 ck dk . Since each team
crosses every bridge an even number of times, ck is always even.
Let Lk be the home venues of {t1 , t2 , . . . , tk } and Rk be the home venues of {tk+1 , . . . , t6 }.
By the each-venue condition, every team in Lk plays a road game against every team in Rk .
By the at-most-three condition, every team in Lk must make at least 2d 6k
3 e trips across
the bridge, with half the trips in each direction. Similarly, every team in Rk must make at
k
least 2d k3 e trips across the bridge, implying that ck  2kd 6k
3 e + 2(6  k)d 3 e.
Thus, c1  14, c2  16, cP
4  16, and c5  14. We now show that c3  20, which will
complete the proof that Z = ck dk  14d1 + 16d2 + 20d3 + 16d4 + 14d5 = S.
Since there are n = 6 teams, there are 2(n  1) = 10 days of games. For each 1  i  9,
let Xi,i+1 be the total number of times the d3 -length bridge is crossed as the teams move
from their games on the ith day to their games on the (i + 1)th day. Let Xstart,1 and X10,end
respectively be the number of times the teams cross this bridge to playPtheir first game, and
return home after having played their last game. Then c3 = Xstart,1 + 9i=1 Xi,i+1 +X10,end .
For each 1  i  9, let f (i) denote the number of games played in L3 on day i. Thus,
on day i, exactly 2f (i) teams are to the left of this bridge and 6  2f (i) teams are to the
right. So f (i)  {0, 1, 2, 3} for all i. Since |L3 | and |R3 | are odd, we have Xstart,1  1 and
X10,end  1.
If f (i) < f (i + 1), then Xi,i+1  2, as at least two teams who played in R3 on day i
must cross over to play their next game in L3 . Similarly, if f (i) > f (i + 1), then Xi,i+1  2.
If f (i) = f (i + 1) = 1, then on day i, two teams p and q play in L3 while the other four
teams play in R3 . If Xi,i+1 = 0 then no team crosses the bridge after day i, forcing p and
261

fiHoshino & Kawarabayashi

q to play against each other on day i + 1, thus violating the no-repeat condition. Thus, at
least one of p or q must cross the bridge, exchanging positions with at least one other team
who must cross to play in L3 . Thus, Xi,i+1  2. Similarly, if f (i) = f (i + 1) = 2, then
Xi,i+1  2.
If f (i) = f (i + 1) = 0, then all teams play in R3 on days i and i + 1. Then Xstart,1 = 3
if i = 1 and X10,end = 3 if i = 9. If 2  i  8, then each of {t1 , t2 , t3 } must play a home
game on either day i  1 or day i + 2, in order to satisfy the at-most-three condition. Thus,
on one of these two days, at least two teams in {t1 , t2 , t3 } play at home, implying at least
four teams are in L3 . Therefore, we must have Xi1,i  4 or Xi+1,i+2  4.
We derive the same results if f (i) = f (i + 1) = 3. We have Xstart,1 = 3 if i = 1,
X10,end = 3 if i = 9, and either Xi1,i  4 or Xi+1,i+2  4 if 2  i  8.
So in our double round-robin schedule, if the sequence
{f (1), . . . , f (10)} has no pair of
P9
consecutive 0s or consecutive 3s, then c3 = Xstart,1 + i=1 Xi,i+1 +X10,end  1+92+1 = 20.
And if this is not the case, we still have c3  P
20 from the results of the previous two
paragraphs. We have therefore proven that Z =
ck dk  S.
Lemma 2. Consider a feasible schedule of  with total distance Z =
then teams t1 and t2 must play against each other on Days 1 and 10.

P

ck dk . If c2 = 16,


Proof. As we did in Lemma 1, for each 1  i  9 define Xi,i+1
be the total number
of times the d2 -length bridge is crossed as the teams move from their games on the ith


so that
day to their games on the (i + 1)th day. Similarly define Xstart,1
and X10,end
P
9



c2 = Xstart,1 + i=1 Xi,i+1 + X10,end .
P

We now prove that 9i=1 Xi,i+1
 16. To do this, for each 1  i  10, let g(i) denote
the number of games played in L2 (i.e., the home stadiums of t1 and t2 ) on day i. So on
day i, exactly 2g(i) teams are to the left of the d2 -length bridge and 6  2g(i) teams are to
the right. Clearly, 0  g(i)  2 for all 1  i  10.

If |g(i + 1)  g(i)| = 1, then Xi,i+1
 2, as at least two teams who played on day i
on one side of the bridge must cross over to play their next game on the other side. If

|g(i + 1)  g(i)| = 2, then Xi,i+1
= 4.
If g(i) = g(i + 1) = 1, then on day i, two teams p and q play in L2 while the other four

teams play in R2 . If Xi,i+1
= 0 then no team crosses the bridge after day i, forcing p and
q to play against each other on day i + 1, thus violating the no-repeat condition. Thus, at
least one of p or q must cross the bridge, exchanging positions with at least one other team

who must cross to play in L2 . Thus, Xi,i+1
 2. Similarly, if g(i) = g(i + 1) = 2, then two
teams p and q play in R2 while the other four teams play in L2 , and we apply the same

argument to show that Xi,i+1
 2. The remaining case to consider is g(i) = g(i + 1) = 0,

in which case Xi,i+1 could equal 0.
Suppose there are a days with g(i) = 0, b days with g(i) = 1, and c days with g(i) = 2.
Then a + b + c = 10. Since each of t1 and t2 play five home games, this implies b + 2c = 10.
From this, we see that a = c and that there are only six possible triplets for (a, b, c), namely
(0, 10, 0), (1, 8, 1), (2, 6, 2), (3, 4, 3), (4, 2, 4), and (5, 0, 5).
If a = 0 or a = 1, then there does not P
exist an index i with g(i) = g(i + 1) = 0, implying


that Xi,i+1
 2 for all 1  i  9. Hence, 9i=1 Xi,i+1
 9  2 = 18 in these cases. If a = 2,
P

then there is at most one index i with g(i) = g(i + 1) = 0, implying that 9i=1 Xi,i+1
 16.

262

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

P

Suppose 9i=1 Xi,i+1
< 16. Then we must have 3  a  5, with two or more indices i satisfying g(i) = g(i + 1) = 0. For example,P
one such 10-tuple is (g(1), g(2), . . . , g(9), g(10)) =

(1, 0, 0, 0, 1, 1, 1, 2, 2, 2), which can have 9i=1 Xi,i+1
= 14. A simple case analysis of each
of (a, b, c)  {(3, 4, 3), (4, 2, 4), (5, 0, 5)} shows that all such bad 10-tuples violate the atmost-three condition; for example, in the 10-tuple above, either t1 or t2 must play four
consecutive road games to start the tournament, which is a contradiction.
P9

Therefore, we have proven that
i=1 Xi,i+1  16 in all cases. This implies that if


= X10,end
= 0. Hence, on Days 1 and 10, t1 and t2 stay in L2 while
c2 = 16, then Xstart,1
the other four teams stay in R2 . Since t1 and t2 are the only teams in L2 , clearly this forces
these two teams to play against each other, to begin and end the tournament.
Lemma 3. Let S1 be the set of tournament schedules with distance S + 2(d2 + d4 ), S2 with
distance S + 2(d1 + d4 ), S3 with distance S + 2(d3 + d4 ), S4 with distance S + 6d4 , S5 with
distance S + 2(d2 + d5 ), S6 with distance S + 2(d2 + d3 ), and S7 with distance S + 6d2 . Then
each set in {S1 , S2 , . . . , S7 } is non-empty.
Proof. For each of these seven sets, it suffices to find just one feasible schedule with the
desired total distance. For each of {S1 , S2 , S3 , S4 }, at least one such set has appeared
previously in the literature, as the solution to a 6-team benchmark set or in some other
context. (As we will see in the following section, we can label the six teams of the NL6
benchmark set so that Table 1 is an element of S4 .)
t1
t2
t3
t4
t5
t6

1
t2
t1
t4
t3
t6
t5

2
t3
t6
t1
t5
t4
t2

3
t4
t5
t6
t1
t2
t3

4
t6
t4
t5
t2
t3
t1

5
t3
t6
t1
t5
t4
t2

6
t5
t3
t2
t6
t1
t4

7
t6
t4
t5
t2
t3
t1

8
t4
t5
t6
t1
t2
t3

9
t5
t3
t2
t6
t1
t4

10
t2
t1
t4
t3
t6
t5

d1
4
2
2
2
2
2

d2
4
4
4
2
2
2

d3
4
2
4
4
2
2

d4
2
2
2
4
4
4

d5
2
2
2
2
2
4

Table 4: Optimal CIRC6 solution, with distance S + 2(d2 + d4 ) = 14d1 + 18d2 + 20d3 + 18d4 + 14d5 .

The solution to CIRC6 (Trick, 2012), where Di,j = min{j  i, 6  (j  i)} for all 1  i <
j  6, is an element of S1 . Table 4 provides this schedule. For each 1  k  5, we list the
number of times the dk bridge is crossed by each of the six teams.
We conclude the proof by noting that |Si+3 | = |Si | for 2  i  4, as we can label the
teams backward from t6 to t1 to create a feasible schedule where each distance dk is replaced
by d6k . Therefore, we have shown that each Si is non-empty.
We are now ready to prove Theorem 1, that the optimal solution to any 6-team instance
 is a schedule that appears in S1  S2  . . .  S7 . We note that any of these seven optimal
distances can be the minimum, depending on the 5-tuple (d1 , d2 , d3 , d4 , d5 ).
P
Proof. Suppose the optimal solution to  has total distance Z =
ck dk . By Lemma 1,
c1 , c5  14, c2 , c4  16, and c3  20. Recall that each coefficient ck is even.
263

fiHoshino & Kawarabayashi

By Lemma 3, S1 is non-empty, and so a schedule cannot be optimal if Z > S +2(d2 +d4 ).
Thus, if c2 , c4  18, then we must have (c1 , c2 , c3 , c4 , c5 ) = (14, 18, 20, 18, 14) so that Z =
S + 2(d2 + d4 ), forcing the schedule to be in set S1 .
Suppose that c2  c4 , so that it suffices to check the possibility c2 = 16. By Lemma 2,
t1 and t2 must play against each other on Days 1 and 10. There are three cases:
Case 1: c2 = 16, c1 = 14.
Case 2: c2 = 16, c1  16, c4 = 16.
Case 3: c2 = 16, c1  16, c4  18.
In Case 1, every team must travel the minimum number of times across the d1 - and
d2 -bridges: team t1 can only take two road trips, team t2 can only take two road trips to
play {t3 , t4 , t5 , t6 }, and each of {t3 , t4 , t5 , t6 } must play their road games against t1 and t2
on consecutive days.
By symmetry, we may assume that the first match between t1 and t2 occurs in the home
city of t2 (i.e., it is a road game for t1 ). By Lemma 2, the schedule for team t1 must be one
of the following four cases, for some permutation {p, q, r, s} of {3, 4, 5, 6}.
Case
#A1
#A2
#A3
#A4

Team
t1
t1
t1
t1

1
t2
t2
t2
t2

2
t?
t?
t?
t?

3
tp
t?
tp
t?

4
tq
tp
tq
tp

5
t?
tq
tr
tq

6
t?
t?
t?
tr

7
t?
t?
t?
t?

8
tr
tr
t?
t?

9
ts
ts
ts
ts

10
t2
t2
t2
t2

In all four cases, t1 plays a home game against ts on day 9. In other words, ts plays
on the road against t1 on day 9, forcing ts s road game against t2 to take place either the
day before or the day after. The latter is not possible, as t2 already has a game scheduled
against t1 on day 10; thus, ts must play on the road against t2 on day 8.
Hence, t2 plays a home game against ts on day 8 and a road game against t1 on day 10.
Now suppose that t2 has a home game on day 9. Then t2 s opponent that day must be tr ,
and we must have either Case #A1 or #A2 above. (This is the only way we can ensure tr
plays their road games against t1 and t2 on consecutive days.)
Team
t1
t2

1
t1
t1

2

3

4

5

6

7

8
tr
ts

9
ts
tr

10
t2
t1

There are six teams in the tournament, and on days 8 and 9, the same set of four teams
have each been assigned a game. From the above table, it is clear that teams tp and tq must
play each other on day 8 and day 9, which is a violation of the no-repeat condition. This
is a contradiction, and therefore t2 must play a road game on day 9, against some team in
{t3 , t4 , t5 , t6 }.
As mentioned earlier, t2 can only take two road trips to play the four teams in {t3 , t4 , t5 , t6 },
which forces one of the following two scenarios:
264

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

Case
#B1
#B2

Team
t2
t2

1
t1
t1

2
tp
tp

3
tq
t?

4
t?
t?

5
t?
t?

6
t?
tq

7
tr
tr

8
ts
ts

9
t?
t?

10
t1
t1

For each of the 4  2 = 8 pairs matching the cases for t1 with the cases for t2 , we check
whether there exists a feasible schedule for which each team in {t3 , t4 , t5 , t6 } plays their road
games against t1 and t2 on consecutive days. A quick check shows that the only possibility
is the pairing of Case #A1 with Case #B1, leading to the following schedule for the first
two teams:
Team
t1
t2

1
t2
t1

2
t?
tp

3
tp
tq

4
tq
t?

5
t?
t?

6
t?
t?

7
t?
tr

8
tr
ts

9
ts
t?

10
t2
t1

This structural characterization reduces the search space considerably, and from this
(see Appendix B) we show that either (i) c4  22, or (ii) c3  22 and c4  18. By Lemma
3, the latter implies Z = S + 2(d3 + d4 ) and the former implies Z = S + 6d4 . Therefore,
this optimal schedule must be in S3 or S4 .
In Case 2, we demonstrate that no structural characterization exists if c2 = c4 = 16. To
do this, we use Lemma 2 (for c2 = 16) and its symmetric analogue (for c4 = 16) to show
that in order not to violate the at-most-three or no-repeat conditions, t3 and t4 must play
each other on Days 1 and 10, as well as on some other Day i with 2  i  9. But then this
violates the each-venue condition. Hence, we may eliminate this case.
In Case 3, if c1  16 and c4  18, then Z is at least S + 2(d1 + d4 ). By Lemma 3, we
must have Z = S + 2(d1 + d4 ) and this optimal schedule must be in S2 .
So we have shown that if c2 = 16, then the schedule appears in S2  S3  S4 . By
symmetry, if c4 = 16, then the schedule appears in S5  S6  S7 . Finally, if c2 , c4  18, the
schedule appears in S1 . This concludes the proof.
By Theorem 1, there are only seven possible optimal distances. For each optimal distance, we can enumerate the set of tournament schedules with that distance, thus producing
the complete set of possible LD-TTP solutions, over all instances, for the case n = 6.
Theorem 2. Consider the set of all feasible tournaments for which the first game between
t1 and t2 occurs in the home city of t2 . Then there are 295 schedules whose total distance
appears in S1  S2  . . .  S7 , grouped as follows:
Total Distance
# of Schedules

 S1
223

 S2
4

 S3
8

 S4
24

 S5
4

 S6
8

 S7
24

We derive Theorem 2 by a computer search. For each of {S1 , S2 , S3 , S4 }, we develop
a structural characterization theorem, similar to Case 1 above, that shows that a feasible
schedule in that set must have a certain form. This characterization reduces the search
space, from which a brute-force search (using Maplesoft) enumerates all possible schedules.
While it took several days to enumerate the 223 schedules in S1 , Maplesoft took less than
100 seconds to enumerate the set of schedules in S3 and S4 . As noted earlier, once we have
265

fiHoshino & Kawarabayashi

the set of schedules in Si (for 2  i  4), we immediately have the set of schedules in Si+3
by symmetry. For the full details of each case, we refer the reader to Appendix B.
Let us briefly explain why |S1 | is odd. For any schedule S, let (S) denote the schedule
produced by playing the games backwards (i.e., ti hosts tj on day d in S iff ti hosts tj on
day (11  d) in (S).) And let (S) denote the schedule produced by labelling the six
teams in reverse order (i.e., ti hosts tj on day d in S iff t7i hosts t7j on day d in (S).)
For any schedule S, clearly S 6= (S) and S 6= (S).
For any schedule S   S1 , exactly one of (S  ) and ((S  )) belongs to S1 , since weve
stipulated that the first game between t1 and t2 occurs in the home city of t2 . Since the
mapping functions  and () are involutions, the schedules in S1 can be grouped into
pairs. However, in 13 exceptional cases, the schedule S   S1 does not have a pair, since
S  = ((S  )). One such example is given in Table 5.
t1
t2
t3
t4
t5
t6

1
t3
t4
t1
t2
t6
t5

2
t6
t5
t4
t3
t2
t1

3
t5
t4
t6
t2
t1
t3

4
t4
t3
t2
t1
t6
t5

5
t3
t6
t1
t5
t4
t2

6
t5
t3
t2
t6
t1
t4

7
t2
t1
t6
t5
t4
t3

8
t4
t6
t5
t1
t3
t2

9
t6
t5
t4
t3
t2
t1

10
t2
t1
t5
t6
t3
t4

Table 5: A schedule S  in S1 with the property that S  = ((S  )).
In the above schedule, for any pair (i, j), ti hosts tj on day d iff t7i hosts t7j on day
11  d. These thirteen exceptions justify the odd parity of |S1 |. For 2  i  7, there is no
schedule with S  = ((S  )), which explains why |Si | is even in each of these cases.

5. An Approximation Algorithm
We have solved the LD-TTP for n = 4 and n = 6, and in both cases, determined the
complete set of schedules attaining the optimal distances. A natural follow-up question is
whether our techniques scale for larger values of n. To give a partial answer to this question,
we show that for all n  4 (mod 6), we can develop a solution to the n-team LD-TTP whose
total distance is at most 33% higher than that of the optimal solution, although in practice
this optimality gap is actually much lower.
While our construction is only a 34 -approximation, we note that this ratio is stronger than
the currently best-known ( 53 + )-approximation for the general TTP (Yamaguchi, Imahori,
Miyashiro, & Matsui, 2011). Our schedule is based on an expander construction, and is
completely different from previous approaches that generate approximate TTP solutions.
We now describe this construction, and apply it to benchmark instances on 10 teams and
16 teams.
Let m be a positive integer. We first create a single round-robin tournament U on 2m
teams, and then expand this to a double round-robin tournament T on n = 6m  2 teams.
We use a variation of the Modified Circle Method (Fujiwara, Imahori, Matsui, & Miyashiro,
2007) to build U , our single round-robin schedule. Let {u1 , u2 , . . . , u2m1 , x} be the 2m
teams. Then each team plays 2m  1 games, according to this three-part construction:
266

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

(a) For 1  k  m, team k plays the other teams in the following order: {2m  k +
1, 2m  k + 2, . . . , 2m  1, 1, 2, . . . , k  1, x, k + 1, k + 2, . . . , 2m  k}.
(b) For m + 1  k  2m  1, team k plays the other teams in the following order:
{2m  k + 1, 2m  k + 2, . . . , k  1, x, k + 1, k + 2, . . . , 2m  1, 1, 2, . . . , 2m  k}.
(c) Team x plays the other teams in the following order: {1, m + 1, 2, m + 2, . . . , m 
1, 2m  1, m}.

u1
u2
u3
u4
u5
u6
u7
x

1
x

u7
u6
u5
u4
u3
u2
u1

2
u2
u1
u7
u6
x

u4
u3
u5

3
u3
x

u1
u7
u6
u5
u4
u2

4
u4
u3
u2
u1
u7
x

u5
u6

5
u5
u4
x

u2
u1
u7
u6
u3

6
u6
u5
u4
u3
u2
u1
x

u7

7
u7
u6
u5
x

u3
u2
u1
u4

Table 6: The single round-robin construction for 2m = 8 teams.
For all games not involving team x, we designate one home team and one road team as
follows: for 1  k  m, uk plays only road games until it meets team x, before finishing
the remaining games at home. And for m + 1  k  2m  1, we have the opposite scenario,
where uk plays only home games until it meets team x, before finishing the remaining games
on the road. As an example, Table 6 provides this single round-robin schedule for the case
m = 4.
This construction ensures that for any 1  i, j  2m1, the match between ui and uj has
exactly one home team and one road team. To verify this, note that ui is the home team and
uj is the road team iff i occurs before j in the set {1, 2m  1, 2, 2m  2, . . . , m  1, m + 1, m}.
Now we expand this single round-robin tournament U on 2m teams to a double
round-robin tournament T on n = 6m  2 teams. To accomplish this, we keep x and
transform uk into three teams, {t3k2 , t3k1 , t3k }, so that the set of teams in T is precisely
{t1 , t2 , t3 , . . . , t6m5 , t6m4 , t6m3 , x}.

t3i2
t3i1
t3i
t3j2
t3j1
t3j

6r  5
t3j1
t3j
t3j2
t3i
t3i2
t3i1

6r  4
t3j
t3j2
t3j1
t3i1
t3i
t3i2

6r  3
t3j2
t3j1
t3j
t3i2
t3i1
t3i

6r  2
t3j1
t3j
t3j2
t3i
t3i2
t3i1

6r  1
t3j
t3j2
t3j1
t3i1
t3i
t3i2

6r
t3j2
t3j1
t3j
t3i2
t3i1
t3i

Table 7: Expanding one time slot in U to six time slots in T .
267

fiHoshino & Kawarabayashi

Suppose ui is the home team in its game against uj , played in time slot r. Then we
expand that time slot in U into six time slots in T , namely the slots 6r  5 to 6r. We
describe the match assignments in Table 7.
Before proceeding further, let us explain the idea behind this construction. Recall that
by the each-venue condition, each team in T must visit every opponents home stadium
exactly once, and by the at-most-three condition, road trips are at most three games. We
will build a tournament that maximizes the number of three-game road trips, and ensure
that the majority of these road trips involve three venues closely situated to one another, to
minimize total travel. In Table 7 above, if {t3j2 , t3j1 , t3j } are located in the same region,
then each of the teams in {t3i2 , t3i1 , t3i } can play their three road games against these
teams in a highly-efficient manner.
We now explain how to expand the time slots in games involving team x. For each
1  k  m, consider the game between uk and x. We expand that time slot in U into six
time slots in T , as described in Table 8.
t3k2
t3k1
t3k
x

6r  5
x
t3k
t3k1
t3k2

6r  4
t3k
x
t3k2
t3k1

6r  3
t3k1
t3k2
x
t3k

6r  2
x
t3k
t3k1
t3k2

6r  1
t3k
x
t3k2
t3k1

6r
t3k1
t3k2
x
t3k

Table 8: The six time slot expansion for 1  k  m.
And for each m + 1  k  2m  1, consider the game between uk and x. We expand
that time slot in U into six time slots in T , as described in Table 9.
t3k2
t3k1
t3k
x

6r  5
x
t3k
t3k1
t3k2

6r  4
t3k
x
t3k2
t3k1

6r  3
t3k1
t3k2
x
t3k

6r  2
x
t3k
t3k1
t3k2

6r  1
t3k
x
t3k2
t3k1

6r
t3k1
t3k2
x
t3k

Table 9: The six time slot expansion for m + 1  k  2m  1.
This construction builds a double round-robin tournament T with n = 6m  2 teams
and 2n  2 = 12m  6 time slots. To give an example, Table 10 provides T for the case
m = 2.
It is straightforward to verify that this tournament schedule on n = 6m  2 teams is
feasible for all m  1, i.e., it satisfies the each-venue, at-most-three, and no-repeat conditions.
We now show that this expander construction gives a 34 -approximation to the LD-TTP,
regardless of the values of the distance parameters d1 , d2 , . . . , dn1 .
Let  be an n-team instance of the LD-TTP, with n = 6m  2 for some m  1. Let S be
the total distance of the optimal solution of . Using our expander construction, we generate
a feasible tournament with total distance less than 43 S. This gives a 34 -approximation to
the LD-TTP.
268

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

t1
t2
t3
t4
t5
t6
t7
t8
t9
x

1
x
t3
t2
t9
t7
t8
t5
t6
t4
t1

2
t3
x
t1
t8
t9
t7
t6
t4
t5
t2

3
t2
t1
x
t7
t8
t9
t4
t5
t6
t3

4
x
t3
t2
t9
t7
t8
t5
t6
t4
t1

5
t3
x
t1
t8
t9
t7
t6
t4
t5
t2

6
t2
t1
x
t7
t8
t9
t4
t5
t6
t3

7
t5
t6
t4
t3
t1
t2
x
t9
t8
t7

8
t6
t4
t5
t2
t3
t1
t9
x
t7
t8

9
t4
t5
t6
t1
t2
t3
t8
t7
x
t9

10 11
t5 t6
t6 t4
t4 t5
t3 t2
t1 t3
t2 t1
x t9
t9 x
t8 t7
t7 t8

12 13 14 15 16 17 18
t4 t8 t9 t7 t8 t9 t7
t5 t9 t7 t8 t9 t7 t8
t6 t7 t8 t9 t7 t8 t9
t1 x t6 t5 x t6 t5
t2 t6 x t4 t6 x t4
t3 t5 t4 x t5 t4 x
t8 t3 t2 t1 t3 t2 t1
t7 t1 t3 t2 t1 t3 t2
x t2 t1 t3 t2 t1 t3
t9 t4 t5 t6 t4 t5 t6

Table 10: The case m = 2, producing a 10-team tournament.
Let y1 , y2 , . . . , yn be the n = 6m  2 teams of , in that order, with dk being the
distance from yk to yk+1 for all 1  k  n  1. Now we map the set {t1 , t2 , . . . , tn1 , x}
to {y1 , y2 , . . . , yn } as follows: ti = yi for 1  i  3m  3, x = y3m2 , and ti = yi+1 for
3m  2  i  6m  3. In Figure 4 below, we illustrate this mapping for the case m = 2,
where the n = 6m  2 teams are divided into three triplets and a singleton x:

Figure 4: The labeling of the n = 6m  2 teams, for m = 2.
We then apply this labeling to our expander construction to create a feasible n-team
tournament T , where n = 6m  2 for some m  1. The following theorem tells us the total
distance of this tournament, as a function of the n  1 distance parameters d1 , d2 , . . . , dn1 .
Theorem 3. Let T be the n-team double round-robin tournament created by our expander
construction, where n = 6m  2. For each 1  k  6m  3, let fk be the total
number
Pn1
of times the dk -length bridge is crossed, so that the total distance of T is
k=1 fk dk .
Then the value of fk is given by Table 11. In addition, f1 = (8n  8)/3, f2 = 4n  4,
f3m2 = fn/21 = (n2 + 6n  16)/3, f3m1 = fn/2 = (n2 + 9n  22)/3, f3m = fn/2+1 =
(n2 + 9n  34)/3, and f6m3 = fn1 = (8n  2)/3.
Case
(a)
(b)
(c)
(d)
(e)
(f)

k
k = 4, 7, 10, . . . , 3m  5
k = 5, 8, 11, . . . , 3m  4
k = 3, 6, 9, 12, . . . , 3m  3
k = 3m + 1, 3m + 4, . . . , 6m  8, 6m  5
k = 3m + 2, 3m + 5, . . . , 6m  7, 6m  4
k = 3m + 3, 3m + 6, . . . , 6m  6

fk
4k(n  k)/3 + (6n + 8k  20)/3
4k(n  k)/3 + (4n + 12k  20)/3
4k(n  k)/3 + (4n + 6k  16)/3
4k(n  k)/3 + (8n  4k  22)/3
4k(n  k)/3 + (14n  10k  16)/3
4k(n  k)/3 + (4n  2k  4)

Table 11: The formulas for fk as a function of n and k.

269

fiHoshino & Kawarabayashi

Proof. For each of the six cases, we carefully enumerate the number of times each team
crosses the bridge, by considering the activity of each team in the tournament schedule T .
(a) Of the k teams to the left of the dk -length bridge, one team crosses the bridge 2(nk)/3
times, (k + 5)/3 teams cross the bridge 2(n  k + 3)/3 times and (2k  8)/3 teams
cross the bridge 2(n  k + 6)/3 times. And of the n  k  1 teams to the right of
the bridge (not including team x), (2n  3k  5)/3 of these teams cross the bridge
2(k + 2)/3 times and the remaining (n + 2)/3 teams cross the bridge 2(k + 5)/3 times.
Finally, team x crosses the bridge (4k + 2)/3 times. From there, we sum up the cases
and determine that fk = 4k(n  k)/3 + (6n + 8k  20)/3.
(b) Of the k teams to the left of the dk -length bridge, one team crosses the bridge 2(n 
k + 1)/3 times, (k + 4)/3 teams cross the bridge 2(n  k + 4)/3 times and (2k  7)/3
teams cross the bridge 2(n  k + 7)/3 times. And of the n  k  1 teams to the right
of the bridge (not including team x), (2n  3k  2)/3 of these teams cross the bridge
2(k + 1)/3 times, (n  4)/3 teams cross the bridge 2(k + 4)/3 times, and one team
crosses 2(k + 7)/3 times. Finally, team x crosses the bridge (4k  2)/3 times. From
there, we sum up the cases and determine that fk = 4k(n  k)/3 + (4n + 12k  20)/3.
(c) Of the k teams to the left of the dk -length bridge, (k + 6)/3 of these teams cross the
bridge 2(n  k + 2)/3 times, and the remaining (2k  6)/3 teams cross the bridge
2(n  k + 5)/3 times. And of the n  k  1 teams to the right of the bridge (not
including team x), (n  k  1)/3 of these teams cross the bridge 2k/3 times and the
remaining 2(n  k  1)/3 teams cross the bridge (2k + 6)/3 times. Finally, team x
crosses the bridge 4k/3 times. From there, we sum up the cases and determine that
fk = 4k(n  k)/3 + (4n + 6k  16)/3.
(d) Of the k  1 teams to the left of the dk -length bridge (not including team x), (k + 5)/3
teams cross the bridge 2(n  k)/3 times, and the remaining (2k  8)/3 teams cross
the bridge 2(n  k + 3)/3 times. And of the n  k teams to the right of the bridge,
(nk +3)/3 cross the bridge 2(k +2)/3 times and the remaining (2n2k 3)/3 teams
cross the bridge 2(k + 5)/3 times. Finally, team x crosses the bridge 2(n  k)/3 times.
From there, we sum up the cases and determine that fk = 4k(nk)/3+(8n4k22)/3.
(e) Of the k  1 teams to the left of the dk -length bridge (not including team x), (3k 
n + 4)/3 teams cross the bridge 2(n  k + 1)/3 times, and the remaining (n  7)/3
teams cross the bridge 2(n  k + 4)/3 times. And of the n  k teams to the right
of the bridge, (n  k + 4)/3 cross the bridge 2(k + 4)/3 times and the remaining
(2n  2k  4)/3 teams cross the bridge 2(k + 7)/3 times. Finally, team x crosses the
bridge 2(n  k + 4)/3 times. From there, we sum up the cases and determine that
fk = 4k(n  k)/3 + (14n  10k  16)/3.
(f) Of the k  1 teams to the left of the dk -length bridge (not including team x), (3k 
n + 1)/3 teams cross the bridge 2(n  k + 2)/3 times, and the remaining (n  4)/3
teams cross the bridge 2(n  k + 5)/3 times. And of the n  k teams to the right
of the bridge, (n  k + 2)/3 cross the bridge 2(k + 3)/3 times and the remaining
(2n  2k  2)/3 teams cross the bridge 2(k + 6)/3 times. Finally, team x crosses the
270

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

bridge 2(n  k + 2)/3 times. From there, we sum up the cases and determine that
fk = 4k(n  k)/3 + (4n  2k  4).
Finally, we clear all the exceptional cases. If k = 1, team t1 crosses the bridge 2(n  1)/3
times, while the remaining n  1 teams cross twice. Thus, f1 = 2(n  1)/3 + 2(n  1) =
(8n  8)/3. If k = 2, team t1 crosses the bridge 2(n  1)/3 times, team t2 crosses 2(n + 2)/3
times, (2n  5)/3 teams cross twice, and (n  1)/3 teams cross four times. Thus, f2 =
2(n  1)/3 + 2(n + 2)/3 + (4n  10)/3 + (4n  4)/3 = 4n  4. If k = n  1, team tn
crosses the bridge 2(n + 2)/3 times, while the remaining n  1 teams cross twice. Thus,
fn1 = 2(n + 2)/3 + 2(n  1) = (8n  2)/3.
For k = n2  1, the formula for fk is the same as that of case (d), except that one team
makes an additional trip across the bridge. For k = n2  1, the formula for fk is the same
as that of case (e), except that one team makes one fewer trip across the bridge. Finally,
for k = n2 + 1, the formula for fk is the same as that of case (f), except that two teams
make one additional trip across the bridge. A straightforward calculation then results in
verifying that f3m2 = fn/21 = (n2 + 6n  16)/3, f3m1 = fn/2 = (n2 + 9n  22)/3, and
f3m = fn/2+1 = (n2 + 9n  34)/3. This completes the proof.
For example, for the case m = 2 (see Table 10), we have n = 10, and so the total travel
distance of T is 24d1 + 36d2 + 42d3 + 48d4 + 56d5 + 52d6 + 38d7 + 36d8 + 26d9 .
Pn1
Let S = k=1
lk dk be the trivial lower bound of , found by adding the independent
lower bounds for each team ti . As we described in the proof of Lemma 1, we have lk =
k
2kd nk
3 e + 2(n  k)d 3 e because each of the k teams to the left of the dk bridge must make
at least 2d nk
3 e trips across the bridge, and the n  k teams to the right of this bridge must
make at least 2d k3 e trips across.
For m  3, it is straightforward to verify that flkk < 34 for all 1  k  n  1, thus
establishing our 34 -approximation for the LD-TTP. This ratio of 43 is the best possible due
and l3 = 4n  8, implying fl33  34 as n  .
to the case k = 3, which has f3 = 16n34
3
This worst-case scenario is achieved when dk = 0 for all k 6= 3, i.e., when teams {t1 , t2 , t3 }
are located at one vertex, and the remaining n  3 teams are located at another vertex.
A natural question is whether there exist similar constructions for n  0 and n  2
(mod 6). In these cases, in addition to the n  4 case we just analyzed, we ask whether a
4
3 -approximation is best possible. This is just one of many open questions arising from this
work.

6. Application to Benchmark Sets
We now apply our theories to various benchmark TTP sets. We start with the case n = 6,
and apply Theorems 1 and 2 to all known 6-team TTP benchmarks. In addition to NL6,
we examine a six-team set from the Super Rugby League (SUPER6), six galaxy stars whose
coordinates appear in three-dimensional space (GALAXY6), our earlier six-team circular
distance instance (CIRC6), and the trivial constant distance instance (CON6) where each
pair of teams has a distance of one unit.
For all our benchmark sets, we first order the six teams so that they approximate a
straight line, either through a formal line of best fit or an informal check by inspection.
271

fiHoshino & Kawarabayashi

Having ordered our six teams, we determine
the five-tuple (d1 , d2 , d3 , d4 , d5 ) from the dis
tance matrix and ignore the other 62  5 = 10 entries. Modifying our benchmark set and
assuming the six teams lie on a straight line, we solve the LD-TTP via Theorem 1. Using
Theorem 2, we take the set of tournament schedules achieving this
optimal distance and
6
apply the actual distance matrix of the benchmark set (with all 2 entries) to each of these
optimal schedules and output the tournament with the minimum total distance.
This simple process, each taking approximately 0.3 seconds of computation time per
benchmark set, generates a feasible solution to the 6-team TTP. To our surprise, this
algorithm outputs the distance-optimal schedule in all five of our benchmark sets. This
was an unexpected result, given the non-linearity of our data sets: for example, CIRC6
has the teams arranged in a circle, while GALAXY6 uses three-dimensional distances. To
illustrate our theory, let us begin with NL6, ordering the six teams from south to north:

Figure 5: Location of the six NL6 teams.
Thus, Florida is t1 , Atlanta is t2 , Pittsburgh is t3 , Philadelphia is t4 , New York is t5 , and
Montreal is t6 . From the NL6 distance matrix (Trick, 2012), we have (d1 , d2 , d3 , d4 , d5 ) =
(605, 521, 257, 80, 337).
Since 2 min{d2 + d4 , d1 + d4 , d3 + d4 , 3d4 , d2 + d5 , d2 + d3 , 3d2 } = 6d4 = 480, Theorem
1 tells us that the optimal LD-TTP solution has total distance S + 6d4 = 14d1 + 16d2 +
20d3 + 22d4 + 14d5 = 28424. By Theorem 2, there are 24 schedules in set S4 , all with total
distance S + 6d4 . Two of these 24 schedules are presented in Table 12.
t1
t2
t3
t4
t5
t6

1
t2
t1
t5
t6
t3
t4

2
t4
t5
t6
t1
t2
t3

3
t5
t3
t2
t6
t1
t4

4
t3
t4
t1
t2
t6
t5

5
t5
t6
t4
t3
t1
t2

6
t6
t3
t2
t5
t4
t1

7
t3
t4
t1
t2
t6
t5

8
t4
t6
t5
t1
t3
t2

9
t6
t5
t4
t3
t2
t1

10
t2
t1
t6
t5
t4
t3

t1
t2
t3
t4
t5
t6

1
t2
t1
t6
t5
t4
t3

2
t5
t6
t4
t3
t1
t2

3
t6
t3
t2
t5
t4
t1

4
t3
t5
t1
t6
t2
t4

5
t6
t4
t5
t2
t3
t1

6
t4
t3
t2
t1
t6
t5

7
t3
t5
t1
t6
t2
t4

8
t5
t4
t6
t2
t1
t3

9
t4
t6
t5
t1
t3
t2

10
t2
t1
t4
t3
t6
t5

Table 12: Two LD-TTP solutions with total distance S + 6d4 .
Removing this straight line assumption, we now apply the actual NL6 distance matrix
to determine the total distance traveled for each of these 24 schedules from set S4 , which
will naturally produce different sums. The left schedule in Table 12 is best among the
24 schedules, with total distance 23916, while the right schedule is the worst, with total
272

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

distance 24530. We note that the left schedule, achieving the optimal distance of 23916
miles, is identical to Table 1.
We repeat the same analysis with the other four benchmark sets. In each, we mark
which of the sets {S1 , S2 , . . . , S7 } produced the optimal schedule.
Benchmark
Data Set
NL6
SUPER6
GALAXY6
CIRC6
CON6

Optimal
Solution
23916
130365
1365
64
43

LD-TTP
Solution
23916
130365
1365
64
43

Optimal
Schedule
 S4
 S3
 S1
 S1
 S1

Table 13: Comparing LD-TTP to TTP on benchmark data sets.
A sophisticated branch-and-price heuristic (Irnich, 2010) solved NL6 in just over one
minute, yet required three hours to solve CIRC6. The latter problem was considerably
more difficult due to the inherent symmetry of the data set, which required more branching.
However, through our LD-TTP approach, both problems can be solved to optimality in the
same amount of time  approximately 0.3 seconds.
Based on the results of Table 13, we ask whether there exists a 6-team instance  where
the optimal TTP solution is different from the optimal LD-TTP solution. This question
will be answered in the following section.
To conclude this section, we apply the 34 -approximation produced by our expander
construction to various (non-linear) benchmark sets with n  4 (mod 6). We apply our
construction to the 10-team and 16-team instances of our earlier examples (Trick, 2012).
Instance
CONS10
CIRC10
NL10
SUPER10
GALAXY10
CONS16
CIRC16
NL16
GALAXY16

Optimal
124
242
59436
316329
4535
327
[846, 916]
[249477, 261687]
[13619, 14900]

Our Solution
128
276
63850
361924
4862
334
994
286439
15429

Percentage Gap
3.2%
14.0%
7.4%
14.4%
7.2%
2.1%
[8.5%, 17.5%]
[9.5%, 14.8%]
[3.6%, 13.3%]

Table 14: Comparing our construction to the optimal solution in nine benchmark sets.
For the GALAXY, NL, and SUPER instances, we first need to arrange the n teams to
approximate a straight line. To do this, we apply a simple algorithm that first randomly
assigns the n teams to {t1 , t2 , . . . , tn1 , x}, and calculates the sum total of distances between
each adjacent pair of teams. We generate a local line-of-best-fit by recursively selecting
two teams ti and tj and switching their positions if it reduces the sum of these n1 distances.
The algorithm terminates with a permutation of the n teams to {t1 , t2 , . . . , tn1 , x} that is
273

fiHoshino & Kawarabayashi

locally optimal (but perhaps not globally), from which we apply the expander construction
to calculate the total travel distance of our n-team tournament.
Instead of a time-consuming process that enumerates all n! permutations of the teams,
our simple algorithm generates a fast solution to each of our benchmark instances in less
than 2 seconds of total computation time. Despite the simplicity of our approach, we see
in Table 14 that the optimality gap is extremely small for the constant instances (CONS),
and is quite reasonable for all the other (non-linear) instances.

7. Optimality Gap
In Table 13, all five of the 6-team benchmark instances produced identical solutions for both
the TTP and LD-TTP. A natural question is whether this is always the case. We show that
the TTP and LD-TTP solutions must be identical for n = 4, but not necessarily for n = 6.
For any instance  on n teams, define X to be the total distance of an optimal TTP
solution, and X to be the total distance of an optimal LD-TTP solution. Define OGn to
X  X
be the maximum optimality gap, the largest value of X  taken over all instances .
Theorem 4. For any instance  on n = 4 teams, the optimal TTP solution is the optimal
LD-TTP solution. In other words, OG4 = 0%.
Proof. In Table 3, we showed that there are 18 non-isomorphic schedules with total distance
8(d1 + d2 + d3 ), i.e., 18 different solutions to the LD-TTP. For each of these 18 schedules,
we remove the linear distance assumption and determine the total travel distance as a
function of the six distance parameters (i.e., the variables in {Di,j : 1  i < j  4}). For
example, the schedule in Table 2 has total distance 4D1,2 + 2D1,3 + 2D1,4 + 3D2,3 + D2,4 +
5D3,4 which we represent by the 6-tuple (4, 2, 2, 3, 1, 5). Considering all 4! permutations
of {t1 , t2 , t3 , t4 }, there are 18  24 tournament schedules, producing 36 unique 6-tuples,
including (4, 2, 2, 3, 1, 5). Denote by L this set of thirty-six 6-tuples.
A brute-force enumeration finds 1920 feasible 4-team tournaments. For each of these
1920 tournaments, we determine the 6-tuple representing the total travel distance, and find
246 unique 6-tuples, which we denote by set A. By definition, L  A.
To prove that OG4 = 0, we must verify that for any set {D1,2 , D1,3 , D1,4 , D2,3 , D2,4 , D3,4 }
satisfying the Triangle Inequality, the optimal solutions of the TTP and LD-TTP are the
same, i.e., the optimal solution among all schedules (whose six-tuples are given by A)
appears in the subset of linear-distance schedules (whose six-tuples are given by L). To
establish this, we first use the Triangle Inequality to verify that for 204 of the 24636 = 210
elements in A\L, the corresponding schedule is dominated by at least one of the elements
in L.
For example, the six-tuple (3, 4, 3, 4, 1, 4) is one of the 210 elements in A\L. Comparing
this with the six-tuple (4, 2, 2, 3, 1, 5)  L, we see that the corresponding schedule in A\L has
total distance 2D1,3 +D1,4 +D2,3 D1,2 D3,4 = (D1,3 +D1,4 D3,4 )+(D1,3 +D2,3 D1,2 )  0
more than the corresponding schedule in L, which is given in Table 2.
A computer search shows that 204 of the 210 elements in A\L can be handled by
applying the Triangle Inequality in this way, showing it is dominated by at least one element in L. There are just six exceptions, namely the 6-tuples in the set {(2, 3, 3, 3, 3, 4),
(3, 2, 3, 3, 4, 3), (3, 3, 2, 4, 3, 3), (3, 3, 4, 2, 3, 3), (3, 4, 3, 3, 2, 3), and (4, 3, 3, 3, 3, 2)}. In these
274

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

cases, the analysis is slightly harder. Consider the six-tuple (2, 3, 3, 3, 3, 4); the rest can be
handled in the same way, by symmetry.
There are twelve 6-tuples in L which have 17 total trips, where the D1,2 coefficient is
strictly less than the D4,5 coefficient. (An example of one such 6-tuple is (4, 2, 2, 3, 1, 5).)
Taking its average, we derive the 6-tuple (7/3, 17/6, 17/6, 17/6, 17/6, 10/3), implying the
existence of at least one LD-TTP schedule whose total distance X is at most (14D1,2 +
17D1,3 + 17D1,4 + 17D2,3 + 17D2,4 + 20D3,4 )/6. Let Y be the distance represented by the
6-tuple (2, 3, 3, 3, 3, 4). Then by the Triangle Inequality,
6(Y  X) = 2D1,2 + D1,3 + D1,4 + D2,3 + D2,4 + 4D3,4
= (D1,3 + D3,4 + D4,2  D2,1 ) + (D1,4 + D4,3 + D3,2  D2,1 ) + 2D3,4
 0 + 0 + 2  0 = 0.
In other words, we have shown that every element in A\L is dominated by at least
one element in L. Therefore, for any choice of {D1,2 , D1,3 , D1,4 , D2,3 , D2,4 , D3,4 } satisfying
the Triangle Inequality, the optimal solutions of the TTP and LD-TTP are the same, i.e.,
OG4 = 0%.
In an earlier paper (Hoshino & Kawarabayashi, 2012), the authors conjectured that
OG6 > 0%, although we were unable to find a 6-team instance with a positive optimality
1
 2.3%.
gap. Here we present a simple instance to show that OG6  43
Let 
 be the 6-team instance with D1,2 = D5,6 = 2 and all other Di,j = 1. Clearly
these 62 = 15 distances satisfy the Triangle Inequality. We now show that X = 43 and
1
. Consider Table 15, which is a solution to the TTP
X = 44, thus proving that OG6  43
(but not LD-TTP) with 43 trips.
t1
t2
t3
t4
t5
t6

1
t5
t6
t4
t3
t1
t2

2
t2
t1
t6
t5
t4
t3

3
t3
t5
t1
t6
t2
t4

4
t5
t6
t4
t3
t1
t2

5
t3
t5
t1
t6
t2
t4

6
t4
t3
t2
t1
t6
t5

7
t6
t4
t5
t2
t3
t1

8
t4
t3
t2
t1
t6
t5

9
t2
t1
t6
t5
t4
t3

10
t6
t4
t5
t2
t3
t1

# of Trips
7
7
8
7
7
7

Table 15: An optimal 43-trip TTP solution that beats the optimal LD-TTP solution.
By inspection, we see that no team travels along the bridge connecting the stadiums of
t1 and t2 , or along the bridge connecting the stadiums of t5 and t6 . Thus, the total travel
distance must be 43  1 = 43, since the 2-unit distances D1,2 and D5,6 do not appear in the
total sum. Since every 6-team tournament must have at least 43 total trips (see Table 13),
this proves that X = 43.
For each of the 295 potentially-optimal LD-TTP schedules in Theorem 2, we consider
all 6! = 720 permutations of (t1 , t2 , t3 , t4 , t5 , t6 ) to see if any tournament can have total
distance 43. A computer search shows that 36 of the 295 schedules can have total distance
44, but none can have distance 43. This proves that X = 44 is the optimal LD-TTP travel
distance for this instance .
275

fiHoshino & Kawarabayashi

1
 2.3%. We ask whether
Therefore, the maximum optimality gap OG6 is at least 43
this gap can be made larger, and propose the following question.

Problem 1. Determine the value of OGn for n  6.
Suppose that OG6 = 5%. Then one of the 295 LD-TTP solutions in Theorem 2 is at
most 5% higher than the optimal TTP solution, found at a fraction of the computational
cost. Of course, this is not necessary for the case n = 6 as we can use integer and constraint
programming to output the TTP solution in a reasonable amount of time. However, for
larger values of n, this linear distance relaxation technique would allow us to quickly generate
close-to-optimal solutions when the exact optimal total distance is unknown or too difficult
computationally. We are hopeful that this approach will help us develop better upper
bounds for large unsolved benchmark instances.

8. Conclusion
In many professional sports leagues, teams are divided into two conferences, where teams
have intra-league games within their own conference as well as inter-league games against
teams from other conference. The TTP models intra-league tournament play. The NPcomplete Bipartite Traveling Tournament Problem (Hoshino & Kawarabayashi, 2011) models inter-league play, and it would be interesting to see whether our linear distance relaxation
can also be applied to bipartite instances to help formulate new ideas in inter-league tournament scheduling.
We conclude the paper by proposing two new benchmark instances for the Traveling
Tournament Problem, as well as an open problem and a conjecture on the Linear Distance
TTP. We first begin with the benchmark instances.
For each n  4, define LINEn to be the instance where the n teams are located on a
straight line, with a distance of one unit separating each pair of adjacent teams, i.e., dk = 1
for all 1  k  n  1. And define INCRn to be the increasing-distance scenario where the
n teams are arranged so that dk = k for all 1  k  n  1. Figure 6 illustrates the location
of each team in INCR6.

Figure 6: The instance INCR6.
By definition, the TTP solution matches the LD-TTP solution for each of these two
instances. By Theorem 1, the optimal solutions for LINE6 and INCR6 have total distance
84 and 250, respectively. This naturally motivates the following problem:
Problem 2. Solve the TTP for the instances LINEn and INCRn, for n  8.
We conclude with one more problem, inspired by Theorem 2 which listed all seven
possible optimal distances for the 6-team LD-TTP:
276

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

Problem 3. Let P Dn denote the number of possible distances that can be a solution to the
n-team LD-TTP. For example, P D4 = 1 and P D6 = 7. Prove or disprove that P Dn is
exponential in n.

Acknowledgments
This research has been partially supported by the Japan Society for the Promotion of Science
(Grant-in-Aid for Scientific Research), the C & C Foundation, the Kayamori Foundation,
and the Inoue Research Award for Young Scientists. The authors thank Brett Stevens from
Carleton University for suggesting the idea of the Linear Distance TTP during the 2010
Winter Meeting of the Canadian Mathematical Society.

Appendix A
We used Maplesoft (www.maplesoft.com) to generate the set of optimal LD-TTP schedules
for n = 4 and n = 6. In this appendix, we explain the process by which we generated the
36 optimal schedules for the case n = 4.
To simplify notation, we used the numbers 1 to 4 to represent the team numbers of
opponents for road games, and the numbers 11 to 14 to represent the team numbers of
opponents for home games. Thus, in our notation, the schedule on the left (from Table 2)
is identical to the 4  6 matrix on the right.
Team
t1
t2
t3
t4

1
t4
t3
t2
t1

2
t3
t4
t1
t2

3
t2
t1
t4
t3

4
t4
t3
t2
t1

5
t3
t4
t1
t2

6
t2
t1
t4
t3

14 13 2 4 3 12
13 14 11 3 4 1
2 1 14 12 11 4
1 2 3 11 12 13

To produce the set of 36 schedules, the following code was used:
restart: with(combinat):
A1 :=
A3 :=
B1 :=
B3 :=
C1 :=
C3 :=
Z[{1,
Z[{1,

<,>(12, 1, 14, 3): A2
<,>(2, 11, 14, 3): A4
<,>(13, 14, 1, 2): B2
<,>(3, 14, 11, 2): B4
<,>(14, 13, 2, 1): C2
<,>(4, 13, 2, 11): C4
2}] := d1: Z[{2, 3}] :=
3}] := d1+d2: Z[{1, 4}]

:= <,>(12, 1, 4, 13):
:= <,>(2, 11, 4, 13):
:= <,>(13, 4, 1, 12):
:= <,>(3, 4, 11, 12):
:= <,>(14, 3, 12, 1):
:= <,>(4, 3, 12, 11):
d2: Z[{3, 4}] := d3:
:= d1+d2+d3: Z[{2, 4}] := d2+d3:

dist := proc (myinput, k)
local i, myseq, x; x := 0; myseq :=
for i to 7 do
if 7<= myseq[i] and 7<= myseq[i+1]
elif 7<= myseq[i] and myseq[i+1]<7
elif myseq[i]<7 and 7<= myseq[i+1]

[7, op(myinput), 7];
then x:=x
then x:=x+Z[{myseq[i+1],k}]
then x:=x+Z[{myseq[i],k}]
277

fiHoshino & Kawarabayashi

elif myseq[i]<7 and myseq[i+1]<7 then x:=x+Z[{myseq[i+1],myseq[i]}]
else RETURN(ERROR)
fi:
od: x: end:
checker := proc (my720)
local k, flag, x, y, goodlist, temp; goodlist := NULL;
for k to 720 do
temp := Matrix([seq(my720[k][t], t = 1 .. 6)]); flag := 0;
for x to 4 do for y to 5 do
if abs(temp[x][y]-temp[x][y+1])=10 then flag:=1 fi:
od: od:
for x to 4 do
if dist([seq(temp[x,k],k = 1..6)],x)<>2*(d1+d2+d3) then flag := 1 fi:
od:
if flag = 0 then goodlist := goodlist, temp: fi:
od: goodlist: end:
my720 := permute([A1, A4,
my720 := permute([A1, A4,
my720 := permute([A1, A4,
my720 := permute([A1, A4,
my720 := permute([A2, A3,
my720 := permute([A2, A3,
my720 := permute([A2, A3,
my720 := permute([A2, A3,
finallist := [set1, set2,

B1, B4, C1,
B1, B4, C2,
B2, B3, C1,
B2, B3, C2,
B1, B4, C1,
B1, B4, C2,
B2, B3, C1,
B2, B3, C2,
set3, set4,

C4]):
C3]):
C4]):
C3]):
C4]):
C3]):
C4]):
C3]):
set5,

set1 := checker(my720):
set2 := checker(my720):
set3 := checker(my720):
set4 := checker(my720):
set5 := checker(my720):
set6 := checker(my720):
set7 := checker(my720):
set8 := checker(my720):
set6, set7, set8];

Appendix B
We now provide the Maplesoft code from which we generated the 295 non-isomorphic schedules in Theorem 2. Due to symmetry, we only need to consider the cases S1 , S2 , S3 , S4 . The
authors would be happy to provide the full set of 295 schedules (available as a simple .txt
file upon request), and/or answer any questions that explain why this code generates the
complete set of optimal schedules for the n = 6 case of the LD-TTP.
restart: with(combinat):
Z := Matrix(6, 6, 0):
Z[1, 2] := a: Z[1, 3] := a+b: Z[1, 4] := a+b+c: Z[1, 5] := a+b+c+d:
Z[1, 6] := a+b+c+d+e: Z[2, 3] := b: Z[2, 4] := b+c: Z[2, 5] := b+c+d:
Z[2, 6] := b+c+d+e: Z[3, 4] := c: Z[3, 5] := c+d: Z[3, 6] := c+d+e:
Z[4, 5] := d: Z[4, 6] := d+e: Z[5, 6] := e:
for i to 6 do for j from i+1 to 6 do Z[j, i] := Z[i, j] od: od:
all252 := choose(10, 5): combos := []:
278

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

for i to 252 do
test := all252[i]: flag := 0:
for j to 2 do if test[j+3]-test[j] <= 3 then flag := 1: fi: od:
for j to 4 do if test[j+1]-test[j] >= 5 then flag := 1: fi: od:
if or(test[1] >= 5, test[5] <= 6) then flag := 1 fi:
if flag = 0 then combos := [op(combos), test]: fi:
od:
totaldist := proc (myinput, k)
local i, myseq, y; y := 0; myseq := [7, op(myinput), 7];
for i to 11 do
if 7<= myseq[i] and 7<= myseq[i+1] then y:=y
elif 7<= myseq[i] and myseq[i+1]<7 then y:=y+Z[myseq[i+1],k]
elif myseq[i]<7 and 7<= myseq[i+1] then y:=y+Z[myseq[i],k]
elif myseq[i]<7 and myseq[i+1]<7 then y:=y+Z[myseq[i+1],myseq[i]]
else RETURN(ERROR)
fi:
od: y: end:
getseq := proc (myfive, k)
local myperm, myseq, mylist, i, j;
mylist := []; myperm := permute(minus({1, 2, 3, 4, 5, 6}, {k}));
for i to 120 do myseq := [seq(7, i = 1 .. 10)];
for j to 5 do myseq[myfive[j]] := myperm[i][j]: od:
mylist := [op(mylist), myseq]
od:
mylist: end:
checkdup := proc (tryj, j, tryk, k)
local i, val1, val2, x; x := 0;
i:=0: while x=0 and i<10 do
i:=i+1; if tryj[i]=tryk[i] and tryj[i]<7 then x:=1: fi: od:
i:=0: while x=0 and i<10 do
i:=i+1; if tryj[i]=k then if tryk[i]<7 then x:=1: fi: fi: od:
i:=0: while x=0 and i<10 do
i:=i+1; if tryk[i]=j then if tryj[i]<7 then x:=1: fi: fi: od:
i:=0: while x=0 and i<10 do
i:=i+1; if tryk[i]=j then val1:=i fi: if tryj[i]=k then val2:=i: fi: od:
if x = 0 then if abs(val1-val2) <= 1 then x := 1: fi: fi:
x: end:
fivetuple := proc (myset)
[coeff(myset,a),coeff(myset,b),coeff(myset,c),coeff(myset,d),coeff(myset,e)]:
end:

279

fiHoshino & Kawarabayashi

for p to 5 do for q to 5 do for r to 5 do
for s to 5 do for t to 5 do for k to 6 do
S[k, [2*p, 2*q, 2*r, 2*s, 2*t]] := NULL:
od: od: od: od: od: od:
for kk to 6 do allvals[kk] := {}: od:
for r to 194 do x := getseq(combos[r], 1):
for s to 120 do if in(2, {seq(x[s][k], k = 6 .. 10)}) then
y := fivetuple(totaldist(x[s], 1));
allvals[1] := {y, op(allvals[1])}; S[1, y] := S[1, y], x[s] fi: od: od:
for r to 194 do x := getseq(combos[r], 2):
for s to 120 do y := fivetuple(totaldist(x[s], 2));
allvals[2] := {y, op(allvals[2])}; S[2, y] := S[2, y], x[s] od: od:
for r to 194 do x := getseq(combos[r], 3);
for s to 120 do y := fivetuple(totaldist(x[s], 3));
allvals[3] := {y, op(allvals[3])}; S[3, y] := S[3, y], x[s] od: od:
for r to 194 do x := getseq(combos[r], 4);
for s to 120 do y := fivetuple(totaldist(x[s], 4));
allvals[4] := {y, op(allvals[4])}; S[4, y] := S[4, y], x[s] od: od:
for r to 194 do x := getseq(combos[r], 5);
for s to 120 do y := fivetuple(totaldist(x[s], 5));
allvals[5] := {y, op(allvals[5])}; S[5, y] := S[5, y], x[s] od: od:
for r to 194 do x := getseq(combos[r], 6);
for s to 120 do y := fivetuple(totaldist(x[s], 6));
allvals[6] := {y, op(allvals[6])}; S[6, y] := S[6, y], x[s] od: od:
for pp to 10 do for qq to 10 do for rr to 10 do for ss to 10 do
triplet1[[2*pp, 2*qq, 2*rr, 2*ss, 6]] := []: od: od: od: od:
for pp to 10 do for qq to 10 do for rr to 10 do for ss to 10 do
triplet2[[6, 2*ss, 2*rr, 2*qq, 2*pp]] := []: od: od: od: od:
for pp to nops(allvals[1]) do
for qq to nops(allvals[2]) do
for rr to nops(allvals[3]) do
val := allvals[1][pp]+allvals[2][qq]+allvals[3][rr];
triplet1[val] := [op(triplet1[val]), [pp, qq, rr]]
od: od: od:
for pp to nops(allvals[4]) do
280

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

for qq to nops(allvals[5]) do
for rr to nops(allvals[6]) do
val := allvals[4][pp]+allvals[5][qq]+allvals[6][rr];
triplet2[val] := [op(triplet2[val]), [pp, qq, rr]]
od: od: od:
getnext := proc (inputset, x, setx)
local i, k1, k2, k3, candx, mylist;
mylist := NULL;
k1 := op(minus({1, 2, 3, 4, 5, 6, 7}, {op(inputset[1])}));
k2 := op(minus({1, 2, 3, 4, 5, 6, 7}, {op(inputset[2])}));
k3 := op(minus({1, 2, 3, 4, 5, 6, 7}, {op(inputset[3])}));
for i to nops(setx) do candx := setx[i];
if checkdup(candx, x, inputset[1], k1) = 0 then
if checkdup(candx, x, inputset[2], k2) = 0 then
if checkdup(candx, x, inputset[3], k3) = 0 then
mylist := mylist, candx fi: fi: fi: od:
[mylist]: end:
getpos := proc (aval, bval, cval, dval)
local pos3, pos4, pos5, pos6;
if aval = 3 then pos3 := 2 elif aval = 4 then pos4 := 2 elif aval =
pos5 := 2 elif aval = 6 then pos6 := 2 else RETURN(ERROR) end if;
if bval = 3 then pos3 := 3 elif bval = 4 then pos4 := 3 elif bval =
pos5 := 3 elif bval = 6 then pos6 := 3 else RETURN(ERROR) end if;
if cval = 3 then pos3 := 7 elif cval = 4 then pos4 := 7 elif cval =
pos5 := 7 elif cval = 6 then pos6 := 7 else RETURN(ERROR) end if;
if dval = 3 then pos3 := 8 elif dval = 4 then pos4 := 8 elif dval =
pos5 := 8 elif dval = 6 then pos6 := 8 else RETURN(ERROR) end if;
[pos3, pos4, pos5, pos6]: end:

5 then
5 then
5 then
5 then

firsttwo := proc (aval, bval, cval, dval,new1,new2)
local pairs12, p, q, i, t1, t2, flag; pairs12 := {};
for p to nops(new1) do for q to nops(new2) do
if checkdup(new1[p], 1, new2[q], 2) = 0 then
if new1[p][4] <> bval and new1[p][6] <> cval and new1[p][9] <> dval and
new2[q][2] <> aval and new2[q][5] <> bval and new2[q][7] <> cval then
flag := 0;
t1:=[2,aval,bval,new1[p][4],new1[p][5],new1[p][6],cval,dval,new1[p][9],2];
t2:=[1,new2[q][2],aval,bval,new2[q][5],new2[q][6],new2[q][7],cval,dval,1];
for i to 9 do if t1[i]=t2[i+1] and t1[i+1]=t2[i] then flag:=1 fi: od:
if flag = 0 then pairs12 := {op(pairs12), [new1[p], new2[q]]} fi: fi: fi:
od: od:
pairs12: end:

281

fiHoshino & Kawarabayashi

firstthree := proc (pairs12, sixpos, new6)
local last6, mytry, trips126, p, q, k; last6 := {}; trips126 := {};
for k to nops(new6) do mytry := new6[k];
if mytry[sixpos] = 1 and mytry[sixpos+1] = 2 then
last6 := {op(last6), mytry} fi:
od:
for p to nops(pairs12) do for q to nops(last6) do
if checkdup(pairs12[p][1], 1, last6[q], 6) = 0 and
checkdup(pairs12[p][2], 2, last6[q], 6) = 0 then
trips126 := {op(trips126), [op(pairs12[p]), last6[q]]}: fi:
od: od:
trips126: end:
steps126 := proc (new1, new2, new6)
local i, j, k, finalsol; finalsol := NULL;
for i to nops(new1) do for j to nops(new2) do
if checkdup(new1[i], 1, new2[j], 2) = 0 then
for k to nops(new6) do
if checkdup(new1[i], 1, new6[k], 6) = 0 and
checkdup(new2[j], 2, new6[k], 6) = 0 then
finalsol := finalsol, [new1[i], new2[j], new6[k]]:
fi: od: fi: od: od:
[finalsol]: end:
steps345 := proc (iset, new3, new4, new5)
local mylist, tryd, trye, tryf, candd, cande, candf, a, b, c;
mylist := NULL; tryd := getnext(iset, 3, new3);
if tryd <> [] then trye := getnext(iset, 4, new4);
if trye <> [] then tryf := getnext(iset, 5, new5);
if tryf <> [] then for a to nops(tryd) do candd := tryd[a];
for b to nops(trye) do cande := trye[b];
if checkdup(candd, 3, cande, 4) = 0 then
for c to nops(tryf) do candf := tryf[c];
if checkdup(candf, 5, candd, 3) = 0 then
if checkdup(candf, 5, cande, 4) = 0 then
mylist := mylist, [iset[1], iset[2], candd, cande, candf, iset[3]]:
fi: fi: od: fi: od: od: fi: fi: fi:
[mylist]: end:
allsix := proc (my126,aval,bval,cval,dval,new3,new4,new5)
local last3, last4, last5, k, mytry, tempval, pos3, pos4, pos5,
finalresult, p, q, r, s, trips345, my345, valnext, finalans;
last3:={}; last4:={}; last5:={}; finalresult:={}; trips345:={};
tempval := getpos(aval, bval, cval, dval);
pos3 := tempval[1]; pos4 := tempval[2]; pos5 := tempval[3];
282

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

for k to nops(new3) do mytry := new3[k];
if mytry[pos3] = 1 and mytry[pos3+1] = 2 then
if checkdup(my126[1], 1, mytry, 3) = 0 and
checkdup(my126[2], 2, mytry, 3) = 0 and
checkdup(my126[3], 6, mytry, 3) = 0 then
last3 := {op(last3), mytry} fi: fi:
od:
for k to nops(new4) do mytry := new4[k];
if mytry[pos4] = 1 and mytry[pos4+1] = 2 then
if checkdup(my126[1], 1, mytry, 4) = 0 and
checkdup(my126[2], 2, mytry, 4) = 0 and
checkdup(my126[3], 6, mytry, 4) = 0 then
last4 := {op(last4), mytry} fi: fi:
od:
for k to nops(new5) do mytry := new5[k];
if mytry[pos5] = 1 and mytry[pos5+1] = 2 then
if checkdup(my126[1], 1, mytry, 5) = 0 and
checkdup(my126[2], 2, mytry, 5) = 0 and
checkdup(my126[3], 6, mytry, 5) = 0 then
last5 := {op(last5), mytry} fi: fi:
od:
for p to nops(last3) do for q to nops(last4) do
if checkdup(last3[p], 3, last4[q], 4) = 0 then
for r to nops(last5) do
if checkdup(last3[p], 3, last5[r], 5) = 0 and
checkdup(last4[q], 4, last5[r], 5) = 0 then
trips345 := {op(trips345), [last3[p], last4[q], last5[r]]}:
fi: od: fi: od: od:
for s to nops(trips345) do my345 := trips345[s];
finalresult := {op(finalresult),
[my126[1], my126[2], my345[1], my345[2], my345[3], my126[3]]}:
od:
finalresult: end:
checkallsolutions := proc(sixtuples)
local k,rr,mysolutions,cand1,cand2,cand3,cand4,cand5,cand6,
new1,new2,new3,new4,new5,new6,mytry,firsthalf,val:
mysolutions := []:
for rr to nops(sixtuples) do
cand1 := [S[1, allvals[1][sixtuples[rr][1]]]];
cand2 := [S[2, allvals[2][sixtuples[rr][2]]]];
cand3 := [S[3, allvals[3][sixtuples[rr][3]]]];
cand4 := [S[4, allvals[4][sixtuples[rr][4]]]];
cand5 := [S[5, allvals[5][sixtuples[rr][5]]]];
cand6 := [S[6, allvals[6][sixtuples[rr][6]]]];
283

fiHoshino & Kawarabayashi

new1 := {}; new2 := {}; new3 := {}; new4 := {}; new5 := {}; new6 := {};
for k to nops(cand1) do mytry := cand1[k]; new1 := {mytry, op(new1)}: od:
for k to nops(cand2) do mytry := cand2[k]; new2 := {mytry, op(new2)}: od:
for k to nops(cand3) do mytry := cand3[k]; new3 := {mytry, op(new3)}: od:
for k to nops(cand4) do mytry := cand4[k]; new4 := {mytry, op(new4)}: od:
for k to nops(cand5) do mytry := cand5[k]; new5 := {mytry, op(new5)}: od:
for k to nops(cand6) do mytry := cand6[k]; new6 := {mytry, op(new6)}: od:
firsthalf := steps126(new1, new2, new6);
for k to nops(firsthalf) do val:=steps345(firsthalf[k],new3,new4,new5);
if val <> [] then mysolutions := [op(mysolutions), op(val)]: fi:
od: od:
mysolutions: end:
generatesolutions := proc(sixtuples)
local cand1,cand2,cand3,cand4,cand5,cand6,new1,new2,new3,new4,new5,new6,
k,rr,x,y,mytry,flag,aval,bval,cval,dval,pairs12,sixpos,trips126,my24,sols:
sols := {}: my24 := permute([3,4,5,6]):
for rr to nops(sixtuples) do
cand1 := [S[1, allvals[1][sixtuples[rr][1]]]];
cand2 := [S[2, allvals[2][sixtuples[rr][2]]]];
cand3 := [S[3, allvals[3][sixtuples[rr][3]]]];
cand4 := [S[4, allvals[4][sixtuples[rr][4]]]];
cand5 := [S[5, allvals[5][sixtuples[rr][5]]]];
cand6 := [S[6, allvals[6][sixtuples[rr][6]]]];
new1:={}; new2:={}; new3:={}; new4:={}; new5:={}; new6:={};
for k to nops(cand1) do mytry := cand1[k];
if {mytry[1], mytry[2], mytry[3], mytry[7], mytry[8]} = {7} and
mytry[10] = 2 then new1 := {mytry, op(new1)}: fi: od:
for k to nops(cand2) do mytry := cand2[k];
if {mytry[3], mytry[4], mytry[8], mytry[9], mytry[10]} = {7} and
mytry[1] = 1 then new2 := {mytry, op(new2)}: fi: od:
for k to nops(cand3) do mytry := cand3[k]; flag := 0;
if and(mytry[1] > 2, mytry[10] > 2) then
if mytry[2] = 1 and mytry[3] = 2 then flag := 1 fi:
if mytry[3] = 1 and mytry[4] = 2 then flag := 1 fi:
if mytry[7] = 1 and mytry[8] = 2 then flag := 1 fi:
if mytry[8] = 1 and mytry[9] = 2 then flag := 1 fi:
if flag = 1 then new3 := {mytry, op(new3)}: fi: fi: od:
for k to nops(cand4) do mytry := cand4[k]; flag := 0;
if and(mytry[1] > 2, mytry[10] > 2) then
if mytry[2] = 1 and mytry[3] = 2 then flag := 1 fi:
if mytry[3] = 1 and mytry[4] = 2 then flag := 1 fi:
if mytry[7] = 1 and mytry[8] = 2 then flag := 1 fi:
if mytry[8] = 1 and mytry[9] = 2 then flag := 1 fi:
if flag = 1 then new4 := {mytry, op(new4)}: fi: fi: od:
284

fiGenerating Approximate Solutions to the TTP using a Linear Distance Relaxation

for k to nops(cand5) do mytry := cand5[k]; flag := 0;
if and(mytry[1] > 2, mytry[10] > 2) then
if mytry[2] = 1 and mytry[3] = 2 then flag := 1 fi:
if mytry[3] = 1 and mytry[4] = 2 then flag := 1 fi:
if mytry[7] = 1 and mytry[8] = 2 then flag := 1 fi:
if mytry[8] = 1 and mytry[9] = 2 then flag := 1 fi:
if flag = 1 then new5 := {mytry, op(new5)}: fi: fi: od:
for k to nops(cand6) do mytry := cand6[k]; flag := 0;
if and(mytry[1] > 2, mytry[10] > 2) then
if mytry[2] = 1 and mytry[3] = 2 then flag := 1 fi:
if mytry[3] = 1 and mytry[4] = 2 then flag := 1 fi:
if mytry[7] = 1 and mytry[8] = 2 then flag := 1 fi:
if mytry[8] = 1 and mytry[9] = 2 then flag := 1 fi:
if flag = 1 then new6 := {mytry, op(new6)}: fi: fi: od:
for x to 24 do
aval := my24[x][1]; bval := my24[x][2];
cval := my24[x][3]; dval := my24[x][4];
pairs12 := firsttwo(aval, bval, cval, dval,new1,new2);
sixpos := getpos(aval, bval, cval, dval)[4];
trips126 := firstthree(pairs12, sixpos, new6);
for y to nops(trips126) do
sols := {op(sols),op(allsix(trips126[y],
aval,bval,cval,dval,new3,new4,new5))}:
od:
od:
od:
sols: end:

S4cases := []:
for pp to 8 do for qq to 8 do
xx := triplet1[[8, 10, 2*pp, 2*qq, 6]];
yy := triplet2[[6, 6, 20-2*pp, 22-2*qq, 8]];
for u in xx do for v in yy do S4cases := [op(S4cases), [op(u), op(v)]]:
od: od: od: od:
SolutionsForS4 := generatesolutions(S4cases):
S3cases := []:
for pp from 2 to 8 do for qq to 8 do
xx := triplet1[[8, 10, 2*pp, 2*qq, 6]];
yy := triplet2[[6, 6, 22-2*pp, 18-2*qq, 8]];
for u in xx do for v in yy do S3cases := [op(S3cases), [op(u), op(v)]]:
od: od: od: od:
SolutionsForS3 := generatesolutions(S3cases):

285

fiHoshino & Kawarabayashi

S2cases := []:
for pp to 9 do for qq to 9 do
xx := triplet1[[10, 10, 2*pp, 2*qq, 6]];
yy := triplet2[[6, 6, 20-2*pp, 18-2*qq, 8]];
for u in xx do for v in yy do S2cases := [op(S2cases), [op(u), op(v)]]:
od: od: od: od:
SolutionsForS2 := checkallsolutions(S2cases):
S1cases := []:
for pp to 8 do for qq to 8 do for rr to 8 do
xx := triplet1[[8, 2*pp, 2*qq, 2*rr, 6]]:
yy := triplet2[[6, 18-2*pp, 20-2*qq, 18-2*rr, 8]]:
for u in xx do for v in yy do S1cases := [op(S1cases), [op(u), op(v)]]:
od: od: od: od: od:
SolutionsForS1 := checkallsolutions(S1cases):

References
Easton, K., Nemhauser, G., & Trick, M. (2001). The traveling tournament problem: description and benchmarks. Proceedings of the 7th International Conference on Principles
and Practice of Constraint Programming, 580584.
Fujiwara, N., Imahori, S., Matsui, T., & Miyashiro, R. (2007). Constructive algorithms
for the constant distance traveling tournament problem. Lecture Notes in Computer
Science, 3867, 135146.
Hoshino, R., & Kawarabayashi, K. (2011). Scheduling bipartite tournaments to minimize
total travel distance. Journal of Artificial Intelligence Research, 42, 91124.
Hoshino, R., & Kawarabayashi, K. (2012). The linear distance traveling tournament problem. Proceedings of the 26th AAAI Conference on Artificial Intelligence, 17701778.
Irnich, S. (2010). A new branch-and-price algorithm for the traveling tournament problem.
European Journal of Operational Research, 204, 218228.
Kendall, G., Knust, S., Ribeiro, C., & Urrutia, S. (2010). Scheduling in sports: An annotated
bibliography. Computers and Operations Research, 37, 119.
Thielen, C., & Westphal, S. (2010). Complexity of the traveling tournament problem.
Theoretical Computer Science, 412, 345351.
Trick, M. (2012). Challenge traveling tournament problems.. [Online; accessed 9-June-2012].
Yamaguchi, D., Imahori, S., Miyashiro, R., & Matsui, T. (2011). An improved approximation algorithm for the traveling tournament problem. Annals of Operations Research,
61(4), 10771091.

286

fiJournal of Artificial Intelligence Research 45 (2012) 515-564

Submitted 8/12; published 12/12

Safe Exploration of State and Action Spaces in
Reinforcement Learning
Javier Garca
Fernando Fernandez

fjgpolo@inf.uc3m.es
ffernand@inf.uc3m.es

Universidad Carlos III de Madrid,
Avenida de la Universidad 30,
28911 Leganes, Madrid, Spain

Abstract
In this paper, we consider the important problem of safe exploration in reinforcement
learning. While reinforcement learning is well-suited to domains with complex transition
dynamics and high-dimensional state-action spaces, an additional challenge is posed by
the need for safe and efficient exploration. Traditional exploration techniques are not
particularly useful for solving dangerous tasks, where the trial and error process may lead
to the selection of actions whose execution in some states may result in damage to the
learning system (or any other system). Consequently, when an agent begins an interaction
with a dangerous and high-dimensional state-action space, an important question arises;
namely, that of how to avoid (or at least minimize) damage caused by the exploration of the
state-action space. We introduce the PI-SRL algorithm which safely improves suboptimal
albeit robust behaviors for continuous state and action control tasks and which efficiently
learns from the experience gained from the environment. We evaluate the proposed method
in four complex tasks: automatic car parking, pole-balancing, helicopter hovering, and
business management.

1. Introduction
Reinforcement learning (RL) (Sutton & Barto, 1998) is a type of machine learning whose
main goal is that of finding a policy that moves an agent optimally in an environment, generally formulated as a Markov Decision Process (MDP). Many RL methods are being used
in important and complex tasks (e.g., robot control see Smart & Kaelbling, 2002; Hester,
Quinlan, & Stone, 2011, stochastic games see Mannor, 2004; Konen & Bartz-Beielstein,
2009 and control optimization of complex dynamical systems see Salkham, Cunningham,
Garg, & Cahill, 2008). While most RL tasks are focused on maximizing a long-term cumulative reward, RL researchers are paying increasing attention not only to long-term
reward maximization, but also to the safety of approaches to Sequential Decision Problems
(SDPs) (Mihatsch & Neuneier, 2002; Hans, Schneegass, Schafer, & Udluft, 2008; Martn H.
& Lope, 2009; Koppejan & Whiteson, 2011). Well-written reviews of these matters can also
be found (Geibel & Wysotzki, 2005; Defourny, Ernst, & Wehenkel, 2008). Nevertheless,
while it is important to ensure reasonable system performance and consider the safety of
the agent (e.g., avoiding collisions, crashes, etc.) in the application of RL to dangerous
tasks, most exploration techniques in RL offer no guarantees on both issues. Thus, when
using RL techniques in dangerous control tasks, an important question arises; namely, how
can we ensure that the exploration of the state-action space will not cause damage or injury
c
2012
AI Access Foundation. All rights reserved.

fiGarca & Fernandez

while, at the same time, learning (near-)optimal policies? The matter, in other words, is
one of ensuring that the agent be able to explore a dangerous environment both safely and
efficiently. There are many domains where the exploration/exploitation process may lead
to catastrophic states or actions for the learning agent (Geibel & Wysotzki, 2005). The
helicopter hovering control task is one such case involving high risk, since some policies
can crash the helicopter, incurring catastrophic negative reward. Exploration/exploitation
strategies such as greedy may even result in constant helicopter crashes (especially where
there is a high probability of random action selection). Another example can be found in
portfolio theory where analysts are expected to find a portfolio that maximizes profit while
avoiding risks of considerable losses (Luenberger, 1998). Since the maximization of expected
returns does not necessarily prevent rare occurrences of large negative outcomes, a different
criteria for safe exploration is needed. The exploration process in which new policies are
evaluated must be conducted with extreme care. Indeed, for such environments, a method is
required which not only explores the state-action space, but which does so in a safe manner.
In this paper, we propose the Policy Improvement through Safe Reinforcement Learning
(PI-SRL) algorithm for safe exploration in dangerous and continuous control tasks. Such a
method requires a predefined (and safe) baseline policy which is assumed to be suboptimal
(otherwise, learning would be pointless). Predefined baseline policies have been used in
different ways by other approaches. In the work of Koppejan and Whiteson (2011), singlelayers perceptrons are evolved, albeit starting from a prototype network whose weights correspond to a baseline policy provided by helicopter control task competition software (Abbeel,
Coates, Hunter, & Ng, 2008). This approach can be viewed as a simple form of population seeding which has proven to be advantageous in numerous evolutionary methods
(e.g. see Hernandez-Daz, Coello, Perez, Caballero, Luque, & Santana-Quintero, 2008; Poli
& Cagnoni, 1997). In the work of Martn and de Lope (2009), the weights of neural networks are also evolved by inserting several baseline policies (including that provided in the
helicopter control task competition software) into the initial population. To minimize the
possibility of evaluating unsafe policies, their approach prevents crossover and mutation
operators from permitting anything more than tiny changes to the initial baseline policies.
In this paper, we present the PI-SRL algorithm, a novel approach to improving baseline
policies in dangerous domains using RL. The PI-SRL algorithm is composed of two different steps. In the first, baseline behavior (robust albeit suboptimal) is approximated
using behavioral cloning techniques (Anderson, Draper, & Peterson, 2000; Abbott, 2008).
In order to achieve this goal, case-based reasoning (CBR) techniques (Aamodt & Plaza,
1994; Bartsch-Sprl, Lenz, & Hbner, 1999) were used which have been successfully applied
to imitation tasks in the past (Floyd & Esfandiari, 2010; Floyd, Esfandiari, & Lam, 2008).
In the second step, the PI-SRL algorithm attempts to safely explore the state-action space
in order to build a more accurate policy from previously-learned behavior. Thus, the set
of cases (i.e., state-action pairs) obtained in the previous phase is improved through the
safe exploration of the state-action space. To perform this exploration, small amounts of
Gaussian noise are randomly added to the greedy actions of the baseline policy approach.
The exploration strategy has been used successfully in previous works (Argall, Chernova,
Veloso, & Browning, 2009; Van Hasselt & Wiering, 2007).
The novelty of the present study is in the use of two new, main components: (i) a risk
function to determine the degree of risk of a particular state and (ii) a baseline behavior
516

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

capable of producing safe actions in supposedly risky states (i.e., states that can lead to
damage or injury). In addition, we present a new definition of risk based on what for the
agent is unknown and known space. As will be described in Section 5 in greater detail, this
new definition is completely different from traditional definitions of risk found in the literature (Geibel, 2001; Mihatsch & Neuneier, 2002; Geibel & Wysotzki, 2005). The paper also
reports the experimental results obtained from the application of the new approach in four
different domains: (i) automatic car parking (Lee & Lee, 2008), (ii) pole-balancing (Sutton
& Barto, 1998), (iii) 2009 RL Competition helicopter hovering (Ng, Kim, Jordan, & Sastry,
2003) and (iv) business management (Borrajo, Bueno, de Pablo, Santos, Fernandez, Garca,
& Sagredo, 2010). In each domain, we propose the learning of a near-optimal policy which,
in the learning phase, will minimize car crashes, pole disequilibrium, helicopter crashes and
company bankruptcies, respectively. It is important to note that the comparison of our
approach with an agent with an optimal exploration policy is not possible since, in the
proposed domains (each with a high-dimensional and continuous state and action space, as
well as complex stochastic dynamics), we do not know what the optimal exploration policy
is.
Regarding the organization of the remainder of the paper, Section 2 introduces key
definitions, while Section 3 describes in detail the learning approach proposed. In Section 4,
the evaluation performed in the four above mentioned domains is presented. Section 5
discusses related work and Section 6 summarizes the main conclusions of our study. In
these sections,
the term return is used to refer to the expected cumulative future discounted
P
reward R = t=0  t rt , while the term reward is used to refer to a single real value used to
evaluate the selection of an action in a particular state and it is denoted by r.

2. Definitions
To illustrate the concept of safety used in our approach, a navigation problem is presented
below in Figure 1. In the navigation problem presented in Figure 1, a control policy must
be learned to get from a particular start state to a goal state, given a set of demonstration
trajectories. In this environment, we assume the task to be difficult due to a stochastic
and complex dynamic of the environment (e.g., an extremely irregular surface in the case
of a robot navigation domain or wind effects in the case of the helicopter hover task). This
stochasticity makes it impossible to complete the task using exactly the same trajectory
every time. Additionally, the problem supposes that a set of demonstrations from a baseline
controller performing the task (the continuous black lines) are also given. This set of
demonstrations is composed of different trajectories covering a well-defined region of the
state space (the region within the rectangle).
Our approach is based on the addition of small amounts of Gaussian noise or perturbations to the baseline trajectories in order to find new and better ways of completing the
task. This noise will affect the baseline trajectories in different ways, depending on the
amount of noise added which, in turn, depends on the amount of risk to be taken. If no risk
is desired, the noise added to the baseline trajectories will be 0 and, consequently, no new
or improved behavior will be discovered (nevertheless, the robot will never fall off the cliff
and the helicopter will never crash). If, however, an intermediate level of risk is desired,
small amounts of noise will be added to the baseline trajectories and new trajectories (the
517

fiGarca & Fernandez

Figure 1: Exploration strategy based on the addition of small amounts of noise to baseline
policy behavior. Continuous lines represent the baseline behavior, while newly
explored behaviors are indicated by the dotted and dashed lines.
dotted blue lines) to complete the task are discovered. In some cases, the exploration of new
trajectories leads the robot to unknown regions of the state space (the dashed red lines).
The robot is assumed to be able to detect such situations with a risk function and use the
baseline behavior to return to safe, known states. If, instead, a very high risk is desired,
large amounts of noise will be added to the baseline trajectories, leading to the discovery
of new trajectories (but also to a higher probability that the robot gets damaged). The
iteration of this process leads the robot to progressively and safely explore the state and
action spaces in order to find new and improved ways to complete the task. The degree of
safety in the exploration, however, will depend on the risk taken.
2.1 Error and Non-Error States
In this paper, we follow as far we can the notation presented in Geibel et al. (2005) for
the definition of our concept of risk. In their study, Geibel et al. associate risk with error
states and non-error states, with the former understood as a state in which it is considered
undesirable or dangerous to enter.
Definition 1 Error and non-error states. Let S be a set of states and   S the set
of error states. A state s   is an undesirable terminal state where the control of the
agent ends when s is reached with damage or injury to the agent, the learning system or
any external entities. The set   S is considered a set of non-error terminal states with
   =  and where the control of the agent ends normally without damage or injury.
In terms of RL, if the agent enters an error state, the current episode ends with damage
to the learning system (or other systems); whereas if it enters a non-error state, the episode
ends normally and without damage. Thus, Geibel et al. define the risk of s with respect
to policy ,  (s), as the probability that the state sequence (si )i0 with s0 = s, generated
by the execution of policy , terminates in an error state s0  . By definition,  (s) = 1
if s  . If s  , then  (s) = 0 because    = . For states s 
/   , the risk
taken depends on the actions selected by the policy . With these definitions, we have the
518

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

theoretical framework with which to introduce our own definition of the risk associated with
known and unknown states.
2.2 Known and Unknown States in Continuous Action and State Spaces
We assume a continuous, n-dimensional state space S  <n where each state s = (s1 , s2 , . . . ,
sn )  S is a vector of real numbers and each dimension has an individual domain Dis  <.
Similarly, we assume a continuous and m-dimensional action space A  <m where each
action a = (a1 , a2 , . . . , am )  A is a vector of real numbers and each dimension has an
individual domain Dia  <. Additionally, the agent considered here is endowed with a
memory, or case-base B, of the size . Each memory element represents a state-action pair,
or case, the agent has experienced before.
Definition 2 (Case-base). A case-base is a set of cases B = {c1 . . . , c }. Every case
ci consists of a state-action pair (si , ai ) the agent has experienced in the past and with an
associated value V (si ). Thus, ci =< si , ai , V (si ) >, where the first element represents the
cases problem part and corresponds to the state si , the following element ai depicts the case
solution (i.e., the action expected when the agent is in the state si ) and the final element
V (si ) is the value function associated with the state si . Each state si is composed of n
continuous state variables and each action ai is composed of m continuous action variables.
When the agent receives a new state sq , it first retrieves the nearest neighbor of sq in
B according to a given similarity metric and then performs the associated action. In this
paper, we use Euclidean distance as our similarity metric (Equation 1).
v
uX
u n
d(sq , si ) = t (sq,j  si,j )2

(1)

j=0

The Euclidean distance metric is useful when the value function is expected to be continuous and smooth throughout the state space (Santamara, Sutton, & Ram, 1998). However,
since the value function is unknown a priori and the Euclidean distance metric is not particularly suitable for many problems, many researchers have begun to ask how the distance
metric itself can learn or adapt in order to achieve better results (Taylor, Kulis, & Sha,
2011). While the use of distance metric learning techniques would certainly be desirable in
order to induce a more powerful distance metric for a specific domain, such a consideration
lies outside the scope of the present study. In this paper, therefore, we have focused only on
domains in which Euclidean distance has been proven successful (i.e., it has been successfully applied to car parking (Cichosz, 1995), pole-balancing (Martin H & de Lope, 2009),
helicopter hovering control (Martin H & de Lope, 2009) and SIMBA (Borrajo et al., 2010).
Traditionally, case-based approaches use a density threshold  in order to determine when
a new case should be added to the memory. When the distance of the nearest neighbor to
sq is greater than , a new case is added. In this sense, the parameter  defines the size
of the classification region for each case in B (Figure 2). If a new case sq is within the
classification region of a case ci , it is considered to be a known state. Hence, the cases in

 and its associated value function V B
B describe a case-based policy of the agent B
.
519

fiGarca & Fernandez

Figure 2: Known and Unknown states.
Definition 3 (Known/Unknown states). Given a case-base B = {c1 . . . , c } composed
of cases ci = (si , ai , V (si )) and a density threshold , a state sq is considered known when
min1i d(sq , si )   and unknown in all other cases. Formally,   S is the set of known
states, while   S is the set of unknown states with    =  and    = S.
With Definition 3, states can be identified as known or unknown. When the agent
receives a new state s  , it performs the action ai of the case ci for which d(s, si ) =
min1j d(s, sj ). However, if the agent receives a state s   where, by definition, the
distance to any state in B is larger than , no case is retrieved. Consequently, the action
to be performed from that state is unknown to the agent.
Definition 4 (Case-Based risk function). Given a case base B = {c1 . . . , c } composed
of cases ci = (si , ai , V (si )), the risk for each state s is defined as Equation 2.

B

%


(s) =

0
1

if min1j d(s, sj ) < 
otherwise

(2)



Thus, %B (s) = 1 holds if s   (i.e., s is unknown), such that the state s is not
associated with any case and, hence, the action to be performed in the given situation is

unknown. If s  , then %B (s) = 0.
 derived from a caseDefinition 5 (Safe case-based policy). The case-based policy B
base B = {c1 . . . . , c } is safe when, from any initial known state s0 with respect to B, the
 always produces known non-error states with respect to B.
execution of B






B
s0 | %B (s0 ) = 0, then (si )i>0
%B (si ) = 0

(3)

Additionally, it is assumed here that the probability that the state sequence (si )i0 from
 , terminates in an error state
any known state s0  , generated by executing policy B

s   is B (s0 ) = 0 (i.e.,    = ).
520

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Definition 6 (Safe case-based coverage). The coverage of a single state s with respect
to a safe case-base B = {c1 . . . . , c } is defined as the state si for which min1i d(s, si )  .
Therefore, we assume that the safe case-based does not provide actions for the entire state
space, but rather only for known states s  .
Figure 3 graphically represents the relationship between known/unknown and error/non learnt, an
error states. The green area in the image denotes the safe case-based policy B
area of the state space corresponding to the initial known space. An agent following the
 will always be in the green area and all resulting episodes will end without
policy B
damages. Consequently, a subset of non-error states will also form part of the known space.
Formally, let  and  be subsets of non-error states belonging to the known and unknown
spaces, respectively, with    = . Then   . The yellow area in the Figure, by
contrast, represents the unknown space . In this space will be found all error states, as
well as a subset of remaining non-error states. Formally,    and   .
Understood in this way, the PI-SRL algorithm can be summed up as follows:
.
 As a first step, learn the known space (green area) from the safe case-based policy B

 As a second step, adjust the known space (green area) and unknown space (yellow
area) in order to explore new and improved behaviors while avoiding error states (red
area). During this process of adjusting the known space to the space used for safe and
better policies, the algorithm can forget ineffectual known states, as will be shown
in Section 4.

Figure 3: Known/unknown and error/non-error states given the Case Base B.

2.3 The Advantages of Using Prior Knowledge and Predetermined
Exploration Policies
In the present subsection, the advantages of using teacher knowledge in RL, namely (i) to
provide initial knowledge about the task to be learned and (ii) to support the exploration
process, are highlighted. Furthermore, we explain why we believe this knowledge to be
521

fiGarca & Fernandez

indispensable in RL for tackling highly complex and realistic problems with large, continuous
state and action spaces and in which a particular action may result in an undesirable
consequence.
2.3.1 Providing Initial Knowledge about the Task
Most RL algorithms begin learning without any previous knowledge about the task to be
learnt. In such cases, exploration strategies such as   greedy are used. The application
of this strategy results in the random exploration of the state and action spaces to gather
knowledge about the task. Only when enough information is discovered from the environment does the algorithms behavior improve. Such random exploration policies, however,
waste a significant amount of time exploring irrelevant regions of the state and action
spaces in which the optimal policy will never be encountered. This problem is compounded
in domains with extremely large and continuous state and action spaces in which random
exploration will never likely visit the regions of the spaces necessary to learn (near-)optimal
policies. Additionally, in many real RL tasks with real robots, a random exploration to
gather information from the environment cannot even be applied. With real robots, what
is considered to be sufficient information can be much more information than a real robot
can gather from the environment. Finally, as it is impossible to avoid undesirable situations
in high-risk environments without a certain amount of prior knowledge about the task, the
use of random exploration would require that an undesirable state be visited before it can
be labeled as undesirable. However, such visits to undesirable states may result in damage
or injury to the agent, the learning system or external entities. Consequently, visits to these
states should be avoided from the earliest steps of the learning process.
Mitigating the difficulties described above, finite sets of teacher-provided examples or
demonstrations can be used to incorporate prior knowledge into the learning algorithm.
This teacher knowledge can be used in two general ways, either (i) to bootstrap the learning algorithm (i.e., a sort of initialization procedure) or (ii) to derive a policy from such
examples. In the first case, the learning algorithm is provided with examples or demonstrations from which to bootstrap the value function approximation and lead the agent through
the more relevant regions of the space. The second way in which teacher knowledge can
be used refers to Learning from Demonstration (LfD) approaches in which a policy is derived from a finite set of demonstrations provided by a teacher. The principal drawback
to this approach, however, is that the performance of the derived policy is heavily limited
by teacher ability. While one way to circumvent the difficulty and improve performance is
by exploring beyond what is provided in the teacher demonstrations, this again raises the
question of how the agent should act when it encounters a state for which no demonstration
exists (an unknown state).
2.3.2 Supporting the Exploration Process
While furnishing the agent with initial knowledge helps mitigate the problems associated
with random exploration, this alone is not sufficient to prevent the undesirable situations
that arise in the subsequent explorations undertaken to improve learner ability. An additional mechanism is necessary to guide this subsequent exploration process in such a way
that the agent may be kept far away from catastrophic states. In this paper, a teacher,
522

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

rather than the policy derived from the current value function approximation is used for
the selection of actions in unknown states. One way to prevent the agent from encountering
unknown states during the exploration process would be by requesting from the beginning
a teacher demonstration for every state in the state space. However, such a strategy is not
possible due to (i) its computational infeasibility given the extremely large number of states
in the state space and (ii) the fact that the teacher should not be forced to give an action
for every state, given that many states will be ineffectual for learning the optimal policy.
Consequently, PI-SRL requests teacher action only when such action is actually required
(i.e., when the agent is in an unknown state).
As this paper supposes that such a teacher is available for the task to be learned, the
teacher is taken as the baseline behavior. Although some studies have examined the use of
robotic teachers, hand-written control policies and simulated planners, the great majority
to date have made use of human teachers. This paper uses suboptimal automatic controllers
as teachers, with T taken as the teachers policy.
Definition 7 (Baseline behavior). Policy T is considered the baseline behavior about
which three assumptions are made: (i) it is able to provide safe demonstrations of the
task to be learnt from which prior knowledge can be extracted; (ii) it is able to support the
subsequent exploration process, advising suboptimal actions in unknown states to reduce the
probability of entering into error states and return the system to a known situation; and
(iii) its performance is far from optimal.
While optimal baseline behaviors are certainly ideal to behave safely, non-optimal behaviors are often easy (or easier) to implement or generate than optimal ones. The PI-SRL
algorithm uses the baseline behavior T in two different ways. First, it uses the safe demonstrations of T to provide prior knowledge about the task. In this step, the algorithm builds
 with the
the initial known space of the agent derived from the safe case-based policy B

purpose of mimicking T through B . In the second step, PI-SRL uses T to support the
subsequent exploration process conducted to improve the abilities of the previously-learnt
 . As the exploration process continues, an action of  is requested only when required,
B
T
that is, when the agent is in an unknown state (Figure 4). In this step, T acts as a backup
policy in the case of an unknown state with the intention of guiding the learning away from
catastrophic errors or, at least, reducing their frequency. It is important to note that the
baseline behavior cannot demonstrate the correct action for every possible state. However,
while the baseline behavior might not be able to indicate the best action in all cases, the
action it supplies should, at the very least, be safer than that obtained through random
exploration.
2.4 The Risk Parameter
In order to maximize exploration safety, it seems advisable that movement through the
state space not be arbitrary, but rather that known space be expanded only gradually by
starting from a known state. Such an exploration is carried out through the perturbation
 . Perturbation of the trajectories
of the state-action trajectories generated by the policy B
is accomplished by the addition of Gaussian random noise to the actions in B in order
to obtain new ways of completing the task. Thus, the Gaussian exploration takes place
523

fiGarca & Fernandez

Figure 4: The exploration process in PI-SRL requests actions of the baseline behavior, T ,
when it is really required.
around the current approximation of the action ai for the current known state sc  , with
ci = (si , ai , V (si )) and d(sc , si ) = min1j d(s, sj ). The action performed is sampled from
a Gaussian distribution with the mean at the action output given by the instance selected
in B. When ai denotes the algorithm action output, the probability of selecting action a0i ,
(s, a0i ) is computed using Equation 4.
(s, a0i ) =

0
2
2
 1 e(ai ai ) /2
2 2

if  2 > 0.

(4)

The shape of the Gaussian distribution depends on parameter  (standard deviation).
In this study,  is used as a width parameter. While large  values imply a wide bellshaped distribution, increasing the probability of selecting actions a0i very different from
the current action ai , a small  value implies a narrow bell-shaped distribution, increasing
the probability of selecting actions a0i very similar to the current action ai . When  2 = 0,
we assume (s, ai ) = 1. Hence, the  value is directly related to the amount of perturbation
 . Higher  values imply
added to the state-action trajectories generated by the policy B
greater perturbations (more Gaussian noise) and a greater probability of visiting unknown
states.
Definition 8 (Risk Parameter). The parameter  is considered a risk parameter. Large
values of  increase the probability of visiting distant unknown states and, hence, increase
the probability of reaching error states.
These exploratory actions drive the agent to the edge of the known space and force it
to go slightly beyond, into the unknown space, in search of better, safer behaviors. After
a period of time, the execution of these exploratory actions increases the known space
 . The risk
and improves the abilities of the previously-learned safe case-based policy B
parameter , as well as , are design parameters that must be selected by the user. In
Section 3.3, guidelines for this selection are offered.
It is important to note that the approach proposed in this study is based on two logical
assumptions in RL derived from the following generalization principles (Kaelbling, Littman,
& Moore, 1996; Sutton & Barto, 1998):
524

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

(i) Nearby states have similar optimal actions. In continuous state spaces, it is
impossible for the agent to visit every state and store its value (or optimal action) in a
table. This is why generalization techniques are needed. In large, smooth state spaces,
similar states are expected to have similar values and similar optimal actions. Therefore,
it is possible to use experience gathered from the environment with a limited subset of the
state space and produce a reliable approximation over a much larger subset (Boyan, Moore,
& Sutton, 1995; Hu, Kostiadis, Hunter, & Kalyviotis, 2001; Fernandez & Borrajo, 2008).
One must also note that, in the proposed domains, an optimal action is also considered to
be a safe action in the sense that it never produces error states (i.e., no action is considered
optimal that leads the agent to a catastrophic situation).
(ii) Similar actions in similar states tend to produce similar effects. Considering a deterministic domain, the action at performed in state st always produces the same
state st+1 . In a stochastic domain, it is understood intuitively that the execution of the
action at in state st will produce similar effects (i.e., it produces states {s1t+1 , s2t+1 , s3t+1 , . . .}
where i, j i 6= j dist(sit+1 , sjt+1 )  0). Additionally, the execution of the action a0t  at
in a state s0t  st produces states {s0 1t+1 , s0 2t+1 , s0 3t+1 , . . .} where i, j dist(s0 it+1 , sjt+1 )  0.
As explained earlier, the present study uses Euclidean distance as a similarity metric, as
it has been proven successful in the proposed domains. As a result of this assumption,
approximation techniques can be used, such that actions that generate similar effects can
be grouped together as one action (Jiang, 2004). In continuous action spaces, the need
for generalization techniques is even greater (Kaelbling et al., 1996). In this paper, the
assumption also allows us to assume that low values of  increase the probability of visiting
known states and, hence, of exploring less and taking less risks, while greater values of 
increase the probability of reaching error states.

3. The PI-SRL Algorithm
The PI-SRL algorithm is composed of two main steps described in detail below.
3.1 First Step: Modeling Baseline Behaviors by CBR
The first step of PI-SRL is an approach for behavioral cloning, using CBR to allow a software
agent to behave in a similar manner to a teacher policy (baseline behavior) T (Floyd et al.,
2008). Whereas LfD approaches are named differently according to what is learned (Argall et al., 2009), to prevent terminological inconsistencies here, we consider behavioral
cloning (also known as imitation learning) to be an area of LfD whose goal is the reproduction/mimicking of the underlying teacher policy T (Peters, Tedrake, Roy, & Morimoto,
2010; Abbott, 2008).
When using CBR for behavioral cloning, a case can be built using the agents state
received from the environment, as well as the corresponding action command performed by
the teacher. In PI-SRL, the objective of the first step is to properly imitate the behavior of
T using the cases stored in a case-base. At this point, an important question arises; namely,
how a case-base B can be learnt using the sample trajectories provided by T such that, at
the end of the learning process, the resulting policy derived from B mimics the behavior
of T ? Baseline behavior is a function that maps states to actions T : S  A or, in other
525

fiGarca & Fernandez

words, a function that, given a state si  S, provides the corresponding action ai  A. In
this paper, we want to build a policy B derived from a case-base composed of cases (sj , aj )
such that, for a new state sq , the case with the minimum Euclidean distance dist(sq , sj ) is
retrieved and the corresponding action aj is returned. Intuitively, it can be assumed that
B can be built simply by storing all cases (si , ai ) gathered from one interaction between
T and the environment during a limited number of episodes K. At the end of K episodes,
one expects the resulting B to be able to properly mimic the behavior of T . However,
informal experimentation in the helicopter hovering domain shows this not to be the case
(Section 4.3). In helicopter hovering, after K = 100 episodes and the prohibitive number
of 600,000 cases stored, the policy derived from the case-base B is unable to correctly
imitate the baseline behavior T and, instead, continuously crashes the helicopter. Indeed,
in order for B to mimic T in large continuous and stochastic domains, the approach
requires a larger number of episodes and, consequently, a prohibitive number of cases. In
fact, to perfectly mimic T in these domains, an infinite number of cases would be required.
Figure 5 attempts to explain why we believe that this learning process does not work. In
it, the region of the space represented by simply storing cases derived from T in the form
c = (s, a) is shown. Each stored case (red circles) covers an area of the space and represents
the centroid of a Voronoi region.

Figure 5: Effects of storing all training cases.
If the previously-learned policy B is used when a new state sq is presented, the action aj is performed, corresponding to the case cj = (sj , aj ) where the Euclidean distance
dist(sq , sj ) is less than that with all other stored cases. However, if we use the policy T to
provide an action in the situation sq , the action ai is provided which is different than aj .
At this point, the policy B can be said to classify the state sq as the obtained class aj ,
while the policy T can be said to classify the state sq as the desired class ai (insofar as
T is the policy to be mimicked), with |ai  aj | > 0. Furthermore, |ai  aj | is understood
as the classification error. If the case-base stored all the possible pairs (si , ai ) that T
were able to generate in the domain, the actions aj and ai would always be identical, with
dist(sq , sj ) = 0 and |ai  aj | = 0. However, in a stochastic and large, continuous domain, it
is impossible to store all such cases. The sum of all such classification errors in an episode
526

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

leads to the visiting of unexplored regions of the case space (i.e., regions where the new
state sq received from the environment has a Euclidean distance dist(sq , sj ) >>  with
respect to the closest case cj = (sj , aj ) in B). When these unexplored regions are visited,
the difference between the obtained class derived from B and the desired class derived
from T is large (i.e., |ai  aj | >> 0) and the probability that error states might be visited
greatly increases.
It may be concluded, therefore, that simply storing the pairs c = (s, a) generated by T
is not sufficient to properly mimic its behavior. For this reason, the algorithm in Figure 6
below has been proposed.
CBR Approach for Behavioral Cloning
00
01
02
03

Given
Given
Given
1. Set

04
05
06
07

2. Repeat
Set k = 0
while k < maxEpisodeLength do
Compute the case < sc , ac , 0 > closest to the current state sk

08
09
10
11
12
13
14
15
16
17
18
19
20

the
the
the
the

baseline behavior T
density threshold 
maximum number of cases 
case-base B = 



if %B (sk ) = 0 then // By equation 2
Set ak = ac
else
Set ak using the baseline behavior T
Create a new case cnew = (sk , ak , 0)
B := B  cnew
Execute ak , and receive sk+1
Set k = k + 1
end while
if kBk >  then
Remove the   kBk least-frequently-used cases in B
until stop criterion becomes true

3. Return B performing the safe case-based policy B

Figure 6: CBR algorithm for behavioral cloning.


In the first step of the algorithm, the state-value function V B (si ) is initialized to 0 (see

line 07). The value V B (si ) for each case is computed in the second step of the algorithm
in Section 3.2. Additionally, this step uses the case-based risk function (Equation 2) to
determine whether a new state sk should be considered risky (line 08). If the new state is
not risky (i.e., it is a known state sk  ), a 1-nearest neighbor strategy is followed (line
09). Otherwise, the algorithm performs the action ak using the baseline behavior T and a
new case cnew = (sk , ak , 0) is built and added to the case-base B (line 13). Starting with an
empty case-base, the learning algorithm continuously increases its competence by storing
new experiences. However, there are a number of reasons why the inflow of new cases should
be limited. Large case-bases increase the time required to find the closest cases to a new
example. While this may be partially solved using techniques to reduce the retrieval time
(e.g., k-d trees that have been used in this work), they nevertheless do not reduce the storage
527

fiGarca & Fernandez

requirements. Several approaches to the removal of ineffectual cases during training exist,
including Ahas IBx algorithms (Aha, 1992) or any nearest prototype approach (Fernandez
& Isasi, 2008). When the number of cases stored in B exceeds a critical value kBk >  such
that the realization of a retrieval within a certain amount of time cannot be guaranteed,
the removal of some cases is inevitable. An efficient approach to such a problem is through
the removal of the least-frequently-used elements of B (line 18).
The result of this step is a constrained case-base B describing the safe case-based policy

B that mimics the baseline behavior T , though perhaps with some deviation (line 20).
Formally, let U (T ) be an estimate of the utility of the baseline behavior T computed by
 )  U ( ).
averaging the sum of rewards accumulated in each of NT trials. Then, U (B
T
3.2 Second Step: Improving the Learned Baseline Behavior
 learned in the previous
In this step of the PI-SRL algorithm, the safe case-based policy B
step is improved by the safe exploration of the state-action space. First, for each case ci 

B, the state-value function V B (si ) is computed following a Monte Carlo (MC) approach
(Figure 7).
MC Algorithm Adapted to CBR
00
01
02
03

Given the case-base B
1. Initialize, for each ci  B
V (s)  arbitrary
Returns(s)  empty list

04
05
06
07
08
09

2. while k < maxN umberEpisodes

Generate an episode using B
for each s appearing in the episode with < s, a, V (s) >  B
R  return following the first occurrence of s
Append R to Returns(s)
V(s)  average(Returns(s))

10
11

Set k = k + 1
3. Return B

Figure 7: Monte Carlo algorithm for the computation of state-value function for each case.
This algorithm is similar in spirit to a first-visit MC method for V  (Sutton & Barto,
1998), adapted in this paper to work with a policy given by a case-base. In the algorithm
shown in Figure 7, all returns for each state si  B are accumulated and averaged, following
 derived by the case base B (see line 09). It is important to note that in the
the policy B
algorithm the term return following the first occurrence of s refers to the expected return of
s (i.e., the expected cumulative future discounted reward starting from that state), whereas
Returns refers to a list composed of each return of s in different episodes. One of the
principal reasons for using the MC method is that it allows us to quickly and easily estimate

state values V B (si ) for each case ci  B. In addition, MC methods have been shown to
be successful in a wide variety of domains (Sutton & Barto, 1998). Once the state-value

function V B (si ) is computed for each case ci  B, small amounts of Gaussian noise are
 in order to obtain new and improved ways
randomly added to the actions of the policy B
528

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

to complete the task. The algorithm used to improve the baseline behavior learned in the
previous step is depicted in Figure 8. The algorithm is composed of four steps performed
in each episode.
- (a) Initialization step. The algorithm initializes the list used to store cases occurring
during an episode and sets the cumulative reward counter of the episode to 0.
- (b) Case Generation. The algorithm builds a case for each step of an episode.
For each new state sk , the closest case < s, a, V (s) > B is computed using the Euclidean
distance metric from Equation 1 (see line 09 in algorithm of Figure 8). In order to determine
the perceived degree of risk of the new state sk , the case-based risk function is used (line

10). If %B (sk ) = 0, then sk   (known state). In this case, the action ak performed is
computed using Equation 4 and a new case cnew =< s, ak , V (s) > is built to be added to
the list of cases having occurred in the episode (line 13). It is important to note that the
new case < s, ak , V (s) > is built replacing the action a corresponding to the closest case
in < s, a, V (s) > B, with the new action ak resulting from the application of random
Gaussian noise to a in the Equation 4. Thus, the algorithm only produces smooth changes

in the cases of B where ak  a. If, however, %B (sk ) = 1, the state sk   (i.e., unknown
state [line 14]). In unknown states, the action ak performed is suggested by the baseline
behavior T which defines safe behavior (line 15). A new case < sk , ak , 0 > is built and
added to the list of cases in the episode and actions will be performed using T until the
agent is not in a known state. Finally, the reward obtained in the episode is accumulated,
where r(sk , ak ) is the immediate reward obtained when action ak is performed in state sk
(line 18).
- (c) Computing the state-value function for the unknown states. In this step,
the state-value function of the states considered to be unknown in the previous step is
computed. In the previous step (line 17), the state-value function for these states is set at
0. The algorithm proceeds in a manner similar to the first-visit MC algorithm in Figure 7.
In this case, the return for each unknown state si is computed, but not averaged since only
one episode is considered (line 24 and 25). The return for each si is computed, taking into
account the first visit of the state si in the episode (each occurrence of a state in an episode
is called a visit to si ), although the state si could appear multiple times in the rest of the
episode.
- (d) Updating the cases in B using experience gathered. Updates in B are
made with the cases gathered from episodes with a cumulative reward similar to that of the
best episode found to that point using the threshold  (line 27). In this way, good sequences
are provided for the updates since it has been shown that such sequences of experiences can
cause an adaptive agent to converge to a stable and useful policy, whereas bad sequences may
cause an agent to converge to an unstable or bad policy (Wyatt, 1997). This also prevents
the degradation of the initial performance of B as computed in the first step of the algorithm
through the use of bad episodes, or episodes with errors, for updates. In this step, two types
of updates appear, namely, replacements and additions of new cases. Again, the algorithm
iterates for each case ci = (si , ai , V (si ))  listCasesEpisode (line 29). If si is a known state
(line 30), we compute the case < si , a, V (si ) > B corresponding to the state si (line 31).
One should note that the case ci = (si , ai , V (si ))  listCasesEpisode was built in line 13 of
the algorithm, replacing the action a corresponding to the case < si , a, V (si ) > B with the
new action ai and resulting from the application of random Gaussian noise to the action a
529

fiGarca & Fernandez

Policy Improvement Algorithm
00
01
02
03
04
05
06
07
08
09

Given the case-base B, and the maximum number of cases 
Given the baseline behavior T
Given the update threshold 
1. Set maxT otalRwEpisode = 0, the maximum cumulative reward reached in an episode
2. Repeat
(a) Initialization step:
set k = 0, listCasesEpisode  , totalRwEpisode = 0
(b) Case generation:
while k < maxEpisodeLength do
Compute the case < s, a, V (s) > B closest to the current state sk


10
11
12
13

if %B (sk ) = 0 then // known state
Chose an action ak using equation 4
Perform action ak
Create a new instance cnew := (s, ak , V (s))

14
15
16
17
18
19

else // unknown state
Chose an action ak using T
Perform action ak
Create a new instance cnew := (sk , ak , 0)
totalRwEpisode := totalRwEpisode + r(sk , ak )
listCasesEpisode := listCasesEpisode  cnew

20
21
22
23
24
25
26
27
28
29

Set k = k + 1
(c) Computing the state-value function for the unknown states:
for each instance ci in listCasesEpisode


if %B (si ) = 1 then // unknown state
P
return(si ) := kj=n  jn r(sj , aj ) // n is the first ocurrence of si in the episode
V (si ) := return(si )
(d) Updating the cases in B using the experience gathered :
if totalRwEpisode > (maxT otalRwEpisode  ) then
maxT otalRwEpisode := max (maxT otalRwEpisode, totalRwEpisode)
for each case ci =< si , ai , V (si ) > in listCasesEpisode


30
31
32

if %B (si ) = 0 then // known state
Compute the case < si , a, V (si ) > B corresponding to the state si
Compute  = r(si , ai ) + V (si+1 )  V (si )

33
34
35
36
37

If  > 0 then
Replace the case < si , a, V (si ) > B with the case < si , ai , V (si ) > listCasesEpisode
V (si ) = V (si ) + 
else // unknown state
B := B  ci

38
39
40
41

if kBk >  then
Remove the   kBk least-frequently-used cases in B
until stop criterion becomes true
3. Return B

Figure 8: Description of step two of PI-SRL algorithm.

by the Equation 4. Then, the temporal distance (TD) error  is computed (line 32). If  > 0,
performing the action ai results in a positive change for the value of a state. The action, in
530

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

turn, could potentially lead to a higher return and, thus, to a better policy. Van Hasselt and
Wiering (2007) also update the value function using only the actions that potentially lead
to a higher return. If the TD error  is positive, ai is considered to be a good selection and is
reinforced. In the algorithm, this reinforcement is carried out by updating the output of the
case < si , a, V (si ) > B at ai (line 34). Therefore, an update to the case-base only occurs
when the TD error is positive. This is similar to a linear reward-inaction update for learning
automata (Narendra & Thathachar, 1974, 1989) in which the sign of the TD error is used
as a measure of success. PI-SRL only updates the case-base when actual improvements
have been observed, thus avoiding slow learning when there are plateaus in the value space
and TD errors are small. It has been shown empirically that this procedure can result in
better policies than when step size depends on the size of the TD error (Van Hasselt &
Wiering, 2007). It is important to note that these replacements produce smooth changes in
the case-base B since an action a is replaced only if ai results in a higher V (si ) and ai  a.
This form of updating can be understood as a risk-seeking approach, overweighting only
transitions to successor states that promise an above-average return (Mihatsch & Neuneier,
2002). Additionally, it prevents the degradation of B, ensuring that replacements are made
only when an action can potentially lead to a higher V (si ).
If, instead, si is not a known state, the case ci is added to B (line 37). Finally, the
algorithm removes cases from B if necessary (line 39). Complex scoring metrics to calculate
which cases are to be removed for a given moment have been proposed by several authors.
Forbes and Andres (2002) suggest the removal of cases that contribute least to the overall
approximation, while Driessens and Ramon (2003) pursue a more error-oriented view and
propose the deletion of cases that contribute most to the prediction error of other examples.
The principal drawback of these more sophisticated measures is their complexity. The
determination of the case(s) to be removed involves the computation of a score value for
each ci  B, which in turn requires at least one retrieval and regression, respectively, for
each cj  B (j 6= i). Such entire repeated sweeps through the case-base entail an enormous
computational load. Gabel and Riedmiller (2005) compute a different score metric for
each ci  B, requiring the computation of the set of the k-nearest neighbors around ci .
Such approaches are not well-suited to systems learning with adjusted time requirements
and with a high-dimensional state space, requiring the use of larger case-bases than those
proposed here. Rather, in this paper, we propose the removal of the least-frequently-used
cases. The idea seems intuitive insofar as the least-frequently-used cases usually contain
worse estimates of a corresponding states value; although the strategy might lead to a
function approximator that forgets some of the valuable experience made in the past
(e.g., corner cases). Despite this, PI-SRL performs successfully in all domains proposed
using the strategy, as demonstrated in Section 4. Thus, the ability to forget ineffectual
known states described in Section 2 is a result of the algorithm removing kBk   cases
from the least-frequently-used cases of B.
3.3 Parameter Setting Design
One of the main difficulties of applying the PI-SRL algorithm to a given problem is to
decide on an appropriate set of parameter values for the threshold , the risk parameter ,
the update threshold  and the maximum number of cases . An incorrect value for the
531

fiGarca & Fernandez

parameter  can lead to mislabeling a state as known when it is really unknown, potentially
leading to damage or injury in the agent. In the case of the risk parameter , high values
can continuously result in damage or injury; while low values are safe, but do not allow for
exploration of the state-action space sufficient for reaching a near-optimal policy. Unlike
 and , the parameter  is not related to risk, but instead is directly related to the
performance of the algorithm. Parameter  is used to determine how good an episode
must be with respect to the best episode obtained, since only the best episodes are used to
update the case-base B. If the  value is too large, bad episodes may be used to update B
(influencing the convergence and performance of the algorithm). If, instead,  is too low,
the number of updates in B may be insufficient for improving the baseline behavior. Finally,
a very high  value allows for large case-bases, increasing the computational effort during
retrieval and degrading the efficiency of the system. By contrast, a very low  value might
excessively restrict the size of the case-base and thus negatively affect the final performance
of the algorithm. In this subsection, a solid perspective is given on the automatic definition
of these parameters. The parameter setting proposed here are taken as a suitable set of
heuristics tested successfully in a wide variety of domains (Section 4).
 Parameter : The parameter is domain-dependent and related to the average size
of the actions. In this paper, the value for this parameter has been established by
computing the mean distance between states during an execution of the baseline
behavior T . Expressed in another way, the execution of the policy T provides a
state-action sequence of the form s1  a1  s2  a2  . . .  sn . Thus, the value of
 is computed using Equation 5.

=

dist(s1 , s2 ) + . . . + dist(sn1 , sn )
n1

(5)

 Parameter : Several authors agree that it is impossible to completely avoid all
accidents (Moldovan & Abbeel, 2012; Geibel & Wysotzki, 2005). It is important to
note that PI-SRL is completely safe only if the first step of the algorithm is executed.
However, by proceeding in this way, the performance of the algorithm is heavily
limited by the abilities of the baseline behavior. The running of the subsequent
exploratory process is inevitable if learner performance is to be improved beyond that
of the baseline behavior. Since the agent operates in a state of incomplete knowledge
of the domain and its dynamic, it is inevitable during the exploratory process that
unknown regions of the state space will be visited where the agent may reach an error
state. However, it is possible to adjust the risk parameter  to determine the level
of risk assumed during this exploratory process. In this paper, we start with low 
values (low risk) which we gradually increase. Specifically, we propose beginning with
 = 9  107 and increasing this value iteratively until either an accurate policy is
obtained or the amount of damage or injury is high.
 Parameter : The value of this parameter is set relative to the best episode obtained.
In this paper, the  value is set to 5% of the cumulative reward of the best episode
obtained.
532

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 9: Trajectories generated by the baseline policy T in a deterministic, slightly
stochastic and highly stochastic domain.
 Parameter : Previously, we estimated the maximum number of cases  to be stored
in the case-base as being the estimated maximum number of cases required to properly mimic the baseline behavior T . What follows is a description of how this value is
computed. Figure 9 presents the trajectories (sequences of states) followed by the baseline policy T in three different domains: deterministic, slightly stochastic and highly
stochastic. For each domain, different sequences of the states produced by T are
represented {s00 , s01 , s02 , . . . , s0n }, {s00 , s11 , s12 , . . . , s1n },. . ., {s00 , sm1 , sm2 , . . . , smn },
where sji is the i-th state, s00 the initial state and sjn the final state of the resulting
trajectory in episode j. In the deterministic domain, the m different executions of T
always result in the same trajectory. In this case, we set the maximum number of
cases to  = n with all the cases computed in the episode being stored.
In the slightly stochastic domain, the trajectories produced in m different episodes
are different, but only slightly so. Here, we suppose the case-base at the beginning to
be empty. Additionally, we assume that all states {s00 , s01 , s02 , . . . , s0n } corresponding to the first trajectory produced in the domain will be stored in the case-base.
Furthermore, for each domain we execute m different episodes, obtaining m different
trajectories. Following the execution of the m episodes, we compute the maximum distance between the i-th state of the first trajectory (previously added to the case-base)
and the i-th state produced in the trajectory j such that max1jm d(s0i , sji ). In the
slightly stochastic domain, this maximum distance does not exceed the threshold  in
any case such that max1jm d(s0i , sji ) < . At this point, we assume the i-th state in
trajectory j to have at least one neighbor with a distance less than  (corresponding
to the state s0i ). Thus, the i-th state in j is not added to the case-base.
By contrast, in a highly stochastic domain, this maximum distance greatly exceeds the
threshold  in all the cases such that max1jm d(s0i , sji ) >> . In this domain, we
estimate the total number of cases that will be added to the case-base in the following
533

fiGarca & Fernandez

way. For each i-th state in the sequence of the
j first trajectory,k we estimate the number
max1jm d(s0i ,sji )
of cases to be added to the case-base as
or, in other words, we

compute the number of intervals in the range [0, max1jm d(s0i , sji )] with a width of
 (the threshold used to decide whether a new case is to be added or not to the casebase). Consequently, the estimated number of cases addedjto the case-base, taking
into
k
Pn
max1jm d(s0i ,sji )
account all states in the sequence, is computed as i=0
. Finally,

the estimated maximum number of cases is computed as shown in Equation 6.

 =n+


n 
X
max1jm d(s0i , sji )


i=0

!
(6)

It is important to remember that in a deterministic domain, the summation in equation 6 is equal to 0 and that, therefore,  = n. The increase of the value of this element
is related to the increase of stochasticity of the environment, insofar as the greater
stochasticity of the environment increases the number of cases required. Finally, if
the number of cases is very large or nearly infinite, the threshold  can be increased
to make more restrictive the addition of new cases to the case-base. However, this
increase may also adversely affect the final performance of the algorithm.

4. Experimental Results
This section presents the experimental results collected from the use of PI-SRL for policy
learning in four different domains presented in order of increasing complexity (i.e., increasing number of variables describing states and actions): the car parking problem (Lee &
Lee, 2008), pole-balancing (Sutton & Barto, 1998), helicopter hovering (Ng et al., 2003)
and the business simulator SIMBA (Borrajo et al., 2010). For each of these domains,
we have proposed the learning of a near-optimal policy which minimizes car accidents,
pole disequilibrium, helicopter crashes and company bankruptcies, respectively, during the
learning phase. All four of the domains are stochastic in our experimentation. While both
helicopter hovering and the business simulator SIMBA are, in themselves, stochastic and,
additionally, generalized domains, we have made the car parking and pole-balancing domains stochastic with the intentional addition of random Gaussian noise to the actions and
reward function. The results of PI-SRL in the four domains are compared to those yielded
by two additional techniques, namely, the evolutionary RL approach selected winner of the
helicopter domain in the 2009 RL Competition (Martn H. & Lope, 2009) and Geibel and
Wysotzkis risk-sensitive RL approach (Geibel & Wysotzki, 2005). In the evolutionary approach, several neural networks cloning error-free teacher policies are added to the initial
population (guaranteeing rapid convergence of the algorithm to a near-optimal policy and,
indirectly, minimizing agent damage or injury). Indeed, as the winner of the helicopter
domain is the agent with the highest cumulative reward, the winner must also indirectly
minimize helicopter crashes insofar as these incur large catastrophic negative rewards. On
the other hand, the risk-sensitive approach defines risk as the probability  (s) of reaching
a terminal error state (e.g., a helicopter crash ending agent control), starting at some initial
534

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

state s. In this case, a new value function with the weighted sum of the risk probability,
 , and value function, V  , is used (Equation 7).
V (s) = V  (s)   (s)

(7)

The parameter   0 determines the influence of the V  (s)-values compared to the  (s)values. For  = 0, V corresponds to the computation of minimum risk policies. For large 
values, the original value function multiplied by  dominates the weighted criterion. While
Geibel and Wysotzki (2005) consider only finite (discretized) action sets in their study,
their algorithm has been adapted here for continuous action sets. We use CBR for value
and risk function approximation and a Gaussian exploration around the current action. In
the experiments, for each domain, three different  values are used, modifying the influence
of the V -values compared to the -values. In all cases, the goal is to improve the control
policy while, at the same time, minimizing the number of episodes with agent damage or
injury. In each domain, we establish different risk levels by modifying risk parameter 
values according to the procedure described in subsection 3.3. It is important to note that
one baseline behavior used to initialize the evolutionary RL approach is exactly the same as
that used subsequently in the first and second step of PI-SRL. Furthermore, the case-base
in the risk-sensitive approach does not begin from scratch since it is initialized with the safe
 . This makes the comparison of performances as fair as possible, but
case-based policy B
taking into account that the different techniques make its own use of the baseline behaviors.
4.1 Car Parking Problem
The car parking problem is represented in Figure 10 and originates from the RL literature (Cichosz, 1996). A car, represented as the rectangle in Figure 10, is initially located
inside a bounded area, represented by the dark solid lines, referred to as the driving area.
The goal for the learning agent is to navigate the car from its initial position into the garage,
such that the car is entirely inside, in a minimum number of steps. The car cannot move
outside of the driving area. Figure 10 (b) shows the two possible paths the car can take from
the starting point to the garage with an obstacle in between in order to correctly perform
the task. We consider the optimal policy for the domain to be that which reaches the goal
state in the shortest time and which, at the same time, is free of failures.
The state space of the domain is described by three continuous variables, namely, the
coordinates of the center of the car xt and yt and the angle t between the cars axis and
the X of the coordinate system. While the car can be modeled essentially with two control
inputs, speed v and steering angle , let us suppose here that the car is controlled only by the
steering angle (i.e., it moves at a constant speed). Thus, the action space is described by one
continuous variable at  [1, 1] corresponding to the turn radius, as used in the equations
below. The agent receives a positive reward value of r = (1  (dist(Pt , Pg )))  10, where
Pt = (xt , yt ) is the center of the car, Pg = (xg , yg ) is the center of the garage (i.e., the goal
position) and  is a normalizing function scaling the Euclidean distance dist(Pt , Pg ) between
Pt and Pg to a range [0, 1] when the car is inside the garage (i.e., the reward value is greater
if the car is parked correctly in the center of the garage). The agent receives a reward of
-1 whenever it hits the wall or obstacle. All other steps receive a reward of -0.1. Thus, the
difficulty of the problem lies not only in the reinforcement delay, but also in the fact that
535

fiGarca & Fernandez

Figure 10: Car Parking Problem: (a) Model of the car parking problem. (b) Examples of
trajectories generated by the agent to park the car in the garage.
punishments are much more frequent than positive rewards (i.e., it is much easier to hit
a wall than park the car correctly). The motion of the car is described by the following
equations (Lee & Lee, 2008)
t+1 = t + v /(l/2) tan(  at ),

(8)

xt+1 = xt + v cos(t+1 ),

(9)

yt+1 = yt + v sin(t+1 ),

(10)

where v is the linear velocity of the car (assumed to be a constant value),  is the
maximum steering angle (i.e., the car can change its position by a maximum angle of 
in both directions) and  is the simulation time step. Gaussian noise was added to the
actions and rewards with a standard deviation of 0.1, since noisy interactions are inevitable
in most real-world applications. Adding this noise to the actuators and the environment,
we transform the deterministic domain into a stochastic domain. It is important to note
that the noise added to transform the domain into a stochastic domain is independent of
the Gaussian noise with standard deviation  (risk parameter) used to explore the state and
action space in the second step of the PI-SRL algorithm. In this case, the Gaussian noise
with standard deviation  used for exploration will be added to the noise previously added
to the actuators. In this paper, l = 4 (m), v = 1.0 (m/s),  = 0.78 (rad) and  = 0.5 (s)
(the driving area and obstacle dimensions are detailed in Figure 10 [a]). The initial position
of the car is fixed at xs = 4.0, ys = 4.0 and s = 0.26 (rad), while the goal position is
xg = 22.5 and yg = 13.5. For this domain, we have designed a baseline behavior T with
an average cumulative reward per trial of 4.75.
In order to perform the PI-SRL algorithm, the modeling baseline behavior step is exe learned from demonstrations
cuted. The result of this step is the safe case-based policy B
provided by the baseline behavior T (see subsection 3.1).  and  were computed following
the procedure described in subsection 3.3 with resulting values of 0.01 and 207, respectively.
536

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 11: Car Parking Task Modeling Baseline Behavior Step: (a) Number of steps per
trial executed by Case Base B and the baseline behavior T . (b) Cumulative
reward per trial by the baseline behavior T , the learned Safe Case Based Policy
 and an IBL approach.
B
Figure 11 (a) graphically represents the execution of the modeling baseline behavior step. In
it, two different learning processes are presented and, for each one, the number of steps per
trial executed by the baseline behavior T (continuous red lines) and the cases in B (dashed
green lines) is shown. At the beginning of the learning process with an empty case-base B,
all steps are performed using the baseline behavior T . As the learning process continues,
 is learned. At around the trials
new cases are added to B and the safe case-based policy B
40-50, practically all steps are performed using the cases in B and T is rarely used, that
means that a safe case-based policy has been learned. In the two learning processes shown
in Figure 11 (a), the modeling baseline behavior step is performed without collisions with
the wall or the obstacle. In other words, the baseline behavior T is cloned safely without
errors. Figure 11 (b) shows the cumulative reward for three different execution processes:
the first (continuous red lines) corresponding to the performance of the baseline behavior
T , the second (dashed green lines) corresponding to the previously-learned safe case-based
 (derived from B ) and the third (dashed blue lines) corresponding to an instancepolicy B
based learning (IBL) approach consisting of storing cases in memory. In the IBL approach,
new items are classified by examining the cases stored in memory and determining the most
similar case(s) given a particular similarity metric (Euclidean distance is used in this paper). The classification of that nearest neighbor (or those nearest neighbors) is taken as the
classification of the new item using a 1-nearest neighbor strategy (Aha & Kibler, 1991). For
each approach, two different executions are carried out. In the IBL approach, the training
process is performed saving all training cases produced by the baseline behavior T during
50 trials (so we consider this approach an IB1 algorithm in the sense that it saves every
case during the training phase, see Aha & Kibler, 1991). Figure 11 (b) shows that the safe
case-based policy B almost perfectly mimics the behavior of the baseline behavior T . In
the domain, the performance of the IB1 approach is also similar.
Figure 12 (a) shows the results for different risk configurations obtained by the improving
the learned baseline behavior step. For each risk configuration, two different learning pro537

fiGarca & Fernandez

Figure 12: Improving the learned baseline behavior step in car parking problem: (a) Cumulative reward per episode for different risk configurations () obtained by
PI-SRL. (b) Cumulative reward per episode by the evolutionary RL and risksensitive RL approaches. In all cases, any episode ending in failure is marked.
cesses are performed. All trials ending in failure (car hits the wall or obstacle) are marked
(blue triangles). The learning processes in Figure 12 (a) demonstrate that the number of
failures increases with an increase in the parameter . For a low level of risk ( = 9  104 ),
although no failures are produced, the performance is nevertheless weak (around the baseline behavior T ) and constant throughout the whole of the learning process. Additional
experiments have demonstrated that increasing the  value above  = 9102 increases the
number of failures without improving performance. Figure 12 (b) shows the results for the
evolutionary and risk-sensitive RL approaches for different  values. Regarding the former,
the number of failures is higher than that obtained by the PI-SRL approach, while its final
performance is similar. In the case of the latter, performance is higher when  = 1.0 (value
maximization), yet the agent consistently crashes the car into the wall.
Figure 13 shows the mean number of failures (i.e., car collisions) and cumulative reward
for each approach over 500 trials with the red circles corresponding to the PI-SRL algorithm,
the black triangles to the risk-sensitive approach and the blue square to the evolutionary
RL approach. Additionally, Figure 13 shows two asymptotes. The horizontal asymptote
is established according to the cumulative reward obtained by the highest  value. The
horizontal asymptote indicates that higher  values increase the number of failures without
improving the cumulative reward (which may, in fact, get worse). The vertical asymptote
at F ailures = 0 indicates that reducing the risk parameter  does not reduce the number
of failures. Figure 13 also shows the performance for two additional risk levels, a very
high level of risk ( = 9  101 ) and very low level of risk ( = 0), with respect to
Figure 12. When using a very low level of risk  = 0, no additional random Gaussian
noise is added to the actions and the algorithm is free of failures, although performance
 learned in the first step
does not improve with respect to the safe case-based policy B
of the algorithm. PI-SRL with a medium level of risk ( = 9  104 ) also is free of
failures, yet performance is also slightly improved. The PI-SRL algorithm with high level
of risk ( = 9  102 ) obtains the highest cumulative reward, 3053.37, with a mean of
538

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 13: Mean number of failures (car collisions) and cumulative reward over 500 trials
for each approach in car parking task. The means have been computed from 10
different executions.

78.8 failures. However, when using a very high level of risk ( = 9  101 ), the number of
failures greatly increases and, consequently, the cumulative reward decreases. As shown in
Figure 12, PI-SRL with high risk ( = 9  102 ) and the evolutionary RL approach obtain
a similar performance, while PI-SRL demonstrates a faster convergence (thus, in Figure 13,
the cumulative reward obtained by PI-SRL is higher). The Pareto comparison criterion can
be used to compare the solutions in Figure 13. Using this principle, one solution y  strictly
dominates (or is preferred to) a solution y if each parameter of y  is not strictly worse
than the corresponding parameter of y and at least one parameter is strictly better. This
is written as y   y, indicating that y  strictly dominates y. In accordance with the Pareto
principle, we can assume the points in Figure 13 corresponding to the PI-SRL solutions,
save PI-SRL with very high level of risk, to be on the Pareto frontier, since these points are
not strictly dominated by any other solution (i.e., no other solution has, at the same time, a
higher cumulative reward and a lower number of failures than PI-SRL). In this domain, the
solution of the PI-SRL with a medium level of risk strictly dominates (or is preferred to)
the risk-sensitive solutions (PI-SRL  = 9  103  risk-sensitive) and the solution PI-SRL
with a high level of risk strictly dominates the solution of the evolutionary RL solution
(PI-SRL  = 9  102  evolutionary RL).
Nevertheless, it is important to note that any ultimate decision about which approach
in Figure 13 is best depends on the criteria of the researcher. If, for instance, the minimization of the number of failures is deemed the most important optimization criterion
(independently of the improvement obtained with respect to the baseline behavior T ), the
best approach will be PI-SRL with a low level of risk ( = 9  104 ). Similarly, if the
maximization of the cumulative reward is instead judged to be the most important optimization criterion (independently of the number of failures generated), the best approach
will be PI-SRL with a high level of risk ( = 9  102 ).
Figure 14 shows the evolution of the cases in the case-base B (known space) in different
trials for a high-risk learning process. Each graph presents the set of known states  (green
539

fiGarca & Fernandez

Figure 14: Car parking problem: Evolution of the known space for different trials T = 0
(a), T = 50 (b), T = 100 (c) and T = 200 (d) in a high-risk learning process
( = 9  102 ). Each graph corresponds to the situation of the state space in
accordance with the case-base B in trial T .
area), error states  (red area), unknown states  (yellow area) and non-error states 
(orange circles). PI-SRL adapts the known space in order to find safer and better policies
to complete the task. Figure 14 (a) shows the initial situation of B (corresponding to the
 ). It is robust in the sense that it never results in
previously-learned safe case-based policy B
any collisions, but suboptimal (it selects the longest parking path driving around the upper
side of the obstacle). As the learning process progresses (Figure 14 (b)), PI-SRL finds a
shorter path to park the car in the garage along the upper side of the obstacle (increasing the
performance), but which comes closer to the obstacle than before (increasing the probability
of collisions). In Figure 14 (c), PI-SRL finds a new and even shorter path, this time along
the lower side of the obstacle. However, there are still cases in the case-base B corresponding
to the older path along the upper side of the obstacle (so Figure 14 (c) indicates two paths
to park the car). Finally, in Figure 14 (d), the cases corresponding to the suboptimal path
along the upper side of the obstacle have been removed from B and replaced by new cases
corresponding to the safe and improved path along the lower side of the obstacle. In other
words, PI-SRL adapts the known space through the exploration of the unknown space in
order to find new and improved behaviors. During this process of adjusting the known space
540

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

to safe and better policies, the algorithm forgets the previously-learned, yet ineffective
known states.
In the following experiment, it becomes apparent that if the domain is noisy enough, even
when taking no risk at all (i.e., no further noise added to the actuator for exploration), the
agent could nevertheless perform poorly and constantly produce collisions. The experiment
also serves to explain why domain noise can never be sufficient for the efficient exploration
of the space without action selection noise. In the experiment, we have intentionally added
more noise to the actuators and have performed second step of PI-SRL again, however this
time taking no risk (i.e.,  = 0). In this test, we have added random Gaussian noise with
a standard deviation of 0.3, rather than the standard deviation of 0.1 used previously, to
the actuators. Figure 15 shows two executions of the second step (improving the learned
baseline policy) of the PI-SRL algorithm with the x-axis indicating the number of trials,
the y-axis the cumulative reward per episode and failures (i.e., collisions) marked as blue
triangles. In the experiments in Figure 12 (b), the case-based policy B with low level
of risk ( = 9  104 ) never produces failures. In contrast, in the experiments shown in
Figure 15, the same case-based policy B continually collides with the wall although the
risk parameter is set to 0 ( = 0). Furthermore, an increase in the performance can also be
detected.

Figure 15: Improving the learned baseline behavior step of car parking task: Two learning processes for risk configuration  = 0 and an increase in the noise in the
actuators.

The increase of noise in the actuators in the second step of the algorithm with respect
to the first step (the case-based policy B is learned in the first step using Gaussian random
noise in the actuator with a standard deviation of 0.1, while the second step is performed
using Gaussian random noise in the actuator with a standard deviation of 0.3) takes the
agent beyond the known space of the case-base B learnt in the first step of PI-SRL and
allows it to find new trajectories for parking the car in the garage. In this new situation, the
exploration process is guided as follows. If a known state is reached, the agent performs the
action a retrieved from B without the addition of Gaussian noise, since the risk parameter
 = 0 (see line 11 in Figure 8 algorithm). If an unknown state is reached, the agent performs
541

fiGarca & Fernandez

the action a advised by the baseline behavior T (see line 15). Using this exploration
process, if a new and better trajectory is found for parking the car in the garage, the
resulting cases in the episode corresponding to unknown states are added to the case-base
(see line 37), slightly improving the performance in Figure 15. It is important to note that
the replacements of cases (see line 34) does not change the actions in B, since these are
replaced by the same action previously retrieved from B plus a certain amount of Gaussian
noise with standard deviation  (see line 11). Nevertheless, given that the risk parameter 
has been set to 0, the actions retrieved from the case-base are not replaced. This exploration
process, however, with  = 0 (i.e., taking no risk) does not lead to optimal behavior since:
 The actions performed in unknown situations and added to the case-base B are performed using the baseline behavior T which is supposed perform suboptimal actions
(see definition of baseline behavior).
 The actions in the cases of B are not replaced with improved actions. The Gaussian
noise with standard deviation  is used to explore different and better actions than
those provided by B and T ; however, in this case, the risk parameter is set to  = 0
and new and better actions are not discovered.
Additional experiments demonstrate that PI-SRL behaves much worse when a higher
value of noise is used in the actuators (with collisions in all episodes). We assume that taking
no risk (i.e.,  = 0) implies always performing the same actions while not discovering any
newer or better actions than those provided by the learned case-base B and the baseline
behavior T . In PI-SRL, the replacements in the case-base are executed towards the more
promising action which, in our case, is that which guarantees a higher return. This is
why exploration is necessary in order to obtain (near-)optimal behavior, since without
exploration, new and better actions are not discovered and PI-SRL performance is limited
by that of the case-based policy learned in the first step B and the baseline behavior T
which, one must remember, is intended to perform suboptimal policies.
4.2 Pole-Balancing
As the name suggests, the objective in the pole-balancing problem is to balance a pole
vertically on top of a moving cart (Sutton & Barto, 1998). The state description consists
of a four-dimensional vector containing the angle , the radial speed 0 , the cart position
x and the speed x0 . The action consists of a real-valued force that is used to push the cart.
In this study, the reward is computed to encourage actions that keep the pole as upright as
possible on the cart and the cart as centered as possible on the track. Thus, the reward in
step t is computed as rt = 1  ((t ) + (xt ))/2, where  and  are normalizing functions
scaling the angle t and the position xt to a range [0, 1]. An episode is composed of 10,000
steps, although it may nevertheless end prematurely if the pole becomes unbalanced (i.e.,
if it has an inclination of more than twelve degrees in either direction) or the cart falls off
the track (i.e., if it is more than 2.4m from the center of the track), both of which being
considered failures. As in the car parking problem, Gaussian noise was added to the actions
and rewards, this time with a standard deviation of 104 . The pole-balancing domain
becomes stochastic through the addition of this noise to the actuators and reward function.
542

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 16: Modeling baseline behavior step in pole-balancing task: (a) Number of steps per
trial executed by case-base B and baseline behavior T . (b) Cumulative reward
 and an IBL approach.
per trial for T , the learned safe case-based policy B
The hand-made baseline behavior T demonstrates the execution of a safe, yet suboptimal
policy, with an average cumulative reward per episode/trial of 9292.
 is learnt
In the modeling baseline behavior step of PI-SRL, the safe case-based policy B
from demonstrations provided by the baseline behavior T .  and  were computed following
the procedure described in subsection 3.3, with values of 0.02 and 12572, respectively.
Figure 16 (a) shows two different learning processes for the modeling baseline behavior step.
For each learning process, Figure 16 (a) shows the number of steps per trial executed by
baseline behavior T (continuous red lines) and by the case-base B (dashed green lines). At
the beginning of the learning process, the case-base B is empty and all steps are performed
using the baseline behavior T . As the learning process progresses, however, B is filled and
 is learnt. At the end of the learning process (after around
the safe case-based policy B
45-50 trials), almost all steps are performed using the cases in B and T is rarely used. It
is important to note that the modeling baseline behavior step has been performed without
failures (i.e., pole disequilibrium or cart off the track) in each case. As with the previous
task, Figure 16 (b) represents three independent execution processes using the previously (derived from B and indicated with dashed green lines),
learned safe case-based policy B
the baseline behavior T (indicated with continuous red lines) and an approach based on
IBL (indicated with dashed blue lines) (Aha & Kibler, 1991). The average cumulative
 is 9230 (Figure 16 [b]). While   almost perfectly clones  , the
reward per episode in B
T
B
IB1 approach which, in most cases, results in pole disequilibrium or the cart falling off the
track averages a cumulative reward per episode of 8055.
Figure 17 (a) shows the results of PI-SRL for different risk configurations. For each
configuration, the learning curves are shown for two different learning processes performed.
Additionally, any episode ending in failure is marked (blue triangles). While an increase in
risk increases the probability of failure, the policy obtained is nevertheless better in terms of
the cumulative reward. Nevertheless, much greater risk values ( = 9  105 ) produce more
failures without an accompanying increase in the cumulative reward. Figure 17 (b) shows
the results for the evolutionary and risk-sensitive RL approaches, the former of which being
543

fiGarca & Fernandez

Figure 17: Improving the learned baseline behavior step of pole-balancing task: (a) Cumulative reward per episode for different risk configurations () obtained by PISRL. (b) Cumulative reward per episode obtained by the evolutionary and risksensitive RL approaches. In all cases, any episode ending in failure is marked.

clearly the algorithm with the greatest number of failures. In the risk-sensitive approach,
for  = 2.0 (value maximization), the agent selects actions that result in a higher value,
but also in a higher risk. On the contrary, for  = 0 (risk minimization), when the agent
learns the risk function (at around episode 6000), it selects actions with a lower risk (and a
lower number of failures), but also with considerably weak performance. The value  = 0.1
produces an intermediate policy. Consequently, it can be concluded that PI-SRL with a high
level of risk obtains better policies and less failures than the evolutionary or risk-sensitive
RL approaches. Figure 18 reinforces the previous conclusions.

Figure 18: Mean number of failures (pole disequilibrium or cart off the track) and cumulative reward during 500 trials for each approach in the pole-balancing task. The
means have been computed from 10 different executions.
544

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

In it, the mean number of failures and cumulative reward during 12,000 trials are shown,
with the red circles corresponding to PI-SRL, the black triangles corresponding to the risksensitive approach and the blue square corresponding to the evolutionary RL approach.
The figure also shows performance for two additional risk levels, a very high level of risk
( = 9  104 ) and very low level of risk ( = 0), with respect to Figure 17. The cumulative
reward and number of failures increase with the high level of risk ( = 9  105 ). This
risk level represents an inflection point at which higher levels of risk produce more failures
without an accompanying improvement in the cumulative reward. In fact, the very high level
of risk ( = 9  104 ) results in a reduction in the cumulative reward when compared with
the high level of risk ( = 9  105 ). Again, the Pareto comparison criterion may be used
to compare the solutions from Figure 18. In this domain, the solution from PI-SRL with
a low level of risk strictly dominates the risk-sensitive solutions with  = 0.0 and  = 0.1,
such that PI-SRL  = 9  107  risk-sensitive with  = 0.0 and  = 0.1. Additionally, the
solution from PI-SRL with a high level of risk strictly dominates evolutionary RL solution,
such that PI-SRL  = 9  105  evolutionary RL.
Lastly, Figure 19 shows the evolution of the known space derived from the case-base
B in different trials for a high-risk learning process. For each graph, error states  (red
area), the set of unknown states  (yellow area), the set of known states  (green area) and
the set of non-error states  (orange circles) are represented. The known space  in each
graph has been computed taking cases from B in the trials T = 0, 3000, 6000 and 8000. For
each graph, non-error states  have been computed from 10 different executions of B in
the trial T (the orange circles representing the terminal states for each of these executions).
The first graph (Figure 19 [a]) presents the initial known space resulting from the modeling
baseline behavior step. The evolution in Figure 19 demonstrates two different points. First,
PI-SRL progressively adapts the known space in order to encounter better behavior such
that the known space tends to be compressed toward the center of the coordinates. This
is so due to the fact that the reward is greater if the angle  of the pole and the cart
position x are 0 (i.e., the pole is as upright as possible on the cart and the cart is centered
on the track). Second, the risk of failure in the pole-balancing domain is greater during
early trials of the learning process. At the beginning of the learning process (Figure 19 [a]),
T = 0), some regions of the known space are close to the error space. In this situation,
slight modifications of the actions consistently produce visits to the states in  (i.e., pole
disequilibrium or cart falling off the track). As the learning process advances (Figure 19
[b], [c] and [d]), the known space is compressed toward the origin of coordinates and away
from the error space. Consequently, the probability of visiting error states decreases. For
example, returning to Figure 17 (a), in the high-risk learning processes, 52% of the failures
(126) occur in the first 4000 trials, while the remaining 48% (117) occur in the last 8000
trials.
4.3 Helicopter Hovering
As suggested by its name, the objective of this domain is to make a helicopter hover as close
as possible to a defined position for a duration established by an episode. The task is challenging for two main reasons. Firstly, both the state and action spaces are high-dimensional
and continuous (more specifically, the state space is 12-dimensional and the action space
545

fiGarca & Fernandez

Figure 19: Pole-balancing task: Evolution of the known space for different trials T = 0 (a),
T = 3000 (b), T = 6000 (c) and T = 8000 (d) in a high-risk learning process
( = 9  105 ). Each graph corresponds to the situation of the state space
according to the case-base B in trial T .
4-dimensional). Secondly, it is a generalized domain whose behavior is modified by the wind
factor. A helicopter episode is composed of 6000 steps, although it may end prematurely if
the helicopter crashes. The first step of PI-SRL is performed in order to imitate the baseline
behavior T .  and  were computed following the procedure described in subection 3.3
with values of 0.3 and 49735, respectively. Once this step has been performed, the resulting
 is able to properly imitate the baseline behavior  .
safe case-based policy B
T
Figure 20 (a) shows two learning processes of the modeling baseline behavior step.
Similar to previous tasks, as the learning processes progress, the number of steps executed
by the baseline behavior T is reduced while the number of steps using the case-base B
increases. By the end of the learning process, the case-base B stores the safe case-based
 . Figure 20 (b) compares the performance (in terms of cumulative reward per
policy B
 and the IB1 approach. Regarding the
episode) of T , the learned case-based policy B
first two, the average cumulative reward per episode of T is -78035.93, while that obtained
 is -85130.11. Although the   does not perfectly mimic the baseline behavior  ,
by B
T
B
546

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 20: Modeling baseline behavior step of helicopter hovering task: (a) Number of
steps per trial executed by case-base B and baseline behavior T . (b) Cumula and an IBL
tive reward per trial by T , the learned safe case-based policy B
approach.
it nevertheless performs a safe policy without crashing the helicopter. With regard to the
training process of the IB1 approach, every case produced during 15 episodes by the baseline
behavior T is stored. Figure 20 (b) demonstrates that the IB1 approach consistently results
in helicopter crashes, with a performance extremely far from that of the learned safe case . Improvement of the policy   begins when the state-action space is safely
based policy B
B
explored through the execution of step two of PI-SRL.
Figure 21 (a) shows the results for different risk levels. While PI-SRL low and medium
levels of risk levels do not produce helicopter crashes in PI-SRL, performance is nevertheless
quite weak.

Figure 21: Improving the learned baseline behavior step in helicopter hovering task: (a)
Cumulative reward per episode for different risk configurations obtained by PISRL. (b) Cumulative reward per episode obtained by evolutionary and risksensitive RL approaches. In all cases, any episode ending in failure is marked.
547

fiGarca & Fernandez

Conversely, the high level of risk established produces a near-optimal policy with a
low number of collisions. Extensive experimentation demonstrates that increasing the risk
parameter  = 9  103 also increases the number of crashes without an accompanying
improvement in the cumulative reward. Figure 21 (b) shows the results of the evolutionary
RL approach which, it should be remembered, was selected winner of the RL Competition
2009 in the same domain (Martn H. & Lope, 2009), as well as the risk-sensitive RL algorithm
for different  values. A comparison of the results between the evolutionary RL approach
and PI-SRL shows a similar cumulative reward, while also a significantly higher number
of crashes from the former than from the latter. In the evolutionary approach, all crashes
occur in the early steps of the learning process; while in PI-SRL, accidents occur at more
advanced steps of the learning process. In the case of the risk-sensitive RL algorithm, for
 = 0 and  = 0.01 the risk function is learned at around episode 3000. At this point, the
agent selects lower-risk actions and the number of crashes is considerably reduced. When
 = 0.4 and the agent selects actions resulting in higher values without taking risk into
account, performance improves, but at the expense of an increased number of accidents.
Nevertheless and whatever the  value, the number of crashes is higher and the performance
is worse than with PI-SRL.

Figure 22: Mean number of failures (helicopter crashes) and cumulative reward during 5000
episodes for each approach to the helicopter hovering task. The means have been
computed from 10 different executions.
The information from Figure 22, indicating the mean number of failures and cumulative
reward over 5000 episodes for each approach, complements the conclusions made above.
The data has been computed from 10 independent executions of each approach. As in
previous domains, PI-SRL is indicated by red circles, the risk-sensitive approach by the
black triangles and the evolutionary RL approach by the blue square. Figure 22 also shows
the performance for two additional risk levels, a very high level of risk ( = 9  102 )
and a very low level risk ( = 0), with respect to Figure 21. Figure 22 demonstrates
that the evolutionary RL approach obtains the highest cumulative reward (7.13  107 ),
followed closely by PI-SRL (7.57  107 ). The other approaches are far from these results.
Regarding the number of failures (i.e., helicopter crashes), as PI-SRL with a very low level
of risk ( = 0), a low level of risk ( = 9  105 ) and a medium level of risk ( = 9  104 )
548

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

produces no collisions, the PI-SRL algorithm with medium risk is preferable inasmuch as
the cumulative reward is higher (18.01  107 ). Using the Pareto comparison criterion,
the PI-SRL solution with a high level of risk strictly dominates the solutions of the risksensitive approach (PI-SRL  = 9  103  risk-sensitive). Moreover, PI-SRL is not strictly
dominated by any other solution.

Figure 23: Evolution of the known space for different episodes in the helicopter hovering
task. (a) Example of representation of a single known state in a radar chart. (b),
(c), and (d) Known states in episodes T = 0, T = 500 and T = 4000, respectively,
in a high-risk learning process ( = 9  103 ). Each graph corresponds to the
situation of the known space according to the case-base B in episode T .
As with the pole-balancing domain, Figure 23 shows the evolution of the known space
according to the case-base B in different episodes for a high-risk learning process. In this
case, radar charts are used due to the high number of features describing the states. A
radar chart is a graphical method for displaying multivariate data two-dimensionally. In the
Figure, each axis represents one of the features of the state and, to preserve the simplicity of
the representation, the charts are generated normalizing the absolute values of the features
between 0 and 1. Figure 23 (a) is an example of a representation of a single known state.
549

fiGarca & Fernandez

The value of each axis corresponds to the value of an individual feature in a state and a
line is drawn connecting the feature values for each axis. While the line in Figure 23 (a)
represents a single state, Figures 23 (b), (c) and (d) show the known space according to the
case-base B in episodes 0, 500 and 4000, respectively. These three charts do not represent
a single state, but rather all the states in B for the corresponding episode. Thus, for each
graph, the set of known states is marked  (green area). A state is considered an error state
if a single feature value for that state is greater than 1. The limits (marked by a red line in
the graphs) have been computed taking into account that the helicopter crashes if (i) the
velocity along any of the main axes exceeds 5 m/s, (ii) the position of the helicopter is off by
more than 20 m, (iii) the angular rate around any of the main axes exceeds 2  2 rad/s or
(iv) the orientation is more than 30 degrees from the target orientation. As with previous
tasks, Figure 23 indicates two different matters. First, as the learning proceeds, the known
space derived from B is adjusted to the space used for better and safer policies. In the
helicopter domain, the agent tries to hover the helicopter as close as possible to a target
position (i.e., the origin of coordinates), since the immediate rewards are greater the closer
the helicopter hovers to the origin. Thus, the known space starts to expand (Figure 23
[b]) and, progressively, is concentrated at the origin of coordinates (Figure 23 [c] and [d]).
With regard to the second matter, the probability of crashing is very low since, from the
very beginning, the known space already appears concentrated at the origin and far from
the error space (Figure 23 [b]). In other words, from the very beginning, all features of the
known space (i.e., forward, sideways and downward velocities; x, y, and z coordinates; x,
y and z angular-rates; and x, y and z quaternation) are very far from error space limits,
decreasing the probability of visiting an error state.
In the previous experiments, the second step of PI-SRL has been performed using an
initial case-base B free of failures that is built into the first step of the algorithm. The
following experiments show the performance of the second step of PI-SRL when different
initial policies are used. Figure 24 (a) shows the performance of these policies used as initial
policies. The continuous black line indicates the performance of the initial safe case-based
policy B , with an average cumulative reward per episode of -85,130.11, used in the previous
experiments prior to the execution of step two in the algorithm. The remaining lines in the
Figure correspond to the performance of three different initializations of the case-base B
used in the new experiments, prior to the execution of step two of the algorithm. Using a
very poor initial policy (dashed green lines) with which the helicopter crashed in nearly all
of the episodes, the average cumulative reward per episode was calculated at -108,548.03.
Using a different poor (albeit less poor) initial policy (continuous red lines) with which the
helicopter crashed occasionally, the average cumulative reward per episode was -91,723.89.
Finally, a near-optimal policy (dashed blue lines) whereby helicopter hovering is free of
failures yields an average cumulative reward per episode of -13,940.1.
The Figure 24 (b) shows performance in the second step (improving the baseline behavior
step) of PI-SRL, starting from a case-base B corresponding to the very poor, poor and the
near-optimal policies presented in Figure 24 (a). In Figure 24 (b), the dashed blue lines
correspond to the use of a case-base B containing the near-optimal policy, the continuous
red lines correspond to the use of a case-base B containing the poor policy and the dashed
green lines correspond to the use of a case-base B containing the very poor policy. All the
experiments in the Figure have been conducted using a high level of risk in the domain
550

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 24: (a) The performance of different initial policies in the helicopter hovering task.
(b) The performance of different executions of the second step of PI-SRL, each
starting from a case-base B containing a policy of three different types: very
poor, poor and near-optimal.

( = 9  103 ). The graph indicates that with the use of a near-optimal policy for an initial
policy and a high level of risk level, the case-base does not worsen performance which, in
fact, appears to improve slightly. The second step of PI-SRL prevents the degradation of
the initial performance of B, since no updates of cases in the case-base are made using bad
episodes. In other words, the updates in B are made with the cases gathered from episodes
with a cumulative reward similar to that of the best episode found at a particular point and
using a threshold  (whose value is set to 5% of the cumulative reward of the best episode).
For example, if the cumulative reward of the best episode is -13,940.1, only the episodes
with a cumulative reward higher than -14,637 are used to update the case-base (discarding
the bad episodes or other episodes with failures). In this way, good sequences of experiences
are provided to the updates, since it has been proven that good sequences of experiences
can cause an adaptive agent to converge to a stable and useful policy, while bad sequences
may cause an agent to converge to an unstable or poor policy (Wyatt, 1997). The solid red
lines in Figure 24 (b) show that using a poor policy with failures as initial policy produces
a higher number of failures than using an initial policy that is free of failures. However and
despite the poor initialization, PI-SRL is nevertheless able to learn a near-optimal policy as
well as when a policy free of failures is used to initialize B (see lines corresponding to a high
level of risk,  = 9  103 , in Figure 21 (a)). Finally, the dashed green lines in Figure 24
(b) show that the use of a very poor initial policy with many failures results in decreased
performance and a higher number of failures produced, even though it is nevertheless able
to learn better behavior. In this case, the algorithm falls into a local minimum, probably
biased by the very poor initialization. In both cases with poor policies, the number of
failures is higher at the beginning of the learning process and decreases as the learning
process proceeds. While both the poor and very poor initial policies are very close to the
error space, this is in stark contrast to the initial policy shown in Figure 23 which, from
the very beginning, already appears concentrated at the origin, far from the error space.
551

fiGarca & Fernandez

As the learning process proceeds, the different policies are compressed away from the error
space and the number of failures decreases.
4.4 SIMBA
Business simulators are powerful tools for improving management decision-making processes. An example of such a tool is the SIMulator for Business Administration (SIMBA)
(Borrajo et al., 2010). SIMBA is a competitive simulator, since agents can compete against
other agents through their management of different virtual companies. The simulator,
the result of over twenty years of experience both with university students and business
executives, emulates business realities using the same variables, relationships and events
present in the business world. Its objective is to provide users with an integrated vision
of a company, using basic techniques of business management, simplifying complexity and
emphasizing the content and principles with the greatest educational value (Borrajo et al.,
2010). In the experiments performed here, the learning agent competes against five handcoded agents (Borrajo et al., 2010). Decision-making in SIMBA is an episodic task where
decisions are made sequentially. To make a business decision, the state must be studied
and 10 continuous decision variables (e.g., selling price, advertising expenses, etc.) must
be set, followed by the study of a state composed of 12 continuous variables (e.g., material
costs, financial expenses, economic productivity, etc.) (Borrajo et al., 2010). Each episode
is composed of 52 steps, although it may prematurely if the company goes bankrupt (i.e.,
its losses are higher than 10% of its net assets).

Figure 25: Modeling baseline behavior step in SIMBA Task: (a) Number of steps per trial
executed by case-base B and baseline behavior T . (b) Cumulative reward per
 and an IBL approach.
trial by T , the learned safe case-based policy B
Figure 25 (a) shows the evolution of the number of steps executed by the baseline behavior T and the case-base B during two learning processes performing the modeling baseline
behavior step.  and  were computed following the procedure described in subsection 3.3
and have values of 1  102 and 513, respectively. In few episodes (approximately 25), the
 is learned. Figure 25 (b) shows the performance of the previouslysafe case-based policy B

learned B , T and the IB1 approach. In this study, the mean profits per episode of T
552

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Figure 26: Improving the learned baseline behavior step in SIMBA task: (a) The mean
profits per episode for different risk configurations obtained by the PI-SRL agent
against five hand-coded agents. (b) The mean profits per episode obtained by
the evolutionary and risk-sensitive RL agent against five hand-coded agents. In
each cases, any episode ending in failure (bankruptcy) is noted.
 are 4.02 million Euros. In the IB1
are 5.24 million Euros, while those obtained for B
approach, all cases generated using the baseline behavior T during 25 episodes are stored.
The experiments demonstrate that in SIMBA, in contrast with the previous domains, storing all cases is sufficient for obtaining a safe policy with a performance similar to that using
the modeling baseline behavior step (with mean profits per episode of 3.98 million Euros).
 is learned, we execute the improving the learned baseline
Once the safe case-based policy B
behavior step.
Similar to the findings in earlier tasks, Figure 26 (a) indicates that while low and medium
levels of risk do not produce bankruptcies, performance is nevertheless weak. The highest
level of risk produces a near-optimal policy with a low number number of failures. By
contrast, Figure 26 (b) presents the results for the evolutionary and risk-sensitive RL approaches, with the former being clearly that which yields the highest number of failures.
In the risk-sensitive case, the number of bankruptcies in all cases is insufficient for learning the risk function . The comparative results in Figure 26 show that PI-SRL with
 = 9  101 obtains better policies and less failures than the evolutionary or risk-sensitive
RL approaches.
Figure 27 shows a graphical representation of the different solutions in this domain. It
shows the mean number of failures and cumulative reward for the different approaches over
100 episodes, with data computed from 10 independent executions of each approach. In the
Figure, red circles correspond to the PI-SRL algorithm, black triangles correspond to the
risk-sensitive approach and the blue square corresponds to the evolutionary RL approach.
Figure 27 also shows the performance for two additional risk levels, very high ( = 9  102 )
and very low ( = 0), with respect the Figure 26. The experiments in Figure 27 demonstrate
that PI-SRL with a high level of risk ( = 9  101 ) obtains the highest cumulative reward,
6693.58. Additionally, PI-SRL with a very low level of risk ( = 0), a low level of risk
( = 9  101 ) and a medium level of risk ( = 9  100 ) are the approaches with the lowest

553

fiGarca & Fernandez

Figure 27: Mean number of failures (company bankruptcies) and the cumulative reward
over 100 episodes for each approach to the SIMBA task. The means have been
computed from 10 different executions.
mean number of failures, 0.0. However, PI-SRL with a medium level of risk is preferred
inasmuch as its performance is superior in terms of cumulative reward. PI-SRL with a very
high level risk ( = 9  102 ) increases the number of failures and obtains a lower cumulative
reward when compared to PI-SRL with a high level of risk. Using the Pareto comparison
criterion, PI-SRL with a high level of risk strictly dominates all other solutions (PI-SRL
 = 9101  risk-sensitive and PI-SRL  = 9101  evolutionary RL), while the approach
is not strictly dominated by any other solution.
Due to the difficulty of representing the high-dimensional state and action space of the
SIMBA domain, no graphs are provided with the evolution of the known space.

5. Related Work
Reinforcement learning (RL) and case-based reasoning (CBR) techniques have been combined in the literature in different ways. In the work of Bianchi et al. (2009), a new approach
is presented permitting the use of cases as heuristics to speed up RL algorithms. Additionally, Sharma et al. (2007) use a combination of CBR and RL (called CARL) to achieve
transfer while playing against the Game AI across a variety of scenarios in MadRTS TM,
a commercial Real Time Strategy game. CBR has also been used for state value function
approximation in RL (Gabel & Riedmiller, 2005). However, the present study is, to our
knowledge, the first time that CBR and RL have been used in conjunction for safe exploration in dangerous domains. In the field of safe reinforcement learning, three principal
trends can be observed: (i) approaches based on return and its variance, (ii) risk-sensitive
approaches based on the definition of error states and (iii) approaches using teachers.
5.1 Approaches Based on the Return and its Variance
In the literature, it has long been known that the optimal policy and the optimal expected
return of an MDP are quite sensitive to parameter variations (even an optimal policy may
554

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

perform badly in some cases due to the stochastic nature of the problem). To mitigate this
problem, the agent can try to maximize the return associated with the worst-case scenario,
even though the case may be highly
unlikely. Thus, in this trend, the risk refers to the worst
P
t r or its variance. An example of such an approach
outcomes of the return R = 

t
t=0
is worst-case control where the worst possible outcome of R is to be optimized (Coraluppi
& Marcus, 1999; Heger, 1994). In worst case control strategies, the optimality criterion
is exclusively focused on risk-avoiding policies. A policy is considered to be optimal if its
worst-case return is superior. The approach, however, is too restrictive inasmuch as it takes
very rare scenarios fully into account.
The   value of the return m introduced by Heger (1994) can be seen as an extension
of the worst case control of MDPs. This concept establishes that the returns R < m of
a policy that occur with a probability lower than  are neglected. The algorithm is less
pessimistic than pure worst case control, given that extremely rare scenarios have no effect
on the policy. In the work of Heger et al., the idea of weighting return and risk, namely the
expected value-variance criterion, is also introduced.
In risk-sensitive control based on the use of exponential utility functions, the return R is
transformed to reflect a subjective measure of utility. Instead of maximizing the expected
value of R, the objective here is to maximize U =  1 logE(eR ), where  is a parameter
and R is the usual return. It can be shown that, depending on the parameter , policies
with a high variance V (R) are penalized ( < 0) or enforced ( > 0). Instead, Neuneier
and Mihatsch (2002) consider the worst-case-outcomes of a policy, (i.e., risk related to the
variability of the return). In the study, the authors demonstrate that the learning algorithm
interpolates between risk-neutral and the worst-case criterion and has the same limiting
behavior as exponential utility functions. It should be noted that these approaches based
on the variability of the return or its worst possible outcomes are not suited for problems
where a policy with a small variance can produce a large risk (Geibel & Wysotzki, 2005).
Our view of risk in the present study, however, is not concerned with the variance of the
return or its worst possible outcome, but instead with the fact that processes generally
possess unsafe states that should be avoided. Consequently, we address a different class of
problems than those dealt with by approaches focusing on the variability of the return.
5.2 Risk-sensitive Approaches based on Error States.
In this second trend of approaches, the concept of risk is based on the definition of error
states or fatal transitions. Thus, Geibel et al. (2005) , for instance, establish the risk
function as the probability of entering in an error state. Instead, Hans et al (2008) consider
a transition to be fatal if the corresponding reward is less than a given threshold  . In
the first case and as demonstrated in Section 4,  is learned by TD methods which require
that error states (i.e., car collisions, pole-balancing disequilibrium, helicopter crashes and
company bankruptcies) be visited repeatedly in order to approximate the risk function
and, subsequently, avoid dangerous situations. In the second case, the concept of risk is
again joined with that of reward. Moreover, the above mentioned studies either (i) assume
that the system dynamics are known, (ii) tolerate undesirable states during exploration
or, in contrast with our paper, (iii) do not deal with problems with high-dimensional and
continuous state-action spaces. Regarding the latter, while Geibel et al. write that their
555

fiGarca & Fernandez

approach can also be extended to continuous action sets (e.g., by using an actor-critic
method), they do not give any more details on how this may be done with entirely continuous
problems. In Section 4, we present an approach that solves the problem.
5.3 Approaches Using Teachers
The last trend in the approaches is based on the use of teachers in three different ways:
(i) to bootstrap the learning algorithm (i.e., as an initialization procedure), (ii) to derive a
policy from a finite demonstration set and (iii) to guide the exploration process.
5.3.1 Bootstrapping the Learning Algorithm
In the work of Driessens and Szeroski (2004), a bootstraping procedure is used for relational RL in which a finite set of demonstrations are recorded from a human expert and
later presented to a regression algorithm. This allows the regression algorithm to build a
partial Q-function which can later be used to guide further exploration of the state space
using a Boltzmann exploration strategy. Smart and Kaelbling (2000) also use examples,
training runs to bootstrap the Q-learning approach for their HEDGER algorithm. The
initial knowledge bootstrapped into the Q-learning approach allows the agent to learn more
effectively and helps reduce the time spent with random actions. Teacher behaviors are
also used as a form of population seeding in neuroevolution approaches (Yao, 1999; Siebel &
Sommer, 2007). Evolutionary methods are used to optimize the weights of neural networks,
but starting from a prototype network whose weights correspond to a teacher (or baseline
policy). Using this technique, RL Competition helicopter hovering task winners Martin et
al. (2009) developed an evolutionary RL algorithm in which several teachers are provided in
the initial population. The algorithm restricts crossover and mutation operators, allowing
only slight changes to the policies given by the teachers. Consequently, the rapid convergence of the algorithm to a near-optimal policy is ensured, as is the indirect minimization of
damage to the agent. However, the teachers included in the initial population resulting from
an ad-hoc training regimen conducted before the competition. Consequently, the proposed
approach seems somewhat ad-hoc and not easily generalizable to arbitrary RL problems.
In the work of Koppejan et al. (2009, 2011), neural networks are also evolved, beginning
with one whose weights corresponds to teacher behavior. While this approach has been
proven advantageous in numerous applications of evolutionary methods (Hernandez-Daz
et al., 2008; Koppejan & Whiteson, 2009), Koppejans algorithm nevertheless also seems
somewhat ad-hoc and designed for a specialized set of environments.
5.3.2 Deriving a Policy from a Finite Set of Demonstrations
All approaches falling under this category are framed according to the field of Learning from
Demonstration (LfD) (Argall et al., 2009). Highlighting the study by Abbeel et al. (2010)
based on apprenticeship learning, the approach is composed of three distinct steps. In the
first, a teacher demonstrates the task to be learned and the state-action trajectories of the
teachers demonstration are recorded. In the second step, all state-action trajectories seen
to that point are used to learn a dynamics model for the system. For this model, a (near)optimal policy is to be found using any reinforcement learning (RL) algorithm. Finally, the
policy obtained should be tested by running it on the real system. In the work of Tang et
556

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

al. (2010), an algorithm based on apprenticeship learning is also presented for automaticallygenerating trajectories for difficult control tasks. The proposal is based on the learning of
parameterized versions of desired maneuvers from multiple expert demonstrations. Despite
each approachs potential strengths and general interest, all are inherently linked to the
information provided in the demonstration dataset. As a result, learner performance is
heavily limited by the quality of the teachers demonstrations.
5.3.3 Guiding the Exploration Process
Driessens and Szeroski (2004), in the context of relational RL, also use a given teachers
policy, rather than a policy derived from the current Q-function hypothesis (which is not
informative in the early learning stages), for the selection of actions. In this approach,
episodes performed by a teacher are interleaved with normal exploration episodes. This
mixture of teacher and normal exploration make it easier for the regression algorithm to
distinguish between beneficial and poor actions. In the context of LfD, there are other
approaches which include teacher advice (Argall et al., 2009). This advice is used to improve
learner performance, offering information beyond that which is provided by a demonstration
dataset. In this approach, following an initial task demonstration by the teacher, the agent
directly requests additional demonstration from the teacher in very different states from
those previously demonstrated or in states in which a single action cannot be selected with
certainty (Chernova & Veloso, 2007, 2008).
In all works mentioned for this trend, no explicit definition of risk is ever given.

6. Conclusions
In this work, PI-SRL, an algorithm for policy improvement through safe reinforcement
learning in high-risk tasks, is described. The main contributions of this algorithm are the
definitions of a novel case-based risk function and a baseline behavior for the safe exploration
of the state-action space. The use of the case-based risk function presented is possible
inasmuch as the policy is stored as a case-base. This represents a clear advantage over
other approaches, e.g., evolutionary RL (Martn H. & Lope, 2009; Koppejan & Whiteson,
2011) where the extraction of knowledge about the known space by the agent is impossible
using the weights of the neural-networks. Additionally, a completely different notion of
risk from others found in the literature is presented. According to our notion, risk is
independent of the variance of the return and the reward function, and does not require
the identification of error states or the learning of risk functions. Rather, the concept of
risk described in this paper is based on the distance between the known and unknown
space and, therefore, is a domain-independent parameter (in this sense, our proposal allows
for the application of a parameter-setting method as described in subsection 3.3). While
Koppejan et al. (2011) also use a function to identify dangerous states, in contrast with our
approach, the definition of their function requires strong previous knowledge of the domain.
Furthermore, most of the approaches to risk found in the literature only tackle problems
that are not entirely continuous (Geibel & Wysotzki, 2005) or that only report results on
one continuous domain (Koppejan & Whiteson, 2011). Consequently, it is difficult to know
for certain if these approaches from the literature generalize easily to arbitrary domains.
557

fiGarca & Fernandez

This paper presents the PI-SRL algorithm in great detail and demonstrates its effectiveness in four entirely different continuous domains: the car parking problem, pole-balancing,
helicopter hovering and business management (SIMBA). The experiments presented in this
paper demonstrate different characteristics about the learning capabilities of the PI-SRL
algorithm.
(i) PI-SRL obtains higher quality solutions. The experiments in Section 4 demonstrate
that, save in the helicopter hovering task, PI-SRL obtains in all cases the best cumulative
reward per episode and the least number of failures. Additionally, using the Pareto comparison criterion it can be said that, save the very high risk configuration in the car parking
problem, our approach is not strictly dominated by any other approach.
(ii) PI-SRL adjusts the initial known space to safe and better policies. The initial known
space resulting from the first step of PI-SRL, modeling baseline behavior, is adjusted and
improved in the second step of the algorithm, improving the learned baseline behavior.
Additionally, the experiments demonstrate that the adjustment process can compress the
known space away from the error space (e.g., pole-balancing domain, subsection 4.2, and
helicopter hovering domain, subsection 4.3) or, on other occasions, can require the known
space to move closer to the error space (e.g., car parking problem, subsection 4.1) in the
event that better policies are be found there.
(iii) PI-SRL works well in domains with differently structured state-action spaces and
where the value function can vary sharply. Although the car parking problem, the polebalancing domain, the helicopter hovering task and the business simulator all represent
very differently structured problems, experiments in the study nevertheless demonstrate
that PI-SRL performs well in each. Furthermore, even in such domains as the car parking
problem in which the value function varies sharply due to the presence of an obstacle,
experimental results demonstrate that PI-SRL can nevertheless successfully handle this
difficulty. However, it is impossible to avoid all failures if the known space edge is the
same as the edge to error states the algorithm would often explore into error states.
(iv) The number of failures depends on the distance between the known space and the
error space. The experiments in the pole-balancing and helicopter hovering domains demonstrate that the number of failures depends on how close the known space is to the error
space. Due to the structure of these domains, the improving the learned baseline behavior
step in the algorithm tends to concentrate the known space at the origin of coordinates
away from the error space. The greater the distance between the known space and the error
space, the lower the number of failures. Additionally, in helicopter hovering, the known
space is, from the beginning, far from the error space (consequently, the number of failures is also low from the beginning). Therefore, the initial distribution of the known space
learned from the baseline policy T later influences the number of failures obtained by the
second step of PI-SRL.
(v) PI-SRL is completely safe if only the first step of the algorithm is executed. However,
by proceeding only in this way, algorithm performance would be heavily limited by the
capabilities of the baseline behavior. If learner performance is to be improved beyond
the performance of this baseline behavior, the subsequent exploratory process from the
second step of PI-SRL must be carried out. Since complete knowledge of the domain and
its dynamic is not possessed, however, it is also inevitable that, during this exploratory
558

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

process, unknown regions of the state space will be visited where the agent may reach error
states.
(vi) The risk parameter allows the user to configure the level of risk assumed. In our
algorithm, the user can gradually increase the value of the risk parameter  in order to
obtain better policies, but also assuming a greater likelihood of damage in the learning
system.
(vii) PI-SRL performs successfully even when a poor initial policy with failures is used.
The experiments in Figure 24 from the helicopter hovering domain demonstrate that PI-SRL
is able to learn a near-optimal policy despite poor initialization, just as it can when a policy
free of failures is used to initialize the case-base B. However, the Figure also shows that if
a very poor initial policy with many failures is used, PI-SRL decreases in performance and
produces a higher number of failures, although some better behavior is still learnt. In this
case, the algorithm falls into a local minimum, likely biased by the very poor initialization.
In what follows, the applicability of the method is discussed, allowing the reader to more
clearly understand the scenarios in which the proposed PI-SRL approach may be applicable.
This applicability is restricted to domains having the following characteristics.
(i) It is mandatory that the scenario satisfy the two assumptions described in Section 2.
According to the first assumption, nearby states in the domain must necessarily have similar actions. According to the other, similar actions in similar states should produce similar
effects. This fact that similar actions lead to similar states assumes some degree of smoothness in the dynamic behavior of the system which, in certain environments, may not hold.
However, as we clearly explain in Section 2, we consider both assumptions to be logical
assumptions derived from generalization principles in the RL literature (Kaelbling et al.,
1996; Jiang, 2004).
(ii) The applicability of the method is limited by the size of the case-base B required to
mimic the baseline behavior. It is not possible to apply the proposed approach to tasks when,
in the first step of the PI-SRL algorithm, modeling baseline behavior, a prohibitively large
number of cases are required to properly mimic complex baseline behaviors. In this case,
the threshold  can be increased to further restrict the addition of new cases to the casebase. However, this increase may adversely affect the final performance of the algorithm.
Nevertheless, the experiments performed in Section 4 demonstrate that relatively simple
baseline behaviors are mimicked almost perfectly using a manageable number of cases.
(iii) The PI-SRL algorithm requires the presence of a baseline behavior. The proposed
method requires the presence of a baseline behavior that safely demonstrates the task to
be learned. This baseline behavior can be conducted by a human teacher or a hand-coded
agent. It is important to note, nevertheless, that the presence of such a baseline behavior
is not guaranteed in all domains.
Finally, a logical continuation of the present study would take into account the automatic
graduation of the risk parameter along the learning process. For example, it would be
particularly interesting to exploit the fact that the known space is far away from the error
space in order to increase the risk parameter or, on the contrary, to reduce it when it is
close. Other future work aims to deploy the algorithm in real environments, inasmuch
as the uncertainty of the real environments presents the biggest challenge to autonomous
robots. Autonomous robotic controllers must deal with a large number of factors such
as the robotic mechanical system and electrical characteristics, as well as environmental
559

fiGarca & Fernandez

complexity. However, the use of the PI-SRL algorithm (or other risk-sensitive approaches)
for learning processes in real environments could reduce the amount of damage incurred
and, consequently, allow the lifespan of the robots to be extended. It might be worthwhile
add a mechanism to the algorithm to detect when a known state can lead directly to an
error state. All such problems are currently being investigated.

Acknowledgments
This study has been partially supported by Spanish MICIIN projects TIN2008-06701-C0303, TRA2009-0080 and CCG10-UC3M/TIC-5597. We offer our gratitude and special thanks
to Raquel Fuentetaja Pizan, Assistant Professor at Universidad Carlos III de Madrid in the
Planning & Learning Group (PLG), for her generous and invaluable comments during the
revision of this paper. We would also like to thank to Jose Antonio Martn, Assistant
Professor at Universidad Complutense de Madrid, for his invaluable comments regarding
his evolutionary RL algorithm.

References
Aamodt, A., & Plaza, E. (1994). Case-Based Reasoning; Foundational Issues, Methodological Variations, and System Approaches. AI Communications, 7 (1), 3959.
Abbeel, P., Coates, A., Hunter, T., & Ng, A. Y. (2008). Autonomous Autorotation of an
RC Helicopter. In ISER, pp. 385394.
Abbeel, P., Coates, A., & Ng, A. Y. (2010). Autonomous helicopter aerobatics through
apprenticeship learning. I. J. Robotic Res., 29 (13), 16081639.
Abbott, R. G. (2008). Robocup 2007: Robot soccer world cup xi.. chap. Behavioral Cloning
for Simulator Validation, pp. 329336. Springer-Verlag, Berlin, Heidelberg.
Aha, D. W. (1992). Tolerating Noisy, Irrelevant and Novel Attributes in Instance-Based
Learning Algorithms. International Journal Man-Machine Studies, 36 (2), 267287.
Aha, D. W., & Kibler, D. (1991). Instance-based learning algorithms. In Machine Learning,
pp. 3766.
Anderson, C. W., Draper, B. A., & Peterson, D. A. (2000). Behavioral cloning of student
pilots with modular neural networks. In Proceedings of the Seventeenth International
Conference on Machine Learning, pp. 2532. Morgan Kaufmann.
Argall, B., Chernova, S., Veloso, M., & Browning, B. (2009). A Survey of Robot Learning
from Demonstration. Robotics and Autonomous Systems, 57 (5), 469483.
Bartsch-Sprl, B., Lenz, M., & Hbner, A. (1999). Case-based reasoning: Survey and future
directions.. In Puppe, F. (Ed.), XPS, Vol. 1570 of Lecture Notes in Computer Science,
pp. 6789. Springer.
Bianchi, R., Ros, R., & de Mantaras, R. L. (2009). Improving reinforcement learning by
using case-based heuristics.. Vol. 5650, pp. 7589. Lecture Notes in Artificial Intelligence, Springer, Lecture Notes in Artificial Intelligence, Springer.
560

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Borrajo, F., Bueno, Y., de Pablo, I., Santos, B. n., Fernandez, F., Garca, J., & Sagredo, I.
(2010). SIMBA: A Simulator for Business Education and Research. Decission Support
Systems, 48 (3), 498506.
Boyan, J., Moore, A., & Sutton, R. (1995). Proceedings of the workshop on value function
approximation, machine learning conference 1995... Technical Report CMU-CS-95206.
Chernova, S., & Veloso, M. (2007). Confidence-based policy learning from demonstration
using gaussian mixture models. In Joint Conference on Autonomous Agents and
Multi-Agent Systems.
Chernova, S., & Veloso, M. (2008). Multi-thresholded approach to demonstration selection
for interactive robot learning. In Proceedings of the 3rd ACM/IEEE international
conference on Human robot interaction, HRI 08, pp. 225232, New York, NY, USA.
ACM.
Cichosz, P. (1995). Truncating temporal differences: On the efficient implementation of
td(lambda) for reinforcement learning. Journal of Artificial Intelligence Research
(JAIR), 2, 287318.
Cichosz, P. (1996). Truncated temporal differences with function approximation: Successful examples using cmac. In Proceedings of the Thirteenth European Symposium on
Cybernetics and Systems Research (EMCSR-96).
Coraluppi, S. P., & Marcus, S. I. (1999). Risk-Sensitive and Minimax Control of DiscreteTime, Finite-State Markov Decision Processes. AUTOMATICA, 35, 301309.
Defourny, B., Ernst, D., & Wehenkel, L. (2008). Risk-aware decision making and dynamic
programming. In NIPS 2008 Workshop on Model Uncertainty and Risk in RL.
Driessens, K., & Ramon, J. (2003). Relational instance based regression for relational rl.
In International Conference of Machine Learning (ICML), pp. 123130.
Driessens, K., & Dzeroski, S. (2004). Integrating guidance into relational reinforcement
learning. Machine Learning, 57 (3), 271304.
Fernandez, F., & Isasi, P. (2008). Local feature weighting in nearest prototype classification.
Neural Networks, IEEE Transactions on, 19 (1), 4053.
Fernandez, F., & Borrajo, D. (2008). Two steps reinforcement learning. International
Journal of Intelligent Systems, 23 (2), 213245.
Floyd, M. W., & Esfandiari, B. (2010). Toward a domain-independent case-based reasoning
approach for imitation: Three case studies in gaming. In Workshop on Case-Based
Reasoning for Computer Games at the 18th International Conference on Case-Based
Reasoning (ICCBR), pp. 5564.
Floyd, M. W., Esfandiari, B., & Lam, K. (2008). A Case-Based Reasoning Approach to
Imitating Robocup Players. In Proceedings of the 21st International Florida Artificial
Intelligence Research Society Conference, pp. 251256.
Forbes, J., & Andre, D. (2002). Representations for learning control policies. In The
University of New South, pp. 714.
561

fiGarca & Fernandez

Gabel, T., & Riedmiller, M. (2005). Cbr for state value function approximation in reinforcement learning. In Proceedings of the 6th International Conference on Case-Based
Reasoning (ICCBR 2005, pp. 206221. Springer.
Geibel, P. (2001). Reinforcement Learning with Bounded Risk. In Proceedings of the 18th
International Conference on Machine Learning, pp. 162169. Morgan Kaufmann.
Geibel, P., & Wysotzki, F. (2005). Risk-sensitive Reinforcement Learning Applied to Control
under Constraints. Journal of Artificial Intelligence Research (JAIR), 24, 81108.
Hans, A., Schneegass, D., Schafer, A. M., & Udluft, S. (2008). Safe Exploration for Reinforcement Learning. In European Symposium on Artificial Neural Network, pp.
143148.
Heger, M. (1994). Consideration of Risk in Reinforcement Learning. In 11th International
Conference on Machine Learning, pp. 105111.
Hernandez-Daz, A. G., Coello, C. A. C., Perez, F., Caballero, R., Luque, J. M., & SantanaQuintero, L. V. (2008). Seeding the initial population of a multi-objective evolutionary algorithm using gradient-based information. In IEEE Congress on Evolutionary
Computation, pp. 16171624. IEEE.
Hester, T., Quinlan, M., & Stone, P. (2011). A real-time model-based reinforcement learning
architecture for robot control. Tech. rep. arXiv e-Prints 1105.1749, arXiv.
Hu, H., Kostiadis, K., Hunter, M., & Kalyviotis, N. (2001). Essex wizards 2001 team
description. In Birk, A., Coradeschi, S., & Tadokoro, S. (Eds.), RoboCup, Vol. 2377
of Lecture Notes in Computer Science, pp. 511514. Springer.
Jiang, A. X. (2004). Multiagent reinforcement learning in stochastic games with continuous
action spaces..
Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: A survey. Journal
of Artificial Intelligence Research (JAIR), 4, 237285.
Konen, W., & Bartz-Beielstein, T. (2009). Reinforcement learning for games: failures and
successes. In Proceedings of the 11th Annual Conference Companion on Genetic and
Evolutionary Computation Conference: Late Breaking Papers, GECCO 09, pp. 2641
2648, New York, NY, USA. ACM.
Koppejan, R., & Whiteson, S. (2009). Neuroevolutionary reinforcement learning for generalized helicopter control. In GECCO 2009: Proceedings of the Genetic and Evolutionary
Computation Conference, pp. 145152.
Koppejan, R., & Whiteson, S. (2011). Neuroevolutionary reinforcement learning for generalized control of simulated helicopters. Evolutionary Intelligence, 4, 219241.
Lee, J.-Y., & Lee, J.-J. (2008). Multiple Designs of Fuzzy Controllers for Car Parking Using
Evolutionary Algorithm, pp. 16. No. May.
Luenberger, D. G. (1998). Investment science. Oxford University Press.
Mannor, S. (2004). Reinforcement learning for average reward zero-sum games. In ShaweTaylor, J., & Singer, Y. (Eds.), COLT, Vol. 3120 of Lecture Notes in Computer Science,
pp. 4963. Springer.
562

fiSafe Exploration of State and Action Spaces in Reinforcement Learning

Martin H, J., & de Lope, J. (2009). Exa: An effective algorithm for continuous actions
reinforcement learning problems. In Industrial Electronics, 2009. IECON 09. 35th
Annual Conference of IEEE, pp. 2063 2068.
Martn H., J. A., & Lope, J. (2009). Learning Autonomous Helicopter Flight with Evolutionary Reinforcement Learning. In 12th International Conference on Computer
Aided Systems Theory (EUROCAST), pp. 7582.
Mihatsch, O., & Neuneier, R. (2002). Risk-Sensitive reinforcement learning. Machine Learning, 49 (2-3), 267290.
Moldovan, T. M., & Abbeel, P. (2012). Safe exploration in markov decision processes.
CoRR, abs/1205.4810.
Narendra, K. S., & Thathachar, M. A. L. (1974). Learning automata - a survey. Ieee
Transactions On Systems Man And Cybernetics, SMC-4 (4), 323334.
Narendra, K. S., & Thathachar, M. A. L. (1989). Learning automata: an introduction.
Prentice-Hall, Inc., Upper Saddle River, NJ, USA.
Ng, A. Y., Kim, H. J., Jordan, M. I., & Sastry, S. (2003). Autonomous Helicopter Flight
via Reinforcement Learning. In Thrun, S., Saul, L. K., & Scholkopf, B. (Eds.), NIPS.
MIT Press.
Peters, J., Tedrake, R., Roy, N., & Morimoto, J. (2010). Robot learning. In Sammut, C.,
& Webb, G. I. (Eds.), Encyclopedia of Machine Learning, pp. 865869. Springer.
Poli, R., & Cagnoni, S. (1997). Genetic programming with user-driven selection: Experiments on the evolution of algorithms for image enhancement. In Genetic Programming
1997: Proceedings of the Second Annual Conference, pp. 269277. Morgan Kaufmann.
Salkham, A., Cunningham, R., Garg, A., & Cahill, V. (2008). A collaborative reinforcement learning approach to urban traffic control optimization. In Web Intelligence
and Intelligent Agent Technology, 2008. WI-IAT 08. IEEE/WIC/ACM International
Conference on, Vol. 2, pp. 560566.
Santamara, J. C., Sutton, R. S., & Ram, A. (1998). Experiments with reinforcement
learning in problems with continuous state and action spaces. Adaptive Behavior, 6,
163218.
Sharma, M., Holmes, M., Santamaria, J., Irani, A., Isbell, C., & Ram, A. (2007). Transfer
learning in real-time strategy games using hybrid cbr/rl. In In Proceedings of the
Twentieth International Joint Conference on Artificial Intelligence.
Siebel, N. T., & Sommer, G. (2007). Evolutionary reinforcement learning of artificial neural
networks. International Journal of Hybrid Intelligent Systems, 4, 171183.
Smart, W. D., & Kaelbling, L. P. (2000). Practical reinforcement learning in continuous
spaces. In Artificial Intelligence, pp. 903910. Morgan Kaufmann.
Smart, W. D., & Kaelbling, L. P. (2002). Effective reinforcement learning for mobile robots.
In ICRA, pp. 34043410. IEEE.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: An Introduction. The MIT
Press.
563

fiGarca & Fernandez

Tang, J., Singh, A., Goehausen, N., & Abbeel, P. (2010). Parameterized maneuver learning for autonomous helicopter flight. In International Conference on Robotics and
Automation (ICRA).
Taylor, M. E., Kulis, B., & Sha, F. (2011). Metric learning for reinforcement learning agents.
In Proceedings of the International Conference on Autonomous Agents and Multiagent
Systems (AAMAS).
Van Hasselt, H., & Wiering, M. A. (2007). Reinforcement Learning in Continuous Action
Spaces. In Approximate Dynamic Programming and Reinforcement Learning, 2007.
ADPRL 2007. IEEE International Symposium on, pp. 272279.
Wyatt, J. (1997). Exploration and Inference in Learning from Reinforcement. University of
Edinburgh.
Yao, X. (1999). Evolving artificial neural networks. PIEEE: Proceedings of the IEEE, 87,
14231447.

564

fiJournal of Artificial Intelligence Research 45 (2012) 1-45

Submitted 11/11; published 9/12

Interactions between Knowledge and Time in
a First-Order Logic for Multi-Agent Systems:
Completeness Results
F. Belardinelli
A. Lomuscio

f.belardinelli@imperial.ac.uk
a.lomuscio@imperial.ac.uk

Department of Computing
Imperial College London, UK

Abstract
We investigate a class of first-order temporal-epistemic logics for reasoning about multiagent systems. We encode typical properties of systems including perfect recall, synchronicity, no learning, and having a unique initial state in terms of variants of quantified interpreted systems, a first-order extension of interpreted systems. We identify several monodic
fragments of first-order temporal-epistemic logic and show their completeness with respect
to their corresponding classes of quantified interpreted systems.

1. Introduction
While reactive systems (Pnueli, 1977) are traditionally specified using plain temporal logic,
there is a well-established tradition in Artificial Intelligence (AI) and, in particular, MultiAgent Systems (MAS) research to adopt more expressive languages. Much of this tradition
is inspired by the earlier, seminal work in AI by McCarthy (1979, 1990) and others aimed at
adopting an intentional stance (Dennett, 1987) when reasoning about intelligent systems.
Specifically, logics for knowledge (Fagin, Halpern, Moses, & Vardi, 1995), beliefs, desires,
intentions, obligations, etc., have been put forward to represent the informational and
motivational attitudes of agents in the system. Theoretical explorations have focused on
the soundness and completeness of a number of axiomatisations as well as the decidability
and computational complexity of the corresponding logics.
The great majority of work in these lines focuses on propositional languages. Yet, specifications supporting quantification are increasingly required in applications. For example,
it is often necessary to refer to different individuals at different instances of time.
Quantified modal languages (Garson, 2001) have long attracted considerable attention.
Early work included analysing the philosophical and logical implications of different setups for the quantification domains, particularly in combination with temporal concepts.
More recently, considerable attention has been given to identifying suitable fragments that
preserve completeness and decidability, and then studying the resulting computational complexity of the satisfiability problem. This article follows this direction.
In more detail, we investigate the meta-theoretical properties of monodic fragments
of quantified temporal-epistemic logic where interactions between quantifiers, time, and
knowledge of the agents are present. There is a deep-rooted interest (Fagin et al., 1995;
Meyden, 1994) in understanding the implications of interaction axioms in this context, as
they often express interesting properties of MAS, including perfect recall, synchronicity,
c
2012
AI Access Foundation. All rights reserved.

fiBelardinelli & Lomuscio

and no learning. These features are well-understood at the propositional level (Fagin,
Halpern, & Vardi, 1992; Halpern, van der Meyden, & Vardi, 2004) and are commonly used
in several application areas. The technical question this paper aims to resolve is whether a
similar range of results can be provided in the presence of (limited forms of) quantification.
As we shall demonstrate, the answer to this question is largely positive.
1.1 State of the Art
The analysis and application of temporal-epistemic logic in a first-order setting has an
established tradition in AI. One of the early contributions is the work of Moore (1990),
which presents a theory of action that takes into consideration the epistemic preconditions
to actions and their effects on knowledge. More recently, a number of first-order temporalepistemic logics for reasoning about MAS were introduced by Wooldridge et al. (2002,
2006, 1999), often in the context of the MABLE programming language for agents. The
same authors introduced a first-order branching time temporal logic for MAS (Wooldridge
& Fisher, 1992), and developed it in a series of papers (Wooldridge et al., 2002, 2006).
First-order multi-modal logics also constitute the conceptual base of a number of other
agent theories, such as BDI logics (Rao & Georgeff, 1991), the KQML framework (Cohen
& Levesque, 1995), and the LORA framework (Wooldridge, 2000b). All of these include
operators for mental attitudes (e.g., knowledge, belief, intention, desire, etc.), as well as
temporal and dynamic operators with some form of quantification. However, most of the
current literature has so far fallen short of a systematic analysis of the formal properties of
these frameworks. Some of the frameworks above are so rich that they are unlikely to be
finitely axiomatisable, let alone decidable. Still, these earlier contributions are an inspiration
to the present investigation, as they are among the few to have explicitly addressed the
subject of first-order temporal-epistemic languages in a MAS setting.
At a purely theoretical level, first-order temporal and epistemic logics have also received increasing attention with a range of contributions on axiomatisability (Degtyarev
et al., 2003; Sturm et al., 2000; Wolter & Zakharyaschev, 2002), decidability (Degtyarev
et al., 2002; Hodkinson et al., 2000; Wolter & Zakharyaschev, 2001), and complexity (Hodkinson, 2006; Hodkinson et al., 2003). Wolter and Zakharyaschev (2001) introduced the
monodic fragment of quantified modal logic, where the modal operators are restricted to
formulas with at most one free variable, and they proved the decidability of various fragments. Similar results have been obtained for monodic fragments of first-order temporal
logic (Hodkinson, 2002; Hodkinson et al., 2000), and the computational complexity of these
formalisms have been analysed (Hodkinson, 2006; Hodkinson et al., 2003). Further, Wolter
and Zakharyaschev (2002) provided a complete axiomatisation of the monodic first-order
validities on the natural numbers. The monodic fragment of first-order epistemic logic has
also been explored (Sturm et al., 2000; Sturm, Wolter, & Zakharyaschev, 2002), and an
axiomatisation including common knowledge has been provided. These lines of research
constitute the theoretical background against which this research is set.
The contributions discussed previously used plain Kripke models as the underlying semantics. However, it has been argued though that in applications a computationallygrounded semantics (Wooldridge, 2000a) is preferable, as this enables systems to be modelled directly. We introduced quantified interpreted systems (QIS) to fill this gap (Belar2

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

dinelli & Lomuscio, 2009). This enabled us to provide a complete axiomatisation of the
monodic fragment of quantified temporal-epistemic logic on linear time (Belardinelli & Lomuscio, 2011). However, no interaction between temporal and epistemic modalities was
studied. Preliminary investigations into the interactions between temporal and epistemic
operators in a first-order setting have already appeared (Belardinelli & Lomuscio, 2010). In
this paper we extend the previous results and also consider epistemic languages containing
the common knowledge operator.
1.2 The Present Contribution
This paper extends the current state of the art in first-order temporal-epistemic logic by
introducing a family of provably complete calculi for a variety of quantified interpreted systems characterising a range of properties including perfect recall, no learning, synchronicity,
and having a unique initial state. We prove the completeness of the presented first-order
temporal-epistemic logics via a quasimodel construction, which has previously been used
(Hodkinson, Wolter, & Zakharyaschev, 2002; Hodkinson et al., 2000) to prove decidability
for monodic fragments of first-order temporal logic (FoTL). Quasimodels have also been
applied to first-order temporal as well as epistemic logic (Sturm et al., 2000; Wolter & Zakharyaschev, 2002). Wolter et al. (2002) present a complete axiomatisation for the monodic
fragment of FoTL on the natural numbers; a similar result for a variety of first-order epistemic logics with common knowledge has also appeared (Sturm et al., 2000). However, the
interaction between temporal and epistemic modalities in a first order setting has not been
taken into account yet, nor has the interpreted systems semantics. Nonetheless, both of
these features are essential for applications to multi-agent systems and are the subject of
analysis here.
1.2.1 Structure of the Paper.
In Section 2 we first introduce the first-order temporal-epistemic languages Lm and LCm
with common knowledge for a set Ag = {1, . . . , m} of agents. We then present the relevant
classes of QIS as well as the monodic fragments of Lm and LCm . In Sections 3 we introduce
the axiomatisations for these classes of QIS, while the details of the completeness proofs
are presented in Sections 4 and 5. Finally, in Section 6 we elaborate on the results obtained
and discuss possible extensions and future work.

2. First-Order Temporal-Epistemic Logics
Interpreted systems are a standard semantics for interpreting temporal-epistemic logics in a
multi-agent setting (Fagin et al., 1995; Parikh & Ramanujam, 1985). We extend interpreted
systems to the first-order case by enriching these structures with a domain of individuals.
We first investigated static quantified interpreted systems, where no account for the
evolution of the system is given (Belardinelli & Lomuscio, 2008, 2009). Then, fully-fledged
QIS on a language with also temporal modalities were introduced (Belardinelli & Lomuscio,
2010, 2011). We follow the definition of QIS provided in the references.
3

fiBelardinelli & Lomuscio

2.1 First-Order Temporal-Epistemic Languages
Given a set Ag = {1, . . . , m} of agents, the first-order temporal-epistemic language Lm
contains individual variables x1 , x2 , . . ., individual constants c1 , c2 , . . ., n-ary predicate constants P1n , P2n , . . ., for n  N, the propositional connectives  and , the quantifier , the
linear time operators  and U, and the epistemic operator Ki for each agent i  Ag. The
language LCm also contains the common knowledge operator C (Fagin et al., 1992). For
simplicity we consider only one group of agents for the common knowledge modality, that
is, the whole of Ag; C is really tantamount to CAg . The extension to proper non-empty
subsets of Ag is not problematic.
The languages Lm and LCm contain no symbol for functions; so all terms t1 , t2 , . . . in
these languages are either individual variables or constants.
Definition 1. Formulas in Lm are defined in the Backus-Naur form as follows:
 ::= P k (t1 , . . . , tk ) |  |    0 | x |  | U 0 | Ki 
The language LCm extends Lm with the following clause:
 if  is a formula in LCm , then also C is a formula in LCm .
The formulas  and U0 are read as at the next step  and eventually 0 and until
then  respectively. The formula Ki  represents agent i knows , while C stands for
 is common knowledge in the set Ag of agents.
We define the symbols , , , , G (always in the future), F (some time in the future)
as standard. Further, we introduce some abbreviations. The V
operator Ki is dual to Ki ,
that is, Ki  is defined as Ki , while E is a shorthand for iAg Ki . For k  N, E k 
is defined as follows: E 0  =  and E k+1  = EE k . The formulas Ki  and E are read as
agent i considers  possible and every agent knows  respectively.
Free and bound variables are defined as standard. By [~y ] we mean that ~y = y1 , . . . , yn
are all the free variables in . Additionally, [~y /~t] is the formula obtained by substituting simultaneously some, possibly all, free occurrences of ~y in  with ~t = t1 , . . . , tn while
renaming bound variables. A sentence is a formula with no free variables.
2.2 Quantified Interpreted Systems
To introduce quantified interpreted systems we assume a set Li of local states li , li0 , . . . for
each agent i  Ag in a multi-agent system. We consider a set Le of local states for the
environment e as well. The set S  Le L1 . . .Lm contains all and only the global states
of the multi-agent system. To represent the temporal evolution of the MAS we consider
the flow of time N of natural numbers; a run is a function r : N  S. Intuitively, a run
represents one possible evolution of the MAS assuming N as the flow of time. Given the
above, we define quantified interpreted systems for the languages Lm and LCm as follows:
Definition 2 (QIS). A quantified interpreted system is a triple P = hR, D, Ii where:
 R is a non-empty set of runs;
 D is a non-empty set of individuals;
4

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

 for r  R, n  N, I is a first-order interpretation, that is, a function such that
 for every constant c, I(c, r(n))  D,
 for every predicate constant P k , I(P k , r(n)) is a k-ary relation on D.
Further, for every r, r0  R, n, n0  N, I(c, r(n)) = I(c, r0 (n0 )).
Notice that we assume a unique domain of interpretation, as well as a fixed interpretation
for individual constants; so we simply write I(c). Following standard notation (Fagin et al.,
1995), for r  R and n  N, a pair (r, n) is a point in P. If r(n) = hle , l1 , . . . , lm i is the
global state at point (r, n) then re (n) = le and ri (n) = li are the environments and agent
is local state at (r, n) respectively. Further, for i  Ag the epistemic equivalence relation
i is defined such that (r, n) i (r0 , n0 ) iff ri (n) = ri0 (n0 ). Clearly, each i is an equivalence
relation. Two points (r, n) and (r0 , n0 ) are said to be epistemically
reachable, or simply
S
reachable, if (r, n)  (r0 , n0 ) where  is the transitive closure of iAg i .
In this paper we consider the following classes of QIS.
Definition 3. A quantified interpreted system P satisfies
synchronicity

iff

for every i  Ag, for all points (r, n), (r0 , n0 ),
(r, n) i (r0 , n0 ) implies n = n0

perfect recall for agent i

iff

for all points (r, n), (r0 , n0 ), if (r, n) i (r0 , n0 ) and n > 0
then either (r, n  1) i (r0 , n0 ) or
there is k < n0 such that (r, n  1) i (r0 , k) and
for all k 0 , k < k 0  n0 implies (r, n) i (r0 , k 0 )

no learning for agent i

iff

for all points (r, n), (r0 , n0 ), if (r, n) i (r0 , n0 )
then either (r, n + 1) i (r0 , n0 ) or
there is k > n0 such that (r, n + 1) i (r0 , k) and
for all k 0 , k > k 0  n0 implies (r, n) i (r0 , k 0 )

unique initial state

iff

for all r, r0  R, r(0) = r0 (0)

These conditions have extensively been discussed in the literature (Halpern et al., 2004)
together with equivalent formulations. Intuitively, a QIS is synchronous if time is part of
the local state of each agent. A QIS satisfies perfect recall for agent i if is local state records
everything that has happened to him (from the agents point of view) so far in the run. No
learning is dual to perfect recall: agent i does not acquire any new knowledge during a run.
Finally, a QIS has a unique initial state if all runs start from the same global state.
A QIS P satisfies perfect recall (resp. no learning) if P satisfies perfect recall (resp. no
learning) for all agents. We denote the class of QIS with m agents as QIS m ; the superscripts
pr, nl, sync, uis denote the subclasses of QIS m satisfying perfect recall, no learning,
synchronicity, and having a unique initial state respectively. For instance, QIS sync,uis
is
m
the class of all synchronous QIS with m agents and having a unique initial state.
We now assign an interpretation to the formulas in Lm and LCm by means of quantified
interpreted systems. Let  be an assignment from variables to individuals in D, the valuation
5

fiBelardinelli & Lomuscio

I  (t) of a term t is defined as (y) for t = y, and I  (t) = I(c) for t = c. A variant ax of an
assignment  assigns a  D to x and agrees with  on all other variables.
Definition 4. The satisfaction of a formula   Lm at point (r, n)  P under an assignment
, denoted (P  , r, n) |= , is defined inductively as follows:
(P  , r, n) |= P k (t1 , . . . , tk )
(P  , r, n) |= 
(P  , r, n) |=    0
(P  , r, n) |= x
(P  , r, n) |= 
(P  , r, n) |= U 0

iff
iff
iff
iff
iff
iff

(P  , r, n) |= Ki 

iff

hI  (t1 ), . . . , I  (tk )i  I(P k , r(n))
(P  , r, n) 6|= 
(P  , r, n) 6|=  or (P  , r, n) |=  0
x
for all a  D, (P a , r, n) |= 
(P  , r, n + 1) |= 
there is n0  n such that (P  , r, n0 ) |=  0
and (P  , r, n00 ) |=  for all n  n00 < n0
for all r0 , n0 , (r, n) i (r0 , n0 ) implies (P  , r0 , n0 ) |= 

For   LCm we have to consider also the case for the common knowledge operator:
(P  , r, n) |= C

iff

for all k  N, (P  , r, n) |= E k 

The truth conditions for , , , , G and F are defined from those above. From
the definition above it follows that (P  , r, n) |= C iff for all (r0 , n0 ) reachable from (r, n),
(P  , r0 , n0 ) |= .
A formula  is true at a point (r, n) if it is satisfied at (r, n) by every assignment ;  is
true on a QIS P if it is true at every point in P;  is valid on a class C of QIS if it is true
on every QIS in C. Further, a formula  is satisfiable on a QIS P if it is satisfied at some
point in P, for some assignment ;  is satisfiable on a class C of QIS if it is satisfiable on
some QIS in C.
By considering all combinations of pr, nl, sync and uis we obtain 16 subclasses of QIS m
for any m  N. Not all of them are independent, nor axiomatisable. Indeed, some of these
are not axiomatisable even at the propositional level (Halpern & Moses, 1992; Halpern &
Vardi, 1989). In the first column of Table 1 we group together the classes of QIS that share
the same set of validities on the languages Lm and LCm . The proofs of these equivalences
are similar to those of the propositional case (Halpern et al., 2004) and are not reported
here. Further, we define the languages PLm and PLCm as the propositional fragments of
Lm and LCm respectively (formally, PLm and PLCm are obtained by restricting atomic
formulas to 0-ary predicate constants p1 , p2 , . . .). Table 1 summarises the results by Halpern
et al. (2004) concerning the axiomatisability of propositional validities in PLm and PLCm .
Observe that, as regards the language PLm , for m = 1 all sets of validities on the various
classes of QIS are axiomatisable, while for m  2 no axiomatisation can be given for
QIS nl,uis
and QIS nl,pr,uis
(Halpern & Vardi, 1986, 1989). As to the language PLCm , we
m
m
restrict to the case for m  2, as for m = 1 PLCm has the same expressive power as
PLm . For m  2 no class of validities on PLCm has a recursive axiomatisation but QIS m ,
uis
sync,uis
and QIS nl,sync,uis
, QIS nl,pr,sync,uis
.
QIS sync
m
m
m , QIS m , QIS m
In the next section we show that the axiomatisability results at the propositional level
can be lifted to the monodic fragment of the languages Lm and LCm .
6

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

QIS
sync,uis
QIS m , QIS sync
,
QIS uis
m
m , QIS m
pr,uis
QIS pr
m , QIS m
pr,sync
QIS m
, QIS pr,sync,uis
m
nl
QIS m
QIS nl,sync
m
QIS nl,pr
m
QIS nl,pr,sync
m
QIS nl,uis
m
QIS nl,pr,uis
m
QIS nl,sync,uis
, QIS nl,pr,sync,uis
m
m

PL1
X
X
X
X
X
X
X
X
X
X

PLm , m  2
X
X
X
X
X
X
X
7
7
X

PLCm , m  2
X
7
7
7
7
7
7
7
7
X

Table 1: Equivalences between classes of QIS and axiomatisability results for the propositional fragments PLm and PLCm . The sign X indicates that the set of validities
on a specific class is axiomatisable; while 7 indicates that it is not.

2.3 The Monodic Fragment
In the rest of the paper we will show that a sufficient condition for lifting the results in
Table 1 to the first-order case is to restrict the languages Lm and LCm to their monodic
fragments.
Definition 5. The monodic fragment L1m is the set of formulas   Lm such that any subformula of  of the form Ki , , or 1 U2 contains at most one free variable. Similarly,
1 is the set of formulas   LC
the monodic fragment LCm
m such that any subformula of 
of the form Ki , C, , or 1 U2 contains at most one free variable.
The monodic fragments of a number of first-order modal logics have been thoroughly
investigated in the literature (Hodkinson et al., 2000, 2003; Wolter & Zakharyaschev, 2001,
2002). In the case of Lm and LCm these fragments are quite expressive as they contain
formulas like the following:
y C(zAvailable(y, z)UxRequest(x, y))

(1)

Ki  xyz(Request(x, y)  Available(y, z)) 
 Ki xyz(Request(x, y)  Available(y, z))

(2)

Formula (1) intuitively states that it is common knowledge that every resource y will
eventually be requested by somebody, but until that time the resource remains available to
everybody. Notice that y is the only free variable within the scope of modal operators U
and C. Formula (2) represents that if agent i knows that at the next step every resource is
available whenever it is requested, then at the next step agent i knows that this is indeed
the case. However, note that the formula
xKi (Process(x)  yF Access(x, y))
7

fiBelardinelli & Lomuscio

which intuitively means that agent i knows that every process will eventually try to access
every resource, is not in L1m as both x and y occur free within the scope of modal operator
F . Still, the monodic fragments of Lm and LCm are quite expressive as they contain all
de dicto formulas, i.e., formulas where no free variable appears in the scope of any modal
operator, as in (2). So, the limitation is really only on de re formulas.
We stress the fact that the formulas above have no propositional equivalent in the
case that they are interepreted on quantified interpreted systems in which the domain of
quantification is infinite, or its cardinality cannot be bounded in advance.
Finally, observe that the Barcan formulas x  x   and Ki x  xKi 
are both true in all quantified interpreted systems, as each QIS includes a unique domain
of quantification. This implies that the universal quantifier commutes with the temporal
modality  and the epistemic modality Ki . Thus, it can be the case that for some formulas
,  0  Lm , we have that    0 is a validity, but   L1m and  0 
/ L1m . For instance,
consider  = xP (x, y) and  0 = x  P (x, y). We will see that this remark does not
interfere with our results.

3. Axiomatisations
In this section we present sound and complete axiomatisations of the sets of monodic validities for the classes of quantified interpreted systems in Section 2. First, we introduce
the basic system QKTm that extends to the first-order case the multi-modal epistemic logic
S5m combined with the linear temporal logic LTL.
Definition 6. The system QKTm contains the following schemes of axioms and rules,
where ,  and  are formulas in L1m and = is the inference relation.
First-order logic

Temporal logic

Epistemic logic

Taut
MP
Ex
Gen
K
T1
T2
Nec
T3
K
T
4
5
Nec

classical propositional tautologies
  ,  = 
x  [x/t]
  [x/t] =   x, where x is not free in 
(  )  (  )
    
U    (  (U))
 = 
     =   (U)
Ki (  )  (Ki   Ki )
Ki   
Ki   Ki Ki 
Ki   Ki Ki 
 = Ki 

The operator Ki is an S5 modality, while the next  and until U operators are axiomatised as linear-time modalities (Fagin et al., 1995). To this we add the classical postulates
Ex and Gen for quantification, which are both sound as we consider a unique domain of
individuals in the quantified interpreted systems.
8

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Definition 7. The system QKT Cm extends QKTm with the following schemes of axioms
1 and = is the inference
for common knowledge, where ,  and  are formulas in LCm
relation.
C1
C2

C  (  EC)
  (  E) =   C

We consider the standard definitions of proof and theorem; `S  means that the formula
 is a theorem in the formal system S. We remark that the Barcan formula (BF ) 2x 
x2 is provable for any unary modal operator 2 by the axioms K and Ex, and the rules
M P and Gen. The notions of soundness and completeness of a system S with respect to a
class C of QIS are defined as standard: S is sound w.r.t. C if for all , S `  implies C |= .
Similarly, S is complete w.r.t. C if for all , C |=  implies S ` .
In this paper we focus on the schemes of axioms in Table 2 that specify key interactions
between time and knowledge (Halpern et al., 2004). We use 1, . . . , 5 as superscripts to denote
KT1
KT2
KT3
KT4
KT5

Ki   (Ki   Ki )  Ki ((Ki )U((Ki )U))
Ki    Ki 
(Ki )UKi   Ki ((Ki )UKi )
Ki   Ki  
Ki   Kj 
Table 2: the axioms KT1-KT5.

the systems obtained by adding to QKTm or QKTCm any combination of KT1-KT5. For
instance, the system QKTC2,3
m extends QKTCm with the axioms KT2 and KT3.
It is straightforward to check that the axioms of QKTm and QKTCm are valid on every
QIS and the inference rules preserve validity. However, the axioms KT1-KT5 are valid only
on specific classes of QIS as stated in the following Remark.
Remark 1. A QIS P satisfies any of the axioms KT1-KT5 in the first column if P satisfies
the corresponding semantical condition in the second column.
Axiom
KT1
KT2
KT3
KT4
KT5

Condition on QIS
perfect recall
perfect recall, synchronicity
no learning
no learning, synchronicity
all agents share the same knowledge, i.e.,
for all i, j  Ag, (r, n) i (r0 , n0 ) iff (r, n) j (r0 , n0 ).

These results can be shown in a similar way to the propositional case (Halpern et al.,
2004); so the proofs are omitted.
By using Remark 1 we can prove soundness results for all our first-order temporalepistemic systems.
Theorem 1 (Soundness). The systems reported in the first and second column of the following table are sound w.r.t. the corresponding classes of QIS in the third column.
9

fiBelardinelli & Lomuscio

Systems
QKTm
QKT Cm
1
1
QKTm
QKT Cm
2
2
QKTm
QKT Cm
3
3
QKTm
QKT Cm
4
4
QKTm
QKT Cm
2,3
2,3
QKTm
QKT Cm
1,4
1,4
QKTm
QKT Cm
1,4,5
1,4,5
QKTm
QKT Cm

QIS
sync,uis
QIS m , QIS sync
,
QIS uis
m
m , QIS m
pr,uis
QIS pr
m , QIS m
pr,sync
QIS m
, QIS pr,sync,uis
m
nl
QIS m , QIS nl,uis
m
QIS nl,sync
m
nl,pr,uis
QIS nl,pr
m , QIS m
nl,pr,sync
QIS m
QIS nl,sync,uis
, QIS nl,pr,sync,uis
m
m

Proof. These results follow from Remark 1 by a line of reasoning similar to that used in
the propositional case (Fagin et al., 1995; Halpern et al., 2004). Notice that if a quantified
interpreted systems P satisfies no learning, synchronicity, and has a unique initial state,
then P satisfies also perfect recall, that is, P  QIS nl,sync,uis
implies P  QIS nl,pr,sync,uis
.
m
m
Further, all agents share the same knowledge, therefore KT5 holds in P.
As we anticipated above, not all calculi are complete w.r.t. the corresponding classes
of quantified interpreted systems in Theorem 1. In the next theorem we summarise the
completeness results that will be proved in the rest of this paper.
Theorem 2 (Completeness). The systems reported in the first and second column of the
following table are complete w.r.t. the corresponding classes of QIS in the third column.
Systems
QKTm
QKT Cm
1
QKTm
2
QKTm
3
QKTm
4
QKTm
2,3
QKTm
1,4
QKTm
QKT12,3
1,4,5
1,4,5
QKTm
QKT Cm

QIS
sync,uis
uis
QIS m , QIS sync
m , QIS m , QIS m
pr
pr,uis
QIS m , QIS m
QIS pr,sync
, QIS pr,sync,uis
m
m
nl
QIS m
QIS nl,sync
m
QIS nl,pr
m
QIS nl,pr,sync
m
QIS nl,uis
, QIS nl,pr,uis
1
1
nl,pr,sync,uis
QIS nl,sync,uis
,
QIS
m
m

We observe that, as regards the language L1m , the sets of monodic validities are axiomatisable for all classes introduced but QIS nl,uis
and QIS nl,pr,uis
. However, for L11 we
m
m
have that QIS nl,uis
and QIS nl,pr,uis
are equivalent to QIS nl,pr
. Thus, the sets of monodic
1
1
1
nl,pr,uis
nl,uis
validities on QIS 1
and QIS 1
are axiomatised by QKT2,3
1 .
1
As regards the language LCm , only the set of monodic validities on QIS m , QIS sync
m ,
sync,uis
nl,sync,uis
nl,pr,sync,uis
QIS uis
,
QIS
are
axiomatisable,
as
well
as
those
on
QIS
and
QIS
.
m
m
m
m
All other classes are not recursively axiomatisable, as this is the case already at the propositional level (Halpern & Moses, 1992; Halpern & Vardi, 1986, 1989).
For proving the completeness results reported above we introduce Kripke models as a
generalisation of quantified interpreted systems.
10

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

3.1 Kripke Models
To prove the completeness results in Theorem 2, we first introduce an appropriate class of
Kripke models as a generalisation of QIS and prove completeness for these models. Then
we apply a correspondence result between Kripke models and QIS to obtain the desired
results.
Definition 8 (Kripke model). A Kripke model is a tuple M = hW, RW , {i }iAg , D, Ii
such that
 W is a non-empty set of states;
 RW is a non-empty set of functions r : N  W ;
 for every agent i  Ag, i is an equivalence relation on W ;
 D is a non-empty set of individuals;
 for every w  W , I is a first-order interpretation, that is, a function such that
 for every constant c, I(c, w)  D,
 for every predicate constant P k , I(P k , w) is a k-ary relation on D.
Further, for every w, w0  W , I(c, w) = I(c, w0 ).
Notice that Def. 8 differs from other notions of Kripke model in that it includes the
set RW of functions to guarantee that the correspondence between Kripke models and
QIS is one-to-one. We also assume a unique domain of interpretation, as well as a fixed
interpretation for individual constants, so also in this case we simply write I(c). Kripke
models are a generalisation of QIS in that they do not specify the inner structure of the states
in W . Also for Kripke models we introduce points as pairs (r, n) for r  RW and n  N.
A point derives its properties from the corresponding state; for instance, (r, n) i (r0 , n0 ) if
r(n) i r0 (n0 ).
We consider Kripke models satisfying synchronicity, perfect recall, no learning, and
having a unique initial state. The definition of these subclasses is analogous to Def. 3.
Definition 9. A Kripke model M satisfies
synchronicity

iff

for every i  Ag, for all points (r, n), (r0 , n0 ),
(r, n) i (r0 , n0 ) implies n = n0

perfect recall for agent i

iff

for all points (r, n), (r0 , n0 ), if (r, n) i (r0 , n0 ) and n > 0
then either (r, n  1) i (r0 , n0 ) or
there is k < n0 such that (r, n  1) i (r0 , k) and
for all k 0 , k < k 0  n0 implies (r, n) i (r0 , k 0 ).

no learning for agent i

iff

for all points (r, n), (r0 , n0 ), if (r, n) i (r0 , n0 )
then either (r, n + 1) i (r0 , n0 ) or
there is k > n0 such that (r, n + 1) i (r0 , k) and
for all k 0 , k > k 0  n0 implies (r, n) i (r0 , k 0 ).

unique initial state

iff

for all r, r0  RW , r(0) = r0 (0).
11

fiBelardinelli & Lomuscio

Now let Km be the class of Kripke models with m agents. Hereafter we adopt the same
sync,uis
naming conventions as for QIS; for instance, Km
is the class of synchronous Kripke
models with m agents and having a unique initial state. Further, the inductive clauses for
the satisfaction relation |= with respect to an assignment  are straightforwardly defined
from those for QIS, as well as the notions of truth and validity.
Definition 10. The satisfaction of a formula   Lm (resp. LCm ) at point (r, n)  M for
an assignment , or (M , r, n) |= , is inductively defined as follows:
(M , r, n) |= P k (t1 , . . . , tk )
(M , r, n) |= 
(M , r, n) |=    0
(M , r, n) |= x
(M , r, n) |= 
(M , r, n) |= U 0

iff
iff
iff
iff
iff
iff

(M , r, n) |= Ki 
(M , r, n) |= C

iff
iff

hI  (t1 ), . . . , I  (tk )i  I(P k , r(n))
(M , r, n) 6|= 
(M , r, n) 6|=  or (M , r, n) |=  0
x
for all a  D, (Ma , r, n) |= 
(M , r, n + 1) |= 
there is n0  n such that (M , r, n0 ) |=  0
and n  n00 < n0 implies (M , r, n00 ) |= 
for all r0 , n0 , (r, n) i (r0 , n0 ) implies (M , r0 , n0 ) |= 
for all k  N, (M , r, n) |= E k 

A formula  is true at a point (r, n) if it is satisfied at (r, n) by every assignment ; 
is true on a Kripke model M if it is true at every point in M;  is valid on a class C of
Kripke models if it is true on every Kripke model in C. Further, a formula  is satisfiable
on a Kripke model M if it is satisfied at some point in M, for some assignment ;  is
satisfiable on a class C of Kripke models if it is satisfiable on some Kripke model in C.
We relate Kripke models and quantified interpreted systems by means of a map g :
Km  QIS m (Lomuscio & Ryan, 1998). Let M = hW, RW , {i }iAg , D, Ii be a Kripke
model. For every agent i  Ag, for (r, n)  M, let the equivalence class [(r, n)]i = {(r0 , n0 ) |
(r, n) i (r0 , n0 )} be a local state for agent i; while each (r, n) is a local state for the
environment. Then define g(M) as the tuple hR0 , D, I 0 i where R0 contains the runs rr for
r  RW such that rr (n) = h(r, n), [(r, n)]1 , . . . , [(r, n)]m i. Further, D is the same as in M,
and for every constant c, I 0 (c, rr (n)) = I(c, r(n)), and I 0 (P k , rr (n)) = I(P k , r(n)). The
structure g(M) is a QIS that satisfies the following result:
Lemma 1. For every  in Lm (resp. LCm ),
(M , r, n) |=  iff (g(M) , rr , n) |= 
Proof. The proof is by induction on the structure of . If  is an atomic formula P k (t1 , . . . , tk ), then (M , r, n) |=  iff hI  (t1 ), . . . , I  (tk )i  I(P k , r(n)), iff we have
hI 0 (t1 ), . . . , I 0 (tk )i  I 0 (P k , rr (n)), iff (g(M) , rr , n) |= . The inductive cases for the
propositional connectives and quantifiers are straightforward, as well as those for the temporal operators  and U. As to  = Ki , we have that (M , r, n) |=  iff (r, n) i (r0 , n0 )
0
implies (M , r0 , n0 ) |= , but (r, n) i (r0 , n0 ) iff rri (n) = rri (n0 ). Thus, (M , r, n) |=  iff
0
(rr , n) 0i (rr , n0 ) implies (M , r0 , n0 ) |= . Again, by the induction hypothesis (M , r, n) |=
0
0
 iff (rr , n) 0i (rr , n0 ) implies (g(M) , rr , n0 ) |= , i.e., iff (g(M) , rr , n) |= . The case
for  = C is treated similarly by considering the epistemic reachability relation.

12

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Notice that if M satisfies synchronicity, or perfect recall, or no learning, or has a unique
initial state, then also g(M) satisfies the same property. This follows from the fact that
0
(r, n) i (r0 , n0 ) iff (rri , n) 0i (rr , n0 ). Thus, g defines a map from each of the 16 subclasses
of Km outlined in Def. 9 to the corresponding subclass of QIS m and we obtain the following
corollary to Lemma 1.
Corollary 1. Let X be any subset of {pr, nl, sync, uis}. For every monodic formula   L1m
1 ), if  is satisfiable in KX , then  is satisfiable in QIS X .
(resp. LCm
m
m
For reasoning about the monodic fragments of Lm and LCm when we are dealing with no
learning and perfect recall, we introduce the following class of monodic friendly Kripke
models. These structures are motivated by the fact that KT1 and KT3 are too weak
to enforce either perfect recall or no learning on Kripke models when these axioms are
restricted to monodic formulas. However, they suffice for monodic friendly structures. In
the following, we also prove that satisfiability in Kripke models is equivalent to satisfability
in monodic friendly structures when we restrict our languages to monodic formulas.
Definition 11 (mf-model). A monodic friendly
Mmf = hW, RW , {i,a }iAg,aD , D, Ii such that

Kripke

model

is

a

tuple

 W , RW , D and I are defined as for Kripke models;
 for i  Ag, a  D, i,a is an equivalence relation on W .
We can define synchronicity, perfect recall, no learning, and having a unique initial state
also for mf-models by parametrising Def. 9 to each relation i,a . For instance, an mf-model
satisfies perfect recall for agent i if for all points (r, n), (r0 , n0 ), for all a  D, whenever
(r, n) i,a (r0 , n0 ) and n > 0 then either (r, n  1) i,a (r0 , n0 ) or there is k < n0 such that
(r, n  1) i,a (r0 , k) and for all k 0 , k < k 0  n0 implies (r, n) i,a (r0 , k 0 ). As regards the
subclasses of the class MF m of all mf-models with m agents, we adopt the same naming
conventions as for QIS and Kripke models. Notice that Kripke models can be seen as
mf-models such that for all i  Ag, a, b  D, i,a is equal to i,b .
1 ) in a mf-model M
Finally, the satisfaction relation |= for   L1m (resp. LCm
mf is
defined in the same way as in Kripke models, except for the epistemic operators:
(Mmf , r, n) |= Ki [y]

iff

for all r0 , n0 , (r, n) i,(y) (r0 , n0 ) implies (Mmf , r0 , n0 ) |= [y]

where at most y appears free in . Notice that if  is a sentence, then (Mmf , r, n) |= Ki 
iff (r, n) i,a (r0 , n0 ) implies (Mmf , r0 , n0 ) |=  for all a  D. The case for the common
knowledge operator C is straightforward by definition of E k . In particular, two points (r, n)
0 0
and (r0 , n0 ) are epistemically reachable
S for a  D, or simply reachable, if (r, n) a (r , n ),
where a is the transitive closure of iAg i,a .
We remark that the converse of the Barcan formula, or CBF , Ki x  xKi  holds
in all mf-models; while the Barcan formula, or BF , xKi   Ki x does not. To check
this consider the mf-model M = hW, RW , {i,a }iAg,aD , D, Ii in Fig.1(a) such that
- W = {w, w0 , w00 }
- RW = {r, r0 , r00 } and r(0) = w, r0 (0) = w0 , and r00 (0) = w00
13

fiBelardinelli & Lomuscio

..
.

..
.

..
.

..
.

i,b

i,a

..
.

..
.
i,d

i,c

w0

w

w00

v0

v

P (a)

P (a), P (b)

P (b)

Q(c)

Q(c)

v 00

(b) The mf-model M0 .

(a) The mf-model M.

Figure 1: Arrows represent the system runs; while epistemically related states are grouped
together.

- D = {a, b}
- I(P 1 , r(0)) = {a, b}, I(P 1 , r0 (0)) = {a} and I(P 1 , r00 (0)) = {b}
- i,a and i,b are equivalence relations such that (r, 0) i,a (r0 , 0) and (r, 0) i,b (r00 , 0).
We can see that (M, r, 0) |= xKi P (x), but (M, r, 0) 6|= Ki xP (x) as (r, 0) i,a (r0 , 0) and
(M , r0 , 0) 6|= P (x) for (x) = b.
Furthermore, the K axiom Ki (   0 )  (Ki   Ki  0 ) is not valid on mf-models
either. In fact, consider the mf-model M0 = hW 0 , R0W 0 , {0i,a }iAg,aD0 , D0 , I 0 i in Fig.1(b)
such that
- W 0 = {v, v 0 , v 00 }
- R0W 0 = {q, q 0 , q 00 } and q(0) = v, q 0 (0) = v 0 , and q 00 (0) = v 00
- D0 = {c, d}
- I 0 (Q1 , q(0)) = {c}, I 0 (Q1 , q 0 (0)) = {c} and I 0 (Q1 , q 00 (0)) = 
- i,c and i,d are equivalence relations such that (q, 0) i,c (q 0 , 0) and (q, 0) i,d (q 00 , 0).
Finally, let (x) = c. We can check that (M , q, 0) |= (Q(x)  xQ(x))  Q(x) and
(M , q 0 , 0) |= (Q(x)  xQ(x))  Q(x). Thus, (M , q, 0) |= Ki (Q(x)  xQ(x))  Ki Q(x).
But (M, q 00 , 0) 6|= xQ(x), so (M , q, 0) 6|= Ki xQ(x).
We now prove the following lemma, which will be used in the completeness proof for
systems satisfying perfect recall or no learning. The lemma states that, when we deal with
satisfability of monodic formulas, mf-models suffice.
Lemma 2. Let MF K,BF
be the class of all mf-models validating the formulas K and BF .
m
1 ),
For every monodic formula   L1m (resp. LCm
Km |=  iff MF K,BF
|= 
m
14

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Proof. The implication from right to left follows from the fact that the class Km of all
Kripke models is isomorphic to the subclass of monodic friendly Kripke models such that
for all i  Ag, a, b  D, i,a is equal to i,b . In other words, given a Kripke model M =
hW, RW , {i }iAg , D, Ii we can define the mf-model M0 = hW, RW , {i,a }iAg,aD , D, Ii,
where for every a  D, i,a is equal to i . It is straightforward to see that M0 validates
both K and BF (in particular, the counterexamples in Fig. 1 are ruled out). Further, if
M 6|=  then M0 6|= . Thus, if MF K,BF
|= , then Km |= .
m
For the implication from left to right, assume that Mmf = hW, RW ,
{i,a }iAg,aD , D, Ii is an mf-model validating K and BF such that (Mmf , r, n) 6|= 
for some point (r, n) and some assignment . We can then build a Kripke model M0 =
hW 0 , R0W 0 , {0i }iAg , D0 , I 0 i from Mmf such that (M0 , r, n) 6|=  as follows. We start by
assuming W 0 = W , SR0 = R and D0 = D. Further, for each i  Ag, define 0i as the
transitive closure of aD i,a . Finally, set I 0 = I. We now have to check that the Kripke
model M0 is well defined and does not validate .
First of all, we point out the following issue associated with the construction above: it
can be the case that for some point (q, k) and some monodic formula [x], it happens that
(Mmf , q, k) |= Ki [x], (q, k) i,(x) (q 0 , k 0 ) and (q, k) i,(y) (q 00 , k 00 ) for some (x) 6= (y).
Further, suppose that (Mmf , q 00 , k 00 ) 6|= [x], while we obviously have that (Mmf , q 0 , k 0 ) |=
[x]. Now by the definition of 0i we have that (M0 , q, k) 6|= Ki [x]; so the two models do
not satisfy the same formulas. We can solve this problem by modifying the interpretation I
according to the structure of the monodic formula [x], while keeping the same truth value
for [x] at point (q, k). We consider the relevant cases according to the structure of [x];
the induction hypothesis consists of the fact that we are able to find such an interpretation
I for all subformulas of [x].
For [x] = P (x) we simply assume that (x)  I(P, q 00 (k 00 )), so that (M0 , q 00 , k 00 ) |=
[x] and (M0 , q, k) |= Ki [x]. Note that this does not change the truth value of any
epistemic formula in (q, k) as we assumed that (q, k) 6i,(x) (q 00 , k 00 ) (otherwise [x] would
be satisfied in (q 00 , k 00 )). The cases for propositional connectives and modal operators are
similarly dealt with by applying the induction hypothesis. For [x] = y[x, y] we have
y

b
, q 00 , k 00 ) 6|= [x, y].
that (Mmf , q 00 , k 00 ) 6|= [x], therefore there exists b  D such that (Mmf
Now we have to consider 4 different cases depending on whether (q, k) satisfies any of these
4 formulas:

Ki x [x, y]

(3)

Ki x [x, y]

(4)

Ki x [x, y]

(5)

Ki x [x, y]

(6)

By using the axioms and inference rules in QKTm for Formula (3) we can show what
follows (where  is used for entailment):
(Mmf , q, k) |= Ki y[x, y]  Ki x[x, y] 
 (Mmf , q, k) |= xKi y[x, y]  yKi x[x, y] by Ex
 (Mmf , q, k) |= Ki xy[x, y]  Ki yx[x, y] by zKi   Ki z
 (Mmf , q, k) |= Ki (xy[x, y]  yx[x, y]) by Ki (  )  Ki   Ki 
15

fiBelardinelli & Lomuscio

 (Mmf , q, k) |= Ki (xu[x, u]  yv[v, y])
 (Mmf , q, k) |= Ki xyuv([x, u]  [v, y])
 (Mmf , q, k) |= Ki xy([x, y]  [x, y])

by change of variables
by prefixing
by Ex

but the last formula is a contradiction; so (3) cannot hold in (q, k). Similarly, Formula
(4) cannot hold in (q, k) either because:
(Mmf , q, k) |= Ki y[x, y]  Ki x[x, y]
 (Mmf , q, k) |= xKi y[x, y]  y Ki x[x, y]
 (Mmf , q, k) |= Ki xy[x, y]  y Ki x[x, y]
 (Mmf , q, k) |= Ki xy[x, y]  Ki yx[x, y]
 (Mmf , q, k) |= Ki (xy[x, y]  yx[x, y])
 (Mmf , q, k) |= Ki xy([x, y]  [x, y])

by Ex
by zKi   Ki z
by z Ki   Ki z
by Ki   Ki   Ki (  )
similarly to above

Note that in both derivations we make use of the formulas K and BF (for instance, to
prove the theorems Ki (  )  Ki   Ki  and zKi   Ki z). Finally, to satify the
Formulas (5) and (6) in (q, k), we have to guarantee the existence of an individual x while
avoiding the clash with (x). So, we introduce a new individual a0 in the domain D0 such
that a0 and (x) satisfy the same formulas at all points. Thus, a0 can be seen as a copy
of (x). Finally, by the induction hypothesis we can modify the interpretation I 0 so that
(M0 , q 00 , k 00 ) |= [x, y].
The case for the common knowledge operator derives from the one for Ki . As a result,
we obtain a Kripke model M0 such that (M0 , r, n) 6|= .
Moreover, by the procedure described above, if Mmf satisfies perfect recall, or no learning, or synchronicity, or has unique initial state, then also M0 satisfies the same property.
Thus, by Lemma 2 we can prove the following result.
Corollary 2. Let X be any subset of {pr, nl, sync, uis}. For every monodic formula   L1m
1 ), if  is satisfiable in MF X also validating the formulas K and BF , then  is
(resp. LCm
m
X.
satisfiable in Km
Proof. It is easy to see that if Mmf satisfies either synchronicity or has a unique
initial state, then M0 does as well by the way it is defined. Further, suppose that Mmf
satisfies perfect recall, and (r, n) 0i (r0 , n0 ) for n > 0. This means that there is a sequence
a1 , . . . , ak of individuals in D and a sequence (q1 , m1 ), . . . , (qk , mk ) of points such that (i)
(r, n) = (q1 , m1 ) and (r0 , n0 ) = (qk , mk ); and (ii) (qj , mj ) i,aj (qj+1 , mj+1 ) for j < k. We
show the result for k = 3, the case for k > 3 follows by a straightforward generalisation.
If (q1 , m1  1) i,a1 (q2 , m2 ), then by the definition of 0i we have that (q1 , m1  1) 0i
(q3 , m3 ) as well. Hence, Mmf satisfies perfect recall. Otherwise, suppose that by perfect
recall there is l2 < m2 such that (q1 , m1  1) i,a1 (q2 , l2 ), and for all l20 , l2 < l20  m2
implies (q1 , m1 ) i,a1 (q2 , l20 ). Now consider each l20 (h) = m2  h, for 0  h < m2 
l2 . By perfect recall, either (i) there exists p3 (h) such that (q2 , l20 (h)) i,a2 (q3 , p3 (h)),
and for all p03 (h), p3 (h) < p03 (h)  p3 (h  1) implies (q2 , l2 (h)) i,a2 (q3 , p03 (h)), or (ii)
(q2 , l20 (h)  1) i,a2 (q3 , p3 (h  1)), where p3 (1) = m3 . Notice that in both cases, by
the definition of 0i , we have that (q1 , m1 ) 0i (q3 , p03 (h)) for all 0  h < m2  l2 , that is,
(q1 , m1 ) 0i (q3 , p03 ) for all p3 [l2 + 1] < p03  m3 . Further, for l2 , either (i) there exists l3 such
16

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

that (q2 , l2  1) i,a2 (q3 , l3 ), and for all l30 , l3 < l30  p3 [l2 + 1] implies (q2 , l2 ) i,a2 (q3 , l30 ),
or (ii) (q2 , l2  1) i,a2 (q3 , p3 [l2 + 1]). In the first case, if some l30 is strictly less than
m3 , then there is l30 such that (q1 , m1  1) 0i (q3 , l30 ) and for all l300 , l30 < l300  m3 implies
(q1 , m1 ) 0i (q3 , l300 ). Otherwise, we have that (q1 , m1  1) 0i (q3 , m3 ). Hence, Mmf satisfies
perfect recall.
The proof for no learning is similar.
Finally, by combining Corollaries 1 and 2 we immediately obtain the following result.
Corollary 3. Let X be any subset of {pr, nl, sync, uis}. For every monodic formula   L1m
1 ), if  is satisfiable in MF X also validating the formulas K and BF , then  is
(resp. LCm
m
satisfiable in QIS X
m.
In the next section we show that it is indeed possible to build such an mf-model.

4. The Completeness Proof
In this section we outline the main steps of the completeness proof, which is based on
a quasimodel construction (Gabbay, Kurucz, Wolter, & Zakharyaschev, 2003; Hodkinson
et al., 2000). Differently from these contributions, here we explicitly take into account
the interaction between temporal and epistemic modalities. Intuitively, a quasimodel for
a monodic formula  is a relational structure whose points are sets of sets of subformulas
of . Each set of sets of subformulas describes a possible state of affairs, and contains
sets of subformulas defining the individuals in that state. More formally, given a formula
  LCn1 we define
subC  = sub  {EC | C  sub}  {Ki C | C  sub, i  Ag}
where sub is the set of subformulas of . For   L1n , subC  is simply sub. Further, we
define
subC  = subC   { |   subC }  { |   subC }  { |   subC }
Observe that subC  is closed under negation modulo equivalences    and T 1,
that is, for all   subC , if  is not of the form  then   subC ; otherwise,
  subC . Finally, let subn  be the subset of subC  containing formulas with at most
n free variables. So, sub0  is the set of sentences in subn . If x is a variable not occurring
in , we define subx  = {[y/x] | [y]  sub1 }. Clearly, x is the only free variable in the
formulas in subx . By con we denote the set of all constants occurring in . In Table 3
we report the set suby  for  equal to Formula (1) thus abbreviated:
y C(zAv(y, z)UxReq(x, y))
Further, for k  N we define the closures clk  and clk,i  by mutual recursion.
S
Definition 12. Let cl0  = subx  and for k  0, clk+1  = iAg clk,i . For k  0, i  Ag,
clk,i  = clk   {Ki (1  . . .  n ), Ki (1  . . .  n ) | 1 , . . . , n  clk }.
17

fiBelardinelli & Lomuscio

suby 

{, C(zAv(y, z)UxReq(x, y)), EC(zAv(y, z)UxReq(x, y)),
{Ki C(zAv(y, z)UxReq(x, y))}iAg , zAv(y, z)UxReq(x, y), zAv(y, z), xReq(x, y),
, C(zAv(y, z)UxReq(x, y)), EC(zAv(y, z)UxReq(x, y)),
{Ki C(zAv(y, z)UxReq(x, y))}iAg , zAv(y, z)UxReq(x, y), zAv(y, z),
xReq(x, y),
, C(zAv(y, z)UxReq(x, y)), EC(zAv(y, z)UxReq(x, y)),
{Ki C(zAv(y, z)UxReq(x, y))}iAg , zAv(y, z)UxReq(x, y), zAv(y, z),
xReq(x, y),
, C(zAv(y, z)UxReq(x, y)), EC(zAv(y, z)UxReq(x, y)),
{Ki C(zAv(y, z)UxReq(x, y))}iAg , zAv(y, z)UxReq(x, y), zAv(y, z),
xReq(x, y)}

Table 3: the set suby  for  equal to Formula (1).
t

{, C(zAv(y, z)UxReq(x, y)), EC(zAv(y, z)UxReq(x, y)),
{Ki C(zAv(y, z)UxReq(x, y))}iAg , zAv(y, z)UxReq(x, y), zAv(y, z), xReq(x, y),
, C(zAv(y, z)UxReq(x, y)), EC(zAv(y, z)UxReq(x, y)),
{Ki C(zAv(y, z)UxReq(x, y))}iAg , zAv(y, z)UxReq(x, y), zAv(y, z),
xReq(x, y)}
Table 4: a type t in cl0 , for  equal to Formula (1).

We define ad() as the greatest number of alternations of distinct Ki s along any branch
in s parse tree (Halpern et al., 2004). Further, an index is any finite sequence  = i1 , . . . , ik
of agents such that in 6= in+1 , for 1  n < k; the length of  is denoted by ||. Also, ]i is
the absorptive concatenation of indexes  and i such that ]i =  if ik = i. Finally, K  is a
shorthand for Ki1 . . . Kik . Now let  be an index such that ||  ad(). If  is the empty
sequence  then cl  = clad() . If  = 0 ]i, then cl  = clk,i  for k = ad()  ||. We now
introduce types for quasimodels, which intuitively can be seen as individuals described by
maximal and consistent sets of formulas.
Definition 13 (Type). A -type t for  is any maximal and consistent subset of cl , i.e.,
for every monodic formulas  and  0 in cl ,
(i)   t iff  
/ t;
(ii)    0  t iff ,  0  t.
Two -types t, t0 are said to agree on sub0  if t  sub0  = t0  sub0 , i.e., if they share
the same sentences. Given a -type t for  and a constant c  con, ht, ci is an indexed type
for , abbreviated as tc . In Table 4 we report a type t in cl0 , for  equal to Formula (1).
We now introduce state candidates, which intuitively represent the states of a quasimodel.
Definition 14 (State candidate). A -state candidate for  is a pair C = hT, T con i such
that
(i) T is a set of -types for  that agree on sub0 ;
(ii) T con is a set containing for each c  con an indexed type tc such that t  T .
18

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

We also introduce the notion of point, which describes a state candidate from the perspective of a particular type.
Definition 15 (Point). A -point for  is a pair P = hC, ti such that
(i) C = hT, T con i is a -state candidate for ;
(ii) t  T is a -type.
Note that, by a slight abuse of notation, we call points both the pairs (r, n) in QIS and
the pairs P = hC, ti. This is to be consistent with previous work (Fagin et al., 1995; Halpern
et al., 2004); the context will disambiguate. Also, we write t  C for C = hT, T con i and
t  T . Similarly for t  P. Given a -state candidate C = hT, T con i and a point P = hC, ti
we define the formulas C and P as follows:
C :=

^

xt[x]  x

tT

_
tT

t[x] 

^

t[x/c]

tc T con

P := C  t
where we do not distinguish between a type t and the conjuction of formulas it contains.
A -state candidate C is S-consistent if the formula C is consistent w.r.t. the system S,
i.e., if 0S C . Similarly, a -point P is S-consistent if the formula P is consistent w.r.t. S.
We refer to plain consistency whenever the system S of reference is understood. Consistent
state candidates represent the states of our quasimodels. We now define the relations of
suitability that constitute the relational part of quasimodels.
Definition 16.
 A 1 -type t1 and a 2 -type t2 are -suitable, or t1  t2 , iff 1 = 2
and t1  t2 is consistent. They are i-suitable, or t1 i t2 , iff 1 ]i = 2 ]i and t1  Ki t2
is consistent.
 A 1 -state candidate C1 and a 2 -state candidate C2 are -suitable, or C1  C2 , iff
1 = 2 and C1  C2 is consistent. They are i-suitable, or C1 i C2 , iff 1 ]i = 2 ]i
and C1  Ki C2 is consistent.
 A 1 -point P1 and a 2 -point P2 are -suitable, or P1  P2 , iff 1 = 2 and P1 
P2 is consistent. They are i-suitable, or P1 i P2 , iff 1 ]i = 2 ]i and P1  Ki P2
is consistent.
 A 1 -point P1 = hC1 , t1 i and a 2 -point P2 = hC2 , t2 i are -suitable for a constant
c  con, or P1 c P2 , iff P1  P2 , tc1  T1con and tc2  T2con . They are i-suitable
for c, or P1 ci P2 , iff P1 i P2 , tc1  T1con and tc2  T2con .
By using the axioms T , 4 and 5 it can be shown that the relation i is reflexive,
transitive and symmetric, that is, an equivalence relation. Also, the relation  is serial.
In the following lemma we list some properties of relations  and i that will be useful in
what follows.
Lemma 3.

(i) Let   subx , if t1  t2 then   t1 iff   t2 .
19

fiBelardinelli & Lomuscio

(ii) Let Ki   subx  and let t be a -type, Ki   t iff for all -types t0 , t i t0 implies
  t0 . Moreover, let |]i|  ad(), then Ki   t iff for all ]i-types t0 , t i t0 implies
  t0 .
Proof.
(i) The proof is similar to the one for Lemma 9(i) in the work of Wolter et al. (2002). If
  t1 and  
/ t2 then   t2 and since t1 t2 is consistent, then also  
is consistent, which is a contradiction. From right to left, if   t2 and  
/ t1 then
    t1 . Since t1  t2 is consistent, then also      is consistent, which
is a contradiction.
(ii) From left to right, if Ki   t and  
/ t0 then   t0 and since t  Ki t0 is consistent,
then also Ki   Ki  is consistent, which is a contradiction. From right to left, if
Ki  
/ t then we can extend the set {}  { | Ki   t} to a -type t0 . In particular,
t i t0 and   t0 . Moreover, if |]i|  ad() then we can similarly prove that Ki   t
iff for all ]i-types t0 , t i t0 implies   t0 .
We now present the frame underlying the quasimodel for .
Definition 17 (Frame). A frame F is a tuple hR, D, {i,a }iAg,aD , fi where
(i) R is a non-empty set of indexes r, r0 , . . .;
(ii) D is a non-empty set of individuals;
(iii) for every i  Ag, a  D, i,a is an equivalence relation on the set of points (r, n) for
r  R and n  N;
(iv) f is a partial function associating to each point (r, n) a consistent state candidate
f(r, n) = Cr,n such that
(a) the domain of f is not empty;
(b) if f is defined on (r, n), then it is defined on (r, n + 1);
(c) if f is defined on (r, n) and (r, n) i,a (r0 , n0 ), then f is defined on (r0 , n0 ).
The function f is partial to take into consideration the case of synchronous systems. Also,
it is straightforward to introduce frames satisfying perfect recall, no learning, synchronicity,
or having a unique initial state, by following the same definitions given for mf-models. Next,
we provide the definition of objects, which correspond to the runs of Gabbay et al. (2003).
We choose this terminology to avoid confusion with the runs in QIS.
Definition 18 (Object). Given an individual a  D, an object in the frame F is a map a
con i
associating a type a (r, n)  Tr,n to every (r, n)  Dom(f) with f(r, n) = Cr,n = hTr,n , Tr,n
such that
1. a (r, n)  a (r, n + 1)
2. if (r, n) i,a (r0 , n0 ) then a (r, n) i a (r0 , n0 )
20

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

3. U  a (r, n) iff there is n0  n such that   a (r, n0 ) and for all n00 , n  n00 < n0
implies   a (r, n00 )
4. if a (r, n) i t are -types, then for some (r0 , n0 ), (r, n) i,a (r0 , n0 ) and a (r0 , n0 ) = t
5. if C  a (r, n) then there exists a point (r0 , n0 ) reachable from (r, n) such that
  a (r0 , n0 )
An object+ satisfies (1), (2), (3), (5) above and (40 ) below instead of (4).
(40 ) if a (r, n) is a -type, t is a ]i-type and a (r, n) i t, then for some (r0 , n0 ) i,a (r, n),
a (r0 , n0 ) = t.
Intuitively, an object identifies the same individual, here represented by types, across
different state candidates. Now we have all the elements to give the definition of quasimodel.
Definition 19 (Quasimodel). A quasimodel for  is a tuple Q = hR, O, {i, }iAg,O , fi
such that hR, O, {i, }iAg,O , fi is a frame, and
1.   t for some t  Tr,n and Tr,n  Cr,n
2. Cr,n  Cr,n+1
3. if (r, n) i, (r0 , n0 ) then (r, n) i (r0 , n0 )
4. for every t  Tr,n there exists an object   O such that (r, n) = t
con is an object in O.
5. for every c  con, the function c such that c (r, n) = tc  Tr,n

A quasimodel+ is defined as a quasimodel but where clauses (4) and (5) refer to objects+
rather than objects. We can define quasimodels (resp. quasimodel+ ) satisfying perfect recall,
no learning, synchronicity, or having a unique initial state, by assuming the corresponding
condition on the underlying frame. The difference between objects (resp. quasimodel) and
objects+ (resp. quasimodel+ ) is purely technical. In particular, the latter are needed for
systems satisfying perfect recall and no learning as it will become apparent in Section 5.
In the following lemma we list some properties of quasimodels that will be useful in what
follows.
Lemma 4. In every quasimodel Q, for every object   O,
(i) Ki   (r, n) iff for all (r0 , n0 ), (r0 , n0 ) i, (r, n) implies   (r0 , n0 ).
(ii) C  (r, n) iff for all points (r0 , n0 ) reachable from (r, n) we have that   (r0 , n0 ).
Proof.
(i) The implication from left to right follows from the fact that (r0 , n0 ) i, (r, n) implies
(r, n) i (r0 , n0 ). For the implication from right to left, if Ki  
/ (r, n) then by
Lemma 3(ii) there is a -type t such that (r, n) i t and   t. By Definition 18 for
some (r0 , n0 ), (r, n) i, (r0 , n0 ) and   (r0 , n0 ) = t.
21

fiBelardinelli & Lomuscio

(ii) The implication from left to right is proved by induction on the length of the path
from (r, n) to (r0 , n0 ). Both the base case and the inductive step follow by axiom C1.
The implication from right to left follows from Definition 18.
We now state the main result of this section, that is, satisfability in quasimodels implies
satisfability in mf-models. In what follows a quasimodel Q validates a formula  if  belongs
to every type in every state-candidate in Q.
Theorem 3. If there is a quasimodel (resp. quasimodel+ ) Q for a monodic formula , then
 is satisfiable in a mf-model Mmf . Moreover, if Q validates the formulas K and BF , then
so does Mmf . Finally, if Q satisfies perfect recall, or no learning, or synchronicity, or has
a unique initial state, then so does Mmf .
Proof. This proof is inspired by those of Lemmas 11.72 and 12.9 in the work of Gabbay
et al. (2003), but here we consider monodic friendly Kripke models rather than standard
Kripke models. First, for every monodic formula  of the form Ki , C,  or 1 U2
we introduce a k-ary predicate constant Pk for k equal to 0 or 1, depending whether there
are 0 or 1 free variables in . The formula Pk (x) is called the surrogate of . Given a
monodic formula  we denote by  the formula obtained from  by substituting all its modal
subformulas which are not within the scope of another modal operator with their surrogates.
Since every state candidate C in the quasimodel Q is consistent and all the system S of
first-order temporal-epistemic logic considered in Section 3 are based on classical first-order
logic, the formula C is consistent with respect to first-order (non-modal) logic. By Godels
completeness theorem there is a first-order structure I = hI, Di, where D is a non-empty set
of individuals and I is a first-order interpretation on D, that satisfies C , i.e., I  |= C for
some assignment  of the variables to the elements in D. We intend to build an mf-model
by joining all these first-order structures. However, it is possible that these structures have
different domains with different cardinalities. To solve this problem, we consider a cardinal
number   0 greater than the cardinality of the set O of all objects in Q and define
D = {h, i |   O,  < }
Then, for (r, n)  Q, for any -type t  Tr,n we have that
|{h, i  D | (r, n) = t}| = 
By the method described in Claim 11.24 by Gabbay et al. (2003), we can expand each
first-order structure to obtain a structure Ir,n = hIr,n , Di with domain D such that Ir,n
satisfies Cr,n and

|{a  D | (x) = a and Ir,n
|= t[x]}| = 

So, we can assume without loss of generality that all first-order structures Ir,n share the
same domain D, and for every t  Tr,n , h, i  D, we have

(r, n) = t iff Ir,n
|= t[x]

for (x) = h, i. Equivalently, for t  Tr,n , (x) = h, i  D,

(r, n) = {  cl  | Ir,n
|= [x]}

22

(7)

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Moreover, Ir,n (c) = hc , 0i for every c  con.
We define the mf-model Mmf as the tuple hW, R, {i,a }iAg,aD , D, Ii such that W is
the set of points (r, n) for r in R  Q and n  N; R is the set of runs from N to W such that
r(n) = (r, n); D is defined as above; for i  Ag and h, i  D, i,h,i is defined as i, ;
and the interpretation I is obtained by joining the various first-order interpretations Ir,n ,
i.e., I(P, r(n)) = Ir,n (P ) for every predicate constant P . We can now prove the following
result for Mmf .
Lemma 5. If the mf-model Mmf is obtained from a quasimodel Q as described above, then
for every   subx ,

Ir,n
|=  iff (Mmf , r, n) |= 

Moreover, if Q is a quasimodel+ , f(r, n) is a -state candidate and ad(K )  ad() then

Ir,n
|=  iff (Mmf , r, n) |= 

Proof. The proof is similar to Lemma 12.10 in the work of Gabbay et al. (2003). We
begin with the first part. The base case of induction follows by definition of the interpretation I in the mf-model. The step for propositional connectives and quantifiers follows by
the induction hypothesis and equations 1  2 = 1  2 , 1 = 1 , x1 = x1 .
Now let  = [x] and assume that (x) = h, i, then we have:

Ir,n
|= [x]

iff

[x]  (r, n)

(8)

iff

[x]  (r, n + 1)

(9)

iff


Ir,n+1
|= [x]

(Mmf , r, n + 1) |= [x]
(Mmf , r, n) |= [x]

iff
iff

(10)
(11)

Steps (8) and (10) follow by Equation (7). Step (9) is motivated by Lemma 3(i), and
step (11) follows by the induction hypothesis.
Let  = (U0 )[x] and (x) = h, i, then we have:

Ir,n
|= (U0 )[x] iff

iff

(U0 )[x]  (r, n)
0

(12)
0

0

there is n  n such that  [x]  (r, n )
and [x]  (r, n00 ) for all n  n00 < n0

iff

0

there is n  n such that
and


Ir,n
00


Ir,n
0

|=

(13)

0 [x]

00

|= [x] for all n  n < n0
0

iff

there is n  n such that

iff

and (Mmf , r, n00 ) |= [x]
(Mmf , r, n) |= U0 [x]

(Mmf , r, n0 )

(14)
0

|=  [x]
00

for all n  n < n0

(15)

Steps (12) and (14) follow by Equation (7). Step (13) is motivated by Def. 18, and step
(15) follows by the induction hypothesis.
23

fiBelardinelli & Lomuscio

Let  = Ki [x] and (x) = h, i, then we have:

Ir,n
|= Ki [x]

iff
iff

Ki [x]  (r, n)
0

0

0

0

(16)
0

0

for all (r , n ) i, (r, n), [x]  (r , n )

(17)

(r , n ) i,h,i (r, n), Ir0 ,n0 |= [x]
(r0 , n0 ) i,h,i (r, n), (Mmf , r0 , n0 )

iff

for all

iff

for all

iff

(Mmf , r, n)

(18)
|= [x]

(19)

|= Ki [x]

Steps (16) and (18) follow by Equation (7). Step (17) is motivated by Lemma 4(i), and step
(19) follows by the induction hypothesis.
Let  = C[x] and (x) = h, i, then we have:

Ir,n
|= C[x]

iff
iff
iff

C[x]  (r, n)
0

0

0

0

0

0

(20)
0

0

for all (r , n ) reachable from (r, n), [x]  (r , n )
for all (r , n ) reachable from

(r, n), Ir0 ,n0

(21)

|= [x]

(22)

0

(23)

0

iff

for all (r , n ) reachable from (r, n), (M, r , n ) |= [x]

iff

(M, r, n) |= C[x]

Steps (20) and (22) follow by Equation (7). Step (21) is motivated by Lemma 4(ii), and
step (23) follows by the induction hypothesis.
Now we prove the second part of the lemma. All cases are identical to the first part,
except for  = Ki . Suppose that f(r, n) is a -state candidate and ad(K )  ad().
For the implication from left to right, if (r, n) i, (r0 , n0 ) then (r0 , n0 ) is a 0 -type such
that ]i = 0 ]i. Thus, ad(K0 )  ad(K]i )  ad(K Ki )  ad(). So, we can apply
the induction hypothesis. For the implication from right to left, if ad(K Ki )  ad()
then |]i|  ad() and by Lemma 3(ii) there is some ]i-type t such that t i (r, n) and
  t. By Def. 18 there is (r0 , n0 ) such that (r, n) i, (r0 , n0 ) and (r0 , n0 ) = t. Since
ad(K]i ) = ad(K Ki )  ad() we can apply the induction hypothesis.
To complete the proof of Theorem 3, by definition of quasimodel we have that   t for
some t  Tr,n and Tr,n  Cr,n . Therefore,  is satisfied in the mf-model Mmf at point (r, n).
We also remark that if Q validates the formulas K and BF , so does Mmf . This is the case
as, if K and BF belong to every type in every state-candidate in Q, then by Lemma 5 we
have that Mmf validates K and BF as well.
Finally, if Q satisfies perfect recall, or no learning, or synchronicity, or has a unique
initial state, then the mf-model obtained from Q satisfies the corresponding constraints by
construction. We show this fact for perfect recall: if (r, n) i,h,i (r0 , n0 ) and n > 0, then
in particular (r, n) i, (r0 , n0 ). Since Q satisfies perfect recall, either (r, n  1) i, (r0 , n0 ),
or there is k < n0 such that (r, n  1) i, (r0 , k) and for all k 0 , k < k 0  n0 implies
(r, n) i, (r0 , k 0 ). By the definition of i,h,i we obtain that either (r, n  1) i,h,i (r0 , n0 ),
or there is k < n0 such that (r, n  1) i,h,i (r0 , k) and for all k 0 , k < k 0  n0 implies
(r, n) i,h,i (r0 , k 0 ), that is, Mmf satisfies perfect recall as well.
We next show the existence of quasimodels for any monodic .
24

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

5. Dealing with each System
In this section we consider the completeness proof for each system in Theorem 2. In particular, we show that if a monodic formula  is consistent with respect to a system S, then
we can build a quasimodel (or a quasimodel+ in specific cases) for  based on a frame for
S. In the following sections the symbol ` represents provability in the appropriate system
S. We start with some lemmas that are useful for the construction of the quasimodel for
any system.
Lemma 6. (i) For any consistent monodic formula  there is a consistent -state candidate C = hT, T con i such that   t for some t  T .
(ii) Let P = hC, ti be a consistent -point for  such that C = hT, T con i, and let c  con.
Then,
(a) if C  C0 then there exists a -point P0 = hC0 , t0 i such that P  P0 .
(b) if tc  T con and C  C0 then there exists a -point P0 = hC0 , t0 i such that P c P0 .
(c) if 1 U2  t then there is a sequence of -points Pj = hCj , tj i for j  k that
realises 1 U2 , i.e., P = P0  . . .  Pk , 2  tk and 1  tj for j < k.
(d) if 1 U2  tc then there is a sequence of -points Pj = hCj , tj i for j  k that
c-realises 1 U2 , i.e., the sequence realises 1 U2 and P0 c . . . c Pk .
(e) if Ki   t then there is a -point P0 = hC0 , t0 i such that P i P0 and   t0 .
(f ) if Ki   tc then there is a -point P0 = hC0 , t0 i such that P ci P0 and   t0 .
(g) if C  t then there is a sequence of -points Pj = hCj , tj i for j  k such that
P = P0 i0 . . . ik1 Pk and   tk .
(h) if C  tc then there is a sequence of -points Pj = hCj , tj i for j  k such that
P = P0 ci0 . . . cik1 Pk and   tk .
Proof. The proof is similar to the one for Claims 11.75, 11.76 and 12.13 in the work
of Gabbay et al. (2003), but here we consider -state candidates and -points. Let  be
the disjunction of all formulas P for all -points P for . Consider the formula   , which
is obtained by substituting all subformulas of  of the form Ki , C,  or 1 U2 that
are not within the scope of another modal operator with their surrogates. We can check
that   is true on all (non-modal) first-order structures. Since both QKTm and QKTCm
extend first-order logic, by the semantical completeness of first-order logic we have that
` 

(24)

W
(i) Notice that, by the previous remark, `  also for  = {P|P is a -point for } P .
Moreover,  is consistent and by (24) also    is consistent. Therefore, there is a
disjunct P of  such that P   is consistent. So,   t for P = hC, ti.
(a) By (24) and Nec we have `  . So, P   is consistent and there must be a
-point P0 such that P  P0 is also consistent.
(b) The proof is similar to (a).
25

fiBelardinelli & Lomuscio

(c) The proof is by contradiction. Let U be the set of all -points P0 such that
W there exist points Pj = hCj , tj i for j < k and P = P0  . . .  Pk = P0 . Let  = {P0 |P0 U } P0 .
We can show that
`   2
(25)
otherwise, we would have a sequence realising 1 U2 . Moreover, by the definition of
U,
`   
(26)
From (25) we obtain
` G  G2
and together with (25) and (26) we derive
`   (2  G2 )

(27)

Now consider any P1  U such that P  P1 . By (27) we have
`

P1  (2  G2 )

`

P1  G2

`

(P  P1 )  G2

(28)

On the other hand, since 1 U2  t we have
` (P  P1 )  F 2

(29)

but (28) and (29) contradict the fact that P  P1 .
(d) The proof is similar to (c).
(e) First we remark that P  Ki (  ) is consistent. Thus, there exists a -point
P0 = hC0 , t0 i such that P  Ki (P0  ) is consistent. Hence, P i P0 and   t0 .
(f) The proof is similar to (e).
(g) The proof is by contradiction. Let V be the minimal set of -points DWsuch that (i)
P  V ; (ii) if D  V and D i D0 for some i  Ag, then D0  V . Let  = {D|DV } D .
We can show
`
(30)
If (30) did not hold, we would have a sequence as specified in the lemma. Moreover,
by the definition of V ,
`   Ki 
(31)
for all i  Ag. From (30) and (31) we obtain
`   (  E)
and by axiom C2,
`   C
but by definition of P,
` P  C
which contradicts (32).
26

(32)

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

(h) The proof is similar to (g).
By the following result it is always possible to extend the -suitability relation 
between types to -suitability between points.
Lemma 7. Suppose that t and t0 are -types such that t  t0 , then there are -points
P = hC, ti and P0 = hC0 , t0 i such that P  P0 . In particular, for any c  con, there are
-points P = hC, ti and P0 = hC0 , t0 i such that P c P0 .
W
Proof. By Lemma 6 we have that `  and `  for  = {P|P is a -point for } P .
Since t  t0 , then   t  (  t0 ) is consistent. Thus, there must be -points P and
P0 such that P  t  (P0  t0 ) is consistent. Then, it is the case that P = hC, ti and
P0 = hC0 , t0 i for some -state candidates C and C0 . As a result, P  P0 . The second part of
the lemma is proved similarly to the first by observing that if t  t0 then t[x/c]  t[x/c]
is consistent. Hence, also   t[x/c]  (  t0 [x/c]) is consistent. Thus, there must be
-points P and P0 such that P  t[x/c]  (P0  t0 [x/c]) is consistent. So, tc  T con and
t0c  T 0con , that is, P c P0 .
According to Lemma 7 we can always extend a possibly infinite sequence of -types t0 
t1  . . . to a possibly infinite sequence of -points P0  P1  . . . such that Pk = hCk , tk i.
Definition 20. Let a -sequence be a possibly infinite sequence C0  C1  . . . of -state
candidates. A -sequence is acceptable if for all k  0,
(i) if 1 U2  tk , for tk  Ck , then 1 U2 is realised in a sequence of -points Pj =
hCj , tj i for k  j  n;
(ii) if 1 U2  tck , for tck  Ck , then 1 U2 is c-realised in a sequence of -points Pj =
hCj , tj i for k  j  n.
The following lemma entails the completeness result.
Lemma 8. Every finite -sequence of -state candidates can be extended to an infinite
acceptable -sequence.
Proof. Assume that C0  . . .  Cn is a finite -sequence  and 1 U2  tk  Ck for
some k  n. Either 1 U2 is realised in C0  . . .  Cn , or by Lemma 6(ii)(c) we can extend
 to a -sequence 0 that realises 1 U2 . This procedure is repeated for all formulas of
the form 1 U2 appearing at some point in the -sequence. Thus, we obtain a (possibly
infinite) -sequence C0  C1  . . . such that property (i) in Definition 20 is satisfied. To
also satisfy property (ii) we reason similarly by using Lemma 6(ii)(d) instead.
Now let X be a new object, a sequence X, . . . , X, Cn , Cn+1 , . . . is acceptable from n if
it starts with n copies of X and Cn , Cn+1 , . . . is an acceptable -sequence. We can now
consider the completeness proof for each single class of QIS.
uis
sync,uis
5.1 The Classes QIS m , QIS sync
m , QIS m and QIS m

We start with the completeness proof for the systems QKTm and QKTCm , where there is
no interaction between temporal and epistemic operators.
27

fiBelardinelli & Lomuscio

If a monodic formula  is consistent, then by Lemma 6(i) there is a consistent -state
candidate C = hT, T con i such that   t for some type t  T . Also, by Lemma 8 we
can extend C to an infinite acceptable -sequence. So, the set of infinite acceptable sequences is non-empty. Let R be the set of all -sequences acceptable from n, for some
n  N. For r  R, k  N, define the partial function f on R  N as f(r, k) = Ck if r is
the -sequence X, . . . , X, Cn , Cn+1 , . . . acceptable from n and k  n, undefined otherwise.
Finally, let O be the set of all functions  associating every (r, n)  Dom(f) to a type
(r, n)  Tr,n such that
(A) (r, n)  (r, n + 1);
(B) U  (r, n) iff there is n0  n such that   (r, n0 ) and   (r, n00 ) for all
n  n00 < n0 ;
(C) if (r, n) i t are -types, then for some (r0 , n), (r0 , n) = t;
(D) if C  (r, n) then there exists a point (r0 , n) and a sequence of -points Pj =
hCj , tj i for j  k, such that hf(r, n), (r, n)i = P0 i0 . . . ik1 Pk ,   tk , f(r0 , n) =
Ck and (r0 , n) = tk .
We show that O is non-empty. Condition (A) is guaranteed by Lemma 6(ii)(a), and
condition (B) by the fact that r is an acceptable -sequence. As regards (C) we remark
that if (r, n) i t then we can find a consistent -point P = hC, ti by reasoning similarly
as in Lemma 6(i), and by Lemma 8, C can be extended to a -sequence r0 acceptable
from n. Finally, set (r0 , n) = t. As to (D) we observe that if C  (r, n) then by
Lemma 6(ii)(g) there exists a sequence of -points Pj = hCj , tj i for j  k, such that
hf(r, n), (r, n)i = P0 i0 . . . ik1 Pk and   tk . Now, Ck can be extended to a sequence r0 acceptable from n such that (r0 , n) = tk . Finally, for i  Ag,   O, define
(r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ) and n = n0 .
Lemma 9. The tuple hR, O, {i, }iAg,O , fi is a synchronous frame.
Proof. We have previously shown that R and O are non-empty. Also, each i, is an
equivalence relation by definition, and f satisfies the conditions in Definition 17. Further,
the frame is synchronous by definition of i, .
Now we can prove the main result.
Lemma 10. The tuple hR, O, {i, }iAg,O , fi is a synchronous quasimodel for  and it
validates the formulas K and BF .
Proof. By the previous lemma, it remains to prove that the functions in O are objects.
Conditions (1), (3), (4) and (5) on objects are safisfied by remarks (A)-(D) above. Condition (2) is satisfied by the definition of i, . Furthermore, conditions (1), (2) and (3) on
quasimodels are satisfied by the definitions of R, f and i, . As regards (4), we can extend
the function (r, n) = t to all Dom(f) by using Lemma 6(ii)(a), (c), (e) and (g). As to (5)
the function c such that c (r, n) = tc is an object by Lemma 6(ii)(b), (d), (f) and (h).
Finally, Q validates both the formulas K and BF , as all t  C, for all C  Q, are consistent
with QKTm (resp. QKTCm ).
28

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

The completeness of QKTm and QKTCm with respect to the classes QIS m and QIS sync
m
of quantified interpreted systems directly follows from Lemma 10 together with Theorem 3.
Thus, we obtain the following item in Theorem 2.
Theorem 4 (Completeness). The system QKTm (resp. QKTCm ) is complete w.r.t. the
classes QIS m and QIS sync
of QIS.
m
sync,uis
To prove completeness for QIS uis
we use the next result, which is an
m and QIS m
extension from the propositional case (Halpern et al., 2004).
1 ) is satisfiable in
Remark 2. Suppose X is a subset of {pr, sync}. If   L1m (resp. LCm
X
X,uis
QIS m then it is also satisfiable in QIS m .

Thus, the system QKTm (resp. QKTCm ) is also complete w.r.t. the classes QIS uis
m and
sync,uis
QIS m
of QIS.
pr,uis
5.2 The Classes QIS pr
m and QIS m

We now begin to investigate systems where interactions between time and knowledge are
pr,uis
present. The completeness proof for QKT1m with respect to QIS pr
relies on
m and QIS m
the following lemma.
Lemma 11. For all -points P1 = hC1 , t1 i, P2 = hC2 , t2 i and ]i-type t02 , if P1  P2 and
t2 i t02 then there is a ]i-point P02 = hC02 , t02 i and a -sequence S1  . . .  Sn = P02
of ]i-points such that Sk = hDk , sk i, s1 i t1 and sk i t2 for 1 < k  n. Further, if
for k  n.
P1 c P2 then sck  TDcon
k
Proof. We extend the proof of Halpern et al. (2004, Lemma 5.5) to deal with state
candidates and monodic friendly Kripke frames. By the cited result we can prove that if
t1  t2 and t2 i t02 then there is a sequence of ]i-types s1  . . .  sn = t02 such that
s1 i t1 and sk i t2 for 1 < k  n. Now by Lemma 7 we can extend this sequence of
]i-types to a sequence of ]i-points S1  . . .  Sn such that Sk = hDk , sk i and the
lemmas statement is satisfied. In particular, if P1 c P2 also by Lemma 7 we can assume
without loss of generality that sck  TDcon
for k  n.
k
For any consistent   L1m we define a quasimodel+ for  to establish the completeness
of QKT1m with respect to QIS pr
m . Let R be the set of all acceptable -sequences, and define
f such that f(r, k) = Ck if r is the -sequence C0 , C1 , . . . . Finally, let O be the set of all
functions  associating every (r, n)  Dom(f) to a type (r, n)  Tr,n such that conditions
(A) and (B) above are satisfied and
(C) if (r, n) is a -type, t is a ]i-type and (r, n) i t, then for some (r0 , n0 ), (r0 , n0 ) = t.
(E) if (r, n) i (r0 , n0 ) and n > 0 then either (a) (r, n  1) i (r0 , n0 ) or (b) there is
k < n0 such that (r, n  1) i (r0 , k) and for all k 0 , k < k 0  n0 implies (r, n) i
(r0 , k 0 ).
Finally, for i  Ag,   O, we define (r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ).
The following lemma shows that the set O is non-empty. In particular, conditions (C)
and (E) are satisfied by the functions in O.
29

fiBelardinelli & Lomuscio

Lemma 12. The set O of functions that satisfies conditions (A), (B), (C) and (E) is
non-empty.
Proof. Conditions (A) and (B) follow respectively from Lemma 6(ii)(a) and the fact
that r is an acceptable -sequence. As regards (C) and (E), the proof proceeds by induction
on n. The result for n = 0 is immediate, as we can take r0 to be an acceptable -sequence
starting from C such that t  C. Further, we define (r0 , 0) = t. Thus, (r0 , 0) i (r, 0) and
both (C) and (E) are satisfied.
Now suppose that n > 0 and the result holds for n  1. Since f(r, n  1)  f(r, n) and
(r, n) i t, it follows by Lemma 11 that there is a ]i-point P = hC, ti and a -sequence of
]i-points P0  S0  . . .  Sk = P such that Sk0 = hDk0 , sk0 i and sk0 i (r, n) for k 0  k.
By the induction hypothesis, there exists for every ]i-type s such that (r, n1) i s a point
(r0 , n0 ) and (r0 , n0 ) = s. In case (a), we take s = t; then we have that (r, n  1) i (r0 , n0 )
for (r0 , n0 ) = t. Thus, it is also the case that (r, n) i (r0 , n0 ). In case (b), we take s = t0 .
Hence, (r, n  1) i (r0 , n0 ) for (r0 , n0 ) = t0 . Now suppose that r0 is derived from the
acceptable -sequence v0 , v1 , . . .. Let r00 be the run derived from an acceptable sequence
with initial segment v0 , . . . , vn0 , D0 , . . . , Dk . Again, such a run exists by Lemma 8. We
define (r00 , n0 + k + 1) = sk = t. Thus, we have (r, n) i (r00 , n0 + k + 1) and both (C)
and (E) are satisfied.
We can now prove the following lemma.
Lemma 13. The tuple hR, O, {i, }iAg,O , fi is a frame that satisfies perfect recall.
Proof. By Lemmas 6(i), 8 and 12 the sets R and O are non-empty. Also, f satisfies the
conditions in Definition 17. Finally, each i, is an equivalence relation by definition, and
it satisfies perfect recall by definition of the functions  in O.
Finally, we prove the main result in this section.
Lemma 14. The tuple hR, O, {i, }iAg,O , fi is a quasimodel+ for  with perfect recall
and it validates the formulas K and BF .
Proof. By the previous lemma hR, O, {i, }iAg,O , fi is a frame satisfying perfect
recall; so we are left to prove that the functions in O are objects+ . Conditions (1)-(4) on
objects+ are safisfied by remarks (A)-(E) and the definition of i, . Furthermore, conditions
(1), (2) and (3) on quasimodels+ are satisfied by the definitions of R, f and i, . As
regards (4), it follows from Lemma 11. Finally, condition (5) on quasimodels+ holds by
Lemma 6(ii)(b), (d), (f) and (h) and Lemma 11. Finally, Q validates both the formulas K
and BF , as all t  C, for all C  Q, are consistent with QKTm .
This completes the proof for QIS pr
m . Thus, we obtain the following item in Theorem 2.
Theorem 5 (Completeness). The system QKT1m is complete w.r.t. the class QIS pr
m of QIS.
The completeness of QKT1m with respect to QIS pr,uis
follows by Remark 2.
m
5.3 The Classes QIS pr,sync
and QIS pr,sync,uis
m
m
The completeness of QKT2m with respect to QIS pr,sync
is proved similarly to the previous
m
case by using the following lemma instead of Lemma 11.
30

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Lemma 15. For -state candidates C1 , C2 and ]i-state candidate C02 , there is a ]i-state
candidate C01 such that
 if C1  C2 and C2 i C02 then C1 i C01 and C01  C02 .
 for c  con, for P1 = hC1 , t1 i, P2 = hC2 , t2 i and P02 = hC02 , t02 i, if P1 c P2 and
P2 ci P02 then for P01 = hC01 , t01 i, P1 ci P01 and P01 c P02 .
Proof. if C1  C2 and C2 i C02 then there exist t1  C1 , t2  C2 and t02  C02 such
that t1  t2 and t2 i t02 . Moreover, without loss of generality we can assume that for
0con . Following the proof by Halpern et
some c  con, tc1  T1con , tc2  T2con and t0c
2  T2
0
al. (2004, Lemma 5.8) we can find a ]i-type t1 such that t1 i t01 and t01  t02 . Define T10
0
0
0con i is a
as the set of all such t01 and T10con as the set of t0c
1 . We can show that C1 = hT1 , T1
0
0
0
consistent ]i-state candidate such that C1 i C1 , C1  C2 , and for c  con, P1 ci P01
and P01 c P02 .
For any consistent   L1m we define a quasimodel+ for  to establish the complete. Let R be the set of all -sequences acceptness of QKT2m with respect to QIS pr,sync
m
able from n, for some n  N, and define f such that f(r, k) = Ck if r is the -sequence
X, . . . , X, Cn , Cn+1 , . . . acceptable from n and k  n, and undefined otherwise. Finally, let
O be the set of all functions  associating every (r, n)  Dom(f) to a type (r, n)  Tr,n
such that conditions (A) and (B) in Section 5.1 are satisfied and
(C) if (r, n) is a -type, t is a ]i-type and (r, n) i t, then for some (r0 , n), (r0 , n) = t.
(F) if (r, n) i (r0 , n) and n > 0 then (r, n  1) i (r0 , n  1).
Finally, for i  Ag,   O, we define (r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ) and n = n0 .
The following remark shows that the set O is non-empty. In particular, conditions (C)
and (F) are satisfied by the functions in O.
Lemma 16. The set O of functions that satisfies condition (A), (B), (C) and (F) is
non-empty.
Proof. Conditions (A) and (B) follow from Lemma 6(ii)(a) and the fact that r is an
acceptable -sequence. As regards (C) and (F), assume that (r, n)  f(r, n) is a -type,
t is a ]i-type and (r, n) i t. For each s  f(r, n) different from (r, n) consider the set
U = { | Ki   s}. We can check that U is consistent and it can be extended to a ]i-type s0
such that s i s0 . Now define T 0 as the collection of all these s0 . Further, for each sc  T con ,
we set s0c  T 0con . Let C0 = hT 0 , T 0con i. Clearly, C i C0 and hC, si ci hC0 , s0 i. By Lemma 15
we can construct a -sequence C0  . . .  Cn such that Cn = C0 and f(r, k) i Ck for
k  n. By Lemma 8 we can extend this -sequence to an infinite acceptable -sequence
r0 . In particular, the function  can be extended so that for k  n, (r, k) i (r0 , k) and
(r0 , n) = t. Thus, both (C) and (F) are satisfied.
We can now show the following lemma.
Lemma 17. The tuple hR, O, {i, }iAg,O , fi is a frame that satisfies perfect recall and
synchronicity.
31

fiBelardinelli & Lomuscio

Proof. By Lemmas 6(i), 8 and 16 the sets R and O are non-empty. Also, f satisfies the
conditions in Definition 17. Finally, each i, is an equivalence relation by definition, and
it satisfies perfect recall and synchronicity by definition of the functions in O.
Now we prove the main result.
Lemma 18. The tuple hR, O, {i, }iAg,O , fi is a quasimodel+ for  with perfect recall
and synchronicity, and it validates the formulas K and BF .
Proof. By the previous lemma hR, O, {i, }iAg,O , fi is a frame satisfying perfect
recall and synchronicity; so we are left to prove that the functions in O are objects+ .
Conditions (1)-(4) on objects+ are safisfied by the remarks (A)-(F) and the definition
of i, . Furthermore, conditions (1), (2) and (3) on quasimodels+ are satisfied by the
definitions of R, f and i, . As regards condition (4), we can make use of Lemma 15 to
show that it holds. Additionally, (5) holds by Lemma 6(ii)(b), (d), (f) and (h) and Lemma
15. Finally, Q validates both the formulas K and BF , as all t  C, for all C  Q, are
consistent with QKTm .
This completes the proof for QKT2m . Thus, we obtain the following item in Theorem 2.
Theorem 6 (Completeness). The system QKT2m is complete w.r.t. the class QIS pr,sync
of
m
QIS.
follows again by Remark 2.
The completeness of QKT2m with respect to QIS pr,sync,uis
m
5.4 The Class QIS nl
m
First, we give the following definitions, which will be used in the completeness proof.
Definition 21. If t is a -type, then t,i is the conjunction of all -types t0 such that t i t0 .
Similarly, if P is a -point, then P,i is the set of -points P0 such that P i P0 .
Definition 22. Two sequences of types  and 0 are i -concordant if there is some n  N
(or n may be ) and non-empty consecutive intervals 1 , . . . , n of  and 01 , . . . , 0n of 0
such that for all s  j and s0  0j we have s i s0 for j  n.
Two sequences  and 0 of state candidates are i -concordant if for all t  C, for either
C   or C  0 , there are two sequences  and 0 of types in  and 0 respectively that
are i -concordant.
To prove the completeness of QKT3m with respect to QIS nl
m we need the following lemma,
which is dual to Lemma 11.
Lemma 19. For all -points P1 = hC1 , t1 i, P2 = hC2 , t2 i and ]i-type t01 , if P1  P2 and
t1 i t01 then there exists a ]i-point P01 = hC01 , t01 i and a -sequence P01 = S1  . . .  Sn
of ]i-points such that Sk = hDk , sk i, sk i t1 for k < n, and t2 i sn . Further, if P1 c P2
then sck  TDcon
for k  n.
k
Proof. By adapting the result of Halpern et al. (2004, Lemma 5.11) to types we can
prove that if t1  t2 and t1 i t01 then there is a sequence of ]i-types t01 = s0  . . .  sn
such that sk i t1 for k < n and sn i t2 . Now by Lemma 7 we can extend this sequence
of ]i-types to a sequence of ]i-points S1  . . .  Sn such that Sk = hDk , sk i. So, the
32

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

statement of the lemma is satisfied. In particular, if P1 c P2 then by Lemma 7 we can
assume without loss of generality that sck  TDcon
for k  n.
k
As pointed out by Halpern et al. (2004), Lemma 19 is not sufficient to construct a
quasimodel+ that satisfies no learning. In fact, given a -sequence  = C0 , C1 , . . . of state candidates and a ]i-type t00 such that t0 i t00 for t0  C0 , by Lemma 19 we can find a
-sequence 0 = C00 , C01 , . . . such that t00  C00 and no learning is satisfied. However, it does
not follow from the acceptability of  that 0 is also acceptable. So, as in the propositional
case, we have to work with trees of state candidates. Hereafter we extend the definitions
given by Halpern et al. (2004) to be able to deal with points and monodic friendly Kripke
models.
Definition 23. Let k  ad(). A k-tree of state candidates for  is a set  of -state
candidates for  with ||  k that contains a unique -state candidate, i.e., the root, and for
every -point t in some C  ,
 if t0 is a ]i-type such that t i t0 and |]i|  k then there is some ]i-state candidate
C0   such that t0  C0 ;
 if  = 0 ]i then there is a 0 -state candidate C0   and a 0 -type t0  C0 such that
t i t0 .
Similarly, we define a k-tree of points for  as a set  of -points for  with ||  k that
contains a unique -point, and for every -point P = hC, ti  ,
 if t0 is a ]i-type such that t i t0 and |]i|  k, then there is some ]i-point P0 =
hC0 , t0 i  ;
 if  = 0 ]i then there is a 0 -point P0 = hC0 , t0 i   such that t i t0 .
Intuitively, a k-tree is a view of the epistemic state of our quasimodel from a particular
type t, up to k steps from t. We now extend the -suitability relation  to k-trees.
Definition 24. Let  and 0 be k-trees of state candidates for . We say that  f 0
whenever f is a function associating with each -state candidate C   and each -type t  C
finite -sequences of -state candidates in   0 and -types such that:
1. if f (C) = C0  . . .  Ck then (a) C = C0 and (b) Cj   for j < k and Ck  0 .
Similarly, if f (t) = t0  . . .  tk then (a) t = t0 and (b) tj  Cj for j < k and
t k  Ck .
2. Let t  C and t0  C0 for some C, C0  . If t i t0 then f (t) and f (t0 ) are i concordant;
3. for at least one C   the sequence f (C) has a length of at least 2.
Further, let  and 0 be k-trees of points for . We say that  f 0 whenever f is a
function associating with each -point P   a finite -sequence of -points in   0 such
that:
1. if f (P) = P0  . . .  Pk then (a) P = P0 and (b) Pj   for j < k and Pk  0 ;
33

fiBelardinelli & Lomuscio

2. Let P = hC, ti and P0 = hC0 , t0 i be in . If t i t0 then f (t) and f (t0 ) are i -concordant;
3. for at least one P   the sequence f (P) has a length of at least 2.
Finally, for any constant c  con, we say that  cf 0 whenever  f 0 and f (P) =
P0 c . . . c Pk .
Notice that given a k-tree  of state candidates with root C and t  C, we can obtain a
k-tree  of points such that P0 = hC0 , t0 i   iff C0  . Also, if , 0 are k-tree of state
candidates and  f 0 , then we also have  f 0 where  and 0 are k-trees of points
based on  and 0 respectively.
We now show how to obtain acceptable sequences of state candidates from sequences
of trees. Given two sequences of -state candidates  = C0 , . . . , Ck and  = C00 , . . ., where
 is finite, the fusion    is defined as C0 , . . . , Ck1 , C00 , . . . only if Ck = C00 . Further,
given an infinite sequence  = 0 f0 1 f1 . . . of k-trees, we say that a sequence  of
-state candidates is compatible with  if there exists some h  N and -state candidates
Ch , Ch+1 , . . ., with Cj  j for j  h, such that  = fh (Ch )  fh+1 (Ch+1 )  . . .. The sequence
 is acceptable if every -sequence compatible with  is infinite and acceptable.
The basic idea of the completeness proof is to define the quasimodel+ starting from an
acceptable sequence . Next we introduce some definitions and lemmas that are essential
for the completeness proof.
Given a k-tree  and a -point P   we inductively define the formula tree,P that
describes the k-tree  from the viewpoint of P.
Definition 25. If P is a -point, then tree,P ::= P . If P is a 0 ]i-point with 0 6= 0 ]i
then
^
tree,P = P 
Ki tree,P0
{0 point P0 |t0 i t}

If  and 0 are k-trees, P   and P0  0 , then we write (, P) + (0 , P0 ) if there is a
sequence of k-trees 0 , . . . , l and functions f0 , . . . , fl1 such that (a)  = 0 f0 . . . fl1
l = 0 ; (b) fj (P) = P for j  l  2 and fl1 (P) = (P, P0 ). Similarly, (, P) c+ (0 , P0 )
if (, P) + (0 , P0 ) and (a)  = 0 cf0 . . . cfl1 l = 0 .
We prove the following lemma, which extends a result by Halpern et al. (2004, Lemma 5.12)
to points.
Lemma 20. Suppose  is a k-tree of points and P = hC, ti   is a -point with || = k,
(a) If t0 is a -type and tree,P  (t0  ) is consistent, then there is a k-tree 0 and a
-point P0 = hC0 , t0 i  0 such that (, P) + (0 , P0 ) and tree0 ,P0   is consistent.
Further, if tc  T con then (, P) c+ (0 , P0 ).
W
(b) ` tree,P   {(0 ,P0 )|(,P)+ (0 ,P0 )} tree0 ,P0
(c) if tree,P  U 0 is consistent, then there is a sequence 0 , . . . , l of k-trees and
points P0 , . . . , Pl such that (i) Pj  j for j  l; (ii) (0 , P0 ) = (, P); (iii)
(j , Pj ) + (j+1 , Pj+1 ) for j < l; (iv) treej ,Pj   is consistent for j < l; (v)
treel ,Pl   0 is consistent. Further, if tc  T con then (iii) (j , Pj ) c+ (j+1 , Pj+1 )
for j < l.
34

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Proof. We proceed by induction on k. The case for k = 0 is immediate using standard
arguments as tree,P is just P .
Assume that k > 0 and  = 0 ]i for  6= 0 . We first prove part (a) for  = Ki  0 , then
part (b), then the general case for (a), and finally (c).
As regards part (a) for  = Ki  0 , note that tree,P  (t0  Ki  0 ) implies that
tree,P  Ki P,i UKi ( 0  t0 ,i )
By the definition of k-tree there is a 0 -point P   such that t i t . Let  be the
(k  1)-tree consisting of all  -points in  for | |  k  1. By the axiom KT3 also
tree ,P  Ki P,i UKi ( 0  t0 ,i ) is consistent, and by part (c) there is a sequence 0 , . . . , l
of (k  1)-trees and points P0 , . . . , Pl such that (i) Pj  j for j  l; (ii) (0 , P0 ) =
( , P ); (iii) (j , Pj ) + (j+1 , Pj+1 ) for j < l; (iv) treej ,Pj  Ki P,i is consistent for
j < l; (v) treel ,Pl  Ki ( 0  t0 ,i ) is consistent.
Again, by the definition of the relation + there is a sequence of (k 1)-trees 0 , . . . , m
and functions f0 , . . . , fm1 such that (a)  = 0 = 0 f0 . . . fm1 m = l . Moreover,
there are (k 1)-points u0 , . . . , um such that u0 = P , um = Pl , and for j < m, uj = Pj 0 for
some j 0  j, and if uj = uj+1 then fj (uj ) = uj , while if uj 6= uj+1 then fj (uj ) = (uj , uj+1 ).
We now show how to define the k-tree 0j extending j for j < m. By (iv) above
uj  Ki P,i is consistent for j < m, and we have that uj i P. So P  0j . Similarly,
um  Ki t0 ,i is consistent; so there exists P0 = hC0 , t0 i such that P0  0m . Further, we can
saturate each 0j so that the conditions on k-trees are satisfied and in particular 00 = . We
now show how to construct fj0 for j < m. For each point S0 = hD0 , s0 i  0j \ j there must
exist a point S = hD, si  j and an agent j 0  Ag such that s j 0 s0 . From Lemma 19 it
follows that there exists a sequence S0 starting with S0 that is j 0 -concordant with fj (S).
Moreover, we can take Pj = (P) for j < m  1, and Pm1 = (P, P0 ). We define fj0 such
that it agrees with fj on j , and for S0  0j \ j we have fj0 (S0 ) = S0 .
Notice that 00 =  by construction. If m > 0 it follows immediately from the definition
that (, P) + (m , P0 ) and that treem ,P0  Ki  0 is consistent. If m = 0 we can easily
check that we have P0   as t i t0 . Since we also have t i t, it follows that t i t0 . We
define f so that f (u) = u for every u 6= P and f (P) = (P, P0 ). Then (, P) f (, P0 ).
Since also P  P0 we have (, P) + (, P0 ).
The second part of (a) follows by a similar line of reasoning.
To prove part (b), by contradiction we assume that
_
0 tree,P  
tree0 ,P0
{(0 ,P0 )|(,P)+ (0 ,P0 )}

V
Then tree,P   {(0 ,P0 )|(,P)+ (0 ,P0 )} tree0 ,P0 is consistent. By temporal reasoning
there must be some point u such that
^
tree,P  (u 
tree0 ,P0 )
(33)
{(0 ,P0 )|(,P)+ (0 ,P0 )}

W
is consistent. Note that tree0 ,P0 is equivalent to P0  {0 point P 0 |t i t0 } Ki tree0 ,P .
Thus, the consistency of (33) implies that for each tree 0 such that (, P) + (0 , u) there
35

fiBelardinelli & Lomuscio

exists a 0 -point P0 = hC0 , t0 i such that t0 i tu and
^
tree,P  (u  Ki (

tree0 ,P0 ))

(34)

{0 |(,P)+ (0 ,P0 )}



+


is consistent. By part (a)
Vthere exists a k tree  and P   such that (, P)  ( , P )
and tree ,P u Ki ( {0 |(,P)+ (0 ,P 0 )} tree0 ,P0 ) is consistent. But this means that

P = u. Thus we have a contradiction, since tree ,u  Ki tree ,P is inconsistent.
The general case for (a) follows from (b). Part (c) also follows from (b).
The following lemma is the correspondent of Lemma 8 for k-trees.

Lemma 21. If   L1m is consistent with QKT3m , then there exists an acceptable sequence
 of ad()-trees of state candidates such that  belongs to the root of the first tree.
Proof. As in Lemma 8 the key part of this proof consists of showing that, given a finite
sequence 0 f0 . . . fl1 l of d-trees of points and a -point P = hC, ti  l such that
U 0  t (resp.   t), by Lemmas 19 and 20 we can extend the sequence of trees to
satisfy acceptability. Specifically, suppose that U 0  t. Let  include P and the 0 -points
P0 = hC0 , t0 i  l with |0 |  k = ||. Note that  is a k-tree. Further, by Lemma 20 we
can find a sequence 0 , . . . , n of k-trees and points P0 , . . . , Pn such that (i) Pj  j for
j  n; (ii) (0 , P0 ) = (, P); (iii) (j , Pj ) + (j+1 , Pj+1 ) for j < l; (iv) treej ,Pj  
is consistent for j < l; and (v) treen ,Pl   0 is consistent. By using Lemma 19 we can
extend this to a sequence of ad()-trees starting with l that satisfies U 0 as in the proof
of Lemma 20(a). For   t the argument is similar. Since  is consistent, there must be
some tree  with root C such that   t for some t  C; we can then extend  as above to
complete the proof.
For any consistent   L1m we define a quasimodel+ for  to establish the completeness
of QKT3m with respect to QIS nl
m . Let R consist of all acceptable -sequences compatible
with the ad()-tree , while the function f is given by f(r, k) = Ck if r is the acceptable
-sequence C0 , C1 , . . .. Further, let O be the set of functions  associating every (r, n) 
Dom(f) to a type (r, n)  Tr,n such that conditions (A), (B) and (C) given previously are
satisfied and the following holds:
(G) if (r, n) i (r0 , n0 ) then either (r, n + 1) i (r0 , n0 ) or there exists k > n0 such that
(r, n + 1) i (r0 , k) and for all k 0 , k > k 0  n0 implies (r, n) i (r0 , k 0 ).
Finally, for i  Ag,   O, (r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ).
As in the previous cases we have the following.
Lemma 22. The set O of functions that satisfies conditions (A), (B), (C) and (G) is
non-empty.
Proof. Conditions (A) and (B) are guaranteed by Lemma 6(ii) and by the fact that r
is an acceptable -sequence respectively. As regards (C) and (G), assume that (r, n) is
a -type, t is a ]i-type and (r, n) i t. By using the proofs of Lemmas 20 and 19 we can
find an acceptable -sequence r0 compatible with the d-tree  such that t  f(r0 , 0) and
(G) is satisfied.
We can now show the following lemma.
36

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Lemma 23. The tuple hR, O, {i, }iAg,O , fi is a frame that satisfies no learning.
Proof. By Lemmas 6(i), 21 and 22 the sets R and O are non-empty. Also, f satisfies
the conditions in Definition 17. Further, each i, is an equivalence relation by definition.
Finally, the no learning condition is satisfied by definition of the functions in O.
Lemma 24. The tuple hR, O, {i, }iAg,O , fi is a quasimodel+ for  that satisfies no
learning and validates the formulas K and BF .
Proof. By the previous lemma hR, O, {i, }iAg,O , fi is a frame satisfying no learning;
so we are left to prove that the functions in O are objects+ . Conditions (1)-(4) on objects+
are safisfied by remarks (A)-(G) and the definition of i, . Furthermore, conditions (1), (2)
and (3) on quasimodels+ are satisfied by the definitions of R, f and i, . As regards (4)
we use Lemma 19 to show that it holds. Finally, (5) holds by Lemma 6(ii)(b), (d), (f) and
(h) and Lemma 19. Finally, Q validates both K and BF , as all t  C, for all C  Q, are
consistent with QKTm .
This completes the proof for QKT3m . Thus, we obtain the following item in Theorem 2.
Theorem 7 (Completeness). The system QKT3m is complete w.r.t. the class QIS nl
m of QIS.
5.5 The Class QIS nl,sync
m
To show that QKT4m is a complete axiomatisation for QIS nl,sync
, analogously to Lemma 15,
m
we need the following.
Lemma 25. For -state candidate C1 , C2 and ]i-state candidate C01 there exists a ]i-state
candidate C02 such that
 if C1  C2 and C1 i C01 then C01  C02 and C2 i C02 .
 for all c  con, for P1 = hC1 , t1 i, P2 = hC2 , t2 i and P01 = hC01 , t01 i, if P1 c P2 and
P1 ci P01 then P01 c P02 and P2 ci P02 .
Proof. The proof is similar to Lemma 15. If C1  C2 and C1 i C01 then there exist
t1  C1 , t2  C2 and t01  C01 such that t1  t2 and t1 i t01 . Moreover, without loss of
0con .
generality, we can assume that for some c  con, tc1  T1con , tc2  T2con and t0c
1  T1
By adapting the proof of Halpern et al. (2004, Lemma 5.18) we can find a ]i-type t02 such
that t2 i t02 and t01  t02 . We define T20 as the set of all such t02 and T10con as the set of t0c
2.
Clearly, C02 = hT20 , T20con i is a consistent ]i-state candidate such that C2 i C02 , C01  C02 ,
and for c  con, P2 ci P02 and P01 c P02 .
For systems including the axiom KT4m we can define a synchronous version of the relation
 between k-trees.
Definition 26. If  and 0 are k-trees of state candidates for  then  sync
0 iff
f
0
 f  and for all C  , f (C) has exactly a length of 2. Similarly, if  and 0 are
k-trees of points for  then  sync
0 iff  f 0 and for all P  , f (P) has exactly a
f
length of 2.
37

fiBelardinelli & Lomuscio

For any c  con, the relation cf sync is defined similarly. We define a sync-acceptable
sequence of trees as an acceptable sequence where the relation  is substituted by the
relation sync , that is, the sequence  is acceptable if every sync -sequence compatible with
 is infinite and acceptable. Similarly, given the relations + and c+ for c  con, the
definitions of sync,+ and c sync,+ are straightforward. We now state the following result,
which is a simplified version of Lemma 20. The proof is analogous to that of Lemma 20, in
which Lemma 25 is used instead of Lemma 19.
Lemma 26. Let  be a k-tree of points and P   is a -point with || = k,
(a) If t0 is a -type and tree,P  (t0  ) is consistent, then there exists a k-tree 0
and a -point P0 = hC0 , t0 i  0 such that (, P) sync,+ (0 , P0 ) and tree0 ,P0   is
consistent. Further, if tc  T con then (, P) c sync,+ (0 , P0 ).
W
(b) ` tree,P   {(0 ,P0 )|(,P)sync,+ (0 ,P0 )} tree0 ,P0
(c) if tree,P  U 0 is consistent, then there exists a sequence 0 , . . . , l of k-trees and
points P0 , . . . , Pl such that (i) Pj  j for j  l; (ii) (0 , P0 ) = (, P); (iii)
(j , Pj ) sync,+ (j+1 , Pj+1 ) for j < l; (iv) treej ,Pj   is consistent for j < l;
and (v) treel ,Pl   0 is consistent. Further, if tc  T con then (iii) (j , Pj ) c sync,+
(j+1 , Pj+1 ) for j < l.
Further, we make use of Lemma 26 to adapt Lemma 21 and obtain the following result.
Lemma 27. If   L1m is consistent with QKT4m , then there exists a sync-acceptable
sequence  of ad()-trees of state candidates such that  belongs to the root of the first tree.
For any consistent   L1m we define a quasimodel+ for  to establish the completeness of QKT4m with respect to QIS nl,sync
. Let X be a new object, a sequence
m
X, . . . , X, Cn , Cn+1 , . . . is sync-acceptable from n if it starts with n copies of X and Cn , Cn+1 , . . .
is a sync-acceptable -sequence compatible with the ad()-tree . Let R consist of all sequences sync-acceptable from n, for some n  N. The function f is defined as f(r, k) = Ck if
r is the -sequence X, . . . , X, Cn , Cn+1 , . . . sync-acceptable from n and k  n; f(r, k) is undefined otherwise. Further, Let O be the set of functions  associating every (r, n)  Dom(f)
to a type (r, n)  Tr,n such that conditions (A), (B) and (C) are satisfied and the following
holds:
(H) if (r, n) i (r0 , n0 ) then (r, n + 1) i (r0 , n0 + 1).
Finally, for i  Ag,   O, (r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ) and n = n0 .
Similarly to Lemma 22, we can show the following.
Lemma 28. The set O of functions that satisfies conditions (A), (B), (C) and (H) above
is non-empty.
Moreover, the following result follows from Lemmas 6(i), 27 and 28.
Lemma 29. The tuple hR, O, {i, }iAg,O , fi is a frame that satisfies no learning and
synchronicity.
38

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Finally, by adapting the proof for Lemma 24 we can state the following result.
Lemma 30. The tuple hR, O, {i, }iAg,O , fi is a quasimodel+ for  with no learning
and synchronicity, and it validates the formulas K and BF .
This completes the proof for QKT4m . Thus, we obtain the following item in Theorem 2.
Theorem 8 (Completeness). The system QKT4m is complete w.r.t. the class QIS nl,sync
of
m
QIS.
5.6 The Classes QIS nl,pr
and QIS nl,pr,uis
m
1
To obtain the completeness proof for QIS nl,pr
we combine the results shown for QIS pr
m
m and
nl
QIS m .
2,3
If   L1m is consistent with QKTm
then by Lemma 21 there exists an acceptable
sequence  of ad()-trees such that  belongs to the root of the first tree. Let R be the
set of all acceptable -sequences that have a suffix that is compatible with , while the
function f is defined as in Section 5.2. Further, O is the set of all functions  associating
every (r, n)  Dom(f) to a type (r, n)  Tr,n that satisfies the conditions (A), (B), (C),
(E) and (G). Finally, for i  Ag,   O, (r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ).
Lemma 31. The set O of functions that satisfies conditions (A), (B), (C), (E) and (G)
is non-empty.
Proof. We can show that all conditions but (C) are satisfied similarly to the cases of
nl
QIS pr
m and QIS m . As to (C), suppose that (r, n) is a -type in f(r, n) and t is ]i-type.
Also,  is the sequence of ad()-trees 0 f0 1 f1 . . . of state candidates. The run r
is derived by definition from a -sequence C0 , C1 , . . . that has a suffix CN , CN +1 , . . . that is
compatible with , and f(r, n) = Cn . We consider two cases.
If n  N , then there exists some k  N such that Cn  k . By Lemma 11 there exists
a -sequence S0  . . .  Sh of ]i-state candidates such that t  Sh and S0 , . . . , Sh is
i -concordant with C0 , . . . , Cn . Further, we can assume that Sh  k and let Sh , Sh+1 , . . .
be the sequence compatible with . Now consider the -sequence S0  S1  . . ..
By construction the run r0 derived from this sequence is in R and we can assume that
(r0 , h) = t.
If n < N , then by Lemma 11 there exists a -sequence S0  . . .  Sh of ]i-state
candidates such that t  Sh and S0 , . . . , Sh is i -concordant with C0 , . . . , Cn . By Lemma 19
we can extend this sequence to a -sequence S0  . . .  Sk that is i -concordant
with C0 , . . . , CN . Since CN  M for some M  N, we can assume that Sk  M as
well. Let Sh , Sh+1 , . . . be the sequence compatible with , and consider the -sequence
S0  S1  . . .. As in the previous case, the run r0 derived from this sequence is in R by
construction and we can assume that (r0 , h) = t.
By Lemmas 6(i), 21 and 31 we obtain the next result.
Lemma 32. The tuple hR, O, {i, }iAg,O , fi is a frame that satisfies perfect recall and
no learning.
Finally, we state the following lemma, whose proof follows the lines of the corresponding
nl
proofs for QIS pr
m and QIS m and Lemma 31.
39

fiBelardinelli & Lomuscio

Lemma 33. The tuple hR, O, {i, }iAg,O , fi is a quasimodel+ for  that satisfies perfect
recall and no learning, and validates the formulas K and BF .
This establishes the completeness of QKT2,3 . Thus, we obtain the following item in
Theorem 2.
nl,pr
Theorem 9 (Completeness). The system QKT2,3
of
m is complete w.r.t. the class QIS m
QIS.

The completeness of QKT2,3
with respect to QIS nl,pr,uis
follows from the following
1
1
remark, whose proof is analogous to the propositional case.
Remark 3. A formula   L11 is satisfiable in QIS nl,pr
(resp. QIS nl,pr,sync
) iff it is
1
1
nl,pr,uis
nl,pr,sync,uis
satisfiable in QIS 1
(resp. QIS 1
).
5.7 The Class QIS nl,pr,sync
m
1,4
To prove the completeness of QKTm
with respect to QIS nl,pr,sync
we combine the results
m
nl,pr
obtained for QIS m in the previous section with those for QIS nl,sync
and QIS pr,sync
.
m
m
1,4
1
Specifically, if   Lm is consistent with QKTm by Lemma 27 we can construct a syncacceptable sequence  of ad()-trees such that  belongs to the root of the first tree. Let R
be the set of all sync-acceptable -sequences with suffixes that are compatible with ; and
the function f is defined as in Section 5.2. Further, O is the set of all functions  associating
every (r, n)  Dom(f) to a type (r, n)  Tr,n that satisfies the conditions (A), (B), (C),
(F) and (H). Finally, for i  Ag,   O, (r, n) i, (r0 , n0 ) iff (r, n) i (r0 , n0 ) and n = n0 .
By adapting the proof of Lemma 31 by means of Lemmas 15 and 25 we can show the
following result.

Lemma 34. The set O of functions that satisfies conditions (A), (B), (C), (F) and (H)
is non-empty.
By Lemmas 6(i), 27 and 34 we obtain the following result.
Lemma 35. The tuple hR, O, {i, }iAg,O , fi is a frame that satisfies perfect recall, no
learning and synchronicity.
Finally, we state the following lemma whose proof follows the lines of the corresponding
proofs for QIS pr,sync
, QIS nl,sync
and Lemma 34.
m
m
Lemma 36. The tuple hR, O, {i, }iAg,O , fi is a quasimodel+ for  that satisfies perfect
recall, no learning and synchronicity, and validates the formulas K and BF .
This completes the proof for QKT1,4
m . Thus, we obtain the following item in Theorem 2.
1,4
Theorem 10 (Completeness). The system QKTm
is complete w.r.t. the class QIS nl,pr,sync
m
of QIS.

40

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

5.8 The Classes QIS nl,sync,uis
and QIS nl,pr,sync,uis
m
m
1,4,5
We now show that the system QKTm
is complete with respect to the classes QIS nl,sync,uis
m
nl,pr,sync,uis
and QIS m
. The completeness result follows from next remark.

Remark 4. A formula   Lm is valid on QIS nl,sync,uis
iff it is valid in QIS nl,pr,sync,uis
.
m
m
The proof is a straightforward extension to first-order of a result by Halpern et al. (2004,
Proposition 5.22). Given this remark and the axiom KT5 it is sufficient to prove the
completeness of QKT1,4
with respect to QIS nl,pr,sync,uis
. By the result in the previous
1
1
1,4
nl,pr,sync
section, QKT1 is indeed complete with respect to QIS 1
. The desired result follows
by Remark 3. Thus, we obtain the following item in Theorem 2.
1,4
Theorem 11 (Completeness). The system QKTm
is complete w.r.t. the classes QIS nl,sync,uis
m
and QIS nl,pr,sync,uis
of
QIS.
m

6. Conclusions and Further Work
In this paper we investigated interaction axioms in the context of monodic first-order
temporal-epistemic logic. Specifically, we explored classes of quantified interpreted systems
satisfying conditions such as synchronicity, no learning, perfect recall, and having a unique
initial state. The contribution of the article concerns the provably complete axiomatisation
of these classes.
The results presented extend previous contributions on first-order epistemic and temporal logic with no interactions (e.g., see Belardinelli & Lomuscio, 2011, Sturm et al., 2000,
Wolter & Zakharyaschev, 2002), in a direction that was previously only explored at the
propositional level (Halpern et al., 2004). Our findings show that the characterisation
axioms considered at the propositional level can be extended to the first-order monodic
setting.
While temporal-epistemic logic in a first-order context has so far mostly attracted theoretical contributions, there is evidence in the literature of it being increasingly embraced
in applications. For instance, there is an active interest in verifying artifact-centric systems
against first-order modal specifications (Belardinelli, Lomuscio, & Patrizi, 2011a, 2011b;
Deutsch, Hull, Patrizi, & Vianu, 2009; Deutsch, Sui, & Vianu, 2007; Calvanese, Giacomo,
Lenzerini, & Rosati, 2012; Hariri, Calvanese, Giacomo, Masellis, & Felli, 2011).
Given this, it remains of importance to investigate the questions pertaining to computational aspects of the formalisms introduced, including their decidability and the computational complexity of the satisfiability and model checking problems. Work so far (including
Belardinelli & Lomuscio, 2011; Hodkinson at al., 2000; Wolter & Zakharyaschev 2001)
has focused on fragments where no interaction is present, but we know from the literature (Halpern et al., 2004) that interactions can make these problems harder. We leave this
for further work, particularly in connection with the addition of other epistemic modalities
(e.g., explicit and algorithmic knowledge, see Halpern & Pucella, 2005), or branching-time
modalities. Epistemic variants of branching-time CTL are well understood at the propositional level (Meyden & Wong, 2003) but their first-order extensions have not yet been
explored.
41

fiBelardinelli & Lomuscio

Acknowledgments
The research presented was supported by the European Commission through the Marie
Curie Fellowship FoMMAS (grant n. 235329) and the STREP Project ACSI (grant
n. 257593), and by the UK Engineering and Physical Sciences Research Council Leadership
Fellowship Trusted Autonomous Systems (grant n. EP/I00520X/1).
We would like to thank the anonymous reviewers and Mr. Andrew V. Jones for valuable
comments on the paper.

References
Belardinelli, F., & Lomuscio, A. (2009). Quantified epistemic logics for reasoning about
knowledge in multi-agent systems. Artificial Intelligence, 173 (9-10), 9821013.
Belardinelli, F., & Lomuscio, A. (2011). First-order linear-time epistemic logic with group
knowledge: An axiomatisation of the monodic fragment. Fundamenta Informaticae,
106 (2-4), 17590.
Belardinelli, F., & Lomuscio, A. (2008). A complete quantified epistemic logic for reasoning
about message passing systems. In Computational Logic in Multi-Agent Systems, 8th
International Workshop, CLIMA VIII. Revised Selected and Invited Papers, Vol. 5056
of Lecture Notes in Computer Science, pp. 248267. Springer.
Belardinelli, F., & Lomuscio, A. (2010). Interactions between time and knowledge in a firstorder logic for multi-agent systems. In Principles of Knowledge Representation and
Reasoning: Proceedings of the 12th International Conference, KR 2010. AAAI Press.
Belardinelli, F., Lomuscio, A., & Patrizi, F. (2011a). A computationally-grounded semantics for artifact-centric systems and abstraction results. In Proceedings of the 22nd
International Joint Conference on Artificial Intelligence, IJCAI 2011, pp. 738743.
AAAI Press.
Belardinelli, F., Lomuscio, A., & Patrizi, F. (2011b). Verification of deployed artifact systems via data abstraction. In Service-Oriented Computing: Proceedings of the 9th
International Conference, ICSOC 2011, Vol. 7084 of Lecture Notes in Computer Science, pp. 142156. Springer.
Calvanese, D., Giacomo, G. D., Lenzerini, M., & Rosati, R. (2012). View-based query
answering in description logics: Semantics and complexity. Journal of Computer and
System Sciences, 78 (1), 2646.
Cohen, P., & Levesque, H. (1995). Communicative actions for artificial agents. In Proceedings of the 1st International Conference on Multi-Agent Systems, ICMAS 1995, pp.
6572. AAAI Press.
Degtyarev, A., Fisher, M., & Konev, B. (2003). Monodic temporal resolution. In Automated
Deduction: Proceedings of the 19th International Conference on Automated Deduction,
CADE-19, Vol. 2741 of Lecture Notes in Computer Science, pp. 397411. Springer.
Degtyarev, A., Fisher, M., & Lisitsa, A. (2002). Equality and monodic first-order temporal
logic. Studia Logica, 72 (2), 147156.
Dennett, D. (1987). The Intentional Stance. MIT Press.
42

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Deutsch, A., Hull, R., Patrizi, F., & Vianu, V. (2009). Automatic verification of datacentric business processes. In Database Theory: Proceedings of the 12th International
Conference, ICDT 2009, Vol. 361 of ACM International Conference Proceeding Series,
pp. 252267. ACM Press.
Deutsch, A., Sui, L., & Vianu, V. (2007). Specification and verification of data-driven web
applications. Journal of Computer and System Sciences, 73 (3), 442474.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning about Knowledge.
MIT Press.
Fagin, R., Halpern, J. Y., & Vardi, M. Y. (1992). What can machines know? On the
properties of knowledge in distributed systems. Journal of the ACM, 39 (2), 328376.
Gabbay, D., Kurucz, A., Wolter, F., & Zakharyaschev, M. (2003). Many-Dimensional Modal
Logics: Theory and Applications, Vol. 148 of Studies in Logic. Elsevier.
Garson, J. (2001). Quantification in modal logic. In Gabbay, D., & Guenthner, F. (Eds.),
Handbook of Philosophical Logic, Vol. 3, pp. 267323. Reidel.
Halpern, J., & Moses, Y. (1992). A guide to completeness and complexity for modal logics
of knowledge and belief. Artificial Intelligence, 54, 319379.
Halpern, J., van der Meyden, R., & Vardi, M. (2004). Complete axiomatizations for reasoning about knowledge and time. SIAM Journal on Computing, 33 (3), 674703.
Halpern, J., & Vardi, M. (1986). The complexity of reasoning about knowledge and time.
In ACM Symposium on Theory of Computing, STOC 1986, pp. 304315. ACM Press.
Halpern, J., & Vardi, M. (1989). The complexity of reasoning about knowledge and time
1: lower bounds. Journal of Computer and System Sciences, 38 (1), 195237.
Halpern, J., & Pucella, R. (2005). Probabilistic algorithmic knowledge. Logical Methods in
Computer Science, 1 (3).
Hariri, B. B., Calvanese, D., Giacomo, G. D., Masellis, R. D., & Felli, P. (2011). Foundations
of relational artifacts verification. In Business Process Management: Proceedings of
the 9th International Conference, BPM 2011, Vol. 6896 of Lecture Notes in Computer
Science, pp. 379395. Springer.
Hodkinson, I. (2002). Monodic packed fragment with equality is decidable. Studia Logica,
72, 185197.
Hodkinson, I. (2006). Complexity of monodic guarded fragments over linear and real time.
Annals of Pure and Applied Logic, 138, 94125.
Hodkinson, I., Kontchakov, R., Kurucz, A., Wolter, F., & Zakharyaschev, M. (2003). On the
computational complexity of decidable fragments of first-order linear temporal logics.
In Proceedings of the 10th International Symposium on Temporal Representation and
Reasoning / 4th International Conference on Temporal Logic, TIME-ICTL 2003, pp.
9198. IEEE Computer Society Press.
Hodkinson, I., Wolter, F., & Zakharyaschev, M. (2000). Decidable fragment of first-order
temporal logics. Annals of Pure and Applied Logic, 106 (1-3), 85134.
43

fiBelardinelli & Lomuscio

Hodkinson, I., Wolter, F., & Zakharyaschev, M. (2002). Decidable and undecidable fragments of first-order branching temporal logics. In Proceedings of the 17th IEEE Symposium on Logic in Computer Science, LICS 2002, pp. 393402. IEEE Computer
Society Press.
Lomuscio, A., & Ryan, M. (1998). On the relation between interpreted systems and Kripke
models. In Agent and Multi-Agent Systems: Proceedings of the AI97 Workshop on the
theoretical and practical foundations of intelligent agents and agent-oriented systems,
Vol. 1441 of Lecture Notes in Artificial Intelligence, pp. 4659. Springer.
McCarthy, J. (1979). Ascribing mental qualities to machines. In Ringle, M. (Ed.), Philosophical Perspectives in Artificial Intelligence, pp. 161195. Harvester Press.
McCarthy, J. (1990). Artificial intelligence, logic and formalizing common sense. In Thomason, R. (Ed.), Philosophical Logic and Artificial Intelligence, pp. 161190. Kluwer
Academic.
Meyden, R. (1994). Axioms for knowledge and time in distributed systems with perfect
recall. In Proceedings of the 9th Annual IEEE Symposium on Logic in Computer
Science, LICS 1994, pp. 448457. IEEE Computer Society Press.
Meyden, R. v., & Wong, K. (2003). Complete axiomatizations for reasoning about knowledge
and branching time. Studia Logica, 75 (1), 93123.
Moore, R. C. (1990). A formal theory of knowledge and action. In Allen, J., Hendler, J., &
Tate, A. (Eds.), Readings in Planning, pp. 480519. Kaufmann.
Parikh, R., & Ramanujam, R. (1985). Distributed processes and the logic of knowledge. In
Logics of Programs, Conference Proceedings, Vol. 193 of Lecture Notes in Computer
Science, pp. 256268. Springer.
Pnueli, A. (1977). The temporal logic of programs. In Proceedings of the 18th International
Symposium Foundations of Computer Science, FOCS 1977, pp. 4657.
Rao, A., & Georgeff, M. (1991). Deliberation and its role in the formation of intentions.
In Proceedings of the 7th Conference on Uncertainty in Artificial Intelligence, pp.
300307. Kaufmann.
Sturm, H., Wolter, F., & Zakharyaschev, M. (2000). Monodic epistemic predicate logic.
In Logics in Artificial Intelligence, European Workshop, JELIA 2000, Vol. 1919 of
Lecture Notes in Computer Science, pp. 329344. Springer.
Sturm, H., Wolter, F., & Zakharyaschev, M. (2002). Common knowledge and quantification.
Economic Theory, 19, 157186.
Wolter, F., & Zakharyaschev, M. (2001). Decidable fragments of first-order modal logics.
Journal of Symbolic Logic, 66 (3), 14151438.
Wolter, F., & Zakharyaschev, M. (2002). Axiomatizing the monodic fragment of first-order
temporal logic. Annals of Pure and Applies Logic, 118 (1-2), 133145.
Wooldridge, M. (2000a). Computationally grounded theories of agency. In Proceedings of
the International Conference of Multi-Agent Systems, ICMAS 2000, pp. 1322. IEEE
Computer Society Press.
44

fiInteractions between Knowledge and Time in a First-Order Logic for MAS

Wooldridge, M. (2000b). Reasoning about Rational Agents. MIT Press.
Wooldridge, M., & Fisher, M. (1992). A first-order branching time logic of multi-agent
systems. In Proceedings of the 10th European Conference on Artificial Intelligence,
ECAI 1992, pp. 234238. John Wiley and Sons.
Wooldridge, M., Fisher, M., Huget, M., & Parsons, S. (2002). Model checking multi-agent
systems with MABLE. In Proceedings of the 1st International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2002, pp. 952959. ACM Press.
Wooldridge, M., Huget, M., Fisher, M., & Parsons, S. (2006). Model checking for multiagent
systems: the MABLE language and its applications. International Journal on Artificial
Intelligence Tools, 15 (2), 195226.
Wooldridge, M. (1999). Verifying that agents implement a communication language. In
Proceedings of the 16th National Conference on Artificial Intelligence and 11th Conference on Innovative Applications of Artificial Intelligence, pp. 5257. AAAI Press.

45

fiJournal of Artificial Intelligence Research 45 (2012) 761-780

Submitted 08/12; published 12/12

Evaluating Indirect Strategies for ChineseSpanish
Statistical Machine Translation
Marta R. Costa-jussa

vismrc@i2r.a-star.edu.sg

Institute for Infocomm Research,
Singapore 138632

Carlos A. Henrquez Q.

carlos.henriquez@upc.edu

Universitat Politecnica de Catalunya,
08034 Barcelona

Rafael E. Banchs

rembanchs@i2r.a-star.edu.sg

Institute for Infocomm Research,
Singapore 138632

Abstract
Although, Chinese and Spanish are two of the most spoken languages in the world,
not much research has been done in machine translation for this language pair. This
paper focuses on investigating the state-of-the-art of Chinese-to-Spanish statistical machine
translation (Smt), which nowadays is one of the most popular approaches to machine
translation. For this purpose, we report details of the available parallel corpus which
are Basic Traveller Expressions Corpus (Btec), Holy Bible and United Nations (Un).
Additionally, we conduct experimental work with the largest of these three corpora to
explore alternative Smt strategies by means of using a pivot language. Three alternatives
are considered for pivoting: cascading, pseudo-corpus and triangulation. As pivot language,
we use either English, Arabic or French. Results show that, for a phrase-based Smt system,
English is the best pivot language between Chinese and Spanish. We propose a system
output combination using the pivot strategies which is capable of outperforming the direct
translation strategy. The main objective of this work is motivating and involving the
research community to work in this important pair of languages given their demographic
impact.

1. Introduction
Chinese and Spanish are very distant languages in many aspects. However, they come close
together in the ranking of most spoken languages in the world (Ethnologue, 2012). In the
Web 2.0 era, in which most of the content is produced by the users, the number of native
speakers is an excellent indicator of the actual relevance of machine translation between two
languages. Of course, other factors such as literacy, amount of text published and strength
of commercial relationships are also to be taken into account, but these factors will actually
support further our idea of the strategic importance of developing machine translation
technologies between Chinese and Spanish. The huge increase in volume of online contents
in Chinese during the last years, as well as the steady increase of commercial relationships
between Spanish speaking Latin American countries and China are just two basic examples
supporting this fact. Needless to say, these languages involve many economical interests
c
2012
AI Access Foundation. All rights reserved.

fiCosta-jussa, Henrquez & Banchs

(Zapatero, 2010). Nevertheless, these two languages seem to become far apart again when
looking for bilingual resources.
We have been recently interested in gathering and collecting ChineseSpanish bilingual
resources for research and machine translation application purposes. The amount of bilingual resources that are currently available for this specific language pair is surprisingly low.
Similarly, the related amount of work we have found, within the computational linguistic
community, can be reduced to a very small set of references (Banchs, Crego, Lambert, &
Marino, 2006; Banchs & Li, 2008; Bertoldi, Cattoni, Federico, & Barbaiani, 2008; Wang,
Wu, Hu, Liu, Li, Ren, & Niu, 2008). Apart from the Btec1 corpus available through International Workshop on Spoken Language Translation (Iwslt) competition (Bertoldi et al.,
2008) and Holy Bible datasets (Banchs & Li, 2008), we were not aware of any other Chinese
Spanish parallel corpus suitable for training phrase-based (Koehn, Och, & Marcu, 2003)2
statistical machine translation systems between these two languages, until a six-language
parallel corpus (including both Chinese and Spanish) from United Nations was released for
research purposes (Rafalovitch & Dale, 2009).
Using the recently released United Nations parallel corpus as a starting point, this work
focuses on the problem of developing Chinese-to-Spanish phrase-based machine translation
technologies with a limited set of bilingual resources. We explore and evaluate different
alternatives for the problem in hand by means of pivot-language strategies through other
languages available in the United Nations parallel corpus, such as Arabic, English and
French 3 . Existing strategies such as system cascading, pseudo-corpus generation and triangulation are implemented and compared against a baseline system built with a direct
translation approach. As follows, we briefly describe these pivot approaches:
 The cascaded approach generates Chinese-to-Spanish translations by concatenating a
system that translates Chinese into a pivot language with a system that translates
from the pivot language into Spanish.
 The pseudo-corpus approach builds a synthetic ChineseSpanish corpus either by
translating into Spanish the pivot side of a Chinesepivot corpus or by translating
into Chinese the pivot side of a PivotSpanish corpus.
 The triangulation approach implements a Chinese-to-Spanish translation system by
combining the translation table probabilities of a Chinesepivot system and a Pivot
Spanish system.
Additionally, we implement and evaluate a system combination of the three pivot strategies based on the minimum Bayes risk (Mbr) (Kumar & Byrne, 2004) technique. Such a
combination strategy is capable of outperforming the direct system.
Besides experimenting with different pivot languages to compare the mentioned approaches, we also wanted to determine which pivot alone gives the best results and why.
1. Basic Traveller Expressions Corpus.
2. Note that phrase-based is commonly used to refer to statistical machine translation systems, in which
the term phrase refers to segments of one or more than one word and it does not have the usual meaning
of multi-word syntactical consitutent, as it has in linguistics.
3. Although Russian is available in the Un corpus, we discard to use it because we do not have the proper
preprocessing tools for it.

762

fiEvaluating Indirect Strategies for ChineseSpanish SMT

Hence, we present a short comparison of the amount of reordering and vocabulary sizes of
pivot languages, following the study presented by Birch et al. (2008) where they identified
these two properties as key elements for predicting machine translation quality. The results
from such comparisons, together with the translation quality obtained in the different approaches, show that English was the best pivot language for Chinese-to-Spanish translation
purposes in our experimental framework.
The paper is structured as follows. Section 2 motivates this work which is intended to
bring some light into the investigation of Chinese-to-Spanish translation task. Section 3
presents some related work in the Chinese-to-Spanish translation task. Section 4 reports
the details of the main parallel corpora available for this translation task. Next, section
5 describes the main strategies for performing Chinese-to-Spanish translation which are
tested in this work: direct, cascade, pseudo-corpus and triangulation. Section 6 presents
the evaluation framework which includes the corpus statistics, the system and evaluation
details. Then, section 7 reports the experiments (including the system combination) and
the results. Finally, section 8 concludes our work and proposes new research directions in
the area.

2. Motivation
Although some current web translation systems allow for performing translations between
Chinese and Spanish, the quality of current Chinese-to-Spanish translations is still well
below the quality achieved for other language pairs, such as English to Spanish. As far as
we know, there is not much research in this translation task. The main reason may be the
lack of parallel corpora. This study intends to make progress and involve other researchers
in the area of ChineseSpanish statistical machine translation by:
1. Listing the available parallel corpora for ChineseSpanish.
2. Comparing different methodologies for performing statistical machine translation: cascaded (Wang et al., 2008), pseudo-corpus generation (Banchs et al., 2006; de Gispert
& Marino, 2006) and triangulation (Wu & Wang, 2007).
3. Evaluating which is the best language (among Arabic, English and French) for generating the cascade, pseudo-corpus or triangulation Mt between ChineseSpanish.
4. Performing an output system combination to explore new ways of improving Chineseto-Spanish translation.

3. Related Work
One of the first works dealing with ChineseSpanish statistical machine translation was
presented by Banchs et al. (2006). Authors experimented with two independent corpora
ChineseEnglish and EnglishSpanish to translate from Chinese to Spanish. They built
their translation systems using the so-called Ngram-based approach, which differs from
the phrase-based system mainly in the translation and reordering model (Marino, Banchs,
Crego, de Gispert, Lambert, Fonollosa, & Costa-jussa, 2006).
763

fiCosta-jussa, Henrquez & Banchs

The only research event recently performed for this language pair was the 2008 Iwslt
evaluation campaign (Paul, 2008). This evaluation organized two Chinese-to-Spanish tracks.
One of them focused on direct translation and the other one on pivot translation through
English. The best translation results accordingly to the manual evaluation were obtained
by far in the pivot task.
The best systems in both tracks were developed by Wang et al. (2008). Regarding the
direct system, they used a standard phrase-based Smt system. What makes it different from
the other participating systems is that they provide their own Chinese segmentation and
the Ldc (Linguistic Data Consortium) bilingual dictionary. Regarding the pivot task, they
compared two different approaches. The first one, referred to as triangulation, consisted of
training two translation models on the ChineseEnglish corpus and EnglishSpanish corpus,
and then building a new translation model for ChineseSpanish translation by combining
the two previous models as proposed by Wu & Wang (2007); the second one obtained better
results and it was based on a cascaded approach. The idea here is to translate from Chinese
into English and then from English into Spanish, which means performing two translations.
Other participants also proposed the cascaded methodology. This approximation can be
done with the n-best translations (Khalilov, Costa-Jussa, Henrquez, Fonollosa, Hernandez,
Marino, Banchs, Chen, Zhang, Aw, & Li, 2008).
Another proposal was to generate pseudo-corpus which means to translate either the
English into Chinese or into Spanish, creating a parallel ChineseSpanish corpus. This
pseudo-corpus is used to train the ChineseSpanish translation (Bertoldi et al., 2008).
As mentioned aboved, the comparison performed by Wang et al. (2008) showed that the
cascaded approach performed better than the phrase-table combination for the Chinese
Spanish pivot task.
Finally, our previous work (Costa-jussa, Henrquez, & Banchs, 2011b) compared two
standard pivot approaches (pseudo-corpus and cascaded) using English and the direct system. Experiments in this work showed that the quality between the direct system and the
pivot systems did not differ much. Additionally, the cascaded system presented slightly
better results than the pseudo-corpus system. In our other previous work (Costa-jussa,
Henrquez, & Banchs, 2011a), we compared again two pivot approaches (pseudo-corpus and
cascaded) using Arabic, French and English as pivot languages and the direct system. We
concluded that English was the best pivot language.
In the present work, we are extending the two previous studies by: (1) using more pivot
strategies (including the triangulation strategy); (2) introducing a measure to pre-evaluate
the quality of pivot approaches; (3) extending the pivot combination experiments; and (4)
providing further evaluation.
Note that we are working with the United Nations (Un) corpus rather than with the
Btec corpus (the one used in the Iwslt). The former is freely available and larger than
the latter.

4. ChineseSpanish Parallel Corpora
There are very limited resources for the language pair ChineseSpanish in comparison to
the number of native speakers in these languages. In practice, it is also common to translate
Chinese into Spanish through English even when manual translations are conducted.
764

fiEvaluating Indirect Strategies for ChineseSpanish SMT

As parallel corpus at the sentence level, there is the Basic Travel Expressions Corpus
(Btec) (Paul, Yamamoto, Sumita, & Nakamura, 2009), which is a collection of sentences
that bilingual travel experts consider useful for people going to or coming from another
country. This corpus contains around 160,000 parallel sentences but only around 20,000
sentences and 180,000 words are actively used for Mt purposes in the Iwslt evaluation
campaign. The full corpus is not freely available, and the 20,000 version was only available
for participation purposes in the 2008 Iwslt evaluation campaign.
Another parallel corpus is the Holy Bible, which has been proved to be a good resource for
CLIR (Cross-language information retrieval) (Chew, Verzi, Bauer, & McClain, 2006). This
corpus contains around 28,000 parallel sentences and around 800,000 tokens per language.
The main advantages of using this corpus is that it is the worlds most translated book; it
covers a variety of literary styles including narrative, poetry, and correspondence; great care
is taken over the translations; and, perhaps surprisingly, its vocabulary appears to have a
high rate of coverage (as much as 85%) of modern-day language.
Finally, there is the United Nations multilanguage corpus (Rafalovitch & Dale, 2009),
which is freely available online for research purposes. Among others, it contains parallel
texts at the sentence level in the following languages: Chinese, English, Spanish, French and
Arabic. It consists of 2100 United Nations General Assembly resolutions with translation in
the six official languages of the United Nations, with average of around 3 million tokens per
language. This is the material that we are using in this work. Table 1 shows the statistics
of the three different corpora with their corresponding languages.
Corpus
Btec
Holy
Bible

Un

Lang.
Chinese
English
Spanish
Chinese
English
Spanish
Chinese
English
Spanish
Arabic
French

Sent.
20
20
20
30
30
30
60
60
60
60
60

Words
164
182
147
814
908
836
1,750
2,080
2,380
2,720
2,380

Vocab.
8
8
17
13
12
27
18
15
20
17
18

Avg. sent. length
6
7
9
26
29
27
28
34
39
44
39

Table 1: Available corpora for ChineseSpanish (all figures are given in thousands, except
the average sentence length)

Additionally, we can surf the web and find several publications which are available both
in Chinese and Spanish e.g. Global Asia Magazine (2012), but this additional material consists mainly of comparable corpora rather than parallel corpora. This comparable material
cannot directly be used in a statistical machine translation system. However, there are
many nice algorithms which can extract parallel corpora from comparable corpora (Moore,
2002; Senrich, 2010; Abdul-Rauf, Fishel, Lambert, Noubours, & Sennrich, 2012).
765

fiCosta-jussa, Henrquez & Banchs

5. Direct and Pivot Statistical Machine Translation Approaches
There are several strategies that we can follow when translating a pair of languages in
statistical machine translation (Smt). In this section we present the details of the ones we
are using in this work.
In general, a statistical machine translation system relies on the translation of a source
language sentence s into a target language sentence t. Among all possible target language
sentences t we choose the one with the highest probability, as show in equation (2):

t = arg max [P (t|s)]

(1)

t

= arg max [P (t) P (s|t)]
t

(2)

This probability decomposition based on Bayes theorem is known as the source-channel
approach to statistical machine translation (Brown, Cocke, Della Pietra, Della Pietra, Jelinek, Lafferty, Mercer, & Roossin, 1990). It allows to model independently the target
language model P (t) and the source translation model P (s|t). On the one hand, the translation model weights how likely words in the foreign language are translation of words in the
source language; the language model, on the other hand, measures the fluency of hypothesis
t. The search process is represented as the arg max operation.
Later on, a variation was proposed by Och & Ney (2002) named log-linear model. It
allows using more than two models or features and to weight them independently as can be
seen in equation (3):
t = arg max
t

" M
X

#

m hm (s, t)

(3)

m=1

This equation should be interpreted as a maximum-entropy framework. We see that eq.
(2) is a special case of eq. (3). In fact, it is the logarithm of (2) which would be similar
to (3). Then, we have to identify h1 (s, t) with log(p(t)) and h2 (s, t) with log(p(s|t)), and
taking M = 2 (two models) and 1 = 2 = 1. In the general case, s are obtained by
maximizing an objective function on a held-out set (development set).
Among the additional features that can be used with the log-linear model we have lexical
models, word bonus, and the reordering model. The lexical models are particularly useful in
cases where the translation model may be sparse. For example, for phrases which may have
appeared few times the translation model probability may not be well estimated. Then, the
lexical models provide a probability among words (Koehn et al., 2003). The word bonus
is used to compensate the language model which benefits shorter outputs. The reordering
model is used to provide reordering between phrases. If not, reordering would only be
treated internally in each phrase. Finally, it should be mentioned that the name log-linear
is clearly a misnomer as many of these features are not logarithms at all.
As regards the reordering model, the standard way of implementing it is with a distancebased model that gives a linear cost depending on the reordering distance. For instance,
if consecutive target words t1 , t2 come from translating source words s1 and s5 , where the
sub-scripts indicate the word position in their corresponding sentences, then a movement
766

fiEvaluating Indirect Strategies for ChineseSpanish SMT

Figure 1: Word alignment between two sentences
of d = 5  1 = 4 words has taken place and its cost should be double than a movement of
d = 2 words. A visual representation of these phrases can be seen in Figure 1
Besides the traditional distance-based reordering mentioned before, state-of-the-art systems implement an additional lexicalized reordering model (Tillman, 2004). The lexicalized
reordering model classifies phrases by the movement they make relative to the previous used
phrase, i.e., for each phrase the model learns how likely it is followed by the previous phrase
(monotone), swapped with it (swap) or not connected at all (discontinuous). For instance,
considering again sub-scripts as word positions in their corresponding sentences, in Figure
1 the bilingual phrases (s1  t1 ) and (s5  t2 ) are not connected, (s7  t6 ) is followed by
(s6  t5 ) and (s2  t4 ) is swapped with (s3 s4  t3 ).
5.1 Direct System
Our direct system uses the phrase-based translation approach (Koehn et al., 2003). The
basic idea is to segment the given source sentence s into segments of one or more words,
then each source segment is translated using a bilingual phrase obtained from the training
corpus and finally compose the target sentence from these phrase translations. A bilingual
phrase is a pair of m source words and n target words extracted from a parallel sentence
that belongs to a bilingual corpus previously aligned by words. For extraction, we consider
the words that are consecutive in both source and target sides and which are consistent
with the word alignment. We consider a phrase is consistent with the word alignment if no
word inside the phrase is aligned with one word outside the phrase.
Regarding the segmentation of the sentence in K phrases, we assume that all possible
segmentations (which are considered as a hidden variable M ) have the same probability
(t):

P (s|t) =

X

P (s, M |t)

(4)

P (M |t)P (s|t)

(5)

M

=

X
M

= (t)

X

P (s|t)

(6)

M

Then, we consider only monotone translations so the phrase sk is produced by tk (Zens,
Och, & Ney, 2002).

P (s|t) =

K
Y
k=1

767

p(sk , tk )

(7)

fiCosta-jussa, Henrquez & Banchs

Finally, phrase translation probabilities are estimated as relative frequencies over all
bilingual phrases in the corpus.

p (s|t) =

N (s, t)
N (t)

(8)

where N (s, t) counts the number of times the phrase s is translated as t and N (t) the
number of times the phrase in the target language appears in the training corpus.
5.2 Pivot-Based Systems
The cascaded approach handles the sourcepivot and the pivottarget system independently. They are both built and tuned to improve their local translation quality and then
composed to translate from the source language to the target language in two steps: first,
the translation output from source to pivot is computed and then it is used to obtain the
target translation output.
The pseudo-corpus approach translates the pivot section of the sourcepivot parallel corpus to the target language using a pivottarget system built previously. Then, a
sourcetarget Smt system is built using the source side and the translated pivot side of the
sourcepivot corpus. The pseudo-corpus system is tuned using an original sourcetarget
development corpus, since we have it available.
The triangulation approach combines the sourcepivot (P (s|p) and P (p|s)) and pivot
target (P (p|t) and P (t|p)) relative frequencies following the strategy proposed by Cohn &
Lapata (2007) in order to build a sourcetarget translation model. The translation probabilities are computed assuming the independence between the source and target phrases
when given the pivot phrase.

P (s|t) =

X

P (s|p)P (p|t)

(9)

P (t|p)P (p|s)

(10)

p

P (t|s) =

X
p

where s, t, and p represent phrases in the source, target and pivot language respectively.
The lexical weights are computed in a similar manner, following the strategy proposed
by Cohn & Lapata (2007). This approach does not handle the lexicalized reordering and
the other pivot strategies and therefore represents a limitation in its potential. Instead, a
simple distance-based reordering is applied during decoding. This model gives a cost linear
to the reordering distance. For instance, skipping over two words costs twice as much as
skipping over one word.
Once the corresponding translation model have been obtained, the sourcetarget system
is tuned using the same original sourcetarget development corpus mentioned in the previous
approach.
768

fiEvaluating Indirect Strategies for ChineseSpanish SMT

6. Evaluation Framework
The following section introduces the details of the evaluation framework. We report the
statistics of the Un corpus, a description of how we built the systems and the evaluation
details.
6.1 Corpus Statistics
As far as we know, and as discussed in section 4, three parallel corpora are available for
the ChineseSpanish language pair: Btec, Holy Bible and Un.4 The former was used in
the 2008 Iwslt and complete experiments of pivot strategies are reported in works such
as Bertoldi et al. (2008). The Holy Bible was used for the similar purposes by Henrquez,
Banchs & Marino (2010).
In this study we decide to use the Un corpus taking advantage of the fact that it is
the largest corpus (among those three) and it contains the same sentences in six languages,
therefore we can experiment with different pivot languages.
When experimenting with different pivot languages, in order to make the systems as
comparable as possible, we first did a sentence selection over the corpus so all systems were
built exactly with the same training, tuning and testing sets. This selection process was as
follows:
1. All corpora were tokenized, using the standard tokenizer available in Moses (Koehn,
Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer,
Bojar, Constantin, & Herbst, 2007) for Spanish, English and French; ictclass (Zhang,
Yu, Xiong, & Liu, 2003) for Chinese; and Mada+Tokan (Habash & Rambow, 2005)
for Arabic.
2. The Spanish, English and French corpora were lowercased.
3. If a sentence had more than 100 words in any language, it was deleted from all corpora.
4. If a sentence pair had a word ratio larger than three for any Chinesepivot or pivot
Spanish parallel corpora, it was deleted from all corpora.
5. To extract the tuning and test sets we identified all sentences ocurring once in the
corpora for all languages. The tuning and testing sets were drawn over these sentences
to assure they do not appear in the training corpus. Additionally, from these sentences,
we want to select those which differ most from the sentences in the training set and
which have the lowest out-of-vocabulary rate. In order to do this, the perplexity over
the English language model was computed on a sentence-by-sentence basis by using
a leave-one-out strategy; then, we selected the two thousand sentences which had the
highest perplexity and the lowest ratio of out-of-vocabulary words for constructing
the tuning and testing sets. The highest perplexity criterion was used in order to
avoid that tuning and test sentences were similar from the ones in the training set.
The lowest out-of-vocabulary words criterion was used to minimize the number of outof-vocabulary words in the tuning and test translation. The two criteria were used
4. During the review process of this paper, we have been aware of a new corpus KDE (K Desktop Environment), which is available from the recent OPUS project 5

769

fiCosta-jussa, Henrquez & Banchs

sequentially, first we selected the sentences with the highest perplexity, and among
them, we selected those with the lowest ratio of out-of-vocabulary words.
Table 2 shows the main statistics for all corpora used once divided for experimentation.
Dataset

Train

Dev.

Test

Lang.
Chinese
Spanish
English
Arabic
French
Chinese
Spanish
English
Arabic
French
Chinese
Spanish
English
Arabic
French

Sent.
58
58
58
58
58
1
1
1
1
1
1
1
1
1
1

Words
1,700
2,300
2,000
2,600
2,300
33.0
43.4
37.4
48.8
44.1
33.7
44.2
38.1
49.3
44.9

Vocab.
17
20
14
17
18
3
5
4.2
4.6
5
3.8
5
4.2
4.6
5

Table 2: Un Corpus Statistics used for this research (all figures are given in thousands)

6.2 System Implementation and Evaluation Details
Our systems were build using revision 4075 of Moses (Koehn et al., 2007). For all systems,
we used the default Moses parameters which includes the grow-diagonal-final-and word
alignment symmetrization, the lexicalized reordering (where possible), relative frequencies,
lexical weights and phrase bonus for the translation model (with phrases up to length 10), a
5-gram language model using Kneser-Ney smoothing and a word penalty model. Therefore,
14 different features are combined in equation (3). The language model was built using
Srilm (Stolcke, 2002) version 1.5.12. The optimization was done using Mert (Och, 2003).
For word aligning we used Giza++ (Och & Ney, 2000) version 1.0.5.
In order to evaluate the translation quality, we used Bleu (Papineni, Roukos, Ward,
& Zhu, 2001), Ter (Snover, Dorr, Schwartz, Micciulla, & Makhoul, 2006) and Meteor
(Banerjee & Lavie, 2005) automatic evaluation metrics.
Additionally, significance tests were performed to study when a system was better than
the other. These tests followed the pair bootstrap resampling method presented by Koehn
(2004): Given two translation outputs coming from two different systems, we created two
new virtual test sets by drawing sentences with replacement from the translation outputs.
Once we obtained them, we computed their Bleus and observed which system performs
better. This procedure was repeated 1, 000 times. At the end, if one of the systems outperformed the other 99% of the time, we concluded that it was indeed a better Bleu score
with 99% statistical significance.
770

fiEvaluating Indirect Strategies for ChineseSpanish SMT

7. ChineseSpanish Machine Translation Strategies
Given the different languages available in the Un corpora, we tested three different language
pivots. Additionally, we compared the cascaded, pseudo-corpus and triangulation pivot
strategies. Finally, we tried to combine the system outputs to improve the translation.
7.1 Experimenting with Different Pivot Languages
We built and compared several translation approaches in order to study the impact of
the different pivot languages when translating from Chinese into Spanish. Moreover, we
evaluated how the quality of pivot approaches differs from a direct system. We built the
pivot systems using five of the languages available in the Un parallel corpus: English,
Spanish, Chinese, Arabic and French, and we built the direct system on a ChineseSpanish
parallel corpus.
In particular, we experimented with the following Chinese-to-Spanish systems: the direct
Chinese-to-Spanish system as a quality upper bound; three cascaded, three pseudo-corpus
and three triangulation approaches, using English, Arabic and French as pivots. In order
to build the pivot systems, we need the corresponding Chinesepivot and pivotSpanish
systems.
Table 3 shows the Bleu, Ter and Meteor scores achieved with the intermediate
systems trained with the Un Corpus that were later used to built the different pivot approaches. Meteor score for the Chinese-to-Arabic system is not shown as we did not have
the postprocessing tools required for the language.

ChineseEnglish
ChineseArabic
ChineseFrench
EnglishSpanish
ArabicSpanish
FrenchSpanish

Bleu
35.67
46.11
28.31
51.22
41.79
46.42

Ter
51.07
56.12
63.21
32.02
44.37
40.25

Meteor
36.77

47.35
70.12
60.22
64.76

Table 3: Pivot Systems.
Table 4 shows the results for our Chinese-to-Spanish configurations with the Un corpus.
We can see there that the best pivot system used the pseudo-corpus approach with English
as the pivot language.
In Chinese-to-Spanish, the fact that the pseudo-corpus through English outperforms
cascaded through English according to the Bleu score is not statistically significant, with
a 99% confidence (Koehn, 2004). These results, however, are coherent with previous works
using the same language pair (Bertoldi et al., 2008; Henrquez Q. et al., 2010) that also
reported the pseudo-corpus strategy was better than the cascaded strategy. The cascaded
and pseudo-corpus approaches through English are statistically significantly better than the
triangulation approach, with a 99% confidence. To the best of our knowledge, reasons why
one pivot approach is better than the other are not reported in the literature. Moreover,
given that difference among approaches such as pseudo-corpus as cascaded approaches is
771

fiCosta-jussa, Henrquez & Banchs

Languages

System

Bleu

Ter

Meteor

Pivot vocab.

ChineseSpanish
ChineseEnglishSpanish
ChineseFrenchSpanish
ChineseArabicSpanish
ChineseEnglishSpanish
ChineseFrenchSpanish
ChineseArabicSpanish
ChineseEnglishSpanish
ChineseFrenchSpanish
ChineseArabicSpanish

direct
cascaded
cascaded
cascaded
pseudo
pseudo
pseudo
triangulation
triangulation
triangulation

33.06
32.90
30.37
28.88
32.97
32.61
32.23
32.05
30.41
30.61

57.32
56.67
60.33
60.37
57.39
57.43
57.47
57.91
59.70
59.53

53.96
54.06
50.96
50.15
53.99
53.55
53.27
53.37
51.51
51.43

14k
18k
17k
14k
18k
17k
14k
18k
17k

Table 4: Chinese-to-Spanish cascaded, pseudo-corpus and triangulation approaches.
not significant, it is better to perform experiments for each particular task and language
pair.
In all three approaches, according to the scores in table 4 English is the best pivot
language, with a statistical signicance of 99%, which is coherent with the pivotSpanish
results in table 3.
As follows, we use a procedure to predict the most suitable pivot language and justify
why a language may be a better pivot than another. For example, the pivot vocabulary
sizes play an important role. Birch et al. (2008) concluded in their study that the target
vocabulary size has a negative impact in the translation quality as measured with the Bleu
score and it can be seen that Arabic and French have both a larger vocabulary size than
English.
Apart from the vocabulary size, the research mentioned above also measured the success
of machine translation in terms of word reordering, i.e., differences in word order that occur
in a parallel corpus, which are mainly driven by syntactic differences between the languages.
In order to measure reordering in translation they assumed that reordering only occurs
between two adjacent blocks in the source side. This simplification allowed them to detect
a extract all reordering in a deterministic way.
A block As is defined by Birch et. al. (2008) as a segment of consecutive source words
(source span) which is aligned to a set of target words. The target words also form a block
At . With the definition of block set, they formally defined a reordering r as two blocks
A and B that are adjacent in the source, the relative order of the blocks in the source is
reversed in the target and the reordering is consistent. A reordering between blocks As
and Bs is consistent if the block Cs , consisting of the union of blocks As and Bs , is also
consistent. A block As is said to be consistent if the span defined by its corresponding
target block At does not contain words that are aligned to source words outside of As . This
definition of a consistent block is equivalent to the definition of a phrase in the phrase-based
machine translation paradigm. Finally, the set of all reorderings r in a sentence is defined
as R and it is unique for a given pair of sentences. Summarizing, this concept of reordering
is equivalent to the swap movement described in the lexicalized reordering at the end of
section 5.
772

fiEvaluating Indirect Strategies for ChineseSpanish SMT

Languages
ChineseEnglishSpanish
ChineseFrenchSpanish
ChineseArabicSpanish

SourcePivot
0.3955
0.6200
0.6921

PivotTarget
0.2124
0.0170
0.0908

Average
0.3039
0.3185
0.3914

Table 5: Chinese-to-Spanish RQuantity metrics depending on the pivot used.

With those concepts defined, they developed a metric called RQuantity, defined as a
sentence level metric which is then averaged over a corpus:
rR |rAs |

P

RQuantity =

I

+ |rBs |

(11)

where R is the set of reorderings for a sentence, I is the source sentence length, A and B
are the two blocks involved in the reordering, |rAs | is the size or span of block A on the
source side and |rBs | is the size or span of block B on the source side (Birch et al., 2008).
The objective of the RQuantity is to measure the amount of reordering we need when
translating from a source language to a target language. The minimum RQuantity for a
given sentence is 0 if the translation does not involve any word movement and its maximum
P
is ( Ii=2 i)/I when the words in the translation are inverted compared with their order in
the source sentence.
We have computed the RQuantity for the different language pairs involved in our pivot
approaches. It can be seen in table 5 that English appears as the best pivot because it
has the lowest average RQuantity between the three, i.e. it is the pivot that needs the
least amount of reordering in average to achieve the final translation. French and Arabic
required less movements to translate into Spanish than English, but a lot of reordering is
needed to obtain the first step from Chinese, hence penalizing the average. This result is
coherent with the conclusion obtained by Birch et al. (2008), which says that the amount
of reordering has also a negative impact in Bleu score.
These results support the intuitive idea that English works as a good intermediate
step between Chinese and Spanish. Both French and Arabic have a vocabulary which is
closer in size to Spanish and their reorderings are also more complex than English during
the first step, making the source-to-pivot translation harder with these candidates. The
gradual increase in difficulty (measured as target vocabulary size and reordering) presented
in English seems to benefit the global result.
Nevertheless, it is also possible that most Un texts were authored in English, and then,
translated into the other languages. This would also favour English as the best pivot
language.
In order to observe the benefits of the pivot language against the direct translation,
table 6 presents three examples where the Bleu scores of the pivot approach were better
than those of the direct approach. Notice how some phrases that disappeared from the
direct translation correctly appear on the pseudo-corpus approach.
773

fiCosta-jussa, Henrquez & Banchs

DIRECT
PSEUDO
REF
EN REF
DIRECT
PSEUDO
REF
EN REF
DIRECT
PSEUDO
REF
EN REF

cuestiones como a que consideren seriamente la posibilidad de ratificar la tortura y otros tratos
o penas crueles , inhumanos o degradantes
como cuestiones a que consideren seriamente la posibilidad de ratificar la convencion contra
la tortura y otros tratos o penas crueles , inhumanos o degradantes
considere seriamente la posibilidad de ratificar , con caracter prioritario , la convencion
contra la tortura y otros tratos o penas crueles , inhumanos o degradantes
to seriously consider ratifying , as a matter of priority , the convention against torture and
other cruel , inhuman or degrading treatment or punishment
habiendo examinado el segundo informe de la comision y la recomendacion que figura en el
habiendo examinado el segundo informe de la comision de verificacion de poderes y las
recomendaciones que figuran en el
habiendo examinado el segundo informe de la comision de verificacion de poderes y la
recomendacion que figura en el
having considered the second report of the credentials committee and the recommendation
contained therein
pide al secretario general que prepare un informe sobre la aplicacion de esta resolucion a la
asamblea general , quincuagesimo sexto perodo de sesiones
pide al secretario general que prepare un informe sobre la aplicacion de la presente resolucion
para su examen por la asamblea general en su quincuagesimo sexto perodo de sesiones
pide al secretario general que prepare un informe sobre la aplicacion de la presente resolucion ,
que sera examinado por la asamblea general en su quincuagesimo sexto perodo de sesiones
requests the secretary-general to prepare a report on the implementation of the present resolution
for consideration by the general assembly at its fifty-sixth session .

Table 6: Chinese-to-Spanish examples for which the pseudo-corpus system (through English) is better than the direct system. En ref is the English reference of the
sentence

7.2 Pivot Combination
Using the 1-best translation output from the different pivot strategies, we built an n-best
list and computed the final translation using minimum Bayes risk (Mbr) (Kumar & Byrne,
2004).
When translating a sentence s, we obtain a translation t0 which can then be evaluated
against reference t to measure the systems performance. Mbr focuses on finding the best
performance over all possible translations. To do so, it uses a loss function LF(t, t0 ) that
measures the loss of obtaining hypothesis t0 instead of the real translation t. The Bayes
Risk is defined as the expected value of the loss function over all possible hypotheses t0 and
translations t.
E(LF) =

X

LF(t, t0 )p(t0 |s)

(12)

t,t0

where p(t0 |s) is the translation probability of hypothesis t0 given the source sentence s as
obtained by the decoder, as an approximation of its real probability distribution.
The objective of finding the best performance over all possible translation is therefore
to minimize the Bayes Risk. Given a loss function and a distribution, the decision rule that
minimizes the Bayes Risk (Bickel & Doksum, 1977; Goel & Byrne, 2000) is given by:
t = arg min
0
t

X

LF(t, t0 )p(t0 |s)

t

774

(13)

fiEvaluating Indirect Strategies for ChineseSpanish SMT

Mbr has been used in literature both during decoding (Ehling, Zens, & Ney, 2007) and as
a postprocess over a n-best list. For instance, this last approach was used by Khalilov et al.
(2008) together with their cascaded approach in order to obtain the best ChineseSpanish
translation. The current version of the Moses toolkit includes both implementations.
The Mbr algorithm implemented in Moses as postprocess uses 1Bleu(t, t0 ) as the loss
function. In our experiment, we consider all our hypothesis as equally likely and therefore
p(t0 |s) was a positive constant and therefore could be discarded. At the end, Mbr chooses
the hypotheses t that fullfills:


t = arg min
0
t


X

1  Bleu(t, t0 )

(14)

t6=t0

Different n-best lists were built to compare different Mbr outputs: a cascaded Mbr
using all three pivot languages (hence n = 3, one hypothesis per pivot), a pseudo-corpus
Mbr again using all three pivot languages (n = 3), a triangulation Mbr using all three
languages (n = 3), a combination of cascaded, pseudo-corpus and triangulation outputs
using two languages (n = 6, one hypothesis per pivot and strategy) and another using all of
them (n = 9). It is important to mention that all n-best lists must have at least 3 hypothesis
per sentence. Having only two hypothesis would not work as expected because the Loss
Function would always choose the longest one, which can be explained by the definition of
Bleu:
N
X

!

pn (t, t0 )
Bleu(t, t0 ) = exp
log
(t, t0 )
N
n=1

(15)

where pn (t, t0 ) is the precision of n-grams in the hypothesis t0 with reference t; and (t, t0 )
is a brevity penalty disfavouring translation t0 if it is shorter than the reference t. Then
pn (t, t0 ) = pn (t0 , t) and
t, t0 : length(t) > length(t0 )



(16)

1  Bleu(t, t )  1  Bleu(t , t)

(17)

0

0

Tables 7 and 8 show the results of the different ChineseSpanish output systems (from
table 4) combined with the Mbr technique. From these tables, it can be observed that
combinations from all pivot strategies obtained better results in all metrics than the direct
approach. Only in the case of Ar + Fr, the combination was not statistically significantly
better than the direct system in terms of Bleu score (with a 99% confidence).
The Mbr cascaded and triangulation approach (1st row, 2nd and 4th column, respectively, in table 8) did not outperform the direct system.
Finally, both A All and D+A All (which combine all languages and pivot system outputs
from table 4 including or not the direct approach) are the best Chinese-to-Spanish systems.
We have not experimented on the reverse translation direction (from Spanish into Chinese) as we would be unable to assess subjective evaluations on the resulting translation
outputs. However, in the reversed direction, our intuition is that the reordering difficulties
will be then moved to the pivottarget step of the cascade system.
775

fiCosta-jussa, Henrquez & Banchs

En+Fr
En+Ar
Ar+Fr

All
33.58*/56.34/54.48
33.53*/56.15/54.63
33.14/56.83/53.95

Table 7: Chinese-to-Spanish percent Bleu/Ter/Meteor scores for system combinations
of two languages and all pivot approaches using Mbr. (*) statistically significant
better Bleu than the direct system.

A
D+A

Cascaded
32.66/57.27/53.34
33.60*/56.72/54.38

Pseudo
33.30*/57.04/53.91
33.77*/56.52/54.47

Triangulation
31.84/58.12/53.05
32.90/57.01/54.03

All
33.97*/56.00/54.87
34.09*/55.88/55.02

Table 8: Chinese-to-Spanish percent Bleu/Ter/Meteor scores for system combinations
of En + Fr + Ar languages (A), direct system (D) and pivot approaches using
Mbr. (*) statistically significant better Bleu than the direct system.

Regarding the fact of English being the best pivot language for the task under consideration, we can argue that English might constitute a better intermediate step between
Spanish and Chinese, rather than French or Arabic, based on the assumption of Spanish
being closer to French (both are romance languages derived from Latin) and Arabic (the
Iberian peninsula was occupied by Arabic culture for more than 500 years, so Spanish has
strong influence from Arabic) than Chinese to French and Arabic. In this sense, English
seems to represent an optimal intermediate point between Chinese and Spanish, in which the
translation complexity is divided in two phases. Most of the reordering burden is resolved
in the Chinese-to-English phase and most of the morphology generation burden is resolved
in the English-to-Spanish phase. Thinking on translation-space as a non-conservative field,
we can say that English is just in the middle of the way between Chinese and Spanish, while
passing through French or Arabic implies a larger path by some kind of detour in the proximities of Spanish. This is just a conjecture, of course, but it nicely explains what we are
observing. Definitively, more research is needed to better understand what is happening.

8. Conclusions
This work provided a brief survey in the state-of-the-art of ChineseSpanish Smt. First
of all, this language pair is of great interest both economically and culturally if we take
into account the high number of Chinese and Spanish speakers. Besides, statistical machine
translation is the most popular approach in the field of Mt given that has shown great
quality in all the international evaluation campaigns such as Nist (2009) and Wmt (2012).
The main points covered in our study were:
 There are mainly three ChineseSpanish parallel corpora (Btec, Holy Bible and Un)
that are freely available for research purposes.
776

fiEvaluating Indirect Strategies for ChineseSpanish SMT

 English is the best pivot language for conducting Chinese-to-Spanish translations
compared to languages such as French or Arabic. The system built using English as
pivot was significantly better than the ones built with French or Arabic, with a 99%
confidence in both comparisons.
 The preference for a pivot language appears to be correlated with other proposed
translation-quality prediction metrics such as the differences in vocabulary sizes and
the amount of reordering. According to the above conclusion, the best pivot language
is English because it has the lowest increase in vocabulary size and the lowest increase
in reordering complexity.
 No significant difference is found among the best cascaded and pseudo-corpus pivot
approaches, but the pseudo-corpus strategy is the best pivot strategy for Chineseto-Spanish. Additionally, pseudo-corpus and cascaded approaches are significantly
better than the triangulation approach.
 The output combination using Mbr is able to improve the direct system in 1 Bleu
point in the best case. This improvement is significantly better with a 99% confidence
and is coherent with improvements in all other evaluation metrics studied.
As future research we plan to work on the problem of automatically extracting parallel
corpus from comparable corpora collected from the web. Additionally, we intend to develop
a freely available ChineseSpanish translation system which would allow for collecting user
feedback. Then, we will work on special techniques to incorporate this knowledge in the
Smt system.

Acknowledgments
The authors would like to specially thank the reviewers for their comments that helped a
lot to improve this work. Additionally, the authors would like to thank the Universitat
Politecnica de Catalunya and the Institute for Infocomm Research for their support and
permission to publish this research.
This work has been partially funded by the Seventh Framework Program of the European
Commission through the International Outgoing Fellowship Marie Curie Action (IMTraP2011-29951); and by the Spanish Ministry of Economy and Competitiveness through the FPI
Scholarship BES-2008-003851 for Ph.D. students under the AVIVAVOZ project (TEC200613694-C03-01); and the BUCEADOR project (TEC2009-14094-C04-01).

References
Abdul-Rauf, S., Fishel, M., Lambert, P., Noubours, S., & Sennrich, R. (2012). Extrinsic
evaluation of sentence alignment systems. In Proceedings of LREC workshop on Creating Cross-language Resources for Disconnected Languages and Styles, CREDISLAS,
Istambul.
Banchs, R. E., Crego, J. M., Lambert, P., & Marino, J. B. (2006). A Feasibility Study For
Chinese-Spanish Statistical Machine Translation. In Proc. of the 5th Int. Symposium
777

fiCosta-jussa, Henrquez & Banchs

on Chinese Spoken Language Processing (ISCSLP)CONLL, pp. 681692, Kent Ridge,
Singapore.
Banchs, R. E., & Li, H. (2008). Exploring Spanish Morphology effects on Chinese-Spanish
SMT. In MATMT 2008: Mixing Approaches to Machine Translation, pp. 4953,
Donostia-San Sebastian, Spain.
Banerjee, S., & Lavie, A. (2005). METEOR: An Automatic Metric for MT Evaluation with
Improved Correlation with Human Judgments. In Proceedings of ACL Workshop on
Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization.
Bertoldi, N., Cattoni, R., Federico, M., & Barbaiani, M. (2008). FBK @ IWSLT-2008.
In Proc. of the International Workshop on Spoken Language Translation, pp. 3438,
Hawaii, USA.
Bickel, P. J., & Doksum, K. A. (1977). Mathematical: Basic Ideas and Selected topics. In
HoldenDay Inc., Oakland, CA, USA.
Birch, A., Osborne, M., & Koehn, P. (2008). Predicting Success in Machine Translation.
In Proceedings of the 2008 Conference on Empirical Methods in Natural Language
Processing, pp. 745754, Honolulu, Hawaii. Association for Computational Linguistics.
Brown, P. F., Cocke, J., Della Pietra, S. A., Della Pietra, V. J., Jelinek, F., Lafferty, J. D.,
Mercer, R. L., & Roossin, P. S. (1990). A Statistical Approach to Machine Translation.
Computational Linguistics, 16 (2), 7985.
Callison-Burch, C., Koehn, P., Monz, C., Post, M., Soricut, R., & Specia, L. (2012). Findings
of the 2012 workshop on statistical machine translation. In Proceedings of the Seventh
Workshop on Statistical Machine Translation, pp. 1051, Montreal, Canada.
Chew, P. A., Verzi, S. J., Bauer, T. L., & McClain, J. T. (2006). Evaluation Of The Bible As
A Resource For Cross-language Information Retrieval. In Proceedings of the Workshop
on Multilingual Language Resources and Interoperability, pp. 6874.
Cohn, T., & Lapata, M. (2007). Machine Translation by Triangulation: Making Effective
Use of Multi-Parallel Corpora. In Proc. of the ACL.
Costa-jussa, M., Henrquez, C., & Banchs, R. E. (2011a). Enhancing Scarce-resource Language Translation Through Pivot Combinations. In 5th International Joint Conference
on Natural Language Processing, IJCNLP, Chiang Mai, Thailand.
Costa-jussa, M., Henrquez, C., & Banchs, R. E. (2011b). Evaluacion de estrategias para
la traduccion automatica estadstica de chino a castellano con el ingles como lengua
pivote. In XXVII edicion del Congreso Anual de la Sociedad Espanola para el Procesamiento del Lenguaje Natural, SEPLN, Huelva.
de Gispert, A., & Marino, J. (2006). Catalan-English Statistical Machine Translation without Parallel Corpus: Bridging through Spanish. In Proc. of LREC 5th Workshop on
Strategies for developing Machine Translation for Minority Languages (SALTMIL06),
pp. 6568, Genova.
EastAsiaFoundation (2012). Global asia magazine.. [Online; accessed 12-December-2012].
778

fiEvaluating Indirect Strategies for ChineseSpanish SMT

Ehling, N., Zens, R., & Ney, H. (2007). Minimum Bayes Risk Decoding for BLEU. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pp. 101104,
Prague, Czech Republic. Association for Computational Linguistics.
Ethnologue (2012). Ranking of most spoken languages.. [Online; accessed 12-December2012].
Goel, V., & Byrne, W. (2000). Minimum Bayes-risk Automatic Speech Recognition. Computer Speech and Language, 14 (2), 115135.
Habash, N., & Rambow, O. (2005). Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proc. of the 43rd Annual Meeting
of the Association for Computational Linguistics, pp. 573580, Ann Arbor, MI. Association for Computational Linguistics.
Henrquez Q., C. A., Banchs, R. E., & Marino, J. B. (2010). Learning Reordering Models for
Statistical Machine Translation with a Pivot Language. Internal Report TALP-UPC.
Khalilov, M., Costa-Jussa, M. R., Henrquez, C. A., Fonollosa, J. A. R., Hernandez, A.,
Marino, J. B., Banchs, R. E., Chen, B., Zhang, M., Aw, A., & Li, H. (2008). The
TALP & I2R SMT Systems for IWSLT 2008. In Proc. of the International Workshop
on Spoken Language Translation, pp. 116123, Hawaii, USA.
Koehn, P. (2004). Statistical Significance Tests For Machine Translation Evaluation. In
Proceedings of EMNLP, Vol. 4, pp. 388395.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., & Herbst, E.
(2007). Moses: Open source toolkit for statistical machine translation. In Proc. of the
ACL, pp. 177180, Prague, Czech Republic.
Koehn, P., Och, F., & Marcu, D. (2003). Statistical Phrase-Based Translation. In Proc. of
the 41th Annual Meeting of the Association for Computational Linguistics.
Kumar, S., & Byrne, W. (2004). Minimum Bayes-Risk Decoding For Statistical Machine
Translation. In Proceedings of the Human Language Technology and North American
Association for Computational Linguistics Conference (HLT/NAACL04), pp. 169
176, Boston, USA.
Marino, J., Banchs, R. E., Crego, J. M., de Gispert, A., Lambert, P., Fonollosa, J. R.,
& Costa-jussa, M. R. (2006). N-gram Based Machine Translation. Computational
Linguistics, 32 (4), 527549.
Moore, R. (2002). Fast And Accurate Sentence Alignment Of Bilingual Corpora. In Proc.
of AMTA, pp. 135144, London.
Nist (2009). NIST machine translation evaluation campaign..
December-2012].

[Online; accessed 12-

Och, F. J., & Ney, H. (2000). Improved Statistical Alignment Models. In Proc. of the
38th Annual Meeting of the Association for Computational Linguistics, pp. 440447,
Hongkong, China.
779

fiCosta-jussa, Henrquez & Banchs

Och, F. (2003). Minimum Error Rate Training In Statistical Machine Translation. In Proc.
of the 41th Annual Meeting of the Association for Computational Linguistics, pp.
160167.
Och, F., & Ney, H. (2002). Dicriminative training and maximum entropy models for statistical machine translation. In Proc. of the 40th Annual Meeting of the Association for
Computational Linguistics, pp. 295302, Philadelphia, PA.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2001). BLEU: A Method for Automatic
Evaluation of Machine Translation. IBM Research Report, RC22176.
Paul, M. (2008). Overview of the iwslt 2008 evaluation campaign. In Proc. of the International Workshop on Spoken Language Translation, pp. 117, Hawaii, USA.
Paul, M., Yamamoto, H., Sumita, E., & Nakamura, S. (2009). On the Importance of Pivot
Language Selection for Statistical Machine Translation. In HLT-NAACL (Short Papers), pp. 221224.
Rafalovitch, A., & Dale, R. (2009). United Nations General Assembly Resolutions: A SixLanguage Parallel Corpus. In Proc. of the MT Summit XII, pp. 292299, Ottawa.
Senrich, R. (2010). MT-based Sentence Alignment For OCR-generated Parallel Texts. In
Proc. of AMTA, Denver.
Snover, M., Dorr, B., Schwartz, R., Micciulla, L., & Makhoul, J. (2006). A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of Association for
Machine Translation in the Americas.
Stolcke, A. (2002). SRILM: an extensible language modeling toolkit.. In Proc. of the Int.
Conf. on Spoken Language Processing, pp. 901904, Denver, CO.
Tillman, C. (2004). A Block Orientation Model for Statistical Machine Translation. In
HLT-NAACL.
Wang, H., Wu, H., Hu, X., Liu, Z., Li, J., Ren, D., & Niu, Z. (2008). The TCH Machine
Translation System for IWSLT 2008. In Proc. of the International Workshop on
Spoken Language Translation, pp. 124131, Hawaii, USA.
Wu, H., & Wang, H. (2007). Pivot Language Approach for Phrase-Based Statistical Machine
Translation. In Proc. of the ACL, pp. 856863, Prague.
Zapatero, J. R. (2010). China is a top priority for the spanish economy; our companies are
well aware of that.. [Online; accessed 12-December-2012].
Zens, R., Och, F., & Ney, H. (2002). Phrase-based statistical machine translation. In Verlag,
S. (Ed.), Proc. German Conference on Artificial Intelligence (KI).
Zhang, H., Yu, H., Xiong, D., & Liu, Q. (2003). HHMM-based chinese lexical analyzer
ICTCLAS. In Proc. of the 2nd SIGHAN Workshop on Chinese language processing,
pp. 184187, Sapporo, Japan.

780

fiJournal of Artificial Intelligence Research 45 (2012) 641-684

Submitted 11/12; published 12/12

Learning to Predict from Textual Data
Kira Radinsky
Sagie Davidovich
Shaul Markovitch

kirar@cs.technion.ac.il
mesagie@gmail.com
shaulm@cs.technion.ac.il

Computer Science Department
TechnionIsrael Institute of Technology
Haifa 32000, Israel

Abstract
Given a current news event, we tackle the problem of generating plausible predictions
of future events it might cause. We present a new methodology for modeling and predicting
such future news events using machine learning and data mining techniques. Our Pundit
algorithm generalizes examples of causality pairs to infer a causality predictor. To obtain
precisely labeled causality examples, we mine 150 years of news articles and apply semantic
natural language modeling techniques to headlines containing certain predefined causality
patterns. For generalization, the model uses a vast number of world knowledge ontologies.
Empirical evaluation on real news articles shows that our Pundit algorithm performs as
well as non-expert humans.

1. Introduction
Causality has been studied since antiquity, e.g., by Aristotle, but modern perceptions of
causality have been most influenced, perhaps, by the work of David Hume (17111776),
who referred to causation as the strongest and most important associative relation, that
which lies at the heart of our perception and reasoning about the world, as it is constantly
supposed that there is a connection between the present fact and that which is inferred
from it.
Causation is also important for designing computerized agents. When an agent, situated in a complex environment, plans its actions, it reasons about future changes to the
environment. Some of these changes are a result of its own actions, but many others are
a result of various chains of events not necessarily related to the agent. The process of
observing an event, and reasoning about future events that might be caused by it, is called
causal reasoning.
In the past, computerized agents could not operate in complex environments due to
their limited perceptive capabilities. The proliferation of the World Wide Web, however,
changed all that. An intelligent agent can act in the virtual world of the Web, perceiving the
current state of the world through extensive sources of textual information, including Web
pages, tweets, news reports, and online encyclopedias, and performing various tasks such
as searching, organizing, and generating information. To act intelligently in such a complex
virtual environment, the agent must be able to perceive the current state and reason about
future states through causal reasoning. Such reasoning ability can be extremely helpful
in conducting complex tasks such as identifying political unrest, detecting and tracking
c
2012
AI Access Foundation. All rights reserved.

fiRadinsky, Davidovich & Markovitch

social trends, and generally supporting decision making by politicians, businesspeople, and
individual users.
While many works have been devoted to extracting information from text (e.g., Banko,
Cafarella, Soderl, Broadhead, & Etzioni, 2007; Carlson, Betteridge, Kisiel, Settles, Hruschka, & Mitchell, 2010), little has been done in the area of causality extraction, with
the works of Khoo, Chan, and Niu (2000) and Girju and Moldovan (2002) being notable
exceptions. Furthermore, the algorithms developed for causality extraction try to detect
causality and cannot be used to predict it, that is, to generate new events the given event
might cause.
Our goal in this paper is to provide algorithms that perform causal reasoning, in particular causality prediction, in textually represented environments. We have developed a
causality learning and prediction algorithm, Pundit, that, given an event represented in
natural language, predicts future events it can cause. Our algorithm is trained on examples
of causality relations. It then uses large ontologies to generalize over the causality pairs and
generate a prediction model. The model is represented by an abstraction tree, that, given
an input cause event, finds its most appropriate generalization, and uses learned rules to
output predicted effect events.
We have implemented our algorithm and applied it to a large collection of news reports
from the last 150 years. To extract training examples from the news corpus, we do not
use correlation, by means of which causality is often misidentified. Instead, we use textual
causality patterns (such as X because Y or X causes Y), applied to news headlines, to
identify pairs of structured events that are supposedly related by causality. The result is a
semantically-structured causality graph of 300 million fact nodes connected by more than
one billion edges. To evaluate our method, we tested it on a news archive from 2010, which
was not used during training. The results are judged by human evaluators.
To give some intuition about the type of predictions the algorithm generates, we present
here two examples of actual predictions made by our system. First, given the event Magnitude 6.5 earthquake rocks the Solomon Islands, the algorithm predicted that a tsunamiwarning will be issued for the Pacific Ocean. It learned this from past examples on which
it was trained, one of which was
h7.6 earthquake strikes island near India, tsunami warning issued for Indian Oceani.
Pundit was able to infer that an earthquake occurring near an island would result in a
tsunami warning being issued for its ocean. Second, given the event Cocaine found at
Kennedy Space Center, the algorithm predicted that a few people will be arrested. This
was partially based on the past example hpolice found cocaine in lab  2 people arrested i.

The contributions of this work are threefold: First, we present novel and scalable algorithms for generalizing causality pairs to causality rules. Second, we provide a new method
for using casualty rules to predict new events. Finally, we implement the algorithms in a
large scale system and perform an empirical study on realistic problems judged by human
raters. We make the extracted causality information publicly available for further research
in the field 1 .
1. http://www.technion.ac.il/~kirar/Datasets.html

642

fiLearning to Predict from Textual Data

2. Learning and Predicting Causality
In this section, we describe the Pundit algorithm for learning and predicting causality. We
start with an overview of the learning and prediction process. During training, the learning
algorithm receives causality event pairs, extracted from historical news archives (Section
3). The algorithm then generalizes over the given examples using world knowledge and
produces an abstraction tree (AT)(Section 2.4). For each node in the AT, a prediction
rule is generated from the examples in the node (Section 2.5). Then, during the prediction
phase, the algorithm matches the given new event to nodes in the AT, and the associated
rule is applied on it to produce possible effect events (Section 2.6). Those events are then
filtered (Section 2.7) and an effect event output. The output event itself is also given in
natural language, in sentence-like form. The process is illustrated in Figure 1.

Implausible	 
event	 lter	 

Figure 1: Structure of the Pundit prediction algorithm

2.1 Event Representation
The basic element of causal reasoning is an event. The Topic Tracking and Detection (TDT)
community (Allan, 2002) has defined an event as a particular thing that happens at a specific time and place, along with all necessary preconditions and unavoidable consequences.
643

fiRadinsky, Davidovich & Markovitch

Other philosophical theories consider events as exemplifications of properties by objects at
times (Kim, 1993). For example, Caesars death at 44 BC is Caesars exemplification of
the property of dying at time 44 BC. Those theories impose structure on events, where a
change in one of the elements yields a different event. For example, Shakespears death is a
different event from Caesars death, as the objects exemplifying the property are different.
In this section, we will discuss a way to represent events following Kims (1993) exemplification theory that will allow us to easily compare them, generalize them, and reason about
them.
There are three common approaches for textual event representation: The first approach
describes an event at sentence level by running text or individual terms (Blanco, Castell,
& Moldovan, 2008; Sil, Huang, & Yates, 2010). Event similarity is treated as a distance
metric between the two events bag of words. While such approaches can be useful, they
often fail to perform fine-grained reasoning. Consider, for example, three events: US Army
bombs a warehouse in Iraq, Iraq attacks US base, and Terrorist base was attacked by
the US Marines in Kabul. Representing these events by individual terms alone might yield
that the first two are more similar than the first and the last as they have more words in
common. However, such approaches disregard the fact the actors of the first and last event
are military groups and that Kabul and Iraq are the event locations. When these facts
are taken into account, the first and last events are clearly more similar than the first and
second.
The second approach describes events in a syntax-driven manner, where the event text is
transformed into syntax-based components, such as noun phrases (Garcia, 1997; Khoo et al.,
2000; Girju & Moldovan, 2002; Chan & Lam, 2005). In our example, this representation
again erroneously finds the second and third events to be most similar due to the syntactic
similarity between them. Using the first two approaches, it is hard to make practical
generalizations about events or to compare them in a way that takes into account all the
semantic elements that compose them.
The third approach is semantic (similar to the representation in Cyc; Lenat & Guha,
1990), and maps the atomic elements of each event to semantic concepts. This approach
provides grounds for canonic representation of events that are both comparable and generalizable. In this work, we follow the third approach and represent events semantically.
Given a set of entities O that represent physical objects and abstract concepts in the
real world (e.g., people, instances, and types), and a set of actions P , we define an event as
an ordered set e = hP, O1 , . . . , O4 , ti, where:
1. P is a temporal action or state that the events objects exhibit.
2. O1 is the actor that performed the action.
3. O2 is the object on which the action was performed.
4. O3 is the instrument with which the action was performed.
5. O4 is the location of the event.
6. t is a time-stamp.
644

fiLearning to Predict from Textual Data

For example, the event The U.S Army destroyed a warehouse in Iraq with explosives,
which occurred on October 2004, is modeled as: Destroy (Action); U.S Army (Actor);
warehouse (Object); explosives (Instrument); Iraq (Location); October 2004 (Time). This
approach is inspired by Kims (1993) property-exemplification of events theory.
2.2 Learning Problem Definition
We treat causality inference as a supervised learning problem. Let Ev be the universe of
all possible events. Let f : Ev  Ev  {0, 1} be the function
(
1 if e1 causes e2 ,
f (e1 , e2 ) =
0 if otherwise.
We denote f + = {(e1 , e2 )|f (e1 , e2 ) = 1}. We assume we are given a set of possible positive
examples E  f + .
Our goal is not merely to test whether a pair of events is a plausible cause-effect pair
by f , but to generate for a given event e the events it can cause. For this purpose we define
g : Ev  2Ev to be g(e) = {e0 |f (e, e0 ) = 1}; that is, given an event, output the set of events
it can cause. We wish to build this predictor g using the examples E.
Learning f from E could have been solved by standard techniques for concept learning
from positive examples. The requirement to learn g, however, presents the challenging task
of structured prediction from positive examples.
2.3 Generalizing Over Objects and Actions
Our goal is to develop a learning algorithm that automatically produces a causality function
based on examples of causality pairs. The inferred causality function should be able to
predict the outcome of a given event, even if it was never observed before. For example, given
the training examples hearthquake in Turkey, destructioni and hearthquake in Australia,
destructioni, and a current new event of earthquake in Japan, a reasonable prediction
would be destruction. To be able to handle such predictions, we must endow our learning
algorithm with generalization capacity. For example, in the above scenario, the algorithm
must be able to generalize Australia and Turkey to countries, and to infer that earthquakes
in countries might cause destruction. This type of inference and the knowledge that Japan
is also a country enables the algorithm to predict the effects of new events using patterns
in the past.
To generalize over a set of examples, each consisting of a pair of events, we perform
generalization over the components of these events. There are two types of components 
objects and actions.
To generalize over objects, we assume the availability of a semantic network Go = (V, E),
where the nodes V  O are the objects in our universe, and the labels on the edges are
relations such as isA, partOf and CapitalOf. In this work, we consider one of the largest
semantic networks available, the LinkedData ontology (Bizer, Heath, & Berners-Lee, 2009),
which we describe in detail in Section 3.
We define two objects to be similar if they relate to a third object in the same way.
This relation can be a label or a sequence of labels in the semantic network. For example,
645

fiRadinsky, Davidovich & Markovitch

Paris and London will be considered similar because their nodes are connected by the path
Capitalof Incontinent

 to the node Europe. We now formally define this idea.
Definition 1. Let a, b  V . A sequence of labels L = l1 , . . . , lk is a generalization path
of a, b, denoted by GenPath(a,b), if there exist two paths in G, (a, v1 , l1 ), . . . (vk , vk+1 , lk )
and (b, w1 , l1 ), . . . (wk , wk+1 , lk ), s.t. vk+1 = wk+1 .
Overgeneralization of events should be avoided  e.g., given two similar events, one
occurring in Paris and one in London, we wish to produce the generalization city in Europe
Capitalof Incontinent

( Europe) rather than the more abstract generalization city on a
Capitalof Incontinent IsA

continent ( Continent). We wish our generalization to be as
specific as possible. We call this minimal generalization of objects.

Definition 2. The minimal generalization path, denoted by M GenP ath(a, b), is defined
as the set containing the shortest generalization paths. We denote distGen (a, b) as the length
of the M GenP ath(a, b).
Path-based semantic distances such as the one above were shown to be successful in
many NLP applications. For example, the semantic relatedness of two words was measured
by means of a function that measured the distance between words in a taxonomy (Rada,
Mili, Bicknell, & Blettner, 1989; Strube & Ponzetto, 2006). We build on this metric and
expand it to handle events that are structured and can contain several objects from different
ontologies.
To efficiently produce M GenP ath, we designed an algorithm (described in Figure 2),
based on dynamic programming, that computes the M GenP ath for all object pairs in G.
For simplicity, we describe an algorithm that computes a single path for each two nodes a
and b, rather than the set of all shortest paths. At step 1 a queue that holds all nodes with
the same generalization is initialized. At step 2, the algorithm identifies all nodes (a, b)
that have a common node (c) connecting to them via the same type of edge (l). c can be
thought of as a generalization of a and b. The M gen structure maps a pair of nodes to
their generalization (M gen.Gen) and their generalization path (M Gen.P red). At step 3,
in a dynamic programming manner, the algorithm iterates over all nodes (a, b) in M gen for
which we found a minimal generalization in previous iterations, and finds two nodes  one
(x) connecting to a and one (y) connecting to b via the same type of edge l (step 3.4). Thus,
the minimal generalization of x and y is the minimal generalization of a and b, and the path
is the M GenP ath of a, b with the addition of the edge type l. This update is performed
in steps 3.4.13.4.4. Eventually, when no more nodes with minimal generalization can be
expanded (i.e., the algorithm cannot find two nodes that connect to them via the same edge
type), it stops and returns M gen (step 4). During prediction, if several M gen exists, we
consider both during the prediction with their corresponding M GenP ath.
We define a distance between actions using an ontology Gp , similarly to the way we
defined distance between objects. Specifically, we use the VerbNet (Kipper, 2006) ontology,
which is one of the largest English verb lexicons. It has mapping to many other online
resources, such as Wordnet (Miller, 1995). The ontology is hierarchical and is based on a
classification of the verbs to the Levin classes (Dang, Palmer, & Rosenzweig, 1998). This
resource has been widely used in many natural language processing applications (Shi &
646

fiLearning to Predict from Textual Data

Procedure Minimal Generalization Path(G)
(1) Q  new Queue
(2) Foreach {(a, c, l), (b, c, l)  E(G)|
a, b, c  V (AT ), l  Lables}
(2.1) M gen(a, b).Gen = c
(2.2) M gen(a, b).P red = l
(2.3) M gen(a, b).Expanded = f alse
(2.4) Q.enqueue((a, b))
(3) While Q 6= :
(3.1) (a, b)  Q.dequeue()
(3.2) If M gen(a, b).Expanded 6= true:
M gen(a, b).Expanded = true
(3.4) Foreach {(x, a, l), (y, b, l)  E(AT )|
x, y  V (AT ), l  Lables}
(3.4.1) M gen(x, y).Gen = M gen(a, b).Gen
(3.4.2) M gen(x, y).P red = M gen(a, b).P red||l
(3.4.3) M gen(x, y).Expanded = f alse
(3.4.4) Q.enqueue((x, y))
(4)Return M gen
Figure 2: Procedure for calculating the minimal generalization path for all object pairs
Mihalcea, 2005; Giuglea & Moschitti, 2006). Using this ontology we describe the connections
between verbs. Figure 10 shows a node in this ontology that generalizes the actions hit
and kick.
2.4 Generalizing Events
In order to provide strong support for generalization, we wish to find similar events that
can be generalized to a single abstract event. In our example, we wish to infer that both
hearthquake in Turkey, destructioni and hearthquake in Australia, destructioni are examples
of the same group of events. Therefore, we wish to cluster the events in such a way that
events with similar causes and effects will be clustered together. As in all clustering methods,
a distance measure between the objects should be defined. Let ei = hP i , O1i , . . . , O4i , ti i and
ej = hP j , O1j , . . . , O4j , tj i be two events. In the previous subsection we defined a distance
function between objects (and between actions). Here, we define the similarity of two events
ei and ej to be a function of distances between their objects and actions:
Gp
j
j 
Go
i
i
o
SIM (ei , ej ) = f distGen
(P i , P j ), distG
Gen (O1 , O1 ), . . . , distGen (O4 , O4 ) ,

(1)

where, distG
Gen is the distance function distGen in the graph G, and f is an aggregation
function. In this work, we mainly use the average as the aggregation function, but also
analyze several alternatives.
647

fiRadinsky, Davidovich & Markovitch

Likewise, a similarity between two pairs of cause-effect events hci , ei i and hcj , ej i is
defined as:

SIM (hci , ei i, hcj , ej i) = f SIM (ci , cj ), SIM (ei , ej ) .

(2)

Using the similarity measure suggested above, the clustering process can be thought of
as a grouping of the training examples in such a way that there is a low variance in their
effects and a high similarity in their cause. This is similar to information gain methods where
examples are clustered by their class. We use the HAC hierarchical clustering algorithm
(Eisen, Spellman, Brown, & Botstein, 1998) as our clustering method. The algorithm starts
by joining the closest event pairs together into a cluster. It then keeps repeating the process
by joining the closest two clusters together until all elements are linked into a hierarchical
graph of events we call an abstraction tree (AT). Distance between clusters is measured by
the distance of their representative events. To allow this, we assign to each node in the AT
a representative cause event, which is the event closest to the centroid of the nodes cause
events. During the prediction phase, the input cause event will be matched to one of the
created clusters, i.e., closest to the representative cause event of the cluster.
2.5 Causality Prediction Rule Generation
The last phase of the learning is the creation of rules that will allow us, given a cause event,
to generate a prediction about it. As the input cause event is matched against the node
centroid, a naive approach would be to return the effect event of the matched centroid. This,
however, would not provide us with the desired result. Assume an event ei =Earthquake
hits Haiti occurred today, and that is matched to a node represented by the centroid:
Earthquake hits Turkey, whose effect is Red Cross help sent to Ankara. Obviously,
predicting that Red Cross help will be sent to Ankara because of an earthquake in Haiti is
not reasonable. We would like to be able to abstract the relation between the past cause and
past effect and learn a predicate clause that connects them, for example Earthquake hits
[Country Name] yielding Red Cross help sent to [Capital of Country]. During prediction,
such a clause will be applied to the input event ei , producing its predicted effect. In our
example, the logical predicate clause would be CapitalOf, as CapitalOf(Turkey)= Ankara.
When applied on the current event ei , CapitalOf(Haiti) = Port-au-Prince, the output will
now be Red Cross help sent to Port-au-Prince. Notice that the the clauses can only be
applied on certain types of objects  in our case, countries. The clauses can be of any length,
e.g., the pair hsuspect arrested in Brooklyn, Bloomberg declares emergencyi produces
the clause Mayor(BoroughOf(x)), as Brooklyn is a borough of New York, whose mayor is
Bloomberg.
We will now show how to learn such clauses for each node in the AT graph. Recall
that the semantic network graph GO is an edge-labeled graph, where each edge is a triplet
hv1 , v2 , li, where l is a predicate (e.g., CapitalOf). The rule-learning procedure is divided
into two main steps. First, we find an undirected path pi of length at most k in GO
between any object of the cause event to any object of the effect event. Note that we do not
necessarily look for paths between two objects with the same role. In the above example,
we found a path between the location of the cause event (Brooklyn) to the actor of the
effect event (Bloomberg). Second, we construct a clause using the labels of the path pi as
648

fiLearning to Predict from Textual Data

the predicates. We call this the predicate projection of size k, pred = l1 , . . . , lk from an
event ei to an event ej . During prediction, the projections will be applied to the new event
e = hP i , O1 , . . . , O4 , ti by finding an undirected path in GO from Oi with the sequence of
labels of pred. As k is unknown, the algorithm, for each training example hct , et i in a node
in the AT, finds all possible predicate paths with increasing sizes of k from the objects of
ct to the objects of et in the GO graph. Each such path is weighted by the number of times
it occurred in the node, the support of the rule. The full predicate generation procedure
is described in Figure 3. The function LearnP redicateClause calls the inner function
F indP redicateP ath for different k sizes and different objects from the given cause and
effect events. F indP redicateP ath is a recursive function that tries to find a path between
the two objects in a graph of length k. It returns the labels of such a path if found. The
rule generated is a template for generating the prediction of a future event given the cause
event. An example of such a rule can be seen in Figure 4. Rules that return NULL are not
displayed in the figure. In this example, when we generate object O1 of the future event, we
l1 l2
try to apply the path 


 on the object O4 of the cause, thus generating possible objects
l1 l2
that can be object O1 of the prediction (see Section 2.6). Similarly, the path 


 is applied
on O2 , generating more possible objects. For object O2 of the prediction, a simple path of
one label was generated. Therefore, during prediction, the possible objects for O2 are the
ones that connect to O4cause with the label l8 (if any). For object O3 of the prediction, we
use the O3cause . For O4 no special rule was generated (F indP redicateP ath returned NULL
for all objects), and the final prediction will have O4ef f ect .
2.6 Prediction
Given a trained model g, it can be applied to a new event e = hP i , O1 , . . . , O4 , ti in order
to produce its effects. The process is divided into two main steps  propagating the event
in the AT to retrieve a set of matched nodes, and applying the rules of each matched node
to produce the possible effects.
Given a new event, Pundit traverses the AT starting from the root. For each node in
the search frontier, the algorithm computes the similarity (SIM (ei , ej )) of the input event
to the centroid of each of the children on this node, and expands those children with better
similarity than their parent. This idea can be stated intuitively as an attempt to find the
nodes which are the least general but still similar to the new event. The full algorithm is
illustrated in Figure 5. An illustration of the process can be seen in Figure 6. Here, an event
of a bombing in Baghdad is received as input. The system searches for the least general
cause event it has observed in the past (for simplicity we only show a short notation of the
cause events in the AT). In our case, it is a generalized cluster: bombing in city. Other
candidates selected are the military communication cluster and the bombing cluster
(as the node bombing in worship area has a lower score than bombing).
For each node retrieved in the previous stage, its predicate projection, pred, is applied
to the new event e = hP i , O1 , . . . , O4 , ti. Informally, we can say that pred is applied by
finding an undirected path in GO from Oi with the labels of pred. This rule generates a
possible effect event from the retrieved node. The projection results are all the reached
objects in the vertex. The formal explanation is that pred can be applied if V0 : O 
V0 , V1 . . . Vk : (V0 , V1 , l1 ), . . . (Vk1 , Vk , lk )  Edges(GO ). The projection results are all the
649

fiRadinsky, Davidovich & Markovitch

Procedure FindPredicatePath(curEntity, goalEntity, depth)
If curEntity = goalEntity Return 
Else
If depth = 0 Return N U LL
Else
Foreach relation  outEdges(curEntity)
solution  FindPredicatePath(relation(curEntity), goalEntity, depth  1)
If solution 6= N U LL
Foreach existingSolution
S  Solutions :
Return Solutions (existingSolution||relation||solution)
Return Solutions
Procedure LearnPredicateClause(hP c , O1c , . . . , O4c , tc i, hP e , O1e , . . . , O4e , te i, depth)
Foreach Oic  Oc , Oje  Oe , k  {1 . . . depth}
rule(j)  
Foreach Oic  Oc , Oje  Oe , k  {1 . . . depth}
S
rule(j)  rule(j) {hOic , FindPredicatePath(Oic , Oje , k)i}
Return rule
Figure 3: Procedure for generating a rule between two events by inferring paths between the two
events in the causality graph.

objects o  Vk . The projection results of all the nodes are weighted by the similarity of
the target cause to the node M Gen and then ranked by the support of the rule (for tie
breaking). If several M Gen exists, the highest similarity is considered. See Figure 7 for
a complete formal description of the algorithm. In our example (Figure 6), the candidate
bombing in [city] has the following rules:
1. P ef f ect = happen, O1ef f ect = riot , O4ef f ect = O4cause
2. P ef f ect = happen, O1ef f ect = riot , O4ef f ect = O4cause

mainstreetof



3. P ef f ect = kill, O2ef f ect = people
4. P ef f ect = condemn, O1ef f ect = O4

mayorof boroughof





, O2ef f ect = attack

For clarity, for objects where no rule can be applied (the rule for the object is NULL), we
use the effect concept of the matched training example.
For the event Baghdad Bombing (O1 = Bombing, O4 = Baghdad), applying the rules
yields the following:
1. Baghdad Riots (P ef f ect = happen, O1ef f ect = riot , O4ef f ect = Baghdad).
2. Caliphs Street Riots (P ef f ect = happen, O1ef f ect = riot , O4ef f ect = Caliphs Street
mainstreetof



O4cause ).
650

fiLearning to Predict from Textual Data

Rule(cause, ef f ect) =

O1

O4cause

l1

O2

{O4cause

l8

O3

{O3cause ;}

l

2
! !,
O2cause

l1

l

3
! !

!}

O4

Figure 4: An example of a generated rule

3. People killed (P ef f ect = kill, O2ef f ect = people).
4. This rule cannot be applied on the given event, as there is no outgoing edge of type
borough-of for the node Baghdad.

2.7 Pruning Implausible Effects
In some cases, the system generated implausible predictions. For example, for the event
hlightning kills 5 peoplei, the system predicted that hlightning will be arrestedi. This
prediction was based on generalized training examples in which people who killed other
people got arrested, such as: hMan kills homeless man, man is arrested i. But if we could
determine how logical an event is, we could avoid such false predictions. In this section we
discuss how we filter them out.
The goal of our filtering component is different from that of the predictor. While the
predictors goal is to generate predictions about future events, this components goal is to
monitor those predictions. While the predictor learns a causality relation between events,
this component learns their plausibility.
The right way to perform such filtering is to utilize common sense knowledge for each
action. Such knowledge would state the type of the actor and the object that can perform
the action, the possible instruments with which the action can be preformed and the possible
locations. If such knowledge would have existed, it would have identified that for the action
arrest the object can be only human. However, such common sense knowledge is currently
not available. Therefore, we had to resort to the common practice of using statistical
methods.
651

fiRadinsky, Davidovich & Markovitch

Procedure Propagation(e = hP i , O1 , . . . , O4 , ti)
(1) Candidates  {}
(2) Q  new Queue
(3) Q.enqueue(G.root)
(4) While Q 6= :
(4.1) cur  Q.dequeue()
(4.2) Foreach edge  cur.OutEdges:
If SIM (e, edge.Source) > SIM
S (e, edge.Destination):
Candidates  Candidates
{(edge.Source, SIM (e, edge.Source))}
Else :
Q.enqueue(edge.Destination)
(5) Return Candidates

Figure 5: Procedure for locating candidates for prediction. The algorithm saves a set of
possible matched results (Candidates), and a queue holding the search frontier
(Q). In step 4, the algorithm traverses the graph. In step 4.2, for each edge,
the algorithm tests whether the similarity of the new event e to the parent node
(edge.Source) is higher than to the child node (edge.Destination). If the test
succeeds, the parent node, with its similarity score, is added to the possible
results. After all edges are exposed, the algorithm returns the possible results in
step 5.

Baghdad
bombing

military
0.2

military
communication

bombing
0.7
bombing in
0.8
city

0.3

bombing in
0.65 worship area

0.2

0.75
bombing in Kabul

Figure 6: An event of a bombing in Baghdad is received as input. The system searches
for the least general cause event it has observed in the past. In our case it is a
generalized cluster: bombing in city. The rule at this node now will be applied
on the Baghdad bombing to generate the prediction.

652

fiLearning to Predict from Textual Data

Procedure FindPredicatePathObjects(entity, path = hl1 . . . lk i)
(1) Candidates  {}
(2) Q  new Queue
(3) Q.enqueue(entity)
(4) labelIndexInP ath = 1
(5) If path.Count == 0: Return {entity}
(6) While Q 6= :
cur  Q.dequeue()
Foreach edge  {edge  cur.OutEdges|edge.label = path[labelIndexInP ath]}:
If labelIndexInP ath = k : S
Candidates  Candidates {edge.Destination}
Else :
If labelIndexInP ath > k: Return Candidates
Q.enqueue(edge.Destination)
labelIndexInP ath  labelIndexInP ath + 1
(7) Return Candidates
Procedure ApplyPredicateClause(hP, O1 , . . . , O4 , ti, rule)
Foreach i = 1...4
Oiprediction  
Foreach path = {Oj , {l1 . . . lk }}  rule(i)
S
Oiprediction FindPredicatePathObjects(Oj , hl1 . . . lk i)
Return hO1prediction . . . O4prediction i
Figure 7: Procedure for applying a rule to a new given event. The main procedure is ApplyPredicateClause. This procedure generates the objects of the predicted event O1 . . . O4 given
a rule. The rule is a list of lists of tuples. Each tuple is a concept and a path. For
each such tuple the function FindPredicatePathObjects is applied. This procedure finds
objects that have a path whose labels connect to the given concept. Those objects are
stored in Candidates (step 1). The algorithm holds a queue Q with the frontier (step
2). The queue first holds the given entity (step 3). The procedure holds a counter indicating whether we followed the entire given path (step 4). The algorithm then checks
whether there is an edge with the label path[labelIndexInPath] going out of the object
at the head of the frontier. When the algorithm reaches the end of the given path
(labelIndexInP ath = k), it returns the candidates.

In the information extraction literature, identifying the relationship between facts and
their plausibility has been widely studied. These methods usually estimate the prior probability of a relation by examining the frequency of its pattern in a large corpus, such as
the Web (Banko et al., 2007). For example, for the relation hPeople,arrest,Peoplei these
methods return that this phrase was mentioned 188 times on the Web, and that the relation
hPeople,arrest,[Natural Disaster]i was mentioned 0 times. Similarly, we estimate the prior
probability of an event to occur from its prior appearance in the New York Times, our
653

fiRadinsky, Davidovich & Markovitch

Procedure Pruning Implausible Effects(ev = hPi , O1 , . . . , O4 , ti, generalizationBound)
(1) Foreach j  1 . . . 4 :
generalizationPath = {}
For i  0 . . . generalizationBound
Gen(Oi )  F indP redicateP athObjects(OjS, generalizationP ath)
generalizationPath  generalizationP ath {IsA}
(2) Return Averagei,j,i6=j (M axo1 Gen(Oi ),o2 Gen(Oj ) P M CI(o1 , o2 , i, j))
Figure 8: A procedure for calculating the PMCI of an event. The procedure, at step 1,
first generates all generalizations of type IsA of an object (with a path whose
length is at most generalizationBound). For this purpose it uses the function
FindPredicatePathObjects (defined in Figure 7). The generalization procedure
is repeated on all objects comprising the event ev, and the result is stored in
Gen. The final result of the algorithm is calculated in step 2. For two objects
(o1 , o2 ) in the generalization (Gen), which also contains the original objects, we
find the maximum PMCI. We then compute the final result by averaging over
this maximum PMCI.

primary source of news headlines. We then filter out events that, a priori, have very low
probability to occur.
We present the algorithm in Figure 8. We calculated how many times the semantic concepts representing the event, or their immediate generalizations, actually occurred together
in the past in the same semantic roles. In our example, we check how many times lightning
or other natural phenomena were arrested. Formally, we define point-wise mutual concept
information (PMCI) between two entities or verbs oi , oj (e.g., lightning and arrest) in roles
ri , rj (e.g., actor and action) be defined as

P M CI(oi , oj , ri , rj ) = log

p(oi @ri , oj @rj )
.
p(oi @ri )p(oj @rj )

(3)

Given an event, we calculate the average PMCI of its components. The algorithm filters
out predicted events that have low average PMCI. We assume that the cause and effect
examples in the training are the ground truth, and should yield a high PMCI. Therefore,
we evaluate the threshold for filtering from this training data. That is, we collected all the
effects we observed in the training data and estimated their average PMCI on the entire
NYT dataset.
The reader should note that applying such rules might create a problem. If in the past
no earthquake occurred in Tokyo, the pruning procedure might return low plausibility. To
handle these type of errors, we calculate the PMCI of the upper level categories of entities
(e.g., natural disasters) rather than specific entities (e.g., earthquakes). We therefore restrict
ourselves to only the two upper level categories.
654

fiLearning to Predict from Textual Data

3. Implementation Details
In the previous section, we presented a high-level algorithm that requires training examples
T , knowledge about entities GO , and event action classes P . One of the main challenges of
this work was to build a scalable system to meet those requirements.
We present a system that mines news sources to extract events, constructs their canonical
semantic model, and builds a causality graph on top of those events. The system crawled,
for more than 4 months, several dynamic information sources (see Section 3.1 for details).
The largest information source was the NYT archive, on which optical character recognition
(OCR) was performed. The overall gathered data spans more than 150 consecutive years
(1851  2009).
For generalization of the objects, the system automatically reads Web content and extracts world knowledge. The knowledge was mined from structured and semi-structured
publicly available information repositories. The generation of the causality graph was distributed over 20 machines, using a MapReduce framework. This process efficiently unites
different sources, extracts events, and disambiguates entities. The resulting causality graph
is composed of over 300 million entity nodes, one billion static edges (connecting the different objects encountered in the events), and over 7 million causality edges (connecting
events that were found by Pundit to cause each other). Each rule in the AT was generated
using an average of 3 instances with standard deviation of 2.
On top of the causality graph, a search and indexing infrastructure was built to enable
search over millions of documents. This highly scalable index allows a fast walk on the
graph of events, enabling efficient inference capabilities during the prediction phase of the
algorithm.
3.1 World Knowledge Mining
The entity graph Go is composed of concepts from Wikipedia, ConceptNet (Liu & Singh,
2004), WordNet (Miller, 1995), Yago (Suchanek, Kasneci, & Weikum, 2007), and OpenCyc;
the billion labeled edges of the graph Go are the predicates of those ontologies. In this
section we describe the process by which this knowledge graph is created and the search
system built upon it.
Our system creates the entity graph by collecting the above content, processing feeds,
and processing formatted data sets (e.g., Wikipedia). Our crawler then archives those documents in raw format, and transforms them into RDF (Resource Description Framework)
format (Lassila, Swick, Wide, & Consortium, 1998). The concepts are interlinked by humans as part of the Linked Data project (Bizer et al., 2009). The goal of Bizer et al.s
(2009) Linked Data project is to extend the Web by interlinking multiple datasets as RDF
and by setting RDF links between data items from different data sources. Datasets include
DBPedia (a structured representation of Wikipedia), WordNet, Yago, Freebase, and more.
By September 2010 this had grown to 25 billion RDF triples, interlinked by around 395
million RDF links.
We use SPARQL queries as a way of searching over the knowledge graph. Experiments of
the performance of those queries on the Berlin benchmark (Bizer & Schultz, 2009) provided
evidence for the superiority of Virtuoso open source triple structures for our task.
655

fiRadinsky, Davidovich & Markovitch

3.2 Causality Event Mining and Extraction
Our supervised learning algorithm requires many learning examples to be able to generalize
well. As the amount of temporal data is extremely large, spanning over millions of articles,
the goal of obtaining human annotated examples becomes impossible. We therefore provide
an automatic procedure to extract labeled examples for learning causality from dynamic
content. In this work, we used the NYT archives for the years 1851  2009, WikiNews,
and the BBC  over 14 million articles in total (see data statistics in Table 1). Extracting
causal relations between events in text is a hard task. The state-of-the-art precision of
this task is around 37% (Do, Chan, & Roth, 2011). Our hypothesis is that most of the
information regarding an event can be found in the headlines. These are more structured
and therefore easier to analyze. Many times the headline itself can contain both the cause
and effect event. We assume that only some of the headlines are describing events and
developed an extraction algorithm to identify those headlines and to extract the events
from them. News headlines are quite structured, and therefore the accuracy of this stage
(performed on a representative subset of the data) is 78% (see Section 4.2.1). The system
mines unstructured natural language text found in those headlines, and searches for causal
grammatical patterns. We construct those patterns using causality connectors (Wolff, Song,
& Driscoll, 2002; Levin & Hovav, 1994). In this work we used the following connectors:
1. Causal Connectives: the words because, as, and after as the connectors.
2. Causal prepositions: the words due to and because of.
3. Periphrastic causative verbs: the words cause and lead to.
We constructed a set of rules for extracting a causality pair. Each rule is structured as:
hPattern, Constraint, Priorityi, where Pattern is a regular expression containing a causality
connector, Constraint is a syntactic constraint on the sentence on which the pattern can
be applied, and Priority is the priority of the rule if several rules can be matched. The
following constraints were composed:
1. Causal Connectives: The pattern [sentence1] after [sentence2] was used with the following constraints: [sentence1] cannot start with when, how, where, [sentence2]
cannot start with all, hours, minutes, years, long, decades. In the pattern
After [sentence1], [sentence2] we add the constraint that [sentence1] cannot start
with a number. This pattern can match the sentence after Afghan vote, complaints
of fraud surface but will not match the sentence after 10 years in Lansing, state
lawmaker Tom George returns. The pattern [sentence1] as [sentence2] was used
with the constraint of [sentence2] having a verb. Using the constraint, the pattern
can match the sentence Nokia to cut jobs as it tries to catch up to rivals, but not
the sentence civil rights photographer unmasked as informer.
2. Causal prepositions: The pattern [sentence1][because of, due to] [sentence2] only
required constraints that [sentence1] does not start with when, how, where.
3. Periphrastic causative verbs: The pattern [sentence1] [leads to, Leads to, lead
to, Lead to, led to, Led to] [sentence2] is used, where [sentence1] cannot con656

fiLearning to Predict from Textual Data

tain when, how, where, and the prefix cannot be study or studies. Additionally, as we consider periphrastic causative verbs, we do not allow additional verbs
in [sentence1] or [sentence2].
The result of a rule application is a pair of sentences  one tagged as a cause, and one
tagged as an effect.
Given a natural-language sentence (extracted from an article headline), representing an
event (either during learning or prediction), the following procedure transforms it into a
structured event:
1. Root forms of inflected words are extracted using a morphological analyzer derived
from WordNet (Miller, 1995) stemmer. For example, in the article headline from
10/02/2010: U.S. attacks kill 17 militants in Pakistan, the words attacks, killed
and militants are transformed to attack, kill, and militant respectively.
2. Part-Of-Speech tagging (Marneffe, MacCartney, & Manning, 2006) is performed, and
the verb is identified. The class of the verb is identified using the VerbNet vocabulary
(Kipper, 2006), e.g., kill belongs to P =murder class.
3. A syntactic template matching the verb is applied to extract the semantic relations
and thus the roles of the words (see example in Figure 10). Those templates are based
on VerbNet, which supplies for each verb class a set of syntactic templates. These
templates match the syntax to the thematic roles of the entities in the sentence. We
match the templates even if they are not continuous in the sentence tree. This allows
the match of a sentence even where there is an auxiliary verb between the subject
and the main transitive verb. In our example, the template is NP1 V NP2, which
transforms NP1 to Agent, and NP2 to Patient. Therefore, we match U.S. attacks
to be the Actor, and the militant to be the Patient . If no template can be matched,
the sentence is transformed into a typed-dependency graph of grammatical relations
(Marneffe et al., 2006). In the example, U.S. attacks is identified as the subject of
the sentence (candidate for Actor), militants as the object (candidate for Patient),
and Pakistan as the preposition (using Locations lexicons). Using this analysis, we
identify that the Location is Pakistan.
4. Each word in Oi is mapped to a Wikipedia-based concept. If a word matches more
than one concept, we perform disambiguation by computing the cosine similarity
between the body of the news article and the body of the Wikipedia article associated
with the concept. For example, U.S was matched to several concepts, such as United
States, University of Salford, and Us (Brother Ali album). The most similar by
content was the Wikipedia concept United States. If a word in Oi is not found in
Wikipedia, it is treated as a constant, i.e., generalization will not be applied on it,
but it will be used during similarity calculation. That is, distGen (const1 , const2 ) = 0
if const1 = const2 , or distGen (const1 , const2 ) = k otherwise. In our experiments, we
set k = 4, as it was the length of the longest distance found between two concepts in
GO .
5. The time of the event t is the time of the publication of the article in the news, e.g.,
t =10/02/2010.
657

fiRadinsky, Davidovich & Markovitch

Data Source
NYT
BBC
WikiNews

Number of Titles Extracted
14,279,387
120,445
25,808

Table 1: Data Summary.
Time	 

5	 
QuanGer	 

kill	 
AcGon	 

Troops	 
APribute	 

Afghan	 
1/2/1987	 
11:15AM	 +(3h)	 

Time-
frame	 

Event2	 

5	 Afghan	 troops	 were	 killed	 

Army	 
bombard	 

1/2/1987	 
11:00AM	 +(2h)	 

US	 Army	 

Time-
frame	 

Weapons	 
warehouse	 

AcGon	 

US	 

Event1	 

LocaGon	 

Kabul	 

Instr
ume
nt	 

US	 Army	 bombards	 a	 weapons	 
warehouse	 in	 Kabul	 with	 missiles	 

Missiles	 

Figure 9: A pair of events in the causality graph. The first represents a cause event and the
second represents the effect event. Both were extracted from the headline published on 1/2/1987: 5 Afghan troops killed after US army bombards warehouse
in Kabul.

In our example, the final result is the event e = hMurder-Class, United States of America,
Militant, NULL, Pakistan, 10/02/2010i . The final result of this stage is a causality graph
composed of causality event pairs. Those events are structured as described in Section 2.1.
We illustrate such a pair in Figure 9.
In certain cases, additional heuristics were needed in order to deal with the brevity of
news language. We used the following heuristics:
1. Missing Context  In McDonalds recalls glasses due to cadmium traces, the extracted event cadmium traces needs additional context  Cadmium traces [in McDonalds glasses]. If an object is missing, the first sentence ([sentence1]) subject is
used.
658

fiLearning to Predict from Textual Data

Class Hit-18.1
Roles and Restrictions:
Agent[int control] Patient[concrete] Instrument[concrete]
Members: bang, bash, hit, kick, . . .
Frames:
Example
Syntax
Semantics
cause(Agent, E)
manner(during(E),
directedmotion, Agent)
!contact(during(E),
Paula hit the ball Agent V Patient
Agent, Patient)
manner(end(E),forceful,
Agent)
contact(end(E), Agent,
Patient)

Figure 10: VerbNet Template.
2. Missing entities and verbs  the text 22 dead should be structured to the event 22
[people] [are] dead. If a number appears as the subject, the word people is added
and used as the subject, and be is added as the verb.
3. Anaphora resolution  the text boy hangs himself after he sees reports of Husseins
execution is modeled as [boy1 ] sees reports of Husseins execution causes [boy1 ]
hangs [boy1 ] (Lappin & Leass, 1994).
4. Negation  the text Matsui is still playing despite his struggles should be modeled as:
[Matsui] struggles causes the event Matsui is [not] playing. Modeling preventive
connectors (e.g., despite) requires negation of the modeled event.

4. Experimental Evaluation
In this section, we describe a set of experiments performed to evaluate the ability of our
algorithms to predict causality. We first evaluate the predictive precision of our algorithm,
continue with analyzing each part of the algorithm separately, and conclude with a qualitative evaluation.
4.1 Prediction Evaluation
The prediction algorithm was trained using news articles from the period 1851  2009. The
world knowledge used by the algorithm was based on Web resource snapshots (Section 3)
dated until 2009. The evaluation was performed on separate data  Wikinews articles from
the year 2010. We refer to this data as the test data.
As the task tackled by our algorithm has not been addressed before, we could not find
any baseline algorithm to compare against. We therefore decided to compare our algorithms
performance to that of human predictors. Our algorithm and its human competitors were
assigned the basic task of predicting what event a given event might cause. We evaluate
each such prediction using two metrics. The first metric is accuracy: whether the predicted
659

fiRadinsky, Davidovich & Markovitch

event actually occurred in the real world. There are two possible problems with this metric.
First, a predicted event, though plausible, still might not actually have occurred in the real
world. Second, the predicted event might have happened in the real world but was not
caused by the given event, for example, in trivial predictions that are always true (the
sun will rise). We therefore use an additional metric, event quality, the likelihood that the
predicted event was caused by the given event.
The experiments were conducted as follows:
1. Event identification  our algorithm assumes that the input to the predictor h is an
event. To find news headlines that represent an event, we randomly sample n = 1500
headlines from the test data. For each headline, a human evaluator is requested to
decide whether the headline is an event that can cause other events. We denote the
set of headlines labeled as events as E. We again randomly sample k = 50 headlines
from E. We denote this group as C.
2. Algorithm event prediction  on each headline ci  C, Pundit performs event extraction, and produces an event P undit(ci ) with the highest score of being caused by the
event represented by ci . Although the system provides a ranked list of results, to
simplify the human evaluation of theses results, we consider only the highest score
prediction. If there is a tie for the top score, we pick one at random. The results of
this stage are the pairs: {(ci , P undit(ci ))|ci  C}.
3. Human event prediction  For each event ci  C, a human evaluator is asked to predict
what that event might cause. Each evaluator is instructed to read a given headline
and predict its most likely outcome, using any online resource and with no time limit.
The evaluators are presented with empty structured forms with the 5 fields for the
output event they need to provide. The human result is denoted as human(ci ). The
results of this stage are the pairs: {(ci , human(ci ))|ci  C}.
4. Human evaluation of the results 
(a) Quality: We present m = 10 people with a triplet (ci , human(ci ), P undit(ci )).
The human evaluators are asked to grade (ci , human(ci )) and (ci , P undit(ci ))
on a scale of 0-4 (0 is a highly implausible prediction and 4 is a highly plausible
prediction). They were allowed to use any resource and were not limited by time.
The human evaluators were different from those who performed the predictions.
(b) Accuracy: For each predicted event, we checked the news (and other Web resources), up to a year after the time of the cause event, to see whether the
predicted events were reported.
Human evaluation was conducted using Amazon Mechanical Turk, an emerging utility
for performing user study evaluations, which was shown to be very precise for certain tasks
(Kittur, Chi, & Suh, 2008). During the evaluation, tasks are created by routing a question
to random users and obtaining their answers. We filtered the raters using a CAPTCHA.
We restricted to only US-based users, as the events used by our system are extracted from
the NYT. We did not perform any other manual filtering of the results. The average times
for all human tasks are reported in table 2. We observed that the most time-consuming
660

fiLearning to Predict from Textual Data

Human Event
Identification
1 min 26 sec

Human Event
Prediction
4 min 10 sec

Human Evaluation
(Quality)
1 min 44 sec

Human Evaluation
(Accuracy)
6 min 24 sec

Table 2: Response times of human evaluators for the different evaluation tasks.

Pundit
Humans

[0-1)

[1-2)

[2-3)

[3-4]

Average
Quality

0
0

2
3

19
24

29
23

3.08
2.86

Table 3: Quality results. The histogram of the rankings of the users for humans and the
algorithm.

task for humans was to verify that the event indeed happened in the past. The other timeconsuming task was Human Event Prediction. This is not surprising, as both cases required
more use of external resources, whereas the quality evaluation only measured whether those
events make sense. Additionally, we manually investigated the human evaluations in each
category, and did not find correlation between the response time and quality of the human
prediction. As we used Mechanical Turk, we do not know which external resources the
evaluators used. We measured inter-rater reliability using Fleiss kappa statistical test,
where  measures the consistency of the ratings. For the raters in our test, we obtained
 = 0.3, which indicates fair agreement (Landis & Koch, 1977; Viera & Garrett, 2005).
This result is quite significant, for the following reasons:
1. Conservativeness of this measure.
2. Subjectivity of the predictions  asking people whether a prediction makes sense often
leads to high variance in responses.
3. Small dataset  the tests were performed with 10 people asking to categorize into 5
different scales of plausibility over 50 examples.
4. Lack of formal guidelines for evaluating the plausibility of a prediction  no instructions were given to the human evaluators regarding what should be considered plausible and what is not.
Additionally, for comparison, similar tasks in natural language processing, such as sentence
formality identification (Lahiri, Mitra, & Lu, 2011), usually reach kappa values of 0.1  0.2.
The quality evaluation yielded that Pundits average predictive precision is 3.08/4 (3 is
a plausible prediction), as compared to 2.86/4 for the humans. For each event, we average
the results of the m rankers, producing an average score for the algorithms performance
on the event, and an averaged score for the human predictors (see Table 3). We performed
a paired t-test on the k paired scores. The advantage of the algorithm over the human
evaluators was found to be statistically significant, with p  0.05.
661

fiRadinsky, Davidovich & Markovitch

Algorithm
Pundit
Humans

Average Accuracy
63%
42%

Table 4: Prediction accuracy for both human and algorithm.
The accuracy results are reported in Table 4. We performed a Fishers exact test (as
the results are binary) on the k paired scores. The results were found to be statistically
significant, p  0.05.
4.2 Component Analysis
In this section, we report the results of our empirical analysis of the different parts of the
algorithm.
4.2.1 Evaluation of the Extraction Process
In Section 3.1, we described a process for extracting causality pairs from the news. These
pairs are used as a training set for the learning algorithm. This process consists of two
main parts: causality identification and event extraction. We perform a set of experiments
to provide insights on this extracted training data quality.
Causality Extraction Experiment The first step in building a training set consists of
using causality patterns to extract pairs of sentences for which the causality relation holds.
To assess the quality of this process, we randomly sampled 500 such pairs from the training
set and presented them to human evaluators. Each pair was evaluated by 5 humans. We
filtered the raters using a CAPTCHA and filtered out outliers. The evaluators were shown
two sentences the system believed to be causally related and they were asked to evaluate
the plausibility of this relation on a scale of 0-4.
The results show that the averaged precision of the extracted causality events is 3.11 out
of 4 (78%), where 3 means a plausible causality relation, and 4 means a highly plausible
causality relation. For example, the causality pair: pulling over a car  2 New Jersey
police officers shot, got a very high causality precision score, as this is a plausible causeeffect relation, which the system extracted from the headline 2 New Jersey Police Officers
Shot After Pulling Over a Car.
For comparison, other temporal rule extraction systems (Chambers, Wang, & Jurafsky,
2007) reach precision of about 60%. The better performance of our system can be explained
by our use of specially crafted templates (we did not attempt to solve the general problem
of temporal information extraction).
Most causality pairs extracted were judged to be of high quality. The main reason for
errors was that some events, although reported in the news and matching the templates we
have described, are not common-sense causality knowledge. For example, Aborted landing
in Beirut  Hijackers fly airliner to Cyprus, was rated unlikely to be causally related,
although the event took place on April 09, 1988.

662

fiLearning to Predict from Textual Data

Quality Precision

Action
93%

Actor
74%

Object
76%

Instrument
79%

Location
79%

Time
100%

Table 5: Extraction precision for each of the 5 event components using the causality patterns.

Actor
Matching
84%

Object
Matching
83%

Instrument
Matching
79%

Location
Matching
89%

Action
Matching
97%

Table 6: Entity-to-ontology matching precision.

Event Extraction Experiment After a pair of sentences is determined to have a casualty relation, our algorithm extracts a structured event from each of the sentences. This
event includes the following roles: action, actor, object, instrument, and time.
To assess the the quality of this process, we used the 500 pairs from the previous experiment and presented each of the 1000 associated sentences to 5 human evaluators. The
evaluators were shown a sentence together with its extracted roles: action, actor, object,
instrument, and time, and they were asked to mark each role assignment as being right or
wrong.
Table 5 shows that the precision for the extracted event components ranges from 74 
100%. In comparison, other works (Chambers & Jurafsky, 2011) for extracting entities for
different types of relations reach 42  53% precision. The higher precision of our results is
mainly due to the use of domain-specific templates.
We performed additional experiments to evaluate the matching of every entity from the
above experiment to the world-knowledge ontology. The matching was based on semantic
similarity. Each ranker was asked to indicate whether the extracted entity was mapped
correctly to a Wikipedia URI. The results are summarized in Table 6.
4.2.2 Evaluation of the Event Similarity Algorithm
Both the learning and prediction algorithms strongly rely on the event similarity function
dist described in Section 2.4. To evaluate the quality of this function, we randomly sampled
30 events from the training data and found for each the most similar event from the entire
past data (according to the similarity function). A human evaluator was then asked to
evaluate the similarity of these events on a scale of 15. We repeated the experiment,
replacing the average aggregator function f with minimum and maximum functions.
The results are presented in Table 7. The general precision of the average function
was high (3.9). Additionally, the average function performed substantially (confirmed by
a t-test) better than over the minimum and maximum. This result indicates that distance functions that aggregate over several objects of the structured event (rather than just
selecting the minimum or maximum of one of the events) yield the highest performance.
663

fiRadinsky, Davidovich & Markovitch

Minimum
1.9

Maximum
3.5

Average
3.9

Table 7: Comparison of the different aggregations for the event-similarity f .
4.2.3 The Importance of Abstraction
Given a cause event whose effect we wish to predict, we use the algorithm described in
Section 2.4 to identify similar generalized events. To evaluate the importance of this stage,
we compose an alternative matching algorithm, similar to the nearest-neighbor approach
(as applied by the work by Gerber, Gordon, & Sagae, 2010), that matches the cause event to
the cause events of the training data. Instead of building an abstraction tree, the algorithm
simply finds the closest cause in the past based on text similarity. We then rank the matched
results using TF-IDF measure.
We applied both our original algorithm and this baseline algorithm on the 50 events
used for prediction. For each event, we asked a human evaluator to compare the prediction
of the original and the baseline algorithm. The results showed that in 83% of the cases
the predictions with generalization were rated as more plausible than those of the nearestneighbor approach without generalization.
4.2.4 Analysis of Rule Generation Application
In order to generate an appropriate prediction with respect to the given cause event, a
learned rule is applied, as described in Section 2.5. We observe that in 31% of the predictions, a non-trivial rule was generated and applied (that is, a non-NULL rule that does not
simply output the effect it observed in the matched past cause-effect pair example). Out of
those, the application predicted correctly in more than 90% of the cases and generated a
plausible object in the effect. These results indicate that generalization and rule-generation
techniques are essential to the performance of the algorithm.
4.2.5 Analysis of Pruning Implausible Causation
To eliminate situations in which a generated prediction is implausible, we devised an algorithm (Section 2.7) that prevents implausible predictions. We randomly selected 200
predictions from the algorithm predictions based on the human-labeled events extracted
from the Wikinews articles (see Section 4.1). A human rater was requested to label predictions that are considered implausible. We then applied our filtering rules on the 200
predictions as well. The algorithm found 15% of the predictions to be implausible with 70%
precision and 90% recall with respect to the human label. A qualitative example of a filtered
prediction is Explosion will surrender for the cause event Explosion in Afghanistan kills
two.
4.3 Qualitative Analysis
For a better understanding of the algorithms strengths and weaknesses we now present
some examples of results. Given the event Louisiana flood, the algorithm predicted that
[number] people will flee. The prediction process is illustrated in Figure 11.
664

fiLearning to Predict from Textual Data

1. Raw data:
The above prediction was based on the following raw news articles:
(a) 150000 flee as hurricane nears North Carolina coast.
(b) A million flee as huge storm hits Texas coast.
(c) Thousands flee as storm whips coast of Florida.
(d) Thousands in Dallas Flee Flood as Severe Storms Move Southwest.
2. Causality pair extraction:
The as template was used to process the above headlines into the following structured events:
(a) Cause Event: near (Action); hurricane (Actor); Coast(Object); North Carolina
(Object Attribute) ; (Instrument); Carolina (Location); 31 Aug 1993 (Time).
Effect Event: flee (Action); People (Actor); 150000(Actor Attributes); Carolina
(Location); 31 Aug 1993 (Time).
(b) Cause Event: hit (Action); Storm (Actor); Huge (Actor Attributes); Coast(Object);
Texas (Object Attribute); Texas (Location); 13 Sep 2008 (Time).
Effect Event: flee (Action); People (Actor); million(Actor Attributes); Texas
(Location); 13 Sep 2008 (Time).
(c) Cause Event: whip (Action); Storm (Actor); Coast(Object); Florida (Object
Attribute); Florida (Location); March 19, 1936 (Time).
Effect Event: flee (Action); People (Actor); thousands(Actor Attributes); Florida
(Location); March 19, 1936 (Time).
(d) Cause Event: move (Action); Storm (Actor); Severe (Actor Attributes); Dallas
(Location); May 27, 1957 (Time).
Effect Event: flee (Action); People (Actor); thousands(Actor Attributes);
Flood(Object); Dallas (Location); May 27, 1957 (Time).
3. Learning the abstraction tree:
The above four events were clustered together in the AT. They were clustered in the
same node because the causes were found to be similar: the actors were all weather
hazards and the location was a state of the United States. The effects were found
to be similar as the actions and actors were similar across all events, and the actor
attributes were all numbers. For this generalization, the following world knowledge
was used:
(a) Storm, hurricane and flood are weather hazards (extracted from the in-category
relation in Wikipedia).
(b) Carolina, Texas, and California are located in the United States (extracted
from the located-in relation in Yago).
4. Prediction:
665

fiRadinsky, Davidovich & Markovitch

During the prediction, the event Louisiana flood (which did not occur in the training
examples) was found most similar to the above node, and the node rule output was
that [number] people will flee.

 150000 flee as hurricane
nears north Carolina coast.
 A million flee as
huge storm hits
Texas coast.

Cause Event: near (Action);
hurricane (Actor);
Coast(Object);
North Carolina (Object Attribute) ;
(Instrument); Carolina (Location);
31 Aug 1993 (Time).
Effect Event: flee (Action);
People (Actor);
150000(Actor Attributes);
Carolina (Location);
31 Aug 1993 (Time).

 Storm, Hurricane and Flood   
`Weather hazards''
 Carolina, Texas, California, Nebraska 
``United States''


 

  



Louisiana(Location);
Flood (Actor)

people (Actor);
flee (Action)

Implausible	 
event	 lter	 

Figure 11: Examples of a prediction
As another example, given the event 6.1 magnitude aftershock earthquake hits Haiti,
the highest matching predictions were: [number] people will be dead, [number] people
will be missing, [number] magnitude aftershock earthquake will strike island near Haiti
and earthquake will turn to United States Virgin Islands. The first three predictions seem
very reasonable. For example, the third prediction came from a rule that natural disasters
hitting countries next to a shore tend to affect nearby countries. In our case it predicted
that the earthquake will affect the United States Virgin Islands, which are geographically
close to Haiti. The fourth prediction, however, is not very realistic as an earthquake cannot
change its course. It was created from a match with a past example of a tornado hitting
a country on a coast. The implausible causation filters this prediction, as it has very low
PMCI, and the output of the system is [number] people will be dead. This example is
also interesting, as it issues a prediction using spatial locality (the United States Virgin
Islands are [near] Haiti).
Additional examples out of the 50 in the test and their predictions can be seen in Table
8.
666

fiLearning to Predict from Textual Data

Cause event

Human-predicted effect event

Al-Qaida demands hostage
exchange
Afghanistans parliament rejects Karzais cabinet nominations
Remains of 1912 expedition
plane found in Antarctica

Al-Qaida
exchanges
hostage
Parliament
accepts
Karzais cabinet nominations
Europe museums vie for remains

North Korea seeks diplomatic
relations with the US
Volcano erupts in Democratic
Republic of Congo
Icelands President vetoes repayment of Ice save losses
Death toll from Brazil mudslides rises to sixty
7.0 magnitude earthquake
strikes Haitian coast
2 Palestinians reportedly shot
dead by Israeli troops
Professor of Tehran University killed in bombing

UN officials offer mediation
services
Scientists in Republic of
Congo investigate lava beds
Banks in Reykjavik report
record withdrawals
Rescuers in Brazil abandon rescue efforts
Tsunami in Haiti affects
coast
Israeli citizens protest against
Palestinian leaders
Tehran students remember
slain professor in memorial
service
Mafia kills people with guns in
town
Islamist group would adopt
another name in the UK
German officials suspend tariffs
Someone will be fired

Alleged drug kingpin arrested
in Mexico
UK bans Islamist group
China overtakes Germany as
worlds biggest exporter
Cocaine found at Kennedy
Space Center

Algorithm-predicted effect event
A country will refuse
the demand
Many critics of rejection
Enduring
mystery
will be solved in
Antarctica
North Korea rift will
grow
Thousands of people
flee from Congo
Official administration reaction issued
Testimonies will be
heard
Tsunami warning is
issued
Israeli troops will
face scrutiny
Professor
funeral
will be held
Kingpin will be sent
to prison
Group will grow
Wheat price will fall
People will be arrested

Table 8: Human and algorithm predictions for events. Predictions in bold were labeled by
the evaluators as correct predictions.

4.4 Discussion
In our experiments we only report the precision of our algorithms. Further experiments
measuring the recall of the system are necessary. However, in our experiments each validation step required human intervention. For example, validating that a prediction occurred in
the future news. In order to perform a full recall experiment one should apply the algorithm
on all the news headlines reported on a certain day and measure the appearance of all the
667

fiRadinsky, Davidovich & Markovitch

corresponding predictions in the future news. Unfortunately, performing human validation
on such a large prediction space is hard. We leave the task of performing experiments to
provide a rough estimate of recall to future work.
It is common practice to compare system performance to previous systems tackling the
same problem. However, the ambitious task we tackled in this work had no immediate
baselines to compare with. That is, there was no comparable system neither in scale nor in
the ability to take an arbitrary cause event in natural language and output an effect event in
natural language. Instead, we compared to the only agents we know capable of performing
such a task  humans.
Although the results indicate the superiority of the system over such human agents, we
do no claim that the system predictions perform better than humans. We rather provide
evidence that the system provides similar predictions to that of humans, and sometimes
even outperforms human ability to predict, as can be supported by the superiority of the
system in the accuracy evaluation.
To fully support the claim of superiority of the system over humans, wider experiments
should be performed. Experiments larger by an order of magnitude can provide results
with higher agreement between raters and shed light on the different types of events where
the systems performance is better. Additionally, more experiments comparing the system
performance to that of experts in the fields of each individual prediction can be valuable
as well. At this point, we assume the performance of experts would be higher than that
of our algorithm. The main reason for this is the causality knowledge used to train the
algorithms. This knowledge is extracted from headlines that tend to have simple causality
contents, which is easily understandable by the general population. This type of knowledge
limits the complexity of the predictions that can be made by Pundit. Pundit predictions
therefore that tend to be closer to common knowledge of the average human. In order to
predict more complex events we would need to rely on better training examples than news
headlines alone.
The evaluation presented in this section provides evidence of the quality of the predictions that the system can provide. Our results are impressive in the sense that they
are comparable to that of humans, thus providing evidence to the ability of a machine to
perform one of the most desirable goals of general AI.

5. Related Work
We are not aware of any work that attempts to perform the task we face: receive arbitrary
news events in natural language representation and predict events they can cause. Several
works, however, deal with related tasks. In general, our work does not focus on better information extraction or causality extraction techniques, but rather on how this information
can be leveraged for prediction. We present novel methods of combining world knowledge
with event extraction methods to represent coherent events, and present novel methods for
rule extraction and generalization using this knowledge.
5.1 Prediction from Web Behavior, Books and Social Media
Several works have focused on using search-engine queries for prediction in both traditional
media (Radinsky, Davidovich, & Markovitch, 2008) and blogs (Adar, Weld, Bershad, &
668

fiLearning to Predict from Textual Data

Gribble, 2007). Ginsberg et al. (2009) used queries for predicting H1N1 influenza outbreaks. In the context of causality recognition, Gordon, Bejan, and Sagae (2011) present a
methodology for mining blogs to extract common-sense causality. The evaluation is done on
a human-labeled dataset where each test consists of a fact and two possible effects. Applying point-mutual information to personal blog stories, the authors select the best prediction
candidate. The work differs from ours in that the authors focus on personal commonsense mining and do not consider whether their predictions actually occurred. Other works
focused on predicting Web content change itself. For example, Kleinberg (2002, 2006) developed general techniques for summarizing the temporal dynamics of textual content and for
identifying bursts of terms within content. Similarly, Amodeo, Blanco, and Brefeld (2011)
built a time series model over publication dates of documents relevant to a query in order to
predict future bursts. Social media were used to predict riots (Kalev, 2011) and movie box
office sales (Asur & Huberman, 2010; Joshi, Das, Gimpel, & Smith, 2010; Mishne, 2006).
Other works (Jatowt & Yeung, 2011; Yeung & Jatowt, 2011; Michel, Shen, Aiden, Veres,
Gray, Google Books Team, Pickett, Hoiberg, Clancy, Norvig, Orwant, Pinker, Nowak, &
Aiden, 2011) have explored the use of text mining techniques over news and books to explain
how culture develops, and what peoples expectations and memories are.
Our work differs from the above in several ways: First, we present a general-purpose
prediction algorithm rather than a domain-specific one. Second, unlike the above works,
ours combines a variety of heterogenous online sources, including world knowledge mined
from the Web. Finally, we focus on generation of future event predictions represented
entirely in natural language, and provide techniques to enrich and generalize historical
events for the purpose of future event prediction.
5.2 Textual Entailment
A related topic to our work is that of textual entailment (TE) (Glickman, Dagan, & Koppel,
2005). A text t is said to entail a textual hypothesis h if people reading it agree that
the meaning of t implies the truth of h. TE can be divided into three main categories:
recognition, generation, and extraction. In this section, we provide a short summary of
the first two categories. For a more detailed overview we refer the reader to the survey by
Androutsopoulos and Malakasiotis (2010). We then discuss the specific task of causality
extraction from text in Section 5.3.4.
5.2.1 Textual Entailment recognition
In this task, pairs of texts are given as input, and the output is whether TE relations hold
for the pair. Some approaches map the text to logical expressions (with some semantic enrichment, using WordNet, for example) and perform logical entailment checks, usually using
theorem provers (Raina, Ng, & Manning, 2005; Bos & Markert, 2005; Tatu & Moldovan,
2005). Other approaches map the two texts to a vector space model, where each word
is mapped to strongly co-occurring words in the corpus (Mitchell & Lapata, 2008), and
then similarity measures over those vectors are applied. Some measure syntactic similarity by applying graph similarity measure on the syntactic dependency graphs of the two
texts (Zanzotto, Pennacchiotti, & Moschitti, 2009). Similarly, other methods measure the
semantic distance similarity between the words in text (Haghighi, 2005), usually exploiting
669

fiRadinsky, Davidovich & Markovitch

other resources such as WordNet as well. The last set of approaches represents the two texts
in a single feature vector and trains a machine learning algorithm, which later, given two
new texts represented via a vector, can determine whether they entail each other (Bos &
Markert, 2005; Burchardt, Pennacchiotti, Thater, & Pinkal, 2009; Hickl, 2008). For example, Glickman et al. (2005) show a naive Bayes classifier trained on lexical features, i.e., the
number of times that words of t appeared with words of h. Other features usually include
polarity (Haghighi, 2005), whether the theorem prover managed to prove entailment (Bos
& Markert, 2005), or tagging of the named entities to the categories people, organizations,
or locations.
5.2.2 Textual Entailment Generation
Here we discuss TE generation, where, given an expression, the system should output a
set of expressions that are entailed by the input. This task is most closely related to
the one presented in this work: in TE generation, a text is received and an entailed text is
generated as output. Androutsopoulos and Malakasiotis (2010) mention that no benchmarks
exist to evaluate this task, and the most common and costly approach is to evaluate using
human judges. We also encountered this difficulty in our own task, and performed human
evaluation.
TE generation methods can be divided into two types: those that use machine translation techniques and those that use template-based techniques. Those that use machine
translation techniques try to calculate the set of transformations with the highest probability, using a training corpus. Quirk, Brockett, and Dolan (2004) cluster news articles
referring to the same event, select pairs of similar sentences, and apply the aforementioned
techniques. Other methods use template-based approaches on large corpora, such as the
Web. Some methods (Idan, Tanev, & Dagan, 2004) start with an initial seed of sentences
(composed of entities), and use a search engine to find other entities for which these entailment relations hold. Those relations are used as templates. To find additional entities for
which these relations hold, the relations themselves are then searched again. The TE generation system, given a text, matches it to a template and outputs all the texts that matched
this template. Others (Ravichandran, Ittycheriah, & Roukos, 2003) also add additional
filtering techniques on those templates.
Our work is most closely related to the template-based approach. We have crafted a
new set of templates to extract causality pairs from the news.
5.3 Information Extraction
Information Extraction is the study of automatic extraction of information from unstructured sources. We categorizes the types of information extracted into three types: entities,
relationships between entities, and higher-order structures such as tables and lists. The
most closely related tasks to ours are those of entity extraction and relation extraction; for
the rest we refer the reader to the survey by Sarawagi (2008). The former task, similar to
our process of extracting concepts, deals with extracting noun phrases from text. In the
latter task, given a document and a relation as input, the problem is to extract all entity
pairs in the document for which this relation holds. Whereas the above works deal only
with one element of our problem  extraction of information needed to understand a given
670

fiLearning to Predict from Textual Data

causality, we deal with the actual causality prediction. We do not claim to create more
precise information extraction methods, but rather try to leverage all this knowledge to
perform an important AI task  future event prediction.
5.3.1 Entity Extraction
For entity extraction, two categories of methods exist  rule-based and statistical methods.
Rule-based methods (Riloff, 1993; Riloff & Jones, 1999; Jayram, Krishnamurthy, Raghavan,
Vaithyanathan, & Zhu, 2006; Shen, Doan, Naughton, & Ramakrishnan, 2007; Ciravegna,
2001; Maynard, Tablan, Ursu, Cunningham, & Wilks, 2001; Hobbs, Bear, Israel, & Tyson,
1993) define contextual patterns consisting a regular expression over features of the entities
in the text (e.g., the entity word, part-of-speech tagging). Those rules are either manually
coded by a domain expert or learned using bottom-up (Ciravegna, 2001; Califf & Mooney,
1999) or top-down learners (Soderland, 1999). Others follow statistical methods that define
numerous features over the sentence and then treat the problem as a classification problem,
applying well-known machine learning algorithms (e.g., Hidden Markov Models; Agichtein
& Ganti, 2004; Borkar, Deshmukh, & Sarawagi, 2001). Our system does not deal with the
many challenges in this field, as we propose a large scale domain-specific approach driven
by specific extraction templates.
5.3.2 Relation Extraction
Relation extraction has been developed widely in the last years from large text corpora
(Schubert, 2002) and, in particular, from different Web resources, such as general Web
content (Banko et al., 2007; Carlson et al., 2010; Hoffmann, Zhang, & Weld, 2010), blogs
(Jayram et al., 2006), Wikipedia (Suchanek et al., 2007), and news articles (e.g., the topic
detection and tracking task (Section 5.3.3)). Given two entities, the first task in this domain is to classify their relationship. Many feature-based methods (Jiang & Zhai, 2007;
Kambhatla, 2004; Suchanek, 2006) and rule-based methods (Aitken, 2002; Mcdonald, Chen,
Su, & Marshall, 2004; Jayram et al., 2006; Shen et al., 2007) have been developed for this
task. Most methods use different features extracted from the text, such as the words, the
grammar features, such as parse tree and dependency graphs, and features extra ion from
external relation repositories (e.g., Wikipedia Infobox) to add additional features (Nguyen
& Moschitti, 2011; Hoffmann, Zhang, Ling, Zettlemoyer, & Weld, 2011). Labeled training
examples, from which those feature are extracted, are then fed into a machine learning classifier, sometimes using transformations such as kernels (Zhao & Grishman, 2005; Zhang,
Zhang, Su, & Zhou, 2006; Zelenko, Aone, & Richardella, 2003; Wang, 2008; Culotta &
Sorensen, 2004; Bunescu & Mooney, 2005; Nguyen, Moschitti, & Riccardi, 2009), which,
given new unseen entities, will be able to classify them into those categories.
Given a relation, the second common task in this domain is to find entities that satisfy
this relation. Out of all information extraction tasks, this task is most relevant to ours, as
we try to find structured events for which the causality relation holds. Most works in this
domain focus on large collections, such as the Web, where labeling all entities and relations
is infeasible (Agichtein & Gravano, 2000; Banko et al., 2007; Bunescu & Mooney, 2007;
Rosenfeld & Feldman, 2007; Shinyama & Sekine, 2006; Turney, 2006). Usually seed entity
databases are used, along with some manual extraction templates, and then expanded and
671

fiRadinsky, Davidovich & Markovitch

filtered iteratively. Sarawagi states that in spite of the extensive research on the topic,
relationship extraction is by no means a solved problem. The accuracy values still range
in the neighborhood of 50%70% even in closed benchmark datasets . . . In open domains
like the Web, the state-of-the-art systems still involve a lot of special case handling that
cannot easily be described as principled, portable approaches. (Sarawagi, 2008, p. 331).
Similarly, in our task the size of our corpus does not allow us to assume any labeled sets.
Instead, like the common approaches presented here, we also start with a predefined set of
patterns.
5.3.3 Temporal Information Extraction
The temporal information extraction task deals with extraction and ordering of events from
many events over time. Temporal information extraction can be categorized into three
main subtasks  predicting the temporal order of events or time expressions described in
text, predicting the relation between those events, and identifying when the document was
written. This task has been found to be important in many natural language processing
applications, such as question answering, information extraction, machine translation and
text summarization, all of which require more than mere surface understanding. Most of
these approaches (Ling & Weld, 2010; Mani, Schiffman, & Zhang, 2003; Lapata & Lascarides, 2006; Chambers et al., 2007; Tatu & Srikanth, 2008; Yoshikawa, Riedel, Asahara,
& Matsumoto, 2009) learn classifiers that predict a temporal order of a pair of events from
predefined features of the pair.
Other related works deal with topic detection and tracking (Cieri, Graff, Liberman,
Martey, & Strassel, 2000). This area includes several tasks (Allan, 2002). In all of them,
multiple, heterogenous new sources are used, including audio. The story segmentation task
aims to segment data into its constituent stories. The topic tracking task  e.g., the work by
Shahaf and Guestrin (2010)  aims to find all stories discussing a certain topic. A subtask
of this is the link detection task which, given a pair of stories, aims to classify whether
they are on the same topic. The topic detection task  e.g. the works by Ahmed, Ho,
Eisenstein, Xing, Smola, and Teo (2011) and Yang, Pierce, and Carbonell (1998)  aims to
detect clusters of topic-cohesive stories in a stream of topics. The first-story detection task
aims to identify the first story on a topic (Jian Zhang & Yang, 2004). In this paper, we
focused on short text headlines and the extraction of events from them. Our work differs
from that of temporal information extraction, in that we generate predictions of future
events, whereas temporal information extraction tasks focus on identifying and clustering
the text corpus into topics.
5.3.4 Causality Pattern Extraction and Recognition
In the first stage of our learning process we extract causality pairs from text. Causality
extraction has been discussed in the literature in the past, and can be divided into the
following subgroups:
1. Use of handcrafted domain-specific patterns. Some studies deal with causality extraction using specific domain knowledge. Kaplan and Berry-Rogghe (1991) used scientific
texts to create a manually designed set of propositions which were later applied on
672

fiLearning to Predict from Textual Data

new texts to extract causality. These methods require handcrafted domain knowledge,
which is problematic to obtain for real-world tasks, especially in large amounts.
2. Use of handcrafted linguistic patterns. These works use a more general approach
by applying linguistic patterns. For example, Garcia (1997) manually identified 23
causative verb groups (e.g., to result in, to lead to, etc.). If a sentence contained one
of those verbs, it was classified as containing a causation relation. A precision of 85%
was reported. Khoo et al. (2000) used manually extracted graphical patterns based
on syntactic parse trees, reporting accuracy of about 68% on an English medical
database. Similarly, Girju and Moldovan (2002) defined lexicon-syntactic patterns
(pairs of noun phrases with a causative verb in between) with additional semantic
constraints.
3. Semi-supervised pattern learning approaches. This set of approaches uses supervised
machine learning techniques to identify causality in text. For example, Blanco et al.
(2008) and Sil et al. (2010) use syntactic patterns as features that are later fed into
classifiers, whose output is whether the text implies causality or the cause and effect
themselves.
4. Supervised pattern learning approaches. There have been many works on design
inference rules to discover extraction patterns for a given relation using training examples (Riloff, 1996; Riloff & Jones, 1999; Agichtein & Gravano, 2000; Lin & Pantel,
2001). Specifically, Chan and Lam (2005) dealt with the problem of creating syntactic
patterns for cause-effect extraction.
In the domain of causality pattern extraction, our work most resembles the handcrafted
linguistic patterns pattern approaches. We evaluated their performance on our specific
domain. Since our goal was to obtain a very precise set of examples to feed into our
learning, we chose to follow such an approach as well.
5.4 Learning Causality
We have drawn some of our algorithmic motivation from work in the machine learning
community. In this section, we give a partial review of the main areas of machine learning
that are relevant to our work.
5.4.1 Bayesian Causal Inference
The functional causal model (Pearl, 2000) assumes a set of observables X1 . . . Xn , which are
the vertices of a directed acyclic graph G. The semantics of the graph is that parents of a
node are its directed causes. It was shown to satisfy Reichenbachs common cause principle,
which states that for a node Z with children X, Y , if X and Y are statistically dependent,
then there is a Z causally influencing both. This model, similar to a Bayesian network,
satisfies several conditions: (1) Local Causal Markov condition: a node is statistically
independent of non-descendants, given its parents; (2) Global Causal
Q Markov condition: dseparation criterion; (3) Factorization criterion: P (X1 , . . . , Xn ) = i P (Xi |P arents(Xi )).
The theoretical literature on the inference and learning of causality models is extensive.
Those models resemble our work in the use of structural models. The literature on inference
673

fiRadinsky, Davidovich & Markovitch

and learning of causality models is extensive, but to our knowledge there are no solutions
that scale to the scope of tasks discussed in this paper. In contrast with Bayesian approach,
the causality graph in our work contains less detailed information. Our work combines
several linguistic resources that were learned from data with several heuristics to build the
causality graph.
5.4.2 Structured Learning
An important problem in the machine learning field is structured learning, where the input
or the output of the classifier is a complex structure, such as relational domain, where each
object is related to another, either in time or in its features. Our task resembles structured
learning in that we also use structured input (structured events given as input) and produce
a structured event as output.
Many generative models have been developed, including hidden Markov models, Markov
logic networks, and conditional random fields, among others. Other approaches use transformations, or kernels, that unite all the objects, ignoring the structure, and then feed it
into a standard structured classifier, e.g., kernelized conditional random fields (Lafferty,
Zhu, & Liu, 2004), maximum margin Markov networks (Taskar, Guestrin, & Koller, 2003),
and others (Bakir, Hofmann, Scholkopf, Smola, Taskar, & Vishwanathan, 2007). When
dealing with complex output, such as annotated parse trees for natural language problems,
most approaches define a distance metric in the label space between the objects, and they
again apply standard machine learning algorithms, e.g., structured support vector machines
(Joachims, 2006).
5.4.3 Learning from Positive Examples (One Class Classification)
As our system is only fed examples of the sort a causes b, and no examples of the sort a
does not cause b, we must deal with the problem of learning from positive examples only.
This is a challenge for most multi-class learning mechanisms, which require both negative
and positive examples. Some theoretical studies of the possibility of learning from only
positive unlabeled data are provided in the work by Denis (1998) (probably approximately
correct (PAC) learning) and Muggleton (1996) (Bayesian learning).
Most works (Tax, 2001; Manevitz & Yousef, 2000; Manevitz, Yousef, Cristianini, ShaweTaylor, & Williamson, 2001) in this domain develop algorithms that use one-class SVM
(Vapnik, 1995) and learn the support using only positive distribution. They construct
decision boundaries around the positive examples to differentiate them from all possible
negative data. Tax and Duin (1991) use a hyper-sphere with some defined radius around
some of the positive class points (support vector data description method). Some also use
kernel tricks before finding this sphere (Tax, 2001). Scholkopf et al. (1999, 2000) develop
methods that try to separate the surface region of the positive labeled data from the region
of the unlabeled data.

6. Conclusions
Much research has been carried out on information extraction and ontology building. In
this work, we discuss how to leverage such knowledge into a large-scale AI problem of event
674

fiLearning to Predict from Textual Data

prediction. We present a system that is trained to predict future events, using a cause event
as input. Each event is represented as a tuple of one predicate and 4 general semantic roles.
The event pairs used for training are extracted automatically from news headlines using
simple syntactic patterns. Generalization to unseen events is achieved by:
1. Creating an abstraction tree (AT) that contains entities from observed events together
with their subsuming categories extracted from available online ontologies.
2. Finding predicate paths connecting entities from cause events to entities in the effect
events, where the paths are again extracted from available ontologies.
We discuss the many challenges of building such a system: obtaining a large enough dataset,
representing the knowledge, and developing the inference algorithms required for such a
task. We perform large-scale mining and apply natural language techniques to transform
the raw data of over 150 years of history archives into a structured representation of events,
using a mined Web-based object hierarchy and action classes. This shows the scalability
of the proposed method, which is crucial to any method that requires large amounts of
data to work well. However, more engineering design and analysis should be performed to
scale it to the entire knowledge of the web and provide real-time alerts. We also show that
the numerous resources built by different people for different purposes (e.g., the different
ontologies) can in fact be merged via a concept-graph to build a system that can work well
in practice.
We perform large-scale learning over the large data corpus and present novel inference
techniques. We consider both rule extraction and generalization. We propose novel methods
for rule generalization using existing ontologies, which we believe can be useful for many
other related tasks. Tasks such as entailment and topic tracking can benefit from the
concepts of understanding sequences and their generalizations.
In this work we only scratch the surface of what can be a real-time fully functional
prediction system. Due to the complexity of the problem, the size of the system and it
many components, errors are unavoidable. For example, errors due to noise during event
extraction, noise during the similarity calculation between events, etc. Although we perform
experiments analyzing the different components of the system and their errors in addition
to the overall system performance, we believe that additional training examples and better
sources of knowledge and deeper ontologies can bring many improvements to our algorithms.
For future work, we suggest the following directions and extensions:
1. Better event extraction and event matching  Event extraction techniques, e.g., as
proposed by Do et al. (2011) can provide higher analysis of the data from the entire
text rather than just the titles. Event similarity can be enriched in many ways, e.g.,
in this work we compared three aggregation functions f , however, a more coherent
way of learning the weights of Oi from past data can be applied.
2. Analysis of knowledge sources  We believe that more in-depth analysis of the different
types of knowledge obtained from the Web and their individual contributions should
be studied. In this work, we did not explore the sensitivity of the system to the initial
noise of the conceptual networks, and we believe that proper analysis of those and
better networks can provide higher prediction accuracy, as already being carried on
by the LinkedData community.
675

fiRadinsky, Davidovich & Markovitch

3. Large scale experiments  Performance of larger experiments with humans over larger
periods of times, and even comparison to experts can provide more insights on the
performance and reliability of the system. Automation of such experiments without
human involvement to measure accuracy of predictions will make it possible to provide
richer metrics of performance, such as recall.
4. Time effect  In this work, all events were treated similarly, even events from 100
years ago. For future directions, we wish to investigate how to give decaying weight
to information about events in the system, as causality learned from an event that
took place in 1851 might be less relevant to the prediction in 2010. However, much
common-sense knowledge can still be used even if learned from events that happened
a long time ago. For example, the headlines Order Restored After Riots (1941) and
Games Suspended After Riot (1962) are still relevant today.
Our experimental evaluation showed that the predictions of the Pundit algorithm are at
least as good as those of non-expert humans. We believe that our work is one of the first to
harness the vast amount of information available on the Web to perform event prediction
that is general purpose, knowledge based, and human-like.

References
Adar, E., Weld, D. S., Bershad, B. N., & Gribble, S. D. (2007). Why we search: visualizing
and predicting user behavior. In Proceedings of the International Conference on the
World Wide Web (WWW).
Agichtein, E., & Ganti, V. (2004). Mining reference tables for automatic text segmentation.
In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD).
Agichtein, E., & Gravano, L. (2000). Snowball: extracting relations from large plain-text
collections. In Proceedings of Joint Conference on Digital Libraries (JCDL), pp. 85
94.
Ahmed, A., Ho, Q., Eisenstein, J., Xing, E. P., Smola, A. J., & Teo, C. H. (2011). Unified
analysis of streaming news. In Proceedings of the International Conference on the
World Wide Web (WWW).
Aitken, J. (2002). Learning information extraction rules: An inductive logic programming
approach. In Proceedings of the 15th European Conference on Artificial Intelligence
(ECAI), pp. 355359.
Allan, J. (Ed.). (2002). Topic Detection and Tracking: Event-based Information Organization, Vol. 12. Kluwer Academic Publishers, Norwell, MA, USA.
Amodeo, G., Blanco, R., & Brefeld, U. (2011). Hybrid models for future event prediction.
In Proceedings of the ACM Conference on Information and Knowledge Management
(CIKM).
Androutsopoulos, I., & Malakasiotis, P. (2010). A survey of paraphrasing and textual
entailment methods. Journal of Artificial Intelligence Research (JAIR), 38, 135187.
Asur, S., & Huberman, B. A. (2010). Predicting the future with social media. In ArxiV.
676

fiLearning to Predict from Textual Data

Bakir, G. H., Hofmann, T., Scholkopf, B., Smola, A. J., Taskar, B., & Vishwanathan, S.
V. N. (2007). Predicting Structured Data. MIT Press.
Banko, M., Cafarella, M. J., Soderl, S., Broadhead, M., & Etzioni, O. (2007). Open information extraction from the web. In Proceedings of the International Joint Conferences
on Artificial Intelligence (IJCAI).
Bizer, C., Heath, T., & Berners-Lee, T. (2009). Linked data  the story so far. International
Journal on Semantic Web and Information Systems (IJSWIS).
Bizer, C., & Schultz, A. (2009). The berlin sparql benchmark. International Journal on
Semantic Web and Information Systems (IJSWIS).
Blanco, E., Castell, N., & Moldovan, D. (2008). Causal Relation Extraction. In Proceedings
of the International Conference on Language Resources and Evaluation (LREC).
Borkar, V., Deshmukh, K., & Sarawagi, S. (2001). Automatic text segmentation for extracting structured records. In Proceedings of ACM SIGMOD International Conference on
Management of Data (KDD).
Bos, J., & Markert, K. (2005). Recognising textual entailment with logical inference. In
Proceedings of the Human Language Technology Conference Conference on Empirical
Methods in Natural Language Processing (HLT EMNLP).
Bunescu, R., & Mooney, R. (2007). Learning to extract relations from the web using
minimal supervision. In Proceedings of the 45th Annual Meeting of the Association
for Computational Linguistics (ACL), pp. 576583.
Bunescu, R. C., & Mooney, R. J. (2005). A shortest path dependency kernel for relation
extraction. In Proceedings of the Conference on Human Language Technology and
Empirical Methods in Natural Language Processing (HLT EMNLP), pp. 724731.
Burchardt, A., Pennacchiotti, M., Thater, S., & Pinkal, M. (2009). Assessing the impact of
frame semantics on textual entailment. Natural Language Engineering, 15, 527550.
Califf, M. E., & Mooney, R. J. (1999). Relational learning of pattern-match rules for information extraction. In Proceedings of the Sixteenth National Conference on Artificial
Intelligence (AAAI), pp. 328334.
Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hruschka, E., & Mitchell, T. (2010).
Toward an architecture for never-ending language learning. In Proceedings of the
Association for the Advancement of Artificial Intelligence (AAAI).
Chambers, N., & Jurafsky, D. (2011). Template-Based Information Extraction without the
Templates. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics (ACL).
Chambers, N., Wang, S., & Jurafsky, D. (2007). Classifying temporal relations between
events. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics (ACL) (Poster).
Chan, K., & Lam, W. (2005). Extracting causation knowledge from natural language texts.
International Journal of Information Security (IJIS), 20, 327358.
677

fiRadinsky, Davidovich & Markovitch

Cieri, C., Graff, D., Liberman, M., Martey, N., & Strassel, S. (2000). Large, multilingual,
broadcast news corpora for cooperative research in topic detection and tracking: The
tdt-2 and tdt-3 corpus efforts. In Proceedings of the International Conference on
Language Resources and Evaluation (LREC).
Ciravegna, F. (2001). Adaptive information extraction from text by rule induction and
generalisation. In Proceedings of the 17th International Joint Conference on Artificial
Intelligence (IJCAI).
Culotta, A., & Sorensen, J. (2004). Dependency tree kernels for relation extraction. In
Proceedings of the 42nd Meeting of the Association for Computational Linguistics
(ACL), pp. 423429.
Dang, H. T., Palmer, M., & Rosenzweig, J. (1998). Investigating regular sense extensions
based on intersective levin classes. In Proceedings of the International Conference on
Computational Linguistics (COLING).
Denis, F. (1998). PAC learning from positive statistical queries. In Proceedings of the
International Conference on Algorithmic Learning Theory (ALT), pp. 112126.
Do, Q., Chan, Y., & Roth, D. (2011). Minimally supervised event causality identification. In
Proceedings of the Conference on Empirical Methods on Natural Language Processing
(EMNLP).
Eisen, M. B., Spellman, P. T., Brown, P. O., & Botstein, D. (1998). Cluster analysis and
display of genome-wide expression patterns. PNAS, 95, 1486314868.
Garcia, D. (1997). Coatis, an NLP system to locate expressions of actions connected by
causality links. In Proceedings of Knowledge Engineering and Knowledge Management
by the Masses (EKAW).
Gerber, M., Gordon, A. S., & Sagae, K. (2010). Open-domain commonsense reasoning using
discourse relations from a corpus of weblog stories. In Proceedings of Formalisms and
Methodology for Learning by Reading, NAACL-2010 Workshop.
Ginsberg, J., Mohebbi, M. H., Patel, R. S., Brammer, L., Smolinski, M. S., & Brilliant, L.
(2009). Detecting influenza epidemics using search engine query data. Nature, 457,
10121014.
Girju, R., & Moldovan, D. (2002). Text mining for causal relations. In Proceedings of
the Annual International Conference of the Florida Artificial Intelligence Research
Society (FLAIRS), pp. 360364.
Giuglea, A.-M., & Moschitti, A. (2006). Shallow semantic parsing based on framenet, verbnet and propbank. In Proceedings of the the 17th European Conference on Artificial
Intelligence (ECAI 2006).
Glickman, O., Dagan, I., & Koppel, M. (2005). A probabilistic classification approach for
lexical textual entailment. In Proceedings of the Association for the Advancement of
Artificial Intelligence (AAAI).
Gordon, A. S., Bejan, C. A., & Sagae, K. (2011). Commonsense causal reasoning using
millions of personal stories. In Proceedings of the Association for the Advancement of
Artificial Intelligence (AAAI).
678

fiLearning to Predict from Textual Data

Haghighi, A. D. (2005). Robust textual inference via graph matching. In Proceedings of the
Human Language Technology Conference Conference on Empirical Methods in Natural
Language Processing (HLT EMNLP).
Hickl, A. (2008). Using discourse commitments to recognize textual entailment. In Proceedings of the International Conference on Computational Linguistics (COLING).
Hobbs, J. R., Bear, J., Israel, D., & Tyson, M. (1993). Fastus: A finite-state processor for
information extraction from real-world text. In Proceedings of the 13th International
Joint Conference on Artificial Intelligence (IJCAI), pp. 11721178.
Hoffmann, R., Zhang, C., Ling, X., Zettlemoyer, L., & Weld, D. S. (2011). Knowledge-based
weak supervision for information extraction of overlapping relations. In Proceedings
of the 49th Annual Meeting of the Association for Computational Linguistics: Human
Language Technologies (HLT).
Hoffmann, R., Zhang, C., & Weld, D. S. (2010). Learning 5000 relational extractors. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics
(ACL).
Idan, I. S., Tanev, H., & Dagan, I. (2004). Scaling web-based acquisition of entailment
relations. In Proceedings of the Conference on Empirical Methods on Natural Language
Processing (EMNLP), pp. 4148.
Jatowt, A., & Yeung, C. (2011). Extracting collective expectations about the future from
large text collections. In Proceedings of the ACM Conference on Information and
Knowledge Management (CIKM).
Jayram, T. S., Krishnamurthy, R., Raghavan, S., Vaithyanathan, S., & Zhu, H. (2006).
Avatar information extraction system. IEEE Data Engineering Bulletin, 29, 4048.
Jian Zhang, Z. G., & Yang, Y. (2004). A probabilistic model for online document clustering
with application to novelty detection. In Proceedings of the Annual Conference on
Neural Information Processing Systems (NIPS).
Jiang, J., & Zhai, C. (2007). A systematic exploration of the feature space for relation
extraction. In Proceedings of the Human Language Technologies and the Conference
of the North American Chapter of the Association for Computational Linguistics (HLT
NAACL), pp. 113120.
Joachims, T. (2006). Structured output prediction with support vector machines. In Yeung,
D.-Y., Kwok, J., Fred, A., Roli, F., & de Ridder, D. (Eds.), Structural, Syntactic, and
Statistical Pattern Recognition, Vol. 4109 of Lecture Notes in Computer Science, pp.
17. Springer Berlin / Heidelberg.
Joshi, M., Das, D., Gimpel, K., & Smith, N. A. (2010). Movie reviews and revenues: An
experiment in text regression. In Proceedings of the North American Chapter of the
Association for Computational Linguistics - Human Language Technologies (NAACL
HLT).
Kalev (2011). Culturomics 2.0: Forecasting large-scale human behavior using global news
media tone in time and space. First Monday, 15 (9).
679

fiRadinsky, Davidovich & Markovitch

Kambhatla, N. (2004). Combining lexical, syntactic and semantic features with maximum
entropy models for information extraction. In Proceedings of the Annual Meeting of
the Association for Computational Linguistics (ACL), pp. 178181.
Kaplan, R., & Berry-Rogghe, G. (1991). Knowledge-based acquisition of causal relationships
in text. Knowledge Acquisition, 3, 317337.
Khoo, C., Chan, S., & Niu, Y. (2000). Extracting causal knowledge from a medical database
using graphical patterns. In Proceedings of the Annual Meeting of the Association for
Computational Linguistics (ACL), pp. 336343.
Kim, J. (1993). Supervenience and mind. Selected Philosophical Essays.
Kipper, K. (2006). Extending verbnet with novel verb classes. In Proceedings of the International Conference on Language Resources and Evaluation (LREC).
Kittur, A., Chi, H., & Suh, B. (2008). Crowdsourcing user studies with mechanical turk. In
Proceedings of the ACM CHI Conference on Human Factors in Computing Systems
is the premier International Conference of human-computer interaction (CHI).
Kleinberg, J. (2006). Temporal dynamics of on-line information systems. Data Stream
Management: Processing High-Speed Data Streams. Springer.
Kleinberg, J. (2002). Bursty and hierarchical structure in streams. In Proceedings of the
Annual ACM SIGKDD Conference (KDD).
Lafferty, J., Zhu, X., & Liu, Y. (2004). Kernel conditional random fields: Representation and
clique selection. In The 21st International Conference on Machine Learning (ICML).
Lahiri, S., Mitra, P., & Lu, X. (2011). Informality judgment at sentence level and experiments with formality score. In Proceedings of the 12th International Conference on
Computational Linguistics and Intelligent Text Processing (CICLing).
Landis, & Koch (1977). The measurement of observer agreement for categorical data.
Biometrics, 33 (1), 74159.
Lapata, M., & Lascarides, A. (2006). Learning sentence-internal temporal relations. Journal
of Artificial Intelligence Research (JAIR), 27, 85117.
Lappin, S., & Leass, H. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics, 20, 535561.
Lassila, O., Swick, R. R., Wide, W., & Consortium, W. (1998). Resource description framework (rdf) model and syntax specification..
Lenat, D. B., & Guha, R. V. (1990). Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project. Addison-Wesley.
Levin, B., & Hovav, M. R. (1994). A preliminary analysis of causative verbs in english.
Lingua, 92, 3577.
Lin, D., & Pantel, P. (2001). Dirt-discovery of inference rules from text. In Proceedings of
the Annual ACM SIGKDD Conference (KDD).
Ling, X., & Weld, D. (2010). Temporal information extraction. In Proceedings of the
Association for the Advancement of Artificial Intelligence (AAAI).
680

fiLearning to Predict from Textual Data

Liu, H., & Singh, P. (2004). Conceptnet: A practical commonsense reasoning toolkit. BT
Technology Journal, 22, 211226.
Manevitz, L. M., & Yousef, M. (2000). Document classification on neural networks using
only positive examples. In Proceedings of 23rd Annual International ACM SIGIR
Conference on Research and Development in Information Retrieval (SIGIR), pp. 304
306.
Manevitz, L. M., Yousef, M., Cristianini, N., Shawe-Taylor, J., & Williamson, B. (2001).
One-class svms for document classification. Journal of Machine Learning Research,
2, 139154.
Mani, I., Schiffman, B., & Zhang, J. (2003). Inferring temporal ordering of events in news.
In Proceedings of the North American Chapter of the Association for Computational
Linguistics - Human Language Technologies (NAACL HLT).
Marneffe, M., MacCartney, B., & Manning, C. (2006). Generating typed dependency parses
from phrase structure parses. In Proceedings of the International Conference on Language Resources and Evaluation (LREC).
Maynard, D., Tablan, V., Ursu, C., Cunningham, H., & Wilks, Y. (2001). Named entity
recognition from diverse text types. In Recent Advances in Natural Language Processing Conference (RANLP), pp. 11721178.
Mcdonald, D. M., Chen, H., Su, H., & Marshall, B. B. (2004). Extracting gene pathway
relations using a hybrid grammar: The arizona relation parser. Bioinformatics, 20,
33703378.
Michel, J., Shen, Y., Aiden, A., Veres, A., Gray, M., Google Books Team, Pickett, J.,
Hoiberg, D., Clancy, D., Norvig, P., Orwant, J., Pinker, S., Nowak, M., & Aiden, E.
(2011). Quantitative analysis of culture using millions of digitized books. Science,
331, 176182.
Miller, G. (1995). Wordnet: A lexical database for english. Journal of Communications of
the ACM (CACM), 38, 3941.
Mishne, G. (2006). Predicting movie sales from blogger sentiment. In Proceedings of the
Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium.
Mitchell, J., & Lapata, M. (2008). Vector-based models of semantic composition. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).
Muggleton, S. (1996). Learning from positive data. In Proceedings of the Inductive Logic
Programming Workshop, pp. 358376.
Nguyen, T.-V. T., & Moschitti, A. (2011). Joint distant and direct supervision for relation
extraction. In Proceedings of the The 5th International Joint Conference on Natural
Language Processing (IJCNLP).
Nguyen, T.-V. T., Moschitti, A., & Riccardi, G. (2009). Convolution kernels on constituent,
dependency and sequential structures for relation extraction. In Proceedings of the
2009 Conference on Empirical Methods in Natural Language Processing (EMNLP).
Pearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press.
681

fiRadinsky, Davidovich & Markovitch

Quirk, C., Brockett, C., & Dolan, W. (2004). Monolingual machine translation for paraphrase generation. In Proceedings the Conference on Empirical Methods on Natural
Language Processing (EMNLP), pp. 142149.
Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development and application of a
metric to semantic nets. IEEE Transactions on Systems, Man and Cybernetics, 19 (1),
1730.
Radinsky, K., Davidovich, S., & Markovitch, S. (2008). Predicting the news of tomorrow
using patterns in web search queries. In Proceedings of the IEEE/WIC International
Conference on Web Intelligence (WI).
Raina, R., Ng, A. Y., & Manning, C. D. (2005). Robust textual inference via learning
and abductive reasoning. In Proceedings of the Association for the Advancement of
Artificial Intelligence (AAAI).
Ravichandran, D., Ittycheriah, A., & Roukos, S. (2003). Automatic derivation of surface text
patterns for a maximum entropy based question answering system. In Proceedings of
the North American Chapter of the Association for Computational Linguistics: Short
Papers (NAACL Short), pp. 8587.
Riloff, E. (1993). Automatically constructing a dictionary for information extraction
tasks. In Proceedings of the Association for the Advancement of Artificial Intelligence
(AAAI), pp. 811816.
Riloff, E. (1996). Automatically Generating Extraction Patterns from Untagged Text. In
Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI).
Riloff, E., & Jones, R. (1999). Learning dictionaries for information extraction by multi-level
bootstrapping. In Proceedings of the Association for the Advancement of Artificial
Intelligence (AAAI).
Rosenfeld, B., & Feldman, R. (2007). Using corpus statistics on entities to improve semisupervised relation extraction from the web. In Proceedings of the 45th Annual Meeting
of the Association for Computational Linguistics (ACL), pp. 600607.
Sarawagi, S. (2008). Information extraction. Foundations and Trends in Databases, 1 (3),
261377.
Scholkopf, B., Williamson, R., Smola, A., Shawe-Taylor, J., & Platt, J. (2000). Support
vector method for novelty detection. In Proceedings of the Annual Conference on
Neural Information Processing Systems (NIPS), pp. 582588.
Scholkopf, B., Williamson, R. C., Smola, A., & Shawe-Taylor, J. (1999). Sv estimation of a
distributions support. In Proceedings of the Annual Conference on Neural Information
Processing Systems (NIPS).
Schubert, L. (2002). Can we derive general world knowledge from texts?. In Proceedings of
the Second Conference on Human Language Technology (HLT).
Shahaf, D., & Guestrin, C. (2010). Connecting the dots between news articles. In Proceedings
of the Annual ACM SIGKDD Conference (KDD).
682

fiLearning to Predict from Textual Data

Shen, W., Doan, A., Naughton, J. F., & Ramakrishnan, R. (2007). Declarative information
extraction using datalog with embedded extraction predicates. In Proceedings of the
Conference on Very Large Data Bases (VLDB), pp. 10331044.
Shi, L., & Mihalcea, R. (2005). Putting pieces together: Combining framenet, verbnet
and wordnet for robust semantic parsing. In Proceedings of the Sixth International
Conference on Intelligent Text Processing and Computational Linguistics (CICLing),
pp. 100111.
Shinyama, Y., & Sekine, S. (2006). Preemptive information extraction using unrestricted
relation discovery. In Proceedings of the North American Chapter of the Association
for Computational Linguistics - Human Language Technologies (NAACL HLT).
Sil, A., Huang, F., & Yates, A. (2010). Extracting action and event semantics from web
text. In Proceedings of the Association for the Advancement of Artificial Intelligence
(AAAI) Fall Symposium on Commonsense Knowledge.
Soderland, S. (1999). Learning information extraction rules for semi-structured and free
text. Machine Learning, 34.
Strube, M., & Ponzetto, S. P. (2006). Wikirelate! computing semantic relatedness using
wikipedia. In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI).
Suchanek, F. M. (2006). Combining linguistic and statistical analysis to extract relations
from web documents. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), pp. 712717.
Suchanek, F. M., Kasneci, G., & Weikum, G. (2007). Yago: a core of semantic knowledge.
In Proceedings of the International Conference on the World Wide Web (WWW).
Taskar, B., Guestrin, C., & Koller, D. (2003). Max-margin markov networks. In Proceedings
of the Annual Conference on Neural Information Processing Systems (NIPS).
Tatu, M., & Moldovan, D. (2005). A semantic approach to recognizing textual entailment. In
Proceedings of the Human Language Technology Conference Conference on Empirical
Methods in Natural Language Processing (HLT EMNLP).
Tatu, M., & Srikanth, M. (2008). Experiments with reasoning for temporal relations between
events. In Proceedings of the International Conference on Computational Linguistics
(COLING).
Tax, D. (2001). One class classification. In PhD thesis, Delft University of Technology.
Tax, D. M. J., & Duin, R. P. W. (1991). Support vector domain description. Pattern
Recognition Letters, 20, 11911199.
Turney, P. D. (2006). Expressing implicit semantic relations without supervision. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics
(ACL).
Vapnik, V. (1995). The Nature of Statistical Learning Theory. Springer-Verlag, NY, USA.
Viera, A. J., & Garrett, J. M. (2005). Understanding interobserver agreement: The kappa
statistic. Family Medicine, 37 (5), 360363.
683

fiRadinsky, Davidovich & Markovitch

Wang, M. (2008). A re-examination of dependency path kernels for relation extraction. In
Proceedings of the Third International Joint Conference on Natural Language Processing (ACL IJCNLP).
Wolff, P., Song, G., & Driscoll, D. (2002). Models of causation and causal verbs. In
Proceedings of the Annual Meeting of the Association for Computational Linguistics
(ACL).
Yang, Y., Pierce, T., & Carbonell, J. (1998). A study on retrospective and online event
detection. In Proceedings of ACM SIGIR Special Interest Group on Information Retrieval (SIGIR).
Yeung, C., & Jatowt, A. (2011). Studying how the past is remembered: Towards computational history through large scale text mining. In Proceedings of the ACM Conference
on Information and Knowledge Management (CIKM).
Yoshikawa, K., Riedel, S., Asahara, M., & Matsumoto, Y. (2009). Jointly identifying temporal relations with markov logic. In Proceedings of the Third International Joint
Conference on Natural Language Processing (ACL IJCNLP).
Zanzotto, F. M., Pennacchiotti, M., & Moschitti, A. (2009). A machine learning approach
to textual entailment recognition. Natural Language Engineering, 15, 551582.
Zelenko, D., Aone, C., & Richardella, A. (2003). Kernel methods for relation extraction.
Journal of Machine Learning Research, 3, 10831106.
Zhang, M., Zhang, J., Su, J., & Zhou, G. (2006). A composite kernel to extract relations
between entities with both flat and structured features. In Proceedings of the 21st
International Conference on Computational Linguistics and 44th Annual Meeting of
the Association for Computational Linguistics, pp. 825832.
Zhao, S., & Grishman, R. (2005). Extracting relations with integrated information using
kernel methods. In Proceedings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL), pp. 419426.

684

fiJournal of Artificial Intelligence Research 45 (2012) 731-759

Submitted 06/12; published 12/12

Tractable Set Constraints
Manuel Bodirsky

bodirsky@lix.polytechnique.fr

Ecole Polytechnique, LIX
(UMR 7161 du CNRS)
91128 Palaiseau, France

Martin Hils

hils@math.univ-paris-diderot.fr

Institut de Mathematiques de Jussieu
(UMR 7586 du CNRS)
Universite Paris Diderot Paris 7
UFR de Mathematiques
75205 Paris Cedex 13, France

Abstract
Many fundamental problems in artificial intelligence, knowledge representation, and
verification involve reasoning about sets and relations between sets and can be modeled as
set constraint satisfaction problems (set CSPs). Such problems are frequently intractable,
but there are several important set CSPs that are known to be polynomial-time tractable.
We introduce a large class of set CSPs that can be solved in quadratic time. Our class,
which we call EI, contains all previously known tractable set CSPs, but also some new
ones that are of crucial importance for example in description logics. The class of EI set
constraints has an elegant universal-algebraic characterization, which we use to show that
every set constraint language that properly contains all EI set constraints already has a
finite sublanguage with an NP-hard constraint satisfaction problem.

1. Introduction
Constraint satisfaction problems are computational problems where, informally, the input
consists of a finite set of variables and a finite set of constraints imposed on those variables;
the task is to decide whether there is an assignment of values to the variables such that all
the constraints are simultaneously satisfied. Set constraint satisfaction problems are special
constraint satisfaction problems where the values are sets, and the constraints might, for
instance, force that one set y includes another set x, or that one set x is disjoint to another
set y. The constraints might also be ternary (or, more generally, of any finite arity), such
as the constraint that the intersection of two sets x and y is contained in z, in symbols
px X yq  z.
To systematically study the computational complexity of constraint satisfaction problems, it has turned out to be a fruitful approach to consider constraint satisfaction problems
CSPpq where the set of allowed constraints is formed from a fixed finite set  of relations
R  Dk over a (possibly infinite) common domain D. For example, if D equals Q, the
rational numbers, and  is tu where  is the usual order of the rationals, then CSPpq
is the problem of deciding whether a given set of (binary) constraints of the form x  y
has a common solution over the rational numbers. This way of parametrizing the conc
2012
AI Access Foundation. All rights reserved.

fiBodirsky & Hils

straint satisfaction problem by a constraint language  has led to many strong algorithmic
results (e.g., Bulatov & Dalmau, 2006; Idziak, Markovic, McKenzie, Valeriote, & Willard,
2010; Barto & Kozik, 2009; Bodirsky & Kutz, 2007; Bodirsky & Kara, 2009), and to many
powerful hardness conditions for large classes of constraint satisfaction problems (Schaefer,
1978; Bulatov, Krokhin, & Jeavons, 2005; Bulatov, 2003, 2006; Bodirsky & Kara, 2009).
A set constraint language  is a set of relations R  pP pNqqk where the common domain
D  P pNq is the set of all subsets of the natural numbers; moreover, we require that each
relation R can be defined by a Boolean combination of equations over the signature [, \, c,
0, and 1, which are function symbols for intersection, union, complementation, the empty
and full set, respectively. Details of the formal definition of set constraint languages can be
found in Section 3. In Section 4, we give many examples of set constraint languages. The
choice of N is just for notational convenience; we could have selected any infinite set for our
purposes, e.g., Rn instead of N, a more natural choice in spatial reasoning. One may even
replace P pNq by any infinite Boolean algebra (see Theorem 28).
In the following, a set constraint satisfaction problem (set CSP) is a problem of the form
CSPpq for a finite set constraint language . It has been shown by Marriott and Odersky
that all set CSPs are contained in NP.
Drakengren and Jonsson (1998) initiated the search for set CSPs that can be solved
in polynomial time. They showed that CSPpt, ||, uq can be solved in polynomial time,
where
 x  y holds iff x is a subset of or equal to y;
 x || y holds iff x and y are disjoint sets; and
 x  y holds iff x and y are distinct sets.
They also showed that CSPpq can be solved in polynomial time if all relations in  can be
defined by formulas of the form
x1

 y1 _    _ xk  yk _ x0  y0

x1

 y1 _    _ xk  yk _ x0 || y0

or of the form

where x0 , . . . , xk , y0 , . . . , yk are not necessarily distinct variables (Drakengren & Jonsson,
1998, Thm. 20). We will call the set of all relations that can be defined in this way Drakengren and Jonssons set constraint language. It is easy to see that the algorithm they
present runs in time quadratic in the size of the input. On the other hand, they also show
that if  contains the relation defined by x1  y1 _ x2  y2 and the relation defined by
x1  x0 _ x2  x0 then the problem CSPpq is NP-hard (Drakengren & Jonsson, 1998,
Thm. 22).
1.1 Contributions and Outline.
We present a significant extension of Drakengren and Jonssons (1998) set constraint language (Section 4) whose CSP can still be solved in quadratic time in the input size (Section 5); we call this set constraint language EI. Unlike Drakengren and Jonssons set
732

fiTractable Set Constraints

constraint language, our language also contains the ternary relation defined by px X y q  z,
which is a relation that is of particular interest in description logics  we will discuss this
below. Moreover, we show that any further extension of EI contains a finite sublanguage
with an NP-hard set CSP (Section 6), using concepts from model theory and universal
algebra. In this sense, we present a maximal tractable class of set constraint satisfaction
problems.
Our algorithm is based on the concept of independence in constraint languages which
was discovered several times independently in the 90s (Lassez & McAloon, 1989; Jonsson &
Backstrom, 1998; Marriott & Odersky, 1996, see also Koubarakis, 2001; Broxvall, Jonsson,
& Renz, 2002; Cohen, Jeavons, Jonsson, & Koubarakis, 2000); however, we apply this
concept twice in a novel, nested way, which leads to a two level resolution procedure that
can be implemented to run in quadratic time. The technique we use to prove the correctness
of the algorithm is also an important contribution of our paper, and we believe that a similar
approach can be applied in many other contexts; our technique is inspired by the already
mentioned connection to universal algebra.
1.2 Application Areas and Related Literature
We mention three different contexts where set constraints appeared in the literature.
1.2.1 Set Constraints for Programming Languages.
Set constraints find applications in program analysis; here, a set constraint is of the form
X  Y , where X and Y are set expressions. Examples of set expressions are 0 (denoting
the empty set), set-valued variables, and union and intersection of sets, but also expressions
of the form f pZ1 , Z2 q where f is a function symbol and Z1 , Z2 are again set expressions.
Unfortunately, the worst-case complexity of most of the reasoning tasks considered in this
setting is very high, often EXPTIME-hard (for a survey on this, see Aiken, 1994). More
recently, it has been shown that the quantifier-free combination of set constraints (without
function symbols) and cardinality constraints (quantifier-free Pressburger arithmetic) has
a satisfiability problem in NP (Kuncak & Rinard, 2007). This logic (called QFBAPA) is
interesting for program verification (Kuncak, Nguyen, & Rinard, 2006).
1.2.2 Tractable Description Logics.
Description logics are a family of knowledge representation formalisms that can be used to
formalize and reason with concept definitions. The computational complexity of most of the
computational tasks that have been studied for the various formalisms is usually quite high.
However, in the last years a series of description logics, for example EL, EL , Horn-FL0 ,
and various extensions and fragments (Kusters & Molitor, 2002; Baader, 2003; Baader,
Brandt, & Lutz, 2005; Krotzsch, Rudolph, & Hitzler, 2006), has been discovered where
crucial tasks such as e.g. entailment, concept satisfiability and knowledge base satisfiability
can be decided in polynomial time.
Two of the basic assertions that can be made in EL
and Horn-FL0 are C1 ||C2 (there
is no C1 that is also C2 ) and C1 X C2  C3 (every C1 that is C2 is also C3 ), for concept
names C1 , C2 , C3 . These are EI set constraints, and the latter has not been treated in
733

fiBodirsky & Hils

the framework of Drakengren and Jonsson. None of the description logics with a tractable
knowledge base satisfiability problem contains all EI set constraints.
1.2.3 Spatial Reasoning.
Several spatial reasoning formalisms (like RCC-5 and RCC-8) are closely related to set constraint satisfaction problems. These formalisms allow to reason about relations between
regions; in the fundamental formalism RCC-5 (see, e.g., Jonsson & Drakengren, 1997),
one can think of a region as a non-empty set, and possible (binary) relationships are containment, disjointness, equality, overlap, and disjunctive combinations thereof. Thus, the
exclusion of the empty set is the most prominent difference between the set constraint languages studied by Drakengren and Jonsson (1998)  contained in the class of set constraint
languages considered here  and RCC-5 and its fragments. We will see in Section 3 that
the CSP for RCC-5 and the CSPs for all its reducts are set CSPs (Proposition 2).

2. Constraint Satisfaction Problems
To use existing terminology in logic and model theory, it will be convenient to describe
constraint languages by structures (see, e.g., Hodges, 1993). A structure  is a tuple
pD; f1, f2, . . . , R1, R2, . . . q where D is a set (the domain of ), each fi is a function from
Dki  D (where ki is called the arity of fi ), and each Ri is a relation over D, i.e., a subset
of Dli (where li is called the arity of Ri ). For each function fi we assume that there is a
function symbol which we denote by fi , and for each relation Ri we have a relation symbol
which we denote by Ri . Constant symbols will be treated as 0-ary function symbols. The
set  of all relation and function symbols for some structure  is called the signature of ,
and we also say that  is a  -structure. If the signature of  only contains relation symbols
and no function symbols, we also say that  is a relational structure. In the context of
constraint satisfaction, relational structures  are also called constraint languages, and a
constraint language 1 is called a sublanguage (or reduct) of a constraint language  if the
relations in 1 are a subset of the relations in  (and  is called an expansion of 1 ).
Let  be a relational structure with domain D and a finite signature  . The constraint
satisfaction problem for  is the following computational problem, also denoted by CSPpq:
given a finite set of variables V and a conjunction  of finitely many atomic formulas of the
form Rpx1 , . . . , xk q, where x1 , . . . , xk P V and R P  , is  satisfiable in ; that is, does there
exist an assignment s : V  D such that for every constraint Rpx1 , . . . , xk q in the input we
have that pspx1 q, . . . , spxk qq P R ?
The mapping s is also called a solution to the instance  of CSPpq, and the conjuncts
of  are called constraints. Note that we only introduce constraint satisfaction problems
CSPpq for finite constraint languages, i.e., relational structures  with a finite relational
signature.

Example 1. The problem CSPppQ; qq is the problem of deciding whether a given set of
constraints of the form x  y has a solution that simultaneously satisfies all constraints.
734

fiTractable Set Constraints

3. Set Constraint Languages
In this section, we give formal definitions of set constraint languages. Let S be the structure with domain P pNq, the set of all subsets of natural numbers, and with signature
t[, \, c, 0, 1u, where



[ is a binary function symbol that denotes intersection, i.e., [S  X;
\ is a binary function symbol for union, i.e., \S  Y;

 c is a unary function symbol for complementation, i.e., cS is the function that maps
S  N to NzS;
 0 and 1 are constants (treated as 0-ary function symbols) denoting the empty set
and the full set N, respectively.

H

Sometimes, we simply write [ for the function [S and \ for the function \S , i.e., we do
not distinguish between a function symbol and the respective function. We use the symbols
[, \ and not the symbols X, Y to prevent confusion with meta-mathematical usages of X
and Y in the text.
A set constraint language is a relational structure whose relations have a quantifier-free
definition in S. We always allow equality in first-order formulas, and the equality symbol
 is always interpreted to be the true equality relation on the domain of the structure. We
write x  y as an abbreviation for x [ y  x.
Example 2. The ternary relation px, y, z q
definition z [ px [ y q  x [ y over S.

P P pN q3 | x [ y  z

(

has the quantifier-free

Theorem 1 (See Marriott & Odersky, 1996, Proposition 5.8). Let  be a set constraint
language with a finite signature. Then CSPpq is in NP.
It is easy to see that there are NP-hard set CSPs, as shown in the next example.
Example 3. Consider the set constraint language  that contains the eight relations

tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u
tpx, y, zq | x  1 _ y  1 _ z  1u .
Then the set CSP for those relations is the well-known 3-SAT problem, which is NPcomplete (Garey & Johnson, 1978).
It is well-known that the structure pP pNq; \, [, c, 0, 1q is a Boolean algebra, with
735

fiBodirsky & Hils

 0 playing the role of false, and 1 playing the role of true;
 c playing the role of


;

[ and \ playing the role of ^ and _, respectively.

We refer to the work of Koppelberg (1989) for background on Boolean algebras.
To not confuse logical connectives with the connectives of Boolean algebras, we always
use the symbols [, \, and c instead of the usual function symbols ^, _, and in Boolean
algebras. To facilitate the notation, we also write x instead of cpxq, and x  y instead of
p x  y q.
We assume that all terms t over the functional signature
t[, \, c, 0, 1u are written in


(inner) conjunctive normal form (CNF), i.e., as t  ni1 nj i 1 lij where lij is either of the
form x or of the form x for a variable x. Note that every term over t[, \, c, 0, 1u can be rewritten into an equivalent term of this form, using the usual laws of Boolean algebras (Boole,
1847). We allow the special
case n  0 (in which case t becomes 1), and the special case
ni
ni  0 (in which case j 1 lij becomes 0). We refer to ci : tlij | 1  j  ni u as an
(inner) clause of t, and to lij as an (inner) literal of ci . We say that a set of inner clauses
is satisfiable if there exists an assignment from V  P pNq such that for all inner clauses,
the
union of the evaluation of all literals equals N (this is the case if and only if the formula
n
i1 ci  1 has a satisfying assignment).
Example 4. Inequality x  y on P pNq can be equivalently written as py \ xq[px \ y q  1;
in this formula, we have two inner clauses, each with a positive and a negative inner literal.
We assume that all quantifier-free formulas  over the signature
t[, \, c, 0, 1u are written

mi
in (outer) conjunctive normal form (CNF), i.e., as   m
j 1 Lij where Lij is either
i1
of the form t  1 (a positive (outer) literal ) or of the form t  1 (a negative (outer) literal ).
Again, it is well-known and easy to see that we can for every quantifier-free formula find
a formula in this form which is equivalent to it in every Boolean algebra. We refer to
Ci : tLij | 1  j  mi u as an (outer) clause of , and to Lij as an (outer) literal of Ci .
Whenever convenient, we identify  with its set of clauses.
Example 5. Consider the formula px  y ^ y  z q _ px  y ^ y  z q. It can be rewritten
as px  y _ y  z q^px  y _ y  z q. When we subsequently replace inequality literals x  y
by py \ xq [ px \ y q  1 (see Example 4), we arrive at a formula which is in the discussed
normal form: it has two outer clauses, one with two positive outer literals, and the other
with two negative outer literals.
As mentioned in the introduction, all CSPs for reducts of RCC-5 (and therefore also
many reducts of RCC-8) can be formulated as set CSPs. The network satisfaction problem for RCC-5 can be seen as the CSP for the following structure RCC-5 with domain
P pNqztHu and all binary relations given as follows: for each relation R of RCC-5 there
exists a quantifier-free t\, [, c, 0, 1u-formula px1 , x2 q such that ps1 , s2 q P R if and only if
both s1 and s2 are non-empty, and ps1 , s2 q is true in S. It is clear that there are only
finitely many inequivalent quantifier-free formulas over the language t\, [, c, 0, 1u, and
hence RCC-5 has only finitely many relations.
736

fiTractable Set Constraints

Proposition 2. Let  be a reduct of RCC-5. Then there exists a set constraint language 
such that CSPpq and CSPpq are the same problem.
Proof. Let 1 , . . . , n be the formulas the define the relations of  (which has domain
P pNqztHu). Let  be the structure with domain P pNq and relations R1 , . . . , Rn defined
by 1 , . . . , n in S. That is, the only difference between  and  is the additional element
tHu, which appears in none of the relations of . We have to prove that every finite
conjunction  of atomic formulas of the form Ri px1 , . . . , xk q is satisfiable in  if and only if
the conjunction is satisfiable in . If  is satisfiable over  then it is clearly also satisfiable
over  since  is an induced substructure of . Conversely, if  is satisfiable over , then
any solution must have the property that if spxi q  H, then xi does not appear in any
constraint (since the constraints force that their arguments are non-empty). Hence, setting
spxi q to any non-empty subset of N will still be a solution, which implies the claim.
Proposition 2 shows that the class of set CSPs contains the class of all CSPs for reducts
of RCC-5. The inclusion is clearly strict: there are set CSPs that cannot be formulated as
CSPs for reducts of RCC-5, since relations in set constraint languages can have arbitrary
arity, while reducts of RCC-5 only contain binary relations.

4. Horn-Horn Set Constraints
In this section, we study Horn-Horn set constraints, a class of set constraints which admits
an intuitive syntactic description and which is thus easy to define. Universal algebraic
considerations on this class in Section 4.2 lead us to another class of set constraints, called
EI and introduced in Section 4.3. This class strictly contains the class of Horn-Horn set
constraints. Its universal algebraic description is the key for the maximality result which
we will prove in Section 6. As for tractability, set constraint languages from EI allow for a
(linear-time) reduction to satisfiability of Horn-Horn clauses (see Proposition 22). We note
that these classes of set constraints (Horn-Horn and EI) have not been studied before.
4.1 Horn-Horn Relations
Definition 3. A quantifier-free formula is called Horn-Horn if
1. every outer clause is outer Horn, i.e., contains at most one positive outer literal, and
2. every inner clause of positive outer literals is inner Horn, i.e., contains at most one
positive inner literal.
A relation R  P pNqk is called
 outer Horn if it can be defined over S by a conjunction of outer Horn clauses;
 inner Horn if it can be defined over S by a formula of the form pc1 [    [ ck q
where each ci is inner Horn;

1

 Horn-Horn if it can be defined by a Horn-Horn formula over S.
Example 6. Inequality

 is Horn-Horn: recall that it may defined by py \ xq[px \ yq  1.
737

fiBodirsky & Hils

Example 7. Using the previous example, the relation
easily be seen to be Horn-Horn, too.
Example 8. The ternary relation tpx, y, z q | x [ y
has the Horn-Horn definition x \ y \ z  1.

tpx, y, u, vq | x  y _ u  vu can

 zu, which we have encountered above,

Proposition 4. Drakengren and Jonssons set constraint language only contains Horn-Horn
relations.
Proof. The disjointness relation || has the definition x \ y  1, so is inner Horn. The
inequality relation  is Horn-Horn since both inner clauses in its definition py \ xq[px \ y q 
1 have only one positive inner literal. The inclusion relation x  y has the definition
y \ x  1, so is inner Horn.
Horn-Horn is preserved under adding additional outer disequality literals to the outer
clauses, so all relations considered in Drakengren and Jonssons language are Horn-Horn.
4.2 Universal Algebraic Preliminaries
As we will see in this section, the class of Horn-Horn formulas is preserved by several
important functions defined on the set of subsets of natural numbers.
Definition 5.
 Let i : pP pNqq2  P pNq be the function that maps a pair of sets pS1 , S2 q
to the set t2a | a P S1 u Y t2a 1 | a P S2 u;

 denote by Fin the set of finite non-empty subsets of N, and let F : P pNq  P pFin q,
F pS q : tS0

 S | S0 is finite and non-emptyu ;

 let G : N  Fin be a bijection (since both sets are countable, such a bijection exists);
 let e : P pNq  P pNq be defined by
epS q  tG1 pT q | T

P F pS qu ;

 let ei be the function defined by eipx, y q  epipx, y qq.
Intuitively, the functions e and ei are designed so that they forget unions (this will be
formalized in Definition 34), while preserving the other basic operations in S (see Lemma
11 and Proposition 8 for the case of e).
Definition 6. Let f : pP pNqqk  P pNq be a function, and R  P pNql be a relation. Then
we say that f preserves R if the following holds: for all a1 , . . . , ak P pP pNqql we have that
pf pa11, . . . , ak1 q, . . . , f pa1l , . . . , akl qq P R if ai P R for all i  k. If f does not preserve R, we
also say that f violates R. We say that f strongly preserves R if for all a1 , . . . , ak P pP pNqql
we have that pf pa11 , . . . , ak1 q, . . . , f pa1l , . . . , akl qq P R if and only if ai P R for all i  k. If  is
a first-order formula that defines a relation R over S, and f preserves (strongly preserves)
R, then we also say that f preserves (strongly preserves) . Finally, if g : pP pNqql  P pNq is
a function, we say that f preserves (strongly preserves) g if it preserves (strongly
preserves)
(
the graph of g, i.e., the relation px1 , . . . , xl , g px1 , . . . , xl qq | x1 , . . . , xl  N .
738

fiTractable Set Constraints

Note that if an injective function f preserves a function g, then it also strongly preserves
g.
Example 9. Consider the function f : pP pNqq2  P pNq, px, y q  x \ y. Then f preserves
, since x \ y  x1 \ y1 whenever x  x1 and y1  y. On the other hand, f does not strongly
preserve , as is shown by f pN, Hq  f pH, Nq.
Fact 7. The mapping i is an isomorphism between S2 and S.
Proof. The mapping
 i can be inverted by the mapping that sends S  N to ta | 2a P
S u, ta | 2a 1 P S u . It is straightforward to verify that i strongly preserves 0, 1, c, \, [.
 Clearly, ipx, y q  H if and only if x  y

 H.

 Similarly, since the natural numbers are partitioned by the even and odd numbers,
ipx, y q  N if and only if x  y  N.
 Let S1 and S2 be subsets of N. To verify that i preserves c we have to show that
ipcpS1 , S2 qq, which is by definition equal to ipS1 , S2 q, equals cpipS1 , S2 qq. Suppose
that a  2a1 . Then:
a P i pS 1 , S 2 q  a 1

P S1

 a1 R S1
 2a1 R ipS1, S2q
 a P ipS1, S2q

The argument for a  2a1
even strongly preserves c.

1 is analogous. Thus, i preserves c. Since i is injective, it

 Let pS1 , S2 q and pT1 , T2 q be from pP pNq2 . We have to show that ippS1 , S2 q\pT1 , T2 qq,
which is by definition equal to ipS1 \ T1 , S2 \ T2 q, equals ipS1 , S2 q \ ipT1 , T2 q. With
a  2a1 as before:
a P ipS1 \ T1 , S2 \ T2 q  a1

P pS1 \ T1q

 2a1 P ipS1, S2q \ ipT1, T2q

The argument for a  2a1 1 is again analogous. Thus, i preserves
injective, it even strongly preserves \.
The verification for

\.

Since i is

[ is similar to that for \.

Proposition 8. The function e has the following properties.
 e is injective,

[, and
for x, y, z P P pNq such that x \ y 
epxq \ epy q  epz q.

 e strongly preserves 1, 0, and


z, not x

739



y, and not y



x, we have that

fiBodirsky & Hils

Proof. We verify the properties one by one. Since G is bijective, epxq  epy q if and only if
x and y have the same finite subsets. This is the case if and only if x  y, and hence e is
injective. Thus, to prove that e strongly preserves 1, 0, and [, it suffices to check that e
preserves 1, 0, and [.
Since G is bijective, we have that GpNq equals the set of all finite subsets of N, and
hence epNq  N, which shows that e preserves 1. We also compute epHq  G1 pF pHqq 
G1 pHq  H.
Next, we verify that for all x, y P P pNq we have epxq [ epy q  epx [ y q. Let a P N be
arbitrary. We have a P epxq [ epy q if and only if Gpaq P F pxq X F py q. By definition of F
and since Gpaq is a finite subset of N, this is the case if and only if Gpaq P F px [ y q. This
is the case if and only if a P epx [ y q, which concludes the proof that e preserves [.
We verify that if x \ y  z, not x  y, and not y  x, then epxq \ epy q  epz q. First
observe that for all u, v  N with u  v we have epuq  epv q since e preserves [. This
implies that epxq \ epy q  epz q. Since x  y and y  x, there are a, b such that a P x,
a R y, b P y, b R x. Then we have that ta, bu P F pz q, but ta, bu R F pxq Y F py q. Hence,
G1 pta, buq P epz q, but G1 pta, buq R epxq \ epy q. This shows that epz q  epxq \ epy q.
Note that in particular e preserves , , and ||. Moreover, epcpxqq  cpepxqq: this
follows from preservation of ||, since x||cpxq, and therefore epxq||epcpxqq, which is equivalent
to the inclusion above. Both e and i strongly preserve [, 0, and 1, and therefore also ei
strongly preserves [, 0, and 1.
The following is a direct consequence of the fact that isomorphisms between k and 
preserve Horn formulas over ; since the simple proof is instructive for what follows, we
give it for the special case that is relevant here.
Proposition 9. Outer Horn relations are preserved by i.
Proof. Let  be a conjunction of outer Horn clauses with variables V . Let tt0  1, t1 
1, . . . , tk  1u be an outer clause of . Let u, v : V  P pNq be two assignments that satisfy
this clause. Let w : V  P pNq be given by x  ipupxq, v pxqq. Suppose that w satisfies
tj  1 for all 1  j  k. Since i is injective we must have that tj  1 for both u and v for
1  j  k, and therefore neither assignment satisfies the negative literals. Hence, u and v
must satisfy t0  1. Since i is an isomorphism between S2 and S, it preserves in particular
t0  1, and hence w also satisfies t0  1.
Proposition 10. Inner Horn relations are strongly preserved by e.






Proof. Observe that x \ p j y j q  1 is equivalent to x [ p j yj q  j yj , which is strongly
preserved by e since e strongly preserves [. This clearly implies the statement.
Note that Proposition 9 and Proposition 10 imply that ei strongly preserves inner Horn
relations. We later also need the following.

 N, where k  1. Then the following are equivalent.
epx1 q \    \ epxk q \ epy1 q \    \ epyl q  1.

there exists an i  k such that xi \ p j y j q  1.

Lemma 11. Let x1 , . . . , xk , y1 , . . . , yl
1.
2.

740

fiTractable Set Constraints

3. there exists an i  k such that epxi q \ p


j

epyj qq  1.

 0, we have that j yjl  1 if and only if jl epyj q  1.
Proof. For the implication 
from p1q to p2q, suppose that there is for every i  k an ai P N
such that ai R Xi : xi \ p j y j q. Let c be G1 ta1 , a2 , . . . , ak u . Then for each i  k, we


have that c R epxi q \ j l epyj q. To see this, first observe that ai P j l yj [ xi . Therefore,
ta1, . . . , ak u P jl F pyj q [ F pxiq for all i  k. We conclude that c R epx1q \    \ epxk q \
epy1 q \    \ epyl q.
The implication p2q  p3q follows directly from Proposition 10. The implication p3q 
p1q is trivial. The second statement is a direct consequence of Proposition 10.
For k

Proposition 12. Every Horn-Horn relation is preserved by e and i, and so in particular
by ei.
Proof. Suppose that R has a Horn-Horn definition  over S with variables V . Since R is
in particular outer Horn, it is preserved by i by Proposition 9.
Now we verify that R is preserved by e. Let u : V  P pNq be an assignment that
satisfies . That is, u satisfies at least one literal in each outer clause of . It suffices to
show that the assignment v : V  P pNq defined by x  epupxqq satisfies the same outer
literal. Suppose first that the outer literal is positive; because  is Horn-Horn, it is of the
form x \ y1 \    \ yl  1 or of the form y1 \    \ yl  1, which is preserved by e by
Lemma 11.
Now, suppose that the outer literal is negative, that is, of the form x1 \    \ xk \ y1 \
   \ yl  1 for some k  0. We will treat the case k  1, the other case being similar.
Suppose for contradiction that v px1 q \ 
  \ vpxk q \ vpy1q \    \ vpyl q  1. By Lemma 11,
there exists an i  k such that upxi q \ p j upy j qq  1. But then we have in particular that
upx1 q \    \ upxk q \ upy1 q \    \ upyl q  1, in contradiction to the assumption that u
satisfies .
4.3 EI Set Constraints
In this section we introduce the class of EI set constraints, show that it strictly contains
all Horn-Horn relations, give several examples and non-examples. Then we present an
algorithmic reduction from CSPs for EI set constraints to satisfiability for finite sets of
Horn-Horn clauses.
Definition 13. The set of all relations with a quantifier-free definition over S that are
preserved by the operation ei is denoted by EI.
Remark. Note that the definition of the operation ei (Definition 5) involved a bijection G
between N and Fin ; we will see later (Proposition 36 and Proposition 37) that the class
EI is independent from the precise choice of G.
Recall from Proposition 12 that EI contains all Horn-Horn relations. We now present
examples of relations that are not from EI, and examples of relations that are in EI but
not Horn-Horn.
741

fiBodirsky & Hils

Example 10. We give an example of a relation that is clearly not from EI. The relation
R  tpx, y q | x \ y  1u is violated by ei: consider S1  t2a | a P Nu and S2  t2a
1 | a P Nu. Then pS1 , S2 q P R, and since i is an isomorphism between S2 and S we
also have that pipS1 , S1 q, ipS2 , S2 qq P R. Since neither ipS1 , S1 q  ipS2 , S2 q nor ipS2 , S2 q 
ipS1 , S1 q, we get that epipS1 , S1 qq \ epipS2 , S2 qq  ep1q  1 by Proposition 8. Therefore,
peipS1, S1q, eipS2, S2qq R R which is what we wanted to show.
Example 11. The relation R  tpx, y, z q | px  y q _ py  z qu is also not preserved by
ei: note that p0, 1, 1q, p0, 0, 1q P R, but eip0, 0q, eip1, 0q, and eip1, 1q are pairwise distinct
since ei is injective.
Example 12. The formula

p x [ y  xq
^ px [ y  yq
^ pv  1 _ u  1 _ x \ y  1q
is clearly not Horn-Horn. However, the relation defined by the formula is from EI: if
px1, y1, u1, u2q und px2, y2, u2, v2q are from that relation, then neither ipx1, x2q  ipy1, y2q nor
ipy1 , y2 q  ipx1 , x2 q. By Proposition 8, peipx1 , x2 q, eipy1 , y1 q, eipu1 , u2 q, eipv1 , v2 qq satisfies
the formula. There is no equivalent Horn-Horn formula, since the formula is not preserved
by i.
Example 13. The formula ppx \ y  1q _ pu \ v  1qq ^ px \ y  1q ^ px \ y  1q is not
Horn-Horn. However, it is preserved by e and by i: the reason is that one of its clauses has
the negative literal x \ y  1, and the conjuncts tx \ y  1u and tx \ y  1u. Therefore,
for every tuple t P R the tuple eptq satisfies x \ y  1 and is in R as well. By Proposition 9,
R is preserved by i. In this case, the authors suspect that there is no equivalent Horn-Horn
formula. More generally, it is open whether there exist formulas that are preserved by e and
i, but that are not equivalent to a Horn-Horn formula.
Corollary 14. The class of Horn-Horn relations is a proper subclass of EI.
Proof. Proposition 12 shows that EI contains all Horn-Horn relations. Example 12 shows
that the inclusion is strict.
We prepare now some results that can be viewed as a partial converse of Proposition 12.
Definition 15. A quantifier-free formula  (in the syntactic form described at the end of
Section 3) is called reduced if if every formula obtained from  by removing an outer literal
is not equivalent to  over S.
We note that a slightly different notion of a reduced formula has been introduced by
Bodirsky, Chen, and Pinsker (2010). The variant we are using here is better suited for our
purposes.
Lemma 16. In the structure S, every quantifier-free formula is equivalent to a reduced
formula.
742

fiTractable Set Constraints

Proof. It is clear that every quantifier-free formula can be written as a formula  in CNF
and in the form as we have discussed it after Theorem 1. We now remove successively outer
literals as long as this results in an equivalent formula.
We first prove a partial converse of Proposition 9.
Proposition 17. Let  be a reduced formula that is preserved by i. Then each outer clause
of  is Horn.
Proof. Let V be the set of variables of . Assume for contradiction that  contains an outer
clause with two positive literals, t1  1 and t2  1. If we remove the literal t1  1 from
its clause C, the resulting formula is inequivalent to , and hence there is an assignment
s1 : V  P pNq that satisfies none of the literals of C except for t1  1. Similarly, there is
an assignment s2 : V  P pNq that satisfies none of the literals of C except for t2  1. By
injectivity of i, and since i strongly preserves c, [, \, and 1, the assignment s : V  P pNq
defined by x  ips1 pxq, s2 pxqq does not satisfy the two literals t1  1 and t2  1. Since i
strongly preserves c, \, [, none of the other literals in C is satisfied by those mappings as
well, in contradiction to the assumption that  is preserved by i.
Definition 18. Let V be a set of variables, and s : V  P pNq be a mapping. Then a
function from V  P pNq of the form x  epspxqq is called a core assignment.
Lemma 19. For every quantifier-free formula  there exists a formula  such that all inner
clauses are inner Horn, and such that  and  have the same satisfying core assignments.
If  is preserved by ei, then the set of all satisfying core assignments of  is closed under
ei.
Proof. Suppose that  has an outer clause C with a positive outer literal t  1 such that t
contains an inner clause c : x1 \    \ xk \ y 1 \    \ y l that is not Horn, i.e., k  2. Then
we replace the outer literal t  1 in  by k literals t1  1, . . . , tk  1 where ti is obtained
from t by replacing c by xi \ y 1 \    \ y l .
We claim that the resulting formula 1 has the same set of satisfying core assignments.
Observe that xi \ y 1 \    \ y l  c, and hence ti  1 implies t  1. An arbitrary satisfying
assignment of 1 satisfies either one of the positive outer literals ti  1, in which case that
observation shows that it also satisfies , or it satisfies one of the other outer literals of C,
in which case it also satisfies this literal in . Hence, 1 implies . Conversely, let s be a
satisfying core assignment of . If s satisfies a literal from C other than t  1, then it also
satisfies this literal in 1 , and s satisfies 1 . Otherwise, s must satisfy t  1, and hence
spx1 q\  \ spxk q\ spy1 q\  \ spyl q  1. Since s is a core assignment, Lemma 11 implies
that there exists an i  k such that spxi q \ spy1 q \    \ spyl q  1. So s satisfies 1 .
Suppose that  has an outer clause C with a negative outer literal t  1 such that t
contains an inner clause c : x1 \    \ xk \ y 1 \    \ y l that is not Horn, i.e., k  2.
Then we replace the clause C in  by k clauses C1 , . . . , Ck where Ck is obtained from C
by replacing c with xi \ y 1 \    \ y l .
We claim that the resulting formula 1 has the same set of satisfying core assignments.
Observe that x1 \    \ xk \ y 1 \    \ y l  1 implies that xi \ y 1 \    \ y l  1, for every
i  k. The observation shows that an arbitrary assignment of  is also an assignment of 1 .
743

fiBodirsky & Hils

Conversely, let s be a satisfying core assignment of 1 . If s satisfies one of the other literals
of C other than t  1, then s satisfies . Otherwise, s must satisfy xi \ y 1 \  \ y l  1 for
all i  k, and by Lemma 11 we have that s also satisfies x1 \    \ xk \ y 1 \    \ y l  1.
We perform these replacements until we obtain a formula 1 where all inner clauses are
Horn; this formula satisfies the requirements of the first statement of the lemma.
To prove the second statement, let u, v : V  P pNq be two satisfying core assignments
of 1 . Since 1 and  have the same satisfying core assignments, u and v also satisfy . Then
the mapping w : V  P pNq given by x  eipupxq, v pxqq is a core assignment, and because
ei preserves , the mapping w satisfies . Since  and 1 have the same core assignments,
w is also a satisfying assignment of 1 , which proves the statement.
We now single out a technical condition which guarantees, under some extra condition
(see Proposition 21) that formulas satisfying a certain universl algebraic property are HornHorn. This will allow us to perform a reduction from a CSP associated to a (finite) set
constraint languages from EI to satisfiability of Horn-Horn clauses.
Definition 20. A quantifier-free formula  (in the syntactic form described at the end of
Section 3) is called strongly reduced if every formula obtained from  by removing an outer
literal does not have the same set of satisfying core assignments over S.
Proposition 21. Let  be a strongly reduced formula all of whose inner clauses are Horn.
If the set of satisfying core assignments of  is closed under ei, then  is Horn-Horn.
Proof. Let V be the set of variables of . It suffices to show that all clauses of  are outer
Horn. Assume for contradiction that  contains an outer clause with two positive literals,
t1  1 and t2  1. If we remove the literal t1  1 from its clause C, the resulting formula
has strictly less satisfying core assignments; this shows the existence of a core assignment
s1 : V  P pNq that satisfies none of the literals of C except for t1  1. Similarly, there exists
a core assignment s2 : V  P pNq that satisfies none of the literals of C except for t2  1.
By assumption, the inner clauses of t1 and t2 are Horn. We claim that the assignment
s : V  P pNq defined by x  eips1 pxq, s2 pxqq does not satisfy the clause C. Since ei
strongly preserves inner Horn clauses, we have that s does not satisfy t1  1 _ t2  1. For
the same reasons s does not satisfy any other literals in C; this contradicts the assumption
that the satisfying core assignments for  are preserved by ei.
Satisfiability of Horn-Horn clauses is the computational problem to decide whether,
given a finite set S of Horn-Horn clauses, there is a satisfying assignment for S.
Proposition 22. Let  be a finite set constraint language from EI. Then CSPpq can be
reduced in linear time to satisfiability of Horn-Horn clauses.
Proof. Let  be an instance of CSPpq, and let V be the set of variables that appear in
. For each constraint Rpx1 , . . . , xk q from , let R be the definition of R over S. By
Lemma 19, there exists a formula R that has the same satisfying core assignments as R
and where all inner clauses are Horn; moreover, since R is preserved by ei, the lemma
asserts that the set of all satisfying core assignments of R is preserved by ei. We can
assume without loss of generality that R is strongly reduced; this can be seen similarly to
Lemma 16. By Proposition 21, the formula R is Horn-Horn.
744

fiTractable Set Constraints

Let  be the set of all Horn-Horn clauses of formulas R px1 , . . . , xk q obtained from constraints Rpx1 , . . . , xk q in  in the described manner. We claim that  is a satisfiable instance
of CSPpq if and only if  is satisfiable. This follows from the fact that for each constraint
Rpx1 , . . . , xk q in , the formulas R and R have the same satisfying core assignments, and
that both R and R are preserved by ei (for R this follows from Proposition 12), so in
particular by the function x  eipx, xq.
Note that in Proposition 22 we reduce satisfiability for EI to satisfiability for a proper
subclass of Horn-Horn set constraints: while for general Horn-Horn set constraints we allow
that inner clauses of negative outer literals are not Horn, the reduction only produces HornHorn clauses where all inner clauses are Horn.

5. Algorithm for Horn-Horn Set Constraints
We present an algorithm that takes as input a set  of Horn-Horn clauses and decides
satisfiability of  over S  pP pNq; \, [, c, 0, 1q in time quadratic to the length of the input.
By Proposition 22, this section will therefore conclude the proof that CSPpq is tractable
when all relations in  are from EI.
As mentioned in the introduction, our algorithm is based on two procedures, both
resolution-like. The inner procedure is essentially the well-known positive unit resolution
procedure for Horn-SAT, and the outer procedure is basically an algorithm that has been
used in the literature about independence in constraint satisfaction (see, e.g., Jonsson &
Backstrom, 1998; Koubarakis, 2001; Broxvall et al., 2002; Cohen et al., 2000). Our contribution in this section is the way how to nest these two algorithms to obtain a polynomial-time
decision procedure for satisfiability of Horn-Horn clauses.
We start by discussing the first procedure of our algorithm, which we call the inner
resolution algorithm. As in the case of Boolean positive unit resolution (Dowling & Gallier,
1984) one can implement the procedure Inner-Res such that it runs in linear time in the
input size.
Lemma 23. Let  be a finite set of inner Horn clauses. Then the following are equivalent.
1.



  1 is satisfiable over S.

2. Inner-Respq from Figure 1 accepts.
3.



  1 has a solution whose image is contained in


tH, Nu.

Proof. It is obvious that   1 is unsatisfiable when Inner-Respq rejects; in fact, for
all
inner clauses c derived by Inner-Res from , the formula c  1 is logically implied by

  1. Conversely, if the algorithm accepts then we can set all eliminated variables to
N and all remaining variables to H, which satisfies all clauses: in the removed clauses the
positive literal is satisfied, and in the remaining clauses we have at least one negative literal
at the final stage of the algorithm, and all clauses with negative literals at the final stage
of the algorithm are satisfied.




The proof of the previous lemma shows that   1 is satisfiable over S if and only if
  1 is satisfiable over the two-element Boolean algebra. As we will see in the following,
745

fiBodirsky & Hils

Inner-Res()
// Input: A finite set  of inner Horn clauses
// Accepts iff   1 is satisfiable
During the entire algorithm:
if  contains an empty clause, then reject.
Repeat := true
While Repeat = true do
Repeat := false
If  contains a positive unit clause txu then
Repeat := true
Remove all clauses where the literal x occurs.
Remove the literal x from all clauses.
End if
Loop
Accept



Figure 1: Inner Resolution Algorithm.
this holds more generally (and not only for inner Horn clauses). The following should be
well-known, and can be shown with the same proof as given by Koppelberg (1989) for the
weaker Proposition 2.19 there. We give the proof here for the convenience of the reader.
Fact 24. Let t1 , t2 be terms over

t[, \, c, 0, 1u. Then the following are equivalent:

 1 ^ t2  1 is satisfiable over the two-element Boolean algebra;
t1  1 ^ t2  1 is satisfiable over all Boolean algebras;
t1  1 ^ t2  1 is satisfiable over some Boolean algebra;
t1  1 ^ t2  1 is satisfiable over some finite Boolean algebra.

1. t1
2.
3.
4.

Proof. Obviously, (1) implies (2), and (2) implies (3).
For (3) implies (4), assume that t1  1 ^ t2  1 has a satisfying assignment in some
Boolean algebra C. Let x1 , . . . , xn be the variables which occur in t1 or t2 , and let xi  ci
be a satisfying assignment. Then t1  1 ^ t2  1 is satisfiable in the Boolean sub-algebra
n
C1 of C generated by tc1 , . . . , cn u, and C1 is finite (it has at most 2p2 q elements).
For (4) implies (1), first note that any finite Boolean algebra is isomorphic to the Boolean
algebra pP pX q; [, \, c, 0, 1q of subsets of some finite set X. If x P X, consider the map hx :
P pX q  t0, 1u, hpY q : 1 if x P Y , and hpY q  0 otherwise. Then hx is a homomorphism
of Boolean algebras. In particular, this shows that for every non-zero element a of a finite
Boolean algebra C, there is a homomorphism h from C to the two-element Boolean algebra
such that hpaq  0. Now suppose (4), and assume that t1  1 ^ t2  1 has a satisfying
assignment in some finite Boolean algebra C. Let c be the element denoted by t2 in C
under this assignment, so c  1. Now let h be a homomorphism from C to t0, 1u such that
hpcq  0, i.e. hpcq  1. By construction, the image of the satisfying assignment under h is
a satisfying assignment of t1  1 ^ t2  1 in t0, 1u.
746

fiTractable Set Constraints

The same statement for t1  1 instead of t1  1 ^ t2  1 has been given in Proposition
2.19 (Koppelberg, 1989). Fact 24 has the following consequence that is crucial for the way
how we use the inner resolution procedure in our algorithm.
Lemma 25. Let  be a finite set of inner Horn clauses. The following are equivalent:
1. Inner-RespYtx1 , . . . , xk , y0 , . . . , yl uq rejects.


 1 over S.


Proof.
  1 implies that x1 \    \ xk \ y 1 \    \ y l  1 if and only if
 
1 ^ x1 \   
\ xk \ y1 \    \ yl  1 is unsatisfiable over S. By Fact 24, this is the case if
and only if   1 ^ x1 \    \ xk \ y 1 \    \
y  1 is unsatisfiable over the 2-element
 l
Boolean algebra, which is the case if and only if   1 ^ x1 \  \ xk \ y 1 \  \ y l  0 is
2.

  1 implies that x1 \    \ xk \ y 1 \    \ y l

unsatisfiable over the two-element Boolean algebra. As we have seen in Lemma 23, this in
turn holds if and only if Inner-RespYtx1  1, . . . , xk  1, y1  1, . . . , yl  1uq rejects.
Outer-Res()
// Input: A finite set  of Horn-Horn clauses
// Accepts iff  is satisfiable over pP pNq; [, \, c, 0, 1q
During the entire algorithm:
if  contains an empty clause, then reject.
Repeat := true
While Repeat = true do
Repeat := false
Let  be the set of all inner Horn clauses of terms t
from positive unit clauses tt  1u in .
If Inner-Res rejects , then reject.
For each negative literal t  1 in clauses from 
For each inner clause D  tx1 , . . . , xk , y 1 , . . . , y l u of t
Call Inner-Res on
 Y tx1  1, . . . , xk  1, y0  1, . . . , yl  1u
If Inner-Res rejects then remove clause D from t
End for
If all clauses in t have been removed, then
Remove outer literal t  1 from its clause
Repeat := true
End for
Loop
Accept

Figure 2: Outer Resolution Algorithm.
Theorem 26. The algorithm Outer-Res in Figure 2 decides satisfiability for sets of HornHorn clauses in quadratic time.
Proof. We first argue that if the algorithm rejects , then  has indeed no solution. First
note that during the whole argument, the set of clauses  has the same satisfying tuples
747

fiBodirsky & Hils

(i.e., the corresponding formulas are equivalent): Observe that only negative literals get
removed from clauses, and that a negative literal t  1 only gets removed from a clause
when Inner-Res rejects  Y tx1  1, . . . , xk  1, y0  1, . . . , yl  1u for each inner clause
tx1, . . . , xk , y1, . . . , yl u of t. By Lemma 25, if Inner-Res rejects  Ytx1  1, . . . , xk  1, y0 
1, . . . , yl  1u then  implies that x1 \    \ xk \ y 1 \    \ y l  1. Hence, the positive
unit clauses imply that t  1 and therefore the literal t  1 can be removed from the clause
without changing the set of satisfying tuples. Now the algorithm rejects if either Inner-Res
rejects  or if it derives the empty clause. In both cases it is clear that  is not satisfiable.
Thus, it suffices to construct a solution when the algorithm accepts. Let  be the set of
all inner clauses of terms from positive unit clauses at the final stage, when the algorithm
accepts. For each remaining negative outer literal tt  1u and each remaining inner clause
D  tx1 , . . . , xk , y 1 , . . . , y l u of t there exists an assignment D from V  P pNq that satisfies
 Ytx1 \  \ xk \ y 1 \  \ y l  1u: otherwise, by Lemma 25, the inner resolution algorithm
would have rejected  Y tx1  1, . . . , xk  1, y0  1, . . . , yl  1u, and would have removed
the inner clause D from t. Let D1 , . . . , Ds be an enumeration of all remaining inner clauses
D that appear in all remaining negative outer literals.
Write is for the s-ary operation defined by px1 , . . . , xs q  ipx1 , ipx2 , . . . , ipxs1 , xs q    qq
(where i is as in Fact 7). We claim that s : V  P pNq given by
x  is pD1 pxq, . . . , Ds pxqq

satisfies all clauses in . Let C be a clause from . By assumption, at the final stage of the
algorithm, the clause C is still non-empty. Also note that since all formulas in the input
were Horn-Horn, they contain at most one positive literal. This holds in particular for C,
and we therefore only have to distinguish the following cases:
 At the final state of the algorithm, C still contains a negative literal t  1. Since t  1
has not been removed, there is a remaining inner clause D  tx1 , . . . , xk , y 1 , . . . , y l u
of t. Observe that spx1 q \    \ spxk q \ spy1 q \    \ spyl q  1 if and only if Dj px1 q \
   \ Dj pxk q \ Dj py1q \    \ Dj pyl q  1 for all 1  j  s. Hence, and since
D px1 q \    \ D pxk q \ D py1 q \    \ D pyl q  1, s satisfies t  1. This shows that
s satisfies C.
 All negative literals have been removed from C during the algorithm. The positive
literal t0  1 of C is such that the inner clauses of t0 are Horn. They will be part of
, and therefore t0  1 is satisfied by s. Indeed, by assumption the assignments Dj
satisfy , and  is preserved by i.
We conclude that s is a solution to . The inner resolution algorithm has a linear time
complexity; the outer resolution algorithm performs at most a linear number of calls to
the inner resolution algorithm, and it is straightforward to implement all necessary data
structures for outer resolution to obtain a running time that is quadratic in the input
size.
Combining Proposition 22 with Theorem 26, we obtain the following.
Theorem 27. Let  be a finite set constraint language from EI. Then CSPpq can be
solved in quadratic time.
748

fiTractable Set Constraints

6. Maximal Tractability
In this section we show that the class EI is a maximal tractable set constraint language.
More specifically, let  be a set constraint language that strictly contains all EI relations.
We then show that  contains a finite set of relations 1 such that already the problem
CSPp1 q is NP-hard (Theorem 40).
6.1 The Universal-Algebraic Approach
In our proof we use the so-called universal-algebraic approach to the complexity of constraint satisfaction problems, which requires that we re-formulate set CSPs as constraint
satisfaction problems for -categorical structures. For a more detailed introduction to the
universal-algebraic approach for -categorical structures (see Bodirsky, 2012). A structure
 with a countable domain is called -categorical if all countable structures that satisfy
the same first-order sentences as  are isomorphic to  (see, e.g., Hodges, 1993). By the
theorem of Ryll-Nardzewski, and for countable signatures, this is equivalent to requiring
that every relation that is preserved by the automorphisms1 of  is first-order definable in
 (see, e.g., Hodges, 1993). A useful consequence of this is that in an -categorical structure , whenever two tuples c  pc1 , . . . , cn q and d  pd1 , . . . , dn q from  satisfy the same
first-order formulas, there is an automorphism  of  which maps c to d.
An example of an -categorical structure is pQ; q (by Cantors theorem), and a nonexample is given by pZ; q. Note that pQ; q and pZ; q have the same CSP; indeed, any two
infinite linear orders share the same CSP, since they even have the same finite substructures.
A characterisation of those infinite structures for which there is an -categorical structure
having the same CSP has been given by Bodirsky, Hils, and Martin (2011). Empirically,
it can be observed that constraint satisfaction problems studied in temporal and spatial
reasoning are typically called qualitative if and only if they can be formulated with an
-categorical template.
Set constraint languages are in general not -categorical (this follows easily by the
mentioned theorem of Ryll-Nardzewski). However, every set CSP can be formulated as the
CSP of an -categorical structure. To see this, we first have to recall some basic facts about
Boolean algebras. All countable atomless2 Boolean algebras are isomorphic (Koppelberg,
1989, Corollary 5.16; see also Hodges, 1993, Example 4 on page 100). Let A denote such a
countable atomless Boolean algebra, and let A denote the domain of A. Again, we use [
and \ to denote join and meet in A, respectively. Since the axioms of Boolean algebras and
the property of not having atoms can all be written as first-order sentences, it follows that A
is -categorical. A structure B has quantifier elimination if every first-order formula is over
B equivalent to a quantifier-free formula. It is well-known that A has quantifier elimination
(see Hodges, 1993, Exercise 17 on page 391). We will also make use of the following.
Theorem 28 (Marriott & Odersky, 1996, Corollary 5.7). A quantifier-free formula is satisfiable in some infinite Boolean algebra if and only if it is satisfiable in all infinite Boolean
algebras.
1. An isomorphism of a structure  with itself is called an automorphism of .
2. An atom in a Boolean algebra is an element x  0 such that for all y with x X y
y  0. If a Boolean algebra does not contains atoms, it is called atomless.

749

 y and x  y we have

fiBodirsky & Hils

In particular, when B is an infinite Boolean algebra and 1 , . . . , n are quantifier-free
formulas over the signature t[, \, c, 0, 1u, and when  is the relational structure with signature tR1 , . . . , Rn u where Ri is for each i  n defined by i over B, then CSPpq does not
depend on the choice of B.
A fundamental concept in the complexity theory of constraint satisfaction problems is
the notion of primitive positive definitions. A first-order formula is called primitive positive
(pp) if it is of the form
Dx1, . . . , xn p1 ^    ^ mq
where for each i  m the formula i is of the form Rpy1 , . . . , yl q or of the form y1  y2 , and
where R is a relation symbol and y1 , y2 , . . . , yl are either free variables or from tx1 , . . . , xn u.
We say that a k-ary relation R  Dk is primitive positive definable (pp definable) over a
 -structure  with domain D iff there exists a primitive positive formula px1 , . . . , xk q with
the k free variables x1 , . . . , xk such that a tuple pb1 , . . . , bk q is in R if and only if pb1 , . . . , bk q
is true in .
Example 14. The relation tpx, y q P P pNq2 | x  y u is pp definable in pP pNq; S, q where
S  tpx, y, z q | x [ y  z u. The pp definition is S px, x, y q ^ x  y (the definition is even
quantifier-free).
Example 15. The relation tpx1 , x2 , x3 , y q P P pNq4 | x1 [ x2 [ x3  y u is pp definable
in pP pNq; S q where S  tpx, y, z q | x [ y  z u. The pp definition is Du pS px1 , x2 , uq ^
S pu, x3 , y qq.
When every relation of a structure  is preserved by an operation f , then f is called a
polymorphism of . Note that polymorphisms of  also preserve all relations that have a pp
definition in . The following has been shown for finite domain constraint satisfaction by
Bulatov et al. (2005); the easy proof also works for infinite domain constraint satisfaction.
Lemma 29. Let R be a relation with a primitive positive definition in a structure . Then
CSPpq and the CSP for the expansion of  by the relation R are polynomial-time equivalent.
The following theorem is one of the reasons why it is useful to work with -categorical
templates (when this is possible).
Theorem 30 (Bodirsky & Nesetril, 2006). Let  be an -categorical structure. Then R is
primitive positive definable in  if and only if R is preserved by all polymorphisms of .
The previous and the next result together can be used to translate questions about
primitive positive definability 
into purely operational questions. Let D be a set, let Opnq
pnq the set of operations on D of finite arity. An
be Dn  D, and let O be 8
n1 O
p
n
q
operation  P O is called a projection if for some fixed i P t1, . . . , nu and for all n-tuples
px1, . . . , xnq P Dn we have the identity px1, . . . , xnq  xi. The composition of a k-ary
operation f and k operations g1 , . . . , gk of arity n is the n-ary operation defined by

pf pg1, . . . , gk qqpx1, . . . , xnq

 f g1px1, . . . , xnq, . . . , gk px1, . . . , xnq .
750

fiTractable Set Constraints

Definition 31. We say that F  O locally generates f : Dn  D if for every finite subset
A of D there is an operation g : Dn  D that can be obtained from the operations in F
and projection maps by composition such that f paq  g paq for all a P An .
Theorem 32 (see Szendrei, 1986, Corollary 1.9; also Bodirsky, 2012, Proposition 5.2.1). Let
F  O be a set of operations with domain D. Then an operation f : Dk  D preserves all
finitary relations that are preserved by all operations in F if and only if F locally generates
f.
The set of all automorphisms of a structure  is denoted by Autpq. In the following, we
always consider sets of operations F that contain AutpAq, and therefore make the following
convention. For F  O, we say that F generates f P O if F Y AutpAq locally generates f .
6.2 EI Set Constraints over the Atomless Boolean Algebra
In the previous subsection we have seen that all set CSPs can be formulated as CSPs for
-categorical structures. In this section, we describe those -categorical templates that
correspond to set CSPs for EI set constraints. In order to do so, we define analogs of the
operations e and i, defined on A instead of P pNq.
Proposition 33. There is an isomorphism i between A2 and A.
Proof. It is straightforward to verify that A2 is again a countable atomless Boolean algebra.

Motivated by the properties of e described in Lemma 11, we make the following definition.
Definition 34. Let B and B1 be two arbitrary Boolean algebras with domains B and B 1 ,
respectively, and let g : B  B 1 be a function that strongly preserves [, 0, and 1. We say
that g forgets unions if for all k  1, l  0, and x1 , . . . , xk , y1 , . . . , yl P B we have
epx1 q \    \ epxk q \ epy1 q \    \ epyl q  1
if and only if there exists an i  k such that xi \ y1 \    \ yl

 1.

Proposition 35. There exists an injection e : A  A that strongly preserves
in A, and that forgets unions.

[, 0, and 1

Proof. The construction of e is by a standard application of Konigs tree lemma for categorical structures (see, e.g., Bodirsky & Dalmau, 2012, Lemma 2); it suffices to show
that there is an injection f from every finite induced substructure B of A to A such that f
strongly preserves [, 0, and 1, and forgets unions.
So let B be such a finite substructure of A, and let B be the domain of B. Let C 
pP pB q; [, \, c, 0, 1q be the Boolean algebra of the subsets of B. We claim that g : B  P pB q
given by g p1q  1 and g pxq  tz | z  0 ^ z B xu for x  1
 preserves 0 and 1: this is by definition;
751

fiBodirsky & Hils

 preserves

[: for x, y P B (including the case that x  1 or y  1) we have
g pxq [C g py q  tz | z  0 ^ z B x ^ z B y u
(
 z | z  0 ^ z B px [B y q
 g p x [B y q ;

 is injective: if x, y
x  y;
 strongly preserves

P B such that gpxq  gpyq, then x B y and y B x, and hence
[: this follows from the previous two items;

 forgets unions: this can be shown analogously to the proof of Lemma 11.






Indeed, one has xi \ y1 \    \ yl  1 iff xi B j yj iff xi [ j yj  j yj iff


g pxi q[ j g pyj q  j g pyj q iff g pxi q\ g py1 q\  \ g pyl q  1. Thus, xi \ y1 \  \ yl  1
for some 1  i  k implies g px1 q \    \ g pxk q \ g py1 q \    \ g pyl q  1.
To prove the converse, we use that the finite Boolean algebra B may be identified with
pP pAq; [, \, c, 0, 1q for some finite set A. If Xi : xi \ y1 \  \ yl  1 for i  1, . . . , k,
we may choose ai P AzXi , i.e. ai P j yj [ xi , for i  1, . . . , k. Let C : ta1 , . . . , ak u 
A, so C P B. By construction, for i  k one has tC u R g pxi q \ g py1 q \    \ g pyl q. In
particular, it follows that g px1 q \    \ g pxk q \ g py1 q \    \ g pyl q  1.
Clearly, there is an embedding h from C into A. Then f : hpg q is a homomorphism from
B to A that forgets unions.
Proposition 36. Let  be a quantifier-free formula over the signature t[, \, c, 0, 1u. Then
e preserves  over S if and only if e preserves  over A. Moreover, every operation from
A  A that strongly preserves [, 0, and 1 and forgets unions generates e, and is generated
by e.
Proof. Let a be a tuple of elements from A. Clearly, there exists a tuple b of elements from
P pNq such that a and b satisfy the same set  of quantifier-free formulas; this follows from
the fact that every finite Boolean algebra is the Boolean algebra of subsets of a finite set.
Now observe that whether or not the tuple epbq satisfies a quantifier-free formula  only
depends on , by Lemma 11. Since e strongly preserves [, 0, and 1, and forgets unions,
the same is true for the quantifier-free formulas that hold on epaq. Hence, e preserves 
over A if and only if e preserves  over S.
To prove the second part of the statement, we use Theorem 32. Suppose that c and
d are tuples (of the same length) of elements from A that satisfy the same quantifier-free
formulas. Since A has quantifier-elimination, it follows that c and d satisfy the same firstorder formulas in A. By the consequence of the theorem of Ryll-Nardzewski mentioned at
 By the
the beginning of Section 6.1, there exists an automorphism  of A that maps c to d.
above observations and Theorem 32, this implies that all operations that strongly preserve
[, 0, and 1, and forget unions generate each other.
r be the operation px, y q  epipx, y qq.
Let ei
752

fiTractable Set Constraints

Proposition 37. Let  be a quantifier-free formula over the signature t[, \, c, 0, 1u. Then
r preserves  over A. Moreover, every binary operation
ei preserves  over S if and only if ei
r and is generated by
g that strongly preserves [, 0, and 1, and forgets unions generates ei,
r
ei.
Proof. The arguments are similar to the ones given in the proof of Proposition 36. If a1
and a2 are n-tuples of elements from A, there are n-tuples b1 , b2 of elements from P pNq such
that pa1 , a2 q and pb1 , b2 q satisfy the same set  of quantifier-free formulas. Whether or not
eipb1 , b2 q satisfies a quantifier-free formula  only depends on , as ei strongly preserves [,
r pa1 , a2 q, and so ei
r preserves  over A if
0, and 1, and forgets unions. The same holds for ei
and only if ei preserves  over S.
The proof of the second part of the statement is identical to the one for Proposition 36.

6.3 The Central Argument
We now give the central argument for the maximal tractability of EI, stated in universalalgebraic language. We say that an operation from Ak  A depends on the argument
i P t1, . . . , k u if there is no pk 1q-ary operation f 1 such that for all x1 , . . . , xk P A
f px1 , . . . , xk q  f 1 px1 , . . . , xi1 , xi

1 , . . . , xk

q.

We can equivalently characterize k-ary operations that depend on the i-th argument by
requiring that there are x1 , . . . , xk P A and x1i P A such that
f px1 , . . . , xk q  f px1 , . . . , xi1 , x1i , xi

1 , . . . , xk

q.

The following is a general fact about injective maps.
Lemma 38. Let f : Ak  A be a function that depends on all arguments, and which is
locally generated by a set of injective operations F. Then f is injective.
Proof. We first prove that every term T px1 , . . . , xn q formed from operations from F over
the variables x1 , . . . , xn such that every variable appears at least once defines an injective
map. We prove this by induction over the term structure. In case that n  1 and T is just
x1 there is nothing to show. Otherwise, T has the form f pT1 , . . . , Tk q for a k-ary f P F such
that Tj  Tj pxi1 , . . . , ximpj q q is for all j  k a term over operations from F with variables
xi1 , . . . , ximpj q each of which appears at least once in Tj . Now suppose that a1 , . . . , an P A
and b1 , . . . , bn P A are such that T pa1 , . . . , an q  T pb1 , . . . , bn q. We want to show that ai  bi
for all i  n. Since f is injective we must have that Tj pai1 , . . . , aimpj q q  Tj pbi1 , . . . , bimpj q q
for all j  k. Since every variable from x1 , . . . , xn appears in T at least once, the variable
xi must appear in Tj , for some j  k. Since Tj defines an injective operation by inductive
assumptions, we must have that ai  bi . It follows that T defines an injective map.
Now suppose that f is an operation that is locally generated by F and depends on
all arguments. Thus, for each i there are ci1 , . . . , cin and di such that f pci1 , . . . , cin q 
f pci1 , . . . , cii1 , di , cii 1 , . . . , cin q. Let a1 , . . . , an , b1 , . . . , bn P A be such that f pa1 , . . . , an q 
f pb1 , . . . , bn q. We have to show that a1  b1 , . . . , an  bn . Since f is locally generated
753

fiBodirsky & Hils

by F, there exists a term T px1 , . . . , xn q composed from the variables x1 , . . . , xn and operations from F such that T pe1 , . . . , en q  f pe1 , . . . , en q for all elements e1 , . . . , en from the
set ta1 , . . . , an , b1 , . . . , bn , c11 , . . . , cnn , d1 , . . . , dn u. For all i, the variable xi must appear in
T px1 , . . . , xn q because T pci1 , . . . , cin q  T pci1 , . . . , cii1 , di , cii 1 , . . . , cin q. Hence, the argument
from the beginning of the proof shows that T px1 , . . . , xn q defines an injective map, and
therefore that a1  b1 , . . . , an  bn . We have shown that f is injective.
r u. Then either tf u generates ei,
r or f
Theorem 39. Let f be an operation generated by tei
is generated by teu.

r u.
Proof. To show the statement of the theorem, let f be a k-ary operation generated by tei
For the sake of notation, let x1 , . . . , xl be the arguments on which f depends, for l  k.
Let f 1 : Al  A be the operation given by f 1 px1 , . . . , xl q  f px1 , . . . , xl1 , xl , xl , . . . , xl q.
Observe that f 1 depends on all arguments, and is locally generated by injective operations;
by Lemma 38, f 1 is injective. Since f 1 is generated by operations that preserve 0, 1, and
[, also f 1 preserves them. As f 1 is injective, it even strongly preserves 0, 1, and [.
Consider first the case that l  1, i.e., f 1 is unary. If for all finite subsets of A, the
operation f 1 equals an automorphism of A, then f is generated by AutpAq and there is
nothing to show. So assume otherwise; that is, assume that there is a finite set S  A
such that there is no a P AutpAq with f 1 pxq  apxq for all x P S. We claim that f 1 forgets
unions. To see this, let u1 , . . . , um , v1 , . . . , vn be from A such that f 1 pu1 q \    \ f 1 pum q \
 u, there is a term T pxq composed
f 1 pv1 q \    \ f 1 pvn q  1. Since f 1 is generated by tei
r
from ei, the automorphisms of A, and a single variable x such that f 1 pxq  T pxq for all
x P S Y tu1 , . . . , um , v1 , . . . , vn u. By the choice of S, this term cannot be composed of
automorphisms alone, and hence there must be a P AutpAq and operational terms T1 , T2
r such that f 1 pxq  apei
r pT1 pxq, T2 pxqqq for all
composed from automorphisms of A and ei
r
x P S. As ei forgets unions, there exists an i  k such that T1 pui q\ T1 pv1 q\  \ Tl pvn q  1.
Since T1 strongly preserves [, this means that ui \ v 1 \    \ v n  1 (see the proof of
Proposition 10), which is what we wanted to show. By Proposition 36 it follows that f 1 is
generated by e. But then f is generated by e as well.
Next, consider the case that l  1. Let g be the binary operation defined by g px, y q 
1
f px, y, . . . , y q. This functions depends on both arguments, and so cannot be generated by
the automorphisms of A alone. Hence, there is a term of the form
r pT1 px, y q, T2 px, y qqq
T px, y q  apei

where
 a P AutpAq,
r the automorphisms of A, and the
 T1 and T2 are operational terms composed from ei,
two variables x and y,

 g px, y q  T px, y q for all px, y q P tu1 , . . . , um , v1 , . . . , vn u.

We claim that g forgets unions. Assume g pu1 q\  \ g pum q\ g pv1 q\  \ g pvn q  1 for
some elements u1  pu11 , u21 q, . . . , um  pu1m , u2m q, v1  pv11 , v12 q, . . . , vn  pvn1 , vn2 q from A2 .
r forgets unions, there exists an i  k such that T1 pui q\ T1 pv1 q\  \ T1 pvn q  1 and
Since ei
754

fiTractable Set Constraints

T2 pui q\T2 pv1 q\  \T2 pvn q  1. Suppose first that T1 depends on both arguments. Then T1
defines an injective operation and strongly preserves [. It follows that ui \ v 1 \  \ v n  1
in A2 since these equations are inner Horn. We can argue similarly if T2 depends on both
arguments, and in those cases we have established that g forgets unions. Suppose now
that each of T1 and T2 does not depend on both arguments. Consider first the case that
T1 only depends on the first argument. Then the function x  T1 px, xq is injective and
strongly preserves [, and from T1 pui q \ T1 pv1 q \    \ T1 pvn q  1 we derive as above that
u1i \ v11 \    \ vn1  1 holds in A. In this case, T2 must depend on the second argument,
since T depends on both arguments. We therefore also have that u2i \ v12 \  \ vn2  1 holds
in A. The situation that T1 only depends on the second argument and T2 only depends on
r
the first argument is analogous. So g forgets unions. By Proposition 37, g generates ei.
r
Consequently, also f generates ei.
Theorem 40. Let  be a set constraint language. Suppose that  contains all relations from
EI, and also contains a relation that is not from EI. Then there is a finite sublanguage 1
of  such that CSPp1 q is NP-hard.
Proof. When R1 , R2 , . . . are the relations of , let 1 , 2 , . . . be quantifier-free formulas that
define R1 , R2 , . . . over S  pP pNq; \, [, c, 0, 1q. Let R1A , R2A , . . . be the relations defined
by 1 , 2 , . . . over A, and let  be the relational structure with domain A and exactly those
r and contains
relations. By Proposition 37,  contains a relation that is not preserved by ei,
r Consider the set F of all polymorphisms of . By
all relations that are preserved by ei.
Theorem 32, all operations in F are locally generated by eri.
The set F does not contain eri, since this would contradict by Theorem 32 the fact
r Since F is locally closed, it follows
that  contains a relation that is not preserved by ei.
from Theorem 39 that all operations f P F are generated by e. But then the relation
tpx, y, zq | x  y  z _ x  y  zu is preserved by all operations in F (we have already seen
this relation in Example 5), and hence pp definable in  by Theorem 30. This relation has
an NP-complete CSP (Bodirsky & Kara, 2008). Let 1 be the reduct of  that contains
exactly the relations that appear in the pp definition of tpx, y, z q | x  y  z _ x  y  z u
in . Clearly, there are finitely many such relations; we denote the corresponding relation
symbols by  1   . By Lemma 29, CSPp1 q is NP-hard.
This establishes also the hardness of CSPpq: let 1 be the  1 -reduct of . We claim
that CSPp1 q and CSPp1 q are the same computational problem. We have to show that
a conjunction of atomic  1 -formulas  is satisfiable in 1 if and only if it is true in 1 .
Replacing each atomic  1 -formula in  by its quantifier-free definition, this follows from
Theorem 28.

7. Concluding Remarks
We have introduced the powerful set constraint language of EI set constraints, which in
particular contains all Horn-Horn set constraints and all previously studied tractable set
constraint languages. Constraint satisfaction problems over EI can be solved in polynomial
 even quadratic  time. Our tractability result is complemented by a complexity result
which shows that tractability of EI set constraints is best-possible within a large class of
set constraint languages.
755

fiBodirsky & Hils

We would also like to remark that there is an algorithm to test whether a given finite set
constraint language (where relations in the language are given by quantifier-free formulas
over the signature t\, [, c, 0, 1u) is contained in EI. This means that the so-called metaproblem for EI set constraints can be decided effectively.
Proposition 41. There is an algorithm to test whether a given quantifier-free formula over
the signature t\, [, c, 0, 1u defines a relation from EI.
Proof. It is clear that  can be effectively transformed into the normal form that is described
in Section 3, so we will from now on assume that  is a conjunction of outer clauses, and
that each atomic formula is of the form t  1 where t is in inner conjunctive normal form.
Let n be the number of variables of . We have to test that for any two n-tuples u1 , u2
of elements of P pNq that satisfy , the n-tuple eipu1 , u2 q satisfies  as well. Note that
whether or not a tuple satisfies  in S only depends on the Boolean algebra generated
by the entries of this tuple in S. Any Boolean algebra generated by n elements is of size
n
at most 22 ; therefore, there are finitely many cases to check. For each pair of Boolean
algebras with generating tuples u1 , u2 , we check whether eipu1 , u2 q satisfies  as follows. By
Lemma 11, eipu1 , u2 q satisfies an atomic formula t  1 if and only if for every inner clause
x1 \ 
   \ xk \ epy1q \    \ epy1q of t there exists an i  k such that ipu1, u
2 q satisfies
xi \ j y j  1. This in turn is true if and only if both u1 and u2 satisfy xi \ j y j  1.
The truth value of non-atomic formulas of the tuple eipu1 , u2 q can then be computed from
the truth value of the atomic formulas in the usual way.

Finally we would also like to remark that one can analogously obtain tractability for
the class of constraints where the inner clauses of the positive outer literals are dual Horn
(i.e., have at most one negative literal). All statements and proofs for the respective result
can be obtained by dualizing in the following formal sense: the dual of a relation R that is
definable over a Boolean algebra is the relation tcptq | t P Ru. The dual of a k-ary operation
f on the same domain is the operation px1 , . . . , xk q  cpf pcpx1 q, . . . , cpxk qqq. The proofs
then translate literally into proofs for the dualized versions of the statements.

Acknowledgments
An extended abstract of this article appeared in the proceedings of IJCAI11 (Bodirsky, Hils,
& Krimkevitch, 2011)3 . We want to thank Francois Bossiere who pointed out mistakes in
the conference version of the paper. One mistake concerned the reduction from the CSP
for languages from EI to satisfiability of Horn-Horn clauses; the other concerned a problem
in a previous proof of Theorem 26.
Manuel Bodirsky has received funding from the ERC under the European Communitys
Seventh Framework Programme (FP7/2007-2013 Grant Agreement no. 257039).
3. The third author of the conference version left the author team for the preparation of the journal version.

756

fiTractable Set Constraints

References
Aiken, A. (1994). Set constraints: Results, applications, and future directions. In Proceedings
of the Second Workshop on the Principles and Practice of Constraint Programming,
pp. 326335.
Baader, F. (2003). Least common subsumers and most specific concepts in a description logic
with existential restrictions and terminological cycles. In Proceedings of International
Joint Conferences on Artificial Intelligence (IJCAI), pp. 319324.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL envelope. In International Joint
Conferences on Artificial Intelligence (IJCAI), pp. 364369.
Barto, L., & Kozik, M. (2009). Constraint satisfaction problems of bounded width. In
Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS),
pp. 595603.
Bodirsky, M. (2012). Complexity classification in infinite-domain constraint satisfaction.
Memoire dhabilitation a diriger des recherches, Universite Diderot  Paris 7. Available
at arXiv:1201.0856.
Bodirsky, M., Chen, H., & Pinsker, M. (2010). The reducts of equality up to primitive
positive interdefinability. Journal of Symbolic Logic, 75 (4), 12491292.
Bodirsky, M., & Dalmau, V. (2012). Datalog and constraint satisfaction with infinite templates. To appear in the Journal on Computer and System Sciences. A preliminary
version appeared in the proceedings of the Symposium on Theoretical Aspects of
Computer Science (STACS05).
Bodirsky, M., Hils, M., & Krimkevitch, A. (2011). Tractable set constraints. In Proceedings
of International Joint Conferences on Artificial Intelligence (IJCAI), pp. 510515.
Bodirsky, M., Hils, M., & Martin, B. (2011). On the scope of the universal-algebraic approach to constraint satisfaction. To appear in Logical Methods in Computer Science (LMCS), 9099. Available at arXiv:0909.5097v3. An extended abstract that
announced some of the results appeared in the proceedings of Logic in Computer
Science (LICS10).
Bodirsky, M., & Kara, J. (2008). The complexity of equality constraint languages. Theory of
Computing Systems, 3 (2), 136158. A conference version appeared in the proceedings
of Computer Science Russia (CSR06).
Bodirsky, M., & Kara, J. (2009). The complexity of temporal constraint satisfaction problems. Journal of the ACM, 57 (2), 141. An extended abstract appeared in the
Proceedings of the Symposium on Theory of Computing (STOC08).
Bodirsky, M., & Kutz, M. (2007). Determining the consistency of partial tree descriptions.
Artificial Intelligence, 171, 185196.
Bodirsky, M., & Nesetril, J. (2006). Constraint satisfaction with countable homogeneous
templates. Journal of Logic and Computation, 16 (3), 359373.
Boole, G. (1847). An Investigation of the Laws of Thought. Walton, London. Reprinted by
Philisophical Library, New York, 1954.
757

fiBodirsky & Hils

Broxvall, M., Jonsson, P., & Renz, J. (2002). Disjunctions, independence, refinements.
Artificial Intelligence, 140 (1/2), 153173.
Bulatov, A. A. (2003). Tractable conservative constraint satisfaction problems. In Proceedings of the Symposium on Logic in Computer Science (LICS), pp. 321330, Ottawa,
Canada.
Bulatov, A. A. (2006). A dichotomy theorem for constraint satisfaction problems on a
3-element set. Journal of the ACM, 53 (1), 66120.
Bulatov, A. A., & Dalmau, V. (2006). A simple algorithm for Maltsev constraints. SIAM
Journal on Computing, 36 (1), 1627.
Bulatov, A. A., Krokhin, A. A., & Jeavons, P. G. (2005). Classifying the complexity of
constraints using finite algebras. SIAM Journal on Computing, 34, 720742.
Cohen, D., Jeavons, P., Jonsson, P., & Koubarakis, M. (2000). Building tractable disjunctive
constraints. Journal of the ACM, 47 (5), 826853.
Dowling, W. F., & Gallier, J. H. (1984). Linear-time algorithms for testing the satisfiability
of propositional Horn formulae. The Journal of Logic Programming, 1 (3), 267284.
Drakengren, T., & Jonsson, P. (1998). Reasoning about set constraints applied to tractable
inference in intuitionistic logic. Journal of Logic and Computation, 8 (6), 855875.
Garey, M., & Johnson, D. (1978). A guide to NP-completeness. CSLI Press, Stanford.
Hodges, W. (1993). Model theory. Cambridge University Press.
Idziak, P. M., Markovic, P., McKenzie, R., Valeriote, M., & Willard, R. (2010). Tractability
and learnability arising from algebras with few subpowers. SIAM Journal on Computing, 39 (7), 30233037.
Jonsson, P., & Backstrom, C. (1998). A unifying approach to temporal constraint reasoning.
Artificial Intelligence, 102 (1), 143155.
Jonsson, P., & Drakengren, T. (1997). A complete classification of tractability in RCC-5.
Journal of Artificial Intelligence Research, 6, 211221.
Koppelberg, S. (1989). Projective boolean algebras. In Handbook of Boolean Algebras,
Vol. 3, pp. 741773. North Holland, Amsterdam-New York-Oxford- Tokyo.
Koubarakis, M. (2001). Tractable disjunctions of linear constraints: Basic results and applications to temporal reasoning. Theoretical Computer Science, 266, 311339.
Krotzsch, M., Rudolph, S., & Hitzler, P. (2006). On the complexity of Horn description
logics. In OWL: Experiences and Directions Workshop.
Kuncak, V., Nguyen, H. H., & Rinard, M. C. (2006). Deciding boolean algebra with presburger arithmetic. Journal of Automatic Reasoning, 36 (3), 213239.
Kuncak, V., & Rinard, M. C. (2007). Towards efficient satisfiability checking for boolean
algebra with presburger arithmetic. In Proceedings of the International Conference
on automated deduction (CADE), pp. 215230.
Kusters, R., & Molitor, R. (2002). Approximating most specific concepts in description
logics with existential restrictions. AI Communications, 15 (1), 4759.
758

fiTractable Set Constraints

Lassez, J.-L., & McAloon, K. (1989). Independence of negative constraints. In International
Joint Conference on Theory and Practice of Software Development (TAPSOFT), Volume 1, pp. 1927.
Marriott, K., & Odersky, M. (1996). Negative Boolean constraints. Theoretical Computer
Science, 160 (1&2), 365380.
Schaefer, T. J. (1978). The complexity of satisfiability problems. In Proceedings of the
Symposium on Theory of Computing (STOC), pp. 216226.
Szendrei, A. (1986). Clones in universal algebra. Seminaire de Mathematiques Superieures.
Les Presses de lUniversite de Montreal.

759

fiJournal of Artificial Intelligence Research 45 (2012) 305-362

Submitted 4/12; published 10/12

A Tutorial on Dual Decomposition and Lagrangian Relaxation for
Inference in Natural Language Processing
Alexander M. Rush

SRUSH @ CSAIL . MIT. EDU

Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
Cambridge, MA 02139, USA

Michael Collins

MCOLLINS @ CS . COLUMBIA . EDU

Department of Computer Science
Columbia University
New York, NY 10027, USA

Abstract
Dual decomposition, and more generally Lagrangian relaxation, is a classical method for combinatorial optimization; it has recently been applied to several inference problems in natural language processing (NLP). This tutorial gives an overview of the technique. We describe example algorithms, describe formal guarantees for the method, and describe practical issues in implementing
the algorithms. While our examples are predominantly drawn from the NLP literature, the material
should be of general relevance to inference problems in machine learning. A central theme of this
tutorial is that Lagrangian relaxation is naturally applied in conjunction with a broad class of combinatorial algorithms, allowing inference in models that go significantly beyond previous work on
Lagrangian relaxation for inference in graphical models.

1. Introduction
In many problems in statistical natural language processing, the task is to map some input x (e.g., a
string) to some structured output y (e.g., a parse tree). This mapping is often defined as
y  = argmax h(y)

(1)

yY

where Y is a finite set of possible structures for the input x, and h : Y  R is a function that assigns
a score h(y) to each y in Y. For example, in part-of-speech tagging, x would be a sentence, and Y
would be the set of all possible tag sequences for x; in parsing, x would be a sentence and Y would
be the set of all parse trees for x; in machine translation, x would be a source-language sentence
and Y would be the set of all possible translations for x. The problem of finding y  is referred to
as the decoding problem. The size of Y typically grows exponentially with respect to the size of
the input x, making exhaustive search for y  intractable.
This paper gives an overview of decoding algorithms for NLP based on dual decomposition,
and more generally, Lagrangian relaxation. Dual decomposition leverages the observation that
many decoding problems can be decomposed into two or more sub-problems, together with linear
constraints that enforce some notion of agreement between solutions to the different problems.
The sub-problems are chosen such that they can be solved efficiently using exact combinatorial
c
2012
AI Access Foundation. All rights reserved.

fiRUSH & C OLLINS

algorithms. The agreement constraints are incorporated using Lagrange multipliers, and an iterative
algorithmfor example, a subgradient algorithmis used to minimize the resulting dual. Dual
decomposition algorithms have the following properties:
 They are typically simple and efficient. For example, subgradient algorithms involve two
steps at each iteration: first, each of the sub-problems is solved using a combinatorial algorithm; second, simple additive updates are made to the Lagrange multipliers.
 They have well-understood formal properties, in particular through connections to linear programming (LP) relaxations.
 In cases where the underlying LP relaxation is tight, they produce an exact solution to the
original decoding problem, with a certificate of optimality.1 In cases where the underlying LP
is not tight, heuristic methods can be used to derive a good solution; alternatively, constraints
can be added incrementally until the relaxation is tight, at which point an exact solution is
recovered.
Dual decomposition, where two or more combinatorial algorithms are used, is a special case of
Lagrangian relaxation (LR). It will be useful to also consider LR methods that make use of a single
combinatorial algorithm, together with a set of linear constraints that are again incorporated using
Lagrange multipliers. The use of a single combinatorial algorithm is qualitatively different from
dual decomposition approaches, although the techniques are very closely related.
Lagrangian relaxation has a long history in the combinatorial optimization literature, going back
to the seminal work of Held and Karp (1971), who derive a relaxation algorithm for the traveling
salesman problem. Initial work on Lagrangian relaxation/dual decomposition for decoding in statistical models focused on the MAP problem in Markov random fields (Komodakis, Paragios, &
Tziritas, 2007, 2011). More recently, decoding algorithms have been derived for several models
in statistical NLP, including models that combine a weighted context-free grammar (WCFG) with
a finite-state tagger (Rush, Sontag, Collins, & Jaakkola, 2010); models that combine a lexicalized
WCFG with a discriminative dependency parsing model (Rush et al., 2010); head-automata models
for non-projective dependency parsing (Koo, Rush, Collins, Jaakkola, & Sontag, 2010); alignment
models for statistical machine translation (DeNero & Macherey, 2011); models for event extraction
(Riedel & McCallum, 2011); models for combined CCG parsing and supertagging (Auli & Lopez,
2011); phrase-based models for statistical machine translation (Chang & Collins, 2011); syntaxbased models for statistical machine translation (Rush & Collins, 2011); models for semantic parsing (Das, Martins, & Smith, 2012); models for parsing and tagging that make use of document-level
constraints (Rush, Reichart, Collins, & Globerson, 2012); models for the coordination problem in
natural language parsing (Hanamoto, Matsuzaki, & Tsujii, 2012); and models based on the intersection of weighted automata (Paul & Eisner, 2012). We will give an overview of several of these
algorithms in this paper.
While our focus is on examples from natural language processing, the material in this tutorial
should be of general relevance to inference problems in machine learning. There is clear relevance
to the problem of inference in graphical models, as described for example by Komodakis et al.
(2007, 2011); however one central theme of this tutorial is that Lagrangian relaxation is naturally
1. A certificate of optimality is information that allows a proof of optimality of the solution to be constructed in polynomial time.

306

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

applied in conjunction with a much broader class of combinatorial algorithms than max-product
belief propagation, allowing inference in models that go significantly beyond graphical models.
The remainder of this paper is structured as follows. Section 2 describes related work. Section 3
gives a formal introduction to Lagrangian relaxation. Section 4 describes a dual decomposition
algorithm (from Rush et al., 2010) for decoding a model that combines a weighted context-free
grammar with a finite-state tagger. This algorithm will be used as a running example throughout
the paper. Section 5 describes formal properties of dual decomposition algorithms. Section 6 gives
further examples of algorithms, and section 7 describes practical issues. Section 8 gives an overview
of work on alternative optimization methods to the subgradient methods described in this tutorial.
Finally, section 9 describes the relationship to LP relaxations, and describes tightening methods.

2. Related Work
This tutorial draws on ideas from the fields of combinatorial optimization, machine learning, and
natural language processing. In this section, we give a summary of work from these fields that is
relevant to the methods we will describe.
2.1 Combinatorial Optimization
Lagrangian relaxation (LR) is a widely used method in combinatorial optimization, going back
to the seminal work of Held and Karp (1971) on the traveling salesman problem. See the work
of Lemarechal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte
and Vygen (2008) for background on combinatorial optimization. Decomposing linear and integer
linear programs is also a fundamental technique in the optimization community (Dantzig & Wolfe,
1960; Everett III, 1963). There is a very direct relationship between LR algorithms and linear
programming relaxations of combinatorial optimization problems; again, see the textbook of Korte
and Vygen.
2.2 Belief Propagation, and Linear Programming Relaxations for Inference in MRFs
There has been a large amount of research on the MAP inference problem in Markov random fields
(MRFs). For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988)
gives exact solutions. (Max-product BP is a form of dynamic programming, which is closely related to the Viterbi algorithm.) For general MRFs where the underlying graph may contain cycles,
the MAP problem is NP-hard: this has led researchers to consider a number of approximate inference algorithms. Early work considered loopy variants of max-product BP (see for example
Felzenszwalb & Huttenlocher, 2006, for the application of loopy max-product BP to problems in
computer vision); however, these methods are heuristic, lacking formal guarantees.
More recent work has considered methods based on linear programming (LP) relaxations of the
MAP problem. See the work of Yanover, Meltzer, and Weiss (2006), or section 1.6 of the work of
Sontag, Globerson, and Jaakkola (2010), for a description. Methods based on LP relaxations have
the benefit of stronger guarantees than loopy belief propagation. Inference is cast as an optimization
problem, for example the problem of minimizing a dual. Since the dual problem is convex, convergence results from convex optimization and linear programming can be leveraged directly. One
particularly appealing feature of these methods is that certificates of optimality can be given when
the exact solution to the MAP problem is found.
307

fiRUSH & C OLLINS

Komodakis et al. (2007, 2011) describe a dual decomposition method that provably optimizes
the dual of an LP relaxation of the MAP problem, using a subgradient method. This work is a
crucial reference for this tutorial. (Note that in addition, Johnson, Malioutov, & Willsky, 2007, also
describes LR methods for inference in MRFs.)
In this tutorial we focus on subgradient algorithms for optimization of the dual objective. See
section 8 for a discussion of alternative optimization approaches that have been developed within
the machine learning community.
2.3 Combinatorial Algorithms in Belief Propagation
A central idea in the algorithms we describe is the use of combinatorial algorithms other than maxproduct BP. This idea is closely related to earlier work on the use of combinatorial algorithms within
belief propagation, either for the MAP inference problem (Duchi, Tarlow, Elidan, & Koller, 2007),
or for computing marginals (Smith & Eisner, 2008). These methods generalize loopy BP in a way
that allows the use of combinatorial algorithms. Again, we argue that methods based on Lagrangian
relaxation are preferable to variants of loopy BP, as they have stronger formal guarantees.
2.4 Linear Programs for Decoding in Natural Language Processing
Dual decomposition and Lagrangian relaxation are closely related to integer linear programming
(ILP) approaches, and linear programming relaxations of ILP problems. Several authors have
used integer linear programming directly for solving challenging problems in NLP. Germann, Jahr,
Knight, Marcu, and Yamada (2001) use ILP to test the search error of a greedy phrase-based translation system on short sentences. Roth and Yih (2005) formulate a constrained sequence labeling
problem as an ILP and decode using a general-purpose solver. Lacoste-Julien, Taskar, Klein, and
Jordan (2006) describe a quadratic assignment problem for bilingual word alignment and then decode using an ILP solver. Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing
(2009) formulates higher-order non-projective dependency parsing as an ILP. Riedel and Clarke decode using an ILP method where constraints are added incrementally. Martins et al. solve an LP
relaxation and project to a valid dependency parse. Like many of these works, the method presented
in this tutorial begins with an ILP formulation of the decoding problem; however, instead of employing a general-purpose solver we aim to speed up decoding by using combinatorial algorithms
that exploit the underlying structure of the problem.

3. Lagrangian Relaxation and Dual Decomposition
This section first gives a formal description of Lagrangian relaxation, and then gives a description
of dual decomposition, an important special case of Lagrangian relaxation. The descriptions we
give are deliberately concise. The material in this section is not essential to the remainder of this
paper, and may be safely skipped by the reader, or returned to in a second reading. However the
descriptions here may be useful for those who would like to immediately see a formal treatment of
Lagrangian relaxation and dual decomposition. All of the algorithms in this paper are special cases
of the framework described in this section.
308

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

3.1 Lagrangian Relaxation
We assume that we have some finite set Y, which is a subset of Rd . The score associated with any
vector y  Y is
h(y) = y  

where  is also a vector in Rd . The decoding problem is to find

y  = argmax h(y) = argmax y  
yY

(2)

yY

Under these definitions, each structure y is represented as a d-dimensional vector, and the score
for a structure y is a linear function, namely y  . In practice, in structured prediction problems y is
very often a binary vector (i.e., y  {0, 1}d ) representing the set of parts2 present in the structure y.
The vector  then assigns a score to each part, and the definition h(y) = y   implies that the score
for y is a sum of scores for the parts it contains.
We will assume that the problem in Eq. 2 is computationally challenging. In some cases, it
might be an NP-hard problem. In other cases, it might be solvable in polynomial time, but with an
algorithm that is still too slow to be practical.
The first key step in Lagrangian relaxation will be to choose a finite set Y 0  Rd that has the
following properties:
 Y  Y 0 . Hence Y 0 contains all vectors found in Y, and in addition contains some vectors that
are not in Y.
 For any value of   Rd , we can easily find
argmax y  
yY 0

(Note that we have replaced Y in Eq. 2 with the larger set Y 0 .) By easily we mean that this
problem is significantly easier to solve than the problem in Eq. 2. For example, the problem
in Eq. 2 might be NP-hard, while the new problem is solvable in polynomial time; or both
problems might be solvable in polynomial time, but with the new problem having significantly
lower complexity.
 Finally, we assume that

Y = {y : y  Y 0 and Ay = b}

(3)

for some A  Rpd and b  Rp . The condition Ay = b specifies p linear constraints on y.
We will assume that the number of constraints, p, is polynomial in the size of the input.
The implication here is that the linear constraints Ay = b need to be added to the set Y 0 , but these
constraints considerably complicate the decoding problem. Instead of incorporating them as hard
constraints, we will deal with these constraints using Lagrangian relaxation.
2. For example, in context-free parsing each part might correspond to a tuple hA  B C, i, k, ji where A  B C is
a context-free rule, and i, k, j are integers specifying that non-terminal A spans words i . . . j in the input sentence,
non-terminal B spans words i . . . k, and non-terminal C spans words (k + 1) . . . j. In finite-state tagging with a
bigram tagging model each part might be a tuple hA, B, ii where A, B are tags, and i is an integer specifying that tag
B is seen at position i in the sentence, and that tag A is seen at position (i  1). See the work of Rush et al. (2010)
for a detailed treatment of both of these examples.

309

fiRUSH & C OLLINS

We introduce a vector of Lagrange multipliers, u  Rp . The Lagrangian is
L(u, y) = y   + u  (Ay  b)
This function combines the original objective function y  , with a second term that incorporates
the linear constraints and the Lagrange multipliers. The dual objective is
L(u) = max0 L(u, y)
yY

and the dual problem is to find
minp L(u)

uR

A common approachwhich will be used in all algorithms in this paperis to use a subgradient
algorithm to minimize the dual. We set the initial Lagrange multiplier values to be u(0) = 0. For
k = 1, 2, . . . we then perform the following steps:
y (k) = argmax L(u(k1) , y)

(4)

u(k) = u(k1)  k (Ay (k)  b)

(5)

yY 0

followed by
where k > 0 is the step size at the kth iteration. Thus at each iteration we first find a structure
y (k) , and then update the Lagrange multipliers, where the updates depend on y (k) .
A crucial point is that y (k) can be found efficiently, because




argmax L(u(k1) , y) = argmax y   + u(k1)  (Ay  b) = argmax y  0
yY 0

yY 0

yY 0

where 0 =  + A> u(k1) . Hence the Lagrange multiplier terms are easily incorporated into the
objective function.
We can now state the following theorem:
Theorem 1 The following properties hold for Lagrangian relaxation:
a). For any u  Rp , L(u)  maxyY h(y).
b). Under a suitable choice of the step sizes k (see section 5), limk L(u(k) ) = minu L(u).
c). Define yu = argmaxyY 0 L(u, y). If u such that Ayu = b, then yu = argmaxyY y   (i.e.,
yu is optimal).
In particular, in the subgradient algorithm described above, if for any k we have Ay (k) = b,
then y (k) = argmaxyY y  .
d). minu L(u) = maxQ   , where the set Q is defined below.

310

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Thus part (a) of the theorem states that the dual value provides an upper bound on the score for the
optimal solution, and part (b) states that the subgradient method successfully minimizes this upper
bound. Part (c) states that if we ever reach a solution y (k) that satisfies the linear constraints, then
we have solved the original optimization problem.
Part (d) of the theorem gives a direct connection between the Lagrangian relaxation method and
an LP relaxation of the problem in Eq. 2. We now define the set Q. First, define  to be the set of
all distributions over the set Y 0 :
0

 = { :   R|Y | ,

X
yY 0

y = 1, y 0  y  1}

The convex hull of Y 0 is then defined as
Conv(Y 0 ) = {  Rd :    s.t.  =

X

y y}

yY 0

Finally, define the set Q as follows:
Q = {y : y  Conv(Y 0 ) and Ay = b}
Note the similarity to Eq. 3: we have simply replaced Y 0 in Eq. 3 by the convex hull of Y 0 . Y 0 is a
subset of Conv(Y 0 ), and hence Y is a subset of Q. A consequence of the Minkowski-Weyl theorem
(Korte & Vygen, 2008, Thm. 3.31) is that Conv(Y 0 ) is a polytope (a bounded set that is specified by
an intersection of a finite number of half spaces), and Q is therefore also a polytope. The problem
max   
Q

is therefore a linear program, and is a relaxation of our original problem, maxyY y  .
Part (d) of theorem 1 is a direct consequence of duality in linear programming. It has the
following implications:
 By minimizing the dual L(u), we will recover the optimal value maxQ    of the LP
relaxation.
 If maxQ    = maxyY y   then we say that the LP relaxation is tight. In this case the
subgradient algorithm is guaranteed3 to find the solution to the original decoding problem,
y  = argmax    = argmax y  
Q

yY

 In cases where the LP relaxation is not tight, there are methods (e.g., see Nedic & Ozdaglar,
2009) that allow us to recover an approximate solution to the linear program,  = argmaxQ 
. Alternatively, methods can be used to tighten the relaxation until an exact solution is obtained.
3. Under the assumption that there is unique solution y  to the problem maxyY y  ; if the solution is not unique then
subtleties may arise.

311

fiRUSH & C OLLINS

3.2 Dual Decomposition
We now give a formal description of dual decomposition. As we will see, dual decomposition is
a special case of Lagrangian relaxation;4 however, it is important enough for the purposes of this
tutorial to warrant its own description. Again, this section is deliberately concise, and may be safely
skipped on a first reading.
We again assume that we have some finite set Y  Rd . Each vector y  Y has an associated
score
f (y) = y  (1)
0

where (1) is a vector in Rd . In addition, we assume a second finite set Z  Rd , with each vector
z  Z having an associated score
g(z) = z  (2)
The decoding problem is then to find
argmax y  (1) + z  (2)
yY,zZ

such that
Ay + Cz = b
0

where A  Rpd , C  Rpd , b  Rp .
Thus the decoding problem is to find the optimal pair of structures, under the linear constraints
specified by Ay + Cz = b. In practice, the linear constraints often specify agreement constraints
between y and z: that is, they specify that the two vectors are in some sense coherent.
For convenience, and to make the connection to Lagrangian relaxation clear, we will define the
following sets:
W = {(y, z) : y  Y, z  Z, Ay + Cz = b}

W 0 = {(y, z) : y  Y, z  Z}
It follows that our decoding problem is to find


argmax y  (1) + z  (2)



(6)

(y,z)W

Next, we make the following assumptions:
4. Strictly speaking, Lagrangian relaxation can also be viewed as a special case of dual decomposition: in the formulation of this section we can set Z = Y, (2) = 0, and Ci,j = 0 for all i, j, thus recovering the Lagrangian relaxation
problem from the previous section. In this sense Lagrangian relaxation and dual decomposition are equivalent (we
can transform any Lagrangian relaxation problem to a dual decomposition problem, and vice versa). However, in our
view dual decomposition is more naturally viewed as a special case of Lagrangian relaxation, in particular because
the methods described in this tutorial go back to the work of Held and Karp (1971) (see section 6.3), which makes
use of a single combinatorial algorithm. In addition, Lagrangian relaxation appears to be a more standard term in
the combinatorial optimization literature: for example the textbook of Korte and Vygen (2008) has a description of
Lagrangian relaxation but no mention of dual decomposition; there are several tutorials on Lagrangian relaxation
in the combinatorial optimization literature (e.g., see Lemarechal, 2001; Fisher, 1981), but we have found it more
difficult to find direct treatments of dual decompositon. Note however that recent work in the machine learning and
computer vision communities has often used the term dual decomposition (e.g., Sontag et al., 2010; Komodakis et al.,
2007, 2011).

312

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

 For any value of (1)  Rd , we can easily find argmaxyY y  (1) . Furthermore, for any
0
value of (2)  Rd , we can easily find argmaxzZ z  (2) . It follows that for any (1)  Rd ,
0
(2)  Rd , we can easily find
(y  , z  ) = argmax y  (1) + z  (2)

(7)

(y,z)W 0

by setting
y  = argmax y  (1) ,
yY

z  = argmax z  (2)
zZ

Note that Eq. 7 is closely related to the problem in Eq. 6, but with W replaced by W 0 (i.e., the
linear constraints Ay + Cz = b have been dropped). By easily we again mean that these
optimization problems are significantly easier to solve than our original problem in Eq. 6.
It should now be clear that the problem is a special case of the Lagrangian relaxation setting,
as described in the previous section. Our goal involves optimization of a linear objective, over the
finite set W, as given in Eq. 6; we can efficiently find the optimal value over a set W 0 such that W
is a subset of W 0 , and W 0 has dropped the linear constraints Ay + Cz = b.
The dual decomposition algorithm is then derived in a similar way to before. We introduce a
vector of Lagrange multipliers, u  Rp . The Lagrangian is now
L(u, y, z) = y  (1) + z  (2) + u  (Ay + Cz  b)
and the dual objective is
L(u) = max 0 L(u, y, z)
(y,z)W

A subgradient algorithm can again be used to find minuRp L(u). We initialize the Lagrange multipliers to u(0) = 0. For k = 1, 2, . . . we perform the following steps:
(y (k) , z (k) ) = argmax L(u(k1) , y, z)
(y,z)W 0

followed by
u(k) = u(k1)  k (Ay (k) + Cz (k)  b)
where each k > 0 is a stepsize.
Note that the solutions y (k) , z (k) at each iteration are found easily, because it is easily verified
that
!
(k1)

argmax L(u

, y, z) =

(y,z)W 0

argmax y  
yY

0(1)

, argmax z  

0(2)

,

zZ

where 0(1) = (1) + A> u(k1) and 0(2) = (2) + C > u(k1) . Thus the dual decomposes into two
easily solved maximization problems.
The formal properties for dual decomposition are very similar to those stated in theorem 1. In
particular, it can be shown that
minp L(u) = max   (1) +   (2)

uR

(,)Q

313

fiRUSH & C OLLINS

S
NP

VP

N

V

United

flies

NP
D

A

N

some

large

jet

Figure 1: An example parse tree.

where the set Q is defined as
Q = {(, ) : (, )  Conv(W 0 ) and A + C = d}
The problem
max   (1) +   (2)

(,)Q

is again a linear programming problem, and L(u) is the dual of this linear program.
The descriptions of Lagrangian relaxation and dual decomposition that we have given are at a
sufficient level of generality to include a very broad class of algorithms, including all those introduced in this paper. The remainder of this paper describes specific algorithms developed within this
framework, describes experimental results and practical issues that arise, and elaborates more on
the theory underlying these algorithms.
Note that in this section we have described the dual-decomposition approach with two components. The generalization to more than two components is relatively straightforward; for example
see the work of Komodakis et al. (2007, 2011), see also the work of Martins, Smith, Figueiredo, and
Aguiar (2011).

4. An Example: Integration of a Parser and a Finite-State Tagger
We next describe a dual decomposition algorithm for decoding under a model that combines a
weighted context-free grammar and a finite-state tagger. The classical approach for this problem
is to use a dynamic programming algorithm, based on the construction of Bar-Hillel, Perles, and
Shamir (1964) for the intersection of a context-free language and a finite-state language. The dual
decomposition algorithm has advantages over exhaustive dynamic programming, in terms of both
efficiency and simplicity. We will use this dual decomposition algorithm as a running example
throughout this tutorial.
We first give a formal definition of the problem, describe motivation for the problem, and describe the classical dynamic programming approach. We then describe the dual decomposition
algorithm.
314

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

4.1 Definition of the Problem
Consider the problem of mapping an input sentence x to a parse tree y. Define Y to be the set of all
parse trees for x. The parsing problem is to find
y  = argmax h(y)

(8)

yY

where h(y) is the score for any parse tree y  Y.
We consider the case where h(y) is the sum of two model scores: first, the score for y under a
weighted context-free grammar; and second, the score for the part-of-speech (POS) sequence in y
under a finite-state part-of-speech tagging model. More formally, we define h(y) to be
h(y) = f (y) + g(l(y))

(9)

where the functions f , g, and l are defined as follows:
1. f (y) is the score for y under a weighted context-free grammar (WCFG). A WCFG consists of
a context-free grammar with a set of rules G, and a scoring function  : G  R that assigns a
real-valued score to each rule in G. The score for an entire parse tree is the sum of scores for
the rules it contains. As an example, consider the parse tree shown in Figure 1; for this tree,
f (y) = (S  NP VP) + (NP  N) + (N  United)
+(VP  V NP) + . . .

We remain agnostic as to how the scores for individual context-free rules are defined. As one
example, in a probabilistic context-free grammar, we would define (  ) = log p( 
|). As a second example, in a conditional random field (CRF) (Lafferty, McCallum, &
Pereira, 2001) we would define (  ) = w  (  ) where w  Rq is a parameter
vector, and (  )  Rq is a feature vector representing the rule   .
2. l(y) is a function that maps a parse tree y to the sequence of part-of-speech tags in y. For the
parse tree in Figure 1, l(y) would be the sequence N V D A N.
3. g(z) is the score for the part-of-speech tag sequence z under an mth-order finite-state tagging
model. Under this model, if zi for i = 1 . . . n is the ith tag in z, then
g(z) =

n
X

(i, zim , zim+1 , . . . , zi )

i=1

where (i, zim , zim+1 , . . . , zi ) is the score for the sub-sequence of tags zim , zim+1 , . . . , zi
ending at position i in the sentence.5
We again remain agnostic as to how these  terms are defined. As one example, g(z) might
be the log-probability for z under a hidden Markov model, in which case
(i, zim . . . zi ) = log p(zi |zim . . . zi1 ) + log p(xi |zi )
5. We define zi for i  0 to be a special start POS symbol.

315

fiRUSH & C OLLINS

where xi is the ith word in the input sentence. As another example, under a CRF we would
have
(i, zim . . . zi ) = w  (x, i, zim . . . zi )
where w  Rq is a parameter vector, and (x, i, zim . . . zi ) is a feature-vector representation
of the sub-sequence of tags zim . . . zi ending at position i in the sentence x.
The motivation for this problem is as follows. The scoring function h(y) = f (y) + g(l(y))
combines information from both the parsing model and the tagging model. The two models capture
fundamentally different types of information: in particular, the part-of-speech tagger captures information about adjacent POS tags that will be missing under f (y). This information may improve
both parsing and tagging performance, in comparison to using f (y) alone.6
Under this definition of h(y), the conventional approach to finding y  in Eq. 8 is to construct
a new context-free grammar that introduces sensitivity to surface bigrams (Bar-Hillel et al., 1964).
Roughly speaking, in this approach (assuming a first-order tagging model) rules such as
VP  V NP
are replaced with rules such as
VPN,N  VN,V NPV,N

(10)

where each non-terminal (e.g., NP) is replaced with a non-terminal that tracks the preceding and last
POS tag relative to that non-terminal. For example, NPV,N represents a NP that dominates a sub-tree
whose preceding POS tag was V, and whose last POS tag is N. The weights on the new rules are just
context-free weights from f (y). Furthermore, rules such as
V  flies
are replaced with rules such as
VN,V  flies
The weights on these rules are the context-free weights from f (y) plus the bigram tag weights from
g(z), in this example for the bigram N V. A dynamic programming parsing algorithmfor example
the CKY algorithmcan then be used to find the highest scoring structure under the new grammar.
This approach is guaranteed to give an exact solution to the problem in Eq. 8; however it is
often very inefficient. We have greatly increased the size of the grammar by introducing the refined
non-terminals, and this leads to significantly slower parsing performance. As one example, consider
the case where the underlying grammar is a CFG in Chomsky-normal form, with G non-terminals,
and where we use a 2nd order (trigram) tagging model, with T possible part-of-speech tags. Define
n to be the length of the input sentence. Parsing with the grammar alone would take O(G3 n3 )
time, for example using the CKY algorithm. In contrast, the construction of Bar-Hillel et al. (1964)
6. We have assumed that it is sensible, in a theoretical and/or empirical sense, to take a sum of the scores f (y) and
g(l(y)). This might be the case, for example, if f (y) and g(z) are defined through structured prediction models (e.g.,
conditional random fields), and their parameters are estimated jointly using discriminative methods. If f (y) and g(z)
are log probabilities under a PCFG and HMM respectively, then from a strict probabilistic sense it does not make
sense to combine their scores in this way: however in practice this may work well; for example, this type of log-linear
combination of probabilistic models is widely used in approaches for statistical machine translation.

316

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

results in an algorithm with a run time of O(G3 T 6 n3 ).7 The addition of the tagging model leads
to a multiplicative factor of T 6 in the runtime of the parser, which is a very significant decrease
in efficiency (it is not uncommon for T to take values of say 5 or 50, giving values for T 6 larger
than 15, 000 or 15 million). In contrast, the dual decomposition algorithm which we describe next
takes O(k(G3 n3 + T 3 n)) time for this problem, where k is the number of iterations required for
convergence; in experiments, k is often a small number. This is a very significant improvement in
runtime over the Bar-Hillel et al. method.
4.2 The Dual Decomposition Algorithm
We now introduce an alternative formulation of the problem in Eq. 8, which will lead directly to the
dual decomposition algorithm. Define T to be the set of all POS tags. Assume the input sentence
has n words. For any parse tree y, for any position i  {1 . . . n}, for any tag t  T , we define
y(i, t) = 1 if parse tree y has tag t at position i, y(i, t) = 0 otherwise. Similarly, for any tag
sequence z, we define z(i, t) = 1 if the tag sequence has tag t at position i, 0 otherwise. As an
example, the following parse tree and tag sequence have y(4, A) = 1 and z(4, A) = 1:

S
NP
N

VP
V

United flies

NP
D

A

N

N

some large jet

V

United1 flies2

D

A

some3 large4

N
jet5

In addition, define Z to be the set of all possible POS tag sequences for the input sentence. We
then introduce the following optimization problem:
Optimization Problem 1 Find
argmax f (y) + g(z)

(11)

yY,zZ

such that for all i  {1 . . . n}, for all t  T , y(i, t) = z(i, t).
Thus we now find the best pair of structures y and z such that they share the same POS sequence.
We define (y  , z  ) to be the pair of structures that achieve the argmax in this problem. The crucial
7. To be precise, assume we have a finite-state automaton with Q states and a context-free chart with rule productions
hA  B C, i, k, ji for all A, B, C  G and 1  i < k < j  n as well as productions hA  wi , ii for all A  G
and i  {1 . . . n}. (Here we use wi to refer to the ith word in the sentence, and the set G to refer to the set of nonterminals in the grammar. It follows that G = |G|.) Applying the Bar-Hillel intersection gives new rule productions
hAs1 ,s3  Bs1 ,s2 Cs2 ,s3 , i, k, ji for s1 , s2 , s3  {1 . . . Q} as well as hAs,t  wi , ii for s, t  {1 . . . Q} where
(s, t) is a valid state transition in the FSA. After intersection, we can count the free variables to see that there are
O(G3 n3 Q3 ) rule productions, which implies that the CKY algorithm can find the best parse in O(G3 n3 Q3 ) time.
In the case of tagging, a 2nd-order tagging model can be represented as an FSA with |T |2 states, where each state
represents the previous two tags. After intersection, this yields an O(G3 n3 |T |6 ) time algorithm.

317

fiRUSH & C OLLINS

claim, which is easily verified, is that y  is also the argmax to the problem in Eq. 8. In this sense,
solving the new problem immediately leads to a solution to our original problem.
We then make the following two assumptions. Whether these assumptions are satisfied will
depend on the definitions of Y and f (y) (for assumption 1) and on the definitions of Z and g(z)
(for assumption 2). The assumptions hold when f (y) is a WCFG and g(z) is a finite-state tagger,
but more generally they may hold for other parsing and tagging models.
Assumption 1 Assume that we introduce variables u(i, t)  R for i  {1 . . . n}, and t  T . We
assume that for any value of these variables, we can find




argmax f (y) +
yY

X

u(i, t)y(i, t)

i,t

efficiently.
An example. Consider a WCFG where the grammar is in Chomsky normal form. The scoring
function is defined as
f (y) =

X
XY Z

c(y, X  Y Z)(X  Y Z) +

X
i,t

y(i, t)(t  wi )

where we write c(y, X  Y Z) to denote the number of times that rule X  Y Z is seen in the
parse tree y, and as before y(i, t) = 1 if word i has POS t, 0 otherwise (note that y(i, t) = 1 implies
that the rule t  wi is used in the parse tree). The highest scoring parse tree under f (y) can be
found efficiently, for example using the CKY parsing algorithm. We then have




argmax f (y) +
yY

X

u(i, t)y(i, t) =

i,t





argmax 
yY

X

XY Z

c(y, X  Y Z)(X  Y Z) +

X
i,t

y(i, t)((t  wi ) + u(i, t))

This argmax can again be found easily using the CKY algorithm, where the scores (t  wi ) are
simply replaced by new scores defined as 0 (t  wi ) = (t  wi ) + u(i, t).
Assumption 2 Assume that we introduce variables u(i, t)  R for i  {1 . . . n}, and t  T . We
assume that for any value of these variables, we can find




argmax g(z) 
zZ

X

u(i, t)z(i, t)

i,t

efficiently.
An example. Consider a 1st-order tagging model,
g(z) =

n
X

(i, zi1 , zi )

i=1

318

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Initialization: Set u(0) (i, t) = 0 for all i  {1 . . . n}, t  T
For k = 1 to K


P



P

y (k)  argmaxyY f (y) +
z (k)  argmaxzZ g(z) 



(k1) (i, t)y(i, t) [Parsing]
i,t u



(k1) (i, t)z(i, t) [Tagging]
i,t u

If y (k) (i, t) = z (k) (i, t) for all i, t Return (y (k) , z (k) )
Else u(k+1) (i, t)  u(k) (i, t)  k (y (k) (i, t)  z (k) (i, t))

Figure 2: The dual decomposition algorithm for integrated parsing and tagging. k for k = 1 . . . K
is the step size at the kth iteration.

Then




argmax g(z) 
zZ

X

u(i, t)z(i, t)

i,t



n
X
X
u(i, t)z(i, t)
= argmax  (i, zi1 , zi ) 
zZ

= argmax
zZ

i,t

i=1
n
X
0

 (i, zi1 , zi )

i=1

where
0 (i, zi1 , zi ) = (i, zi1 , zi )  u(i, zi )
This argmax can be found efficiently using the Viterbi algorithm, where we have new 0 terms that
incorporate the u(i, t) values.
Given these assumptions, the dual decomposition algorithm is shown in Figure 2. The algorithm
manipulates a vector of variables u = {u(i, t) : i  {1 . . . n}, t  T }. We will soon see that each
variable u(i, t) is a Lagrange multiplier enforcing the constraint y(i, t) = z(i, t) in our optimization
problem. At each iteration the algorithm finds hypotheses y (k) and z (k) ; under assumptions 1 and 2
this step is efficient. If the two structures have the same POS sequence (i.e., y (k) (i, t) = z (k) (i, t)
for all (i, t)) then the algorithm returns this solution. Otherwise, simple updates are made to the
u(i, t) variables, based on the y (k) (i, t) and z (k) (i, t) values.
In a moment well give an example run of the algorithm. First, though, we give an important
theorem:
Theorem 2 If at any iteration of the algorithm in Figure 2 we have y (k) (i, t) = z (k) (i, t) for all
(i, t), then (y (k) , z (k) ) is a solution to optimization problem 1.
319

fiRUSH & C OLLINS

This theorem is a direct consequence of theorem 5 of this paper.
Thus if we do reach agreement between y (k) and z (k) , then we are guaranteed to have an optimal
solution to the original problem. Later in this tutorial we will give empirical results for various NLP
problems showing how often, and how quickly, we reach agreement. We will also describe the
theory underlying convergence; theory underlying cases where the algorithm doesnt converge; and
methods that can be used to tighten the algorithm with the goal of achieving convergence.
Next, consider the efficiency of the algorithm. To be concrete, again consider the case where
f (y) is defined through a weighted CFG, and g(z) is defined through a finite-state tagger. Each
iteration of the algorithm requires decoding under each of these two models. If the number of
iterations k is relatively small, the algorithm can be much more efficient than using the construction
of Bar-Hillel et al. (1964). As discussed before, assuming a context-free grammar in Chomsky
normal form, and a trigram tagger with T tags, the CKY parsing algorithm takes O(G3 n3 ) time,
and the Viterbi algorithm for tagging takes O(T 3 n) time. Thus the total running time for the dual
decomposition algorithm is O(k(G3 n3 + T 3 n)) where k is the number of iterations required for
convergence. In contrast, the construction of Bar-Hillel et al. results in an algorithm with running
time of O(G3 T 6 n3 ). The dual decomposition algorithm results in an additive cost for incorporating
a tagger (a T 3 n term is added into the run time), whereas the construction of Bar-Hillel et al. results
in a much more expensive multiplicative cost (a T 6 term is multiplied into the run time). (Smith &
Eisner, 2008, makes a similar observation about additive versus multiplicative costs in the context
of belief propagation algorithms for dependency parsing.)
4.3 Relationship of the Approach to Section 3
It is easily verified that the approach we have described is an instance of the dual decomposition
framework described in section 3.2. The set Y is the set of all parses for the input sentence; the set
Z is the set of all POS sequences for the input sentence. Each parse tree y  Rd is represented as a
vector such that f (y) = y(1) for some (1)  Rd : there are a number of ways of representing parse
trees as vectors, see the work of Rush et al. (2010) for one example. Similarly, each tag sequence
0
0
z  Rd is represented as a vector such that g(z) = z  (2) for some (2)  Rd . The constraints
y(i, t) = z(i, t)
for all (i, t) can be encoded through linear constraints
Ay + Cz = b
for suitable choices of A, C, and b, assuming that the vectors y and z include components y(i, t)
and z(i, t) respectively.
4.4 An Example Run of the Algorithm
We now give an example run of the algorithm. For simplicity, we will assume that the step size k is
equal to 1 for all iterations k. We take the input sentence to be United flies some large jet. Initially,
the algorithm sets u(i, t) = 0 for all (i, t). For our example, decoding with these initial weights
leads to the two hypotheses
320

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

S
NP
A

N

VP
D

A

V

N

United flies some large jet

V

D

A

United1 flies2 some3 large4

N
jet5

These two structures have different POS tags at three positions, highlighted in red; thus the two
structures do not agree. We then update the u(i, t) variables based on these differences, giving new
values as follows:
u(1, A) = u(2, N ) = u(5, V ) = 1
u(1, N ) = u(2, V ) = u(5, N ) = 1
Any u(i, t) values not shown still have value 0. We now decode with these new u(i, t) values,
giving structures
S
VP

NP
N

V

United flies

NP
D

A

N

A

some large jet

N

D

A

United1 flies2 some3 large4

N
jet5

Again, differences between the structures are shown in red. We update the u(i, t) values to
obtain new values as follows:
u(5, N ) = 1
u(5, V ) = 1
with all other u(i, t) values being 0. (Note that the updates reset u(1, A), u(1, N ), u(2, N ) and
u(2, V ) back to zero.)
We decode again, with the new u(i, t) values; this time, the two structures are
321

fiRUSH & C OLLINS

100

% examples converged

80

60

40

20

0

50
<=

20
<=

10
<=

4
<=

3
<=

2
<=

1
<=

number of iterations

Figure 3: Convergence results from the work of Rush et al. (2010) for integration of a probabilistic
parser and a POS tagger, using dual decomposition. We show the percentage of examples
where an exact solution is returned by the algorithm, versus the number of iterations of
the algorithm.

S
NP
N

VP
V

United flies

NP
D

A

N

some large jet

N

V

D

A

United1 flies2 some3 large4

N
jet5

These two structures have identical sequences of POS tags, and the algorithm terminates, with
the guarantee that the solutions are optimal.
Rush et al. (2010) describe experiments using this algorithm to integrate the probabilistic parser
of Collins (1997) with the POS tagger of Toutanova, Klein, Manning, and Singer (2003). (In these
experiments the stepsize k is not held constant, but is instead set using the strategy described in
section 7.2 of this paper.) Figure 3 shows the percentage of cases where exact solutions are returned
(we have agreement between y (k) and z (k) ) versus the number of iterations of the algorithm. The
algorithm produces exact solutions on over 99% of all examples. On over 94% of the examples the
algorithm returns an exact solution in 10 iterations or fewer. So with these models at least, while
the dual decomposition algorithm is not guaranteed to give an exact solution, in this case it is very
successful at achieving this goal.
322

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

5. Formal Properties
We now give some formal properties of the algorithm described in the previous section. We first
describe three important theorems regarding the algorithm, and then describe connections between
the algorithm and subgradient optimization methods.
5.1 Three Theorems
Recall that the problem we are attempting to solve (optimization problem 1) is
argmax f (y) + g(z)
yY,zZ

such that for all i = 1 . . . n, t  T ,

y(i, t) = z(i, t)

The first step will be to introduce the Lagrangian for this problem. We introduce a Lagrange
multiplier u(i, t) for each equality constraint y(i, t) = z(i, t): we write u = {u(i, t) : i 
{1 . . . n}, t  T } to denote the vector of Lagrange mulipliers. Each Lagrange multiplier can take
any positive or negative value. The Lagrangian is
L(u, y, z) = f (y) + g(z) +

X
i,t

u(i, t) (y(i, t)  z(i, t))

(12)

Note that by grouping the terms that depend on y and z, we can rewrite the Lagrangian as




L(u, y, z) = f (y) +

X
i,t





u(i, t)y(i, t) + g(z) 

X

u(i, t)z(i, t)

i,t

Having defined the Lagrangian, the dual objective is
L(u) =

max L(u, y, z)

yY,zZ



= max f (y) +
yY


X
i,t



u(i, t)y(i, t) + max g(z) 
zZ


X

u(i, t)z(i, t)

i,t

Under assumptions 1 and 2 described above, the dual value L(u) for any value of u can be calculated
efficiently: we simply compute the two maxs, and sum them. Thus the dual decomposes in a very
convenient way into two efficiently solvable sub-problems.
Finally, the dual problem is to minimize the dual objective, that is, to find
min L(u)
u

We will see shortly that the algorithm in Figure 2 is a subgradient algorithm for minimizing the dual
objective.
Define (y  , z  ) to be the optimal solution to optimization problem 1. The first theorem is as
follows:
Theorem 3 For any value of u,
L(u)  f (y  ) + g(z  )
323

fiRUSH & C OLLINS

Hence L(u) provides an upper bound on the score of the optimal solution. The proof is simple:
Proof:
L(u) =

=

max L(u, y, z)

yY,zZ

(13)

max

L(u, y, z)

(14)

max

f (y) + g(z)

(15)

yY,zZ:y=z

yY,zZ:y=z



= f (y ) + g(z )

(16)

Here we use the shorthand y = z to state that y(i, t) = z(i, t) for all (i, t). Eq. 14 follows because
by adding the constraints y = z, we are optimizing over a smaller set of (y, z) pairs, and hence the
max cannot increase. Eq. 15 follows because if y = z, we have
X
i,t

u(i, t) (y(i, t)  z(i, t)) = 0

and hence L(u, y, z) = f (y) + g(z). Finally, Eq. 16 follows through the definition of y  and z  .
The property that L(u)  f (y  ) + g(z  ) for any value of u is often referred to as weak duality.
The value of inf u L(u)  f (y  )  g(z  ) is often referred to as the duality gap or the optimal duality
gap (see for example Boyd & Vandenberghe, 2004).
Note that obtaining an upper bound on f (y  ) + g(z  ) (providing that it is relatively tight) can
be a useful goal in itself. First, upper bounds of this form can be used as admissible heuristics for
search methods such as A* or branch-and-bound algorithms. Second, if we have some method that
generates a potential solution (y, z), we immediately obtain an upper bound on how far this solution
is from being optimal, because
(f (y  ) + g(z  ))  (f (y) + g(z))  L(u)  (f (y) + g(z))
Hence if L(u)  (f (y) + g(z)) is small, then (f (y  ) + g(z  ))  (f (y) + g(z)) must be small. See
section 7 for more discussion.
Our second theorem states that the algorithm in Figure 2 successfully converges to minu L(u).
Hence the algorithm successfully converges to the tightest possible upper bound given by the dual.
The theorem is as follows:
Theorem 4 Consider the algorithm in Figure 2. For any sequence 1 , 2 , 3 , . . . such that k > 0
for all k  1, and
lim k = 0 and

k


X

k=1

k = ,

we have
lim L(uk ) = min L(u)
u

k

Proof: See the work of Shor (1985). See also Appendix A.3.
Our algorithm is actually a subgradient method for minimizing L(u): we return to this point in
section 5.2. For now though, the important point is that our algorithm successfully minimizes L(u).
Our final theorem states that if we ever reach agreement during the algorithm in Figure 2, we
are guaranteed to have the optimal solution. We first need the following definitions:
324

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Definition 1 For any value of u, define




y (u) = argmax f (y) +
yY

and

X

u(i, t)y(i, t)

i,t





z (u) = argmax g(z) 
zZ

X

u(i, t)z(i, t)

i,t

The theorem is then:
Theorem 5 If u such that

y (u) (i, t) = z (u) (i, t)

for all i, t, then
f (y (u) ) + g(z (u) ) = f (y  ) + g(z  )
i.e., (y (u) , z (u) ) is optimal.
Proof: We have, by the definitions of y (u) and z (u) ,
L(u) = f (y (u) ) + g(z (u) ) +

X
i,t

= f (y

(u)

) + g(z

(u)

u(i, t)(y (u) (i, t)  z (u) (i, t))

)

where the second equality follows because y (u) (i, t) = z (u) (i, t) for all (i, t). But L(u)  f (y  ) +
g(z  ) for all values of u, hence
f (y (u) ) + g(z (u) )  f (y  ) + g(z  )
Because y  and z  are optimal, we also have
f (y (u) ) + g(z (u) )  f (y  ) + g(z  )
hence we must have
f (y (u) ) + g(z (u) ) = f (y  ) + g(z  )
Theorems 4 and 5 refer to quite different notions of convergence of the dual decomposition
algorithm. For the remainder of this tutorial, to avoid confusion, we will explicitly use the following
terms:
 d-convergence (short for dual convergence) will be used to refer to convergence of the dual
decomposition algorithm to the minimum dual value: that is, the property that limk L(u(k) ) =
minu L(u). By theorem 4, assuming appropriate step sizes in the algorithm, we always have
d-convergence.
 e-convergence (short for exact convergence) refers to convergence of the dual decomposition algorithm to a point where y(i, t) = z(i, t) for all (i, t). By theorem 5, if the dual
decomposition algorithm e-converges, then it is guaranteed to have provided the optimal solution. However, the algorithm is not guaranteed to e-converge.
325

fiRUSH & C OLLINS

5.2 Subgradients
The proof of d-convergence, as defined in theorem 4, relies on the fact that the algorithm in Figure 2
is a subgradient algorithm for minimizing the dual objective L(u). Subgradient algorithms are a
generalization of gradient-descent methods; they can be used to minimize convex functions that are
non-differentiable. This section describes how the algorithm in Figure 2 is derived as a subgradient
algorithm.
Recall that L(u) is defined as follows:
L(u) =

max L(u, y, z)

yY,zZ



= max f (y) +
yY




X
i,t

u(i, t)y(i, t) + max g(z) 
zZ


X

u(i, t)z(i, t)

i,t

and that our goal is to find minu L(u).
First, we note that L(u) has the following properties:
 L(u) is a convex function. That is, for any u(1)  Rd , u(2)  Rd ,   [0, 1],
L(u(1) + (1  )u(2) )  L(u(1) ) + (1  )L(u(2) )
(The proof is simple: see Appendix A.1.)
 L(u) is not differentiable. In fact, it is easily shown that it is a piecewise linear function.
The fact that L(u) is not differentiable means that we cannot use a gradient descent method to
minimize it. However, because it is nevertheless a convex function, we can instead use a subgradient
algorithm. The definition of a subgradient is as follows:
Definition 2 (Subgradient) A subgradient of a convex function L : Rd  R at u is a vector  (u)
such that for all v  Rd ,
L(v)  L(u) +  (u)  (v  u)
The subgradient  (u) is a tangent at the point u that gives a lower bound to L(u): in this sense
it is similar8 to the gradient for a convex but differentiable function.9 The key idea in subgradient
methods is to use subgradients in the same way that we would use gradients in gradient descent
methods. That is, we use updates of the form
u0 = u   (u)
where u is the current point in the search,  (u) is a subgradient at this point,  > 0 is a step size, and
u0 is the new point in the search. Under suitable conditions on the stepsizes  (e.g., see theorem 4),
these updates will successfully converge to the minimum of L(u).
8. More precisely, for a function L(u) that is convex and differentiable, then its gradient at any point u is a subgradient
at u.
9. It should be noted, however, that for a given point u, there may be more than one subgradient: this will occur, for
example, for a piecewise linear function at points where the gradient is not defined.

326

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

S(flies)
NP(United)

VP(flies)

N

V

United

flies

NP(jet)
D

A

N

some large jet

*0

United1 flies2

some3 large4

jet5

Figure 4: A lexicalized parse tree, and a dependency structure.
So how do we calculate the subgradient for L(u)? It turns out that it has a very convenient
form. As before (see definition 1), define y (u) and z (u) to be the argmaxs for the two maximization
problems in L(u). If we define the vector  (u) as
 (u) (i, t) = y (u) (i, t)  z (u) (i, t)
for all (i, t), then it can be shown that  (u) is a subgradient of L(u) at u. The updates in the
algorithm in Figure 2 take the form
u0 (i, t) = u(i, t)  (y (u) (i, t)  z (u) (i, t))
and hence correspond directly to subgradient updates.
See Appendix A.2 for a proof that the subgradients take this form, and Appendix A.3 for a proof
of convergence for the subgradient optimization method.

6. Other Examples
In this section we describe other examples of dual decomposition algorithms. Our first example,
also from the work of Rush et al. (2010), is a dual decomposition algorithm that combines two
parsing models. Our second example, from the work of Komodakis et al. (2007, 2011), is a dual
decomposition algorithm for inference in Markov random fields. Finally, we describe the algorithm
of Held and Karp (1971) for the traveling salesman problem, and the algorithm of Chang and Collins
(2011) for decoding of phrase-based translation models.
6.1 Combined Constituency and Dependency Parsing
Rush et al. (2010) describe an algorithm for finding the highest scoring lexicalized context-free
parse tree for an input sentence, under a combination of two models: a lexicalized probabilistic
context-free grammar, and a discriminative dependency parsing model.
Figure 4 shows an example of a lexicalized context-free tree. We take Y to be the set of all
lexicalized trees for the input sentence, and f (y) to be the score of the tree y under a lexicalized
parsing modelspecifically, f (y) is the log-probability of y under the model of Collins (1997).
Under this model, each lexicalized rule in y receives a score that is a log probability, and the log
probability of y is a sum of the log probabilities for the rules that it contains.
327

fiRUSH & C OLLINS

100

% examples converged

80

60

40

20

0

50
<=

20
<=

10
<=

4
<=

3
<=

2
<=

1
<=

number of iterations

Figure 5: Convergence results from the work of Rush et al. (2010) for integration of a lexicalized
probabilistic context-free grammar, and a discriminative dependency parsing model. We
show the percentage of examples where an exact solution is returned by the algorithm,
versus the number of iterations of the algorithm.

Our second model is a dependency parsing model. An example dependency parse is also shown
in Figure 4. The set of all possible dependency parses for the sentence is Z; each parse z receives
a score g(z) under the dependency parsing model. We use the discriminative dependency parsing
model of Koo, Carreras, and Collins (2008) (see also McDonald, 2006).
For any lexicalized parse tree y, there is a mapping to an underlying dependency structure l(y).
The decoding problem we consider is to find
argmax f (y) + g(l(y))

(17)

yY

The motivation for this problem is that it will allow us to inject information from the dependency
parsing model g(z) into the lexicalized parsing model of Collins (1997); Rush et al. (2010) show
that this gives significant improvements in parsing accuracy.
The problem can be again solved exactly using a dynamic programming approach, where a
dynamic program is created that is an intersection of the two models (there is a clear analogy to
the Bar-Hillel et al. (1964) method for construction of a dynamic program for the intersection of a
PCFG and an HMM). However this dynamic program is again relatively inefficient.
We develop a dual decomposition algorithm in a very similar way to before. For any dependency
(i, j) where i  {0 . . . n} is the head word (we use 0 to denote the root symbol) and j  {1 . . . n},
j 6= i, is the modifier, we define y(i, j) = 1 if y contains the dependency (i, j), and y(i, j) = 0
otherwise. We define similar variables z(i, j) for dependency structures. We can then reformulate
the problem in Eq. 17 as:
Optimization Problem 2 Find
argmax f (y) + g(z)
yY,zZ

such that for all (i, j), y(i, j) = z(i, j).
328

(18)

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

A Lagrangian is introduced for this problem, which is very similar to that in Eq. 12, and a
subgradient algorithm is used to minimize the resulting dual. We introduce Lagrange multipliers
u(i, j) for all dependencies (i, j), whose initial values are u(0) (i, j) = 0 for all i, j. At each iteration
of the algorithm we find




y (k) = argmax f (y) +
yY

X

u(k1) (i, j)y(i, j)

i,j

using a dynamic programming algorithm for lexicalized context-free parsing (a trivial modification
of the original algorithm for finding argmaxy f (y)). In addition we find




z (k) = argmax g(z) 
zZ

X

u(k1) (i, j)z(i, j)

i,j

using a dynamic programming algorithm for dependency parsing (again, this requires a trivial modification to an existing algorithm). If y (k) (i, j) = z (k) (i, j) for all (i, j) then the algorithm has
e-converged, and we are guaranteed to have a solution to optimization problem 2. Otherwise, we
perform subgradient updates
u(k) (i, j) = u(k1) (i, j)  k (y (k) (i, j)  z (k) (i, j))
for all (i, j), then go to the next iteration.
Rush et al. (2010) describe experiments with this algorithm. The method e-converges on over
99% of examples, with over 90% of examples e-converging in 10 iterations or less. Figure 5 shows
a histogram of the number of examples that have e-converged, versus the number of iterations of the
algorithm. The method gives significant gains in parsing accuracy over the model of Collins (1997),
and significant gains over a baseline method that simply forces the lexicalized CFG parser to have
the same dependency structure as the first-best output from the dependency parser.10
6.2 The MAP Problem for Pairwise Markov Random Fields
Markov random fields (MRFs), and more generally graphical models, are widely used in machine
learning and statistics. The MAP problem in MRFs the problem of finding the most likely setting
of the random variables in an MRFis an inference problem of central importance. In this section
we describe the dual decomposition algorithm from the work of Komodakis et al. (2007, 2011) for
finding the MAP solution in pairwise, binary, MRFs. Pairwise MRFs are limited to the case where
potential functions consider pairs of random variables, as opposed to larger subsets; however, the
generalization of the method to non-pairwise MRFs is straightforward.
A commonly used approach for the MAP problem in MRFs is to use loopy max-product belief propagation. The dual decomposition algorithm has advantages in terms of stronger formal
guarantees, as described in section 5.
10. Note that Klein and Manning (2002) describe a method for combination of a dependency parser with a constituent
based parser, where the score for an entire structure is again the sum of scores under two models. In this approach
an A* algorithm is developed, where admissible estimates within the A* method can be computed efficiently using
separate inference under the two models. There are interesting connections between the A* approach and the dual
decomposition algorithm described in this section.

329

fiRUSH & C OLLINS

The MAP problem is as follows. Assume we have a vector y of variables y1 , y2 , . . . , yn , where
each yi can take two possible values, 0 or 1 (the generalization to more than two possible values
for each variable is straightforward). There are 2n possible settings of these n variables. An MRF
assumes an underlying undirected graph (V, E), where V = {1 . . . n} is the set of vertices in the
graph, and E is a set of edges. The MAP problem is then to find
argmax h(y)

(19)

y{0,1}n

where
X

h(y) =

i,j (yi , yj )

{i,j}E

Here each i,j (yi , yj ) is a local potential associated with the edge {i, j}  E, which returns a real
value (positive or negative) for each of the four possible settings of (yi , yj ).
If the underlying graph E is a tree, the problem in Eq. 19 is easily solved using max-product
belief propagation, a form of dynamic programming. In contrast, for general graphs E, which may
contain loops, the problem is NP-hard. The key insight behind the dual decomposition algorithm
will be to decompose the graph E into m trees T1 , T2 , . . . , Tm . Inference over each tree can be
performed efficiently; we use Lagrange multipliers to enforce agreement between the inference
results for each tree. A subgradient algorithm is used, where at each iteration we first perform
inference over each of the trees T1 , T2 , . . . , Tm , and then update the Lagrange multipliers in cases
where there are disagreements.
For simplicity, we describe the case where m = 2. Assume that the two trees are such that
T1  E, T2  E, and T1  T2 = E.11 Thus each of the trees contains a subset of the edges in
(1)
E, but together the trees contain all edges in E. Assume that we define potential functions i,j for
(2)

(i, j)  T1 and i,j for (i, j)  T2 such that
X

i,j (yi , yj ) =

{i,j}E

(1)

X
{i,j}T1

(2)

X

i,j (yi , yj ) +

i,j (yi , yj )

{i,j}T2

This is easy to do: for example, define
m
i,j
(yi , yj ) =

i,j (yi , yj )
#(i, j)

for m = 1, 2 where #(i, j) is 2 if the edge {i, j} appears in both trees, 1 otherwise.
We can then define a new problem that is equivalent to the problem in Eq. 19:
Optimization Problem 3 Find
argmax

X

y{0,1}n ,z{0,1}n

{i,j}T1

(1)

i,j (yi , yj ) +

X

(2)

i,j (zi , zj )

{i,j}T2

such that yi = zi for i = 1 . . . n.
11. It may not always be possible to decompose a graph E into just 2 trees in this way. Komodakis et al. (2007, 2011)
describe an algorithm for the general case of more than 2 trees.

330

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Note the similarity to our previous optimization problems. Our goal is to find a pair of structures,
y  {0, 1}n and z  {0, 1}n . The objective function can be written as
f (y) + g(z)
where
(1)

X

f (y) =

i,j (yi , yj )

{i,j}T1

and
(2)

X

g(z) =

i,j (zi , zj )

{i,j}T2

We have a set of constraints, yi = zi for i = 1 . . . n, which enforce agreement between y and z.
We then proceed as beforewe define a Lagrangian with a Lagrange multiplier ui for each
constraint:
(1)

X

L(u, y, z) =

{i,j}T1

(2)

X

i,j (yi , yj ) +

i,j (zi , zj ) +

n
X
i=1

{i,j}T2

ui (yi  zi )

We then minimize the dual
L(u) = max L(u, y, z)
y,z

(0)

using a subgradient algorithm. The algorithm is initialized with ui
iteration of the algorithm we find

X

y (k) = argmax 
y{0,1}n

= 0 for i = 1 . . . n. At each


X
(k1) 
(1)
u
yi
 (yi , yj ) +
i

i,j

i

{i,j}T1

and


z (k) = argmax 
z{0,1}n

X

(2)
i,j (zi , zj )


X (k1)
u
zi 

i

i

{i,j}T2

These steps can be achieved efficiently, because T1 and T2 are trees, hence max-product belief propP (k1)
P (k1)
agation produces an exact answer. (The Lagrangian terms i ui
yi and i ui
zi are easily
(k)
(k)
incorporated.) If yi = zi for all i then the algorithm has e-converged, and we are guaranteed to
have a solution to optimization problem 3. Otherwise, we perform subgradient updates of the form
(k)

ui

(k1)

= ui

(k)

 k (yi

(k)

 zi )

for i = {1 . . . n}, then go to the next iteration. Intuitively, these updates will bias the two inference
problems towards agreement with each other.
Komodakis et al. (2007, 2011) show good experimental results for the method. The algorithm
has some parallels to max-product belief propagation, where the ui values can be interpreted as
messages being passed between sub-problems.
331

fiRUSH & C OLLINS

1

5

1

3

5

7
4

3

6

7
4

2

6

2

Figure 6: An illustration of the approach of Held and Karp (1971). On the left is a tour of the
vertices 1 . . . 7. On the right is a 1-tree over the vertices 1 . . . 7. A 1-tree consists of a tree
over vertices 2 . . . 7, together with 2 additional edges that include vertex 1. The tour on
the left is also a 1-tree (in fact every tour is also a 1-tree).

6.3 The Held and Karp Algorithm for TSPs
Our next example is the approach of Held and Karp (1971) for traveling salesman problems (TSPs),
which is notable for being the original paper on Lagrangian relaxation. This algorithm is not an
instance of dual decomposition. Instead of leveraging two or more combinatorial algorithms, in
combination with agreement constraints, it makes use of a single combinatorial algorithm, together
with a set of linear constraints that are again incorporated using Lagrange multipliers. While the use
of two or more combinatorial algorithms, as seen in dual decomposition, is a very useful technique,
broadening our scope to algorithms that make use of a single combinatorial algorithm will be very
useful. For NLP decoding algorithms that leverage a single combinatorial algorithm, see the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models (we describe
this algorithm in the next section), and the algorithm of Rush and Collins (2011) for decoding of
syntax-based translation models.
A TSP is defined as follows. We have an undirected graph (V, E) with vertices V = {1, 2, . . . , n},
and edges E. Each edge e  E has a score e  R. Any subset of the edges E can be represented
as a vector y = {ye : e  E}, where ye = 1 if the edge is in the subset, and ye = 0 otherwise. Thus
y is a vector in {0, 1}|E| . A tour of the graph is a subset of the edges that corresponds to a path
through the graph that begins and ends at the same vertex, and includes every other vertex exactly
once. See Figure 6 for an example of a tour. We use Y  {0, 1}|E| to denote the set of all possible
tours. The traveling salesman problem is to find
argmax

X

yY

eE

ye e

This problem is well-known to be NP-hard.12
A key idea in the work of Held and Karp (1971) is that of a 1-tree, which, like a tour, is a subset
of E. Held and Karp define a 1-tree as follows:
A 1-tree consists of a tree on the vertex set {2, 3, . . . , n}, together with two distinct
edges at vertex 1... Thus, a 1-tree has a single cycle, this cycle contains vertex 1, and
vertex 1 always has degree two.
12. In many presentations of the traveling salesman problem the goal is to find a minimum cost tour: for consistency with
the rest of this tutorial our presentation considers the maximization problem, which is equivalent.

332

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Figure 6 shows an example 1-tree. We define Y 0 to be the set of all possible 1-trees. It follows that
Y is a subset of Y 0 , because every tour is also a 1-tree.
Crucially, it is possible to find
X
argmax
ye e
yY 0

eE

using an efficient algorithm. In the first step, we find the maximum scoring spanning tree over
the vertices {2, 3, . . . , n}, using a maximum spanning tree algorithm. In the second step, we add
the two highest scoring edges that include vertex 1. It is simple to show that the resulting 1-tree is
optimal. Thus while search over the set Y is NP-hard, search over the larger set Y 0 can be performed
easily. The Lagrangian relaxation algorithm will explicitly leverage this observation.
Next, we note that
Y = {y : y  Y 0 , and for all i  {1, 2, . . . , n},

e:ie ye

P

= 2}

Each constraint of the form
X

ye = 2

(20)

e:ie

corresponds to the property that the ith vertex should have exactly two incident edges. Thus if we
add the constraint that each vertex has exactly two incident edges, we go from the set of 1-trees to
the set of tours. Constraints of the form in Eq. 20 are linear in the ye variables, and are therefore
easily incorporated into a Lagrangian.
Held and Karp introduce the following optimization problem:
Optimization Problem 4 Find
X

argmax
yY 0

such that for all i  {1, 2, . . . , n},

e:ie ye

P

ye e

eE

= 2.

It is clear that this is equivalent to finding the highest scoring tour in the graph.
As before, we deal with the equality constraints using Lagrange multipliers. Define the Lagrange multipliers to be a vector u = {ui : i  {1 . . . n}}. The Lagrangian is
L(u, y) =

X

ye e +

n
X

!

ui

e:ie

i=1

eE

X

ye  2

and the dual objective is
L(u) = max0 L(u, y)
yY

(0)

The subgradient algorithm takes the following form. Initially we set ui
At each iteration we find
y (k) = argmax
yY 0

X

ye e +

eE

n
X
(k1)

X

i=1

e:ie

ui

If the constraints are satisfied, i.e., if for all i
X

ye(k) = 2

e:ie

333

= 0 for i = 1 . . . n.

!!

ye  2

(21)

fiRUSH & C OLLINS

then the algorithm terminates, with a guarantee that the structure y (k) is the solution to optimization
problem 4. Otherwise, a subgradient step is used to modify the Lagrange multipliers. It can be
shown that the subgradient of L(u) at u is the vector g (u) defined as
g (u) (i) =

X
e:ie

ye(u)  2

where y (u) = argmaxyY 0 L(u, y). Thus the subgradient step is for all i  {1 . . . n},
!
(k)
ui

=

(k1)
ui

 k

X
e:ie

ye(k)  2

(22)

Note that the problem in Eq. 21 is easily solved. It is equivalent to finding
X

y (k) = argmax
yY 0

ye e0

eE

with modified edge weights e0 : for an edge e = {i, j}, we define
(k1)

e0 = e + ui

(k1)

+ uj

Hence the new edge weights incorporate the Lagrange multipliers for the two vertices in the edge.
The subgradient step in Eq. 22 has a clear intuition. For vertices with greater than 2 incident
edges in y (k) , the value of the Lagrange multiplier ui is decreased, which will have the effect of
penalising any edges including vertex i. Conversely, for vertices with fewer than 2 incident edges,
ui will increase, and edges including that vertex will be preferred. The algorithm manipulates the
ui values in an effort to enforce the constraints that each vertex has exactly two incident edges.
We note that there is a qualitative difference between this example and our previous algorithms.
Our previous algorithms had employed two sets of structures Y and Z, two optimization problems,
and equality constraints enforcing agreement between the two structures. The TSP relaxation instead involves a single set Y. The two approaches are closely related, however, and similar theorems
apply to the TSP method (the proofs are trivial modifications of the previous proofs). We have
L(u) 

X

ye e

eE

for all u, where y  is the optimal tour. Under appropriate step sizes for the subgradient algorithm,
we have
lim L(u(k) ) = min L(u)
u

k

y (k)

Finally, if we ever find a structure
that satisfies the linear constraints, then the algorithm has
e-converged, and we have a guaranteed solution to the traveling salesman problem.
6.4 Phrase-Based Translation
We next consider a Lagrangian relaxation algorithm, described in the work of Chang and Collins
(2011), for decoding of phrase-based translation models (Koehn, Och, & Marcu, 2003). The input
to a phrase-based translation model is a source-language sentence with n words, x = x1 . . . xn . The
output is a sentence in the target language. The examples in this section will use German as the
source language, and English as the target language. We will use the German sentence

334

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

wir mussen auch diese kritik ernst nehmen
as a running example.
A key component of a phrase-based translation model is a phrase-based lexicon, which pairs
sequences of words in the source language with sequences of words in the target language. For
example, lexical entries that are relevent to the German sentence shown above include
(wir mussen, we must)
(wir mussen auch, we must also)
(ernst, seriously)
and so on. Each phrase entry has an associated score, which can take any value in the reals.
We introduce the following notation. A phrase is a tuple (s, t, e), signifying that the subsequence xs . . . xt in the source language sentence can be translated as the target-language string e,
using an entry from the phrase-based lexicon. For example, the phrase (1, 2, we must) would specify that the sub-string x1 . . . x2 can be translated as we must. Each phrase p = (s, t, e) receives a
score (p)  R under the model. For a given phrase p, we will use s(p), t(p) and e(p) to refer to its
three components. We will use P to refer to the set of all possible phrases for the input sentence x.
A derivation y is then a finite sequence of phrases, p1 , p2 , . . . pL . The length L can be any
positive integer value. For any derivation y we use e(y) to refer to the underlying translation defined
by y, which is derived by concatenating the strings e(p1 ), e(p2 ), . . . e(pL ). For example, if
y = (1, 3, we must also), (7, 7, take), (4, 5, this criticism), (6, 6, seriously)

(23)

then
e(y) = we must also take this criticism seriously
The score for any derivation y is then defined as
h(y) = g(e(y)) +

X

(p)

py

where g(e(y)) is the score (log-probability) for e(y) under an n-gram language model.
The set Y of valid derivations is defined as follows. For any derivation y, we define y(i) for
i = 1 . . . n to be the number of times that source word i is translated in the derivation. More
formally,
X
y(i) =
[[s(p)  i  t(p)]]
py

where [[]] is 1 if the statement  is true, 0 otherwise. The set of valid derivations is then
Y = {y  P  : for i = 1 . . . n, y(i) = 1}
where P  is the set of finite length sequences of phrases. Thus for a derivation to be valid, each
source-language word must be translated exactly once. Under this definition, the derivation in Eq. 23
is valid. The decoding problem is then to find
y  = argmax h(y)
yY

335

(24)

fiRUSH & C OLLINS

This problem is known to be NP-hard. Some useful intuition is as follows. A dynamic programming
approach for this problem would need to keep track of a bit-string of length n specifying which of
the n source language words have or havent been translated at each point in the dynamic program.
There are 2n such bit-strings, resulting in the dynamic program having an exponential number of
states.
We now describe the Lagrangian relaxation algorithm. As before, the key idea will be to define
a set Y 0 such that Y is a subset of Y 0 , and such that
argmax h(y)

(25)

yY 0

can be found efficiently. We do this by defining
Y 0 = {y  P  :

Pn

i=1 y(i)

= n}

Thus derivations in Y 0 satisfy the weaker constraint that the total number of source words translated
is exactly n: we have dropped the y(i) = 1 constraints. As one example, the following derivation
is a member of Y 0 , but is not a member of Y:
y = (1, 3, we must also), (1, 2, we must), (3, 3, also), (6, 6, seriously)

(26)

In this case we have y(1) = y(2) = y(3) = 2, y(4) = y(5) = y(7) = 0, and y(6) = 1. Hence
some words are translated more than once, and some words are translated 0 times.
Under this definition of Y 0 , the problem in Eq. 25 can be solved efficiently, using dynamic
programming. In contrast to the dynamic program for Eq. 24, which keeps track of a bit-string of
length n, the new dynamic program merely needs to keep track of how many source language words
have been translated at each point in the search.
We proceed as follows. Note that
Y = {y : y  Y 0 , and for i = 1 . . . n, y(i) = 1}
We introduce a Lagrange multiplier u(i) for each constraint y(i) = 1. The Lagrangian is
L(u, y) = h(y) +

n
X
i=1

u(i) (y(i)  1)

The subgradient algorithm is as follows. Initially we set u(0) (i) = 0 for all i. At each iteration we
find
y (k) = argmax L(u(k1) , y)
(27)
yY 0

and perform the subgradient step
u(k) (i) = u(k1) (i)  k (y (k) (i)  1)

(28)

If at any point we have y (k) (i) = 1 for i = 1 . . . n, then we are guaranteed to have the optimal
solution to the original decoding problem.
336

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

The problem in Eq. 27 can be solved efficiently, because
argmax L(u(k1) , y)
yY 0



= argmax g(e(y)) +
yY 0

X

(p) +

py

n
X
i=1





u(k1) (i) (y(i)  1)



= argmax g(e(y)) +
yY 0

X

0 (p)

py

where
0 (p) = (p) +

t(p)
X

u(k1) (i)

i=s(p)

0 (p),

Thus we have new phrase scores,
which take into account the Lagrange multiplier values
for positions s(p) . . . t(p). The subgradient step in Eq. 28 has a clear intuition. For any source
language word i that is translated more than once, the associated Lagrange multiplier u(i) will
decrease, causing phrases including word i to be penalised at the next iteration. Conversely, any
word translated 0 times will have its Lagrange multiplier increase, causing phrases including that
word to be preferred at the next iteration. The subgradient method manipulates the u(i) values in
an attempt to force each source-language word to be translated exactly once.
The description we have given here is a sketch: Chang and Collins (2011) describe details of the
method, including a slightly more involved dynamic program that gives a tighter relaxation than the
method we have described here, and a tightening method that incrementally adds constraints when
the method does not initially e-converge. The method is successful in recovering exact solutions
under a phrase-based translation model, and is far more efficient than alternative approaches based
on general-purpose integer linear programming solvers.

7. Practical Issues
This section reviews various practical issues that arise with dual decomposition algorithms. We
describe diagnostics that can be used to track progress of the algorithm in minimizing the dual, and
in providing a primal solution; we describe methods for choosing the step sizes, k , in the algorithm;
and we describe heuristics that can be used in cases where the algorithm does not provide an exact
solution. We will continue to use the algorithm from section 4 as a running example, although our
observations are easily generalized to other Lagrangian relaxation algorithms.
The first thing to note is that each iteration of the algorithm produces a number of useful terms,
in particular:
 The solutions y (k) and z (k) .
 The current dual value L(u(k) ) (which is equal to L(u(k) , y (k) , z (k) ).
In addition, in cases where we have a function l : Y  Z that maps each structure y  Y to a
structure l(y)  Z, we also have
 A primal solution y (k) , l(y (k) ).
337

fiRUSH & C OLLINS

-13
-14

Value

-15
-16
-17
-18

Current Primal
Current Dual

-19
0

10

20

30
Round

40

50

60

Figure 7: Graph showing the dual value L(u(k) ) and primal value f (y (k) ) + g(l(y (k) )), versus
iteration number k, for the subgradient algorithm on a translation example from the work
of Rush and Collins (2011).

 A primal value f (y (k) ) + g(l(y (k) )).
By a primal solution we mean a pair (y, z) that satisfies all constraints in the optimization problem.
For example, in optimization problem 1 (the combined HMM and PCFG problem from section 4) a
primal solution has the properties that y  Y, z  Z, and y(i, t) = z(i, t) for all (i, t).
As one example, in the algorithm in Figure 2, at each iteration we produce a parse tree y (k) .
It is simple to recover the POS sequence l(y (k) ) from the parse tree, and to calculate the score
f (y (k) ) + g(l(y (k) )) under the combined model. Thus even if y (k) and z (k) disagree, we can still use
y (k) , l(y (k) ) as a potential primal solution. This ability to recover a primal solution from the value
y (k) does not always holdbut in cases where it does hold, it is very useful. It will allow us, for
example, to recover an approximate solution in cases where the algorithm hasnt e-converged to an
exact solution.
We now describe how the various items described above can be used in practical applications of
the algorithm.
7.1 An Example Run of the Algorithm
Figure 7 shows a run of the subgradient algorithm for the decoding approach for machine translation
described in the work of Rush and Collins (2011). The behavior is typical of cases where the
algorithm e-converges to an exact solution. We show the dual value L(u(k) ) at each iteration, and
the value for f (y (k) ) + g(l(y (k) )). A few important points are as follows:
 Because L(u) provides an upper bound on f (y  ) + g(z  ) for any value of u, we have
L(u(k) )  f (y (k) ) + g(l(y (k) ))
at every iteration.
 On this example we have e-convergence to an exact solution, at which point we have
L(u(k) ) = f (y (k) ) + g(z (k) ))
338

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

-13

4

Gap

3.5

-14

3
Value

Value

-15
-16

2.5
2
1.5

-17

1
-18

Best Primal
Best Dual

-19
0

10

20

30
Round

40

50

0.5
0
60

0

10

20

30
Round

40

50

60

Figure 8: The graph on the left shows the best dual value Lk and the best primal value pk , versus
iteration number k, for the subgradient algorithm on a translation example from the work
of Rush and Collins (2011). The graph on the right shows Lk  pk plotted against k.
with (y (k) , z (k) ) guaranteed to be optimal (and in addition, with z (k) = l(y (k) )).
 The dual values L(u(k) ) are not monotonically decreasingthat is, for some iterations we
have
L(u(k+1) ) > L(u(k) )
even though our goal is to minimize L(u). This is typical: subgradient algorithms are not in
general guaranteed to give monotonically decreasing dual values. However, we do see that
for most iterations the dual decreasesthis is again typical.
 Similarly, the primal value f (y (k) ) + g(z (k) ) fluctuates (goes up and down) during the course
of the algorithm.
The following quantities can be useful in tracking progress of the algorithm at the kth iteration:
 L(u(k) )  L(u(k1) ) is the change in the dual value from one iteration to the next. We will
soon see that this can be useful when choosing the step size for the algorithm (if this value is
positive, it may be an indication that the step size should decrease).
0

 Lk = mink0 k L(u(k ) ) is the best dual value found so far. It gives us the tightest upper bound
on f (y  ) + g(z  ) that we have after k iterations of the algorithm.
0

0

 pk = maxk0 k f (y (k ) ) + g(l(y (k ) )) is the best primal value found so far.
 Lk pk is the gap between the best dual and best primal solution found so far by the algorithm.
Because Lk  f (y  ) + g(z  )  pk , we have
Lk  pk  f (y  ) + g(z  )  pk

hence the value for Lk  pk gives us an upper bound on the difference between f (y  ) + g(z  )
and pk . If Lk  pk is small, we have a guarantee that we have a primal solution that is close
to being optimal.
Figure 8 shows a plot of Lk and pk versus the number of iterations k for our previous example, and in addition shows a plot of the gap Lk  pk . These graphs are, not surprisingly, much
smoother than the graph in Figure 7. In particular we are guaranteed that the values for Lk and pk
are monotonically decreasing and increasing respectively.
339

fiRUSH & C OLLINS

-13

0.01
0.005
0.0005

-13.5

Value

-14
-14.5
-15
-15.5
-16
0

5

10

15

20
Round

25

30

35

40

Figure 9: Graph showing the dual value L(u(k) ) versus the number of iterations k, for different
fixed step sizes.

7.2 Choice of the Step Sizes k
Figure 9 shows convergence of the algorithm for various choices of step size, where we have chosen
to keep the stepsize constant at each iteration. We immediately see a potential dilemma arising.
With too small a step size ( = 0.0005), convergence is smooththe dual value is monotonically
decreasingbut convergence is slow. With too large a step size ( = 0.01), convergence is much
faster in the initial phases of the algorithm, but the dual then fluctuates quite erratically. In practice
it is often very difficult to choose a constant step size that gives good convergence properties in both
early and late iterations of the algorithm.
Instead, we have found that we often find improved convergence properties with a choice of
step size k 
that decreases with increasing k. One possibility is to use a definition such as k = c/k
or k = c/ k where c > 0 is a constant. However these definitions can decrease the step size
too rapidlyin particular, they decrease the step size at all iterations, even in cases where progress
is being made in decreasing the dual value. In many cases we have found that a more effective
definition is
c
k =
t+1
where c > 0 is again a constant, and t < k is the number of iterations prior to k where the dual value
0
0
increases rather than decreases (i.e., the number of cases for k 0  k where L(u(k ) ) > L(u(k 1) )).
Under this definition the step size decreases only when the dual value moves in the wrong direction.
7.3 Recovering Approximate Solutions
Figure 10 shows a run of the algorithm where we fail to get e-convergence to an exact solution. In
section 9.4 we will describe one possible strategy, namely tightening the relaxation, which can be
used to produce an exact solution in these cases. Another obvious strategy, which is approximate,
is to simply choose the best primal solution generated after k iterations of the algorithm, for some
0
0
fixed k: i.e., to choose y (k ) , l(y (k ) ) where
0

0

k 0 = argmax f (y (k ) ) + g(l(y (k ) ))
k0 k

340

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

0
Best Primal
-5

Value

-10
-15
-20
-25

Current Primal
Current Dual

-30
0

10

20

30

40
Round

50

60

70

100

100

90

90
Percentage

Percentage

Figure 10: Graph showing the dual value L(u(k) ) and primal value f (y (k) ) + g(l(y (k) )), versus
iteration number k, for the subgradient algorithm on a translation example from the
work of Rush and Collins (2011), where the method does not e-converge to an exact
solution.

80
70
60

0

200
400
600
800
Maximum Number of Dual Decomposition Iterations

70
60

% validation UAS
% certificates
% match K=5000

50

80

f score
% certificates
% match K=50

50
1000

0

10
20
30
40
Maximum Number of Dual Decomposition Iterations

50

Figure 11: Figures showing effects of early stopping for the non-projective parsing algorithm of
Koo et al. (2010) (left graph) and combined constituency and dependency parsing (right
graph). In each case we plot three quantities versus the number of iterations, k: 1) the
accuracy (UAS or f-score); 2) the percentage of cases where the algorithm e-converges
giving an exact solution, with a certificate of optimality; 3) the percentage of cases where
the best primal solution up to the kth iteration is the same as running the algorithm to
e-convergence.

As described before, we can use Lk  pk as an upper bound on the difference between this approximate solution and the optimal solution.
7.4 Early Stopping
It is interesting to also consider the strategy of returning the best primal solution early in the algorithm in cases where the algorithm does eventually e-converge to an exact solution. In practice,
this strategy can sometimes produce a high quality solution, albeit without a certificate of optimality, faster than running the algorithm to e-convergence. Figure 11 shows graphs for two problems:
non-projective dependency parsing (Koo et al., 2010), and combined constituency and dependency
341

fiRUSH & C OLLINS

parsing (Rush et al., 2010). In each case we show how three quantities vary with the number of
iterations of the algorithm. The first quantity is the percentage of cases where the algorithm econverges, giving an exact solution, with a certificate of optimality. For combined constituency and
dependency parsing it takes roughly 50 iterations for most (over 95%) of cases to e-converge; the
second algorithm takes closer to 1000 iterations.
In addition, we show graphs indicating the quality of the best primal solution generated up to
iteration k of the algorithm, versus the number of iterations, k. An early stopping strategy would
be to pick some fixed value for k, and to simply return the best primal solution generated in the first k
iterations of the algorithm. We first plot the accuracy (f-score, or dependency accuracy respectively)
for the two models under early stopping: we can see that accuracy very quickly asymptotes to its
optimal value, suggesting that returning a primal solution before e-convergence can often yield high
quality solutions. We also plot the percentage of cases where the primal solution returned is in fact
identical to the primal solution returned when the algorithm is run to e-convergence. We again see
that this curve asymptotes quickly, showing that in many cases the early stopping strategy does in
fact produce the optimal solution, albeit without a certificate of optimality.

8. Alternatives to Subgradient Optimization
This tutorial has focused on subgradient methods for optimization of the dual objective. Several
alternative optimization algorithms have been proposed in the machine learning literature; in this
section we give an overview of these approaches.
Wainwright, Jaakkola, and Willsky (2005) describe an early and important algorithm for Markov
random fields (MRFs) based on LP relaxations, tree-reweighted message passing (TRW). Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and
TRW-T to refer to the tree-based algorithm. Kolmogorov (2006) derives a further variant, TRW-S
(the S refers to the sequential nature of the algorithm). All three algorithmsTRW-E, TRW-T,
and TRW-Sare motivated by the LP relaxation for MRFs, but none of them have a guarantee
of converging to the optimal value of the LP. TRW-S has the strongest guarantee of the three algorithms, namely that it monotonically improves the dual value, but it may not converge to the optimal
dual value.
Yanover et al. (2006) describe experiments comparing TRW-based algorithms to generic LP
solvers for MRF problems (specifically, the LP solver they use is CPLEX13 ). The TRW-based algorithms are considerably more efficient than CPLEX, due to the fact that the TRW-based methods
leverage the underlying structure of the MRF problem. The various Lagrangian relaxation algorithms described in the current paper can all be viewed as specialized algorithms for solving LP
relaxations, which explicitly leverage combinatorial structure within the underlying problem.
Komodakis et al. (2007, 2011) give experiments comparing the subgradient method to the TRWS and TRW-T algorithms. In these experiments TRW-S generally performs better than TRW-T. In
several cases TRW-S finds the optimal dual solution faster than the subgradient method; in other
cases TRW-S appears to get stuck (as expected given its lack of convergence guarantee), while the
subgradient method finds the global optimum. Overall, the subgradient method is competitive with
TRW-S: it may initially make slower progress on the dual objective, but has the benefit of guaranteed
convergence to the global optimum of the LP relaxation.
13. http://www.ilog.com/products/cplex/

342

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Another important class of algorithms for optimizing the dual of the LP are block coordinate
descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the
work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm
is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the
global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces
better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal
solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi
& Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals
for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower
to compute in practice, and for some combinatorial problems computation may be asymptotically
slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem
can be solved in O(n2 ) time where n is the length of the input sentence, but we are not aware of an
algorithm that solves the max-marginal problem in better than O(n4 ) time.)
In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the
method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method
has a relatively fast rate of convergence (O(1/) time to reach a solution that is -close to optimal).
Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required
compared to subgradient; however in the work of Martins et al. (2011) the accelerated method
requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes
more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLPs requirement of max-marginals.
Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using
the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu,
Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the
objective with a quadratic penalty term representing the amount of constraint violation. ADMM
is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find
the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a
comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate
sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been
proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor
graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of
the LP; Martins (2012) and Das et al. (2012) use an iterative active set method that utilizes MAP
solutions of the original sub-problems to solve the quadratic version. Martins (2012) also describes
recent results on ADMM that give a O(1/) bound for relaxed primal convergence.

9. The Relationship to Linear Programming Relaxations
This section describes the close relationship between the dual decomposition algorithm and linear
programming relaxations. This connection will be very useful in understanding the behavior of the
algorithm, and in particular in understanding the cases where the algorithm does not e-converge to
an exact solution. In addition, it will suggest strategies for tightening the algorithm until an exact
solution is found.
343

fiRUSH & C OLLINS

9.1 The Linear Programming Relaxation
We continue to use the algorithm from section 4 as an example; the generalization to other problems
is straightforward. First, define the set
y = { :   R|Y| ,

X
y

y = 1, y 0  y  1}

Thus y is a simplex, corresponding to the set of probability distributions over the finite set Y.
Similarly, define
X
z = { :   R|Z| ,
z = 1, z 0  z  1}
z

as the set of distributions over the set Z.
We now define a new optimization problem, as follows:
Optimization Problem 5 Find
max

y ,z

X

y f (y) +

y

X

z g(z)

(29)

z

such that for all i, t,
X

y y(i, t) =

y

X

z z(i, t)

(30)

z

This optimization problem is a linear program: the objective in Eq. 29 is linear in the variables
 and ; the constraints in Eq. 30, together with the constraints in the definitions of y and z , are
also linear in these variables.
This optimization problem is very similar to our original problem, optimization problem 1. To
see this, define 0y as follows:
0y = { :   R|Y| ,

X
y

y = 1, y y  {0, 1}}

Thus 0y is a subset of y , where the constraints 0  y  1 have been replaced by y  {0, 1}.
Define 0z similarly. Consider the following optimization problem, where we replace y and z in
Eq. 29 by 0y and 0z respectively:
Optimization Problem 6 Find
max
0

X

y ,0z y

y f (y) +

X

z g(z)

(31)

z

such that for all i, t,
X

y y(i, t) =

y

X
z

344

z z(i, t)

(32)

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

This new problem is equivalent to our original problem, optimization problem 1: choosing
vectors   0y and   0z is equivalent to choosing a single parse in Y, and a single POS
sequence in z. In this sense, optimization problem 5 is a relaxation of our original problem, where
constraints of the form y  {0, 1} and z  {0, 1} are replaced with constraints of the form
0  y  1 and 0  z  1.
Note that optimization problem 6 is an integer linear program, because the objective is again
linear in the  and  variables, and the constraints on these variables combine linear constraints
with integer constraints (that each y and z must be either 0 or 1). It is also worth noting that y
is actually the convex hull of the finite set 0y . The points in 0y form the vertices of the polytope
y .
A useful theorem, which is central to the relationship between linear programming and combinatorial optimization problems, is the following:
Theorem 6 For any finite set Y, and any function f : Y  R,
max f (y) = max
yY

y

X

y f (y)

yY

where y is as defined above.
The proof is simple, and is given in Appendix A.4.
9.2 The Dual of the New Optimization Problem
We now describe the dual problem for the linear program in Eqs. 29 and 30. This will again be a
function M (u) of a vector of dual variables u = {u(i, t) : i  {1 . . . n}, t  T }. A crucial result
will be that the two dual functions M (u) and L(u) are identical.
Our new Lagrangian is
!

M (u, , ) =

X

y f (y) +

y

=

X

X

z g(z) +

z

u(i, t)

X
y

i,t

y y(i, t) 

X

z z(i, t)

z



X
X
X

y y(i, t)
y f (y) +
u(i, t)
y

y

i,t



X
X
X
+  z g(z) 
u(i, t)
z z(i, t)
z

z

i,t

The new dual objective is
M (u) =

max

y ,z

M (u, , )

Note that once again we have simply maximized out over the primal ( and ) variables, ignoring
the constraints in Eq. 30. The dual problem is to find
min M (u)
u

Two theorems regarding the dual problem are then as follows:
345

fiRUSH & C OLLINS

Theorem 7 Define ( ,   ) to be the solution to the optimization problem in Eqs. 29 and 30. Then
min M (u) =

X

u

y f (y) +

y

X

z g(z)

z

Proof. This follows immediately by results from linear programming duality see the textbook
of Korte and Vygen (2008) for more details.
Note that we now have equality in the above, in contrast to our previous result,
min L(u)  f (y  ) + g(z  )
u

where the dual function only gave an upper bound on the best primal solution.
Our second theorem is as follows:
Theorem 8 For any value of u,
M (u) = L(u)

Thus the two dual functions are identical. Given that the subgradient algorithm we have described minimizes L(u), it therefore also minimizes the dual of the linear program in Eqs. 29 and 30.
Proof. We have
M (u) =



X
X
X
y y(i, t) +
u(i, t)
max  y f (y) +

y

y

y

i,t



X
X
X
z z(i, t)
u(i, t)
max  z g(z) 

z

z

z

i,t





= max f (y) +
yY

X

u(i, t)y(i, t) +

i,t





max g(z) 
zZ

X

u(i, t)z(i, t)

i,t

= L(u)
where we have used theorem 6 to give




X
X
X
X
u(i, t)y(i, t)
max  y f (y) +
u(i, t)
y y(i, t) = max f (y) +

y

y

i,t

yY

y

i,t

and we have used a similar result to replace the max over z by the max over Z.
346

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Y

y1

y2

y3

x

x

x

a

Z

a

b

b

c

c

He is

He is

He is

z1

z2

z3

a

b

b

a

c

c

He

is

He

is

He

is

Figure 12: A simple example with three possible parse trees and three possible POS sequences.

Y

Z

y1

y2

y3

x

x

x

a

a

b

b

c

Y

c

y1

y2

y3

x

x

x

a

a

b

b

c

c

He is

He is

He is

He is

He is

He is

z1

z2

z3

z1

z2

z3

a

b

b

a

c

c

He

is

He

is

He

is

Z

a

b

b

a

c

c

He

is

He

is

He

is

Figure 13: Illustration of two solutions that satisfy the constraints in Eq. 30. On the left, the solution
 = [0, 0, 1],  = [0, 0, 1] puts weight 1 on y3 and z3 . On the right, the fractional
solution  = [0.5, 0.5, 0] and  = [0.5, 0.5, 0] puts 0.5 weight on y1 /y2 and z1 /z2 .

347

fiRUSH & C OLLINS

9.3 An Example
We now give an example that illustrates these ideas. Through this example we will also illustrate
what happens when the algorithm fails to e-converge.
We assume that there are three possible parse trees, Y = {y1 , y2 , y3 }, and three possible tag
sequences, Z = {z1 , z2 , z3 }, shown in Figure 12. We will write distributions over these sets as
vectors such as  = [0, 0, 1] or  = [0.5, 0.5, 0].
Now consider pairs of vectors (, ) that satisfy the constraints in Eq. 30. Figure 13 illustrates
two possible solutions. One such pair, which we will denote as (1 ,  1 ), is 1 = [0, 0, 1],  1 =
[0, 0, 1]. It is easily verified that under this definition
X

y1 y(1, c) =

yY

X

z1 z(1, c) =

zY

X

y1 y(2, c) =

yY

X

z1 z(2, c) = 1

zY

with all other expected values being equal to 0: hence (1 ,  1 ) satisfies the constraints. This potential solution is integral, in that it puts weight 1 on a single parse tree/POS-tag sequence, with all
other structures having weight 0.
A second pair that satisfies the constraints is 2 = [0.5, 0.5, 0],  2 = [0.5, 0.5, 0]. Under these
definitions,
X

y2 y(1, a) =

X

z2 z(1, a) =

y2 y(1, b) =

X

z2 z(1, b) = 0.5

zY

yY

zY

yY

X

and
X
yY

y2 y(2, a) =

X

z2 z(2, a) =

X
yY

zY

y2 y(2, b) =

X

z2 z(2, b) = 0.5

zY

with all other expected values being equal to 0. The pair (2 ,  2 ) is a fractional solution, in that it
puts fractional (0.5) weight on some structures.
Next, consider different definitions for the functions f (y) and g(z). Consider first the definitions
f = [0, 0, 1] and g = [0, 0, 1] (we write f = [0, 0, 1] as shorthand for f (y1 ) = 0, f (y2 ) = 0,
f (y3 ) = 1). The solution to the problem in Eqs. 29 and 30 is then the pair (1 ,  1 ).
Alternatively, consider the definitions f = [1, 1, 2] and g = [1, 1, 2]. In this case the following
situation arises:
 The pair (1 ,  1 ) achieves score 0 under the objective in Eq. 29, whereas the pair (2 ,  2 )
achieves a score of 2. Thus the solution to the problem in Eqs. 29 and 30 is (2 ,  2 ), which is
a fractional solution.
 By theorem 7, minu M (u) is equal to the value for the optimal primal solution, i.e., minu M (u) =
2. Hence minu L(u) = 2.
 In contrast, the solution to the original optimization problem 1 is (y  , z  ) = (y3 , z3 ): in fact,
(y3 , z3 ) is the only pair of structures that satisfies the constraints y(i, t) = z(i, t) for all (i, t).
Thus f (y  ) + g(z  ) = 0. We have
min L(u) = 2 > f (y  ) + g(z  ) = 0
u

Thus there is a clear gap between the minimum dual value, and the score for the optimal
primal solution.
348

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

5

Dual

4
3
2
1
0
0

1

2

3

4

5

6

7

8

9

10

k
1
2
3
4
5
6
7
8
9

y (k)
y3
y2
y1
y1
y2
y1
y2
y1
y2

z (k)
z2
z1
z1
z1
z2
z1
z2
z1
z2

Round

Figure 14: Figures showing progress of the subgradient algorithm for f = [1, 1, 2] and g =
[1, 1, 2]. The graph shows the dual value L(u(k) ) versus number of iterations k. The
table shows the hypotheses y (k) and z (k) versus number of iterations k. In later iterations
the method alternates between hypotheses (y1 , z1 ) and (y2 , z2 ).

Figure 14 shows a trace of the subgradient method on this problem. After nine iterations the
method has reached L(u(9) ) = 2.06, which is close to the optimal dual value. In this case, however,
the algorithm does not reach agreement between the structures y (k) and z (k) . Instead, it reaches a
point where it alternates between solutions (y (1) , z (1) ), and (y (2) , z (2) ). Thus the dual d-converges to
its minimum value, but the primal solutions generated alternate between the structures y1 , y2 , z1 , z2
that have greater than 0 weight in the fractional solution (2 ,  2 ). This behavior is typical of cases
where there is a duality gap, i.e., where minu L(u) is strictly greater than f (y  ) + g(z  ).
9.4 Fixing E-Convergence: Tightening Approaches
We now describe a tightening approach that can be used to fix the issue of non-convergence given
in the previous example.
Consider again the problem of integrated CFG parsing and HMM tagging. Assume that the input
sentence is of length n. The first approach is as follows. We introduce new variables y(i, t1 , t2 ) for
i = 1 . . . (n  1), t1  T , t2  T , with y(i, t1 , t2 ) = 1 if y(i, t1 ) = 1 and y(i + 1, t2 ) = 1, 0
otherwise. Thus the new variables track tag bigrams. Similarly, we introduce variables z(i, t1 , t2 )
for tag sequences z  Z. We now define the set of constraints to be
y(i, t) = z(i, t)
for all i  {1 . . . n}, t  T (the same constraints as before), and in addition
y(i, t1 , t2 ) = z(i, t1 , t2 )
for all i  {1 . . . n  1}, t1  T , t2  T .
We then proceed as before, using Lagrange multipliers u(i, t) to enforce the first set of constraints, and Lagrange multipliers v(i, t1 , t2 ) to enforce the second set of constraints. The dual
349

fiRUSH & C OLLINS

decomposition algorithm will require us to find
y (k) = argmax f (y) +

X

yY

i,t

z (k) = argmax g(z) 

X

u(k1) (i, t)y(i, t) +

X

v (k1) (i, t1 , t2 )y(i, t1 , t2 )

(33)

v (k1) (i, t1 , t2 )z(i, t1 , t2 )

(34)

i,t1 ,t2

and
zZ

i,t

u(k1) (i, t)z(i, t) 

X
i,t1 ,t2

at each iteration, followed by updates of the form
u(k) (i, t)  u(k1) (i, t)  (y (k) (i, t)  z (k) (i, t))
and
v (k) (i, t1 , t2 )  v (k1) (i, t1 , t2 )  (y (k) (i, t1 , t2 )  z (k) (i, t1 , t2 ))
It can be shown that if g(z) is defined through a bigram HMM model, the above method is
guaranteed to e-converge to an exact solution. In fact, the underlying LP relaxation is now tight, in
that only integral solutions are possible.
The problem with this approach is that finding the argmax in Eq. 33 is now expensive, due to
the v(i, t1 , t2 )y(i, t1 , t2 ) terms: in fact, it requires the exact dynamic programming algorithm for
intersection of a bigram HMM with a PCFG. Thus we end up with an algorithm that is at least as
expensive as integration of a bigram HMM with a PCFG using the construction of Bar-Hillel et al.
(1964).14
A second approach, which may be more efficient, is as follows. Rather than introducing all
constraints of the form of Eq. 33, we might introduce a few selected constraints. As an example,
with the previous non-convergent example we might add the single constraint
y(1, a, b) = z(1, a, b)
We have a single Lagrange multiplier v(1, a, b) for this new constraint, and the dual decomposition
algorithm requires the following steps at each iteration:
y (k) = argmax f (y) +

X

yY

i,t

z (k) = argmax g(z) 

X

u(k1) (i, t)y(i, t) + v (k1) (1, a, b)y(1, a, b)

(35)

u(k1) (i, t)z(i, t)  v (k1) (1, a, b)z(1, a, b)

(36)

and
zZ

i,t

and updates
u(k) (i, t)  u(k1) (i, t)  (y (k) (i, t)  z (k) (i, t))
and
v (k) (1, a, b)  v (k1) (1, a, b)  (y (k) (1, a, b)  z (k) (1, a, b))
Figure 15 shows a run of the subgradient algorithm with this single constraint added. The
fractional solution (2 ,  2 ) is now eliminated, and the method e-converges to the correct solution.
Two natural questions arise:
14. If g(z) is defined through a bigram HMM, then clearly nothing has been gained in efficiency over the Bar-Hillel et al.
(1964) method. If g(z) is more complex, for example consisting of a trigram model, the dual decomposition method
may still be preferable.

350

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

5

Dual

4
3
2
1
0
7

8

9

10

11

12

13

14

15

16

k
7
8
9
10
11
12
13
14
15
16

y (k)
y3
y2
y1
y3
y2
y1
y3
y2
y1
y3

z (k)
z2
z3
z2
z1
z3
z2
z1
z3
z2
z3

Round

Figure 15: Figures showing progress of the subgradient algorithm for f (y) = [1, 1, 2] and g(z) =
[1, 1, 2], with the additional constraint y(1, a, b) = z(1, a, b) incorporated in the Lagrangian. The graph shows the dual value L(u(k) ) versus number of iterations k. The
table shows the hypotheses y (k) and z (k) versus number of iterations k.

 Which constraints should be added? One strategy is to first run the subgradient method with
the basic constraints, as shown in Figure 14. Some heuristic is used to determine that the
dual is no longer decreasing at a significant rate. At that point, it can be determined that
the algorithm is oscillating between solutions (y1 , z1 ) and (y2 , z2 ), and that the additional
constraint y(1, a, b) = z(1, a, b) would rule out these solutions; hence this constraint is added.
 When is this more efficient than adding all constraints in Eq. 33? Our toy example is too
simple to illustrate the benefit of only adding selected constraints. To understand the benefit,
consider the case where the sentence length n is reasonably large. In that case, we might
add bigram constraints at only a few positions in the sentence: in practice the CKY decoding
algorithm will only need to introduce the Bar-Hillel et al. (1964) machinery at these selected
points, which can be much more efficient that introducing all constraints.
For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008),
Rush and Collins (2011), Chang and Collins (2011), and Das et al. (2012). This is related to previous work on non-projective dependency parsing (Riedel & Clarke, 2006) that incrementally adds
constraints to an integer linear program solver.
9.5 Compact Linear Programs
The LP relaxations that we have described have a very large set of variables: that is, one variable
for each member of Y and Z. In most cases of interest, the sets Y and Z will be exponential in size.
In this section we describe how to derive equivalent linear programs with far fewer variables.
This is a problem of practical interest: for many problems, we have found it beneficial to implement
the underlying LP relaxation within a generic LP solver, as a way of debugging dual decomposition
351

fiRUSH & C OLLINS

algorithms. This is practical with the compact LPs that we describe in this section, but is clearly
impractical with the exponential-size linear programs described in the previous section.
First, consider the abstract description of Lagrangian relaxation given in section 3. The LP
relaxation was
argmax   
Q

where
Q = {y : y  Conv(Y 0 ) and Ay = b}

where A  Rpd and b  Rp . Recall that Conv(Y 0 ) is the convex hull of the set Y 0 . Next, assume
that Conv(Y 0 ) can itself be defined through a polynomial number of linear constraints: that is,
Conv(Y 0 ) = {y  Rd : Cy = e, y  0}

(37)

for some C  Rqd and e  Rq , where the number of constraints, q, is polynomial. In this case we
have an explicit characterization of the set Q as
Q = {y  Rd : Cy = e, y  0 and Ay = b}
Because d, p, and q are all polynomial in size, the resulting linear program is polynomial in size. In
this sense it is compact.
The remaining question is whether a characterization of the form of Eq. 37 exists, and if so, how
it is defined. Recall that we made the assumption that for any value of ,
argmax y  

(38)

yY 0

can be found using a combinatorial algorithm. For many combinatorial algorithms, there are LP
formulations that are polynomial in size: these formulations lead directly to definitions of C and
e.15 For example, Martin, Rardin, and Campbell (1990) give such a construction for dynamic programming algorithms, which includes parsing algorithms for weighted context-free grammars, the
Viterbi algorithm, and other dynamic programs used in NLP. Martins et al. (2009) make use of a
construction for directed spanning trees (see also Magnanti & Wolsey, 1994), and apply it to nonprojective dependency parsing. Korte and Vygen (2008) describe many other such constructions. In
short, given a combinatorial algorithm that solves the problem in Eq. 38, it is often straightforward
to find a recipe for constructing a pair (C, e) that completely characterizes Conv(Y 0 ).
It is straightforward to extend this idea to the LP for dual decomposition. Consider again our
running example, (optimization problem 1),
argmax f (y) + g(z)
yY,zZ

such that for all i = 1 . . . n, t  T ,

y(i, t) = z(i, t)

Rush et al. (2010) give a full description of the compact LP for this problem: we give a sketch here.
15. There is one subtlety here: in some cases additional auxilliary variables may need to be introduced. See for example the spanning tree construction of Magnanti and Wolsey (1994). However the number of auxilliary variables is
generally polynomial in number, hence this is benign.

352

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Define each y to be a vector in {0, 1}d that specifies which context-free rules y contains. It
follows that Y is a subset of {0, 1}d . We then have
f (y) = y  
where   Rd is a vector specifying the weight for each rule. Similarly, define z to be a vector in
0
{0, 1}d that specifies the trigrams that z contains (assuming that g(z) is a trigram tagging model).
0
It follows that Z is a subset of {0, 1}d . We can then write
g(z) = z  0
0

for some 0  Rd . The compact LP is then
argmax
   +   0
Conv(Y),Conv(Z)
such that for all i = 1 . . . n, t  T ,
0

(i, t) = (i, t)

Again, the existence of combinatorial algorithms for the problems argmaxyY y and argmaxzZ z
implies explicit representations
Conv(Y) = {  Rd : A = b,   0}

and

0

Conv(Z) = {  Rd : C = e,   0}
where A, b, C and e are polynomial in size. Rush et al. (2010) describe this construction in detail
for the case where a weighted CFG is combined with a finite-state tagger.
9.6 Summary
To summarize, the key points of this section were as follows:
 We introduced a linear programming problem that was a relaxation of our original problem.
The function L(u) was shown to be the dual of this linear programming relaxation.
 In cases where the optimal solution to the underlying LP is fractional, the subgradient method
will still d-converge to minu L(u). However the primal solutions (y (k) , z (k) ) will alternate
between different solutions that do not satisfy the y(i, t) = z(i, t) constraints.
 In practice, tightening methods can be used to improve convergence. These methods selectively introduce constraints in an effort to improve convergence of the method, with the cost
of increased complexity in finding y (k) and/or z (k) . The precise constraints to be added can be
chosen by identifying constraints that are frequently violated during the subgradient method.
 Finally, we described methods that construct a compact linear program that is equivalent to
the original LP relaxation. This linear program is often small enough to be solved by a generic
LP solver; this can be useful in debugging dual decomposition or Lagrangian relaxation algorithms.
353

fiRUSH & C OLLINS

10. Conclusions
A broad class of inference problems in statistical NLP and other areas of machine learning are
amenable to Lagrangian relaxation (LR) methods. LR methods make use of combinatorial algorithms in combination with linear constraints that are introduced using Lagrange multipliers: iterative methods are used to minimize the resulting dual objective. LR algorithms are simple and
efficient, typically involving repeated applications of the underlying combinatorial algorithm, in
conjunction with simple additive updates to the Lagrange multipliers. They have well-understood
formal properties: the dual objective is an upper bound on the score for the optimal primal solution;
there are close connections to linear programming relaxations; and crucially, they have the potential
of producing an exact solution to the original inference problem, with a certificate of optimality. Experiments on several NLP problems have shown the effectiveness of LR algorithms for inference:
LR methods are often considerably more efficient than existing exact methods, and have stronger
formal guarantees than the approximate search methods that are often used in practice.

Acknowledgments
We thank the anonymous reviewers for helpful comments. Tommi Jaakkola and David Sontag introduced us to dual decomposition and Lagrangian relaxation for inference in probabilistic models;
this work would not have happened without them. We have benefited from many discussions with
Yin-Wen Chang, Terry Koo, and Roi Reichart, who with Tommi and David were collaborators on
our work on dual decomposition/Lagrangian relaxation for NLP. We also thank Shay Cohen, Yoav
Goldberg, Mark Johnson, Andre Martins, Ryan McDonald, and Slav Petrov for feedback on earlier
drafts of this paper. Columbia University gratefully acknowledges the support of the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-C-0181. Alexander Rush was supported by a
National Science Foundation Graduate Research Fellowship.

Appendix A. Proofs
In this section we derive various results for the combined parsing and tagging problem. Recall that
in this case the Lagrangian is defined as
L(u, y, z) = f (y) + g(z) +

X
i{1...n},tT

u(i, t)(y(i, t)  z(i, t))

and that the dual objective is L(u) = maxyY,zZ L(u, y, z). Here n is the number of words in the
sentence, and T is a finite set of part-of-speech tags.
We first prove that L(u) is a convex function; we then derive the expression for subgradients
of L(u); we then give a convergence theorem for the algorithm in Figure 2, which is a subgradient
algorithm for minimization of L(u).
Finally, we give a proof of theorem 6.
A.1 Proof of Convexity of L(u)
The theorem is as follows:
354

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Theorem 9 L(u) is convex. That is, for any u(1)  Rd , u(2)  Rd ,   [0, 1],
L(u(1) + (1  )u(2) )  L(u(1) ) + (1  )L(u(2) )
Proof: Define
(y  , z  ) = arg max L(u , y, z)
yY,zZ

where u = u(1) + (1  )u(2) . It follows that
L(u ) = L(u , y  , z  )
In addition, note that
L(u(1) , y  , z  )  max L(u(1) , y, z) = L(u(1) )
yY,zZ

and similarly
L(u(2) , y  , z  )  L(u(2) )
from which it follows that
L(u(1) , y  , z  ) + (1  )L(u(2) , y  , z  )  L(u(1) ) + (1  )L(u(2) )
Finally, it is easy to show that
L(u(1) , y  , z  ) + (1  )L(u(2) , y  , z  ) = L(u , y  , z  ) = L(u )
hence
L(u )  L(u(1) ) + (1  )L(u(2) )
which is the desired result.
A.2 Subgradients of L(u)
For any value of u  Rd , as before define
(y (u) , z (u) ) = argmax L(u, y, z)
yY,zZ

or equivalently,




y (u) = argmax f (y) +

X

yY

and

u(i, t)y(i, t)

i,t





z (u) = argmax g(z) 

X

zZ

u(i, t)z(i, t)

i,t

Then if we define  (u) as the vector with components
 (u) (i, t) = y (u) (i, t)  z (u) (i, t)
355

fiRUSH & C OLLINS

for i  {1 . . . n}, t  T , then  (u) is a subgradient of L(u) at u.
This result is a special case of the following theorem:16
Theorem 10 Define the function L : Rd  R as
L(u) = max (ai  u + bi )
i{1...m}

where ai  Rd and bi  R for i  {1 . . . m}. Then for any value of u, if
j = argmax (ai  u + bi )
i{1...m}

then aj is a subgradient of L(u) at u.
Proof: For aj to be a subgradient at the point u, we need to show that for all v  Rd ,
L(v)  L(u) + aj  (v  u)
Equivalently, we need to show that for all v  Rd ,
max (ai  v + bi )  max (ai  u + bi ) + aj  (v  u)

i{1...m}

i{1...m}

(39)

To show this, first note that
aj  u + bj = max (ai  u + bi )
i{1...m}

hence
max (ai  u + bi ) + aj  (v  u) = bj + aj  v  max (ai  v + bi )

i{1...m}

i{1...m}

thus proving the theorem.
A.3 Convergence Proof for the Subgradient Method
Consider a convex function L : Rd  R, which has a minimizer u (i.e., u = argminuRd L(u)).
The subgradient method is an iterative method which initializes u to some value u(0)  Rd , then
sets
u(k+1) = u(k)  k gk
for k = 0, 1, 2, . . ., where k > 0 is the stepsize at the kth iteration, and gk is a subgradient at u(k) :
that is, for all v  Rd ,
L(v)  L(u(k) ) + gk  (v  u(k) )
The following theorem will then be very useful in proving convergence of the method (the
theorem and proof is taken from Boyd & Mutapcic, 2007):
16. To be specific, our definition of L(u) can be written in the form maxi{1...m} (ai  u + bi ) as follows. Define the
integer m to be |Y|  |Z|. Define (y (i) , z (i) ) for i  {1 . . . m} to be a list of all possible pairs (y, z) such that y  Y
and z  Z. Define bi = f (y (i) ) + g(z (i) ), and ai to be the vector with components ai (l, t) = y (i) (l, t)  z (i) (l, t)
for l  {1 . . . n}, t  T . Then it can be verifed that L(u) = maxi{1...m} (ai  u + bi ).

356

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Theorem 11 Assume that for all k, ||gk ||2  G2 where G is some constant. Then for any k  0,
||u(0)  u ||2 + G2
min L(u )  L(u ) +
P
i{0...k}
2 ki=0 i


(i)

Pk

2
i=0 i

Proof: First, given the updates u(k+1) = u(k)  k gk , we have for all k  0,
||u(k+1)  u ||2 = ||u(k)  k gk  u ||2

= ||u(k)  u ||2  2k gk  (u(k)  u ) + k2 ||gk ||2

By the subgradient property,
L(u )  L(u(k) ) + gk  (u  u(k) )
hence
gk  (u(k)  u )  L(u )  L(u(k) )

Using this inequality, together with ||gk ||2  G2 , gives





||u(k+1)  u ||2  ||u(k)  u ||2 + 2k L(u )  L(u(k) ) + k2 G2

Taking a sum over both sides of i = 0 . . . k gives
k
X
i=0

k
X

||u(i+1)  u ||2 

i=0

||u(i)  u ||2 + 2

k
X
i=0



k
X



i L(u )  L(u(i) ) +

i2 G2

i=0

and hence
||u(k+1)  u ||2  ||u(0)  u ||2 + 2
Finally, using

||u(k+1)
k
X
i=0




u ||2

 0 and



(i)



i L(u )  L(u ) 

k
X
i=0

k
X





i L(u )  L(u(i) ) +

k
X
i=0

!

i

i=0

i2 G2

!


(i)

L(u )  min L(u )
i{0...k}

gives
(0)

0  ||u

 2

 u || + 2

k
X

!

i

i=0

!


(i)

L(u )  min L(u ) +
i{0...k}

k
X

i2 G2

i=0

Rearranging terms gives the result in the theorem.
This theorem has a number of consequences. As one example, for a constant step-size, k = h
for some h > 0,
!
P
||u(0)  u ||2 + G2 ki=1 i2
Gh
lim
=
Pk
k
2
2 i=1 i
hence in the limit the value for
min L(u(i) )
i{1...k}

is within Gh/2 of the optimal solution. A slightly more involved argument shows that under the
P
assumptions that k > 0, limk k = 0, and 
k=0 k = ,
lim

k

||u(0)  u ||2 + G2
P
2 ki=1 i

See Boyd and Mutapcic for the full derivation.
357

Pk

2
i=1 i

!

=0

fiRUSH & C OLLINS

A.4 Proof of Theorem 6
Recall that our goal is to prove that
X

max f (y) = max
yY

y

y f (y)

yY

We will show this by proving: (1) maxyY f (y)  maxy yY y f (y), and (2) maxyY f (y) 
P
maxy yY y f (y).
First, consider case (1). Define y  to be a member of Y such that
P

f (y  ) = max f (y)
yY

Next, define y = 1, and y = 0 for y 6= y  . Then we have
X

y f (y) = f (y  )

yY

Hence we have found a setting for the  variables such that
X

y f (y) = max f (y)
yY

yY

from which it follows that
max

y

X
yY

y f (y)  max f (y)
yY

Next, consider case (2). Define  to be a setting of the  variables such that
X

y f (y) = max

X

y

y

y f (y)

yY

Next, define y  to be a member of Y such that
f (y  ) = max
f (y)

y:y >0

It is easily verified that
f (y  ) 

X

y f (y)

y

Hence we have found a y   Y such that
f (y  )  max

y

X

y f (y)

y

from which it follows that
max f (y)  max
yY

y

358

X
y

y f (y)

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

References
Auli, M., & Lopez, A. (2011). A comparison of loopy belief propagation and dual decomposition
for integrated ccg supertagging and parsing. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Human Language Technologies, pp. 470480,
Portland, Oregon, USA. Association for Computational Linguistics.
Bar-Hillel, Y., Perles, M., & Shamir, E. (1964). On formal properties of simple phrase structure
grammars. In Language and Information: Selected Essays on their Theory and Application,
pp. 116150.
Boyd, S., Parikh, N., Chu, E., Peleato, B., & Eckstein, J. (2011). Distributed optimization and
statistical learning via the alternating direction method of multipliers. Now Publishers.
Boyd, S., & Vandenberghe, L. (2004). Convex optimization. Cambridge Univ Pr.
Boyd, S., & Mutapcic, A. (2007). Subgradient Methods. Course Notes for EE364b, Stanford
University, Winter 2006-07.
Chang, Y., & Collins, M. (2011). Exact Decoding of Phrase-based Translation Models through
Lagrangian Relaxation. In To appear proc. of EMNLP.
Collins, M. (1997). Three Generative, Lexicalised Models for Statistical Parsing. In Proc. ACL, pp.
1623.
Dantzig, G., & Wolfe, P. (1960). Decomposition principle for linear programs. In Operations
research, Vol. 8, pp. 101111.
Das, D., Martins, A., & Smith, N. (2012). An exact dual decomposition algorithm for shallow
semantic parsing with constraints. Proceedings of* SEM.[ii, 10, 50].
DeNero, J., & Macherey, K. (2011). Model-Based Aligner Combination Using Dual Decomposition. In Proc. ACL.
Duchi, J., Tarlow, D., Elidan, G., & Koller, D. (2007). Using combinatorial optimization within maxproduct belief propagation. In Advances in Neural Information Processing Systems (NIPS).
Everett III, H. (1963). Generalized lagrange multiplier method for solving problems of optimum
allocation of resources. Operations Research, 399417.
Felzenszwalb, P., & Huttenlocher, D. (2006). Efficient belief propagation for early vision. International journal of computer vision, 70(1), 4154.
Fisher, M. L. (1981). The lagrangian relaxation method for solving integer programming problems.
Management Science, 27(1), pp. 118.
Germann, U., Jahr, M., Knight, K., Marcu, D., & Yamada, K. (2001). Fast decoding and optimal
decoding for machine translation. In Proceedings of the 39th Annual Meeting on Association
for Computational Linguistics, pp. 228235. Association for Computational Linguistics.
Globerson, A., & Jaakkola, T. (2007). Fixing max-product: Convergent message passing algorithms
for map lp-relaxations. In NIPS.
Hanamoto, A., Matsuzaki, T., & Tsujii, J. (2012). Coordination structure analysis using dual decomposition. In Proceedings of the 13th Conference of the European Chapter of the Association
for Computational Linguistics, pp. 430438, Avignon, France. Association for Computational
Linguistics.
359

fiRUSH & C OLLINS

Held, M., & Karp, R. M. (1971). The traveling-salesman problem and minimum spanning trees:
Part ii. Mathematical Programming, 1, 625. 10.1007/BF01584070.
Johnson, J., Malioutov, D., & Willsky, A. (2007). Lagrangian relaxation for map estimation in
graphical models. In 45th Annual Allerton Conference on Communication, Control and Computing.
Jojic, V., Gould, S., & Koller, D. (2010). Fast and smooth: Accelerated dual decomposition for
MAP inference. In Proceedings of International Conference on Machine Learning (ICML).
Klein, D., & Manning, C. (2002). Fast exact inference with a factored model for natural language
parsing. Advances in neural information processing systems, 15(2002).
Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. In Proceedings of
the 2003 Conference of the North American Chapter of the Association for Computational
Linguistic s on Human Language Technology, NAACL 03, pp. 4854.
Kolmogorov, V. (2006). Convergent tree-reweighted message passing for energy minimization.
Pattern Analysis and Machine Intelligence, IEEE Transactions on, 28(10), 15681583.
Komodakis, N., Paragios, N., & Tziritas, G. (2007). MRF Optimization via Dual Decomposition:
Message-Passing Revisited. In Proc. ICCV.
Komodakis, N., Paragios, N., & Tziritas, G. (2011). Mrf energy minimization and beyond via dual
decomposition. Pattern Analysis and Machine Intelligence, IEEE Transactions on, pp. 11.
Koo, T., Carreras, X., & Collins, M. (2008). Simple semi-supervised dependency parsing. In Proc.
ACL/HLT.
Koo, T., Rush, A. M., Collins, M., Jaakkola, T., & Sontag, D. (2010). Dual decomposition for
parsing with non-projective head automata. In EMNLP.
Korte, B., & Vygen, J. (2008). Combinatorial Optimization: Theory and Algorithms. Springer
Verlag.
Lacoste-Julien, S., Taskar, B., Klein, D., & Jordan, M. (2006). Word alignment via quadratic assignment. In Proceedings of the main conference on Human Language Technology Conference of
the North American Chapter of the Association of Computational Linguistics, pp. 112119.
Association for Computational Linguistics.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional Random Fields: Probabilistic Models
for Segmenting and Labeling Sequence Data. In Proc. ICML, pp. 282289.
Lemarechal, C. (2001). Lagrangian Relaxation. In Computational Combinatorial Optimization, Optimal or Provably Near-Optimal Solutions [based on a Spring School], pp. 112156, London,
UK. Springer-Verlag.
Magnanti, T. L., & Wolsey, L. A. (1994). Optimal trees. Tech. rep. 290-94, Massachusetts Institute
of Technology, Operations Research Center.
Martin, R., Rardin, R., & Campbell, B. (1990). Polyhedral characterization of discrete dynamic
programming. Operations research, 38(1), 127138.
Martins, A. (2012). The Geometry of Constrained Structured Prediction: Applications to Inference
and Learning of Natural Language Syntax. Ph.D. thesis.
360

fiA T UTORIAL ON D UAL D ECOMPOSITION FOR NATURAL L ANGUAGE P ROCESSING

Martins, A., Figueiredo, M., Aguiar, P., Smith, N., & Xing, E. (2011). An augmented lagrangian
approach to constrained map inference. In International Conference on Machine Learning.
Martins, A., Smith, N., & Xing, E. (2009). Concise Integer Linear Programming Formulations for
Dependency Parsing. In Proc. ACL, pp. 342350.
Martins, A., Smith, N., Figueiredo, M., & Aguiar, P. (2011). Dual decomposition with many overlapping components. In Proceedings of the 2011 Conference on Empirical Methods in Natural
Language Processing, pp. 238249, Edinburgh, Scotland, UK. Association for Computational
Linguistics.
McDonald, R. (2006). Discriminative Training and Spanning Tree Algorithms for Dependency
Parsing. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA, USA.
Meshi, O., & Globerson, A. (2011). An alternating direction method for dual map lp relaxation.
Machine Learning and Knowledge Discovery in Databases, 470483.
Nedic, A., & Ozdaglar, A. (2009). Approximate primal solutions and rate analysis for dual subgradient methods. SIAM Journal on Optimization, 19(4), 17571780.
Nesterov, Y. (2005). Smooth minimization of non-smooth functions. Mathematical Programming,
103(1), 127152.
Paul, M. J., & Eisner, J. (2012). Implicitly intersecting weighted automata using dual decomposition. In Proc. NAACL.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference
(2nd edition). Morgan Kaufmann Publishers.
Riedel, S., & Clarke, J. (2006). Incremental integer linear programming for non-projective dependency parsing. In Proceedings of the 2006 Conference on Empirical Methods in Natural
Language Processing, pp. 129137. Association for Computational Linguistics.
Riedel, S., & McCallum, A. (2011). Fast and robust joint models for biomedical event extraction. In
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,
pp. 112, Edinburgh, Scotland, UK. Association for Computational Linguistics.
Roth, D., & Yih, W. (2005). Integer linear programming inference for conditional random fields. In
Proceedings of the 22nd international conference on Machine learning, pp. 736743. ACM.
Rush, A., Reichart, R., Collins, M., & Globerson, A. (2012). Improved parsing and pos tagging
using inter-sentence consistency constraints. In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Processing and Computational Natural Language
Learning, pp. 14341444, Jeju Island, Korea. Association for Computational Linguistics.
Rush, A., & Collins, M. (2011). Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation. In Proc. ACL.
Rush, A., Sontag, D., Collins, M., & Jaakkola, T. (2010). On Dual Decomposition and Linear
Programming Relaxations for Natural Language Processing. In Proc. EMNLP.
Shor, N. Z. (1985). Minimization Methods for Non-differentiable Functions. Springer Series in
Computational Mathematics. Springer.
Smith, D., & Eisner, J. (2008). Dependency parsing by belief propagation. In Proc. EMNLP, pp.
145156.
361

fiRUSH & C OLLINS

Sontag, D., Globerson, A., & Jaakkola, T. (2010). Introduction to dual decomposition for inference.
In Sra, S., Nowozin, S., & Wright, S. J. (Eds.), Optimization for Machine Learning. MIT
Press.
Sontag, D., Meltzer, T., Globerson, A., Jaakkola, T., & Weiss, Y. (2008). Tightening LP relaxations
for MAP using message passing. In Proc. UAI.
Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). Feature-rich part-of-speech tagging
with a cyclic dependency network. In HLT-NAACL.
Wainwright, M., Jaakkola, T., & Willsky, A. (2005). MAP estimation via agreement on trees:
message-passing and linear programming.. In IEEE Transactions on Information Theory,
Vol. 51, pp. 36973717.
Yanover, C., Meltzer, T., & Weiss, Y. (2006). Linear Programming Relaxations and Belief
PropagationAn Empirical Study. In The Journal of Machine Learning Research, Vol. 7,
p. 1907. MIT Press.

362

fiJournal of Artificial Intelligence Research 45 (2012) 79-124

Submitted 03/12; published 09/12

An Approximative Inference Method for Solving SO
Satisfiability Problems
Hanne Vlaeminck
Joost Vennekens
Marc Denecker
Maurice Bruynooghe

hanne.vlaeminck@cs.kuleuven.be
joost.vennekens@cs.kuleuven.be
marc.denecker@cs.kuleuven.be
maurice.bruynooghe@cs.kuleuven.be

Department of Computer Science,
Celestijnenlaan 200a
3001 Heverlee, Belgium

Abstract
This paper considers the fragment SO of second-order logic. Many interesting problems, such as conformant planning, can be naturally expressed as finite domain satisfiability problems of this logic. Such satisfiability problems are computationally hard (P
2 ) and
many of these problems are often solved approximately. In this paper, we develop a general
approximative method, i.e., a sound but incomplete method, for solving SO satisfiability
problems. We use a syntactic representation of a constraint propagation method for firstorder logic to transform such an SO satisfiability problem to an SO(ID) satisfiability
problem (second-order logic, extended with inductive definitions). The finite domain satisfiability problem for the latter language is in NP and can be handled by several existing
solvers. Inductive definitions are a powerful knowledge representation tool, and this motivates us to also approximate SO(ID) problems. In order to do this, we first show how
to perform propagation on such inductive definitions. Next, we use this to approximate
SO(ID) satisfiability problems. All this provides a general theoretical framework for a
number of approximative methods in the literature. Moreover, we also show how we can
use this framework for solving practical useful problems, such as conformant planning, in
an effective way.

1. Introduction
Finite model generation is a logical paradigm for solving constraint problems. A successful
instance is the field of SAT, where efficient solvers for the low level CNF language are developed. Other instances, but for more expressive languages, are Answer Set Programming
(ASP) (Baral, 2003) and model expansion (MX) for (extensions of) first order logic. In ASP,
e.g., finite Herbrand models of an answer set program are computed (Baral, 2003). Model
expansion (MX) (Mitchell & Ternovska, 2005) generalizes Herbrand model generation and
aims at computing one or more models of a theory T that expand a finite interpretation I0
for a (possibly empty) subset of symbols of T . MX for first order logic (MX(FO)) is formally
equivalent to the finite domain satisfiability checking problem for existential second-order
logic (SAT (SO))1 which is known from Fagins celebrated theorem to capture NP (Fagin,
1974). That is, the problems in NP are exactly those that are in a precise sense equivalent
to an SO satisfiability problem, and hence an MX(FO) problem. A range of solvers exists
1. Or more specifically, to the search problem for a witness of such a problem.
c
2012
AI Access Foundation. All rights reserved.

fiVlaeminck, Vennekens, Denecker & Bruynooghe

for finite model generation, e.g., an overview of state-of-the-art ASP and MX(FO()) solvers
(here, FO() refers to the family of extensions of FO) can be found in the reports of the
ASP competition (e.g., Denecker, Vennekens, Bond, Gebser, & Truszczynski, 2009).
Example 1.1. Here is a bounded planning problem modeled as a Finite Model Generation
problem. The problem is deliberately kept simple as it will serve as the running example
in this paper: a glass may be clean or not, and can be cleaned by the action of wiping. We
can represent this dynamic domain by the following FO theory Tact :
t : (Clean(t + 1)  Clean(t)  W ipe(t)).
Clean(0)  InitiallyClean.

(1)
(2)

The bounded planning problem we are considering is then to turn a dirty glass into a clean
one in n steps, where n  N is a given constant. This can indeed be formulated as a
Model Expansion problem: find a model that satisfies Tact while InitiallyClean is false,
and Clean(n) true. We can formulate this problem equivalently as an SO finite domain
satisfiability problem, namely as the satisfiability problem in the range [0 . . . n] of time
points of the following SO formula:
W ipe, Clean, InitiallyClean : (act  InitiallyClean  Clean(n)),

(3)

where with act we denote the conjunction of sentences in Tact . For n > 0, this formula is
indeed satisfiable in the suitable interpretation of constants 0 and n and the binary function
+, and, moreover, each witness W for its satisfiability provides a plan. For instance, wiping
at time point 0 does the job, as is verified by the witness W for which W ipeW = {0} and
CleanW = {1, . . . , n}.
While a large number of search problems can indeed be seen as Finite Model Generation
problems, there are also a number of problems that are of a higher complexity than NP,
and consequently cannot be formulated as an MX(FO) problem. Indeed, in this paper we
are not interested in NP, but in the next level P2 of the polynomial hierarchy. Perhaps
the prototypical such problem is finite domain satisfiability for SO: satisfaction in finite
interpretations is in P2 for every SO sentence and is P2 -hard for some such sentences
(Immerman, 1998). An interesting P2 problem is that of conformant planning, which we
discuss in detail in Section 7, but already introduce in the next example.
Example 1.2. Extending Example 1.1, suppose that we do not know whether the object is
initially clean or dirty, but still want a plan that is guaranteed to make it clean, no matter
what the initial situation was. This is no longer a standard planning problem, but is called
a conformant planning problem. We can formulate this as the following SO satisfiability
problem:
 W ipe InitiallyClean, Clean : (act  Clean(n)).
(4)
In words, we need an assignment to the action W ipe such that the goal Clean(n) is satisfied
for every initial situation InitiallyClean and fluent Clean that satisfy the action theory.
Solving problems like this would require us to make a choice for the existentially quantified predicates and then check that the implication is satisfied for every interpretation of
80

fiAn Approximative Inference Method for SO

the universally quantified predicates. While this can be done in principle, in practice it
is often too expensive. In this paper, we explore an alternative based on a propagation
method for first order logic developed by Wittocx, Denecker, and Bruynooghe (2010). This
method computes in polynomial time, for a given theory T and a partial interpretation I,
an approximation of what has to be certainly true (= true in all models of T that expand
I) and certainly false (= false in all such models). Now, an interesting property of this
propagation method is that it can be syntactically represented as a monotone inductive
definition (Denecker & Ternovska, 2008) that defines (in an approximative way) these underestimates of the predicates in T and of their complements. Such a monotone inductive
definition is essentially just a set of propagation rules, similar to a definite logic program,
that is interpreted by the least fixpoint of its immediate consequence operator. For any
given theory T we can obtain this approximating definition by a linear transformation of
the original FO formula.
Returning to the above example, we need to find an interpretation for the action predicates, such that for every interpretation of the other predicates, the implication act 
Clean(n) is satisfied, i.e., such that without knowing anything about these other predicates, we should already be certain that the implication is satisfied. The basic idea behind
our method is to approximate an SO problem of the form P Q , using the approximate definition from Wittocx et al. to check whether an interpretation for the existentially
quantified predicates P has the property of making  true, regardless of the predicates Q.
Essentially, this reduces an SO problem to an SO(ID) problem (where with SO(ID) we
refer to SO extended with inductive definitions).
In Section 5, we extend our method to SO(ID) problems. As argued by Denecker
and Ternovska, inductive definitions are a useful tool for knowledge representation. For
example, many dynamic domains can be formulated naturally and in a modular way using
inductive definitions, while this can be quite tedious in FO. We already mentioned conformant planning as a typical SO satisfiability problem. Typically, these conformant
planning problems require the modeling of a dynamic domain. We will come back to the
syntax and semantics of inductive definitions in the next section, but the dynamic domain of
Example 1.1 can, as an alternative to the action theory Tact , be formulated as the following
inductive definition act :


 Clean(t + 1)  Clean(t).

Clean(t + 1)  W ipe(t).
(5)


Clean(0)
 InitiallyClean.
The conformant planning problem can then be formulated alternatively as the satisfiability problem of the formula  W ipe InitiallyClean, Clean : (act  Clean(n)). However,
this is no longer a SO satisfiability problem, but a SO(ID) satisfiability problem.
This motivates us to see how we can extend our approximation method to such SO(ID)
satisfiability problems. For this purpose, we first show how to symbolically represent propagation on inductive definitions. Next, we show how we can use this together with the
representation of propagation for FO to approximate finite domain SO(ID) satisfiability
problems.
Our approximation method has a number of benefits. First of all, it is a general method,
that can be applied automatically to approximately solve any SO problem. Second, the
81

fiVlaeminck, Vennekens, Denecker & Bruynooghe

required computation can be carried out by any off-the-shelf MX(FO(ID)) solver, allowing
our method to benefit effortlessly from improvements in solver technology, such as the
IDP system by Marien, Wittocx, and Denecker (2006). Finally, as we show in Section 7,
our method elegantly generalizes a number of approximate reasoning methods from the
literature (e.g., Baral, Gelfond, & Kosheleva, 1998; Son, Tu, Gelfond, & Morales, 2005;
Denecker, Cortes Calabuig, Bruynooghe, & Arieli, 2010; Doherty, Magnusson, & Szalas,
2006; Son et al., 2005).
Parts of this work have already been presented at the JELIA 2011 conference (Vlaeminck, Wittocx, Vennekens, Denecker, & Bruynooghe, 2010).

2. Preliminaries
We assume familiarity with classical first-order logic (FO) and second-order logic (SO). In
this section we introduce some of the notations and conventions used throughout this paper.
2.1 First-order Logic
A vocabulary  is a finite set of predicate symbols P and function symbols F , each with
an associated arity. Constants are function symbols with arity 0. We often denote a symbol
S with arity n by S/n. A interpretation I consists of a domain D and an assignment
of a relation P I  Dn to each predicate symbol P/n   and an assignment of a function
F I : Dn  D to each function symbol F/n  . We assume that P contains the equality
predicate = interpreted as the identity relation. A pre-interpretation of  consists of a
domain and an interpretation of the function symbols. If I is a -interpretation and 0  ,
we denote by I|0 the restriction of I to the symbols of 0 . If 1 and 2 are two disjoint
vocabularies, I a 1 -interpretation with domain D and J a 2 -interpretation with the same
domain, then I + J denotes the unique (1  2 )-interpretation with domain D such that
(I + J)|1 = I and (I + J)|2 = J.
Terms and formulas over a vocabulary  are defined as usual. An expression of the form
 where P is an n-ary predicate and d  Dn is called a domain atom. A domain literal
P (d)
 or the negation P (d)
 thereof. As usual, we denote a formula 
is a domain atom P (d)
by [x] to indicate that the set of free variables of  is a subset of x. A formula without
free variables is called a sentence. The satisfaction relation |= is defined as usual. For an
 we
interpretation I, a formula  with n free variables and a tuple of n domain elements d,


use I |= [d] as a shorthand for I, [x : d] |= [x], where  is a variable assignment, and
 is the variable assignment that is the same as  except that it maps the variables
[x : d]
 We define the truth evaluation function ([d])
 I as follows:
x to the domain elements d.
I
I



([d]) = t iff I |= [d] and ([d]) = f otherwise. We say that a formula  is in negation
normal form if  contains no implications or equivalences, and all negations occur directly
in front of atoms. We define the inverse on truth values as follows: (f )1 = t and (t)1 = f .
We also define the following strict order on the truth values: f <t t. The truth order
point-wise extends to interpretations: if I and J are two -interpretations, then we say
that I t J if for every predicate symbol P and tuple of domain elements d it holds that
 t P J (d).

P I (d)
Similar to how a real number r can be approximated by an interval [l, u] such that l  r 
u, in this paper we approximate -interpretations K by a pair (I, J) of -interpretations,
82

fiAn Approximative Inference Method for SO

such that I t K t J. We denote by [I, J] the interval of all such interpretations K.
This interval is empty if and only if I 6t J. It follows easily from well-known monotonicity
results, that if we evaluate all positive occurrences (i.e., in the scope of an even number of
negations) of atoms in some formula  by I, and all negative occurrences (i.e., in the scope
of an odd number of negations) by J, we are underestimating the truth of  in the interval
[I, J]. Conversely, if we evaluate positive occurrences in J and negative occurrences in I,
we are overestimating the truth of  in [I, J]. To state this property more formally, we
introduce the following notation.
Definition 2.1 (Pos-neg evaluation relation +IJ ). Let  be a -formula and let I and J
be -interpretations. We define the pos-neg evaluation of  in I and J, denoted by +IJ ,
by induction over the size of :
 for an atom  = P (t), +IJ = I ;
 for  = , +IJ = ( +JI )1 ;
 for  = 1  2 , +IJ = t iff i+IJ = t for both i = 1, 2;
 for  = x , +IJ = t iff there is a d  D such that  +I[x/d]J[x/d] = t.
We now indeed have that, for each K  [I, J], +IJ  K  +JI . Also, we have
that K = +KK .
There is an intimate connection between the approximation of an interpretation by a
pair of interpretations and Belnaps four-valued logic (1977). We denote the truth values
true, false, unknown and inconsistent of four-valued logic by respectively t, f , u and i. On
these truth values, the truth order t and precision order p are defined as shown in Figure
1.
A four-valued relation of arity n on some domain D is a function from Dn to {t, f , u, i}.
A four-valued interpretation I of vocabulary  consists of a pre-interpretation and of P I ,
a four-valued relation of arity n on D for each predicate symbol P/n  . Again, the
precision order pointwise extends to interpretations: if I and J are two -interpretations,
then we say that I p J if for every predicate symbol P and tuple of domain elements d it
 p P J (d).
 Similarly, also the truth order is extended to interpretations.
holds that P I (d)
@t^
<t

<p

<t

u^

@i

<p

f_

<t

<t

@i^

?t
<p

<p

u

f

Figure 1: The truth and precision order
83

fiVlaeminck, Vennekens, Denecker & Bruynooghe

There is a natural isomorphism between Belnaps four truth values and pairs of the two
standard truth values:
 (t, t) = t;
 (f , t) = u;
 (t, f ) = i;
 (f , f ) = f .
Intuitively, this mapping  interprets its first argument as an underestimate to the real
truth value, and its second argument as an overestimate: if the underestimate is f and the
overestimate is t, then the real truth value is indeed unknown; whereas, if the underestimate
is t and the overestimate if f , then there cannot exist a real truth value, since t 6 f , so we
end up with inconsistency. This isomorphism  extends in an obvious way to an isomorphism
between pairs (I, J) of two-valued interpretations and four-valued interpretations I which
all share the same pre-interpretations: (I, J) and I are isomorphic iff, for each predicate
 =  (P I (d),
 P J (d)).
 We also denote this isomorphism by  .
P/n and tuple d  Dn , P I (d)
There is a tight link between the pos-neg evaluation function +IJ and the Belnap
evaluation I :
I =  (+IJ , +JI ), where  (I, J) = I.
When I is a three-valued structure (i.e., it never assigns i) this corresponds to the standard
Kleene evaluation (1952). In the rest of this paper, we will often omit the isomorphism  ,
and, e.g., simply denote the four-valued truth value of a formula  in a pair of interpretations
(I, J) as (I,J) . An important property, that we already stated above in different notation,
is that (I,J) p K for all K  [I, J].
There is a natural and well-known alternative way of using an interval [I, J] for which
I t J to assign a truth value to a formula : the supervaluation (van Fraassen, 1966).
Definition 2.2 (Supervaluation sv(I,J) (.)). The supervaluation sv(I,J) () of a sentence 
in a pair of interpretations (I, J) (or equivalently, a three-valued interpretation  (I, J)) is
defined as
sv(I,J) () = glbp ({K |K  [I, J]}).
It is easy to see that always sv(I,J) () p (I,J) . This inequality may be strict. For
instance, if we take  = Q  Q and interpretations I and J such that Q(I,J) = u, then
sv(I,J) () = t, but (I,J) = u. The supervaluation has the following interesting property.
Let I be an interpretation for the free vocabulary of a SO formula  = Q , and let (J1 , J2 )
 =u
be the least precise pair of interpretations for Q in the domain D of I (i.e., Q(J1 ,J2 ) (d)
n

for all Q/n  Q and d  D ). We then have that sv(I+J1 ,I+J2 ) () = t if and only if I = t.
Key to our approach is that we can simulate the four-valued truth evaluation in pairs
of interpretations by encoding what is certainly true and certainly false, using a single
two-valued structure I tf over a new vocabulary tf . As we show in the next section, this
gives us a convenient vocabulary to syntactically represent the construction of such an
approximation. The new vocabulary tf contains the function symbols F of  and, for
each predicate P  P , two symbols P ct and P cf . The interpretations of P ct and P cf
 is certainly true and those for
in I tf contain, respectively, those tuples d for which P I (d)
which it is certainly false. Formally, for a vocabulary  and a four-valued -interpretation
84

fiAn Approximative Inference Method for SO

I =  (I, J), the tf -interpretation I tf has the same pre-interpretation as I, and is defined
by:
(P ct )I

tf

 I (d)
 p t} = P I ,
= {d|P

(P cf )I

tf

 I (d)
 p f } = Dn \ P J .
= {d|P
tf

tf

An interpretation I is three-valued iff (P ct )I and (P cf )I are disjoint for any P  . I
tf
tf
is two-valued iff (P ct )I and (P cf )I are each others complement in Dn . Also, if I p J ,
tf
tf
tf
tf
then, for each P , (P ct )I  (P ct )J and (P cf )I  (P cf )J .
Definition 2.3 (ct and cf ). For any given -formula [x], let ct [x] be the tf -formula
obtained by first reducing to negation normal form and then replacing all occurrences of
positive literals P (t) by P ct (t) and all negative literals P (t) by P cf (t), and let cf [x] be
the formula ([x])ct .
An interesting property of the formulas ct and cf is that they do not contain negations.
Also, the following proposition is well-known.
Proposition 2.1 (Feferman, 1984). For every -formula  and interpretation I, it holds
 I p t if and only if [d]
 +IJ = t if and only if (ct [d])
 I tf = t. Also, [d]
 I p f
that [d]
tf
+JI
cf
I


if and only if [d]
= f if and only if ( [d])
= t.
2.2 FO(ID)
In this subsection we recall FO(ID) (Denecker & Ternovska, 2008), the extension of FO
with a construct to respresent some of the most common forms of inductive definitions,
such as monotone induction, induction over a well-founded order or iterated induction. As
illustrated by Denecker and Ternovska, FO(ID) can be used to represent different sorts
of common knowledge, such as temporal and dynamic domains, the closed world assumption, defaults, causality, etc. In this paper, we use definitions to symbolically represent
propagation, not only for FO formulas, as already mentioned in the introduction, but also
propagation for inductive definitions themselves.
A definitional rule over a vocabulary  is an expression of the form x P (t)   where
P (t) is an atomic formula and  an FO formula. The symbol  is a new connective, called
the definitional implication, to be distinguished from the FO material implication symbol
 (or its converse ). A definition  is a finite set of definitional rules. A predicate
symbol P in the head of a rule of  is called a defined predicate; all other predicate and
function symbols in  are called the open symbols or the parameters of the definition; the
set of defined predicates is denoted Def (), the remaining symbols Open() (note that
Open() therefore also includes F ).
Given an interpretation for its open predicates, each definition will have a unique model,
that can be constructed by firing its rules in an appropriate order. Before defining this
formally, we first consider an example.
Example 2.1. Reachability in a graph is not expressible in FO. That is, there is no FO
formula  over the vocabulary consisting of two predicates Edge/2 and Reach/2 such that
in any model M of , (d1 , d2 )  ReachM iff there is a non-empty path from d1 to d2 in the
85

fiVlaeminck, Vennekens, Denecker & Bruynooghe

graph represented by EdgeM . We can represent reachability with an inductive definition
however. The following definition defines the predicate Reach in terms of the open predicate
Edge.
(
)
xy Reach(x, y)  Edge(x, y).
xy Reach(x, y)  z(Reach(x, z)  Reach(z, y)).
O ). With a definition  and a given Open()-interpretation O,
Definition 2.4 (Operator T
O on two-valued Def ()-interpretations
we define the immediate consequence operator T
O
such that T (I) = J iff for each defined predicate P/n and tuple d  Dn , it holds that
 = t iff there exists a rule x P (t)  [x], such that t(O+I) = d and (O+I) [d]
 = t.
P J (d)

The model of a positive definition (i.e., no defined predicates occur negatively in the
body of rules) can be defined as the least fixpoint of this immediate consequence operator.
We use M odI|Open() () to denote the model of the definition  extending the restriction
of I to the open predicates and function symbols of . When  has no open predicates,
we omit the subscript and simply use M od(). We postpone going into more detail about
how to construct the model of a general (non-monotonic) inductive definition until Section
5. In the next two sections, we only use positive definitions.
FO(ID) formulas are inductively defined by the same rules as standard FO formulas,
augmented with one extra case:
 A definition  over  is an FO(ID) formula (over )).
Note that rule bodies do not contain definitions, and that rules only occur inside definitions
and are not FO(ID) formulas themselves whereas definitions can be used in FO(ID) formulas
anywhere atoms can be used.
We can now define the satisfaction relation I |=  of FO(ID) using the standard inductive
rules of FO, augmented with one extra rule:
 I |=  if I = M odI|Open() (),
From now on, we assume without loss of generality that for any definition , it holds that
every defined predicate P  Def () is defined by exactly one rule, denoted by x(P (x) 
P [x]). Indeed, any definition  can be brought into this form by a process similar to
predicate completion. The transformation consists of first transforming rules of the form
x(P (t)  ) into equivalent rules y(P (y)  x(y = t  )). Next, one merges all rules
of the form x(P (x)  i [x]) into x(P (x)  1 [x]  . . .  n [x]).

3. Propagation for FO
In this section we give a general, symbolic representation of propagation for first-order logic.
For this, we base ourselves on the work by Wittocx et al. (2010). We come back to the
precise relation between the material presented in this section and their work at the end of
this section.
Suppose we have an FO theory T in vocabulary , a pre-interpretation of , and a
finite three-valued interpretation I that represents some (incomplete) knowledge about the
86

fiAn Approximative Inference Method for SO

t (Clean(t + 1)  (Clean(t)  W ipe(t))).
t

A1
Act
1

Clean(t + 1)  (Clean(t)  W ipe(t))
t for t = 3

Clean(t + 1)
f for t = 3

A2 (t)
Act
2 (3)

Clean(t)  W ipe(t)
t for t = 3

Clean(t)
t for t = 3

A3 (t)
Act
3 (3)

Clean(t + 1)
Cleancf (4)

W ipe(t)
t for t = 3

Clean(t)
Cleancf (3)

W ipe(t)
W ipecf (3)

Figure 2: Propagation for FO.
predicates of . We would now like to know the implications of this knowledge, assuming
the theory T is satisfied in the context of I. To find this out, we can look at the set M
of all models of T that complete this three-valued interpretation, i.e., M = {M | M |=
T and I p M }. Given the partial information I, everything that is true in all M  M
must certainly be true according to T , while everything that is false in all such M must
certainly be false according to T . In other words, all the information that T allows us to
derive from I can be captured by the greatest lower bound G = glbp M.
In general, computing this greatest lower bound may be too expensive (the data complexity is in P2 ) to be of practical use. However, we may still achieve useful results by
computing some approximation M such that I p M p G. We can compute such an
approximation by propagating the three-valued interpretation I through the parse tree of
T . We illustrate this with the following example.
Example 3.1. Consider the sentence : t Clean(t + 1)  Clean(t)  W ipe(t). Rewriting
this into negation normal form, it becomes:
t Clean(t + 1)  (Clean(t)  W ipe(t)).
Now, assume that  is satisfied, and that we know that Clean is false at timepoint 4.
From the knowledge that  is satisfied, it immediately follows that, for all timepoints t,
the disjunctive formula Clean(t + 1)  (Clean(t)  W ipe(t)) is satisfied. Using the fact
that Clean is false at timepoint 4, we can now deduce that the conjunction (Clean(t) 
W ipe(t)) is true for timepoint 3. Therefore, in all models of  where Clean is false at
timepoint 4, W ipe and Clean have to be false at timepoint 3. This reasoning process is
illustrated on the left part of Figure 2.
We now construct a symbolic representation of this propagation process. First, we
introduce some additional vocabulary Aux to refer to the different nodes of the parse
tree on which this process operates. We then use this additional vocabulary to transform
an FO formula into an equivalence normal form formula. This is similar to the Tseitin
transformation (1968) for propositional logic.
Definition 3.1 (EN F ()). For an FO formula  in negation normal form, we introduce
a new predicate symbol A of arity n for each non-literal subformula [x] of  with n
87

fiVlaeminck, Vennekens, Denecker & Bruynooghe

free variables. We denote the set of these new predicates by Aux(). Each of these new
predicate symbols is defined by a formula Eq(A ) as follows. To make notation simpler
we assume that each 1 , . . . , n is a non-literal subformula. The definitions are analogous
whenever a i is a literal, but instead of Ai the literal i itself is used in the body of the
definition.
 If [x] is a subformula of the form 1 [x1 ]  2 [x2 ]  . . .  n [xn ], then Eq(A ) is
x (A (x)  A1 (x1 )  A2 (x2 )  . . .  An (xn )).
 If [x] is a subformula of the form 1 [x1 ]  2 [x2 ]  . . .  n [xn ], then Eq(A ) is
x (A (x)  A1 (x1 )  A2 (x2 )  . . .  An (xn )).
 If [x] is a subformula of the form y 1 [x, y], then Eq(A ) equals x (A (x) 
y A1 (x, y)).
 If [x] is a subformula of the form y 1 [x, y], then Eq(A ) equals x (A (x) 
y A1 (x, y)).
We define the equivalence normal form of  as the set of all such Eq(A ), and denote
it as EN F ().
Example 3.2. According to this definition, the EN F () theory from Example 3.1 is:
A1  t A2 (t).
t A2 (t)  Clean(t + 1)  A3 (t).
t A3 (t)  Clean(t)  W ipe(t).
This is illustrated in the right side of Figure 2.
Using the auxiliary vocabulary, we can now write down the propagations shown in
Figure 2 as the following implications.
A1
A2 (3)  Clean(4)
A3 (3)
A3 (3)






A2 (3).
A3 (3).
Clean(3).
W ipe(3).

Note that these rules are all top-down rules, that is, implications that propagate information
about a subformula down the parse tree, to a component of that subformula (possibly
using also information about other components of the subformula, as in the implication
A2 (3)Clean(4)  A3 (3)). In general, also bottom-up propagations are of course possible.
For instance, from Clean(4) we could derive A2 (3). For every predicate A , we can derive
from Eq(A ) a set of implications 1  2 , such that each such propagation corresponds
to deriving the consequent 2 from the antecedent 1 (so, different implications can be
logically equivalent). This is defined in Table 1. The last column of this table indicates
whether the rule is top-down (TD) or bottom-up (BU).
Definition 3.2 (IN F ()). Given an equivalence   EN F () for a certain formula , we
denote with Imp() the set of all implications obtained through Table 1.
S We define the implication normal form of , denoted by IN F (), as follows: IN F () = EN F () Imp().
88

fiAn Approximative Inference Method for SO

 = Eq(A )

Imp()

x (L  L1  . . .  Ln ).

x
x
x
x

(L1  . . .  Ln  L).
(Li  L).
(L  Li ).
(L  L1  . . .  Li1  Li+1  . . .  Ln  Li ).

1in
1in
1in

BU
BU
TD
TD

x (L  L1  . . .  Ln ).

x
x
x
x

(L1  . . .  Ln  L).
(Li  L).
1in
(L  Li ).
1in
(L  L1  . . .  Li1  Li+1  . . .  Ln  Li ). 1  i  n

BU
BU
TD
TD

x (L[x]  y L0 [x, y]).

x ((y L0 [x, y])  L[x]).
x(y L0 [x, y])  L[x]).
xy (L[x]  L0 [x, y]).
xy ((L[x]  z (y 6= z  L0 [x, y][y/z]))  L0 [x, y]).

BU
BU
TD
TD

x (L[x]  y L0 [x, y]).

x ((y L0 [x, y])  L[x]).
x(y L0 [x, y])  L[x]).
xy (L[x]  L0 [x, y]).
xy ((L[x]  z (y 6= z  L0 [x, y][y/z]))  L0 [x, y]).

BU
BU
TD
TD

Table 1: From ENF to INF

In the work of Wittocx et al. (2010) it is proven that models of  and models of IN F ()
where A is true correspond, in the sense that the restriction of a model of IN F ()  A
to  is also a model of , and vice versa, every model of  can be extended to a model
of IN F ()  A . These implications will form the core of our approximation method.
While our approximation could be made more complete by adding more implications to
IN F (), the above definition tries to strike a balance between completeness and the ease
of automatically deriving the implications.
Example 3.3. For each of the three formulas  in EN F () in Example 3.2, the following
table shows the corresponding set of implications Imp(). The complete theory IN F ()
consists of the union of these three sets.
A1  t A2 (t).
(t A2 (t))  A1 .
(t A2 (t))  A1 .
t (A1  A2 (t)).
t ((A1  t0 (t 6= t0
 A2 (t0 )))  A2 (t)).

t (A2 (t)  Clean(t + 1)  A3 (t)).
t (Clean(t + 1)  A3 (t)  A2 (t)).
t (Clean(t + 1)  A2 (t)).
t (A3 (t)  A2 (t)).
t (A2 (t)  Clean(t + 1)).
t (A2 (t)  A3 (t)).
t (A2 (t)  A3 (t)  Clean(t + 1)).
t (A2 (t)  Clean(t + 1)  A3 (t)).

t (A3 (t)  (Clean(t)  W ipe(t))).
t (Clean(t)  W ipe(t)  A3 (t)).
t (Clean(t)  A3 (t)).
t (W ipe(t)  A3 (t)).
t (A3 (t)  Clean(t)).
t (A3 (t)  W ipe(t)).
t (A3 (t)  W ipe(t)  Clean(t)).
t (A3 (t)  Clean(t)  W ipe(t)).

The reader can verify that the four implications representing the propagation in Example 3.1
all indeed belong to IN F ().
The propagation process in Example 3.1 can now be described as a least fixpointcomputation, where we apply the implications (i.e., infer the head when the body is
already inferred), until we no longer can infer any new information. We will represent this
fixpoint computation as an inductive definition in the syntax of FO(ID). However, there are
two complications.
89

fiVlaeminck, Vennekens, Denecker & Bruynooghe

First, in this paper, we do not always need all of the implications in IN F (). Indeed,
there will typically be some subset    of symbols about which we already know all there
is to know. In the conformant planning example, for instance, this will be the case for the
existentially quantified predicate W ipe/2, simply because we will use a model expansion
system to guess a complete interpretation for this predicate. The job of the propagation
process is then to figure out the consequences of each particular guess. For this, the implications with a predicate from  (i.e., W ipe/2) in their head are obviously not needed.
Second, the fixpoint computation not only needs to infer that atoms are true but also
that they are false. However, the syntax of FO(ID) does not allow negative literals in the
heads of rules. Therefore, our definition will not contain rules with the predicates P of the
original vocabulary  in their head, but will instead use predicates P ct and P cf from the
tf -vocabulary. Since we do not need rules with the fully known predicates  in the head,
we will only introduce these P ct and P cf predicates for those P that are in  \ . For a
ct
ct
given formula , we therefore define ct
 as the formula  (see Definition 2.3) but with P
cf
replaced by P and P by P for every predicate P  .
Definition 3.3 (Approx ()). For a formula  and   , we define Approx () as the
inductive definition that contains, for every sentence x (  L[x]) of IN F () in which L
ct
is a literal of a predicate not in , the definitional rule x(L[x]ct
   ). We also define
TD
ApproxBU
 () (and Approx ()) in the same way as Approx (), but only containing
definitional rules coming from the bottom-up (respectively, top-down) rules of IN F ().
We can often assume without loss of generality that  = . Whenever this is the case
we drop the  and use Approx() rather than Approx (), to denote the approximative
definition.
Example 3.4. Using the implications IN F () of Example 3.3, we obtain the definition
shown in Figure 3 for Approx(). If we take  = {W ipe}, we get the same definition for
Approx () as in Figure 3, apart from the last seven definitional rules that are replaced by
the following five definitional rules.


..




.






ct
cf


A
(t)

Clean
(t)

W
ipe(t).


3


 cf

ct
A3 (t)
 Clean (t).


 W ipe(t).
 Acf

3 (t)




cf
ct




Clean
(t)

A
(t).
3






cf
ct
Clean (t)  A3 (t)  W ipe(t).
In contrast with Approx() this definition no longer approximates the predicate W ipe. The
definition Approx () can be used to find out what certainly holds or not holds given a two
valued interpretation for the predicates in .
Example 3.5. For a larger example, we look again at the Example 1.1. Let us again take
 = act and  = {W ipe}. Then the definition Approx () can be found in the Appendix
A.
This approximative definition has some useful properties, which we formulate in the
next two theorems. The first property is that, when using the approximative definition
90

fiAn Approximative Inference Method for SO

 ct
A1



cf


A
1


ct


A2 (t)




Acf

2 (t)







Acf

2 (t)


ct

A

 2 (t)

ct


A2 (t)



Cleancf (t + 1)


 cf
A3 (t)
Cleanct (t + 1)




Act

3 (t)







Act

3 (t)


cf

A

3 (t)


cf


A
3 (t)


cf


Clean
(t)


cf


W
ipe
(t)




Cleanct (t)



W ipect (t)


 t Act

2 (t).




 t Acf
(t).
2


ct


 A1 .


cf
0
0
ct 0

 A1  t (t 6= t  A2 (t )).







cf
cf
 Clean (t + 1)  A3 (t). 



ct

 Clean (t + 1).



ct

 A3 (t).



cf


 A2 (t).



cf
 A2 (t).
cf

 Act
2 (t)  A3 (t).


ct


 A2 (t)  Cleancf (t + 1).






cf
cf

 Clean (t)  W ipe (t). 




 Cleanct (t).





 W ipect (t).




 Act
(t).
3




 Act
(t).
3


cf

cf

 A3 (t)  W ipe (t).



cf
cf
 A3 (t)  Clean (t).

A1
t
A2 (t)


A3 (t)

Clean(t + 1)



Clean(t)

W ipe(t)

Figure 3: Example of an approximative definition
together with an encoding of a three-valued interpretation I of the original vocabulary, we
can give an exact characterization of what the approximative definition computes. Indeed,
in this setting, ApproxBU () actually encodes the three-valued Kleene evaluation of  in
I. Moreover, adding the top-down rules does not change this, since they will not compute
actually anything, as long as only information about the original vocabulary is provided
as input. Before we can formally state this property, we need to define how we encode a
four-valued interpretation as a definition. From here on, we assume that for any vocabulary
 and -pre-interpretation I,  contains a constant symbol Cd for every domain element
d in the domain D of I, and that for the pre-interpretation I it holds that (Cd )I = d. This
allows us to identify Cd and d and therefore, abusing notation, we will use d to denote Cd
in what follows.
Definition 3.4 (I ). Given a four-valued -interpretation I, the definition associated to
I is denoted by I and is defined by
I

=

  t | P I (d)
 p t}
{P ct (d)
cf
I


 {P (d)  t | P (d) p f }

Theorem 3.1. Given a -formula  and a four-valued -interpretation I, the following
holds:
a) In the case that I is three-valued it holds that Approx()  I is logically equivalent
to ApproxBU ()  I , that is, M od(Approx()  I ) = M od(ApproxBU ()  I )
91

fiVlaeminck, Vennekens, Denecker & Bruynooghe

b) Let M be M od(Approx()  I ), v1 the truth value of Act
 in M and v2 be the truth
I
value of Acf
 in M , then (v1 , v2 ) corresponds to the four-valued truth value  , i.e.,
 I =  (v1 , v2 ).

Proof. See Appendix B.
In summary, what this theorem says is that, first of all, the approximation always
computes the four-valued Belnap evaluation of  in the four-valued structure I. Moreover,
this computation is done by the bottom-up rules of the approximation alone. If I is threevalued, then the top-down rules actually have no effect at all. If I is four-valued, then
they may still serve a purpose, however: once the bottom-up rules have derived that some
subformula is inconsistent, they can then propagate this information to derive that smaller
formulas are also inconsistent. To see this, consider the following formula P  Q, and take
for I the four-valued interpretation such that P = i and Q = t. Then one can verify that
cf
the bottom-up rules in Approx()  I will infer that both Act
P Q and AP Q are true.
However, now the top-down rules can also infer that Qcf has to be true.
In the theorem above the only information we add to the approximative definition is in
the form of the definition I , i.e., we only assert the truth, resp. falsity of domain atoms.
The following definition now allows us to assert the truth or the falsity of any grounded

subformula [d].
Definition 3.5 ( ). Given a -formula , a -pre-interpretation I, and a set  of
 such that [x] is a subformula of  of arity n and d  Dn where D is the
formulas ()[d],
domain of I, we then define  as follows:
cf 



 = {Act
 (d)  t | [d]  }  {A (d)  t | [d]  }.

If we assert in this way the truth (or the falsity) of a set of grounded subformulas ,
then we will obtain an approximation of everything that holds (respectively, does not hold)
in all models of . However, as opposed to the theorem above, the next theorem does not
give an exact characterization of the approximation we get.
Theorem 3.2. Given a -formula , a set  as defined above and a subformula 0 [x0 ] of
cf 0
0 0
0
. Let M be M od(Approx()   ). If M |= Act
0 (d ) (resp. A0 (d )), then  |=  [d ]
(resp.  |= 0 [d0 ]).
Note that an interesting special case of this theorem is where we take  equal to {} and
thus add Act
  t to Approx(). Then this definition gives an approximation of everything
that is certainly true resp. certainly false in all models of .
Returning now to the exact relationship between the work of Wittocx et al. (2010) and
the content of this section, we see that Wittocx et al. are only interested in this special
case, i.e., in approximating all models of a theory. For this reason their transformation
from a formula  to EN F () already includes a formula A  t, which will cause the rule
Act
  t to always be included in the approximating definition. All their soundness results
have also been formulated and proven in this setting. However, it is not difficult to see that
the proofs can be trivially adapted to a proof of Theorem 3.2 in the more general setting
used in this section.
92

fiAn Approximative Inference Method for SO

4. Approximating SO-Satisfiability Problems
We now use the approximate definition from the previous section to approximate the following problem. Take an SO formula F = P Q : . For ease of presentation, we
assume that the second-order formulas in this paper contain no free predicate symbols, but
all results generalize to the setting where there are free predicate symbols. We also assume
that Q contains only predicate symbols. In what follows, we denote the vocabulary of 
by . The question we want to answer is whether the formula F is satisfied in a given
finite-domain pre-interpretation I of the constant and function symbols of the formula.
This satisfiability problem boils down to deciding whether we can find a witness for the
satisfiability of this formula, in the following sense.
Definition 4.1 (Witness). We call J a witness for the satisfiability of a formula P Q : 
given a finite  pre-interpretation I, if J is an interpretation of  \ Q extending I (i.e., J
is an interpretation of the whole vocabulary without the universally quantified predicates)
such that Q :  is satisfied in J. Equivalently, J is a witness if in the three-valued  it holds that
interpretation J that expands J by assigning u to each domain atom Q(d),
svJ () = t.
Our goal in this section is now to approximate an SO satisfiability problems by an
SO satisfiability problem in the following sense.
Definition 4.2 (Sound approximation). Consider the SO satisfiability problem for a
formula P Q : , where  is an FO formula in alphabet . An SO(ID) formula of
the form P R :  0 , where  0 is an FO(ID) formula in the alphabet  \ Q  R, is a sound
approximation of this satisfiability problem if, whenever J is a witness for the satisfiability
of P R :  0 , then J|\Q is a witness for the satisfiability of P Q : .
In other words, a sound approximation G of the satisfiability problem for an SO
formula F is a stronger SO(ID) formula, i.e., one that has fewer witnesses for P .
4.1 A Naive Method
We can now use the results of Theorem 3.1 to construct a sound approximation for a given
SO formula.
Definition 4.3 (APP(F )). Given a formula F = P Q : . Take  to be the alphabet
of all function symbols in  and the predicates P . We define APP(F ) as the SO formula
tf
P R : Approx ()  Act
 in the vocabulary   R, where R = (Q  Aux()) .
The intuition here is that for any -interpretation I, Approx () will give the result
of the four-valued evaluation  I in the -interpretation I that expands I by assigning unknown to all universally quantified predicates Q. If the entire FO formula  evaluates to
true in this four-valued interpretation, we know that  will be satisfied in any  interpretation that expands I (in other words, for every interpretation of the Q predicates), and thus
that I is a witness for the satisfiability of the entire formula F . The auxiliary predicates
Aux()  introduced by the transformation to ENF  are needed because of the way in
which the propagation works, but their value is completely determined by that of P .
93

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Proposition 4.1. For each SO formula F of the form P Q : , it holds that APP(F )
is a sound approximation of F .
Proof. This follows immediately from Theorem 3.1, where we take as three-valued inter I = u for all Q  Q and d  Dn , and
pretation, the interpretation I such that (Q(d))
 I = (P (d))
 I for all P  P and d  Dn , with D the domain of I.
(P (d))
For example, if we take F to be the formula P Q :  where  = P  Q, then APP(F )
becomes:
 ct

ct
A

P

Q






 Acf  P  Qcf 

cf
ct
cf
ct

P, Q , Q , A , A :
 Act
.
ct  Act  P
Q







 cf

Q  Acf

We start from an interpretation O of the open predicate P of the definition Approx{P } ().
Let us take the interpretation O that makes P true. The unique model I of the definition
ct
cf and
that extends O is then the interpretation that assigns true to Act
 and false to Q , Q
ct
Acf
 . Therefore, this I satisfies both Approx{P } () and A . Hence, it is a witness for the
satisfiability of APP(F ), and, indeed, it is also a witness for the satisfiability of the original
formula P Q : P  Q.
This approximation method is sound, but for many applications still too incomplete.
Indeed, let us look at the following formula: F = Q : Q  Q. Then APP(F ) becomes:



 Qct  Qcf 
Act






cf
cf  Qct 


A

Q






 Qct  Act  Qct 

cf

:
,
A
Qct , Qcf , Act
 Act

.
cf  Acf



Q






cf 


Qcf  Act


 Q




 Qct  Acf



The definition does not entail that Act
 , so APP(F ) is unsatisfiable, even though the original formula F is clearly always satisfied. The problem here is that, as we showed in the
previous section, the definition encodes the three-valued Kleene evaluation, which is not
strong enough to find out that the formula F is satisfied. To do this, we need the stronger
supervaluation.
Recall that in the preliminaries we saw that supervaluation and Kleene evaluation are
in general not equal. However, for some formulas  they are equal. In the literature, several
classes of formulas for which they agree have been proposed, e.g., in the context of locally
closed databases (Denecker et al., 2010), or in the context of reasoning with incomplete
first-order knowledge (Liu & Levesque, 1998). The latter introduces a normal form N F for
first-order formulas, for which the supervaluation coincides with the Kleene evaluation, and
proves for certain classes of formulas that they are in the normal form N F. One such class
is that of all CNF formulas in which every two literals are conflict-free: a pair of literals
is conflict-free if they either have the same polarity, or they use different predicates, or
they use different constants at some argument position. It immediately follows that our
94

fiAn Approximative Inference Method for SO

approximation is complete for SO formulas in which the first-order formula satisfies this
condition.
Proposition 4.2. Each SO formula F of the form P Q : , where  is in the N F
normal form (according to Liu & Levesque, 1998) is satisfiable with respect to a given finite
pre-interpretation I if and only if the SO-formula APP(F ) is satisfiable w.r.t. I.
Proof. This follows immediately from the results by Liu and Levesque and Theorem 3.1.
4.2 A More Complete Method
Unfortunately, many applications give rise to formulas in which the first-order part falls
outside the class N F, which means that completeness of our method is not guaranteed.
Particularly troublesome in practice are formulas of the common form P Q : 1  2 .
For such formulas, the naive approximation method of the previous section tries to find
interpretations for P such that the implication  = (1  2 ) holds for all Q. However, if
we look at the details of the approximative definitions, we find that Act
 is defined by a rule
cf
ct
with a body 1  2 . In other words, the approximation will only derive that  holds for
all Q if it is either the case that 1 is false for all Q or that 2 is true for all Q. However,
this will rarely be the case. In most practical applications, the witnesses of interest will
typically satisfy the implication 1  2 not because they always falsify 1 or always
satisfy 2 , but rather because each interpretation for Q that satisfies 1 also satisfies 2.
For instance, in the conformant planning example, there will always be interpretations for
the fluents that do not satisfy the action theory act , because they arbitrarily assign some
fluent a value that is wrong for its initial value and the actions that are performed. Even if
a set of actions is a completely correct conformant plan, it therefore cannot make the goal
certainly true, because it will still be unsatisfied in some of these wrong interpretations of
the fluents. Of course, this should not bother a good method for finding conformant plans.
The only thing that should matter is that the goal is satisfied in those interpretations of
the fluents that do satisfy the action theory.
Luckily, our approximation method can also be used to discover this kind of witnesses.
The only thing that is required is to add to the approximative definition  = Approx ()
a rule Act
1  t. By doing do, we seed our approximation with the assumption that 1
holds. Starting from this assumption, the top-down rules will then derive properties of
the predicates Q that are shared by all interpretations for Q that actually satisfy 1 . The
bottom-up rules will then propagate this information upwards and discover whether these
properties suffice to ensure that 2 also holds. If they do, then we know that 2 indeed
must hold in every interpretation for Q that satisfies 1 and that we therefore have found
a witness for our formula.
If we want to find both witnesses of this kind and degenerate witnesses that either make
1 false for all Q or 2 true for all Q, we could simply combine our new method with the old
ct
ct
one and check either whether Act
2 holds according to   {A1  t} or whether A holds
according to just  itself. However, it turns out that this is not necessary: we can achieve
ct
the same effect by just checking whether   {Act
1  t} implies A . This is because, first,
ct
the definition   {Act
1  t} will be able to derive A whenever  itself can: if  can
ct
ct
derive that A2 then   {A1  t} will obviously still be able to do so; if  would be
95

fiVlaeminck, Vennekens, Denecker & Bruynooghe

ct
able to derive that Acf
1 , then   {A1  t} will also be able to do so, simply because
our approximation has no flow of information between the ct and cf variants of the same
formula, so the additional assumption that Act
1 holds will not change the original derivation
ct
ct
ct
of Acf
1 . Second, if   {A1  t} can derive A2 , then it also derives A , simply because
cf
ct
it contains the rule Act
  A1  A2 . Therefore, we can find both kinds of witnesses by
ct
checking whether Act
 is implied by the single definition   {A1  t}.

Definition 4.4 (APP  (F )). For an SO formula F = P Q : , where  is of the
 is the definition
form 1  2 , we define APP  (F ) as P R :   Act
 , where 
ct
Approx (1  2 )  {A1  t}.
Note that we obtain Definition 4.3 as a special case when taking the trivial formula t
for 1 . This approximation method is still sound, as the following proposition states.
Proposition 4.3. Given a formula F of the form P Q : , where  = 1  2 , the
SO(ID) formula APP  (F ) is a sound approximation of F .
Proof. See Appendix C.
Since the approximative definition  in APP  (F ) contains all the rules of Approx(F ),
it is not hard to see that this new approximation method is at least as complete as the one
using APP(F ) (Definition 4.3). Moreover, as can be seen from the following example, it is
also strictly more complete.
Example 4.1. Let us consider the following formula F = P Q : (Q  P )  Q. We have
that P = t is clearly a witness for this satisfiability problem. If we denote (Q  P )  Q
by 1 and (Q  P ) by 2 , then APP(F ) is the following SO formula.

Act

1


cf


A



 ct1
A2
P R :

Acf
2



ct

Q


 cf
Q








ct
Acf
2  Q
ct
A2  Qcf
P  Qct
P  Qcf
Act
2  P
Acf
2











 Act
1 .










Now, even for P = t, the definition in the body of this formula will not entail Act
1 = t.

Therefore, APP(F ) is not satisfiable. On the other hand, APP (F ) is the same formula
as above, apart from that the definition contains one more rule, that is, the rule Act
2  t.
It is easy to verify that APP  (F ) is satisfiable, and indeed has P = t as a witness.
Obviously, the new method is still complete on formulas 1  2 , where 1  2
satisfies the normal form N F. However, our method also works for many formulas outside
this class. Unfortunately, it is difficult to characterize precisely how much more complete the
new method is. For instance, one source of loss in completeness comes from the fact that our
current translation to ENF cannot recognize multiple occurrences of the same subformula,
and will introduce a different Tseitin predicate for each occurrence. Even though we cannot
96

fiAn Approximative Inference Method for SO

guarantee completeness for our method in general, we always found all solutions in the
conformant planning benchmarks we considered in Section 6.
A final remark about this method is that the approximative definition Approx (1 
2 ) contains a number of rules that are superfluous in our context. Indeed, with our method,
this definition takes as its input an interpretation for P together with the assumption that
1 is certainly true. It then uses the bottom-up and top-down rules derived from 1 to
compute the effect of these inputs on the predicates Q. Finally, the rules derived from 2
then compute whether the derived information about Q suffices to make 2 certainly true.
However, as we know from Theorem 3.1, only the bottom-up rules for 2 are needed for
this. Therefore, the top-down rules for 2 actually contribute nothing and could just as

TD
well be removed. Adapting Definition 4.4 to use 
BU =  \ Approx (2 ) instead of

 leads to the following definition.
Definition 4.5 (APP 
BU (F )). For an SO formula F = P Q : , where  is of the
ct

form 1  2 , we define APP 
BU (F ) as P R : BU  A , where
TD
ct

BU = Approx (1  2 ) \ Approx (2 )  {A1  t}.

It follows directly from Theorem 3.1 and Proposition 4.3 that this too is a sound approximation. Having removed the top-down rules from the approximation of 2 , the remaining
rules just serve, as we already know, to compute the Kleene evaluation of 2 . They do
this by computing the Kleene evaluation of each subformula  of 2 , for which they use
pt
the Tseitin predicates Act
 and A . An alternative is to avoid these Tseitin predicates by
defining Act
2 directly by the single rule:
ct
Act
2  (2 )

This variant is summarized in the following definition.
Definition 4.6 (APP 
BU,U nf (F )). For an SO formula F = P Q : , where  is
ct

1  2 , we define APP 
BU,U nf (F ) as P R : BU,U nf  A , where
ct
ct
ct

BU,U nf = Approx () \ Approx (2 )  {A2  (2 ) }  {A1  t}.

This approximation is actually equivalent to that of Def. 4.5. This follows from the
fact that all bottom-up rules for 2 are positive and non-recursive, which allows us to
eliminate the Tseitin predicates introduced for the parse tree of 2 by applying the unfolding
procedure from Tamaki and Sato (1984). By iteratively applying this equivalence preserving
procedure, we can reduce all the rules that were generated to approximate 2 to just the
ct
single rule Act
2  (2 ) .

5. Approximating SO(ID)-Satisfiability Problems
Inductive definitions are important for knowledge representation. As argued by Denecker
and Ternovska (2008), inductive definitions are not only used to represent mathematical
concepts, but also the sort of common sense knowledge that is often represented by logic
programs, such as dynamic domains, the closed world assumption, defaults, causality, etc.
97

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Therefore, inductive definitions can make the task of representing a problem in logic considerably easier. An example of this is the use of inductively defined Situation Calculus for
reasoning about actions (Denecker & Ternovska, 2007). Recall that in the introduction we
showed how to represent Tact from Example 1.1 as an inductive definition act :


 Clean(t + 1)  Clean(t).

Clean(t + 1)  W ipe(t).
.


Clean(0)
 InitiallyClean.
The associated conformant planning problem can then be expressed as an SO(ID) satisfiability problem:
W ipe Clean, InitiallyClean : act  Clean(n).
As we will show in more detail in Section 7, a general conformant planning problem can
be seen as a satisfiability problem of the form
 F : (act  init )  (prec  goal ),
AI
where the predicates A represent the actions, I the initial fluents and F the other fluents.
The definition act defines how the fluents change in terms of the action, init is a first
order formula about the initial situation, prec describes the preconditions of the actions
and goal the goal. This motivates the extension of our approximation method to formulas
including definitions. However, we do not analyze the general case where definitions may
appear at arbitrary locations in a formula, but instead restrict attention to formulas of the
form
P Q : (  1 )  2 ,
where  is a definition such that Def ()  Q and 1 and 2 are FO formulas. Even
though these restrictions are not strictly necessary, they allow us to keep the technical
details relatively simple (in particular, we avoid the need for approximation rules that infer
that a definition as a whole is certainly true/false), while still covering the way in which
definitions are typically used: under the assumption that all predicates indeed are what the
definition  and the formula 1 say they should be, 2 then states what properties they
should satisfy.
To extend our approximative method to (  1 )  2 satisfiability problems, we
need a syntactic representation (i.e., an approximative definition) that describes sound
inferences that can be made from the definition in a three-valued context. In this section
we propose two ways to obtain such an approximative definition, and accordingly, two ways
to approximate (  1 )  2 satisfiability problems. Before we can continue, we first
need to recall some more preliminaries.
5.1 Preliminaries on the Well-founded Semantics for Inductive Definitions
Earlier, we defined the model of a positive inductive definition given a two-valued interpretation for the open predicates. From here on, the inductive definitions are no longer only
positive definitions, so the model of a definition can no longer always be computed as the
least fixpoint of the immediate consequence operator introduced in Section 2. Moreover,
98

fiAn Approximative Inference Method for SO

in what follows we want to use inductive definitions together with four-valued information
about the open predicates (for example, information obtained through propagation on a
first order theory). Therefore, we now recall (see, e.g., Denecker & Ternovska, 2008) how to
define the well-founded model of a non-monotone inductive definition  (that is, negation
in the body of rules is allowed), given some four-valued information O about its open predicates, which we denote by W F MO (). In order to do this, we first need to define some
additional concepts. Recall that P denotes the body of the unique rule with predicate P
in the head.
Definition 5.1 (Operator TO ). For a definition  and a given (potentially 4-valued)
Open()-interpretation O, we define the operator TO on 4-valued Def ()-interpretations
with the same domain as Open() such that TO (I) = J iff for each defined predicate P/n
and n-tuple d  Dn , it holds that
 = O+I [d]

P J (d)
P
Recall that in the preliminaries we defined the isomorphism  that maps a pair of
interpretations (I, J) to the corresponding four-valued interpretation I.
Definition 5.2 (W F MO ()). We define the well-founded model of  in O as the 4-valued
O,
interpretation  (I, J) such that (I, J) is the maximal oscillation pair of the operator ST
O
O
where ST is the operator J(lf p(K(T (K, J)1 )). I.e., (I, J) is the least precise pair of
2-valued interpretations such that
O
O
I = ST
(J) and J = ST
(I).

Some explanation is in order. First look at the operator K(TO (K, J)1 ). This operator takes a Def ()-structure K, turns it into a 4-valued one by combining it with J,
applies the operator TO , and projects the result on its first argument. We can see that
K(TO (K, J)1 ) = L iff for each defined predicate P/n and n-tuple d  Dn , it holds that
 = t iff (P [d])
 +(O1 +L)(O2 +J) = t
P L (d)
In other words, positive occurrences of atoms are evaluated in O1 + L, negative occurrences
in O2 + J. For each J, this operator K(TO (K, J)1 ) is monotone, and therefore has a
O now maps J to this least fixpoint. It can be proven that
least fixpoint. The operator ST
this operator is antimonotone, and therefore has a maximal oscillation pair. The definition
O is a nonof the well-founded model as the maximal oscillation pair of the operator ST
constructive definition. This maximal oscillation pair can be constructed by iterating the
following operator, starting from the least precise interpretation I that extends O, until it
reaches its least fixpoint.
O
Definition 5.3 (Stable operator ST O
 ). We define the operator ST  on pairs of interpretations as:
O
O
ST O
 (I, J) = (ST (J), ST (I)).

The stable operator is monotone w.r.t. the precision order p on pairs of interpretations
and its fixpoints therefore form a complete lattice. The fixpoints of this operator are called
99

fiVlaeminck, Vennekens, Denecker & Bruynooghe

the four-valued stable fixpoints of , and the least precise of these fixpoints is precisely the
well-founded model of  given O.
We can now define the semantics of inductive definitions in the general case. The
reader can easily verify that this indeed generalizes the definition of M odO () for positive
definitions we gave in Section 2.2.
Definition 5.4 (Satisfaction relation for definitions). I |=  iff (I|Def () , I|Def () ) is the
well-founded model of  in I|Open() .
Note that when the definition  has a three-valued well-founded model for every possible
interpretation of the open predicates Open(), the definition has no model (i.e. there
does not exists an interpretation I such that I |= ). We call a definition total if it has
a two-valued well-founded model for every possible two-valued interpretation of its open
predicates.
The above definitions generalize in a rather obvious way the standard well-founded
semantics of propositional logic programs and are strongly linked to the stable semantics (Gelfond & Lifschitz, 1988). In the case of a propositional logic program , where
Open() = {}, the operator K(T (K, J)1 ) is nothing else than the immediate consequence operator TJ of the Gelfond Lifschitz reduct J of , and the operator that maps
J to lf p(K(T (K, J)1 ) is the stable operator of . As shown by Van Gelder (1993), its
maximal oscillation pair is indeed the well-founded model of .
5.2 Approximating SO(ID)-Satisfiability Problems
Assume we have a formula , where  is an FO(ID) formula instead of an FO. The
concepts of witness (Definition 4.1) and sound approximation (Definition 4.2) can straightforwardly be generalised for  being a FO(ID) formula. This allows us to develop two
approaches. The first one, in Section 5.2.1, replaces the definition by its completion and
then applies the method of Section 4. However, the completion can be weaker than the
definition. Therefore, in Section 5.2.2, we develop another approach that constructs an
approximation for the conjunction of a definition with a FO formula.
5.2.1 Using the Completion of a Definition
Our first approach is based on the use of the completion (Clark, 1978). The completion
of a definition  is the conjunction of the equivalences x P (x)  P (x) for all predicates
P  Def (), where P (x) is the body of the unique rule with P in its head. A useful
property is that each definition  implies its completion compl(). Moreover, if  is nonrecursive, then the two are actually equivalent. Replacing the definition by its completion
in (  1 )  2 we obtain the formula (comp()  1 )  2 . As every model of  is
a model of comp(), every model of (comp()  1 )  2 is a model of (  1 )  2
and every witness of the  (compl()  1 )  2 satisfiability problem is a witness of the
 (  1 )  2 satisfiability problem. Hence we can use the results of Section 4 and
formulate the following proposition.
Proposition 5.1. The formula APP 
BU ((compl()  1 )  2 ) is a sound approximation
of P Q(  1 )  2 .
100

fiAn Approximative Inference Method for SO

The disadvantage of using the completion is that no matter how complete the approximation method defined in Definition 4.4 is, it will never be able to infer something that
follows from  but not from compl(). For instance, the inductive definition {P  P }
entails P , but its completion P  P does not.
Denecker and Ternovska (2008) have proven that, in addition to non-recursive definitions, a class of recursive definitions are equivalent to their completion. In particular, this
is the case for definitions over a strict well-founded order 2 . We can therefore replace
those definitions by their completion without losing precision. The theory Tact in Example
1.1 is actually the completion of the definition act . Since act is a recursive definition
over a strict well-founded order (we can make use of the time argument in the predicates
to construct such a well-founded order), act and Tact are equivalent.
The Gaspipe conformant planning problem (Son et al., 2005), on the other hand, uses
a dynamic domain for which the completion does not suffice. Summarized, the objective
of this conformant planning problem is to start a flame in a burner which is connected to
a gas tank through a pipe line. The pipe line consists of sections connected to each other
with valves. When a valve is opened with gas on one side and not on the other, the gas
will spread as far as possible. This can be formalized by an inductive definition of the
reachability relation on the pipe line:
(
)
x, t Gas(x, t)  y Gas(y, t)  v Connected(x, y, v)  Open(v, t).
x, t Gas(x, t)  T ank(x).
Such reachability definitions are not equivalent to their completion. Therefore, the approximative method presented in this subsection will not work. The problem with the completion
in this case is that it does not correctly minimize the defined predicates in the presence of
recursion, which would allow models in which a loop in the pipe line is filled with gas even
when it is not connected to a tank. What is missing, therefore, is the unfounded set reasoning that allows the well-founded semantics to correctly minimize the defined predicates.
5.2.2 Using a Certainly True/Possibly True Approximation
The approximative definition Approx () used in Section 4 has the nice property that it
defines, for each subformula of  (including  itself), whether it is certainly true or certainly
false. It was this property that allowed us to find witnesses by simply asserting that Act

had to hold according to this definition. If we want to apply the same method to formulas
 that contain a definition , we have to construct an approximative definition that defines
whether each of the subformulas of  (including  itself) is certainly true or certainly
false. In Section 5.2.1, our naive method managed to do this by simply replacing  by its
completion. We now want to improve on this method by constructing an approximation that
also takes into account the unfounded set reasoning that is performed by the well-founded
semantics.
Once we also take this aspect of the well-founded semantics into account, however,
it becomes difficult to define when a definition as a whole is certainly true or certainly
false. Luckily, this is not needed if we stick to our assumption that definitions appear only
in the antecedent of the implication . Indeed, because we approximate implications by
2. An order < is well-founded if there are no infinite descending chains . . . < xn < xn1 < . . . < x1

101

fiVlaeminck, Vennekens, Denecker & Bruynooghe

assuming that their antecedent is certainly true (Definition 4.4), all that we really need
is an approximation of the consequences of a definition. To this end, we will transform
the original definition  into an approximative definition 0 such that the well-founded
model of 0 , given an approximation O of the open predicates of , approximates each
of the well-founded models of  given an interpretation O for the open predicates that is
approximated by O. In other words, we construct an approximative definition 0 whose
two-valued well-founded model encodes the potentially four-valued well-founded model of
the original definition , given a potentially four-valued interpretation for the predicates of
. We therefore again represent a four-valued interpretation of the orginal vocabulary  of
 by a two-valued interpretation of a larger vocabulary 0 . However, instead of introducing,
for each predicate P of , a predicate P ct (P is certainly true) and P cf (P is certainly false),
as we did before, we now introduce predicates P ct and P pt (P is possibly true, i.e., P is not
certainly false). Let ct/pt denote this vocabulary F  {P ct | P  }  {P pt | P  }. For
a four-valued -interpretation I, we define the corresponding ct/pt -interpretation I ct/pt
ct/pt
as the interpretation with the same pre-interpretation as I such that (P ct )I
= {d |
ct/pt
I
pt
I
I



P (d) p t} and (P )
= {d | (P (d) p t)}.
Also, for a -formula , we define the formula ct/pt as the formula that we obtain after
replacing all positive occurrences of a predicate P in  by P ct , and all negative occurrences
by P pt , and finally reducing to negational normal form. It is easy to see that ct/pt can also
be obtained from ct by replacing, for every predicate P , all occurrences of P cf by P pt .
Unlike ct , ct/pt is not always a positive formula as it can contain negations. In particular,
P ct occurs only positively while P pt occurs only negatively. For a subvocabulary   ,
ct/pt

again denotes ct/pt but with both P ct and P pt replaced by P for every predicate
P  . Again, in what follows we will use  to denote predicates that do not need to be
approximated because we have two-valued information about them.
ct/pt

ct/pt

Definition 5.5 (App ()). For a definition , we define App
{Rct  Rpt } where Rct consists of the rules

() as the definition

x(P ct (x)  ct/pt
)

and Rpt consists of the rules
x(P pt (x)  ()ct/pt
)

for every definitional rule x (P (x)  ) in .
We again assume for the rest of this paragraph without loss of generality that  is empty,
ct/pt
and we drop it in the notation of App .
Example 5.1. Consider the following inductive definition.


B  B  A
A  D
Assume  = {}. Then

Appct/pt

 ct
B


 ct
A
=
pt
B


 pt
A





102

B ct  Apt
Dpt
B pt  Act
Dct









.

fiAn Approximative Inference Method for SO

We see that for a three-valued interpretation {D = u}, which translates to {Dct = f , Dpt =
t}, the approximative definition will correctly infer that B ct is false and B pt is true. If we
take {D = f } as an interpretation for the open predicate D, we see that the approximative
definition correctly infers that both B ct and B pt are false. This is an example of unfounded
set reasoning: once A is known to be true, the approximation detects that B could only be
derived from B itself and therefore must be false. This kind of reasoning could not be done
by our previous, completion-based approximation method, since it is only sound w.r.t. the
semantics of the definition itself, and not w.r.t. its weaker completion.
This example also demonstrates why we have to use the vocabulary ct/pt instead of
ct/cf , since the latter would have yielded a definition:
 ct

B
 B ct  Acf 



 ct

A
 Dcf
.
B cf  B cf  Act 



 cf

A
 Dct
For {D = f }, this definition would fail to infer B cf . Intuitively, the reason for this is that
the unfounded set reasoning of the well-founded semantics tries to minimize the extension
of the defined predicates by making as many atoms false as possible. Using the ct/cf
vocabulary, the well-founded semantics of the approximating definition therefore attempts
 as possible, which actually corresponds to maximizing the
to falsify as many atoms P cf (d)
possible extension of the original predicates P , instead of minimizing it as the well-founded
semantics of the original definition does.
Each two-valued interpretation of the double vocabulary ct/pt corresponds to a fourvalued interpretation of the original vocabulary . We again want to establish a link
ct/pt
between the well-founded model of the original definition  and that of App . A complict/pt
cating factor here is that, as the above example shows, the definition App
is no longer
monotone and therefore it is no longer guaranteed to have a two-valued well-founded model.
Because a three-valued interpretation of ct/pt no longer corresponds to even a four-valued
interpretation of the original vocabulary , we can only prove such a correspondence if the
ct/pt
well-founded model of App
is two-valued.
Theorem 5.2. Let O be a four-valued interpretation for the open predicates of a definition
. Appct/pt () has a two-valued well-founded model given Oct/pt if and only if  has a
unique four-valued stable fixpoint given O. Moreover, if Appct/pt () has a two-valued wellfounded model I, then the unique four-valued stable fixpoint of  is the unique interpretation
I for which I ct/pt = I.
Proof. See Appendix D.
This theorem requires that  has a unique four-valued stable model for each four-valued
input interpretation O. This is a stronger requirement than the more common condition of
totality, which only requires a definition to have a two-valued well-founded model given a
two-valued input interpretation O. As the following example shows, this stronger condition
is indeed necessary.
103

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Example 5.2. Consider the following definition:




 A  B.

B  A  C.




C  O  O.
This definition is total, because, for each two-valued interpretation for the open predicate
O, it has ({A}, {A}) as its two-valued well-founded model. However, for the three-valued
interpretation ({}, {O}) (i.e., O is unknown) for the open predicate O, the three-valued
well-founded model ({}, {O, A, B, C}) is not the unique three-valued stable fixpoint, since
({A}, {O, A, C}) is also such a fixpoint. And indeed, we find that
 ct
A





B ct



 C ct
ct/pt
App
() =

Apt



 B pt



 pt
C

 B pt .






 Apt  C ct . 


ct
pt 
 O  O .

 B ct .



ct
pt 
 A  C . 


pt
ct 
 O  O .

does not have a two-valued well-founded model given {Opt }. The easiest way to see this is
to fill in the fact that we know that Opt is t and Oct is f and propagate this information:
 ct

A  B pt .






ct
pt
ct



B  A  C .






 C ct  f  t.



Apt  B ct .








pt
ct
pt


B

A

C
.




 pt

C  t  f .

 ct

A  B pt .






ct
pt



B  A  f .









 ct

A  B pt .


















 ct

A  B pt .




















Apt  B ct .








pt
ct


B

A

t.




 pt

C 


Apt  f . 







pt
ct 


B

A
.




 pt

C 



Apt 








pt
ct


B

A
.




 pt

C 

So, we are left with a loop over negation, which means that Act and B pt will remain unknown
in the three-valued well-founded model ({Apt , C pt }, {Act , Apt , C pt , B pt }) of the definition.
By computing the three-valued well-founded model of  given O, the approximative definition Appct/pt () can produce more precise results than the approximation of compl();
in particular it can detect that atoms in an unfounded set must be false, as illustrated in
Example 5.2 above. To use Appct/pt () in an approximation of an ()  2 -problem,
we still need to show how it can be combined with the approximation Approx () of  to
produce a sound approximation of   . To do this, we need to combine one definition of
ct/cf-predicates with another definition of ct/pt-predicates. We achieve this by first merging
the two definitions and then adding rules that copy information from the one vocabulary
to the other.
104

fiAn Approximative Inference Method for SO

Definition 5.6 (D ). Given a vocabulary , a subvocabulary   , an inductive
definition  and first-order formula . We define D as the following inductive definition.
ct/pt

App

{Ocf

()

Approx ()  {Act
  t}

{Opt  Ocf | for every predicate O  Open() \ }

{P cf  P pt | for every predicate P  Def () \ }

ct
 f , O  f | for every predicate O  Open() \  that does not occur in }

This definition indeed contains both the rules from the approximation of  and the rules
from the approximation of , that is, Appct/pt () and Approx()  {Act
  t}, respectively,
but also a number of extra rules that make a connection between these two approximations.
To approximate a defined predicate Q the approximation of  uses the pair of predicates
Qct and Qpt while the approximation of  uses Qct and Qcf . Hence, a number of extra
rules are needed to transfer information between the predicates Qpt and Qcf . The rules
{Opt  Ocf } transfer information that the approximation of  has derived about the
truth of an open predicate O (by means of Ocf ) to the corresponding predicate Opt of the
approximation of the definition. The rules {P cf  P pt } in turn propagate information
derived about the truth of a defined predicate in the approximation of the definition to the
corresponding predicate P cf of the approximation of . Finally, the rules {Ocf  f , Oct 
f } make sure that Ocf and Oct are defined atoms (instead of open ones) and that their
default value is u. The following proposition relates the well founded model of D with
the models of   .
Proposition 5.3. Given a vocabulary , a subvocabulary  and an FO(ID) formula   .
 (resp. P cf (d)),
 then it holds
Then, for every -interpretation I, if W F MI (D ) |= P ct (d)
 (resp. M |= P (d)).

for every model M of    extending I that M |= P (d)
Proof. See Appendix E.
This proposition is the analogue for inductive definitions of the result that Theorem 3.2
states for FO formulas. One difference between the two results is that the above proposition always assumes that the definition  itself holds, while Theorem 3.2 makes no such
assumption about the FO formula  that is approximated. As discussed in the beginning of
this section, this restriction is not a problem, because of the way in which we approximate
implications and because we only allow definitions to appear in the antecedent. A second
difference is that Theorem 3.2 applies to arbitrary subformulas  of , while the above
 It is, however, an easy corrolary of this proposition
proposition only considers atoms P (d).
that the result in fact holds for each formula  that contains only predicates defined by
 (or  cf (d)),
 then for every model M of   
D , i.e., whenever W F MI (D ) |=  ct (d)
 (resp. M |= (d)).

extending I, it holds that M |= (d)
We introduced the approximation Appct/pt () with the aim of being more complete than
the completion-based approximation. As long as only a single definition  was considered
105

fiVlaeminck, Vennekens, Denecker & Bruynooghe

in isolation, we succeeded in this goal. However, now that we have also incorporated the
additional formula , this is no longer the case. For instance, consider the following FO(ID)
theory:

	
Q  P  Q.
Here, the approximation D cannot derive that P is certainly true, simply because the
ct/pt-approximation Appct/pt () does not contain rules for head-to-body propagation, i.e.,
there are no rules to infer something about the body of a definitional rule, given information
about its head. By contrast, the approximation of the completion does contain such rules
and therefore has no problems reaching this conclusion. This motivates us to not just use
D but to use D(compl()) instead. Because each definition implies its completion,
this is sound.
To obtain a sound approximation for an SO(ID) formula P Q  with  = ( 
)  2 , we now just need to plug in our approximation D(compl()) for  into a
suitable SO(ID) formula, similar to the one we defined in Definition 4.4 for an SO
formula P Q 1  2 . A small complication, however, is that, as discussed previously,
cf
our approximation of a definition does not define predicates Act
 and A that tell us when
the definition  as a whole is certainly true or certainly false. Therefore, we can no longer
use our normal approximation of when the entire implication  is certainly true. Before
we present the approximation for SO(ID), let us first introduce a reformulation of our
original approximation for SO, that avoids the use of this Act
.
Proposition 5.4. For an SO formula F = P Q : , where  is of the form 1  2 ,
the approximation defined in Definition 4.4, i.e., the formula
ct
P R : (Approx (1  2 )  {Act
1  t})  A

is equivalent to
cf
ct
P R : (Approx (1 )  Appox (2 )  {Act
1  t})  (A1  A2 )

Proof. This is obvious from the fact that the difference between Approx (1  2 ) and
Approx (1 )  Appox (2 ) is precisely a set of rules that ensure that Act
 is equivalent to
ct
Acf
1  A2 .

Our approximation for SO(ID) now essentially consists of just replacing Approx (1 )
compl()
cf
 {Act
and Acf
 in the above form.
1  t} and A1 respectively by D
Proposition 5.5. Given an SO(ID) formula F = P Q (  )  2 . We define
APP wf (F ) as the following SO(ID) formula.
ct
P R : (Dcompl()  Approx (2 ))  (Acf
  A2 ).

Then APP wf (F ) is a sound approximation of F .
compl()

In some cases, the approximating D
instead of D will not gain us anything. For instance, consider an P Q(  )  2 problem, where  only contains open
predicates of  (as is the case for the conformant planning problems we consider in the next
106

fiAn Approximative Inference Method for SO

sections). In this case, we will never need head-to-body propagation, and therefore D
compl()
is just as complete as D
, and we are therefore better off using the former.
As was the case for our approximation method for SO , here as well not all rules from
the definition in APP wf are necessary. Indeed, only the bottom-up rules from Approx (2 )
are needed, and can be unfolded into a single rule. Therefore, below we define two more
variants of Definition 5.5.
Definition 5.7 (APP wf
BU (F )). Given an SO(ID) formula F = P Q (  )  2 .
wf
We define APP BU (F ) as the following SO(ID) formula,
cf
ct
P R : (Dcompl()  ApproxBU
 (2 ))  (A  A2 ),

and we define APP wf
BU,U nf (F ) as the following SO(ID) formula,
ct
cf
ct
P R : (Dcompl()  {Act
2  (2 ) })  (A  A2 ).

6. Experimental Evaluation
In this paper we have seen a number of methods to approximate SO and SO(ID)
satisfiability problems. In this subsection, we explore, through a number of experiments,
how we can use these methods to solve practically useful problems as fast as possible. We
performed these experiments on a number of conformant planning benchmarks from the
paper of Son et al. (2005). As we show in Section 7, all these benchmarks are of the
form F =   , where  is a stratified definition, and is therefore equivalent to its
completion. Therefore, F is equivalent to the SO formula  compl()  , which
we denote by F cp . All experiments were run on a dual core 2.4 Ghz CPU, 2.8 Gb RAM
Linux machine, using the IDP model expansion system for FO(ID) (Marien et al., 2006).
A time-out of twenty minutes was used.
A first question we want to answer is whether for these definitions, the completion
based approximation is faster than the ct/pt approximation. It is not hard to see that, even
though Approx(compl()) is linear in the size of the parse tree of compl(), this definition
may contain more rules than Appct/pt (), and moreover, these rules may contain a lot of
recursion. This can pose a challenge for current solvers, and suggests that it is likely to be
more efficient to use the ct/pt approximation for definitions. The first column in Table 2
shows times for using the completion of the definition , that is, APP  (F cp ), while for the
second column, the ct/pt-approximation of  was used, that is, APP wf (F ). As expected,
the ct/pt-approximation was consistently faster.
Table 2 also compares solving times of the full completion-based approximative definition
cp
(in the first column) with the approximation APP 
BU (F ) (Def. 4.5), from which the topdown propagation rules for  have been removed (third column). We see that in the BT
and BTC benchmarks we get an order of magnitude improvement. The fourth column of
cp
Table 2 shows timings for the unfolded approximation of 2 , APP 
BU,U nf (F ), in which the
intermediate Tseitin predicates have been removed (Def. 4.6). We see that this unfolding
consistently provides a speed-up.
These results suggest that combining the above techniques, that is, using the ct/pt
approximation for  and the unfolding of the bottom-up approximation of 2 together, will
107

fiVlaeminck, Vennekens, Denecker & Bruynooghe

APP  (F cp )

APP wf (F )

cp
APP 
BU (F )

cp
APP 
BU,U nf (F )

APP wf
BU,U nf (F )

BT(2,2)
BT(4,2)
BT(6,2)
BT(8,4)
BT(10,4)

0,151
3,404
38,93
-

0,109
3,493
14,76
-

0,115
0,312
0,876
32,91
-

0,065
0,153
0,409
1,774
-

0,031
0,064
0,113
0,462
1,643

BTC(2,2)
BTC(4,2)
BTC(6,2)
BTC(8,4)

0,210
-

0,131
-

0,171
40,081
-

0,116
8,408
-

0,037
0,109
0,335
41,894

0,390
1,101
6,597
31,275
-

0,026
0,036
0,067
0,120
0,231

0,507
1,250
8,995
42,583
-

0,473
1,266
6,997
28,387
-

0,049
0,052
0,128
0,396
1,530

7,023
-

0,374
-

5,217
-

2,792
-

0,100
0,358
6,650
193,290
2485

Problem

Domino(100)
Domino(200)
Domino(500)
Domino(1000)
Domino(2000)
Ring(2)
Ring(4)
Ring(6)
Ring(8)
Ring(10)

Table 2: The first column gives the name of the benchmark and the other ones different
execution times. The second column gives the execution time for the approximation of the
completion and the third for the cp/pt approximation. The fourth and fifth column use
variants of the completion approximation. For the fourth column, the top-down rules for
2 are removed while in addition, for the fifth column, the remaining bottom-up rules are
unfolded. The last column combines the cp/pt approximation with both other changes. -
means the execution was interrupted after 20 minutes.
give us the fastest way of approximating (  1 )  2 satisfiability problems. Indeed,
this is what formula APP wf
BU,U nf (F ) (Definition 5.7) does, and the results of this method
are shown in the last column of Table 2. As expected, this is by far the fastest method.

7. Applications and Related Work
In the literature, many examples can be found of approaches that perform some kind of
approximate reasoning about the models of a logical theory. Often, these approaches, which
are specific to the problem at hand, seem to boil down to an instantiation of the general
methods presented here. In this section we give some examples.
7.1 Conformant Planning
In general, a conformant planning problem is a planning problem in a non-deterministic
domain where the initial state may be not fully known. The goal is to come up with a
plan (i.e., a sequence of actions) that is nevertheless guaranteed to work. This is a hard
problem: the decision problem of deciding whether a conformant plan with a fixed length
k exists is P2 -complete3 (Baral, Kreinovich, & Trejo, 2000; Turner, 2002). Therefore, one
3. For planning domains where the executability of actions in a given state cannot be determined polynomially, this is even P
3 (Turner, 2002)

108

fiAn Approximative Inference Method for SO

typically attempts to solve it approximately. In this section, we show how we can apply our
approximative methods to solve conformant planning problems.
Example 7.1. Let us consider the Clogged Bombs in the Toilet domain (McDermott, 1987;
Son et al., 2005). There are a number of packages and a toilet. Each of the packages may
contain a bomb which can be disarmed by dunking the package in the toilet. Dunking a
package into a toilet also clogs the toilet and we cannot throw a package in a clogged toilet.
Flushing the toilet unclogs it. The effects of the actions on the fluents are modeled by the
following definition act , and the preconditions by the conjunction prec of sentences in
Tprec .

act



Clogged(0)  Init Clogged.





 Clogged(t + 1)  p : Dunk(p, t)  (Clogged(t)  F lush(t)).

=


Armed(p, 0)  Init Armed(p).






Armed(p, t + 1)  Armed(p, t)  Dunk(p, t).

Tprec

 p t : Dunk(p, t)  Clogged(t).
( p t : Dunk(p, t)  F lush(t)).
=
 p p2 t : Dunk(p, t)  Dunk(p2 , t)  p = p2 .
 p t t2 : Dunk(p, t)  Dunk(p, t2 )  t = t2 .

Now consider the following regular planning problem: given a completely specified initial
situation (specified by a formula init ), find a plan such that all packages are disarmed. We
can formulate this problem as the following formula:
A, F , I : act  prec  init  (t p Armed(p, t)),
where with A, we denote the action predicates {Dunk/2, F lush/1}, with F we denote
the fluent predicates {Armed/2, Clogged/1} and with I we denote the predicates used to
describe the initial situation {Init Clogged/0, Init Armed/1}. Now imagine that initial
situation is not specified, and we want to find a plan that works for all possible initial
situations, in other words a conformant plan. We can formulate the problem of finding such
a plan as follows.
A F , I : act  (prec  t p Armed(p, t)).
All this can be formalized in general as follows.
Definition 7.1 (Conformant planning). Let  be a vocabulary, consisting of a set of
predicates A, denoting actions, I, denoting initial fluents, and F denoting fluents. Let
Tact be an FO(ID) theory and Tinit , Tprec and Tgoal FO theories, all over , such that Tact
specifies the values of the fluents given an interpretation for the actions and initial fluents,
Tinit is a theory specifying the initial situation, Tprec contains preconditions for the actions,
and Tgoal specifies the goal of the planning problem. With act we denote the conjunction
of the sentences and possibly definitions in Tact and similarly for the other theories. The
problem of conformant planning is then to decide the satisfiability of the following formula:
A I F : (act  init )  (prec  goal ).
109

(6)

fiVlaeminck, Vennekens, Denecker & Bruynooghe

AR :


Cloggedct (0)



ct (t + 1)

Clogged




Armedct (p, 0)




Armedct (p, t + 1)




Cloggedpt (0)




Cloggedpt (t + 1)




Armedpt (p, 0)




Armedpt (p, t + 1)




Init Cloggedct




Init
Armedct (p)

Init Cloggedpt


Init Cloggedcf




Init
Armedpt (p)




Armedcf
Init



cf (t)

Clogged



cf (p, t)

Armed




Act

2

































Init Cloggedct .
p : Dunk(p, t)  (Cloggedct (t)  F lush(t)).
Init Armedct (p).
Armed(p, t)  Dunk(p, t).
Init Cloggedpt .
p : Dunk(p, t)  (Cloggedpt (t)  F lush(t)).
Init Armedpt (p).
Armed(p, t)  Dunk(p, t).
f.
f.
Init Cloggedcf .
f.
Init Armedcf (p).
f.
Cloggedpt (t).
Armedpt (p, t).
pt : Dunk(p, t)  Cloggedcf (t)
 (pt : Dunk(p, t)  F lush(t))
 p1 p2 t : Dunk(p, t)  Dunk(p2 , t)  p1 = p2
 pt1 t2 : Dunk(p, t1 )  Dunk(p, t2 )  t1 = t2
 tp : Armedcf (p, t).














































































Act
2 .

Figure 4: The complete approximation of the Clogged Bombs in the Toilet example.
In words, there must be a plan (A), such that no matter how the nondeterministic
 F ), as long as the specification of the effects of the actions (act )
aspects turn out (I,
and the (partial) specification of the initial situation (init ) are obeyed, the plan will be
executable (prec ) and achieve the goal (goal ).
Formula 6 is now exactly of the form we assumed above, and we can thus use one of our
methods to approximate conformant planning problems.
Example 7.1. (continued) Continuing the Clogged Bombs in the Toilet example, by
using the ct/pt-approximation for the definition, and unfolding the constraint (prec 
t p Armed(p, t))ct , we get the approximating SO formula APP wf
BU,U nf (Definition 5.7),
shown in Figure 4, where R are the ct- and cf-predicates introduced by the approximation
method.
The result of applying our general approximation method to a conformant planning
problem, as specified by Tact , Tprec , Tgoal and Tinit as above, is very similar to the approximation of an AL action theory by a logic program as in the work of Son et al. (2005).
However, there are some small differences in the details that make it difficult to formally
compare the two. Nevertheless, for all experiments discussed in this section, our method
always finds a correct solution (unless it times out), as does the method of Son et al.
Moreover, the two approaches also found these solutions in comparable execution times.
In more detail, Table 3 presents the following results. We implemented a conformant
planner by iteratively calling the IDP model generator for FO(ID) (Marien et al., 2006)
on our approximation, giving it an increasing number of timesteps until either a plan is
110

fiAn Approximative Inference Method for SO

Problem

IDP

Smodels

Cmodels

BT(2,2)
BT(4,2)
BT(6,2)
BT(8,4)
BT(10,4)

0.438
0.513
1.050
1.55
2.80

0.199
0.219
0.587
30.9
-

0.145
0.212
0.425
2.39
5.80

BTC(2,2)
BTC(4,2)
BTC(6,2)
BTC(8,4)

0.273
0.844
1.60
43.7

0.136
0.412
3.88
-

0.139
0.389
1.23
102

Cleaner(2,2)
Cleaner(2,5)
Cleaner(2,10)
Cleaner(4,2)
Cleaner(4,5)
Cleaner(4,10)
Cleaner(6,2)
Cleaner(6,5)

0.644
1.57
1.55
2460
8.30
-

0.226
72.5
13.8
-

0.376
1.36
1.13
6.16
-

Domino(100)
Domino(200)
Domino(500)
Domino(1000)
Domino(2000)

0.176
0.181
0.212
0.236
0.339

0.096
0.114
0.324
0.618
1.22

0.090
0.151
0.354
0.660
1.32

0.655
1.56
7.35
157
1537

0.285
2.092
19.1
-

0.296
0.937
3.542
19.860
232

Ring(2)
Ring(4)
Ring(6)
Ring(8)
Ring(10)

Table 3: Comparison IDP vs Cmodels vs Smodels

found or a maximum number of timesteps is reached. We then compared this planner to
the CPASP conformant planner (Son et al., 2005), using the same experimental setup as
in Section 6. CPASP takes an action theory in the action language AL, and encodes an
approximation of the transition diagram corresponding to that action theory, by means of
an answer set program. Then any answer set solver can be used to find conformant plans.
As Son et al., we used as the ASP solver behind CPASP both CModels (E. Giunchiglia &
Maratea, 2011) and SModels (Niemela, Simons, & Syrjanen, 2000). As Table 3 shows, the
combination of our approximation and the IDP system is comparable to, but overall slightly
worse, than the combination of CModels and Son et al.s approximation. When compared
to the same approximation given to SModels, our method tends to be a bit better. These
results are in line with results from the ASP competition (Denecker et al., 2009) concerning
the performance of SModels, CModels and IDP in general, suggesting that, for conformant
planning, our approximation and that of Son et al. are of comparable quality.
Another approximative method for solving conformant planning problems can be found
in the work of Palacios and Geffner (2009). In their paper, the authors consider conformant
planning problems, specified in the language Strips extended with conditional effects and
negation. They define a transformation K0 that transforms such a conformant planning
problem into a classical planning problem in a sound but incomplete way. For each fluent
literal L in the conformant planning specification, two new literals KL and KL are created,
111

fiVlaeminck, Vennekens, Denecker & Bruynooghe

denoting that L is known to be true, resp. known to be not true, and the initial situation,
action preconditions and effects are translated into an initial situation, preconditions and
effects with reference to these new knowledge literals. It is not hard to verify that our
approximation method generalizes this transformation: if we take an SO encoding of a
conformant planning problem P , the SO approximation obtained by our method can be
interpreted as a classical planning problem in the ct/cf vocabulary. This planning problem
will exactly be the planning problem specified by K0 (P ) (i.e., the action preconditions and
effects correspond), apart from the initial situation. The K0 transformation does not do
propagation on knowledge about the initial situation: given an initial situation I (specified
as a set of clauses), then K0 (I) consists of only those literals KL where L is a unit clause
in I. This means that, e.g., for an initial situation I = {P  Q, P }, K0 (I) will not include
the literal KQ, while our method will be able to infer that Qct holds (which means our
approximation method will be more complete than the K0 transformation).
Being a general method, ours does not only allow for solving conformant planning problems, but also allows for approximating a number of related problems in temporal domains.
Consider, for example, the following problem: Given that a certain action A happens at
timepoint t, will this certainly lead to a property  being true ? This can be formalized as
the following SO satisfiability problem, to which our method applies again.
AIF : ((act  init  prec  A(t))  ).
This formula is true if for all possible plans in which A(t) happens, the property  holds.
A variant on this problem is the so-called projection problem: Given that we exactly know
which actions happened (we can thus assume that the preconditions were satisfied), does
the property  hold ? In order to formulate this problem as a SO satisfiability problem, we
need to express that these and only these actions happened. This can be done, for example,
by using an inductive definition A . The projection problem can then be expressed as the
AIF : ((act  init  A )  ) satisfiability problem. Another variant is the following
problem: If the property 1 holds for a certain plan, does property 2 also hold?, which
can be expressed as the AIF ((act  init  prec  1 )  2 ) satisfiability problem.
7.2 Querying and Reasoning in Open Databases
Approximate methods similar to ours have been used in the context of databases without
complete information, in particular in databases without CWA, such as open databases
(Baral et al., 1998; Liu & Levesque, 1998) or databases that make forms of local closed
world assumptions (Denecker et al., 2010; Doherty et al., 2006). In most of these papers
the goal is to compute certain or possible answers to queries. Because this task has a
high complexity (from CoNP for a locally closed database without integrity constraints to
possibly P2 for databases with first-order constraints - assuming a given finite domain),
approximate methods are presented which translate an FO query into an approximate FO
or FO(FP)4 query that can be solved directly against the database tables using standard
(polynomial) query methods.
The method presented in this paper can provide a similar functionality. Let DB be a
set of ground literals, representing an incomplete database. Let  be a background theory:
4. FO(FP) is the extension of FO with least and greatest fixpoint constructs.

112

fiAn Approximative Inference Method for SO

it may contain integrity constraints, view definitions (datalog view programs are a special
case of FO(ID) definitions), local closed world statements expressed in FO, etc. For a given
 holds in all Herbrand models
FO query Q [x], the goal is to find all tuples d such that Q [d]
of DB  . The problem of deciding whether a given tuple d is an answer corresponds to
the satisfiability problem of the formula

R(DB    Q [d]),

(7)

and we can directly use our approximation method on this problem. While this allows us
to answer yes/no queries as well as to decide whether a given tuple d is a certain answer
to a query, our approximation method does not directly provide a method to compute (an
approximation of) all such tuples.
However, let us look at the following SO satisfiability problem.
R0 : DDB  ApproxBU (Q [x]),
It looks very much like our approximation of (  1 )  2 satisfiability problems (as
formulated in Proposition 5.5). We again have the definition DDB approximating the
database DB and background knowledge  (note that  possibly contains definitions), and
the bottom up evaluation of the query, only now the constraint Act
Q has been dropped.
The definition DDB  ApproxBU (Q [x]) consists of rules describing propagations allowed by the database and the theory , and rules defining the predicate symbol Act
Q , where
AQ is the Tseitin predicate representing the query Q [x]. In the unique Herbrand model
of this definition, the interpretation of Act
Q contains those tuples for which our propagation
can derive that they certainly satisfy the query  a sound approximation of the full set of
answers!
In the work of Denecker et al. (2010), a locally closed database LCDB is assumed. Such
a locally closed database consists of a standard database DB, i.e. a set of atoms, together
with a set of local closed world assumptions LCWA(P (x), [x]). Each of these LCWA
statements expresses that the databases knowledge about P is complete for those tuples x
 is therefore true if it is in DB and it is false
that satisfy the formula [x]. An atom P (d)
 holds in the domain
if it is not in DB and there is a LCWA(P (x), [x]) such that [d]
of discourse; otherwise it is unknown. The authors then present an approximate reasoning
method for query answering in locally closed databases and show how this approximate
query answering can be formulated as a fixpoint query. Basically, this boils down to the
following. One constructs the following definition




...






 P ct (x)  P (x)

,
LCWA =
 P cf (x)  P ct (x)  ct


P [x]






...
for every relation P and every local closed world assumption LCWA(P (x), [x]). Although
the authors do not phrase it in this form, their method for finding an approximation of the
certain answers to a query Q [x] actually boils down to solving the following satisfiability
problem:
R0 : DB  CW A(DB)  LCWA  ApproxBU (Q [x]),
113

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Here R0 denotes all predicates and auxiliary predicates occurring in the body of the existential formula. With CW A(DB), we denote the formula expressing closed world assumption
for the database DB. The presence of this closed world assumption might seem strange at
first sight, since the whole idea behind locally closed world databases is to not assume CWA
per default. However, in order to correctly apply the local closed world assumptions, we
need an exact specification of what is in the database and what is not, and this is precisely
what is expressed by DB  CW A(DB). Indeed, given DB  CW A(DB), LCWA can be
seen as an approximative definition of what is certainly true and false in the context of the
locally closed world assumptions. Again the predicate Act
Q will contain an approximate
answer to the query Q [x], i.e., a lower bound on all the tuples for which the query Q [x]
is certainly true. Similarly, the predicate Acf
Q will contain a lower bound on all the tuples
for which the query is false.
A limitation of the approach by Denecker et al. is that they extend the above method
for only one type of integrity constraints, namely functional dependencies. The way these
functional dependencies are handled is by extending LCWA with extra propagation rules
taking these functional dependencies into account. By contrast, our more general method
can be used to easily extend this to arbitrary integrity constraints. This works as follows.
Let Tint be a set of first-order integrity constraints. We can then approximate the problem
of finding certain queries by the following satisfiability problem.
BU
ct  t}  DB  CW A(DB)  LCWA  Approx
(Q [t]).
R0 : Approx(Tint )  {ATint

Again, the predicate Act
Q will contain an approximate answer to the query Q [x].
Doherty et al. (2006), propose yet another approach to asking queries to an incomplete
database. The authors use the term approximate database to denote a database, consisting
of two layers: an extentional and an intensional layer. Both of these layers have an external
representation towards the user, and an internal representation.
The extentional database consists of positive and negative literals, and is internally
stored as a classical database, using the Feferman transformation. For example, the extentional database (EDB), as entered by a user,
Color(Car1, Black), Color(Car1, Red), Color(Car2, Red),
is internally stored as
Colorct (Car1, Black), Colorcf (Car1, Red), Colorct (Car2, Red).
The intentional database consists of rules to infer additional information from the facts in
the EDB. The user can write down rules of the form ()P1 (x1 ). . .()Pn (xn )  ()P (x)),
which are then internally stored as (()P1 (x1 ))ct  . . .  (()Pn (xn ))ct  (()P (x)))ct . An
example of such a IDB rule is the following rule
Color(x, y1 )  y1 6= y2  Color(x, y2 ),
which is internally stored as
Colorct (x, y1 )  y1 6= y2  Colorcf (x, y2 ).
114

fiAn Approximative Inference Method for SO

To evaluate a query, a naive algorithm based on exhaustively applying all rules on the EDB
is used.
The rules in the IDB resemble our IN F formulas in the sense that both describe valid
inferences that can be made based on incomplete information. The internal representation
of the IDB is indeed similar to our representation of IN F formulas as definitional rules.
However, a key difference is that in the approach of Doherty et al., when a user wants to add
a property  to the database (e.g., a car can only have one color), he has to write down all
inferences that are valid according to that property, while in our approach these inference
rules are automatically generated from the property itself. Manually writing down all valid
inferences sanctioned by a property is not an easy task. For example, take the property a
car has to be inspected if and only if it was suspect and black from the paper by Doherty
et al.. This can be expressed in FO as the formula  = c(Suspect(c)  Color(c, Black) 
Investigate(c)). While, in our method, Approx() constructs an approximation of all valid
inferences that can be made from this formula, the user has to write down the following
rules in Doherty et al.s approach:
Suspect(c)  Color(c, Black)  Investigate(c)
Suspect(c)  Investigate(c)  Color(c, Black)
Suspect(c)  Investigate(c)
...
Our method therefore generalizes the work of Doherty et al. by deriving these rules automatically from a general first-order theory.
Liu and Levesque (1998) propose another type of reasoning in open databases. They
only consider a simple form of first order knowledge bases, called proper knowledge bases.
An interesting feature of these knowledge bases is that it is easy to obtain a complete
characterization of what is certainly true, resp. certainly false. In our terminology, that
 if and only if  |= P ct (d)

means that one can construct a definition , such that KB |= P (d)
cf

and KB |= P (d) if and only if  |= P . It holds that every two valued extension of the
three valued interpretation encoded by  is a model of the KB. Then Levesque et al. use
an evaluation procedure based on the three-valued Kleene-evaluation to check whether a
query holds in the knowledge base. As mentioned earlier, they also define a normal form
N F for queries, for which they prove that the Kleene-evaluation is complete. Our work
extends their work, in the sense that we can take a general first order knowledge base
and approximately solve queries, as we have shown above. Of course, since in general we
can no longer guarantee a complete characterization of what is certainly true/false, we can
no longer guarantee completeness, even if the query is in the normal form N F. Another
difference between the work of Liu and Levesque and our work here, is that they assume a
fixed countable infinite domain, while we assume a fixed finite domain. While this is indeed
a theoretical difference, in practice it does not make any difference, since their evaluation
method only considers a finite set of domain elements that can be determined up-front.

8. Conclusions and Future Work
Even if a problem is computationally hard in general, specific instances of it might still
be solved efficiently. This is why approximate methods are important: they cannot solve
115

fiVlaeminck, Vennekens, Denecker & Bruynooghe

every instance, but the instances they can solve, they solve quickly. In computational
logic, hard problems arise quite readily. It is therefore not surprising that the literature
contains numerous examples of algorithms that perform approximate reasoning tasks for
various logical formalisms in various specific contexts. Since many of these algorithms share
common ideas, it is a natural question whether they can be seen as instances of some more
general method for a more general language.
This paper presents such a method. We start from the propagation method for FO()
developed by Wittocx, Marien, and Denecker (2008) and its symbolic expression (Wittocx,
2010) and generalize this to a method for approximating the P2 -complete SO(ID) satisfiability problem by solving an NP problem. Importantly, this is a syntactic method that
transforms the SO(ID) formula into an SO(ID) formula. This affords us the freedom
to use any off-the-shelf solver for such a language to perform the approximative reasoning.
Moreover, it also makes it significantly easier to update the method by adding (or removing)
specific propagations.
Since our method is an approximation, it is necessarily incomplete. Nevertheless, our
experiments have shown that, in practice, it often does manage to find a solution. An
interesting topic for future work is to determine classes of problems, for which our method
can be shown to be complete.
In summary, the contributions of this paper are that (1) we have extended the logical
representation describing the propagation process to a general method for approximating
SAT (SO) problems; (2) we have shown how to approximate inductive definitions, and use
this to approximate a class of useful SAT (SO(ID))-problems; and (3) we have examined
how existing approximation methods fit into our general framework.

Acknowledgments
This work is supported by Research Foundation - Flanders FWO-Vlaanderen, projects
G.0489.10 and G.035712, and by Research Fund KULeuven, project GOA/08/008. Hanne
Vlaeminck is supported by IWT-Vlaanderen.

Appendix A. An Example of an Approximation
Figure 5 shows the full approximation of act as in Example 1.1.

Appendix B. Proof of Theorem 3.1
Proof. First, remark that Feferman (1984) showed that the four-valued evaluation of a
formula  in an interpretation I can be simulated by computing the standard two-valued
evaluation of ct and cf in I tf . It is easy to verify that the bottom-up rules in Approx()
inductively encode this evaluation. We split the proof in two parts. First we assume that I
is three-valued. We show that in this case only the bottom-up rules are used, i.e., leaving
out the top-down rules does not change the model of the definition. This proves the first
part of the theorem, and together with the above remark also proves the second part of
the theorem for the case that I is three-valued. Then, all that is left to prove, is that the
second part of the theorem also holds for four-valued I.
116

fiAn Approximative Inference Method for SO

























































































































































































Act
act
Acf
act
Acf
act
Act
0
Act
8
Acf
0
Acf
8









Act
0
Acf
0
Act
1 (t)
Acf
1 (t)
Acf
1 (t)
Acf
1 (t)
Act
1 (t)
Act
2 (t)
Acf
2 (t)
Act
5 (t)
Acf
5 (t)
Act
2 (t)
Act
2 (t)
Acf
2 (t)
Cleanct (t + 1)
Cleancf (t + 1)
Acf
4 (t)
Act
4 (t)
Act
4 (t)
Act
4 (t)
Acf
4 (t)
Cleancf (t)
Cleanct (t)
Act
5 (t)
Act
5 (t)
Acf
5 (t)
Acf
6 (t)
Act
6 (t)
Cleancf ((t + 1))
Cleanct ((t + 1))
Acf
6 (t)
Acf
6 (t)
Act
6 (t)
Cleancf (t)
Cleanct (t)





































Acf
8
Acf
8
Act
8
Act
9
Acf
9
Act
11
Acf
11
Act
9
(t : Act
Act
1 (t)).
9
(t : Acf
Acf
1 (t)).
9
Act
Cleanct (0)
0.
ct
cf
(Acf
0  (t1 : (t1 = t  A1 (t1 )))). Clean (0)
cf
Acf
(t).
InitiallyClean
2
cf
A5 (t).
InitiallyCleanct
ct
ct
(A2 (t)  A5 (t)).
Act
11
Act
(t).
Act
1
11
ct
(Acf
Acf
1 (t)  A5 (t)).
11
ct
A1 (t).
Acf
12
ct
(Acf
Act
12
1 (t)  A2 (t)).
Cleancf ((t + 1)).
Cleancf (0)
Act
(t).
Cleanct (0)
4
cf
ct
(Clean (t + 1))  A4 (t)).
Act
12
cf
A2 (t).
Acf
12
cf
(Act
InitiallyCleancf
2 (t)  A4 (t)).
cf
A2 (t).
InitiallyCleanct
ct
(Act
2 (t)  Clean (t + 1)).
Cleanct (t).
W ipe(t).
(Cleancf (t)  W ipe(t)).
Acf
4 (t).
(Act
4 (t)  W ipe(t)).
Act
6 (t).
Cleanct (t + 1).
cf
(Acf
6 (t)  Clean (t + 1)).
cf
A5 (t).
cf
(Act
5 (t)  Clean (t + 1)).
cf
A5 (t).
cf
(Act
5 (t)  A6 (t)).
ct
Clean (t).
W ipe(t).
(Cleancf (t)  W ipe(t)).
Act
6 (t).
(Acf
6 (t)  W ipe(t)).
ct
Act
0  A8 .
cf
A0 .
Acf
8 .
Act
act .
Act
act .
ct
Acf
act  A8 .
cf
Aact  Act
0.



























Acf
9 .
Acf
11 .
ct
(Act
9  A11 ).
ct
A8 .
ct
(Acf
8  A11 ).
ct
A8 .
ct
(Acf
8  A9 ).
cf
Clean (0).
InitiallyCleanct .
(Cleanct (0)  InitiallyCleancf ).
Acf
9 .
cf
(Act
9  InitiallyClean ).
Acf
.
9
ct
(Act
9  Clean (0).
ct
A12 .
Cleanct (0).
cf
(Acf
12  Clean (0)).
cf
A11 .
cf
(Act
11  Clean (0)).
Acf
.
11
cf
(Act
11  A12 ).
InitiallyCleancf .
InitiallyCleanct .
Act
12 .
Acf
12 .

























































































































































































Figure 5: Approx{W ipe} (act ), with act taken from Example 1.1.
So let us assume that I is three-valued. We prove that M od(ApproxBU ()  I ) =
M od(Approx()  I ) by contradiction. Assume there is a predicate Act
 (the proof goes
cf
ct
analogously for A ) such that M od(Approx()  I ) |= A but M od(ApproxBU () 
I ) 6|= Act
 . In the preliminaries we recalled that the model of a positive inductive definition
O . The model of such a
is the least-fixpoint of the immediate consequence operator T
117

fiVlaeminck, Vennekens, Denecker & Bruynooghe

definition is thus the limit of a sequence of applications of the immediate consequence
operator. One can prove (see, e.g., Denecker & Ternovska, 2004) that we do not have to
apply the immediate consequence operator of the complete definition in every step. I.e.,
applying the immediate consequence operator of a subset of the definition, until there no
longer exists such a immediate consequence operator that will give something new, gives
the same model. Suppose we take such a sequence where we first apply all the bottom-up
rules, and only after no bottom-up rules are applicable we try to apply the top-down rules.
Suppose Act
 is the first atom we infer with the top down rules in this sequence. Obviously
Act
cannot
be the top-level atom Act

 , since there are no top-down rules for this. We can now
do a case study on the type of (sub)formula  occurs in, e.g., assume that  is a subformula
of the formula  where  =   0 . From the fact that Act
 is true, it follows that the body
cf
cf
ct
ct
of the top down rule A  A  A0 has to be true, and thus that Act
 and A0 are true.
ct
Since Act
 was the first atom to be inferred by a top-down rule, we have that since A is
ct
ct
ct
true, also A  A0 must be true. Now since A only became true in the last step of the
sequence, we have that Act
0 must have been true already. This means that after applying
cf
the bottom-up rules Act
0 and A0 are both true, which is a contradiction with the fact that
I was three-valued and that the bottom-up rules encode the four-valued evaluation. The
proof is analogous for the other types of subformulas.
Now in the case that I is four-valued, and not three-valued it is no longer the case
that only the bottom-up rules contribute to the model (i.e., M od(ApproxBU ()  I ) 6=
M od(Approx()  I )). To see this, consider the following formula P  Q, and take for
I the four-valued interpretation such that P = i and Q = t. Then one can verify that
cf
the bottom-up rules in Approx()  I will infer that both Act
P Q and AP Q are true.
However, now the top-down rules can also infer that Qcf has to be true. What happens is
that once an inconsistency is inferred for a certain subformula, this propagates back down
the parse-tree. However, similar to above, we can again do a case study on the structure of
cf
 to prove that (for the top formula  ) M od(ApproxBU ()  I ) |= Act
  A if and only
cf
BU () is clearly a direct
if M od(Approx()  I ) |= Act
  A . Now since since Approx
encoding of the four-valued evaluation, this concludes the proof.

Appendix C. Proof of Proposition 4.3
Proof. Take a witness I for the satisfiability of APP  (F ). First let us remark that
Open(Approx (1  2 )  {Act
1  t}) = . From the fact that I is a witness of the
satisfiability of APP  (F ) we know that the model M of this definition extending I concf
tains Act
 and by construction of Approx (1  2 ) it must also contain either A1 or
Act
2 .
Assume first that Acf
1 is true in M . Then application of Theorem 3.2 (where we take
 = {1 } and 0 = 1 ) gives: if M extends I and M |= 1 , then M 6|= 1 , so the assumption
that M |= 1 results in a contradiction and hence M 6|= 1 , in which case 1  2 holds
for every M extending I, and thus is I a witness for the satisfiability of F .
Next, assume that Act
2 is true in M . Again applying Theorem 3.2 (where this time
 = {1 } and 0 = 2 ) gives: if M extends I and M |= 1 then M |= 2 , hence also in this
118

fiAn Approximative Inference Method for SO

case does 1  2 hold for every M extending I, and again this means that I is a witness
of the satisfiability of F .

Appendix D. Proof of Theorem 5.2
A key ingredient in the proof of Theorem 5.2 is the following property of Appct/pt ().
Oct/pt
Its immediate consequence operator TApp
ct/pt () on two-valued interpretations simulates
(O ,O )

the immediate consequence operator T 1 2 on four-valued interpretations of the original
definition. This is made more precise in the following lemma.
Definition D.1. For a pair of -interpretations (I, J), we use t(I, J) to denote the ct/pt interpretation (I, J)ct/pt .
Lemma D.1. For each (O1 , O2 ) and (I, J),
(O1 ,O2 )

T

(O1 ,O2 )

Proof. Let (I 0 , J 0 ) be T

t(O ,O )

(I, J) = t1 (TApp1ct/pt2 () (t(I, J))).
t(O ,O )

(I, J) and let F = TApp1ct/pt2 () (t(I, J)). We first show that

F |ct = I 0 . Since F |ct depends only on the rules of Appct/pt () with a predicate from ct ,
we can discard all rules with a head from pt . As a result, we are left with a single copy of 
in which positive occurrences of atoms have been replaced by their ct variant and negative
ones by their pt variant. This implies that the evaluation of the bodies of these remaining
rules according to t(O1  I, O2  J) will be identical to the evaluation of the bodies of the
original rules by (O1  I, O2  J) in the construction of I 0 , thus proving the equality. The
proof of the remaining equality F |pt = J 0 is analoguous.
Proof of Theorem 5.2. First, recall that, given some partial knowledge (O1 , O2 ), the threevalued well-founded models of , resp. Appct/pt () are the least fixpoints of operators
(O ,O )
t(O ,O2 )
ST  1 2 resp. ST App1ct/pt
(note that since t(O1 , O2 ) is two-valued, we abuse notation
()
here and in the rest of the proof and denote the two-valued pair (t(O1 , O2 ), t(O1 , O2 )) by
t(O1 , O2 )).
Now, the latter operator is rather peculiar, in the sense that it is actually juggling four
different interpretations of the original alphabet . In more detail, each element in its
domain looks like this:


Ict
Jct
(I, J) =   ,   .
Ipt
Jpt
where Ict and Jct interpret the alphabet ct , and Ipt and Jpt interpret pt . If we now apply
t(O ,O2 )
the operator ST App1ct/pt
, we obtain a new such pair:
()

0
0
Ict
Jct
(I 0 , J 0 ) =   ,   .
0
0
Ipt
Jpt


119

fiVlaeminck, Vennekens, Denecker & Bruynooghe

0
0
From the general definition of the ST O
 construction, it is obvious that Ict Ipt depends only
on Jct  Jpt . However, in this particular case, the operator exhibits even more structure.
(O ,O2 )
The operator STApp1ct/pt
(J) uses its argument J as a fixed interpretation for the negative
()
occurrences, which remains constant throughout the least fixpoint computation over the
positive occurrences. Now, Appct/pt () contains two copies of  which interact only through
negative occurrences (that is, all occurrences of a pt predicate in the body of a rule with
a ct predicate in its head are always negative ones, and vice versa). This means that as
long as we keep the interpretation of the negative occurrence fixed to a constant value J,
0 , we can discard
these two copies of  do not interact at all. Consequently, to construct Ict
all rules with a pt predicate in its head. This means we are left with rules whose head
is a ct predicate and whose body contains only positive occurrences of ct predicates and
0 depends only on J . Moreover, the
negative occurrences of pt predicates. Therefore, Ict
pt
0 will be such that if we map its symbols back to the original alphabet  (let
value of Ict
0 ) = ST (O1 ,O2 ) (orig(J )). Similarly,
orig( ct ) = orig( pt ) =  for all   ), then orig(Ict
pt

we also obtain that:
(O1 ,O2 )

(orig(Jct )),

(O1 ,O2 )

(orig(Ipt )),

(O1 ,O2 )

(orig(Ict )).

0
orig(Ipt
) = ST

0
orig(Jct
) = ST

0
orig(Jpt
) = ST

In other words,
(O ,O2 )

0
0
(orig(Ict
), orig(Jpt
)) = ST  1
0
0
(orig(Ipt
), orig(Jct
)) = ST

(orig(Ict ), orig(Jpt )),

(O1 ,O2 )
(orig(Ipt ), orig(Jct )).


Now, if we consider the construction of the well-founded model of Appct/pt (), we have a
sequence of this form:

 1

 2

 

 0
0
1
2

Ict
Jct
Ict
Jct
Ict
Jct
Ict
Jct
  ,   7   ,   7   ,   7    7   ,   .
0
0
1
1
2
2


Ipt
Jpt
Ipt
Jpt
Ipt
Jpt
Ipt
Jpt
Let (I i , J i )i0 be the well-founded model construction for the original definition , i.e., for
 I 0 = f and
all predicates P/n  Def () and domain tuples d  Dn we have that (P (d))
 J 0 = t, and (I n+1 , J n+1 ) = ST (O1 ,O2 ) (I n , J n ) for n  0. It is easy to see that we have
(P (d))

0  J 0 ) = (I , J ). This provides a base case, while the above equation provides
that t1 (Ict
0 0
pt
i  J i ). In other words, the
the inductive step to prove that, for each i, (I i , J i ) = t1 (Ict
pt
well-founded model construction for the original definition  is tracked by these elements
of the well-founded model construction for Appct/pt ():
 0

 1

 2

 

Ict

Ict

Ict

Ict

  ,   7   ,   7   ,   7    7   ,   .
0
1
2


Jpt

Jpt

Jpt

Jpt
What about the other diagonal? There we have that t1 (J0ct  I0ct ) = (>, ), which is
the most precise element >p in the lattice of pairs of interpretations. Therefore, we find
120

fiAn Approximative Inference Method for SO

(O ,O )

that the other diagonal actually tracks the construction of the greatest fixpoint of ST  1 2 .
Combining these two results, we see that if (L1 , L2 ) and (G1 , G2 ) are these least and greatest
fixpoint, respectively, the well-founded model of Appct/pt () looks like this:


L1
G1
  ,  .
G2
L2
Note that a unique four-valued stable fixpoint is both the least and greatest stable fixpoint
and hence also the well-founded fixpoint. This immediately concludes the proof.

Appendix E. Proof of Proposition 5.3
Lemma E.1. Given a -definition , and a FO-formula . Let  be a subset of 0 (a
renamed copy of ). Consider the definition
D = Appct/pt ()  {P ct  P 0ct }P   {Opt  O0pt }OOpen(0 ) .
Assume that we have a three-valued interpretation I that approximates all models of   .
Then it holds that W F MI ct/pt (D) also approximates   , i.e.,
  W F M ct/pt (D), then |= (  )  P (d),

- if P ct (d)
I
 6 W F M ct/pt (D), then |= (  )  P (d).

- if P pt (d)
I
Proof. We prove this through induction over a well-founded model construction alternative
to the one we described in this paper, which can be found in the work by Denecker and
Vennekens (2007). Assume we have an induction sequence (Ii )0in , of four-valued Def (D)interpretations such that I0 is the interpretation in which everything is completely unknown,
and In = W F MI ct/pt (D). We prove for every i that Ii is a sound approximation of   .
This is trivially the case for n = 0. So now assume that Ik is a sound approximation of
  . We have to prove that this is also the case for Ik+1 . We need to prove two things for
 cannot be true in Ik+1 if P (d)
 is not true in all models of   ,
this: first, an atom P ct (d)
pt
 cannot be false in Ik+1 if it is not false in all models of
and second, that an atom P (d)
  . We prove both cases by contradiction.
We start with the first case. So assume that in the k-th well-founded induction step,
 is incorrectly deduced, i.e., there
for a certain predicate P and domain tuple D, P ct (d)

 was inferred in the k-th step,
exists a model M |=   , s.t. M 6|= P (d). Since P ct (d)
ct
 that is, (P )ct [d]
 was already made
this means that the body of the rule defining P (d),
true in a previous step. The induction hypothesis then tells us that in every model M of
 but then the semantics of inductive definitions says that
   it holds that M |= P [d],
also M |= P , which is a contradiction with our assumption.
Next, we consider the second case. This time, assume that in the k-th well-founded
 is inferred to be false, while there exists a model M of   , s.t.
induction step, P pt (d)

M |=     P (d). Now, using this alternative version of the well-founded semantics, there
are two ways for a domain atom to become false. Indeed, a domain atom can become false
121

fiVlaeminck, Vennekens, Denecker & Bruynooghe

because the body of the defining rule was already false, or because it is part of an unfounded
set.
 was made false because the body of the defining rule (P )pt was already false,
If P pt (d)
an argument completely analogous to the one above - using the induction hypothesis - again

gives a contradiction with the assumption. So now, all that is left to prove, is that P pt (d)
pt

cannot be incorrectly made false through the application of an unfounded set rule. If P (d)
is made false through the application of the unfounded set rule, this means that there is a
set U S of atoms, that are unknown in Ik , such that when made false in the bodies of the
rules defining these atoms, the Kleene evaluation of these bodies returns false. It is possible
to verify that we can always find an U S such that it only contains pt -atoms.
Now let us take such a model M of   . Such an M is obviously also a model
 such that
of . Consider the corresponding set U S 0 , consisting of domain atoms P (d),
pt
pt
pt


P (d)  U S. For every atom Q [d] in the body (P ) not in the set U S, the induction
 M t (Qpt [d])
 Ik . Similarly, for every atom Qct in
hypothesis actually tells us that (Q[d])
pt
ct
I
 k t (Q[d])
 M . Now, since Qpt atoms occur only
the body of (P ) , it says that (Q [d])
positively and and Qct only negatively in (P )pt , it follows that M interprets literals that
are not in U S 0 in a more false way than Ik . Thus, U S 0 is also an unfounded set (indeed,
turning all the atoms in U S 0 to false will make all the bodies of the defining rules false), and
 which is again a contradiction with the assumption, and which concludes
thus M |= P (d),
the proof of this lemma.

Proof of Proposition 5.3. The proof of this proposition is now an easy proof over induction
on the construction of the well-founded model of D , using the lemma above, and the
soundness of Approx().

References
Baral, C. (2003). Knowledge Representation, Reasoning, and Declarative Problem Solving.
Cambridge University Press, New York, NY, USA.
Baral, C., Gelfond, M., & Kosheleva, O. (1998). Expanding queries to incomplete databases
by interpolating general logic programs. J. Log. Program., 35 (3), 195230.
Baral, C., Kreinovich, V., & Trejo, R. (2000). Computational complexity of planning and
approximate planning in the presence of incompleteness. Artif. Intell., 122 (1-2), 241
267.
Belnap, N. D. (1977). A useful four-valued logic. In Dunn, J. M., & Epstein, G. (Eds.),
Modern Uses of Multiple-Valued Logic, pp. 837. Reidel, Dordrecht. Invited papers
from the Fifth International Symposium on Multiple-Valued Logic, held at Indiana
University, Bloomington, Indiana, May 13-16, 1975.
Clark, K. L. (1978). Negation as failure. In Logic and Data Bases, pp. 293322. Plenum
Press.
Denecker, M., Cortes Calabuig, A., Bruynooghe, M., & Arieli, O. (2010). Towards a logical
reconstruction of a theory for locally closed databases. ACM Transactions on Database
Systems, 35 (3), 22:122:60.
122

fiAn Approximative Inference Method for SO

Denecker, M., & Ternovska, E. (2004). A logic of non-monotone inductive definitions and
its modularity properties. In Lifschitz, V., & Niemela, I. (Eds.), LPNMR, Vol. 2923
of LNCS, pp. 4760. Springer.
Denecker, M., & Ternovska, E. (2007). Inductive situation calculus. Artificial Intelligence,
171 (5-6), 332360.
Denecker, M., & Ternovska, E. (2008). A logic of nonmonotone inductive definitions. ACM
Transactions on Computational Logic (TOCL), 9 (2), Article 14.
Denecker, M., & Vennekens, J. (2007). Well-founded semantics and the algebraic theory of
non-monotone inductive definitions. In Baral, C., Brewka, G., & Schlipf, J. S. (Eds.),
LPNMR, Vol. 4483 of LNCS, pp. 8496. Springer.
Denecker, M., Vennekens, J., Bond, S., Gebser, M., & Truszczynski, M. (2009). The second
Answer Set Programming competition. In Erdem, E., Lin, F., & Schaub, T. (Eds.),
LPNMR, Vol. 5753 of LNCS, pp. 637654. Springer.
Doherty, P., Magnusson, M., & Szalas, A. (2006). Approximate databases: a support tool
for approximate reasoning. Journal of Applied Non-Classical Logics, 16 (1-2), 87118.
E. Giunchiglia, Y. L., & Maratea, M. (2011). Cmodels homepage. http://www.cs.utexas.
edu/users/tag/cmodels.html.
Fagin, R. (1974). Generalized first-order spectra and polynomial-time recognizable sets.
Complexity of Computation, 7, 4374.
Feferman, S. (1984). Toward useful type-free theories. Journal of Symbolic Logic, 49 (1),
75111.
Gelfond, M., & Lifschitz, V. (1988). The stable model semantics for logic programming. In
Kowalski, R. A., & Bowen, K. A. (Eds.), ICLP/SLP, pp. 10701080. MIT Press.
Immerman, N. (1998). Descriptive Complexity. Springer Verlag.
Kleene, S. C. (1952). Introduction to Metamathematics. Van Nostrand.
Liu, Y., & Levesque, H. J. (1998). A completeness result for reasoning with incomplete
first-order knowledge bases. In KR, pp. 1423.
Marien, M., Wittocx, J., & Denecker, M. (2006). The IDP framework for declarative problem
solving. In Search and Logic: Answer Set Programming and SAT, pp. 1934.
McDermott, D. (1987). A critique of pure reason. Computational Intelligence, 3, 151160.
Mitchell, D. G., & Ternovska, E. (2005). A framework for representing and solving NP
search problems. In Veloso, M. M., & Kambhampati, S. (Eds.), AAAI, pp. 430435.
AAAI Press / The MIT Press.
Niemela, I., Simons, P., & Syrjanen, T. (2000). Smodels: A system for answer set programming. In Proceedings of the 8th International Workshop on Non-Monotonic Reasoning,
Breckenridge, Colorado, USA. CoRR, cs.AI/0003033.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning
problems with bounded width. Journal of Artificial Intelligence Research (JAIR), 35,
623675.
123

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Son, T. C., Tu, P. H., Gelfond, M., & Morales, A. R. (2005). An approximation of action
theories of and its application to conformant planning. In Baral, C., Greco, G., Leone,
N., & Terracina, G. (Eds.), LPNMR, Vol. 3662 of LNCS, pp. 172184. Springer.
Tamaki, H., & Sato, T. (1984). Unfold/fold transformations of logic programs. In ICLP,
pp. 127138.
Tseitin, G. S. (1968). On the complexity of derivation in propositional calculus. In Slisenko,
A. O. (Ed.), Studies in Constructive Mathematics and Mathematical Logic II, pp. 115
125. Consultants Bureau, N.Y.
Turner, H. (2002). Polynomial-length planning spans the polynomial hierarchy. In JELIA,
pp. 111124.
van Fraassen, B. (1966). Singular terms, truth-value gaps and free logic. Journal of Philosophy, 63 (17), 481495.
Van Gelder, A. (1993). The alternating fixpoint of logic programs with negation. Journal
of Computer and System Sciences, 47 (1), 185221.
Vlaeminck, H., Wittocx, J., Vennekens, J., Denecker, M., & Bruynooghe, M. (2010). An
approximate method for solving SO problems. In Fisher, M., van der Hoek, W.,
Konev, B., & Lisitsa, A. (Eds.), JELIA, Lecture Notes in Computer Science, pp.
326338. Springer.
Wittocx, J. (2010). Finite Domain and Symbolic Inference Methods for Extensions of FirstOrder Logic. Ph.D. thesis, Department of Computer Science, K.U.Leuven, Leuven,
Belgium.
Wittocx, J., Denecker, M., & Bruynooghe, M. (2010). Constraint propagation for extended
first-order logic. CoRR, abs/1008.2121.
Wittocx, J., Marien, M., & Denecker, M. (2008). Approximate reasoning in first-order logic
theories. In Brewka, G., & Lang, J. (Eds.), KR, pp. 103112. AAAI Press.

124

fiJournal of Artificial Intelligence Research 45 (2012) 197255

Submitted 12/11; published 10/12

Reasoning over Ontologies with Hidden Content:
The Import-by-Query Approach
Bernardo Cuenca Grau
Boris Motik

bernardo.cuenca.grau@cs.ox.ac.uk
boris.motik@cs.ox.ac.uk

Department of Computer Science, Oxford University
Wolfson Building, Parks Road, Oxford OX1 3QD UK

Abstract
There is currently a growing interest in techniques for hiding parts of the signature
of an ontology Kh that is being reused by another ontology Kv . Towards this goal, in
this paper we propose the import-by-query framework, which makes the content of Kh
accessible through a limited query interface. If Kv reuses the symbols from Kh in a certain
restricted way, one can reason over Kv  Kh by accessing only Kv and the query interface.
We map out the landscape of the import-by-query problem. In particular, we outline the
limitations of our framework and prove that certain restrictions on the expressivity of Kh
and the way in which Kv reuses symbols from Kh are strictly necessary to enable reasoning
in our setting. We also identify cases in which reasoning is possible and we present suitable
import-by-query reasoning algorithms.

1. Introduction
Ontologiesformal conceptualizations of a domain of interesthave become increasingly
important in computer science. They play a central role in many applications, such as the
Semantic Web and biomedical information systems. The most widely used ontology languages are the Web Ontology Language (OWL) (Horrocks, Patel-Schneider, & van Harmelen, 2003) and its revision OWL 2 (Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider,
& Sattler, 2008), which have been standardized by the World Wide Web Consortium (W3C).
The formal underpinning of the OWL family of languages is provided by description logics (DLs) (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2007)knowledge
representation formalisms with well-understood computational properties.
Constructing ontologies is a labor-intensive task, so reusing (parts of) well-established
ontologies is seen as key to reducing ontology development cost. Consequently, the problem
of ontology reuse has recently received significant attention (Stuckenschmidt, Parent, &
Spaccapietra, 2009; Lutz & Wolter, 2010; Lutz, Walther, & Wolter, 2007; Cuenca Grau,
Horrocks, Kazakov, & Sattler, 2008, 2007; Doran, Tamma, & Iannone, 2007; Jimenez-Ruiz,
Cuenca Grau, Sattler, Schneider, & Berlanga Llavori, 2008).
We discuss the problems of ontology reuse by means of an example from the health-care
domain. In particular, ontologies are currently being used in several countries to describe
electronic patient records (EPR). The representation of patients data typically involves
ontological descriptions of human anatomy, medical conditions, drugs and treatments, and
so on. The latter domains have already been described in well-established reference ontologies, such as SNOMED-CT, GALEN, or the Foundational Model of Anatomy (FMA). In
order to save resources, increase interoperability between applications, and rely on experts
c
2012
AI Access Foundation. All rights reserved.

fiCuenca Grau & Motik

knowledge, these and other reference ontologies should be reused whenever possible. For
example, assume that some reference ontology Kh describes concepts such as the ventricular septum defect; then, one might reuse the terms from Kh in order to define an ontology
Kv of concepts such as patients having a ventricular septum defect, which might then be
embedded in an EPR application.
To enable ontology reuse, OWL provides an importing mechanism: an ontology Kv
can import another ontology Kh , and the result is logically equivalent to Kv  Kh . OWL
reasoners deal with imports by loading both ontologies and merging their contents, thus
requiring physical access to the axioms of Kh . The vendor of Kh , however, may be reluctant
to distribute (parts of) the contents of Kh , as doing so might allow competitors to plagiarize
Kh . Moreover, Kh may contain information that is sensitive from a privacy point of view.
Finally, one may want to impose a varying cost on the reuse of dierent parts of Kh .
Rather than publishing the entire ontology, the vendor of Kh might want to freely
distribute the symbols that describe organs and medical conditions, but without distributing
the axioms describing these symbols. Furthermore, the vendor might want to completely
hide the sensitive information from Kh , such as the information about treatments. It should,
however, be possible to reuse the published part of Kh without aecting the ontologys
consequences; that is, if a part of Kh is used to construct an ontology Kv , then any query
q mentioning only symbols from Kv should be answered over Kv and the respective part of
Kh in the same way as this would be done over Kv  Kh . To stipulate that Kh should not
be publicly available, we call the ontology Kh hidden and, by analogy, we call Kv visible.
Motivated by such scenarios, several approaches to hiding a subset  of the signature of
Kh have been developed. For example, one possible approach is to publish an -interpolant
of Kh an ontology that contains no symbols from  and that coincides with Kh on all logical
consequences formed using the symbols not in  (Konev, Walther, & Wolter, 2009; Wang,
Wang, Topor, Pan, & Antoniou, 2009; Wang, Wang, Topor, & Pan, 2008; Wang, Wang,
Topor, & Zhang, 2010; Wang et al., 2008; Lutz & Wolter, 2011; Nikitina, 2011). Publishing
an interpolant ensures that the sensitive information in Kh (i.e., the information about the
symbols from Kh not mentioned in the interpolant) is not exposed in any way; furthermore,
interpolants preserve all consequences of symbols not in  and have the additional advantage
that the developers of Kv can reason over the union of Kv and the interpolant using o-theshelf reasoners. The interpolation approach may, however, exhibit several drawbacks. First,
an interpolant may exist only if Kh is expressed in a relatively weak ontology language and if
it satisfies certain syntactic conditions (Konev et al., 2009). Second, although interpolants
preserve logical consequences formed using symbols not in , they are not robust under
replacement (Sattler, Schneider, & Zakharyaschev, 2009)that is, the union of Kv and an
-interpolant of Kh is not guaranteed to yield the same consequences as Kh  Kv for a query
q involving only symbols from Kv . Finally, an -interpolant of Kh can be exponentially
larger than Kh , and it may reveal more information than what is strictly needed. We refer
the reader to Section 7 for a detailed discussion of the related work.
In this paper, we propose a novel approach to ontology reuse that addresses the problems
outlined above by making Kh accessible via a limited query interface called an oracle. The
oracle advertises a public subset  of the signature of Kh (e.g., all symbols describing organs
or medical conditions), and it can answer queries over Kh that are expressed in a particular
query language and that use only the symbols from . Under certain assumptions, a so198

fiReasoning over Ontologies with Hidden Content

called import-by-query algorithm can reason over Kv  Kh (e.g., determine the satisfiability
of Kv  Kh ) by posing queries to the oracle for Kh , and without accessing any of the axioms
from Kh . Furthermore, reasoning can be performed without making the axioms of Kv
available to Kh , which is beneficial as Kv might also contain sensitive information from a
privacy point of view. Finally, our framework can be applicable even in cases when the
relevant interpolant for Kh does not exist.
In order to achieve these benefits, however, Kv must reuse the symbols from  only
in a syntactically restricted way, and the formal properties of import-by-query algorithms
and the specific restrictions necessary for an import-by-query algorithm to exist depend on
the oracle query language and the ontology languages used to express Kv and Kh . In this
paper, we explore the properties of import-by-query reasoning with languages ranging from
the lightweight description logic EL (Baader, Brandt, & Lutz, 2005) to the expressive logic
ALCHOIQ (Horrocks & Sattler, 2005), combined with the following types of oracles.
 Queries for concept satisfiability oracles are concepts constructed using the symbols
in  expressed in a particular DL; for each query, the oracle decides the satisfiability
of the query concept w.r.t. Kh .
 Queries for ABox satisfiability oracles are ABoxes constructed using the symbols in
; for each query, the oracle decides the satisfiability of the query ABox w.r.t. Kh .
 Queries for ABox entailment oracles consist of an ABox and an assertion, both constructed using the symbols in ; for each query, the oracle determines whether the
assertion is entailed by Kh and the query ABox.
Concept satisfiability, ABox satisfiability, and ABox entailment have been implemented in
most state-of-the-art DL reasoners, so the above mentioned query languages seem like a
natural foundation for practical implementations of our framework.
The main contributions of this paper are as follows:
1. We present the import-by-query framework, formalize the notions of an oracle and an
import-by-query algorithm, and establish the connections between import-by-query
algorithms based on dierent types of oracles.
2. We explore the limitations of our framework for a wide range of description logics and
formulate precise conditions under which import-by-query algorithms fail to exist.
3. We identify sucient conditions on the visible ontology Kv for which an import-byquery algorithm can be obtained.
4. We present a general hypertableau-based (Motik, Shearer, & Horrocks, 2009) importby-query algorithm that relies on ABox satisfiability oracles and that is applicable to
Kv and Kh given in the expressive description logic ALCHIQ (Horrocks & Sattler,
1999), provided that Kv satisfies our sucient conditions.
5. Our general algorithm, however, is unlikely to be suitable for practice due to a high
degree of nondeterminism. Therefore, we present a practical (goal-oriented) variant
that is applicable whenever Kh is expressed in a Horn DL. This algorithm can be
199

fiCuenca Grau & Motik

readily applied to ontologies expressed in the lightweight description logic EL, but
it is not guaranteed to be computationally optimal. Therefore, we also present a
practical and computationally optimal algorithm that can be used if both Kv and Kh
are expressed in EL.
6. We establish the lower bounds on the size and the number of queries that an importby-query algorithm may need to ask an oracle in order to solve a reasoning task.
Our results provide flexible and useful ways for ontology designers to ensure selective
access to their ontologies, as well as a family of reasoning algorithms that provide a starting
point for implementation and optimization. Furthermore, we believe our techniques can
also be adapted to other settings, such as distributed ontology reasoning, or collaborative
ontology development scenarios in which ontology developers have restricted access to the
parts of the ontology developed by others.

2. Preliminaries
In this section, we recapitulate the description logic notation used in this paper, we present
an overview of various hypertableau reasoning algorithms for description logics (Motik et al.,
2009), and we recapitulate various notions of modular ontology reuse (Lutz, Walther, &
Wolter, 2007; Cuenca Grau, Horrocks, Kazakov, & Sattler, 2008; Konev, Lutz, Walther, &
Wolter, 2008).
2.1 Description Logics
The syntax of the description logic ALCHOIQ is defined w.r.t. pairwise-disjoint countably
infinite sets of atomic concepts NC , atomic roles NR , and named individuals NI . Set NC
contains a distinguished infinite subset NO  NC of nominal concepts (or simply nominals).
A role is either an atomic role or an inverse role R for R an atomic role.
The set of concepts is the smallest set containing , A, C, C1  C2 , R.C (existential
restriction), and  n R.C (cardinality restriction), for A an atomic concept, C, C1 , and
C2 concepts, R a role, and n a nonnegative integer. Furthermore, , C1  C2 , R.C,
and  n R.C are abbreviations of , (C1  C2 ), and (R.C), and ( n+1 R.C),
respectively. We also often treat concepts of the form R.C as abbreviations of  1 R.C.
A concept inclusion axiom has the form C1  C2 for C1 and C2 concepts, a concept
equivalence C1  C2 is an abbreviation for C1  C2 and C2  C1 , and a concept definition
is a concept equivalence of the form A  C with A an atomic concept. A role inclusion
axiom has the form R1  R2 for R1 and R2 roles. A TBox axiom is either a concept
inclusion axiom or a role inclusion axiom. A TBox T is a finite set of TBox axioms. An
assertion has the form C(a), R(a, b), R(a, b), a  b, or a  b, for C a concept, R a role,
and a and b individuals. An ABox A is a finite set of assertions. An ABox is normalized
if it contains only assertions of the form A(a), A(a), R(a, b), R(a, b), and a  b, where
A is an atomic concept and R is an atomic role. An axiom is either a TBox axiom or an
assertion. A knowledge base K = T  A consists of a TBox T and an ABox A.

200

fiReasoning over Ontologies with Hidden Content

Table 1: Model-Theoretic Semantics of ALCHOIQ
Interpretation of Roles
(R )I = {y, x | x, y  RI }
Interpretation of Concepts
I = I
(C)I = I \ C I
(C1  C2 )I = C1I  C2I
(R.C)I = {x | y : x, y  RI  y  C I }
( n R.C)I = {x | {y | x, y  RI  y  C I }  n}
Satisfaction of Axioms in an Interpretation
I
I
I
I
I
I
I

|= C  D
|= R1  R2
|= C(a)
|= R(a, b)
|= R(a, b)
|= a  b
|= a  b

i
i
i
i
i
i
i

C I  DI
R1I  R2I
aI  C I
aI , bI   RI
aI , bI  
/ RI
I
I
a =b
aI = bI

A signature is a set of atomic concepts and atomic roles. For  a concept, a role, an
axiom, or a set of axioms, the signature of , written sig(), is the set of atomic concepts
and atomic roles occurring in .1
The cardinality of a set S is written S. An interpretation I = (I , I ) consists of a
nonempty domain set I and a function I that assigns an object aI  I to each individual
a, a set AI  I to each atomic concept A such that A  NO implies AI = 1, and a
relation RI  I  I to each atomic role R. Table 1 defines the extension of I to roles
and concepts, as well as the satisfaction of axioms in I. An interpretation I is a model of
K, written I |= K, if I satisfies all axioms in K; if such I exists, then K is satisfiable. A
concept C is satisfiable w.r.t. K if a model I of K exists such that C I = .
Sometimes, nominal concepts are defined as having the form {a} for a an individual, and
such a concept is interpreted as ({a})I = {aI }; that is, a nominal concept contains precisely
the given individual. The drawback of such a definition is that it blurs the distinction
between concepts and individuals at the syntactic level. Such a distinction is important
for the import-by-query framework since our framework supports sharing concepts, but not
individuals. In this paper we thus use the above given alternative definition, where nominals
are special atomic concepts with a singleton interpretation. It is well known that these
two definitions are equally expressive (Baader et al., 2007).
Some of our results use a general notion of a description logic. Formally, we define a
description logic DL as a pair consisting of a set of concepts and a set of knowledge bases.
We call the elements of the former set DL-concepts and the elements of the latter set DLknowledge bases. Each concept in a DL-knowledge base must be a DL-concept. A DL-TBox
(resp. DL-ABox ) is a DL-knowledge base containing no assertions (resp. no TBox axioms).
1. Note that we are treating nominals as special atomic concepts (and not as individuals); hence, sig()
includes the nominals, but not the individuals occurring in .

201

fiCuenca Grau & Motik

A DL-TBox axiom (resp. DL-assertion) is a TBox axiom (resp. assertion) that occurs in
some DL-knowledge base. A description logic DL1 is a fragment of DL2 (or, conversely,
DL2 extends DL1 ) if each DL1 -concept is a DL2 -concept and each DL1 -knowledge base is
a DL2 -knowledge base. Since the unqualified notions of a concept and knowledge base
are defined for ALCHOIQ, our definitions imply that each description logic considered in
this paper is a fragment of ALCHOIQ.
Let DL1 and DL2 be description logics. We say that DL1 allows for DL2 -definitions
if, for each DL1 -knowledge base K, each atomic concept A, and each DL2 -concept C, we
have that K  {A  C} is a DL1 -knowledge base. Furthermore, DL1 has the finite model
property if each satisfiable DL1 -knowledge base has a model with a finite domain.
The description logic ALC is obtained from ALCHOIQ by disallowing nominal concepts
(O), inverse roles (I), role inclusion axioms (H), and cardinality restrictions (Q). The
description logics between ALC and ALCHOIQ are named by appending combinations of
letters O, H, I, and Q to ALC.
The DL EL (Baader et al., 2005) (resp. FL0 , see Baader et al., 2007) is obtained from
ALC by allowing only concepts of the form , , A, C1  C2 , and R.C (resp. R.C) for
A and R atomic, and by allowing only assertions of the form C(a) or R(a, b), with C an
EL (resp. FL0 ) concept and R an atomic role. In recent years, significant eort has been
devoted to the development of DL languages with good computational properties, such as
EL, DL-Lite (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007), and Horn-SHIQ
(Hustadt, Motik, & Sattler, 2005). An ALCHIQ knowledge base is Horn if it is expressed
in the Horn-SHIQ fragment of ALCHIQ.
For an ABox A, with G(A) we denote the graph whose nodes are precisely the individuals
occurring in A, and that contains an undirected edge between individuals a and b if and
only if a = b or both a and b occur together in an assertion in A. Individuals a and b are
connected in A if a and b are connected in G(A); furthermore, A is connected if all pairs of
individuals occurring in A are connected. An ABox A  A is a connected component of A
if G(A ) is a connected component of G(A).
2.2 Hypertableau Reasoning Algorithm
The hypertableau calculus by Motik et al. (2009) decides the satisfiability of an ALCHOIQ
knowledge base K. As we show in Section 4.1, the presence of nominals precludes the
existence of an import-by-query algorithm; hence, in this section we present an overview of
a simplified version of the algorithm that is applicable if K is an ALCHIQ knowledge base.
The algorithm first preprocesses K into a set of rules Rimplications interpreted under first-order semanticsand a normalized ABox A such that K is equisatisfiable with
R  A. Preprocessing consists of three steps. First, transitivity axioms are eliminated
from K by encoding them using concept inclusions. Second, axioms are normalized and
complex concepts are replaced with atomic ones in a way similar to the structural transformation for first-order logic. Third, the normalized axioms are translated into rules by
using the correspondence between description and first-order logic. We omit the details
of the preprocessing for the sake of brevity; Motik et al. (2009) present all the relevant
details. Preprocessing produces so-called HT-rulessyntactically restricted rules on which

202

fiReasoning over Ontologies with Hidden Content

the hypertableau calculus is guaranteed to terminate; the precise syntactic form of HT-rules
is described in Section 2.2.1.
After preprocessing, the satisfiability of RA is decided using the hypertableau calculus,
which is described in Section 2.2.2.
2.2.1 HT-Rules
Let NV be a set of variables disjoint with the set of individuals NI . An atom is an expression
of the form C(s) (a concept atom), R(s, t) (a role atom), or s  t (an equality atom), where
s, t  NV  NI , C is a concept, and R is a role. A rule is an expression of the form
(1)

U1  . . .  Um  V1  . . .  Vn

where Ui and Vj are atoms, m  0, and n  0. Conjunction U1  . . .  Um is called the body,
and disjunction V1  . . .  Vn is called the head of the rule. The empty body and the empty
head are written as  and , respectively. Rules are interpreted as universally quantified
FOL implications in the usual way. A rule is Horn if it contains at most one head atom.
An HT-rule is a rule of the form




Ai (x)  Rij (x, yi )  Sij (yi , x)


  Bij (yi ) 

(2)

Ci (x)  Rij (x, yi )  Sij (yi , x)  Dij (yi )  yi  yj
 , and S  are atomic roles; A , B , and D are atomic concepts; and
where Rij , Sij , Rij
i
ij
ij
ij
Ci are either atomic concepts or concepts of the form  n R.A or  n R.A. In addition,
each variable yi occurring in an HT-rule is required to occur in a body atom of the form
Rij (x, yi ) or Sij (yi , x). Intuitively, the body and the head of HT-rules can be seen as being
star-shaped: center variable x represents the center of the star, and branch variables yi
can be connected to the center only through role atoms. Such shape ensures that satisfiable
HT-rules will always have a tree-like modela property that can be used to explain the
good computational properties of many DLs.
As Motik et al. (2009) have shown, the preprocessing of K produces an equisatisfiable
set of HT-rules and a normalized ABox; furthermore, if K is Horn, then the resulting set
contains only Horn HT-rules. Furthermore, if certain description logic constructors are not
used in K, then R satisfies certain syntactic restrictions as discussed next.

 If K does not use cardinality restrictions, then no HT-rule   R contains an atom of
the form yi  yj in the head.
 If K does not use inverse roles, then no HT-rule   R contains an atom of the form
 (y , x) in the head or an atom of the form S (y , x) in the body.
Sij
i
ij i
 If K does not use role hierarchies, then no HT-rule   R contains a role atom in the
head.
As an example, consider the following knowledge base K and the corresponding set of
HT-rules R obtained from K.
A  R.B
A  R.C



A(x)  R.B(x)



A(x)  R.C(x)
203

(3)
(4)

fiCuenca Grau & Motik



   1 R.

R(x, y1 )  R(x, y2 )  y1  y2



BC D

B(x)  C(x)  D(x)



R.D  E

R(x, y)  D(y)  E(x)

(5)
(6)
(7)

Note that R is a set of Horn HT-rules. Note also that K uses a cardinality restriction
 1 R., so R contains a rule with an equality atom in the head. Furthermore, K does not
use role hierarchies, so no rule in R contains a role atom in the head. Finally, K does not
use inverse roles, so each role atom occurring in the body of a rule in R contains the center
variable x in the first position and a branch variable yi in the second position.
When applied to an EL knowledge base, the transformation by Motik et al. (2009)
produces EL-rulesHT-rules of the form (8) in which C is either an atomic concept or a
concept of the form R.A with A an atomic concept.


mi
k
m



Ri (x, yi ) 
Ai (x) 
Bij (yi )  C(x)
(8)
i=1

i=1

j=1

Note that all the rules in our previous example except for the third one (which uses equality
in the head) are EL-rules.
2.2.2 Hypertableau Calculus for HT-Rules

Given an arbitrary set of HT-rules R and a normalized ABox A, satisfiability of R  A can
be decided using the calculus described in Definition 1.
Definition 1. Individuals. For a set of named individuals NI , the set of all individuals
NX is inductively defined as the smallest set such that NI  NX and, if x  NX , then
x.i  NX for each integer i. The individuals in NX \ NI are unnamed. An individual x.i is
a successor of x, and x is a predecessor of x.i; descendant and ancestor are the transitive
closures of successor and predecessor, respectively.
Pairwise Anywhere Blocking. The label LA (s) of an individual s and the label
LA (s, t) of an individual pair s, t in an ABox A are defined as follows:
LA (s) = {A | A(s)  A and A is atomic}
LA (s, t) = {R | R(s, t)  A}
Let  be a strict ordering on NX containing the ancestor relation. By induction on , we
assign to each individual s in A a blocking status as follows.
 Individual s is directly blocked by individual t i the following conditions hold, for s
and t the predecessors of s and t, respectively:
 s and t are unnamed, t is not blocked, and t  s;2
 LA (s) = LA (t) and LA (s ) = LA (t ); and

 LA (s, s ) = LA (t, t ) and LA (s , s) = LA (t , t).
2. When blocking is used with ALCHOIQ knowledge bases, individuals s and t are also required to be
unnamed; however, this restriction is not needed for ALCHIQ knowledge bases.

204

fiReasoning over Ontologies with Hidden Content

Hyp-rule

-rule

-rule
-rule

Table 2: Hypertableau Derivation Rules
Derivation Rules for HT-rules
If 1.   R of the form (1) and
2. a mapping  from the variables in  to the individuals in A exists where
2.1 (x) is not indirectly blocked for each variable x in ,
2.2 (Ui )  A for each 1  i  m, and
2.3 (Vj )  A for each 1  j  n,
then A1 = A  {} if n = 0;
Aj := A  {(Vj )} for 1  j  n otherwise.
If 1.  n R.C(s)  A such that s is not blocked in A and
2. no individuals u1 , . . . , un in A exist such that
{ar(R, s, ui ), C(ui ) | 1  i  n}  {ui  uj | 1  i < j  n}  A,
then A1 := A  {ar(R, s, ti ), C(ti ) | 1  i  n}  {ti  tj | 1  i < j  n}
where t1 , . . . , tn are fresh successors of s.
If 1. s  t  A such that s = t and neither s not t is indirectly blocked
then A1 := mergeA (s  t) if t is named or s is a descendant of t, and
A1 := mergeA (t  s) otherwise.
If 1. s  s  A or {A(s), A(s)}  A or {R(s, t), R(s, t)}  A
such that neither s nor t is indirectly blocked and
2.   A
then A1 := A  {}.
The -rule for EL-rules
If
R.A(s)  A and {R(s, aA ), A(aA )}  A
-rule
then A1 := A  {R(s, aA ), A(aA )}

 Individual s is indirectly blocked i its predecessor is blocked.
 Individual s is blocked i it is either directly or indirectly blocked.
Pruning and Merging. The ABox pruneA (s) is obtained from A by removing all assertions containing a descendant of s. The ABox mergeA (s  t) is obtained from pruneA (s)
by replacing s with t in all assertions.
Clash. An ABox A contains a clash if   A; otherwise, A is clash-free.
Derivation Rules. The derivation rules consist of the Hyp-, -, -, and -rule from
Table 2, which, given R and a clash-free ABox A, derive the ABoxes A1 , . . . , An . In the
Hyp-rule, (U ) is obtained from U by replacing each variable x with (x). For a role R and
individuals s and t, function ar(R, s, t) returns assertion R(s, t) if R is atomic, or assertion
S(t, s) if R is an inverse role and R = S  .
Derivation. A derivation for R and A is a pair (T, ) where T is a finitely branching
tree and  labels the nodes of T with ABoxes such that ( i) () = A for  the root, and
( ii) for each node t, if a derivation rule is applicable to R and (t), then t has children
t1 , . . . , tn such that (t1 ), . . . , (tn ) are the result of applying one derivation rule to R and
(t). The algorithm returns t if some derivation for R and A has a leaf node labeled with
a clash-free ABox, and f otherwise.
205

fiCuenca Grau & Motik

The Hyp-rule is similar to the one of the hypertableau calculus for first-order logic: given
an HT-rule of he form (1) and an ABox A, the Hyp-rule tries to unify the atoms U1 , . . . , Um
with a subset of the assertions in A; if a unifier  is found, the rule nondeterministically
derives (Vj ) for some 1  j  n. For example, given the rule A(x)  R.C(x)  D(x)
and an assertion A(a), the Hyp-rule derives either R.C(a) or D(a). The -rule deals with
existential quantifiers; for example, given R.C(a), the rule introduces a fresh individual
t and derives R(a, t) and C(t). The -rule deals with equality; for example, given a  b,
the rule replaces the individual a in all assertions with the individual b. Finally, the -rule
detects obvious contradictions such as A(a) and A(a), R(a, b) and R(a, b), or a  a.
Since ALCHIQ allows for cyclic concept inclusions of the form C  R.C, termination
of the hypertableau calculus requires a blocking mechanism to prevent the -rule from
generating infinite sequences of successors. When an individual s is directly blocked by
another individual t, the -rule is no longer applicable to s, which prevents the introduction
of fresh successors of s. Furthermore, all descendants of s are then indirectly blocked, which
prevents the application of any of the rules in Table 2 to the descendants of s.
If a derivation for R and A exists in which a leaf node is labeled with a clash-free ABox
A , then a model of R  A can be constructed from A via a well-known technique called
unraveling. Models of R  A obtained in such a way are called canonical forest models, and
Motik et al. (2009) discuss in depth the properties of such models.
Let R be the set of HT-rules (3)(7) given in Section 2.2.1, and let A = {A(a), E(a)};
we next show how to demonstrate using the hypertableau algorithm that R  A is unsatisfiable. By applying the Hyp-rule to A(a), we derive R.B(a) and R.C(a). Next, by
applying the -rule to R.B(a) we derive R(a, t1 ) and B(t1 ); and by applying the -rule
to R.C(a) we derive R(a, t2 ) and C(t2 ). Individuals t1 and t2 are fresh successors of s and
are actually of the form s.1 and s.2; however, for clarity we write them simply as t1 and
t2 . By applying the Hyp-rule to R(a, t1 ) and R(a, t2 ), we derive t1  t2 . Furthermore, to
apply the -rule to t1  t2 , we must replace t1 with t2 in all assertions; thus, we replace
R(a, t1 ) and B(t1 ) with R(a, t2 ) and B(t2 ), respectively. Next, by applying the Hyp-rule
to B(t2 ) and C(t2 ) we derive D(t2 ). Next, by applying the Hyp-rule to R(a, t2 ) and D(t2 )
we derive E(a). Finally, by applying the the -rule to E(a) and E(a) we derive . We
have thus constructed a derivation for R and A whose (only) leaf contains a clash, and so
R  A is unsatisfiable.
2.2.3 Hypertableau Algorithm for EL-rules

Since any EL knowledge base is an ALCHIQ knowledge base as well, the hypertableau
algorithm can straightforwardly be applied to EL KBs. Motik and Horrocks (2008) showed,
however, that a worst-case optimal algorithm can be obtained by modifying the -rule.
This modified algorithm works on a set R of EL-rules.
The following algorithm checks satisfiability of R  A, for R a set of EL-rules and A a
normalized ABox.
Definition 2. For each named individual a  NI and each atomic concept A  NC , let aA
be a fresh individual that is uniquely associated with a and A. The hypertableau algorithm
for EL is the same as the one described in Definition 1, but the derivation rules include the
Hyp-, -, and -rule from Table 2.
206

fiReasoning over Ontologies with Hidden Content

2.3 Modularity
Let Kv be a knowledge base that reuses a knowledge base Kh , and let  be the subset of
sig(Kh ) that is being reused in Kv that is,  = sig(Kh )  sig(Kv ). It is often beneficial if
Kv reuses Kh in a modular way; intuitively, this is the case if the knowledge base Kv does
not aect the meaning of the symbols in  (Lutz, Walther, & Wolter, 2007; Cuenca Grau,
Horrocks, Kazakov, & Sattler, 2008; Konev, Lutz, Walther, & Wolter, 2008). Two dierent
notions of modularity have been considered in literature, each providing a dierent formal
account of what it means for Kv to aect the meaning of the symbols in .
A knowledge base Kv is deductively modular w.r.t. a signature  if, for all concepts C
and D expressed in the same description logic as Kv such that sig(C)   and sig(D)  ,
we have that Kv |= C  D implies  |= C  D. That is, the axioms of Kv must not give
rise to nontrivial logical consequences that involve only the symbols from .
A knowledge base Kv is semantically modular w.r.t. a signature  if, for each interpretation I = (I , I ) for the symbols in , there exists an interpretation J = (J , J ) such
that I = J , X I = X J for each X  , and J |= Kv . That is, the axioms of Kv are not
allowed to impose any constraints on the interpretation of the symbols from .
Semantic modularity is stronger than the deductive one: if Kv is semantically modular
w.r.t. , then it is also deductively modular w.r.t. ; the converse does not hold necessarily.
Deciding whether a knowledge base Kv is deductively or semantically modular w.r.t. a
signature  is a very hard computational problem for most DLs, and it is often undecidable
(Lutz et al., 2007; Konev et al., 2008). Cuenca Grau, Horrocks, Kazakov, and Sattler
(2008) have defined several practically useful sucient syntactic conditions that guarantee
semantic modularity.

3. The Import-by-Query Framework
In this section we introduce our framework. We first present a motivating example, after
which we proceed with a formalization of the import-by-query problem.
Consider a medical research company (MRC) that has developed a knowledge base of
human anatomy. This knowledge base contains concepts describing organs such as Heart
and TV (tricuspid valve); medical conditions such as CHD (congenital heart defect), VSD
(ventricular septum defect), and AS (aortic stenosis); and treatments such as Surgery. The
roles part, con, and treatment relate organs with their parts, medical conditions, and
treatments, respectively, and they are used to define concepts such as VSD Heart (a
heart with a ventricular septum defect) and Sur Heart (a heart that requires surgical
treatment). We focus on reusing schema knowledge, so we assume that the knowledge
base consists only of a TBox Th , which is shown in Table 3. Assume that MRC wants to
freely distribute information about organs and conditions, but hide the information about
treatments. Thus, MRC identifies a set  of public symbols of Th ; we write these symbols
in bold, and the remaining private symbols in sans serif. MRC does not want to distribute
the axioms of Th , as this might allow competitors to copy parts of Th ; therefore, we say that
knowledge base Th is hidden.
Consider also a health-care provider (HCP) that reuses Th to describe types of patients
such as VSD Patient (patients with a ventricular septum defect), HS Patient (patients
requiring heart surgery), AS Patient (patients with aortic stenosis), EA Patient (patients
207

fiCuenca Grau & Motik

Table 3: Example Knowledge Bases
Hidden Knowledge Base Th

1
Heart  Organ  part.TV
2
VSD  CHD
3
AS  CHD
4 VSD Heart  Heart  con.VSD
5 VSD Heart  treatment.Surgery
6 Sur Heart  Heart  treatment.Surgery
Visible Knowledge Base Kv

1 VSD Patient  Patient  hasOrg.VSD Heart
2 HS Patient  Patient  hasOrg.Sur Heart
3 AS Patient  Patient  hasOrg.(Heart  con.AS)
4
Ab TV  TV
5
Dis TV  Ab TV
6
EA Heart  VSD Heart  part.Dis TV
7 EA Patient  Patient  hasOrg.EA Heart
8 Ab TV Heart  Heart  part.Ab TV
9 TVD Patient  Patient  hasOrg.Ab TV Heart
with Ebsteins anomaly), and TVD Patient (patients with a tricuspid valve defect). Since
the TBox Th does not describe Ebsteins anomaly, HCP defines EA Heart as a heart with
a ventricular septum defect and with a displaced tricuspid valve Dis TV ; furthermore, it
defines a displaced tricuspid valve as abnormal, and Ab TV Heart as a heart with an abnormal tricuspid valve. In general, HCPs knowledge base could contain ABox assertions,
so we denote the knowledge base with Kv and call it visible. The axioms of Kv are shown
in Table 3, and the private symbols of Kv are written in italic. HCP can use the combined
knowledge base Kv  Th to deduce that VSD Patient  HS Patient (patients with ventricular septum defect require heart surgery) and EA Patient  TVD Patient (patients with
Ebsteins anomaly are a kind of patients with a tricuspid valve defect).
To support such scenarios, we propose the import-by-query framework. Instead of publishing (a subset of) the axioms of Th , MRC can publish an oracle for Th a service that
advertises a set  of public symbols in Th and a query language L, and that can answer
L-queries over Th provided that these queries use only symbols in . A so-called import-byquery algorithm can then reason with Kv  Th (e.g., determine the satisfiability of Kv  Th )
without having physical access to the contents of Th , by just asking queries to the oracle.
The existence of such an algorithm, however, depends on the oracles query language, the
DLs used to express Kv and Th , and the way in which the symbols from  are reused in Kv .
One of the most popular query languages in description logics is concept satisfiability,
which is available in all DL reasoners known to us. It is thus natural to consider concept
satisfiability oracles, which advertise a signature  and check the satisfiability w.r.t. Th of
(not necessarily atomic) concepts formed using the symbols in . Later on we show that
import-by-query algorithms based on concept satisfiability oracles exist only if rather strong
208

fiReasoning over Ontologies with Hidden Content

restrictions are imposed on the way Kv reuses the symbols from ; roughly speaking, it is
not possible to mix roles from  with concepts private to Kv in existential and universal
restrictions. In our example, this means that axioms 6 and 8 from Table 3 would not be
allowed in Kv . To overcome the limitations of concept satisfiability oracles, we consider two
additional types of (closely related) oracles that are more powerful than the oracles based on
concept satisfiability. An ABox satisfiability oracle is given an ABox A with sig(A)  , and
it checks the satisfiability of A  Th . An ABox entailment oracle is given an ABox A and
an assertion  with sig(A)   and sig()  , and it checks whether A  Th |= . ABox
satisfiability and entailment have been implemented in most state-of-the-art DL reasoners,
so oracles based on such inferences seem natural.
In practice, it is natural to express oracle queries in the same DL as Th ; however, for
the sake of generality we allow queries to be expressed in an arbitrary description logic L.
Intuitively, this allows Kv to learn more about the structure of the models of Th , which
allows us to obtain more general results about nonexistence of import-by-query algorithms.
Definition 3 formally introduces dierent types of oracles.
Definition 3. Let Th be a TBox, let  be a signature, and let L be a description logic.
The concept satisfiability oracle for Th , , and L is the Boolean function cTh ,,L that,
for each L-concept C with sig(C)  , returns t if and only if C is satisfiable w.r.t. Th .
The ABox satisfiability oracle for Th , , and L is the Boolean function aTh ,,L that, for
each connected L-ABox A with sig(A)  , returns t if and only if Th  A is satisfiable.
The ABox entailment oracle for Th , , and L is the Boolean function eTh ,,L that, for
each connected L-ABox A such that sig(A)   and each L-assertion  that mentions only
the individuals in A such that sig()  , returns t if and only if Th  A |= .
We use the generic term oracle for either a concept satisfiability, an ABox satisfiability,
or an ABox entailment oracle. Furthermore, if L is the same as the description logic of Th ,
we abbreviate Th ,,L to Th , . Finally, we often refer to the oracle arguments (i.e., the
concepts C, the ABoxes A, and the pairs A,  in the case of concept satisfiability, ABox
satisfiability, and ABox entailment oracles, respectively) as oracle queries.
We next formally define import-by-query algorithms using the well-known notion of an
oracle Turing machine. A precise definition of the latter is given by Papadimitriou (1993);
we next present just an informal overview of the main ideas. An oracle Turing machine T
has a separate query tape, on which it can write arbitrary strings over a given alphabet. At
any point in time, T can enter a special state q? , upon which a black-box oracle  checks
whether the string currently written on the query tape belongs to the language associated
with ; if that is the case, then T enters a special state qyes , and otherwise T enters a special
state qno . This allows the oracles answers to aect the computation of T . A combination
of T and  is usually written as T  . This definition assumes that the computation of T
depends only on the input and the oracles answers; that is, if 1 and 2 are two distinct
oracles, the computations of T 1 will be indistinguishable from the computations of T 2 if
1 and 2 return the same answers to queries encountered in computations. In the rest of
this paper, we do not make any assumptions on the type of T : any reasonable Turing
machine model can be used. We merely assume that T is equipped with a suitable notion
of a run which captures the computation of T  on each input. A run can (but does not
need to) accept or reject the input.
209

fiCuenca Grau & Motik

Definition 4. A class of inputs C is a class of triples of the form C , KvC , ThC  where C is
a signature, KvC is a knowledge base, and ThC is a TBox such that sig(KvC )  sig(ThC )  C .
Each triple in C is called an input.
An import-by-query algorithm for a description logic L and a class of inputs C based on
oracles of type x  {a, e, c} is an oracle Turing machine ibqx that can be combined with an
oracle of type x. For each input , Kv , Th   C the following properties must be satisfied,
where ibqx [Th , , L] is the combination of ibqx and the oracle xTh ,,L :
1. whenever ibqx [Th , , L] enters the state q? in a run, the string on the query tape encodes
a query accepted by xTh ,,L ;
2. ibqx [Th , , L] has an accepting run on Kv if and only if Kv  Th is satisfiable; and
3. each run of ibqx [Th , , L] on Kv is finite.

Intuitively, the transition relation of ibqx takes into account the possible answers of an
oracle of type x, but ibqx is not executable because the actual oracle is unknown. Thus,
ibqx can be seen as a computer program in which a particular subroutine is missing. Given
an input , Kv , Th   C, we can parameterize ibqx by xTh ,,L to obtain ibqx [Th , , L], and
the latter Turing machine can be freely applied to Kv .
In the rest of this paper, whenever the oracle type is not explicitly given, our discussion
applies to all oracle types. We will consider various classes of inputs, each of which can be
defined using the following formulation:
C is the largest class of triples C , KvC , ThC  where sig(KvC )  sig(ThC )  C and
C , KvC , and ThC satisfy some condition.

Usually, however, we abbreviate such formulations as follows:

C[C , KvC , ThC ] is a class of inputs where C , KvC , and ThC satisfy some condition.

Definition 4 straightforwardly implies the following property, which essentially just reformulates the idea that the runs of a Turing machine are determined only by the oracles
answers, and not the oracles themselves.
Proposition 1. Let ibq be an import-by-query algorithm for a description logic L and a
class of inputs C, let , Kv , Th1  be an arbitrary input from C, and let Q1 , . . . , Qn be the
oracle queries encountered in all possible runs of ibq[Th1 , , L] on Kv . Then, for each Th2
such that , Kv , Th2   C and T 1 ,,L (Qi ) = T 2 ,,L (Qi ) for each 1  i  n, each run of
h
h
ibq[Th1 , , L] on Kv is a run of ibq[Th2 , , L] on Kv and vice versa.

In Section 4 we will identify DLs defining the oracle query language and classes of
inputs for which no import-by-query algorithm based on oracles of a particular type exists.
The following proposition shows that it suces to prove nonexistence results for the most
expressive DL and the smallest class of inputs; then, analogous results then hold for each
weaker DL and each larger class of inputs.
Proposition 2. Let L1 be a description logic and let L2 be a fragment of L1 ; let C1 and C2
be classes of inputs such that each triple in C1 also belongs to C2 ; and let x  {a, c, e} be an
oracle type. If there is no import-by-query algorithm for L1 and C1 based on oracles of type
x, then there is also no import-by-query algorithm for L2 and C2 based on oracles of type x.
210

fiReasoning over Ontologies with Hidden Content

Proof. We prove the contrapositive claim. Let ibqx be an import-by-query algorithm for
L2 and C2 . Since each triple in C1 is also contained in C2 , ibqx is clearly an import-byquery algorithm for L2 and C1 . Let , Kv , Th   C1 be an arbitrary input, and let Q be an
arbitrary L2 -query encountered in a run of ibqx [Th , , L] on Kv . Since L2 is a fragment of
L1 , Q is an L1 -query as well. Thus, ibqx is an import-by-query algorithm for L1 and C1 .
The following theorem shows that oracles of certain types can simulate oracles of other
types. This is important because if 1 can simulate 2 and we show that no import by
query algorithm exists for a particular class of inputs applicable to 1 , then also no such
algorithm exists that is applicable to 2 .
Theorem 1. Let  be the smallest partial order on the class of all oracles that satisfies the
following conditions for each TBox Th , each signature , and each description logic L:
1. cTh ,,L  aTh ,,L  eTh ,,L ; and
2. if for each L-ABox A and each L-assertion  we have that A  {} is an L-ABox,
then eTh ,,L  aTh ,,L holds as well.
Let L be a description logic, let C be a class of inputs, and let x1 , x2  {a, c, e} be oracle
types such that xTh1 ,,L  xTh2 ,,L for each , Kv , Th   C. Then, each import-by-query algorithm ibqx1 for L and C can be transformed into an import-by-query algorithm ibqx2 for
L and C such that, for each input , Kv , Th   C, ibqx1 [Th , , L] has a run on Kv with n
oracle queries if and only if ibqx2 [Th , , L] has a run on Kv with n oracle queries.
Proof. Let ibqx1 be an arbitrary import-by-query algorithm for L and C, and consider
an arbitrary input , Kv , Th   C. Conditions 1 and 2 ensure that xTh1 ,,L is reducible
to xTh2 ,,L in the sense that a computable total function f exists from the domain of
xTh1 ,,L to the domain of xTh2 ,,L such that for each query Q accepted by xTh1 ,,L , we have
xTh1 ,,L (Q) = xTh2 ,,L (f (Q)). In particular, an ABox satisfiability oracle is reducible to an
ABox entailment oracle via f (A) = (A, ) for each ABox A. Furthermore, if Condition
2 holds, then an ABox entailment oracle is reducible to an ABox satisfiability oracle via
f (A, ) = A  {}. Finally, a concept satisfiability oracle is reducible to an ABox satisfiability oracle via f (C) = {C(a)} for a a fresh individual.
Algorithm ibqx2 can then simply simulate ibqx1 on each input , Kv , Th   C; furthermore, whenever ibqx1 [Th , , L] poses a query Q to xTh1 ,,L , then ibqx2 [Th , , L] computes
f (Q) and poses the query f (Q) to xTh2 ,,L . Since ibqx1 is an import-by-query algorithm for
L and C, so is ibqx2 . Furthermore, for each input, there is a one-to-one correspondence between the runs of both algorithms with corresponding runs posing exactly the same number
of oracle queries.
We next show that, if the shared signature  contains only atomic concepts, there is a
close correspondence between ABox and concept satisfiability oracles.
Theorem 2. Let L be a description logic and let C[C , KvC , ThC ] be a class of inputs where C
contains only atomic concepts. Then, each import-by-query algorithm ibqa for L and C can
be transformed into an import-by-query algorithm ibqc for L and C such that the following
statements hold for each input , Kv , Th   C.
211

fiCuenca Grau & Motik

 For each run of ibqa [Th , , L] on Kv with n oracle queries and m the maximum number
of individuals in a query ABox, a run of ibqc [Th , , L] on Kv with at most n  m oracle
queries exists.
 For each run of ibqc [Th , , L] on Kv with n oracle queries, a run of ibqa [Th , , L] on
Kv with at most n oracle queries exists.
Proof. Let ibqa be an import-by-query algorithm for L and C. We define ibqc such that,
on each input , Kv , Th   C, algorithm ibqc [Th , , L] simulates the steps of algorithm
ibqa [Th , , L]; furthermore, when ibqa [Th , , L] queries aTh ,,L with an ABox A, algorithm
ibqc [Th , , L] proceeds as follows.
1. The algorithm transforms A into an ABox A by iterating over all assertions of the
form a  b in A and, for each such assertion, replacing one individual (say a) with
the other one (say b) in all assertions.
2. If A contains an individual a such that a  a  A or cTh ,,L (B1  . . .  Bn ) = f where
B1 , . . . , Bn are all concepts such that Bi (a)  A , then ibqc [Th , , L] proceeds in the
same way as ibqa [Th , , L] for aTh ,,L (A) = f; otherwise, ibqc [Th , , L] proceeds in the
same way as ibqa [Th , , L] for aTh ,,L (A) = t.
There is an obvious correspondence between the runs of ibqa [Th , , L] and ibqc [Th , , L] on
Kv ; furthermore, whenever ibqa [Th , , L] issues a query to aTh ,,L , then ibqc [Th , , L] issues
at most m queries to cTh ,,L in order to determine how to proceed. Finally, note that the
second statement in the theorem directly follows from Theorem 1.
We finally show that we can without loss of generality assume Kv to contain no concept
such as con.AS in axiom 3 in Table 3.
Definition 5. Let  be a signature. A concept C is -modal if sig(C)   and C is of the
form R.D, R.D,  n R.D, or  n R.D.
Intuitively, -modal concepts can always be treated as atomic from the point of view
of Kv , so we can rely on the oracle to compute all relevant consequences of such concepts.
Theorem 3. Let L, DL1 , and DL2 be description logics such that each DL1 -concept is
also an L-concept and DL2 allows for DL1 -definitions; let x  {a, c, e}; let C[C , KvC , ThC ]
be a class of inputs where KvC is a DL1 -knowledge base and ThC is a DL2 -TBox; and let
D[D , KvD , ThD ] be the class of inputs consisting of all triples , Kv , Th  in C[C , KvC , ThC ] in
which Kv contains no -modal concepts. Then, each import-by-query algorithm ibqx2 for L
and D can be transformed into an import-by-query algorithm ibqx1 for L and C.
Proof. For  a signature, C a concept, and  a concept, axiom, or knowledge base, we
say that C is -outermost in  if C is -modal and C does not occur in  as a proper
subconcept of another -modal concept.
Let , Kv , Th   C be an arbitrary input in C, let S be the set of all -outermost concepts
in Kv , and let XC be a fresh atomic concept uniquely associated with each C  S. We define
 , Th , and Kv as follows:  =   {XC | C  S}; Kv is obtained from Kv by replacing each
C  S with XC ; and Th = Th  {XC  C | C  S}. Clearly, Kv  Th is equisatisfiable with
212

fiReasoning over Ontologies with Hidden Content

Kv  Th , and  , Kv , Th   D. Let ibqx2 be an arbitrary import-by-query algorithm for L
and D. We define ibqx1 as the algorithm that on each , Kv , Th   C simulates the steps of
ibqx2 on input  , Kv , Th   D, but with the following modifications:
 ibqx1 [Th , , L] treats all concepts in S as if they were atomic; and
 whenever ibqx2 [Th ,  , L] queries xT  , ,L with a query Q , then ibqx1 [Th , , L] queries
h
xTh ,,L with a query Q obtained from Q by replacing each occurrence of XC with C.
There is an obvious correspondence between the runs of ibqx2 [Th ,  , L] and ibqx1 [Th , , L] on
Kv , so ibqx1 is an import-by-query algorithm for L and C.

4. Limitations of the Import-by-Query Framework
In this section, we explore the limitations of the import-by-query framework and show that
import-by-query algorithms do not exist under certain conditions. Our negative results
apply to classes of input where Kv and Th are expressed in a description logic DL that is
as lightweight as possible, the oracle is based on ABox satisfiability, and the oracle accepts
queries expressed in a description logic L that is as expressive as possible. By Theorem 1
and Proposition 2, our results also apply to all other oracle types, queries expressed in a
fragment of L, and all classes of input where Kv and Th are expressed in a description logic
that extends DL.
In particular, in Section 4.1 we establish the following general limitations of the importby-query framework.
 The presence of nominals in Th may preclude the existence of an import-by-query
algorithm even if  =  (cf. Theorem 4).
 Deductive modularity of the TBox of Kv w.r.t.  is a necessary condition for the
existence of an import-by-query algorithm (cf. Theorem 5).
 Deductive modularity, however, is not sucient, even if Kv and Th are in EL and 
is allowed to contain only atomic concepts (cf. Theorem 6).
In response to these negative results, all import-by-query algorithms proposed in this paper
are subjected to the following restrictions:
R1. Th is not allowed to contain nominals.
R2. The TBox of Kv is required to be semantically modular w.r.t. .
We show in Section 5.1 that these two restrictions are sucient to guarantee the existence
of an import-by-query algorithm for Kv in ALCHIQ and Th in ALCHIQ, provided that 
contains only atomic concepts.
In Section 4.2, however, we show that further restrictions on the input are necessary if 
is allowed to contain atomic roles. Roughly speaking, restrictions R1 and R2 are insucient
since the axioms in Kv can arbitrarily propagate information about the symbols private to
Kv via a role in  to a hidden part of the canonical model of Kv  Th (that is, a part of the
canonical model that cannot be constructed using only the axioms in Kv ); such propagation
213

fiCuenca Grau & Motik

can occur both via existential (cf. Theorem 7) and universal quantification (cf. Theorem 8).
To overcome these negative results, we define in Section 5.1 the HT-safety condition that,
on the one hand, ensures semantic modularity and, on the other hand, prevents arbitrary
transfer of information about the symbols private to Kv to hidden parts of the canonical
model via a role in . This condition, however, is still insucient to enable import-byquery reasoning if Th contains universal quantifiers, inverse roles, and functional roles, and
Kv entails cyclic axioms of the form A  R.A for R   and A   (cf. Theorem 9).
To overcome this negative result, in Section 5.1 we introduce an acyclicity condition that
together with HT-safety guarantees the existence of an import-by-query algorithm based
on ABox satisfiability oracles for Kv and Th expressed in ALCHIQ.
Finally, in Section 4.3 we show that no import-by-query algorithm based on concept
satisfiability oracles exists for the class of inputs C[C , KvC , ThC ] where KvC is in EL and it
satisfies the HT-safety condition, and ThC is in EL (cf. Theorem 10). In Section 5.2.2,
however, we present an algorithm based on ABox entailment oracles that applies to this
class of inputs C. Thus, practically relevant cases exist for which import-by-query reasoning
is impossible with concept satisfiability oracles, but it becomes feasible with ABox oracles.
4.1 General Limitations
We first show that the presence of nominals in the hidden knowledge base precludes the
existence of an import-by-query algorithm if the visible knowledge base is satisfiable only in
infinite models. Expressive DLs used in practice often do not have the finite model property,
and our negative result holds even if the shared signature is empty; thus, in the rest of this
paper we do not further consider DLs with nominals, and we leave an investigation of
conditions that enable import-by-query reasoning with such DLs for future work.
Theorem 4. For each description logic DL without the finite model property, no importby-query algorithm based on ABox satisfiability oracles exists for L = ALCHOIQ and the
class of inputs C[C , KvC , ThC ] where C = , KvC is a DL-knowledge base, and ThC is an
ALCHOIQ-TBox.
Proof. Let C be an arbitrary class of inputs and let ibqa be an arbitrary import-by-query
algorithm such that C and ibqa both satisfy the theorems assumptions. Furthermore, let
, Kv , Th1   C be an arbitrary input where KvC is satisfiable only in infinite models,  = ,
and Th1 = . Since all runs of ibqa [Th1 , , L] on Kv are finite, the number of individuals
occurring in a query ABox in each such run is bounded by some integer n. Let Th2 be as
follows, where O1 , . . . , On are fresh nominal concepts:
Th2 = {  O1  . . .  On }

(9)

Clearly, Kv  Th1 is satisfiable, but Kv  Th2 is not. Consider now an arbitrary query ABox
A occurring in a run of ibqa [Th1 , , L]. Since  = , A consists only of assertions of the form
a  b or a  b; furthermore, A contains at most n individuals, so aT 1 , (A) = t implies
h

aT 2 , (A) = t, and the converse holds by the monotonicity of first-order logic. But then, by
h

Proposition 1, the runs of ibqa [Th1 , , L] on Kv coincide with the runs of ibqa [Th2 , , L] on
Kv , which contradicts the fact that Kv  Th1 is satisfiable but Kv  Th2 is not.
214

fiReasoning over Ontologies with Hidden Content

We next present a very strong result: deductive modularity is a necessary requirement
for the existence of an import-by-query algorithm; that is, no import-by-query algorithm
exists for any class of inputs that contains a triple , Kv , Th  such that the TBox of Kv
is not deductively modular w.r.t. . Intuitively, without deductive modularity, Kv can
arbitrarily influence the consequences of Th , and the oracle cannot take this into account
since it does not have access to the axioms of Kv . For the sake of generality, we do not
impose any conditions on .
Theorem 5. Let DL1 be an arbitrary fragment of ALCHIQ; let DL2 be an arbitrary
description logic that extends EL and allows for DL1 -definitions; let  be an arbitrary
signature; and let Kv be an arbitrary satisfiable DL1 -knowledge base whose TBox is not
deductively modular w.r.t. . Then, no import-by-query algorithm based on ABox satisfiability oracles exists for L = ALCHIQ and the class of inputs C[C , KvC , ThC ] where C = ,
KvC = Kv , and ThC is a DL2 -TBox.
Proof. Let C be a class of inputs satisfying the theorems conditions, and let , Kv , Th1   C
be an input where Th1 = . Since Kv is not deductively modular w.r.t. , possibly complex DL1 concepts C1 and C2 exist such that sig(C1 )  , sig(C2 )  , Tv |= C1  C2 , and
 |= C1  C2 . Let ibqa be an import-by-query algorithm for L = ALCHIQ and C. Finally,
let Th2 be as follows, where A, B1 , B2 , and R do not occur in .
Th2 = { B1  C1 , B2  C2 ,   R.(A  B1 ), A  B2   }

(10)

Clearly, Kv  Th1 is satisfiable, but Kv  Th2 is not. Consider now an arbitrary L-ABox
A such that sig(A)  . If A  Th1 is unsatisfiable, so is A  Th2 . Conversely, assume


that A  Th1 is satisfiable in a model I  = (I , I ). Since  |= C1  C2 , an interpretation





I  = (I , I ) and a domain element x  I exist such that x  C1I but x  C2I . With

out loss of generality we assume that I  I = . Let I be the following interpretation:
I
aI
AI
B1I
B2I
RI
XI





= I  I

= aI for each individual a occurring in A
= {x}


= C1I  C1I


= C2I  C2I
= {o, x | o  I }


= X I  X I for each atomic concept or role X  




Now for each ALCHIQ-concept E such that sig(E)  , since I and I are disjoint, by


a straightforward induction on the structure of E one can show that E I = E I  I and



E I = E I  I . Furthermore, S I  S I for each atomic role S  . Thus I |= A, and it is
straightforward to check that I |= Th2 . Consequently, aT 1 ,,L (A) = aT 2 ,,L (A) for each Lh

h

ABox A with sig(A)  . Hence, by Proposition 1, the runs of ibqa [Th1 , , L] on Kv coincide
with the runs of ibqa [Th2 , , L] on Kv , which contradicts the fact that Kv  Th1 is satisfiable
but Kv  Th2 is not.

While Theorem 5 shows that deductive modularity is a necessary requirement for an
import-by-query algorithm to exist, the following theorem shows that it is not a sucient
215

fiCuenca Grau & Motik

requirement, even if  contains only atomic concepts, Kv is an EL-knowledge base, and Th
is an EL-TBox.
Theorem 6. No import-by-query algorithm based on ABox satisfiability oracles exists for
L = ALCHIQ and the class of inputs C[C , KvC , ThC ] where C contains only atomic concepts,
KvC and ThC are in EL, and the TBox of KvC is deductively modular w.r.t. C .
Proof. Let ibqa be an import-by-query algorithm satisfying the theorems assumptions, let
 = {A, B, C}, and let Kv , Th1 , and Th2 be the following EL knowledge bases:
Kv = { A(a), B  R.C }

(11)

= Th1  { A  S.B }

(13)

Th1
Th2

={C}

(12)

The TBox of Kv is clearly deductively modular w.r.t. , so , Kv , Thi   C for i  {1, 2};
furthermore, Kv  Th1 is satisfiable, whereas Kv  Th2 is not. Consider now an arbitrary
query ABox A such that sig(A)  ; since A contains only assertions of the form X(a),
X(a), a  b, and a  b where sig(X)  , we have aT 1 ,,L (A) = aT 2 ,,L (A). But then,
h

h

by Proposition 1, the runs of ibqa [Th1 , , L] on Kv coincide with the runs of ibqa [Th2 , , L]
on Kv , which contradicts the fact that Kv  Th1 is satisfiable but Kv  Th2 is not.

While deductive modularity is not sucient, semantic modularity is sucient in some
cases: in Section 5.1 we present an import-by-query algorithm that can be applied to the
case when  contains only atomic concepts, Kv and Th are in ALCHIQ, and the TBox of
Kv is semantically modular w.r.t. .
4.2 Limitations of Importing Atomic Roles
In this section, we establish the limitations of the import-by-query framework for the cases
when  is allowed to contain atomic roles. In particular, we show that semantic modularity
is not sucient to guarantee existence of an import-by-query algorithm.
Theorems 7 and 8 demonstrate problems that arise due to certain fundamental limitations of our oracle query languages. To understand the intuition behind these results,
assume that the shared signature  contains one atomic role R. Even in the relatively simple
DL EL, knowledge base Th can imply existence of arbitrarily long R-chains using an axiom
such as C  R.C. All of the oracle languages that we consider, however, can examine only
bounded prefixes of such chains. For example, assume that we use an ABox satisfiability oracle and a query language based on ALCHIQ. Each concept in a query ABox corresponds
to a first-order formula, and it is well known that the satisfiability of such a formula in a
first-order interpretation depends on the formulas quantifier depth. Since the number of
oracle calls in a run of an import-by-query algorithm must be bounded, an import-by-query
algorithm can examine only a bounded prefix of a model of Th . But this leads us to a
fundamental problem: if Th is changed so that it has interesting consequences that can
be detected only by examining longer R-chains, then such consequences will go undetected
by our algorithm and render the algorithm incorrect. Theorem 7 exploits the fact that the

216

fiReasoning over Ontologies with Hidden Content

interesting consequences of Th are detected by Kv using axioms with existentially quantified concepts (i.e., our proof uses axiom R.B2  B2 ), whereas Theorem (8) analogously
uses axioms with universally quantified concepts (i.e., B  R.B).
An alternative intuitive explanation of the results in Theorems 7 and 8 is to think
of the culprit axioms R.B2  B2 and B  R.B in Kv as propagating information from
Kv into Th . In order not to miss the interesting consequences of Th , an import-by-query
algorithm must examine a suciently large portion of the hidden part of a canonical model
of Kv  Th in order to correctly evaluate the culprit axioms. This, however, is impossible
because no bound on the portion size can be determined from the algorithms inputs.
Theorem 7. No import-by-query algorithm based on ABox satisfiability oracles exists for
L = ALCHIQ and the class of inputs C[C , KvC , ThC ] where C is arbitrary, KvC and ThC are
expressed in EL, and the TBox of KvC is semantically modular w.r.t. C .
Proof. Let ibqa be an import-by-query algorithm satisfying the theorems assumptions, let
 = {A1 , A2 , R}, and let Kv be the following EL knowledge base:
Kv = { B1 (a), B1  S.A1 , A2  B2 , R.B2  B2 , S.B2   }

(14)

The TBox of Kv is semantically modular w.r.t. : for each interpretation I of the symbols
in , the interpretation J such that X J = X I for each X  , B1J = , B2J = J , and
S J =  is a model of the TBox of Kv . Let Th1 be the following EL TBox:
Th1 = { A1  C, C  R.C }

(15)

Since each run of ibqa [Th1 , , L] on Kv is finite, an integer n exists such that each query
ABox occurring in a run contains concepts of quantifier depth at most n. Let Th2 be the
following EL TBox:
Th2 = {A1  R
. . R .A2 }
 .
n + 1 times

(16)

Clearly, Kv  Th1 is satisfiable, whereas Kv  Th2 is not. Consider an arbitrary query ABox
A occurring in a run of ibqa [Th1 , , L]. We next show that aT 1 ,,L (A) = aT 2 ,,L (A).
h

h

Assume that Th1  A is satisfiable. Since A is expressed in ALCHIQ and Th1 is in EL, a
canonical forest model I = (I , I ) of Th1  A exists (e.g., such a model can be obtained by
applying the hypertableau algorithm to Th1 and A). Due to (15), for each x  AI1 , an infinite
x   RI for each 0  i.
sequence {0x , 1x , 2x , . . .}  I exists such that 0x = x and ix , i+1
J
J
Let J = ( ,  ) be the interpretation defined as follows:
J = I

x
AJ2 = AI2  {n+1
| x  AI1 }

X J = X I for each X = A2

Clearly, J |= Th2 . Furthermore, since I |= A, A contains concepts of quantifier depth at
most n, and I and J coincide up to depth n, we have J |= A. Thus, Th2  A is satisfiable.
Assume that Th2  A is satisfiable. Then a canonical forest model I = (I , I ) of Th2  A
x }  I exists
exists. Due to (16), for each x  AI1 , a finite sequence {0x , 1x , 2x , . . . , n+1
217

fiCuenca Grau & Motik

x   RI for each 0  i < n. Let J = (J , J ) be the interpresuch that 0x = x and ix , i+1
tation defined as follows:

J = I
x
C J = {0x , . . . , n+1
| x  AI1 }

x ,  x  | x  AI }
RJ = RI  {n+1
n+1
1
X J = X I for each X  {R, C}

Clearly, J |= Th1 . Furthermore, since I |= A, C  sig(A), A contains only concepts of
quantifier depth at most n, and I and J coincide up to depth n, we have J |= A. Thus,
Th1  A is satisfiable.
By Proposition 1, the runs of ibqa [Th1 , , L] on Kv coincide with the runs of ibqa [Th2 , , L]
on Kv , which contradicts the fact that Kv  Th1 is satisfiable but Kv  Th2 is not.
Theorem 8. No import-by-query algorithm based on ABox satisfiability oracles exists for
L = ALCHIQ and the class of inputs C[C , KvC , ThC ] where C is arbitrary, KvC is expressed
in FL0 , ThC is expressed in EL, and the TBox of KvC is semantically modular w.r.t. C .
Proof. Let ibqa be an import-by-query algorithm satisfying the theorems assumptions, let
 = {A1 , A2 , R}, and let Kv be the following FL0 knowledge base.
Kv = { A1 (a), B(a), B  R.B, A2  B   }

(17)

The TBox of Kv is semantically modular w.r.t. : for each interpretation I for , the
interpretation J such that X J = X I for each X   and B J =  is a model of the TBox
of Kv . Let Th1 be the EL TBox (15) given in the proof of Theorem 7. Since each run of
ibqa [Th1 , , L] on Kv is finite, an integer n exists such that each query ABox occurring in
a run contains concepts of quantifier depth at most n. Let Th2 be the the EL TBox (16)
from Theorem 7. Clearly, Kv  Th1 is satisfiable, whereas Kv  Th2 is not. Using arguments
analogous to those from the proof of Theorem 7, one can show that aT 1 ,,L (A) = aT 2 ,,L (A)
h

h

for each query ABox A occurring in a run of ibqa [Th1 , , L]. By Proposition 1, the runs of
ibqa [Th1 , , L] on Kv coincide with the runs of ibqa [Th2 , , L] on Kv , which contradicts the
fact that Kv  Th1 is satisfiable but Kv  Th2 is not.

A possible way to overcome these negative results is to prevent the axioms in Kv from
propagating information via the roles in  into the hidden part of a canonical model of
Kv  Th . In Section 5.1, we achieve this by requiring Kv to be HT-safe. Roughly speaking,
such Kv is semantically modular w.r.t. , but, in addition, it can be translated into a set of
HT-rules Rv where variables x and y in each role atom of the form R(x, y) with R   are
guarded by suitable concepts. For example, although the knowledge base Kv in (17) is
semantically modular w.r.t.  = {A1 , A2 , R}, the axiom B  R.B  Kv violates the HTsafety condition since the body of its corresponding HT-rule B(x)  R(x, y)  B(y) does
not contain a guard concept atom for variable y. In order to streamline the presentation
and ensure that all notions needed to enable import-by-query reasoning are defined in one
place, we formalize HT-safety in Definition 6 in Section 5.1. Unfortunately, as Theorem 9
shows, HT-safety alone does not ensure existence of an import-by-query algorithm.
Theorem 9. No import-by-query algorithm based on ABox satisfiability oracles exists for
L = ALCHIQ and the class of inputs C[C , KvC , ThC ] where C is arbitrary, KvC is expressed
in EL, ThC is expressed in Horn-ALCIF, and the TBox of KvC is HT-safe w.r.t. C .
218

fiReasoning over Ontologies with Hidden Content

Proof. Let ibqa be an import-by-query algorithm satisfying the theorems assumptions, let
 = {B, R}, and let Kv be the following EL knowledge base:
Kv = { A(a), B(a), A  R.A }

(18)

The TBox of Kv is semantically modular w.r.t. : for each interpretation I for , the
interpretation J such that X J = X I for each X   and AJ =  is a model of the TBox
of Kv . According to Definition 6, the TBox of Kv is then HT-safe as well. Let Th1 be the
following Horn-ALCIF TBox:
Th1 = { B  C  , B  R.C, C  R.C,    1 R }

(19)

Since each run of ibqa [Th1 , , L] on Kv is finite, integers n and m exist such that each query
ABox occurring in a run contains at most n individuals and concepts of quantifier depth at
most m. Let k = n + m and let D0 , . . . , Dk be distinct and fresh atomic concepts. Let Th2
be the following Horn-ALC TBox:
Th2 = Th1  { Di  Dj  , | 0  i < j  k }  { Dj1  R.Dj | 1  i  k }
 { B  D0 , Dk   }

(20)

Clearly, Kv  Th1 is satisfiable, whereas Kv  Th2 is not. Consider an arbitrary query
ABox A occurring in a run of ibqa [Th1 , , L]. We next show that aT 1 ,,L (A) = aT 2 ,,L (A).
h

h

This clearly holds if Th1 A is unsatisfiable, so assume that Th1 A is satisfiable. Then, there
exists a canonical forest model I = (I , I ) of Th1  A. Consider now an arbitrary domain
element x  B I . We say that a domain element y  I is reachable from x in  steps if a
sequence of domain elements 0 = x, 1 , 2 , . . . ,  = y exist such that i , i+1   RI for
each 1  i < . For each such x and y, the axioms of Th1 ensure the following properties:
1. Each such sequence is unique and it consists of unique domain elements. This is
because RI is an inverse-functional relation so, for each 0  i < , domain element i is
the only element such that i , i+1   RI , so i = j for 0 < i < j  ; furthermore,
0  B I and 0  C I , and i  C I for 0 < i  , which ensures 0 = i for 0 < i  .
2. No x  B I distinct from x exists such that y is reachable form x . This is because
xi  B I for each 0 < i   and RI is inverse-functional.
3.  < k. This is because A contains at most n individuals and all concepts in A are of
quantifier depth at most m.
Let J = (J , J ) be an interpretation defined as follows:
I
J = 
X J = X I for each X  sig(Th1 )
DkJ = 
DiJ =
{y  I | y is reachable from x in i steps } for each 0  i < k
xB I

Interpretations I and J coincide on the symbols from Th1 , so J |= A  Th1 . Furthermore, if
y  DiI with i < k, by properties 13 then y  DjI for each j = i, so J |= A  Th2 . But then,
by Proposition 1, the runs of ibqa [Th1 , , L] on Kv coincide with the runs of ibqa [Th2 , , L]
on Kv , which contradicts the fact that Kv  Th1 is satisfiable but Kv  Th2 is not.
219

fiCuenca Grau & Motik

The proof of Theorem 9 uses Kv that implies A  Rn .A for arbitrary n, where A  
and R  . Furthermore, axioms in Th containing universally quantified concepts propagate information along an R-chain to an unknown level m. An import-by-query algorithm
cannot determine the depth to which it must examine a model of Kv , which precludes the
termination requirement of Definition 4. In Section 5.1, we present a sucient acyclicity
restriction on Kv that bounds n and ensures the existence of an import-by-query algorithm.
4.3 ABox vs. Concept Satisfiability Oracles
In this section we show that, for Kv an EL-knowledge base and and Th an EL-TBox, no
import-by-query algorithm based on concept satisfiability oracles exists, even if Kv is HTsafe w.r.t. . This is interesting because in Section 5.2.2 we present an algorithm based on
ABox entailment oracles that can handle such a case. Thus, ABox oracles are strictly more
expressive than concept satisfiability oracles.
Theorem 10. No import-by-query algorithm based on concept satisfiability oracles exists
for L = ALCHIQ and the class of inputs C[C , KvC , ThC ] where C is arbitrary, KvC and ThC
are expressed in EL, and the TBox of KvC is HT-safe w.r.t. C .
Proof. Let ibqc be an import-by-query algorithm satisfying the theorems assumptions, let
 = {R}, and let Kv be the following EL knowledge base:
Kv = { A(a), A  R.A }

(21)

By Definition 6, the TBox of Kv is HT-safe. Let Th1 = . Each run of ibqc [Th1 , , L] on Kv
is finite, so an integer n exists such that each query concept occurring in a run contains
concepts of quantifier depth at most n. Let Th2 be the following EL TBox:
Th2 = { R. 
. . . R .   }
n + 1 times

(22)

Clearly, Kv  Th1 is satisfiable, whereas Kv  Th2 is not. Furthermore, it is straightforward
to see that, for each ALCHIQ concept C of quantifier depth at most n with sig(C)  ,
we have Th1 |= C   if and only if Th2 |= C  , so cT 1 , (C) = cT 2 , (C). But then, by
h

h

Proposition 1, the runs of ibqc [Th1 , , L] on Kv coincide with the runs of ibqc [Th2 , , L] on
Kv , which contradicts the fact that Kv  Th1 is satisfiable but Kv  Th2 is not.
Note that the knowledge base Kv used in the proof of Theorem 10 is analogous to the
one from the proof of Theorem 9that is, it entails a cyclic axiom of the form A  R.A
with R   but A  . The negative result from Theorem 9, however, does not apply in this
case because Th is expressed in EL. The algorithm presented in Section 5.2.2 can handle
such knowledge bases via an ABox entailment oracle. Intuitively, this is because ABoxes
can encode cyclic structures, whereas concepts cannot.

5. Import-by-Query Algorithms
In this section, we identify several cases in which import-by-query algorithms exist. For
simplicity, throughout this section we assume that Kv does not contain -modal concepts;
by Theorem 3 this is without loss of generality.
220

fiReasoning over Ontologies with Hidden Content

To overcome the negative results from Section 4, in Sections 5.1.1 and 5.1.2 we introduce
the HT-safety and acyclicity conditions, respectively, that Kv must satisfy in order to prevent the undesirable interactions between the axioms of Kv and Th . Furthermore, in the rest
of this paper we assume that Kv is preprocessed as described by Motik et al. (2009) into the
corresponding set of HT-rules Rv and ABox Av ; this will be convenient because HT-rules
do not contain nested quantifiers. We thus formulate HT-safety and acyclicity in terms of
Rv and Av , and we define Kv as being HT-safe (resp. acyclic) if the corresponding Rv and
Av are HT-safe (resp. acyclic). All our algorithms take as inputs Rv and Av , and we specify
the allowed inputs using classes C[C , RCv  ACv , ThC ] of triples C , RCv  ACv , ThC  where Rv
is a set of HT-clauses, Av is a normalized ABox, and sig(RCv  ACv )  sig(ThC )  C .
In Section 5.1 we present a general import-by-query algorithm based on ABox satisfiability oracles that is applicable to the case when Kv imports both atomic concepts and
roles, and Kv and Th are expressed in ALCHIQ. In order for the algorithm to be applicable,
however, Kv must be both HT-safe and acyclic. If  contains only atomic concepts, then
acyclicity is vacuously satisfied for each Kv and HT-safety becomes equivalent to semantic
modularity; thus, if only atomic concepts are shared, our algorithms is applicable whenever
Kv is semantically modular w.r.t. .
The algorithm from Section 5.1, however, is unlikely to be suitable for practice due to a
high degree of nondeterminism. Therefore, in Section 5.2.1 we present an import-by-query
algorithm based on ABox entailment oracles that, we believe, is suited for implementation
and optimization. The algorithm requires Th to be a Horn knowledge base, which allows
the algorithm to be more goal-oriented.
The practical algorithm from Section 5.2.1 can readily be applied to EL knowledge bases,
but it is not guaranteed to be optimal. Therefore, in Section 5.2.2 we present an EL-specific
import-by-query algorithm for the case when Kv and Th are expressed in EL. In addition
to being optimal on EL knowledge bases, this EL-specific algorithm does not require Kv to
be acyclic and it somewhat relaxes the HT-safety requirement.
5.1 Import-by-Query in ALCHIQ

We next present an import-by-query algorithm based on ABox satisfiability oracles that is
applicable to a set of HT-rules Rv and a TBox Th in ALCHIQ. No assumptions are made
on the type of symbols in : Rv can reuse both atomic concepts and roles from Th .
5.1.1 HT-Safety
We now define the HT-safety condition that allows us to overcome the negative results of
Theorems 7 and 8, and that also guarantees semantic modularity required to overcome the
negative results of Theorems 5 and 6. If  contains only atomic concepts, then HT-safety
reduces to the semantic modularity of Rv w.r.t. .
The notion of HT-safety for Rv consists of the following building blocks. We first identity
the safe conceptsthat is, concepts private to Rv that should not be propagated into
the models of Th . Next, we transform Rv into a reduct by replacing in Rv all safe concepts
with , and we require the reduct to be semantically modular w.r.t. . The latter property
ensures that any interpretation for the symbols in  can be extended to an interpretation of
the symbols in Rv by interpreting safe concepts as the empty set. Finally, as motivated in
221

fiCuenca Grau & Motik

Section 4.2, we impose a syntactic restriction on each HT-rule   Rv : for each body atom
R(x, y) in  with R  , we require variables x and y to be guarded by a safe concept.

Definition 6. Let Rv be a set of HT-rules and let  be a signature. The set of safe concepts
of Rv and  is the smallest set safe(Rv , ) such that, for each HT-rule   Rv whose body
contains an atom of the form R(x, yi ) or R(yi , x) with R   and an atom of the form A(x)
or A(yi ) with A  , we have A  safe(Rv , ).
The reduct of Rv w.r.t.  is the set of rules obtained from Rv by removing each rule
containing a concept in safe(Rv , ) in the body, and then removing from the head of the
remaining rules each atom containing a concept in safe(Rv , ).
The set Rv is HT-safe w.r.t.  if
1. the reduct of Rv w.r.t.  is semantically modular w.r.t. , and

2. for each rule   Rv and each body atom of  of the form R(x, yi ) or R(yi , x) with
R  , the body of  contains atoms A(x) and B(yi ) such that A, B  safe(Rv , ).

HT-safety invalidates the proofs of Theorems 7 and 8: the knowledge bases Kv used
in the proofs of these two theorems are not HT-safe w.r.t. the respective signatures . In
particular, consider Kv used in the proof of Theorem 7. The set of HT-rules Rv obtained
from the TBox of Kv is shown below.
B1  S.A1
A2  B2

R.B2  B2
S.B2  



B1 (x)  S.A1 (x)



A2 (x)  B2 (x)



R(x, y)  B2 (y)  B2 (x)



S(x, y)  B2 (y)  

(23)
(24)
(25)
(26)

Now safe(Rv , ) = {B2 }. It is straightforward to see that the reduct of Rv w.r.t. , shown
below, is not semantically modular w.r.t.  = {A1 , A2 , R}.
B1 (x)  S.A1 (x)

(27)

A2 (x)  

(28)

Consider now Kv used in the proof of Theorem 8. The set of HT-rules Rv obtained from
the TBox of Kv is shown below.
B  R.B

A2  B  



B(x)  R(x, y)  B(y)



A2 (x)  B(x)  

(29)
(30)

Now safe(Rv , ) = {B}, so the reduct of Rv w.r.t.  is empty and thus semantically modular
w.r.t.  = {A1 , A2 , R}; however, the first HT-rule does not satisfy Condition 2 from Definition 6 since the rule body does not contain an atom of the form A(y) with A  safe(Rv , ).
Note that, if  contains only atomic concepts, then safe(Rv , ) = . The reduct of Rv
w.r.t.  is then equal to Rv , so Condition 1 from Definition 6 holds if and only if Rv is
semantically modular w.r.t. ; furthermore, Condition 2 vacuously holds for Rv . Thus,
HT-safety reduces to semantic modularity w.r.t.  if only atomic concepts are shared. The
following proposition shows that, given an interpretation for the symbols in , we can obtain
a model of Rv by interpreting safe concepts as the empty set.
222

fiReasoning over Ontologies with Hidden Content

Proposition 3. Let Rv be a set of HT-rules that is HT-safe w.r.t. . Then, for each
interpretation I of the symbols in , a model J of Rv exists such that J = I , X J = X I
for each symbol X  , and X J =  for each atomic concept X  safe(Rv , ).
Proof. Let I be an interpretation for the symbols in , and let Rv be the reduct of Rv w.r.t

. Since Rv is semantically modular w.r.t. , a model I  of Rv exists such that I = I

and X I = X I for each symbol X  . Let J be the interpretation obtained from I  by
setting X J =  for each X  safe(Rv , ). Consider now an arbitrary HT-rule   Rv . If
some A  safe(Rv , ) occurs in the body of , then AJ =  clearly implies J |= . Otherwise,
let   Rv be the rule obtained by removing in  all head atoms that contain a safe concept;
then I  |=  clearly implies J |= . Consequently, J |= Rv .
Finally, note that HT-safety is not a syntactic condition; in fact, checking HT-safety is
undecidable in general because it requires checking semantic modularity of a set of HT-rules
w.r.t. a signature. As mentioned in Section 2.3, however, several practically useful syntactic
conditions are known that guarantee semantic modularity (Cuenca Grau, Horrocks, Kazakov, & Sattler, 2008), and any such condition can be used to obtain a purely syntactic
HT-safety notion.
5.1.2 Acyclicity
The negative result of Theorem 9 relies on Kv containing a cyclic axiom A  R.A with
R   and A  . We next present a sucient condition that can detect such cycles in
polynomial time.
Our test involves a set of function-free first-order formulae with equality D(Rv , Av )
whose consequences summarize the models of Rv  Th  Av ; more precisely, the projection
of each canonical model of Rv  Th  Av to the symbols in sig(Rv ) can be homomorphically
embedded into the set of ground facts entailed by D(Rv , Av ). Intuitively, since the axioms of
Th are not available, the facts entailed by D(Rv , Av ) should reflect all possible consequences
of Th and all information that can be derived using Rv  Av . Theory D(Rv , Av ) also keeps
track of the paths in the visible part of the canonical models of Rv  Th  Av by using
two special binary predicates: Succ keeps track the successorship relation between domain
elements, and -Desc keeps track the descendant relation via roles contained in . The
acyclicity condition then checks whether the -Desc relation as entailed by D(Rv , Av ) is
cyclic; if this is not the case, we can establish a bound on the length of paths of roles in .
Definition 7. Let Rv be a set of HT-rules, let Av be an ABox, and let  be a signature. For
each atomic concept A  sig(Rv )  sig(Av ), let vA and vA be individuals uniquely associated
with A and A, respectively; furthermore, let Succ and -Desc be binary predicates not
occurring in Rv or Av . Function tt() maps each atom  occurring in Rv  Av into a
conjunction of atoms as follows, where z is an arbitrary term:
 tt(A(z)) = ;
 tt( n R.C(z)) = ar(R, z, vC )  tt(C(vC ))  Succ(z, vC ); and
 tt() =  for each atom  of the form not covered by the above two cases.
223

fiCuenca Grau & Motik

Furthermore, D(Rv , Av ) is the set of function-free formulas of first-order logic with
equality defined as follows, where all variables are implicitly universally quantified.
 For each assertion   Av , set D(Rv , Av ) contains tt().
 For each individual c occurring in Av and each atomic concept A  , set D(Rv , Av )
contains A(c).
 For each HT-rule   Rv of the form (1) and each 1  j  n, set D(Rv , Av ) contains
the following formula:
tt(U1 )  . . .  tt(Um )  tt(Vj )

(31)

 For each atomic concept A  , set D(Rv , Av ) contains the following formula:
Succ(z1 , z2 )  A(z2 )

(32)

 For all atomic roles R, R  , set D(Rv , Av ) contains the following formulae:
R (z1 , z2 )  R(z1 , z2 )


R (z1 , z2 )  R(z2 , z1 )

(33)
(34)



(35)



(36)



(37)

R(z, z1 )  R (z, z2 )  z1  z2
R(z1 , z)  R (z2 , z)  z1  z2
R(z1 , z)  R (z, z2 )  z1  z2

 For each atomic role R  , set D(Rv , Av ) contains the following formulae:
Succ(z1 , z2 )  R(z1 , z2 )  -Desc(z1 , z2 )

-Desc(z1 , z2 )  -Desc(z2 , z3 )  -Desc(z1 , z3 )

(38)
(39)

Set D(Rv , Av ) contains a harmful cycle if D(Rv , Av ) |= -Desc(vC , vC ) for some vC . Furthermore, Rv  Av is acyclic w.r.t.  if D(Rv , Av ) does not contain a harmful cycle.
The set of formulae D(Rv , Av ) can be straightforwardly transformed into an equivalent datalog program with equality using the well-known equivalences of first-order logic;
therefore, we often refer to D(Rv , Av ) as a datalog program.
Acyclicity allows us to express axioms 6 and 8 from Table 3. Intuitively, acyclicity
ensures that the visible parts of the canonical forest models of Rv  Th  Av do not contain
infinite chains of roles from ; we use this property in our algorithm to define a suitable
blocking condition. We explain this intuition by means of an example. Let  = {C, R, U }
where C is a concept and R and U roles, Av = {A(a)}, and Rv contains the following HTrules; the corresponding formulae in D(Rv , Av ) are shown after the  symbol. Note that
Rv is HT-safe w.r.t. .
A(x)  R.B(x) 
A(x)  S.C(x) 

A(x)  R(x, vB )  B(vB )  Succ(x, vB ) (40)
A(x)  S(x, vC )  C(vC )  Succ(x, vC ) (41)

224

fiReasoning over Ontologies with Hidden Content

B, C
U
A

U

B, C,E
b

U
A

R
a

b

A, C
e

R

R
a

S

S
c

C, D

S

C, D
c

d

A

(a) Model

A
d

S

(b) Extended Model

B, C
B, C, D

vB

vB vC
vD

R R
U U

A, C

B, C, E

vB
vE

R R
U U
S S

a
vA

R R
U U

S
C, D
S

A, C

vC
vD

(c) Acyc. Check

a
vA

A, C

a
vA

S
C, D
S

(d) Acyc. Check (I)

vC
vD

(e) Acyc. Check (II)

Figure 1: Canonical Models and Acyclicity
A(x)  S.D(x) 

S(x, y1 )  S(x, y2 )  y1  y2



A(x)  S(x, vD )  D(vD )  Succ(x, vD ) (42)
S(x, y1 )  S(x, y2 )  y1  y2

(43)

C(x)  D(x)  S.A(x)  C(x)  D(x)  S(x, vA )  A(vA )  Succ(x, vA ) (44)

Consider also the following hidden TBox expressed in ALCHIQ:
Th = {    1 R., R  U  , U.  C }

(45)

Figure 1(a) shows a canonical model I of Rv  Th  Av . Furthermore, Figure 1(c) shows the
ground atoms entailed by D(Rv , Av ) represented as a graph G in which solid arrows show
roles R, U , and S, and dashed arrows show the special predicate -Desc; for clarity, the
atoms involving the special predicate Succ have not been included in this and the following
figures. Note that D(Rv , Av ) entails R(vA , vB ) and R(a, vB ); these atoms, together with
rules (34) and (35), entail vA  va ; consequently, vA and va are represented in Figure 1(c)
by the same node. Structure G summarizes I in the sense that I can be homomorphically
embedded into G. The repetitive structure of I is represented in G as a cycle over nodes vA
and vC via S; however, since S is not a shared symbol (i.e., S  ), this does not give rise
to a harmful cycle. Consequently, Rv  Av is acyclic w.r.t. , which guarantees that the
visible part of a model of Rv  Th  Av does not contain R-chains of unbounded length,
regardless of the contents of Th . Accordingly, the canonical model I of Rv  Th  Av shown
in Figure 1(a) contains no such R-chains.
225

fiCuenca Grau & Motik

Note, however, that G overestimates the canonical model I; for example, G contains an
individual vA that is an instance of both A and C, which is not reflected in I. Now let us
assume that Rv is Rv extended with the following HT-rule:
A(x)  C(x)  R.C(x)



A(x)  C(x)  R(x, vC )  C(vC )  Succ(x, vC )

(46)

The canonical model of Rv  Th  Av is clearly the same as that of Rv  Th  Av ; however,
D(Rv , Av ) contains a harmful cycle, as shown in Figure 1(d). Intuitively, D(Rv , Av ) provides
us with a conservative overestimate of the canonical models, which can in some cases detect
cycles that do not really exist in canonical models. This is a necessary consequence of
the fact that acyclicity can be checked in polynomial time.
Definition 7, however, provides us with a sucient check. For example, let Rv be Rv
extended with the following HT-rules:
A(x)  R.E(x)



B(x)  C(x)  E(x)  R.A(x)



A(x)  R(x, vE )  E(vE )  Succ(x, vE )

B(x)  C(x)  E(x) 
R(x, vA )  A(vA )  Succ(x, vA )

(47)
(48)

The canonical model of Rv Th Av and the ground atoms entailed by D(Rv , Av ) are shown
in Figures 1(b) and 1(e), respectively. The HT-rules in Rv \ Rv enforce the existence of an
infinite R-chain, which is reflected as a harmful cycle (e.g., the self-loop on vA ).
Acyclicity can indeed be checked in polynomial time, as shown next.
Proposition 4. Acyclicity of Rv  Av w.r.t.  can be checked in polynomial time.

Proof. Let D(Rv , Av ) be as specified in Definition 7. The number of fresh individuals of
the form vA and vA is clearly linear in the size of Rv , Av , and , so the size of D(Rv , Av )
is polynomial in the size of Rv , Av , and .
We can compute the set of all positive ground atoms that follow from D(Rv , Av ) in
polynomial time using forward chaining. All predicates in D(Rv , Av ) are of bounded arity,
so the number of such atoms is polynomial in the size of D(Rv , Av ). This straightforwardly implies the claim of this proposition if we show that, given a set of facts and a rule
  D(Rv , Av ), we can compute the set of entailed facts in polynomial time. Rules not of
the form (31) contain a bounded number of variables, so the set of entailed facts can be
computed in polynomial time by simply considering all possible mappings of variables to
individuals. Assume now that  is of the form (31). The number of variables in  is linear
in the size of Rv , so there are exponentially many mappings of variables to individuals. We
can, however, determine the values for x and yi that make the body true as follows. For
each variable yi , let Pi be a binary relation that initially contains all pairs of individuals
occurring in D(Rv , Av ); this relation will eventually contain all pairs of values for x and yi
that make the body of  true. We then remove from each Pi all pairs that do not satisfy all
body atoms of  that contain only variables x and yi . Next, for all Pi and Pj , we remove
all pairs c, c  from Pi for which no c exists such that c, c   Pj . We then consider each
consequent atom  of ; if  contains only variables x and yi , we infer all ground atoms
obtained by replacing x with c and yi with c for each c, c   Pi ; if  contains only variables
yi and yj , we infer all ground atoms c  c such that an individual c exists where c, c   Pi
and c, c   Pj . This can clearly be done by polynomially many steps in the number of
individuals in D(Rv , Av ) and the maximal number of variables in a rule in Rv .
226

fiReasoning over Ontologies with Hidden Content

Table 4: Additional Derivation Rules
an individual s in A and an atomic concept A   exist such that
1. s is not indirectly blocked in A and
2. {A(s), A(s)}  A = 
then A1 := A  {A(s)} and A2 := A  {A(s)}.
If
individuals s and t in A and atomic roles R, R   exist such that
1. neither s nor t is indirectly blocked in A,
2. R (s, t)  A, and
3. {R(s, t), R(s, t)}  A = 
then A1 := A  {R(s, t)} and A2 := A  {R(s, t)}.
If
individuals s and t in A and atomic roles R, R   exist such that
1. neither s nor t is indirectly blocked in A,
2. R (s, t)  A, and
3. {R(t, s), R(t, s)}  A = ,
then A1 := A  {R(t, s)} and A2 := A  {R(t, s)}.
If
individuals s, s1 , and s2 in A exist such that
1. none of s, s1 , and s2 is indirectly blocked in A,
2. {s1  s2 , s1  s2 }  A = , and
3. atomic roles R, R   exist such that
3.1 {R(s, s1 ), R (s, s2 )}  A or
3.2 {R(s1 , s), R (s2 , s)}  A or
3.2 {R(s1 , s), R (s, s2 )}  A
then A1 := A  {s1  s2 } and A2 := A  {s1  s2 }.
If 1.   A and
2. a connected component A of A| exists such that aTh , (A ) = f
then A1 := A  {}.
If

A-cut

R-cut

R -cut

-cut

a -rule

5.1.3 An Import-by-Query Algorithm
We next present our import-by-query algorithm applicable to Rv  Av that is HT-safe and
acyclic w.r.t. . The algorithm modifies the standard hypertableau algorithm as follows.
First, several cut rules nondeterministically guess all relevant assertions involving the
symbols in . Second, the a -rule checks whether the guesses are indeed consistent with
Th . Third, a relaxed blocking condition ensures termination.
Definition 8. Let C[C , RCv  ACv , ThC ] be the class of inputs where RCv  ACv is acyclic w.r.t.
C , RCv is HT-safe w.r.t. C , and ThC is an ALCHIQ TBox. The ALCHIQ a -algorithm
takes a triple , Rv  Av , Th   C and is obtained by modifying Definition 1 as follows.
Blocking. An unnamed individual s is blocking-relevant in A if, for s the predecessor
of s, we have
LA (s, s )   = LA (s , s)   = .
Then, each individual s in an ABox A is assigned a blocking status in the same way as in
Definition 1, with the dierence that s is directly blocked by t if, in addition to the conditions
in Definition 1, both s and t are blocking-relevant.

227

fiCuenca Grau & Motik

B

Anm

b

R

A, C

B

a

e

R

b

R

C

Ad

a

S

c

C, D

S

C

d

A, C

c

S

f

d

Ac

C, D

C

(a) Clash-free ABox A

f

(b) ABox A|
Anm
fin

Acfin
C, E

b

R

C, E

C

e

R

Adfin

c

a

e

d

C, E
T

T

T

C, E

R

C, E

T

C, E

C, E
T

T

C, E

C, E

(c) Saturation via Rh
B
b

R

A, C, E

B

a

T
C, E
T
C, E

A, C, E R

C, D, E
S

c

T
C, E

S

T

C, E
T

C, E

d

e

C, D, E
S

f

T
C, E

(d) Extended ABox Afin

Figure 2: Completeness of the ALCHIQ a -algorithm
Derivation Rules. The derivation rules are given in Tables 2 and 4, where A| is the
ABox obtained from A by removing each assertion containing an indirectly blocked individual
and each assertion  such that sig()  .
In Section 5.1.4 we show that some of the cut rules in Table 4 are not needed if we know
that Th is expressed in a description logic between ALC and ALCHIQ. Our algorithm is
indeed an import-by-query algorithm, as we show next.

Theorem 11. The ALCHIQ a -algorithm is an import-by-query algorithm based on ABox
satisfiability oracles for the class of inputs C[C , RCv  ACv , ThC ] from Definition 8. The algorithm can be implemented such that it runs in N2ExpTime in N , and the total number
of oracle queries and the size of each query are both at most exponential in N , where
N = |Rv  Av | + || for the input Rv , Av , and .
The proof of Theorem 11 is lengthy and quite technical, so we defer it to the appendix
and next discuss only the intuitions. The derivation rules from Table 2 are clearly sound.
228

fiReasoning over Ontologies with Hidden Content

Furthermore, due to acyclicity, the chains of assertions involving roles from  are bounded
in length, which enables blocking and ensures termination. We next sketch the completeness
argument. In particular, for completeness we need to show that the existence of a clash-free
ABox in a derivation to which no rule is applicable implies the satisfiability of the input.
Let A be a clash-free ABox labeling the leaf of a derivation for , Rv  Av , Th , and let Rh
be the set of HT-rules corresponding to Th . Each model of Rv  A  Th can be extended
to a model of Rv  Av  Th , so it suces to show the satisfiability of Rv  A  Th . To this
end, we extend A to a clash-free ABox Afin such that no derivation rule of the standard
hypertableau algorithm is applicable to Rv  Rh and Afin ; thus, Rv  Afin  Th is satisfiable,
and since A  Afin so is Rv  A  Th by monotonicity. The construction of Afin proceeds
as follows:
1. We split the projection A| of A to . In particular, we define Anm as the ABox containing all assertions of A| involving individuals reachable from a named individual;
furthermore, for each nonblocked blocking-relevant individual t, we define At as the
ABox containing all assertions of A| involving individuals reachable from t.
2. We apply the standard hypertableau algorithm to Rh and each of the connected
t
components of Anm , and Rh and each At ; let Anm
fin and Afin be clash-free ABoxes
a
labeling leaves of the respective derivations. The  -rule is not applicable to A so
such ABoxes exist.
t
3. We define Afin as the union of A, Anm
fin , all  Afin , and all assertions C(s) such that s is


s
blocked in A by the blocker s , C(s )  Afin , and sig(C)  sig(Rh ).

Let us call the individuals from A old, and the individuals introduced in the second step
new ; we then observe the following. (1) Due to the cut rules, the second step above cannot
derive fresh assertions involving only old individuals and the symbols in  without leading to
a contradiction. (2) Each of the connected components of Anm and each At are disjoint, so
the HT-rules from Rh can be applied in Afin only to subsets that correspond to a connected
component of Anm and At . (3) Due to (1), no HT-rule from Rv can become applicable to
assertions involving only old individuals. (4) Due to HT-safety, no HT-rule from Rv can
become applicable to an assertion of Afin that involves a new individual. (5) Due to (1) and
t
the third step from the construction above, if an individual s is blocked in A, Anm
fin , or Afin ,
then s is blocked in Afin as well. Then, (1)(5) imply that no derivation rule of the standard
hypertableau algorithm is applicable to Rv  Rh and Afin , which proves completeness.
We explain this intuition on an example where  = {C, R}, Av = {A(a)}, Rv consists
of HT-rules (40)(44), and Th is defined as follows:
Th = { R.  C, C  T.C, C  E }

(49)

As shown in Section 5.1.2, Rv  Av is acyclic w.r.t. , so the ALCHIQ a -algorithm
is applicable. The algorithm produces a derivation in which a leaf is labeled with the
ABox A shown in Figure 2(a); for readability, we show neither the negative assertions
nor the assertions involving complex concepts. Individual f is directly blocked by c in A,
and assertions C(a) and C(d) are introduced by the A-cut rule. To construct Afin , the
assertions containing a symbol not in  are removed, resulting in the ABox A| shown in
229

fiCuenca Grau & Motik

R, U
A, C

B, C

a

vB

R, U
S

R
U

R
U

C, D

R
U

vC
vD

R
U

S
S

E, C

vE

R, U

vA

A, C

R, U

Figure 3: Acyclicity Check for Th in ALCHI
Figure 2(b). This ABox is then split into connected components Anm , Ac , and Ad ; note
that c and d are the only nonblocked blocking-relevant individuals. Next, Anm , Ac , and Ad
are completed w.r.t. Rh using the standard hypertableau algorithm; Figure 2(c) shows the
c
d
resulting ABoxes Anm
fin , Afin , and Afin . Note that C(a) and C(d) in A are consistent with
the axiom R.  C from Th . Finally, Afin is obtained by taking the union of A, Anm
fin ,
Acfin , and Adfin , and adding E(f ); the latter is because f is blocked by c and E(c)  Acfin .
The result is shown in Figure 2(d); clearly, no derivation rule of the standard hypertableau
algorithm is applicable to Afin .
5.1.4 Hidden Ontology in DLs Between ALC and ALCHIQ

The main limitation of the acyclicity condition from Definition 7 stems from the fact that
we must anticipate all possible consequences of Th . Both the acyclicity conditions and
the derivation rules from Table 4 can be simplified if the hidden ontology is known to be
expressed in a description logic between ALC and ALCHIQ.
 If Th is known not to use cardinality restrictions, then we can omit rules (35)(37) in
the definition of D(Rv , Av ), and the -cut rule in Table 4 is not required.
 If Th is known not to use inverse roles, then we can omit rules (34), (36), and (37) in
the definition of D(Rv , Av ), the R -cut rule is not required, and Conditions 3.2 and
3.3 can be removed from the -cut rule.
 If Th is known not to use role hierarchies, then we can omit rules (33) and (34) in
the definition of D(Rv , Av ), the R-cut in Table 4 is not required, and the R -cut rule
need only be applied if R and R are the same.
These simplifications allow our approach to be applied to a wider range of visible ontologies. For example, consider the set Rv consisting of HT-rules (40)(44) and (47)(48),
for which we obtained a harmful cycle w.r.t.  = {C, R, U }, as shown in Figure 1(e). If
Th is known to be expressed in ALCHI (and so does not use cardinality restrictions), we
230

fiReasoning over Ontologies with Hidden Content

can omit formulas of the form (35)(37) in the definition of D(Rv , Av ); the ground atoms
entailed by such D(Rv , Av ) are shown in Figure 3. This change makes Rv  Av acyclic
w.r.t. : we can now be sure that, for an arbitrary hidden TBox expressed in ALCHI, no
infinite R-chains need to be considered during reasoning with Rv .
5.2 Practical Import-by-Query Algorithms
The algorithm presented in Section 5.1.3 is not suited for practical implementation because
the derivation rules in Table 4 incur a huge amount of nondeterminism. In this section, we
present practical import-by-query algorithms in which nondeterministic rules are replaced
with on demand oracle calls, which makes the algorithms more goal-oriented. Our
algorithms make no assumptions about the kinds of symbols contained in : both atomic
concepts and roles can be shared.
5.2.1 Importing Horn Ontologies
In this section, we present a practical algorithm that applies when Th is expressed in the
Horn-ALCHIQ fragment of ALCHIQ. It is well known that Th can then be transformed
into a set of Horn HT-rules. This allows us to eliminate the nondeterministic cut rules,
use an ABox entailment oracle instead of an ABox satisfiability oracle, and define oracle
query rules that deterministically complete the query ABox A with the missing assertions
entailed by Th  A. Such an algorithm issues oracle queries on demand, so it is goal oriented
and thus more amenable to implementation.
Definition 9. Let C[C , RCv  ACv , ThC ] be the class of inputs where RCv  ACv is acyclic w.r.t.
C , RCv is HT-safe w.r.t. C , and ThC is a Horn-ALCHIQ TBox. The Horn-ALCHIQ e algorithm takes a triple , Rv  Av , Th   C and is obtained from Definition 8 by replacing
the derivation rules from Table 4 with those in Table 5.
Our algorithm is indeed an import-by-query algorithm with the same worst-case complexity as the algorithm for the non-Horn case.
Theorem 12. The Horn-ALCHIQ e -algorithm is an import-by-query algorithm based on
ABox entailment oracles for the class of inputs C[C , RCv  ACv , ThC ] from Definition 9. The
algorithm can be implemented such that it runs in N2ExpTime in N , and the total number
of oracle queries and the size of each query are both also at most exponential in N , where
N = |Rv  Av | + || for the input Rv , Av , and .

The proof of Theorem 12 is obtained by a modification of the one for Theorem 11 and
is given in the appendix.
5.2.2 Import-by-Query in EL

In this section, we present an import-by-query algorithm based on ABox entailment oracles
that can handle the case when both Kv and Th are expressed in EL. In this setting, only
Theorems 5 and 7 provide clues about features that hinder existence of an import-by-query
algorithm. In particular, it is no longer necessary for Kv to be acyclic.
Our algorithm is again based on the hypertableau framework, so Kv is first converted into
a set Rv of EL-rules and a normalized ABox Av . Since EL does not allow for inverse roles
231

fiCuenca Grau & Motik

Table 5: Additional Derivation Rules for Horn KBs
a connected component A of A| , an individual s in A ,
and an atomic concept A    {} exist such that
1. s is not indirectly blocked in A,
2. A(s)  A, and
3. eTh , (A , A(s)) = t
then A1 := A  {A(s)}
If
a connected component A of A| , individuals s and t in A ,
and atomic roles R, R   exist such that
1. neither s not t is indirectly blocked in A,
2. R (s, t)  A or R (t, s)  A ,
3. R(s, t)  A, and
4. eTh , (A , R(s, t)) = t
then A1 := A  {R(s, t)}
If
a connected component A of A| and individuals s, s1 , and s2 in A
exist such that
1. none of s, s1 , and s2 are indirectly blocked in A,
2. s1  s2  A,
3. atomic roles R, R   exist such that
3.1 {R(s, s1 ), R (s, s2 )}  A or
3.2 {R(s1 , s), R (s2 , s)}  A or
3.3 {R(s1 , s), R (s, s2 )}  A, and
4. eTh , (A , s1  s2 ) = t
then A1 := A  {s1  s2 }
If

e -concept

e -role

e -

or universal quantification, there is no danger of information propagating from a successor
to a predecessor; therefore, we can relax the HT-safety condition as shown in Definition 10.
Definition 10. Let Rv be a set of EL-rules, and let  be a signature Then, Rv is EL-safe
w.r.t.  if
 it satisfies Condition 1 from Definition 6, and
 for each rule   Rv and each body atom of  of the form R(x, yi ) with R  , the
body of  contains an atom B(yi ) such that B  safe(Rv , ).
Our algorithm takes a set Rv of EL-safe rules and a normalized ABox Av . It applies
the standard EL hypertableau derivation rules; furthermore, just like the Horn-ALCHIQ
e -algorithm from Section 5.2.1, it uses the oracle to complete the ABoxes encountered in
a derivation with the relevant concept assertions.
Definition 11. Let C[C , RCv  ACv , ThC ] be the class of inputs where RCv is a set of EL-rules
that is EL-safe w.r.t. C , ACv is a normalized ABox, and ThC is an EL TBox. The EL
e -algorithm takes a triple , Rv  Av , Th   C and is obtained by extending the algorithm
from Definition 2 with the e -concept derivation rule shown in Table 5.

232

fiReasoning over Ontologies with Hidden Content

Our algorithm is indeed an import-by-query algorithm, and it can be implemented to run
in polynomial time, as shown by the following theorem. In contrast to algorithms we have
presented thus far, the EL e -algorithm is both optimal and amenable to implementation.
Theorem 13. The EL e -algorithm is an import-by-query algorithm based on ABox entailment oracles for the class of inputs C[C , RCv  ACv , ThC ] from Definition 11. The algorithm
can be implemented such that it runs in PTime in N with a polynomial number in N of
calls to eTh , , where N = |Rv  Av | + || for the input Rv , Av , and .
The proof of Theorem 13 is rather technical and lengthy, and it is given in the appendix.
The intuition behind the proof, however, is the same as in the case of the ALCHIQ a algorithm, and the dierences are due to the fact that the ABoxes produced by the EL
e -algorithm have a specific shape.

6. A Lower Bound on the Complexity of Import-by-Query Reasoning
In this section we show that no import-by-query algorithm that handles the same input as
our ALCHIQ a -algorithm can make only a polynomial number (in ||) of queries each of
which is of polynomial size (in ||). This result applies already if  contains only atomic
concepts, so the only requirement for the ALCHIQ a -algorithm to be applicable is that
the TBox of Kv is semantically modular w.r.t. .

Theorem 14. Let C[C , KvC , ThC ] be the class of inputs where C contains only atomic concepts, KvC is an ALCHIQ knowledge base that is semantically modular in C , and ThC is
an ALCHIQ TBox. Then, no import-by-query algorithm ibqa based on ABox satisfiability
oracles for L = ALCHIQ and C exists such that, for each input , Kv , Th   C, the total
number of oracle queries in all possible runs of ibqa [Th , , L] on Kv , as well as the size of
each query, are both polynomial in ||.
Proof. Assume that ibqa is an algorithm that satisfies the theorems assumptions; then,
integers c1 and c2 exist such that, for each input , Kv , Th   C, the total number of oracle
queries in all possible runs of ibqa [Th , , L] on Kv is smaller than or equal to ||c1 , and the
maximal size of each query ABox is smaller than or equal to ||c2 .
We next construct a particular input in C for which we show that ibqa violates the above
assumption. Let k be an arbitrary integer such that k c1 +c2 < 2k ; such k exists since c1 and
c2 are fixed. Let  = {A1 , . . . , Ak } be arbitrary atomic concepts, and let Z, B, C1 , . . ., Ck ,
C 1 , . . ., C k be atomic concepts not occurring in . Then, we define Kv = Tv  Av such that
Av = {Z(a)} and Tv contains the following axioms:
(50)

B  R.B

Z  B  C1  . . .  Ck

(51)

  (C1  R.C 1 )  (C 1  R.C1 )

(53)

Cj  C j  

1jk

Cj1  R.C j1  (Cj  R.C j )  (C j  R.Cj ) 1 < j  k

C j1  (Cj1  R.Cj1 )  (Cj  R.Cj )  (C j  R.C j ) 1 < j  k
Ci  Ai

1ik
233

(52)
(54)
(55)
(56)

fiCuenca Grau & Motik

C i  Ai

1ik

(57)

TBox Tv uses the well-known integer counting technique (Tobies, 2000). Consider an
arbitrary model I of Kv . Domain elements of I can be assigned integers between 0 and
2k  1 by means of 2k atomic concepts C1 , . . ., Ck , C 1 , . . ., C k . Axiom (51) implies that
aI  (C k  . . .  C 1 )I , which initializes the counter to 0. Axiom (50) ensures that aI is
an origin of an infinite R-chain. Axioms (52) ensure that no domain element in this chain
is labeled with both Cj and C j . Axioms (53), (54), and (55) increment the counter over R.
Finally, these axioms together with axioms (56) and (57) ensure that each possible number
between 0 and 2k  1 is assigned to some domain element of I in the R-chain. Clearly, Tv
is semantically modular w.r.t.  since we can extend each interpretation of the symbols of
 to a model of Tv by interpreting the symbols not in  with the empty set.
Let Th1 = , let A1 , . . . , Am be the query ABoxes occurring in all possible runs of
a
ibq [Th1 , , L] on Kv , and let n be the maximal size of Ai for 1  i  m. By our assumptions,
we have m  k c1 and n  k c2 , which implies m  n = k c1 +c2 < 2k due to the way we chose
k. For each 1  i  m, let Ai be the following ABox equivalent to Ai :
 If Ai is unsatisfiable, then Ai = {}.

 If Ai is satisfiable, let Ai be an ABox that contains for each individual s exactly one
concept assertion of the form D(s) where D is in disjunctive normal form; that is, D
is expressed as a disjunction of concepts of the form ()A1  . . .  ()Ak . Such Ai
can be obtained from Ai by applying de Morgans laws.

Let D1 , . . . , D be all disjunctive concepts that occur in some satisfiable ABox Ai . Each Ai
contains at most n such concepts, so 1    m  n. Furthermore, let U be the subset of
{D1 , . . . , D } containing precisely those Di that have exactly one disjunct. Finally, let S be
a concept of the form ()A1  . . .  ()Ak that does not occur in U ; such S exists because
  m  n < 2k . Now let Th2 be the following TBox:
Th2 = {S  }

(58)

We next show that, for each 1  j  , concept Dj is satisfiable w.r.t. Th2 . The
claim is trivial if Dj does not contain S; otherwise, Dj contains a disjunct S  = S, so an
interpretation satisfying Th2 and Dj can be obtained by interpreting S  as a nonempty set.
We next show that aT 1 ,,L (Ai ) = aT 2 ,,L (Ai ) for each 1  i  m; since Ai and Ai are
h

h

equivalent, then aT 1 ,,L (Ai ) = aT 2 ,,L (Ai ) as well. The statement clearly holds if Ai is
h

h

unsatisfiable, so assume that Ai is satisfiable. Since Ai consists of assertions of the form
D(s) where D is satisfiable w.r.t. Th2 , an interpretation satisfying Ai  Th2 can be obtained
as a disjoint union of the interpretations satisfying each D.
By Proposition 1, the runs of ibqa [Th1 , , L] on Kv then coincide with the runs of
a
ibq [Th2 , , L] on Kv ; however, it is straightforward to see that Kv Th1 is satisfiable, whereas
Kv  Th2 is unsatisfiable, which is a contradiction.

7. Related Work
There is currently a growing interest in techniques for hiding parts of an ontology Th . One
possible approach is to hide a subset  of the signature of Th by first extracting from Th an 234

fiReasoning over Ontologies with Hidden Content

module M a subset of Th that preserves all -consequences (i.e., all logical consequences
formed using only the symbols in )and then publishing the ontology Th \ M . In order
to ensure that no sensitive information about  is being disclosed, the module M should
be depleting (Kontchakov, Pulina, Sattler, Schneider, Selmer, Wolter, & Zakharyaschev,
2009)that is, ontology Th \ M should be indistinguishable from the empty ontology
w.r.t. -consequences. This approach ensures that no -consequences are disclosed to
external applications and oers the additional advantage that one can reason over the union
of Kv and Th \ M using o-the-shelf DL reasoners. Finally, although determining whether
a subset of an ontology is a depleting module for a signature is an undecidable problem for
many DLs (and hence extraction of minimal depleting modules is often computationally
infeasible), several practical techniques for extracting (not necessarily minimal) depleting
modules are known (Cuenca Grau, Horrocks, Kazakov, & Sattler, 2008).
An important disadvantage of this approach is that the module M may also contain
relevant information that is not sensitive (e.g., M may entail consequences about symbols
 not in ) and hence the union of Kv (which may use symbols from ) and Th \ M may
not contain enough information to answer relevant queries. Furthermore, by adopting this
approach, the vendor of Th would distribute a subset of the axioms of Th , which may allow
competitors to plagiarize parts of Th . Finally, the published axioms might mention symbols
in  (even if they do not entail any -consequence) and external applications would be
aware of the presence of those symbols in the ontology.
Some of these drawbacks can be overcome by publishing an -interpolant of Th an
ontology that contains no symbols from  and that coincides with Th on all logical consequences formed using the symbols not in  (Konev et al., 2009; Wang et al., 2009, 2008;
Lutz & Wolter, 2011; Nikitina, 2011). In contrast to the module extraction approach, publishing an interpolant ensures that the sensitive information in Th (i.e., the information
about the symbols from Th not mentioned in the interpolant) is not exposed in any way
to external applications; furthermore, interpolants preserve all consequences of symbols not
in . Similarly to the module extraction approach, using interpolation has the additional
advantage that the developers of Kv can reason over the union of Kv and the interpolant
using o-the-shelf DL reasoners.
The interpolation approach may, however, have several drawbacks. First, an interpolant
may exist only if Th is expressed in a relatively weak DL and satisfies certain syntactic
conditions (Konev et al., 2009). In contrast, import-by-query is often possible even if an
interpolant of Th for the signature of interest does not exist.
Second, although interpolants preserve logical consequences formed using symbols not
in , they are not robust under replacement (Sattler et al., 2009)that is, the union of Kv
and an -interpolant of Th is not guaranteed to yield the same consequences as Th  Kv for a
query q involving no symbols from . For example, given  = {R} and Th = {A  R.B},
the empty ontology is an -interpolant (it preserves all consequences of the form C  D with
C and D arbitrary boolean concepts over the signature {A, B}); however, for Kv = {B  }
we have that Kv  Th entails the consequence A  , whereas the union of Kv and the
(empty) interpolant does not. Thus, once an interpolant has been published, it cannot be
imported into Kv with the guarantee that all relevant consequences will be preserved, unless
suitable restrictions are imposed to Kv .

235

fiCuenca Grau & Motik

Finally, an -interpolant of Th can be exponentially larger than Th , and may reveal
more information than what is strictly needed. Although import-by-query algorithms can
also formulate in the worst-case exponentially many queries to the oracle, our algorithms
may limit the flow of irrelevant information from Th to Kv , especially if Th is expressed in
a Horn DL, in which case our import-by-query algorithms issue queries on demand. For
example, for  = {R, C},  = , Kv = {A  R.B, B  C} and Th = {R.R.C  C}, the
-interpolant is equal to Th and thus publishing the interpolant reveals entire contents of Th .
In contrast, our import-by-query algorithm for EL would not reveal any positive information
about Th , as it would only disclose the fact that an ABox of the form {R(a, b), C(b)} is
satisfiable w.r.t. Th .
The idea of accessing an ontology through an oracle is similar in spirit to the proposal by
Calvanese, De Giacomo, Lembo, Lenzerini, and Rosati (2004) for query answering in a peerto-peer setting. The authors consider the problem of answering a conjunctive query q over
KBs Kv and Kh and mappings M by reformulating q as queries that can be evaluated over
Kv and Kh in isolation. The query reformulation algorithm accesses only Kv and M , so q
can be answered using an oracle for Kh . In this setting, however, the focus is on the reuse of
data, rather than schema. Since a satisfiable Kh cannot aect the subsumption of concepts
in Kv , the results by Calvanese et al. (2004) are not applicable to schema reasoning.

8. Conclusion
In this paper, we have proposed and studied the import-by-query framework. Our results
provide a flexible way for ontology designers to ensure selective access to their ontologies.
Our framework thus provides key theoretical insights into the issues surrounding ontology
privacy. Furthermore, we believe our algorithms to be practicable when applied to Horn
ontologies; thus, our results provide a starting point for the development of practical importby-query systems.
The problem of import-by-query is novel, and we see many open questions. For example,
a problem that is relevant to both theory and practice is to allow the hidden ontology to
selectively export data and not just schema statements.

Acknowledgments
This is an extended version of the paper Import-by-Query: Ontology Reasoning under
Access Limitations by Bernardo Cuenca Grau, Boris Motik, and Yevgeny Kazakov published at IJCAI 2009 and the paper Pushing the Limits of Reasoning over Ontologies with
Hidden Content by Bernardo Cuenca Grau and Boris Motik published at KR 2010.
This research has been supported by the Royal Society and the EPSRC projects ExODA
(EP/H051511/1) and HermiT (EP/F065841/1).

236

fiReasoning over Ontologies with Hidden Content

Appendix A. Proof of Theorem 11
We will use the following definitions and intermediate results to prove the theorem.
Definition 12. An ABox A is an HT-ABox if all of its assertions satisfy the following
conditions, for B an atomic or a negated atomic concept, S a role, R an atomic role, a and
b named individuals, s an individual, and i and j integers.
1. Each concept assertion in A is of the form B(s) or  n S.B(s).

2. Each role assertion in A is of the form R(a, b), R(s, s.i), or R(s.i, s).

3. If an individual s.i occurs in an assertion in A, then A contains a role assertion of
the form R(s, s.i) or R(s.i, s).
4. Each equality in A is of the form s.i  s.j, s.i.j  s, s  s, or a  b.i.

Furthermore, an extended HT-ABox A is additionally allowed to contain assertions of the
form R(s, s) and s.i  s.
Lemma 1. Let R be a set of HT-rules and let A be an ABox. Then, each ABox labeling a
node of a derivation for R and A is an HT-ABox.

Proof. The proof is a straightforward modification of the proof of Lemma 4 by Motik et al.
(2009), which are due the following observations: since HT-rules do not allow for atoms of
the form R(x, x) in the head, one cannot derive atoms of the form R(s, s); this, in turn,
guarantees that one cannot derive equalities of the form s.i  s.
Lemma 2. (Motik et al., 2009, Lemma 6) Let R be a set of HT-rules and let A be a clashfree extended HT-ABox not containing indirectly blocked individuals. If no derivation rule
is applicable to R and A, then R  A is satisfiable.

Definition 13. The weakened pairwise anywhere blocking, abbreviated w-blocking, is the
same as in Definition 1, with the dierence that the following condition is used instead of
LA (s ) = LA (t ):
For each HT-rule   R containing a body atom of the form R(x, y) or R(y, x)
with R an atomic role such that R  LA (s, s )  LA (s , s), and for each atomic
concept A occurring in , we have A  LA (s ) if and only if A  LA (t ).

Lemma 3. Lemma 2 holds even if the derivation for R and A uses w-blocking.

Proof (Sketch). Let A be an ABox labeling a leaf of a derivation for R and A; let s be an
individual that is blocked in A by t by w-blocking; and let s and t be the parents of s and
t. For the proof by Motik et al. (2009, Lemma 6) to hold, we must show that no HT-rule
is applicable to an interpretation obtained by unraveling A . Let   R be an arbitrary
HT-rule. If  does not contain in the body a role atom with a role R  LA (s, s )  LA (s , s),
then the Hyp-rule cannot be applied to  with mapping (x) = s. Furthermore, if  does
not contain an atomic concept A, then the fact that A  LA (s ) but A  LA (t ) or vice versa
cannot aect the applicability of . Thus, by a straightforward modification of the proof by
Motik et al. (2009, Lemma 6), we can construct a model for A and R by unraveling A .
It is straightforward to see that the derivation rules in Table 4 do not invalidate Lemma
1that is, given an HT-ABox, they always produce an HT-ABox.
237

fiCuenca Grau & Motik

A.1 Termination
We first show that the logical consequences of the datalog program D(Rv , Av ) from Definition 7 overestimate the ABoxes produced by the hypertableau algorithm; that is, we
show that each ABox (t) labeling a derivation node can be homomorphically embedded
into the set of ground facts entailed by D(Rv , Av ).
If s = s.i and either R(s, s )  (t) or R(s , s)  (t) with R  , we say that s is a
-successor of s.
Lemma 4. Let Rv be a set of HT-rules, let Av be an ABox, let  be a signature, let
D(Rv , Av ) be as given in Definition 7, let Th be an ALCHIQ TBox, and let (T, ) be a
derivation for , Rv  Av , Th . Then, for each derivation node t  T , a mapping  from
the individuals in (t) to the individuals in D(Rv , Av ) exists satisfying all of the following
properties for all individuals s and s occurring in (t):
1. A(s)  (t) with A an atomic concept implies D(Rv , Av ) |= A((s)).
2. R(s, s )  (t) implies D(Rv , Av ) |= R((s), (s )).
3. If s is a successor of s in (t), then D(Rv , Av ) |= Succ((s), (s )).
4. If s is a -successor of s in (t), then D(Rv , Av ) |= -Desc((s), (s )).
5. If  n R.C(s)  (t) with R a possibly inverse role, then the following conditions hold:
(a) if C is an atomic concept, then D(Rv , Av ) |= C(vC );
(b) D(Rv , Av ) |= ar(R, (s), vC );

(c) D(Rv , Av ) |= Succ((s), vC ); and

(d) if R  , then D(Rv , Av ) |= -Desc((s), vC ).
6. If s  s  (t), then D(Rv , Av ) |= (s)  (s ).
7. If s is an unnamed individual in (t), an atomic concept A  sig(Rv )  sig(Av ) exists
such that (s) = vA or (s) = vA .
Proof. We prove the lemma by induction on the structure of the derivation. For   T
the root node of the derivation, let  map each individual in Av to itself. ABox () = Av
trivially satisfies Properties 3, 4, and 7 since Av contains only named individuals. Properties
5 and 6 also hold trivially because () is a normalized ABox and hence it does not contain
assertions of the form  n R.C(s) or of the form s  s . Finally, Properties 1 and 2 hold
because ()  D(Rv , Av ).
For the induction step, assume that, for some derivation node t  T , ABox (t) satisfies
the claim for some mapping . For each child node t of t in T , we consider the possible
ways (t ) can be derived from (t).
 a -rule: All properties hold trivially for (t ) and .

238

fiReasoning over Ontologies with Hidden Content

 A-cut: All properties hold trivially for (t ) and  except for Property 1 in case
(t ) = (t)  {A(s)} with A  . If s is a named individual in (t), then s occurs in Av and Property 1 holds because D(Rv , Av ) contains the assertion A(s) for
each A   and each s occurring in Av . If s is unnamed, then s is the successor of some individual s in (t); by the induction hypothesis (Property 3) we have
D(Rv , Av ) |= Succ((s ), (s)); however, D(Rv , Av ) contains the formula (32) for each
A  , so we have D(Rv , Av ) |= A((s)), as required.
 R-cut: All properties hold trivially for (t ) and  except for Property 2 in case
(t ) = (t)  {R(s, s )} with R  . By Condition 2 of R-cut we have R (s, s )  (t)
for some atomic role R  , so we have D(Rv , Av ) |= R ((s), (s )) by the induction
assumption. Since R, R   and D(Rv , Av ) contains formulae (33) for all roles in ,
we have D(Rv , Av ) |= R((s), (s )), so (t ) satisfies Property 2 for .
 R -cut: All properties hold trivially for (t ) and  except for Property 2 in case
(t ) = (t)  {R(s , s)} with R  . By Condition 2 of R -cut we have R (s, s )  (t)
for some atomic role R  , so we have D(Rv , Av ) |= R ((s), (s )) by the induction
assumption. Since R, R   and D(Rv , Av ) contains formulae (34) for all roles in ,
we have D(Rv , Av ) |= R((s ), (s)), so (t ) satisfies Property 2 for .
 -rule: All properties hold trivially for (t ) and .
 -rule: Assume that (t ) is defined as follows, where  n R.C(s)  (t), si are fresh
successors of s, and C is a possibly negated atomic concept:
(t ) = (t)  { ar(R, s, si ), C(si ) | 1  i  n }  { si  sj | 1  i < j  n }
Let  =   {si  vC | 1  i  n}. Properties 5 and 6 hold trivially for (t ) and  ,
and it is obvious that Property 7 holds as well. Hence, we focus on showing Properties 14. For Property 1, assume that C is an atomic concept; since Property
5(a) holds for (t) and  by the induction assumption, we have D(Rv , Av ) |= C(vC ),
as required. For Property 2, since Property 5(b) holds for (t) and  by the induction assumption, we have D(Rv , Av ) |= ar(R, (s), vC ), as required. For Property
3, since Property 5(c) holds for (t) and  by the induction assumption, we have
D(Rv , Av ) |= Succ((s), vC ), so Property 3 holds for (t ) and  . For Property 4,
assume that R  ; Property 5(d) holds for (t) and  by the induction assumption,
we have D(Rv , Av ) |= -Desc((s), vC ), so Property 4 holds for (t ) and  .
 Hyp-rule: Assume that (t ) = (t)  {} for  the head atom of an HT-rule  of
the form (2). Properties 3, 4, and 7 hold trivially for (t ) and , so we focus on
the remaining properties. By Condition 2 of the Hyp-rule, (t) contains individuals
s, s1 , . . . , sn such that the statements from the left column from the following table
holds. But then, by the induction assumption, the statements from the right column
hold as well.
Ai (s)  (t)
Rij (s, si )  (t)
Sij (si , s)  (t)
Bij (si )  (t)

D(Rv , Av ) |= Ai ((s))
D(Rv , Av ) |= Rij ((s), (si ))
D(Rv , Av ) |= Sij ((si ), (s))
D(Rv , Av ) |= Bij ((si ))





239

fiCuenca Grau & Motik

For the HT-rule , the datalog program contains the rule (31). Thus, the statements
from the following table then hold as well:
D(Rv , Av ) |= tt(Ci ((s)))
 ((s), (s ))
D(Rv , Av ) |= Rij
i
 ((s ), (s))
D(Rv , Av ) |= Sij
i
D(Rv , Av ) |= Dij ((si ))
D(Rv , Av ) |= (si )  (sj )
Consequently, Properties 2 and 6 clearly hold; Property 1 also holds since for an
atomic concept atom  we have tt() = . To show Property 5, assume that Ci ((s))
is of the form  n R.C((s)), so
tt(Ci ((s))) = ar(R, (s), vC )  tt(C(vC ))  Succ((s), vC ).
Then, the following holds:
D(Rv , Av ) |= ar(R, (s), vC )
D(Rv , Av ) |= tt(C(vC ))
D(Rv , Av ) |= Succ((s), vC )
Thus, Properties (5a), (5b), and (5c) hold. Finally, if R  , then Property (5d) holds
because the datalog program entails assertion Succ((s), vC ), and it contains formulae
(38) and (34) for all roles in .
 -cut rule: Assume that (t ) = (t)  {} with  an assertion of the form s1  s2
or s1  s2 . Then, (t) trivially satisfies Properties 15 and 7 for . Property 6 also
holds trivially if  is of the form s1  s2 , so assume that  of the form s1  s2 . By
the preconditions of the -cut rule, an individual s in (t) and atomic roles R, R  
exist such that
{ R(s, s1 ), R (s, s2 ) }  (t) or
{ R(s1 , s), R (s2 , s) }  (t) or
{ R(s1 , s), R (s, s2 ) }  (t).
By the induction hypothesis (Property 2), then

D(Rv , Av ) |= { R((s), (s1 )), R ((s), (s2 )) } or
D(Rv , Av ) |= { R((s1 ), (s)), R ((s2 ), (s)) } or
D(Rv , Av ) |= { R((s1 ), (s)), R ((s), (s2 )) }.
But then, since the datalog program contains formulas (35)(37) for all roles in , we
have D(Rv , Av ) |= (s1 )  (s2 ), as required.
 -rule: Assume that (t ) = merge(t) (s  s ). Then, by Conditions 1 and 2 of the
-rule, s  s  (t) with s = s . Furthermore, by the induction assumption, we have
D(Rv , Av ) |= (s)  (s ). Since merging merely replaces s with s , by the semantics
of equality (t ) satisfies all the required properties.
We next use Lemma 4 to prove that the length of chains of role assertions involving a
role in  is bounded.
240

fiReasoning over Ontologies with Hidden Content

Lemma 5. Let Rv , Av , , D(Rv , Av ), and (T, ) be as in Lemma 4 with the additional
restriction that Rv  Av is acyclic w.r.t. . Let N be the number of individuals of the
form vC occurring in D(Rv , Av ), let t  T be an arbitrary derivation node of (T, ), and let
s1 , . . . , s be unnamed individuals occurring in (t) such that si+1 is a -successor of si for
each 1  i < . Then,   N .
Proof. Assume that, for some integer  > N , unnamed individuals s1 , . . . , s satisfying the
conditions of this lemma exist, and let  be a mapping satisfying Lemma 4. By Property 7 in
Lemma 4, for each 1  i   we have (si ) = vCi for some Ci (because each si is unnamed).
Furthermore, by Property 4 in Lemma 4, we also have D(Rv , Av ) |= -Desc((si ), (si+1 ))
for each 1  i < . But then, since  > N and predicate -Desc(x, y) is axiomatized as
transitive by formula (39) in D(Rv , Av ), we clearly obtain a harmful cycle, which is a
contradiction.
We are now ready to prove our main claim.
Lemma 6 (Termination). Let Rv , Av , , D(Rv , Av ), N , and (T, ) be as in Lemma 5.
Then, (T, ) is finite.
Proof. Let the depth of an individual s be the number of its ancestors, and let c and r be
the numbers of atomic concepts and roles, respectively, occurring in Rv and Av ; finally, let
 = (22cr + 1)(N + 1) + 1. Consider now an arbitrary derivation node t  T . Let s be an
individual in (t) of depth i(N + 1) + 1. By a simple induction on i, one can show that s
has at least i ancestors that are blocking-relevant. The induction base is straightforward
for i = 0; furthermore, the induction step holds because, by Lemma 5 and the fact that
(t) is an HT-ABox, the depth of the nearest blocking-relevant ancestor of s can be at most
N + 1 less than the depth of s. Thus, each individual s of depth  has at least 22cr + 1
blocking-relevant ancestors; since there are at most 22cr possible concept and role labelings
for an individual and its predecessor, one of the blocking ancestors of s is blocked due to the
definition of blocking; hence, s is either directly or indirectly blocked in (t). The rest of
the proof of our claim is then analogous to the proof of Lemma 7 by Motik et al. (2009).
A.2 Soundness
Lemma 7 (Soundness). Let Rv be a set of HT-rules, let Th be an ALCHIQ TBox, let A be
an ABox such that Rv  Th  A is satisfiable, and let A1 , . . . , An be the ABoxes obtained by
applying a derivation rule from Table 2 or 4 to Rv and A. Then, Rv  Th  Ai is satisfiable
for some 1  i  n.
Proof. Let I be a model of Rv  Th  A, and let us consider the possible derivation rules
that derive A1 , . . . , An . The cases for the Hyp-, -, -, and -rule are the same as in the
proof by Motik et al. (2009, Lemma 5). Furthermore, by the law of excluded middle of
first-order logic, the claim is true for A, R-cut, R -cut and -cut rules. Assume that the
a -rule derives that is, that Th  A is unsatisfiable for some connected component A
of A| . But then, since A  A|  A, by the monotonicity of first-order logic Rv  Th  A
is unsatisfiable as well, which is a contradiction.

241

fiCuenca Grau & Motik

A.3 Completeness
Definition 14 and Proposition 5 show that the part of a model that is implied by Th can
always be extended to a model of Rv . We say that an assertion is atomic if it is of the form
A(a) with A an atomic concept, or R(a, b) with R an atomic role.
Definition 14. Let  be a signature, let Rv be a set of HT-rules, and let A be a nonempty
clash-free ABox containing exactly one individual such that sig(A)  . An ABox A is an
Rv -extension of A w.r.t.  if the following conditions hold:
1. A contains exactly one individual, A | = A, and sig(A )  sig(Rv );
2. no derivation rule from Table 2 is applicable to A and Rv ; and
3. A does not contain an assertion of the form A(s) with A  safe(Rv , ).
Proposition 5. For each , Rv , and A as in Definition 14 where Rv is additionally HTsafe, at least one Rv -extension A of A w.r.t.  exists.
Proof. Let s be the individual occurring in A, and let I = (I , I ) be the interpretation for
the symbols in  defined as follows:


{s} if A(s)  A
{s, s} if R(s, s)  A
I = {s}
AI =
RI =

otherwise

otherwise
Since Rv is HT-safe w.r.t.  and sig(A)  , by Proposition 3 a model J of Rv exists such
that J = I , X J = X I for each symbol X  , and X J =  for each X  safe(Rv , ).
We define the ABox A as follows:
A = {s  s} 
{A(s) | s  AJ and A  sig(Rv )} 
{A(s) | s  AJ and A  sig(Rv )} 
{R(s, s) | s, s  RJ and R  sig(Rv )} 
{ 1 R.A(s) | s  ( 1 R.A)J and {R, A}  sig(Rv )} 
{ 1 R.A(s) | s  ( 1 R.A)J and {R, A}  sig(Rv )}
We now show that A is an Rv -extension of A w.r.t. . Since J coincides with I on the
interpretation of all atomic concepts and roles in , A satisfies Properties 1 and 3 of
Definition 14. We next show that no hypertableau derivation rule is applicable to A and
Rv . The - and the -rule are clearly not applicable to A . Furthermore, the construction
of A ensures that  1 R.C(s)  A if and only if {R(s, s), C(s)}  A , so the -rule is not
applicable to A either. Finally, assume that the Hyp-rule is applicable to an HT-rule
  Rv and A with a mapping . Since A contains only the individual s, the mapping
 maps all variables in  to s. Since J |= Rv , rule  contains a head atom Vj such that
J |= (Vj ). Note that if Vj is of the form  n R.C, then n = 1 since J contains just
one element. Thus, (Vj ) can be of the form A(s), R(s, s),  1 R.C(s), or s  s, where
A  sig(Rv ), R  sig(Rv ), and sig(C)  sig(Rv ). But then, by the construction of A we
have (Vj )  A , which contradicts the assumption that the Hyp-rule is applicable to Rv
and A .
242

fiReasoning over Ontologies with Hidden Content

We are now ready to prove the main claim of the section.
Lemma 8 (Completeness). Let , Rv  Av , Th  be an input of the ALCHIQ a -algorithm.
If a derivation for , Rv  Av , Th  contains a leaf node labeled with a clash-free ABox, then
Rv  Av  Th is satisfiable.
Proof. Let A be an ABox obtained from a clash-free ABox labeling a leaf of a derivation for
, Rv  Av , Th  by removing all assertions involving an indirectly blocked individual. Since
Rv  Av is acyclic w.r.t. , ABox A is finite by Lemma 6. Furthermore, A is clearly an HTABox and no derivation rule is applicable to Rv , A, and aTh , . Finally, it is straightforward
to see that a mapping h from the individuals in Av to the individuals in A exists such
that h(a) = a for each individual a occurring in A, C(a)  Av implies C(h(a))  A, and
R(a, b)  Av implies R(h(a), h(b))  A. Hence, each model of Rv  A  Th can be extended
to a model of Rv  Av  Th by interpreting each individual a not occurring in Av in the
same way as h(a). Thus, we prove this lemma by showing that Rv  A  Th is satisfiable.
Let Rh be the result of transforming Th into a set of HT-rules as described by Motik
et al. (2009); then, Rv  Av  Th is equisatisfiable with Rv  Av  Rh , and each model of
the latter is a model of the former as well. Therefore, in the rest of the proof we extend A to
a clash-free extended HT-ABox Afin such that no derivation rule from Table 2 is applicable
to Rv  Rh and Afin . By Lemma 3, Rv  Afin  Rh is satisfiable, which, together with
A  Afin , implies the satisfiability of Rv  A  Rh . Before proceeding with the construction
of Afin , we next introduce several useful definitions and notational conventions.
 Let v = sig(Rv )  sig(Av ) and let h = sig(Rh ).
 In this proof, term blocking refers to the version of blocking given in Definition
8; term w-blocking refers to the version of blocking in Definition 13; and term sblocking refers to the standard blocking given in Definition 1 with the additional
requirement that individuals s, s , t, and t are all unnamed.
 For each blocked individual s, we pick an arbitrary but fixed individual s that blocks
s, which we call the blocker of s.
 The modified hypertableau algorithm is the same as the standard hypertableau algorithm from Definition 1 with the dierence that it uses s-blocking and that it can
be applied to ABoxes that contain unnamed individuals; such individuals are then
treated by the algorithm as if they were named. The modified hypertableau algorithm is clearly sound, complete, and terminating.
 The projection of an ABox A to a set of individuals S is the ABox consisting of exactly
those assertions from A that contain only individuals in S.
We now proceed with the construction of Afin . To this end, we split A| into ABoxes
Anm and At as follows; we use these ABoxes later to construct Afin .
 The ABox Anm is the projection of A| to the set containing all named individuals in
A and all unnamed individuals that are connected to a named individual in A| .
243

fiCuenca Grau & Motik

 For each nonblocked blocking-relevant individual t in A, the ABox At is the projection
of A| to the set containing t and all (unnamed) individuals connected to t in A| .
Let Anm
der be the result of taking any clash-free ABox labeling a leaf of a derivation
for Rh  Anm by the modified hypertableau algorithm and then removing all assertions
containing an indirectly blocked individual; furthermore, for each nonblocked blockingrelevant individual t in A, let Atder be obtained from At in an analogous way. ABoxes Anm
der
and Atder exist because aTh , (A ) = t for each connected component A of Anm , aTh , (At ) = t
for each t, and the modified hypertableau algorithm is sound, complete, and terminating.
Since the supply of unnamed individuals is unlimited, we assume without loss of generality
that the -rule always introduces individuals that are globally freshthat is, that do not
occur in any other ABox.
t

We next extend Anm
der and each Ader with assertions necessary to satisfy Rv . Let A
nm
t

nm
t
be A
(resp. some A ) and let Ader be Ader (resp. the corresponding Ader ). We say
that an individual u is fresh in Ader if u occurs in Ader but not in A . For each fresh
individual u in Ader , we define Ader [u] as an Rv -extension of the projection of Ader | to {u};
without loss of generality, we assume that Ader [u1 ] = Ader [u2 ] for all u1 and u2 for which
the projections of Ader | to {u1 } and {u2 } are isomorphic (i.e., identical up to the renaming
of individuals). Finally, let Afin be the union of Ader and Ader [u] for each u that is fresh in
t
Ader ; thus, we obtain ABoxes Anm
fin and Afin . By Condition 1 of Definition 14, the atomic

assertions of Ader |sig(Rh ) coincide with the atomic assertions of A |sig(Rh ) . Furthermore,
since all individuals involved in s-blocking are required to be unnamed and all isomorphic
individuals are extended in the same way, this construction does not aect s-blockingthat
is, u is s-blocked in A if and only if u is s-blocked in Ader .

We now define Afin as the ABox obtained by

t
1. taking the union of A, Anm
fin , and Afin for each nonblocked blocking-relevant individual
t in A, and


2. adding A(s) for each blocked individual s in A with blocker s such that A(s )  Asfin
and A  h .3
t
By Lemma 1, Anm
fin and all Afin are HT-ABoxes, and Afin is clearly an extended HT-ABox.
We next show that no hypertableau derivation rule is applicable to Rv  Rh and Afin .
To this end, we first show that Afin satisfies the following property (*): if   Afin is an
atomic assertion or an assertion of the form a  b such that sig()  v and all individuals
mentioned in  occur in A, then   A. In particular, note that the extension of Anm
der and
t
nm
t
Ader to Afin and Afin , respectively, does not introduce an atomic assertion  that involves
an individual from A and for which sig()  (v \ ) = ; hence, the only possibility for
t
  Afin ,   A, and sig()  v is if   Anm
der or   Ader for some t. We consider next
the former case; the latter one is analogous. We prove (*) by induction on the application

of the derivation rules in the construction of Anm
der . To this end, we show that each ABox A
in a derivation for Anm and Rh satisfies the following properties:

3. Note that, since s is blocked, it is blocking-relevant.

244

fiReasoning over Ontologies with Hidden Content

1. If   A is an atomic assertion or an assertion of the form a  b such that sig()  v
and all individuals mentioned in  occur in A, then   A or   A.
2. If R(a, b)  A such that a and b occur in A and R  h \ , then S   exists such
that S(a, b)  A or S(b, a)  A.
3. If a  b  A such that a occurs in A, then R   and an individual c occurring in A
exist such that R(a, c)  A or R(c, a)  A.

The base case is trivial. We next consider ways in which an assertion in A can be derived.
An application of the -rule or the -rule clearly preserves (1)(3). In an application
of the -rule, the modified hypertableau algorithm treats the individuals in A as named;
furthermore, if a  b  A and a and b occur in A, by (1) we have a  b  A, so a = b since
the -rule is not applicable to A; but then, it is straightforward to see that (1)(3) remain
preserved. Finally, the following types of assertions are relevant in an application of the
Hyp-rule to an HT-rule   Rh :
 A(a) with a in A and A  . Since the A-cut rule is not applicable to A, we have
A(a)  A or A(a)  A, so (1) holds.

 R(a, b) with a and b in A. The body of  then contains an atom that is matched
to an assertion R (a, b)  A or R (b, a)  A with R  v that satisfies the induction
assumption; thus, S   exists such that S(a, b)  A or S(b, a)  A, so (2) holds.
Furthermore, if R  , then this assertion satisfies the preconditions of the R-cut and
the R -cut rule; since these rules are not applicable to A, we have R(a, b)  A or
R(a, b)  A, so (1) holds.
 a  b with a in A. The body of  then contains an atom that is matched to an assertion
R (a, c)  A or R (c, a)  A with R  v that satisfies the induction assumption;
thus, S   exists such that S(a, c)  A or S(c, a)  A, so (3) holds. Furthermore, if
b is in A, then the body of  also contains an atom that is matched to an assertion
R (a, c)  A or R (c, a)  A that satisfies the induction assumption; thus, S   
exists such that S  (a, c)  A or S  (c, a)  A. The precondition of the -cut rule is then
satisfied and, since the rule is not applicable to A, we have a  b  A or a  b  A,
so (1) holds.
This completes the proof of (1)(3). Property (*) is a straightforward consequence of (1): a
derivation of an assertion  such that sig()  v and all individuals mentioned in  occur
in A either makes no dierence or it leads to a contradiction. A straightforward consequence
of (*) is that (59) and (60) hold for all individuals u and v that occur in A:
LAfin (u)  v = LA (u)

LAfin (u, v)  v = LA (u, v)

(59)
(60)

We now show that no derivation rule of the hypertableau algorithm with w-blocking is
applicable to Rv  Rh and Afin . We do so by considering the possible derivation rules.
(-rule) Assume that the -rule is applicable to an assertion  n R.C(s)  Afin , so s is
not w-blocked in Afin . We show that then s is not blocked in A, or s is not s-blocked in
t
Anm
fin , or s is not s-blocked in some Afin . We have the following cases.
245

fiCuenca Grau & Motik

  n R.C(s)  A. Assume that s is blocked in A with blocker t, and let s and t be the
predecessors of s and t, respectively. By the definition of blocking, (61)(65) hold:
LA (s) = LA (t)


(61)



LA (s ) = LA (t )


(62)


LA (s, s ) = LA (t, t )




LA (s , s) = LA (t , t)





LA (s, s )  LA (s , s)  v \ 

(63)
(64)
(65)

By (59) and (60), the following properties hold as well:
LAfin (s)  v = LAfin (t)  v




LAfin (s )  v = LAfin (t )  v

(66)
(67)

Furthermore, the second item in the construction of Afin ensures that LAfin (s) and
LAfin (t) coincide on each concept C  h , which ensures the following property:
LAfin (s) = LAfin (t)

(68)

By (65), A| does not contains an assertion involving individuals s and s , or individuals t and t . By the construction of Afin , the following properties hold:
LAfin (s, s ) = LAfin (t, t )




LAfin (s , s) = LAfin (t , t)

(69)
(70)

Consider now each rule   Rv  Rh . If   Rh , then no role in the body of  occurs
in LAfin (s, s )  LAfin (s , s), so  satisfies the condition of weakened pairwise anywhere
blocking. If   Rv , then  satisfies the condition of weakened pairwise anywhere
blocking due to (67). Together with (68)(70), this implies that s is w-blocked by t,
which is a contradiction. Consequently, s is not blocked in A.
  n R.C(s)  Anm
fin and  n R.C(s)  A. If s occurs in A or if s is a successor of an
individual that occurs in A, then s is not s-blocked in Anm
fin since the modified hypertableau algorithm treats the individuals occurring in A as named and such individuals
cannot be s-blocked. Otherwise, by the construction of Afin , LAfin (u) = LAnm
(u) and
fin
nm but not in A;
LAfin (u, v) = LAnm
(u,
v)
for
all
individuals
u
and
v
occurring
in
A
fin
fin
again, s is not s-blocked in Anm
fin .
  n R.C(s)  Atfin for some t and  n R.C(s)  A. This case is completely analogous
to the previous one.
Let A be the ABox for which the above property holds; note that  n R.C(s)  A . The
-rule is not applicable to s in A , so A contains individuals u1 , . . . , un such that
{ar(R, s, ui ), C(ui ) | 1  i  n}  {ui  uj | 1  i < j  n}  A .
By the construction of Afin we have A  Afin , which then contradicts the assumption that
the -rule is applicable to s and Afin .
246

fiReasoning over Ontologies with Hidden Content

(-rule, first variant) Property (59) holds for each individual s occurring in A, and (71)
t
and (72) hold for each individual s occurring in Anm
fin and Afin , respectively.
LAfin (s)  h = LAnm
(s)  h
fin
LAfin (s)  h = LAt (s)  h
fin

(71)
(72)

Thus, {A(s), A(s)}  Afin implies {A(s), A(s)}  A , where A can be A, or Anm
fin , or
t

some Afin . Since the first variant of the -rule is not applicable to A , it is not applicable
to Afin either.
(-rule, second variant) Property (60) holds for each pair of individuals s and t occurring
t
in A. Furthermore, Anm
fin and Afin do not contain negative assertions other than those already
present in A. Since the second variant of the -rule is not applicable to A, Anm
fin , and all
t
Afin , it is not applicable to Afin either.
(-rule, third variant) Suppose that the -rule is applicable to an assertion of the form
t
s  s  Afin . By the construction of Afin , then s  s  A for A being A, Anm
fin , or Afin for

some t. But then, since the -rule is not applicable to A , it is not applicable to Afin either.
(-rule) Assume now that the -rule is applicable to Afin . Then, an assertion s  s in
Afin exists with s = s . By the construction of Afin , we have that s  s  A , with A = A,

t

or A = Anm
fin , or A = Afin for some t. But then, since the -rule is not applicable to A , it
is not applicable to Afin either.
(Hyp-rule) Assume that the Hyp-rule is applicable to Afin and an HT-rule   Rv  Rh
of the form (2). Thus, a mapping  from the variables in  to the individuals Afin exists such
that (Ui )  Afin for each 1  i  m, but (Vj )  Afin for each 1  j  n. Let s = (x) and
ui = (yi ). We have the following possibilities:
t
   Rh . Let A be the ABox chosen among Anm
fin and Afin containing the individual s.
Consider now each ui . Then  contains an atom of the form Rij (x, yi ) or Rij (yi , x)
with Rij  h , so Afin contains an assertion of the form Rij (s, ui ) or Rij (ui , s). By the
definition of blocking, for each pair of individuals u and v that belong to dierent Anm
and At , the ABox A does not contain an assertion of the form T (u, v) with T  h ;
t
but then, by the construction of Afin , if u and v belong to dierent Anm
fin and Afin , the

ABox Afin does not contain such an assertion either. Thus, all ui occur in A , so the
Hyp-rule is applicable to  and A , which is a contradiction.

   Rv . We first show the following property (**): if s or some ui does not occur in
A, then s = uj for each uj . We consider first the case when s does not occur in A.
Consider an arbitrary uj . Since  is an HT-rule, the body of  contains an atom of
the form Rjk (x, yj ) or Rjk (yj , x), so Afin contains an assertion of the form Rjk (s, uj )
or Rjk (uj , s). We have the following two possibilities for Rjk .
 Rjk  v \. By the construction of Afin , assertion Rjk (s, uj ) or Rjk (uj , s) with s
not occurring in A must have been introduced via some Rv -extension, so uj = s.

 Rjk  . Since  is HT-safe w.r.t. ,  contains an atom of the form A(x) such
that A  safe(Rv , ) in the body. By Condition 3 of Definition 14, A(s)  Afin ,
which is a contradiction.

247

fiCuenca Grau & Motik

The case when some ui does not occur in A is symmetric; the only dierence is that
in case Rjk   we consider a body atom B(yj ) of  such that B  safe(Rv , ).

Let A = A if s occurs in A, and let A be the ABox that contains s otherwise. A
straightforward consequence of (**) is that (Ui )  A for each 1  i  m; furthermore, A  Afin and (Vj )  Afin imply (Vj )  A for each 1  j  n. But then, the
Hyp-rule is applicable to A for  and , which is a contradiction.
Thus, no derivation rule of the hypertableau algorithm with w-blocking is applicable to
Rv  Rh and Afin , so Rv  Rh  Afin is satisfiable by Lemma 3. As explained earlier, this
then proves the claim of this lemma.
Lemmas 6, 7, and 8 immediately imply Theorem 11.

Appendix B. Proof of Theorem 12
The termination argument for the Horn-ALCHIQ e -algorithm is analogous to the nonHorn case: for each derivation for , Rv  Av , Th , and each node t in the derivation, we
can find an embedding  as in Lemma 4; the proof is a straightforward variant of the
proof given for the non-Horn case. Termination then follows exactly as in the non-Horn
case. Soundness is a consequence of the soundness of the standard hypertableau algorithm
together with the following lemma.
Lemma 9. Let Rv be a set of HT-rules, let Th be a Horn-ALCHIQ TBox, and let A an
ABox such that Rv  Th  A is satisfiable. Furthermore, let A1 be the ABox obtained by
applying a derivation rule from Table 5 to Rv and A. Then, Rv  Th  A1 is satisfiable.
Proof. Let I be a model of Rv  Th  A, and let us assume that a derivation rule from
Table 5 derives A1 = A  {}. By the preconditions of the e -concept, e -role, and e -
rules, then eTh , (A , ) = t for some connected component A of A| , so Th  A |= . Since
A  A|  A, we have that I |= Th  A , so I |= , which implies our claim.
We now show completeness of the algorithm. If a set of HT-rules R is Horn, then
each derivation of the hypertableau algorithm contains exactly one leaf node, so we can
identify a derivation with a sequence of ABoxes A0 , . . . , An . The following proposition is a
straightforward consequence of the fact that R is a Horn set of HT-rules.
Proposition 6. Let R be a set of Horn HT-rules, let A an ABox, and let A0 , . . . , An be
a derivation for R and A. Then, for each assertion  that mentions only the individuals
from A such that   Ai for some 1  i  n, we have R  A |= .
Lemma 10 (Completeness). Let , Rv  Av , Th  be an input of the Horn-ALCHIQ e algorithm. If a derivation for , Rv  Av , Th  contains a leaf node labeled with a clash-free
ABox, then Rv  Av  Th is satisfiable.
Proof. The proof is analogous to the proof of Lemma 8: given an ABox A labeling a
derivation leaf, we construct an ABox Afin such that no derivation rule of the hypertableau
algorithm with w-blocking is applicable to Rv  Rh and Afin . The construction and the
248

fiReasoning over Ontologies with Hidden Content

bulk of the proof are exactly the same as in Lemma 8, and we next prove only properties
that are aected by the dierence in the derivation rules.
The preconditions of the derivation rules in Table 5 clearly ensure that, whenever a
derivation rule is applied to an HT-ABox, the result is also an HT-ABox; consequently, Afin
is an extended HT-ABox.
We next show that property (*) holds despite the change in the derivation rules: if
  Afin is an atomic assertion or an assertion of the form a  b such that sig()  v
and all individuals mentioned in  occur in A, then   A. In particular, note that the
construction of Afin does not introduce an atomic assertion  that involves an individual
from A and for which sig()  (v \ ) = . Assume now that sig()   and all individuals
in  occur in A. By Proposition 6 we have Rh  A |= . Furthermore, in the same say as in
Lemma 8 one can show that the preconditions of the e -concept, e -role, or e - rule are
satisfied in A; since the relevant rule in not applicable to A, we have   A, which proves
our claim.
The rest of the proof is exactly the same as in Lemma 8.
Theorem 12 follows immediately from Lemmas 9 and 10.

Appendix C. Proof of Theorem 13
For each set of EL-rules R and each ABox A, each derivation of the EL hypertableau algorithm contains exactly one leaf node, so we identify a derivation with a sequence of ABoxes
A0 , A1 , . . . , An . Since Aj1  Aj for each 1  i  n, the ABox labeling the derivation leaf
is uniquely defined by R and A. The following lemma captures the relevant properties of
the standard EL hypertableau algorithm, and it can be proved by a slight variation of the
proofs by Motik and Horrocks (2008) and Baader et al. (2005).
Lemma 11. Let R be a set of EL-rules, let A be an ABox containing only named individuals, and let Af be the ABox labeling a leaf of a derivation for R and A. Then the following
properties hold for each pair of atomic concepts A, B  sig(R) and each individual s in A:
1. A(s)  Af if and only if R  A |= A(s).
2. B(aA )  Af if and only if R |= A  B.
3. For each A  A and each R  R, we have Af  Af , where Af is the ABox labeling
a leaf of a derivation for R and A .
Just like in the EL hypertableau algorithm, each derivation of the EL e -algorithm
contains exactly one leaf node, and the ABox labeling the derivation leaf is uniquely defined
by , Rv  Av , Th . We next show several useful properties of this algorithm.
Lemma 12. Let , Rv  Av , Th  be an input of the EL e -algorithm and let Ae be the
ABox labeling a leaf of a derivation for , Rv  Av , Th . Then the following holds.
1. Let Rh be the set of EL-rules corresponding to Th as described by Motik et al. (2009),
and let AEL be the ABox labeling a leaf of a derivation of the standard EL hypertableau
algorithm for Rv  Rh and Av ; then, Ae  AEL .
249

fiCuenca Grau & Motik

2. If   Ae and B(aA )  Ae with A  , then B  safe(Rv , ).
Proof. (Claim 1) Let A0 , . . . , An be a derivation of the EL e -algorithm for Rv , Av , and
eTh , such that A0 = Av and An = Ae . We prove the claim inductively by showing that
Aj  AEL for each 0  j  n. For the induction base, we clearly have A0  AEL . Assume
now that Aj1  AEL and let Aj be obtained from Aj1 by applying a derivation rule of the
EL e -algorithm. If the Hyp-rule is applied to Aj1 and some   Rv , then   Rv  Rh ,
Aj1  AEL , and the fact that Hyp-rule is not applicable to AEL and  imply Aj  AEL .
The argument is analogous for the -rule. Finally, assume that the e -concept rule derives
A(s) with A    {} from Aj1 . By the preconditions of the e -concept rule, then
eTh , (A , A(s)) = t for some connected component A of Aj1 | . By Property 1 of Lemma
11 then A(s)  A , where A is the ABox labeling a leaf of a derivation of the standard EL
hypertableau algorithm for A and Rh . Now A  AEL , Rh  Rh  Rv , and Property 3 of
Lemma 11 imply A  AEL ; consequently, A(s)  AEL and Aj  AEL .
(Claim 2) Consider an arbitrary individual of the form aA with A   and an arbitrary
assertion B(aA )  Ae . By Claim 1, B(aA )  AEL , so by Property 2 of Lemma 11 we have
Av  Rv  Rh |= A  B. Since Rv  Rh are EL-rules, Av does not aect subsumption
inferences, so Rv  Rh |= A  B. Since   Ae , an interpretation I exists such that AI = 
and I |= Rh . Assume now that B  safe(Rv , ). By Proposition 3 and the fact that Rv is
EL-safe, a model J of Rv exists such that X J = X I for each X  sig(Rh ), and B J = .
Thus, J |= Rv  Rh , which contradicts the fact that Rv  Rh |= A  B.
Soundness of the EL e -algorithm follows immediately from Property 1 of Lemma 12
and the fact that the standard EL hypertableau algorithm is sound. We next prove that
the algorithm is complete.
Lemma 13 (Completeness). Let , Rv  Av , Th  be an input of the EL e -algorithm and let
Th be an EL TBox, and let Ae be the ABox labeling a leaf of a derivation for , Rv  Av , Th .
If   Ae , then Rv  Av  Th is satisfiable.
Proof. Let Rh be the result of transforming Th into a set of EL-rules as described by Motik
et al. (2009); then, Rv  Av  Th is equisatisfiable with Rv  Av  Rh , and each model of
the latter is a model of the former as well. Therefore, in the rest of the proof we extend A
to a clash-free ABox Afin such that no derivation rule from Table 2 is applicable to Rv  Rh
and Afin . By Lemma 3, then Rv  Afin  Rh is satisfiable, which, together with A  Afin ,
implies the satisfiability of Rv  A  Rh . Let v = sig(Rv )  sig(Av ) and h = sig(Rh ).
We next present the construction of Afin . The first step is to extend Ae such that it
satisfies Rh , which we achieve by applying the EL hypertableau algorithm to Rh and Ae .
We assume that the individuals in Ae of the form aA are reused whenever A  v . We
call the individuals from Ae old and the freshly introduced individuals new, and we call an
individual -relevant if it is of the form aA with A  .
We next show that each ABox Aj in a derivation for Rh and Ae satisfies the following
properties (*):
1.   Aj implies   Ae whenever  is of the form
(a) C(s) with sig(C)  v and s an old individual, or
250

fiReasoning over Ontologies with Hidden Content

(b) R(s, t) with R  v and s and t old individuals.
2. For each C(s)  Aj , the following properties hold:
(a) sig(C)  v or sig(C)  h , and

(b) if s is a new individual, then sig(C)  h .
3. For each R(s, t)  Aj , the following properties hold:
(a) if t is a new individual, then R  h , and

(b) if s is new and t is old, then t is -relevant and R  h .
The proof of (*) is by induction on the application of the derivation rules. For the
induction base, we have A0 = Ae . Statements (1) and (2a) hold trivially, and (2b) and (3)
are vacuously true since Ae contains only old individuals. Assume now that (1)(3) hold
for Aj1 and consider an application of a derivation rule that derives Aj .
Assume that the -rule is applied to R.A(s)  Aj1 , deriving R(s, aA ) and A(aA ). If
{R, A}  v and s is old, then R.A(s)  Ae by the induction assumption; since the rule is not applicable to Ae , then {R(s, aA ), A(aA )}  Ae , so (1) holds. Furthermore, if
A  v \ , then s is old by (2b), and R  v by (2a); but then R.A(s)  Ae , so the -rule
cannot be applicable to R.A(s) in Aj1 . Consequently, we have {R, A}  h , so A(aA )
clearly satisfies (2), and R(s, aA ) clearly satisfies (3a). Finally, aA can be old only if A  ,
so R(s, aA ) clearly satisfies (3b).
Assume that the Hyp-rule is applied to an EL-rule   Rh of the form (8), deriving
C(s). Then, individuals t1 , . . . , tm in Aj1 exist such that Ai (s)  Aj1 for each 1  i  k
and {Ri (s, ti ), Bi,1 (ti ), . . . , Bi,mi (ti )}  Aj1 for each 1  i  m. ABox Aj trivially satisfies
(1b) and (3), and it satisfies (2) because   Rh , so sig(C)  h . To show (1a), assume that
s is an old individual and sig(C)  v ; since   Rh , then sig(C)  . By Property 1 of
Lemma 11, then Rh  Ae |= C(s). Since sig(C)  , we have Rh  Ae | |= C(s). Since the
e -concept rule is not applicable to Ae , we have C(s)  Ae , so Aj satisfies (1a).
This completes the proof of (*). Let Ader be the ABox labeling a leaf of a derivation
of the EL hypertableau algorithm for Rh and Ae . Such Ader is clash-free since  
/ Ae and
the e -rule is not applicable to Ae ; furthermore, Ader satisfies (*).
We now extend Ader such that the EL-rules in Rv are satisfied when they are matched
to new individuals. To this end, for each new individual u in Ader , let Ader [u] be an Rv extension w.r.t.  of the projection of Ader on {u}; such Ader [u] exists by Proposition 5
and the fact that Rv is EL-safe. Let Afin be the union of Ader and all such Ader [u]. Since
Av  Ae and Ae  Afin , we have Av  Afin . Furthermore, since   Ader and   Ader [u]
for each u that is new in Ader , we have   Afin . Finally, by (*), Property 2 of Lemma
12, and the fact that each Ader [u] contains only one individual and no safe concepts, Afin
satisfies the following properties (**):
1. For each B(s)  Afin such that s is -relevant or new, we have B  safe(Rv , ).
2. For each R(s, t)  Afin , the following properties hold:
(a) if t is a new individual and s = t, then R  h , and
251

fiCuenca Grau & Motik

(b) if s is new and t is old, then t is -relevant and R  h .
To complete the proof of this lemma, we show that no derivation rule of the hypertableau
algorithm is applicable to Afin and Rv  Rh .
(-rule) Consider an arbitrary R.C(s)  Afin . If R.C(s)  Ader , since the -rule is
not applicable to Ader , we have {R(s, t), C(t)}  Ader  Afin . If R.C(s)  Ader [u] for some
individual u that is new in Ader , by Definition 14 the -rule is not applicable to Ader [u], so
{R(s, t), C(t)}  Ader [u]  Afin . Either way, the -rule is not applicable to R.C(s) in Afin .
(Hyp-rule) Assume that the Hyp-rule is applicable to an EL-rule   Rv  Rh of the
form (8), deriving C(s). Then, individuals t1 , . . . , tm in Afin exist such that Ai (s)  Afin
for each 1  i  k and {Ri (s, ti ), Bi,1 (ti ), . . . , Bi,mi (ti )}  Afin for each 1  i  m. Then we
have the following possibilities:
   Rh . For each new individual u and each assertion   Ader [u] \ Ader , by Definition 14 either sig()  v \  or  is of the form R.C. Thus, Ai (s)  Ader for
each 1  i  k and {Ri (s, ti ), Bi,1 (ti ), . . . , Bi,mi (ti )}  Ader for each 1  i  m, so the
Hyp-rule is applicable to  and Ader , which is a contradiction.
   Rv . We first show the following property (***): if s or some ti is new, then s = tj
for each tj . We have the following cases.
 Assume that s is new and consider an arbitrary 1  i  m. Clearly, Ri  v ;
furthermore, if Ri  , since  is EL-safe, the body of  contains an atom that
is matched to some Bij (ti )  Afin such that Bij  safe(Rv , ). Assume now that
ti = s. If ti is new, then Ri   by Statement (2a) of (**); furthermore, if ti is
old, then Ri   and ti is -relevant by Statement (2b) of (**); consequently,
Ri   and ti is either new or -relevant. But then, by Statement (1) of (**) and
Property 3 of Definition 14, then Bij (ti )  Afin , which is a contradiction. Hence,
we conclude that s = ti .
 Assume that ti is new for some 1  i  m. If ti = s, by Statement (2a) of (**)
then Ri  . Since  is EL-safe, the body of  then contains an atom that is
matched to some Bij (ti )  Afin such that Bij  safe(Rv , ). Statement (1) of
(**) then implies Bij (ti )  Afin , which is a contradiction. Hence, we conclude
that s = ti ; by the previous case then s = tj for each 1  j  m.
Let A = Ae if s is old, and A = Ader [s] otherwise. A straightforward consequence of
(***) is that Ai (s)  A for each 1  i  k and {Ri (s, ti ), Bi,1 (ti ), . . . , Bi,mi (ti )}  A
for each 1  i  m. The Hyp-rule is not applicable to  and A , so C(s)  A . Since
A  Afin , we have C(s)  Afin , which contradicts the assumption that the Hyp-rule
is applicable to  and Afin .
This completes the proof of this lemma.
Finally, we prove that the EL e -algorithm is an optimal import-by-query algorithm.

252

fiReasoning over Ontologies with Hidden Content

Theorem 13. The EL e -algorithm is an import-by-query algorithm based on ABox entailment oracles for the class of inputs C[C , RCv  ACv , ThC ] from Definition 11. The algorithm
can be implemented such that it runs in PTime in N with a polynomial number (in N ) of
calls to eTh , , where N = |Rv  Av | + || for the input Rv , Av , and .

Proof. That the EL e -algorithm is an import-by-query algorithm is a straightforward
consequence of Lemmas 12 and 13. To estimate the algorithms running time, note that
each application of a derivation rule adds an assertion of the form C(a) or R(a, b) for
C  v  {}, where a and b are individuals occurring either in Av or are of the form aA
with A  sig(Rv ). Clearly, the maximal number of individuals occurring in an ABox in
a derivation is polynomial in the size of Av , Rv , and , and so is the maximal number
of assertions. Furthermore, no derivation rule removes assertions from an ABox, so the
number of assertions in an ABox monotonically increases in the course of a derivation.
Consequently, the number of rule applications is polynomial in the size of Av , Rv , and .
In the same way as in the standard EL hypertableau algorithm (Motik & Horrocks, 2008),
one can show that each derivation rule can be applied in polynomial time, which implies
the claim of this theorem.

References
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL Envelope. In Kaelbling, L. P., &
Saotti, A. (Eds.), Proc. of the 19th Int. Joint Conference on Artificial Intelligence
(IJCAI 2005), pp. 364369, Edinburgh, UK. Morgan Kaufmann Publishers.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2007). The Description Logic Handbook: Theory, Implementation and Applications
(2nd edition). Cambridge University Press.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
Reasoning and Ecient Query Answering in Description Logics: The DL-Lite Family.
Journal of Automated Reasoning, 9 (3), 385429.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2004). What to
Ask to a Peer: Ontolgoy-based Query Reformulation. In Dubois, D., Welty, C. A., &
Williams, M.-A. (Eds.), Proc. of the 9th Int. Conf. on the Principles of Knowledge
Representation and Reasoning (KR 2004), pp. 469478. AAAI Press.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2007). A Logical Framework for
Modularity of Ontologies. In Veloso, M. M. (Ed.), Proc. of the 20th Int. Joint Conf.
on Artificial Intelligence (IJCAI 2007), pp. 298303, Hyderabad, India.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2008). Modular Reuse of Ontologies: Theory and Practice. Journal of Artificial Intelligence Research, 31, 273318.
Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.
(2008). OWL 2: The next step for OWL. Journal of Web Semantics: Science, Services
and Agents on the World Wide Web, 6 (4), 309322.
Doran, P., Tamma, V. A. M., & Iannone, L. (2007). Ontology module extraction for ontology
reuse: an ontology engineering perspective. In Silva, M. J., Laender, A. H. F., BaezaYates, R. A., McGuinness, D. L., Olstad, B., Olsen, . H., & Falcao, A. O. (Eds.), Proc.
253

fiCuenca Grau & Motik

of the 16th ACM Conference on Information and Knowledge Management (CIKM
2007), pp. 6170, Lisbon, Portugal. ACM.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). From SHIQ and RDF to
OWL: the making of a Web Ontology Language. Journal of Web Semantics, 1 (1),
726.
Horrocks, I., & Sattler, U. (1999). A Description Logic with Transitive and Inverse Roles
and Role Hierarchies. Journal of Logic and Computation, 9 (3), 385410.
Horrocks, I., & Sattler, U. (2005). A Tableaux Decision Procedure for SHOIQ. In Proc.
of the 19th Int. Joint Conf. on Artificial Intelligence (IJCAI 2005), pp. 448453,
Edinburgh, UK. Morgan Kaufmann Publishers.
Hustadt, U., Motik, B., & Sattler, U. (2005). Data Complexity of Reasoning in Very Expressive Description Logics. In Proc. of the 19th Int. Joint Conf. on Artificial Intelligence
(IJCAI 2005), pp. 466471, Edinburgh, UK. Morgan Kaufmann Publishers.
Jimenez-Ruiz, E., Cuenca Grau, B., Sattler, U., Schneider, T., & Berlanga Llavori, R.
(2008). Safe and Economic Re-Use of Ontologies: A Logic-Based Methodology and
Tool Support. In Bechhofer, S., Hauswirth, M., Homann, J., & Koubarakis, M.
(Eds.), Proc. of the 5th European Semantic Web Conference (ESWC 2008), Vol. 5021
of LNCS, pp. 185199, Tenerife, Spain. Springer.
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2008). Semantic Modularity and Module
Extraction in Description Logics. In Ghallab, M., Spyropoulos, C. D., Fakotakis, N.,
& Avouris, N. M. (Eds.), Proc. of the 18th European Conf. on Artificial Intelligence
(ECAI 2008), Vol. 178 of FAIA, pp. 5559, Patras, Greece. IOS Press.
Konev, B., Walther, D., & Wolter, F. (2009). Forgetting and Uniform Interpolation in
Large-Scale Description Logic Terminologies. In Boutilier, C. (Ed.), Proc. of the 21st
Int. Joint Conf. on Artificial Intelligence (IJCAI 2009), pp. 830835, Pasadena, CA,
USA.
Kontchakov, R., Pulina, L., Sattler, U., Schneider, T., Selmer, P., Wolter, F., & Zakharyaschev, M. (2009). Minimal Module Extraction from DL-Lite Ontologies Using
QBF Solvers. In Boutilier, C. (Ed.), Proc. of the 21st Int. Joint Conf. on Artificial
Intelligence (IJCAI 2009), pp. 836841, Pasadena, CA, USA.
Lutz, C., Walther, D., & Wolter, F. (2007). Conservative Extensions in Expressive Description Logics. In Veloso, M. M. (Ed.), Proc. of the 20th Int. Joint Conf. on Artificial
Intelligence (IJCAI 2007), pp. 453458, Hyderabad, India.
Lutz, C., & Wolter, F. (2010). Deciding inseparability and conservative extensions in the
description logic EL. Journal of Symbolic Computation, 45 (2), 194228.

Lutz, C., & Wolter, F. (2011). Foundations for Uniform Interpolation and Forgetting in
Expressive Description Logics. In Walsh, T. (Ed.), Proc. of the 22nd Int. Joint Conf.
on Artificial Intelligence (IJCAI 2011), pp. 989995, Barcelona, Spain.
Motik, B., & Horrocks, I. (2008). Individual Reuse in Description Logic Reasoning. In
Armando, A., Baumgartner, P., & Dowek, G. (Eds.), Proc. of the 4th Int. Joint Conf.
on Automated Reasoning (IJCAR 2008), Vol. 5195 of LNAI, pp. 242258, Sydney,
NSW, Australia. Springer.
254

fiReasoning over Ontologies with Hidden Content

Motik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau Reasoning for Description
Logics. Journal of Artificial Intelligence Research, 36, 165228.
Nikitina, N. (2011). Forgetting in General EL Terminologies. In Rosati, R., Rudolph, S.,
& Zakharyaschev, M. (Eds.), Proc. of the 24th Int. Workshop on Description Logics
(DL 2011), Vol. 745 of CEUR Workshop Proceedings, Barcelona, Spain.
Papadimitriou, C. H. (1993). Computational Complexity. Addison Wesley.
Sattler, U., Schneider, T., & Zakharyaschev, M. (2009). Which Kind of Module Should I
Extract?. In Cuenca Grau, B., Horrocks, I., Motik, B., & Sattler, U. (Eds.), Proc. of
the 22nd Int. Workshop on Description Logics (DL 2009), Vol. 477 of CEUR Workshop
Proceedings, Oxford, UK.
Stuckenschmidt, H., Parent, C., & Spaccapietra, S. (Eds.). (2009). Modular Ontologies:
Concepts, Theories and Techniques for Knowledge Modularization, Vol. 5445 of LNCS.
Springer.
Tobies, S. (2000). The Complexity of Reasoning with Cardinality Restrictions and Nominals
in Expressive Description Logics. Journal of Artificial Intelligence Research, 12, 199
217.
Wang, K., Wang, Z., Topor, R. W., Pan, J. Z., & Antoniou, G. (2009). Concept and Role
Forgetting in ALC Ontologies. In Bernstein, A., Karger, D. R., Heath, T., Feigenbaum,
L., Maynard, D., Motta, E., & Thirunarayan, K. (Eds.), Proc. of the 8th Int. Semantic
Web Conference (ISWC 2009), Vol. 5823 of LNCS, pp. 666681, Chantilly, VA, USA.
Springer.
Wang, Z., Wang, K., Topor, R. W., & Pan, J. Z. (2008). Forgetting Concepts in DL-Lite.
In Bechhofer, S., Hauswirth, M., Homann, J., & Koubarakis, M. (Eds.), Proc. of
the 5th European Semantic Web Conference (ESWC 2008), Vol. 5021 of LNCS, pp.
245257. Springer.
Wang, Z., Wang, K., Topor, R. W., & Zhang, X. (2010). Tableau-based Forgetting in
ALC Ontologies. In Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proc. of the
19th European Conference on Artificial Intelligence, Vol. 215 of Frontiers in Artificial
Intelligence and Applications, pp. 4752, Lisbon, Portugal. IOS Press.

255

fiJournal of Artificial Intelligence Research 45 (2012) 481514

Submitted 06/12; published 11/12

Complexity of Judgment Aggregation
Ulle Endriss
Umberto Grandi
Daniele Porello

ulle.endriss@uva.nl
umberto.uni@gmail.com
danieleporello@gmail.com

Institute for Logic, Language and Computation
University of Amsterdam
Postbus 94242, 1090 GE Amsterdam
The Netherlands

Abstract
We analyse the computational complexity of three problems in judgment aggregation:
(1) computing a collective judgment from a profile of individual judgments (the winner
determination problem); (2) deciding whether a given agent can influence the outcome
of a judgment aggregation procedure in her favour by reporting insincere judgments (the
strategic manipulation problem); and (3) deciding whether a given judgment aggregation
scenario is guaranteed to result in a logically consistent outcome, independently from what
the judgments supplied by the individuals are (the problem of the safety of the agenda).
We provide results both for specific aggregation procedures (the quota rules, the premisebased procedure, and a distance-based procedure) and for classes of aggregation procedures
characterised in terms of fundamental axioms.

1. Introduction
Judgment aggregation (JA) is a branch of social choice theory that studies the properties
of procedures for amalgamating several agents individual judgments regarding the truth or
falsity of a set of inter-related propositions into a collective judgment reflecting the views of
that group of agents as a whole (List & Pettit, 2002; List & Puppe, 2009). A by now classic
example is due to Kornhauser and Sager (1993): Suppose three judges have to decide on a
legal case involving a possible breach of contract. Two relevant propositions are that there
really has been a binding contract rather than just an informal promise (proposition p) and
that the defendant broke her promise (proposition q). The defendant should be pronounced
guilty if the conjunction of these two propositions is found to be true (p  q). Our judges
take the following views on the matter:
Judge 1
Judge 2
Judge 3
Majority

p
Yes
Yes
No
Yes

q
Yes
No
Yes
Yes

pq
Yes
No
No
No

Note that the position of each individual judge is logically consistent. However, if we
aggregate this information using the majority rule (i.e., if we accept a proposition if and
only if a strict majority of the judges do), then we arrive at a collective judgment set that
is inconsistent. This paradoxical outcome, variations of which are known as the doctrinal
c
2012
AI Access Foundation. All rights reserved.

fiEndriss, Grandi, & Porello

paradox (Kornhauser & Sager, 1993) or the discursive dilemma (Pettit, 2001), has inspired
an important and fast growing literature on JA, starting with the seminal contribution of
List and Pettit (2002), who showed that in fact no aggregation procedure satisfying certain
axioms encoding natural desiderata can avoid this kind of paradox.
The literature on JA has largely developed in outlets associated with Philosophy, Economic Theory, Political Science, and Logic, but recently JA has also come to be recognised
as being relevant to AI, particularly to the design and analysis of multiagent systems. The
reasons are clear: in a multiagent system, different autonomous software agents may have
different opinions on the same issues (maybe due to a difference in access to the relevant
information, or due to different reasoning capabilities), and some joint course of action
needs to be extracted from these diverse views. Indeed, in AI, the related problem of belief
merging has been studied for some time (see, e.g., Konieczny & Pino Perez, 2002; MaynardZhang & Lehmann, 2003; Chopra, Ghose, & Meyer, 2006; Everaere, Konieczny, & Marquis,
2007), and there are interesting parallels between that literature and JA (Pigozzi, 2006).
JA has also been found to be relevant to the analysis of abstract argumentation frameworks
widely studied in AI (Caminada & Pigozzi, 2011; Rahwan & Tohme, 2010).
Given the relevance of JA to AI, it is important to understand its computational aspects.
However, to date, these have only received relatively little attention in the literature. This
can of course be explained by the origins of the field in Law, Economics, and Philosophy.
In other domains of social choice, particularly voting and fair division, on the other hand,
the recent focus on computational aspects has been very successful and has given rise to the
field of computational social choice (Chevaleyre, Endriss, Lang, & Maudet, 2007; Brandt,
Conitzer, & Endriss, 2012).
To help bridge this gap, in this paper we shall analyse the computational complexity of
three important problems that arise in JA:
 Winner determination. The winner determination problem is the problem of computing the result of applying a given aggregation procedure to a given profile of individual judgment sets. It is of immediate practical relevance to all applications of JA. We
obtain both positive and negative results: for two types of aggregation procedures,
namely the quota rules and the premise-based procedure, the winner determination
problem is easily seen to be polynomial, while for a certain distance-based procedure
we obtain an interesting intractability result, establishing completeness for parallel
access to NP that mirrors corresponding results in voting theory for the Dodgson rule
(Hemaspaandra, Hemaspaandra, & Rothe, 1997), the Young rule (Rothe, Spakowski,
& Vogel, 2003) and the Kemeny rule (Hemaspaandra, Spakowski, & Vogel, 2005).
 Strategic manipulation. An agent may try to influence the result of aggregation
in her favour by reporting a set of judgments that is different from her truthfully held
beliefs. The manipulation problem asks, for a given aggregation procedure, a given
profile of judgment sets, and a given agent, whether that agent has the opportunity to
manipulate successfully in this situation. For one natural way of defining preferences
on top of the JA framework (namely in terms of the Hamming distance) and for
aggregation procedures that are independent and monotonic, it is well-known that
agents will never have an incentive to manipulate (Dietrich & List, 2007c). In other
cases, it is interesting to explore how hard it is to solve the manipulation problem, as
482

fiComplexity of Judgment Aggregation

high complexity might signal a certain level of immunity against manipulation. In the
context of voting, this kind of question has lead to a series of interesting and important
results (Bartholdi, Tovey, & Trick, 1989; Faliszewski & Procaccia, 2010), even if we
have to be careful not to over-interpret theoretical intractability results as necessarily
providing protection in practice (Walsh, 2011). For one widely used procedure (with
an easy winner determination problem), namely the premise-based procedure, we are
able to show NP-completeness for the manipulation problem.
 Safety of the agenda. The paradox presented above shows that for some aggregation procedures it is possible to obtain a collective judgment set that is logically
inconsistent, even though each of the judgment sets supplied by the individuals is
consistent. An important parameter determining the possibility of such a paradox is
the agenda, the set of propositions on which to pass judgment. For a given aggregation procedure, the problem of the safety of the agenda asks whether a given agenda
is safe in the sense that no profile of individual judgment sets that are consistent can
ever result in a collective judgment set that is inconsistent. For various classes of
aggregation procedures, defined in terms of classical axioms, we prove safety theorems
that fully characterise agendas that are safe in this sense and we relate our results
to known possibility theorems from the JA literature (List & Puppe, 2009). We then
study the complexity of deciding whether a given agenda meets the safety conditions
identified and we find that this is typically a highly intractable problem located at
the second level of the polynomial hierarchy.
These results build on and extend our earlier work on the complexity of judgment aggregation (Endriss, Grandi, & Porello, 2010a, 2010b).
The remainder of this paper is organised as follows. In Section 2 we introduce the formal
framework of JA, including several concrete aggregation procedures and the most important
axioms used to define desiderata for such procedures. Section 2 also includes proofs of
some simple representation results that characterise aggregation procedures that satisfy
certain combinations of these axioms. Section 3 is devoted to the study of the complexity
of the winner determination problem and Section 4 does the same for the manipulation
problem. In Section 5 we then introduce the problem of the safety of the agenda, prove
several agenda characterisation theorems establishing necessary and sufficient conditions for
safety, and finally study the complexity of deciding whether those conditions are satisfied.
Section 6 reviews related work on computational aspects of JA and Section 7 concludes
with a discussion of possible avenues for future work.
Throughout this paper, we shall assume familiarity with the basics of complexity theory up to the notion of NP-completeness. Helpful introductions include the textbooks by
Papadimitriou (1994) and Arora and Barak (2009).

2. The Formal Framework of Judgment Aggregation
In this section we provide a succinct exposition of the formal framework of JA (List &
Puppe, 2009), which originally was laid down by List and Pettit (2002) and since then has
been further refined by a number of authors, notably Dietrich (2007). We also define three
concrete (families of) aggregation procedures and we discuss the most important axiomatic
483

fiEndriss, Grandi, & Porello

properties from the literature. Finally, we prove a number of representation results, which
have the status of folk theorems in the JA literature and often play a crucial role in the
proofs of more complex results, but which have rarely been stated explicitly.
2.1 Notation and Terminology
Let L be a set of propositional formulas built from a finite set of propositional variables
using the usual connectives , , , , , and the constants  (true) and  (false).
For every formula , define  to be the complement of , i.e.,  =  if  is not
negated, and  =  if  =  for some formula . We say that a set  is closed under
complementation if it is the case that    whenever   .
Definition 1. An agenda is a finite nonempty set   L that does not contain any
doubly-negated formulas and that is closed under complementation.
That is, in a slight departure from the common definition in the literature (List & Puppe,
2009), we allow for tautologies and contradictions in the agenda. The reason is that we want
to study the computational complexity of JA, and recognising a tautology or a contradiction
is itself a computationally intractable problem. We write + for the set of non-negated
formulas in , i.e.,  = +  { |   + }.
Definition 2. A judgment set J for the agenda  is a subset J  .
We call a judgment set J complete if   J or   J for all   ; we call it complementfree 1 if for all    it is not the case that both  and its complement are in J; and we
call it consistent if there exists an assignment that makes all formulas in J true. Let J ()
denote the set of all complete and consistent subsets of .
We shall occasionally interpret a judgment set J as a (characteristic) function J :  
{0, 1} with J() = 1 if   J and J() = 0 if  6 J. The Hamming distance H(J, J  )
between two (complete and complement-free) judgment sets J and J  is the number of
positive formulas on which they differ:
X
H(J, J  ) =
|J()  J  ()|
+

Given a set N = {1, . . . , n} of n > 1 individuals (or agents), we write J = (J1 , . . . , Jn ) 
J ()n for a generic profile of judgment sets, one for each individual.2 For ease of exposition,
we shall assume that n is odd (i.e., n > 3). We write NJ = {i  N |   Ji } for the set of
individuals accepting the formula  under profile J .
Definition 3. A (resolute) judgment aggregation procedure for the agenda  and the
set of individuals N with n = |N | is a function F : J ()n  2 .
1. This property is called weak consistency by Dietrich (2007), and consistency by List and Pettit (2002).
Our choice of terminology is intended to emphasise the fact that it is a purely syntactic notion, not
involving any model-theoretic concept, a distinction we believe is worth stressing.
2. In previous work we have used the more general notation J ()N (i.e., the set of functions from N to
J ()) for the set of admissible profiles (Endriss et al., 2010a). This is useful when N might be infinite
or when we do not necessarily want to associate the set of individuals with a set of natural numbers, but
we do not require this level of generality here.

484

fiComplexity of Judgment Aggregation

That is, an aggregation procedure maps any profile of individual (complete and consistent)
judgment sets to a single collective judgment set (an element of the powerset of ). We
shall occasionally refer to the assumption of all individual judgment sets being complete
and consistent as individual rationality. Note that the collective judgment set need not
be complete and consistent (that is, collective rationality need not hold). The kind of
procedure defined above is called resolute, because it will return a single judgment set for
any profile. Later, we shall also discuss irresolute JA procedures, which may return a
nonempty set of judgment sets (that are tied for winning). Finally, note that, since F is
defined on the set of all profiles of consistent and complete judgment sets, we are implicitly
making a universal-domain assumption, which is sometimes stated as a separate property
(List & Pettit, 2002).
2.2 Axiomatic Properties
In Definition 3 we did not put any constraints on the collective judgment set, the outcome
of the aggregation process. This is the role of the following definition:
Definition 4. A judgment aggregation procedure F , defined on an agenda , is said to be:
(i) complete if F (J ) is complete for every J  J ()n ;
(ii) complement-free if F (J ) is complement-free for every J  J ()n ;
(iii) consistent if F (J ) is consistent for every J  J ()n .
We now present several axioms to provide a normative framework in which to state what
the desirable properties of an acceptable aggregation procedure should be. Note that not
every procedure has to satisfy every axiom. Rather, axioms model desiderata that some
procedures satisfy and others do not. The first axiom is a very basic requirement, restricting
possible aggregators F in terms of fundamental properties of the outcomes they produce.
Weak Rationality (WR): F is complete and complement-free.3
This condition differs from what has been called collective rationality in the literature on
JA (List & Puppe, 2009), as we do not require the collective judgment set to be consistent.
The first reason not to include consistency in our most basic notion of rationality is that the
requirements of (WR) are purely syntactic notions that can easily be checked automatically,
which is not the case for consistency. The second reason is that consistency is not intrinsic
to the aggregation function, but rather depends on the properties of the agenda. This point
will be made more precise in Section 5, where we will study the consistency of a class of
aggregators depending on the agenda.
The following are the most important axioms discussed in the literature on JA (List &
Pettit, 2002; Dietrich, 2007; List & Puppe, 2009; Nehring & Puppe, 2010):
Unanimity (U): If   Ji for all agents i  N , then   F (J ).
3. In our previous work (Endriss et al., 2010a), we used a definition of weak rationality that in addition
to completeness and complement-freeness also included the (very weak) technical requirement that no
contradictory formula should be universally accepted under all profiles. As a consequence, some of our
results later on are stated slightly differently.

485

fiEndriss, Grandi, & Porello

Anonymity (A): For any profile J in J ()n and any permutation  : N  N , we have
F (J1 , . . . , Jn ) = F (J(1) , . . . , J(n) ).
Neutrality (N): For any two formulas ,  in the agenda  and any profile J in J ()n ,
if for all agents i  N we have that   Ji    Ji , then   F (J )    F (J ).
Independence (I): For any formula  in the agenda  and any two profiles J , J  in
J ()n , if   Ji    Ji for all agents i  N , then   F (J )    F (J  ).
Systematicity (S): For any two formulas ,  in the agenda  and any two profiles J ,
J  in J ()n , if   Ji    Ji for all agents i  N , then   F (J )    F (J  ).
Unanimity expresses the idea that if all individuals accept a given judgment, then so should
the collective.4 Anonymity states that aggregation should be symmetric with respect to
individuals, i.e., all individuals should be treated the same. Neutrality is a symmetry
requirement for propositions: if the same subgroup accepts two propositions, then either
both or neither should be collectively accepted. Independence says that if a proposition is
accepted by the same subgroup under two otherwise distinct profiles, then that proposition
should be accepted either under both or under neither profile. Systematicity is satisfied if
and only if both neutrality and independence are. While all of these axioms are intuitively
appealing, they are stronger than they may seem at first, and several impossibility theorems,
establishing inconsistencies between certain combinations of axioms with other desiderata,
have been proved in the literature. The original impossibility theorem of List and Pettit
(2002), for instance, shows that (under certain assumptions regarding the agenda) there
can be no complete and consistent aggregation procedure satisfying (A) and (S).
A further important property is monotonicity. We introduce two different axioms for
monotonicity. The first is the one commonly used in the literature (Dietrich & List, 2007a;
List & Puppe, 2009). It implicitly relies on the independence axiom. The second, introduced
in our previous work (Endriss et al., 2010a), is designed to be applied to neutral procedures.
For systematic procedures the two formulations are equivalent.
I-Monotonicity (MI ): For any formula  in the agenda  and any two profiles J , J  in
J ()n , if   Ji    Ji for all agents i  N , and for some s  N we have that
 6 Js and   Js , then   F (J )    F (J  ).
N-Monotonicity (MN ): For any two formulas ,  in the agenda  and any profile J
in J ()n , if   Ji    Ji for all agents i  N and  6 Js and   Js for some
s  N , then   F (J )    F (J ).
That is, (MI ) expresses that if  is collectively accepted (in J ) and receives additional
support (in J  , from agent s), then it should continue to be collectively accepted. Axiom
(MN ) says that if  is collectively accepted and  is accepted by a strict superset of the
individuals accepting , then  should also be collectively accepted.
Axioms can be used to define different classes of aggregation procedures: Given an
agenda  and a list of desirable properties AX provided in the form of axioms, we define
F [AX] to be the set of all procedures F : J ()n  2 that satisfy the axioms in AX.
4. This notion of unanimity is stronger than another common formulation only requiring J = (J, . . . , J) to
imply F (J ) = J (List & Puppe, 2009), but the two are equivalent under the assumption of (I).

486

fiComplexity of Judgment Aggregation

2.3 Judgment Aggregation Procedures
Next, we define three concrete types of aggregation procedures.
2.3.1 Uniform Quota Rules and the Majority Rule
An aggregation procedure F for n = |N | individuals is a quota rule if for every formula 
there exists a quota q  {0, . . . , n+1} such that   F (J ) if and only if |NJ | > q . The
class of quota rules has been studied in depth by Dietrich and List (2007a). In this paper,
we are interested in a particular class of quota rules:
Definition 5. Given some m  {0, . . . , n+1} and an agenda , the uniform quota rule
with quota m is the aggregation procedure Fm with   Fm (J )  |NJ | > m.
An aggregation procedure satisfies (A), (I), (MI ), and (N) if and only if it is a uniform quota
rule; this fact follows immediately from a result by Dietrich and List (2007a), who use a
slightly more narrow definition of quota rule. Provided m 6= n + 1, the uniform quota rule
Fm also satisfies (U).
A quota rule of special interest is the majority rule. The majority rule is the uniform
quota rule with m = n+1
2 ; it accepts a formula whenever there are more individuals accepting
it than there are rejecting it (recall that we did assume n to be odd). Clearly, the majority
rule is the only uniform quota rule that satisfies (WR).
2.3.2 The Premise-Based Procedure
As we have seen in the introduction, the majority rule may fail to produce a consistent
outcome. Two basic aggregation procedures that can be set up in a way so as to avoid
this problem have been discussed in the JA literature from the very beginning, namely
the premise-based and the conclusion-based procedure (Kornhauser & Sager, 1993; Dietrich
& Mongin, 2010). The basic idea is to divide the agenda into premises and conclusions.
Under the premise-based procedure, we apply the majority rule to the premises and then
infer which conclusions to accept given the collective judgments regarding the premises;5
under the conclusion-based procedure we directly ask the agents for their judgments on the
conclusions and leave the premises unspecified in the collective judgment set. That is, the
conclusion-based procedure does not result in complete outcomes (indeed, strictly speaking,
it does not conform to Definition 3), and we shall not consider it here. The premise-based
procedure, on the other hand, can be set up in a way that guarantees consistent and complete
outcomes, which provides a usable procedure of some practical interest.
For many JA problems, it may be natural to divide the agenda into premises and
conclusions. Let  = p  c be an agenda divided into a set of premises p and a set of
conclusions c , each of which is closed under complementation.

5. This is what is commonly understood by premise-based procedure. Dietrich and Mongin (2010), who
call this rule premise-based majority voting, have also investigated a more general class of premise-based
procedures in which the procedure used to decide upon the premises need not be the majority rule.

487

fiEndriss, Grandi, & Porello

Definition 6. The premise-based procedure PBP for p and c is the function mapping
each profile J = (J1 , . . . , Jn )  J ()n to the following judgment set:
PBP(J ) =   {  c |  |= },
where  = {  p | |NJ | >

n+1
}
2

That is,  is the set of premises accepted by a (strict) majority; and the PBP will return
this set  together with those conclusions  that logically follow from  ( |= ).
If we want to ensure that the PBP always returns judgment sets that are consistent and
complete, then we have to impose certain restrictions:
 If we want to guarantee consistency, then we have to impose restrictions on the
premises. It is well-known that the majority rule is guaranteed to be consistent if
and only if the agenda  satisfies the so-called median property, i.e., if every inconsistent subset of  has itself an inconsistent subset of size 6 2 (Nehring & Puppe, 2007;
List & Puppe, 2009).6 This result immediately transfers to the PBP: it is consistent
if and only if the set of premises satisfies the median property.
 If we want to guarantee completeness, then we have to impose restrictions on the
conclusions: for any assignment of truth values to the premises, the truth value of
each conclusion has to be fully determined.
We shall see in Section 5 that deciding whether a set of formulas satisfies the median
property is highly intractable. That is, in its most general form, deciding whether the
PBP is a consistent aggregation procedure for a given agenda is a complex problem. For a
meaningful analysis, we therefore make two additional assumptions. First, we assume that
the agenda  is closed under propositional variables: p   for any propositional variable p
occurring within any of the formulas in . Second, we equate the set of premises with the
set of literals. Clearly, the above-mentioned conditions for consistency and completeness
are satisfied under these assumptions.
So, to summarise, the instance of the PBP we shall work with in this paper is defined as
follows: Under the assumption that the agenda is closed under propositional variables, the
PBP accepts a literal  if and only if more individuals accept  than do accept ; and the
PBP accepts a compound formula if and only if it is entailed by the accepted literals. For
consistent and complete input profiles, and assuming that n is odd, this leads to a resolute
JA procedure that is consistent and complete. On the downside, the PBP violates most of
the standard axioms typically considered, such as (N) and (I). It even violates (U):
Agent 1
Agent 2
Agent 3
PBP

p
Yes
No
No
No

q
No
Yes
No
No

r
No
No
Yes
No

pqr
Yes
Yes
Yes
No

In this example, all three agents unanimously accept p  q  r, but when we aggregate using
the PBP, then we end up rejecting p  q  r, because each of the three premises is rejected.
6. We shall discuss this result in detail in Section 5.

488

fiComplexity of Judgment Aggregation

2.3.3 The Distance-Based Procedure
The basic idea of a distance-based approach to aggregation is to select an outcome that, in
some sense, minimises the distance to the input profile. This idea has been used extensively
in both preference aggregation (Kemeny, 1959) and belief merging (Konieczny & Pino Perez,
2002). The first example of a JA procedure based on a notion of distance was introduced
by Pigozzi (2006), albeit under the restrictive assumption that the agenda is closed under
propositional variables and that each compound formula will either be unanimously accepted
or unanimously rejected by all agents. Most importantly, in Pigozzis approach the syntactic
information contained in the agenda was discarded by moving the aggregation from the
level of formulas to the level of models. A syntactic variant of this procedure has later been
defined by Miller and Osherson (2009), which these authors call the Prototype-Hamming
rule. This is the distance-based procedure we shall define and analyse here. It is an irresolute
procedure, returning a (nonempty) set of collective judgment sets.
Definition 7. Given an agenda , the distance-based procedure DBP is the function
mapping each profile J = (J1 , . . . , Jn )  J ()n to the following set of judgment sets:
DBP(J ) = argmin

X

H(J, Ji )

JJ () iN

A collective judgment set under the DBP minimises the amount of disagreement with the
individual judgment sets (i.e., it minimises the sum of the Hamming distances with all
individual judgment sets). Note that in cases where the majority rule leads to a consistent
outcome, the outcome of the DBP coincides with that of the majority rule (making it a
resolute procedure over these profiles). We can combine the DBP with a tie-breaking rule
to obtain a resolute procedure.
The DBP is complete and consistent by design: only judgment sets in J () are considered candidates when searching for a solution. However, it violates most of the standard
axiomatic properties when those are adapted to the case of irresolute JA procedures (Lang,
Pigozzi, Slavkovik, & van der Torre, 2011). In particular, the DBP is not independent; indeed, it is based on the very idea that correlations between propositions should be exploited
rather than neglected.
2.4 Representation Results
We now prove a number of representation results that characterise the aggregation procedures that satisfy certain combinations of axioms. All of the results in this section are
known results, butdespite being very usefulthey have rarely been stated explicitly in
the literature.
Observe that an aggregation procedure F satisfies (I) if and only if there exists a family
of sets of winning coalitions W  2N , one for each formula   , such that   F (J ) 
NJ  W . Imposing additional axioms, on top of (I), forces some additional structure onto
the family of winning coalitions:
 F satisfies (I) and (U) if and only if the grand coalition belongs to every set of winning
coalitions: N  W .
489

fiEndriss, Grandi, & Porello

 F satisfies (I) and (N), i.e., it satisfies (S), if and only if there exists a single set of
winning coalitions W  2N such that   F (J )  NJ  W.
 F satisfies (I) and (A) if and only if collective acceptance of a formula only depends
on the number of individuals accepting it: C  W and |C| = |C  | imply C   W .
One consequence of the latter two insights is that, if F satisfies (A) and (S), then

|NJ | = |NJ | implies   F (J )    F (J  ). This is a well-known fact; List and Pettit
(2002), for instance, use it in the proof of their impossibility theorem (for the special case
of J = J  ). Note that a (somewhat surprising) consequence of this fact is that, in case n
is even, there exists no aggregation procedure that satisfies (A), (S), as well as (WR). To
see this, it suffices to consider a (single) profile J where exactly n2 agents accept  and n2
J |, i.e., either both  and  must be in F (J ), contraagents accept . Then |NJ | = |N
dicting complement-freeness, or neither  nor  must be in F (J ), this time contradicting
completeness. We emphasise that this basic impossibility result does not involve any notion
of logical consistency.
On the other hand, when n is odd (which we shall continue to assume), then these
axioms characterise a relevant class of aggregation procedures:
Proposition 1. F  F [WR, A, S] if and only if there exists a function h : {0, . . . , n} 
{0, 1} satisfying h(i) = 1  h(n  i) for all i  N such that   F (J )  h(|NJ |) = 1.


Proof. We have already seen that when F satisfies (S) and (A), then |NJ | = |NJ | implies
  F ()    F (J  ). The latter is equivalent to the existence of a function h :
{0, . . . , n}  {0, 1} with   F (J )  h(|NJ |) = 1. The additional requirement of h(i) =
1  h(n  i) then is a consequence of (WR). The other direction is immediate: as acceptance
of a formula under F only depends on the number of agents accepting it, F must be
anonymous, neutral and independent; the condition h(i) = 1  h(n  i) furthermore ensures
completeness and complement-freeness.
Dropping either neutrality or independence, we obtain the following representation results:
Proposition 2. F  F [WR, A, I] if and only if there exists a function h : {0, . . . , n} 
{0, 1} for every formula    satisfying h (i) = 1  h (n  i) for all i  N such that
  F (J )  h (|NJ |) = 1.
Proof. As is clear from our characterisation of procedures satisfying (I) and (A) in terms
of winning coalitions given above, for such a procedure we can always decide whether 
should be collectively accepted by only looking at the cardinality of the coalition accepting
. The rest of the proof proceeds just as for Proposition 1.
Proposition 3. F  F [WR, A, N] if and only if there exists a function hJ : {0, . . . , n} 
{0, 1} for every profile J  J ()n satisfying hJ (i) = 1  hJ (n  i) for all i  N such that
  F (J )  hJ (|NJ |) = 1.
Proof. When we drop (I), then winning coalitions are not anymore associated with formulas,
but depend on the profile J we are in. (N) merely ensures that those winning coalitions do
not also depend on the formula in question. (WR) again forces the symmetry requirement
hJ (i) = 1  hJ (n  i). The opposite direction is once again immediate.
490

fiComplexity of Judgment Aggregation

For each of the three representation results above, if we add (U) to the list of axioms, then
this corresponds to requiring h(n) = 1 for each of the characteristic functions h.
Finally, recall that we have seen in Section 2.3.1, that F  F [A, S, MI ] if and only if
F is a uniform quota rule and that F  F [WR, A, S, MI ] if and only if F is the majority
rule. That is, the representation results stated above all concern natural weakenings of
the combination of axioms characterising the majority rule. In particular, we chose never
to drop the anonymity axiom, because we find it very appealing and uncontroversial for
JA. We also consider unanimity and weak rationality very fundamental (although we make
exceptions for the class of quota rules). The independence and neutrality axioms, on the
other hand, are much more debatable, which is why we have considered the various options
of either including and not including them (although we always keep at least one of them,
to maintain a minimal amount of structure). That is, the classes of aggregation procedures
covered by the representation results above are all very natural to focus on.

3. Winner Determination
In this section we define the problem of winner determination of a given JA procedure as a
decision problem, and we study the computational complexity of this problem for each of
the procedures presented in Section 2.3.
3.1 Problem Definition
The problem of winner determination in voting theory is that of computing the election
winner given a profile of preferences supplied by the voters. The corresponding decision
problem asks, given a preference profile and a candidate, whether the given candidate is
the winner of the election. In JA, we want to compute F (J ) for a given profile J . For a
resolute aggregation procedure F , we can formulate a corresponding decision problem by
asking, for a given formula, whether it belongs to F (J ):
WinDet(F )
Instance: Agenda , profile J  J ()n , formula   .
Question: Is  an element of F (J )?
By solving WinDet once for each formula in the agenda, we can compute the collective
judgment set from an input profile. Note that asking instead whether a given judgment set
J  is equal to F (J ) does not lead to an appropriate formulation of the winner determination
problem, because to actually compute the winner we would then have to solve our decision
problem an exponential number of times (once for each possible J  ).
For the case of irresolute JA procedures F we can adapt the winner determination
problem in the following way:
WinDet (F )
Instance: Agenda , profile J  J ()n , subset L  .
Question: Is there a J    with L  J  such that J   F (J )?
To see that this is an appropriate formulation of a decision problem corresponding to the
task of computing some winning set, note that we can compute a winner using a polynomial
491

fiEndriss, Grandi, & Porello

number of queries to WinDet as follows. First, ask whether there exists a winning set
including an arbitrarily chosen first formula of the agenda 1 , i.e., L = {1 }. In case the
answer is positive, consider a second formula 2 and query WinDet with L = {1 , 2 }.
Use subset L = {1 , 2 } in case of a negative answer. Continue this process until all
formulas in the agenda have been covered.7
3.2 Winner Determination for Quota Rules and the Premise-Based Procedure
It is immediately clear that winner determination is a polynomial problem for any quota
rule, including the majority rule.
Fact 4. WinDet(Fm ) is in P for any uniform quota rule Fm .
Winner determination is also tractable for the premise-based procedure:
Proposition 5. WinDet(PBP) is in P.
Proof. Counting the number of agents accepting each of the premises and checking for each
premise whether the positive or the negative instance has the majority is easy. This determines the collective judgment set as far as the premises are concerned. Deciding whether
a given conclusion should be accepted by the collective now amounts to a model checking
problem (is the conclusion  true in the model induced by the accepted premises/literals?),
which can also be done in polynomial time.
3.3 Winner Determination for the Distance-Based Procedure
We now want to analyse the complexity of the winner determination problem for the
distance-based procedure. As the DBP is irresolute, we study the decision problem
WinDet . As we shall see, WinDet (DBP) is p2 -complete, thus showing that this rule
is very hard to compute. The class p2 (also known as p2 (O(log n)), PNP[log] or PNP
|| ) is
the class of problems that can be solved in polynomial time asking a logarithmic number
of queries to an NP oracle or, equivalently, that can be solved in polynomial time asking
a polynomial number of such queries in parallel (Wagner, 1987; Hemachandra, 1989). To
obtain our result, we first have to devise an NP oracle that will then be used in the proof
of p2 -membership. We shall use the following problem:
WinDetK (DBP)
Instance: Agenda , profile J  J ()n , subset L  , P
K  N.
Question: Is there a J   J () with L  J  such that iN H(J  , Ji ) 6 K?
That is, we ask whether there exists a judgment set J  with a Hamming distance to the
profile of at most K that accepts all the formulas in L. In other words, rather than aiming at
computing a winning judgment set, this problem merely allows us to compute a judgment set
7. In line with recent work by Hemaspaandra, Hemaspaandra, and Menton (2012), we can therefore argue
that our formulation of the winner determination problem is the correct decision problem associated
with the search problem of actually computing a winning judgment set.

492

fiComplexity of Judgment Aggregation

of a certain minimal quality (where quality is measured in terms of the Hamming distance).
We now show that this problem lies in NP.8
Lemma 6. WinDetK (DBP) is in NP.
Proof. We show that WinDetK (DBP) can be modelled as an integer program (without
objective function). This proves membership in NP (Papadimitriou, 1981). Suppose we
want to answer an instance of WinDetK (DBP). The number of subformulas of propositions
occurring in the agenda  is linear in the size (not cardinality) of . We introduce a binary
decision variable for each of these subformulas: xi  {0, 1} for the ith subformula.
We first write constraints that ensure that the chosen outcome will correspond to a
consistent judgment set (i.e., that J   J ()). Note that we can rewrite any formula in
terms of negation, conjunction, and bi-implication without resulting in a superpolynomial
(or even superlinear) increase in size. So we only need to show how to encode the constraints
for these connectives. The following table indicates how to write these constraints:
2 = 1
x2 = 1  x1
3 = 1  2 x3 6 x1 and x3 6 x2 and x1 + x2 6 x3 + 1
3 = 1  2 x1 + x2 6 x3 + 1 and x1 + x3 6 x2 + 1
and x2 + x3 6 x1 + 1 and 1 6 x1 + x2 + x3
Before we continue, consider the following way of rewriting the sum of distances featuring
in the definition of WinDetK (DBP):
X



H(J , Ji ) =

iN

=
=

n X
X

|J  ()  Ji ()|

i=1 +
n
XX

1

2

|J  ()  Ji ()|

 i=1

n
X
1 X
Ji ()|

|n  J  () 
2


i=1

We will need to bound this sum from above. Now suppose that variables xi with indices
i  {1, . . . , m} with m = || are those that correspond to the propositions that are elements
of . Let ai = |NJi | be the number of individuals that accept the ith proposition in 
(under J ). To compute a winner under the DBP, we need to find a consistent judgment
set J  (characterised by variables x1 , . . . , xm ) that minimises the sum |n  x1  a1 | +    +
|n  xm  am |. We do this by introducing an additional set of integer variables yi > 0 for
i = 1, . . . , m. We can ensure that yi = |n  xi  ai | by adding the following constraints:9
(i 6 m)
(i 6 m)

n  x i  a i 6 yi
a i  n  x i 6 yi

8. Our proof not only establishes membership in NP, but also suggests how to implement a solver for this
difficult problem. As pointed out by one anonymous reviewer, it is also possible to prove NP-membership
more directly, using a certificate that consists of both J  and a satisfying assignment for J  .
9. To be precise, these constraints only ensure |n  xi  ai | 6 yi . However, our next constraint will force the
yi to be minimal.

493

fiEndriss, Grandi, & Porello

P
Now the sum 21  m
i=1 yi corresponds to the Hamming distance between the winning set
and the profile. To ensure it does not exceed K, we can add the following constraint:
m
1 X
yi 6 K

2
i=1

Finally, we need to ensure that all the formulas in the set L   get accepted. We do this
by adding one last set of constraints:
(for all i such that i  L)

xi = 1

Now, by construction, the integer program we have presented is feasible if and only if the
instance of WinDetK (DBP) we have started out with should be answered in the positive.
This completes the proof.
To obtain an upper bound for the winner determination problem for the DBP, we can now
use a standard construction. This first involves identifying the best value for K, and then
deciding WinDetK (DBP) for that value of K. The latter can be done with a logarithmic
number of queries to the problem the complexity of which we have analysed in Lemma 6.
Together, this yields the desired upper bound:
Lemma 7. WinDet (DBP) is in p2 .
Proof. The problem WinDet (DBP) asks whether there exists a winning judgment set
that accepts all formulas in a given subset L  . Since the Hamming distance between
a judgment set and a profile is bounded from above by a polynomial figure, we can solve
this problem by performing a binary search over K using a logarithmic number of queries
to WinDetK (DBP).
P
More precisely, since iN H(J  , Ji )) 6 K  = ||
2  |N |, a figure that is polynomial
in the size of the problem description, we can ask a first query to WinDetK (DBP) with

K = K2 and an empty subset of designated formulas. In case of a positive answer, we

can continue the search with a new K = K4 , otherwise we move to the higher half of the
interval querying WinDetK (DBP) with K = 43  K  . This process ends after a logarithmic
number of steps, providing the exact Hamming distance K w of a winning candidate from
the profile J under consideration. It is now sufficient to run the problem WinDetK (DBP)
with K = K w and subset L as in the original instance of WinDet (DBP) we wanted to
solve. In case the answer is positive, since there cannot be a winning judgment set with
Hamming distance strictly less than K w , one of the winning judgment sets contains all
formulas in L. On the other hand, in case of a negative answer all judgment sets containing
L have Hamming distance bigger than K w , and thus cannot belong to the winning set.
Next, we show that the upper bound established by Lemma 7 is tight. We exploit the
similarity of the DBP to the Kemeny rule in preference aggregation to build on a known
p2 -hardness result by Hemaspaandra et al. (2005).
Lemma 8. WinDet (DBP) is p2 -hard.
494

fiComplexity of Judgment Aggregation

Proof. We build a reduction from the problem Kemeny Winner, as defined in the work of
Hemaspaandra et al. (2005).10 An instance of this problem consists of a set of candidates C,
a profile of linear preference orders P = (P1 , . . . , Pn ) over C, and a designated candidate c 
C. Define the Kemeny score of c as the following expression:
P
KemenyScore(c, P ) = min{ ni=1 dist(Pi , Q) | Q is a linear order with top(Q) = c}
Here, dist(Pi , Q) is the Hamming distance between two linear orders (defined as the number
of ordered pairs of candidates on which they disagree) and top(Q) is the most preferred
candidate under preference order Q. Kemeny Winner asks whether the Kemeny score of
c is less than or equal to the Kemeny score of all other candidates d  C.
We now build an instance of WinDet (DBP) to decide this problem. Define an agenda
C in the following way. First, add propositional variables pab for all ordered pairs of
distinct candidates a, b in C; these variables can encode a linear order over C as a binary
relation (where pab stands for a  b). Now we can describe the properties of a linear order
by means of formulas of the form pab  pbc  pac and pab  pba . We include all of these
formulas, for all a, b, c  C, in C . In fact, we include m2 + 1 syntactic variants (where
m = |C|) for each of them.11 The figure m2 + 1 is chosen to be higher than the maximal
Hamming distance between any two linear orders (which is m2 ).
Given a preference profile P , we can build a judgment profile J P by encoding each
order Pi over C in a judgment set JiP over C . For example, if agent 1s preference order
is a  b  c, then J1P will include the set {pab , pba , pbc , pcb , pac , pca }. In addition, each
JiP will include all of the syntactic copies of all of the formulas encoding linear orders.
Observe that we have dist(Pi , Pj ) = H(JiP , JjP ) by construction. It is therefore sufficient
to ask a query to WinDet (DBP) using C as the agenda, J P as the profile, and L =
{pcd | d  C, c 6= d} as the set of propositions to accept for sure, to obtain an answer to
the initial Kemeny Winner instance with designated candidate c. If the winning ranking
features c as the top candidates (i.e., formulas pcd are accepted for all other candidates d),
then its Kemeny score will be lower than or equal to that of all other candidates, providing
a positive answer to the original problem. A key insight here is to notice that judgment
sets encoding relations that are not linear orders will not be considered in the minimisation
process, since every disagreement on one of the formulas encoding linear orders will cause
a much greater loss in the Hamming distance than what can be gained by modifying the
variables encoding the individual candidate rankings.
Putting Lemma 7 and 8 together yields a complete characterisation of the complexity of
winner determination under distance-based aggregation:
Theorem 9. WinDet (DBP) is p2 -complete.
Theorem 9 shows that the DBP is highly intractable. However, by adapting efficient heuristics developed for the Kemeny rule (which, as seen in the proof of Lemma 8, is closely related
to the DBP) it may be possible to obtain an implementation of the DBP that achieves an
acceptable performance in practice (Conitzer, Davenport, & Kalagnanam, 2006).
10. Hemaspaandra et al. (2005) work with preferences that are weak orders, but point out that their results
remain valid when linear orders are used instead. To simplify presentation, we work with linear orders.
11. For instance, for the formula  we might use the syntactic variants ,   ,     , and so forth.

495

fiEndriss, Grandi, & Porello

4. Strategic Manipulation
In the context of voting, an agent is said to be able to manipulate a voting rule when there
exists a situation in which voting in a manner that does not truthfully reflect her preferences
will result in an outcome that she prefers to the outcome that would be realised if she were
to vote truthfully (Gaertner, 2006). What would constitute an appropriate definition of
manipulation in the context of JA is not immediately clear, because in JA there is no
notion of preference. However, by fixing a suitable notion of closeness on judgment sets,
it is possible to build a preference ordering starting from an individuals initial judgment
set. This is the approach followed by Dietrich and List (2007c) for JA and by Everaere
et al. (2007) in the related setting of belief merging. It builds on the assumption that an
agents individual judgment set is also her most preferred outcome and amongst any two
outcomes she will prefer the one that is closer to that most preferred outcome. We will
measure closeness using the Hamming distance and we will call an aggregation procedure
F manipulable if it permits a situation where an agent can change the outcome to get closer
to her truthful judgment by reporting untruthfully.
Our main interest will be the computational complexity of deciding whether a given
agent can successfully manipulate under a given profile. In this context, a result showing
that manipulation is computationally intractable would count as a positive result. Specifically, we will study this problem for the premise-based procedure. We will not do so for
the family of quota rules, because (as we shall see) it is impossible to manipulate a quota
rule in the aforementioned sense. We will also not study the manipulation problem for
the distance-based procedure, because (as we have seen) even the much more basic winner
determination problem already is intractable for this procedure.
4.1 Problem Definition
We first need to define a preference ordering over judgment sets for each agent i  N .
In principle, there are any number of ways of doing this, but one reasonable approach is
to assume that agent is judgment set Ji is also her most preferred outcome and that her
preferences over other outcomes depend on how close they are to Ji (Dietrich & List, 2007c).
We shall measure closeness using the Hamming distance, but other distances could also be
used to this end (Duddy & Piggins, 2012). So we will say that agent i prefers J to J  if
and only if H(Ji , J) < H(Ji , J  ).
Below we employ standard game-theoretical notation and denote by (J i , Ji ) the profile
that is like J , except that the judgment set of agent i has been replaced by Ji .
Definition 8. F is manipulable at profile J  J ()n by agent i  N , if there exists an
alternative judgment set Ji  J () such that H(Ji , F (J i , Ji )) < H(Ji , F (J )).
That is, by reporting Ji rather than her truthful judgment set Ji , agent i can achieve the
outcome F (J i , Ji ) and that outcome is closer (in terms of the Hamming distance) to her
truthful (and most preferred) set Ji than the outcome F (J ) that would get realised if she
were to truthfully report Ji . A procedure that is not manipulable at any profile by any
agent is called strategy-proof.
Dietrich and List (2007c) have shown that a JA procedure is strategy-proof if and only if
it satisfies (I) and (MI ). Indeed, this follows immediately from our definitions: independence
496

fiComplexity of Judgment Aggregation

means that the would-be manipulator can consider one proposition at a time; monotonicity
then means that it is always in her best interest to drive up the support for formulas in her
judgment set and to reduce the support for those not in her judgment set, i.e., it is in her
best interest to report her judgment set truthfully.12
For aggregation procedures for which strategy-proofness cannot be guaranteed, we want
to study the algorithmic problem of computing a manipulating judgment set. To this end,
we formulate manipulation as a decision problem for an aggregation procedure F :
Manip(F )
Instance:
Question:

Agenda , profile J  J ()n , agent i  N .
Is there a Ji  J () such that H(Ji , F (J i , Ji )) < H(Ji , F (J ))?

Note that we are asking whether an agent can manipulate successfully, rather than how.
That is, this problem does not immediately correspond to the practical (and potentially
harder) problem of computing an actual strategy for the manipulator. However, since the
interest here is in obtaining intractability results (to provide protection against manipulation), we can safely concentrate on this formulation, which provides a lower bound for the
corresponding search problem.
As we have seen, the uniform quota rules (including the majority rule) are all independent and monotonic, which means that they are also strategy-proof (so the algorithmic
problem of deciding Manip does not arise for these procedures). Of course, this comes at
the price of not always producing outcomes that are consistent.
4.2 Strategic Manipulation under the Premise-Based Procedure
We now prove that manipulating the premise-based procedure is intractable, thus showing the existence of the kind of a jump in computational complexity between winner
determination and manipulation that is desirable in this context.
Theorem 10. Manip(PBP) is NP-complete.
Proof. We first establish NP-membership. An untruthful judgment set Ji yielding a preferred outcome can serve as a certificate. Checking the validity of such a certificate means
checking that (a) Ji is actually a complete and consistent judgment set and that (b) the
outcome produced by Ji is better than the outcome produced by the truthful set Ji . As
for (a), checking completeness is easy. Consistency can also be decided in polynomial time:
for every propositional variable p in the agenda, Ji must include either p or p; this admits
only a single possible model; all that remains to be done is checking that all compound
formulas in Ji are satisfied by that model.13 As for (b), we need to compute the outcomes
for Ji and Ji (by Proposition 5, this is polynomial), compute their Hamming distances from
Ji , and compare those two distances.
Next, we prove NP-hardness by reducing Sat to Manip(PBP). Suppose we are given
a propositional formula  and want to check whether it is satisfiable. We will build a
12. Note that this does not contradict the Gibbard-Satterthwaite Theorem in voting theory (Gaertner,
2006). That theorem involves a universal-domain assumption, while the manner in which we are using
the Hamming distance to induce preferences from judgment sets amounts to a domain restriction.
13. That is, at this point we crucially rely on our assumption that the PBP is only defined for agendas that
are closed under propositional variables.

497

fiEndriss, Grandi, & Porello

judgment profile for three agents such that the third agent can manipulate the aggregation
if and only if  is satisfiable. Let p1 , . . . , pm be the propositional variables occurring in ,
and let q1 , q2 be two additional propositional variables. Define an agenda  that contains
all atoms p1 , . . . , pm , q1 , q2 and their negation, as well as m + 2 syntactic variants of the
formula q1  (  q2 ), as well as the complements of all of these formulas. For instance, if
 = q1  (  q2 ), we might use the syntactic variants ,   ,     , and so forth.
Now consider the profile J below (with the rightmost column having a weight of m + 2):

J1
J2
J3
F (J )

p1
1
0
1
1

p2
1
0
1
1







pm
1
0
1
1

q1
0
0
1
0

q2
0
1
0
0

q1  (  q2 )
?
?
1
0

The judgments of agents 1 and 2 regarding q1  (  q2 ) are irrelevant for our argument, so
they are indicated as ? in the table (but note that they can be determined in polynomial
time; in particular, J1 (q1  (  q2 )) = 0 for any ).
If agent 3 reports her judgment set truthfully (as shown in the table), then the Hamming
distance between J3 and the collective judgment set will be 1 + (m + 2) = m + 3. Note that
agent 3 is decisive about all propositional variables (i.e., premises) except for q1 (which will
certainly get rejected). Now:
 If  is satisfiable, then agent 3 can report judgments regarding p1 , . . . , pm that correspond to a satisfying assignment for . If she furthermore accepts q2 , then all m + 2
copies of q1  (  q2 ) will get accepted in the collective judgment set. Thus, the
Hamming distance from J3 to this new outcome will be at most m + 2, i.e., agent 3
will have manipulated successfully.
 If  is not satisfiable, then there is no way to get any of the m+2 copies of q1 (q2 )
accepted (and q1 will get rejected in any case). Thus, agent 3 has no means of
improving over the Hamming distance of m + 3 she can guarantee for herself by
reporting truthfully.
Hence,  is satisfiable if and only if agent 3 can manipulate successfully, and our reduction
from Sat to Manip(PBP) is complete.
Thus, manipulating the PBP is significantly harder than using it, at least in terms of worstcase complexity (and under the assumption that P 6= NP).

5. Safety of the Agenda
In this section, we introduce the concept of safety of the agenda: An agenda  is safe
for a given aggregation procedure F , if the collective judgment set returned by F will be
consistent for any (consistent) input profile. Of course, this question is only relevant for
aggregation procedures that are not always consistent to begin with, which is why we do
not consider the PBP and the DBP in this section. In fact, our main interest will be in
the safety of the agenda for entire classes of aggregation procedures, characterised by a set
498

fiComplexity of Judgment Aggregation

of axioms AX:  is safe for a class F [AX] of aggregation procedures if it is safe for every
procedure F  F [AX].
After defining the problem and relating it to so-called agenda characterisation results (or
possibility theorems, as we shall call them) studied in the JA literature, we characterise safe
agendas for a number of natural combinations of axioms and we establish the computational
complexity of checking the safety of an agenda for these cases.
5.1 Problem Definition
When performing an aggregation of judgments, we would like to avoid paradoxical outcomes,
i.e., we would like to ensure that the collective judgment set will be consistent. Whether or
not this will indeed be the case depends on several factors: the aggregation procedure, the
agenda, and the individual judgment sets. We cannot control what choices the individuals
will make. We might not even know what aggregation procedure exactly they are going
to use; we might only know about some of its properties, i.e., we might only know that it
belongs to a certain class of procedures. Can we nevertheless guarantee that the collective
judgment set will be consistent? We formalise this question as follows:
Definition 9. An agenda  is safe with respect to a class of aggregation procedures F, if
every procedure in F is consistent when applied to profiles of judgment sets over .
The example for a paradox presented in the introduction demonstrates the unsafety of the
agenda {p, p, q, q, p  q, (p  q)} with respect to the majority rule. The agenda {p, p},
on the other hand, is immediately seen to be safe with respect to the full class of all weakly
rational aggregation procedures.
The question of whether an agenda is safe is closely related to the rich literature on socalled agenda characterisation results (see, e.g., Nehring & Puppe, 2007; Dokow & Holzman,
2010; Dietrich & List, 2007b; List & Puppe, 2009). These authors have asked the following
kind of question: for a given agenda and a given list of axiomatic requirements (always
including the requirement of consistency), is it possible to find an aggregation procedure
that meets those requirements on that agenda? We may rephrase this question as follows:
given an agenda  and a list of axioms AX (now excluding consistency), is it possible to
find a procedure in F [AX] that is consistent? To distinguish results of this kind from our
safety theorems below (which are also agenda characterisations of a kind), we shall refer to
them as possibility theorems. To summarise: while a possibility theorem shows that there
is some consistent procedure in F [AX], a safety theorem shows that all procedures in
F [AX] are consistent.
Note that in case a class of aggregation procedures consists of just a single aggregation
procedure (e.g., F [WR, A, S, MI ] consists only of the majority rule), possibility and safety
results coincide.
Possibility theorems are important from the point of view of the mechanism designer:
given certain axioms that I would like to see satisfied, is it still possible to design an
aggregation procedure meeting them once I know certain characteristics of the kind of
agenda on which the procedure should be used? That is, this is a question we are likely to
ask in an off-line situation and only once. Safety theorems, on the other hand, are more
likely to play a role in an on-line situation and they arguably are of particular interest
499

fiEndriss, Grandi, & Porello

for applications. The reason is that actual users are more likely to want an assurance that
aggregation will be consistent (provided certain axioms are satisfied and the agenda has
certain properties) rather than to learn that there exists a consistent form of aggregation
(satisfying certain axioms). For instance, suppose we want to give certain guarantees for
the quality of operations of a multiagent system, but without full knowledge of the precise
specification of every individual agent and without full knowledge of all the interaction
protocols they are going to employ. We might nevertheless have sufficient information for a
safety theorem to apply, in which case we can check, for a given agenda, whether consistency
can be guaranteed. That is, deciding whether safety holds is a question we might have
to answer again and again, for many different agendas. This is why the computational
complexity of this problem is a relevant question.
5.2 Agenda Properties
As we shall see, if an agenda satisfies certain structural properties, then that might be a
sufficient condition to ensure safety with respect to certain aggregation rules. It turns out
that the types of agenda properties that are of help here are similar to those that feature in
known possibility theorems. Specifically, we shall make use of the so-called median property,
introduced by Nehring and Puppe (2007).14
Definition 10. We say that an agenda  satisfies the median property (MP), if every
inconsistent subset of  has itself an inconsistent subset of size at most 2.
In other words,  satisfies the MP if it has no minimally inconsistent subset (mi-subset)
with more than 2 elements. Note that in case  is known not to include any tautologies
(and thus no contradictions), this definition simplifies to requiring that any mi-subset must
be exactly of size 2. We can generalise the median property as follows:
Definition 11. Let k > 2. An agenda  satisfies the k-median property (kMP), if every
inconsistent subset of  has itself an inconsistent subset of size at most k.
That is, the MP and the 2MP are the same property. Agendas satisfying the MP are already
quite simple, but the restriction can be made tighter by requiring all inconsistent subsets to
have a particular form. In the sequel, we call an inconsistent set  nontrivially inconsistent
if it does not contain any single formula that is a contradiction.
Definition 12. An agenda  satisfies the simplified median property (SMP), if every
nontrivially inconsistent subset of  has a subset of the form {, } with  being logically
equivalent to .
A further simplification yields:
Definition 13. An agenda  satisfies the syntactic simplified median property
(SSMP), if every nontrivially inconsistent subset of  has a subset of the form {, }.
14. The name median property derives from the work of Nehring and Puppe (2007), who analyse social
choice functions for a class of vector spaces called median spaces.

500

fiComplexity of Judgment Aggregation

Agendas satisfying the SSMP are composed of uncorrelated formulas, i.e., they are essentially equivalent to agendas composed of atoms alone. The SMP is less restrictive, allowing
for logically equivalent but syntactically different formulas.
Observe that every agenda that satisfies the SMP also satisfies the MP. The converse
is not true:  = {p, p, p  q, (p  q)} satisfies the MP, but not the SMP. Similarly, every
agenda that satisfies the SSMP also satisfies the SMP. Again, the converse is not true:
 = {p, p, p  p, (p  p)} satisfies the SMP, but not the SSMP.
5.3 Safety Theorems: Linking Agenda Properties and Axioms
We now prove several characterisation results for the safe aggregation of judgments, concentrating on classes of procedures defined by weakening the axiomatisation of the majority
rule. We begin with a safety theorem for the majority rule itself. In fact, this result is
familiar from the literature (Nehring & Puppe, 2007), although it is presented there in a
different form. Despite the fact that it is a known result, we still provide a proof, which
arguably is simpler than translating the result of Nehring and Puppe into our setting.
Theorem 11. An agenda  is safe for the majority rule if and only if  satisfies the MP.
Proof. Let F be the majority rule.
() First, suppose  satisfies the MP. We need to show that F (J ) is consistent for
any J  J ()n . For the sake of contradiction, suppose it is not, and let  be a mi-subset
of F (J ). As F (J )  ,  can have at most 2 elements. Clearly, it cannot be the case
that F (J ) includes a contradiction  , as that would mean that a majority of the agents
would have accepted  . Hence,  must be a set of exactly two formulas, say,  and .
This means that  must have been accepted by n+1
2 or more agents and  must have been
accepted by n+1
or
more
agents.
Hence,
by
the
pigeon hole principle, at least one agent
2
must have accepted both of them, thereby contradicting individual rationality.
() For the other direction, suppose  does not satisfy the MP, i.e.,  has a mi-subset
 of size k > 3. We need to show that there exists a profile J such that F (J ) is inconsistent.
Let  and  be two distinct formulas in . Now consider a profile J with the following
properties (recall that we assume that n > 3): (1) the first n1
2 agents accept all formulas
in  except for ; (2) the last n1
agents
accept
all
formulas
in
 except for ; and (3) the
2
n+1
middlemost agent 2 accepts  and  and no other formula in . That is, no individual
agent accepts all of the formulas in , i.e., we really can build an individually rational
profile with these properties (note that any consistent subset of  can always be extended
to a complete and consistent judgment set in ). However, under this profile each of the
formulas in  has a majority and we get   F (J ), i.e., F (J ) is inconsistent.
The reason that in this case we were able to rely on a known result is the aforementioned fact
that for classes of aggregation procedures consisting of just a single procedure, safety and
possibility results coincide. Unfortunately, for larger classes of procedures, this approach of
exploiting known possibility results cannot be used.
We first establish two sufficient conditions for the safety of the agenda, for two different
(fairly large) classes of aggregation procedures:
Lemma 12. If an agenda  satisfies the SSMP, then  is safe for F [WR, U].
501

fiEndriss, Grandi, & Porello

Proof. Consider an aggregation procedure that satisfies (WR) and (U). Let  be an agenda
that satisfies the SSMP. Hence, the only way to obtain an inconsistent outcome would be to
either accept an inconsistent formula or to accept a formula  and its syntactic complement
. The latter possibility is excluded by (WR). So, for the sake of excluding also the
former possibility, suppose the inconsistent formula  has been collectively accepted. By
individual rationality,  will get accepted by all agents. Hence, by (U),  will be
collectively accepted, and thus  will be collectively rejected by (WR).
Lemma 13. If an agenda  satisfies the SMP, then  is safe for F [WR, U, N].
Proof. Let F be an aggregation procedure that satisfies (WR), (U) and (N), and let  be an
agenda that satisfies the SMP. For the sake of contradiction, suppose there exists a profile
J  J ()n such that F (J ) is inconsistent. We distinguish two cases:
(1) There exists a set {, }  F (J ) with  being logically equivalent to . But given
that all individual judgment sets are assumed to be complete and consistent,  being
logically equivalent to  means that every agent who accepts  will also accept ,
J . Together with (N) this entails   F (J )   
and vice versa, i.e., NJ = N
F (J ). We already know that   F (J ); thus, we also get   F (J ). But as we also
have   F (J ), we have obtained a contradiction to (WR).
(2) There exists an inconsistent formula   F (J ). By the same argument as used in
the proof of Lemma 12, this contradicts our assumption of F satisfying (U) and (WR).
That is, we obtain a contradiction in all possible cases.
Next, we prove two results concerning necessary conditions for the safety of the agenda
(now we aim for relatively narrowly defined classes of aggregation procedures):
Lemma 14. If an agenda  is safe for F [WR, A, U, S], then  satisfies the SMP.
Proof. Let  be an agenda that violates the SMP. We need to provide an example for
an aggregation procedure F that satisfies (WR), (A), (U) and (S) that will produce an
inconsistent outcome for at least one input profile. We distinguish two cases:
(1) Suppose  violates the SMP by virtue of having a mi-subset of size greater than 2. In
this case  also violates the MP. Then Theorem 11 shows that  is not safe for the
majority rule. As the majority rule satisfies (WR), (A), (U) and (S), we are done.
(2) The only other possibility is for  to have a mi-subset consisting of two formulas
that are not logical complements, i.e., there exists a set of the form {, }   with
 |=  but  6|= .15 Consider then the following weakly rational, anonymous,
unanimous and systematic aggregation procedure Fh for 3 individuals, defined using
the notation of Proposition 1: h(0) = h(2) = 0 and h(1) = h(3) = 1. That is, Fh
accepts a proposition only if it is accepted by an odd number of individuals.16 Consider
the following profile, restricted to  and  and their complements: J1 = {, },
15. For example,  might be p  q and  might be p.
16. This parity rule has also been used by Dokow and Holzman (2010) to provide a witness for one of their
possibility results.

502

fiComplexity of Judgment Aggregation

J2 = {, }, J3 = {, }. Note that each of these sets is consistent. However,
the profile (opportunely extended to a profile on the whole agenda) will generate an
inconsistent outcome, since both  and  are accepted by exactly one individual.
Hence, in all cases  fails to be safe for at least one procedure in F [WR, A, U, S].
Lemma 15. If an agenda  is safe for F [WR, A, U, I], then  satisfies the SSMP.
Proof. Let  be an agenda that violates the SSMP. If it also violates the SMP, then
Lemma 14 applies and we are done.
Otherwise, there must be two formulas  and  in  such that |=    but  6= ,
i.e., they are logical but not syntactic complements. Let F be the procedure that accepts
 (and rejects ) if at least one agent accepts , that accepts  (and rejects ) if at
least one agent accepts , and that behaves like the majority rule with respect to all other
propositions. F satisfies (WR), (A), (U) and (I), but  is not safe for F , because in case one
agent accepts  and another , the collective judgment set will include both  and .
We are now ready to state and prove our safety theorems:
Theorem 16. An agenda  is safe for F [WR, A, U, S] if and only if  satisfies the SMP.
Proof. One direction is given by Lemma 14. The other follows from Lemma 13 together
with the observation that F [WR, U, N]  F [WR, A, U, S].
This characterisation of safe agendas remains intact when we widen the class of aggregation
procedures under consideration from systematic to neutral procedures:
Theorem 17. An agenda  is safe for F [WR, A, U, N] if and only if  satisfies the SMP.
Proof. One direction follows from Lemma 14 together with the fact that F [WR, A, U, S] 
F [WR, A, U, N]; the other from Lemma 13 and F [WR, U, N]  F [WR, A, U, N].
Indeed, while Theorems 16 and 17 state safety results for particularly natural classes of
aggregation procedures, by the same argument we can easily see that for any class F with
F [WR, A, U, S]  F  F [WR, U, N] it is the case that  is safe for F if and only if 
satisfies the SMP.
If we drop neutrality from F [WR, A, U, S] rather than independence, then we obtain
an even more restrictive characterisation of safe agendas:
Theorem 18. An agenda  is safe for F [WR, A, U, I] if and only if  satisfies the SSMP.
Proof. One direction is given by Lemma 15; the other follows from Lemma 12 together with
F [WR, U]  F [WR, A, U, I].
Again, we can generalise the above result to say that, for any class F with F [WR, A, U, I] 
F  F [WR, U], it is the case that  is safe for F if and only if  satisfies the SSMP.
Finally, for uniform quota rules a characterisation result of the kind we seek is available
in the literature (albeit under a different name), at least for rules with certain bounds
imposed on the quota (Dietrich & List, 2007a). We state this interesting result as follows
(recall that n is the number of individuals):
503

fiEndriss, Grandi, & Porello

Theorem 19. Let k > 2. An agenda  is safe for the class of uniform quota rules Fm
satisfying the constraint m > n  nk if and only if  satisfies the kMP.
Theorem 19 is a reformulation of Corollary 2(a) in the work of Dietrich and List (2007a)
and we shall not prove it here.
Let us conclude this presentation of safety theorems with a remark on the role of the
axiom (U) in our results above. Recall that we have not made any assumption about the
agenda not including any contradictory formulas (or their complements, i.e., tautologies).
If we do make this assumption (which is very common in the JA literature and certainly
not unreasonable), then we can remove all mentionings of (U) in the safety results above.
Indeed, we only ever used (U) in our proofs to avoid situations where a contradiction gets
unanimously rejected yet collectively accepted. If we do not wish to make any assumption
regarding the absence of contradictory formulas from the agenda, then we can still remove
all mentionings of (U) from our safety results above, provided we replace all mentionings of
the SMP with the property of both satisfying the SMP and not including any contradictory
formulas (and accordingly for results involving the SSMP).
5.4 Membership Results for Agenda Properties
Now that we have identified conditions under which we can guarantee the safety of a given
agenda, we want to know how difficult it is to decide whether those conditions are satisfied.
As we shall see, this problem is p2 -complete for each of the classes of aggregation procedures
we have considered. p2 (also known as coNPNP or coNP with an NP oracle) is a complexity class located at the second level of the polynomial hierarchy (Meyer & Stockmeyer, 1972;
Stockmeyer, 1976; Arora & Barak, 2009). This is the class of decision problems for which a
certificate for a negative answer can be verified in polynomial time by a machine that has
access to an oracle for answering queries to Sat (or any other NP-complete problem). To
prove a problem p2 -complete, we have to prove both membership in p2 and p2 -hardness.
We begin by proving membership in p2 . To do so, we need to provide an algorithm
that, when provided with a certificate intended to establish a negative answer, can verify
the correctness of that certificate in polynomial time, if we assume that the algorithm has
access to a Sat oracle. In the sequel, we shall write MP both for the median property itself
and for the problem of deciding whether a given agenda  satisfies the median property,
and similarly for the SMP, SSMP and kMP.
Lemma 20. MP, SMP, SSMP, and kMP are all in p2 .
Proof. We shall present the proof for kMP, which is intuitively the most difficult of the four
problems. The proofs for the other three problems are very similar.
We need to give an algorithm that decides the correctness of a certificate for the violation
of the kMP in polynomial time, assuming it has access to a Sat oracle. For a given agenda
 (with m = ||), such a certificate is a set    that (a) needs to be inconsistent and that
(b) must not have any inconsistent subsets of size 6 k. Inconsistency of  can be checked
P

with a single query to the Sat oracle. If m = ||, then there are ki=1 mi nonempty
subsets of  of size 6 k, which is polynomial in m (and thus also in m).17 Hence, the second
condition can be checked by a further polynomial number of queries to the oracle.
17. This figure is not polynomial in k, but this does not affect the argument, as k is a constant.

504

fiComplexity of Judgment Aggregation

5.5 Hardness Results for Agenda Properties
Next, we want to show that MP, SMP, SSMP and kMP are all p2 -hard. This can be done
by giving a polynomial-time reduction from a problem that is already known to be p2 -hard
to the problem under investigation. For this purpose, we will make use of quantified boolean
formulas (QBFs). While QSat, the satisfiability problem18 for general QBFs, is PSPACEcomplete, by imposing suitable syntactic restrictions we can generate complete problems
for any level of the polynomial hierarchy. Consider a QBF of the following form:
x1    xr y1    ys .(x1 , . . . , xr , y1 , . . . , ys )
Here  is an arbitrary propositional formula and {x1 , . . . , xr }  {y1 , . . . , ys } is the set of
all propositional variables occurring in  (that is, the above could be any QBF for which
any existential quantifiers occur inside the scope of all universal quantifiers). The problem
of checking whether a formula of this form is satisfiable (i.e., true), which we shall denote
Sat, is known to be p2 -complete (Arora & Barak, 2009). Below, we shall abbreviate
formulas of the above type by writing xy.(x, y).
The basic intuition for why MP and related problems are p2 -hard is that they share
some basic structure with Sat, asking a question of the form for all subsets of  that
are inconsistent, does there exist a subset with a certain property? Indeed, embedding,
say, MP into Sat is relatively straightforward. However, here we require the opposite:
we need to show that even though Sat may appear to be more general than MP and our
other agenda problems, it actually can be reduced to each of these problems.
We first prove a technical lemma. Let Sat2 be the problem of checking whether a
QBF of the following form is true, given that we already know that (i)  is not a tautology,
(ii)  is not a contradiction, and (iii)  is not logically equivalent to a literal:
xy.(x, y)  xy.(x, y)
Lemma 21. Sat2 is p2 -hard.
Proof. By reduction from Sat: Given any QBF of the form xy.(x, y), we show
that checking its satisfiability is equivalent to running Sat2 on (  a)  b with a being
universally and b being existentially quantified, for two new propositional variables a and b
not occurring in , i.e., to checking the satisfiability of the formula
xayb.[((x, y)  a)  b]  xayb.[((x, y)  a)  b].
First, note that (  a)  b cannot be a tautology, a contradiction, or equivalent to a literal;
so the side constraints specified in the definition of Sat2 are satisfied. Also note that the
first conjunct above is true exactly when the original formula xy.(x, y) is true. This is
because b can always be set to true, and the original formula has to be true whenever a is
set to false (a falls under the scope of a universal quantifier). Therefore, a positive answer
to the Sat2 instance above entails a positive answer to the original Sat instance. The
other direction is immediate, because the second of the above conjuncts is always satisfiable
(by making b false).
18. We shall speak of satisfiability problems for QBFs, even though strictly speaking for QBFs there is no
distinction between satisfiability, truth and validity, as every QBF is a closed formula.

505

fiEndriss, Grandi, & Porello

We are now able to prove p2 -hardness for the SSMP:
Lemma 22. SSMP is p2 -hard.
Proof. We shall give a polynomial-time reduction from Sat2 to SSMP; the claim
then follows from Lemma 21. Take any instance of Sat2 , i.e., the question whether
xy.(x, y)  xy.(x, y) is true for some  with 6|= ,  6|= , and 6|=    for
literals . Suppose x = hx1 , . . . , xr i, and define an agenda as follows:19
 = {x1 , x1 , x2 , x2 , . . . , xr , xr , (  ), (  )}
We now prove that  violates the SSMP if and only if the answer to our Sat2 -question
is NO. To see this, consider the following facts. First, suppose  violates the SSMP. Under
what circumstances will this be the case? As  is neither a tautology nor a contradiction, any
inconsistent subset of  must be nontrivially inconsistent. Furthermore, by construction
of  (consisting largely of literals), any inconsistent subset of  not including a pair of
syntactic complements must include either (  ) or (  ), as well as a (complementfree) subset of {x1 , x1 , . . . , xr , xr }. That is, the only way of violating the SSMP is to
find a subset of literals from {x1 , x1 , . . . , xr , xr } to make true that forces either (  )
or (  ) to be false. But this is precisely the situation in which our instance of Sat2
requires a negative answer.
For the other direction, suppose the answer to our Sat2 -question is NO. This means
that we are able to find an assignment  for the variables in x that makes either  or 
unsatisfiable. W.l.o.g., suppose we are in the latter situation. Construct a subset of ,
containing (  ), that includes the literal xi if it is set to true by the assignment , and
xi otherwise. This is an inconsistent subset of , and since  is neither a tautology nor a
contradiction, this falsifies the SSMP.
Proving hardness for the SMP works similarly:
Lemma 23. SMP is p2 -hard.
Proof. The construction used is the same as for the proof of Lemma 22. The only additional
insight required is the observation that for the special kind of agenda constructed in that
proof, the SMP and the SSMP coincide: By excluding formulas  that are equivalent to
literals, we ensure that the agenda  constructed in the previous proof does not contain
any pairs of logically equivalent formulas.
For the MP we give a proof using a reduction from the SSMP:
Lemma 24. MP is p2 -hard.
Proof. We will show how to reduce the problem of deciding SSMP to an instance of MP.
Let  be an agenda on which we want to test the SSMP and let + = {1 , . . . , m } be
the set of non-negated formulas in . Now build the set + in the following way: copy all
formulas in + m times, every time renaming the variables occurring in i , obtaining the
19. Using (  ) rather than  ensures that the agenda  does not include doubly-negated formulas.

506

fiComplexity of Judgment Aggregation

formulas ji for 1 6 i, j 6 m. For every i substitute ii by ii  pi , where pi is a new variable
not occurring in any of the ji . Finally, add p1 , . . . , pm to + . We obtain the following set:
+ = {p1 , 11  p1 , . . . , 1m ,
p2 , 21 , 22  p2 , . . . , 2m ,
..
.
m
m
p m , m
1 , . . . , m  p }

Define  = +  { |   + }. We will now show that  satisfies the SSMP if and only
if  satisfies the MP. One direction is immediate. Suppose  does not satisfy the SSMP.
Then  must have a mi-subset  of size k > 2.20 Let  = {i1 , . . . , ik }. Then there exists
a subset of , namely  = {pi1 , ii11  pi1 , ii12 , . . . , ii1k }, that is a mi-set of size k + 1 > 3,
thereby falsifying the MP.
For the opposite direction, suppose that  does not satisfy the MP. That is,  has
a mi-subset  of size > 3. By construction of , we know that such a subset must only
contain formulas with the same superscript or their complements (all other formulas having
different variables). If this subset does not contain any pi or pi , then we can find a copy of
it in , which then violates the SSMP, in which case we are done. Clearly,  cannot include
both pi and pi , as that would contradict || > 3. So we are left with those cases where
 includes either pi or pi for some i. Then, by minimality, also ii  pi or its negation
must be included. We can now reason by cases: (1) if both pi and ii  pi are in , then
by dropping the disjunction we will still get an inconsistent subset, against the assumption
of minimality; (2) both pi and (ii  pi ) cannot be in  for the same reason; (3) finally,
pi together with the negation of ii  pi is already inconsistent. Therefore, we can conclude
that  must be of the form {pi , ii pi }i , where i is a set of (one or more) formulas in
 with the same superscript i. It is now easy to see that the set we obtain when we remove
the superscript from {ii }  i is a mi-subset of  that falsifies the SSMP. In particular,
ii 6 i , because ii 6  by construction, i.e., the mi-subset of  we obtain does not
consist of two formulas that are logical complements.
Finally, we establish hardness for the kMP:
Lemma 25. kMP is p2 -hard for every k > 2.
Proof. For k = 2, the claim has been established by Lemma 24. Now observe that we can
use exactly the same construction as in the proof of Lemma 24 to reduce any instance of
kMP for some k > 2 to an instance of the corresponding (k+1)MP. Hence, by a simple
inductive argument, kMP must be p2 -hard for any finite k > 2.
5.6 Complexity of the Safety of the Agenda
We have shown that deciding whether a given agenda  satisfies the MP, the SMP, the
SSMP, or the kMP is both in p2 and p2 -hard. Furthermore, in Section 5.3 we have linked
these properties to the safety of  for various combinations of axioms. As an immediate
corollary to all of these results, we obtain our theorem concerning the complexity of deciding
the safety of an agenda:
20. The fact that  cannot contain two formulas that are logical complements is not relevant for our proof.

507

fiEndriss, Grandi, & Porello

Theorem 26. Deciding the problem of the safety of an agenda is p2 -complete for any of
the following classes of aggregation procedures:
(i)
(ii)
(iii)
(iv)
(v)

F [WR, A, S, MI ], consisting only of the majority rule;
F [WR, A, U, S], the systematic procedures;
F [WR, A, U, N], the neutral procedures;
F [WR, A, U, I], the independent procedures;
any class of uniform quota rules Fm with m > n  nk for some k > 2.

Proof. Concerning p2 -hardness, (i) is a direct consequence of Theorem 11 and Lemma 24.
In the same way, (ii) is derived from Theorem 16 and Lemma 23, (iii) from Theorem 17 and
Lemma 23, and (iv) from Theorem 18 and Lemma 22. Finally, (v) follows from Theorem 19
together with Lemma 25. Membership in p2 follows from Lemma 20 in all five cases.
That is, not only is it the case that the safety of the agenda can only be guaranteed for
structurally simple agendas, but deciding whether a given agenda meets those structural
constraints is highly intractable. This is a negative result in the sense that it concerns a
problem that we would like to be able to solve efficiently. We should stress that this does not
render the problem hopeless. Work on QBF solvers has seen a lot of progress in recent years
(see, e.g., Narizzano, Pulina, & Tacchella, 2006), and such tools could be deployed to check
whether an agenda satisfies a given type of median property.21 In any event, understanding
how a naturally arising question in JA relates to a difficult but well-studied algorithmic
problem such as Sat is interesting and worthwhile in its own right.

6. Related Work: Computational Perspectives on Judgment Aggregation
Starting with the work of List and Pettit (2002), most research in JA has focussed either
on the philosophical implications of the fact that aggregation may result in an inconsistent
outcome or on the derivation of impossibility and characterisation results. The extensive
literature in this field has recently been reviewed by List and Puppe (2009). Some work
has also explored the links between JA and preference aggregation (Dietrich & List, 2007b;
Grossi, 2009; Porello, 2010; Grandi & Endriss, 2011) and several recent contributions have
furthermore focussed on the definition and analysis of specific aggregation procedures (Dietrich & List, 2007a; Dietrich & Mongin, 2010; Miller & Osherson, 2009; Lang et al., 2011).
Here we shall instead concentrate on contributions to JA that either have a computational
slant or that are otherwise relevant to AI.
Besides our own previous work on the subject of the present paper (Endriss et al., 2010a,
2010b), there have been a small number of contributions in computational social choice
taking a computational perspective on JA (Nehama, 2010; Slavkovik & Jamroga, 2011;
Baumeister, Erdelyi, & Rothe, 2011; Baumeister, Erdelyi, Erdelyi, & Rothe, 2012): The
first example is the work of Nehama (2010), who proposes a framework for approximate JA
in which the goal of finding an aggregation procedure that will never return an inconsistent
21. As pointed out by one anonymous reviewer, Answer Set Programming may also be a useful framework
in which to reason about safety problems. The DLV System, for instance, provides a flexible tool for
deciding arbitrary problems located at the second level of the polynomial hierarchy (Leone, Pfeifer,
Faber, Eiter, Gottlob, Perri, & Scarcello, 2006).

508

fiComplexity of Judgment Aggregation

judgment set is replaced by the goal of finding a procedure under which returning an
inconsistent set is highly unlikely. The (negative) result obtained for this framework is that
this does however not extend the range of available procedures in a significant way. Second,
Slavkovik and Jamroga (2011) extend the standard JA framework with weights (to model
differences in influence between individuals) and provide an upper bound on the complexity
of the winner determination problem for a family of distance-based aggregation procedures.
Third, Baumeister et al. (2011) provide the first study of the computational complexity of
the bribery problem in JA, asking whether it is possible to obtain a desired outcome if up to
k individual agents can be bribed so as to change their judgment set. Finally, Baumeister
et al. (2012) discuss the complexity of various forms of controlling judgment aggregation
processes, e.g., influencing the outcome by adding or removing judges.
The clearest example for work that explores the integration of ideas from JA with ideas
coming from a field traditionally studied in AI is the recent work on connections between
JA and abstract argumentation frameworks (Rahwan & Tohme, 2010; Caminada & Pigozzi,
2011): A problem commonly studied in abstract argumentation is how to decide which
ones out of a set of arguments that mutually attack each other to accept, which to reject,
and on which to remain undecided. Rahwan and Tohme (2010) study a variant of this
problem where a group of agents have to decide which status to award to which argument,
a problem that naturally lends itself to be viewed through the lens of JA. In related work,
Caminada and Pigozzi (2011) have proposed an approach to JA that involves a translation
into an abstract argumentation framework, which makes the tools and techniques of abstract
argumentation available to the aggregation of judgments.
A field of research within AI that is closely related to JA is belief merging (see, e.g.,
Konieczny & Pino Perez, 2002; Maynard-Zhang & Lehmann, 2003; Chopra et al., 2006;
Everaere et al., 2007). The work of Konieczny and Pino Perez (2002), in particular, has
inspired the distance-based procedure for JA we have used in this paper. JA and belief
merging as modelled by Konieczny and Pino Perez share interesting features, but ultimately
study different problems. While in JA individuals are assumed to submit consistent judgment sets, in belief merging this constraint is enforced only on the outcome. This reflects
the view that consistency in belief merging (modelled in terms of an integrity constraint) is
a feasibility requirement, while in JA it amounts to a rationality assumption.

7. Conclusions and Future Work
We have studied the computational complexity of three problems in JA: computing the
winning judgment set for a given aggregation procedure, deciding whether manipulation
would be beneficial for a given agent under a given aggregation procedure and for a given
profile, and deciding on the safety of the agenda for a given class of aggregation procedures.
We have also proven several safety theorems that link safety to simple structural properties
of the agenda and that provide an interesting counterpart to known possibility theorems.
Our results show that, while the winner determination problem is easy for all quota rules
and the premise-based procedure, it is intractable for the otherwise attractive distance-based
procedure. Regarding strategic manipulation, we have seen that manipulation is NP-hard
for the premise-based procedure, which is a positive result. We have also seen that for
quota rules the question of manipulation complexity does not arise, at least not for the
509

fiEndriss, Grandi, & Porello

model of preferences used here. For the distance-based procedure, we have not investigated
the complexity of the manipulation problem, because already the winner determination
problem was found to be intractable. In our work on the safety of the agenda, we have
derived characterisation results for a wide range of procedures, defined in terms of commonly
used axioms. We have seen that safety can only be guaranteed for relatively simple agendas
and we have also seen that deciding whether these simplicity conditions are met is highly
intractable.
While work on the computational aspects of JA has so far been limited to a small
number of interesting but scattered contributions, we strongly believe that JA should be
taken up as an important research topic in both AI and computational social choice. One
important direction to pursue concerns practical algorithms for the problems studied in this
paper (as well as for related problems naturally arising in JA). We have already mentioned
that existing work on algorithms for the winner determination problem for the Kemeny
rule in preference aggregation (Conitzer et al., 2006) may provide a starting point for a
working implementation of the distance-based procedure and that work on QBF solvers in
automated reasoning (Narizzano et al., 2006) or work on Answer Set Programming (Leone
et al., 2006) could prove helpful in tackling the challenges identified by our complexity
results regarding the safety of the agenda.
Alongside the development of practical algorithms, improving our understanding of the
algorithmic aspects of JA by studying it in the framework of parameterised complexity would
also be of great interest. In the context of voting, this approach has lead to a number of
insightful results (Betzler, 2010). Indeed, for JA, initial steps in this direction have already
been taken by Baumeister et al. (2011).
Studying the winner determination problem, both in complexity-theoretic and in practical terms, for the other distance-based procedures proposed by Miller and Osherson (2009)
and Lang et al. (2011) also constitutes a very worthwhile direction for future work.
Recall that we have analysed manipulation for one particular way of defining preferences,
namely in terms of the Hamming distance to an agents true set of judgments. Thus, it
would be interesting to investigate to what extent changing the definition of manipulation
(by altering the notion of induced preference) affects our complexity result. Indeed, other
notions of induced preference (and thus manipulation) are conceivable. For instance, a
would-be manipulator might only be interested in the status of specific propositions (e.g.,
the conclusions) or she might use a different notion of distance, e.g., one of those recently
proposed by Duddy and Piggins (2012).
Above we have justified our decision not to study the complexity of the manipulation
problem for the distance-based procedure with the fact that already the much more basic
winner determination problem is p2 -complete. An important question that we believe
requires discussion in the research community is whether this is indeed a valid argument.
In the context of voting, the initial idea of Bartholdi et al. (1989) had been that, say, an
NP-hardness result for the manipulation problem for a particular voting rule might suggest
that this rule is immune against manipulation in practice. Recent work very strongly
suggests that this is not the case (Faliszewski & Procaccia, 2010), and that for the kind
of NP-hard problems encountered in this context algorithms that perform well in practice
are relatively easy to design (Walsh, 2011). The question now arises whether the same will
still be true for hardness results with respect to higher complexity classes. For instance, it
510

fiComplexity of Judgment Aggregation

is conceivable that it will be possible to design algorithms that can efficiently solve most
typical instances of the winner determination problem for the distance-based procedure,
while it might turn out to be much more difficult to design a similarly successful algorithm
for the corresponding manipulation problem. That is, the question arises whether hardnessof-manipulation studies need to be restricted to problems for which winner determination
is polynomial, or whether any jump in complexity is desirable in principle and might
provide some level of protection in practice.
Regarding the safety of the agenda, we have given results for the most natural combinations of axioms that correspond to a weakening of the majority rule, but a similar study
could also be conducted for other combinations of axioms. Indeed, it would be interesting to
explore how robust our p2 -completeness results are. That is, an open question that suggests
itself is whether there exists an interesting and relevant class of aggregation procedures for
which the safety problem falls into a different complexity class.
Generally speaking, we believe that much more work on exploring the obvious potential
of JA for AI and multiagent systems is needed. This should lead to both practical advances
and the definition of interesting new theoretical problems. Some steps in this direction have
recently been taken by Slavkovik (2012), concerning the modelling of collective decision
making in multiagent systems, and by Caminada and Pigozzi (2011) and Rahwan and
Tohme (2010), concerning applications of JA to abstract argumentation.

Acknowledgments
This paper builds on our earlier work on the complexity of judgment aggregation presented
at AAMAS-2010 (Endriss et al., 2010a) and COMSOC-2010 (Endriss et al., 2010b). We
would like to thank the reviewers and members of the audiences of these meetings, three
reviewers for the Journal of Artificial Intelligence Research, and the attendees of workshop and seminar talks we have given on this topic at Amsterdam, Barcelona, Chongqing,
Luxembourg, Moscow, New Delhi, Padova, Paris, Pisa, and Tilburg for the many helpful
suggestions received.

References
Arora, S., & Barak, B. (2009). Computational Complexity: A Modern Approach. Cambridge
University Press.
Bartholdi, J. J., Tovey, C. A., & Trick, M. A. (1989). The computational difficulty of
manipulating an election. Social Choice and Welfare, 6 (3), 227241.
Baumeister, D., Erdelyi, G., Erdelyi, O. J., & Rothe, J. (2012). Control in judgment aggregation. In Proceedings of the 6th Starting AI Researchers Symposium (STAIRS-2012).
IOS Press.
Baumeister, D., Erdelyi, G., & Rothe, J. (2011). How hard is it to bribe the judges?
A study of the complexity of bribery in judgment aggregation. In Proceedings of the
2nd International Conference on Algorithmic Decision Theory (ADT-2011). SpringerVerlag.
511

fiEndriss, Grandi, & Porello

Betzler, N. (2010). A Multivariate Complexity Analysis of Voting Problems. Ph.D. thesis,
University of Jena.
Brandt, F., Conitzer, V., & Endriss, U. (2012). Computational social choice. In Weiss, G.
(Ed.), Multiagent Systems. MIT Press. In press.
Caminada, M., & Pigozzi, G. (2011). On judgment aggregation in abstract argumentation.
Autonomous Agents and Multi-Agent Systems, 22 (1), 64102.
Chevaleyre, Y., Endriss, U., Lang, J., & Maudet, N. (2007). A short introduction to computational social choice. In Proceedings of the 33rd Conference on Current Trends in
Theory and Practice of Computer Science (SOFSEM-2007). Springer-Verlag.
Chopra, S., Ghose, A., & Meyer, T. (2006). Social choice theory, belief merging, and
strategy-proofness. Information Fusion, 7 (1), 6179.
Conitzer, V., Davenport, A. J., & Kalagnanam, J. (2006). Improved bounds for computing Kemeny rankings. In Proceedings of the 21st National Conference on Artificial
Intelligence (AAAI-2006).
Dietrich, F. (2007). A generalised model of judgment aggregation. Social Choice and
Welfare, 28 (4), 529565.
Dietrich, F., & List, C. (2007a). Judgment aggregation by quota rules: Majority voting
generalized. Journal of Theoretical Politics, 19 (4), 391424.
Dietrich, F., & List, C. (2007b). Arrows theorem in judgment aggregation. Social Choice
and Welfare, 29 (1), 1933.
Dietrich, F., & List, C. (2007c). Strategy-proof judgment aggregation. Economics and
Philosophy, 23 (3), 269300.
Dietrich, F., & Mongin, P. (2010). The premiss-based approach to judgment aggregation.
Journal of Economic Theory, 145, 562582.
Dokow, E., & Holzman, R. (2010). Aggregation of binary evaluations. Journal of Economic
Theory, 145 (2), 495511.
Duddy, C., & Piggins, A. (2012). A measure of distance between judgment sets. Social
Choice and Welfare, 39 (4), 855867.
Endriss, U., Grandi, U., & Porello, D. (2010a). Complexity of judgment aggregation: Safety
of the agenda. In Proceedings of the 9th International Conference on Autonomous
Agents and Multiagent Systems (AAMAS-2010).
Endriss, U., Grandi, U., & Porello, D. (2010b). Complexity of winner determination and
strategic manipulation in judgment aggregation. In Proceedings of the 3rd International Workshop on Computational Social Choice (COMSOC-2010).
Everaere, P., Konieczny, S., & Marquis, P. (2007). The strategy-proofness landscape of
merging. Journal of Artificial Intelligence Research (JAIR), 28 (1), 49105.
Faliszewski, P., & Procaccia, A. D. (2010). AIs war on manipulation: Are we winning?. AI
Magazine, 31 (4), 5364.
Gaertner, W. (2006). A Primer in Social Choice Theory. LSE Perspectives in Economic
Analysis. Oxford University Press.
512

fiComplexity of Judgment Aggregation

Grandi, U., & Endriss, U. (2011). Binary aggregation with integrity constraints. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI2011).
Grossi, D. (2009). Unifying preference and judgment aggregation.. In Proceedings of the 8th
International Conference on Autonomous Agents and Multiagent Systems (AAMAS2009).
Hemachandra, L. A. (1989). The strong exponential hierarchy collapses. Journal of Computer and System Sciences, 39 (3), 299322.
Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (1997). Exact analysis of Dodgson
elections: Lewis Carrolls 1876 system is complete for parallel access to NP. Journal
of the ACM, 44 (6), 806825.
Hemaspaandra, E., Hemaspaandra, L. A., & Menton, C. (2012). Search versus decision
for election manipulation problems. Tech. rep. URCS-TR-2012-971, University of
Rochester, Computer Science Department.
Hemaspaandra, E., Spakowski, H., & Vogel, J. (2005). The complexity of Kemeny elections.
Theoretical Computer Science, 349 (3), 382391.
Kemeny, J. (1959). Mathematics without numbers. Daedalus, 88 (4), 577591.
Konieczny, S., & Pino Perez, R. (2002). Merging information under constraints: A logical
framework. Journal of Logic and Computation, 12 (5), 773808.
Kornhauser, L. A., & Sager, L. G. (1993). The one and the many: Adjudication in collegial
courts. California Law Review, 81 (1), 159.
Lang, J., Pigozzi, G., Slavkovik, M., & van der Torre, L. (2011). Judgment aggregation
rules based on minimization. In Proceedings of the 13th Conference on Theoretical
Aspects of Rationality and Knowledge (TARK-XIII).
Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).
The DLV system for knowledge representation and reasoning. ACM Transactions on
Computational Logic, 7 (3), 499562.
List, C., & Pettit, P. (2002). Aggregating sets of judgments: An impossibility result. Economics and Philosophy, 18 (1), 89110.
List, C., & Puppe, C. (2009). Judgment aggregation: A survey. In Handbook of Rational
and Social Choice. Oxford University Press.
Maynard-Zhang, P., & Lehmann, D. J. (2003). Representing and aggregating conflicting
beliefs. Journal of Artificial Intelligence Research (JAIR), 19, 155203.
Meyer, A. R., & Stockmeyer, L. J. (1972). The equivalence problem for regular expressions
with squaring requires exponential space. In Proceedings of the 13th Annual Symposium on Switching and Automata Theory (SWAT/FOCS-1972). IEEE Computer
Society.
Miller, M., & Osherson, D. (2009). Methods for distance-based judgment aggregation. Social
Choice and Welfare, 32 (4), 575601.
513

fiEndriss, Grandi, & Porello

Narizzano, M., Pulina, L., & Tacchella, A. (2006). The QBFEVAL web portal. In Proceedings of the 10th European Conference on Logics in Artificial Intelligence (JELIA2006). Springer-Verlag.
Nehama, I. (2010). Approximate judgment aggregation. In Proceedings of the 3rd International Workshop on Computational Social Choice (COMSOC-2010).
Nehring, K., & Puppe, C. (2007). The structure of strategy-proof social choice. Part I: General characterization and possibility results on median spaces. Journal of Economic
Theory, 135 (1), 269305.
Nehring, K., & Puppe, C. (2010). Abstract Arrowian aggregation. Journal of Economic
Theory, 145 (2), 467494.
Papadimitriou, C. H. (1981). On the complexity of integer programming. Journal of the
ACM, 28 (4), 765768.
Papadimitriou, C. H. (1994). Computational Complexity. Addison Wesley.
Pettit, P. (2001). Deliberative democracy and the discursive dilemma. Philosophical Issues,
11 (1), 268299.
Pigozzi, G. (2006). Belief merging and the discursive dilemma. Synthese, 152 (2), 285298.
Porello, D. (2010). Ranking judgments in Arrows setting. Synthese, 173 (2), 199210.
Rahwan, I., & Tohme, F. (2010). Collective argument evaluation as judgement aggregation. In Proceedings of the 9th International Conference on Autonomous Agents and
Multiagent Systems (AAMAS-2010).
Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity of the winner problem for
Young elections. Theoretical Computer Science, 63 (4), 375386.
Slavkovik, M. (2012). Judgment Aggregation for Multiagent Systems. Ph.D. thesis, University of Luxembourg.
Slavkovik, M., & Jamroga, W. (2011). Distance-based judgment aggregation of three-valued
judgments with weights. In Proceedings of the IJCAI-2011 Workshop on Social Choice
and Artificial Intelligence.
Stockmeyer, L. J. (1976). The polynomial-time hierarchy. Theoretical Computer Science,
3 (1), 122.
Wagner, K. W. (1987). More complicated questions about maxima and minima, and some
closures of NP. Theoretical Computer Science, 51 (12), 5380.
Walsh, T. (2011). Where are the hard manipulation problems?. Journal of Artificial Intelligence Research (JAIR), 42, 129.

514

fiJournal of Artificial Intelligence Research 45 (2012) 287-304

Submitted 05/12; published 10/12

Research Note
Removing Redundant Messages in N-ary BnB-ADOPT
Patricia Gutierrez
Pedro Meseguer

PATRICIA @ IIIA . CSIC . ES
PEDRO @ IIIA . CSIC . ES

IIIA - CSIC, Universitat Autonoma de Barcelona
08193 Bellaterra, Spain

Abstract
This note considers how to modify BnB-ADOPT, a well-known algorithm for optimally solving
distributed constraint optimization problems, with a double aim: (i) to avoid sending most of the
redundant messages and (ii) to handle cost functions of any arity. Some of the messages exchanged
by BnB-ADOPT turned out to be redundant. Removing most of the redundant messages increases
substantially communication efficiency: the number of exchanged messages is in most cases
at least three times fewer (keeping the other measures almost unchanged), and termination and
optimality are maintained. On the other hand, handling n-ary cost functions was addressed in the
original work, but the presence of thresholds makes their practical usage more complex. Both issues
removing most of the redundant messages and efficiently handling n-ary cost functions can be
combined, producing the new version BnB-ADOPT+ . Experimentally, we show the benefits of this
version over the original one.

1. Introduction
Distributed Constraint Optimization Problems (DCOPs) have been used to model many actual world
multiagent coordination problems, such as meeting scheduling (Maheswaran, Tambe, Bowring,
Pearce, & Varakantham, 2004), sensor network (Jain, Taylor, Tambe, & Yokoo, 2009), traffic control (Junges & Bazzan, 2008), and coalition structure generation (Ueda, Iwasaki, & Yokoo, 2010).
DCOPs include a finite number of agents, with the usual assumption that each agent holds one variable with a finite and discrete domain. Variables are related by cost functions that define a cost for
every combination of value assignments. Such costs represent preferences or penalty relations. The
cost of a particular assignment is the sum of all cost functions evaluated on that assignment. The
goal is to find a complete assignment of minimum cost by message passing.
Considering distributed search for DCOP solving, the first proposed complete asynchronous
algorithm was ADOPT (Modi, Shen, Tambe, & Yokoo, 2005). Later on, the closely related BnBADOPT (Yeoh, Felner, & Koenig, 2010) was presented. BnB-ADOPT changes the nature of the
search from ADOPT best-first search to a depth-first branch-and-bound strategy, obtaining better
performance. Both algorithms are complete, so they compute the optimum cost and are guaranteed
to terminate. ADOPT and BnB-ADOPT have a similar communication strategy, using a similar set
of messages (with small differences in their processes). They also share the same data structures
and semantics to store and update their internal tables.
In the last years, several complete DCOP algorithms have been proposed. Following the classification that appears in the work of Yeoh et al. (2010), in the search algorithm class we mention (in
addition to the previously cited ADOPT and BnB-ADOPT), Synchronous Branch and Bound (SBB)
(Hirayama & Yokoo, 1997), No Commitment Branch and Bound (NCBB) (Chechetka & Sycara,
c
2012
AI Access Foundation. All rights reserved.

fiG UTIERREZ & M ESEGUER

2006) and Asynchronous Forward Bounding (AFB) (Gershman, Meisels, & Zivan, 2009). As distributed inference algorithms we mention Dynamic Programming Optimization (DPOP) (Petcu &
Faltings, 2005). Our interest for ADOPT and BnB-ADOPT comes from the fact that they require
polynomial memory, they are asynchronous and communication is limited to neighbors. Distributed
search algorithms use polynomial memory, while DPOP requires exponential memory in the worst
case. Asynchronous algorithms have been shown more suitable to the distributed context, because
agents are active all the time and this approach is globally more robust to failures. SBB and NCBB
are examples of synchronous algorithms. Limiting communication to neighbors (no agent can communicate with other agent it is not constrained with) is a common requirement for some applications
(for instance in sensor networks). There are algorithms, such as AFB, which do not have this restriction and allow agents to broadcast messages.
ADOPT and to a lesser extent BnB-ADOPT exchange a large number of messages. Often,
this is a major drawback for their practical applicability, despite their good theoretical properties
(soundness, optimality, termination). Aiming at decreasing the number of exchanged messages
without compromising optimality and termination, this paper contains results for detecting redundant messages in BnB-ADOPT. Using these results we generate a new version which avoids sending
most of the redundant messages. Experimentally, we have seen that removing most of the redundant
messages significantly decreases communication costs (the new algorithm exchanges at least three
times fewer messages) on several widely used DCOP benchmarks. The proposed modifications can
also be applied to ADOPT (Gutierrez & Meseguer, 2010a), although we do not detail results here
since according to our experiments BnB-ADOPT usually achieves better performance.
In DCOPs, it is somehow natural to use binary cost functions, because an agent has a one-toone relation with each of its neighbors. Since each agent holds a single variable, this naturally
brings to binary functions. However, in some cases an agent may have a cost function of higher
arity with a subset of agents. The original ADOPT (Modi et al., 2005) proposes a way to deal with
n-ary constraints, and BnB-ADOPT takes the exact same strategy to deal with constraints with arity
higher than two. However, this strategy may cause inefficiency when applied to BnB-ADOPT. We
provide a simple way to correct this inefficiency, which can be easily integrated in BnB-ADOPT.
We have combined both improvements in a new version of the algorithm called BnB-ADOPT+ .
Experimental results show the benefits of the proposed approach with respect to the original algorithm. A comparison with other state-of-the-art DCOP algorithms is also included.
This paper is structured as follows. First, we provide some basic definitions and a short description of the BnB-ADOPT algorithm in Section 2. We introduce the detection of redundant messages
in Section 3. We discuss how to generalize the algorithm to deal efficiently with cost functions
of any arity in Section 4. Using these results, we propose a new version of BnB-ADOPT, called
BnB-ADOPT+ . In Section 5 we report experimental results on the benefits of BnB-ADOPT+ with
respect to its previous version. In addition, we present results comparing BnB-ADOPT+ with other
DCOP algorithms. Finally, we conclude in Section 6.

2. Background
In this Section we provide some basic DCOP definitions and a short description of the BnB-ADOPT
algorithm (Yeoh et al., 2010).
288

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

2.1 DCOP
A Distributed Constraint Optimization Problem (DCOP) (Modi et al., 2005), is formally defined by
(X , D, F, A, ) where:
 X = {x1 , ..., xn } is a set of n variables.
 D = {D1 , ..., Dn } is a collection of finite domains such that variable xi takes values in Di .
 F is a set of binary cost functions; fij  C involving the set of variables var(f ) = {xi , xj }
is a mapping Di  Dj 7 N  {0, } that associates a non-negative cost to each combination
of values of variables xi and xj . The scope of f is var(f ), and its arity is |var(f )|.
 A = {1, . . . , p} is a set of p agents.
  : X  A, maps each variable to one agent.
A cost function (also called soft constraint elsewhere) f evaluated on a particular value tuple
t gives the cost one has to pay for taking the values of t on the variables var(f ). Completely
permitted tuples in f have 0 cost, while completely forbidden tuples have  cost. Intermediate
costs are associated to tuples which are neither completely permitted nor completely forbidden. The
cost of a complete assignment is the sum of the evaluation of all cost functions on that assignment.
A solution is a complete assignment with cost below a user threshold. A solution is optimal if it
has minimum cost. We make the usual simplifying assumption that each agent owns exactly one
variable, so agents and variables can be used interchangeably (we connect agents and variables by
subindexes, agent i owns variable xi ). We also assume that a cost function f among several variables
is known by every agent that owns a variable in var(f ) (Yokoo, Durfee, Ishida, & Kuwabara, 1998).
Agents communicate through messages which are never lost and, for any pair of agents, messages
are delivered in the same order that they were sent.
A constraint graph represents a DCOP instance, where nodes in the graph correspond to variables and edges connect pairs of variables appearing in the same cost function. A depth-first search
(DFS) pseudo-tree arrangement has the same nodes and edges as the constraint graph and satisfies
that (i) there is a subset of edges, called tree edges, that form a rooted tree and (ii) two variables in
a cost function appear in the same branch of that tree. The other edges are called backedges. Tree
edges connect parent-child nodes, while backedges connect a node with its pseudo-parents and its
pseudo-children. DFS pseudo-trees can be constructed using distributed algorithms (Petcu, 2007).
2.2 BnB-ADOPT
BnB-ADOPT (Yeoh et al., 2010) is a distributed algorithm that optimally solves DCOPs using a
depth-first branch-and-bound search strategy. It is closely related to ADOPT (Modi et al., 2005),
maintaining most of its data structures and communication framework. BnB-ADOPT starts constructing a DFS pseudo-tree arrangement of its agents. After this, each agent knows its parent,
pseudo-parents, children and pseudo-children.
2.2.1 DATA S TRUCTURES
During execution an agent i maintains: its current value di ; its current context Xi , which is its
knowledge about the current value assignment of its ancestors; a timestamp for the current value
289

fiG UTIERREZ & M ESEGUER

di and each value assignment of the current context (so value recency can be compared); for every
value d  Di and context Xi , a lower and upper bound LBi (d) and UBi (d); and two bounds LBi
and UBi that are calculated in the following way:
i (d) =

P

(xj ,dj )Xi

fij (d, dj )

P
LBi (d) = i (d) + P xc children lbi,c (d)
UBi (d) = i (d) + xc children ubi,c (d)
LBi = mindDi {LBi (d)}
UBi = mindDi {UBi (d)}
where i (d) is the sum of costs of all cost functions between i and its ancestors given that i assigns
value d and ancestors assign their respective values in Xi . Tables lbi,c (d) and ubi,c (d) store upper
and lower bounds of children c, for all values d  Di and current context Xi . LBi and UBi are lower
and upper bounds of the optimal solution for context Xi . Due to memory limitations, agent i can
only store lower and upper bounds for one context. Agents may reinitialize their bounds each time
there is a context change.
The goal of every agent i is to explore the search space and ultimately chooses the value that
minimizes LBi . An agent in BnB-ADOPT changes its value assignment only when it is able to
determine that the optimal solution for that value is provably no better than the best solution found
so far for its current context. In other words, when LBi (di )  UBi for current value di .
To prune values during search, agents use a threshold value T H, initially . T Hroot remains
 during the entire solving process. In other agents, threshold values are calculated and sent from
parent to children in the following way. A threshold th sent from agent i with value d to its child c
is calculated as:
th = min(T Hi , U Bi )  i (d) 

P

chchildren,ch6=c lbi,ch (d)

Thresholds represent an estimated upper bound for the current context. Therefore, agents can
prune values using thresholds sent from their parents. That is, agent i changes its value di (prunes
it) when LBi (di )  min{THi , UBi }. If LBi = U Bi , agent i has reached the cost of an optimal
solution for context Xi .
2.2.2 C OMMUNICATION
Some communication is needed in BnB-ADOPT to calculate the global costs of individual agents
assignments and to coordinate search towards the optimal solution. BnB-ADOPT agents use three
types of messages: VALUE, COST and TERMINATE, defined as follows:
 VALUE(i; j; val; th): agent i informs child or pseudo-child j that it takes value val with
threshold th;
 COST(k; j; context; lb; ub): agent k informs parent j that with context its bounds are lb, ub;
 TERMINATE(i; j): agent i informs child j that i terminates.
290

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

As mentioned above, in BnB-ADOPT each value assignment is timestamped (both in VALUE
or COST messages). This permits VALUE and COST messages to update the context of the receiver
agent, only if their values are more recent.
Upon reception of a VALUE message, value val is copied in the receiver context if its timestamp
is more recent, and threshold th is updated if the sender is the parent of the receiver.
Upon reception of a COST message from child c, values in the context of the COST message
more recent than in the receiver context are copied in the receiver agent. If the receiver context is
compatible with the COST message context, then the agent updates its lower and upper bounds
lbi,c (d) and ubi,c (d) with the lower and upper bounds in the COST message, respectively. Otherwise, the COST message is discarded. Contexts are compatible iff they agree on common agentvalue pairs. Every time there is a context change, agents check if their bounds must be reinitialized.
2.2.3 E XECUTION
A BnB-ADOPT agent executes the following loop. First, it reads and processes all incoming messages. After completely processing the message queue, it changes its value if the lower bound of
the current value surpasses min{THi , UBi }, because in that case the value is proven to be suboptimal for the current context. Finally, the agent sends the following messages: a VALUE per child,
a VALUE per pseudo-child and a COST to its parent. This process repeats until the root agent r
reaches the termination condition LBr = UBr , which means that it has found the minimum cost.
Then it sends a TERMINATE message to each of its children and terminates. Upon reception of
a TERMINATE message, agent i sends TERMINATE messages to its children; agent i terminates
when LBi = U Bi .
For the rest of the paper, we assume that the reader has some familiarity with BnB-ADOPT (for
a more detailed description, see the original source, Yeoh et al., 2010).

3. Redundant Messages
In this Section we present the results on redundant messages considering BnB-ADOPT working on
DCOP instances with binary cost functions. In the following i, j and k are agents, all executing
BnB-ADOPT. Agent i, holding variable xi , takes value v when the assignment xi  v is made and
i informs its children, pseudo-children and parent about its new value assignment. The state of i is
defined by: (i) its value, (ii) its context, contexti , as the set of value assignments of agents located
before i in its branch (timestamps are not considered part of the context), and (iii) for each possible
value d and each children c, the lower and upper bounds lbi,c (d)/ubi,c (d).
A message msg sent from i to j is redundant if, at some future time t, other messages received
by j between msg and t would cause the same effect, so msg could have been avoided. A message
msg sent from i to j containing the assignment xi  v with timestamp t updates contextj [i] (that
is, the part of contextj containing the value of xi ) which has timestamp t0 if and only if t > t0 .
Lemma 1 In BnB-ADOPT, if agent i sends two consecutive VALUE messages to agent j with timestamps t1 and t2 , there is no message with timestamp t for agent i assignment such that t1 < t < t2 .
Proof. There is no VALUE message with timestamp between t1 and t2 for i, since both VALUE
messages are consecutive and sent from agent i. COST messages build their contexts from the
information in VALUE messages. Since no VALUE contains a timestamp between t1 and t2 for i,
no COST will contain it for i.
2
291

fiG UTIERREZ & M ESEGUER

Theorem 1 In BnB-ADOPT, if agent i sends to agent j two consecutive VALUE messages with the
same val, the second message is redundant.
Proof. Let V1 and V2 be two consecutive VALUE messages sent from agent i to agent j with the
same value val and timestamps t1 and t2 , t1  t2 . If t1 = t2 , V2 will always be discarded (and
therefore V2 will always be redundant), so we concentrate on the second option, t1 < t2 . Between
V1 and V2 agent j may receive any messages coming from other agents. When V1 reaches j, the
following cases are possible:
1. V1 does not update contextj [i] (V1 is discarded). When V2 arrives to j it may happen:
(a) V2 does not update contextj [i] (V2 is discarded). Future messages will be processed as
if V2 has not been received, so V2 is redundant.
(b) V2 updates contextj [i] which has timestamp t. There are two options: (i) t2 > t >
t1 and (ii) t2 > t = t1 . Option (i) is impossible according to Lemma 1. Option
(ii) is possible, but since t = t1 the value contained in V2 is already in contextj [i].
About future messages, every message accepted with timestamp t2 in contextj [i] would
also be accepted with timestamp t1 in contextj [i]. Since there are no messages with
timestamp between t1 and t2 for i, we conclude that V2 is redundant.
2. V1 updates contextj [i]  val, timestamp t1 . When V2 arrives to j it may happen:
(a) V2 does not update contextj [i]; as in case (1.a).
(b) V2 updates contextj [i]: since V1 updated contextj and Lemma 1, the timestamp of
contextj [i] must be t1 . V2 does not change contextj [i] but its timestamp is rewritten
with t2 . Since there are no messages with timestamp between t1 and t2 (Lemma 1), any
future message that could update contextj with t2 would also update it with t1 . So V2
is redundant.
We have not considered the threshold contained in VALUE messages because BnB-ADOPT is
complete and terminates without the use of thresholds (they are included to increase efficiency). To
see this, it is enough to realize that BnB-ADOPT without using thresholds is equivalent to BnBADOPT where thresholds were always equal to  (equal to the initial value of threshold in each
agent). All results of Section 5 of the work of Yeoh et al. (2010) remain valid if BnB-ADOPT
works with  thresholds.1 Therefore, BnB-ADOPT without thresholds terminates with the cost of
an optimal solution.
2
Lemma 2 In BnB-ADOPT, if agent k sends two consecutive COST messages C1 and C2 with the
same context, and k has not detected a context change between C1 and C2 , then there is no message
with timestamp for agent i between the ones of C1 and C2 for i, such that its context is incompatible
with C1 and C2 .
Proof. Each time agent i constrained with agent k changes value it sends a VALUE message to all
its children and pseudo-children. Since there is no context change between C1 and C2 , no message
with timestamp for i between the ones of C1 and C2 can contain a context incompatible with C1 and
C2 ; otherwise agent k would have necessarily detected a context change.
2
1. To see this, it is enough to realize that thresholds are not used in any proof of Section 5 but in the proof of Lemma 8.
However, the proof of this Lemma remains valid replacing threshold by .

292

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

Theorem 2 In BnB-ADOPT, if agent k sends to agent j two consecutive COST messages with the
same content (context, lower/upper bound) and k has not detected a context change, the second
message is redundant.
Proof. Let C1 and C2 be two consecutive COST messages sent from k to j with the same content,
and contextk has not changed between sending them. Any message may arrive to j between C1 and
C2 (coming from other agents). Upon reception, the more recent values of C1 (and later of C2 ) are
copied to contextj (by PriorityMerge, see Yeoh et al., 2010). If j detects a context change, tables
lbj,c (d) and ubj,c (d) could be reinitialized. Otherwise, contextj is compatible with the COST
context and tables lbj,c (d) and ubj,c (d) are updated with the information contained in the COST
message.
Copying C2 more recent values to contextj is not essential. Let us assume that these values
are not copied. Since there is no context change between C1 and C2 , any message with timestamps
between those of C1 and C2 will necessarily include a context compatible with C2 , according to
Lemma 2. Therefore when C2 arrives, if C2 contains values with a more recent timestamp they will
not be incompatible with contextj , so C2 only updates timestamps.
Now, let us consider some possible lbj,c (d), ubj,c (d) reinitializations. Since C2 does not cause a
context change in j, because it updates timestamps only (Lemma 2), it does not cause a lower/upper
bound reinitialization on j. Because of that, our proof concentrates on the update of bounds.
When C1 arrives, it may happen:
1. C1 is not compatible with contextj , its bounds are discarded. When C2 arrives it may happen:
(a) C2 is not compatible with contextj , so its bounds are discarded. Since C2 = C1 (except
for timestamps), actions that should be done when detecting that C2 is not compatible
were already done after detecting that C1 was not compatible. Thus, C2 is redundant.
(b) C2 is compatible with contextj , so its bounds are included in j. Since C1 was not
compatible, there must be at least one agent above j that changed its value, received
by j between C1 and C2 . There are one or several VALUE messages on its/their way
towards k or k descendants. Upon reception, one or several COST messages will be
generated. The last of them will be sent from k to j with more updated bounds, so C2
could have been avoided because a more updated COST will arrive to j. Consequently,
C2 is redundant.
2. C1 is compatible with contextj , so its bounds are included. When C2 arrives to j it may
happen:
(a) C2 is not compatible with contextj , so its bounds are discarded. Bounds provided by
C2 are useless, because are based on outdated information. In the future a more updated
COST will reach j (same reasons as previous case 1.b). So C2 is redundant.
(b) C2 is compatible with contextj , so its bounds are included. However, this causes no
change in j bounds, unless bounds have been reinitialized. In this case there is at least
one agent above j that has changed its value, and that information reached j between
C1 and C2 . The situation is the same as in case (1.b). Hence, C2 is redundant.
2
Temporarily, we define BnB-ADOPT+ as our version of BnB-ADOPT with the following changes:
(i) the second of two consecutive VALUE messages with the same i, j, val and th is not sent, and
293

fiG UTIERREZ & M ESEGUER

(ii) the second of two consecutive COST messages with the same k, j, context, lb and ub when
k detects no context change is not sent. These changes do not affect the algorithms optimality, as
proved next.
Theorem 3 BnB-ADOPT+ terminates with the cost of an optimal solution.
Proof. By Theorem 1 if agent i sends two consecutive VALUE messages with the same val to
agent j, the second is redundant. However, if they differ in th, we also send the second VALUE
message for efficiency purposes. Observe that sending some redundant messages does not cause
any incorrect behavior. By Theorem 2, COST messages not sent by BnB-ADOPT+ are redundant
so they can be eliminated. BnB-ADOPT terminates with a the cost of an optimal solution (Yeoh
et al., 2010), so BnB-ADOPT+ also terminates with the cost of an optimal solution.
2
Experimentally, this version only caused some minor benefits. We realized that we have ignored threshold management. Observe that thresholds are reinitialized to  after each context
change (caused by VALUE or COST messages); this causes no special difficulty in the original
BnB-ADOPT algorithm because each time an agent processes its message queue, it sends VALUE
messages to its children containing their thresholds. Now, if some of these VALUE messages are not
sent, children will run the algorithm with an  threshold during some periods. To avoid this, children should have a way to ask for threshold to their parents after each reinitialization. This is done
using COST messages, which are sent from children to parents. Thus, we define BnB-ADOPT+ as
our BnB-ADOPT version with the following changes:
1. Agent i remembers the last message sent to each of its neighbors.
2. A COST message from j to i includes a boolean T hReq, set to true when j threshold was
reinitialized.
3. If j has to send a COST message to i that is equal to (ignoring timestamps) the last message
sent, the new COST message is sent if and only if j has detected a context change between
them.
4. If i has to send a VALUE message to j that is equal to (ignoring timestamps) the last message
sent, the new VALUE message is sent if and only if the last COST message that i received
from j had T hReq = true.
It is immediate to see that these changes do not alter the optimality and termination properties of
BnB-ADOPT+ : original BnB-ADOPT, that includes redundant messages, terminates with the cost
of an optimal solution (Yeoh et al., 2010); sending some of those redundant messages the algorithm
remains optimal and terminates. The proposed changes to avoid redundant messages can also be
applied to the ADOPT algorithm (Gutierrez & Meseguer, 2010a).

4. Dealing with N-ary Cost Functions
We have defined DCOPs using binary cost functions, although DCOP definition can be easily extended to include cost functions of any arity. Similarly, ADOPT and BnB-ADOPT can be extended
to deal with cost functions of any arity. The proposed BnB-ADOPT extension is exactly the same as
294

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

the ADOPT extension to handle n-ary cost functions (Yeoh et al., 2010). That extension, described
in the work of Modi et al. (2005), is as follows: 2
...a ternary constraint fijk ... defined over three variables xi , xj , xk ... Suppose xi and
xj are ancestors of xk ... With our ternary constraint, both xi and xj will send VALUE
messages to xk . xk then evaluates the ternary constraint and sends COST messages
back up the tree as normal ... Thus, we deal with an n-ary constraint by assigning
responsibility for its evaluation to the lowest agent involved in the constraint. The only
difference between evaluation of an n-ary constraint and a binary one is that the lowest
agent must wait to receive all ancestors VALUE messages before evaluating ...
In other words (replacing constraint by cost function), in the proposed extension agents
must send their VALUE messages to the lowest agent of the DFS pseudo-tree involved in a cost
function. In the case of a binary cost function, the lower agent (of the two involved in the cost
function) always receives VALUE messages. In the case of n-ary cost functions (involving more
than two agents), intermediate agents do not receive VALUE messages from the rest of the agents
involved in that function. The lowest agent xk must receive all VALUE messages before evaluating
the cost function. Because of this, it is called the evaluator agent. Upon reception of all these
messages, xk evaluates the function and sends a COST message to its parent, which receives and
processes the message as any other COST message. When applying this technique to BnB-ADOPT
some issues appear, as explained in the following.
4.1 TERMINATE Messages
In our version of binary BnB-ADOPT, each time an agent changes value it sends VALUE messages
to its children and pseudo-children. A non-root agent terminates when it reaches the termination
condition LB = U B after receiving a TERMINATE message from its parent (for the root agent
no TERMINATE message is needed). As a side-effect, the last value taken by all agents is the
optimal value. This feature is very appreciated in distributed environments, because optimal values
are distributed among agents without requiring a central agent in charge of the whole solution.
In n-ary BnB-ADOPT, although the root agent computes the minimum cost, a direct implementation may not terminate with an optimal value assigned to every agent. Let us consider a ternary
cost function among agents i, j and k (as in Figure 1); i is at the root of the DFS pseudo-tree, and
k evaluates the cost function. Agent i may explore its last value, jump back to its best value where
it reaches termination condition LB = U B, it sends a VALUE message to k and a TERMINATE
message to its child j. Upon reception of VALUE message, k will send a COST message to j. This
COST message contains the last assignment (optimal value) made by i. However, if j has already
processed the TERMINATE message from i, it will have ended without processing that COST message, which means that j may end with an outdated context: 3 this causes j to end with an assigned
value which may not be an optimal one, since it does not truly minimize the cost of the global
solution. 4
2. It must also be assured that all agents involved in an n-ary cost function lie on the same branch of the pseudo-tree.
This is guaranteed since agents sharing n-ary cost functions form a clique in the constraint graph. When performing
a depth first traversal to construct the DFS pseudo-tree, agents of the clique will necessarily lie on the same branch.
3. This would not happen if agent i would have sent VALUE messages to every child j informing of value changes, but
this is not the original BnB-ADOPT strategy to deal with n-ary cost functions.
4. Technically speaking, j might terminate with an incorrect context.

295

fiG UTIERREZ & M ESEGUER

VALUE

xi

TH=50

xj

TH=

xk
nary constraint

TH=min(, UB) 
(v)-child  xc lb(v,child)

xc

xi, xj, xk

Figure 1: Original BnB-ADOPT dealing with n-ary constrains, use of VALUE messages
A simple way to correct this is to include in TERMINATE messages the last assignment made
by the sender agent. In this way, the receiver can update its context and terminate with the value
that truly minimizes the lower bound.
4.2 VALUE Messages
If the ADOPT strategy for n-ary cost functions is applied literally to BnB-ADOPT, there are scenarios which are inefficiently solved. For instance, consider Figure 1, where variables of agents i, j, k
share a ternary cost function. Agent i is the root of the DFS pseudo-tree and k is the lowest agent
(therefore the evaluator) of the ternary cost function. Suppose xj is constrained with other variables
of the problem, represented here as a gray subtree. Since VALUE messages are sent from i and j
to k to inform value changes, but no VALUE messages are sent from i to j, agent j will not have
a threshold provided by its parent. Thresholds provided by parents are the lowest upper bounds
among all visited contexts (the cost of the best solution found so far), while thresholds computed
by agents themselves are upper bounds of the cost for the current context. Thresholds were introduced in BnB-ADOPT to speed up problem resolution and increase pruning opportunities, so not
having the tightest threshold on agent j and on j subtree is clearly detrimental to the algorithm
performance.
A simple way to avoid this issue is to send VALUE messages to all descendants (children and
pseudo-children). However, this is more than needed. We can avoid unnecessary messages by only
sending VALUE messages to the lowest agent in charge of evaluating the cost function to generate
COST messages with updated LB and U B and to children to propagate the T H value down
in the DFS pseudo-tree. Any agent involved in a cost function with i, such that it is neither the
evaluator of the cost function nor a child of i does not need to receive VALUE messages from i.
This is our proposed extension for BnB-ADOPT to deal with n-ary cost functions. Observe that in
296

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

the binary case, this proposal collapses into the existing operation for both algorithms. In the rest
of the paper we assume this extension is included in our version of BnB-ADOPT, to deal with cost
functions of any arity.
4.3 Correctness and Completeness
We define n-ary BnB-ADOPT as in the work of Yeoh et al. (2010) (i.e., each agent sends VALUE
messages to the evaluator agent of the cost functions it is involved in) plus each agent sends its
VALUE messages to all its children in the pseudo-tree. It is easy to show that this n-ary BnBADOPT version is optimal and terminates. First, we prove that if agents send VALUE messages to
their children and pseudo-children, this extended n-ary BnB-ADOPT terminates with the cost of an
optimal solution. Second, we show that VALUE messages send to pseudo-children are redundant
(except if the pseudo-child is the evaluator agent of a cost function that involved the sender). Third,
we demonstrate that redundant messages in the binary case remain redundant in the n-ary case.
Combining these results we obtain the desired output: a proof that n-ary BnB-ADOPT+ terminates
with the cost of an optimal solution.
Theorem 4 N-ary BnB-ADOPT terminates with the cost of an optimal solution.
Proof. Imagine an extended version of n-ary BnB-ADOPT where agents send VALUE messages
to all their descendants (children and pseudo-children) in the pseudo-tree. This extended version
of n-ary BnB-ADOPT is working as in the binary case: each agent sends VALUE messages to all
its descendants (children or pseudo-children) and it sends a COST message to its parent. In this
case, it is easy to check that all the results of Section 5 in the paper of Yeoh et al. (2010) apply
here (it is long but conceptually easy; observe that no result of Section 5 in the paper of Yeoh et al.
uses the fact that cost functions are binary). In particular, Yeoh et al. proved that binary BnBADOPT terminates with the cost of an optimal solution. Therefore, this extended version of n-ary
BnB-ADOPT terminates with the cost of an optimal solution.
Now, we consider VALUE messages sent from agent i to its pseudo-children that are not the
evaluators of any cost function involving agent i. We show that these messages are redundant. After
receiving a VALUE message from i:
1. Agent j updates its context.
2. If the message comes from its parent, agent j rewrites its own threshold with the message
threshold.
We know that i is not the parent of j, so we consider point (1) only. Agent j is not the evaluating
agent of a cost function involving i; thus, there is another agent k in the same branch and below
i and j that is in charge of such evaluation. This agent k will receive for sure the VALUE
messages coming from its ancestors, and then it will send COST messages up the tree. When these
COST messages reach j, they will update its context exactly in the same way as after receiving j
a VALUE message from i. Original VALUE messages are redundant because the same effect can
be obtained with the COST messages arriving from k. Therefore, we can remove these VALUE
messages from our extended version of n-ary BnB-ADOPT, and the algorithm will terminate with
the cost of an optimal solution. By definition, this algorithm is n-ary BnB-ADOPT.
2
Next we prove that redundant messages in the binary case remain redundant in the n-ary case.
297

fiG UTIERREZ & M ESEGUER

Lemma 3 VALUE and COST messages found redundant for binary BnB-ADOPT remain redundant
for n-ary BnB-ADOPT.
Proof. To prove this Lemma, it is enough to realize that Theorems 1 and 2 remain valid for n-ary
BnB-ADOPT. Observe that in the proofs of Lemma 1, Theorems 1 and 2 do not required the use
of binary cost functions. The proof of Lemma 2 can be easily generalized to the n-ary case, simply
replacing to all its children and pseudo-children by to all its children and evaluator pseudochildren.
2
We define n-ary BnB-ADOPT+ as n-ary BnB-ADOPT removing redundant VALUE and COST
messages, as in Section 3.
Corollary 1 N-ary BnB-ADOPT+ terminates with the cost of an optimal solution.
Proof. Combining Theorem 4 and Lemma 3 we prove that n-ary BnB-ADOPT is not sending
redundant VALUE or COST messages and terminates with the cost of an optimal solution.
As in Section 3, a child may ask its parent to resend the threshold in a VALUE message if
its threshold has been reinitialized. These exceptions do not cause any extra difficulty here. The
justification to show that sending these messages does not question optimality and termination in
the binary case, remains fully valid for the n-ary case.
2
In the following we do not make any difference between the binary and n-ary cases; instead we
use a single algorithm, n-ary BnB-ADOPT+ , that we simply name BnB-ADOPT+ .

5. Experimental Results
We experimentally evaluated the performance of original BnB-ADOPT (binary and n-ary versions)
against our proposal for n-ary BnB-ADOPT (Section 4) and against BnB-ADOPT+ (that includes
the changes proposed in Sections 3 and 4), using a discrete event simulator. Performance is evaluated in terms of communication cost (total number of messages exchanged) and computation effort
(NCCCs, non-concurrent constraint checks, see Meisels, Kaplansky, Razgon, & Zivan, 2002). We
also consider the number of cycles as the number of iterations the simulator must perform until
the solution is found. On each cycle, agents read incoming messages from their message queue,
process them, and send outgoing messages when required. The DFS pseudo-tree is generated in a
distributed form, following a most-connected heuristic.
First, we evaluate the impact of removing redundant messages in the binary case, comparing
original BnB-ADOPT against BnB-ADOPT+ . Second, we evaluate performance in non-binary instances. We compare original BnB-ADOPT with our proposal for n-ary BnB-ADOPT (changes of
Section 4) and against BnB-ADOPT+ (n-ary BnB-ADOPT saving redundant messages). Lastly, we
compare BnB-ADOPT+ against two other well-known algorithms for DCOP solving: Synchronous
Branch and Bound (SBB) (Hirayama & Yokoo, 1997) and Asynchronous Forward Bounding (AFB)
(Gershman et al., 2009). SBB is a completely synchronous algorithm whereas AFB performs synchronous value assignments but asynchronously computes the bounds used for pruning. SBB and
AFB maintain a total order of variables to perform assignments while BnB-ADOPT+ uses a partial
ordering following the DFS pseudo-tree structure. We present this last comparison to provide an
overall picture of BnB-ADOPT+ and how its asynchronous nature affects the number of messages
exchanged and computation.
Experiments are performed on three different benchmarks: random DCOPs (binary and ternary
cases), meeting scheduling and sensor networks (both are binary, obtained from a public DCOP
298

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

repository, Yin, 2008). Random DCOPs are characterized by hn, d, p1 i, where n is the number
of variables, d is the domain size and p1 is the network connectivity. Random generation assures
connected problems, so all agents of the problem belong to the same constraint graph and the same
DFS pseudo-tree. Binary instances contain p1  n(n  1)/2 binary cost functions, while ternary
instances contain p1  n(n  1)(n  2)/6 ternary cost functions. Costs are selected randomly from
the set {0,..., 100}. In meeting scheduling, variables represent meetings, domains represent time
slots assigned for meetings, and there are cost functions between meetings that share participants
(Maheswaran et al., 2004). In sensor networks, variables represent areas that need to be observed,
domains represent time slots, and there are cost functions between adjacent areas (Maheswaran
et al., 2004).
Results of the first experiment comparing BnB-ADOPT and BnB-ADOPT+ appear in Table 1
and Table 2. Table 1 shows results on binary random problems averaged over 50 instances. Table
1(a) shows results varying network connectivity with hn = 10, d = 10, p1 = 0.2...0.8i. Table 1(b)
shows results varying domain size with hn = 10, d = 6...12, p1 = 0.5i. Table 1(c) shows results
varying the number of variables with hn = 6...12, d = 10, p1 = 0.5i. Table 2 (a) shows meeting
scheduling instances in 4 cases with different hierarchical scenarios: case A (8 variables), B (10
variables), C (12 variables) and D (12 variables). Table 2 (b) shows sensor network instances in 4
cases with different topologies: cases A (16 variables), B (16 variables), C (10 variables) and D (16
variables). In these two last benchmarks, results are averaged over 30 instances.
Experiments with binary random DCOPs show that our algorithm BnB-ADOPT+ obtains important communication savings with respect to original BnB-ADOPT. The number of messages is
reduced between 3 and 6 times when connectivity and domain size increases, also showing a consistent reduction, by a factor between 4 and 5, when increasing the number of variables. For meeting
scheduling instances, messages are reduced by a factor between 3 and 9, and for sensor networks,
by a factor between 5 and 8. The standard deviation of messages also decreases in all problems
considered.
Regarding NCCCs, the mean is also moderately reduced in all instances (around 10%). In the
binary random benchmark, their standard deviation is also slightly reduced. In meeting scheduling
and sensor networks, their standard deviation increases. However, when looking at every problem
separately, the number of NCCCs of BnB-ADOPT+ is always smaller in every instance. The number of cycles remain practically unchanged. These results clearly indicate that, in the binary case,
removing redundant messages is very beneficial to enhance communication, achieving also some
moderated gains in computation.
In addition, we took a particular random instance hn = 10, d = 10, p1 = 0.5i, and solved it
repeatedly using original BnB-ADOPT and BnB-ADOPT+ , varying the order in which agents are
activated in the simulator (using the same DFS pseudo-tree in all executions). Results were quite
similar across executions. Regarding saved messages, BnB-ADOPT always required between 4.3
and 4.4 times more messages than BnB-ADOPT+ (considering individual executions). These results show that the activation order of agents in the simulator has no impact in the message reduction
achieved by BnB-ADOPT+ .
Results of the second experiment appear in Table 3, which contains results of ternary random
instances with hn = 8, d = 5, p1 = 0.4...0.8i averaged over 50 instances. First row contains results
of original BnB-ADOPT (including the modification of Section 4.1). Second row contains results
for our n-ary BnB-ADOPT proposal (Section 4), where thresholds are propagated to all children.
299

fiG UTIERREZ & M ESEGUER

(a) < n = 10, d = 10, p1 >
p1
0.2
0.3
0.4
0.5
0.6
0.7
0.8

#Messages
1068 (274)
416 (74)
39,158 (36,578)
11,774 (10,105)
270,379 (432,782)
69,277 (92,291)
2,273,768 (2,149,369)
493,137 (422,360)
11,439,563 (10,231,971)
2,205,848 (1,802,655)
60,221,283 (34,121,853)
8,930,713 (5,092,602)
161,327,710 (94,398,879)
22,972,676 (13,464,530)

#NCCC
904 (23)
881 (23)
68,882 (62,180)
62,031 (53,085)
504,373 (796,625)
475,534 (776,820)
4,311,524 (3,923,577)
4,112,299 (3,760,583)
23,759,356 (22,468,476)
22,783,209 (21,040,893)
134,868,051 (90,469,274)
129,143,706 (89,328,458)
360,857,244 (212,464,295)
353,180,585 (209,726,371)

#Cycles
62 (15)
62 (15)
1,751 (1,625)
1,753 (1,629)
10,313 (16,478)
10,317 (16,483)
73,715 (69,676)
73,792 (69,808)
331,947 (299,259)
332,841 (300,784)
1,526,394 (862,540)
1,527,960 (865,974)
3,752,164 (2,210,488)
3,755,118 (2,213,631)

(b) < n = 10, d, p1 = 0.5 >
d
6
8
10
12

#Messages
618,005 (573,704)
119,841 (104,980)
1,362,586 (951,900)
288,422 (201,488)
2,711,719 (2,929,759)
597,325 (633,879)
4,871,563 (9,725,100)
1,015,541 (1,706,302)

#NCCC
701,352 (642,821)
657,276 (593,830)
2,090,231 (1,470,631)
1,986,430 (1,398,420)
5,092,387 (5,376,943)
4,842,265 (5,133,731)
10,969,641 (20,549,608)
10,342,414 (18,679,208)

#Cycles
20,305 (18,869)
20,342 (18,924)
44,507 (31,209)
44,562 (31,238)
88,224 (96,033)
88,329 (96,195)
157,856 (314,908)
157,994 (315,137)

(c) < n, d = 10, p1 = 0.5 >
n
6
8
10
12

#Messages
4,388 (3,272)
1,514 (1,020)
72,783 (54,772)
20,326 (12,971)
2,603,727 (3,358,285)
547,079 (656,709)
111,436,193 (133,362,317)
20,169,771 (23,877,564)

#NCCC
13,077 (13,214)
12,221 (12,439)
173,038 (126,743)
159,698 (113,801)
5,289,823 (6,844,174)
5,005,774 (6,576,047)
187,178,211(237,619,542)
179,110,208 (228,862,664)

#Cycles
350 (259)
350 (259)
3,576 (2,679)
3,581 (2,689)
84,706 (112,469)
84,816 (112,774)
2,633,456 (3,148,339)
2,636,675 (3,152,543)

Table 1: Results (mean and standard deviation between parenthesis) of random binary benchmarks
when varying network connectivity, domain size and number of variables: BnB-ADOPT
(first row), BnB-ADOPT+ (second row).

Third row contains BnB-ADOPT+ results, which enhances this last version by removing redundant
messages.
Experiments with ternary random DCOPs show that assuring the propagation of threshold values to all children produces clear performance benefits (Table 3, second row). Agents send some
extra messages to children containing threshold values, which are not sent in the original version,
but these extra messages contribute to a better pruning. As a global effect, less communication
is required in the overall search, and significant reductions are obtained in all metrics (messages,
NCCCs and cycles). Maintaining this positive effect, we remove redundant messages using BnBADOPT+ (Table 3, third row). Removing redundant messages causes savings up to one order of
magnitude in the number of messages exchanged. This result is very positive because execution
time is often dominated by communication time. Observe that the number of cycles have very little
300

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

variation between the second and third row. Also, there are some savings in NCCCs, although they
are not very significant. From these results we conclude that, in the n-ary case, our proposal for nary BnB-ADOPT yields clear benefits in both communication and computation, and that removing
redundant messages substantially reduces communication.
Finally, we present a third experiment comparing BnB-ADOPT with SBB and AFB in Figure
2. These experiments were performed on binary random (top), meeting scheduling (middle) and
sensor network (bottom) instances. SBB variables were statically ordered using the width heuristic
described by Hirayama and Yokoo (1997), AFB variables were ordered following this same heuristic, and BnB-ADOPT+ variables were partially ordered using a most connected heuristic when
constructing the pseudo-tree. We restrict the solving time to one hour; in the case of SBB and AFB

(a) Meeting Scheduling

A
B
C
D

#Messages
178,899 (3,638)
18,117 (627)
65,556 (912)
15,373 (426)
62,707 (741)
11,343 (347)
41,282 (862)
13,354 (455)

#NCCC
446,670 (2,786)
413,507 (13,446)
125,331 (1,963)
120,900 (1,969)
80,369 (54)
74,518 (407)
60,424 (460)
49,878 (1,692)

(b) Sensor Network
#Cycles
8,202 (302)
8,203 (302)
2,663 (43)
2,665 (43)
2,353 (34)
2,355 (35)
1,545 (48)
1,547 (48)

A
B
C
D

#Messages
9,369 (99)
1,103 (73)
12,917 (116)
1,569 (77)
6,429 (59)
1,177 (51)
15,560 (145)
2,155 (81)

#NCCC
7,241 (52)
450 (232)
11,054 (135)
592 (879)
8,786 (52)
1,495 (2,490)
12,641 (57)
2,137 (3,552)

#Cycles
313 (3)
307 (4)
414 (4)
409(4)
340 (5)
340 (6)
477 (2)
477 (2)

Table 2: Results (mean and standard deviation between parenthesis) of meeting scheduling and
sensor network instances: BnB-ADOPT (first row), BnB-ADOPT+ (second row).

p1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

#Messages
257,238 (294,137)
147,379 (139,646)
28,614 (23,822)
648,217 (413,580)
401,306 (239,271)
63,778 (33,025)
1,642,247 (975,131)
1,210,143 (523,825)
164,901 (68,876)
2,321,729 (1,106,146)
1,771,256 (678,893)
225,836 (69,630)
3,666,514 (1,316,782)
2,973,239 (1,406,400)
311,524 (93,062)
4,013,891 (897,046)
3,537,027 (1,119,242)
348,199 (73,620)
4,892,733 (788,897)
4,616,032 (1,135,830)
399,662 (70,572)

#NCCC
1,522,580 (1,863,696)
829,594 (852,754)
764,516 (783,253)
4,029,045 (2,807,389)
2,414,946 (1,641,836)
2,237,786 (1,520,761)
12,585,339 (8,483,693)
9,194,309 (4,938,582)
8,744,465 (4,813,577)
19,424,669 (10,248,817)
14,775,187 (6,678,667)
14,337,952 (6,372,442)
35,743,718 (15,729,105)
29,252,469 (16,146,978)
27,614,749 (14,316,979)
41,469,157 (11,804,005)
36,966,889 (13,604,359)
35,314,718 (12,331,316)
55,151,742 (11,209,964)
52,221,369 (14,948,424)
49,189,230 (13,197,765)

#Cycles
10,880 (12,295)
5,793 (5,357)
5,797 (5,360)
24,026 (15,085)
13,938 (8,271)
13,943 (8,270)
55,156 (32,553)
39,373 (17,188)
39,381 (17,197)
74,279 (36,150)
55,101 (21,280)
55,103 (21,280)
115,523 (43,001)
92,020 (45,010)
92,020 (45,010)
124,408 (29,353)
108,858 (36,028)
108,858 (36,028)
150,077 (25,114)
140,472 (35,672)
140,472 (35,672)

Table 3: Results (mean and standard deviation between parenthesis) on random ternary DCOPs:
original BnB-ADOPT (first row), our proposal for n-ary BnB-ADOPT (second row), and
BnB-ADOPT+ (third row).

301

fiG UTIERREZ & M ESEGUER

8

10

10

10

7

10

8

10
6

NCCC

messages

10

5

10

4

10

BnB-ADOPT+
SBB
AFB

3

10

BnB-ADOPT+
SBB
AFB

4

10

2

10
0.2

6

10

2

0.3

0.4

0.5

0.6
p1

0.7

10

0.8

9

0.2

0.3

0.4

0.5

0.6
p1

0.7

0.8

12

10

10

8

10

10

7

10

NCCC

messages

10

6

10

5

10

BnB-ADOPT+
SBB (timeouts)
AFB (timeouts)

A

BnB-ADOPT+
SBB (timeouts)
AFB (timeouts)

6

10

4

10

8

10

4

B
C
meeting scheduling problems

10

D

A

B
C
meeting scheduling problems

D

9

10

10

10

8

10

8

10

7

NCCC

messages

10

6

10

6

10

5

10

4

10

BnB-ADOPT+
SBB (timeouts)
AFB (timeouts)

BnB-ADOPT+
SBB (timeouts)
AFB (timeouts)

4

10

3

10

A

B
C
sensor network problems

D

A

B
C
sensor network problems

D

Figure 2: Comparison of algorithms BnB-ADOPT+ , SBB, AFB. Top: binary random instances.
Middle: meeting scheduling. Bottom: sensor networks.

if a problem instance could not be solved in this amount of time, we present the amount of messages
exchanged and NCCCs performed until timeout.
From these results we can observe that for random instances BnB-ADOPT+ is significantly
more efficient in low connected problems, however in tightly connected problems it requires more
messages and computational effort than SBB and AFB. We explain this behavior given that BnBADOPT+ is an asynchronous algorithm, designed to benefit from a pseudo-tree structure, where
non-connected agents lying on different branches of the pseudo-tree can explore the search space in
302

fiR EMOVING R EDUNDANT M ESSAGES IN N- ARY B N B-ADOPT

parallel. When connectivity increases, the width of the pseudo-tree decreases (in a fully connected
problem the pseudo-tree has a single branch where all agents are totally ordered). This makes
BnB-ADOPT+ asynchronous potential to decrease. At the same time, a higher number reinitializations (bounds and context) are performed, since agents have more links to ancestors, which reduces
pruning effectiveness.
For the meeting scheduling and sensor network instances, we can see that BnB-ADOPT+ is several orders of magnitude more efficient than SBB and AFB. The structured nature of these problems
(with a different topology for every case A, B, C or D (Maheswaran et al., 2004) suitable to build
balanced pseudo-trees) allows BnB-ADOPT+ to benefit from asynchronous search. In addition, we
observed that in these instances the variability of costs is smaller than in random problems: most
costs are quite similar, while some others are clearly larger. In this cases, an upper bound close
to the optimum cost is reached early in the execution. However to satisfy the pruning condition,
lower bounds contributions from almost all cost functions are needed. We observed that SBB and
to a lesser extent AFB have to go deep in the search tree to obtain such contributions (pruning is
usually done in the last agents of the ordering) and finally they are subject to thrashing. On the other
hand, BnB-ADOPT+ computes local bounds on every agent since all agents are assigned at every
moment of the execution, and specialized upper bounds are propagated to every node of the pseudotree. This allows BnB-ADOPT+ to perform pruning and, as a consequence, it reduces the search
space faster than AFB and SBB. We have confirmed this fact empirically by testing on instances
with small variability costs (even on synthetic instances where all tuples have the same cost).
In summary, we can see that the proposed BnB-ADOPT+ is clearly more efficient than original
BnB-ADOPT. In binary instances, BnB-ADOPT+ processes a third (or less) of the total number of
messages required by BnB-ADOPT (in some instances, messages are reduced by a factor of 8 or
9), and still reaches an optimal solution in almost the same number of cycles. In ternary instances,
savings reach up to one order of magnitude in communication for almost all cases. Regarding the
comparison with SBB and AFB, the new BnB-ADOPT+ outperforms both of them (in number of
messages and NCCCs) in low connected random instances, while the contrary occurs in highly
connected ones. Regarding meeting scheduling and sensor network instances, BnB-ADOPT+ outperforms SBB and AFB by a large margin. These results indicate the value of BnB-ADOPT+ for
optimal DCOP solving.

6. Conclusion
We have presented two contributions to increase the performance of BnB-ADOPT, a reference algorithm to optimally solve distributed constrained optimization problems. First, we presented theoretical results to detect redundant messages. Second, we described some difficulties when dealing with
n-ary cost functions (the original algorithm was presented in detail for the binary case). Combining these two contributions, we generated a new version of BnB-ADOPT. This new version, called
BnB-ADOPT+ , obtains substantial savings with respect to the original algorithm, when tested on
commonly used benchmarks by the DCOP community.
303

fiG UTIERREZ & M ESEGUER

Acknowledgments
This paper is an extension of a previous publication (Gutierrez & Meseguer, 2010b), with the generalization to n-ary cost functions, deeper explanations, more detailed proofs, and more experiments.
Authors sincerely thank reviewers for their useful criticisms.

References
Chechetka, A., & Sycara, K. (2006). No-commitment branch and bound search for distributed
constraint optimization. Proc. AAMAS-06, 14271429.
Gershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous forward bounding for distributed
cops. Journal of Artificial Intelligence Research, 34, 6188.
Gutierrez, P., & Meseguer, P. (2010a). Saving messages in adopt-based algorithms. Proc. 12th DCR
workshop in AAMAS-10, 5364.
Gutierrez, P., & Meseguer, P. (2010b). Saving messages in BnB-ADOPT. Proc. AAAI-10, 1259
1260.
Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem. Proc. CP97, 222236.
Jain, M., Taylor, M., Tambe, M., & Yokoo, M. (2009). DCOPs meet the realworld: Exploring
unknown reward matrices with applications to mobile sensor networks. Proc. IJCAI-09, 181
186.
Junges, R., & Bazzan, A. L. C. (2008). Evaluating the performance of DCOP algorithms in a real
world dynamic problem. Proc. AAMAS-08, 599606.
Maheswaran, R., Tambe, M., Bowring, E., Pearce, J., & Varakantham, P. (2004). Taking DCOP to
the real world: Efficient complete solutions for distributed event scheduling. Proc. AAMAS04, 310317.
Meisels, A., Kaplansky, E., Razgon, I., & Zivan, R. (2002). Comparing performance of distributed
constraints processing algorithms. Proc. 3rd DCR workshop in AAMAS-02, 8693.
Modi, P. J., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed
constraint optimization with quality guarantees. Artificial Intelligence, 161, 149180.
Petcu, A. (2007). A class of algorithms for Distributed Constraint Optimization. Ph.D. thesis.
Petcu, A., & Faltings, B. (2005). A scalable method for multiagent constraint optimization. Proc.
IJCAI-05, 266271.
Ueda, S., Iwasaki, A., & Yokoo, M. (2010). Coalition structure generation based on distributed
constraint optimization. Proc. AAAI-10, 197203.
Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: An asynchronous branch-and-bound
DCOP algorithm. Journal of Artificial Intelligence Research, 38, 85133.
Yin, Z. (2008). USC DCOP repository..
Yokoo, M., Durfee, E., Ishida, T., & Kuwabara, K. (1998). The distributed constraint satisfaction
problem: Formalization and algorithms. IEEE Trans. Know. and Data Engin., 10, 673685.

304

fiJournal of Artificial Intelligence Research 45 (2012) 125-163

Submitted 05/12; published 09/12

Towards Unsupervised Learning of Temporal
Relations between Events
Seyed Abolghasem Mirroshandel
Gholamreza Ghassem-Sani

mirroshandel@ce.sharif.edu
sani@sharif.edu

Computer Engineering Department
Sharif University of Technology
Azadi Avenue, Tehran 11155-9517, Iran

Abstract
Automatic extraction of temporal relations between event pairs is an important task for
several natural language processing applications such as Question Answering, Information
Extraction, and Summarization. Since most existing methods are supervised and require
large corpora, which for many languages do not exist, we have concentrated our efforts to
reduce the need for annotated data as much as possible. This paper presents two different
algorithms towards this goal. The first algorithm is a weakly supervised machine learning
approach for classification of temporal relations between events. In the first stage, the
algorithm learns a general classifier from an annotated corpus. Then, inspired by the
hypothesis of one type of temporal relation per discourse, it extracts useful information
from a cluster of topically related documents. We show that by combining the global
information of such a cluster with local decisions of a general classifier, a bootstrapping
cross-document classifier can be built to extract temporal relations between events. Our
experiments show that without any additional annotated data, the accuracy of the proposed
algorithm is higher than that of several previous successful systems. The second proposed
method for temporal relation extraction is based on the expectation maximization (EM)
algorithm. Within EM, we used different techniques such as a greedy best-first search
and integer linear programming for temporal inconsistency removal. We think that the
experimental results of our EM based algorithm, as a first step toward a fully unsupervised
temporal relation extraction method, is encouraging.

1. Introduction
Much progress has been made in natural language processing (NLP) in recent years. Combining statistical and symbolic methods has played a significant role in these advances. As a
result, tasks such as part-of-speech tagging (Sgaard, 2011), parsing (Petrov & Klein, 2007),
and named entity recognition (Mikheev, Grover, & Moens, 1998) have been addressed with
satisfactory results. However, in some other tasks such as temporal information processing, which need a deeper analysis of meaning, the achieved results have not yet been as
satisfactory.
Temporal information is encoded in the textual description of events. Lately, the increasing attention to practical NLP applications such as question answering, summarization, and information extraction have resulted in a growing demand of temporal information
processing (Tatu & Srikanth, 2008). In question answering, one may expect the system to
answer questions such as when an event occurred, or what is the chronological order bec
2012
AI Access Foundation. All rights reserved.

fiMirroshandel & Ghassem-Sani

tween some desired events. In text summarization, especially in the multi-document type,
knowing the order of events is a useful source for correctly merging related information.
Construction of the TimeBank corpus in 2003 (Pustejovsky et al., 2003), provided the
opportunity of applying different machine learning methods to the task of temporal relation
extraction. However, it has been realized that even a six-class classification of temporal
relations is a very complicated task, even for human annotators (Mani, Verhagen, Wellner,
Lee, & Pustejovsky, 2006).
This paper presents two different approaches in which the need for annotated data in
temporal relation learning is reduced. The first approach is a weakly supervised machine
learning algorithm for classification of temporal relations between events. In the first stage,
the algorithm learns a general classifier from an annotated corpus. Then, inspired by the
hypothesis of one type of temporal relation per discourse, it extracts useful information
from a cluster of topically related documents for retraining of the model. By combining the
global information of such a cluster with local decisions of a general classifier, we propose a
novel bootstrapping cross-document classifier to extract temporal relations between events.
Our experiments show that without any additional annotated data, the accuracy of the
proposed algorithm is at least 7% higher than that of the state-of-the-art of statistical
methods (Chambers, Wang, & Jurafsky, 2007).
The second introduced approach is a novel usage of expectation maximization (EM) algorithm for temporal relation learning. This algorithm also employs Allens interval algebra
(Allen, 1984) for correction of predicted relations. For applying interval algebra, we utilize
two different approaches: 1) a heuristic search method and 2) integer linear programming
(ILP). We think that the experimental results of this EM based algorithm, as a first step
toward a fully unsupervised temporal relation extraction method, is encouraging.
The remainder of this paper is organized as follows: section 2 is about previous approaches to the temporal relation learning. Section 3 explains our first proposed method,
which is evaluated in section 4. The second algorithm is explained in section 5, and evaluated in section 6. Finally, section 7 includes our conclusions and some possible future
work.

2. Temporal Relation Learning
Assuming that we have access to the texts in which events and time expressions have been
appropriately tagged, two different tasks pertaining to temporal relation learning can be distinguished: 1) detecting whether there exist any relation between a given pair of events/time
expressions; 2) identifying the relation type for positive cases of the first task. The first
task is very hard to evaluate, because the annotators may ignore many plausible existing
relations while tagging the corpora (Mani et al., 2006). Accordingly, in this paper like other
existing research, we have only addressed the second task, which can be more specifically
defined as follows: For a given ordered pair of components (x1 , x2 ), where x1 and x2 are
annotated events and/or time expressions, a temporal relation classifier identifies the type
of relation ri that temporally links x1 to x2 . As it is shown in Figure 1, each temporal relation can be one of the fourteen types proposed in TimeML (Pustejovsky et al., 2003). For
example, in Powerful political pressures (event1 ) may convince (event2 ) the Conservative
government to keep (event3 ) its so-called golden share, which limits any individual holding to
126

fiUnsupervised Temporal Relation Learning between Events

	 
Figure 1: Different temporal relations in TimeML.

15%, until the restriction (event4 ) expires (event5 ) on Dec. 31, 1990 (time1 ). (taken from
document wsj 0745 of TimeBank, see Pustejovsky et al., 2003). The task is to automatically tag the relations between pairs (event1 , event2 ), (event3 , event5 ), (event5 , event4 ),
and (event5 , time1 ) with BEFORE, ENDED BY, ENDS, and IS INCLUDED, respectively
(see Figure 2). Since automatic extraction of just event-event relations is itself a difficult
task, in this paper, we have focused on this particular task, and left the detection of other
type of temporal relations such as event-time or time-time to future work.
There are many ongoing research focusing on temporal relation learning. Additionally,
there have been two important shared tasks on temporal information extraction: TempEval
2007 (Verhagen et al., 2007) and TempEval 2010 (Verhagen, Sauri, Caselli, & Pustejovsky,
2010). In TempEval 2007, there were three different tasks regarding temporal relations
classification between A) events and times within the same sentence; B) creation time of a
document and its events; and C) main (verb) events in adjacent sentences.
In TempEval 2010, there were six different tasks including A, B) Determining the time
expressions and events of input texts and specified features; and temporal relation classification between C) events and times within the same sentence; D) creation time of a document
and its events; E) main events in consecutive sentences; and F) two events where one event
syntactically dominates the other event.
Due to focusing on temporal relations between event pairs, task C of TempEval 2007
plus tasks E and F of TempEval 2010 are similar to the task that we tackle in this paper;
however, these tasks can be considered as special cases of ours. For instance, in task E of
TempEval 2010, only the event pairs from consecutive sentences are considered; whereas,
in our task the event pairs can be either from the same sentence or from any other two
sentences of the input text.
The research on temporal relation learning can be divided into different categories. In
this paper, we divide these efforts into three groups: 1) Statistical; 2) Rule-based, and 3)
127

fiMirroshandel & Ghassem-Sani

Hybrid, which are explained in the following sections.

	 
Figure 2: Temporal relations of the sentence Powerful political pressures (event1 ) may
convince (event2 ) the Conservative government to keep (event3 ) its so-called
golden share, which limits any individual holding to 15%, until the restriction
(event4 ) expires (event5 ) on Dec. 31, 1990 (time1 ). Bold arrows show relations
between event pairs.

2.1 Statistical Methods
In all statistical methods, a classification (or clustering) algorithm is employed over a number of tagged and/or extracted features of an input corpus. Maximum Entropy (Mani,
Wellner, Verhagen, & Pustejovsky, 2007; Derczynski & Gaizauskas, 2010), Support Vector
Machines (Chambers et al., 2007; Bethard & Martin, 2007; Hepple, Setzer, & Gaizauskas,
2007; Cheng, Asahara, & Matsumoto, 2007; Mirroshandel, Ghassem-Sani, & Khayyamian,
2009a, 2009b, 2011), Conditional Random Fields (Llorens, Saquete, & Navarro, 2010; Kolya,
Ekbal, & Bandyopadhyay, 2010), and Markov Logic Networks (UzZaman & Allen, 2010;
Ha, Baikadi, Licata, & Lester, 2010) are some of the statistical techniques that have been
applied to this problem.
MaxEnt is one of the first approaches to the temporal relation learning, which uses
maximum entropy classification algorithm (Mani et al., 2007). In this method, the classifier
assigns one of six different temporal relation types to each event-event or event-time pair.
The classifier relies on a number of features including modality, polarity, tense, aspect, and
the event class, which have been hand-tagged in the corpus. In addition to these features,
it also relies on pairwise agreement of two additional features: tense and aspect. We later
propose a new technique to improve MaxEnt. The results of comparing the proposed method
and MaxEnt are given in section 4.
128

fiUnsupervised Temporal Relation Learning between Events

USFD2 (Derczynski & Gaizauskas, 2010) is another method that employs maximum
entropy in solving tasks C and F of TempEval 2010. This method uses the same features
as MaxEnt plus some features related to the so-called signals of the text. USFD2 achieved
the second highest score in task C of TempEval 2010. However, its results on task F were
not satisfactory enough.
The state-of-the-art of the statistical methods is analogous to MaxEnt (Chambers et al.,
2007). It works in two consecutive stages and employs some event-event features in addition
to those used by MaxEnt. In this work, Support Vector Machines (SVM) are used for
classification. Similar results were reported for using a Naive Bayes classier instead of SVM.
Section 4 also includes the results of comparing this work with our proposed algorithm.
SVMs have been also used as a classification algorithm in several other research. CUTMP (Bethard & Martin, 2007) applied SVM for solving all three tasks of TempEval 2007.
It also used gold-standard TimeBank features for event and time expressions plus parts
of derived parse trees from the input text. CU-TMP first solves task B and then uses its
results to tackle tasks A and C.
USFD (Hepple et al., 2007) and NAIST-Japan (Cheng et al., 2007) were two other
participants of TempEval 2007 that used SVM for classification. In NAIST-Japan, the
task was defined as a sequence labeling model. The task is approached by using HMMSVM, relying on features from dependency-parsed trees and standard attributes of target
events/time expressions. The result of this system was slightly more than average in tasks A
and B, but less than average in task C. It was shown that extracted features from dependency
parsed trees were not so effective for task C, in contrast with tasks A and B. In USFD,
temporal relation learning is treated as a simple classification task (Hepple et al., 2007).
They used different classification algorithm from WEKA machine learning workbench (Hall
et al., 2009). In task C, SVMs have gained the best result among the participants of the
shared task.
In another work, a corpus of parallel temporal and causal relations was employed, and
SVMs were used to extract both types of relations (Bethard & Martin, 2008). Since existing
corpora provide no parallel temporal or causal annotations, 1000 conjoined event pairs were
annotated (Bethard & Martin, 2008; Bethard, 2007). It was shown that causal relation
information could be helpful in temporal relation extraction, too. It was also shown that
temporal relation information has mutually positive effects in causal relation extraction
(Bethard & Martin, 2008).
Bethard and his colleagues (2007a, 2007b) have applied SVM to classify event pairs in
which the first event is a verb and the second one is the head of a clausal argument of that
verb. They have used a combination of a number of event based features (e.g., tense and
aspect) and some syntactic features (e.g., a specific path through the parse tree). Their
reported results have shown a high accuracy for these specific event pairs.
There are also other algorithms which utilize grammatical information in SVM using
convolution tree kernels (Mirroshandel et al., 2009a, 2009b, 2011). It was shown that
grammatical aspects of the input text are rich sources of information for temporal relation
classification. Argument Ancestor Path Distance (AAPD) convolution tree kernel is the
most successful tree kernel that has been used in SVM classification. This kernel is similar
to the CollinsDuffy tree kernel (Collins & Duffy, 2001). The CollinsDuffy kernel effectively
counts the number of common subtrees between two comparing parse trees. In this kernel,
129

fiMirroshandel & Ghassem-Sani

all subtrees have the same importance, whereas in AAPD, different weighting functions are
used to compute the kernel value. Furthermore, in AAPD, the significance of subtrees are
measured using the distance from a so-called argument ancestor path (AAP). An AAP is
the ancestor nodes of an argument (event). An example of a node (NN) and the distance
between the node and an AAP is shown in Figure 3. In AAPD, the closer a node is to the
path, the less it is decayed by the weighting function. In other words, the nodes which are
located nearer to the path are more important than those farther away.
To improve the accuracy of AAPD, it was combined with some other kernels, which
were either linear or polynomial (Zhang, Zhang, Su, & Zhou, 2006). However, polynomial
composite kernels have shown superior results (Mirroshandel et al., 2009b). Section 4
includes the results of comparing AAPD and AAPD Polynomial kernels.

	 
Figure 3: A syntactic parse tree with two argument ancestor paths for events move and
resigned plus the distance of node NN from AAP of resigned.

Markov Logic Networks (MLN) is another classification algorithm, which have been
used by two participants of TempEval 2010: TRIPS & TRIOS (UzZaman & Allen, 2010)
and NCSU (Ha et al., 2010). TRIPS and TRIOS use a number of features produced by
a deep semantic parser, plus a few features extracted from target pairs (i.e., event/time
expression). In contrast with other participants, TRIPS and TRIOS operate on raw texts.
In other words, these systems do not use any tagged events/time expressions. They both
outperformed all other teams on two tasks (C and E). TRIOS also gained the second best results on the four remaining tasks. NCSU is another participant of TempEval 2010 that uses
MLN for classification. It relies on basic annotated features, syntactic features extracted
from generated parse trees, and lexical semantic features from two external resources (Ver130

fiUnsupervised Temporal Relation Learning between Events

bOcean and WordNet) (Ha et al., 2010). NCSU was applied to tasks C, D, E, and F in
two different settings: NCSU-indi and NCSU-joint. In NCSU-indi, an independent MLN
was trained for each task. On the other hand, a set of global formulae was also added to
NCSU-joint to ensure the consistency among classification decisions from four local MLNs
(one for each task). NCSU-indi achieved the best result in task F and the second best result
on task C.
One of the most successful participants of TempEval 2010 was TIPSem that is based on
Conditional Random Field (CRF) models for classification purpose (Llorens et al., 2010).
TIPSem employs different morphological, syntactic, and semantic features for building CRF
models. In Spanish, it achieved the best results in all tasks. In English, TIPSem achieved
the best results in Tasks B and D; and was one of the best systems in all other tasks.
JU CSE TEMP was another participant of TempEval 2010 that utilized CRF models for
temporal relation learning tasks (Kolya et al., 2010). The system needs only the goldstandard features of TimeBank for time expressions and/or events. In comparison with
TIPSem, JU CSE TEMP achieved weaker results, which shows the importance of feature
engineering in temporal relation learning.
There is another approach that applies different machine learning techniques to detect
intra-sentential events, and builds a corpus of sentences with two or more events in which
at least one event is triggered by a key time word (e.g., after, before, etc.). The classifier is
based on a number of syntactic and clausal ordering features (Lapata & Lascarides, 2006;
Bramsen, Deshpande, Lee, & Barzilay, 2006).
There exist a comprehensive study about statistical methods, which compares three
different interval based algebras in terms of classification accuracy, performance, and expressiveness power (Denis & Muller, 2010). There are also a few algorithms that exclusively
work on temporal relation classification between events and time expressions. One of such
algorithms employs cascaded finite-state grammars (for temporal expression analysis, shallow syntactic parsing, and feature generation) together with a machine learning component
capable of effectively using large amounts of unannotated data (Boguraev & Ando, 2005).
There is a group of statistical methods that rely on information of argument fillers (called
anchors) of every event expression as a valuable clue for recognizing temporal relations. In
these methods, by looking at a set of event expressions whose argument fillers have a similar
distribution, analogous event expressions are recognized. Algorithms such as DIRT (Lin &
Pantel, 2001), TE/ASE (Szpektor, Tanev, Dagan, & Coppola, 2004), and that of the Pekars
system (2006) are examples of this type of statistical method.
DIRT is an unsupervised method based on an extended version of the so-called distributional hypothesis (Lin & Pantel, 2001). According to this hypothesis, words that occur
in the same contexts are usually similar. Here, instead of words, the algorithm applies the
distributional hypothesis to certain paths of the dependency trees of a parsed corpus.
TE/ASE, too, is an unsupervised algorithm, which has two major phases. In the first
phase (called Anchor Set Extraction), the algorithm extracts similar anchors. Then, in the
second phase (called Template Extraction), the system extracts templates from the resulting
anchor sets. In the final part of the algorithm, some post-processing transformations are
applied to the extracted templates to remove inappropriate templates (Szpektor et al.,
2004).
131

fiMirroshandel & Ghassem-Sani

In Pekars approach (2006), co-occurrence of two verbs inside a locally coherent text is
used to extract some useful information. This method has three major steps. First, based
on the local discourse, it identifies several pairs of clauses as being related. Next, based
on those related clauses, it tries to create a number of templates of verb pairs by using
information such as syntactic behavior. In the last step, the algorithm scores and employs
those templates for relation extraction.
2.2 Rule-Based Methods
The common idea behind rule-based methods is to find some general patterns for classifying
temporal relations. In most of these works, rules (patterns) are manually defined.
Perhaps the simplest rule-based method is the one that was developed using a knowledge
resource called VerbOcean (Chklovski & Pantel, 2005). VerbOcean has a small number of
manually designed generic rules. The style of rules is in the form of * <Verb-X> * <VerbY> *. For example, there are rules such as to Verb-X and then Verb-Y, to Verb-X
and eventually Verb-Y, or to Verb-X and later Verb-Y for the happens-before relation
type; and also there are rules such as Verb-X even Verb-Y or Verb-Y or at least Verb-X
for the so-called strength relation type. After manually creating these rules, a number of
semantic relations (e.g., strength, antonymy, happens-before, etc.) between events can be
detected. Several heuristics were also employed to filter inappropriate relations (Chklovski
& Pantel, 2005).
There is another rule-based method for temporal relation learning focused on biomedical
texts (Mulkar-Mehta, Hobbs, Liu, & Zhou, 2009). It was shown that existing methods for
temporal relation learning were not effective for such texts. In this work, some specific
axioms (rules) were used to predict the temporal and causal relations. A pattern extraction
algorithm was employed to create the system rules in a semi-automatic manner.
XRCE-T, a participant of TempEval 2007, is a rule-based system that relies on syntactic
and semantic features (e.g., deep syntactic analysis and determination of thematic roles)
(Hagege & Tannier, 2007). XRCE-T was in fact used as a post-processing module of a
general purpose linguistic analyzer.
In another study, rules of temporal transitivity were used to increase the training set.
The test accuracy on this enlarged corpus showed some improvements (Mani et al., 2007).
Reasoning with pre-determined rules is another approach to the rules usage. In the work
of Tatu and Srikanth (2008), a rich set of axioms (rules) was created and used by a first
order logic based theorem prover to find a proof for each temporal relation by refutation.
A set of discourse rules was used in the algorithm of Muller and Tannier (2004) to
establish the possible relations between every two consecutive events of the input text.
These rules were based on tenses of the event verbs. Then a classical path-consistency
algorithm (Allen, 1984) was applied to the extracted relations of the first step.
2.3 Hybrid Methods
It has been shown that one can increase the accuracy of temporal relation classifiers by
merging some of discussed methods. For example in the work of Chambers and Jurafsky
(2008), local decisions generated by a statistical method were combined with two types of
implicit global rule-based properties. These properties included the transitivity rule (e.g., A
132

fiUnsupervised Temporal Relation Learning between Events

before B and B before C implies A before C), and time expressions normalization (e.g., last
month is before yesterday). The constraints were used to create a more densely-connected
network of events, and then a global state of consistency was enforced by incorporating the
constraints into an integer linear programming framework (Chambers & Jurafsky, 2008).
Integer linear programming with local classifiers was shown to be appropriate only for
cases in which the number of possible relations between events is restricted (Denis & Muller,
2011). It was suggested that a translation of constraints from temporal intervals to their endpoints can be used to handle a significantly smaller set of constraints. During translation,
temporal relations are preserved. This method was shown to have a rather high accuracy.
They also proposed a graph decomposition technique that can further improve the accuracy.
In another algorithm, which was spiritually similar to that of (Chambers & Jurafsky,
2008), instead of applying global constraints using integer linear programming, the so-called
Markov logic (ML) was used (Yoshikawa, Riedel, Asahara, & Matsumoto, 2009). Global
constraints can be easily captured through adding some weighted first order logic formulas.
It was shown that the problem can be solved by ML more easily and accurately than by
ILP.
WVALI is another hybrid system, which has an enhanced classification process by using some rules from a particular knowledge base (Puscasu, 2007). In this system, different
heuristics and temporal reasoning mechanism have been combined with statistical data extracted from the training corpus. WVALI achieved the best results in all tasks of TempEval
2007.
LCC-TE was another hybrid system of TempEval 2007. It combined different machine
learning models with human rules for temporal relation learning (Min, Srikanth, & Fowler,
2007). LCC-TE uses gold-standard features available in TimeBank, as well as a number of
derived and extended features such as grammatical and semantic features. The evaluations
on LCC-TE have shown acceptable results in all three tasks.

3. Bootstrapped Cross-Document Classification (BCDC)
In this section, a new method of extracting temporal relations between events is introduced.
We call this method Bootstrapped Cross-Document Classification (BCDC). The results of
experiments with BCDC show a significant improvement over previous work in terms of
accuracy (see Tables 6 and 7). We have used SVM with three different kernels in the
learning process. There are two novelties in our bootstrapping (self-training) method: 1) it
is an information retrieval based approach that extracts useful information exclusively from
related documents. 2) It builds a specific model for each test document. Before describing
BCDC, our motivation is briefly explained in the next section.
3.1 Motivation
In a regular corpus with heterogeneous documents, verbs, which often act as event triggers,
may have different senses in different documents. For example, event firing may have a
sense of shooting a gun in a document about army, whereas it may also have a sense of
ending someones job in a different document about a company. However, for a cluster of
topically-related documents, the distribution should be much less divergent. This motivated
us to apply the so-called one sense per discourse hypothesis (Yarowsky, 1995) to the
133

fiMirroshandel & Ghassem-Sani

problem of temporal relation classification, and extend the scope of discourse from a single
document to a cluster of topically related documents. Also inspired by another work that
proposed assumptions of one event trigger sense and one event argument role per discourse
(Ji & Grishman, 2008), we based our work on an analogous assumption, which we called
one type of temporal relation per discourse. In other words, we assume that similar event
pairs in different places of topically related documents are very likely to have the same
temporal relations. Although, as it is later explained, we have not explicitly employed this
assumption in our proposed algorithm, we have tried to verify the assumption by considering
temporal relations of the Opinion corpus (Mani et al., 2006). In this corpus, documents are
located in four different directories each having a specific topic. In our verification, we have
considered all documents within the same directory as being related. In other words, two
documents are considered as related documents if they are in the same directory (i.e.,
they have the same topic). To verify the assumption, we selected those event pairs that have
appeared more than once. In Opinion corpus, there are a total number of 2666 temporally
related event pairs (i.e., TLinks), out of which, only 994 pairs appeared more than once1 .
Table 1 shows the results of our verification. Supporting samples are those event pairs that
have appeared in two or more related documents with exact the same temporal relation.
Even if event pairs having different relations are from unrelated documents, they are also
regarded as the supporting samples. On the contrary, if event pairs having different relations
are from related documents, they are considered as contradictory samples. As it is shown in
Table 1, more than 95% of the samples have supported our assumption (i.e., one temporal
relation per discourse).
Supporting Samples
Contradictory Samples
Total

Count
942(95%)
52(5%)
994

Table 1: The distribution for assumption of one type of temporal relation per discourse
over the Opinion corpus.
As an example, in the following sentences, which have been taken from different documents of the same topic (i.e., Kenya Tanzania Embassy bombings), the event pair (blast
and kill) has IBEFORE temporal relation in all sentences:
Reports reaching here said a massive blast damaged the U.S. embassy in Nairobi ,
killing 40 people while wounding at least 1,000 people.
More than 100 people have been killed and more than 1,000 others wounded in the
blasts next to the U.S. embassies in Kenya and Tanzania on Friday.
In Dar es Salaam , she laid a wreath next to the crater left by the embassy blast that
killed 10 people.
1. Before counting the number of event pairs, we applied a lemmatizer to event words.

134

fiUnsupervised Temporal Relation Learning between Events

3.2 Feature Engineering
In BCDC, two types of features are used: basic and extra event-event features. Basic
features are simple features related to individual events and extra event-event features
are those extracted from two related events. In the next two sections, these features are
explained in more detail.
3.2.1 Basic Features
These are simple features extracted from events. For each event, there are five temporal
attributes, which are tagged in standard corpora: 1) tense; 2) grammatical aspect; 3)
modality; 4) polarity, and 5) event class. Tense and aspect define temporal location and
event structure; thus, they are necessary in any method of temporal relation extraction.
Modality and polarity specify non-occurring or hypothetical situations. The event class
shows the type of event. The range of values for these attributes is based on the work of
Pustejovsky et al. (2003), and is shown in Table 2. These attributes are either annotated
in the input corpus or can be automatically extracted by existing tools.
Attribute
Tense
Aspect
Modality
Polarity
Event Class

Range of values
none, present, past, future
none, prog, perfect, prog perfect
none, to, should, would, could, can, might
positive, negative
report, aspectual, state, I state, I action, perception, occurrence

Table 2: The range of values for five temporal attributes.
In addition to the five mentioned attributes, BCDC also employs the string of words
that constitute each event, their part of speech tags as well as a number of contextual features including pairwise agreement of tenses and aspects. Part of speech tags of events are
again either annotated in the corpora or can be determined by existing POS taggers. For
example, in sentence He succeeds James A. Taylor, who ..., succeeds is an event with
the following features:
[tense: present], [aspect: none], [modality: none], [polarity: positive], [event class: aspectual], [word: succeeds], [pos: verb]
3.2.2 Extra Event-Event Features
Extra event-event features are based on two related events and are automatically extracted
from the input text. In our case, there are three types of these features, defined as follows:
Event-Event parse tree: if both events are in the same sentence, the algorithm can
use the parse tree of the sentence to learn some useful syntactic properties such as domination. In a parse tree, event A dominates event B, if A is an ancestor of B. These properties
are not explicit features, but rather implicit properties which can be extracted and learned
by the SVM using appropriate tree kernels such as those proposed in the work of Mirroshan135

fiMirroshandel & Ghassem-Sani

del et al. (2009b). Parse trees can be extracted by a statistical parser and there is no need
for any Treebank.
Prepositional phrase: a preposition head is often an indicator of a temporal class.
Thus, we can use a new feature that indicates if an event is a part of a prepositional phrase.
This information can also be extracted from the parse trees. For example, in sentence I
saw him before the earthquake, the relation between events saw and earthquake can be
easily determined by the word before in the prepositional phrase before the earthquake.
Event-Event distance: it is based on the idea that the strength of the relationship
between two events is inversely related to the textual distance of those events. It means
that the relationship becomes weaker as the distance increases (and vice versa). Accordingly, intra- and inter-sentential events should be treated differently. We train two separate
models: one for the intra-sentential events and one for the inter-sentential ones.
3.3 Proposed Algorithm
BCDC applies a novel usage of bootstrapping to the classification of temporal relations
between events. It works in two main stages. In the first stage, using a standard corpus,
a general model is learned. Then in stage two, the general model is retrained for each test
document based on some related information. Figure 4 shows the flowchart of the proposed
algorithm, which is described in more detail in the following sections.
3.3.1 Stage One
In stage one, BCDC employs the discussed features extracted from a standard corpus to
train a general model for classification using SVM. At the end of this stage, we will have
a model for temporal relation classification. However, such models, which have also been
proposed before by other researchers, all have the problem of being too general. In other
words, such a model does not have any specific information about the particular domain
under consideration. To better deal with this problem, BCDC has an extra bootstrapping
phase of training.
3.3.2 Stage Two
In stage two, we retrain the general model produced in stage one, for each test document
with some related information. In order to achieve this goal, the bootstrapping phase of
BCDC proceeds according to the following steps:
Step 1: first of all, an unprocessed test document is randomly selected.
Step 2: then BCDC finds the top N documents that are topically related to the selected test document from a large unannotated corpus. The choice of related documents can
be made by the INDRI retrieval system (Strohman, Metzler, Turtle, & Croft, 2005). Note
that the mentioned large unannotated corpus is different from the training and test corpora.

136

fiUnsupervised Temporal Relation Learning between Events

	 
Figure 4: The flowchart of BCDC.

137

fiMirroshandel & Ghassem-Sani

Step 3: in this step, we extract events and required features from the related documents
found by INDRI. The events and specified features of section 3.2 can be automatically annotated by EVITA (Saur, Knippen, Verhagen, & Pustejovsky, 2005). Although some of
the events and/or features extracted by EVITA may be incorrect, our experimental results
show that they can still be very helpful. The extra event-event features and other required
features can be extracted by a POS tagger and a statistical parser.
Step 4: then by using the existing model, the temporal relations between only intrasentential event pairs of the related documents are predicted. Besides, a normalized measure
of confidence is computed for each relation. We have used SVM for our classification
purpose. Therefore, we have designed a confidence measure using SVM, as it is explained
below.
In SVM binary classification, positive and negative instances are linearly partitioned by
a hyper-plane (with maximum marginal distance to instances) in the original or a higher
dimensional feature space. In order to classify a new instance X, its distance to the hyperplane is computed and X is assigned to the class that corresponds to the sign of the computed distance. The distance between instance X and hyper-plane H, which can be either
a positive or a negative value, is supported by the support vectors X1 . . . Xl and computed
by equation 1 (Han & Kambert, 2006):
d(X, H) =

l
X

yi i Xi X T + b0

(1)

i=1

where yi is the class label of support vector Xk ; k and b0 are numeric parameters that
are automatically determined.
We have used one-versus-one case of multi-class classification with m classes, in which
a set of m  (m  1) / 2 hyper-planes (i.e., one hyper-plane for every class pair) denoted by
H is defined. The hyper-plane that separates class i and j is referred to as Hi,j . Hi is used
to denote a subset of m  1 hyper-planes of H that separates class i from the others. In
order to classify a new instance X, its distance to each hyper-plane Hi,j is computed. Then
X is assigned to class i or j. At the end of this process, for every instance X, each class i
has accumulated a certain number of votes, represented as Vi (X), which is the number of
times that the classifier has assigned instance X to class i. The final class of X, denoted
by C(X), will be the one with the highest number of votes.
In the process described above, it is easy to compute the confidence values based on the
distance measures of equation 1 (i.e., the closer a case is to the support vectors, the less it
is confident). More precisely, in the multi-class classification, we define the confidence of
instance X as the sum of its distances to all its class-separating hyper-planes:
fi
fi
fi X
fi
fi
fi
fi
(X) = fi
d(X, H)fifi
fiHHC(x)
fi

(2)

Based on equation 2, the larger value of (X) shows that X is more confident, and vice
versa.

138

fiUnsupervised Temporal Relation Learning between Events

Step 5: in this step, BCDC chooses the K most confident temporal relations of those
detected in step 4.
Step 6: we then retrain the SVM by injecting the temporal relations selected in step
5. It should be noted that for each test document, the original model is retrained by the
most confident relations from the documents related to only that test document and not
any other test documents.
the model is trained on only the original training data plus the most confident predicted
relations from the relevant documents for the current test document and not any of predicted relations for other test documents.
Steps 4-6 are repeated until one of the following two termination conditions will be satisfied: 1) there will be no more unselected temporal relation, or 2) a predefined number of
iterations will be reached.
Step 7: when the retraining phase of the general model for a selected test document
is finished, the temporal relations of the test document are classified based on the new
specifically retrained model.
Then, if there are still some unprocessed test documents, BCDC will start from step 1
again; otherwise the algorithm will terminate.
The fundamental idea of the second stage of BCDC is to obtain some document- and
cluster-wide statistics about the temporal relations between different types of events, and
then using this information to improve temporal relation identification.
As it was explained above, a specific model is learned for each test document, using a
number of unannotated text documents which are topically related to that test document
(i.e., bootstrapping phase). However, if some test documents are themselves topically related, their corresponding retrained models will be very similar. For the sake of efficiency,
we can run the bootstrapping phase for just one of such test documents, and then use the
same retrained model for the rest. In other words, we run steps 2 to 6 of BCDC just for one
member of a set of similar test documents, and for other members, we solely apply step 7.
As it was explained in the section 3.1, we do not explicitly use the assumption of one
type of temporal relation per discourse in any part of BCDC. However, in bootstrapping,
we somehow implicitly benefit from this assumption by seeking only topically related documents, which are more likely to include similar event pairs with identical temporal relations.

4. Experimental Results of BCDC
In this section, the specification of the employed corpora is briefly explained. Then, the
accuracy of BCDC is analyzed.
4.1 Characteristic of Corpora
We have used two standard corpora (i.e., TimeBank (v 1.2) and Opinion, see Mani et al.,
2006) in our experiments. TimeBank has 183 newswire documents with 64, 077 tokens, and
139

fiMirroshandel & Ghassem-Sani

Opinion has 73 documents with 38, 709 tokens. These two datasets have been annotated
based on the TimeML standard (Pustejovsky et al., 2003). As mentioned before, there
are fourteen temporal relation types (SIMULTANEOUS, IDENTITY, BEFORE, AFTER,
IBEFORE, IAFTER, INCLUDES, IS INCLUDED, DURING, DURING INV, BEGINS,
BEGUN BY, ENDS, ENDED BY) in the TLink class of TimeML. For the sake of reducing
the data sparseness problem, as many others (Mani et al., 2006; Tatu & Srikanth, 2008;
Mani et al., 2007; Chambers et al., 2007), we have used a normalized version of these
relation types including only six following relations:
SIMULTANEOUS
BEFORE

Original Relation
X AFTER Y
X IAFTER Y
X ENDED BY Y
X BEGUN BY Y
X IS INCLUDED Y
X DURING Y
X IDENTITY Y
X DURING INV Y

ENDS
IBEFORE

BEGINS
INCLUDES

Converted Relation
Y BEFORE X
Y IBEFORE X
Y ENDS X
Y BEGINS X
Y INCLUDES X
Y INCLUDES X
X SIMULTANEOUS Y
X INCLUDES Y

Table 3: The normalization process for temporal relation types.
For normalizing, the inverse relations are merged. These conversions are shown in the
Table 3. In the first six conversions, relations can be easily converted by swapping their
arguments. Relations IDENTITY and SIMULTAENOUS are collapsed, since IDENTITY
is a subtype of SIMULTANEOUS (i.e., two events are IDENTITY if they are SIMULTANEOUS and coreferential). Similarly, relations DURING INV and INCLUDES are also
collapsed because DURING INV is a subtype of INCLUDES (i.e., identical to the Allens
CONTAINS) based on the Allens interval algebra (Allen, 1984). It should be clear that by
using these conversions, no information is lost.
Relation Type
IBEFORE
BEGINS
ENDS
SIMULTANEOUS
INCLUDES
BEFORE
TOTAL

TimeBank
63
77
114
1304
588
1335 (38.35%)
3481

OTC
131
160
208
1528
950
3170 (51.57%)
6147

Table 4: The normalized TLink class distribution in TimeBank and OTC.
140

fiUnsupervised Temporal Relation Learning between Events

In our experiments, like some previous work (Mani et al., 2006; Chambers et al., 2007;
Chambers & Jurafsky, 2008), TimeBank and Opinion corpora have been merged into a single
corpus called Opinion TimeBank Corpus (OTC). Table 4 shows the normalized TLink class
distribution (only for Event-Event relations) over TimeBank and OTC. As it is shown,
relation BEFORE is the most frequent relation; thus it forms the majority class, and can
be used as a baseline of the experiments.
For comparison with some other methods, we also used the English part of the TempEval2 corpus. This part is based on TimeBank (Verhagen et al., 2010; Pustejovsky et al., 2003;
Boguraev, Pustejovsky, Ando, & Verhagen, 2007). However, all the TimeBank annotations
have been reviewed based on the guidelines of TempEval 2010 and the temporal relations
have been modified according to the specific types of the shared task.
Relation Type
BEFORE
AFTER
OVERLAP
BEFORE-OR-OVERLAP
OVERLAP-OR-AFTER
VAGUE
TOTAL

Task E
Training
403
279
652 (41.19%) 124
61
51
137
1583

Test
58
38
(48.63%)
9
6
20
255

Task F
Training
Test
600 (35.46%)
92
299
45
518
100 (33%)
111
55
89
11
75
0
1692
303

Table 5: The distribution of temporal relation types in TempEval-2 Corpus for Task E and
F.

There are two parts in this corpus: 1) the training part including 163 documents and
53, 450 tokens; and 2) the test part with 21 documents and 4, 848 tokens. There are six different temporal relation types: BEFORE, AFTER, OVERLAP, BEFORE-OR-OVERLAP,
OVERLAP-OR-AFTER, and VAGUE. Among six different tasks of TempEval 2010, we
just focused on tasks E and F, which are similar to the problem that we have tackled in this
paper. Tasks E and F are the only tasks which consider exclusively the relations between
two events. The distribution of temporal relation types for these tasks over the training
and test parts of the corpus is shown in Table 5. The majority classes have been underlined
in the table.
As it was discussed in section 3.3.2, for each text, we retrieve a number of topically
related texts using a public domain software called INDRI. In our experiments, these related
texts have been retrieved from the English part of TDT5 multilingual news text corpus2 . In
total, TDT5 consists of 407, 505 text documents in English (278, 109 documents), Mandarin
Chinese (56, 486 documents), and modern standard Arabic (72, 910 documents). It also has
250 different topics. Unlike previous TDT corpora, TDT5 does not contain any broadcast
news data; all sources are newswires.
2. TDT 2004: Annotation Manual, Available at http://www.ldc.upenn.edu/Projects/TDT2004.

141

fiMirroshandel & Ghassem-Sani

4.2 Experiments
We have used the LIBSVM java source for the SVM classification (Chang & Lin, 2011).
The EVITA system (Saur et al., 2005) has been used for event extraction. EVITA works
based on both linguistic and statistical information. In addition to event extraction, event
attributes (which were described in Table 2) can also be extracted by EVITA. We have also
used the Stanford NLP package3 for tokenization, sentence segmentation, part of speech
tagging, and parsing. The INDRI retrieval system (Strohman et al., 2005) has been employed to obtain related documents. INDRI is a language model based search engine that
provides a state-of-the-art text search engine. The English part of TDT5 has been indexed
by INDRI, and by using this search engine, the texts that are highly related to some specified
documents can be retrieved.
As it was mentioned earlier, we applied our algorithm to TimeBank, OTC, and TempEval 2010 Corpora. We randomly selected 20 documents (almost 10 percent of total
documents) of TimeBank as our development set. Based on several experiments on this development set and with different number of extracted related documents in step 2 of BCDC
(i.e., N), and number of most confident relations chosen in step 5 (i.e., K), we have set N
to 25 and K to 40.
On TimeBank and OTC, the results were evaluated by first excluding the 20 documents
of the development set and then measuring accuracy using the five-fold cross validation
method. However, for the corpus of TempEval-2, there was no need for cross validation,
because the training and test sets are predetermined, and we just reported the accuracy of
BCDC on the test set.
Table 6 shows the results of three different settings of the proposed algorithm against
several others over TimeBank and OTC. In this table, the baseline is the majority class for
event-event relations (i.e., the BEFORE relation) of the evaluated corpora. Manis method
is regarded as a successful statistical approach to temporal relation identification, which
exclusively uses gold standard features of events (Mani et al., 2007). Methods proposed
by Chambers and Mani are similar except that Chambers has also used a number of extra
features in a two step algorithm. His method is currently regarded as the state-of-the-art of
statistical approaches over TimeBank and OTC. To achieve a higher accuracy, he has also
used some extra resources such as WordNet (Chambers et al., 2007).
Argument ancestor path distance (AAPD) is an accurate convolution tree kernel which
only uses parse trees of event-event sentences for temporal relation classification (Mirroshandel et al., 2009b). AAPD polynomial is a composite kernel that combines a simple event
kernel and AAPD (Mirroshandel et al., 2009b). The mentioned simple event kernel is a linear kernel that exclusively uses the same features as that of Manis method (Mirroshandel
et al., 2009b). AAPD and AAPD polynomial kernels were designed to be applied only to
the event pairs that are within the same sentence. Accordingly, the relations of TimeBank
and OTC were split into two parts: 1) relations between intra-sentential event pairs, and
2) relations between inter-sentential event pairs. Then these kernels were applied only to
the first part and for the second part, we just used simple event kernel (i.e., Manis kernel).
In Table 6, the results reported for AAPD and AAPD polynomial kernel are in fact the
outcome of merging the partial results from these two parts.
3. Available at http://nlp.stanford.edu/software/index.shtml

142

fiUnsupervised Temporal Relation Learning between Events

Method
Baseline
Chambers
Mani (Event Kernel + Basic Features)
Classic Bootstrapping + Event Kernel + Basic Features
BCDC + Event Kernel + Basic Features
AAPD Kernel + Extra Event-Event Features
Classic Bootstrapping + AAPD Kernel + Extra Event-Event
Features
BCDC + AAPD Kernel + Extra Event-Event Features
AAPD Polynomial Kernel + Basic Features + Extra EventEvent Features
Classic Bootstrapping + AAPD Polynomial Kernel + Basic
Features + Extra Event-Event Features
BCDC + AAPD Polynomial Kernel + Basic Features +
Extra Event-Event Features

TimeBank
Corpus
38.35
59.43
50.97
53.21
59.71
54
57.98

OTC
Corpus
51.57
65.48
62.5
63.12
65.19
63.44
64.53

62.56
57.02

66.29
65.95

59.83

66.55

66.18

68.07

Table 6: The accuracy of proposed methods on event-event temporal relation classification
over TimeBank and OTC.

BCDC + Event Kernel + Basic Features is our bootstrapped algorithm, which only
uses basic features, mentioned in section 3.2.1, by applying a simple event kernel (Mirroshandel et al., 2011). In BCDC + AAPD Kernel + Extra Event-Event Features, we
utilized extra event-event features in AAPD kernel. Third setting (BCDC + AAPD Polynomial Kernel + Basic Features +Extra Event-Event Features) uses AAPD Polynomial
kernel to combine all basic and extra event-event features.
For better comparison, we also applied a classic bootstrapping method with the same
SVM kernels and features as that of BCDC. For reporting these results, the initial model was
trained on a standard corpus (i.e., like stage one of BCDC). Then, in an iterative manner,
most confident samples of all documents (rather than just related documents) were used to
retrain the model. Note that in this case, there is no need to the process of retrieving related
documents, and only one model is learned for all test documents. In order to find the best
value for K (i.e., number of most confident samples) in the classic bootstrapping method,
we performed several different experiments on the mentioned development set. Incidentally,
our experiments showed that here, too, K should be set to 40.
As Table 6 indicates, BCDC + AAPD Kernel + Extra Event-Event Features and
BCDC + AAPD Polynomial Kernel + Basic Features + Extra Event-Event Features both
show a significant improvement over the state-of-the-art method (i.e., Chambers method).
Comparison between BCDC and classical bootstrapping shows the effectiveness of the proposed idea of extracting the retraining samples only from related documents.
The improvement over TimeBank is more considerable than that of OTC. It seems that
different distributions of temporal relations in the two corpora has caused the difference
143

fiMirroshandel & Ghassem-Sani

between these improvements. As it is shown in Table 4, in OTC, the majority class (i.e.,
BEFORE relation) has a larger part of the whole corpus. This causes the learning algorithm
to become biased towards the BEFORE relation, and thus the correct prediction of other
relations becomes harder. On the contrary, in TimeBank, the distribution is less biased and
thus BCDC has shown more improvement on this corpus.
Method 1

Method 2

BCDC + Event Kernel + Basic Features
BCDC + AAPD Kernel + Extra Event-Event Features
BCDC + AAPD Polynomial
Kernel + Basic Features +
Extra Event-Event Features
BCDC + Event Kernel + Basic Features

Mani (Event Kernel + Basic
Features)
AAPD Kernel + Extra EventEvent Features
AAPD Polynomial Kernel
+ Basic Features + Extra
Event-Event Features
Classic Bootstrapping +
Event Kernel + Basic Features
Classic Bootstrapping +
AAPD Kernel + Extra
Event-Event Features
Classic Bootstrapping +
AAPD Polynomial Kernel
+ Basic Features + Extra
Event-Event Features
Chambers

BCDC + AAPD Kernel + Extra Event-Event Features
BCDC + AAPD Polynomial
Kernel + Basic Features +
Extra Event-Event Features
BCDC + Event Kernel + Basic Features
BCDC + AAPD Kernel + Extra Event-Event Features
BCDC + AAPD Polynomial
Kernel + Basic Features +
Extra Event-Event Features

P-Value
on TimeBank
0.0134

P-Value
on OTC

0.0296

0.0383

0.0212

0.0422

0.0311

0.0514

0.0299

0.0441

0.0402

0.0491

0.0765

0.0878

Chambers

0.0503

0.0487

Chambers

0.0431

0.0397

0.0476

Table 7: The statistical significance test results on our proposed methods.
For testing statistical significance, we applied a type of stratified shuffling, which is a
kind of compute-intensive randomized test. The null hypothesis (i.e., the two models that
produced the observed results are the same) was tested by randomly shuffling the generated
output for each event pair between the two models and then re-computing the evaluation
metrics (i.e., accuracy in this case). If the difference in a particular metric after a shuffling is
equal to or greater than the original observed difference in that metric, then a counter (nc)
for that metric is incremented. Ideally, we should perform all 2n possible shuffles, where
n shows the number of test cases (i.e., event pairs). But, in our case, this is impractical
because n is a rather large number. Therefore, as many others, we have tried only 10, 000
144

fiUnsupervised Temporal Relation Learning between Events

iterations (nt). After finishing all iterations, the p-value (likelihood of incorrectly rejecting
the null hypothesis) is simply calculated by (nc + 1)/(nt + 1) (Yeh, 2000). Table 7 shows the
result of the significance test on our proposed methods. In this test, each proposed method
was compared with its relevant method.
As it is shown in Table 7, majority of the methods passed the test (the p-value is less
than 0.05). There are only four exceptions in which the p-value is slightly greater than 0.05.
Table 8 shows the accuracy of BCDC on the English part of the corpus used in TempEval
2010 for tasks E and F. JU-CSE, NCSU-indi, NCSU-joint, TIPSem, TIPSem-B, TRIOS,
and TRIPS are participants of the TempEval 2010 shared task (Verhagen et al., 2010). The
other methods are the same as in Table 6. AAPD kernel can only be applied to event pairs
within the same sentence. Therefore, we are unable to apply it to task E. For inter-sentential
event pairs, AAPD Polynomial kernel is almost similar to simple event kernel, because it
cannot use the syntactic parse trees, which are appropriate sources of information.
Method
Baseline
JU-CSE
NCSU-indi
NCSU-joint
TIPSem
TIPSem-B
TRIOS
TRIPS
Event Kernel + Basic Features
BCDC + Event Kernel + Basic Features
AAPD Kernel + Extra Event-Event Features
BCDC + AAPD Kernel + Extra Event-Event Features
AAPD Polynomial Kernel + Basic Features + Extra
Event-Event Features
BCDC + AAPD Polynomial Kernel + Basic Features
+ Extra Event-Event Features

Task E
49
56
48
51
55
55
56
58
38.02
44.35


38.54

Task F
33
56
66
25
59
60
60
59
33.23
38.44
40.71
47.20
43.51

45.62

50.41

Table 8: The accuracy of proposed methods on tasks E and F of TempEval 2010 shared
task.
As it can be seen in Table 8, although BCDC has shown some improvement in the
accuracy of temporal relation identification (i.e., in comparison with our base methods),
it is generally weaker than almost all the participants of TempEval 2010. We think this
weakness is due to the restricted feature set that have been used in BCDC. In other words,
majority of participants of TempEval 2010 have used richer feature sets of different levels
(e.g., lexical, syntactic, and semantic), while we have just used simple event features (plus
a few syntactic features only for task F). We think but have not verified yet that with a
richer set of features, BCDC will produce more successful results on TempEvals tasks, too.
Besides, we think replacing our base method for a more successful method such as TipSem
145

fiMirroshandel & Ghassem-Sani

or TRIPS, can make BCDC competitive with participants of TempEval 2010. However, to
show this, we first need to find an appropriate confidence measure for step 4 of BCDC4 ,
which requires further investigation and is one of our directions in future research.

	 
Figure 5: The effects of utilizing related documents vs. randomly selected documents on
accuracy of BCDC over TimeBank and OTC.

4.3 Analysis
As it can be seen in Tables 6 and 8, BCDC has shown a substantial improvement over
several different methods in terms of accuracy and without using any extra annotated data.
Bootstrapping by using a number of related documents have the following positive effects:
1) By knowing the relation between events, we can better predict the relation types
between analogous events, which may appear in related documents.
2) In related documents, the number of sentences with similar patterns will increase,
and the tree kernels can extract more confident information from the parse trees. Thus in
4. It should be noted that our proposed confidence measure is just useful for SVM classification technique.

146

fiUnsupervised Temporal Relation Learning between Events

this way, SVM can be more informative.
3) The used corpora are rather small with few examples for each relation. This data
sparseness problem can affect the performance of any temporal relation identification method.
In BCDC, retrieving related documents and extraction of new temporal relations of these
documents can increase the number of relations and improve its performance by alleviating
the data sparseness problem.
One remaining question is what is the impact of choosing related documents?. In other
words, what if we randomly choose a number of unrelated documents in the bootstrapping
phase of BCDC. To show the effectiveness of the idea of using related documents, we have
repeated our experiments with N = 25 (i.e., the same as original BCDC) randomly selected
documents. The results of these experiments are shown in Figure 5. As it is shown,
although randomly selected documents have slightly improved the base methods, however,
the improvement is not comparable with that of using related documents.

5. Using EM for Temporal Relation Learning (EMTRL)
Since supervised and even semi-supervised methods need annotated corpora, which for many
languages and/or domains do not exist, here, we propose an unsupervised algorithm for the
temporal relation learning problem. Due to the encouraging results of the expectation
maximization (EM) algorithm in other unsupervised tasks of natural language processing
such as unsupervised grammar induction (Klein, 2005), unsupervised anaphora resolution
(Cherry & Bergsma, 2005; Charniak & Elsner, 2009), and unsupervised coreference resolution (Ng, 2008), we decided to evaluate EM in unsupervised temporal relation extraction.
Currently, there is no reported work in temporal relation extraction based on EM. In fact,
there has not yet been any attempt towards an unsupervised approach to temporal relation
extraction. Here, we explain how EM can be successfully applied to the task of temporal
relation extraction and show that the performance of EM is encouraging in this task. Before
that, we first introduce the definitions and notations that will be later used in subsequent
sections.
5.1 The EM Algorithm
EM is a general algorithm for maximum likelihood estimation (MLE) (Dempster, Laird, &
Rubin, 1977). This algorithm can be used when we deal with incomplete information. As
it was mentioned before, in temporal relation learning, the task is to determine the type of
temporal relation r that is between two events e1 and e2 . In this algorithm, context means
the sentence (or sentences) containing a pair of events.
5.2 The Proposed Model
Let us call the new proposed algorithm EMTRL, which stands for EM based temporal
relation learning. EMTRL operates at the corpus level, inducing valid temporal clustering
for all event pairs of a given corpus. More specifically, EMTRL induces a probability
distribution to maximize P (corpus) (the probability of the corpus). To easily incorporate
147

fiMirroshandel & Ghassem-Sani

linguistic constraints, corpus is represented by its event pairs (ei ej ). We assume event pairs
are independent:
Y

P (corpus) =

P (ei ej )

(3)

ei ej  corpus

We can rewrite P (ei ej ) so that it uses a hidden variable T Ci
pair ei ej ) that influences the observed variables (ei ej ):
X

P (ei ej ) =
T Ci

j

j

(temporal class for event

P (ei ej , T Ci j )

(4)

 possible temporal classes

The probability P (ei ej , T Ci j ) can be rewritten as:
P (ei ej , T Ci j ) = P (ei ej | T Ci j )P (T Ci j )

(5)

For inducing temporal relations, EMTRL runs EM on this model. We use a uniform
distribution over P (T Ci j ). It is clear that if we could choose a more informative prior
distribution P (T Ci j ), it would have some benefits like having a better handle on the skewness of the distribution. In some other applications of EM, there are settings for this prior
distribution. However, in the problem of temporal relation learning, there cannot be any
other prior distribution except uniform distribution; because here, all temporal relation
types would seem equal to the learner.
If we expand equation 5, each pair ei ej can be represented by its features, which can
be potentially used for determining the temporal relation type between events ei and ej .
Therefore, P (ei ej | T Ci j ) can be rewritten using equation 6:
P (ei ej | T Ci j ) = P (ei e1j , ei e2j , ... ei ekj | T Ci j )

(6)

where ei elj is the value of the lth feature of ei ej . These features, which are similar to
those mentioned in the work of Chambers and Jurafsky (2008), are listed in Table 9.
To reduce the data sparseness problem and improve the probability estimation, the conditional independence is assumed for these features value generation. We only assume that
tense and aspect are dependent (i.e., tensei and aspecti ), because tense and aspect define
temporal location and event structure, and thus considering these features together can be
a rich source of information in any temporal relation extraction system. By conditional
independence assumption, the value of P (ei ej | T Ci j ) can be rewritten as:
P (ei ej | T Ci j ) =

Y

P (ei elj | T Ci j )

(7)

all f eatures l

These probabilities (i.e. P (ei elj | T Ci j ) ) are regarded as the parameters of our proposed
model. Because using them, the likelihood of different temporal classes can be determined.
Based on the features in Table 9 and different temporal classes, P (ei elj | T Ci j ) can be
defined. Four examples of such probabilities are shown below:
 P (class(ei ) = OCCU RREN CE AN D class(ej ) = P ERCEP T ION  | T Ci j =
BEF ORE)

148

fiUnsupervised Temporal Relation Learning between Events

Feature
W ord1 & W ord2
Lemma1 & Lemma2
Synset1 & Synset2
P OS1 & P OS2
Event Government V erb1 &
V erb2
Event Government V erb1 &
V erb2 POS
Auxiliary
Class1 & Class2
T ense1 & T ense2
Aspect1 & Aspect2
M odality1 & M odality2
P olarity1 & P olarity2
Tense Match
Aspect Match
Class Match
Tense Pair
Aspect Pair
Class Pair
POS pair
P reposition1
P reposition2
Text order
Dominates
Entity Match

Description
The text of first and second events
The lemmatized first and second events heads
The WordNet synset for first and second events heads
The POS of the first and second events
The verbs that govern the first and second events
The verbs POS that govern the first and second events
Any auxiliary adverbs and verbs that modifies the governing verbs
The Class of the first and second events
The tense of the first and second events
The aspect of the first and second events
The modality of the first and second events
The polarity of the first and second events
If two events have the same tense or not
If two events have the same aspect or not
If two events have the same class or not
Pair of two events tense
Pair of two events aspect
Pair of two events class
Pair of two events POS
If first event is in a prepositional phrase or not
If second event is in a prepositional phrase or not
If the first event occurs first in the document or not
If the first event syntactically dominates second event
or not
If an entity as an argument is shared between two
events

Table 9: The features of events which are used in EMTRL for temporal relation learning.

149

fiMirroshandel & Ghassem-Sani

 P (ei dominates ej | T Ci

j

= AF T ER )

 P (T ense(ei ) = P AST  AN D T ense(ej ) = P AST  AN D Aspect(ei )
N ON E AN D Aspect(ej ) = P ROGRESSIV E | T Ci j = OV ERLAP )
 P (P OS of ei = V  AN D P OS of ej = N  | T Ci

j

=

= AF T ER )

5.3 The Induction Algorithm
To induce a temporal clustering on a corpus, EM was applied to our proposed model. In
EMTRL, the corpus (i.e., event pairs) and the temporal clustering T C are respectively the
observed and unobserved (the hidden) random variables. The EM algorithm includes two
main steps of expectation (E) and maximization (M), which in our task can be defined in
the following way to iteratively estimate the parameters of the model (i.e., P (ei elj | T Ci j )):
E-step: Fix current parameters of the model, and assign a probability, P (T Ci j | ei ej ),
to each possible temporal class for event pairs (ei ej ) of the corpus. This probability can
be computed by following equation:
P (ei ej , T Ci j )
P (ei ej )
We can rewrite equation 8 by using equations 4, 5, 7:
P (T Ci

P (T Ci

j

j

| ei ej ) =

l
all f eatures l P (ei ej | T Ci j )
Q
0
 possible temporal classes P (T Ci j ) all f eatures l P (ei

P (T Ci j )

| ei ej ) = P

(8)

Q

elj | T Ci0 j )
(9)
Using equation 9, for each event pair (ei ej ), the temporal relation type (temporal class)
with the highest probability is selected. These relations will be later used in the M-step to
update the parameters of the model.
T Ci0

j

M-step: By fixing determined temporal relations in E-step, the parameters of the
model, P (ei elj | T Ci j ), are updated in this step. For achieving this goal, different optimization algorithms such as conjugate gradient can be used. However, these algorithms are
slow and costly. In addition, it is difficult to smooth these methods in a desired manner.
Therefore, we have used the relative frequency method for re-estimation of the parameters,
using equation 10:
P (ei elj | T Ci j ) =

N (ei elj , T Ci j )
N (T Ci j )

(10)

where N () counts the number of times that given items or joint items have appeared
in the corpus. For example, updating probability P (ei dominates ej | T Ci j = AF T ER)
can be done by dividing N (ei dominates ej , T Ci j = AF T ER) (i.e., number of times
that ei dominates ej and the temporal relation between ei and ej is AFTER) by N (T Ci j =
AF T ER) (i.e., number of times that relation between event pairs in the corpus is AFTER).
150

fiUnsupervised Temporal Relation Learning between Events

Steps E and M are repeated until one of the following termination conditions will be
satisfied: 1) a predefined number of iterations will be reached, or 2) there will be no more
changes in P (ei elj | T Ci j ). In practice, EMTRL is usually stopped after 30 predefined
iterations, while final behavior had been apparent after 15  22 iterations.
After finishing the training phase, the temporal relation (T Ci j ) for requested event
pairs ei ej can be determined using the following equation:
T Ci

j

= arg maxT C 0

 possible temporal classes P (T C

0

| ei ej )

(11)

Now, the EM algorithm can begin at either the E-Step or the M-step. We start the
induction algorithm at the M-step. It is clear that parameters of the model are not available
in the first iteration of EM. Instead, an initial distribution over temporal clustering can be
used. There is an important question: how one should initialize this distribution?
Initialization is an important task in EM, because EM only guarantees to find a local
maximum of likelihood. The quality of such a local maxima is highly dependent on the
initial starting point. We tested three different ways of initialization:
1) Random Initialization: a uniform distribution over all temporal clustering was
used; therefore, all temporal clustering in the first step had equal probability.
2) 10% Supervised Initialization: we used a small part of a labeled corpus (10% of
each relation type) for this task. Relations were selected randomly.
3) Rule-based Initialization: we used specific rules for initial estimation of temporal relation types and used this initial estimation for computing parameters of the model.
These rules were the combination of the so-called GTag rules (Mani et al., 2006), VerbOcean (Chklovski & Pantel, 2005), and rules derived from certain signal words (e.g., on,
during, when, and if) of the text. GTag contains 187 syntactic and lexical rules for
inferring and labeling temporal relations between event, document time, and time expressions. Out of these rules, 169 are between event pairs, which were utilized in EMTRL.
These 169 rules are either between event pairs of the same sentence or between two main
events of two consecutive sentences. An example of a GTag rule is shown below; other rules
are accessible from the Blinker part of the TARSQI toolkit5 .
if conjBetweenEvents = Y ES &&
isT heSameSentence = T RU E &&
event1 .class = (OCCU RREN CE|P ERCEP T ION |ASP ECT U AL|I ACT ION ) &&
event2 .class = ST AT E &&
event1 .tense = P AST &&
event2 .tense = P AST &&
event1 .aspect = N ON E &&
event2 .aspect = P ERF ECT &&
event1 .pos = V ERB &&
event2 .pos = V ERB
5. Available at http://www.timeml.org/site/tarsqi/index.html

151

fiMirroshandel & Ghassem-Sani

Then
relation(event1 , event2 ) = AF T ER

VerbOcean contains lexical rules between two verbs, which can be mined using some
lexical and syntactic patterns. The relation between verb pairs can be one of different semantic relations such as strength, enablement, antonymy, similarity, and happens-before.
We extracted 4, 205 happens-before rules from VerbOcean. Two examples of these rules are
shown below:
announce [happens-before] postpone :: 12.844086
review [happens-before] recommend :: 9.049530

Each rule contains two verbs, their relation, and the strength value of the relationship.
For example, the second rule shows relation happens-before between review and recommend with strength of 9.049530. We also designed 23 other rules based on some signal
words such as before, on, when. These rules are in the GTag format. An example of
this group of rules is given below:
if isT heSameSentence = T rue &&
signal = bef ore &&
signalBetweenT woEvents = T rue
Then
relation(event1 , event2 ) = bef ore

Like many other statistical NLP tasks, smoothing is vital here to alleviate the problem of
data sparseness. In particular, in the first few iterations, much more smoothing is required
than in later iterations. In our experiments, we used simply the add-1 smoothing technique
in computing equation 10.

6. Experimental Results of EMTRL
Like our experiments with BCDC, TimeBank and OTC were also used in the experiments
with EMTRL. However, in order to simplify the task, we used a different normalized version
of these corpora, which contained only the three following temporal relations:
BEFORE

AFTER

OVERLAP

The main reason for this simplification in EMTRL was that reducing the level of supervision in the task of temporal relation learning makes it an even more difficult task, which
is itself already considered to be a hard one (Mani et al., 2006). To normalize these corpora
and reduce the number of relation types to three, we adopted the same normalization approach like some previous work (Bethard et al., 2007b), BEFORE and IBEFORE relations
were merged into only BEFORE relations. Similarly, the AFTER and IAFTER relations
should also be merged into AFTER relations. All the remaining ten relation types were
collapsed in OVERLAP relations. Table 10 shows the converted TLink class distribution
over TimeBank and OTC.
152

fiUnsupervised Temporal Relation Learning between Events

Relation Type
BEFORE
AFTER
OVERLAP
Total

TimeBank Corpus
706
692
2083 (59.83 %)
3481

OTC Corpus
2369
1073
2792 (44.79 %)
6234

Table 10: The converted TLink class distribution in TimeBank and OTC.
Beside TimeBank and OTC, the performance of EMTRL has been also evaluated on
tasks E and F of TempEval-2 corpus. The tasks and relations distribution are the same as
those shown in Table 5.
6.1 Results and Discussions
In our experiments, the baselines were the majority class of event pair relations in the
employed corpora (i.e., OV ERLAP in both corpora). Note that the Manis method is
in fact supervised, which exclusively uses gold-standard features (Mani et al., 2007). The
Chambers method is similar to Manis, except that it also uses some external resources such
as WordNet (Chambers et al., 2007). Here, the result of our implementation of Mani and
Chambers methods are different from their reported results, because, as it was explained
before, we only considered three temporal relation types while in their reported experiments,
there were six relation types.
In Table 11, in addition to the results of employing EMTRL with three different initializations, we have also reported the results of these initializations as stand-alone classifiers.
For Random Initialization and EMTRL + Random Initialization, a question that may arise
is how these methods can determine the label of different classes. In fact, these methods
can only distinguish three different classes (Class1 , Class2 , and Class3 ). Among different possible ways that these unlabeled classes can be mapped to BEF ORE, AF T ER, or
OV ERLAP , we choose the mapping in which the similarity between predicted and annotated temporal relations is maximized.
Method Type
Baseline
Mani
Chambers
Random Initialization
EMTRL + Random Initialization
10% Supervised Initialization
EMTRL + 10% Supervised Initialization
Rule-based Initialization
EMTRL + Rule-based Initialization

TimeBank Corpus
59.83
61.55
66.79
35.99
40.92
39.33
48.31
38.92
47.86

OTC Corpus
44.79
60.58
62.94
37.29
43.02
41.14
49.34
41.03
48.78

Table 11: The accuracy results of different methods on TimeBank and OTC.
153

fiMirroshandel & Ghassem-Sani

Considering the unsupervised nature of EMTRL, the results of Table 11 can be encouraging. As it is shown in the table, TimeBanks baseline is well above that of OTC. That
is because TimeBank is highly biased towards OVERLAP. Accordingly, it is more difficult
for learning methods to pass the baseline of TimeBank. The performance of the Manis
method, which is a fully supervised approach, is only slightly over this baseline. In this
case, EMTRLs accuracy is considerably below the baseline. However, in the case of OTC,
its performance has passed the baseline.
As it is shown in Table 11, EMTRLs accuracy in all three different initializations,
have been respectively superior to that of the stand-alone counterparts. The statistical
significance of all those results in this table that shows the superiority of EMTRL over the
baseline (i.e., in the case of OTC) or the stand-alone initializations (i.e., both corpora) have
been verified by the stratified shuffling test with significance level  = 0.05.
Table 11 shows that the best accuracy belongs to the Chambers method. However, it
should be noted that this method currently has the best-reported results over TimeBank
and OTC among all supervised temporal relation extraction methods.
Table 11 also shows that EMTRL + Randomized Initialization has not been efficient in
either corpora. It may be due to the fact that randomized initialization in this very hard
problem causes some divergence in the probability distribution. On the other hand, two
other initializations have shown satisfactory results in tackling the problem. This implies
that initialization is a critical factor in EMTRL, and even little source of supervision can
be crucial for achieving satisfactory results.
Method Type
Baseline
NCSU-indi
TRIPS
Random Initialization
EMTRL + Random Initialization
10% Supervised Initialization
EMTRL + 10% Supervised Initialization
Rule-based Initialization
EMTRL+ Rule-based Initialization

Task E
49
48
58
24.75
27.92
26.35
32.20
27.17
32.76

Task F
33
66
59
19.11
22.33
23.77
26.29
23.64
27.03

Table 12: The accuracy results of different methods on tasks E and F over TempEval-2
Corpus.

Table 12 shows the results of applying EMTRL to the corpus of TempEval 2010. In
comparison with the accuracy of kernels in Table 8, EMTRL could achieve encouraging
results. In this case, EMTRLs accuracy in all three different initializations, have also been
respectively superior to that of the stand-alone counterparts. TRIPS and NCSU-indi are
the most successful supervised systems in tasks E and F of TempEval 2010, respectively
(Verhagen et al., 2010).
154

fiUnsupervised Temporal Relation Learning between Events

6.2 Inconsistency Removal
Since in a pair-wise relation learning system, the relation between each pair of events is
predicted without considering its impact on the relations of other event pairs, system may
encounter some inconsistencies among predicted relations. This may happen after selecting
temporal relations by equation 9 in E-step. It can also happen in finding final class labels
by equation 11. Figure 6 shows an example of an inconsistent relation between events A,
B, and C:

	 

Event	 
B

	 A 	 	 A fter	 	 B

	 B 	 A fter	 C

Event	 A

Event	 C
	 A 	 	 B efore	 C

Figure 6: A contradiction in temporal relations between three events A, B, and C.

There are several ways of eliminating such inconsistencies (Mani et al., 2007; Tatu &
Srikanth, 2008; Chambers & Jurafsky, 2008). In this work, we have used two different
approaches: a greedy best-first search strategy and an Integer Linear Programming (ILP)
based method. More details about both approaches are given next.

6.2.1 Greedy Best-First Search Strategy
In order to detect possible inconsistencies between predicted relations, we first build a graph
for each text, where each node corresponds to an event, and an edge represents a temporal
relation between corresponding events. Then, any existing contradiction among connected
nodes of each graph can be discovered by applying a set of rules (i.e., 640 rules) based on
the Allens interval algebra (Allen, 1984). As an example, consider the following three rules:
 bef ore(x, y) && bef ore(y, z) 
 bef ore(x, z)
 af ter(x, y) && bef ore(z, y) 
 af ter(x, z)
 af ter(x, y) && includes(y, z) 
 af ter(x, z)
The inconsistent relations of each graph is stored in a sorted list named SL, based on a
computed confidence score (i.e., P (T Ci j | ei ej ) of equation 9). Thus, in SL, the first and
the last elements are the most and the least confident relations, respectively.
The algorithm starts from the first relation of SL, and pops off this relation and adds
it to another list named F L. After adding a new relation to F L, the algorithm verifies the
consistency among relations of F L. If the new relation introduces an inconsistency, it will be
155

fiMirroshandel & Ghassem-Sani

replaced by the next confident relation between its corresponding events. This replacement
may be repeated until that the new relation will be consistent with other relations existing
in F L. When there are no more contradictions in F L, the algorithm will move the next
element of SL to F L. These operations are iterated until there will remain no more relations
in SL. The resultant consistent relations in F L can then be used in subsequent M-step or
in the final result of EM.
6.2.2 The Integer Linear Programming (ILP)
In our second approach, we cast the task of finding most probable temporal relations as an
optimization problem. In contrast with the previous method, this approach, which is based
on an integer linear programming (ILP) framework, finds an optimal solution based on the
parameters of the model, P (ei elj | T Ci j ). This method is similar to that of Chambers and
Jurafsky (2008).
In this ILP framework, for each event pair (ei , ej ), there is a relation type M from ei
to ej denoted by T Ri jM . The objective function of the framework is defined as follows:
!

max

X X
i j > i

X

(Pi

jM

T Ri

jM

+ Pj

iM

T Rj

iM )

(12)

M

where (Pi jM (i.e., P (M | ei ej ) of equation 8) is the probability of the temporal relation
of type M from ei to ej . This objective function maximizes the sum of probabilities of all
temporal relations between event pairs of the input text. There are also three following
constraints (i.e., 13, 14, 15) on this objective function:
i j M, i > j : T Ri

jM ,

Constraint 13 implies that each T Ri

jM

X

(T Ri

i j, i > j :

T Rj

iM

 {0, 1}

(13)

variable is either zero or one.
jM

+ T Rj

iM )

=1

(14)

M

Constraint 14 ensures that between each pair of events (ei and ej ), only one T Ri jM
variable is set to one, and the rest are set to zero. In other words, it is impossible for a pair
of events to have two (or more) relations.
T Ri

jM 1

+ T Rj

kM 2

 T Ri

kM 3

 1

(15)

Constraint 15 guarantees the transitivity conditions among event pairs, wherever relations T Ri jM 1 and T Rj kM 2 entail relation T Ri kM 3 . It is obvious that the transitivity
constraint is effective only when the event pairs are connected to one another. In a disconnected graph, this constraint has little effect. For example, in Figure 6, by considering this
constraint and relations T RA BAf ter and T RB CAf ter , T RA CAf ter is the only possible
relation between events A and C.
After generating the set of all constraints for each document, we can use an ILP solver
(SCIP6 ) to solve the problem. One important issue about ILP is that this technique is more
6. This ILP solver which is the fastest existing noncommercial mixed integer programming solver. Available
at http://scip.zib.de/

156

fiUnsupervised Temporal Relation Learning between Events

effective on dense temporal graphs than in sparse ones.
After removing contradictions in the temporal relations, generated (consistent) relations
can be easily used in updating the probabilities of the model in the M-step. The results of
Tables 11 and 12 are without applying the greedy best-first search or ILP. The accuracy
results with the greedy and ILP algorithms over TimeBank and OTC are shown in Table
13. Table 14 shows the accuracy results for tasks E and F over the corpus of TempEval
2010. One question that may arise is how we can enforce the transitivity constraints in EM,
when we have only labels Class1 , Class2 , and Class3 , rather than BEFORE, AFTER, and
OVERLAP. This problem only happens for the case of EMTRL + Random Initialization,
for which we have used a prior assignment of Class1 = AF T ER, Class2 = BEF ORE,
and Class3 = OV ERLAP . For the other two initializations (i.e., 10% Supervised and
Rule-base), this problem does not occur, because our algorithm starts with the actual class
labels BEFORE, AFTER, and OVERLAP.
Method Type

EMTRL + Random Initialization
EMTRL + 10% Supervised
Initialization
EMTRL + Rule-based Initialization

TimeBank
Base
Greedy
Method
40.92
41.09

41.03

Base
Method
43.02

48.31

49.54

50.34

47.86

50.88

52.12

ILP

OTC
Greedy

ILP

42.94

43.00

49.34

50.52

51.44

48.78

49.98

51.17

Table 13: The accuracy results of applying the greedy best-first search strategy and ILP to
TimeBank and OTC.

Method Type

EMTRL + Random Initialization
EMTRL + 10% Supervised
Initialization
EMTRL + Rule-based Initialization

Task E
Greedy

ILP

28.03

28.04

Base
Method
22.33

32.20

33.54

33.92

32.76

33.49

34.12

Base
Method
27.92

Task F
Greedy

ILP

22.32

22.30

26.29

27.94

27.92

27.03

28.36

28.55

Table 14: The accuracy results of applying the greedy best-first strategy and ILP to tasks
E and F of TempEval 2010.

157

fiMirroshandel & Ghassem-Sani

Tables 13 and 14 show the impact of utilizing the greedy best first search and ILP
approaches in EMTRL against the base method. By using these strategies, some of the
inconsistencies that may exist among predicted temporal relations, are removed (in step
E of EMTRL) to make the predicted relations more reliable. As a result, in step M, the
parameters of the model will be updated more accurately and thus the accuracy of the
whole algorithm will iteratively increase.
The significance of the results depicted in Tables 13 and 14 have been verified by the
stratified shuffling with significance level  = 0.05. As we had expected, the results of these
approaches on EMTRL + Random Initialization was not statistically significant. On the
other hand, in majority of tests on EMTRL + 10% Supervised Initialization and EMTRL +
Rule-based Initialization, where we compared the output of the greedy and ILP algorithms
with that of base method, the statistical significance of the results was verified.

7. Conclusion and Future Work
In this paper, we have addressed the problem of temporal relation learning between events,
which has been a topic of interest since early days of statistical natural language processing.
We have concentrated our efforts to reduce the need to annotated corpora as much as
possible. Accordingly, in this paper, two new algorithms, a weakly supervised and an
unsupervised, were presented.
The first algorithm was a two-stage weakly supervised approach for classification of
temporal relations. In the first stage of the algorithm, a SVM based classifier was trained
to learn temporal relations of the corpus. Then, in the second stage of the algorithm, a
cross-document bootstrapping technique was employed to iteratively improve the model
produced in the first stage. By the idea of bootstrapping, which has been inspired by the
hypothesis that we have called one type of temporal relation between events per discourse,
for each test document, some global evidences from a cluster of topically related documents
refined local decisions made by the initial model. The results of experiment with this new
technique showed a significant improvement in terms of accuracy over related work including
the state-of-the-art of the statistical methods.
The second proposed algorithm was a novel model that used the EM algorithm with
interval algebra reasoning for temporal relation learning. We compared this work with some
of the successful fully supervised methods. Our experiments showed encouraging results,
considering the low level of supervision that was provided for the algorithm.
Currently, we are working on finding ways of further improvement of our algorithms, and
at the same time trying to reduce the supervision level. In BCDC, by extracting semantic
features from related documents, we may be able to improve its performance. Inconsistency
removal (i.e. ILP and greedy best first search) algorithms can be also employed in BCDC.
Besides, employing the hypothesis of one type of temporal relation between events per
discourse as an explicit constraint can be other possible direction for further research.
In EMTRL, one can use other sources of information like narrative information, relations
between events and document times, and relations between events and time expressions
to build a denser temporal graph. This increases the effectiveness of the greedy best first
search and integer linear programming algorithms. We also think, but have not verified yet,
that using a richer feature set may further improve the accuracy of EMTRL.
158

fiUnsupervised Temporal Relation Learning between Events

Acknowledgments
The authors wish to thank the associate editor and the anonymous reviewers for their
valuable comments.

References
Allen, J. (1984). Towards a general theory of action and time. Artificial intelligence, 23 (2),
123154.
Bethard, S., & Martin, J. (2007). Cu-tmp: Temporal relation classification using syntactic
and semantic features. In Proceedings of the 4th International Workshop on Semantic
Evaluations, pp. 129132. Association for Computational Linguistics.
Bethard, S., & Martin, J. (2008). Learning semantic links from a corpus of parallel temporal
and causal relations. In Proceedings of the 46th Annual Meeting of the Association
for Computational Linguistics on Human Language Technologies: Short Papers, pp.
177180. Association for Computational Linguistics.
Bethard, S., Martin, J., & Klingenstein, S. (2007a). Finding temporal structure in text:
Machine learning of syntactic temporal relations. International Journal of Semantic
Computing, 1 (4).
Bethard, S., Martin, J., & Klingenstein, S. (2007b). Timelines from text: Identification of
syntactic temporal relations. In Semantic Computing, 2007. ICSC 2007. International
Conference on, pp. 1118. IEEE.
Bethard, S. (2007). Finding event, temporal and causal structure in text: A machine learning
approach. Ph.D. thesis, University of Colorado at Boulder.
Boguraev, B., & Ando, R. (2005). Timeml-compliant text analysis for temporal reasoning.
In Proceedings of IJCAI, Vol. 5, pp. 9971003.
Boguraev, B., Pustejovsky, J., Ando, R., & Verhagen, M. (2007). Timebank evolution as a
community resource for timeml parsing. Language Resources and Evaluation, 41 (1),
91115.
Bramsen, P., Deshpande, P., Lee, Y., & Barzilay, R. (2006). Inducing temporal graphs.
In Proceedings of the 2006 Conference on Empirical Methods in Natural Language
Processing, pp. 189198. Association for Computational Linguistics.
Chambers, N., & Jurafsky, D. (2008). Jointly combining implicit constraints improves
temporal ordering. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing, pp. 698706. Association for Computational Linguistics.
Chambers, N., Wang, S., & Jurafsky, D. (2007). Classifying temporal relations between
events. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, pp. 173176. Association for Computational Linguistics.
Chang, C., & Lin, C. (2011). Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2 (3).
159

fiMirroshandel & Ghassem-Sani

Charniak, E., & Elsner, M. (2009). Em works for pronoun anaphora resolution. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pp. 148156. Association for Computational Linguistics.
Cheng, Y., Asahara, M., & Matsumoto, Y. (2007). Naist. japan: Temporal relation identification using dependency parsed tree. In Proceedings of the 4th International Workshop
on Semantic Evaluations, pp. 245248. Association for Computational Linguistics.
Cherry, C., & Bergsma, S. (2005). An expectation maximization approach to pronoun resolution. In Proceedings of the Ninth Conference on Computational Natural Language
Learning, pp. 8895. Association for Computational Linguistics.
Chklovski, T., & Pantel, P. (2005). Global path-based refinement of noisy graphs applied to
verb semantics. In Natural Language ProcessingIJCNLP 2005, pp. 792803. Springer.
Collins, M., & Duffy, N. (2001). Convolution kernels for natural language. In Proceedings
of NIPS, Vol. 14, pp. 625632.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood from incomplete data via
the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological),
39, 138.
Denis, P., & Muller, P. (2010). Comparison of different algebras for inducing the temporal
structure of texts. In Proceedings of the 23rd International Conference on Computational Linguistics, pp. 250258. Association for Computational Linguistics.
Denis, P., & Muller, P. (2011). Predicting globally-coherent temporal structures from texts
via endpoint inference and graph decomposition. In Twenty-Second International
Joint Conference on Artificial Intelligence.
Derczynski, L., & Gaizauskas, R. (2010). Usfd2: Annotating temporal expresions and tlinks
for tempeval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pp. 337340. Association for Computational Linguistics.
Ha, E., Baikadi, A., Licata, C., & Lester, J. (2010). Ncsu: Modeling temporal relations with
markov logic and lexical ontology. In Proceedings of the 5th International Workshop
on Semantic Evaluation, pp. 341344. Association for Computational Linguistics.
Hagege, C., & Tannier, X. (2007). Xrce-t: Xip temporal module for tempeval campaign. In
Proceedings of the fourth international workshop on semantic evaluations (SemEval2007), pp. 492495.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. (2009). The
weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11 (1),
1018.
Han, J., & Kambert, M. (2006). Data Mining: Concepts and Techniques (second edition).
San Francisco: Morgan Kaufmann.
Hepple, M., Setzer, A., & Gaizauskas, R. (2007). Usfd: preliminary exploration of features
and classifiers for the tempeval-2007 tasks. In Proceedings of SemEval, pp. 438441.
Ji, H., & Grishman, R. (2008). Refining event extraction through cross-document inference.
In Proceedings of the Joint Conference of the 46th Annual Meeting of the ACL, pp.
254262. Association for Computational Linguistics.
160

fiUnsupervised Temporal Relation Learning between Events

Klein, D. (2005). The Unsupervised Learning of Natural Language Structure. Ph.D. thesis,
Department of Computer Science, Stanford University.
Kolya, A., Ekbal, A., & Bandyopadhyay, S. (2010). Ju cse temp: A first step towards
evaluating events, time expressions and temporal relations. In Proceedings of the
5th International Workshop on Semantic Evaluation, pp. 345350. Association for
Computational Linguistics.
Lapata, M., & Lascarides, A. (2006). Learning sentence-internal temporal relations. Journal
of Artificial Intelligence Research, 27 (1), 85117.
Lin, D., & Pantel, P. (2001). Dirt: discovery of inference rules from text. In Proceedings
of the seventh ACM SIGKDD international conference on Knowledge discovery and
data mining, pp. 323328. ACM.
Llorens, H., Saquete, E., & Navarro, B. (2010). Tipsem (english and spanish): Evaluating crfs
and semantic roles in tempeval-2. In Proceedings of the 5th International Workshop
on Semantic Evaluation, pp. 284291. Association for Computational Linguistics.
Mani, I., Verhagen, M., Wellner, B., Lee, C., & Pustejovsky, J. (2006). Machine learning of
temporal relations. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational
Linguistics, pp. 753760. Association for Computational Linguistics.
Mani, I., Wellner, B., Verhagen, M., & Pustejovsky, J. (2007). Three approaches to learning
tlinks in timeml. Tech. rep., Technical Report CS-07-268, Brandeis University.
Mikheev, A., Grover, C., & Moens, M. (1998). Description of the ltg system used for muc-7.
In Proceedings of 7th Message Understanding Conference (MUC-7). Fairfax, VA.
Min, C., Srikanth, M., & Fowler, A. (2007). Lcc-te: a hybrid approach to temporal relation
identification in news text. In Proceedings of the 4th International Workshop on
Semantic Evaluations, pp. 219222. Association for Computational Linguistics.
Mirroshandel, S., Ghassem-Sani, G., & Khayyamian, M. (2009a). Event-time temporal
relation classification using syntactic tree kernels. In Proceeding of the 4th Language
and Technology Conference, pp. 300304.
Mirroshandel, S., Ghassem-Sani, G., & Khayyamian, M. (2009b). Using tree kernels for
classifying temporal relations between events. In Proceedings of the 23th Pacific Asia
Conference on Language, Information and Computation, pp. 355364.
Mirroshandel, S., Ghassem-Sani, G., & Khayyamian, M. (2011). Using syntactic-based kernels for classifying temporal relations. Journal of Computer Science and Technology,
26 (1), 6880.
Mulkar-Mehta, R., Hobbs, J., Liu, C., & Zhou, X. (2009). Discovering causal and temporal
relations in biomedical texts recognizing causal and temporal relations. In Proceedings
of the AAAI Spring Symposium, Stanford CA.
Muller, P., & Tannier, X. (2004). Annotating and measuring temporal relations in texts.
In Proceedings of the 20th international conference on Computational Linguistics, pp.
5056. Association for Computational Linguistics.
161

fiMirroshandel & Ghassem-Sani

Ng, V. (2008). Unsupervised models for coreference resolution. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 640649. Association
for Computational Linguistics.
Pekar, V. (2006). Acquisition of verb entailment from text. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter
of the Association of Computational Linguistics, pp. 4956. Association for Computational Linguistics.
Petrov, S., & Klein, D. (2007). Improved inference for unlexicalized parsing. In Proceedings
of NAACL HLT 2007, pp. 404411.
Puscasu, G. (2007). Wvali: Temporal relation identification by syntactico-semantic analysis.
In Proceedings of the 4th International Workshop on SemEval, pp. 484487.
Pustejovsky, J., Hanks, P., Sauri, R., See, A., Gaizauskas, R., Setzer, A., Radev, D., Sundheim, B., Day, D., Ferro, L., & Lazo, M. (2003). The timebank corpus. In Corpus
Linguistics, Vol. 2003, p. 40.
Saur, R., Knippen, R., Verhagen, M., & Pustejovsky, J. (2005). Evita: a robust event recognizer for qa systems. In Proceedings of the conference on Human Language Technology
and Empirical Methods in Natural Language Processing, pp. 700707. Association for
Computational Linguistics.
Sgaard, A. (2011). Semisupervised condensed nearest neighbor for part-of-speech tagging. In Proceedings of the 49th Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies: short papers, Vol. 2, pp. 4852.
Strohman, T., Metzler, D., Turtle, H., & Croft, W. (2005). Indri: A language model-based
search engine for complex queries. In Proceedings of the International Conference on
Intelligent Analysis.
Szpektor, I., Tanev, H., Dagan, I., & Coppola, B. (2004). Scaling web-based acquisition of
entailment relations. In Proceedings of EMNLP, Vol. 4, pp. 4148.
Tatu, M., & Srikanth, M. (2008). Experiments with reasoning for temporal relations between events. In Proceedings of the 22nd International Conference on Computational
Linguistics-Volume 1, pp. 857864. Association for Computational Linguistics.
UzZaman, N., & Allen, J. (2010). Trips and trios system for tempeval-2: Extracting temporal
information from text. In Proceedings of the 5th International Workshop on Semantic
Evaluation, pp. 276283. Association for Computational Linguistics.
Verhagen, M., Gaizauskas, R., Schilder, F., Hepple, M., Katz, G., & Pustejovsky, J. (2007).
Semeval-2007 task 15: Tempeval temporal relation identification. In Proceedings of
the 4th International Workshop on Semantic Evaluations, pp. 7580. Association for
Computational Linguistics.
Verhagen, M., Sauri, R., Caselli, T., & Pustejovsky, J. (2010). Semeval-2010 task 13:
Tempeval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pp. 5762. Association for Computational Linguistics.
Yarowsky, D. (1995). Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd annual meeting on Association for Computational
Linguistics, pp. 189196. Association for Computational Linguistics.
162

fiUnsupervised Temporal Relation Learning between Events

Yeh, A. (2000). More accurate tests for the statistical significance of result differences. In
Proceedings of the 18th conference on Computational linguistics-Volume 2, pp. 947
953. Association for Computational Linguistics.
Yoshikawa, K., Riedel, S., Asahara, M., & Matsumoto, Y. (2009). Jointly identifying temporal relations with markov logic. In Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th International Joint Conference on Natural
Language Processing of the AFNLP: Volume 1-Volume 1, pp. 405413. Association
for Computational Linguistics.
Zhang, M., Zhang, J., Su, J., & Zhou, G. (2006). A composite kernel to extract relations
between entities with both flat and structured features. In Proceedings of the 21st
International Conference on Computational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics, pp. 825832. Association for Computational Linguistics.

163

fiJournal of Artificial Intelligence Research 45 (2012) 4778

Submitted 03/12; published 09/12

The Tractability of CSP Classes Defined by Forbidden Patterns
David A. Cohen

dave@cs.rhul.ac.uk

Department of Computer Science
Royal Holloway, University of London
Egham, Surrey, UK

Martin C. Cooper

cooper@irit.fr

IRIT
University of Toulouse III, 31062 Toulouse, France

Paid Creed

p.creed@qmul.ac.uk

School of Mathematical Sciences
Queen Mary, University of London
Mile End, London, UK

Daniel Marx

dmarx@cs.bme.hu

Computer and Automation Research Institute
Hungarian Academy of Sciences (MTA SZTAKI)
Budapest, Hungary

Andras Z. Salamon

andras.salamon@ed.ac.uk

Laboratory for Foundations of Computer Science
School of Informatics, University of Edinburgh, UK

Abstract
The constraint satisfaction problem (CSP) is a general problem central to computer
science and artificial intelligence. Although the CSP is NP-hard in general, considerable
effort has been spent on identifying tractable subclasses. The main two approaches consider
structural properties (restrictions on the hypergraph of constraint scopes) and relational
properties (restrictions on the language of constraint relations). Recently, some authors
have considered hybrid properties that restrict the constraint hypergraph and the relations
simultaneously.
Our key contribution is the novel concept of a CSP pattern and classes of problems
defined by forbidden patterns (which can be viewed as forbidding generic sub-problems). We
describe the theoretical framework which can be used to reason about classes of problems
defined by forbidden patterns. We show that this framework generalises certain known
hybrid tractable classes.
Although we are not close to obtaining a complete characterisation concerning the
tractability of general forbidden patterns, we prove a dichotomy in a special case: classes
of problems that arise when we can only forbid binary negative patterns (generic subproblems in which only disallowed tuples are specified). In this case we show that all (finite
sets of) forbidden patterns define either polynomial-time solvable or NP-complete classes
of instances.
c
2012
AI Access Foundation. All rights reserved.

fiCohen, Cooper, Creed, Marx & Salamon

1. Introduction
In the constraint satisfaction paradigm we consider computational problems in which we
have to assign values (from a domain) to variables, under some constraints. Each constraint
limits the (simultaneous) values that a list of variables (its scope) can be assigned. In a
typical situation some pair of variables might represent the starting times of two jobs in a
machine shop scheduling problem. A reasonable constraint would require a minimum time
gap between the values assigned to these two variables.
Constraint satisfaction has proved to be a useful modelling tool in a variety of contexts,
such as scheduling, timetabling, planning, bio-informatics and computer vision. This has
led to the development of a number of successful constraint solvers. Unfortunately, solving
general constraint satisfaction problem (CSP) instances is NP-hard and so there has been
significant research effort into finding tractable fragments of the CSP.
In principle we can stratify the CSP in two quite distinct and natural ways. The structure of the constraint scopes of an instance of the CSP can be thought of as a hypergraph
where the variables are the vertices, or more generally as a relational structure. We can find
tractable classes by restricting this relational structure, while allowing arbitrary constraints
on the resulting scopes (Dechter & Pearl, 1987). Sub-problems of the general constraint
problem obtained by such restrictions are called structural. Alternatively, the set of allowed assignments to the variables in the scope can be seen as a relation. We can choose
to allow only specified kinds of constraint relations, but allow these to interact in an arbitrary structure (Jeavons, Cohen, & Gyssens, 1997). Such restrictions are called relational
or language-based.
Structural subclasses are defined by specifying a set of hypergraphs (or relational structures) which are the allowed structures for CSP instances. It has been shown that tractable
structural classes are characterised by limiting appropriate (structural) width measures
(Dechter & Pearl, 1989; Freuder, 1990; Gyssens, Jeavons, & Cohen, 1994; Gottlob, Leone,
& Scarcello, 2002; Marx, 2010a, 2010b). For example, a tractable structural class of binary
CSPs is obtained whenever we restrict the constraint structure (which is a graph in this
case) to have bounded tree width (Dechter & Pearl, 1989; Freuder, 1990). In fact, it has
been shown that, subject to certain complexity-theoretic assumptions, the only structures
which give rise to tractable CSPs are those with bounded (hyper-)tree width (Dalmau,
Kolaitis, & Vardi, 2002; Grohe, 2006, 2007; Marx, 2010a, 2010b).
Relational subclasses are defined by specifying a set of constraint relations. The complexity of the subclass arising from any such restriction is precisely determined by the so
called polymorphisms of the set of relations (Bulatov, Jeavons, & Krokhin, 2005; Cohen
& Jeavons, 2006). The polymorphisms specify that, whenever some set of tuples is in a
constraint relation, then it cannot be the case that a particular tuple (the result of applying
the polymorphism) is not in the constraint relation. It is thus the relationship between allowed tuples and disallowed tuples inside the constraint relations that is of key importance
to the relational tractability of any given class of instances. Whilst a general dichotomy has
not yet been proven for the relational case, many dichotomies on sub-problems have been
obtained, for instance those by Bulatov (2003), Bulatov et al. (2005) or Bulatov (2006).
48

fiTractability of CSP Classes Defined by Forbidden Patterns

Using only structural or only relational restrictions limits the possible subclasses that
can be defined. By allowing restrictions on both the structure and the relations we are able
to identify new tractable classes. We call these restrictions hybrid reasons for tractability.
Several hybrid results have been published for binary CSPs (Jegou, 1993; Weigel & Bliek,
1998; Cohen, 2003; Salamon & Jeavons, 2008; Cooper, Jeavons, & Salamon, 2010; Cooper &
Zivny, 2011b). Instead of looking at the set of constraint scopes or the constraint language,
these results captured tractability based on the properties of the (coloured) microstructure
of CSP instances. The microstructure of a binary CSP instance is the graph hV, Ei where V
is the set of possible assignments of values to variables and E is the set of pairs of mutually
consistent variable-value assignments (Jegou, 1993). In the coloured microstructure, the
vertices representing an assignment to variable vi are labelled by a colour representing
variable vi . This maintains the distinction between assignments to different variables.
The coloured microstructure of a CSP instance captures both the structure and the
relations of a CSP instance and so it is a natural place to look for tractable classes which are
neither purely structural nor purely relational. Of the results on (coloured) microstructure
properties, three are of particular note. First it was observed that the class of instances
with a perfect microstructure is tractable (Salamon & Jeavons, 2008). This is a proper
generalisation of the well known hybrid tractable CSP class whose instances allow arbitrary
unary constraints and in which every pair of variables is constrained to be not equal (Regin,
1994; van Hoeve, 2001), and of the hybrid class whose microstructure is triangulated (Jegou,
1993; Weigel & Bliek, 1998; Cohen, 2003). The perfect microstructure property excludes
an infinite set of induced subgraphs from the microstructure.
Secondly, the Joint Winner Property (JWP) (Cooper & Zivny, 2011b) applied to CSPs
provides a different hybrid class that also strictly generalises the class of CSP instances
with a disequality constraint (6=) between every pair of variables and an arbitrary set of
unary constraints, but does so by forbidding a single pattern (a subgraph) in the coloured
microstructure. The JWP has been generalized to hierarchies of soft non-binary constraints (Cooper & Zivny, 2011a), including, for example, soft hierarchical global cardinality
constraints, by reduction to a minimum convex cost flow problem.
Thirdly, the so called broken-triangle property properly extends the structural notion
of acyclicity to a more interesting hybrid class (Cooper et al., 2010). The broken triangle
property is specified by excluding a particular pattern in the coloured microstructure. It is
the notion of forbidden pattern that we study in this paper. We therefore work directly with
the CSP instance (or equivalently its coloured microstructure) rather than its microstructure
abstraction which is a simple graph. This allows us to introduce a language for expressing
hybrid classes in terms of forbidden patterns, providing a framework in which to search
for novel hybrid tractable classes. In the case of binary negative patterns we are able
to characterise all tractable (finite sets of) forbidden patterns. We also state a necessary
condition for the tractability of a (finite set of) general patterns.
1.1 Contributions
In this paper we generalise the definition of a CSP instance to that of a CSP pattern
which has three types of tuple in its constraint relations, tuples which are explicitly al49

fiCohen, Cooper, Creed, Marx & Salamon

lowed/disallowed and tuples which are labelled as unknown1 . By defining a natural notion
of containment of patterns in a CSP, we are able to describe problems defined by forbidden
patterns: a class of CSP instances defined by forbidding a particular pattern  are exactly
those instances that do not contain . We use this framework to capture tractability by
identifying local patterns of allowed and disallowed tuples (within small groups of connected
constraints) whose absence is enough to guarantee tractability.
Using the concept of forbidden patterns, we lay foundations for a theory that can be
used to reason about classes of CSPs defined by hybrid properties. Since this is the first
work of this kind, we primarily focus on the simplest case: binary patterns in which tuples
are either disallowed or unknown (called negative patterns). We give a large class of binary
negative patterns which give rise to intractable classes of problems and, using this, show
that any negative pattern that defines a tractable class of problems must have a certain
structure. We are able to prove that this structure is also enough to guarantee tractability
thus providing a dichotomy for tractability defined by forbidding binary negative patterns.
Importantly, our intractability results also allow us to give a necessary condition on the
form of general tractable patterns.
The remainder of the paper is structured as follows. In Section 2 we define constraint
satisfaction problems, and give other definitions used in the paper. Then, in Section 3, we
define the notion of a CSP pattern and describe classes of problems defined by forbidden
patterns. We give some examples of tractable classes defined by forbidden patterns on three
variables. In Section 4 we show that one must take the size of patterns into account to have
a notion of maximal classes defined by forbidding patterns. In general, we are not yet able
to make any conjecture concerning a dichotomy for hybrid tractability defined by general
forbidden patterns. However, in Section 5 we are able to give a necessary condition for such
a class to be tractable and in Section 6 prove the dichotomy for negative patterns. Finally,
in Section 7 we summarise our results and discuss directions for future research.

2. Preliminaries
Definition 2.1. A CSP instance is a triple hV, D, Ci where:
 V is a finite set of variables (with n = |V |).
 D is a finite set called the domain (with d = |D|).
 C is a set of constraints. Each constraint c  C is a pair c = h, i where:
  is a list of distinct variables called the scope of c.
  is a relation over D of arity || called the relation of c. It is the set of tuples
allowed by c.
A solution to the CSP instance P = hV, D, Ci is a mapping s : V  D where, for each
h, i  C we have s()   (where s() represents the tuple resulting from the application
of s component-wise to the list of variables ).
1. This can be viewed as the natural generalisation of the CSP to a three-valued logic.

50

fiTractability of CSP Classes Defined by Forbidden Patterns

For simplicity of presentation, we assume that all variables have the same domains.
Unary constraints can be used to impose different domains for different variables.
The arity of a CSP is the largest arity of any of its constraint scopes. Our long-term
aim is to identify all tractable subclasses of the CSP problem which can be detected in
polynomial time. In this paper we describe a general theory of forbidden patterns for
arbitrary arity but only consider the implications of the new theory for tractable classes of
arity two (binary) problems specified by finite sets of forbidden patterns. In such cases we
are certain that class membership can be decided in polynomial time.
The CSP decision problem, which asks whether a particular CSP instance has a solution,
is already NP-complete for binary CSPs. For example, there is a straightforward reduction
from graph colouring to this problem in which the set of colours is used as the domain of
the CSP instance, vertices i of the graph map to CSP variables vi , and edges {i, j} map to
disequality constraints vi 6= vj .
It will sometimes be convenient in this paper to use an equivalent functional formulation
of a constraint. In this alternative formulation the scope  of the constraint h, i is abstracted to a set of variables and each possible assignment is seen as a function f :   D.
The constraint relation in this alternative view is then a function from the set of possible
assignments, D , into the set {T, F } where, by convention, the tuples which occur in the
constraint relation are those which map to T . It follows that any assignment to the set of
all variables is allowed by h, i when its restriction to  is mapped to T by .
Definition 2.2. For any function f : X  Y and S  X, the notation f |S means the
function with domain S satisfying f |S (x) = f (x) for all x  S.
Given a set V of variables and a domain D, a constraint in functional representation
is a pair h, i where   V and  : D  {T, F }. A CSP instance in functional representation is a triple hV, D, Ci where C is a set of constraints in functional representation.
A solution (to a CSP instance hV, D, Ci in functional representation) is a mapping
s : V  D where, for each h, i  C we have (s| ) = T .
The functional formulation is clearly equivalent to the relational formulation and we
will use whichever seems more appropriate throughout the paper. The choice will always
be clear from the context.
The following notions are standard in the study of the CSP. A binary CSP instance is
one where the maximum arity of any constraint scope is two. The subproblem of I on
variables U  V is the instance hU, D, CU i where CU is the set of constraints h, i  C
such that   U . The instance I is arc-consistent if v1 , v2  V , each solution to the
subproblem of I on {v1 } can be extended to a solution to the subproblem of I on {v1 , v2 }.
The constraint graph of a binary CSP instance I = hV, D, Ci is the graph with vertices
V and edges the set of scopes of binary constraints in C. Since it is often convenient to
consider that a (possibly irrelevant) constraint exists between every pair of variables, we
introduce the refined notion of true constraint graph.
Definition 2.3. A binary constraint between v1 and v2 is improper if it allows every pair
of values allowed by the unary constraints on v1 and v2 , and proper otherwise.
The true constraint graph of a binary CSP instance is the constraint graph of the
instance after removing any improper binary constraints.
51

fiCohen, Cooper, Creed, Marx & Salamon

We may also sometimes need to disregard unary constraints so we have the following.
Definition 2.4. The binary reduction of a CSP instance is obtained by removing from
the constraint set all those constraints whose scope does not have arity two.

3. Forbidden Patterns in CSP
In this paper we explain how we can define classes of CSP instances by forbidding the
occurrence of certain patterns. A CSP pattern is a generalisation of a CSP instance. In a
CSP pattern we define the relations relative to a three-valued logic on {T, F, U }, meaning
that the pattern can be seen as representing the set of CSP instances in which each undefined value U is replaced by either T or F . Forbidding a CSP pattern is equivalent to
simultaneously forbidding all these instances as sub-problems.
Definition 3.1. We define a three-valued logic on {T, F, U }, where U stands for unknown
or undefined. The set {T, F, U } is partially ordered so that U < T and U < F but T and F
are incomparable. Let D be a finite set. A k-ary three-valued relation on D is a function
 : Dk  {T, F, U }. Given k-ary three-valued relations  and 0 , we say  realises 0 if
x  Dk (x)  0 (x).
We can extend the definition of a CSP or constraint pattern to include additional structure on the set of variable names or the set of domain values, as a set of relations on the
set in question. Adding structure makes patterns more specific. We can therefore capture larger, and hence more interesting, tractable classes. For example, when the domain
is totally ordered we can define the tractable max-closed class (Jeavons & Cooper, 1995);
when we have an independent total order for the domain of each variable we can capture
the renamable Horn class (Green & Cohen, 2003); and placing an order on variables in a
pattern will allow us to define the class of tree-structured CSP instances.
Definition 3.2. A CSP pattern is a quadruple  = hV, D, C, Si, where:
 V is the set of variables, with an associated relational structure with universe V .
 D is the domain, with an associated relational structure with universe D.
 C is a set of constraint patterns. Each constraint pattern c  C is a pair c = h, i,
where   V , the scope  of c, is a list of distinct variables and  : D  {T, F, U } is
the three-valued relation (in functional representation) of c. A constraint pattern
is non-trivial if its three-valued relation maps at least one tuple to {T, F }.
 S is the structure, a set consisting of the relational structures associated with its
variable set and its domain.
The arity of a CSP pattern  is the maximum arity of any constraint pattern h, i of .
Our most basic type of pattern is one which employs no structure, with S empty. We
also frequently require patterns which use a disequality relation 6=, applied to every pair
52

fiTractability of CSP Classes Defined by Forbidden Patterns

from some specified subset of variables, and we allow several such subsets of variables in
the structure.
In this paper the relations occurring in the structure all have arity two, and their interpretation is limited to a few selected binary relations representing disequality or a partial
order. When the structure of a variable set or domain is clear from the context, we will not
explicitly mention it. Different kinds of structure can be imposed on CSP patterns; indeed
structures specified by more general relations would be an interesting area for future study.
The weakest structure that we will consider only allows us to say when two variables are
distinct. Thus the structure S of a CSP pattern is then simply a set of disequalities between
subsets of variables. In this paper we denote such disequalities by NEQ(v1 , . . . , vr ) meaning
that variables v1 , v2 , . . . , vr are all pairwise distinct. A pattern with such a structure will
be called flat. Indeed, in this paper we are mostly concerned with flat patterns. If two
variables occur together in the scope of some constraint pattern, then we also assume that
S implicitly includes the disequality NEQ(v1 , v2 ).
Thus CSP patterns are defined using relational structures with three sorts: for variables,
for domain values, and for variable-value assignments. The constraint patterns of a CSP
pattern are then three-valued relations over the sort of variable-value assignments. If a CSP
pattern is flat then its structure specifies relations over the sort of variables. A partial order
over the variables is also a relation over the sort of variables, and partial orders over domain
values are relations over the sort of domain values.
For simplicity of presentation, we assume throughout this paper that no two constraint
patterns in C have the same scope (and that, in the case of CSP instances, that no two
constraints have the same scope). We will represent binary CSP patterns by simple diagrams. Each oval represents the domain of a variable, each dot a domain value. The tuples
in constraint patterns with value F are shown as dashed lines, those with value T as solid
lines and those with value U are not depicted at all.
Definition 3.3. A constraint pattern h, i will be called negative if  never takes the
value T . A CSP pattern  is negative if every constraint pattern in  is negative.
3.1 Patterns, CSPs and Occurrence
In a CSP instance it is implicitly assumed that all variables and all domain values are
distinct. This is equivalent to the existence of implicit disequalities NEQ between all variable
names and all domain values. A CSP instance is just a CSP pattern (with a structure that
all variables and all domain values are distinct) in which the three-valued relations of the
constraint patterns never take the value U . That is, we decide for each possible tuple
whether it is in the relation or not. Furthermore, in a CSP instance, for each pair of
variables we assume that a constraint exists with this scope; if no explicit constraint is
given on this scope, then we assume that the relation is complete, i.e. it contains all tuples.
This can be contrasted with CSP patterns for which the absence of an explicit constraint
on a pair of variables implies that the truth value of each tuple is undefined.
In order to define classes of CSP instances by forbidding patterns, we require a formal
definition of an occurrence (containment) of a pattern within an instance. We define the
more general notion of containment of one CSP pattern within another pattern. Informally,
the names of the variables and domain elements of a CSP pattern are inconsequential and
53

fiCohen, Cooper, Creed, Marx & Salamon

a containment allows a renaming of the variables and the domain values of each variable.
Thus, in order to define the containment of patterns, we firstly require a formal definition
of a renaming. In an arbitrary renaming, unless explicitly prohibited by a disequality in
the structure, two distinct variables may map to the same variable and two distinct domain
values may map to the same domain value. Furthermore, when a pattern occurs in another,
it may use only a subset of the variables of the second pattern; hence the notion we require
is known as a renaming-extension.
A domain labelling of a set of variables is just an assignment of domain values to those
variables. Variable and domain renaming induces a mapping on the domain labellings of
scopes of constraints: we simply assign the renamed domain values to the renamed variables. There is a natural way to extend this mapping of domain labellings to a mapping
of a constraint pattern: the truth-value of each mapped domain labelling is the same as
the truth-value of the original domain labelling. However, it may occur that two domain
labellings of some scope map to the same domain labelling, so instead the resulting value
is taken to be the greatest of the original truth-values. (In order for this process to be
well-defined, if two domain labellings of a constraint are mapped to the same domain labelling, then their original truth-values must be comparable.) This leads to the following
formal definition of a renaming-extension which is the first step towards the definition of
containment.
Definition 3.4. Let  = hV, D, C, Si and 0 = hV 0 , D0 , C 0 , S 0 i be CSP patterns.
We say that 0 is a renaming-extension of  if there exist a variable-renaming function s : V  V 0 and a domain-renaming function t : V  D  D0 such that s, t and
the assignment-renaming function F : V  D  V 0  D0 induced by (s, t) and defined by
F (hv, ai) = hs(v), t(v, a)i satisfy:
 For each constraint pattern h, i  C, for any two domain labellings `, `0  D for
which F (`) = F (`0 ), we have that (`) and (`0 ) are comparable, where F (`) denotes
the assignment f : s()  D0 such that v  , f (s(v)) = t(v, `(v)).
 C 0 = {hs(), 0 i | h, i  C}, where, for each assignment f : s()  D0 , 0 (f ) = U if
F (`) 6= f for every `  D , and 0 (f ) = max {(`) | F (`) = f } otherwise.
 If  has any structure, then s, t and F preserve this structure. The mapping s induces
a homomorphism between the relational structures of the variable-sets, and mapping
t induces a homomorphism between the relational structures of the domains. (In
particular, if NEQ(v1 , v2 )  S, then s(v1 ) 6= s(v2 ) and NEQ(s(v1 ), s(v2 ))  S 0 .)
We will use patterns to define sets of CSP instances by forbidding the occurrence (containment) of the patterns in the CSP instances. In this way we will be able to characterise
tractable subclasses of the CSP. Informally, a pattern  is said to occur in a CSP instance
P if we can find a sub-problem Q of P (formed by taking subsets of variables and domains)
which realises . Q realises  if, after renaming of variables and domain values in , each
constraint pattern in  is realised by the corresponding constraint in Q. By Definition 3.4,
during a renaming-extension, extra variables, domain values and disequalities can be introduced. Thus we only need to combine the notions of renaming-extension and realisation to
formally define what we mean by a pattern occurring in another pattern (and, in particular,
in a CSP instance).
54

fiTractability of CSP Classes Defined by Forbidden Patterns

Definition 3.5. We say that a CSP pattern  occurs in a CSP pattern P = hV, D, C, Si
(or that P contains ), denoted   P , if there is a renaming-extension hV, D, C 0 , Si of 
where, for every constraint pattern h, 0 i  C 0 there is a constraint pattern h, i  C and,
furthermore,  realises 0 .
Pattern 1
d0
b
b

c

d

b

a
a

c

d

y

x

d
z

y

x

(i)

c

a
y

x

(ii)

(iii)

Pattern 2
b

d

a

c
y

x

Example 3.6. This example describes three simple containments. Consider the three CSP
patterns, Pattern 1(i)(iii). These patterns occur in, or are contained in, Pattern 2 by the
mappings F1 , F2 , and F3 , respectively, which we will now describe.
F1 is simply a bijection. Although the patterns are different, this is a valid containment
of Pattern 1(i) into Pattern 2 because the three-valued relation of Pattern 2 is a realisation
of the three-valued relation in Pattern 1(i): we are replacing (b, d) 7 U by (b, d) 7 F .
F2 maps (x, a), (x, b), and (y, c) to themselves, and maps both (y, d) and (y, d0 ) to
(y, d). This merging of domain elements is possible because the values of the three-valued
constraint relation of Pattern 1(ii) are comparable on tuples involving the assignments (y, d)
and (y, d0 ) and, furthermore, the restriction of the three-valued relation of Pattern 1(ii)
to either of these two assignments is realised by the three-valued constraint relation of
Pattern 2: (b, d) 7 F and (a, d) 7 T . For example, we are replacing (a, d0 ) 7 U by
(a, d) 7 T . In a similar manner, Pattern 1(i) is also contained in Pattern 2 by the simple
mapping F10 which maps both of (x, b), (x, a) to (x, b) and both of (y, c), (y, d) to (y, c).
Finally, F3 maps (y, c) and (y, d) to themselves, and maps (x, a) and (z, b) in Pattern 1(iii) to (x, a) and (x, b), respectively, in Pattern 2. This merging of variables is pos55

fiCohen, Cooper, Creed, Marx & Salamon

sible because the three-valued relations agree and because there is no NEQ(x, z) structure
in Pattern 1(iii).

Pattern 3
z
b

b

d

d

z
c

a
y

x

c

a
y

x

NEQ(x, z)
(i)

(ii)

Throughout this paper, we use the notation NEQ(v1 , . . . , vr ) to denote the fact that the
variables v1 , . . . , vr of a CSP pattern are distinct. It is worth discussing what this structure
implies as far as Definition 3.4 is concerned. Structure in the source pattern must be
preserved in the target pattern. Thus Pattern 1(iii) occurs in Pattern 3(i), but Pattern 3(i)
is not contained in Pattern 1(iii) since the structure NEQ(x, z) is not preserved in the target
pattern. The structure NEQ(v1 , v2 ) is considered to be preserved by a renaming-extension
0 of  even if it is not explicitly given in 0 but is implicit, for example, due to the existence
of a non-trivial constraint pattern h, i in 0 such that v1 , v2  . As an example, consider
the two CSP patterns, Pattern 3(i)(ii). Pattern 3(i) can be mapped to Pattern 3(ii) by
a simple bijection so that the three-valued relation of Pattern 3(ii) is a realisation of the
three-valued relation in Pattern 3(i). The structure NEQ(x, z) is considered to be preserved
by this mapping due to the existence of a non-trivial constraint pattern between variables
x and z in Pattern 3(ii). Hence, Pattern 3(i) occurs in Pattern 3(ii).
Before continuing we need to define what we mean when we say that a class of CSP
instances is definable by forbidden patterns.
Definition 3.7. Let C be any class of CSP instances with maximum arity k. We say that
C is definable by forbidden patterns if there is some set of patterns X for which the set
of CSP instances of maximum arity k in which none of the patterns in X occur are precisely
the instances in C.
Notation: Let X be a set of CSP patterns with maximum arity k. We will use CSP(X ) to
denote the set of CSP instances in which no element   X occurs. When X is a singleton
{} we will use CSP() to denote CSP({}).
In this paper, we only consider classes CSP(X ) for sets X of CSP patterns which are
binary in the sense that all constraint patterns have scope of size exactly two.
For all X such that all patterns in X are binary, CSP(X ) is closed under arc consistency
(in the sense that the arc consistency closure of any instance I  CSP(X ) belongs to
56

fiTractability of CSP Classes Defined by Forbidden Patterns

CSP(X )) and any other operation which only updates unary constraints. Indeed, changing
unary constraints cannot introduce any of the patterns X in any instance I  CSP(X ).
3.2 Tractable Patterns
In this paper we will define, by forbidding certain patterns, tractable subclasses of the CSP.
Furthermore, we will give examples of truly hybrid classes (i.e. classes not definable by
purely relational or purely structural properties).
Definition 3.8. A finite set of patterns X is intractable if CSP(X ) is NP-hard. It is
tractable if there is a polynomial-time algorithm to solve CSP(X ). A single pattern  is
tractable (intractable) if {} is tractable (intractable). (We assume throughout this paper
that P6= NP, and therefore that the sets of tractable and intractable patterns are disjoint.)
It is worth observing that classes of CSP instances defined by forbidding patterns do
not have a fixed domain. Recall, however, that each CSP instance has a finite domain. Any
structure present in a CSP instance is assumed given as part of the instance. In particular,
all variables in a CSP instance are assumed to be distinct. For finite sets of patterns X ,
the number of possible renaming-extensions into a particular instance P is polynomial in
the size of P . Hence we can determine whether an instance lies in CSP(X ) by exhaustive
search in polynomial time.
We will need the following simple lemmas for our proofs of intractability results in later
sections of this paper.
Lemma 3.9. If 1  2 and 2  3 , then 1  3 .
Proof. If   0 , then each constraint pattern h, i of  maps to a constraint pattern h 0 , 0 i
such that 0 realises . The transitivity of  follows from the following facts:
 The realisation operation is transitive.
 If 1  2 and 2  3 , then by Definition 3.4, any structure in 1 is preserved in 2
and hence in 3 .
Lemma 3.10. Let X and T be sets of CSP patterns and suppose that for every pattern
  T , there is some pattern   X for which    . Then CSP(X )  CSP(T ).
Proof. Let P  CSP(X ), so  6 P for each   X . Then we cannot have   P for any
  T , since this would imply that there exists some   X such that     P and hence
that   P by Lemma 3.9. Hence, P  CSP(T ).
Corollary 3.11. Let X and T be sets of CSP patterns and suppose that for every pattern
  T , there is some pattern   X for which    .
We then have that CSP(T ) is intractable if CSP(X ) is intractable and conversely, that
CSP(X ) is tractable whenever CSP(T ) is tractable.
Finally, we give some examples of tractable patterns. The first example is a negative
pattern since the only truth-values in the relations are F and U .
57

fiCohen, Cooper, Creed, Marx & Salamon

Pattern 4 A very simple negative pattern.
v
a

x
c
c0

w
b
NEQ(v, w, x)

Example 3.12. Consider Pattern 4. This defines a class of CSPs which is trivially tractable.
Forbidding Pattern 4 ensures that there are no paths of more than two variables in the true
constraint graph. Thus, any problem forbidding Pattern 4 can be decomposed into a set of
independent sub-problems, each with at most two variables.

Example 3.13. Cooper and Zivny (2011b) showed that forbidding the pattern Negtrans
shown in Pattern 5 describes a tractable class of CSP instances. This can be seen as a generalisation of the well-known tractable class of problems, AllDifferent+unary (Costa,
1994; Regin, 1994; van Hoeve, 2001): an instance of this class consists of a set of variables
V , a set of arbitrary unary constraints on V , and the constraint v 6= w defined on each pair
of distinct variables v, w  V . Forbidding Negtrans is equivalent to saying that disallowed
tuples form a transitive relation, i.e. if (hv, ai , hx, bi) and (hx, bi , hw, ci) are disallowed then
(hv, ai , hw, ci) must also be disallowed. Thus Negtrans does not occur in any binary CSP
instance in the class AllDifferent+unary by the transitivity of equality (equality being
exactly what is disallowed).

Pattern 5 Negative transitive pattern (Negtrans)
v
x

w

NEQ(v, w, x)
Cooper and Zivny (2011b) also recently showed that the tractable class defined by
forbidding Pattern 5 (Negtrans) can be extended to soft constraint problems.
58

fiTractability of CSP Classes Defined by Forbidden Patterns

3.3 Tractable Patterns with Structure
This paper primarily studies patterns with a weak structure in that the only conditions that
are imposed are that variables are distinct. However, it is worth pointing out that adding
structure to a pattern allows us to capture larger classes of instances. In Example 3.14
below we show that a forbidden pattern can capture the class of CSPs with tree width 1
by adding a variable-ordering to Pattern 4. In this case pattern containment must preserve
the total order. For an ordered pattern , we will consider an unordered CSP P to be in
CSP() if there exists some ordering of the variable set of P such that  is forbidden. In
order for  to define a tractable class, it must be possible to find this ordering in polynomial
time. This is the case for the patterns in Examples 3.14 and 3.15.
Pattern 6 Tree structure pattern (Tree)

v1
v3
v2
v1 < v2 < v3
Example 3.14. Consider the pattern Tree, given as Pattern 6. We will show that the class
CSP(Tree) is exactly the set of CSPs whose true constraint graph is a forest (i.e. has tree
width 1). First, suppose P  CSP(Tree). Then, there exists some ordering  = (v1 , . . . , vn )
such that each variable shares a proper constraint with at most one variable preceding it
in the ordering. On the other hand, suppose P is a CSP whose true constraint graph is a
tree. By ordering the vertices according to a pre-order traversal, we obtain an ordering in
which each variable shares a proper constraint with at most one variable preceding it in the
ordering (its parent); thus, P  CSP(Tree).

Example 3.15. Forbidding the pattern BTP shown in Pattern 7 is known as the brokentriangle property (Cooper et al., 2010). In order to capture this class by a forbidden
pattern we again have to impose a total order on pattern variables. Cooper et al. (2010)
proved that the class of CSP instances CSP(BTP) can be solved in polynomial time and,
indeed, that CSP instances in CSP(BTP) for some unknown total ordering of the variables
can be recognised and solved in polynomial time.

It is easy to see that Tree (shown in Pattern 6) occurs in BTP (with some truthvalues U being changed to T ). It follows from Lemma 3.10 that CSP(Tree)  CSP(BTP).
Hence the class CSP(BTP) includes all CSP instances whose true constraint graph is a tree.
However, CSP(BTP) also includes certain CSP instances whose true constraint graph has
59

fiCohen, Cooper, Creed, Marx & Salamon

Pattern 7 Broken triangle pattern (BTP)

b

v1

a
v3
v2
v1 < v2 < v3

tree width r for any value of r: consider, for example, a CSP instance with r + 1 variables
and an identical constraint between every pair of variables which simply disallows the single
tuple h0, 0i.
For any tractable forbidden pattern with an order imposed on the variables, we can
obtain another tractable class by considering problems forbidding the pattern without this
ordering condition. The class obtained is generally smaller, because it is easier to establish
containment of the flat pattern. For example, consider Pattern 4 which is the flat version of
Pattern 6. We have seen that forbidding Pattern 4 gives rise to the class of CSP instances
in which there are no paths of length greater than two in the true constraint graph. On the
other hand, forbidding Pattern 6 gives the much larger class of CSP instances in which the
true constraint graph has tree width 1.
In the case of the broken-triangle property, we also obtain a strictly smaller tractable
class by forbidding Pattern 7 for all triples of variables v1 , v2 , v3 irrespective of their order.
We can easily exhibit a CSP instance that shows this inclusion to be strict: for example, the
3-variable CSP instance over Boolean domains consisting of the two constraints v1 = v2 ,
v1 = v3 with the variable ordering v1 < v2 < v3 . This unordered version of BTP was
recently used to obtain a dichotomy for patterns consisting of 2 constraints (Cooper &
Escamocher, 2012).

4. On Maximal Tractable Classes Defined by Forbidden Patterns
In relational tractability we can define a maximal tractable sub-problem of the CSP problem
given by a set  of possible relations. Such a class of relations is maximal if it is not possible
to add even one more relation to  without sacrificing tractability.
In the case of structural tractability the picture is less clear, since here we measure the
complexity of an infinite set of hypergraphs (or, more generally, relational structures). We
obtain tractability if we have a bound on some width measure of these structures. Whatever
width measure is chosen we have a containment of the class with width bounded by k inside
that of the class of width bounded by k +1 and so no maximal class is possible (although for
each k there is a unique maximal class of structurally tractable instances). In this section,
we show that in the case of forbidden patterns the situation is similar.
60

fiTractability of CSP Classes Defined by Forbidden Patterns

Definition 4.1. Let  = hV, D, C, Si and  = hV 0 , D0 , C 0 , S 0 i be any two flat CSP patterns.
 0 and DD
 0 . Now, extend each constraint pattern in
We can form the disjoint unions V V
 0 by setting the value of any tuple including elements of D0 to
C to be over the domain DD
 0.
be U , and extend similarly the constraint patterns in C 0 : in this way we can define C C
 0 by forming the disjoint union of S and S 0 and adding all
Also define the structure S S
0
disequalities NEQ(v, v ) for all v  V and v 0  V 0 . Then we set the disjoint union of 
 = hV V
 0 , DD
 0 , C C
 0 , S S
 0 i.
and  to be 
Lemma 4.2. Let  and  be flat non-empty (i.e. containing at least one variable) binary
CSP patterns. Then
 ).
CSP()  CSP( ) ( CSP(
 ) is tractable whenever CSP() and CSP( ) are tractable.
Moreover, we have that CSP(
Proof. We begin by showing the strict inclusion
 ).
CSP()  CSP( ) ( CSP(
That the inclusion holds follows directly from Lemma 3.10. Among all patterns in which 
occurs, let  be a pattern with the smallest number of variables. We define   similarly.
To see that the inclusion is strict, observe that  and  occur in a CSP pattern whose
domain is the disjoint union of those for  and   , but whose variable set has size equal
to the larger of the variable sets of  and   . Any CSP instance containing this pattern
is neither in CSP() nor in CSP( ). However, we can construct a CSP instance containing
 ), as the structure of 
 imposing disequalities
this pattern which is contained in CSP(

between variables of  and  means that  is not contained in this pattern: there are
simply not enough variables.
 ). If P  CSP()  CSP( ) then P can be solved in polynomial
Suppose P  CSP(
time, by the tractability of CSP() and CSP( ).
So we may suppose that   P . Choose a particular occurrence of  in P and let 
denote the set of variables used in the containment. Consider any assignment t :  
D. Let Pt denote the problem obtained by making this assignment and then enforcing
arc-consistency on the resulting problem. This corresponds to adding some new unary
constraints to P .
 must occur in P . To see this, observe that
We will show that if  occurs in Pt then 
any containment of  in Pm naturally induces a containment of  in P that extends to a
 in P , by considering the occurrence of  in . Thus, we can conclude
containment of 
that Pt  CSP( ), and so can be solved in polynomial time.
By construction, any solution to Pt extends to a solution to P by adding the assignment
t to the variables . Moreover, every solution to P corresponds to a solution to Pt for some
t :   D. Since the size of  is fixed, we can iterate over the solutions to  in polynomial
time. If P has a solution, then we will find it as the solution to some Pt . If we find that no
Pt has a solution, then we know P does not have a solution. Thus, since we can solve each
Pt in polynomial time, we can also solve P in polynomial time.
Corollary 4.3. No tractable class defined by forbidding a flat pattern is maximal.
61

fiCohen, Cooper, Creed, Marx & Salamon

 defined by the disjoint
Proof. Let  be any tractable flat pattern. Consider the pattern 

union of two copies of . By Lemma 4.2 we have that CSP()
is tractable but also that
 ,
CSP() ( CSP()
and hence CSP() is not a maximal tractable class.
It follows that we cannot characterise tractable forbidden patterns by exhibiting all
maximal tractable classes defined by forbidding a pattern (or any finite set of patterns,
since by Lemma 4.2 such a finite set can be replaced by a single pattern). Indeed, a
consequence of Lemma 4.2 is that we can construct an infinite chain of patterns, such that
forbidding each one gives rise to a slightly larger tractable class. Naturally, if we place an
upper bound on the size of the patterns then there are only finitely many patterns that we
can consider, so maximal tractable classes defined by forbidden patterns of bounded size
necessarily exist.

5. Binary Flat Negative Patterns
For the moment, we are not able to make a conjecture concerning the complete characterisation of the complexity of general forbidden patterns, although we conjecture that a
dichotomy exists. Nonetheless, by restricting our attention to a special case, forbidden
binary flat negative patterns, we are able to obtain a dichotomy. Recall that a pattern is
flat if the only structure that can be imposed is that variables are distinct, and that it is
negative if in all of its constraint patterns h, i,  never takes the value T .
We begin by defining three particular patterns and one infinite class of patterns. We
then use these patterns to characterise a very large class of intractable patterns. We prove
that any finite set of flat negative patterns not in this class has a simple structure: one of
the patterns must be contained in one of a particular set of patterns, which we call pivots.
This means that any tractable such set of patterns must include a pattern which occurs in
a pivot pattern. Furthermore, we demonstrate that forbidding any pivot pattern gives rise
to a tractable class. This then leads to a simple characterisation of the tractability of finite
sets of binary flat negative patterns.
Pattern 8 Cycle(6)
c0
c
v1

v2

v3

v6

v5

NEQ(v1 , . . . , v6 )

62

v4

fiTractability of CSP Classes Defined by Forbidden Patterns

Pattern 9 Valency
x1

x01

x2

x02

x3

x03
NEQ(x1 , x2 , x3 , x01 )  NEQ(x01 , x02 , x03 )

Pattern 10 Path

v1

v2

v3

w1

w2

w3

NEQ(v1 , v2 , v3 , w1 )  NEQ(w1 , w2 , w3 )
In Definition 5.1 below, we define the concept of a neg-connected binary pattern. These
correspond to binary patterns  such that the true constraint graph of every realisation of
 as a binary CSP instance is a connected graph. We first generalise the notion of true
constraint graph to CSP patterns. We call the resulting graph the negative structure graph.
Definition 5.1. Let  be any binary pattern. The vertices of the negative structure
graph G are the variables of . A pair of vertices is an edge in G if and only if they form
a scope in  whose constraint pattern assigns at least one tuple the value F . We say that
a pattern  is neg-connected if its negative structure graph is connected. In the case of
negative patterns, we use the simpler term connected instead of neg-connected.
Pattern 9 (Valency), Pattern 10 (Path) and Pattern 11 (Valency+Path) are not
connected. Note that a pattern which is not connected may occur in a connected pattern
(and vice versa). Pattern 8 shows Cycle(6) which is connected. This is just one example
of the generic pattern Cycle(k) where k  2. The only structure for Cycle(k) is that
all variables are distinct, except for the special case k = 2 for which the structure also
includes NEQ(c, c0 ). This additional requirement means that Cycle(2) is composed of a
single binary constraint pattern containing two distinct disallowed tuples. The following
theorem uses these patterns to show that most patterns are intractable.

63

fiCohen, Cooper, Creed, Marx & Salamon

Pattern 11 Valency+Path
v1

v2
w1
v3

w2

w3

x

NEQ(v1 , v2 , v3 ), NEQ(w1 , w2 , w3 ), and NEQ(x, w2 )
Theorem 5.2. Let X be any finite set of neg-connected binary patterns. If, for each   X ,
at least one of Cycle(k) (for some k  2), Valency, Path, or Valency+Path occurs
in , then X is intractable.
Proof. Let X be a finite set of neg-connected negative binary patterns and let ` be the
number of variables in the largest element of X .
Assuming at least one of the four patterns occurs in each   X , we can construct a
class of CSPs in which no element of X occurs and to which we have a polynomial-time
reduction from the well-known NP-complete problem 3SAT (Garey & Johnson, 1979).
The construction will involve three gadgets, examples of which are shown in Figure 1.
These gadgets each serve a particular purpose:
1. The cycle gadget, shown in Figure 1(a) for the special case of 4 variables, enforces
that a cycle of Boolean variables (v1 , v2 , . . . , vr ) all take the same value.
2. The clause gadget in Figure 1(b) is equivalent to the clause v1  v2  v3 , since vC has
a value in its domain if and only if one of the three vi variables is set to true. We can
obtain all other 3-clauses on these three variables by inverting the domains of the vi
variables.
3. The line gadget in Figure 1(c), imposes the constraint v1  v2 . It can also be used to
impose the logically equivalent constraint v2  v1 .
The cycle gadget will be connected to the clause gadget via line gadgets. These three types
of gadgets have been specified to ensure that at most one negative edge is adjacent to any
vertex in the coloured microstructure, except when the cycle gadget is connected to a line
gadget.
Now, suppose that we have an instance  of 3SAT with n propositional variables
X1 , . . . , Xn and m clauses C1 , . . . , Cm .
We begin our construction of a CSP instance P to solve the 3SAT instance  by using
n copies of the cycle gadget (Figure 1(a)), each with m(` + 1) variables. For i = 1, . . . , n,
m(`+1)
the variables along the ith copy of this cycle are denoted by (vi1 , vi2 , . . . , vi
). In any
64

fiTractability of CSP Classes Defined by Forbidden Patterns

v1
T
F

v2

vC
v2

v1

v3

T
F
v3
T
F

v4
(a)

(b)

T
F
v1

v2
(c)

Figure 1: (a) Making copies of the same variable (v1 = v2 = v3 = v4 ). (b) Imposing the
ternary constraint vC = v1  v2  v3 . (c) A line of constraints of length 4 which
imposes v1  v2 .

solution to a CSP instance P with these and other constraints, we will have that the
variables vij , j = 1, . . . , m(` + 1) must all have the same value, di . We can therefore consider
each vij as a copy of Xi .
Consider the clause Cw . There are eight cases to consider but they are all very similar
so we will show the details for just one case. Suppose that Cw  Xi  Xj  Xk . We
build the clause gadget (Figure 1(b)) with the three Boolean variables being ciw , cjw and ckw
and invert the domain of ckw since it occurs negatively in Cw . Then any solution s to our
constructed CSP must satisfy s(ciw )  s(cjw )  s(ckw ) = T .
We complete the insertion of Cw into the CSP instance by adding some line gadgets of
length ` + 1 (Figure 1(c)). We connect the cycle gadgets corresponding to Xi , Xj and Xk
w(`+1)
to the clause gadget for clause Cw since Xi , Xj and Xk occur in Cw . We connect vi
w(`+1)
to ciw since Xi is positive in Cw , so s(ciw ) = T is only possible when s(vi
) = T , for
65

fiCohen, Cooper, Creed, Marx & Salamon

w(`+1)

any solution s. Similarly, we connect vj
to cjw . Finally, since Xk occurs negatively in
Cw , we impose the line constraints in the other direction. This ensures that s(ckw ) = F is
w(`+1)
only possible when s(vk
) = F . Imposing these constraints ensures that a solution is
only possible when at least one of the cycles corresponding to variables Xi , Xj , and Xk is
assigned a value that would make the corresponding literal in Cw true.
We continue this construction for each clause of the 3SAT instance. Since ` is a constant,
this is clearly a polynomial reduction from 3SAT.
We now show that any CSP instance P constructed in the manner we have just described cannot contain any pattern in X . We do this by showing that no neg-connected
pattern containing Cycle(k) (for 2  k  `), Valency, Path, or Valency+Path can
occur in the instance. This is sufficient to show that the CSP instance P does not contain
any of the patterns in X .
In the CSP instance P no constraint contains more than one disallowed tuple. Thus,
any   X for which Cycle(2)   cannot occur in P . Furthermore, P is built from
cycles of length m(` + 1) and paths of length ` + 1, and so cannot contain any cycles on less
than ` + 1 vertices. Thus, since ` is the maximum number of vertices in any element of X ,
it follows that no   X for which Cycle(k)  , for any k  3, can occur in P .
We define the valency of a variable x to be the number of distinct variables which share
a constraint pattern with x. Suppose Valency  , where   X is neg-connected. For
this to be possible we require that there is a variable of valency four in , or a pair of
variables of valency three connected by a path of length at most ` in the negative structure
graph of . Certainly P has no variables of valency four. Moreover, the fact that P was
built using paths of length ` + 1 means that no two of its valency three variables are joined
by a path of length at most `. Thus,   X does not occur in P if Valency  .
Next, consider the case when Path  , where   X is neg-connected. Here  must
have two distinct (but possibly overlapping) three-variable lines (with disallowed tuples in
these constraint patterns that match at domain values) separated by at most ` variables.
The only place where disallowed tuples can meet in P is when we connect the line gadget
to the cycle gadget. These connection sites are always at distance greater than `, so we can
conclude that  6 P whenever Path  .
Finally, consider the case where Valency+Path  , where   X is neg-connected.
Here,  must have a variable of valency at least 3 and a path of constraint patterns on
three variables with intersecting disallowed tuples, and these must be connected by a path
of less than ` variables in the negative structure graph of . As observed above, the only
places in P where we can have disallowed tuples meeting is where the line gadget meets
the cycle gadget, and there is a path of at least ` variables between each one of these points
and every other variable of valency 3. Thus,  6 P whenever Valency+Path  .
It remains to consider which sets of negative binary patterns could be tractable. For
this, we need to define the pivot patterns, Pivot(r), which contain every tractable negative
binary pattern.
Definition 5.3. Let V = {p}  {v1 , . . . , vr }  {w1 , . . . , wr }  {x1 , . . . , xr }, D = {a, b}
and S = {NEQ(p, v1 , . . . , vr , w1 , . . . , wr , x1 , . . . , xr )}. We define the pattern Pivot(r) =
66

fiTractability of CSP Classes Defined by Forbidden Patterns

Pattern 12 Pivot(3)
v3

v2

v1
w1

w2

w3

p
a
x3

x2

x1

b

NEQ(p, v1 , v2 , v3 , w1 , w2 , w3 , x1 , x2 , x3 )

hV, D, Cp  Cv  Cw  Cx , Si, where
Cp = {h(p, v1 ), ab i , h(p, w1 ), ab i , h(p, x1 ), bb i}
Cv = {h(vi , vi+1 ), ab i | i = 1, . . . , r  1}
Cw = {h(wi , wi+1 ), ab i | i = 1, . . . , r  1}
Cx = {h(xi , xi+1 ), ab i | i = 1, . . . , r  1}
and where ab (a, b) = F , ab (s, t) = U (for all (s, t) 6= (a, b)), bb (b, b) = F , bb (s, t) = U
(for all (s, t) 6= (b, b)). The pattern Pivot(r) has the structure S that all its variables are
distinct. See Pattern 12 for an example, Pivot(3).
We say that a pattern  on variables v1 , . . . , vr is a distinct-variable pattern if its
structure includes NEQ(v1 , . . . , vr ). The following proposition characterises those sets of
connected binary flat negative distinct-variable patterns which Theorem 5.2 does not prove
intractable.
Proposition 5.4. Any connected binary flat negative distinct-variable pattern  either
contains Cycle(k) (for some k  3), Valency, Path, or Valency+Path, or itself
occurs in Pivot(r) for some integer r  ||.
Proof. Suppose  does not contain any of the patterns Valency, Cycle(k) (for any k  3),
Path, or Valency+Path. Recall that the valency of a variable x is the number of distinct
variables which share a constraint pattern with x. Since  does not contain Valency it
can only contain one variable of valency three and all other variables must have valency
at most two. Moreover, since Cycle(k) 6  for k  3, the negative structure graph of 
does not contain any cycles. Thus, since  is connected, the negative structure graph of
 consists of up to three disjoint paths joined at a single vertex. If two disallowed tuples
67

fiCohen, Cooper, Creed, Marx & Salamon

over distinct scopes intersect, then we call the union of the scopes the footprint of the
intersection. The fact that the negative structure graph of  is acyclic and that  does not
contain Path means that all such pairs of intersecting disallowed tuples in  must have the
same footprint. Moreover, the fact that  does not contain Valency+Path means that
all such intersections must occur at the variable with valency 3, if it exists. The fact that 
is flat and negative means that in a renaming-extension any pair of disallowed tuples ha, bi,
hc, di over the same scope hu, vi in  can be merged by the domain-renaming function t,
i.e. t(hu, ai) = t(hu, ci) and t(hv, bi) = t(hv, di). It then follows that  occurs in Pivot(r),
for some r  ||.
Corollary 5.5. Let X be a finite set of connected binary flat negative distinct-variable
patterns. Then CSP(X ) is tractable only if there is some   X that occurs in Pivot(r),
for some integer r  ||.
We now prove the same result for patterns which are not necessarily distinct-variable.
Corollary 5.6. Let X be a finite set of connected binary flat negative patterns. Then
CSP(X ) is tractable only if there is some   X that occurs in Pivot(r), for some integer
r  ||.
Proof. For  a connected binary flat negative pattern, let dv() denote the set of connected
binary flat negative distinct-variable patterns in which  occurs, which have the same
domain as  and at most || variables. We use dv(X ) to denote the union of the sets dv()
for   X .
By Lemma 3.10, CSP()  CSP(dv()). For every CSP instance P such that   P ,
we have   P for some   dv(). It follows that CSP(dv())  CSP(), and hence
CSP() = CSP(dv()). Since CSP(X ) is just the intersection of the CSP() for   X
and CSP(dv(X )) the intersection of the CSP(dv()) for   X , we have that CSP(X ) =
CSP(dv(X )).
By Corollary 5.5, CSP(dv(X )) is tractable only if some pattern   dv(), for some
  X , occurs in Pivot(r) for some r  | |. But, by definition of dv(),  occurs in 
and | |  ||. Therefore, CSP(X ) is tractable only if  occurs in Pivot(r) for some integer
r  ||.
For an arbitrary (not necessarily flat or negative) binary CSP pattern , we denote
by neg() the flat negative pattern obtained from  by replacing all truth-values T by
U in all constraint patterns in  and ignoring any structure beyond disequalities between
variables. Recall that the structure of a flat pattern only contains disequality relations
between variables, so neg() is a flat pattern by definition. For a set of patterns X ,
neg(X ) is naturally defined as the set neg(X ) = {neg() :   X }. Clearly CSP(neg(X ))
 CSP(X ). The following result follows immediately from Corollary 5.6. It provides a
necessary condition for tractability of general patterns.
Corollary 5.7. Let X be a finite set of binary patterns such that for each   X , neg() is
connected. Then CSP(X ) is tractable only if there is some   X such that neg() occurs
in Pivot(r), for some integer r  ||.
68

fiTractability of CSP Classes Defined by Forbidden Patterns

6. The Pivot Theorem
Theorem 6.1. Pivot(r) is tractable for all r  1.
This theorem together with Corollary 5.6 immediately provides a dichotomy for finite
sets of connected binary flat negative patterns. Most of this section is devoted to the proof
of this theorem (which we call the pivot theorem). We conclude this section by giving a
dichotomy for finite sets of flat negative patterns which are not necessarily connected.
We will need some definitions from graph theory.
Definition 6.2. A subdivision of a graph G is a graph obtained by replacing some edges
of G with simple paths.
A minor of a graph G is any graph obtained from G by deleting edges, contracting
edges and removing isolated vertices. A graph H is a topological minor of a graph G if a
subdivision of H is a subgraph of G.
We will need to use the following well-known theorem of Robertson and Seymour (1986).
Theorem 6.3. For every planar graph H there is an integer k > 0 such that if a graph
does not contain H as a minor, then its tree width is at most k.
In particular, if a graph has large tree width, then it contains a large grid minor. In this
section we will consider hexagonal grid minors instead (see Figure 2). The reason for this is
the well-known fact that if a graph of maximum degree three is a minor of another graph,
then it is a topological minor and the latter notion is more convenient for our proofs. As
illustrated in Figure 2, an h hexagonal grid is a graph composed of hexagons in a honeycomb
pattern: its width h is the number of hexagons in both horizontal and vertical directions.
Definition 6.4. Let g : r  N be such that every graph of tree width at least g(r) contains
the 3(r + 4) hexagonal grid as a topological minor.
Let us observe the following simple property first:
Lemma 6.5. Any three degree three vertices of the hexagonal grid of width 3r begin disjoint
paths of length r.
Proof. If each vertex is in a different row then we can simply choose a path for each of them
along their row (in the direction away from the nearest boundary of the grid). See vertices
a, b and c in Figure 2 to visualise this typical situation.
Otherwise it may be possible, by rotating the grid through 120 or 240 degrees to get all
three vertices to lie on different rows. If we cannot separate the vertices by rotating then
they are the corners of an equilateral triangle, such as x, y, z or p, q, r in the diagram.
If the triangle has an interior row, such as Row 4 for x, y, z in the diagram, then we
can extend two vertices along their row and drop the third to the interior row and then
along that row. Thus, for example, the path beginning at y would drop down one row and
continue along Row 4.
The only remaining case is when the three vertices form an equilateral triangle occupying
just two adjacent rows, like p, q, r in the diagram. In this case there is some orientation
for which the two vertices that are on the same row do not both lie along the edge of the
69

fiCohen, Cooper, Creed, Marx & Salamon

grid. In the diagram we can rotate either 120 or 240 degrees to achieve this for p, q, r.
Now we can extend two of the three vertices along their row and the third can shift away
from the centre of the triangle in order to find an empty row along which the path can be
extended.
Row 6
b

y

x

Row 5
Row 4

z

Row 3
a
c
Row 2
Row 1
Row 0

r
p

q

Figure 2: A hexagonal grid of width 6 with the rows picked out in bold and numbered.
The following combinatorial result is crucial for our algorithm, but it is interesting in
its own right:
Lemma 6.6. Let G be a 3-connected graph of tree width at least g(r) and let a, b, c be
distinct vertices of G. Then G contains 3 pairwise vertex disjoint paths starting at a, b, c,
respectively, and each having length r.
Proof. Let H be the 3(r + 4) hexagonal grid. By the definition of g(r), graph G contains
H as a topological minor. Note that H contains some vertices of degree 2 on the boundary,
which will cause some complications in the proof. To avoid this complication, we observe
that H is a subdivision of a graph H  whose every vertex has degree 3 and we will focus
on the graph H  instead.

Let HG
denote the subdivision of H  appearing in G and let S denote the vertices of

degree three in HG
. By Mengers theorem (Dirac, 1966) there are vertex-disjoint paths Pa ,
Pb , Pc in G from a, b, c to distinct vertices sa , sb , sc in S, respectively. Choose the paths in

such a way that the total number of edges used by them that are not in HG
is minimized.

Let x, y  S be two vertices that correspond to adjacent vertices in H . This means

that HG
contains a path Q with endpoints x and y whose internal vertices are disjoint
from S. Suppose that, say, Pa contains an internal vertex of Q. We claim that either (1)
x, y  {sa , sb , sc } or (2) sa  {x, y} and Pb , Pc are disjoint from Q. Suppose that (1) does
not hold, say, x 6 {sa , sb , sc }. Consider the internal vertex q of Q closest to x that is used
70

fiTractability of CSP Classes Defined by Forbidden Patterns

by one of the paths. We can reroute this path from q to x without using any further edges

outside HG
. This would create a new set of paths with smaller number of edges outside


HG , unless the rerouted path did not use any further edges outside HG
after q. This is
only possible if the path goes from q to y on Q. But this means that there is only one path
intersecting Q: no path intersects Q between q and x by the definition of q and the same
path uses all the vertices from q to y. Thus case (2) holds.
By Lemma 6.5 there are three independent paths of length r + 4 from the vertices sa , sb
and sc in the (non subdivided) hexagonal grid H, which correspond to paths Xa , Xb , Xc in

HG
. We will use these paths to create three independent paths of length at least r from a, b
and c in G. By definition, the path Xa does not go through sb or sc . Therefore, by the claim
in the previous paragraph, Xa is disjoint from Pb and Pc : if Xa uses the path Q between x
and y, then sb , sc 6 {x, y} means that neither (1) or (2) can happen if Pb or Pc intersects
Q. If Xa is disjoint from Pa as well, then we create a new path Ta by simply concatenating
Pa and Xa . Otherwise, the only way Xa can intersect Pa is on the first subdivided edge
of H  where Xa goes (this is the only place where case (2) of the claim can happen). In
this case, we create a new path Ta by following Pa until it meets this subdivided edge and
then following Xa . As each edge of H  corresponds to up to 4 edges of H, path Ta could
meet up to 4 edges of H fewer than what Xa does. The path Ta will, in either case, meet
at least r subdivided edges of H and so has length at least r. We can build Tb and Tc in an
analogous fashion.
We will require the following technical lemma in our proofs.
Lemma 6.7. Let P be any binary CSP instance. Suppose that the assignment of d to x, or
of d0 to y both extend to a solution of P but that there is no solution assigning both d to x
and d0 to y. Then there is a path of proper binary constraints between x and y. Furthermore,
there is such a path such that the first constraint along this path disallows some tuple hd, d1 i
and the last constraint disallows some tuple hd2 , d0 i.
Proof. Let Sx be any solution to P including the assignment of d to x and similarly let Sy
be any solution to P including the assignment of d0 to y.
Define a graph G on the variables of P . There is an edge from x to a variable z if and
only if the assignment of d to x is incompatible with some domain value for z. Similarly,
there is an edge from y to a variable z if and only if the assignment of d0 to y is incompatible
with some domain value for z. Finally there is an edge between any two variables other
than x and y if and only if the constraint between them is proper.
Let Cx be the component of G containing x. Define an assignment S to the variables
of P by setting S(z) = Sx (z) if z  Cx and S(z) = Sy (z) otherwise. This is a solution to
P since the only possible unsatisfied constraint would have to be between a variable of Cx
and a variable not in Cx , but by the choice of Cx this cannot happen.
By hypothesis, we know that S(y) 6= d0 and so we have the required path of proper
binary constraints.
Note that if in Lemma 6.7 there is a binary constraint between x and y that forbids
assigning d to x and d0 to y, then setting d1 = d0 and d2 = d yields the required path of
proper binary constraints, of length one.
We first show that CSP(Pivot(r)) is tractable in a special case with restricted structure.
71

fiCohen, Cooper, Creed, Marx & Salamon

Lemma 6.8. The subclass of CSP(Pivot(r)) consisting of instances:
 which have an arc-consistent binary reduction;
 which have no unary constraints on variables of degree two in the constraint graph;
 where the true constraint graph is a subdivided three-connected graph,

has time complexity O n3 dg(r)+1 .

Proof. Let P be an instance satisfying the conditions of the lemma. In time O nd2 , we
join the binary constraints along each subdivided edge eliminating intermediate variables
as we go, to obtain the instance P 0 , whose constraint graph is three-connected, but which
may have some improper binary constraints and arbitrary unary constraints. Let G denote
the true constraint graph of P and G0 the three-connected graph obtained from G by
contracting subdivided edges. The true constraint graph of P 0 is a subgraph of G0 on the
same vertex-set.

We can solve P 0  CSP(Negtrans) in time O n2 d3 (n + d) (Cooper & Zivny, 2011b).

This is clearly O n3 dg(r)+1 since g(r)  3 for all r. Furthermore, if G0 has tree width at

most g(r) then P 0 can be solved in time O ndg(r)+1 (Dechter & Pearl, 1989). In either
case this solution can be extended to a solution of the original instance P in time O(nd).
The only remaining case to consider is when Negtrans occurs in P 0 and the tree
width of G0 is also at least g(r). We will complete the proof by deriving the contradiction
P 6 CSP(Pivot(r)), in order to show that this case cannot occur.
Suppose Negtrans occurs in P 0 on variables a, b, c and values da , db , dc :
da

dc

a

c
db
b

By Lemma 6.6, G0 contains 3 vertex-disjoint paths Ta , Tb , Tc starting at a, b, c, respectively, each having length at least r. Recall that the true constraint graph G of the
original instance P was a subdivided three-connected graph and that P 0 was obtained from
P by joining binary constraints along subdivided edges. Let Ta , Tb , Tc denote the paths in
G corresponding to Ta , Tb , Tc in G0 . Recall also that Negtrans occurs in P 0 on variables
a, b, c and values da , db , dc .
Now let a and c be the first vertices along the subdivided edges from b to a and c in
G. The embedding of Negtrans in P 0 shows that hdb , da i is disallowed by the join of the
arc-consistent path from b to a. Since this path is, by construction, a subdivision of an
edge of P 0 we know that no unary constraints occur on any internal vertices. We also know,
by arc consistency of the binary constraints, that the assignments a = da or b = db both
extend to a consistent assignment to the path between a and b. So, by Lemma 6.7 we know
that there is some value da in the domain of a such that hdb , da i is disallowed in P by the
72

fiTractability of CSP Classes Defined by Forbidden Patterns

constraint between b and a. Similarly there is a value dc for which hdb , dc i is disallowed in P
by the constraint between a and c. By appending the path from b to a to the path Ta and
the path from b to c to Tc , together with Tb , we obtain three independent paths of length at
least r of proper constraints in P , beginning at variable b, two beginning with constraints
disallowing a tuple with value db at b. So we have shown that Pivot(r) does indeed occur
in P and we are done.
CSP(Pivot(r)) places an upper bound on the length of the chain of dependencies that
may have to be followed to discard a partial solution that cannot be extended to a solution.
Informally speaking, forbidding the Pivot(r) pattern bounds the amount of local search
that may have to be done when extending a partial solution to a larger partial solution. The
amount of effort that may be required increases with the length of such chains of inference,
and this worst-case behaviour is quantified more precisely in the following result. We first
require some definitions.
Definition 6.9. Let G be a graph and U be a subset of the vertices of G. The induced graph
G[U ] of G on U is the graph with vertex set U and whose edges are those edges of G which
connect two vertices of U .
For graphs G = hV, Ei and G0 = hV 0 , E 0 i define G  G0 = hV  V 0 , E  E 0 i.
In a graph G we say that hU1 , U2 i is a separation if G = G[U1 ]  G[U2 ] and neither of
U1 , U2 is a subset of the other. The separator of the separation hU1 , U2 i is U1  U2 and
its order is |U1  U2 |. A minimal separator is one of minimal order.
The torso of U1 in the separation hU1 , U2 i is obtained from the induced graph G[U1 ] by
adding every edge between the vertices of the separator of hU1 , U2 i.

Theorem 6.10. The class of Pivot(r)-free instances is solvable in time O n3 dg(r)+3 .
Proof. We will prove the result by induction on the number of variables.
The base case is straightforward. When the instance has fewer than g(r)+3 variables, we
can clearly solve it by exhaustive search in time O n3 dg(r)+3 . For the inductive case we can

assume that we can solve all smaller instances with n < k variables in time O n3 dg(r)+3 .
Let P be any Pivot(r)-free instance with n = k variables. First make P arc-consistent
in time O(n2 d2 ) (Bessiere, Regin, Yap, & Zhang, 2005). Since P is now arc-consistent, unary
constraints no longer have any effect. Remove all unary and improper binary constraints
from P in time O(n2 d2 ). Let G be the true constraint graph of the resulting instance, P 0 .
If G has no separation of order two then it is either three-connected or has at most three
vertices. In the three-connected case we can solve P 0 , and hence P , in time O n3 dg(r)+1
by Lemma 6.8. If P has at most three variables then it is trivial to solve in time O(d3 ).
So, we can assume that G has a separation of order two. By definition of the torso any
size-2 separator of a torso is a size-2 separator of G. Hence we can find a size-2 separation
hU1 , U2 i where the torso of U1 has no separation of order two. So we can assume that the
torso of U1 is either three-connected or has at most three vertices.
Now consider the separator M = U1  U2 of hU1 , U2 i. If M is empty then P 0 is composed of two smaller independent
Pivot(r)-free instances and so can be solved in time

3
g(r)+3
3
g(r)+3
O n1 d
+ O n2 d
where n1 + n2 = n and 1  n1 , n2 < n. It follows that we can

solve P in time O n3 dg(r)+3 , so we are done.
73

fiCohen, Cooper, Creed, Marx & Salamon

If M = {m} then we consider the structure of G[U1 ]. It is three-connected, so m
vertex has degree at least three. In this case we can add any unary constraint on m
and, by Lemma 6.8, solve the instance in time O n3 dg(r)+1 . Hence we can find, in time

O dn3 dg(r)+1 , which values of the variable m extend to all variables of U1 . Adding this restriction as a unary constraint on variable m leaves the induced instance on U2 Pivot(r)-free

and we see, by induction, that we can solve P 0 in time O dn3 dg(r)+1 + (n  1)3 dg(r)+3 =

O n3 dg(r)+3 , so we are done.
Finally we must consider M = {x, y}. Since M is minimal we know that G[U2 ] is
connected and there is a path between x and y in U2 . Denote by Q the CSP instance
induced on G[U1 ], together with some path in U2 from x to y. The constraint graph of
Q is a subdivision of the torso of U1 which is either three-connected or has at most three
vertices. In the latter case Q has tree width at most two so, after the addition of unary
constraints on x and y, can be solved in time O(n2 d3 ) (Dechter & Pearl, 1989). If the torso
of U1 is three-connected then the degrees of x and of y in Q are at least three. After the
addition of any
 unary constraints on x and y we can, by Lemma 6.8, solve this case in time
O n3 dg(r)+1 . Hence we can solve Q with all possible unary constraints on x and y which

only allow one value for each of x and y, in time O d2 n3 dg(r)+1 .
For each value of variable x we now know whether it extends to some solution on all
the variables in Q. Similarly, for each value of variable y we know whether it extends to a
solution on all variables in Q. We can express these two restrictions as unary constraints,
u(x) and u(y) on x and y. Lastly we find the binary constraint c(x, y) on x and y which
specifies precisely which pairs of values, allowed by u(x) and u(y), extend to all variables
of U1 . This we obtain by solving the subdivided three-connected instance and seeing which
pairs are disallowed by the subdivided edge in U2  for such pairs we do not set the constraint
relation in c(x, y) to F .
If u(x) allows no values for x then P has no solution and we stop.
Now consider the instance R, which is induced by P 0 on U2 together with the constraints
u(x), u(y) and c(x, y). By construction, P has a solution if and only if R has a solution.
Any Pivot(t) occurring in R must use a pair of values disallowed by c(x, y) since it cannot
occur in P 0 . Suppose that hd, d0 i is disallowed by c(x, y). It follows that the assignment of d
to x, or of d0 to y both extend to a solution of Q but assigning both d to x and d0 to y does
not extend to a solution of the problem induced by P 0 on U1 . By Lemma 6.7 there is a path
of proper constraints between x and y in G[U1 ]. Furthermore, the first constraint along this
path disallows some tuple hd, d1 i and the last constraint disallows some tuple hd2 , d0 i. It
follows that we cannot embed Pivot(r) in the instance R induced on U2 together with the
constraint c(x, y) (otherwise we would have been able to embed it
 in the instance P ).
Since R  CSP(Pivot(r)), we can solve it in time O n3 dg(r)+3 by our inductive hypoth

esis. Thus, in this final case, the complexity is O d2 n3 dg(r)+1 + n3 dg(r)+3 = O n3 dg(r)+3
and we are done.
Theorem 6.1 is important as it gives us a tractable class of CSPs defined by forbidding
a negative pattern which, unlike CSP(Tree), contains problems of unbounded tree width,
and so cannot be captured by structural tractability. This is true even for Pivot(1). As
an example of a class of CSP instances in CSP(Pivot(1)) with unbounded tree width,
consider the n-variable CSP instance Pn with domain {1, . . . , n} whose constraint graph
74

fiTractability of CSP Classes Defined by Forbidden Patterns

is the complete graph and, for each pair of distinct values i, j  {1, . . . , n}, the constraint
on variables vi , vj disallows a single pair of assignments (hvi , ji , hvj , ii). Since each assignment hvi , ji occurs in a single disallowed tuple, Pivot(1) does not occur in Pn , and hence
Pn  CSP(Pivot(1)). To produce an example of a class of instances in CSP(Pivot(1))
with unbounded tree width and which are not in CSP(Negtrans), we can modify Pn by
introducing a Boolean variable vij for each pair i < j and by replacing the constraint on
variables vi , vj by constraints on vi , vij and on vj , vij : the former disallowing the single pair
of assignments (hvi , ji , hvij , 0i) and the latter the pair of assignments (hvj , ii , hvij , 0i). The
pattern Negtrans occurs on each triple of assignments (hvi , ji , hvij , 0i , hvj , ii).
The dichotomy for finite sets of connected binary flat negative patterns now follows
directly from Theorem 6.1 and Corollary 5.6.
Theorem 6.11. Let X be a finite set of connected binary flat negative patterns. Then X is
tractable if and only if there is some   X that is contained in Pivot(r), for some integer
r  ||.
Informally speaking, this dichotomy states that bounding the length of problematic
Pivot(r)-style inference chains leads to tractability, and moreover that when a class of
instances defined by a finite set of forbidden flat patterns is tractable, then it must avoid
problematic inference chains of this form.
This dichotomy easily extends to patterns which are not necessarily connected. When
a negative pattern  is not connected, it can be decomposed into connected patterns corresponding to the connected components of the negative structure graph of . We call these
patterns the connected components of .
Corollary 6.12. Let X be a finite set of binary flat negative patterns. Then X is tractable
if and only if for some   X , each of the connected components of  is contained in
Pivot(r), for some integer r  ||.
Proof. Let X be a finite set of binary flat negative patterns. Let CC() represent the set of
connected components of a pattern , and CC(X ) the union of all the sets CC() (  X ).
Suppose that X is tractable. Consider an arbitrary subset X 0 of CC(X ) such that the
set X 0 contains exactly one connected component from each pattern   X . By Lemma 3.10
CSP(X 0 )  CSP(X ), and hence X 0 is also tractable. Therefore, by Corollary 5.6, there is
some pattern 0  X 0 that occurs in Pivot(r), for some integer r  |0 |. The only way this
can be true for all possible choices of X 0 is if there is some   X such that all connected
components of  occur in Pivot(r), for some integer r  ||.
On the other hand, suppose that for some   X , each of the connected components of
  X occurs in Pivot(r), where r  ||. Let k be the number of connected components
of . Then  occurs in the disjoint union of k copies of Pivot(r). This is tractable by
Theorem 6.1 and k  1 applications of Lemma 4.2. It follows that , and hence X , is
tractable.

7. Conclusion
In this paper we described a framework for identifying classes of CSPs in terms of forbidden
patterns, to be used as a tool for identifying tractable classes of the CSP. We gave several
examples of small patterns that can be used to define tractable classes of CSPs.
75

fiCohen, Cooper, Creed, Marx & Salamon

In the search for a general result, we restricted ourselves to the special case of binary
patterns and binary CSPs. In Theorem 5.2 we showed that CSP(X ) is NP-hard if every
pattern in a set X contains at least one of four patterns (Patterns 8, 9, 10, and 11). Moreover,
we showed that any binary flat negative pattern  that does not contain any of these patterns
must itself be contained within (possibly several copies of) a special type of pattern called
a pivot. Hence, being contained in (several copies of) a pivot is a necessary condition for
pattern  to be tractable. We then showed that forbidding the pivot pattern defines a
tractable class.
Beyond this dichotomy for binary flat negative patterns, it will be interesting to see
what new tractable classes can be defined by more general binary patterns or by non-binary
patterns. In particular, an important area of future research is determining all maximal
tractable classes of problems defined by patterns of some fixed size (given by the number of
variables or the number of variable-value assignments). A further avenue for future research
is the characterisation of the complexity of patterns involving structure that uses more than
just disequalities between groups of variables, such as a total ordering on its variables.

Acknowledgments
The authors acknowledge support from ANR Project ANR-10-BLAN-0210, EPSRC grants
EP/F011776/1 and EP/I011935/1, ERC Starting Grant PARAMTIGHT (No. 280152), and
EPSRC platform grant EP/F028288/1.

References
Bessiere, C., Regin, J.-C., Yap, R. H. C., & Zhang, Y. (2005). An optimal coarse-grained
arc consistency algorithm. Artificial Intelligence, 165 (2), pp. 165185. doi:10.1016/
j.artint.2005.02.004.
Bulatov, A., Jeavons, P., & Krokhin, A. (2005). Classifying the complexity of constraints
using finite algebras. SIAM Journal on Computing, 34 (3), pp. 720742. doi:10.
1137/S0097539700376676.
Bulatov, A. A. (2003). Tractable conservative constraint satisfaction problems. In LICS 03:
Proceedings of 18th IEEE Symposium on Logic in Computer Science, pp. 321330.
doi:10.1109/LICS.2003.1210072.
Bulatov, A. A. (2006). A dichotomy theorem for constraint satisfaction problems on a 3element set. Journal of the ACM, 53 (1), pp. 66120. doi:10.1145/1120582.1120584.
Cohen, D., & Jeavons, P. (2006). The complexity of constraint languages. In Rossi et al.
(Rossi et al., 2006), chap. 8, pp. 245280.
Cohen, D. A. (2003). A new class of binary CSPs for which arc-consistency is a decision
procedure. In CP 03: Proceedings of the 9th International Conference on Principles
and Practice of Constraint Programming, No. 2833 in Lecture Notes in Computer
Science, pp. 807811. Springer-Verlag. doi:10.1007/978-3-540-45193-8_57.
Cooper, M. C., & Escamocher, G. (2012). A Dichotomy for 2-Constraint Forbidden CSP
Patterns. In AAAI 12: Proceedings of the Twenty-Sixth AAAI Conference on Ar76

fiTractability of CSP Classes Defined by Forbidden Patterns

tificial Intelligence. Available from: https://www.aaai.org/ocs/index.php/AAAI/
AAAI12/paper/view/4960/5225.
Cooper, M. C., Jeavons, P. G., & Salamon, A. Z. (2010). Generalizing constraint satisfaction
on trees: Hybrid tractability and variable elimination. Artificial Intelligence, 174 (9
10), pp. 570584. doi:10.1016/j.artint.2010.03.002.
Cooper, M. C., & Zivny, S. (2011a). Hierarchically nested convex VCSP. In CP 11: Proceedings of the 17th International Conference on Principles and Practice of Constraint
Programming, pp. 187194. Springer-Verlag. doi:10.1007/978-3-642-23786-7_16.
Cooper, M. C., & Zivny, S. (2011b). Hybrid tractability of valued constraint problems.
Artificial Intelligence, 175 (910), pp. 15551569. doi:10.1016/j.artint.2011.02.
003.
Costa, M.-C. (1994). Persistency in maximum cardinality bipartite matchings. Operations
Research Letters, 15 (3), pp. 143149. doi:10.1016/0167-6377(94)90049-3.
Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint satisfaction, bounded
treewidth, and finite-variable logics. In CP 02: Proceedings of the 8th International Conference on Principles and Practice of Constraint Programming, No. 2470
in Lecture Notes in Computer Science, pp. 310326. Springer-Verlag. doi:10.1007/
3-540-46135-3_21.
Dechter, R., & Pearl, J. (1987). Network-based heuristics for constraint-satisfaction problems. Artificial Intelligence, 34 (1), pp. 138. doi:10.1016/0004-3702(87)90002-6.
Dechter, R., & Pearl, J. (1989). Tree clustering for constraint networks. Artificial Intelligence, 38 (3), pp. 353366. doi:10.1016/0004-3702(89)90037-4.
Dirac, G. A. (1966). Short proof of Mengers graph theorem. Mathematika, 13 (1), pp.
4244. doi:10.1112/S0025579300004162.
Freuder, E. C. (1990). Complexity of K-Tree Structured Constraint Satisfaction Problems.
In AAAI 90: Proceedings of the Eighth National Conference on Artificial Intelligence,
pp. 49. Available from: http://www.aaai.org/Library/AAAI/1990/aaai90-001.
php.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W. H. Freeman, San Francisco, CA.
Gottlob, G., Leone, N., & Scarcello, F. (2002). Hypertree decompositions and tractable
queries. Journal of Computer and System Sciences, 64 (3), pp. 579627. doi:10.
1006/jcss.2001.1809.
Green, M. J., & Cohen, D. A. (2003). Tractability by approximating constraint languages.
In CP 03: Proceedings of the 9th International Conference on Principles and Practice
of Constraint Programming, Vol. 2833 of Lecture Notes in Computer Science, pp. 392
406. Springer-Verlag. doi:10.1007/978-3-540-45193-8_27.
Grohe, M. (2006). The structure of tractable constraint satisfaction problems. In MFCS 06:
Proceedings of the 31st Symposium on Mathematical Foundations of Computer Science, Vol. 4162 of Lecture Notes in Computer Science, pp. 5872. Springer-Verlag.
doi:10.1007/11821069_5.
77

fiCohen, Cooper, Creed, Marx & Salamon

Grohe, M. (2007). The complexity of homomorphism and constraint satisfaction problems
seen from the other side. Journal of the ACM, 54 (1), pp. 124. doi:10.1145/
1206035.1206036.
Gyssens, M., Jeavons, P. G., & Cohen, D. A. (1994). Decomposing constraint satisfaction
problems using database techniques. Artificial Intelligence, 66 (1), pp. 5789. doi:
10.1016/0004-3702(94)90003-5.
Jeavons, P., Cohen, D., & Gyssens, M. (1997). Closure properties of constraints. Journal
of the ACM, 44 (4), pp. 527548. doi:10.1145/263867.263489.
Jeavons, P. G., & Cooper, M. C. (1995). Tractable constraints on ordered domains. Artificial
Intelligence, 79 (2), pp. 327339. doi:10.1016/0004-3702(95)00107-7.
Jegou, P. (1993). Decomposition of domains based on the micro-structure of finite
constraint-satisfaction problems. In AAAI 93: Proceedings of the Eleventh National Conference on Artificial Intelligence, pp. 731736. Available from: http:
//www.aaai.org/Library/AAAI/1993/aaai93-109.php.
Marx, D. (2010a). Can you beat treewidth?. Theory of Computing, 6 (1), pp. 85112.
doi:10.4086/toc.2010.v006a005.
Marx, D. (2010b). Tractable hypergraph properties for constraint satisfaction and conjunctive queries. In STOC 10: Proceedings of the 42nd ACM symposium on Theory of
computing, pp. 735744. ACM. doi:10.1145/1806689.1806790.
Regin, J.-C. (1994). A filtering algorithm for constraints of difference in CSPs. In AAAI 94:
Proceedings of the Twelfth National Conference on Artificial Intelligence, Vol. 1, pp.
362367. Available from: http://www.aaai.org/Library/AAAI/1994/aaai94-055.
php.
Robertson, N., & Seymour, P. D. (1986). Graph minors. V. Excluding a planar graph. Journal of Combinatorial Theory, Series B, 41, pp. 92114. doi:10.1016/0095-8956(86)
90030-4.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). Handbook of Constraint Programming.
Foundations of Artificial Intelligence. Elsevier.
Salamon, A. Z., & Jeavons, P. G. (2008). Perfect constraints are tractable. In CP 08:
Proceedings of the 14th International Conference on Principles and Practice of Constraint Programming, Vol. 5202 of Lecture Notes in Computer Science, pp. 524528.
Springer-Verlag. doi:10.1007/978-3-540-85958-1_35.
van Hoeve, W. J. (2001). The alldifferent Constraint: A Survey. In Proceedings of the 6th
Annual Workshop of the ERCIM Working Group on Constraints. Available from:
http://arxiv.org/abs/cs/0105015v1.
Weigel, R., & Bliek, C. (1998). On reformulation of constraint satisfaction problems. In
ECAI 98: Proceedings of the 13th European Conference on Artificial Intelligence, pp.
254258.

78

fi