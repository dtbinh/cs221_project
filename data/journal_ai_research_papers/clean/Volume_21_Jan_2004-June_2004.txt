Journal of Artificial Intelligence Research 21 (2004) 471-497

Submitted 11/03; published 04/04

Phase Transitions and Backbones of
the Asymmetric Traveling Salesman Problem
Weixiong Zhang

ZHANG @ CSE . WUSTL . EDU

Department of Computer Science and Engineering
Washington University in St. Louis
St. Louis, MO 63130, U.S.A.

Abstract
In recent years, there has been much interest in phase transitions of combinatorial problems.
Phase transitions have been successfully used to analyze combinatorial optimization problems,
characterize their typical-case features and locate the hardest problem instances. In this paper, we
study phase transitions of the asymmetric Traveling Salesman Problem (ATSP), an NP-hard combinatorial optimization problem that has many real-world applications. Using random instances
of up to 1,500 cities in which intercity distances are uniformly distributed, we empirically show
that many properties of the problem, including the optimal tour cost and backbone size, experience
sharp transitions as the precision of intercity distances increases across a critical value. Our experimental results on the costs of the ATSP tours and assignment problem agree with the theoretical
result that the asymptotic cost of assignment problem is  as the number of cities goes to infinity. In addition, we show that the average computational cost of the well-known branch-and-bound
subtour elimination algorithm for the problem also exhibits a thrashing behavior, transitioning from
easy to difficult as the distance precision increases. These results answer positively an open question regarding the existence of phase transitions in the ATSP, and provide guidance on how difficult
ATSP problem instances should be generated.

1. Introduction and Overview
Phase transitions of combinatorial problems and thrashing behavior similar to phase transitions
in combinatorial algorithms have drawn much attention in recent years (Gomes, Hogg, Walsh, &
Zhang, 2001; Hogg, Huberman, & Williams, 1996; Martin, Monasson, & Zecchina, 2001). Having
been extensively studied in the so-called spin glass theory (Mezard, Parsi, & Virasoro, 1987) in
physics, phase transition refers to a phenomenon when some system properties change rapidly and
dramatically when a control parameter undergoes a slight change around a critical value. Such
transitions appear only in large systems. A larger system usually exhibits sharper and more abrupt
phase transitions, leading to a phenomenon of crossover of the trajectories of phase transitions from
systems of the same type but with different sizes.
A daily-life example of phase transitions is water changing from ice (solid phase) to water
(liquid phase) to steam (gas phase) when temperature increases. It has been shown that many
combinatorial decision problems have phase transitions, including Boolean satisfiability (Cheeseman, Kanefsky, & Taylor, 1991; Mitchell, Selman, & Levesque, 1992; Hogg, 1995; Selman &
Kirkpatrick, 1996; Monasson, Zecchina, Kirkpatrick, Selman, & Troyansky, 1999), graph coloring (Cheeseman et al., 1991), and the symmetric Traveling Salesman Problem (deciding the existence of a complete tour of vising a given set of cities with a cost less than a specified value) (Cheeseman et al., 1991; Gent & Walsh, 1996a). Phase transitions can be used to characterize typical-case

 c 2004 AI Access Foundation. All rights reserved.

fiZ HANG

properties of difficult combinatorial problems (Gomes et al., 2001; Martin et al., 2001). The hardest
problem instances of most decision problems appear very often at the points of phase transitions.
Therefore, phase transitions have been used to help generate the hardest problem instances for testing and comparing algorithms for decision problems (Achlioptas, Gomes, Kautz, & Selman, 2000;
Cheeseman et al., 1991; Mitchell et al., 1992).
Another important and useful concept for characterizing combinatorial problems is that of the
backbone (Kirkpatrick & Toulouse, 1985; Monasson et al., 1999). A backbone variable refers to
a variable that has a fixed value among all optimal solutions of a problem; and all such backbone
variables are collectively referred to as the backbone of the problem. If a problem has a backbone
variable, an algorithm will not find a solution to the problem until the backbone variable is set to its
correct value. Therefore, the fraction of backbone variables, the percentage of variables being in the
backbone, reflects the constrainedness of the problem and directly affects an algorithm searching
for a solution. The larger a backbone, the more tightly constrained the problem becomes. As a
result it is more likely for an algorithm to set a backbone variable to a wrong value, which may
consequently require a large amount of computation to recover from such a mistake.
However, the research on the phase transitions and (particularly) backbones of optimization
problems is limited, which is in sharp contrast with the numerous studies of the phase transitions
and backbones of decision problems, represented by Boolean satisfiability (e.g., Cheeseman et al.,
1991; Mitchell et al., 1992; Hogg, 1995; Selman & Kirkpatrick, 1996; Monasson et al., 1999). An
early work on the symmetric TSP introduced the concept of backbones (Kirkpatrick & Toulouse,
1985). However, it has left the question whether there exists a phase transition of the TSP, the
optimization version of the problem to be specific, open since 1985. One of the best (rigorous)
phase-transition results was obtained on number partitioning (Borgs, Chayes, & Pittel, 2001), an
optimization problem. However, the phase transition analyzed by Borgs, Chayes, & Pittel (2001),
also experimentally by Gent & Walsh (1996b, 1998), is the existence of a perfect partition for a
given set of integers, which is in essence a decision problem. In addition, Gent & Walsh (1996b,
1998) also studied the phase transitions of the size of optimal 2-way partition. The relationship
between the phase transitions of satisfiability, a decision problem, and maximum satisfiability, an
optimization problem, was studied by Zhang (2001). It was experimentally shown that the backbone
of maximum Boolean satisfiability also exhibits phase transitions, emerging from nonexistence to
almost full size abruptly and dramatically. In addition, the relationship between backbones and
average-case algorithmic complexity has also been considered (Slaney & Walsh, 2001).
In this paper, we investigate the phase transitions of the asymmetric Traveling Salesman Problem. The Traveling Salesman Problem (TSP) (Gutin & Punnen, 2002; Lawler, Lenstra, Kan, &
Shmoys, 1985) is an archetypical combinatorial optimization problem and one of the first NP-hard
problems studied (Karp, 1972). Many concepts, such as backbone (Kirkpatrick & Toulouse, 1985),
and general algorithms, such as linear programming (Dantzig, Fulkerson, & Johnson, 1959), branchand-bound (Little, Murty, Sweeney, & Karel, 1963), local search (Lin & Kernighan, 1973) and
simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) were first introduced and studied using
the TSP. The problem is also very often a touchstone for combinatorial algorithms. Furthermore,
the fact that many real-world problems, such as scheduling and routing, can be cast as TSPs has
made the problem of practical importance. In this paper, we consider the asymmetric TSP (ATSP),
where a distance from one city to another may not be necessarily the same as the distance on the
reverse direction. The ATSP is more general and most ATSPs are more difficult to solve than their
symmetric counterparts (Johnson, Gutin, McGeoch, Yeo, Zhang, & Zverovitch, 2002).
472

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

Using the general form of the problem, i.e., the ATSP, we provide a positive answer to the longstanding open question posted by Kirkpatrick & Toulouse (1985) regarding the existence of phase
transitions in the problem, and disapprove the claim made by Kirkpatrick & Selman (1994) that the
Traveling Salesman Problem does not have a clear phase transition.
Specifically, using uniformly random problem instances of up to 1,500 cities, we empirically
reveal that the average optimal tour length, the accuracy of the most effective lower-bound function for the problem (the assignment problem, see Martello & Toth (1987)), and the backbone of
the ATSP undergo sharp phase transitions. The control parameter is the precision of intercity distances which is typically represented by the maximum number of digits for the distances. Note that
these results are algorithm independent and are properties of the problem. Furthermore, we show
that the average computational cost of the well-known branch-and-bound subtour elimination algorithm (Balas & Toth, 1985; Bellmore & Malone, 1971; Smith, Srinivasan, & Thompson, 1977) for
the ATSP exhibits a phase-transition or thrashing behavior in which the computational cost grows
abruptly and dramatically from easy to difficult as the distance precision increases. Our results lead
to a practical guidance on how to generate large, difficult random problem instances for the purpose
of algorithm comparison.
It is worthwhile to mention that besides the results by Kirkpatrick & Toulouse (1985) there
are three additional pieces of early empirical work related to the phase transitions of the Traveling
Salesman Problem. The research by Zhang & Korf (1996) investigated the effects of two different distance distributions on the average complexity of the subtour elimination algorithm for the
asymmetric TSP. The main result is that the average complexity of the algorithm is controlled by
the number of distinct distances of a random asymmetric TSP. We will extend this result further
in Section 6. However, we need to caution that these results are algorithm specific, which may
not necessarily reflect intrinsic features of the underlying problem. The research on phase transitions by Cheeseman, Kanefsky, & Taylor (1991) studied the decision version of the symmetric
TSP (Cheeseman, 1991). A more thorough investigation on this issue was also carried out (Gent
& Walsh, 1996a). Specifically, Gent & Walsh (1996a) analyzed the probability that a tour whose
length is less than a specific value exists for a given random symmetric euclidean TSP, showing that
the probability has a one-to-zero phase transition as the length of the desired tour increases. Note
that the phase-transition results by Cheeseman, Kanefsky, & Taylor (1991, 1996a) do not address
the open question by Kirkpatrick & Toulouse (1985) which is about the optimization version of the
problem. The experimental results by Gent & Walsh (1996a) also showed that the computational
cost of a branch-and-bound algorithm, which unfortunately was not specified in the paper, exhibits
an easy-hard-easy pattern.
The paper is organized as follows. In Section 2, we describe the ATSP and a related problem
called assignment problem (AP). We then investigate the parameter that controls phase transitions
in Section 3, and study various phase transitions of the ATSP in Section 4. In Section 5 we analyze
asymptotic ATSP tour cost, AP cost and the precision of AP as a heuristic function for solving the
ATSP as the number of cities grows to a large number. In Section 6, we describe the well-known
subtour elimination algorithm for the ATSP, and analyze the thrashing behavior of this algorithm.
We discuss related work in Section 7 and finally conclude in Section 8.
473

fiZ HANG

2. The Asymmetric Traveling Salesman Problem and Assignment Problem
Given  cities and the distance or cost between each pair of cities, the Traveling Salesman Problem
(TSP) is to find a minimum-cost tour that visits each city once and returns to the starting city (Gutin
& Punnen, 2002; Lawler et al., 1985). When the distance from city 	 to city 
 is the same as the
distance from 
 to 	 , the problem is the symmetric TSP (STSP). If the distance from city 	 to city

 is not necessarily equal to the reverse distance, the problem is the asymmetric TSP (ATSP). The
ATSP is more difficult than the STSP, with respect to both optimization and approximation (Johnson
et al., 2002). The TSPs are important NP-hard problems (Garey & Johnson, 1979; Karp, 1972) and
have many practical applications. Many difficult combinatorial optimization problems, such as
vehicle routing, workshop scheduling and computer wiring, can be formulated and solved as the
TSPs (Gutin & Punnen, 2002; Lawler et al., 1985).
The ATSP can be formulated as an integer linear programming problem. Let ff be the set of
 cities, fi the set of all pairs of cities, and  the distance or cost matrix specifying the
distance of each pair of cities. The following integer linear programming formulation of the ATSP
is well known:

fi !"$#&%(')

+* 

,.-/021

(1)

subject to

) )
+32? 73 ?

89
&:;ff&<
) -  6571
+324
8/	>:;ff <
) -=6571
.324
- A@CB  BD 571E8FHGIff"1J$M
K LN<
- PORQ 1

8S	T1U
 :Vff

(2)
(3)
(4)
(5)

where variables -  take values zero or one, and -  W5 if and only if arc +	T1U
N is in the optimal
tour, for 	 and 
 in ff . Constraints (2) and (3) restrict the in-degree and out-degree of each city to be
one, respectively. Constraints (4) impose the subtour elimination constraints so that only complete
tours are allowed.
The ATSP is closely related to the assignment problem (AP) (Martello & Toth, 1987), which is
to assign to each city 	 another city 
 , with the distance from 	 to 
 as the cost of the assignment,
such that the total cost of all assignments is minimized. The AP is a relaxation of the ATSP in which
the assignments need not form a complete tour. In other words, by removing the subtour elimination
constraints (4) from the above representation, we have an integer linear programming formulation
of the AP. Therefore, the AP cost is a lower bound on the ATSP tour cost. If the AP solution happens
to be a complete tour, it is also a solution to the ATSP. While the ATSP is NP-hard, the AP can be
solved in polynomial time, in X&+NY to be precise (Martello & Toth, 1987).

3. The Control Parameter
Consider two cases of the ATSP, one with all the intercity distances being the same and the other
with every intercity distance being distinct. In the first case, every complete tour going through all
474

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

 cities is an optimal tour or a solution to the ATSP. There is no backbone variable since removing
one edge from an optimal solution will not prevent finding another optimal solution. The ATSP in
this case is easy; finding an optimal solution does not require any search at all. In addition, the cost
of the optimal solution is also a constant, which is  times of the intercity distance. In the second
case where all distances are distinct, every complete tour covering all  cities has a high probability
to have a distinct cost. Therefore, an arc in the optimal solution is almost surely a backbone variable
and removing it may destroy the optimal solution. In addition, it is expected to be difficult to find
and verify such an optimal solution among a large number of suboptimal solutions in this case.
Therefore, there are significant differences between the above two extreme cases. One of the
most important differences is the number of distinct distances in the distance matrix  . More
precisely, many important characteristics of the random ATSP, including the size of backbone and
complexity, are determined by the fraction of distinct distances among all distances. We denote the
fraction of distinct distances in distance matrix  as Z . We are particularly interested in determining how Z affects the characteristics of the ATSP when it gradually increases from zero, when all
distances are the same, to one, when all distances are distinct.
In practice, however, we do not directly control the number or the fraction of distinct distances
in matrix  . Besides the actual structures of the layouts of the cities, the precision of the distances
affects the number of distinct distances. The precision of a number is usually represented by the
maximal number of digits allowed for the number. This is even more so when we use a digital
computer to solve the ATSP, which typically has 32 bits (or 4 bytes) for integers or 64 bits (or 8
bytes) for double precision real numbers. As a result, the number of digits for distances is naturally
a good choice for the control parameter.
The effect of a given number of digits on the fraction of distinct distances in distance matrix
 is relative to the problem size  . Consider a matrix  with distances uniformly chosen from
integers [ Q 1571]\N1.^.^.^71T_ D 5` , where the range _ is determined by the number of digits a . For a fixed
number of digits a , the fraction of distinct distances of a larger matrix  is obviously smaller than
that of a smaller  . Therefore, the control parameter for the fraction Z of distinct distances of 
must be a function of the number of digits a and the number of cities  , which we denote as ZS+b1]a. .
To find the control parameter, consider the number of distinct distances in  for a given integer
range _ . The problem of finding the number of distinct distances is equivalent to the following
bin-ball problem. We are given c balls and _ bins, and asked to place the balls into the bins.
Each ball is independently put into one of the bins with an equal probability. We are interested in

the fraction of bins that are not empty after all the placements. Here, for asymmetric TSP c
Fd D  balls correspond to the total number of nondiagonal distances of matrix  , and _ bins
represent the possible integers to choose from. Since each ball (distance) is thrown independently
and uniformly into one of the _ bins (integers), the probability that one bin is not empty after
throwing c balls is 5 D e5 D 5gf_hi . The expected number of occupied bins (distinct distances) is
simply _Mj5 D e5 D 5gf_h ilk . Thus, the expected fraction of distinct distances in matrix  is
_ j 5 D e5 D 5gf_h i k
(6)
c
Note that if c
of the
5 as _uswv , since in this case the expectation
mon
number of distinct distances approaches c . On the other hand, when _ is fixed, Zp+b1]aUqxs Q
when c or  goes to infinity, since all of a finite number of _ bins will be occupied by an infinite
mon

pZ +b1]a.Uqr
mon
or  is fixed, Zp+b1]aUqts

number of balls in this case.
475

fiZ HANG

Following convention in practice, we use decimal values for distances. Thus _yz5 Q|{ , where
is the number of digits for distances. It turns out that if we plot ZS+b1]a. against a.f}~2UU,+ , it
will have relatively the same scale for different problem sizes  . This is shown in Figure 1(a). This

means that the scaling function for the effective number of digits is b+h}~2U + . Function
a.f}~2 U + is thus the effective number of digits that controls the fraction of distinct distances in
matrix  , which we denote as x+b1]a . This also means that to have the same effective number
of digits  on two different problem sizes, say   and  with    , the range _ should be
d
d
different. On these two problems, _ needs to be 7  and S , respectively, giving 9   r .
d
d
We need to point out that the integer range _ can also be represented by a number in other
bases, such as binary. Which base to use will not affect the results quantitatively, but introduces
a constant factor to the results. In fact, since alW}~2 U _h , where _ is the range of integers to
be chosen, t+b1]a.hya.f}~2 U +u}~2,p_h , which is independent of the base of the values for
intercity distances.
It is interesting to note that, controlled by the effective number of digits a.f}~2U,+ , the fraction
of distinct entities Z has a property similar to a phase transition, also shown in Figure 1(a). The larger
the problem, the sharper the transition, and there exists a crossover point among the transitions of
problems with different sizes. We may examine this phase-transition phenomenon more closely
using finite-size scaling. Finite-size scaling (Barber, 1983; Wilson, 1979) is a method that has
been successfully applied to phase transitions in similar systems of different sizes. Based on finitesize scaling, around a critical parameter (temperature) . , problems of different sizes tend to be
indistinguishable except for a change of scale given by a power law in a characteristic length, which
 , where  is the problem size and  the exponent of the
is typically in the form of  D ]
rescaling factor. Therefore, finite-size scaling characterizes a phase transition precisely around the
critical point  of the control parameter as the problem scales to infinity. However, our analysis
revealed that the scaling factor has a large exponent of 9 (Zhang, 2003), indicating that the phase
transitions in Figure 1(a) does not exactly follow the power law finite-size scaling.
To find the correct rescaled control parameter, we reconsider (6). As sv and distance range
_ grows with problem size  , i.e., _sv as ;sv , we can rewrite (6) as

a

2A }|%(#*  A

mon

ZS+b1]a.Uq


%|# 
 }|A
c

_

c

_


 
5 D j e5 D 5gf_h  k i


j 5 D  i  
k 1

(7)





where the second equation follows }|%|#  h e5 D 5gf_h
   . Since our underlying control
parameter is the number of digits, alW}~2U2_h , we take -W}~2U2_hfc . Asymptotically as
Rsv , c d , which leads to -}|~2 U _h D \}~2 U ++ D \,N}~2 U + . Using - , we
rewrite (7) as

2A }|%(#*  A

mon

ZS+b1]a.UqF5 Q7 j 5 D 

U2

k

(8)

The rescaled control parameter as Ms v for the expected number of distinct distances in  is
+ D \,N}~2 U + . Therefore, the critical point is 2 and the rescaling factor is }~2 U + . The rescaled
phase transition is shown in Figure 1(b), which plots ZS+b1g+ D \,N}~2JU,+ .
Note that the number of digits used for intercity distances is nothing but a measurement of the
precision of the distances. The larger the number of digits, the higher the precision becomes. This
476

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

average fraction of distinct numbers

(a) fraction of distinct numbers
1
0.8
0.6
0.4
0.2
0

average fraction of distinct numbers

n = 100
n = 500
n = 1,000
n = 1,500

0.5

1
1.5
2
2.5
3
3.5
effective number of digits
(b) rescaled fraction of distinct numbers
1.0
n = 100
n = 500
n = 1,000
0.8
n = 1,500

0.6

0.4
0.2

0

5

4 3 2 1
0
1
2
rescaled effective number of digits

3

Figure 1: (a) Average fraction of distinct distances in matrix  , Zp+b1]a , controled by the effective

number of digits, aS}~2U  + , for ;65 Q2Q 1] Q2Q 15 Q2Q2Q and 5 Q2Q . (b) Average Zp+b1]a
after finite-size scaling, with scaling factor + D .]N}|~2 U + , where t\ .

agrees with the common practice of using more effective digits to gain precision. Therefore, the
control parameter is in turn determined by the precision of intercity distances.
Finally, it is important to note that even though the discussion in this section focused on asymmetric cost matrices and the ATSP, the arguments apply to symmetric distance matrices and the
477

fiZ HANG

symmetric TSP as well. That is, with c revised to +d D f7\ , asymptotically as _ and  goes to
infinity, }|~29U,cP\}~2U,+ , so that + D \,N}|~29U,+ is also a rescaled control parameter for
the number of distinct distances in symmetric cost matrices.

4. Phase Transitions
With the control parameter, the effective number of digits t+b1]a. for intercity distances, identified, we are now in a position to investigate possible phase transitions in the ATSP and the related
assignment problem.
To set forth to investigate these phase transitions, we generated and studied uniformly random
problem instances with 100-, 200-, 300- upto 1,000-cities and 1,500-cities. Although we have
results from 100-, 200-, 300-, up to 1,000-city as well as 1,500-city problems, to make the result
figures readable, we only use the data from 100-, 500-, 1,000- and 1,500-city problems to report the
results. For the problem instances considered, intercity distances are independently and uniformly
chosen from [ Q 1571]\N1.^.^.^71T_ D 5` for a given range _ , which is controlled by the number of digits
a . We varied a from 1.0 to 6.0 for instances with up to 1,000-cities and from 1.0 to 6.5 for instances
with 1,500-cities. The digits are incremented by 0.1, i.e., we used a57 Q 157|57157\N1.^.^.^ .
4.1 Phase Transitions in the ATSP
We are particularly interested in possible phase transitions in the ATSP cost, phase transitions of
backbones and phase transitions of the numbers of ATSP tours. The results on backbone can shed
some light on the intrinsic tightness of the constraints among the cities as the precision of distance
measurement changes.
4.1.1 T HE ATSP T OUR C OST
There is a phase transition in the ATSP tour cost, fi ! , under the control parameter  , the
effective number of digits for intercity distances. Figure 2(a) shows the results on 100-, 500-, 1,000and 1,500-city ATSP instances, averaged over 10,000 instances for each data point. The reported
tour costs are obtained by dividing the integer ATSP tour costs by I_ D 5g , where  is the
number of cities and _ the range of intercity costs. Equivalently, an intercity distance was virtually
n
converted to a real value in Q 15q .
As shown, the ATSP tour cost increases abruptly and dramatically as the effective number of digits increases, exhibiting phase transitions. The transitions become sharper as the problem becomes
larger, and there exist crossover points among curves from different problem sizes. By finite-size
scaling, we further determine the critical value of the control parameter at which the phase transitions occur. Following the discussion in Section 3, the scaling factor has a form of + D ]N}~2 U + .
Our numerical result indicated that   57 Q \A Q  Q2Q . We thus use   y5 to show the result in
Figure 2(b). It is worthwhile to mention that the AP cost follows almost the same phase-transition
pattern of the ATSP tour cost in Figure 2.
4.1.2 BACKBONE

AND

N UMBER

OF

O PTIMAL S OLUTIONS

We now turn to the backbone of the ATSP, which is the percentage of directed arcs that appear in
all optimal solutions. The backbone also exhibits phase transitions as the effective number of digits
for distances increases. The result is included in Figure 3(a), where each data point is averaged
478

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

(a) ATSP tour cost

average ATSP tour cost

1.6
1.4
1.2
1
0.8
0.6
100city
500city
1,000city
1,500city

0.4
0.2
0

0.5

1
1.5
2
effective number of digits
(b) rescaled ATSP tour cost

2.5

normalized average ATSP tour cost

1
0.8
0.6

0.4
100city
500city
1,000city
1,500city

0.2

0

2
1
0
1
2
3
rescaled effective number of digits

Figure 2: (a) Average optimal ATSP tour cost. (b) Scaled and normalized average optimal tour cost,
with rescaling factor + D ,]N}~2U,+ and >5 .

over 10,000 problem instances. The rescaled result is shown in Figure 3(b), where the critical point
=5 . Interestingly, the phase-transition pattern of the backbone follows a similar trend as that
of the fraction of distinct entities in the distance matrix, shown in Figure 1. In addition, the phasetransition patterns of tour costs and backbones are similar, which will be discussed in Section 4.3.
479

fiZ HANG

(a) fraction of backbone

average fraction of backbone

1
0.8
0.6
0.4
100city
500city
1,000city
1,500city

0.2
0

0.5

1
1.5
2
2.5
effective number of digits
(b) rescaled fraction of backbone

average fraction of backbone

1
0.8
0.6

0.4
100city
500city
1,000city
1,500city

0.2

0

2

1
0
1
2
3
rescaled effective number of digits

Figure 3: (a) Average fraction of backbone variables. (b) Rescaled average backbone fraction, with
rescaling factor + D ]N}~2 U + and t5 .

The fraction of backbone variables is related to the number of optimal solutions of a problem.
We thus examined the total number of optimal solutions of the ATSP. This was done on small ATSPs,
from 10 cities to 150 cities, as finding all optimal solutions on larger problems is computationally
too expensive. The results are averaged over 100 trials for each data point. As shown in Figure 4,
where the vertical axes are in logarithmic scale, the number of optimal tours also undergoes a phase
480

fiP HASE T RANSITIONS

6

AND

BACKBONES

ATSP

(a) number of optimal solutions

10
average number of optimal tours

OF THE

20city
30city
50city
100city
150city

4

10

2

10

0

10

6

0.5

1
1.5
2
2.5
3
effective number of bits
(b) rescaled number of optimal tours

average number of optimal tours

10

20city
30city
50city
100city
150city

4

10

2

10

0

10

1
0
1
2
rescaled effective number of digits

Figure 4: (a) Average number of optimal ATSP tours. (b) Rescaled average number of optimal
ATSP tours, with rescaling factor + D ,]N}~2 U + and >6572 Q  Q2Q, .

transition, from exponential to a constant, as the number of digits increases. Note that when the
number of digits is small, it is very costly to find all optimal solutions, even on these relatively small
problems.
The fraction of backbone variables captures in essence the tightness of the constraints among
the cities. As more intercity distances become distinct, the number of tours of distinct lengths
481

fiZ HANG

increases. Consequently, the number of optimal solutions decreases and the fraction of backbone
variables grows inversely. When more arcs are part of the backbone, optimal solutions become
more restricted. As a result, the number of optimal solutions decreases. As the fraction of backbone
variables increases and approaches one, the number of optimal solutions decreases and becomes
one as well, which typically makes the problem of finding an optimal solution more difficult.
4.1.3 E XISTENCE OF H AMILTONIAN C IRCUIT

WITH

Z ERO - COST E DGES

When the precision of intercity distances is low, it is likely that the ATSP tour, a complete tour of
minimal cost among all complete tours, has a cost of zero, meaning that there exists an Hamiltonian
circuit consisting of zero-cost arcs. It is a decision problem to determine if an Hamiltonian circuit
exists in a given ATSP. We examined this decision problem using the same set of 10,000 problem
instances used in Figures 2 and 3. The result is shown in Figure 5. Notice that although it follows
the same rescaling formula of + D 7]N}~2 U + , the critical point of the transition,    Q  2  ,
is different from the critical point of gu5 for the phase transitions of backbones and ATSP tour
cost, as shown in Figures 2 and 3.
4.2 Quality of the AP Lower-bound Function
The existence of Hamiltonian circuits of zero-cost arcs also indicates that when the number of digits
for intercity distances is very small, for example, less than 1.9 (or _ 7Q ) for ;571] Q2Q , both the
AP and ATSP costs are zero, meaning that these two costs are the same as well. It is useful to know
how likely the AP cost is equal to the ATSP tour cost; the answers to this issue constitutes the first
step to the elucidation of the accuracy of the AP lower-bound cost function.
Given a random distance matrix  , how likely is it that an AP cost will be the same as the ATSP
tour cost as the effective number of digits  increases? We answer this question by examining
the probability that an AP cost fi ! is equal to the corresponding ATSP cost fiP ! as
 increases. Figure 6(a) shows the results on 100-, 500-, 1,000- and 1,500-city ATSP instances,
averaged over the same set of 10,000 instances for Figure 2 for each data point. As shown in
the figure, the probability that fi !Pfib l also experiences abrupt and dramatic phase
transitions. Figure 6(b) shows the phase transitions after finite-size scaling, with critical point   
57|5   Q  Q2Q  .
The results in Figure 6 also imply that the quality of the AP lower-bound function degrades
as the distance precision increases. The degradation should also follow a phase-transition process.
This is verified by Figure 7, using the data from the same set of problem instances. Note that the
critical point of the phase transition for the accuracy of AP is    Q   , which is different from the
critical point >57|5  for the phase transition of the probability that fi !"$fi ! .
4.3 How Many Phase Transitions?
So far, we have seen many phase transitions on different features of the ATSP and its related assignment problem. Qualitatively, all these phase transitions follow the same transition pattern, meaning
that they can all be captured by the same finite-size rescaling formula of + D U]N}|~2 U + , where
  is a critical point depending on the particular feature of interest.
It is interesting to note that the critical points for the phase transitions of the ATSP tour costs and
fractions of backbone variables are all at x5 . A close examination also indicates that these two
phase transitions follow almost the same phase transition, as shown in Figure 8, where the rescaled
482

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

(a) probability of Hamiltonian circuit
probability of Hamiltonian circuit

1

100city
500city
1,000city
1,500city

0.8
0.6
0.4
0.2

probability of Hamiltonian circuit

0

0.5
1
1.5
effective number of digits
(b) rescaled prob. of Hamiltonian circuit
1
100city
500city
1,000city
0.8
1,500city

0.6

0.4
0.2

0

1 0.5
0
0.5
1
1.5
rescaled effective number of digits

Figure 5: (a) Probability of the existence of Hamiltonian circuits with zero cost arcs. (b) Rescaled
probability of zero-cost Hamiltonian circuits, with rescaling factor + D TN}~2 U + and
=x Q  2  .

curves for the ATSP tour cost and the fraction of backbone variables are drawn from 1,500-city
ATSP, averaged over 10,000 problem instances.
483

fiZ HANG

normalizedaverage prob. AP(D)=ATSP(D)

average probability AP(D) = ATSP(D)

(a) probability AP(D) = ATSP(D)
1

100city
500city
1,000city
1,500city

0.8
0.6
0.4
0.2
0

0.5

1
1.5
2
2.5
effective number of digits
(b) rescaled probability AP(D)=ATSP(D)

1

100city
500city
1,000city
1,500city

0.8
0.6

0.4
0.2

0
3

2
1
0
1
2
rescaled effective number of digits

3

Figure 6: (a) Average probability that fi !6fiol . (b) Average probability after finitesize scaling, with rescaling factor + D ]N}~2 U + and >657|5   Q  Q2Q  .

Except the close similarity of the phase transitions of the ATSP tour cost and the fraction of
backbone variables, the other phase transitions all have different critical points, indicating that they
undergo the same type of phase transitions at different ranges.
484

finormalized ave. relative error of AP(D)

average relative error of AP(D) to ATSP(D)

P HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

(a) precision of AP function
1.4

100city
500city
1,000city
1,500city

1.2
1
0.8
0.6
0.4
0.2
0

0.5

1
1.5
2
2.5
effective number of digits
(b) rescaled accuracy of AP function

1
0.8
0.6
0.4
100city
500city
1,000city
1,500city

0.2
0
2

1
0
1
2
3
rescaled effective number of digits

Figure 7: (a) Average accuracy of AP lower-bound function, measured by the error of AP cost
relative to ATSP cost. (b) normalized and rescaled average accuracy, with rescaling factor
+ D =]N}~2=U,+ and > Q   .

5. Asymptotic ATSP Tour Length and AP Precision
As a by-product of the phase-transition results, we now provide numerical values of the ATSP
cost, the AP cost and its accuracy, asymptotically when the number of cities grows. We attempt to
485

finormalized cost and fraction of backbone

Z HANG

1
0.8
0.6
0.4
0.2
0

tour cost
backbone
2

1
0
1
2
3
rescaled effective number of digits

Figure 8: Simultanous examination of the phase transitions of backbone and ATSP tour cost on
1,500-city problems, all rescaled with + D 5gN}~2 U + .

extend the previous theoretical results on the AP cost, which was shown to asymptotically approach
 d f  (Aldous, 2001; Mezard & Parsi, 1987), and the observations that the relative error of the AP
lower bounds decreases as the problem size increases (Balas & Toth, 1985; Smith et al., 1977).
Not every real number can be represented in a digital computer. Thus, it is infeasible to directly
examine a theoretical result on reals using a digital computer. For our purpose, on the other hand, the
phase-transition results indicate that when the precision of the intercity distances is high enough,
all the quantities of the ATSP we have examined, including the ATSP cost, the AP cost and its
precision as a lower-bound cost function, as well as the backbone, are relatively stable, in the sense
that they do not change significantly even when the precision of intercity distances increases further.
Therefore, it is sufficient to use a high distance precision to experimentally analyze the asymptotic
properties of the ATSP cost and other related quantities.
We need to be cautious in selecting the number of digits for intercity distances. As we discussed
in Section 3, the same number of digits for intercity distances gives rise to different effective numbers of digits on problems of different sizes. Furthermore, the phase transition results in Section 4
indicate that the effective numbers of digits must be scaled properly in order to have the same effect
on problems of different sizes when we investigate an asymptotic feature.
Therefore, in our experiments, we fixed the scaled effective number of digits for intercity distances, + D ]N}~2 U + , to a constant. Based on our phase-transition results, especially that on the
control parameter in Figure 1, we chose to take + D \,N}~2 U + a constant of 2.1, for two reasons.
First, + D \,N}~2 U +"\N|5 is sufficiently large so that almost all distances are distinct, regardless
of problem size, and the quantities we will examine will not change substantially after the finite-size
scaling. Secondly, + D \,N}~2NU,+bM\N|5 is relatively small so that we can experiment on problems
of large sizes. To save memory as much as possible, the intercity distances are integers of 4 bytes
in our implementation of the subtour elimination algorithm. Thus the number of digits must be less
486

fiP HASE T RANSITIONS

n
200
400
600
800
1,000
1,200
1,400
1,600
2,000
2,200
2,400
2,600
2,800
3,000

digits
6.7021
7.3041
7.6563
7.9062
8.1000
8.2584
8.3923
8.5082
8.7021
8.7848
8.8604
8.9299
8.9943
9.0542

AND

AP cost
1.63533  0.00254
1.63942  0.00180
1.64072  0.00146
1.64227  0.00125
1.64297  0.00114
1.64284  0.00104
1.64313  0.00096
1.64319  0.00090
1.64382  0.00082
1.64372  0.00077
1.64360  0.00074
1.64429  0.00071
1.64382  0.00068
1.64421  0.00065

BACKBONES

OF THE

ATSP

ATSP cost
relative AP error (%)
1.64302  0.00254
0.46817  0.00970
1.64311  0.00180
0.22485  0.00468
1.64314  0.00145
0.14765  0.00317
1.64407  0.00125
0.10904  0.00237
1.64441  0.00114
0.08754  0.00191
1.64402  0.00105
0.07187  0.00158
1.64413  0.00096
0.06148  0.00139
1.64405  0.00090
0.05276  0.00117
1.64451  0.00082
0.04231  0.00095
1.64434  0.00077
0.03813  0.00085
1.64417  0.00073
0.03477  0.00079
1.64481  0.00071
0.03234  0.00074
1.64430  0.00068
0.02966  0.00068
1.64463  0.00065
0.02548  0.00061

Table 1: Numerical results on AP cost, the ATSP cost and AP error relative to the ATSP cost, in
percent. The cost matrices are uniformly random. Each data point is averaged over 10,000
problem instances. In the table,  is the number of cities, digits is the number of digits
for intercity distances, and all numerical error bounds represent 95 percent confidence
intervals.

than 9.4 without causing an overflow in the worst case. Using + D \,N}~2U2+\N|5 , we can go
up to roughly 3,000-city ATSPs.
Table 1 shows the experimental results, with up to 3,000 cities, on the average AP cost, the
ATSP tour cost, and accuracy of the AP cost function in the error of AP cost relative to the ATSP
cost. The results are averaged over 10,000 instances for each problem size. Based on the results,
the AP cost approaches to 1.6442 and the ATSP cost to 1.6446. Note that the experimental AP cost
of 1.6442 is very close to the theoretical asymptotic AP cost of  dgf  57 2  (Aldous, 2001;
Mezard & Parsi, 1987). In addition, the accuracy of AP function indeed improves as the problem
size increases, reduced to about 0.02548% for 3,000-city problem instances. This result supports
the previous observations (Balas & Toth, 1985; Smith et al., 1977).

6. Thrashing Behavior of Subtour Elimination
All the phase-transition results discussed in the previous section indicate that the ATSP becomes
more constrained and difficult as the distance precision becomes higher. In this section, we study
how a well-known algorithm for the ATSP, branch-and-bound subtour elimination (Balas & Toth,
1985; Bellmore & Malone, 1971; Smith et al., 1977), behaves. We separate this issue from the
phase transition phenomena studied before because what we will consider in this section is the behavior of a particular algorithm, which may not be necessarily a feature of the underlying problem.
Nevertheless, this is still an issue of its own interest because this algorithm is the oldest and is still
487

fiZ HANG

among the best known methods for the ATSP, and we hope that a better understanding of an efficient
algorithm for the ATSP can shed light on the typical case computational complexity of the problem.
6.1 Branch-and-bound Subtour Elimination
The branch-and-bound (BnB) subtour algorithm elimination (Balas & Toth, 1985; Bellmore & Malone, 1971; Smith et al., 1977) solves an ATSP in a state-space search (Pearl, 1984; Zhang, 1999)
and uses the assignment problem (AP) as a lower-bound cost function. The BnB search takes the
original ATSP as the root of the state space and repeats the following two steps. First, it solves the
AP of the current problem. If the AP solution is not a complete tour, it decomposes it into subproblems by subtour elimination that breaks a subtour by excluding some arcs from a selected subtour.
As a subproblem is more constrained than its parent problem, the AP cost to the subproblem must
be as much as that of the parent. This means that the AP cost function is monotonically nondecreasing. While solving the AP requires X&+NY computation in general, the AP to a child node can be
incrementally solved in X +Nd time based on the solution to the AP of its parent.
There are many heuristics for selecting a subtour to eliminate (Balas & Toth, 1985), and we use
the Carpaneto-Toth scheme (Carpaneto & Toth, 1980), or the CT scheme for short, in our algorithm.
One important feature of the CT scheme is that it generates no duplicate subproblem so that the
overall search space is a tree. One example of this scheme is shown in Figure 9. The AP solution
to the original ATSP contains two subtours that are in the root of the tree of the figure. The subtour
\ D  D \ is chosen to be eliminated, since it is shorter than the other subtour. We have two ways to
break the selected subtour, i.e., excluding directed arc \N1], or N1]\, . Assume that we first exclude
\N1], and then N1]\, , generating two subproblems, nodes fi and  in Figure 9. When generating
the second subproblem  , we deliberately include \N1], in its solution. By including the arc that
was excluded in the previous subproblem fi , we force to exclude in the current subproblem  all the
solutions to the original problem that will appear in fi , and therefore form a partition of the solution
space using fi and  . In general, let  be the excluded arc set, and  be the included arc set of the
problem to be decomposed. Assume that there are  arcs of the selected subtour, [   1  1.^.^.^1 . ` ,
d
that are not in  . The CT scheme decomposes the problem into  child subproblems, with the  -th
one having excluded arc set . and included arc set 9 , such that

N
F

;[   `,1
(9)
V;[   1.^.^.^g1     `,1 &571]\N1.^.^.^1J
Since   is an excluded arc of the  -th subproblem,  :!9 , and it is an included arc of the H5 -st
subproblem,  ;:F.  , a complete tour obtained from the  -th subproblem does not contain arc
  , while a tour obtained from the 5 -st subproblem must have arc   . Thus a tour from the  -th
subproblem cannot be generated from the &5 -st subproblem, and vice versa. In summary, the
state space of the ATSP under BnB using the CT subtour elimination scheme can be represented by
a tree without duplicate nodes.
In the next step, the algorithm selects as the current problem a new subproblem from the set of
active subproblems, which are the ones that have been generated but not yet expanded. This process
continues until there is no unexpanded problem, or all unexpanded problems have costs greater than
or equal to the cost of the best complete tour found so far.
Thanks to its linear-space requirement, we use depth-first branch-and-bound (DFBnB) in our
algorithm. DFBnB explores active subproblems in a depth-first order. It uses an upper bound  on
488

fiP HASE T RANSITIONS

1

4

5

6

AND

2

A

4

2

6

3

5

OF THE

ATSP

3
E={(3,2)}
I={(2,3)}

E={(2,3)}
I={}
1

BACKBONES

B
2

3 1
6

4
5
E={(3,2),(3,6)}
I={(2,3),(6,2)}

E={(3,2),(6,2)}
I={(2,3)}

C

D

2

3

6

6

2

3

4

1

5

4

1

5

Figure 9: DFBnB subtour elimination on the ATSP.
the optimal cost, whose initial value can be infinity or the cost of an approximate solution, such as
one obtained by Karps patching algorithm (Karp, 1979; Karp & Steele, 1985), which repeatedly
patches two smallest subtours into a big one until a complete tour forms. Starting at the root node,
DFBnB selects a recently generated node - to examine next. If the AP solution of - is a complete
tour, then - is a leaf node of the search tree. If the cost of a leaf node is less than the current upper
bound  ,  is revised to the cost of - . If - s AP solution is not a complete tour and its cost is greater
than or equal to  , - is pruned, because node costs are monotonic so that no descendant of - will
have a cost smaller than - s cost. Otherwise, - is expanded, generating all its child nodes. To find
an optimal goal node quickly, the children of - should be searched in an increasing order of their
costs. In other words we use node ordering to reduce the number of nodes explored. To speed up
the process of reaching a better, possibly optimal, solution, we also apply Karps patching algorithm
to the best child node of the current node.
Our algorithm is in principle the same as the algorithm by Carpaneto, DellAmico & Toth (1995),
which is probably the best known complete algorithm for the ATSP. The main difference between the
two is that, due to a consideration on space requirement, we use depth-first search while Carpaneto,
DellAmico & Toth (1995) used best-first search.
6.2 Thrashing Behavior
The average computational complexity of the BnB subtour elimination algorithm is determined by
two factors, the problem size, or the number of cities, and the number of digits used for intercity
distances. Figure 10 illustrates this average complexity, measured by the number of calls to the AP
function, in a logarithmic scale. The result is averaged over the same 10,000 problem instances for
each data point as used for the phase transitions studied in Section 4. Note that the number of AP
calls increases exponentially from small problems to large ones when they are generated using the
same number of digits for distances.
489

fiZ HANG

4

average number of AP calls

10

3

10

2

10

1

100city
500city
1,000city
1,500city

10

0

10

1

2

3
4
5
number of digits

6

Figure 10: Average computational complexity of the BnB subtour elimination algorithm.

To characterize the thrashing behavior of the algorithm, we normalize the result in Figure 10
in such a way that for a given problem size, the minimal and maximal AP calls among all problem
instances of the same size are mapped to zero and one, respectively, and the other AP calls are
proportionally adjusted to a ratio between 0 and 1. This allows us to compare the results from
different problem sizes in one figure. We also normalize the number of digits for distances by
problem size. The curves in Figure 11(a) follow a pattern similar to that of the phase transitions in
Section 4. The complexity of the subtour elimination algorithm increases with the effective number
of digits, and exhibits a thrashing behavior similar to phase transitions. Indeed, we can use finitesize scaling to capture the behavior as the problem size grows, as illustrated in Figure 11(b).
The results in Figure 11 and the phase-transition results of Section 4 indicate that the complexity
of the subtour elimination algorithm goes hand-in-hand with the accuracy of the AP function and the
constrainedness of the problem, which is determined by the portion of distinct entities of distance
matrix, which is in turn controlled by the precision of distances.
Similar results have been reported by Zhang & Korf (1996), where the effects of two different
distance distributions on the average complexity of the subtour elimination algorithm were analyzed to conclude that the determinant of the average complexity is the number of distinct distances
of a problem. The results of this section extend that by Zhang & Korf (1996) to different sizes
of problems and by applying finite-size scaling to capture the thrashing behavior as problem size
increases.
We need to contrast the experimental result in this section with the theoretical result on the
NP-completeness of the TSP of intercity distances 0 and 1. It has been known that the degenerated
TSP with distances 0 and 1 is still NP-complete (Papadimitriou & Yannakakis, 1993). On the
other hand, our experimental results showed that when intercity distances are small, relative to the
problem size, the ATSP is easy on average. Based on our experimental result, a large portion of the
problem instances with small intercity distances can be solved by the assignment problem or Karps
490

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

normalized average number of AP calls

normalized average number of AP calls

(a) normalized number of AP calls
1
0.8
0.6
0.4
100city
500city
1,000city
1,500city

0.2
0

0.5

1
1.5
2
2.5
effective number of digits
(b) rescaled normalized # of AP calls

1
0.8
0.6

0.4
100city
500city
1,000city
1,500city

0.2

0
4

3
2
1
0
1
rescaled effective number of digits

2

Figure 11: (a) Normalized average number of AP calls of DFBnB subtour elimination. (b) Scaled
average number of AP calls, with + D 2]N}|~2 U + , where   57   Q  Q \2 .

patching algorithm with no branch-and-bound search required. This discrepancy indicates that the
worst case of the problem is rare and most likely pathological.
491

fiZ HANG

7. Related Work and Discussions
Two lines of previous work have directly influenced and inspired this research. The first line of
related work was on the expected complexity of tree search, which shed light to the BnB subtour
elimination algorithm described in Section 6.1 as it solves the ATSP in a tree search. The analysis
was carried out on an abstract random tree model called incremental tree  (Karp & Pearl, 1983;
McDiarmid, 1990; McDiarmid & Provan, 1991; Zhang & Korf, 1995; Zhang, 1999). The internal
nodes of  has variable number of children and edges in  are assigned finite and nonnegative
random values. The cost of a node in  is the sum of the edge costs along the path from the root to
that node. An optimal goal node is a node of minimum cost at a fixed depth  . The overall goal is
to find an optimal goal node.
There exist phase transitions in the cost of the optimal goal node and the complexity to the
problem of finding an optimal goal in  . The control parameter is the expected number of child
nodes of a common parent node which have the same cost as the parent. The cost of an optimal goal
node almost surely undergoes a phase transition from a linear function of depth  to a constant when
the expected same-cost children of a node increases beyond one. Meanwhile, best-first search and
depth-first branch-and-bound also exhibit a phase-transition behavior, i.e., their expected complexity
changes dramatically from exponential to polynomial in  as the expected same-cost children of a
node is reduced to below one. Note that following the result by Dechter & Pearl (1985), best-first
search is optimal for searching this random tree among all algorithms using the same cost function,
in terms of number of node expansions, up to tie breaking. Thus, the above results also give the
expected complexity of the problem of searching an incremental tree.
The second line of related research was on characterizing the the assignment problem (AP)
lower-bound cost function and its relationship with the ATSP, which has been a research interest for
a long time (Aldous, 2001; Coppersmith & Sorkin, 1999; Frieze, Karp, & Reed, 1992; Frieze &
Sorkin, 2001; Karp, 1987; Karp & Steele, 1985; Mezard & Parsi, 1987; Walkup, 1979). The first
surprising result (Walkup, 1979) is that the expected AP cost approaches a constant as the number
of cities  goes to infinity if the entries of distance matrix  are independent and uniform over reals
n
Q 15q . This constant has been the subject of a long history of pursuit. It has been shown rigorously,
based on rigorous replica method from statistical physics (Mezard et al., 1987), that the optimal cost
of random assignment approaches asymptotically to  df  (Aldous, 2001), which is approximately
1.64493. Our results in Section 5 show that the AP and the ATSP costs approach 1.64421 and
1.64463, respectively, which agree with the theoretical results on the AP cost.
More importantly, the relationship between the AP cost and the ATSP cost has remarkably
different characteristics under different distance distributions. On one extreme, the AP cost is the
same as the ATSP cost with a high probability, while on the other extreme, it can differ from the
ATSP cost, with a high probability, by a function of problem size  . Let fi ! be the AP cost
and fiP ! the ATSP cost under a distance matrix  . If the expected number of zeros in
v , then fi !Vfiol with a probability
a row of  approaches infinity when us
tending to one (Frieze et al., 1992). However, if the entities of  are uniform over the integers
n
Q 1571.^.^.^1+  rq , then fi !!fib l with a probability going to zero, where   grows
n
to infinity with  (Frieze et al., 1992). Indeed, when the entities of  are uniform over Q 15q ,
m
fiol D fi ! O   f , where   is a positive constant (Frieze & Sorkin, 2001).
These previous results indicate that the quality of the AP function varies significantly, depending
on the underlying distance distribution. Precisely, the difference between the AP cost and the ATSP
492

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

cost has two phases, controlled by the number of zero distances in the distance matrix  . In one
phase, the difference is zero with high probability, while in the other phase, the expectation of the
difference is a function of the problem size  . Our experimental results in Section 4 adds to this
analysis the existence of a phase transition between these two phases.
The two-phase result on the accuracy of the AP cost function is also in principle consistent with
the phase-transition result of incremental random trees. The root of the search tree has a cost equal
to the AP cost fiol to the problem and an optimal goal node has the ATSP tour cost fiP ! .
If we subtract the AP cost to the root from every node in the ATSP search tree, the root node has
cost zero and an optimal goal node has cost equal to fib l D fi ! . When there are a large
number of zero distances in  , there will be a large number of same-cost children, and the AP cost
of a child node in a search tree is more likely to be the same as the AP cost of its parent, since AP
will tend to use the zero distances. Therefore, it is expected that more nodes in the search tree will
have more than one child node having the same cost as their parents.
In addition to the phase transitions of combinatorial problems mentioned in Section 1, there are
other related previous results. Results on scaling of search cost against constrainedness in symmetric TSP were considered by Gent, MacIntyre, Prosser, & T. Walsh (1997). Phase transitions
in Hamiltonian circuit was studied by Frank, Gent, & Walsh (1998). It was also shown that it is
hard to generate difficult Hamiltonian cycle problem instances (Vandegriend & Culberson, 1998).
In addition, the concept of backbones has been studied in many problems under different names.
For examples, unary prime implicate refers to such a variable that must be set to a fixed value for
an instance of Boolean satisfiability (Parkes, 1997); a frozen development describes a pair of nodes
that must share the same colors in a graph coloring problem (Culberson & Gent, 2001).

8. Conclusions
Our main contributions of this research are twofold. First, we answered positively the long-standing
question if the Traveling Salesman Problem (TSP) has phase transitions (Kirkpatrick & Toulouse,
1985) and disapproved the belief that the problem does not have a phase transition (Kirkpatrick
& Selman, 1994). We studied this issue on a more general, optimization version of the problem,
the asymmetric TSP (ATSP). We empirically showed, using random problem instances with distances from a uniform distribution, that many important properties, including the ATSP tour cost
and the fraction of backbone variables, have two characteristically different values, and the transitions between them are rather abrupt and dramatic, displaying a phase-transition phenomenon. The
control parameter of the phase transitions is the effective number of digits representing the intercity
distances or the precision of distance measure.
Second, our results provide a practical guidance on how to generate difficult random ATSP
problem instances and which random instances should be used for comparing the asymptotic performance of ATSP algorithms. A current common practice in comparing algorithms when using a
random ensemble is to generate problem instances of different sizes with a fixed distance precision.
Our phase transition results indicate that the correct way is to use instances of different sizes that
have the same or similar features such as the same fraction of backbone variables. It is also important to point out that the locations of hardest, albeit random, problem instances typically depend on
distance distribution used. In the case of uniform distribution, this requires increasing the precision
of intercity distances as the problem size grows.
493

fiZ HANG

It is important to note that the exact locations of various phase transitions presented here remain
to be mathematically determined, using methods probably from statistical physics (Martin et al.,
2001; Mezard et al., 1987).
We like to conclude by pointing out that the phase transition results in this paper is general.
The argument on the control parameter in Section 3 is general and applicable to the symmetric
TSP (STSP). Our unpublished data also showed phase transitions in the STSP. The results on the
ATSP with uniformly distributed distances should hold for other types of intercity distances. This
is in part supported by our previous investigation where intercity distances were chosen from a lognormal distribution (Zhang & Korf, 1996). Finally, we believe that phase transitions will persist on
structured TSPs as long as intercity distances are independently drawn from a common distribution.
Such TSPs include those proposed and studied by Cirasella et al., (2001) and Johnson et al., (2002),
for examples, problem instances with constraints of triangle inequalities, instances converted from
particular applications such as disk drive optimization, jobshop scheduling, coin collecting optimization, etc.

Acknowledgments
This research was supported in part by NSF grants IIS-0196057 and ITR/EIA-0113618, and in part
by DARPA Cooperative Agreements F30602-00-2-0531 and F33615-01-C-1897. Thanks to Sharlee
Climer for the joint work on an algorithm for finding backbone using limit crossing (Climer &
Zhang, 2002) and for a critical reading of a draft. Thanks also to Scott Kirkpatrick and David Johnson for comments on a draft. Special thanks to Allon Percus and Sergey Knysh for very constructive
comments and suggestions, especially on the finite-size scaling, which significantly improved the
paper. Thanks also go to the anonymous reviewers for excellent comments. Some early results
were presented at NSF/IPAM Workshop on Phase Transitions and Algorithmic Complexity, June
3-5, 2002, and at the 18-th International Joint Conference on Artificial Intelligence (IJCAI-03),
Acapulco, Mexico, Aug. 9-15, 2003 (Zhang, 2003).

References
Achlioptas, D., Gomes, C., Kautz, H., & Selman, B. (2000). Generating satisfiable instances. In
Proceedings of the 17th National Conference on Artificial Intelligence (AAAI-02).
Aldous, D. J. (2001). The =\, limit in the random assignment problem. Random Structures and
Algorithms, 18, 381418.
Balas, E., & Toth, P. (1985). Branch and bound methods. In The Traveling Salesman Problem, pp.
361401. John Wiley & Sons, Essex, England.
Barber, M. N. (1983). Finite-size scaling. In Phase Transitions and Critical Phenomena, Vol. 8, pp.
145266. Academic Press.
Bellmore, M., & Malone, J. C. (1971). Pathology of traveling-salesman subtour-elimination algorithms. Operations Research, 19, 278307.
Borgs, C., Chayes, J. T., & Pittel, B. (2001). Phase transition and finite-size scaling for the integer
partitioning problem. Random Structures and Algorithms, 19, 247288.
494

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

Carpaneto, G., DellAmico, M., & Toth, P. (1995). Exact solution of large-scale, asymmetric Traveling Salesman Problems. ACM Trans. on Mathematical Software, 21, 394409.
Carpaneto, G., & Toth, P. (1980). Some new branching and bounding criteria for the asymmetric
traveling salesman problem. Management Science, 26, 736743.
Cheeseman, P. (1991). Personal communications..
Cheeseman, P., Kanefsky, B., & Taylor, W. M. (1991). Where the really hard problems are. In Proc.
the 12th International Joint Conference on Artificial Intelligence (IJCAI-91), pp. 331337.
Cirasella, J., Johnson, D., McGeoch, L. A., & Zhang, W. (2001). The asymmetric traveling salesman
problem: Algorithms, instance generators, and tests. In Proc. of 3rd Workshop on Algorithm
Engineering and Experiments (ALENEX-2001).
Climer, S., & Zhang, W. (2002). Searching for backbones and fat: A limit-crossing approach with
applications. In Proc. the 18th National Conference on Artificial Intelligence (AAAI-02), pp.
707712.
Coppersmith, D., & Sorkin, G. B. (1999). Constructive bounds and exact expectations for the
random assignment problem. Random Structures and Algorithms, 15, 113144.
Culberson, J., & Gent, I. (2001). Frozen development in graph coloring. Theoretical Computer
Science, 265, 227264.
Dantzig, G. B., Fulkerson, D. R., & Johnson, S. M. (1959). On a linear programming, combinatorial
approach to the traveling salesman problem. Operations Research, 7, 5866.
Dechter, R., & Pearl, J. (1985). Generalized best-first search strategies and the optimality of A .
Journal of ACM, 32, 505536.
Frank, J., Gent, I., & Walsh, T. (1998). Asymptotic and finite size parameters for phase transitions:
Hamiltonian circuit as a case study. Information Processing Letters, 65(5), 241245.
Frieze, A., Karp, R. M., & Reed, B. (1992). When is the assignment bound asymptotically tight for
the asymmetric traveling-salesman problem?. In Proc. of Integer Programming and Combinatorial Optimization, pp. 453461.
Frieze, A., & Sorkin, G. B. (2001). The probabilistic relationship between the assignment and
asymmetric traveling salesman problems. In Proc. of SODA-01, pp. 652660.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory of
NP-Completeness. Freeman, New York, NY.
Gent, I., MacIntyre, E., Prosser, P., & Walsh, T. (1997). The scaling of search cost. In Proc. the
14th National Conference on Artificial Intelligence (AAAI-96), pp. 315320.
Gent, I., & Walsh, T. (1996a). The TSP phase transition. Artificial Intelligence, 88, 349358.
Gent, I., & Walsh, T. (1996b). Phase transitions and annealed theories: Number partitioning as a
case study. In Proceedings of 12th ECAI.
Gent, I., & Walsh, T. (1998). Analysis of heuristics for number partitioning. Computational Intelligence, 14(3), 430451.
Gomes, C. P., Hogg, T., Walsh, T., & Zhang, W. (2001). IJCAI-2001 tutorial: Phase transitions
and structure in combinatorial problems. http://www.cs.wustl.edu/  zhang/links/ijcai-phasetransitions.html.
495

fiZ HANG

Gutin, G., & Punnen, A. P. (Eds.). (2002). The Traveling Salesman Problem and Its Variations.
Kluwer Academic Publishers.
Hogg, T. (1995). Exploiting problem structure as a search heuristic. Tech. rep., Xerox PARC.
Hogg, T., Huberman, B. A., & Williams, C. (1996). Phase transitions and the search problem.
Artificial Intelligence, 81, 115.
Johnson, D. S., Gutin, G., McGeoch, L. A., Yeo, A., Zhang, W., & Zverovitch, A. (2002). The
Traveling Salesman Problem and its Variations, chap. Experimental Analysis of Heuristics
for the ATSP, pp. 445487. Kluwer Academic Publishers, Dordrecht.
Karp, R. M. (1972). Reducibility among combinatorial problems. In Miller, R. E., & Thatcher, J. W.
(Eds.), Comlexity of Computer Computations, pp. 85103. Plenum Press.
Karp, R. M. (1979). A patching algorithm for the nonsymmetric traveling-salesman problem. SIAM
Journal on Computing, 8, 561573.
Karp, R. M. (1987). An upper bound on the expected cost of an optimal assignment. In Johnson,
D. (Ed.), Discrete Algorithms and Complexity: Proc. of the Japan-US Joint Seminar, pp. 14,
New York. Academic Press.
Karp, R. M., & Pearl, J. (1983). Searching for an optimal path in a tree with random costs. Artificial
Intelligence, 21, 99117.
Karp, R. M., & Steele, J. M. (1985). Probabilistic analysis of heuristics. In The Traveling Salesman
Problem, pp. 181205. John Wiley & Sons, Essex, England.
Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. (1983). Optimization by simulated annealing. Science,
220, 671680.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior in the satisfiability of random boolean
expressions. Science, 264(5163), 12971301.
Kirkpatrick, S., & Toulouse, G. (1985). Configuration space analysis of traveling salesman problems. J. Phys. (France), 46, 12771292.
Lawler, E. L., Lenstra, J. K., Kan, A. H. G. R., & Shmoys, D. B. (Eds.). (1985). The Traveling
Salesman Problem. John Wiley & Sons, Essex, England.
Lin, S., & Kernighan, B. W. (1973). An effective heuristic algorithm for the Traveling Salesman
Problem. Operations Research, 21, 498516.
Little, J. D. C., Murty, K. G., Sweeney, D. W., & Karel, C. (1963). An algorithm for the traveling
salesman problem. Operations Research, 11, 972989.
Martello, S., & Toth, P. (1987). Linear assignment problems. Annals of Discrete Mathematics, 31,
259282.
Martin, O. C., Monasson, R., & Zecchina, R. (2001). Statistical mechanics methods and phase
transitions in optimization problems. Theoretical Computer Science, 265, 367.
McDiarmid, C. J. H. (1990). Probabilistic analysis of tree search. In Gummett, G. R., & Welsh, D.
J. A. (Eds.), Disorder in Physical Systems, pp. 249260. Oxford Science.
McDiarmid, C. J. H., & Provan, G. M. A. (1991). An expected-cost analysis of backtracking and
non-backtracking algorithms. In Proc. the 12th International Joint Conference on Artificial
Intelligence (IJCAI-91), pp. 172177, Sydney, Australia.
496

fiP HASE T RANSITIONS

AND

BACKBONES

OF THE

ATSP

Mezard, M., & Parsi, G. (1987). On the solution of the random link matching problem. J. Physique,
48, 14511459.
Mezard, M., Parsi, G., & Virasoro, M. A. (Eds.). (1987). Spin Glass Theory and Beyond. World
Scientific, Singapore.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard and easy distributions of SAT problems. In
Proc. the 10th National Conference on Artificial Intelligence (AAAI-92), pp. 459465.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999). Determining
computational complexity from characteristic phase transitions. Nature, 400, 133137.
Papadimitriou, C. H., & Yannakakis, M. (1993). The travelling salesman problem with distances
one and two. Math. Oper. Res., 18, 111.
Parkes, A. (1997). Clustering at the phase transitions. In Proc. of the 14th National Conference on
Artificial Intelligence (AAAI-97).
Pearl, J. (1984). Heuristics: Intelligent Search Strategies for Computer Problem Solving. AddisonWesley, Reading, MA.
Selman, B., & Kirkpatrick, S. (1996). Critical behavior in the computational cost of satisfiability
testing. Artificial Intelligence, 81, 273295.
Slaney, J., & Walsh, T. (2001). Backbones in optimization and approximation. In Proc. the 17th
International Joint Conference on Artificial Intelligence (IJCAI-01), pp. 254259.
Smith, T. H. C., Srinivasan, V., & Thompson, G. L. (1977). Computational performance of three
subtour elimination algorithms for solving asymmetric traveling salesman problems. Annals
of Discrete Mathematics, 1, 495506.
Vandegriend, B., & Culberson, J. (1998). The gn,m phase transition is not hard for the hamiltonian
cycle problem. J. Artificial Intelligence Research, 9, 219245.
Walkup, D. W. (1979). On the expected value of a random assignment problem. SIAM Journal on
Computing, 8, 440442.
Wilson, K. G. (1979). Problems in physics with many scales of length. Scientific American, 241,
158179.
Zhang, W. (1999). State-space Search: Algorithms, Complexity, Extensions, and Applications.
Springer.
Zhang, W. (2001). Phase transitions and backbones of 3-SAT and maximum 3-SAT. In Proc. Intern.
Conf. on Principles and Practice of Constraint Programming (CP-01), pp. 153167.
Zhang, W. (2003). Phase transitions of the asymmetric traveling salesman. In Proc. the 18th International Joint Conference on Artificial Intelligence (IJCAI-03), pp. 12021207.
Zhang, W., & Korf, R. E. (1995). Performance of linear-space search algorithms. Artificial Intelligence, 79, 241292.
Zhang, W., & Korf, R. E. (1996). A study of complexity transitions on the asymmetric Traveling
Salesman Problem. Artificial Intelligence, 81, 223239.

497

fiJournal of Artificial Intelligence Research 21 (2004) 579-594

Submitted 08/03; published 05/04

Can We Learn to Beat the Best Stock
Allan Borodin

bor@cs.toronto.edu

Department of Computer Science
University of Toronto
Toronto, ON, M5S 3G4 Canada

Ran El-Yaniv

rani@cs.technion.ac.il

Department of Computer Science
Technion - Israel Institute of Technology
Haifa 32000, Israel

Vincent Gogan

vincent@cs.toronto.edu

Department of Computer Science
University of Toronto
Toronto, ON, M5S 3G4 Canada

Abstract
A novel algorithm for actively trading stocks is presented. While traditional expert
advice and universal algorithms (as well as standard technical trading heuristics) attempt
to predict winners or trends, our approach relies on predictable statistical relations between
all pairs of stocks in the market. Our empirical results on historical markets provide strong
evidence that this type of technical trading can beat the market and moreover, can beat
the best stock in the market. In doing so we utilize a new idea for smoothing critical
parameters in the context of expert learning.

1. Introduction
The portfolio selection (PS) problem is a challenging problem for machine learning, online
algorithms and, of course, computational finance. As is well known (e.g. see Lugosi, 2001)
sequence prediction under the log loss measure can be viewed as a special case of portfolio selection, and perhaps more surprisingly, from a certain worst case minimax criterion,
portfolio selection is not essentially any harder (than prediction) as shown in (Cover & Ordentlich, 1996) (see also Lugosi, 2001, Thm. 20 & 21). But there seems to be a qualitative
difference between the practical utility of universal sequence prediction and universal
portfolio selection. Simply stated, universal sequence prediction algorithms under various
probabilistic and worst-case models appear to work very well in practice whereas the known
universal portfolio selection algorithms do not seem to provide any substantial benefit over
a naive investment strategy (see Section 5).
A major pragmatic question is whether or not a computer program can consistently
outperform the market. A closer inspection of the interesting ideas developed in information theory and online learning suggests that a promising approach is to exploit the natural
volatility in the market and in particular to benefit from simple and rather persistent statistical relations between stocks rather than to try to predict stock prices or winners.

c
2004
AI Access Foundation. All rights reserved.

fiBorodin, El-Yaniv, & Gogan

We present a non-universal portfolio selection algorithm1 , which does not try to predict
winners. The motivation behind our algorithm is the rationale behind constant rebalancing
algorithms and the worst case study of universal trading introduced by Cover (1991). Not
only does our proposed algorithm substantially beat the market on historical markets,
it also beats the best stock. So why are we presenting this algorithm and not just simply
making money? There are, of course some caveats and obstacles to utilizing the algorithm.
But for large investors the possibility of a goose laying silver (if not golden) eggs is not
perhaps impossible.

2. The Portfolio Selection Problem
Assume a market with m stocks. Let vt = (vt (1), . . . , vt (m)) be the daily closing prices2
of the m stocks for the tth day, where vt (j) is the price of the jth stock. It is convenient
to work with relative prices xt (j) = vt (j)/vt1 (j) so that an investment of $d in the jth
stock just before the tth day yields dxt (j) dollars. We let xt = (xt (1), . . . , xt (m)) denote the
market vector of relative prices corresponding to the tth day. A portfolio b is an allocation
of wealth in the stocks, specified by the proportions b = (b(1),
P . . . , b(m)) of current dollar
wealth invested in each of the stocks, where b(j) P
0 and j b(j) = 1. The daily return
of a portfolio b w.r.t. a market vector x is b  x = j b(j)x(j) and the (compound) total
return, retX (b1 , . . .Q
, bn ), of a sequence of portfolios b1 , . . . , bn w.r.t. a market sequence
X = x1 , . . . , xn is nt=1 bt  xt . A portfolio selection algorithm A is any deterministic or
randomized rule for specifying a sequence of portfolios and we let retX (A) denote its total
return for the market sequence X.
The simplest strategy is to buy-and-hold stocks using some portfolio b. We denote this
strategy by BAHb and let U-BAH denote the uniform buy-and-hold when b = (1/m, . . . , 1/m).
We say that a portfolio selection algorithm beats the market when it outpeforms U-BAH
on a given market sequence although in practice the market can be represented by some
non-uniform BAH.3 Buy-and-hold strategies rely on the tendency of successful markets to
grow. Much of modern portfolio theory focuses on how to choose a good b for the buyand-hold strategy. The seminal ideas of Markowitz (1959) yield an algorithmic procedure
for choosing the weights of the portfolio b so as to minimize the variance for any feasible
expected return. This variance minimization is possible by placing appropriate (larger)
weights on subsets of sufficiently anti-correlated stocks, an idea which we shall also utilize.
We denote the optimal in hindsight buy-and-hold strategy (i.e. invest only in the best
stock) by BAH .
An alternative approach to the static buy-and-hold is to dynamically change the portfolio
during the trading period. This approach is often called active trading. One example of
active trading is constant rebalancing; namely, fix a portfolio b and (re)invest your dollars
each day according to b. We denote this constant rebalancing strategy by CBALb and let
CBAL denote the optimal (in hindsight) CBAL. A constant rebalancing strategy can often
1. Any PS algorithm can be modified to be universal by investing any fixed fraction of the initial wealth in
a universal algorithm.
2. There is nothing special about daily closing prices and the problem can be defined with respect to any
(sub)sequence of the (intra-day) sequence of all price offers which appear in the stock market.
3. For example the Dow Jones Industrial Average (DJIA) is calculated as a non uniform average of the 30
DJIA stocks; see e.g. http://www.dowjones.com/

580

fiCan We Learn to Beat the Best Stock

take advantage of market fluctuations to achieve a return significantly greater than that of
is always at least as good as the best stock BAH and in some real market
sequences a constant rebalancing strategy will take advantage of market fluctuations and
significantly outperform the best stock (see e.g. Table 1). For now, consider Cover and
Glusss (1986) classic (but contrived) example
of cash and one stock
 1  consisting

 1 ofa1market
, 12 , . . .. Now consider the CBALb
and the market sequence of price relatives 1/2
, 2 , 1/2
with b = ( 21 , 12 ). On each odd day the daily return of CBALb is 21 1+ 12 12 = 34 and on each even
day, it is 3/2. The total return over n days is therefore (9/8)n/2 , illustrating how a constant
rebalancing strategy can yield exponential returns in a no-growth market. Under the
assumption that the daily market vectors are observations of identically and independently
distributed (i.i.d) random variables, it is shown in (Cover & Thomas, 1991) that CBAL
performs at least as good (in the sense of expected total return) as the best online portfolio
selection algorithm. However, many studies (see e.g. Lo & MacKinlay, 1999) argue that
stock price sequences do have long term memory and are not i.i.d.
A non-traditional objective (in computational finance) is to develop online trading
strategies that are in some sense always guaranteed to perform well.4 Within a line of
research pioneered by Cover (Cover & Gluss, 1986; Cover, 1991; Cover & Ordentlich, 1996)
one attempts to design portfolio selection algorithms that can provably do well (in terms
of their total return) with respect to some online or offline benchmark algorithms. Two
natural online benchmark algorithms are the uniform buy and hold U-BAH, and the uniform
1
1
,..., m
). A natural
constant rebalancing strategy U-CBAL, which is CBALb with b = ( m

offline benchmark is BAH and a more challenging offline benchmark is CBAL .
A portfolio selection algorithm A is called universal if for every market sequence X over
n days, it guarantees a subexponential ratio (in n) between its return retX (A) and that of
retX (CBAL ). In particular, Cover and Ordentlichs Universal Portfolios algorithm (Cover,
1991; Cover & Ordentlich, 1996), denoted here by UNIVERSAL, was proven to be universal;
more specifically for every market sequence X of m stocks over n days, it guarantees the
subexponential (indeed polynomial) ratio
 m1 
(1)
retX (CBAL )/retX (UNIVERSAL) = O n 2 .
BAH . CBAL

From a theoretical perspective this is surprising as this performance ratio is bounded by
a polynomial in n (for fixed m) whereas CBAL is capable of exponential returns. From a
practical perspective, this bound is not very useful because the empirical returns observed
for CBAL portfolios is often not exponential in the number of trading days. However, the
motivation that underlies the potential of CBAL algorithms is useful! We follow this motivation and develop a new algorithm which we call ANTICOR. By attempting to systematically
follow the constant rebalancing philosophy, ANTICOR is capable of some extraordinary performance in the absence of transaction costs, or even with very small transaction costs.
4. A trading strategy is online if it computes the portfolio for the (t+1)st day using only market information
for the first t days. This is in contrast to offline algorithms such as U-BAH , CBAL and the optimal
strategy of picking the best stock for each individual day. Such offline algorithms compute a sequence
of portfolios as a function of the entire market sequence.

581

fiBorodin, El-Yaniv, & Gogan

3. Trying to Learn the Winners
The most direct approach to expert learning and portfolio selection is a (reward based)
weighted average prediction scheme, which adaptively computes a weighted average of
experts by gradually increasing (by some multiplicative or additive update rule) the relative
weights of the more successful experts. In this section we briefly discuss some related
portfolio selection results along these lines.
For example, in the context of the PS problem consider the exponentiated gradient
EG() algorithm proposed by (Helmbold et al., 1998). The EG() algorithm computes the
next portfolio to be
bt (j) exp {xt (j)/(bt  xt )}
bt+1 (j) = Pm
,
j=1 bt (j) exp {xt (j)/(bt  xt )}
where  is a learning rate parameter. EG was designed to greedily choose the best portfolio
for yesterdays market xt while at the same time paying a penalty from movingp
far from yesterdays portfolio. For a universal bound on EG, Helmbold et al. set  = 2xmin 2(log m)/n
where xmin is a lower bound on any price relative.5 It is easy to see that as n increases, 
decreases to 0 so that we can think of  as being very small in order to achieve universality.
When  = 0, the algorithm EG() degenerates to the uniform CBAL (assuming we started
with a uniform portfolio) which is not a universal algorithm. It is also the case that if each
day the price relatives for all stocks were identical, then EG (as well as other PS algorithms)
will converge to the uniform CBAL. Combining a small learning rate with a reasonably
balanced market we expect the performance of EG to be similar to that of the uniform
CBAL and this is confirmed by our experiments (see Table 1).6
Covers universal algorithms adaptively learn each days portfolio by increasing the
weights of successful CBALs. The update rule for these universal algorithms is
R
b  rett (CBALb )d(b)
bt+1 = R
,
rett (CBALb )d(b)
where () is some prior distribution over portfolios. Thus, the weight of a possible portfolio
is proportional to its total return rett (b) thus far times its prior. The particular universal algorithm we consider in our experiments uses the Dirichlet prior (with parameters
( 21 , . . . , 12 )) (Cover & Ordentlich, 1996).7 Somewhat surprisingly, as noted in (Cover & Ordentlich, 1996) the algorithm is equivalent to a static weighted average (given by (b)) over
all CBALs (see also Borodin & El-Yaniv, 1998, p. 291). This equivalence helps to demystify
the universality result and also shows that the algorithm can never outperform CBAL .
5. Helmbold et al. show how to eliminate the need to know xmin and n. While EG can be made universal,
its performance ratio is only sub-exponential (and not polynomial) in n.
6. Following Helmbold et al. we fix  = 0.01 in our experiments. Additional experiments, for a wide range
of fixed  settings, confirm that for our datasets the choice of  = 0.01 is an optimal or near optimal
choice. Of course, it is possible to adaptively set  throughout the trading period, but that is beyond
the scope of this paper.
7. The papers (Cover, 1991; Cover & Ordentlich, 1996; Blum & Kalai, 1998) consider a simpler version
of this algorithm where the (Dirichlet) prior is uniform. This algorithm is also universal and achieves
a ratio (nm1 ). Experimentally (on our datasets) there is a negligible difference between these two
variants and here we only report on the results of the asymptotically optimal algorithm.

582

fiCan We Learn to Beat the Best Stock

A different type of winner learning algorithm can be obtained from any sequence
prediction strategy, as noted in (Borodin, El-Yaniv, & Gogan, 2000). For each stock j, a
(soft) sequence prediction algorithm provides a probability p(j) that the next symbol will
be j  {1, . . . , m}. We view this as a prediction that stock j will have the best relative
price for the next day and set bt+1 (j) = pj . The paper (Borodin et al., 2000) considers
predictions made using the prediction component of the well-known Lempel-Ziv (LZ) lossless
compression algorithm (Ziv & Lempel, 1978). This prediction component is nicely described
in (Langdon, 1983) and in (Feder, 1991). As a prediction algorithm, LZ is provably powerful
in various senses. First it can be shown that it is asymptotically optimal with respect to any
stationary and ergodic finite order Markov source (Rissanen, 1983; Ziv & Lempel, 1978).
Moreover, Feder shows that LZ is also universal in a worst case sense with respect to the
(offline) benchmark class of all finite state prediction machines. To summarize, the common
approach to devising PS algorithms has been to attempt and learn winners using simple or
more sophisticated winner learning schemes.

4. The Anticor Algorithm
We propose a different approach, motivated by a CBAL-inspired philosophy. How can we
interpret the success of the uniform CBAL on the Cover and Gluss example of Section 2?
Clearly, the uniform CBAL here is taking advantage of price fluctuation by constantly transferring wealth from the high performing stock to the relatively low performing stock. Even
in a less contrived market, a CBAL is capable of large returns. A market model favoring
the use of a CBAL is one in which stock growth rates are stable in the long term and occasional larger return rates will be followed by smaller rates (and vice versa). This market
phenomenon is is sometimes called reversal to the mean.
There are many ways that one can interpret and implement algorithms based on the
philosophy of reversal to the mean. In particular, any CBAL can be viewed as a static
implementation of this philosophy. We now describe the motivation and basic ingredients in
our ANTICOR algorithm which adaptively (based on recent empirical statistics) and rather
aggressively8 implements reversal to the mean.
For a given trading day, consider the most recent past w trading days, where w is some
integer parameter. The growth rate of any stock i during this window of time is measured
by the product of relative prices during this window.9 Motivated by the assumption that we
have a portfolio of stocks that are all performing similarly in terms of long term growth rates,
ANTICORs first condition for transferring money from stock i to stock j is that the growth
rate for stock i exceeds that of stock j in this most recent window of time.10 In addition,
the ANTICOR algorithm requires some indication that stock j will start to emulate the past
growth of stock i in the near future. To this end, ANTICOR requires a positive correlation
between stock i during the second last window and stock j during the last window. The
relative extent to which we will transfer money from stock i to stock j will depend on
8. Our ANTICOR algorithm is aggressive (say, compared to CBAL) in the sense that it can transfer all
assets out of a given stock. Various heuristics can be used to moderate this behavior.
9. Since we would rather deal with arithmetic instead of geometric means we will use the logarithms of
relative prices.
10. Note that here the umderlying model assumption is reversal to the same mean. One can modify the
algorithm so as to account for different means.

583

fiBorodin, El-Yaniv, & Gogan

the strength of this correlation as well as the strength of the self anti-correlations for
stocks i and j (again in two consecutive windows). ANTICOR is so named because we use
these correlations and anticorrelations in consecutive windows to indicate the potential for
anticorrelations of the growth rates for stocks i and j in the near future (with hopefully the
growth rate of stock j becoming greater than that of stock i).
Formally, we define
LX1 = log(xt2w+1 ), . . . , log(xtw )T and LX2 = log(xtw+1 ), . . . , log(xt )T ,

(2)

where log(xk ) denotes (log(xk (1)), . . . , log(xk (m))). Thus, LX1 and LX2 are the two vector
sequences (equivalently, two w  m matrices) constructed by taking the logarithm over the
market subsequences corresponding to the time windows [t  2w + 1, t  w] and [t  w + 1, t],
respectively. We denote the jth column of LXk by LXk (j). Let k = (k (1), . . . , k (m)),
be the vectors of averages of columns of LXk . Similarly, let k , be the vector of standard
deviations of columns of LXk . The cross-correlation matrix (and its normalization) between
column vectors in LX1 and LX2 are defined as11
1
(LX1 (i)  1 (i))T (LX2 (j)  2 (j));
w

1
(
Mcov (i,j)
1 (i)2 (j) 1 (i), 2 (j) 6= 0;
Mcor (i, j) =
0
otherwise.

Mcov (i, j) =

(3)

Mcor (i, j)  [1, 1] measures the correlation between log-relative prices of stock i over the
first window and stock j over the second window. We note that if 1 (i) (respectively,
2 (j)) is zero over some window then the growth rate of stock i during the second last
window (respectively, stock j during the last window) is constant during this window. For
sufficiently large windows of time constant growth of any stock i is unlikely. However, in
this unlikely case we choose not to move money into or out of such a stock i.12
For each pair of stocks i and j we compute claimij , the extent to which we want to shift
our investment from stock i to stock j. Namely, there is such a claim iff 2 (i) > 2 (j) and
Mcor (i, j) > 0 in which case claimij = Mcor (i, j) + A(i) + A(j) where A(h) = |Mcor (h, h)| if
Mcor (h, h) < 0, else 0. Following our interpretation for the success of a CBAL, Mcor (i, j) > 0
is used to predict that stocks i and j will be correlated in consecutive windows (i.e. the
current window and the next window based on the evidence for the last two windows) and
Mcor (h, h) < 0 predicts that stock h P
will be negatively auto-correlated over consecutive
windows. Finally,
b
(i)
=
b
(i)
+
t
j6=i [transferji  transferij ] where transferij =
P t+1
bt (i)  claimij / j claimij . A pseudocode summarizing the ANTICOR algorithm appears
in Figure 1. The pseudocode describes the routine ANTICOR(w, t, Xt , bt ) that receives a
window size w, the current trading day t, the historical market sequence Xt (giving the
market vectors corresponding to days 1, . . . , t) and the current portfolio bt defined to be
bt = bt1xt (bt (1)xt (1), . . . , bt (m)xt (m)). The routine is first called with an empty historical
market sequence and with bt being the uniform portfolio (over m stocks). The routine
11. Recall that the correlation coefficient is a normalized covariance with the covariance divided by
the product of the standard deviations; that is, Cor(X, Y ) = Cov(X, Y )/(std(X)  std(Y )) where
Cov(X, Y ) = E[(X  mean(X))(Y  mean(Y ))].
12. Of course, other approaches can be used to accommodate constant or nearly constant growth rate.

584

fiCan We Learn to Beat the Best Stock

returns the new portfolio, to which we should rebalance at the start of the (t + 1)st trading
day.
Algoritm ANTICOR(w, t, Xt , bt )
Input:
1. w: Window size
2. t: Index of last trading day
3. Xt = x1 , . . . , xt : Historical market sequence
4. bt : current portfolio (by the end of trading day t)
Output: bt+1 : Next days portfolio
1. Return the current portfolio bt if t < 2w.
2. Compute LX1 and LX2 as defined in Equation (2), and 1 and 2 , the (vector) averages of
LX1 and LX2 , respectively.
3. Compute Mcor (i, j) as defined in Equation (3).
4. Calculate claims: for 1  i, j  m, initialize claimij = 0
5. If 2 (i)  2 (j) and Mcor (i, j) > 0 then
(a) claimij = claimij + Mcor (i, j);
(b) if Mcor (i, i) < 0 then claimij = claimij  Mcor (i, i);
(c) if Mcor (j, j) < 0 then claimij = claimij  Mcor (j, j);
6. Calculate new portfolio: Initialize bt+1 = bt . For 1  i, j  m
P
(a) Let transferij = bti  claimij / j claimij ;
(b) bt+1
= bt+1
 transferij ;
i
i
(c) bt+1
= bt+1
+ transferji ;
i
i

Figure 1: Algorithm

ANTICOR

Our ANTICORw algorithm has one critical parameter, the window size w. In Figure 2
we depict the total return of ANTICORw on two historical datasets as a function of the
window size w = 2, . . . , 30 (detailed descriptions of these datasets appear in Section 5). As
we might expect, the performance of ANTICORw depends significantly on the window size.
However, for all w, ANTICORw beats the uniform market and, moreover, it beats the best
stock using most window sizes. Of course, in online trading we cannot choose w in hindsight.
Viewing the ANTICORw algorithms as experts, we can try to learn the best expert. But the
windows, like individual stocks, induce a rather volatile set of experts and standard expert
combination algorithms (Cesa-Bianchi et al., 1997) tend to fail.13
Alternatively, we can adaptively learn and invest in some weighted average of all ANTICORw
algorithms with w less than some maximum W . The simplest case is a uniform investment on all the windows; that is, a uniform buy-and-hold investment on the algorithms
ANTICORw , w  [2, W ], denoted by BAHW (ANTICOR). Figure 3 graphs the total return of
BAHW (ANTICOR) as a function of W for all values of 2  W  50 for the four datasets we
consider here. Considering these graphs, our choice of W = 30 was arbitrary but clearly not
13. This assertion is based on empirical studies we conducted with various expert advice algorithms.

585

fiBorodin, El-Yaniv, & Gogan

NYSE: Anticorw vs. window size

TSX: Anticorw vs. window size

120

BAH(Anticor(Window))
Anticor(Window)
Best Stock
Market Return

8

10

80

Anticorw

5

Total Return

Total Return (logscale)

100

10

BAH(Anticorw)
Anticorw
Best Stock
Market

Best Stock

Anticorw
Best Stock

60

40

2

10

20

1

10

0

10

2

5

10

15

20

25

0

30

5

10

Window Size (w)

(a)

30

BAH(Anticorw)
Anticorw

Best Stock
Market Return

2.5

Best Stock
Market Return

Anticorw

8

Total Return

Total Return

25

DJIA: Anticorw vs. window size

3

BAH(Anticor )
w
Anticorw

10

20

(b)

SP500: Anticorw vs. window size
12

15
Window Size (w)

Anticorw
6

2

1.5

4
2

1

Best Stock

Best Stock

1
5

10

15

20

25

30

Window Size (w)

5

10

15

20

25

30

Window Size (w)

(c)
Figure 2:

0.5

(d)

ANTICORw s

total return (per $1 investment) vs. window size 2  w  30 for
(a) NYSE; (b) TSX; (c) SP500; (d) DJIA. The dashed (red) lines represent the
final return of the best stock and the dash-dotted (blue) lines, the final return
the (uniform) market. The dotted (green) horizontal lines represent a uniform
investment on a number of ANTICORw applications as later described.

optimal. Of course, we could try to optimize the parameter W for each particular dataset
by training the algorithm on historical data before beginning to trade. However, our claim
is that almost any choice of W will yield returns that beat the best stock (the only exception
is W = 2 in the DJIA dataset).
Since we now consider the various algorithms as stocks (whose prices are determined by
the cumulative returns of the algorithms), we are back to our original portfolio selection
problem and if the ANTICOR algorithm performs well on stocks it may also perform well on
algorithms. We thus consider active investment in the various ANTICORw algorithms using
ANTICOR. We again consider all windows w  W . Of course, we can continue to compound
the algorithm any number of times. Here we compound twice and then use a buy-and-hold
investment. The resulting algorithm is denoted BAHW (ANTICOR(ANTICOR)). One impact of
this compounding, depicted in Figure 4, is to smooth out the anti-correlations exhibited in
the stocks. It is evident that after compounding twice the returns become almost completely
586

fiCan We Learn to Beat the Best Stock

NYSE: Total Return vs. Max Window

30

7

6

25

BAH (Anticor)
W

BAHW(Anticor)

5

10

Total Return

Total Return (logscale)

10

TSX: Total Return vs Max Window
BAHW(Anticor)

10

Best Stock
Market

4

10

3

10

Best Stock

20
BAHW(Anticor)
15

10

2

Best Stock
Market

Best Stock

10

1

5

10

0

10

2

10

20

30

40

2

50

10

20

(a)
1.6

W

6

Total Return

Total Return

1.4

5

Best Stock
4

Figure 3:

BAHW(Anticor)
Best Stock

1.2

BAHW(Anticor)

1

3

1
2

BAHW(Anticor)

20

30

Best Stock
Market

0.8

Best Stock
Market
10

50

DJIA: Total Return vs Max Window

BAH (Anticor)

2

40

(b)

SP500: Total Return vs Max Window
7

30

Maximal Window Size (W)

Maximal Window size (W)

40

50

2

10

20

30

Maximal Window Size (W)

Maximal Window Size (W)

(c)

(d)

40

50

BAHW (ANTICOR)s

total return (per $1 investment) as a function of the maximal
window W : NYSE (a); TSX (b); SP500 (c); DJIA (d).

correlated thus diminishing the possibility that additional compounding will substantially
help.14 This idea for smoothing critical parameters may be applicable in other learning
applications. The challenge is to understand the conditions and applications in which the
process of compounding algorithms will have this smoothing effect.

5. An Empirical Comparison of the Algorithms
We present an experimental study of the the ANTICOR algorithm and the three online
learning algorithms described in Section 3. We focus on BAH30 (ANTICOR), abbreviated by
ANTI1 and BAH30 (ANTICOR(ANTICOR)), abbreviated by ANTI2 . Four historical datasets are
used. The first NYSE dataset, is the one used in (Cover, 1991; Cover & Ordentlich, 1996;
Helmbold et al., 1998) and (Blum & Kalai, 1998). This dataset contains 5651 daily prices
for 36 stocks in the New York Stock Exchange (NYSE) for the twenty two year period July
3rd , 1962 to Dec 31st , 1984. The second TSX dataset consists of 88 stocks from the Toronto
Stock Exchange (TSX), for the five year period Jan 4th , 1994 to Dec 31st , 1998. The third
14. This smoothing effect also allows for the use of simple prediction algorithms such as expert advice
algorithms (Cesa-Bianchi et al., 1997), which can now better predict a good window size. We have not
explored this direction.

587

fiBorodin, El-Yaniv, & Gogan

DJIA: Dec 14, 2002  Jan 14, 2003
Anticor1

Stocks
1.1

2

Anticor

2.2
2.6

1

Total Return

2.8

2

0.9

2.4
1.8

0.8

2.2

1.6
0.7

2

1.4
0.6

1.8

1.2

0.5

1.6

1

0.4
5 10 15 20 25
Days

5 10 15 20 25
Days

5 10 15 20 25
Days

Figure 4: Cumulative returns for last month of the DJIA dataset: stocks (left panel);
ANTICORw algorithms trading the stocks (denoted ANTICOR1 , middle panel);
ANTICORw algorithms trading the ANTICOR algorithms (right panel).

dataset consists of the 25 stocks from SP500 which (as of Apr. 2003) had the largest market
capitalization. This set spans 1276 trading days for the period Jan 2nd , 1998 to Jan 31st ,
2003. The fourth dataset consists of the thirty stocks composing the Dow Jones Industrial
Average (DJIA) for the two year period (507 days) from Jan 14th , 2001 to Jan 14th , 2003.15
Algorithm
Market (U-BAH)
Best Stock
CBAL
U-CBAL
ANTI1
ANTI2
LZ
EG
UNIVERSAL

NYSE
14.49
54.14
250.59
27.07
17,059,811.56
238,820,058.10
79.78
27.08
26.99

TSX
1.61
6.27
6.77
1.59
26.77
39.07
1.32
1.59
1.59

SP500
1.34
3.77
4.06
1.64
5.56
5.88
1.67
1.64
1.62

DJIA
0.76
1.18
1.23
0.81
1.59
2.28
0.89
0.81
0.80

NYSE1
0.11
0.32
2.86
0.22
246.22
1383.78
5.41
0.22
0.22

TSX1
1.67
37.64
58.61
1.18
7.12
7.27
4.80
1.19
1.19

SP5001
0.87
1.65
1.91
1.09
6.61
9.69
1.20
1.09
1.07

DJIA1
1.43
2.77
2.97
1.53
3.67
4.60
1.83
1.53
1.53

Table 1: Monetary returns in dollars (per $1 investment) of various algorithms for four
different datasets and their reversed versions. The winner and runner-up for each
market appear in boldface. All figures are truncated to two decimals.
These four datasets are quite different in nature (the market returns for these datasets
appear in the first row of Table 1). While every stock in the NYSE increased in value, 32
of the 88 stocks in the TSX lost money, 7 of the 25 stocks in the SP500 lost money and
15. The four datasets, including their sources and individual stock compositions can be downloaded from
http://www.cs.technion.ac.il/rani/portfolios.

588

fiCan We Learn to Beat the Best Stock

25 of the 30 stocks in the negative market DJIA lost money. With the exception of the
TSX, these data sets include only highly liquid stocks with large market capitalizations. In
order to maximize the utility of these datasets and yet present rather different markets, we
also ran each market in reverse. This is simply done by reversing the order and inverting
the relative prices. The reverse datasets are denoted by a -1 superscript. Some of the
reverse markets are particularly challenging. For example, all of the NYSE1 stocks are
going down. Note that the forward and reverse markets (i.e. U-BAH) for the TSX are both
increasing but that the TSX1 is also a challenging market since so many stocks (56 of 88)
are declining.
Table 1 reports on the total returns of the various algorithms for all eight datasets. We
see that prediction algorithms such as LZ can do quite well and the more aggressive ANTI1
and ANTI2 have excellent and sometimes fantastic returns. Note that these active strategies
beat the best stock and even CBAL in all markets with the exception of the TSX1 in which
case they still significantly outperform the market. The reader may well be distrustful of
what appears to be such unbelievable returns for ANTI1 and ANTI2 especially when applied
to the NYSE dataset. However, recall that the NYSE dataset consists of n = 5651 trading
days and the y such that y n = the total NYSE return is approximately 1.0029511 for
ANTI1 (respectively, 1.0074539 for ANTI2 ); that is, the average daily increase is less than
.3% (respectively, .75%). We observe that learning algorithms such as UNIVERSAL and EG
have no substantial advantage over U-CBAL. Some previous expositions of these algorithms
highlighted particular combinations of stocks where the returns significantly outperformed
the best stock. But the same can be said for U-CBAL.
DJIA: Cumulative Total Returns
2.2

Cumulative Total Return

2

Anti1
Anti2
Best Stock
Market

Anti2
1

Anti

1.8
1.6
1.4
1.2

Best Stock

1
0.8

Market

Jan01

Jan02

Jan03

Date

Figure 5: DJIA: Cumulative returns of of
(the market).

ANTI1 , ANTI2 ,

the best stock and a uniform

BAH

The total returns of ANTI1 and ANTI2 presented in Table 1 are impressive but are far
from telling a complete story. Consider the graphs in figure 6. While both ANTI1 and ANTI2
perform well with respect to the uniform market and the best stock throughout most of the
investment period, there are some periods where the cumulative return of these strategies
589

fiBorodin, El-Yaniv, & Gogan

decrease. This (not surprising) behavior indicates that there is a certain degree of risk in
using these investment algorithms.
In finance the standard risk measure is the standard deviation of the return. In Table 2
we provide annualized returns and risks as well as risk-adjusted returns for all markets
and algorithms considered here.16 For example, the annualized return of the best stock in
the DJIA set is 8.6%, its annualized risk (standard deviation) is 42% and its annualized
risk-adjusted return (Sharpe ratio) is 11%.
Algorithm
Market
(U-BAH)
Best Stock
CBAL
U-CBAL
ANTI1
ANTI2
LZ
EG
UNIVERSAL

NYSE
12  14%
58%
19  24%
63%
27  30%
78%
15  13%
88%
110  28%
367%
136  35%
370%
21  23%
76%
15  13%
88%
15  13%
87%

TSX
10  12%
46%
44  55%
73%
46  40%
106%
9  13%
44%
93  45%
196%
108  60%
172%
5  25%
6%
9  13%
44%
9  13%
44%

SP500
5  24%
8%
30  51%
50%
31  42%
65%
10  22%
28%
40  37%
95%
41  44%
86%
10  25%
25%
10  22%
28%
10  22%
27%

DJIA
12  24%
-67%
8  42%
11%
11  26%
27%
9  25%
-54%
26  35%
62%
50  39%
119%
5  28%
-33%
9  25%
-54%
9  25%
-55%

NYSE1
9  15%
-86%
4  21%
-41%
4  40%
1%
6  13%
-77%
27  27%
86%
38  33%
101%
7  21%
17
6  13%
-77%
6  13%
-77%

TSX1
10  22%
29%
106  104%
98%
125  78%
156%
3  13%
-3%
48  41%
107%
48  46%
96%
36  27%
117%
3  13%
-2%
3  13%
-2%

SP5001
2  22%
-28%
10  32%
20%
13  27%
35%
1  21%
-9%
45  32%
126%
56  36%
143%
3  26%
-0.8%
1  22%
-9%
1  22%
-11%

DJIA1
19  25%
61%
65  114%
54%
71  76%
88%
23  25%
77%
90  31%
277%
113  35%
304%
35  27%
112%
23  25%
77%
23  25%
76%

Table 2: Annualized returns and respective annualized volatilities as well as annualized riskadjusted returns (Sharpe Ratio) of the various algorithms over three datasets and
their reversed versions. The winner and runner-up Sharpe Ratio for each market
appear in boldface. All figures are truncated to two decimals.

6. On Commissions, Trading Friction and Other Caveats
When handling a portfolio of m stocks our algorithm may perform up to m transactions
per day. A major concern is therefore the commissions it will incur. Within the proportional commission model (see e.g. Blum & Kalai, 1998; Borodin & El-Yaniv, 1998, Section
14.5.4) there exists a fraction   (0, 1) such that an investor pays at a rate of /2 for
each buy and for each sell. Therefore, the return
of a sequence b1 , . . . , bn of portfolios

Q 
P
with respect to a market sequence x1 , . . . , xn is t bt  xt (1  j 2 |bt (j)  bt (j)|) , where
16. The annualized return is estimated using the geometric mean ofthe individual daily returns and the risk
is the standard deviation of these daily returns multiplied by 252 where 252 is the assumed standard
number of trading days per year. These calculations are standard. The (annualized) Sharpe ratio
(Sharpe, 1975) is the ratio of annualized return minus the risk-free return (taken to be 4%) divided by
the (annualized) standard deviation.

590

fiCan We Learn to Beat the Best Stock

bt = bt1xt (bt (1)xt (1), . . . , bt (m)xt (m)).17 Our investment algorithm in its simplest form
can tolerate very small proportional commission rates and still beat the best stock. The
graphs in Figure 6 depict the total returns of BAH30 (ANTICOR) with proportional commission factor  = 0.1%, 0.2%, . . . , 1%. The strategy can withstand small commission factors.
For example, with  = 0.1% the algorithm still beat the best stock in all four markets we
consider (and it beats the market with  < 0.4%). Moreover it still clearly beats the market
whenever  < 0.4%.
NYSE

10

30

5

Best Stock

10

TSX

25

Anti1
Return

Return (logscale)

10

Market

20
15
10
5

0

10

0

6

0.2
0.4
0.6
0.8
Commission Rate ()

0
0

1

SP500

2

0.2
0.4
0.6
0.8
Commission Rate ()

1

DJIA

5
Return

Return

4
3
2

1.5

1

1
0

0.1 0.2
0.4
0.6
0.8
Commission Rate ()

Figure 6: Total returns of
0.1%, 0.2%, . . . , 1%.

0.5
0

1

BAH30 (ANTICOR)

0.2
0.4
0.6
0.8
Commission Rate ()

1

with proportional commissions 

=

However, some current online brokers charge very small proportional commissions, perhaps in addition to a small flat commission rate for all trades.18 This means that a large
investor can scale up the investment and suffer only a small proportional transaction rate.
An additional caveat is our assumption that all trades could be implemented using the
closing price. While in principle there is nothing special about the closing price (i.e. our
algorithms can trade at any time during the trading day) practical consideration related
to dataset gathering and availability dictated the use of these prices.19 Our algorithms
17. We note that Blum and Kalai (1998) showed that the performance guarantee of UNIVERSAL still holds
(and gracefully degrades) in the case of proportional commissions.
18. For example, on its USA site, E*TRADE (https://us.etrade.com) offers a flat fee of $10 for any trade
up to 5000 shares and then $.01/share thereafter.
19. Specifically, historical closing prices are in the public domain and allow for experimental reproducibility.
Historical intraday trading quotes can also be gathered but such data is usually protected and can be
costly to obtain.

591

fiBorodin, El-Yaniv, & Gogan

assume that all portfolio adjustments are implemented using the quoted prices they receive
as inputs. This means that all transactions are implemented simultaneously using the
quoted prices. With current online brokers a computerized system can issue all transaction
orders almost instantly but there is no guarantee that they will be all implemented instantly.
This trading friction will necessarily generate discrepancies between the input prices and
implementation prices.
A related problem that one must face when actually trading is the difference between
bid and ask prices. These bid-ask spreads (and the availability of stocks for both buying and
selling) are functions of stock liquidity and are typically small for large market capitalization
stocks. We consider here only very large market cap stocks.
Any report of abnormal returns using historical markets should be suspected of data
snooping. In particular, all of our historical data sets are conditioned on the fact that
all stocks were traded every day and there were no bankrupcies or stocks that became
virtually worthless in any of these data sets. Furthermore, when a dataset is excessively
mined by testing many strategies there is a substantial chance that one of the strategies
will be successful by simple over-fitting. Another data snooping hazard is stock selection.
Our ANTICOR algorithms were fully developed using only the NYSE and TSX datasets.
The DJIA and SP500 sets were obtained (from public domain sources) after the algorithms
were fixed. Finally, our algorithm has one parameter (the maximal window size W ). Our
experiments clearly indicate that the algorithms performance is robust with respect to W
(see, for example, Figure 4).

7. Concluding Remarks
Traditional work in financial economics tend to focus on the understanding of stock price
determination. The main question there is: Can we predict the stock market? Judging by
the extensive but inconclusive work done in financial forecasting, perhaps this is not the most
beneficial question to ask. Rather, can a computer program consistently outperform the
market? Besides practicality, it is clear that any successful portfolio selection algorithm is in
itself a mathematical model that can provide some new intuition on stock price formation.
For example, in our case, the algorithms suggest that some stock price fluctuations are
sufficiently periodic and anti-correlated.
A number of well-respected works report on statistically robust abnormal returns
for simple technical analysis heuristics, which slightly beat the market. For example,
the landmark study of Brock, Lakonishok, and LeBaron (1992) apply 26 simple trading
heuristics to the DJIA index from 1897 to 1986 and provide strong support for technical
analysis heuristics. While consistently beating the market is considered a significant (if not
impossible) challenge, our approach to portfolio selection indicates that beating the best
stock is an achievable goal. While we have mainly focused on an idealized frictionless
setting, we believe that even in such a frictionless setting (which seems like a reasonable
starting point) no such results have been previously claimed in the literature.
The results presented here raise various interesting questions. Since simple statistical
relations such as correlation give rise to such outstanding returns it is plausible that various
other, perhaps more sophisticated machine learning techniques, can give rise to better

592

fiCan We Learn to Beat the Best Stock

portfolio selection algorithms capable of larger returns and tolerating larger commissions
fees.
On the theoretical side, what is missing at this point of time is an analytical model which
better explains why our active trading strategies are so successful. In this regard, we are
investigating various statistical adversary models along the lines suggested by Raghavan
(1992) and Chou et al. (1995). Namely, we would like to show that an algorithm performs
well (relative to some benchmark) for any market sequence that satisfies certain constraints
on its empirical statistics.
One final caveat needs to be mentioned. Namely, the entire theory of portfolio selection
algorithms assumes that any one portfolio selection algorithm has no impact on the market!
But just like any goose laying golden eggs, widespread use will soon lead to the end of the
goose. In our case, the market will quickly react to any method which does consistently
and substantially beat the market.

Acknowledgments
We thank Michael Loftus for his helpful comments. We also thank Izzy Nelken and Super
Computing Inc. for their help in validating the DJIA dataset.

References
Blum, A., & Kalai, A. (1998). Universal portfolios with and without transaction costs.
Machine Learning, 30 (1), 2330.
Borodin, A., & El-Yaniv, R. (1998). Online Computation and Competitive Analysis. Cambridge University Press.
Borodin, A., El-Yaniv, R., & Gogan, V. (2000). On the competitive theory and practice
of portfolio selection. In Proc. of the 4th Latin American Symposium on Theoretical
Informatics (LATIN00), pp. 173196.
Brock, L., Lakonishok, J., & LeBaron, B. (1992). Simple technical trading rules and the
stochastic properties of stock returns. Journal of Finance, 47, 17311764.
Cesa-Bianchi, N., Freund, Y., Haussler, D., Helmbold, D., Schapire, R., & Warmuth, M.
(1997). How to use expert advice. Journal of the ACM, 44 (3), 427485.
Chou, A., Cooperstock, J., El-Yaniv, R., Klugerman, M., & Leighton, T. (1995). The
statistical adversary allows optimal money-making trading strategies. In Proceedings
of the 6th Annual ACM-SIAM Symposium on Discrete Algorithms.
Cover, T. (1991). Universal portfolios. Mathematical Finance, 1, 129.
Cover, T., & Gluss, D. (1986). Empirical bayes stock market portfolios. Advances in Applied
Mathematics, 7, 170181.
Cover, T., & Ordentlich, E. (1996). Universal portfolios with side information. IEEE
Transactions on Information Theory, 42 (2), 348363.
Cover, T., & Thomas, J. (1991). Elements of Information Theory. John Wiley & Sons, Inc.
Feder, M. (1991). Gambling using a finite state machine. IEEE Transactions on Information
Theory, 37, 14591465.
593

fiBorodin, El-Yaniv, & Gogan

Helmbold, D., Schapire, R., Singer, Y., & Warmuth, M. (1998). Portfolio selection using
multiplicative updates. Mathematical Finance, 8 (4), 325347.
Langdon, G. (1983). A note on the Lempel-Ziv model for compressing individual sequences.
IEEE Transactions on Information Theory, 29, 284287.
Lo, A., & MacKinlay, C. (1999). A Non-Random Walk Down Wall Street. Princeton
University Press.
Lugosi, G. (2001).
Lectures on prediction
URL:http://www.econ.upf.es/lugosi/ihp.ps.

of

individual

sequences.

Markowitz, H. (1959). Portfolio Selection: Efficient Diversification of Investments. John
Wiley and Sons.
Raghavan, P. (1992). A statistical adversary for on-line algorithms. dimacs Series in
Discrete Mathematics and Theoretical Computer Science, 7, 7983.
Rissanen, J. (1983). A universal data compression system. IEEE Transactions on Information Theory, 29, 656664.
Sharpe, W. (1975). Adjusting for risk in portfolio performance measurement. Journal of
Portfolio Management, 2934. Winter.
Ziv, J., & Lempel, A. (1978). Compression of individual sequences via variable rate coding.
IEEE Transactions on Information Theory, 24, 530536.

594

fiJournal of Artificial Intelligence Research 21 (2004) 101-133

Submitted 3/03; published 2/04

Complexity Results and Approximation Strategies for MAP
Explanations
James D. Park
Adnan Darwiche

jd@cs.ucla.edu
darwiche@cs.ucla.edu

Computer Science Department
University of California
Los Angeles, CA 90095

Abstract
MAP is the problem of finding a most probable instantiation of a set of variables given
evidence. MAP has always been perceived to be significantly harder than the related
problems of computing the probability of a variable instantiation (Pr), or the problem of
computing the most probable explanation (MPE). This paper investigates the complexity
of MAP in Bayesian networks. Specifically, we show that MAP is complete for NPPP and
provide further negative complexity results for algorithms based on variable elimination.
We also show that MAP remains hard even when MPE and Pr become easy. For example,
we show that MAP is NP-complete when the networks are restricted to polytrees, and even
then can not be effectively approximated.
Given the difficulty of computing MAP exactly, and the difficulty of approximating
MAP while providing useful guarantees on the resulting approximation, we investigate
best effort approximations. We introduce a generic MAP approximation framework. We
provide two instantiations of the framework; one for networks which are amenable to exact
inference (Pr), and one for networks for which even exact inference is too hard. This
allows MAP approximation on networks that are too complex to even exactly solve the
easier problems, Pr and MPE. Experimental results indicate that using these approximation
algorithms provides much better solutions than standard techniques, and provide accurate
MAP estimates in many cases.

1. Introduction
The task of computing the Maximum a Posteriori Hypothesis (MAP) is to find the most
likely configuration of a set of variables given partial evidence about the complement of that
set. The focus of this paper is on the complexity of computing MAP in Bayesian networks,
and on a class of best effort methods for approximating MAP.
One specialization of MAP which has received a lot of attention is the Most Probable
Explanation (MPE). MPE is the problem of finding the most likely configuration of a set of
variables given complete evidence about the complement of that set. The primary reason for
this attention is that MPE seems to be a much simpler problem than its MAP generalization.
Unfortunately, MPE is not always suitable for the task of providing explanations. Consider
for example the problem of system diagnosis, where each component has an associated
variable representing its health. Given some evidence about the system behavior, one is
usually interested in computing the most probable configuration of health variables. This
is a MAP problem since the available evidence does not usually specify the value of each
c
2004
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiPark & Darwiche

nonhealth variable. It is common to approximate this problem using MPE, in which case
one is finding the most likely configuration of every unknown variable, including health
variables and some other variables of no particular interest, such as the inputs and outputs
of system components. However, the projection of an MPE solution on health variables is
usually not a most likely configuration. Neither is the configuration obtained by choosing
the most likely state of each health variable separately.
MAP turns out to be a very difficult problem, even when compared to the MPE problem,
or to the Pr problem for computing the probability of evidence. Specifically, we provide
in Section 2 some complexity results which indicate that neither exact nor approximate
solutions can be guaranteed for MAP, even under very restricted circumstances. Yet, MAP
remains an important problem for which we would like to generate solutions. Therefore, we
propose in Section 3 a general framework based on local search for besteffort approximation
of MAP. We also provide two specific instances of the proposed framework, one is applicable
to networks that are amenable to exact computation of Pr and is given in Section 3, while the
other is applicable to networks that are not even amenable to Pr and is given in Section 4.
We report on experimental results for each method using realworld and randomly generated
Bayesian networks, which illustrate the effectiveness of our proposed framework on a wide
range of networks. We close our paper by some concluding remarks in Section 5.

2. MAP Complexity
We begin this section by reviewing some complexity theory classes and terminology that pertain to the complexity of MAP. We then examine the complexity of MAP in the general case,
followed by examining the complexity when the number of MAP variables is constrained.
We then consider the complexity of MAP algorithms based on variable elimination. We
conclude the complexity section by examining the complexity of MAP on polytrees.
2.1 Complexity Review
We assume that the reader is familiar with the basic notions of complexity theory like the
hardness and completeness of languages, as well as the complexity class NP.
In addition to NP, we will also be interested in the class PP and a derivative of it.
Informally, PP is the class which contains the languages for which there exists a nondeterministic Turing machine where the majority of the nondeterministic computations accept
if and only if the string is in the language. PP can be thought of as the decision version of
the functional class #P. As such, PP is a powerful language. In fact NP  PP, and the
inequality is strict unless the polynomial hierarchy collapses to the second level. 1
Another idea we will need is the concept of an oracle. Sometimes it is useful to ask
questions about what could be done if an operation were free. In complexity theory this is
modeled as a Turing machine with an oracle. An oracle Turing machine is a Turing machine
with the additional capability of being able to obtain answers to certain queries in a single
time step. For example, we may want to designate the class of languages that could be
1. This is a direct result of Todas theorem (Toda, 1991). From Todas theorem PPP contains the entire
polynomial hierarchy (PH), so if NP = PP, then PH  PPP = PNP .

102

fiComplexity Results and Approximation Strategies for MAP Explanations

recognized in nondeterministic polynomial time if any PP query could be answered for free.
The class of languages would be NP with a PP oracle, which is denoted NP PP .
Consider now a Boolean expression  over variables X 1 , . . . , Xn . The following three
classical problems are complete for the above complexity classes:
SAT: Is there a truth assignment (world) that satisfies ? This problem is NPcomplete.
MAJSAT: Do the majority of worlds satisfy ? This problem is PPcomplete.
E-MAJSAT: Is there an instantiation of variables X 1 ,. . . ,Xk , 1  k  n, under which the
majority of worlds satisfy ? This problem is NP PP complete.
Intuitively, to solve an NPcomplete problem we have to search for a solution among an
exponential number of candidates, where it is easy to decide whether a given candidate
constitutes a solution. For example, in SAT, we are searching for a world that satisfies
a sentence (testing whether a world satisfies a sentence can be done in time linear in the
sentence size). To solve a PPcomplete problem, we have to add up the weights of solutions,
where it is easy to decide whether a particular candidate constitutes a solution and it is
also easy to compute the weight of a solution. For example, in MAJSAT, a solution is
a world that satisfies the sentence and the weight of a solution is 1. Finally, to solve an
NPPP complete problem, we have to search for a solution among an exponential number of
candidates, but we also need to solve a PPcomplete problem in order to decide whether a
particular candidate constitutes a solution. For example, in E-MAJSAT, we are searching
for an instantiation x1 , . . . , xk , but to test whether an instantiation satisfies the condition
we want, we must solve a MAJSAT problem.
2.2 Decision Problems
We will be dealing with the decision versions of Bayesian network problems in this paper,
which we define formally in this section.
A Bayesian network is a pair (G, ), where G is a directed acyclic graph (DAG) over
variables X, and  defines a conditional probability table (CPT)  X|U for each variable
X and its parents U in the DAG G. That is, for each value x of variable X and each
instantiation u of parents U, the CPT  X|U assigns a number in [0, 1], denoted by  x|u ,
to represent the probability of x given u. 2 The probability distribution Pr induced by a
Bayesian network (G, ) is given as follows. For a complete instantiation x of the network
variables X, the probability of x is given by
Pr(x)

def

Y

=

x|u ,

xux

where xu is the instantiation of a family (a variable and its parents) and  represents
the compatibility relation among instantiations. That is, the probability assigned to a
complete variable instantiation x is the product of all parameters that are consistent with
that instantiation.
The following decision problems assume that we are given a Bayesian network (G, )
that has rational parameters and induces the probability distribution Pr. Moreover, by
evidence e, we mean an instantiation of variables E.
2. Hence, we must have

P

x

x|u = 1.

103

fiPark & Darwiche

D-MPE: Given a rational number p, evidence e, and the set of network variables X, is
there an instantiation x such that Pr(x, e) > p?
D-PR: Given a rational number p and evidence e, is Pr(e) > p?
D-MAP: Given a rational number p, evidence e, and some set of variables Q, is there an
instantiation q such that Pr(q, e) > p? Variables Q are called the MAP variables in
this case.
While decision problems are useful for examining the complexity of finding an exact solution, what we are really interested in is the functional problem of actually computing the
solution. When we cant solve the problem exactly, we would also like to know how close
we can get efficiently. For that we consider approximation algorithms. We now define the
notion of an approximation factor which we will use when discussing the complexity of approximation algorithms. Specifically, we will say that an approximate solution M 0 is within
the approximation factor  > 1 of the true solution M in case M  M 0  M . Moreover, we
will say that an algorithm provides an f (n)factor approximation in case for all problems of
size n, the approximate solutions returned by the algorithm are within the approximation
factor f (n).
2.3 MAP Complexity for the General Case
Computing MPE, Pr, and MAP are all NPHard, but there still appears to be significant
differences in their complexity. MPE is basically a combinatorial optimization problem.
Computing the probability of a complete instantiation is trivial, so the only real difficulty is
determining which instantiation to choose. D-MPE is NP-complete (Shimony, 1994). Pr is
a completely different type of problem, characterized by counting instead of optimization,
as we need to add up the probability of network instantiations. D-PR is PP-complete
(Litmman, Majercik, & Pitassi, 2001)notice that this is the complexity of the decision
version, not the functional version which is #P-complete (Roth, 1996). MAP combines
both the counting and optimization paradigms. In order to compute the probability of a
particular instantiation, a Pr query is needed. Optimization is also required, in order to be
able to decide between the many possible instantiations. This is reflected in the complexity
of MAP.
Theorem 1 D-MAP is NPPP -complete.3
Proof: Membership in NPPP is immediate. Given any instantiation q of the MAP variables,
we can verify if it is a solution by querying the PP oracle if Pr(q, e) > k.
To show hardness, we reduce E-MAJSAT (Littman, Goldsmith, & Mundhenk, 1998)
to D-MAP by first creating a Bayesian network that models a Boolean formula . For each
variable Xi in the formula , we create an analogous variable in the network with values
{T, F } and a uniform prior probability. Then, for each logical operator, we create a variable
with values {T, F } whose parents are the variables corresponding to its operands, and whose
CPT encodes the truth table for that operator (see Figure 1 for a simple example). Let V 
be the network variable corresponding to the top level operand.
3. This result was stated without proof by Littman (1999).

104

fiComplexity Results and Approximation Strategies for MAP Explanations

X1

X2

X3

Figure 1: The Bayesian network produced using the reduction in Theorem 1 for Boolean
formula (x1  x2 )  x3 .

For a complete instantiation x of all of the variables X appearing in the Boolean expression , with evidence V = T , we have:
Pr(x, V = T ) =

(

1
2n

0

x satisfies 
otherwise

For a particular instantiation q of MAP variables X 1 , ..., Xk , and evidence V = T , we have:
Pr(q, V = T ) =

X

Pr(q, xk+1 , ..xn )

xk+1 ,...,xn

=

#q
2n

where #q is the number of complete variable instantiations compatible with q that satisfies
. Since there are 2nk possible instantiations of Xk+1 , ..., Xn , the fraction fq satisfied is
#q /2nk , so
fq
Pr(q, V = T ) = k
2
Thus, an instantiation q of the MAP variables is compatible with more than half of the
complete, satisfying instantiations if Pr(q, V  = T ) > 1/2k+1 . So the MAP query over
variables X1 , ..., Xk with evidence V = T and threshold 1/2k+1 is true if and only if the
E-MAJSAT query is also true. 2
In fact, the above theorem can be strengthened.
Theorem 2 D-MAP remains complete for NP PP even when (1) the network has depth 2,
(2) there is no evidence, (3) all variables are Boolean, and (4) all network parameters lie
in the interval [ 21  , 21 + ] for any fixed  > 0.
The proof appears in Appendix A. Unlike computing probabilities, which becomes easy
when the number of evidence nodes is bounded by a constant and the parameters are
bounded away from 0 (it falls into RP as described by Dagum & Luby, 1997), MAP retains
its NPPP complexity even under these restrictive circumstances. 4
4. This is not altogether surprising since when evaluating the score of a possible solution, the MAP variables
act as evidence variables.

105

fiPark & Darwiche

NPPP is a powerful class, even compared to NP and PP. NP PP contains other important
AI problems, such as probabilistic planning problems (Littman et al., 1998). The three
classes are related by NP  PP  NPPP , where the equalities are considered very unlikely.
In fact, NPPP contains the entire polynomial hierarchy (Toda, 1991). Additionally, because
MAP generalized Pr, MAP inherits the wild nonapproximability of Pr. From the Bayesian
network simulates SAT reduction we get:
Corollary 3 Approximating MAP within any approximation factor f (n) is NPhard.
Proof: Using the evidence V = T , the exact MAP solution is the number of satisfying
instantiations divided by 2n , which is 0 if it is unsatisfiable, and positive if it is satisfiable.
If the formula is unsatisfiable, then the approximate solution must be 0 because 0/ = 0 
M 0  0 = 0, where  = f (n). If the formula is satisfiable, then the approximate solution
must be positive since M/ > 0. Thus we can test satisfiability by testing if the approximate
MAP solution is zero or not.2
2.4 Complexity Parameterized by the Number of Maximization Variables
We now examine the complexity when we restrict the number of maximization variables.
Let n be the number of nonevidence variables, and k be the number of maximization
variables. In the extreme case of k = 0, this is simply D-PR, so it is PPcomplete. At
the other extreme, when k = n, it becomes D-MPE, and is NPcomplete. So constraining
the number of maximization variables can have a dramatic impact on the complexity. We
now examine this issue in detail. Let D-MAP m be the subset of D-MAP problems where
k = O(m), and let D-MAPm be the subset of D-MAP problems where n  k = O(m). We
can then consider the complexity of these parameterized classes of problems. The primary
results are the following:
Theorem 4 D-MAPlog n is in PPP , and D-MAPlog n is in NP. However, for any  > 0,

both D-MAPn and D-MAPn remain NPPP complete.
Proof: First, if k = O(log n), then the number of possible instantiations of the maximization
variables is bounded by a polynomial. Thus, given a PP oracle, it is possible to decide
the problem in polynomial time by asking for each instantiation q of the maximization
variables whether Pr(q, e) exceeds the threshold. Similarly, if n  k = O(log n), then for
any instantiation q of the maximization variables, we can test to see if Pr(q, e) exceeds the
threshold by summing over the polynomial number of compatible instantiations.
For k = O(n ) we can provide a simple reduction to solve any D-MAP problem by
creating a polynomially larger one satisfying the constraint on the number of maximization
variables. From the unconstrained problem, we simply create a new problem by adding a
polynomial number of irrelevant variables, with no parents or children. Similarly, we can
provide a reduction of the general D-MAP problem to one constrained to have n  k =
O(n ), by adding a polynomial number of maximization variables with no parents, no
children, and deterministic priors. 2
106

fiComplexity Results and Approximation Strategies for MAP Explanations

2.5 Results for Elimination Algorithms
Solution to the general MAP problem seems out of reach, but what about for easier networks? Stateoftheart exact inference algorithms (variable elimination (Dechter, 1996),
join trees (Lauritzen & Spiegelhalter, 1988; Shenoy & Shafer, 1986; Jensen, Lauritzen, &
Olesen, 1990), recursive conditioning (Darwiche, 2001)) can compute P r and MPE in space
and time complexity that is exponential only in the width of a given elimination order.
This allows many networks to be solved using reasonable resources even though the general
problems are very difficult. Similarly, stateoftheart MAP algorithms can also solve MAP
with time and space complexity that is exponential only in width of used elimination order
but, for MAP, not all orders can be used. In this section, we investigate the complexity of
variable elimination for MAP.
Before analyzing the complexity of variable elimination for MAP, we review variable
elimination. First, we need the concept of a potential. A potential is simply a function over
some subset of the variables, which maps each instantiation of its variables to a real number.
The size of a potential is parameterized by the number of instantiations of its variables,
and so is exponential in the number of variables. Notice that CPTs are potentials. In
order to use variable elimination for Pr, MPE and MAP, we need three simple operations:
multiplication, summingout, and maximization. Multiplication of two potentials  1 and
2 with variables XY and YZ respectively (where Y is the set of variables they have in
common), is defined as (1 2 )(xyz) = 1 (xy)2 (yz). Notice that if both X and Z are
nonempty, then the size of 1 2 is greater than the size of either 1 or 2 . SumOut(,Y)
where  is over variables XY is defined as
SumOut(, Y)(x) =

X

(xy),

y

where y ranges over the instantiations of Y. Maximization is similar to summing out but
maximizes out the unwanted variables:
Maximize(, Y)(x) = max (xy).
y

In order to handle evidence, we need the concept of an evidence indicator. The evidence
indicator E associated with evidence E = e is a potential over variable E where  E (e) = 1,
and is zero for all other values.
Given a variable ordering , variable elimination can be used to compute the probability
of evidence e as follows:
1. Initialize P to contain the evidence indicators for e and all of the conditional probability tables.
2. For each variable X, according to order ,
(a) Remove from P all potentials mentioning X.
(b) Let MX be the product of all of those potentials.
(c) add SumOut(MX , X) to P .
3. Return the product of all potentials in P .
107

fiPark & Darwiche

In each iteration, a variable X is eliminated which leads to removing all mention of X from
P . By step 3, all variables have been removed, so the potentials remaining are just constants
and the resulting product is a single number representing the probability of evidence e. MPE
is computed in the same way, except the projection in step 2c is replaced by maximization.
The complexity of variable elimination is linear in the number of variables and linear in the
size of the largest potential MX produced in step 2b. The size of the largest potential varies
significantly based on the elimination order. The width of an elimination order is simply
log2 (size(MX ))1 where MX is the largest potential produced using that elimination order. 5
The treewidth of a Bayesian network is the minimum width of all elimination orders. For
Pr and MPE, any elimination order can be used, so the complexity is linear in the number
of variables and exponential in the treewidth. The same is not true for MAP. Variable
elimination for MAP is similar to the other methods, but with an extra constraint. In
step 2c, if X is a MAP variable the projection is replaced with maximization. If it is not
a MAP variable projection is used. The extra constraint is that not all orders are valid.
Maximization and projection do not commute, and maximization must be performed last.
This means that for an elimination order to be valid for performing MAP, when X is a MAP
variable, the potential in step 2b must not mention any non-MAP variables. In practice
this is ensured by requiring that the elimination order eliminate all of the MAP variables
last. This tends to produce elimination orders with widths much larger than those available
for Pr and MPE, often placing exact MAP solutions out of reach.
In order to assess the magnitude of increase in width caused by restricting the elimination order, we randomly generated 100 Bayesian networks, each containing 100 variables,
according to the first method in Appendix B. For each network, we computed the width
using the minfill heuristic (Kjaerulff, 1990; Huang & Darwiche, 1996). Then, we repeatedly added a single variable to the set of MAP variables, and computed the constrained
width, again using minfill, but eliminating the MAP variables last. This process was repeated until all variables were in the MAP variable set. Figure 2 contains statistics on
these experiments. The Xaxis corresponds to the number of MAP variables (thus X = 0
corresponds to the unconstrained width). The Y axis corresponds to the width found. The
graph details the minimum, maximum, mean, and weighted mean for each of the 100 networks. The weighted mean takes into account that the complexity is exponential in the
width, and so provides a better representation of the average complexity. It was computed
P
as log2 ( n1 ni=1 2wi ). Notice that the unconstrained widths range from 11 to 18, and that
as the number of MAP variables increases, the width increases dramatically. For example,
even when only a quarter of the variables are MAP variables (X = 25) the widths range
between 22 and 34, (which corresponds roughly from difficult but doable to well beyond
what todays inference algorithms can handle on todays computers) with a weighted average above 30. Notice also, that as we would expect from our complexity analysis, problems
with very few or very many MAP variables are significantly easier than those in the middle
range.
We now consider the question of whether there are less stringent conditions for valid
elimination orders, that may allow for orders with smaller widths.
5. The -1 in the definition is to preserve compatibility with the previously defined notion of treewidth in
graph theory.

108

fiComplexity Results and Approximation Strategies for MAP Explanations

80

max
weighted mean
mean
min

Constrained Width

70
60
50
40
30
20
10

0

20
40
60
80
Number of MAP variables

100

Figure 2: Statistics on the constrained width for different numbers of MAP variables. The
Xaxis is the number of MAP variables, and the Y axis is the width. Notice that
the widths required for the general MAP problem are significantly larger than for
Pr or MPE, which correspond to X = 0 and X = 100 respectively.

As described earlier, given an ordering, elimination algorithms work by stepping through
the ordering, collecting the potentials mentioning the current variable, multiplying them,
then replacing them with the potential formed by summing out (or maximizing) the current
variable from the product. This process can be thought to induce an evaluation tree; see
Figure 3. The evaluation tree for an elimination order  is described as follows. The leaves
correspond to the CPTs of given Bayesian network, and the internal nodes correspond to
potentials created during the elimination process. The children of a potential  represent
other potentials that had to be multiplied together when constructing . Note that each
internal node in the elimination tree corresponds to variable in the order , whose elimination leads to constructing the node; Figure 3(b). Therefore, an evaluation tree can be
viewed as inducing a partial elimination order; see Figure 3(c).
The standard way of constructing a valid elimination order for MAP is to eliminate the
MAP variables Q last. Two questions present themselves. First, are there valid orderings
in which variables Q are not eliminated last? And second, if so, can they produce widths
smaller than those generated by eliminating variables Q last?
The answer to the first question is yes, there are other valid elimination orders in which
variables Q are not eliminated last. To see that, suppose we have a variable order 
which induces a particular evaluation tree T , and let  be the partial elimination order
corresponding to T . Any variable order  0 which is consistent with the partial order  will
109

fiPark & Darwiche

C
C
A

C

CD B

B

C

D

E
a.

D

BC

C

A

Pr(A) Pr(B|A) Pr(C|A) Pr(D|BC) Pr(E|C)
b.

D

E

E

B
A
c.

Figure 3: (a) A Bayesian network, (b) an evaluation tree for the elimination order
A, E, B, D, E, and (c) a partial elimination order induced by the evaluation tree.

also induce the tree T . Hence, if order  was valid, then order  0 will also be valid. Figure 3
shows the evaluation tree induced by using the order A, E, B, D, C for computing MAP
over variables Q = C, D. The order A, B, D, E, C is consistent with this evaluation tree
and, hence, is also valid for computing MAP over variables C, D. Yet, variables C, D do
not appear last in the order.
Unfortunately, orders in which variables Q are not eliminated last do not help.
Theorem 5 For any elimination order  which is valid for computing MAP over variables
Q, there is an ordering of the same width in which variables Q are eliminated last.
Proof: Consider the evaluation tree induced by any valid elimination order, and the corresponding partial order it induces. No variable in Q is the parent of any variable in Q.
To prove this, suppose that X is a parent of Y in the evaluation tree, where X  Q and
Y  Q. This means that the potential which results from eliminating variable Y includes
variable X, which also means that X must have appeared in some of the potentials we
multiplied when elimination variable Y . But this is a contradiction since the evaluation
tree and its underlying order are valid. Since no variable in Q is a parent of a variable in
Q, all variables in Q can be eliminated first in any order consistent with the partial order
defined by the evaluation tree. Then, all variables in Q can be eliminated, again obeying
the partial ordering defined by the evaluation tree. Because the produced order has the
same elimination tree as the original order, they have the same width. 2
2.6 MAP on Polytrees
Theorem 5 has significant complexity implications for elimination algorithms even on polytrees.
Theorem 6 Elimination algorithms require exponential resources to perform MAP, even
on some polytrees.
Proof: Consider computing MAP over variables X 1 , . . . , Xn given evidence Sn = T for
the network shown in Figure 4. By Theorem 5, there is no order whose width is smaller
110

fiComplexity Results and Approximation Strategies for MAP Explanations

than that of an order  in which we eliminate variables S 0 , . . . , Sn first, and then variables
X1 , . . . , Xn last. It is easy to show though that any such order  will have width n. Hence,
variable elimination will require exponential resources using such an order. 2
The set of MAP variables makes a crucial difference in the complexity of MAP computations. For example, if the MAP variables were X 1 , . . . , Xn/2 , S0 , . . . , Sn/2 instead of
X1 , . . . , Xn can be solved in linear time.
The above negative findings are specific to variable elimination algorithms. The question
then is whether this difficulty is an idiosyncrasy of variable elimination which can be avoided
if we were to use some other method for computing MAP. The following result, however,
shows that finding a good general algorithm for MAP on polytrees is unlikely.
Theorem 7 MAP is N P complete when restricted to polytrees.
Proof: Membership is immediate. Given a purported solution instantiation q, we can
compute Pr(q, e) in linear time and test it against the bound. To show hardness, we reduce
MAXSAT to MAP on a polytree.6 Similar reductions were used by Papadimitriou and
Tsitsiklis (1987) and Littman et al. (1998) relating to partially observable Markov decision
problems, and probabilistic planning respectively. The MAXSAT problem is defined as
follows:
Given a set of clauses C1 , ..., Cm over variables Y1 , ..., Yn and an integer bound
k, is there an assignment of the variables, such that more than k clauses are
satisfied.
The idea behind the reduction is to model the random selection of a clause, and then
successively checking whether the instantiation of each variable satisfies the selected clause.
The clause selector variable S0 with possible values 1, 2, ..., m has a uniform prior. Each
propositional variable Yi induces two network variables Xi and Si , where Xi represents the
value of Yi , and has a uniform prior, and Si represents whether any of Y1 , ..., Yi satisfy the
selected clause. Si = 0 indicates that the selected clause was satisfied by one of Y 1 , ..., Yi .
Si = c > 0 indicates that the selected clause C c was not satisfied by Y1 , ..., Yi . The parents
of Si are Xi and Si1 (the topology is shown in Figure 4). The CPT for S i , for i  1 is
defined as

1 if si = si1 = 0





1 if si = 0 and si1 = j, and



xi satisfies cj
P r(si |xi , si1 ) =

1
if
si = si1 = j and xi does




not
satisfy cj



0 otherwise

In words, if the selected clause was not satisfied by the first i  1 variables (s i1 6= 0), and
xi satisfies it, then Si becomes satisfied (si = 0). Otherwise, we have si = si1 . Now, for a
particular instantiation s0 of S0 , and instantiation x of variables X 1 , ..., Xn ,
Pr(s0 , x, Sn = 0) =

(

1/(m2n ) if x satisfies clause Cs0 ;
0
otherwise.

6. Actually, we only need to reduce it to SAT, but the MAXSAT result will be used in Theorem 8.

111

fiPark & Darwiche

S0

X1

X2

S1

S2

Xn
...

Sn

Figure 4: The network used in the reduction of Theorem 7.
Summing over S0 yields P r(x, Sn = 0) = #C /(m2n ) where #C is the number of clauses
that x satisfies. Thus MAP over X1 , ..., Xn with evidence Sn = 0 and bound k/(m2n ) solves
the MAXSAT problem as well. 2
Since MAXSAT has no polynomial time approximation scheme (unless P = NP), no
polynomial time approximation scheme exists for MAP on polytrees. In fact, approximating
MAP on polytrees appears to be much harder than approximating MAXSAT.


Theorem 8 Approximating MAP on polytrees within a factor of 2 n is NP-hard for any
fixed , 0   < 1, where n is the size of the problem.
The proof appears in Appendix A. So, not only is it hard to approximate within a constant
factor, it is hard to approximate within a polynomial factor, or even a subexponential factor.
We close this section by a summary of the complexity results in this section:
 MAP is NPPP complete for arbitrary Bayesian networks, even if we have no evidence,
every variable is binary, and the parameters are arbitrarily close to 1/2.
 It is NPhard to approximate MAP within any factor f (n).
 Variable elimination for MAP requires exponential time, even on some polytrees.
 MAP is NPcomplete for networks with polytree structure.


 Approximating MAP on polytrees within a factor of 2 n is NPhard for any fixed
  [0, 1).

3. Approximating MAP when Inference is Easy
Since exact MAP computation is often intractable, approximation techniques are needed.
Unfortunately, in spite of MAPs utility, relatively little work has been done in approximating it. In fact, there are only two previous methods for approximating MAP which
we are aware of. The first (Dechter & Rish, 1998) uses the minibucket technique. The
other (de Campos, Gamez, & Moral, 1999), uses genetic algorithms to approximate the
best k configurations of the MAP variables (this problem is known as partial abduction).
Practitioners typically resort to one of two simple approximation methods. One common
approximation technique is to compute an MPE instantiation and then project the result
on the MAP variables. That is, if we want to compute MAP for variables S given evidence
e, and if S0 is the complement of variables S  E, we compute an instantiation s, s 0 that
maximizes Pr(s, s0 | e) and then return s. The other method computes posterior marginals
112

fiComplexity Results and Approximation Strategies for MAP Explanations

for the MAP variables, Pr(S | e), S  S, and then choose the most likely state s of each
variable given e.
We propose a general framework for approximating MAP. MAP consists of two problems
that are hard in generaloptimization and inference. A MAP approximation algorithm can
be produced by substituting approximate versions of either the optimization or inference
component (or both). The optimization problem is defined over the MAP variables, and
the score for each solution candidate instantiation s of the MAP variables is the (possibly
approximate) probability Pr(s, e) produced by the inference method. This allows solutions
tailored to the specific problem. For networks whose treewidth is manageable, but contains
a hard optimization component (e.g. the polytree examples discussed previously), exact
structural inference can be used, coupled with an approximate optimization algorithm.
Alternatively, if the optimization problem is easy (e.g. there are few MAP variables) but
the network isnt amenable to exact inference, an exact optimization method could be
coupled with an approximate inference routine. If both components are hard, both the
optimization and inference components need to be approximated.
We investigate in this section a family of approximation algorithms based on local search.
We first consider the case when inference is tractable, then develop an extension to handle
the case when inference is infeasible. The local search algorithms work basically as follows:
1. Start from an initial guess s at the solution.
2. Iteratively try to improve the solution by moving to a better neighbor s 0 : Pr(s0 | e) >
Pr(s | e), or equivalently Pr(s0 , e) > Pr(s, e).
A neighbor of instantiation s is defined as an instantiation which results from changing the
value of a single variable X in s. If the new value of X is x, we will denote the resulting
neighbor by s  X, x. In order to perform local search efficiently, we need to compute the
scores for all of the neighbors sX, x efficiently. That is, we need to compute Pr(sX, x, e)
for each X  S and each of its values x not in s. If variables have binary values, we will
have | S | neighbors in this case.
Local search has been proposed as a method for approximating MPE (Kask & Dechter,
1999; Mengshoel, Roth, & Wilkins, 2000). For MPE, the MAP variables S contain all
variables which are not in E (the evidence variables). Therefore, the score of a neighbor,
Pr(s  X, x, e), can be computed easily since s  X, x, e is a complete instantiation. In fact,
given that we have computed Pr(s, e), the score Pr(sX, x, e) can be computed in constant
time.7
Unlike MPE, computing the score of a neighbor, Pr(s  X, x, e), in MAP requires a
global computation since s  X, x, e may not be a complete instantiation. One of the main
observations underlying our approach, however, is that the score Pr(s  X, x, e) can be
computed in O(n exp(w)) time and space, where n is the number of network variables and
7. This assumes that none of entries in the CPTs are 0. If there are 0 entries in the CPTs, it may take
time linear in the number of network variables to compute the score. Pr(s, e) is the product of the single
entry of each CPT that is compatible with s, e. When changing the state of variable X from x to x 0 , the
only values in the product that change are those from the CPTs of X and its children. If none of the
CPT entries are 0, P r(s  X, x0 , e) can be computed by dividing Pr(s, e) by the old and multiplying by
the new entry for the CPTs for X and its children. This can be done in constant time if the number of
children is bounded by a constant.

113

fiPark & Darwiche

w is the width of an arbitrary elimination order, i.e., we can use any elimination order
for this purpose, no need for any constraints. In fact, we can even do better than this by
computing the scores of all neighbors, Pr(s  X, x, e) for all X  S and every value x of
X, in O(n exp(w)) time and space. Thus, if we have an elimination order of width w for
the given Bayesian network, then we can perform each search step in O(n exp(w)) time
and space. As we shall see later, it takes a small number of search steps to obtain a good
MAP solution. Hence, the overall runtime is often O(n exp(w)) too. Therefore, we can
produce good quality MAP approximations in time and space which are exponential in the
unconstrained width instead of the constrained one, which is typically much larger.
The local search method proposed in this section differs from the local search methods
used for MPE in that the unconstrained width must be small enough so that a search step
can be performed relatively efficiently. It is pointless to use this method to approximate
MPE since in the time to take one step, the MPE could be computed exactly. This method
is applicable when the unconstrained width is reasonable but the constrained width is not
(see Figure 2).
3.1 Computing Neighbor Scores Efficiently
The key to computing the neighbor scores efficiently is to express the inference problem
as a function over the evidence indicators. For each state x of variable X, the evidence
indicator x is one if it is compatible with the evidence, and zero otherwise. This is a
common technique that is typically used to allow the modeling of a wider range of evidence
assertions. For example, this allows evidence assertions such as X 6= x by setting  x = 0,
and the remaining indicators for X to one. We will use them for a different purpose however.
When the inference problem is cast as a function f of the evidence indicators (f ( e ) = Pr(e),
where e consists of all of the evidence indicators, set so that they are compatible with e),
f
(e ) = Pr(e  X, x). When our we add the current state to the evidence, this
then 
x
partial derivative yields Pr(s  X, x, e), which is precisely the score for one of the neighbors.
We can use the jointree algorithm (Park & Darwiche, 2003), or the differential inference
approach (Darwiche, 2003) to compute all of the partial derivatives efficiently. In the differential approach, these values are immediate, as the entire approach is based on evaluating
and differentiating the expression f above. It can also be computed using jointrees by using
the ShenoyShafer propagation scheme. Specifically, an evidence indicator table is added
for each variable, and evidence about that variable is entered by setting the appropriate
indicator entries. The partial derivatives of all of the indicators associated with a variable
are obtained by multiplying all other tables assigned to the same cluster, and all messages
into the cluster, then projecting that product onto the variable. In either case, the partial derivatives for all indicators, and thus the score for all neighbors, can be computed
in O(n exp(w)) time, which is the same complexity as simply computing the score for the
current state.
3.2 Search Methods
We tested two common local search methods, stochastic hill climbing and taboo search.
Stochastic hill climbing proceeds by repeatedly either changing the the state of the variable
114

fiComplexity Results and Approximation Strategies for MAP Explanations

Given: Probability distribution Pr, evidence e, MAP variables S,
the probability of taking a random flip Pf , and initial state s0 .
Compute: An instantiation s which (approximately) maximizes Pr(s | e).
Initialize current state s to s0 .
sbest = s
Repeat manytimes:
With probability Pf do
s = s0 , where s0 is a randomly selected neighbor of s.
Otherwise
Compute the score P r(s  X, x, e) for each neighbor s  X, x.
If no neighbor has a higher score that the score for s then
s = s0 , where s0 is a randomly selected neighbor of s.
Else
s = s0 where s0 is the neighbor with the highest score.
If P r(s, e) > P r(sbest , e) then
sbest = s
Return sbest

Figure 5: Stochastic hill climbing algorithm.

that creates the maximum probability change, or changing a variable at random. Figure 5
gives the algorithm explicitly.
Taboo search is similar to hill climbing except that the next state is chosen as the
best state that hasnt been visited recently. Because the number of iterations is relatively
small we save all of the previous states so that at each iteration a unique point is chosen.
Pseudocode for taboo search appears in Figure 6.
3.3 Initialization
The quality of the solution returned by a local search routine depends to a large extent on
which part of the search space it is given to explore. We implemented several algorithms
to compare the solution quality with different initialization schemes. Suppose that n is the
number of network variables, w is the width of a given elimination order, and m is the
number of MAP variables.
1. Random initialization (Rand). For each MAP variable, we select a value uniformly
from its set of states. This method takes O(m) time.
2. MPE based initialization (MPE). We compute the MPE solution given the evidence.
Then, for each MAP variable, we set its value to the value that the variable takes on
in the MPE solution. This method takes O(n exp(w)) time.
3. Maximum likelihood initialization (ML). For each MAP variable X, we set its value
to the instance x that maximizes P r(x | e). This method takes O(n exp(w)) time.
4. Sequential initialization (Seq). This method considers the MAP variables X 1 , . . . , Xm ,
choosing each time a variable Xi that has the highest probability Pr(x i | e, y) for one
115

fiPark & Darwiche

Given: Probability distribution Pr, evidence e, MAP variables S.
Compute: An instantiation s which (approximately) maximizes Pr(s | e).
Initialize current state s.
sbest = s
Repeat many times
Add s to visited
Compute the score P r(s  X, x, e) for each neighbor s  X, x.
s = s0 where s0 is a neighbor with the highest score not in visited .
If no such neighbor exists (this rarely occurs)
Repeat for several times
s = s0 where s0 is a randomly selected neighbor of s.
If P r(s, e) > P r(sbest , e) then
sbest = s
Return sbest

Figure 6: Taboo search. Notice that the action taken is to choose the best neighbor that
hasnt been visited. This leads to moves that decrease the score after a peak is
discovered.

of its values xi , where y is the instantiation of MAP variables considered so far. This
method takes O(mn exp(w)) time.
3.4 Experimental Results
Two search methods (Hill and Taboo) and four initialization methods (Rand, MPE, ML,
Seq) lead to 8 possible algorithms. Each of the initialization methods can also be viewed as
an approximation algorithm since one can simply return the computed initialization. This
leads to a total of 12 different algorithms. We experimentally evaluated and compared 11
of these algorithms, leaving out the algorithm corresponding to random initialization.
We tested the algorithms on various synthetically generated data sets as well as real
world networks. For the synthetic networks, we generated random network structures using
two generation methods (see Appendix B). For each structure, we quantified the CPTs
for different bias coefficients from 0 (deterministic except the roots), to .5 (values chosen
uniformly) so we could evaluate the influence of CPT quantification on the solution quality.
Each network consisted of 100 variables, with some of the root variables chosen as the MAP
variables. If there were more than 25 root variables, we randomly selected 25 of them for
the MAP variables. Otherwise we used all of the root variables. We chose root nodes for
MAP variables because typically some subset of the root nodes are the variables of interest
in diagnostic applications. Evidence was set by instantiating leaf nodes. Care was taken to
insure that the instantiation had a non zero probability. Each algorithm was allowed 150
network evaluations.8 We computed the true MAP and compared it to the solutions found
by each algorithm. Additionally, we measured the number of network evaluations needed to
find the solution each algorithm subsequently returned, and the number of peaks discovered
8. An evaluation takes O(n exp(w)) time and space, where n is the number of network variables and w is
the width of given elimination order.

116

fiComplexity Results and Approximation Strategies for MAP Explanations

Data Set 1
0
Rand-Hill 147
Rand-Taboo 181
ML 526
ML-Hill 920
ML-Taboo 942
MPE 999
MPE-Hill 999
MPE-Taboo 1000
Seq 930
Seq-Hill 941
Seq-Taboo 962

Solution Quality
.125 .250
.375
805 917
946
969 985
993
497 676
766
947 989
993
988 999
999
333 160
127
875 923
952
986 992
990
965 990
999
971 992
999
998 1000 1000

.5
966
995
817
997
1000
100
973
998
997
997
1000

Table 1: The solution quality of each method for the first data set. The number associated
with each method and bias is the number of instances solved correctly out of 1000.
The best scores for each bias are shown in bold.
Data Set 2
0
Rand-Hill 20
Rand-Taboo 20
ML 749
ML-Hill 966
ML-Taboo 973
MPE 858
MPE-Hill 961
MPE-Taboo 978
Seq 988
Seq-Hill 988
Seq-Taboo 994

Solution Quality
.125 .250 .375
634 713 799
851 907 943
453 495 519
922 947 963
960 986 987
505 365 275
853 850 874
952 962 977
955 964 985
960 966 986
977 990 994

.5
845
965
514
962
990
206
891
980
972
976
994

Table 2: The solution quality of each method for the second data set. The number associated with each method and bias is the number of instances solved correctly out of
1000. The best scores for each bias are shown in bold.

before that solution was discovered. The hill climbing method used in these data sets is
pure hill climbing with random walk restart. That is, it hill climbs until it reaches a peak,
then randomly flips some of the values to move to a new location.
We generated 1000 random network structures for each of the two structural generation methods. For each random structure generated, and each quantification method, we
quantified the network, computed the exact MAP, and applied each of the approximation
117

fiPark & Darwiche

algorithms. Tables 1 and 2 show the solution quality of each of the methods by reporting
the fraction of networks that were solved correctly; that is, the approximate answer had the
same value as the exact answer.
One can draw a number of observations based on these experiments:
 In each case, taboo search performed slightly better than hill climbing with random
restarts.
 The search methods were typically able to perform much better than the initialization
alone.
 Even from a random start, the search methods were able to find the optimal solution
in the majority of the cases.
 Overall, taboo search with sequential initialization performed the best, but required
the most network evaluations.
Table 3 contains some statistics on the number of network evaluations (including those
used for initialization) needed to achieve the value that the method finally returned. The
mean number of evaluations is quite small for all of the methods. Surprisingly, for the hill
climbing methods, the maximum is also quite small. In fact, after analyzing the results we
discovered that the hill climbing methods never improved over the first peak they discovered.9 This suggests that one viable method for quick approximation is to simply climb to
the first peak and return the result. Taboo search on the other hand was able to improve
on the first peak in some cases.
We ran ten MAP queries for each real world network we tested. For each query we
randomly selected one fourth of the nodes to be the variables of interest, and selected
one fourth of the nodes to be evidence nodes. The evidence values were chosen uniformly
among the nonzero configurations. As our previous experiments demonstrated that a large
number of iterations rarely helps, we reduced the number of iterations to 30. Also, we
moved away from hill climbing with random restart to stochastic hill climbing (performing
a random move with probability .35) since in our previous experiments the random restart
never helped. Also, we ran a minibucket approximation algorithm (the only other MAP
approximation algorithm we are aware of that is not subsumed by our technique) to compare
its performance to our algorithms. Since exact MAP computations on these networks is
too hard for current algorithms to handle, we compare the algorithms based on relative
performance only.
Table 4 shows the number of times (out of ten) that each algorithm was able to produce
the highest probability configuration discovered. The search based methods again performed
much better than the other algorithms. Note that each of them outperformed the mini
bucket approximations on each network. Table 5 provides more specific details about the
relative performance for each network. Each block contains the count of the number of
times that each method produced solutions within some range of the best found solution.
9. It appears that the random walk used in restarting does not make eventually selecting a better region
very likely when using so few search steps. Often, when a sub optimal hill was encountered, the optimal
hill was just 2 or 3 moves away. In those cases, the taboo search was usually able to find it (because its
search was more guided), while random walking was not.

118

fiComplexity Results and Approximation Strategies for MAP Explanations

Evaluations Required
Method Mean Stdev
Rand Hill
12.5
2.5
Rand Taboo
14.3
11.0
MPE
1
0
MPE Hill
2.6
1.3
MPE Taboo
4.0
8.3
ML
1
0
ML Hill
1.6
.74
ML Taboo
1.9
3.3
Seq
25
0
Seq Hill
25.0
.04
Seq Taboo
25.0
.9

Max
21
144
1
8
137
1
4
62
25
26
45

Table 3: Statistics on the number of evaluations each method required before achieving the
value it eventually returned. These are based on the random method 2, bias .5
data set. The statistics for the other data sets are similar.

Barley
Mildew
Munin2
Munin3
Pigs
Water

I
3
6
6
9
0
9

MPE
H T
9
8
10 10
10 10
10 10
0
0
10 10

I
3
8
10
10
5
8

ML
H
10
10
10
10
9
10

T
9
10
10
10
9
10

I
7
8
10
10
8
10

Seq
H
10
10
10
10
8
10

T
10
10
10
10
8
10

14
1
4
4
4
3
6

MB
16 18
3
5
4
7
5
7
6
2
1
6
6
9

Table 4: Number of times out of ten that each algorithm found the instantiation that yielded
the highest score. I, H, and T refer to initialization only, hill climbing, and taboo
search respectively.

So for example, in the Barley group, in the MPE row, for the column labeled > .5 there
is a 3, indicating that in 3 of the 10 cases the solution found was between .5 and .9 times
the best solution found for that query.
Qualitatively, these results are very similar to those obtained for the random networks.
Again the search methods outperformed the static initialization methods. Note that for
different networks, different initializations perform better. Notice also, that the search
methods significantly outperformed the minibucket approximations in every network.
119

fiPark & Darwiche

Barley network results
Best > .9 > .5 > .01
3
2
3
2
9
0
0
1
8
0
1
1
3
2
2
0
10
0
0
0
9
0
1
0
7
3
0
0
10
0
0
0
10
0
0
0
1
2
1
3
3
3
1
2
5
2
0
3
Munin2 network results
Method Best > .9 > .5 > .01
MPE
6
0
4
0
Hill
10
0
0
0
Taboo
10
0
0
0
ML
10
0
0
0
Hill
10
0
0
0
Taboo
10
0
0
0
Seq
10
0
0
0
Hill
10
0
0
0
Taboo
10
0
0
0
MB 14
4
0
1
2
MB 16
5
0
1
2
MB 18
7
0
0
1
Pigs network results
Method Best > .9 > .5 > .01
MPE
0
0
0
0
Hill
0
0
0
0
Taboo
0
0
2
3
ML
5
1
3
1
Hill
9
0
1
0
Taboo
9
0
1
0
Seq
8
0
2
0
Hill
8
0
2
0
Taboo
8
0
2
0
MB 14
3
0
3
4
MB 16
1
1
4
3
MB 18
6
0
2
2
Method
MPE
Hill
Taboo
ML
Hill
Taboo
Seq
Hill
Taboo
MB 14
MB 16
MB 18

 .01
0
0
0
3
0
0
0
0
0
3
1
0
 .01
0
0
0
0
0
0
0
0
0
3
2
2
 .01
10
10
5
0
0
0
0
0
0
0
1
0

Mildew network results
Best > .9 > .5 > .01
6
1
3
0
10
0
0
0
10
0
0
0
8
1
1
0
10
0
0
0
10
0
0
0
9
1
0
0
10
0
0
0
10
0
0
0
4
1
0
1
4
0
0
1
7
0
1
0
Munin3 network results
Method Best > .9 > .5 > .01
MPE
9
0
0
1
Hill
10
0
0
0
Taboo
10
0
0
0
ML
10
0
0
0
Hill
10
0
0
0
Taboo
10
0
0
0
Seq
10
0
0
0
Hill
10
0
0
0
Taboo
10
0
0
0
MB 14
4
0
2
0
MB 16
6
0
1
0
MB 18
2
0
1
0
Water network results
Method Best > .9 > .5 > .01
MPE
9
0
1
0
Hill
10
0
0
0
Taboo
10
0
0
0
ML
8
1
1
0
Hill
10
0
0
0
Taboo
10
0
0
0
Seq
10
0
0
0
Hill
10
0
0
0
Taboo
10
0
0
0
MB 14
6
1
2
0
MB 16
6
1
2
1
MB 18
9
0
0
1
Method
MPE
Hill
Taboo
ML
Hill
Taboo
Seq
Hill
Taboo
MB 14
MB 16
MB 18

 .01
0
0
0
0
0
0
0
0
0
4
5
2
 .01
0
0
0
0
0
0
0
0
0
4
3
7
 .01
0
0
0
0
0
0
0
0
0
1
0
0

Table 5: Detailed performance measures on the real world networks. Each column contains
the number of times out of 10 that each algorithm was able to achieve the given
performance relative to the best solution found.

120

fiComplexity Results and Approximation Strategies for MAP Explanations

4. Approximating MAP when Inference is Hard
The techniques developed thus far depend on the ability to perform exact inference. For
many networks, even inference is intractable. In these cases, approximate inference can be
substituted in order to produce MAP approximations.
We investigate using belief propagation as the approximate inference scheme, and local
search for the optimization scheme. Iterative belief propagation is a useful approximate
inference algorithm for approximating MAP for a number of reasons and has proven to be
a very effective and efficient approximation method for a variety of domains. It has the
ability to approximate MPE, posterior marginals, and probability of evidence, allowing for
the same initialization schemes as we used for exact inference. Additionally, as we will
show in section 4.2, after a single inference call, the scores of neighbors in the search space
can be computed locally, allowing us to obtain the same linear speed up that we obtained
using a similar approach in the exact inference case. Thus belief propagation allows all
of the techniques for approximating MAP for inference tractable networks to be applied
approximately when inference is not tractable.
4.1 Belief Propagation Review
Belief propagation was introduced as an exact inference method on polytrees (Pearl, 1988).
It is a message passing algorithm in which each node in the network sends a message to its
neighbors. These messages, along with the CPTs and the evidence can be used to compute
posterior marginals for all of the variables. In networks with loops, belief propagation is no
longer guaranteed to be exact, and successive iterations generally produce different results,
so belief propagation is typically run until the message values converge. This has been
shown to provide very good approximations for a variety of networks (McEliece, Rodemich,
& Cheng, 1995; Murphy, Weiss, & Jordan, 1999), and has recently received a theoretical
explanation (Yedidia, Freeman, & Weiss, 2000).
Belief propagation works as follows. Each node X, has an evidence indicator  X where
evidence can be entered. If the evidence sets X = x, then  X (x) = 1, and is 0 otherwise. If
no evidence is set for X, then X (x) = 1 for all x. After evidence is entered, each node X
sends a message to each of its neighbors. The message a node X with parents U sends to
child Y is computed as
MXY = 

X

X Pr(X|U)

Y

MZX

Z6=Y

U

where Z ranges over the neighbors of X and  is a normalizing constant. 10 Similarly, the
message X sends to a parent U is
MXU = 

X

X Pr(X|U)

Y

MZX .

Z6=U

XU{U }

10. We use potential notation more common to join trees than the standard descriptions of belief propagation
because we believe the many indices required in standard presentations mask the simplicity of the
algorithm.

121

fiPark & Darwiche

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Figure 7: A scatter plot of the exact versus approximate retracted values of 30 variables
of the Barley network. The x-axis is the true probability, and the y-axis the
approximate probability.

Message passing continues until the message values converge. The posterior of X is then
approximated as
X
Y
Pr0 (X|e) = 
X Pr(X|U)
MZX .
Z

U

The messages are all initialized to 1. There are two main schemes for ordering the
messages. In the first scheme, all of the messages are computed simultaneously, based on
the previous set of messages. In the other scheme, messages are updated incrementally, and
in two phases, consistent with some ordering of the variables. In the first phase, in reverse
order, each variable sends a message to its neighbors that precede it in the order. In the
second phase, in order, each variable sends a message to its neighbors that come after it in
the order. We implemented the second scheme since empirically it seems to converge faster
than the first scheme (Murphy et al., 1999).
4.2 Approximating Neighbors Scores
Belief propagation allows us to approximate the scores of neighbors in the local search space
efficiently, similar to what we have done in the case of exact inference. The key as we shall
show next is to be able to compute the quantity Pr(x|e  X) for each variable X efficiently,
as we can use this quantity to rank the neighbors according to the desired score.
Specifically, in polytrees, the incoming messages are independent of the value of the
local CPT or any evidence entered. Hence, leaving the evidence out of the product yields
Pr(X|e  X) = 

X

Pr(X|U)

U

Y

MZX .

Z

Therefore, we can compute the above quantity for each variable after a single belief propagation. In networks that are not polytrees, the incoming messages are not necessarily
independent of the evidence or the local CPT, but as is done with other BP methods, we
ignore that and hope that it is nearly independent. Empirically, the approximation seems to
122

fiComplexity Results and Approximation Strategies for MAP Explanations

be quite accurate. Figure 7 shows a representative example, comparing the correspondence
between the approximate and exact retracted probabilities for 30 variables in the Barley
network. The x axis corresponds to the true retracted probability, and the y axis to the
approximation produced using belief propagation.
Still, Pr(x|e  X) is not quite what we want to score neighbors in the local search space.
But this quantity can be used to compute the ratio of the neighboring score to the current
score which allows such comparisons. Specifically, simple algebra shows that:
Pr(x, s  X, e)
Pr(x|s  X, e)
=
Pr(s, e)
Pr(xs |s  X, e)
where xs is the value that X takes on in the current instantiation s. Thus, we can find the
neighbor with the best score after a single belief propagation.
4.3 Experimental Results
For the first experiment, we consider the improvement possible over what is typically done
(MPE or ML) using it as a starting point and hill climbing from there. For the first
experiment, we generated 100 synthetic networks with 100 variables each using the first
method described in Appendix B with bias parameter 0.25 and width parameter of 13. We
generated the networks to be small enough that we could often compute the exact MAP
value, but large enough to make the problem challenging. We chose the MAP variables as the
roots (typically between 20 and 25 variables), and the evidence values were chosen randomly
from 10 of the leaves. We computed the true MAP for the ones which memory constraints
(512 MB of RAM) allowed. We computed the true probability of the instantiations produced
by the two standard methods. For both initialization methods we also computed the true
probability of the instantiations returned by pure hill climbing 11 (i.e. only greedy steps
were taken), and stochastic hill climbing with 100 steps, where random moves were taken
with probability pf = .3. Of the 100 networks, we were able to compute the exact MAP in
59 of them. Table 6 shows the number exactly solved for each method, as well as the worst
instantiation produced, measured as the ratio of the probabilities of the found instantiation
to the true MAP instantiation. All of the hill climbing methods improved significantly over
their initializations in general, although for 2 of the networks, the hill climbing versions
were slightly worse than the initial value (the worst was a ratio of .835), because of a slight
mismatch in the true vs. approximate probabilities. Over all, the stochastic hill climbing
routines outperformed the other methods.
In the second experiment, we generated 25 random MAP problems for the Barley network, each with 25 randomly chosen MAP variables, and 10 randomly chosen evidence
assignments. We use the same parameters as in the previous experiment. The problems
were too hard to compute the exact MAP, so we report only on the relative improvements
over the initialization methods. Table 7 summarizes the results. Again, the stochastic
hill climbing methods were able to significantly improve the quality of the instantiations
created.
11. We compare pure and stochastic hill climbing to evaluate what can be gained by stochastic methods.
The initial hill climb usually requires very few evaluations, so if stochastic methods make little difference,
efficiency considerations would dictate that pure hill climbing be used.

123

fiPark & Darwiche

MPE
MPE-Hill
MPE-SHill
ML
ML-Hill
ML-SHill

# solved exactly
9
41
43
31
38
42

worst
.015
.06
.21
.34
.46
.72

Table 6: Solution quality for the random networks. Shows the number solved exactly of
the 59 for which we could compute the true MAP value. Worst is the ratio of the
probabilities of the found instantiation to the true MAP instantiation. Each hill
climbing method improved significantly over the initializations.

MPE-Hill
MPE-SHill
ML-Hill
ML-SHill

min
1.0
1.0
1.0x104
7.7x103

median
8.4
8.4
3.6x107
3.6x107

mean
1.3x1011
1.3x1011
3.4x1015
3.4x1015

max
3.1x1012
3.1x1012
8.4x1016
8.4x1016

Table 7: The statistics on the improvement over just the initialization method for each
search method on the data set generated from the Barley network. Improvement is
measured as the ratio of the found probability to the probability of the initialization
instantiation.

In the third experiment, we performed the same type of experiment on the Pigs network.
None of the search methods were able to improve on ML initialization. We concluded that
the problem was too easy. Pigs has over 400 variables, and it seemed that the evidence didnt
force enough dependence among the variables. We ran another experiment with Pigs, this
time using 200 MAP variables and 20 evidence values to make it more difficult. Table 8
summarizes the results. Again, the stochastic methods were able to improve significantly
over the initialization methods.

MPE-Hill
MPE-SHill
ML-Hill
ML-SHill

min
1.0
1.0
13.0
13.0

median
1.7x105
2.5x105
2.0x103
1.2x104

mean
1.5x107
4.5x1011
3.3x105
8.2x105

max
3.3x108
1.1x1013
4.5x106
8.2x106

Table 8: The statistics on the improvement over just the initialization method alone for each
search method on the data set generated from the Pigs network. Improvement is
measured as the ratio of the found probability to the initialization probability.

124

fiComplexity Results and Approximation Strategies for MAP Explanations

Barley
Mildew
Munin2
Munin3
Pigs
Water

I
2
5
5
8
0
9

MPE
H T
6
7
1 10
0
9
0
1
0
1
0
0

I
2
5
5
8
0
9

ML
H
7
0
0
0
0
0

T
7
10
9
1
1
0

I
7
9
10
10
8
10

Seq
H T
9
9
0 10
0 10
0
1
0
8
0
0

14
1
4
4
4
3
6

MB
16 18
3
5
4
7
5
7
6
2
1
6
6
9

Table 9: Number of times out of ten that each algorithm found the instantiation that yielded
the highest score. The I, H and T entries stand for initial, hill climbing, and taboo
respectively. MB stands for minibuckets, and 14, 16, and 18 are the width bounds.

We also ran these algorithms on the same queries on the real world networks that were
used in Section 3.4 to be able to compare performance between the methods. Table 9
shows how they performed and compares their performance to the minibucket algorithms.
Table 10 gives a more detailed exposition of their performance. There are a couple of
interesting items about this data set. One is the surprising performance of simple sequential
initialization. Over all, it performed the best of the approximate algorithms. Another
interesting thing to note is that hill climbing often negatively impacted performance. This
suggests that marginal computations are often more accurate than probability of evidence
computations. This problem is especially acute in networks with significant determinism.
While belief propagation believes a configuration has significant probability, it may actually
have 0 probability because one of its constraints is violated. These experiments suggest
that it is possible to improve on the standard approaches used when inference is intractable
(approximating MPE, or ML or using a minibucket scheme) by using belief propagation
to estimate the joint, and successively moving to states with higher approximate scores.

5. Conclusion
MAP is a computationally very hard problem which is not in general amenable to exact
solution even for very restricted classes (ex. polytrees). Even approximation is difficult.
Still, we can produce approximations that are much better than those currently used by
practitioners (MPE, ML) through using approximate optimization and inference methods.
We showed one method based on belief propagation and stochastic hill climbing that produced significant improvements over those methods, extending the realm for which MAP
can be approximated to networks that work well with belief propagation.

Acknowledgement
This work has been partially supported by MURI grant N00014-00-1-0617
125

fiPark & Darwiche

Barley network results
Best > .9 > .5 > .01
2
3
1
3
6
1
1
2
7
0
1
2
2
3
1
3
7
1
1
1
7
0
1
2
7
1
1
1
9
0
1
0
9
0
1
0
1
2
1
3
3
3
1
2
5
2
0
3
Munin2 network results
Method Best > .9 > .5 > .01
MPE
5
0
3
1
Hill
0
0
0
0
Taboo
9
0
0
0
ML
5
0
3
1
Hill
0
0
0
0
Taboo
9
0
0
0
Seq
10
0
0
0
Hill
0
0
0
0
Taboo
10
0
0
0
MB 14
4
0
1
2
MB 16
5
0
1
2
MB 18
7
0
0
1
Pigs network results
Method Best > .9 > .5 > .01
MPE
0
0
0
0
Hill
0
0
0
0
Taboo
1
0
0
4
ML
0
0
0
0
Hill
0
0
0
0
Taboo
1
0
0
4
Seq
8
0
2
0
Hill
0
0
0
0
Taboo
8
0
2
0
MB 14
3
0
3
4
MB 16
1
1
4
3
MB 18
6
0
2
2
Method
MPE
Hill
Taboo
ML
Hill
Taboo
SEQ
Hill
Taboo
MB 14
MB 16
MB 18

 .01
1
0
0
1
0
0
0
0
0
3
1
0
 .01
1
10
1
1
10
1
0
10
0
3
2
2
 .01
10
10
5
10
10
5
0
10
0
0
1
0

Mildew network results
Best > .9 > .5 > .01
5
2
3
0
1
0
0
0
10
0
0
0
5
2
3
0
0
0
0
0
10
0
0
0
9
1
0
0
0
0
0
0
10
0
0
0
4
1
0
1
4
0
0
1
7
0
1
0
Munin3 network results
Method Best > .9 > .5 > .01
MPE
8
0
0
1
Hill
0
0
0
0
Taboo
1
0
0
0
ML
8
0
0
1
Hill
0
0
0
0
Taboo
1
0
0
0
Seq
10
0
0
0
Hill
0
0
0
0
Taboo
1
0
0
0
MB 14
4
0
2
0
MB 16
6
0
1
0
MB 18
2
0
1
0
Water network results
Method Best > .9 > .5 > .01
MPE
9
0
1
0
Hill
0
0
0
0
Taboo
0
0
0
0
ML
9
0
1
0
Hill
0
0
0
0
Taboo
0
0
0
0
Seq
10
0
0
0
Hill
0
0
0
0
Taboo
0
0
0
0
MB 14
6
1
2
0
MB 16
6
1
2
1
MB 18
9
0
0
1
Method
MPE
Hill
Taboo
ML
Hill
Taboo
Seq
Hill
Taboo
MB 14
MB 16
MB 18

 .01
0
9
0
0
10
0
0
10
0
4
5
2
 .01
1
10
9
1
10
9
0
10
9
4
3
7
 .01
0
10
10
0
10
10
0
10
10
1
0
0

Table 10: Detailed performance measures on the real world networks using Belief propagation approximation methods. Each column contains the number of times out of
10 that each algorithm was able to achieve the given performance relative to the
best solution found.

126

fiComplexity Results and Approximation Strategies for MAP Explanations

W1
W11

X1





W1r

Wr
W21



X2





W2r

X3

Figure 8: The network produced using the construction in the proof of Theorem 2 for the
formula (x1  x2 )  x3 .

Appendix A. Proofs of Theorems
Proof of Theorem 2
We want to show that MAP remains NPPP -complete even when restricted to networks of
depth 2, with no evidence, only binary variables, and parameters that are arbitrarily close
to 1/2. Membership in NPPP was established in Theorem 1. We show hardness by providing
a reduction from E-MAJSAT.
The flow of the proof is as follows. First, we construct a depth 2 Bayesian network
from the E-MAJSAT problem. Then, we show that by asserting some evidence, we can
overcome the constraint that all of the parameters lie within [1/2  , 1/2 + ], and use
MAP to obtain the E-MAJSAT solution. Finally, we show that by including the evidence
variables as MAP variables instead, no evidence is needed.
The network is constructed as follows. Each logical variable x i induces a network variable
Xi with uniform prior. Each operand yi induces a network variable Yi with a uniform prior.
Notice that they are not connected, so unlike the reduction in Theorem 1, the CPT entries
do not enforce that an operator variable take on a value that is consistent its operands with
respect to the to the logic of the formula. For example, the network will assign positive
probability to an and node being true, and both of its operand variables being false. We
say that a variable Yi is consistent with the variables Pi associated with its operands, if the
logical function of operator yi yields the value of Yi on input pi . Consistency, instead of
being enforced rigidly, is weighted by introducing r weight variables W i1 ...Wir (the actual
value of r will be discussed subsequently) associated with each Y i . The parents of Wij are
the operator variable Yi and the variables corresponding to its operands. The CPT of W ij
is defined as
Pr(Wij = T |Yi , Pi ) =

(

1
2
1
2

+  Yi is consistent with Pi
otherwise

where Pi are the variables associated with the operands of y i . Finally, as children of Ym
(which corresponds to the top level operator) we add r additional binary variables W 1 ...Wr ,
127

fiPark & Darwiche

where
Pr(Wj = T |Ym ) =

(

1
2
1
2

+  if Ym = T
otherwise

for the purpose of weighting states in which the formula is satisfied. See Figure 8 for an
example network construction.
Now, consider the probability of a complete instantiation of the variables, where all
of the weight variables (which includes both the consistency weighting variables W ij , and
satisfiability weighting variables W i ) are set to true, which we denote as W = T.
Pr(x, y, W = T) =

 m+n 

1
2

1
+
2

kr  (mk)r 

1
2

1
+
2

sr  (1s)r

1
2

where x is an instantiation of X1 ...Xn , y is an instantiation of Y1 ...Ym , k is the number
of operator variables that are consistent with their operands variables and s=1 if Y m = T ,
0 otherwise. For a consistent satisfying assignment xy,
Pr(x, y, W = T) =

 m+n 

1
2

1
+
2

(m+1)r

while for an inconsistent, or unsatisfying assignment xy,
Pr(x, y, W = T) 

 m+n+r

1
2

1
( + )mr .
2

We want to choose r such that the probability of a single consistent satisfying instance is
greater than twice the sum of all of the probabilities of inconsistent or unsatisfying instances.
The number of inconsistent or unsatisfying instances is bounded by 2 n+m , so we want an r
where
 m+n+r
(m+1)r
 m+n 
1
1
1
n+m+1 1
( + )mr .
>2
+
2
2
2
2
Solving for r yields
r>

(m + n + 1)
1 + log 2



1
2

+



which is linear in the size of the formula, so the size of the reduction remains polynomially
bounded.
(m+1)r
 m+n 
1
Let C = Pr(x, y, W = T) = 21
+

where xy is a consistent satisfying
2
instance. Then, for a particular instantiation q of X 1 ...Xk ,
Pr(q, W = T) =

X

Pr(q, xk+1 , ...xn , y1 , ...ym , W = T)

xk+1 ,...,xn ,y1 ,...,ym

= #q C +

X

Pr(xy, W = T)

xy

where #q is the number of complete variable instantiations compatible with q that satisfies  and xy ranges over the inconsistent and unsatisfying assignments compatible with
x1 ...xk . Since for any instantiation of x there is only one compatible instantiation, # q
128

fiComplexity Results and Approximation Strategies for MAP Explanations

1

S0

2

S0

q

S0

1

X1

1

X2

S11

S2

X1

2

X2

S21

S2

1

1

Xn
...

1

Sn

2

2

2

Xn
...

2

Sn

q

X1

q

X2

Sq1

S2

q

B1

q

B2
.
.
.

Xn
...

q

Sn

Bq

Figure 9: The network used in the reduction of Theorem 8.

also corresponds to the number of satisfiable instantiations of  consistent with q. The
choice of r ensures that the sum of the unsatisfying or inconsistent instantiations is less
than C/2, and is always greater than 0 assuming there is at least one operator (since
there is some instantiation where the operator and its operands are not consistent). Thus
#q C < Pr(q, W = T) < (#q + 1/2)C. There are 2nk possible instantiations of Xk+1 ...Xn ,
so if half or less are satisfied then Pr(q, W = T ) < (2 nk1 + 1/2)C, while if more than half
are satisfied then Pr(q, W = T ) > (2nk1 + 1)C. Thus the D-MAP query, using MAP
variables X1 ...Xk , evidence W = T, and threshold (2nk1 + 1)C is true if and only if the
E-MAJSAT query is also true.
Now, notice that in every table that contains a weight variable, the value of the configuration where it takes on true is greater or equal to the value when it takes on false. Thus
Pr(q, W = T)  Pr(q, W = w), for all q and w. It then follows that MAP(X 1 ...Xk , W =
T)=MAP(X1 ...Xk W, ). Therefore, the D-MAP query, using MAP variables X 1 ...Xk ,W
and no evidence, with threshold (2nk1 + 1)C is true if and only if the E-MAJSAT query
is also true. 2
Proof of Theorem 8
As part of the proof of the theorem, we will use the following lemma.
Lemma 9 For all x  1, 4x +

1
2

>

1
1 .
ln(1+ 4x
)

1
1
Proof: First, we show that f (x) = ln(1 + 4x
)  4x+
1 is monotonically decreasing for x  1.
2

df
dx

=

1
4
+
4x2 + x (4x + 21 )2
129

fiPark & Darwiche

=
=

16x2 + 4x  (4x + 21 )2
(4x + 21 )2 (4x2 + x)
1
1 2
4(4x + 2 ) (4x2 + x)

which is always negative for x  1, and hence f (x) is monotonically decreasing.
Now, since f (x) is monotonically decreasing, and lim f (x) = 0, f (x) must be strictly
positive. Thus, for all x  1, ln(1 +

1
4x )

1
4x+ 12

>

x

which implies 4x +

1
2

>

1
1 .
ln(1+ 4x
)

2

The basic idea of the proof is to show by repeating the construction of Theorem 7 a
polynomial number of times, that if we can approximate MAP on polytrees within relative
error 2size for any   [0, 1), where the size of the network is parameterized by the number
of conditional probability parameters, then we can solve SAT in polynomial time.
Given a SAT problem instance with n variables, and m clauses, we create a Bayesian
network by replicating the construction from Theorem 7 q times, and connecting them to
form a polytree. Specifically, to each copy i of the construction, we add a variable B i (we
use superscripts to denote variables associated with a particular copy of the construction),
with parents Sni , and if i > 1, parent B i1 (see Figure 9). The conditional probability of

1 q
) > 2size . We
B i is uniform for all parent instantiations. We choose q to satisfy (1 + 4m
now show that q can be chosen so that the network size remains polynomial in the size of
the logical formula. The resulting network has q(2n + 2) variables, and each conditional
probability table has at most 2(m + 1) 2 parameters, so the total size of the reduction is
bounded by q(m + 1)2 (4n + 4). Replacing size with the size bound places the constraint


1+

1
4m

q

> 2(q(m+1)

2 (4n+4) 

)

on q. Since 0   < 1, solving for q yields

2
1 q
> 2(q(m+1) (4n+4))
4m


1
q ln 1 +
> q  (m + 1)2 (4n + 4) ln 2
4m
(m + 1)2 (4n + 4) ln 2


q 1 >
1
ln 1 + 4m





1+

q >





(m + 1)2 (4n + 4) ln 2 



ln 1 +

1
4m



1
1

Now, from Lemma 9, 4m + 1/2 > 1/ ln(1 + 1/4m), so substitution yields a stronger bound,
q >



1
4m +
(m + 1)2 (4n + 4) ln 2
4




1
1

which is polynomially bounded. Thus the network can be constructed in time polynomial
in the size of the formula.
130

fiComplexity Results and Approximation Strategies for MAP Explanations

Sni

Then, for a particular instantiation x of all X variables X 11 ...Xnq , and evidence s asserting
= 0 for each i, the probability is
Pr(x, s) =

Y

Pr(xi , Sni = 0)

i

=

Y # clauses satisfied by xi

m2n

i

because each subnetwork is independent.
Thus the solution M to MAP over X 11 ...Xnq with

q
k
where k is the maximum number of clauses that can
evidence Sn1 = .... = Snq = 0 is m2
n
be simultaneously satisfied in the original SAT problem. If the problem is satisfiable then
k = m, and so the approximate solution M 0 obeys
M
M 
 >
size
2
0



4m
4m + 1

q 

m
m2n

q

>

m
m

1
4

!q 

1
2n

q

=

m  41
m2n

!q

On the other hand, if it isnt satisfiable, then k  m  1, so

M  2size M <

0



4m + 1
4m

q 

m1
m2n

q

=



(4m + 1)(m  1)
4m

q 

1
m2n

q

<

m  43
m2n

!q

The upper bound of M 0 if the SAT problem is unsatisfiable is bounded below the lower
bound of M 0 if it is satisfiable. Because the network construction and the bound tests can
be accomplished in polynomial time, if the MAP problem itself can be approximated within
a factor of 2size in polynomial time then SAT can be decided in polynomial time.

Appendix B. Generating Random Networks
We generated several types of networks to perform our experiments. We used two methods
for generating the structure, and a single parametric method for generating the quantification.
B.1 Generating the Network Structure
The first method is parameterized by the number of variables N and the connectivity c.
This method tends to produce structures with widths that are close to c. Darwiche (2001)
provides an algorithmic description.
The second method is parameterized by the number of variables N , and the probability
p of an edge being present. We generate an ordered list of N variables, and add an edge
between variables X and Y with probability p. The edges added are directed toward the
variable that appears later in the order.
B.2 Quantifying the Dependencies
The quantification method is parameterized by a bias parameter b. The values of the CPTs
for the roots were chosen uniformly. The values for the rest of the nodes were based on a
bias, where one of the values v was chosen uniformly in [0, b), and the other as 1  v. For
131

fiPark & Darwiche

example, for b = .1, each non root variable given its parents has one value in [0, .1), and
the other in (.9, 1]. Special cases b = 0, and b = .5 produce deterministic, and uniformly
random quantifications respectively.

References
Dagum, P., & Luby, M. (1997). An optimal approximation algorithm for Bayesian inference.
Artificial Intelligence, 93, 127.
Darwiche, A. (2001). Recursive conditioning. Artificial Intelligence, 126 (1-2), 541.
Darwiche, A. (2003). A differential approach to inference in Bayesian networks. Journal of
the ACM, 50 (3), 280305.
de Campos, L., Gamez, J., & Moral, S. (1999). Partial abductive inference in Bayesian
belief networks using a genetic algorithm. Pattern Recognition Letters, 20(11-13),
12111217.
Dechter, R., & Rish, I. (1998). Mini-buckets: A general scheme for approximate inference.
Tech. rep. R62a, Information and Computer Science Department, UC Irvine.
Dechter, R. (1996). Bucket elimination: A unifying framework for probabilistic inference.
In Proceedings of the 12th Conference on Uncertainty in Artificial Intelligence (UAI),
pp. 211219.
Huang, C., & Darwiche, A. (1996). Inference in belief networks: A procedural guide. International Journal of Approximate Reasoning, 15 (3), 225263.
Jensen, F. V., Lauritzen, S., & Olesen, K. (1990). Bayesian updating in recursive graphical
models by local computation. Computational Statistics Quarterly, 4, 269282.
Kask, K., & Dechter, R. (1999). Stochastic local search for Bayesian networks. In Seventh International Workshop on Artificial Intelligence, Fort Lauderdale, FL. Morgan
Kaufmaann.
Kjaerulff, U. (1990). Triangulation of graphsalgorithms giving small total state space.
Tech. rep. R-90-09, Department of Mathematics and Computer Science, University of
Aalborg, Denmark.
Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations with probabilities on
graphical structures and their application to expert systems. Journal of Royal Statistics Society, Series B, 50 (2), 157224.
Litmman, M., Majercik, S. M., & Pitassi, T. (2001). Stochastic boolean satisfiability. Journal of Automated Reasoning, 27 (3), 251296.
Littman, M. (1999). Initial experiments in stochastic satisfiability. In Sixteenth National
Conference on Artificial Intelligence, pp. 667672.
Littman, M., Goldsmith, J., & Mundhenk, M. (1998). The computational complexity of
probabilistic planning.. Journal of Artificial Intelligence Research, 9, 136.
McEliece, R. J., Rodemich, E., & Cheng, J. F. (1995). The turbo decision algorithm. In
33rd Allerton Conference on Communications, Control and Computing, pp. 366379.
132

fiComplexity Results and Approximation Strategies for MAP Explanations

Mengshoel, O. J., Roth, D., & Wilkins, D. C. (2000). Stochastic greedy search: Efficiently
computing a most probable explanation in Bayesian networks. Tech. rep. UIUCDSR-2000-2150, U of Illinois Urbana-Champaign.
Murphy, K. P., Weiss, Y., & Jordan, M. I. (1999). Loopy belief propagation for approximate
inference: an emperical study. In Proceedings of Uncertainty in AI.
Papadimitriou, C., & Tsitsiklis, J. (1987). The complexity of Markov decision processes.
Mathematics of Operations Research, 12(3), 441450.
Park, J., & Darwiche, A. (2003). A differential semantics for jointree algorithms. In Neural
Information Processing Systems (NIPS) 15.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Roth, D. (1996). On the hardness of approximate reasoning. Artificial Intelligence, 82 (1-2),
273302.
Shenoy, P. P., & Shafer, G. (1986). Propagating belief functions with local computations.
IEEE Expert, 1 (3), 4352.
Shimony, S. E. (1994). Finding MAPs for belief networks is NPhard. Artificial Intelligence,
68 (2), 399410.
Toda, S. (1991). PP is as hard as the polynomial-time hierarchy. SIAM Journal of Computing, 20, 865877.
Yedidia, J., Freeman, W., & Weiss, Y. (2000). Generalized belief propagation. In NIPS,
Vol. 13.

133

fi
	ff
fi 
			 ! #"$ % 
'&)(!*,+-(..
/02135476819!*

FHGJILKNM

:;<=>  ?).@5A
.1!BDC<	%&?E.(5A
.
/

OQPSRTK;KUVJWXOZY\[]R_^a`bGdcI)ceU5OfVgILVJPih$V)j2R_klceU5OfVm[n^eOfoSKRT`qp

rJstvu#w'xzy|{#w}ffu
a7a
7DTaD_'DDa5
 
SaD'a7Ta7575

~v$EZ2v

rJt$s#t$st)ex]wu

!aTJDf,
5ff
 
8# e

~vZ;T-f2$$

) t2u

Z2v

a7a
7DTaD_'DDa5
 
SaD'a7Ta7575 

)e
>7 7
DT#fEd
ff7L>-
D-D; -Jf7
 !5- dD!Q\77;;75#7! ED-D;;vDffQ !

E_7-
DE
-5)8,L!5- D!# -;;ff8>5DZ

;ld>
#E,ff;>lD-D;;D;
dD!ld
Dv7
f7;Dl_
 l5l)DEff;>;7_D
ff>!2!
DeD-D7;7! ;)77DD;;2>-!
De
;7
_LDef7D27-D;;TTffd;D
d5
##D-D;;vld;DZ!ffl> 7| L
D-D;;T7-)D!#f; 87D5ff7; Z7;5;DDS;-D 7S 

D)D5f;;8#N77;D  ;7fD7\;

 ; ;
 Z;7
L7 7DZD
D)77Qf
ff>
Dd75
,>
S
;$#;7 7DDS5 - 75
,;d7f 7
f;57ff8_5D ;7;T5,;;

	ff
fi T 
 "!$#%&('$)$"!$*+*,#%-).#%/!10#2)04325674898;: <=73- :8"04-32$)$5<>$ 32?@#%-).!1AB#%C-:D?E!E"#2:9F5$<ff8;*HG
I %# 4!E $"#%!$3J' I 3%:*,K3%#2L$:H: 7-M8;:+!$3%32@89!E#2ffNff "!$4 'O$!E#2ffNP!$4CQ8"0-:C473%#%-)-RHST8;  "!$#%&
'$)$M!$*U8;#%K$<V!W:9.$<C:89#%#2X?E!E"#%! I 3%:9Nff:!$8"0YAB#20Q!$Z!$[89#%!E :CYC-*,!$#%X$<?!$3\7-:9N
!$C]!1 :9$<^8;  "!$#%&C-:9_4#%).!$3%32`A:C,?E!$3%7-:/<a$V7 I  :9($<O0-: :b?E!E"#%! I 32:RJcd0:d:9e+89#2:8;5
$</!f8;  "!$#\gK'$)$M!$*hC-:9'O:C4dX*,!$&5i<>!$8; $Mj#%893%7C4#%-),!])$&@CX8"0-#%8;:k<>$b0:kC-:89#\#2
?E!E"#%! I 32:NO!$4CQ89!E:9<>743*[C:3%3%#%-)]$<0:H8;4  "!$#%&jX0-: :?E!E"#%! I 32:9R6cB0-:9:#%b$<a :Y8;@G
#%C:9"! I 32:+8M0-#%8;:l!$k mAB04!E60-:lC-:89#%"#2Z?E!E"#%! I 3%:1!$Cn0-:#2k?!$3\7-:6"0-73%CY:9': :&9Rmo$
:;p-!$*'432:$N[#%+!$+:;p@!$*q#%*:9! I 3\#%-)j' I 32:*WN0-:r?!EM#%! I 32:8;73%C:9'4: :&/0-:r:;p@!$*,N[!$C+0-:
?E!$3%7-:K:9'": :gK0-:#\*:9R6Sb32 :9"4!E#2?$:325$N^A:89!$Z7 :!ZsEtuEvO*@C-:3w#%XAB0#%8M0x0-:H?!E"#\! I 32:
!E:d0:d#%*:9N[!$C0-:B?!$3%7:(!E:B0:d:;p@!$*+9RwyQ:r!$32AV!5@04!?$:r!18"0-#%8;:r$<O0#%wL@#%C#%'O:9"*k7@G
!E#2l'" I 32:*,9Rwz{l!6'O:9"*k7-!E#2f'" I 32:*WN[A:j0!`?$:.!$D*,!$&5+?E!$3%7-:V!$V?!EM#%! I 32:9N-!$Cf:!$8M0
?E!E"#%! I 32:j!EL$:K!$m7#%|[7-:K?!$3\7-:$RyQ:k89!$}0:9:9<a$":.:!$#%325l:;p-8"0!$)$:10-:632:d$<w0-:1?!E"#\! I 32:
!$Cx0-:H?E!$3%7-:b#%}":9': :&#%-)f0-:7C-:9M325[#\-)' I 3%:*WR.~}!$&5m!$"#2)*:&9Nff8"0-:C473%#%-)f!$C
  (..
/, %%!?v		&5%2%a5?

fi 8-
	fiffff
7-#\-)i' I 32:*,.!E:f'O:9"*k7-!E#2Z'4 I 32:*,Rfo-$H:;p-!$*'432:$N 'O$1 7-"!$*,:gk8"0-:C473%#%-)
89!$ I :6*[C:3%32:Ci!$r_4C#\-)!,'O:9"*k7-!E#2i$<0:1)!$*:r ]_4B#%& +0-:6#%*:13%$9N4$K!,'O:9 G
*k7-!E#2i$<0:.#%*:1"32$d ,_4d0-:1)!$*,:r#%& -RVcd0-:.!$#%* $<J04#%D'4!E'O:9B#%B ]8;*'!E:178M0
C# O:9:&d*@C-:3% I $0W0-:9$:9#\89!$3%325l!$Cl:*'4#2M#%89!$3%325$R








cd0:,'4!E'O:91#%6  "78;7-":CZ!$1<>3%32 AB9R]z  [:8;#2 [NJA:+)#2?$:]0-:+<>$"*,!$3%#\* !$CY$!E#2
7 :CX#%m0-:H: K$<0-:H'4!E'O:9RKz  [:8;#2 [NffA:H': :& P!$-)$<>$"C b'" I 32:*WNOAB0#\8"0x#%K7 :C
 +#%3\3%7  "!E :K0-:.C4# :9":gDAV!5@dA:189!$i*@C-:3^!H'O:9"*k7-!E#2i' I 32:*iRJyQ:10-:i#%& @C78;:.!
<>$"*,!$3g*,:!$7-:($<-8; "!$#%&P#2)0&-: [:8;#2 ff7 :C. r8;*'4!E":/0-:9$:9#\89!$3%325K0-:/C# :9:&
*@C-:3%$<K'O:9"*k7-!E#2 '4 I 32:*, [:8;#2
MR z{ [:8;#2 [NVA:}8;*,'4!E: -Sc
&3%:!$
*@C-:3% $<4'O:9"*k7-!E#2k' I 32:*,9R^z{ [:8;#2 r!$C [NA:D8;*'432:*:&w0-:0-:9$:9#%89!$3@:"732
AB#20k *:d!$5[*'4 $#%8V!$Ck:;p['O:9"#%*,:g!$3[!$!$325@#%9R yQ:D0-:H:;p@'432$:0-: I :-:9_J  I "!$8M0#%-)
0-:7-M#% #%89B$</0!?@#%-)l*k732#2'43%:.?[#%:9Ad'O#%gB$<(0-:H'O:9"*k7-!E#2 = :8;#2
MRKz  [:8;#%
@NOA:
:;p@ :Cx7-b!$4!$325["#%B l#% :8;#2?$:H*,!E''4#\-)9Rrow#%4!$3%325$N4A:k:C}Ar#20}":3%!E :CxA$L [:8;#2
!$Ci8;4893%7#24 [:8;#2
MR





!
+

9






#"$ %
-, /.



%&



65
1:$



' (*)

0$

A e$CEaD    
; 
+< >= @?B
w
SGFIHKJMLON*P{uKQRJfiNSL;u7N*QTLTU9u$F:N*QVHKJXWPYH>Z;v\[O]^SM_B#%r!l :9K$<(?E!E"#%!



2



2143
1718

I 32:9NO:!$8"0XAB#%0m!f_4#% :6C-*,!$#\m$<
?E!$3%7-:9N[!$C]!k :9$<^8;  "!$#\g9R(S 8;4  "!$#%&8;4#% $<^!63\#% ($<ff?E!E"#%! I 3%: >0-:
!$Cf!
:3%!E#%iC-:9_4#\-)0-:1!$3%3%`A:Ci?E!$3%7-:d<>$B0: :.?E!E"#%! I 32:RS I #%!E"5f8; "!$#%&B#%d!]8;  "!$#%&
AB0-:f8;$'O:W#%H!x'4!$#2k$<B?E!E"#%! I 3%:9RQS  3%7#2Y Q!X8;  M!$#%g!E#\ <>!$8;#%n'4 I 32:* #%H!$
!$#%)*:&D$<J?E!$3%7-:V ]?!EM#%! I 32:V0!Er!E#% _:D!$3\3ff0-:.8;  M!$#%gR
S
Ht u
;v
#%V!8; "!$#%&d!E#% <=!$8;#2W'" I 32:* #%fAB0#%8M0f:!$8"0}C:89#%#2f?E!E"# G
! I 32:f!EL$:,!$ 7#\|&7-:]?!$3\7-:$N(!$C 0-:9:l#%k0-:W!$*:l&74* I :9k$<B?E!$3%7-:H!$H?!EM#%! I 32:9R r:8;:
!$&5i 3%7-#2}!$#2)B!,'O:9"*k7-!E#2W$<0-:1?!$3%7:d +0:.?!EM#%! I 32:9RVSb}#%*'O$!$&D<>:!E7-:1$<
'O:9"*k7-!E#2W'" I 32:*,D#%d0!EdA:689!$i M!$ 'O :j0-:."32:D$<w0-:.?E!E"#%! I 3%:d!$CW0-:1?!$3%7:d#%
:9'": :g#\-)H0-:17C:9"325@#%-)1'4 I 32:*  ,)#%?$:.!,-:9AqsEtuEv-*@C-:3OAB04#%8"0W#%D!$3\ ,!'O:9"*k7-!E#2
' I 32:*WR /!$8M0l?!E"#\! I 32:K#%+0:b$M#2)#%!$3
,uEv d
I :8;*:D!k?E!$3%7-:K#%f0-:jC7!$3ff JN-!$C
?@#%8;:1?$:9""!@Rrcd0-:6'"#%*+!$3^!$Ci0:kC74!$3J B!E:6:|&74#2?!$3%:gb#%8;:1!$&5} 3\7-#2i f-:k89!$ I :
 "!$"3%!E :Ci#%& ,!, 3%7#2l ,0-:.$0:9R
yQ:H89!$m8M0-[ :1:#20:9r*@C-:3P!E I #2 "!E"#\325+  I :10-:1'M#%*,!$3ff*@C-:3 N4!$3%0-7-)0}#\W'"!$8;#%8;:k#2
*,#2)0& I :f:!$#2:9k X:;p['":10:]'" I 32:* 8;4  "!$#%&H#%Z-:f$<d0-:l*@C-:3%6"!E0-:9k0!$ 0-:
$0-:9Nw iA:+*,#%)0g. :4CZ }04#%-L}$<V0!Ek*@C-:3!$10:,'"#%*+!$3 RyQ:]!$3%}8;#%C:9 Ht[v v
Ht u
;v
#%]AB0#\8"0,0:b?E!E"#%! I 32:/C#%?[#%C:B#%& k!H[7* I :9$< >'O# I 3256 ?$:9"3%!E''#%-)
 :99N$:!$8M0$<AB04#%8"0k#%J!r'O:9"*k7-!E#26' I 32:*WR cB0#%P3%:9J74JC4#%897P' I 3%:*, 3\#2L$:|[7!$#2)$"7-'49R
SbH$"C-:9 l|&7!$"#2)$7-' >$ !E#%H|&74!E: J89!$ I :V*,[C-:3%:Ck!$/!b*k732#%'432:/'O:9"*k7-!E#2H'4 I 32:*
8;&!$#%#%-) Q ?$:9"3%!E''#%-)'O:9"*k7-!E#2l' I 32:*,9R
Sb
;v
#%(!.8;4  "!$#%&/!E#%<>!$8;#2+' I 3%:* #%HAB0#%8M0:!$8"0fC-:89#%"#2H?!EM#%! I 32:
!EL$:.!$Q74#%|&7:1?E!$3%7-:$N I 7-b0-:9:!E:- A *$:H?!$3\7-:b0!$X?!EM#%! I 32:9R
I ?@#27325$Nff#2</0-:9:
!E:.<>:9A:9d?!$3\7-:D0!$W?E!E"#%! I 32:9N@0-:.'" I 32:* #%V "#%?[#%!$3\325+7"!E#% _4! I 3%:$R
~m!$g5m32:9?$:3%r$</32@89!$3 8;"#%  :8;5i0!`?$: I :9:mC-:9_4-:Cm<>$b8; "!$#%&r!E#%<>!$8;#2x'" I 32:*,
#%&?$32?@#%-) I #%4!E5k8;4  "!$#%& ><>$:9<a:9":8;::9: b: I "75[-:r!$C :# :9":$N
MRS ' I 3%:* #%
^# }#%0!$V-@G:*,' 5+C*,!$#%!$Cf!$g5+8;4#%  :&#\ !$&#%!E#2]$< w?!E"#\! I 32:
89!$ I :+8;4#%  :&325X:;p[ :4C-:CZ  }!$CC4#2#2!$3w?E!E"#%! I 3%:9R]ST' I 32:*U#%+u
=SB
# #2+#%
G 8;4#%  :&9R S ' I 32:* #% @u
 H# #2]#%
G 8;#\  :g9R S

 LOFIHIWM[`

aWM[OPb] MN 7N*Q*H7JcWPdHZ \[O]

'e

gf

EhWPbQT] i Sj_
Sj_

Sj_

WM[4PI] MN 7N*QVHKJlWPdHZ \[O]mL

+] N*QkW [


n

go
p q
s6o
pQRJ:t:[uF:N*QVHKJWPYH>Z \[O]

r

w

Rzu{}|~IdFIHKJMLIQTLbN}[4JfiN 



pd1K{:18

B

Bx

|

s)

mW 7NRdFIHKJMLIQTLbN}[4JfiN*_ S 
r:

+v

Vy @1:070$,7

z
7PdF:dFIHKJMLIQTLbN}[4JfiN S
XV~{:18

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



#%mLbN*PYHK
J s-W u7NR>YF`HKJMLbQhLON}[OJfiN= SB _VSb# #2j#%.SB !$C _VbR^ST' I 3%:* #\W@u7NRQRJK[4P`L:[
`F H7JMLIQTLbN}[4JfiN9*_(zS6# #%k#% d1K{`$ G 8;"#%  :&9R S ' I 32:* #%cPY[OLbN*PbQ*F8N}[s W@u7NR>YF`HKJ LIQTLbN}[OJN _VS
# #%6#%HSBq!$C #2<d!x?!$3\7-:f!$"#2)-:C  Q!}?E!E"#%! I 32:f#\68;"#%  :&kAr#20 57 6-:l?!$3\7-:]<>$!$
!$C65 #%#%)i?!EM#%! I 32:,0:n<>$H!$g5Z$0:9k?E!E"#%! I 32:+0-:9":f#%k!x8;*'4!E# I 3%:+?E!$3%7-:$RmS ' I 32:* #%
LIQRJ v [:NHKY
J uKPYF4YF`HKJMLbQhLON}[OJfiN @ SBSd #Z
 #2B0!$r-@G:*'4 5iC-*,!$#\d!$C}<a$b!$g5i#%4 !$g#\!E#2W$<(!

' I 32:*

?E!E"#%! I 32:$N@0-:1:732#\-)k"7 I ' I 32:*

89!$ I :.*,!$C-:.SBbR



o-$f-@G I #\!E5n8;4  "!$#%&9N0-:9:i0!$ I :9: 3%:A$Ln C# O:9:g,3%:9?$:3%$<j32@89!$3D8;@G
#% :8;5$R K-:H:;p-8;:9'#2Z#%K)$::9"!$3%# 9:CZ!EM8 G 8;#%  :48;5$R+S 
AB#20 I #%!E5i$6-@G I #%4!E5
8;  M!$#%gw#%
uEv sku
KSB
# ,<>$w!$g5.?E!$3%7-:<a$w!r?!E"#\! I 32:/#%k!b8;  "!$#%&9N
0-:9:k:;p-#% r8;*,'4!E# I 32:6?!$3\7-:B<>$j!$3%3^0:6$0-:9K?E!E"#%! I 3%:B#%m0-:68;4  "!$#%&9Rbo$j$"C-:9:CxC-EG
*,!$#%4 =748"0l!$D#%& :9)$:9" MN-!k' I 32:*q#% Et s
d # }#2V0!$V-@G:*'4 5+C-*+!$#%
!$Ci!$m!$#2)4*:gD$<#2r*,#%#\*67*T$B*+!p@#%*k7* ?E!$3%7-:j f!$g5l?E!E"#%! I 3%:K#\i! I #%4!E5+$b-@G
I #%4!E5 /8;  M!$#%gD89!$ I :j8;#\  :g3%5+:;p@ :C-:Cl 0-:j$0-:9D?E!E"#%! I 32:D#%f0-:j8;  "!$#\g9R(z{
3%#%:1AB#20m0-:C-:9_44#2#2r#%g "[C748;:C I 5 b: I "75[-:H!$C :# :9:
MN A:!`5}0!E.!l32@89!$3
8;#\  :8;5W'$'O:9F5
#\B!$b  -)f!$r!]32[89!$3 8;#% :8;5W'$'O:9F5
>AB"#2  :
D#
#%x!$g5}' I 32:*h#%iAr0#%8"0
0-3\Cd0-:
03%C9N
#%b  -)$:9K0!$
>AdM#2  :
d#
1N
#%1#\8;*'4!E"! I 32:AB#20
>Ad"#2  :
K# -:#%0-:9
I 71-$
-$
1N !$C
#%K:|[7#2?E!$32:&K 
>AdM#2  :
b# I $0
h!$4C
6R6z 
0!$ I :9:l0- ABf0!E /SB V
-SB
/z 

SB
d
r: I "7-5@-:
:"# :9:$N
MR

lv



j_

[4J [OP Qr[ KPdF:dFIHKJMLbQhLON}[OJfiN S 

B

I

9ZuH jJ KLFIHKJMLIQTLbN}[4JfiN-*) S 

M

!x



')

X

Vy Xd1:070$,7

 
#
$
%
$^
*+ !  ,
- 
-/.0+ 
5
6 
$879+  5: !4
=< _ 0!  0! _ /!'_ /! >! ) *x

( !)
23 !4

  !"+ 
fi&!'+ 
*( !1
53 !;
@? ) *y

1:070$,7
)V!$8L[ "!$8"L[#%)l!$3%)$$"#20*,B!E:1$<> :X7 :CW f_4Ci3%7-#2d lSj_9R @78M0}!$32)$$"#%0*,D 5

 ,:;p@ :Ci'!E#%!$3ff!$#%)*:&9N-:-<>$"89#%-),!,3%[89!$3ff8;"#%  :8;5W!E<> :9d:!$8"0m:;p[ :4#2i!$C I !$8L&G
 "!$8"L[#%)mAB0:Y0#\132@89!$38;4#%  :8;5n-m32)$:9H03%C9R}o$k:;p-!$*'43%:$NJ0:
/u {s
!$32)$$"#%0* =o  V*+!$#%g!$#\D!H:  "#\8; :CW<a$M* $<JSB 0!Ed:7:V0!ED0-: I #%!E5+8;4  "!$#%&
I :9 A:9:Q0-:,*b":8;:g325X#%!$g#%!E :CX?E!E"#%! I 32:k!$4CQ!$g5X7#%4 !$g#\!E :Cm?E!E"#%! I 32:K!E:SBbR
o T0!$ I :9: )$:-:9"!$3\# 9:C  Z-@G I #%4!E5Z8;  "!$#\g :# :9":$N~}: :9)7-:9NVo-:7C:9N
!E G
!@N
MR/oJ 1*,!EL$::9?$:95 &G !E"5H8;4  "!$#%&/AB#%0
D?E!E"#%! I 3%:/#%!$g#%!E :C]SBbR&4o 
!E''43\#2: >:k'!$K$< rSB  f:!$8M0Z8;  M!$#%gK$.8; "!$#%&b'4 {:8;#%x#\g?$32?@#%-)]0-:897-:&
!$Cn:;p@!$8;3%5Z-:f<>7-7:+?E!E"#%! I 3%:$R}o  m!E''43\#2: >-:f'4!$k$< KSB  m:!$8M0 8;  "!$#\gH#%@G
?$32?@#%-)Q0-:m897-:&,!$C !Ef32:!$ ,-:W<=7-7-":W?!E"#\! I 32:$R cd0-":9:i$0-:9+)$::9"!$3%# !E#24$<jo 
 Y--G I #%!E5n8;  "!$#%&9NVo  x no  [NVC-:9)$:-:9"!E :m Zo  Q 0-:i#%)32:W-@G I #%4!E5
8;  M!$#%g.C:8;"# I #\-)]!l'O:9"*k7-!E#2ffN^i!E:,-$.8;#\C-:9:CQ0-:9:$RHow#%!$3%3%5$Nff0-: ,u
u
u
m!$3%)$$"#20*
~mSB ,*,!$#%&!$#%,SB C7-"#\-)x:!E"8"0ffNDAr0#%3% ,~ KSB *,!$#%&!$#%
KSBbR

U4HKPBA KP 2FOM[uFDC6QTJE

 S

@1:07070$
m

3



p*)

I

HG

IGKJ 1







KPYF4YF`HKJ LIQTLbN}[OJ F=M

Nw







l

"

F? 

Vy

65
IL
 





] KQTJN KQTJfiQTJ

$

S

1

OLP @ =0Q?R

no

o

cd0-: OG |&7:9:P'4 I 32:* #\P-:$<-0-:V#%*'32: ff:;p-!$*'432: $<4!d'O:9"*k7-!E#26' I 32:*WRPS 8;*+*
!$C !E7-"!$3*@C-:3/04!$6!xC-:89#%#%Y?E!E"#%! I 3%:,<a$k:!$8"0 "`A.NAB#%0Y#26?!$3\7-: I :#%-)}0-:f8;3\7*,
#% AB0#%8M0 0:x|[7-:9:  0!El`AU3%#%:9R cB0-:mC74!$3r*@C-:3b0!$l! C-:89#%#2 ?E!E"#%! I 32:m<a$l:!$8M0
8;3%7*+ffN&Ar#20l#2?!$3%7: I :#%-)k0-:K A lAB0#%8M0+0-:j|[7-:9:W#%]0!Ed8;3%7*+]3%#%:9R B A:9?$:9N0-:
OG |[7-:9:K' I 32:*h#\b$K8;* I #%4!E $"#%!$3%325m8"0!$3%3%:-)#%-)l!$j#2 I :8;*:K:!$#2:9.!$
)$ AB9R6o$
:;p-!$*'432:$N^~}$"#%
K0!$K!E)7:CX0!EK0-:9:!E:-l32[89!$3w*,!p-#%*,!f l0- AB#%-)l|[7-:9:K!E
"!$C* g m0-: I !E"CY!$CQ'O:9<>$"*,#%-)W*,#\@G 8; 4#%8;j04#%3%3 G 893%#\* I #\-)+AB#\3%3w!$3%* 1"7-:325m_4C
!W 3%7#2ffRHyQ:,<>[897K0:9:9<a$":,Z!WC# O:9:&K' :9M*67-!E#%X' I 32:* 04!E.#%j#%*'32:k3\#2L$:0-:

ge
o

/d1:0707$

TS



rVU

fi 8-
	fiffff
oOG |[7-:9:r'

B)

I 32:* I 7-b!E''O:!E"r  I :k*$:H8;* I #\!E $"#%!$3%3%5i8"0!$3%3%:-)#%-)-R 5m7#%-)f!]"#%*'432:
:;p-!$*'432:$N0:68"04!E"!$8; :9"#% #\89d$<'O:9"*k7-!E#2W'" I 32:*,D!E:k0-$'O:9<>743%325+*$":1!E''4!E:&d0!$m#%
*$:68;*'432:;pl' I 3%:*,AB0-:9:j0-:1$0-:9B8;  M!$#%gr0!?$:6!,3%!E)$:9B#\*'4!$8;9R
!$-)$<a$MC k' I 32:* #%
#% 
#I
K:g hyZ!$3%0ffN
MRZS 8;*':0-:4#2?$:
s  
0#% $5+$<w0-:j'" I 32:* #%D)#%?$: I 5W~m#%3%32:9
MRVcd0-:j'" I 32:* #%dC-:9_-:CW!$d<>3%32 AB

Sj_q 
?
S1:07070$
VK373$$
=<
L  NH NR>PY[I[cN*QT]s[OLc[u$F4j[4PY[lQTLsHKJ [

	fiff  sKQ7Q*NSL:[9tfi[4JFI[sQRJF9v ts>[bLsNRj[ls7Q $QRNR
s7Q $QRN ZI[4NAn[`[4JNRj[-PILbN NAqHKLBuKJs!HKJ ,
[ s7Q $QRN ZI[4NAn[`[4J NRj[,v uKLbN NAqHKLM[OPu[+uKPu[
t t~LbNSNAqHmsKQ7Q*NRL+ZI[4NAn[`[4JNRj[ -PILbNN AqH ff !L ruKJ s!NAqH}sKQ7Q*NRL+ZI[4NAn[I[OJNRM[v2u6LbNNAqH ff L!
"# uKJssLOHHKJ%$-QRJsluEv>vjWjH6LILIQ;Z v\[ML t F4cL:[ t [4JFI[OL &
cd0-:1' I 32:* 89!$}:!$#\325 I :1)$:-:9"!$3%#9:C} ]0:lRog({ '!V
 '" I 32:* Ar0-:9:.A:60!`?$:k!] :|[7-:8;:1$<
32:-)$0po)*'QN8;g!$#%4#%-)0-:.#%& :9)$:9"j
1  +' :9'O:!E :CW:;p-!$8;325Q
o #%*:9R(cB0-:.! I `?$:1'4 I 32:*
#%V0[7D0-:cV[
 Nk0$V ' I 32:*WRwzFr0!$D:;p-!$8;325p
&  3%7-#%=<








,.-,./0,.12435624-61727/34865179-4863797/757869
,./,:2,"-62;8636245/48<17-73948656149/737-796175
,./,.30,"-6271756243/217-486573961;86/797-757869
9785-97/78617937578-6124/327561727-,"3,./0,
9785/97378-96145783/62717-275321,"/,.-0,
56149-37/917578937-6148/527378627-,.2,./0,

=

  :60!Er0-:63\!$ d0-:9:k 3%7-#%d!E:60-:1:9?$:9M :1$<0-:1_" d0:9:$Rdcd0#%B 5[*+*:9 5W89!$ I :
$
:3%#%*+#%!E :C I 5]!$C4C#%-)k8;  "!$#%& @<>$V#\ !$8;:$N-#%]0-: [N ' I 3%:* 0-:K :8;C k89!$$ I :
'43%!$8;:C]#%0-:b :8;Cf0!$32< $<ff0-:r:|&7-:48;:$N[!$C]#2<ff#2/#%/#%,0-:r8;:g "!$3'O#2#2+#%0-:b :|&7:8;:$N
0-: :8;C f*k7  I :6'3%!$8;:CQ#%m0-:H_" j0!$32<$<0-: :|[7-:8;:$R -78"0Q8; "!$#%&j0!?$: I :9:
!$CC-:C}#%lAB0!ED<>3%32 AB9R
cd0:6_M b*,[C-:3 $< !$-)$<>$"C b' I 3%:* A:HAB#%3%3 8;#%C-:9`N Ar0#%8"0mA:H"0!$3%3J!E I #2 "!EM#%325W89!$3%3
0-:d'4"#%*,!$3@*@C-:3 Ng04!$(!j?E!E"#%! I 32:D<>$(:!$8M0+@89897-:48;:D$< 0:BC#2)#2RJcd0:D?!$3%7:D$< 04#%w?!EM#%! I 32:
#%+0-:m'O#%#2 #% 0-:x:|&7-:48;:}$<.0#\,@89897-:8;:$R o-$l:;p@!$*,'432:$ND0-: [N ,'4 I 32:* 0!$
X?E!E"#%! I 32:9N KAB#20
R cB0-:W?!$3\7-:W$< j#%0-:m32[89!E#% #% 0-:m :|&7:8;:i$<K0-:
jC#2?
;0 @89897-:8;:]$<d0-:lC#2)#2 b*,[C QRxcB0&7N * 0!$H!$H#26?!$3%7:+0-:l32@89!E#2Y$<
0-: 9 j@89897-":8;:$<0:,C#2)#2 EN ( 0!$1!$.#2K?E!$3%7-:H0-:,32@89!E#2X$<0-: 9 j@89897-:8;:$<
0-:fC#2)#2 [NDR9R`R9N 9 0!$k!$k#21?E!$3%7-:+0-:f3%[89!E#2Y$<d0-: 9 6@89897-":8;:+$<d0:]C#2)#% [N * .
0!$k!$6#%.?E!$3%7-:,0-:f32@89!E#2Y$<D0: ECY[89897-":8;:+$<D0:]C#2)#% EN!$CY mffRWyQ:l0!?$:W!
'O:9"*k7-!E#2H8;  "!$#\g0!E:47-:J0!E:!$8M0,C#2)#2J@89897-:8;:D@89897-"!E!jC# :9:&w'O#2#2
#%m0-:H :|&7:8;:$Rjcd0#%r89!$ I :H#%*'43%:*:g :C}:#20-:9K!$j!+)3% I !$3 !$3\3 G C# O:9:&r8;  M!$#%gbX!$3%3
0-:
N$+!$'!$#2AB#%:l${G:|&7!$3\,8;  "!$#\g :!$8"0 ' "# I 32:f'4!$#2$<b?E!E"#%! I 32:R yQ:x89!$3%3
0-:]<a$"*,:910-: {'"#%*,!$3!$3%3 G C# :9:& i*@C-:3(!$4CY0-:f3%!E :910: {'"#\*,!$3/-${G:|[7!$3% }*@C-:3 R
ow#%!$3%3%5$NPA:+0!?$:l8;  M!$#%g60!E60-:+C#2)#%j[89897-":8;:6[89897-k#%Q$"C:96C- ABZ0-:f :|[7-:8;:
!$Cn8;  "!$#%&6Z0-:f :9'4!E"!E#2n$<D0-:fC# O:9:g1[89897-":8;:.$<d!mC#2)#2 60!EH#%.A:]0!`?$:
!$C
/<>$
QR
( 6N
(
cJ! I 32: V)#2?$:(0-:D'"#%*+!$3g:9'4: :&!E#2$< 0-:d :|[7-:8;:
N$!j 3%7-#2H j0: [N
' I 32:*WRwo-$893\!E"#2 5$N&A:b!$3% 1#\C#%89!E :D0-:b8;$: 'OC4#%-)jC#2)#2@89897-":8;:B7#\-)j0-:r$!E#2
m<a$60-: [0n[89897:8;:]$<0:]C#2)#% Rio-$k:;p-!$*'432:$N ( #%10-: E4CZ@89897-:8;:]$<D0-:
C#2)#%
]!$C
@R
* #%V0: 9 d@89897-:48;:j$<J0:.C#2)#2

?>

+V k0$

.

m

n

$,

z

'I1

p1

A@B



zDCFE1K{`$,#G

J'

H@B

V k0$

K@

1

c

p1

s1

ON



91

G

X

s1

P

JN



D@BWS U J@BWS0U[Y%z SzA\R'
27948<2,.90,#8
_]
-
c
auN :P
#b#c

0 @





@BQR@BTS0UVQR@BWS U <@BWS0U JX@BZY z
`Nu:P

z

1 L@

M@



D@B

N(]4^.P

p0

P

=<

V 

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



'Rz 

z 4C-:;p
!$3%7-:j$<w'"#\*,!$3 ?!E"#\! I 32:
/|[7#2?E!$32:&VC4#2)#2V[89897:8;:

+ @B}

f

+1 <Bcd0:r'M#%*,!$3:9': :&!E#2l$<

cJ! I 32:

1

1
"



*


*

0-:j :|&7:8;:

32:*iR




1




"





*

,

1(
*

2497862,.9,"8





&


&

(

,

.


.

(

(

/V[N V'

N[!H 3%7-#2]$<P0:

I G



c 0:KC47!$3ff*@C-:3 $< !$-)$<a$MC V' I 3%:*T04!$d!H?!EM#%! I 32:b<a$B:!$8"0}3%[89!E#2W#\]0:. :|&7:8;:$R
d
cd0-:r?!$3\7-:r$<P0#%(?E!E"#%! I 32:B:9'4: :&0:bC#%)#2(@89897-:8;:K!EV0#%32[89!E#%ffR(o-$V:;p@!$*,'432:$N@0-:
[N .' I 32:* 04!$ f?E!E"#%! I 3%:9N +AB#20
RWcd0-:?E!$3%7-: r$< ,#\.!$Y#%& :9)$:96#\Q0-:
#%& :9?E!$3
N:9'::g#%)B0-:V<=!$8;J04!EJ0: ^C#%?
;06@89897-":8;:V$<0-:VC#2)#2 ^*[C
@89897-"D!ED32@89!E#2 -R/cB0&7N 1
k:9'::gV0-:K<=!$8;D0!EV0-: 9 V@89897-:8;:K$<J0-:jC#2)#2
@89897-"b!Er0-: "Cx32[89!E#%ffN !$4C
]:9': :&r0-:6<=!$8;b0!Er0: ECm[89897:8;:6$<(0-:
/
C#2)#% .[89897-Md!Ed0-: $0}32[89!E#%ffN!$Ci +ffR
z{0-:dC74!$3*@C-:3 N$A:B!E)!$#%+04!?$:B!j'O:9"*k7-!E#2+8;  "!$#%&0!E(:!$8M0]3%[89!E#2+8;g!$#%4/!
C# O:9:&^C#2)#2O@89897-:48;:$RJcd04#%ff89!$.!E)!$#% I :(#\*'432:*:& :CK?@#%!D!D)32 I !$3g!$3%3 G C# O:9:&ff8;  "!$#%&
m0-: .$ I 5W'!$#2AB#%:K${G:|&7!$3\r8; "!$#%&B}:!$8"0x'4!$#2r$<(C7!$3ff?E!E"#%! I 3%:9RVyQ:k89!$3%3P0-:
<>$"*:9i0-:
C47!$3.!$3%3 G C4# :9":g
*@C-:3.!$C 0:Y3%!E :9i0-:
C7!$3j-${G:|[7!$3%
*[C:3 R cd0-:
 :9'4!EM!E#2 8;  M!$#%g!E":i-$,!$,#%*,'432:f Y 'O:89#2<>5Y#% 0-:WC7!$3D*,[C-:3R o-$+:;p@!$*'32:$N/<>$
QNDA:x89!$ !$CC 8;  "!$#\g]$<j0-:}<>$"*

H# 
!$C 
H#
*
QR.cJ! I 32: ])#2?$:K0-:HC7!$3J:9'": :g!E#%m$<0-:H :|&7:8;:
NO!
 (;+ *70
 3%7#2l ,0-: [N D' I 3%:*WR

V k0$

0E1K{Yo)7' G


1



]

z\ '

] S

BWS

]

$,

] Y 
] Y 143

+|

9

!| C E1K{`$,#G
nz 'I/1

+1

z

'

m





N

P



Y zI  ) '

N

/

lV 

 |~

f

P

<X] Y z  ] S0BTS Y(z*I '

z C:;p
!$3%7-:.$<wC7!$3O?E!E"#%! I 3%: 
/|[7#2?E!$32:gDC#%)#2D[89897:8;:
cJ! I 32:

+z ]

/
] 6





1


*




*








*

E<nxb74!$3ff:9'::g!E#2i$<J0:. :|&7:8;: 27948<2,.90,#8




&
(

1

1

&
*



] OY(z 
2497862,.9,"8

,

,

"
1(

.

(



.
(

sV[N D'

N-! 3%7-#2l$<w0-:

I 3%:*WR

z 1#%j'O"# I 32:k }8;* I #%-:'M#%*,!$3!$CZC47!$3*@C-:3% I 5X3\#%-L@#%-)+0:, Am :91$<V?!E"#\! I 32:9N
7#\-)
[u
;v>v
{u
 Z*,!$#\g!$#% 8;"#%  :8;5 I :9FA:9: 0-:l AQ?[#2:9AB' #\g9Rncd0#%
!E''"!$8"0 #%}89!$3%32:C {:C74C!$&l*,[C-:3\3%#%-)
MRhS #%*+#%3%!EW#%C-:! AV!$
I 5 V0-:) :9}!$3 R
':9?@#27"325r7)$)$:  :CffN$ 'O:89#2_489!$3%3%5B<>$P'O:9"*k7-!E#2.'4 I 32:*,N I 5 K:9:32:
MR(z{
!$-)$<a$MC 
' I 32:*WN[0-:j8"0!$:3%3%#%-)k8;  "!$#\gd!E":
,# 
N!$Cl8;  "!$#\gV$<J0-:j!$*:K<>$"*
89!$ I :r7:Cf#\ I 74#%3%C#%)K!H8;* I #%-:Cf'M#%*,!$3C74!$3*@C-:34$<J!$g5+' :9M*67-!E#%]'4 I 32:*WR~m!$g5
8;  M!$#%gk [32L[#%k"7-''O$68M0!$-:3\3%#%-)i$<B0#%6L[#%4CYAB#%0Y:9e+89#%:gk)32 I !$3V8;  M!$#%gRXo$
:;p-!$*'432:$N-z
@32?$:9B0!$D!8; "!$#%&9N	ff
fi4NgAB04#%8"0W89!$ I :j7 :Cl ":9'43%!$8;:.! :9d$<

#%C4#2?[#\C7!$3@8;  "!$#\g$<P0:r<>$"*
H#
"N@!$4C+0-: @#%897/_#2 :rC*,!$#%f8;  "!$#%&
3%# I "!E5+0!$B!$ff,'4:C#%89!E :jAB04#%8"0W89!$ I :.74 :CW#%*,#\3%!E"325$R
cd0:B8;* I #%-:C,*@C-:3#\(8932:!E"325k:C74C!$&w!$A:B89!$+C-:3%:9 :B0-:B8;4  "!$#%&($<O:#20-:9#%C# G
?@#%C7!$3^*,[C-:3PAB#20-7r#%8;":!$#%-),0:6 :9b$</ 3%7#29Rdo-$j#%4 !$8;:$N#\ P!$)$<a$"C B'" I 32:*WN

F4 KJ J@[ wQRJ2F`HKJMLON*P 7QTJfiNRL

N

;P

d1:07070$

2

@B Y| ] %Y z

d v2


@ B Y | ] Y%z

ld1:0707$ 9

9

X

#b!





fi 8-
	fiffff
A:+-:9:CQ3%5}:;p@':j0:, :9'4!E"!E#2Y8;  "!$#%&.#%X :9M*,j$<V:#20-:9j0-:+'"#%*,!$3J$.0:,C7!$3
?E!E"#%! I 32:R~i$":67-"'"#%#\-)325$N[0-:.'O:9"*k7-!E#2i8; "!$#%&d I $0W0:1'"#\*,!$3ff!$CW0-:6C7!$3
?E!E"#%! I 32:r!E:6!$3\ +:C47C!$&9Rdcd0-:6:;p@#% :8;:1$<(0:6C7!$3P?!EM#%! I 32:d!$4C}0-:k8"0!$4-:3%3%#%),8;@G
  "!$#\g(3\#%-L@#%-)B0:*  .0-:D'M#%*,!$3[?!EM#%! I 32:w!E:B"7-e+89#2:&w .:7-":04!E(0-:D?E!$3%7-:(!$"#2)-:C
 H0-:K'"#%*+!$3?E!E"#%! I 32:!E:j!6' :9M*67-!E#% =!$4C]0:9:9<a$":b0:b!$*,:K*k7  I :r M7-:r$< 0-:KC7!$3
?E!E"#%! I 32: MR

'

b

f

n

/?$:6#2<-8; "!$#%& !E:32$)#%89!$3%3%5b":C7C!$& >0!Ew#%9N0-:95.89!$ I :/C-:32:9 :C6AB#20-7P8"0!$)#%-)
0-:d :9/$<  3\7-#2 MNg0-:95k*+!5 #%3%3 I :d7 :9<=73@C7-M#%-)K :!E"8"0^R ^$)#%89!$3%3%51:C74C!$&w8;4  "!$#%&
!E:$<a :k89!$3%32:C #%*'3%#2:Cj8;  M!$#%g @N!$C674 :9<>743#%*'43\#2:Cj8;  "!$#\gw!E:<a:|[7-:&325.!$CC-:C1 
!B*,[C-:3 r#%8;":!$ :(0-:/!$*,7g $<-8;  "!$#%&P'4$'4!E)!E#2 @*,#20ffN [ :9)#27^N
yZ!$3%"0ffN
MR
z{H0-:D-:;p[(:8;#2ffNA:D': :&(!j*:!$7:V$< 8; "!$#%&J#%)0g-:"0!E(!$3%32 AB7w .C-:9 :9M*,#%-:
AB0-:x!$x#%*'43%#%:Ci8;  "!$#\gK!$CC-:Cm f!f*@C-:3 AB#%3%3^#\*' ?$:68;  M!$#%gb'$'!E)!E#2ffRbz m0-:
<>3%32`Ar#%-)l :8;#2ffN^A:!E''4325}0#%j*:!$7:H$<8;  M!$#%gj#%)0g-:"K W0-:,C# O:9:&K*,[C-:3\r$<
'O:9"*k7-!E#26' I 32:*+ #%& @C78;:C6#%104#% :8;#2ffRwyQ:D!E:D! I 32: K"0-`A.NE<>$w:;p@!$*'32:$N$0!Ew0-:
8"04!$-:3%3%#\-)i8;  "!$#\gk-$14325Q*,!EL$:]0: I #%4!E5x${G:|&7!$3\18;  M!$#%g6:C74C!$& 60-:95
!E:.#%)0g :9B!$4Ci89!$i)#2?$:6*$:.C-*,!$#\W'"74#%-)-R

N

I

-

P

c

?

7

KK37373>Y



=<

]}D#  R2ff



  ff  

(


vK7-6C-:9_4#2#%X$<d8;  "!$#%&.#2)0&-:6!$7*,:.0!Ek8;  "!$#%&k!E:+C-:9_4:CQ`?$:9H0-:f!$*:

?E!E"#%! I 32:!$4CH?!$3%7:w$N&!$(#\H0-:d89!$ :d$< '"#%*+!$3[!$4CC7!$3-*@C-:3%9N$?E!E"#%! I 32:w!$C?E!$3%7-:wAB0#\8"0
!E: I # {:8;#%?$:325}:3\!E :CffR,z{X0#%KAV!5$NwA:,89!$n!$32AV!5@18;*'4!E":+3%#2L$:HAB#20Q3\#2L$:$R K7-.C-:9_#2#2
$<r8;4  "!$#%&#2)0&-:#%H  )325Y#% 7-:8;:C I 5n0-:WA!`5 3%[89!$3V8;#\  :8;5Y'4$'O:9#2:H!E:
8;*'4!E":C I 5 b: I M7-5[:i!$C :# :9:
MR z 4C-:9:CffN0-:}C-:9_44#2#2 #%'!E"!$*:9 :9"# 9:C I 5
!W32@89!$3w8;#%  :48;5}'$'O:9F5}#%48;:k0:H!$*,7gj$<'"74#%-)+'4`?@#%C-:C I 5x!W :9j$<8;4  "!$#%&
C-:9'O:Cw7-'O60-:d32:9?$:3@$<O32@89!$3[8;4#%  :8;5 I :#%-)b:-<>$"8;:CffRJzF<A:D:-<>$"8;:d!j0#%)0k3%:9?$:3@$< 32@89!$3
8;#\  :8;5$NA:1*,!`5f)$:9r!$B*k78"0i8;4  "!$#%&d'$'!E)!E#2WAB#20W!+32&:.8;  "!$#%&B!$d!+*678M0
32 A:9,32:9?$:3V$<b32@89!$38;4#%  :8;5 !E''43%#%:CY Z!x#2)0&8;  "!$#%&9R j7-*:!$7-:l$<b8;  "!$#%&
#2)0&-:rA743%Ci!$3%  I :17 :9<=73^#%m!+[7* I :9r$<w$0-:9j!E''43%#%89!E#% >:$R )-Rd:!$#%-)+! I 7-r0-:
#%*'!$8;D$<wC4# :9":gD32@89!$3^8;#\  :8;5f :8"0#\|&7-:d}!#%)32:K_-p[:C}*[C:3 MR

5

x

)

lv

TS



Vy d1:070$,7

v







T


	

4#%C-:9l!  :9l$<68;  M!$#%g
C-:9_4-:C `?$:9m! :9f$<6?!EM#%! I 32:
/Nr!$C !$$0-:9W :9
$<68;4  "!$#%&
C-:9_4:C  ?$:9}!  :9l$<.?!EM#%! I 32:
DNBAB0-:9":m0-:9":X#\]! I # :8;#2 I :9 A:9:
!$#%)*:& 
}!$C
=#%H0-:d:($<O0-:d'4!E'O:9N$0#\ I # :8;#2#%:#%0-:9(0-:B#\C-:g#% 5H*,!E'^N
$K0!EKC-:9_4-:C I 5i0:k8M0!$-:3%3\#%-),8;  M!$#%g MRbyQ:H!`5}0!Eb0-:H :9r$<8;  "!$#%&
#%ku
v u du
Du D0-:6:9
AB#20W": 'O:8;d  G 8;4#%  :8;5 >AdM#2  :
V# wN)#2?$:x!$g5
C-*,!$#\<>$0-:#%/?E!E"#%! I 32:Ng#2<
#% G 8;4#%  :&/0-:]0-:d:|[7#2?E!$32:&C-*+!$#%$<
!$898;$"C4#%-)
 k0-: I # {:8;#2]!E:K!$3%  G 8;#%  :&9R 5,8;#%C:9"#%-).!$3%34'O# I 3%:dC-*,!$#%/<a$0-:r?!E"#\! I 32:9N
0#%.$"C-:9"#%)l*,:!$7-:j0:,'O$ :g#%!$3/<a$6C-*,!$#%K  I :'"7-:CQC47-"#%-)l :!E"8M0Y!$1?!E"#\! I 32:
!E:k#% !$&#%!E :C}!$4CiC-*,!$#%4D'"7:C >' "# I 325 I 5l$0-:9K8;  M!$#%gr#%W0-:1' I 32:* MR
$ :
0!EHA:lC4#%89710-:l:|&74#2?!$3%:gkC-*,!$#%k X0!EHA:l89!$ 8;"#%C-:9H'"#%*+!$3/!$C C7!$3*@C-:3%
#%nAB0#%8M0Y0:]?E!E"#%! I 3%:1!$C ?E!$3%7-:k!E:WC# O:9:g I 7-H!E:l#%Y:f x-:l:3%!E#%YAB#%0Y:!$8M0
$0-:9 MRyQ:r!50!E!. :9($<ff8;  M!$#%g
#\
0!$+!. :9
Ad G 8;#%  :48;5 >AB"#2  :
1#
(N
#%
@u u ;v H 
AB G 8;4#%  :8;5
I 76-$
>Ad"#%  :
b# -:#%0-:9
-$
(NP!$4C T#% t EuEv w  hAd G
8;#\  :8;5 >Ad"#2  :
w# I $0
Q!$C
(RwyQ:b89!$,:!$#%3%56)$:-:9M!$3%# 9:



fi	

fiff

fiff#

\[ 6LON 6L N*Q 7N 6L

K

5



 



b

5

5

 	  ! ff  



-)

@



c =



b

7N






N*Q 7N}[OP





	 !  ffq 	  ! ff
ff  ! 	  lQTJFIHK]W KP >Z \[ 5 

	6.ff- 
	  !ff ff  ! 	 # +[ jQ  [4JfiN 6
p
	#7ff-  	# !ff
 ff- !	
#b"!







fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff







fi

#

0-: :kC-:9_4#%#2D f8;*'4!E: G 8;#% :8;5W
Ar#20 rG 8;"#%  :8;5W fRVcB0#%dC-:9_#2#2
$<^8;  M!$#%g#2)0&-:0!$ *:K#%8;:B*$ #%89#2F5+!$C,_p[:C@G'O#%&('"$' :9"#2:(AB04#%8"0+A:bAB#%3%3
7 :j:;p@ :#%?$:325]07-)0-7-D04#%V'4!E'O:9R

Qs   s;	5x  {    {#w}w! tv{ff
fi  
ff
4 	 ff  !"	$ ! 	 ff
ff   	 !  ff QR] W vwQ[bLK 	 ff 7   	



 w'{

@#\*,#%3%!Ed*$ #%89#2F5}!$Ci_p[:C@G'O#%&d'"$'

_

)

_

@

_

9: "#2:d0-3%C}<a$ dbN bN (zbN -SBbNSB VbN
!$C KSBbRDyQ:Z!$3\ n:;p@ :C 0-::XC:9_4#2#24+  8;*'4!E":X8;4  "!$#%&l#2)0g:lAdl :!E"8M0
!$32)$$"#%0*,f3%#2L$:x~mSB !$C o h0!El*,!$#%&!$#%  *:Q32@89!$3r8;"#%  :8;5 C47-"#%-)n :!E"8"0^R o$
:;p-!$*'432:$N A:H!`5i0!E
#%Hu Vv "u ru
du
Adb!$32)$$"#204*
>Ad"#%  :
D# wN
)#2?$:]!$g5_-p@:C?E!E"#%! I 3%:d!$C,?E!$3%7-:D$"C:9"#%-).!$C]!$g5C-*+!$#%<>$/0-:B?!E"#\! I 32:$< 6N
?[#\#2
-X*$:l-@C-:k x_CY!X 3%7#2Z$<
$H'`?$:W#2H7"!E#% _4! I 3%:,0!$
?[#\#26 UAB#20
0-:H:|[7#2?E!$32:gKC-*,!$#\9Nff!$Cx0-::|[7#2?E!$32:gb?E!E"#%! I 32:H!$Cx?E!$3%7-:k$"C-:9"#%)-R /|[7#2?E!$32:8;:H0-:9:
#%D!E)!$#%iAB#20l: 'O:8;D 0-: I # {:8;#% I :9FA:9:}0-:.!$#%)*:&V ,0-:j?E!E"#%! I 32:V$<
!$Cl 
fRwyQ:r!`5,0!E
#%
(04!$
Ad(!$3%)$$"#20*
>AB"#2  :
(#
I 7-
-$
R @#%*,#%3\!E/*-$ #\89#2 5+!$4C,_-p@:C@G'O#%&/'$'O:9#%:/89!$ I :r)#2?$:f<a$Vo bN-~mSB
!$CX~ jSBbR ow#%4!$3%325$N4A:kAd"#2 :
#2<
!$Cm0-:9:k#%r!+'4!E"!$*:9 :9M# 9:CX :9r$<
' I 32:*,J$< "# 9: i!$C!j_-p@:CH?E!E"#%! I 32:D!$CH?E!$3%7-:D$MC-:9"#%-)bAB#20HAr0#%8"0 h?[#\#2w:;p@' :g#%!$3\325
<>:9A:9b-[C:d#% QAB0:i!E''43%#%:Cl 
0!$iAB0:i!E''43%#%:Cl  fR K7-B:732D89!$ I :j:;p[ :4C-:C
 +!$32)$$M#20*,V0!ED_CW!$3%3ff 3%7#29Rwz{W!$CC#2#2^N[0:95f89!$i!$3\  I :j:;p[ :C:CW +!H:  M#%8; :C
893%!$d$<wC5[!$*+#%8b?!E"#\! I 32:j!$CW?E!$3%7-:j$"C:9"#%-) V!$898"0[79NffV0-:ffN-?E!$ :9:9L N
yZ!$3%"0ffN
MR





 

7N [ 6LbN 6LmN*QKN KL 









$ ff  !"	 q
#

N*Q 7N}[OP

 o

5

 
%		& ff '	-! ff
I

9f

F


I v

(

9*)

)w
  R R ?   =0QTg7 



!	5!" ffq #	5 !" ff

I

o

	  ! ffq 
 

p)

?

fiK373$$





yQ:K-`A 0!?$:b0-:d0-:9$":9#%89!$3*+!$8"0#%:95-:9:C-:C, k8;*'4!E:r0-:BC# :9:&(AV!5@A:B89!$f*@C-:3
!k'O:9"*67!E#2+'4 I 32:*T78M0f!$ !$-)$<>$"C ' I 3%:*WRJcB0-:
,uEv[${G:|&7!$3\*,[C-:3$< !k'O:9 G
*k7-!E#2+04!$(-${G:|[7!$3%/8;4  "!$#%& I :9 A:9:+0:D?!E"#\! I 32:(#%H:!$8M0+'O:9"*k7-!E#2^RJcd0:
,uEv
!$3%3 G C4# :9":gw*@C-:3@0!$!$!$3%3 G C# :9:&w8;  "!$#%& I :9 A:9:0-:V?E!E"#%! I 32:w#%k:!$8M0,'O:9"*k7-!E#2ffR
z{Q!ZsEtuEvff*[C:3 NffA:]#%g :9M8"0!$-)$:?E!E"#%! I 32:K<a$j?E!$3%7-:RHST8;* I #%-:C
u$vu sxsEtuEvff*@C-:3
0!$ I $00:d'"#%*+!$3[!$4C0-:BC74!$3@?!E"#\! I 32:9N!$C [u
;v>v
{u
/3%#\-L[#\-)B0-:*iNg$<O0-:
<>$"*
f# 
AB0-:9:
#%d!'M#%*,!$3O?E!E"#%! I 32:.!$4C 6#%d!+C7!$3ff?E!E"#%! I 3%:$RS 8;* I #%-:C
*@C-:3J89!$Q!$3% l0!?$:,-${G:|[7!$3%K!$C $K!$3\3 G C# O:9:&b8; "!$#%&rx0-:H'M#%*,!$3P!$4C  $jC7!$3
?E!E"#%! I 32:R cB0-:9:WAB#%3\3 N($<K8;7-" :$NV 5['4#%89!$3\325 I :W$0-:9+8;4  "!$#%&, I $0 :9,$<b?!E"#\! I 32:
AB0#\8"0fC-:9'O:C,f0-:K!E7-:b$<^0-:K'O:9"*k7-!E#2]' I 3%:*WRJo$D:;p@!$*'32:$N[#\
!$-)$<a$MC ' I G
32:* A:.!$3% ,0!`?$:.0-:. :9'!E"!E#2W8;  M!$#%gR/SrD!+ :8;Cl:;p-!$*'432:$N#%l0:K!$3\3 G #%& :9?!$3ff:9"#2:
' I 32:* <>* 
P# I N@0-:1?E!E"#%! I 3%:d!$CW0-:kC# O:9:8;: I :9FA:9:x-:#2)0 I $"#%-)?E!E"#%! I 3%:d!E:
I $0X'O:9"*67!E#29Rkz ZAB0!EK<a3\32`ABN^A:,Ci-$.8;#%C:9.C#2:8;325m0-:,8;& "# I 7-#%m$<V78M0
!$CC#%#2!$3O8;  "!$#\gV 'M7#%-)-R r`A:9?$:9N40-:j:!$:.AB#20fAB0#\8"0fA:.89!$i:;p['":V:!$8"0m!$CC# G
#2!$3P8;  "!$#%&B#%l0:.'"#%*+!$3O$B0-:1C47!$3ff*@C-:3^!$CW0:.:73%#%-)H'"74#%-)k'  A:9r$< 0: :
8;  M!$#%gB*,!5WC-:9 :9"*+#%-:j7-B8M0-#%8;:.$<J0-:.'4"#%*,!$3 N@C7!$3O$b8;* I #%-:CW*@C-:3 R
yQ:kAB#%3%3P7 :10:1<>3%32`Ar#%-)+7 I 8;"#2'4
+<a$b0-:k'"#%*,!$3P-${G:|&74!$3%r8;4  "!$#%&9N
,<>$
8"04!$-:3%3%#\-)+8;  M!$#%gN
f<a$K0-:k'"#%*+!$3 -${G:|[7!$3%K!$CX8M0!$-:3%3\#%-)+8; "!$#%&9N







SW PIQR]



<A@B Y | X] Y z

WPIQR]

!WPbQR]
!FO KJfiJ [ wQRJ+FIHKJMLON*P KQRJfiNRL

@B

KJ

]



l

SM_q





Ee

N+, * - P

=< +N , * P

#b8

N.- P
N+, * /- , * P

fi 8-
	fiffff

N "P

<>$.0-:'"#\*,!$3w-${G:|&74!$3%9NPC74!$3-${G:|&74!$3%.!$CQ8M0!$-:3%3\#%-)l8;  "!$#%&9N  l<>$.0-:'4"#%*,!$3
!$3%3 G C4# :9":g,8; "!$#%&9N  Q<a$]0-:i'M#%*,!$3D!$3%3 G C4# :9":g,!$C 8"0!$:3%3%#%-)Q8; "!$#%&9Nd!$C
  H<>$r0:.'"#%*+!$3^!$3%3 G C# :9:&9NC7!$3 !$3%3 G C# :9:&d!$Cm8"0!$:3%3%#%-)8; "!$#%&9RDcd0&74BSB
#%HSBT!E''43\#2:CZ X0-:l'"#\*,!$3${G:|&7!$3\k8;4  "!$#%&9N(AB04#%3%  @SB
#% -SBT!E''43%#2:CY Q0-:
'"#\*,!$3O-${G:|&74!$3%B!$CW8M0!$-:3\3%#%-)8;  M!$#%gR

N - "P

`N - P









  s} 

 {#w





,* -

/

,*



 {#}

yQ:b_" '`?$:b0!E9N@AB#20+: 'O:8;/ HSBbN@8"0!$4-:3%3%#%).8;  "!$#%&!E:r#%)0g :9V0!$]0-:B'4"#%*,!$3
-${G:|[7!$3%d8;4  "!$#%&9N I 7d32:V#2)0&d0!$W0:.'"#%*+!$3 !$3\3 G C# O:9:&V8;4  "!$#%&9R



sx  Q
J u9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]
	 - 7 	 - 7 	 ! 	 , * -/, * 7 	 , * - 7 	 - ! 	 , *
u



ff


	

fi 

fi 



fi 







ff



5

v

z{ 0#%k!$C <a3\32`AB#\-)}'"&$<=9NA: 7 k' ?$:W0-:W* #%*'O$!$&1":7329R K0-:9"
Qs e
<>3%32`A |&7#\8L@325$N@$<a :m7#%-)H "!$4#2#2?@#2 5$N*,-$ #%89#2F5f!$4CW0-:._-p@:C@G'O#%&V0-:9$:*,9R
c  0- A KSB
SB Nb8;"#%C-:9i! 'O:9"*k7-!E#2 '" I 32:* AB0-:x'4"#%*,!$3K!$3%3 G C4# :9":g
8;  M!$#%g(#\ KSBbR @7-'4' :0:d8"0!$:3%3%#%-)b8;  "!$#\g I :9 A:9:
!$4C VAV!$/-$(SBKRcd0-:
:#20-:9 (#\B :9b  f!$C k0!$ :3%#%*,#%4!E :CW<a"*h#2bC-*,!$#\ffN$ 6#%b :9B  D!$C
(0!$
:3%#%*+#%!E :CW<>* #%BC-*,!$#\ffR 7r-:#20:9B$<0-: :6 AW89!$ :r#\d'O# I 32: I 5l0-:k8;  "748;#2
$<.0-:X'M#%*,!$3B!$4C C47!$3B*@C-:3 R r:8;:X0-:X8"0!$:3%3%#%-)n8;  "!$#%&W!E:X!$3%3KSBbRVcP 0- A
  "#\8;-:9NO8;#%C:9b! G?!EM#%! I 32:k'O:9"*67!E#2}'4 I 32:*h#%}Ar0#%8"0
]!$C
*
(
1 

RDcd0#%D#\DSB
7
d


$


K
B
S

R
I
/
3
c Y0- AhSB
SB
ND7-''O :l0!E,0:}8"0!$4-:3%3%#%)X8;4  "!$#%&,!E:xSBbR"#%C-:9,!
-${G:|[7!$3%b8;  "!$#\g9N   
D0!Eb#%B$rSBbR  A.N (!$C 1*k7 b0!?$:k0-:k!$*:
#%)32:9 1C-*+!$#%ff
N  R(V#%C-:9 0-:V8"0!$:3%3%#%-)d8;4  "!$#%& I :9 A:9:
4!$4C &Rwcd0-:/4325.SB
?E!$3%7-:.<>$ H#% R @#%*,#%3\!E"325$N[0-:.325lSB ?!$3%7:j<a$ H#%W0-:68"0!$:3%3%#%-)8; "!$#%& I :9 A:9:
 !$C
}#% R 7  -R B:48;:$N i0!$H-xSB ?!$3%7:9RxcB0#%1#\6!x8;g M!$C#%8;#2 !$k0-:
8"04!$-:3%3%#\-)r8; "!$#%&(!E:dSBbR r:8;:d!$3%3--${G:|[7!$3%8;4  "!$#%&(!E:dSBbRc .0- A   "#%8;:9N
8;#\C-:9b! G?E!E"#%! I 32:k'O:9"*k7-!E#2m' I 32:* AB#20
+!$C
Rkcd0#%
*
( 
1 
#%DSB
I 7-d#%D-$BSB R
c .0- A SB
SB N I 5k*-$ #%89#% 5$NgSB
SB Rwc .0-`A 0:":9?$:9" :$Ng8;"#%C-:9
!f'O:9"*67!E#2x' I 32:*hAB0#\8"0X#%KSB
R1cd0:m0:9:H:;p@#%b!E.3%:!$ K-:-${G
I 7-K-$jSB
:|[7!$3%8;  M!$#%gw0!E(#\J$wSBKR$y #207-32J$<4)$:-:9M!$3%#2 5$N&32:90#% I :HFA6C7!$3&?!E"#\! I 32:
=!b 5[*+*:9 "#%8(!E")7*:& 89!$ I :*,!$C-:<a$  Ab'4"#%*,!$3E?E!E"#%! I 3%: MR [ I $0.0-:!$ @89#%!E :C =C7!$3
 *k7 j0!`?$:0-:!$*:#%-)3%:9 xC*,!$#%ffNff!`
?E!E"#%! I 32:NO89!$3\3 0:*
!$4C
5  R B:48;:$N^0-:
C-*,!$#\ $<K0-:i'"#\*,!$3?!E"#\! I 32:
x#%893\7C-: 6!$C -R #%C:90-:}8"04!$-:3%3%#\-)Q8;  "!$#%&
m!$C
R
 A 0#%H#%k-$SBT!$H0-:l?!$3\7-:
Q04!$kX"7-''O$9RQcd0#%k#%H!
I :9 A:9:
8;& "!$C#%8;#2^R
c W0-`A jSB 
jSB N^8;#%C-:9K!l'O:9"*k7-!E#2x' I 3%:* 0!Ej#% KSB Rko-$j:9?$:95
'O# I 32:b!$"#2)*:&D$<w!?!$3\7-:j +!?E!E"#%! I 3%:$N[0:9:.:;p-#% d!8;#\  :gB:;p[ :"#2W ,0-:1$0-:9
?E!E"#%! I 32:N *
! """ #
%$lAB#20
 k<a$j!$3%3 & -R1Sbb0#%K#%b!f' :9M*67-!E#%ffNO0#%
8;$:' 4C( k0-:r!$"#2)*:&/$<^74#%|[7-:D?!EM#%! I 32:/ 6?E!$3%7-:9R r:8;:$N@0-:r8;$": 'OC#%).C7!$3
!$3%3 G C4# :9":gD8;  M!$#%gr#% KSBbR4ow#%4!$3%325$N@0-:18M0!$-:3%3\#%-)H8;  "!$#%&d!E:1 "#2?@#%!$3%325+SBKR('



@B



@ Y @ Y r~{YM{`"

-

!


|

]

)

"

- !

G

,*

-

, * -/, * 7

8

X]

]B =

@B

]4^

@ YV@ Y >1K{`

cz

@B

|

mz

2|

@
@B

_]4^

@ Y >1K{`~{`

-

, * - * , * -/*  !
, ,

I E

G e

@0^ Y |

- 7)

@ Y ] 4{ @ Y ]



=

-

D@^

]



a]

@ Y @ Y @ Y >1K{`

@

]4^

$e

-

]B

@^


e

*
@B , Y @ cRz Y |~





z

-

]4^ z S
O]4^ B| ) z Y | e

@

+@B

2

@B YV@

z Y |

K

#b%)

ge



T

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



#%-)b0-: :d#\C-:g#%#2:9NEA:D89!$#%*+*:C#%!E :325.C:C78;:$N<>$#% !$8;:$N$04!E(#2JC&:-$#%48;:!$ :
'"74#%-), i04!?$: I $0Q8"0!$4-:3%3%#%)]8;  M!$#%gj!$4Cm'4"#%*,!$3 >$1C7!$3 d-${G:|[7!$3%j8;4  "!$#%&9R
${G:|&7!$3\}8;  M!$#%g}C- -$i#%48;:!$ :Q0-:Y!$*,7gW$<8; "!$#%&W'$'4!E)!E#2 `?$:9m0!E
!$8"04#2:9?$:CXAB#20X8"04!$-:3%3%#\-)+8;  M!$#%gj!$3%-:$R.SrK7b:;p@'O:9"#%*:&b0-`A 3\!E :9b^Nff0-:95}3%5
!$CC `?$:9"0:!$C  n0-:x8;  "!$#\gl 32?$:9R zFl#%]#%#2)0& <=73D  :;p[ "!$8;l<>* 0-: :x'[$<>]0-:
:!$ 4HAB0g5n!E"8 G 8;#% :8;5n'O:9<>$"*,kC# O:9:&k!$*,7gH$<b8;  "!$#\gH'$'!E)!E#2 #% 0-:
C# O:9:&d*@C-:3%9RSr"8 G 8;#% :8;5WC-:32:9 :d?E!$3%7-:D#\l0-:1C-*,!$#\V$< ?E!E"#%! I 32:D!$d<>3%32 AB



=

R







=<

 t2}  {st2w'{  #2<0-:C-*,!$#%m$</!$&5}$<(0:k'4"#%*,!$3P?!E"#\! I 32:B#\r":C78;:C
 m
 !i#%-)3%:9  >:#20-:9 I 5x8; "!$#%&.'$'4!E)!E#%Q$ I 5x!$"#2)*:&j#%Q! I !$8"L& "!$8"L[#\-)
!$3%)$$"#20* MN$:<a$"89#\-)bSBnH0:'4"#%*,!$3[-${G:|[7!$3%w8;  "!$#\gw:*,`?$:0#\ ?E!$3%7-:<>*
!$3\3ff$0-:9d'M#%*,!$3 ?!EM#%! I 32:9R

sw'x

t2{  



l

}ffut2{l{

 ''w'{]} 

?>

!$,AB#20 '"#%*+!$3-${G:|[7!$3%+8;  "!$#%& D#% !$CC#%#2ffN/#2<B0-:iC-EG
*+!$#%i$<(!$&5WC7!$3^?E!E"#%! I 32:.#%d":C78;:Ci f!+#\-)32:9 ffN:<a$"89#\-)+SB i0-:k8"0!$:3%3%#%-)
8;4  "!$#%&b:*`?$:K04#%B?E!$3%7-:6<a"*h!$3%3P$0-:9jC7!$3 ?!EM#%! I 32:9RBz m'4!E#%89743%!EN#%<w!]?E!$3%7-:
@89897-"J#%j0:C-*,!$#\.$< 74 P-:$0-:9J'"#%*,!$3E?E!E"#%! I 32:$N :<a$"89#\-)BSBZ.0-:8"0!$:3%3%#%-)
8;4  "!$#%&d:"7-:V0!EB$0-:9B?E!$3%7-:.89!$ I :.!$"#2)-:CW ,04!Ed'"#%*+!$3?E!E"#%! I 32:$R
{#st2w'{ 

r5


  



t2Ttv ,w



s {}  {#st2w'{  :-<>$"89#%-) KSB m!'"#\*,!$3ff!$3%3 G C# :9:&d8;  M!$#%grAB#%3%3
'4"7-:,!$3%3(0-:+?E!$3%7-:j04!E6!E:]:*`?$:C I 5x:<a$"89#\-)}SB Y0-:+'4"#%*,!$3-${G:|[7!$3%1$
8M0!$-:3\3%#%-)18;4  "!$#%&9Rz{]!$CC4#2#2ffN&:-<a$M89#%-) jSB #%/ *,:9#%*:V! I 32:b 6'4"7-:r$0-:9
?E!$3%7-: >:$R )-R#%< A:j0!?$:KFAH'"#\*,!$3-?E!E"#%! I 32:AB#20+325FAH?E!$3%7-: I :9 A:9:]0:*WN&0: :
?E!$3%7-:dAB#%3%3 I :K:*`?$:Cm<>* !$3%3O$0-:9r'"#%*+!$3?E!E"#%! I 32: MR

sw'x





I

z{ I "#2:9< N-SB W0-:j'4"#%*,!$3O-${G:|[7!$3%d8;4  "!$#%&dC-:9 :8;b#%-)3%:9 l?!E"#\! I 32:9N@AB0#\3% VSB 
 0-:k8"0!$:3%3%#%-)]8;  "!$#%&bC-:9 :8; I $0x#%)32:9 i?E!E"#%! I 3%:6u sk#\-)32:9 i?E!$3%7-:R KSB 
!x'"#%*+!$3(!$3%3 G C# :9:&68;4  "!$#%&9N( 0-:f$0-:90!$CffN(C-:9 :9M*,#%-:6)32 I !$38;#% :8;5ZAB0#\8"0
#%893\7C-:V#%-)3%:9 l?!E"#\! I 32:9N#\-)32:9 l?E!$3%7-:d!$CW*+!$g5l$0-:9b#27!E#249R





t2w'{t2w'{lw'{

  H



KJ



s} 

 {wD

 {#}

 

X

cd0-::d:73%(89!$ I :B3%#%<a :C k!$32)$$"#204*,0!E*,!$#%&!$#% >)$:-:9"!$3\# 9:C w!E"8 G 8;4#%  :8;5,C47-"#%-)
 :!E"8M0ffRHz 4C-:9:CffNO0-:)!E'4 I :9FA:9:Q0:k'4"#%*,!$3w!$3%3 G C4# :9":gK!$CX0-:8"04!$-:3%3%#\-)f8;4  "!$#%&9N
!$C I :9 A:9:Q0-:8"04!$-:3%3%#\-)]8; "!$#%&j!$CX0-:H'"#%*+!$3 -${G:|[7!$3%j8;4  "!$#%&j89!$ I :6:;p[G
'O-:&#%!$3%325,3%!E")$:$R
$ :10!Ed-$d!$3%3OC# O:9:8;:D#\f8;4  "!$#%&D#2)0&-:V:7432D#%f:;p['O-:&#%!$3
:C748;#2/#\+ :!E"8M0ffR(o-$D#%!$8;:$N& *,:bC# :9:48;: I :9 A:9:l*[C:3%(AB04#%8"0,!E":r3%5k'O325@-EG
*,#%!$34!E:B#%C-:&#2_:C#\]V0-:-)j:9!$3 R
MR d:89!$3%340!E(A:BAd"#% :
Y#
Y!$C
0-:9:H#%b!+'4 I 32:* mAr0#%8"0x!$32)$$"#%0*
?@#%#%d:;p@' :g#%!$3\325l<a:9A:9 I "!$8M0-:bAB#20
0!$
fR
$ :H0!E KSB
!$CXSB !E: I $0x'O325@-*,#%!$3^ f:<a$"8;:$N^l!$x:;p@'O-:g#\!$3P:C478;#2
#% I M!$8"0-:d "!$3%!E :d ]!$W:;p@'O-:g#\!$3O:C78;#2}#%l"7&#%*:$R



=



d1:07070$ 



u


	

	 &" ff  	#!  ff





=





sx  Q
J u9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]
	 & 	 	 , * -/, * 7 	 	 , * - 7 	 	 - &
ff




fi ff

Qs e





	



-v

yQ:r)#%?$:B'[$<=(<>$/0-:b* #\*'O$!$g#%C-:&#2#2:9R b0-:9:732/<a3\32`A
0-:.3%!$d0-:9$:*WR



<>*

	 , *

#br

#%*,*:C#\!E :325

fi 8-
	fiffff

$

&

RoI$
@ S Y @ S Y :o c
I 1K{YoAI~{YoAI

@BLY

c 0-`A ~ KSB
~}SB N@8;4#%C-:9D!
G?!E"#\! I 32:b' :9M*67-!E#%]'4 I 32:*qAB#20
 <>$

(!$C # (
#

Rwcd0-:ffNE)#2?$:k!B32:;p-#%8;$)$"!E'0#%89!$3
1
?E!E"#%! I 32:K$"C:9"#%-)-N4~ KSB
#%*,*,:C#%!E :325]<>!$#%3\9N@AB0#%3%V~mSB
!EL$:  I "!$8M0-:9R
c ]0`A ~}SB
~mSB
N8;4#%C-:9B!
G?E!E"#%! I 32:1'O:9"*k7-!E#2W'4 I 32:* Ar#20
*

N !$4C
	 """
<a$ 
[R6cB0-:ffNO)#2?$:Q!l32:;p-#%8;$)$"!E'40#\89!$3P?E!E"#%! I 3%:6$"C:9"#%-)-N
~mSB
!EL$:
!EL$:
 I "!$8"0:9R'
I "!$8M0-:D +0`A #\ 3%7 I #%3%#2F5$NgAB0#\3% D~}SB

z \ oAIc1

>1K{"""6{Yo


$

- &

>1K{`

*
@B*Y r~{ 6{Yo I%, 

-

z






  s
	t$s

 

 }fiffaw{

u

-

Ro I $



o

,*

@ Y

MRo6J 18



 

s

~m!$#%g!$#\#%-) >)$:-:9M!$3%# 9:C (!E"8 G 8;#% :8;5]3\!E)$:d'O:9"*k7-!E#2,'4 I 32:*,/89!$ I :D:;p@' :4#2?$:$R
yQ:,*,!`5}0-:9:9<>$:HC-:89#%C-:k W7 :H!l8"0-:!E'O:9.32@89!$3 8;4#%  :8;5m'$'O:9F5i3%#2L$:k0!Ej*,!$#%&!$#%-:C
I 5k<>$AV!E"C,8M0-:8L@#%-)-R(o-$:;p@!$*,'432:$Ng0:bV0-@8;j_4#2 :;G C*,!$#%H [32L[#%(#%]V3%!$#%:D7 : 7 /4o 
 !$3%3 G C# O:9:&,8;  "!$#\g9R cB0-:}8"04!$-:3%3%#\-)Z8;  "!$#\g]:*,!$#% #2)0& :9]0!$ 0-:}'4"#%*,!$3
-${G:|[7!$3%d8;4  "!$#%&dAd"do bR

5



  s  x
u



J$ M ff ! $




3

JQu9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]ff


, * -/, * 7 $ , * - 7 $ - ! $  , * ! J$








! J6$  
K:gW:9W!$3 RVK37373>f' ?$:Qo  , *  !



J$ M ff



3

oJ
R c  0- A  "#%8;-:f 'O:9"*k7-!E#2
Qs e
' I 32:*, =!$]$''O 
: C  n0-:}*$:})$:-:9"!$3B893\!$,$<.C-:8;*,' "! I 32:i8;  M!$#%gf 7C4#2:C I 5
b:&9N [ :9)#%7ffN!$C Z
y !$3%0ffN
MN8;4#%C-:9H!
G?E!E"#%! I 32:]'O:9"*k7-!E#2n' I 32:*UAB#%0
*

f!$C

RHz : 'O:8;#2?$:H$</0:k?E!E"#%! I 32:k!$4Cm?E!$3%7-:H$"C:9"#%-)-N
(
1
/
3
o  0- ABr0-:1'" I 32:* #\r74!E#% _4! I 32:.#%}!EK* 
I "!$8M0-:9RBoJ
I 5i8;*'4!EM#% i!EL$:
!EB32:!$
I "!$48"0-:9R
c x"0-`A o 
oJ
N8;#%C-:9k!$#2)4#%-)i0-:f?E!$3%7-: x x0-:]'"#%*,!$3(?!E"#\! I 32:
FRmo 
:* ?$: H<>*q0-:jC-*,!$#%]$<P!$3%3 $0-:9V'"#\*,!$3?E!E"#%! I 3%:9Ro 
#% !$&#%!E :V0-:KC7!$3?!EM#%! I 32:
 AB#%0 0-:}?E!$3%7-: NB!$C 0-: :*,`?$: k<a* 0-:mC*,!$#% $<.!$3\3D$0-:9f'"#%*,!$3d?!E"#\! I 32:9R
r:8;:$N oJ
'M7-:D!$3%3P0-:.?E!$3%7-:d04!Ero 
C-&:RVc ]"0-`A   "#%8;:9N48;"#%C-:9B! EG?!E"#\! I 32:
'O:9"*k7-!E#2W'" I 32:* AB#%0

,!$C

R K#2?$:x!,32:;p-#%8;$)$"!E'0#%89!$3
*
(
1
/
?E!E"#%! I 32:!$C6[7*:9M#%89!$3?E!$3%7-:($MC-:9"#%-)-NEo 
0- ABP0:/' I 32:* #% 7!E#\ _4! I 32:(#\
I "!$8M0-:9R
o 
I 5W8;*'4!E"#\ l!EL$: 7 
I "!$8M0-:9R
b:&1:96!$3 R
.'`?$:fo 
oJ
R]c }0- A 0-:+:9?$:9" :$Nw8;#%C:9.!$#2)#\-)W0-:
?E!$3%7-: l W0-:k'"#%*,!$3 ?E!E"#%! I 32:
R1o 
:* ?$: l<>* 0-:C-*,!$#%x$</!$3\3 '4"#%*,!$3P?!E"#\! I 32:
:;p-8;:9'
R r`A:9?$:9N^o 
!$3% ]:* ?$: l<a"* 0-:HC-*,!$#\}$<(!$3%3 '"#\*,!$3^?E!E"#%! I 3%:d:;p-8;:9'
#%48;::!$8"0Z@89897-"1#%Q! I #%4!E5}-${G:|[7!$3%.8;4  "!$#%&.AB#20
 I !$#%-:C I 5m'4 {:8;#\-)W7-
0-:1!$3\3 G C# O:9:&V8;4  "!$#%&9R r:8;:$N4o 
o 
R
c ]0`A 4o 
oJ
N8;"#%C-:9B#%4 !$g#\!E#%-)0-:6'"#%*,!$3O?E!E"#%! I 32: wAB#20i0-:.?E!$3%7-:
-RKo 
:* ?$: f<a*h0-:kC-*,!$#%m$<(!$3%3 '"#%*,!$3^?!E"#\! I 32:d:;p-8;:9'
N <>*h0-:kC*,!$#%
$<^!$3%3C7!$3?E!E"#%! I 32:(:;p-8;:9' $N[#% !$&#%!E : BAB#20+0-:B?E!$3%7-: N@!$C+0:,:* ?$: <>*q0-:
C-*,!$#\,$<P!$3%3 C7!$34?!EM#%! I 32:/:;p@8;:9'  R(o 
!$3% k:*`?$: k<>*q0-:KC-*,!$#%+$<P!$3%3'4"#%*,!$3
?E!E"#%! I 32:K:;p-8;:9'
{R,cd0-:325x'O# I 32:kC4# :9":8;:#%.#2<-:,$<0-:,$0-:9kC7!$3w?E!E"#%! I 32:N^!5
04!$b!lC-*+!$#%xAB#2'O:97-9RbzF<(04#%K0!E''O:9N /04!$K-:H?!$3%7:k#%x#2KC-*,!$#\ffN 0!Ej#%b#%x0-:
C-*,!$#\Z$<B-m$0-:9k'"#%*,!$3/?!EM#%! I 32:$R -<a$M89#%-) KSBq#%*+*:C#%!E :325XC-:9 :8;H0!E
d89!$4-$

p

 
@ Y @ Y @ Y >1K{`~{`
1:.

- !

q|

]

-

e

-

@B



|

H@B Be


]

,*

@B

1:

3

m|

z

g5



1  !

@B

1

 !
S|

@ Y

"

@ Y :M{`"

D@ Y >1K{`

nVK37373>

,* - ,*

|

Xz

-K37373>

, * -/, *

,*

, * S|



pf

s

9

|

,*

]

]

-

, * @ Y @ Y[@ Y r~{Y 

1 7

qe

]

,*

@B

@ B

z
-|



0@B

#b#b

#

65

@B z

@B

z

@B

,*

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



G 9e

B|



!EL$:0-:H?E!$3%7-: N^!$CX*674 b#\  :!$Cx!EL$:0-:k?!$3%7:
R r:8;:o 
0!$K!lC-*,!$#%mAB#2'O:97-
AB0-::9?$:9VoJ
C &:Rwc 0- A  "#%8;-:N@8;4#%C-:9V! `G?!E"#\! I 32:b' :9M*67-!E#%+'" I 32:*qAB#20
f!$C

R1z : 'O:8;#2?$:6$<(0-:k?!EM#%! I 32:
*
(
1
/ 
3
4 
!$Cx?E!$3%7-:k$"C-:9"#%)-N o 
!EL$:.!Ej32:!$
I M!$8"0-:b W0- A 0-:H' I 32:*h#%K7!E#\ _4! I 32:$R
o 
I 5l8;*'4!E"#%W!EL$:r,*$:.0!$
I "!$8M0-:9R
:# :9":j:9d!$3 R
V' ?$:jo 
oJ
RcP0- A   "#%8;:Vf' :9M*67-!E#%l' I G
32:*,NP8;#%C:9.!
G?!E"#\! I 32:'O:9"*k7-!E#2X' I 32:* AB#20

i!$C
*
(
1
/

RQz :' :8;#%?$:]$<d0:]?E!E"#%! I 3%:+!$Cn?!$3%7:]$"C:9"#%-)-Nwo  f0- ABk0-:f' I 32:*
#%
3
7"!E#% _4! I 3%:6#%X!Ej32:!$ 
I "!$48"0-:9Rko 
I 5m8;*'!E"#% x!EL$:1l*,$:H0!$
I "!$8M0-:9R

* -/*
@ Y @ Y @ , Y , @ Y >1K{`~{`
S
)

+,
@ Y @ Y @ Y :M{`"~{`&~{I,
&
p
 !
1

, * -/, *

Vy

d1:07070$
p"

@ Y :M{`"

@ Y @ Y @ Y @ Y >1K{`~{`

&

1





'

T

 

r






{ #

 {}

 {#w


5

Sb-$0-:9w8;*,*k*:90-@C1 b:C78;:8; w#%^ b:-<>$"8;: 7  I 74C^8;"#%  :8;5$Rwo-$w:;p@!$*,'432:$N
I 7CD8;4#%  :8;5l#%d74 :CW +'4"7-:j!)32 I !$3^8;  "!$#\gB#\g?$32?@#%-),!+7* $<w?E!E"#%! I 32:D!$4C}!
 :9d$<#%:|&7!$3\#2#2: :9 )#%
r7-:0-:9N
MRdSbB!,:8;Ci:;p-!$*'432:$N *:.$<w0-:.:;p@'O:9"#%*:&
Q'O:9"*k7-!E#2X'" I 32:*,b'O:9<>$"*:C I 5 @*+#20
j7 :C I 74CK8;#%  :48;5mZ8;:9"!$#%
$<D0-:f8;  "!$#%&9Rly #20 I 7C4j8;#%  :48;5QZ'O:9"*k7-!E#2Z'4 I 32:*,NPA:+ I !$#%n!i?$:95
#%*+#%3%!EV$"C-:9"#\-)H$< 0-:6*[C:3%D!$dAB#%0WSBbR

9

sx 

u




#? 

fiK37373>


VK37373>

JQu9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]ff


- !  ,*

	 ,*
Qs e c i0- A )d - ! )d , * NP8;#\C-:9j!l' :9M*67-!E#%X' I 32:* AB04#%8"0X#%)d - I 7-K-:$<
0-:'M#%*,!$3J-${G:|&74!$3%.8;  M!$#%gj#\j-$9)dbRffcd0-:ffN^#2KA73%CQ#%&?$32?$:H Ai?E!E"#%! I 3%:9NZ@BV!$C




!





,* - ,* 7





,* - 7







ff



@

LE G { G7G qf

/)
E zu{Yz G mf

 0lAr#20W#%C-:&#%89!$3O#%& :9?!$3ffC*,!$#%9N
R -<>$"89#%-) d l0-:.8M0!$-:3%3\#%-)H8;  "!$#%&
I $
!$C
A73%Cx:C748;: , l0-:C-*,!$#%
R /-<>$"89#%) d x0-:8"0!$:3%3%#%-)
I :9 A:9:
8;  M!$#%g I :9 A:9: b!$C
KA743%C,0-:f89!$7 :b!6C*,!$#%,Ar#2'O:97-9R V7-0#%8;g M!$C#%8;0-:
8"04!$-:3%3%#\-).8;  "!$#\g I :#\-) dbR r:8;:$N@!$3%30:B'"#\*,!$3--${G:|[7!$3%8;  "!$#%&*67 I : dbR
c }0- A   "#%8;:9R,8;#\C-:9.!
G?E!E"#%! I 32:'O:9"*k7-!E#2X'4 I 32:* AB#%0
D!$C
*
(


R
d
c

0
\
#
D

%
#

d

7
d


$


d

R
I
1
c m0`A d
d
NJ8;"#%C-:91!}' :9M*67-!E#%Q' I 3%:* AB0#%8M0Z#% d R @7-''O :HA:
!$#%)x! I 7C4!E5W?!$3\7-: W i!]'4"#%*,!$3P?!E"#\! I 32:$N
>$j:|[7#2?E!$32:&325$Nff! I 74C!E5W?E!$3%7-: D 
!WC7!$3J?E!E"#%! I 3%:$N  MRHSrK0:,!$3%3 G C# O:9:&b8;4  "!$#%&j#% dbNO0#%j89!$ I :H:;p[ :C:CX i!$3%3w0-:
$0-:9d'4"#%*,!$3 ?E!E"#%! I 32:D74#%-)H:!$8"0m$<J0-:j?!$3\7-:D8;:$R/cB0#%V)#2?$:d74d!,8;#\  :gd!$"#2)*:&
<>$.!$g5m$0-:9j'"#%*+!$3P$.C74!$3 ?E!E"#%! I 32:$R B:48;:$NP#2j#% d
R6c l"0-`A   M#%8;-:9N^8;4#%C-:9j!
G?E!E"#%! I 32:'O:9"*k7-!E#2X'4 I 32:* AB#%0
V!$C
R]cd04#%j#%
*
(
1
/
3
d
I 7-d$ D R
c j0-`A SB
d N8;4#%C-:9w!B'O:9"*k7-!E#26' I 32:* Ar0#%8"06#% D I 7 -$wSB
Rwcd0-:
0-:9:*k7  I :6:H8;4  "!$#%&9N  ENffAB#20
!$C 04!?@#%-)f0-:!$*:#%-)3%:9 xC*,!$#%ffN
 R V7-9NP#2<0#%j#%K0:,89!$ :$NP:-<>$"89#%) d
Z0-:,8"0!$4-:3%3%#%)]8;  M!$#%g I :9FA:9:
!$C
6!$C I :9 A:9: K!$C
.A73%C]'`?$:j04!ED0-:K' I 32:*T#%V7"!E#% _4! I 3%:$R r:8;:$N#2V#%VSB
R
c m0- Aq  M#%8;-:9Nw8;#\C-:91!
G?E!E"#%! I 32:,'O:9"*k7-!E#2Z'4 I 32:* AB#%0
d
$
!


C
*
(
Rcd0#\D#%DSB
I 7-D-$ D R '
1

@ B

@ Y E1K{`"G

]4^
@
)

]7^

*

! ) , , * -/, *
|

)

]7^

) e
X
)

] 

)

"

@ Y @ Y E1K{`"G

-

G +)
4] ^

@ Y E1K{`"G

9)

@B



S)

,* ! ) -

D@

]7^

,*

Z@B Y @
!
)

)

)

@B

p

@

)

mz

)

* -/*
@ Y @ Y @ Y , E 1K, {`"G
9e

, * -/, *

l)
)

X@ Y @ Y E ~{`""G
)

-

,*

@B

e
*
@ YF@ Y E1K{`"G ,

-

#b

fi 8-
	fiffff



  

xb: I

 Dsw}  
 ft$u
m)



 {#w

*y 9d1:070$,7
m_

 {}

,_

"7-5@-:V!$C :"# :9:
w0!`?$:d0-`Ar10!E
n#%J!B'"*,#%#%)d_432 :9"#\-)B :8M0#%|[7-:V! I  ?$:
SBbR zFr'"7:B*,!$&5W$<(0-: (z ?E!$3%7-:b!Eb3\#2 32:.:;p@ "!f8; r lSBbR @7-'4"#%#%)325$N-8"0!$:3%3%#%-)
8;  M!$#%gH!E:l#%8;*,'4!E"! I 32:] m0:f'4"#%*,!$3(${G:|&7!$3\k8;4  "!$#%&kAd
KRwV0!$4-:3%3%#%)
8;  M!$#%gD89!$}#%8;:!$ :K0-:j!$*74gD$< '$'4!E)!E#2 ><a$D:;p-!$*'432:$N@AB0:W!kC47!$3 ?!E"#\! I 32:K0!$
325m-:,?E!$3%7-:32:9<>.#%Q#2jC-*+!$#% MR r`A:9?$:9N
 #\j0#%C-:9":C I 5x0-: I #2'4!E"#2 :8;  "!$#%&
)$"!E'40 I :9FA:9: '"#%*,!$3K!$C C47!$3K?!EM#%! I 32:9R SbCC#2#24!$3r-${G:|[7!$3%}8;  "!$#%&W '4"#%*,!$3
!$C  $rC7!$3O?E!E"#%! I 32:D89!$}0-:9:9<>$:10-:3%'W'$'4!E)!E#2^R

 +e

sx

u



_





 _

JQu9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]





!  , * -/, * 
!   , * - !	  - .
  , * . 	 Qs e cPX0- A  _ - .3 _V * Nw8;4#%C-:9k!XEG?E!E"#%! I 3%:+'O:9"*k7-!E#2Z'4 I 32:* AB#20X@ * Y
@ ( Y @ 1 Y >1K{`~{`m!$CO@ / Y >1K, {`~{`~{Y Rncd0#\6#%* _V , * I 76-$ _V - RXo$k0:]:9?$:9M :
C#2":8;#2ffNd8;#\C-:9f!" G?E!E"#%! I 32:x'O:9"*k7-!E#2 ' I 32:* AB#20 @ * Y @ ( Y @ 1 Y >1K{`n!$C
@/ Y @3 
Y r~{YM{`"RDcd0#%D#\  _ - I 7-d-$K _ , * R
c  0-`A 
 _ , * - !  _ - NB8;4#%C-:9l!E)!$#% 0-:X3%!$ f:;p@!$*'32:$R cd0#%]#%H _ - I 7-l-$
 _V , * - R
c 10- A  _V * -/* !  _V * - Ng8;#%C:9(!9& G?!E"#\! I 32:D'O:9"*k7-!E#2H' I 32:* AB#20`@ * Y @ ( Y
, , Y @ Y , @ Y @ Y :M{`"~{`&RVcB0#%V#%  _ * - I 7-d$K _V * -/* R
>1K{`~{`~{YM{`"~{`&]!$C @
1
/
3
c ]0`A j
 SB !; _ , * - , * N48;4#%C-:9b!'O:9"*67!E#2i'" I 32:, * AB04#%8"0i#\ K SB , R , @7-''O :
A:+!$#2)Y!W?!$3\7-: |i m!W'"#%*+!$3 ?E!E"#%! I 32:$NL@ B >$6:|&7#%?!$32:&325$NP!i?!$3%7:/zB }!iC47!$3w?!EM#%! I 32:$N
] 6MRmSb10:f!$3%32G C#O:9:g68;  "!$#%&6#\K
 SBKN 0#\189!$ I :,:;p[ :4C-:C  x!$3%3/0-:f$0-:96'4"#%*,!$3
	

fi 

?E!E"#%! I 32:K7"#%-)]7'X!$3\3 0:k$0:9j?!$3%7:9R1cd0#\B)#2?$:17K!f8;4#%  :&.!$#2)4*:gK<>$j!$g5x A
$0-:9r'"#%*,!$3 $bC7!$3O?E!E"#%! I 32:R B:48;:$N40-:.'4 I 32:* #% /z 
!$CW0[7
V
Rc +0- A
  "#\8;-:9N^8;"#%C-:9.! `G?E!E"#%! I 32:H'O:9"*k7-!E#2X'" I 32:* AB#20


*
(
1
/
!$C


RDcd0#%D#\


7
d


$


K
B
S

R
I
3
4
c 60`A SB
V
N[8;"#%C-:9(! EG?E!E"#%! I 32:D'O:9"*67!E#2' I 32:* AB#20
*
(
1

r!$C

Rcd04#%P#%
V
I 7- -$SB Rwo-$0-:V:9?$:9M :C4#2:8;#2ffN$8;"#%C-:9
/
! G?!E"#\! I 32:b' :9M*67-!E#%+'" I 32:* Ar#20
1!$C
RVcd0#%
*
(
1 
/
3 
#%DSB

R '
I 7-D-$

X,
D@ Y @ Y @ Y :M{`"~{`&~{I,
- .> _ *
>1K{`~{`
@ Y >1K{`~{`~,{Y
"
K_ , *
-

fiff

tuD{  s 

 



 {wD

qe

_

, * -/@ , * Y @ Y @  _ Y ,@* -/, * Y >1K{`~{`

 _ , * -/, *

9
 _ , *
@ Y @ Y @ Y >1K{`

`@ Y @ Y @ Y

@ Y @ Y r~{YM{`"

 {#}

cd0-:,#\8;*'4!E"! I #%3%#2F5W$<8M0!$-:3%3\#%-)l8;  "!$#%&1!$4CX'"#%*,!$3w-${G:|[7!$3%18;  "!$#%&j:*+!$#%
AB0-:lA:1* ?$:67-'W0:132@89!$3^8;#% :8;5f04#2:9"!E"8M0g5f<a"*
V   (zbR
u



  s  xff



( _

JQu9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]ff


l_

!  , * - , * !  , * - !  - .  , * . 	 Qs e cP 0- AG_(z - . _(z * Nd8;#%C-:9f!EG?E!E"#%! I 3%:i'O:9"*67!E#2 '" I 32:* AB#%0R@ * Y
@ ( Y @ 1 Y >1K{`~{`Y!$4C @ / Y , >1K{`~{`~{Y R cd0#\,#%s_/z  , * I 7-]$l_(z - Raf/<a$"89#\-) _(z
 0:}8"0!$4-:3%3%#%)X8;4  "!$#%&,:C478;:+@ /  Y0-:}"#%-)32:9  C*,!$#% : R o-$f0-:i:9?$:9M :
C#2":8;#2ffNd8;#\C-:9f!" G?E!E"#%! I 32:x'O:9"*k7-!E#2 ' I 32:* AB#20 @ * Y @ ( Y @ 1 Y >1K{`n!$C
@/ Y @3 
Y r~{YM{`"RDcd0#%D#\ _(z - I 7-d-$ _/z  , * R
	

fi 

#b8

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



c x"0-`A _(z * - !
_/z  - N(8;"#%C-:9H! " G?E!E"#%! I 3%:+'O:9"*k7-!E#2n' I 32:* AB#20 @ * Y @ ( Y
@ 1 Y > 1K{`k!$CD@ , / Y @ 3 Yr~{YM{`"RDcd04#%V#%S_(z - I 7-d$S_(z , * - R
c ]0`A _/z  * - * ! _(z * - N48;#\C-:9B!s& G?E!E"#%! I 3%:.'O:9"*67!E#2W' I 32:* AB#20D@ * Y @ ( Y
, , Y @ Y , @ Y @ Y :M{`"~{`&RVcB0#%V#%S_/z  * - I 7d-$S_(z * -/* R
>1K{`~{`~{YM{`"~{`&]!$C @
1
/
3
c }0- A K
 SB ! _/z  , * -/, * NJ8;#%C:9.!W'O:9"*67!E#2X' I 3%,:* #%XAB0#%8M0X0-,:,!$, 3%3 G C4# :9":g
8;  M!$#%gr#% K
 SBKR@@7-'4' :bA:6!$"#2)i!+?!$3%7: |+ f!,'M#%*,!$3O?E!E"#%! I 32:$N<@BS>$r:|[7#2?E!$32:&325$N4!
?E!$3%7-:z( ,!C7!$3 ?E!E"#%! I 3%:$N6
] 8MR/SbD0-:j!$3%3 G C4# :9":gV8;  "!$#\gd#%Kj SBbN-0#%V89!$ I :K:;p[ :4C-:C

 }
 !$3%3(0-:$0-:91'4"#%*,!$3J?E!E"#%! I 32:17#%-)W7-'Z!$3\3w0-:,$0-:96?!$3%7:9R,cd0#%K)#%?$:17.!}8;#%  :&
!$#%)*:&^<a$ !$g5jFAr$0-:9P'M#%*,!$3$ C74!$3$?!EM#%! I 32:9R B:8;:$NE0-:-${G:|&74!$3%P!$C18"0!$:3%3%#%-)
8;  M!$#%gH!E: (zbRwcPX0- A   "#%8;-:"9N(8;#%C:9k! `G?!EM#%! I 32:f'O:9"*67!E#2Y'4 I 32:* AB#20

}!$C

RQcd0#%j#% (z
I 71-$
*
(
1
/
3
4
KSB R
c ,0- A (z
SB N8;4#%C-:9D! EG?!EM#%! I 32:K'O:9"*k7-!E#2f' I 3%:*qAr#20
*
(
1

!$C

RVcB0#%D#% /z 
I 7V$BSB R -<a$M89#%-)SB i0:.8"0!$:3%3%#%-)
/
8;  M!$#%g1:C78;:
/  m0-:+#%)32:9 ZC-*,!$#\  RWo-$10-:]:9?$:9" :]C#2:8;#2^N 8;#\C-:91!
G?E!E"#%! I 32:6'O:9"*67!E#2}'4 I 32:* AB#20
+!$C
R6cd0#%
*
(
1 
/
3 
#%DSB
R'
I 7-D-$ /z 

_

,

@ Y @ YF@ YF@ Y >1K{`~{`

a_ , * .
>1K{`~{`
D@ Y >1K{`~{`~{Y
_@
"

-

aw'{

 

xb: I

,*

_


{



s} 

)

 {#w

e

@ YF@ YF@ Y :M{`"~{`&~{I,

m
_

,*

:

Vy %d1:070$,7
 _
+_

!

, * -/, *

@ Y @ Y @ Y

- qf

@ Y @ Y @ Y >1K{`

 {#}

_

@ Y @ Y r~{YM{`"

" 7-5@-:Q!$C :# :9:
l!$3%  0`A:C 0!E @SB #%l! '*+#%#%-)n_432 :9"#\-)Y :8M0#%|[7-:
! I `?$: I $0+SBbN V !$C /z KN$'"7#\-)b*+!$g5k?!$3\7-:<>$#2
#%*:$R (" :9(:9/!$3 R
:9'O$ :C]'*,#\#%-)K:;p@' :9M#%*:&!$34:"732(Ar#20 @SB f|&7!$"#2)$7-']' I 32:*+9Ng!k*673%#2'432:D'O:9 G
*k7-!E#2m' I 32:*iRDz & :9: #%)325$N !$rAB#20mSB
 !$C /z  AB0#%8M0}3%#%: I :9 A:9:
I 7-r743%#2L$:
SB !$C -SB MN 8M0!$-:3%3\#%-)i8;  M!$#%gk!E:f#2)0& :960!$n0-:]'"#%*,!$3/-${G:|&74!$3%68;4  "!$#%&
Ad -SBbR



u


c

 S

sx





_

g_

2_



fiVK37373>

!_

JQu9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]ff


	 ,* - 7 
	  - ! 	ff , * . 	ff Qs e c }0`A @SB - ! -SB , * N 8;#%C-:9.!l'O:9"*k7-!E#2X'4 I 32:* 0!E.#%9@SB - !$CQ!$g5
#%!$g#%!E#% <a$,!X'M#%*,!$3?!EM#%! I 32: @ B R @7-''O :f0!E0-:W'4"#%*,!$3-${G:|[7!$3%,*@C-:3V$<b0-:
	

fi 

!

	 ,* - ,* 7

 

 





:7432#%-)]' I 32:* 89!$-$ I :H*,!$C-:HSBbRffcd0-:x0-:9:H*674 K:;p@#%rFAW$0-:9j'4"#%*,!$3P?!E"#\! I 32:9N
!`5 H!$C
Ar0#%8"0X0!`?$:,!E.* j-:H$0-:9j?E!$3%7-:$RH#%C:9b0:HC47!$3J?!E"#\! I 32:6!$" [89#\!E :C
AB#20k0#\P?E!$3%7-:$Rwcd0-:H7C:9J04#%w#% !$&#%!E#26$<0:'4"#%*,!$3g?!E"#\! I 32:
N:-<>$"89#%-)KSBnH0-:
8"04!$-:3%3%#\-)]8; "!$#%& I :9FA:9:Z0-:H'"#%*,!$3 ?E!E"#%! I 32:
V!$CX0-:C74!$3 ?E!E"#%! I 32:$N^!$C I :9 A:9:
 !$C
0-:dC74!$3&?E!E"#%! I 32:!$4C
d:"732#%H!jC-*,!$#\6Ar#2'O:97- ,0-:dC7!$3[?E!E"#%! I 32:$R B:48;:d0-:
' I 32:* #%w-$ @SB Rcd0#%J#%!K8;& "!$C#%8;#2^RwcB0-:V'"#%*,!$3[-${G:|[7!$3%*@C-:3@89!$0-:9":9<a$: I :
*,!$C-:(SBQ<a3\32`AB#\-)V0-:/#%!$g#%!E#%K$<
RJcd0!E^#%N`0-:('4 I 32:* #% -SB
R c B0- AY  "#%8;:9N
8;#\C-:9B! G?E!E"#%! I 3%:.'O:9"*67!E#2W' I 32:* AB#20iC*,!$#%

,!$C
*
(
1
/

Rcd0#\D#% @SB
I 7V$ @SB R
3
c +0- A KSB
@SB N48;4#%C-:9d!'O:9"*k7-!E#2i' I 32:* 04!EB#% KSB RD#\C-:9d!$g5
#%!$g#%!E#%Y<>$!m'4"#%*,!$3?E!E"#%! I 32:$RxcB0#%k89!$ I :l8;#% :g325Q:;p@ :C-:C  X!$3%3?!EM#%! I 32:k#%
0-:i'4"#%*,!$3D*@C-:3 R 7,0#%,*,:!$,0!E]#2+89!$ I :i8;"#%  :&325 :;p[ :C:C  Y!$3%3d?!E"#\! I 32:
#%}0-:1'M#%*,!$3^!$CmC7!$3 *[C:3 N4!E#%<a5@#%-)+!$&5 =8;* I #%!E#%i$< d' :9M*67-!E#%i$K8"0!$:3%3%#%-)

@

@^

n

@ Y r~{Y

s"



-

`@

@B

`@0^

#)

B

e

 *
D@ Y @ Y @ , Y @ Y 83j{:1K{`

@ B

 *
!  , -

@B

-




#b U

I

fi 8-
	fiffff
8;  M!$#%gR/Srd0-:.8"0!$4-:3%3%#%)H8;4  "!$#%&d!E:1"!E#% _4! I 3%:$N[0:95f89!$ I :.*+!$C-:.SBbR 4#%C-:9
!$&5,#% !$&#%!E#2<>$!6C7!$3-?E!E"#%! I 32:$R 5,!6#%*,#%3\!E(!E)7*:&9Ng!EL@#%-)60-:B!E''"$'"#%!E :B#\ !$@G
#%!E#2X<>$j0-:,!$[89#%!E :CZ'"#%*,!$3 ?E!E"#%! I 32:$Nff0:k":732#%)]'" I 32:* 89!$ I :k*+!$C-:,SBbR r:8;:$N
)#2?$: !$&5 #\ !$&#%!E#2 <a$,!X'4"#%*,!$3$,C7!$3?E!E"#%! I 32:$N0:i8"0!$:3%3%#%-)x8;  "!$#\g89!$ I :
*,!$C-:HSBbROcd0!EK#%9N 0-:k' I 32:* #% @SB NffcPl0- A   "#%8;-:"9N 8;4#%C-:9K! `G?E!E"#%! I 32:6'O:9"*k7@G
!E#2Q'4 I 32:* AB#20

W!$C

Rfcd0#%
*
(
1
/
3
4
@SB
I 7-d#%D-$ jSB R

)

e

-



-





, * . @ 
 , *
tu   {#w  {}


>1K{`~{`

,

@ Y @ Y @ Y @ Y 83j{:1K{`

@ Y @ Y @ Y r~{YM{`"~{`&

@

a@

c ,0- A @SB
SB N8;#%C-:9D!k<>7-V?!E"#\! I 32:b' :9M*67-!E#%]'4 I 32:* #%fAB0#\8"0
*  
1
0 !`?$:0-: 

f!$C
4
0
$
!
K



0

:
C


,
*
$
!
%
#





+
R
d
c
4
0
%
#
K

%
#

@
B
S

7
K


$

.

B
S

6
R

o
$.0-:
I
/
:9?$:9":$N 8;#\C-:9j! EG?!E"#\! I 32:H'O:9"*67!E#2X' I 3%:*hAr#20

l!$C
*
(
1
/

RDcd0#%V#%BSB
R'
I 7-d-$ -SB

83j{`~{`

 



s  {

-

*
@ Y @ ,Y 83j{:1

83j{:1K{`~{`

9

@ Y @ Y



SbCC#%-)+'"#%*,!$3P$jC7!$3P${G:|&7!$3\b8;4  "!$#%&b l8M0!$-:3\3%#%-)+8;4  "!$#%&rC&:K-$K0-:32'XSB
$ @SBbR4cd0:1<>3%32`Ar#%-):7432B0- ABd04!EB0-:#2b!$CC#2#%iC-[:r-$b0-:32'}04#2)0-:9B32:9?$:3\B$<(32@89!$3
8;#\  :8;5l3%#2L$:.  )'4!E0@G 8;#\  :8;5 =SB  MR

9
u





sx

JQu9WM[OPb]HtMNu7N*Q*H7JWPYH>Z;v\[O]ff





,* - 7 	  - ! 	  ,* . 	 Qs e cPj0- A SB _ - ! SB _V , * Ng8;#%C:9J *,:d8"0!$:3%3%#%-)r8;  "!$#%&w0!E(!E:DSB _VbR
= `A SB - !USB , * NE rA:57  -:9:C1 K0- A2_V - ! _ , * R(#%C:9P!B8;"#%  :& '4!$#%^$<-?!$3\7-:9N
!$C ' <>$j!l'4!$#2b$</'M#%*,!$3 ?!E"#\! I 32:9N0@B!$C@ER6c !EL$:+!$&5}04#2"Cm'"#%*,!$3P?!EM#%! I 32:$N @^&R1Sb
. 	



_ 

	

fi 



, * -/, * 7 	

ff









ff







] ];U

@^ m_

a@0^

0-:i8; "!$#%& I :9FA:9:  N h!$4C
}#\ VbNA:i89!$ _4C !X?E!$3%7-:l<a$
}8;"#%  :&AB#20
0-:b8"0!$:3%3%#%-).8;4  "!$#%&9R V7-/ 0#\/!$3% 6!E#% _:/0-:r${G:|&7!$3\8; "!$#%& I :9 A:9:+'4"#%*,!$3
?E!E"#%! I 32:R r:8;:$N$0-:/'4 I 32:* #% V
Rwc b0`A   "#%8;-:"9N8;4#%C-:9w! EG?E!E"#%! I 3%:/'O:9"*k7-!E#2
' I 32:* AB#20

RDcd0#\D#%DSB 
I 7-d-$dSB V R
*
(
1
/

g)

e

_

@ Y @ Y @ Y @ Y
c j0-`A SB _ * -/* 7 SB _ * , ,
,
A:B-:9:CB57 (0`A 04!Eq_ * - 7 _
,

7

, *>1K{`~{`

-

_

,*
N$A:V:89!$3\3&04!EwSB
_

S

,* - 7

_

,* - 7

-

- Ee

SB V
SB
SB R r:8;:
V R/#%C:9(!j'O:9"*67!E#2' I 32:*WR -<>$"89#%-)
  0-:}8M0!$-:3\3%#%-)X8;  "!$#\g]!$32-:i#%-<>:9" I $0 0-:}'"#%*,!$3D!$4C 0-:}C74!$3D-${G:|&74!$3%
8;  M!$#%gR B:48;:$N 

V R

f
,* - 7 _ qe
fi_ , * - 7 _ , * - 7 _ c .0- A KSB
. SB _ * -/* N&8;#%C-:9!9& G?E!E"#%! I 3%:'O:9"*k7-!E#2k'" I 32:* AB#20@ * Y @ ( Y
@ 1 Y @ / Y >1K{`~{` N!$C @ 3 , YF, @ Y :M{`"~{`& Rmcd04#%.#%6SB _ , * - , * I 7-1-$	KSB RWo-$H0-:
:9?$:9":.C#2:8;#2^N@8;4#%C-:9D!+ G?E!E"#%! I 32:K'O:9"*k7-!E#2f' I 32:*TAB#20 @ Y @ Y @ Y >1K{`~{` N
_









4oq @ I @  9f



*

(

1 



!$Cx0-:H!$CC#2#%!$3 I #\!E5i8;  M !$#%g
'"74-:B0:kC-*+!$#%
*
1 MR /<a$"89#\-) KSB
 
N^!$C
R -<>$"89#%-)
*
1 
(  R r`A:9?$:9Nff0-: :HC-*,!$#\d!E:H-$KSB 
SB VT#2)0& :0-:i8; "!$#%& I :9F
A :9:
$
!


C
>
<




*


$

{


G

:
&
|

7
$
!
\
3
H



x$
*
1
*
1
E
R
*
1

@ Y @ Y >1K{`

_
@ a
Y ~{(@ Y 1

@ Y r Be

* . ,
@ Y @ Y r~ {YM{`"

_

@

@

!"

_ *-* f
@ Y , , K1 {(@ Y^

X@ YF@ Y

c m0`A SB 
SB N8;#%C:91!
G?E!E"#%! I %3 :,'O:9"*67!E#2Z'" I 32:* AB#%0
*
(

N&!$C

RcB0#%P#\JSB
7
J



$

J

B
S

V


R
o
$





0
V
:


9
:
$
?
9
:
"


D
:

C
%
#



:
;
8


2
#
ffN
I
1
/
3
8;#\C-:9J!E)!$#\60: EG?E!E"#%! I 32:/'O:9"*k7-!E#2k' I 32:* B
A #%0

Rcd0#%
*
(
1
/
#%DSB V
I 7-D-$rSB R'

@ Y >1K{`
_

,*

-

?c

_ *
_@ Y @ , Y @ Y @ Y >1K{`~{`

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



 




w

   sx




Qs  ,  x

tw  {



cd0-::j:732V:;p@ :C} +*67432#2'432:b'O:9"*k7-!E#2l' I 32:*,D7C:9V!+#%*'43%:r: "#%8;#2W04!Ed0-:
' I 32:* #%
u v
@ :9)#27
yZ!$3%"0ffN
MRxcd04!E6#%9Nw!$&5Z "#2'43%:$<D?!E"#\! I 32:
AB0#\8"0x!E:,!$3%3 G C# :9:&r*k7 K@89897-K $)$:90-:91#%X!Ej32:!$ K-:H'O:9"*k7-!E#2ffR.o$j:;p@!$*'32:$Nff0-:
0-:9:8;  "!$#%&P!$3\3 G C#
ff!E:/-$^ M#%!$-)32:
*
(
/ MNE!$3%3 G C4#
*
1
3 MNE!$C.!$3%32G C#
(
1
'::9?[#\-)d!$ * N ( !$C
E
!



:
$
!
%
3
2
3
G

C
#
O
9
:



:
g


7
P

E
!


V
:

$

J

%
#
j



0
V
:


$
!

*

:
;
8






"

$
!
%
#
&

9Rwcd0-:(<>3%32 AB#%-)
I
1
0-:9$:*h8;3%32:8;D $)$:90:9b!$Ci)$:-:9"!$3%# 9:B*,!$g5l$<J0-:.'":9?[#274V:732R

lN*PIQ KJ [WPY[OL4[4P rQTJ 

- @ ({ @ {(@ 

M@ :@

sx
u





	

, * -/, *
! 	 ,* - ,*
!  , * - , *

!  , * -/, *

! 	 , * -/, *
!  , * -/, *
. 	

fi 



	

fi 



	





!  , * -


 

!





Qs e

 















- ! 	

ff


	 - !

 





fi 





	 ,*

,* . 	 

. 	 . 
	 -

 





!	  , * - !

7 ff
	  ,* - 7 
	 7   ,* - 7   -



	



- @ {(@ {(@ 









fi 

g @ {(@ {(@ 



,* - 7 	



	 ,* - 7

7



	



7 	ff



 

fi 

1:07070$

JQul]Ht[vN*QkWv [SW [OPb]ktMNu7N*QVHKJW PdH>Z9v [4]ff





@

?





. 
- 
- .	



,*




,* . 	 ! 	 ,* !  !  ,*






ff









g

0-:V#%-)3%:/'O:9"*k7-!E#2H89!$ :$R ^@89!$3
 cd0:'"&$<=w3%#2<> #%k!r "!$#2)0& <a$AV!E"CH*,!$:9J<>*
8;#\  :89#2:]3%#2L$:iSB VbN @SBKN (z !$C
 8;#%C:9, "#2'43%:H$<j?!E"#\! I 32:9R zF<K0-: :x!E:
3%#%L$:Cl $)$:90-:9N A:k7 :j0-:.<=!$8;B04!EB0-:.'4 I 32:* #%d "#%!$-)32:1': :9?@#%-)!$C}!,'O:9"*k7-!E#2
#%0:9:9<a$":mC-:9_4:C `?$:9l0-:*WR z <b0: :m!E:x-$+3%#\-L$:C  $)$:90-:9NBA:x89!$ C-:8;*'O :m0-:
!E)7*,:g1#\g }SB Z'4!$#2MK$<?E!E"#%! I 32:9Ry #20-7-j "#\!$-)32:'::9?!E#%ffN KSB NJ*,!5X3%5
!$8"04#2:9?$:j!$0#%)0+!k32:9?$:34$< 8;#%  :48;5,!$SB
R(o$:;p-!$*'43%:$N[8;"#%C-:9!E)!$#\+0-:K-@G M#%!$-)32:
'::9?[#\-),8;  "!$#\gr#%W0-:13\!$ d'4!E"!E)$M!E'40ffRzF< *

!$C
(
1
/
3

l0-:Q0-:,'4 I 32:*
#% jSB N I 7-j#2.#\.-$
V
NP!$CZ0:8;:+-:#20:9 (z
N @SB
-$BSB 
R '

_

>1K{`~{`

w


_








 _

q_

, * M@ Y @ Y @ Y >1K{`
2 _ , *



,*



F

Rfi?7

@ Y @ Y @ %Y
9_

#

, * g

,*

Sb-$0-:9} 3\7-#2   "!E :9)$5 #%l  :48;[C-:Q'O:9"*k7-!E#2 '4 I 32:*,W#\g  @Sc !$4C 7 :Q! <=!$ 
K!?@#%{G 7-!$*
l$i32[89!$3j:!E"8"0 '@8;:C7-:$R o-$i:;p-!$*'432:$N : !E}!$C ~m!$g5!
:9'O$'"*,#%#%)r:"732w<>$/'$'O#%#2!$3[:8;@C#%-)w$<O74CH I #%H'" I 32:*,9N$Ar0#%8"0#\893%7C-:
'O:9"*k7-!E#2i8; "!$#%&9RVyQ:68;#\C-:9B0-:9: 7 C#2:8; ,:8;[C4#%-)d#%&  -Sc !$d0: :60!`?$:
MR(Sb1!$32 :9"4!E#2?$:/!$C1'*,#%"#%-)V:8;@C#%-)
I :9:17:C.* J8;*,*325j#%.0-:('4!$  >yZ!$3%0ffN
$<d /j#\g  @Sc #\K0-: 7-''O$K:8;@C#%-) @R d:8;:&325$N b:g
j0!$."0-`ABX04!E.7#2
'$'!E)!E#26#\j0-:"7-''O$ff:8;@C#%-)r#%^:|[7#2?E!$32:&^ r:<a$"89#\-)B!E"8 G 8;"#%  :8;5.#%10-:/$M#2)#%!$3
 JNJ!$CY04#%689!$ I :]!$8M0#2:9?$:C #% !$ 5@*' $#%89!$3%3%5Q$'#%*,!$3/#%*:$RXcPX8;*'4!E:f0-:l7-''O$
:8;@C#%-).$<D0-:+C# O:9:&1*@C-:3%j$<d!i' :9M*67-!E#%Z' I 32:*WN^A:]#\*'4325x-:9:CZ0-:9":9<a$:] 
32[$L]!ED7-D":732W!E"8 G 8;"#%  :8;5$R(y #20l0-:jC#%:8;V:8;[C4#%-)-N-7#2'$'4!E)!E#%W:-<>$"8;:
!j32:9?$:3-$< 32@89!$3-8;#%  :48;5k32:"w0!$,!E"8 G 8;"#%  :8;5$Rz{C-:9:CffN$0:d32:9?$:3@$< 8;4#%  :8;5H#%w$<> :
#%C-:&#%89!$3O ,04!EB!$8"0#%:9?$:C I 5f0:j<a$AV!E"Ci8M0-:8L@#%-)]!$32)$$"#20*iR

x

}_

Sj_

Sj_

*x_

) 5

XN

X



5

N

$K37373>

;P 



!

P

VK37373>



,

cVK373$$

fi 8-
	fiffff
SM_


|

aB

)


z{+0:rC#2":8;/:8;@C#%-)1$<^!H n#%&  -ScjN&A:r04!?$:j! [32:!$f?!E"#\! I 32:
rAB0#%8M0+#% 
# i0-:r'"#%*+!$3-?!EM#%! I 32: ^!EL$:0-:b?!$3%7: -Rz{]0-:B'M#%*,!$3 @Sc *@C-:3 N&0-:9:K!E: x893%!$7 : 
1 B893\!$7 :b l:7-:60!Ej-
:7:10!EK:!$8M0Q'"#%*+!$3^?E!E"#%! I 32:6!EL$:j!Ej32:!$ K-:k?!$3%7:$N
1 r893%!$7:r l:"7-:k0!Ej-]FAW'4"#%*,!$3P?!E"#\! I 32:
'"#\*,!$3^?E!E"#%! I 3%:1)$:9jFAW?E!$3%7-:9NO!$C
!EL$:x0-:}!$*:}?!$3%7:$R z{g :9:#%-)325 0-:}8M0!$-:3%3\#%-) @Sc *@C-:3d04!$,0-:}"!$*:}[7* I :9,$<
  i:9'4: :& I $0X0-: 0
&3%:!$Q?!EM#%! I 32:K!$j0-:H'M#%*,!$3 @Sc *@C-:3 =!$jA:,89!$Z7 :
?E!$3%7-:x$<10-:x'"#%*+!$3B?E!E"#%! I 3%:
lu sx0-: 0 ?E!$3%7-:x<>$f0:XC47!$3B?E!E"#%! I 32:  MNK!$C 7 
1 d893%!$7 :B ]:47-:
!$CC#%#2!$3^893%!$74 :d f:7-":.:!$8"0XC7!$3^?!E"#\! I 32:.!EL$:K!,?E!$3%7-:$RdcB0-	
: 
0!E(-.C47!$3@?!EM#%! I 32:)$:9(FA6?!$3%7:!E:D:|&74#2?!$3%:gw .0-:d893\!$7 :0!E:47-:D-jFA.'4"#%*,!$3
?E!E"#%! I 32:)$:9V0-:K!$*:b?!$3%7:$RwcB0-:r<>3%32 AB#%-)1:7320- A 0!EV~mSB #%#2)0& :904!$
JN-!$C
#\V:|&7#%?!$32:&D ]oJ W0-::1C# O:9:&d*[C:3%9Rz{WAB0!ED<>3%32 AB9N-A:1!$7*,:.0!Ed0-:6o 
!$32)$$"#%0*q74 :!6<=!$#%3_M 0-:7"#% #%8V04!E#%4 !$g#\!E :?E!E"#%! I 32:(AB#%0+#%)32:B?E!$3%7-:32:9<aV#%+0-:#2
C-*,!$#\ I :9<a$:j?E!E"#%! I 32:VAB#20W!,8M0-#%8;:.$<w?E!$3%7-: b!E"!$3%#%8"L
/3%3\#2$9N
MR

@B



+Ro 

)

-

@B KJ

x_





'z

  s  x 7
	

fi ff

!

cx_

6?
f

	 , * -/, * 7

!ff
  , * - , *

! $  , * -/, *


	

	

fi ff

	

fi ff

	

Qs e

x_

1:07.K3>

JXu9WM[4PI]HtMNu7N*QVHKJWPYH>Z9v [4]



	

9|
5 co

] r



u

	

( B

+Ro 

9*e



sRo 

o

,* 7

,*

	 , * - 7

	

7fi
  , * 
7 $  ,* 

	

	 - !

7ff
  
7 $ 

	

	 , *

!fi
  , *

! $  ,*


1O 

,* !

MK37373>

,*

o 
#%!6 'O:89#%!$389!$ :b$<Pcd0-:9$:*
>yZ!$3%0ffN
MN-AB0#%3\ /~}SB
o 

#%D!,' :89#\!$3ff89!$ :1$<wcd0-:9$:*
[R
c +0- A
o 
7-''O :K7#2V'"$'4!E)!E#2i :9B!3%#2 :9"!$3  R(cd0-:9":.!E:j<a7d89!$ :9R/z{
0-:K_"V89!$:$N!893%!$7 :b$< 0:b<>$"*
#+04!$ I :9:f:C478;:Cf ,!$W7#29Rcd0!ED#%N&A:
* """ 
0!`?$:1-:.?E!$3%7-:632:9<aB<a$B!+'"#%*+!$3O?!E"#\! I 32:$R/cd0:j<>!$#%3^_" d0-:7"#% #%8K#%}o  '4#\8L@d0#%B3%!$ D?E!$3%7-:
  
 X#% !$&#%!E :$RWz{Z0-:f :8;CY89!$:$N(!}893%!$7:+$<D0-:]<a$"*
f<a$
 Z04!$ I :9:
:C748;:CH 1!$,7#%9RJcd04#%J:7-:w04!E/-j'"#\*,!$3[?!E"#\! I 32:V)$:9(FA.?E!$3%7-:RwcB0-:Do  !$32)$$M#20*
 "#2?@#%!$3%3%5.-:9?$:9 "#2:wFA1"#%*67432!$-:97J?E!$3%7-:w<>$(!K'"#%*,!$3&?E!E"#%! I 32:$RJz{60:D0#2"Ck89!$ :$N&!j893\!$7 :
$<w0-:.<>$"
* 
  
 W04!$ I :9:W:C78;:C} +!$}74#29R/cd04#%V:7-":D0!EB-]C7!$3
 <>$
?E!E"#%! I 32:])$:9k Ax?E!$3%7-:RxSr)!$#%ffNw0-:lo q!$32)$$"#204*  "#%?[#%!$3\325x:9?$:9k M#2:1FAQ#\*673%!$-:97
#  04!$ I :9:l:C78;:Cl +!$}7#29R
?E!$3%7-:V<>$B!,C7!$3 ?E!E"#%! I 3%:$Rz l0-:j<>7-0W89!$:$N
*   """ 
cd0!E6#%9NPA:+0!`?$:]:,?!$3\7-:+32:9<>j<a$k!}C74!$3w?!E"#\! I 32:$R]ST<=!$#%3_M .0-:7-"#\ #%8H#%Zo  '4#%8"L[.0#%
3%!$ ?E!$3%7-:l Z#%4 !$g#\!E :$R r:8;:$NV)#2?$: !Z"7#2! I 32: I "!$48"0#%)x0-:7"#% #%8EN/0-:io  !$32)$$M#20*
 "!$8"L[b0-:
!$32)$$M#20*WRdc ]0`A 0-:1:9?$:9M :$Nff7-''O :j<>$AV!E"Cm8M0-:8L@#%-)f:* ?$:K!,?E!$3%7-:$R
cd0-:9":b!E:KFA,89!$ :R(z f0-:K_M 89!$:$N-0-:K?!$3%7: (#%:* ?$:CW<>* !kC47!$34?E!E"#%! I 32: KC7-:b 
 *:.8M0!$-:3\3%#%-)k8;  "!$#%&9R/cd04#%V*:!$V0!ED0-:9":.#%D!k'"#%*,!$3 ?E!E"#%! I 3%: .AB0#\8"0l0!$ I :9:
 :9K W *:k?!$3\7-:   R
4#2B'"$'4!E)!E#2x
 
     :9   l<=!$3% :$Nff!$Cm0-:x
      :9   H<>!$3\ :b!$:|[7#2":CffR z{]0-:b:8;Cl89!$ :$N-0-:b?!$3%7: #%:*`?$:Cl<>* !
C7!$3P?!EM#%! I 32: $NO!E)!$#%XC7-:6 W!]8M0!$-:3%3\#%-)+8; "!$#%&9Rbcd0:1'[$<(#%b-`A C74!$3^ l0-:k_" 
89!$ :$R
c Z0- A ~}SB
N(A:i74 :l0-:l<>!$8;,04!E~mSB C-*+#%!E :o  !$4C oJ
R
c +0- A   "#\8;-:9N48;4#%C-:9d! G?!E"#\! I 32:j'O:9"*k7-!E#2W'" I 32:* AB#20}!$CC#2#24!$3 I #%!E5f8;@G
  "!$#\gl0!E}"732:x7-W0-:Z!$*,:Q?!$3%7:x<>$}!$3%3
'4"#%*,!$3r?!EM#%! I 32:9R /<a$"89#\-) SB  0-:

ax_ - 7

-

^1:"

aB

aB

 B

'aB

+^

Sz Y G



+^

]



e

mxB_

 B

 B ^ | Y G

z

 B

+^

Y |

- ! x_ -

c

+^

+^

%@0^

]

z

- 7 x_ -

9

 !

f

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



8"04!$-:3%3%#\-),8;  "!$#\gb89!$7 :K!fC-*,!$#%}AB#2'O:97-dm0-:6C47!$3^?E!E"#%! I 3%:1!$ @89#%!E :CxAB#20}0#%
?E!$3%7-:$R(Sbd0-:9:.!E":1-,7#%V893\!$7 :9N
C-&:B-$B#%*,*,:C#%!E :325+32?$:.0-:.'4 I 32:*WR

x_ - ! x_

x_

,*

+

c ]0`A
NA:6$ :.0!EB0:18"0!$4-:3%3%#%) -Sc *@C-:3^8;&!$#%r*$:1893%!$74 :9R
r:8;:$N(#26C*,#%!E :10-:]'4"#%*,!$3 -Scq*@C-:3 Ric m"0-`A   "#%8;:9N8;#%C:96!m<a7-6?!EM#%! I 32:
'O:9"*k7-!E#2m' I 32:*hAB#20m0-:9:H!$CC#%#2!$3 I #%!E5W8;  M!$#%gK04!Eb#2< *
k0-:
[N
(
f
$
!


C
f
E
!



:
$
!
%
3
3
"


7
%
3

:
i
C


7
9

6
R




4



%
#
C
9
:

"

$
!


M
8

0
%
#

]
)



E
R


%
#
r


'
"

$

4
'
E
!

)
E
!


2
#


x




I
1
/
*
I $0}*@C-:3%B :9
* ( N
(( N
1( N
/5( N
(!* N
1!* !$C
/*  +<=!$3% :$R Ki0:68"04!$-:3%3%#\-) @Sc
*@C-:3 N@7#2'$'4!E)!E#%f!E)!$#\ 0-:j893%!$7 :
* ( 
(( 
1( 
/5( 0-:f)$:-:9M!E :D!$l:*' 5
893%!$7:$R 5f8;*'!E"#% ffN74#2V'$'4!E)!E#%Wi0-:j'4"#%*,!$3 @Sc *,[C-:3ffC&:r-,*$:jA$L R'

e

@ Y


@ Y 



n











q)

0Q_$e    = Qg 

 
 -=







@ Y 1

@ Y 1



v





@ Y 
s



cd0-:1':9?@#27D:"732D :3%3 7d-$04#%-)+! I 7-d0:.:3%!E#2?$:k8; B$<(!$8M0#2:9?@#%-),0: :632@89!$3^8;"#%{G
/
 :89#2:RmSb 5[*,' $#%8+!$4!$325["#%1!$CC46C-:9!$#\3( x0-:]":7329RWyQ:W89!$ !$8"0#%:9?$: jSB
#% 
#%*: :9 )#%^N
MRnSB  I #%!E"5Z8;  "!$#%&H89!$ I :]!$8"04#2:9?$:C #%   ( .AB0-:9: l#%k0-:
( 8"04!$-:3%3%#\-)Q8;@G
[7* I :9,$<.8;4  "!$#%&+!$C
#%,0-:#%+C-*,!$#% # 9:$R Sb,0-:9:x!E: 
/
  "!$#\g9N(SB
!$#%?$:325Z!EL$: 
.#%*:$R r`A:9?$:9N I 5Z!EL@#%-)X!$C-?E!$g!E)$:}$<d0-:l<>748;#2!$3
1 j7#\-)W0-:]SBG }!$32)$$M#20*
!E7-":,$<d8"0!$4-:3%3%#%)i8;  "!$#%&9NJA:f89!$Y":C78;:,0#\.  
/ J#%*:d!$/0-:9:B!E: 
(
r:g :-"5[8"LN b:9?[#\3%32:$N
c :-)-N
MRSB
!$3% .4!$#2?$:325k!EL$: 
I #%4!E5}-${G:|[7!$3%.8;4  "!$#%&9R B A:9?$:9`N A:,89!$Q!EL$:+!$C-?E!$&!E)$:+$<0-:, 'O:89#%!$3w!E7-:$<V!
( !$V:!$8M0}-${G:|[7!$3%D8; "!$#%&V:9:CV 
I #%4!E5,-${G:|[7!$3%d8; "!$#%& ":C78;:K0#%  
7r8;:$R6yQ:,0!?$:'4`?$:CX0!E jSB
SB
SB
!$CX)$:!E :9.'4"7#%)
I :k*+!$C-:SB
/ MN 
1 MN 
( : 'O:8;#2?$:3%5 MRcd0[7
'O`A:9/#%w: 4:8; :C+#%0#%)0-:9wA$"/89!$ :B8;*'32:;p@#% 5 
A:6 #%3\3^-:9:Cm +"7}:;p['O:9"#\*:gB ] :9:H#2<w0-:k!$CC#2#24!$3ff'"74#%-)H7- A:#2)0r0-:6' $ :&#%!$3%3%5
0#2)0:9d8; 9R



6

1:0706

]

-

*e

e

1:0707$
/e

,*

?

Mx

=S

sRo 

	OLP Q R$g = R

w




sRo 
sRo 

+Ro 

*

5

?   =0QTg 

 

+Ro 

+ ] 
sRo 

- !

!

"

*

 +Ro  sRo  +Ro , 

+Ro 

M



yQ:f"!$Y!WAr#%C-:?E!E"#2:9 5Q$<D:;p@'O:9"#%*:&j m:;p['43%$:,0-:f#2)#2_89!$8;:$<D0-: :]0-:9$:9#%89!$3!$C
!$ 5@*' $#%8mC# O:9:8;:9R o-$l:;p@!$*'32:$ND:9?$: 0-7-)0 I #%!E5 -${G:|[7!$3%f8;  "!$#\glC- 32:
'"74#%-) 0!$ 0:Y8"0!$4-:3%3%#%) 8;4  "!$#%&9N.0-:95 *,#%)0g}#%3%3j 'O:9:C 7-'  :!E"8"0 I 5 '4"7#%)
|[7#%8L$:9`RYyQ:}3%#\*,#210:W_" H :9$<B:;p@'O:9"#%*:&H Z!X !E#%8l?E!E"#%! I 3%:f!$C ?E!$3%7-:l$"C:9"#%-)X!$
A:BAB#%"0H 68;-_M* 0-:d0-:9$":9#%89!$3:"7329Ng!$4C,0-: :r!E:r3%#\*,#2 :Ck:#20-:9 6 !E#%8d$"C-:9"#%)$
 6!1:  "#\8; :C]893%!$"($<^C-5@!$*,#%8V?E!E"#%! I 32:B!$C+?!$3%7:d$"C-:9"#\-)(#%Ar0#%8"0+A:b*,!EL$: {:|&7#%?!$32:&
MR
I "!$48"0#%)HC:89#%#2D#\l0-:.C# O:9:&d :!E"8"0} :9: V!$898M0&7r:9B!$3 R2N





*)

N

K373$$

P

Sbb:;p['43\!$#%-:C I :9<>$:$N *+!$g5}8;4  "!$#%&B [32L@#2r"7-''O$B8M0!$-:3%3\#%-)AB#20m:9e+89#2:&b)32 I !$3
8;  M!$#%gRJo-$J:;p-!$*'432:$Nz
@32?$:9J04!$^0-: ff
fi  ffD8; "!$#%&9NE!$4C.0-: @#%89 7^_4#2 :
C-*,!$#\m8; "!$#%&r3%# I "!E5W0!$r0-:  ffff]'4:C#%89!E :$R $0m'O:9<>$"*h!]32:9?$:3J$<('4"7#%)
AB0#\8"0 !E''O:!E"+  I :i:|[7#2?E!$32:&, Y:-<>$"89#%)YSB  0-:}:;p@'43%#\89#28"0!$:3%3%#%-)Z8;4  "!$#%&9R
yQ:j0-:9:9<>$:.8;*'!E:Cl0#%V#%]7-D:;p@' :9M#%*:& SB l0: I #%!E5,-${G:|[7!$3%D8;4  "!$#%&
!$C KSB x0-:!$3%3 G C4# :9":gb8;  "!$#%&9R1Sb3%3 0-:k*,[C-:3\r!E:#%*,'432:*:& :Cm#\ @32?$:9 [R @N
!$C !E:X!?E!$#%3%! I 3%:m?@#%! 
# I R yQ:X3%:;p@#%8;$)$M!E'40#%89!$3%3%5 $MC-:9l0-:X?!E"#\! I 32:+!$4C !$"#2) 0-:
?E!$3%7-:1#\Z&74*:9"#%89!$3$MC-:9RlyQ:]0:9:9<a$":+325 I M!$8"0YZ'"#\*,!$3?E!E"#%! I 32:RfSb.A:+ I :9?$:
?$:95 "#%*,#%3%!E":732+ !Y"!$-)$:x$<j'O:9"*67!E#2 '4 I 32:*,NA:}4325 0- A 0-:9":}:7432,<>$
P!$)$<a$"C D' I 3%:*WR

Ev2 





)




Sj_q





4

9" kK373

fi 8-
	fiffff

*@C-:3

Y

Y



Y







Y Y
Y
Y










E< =

cJ! I 32:

0-:7-"#%#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8



I

<=!$#%3%

nV[Nk0$

<>!$#\3%

3@Ri373$

>
.7
> 
> 



aT 

7"

aT 



aT 
aT 




3@Ri373$"




3@Ri373$
3@Ri373$"
3@Ri373$"
3@Ri373>,
3@Ri373$






nV[N\143>

 :8ER

 :8ER



eW 
3@Ri373$"
3@Ri3M171
3@Ri3M1:
3@Ri3M171
3@Ri373$0
3@Ri373$0
3@Ri3M1:"
3@Ri3M171
3@Ri3M1:
3@Ri373$0



>





7* I :9V$< I !$8L[ "!$8L@ ><=!$#%3% /!$Cf"74#%-).#\*:r _C+0:r_M 3%7-#2f H A,#%@G
  !$48;: $< !$-)$<>$"C  ' I 32:*iR B7&#%*: !E:<a$ z
@32?$:9 [R bk!
~
$N
J:&#%7* zz"z/'@8;: $`N!$C
+~
$< BSK~ZR



_

*[C:3

Y

Y

0-:7-"#%#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8



Y







Y Y
Y
Y










T< =

cJ! I 32:



V[Nk0$



ff




ff

<=!$#%3%

77.7





<=!$#%3%

ff

ff

ff



3@Rk7.
3@Rk"70
3@R  1
3@R  1
3@Rk7
3@Rk7
3@Rk"7
3@R >
3@Rk&7&
3@Rk70

m

V[N\1718

 :8ER

<>!$#\3%

1ER >"
[R\1:"
[Rk7&
[Rk7"
1 Rw,K
E
1 Rw,K&
E
[Rkj1
 Rk7.
[
 R >0
[
 Ri3$0
[

7" &776
1:&$,K&76
"7&776
"7&776

  2     

e 

ff

Ev2#

F

nV[N\143>

:8ER

77.7
&K3$&7
77.7
77.7



X"j1: !)

71 1:77&
70K3M1:.
171:77&
171:77&

 


 


171:77&

 


 


 


I

ff

:8ER

 

, R 1
&
K3@Rk"70
17E1 Rk0j1
17E1 Rk06
. Rk&j1
[
. Rw,7,
[
1:[. Rkj1
1:[ Rk7
1:[ Rk07
14@3 Rk"7&

 
 

"7&776

 
 
 

1:K373 !eK

E" kK373

nV[N\1:$

 ff
<>!$#%3\

j1:7077&
06>07.$,K.
j1:7077&
j1:7077&

 ff
 ff

j1:7077&

 ff
 ff
 ff

 :8ER

  

ff

 1ERk.70
1:j1ERi3K
,K[ Rk.7"
,K[ Rk
"K@3 Rk"7
"jE1 R  1
171O- R 7
,K[& Rw,7,
,K[. Rk07"
&7[ R >0

7 * I :9D$< I !$8"L& M!$8L@ ><=!$#%3% !$Ci"7#\-)1#%*,:j ,_4CW!$3%3ff3%7-#2N[$B'`?$:10!E

0-:9":6!E:k-+ 3%7#29N ]<a7r#%!$8;:d$< !$-)$<a$MC d'" I 32:*WR B7&#%*:B!E:1<>$
z
[32?$:9 [R ]
~
$N J:g#%74* zzz'@8;: $N!$C
,~
$< rSb~YR

d v2 

-

" kK373 1:K373 !eK @_

 )





!"j1: X)



fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff





z{ cJ! I 32: [NdA:X8;*'4!E":m0-:m?!EM#27+*,[C-:3\,$<.!n' :9M*67-!E#% AB0-: _4C#\-)Q0-:x_" 
 3%7#2Q iFAx#% !$8;:1$< P!$-)$<>$"C 1' I 32:*iRz nc ! I 3%: -N A:]8;*'!E:,0-:+"!$*:+*@C@G
:3%jAr0-:X_4C#\-)f!$3\3( 3%7-#%K$.' ?[#\-)W0!E.0-:9":,!E:+-i 3\7-#29NP<a$.<>7-1#\ !$8;:j$<
P!$)$<a$"C d' I 32:*WR K325
[N r!$C
[N r#%}0#%D! I 3%:60!`?$:k!$&5i 3%7-#%9RDcd0-:.:;p@'O:9 G
#%*:&!$3:73268;-_"* 7-k0-:9$:9#%89!$3_4C4#%-)9RWow#2" 9NJ:-<>$"89#%-) KSB n!$ !$3%3 G C4# :9":g
8;  M!$#%gC-[:/0-:K* '"74#%-)-N$AB04#%3% :-<>$"89#%)6SB ]0: I #%4!E5-${G:|&74!$3%8;4  "!$#%&
C-[:.0-:]32:!$ 9Nw!$CQ:-<>$"89#%-)iSB Z0-:]8"0!$:3%3%#%-)W8; "!$#%&1#%.#\ I :9 A:9:ffR r7&#%*:
!E:,#\*,#%3%!E"3%5f$MC-:9:CffR @:8;CffNP!$CC4#%-)+0:'"#%*,!$3 $.C7!$3 I #\!E5}-${G:|[7!$3%j8;4  "!$#%&K 
0-:.8M0!$-:3%3\#%-)68;4  "!$#%&DC-[:D-$ I "#%)k!$&5f*,$:K'"7#\-)-N&!$CW*,:9:325]!$C4CV`?$:9"0:!$CW 
0-:k"7&#%*:$Rbcd0#2"C^N4!$CC#%)+:;p@ "!]8;4  "!$#%&b f0:6'M#%*,!$3^$jC74!$3P!$3%3 G C4# :9":gb8;  "!$#%&
!$8"04#2:9?$:j0-:,!$*,:H!$*,7gj$<'"74#%-)+!$j0:H!$3\3 G C# O:9:&b8; "!$#%&bQ#%K`ABffN^!$4CQ!E)!$#%
7 d!$CCV ?$:9"0-:!$Cm ,0-:.M7g#\*:$R







v



nV k0$

/

!nV \143>

5





m





5



w


g?R

  @=

7



?  R

 

R

g $g 

D

cd0-:6:;p['O:9"#\*:g!$3P:73%B#%}0-:63%!$r :8;#2X*,#%)0gb :9:*  l0!`?$:H:9 32:C}0:6*,!E  :9j$<(0- A
 +*@C-:3O'O:9"*k7-!E#2l'" I 32:*,9R -<a$M89#%-) KSB }!,#%-)3%:K!$3\3 G C# O:9:&V8;4  "!$#%&d!$32AV!5@
)!?$:]0-:+*+!$3%32: j :!E"8M0Q :9:6!$CX"7&#%*:9R r`A:9?$:9NJ0#%j#2)-$":.!W#2)#%_489!$gK'O$ :&#%!$3
!$C-?E!$g!E)$:b$<ff8"0!$4-:3%3%#%)K#\g 1!1C7!$3*@C-:3 R b5[4!$*,#%8D?E!E"#%! I 3%:V!$4C,?E!$3%7-:D$"C-:9M#%-).0-:7-M#% #%89
*,!`5 I :f! I 3%:+ x:;p['43%#210-:f'"#\*,!$3/!$C C7!$3?@#2:9Ad'O#%&j$<B!x'O:9"*67!E#2Y X*,!EL$: I :9  :9
C-:89#%"#29R cd0#\,#%+$]!Z $'#%8i0!El89!$ I :}:!$#%325 !$CC-": :C 0:9$:9#%89!$3%325$R B A:9?$:9Nr0-:
:;p@' :9M#%*:&!$3P:"732r)#2?$:X#%}04#%r:8;#2Q0- A 04!Eb?E!E"#%! I 32:6!$Cm?E!$3%7-:k$"C-:9"#%)]0-:7-M#% #%89
89!$i'4$_V)$:!E325l<>* *k732#2'43%:r?@#2:9Ad'O#%&9R
S ?E!E"#%! I 32:j$MC-:9"#%-),0:7-"#% #\8b3\#2L$:.*,!$3%3%: BC-*,!$#\i#%d7"7!$3%325 7 #%_:Ci#%l :9"*+d$<(!<=!$#%3 G
_"'"#%89#%'432: ffA:B0!?$:b .'4#\8Lk:9?$:g7!$3\325!$3%3-0-:d?E!E"#%! I 32:9Ng 6#2(#%AB#\ :D 18"0& :r-:d0!E#%
0!E"C] !$#2)^N&)#2?@#%-)H70-$'O:9<>743%325H*678M0W8;  "!$#\g'$'4!E)!E#%f!$4Cf!k*,!$3\3 :!EM8"0l :9:$R/S
?E!$3%7-:1$MC-:9"#%-)]0-:7-"#%#%8j3%#2L$:1*+!p@#%*k7* '*,#%: b:9:32:ffN
r#%r77!$3%3%5 7 #2_4:Ci#%i :9M*,
$< !"7898;:9:C@G_"'4"#%89#2'32: ^A:j'4#%8L]!H?!$3%7:b3%#%L$:325, 32:!$Cl ,!H 3%7-#%ffN[:C789#%)10-:K"#%L
$< I !$8"L& M!$8L@#%-)!$C] 5[#\-)1-:b$<^0-:K!$32 :9"4!E#2?$:K?!$3%7:9Rwz f!1'O:9"*k7-!E#2]' I 32:*WNgA:j89!$
I "!$48"0QQ0:,'"#%*+!$3w$.0-:+C74!$3w?!E"#\! I 32:K$1 I $0^R,yQ:]04!$3%30- A 0-:9:0!E6<>!$#\3 G_" 
Q-:?@#2:9Ad'O#%&K#%j8;*'4!E# I 32:AB#20X7898;:9:C-G_" jQ0:,C7!$3 Rc iC-i -N^A:+8;#\C-:9j0-:
<>3%32`Ar#%-)0-:7-"#\ #%899R

I

gf

Ex



/e

e

5

<

l

<

 


g1:0707$

95

	 ff
  	fi 
  <

d8M0-&:k0:6'M#%*,!$3ff$K0-:HC7!$3 ?!EM#%! I 32:.Ar#20}0:k*+!$3%32: 

 xtvw{ 
C*,!$#%ffN!$C}8"0-[ :.0-:j?E!$3%7-:B#%W&74*:9"#%8b$"C-:9`R

axt2'

 


Qsffw'xt2x

	 
   <

w8"0-[ :d0-:D'4"#%*,!$3&?!EM#%! I 32:VAB#20H0:d*,!$3%32:wC*,!$#%ffN
t2' 
 x t2w'{ 
!$4Ci8"0-[ :.0:.?!$3\7-:d#%W[7*:9"#\8r$MC-:9R









 


 ff
  
 <

8M0-&:d0-:BC74!$3@?!E"#\! I 32:DAB#20H0:B*,!$3%3%: (C-*,!$#%^Ng!$C

 x t2w'{ 
8M0-[ :10-:j?E!$3%7-:B#%W&74*:9"#%8b$"C-:9`R



t2)xtv



  


 x



t2'

	 
 (  	fi 
 <8"0-[ :B0:r'M#%*,!$3C74!$3@?!E"#\! I

32:DAB#20+0-:r"*,!$3%3 G
:(C-*,!$#%ffN$!$C8M0-[ :D0-:V?!$3\7-:Ar0- :DC7!$3 '4"#%*,!$3g?!E"#\! I 32:V0!$w0-:D*,!$3%3%: JC*,!$#%ffR

,

Qsffw'xt2 


x

t2'



t2w'{ 

  


 
 (   <D8M0-&:60-:6'"#%*+!$3O?!E"#\! I

32:.AB#%0W0-:6"*,!$3%3 G
:BC-*,!$#%^N!$CW8"0-[ :60-:j?!$3\7-:jAB0- :.C47!$3O?!EM#%! I 32:.0!$d0-:.*,!$3%3%: dC-*,!$#%^R


l

x

 x

t2w'{ 

:

fi 8-
	fiffff







$


t2

 


	 ff
 .
  <

(
8"0-[ :Q0-:QC7!$3r?E!E"#%! I 32:xAB#20 0-:Q*+!$3%32: 
x t2' D
  ,
 xt2w'{ )
C*,!$#%ffN!$C}8"0-[ :.0-:j?E!$3%7-:jAr0- :.'M#%*,!$3 ?!EM#%! I 32:j0!$D0:.*,!$3%32:dC-*,!$#%ffR

c 0:k*+!$3%32: bC-*,!$#%x0-:7-"#\ #%8.x0-:HC7!$3J0!$ I :9:X7 :Cx!$j!+?E!$3%7-:k$"C-:9"#\-)]0-:7"#% #%8
d
#%f!6[7* I :9$< :;p['O:9"#%*,:g!$3  7C#%: $7"C!$ffN
V0-:)6:9D!$3 R2N
@*,#%0ffN
MRcd0-:
<>3%32`Ar#%-)]!E")7*:&b0`ABb0!EK0-:HC-7 I 3%:6*,!$3\32: rC*,!$#%x0-:7-"#%#%89B!E:8;*'!E# I 32:6AB#20
0-:b<>!$#\34_M /'M#%89#2'43%:<>$V?!EM#%! I 32:r$"C-:9"#%)1!$Cf7898;:9:Cl_"/<>$?E!$3%7-:b$"C-:9"#\-)-R -7-''O :dA:
!$#%)W0-:.'M#%*,!$3 ?!$3\7-: , +0-:.'"#\*,!$3 ?!E"#\! I 32:
=!$}!$4!$32$)$7B!E")7*:&B89!$ I :K)#2?$:}#%<
A: I "!$48"0mm!]C7!$3ff?E!E"#%! I 3%: MRr  "!$#\gd'4$'4!E)!E#2mAB#%3%3O'4"7-:.0:1'"#\*,!$3ff?E!$3%7-: ]<>*
0-:k$0-:9K'"#%*+!$3ff?!EM#%! I 32:9N !$Cx0-:6C47!$3P?E!$3%7-: V<a*h0-:k$0-:9jC7!$3P?!E"#\! I 32:9Rj  "!$#\g
'$'!E)!E#2 *,!`5 CY*$:W0!$ 0#%,#2<rA:m0!?$:x!$ !$3%3 G C# :9:&8;  "!$#\g,$]8"0!$:3%3%#%-)
8;  M!$#%gR r`A:9?$:9NV Z!m_4" !E''`p@#\*,!E#2ffN0#\k#\!m":!$ ! I 32:W !E"#%-)X'O#%g9Rncd0-:
7898;:9:C _M ,?E!$3%7-:}$MC-:9"#%-)n0-:7-"#%#%8i8;*'47 :+0-: {'*+#% : Z$<j0:xC# :9:&,?E!$3%7-: I 5
*k732#2'43%5[#%)6 $)$:90-:9j0:6C-*,!$#\}# 9:r$<0-:k7#%!$g#%!E :Ci?!E"#\! I 32: K:9:32:ffN
MRbSbg5
 :9"* #%i04#%d'"[C748;B#%B748"0!$)$:Cm#2< f$ NOC-:9'O:C#%-)mAB0-:90:9B0#%r#%b!,'"#\*,!$3ff$KC7!$3
?E!E"#%! I 32:$N-C-[:d-$D@89897-B#\]0:.C-*,!$#%W!$C}#%V:C78;:C I 5 j#2< ,$ (@89897-"9R/cB0-:K'@C78;D#%
3%#2L$:3%51  I :B*+!p@#%*+# 9:C I 5H:"7-"#%-)KA:d:C748;:B!$(<>:9A  :9"*+/!$('O"# I 32:$RJcd0!E/#%N I 5H:"7-"#%-)
l!$C V[89897b#%x!$b<a:9A C-*+!$#%B!$b'O# I 32:$RBcd04!Eb#% H!$C
0!?$:H0-:H*,!$3%3%: rC-*+!$#%
'O# I 32:$R r:8;:C-7 I 3%:6*,!$3\32: rC*,!$#%xAB#%3%3 I "!$8M0mx0-:H?E!E"#%! I 3%:1AB#20x*,!$3\32: rC*,!$#%
!$CW :4CW +!$#%)i#2D0-:j?E!$3%7-:jAB#%0W* d'"*,#% :$R
yQ:K-`A 8;*'4!E":r0-::b0-:7"#% #%89/#%,!$]:;p[ :"#2?$:b:9/$<^:;p@'O:9"#%*:&9Rwcd0-:r0&5[' $0:#%A:
AB#%"0m } : 1#%K0!E I "!$8M0#%-)W0-:7-M#% #%89K89!$Q'"$_K<a* *673%#2'432:k?[#%:9Ad'O#%gR6yQ:+74 :0-:
<>3%32`Ar#%-)8;3%32:8;#2i$< 'O:9"*k7-!E#2W'4 I 32:*,D#\W!$CC#2#2f 
!$-)$<>$"C D'" I 32:*

@1:0707">



|

@1:07070> 

g

@B 

r

|

z



e



|

z




N

P

| Bz

'1



%]

e

K  
+' _'

~K37373>



E1:0707$

| Sz

@B

s







<



K'


 A'

B


w {}
s  l x  Sb.$"C:9 T|&7!$"#2)$7-'1#\P! P!E#%6|&74!E:/$<# 9: QN0!E
#\9Ng!$ 
*k732#%'43%#%89!E#2k! I 3%:B#%AB04#%8"0H:!$8M0]:3%:*:g/[89897-M/#%:9?$:9"5`A !$C:9?$:95
8;3\7*,ffRj7!$#2)$7'm:;p-#%  :8;:'4 I 32:*,bC-:9 :9"*+#%-:k0-::;p@#\  :8;:H$.-@G:;p-#%  :8;:$<
|[7!$#%)$7-'4V$<!H)#2?$:m# 9:jAB#20W!$C4C#2#2!$3 '"$' :9"#2:

t2w 2
 s 










M '! <C-:$ :B|[7!$#2)$7'4$<J$MC-:9 '
Bfi !
'  < C-:$ :B|[7!$#2)$7'4$<J$MC-:9 '

=<

	 )ff
4 )B
A)fijAY4R
<>$dAB0#%8M0
*)jM)B	 )
OAY4R
<>$dAB0#%8M0

`)Y}<>$.:9?$:95

yQ:f!$CC#2#%!$3%325iC-:*+!$CQ0!E.0:+|&74!$#2)$7-'Q#%1#%C-:*'O$ :&9NP# R :$R
:3%:*:g
 4R/cB0-:j' I 3%:*T#\
s  
 #%} P# I R



 s

x :
S b32*



Sj_n

go

"732:9r8;#% r$< n*+!EL[b!E"!$)$:Cm!$32)]!,M732:9B$<
3%:-)$0
78"0+0!E/0:rC#%!$8;: I :9 A:9:f!$g5'4!$#%($<^*,!EL@(<>$"* !1'O:9"*67!E#2ffRwcd0-:
'4 I 32:* #%
!E
P# I RHz{Q7-.:;p@'O:9"#%*:&jA:+ 'O:89#2<>5m0:,L[`ABQ$'4#%*,!$3
s  
3%:-)$0i!$CW_CW!$3%3O$'#%*+!$3ff 3%7-#249R

   x





s



+'

s  l

_



ff






I



Sj_n

o

 'w'{
s  l x  cd0-:b' I 32:*q8;4#% V$<P"8"0-:C743%#%-)6)!$*: I :9 A:9: m :!$*+
 ?$:9
jA:9:9L@dAr0-: Z#%D:9?$: QA:9:9L@dAB0: Z#%V@CC MR /!$8M0iA:9:9Li#%DC#2?@#%C-:Cl#%& 
 i'O:9"#2@CKAB0-:
#%.:9?$:
 iAB0:
#%1[CC MR !$8"0n)!$*:]#%68;*'O :CZ$<
FA]32$9N $0-*: !$4C $!`A!`5 @N AB0-:9":r-:K :!$* '3%!5@D0-*:j!$Cf0-:K$0-:9d :!$* '3%!5@
!`A!`5$R]cd0:k I {:8;#2?$:]#%K }8M0-:C732:!l)!$*:+<a$.:!$8M0Z'O:9"#2@Cx$<:9?$:9"5xA:9:9LX78"0Z0!E
:9?$:9"5x :!$* '43%!`5[j!E)!$#%4 .:9?$:95X$0-:9. :!$* J!W :!$* '43%!`5[K:;p-!$8;325X8;:+!lA:9:9LXAB0-:
A:]04!?$:]!$n:9?$: &7* I :9j$<D :!$*,9N!$CZ!Ek* 68;:]!WA:9:9LQAB0-:YA:]0!?$:l!$Z@CC

 sD}ffu

o K

o6J 1

<P

5

P

o

o

P

2Ro

P

YRo5J 18 K

>

o

?b

o

 -f
 cf

=<

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



?>

ff

[7* I :9D$<JA:9:9L@ 4!$Ci!, :!$* 4
' 3%!`5[B!EB* dFAB#%8;:1#\l0-:1!$*:j'O:9"#%[Cf`?$:9b0-:18;7" :
$<w0-:.:!$ ffRcB0-:K' I 32:* #\
#\}
#I R
s  







o

Sj_q

o

'o

 t2s  s  l x  SbZ$"C-:9
*,!E)#%8,"|&7!E":,#%.!$
*,!E " #2pX8;&!$#%#%)i0-:
I 5
( NAB#%0}0-:H7*h$<(:!$8M0X`A.Nff8;3%74*,ffNO!$CmC4#%!E)$!$3 I :#\-)+:|[7!$3 Rbcd0-:
 7* I :9" 6 
[
'4 I 23 :* #%
#%}
#I R
s  

t v
 w}


e

)t2{

 fi

1 o





  s




 
 
 

cJ! I 32:

  ! !

	  !I



 7-


 )


8 )
8

 )


8 )
8




j_q


 Qs  ,  x

   
   
 '   
 ''  
   
 '   
 ''  

;

 

-

b"!#c! b
! c =6U 
! ! 8b r



!ff!!)6
!b"ff
!!)



b8r

! !

! crrr

  ! 
6!!! %
! c =U6
 !!! c! 66rrU!
)

)

) )
)
)

"b8 U

!I

D

!c !
  8bVU
!  %b )
! !
  U
!  "b !
!  %)
) 8
U
 ) )
!  U !
) 8
U
!

m

 )

7;D



: !
!!b U6

!!b   )
!!c  :

-

I

!I

	  !bff


7;D
 
 !

"b88 ! ! ! ! 8c 
)"6
c 8! U 4 b
!I ) )6
 )  U!U 
)! !:r"!
!) 8U 6 ! )"b   U
U  c ) !I ) )6 8   !
!  c 
)"c"r
b %)"b :  r
!!c  b!
!: )  ?c )6  rb 
! ! ) 
#$)$ )r  ff!
! !  b! )"6c 8! U !!c !  )6
!I  U )
!: ) VU#c b#c  !b
! !  !
!I"c#r
b ! ) U  ff!
! !  "b  U U#c "U ! !!rc   c U
!I  :
! !!I"c  VU  r

"c#cr#c#c
Ur# c ?b
)K !!
U ) VUr
 U U6 )
)K !!
Ur" !8 
!Ur# !b%# )$c ?!I($b 
# b c!
) ) !r
)
U!b !I
8% )68

  8 

"E< =

  ! 




 !D
 


-

:!b"! b#c
! c  !r:%)

7;

!b"c c"c
! ! 
)
! )  !

#r"  $U &b%U "

%).b86ff!
! ! ) )!!b8
 ).b86ff !
%
! c   b U"!
!*!!cc ? "$br!r($r:+% ! )!
!!c"b U !) U
" !?b"cr
! cr ff!bV U
!!c"c U !8 c

!ff!! !%)  



!"!ff!  c!
!b#c  c#c
 U8  ff! !
! !I  ff!

8! !  #c
8  !)
8! "!  ) !
!8r   b
%)"c  c%)
! 4  "!

7* I :9D$< I !$8"L& M!$8L@ ><=!$#%3% !$Ci"7#\-)1#%*,:j ,_4CW!$3%3ff3%7-#2N[$B'`?$:10!E
0-:9":+!E:+-m 3%7-#249N^ }<>7-1#\ !$8;:j$<
!$-)$<a$MCZ' I 32:*WR B74g#%*,:.!E:,<>$
z
[32?$:9 [R ]
~
$N J:g#%74* zzz'@8;: $N!$C
,~
$< rSb~YR

d v2 





" kK373 1:K373 !eK @_
"
N YHP>

!"j1: X)

Xf



cd0:+:74321!E:])#2?$: #%YcJ! I 32: [RiyQ:W*,!EL$:l!}[7* I :96$<d I  :9?E!E#2R /-<>$"89#%)}SB
x0-:H'"#%*+!$3P-${G:|[7!$3%j*@C-:3

r)#2?$:K0-:kA$" K:73% =!$j#2KC-[:j#%x!$3%* K!$3%3J0-:
7 I  :|&7:gd'4 I 32:* C-*+!$#% MRyQ:1AB#\3%3O-$B0-:9":9<a$:kC#%8974D#2d<=7-0-:9`Rcd0-: I : B"7&#%*:
!E:l I !$#%:CnAr#20 0-:
*@C-:3 N(0:7-"#% #\8
>' KC MN# R :$Rw<a* :-<>$"89#%)x!x'O:9"*k7-!E#2 I 5
0-:.8M0!$-:3%3\#%-)8;  "!$#\gd!$3%-:.!$Ci8M0-&"#%-)0-:j?E!E"#%! I 3%:bAr#20W*,!$3%3%: DC-*,!$#%ffN-Ar0-:90-:9
'"#\*,!$3g$C74!$3 R
#%) 7 J0-:V'"#%*+!$3g$ 7 w0-:DC7!$3&?!EM#%! I 32:w!$C-:89#%"#21?E!E"#%! I 32:J :CJ 
#%8;":!$ :D"7&#%*:9Rwcd0-: I "!$8"04#%-)j0-:7-"#\ #%8VC-[:(#%C-:9:CH'4$_<>* 0-:d*k732#2'32:V?[#2:9AB' #\g9R
$ :r0!E0-:
*@C-:3#\-632-)$:90-: I :   "!E :9)$5$N#% :9M*,/$<ff:#%0-:9<=!$#%3%7:$"7&#%*:9N
!$k#21AV!$6#\YcJ! I 32: -R}cB0#%.#%6C-: '4#% :,0-:+<=!$8;k0!Ek#%10!$60-:]  "-)$: k'$'4!E)!E $Rmcd0#%
*@C-:3ff0!$B325+:.?[#%:9Ad'O#%gD!$Ci0#%d0#\C-:9"0-: I "!$8"04#%-)0-:7-"#\ #%8ER
$ :k!$3% ,04!Ed0-:
*,!$3\32: V :!E"8"0i :9: I 7-D-$DM7g#\*: /!E:j I !$#%-:ClAr#20f0-:
*[C:304!Ed8;* I #\-:V0-:
!$3%3 G C4# :9":gK8;  "!$#\gjQ0:k'4"#%*,!$3JAB#20x0-:,8M0!$-:3\3%#%-)f8;  "!$#%& I :9 A:9:Q0-:'4"#%*,!$3
!$ClC7!$3NgAB0-:fA:b74 : I $0f'"#\*,!$34!$ClC74!$3?E!E"#%! I 32:!$DC-:89#%"#2+?E!E"#%! I 32:9Rwcd0#%8;* I #%!G
#2m)#2?$:r0-: I :-:9_B$<0-:H  -)$: b'$'!E)!E $b!$Cx!+C47!$3^?@#2:9Ad'O#%&D<a$b0-: I "!$8M0#%-)
0-:7-M#% #%8ER

I

m

ljx/ 0I 



-5

=

5

+





=

I






fi 8-
	fiffff
e






K

t$w 2
 s 





*@C-:3

0-:7-M#% #%8
>'
>'
>' KC
>'
=C
( >' KC
( >'
( =C
>' KC
>'
=C
( >' KC
( >'
( =C

Y

jx/ 
jx/ 
jx/ 0I
jx/ 
jx/ 
jx  0I
jx  
jx  
jx/ 0I
jx/ 
jx/ 
jx  0I
jx  
jx  

























<=!$#%3%

.



aTff
aTff 

,

3@Ri3$
3@Ri3$

,

aTff

&


,

3@Ri3$

aTff
aTff 

&

,



,

3@Ri3$
3@Ri3$
3@Ri3$
3@Ri3$
3@Ri3$
3@Ri3$

,




,
,


m

2/,7

2MV.$



 :8ER

,

&E< =

cJ! I 32:

MV&$

<=!$#%3%

14373
"70
&7
"70
"6
&7
"7.
"6
"6
"70


"6
7" .




 :8ER
@R
@R

3 k7
3 \18,

ff

a 

3@R\18,
3@R\1:0
3@R\18,
3@R\18,
3@R\1:.

a 

3@R\1:.
3 Rk
@
3@R\18,
3@R\1:.
3 R\1:0
@




ff

I

<=!$#%3%

1:.707"
07"7"
171718,
143$70
.7.7.
171718,
143K>
.7.$,
07070
07"7"
.76
07070
07"70

 

MV0$



 :8ER
[R
[R
[R
[R

<>!$#\3%

. >&
" w,K&
" k.j1
" w,63

.77&7K3


T

 

"[Rk.7
"[Rk&7.
"[R >
&[Ri373
"[Rk.7"
"[Rw,K
&[Ri3$"
"[Rk.6
"[Rk.K3







"7$,K&7&
7.j1:07&
>&7"770
"7$,K.7"
7.j1:07.
>&$,r 1
>07&$,K.




>7$,K.
>0$,63$
7"7K3M1
>6>"7


 :8ER
@R
[R
[R
[R
[R
ER
[R
[R
-R
[R
[R
&R

&K373
7.7"
>&7
$,K
 1:.
>&j1
$,K
 1:0
,r
$,K&
>7.
,7,

ff

k&j1
k"$,
$3
k7.
k07&
i3$"
1
k06
k.7
i3$&
k.j1
i3K

e

>7[Rk.70

7* I :9D$< I !$8"L& M!$8L@ ><=!$#%3% !$Ci"7#\-)1#%*,:j ,_4CW!$3%3ff3%7-#2N[$B'`?$:10!E
0-:9":.!E:j- 3%7-#249N& <>7-d#%4 !$8;:V$< 
k' I 3%:*WR r7&#%*:D!E:K<>$Dz
[3%?$:9 [R +
~
$N J:&#%7* z"zz/'"[8;:$N!$C
,~
$< BSK~ZR





1:K373 Xe  _

" kK373



X"j1: !)

Ev2

F

cd0:.|&7!$"#2)$7-'i:;p-#%  :48;:.' I 3%:* 89!$ I :.*@C-:3%32:CW!$r!,*67432#2'432:K'O:9"*k7-!E#2W'4 I 32:*
AB#20
#%& :9" :8;#%)m'O:9"*k7-!E#2 8;  M!$#%gRYyQ:i#%& @C78;:l!m?E!E"#%! I 32:]<>$:!$8"0 :g 5 #%
0-:+*k732#%'43%#%89!E#2x! I 3%:$<0:+|&74!$#2)$7-'PRyQ:+0-:Q'O 1' :9M*67-!E#%Q8;  "!$#%&.Y0-:
?E!E"#%! I 32:B$<:!$8"0x A !$C}:!$8"0Q8;3%74*,ffRVz mc ! I 32: +!$C &N A:6)#2?$:6:73%d<>$rFAf<>!$*+#%3%#2:
$<' I 32:*+9RkSb I :9<>$:$N^0-:  *,[C-:3J)#2?$:10-:A$" j'O:9<>$"*,!$8;:$NP!$4C I 5X!W8;#%C:9"! I 32:
*,!E)#\Z<>$60-:l3%!E)$:9H#%!$8;:9R}o-$ 
[N(!$3%3(0-:f$0-:9H*@C-:3%1!$4C I M!$8"0#\-)}0-:7-M#% #%89
)#2?$: I !$C3%5,#%*,#%3\!E('O:9<a$M*,!$8;:$RS C7!$34?[#%:9Ad'O#%g9N&:#20-:9 I 5,#2 :32<ff$D#%]8;* I #\!E#2]AB#20
0-:]'"#%*,!$3/?[#%:9Ad'O#%g9NJC-[:6-$k O:9k!$&5Y!$C-?E!$g!E)$:$N I 7-6C&:k-$60[7-k*6748"0n:#20-:9R}o$

-N#\fcJ! I 32: &N4!$3\30:K*,[C-:3\!$4C I "!$8M0#%-)H0-:7-"#\ #%89V!E:j8;*'O:9#2#2?$:$N-:;p-8;:9'd<>$D0-
: 
*@C-:3ff!$CW0:10-:7-"#\ #%890!E I M!$8"0W4325+W0:1C7!$3O?E!E"#%! I 3%:9R

6o

B&

Y

2B


e

   x



29

K

,



,




Y

 s

c m*@C-:30-: b32* I "7432:9"K' I 32:*U!$k!W'O:9"*67!E#2Z'" I 32:*WN^A:]#\g @C78;:,!}?!EM#%! I 32:
<>$r:!$8M0X'4!$#2AB#\ :.C#% !$48;: I :9 A:9:X*,!EL@9R @#\8;:.A:k*,!`5}0!`?$:H*,$:1?E!$3%7-:r0!$m?!E"#\! I 32:9N
A:,#%g "[C748;:k!$CC4#2#2!$3 ?!EM#%! I 32:b W:7:604!Ej0-:9:!E:,!$j*,!$&5m?E!E"#%! I 32:r!$.?!$3%7:9N^!$
7-)$)$: :C I 5 b:9:32:
MRHyQ:+89!$X0-:X'O j!f'O:9"*k7-!E#2X8;  "!$#\gKX0#%b:3\!E)$:C
 :9k$<d?E!E"#%! I 32:R}z{ncJ! I 32: [NA:f)#2?$:l:7432.<>$H_4C#%)i!$3%3/$'4#%*,!$332:-)$0n"732:9"1<a$H<>7-
#%!$8;: b32* I
*:!$V0:b'4 I 32:*q$<P_44C#%-)1! K32* I M732:9$< =*,#%4#%*,!$3 (32:-)$0
UAB#%0 Y*,!EL@9R b: '#2 :.0-:.<=!$8;B04!EB#2B0!$B0-:1  "-)$: d'"$'4!E)!E $N40:
*@C-:3^#\d-$



'

5

o

=< 

d1:0707$

nx

Rog{('!

.

I

4



T

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff





*@C-:3

Y

























0-:7-"#\ #%8
>'
>'
>' KC
>'
=C
( >' KC
( >'
( =C
>' KC
>'
=C
( >' KC
( >'
( =C

<=!$#%3%

jx/ 
jx/ 
jx/ 0I 
jx/ 
jx/ 
jx  0I 
jx  
jx  
jx/ 0I 
jx/ 
jx/ 
jx  0I 
jx  
jx  

eWff
eWff 

&

3@Ri3$

eWff
&
&

3@Ri3$
3@Ri3$

&

eWff
eWff 
&



&

3@Ri3$
3@Ri3$
3@Ri3$




eWff
eWff 
eWff 



m

2fi,7


:8ER

&



,< =

cJ! I 32:

BfiV&$

<=!$#%3%

.7





 :8ER
@R

<=!$#%3%

3 k7

18,7,K0

3@RkK3
3@RkK3
3@Rkj1

077"
07j1
1:7&7&
06$3
077&
1:7&$,
0K373

e 

"70
7" 0
,r
7" 0
7" 0
,K
$" ,
$" ,
$& ,
$" ,
$" ,
&7&

BfiV.$

e 
e 

3@Rk7

e 



-Rk.$,
, Rk$,
&
" R\1:0
[
" Rk70
[
, Ri3K
&
" Rk6
[
" Rk7
[
, Ri3$
&

17143$
0K3$"
.70$,
17143K

e 

3@RkK3
3@Rk7

I

171:&7707.
"76 1:0
"7"777
"7"770$,
.77j1:&
"7"77&6
"7"67>
.770j1:&

 



3@RkK3
3@Rkj1

<>!$#\3%

. k70
" \1:
 k070
 k07
, k"70



BfiV0$



 :8ER
[R
[R
-R
-R
&R





"76 1:0
,K7070$,
"7K3>,7,
"76>&7
,K$,~1O





 :8ER
[R
[R
[R
[R
[R

.6>
>07&
>.70
>.7"
,7,K

k7&
k6
k.70
w,K
\18,

ff fiff ff
e

,K.[R >.
,K&7[& Rk7
>.7[& Rw,K
>0jE1 Rk"6
,r>[" Ri3$0
>0jE1 R >"
>07[ Rw,63
,r>[" Rk.7&

7* I :9D$< I !$8"L& M!$8L@ ><=!$#%3% !$Ci"7#\-)1#%*,:j ,_4CW!$3%3ff3%7-#2N[$B'`?$:10!E
0-:9":.!E:j- 3%7-#249N& <>7-d#%4 !$8;:V$< 
' I 3%:*WR r7&#%*:D!E:K<>$Dz
[3%?$:9 [R +
~
$N J:&#%7* z"zz/'"[8;:$N!$C
,~
$< BSK~ZR



B

1:K373 Xe  _

" kK373



F

X"j1: !)

jx/ 0I 

Ev2

8;*'O:9#2#2?$:D,0-:d3%!E)$:9/#\ !$8;:9R~}[C-:3 !$4C,0-:7-"#\ #%8
>' KC P)#2?$:0: I : w
 "7&#%*:
<>$+0-:x3%!E)$:9l#% !$8;:NAr0-:9:!$+!$C4C#%-)Z0:}!$3%3 G C# :9:&+8; "!$#%& =*@C-:3
N 0-:7"#% #%8
d
>' KC )#2?$:D0-:13%:!$ d :!E"8M0ffR :#%-)<>$"8;:Ci  I "!$8M0l 74 D0-:j'"#\*,!$3 ?!E"#\! I 32:D0[7-
0-: I "!$8"04#%-)0-:7-"#\ #%8ER





jx/ 0I Y

T

e b

q)

 se}u





'w{

m5







3%#2L$:b0-:j':9?@#27' I 32:*,9N[A:j_Cf325,0-:K_M D 3%7-#2f 0-:j 'O$V8M0-:C73\#%-)k' I G
23 :*WRcd04#%32:!$C/ 6*k78"0])$:!E :9?!E"#\!E#2+#%,' :9"<a$"*+!$8;: I :9 A:9:+0-:bC# O:9:&/*@C-:3%9RJyQ:
:9'O$V:7432D#%lc ! I 32: [R b[[ClM7g#\*:D!E:j I !$#%:ClAB#20l0-:
!$C
*@C-:3%N[7"#%-)H0-:
C7!$3^?!E"#\! I 32:d!$bC-:89#%#%W?!EM#%! I 32:9N4:#20-:9B}0-:#2d ABm$r#%m8;* I #\!E#2WAB#%0i0-:.'4"#%*,!$3
?E!E"#%! I 32:R



0 

e 



t 
 w}\



t$s





o
1 o

o

o



yQ:Q*@C-:3b0-:m$MC-:9
*,!E)#\8m|[7!E:x' I 32:* Ar#20 !
*,!E "#2p $<.?E!E"#%! I 32:]AB0#\8"0
I 5
( RyQ:b0:]'O V!k'O:9"*67!E#2]8;4  "!$#%&l!$3%3 0-:b?E!E"#%! I 32:#%]0-:
!EL$:j?E!$3%7-:<a* b 
*,!E "#2p N!$C+7* 8;  "!$#\g,0-:D`Ar9Ng8;3%7*+w!$CC#%!E)$!$3\9R B:732!E":D)#2?$:,#%HcJ! I 32:
@R(Sr)!$#%ffNg_C#%-) 7 (0:d_"  3%7-#23%:!$C( 6AB#%C-:D?E!E"#%!E#2+#%'O:9<>$"*,!$8;: I :9FA:9:]0-:
*@C-:3%9R
"#%-)W325X0-:]C7!$3?E!E"#%! I 3%:.!$1C-:89#\#2Q?E!E"#%! I 3%:.#%.! I !$CY8M0-#%8;:$N I 7-.0-:]C7!$3
?E!E"#%! I 32:D!E":10-:32'<=73 #2<w7 :CW!$BC:89#%#2l?E!E"#%! I 3%:D#%W8;* I #%!E#2lAB#%0l0-:.'"#\*,!$3 ?!E"#\! I 32:9R
o-$k0-:+3%!E")$: 6#%4 !$8;:+ 3%?$:CffN 0: I : 1  "!E :9)$5n#%j0-:fC-7 I 32:*+!$3%32: 1C*,!$#%Z0-:7"#% #%8

143



n5

=U

fi 8-
	fiffff

*@C-:3

Y

jx/ 
0j1:
jx/ 
"K373
jx/ 0I  &K3$&
jx/ 
.70K3
jx/ 
&77&
jx  I  &K3$.
jx  @
077.
jx  
&77&
jx/ 0I   
jx/ 
K" 373
jx/ 
>70 "
jx  I  "K3K
jx  @
"6>
jx  
>07"

























cJ! I 32:



, k7"$

b32* I V .[Nk6 b32* I V 0[N 7 K32* I d 143@Nk"7"$

3 \1:"

"7"6>
706>0
77K3
"76>
770K3
777
"7&6>.
770K3

b32* I &N
<>!$#\3%
 :8ER
@R

0-:7-"#%#%8
>'
>'
>' KC
>'
=C
( >' KC
( >'
( =C
>' KC
>'
=C
( >' KC
( >'
( =C

.E< =

<=!$#%3%

e  
3@R\1:
3@R\1:"
3@R\1:
3@R\1:
3@R\18,
3@R\1:
3@R\1:
3@R\1:
3@R\1:
3@R\1O
3@R\1O
3@R\1:

 



706>0
$,K.7
$,K.$,
77"7.
$,K06

 :8ER
ER

<=!$#%3%

<>!$#%3\

 :8ER

1ERi3M1
1ERk7"
1ERi3$
1ERi3$
1ERk$,
1ERi3$
1ER\143
1ERi3$.
1ER\143
1 R\1
E
1ER\1:
1ER\171

18,6373$

 

,K$,K"j1

 e 7 

18,~1:"j1
18,63$7

,&Rk"7"
,&Rk&7

,K7"770
,K7.7"7

>0[Rk7"
>[0 Rk$,

18,~18,K0

7   

,&Rk"70
.[Rk70

,K7&77.

ffff

<

>0[Rk"70
"6- Rk&7

1O>77"
1O>707

.[Rk7.
.[Rk7.

&j1:&j1:&
&j1:.707.

"6-R >&
"6- Rk06

1O7$373

.[Rk70

&j1:.707

"6-Rk0$,

1 \1:

a ff

 :8ER





I

7* I :9+$< I !$8L[ "!$8L@ ><>!$#\3% H!$C "74#%-)X#%*:i n_4C !$3\3D$'#%*,!$3B 3%7-#24 
<>7-1#%4 !$8;:j$<V0-: K32* I "732:9MK' I 32:*iN^AB0-:9:0:,$'#%*,!$3/32:-)$0Z#%.)#2?$:ffR
r7g#\*:!E":r<>$Vz
[32?$:9 [R H
~
$N J:g#%74*qz"zzw'@8;: $N@!$C
~
$< BSK~ZR4S C!$0}*:!$D0!Er-:73%VA:9:1:97-"-:C}!E<a :9 10-7-R





!)

Ev2 

,

" kK373

1:K373 !e  fi_

"j1:

1

W*@C-:3 $d*,[C-:3
R(cd0:b<>$"*:9V:;p@'432$:D!H3%!E")$:9d :!E"8"0i :9:$N I 7-VC-[:D H?$:95f"3%#2)0&325
|[7#%8L$:9B0!$i0-:.3\!E  :9R




c f8;4893%7C-:$N 0-: :6:732b0- A 04!EbC-5@!$*,#\8 I "!$8M0#%-)]0-:7-"#%#%89d89!$ I :6#2)4#2_489!$&325
* $:k: O:8;#2?$:HAB0-:i0:95i32&$Li!E I $0i?@#2:9Ad'O#%&d$<(!]'O:9"*k7-!E#2ffRdz{C-:9:C^N I "!$48"0#%),

'"#\*,!$3V$]C74!$3V?!E"#\! I 32:AV!$,$<> : *$":}#%*'O$!$&, Z7-]:73%H0!$ 7"#%-)Q!Y  "-)$:9
'$'!E)!E $Rdo-$K:;p@!$*,'432:$N:-<>$"89#%) KSB m!$m!$3%3 G C# O:9:&B8;  M!$#%g9N !$C}:!E"8"0#\-) 7 
 0-:m'4"#%*,!$3D?E!E"#%! I 32:9NV$<a : )!`?$:xA$" :x'O:9<>$"*,!$8;:i04!$ :<a$"89#\-)YSB  0:m8"04!$@G
-:3%3\#%-)W8;  "!$#\g9NJ!$CZ0[7 I :#%)i! I 32:  I "!$8"0Z I $0Z :96$<V?!E"#\! I 32:9R,z{Z!$CC4#2#2ffN
#%Z*:,' I 32:* 893%!$ :N 0-:]C-7 I 32:*+!$3%32: .C-*+!$#% I "!$48"0#%)l0:7-"#% #\86 O:9:CY0-: I : 
'O:9<>$"*,!$8;:$R(SbDA:.0!?$:1!E")7-:CffN-0#%D0:7-"#% #\8r#%D8;4#%  :&DAB#20l0-:j<=!$#%3O_M V'"#%89#%'432:d<>$
?E!E"#%! I 32:K$"C:9"#%-)!$CW0:17898;:9:CW_4" D'"#\89#2'432:r<a$B?!$3%7:j$"C-:9"#%)-R

O





5

K

z D#%A$0W$#%-)k0!ED0-:K:73%/$< 7-D:;p['O:9"#\*:g"74]8;7& :9d H0-:j774!$3:;p@'O:8;!G
#2($< ?E!$3%7-:D$MC-:9"#%-)-RJyQ:B<>7C,0!E/C-7 I 32:D*,!$3%32:(C-*,!$#% >04!E#%9N&*,!$3%32:(C-*,!$#%H<>$
I $0x?!E"#\! I 32:k$"C-:9"#%)f!$CX?E!$3%7-:H$"C:9"#%-) d)!?$:+C4# :9":gj[7* I :9"b$< I !$8L[ "!$8L@. i"*,!$3%3 G
: KC-*,!$#%m?E!E"#%! I 32:1$"C-:9"#%)-N:9?$:xAB0-:m_4C4#%-),!$3%3J 3%7-#%9Rdz b#\B)$:-:9M!$3%325W0-7-)0&b0!E
?E!$3%7-:j$"C-:9M#%-)*,!EL$:B+C# O:9:8;:K +0:j`?$:9"!$3%3  :!E"8M0i: O$dAB0-:i_4C#%)k!$3%3ff3%7-#2N@#%<
8"0-32$)#%89!$3 I !$8"L& M!$8L@#%-)#%7 :CffRwz{C-:9:CffN&0-:j!E)7*:&)#%?$:]:!EM3%#2:9/<>$D7898;:9:Cf_"!$D!
?E!$3%7-:j$"C-:9M#%-)H'"#%489#2'432:b#% I !$ :CiW_4C#\-)64325]:. 3%7-#2 (#2<PA:18"0& :60-:j"#2)0&D?E!$3%7-:$N



X





O

<

8#c

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



*@C-:3

0-:7-M#% #%8
>'
>'
>' KC
>'
=C
( >' KC
( >'
( =C
>' KC
>'
=C
( >' KC
( >'
( =C

Y

jx/ 
jx/ 
jx/ 0I
jx/ 
jx/ 
jx  0I
jx  
jx  
jx/ 0I
jx/ 
jx/ 
jx  0I
jx  
jx  

























cJ! I 32:



8V&$



['O$
<=!$#%3%
 :8ER



aT





&76



"7.70
,
171:
"j1O
&76







"7.70
,
171:
"j1O


0E< =

8V.$



@' $"
<>!$#%3\
 :8ER
@R
@R

1:6>.
"7&7&

"7&7&

eW 

0
&7&K3M1
>

"7&7&

eW 
eW 

3@Ri3$
3@Ri3>,

0
&7"7&7
>

1ERi3$0
3@Ri3$

!

I

3@Ri3M1
3@Ri3$0

aT
3@Ri3>,

3 k7
3 \1:"

aT
3@Ri3$
3@Ri3$&
3@R\143
3@Ri3M1
3@Ri3$0



aT

eW 
eW 
3@Rk06

3@R\1:&

eW 
eW 



70$, w,63
7"K3 k07

eW 

1:$,K&j1O>
77&
17171:
.7K3$&707
,63$7.

7"7"[Rk070
3 Ri3>,
@
3 RkK3
@
1:&7[. Rk0j1
1 Rk"7.
E

1:7&j1:&7.7&
770
17143$
.j1:7&707&
&707K3

$,K[R\143
3 Ri3$.
@
3 Rk7"
@
1:.7[& Rk7
1 Rw,K&
E

8d1:$

['O$
<>!$#%3\

:8ER
&R
@R

1:.7&77$,K"
1:7&j1:&7.7&

3@R\1O



8d143>

['O$
<>!$#%3\

eW 

 :8ER
ER
-R

"$,7,7,K7.7
7"77$,63$"
"777
7"7$,r7,
&77&7.
>&j1:7

1:0$,~1 k07
1O77 7

&77"7

7"77$,63$"
&77&7
>"j1:7"

[Rk70
1 Rk07.
E
1O>07[" R  1
 R\1:.
[
K@3 Rk07.

&j1:70

[Rk"7"



 

2



1:7&7.[Rk.6
1 Rk0
E
1:[. R 

7* I :9k$< I !$8"L& "!$8"L[ ><>!$#%3\ j!$Cn"74#%-)W#%*,:+ x_4CZ0:]_M 6 3\7-#2Z X
 <>7-
%# 4 !$8;:b$</0-:H 'O$K8M0-:C73%#\-),' I 32:*WR B7&#%*:b!E:H<>$bz
@32?$:9 [R

~
$N J:&#%7* z"zz('@8;: $`N4!$C
+~
$< BSK~ZR



1:K373 !e  @_

d v  

,

p"j1: !)

9" kK373

A:189!$}!`?$#%C I !$8"L& M!$8L@#%-), f8"0-[ :1!$-$0:9B-:$R(z <JA:.AV!$&d ,_4CW!$3\3^ 3%7-#%9N@A:60!$3%3
0!`?$:k  I !$8"L& "!$8"Lm f 5}!$3\3P0-:H!$32 :9"4!E#2?$:6?E!$3%7-:b!$&5&AV!5$R @*,#%0
b0- ABK0-`A ?E!$3%7-:
$"C-:9M#%-)+89!$X*,!EL$:!fC# O:9:8;:1 l0-:H :!E"8M0X#%
!$-)$<a$MC b' I 32:*iN4:9?$:xAB0-:m_4C#\-),!$3%3
 3%7#29Rkz  I "#2:9< NffAB0-:XA: I !$8"L& "!$8"LZ0!?@#%-)l "#%:CQ0-:,!$#%)*:&
 
    NPA:+89!$
'O B0:k8; "!$#%&
       Rbz{x *:H89!$ :9NO'$'4!E)!E#%x*+!5}- A
32:!$C} W#%*+*:C#%!E :
<=!$#%3%7-:$RS )$&@Ci$MC-:9"#%-)H<>$d0-:j?E!$3%7-:d89!$}0-:9:9<>$:1!`?$:6 :!EM8"0ffR





R

	
fi 2

R




X





VK37373>



Y

Y

Q Q  D

z{m*,!$&5i'" I 32:*,9N?!EM#%! I 32:r*,!5 I :k8;  "!$#%:C} l!EL$:7#%|[7-:.?E!$3%7-:N I 7BA:k0!`?$:*$:
?E!$3%7-:r0!$x?!E"#\! I 32:9RBcB0!Eb#\9N4A:!E:k3%&$L@#%-),<>$j!$m#\ {:8;#%?$:k*,!E'4'4#%-),<>*h0-:k?!E"#\! I 32:
 +0:1?E!$3%7-:9RDo-$b:;p@!$*,'432:$N!$m$'#%*+!$3 G#%8L b32* I "7432:9B0!$B#%8L@r!Er0-:6*+!EL[ @N EN -N
[N !$4C
ER]cd0: i#%& :9 G#%8LQC#\ !$8;:.!E:]!$3%3C# O:9:& I 7-jC-}-$j<>$"*U!i' :9M*67-!E#%Z!$
0-:HC#% !$48;: ]#%B! I :g9RKow#%C#%),! G#%8"L b32* I "732:9r$</32:-)$0
H89!$ I :1*,[C-:3\32:C}!$K!
'O:9"*k7-!E#2.'4 I 32:* I 5.#%& @C789#%-)d!$k!$CC#%#2!$3 ;06?!EM#%! I 32:( b!EL$:V.0-:V*,#%"#%-)V?E!$3%7-:
[Rz{C-:9:CffN^04#%j#%K0-:,*:90[CXA:+7 : i*,[C-:3w0:' I 32:* #\X0-:,3%!$ . :8;#%ffR B A:9?$:9`N
0-:9:b!E:r!6&74* I :9($<^!$32 :9M!E#2?$:BAV!5@ k*@C-:3!$f#% :8;#2<>* i?!EM#%! I 32:#%g 
?E!$3%7-:
AB0#\8"0lA:.:;p['32$:.0-:9:$R

0

171

m&

p143

$

"

#

c"

65

3 1 



171

171

&

65

+e

_'

o

65

o

o-$:;p-!$*'43%:$NJ0:9:f!E":fFAQ#\*'432:'M#%*,!$3/*,[C-:3\1$<d!$ #% :8;#2ffRmz n:!$8"0 A:l0!?$:
'"#\*,!$3V?!EM#%! I 32:Ar0#%8"0 !EL$:x:i$<
'O# I 32:l?!$3%7:9R z{ 0:}'"#\*,!$3D!$3%3 G C# :9:&,*@C-:3
=C-:-$ :C I 5
MNPA:+#\*'432:k'O j!i#%-)3%:k!$3%32G C# O:9:gj8; "!$#%&jQ0-:'"#\*,!$3J?!E"#\! I 32:9R



N P>

'



8!



fi 8-
	fiffff

*,[C-:3

0:7-"#% #\8
>'
>'
>' KC
>'
=C
( >' jC
( >'
( =C
>' KC
>'
=C
( >' jC
( >'
( =C

Y

Mx @
Mx @
Mx I 
Mx @
Mx 
Mx  0I 
Mx  
Mx  
Mx I 
Mx @
Mx 
Mx  0I 
Mx  
Mx  

























$V$

"

eW
eW
eW
eW
eW
eW
eW
eW

"

eW
eW
"

eW
eW

&


"


"
"


"



"

~m!E)#%8
<>!$#\3%

aW
aW
aW
aW

K3
1:0
1:.
K3
$ ,
143
171
1:.
1:.
1:0

aW
aW
aW
aW
aW
aW

143
71 1
1:&

3@Ri3M1

aW
aW

I



$V&$

~}!E)#\8
<=!$#%3%

 :8ER
@R
@R
@R
@R
-R
@R

1:"$,K&
1:7"7"
>&7$,
1O>"$,
>07j1:
"7"7"
>07"
077.7j18,
7>7&
1:7"7"
>6>7&
>7"

3@Ri3M1



3@Ri3$

c

$V"$

~}!E)#%8
<>!$#%3\
 :8ER

3@Ri3M1



+143< =

cJ! I 32:

$R

~}!E)#%8
<>!$#%3\
 :8ER

3 \171
3 \171
3 k$,
3 \1O
 k&j1
3 i3$&

eW





eW



.7&[Ri3>,
3 R >.
@
3 R\18,
@
" Rk7
[
3 Ri3>,
@

0j1:0K3$"$,

 :8ER

$,r>.7&K3$0

1:07&[R >"

67>.j1:&7

6>0[Rk.6

>&77.7&7"
1:&6>.6$3$.

1:7[Rk7"

   

7[0 Ri3M1
1O>.[Rw,K



143$.770707

143$&[Rk"7"

Tff

v

7* I :9b$< I !$8L[ "!$8"L[ ><>!$#%3\ d!$4CX"7#\-),#%*:H W_44C}0-:_4" K 3%7-#2x W<>7-
#\ !$8;:l$<H*,!E)#%8Q|[7!E:Q'4 I 32:*WR B74g#%*,:W!E:Q<a$}z
[32?$:9 [R

~
$N J:&#%7* zzzB'@8;: $N^!$C
}~
$< BSK~ZR^STC!$0Q*:!$4K0!E.-
":732VA:9:.:97"-:CW!E<> :9 j0-7-`R

1:K373 !e  _



"j1: X)

1

X" kK373

N YHP>

9

z{



Ev2 

0-:W'"#%*+!$3-${G:|[7!$3%+*[C:3 =C-:-$ :C I 5

HA:W'O  I #%4!E5Y-${G:|[7!$3%,8;4  "!$#%&
I :9 A:9:Z:9?$:95XFAxC#% #%48;b'4"#%*,!$3w?E!E"#%! I 3%:9RHyQ:]89!$Y!$3\ i7 :+C47!$3*@C-:3%9R,o-$6:;p@!$*,'432:$N
#%W0:1C7!$3ff-${G:|[7!$3%r*@C-:3 N-A:60!`?$: UC7!$3^?!E"#\! I 32:9N-:!$8M0}AB#%0i!,C-*,!$#\W$<
' "# I 32:
?E!$3%7-:
X$<P0: :.!E:.C7*+*15,?E!$3%7-: MN@!$4C I #%!E5,${G:|&7!$3\d8;  "!$#\g I :9 A:9:W:!$8M0
'4!$#2D$<C74!$3O?!E"#\! I 32:9R

_'

9 ' JXo



'

b

y :AB#%3%3$8;4#%C-:9^0:9:C# :9:&P8;* I #%-:C6*@C-:3%ffAB04#%8"0.8M0!$-:3 I :9 A:9:1'M#%*,!$3$!$C6C7!$3
Q
*@C-:3%9R}z n0-:f_" k8;* I #\-:Cn*,[C-:3 =C-:-$ :C I 5
* MNA:l0!`?$:l8M0!$-:3\3%#%-)}8;4  "!$#%&
$</0:k<>$"*
i#%*,'43%#2: 
d!$CQ-l!$CC#%#2!$3JC7*,*65i?E!$3%7-:b<a$j0:HC47!$3J?!E"#\! I 32:9R
z{ 0-:x :8;C 8;* I #\-:C *@C-:3 =C-:-$ :C I 5
:;p@ "!
( MNd0-:xC7!$3B?!E"#\! I 32:,0!`?$:
C7*+*15 ?E!$3%7-:9Nd!$4C A:Q0!?$:Q8"04!$-:3%3%#\-)Z8;  "!$#\gf$<.0-:x<>$"*
# 
R z{
0-:l0#2MCY8;* I #%-:C *@C-:3 =C-:-$ :C I 5
1 MN(0-:WC7!$3?E!E"#%! I 32:k0!`?$: 7 H!X#%-)3%:+:;p@ "!
C7*+*15m?!$3%7:$N^!$CXA:,04!?$:+8M0!$-:3%3\#%-)l8;  "!$#%&j$<0-:<a$M*
}# 
I 7-K3%5
AB0-: m#\.-$.:|[7!$3 m0-:+C7*+*15x?!$3\7-:$R
$ :]04!E1!$g5X$<D0-::+8"0!$4-:3%3%#%)l8;4  "!$#%&
!$32-: >AB#%0-7-j!$CC#2#%!$3 8;4  "!$#%&jX0-:H'"#\*,!$3P$6C7!$3J?!EM#%! I 32: B#%K:-7)0X iC-:9_4-:
!$i#% {:8;#2^R

@B Y |

%] `Y z

N P>





' %
J o
@B Y |  ] OY z

N P>

m



N P>



5

@B*Y | J] +Y z



=

!|
p
K5

I

X' J%o

65

yQ:Q89!$ !$3% n*,[C-:3r!$ #% :8;#2 I 5 #%& [C4789#%-)
C7*,*65 
' "#\*,!$3D?E!E"#%! I 32:]!$C
:7"#%-)b0!E(0#\w:;p[ :C:C, :9($< ?!EM#%! I 32:w<>$"*,(! I # {:8;#%ffRJcB0#%89!$ :B\# 9N0-`A:9?$:9N@8;`?$:9:C
I 5]7-B:!E"3%#2:9D:"732DW'O:9"*k7-!E#249R

5

8"!

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



7a 



s} 

 {wD

 {#}

yQ:B_4" ('"`?$:B04!E9N&AB#%0: 'O:8;( k!E"8 G 8;#% :8;5$N@0-:d_"( 5['O:d$<^8"0!$4-:3%3%#%)K8;4  "!$#%&
!E:j!$#2)0&!$V0-:b'"#\*,!$34-${G:|[7!$3%V8; "!$#%&9N I 7-3%:#2)0g0!$f0-:b'"#%*+!$34!$3%3 G C4# :9":g
8;  M!$#%g9R cB0-:ffN(A:i' ?$:i0!E0-:m :8;C F5&'O:W$<K8"0!$:3%3%#%-)X8;  M!$#%g+!E:i!$,#2)0&
!$l0-:X'"#\*,!$3B-${G:|[7!$3%W8;4  "!$#%&9N I 7-l32:f#2)0&f04!$ 0:X8M0!$-:3\3%#%-) !$C C7!$3b-${G
:|[7!$3%d8; "!$#%&9NAB0#\8"0W!E:13%:V#2)0&d0!$W0-:1'"#%*,!$3O!$3%32G C# O:9:gD8; "!$#%&9R/ow#%!$3%325$N@A:
' ?$:+0!E10-:+0#%"CX 5['O:,$<D8"0!$:3%3%#%-)W8; "!$#%&1!E:+!$1#2)0&6!$.0:,'"#%*+!$3-${G:|&74!$3%
8;  M!$#%g I 7-(32:w#%)0g(04!$0-:D'"#\*,!$3@!$3%3 G C# O:9:&8;  "!$#%&9Rcd0#%w*:!$4(0!E0-:B0-:9:
 5['O:d$<(8M0!$-:3%3\#%-)8;  "!$#\gr)#2?$:10:1!$*:6'"7#\-)HAB0-:WA:1:-<>$"8;:k!E"8 G 8;#% :8;5i!$
0-:k'"#%*+!$3^-${G:|[7!$3%K8;  "!$#\g9R
$ :$N^0`A:9?$:9NO0!EKA:k)$:9b*,$:6'4"7#%)AB0-:iA:!$CC
0-:dC74!$3[${G:|&7!$3\8;  "!$#%& I 7w$0-:V'"#%*,!$3@-${G:|[7!$3%8;4  "!$#%& MRcd0#%w#%wC# :9:&
 K'O:9"*67!E#2 AB0-:9:V-:#20-:9J0-:V!$CC#2#%1$<0:'4"#%*,!$3&-$ 0:VC47!$3&${G:|&7!$3\J8;4  "!$#%&
 ,0-:68"0!$:3%3%#%-)H8;  M!$#%gD)!`?$:k*,$:.'"74#%-)-R







=



sx 
u



I



JXu7J QRJ:t:[uF8N*Q*HKJlWPYH>Z9v [4]



! 
	  ,* - 7 
	 - 7 
	  ,*

	

fi 

Qs e



-

!

65



c ]0`A jSB
SB ;N8;#\C-:9r!$x#% :8;#2W'" I 32:* AB0 :1'M#%*,!$3ff!$3%3 G C4# :9":g

8;  M!$#%gl#% KSBbR @7-''O :}0-:x8M0!$-:3\3%#%-)Z8; "!$#%& I :9 A:9:
1!$4C xA!$l-$fSBbR
cd0-:
d#%.:91  x!$C ]0!$ B:3%#%*+#%!E :CQ<>* #%.C-*,!$#%^R V7-60#%.#%1-$1'O# I 32: I 5
0-:+8;4  "78;#2X$<V0-:+'"#%*,!$3w!$CQC47!$3*@C-:3 R r:8;:,0-:+8M0!$-:3\3%#%-)l8;  "!$#\g.!E":+!$3%3
SBbR cPf0-`A   "#%8;:9N48;"#%C-:9B!$m#% :8;#2W' I 32:* #%WAr0#%8"0

,!$C
*
(
1

RDcd04#%V#%dSB

7
V



$


K
B
S

R
I
*
(
1
/
c Q0-`A SB
SB
N(7-''O :+0!EH0-:f8M0!$-:3\3%#%-)}8;4  "!$#%&H!E:WSBbRV#%C-:9H!
 >AB0-:9:
 *k7 d0!`?$:.0-:
-${G:|[7!$3%d8;4  "!$#%&9N


04!EB#%D-$dSBbR  A.N
!$C
!$*:H#%)32:9 mC*,!$#%ffN  R1#%C:9B0-:H8"0!$4-:3%3%#%)+8;  "!$#\g I :9 A:9:
/!$C
&RKcd0-:
325lSB ?E!$3%7-:j<>$ 6#% R @#%*+#%3%!E"325$N[0-:j3%5fSB ?!$3%7:j<a$ 6#\W0-:.8"04!$-:3%3%#\-)8;  "!$#%&
k#% -R V7-
 -R B:48;:$N
H0!$B-+SB ?E!$3%7-:R/cd0#%D#\d!,8;& "!$C#%8;#2m!$
I :9 A:9: 1!$C
0-:18M0!$-:3\3%#%-)8;  M!$#%gb!E:1SBKR r:8;:6!$3%3P-${G:|&74!$3%B8; "!$#%&B!E:kSBbR `A 7-''O :
0!EK0-:-${G:|[7!$3%j8; "!$#%&b!E":HSBKR^V#%C-:9K!l8"0!$4-:3%3%#%)]8;  M!$#%g I :9 A:9:
!$C
k04!EK#\b$KSBKROcB0-:
/#%K :9K  W!$C 0!$ D:3%#%*,#\!E :Ci<>* #2KC-*,!$#%^R 7r<>$
  I :j:3%#%*+#%!E :Cf<a"* 0-:.C-*,!$#\W$< $N *,:.$0-:9B'4"#%*,!$3 ?E!E"#%! I 32:$N-!`5
6AB0-:9:
 "N4#%
 :9  N@AB0#%8M0,:3%#%*+#%!E : k<>*q0-:bC*,!$#%,$<
=#%48;:r0-:b-${G:|[7!$3%V8;  "!$#\g!E:KSB MR
r:8;:$N^#2K#%r$r'O# I 32:. W :9 /  i!$C H0!$ V:3%#%*,#%4!E :C}<>* #2KC-*,!$#%ffRKcd0[79NO!$3%3
8"04!$-:3%3%#\-)k8;4  "!$#%&B!E:.SBKR('

@B



c|



J]

z

c)

+e

65

] Y[] Y ] Y ] Y >1K{`~{`
7
*
<@ B Y , @ 
z Y | 
G
%]7^ Sz 
@ ]4^ q| ) Sz Y | e
]4^

@B

]

@ Y @ Y[@ Y >1K{`



=

]7^

@ B

@
@B

=

e

]

@B

|

e

u


	

  s  x 

fi 



n|



+|

M]

H@B /|

]

Bz

@Bq

]

]4^

Bz

@^

9)

@ B

G Y%z

z

S

JXu7J QRJ:t:[uF8N*Q*HKJlWPYH>Z9v [4]


! 
	  , * - , * 7 	 - , * ! 	 - 7 
	  ,*


!

- , * N@8;4#%C-:9D!$i#%K5{:8;#2f'" I 32:*qAB0#%8M0f#\ jSB R@7-''O :
]4BP!$C ]bAV!$$SBbR@cd0-:^N&#%]0-:b_" 89!$ :$N<];B Y ] Y>G

SB 
Qs e c ,0-`A jSB
0-:K-${G:|[7!$3O8;  "!$#%& I :9FA:9:

88

fi 8-
	fiffff

G Q o I 1
@^ Y |  ] OY"G

@^ Y z R];B Y G

!$C
ENJAB0#%8M0Q#%.#%*'O"# I 32: I :89!$7 :,0-:]8"0!$:3%3%#%-)W8; "!$#%&
r#
!$C
# 
!E:QSBbRz{ 0-:x:8;C 89!$ :$N
A73%C I :x)$:!E :9W0!$ NdAB0#\8"0
#%H#%*'O"# I 32: I 5n8;4  "78;#2 $<r0-:W'"#\*,!$3!$4C C47!$3V*[C:3 R r:8;:i!$3%3 I #%!E"5Y-${G:|[7!$3
8;  M!$#%g]0-:KC7!$3?!E"#\! I 32:/!E":bSBbR@c k0`A   "#%8;:9N@8;#%C-:9V!$f#% :8;#2]#\,AB0#\8"0

N
N !$C
Rrcd04#%d#%rSB 
*
(
1
*
( 
1
/
3 

I 7-d$ KSB R
c k"0-`A SB 
SB  N I 5,*,-$ #%89#2F5$N@A:b0!?$:jSB 
SB  Rc k"0-`A   "#%8;:9N
8;#\C-:9j!$Z#% :8;#2x' I 3%:* #\mAr0#%8"0

NJ!$4C

N
*
(
1
*
(
!$C
 Rcd0#\#\dSB  I 7-D-$ KSB  R
1
/
c Q0-`A SB 
SB
N(7-''O :+0!EH0-:f8M0!$-:3\3%#%-)}8;4  "!$#%&H!E:WSBbRV#%C-:9H!
-${G:|[7!$3%d8;4  "!$#%&9N
  >AB0-:9:

04!EB#%D-$dSBbR  A.N w!$C .*k7 d0!`?$:.0-:
!$*:H#%)32:9 mC*,!$#%ffN  R1#%C:9B0-:H8"0!$4-:3%3%#%)+8;  "!$#\g I :9 A:9:
/!$C
&RKcd0-:
325lSB ?E!$3%7-:j<>$ 6#% R @#%*+#%3%!E"325$N[0-:j3%5fSB ?!$3%7:j<a$ 6#\W0-:.8"04!$-:3%3%#\-)8;  "!$#%&
k#\ -R V7-  R B:8;: H0!$b-+SB ?E!$3%7-:9RDcd0#\d#%B!]8;g M!$C#%8;#2x!$
I :9 A:9: 1!$4C
0-:8"04!$-:3%3%#\-)+8;  M!$#%gj!E":HSBKR r:8;:,!$3%3J-${G:|[7!$3%j8; "!$#%&j!E:SBbRffcPW0- A 0-:
:9?$:9":$N7-''O :r0!EV0-:j-${G:|&74!$3%D8;  "!$#\gV!E:jSBbR4"#%C-:9V!k8M0!$-:3\3%#%-)k8;  "!$#%&9N
+# 
N@0!Ed#%V-$DSBbR-cd0:ffN@:#20-:9 J#%V :9V  +!$C j04!$ :3\#%*,#%!E :C]<>* #2
C-*,!$#\ffN$$ B#% :9 
!$C
O0!$ 1:3%#%*,#\!E :Ck<a* #%(C-*,!$#%^R V7-9Ng<>$ ^  I :V:3%#\*,#%!E :C
<>* 0-:C-*,!$#%m$< $Nff *:H$0-:9j'M#%*,!$3^?E!E"#%! I 32:$N "!5
AB0:9:
 N^#%K :9K  -NffAB0#\8"0
AB#%3\3ff:3%#%*,#\!E : f<>* 0:kC-*+!$#%i$<
=#%48;:10-:H-${G:|[7!$3%b8;  "!$#%&K!E:HSB MR r:8;:H#2
 0!$ V:3%#%*+#%!E :Ci<>* #2KC-*,!$#\ffRro-$    I :H :9b 
#%b-$K'O# I 3%:j l:9
  W!$C
N(!$3%30-:f$0-:9H?!$3\7-:6*k7  I :+:* ?$:C <a"* #2kC-*,!$#\ffN I 7-10:9:f#\6-mA!`5Y x:* ?$:
!$&5i$<0-:1?E!$3%7-: I #2)$)$:9b0!$ Z<>* 0:kC-*+!$#%i$<  N I :89!$74 :6!EK* rA:H0!?$: Y'4"#%*,!$3
?E!E"#%! I 32:RwcB0&7N!$3%3ff8"0!$4-:3%3%#%)k8; "!$#%&B!E:1SBKR '

@G

#o

e

65

@ Y @ Y @ Y >1K{` L] Y ] Y >1K{`~{`~{YM{`"
] Y ] Y ] Y :M{`"
- ,*

- ,* ! - ,*  ! 65
@ Y @ Y @ Y >1K{`
X] Y ] Y >1K{`~{`~{Y
] Y ] Y :
@

- ,*
- 7
*,
<@B Y @ +
z Y |
@
= @B
G
@ B
4] ^
%]7^ Sz 
]7^
@ ]7^ n| S) z Y | Se `]4^
@e

@BLY | ] %
Y z
A]
|

*]

9z

a@B

|

]

u

	

sx 

fi 



)

nz

G Y z

@^

-z

]

+|
S e

Bz

]

!o



]

|

@B

@ B +|

z

@B

mo

JXu7J QRJ:t:[uF8N*Q*HKJlWPYH>Z9v [4]


! 	 - 7 
	  ,*

Qs e c m0`A j SB ! SB - NJ8;#%C:96!$Y#\65{:8;#%Z#%QAB04#%8"0@ * Y @ ( YF@ 1 Y >1K{`N
@ / Y	>1K{`~{`~{YM{`"N ] * Y ] ( Y >1K{`~{`~{YM{`"N!$CX] 1 Y ] / Y ] 3 Y :M{`"Rkcd04#%r#\ jSB -  N
 SB R
I 7-d$ K
c Q0-`A SB - 7
SB * N(7-''O :+0!EH0-:f8M0!$-:3\3%#%-)}8;4  "!$#%&H!E:WSBbRV#%C-:9H!
,
-${G:|[7!$3%d8;4  "!$#%&9N<@ B Y  @  >AB0-:9:z Y  |04!EB#%D-$dSBbR =  A.N@ B !$C @  *k7 d0!`?$:.0-:
!$*:H#%)32:9 mC*,!$#%ffN  
G R1#%C:9B0-:H8"0!$4-:3%3%#%)+8;  "!$#\g I :9 A:9:@B/!$C ]4^&RKcd0-:
325lSB ?E!$3%7-:j<>$%]76
^ #%SzR@#%*+#%3%!E"325$N[0-:j3%5fSB ?!$3%7:j<a$ ]76^ #\W0-:.8"04!$-:3%3%#\-)8;  "!$#%&
@ 1!$4C]7k
^ #\n|-RS)V7-zY  |RSeB:8;:`]4H
^ 0!$b-+SB ?E!$3%7-:9RDcd0#\d#%B!]8;g M!$C#%8;#2x!$
I :9 A:9:
@e

0-:8"04!$-:3%3%#\-)+8;  M!$#%gj!E":HSBKR r:8;:,!$3%3J-${G:|[7!$3%j8; "!$#%&j!E:SBbRffcPW0- A 0-:
:9?$:9":$N7-''O :r0!EV0-:j-${G:|&74!$3%D8;  "!$#\gV!E:jSBbR4"#%C-:9V!k8M0!$-:3\3%#%-)k8;  "!$#%&9N
+# 
N@0!Ed#%V-$DSBbR-cd0:ffN@:#20-:9 J#%V :9V  +!$C j04!$ :3\#%*,#%!E :C]<>* #2
C-*,!$#\ffN$$  #% :9 
!$C
0!$ 1:3%#%*,#\!E :Ck<a* #%(C-*,!$#%^R V7-9Ng<>$ ^  I :V:3%#\*,#%!E :C
<>* 0-:C-*,!$#%m$< $Nff *:H$0-:9j'M#%*,!$3^?E!E"#%! I 32:$N "!5
AB0:9:
 N^#%K :9K  -NffAB0#\8"0
AB#%3\3ff:3%#%*,#\!E : f<>* 0:kC-*+!$#%i$<
=#%48;:10-:H-${G:|[7!$3%b8;  "!$#%&K!E:HSB MR r:8;:H#2
#%b-$K'O# I 3%:j l:9 (  W!$C H0!$ V:3%#%*+#%!E :Ci<>* #2KC-*,!$#\ffRro-$ k  I :H :9b 

@BLY | ] %
Y z
A]
|

*]

9z

a@ B

@B +|

@B

|

]

|

@^

@B

]

)

nz

G Y z

-z

]

Bz

8%)

+|
S e

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



zN(!$3%30-:f$0-:9H?!$3\7-:6*k7 

? :C <a"* #2kC-*,!$#\ffN I 7-10:9:f#\6-mA!`5Y x
 :* ?$:
I :+:* $
! &5i$<0-:1?E!$3%7-: I #2)$)$:9b0!$ Z<>*  0:kC-*+!$#%i$< $N I :89!$74 :1A:k04!?$:H!Eb* Y'4"#%*,!$3
$
?E!E"#%! I 32:RwcB0&7N!$3%3ff8"0!$4-:3%3%#%)k8; "$
! #%&B!E:1SBKR '

7a 

Dx

  w}


 x

]

!o

o

t2sw  {



cd0-:H'":9?[#274B:"732K8;*'4!E:0:HC4# :9":gK*@C-:3%bAB#20x: 'O:8;K W0-:!$*7&K$<'4"7#%)
!$8"04#2:9?$:CffRDyQ:689!$^N4<>$r:;p-!$*'432:$N-`A "732:j7B!+*@C-:3 3%#2L$:

* +AB0-:W:<a$"89#\-)+SB #%8;:
A:,)$:9 7 .!$6*6748"0Z'4"7#%)f!Ek32:.8; 6Z0-:]*[C:3 * R r`A:9?$:9N0-: :,":732.C}-$
C#%#%-)7#%"0 I :9FA:9:^N!5$N!b*@C-:3AB#%0.'"#\*,!$3-${G:|[7!$3%w8;  M!$#%gN$!$&5j$<0-:V8;* I #%-:C
*@C-:3% * N ( $ 1 RyQ:j)$:9D0-:j!$*:j'4"7#%)1#%l!$3%3 <a7RwyQ:.89!$i!$CCl *:.C-:9!$#\3% k0: :
:7432 I 5l8;*'4!EM#%-)0-:1!$5[*'4 $#%8 I :0!?@#27-R

NY

S5





le





P



$

+Ro ' 

so

(
( MNAB0-:9":
cd0:+:3%!E#%?$:f8; k$<B!$8M0#2:9?@#%-) jSB
#% 
#\10-:f&74* I :9k$<D?!E"#\! I 32:
1 /#%*:$R B A:9?$:9`N I 5
!$C
#\/0-:#%C-*+!$#%]"# 9:$R(SB 9N@SB  N[!$4CfSB  !$#2?$:3%5,!EL$: 
!EL@#%-),!$C-?E!$g!E)$:6$<w0-:j<>748;#2!$3ff!E7:j$<8"0!$:3%3%#%-)H8;  M!$#%gNA:.89!$}:C78;:j04#%V 
( b<>$

r<a$ * RyQ:]' ?$:CZ#%Qcd0-:9$":*
0!E jSB
SB
( !$C
1 !$C 
(
(
(
SB
!$C}0:#2j8; j!E: 
MN 
MNff!$
C 
d: 'O:8;#2?$:325$R.Sb 5@*' $#%8k!$!$325&G
#%10-`Arj0!E1:<a$"89#\-)iSB
0!$6!$ 5[*,' $#%89!$3%325X3%#%)0g325x*$:+8;10!$Q:<a$"89#\-)iSB
R
r`A:9?$:9N0!?@#%-)10-:bC47!$3-?E!E"#%! I 32:8;73%C I :r!$C-?!$&!E)$:97D#%+8; 748;#2,Ar#20,?E!E"#%! I 3%:B!$C
?E!$3%7-:+$MC-:9"#%-)x0-:7-"#\ #%899RWyQ:W!$3% x' ?$:C #%Ycd0:9$:*
i0!E KSB
SB 
SB
(
( MN 
( MN 
( MNP!$
( B:' :8;#%?$:325$R6Sb 5@*'-G
SB
!$Cx0-:#2.8;.!E: 
C 
 $#%8]!$!$325@#%1"0-`AB10!E10:]8"04!$-:3%3%#\-)W8;  "!$#%&k!E:]*$":]8; 325Q04!$Z0-:f-${G:|&74!$3%
8;  M!$#%g1!$C I "#%)]-i*$":'"7#\-)-Rjy 0:QA:,!$C4CQ-${G:|&74!$3%j8;  "!$#\gjX0:,C7!$3
?E!E"#%! I 32:N[0:.`?$:9"!$3\3P!$ 5@*' $#%818; B#%d#%3%3 0-:1!$*,:.!$d0-:18M0!$-:3\3%#%-)H8;  "!$#\gr!$32-:$N
I 7-BA:H!$8"0#%:9?$:k*$":1'"74#%-)-RzFb#%d0-:9":9<a$:H!+*,[C-:3PA$"0m8;"#%C-:9"#%)-Row#%!$3\325$N4#%mcd0-:9EG
(
( MN 
( MN4!$C
:*
A:.'4`?$:C}0!E KSB
SB 
SB
!$Cl0:#2B8; r!E	
: 
(

: 'O:8;#2?$:325$RSr)!$#%ffN&!$5[*'4 $#%8d!$!$325@#%/0-`Ar(0!E8"0!$:3%3%#%-)j8; "!$#%&/!E:b*$:
8; 325]0!$f0-:j-${G:|[7!$3%D8;  M!$#%gD!$4C I "#%-)k-k*,$:K'"7#\-)-RJ~m!$#%&!$#%#%-)k)$:-:9"!$3\#% :C
!E"8 G 8;"#%  :8;5lW0-:6!$3%3 G C# O:9:&D8;  "!$#%&B#%D!E)!$#\W0-:1*B8; 325$R

+RoZ' 

,*

7

e

-



'



-

sRoZ'!
+Ro '  +RoZ'!



-

+Ro '  sRoZ'  +RoZ' 



1:
+Ro 

- 7

!

+RoZ' 

ge

L

171

+Ro 



,*

7

-

65

I

1:

+Ro 

,*

- ,* !

!

-

!

,*

-

+Ro '  sRoZ' 



c Y8;893%74C-:$NV0-: :i:"732,0`A 0!E9Nd!$]*,#2)0& I :i:;p['O:8; :CffNVA:}#% )$::9"!$3d)$:9f*$:
'"74#%-)+#%<A:#%8;":!$ :60:H!$5[*'4 $#%868;9R6~i@C-:3%bA$0X8;#%C:9"#%-)f!E:H0-:6'4"#%*,!$3 -${G
:|[7!$3%1*,[C-:3N ( k
 N!$CY0-:+'4"#%*,!$3(!$3\3 G C# O:9:&1*@C-:3 R /!$8M0n)#%?$:6!xC# O:9:&1!$*7&6$<
'"74#%-)}!E!XC# O:9:&k!$5[*'4 $#%8l8; 9RZyQ:i*,#2)0&H!$3% Q8;#%C:9 * #%  :!$C $<d0:f'4"#%*,!$3
-${G:|[7!$3%*@C-:34#\8;:$NgAB04#%3% #2#%/!$ 5@*' $#\89!$3%3253%#2)0&325H*$:r:;p['O:#%?$:$N&#232:9/7 I "!$48"0
iC74!$3O?!E"#\! I 32:9R




Y

7a   sffw'x  {J



f





wu



tw}

s


  sw'{

2

yQ:1!E)!$#%i"!$W *:j:;p@'O:9"#%*:& ,:;p['32$:K0-:.#2)4#2_489!$8;:b$< 0: :j0-:9$:9#%89!$3P!$CW!$ 5@*'-G
 $#%8fC# O:9:8;:9Rmc ! I 3%:
])#2?$:k:7321n*:f#\ !$8;:6$<D0-: b32* I "7432:9".'4 I 32:*
7#\-)!+ !E#%8.?!E"#\! I 32:j$"C-:9M#%-)-R/cd0:j:;p['O:9"#%*,:gd!E":6!E)!$#%m8;#%  :&dAB#%0l0-:10-:9$":9#%89!$3
:74329RDow#2" 9N:-<a$M89#%-) jSB x!$m!$3\3 G C# O:9:&B8;  "!$#\gb!$8"0#2:9?$:b0-:k* r'"7#\-),!$C
0!$w0-:d"*,!$3%32: w"74g#%*,:9R [:8;4CffNH0-: :D'4 I 32:*,w#%4 !$8;:9N:<a$"89#\-)jSBn0-: I #%4!E5
-${G:|[7!$3%8; "!$#%&!$8"0#2:9?$:(0-:D!$*:d!$*7&w$<4'M7#%-)b!$*,!$#%&!$#%#%)rSBnH0-:D8"04!$@G
-:3%3\#%-)]8;4  "!$#%&9RHz Q!$C4C#2#2ffNff:<a$"89#\-)WSB Q0-:,8M0!$-:3%3\#%-)]8;4  "!$#%&j!EL$:13%-)$:9



6

!171



E



8r

fi 8-
	fiffff


 l
 !$8"0#2:9?$:$Rbcd0#2MCffN!$CC#%)0-:68M0!$-:3%3\#%-),8;  M!$#%gr f0-:1'M#%*,!$3^!$3%32G C# O:9:gr8;  "!$#%&
C-[:d-$B#\8;:!$ :j'M7#%-)-N@!$Ci*,:9:325]!$C4CD`?$:9M0-:!$Ci ]0-:j"7&#%*:$R

*@C-:3



(

0-:7-"#%#%8
 !E#%8
 !E#%8
 !E#%8
 !E#%8

Y


(





<=!$#%3%

aT0

143K
143K



c

ff

:8ER

<<

3@Ri3$
3@Ri3$
3@Ri3$

+171 < =

cJ! I 32:

b32* I V 0[N 7 b32* I d 143@Nk"7"$ K32* I d 171ENw,K$

V. k6

K32* I [N
<=!$#%3%
 :8ER

e 

1717143
1717143

3@Rk7.
3@Rk6
3@Rk7&

<<

I



ffff



ffff

<>!$#%3\

 :8ER

W

,~1:7
,~1:7

 efiff

<>!$#%3\

[R >&
[Ri3$
[Rw,K&

 



 



 :8ER

$,r$3K
$,r$3K

7[Ri3$
K@3 Rk7
18&, Rk0$,



7 * I :9b$< I !$8L[ "!$8"L[ ><>!$#%3\ d!$4CX"7#\-),#%*:H W_44C}0-:_4" K 3%7-#2x W

 <>7-
#\ !$8;:$<J0-: b32* I "732:9"'" I 32:*WR B74g#%*,:!E":b<>$Dz
[3%?$:9 [R 
~
$N J:&#%7* zz"z/'@8;: $`N!$C
,~
$< BSK~ZR



1:K373 !e  _

7aT 
{t2x]w}Qt$sffwt$l  {ff
Qt2 ff


*@C-:3

Y

0-:7-"#\ #%8
>'
>'
>' KC
>'
=C
( >' KC
( >'
( =C
>' KC
>'
=C
( >' KC
( >'
( =C

(

jx/ 
jx/ 
jx/ 0I 
jx/ 
jx/ 
jx  0I 
jx  
jx  
jx/ 0I 
jx/ 
jx/ 
jx  0I 
jx  
jx  



(


(


(


(


(


(


(


(


(


(




(

+1:E< =

cJ! I 32:

,



y



sww}

b32* I d 171ENw,K$

3 i3$&
3 i3K

7.j143
7&770
K3M143
7.j143
777
K3$7
>67
76>

.K373M1:&70
"7&7K3M171
07.7
.K373M1:&70
1:7"6
07.6
.707.6>"$,
1:6,
"707.
"7&7K3M171
&K3$"

<=!$#%3%

3@Ri3>,

eW
3@Ri3M1
3@Ri3$&

7

 W
e
eW

7

 W
e
eW

<=!$#%3%

3 k07&
3 w,K"
3 k"$,
1 \1:
3 k&j1
3 k"7.
1 \1:.
3 k&K3
3 7
1 \143
3 7

7&770
0K3$&
0j1O
K3$"6
0K3$0

3@Ri3>,
3@Ri3M1
c

 :8ER
@R
@R
@R
ER
@R
@R
ER
@R
@R
ER
@R



3@Ri3>,

7"6
171


  sw'{

b32* I V 0[N 7 K32* I d 143@Nk"7"$

eW

77.
171

s

" kK373

V. k6

b3%* I [N
<=!$#%3%
 :8ER
@R
@R

77&
77.
171
77&
1:
1:
77"
1:



d v2


,

X"j1: !)

"K3$"77&
7$,63$"
77.7.
"K3$"77&
7.77
7$,r
"$,~1:"7.
70j171



eT 
1ER\18,

eT 

I

ff

7$,63$"
143$.$,
171:7"
70j1O>
171:j1

 : 8ER
[R
[R
@R
@R
@R
@R
ER
@R
@R
[R

1:& k&$,
:1  \1:
3 k.7&
K3 >
3 k0K3
3 k.7&
j1 k"6
3 k0j1
3 k&7&
1:0 k7

afiff

3 Rk&70
@
j1ERkj1
3 Rw,63
@

<=!$#%3%



&7&77.707&
"707

 :8ER
[R
[R
@R
[R
@R
@R
ER
@R

7"7 k.
7&7& k"7
3 >.
 1:. i3$
3 k"7
3 >.
7 1 \1:"
3 k"j1

a 

 :1 0[R >"
3 R 7
@
3 R 7
@
>"7[& Rw,K"
3 R 7
@

7 * I :9b$< I !$8L[ "!$8"L[ ><>!$#%3\ d!$4CX"7#\-),#%*:H W_44C}0-:_4" K 3%7-#2x W

 <>7-
#\ !$8;:$<J0-: b32* I "732:9"'" I 32:*WR B74g#%*,:!E":b<>$Dz
[3%?$:9 [R 
~
$N J:&#%7* zz"z/'@8;: $`N!$C
,~
$< BSK~ZR

1:K373 !e  _



,

X"j1: !)

d v2


,

65

" kK373

yQ:x!$3% Z:;p@'432$:C 0:}!$C-?E!$g!E)$:x$<b*k732#%'432:l?[#%:9Ad'O#%gH$<K#% :8;#2 '4 I 32:*,H<>$+C-5&G
!$*,#\8r?E!E"#%! I 32:j!$Cl?!$3\7-:K$"C-:9"#%)k0-:7"#% #%89RJz{WcJ! I 32: [NA:j)#2?$:.:7432<a$ K32* I "732:9

/1:

8#b



fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff





' I 32:*,9RryQ: I  :9?$:k0!EK0-:k'"#%*,!$3 !$3%3 G C# :9:&r*,[C-:3J#%b-$j8;*'O:9#2#2?$:kx0-:k3\!E)$:9
' I 32:*,9RKcd0-: I :r"74g#%*,:r!E:H I !$#\-:CxAB#20m0-:k8M0!$-:3\3%#%-)+8;4  "!$#%& =!$CQ!+'4"#%*,!$3
!$3%3 G C4# :9":gd8; "!$#%& D7#\-)0-:6"*,!$3%32: dC*,!$#%i$r0-:6C7 I 32:.*+!$3%32: BC*,!$#%i0-:7"#% #%8
 I $0] :9($<ff?E!E"#%! I 3%:$/+0-:rC74!$3-?!EM#%! I 32:9R :#%-).<>$"8;:C+  I "!$48"0, 74 (0-:d'4"#%*,!$3
?E!E"#%! I 32:10&7-".0-: I "!$8M0#%-)i0-:7"#% #%8ERfS C7!$3?@#2:9Ad'O#%&.!E''O:!E"j x O:960-: I "!$8M0#%-)
0-:7-M#% #%8r?$:95W#2)#%_489!$gd!$C?!$&!E)$:Bi0#%V' I 32:*WR



I

*,[C-:3

Y

(


(


(


(


(


(


(


(


(


(


(




(

E)

0:7-"#% #\8
>'
>'
>' KC
>'
=C
( >' jC
( >'
( =C
>' KC
>'
=C
( >' jC
( >'
( =C

Mx @
Mx @
Mx I 
Mx @
Mx 
Mx  0I 
Mx  
Mx  
Mx I 
Mx @
Mx 
Mx  0I 
Mx  
Mx  

+1:E< =

cJ! I 32:

/



8,7

1O
O1 

O1 

aW
aW
aW
aW
aW
aW
aW
aW
aW

@' $"
<>!$#%3\
 :8ER




O1 


O1 



3@Ri3M1


1O


aW
aW
aW
aW

/

I



K

8V0$

['O$
<>!$#\3%



1:" k7
:1 & \:1 

>7.$,7,

aTff

1:.770707"6
0j143$7&7

7&7.[Rw,K
1:.7[" Rk&7

1:7"77&7"77

18,K.$,&Rkj1
0 Ri3$"
[

3 Rk&$,
@
18,&Rw,~1
1 Rk7&
E

aTff



K3@Rk$,
3 Ri3$
@
3 Rk6
@
K@3 Rkj1
3 Rk"7
@

K3M1:
1O>7j1:
777.

 :8ER

aTff

18,&Rkj1

ff

8d1718

@' $"
<>!$#\3%

 : 8ER
[R
[R

1O$3$7.$,
1:7.7&6>
6
1O$3$706
7
>"77"
1O>707.70
171O>6
7.
1:7.7&6>

5

T

a



$,r>.770
&K373$&7.7&

K, .[Rk"7
1:"j1ER\1:0

1:.7"6$3$.7

>j1ER\1:0

7* I :9D$< I !$8L[ "!$8L@ ><>!$#%3\ !$CW"74#%-)k#%*:1 ,_4CW0:._" d3%7-#2l ]0-:9:
#\ !$8;:K$<V 'O$.8M0-:C73%#\-)]'4 I 32:*WR B74g#%*,:j!E:<a$1z
[32?$:9 [R }
~
$N J:g#\7* zzzO'@8;: $N!$4C
j~ Y$< BSK~ZR$S C!$"06*:!$4Jb 3\7-#2
#\V<a74CW!E<a :9 .0-7-R

1:K373 !e  _

'1:



m"j1: !)

m1



Ev2 

" kK373

z{ncJ! I 32:
[N(A:])#%?$:]:"7326<a$H0-:l 'O$6"8"0-:C743%#%-)i'4 I 32:* AB0-:n0-:9:l!E:f!$ @CC
[7* I :9H$<bA:9:9L@9R b: '4#2 :W0-:W<=!$8;,0!E,#%H04!$H0-:i  -)$:,'$'4!E)!E $`N0-:l'M#%*,!$3V!$3%3 G
C# O:9:&d*@C-:3^#%d$B8;*'O:9#2#2?$:j}0-:13%!E)$:9B' I 32:*+9R(cd0-: I : DM7g#\*:D!E:1 I !$#%-:C
AB#20,0-:B8"04!$-:3%3%#\-)j8;  "!$#%&/!$4C I "!$48"0#%)j,0-:d'4"#%*,!$3@$C7!$3-?E!E"#%! I 3%:DAB#20,*+!$3%32: 
C-*,!$#\ffR SrAr#20 0-: b32* I "7432:9H' I 32:*iN I :#%-)X<a$M8;:C   I "!$48"0  7 0-:W'4"#%*,!$3
?E!E"#%! I 32:10&7-".0-: I "!$8M0#%-)i0-:7"#% #%8ERfS C7!$3?@#2:9Ad'O#%&.!E''O:!E"j x O:960-: I "!$8M0#%-)
0-:7-M#% #%8/?$:956#%)#2_489!$& !$C-?E!$&!E)$:H0#% ' I 3%:*WR
$ :d!$3% K0!Ewk0-:D3%!E)$: #%4 !$8;:$N
0-:,*+!$3%32: j :!E"8M0Q :9:+#\K I !$#%-:CXAB#%0m0:,8"0!$:3%3%#%-)l!$CX0-:,!$3\3 G C# O:9:&K8;4  "!$#%&9N
I "!$48"0#%)Z 0:}'"#\*,!$3D$lC7!$3d?E!E"#%! I 32:iAB#20 *,!$3%3%: ]C-*+!$#%ffR c n8;893%74C-:$NdC-5@!$*,#%8
I "!$48"0#%)l0:7-"#% #\89b89!$n!E)!$#% I :,#2)4#2_489!$&325m*$":: :8;#2?$:]AB0-:X0-:95Q32[$LX!E I $0Q0-:
'"#\*,!$3O!$CiC7!$3O?@#2:9Ad'O#%&9R



x

#

K

=



O

8

5

fi 8-
	fiffff

 Rfi?  R

	^	ff


$C

a

Md1:07070$

o

V0-:)b:9(!$3R
( 7C#%:C6*@C-:3%3\#%-)r!$4Ck32?[#\-)r0: OG |&7-:9:4 '4 I 32:*WN!$4Ck!j[7-": :9 G
%# -)1' I 32:*q7#%).8"0!$:3%3%#%-).8;4  "!$#%&9R(cd0-:950`A 0!E8M0!$-:3\3%#%-).8; "!$#%&#%48;:!$ :
0-:j!$*7&D$<w8;  "!$#%&V'$'4!E)!E#%ffR(cd0-:95f8; {:8;7:j0!ED0-:K`?$:9M0-:!$CB!$" [89#\!E :ClAB#20
8"04!$-:3%3%#\-)+8;  M!$#%grAB#%3\3ff'4!5} Yx' I 32:*+dAB0#\8"0i":|&7#%:13%!E)$:H!$*7&b$</ :!E"8M0ffNO$
32:!$Cl 0-M!$0#%-) I :0!?@#27-`RwcB0-:95]!$3%H"0-`A 0!Ed8M0!$-:3\3%#%-)H8;  "!$#\gV$'O:l0-:jC-[$D 
#%& :9: #%)]?E!$3%7-:H$"C-:9M#%-)l0-:7-"#%#%899Rjo-$.'O:9"*k7-!E#2x' I 32:*,9NO!W#%*,#\3%!Er#%C:!]AV!$K':9?@# G
73%5+'$'O :C I 5 b:9:32:
MR

65

K

+



d1:0707$

VK373$$

V0#-!$C ^:9:
(<>[897:C0-:d 74C-51$<ff8;* I #%-:C*@C-:3%w$< 'O:9"*k7-!E#2H' I 32:*,9R
c 0-:#%J 74C-5.#%893%74C-:C1-$J325j0:'O:9"*k7-!E#2k8;  M!$#%gN I 7-w!$3% K!$3%3g0:$0-:9(8;4  "!$#%&
d
$<V0-:,'" I 32:*WRcd0-:#%.8;*'4!E"#%Z*:!$7-":+#%j!$Z:;p@ :#%Q$<V0-:'$'4!E)!E $H8;*'4!EM#% 
!E''"!$8"0k$< @8M0&73% :!$C [78"L$:95
MNgAr0#%8"06*:!$7-":P0-:VC# O:9:& 8;* I #%-:Ck*@C-:3%PAB#20
: 'O:8;6 m0-:#%k! I #\3%#2 5x x'"7-:+0-:] :!EM8"0  '4!$8;:fAB#20n8;  "!$#%&1'4$'4!E)!E#2ffR B A:9?$:9`N
0-:#2r*:!$7-:6#%d#%C:9' :4C-:gV$<w0-:13%:9?$:3^$<8;#% :8;5W*,!$#%&!$#%-:CWW0:68;  M!$#%gr!$C
C-:9'O:C 7-'O10: :9w$<48;$":8;'$'4!E)!E $M#%  :!$CffRJcd0-:95.0:9$:9#%89!$3%3256C#%8; ?$:9J0:V8;M#2 :9"#%!
7C:9fAr0#%8"0 *,#\#%*,!$3b8;* I #%-:C *@C-:3%l0!`?$:Z0-:Z!$*:Q'4"7#%)Y'O`A:9}!$l<=73%3K8;* I #%-:C
*@C-:3%D!$Ci:*'4#2"#\89!$3%325,C-:*4  "!E :.0-:1:732V}C# O:9:gD'O:9"*k7-!E#2l'4 I 32:*,R



/

)

fiVK373$$

cVK373M18



e

O



V!$898"0[7:9/!$3 R
(<a$M*,!$3%325k 7C#2:Ck0-:B: :8;#2?$::/$<  A6*,[C-:3\3%#%-)r :8"0#\|&7-:(0!E
 " !$<a$"* !r@G I #%!E"5j }#%& r!$6:|&74#2?!$3%:g I #%!E5. JN`4!$*:325$NE0-:C47!$3 "!$4 <a$M*,!E#2
!$CY0-:]0#\CC-:X-:$RiSbZ$"#%)#%!$3(*@C-:3$<D0:+' I 32:*WN #%1C7!$3/!$CY#260#%CC:X "!$ <>$ G
*,!E#24k!E":l8;*,'4!E:C AB#20n: 'O:8;H X0-:l'O:9<a$M*,!$8;:+$<b!X&7* I :96$<b32@89!$38;4#%  :8;5
 :8"04#%|[7-:,#%893\7C#%-)X!E"8 G 8;"#%  :8;5$Nd!$C AB#20 : 'O:8;, n0-:}8M0--32$)#\89!$3 I !$8"L& "!$8"L[#\-)
!$32)$$"#%0*WNo bN!$Ci~}SBKR

)

SM_

Sj_

d1:07070$

$:9K!$Cxcd!$-)
bC-:9?$:32$'O:Cm!+<>"!$*:9A$Li<>$b5[  :*+!E#%86*,[C-:3J :32:8;#%ffRBcd0-:95
C-:*4  "!E :C 0-:#2!E''4!$8"0  0-:W:9?E!$3%7!E#%n$<b!$CC#%)x!X8;:9!$#% 893\!$H$<r#%*,'43%#2:Cn8;@G
  "!$#\gk Q!$ $"#2)#%!$3*@C-:3 RQcd0-:f:9?E!$3%7!E#2 0-:7-M#% #%8,74 :C #% I !$ :C  !$ :;p@ :#%n$<
0-:j0-:9$":9#%89!$3ff8;*'432:;p-#2F5+: #%*+!E :D'$'O :C I 5
!$C-:3
MRcB0-:#2V:;p['O:9"#\*:g!$3 :"732
0- A 04!EB0-:k!E''!$8M0m#%d'*,#%"#%-)-R B A:9?$:9NOAB#%0W0#%r!E''!$8M0}-:k-:9:CB0-:6#%4 !$8;:
C!E!  I :.!$i:;p['43\#%89#2D#%-'47 ,0:1*:90-@C9R

=

e

fi; 
	 w


qd1:070K3>

M?

   FTE  

65

yQ:Q0!?$:x'O:9<>$"*:C !$ :;p@ :#2?$:X 7C-5 $<.C47!$3B*@C-:3%3\#%-)Q ' :9M*67-!E#% !$C #% :8;#2
' I 32:*,9Rc ,8;*'4!E:.*@C-:3%N[A:1C-:9_-:Cl!*:!$7-:j$<w8;  M!$#%gD#%)0g-:"D'4!E"!$*:9 :9M# 9:C
I 5 0:}32:9?$:3d$<.3%[89!$3d8;4#%  :8;5 I :#%-)Q:<a$"8;:C^R o-$f'O:9"*k7-!E#2 '" I 32:*,,!$4C :-<>$"8 G
#%-)m!E"8 G 8;#% :8;5$NwA:]'`?$:Cn0!Ek!}#%)32:'"#%*+!$3(!$3%3 G C# :9:&.8;  M!$#%gk#%j#2)0& :9k0!$
8"04!$-:3%3%#\-)18;  M!$#%gN I 7/0!ED8"04!$-:3%3%#\-)18;  M!$#%g!E:K#2)0& :9V0!$+'4"#%*,!$3-${G:|&74!$3%
8;  M!$#%gRrcd0-:k:!$ m<>$b04#%BC# :9:48;:6#%r0!Eb0-:6'4"#%*,!$3^${G:|&7!$3\b8;4  "!$#%&KC-:9 :8;
#%)32:9 l?!EM#%! I 32: =# R :$R-0-:j?!E"#\! I 32:VAB#20l!#\-)32:K?!$3\7-: MN-0-:j8"0!$4-:3%3%#%)k8; "!$#%&dC-:;G
 :8;(#%)32:9 1?E!E"#%! I 32: !$4Ck"#%-)32:9 6?!$3\7-: =# R :$RE0- :?!$3%7: Ar0#%8"06@89897-#%10:VC*,!$#%6$<!
#%)32:K?!E"#\! I 32: MN-AB0#\3% 0-:.'"#\*,!$3O!$3%3 G C# O:9:&D8;  "!$#%&dC-:9 :8;r)32 I !$3^8;4#%  :8;5 >AB0#\8"0
#%893\7C-:k#%-)32:9  ?E!E"#%! I 3%:9N(#%-)3%:9 n?E!$3%7-:!$4C *,!$g5n$0-:9,#274!E#2 MR o-$+32 A:9,32:9?&G
:3%D$<32@89!$3^8;"#%  :8;5 >:$R )-R04!EB*,!$#%&!$#%-:C I 5f<a$AV!E"Ci8M0-:8L@#%-) MN 8"0!$4-:3%3%#%)H8;4  "!$#%&
:*,!$#\ #2)0& :9+0!$ '4"#%*,!$3V-${G:|[7!$3%]8;  "!$#%&9R B A:9?$:9ND<>$]8;:9"!$#% 0#2)0:9+32:9?$:3%$<









r



r





%e

88



I



fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



32@89!$3ff8;#% :8;5f3\#2L$:j'4!E0W#%&?$:9" :.8;"#%  :8;5$N48M0!$-:3\3%#%-)H8;  "!$#\gd!E":1#%8;*'!E"! I 32:b 
'"#\*,!$3O-${G:|&74!$3%D8;  "!$#\g9Ro-$B#% :8;#2l'" I 32:*,9N[A:.' ?$:CW0!E9N-AB#20l": 'O:8;D ,!E"8 G
8;#\  :8;5$N!}#\-)32:'"#\*,!$3(!$3%3 G C4# :9":g.8; "!$#%&6#%1#2)0g :9k0!$n8"0!$:3%3%#%-)i8;4  "!$#%&
 $)$:90-:9AB#20k0-:dC7!$3@-${G:|[7!$3%8;4  "!$#%&9N I 7J04!E0-:D8"0!$:3%3%#%-)K8;  M!$#%g!$3%-:d!E:
!$#2)0&V!$0-:b'"#\*,!$34-${G:|[7!$3%V8; "!$#%&9R(cd0-:b!$ 5[*,' $#%8K!$!$325@#%!$3%32`A:Cl7 k":C78;:
<=7-0-:9d0:6[7* I :9r$<w*,[C-:3\d0!Eb*,#2)0& I :.A$"0m8;"#%C-:9"#%)-R (p['O:9"#%*,:g!$3ff":732Dx!
AB#%C:/"!$-)$:V$<' I 32:*+P7-'4' $" :C10-::0:9$:9#%89!$3@:74329R o$:;p@!$*'32:$N!$CC#%) I #%4!E5j-${G
:|[7!$3%.8; "!$#%&j i0-:,8M0!$-:3%3\#%-)l8;  "!$#%&1C&:.$.#%8;:!$#\-)l'"7#\-)-Nff!$CZ*:9:3%5
!$CC.`?$:9"0-:!$CY i0-:,M7g#\*:9R B A:9?$:9`N 0-:+:;p['O:9"#%*,:g!$3w:"732j!$3% iC:*  "!E :CY0-:
?$:95#2)4#2_489!$& I :-:9_4w$< I :#%)K! I 32:D  I "!$48"0 I $0'4"#%*,!$3@!$CC74!$3@?!E"#\! I 32:9RJz +*,!$g5
89!$ :9NBA:m I !$#%-:C 0-: I : ,M7g#\*:AB#20 74 +8"04!$-:3%3%#\-)Q8;  "!$#%&f!$C ! I "!$8M0#%-)
0-:7-M#% #%8r0!EB32[$L$:C}!E I $0i'"#%*,!$3O!$CWC47!$3O?[#%:9Ad'O#%gR



65

f

/e

5

y 0!E,)$:-:9M!$3B32:89!$ I :i32:!E"&<>* 0#%+ 7C-5Uow#2M 9N/0-:9":}!E:}*,!$&5 ' "# I 32:
*@C-:3%j$<V:9?$: !}#\*'432:H' I 32:* 3%#2L$:,_C#%-)W!W'O:9"*k7-!E#2Y$6!$n#% :8;#2ffR+z{Z!$CC4#2#2ffN
-]-:6*@C-:3 #% I : B#\}!$3%3 #27!E#249RVyQ:60-:9":9<a$:k-:9:Cm f7''O$D0-:674 :9r#%m*@C-:3%3%#%)
:9?$:Q#%*,'432:j' I 32:*,9R [:8;CffNff#2r$<a :x'4!`5[b W8;  "748;r:C47C!$&r*@C-:3%rAB#20m*67432#2'432:
?@#2:9Ad'O#%&,$<10:x!$*,:m'" I 32:*WR b: '4#2 :x0-:x`?$:9"0-:!$C49Nr0:x! I #\3%#2 5   I M!$8"0  C7!$3
?E!E"#%! I 32:89!$ I :W?$:95 I :-:9_489#%!$3 R "!$48"0#%)Z0-:7-"#%#%89H0!E]8;4#%C-:9,*k732#2'32:l?[#2:9AB' #\g
89!$ I :x?$:95 : O:8;#2?$:$R cd0#%"CffND0-:Z!$CC4#2#2!$3b8;  "!$#\gl'$'!E)!E#2 ' ?[#\C-:C I 5 )32 I !$3
8;  M!$#%g63%#2L$:+!$3\3 G C# O:9:&.*,!5Z-$ 7#2<a5x0-:#2k8; 9RlyQ:]$<> :Y"!A I :9  :9k'O:9<>$"*,!$8;:
AB0-:fA:K0-:9A 7-V0-:j!$3%3 G C# :9:&8;4  "!$#%&9R(o-7-0^N-7-D*:!$7-:b$< 8;4  "!$#%&V#2)0g:
89!$ I :j7 :Cf +8;*'!E:.C# O:9:&V8;4  "!$#%&d*@C-:3%9R r`A:9?$:9N40#\*,:!$7-:.89!$l3%5+: :8;
8;:9!$#% *@C-:3% 0-: I !$"#%0!E]0-:95 !$CC  ?$:9"0-:!$CffR yQ:X #%3%3D*k7 ,M7 :;p@' :9M#%*:& 
C-:9 :9"*+#%-:j#2<P0:.!$CC#2#24!$38; "!$#%&D'$'4!E)!E#2i'`?@#%C-:C I 5+#%)0g :9b*[C:3%V#%VA$"0W0-:
8; K$</04#%r8;4  "!$#%&r'4$'4!E)!E#2ffR
32#%*,!E :3%5$N 0:k|[7-: #2 I :#%-)f!$CC-::Cm#%K8;:& "!$3J 
*,!$&5]'4 I 32:*,D#\W!E#2_489#%!$3ff#\g :3%3\#2)$:8;: 0-:j "!$C:;G
I :9FA:9:m :!E"8M0}!$CW#%<a:9:48;:$R

65



O

)







x

5

ge

<

5

K

$C  !? R4-D Rfi=0R  
)bRre 4#%8"0X!$CQcjROyZ!$3%"0Q!E:,897-:&325}"7-''O$ :C I 5 @89#2:8;:o-74C!E#2Xz :3%!$C @oJzub!$C
!$nz E2
v   $<> AV!E:f)$"!$&9R}cjR^yZ!$3%"0YAV!$6!$3\ }7-'4' $" :C I 5Z!$2fq_ d !$C-?E!$8;:Cn: :!E"8M0
<>:3%32`Ar0#2'^RyQ:k0!$-Ll0-:1$0-:9r*:* I :9"d$<w0-:kS_nff": :!E"8"0m)$7-'=0g  ' < ff AdAdA.R C89R  {G
!$CffR !$8ER 7L!E'O:I,
 <a$f0-:32'<=73DC#\897#%9N!$4C : 'O:89#%!$3%3%5Yz{!$/b:&+Ar0-Z:8;7-M!E)$:C 7+ 


Ad"#% :j0#%V'4!E'O:9R

R R$ R   R2

)V!$898"0[79NEoR2NV0-:ffN6R2N?E!$ ):9:9L Nr_JR2N ? yZ!$3%0ffN`c.RVK373$$MR~)V#%4!E5r?@9R = @G})V#%!E"5j4  "!$#%&9R
	 PbN*Q nF4Q uEvIJN};[ v>vwQ [4JFI[9N 
	  d1 G $MN-1 ~$,&R
): 5 !E`N.R2N ? ~}!$&5!@NoR VK37373>MRS[32?@#%-)H0-:."7Cl I #\]'4 I 32:* 7"#%-)H'$'O#2#%!$3O32$)#%8ER
z{  PdH8FI[`"[ sKQR
J KL HY
U   NRfi
 ff6u7N*QVHKJ uEv  H7J:U4[4PY[4JFI[HKJ 	 PbN*Q nF:Q=uEvIJN}[;v>vwQ[4JFI[9N(''^Rn7&7 ~7&7&[R
SbSbSBz (
_ ": cd0-:1~}z{ca(_ :"9R
):#V:9y :$NKR2N@~}: :9)7-:9NMJ_ R2No-:74C-:9Njdf R2NT?  !E!@N R@d1:07070$M RnK
v ]<>$A!EMCf8M0-:8L@#%-)H<>$D-@G
 !E`N-R-*/f CffRwM N  PdH8FI[`"[ sKQRJ KLcHYU $qQ UbNR IJfiN}[4PIJ u7N*Q*H7J uEv
I #%!E5}8;4  "!$#%&.!E#% <=!$8;#2ffR6z  g!6O
8 U

fi 8-
	fiffff
 H7J:U4[4PY[4JFI[pHKJ  PbQTJF:QiW v [OL,u7Js  P u$F:N*QVFI[HYU  HKJMLON*P{uKQRJfiN	 PdH $P{u7]m]QRJ   ; NP'4'^R.7.
143$[R  = S'18,~1:[R['"#%)$:9R
)$:9 9N -R2N%? cd!$-)-NfiBf R d1:07070$M RdS 8;& :;p[b<a$b8;  "!$#\gB"!E#% <=!$8;#2i'" I 32:* <>$"*6743%!E#2
:32:8;#2ffR  H7JMLbN*P uKQRJfiNRML NN7070 ~7$&
,R
V0-:)-N~b
) R2N4V0-# NR2NM^ :9:$N -R2NT? yZ7ffN -Rd1:07070$M Rz 48;:!$#%-)k8;  "!$#\gV'$'!E)!E#2 I 5,":C7@G
C4!$gB*,[C-:3\#%-)T<-!$W:;p@' :9M#2:8;:K:9'O$9R  HKJ LbN*P uKQTJNRML N 	-N1:&$, 1:07[
R
V0-#N(KR2N ? ^
 :9:$N-R VK373$$M R K
v  0-:W'"74#%-) I :04!?@#27-H$<b*+#%#%*,!$38;* I #%-:C *@C-:3%k<>$
'O:9"*k7-!E#2HSj
_ 9R$z   PYH:FI[I[ sKQRJ 7LSHYU    ff .ff	 HKP C8LI~HIWXHK
J S[VUOH7PIH
] t@v u$N*QTJ   HKJ LbN*P uKQTJN
 u7N*QhLR;
U u>F:N*QVHKJ  PYH>;Z v\[O]mL 
%H A/uKP s6L M6LON}[O,
] u7N*QT;L u7N*QVHKn
J uKJ s 	 tMNHK,
] u7N*Q*H7J R
xb: I "7-5@-:$N .R2N ?%) :#V:9y :$N&bRMd1:070$,7M R@@ *:V'"!$8;#%89! I 3%:_43% :9"#%-)r :8"0#\|&7-:J<>$w0-:D8;  "!$#%&
"!E#% <=!$8;#2 ' I 3%:*WRmz{  PYH:FI[I[ sKQR
J 7LpHYUcNRj
[ ff
7NR fi L	 MNJ''^R  1: > 18&, R/z{g :9"4!E#2!$3

#%&r-<>:9:8;:.iSr#2_89#%!$3Oz & :3%3%#%)$:8;:$R

b:9:32:^N~_JRd1:0707$MRExK7!$3?@#2:9Ad'O#%&/0-:7-"#\ #%89(<>$ I #%!E58; "!$#%&!E#\ <>!$8;#%+'" I 32:*,9Rffz{
 PdH8FI[`["sKQRJK LcHYUsNRj[   NR L	 MNff''PRj1 ~7"[REf/7$'O:!$Y-<>:9:8;:ZSr#2_489#\!$3 z{& :3%3%# G
)$:48;:$R4y

#%32:95$R

b:&9Nz RVK373$$MR/SBM8j8;#%  :48;5f#%p@Sc.RJz{l?E!$ er!E"*,:32:ffNoR*f/CffRwMN  PdH8FI[`["sKQRJKLmHYU L	 I
ff  .ff N ''^R1:j1 1:7"[ROzYv c_(:R
b:&9NEzMR2N$[ :9)#27^NR2N ? yZ!$3\0ffN c.R~VK37373>MRfixb:8;*'O! I 3%:8; "!$#%&9R 	 PON*Q nF4Q uEv IJfiN}[;v>v Q ~[OJFb[;N
 ff  d1 G $MNg1:7 1:"7&[R
b:&9Nz R2N U
? yZ!$3%0ffNcjRBd1:07070$MR V '43%# I < ! I :8"04*,!EL 3%# I M!E5Y<>$f8;4  "!$#%&9R cP:8M0ffR:9'^R2N

B_qf }3$0 `1:07070
ff fi   fi!#"$%ff& &R
6
*f w  PdH:Fb[`["sKQTJEKLmHdUH$-Q UONR IJfiN}[OPbJu7N*QVHKJuEv  HKJ 
U:[OPu[OJ FI[/HKJ  PIQRJF4QkW \[bL 7J  P $F:N*QVFI[+HdU HKJMLON*P 7QTJfiN  PYH 7P uK]]QTJ'   ;( N''^R >.K3 >>.j1ER
 = '18,~1: @
eb!E"!$3%#%8"LNE.R2N? /f 3%3%#%$9NkR d1:07.K3>M R z 8;":!$#%-)j :9:b :!E"8M0+:9e+89#%:8;5H<a$V8;  "!$#\g/"!E#% <=!$8;#2
'4 I 32:*,R 	 PbN*Q nF4Q uEvIJN};[ v>vwQ [4JFI9[ N 
	-N 7&7 ~j1:[
R
er:g :-"5[8"LNJ_ R R2Nb
x :9?@#%3%32:$N*)kR2N ?Tc :-)-NPbREd1:0707$M RHS K:-:9"#%8kSBM8V#%  :48;5iSr32)$$M#20*
!$4Ci#2[
 'O:89#%!$3\#!E#29R 	 PON*Q F4Q uEvIJfiN}9[ vav Q ~[OJFb;[ N+
  N 70j1 ~7jE1 R
$7"C!$ffN -R d1:0707"$M R  HKJ9F tjPbPY[4JfiN  HKJ LbN*P uKQTJN 	 t[vN*Qk
W v [ 	 H s;[ vwLcQRJ -,  uKJ s  ., uKEJ $tuV[OL 

H A/uKP sQu  PYH 7P uK]]QTJ  	 [:NR~H s$EH v H  M =Z M 	 H s>9[ vwQRJ R+/_ 0ffRik
x Rff0-:#\9Nr
x :4#%K
x #%C-:9$ # G
?$:9M#2 5$N w
_ !E"#% zzMR(Sr?E!$#%3%! I 32:j!$KD~ G S& G 0j1 G`1:K@3 R
~m#%3%32:9N -R
VK373$$M R
 !$-)$<>$"C  '" I 32:*WR2R
P
v 3%#%: C-:8;"#%'#2 !`?!$#\3%! I 32: !E
K
c :8"04#%89!$3w:9'O$jS
[G G
[R+SB?E!$#%3%! I 32:6<>*
S 0$ :9d?$:9"#%i!E''O:!E"d#% g! O!E`N -R ff
C R MN
v ku s
u
{u


[R ['4"#%-)$:9R

ff0/1//2 
fi$3 ff"44% 



156178 
R



 


_ nd1:0707$ Xv
 PdH8FI[`[ KQRJKLcHYU+NRj[  NR

=

~}$"#%9N JR
MR KZ0-:+C-:"#2 5m$<V3%7-#2j#\Q:|&74#%3%# I M#%7*
3%:*WRHz 
"s
 ff6u uEv 
Sb @89#%!E#2i<a$BSr#2_89#%!$3Oz & :3%3%#%)$:8;:$R

7N*Q*H7J

) nd1:070K3> H

9 :;<OWM[OPON =




'O#%&K<>$10-:,|[7-:9:1' I G
MNff''^R
[RwSr*:9M#%89!$

HKJ8U4[4PY[4JFI[HKJ 	

<

@>7. >>7

!$C-:3 N bR
MR B:9': :&!E#2n :32:8;#2Q<>$18; "!$#%&.!E#% <=!$8;#2 PST89!$ :+7C-5m74#%-)
-G K7-:9:9R
=N EN
[R

1:& ~7
_(" :9N>_JR2N [ :9)#27^NR2NE? yZ!$3%0ffN[cjRVK37373>MRg@#%-)32:9 +8;#%  :489#2:9ROz lxb:8"0& :9NT.R*fCffRwMN
7NR IJfiN}[4PIJ u7N*Q*H7JuEv  HKJ8U4[4PY[4JFI[HKJ  PIQRJF:QiW v\[bjL uKJ s  P u$F:N*QVFI[OLHYU  H7JMLbN*P uKQRJfiN  PdH ${P u7]m]QRJ 
. R = S 1:.706- R@[ '4"#%-)$:9 G :9M3%!E)-R
   ff     N4'4'^Rfi7"7 ~7&7[
 U#c

fififfv2$ff6ff  	)T$
    fi
 ff  
  v~ff



:9 )#%^N R~d1:0706MR-S _432 :9"#\-)d!$32)$$"#204* <>$J8; "!$#%&P$<C#  :9:48;:/#%k j_/9Rgz   PYH:FI[I[sKQRJKL HdU
NRM[_ ff NR ff6u7N*Q*H7JuEv  HKJ:U:[OPu[OJ FI[HKJ 	 MNg''^Rj7&7 ~7&$,&R4Sb*:9"#%89!$fSr" [89#\!E#2+<>$DSB"#2_489#%!$3
z{& :3%3%#2)$:8;:$R

:9 )#%^N

? 

-VK37373>
cx
T *f w  PYH:FI[I[ KQRJ7LHdU KNR IJfiN}[OPbJ 7N*QVHKJ H7J:U4[4PY[4JFI[
H7J  PIQRJF:QiW \[bL 7J  P $F:N*QVFI[HYU HKMJ LON*P KQRJfiN  dP H $P 7]m]QRJ  ff  $7.6 ~707" M = S
1:.706 
@8M0&73% :$NbR2N ?%[ 78L$:95$NKJ_ RVK373M18M R[y 0-:6C- I 7C4ff!$C1C-*+!$#%j'$'!E)!E#2132:!$C. B0-:!$*:
:!E"8"0m '4!$8;:$Rz{X[
 C-:9)!$!EMCffN 1
e R *f CffRwM N  PYH:Fb[`[ s7QTJ 7LmHdU  {P s IJfiN}[4PIJ u7N*Q*H7J uEv  H7J:U4[4PY[4JFI[
H7J  PIQRJF4QkW v\[b+
L uKJ s  {P u$F8N*Q*Fb[cHdU 
[u9F v2uKP u7N*Q K[  PYH ${P uK]]QRJ  
  ff   (NP''PRE171:" 1:7[& R
SBd~(/
_ :9R
@*,#%0ffNb
) R2Nq[  :9)#27ffNR2N,? yZ!$3%"0ffNJc.RVK37373>M R #%-)x!$7@p@#\3%#%!E5x?!EM#%! I 32:k!$C #%*'43%#%:CQ8;@G
 "!$#%&P K*@C-:3g--G I #%!E5b' I 32:*,9Rz{ PdH8FI[`"[ sKQR
J KL HdU NRj[ KNR ff1u7N*QVHKJ u$v  H7J:U4[4PY[4JFI[
H7J 	 MN''PR@1:.7 1:.$&, RffSb*:9"#%89!$}Sr[89#%!E#%W<a$rSB#%_489#%!$3 z & :3%3%#%)$:8;:$R
@*,#%0ffN b
) R VK37373>M RB~i@C-:3%3\#%-)!sJ_ :9"*k7-!E#2!(_  I 3%:*WR/z{  PYH:Fb[`[ s7QTJ 7LHdU  L	  ff     HKP Cr
LI~HIW HKJ 	 H s>;[ v>v QTJ fuKJ s EH v 8QRJ   PdH;Z v\[O]mL AgQ*NR  H7JMLbN*P uKQRJfiNRML RSb3% 6!`?!$#\3%! I 32:b!$ B: :!E"8M0
B:9'O$D<a"* 0g  ' < ff8;*WR 0[7CffR !$8ER 7-L  !6 8;* I *,  '4!E'O:9"9R 0&*,3 R
[ :9)#%7ffN=R2N,?hyZ!$3%0ffNwcjR d1:07070$M RZcd0-:]C4# :9":8;:]!$3%32G C#O :9:8;:]*+!EL$:9Rmz{  PYH:FI[I[ sKQRJ KLXHdU
1KNR fi L	 MN-''^RM 1O > 1:[0 ROz{g :9M!E#2!$3 #%grV-<a:9":8;:.iSr#2_489#\!$3Oz & :3%3%#2)$:48;:$R
yZ!$3%0^NcjRVK37373>M R
@
 Sch? SjB_ R z #r
x :8M0g :9`N 1R*f CffRwM N 7NR IJfiN}[OPbJ u7N*QVHKJ u$v  HKJ8U4[4PY[4JFI[ H7J
 PIQRJF:QiW v\[bHL uKJ s  {P u$F8N*Q*Fb[bLmHYU  HKJMLON*{P u7QTJfiN  PYH 7P uK]]QTJ     ff    N''PR 7 1 >>"7[& R = S
1:.706- R[ 'M#%-)$:9 G :9"3\!E)-R
R2N
B7-:0-:9`NO~YR
MRkS )32 I $
! 3w8;  "!$#\gj8;* I #%#%)]!l7* 8;  M!$#%gj!$CXC#%<\G
<>:9:8;:K8;  M!$#%gRffz  b:8"0& :9N .R /CffR MN
s
u
uEv 
v ru s
u
{u
{u
[R



  N&'^' R
-R ['M#%-)$:9R



 U!

fiJournal of Artificial Intelligence Research 21 (2004) 499-550

Submitted 08/03; published 04/04

Compositional Model Repositories via Dynamic Constraint
Satisfaction with Order-of-Magnitude Preferences
Jeroen Keppens
Qiang Shen

JEROEN @ INF. ED . AC . UK
QIANGS @ INF. ED . AC . UK

School of Informatics, The University of Edinburgh
Appleton Tower, Crichton Street, Edinburgh EH8 9LE, UK

Abstract
The predominant knowledge-based approach to automated model construction, compositional
modelling, employs a set of models of particular functional components. Its inference mechanism
takes a scenario describing the constituent interacting components of a system and translates it into
a useful mathematical model. This paper presents a novel compositional modelling approach aimed
at building model repositories. It furthers the field in two respects. Firstly, it expands the application domain of compositional modelling to systems that can not be easily described in terms of
interacting functional components, such as ecological systems. Secondly, it enables the incorporation of user preferences into the model selection process. These features are achieved by casting the
compositional modelling problem as an activity-based dynamic preference constraint satisfaction
problem, where the dynamic constraints describe the restrictions imposed over the composition of
partial models and the preferences correspond to those of the user of the automated modeller. In
addition, the preference levels are represented through the use of symbolic values that differ in
orders of magnitude.

1. Introduction
Mathematical models form an important aid in understanding complex systems. They also help
problem solvers to capture and reason about the essential features and dynamics of such systems.
Constructing mathematical models is not an easy task, however, and many disciplines have contributed approaches to automate it. Compositional modelling (Falkenhainer & Forbus, 1991; Keppens & Shen, 2001b) is an important class of approaches to automated model construction. It uses
predominantly knowledge-based techniques to translate a high level scenario into a mathematical
model. The knowledge base usually consists of generic fragments of models that provide one of
the possible mathematical representation of a process that occurs in one or more components. The
inference mechanisms instantiate this knowledge base, search for the most appropriate selection of
model fragments, and compose them into a mathematical model. Compositional modelling has been
successfully applied to a variety of application domains ranging from simple physics, over various
engineering problems to biological systems.
The present work aims at a compositional modelling approach for building model repositories
of ecological systems. In the ecological modelling literature, a range of models have been devised
to formally characterise the various phenomena that occur in ecological systems. For example,
the logistic growth (Verhulst, 1838) and the Holling predation (Holling, 1959) models describe the
changes in the size of a population. The former expresses changes due to births and deaths and the
latter changes due to one population feeding on another. A compositional model repository aims
c
2004
AI Access Foundation. All rights reserved.

fiK EPPENS & S HEN

to make such (partial) models more generally usable by providing a mechanism to instantiate and
compose them into larger models for more complex systems involving many interacting phenomena.
Thus, the input to a compositional model repository is a scenario describing the configuration
of a system to be modelled. A sample scenario may include a number of populations and various
predation and competition relations between them. The output is a mathematical model, called a
scenario model, representing the behaviour of the system specified in the given scenario. A set of
differential equations describing the changes in the population sizes in the aforementioned scenario
due to births, natural deaths, deaths because of predation, available food supply or competition
would constitute such a scenario model.
This application domain poses three important new challenges to compositional modelling.
Firstly, the processes and components of an ecological system that are to be represented in the
resulting composed model depend on one another and on the ways they are described. In population dynamics for example, models describing the predation or competition phenomena between
two populations rely on the existence of a population growth model for each of the populations
involved in the phenomenon. This inhibits the conventional approach of searching for a consistent and adequate combination of partial models, one for each component in the scenario. This
approach provides an adequate solution for physical systems because these are comprised of components implementing a particular functionality that can be described by one or multiple partial
models. Although the seminal work on compositional modelling (Falkenhainer & Forbus, 1991)
recognised the existence of more complex interdependencies in model construction in general, it
provided only a partial solution for it: all the conditions under which certain modelling choices
were relevant had to be specified manually in the knowledge base.
Secondly, the domain of ecology lacks a complete theory of what constitutes an adequate model.
Most existing compositional modellers are based on a predefined concept of model adequacy. They
employ inference mechanisms that are guaranteed to find a model that meets such adequacy criteria.
However, criteria to determine how adequate an ecological model may be vary between ecological
domains and even between the ecologists that require the model within the same domain. Therefore,
the compositional modeller requires a facility to define the properties that the generated ecological
models must satisfy.
Thirdly, it is not possible to express all the criteria imposed on the scenario model in terms of
hard requirements. Often, ecological models that describe mechanisms and behaviours are only partially understood. In such cases, the choice of one model over another becomes a matter of expert
opinion rather than pure theory. Therefore, in the ecological domain, modelling approaches and presumptions are, to some extent, selected based on preferences. Existing compositional modellers are
not equipped to deal with such user preferences and this paper presents the very first compositional
modeller that incorporates them.
Generally speaking, the above three issues are tackled in this paper by means of a method to
translate the compositional modelling problem into an activity-based dynamic preference constraint
satisfaction problem (aDPCSP) (Keppens & Shen, 2002). An aDPCSP integrates the concept of
activity-based dynamic constraint satisfaction problem (aDCSP) (Miguel & Shen, 1999; Mittal &
Falkenhainer, 1990) with that of order-of-magnitude preferences (Keppens & Shen, 2002). The
attributes and domains of this aDPCSP correspond to model design decisions, with constraints describing the restrictions imposed by consistency requirements and properties and order-of-magnitude
preferences describing the users preferences on modelling choices. The translation method brings
the additional advantage that compositional modelling problems can now be solved by means of
500

fiC OMPOSITIONAL M ODEL R EPOSITORIES

efficient aDCSP techniques. As such, compositional modellers can benefit from recent and future
advances in constraint satisfaction research.
The remainder of this paper is organised as follows. Section 2 introduces the concept of an
aDPCSP, a preference calculus that is suitable to express subjective user preferences for model
design decisions and to be integrated with the general framework of aDPCSPs. It also gives a
solution algorithm for aDPCSPs. Next, section 3 presents the compositional model repository and
shows how such an aDPCSP is employed for automated model construction. These theoretical
ideas are then illustrated by means of a large example in section 4, applying the compositional
model repository to population dynamics problems. Section 5 concludes this paper with a summary
and an outline of further research.

2. Dynamic Constraint Satisfaction with Order-of-Magnitude Preferences
In this section, a preference calculus based on order-of-magnitude reasoning is introduced and integrated into the activity-based dynamic constraint satisfaction problem (aDCSP) to form an aDCSP
with order-of-magnitude preferences (aDPCSP). Then, a solution algorithm for such aDPCSPs is
presented. The theory is illustrated with examples from the compositional modelling domain.
2.1 Background: Activity-based dynamic preference constraint satisfaction
A hard constraint satisfaction problem (CSP) is a tuple hX, D, Ci, where
 X = {x1 , . . . , xn } is a vector of n attributes,
 D = {Dx1 , . . . , Dxn } is a vector containing exactly one domain for each attribute in X.
Each domain Dx  D is a set of values {di1 , . . . , dini } that may be assigned to the attribute
corresponding to the domain.
 C is a set of compatibility constraints. A compatibility constraint c {xi ,...,xj }  C defines a
relation over a subset of the domains Dxi , ..., Dxj , and hence c{xi ,...,xj }  Dxi  . . .  Dxj .
A solution to a hard constraint satisfaction problem is any tuple hx 1 : dx1 , . . . , xn : dxn i such
that
 each attribute is assigned a value from its domain: xi  X, dxi  Dxi , and
 all compatibility constraints are satisfied: x{xi ,...,xj }  C, hdxi , . . . , dxj i  c{xi ,...,xj } .
An activity-based dynamic CSP (aDCSP), originally proposed in by Mittal and Falkenhainer
(1990), extends conventional CSPs with the notion of activity of attributes. In an aDCSP, not all
attributes are necessarily assigned in a solution, but only the active ones. As such, each attribute is
either active and assigned a value or inactive:

xi  X, dxi  Dxi , xi : dxi  active(xi )

The activity of attributes in an aDCSP is governed by activity constraints that enforce under which
assignments of attributes, an assignment to another attribute is relevant or possible. This information
is important because it not only dictates for which attributes a value must be searched, but also the
set of compatibility constraints that must be satisfied. Clearly, only the compatibility constraints
501

fiK EPPENS & S HEN

c{xi ,...,xj }  C for which all attributes xi , . . . , xj are active must be satisfied, and a hard CSP is a
sub-type of aDCSP in which all attributes are always active.
In summary, an activity-based dynamic constraint satisfaction problem (aDCSP) is a tuple
hX, D, C, Ai, where
 hX, D, Ci is a hard CSP, and
 A is a set of activity constraints. An activity constraint restricts the sets of attribute-value
assignments under which an attribute is active or inactive:
axi ,{xj ,...,xk }  Dxj  . . .  Dxk  {active(xi ), active(xi )}
where xi 6 {xj , . . . , xk }.
A solution to an activity-based dynamic constraint satisfaction problem is any tuple hx 1 :
dx1 , . . . , xl : dxl i such that
 the attributes that are part of the solution are assigned a value from their domain: x i 
{x1 , . . . , xl }, dxi  Dxi ,
 all activity constraints are satisfied:

and



axi ,{xj ,...,xk }  A, xj 6 {x1 , . . . , xl }  . . .  xk 6 {x1 , . . . , xl } 

xi  {x1 , . . . , xl }  hdxj , . . . , dxk , active(xi )i  axi ,{xj ,...,xk } 

xi 6 {x1 , . . . , xl }  hdxj , . . . , dxk , active(xi )i  axi ,{xj ,...,xk }

 all compatibility constraints are satisfied:
c{xi ,...,xj }  C, active(xi )  . . .  active(xj )  hdxi , . . . , dxj i  c{xi ,...,xj }
2.2 Order-of-magnitude preferences (OMPs)
Although an aDCSP can capture the hard constraints over decisions in a given problem as well as
their dynamically changing solution space (as described by the activity constraints), the representation scheme it employs does not take into account any preferences users may have over possible
alternative value assignments. Therefore, this work is extended to allow preference information to
be attached to attribute-value assignments. The way in which this can be achieved depends on the
representation and reasoning mechanisms underlying the preference calculus. In general, a preference calculus can be defined as a tuple h , , 4i where:


is the set of preferences,

  is a commutative, associative operator that is closed in , and
 4 forms a partial order, that is, reflexive, anti-symmetric and transitive relation defined over
 .
Because 4 is reflexive, antisymmetric and transitive, comparing preferences with the 4 relation
yields one of four possible results:
502

fiC OMPOSITIONAL M ODEL R EPOSITORIES

 Two preferences P1 , P2 
P2 4 P 1 .

are equal to one another (denoted P1 = P2 ) iff P1 4 P2 and

 A preference P1 
is strictly greater than a preference P2 
P1 64 P2 and P2 4 P1 .

(denoted P1  P2 ) iff

 A preference P1 
is strictly smaller than a preference P2 
P1 4 P2 and P2 64 P1 .

(denoted P1  P2 ) iff

 Two preferences P1 , P2 
and P2 64 P1 .

are incomparable with one another (denoted P1 ?P2 ) iff P1 64 P2

Thus, an activity-based dynamic preference constraint satisfaction problem (aDPCSP) is a tuple
hX, D, C, A, h , , 4i, P i where
 hX, D, C, Ai is an aDCSP,
 h , , 4i is a preference calculus, and
 P is a mapping Dx1  . . .  Dxn 7
preferences.

from the individual attribute-value assignments to the

The preferences attached to attribute-value assignments express the relative desirability of these
assignments. The aim of the aDPCSP is to find a solution with the highest combined preference.
That is, given an aDPCSP hX, D, C, A, h , , 4i, P i, any solution hxi : dxi , . . . , xj : dxj i of the
aDCSP hX, D, C, Ai such that no other solution hxk : dxk , . . . , xl : dxl i of hX, D, C, Ai exists
with P (xi : dxi )  . . .  P (xj : dxj )  P (xk : dxk )  . . .  P (xl : dxl ) is a solution to the aDPCSP.
In this section, a preference calculus is introduced to extend an aDCSP into an aDPCSP. The
calculus will be illustrated with examples from the compositional modelling domain.
2.2.1 R EPRESENTATION

OF

OMP S

Technically, OMPs are combinations of so-called basic preference quantities (BPQs), which are the
primitive units of preference or utility valuation associated with possible design decisions. Because
it is often difficult to evaluate these BPQs numerically, they are ordered relative to one another employing similar ordering relations as those employed by relative order-of-magnitude calculi (Dague,
1993a, 1993b).
Let be the set of all BPQs with respect to a particular decision problem. The BPQs in are
ordered with respect to one another at two levels of granularity, by two relations  and <. First,
is partitioned into orders of magnitude, which are ordered by . Then, the BPQs within each order
of magnitude are ordered by <. Formally, an order-of-magnitude ordering over BPQs is a tuple
hO, i, where O = {O1 , . . . , Oq } is a partition of and  is an irreflexive and transitive binary
relation over O. Any subset of BPQs O  O is said to be an order of magnitude in . Similarly, a
within-magnitude ordering over a set of BPQs is a tuple hO, <i, where O is an order of magnitude
in and < is an irreflexive and transitive binary relation over O.
To illustrate these ideas, consider the problem of constructing an ecological model describing a
scenario containing a number of populations. Let some of the populations be parasites and others
be hosts for these parasites. Also, assume that certain populations compete with others for scarce
resources. In order to construct a scenario model, the compositional modeller must make a number
503

fiK EPPENS & S HEN

b15 : Lotka-Volterra
predation model

b13 : Holling
predation model

<

<
b11 : Rogers
host-parasitoid model

<
b14 : Thomsons
host-parasitoid model

b12 : Nicholson-Baileys
host-parasitoid model

<

O1 (host-parasitoid phenomenon)



b22 : exponential
growth model

<

<
b21 : logistic
growth model


b23 : other
growth model

<

b31 : competition
phenomenon

O3: (competition phenomenon)

O2 (population growth phenomena)

Figure 1: Sample space of BPQs
of model design decisions: which population growth, host-parasitoid and competition phenomena
are relevant, and which types of model best describe these phenomena.
Figure 1 shows a sample space of BPQs that correspond to the selection of types of model. For
the sake of illustration, the presumption is made that the quality of a scenario model depends on the
inclusion of types of model, rather than on the inclusion or exclusion of phenomena. Apart from
b23 and b31 , all BPQs correspond to standard textbook ecological models 1 . BPQ b23 stands for the
use of a population growth model that is implicit in another population growth model (the LotkaVolterra model, for instance, implicitly includes its own concept of growth). Finally, BPQ b 31 is the
preference associated with a competition model (say, the only one included in the knowledge base).
The 9 BPQs in this sample space are partitioned over 3 orders of magnitude. The  relation
orders the orders of magnitude: O2  O1 and O2  O3 . The binary < relation orders individual BPQs within an order of magnitude. In the BPQ ordering within O 1 , for instance, Rogers
host-parasitoid model (b11 ) is preferred over that by Nicholson and Bailey (b12 ) and the Holling
predation model (b13 ). The latter two models can not be compared with one another, but they both
are preferred over the Lotka-Volterra model. Furthermore, Thompsons host-parasitoid model is
less preferred than that of Nicholson and Bailey, but it can not be compared with the Lotka-Volterra
and Holling models.
2.2.2 C OMBINATIONS

OF

OMP S

By definition, OMPs are combinations of BPQs. The implicit value of an OMP p equals the combination b1  . . .  bn of its constituent BPQs b1 , . . . , bn . This property allows OMPs to be defined
as functions such that an OMP P = b1  . . .  bn is a function fP : 7 : b  fP (b) where
1. To be precise, the BPQs b11 , b12 , b13 , b14 , b15 , b21 and b22 respectively correspond to the inclusion of Rogers
host-parasitoid model (1972), the host-parasitoid model by Nicholson and Bailey (1935), Hollings predation model
(1959), Thompsons host-parasitoid model (1929), the predation model by Lotka and Volterra (1925, 1926), a logistic
population growth model (Verhulst, 1838) and an exponential population growth model (Malthus, 1798).

504

fiC OMPOSITIONAL M ODEL R EPOSITORIES

is the set of BPQs, is the set of natural numbers and fP (b) equals the number of occurrences of b
in b1 , . . . , bn .
For example, let Pmodel denote the OMP associated with the scenario model that contains three
logistic population growth models (b21 ), two Holling predation model (b13 ) and one competition
model (b31 ). Therefore,
Pmodel = b21  b21  b21  b13  b13  b31
and hence:



3



2
fPmodel (b) =

1



0

if b = b21
if b = b13
if b = b31
otherwise

By describing OMPs as functions, the concept of combinations of OMPs becomes clear. For
two OMPs P1 and P2 , the combined preference P1  P2 is defined as:
fP1 P2 :

7

: b  fP1 P2 (b) = fP1 (b) + fP2 (b)

Note that the combination operator  is assumed to be commutative, associative and strictly monotonic (P  P  P ). The latter assumption is made to better reflect the ideas underpinning conventional utility calculi (Binger & Hoffman, 1998).
2.2.3 PARTIAL ORDERING OF OMP S
Based on the combinations of OMPs, a partial order 4 over the OMPs can be computed by exploiting the constituent BPQs of the OMPs considered. This partial order implies that a comparison of
any pair of OMPs either returns equal preference (=), smaller preference (), greater preference
() or incomparable preference (?). This calculus is developed assuming the following:
 Prioritisation: A combination of BPQs is never an order of magnitude greater than its constituent BPQs. That is, given the set of BPQs belonging to the same order of magnitude
{b1 , b2 , . . . , bn }  O1 and a BPQ b  O2 belonging to a higher order of magnitude, i.e.
O1  O2 , then
b1  b2  . . .  bn  b
With respect to the ongoing example, this means that any BPQ taken from the order of magnitude O1 is preferred over any combination of BPQs taken from O2 . In other words, the choice
of a model to describe a host-parasitoid phenomenon is considered more important than the
choice of population growth model (see Figure 1).
Prioritisation also means that distinctions at higher orders of magnitude are considered to
be more significant than those at lower orders of magnitude. Consider a number of BPQs
b1 , . . . , bm1 , bm , . . . , bn taken from one order of magnitude O1 and a pair of BPQs {b, b0 }
taken from an order of magnitude that is higher than O1 . If b < b0 , then (irrespective of the
ordering of the BPQs taken from O1 )
b1  . . .  bm1  b  bm  . . .  bn  b0
505

fiK EPPENS & S HEN

 Strict monotonicity: Even though distinctions at higher orders of magnitude are more significant, distinctions at lower orders of magnitude are not negligible. That is, given an OMP
P and two BPQs b1 and b2 taken from the same order of magnitude with b1 < b2 , then
(irrespective of the orders of magnitude of the BPQs that constitute P )
b1  P  b2  P
For instance, the preference ordering depicted in Figure 1 shows that a scenario model with a
Rogers host-parasitoid model and two logistic predation models is preferred over one with a
Rogers host-parasitoid model and two exponential predation models:
b11  b22  b22  b11  b21  b21
Note that this is a departure from conventional order-of-magnitude reasoning. If the OMPs
associated with two (partial) outcomes contain equal BPQs at a higher order of magnitude, it is
usually desirable to compare both solutions further in terms of the (less important) constituent
BPQs at lower orders of magnitude, as the example illustrated. However, conventional orderof-magnitude reasoning techniques can not handle this.
 Partial ordering maintenance: Conventional order-of-magnitude reasoning is motivated by
the need for abstract descriptions of real-world behaviour, whereas the OMP calculus is motivated by incomplete knowledge for decision making. As opposed to conventional orderof-magnitude reasoning and real numbers, OMPs are not necessarily totally ordered. This
implies that, when the user states, for example, that b1 < b2 < b and that b3 < b4 < b, the
explicit absence of ordering information between the BPQs in {b 1 , b2 } and those in {b3 , b4 }
means that the user is unable to compare them (e.g. because they are entirely different things).
Consequently, b1  b2 would be deemed incomparable to b3  b4 (i.e. b1  b2 ?b3  b4 ), rather
than roughly equivalent.
From the above, it can be derived that given two OMPs P1 and P2 and an order of magnitude O,
P1 is less or equally preferred to P2 with respect to the order of magnitude O (denoted P1 4O P2 )
provided that
bi  O, fP1 (bi ) +

X

bj O,bi <bj


fP1 (bj )  fP2 (bi ) +

X

bj O,bi <bj

fP2 (bj )



Thus, comparing two OMPs within an order of magnitude can yield four possible results:
 P1 is less preferred than P2 with respect to O (P1 O P2 ) iff (P1 4O P2 )  (P2 4 P1 ),
 P1 is more preferred than P2 with respect to O (P1 O P2 ) iff (P1 4O P2 )  (P2 4 P1 ),
 P1 is equally preferred than P2 with respect to O (P1 =O P2 ) iff (P1 4O P2 )  (P2 4 P1 ),
and
 P1 is incomparable to P2 with respect to O (P1 ?O P2 ) iff (P1 4O P2 )  (P2 4 P1 ).
506

fiC OMPOSITIONAL M ODEL R EPOSITORIES

In the ongoing example of Figure 1, for instance, the preference of a scenario model with a
Rogers host-parasitoid model and a Holling predation model is P 1 = b11  b13 and the preference
of a scenario model with a Rogers host-parasitoid model and a Lotka-Volterra predation model
is P2 = b11  b15 . The latter model is less than or equally preferred to the former within the
host-parasitoid order of magnitude (O1 ), i.e. P2 4O1 P1 , because
fP2 (b11 ) = 1  1 = fP1 (b11 ),
fP2 (b11 )  fP2 (b12 ) = 1  1 = fP1 (b11 )  fP1 (b12 ),
fP2 (b11 )  fP2 (b13 ) = 1  2 = fP1 (b11 )  fP1 (b13 ),
fP2 (b11 )  fP2 (b12 )  fP2 (b14 ) = 1  1 = fP1 (b11 )  fP1 (b12 )  fP1 (b14 ),
fP2 (b11 )  fP2 (b12 )  fP2 (b13 )  fP2 (b14 ) = 2  2 = fP1 (b11 )  fP1 (b12 )  fP1 (b13 )  fP1 (b14 ).
Similarly, it can be established that the reverse, i.e. P1 4O1 P2 , is not true. Therefore, the latter
scenario model is less preferred than the former within O1 , i.e. P2 O1 P1 .
The above result can be further generalised such that given two OMPs P 1 and P2 , P1 is less or
equally preferred to P2 (denoted P1 4 P2 ) if
Oi  O, (P1 4Oi P2 )  (Oj  O, Oi  Oj  P1 Oj P2 )
More generally, the relations , , = and ? can be derived in the same manner as with the
relation 4 where O , O , =O and ?O with 4O .
To illustrate the utility of such orderings, consider the scenario of one predator population that
feeds on two prey populations while the two prey populations compete for scarce resources. The
following are two plausible scenario models for this scenario:
 Model 1 contains two Holling predation models and three logistic population growth models,
and has preference P1 = b13  b13  b21  b21  b21 .
 Model 2 contains one competition model, two Holling predation models, two logistic population growth models and an exponential population growth model, and has preference
P2 = b13  b13  b21  b21  b22  b31 .
As demonstrated earlier, it can be shown that P1 =O1 P2 , P1 O2 P2 , and P1 O3 P2 . From these
relations it follows that P1 4 P2 because
 for O1 : P1 4O1 P2 since P1 =O1 P2 ,
 for O2 : there exists an order of magnitude O3 where O3  O2 and P1 O3 P2 ,
 for O3 : P1 4O3 P2 since P1 O3 P2 .
As the reverse is not true, it can be concluded that scenario model 2 is preferred over scenario model
1.
2.3 Solving aDPCSPs
This section presents a basic algorithm for solving aDPCSPs. Although OMPs are used in this
work, this algorithm can take any aDPCSP provided that it employs a preference calculus with a
507

fiK EPPENS & S HEN

commutative, associative and monotonic combination operator. However, the use of OMPs provides
a convenient way of specifying incomplete preference information.
An aDPCSP is similar to valued CSPs as presented by Schiex, Fargier and Verfaillie (1995)
and also to semiring based CSPs (Bistarelli, Montanari, & Rossi, 1997). However, it extends both
approaches with activity constraints and involves different underlying presumptions in its valuation
structure. The preference valuations in this work are allowed to be ordered partially, as opposed to
the valued CSPs.
An aDPCSP represents an important type of constraint satisfaction optimisation problem (Tsang,
1993). In order to tackle the optimisation of preferences an A* type algorithm is employed (Hart,
Nilsson, & Raphael, 1968; Raphael, 1990). A* algorithms are known to be efficient in terms of
the total number of nodes explored in an effort to find optimal solutions, with a given amount of
information. On the downside, they have an exponential space complexity. Naturally, a number of
alternative approaches could have been explored, including conventional constraint-based solving
methods such as depth first branch and bound search. However, the use of an A*-like algorithm is
sufficient for solving the aDPCSPs in the domain of the present interest. In particular, algorithm 1
implements an A* search strategy that is capable of handling activity constraints, which involves
the use of basic CSP techniques such as constraint propagation and backtracking.
An A* algorithm maintains the explored attribute-value assignments by means of a priority
queue Q of nodes. Each node n in Q corresponds to a set of attribute-value assignments: solution(n).
The search proceeds through a number of iterations. At each iteration, a node n is taken from Q,
and replaced by nodes that extend solution(n) with an additional attribute-value assignment. More
specifically, for each node n in Q, a set Xu (n) of remaining active but unassigned attributes is
maintained. At each iteration, the possible assignments of the first attribute x  X u (n), where
n is the node taken from Q at the current iteration, are processed. For every assignment x : d
that is consistent with solution(n) (i.e. solution(n)  {x : d}, C 0 ), a new child node n 0 , with
solution(n0 ) = solution(n)  {x : d} and Xu (n0 ) = Xu (n)  {x}, is created and added to Q.
The activity constraints are processed via propagation rather than constraint satisfaction. Whenever a node n is taken from Q such that Xu (n) is empty, the activity constraints are fired in order to
obtain a new set of active but unassigned attributes. That is, X u (n) is assigned
{xi | solution(n), A ` active(xi )}  Xa (n)
where Xa (n) represents the active, but already assigned attributes in node n.
In the priority queue Q, nodes are maintained by means of two heuristics: committed preference
CP (n) and potential preference P P (n). Here, given a node n,
CP (n) = x:dsolution(n) P (x : d)
P P (n) = CP (n)  (xXnd (n) max P (x : d))
dDx

where Xnd (n) is the set of unassigned attributes that can still be activated given the partial assignment solution(n) (as indicated previously, the actual implementation employs an assumption-based
truth maintenance system (de Kleer, 1986) to efficiently determine which attributes activity can no
longer be supported). In other words, CP (n) is the preference associated with the partial attributevalue assignment in node n and P P (n) is CP (n) combined with the highest possible preference
assignments taken from all the values of the domains of those attributes in X nd (n). Thus, P P (n)
508

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Algorithm 1:

SOLVE(X, D, C, A, P )

n  new node;
solution(n)  {};
Xu (n)  {xi | {}, A ` active(xi )};
Xa (n)  {};
CP (n)  0;
P P (n)  xX maxdD(x) P (x : d);
Q  createOrderedQueue();
enqueue(Q, n, P P (n), CP (n)); while Q 6= 

n  dequeue(Q);




if
Xu (n)

 6= 




 then x  first(Xu (n));




 PROCESS(x, n, C, A, P, Q);


Xu (n)  {xi | solution(n), A ` active(xi )}  Xa (n);







if Xu (n) = 






nnext  first(Q);
do











if CP (n)  P P (nfirst)




then 
return (solution(n));
else
then












 else P P (n)  CP (n);







enqueue(Q, n, P P (n), CP (n));










x  first(Xu (n));



 else
PROCESS(x, n, C, A, P, Q);
procedure PROCESS(x, nparent , C, A, P, Q)
for d 
 D(x)
if solution(n


 parent )  {x : d}, C 0 


nchild  new node;





solution(n )  solution(n



child
parent )  {x : d};




X  deactivated(solution(n ), X(n




child
parent ));
d





Xnd (nchild )  Xnd (nparent )  {x}  Xd ;
do
then Xa (nchild )  Xa (nparent )  {x};






Xu (nchild )  Xu (nparent )  {x};









CP (nchild )  CP (nparent )  P (x : d);








P P (nchild )  CP (nchild )  xXnd (n) maxdD(x) P (x : d);




enqueue(Q, nchild , P P (nchild ), CP (nchild ));

computes an upper boundary on the preference of an aDPCSP solution that includes the partial
attribute-value assignments corresponding to n.
The following theorem shows that algorithm 1 is guaranteed to find the set of attribute-value
pairs with the highest combined preferences, within the set of solutions that satisfy the constraints.
Theorem 1 SOLVE(X, D, C, A, P ) is admissible
Proof: SOLVE(X, D, C, A, P ) is an A* algorithm guided by a heuristic function P P (n) = CP (n)
h(n), where CP (n) is the actual preference of node n and h(n) =  xXnd (n) maxdDx P (x : d).
It follows from the previous discussion that h(n) is greater than or equal to the combined preference
of any value-assignment of unassigned attributes that is consistent with the partial solution of n. In
this algorithm, the nodes n are maintained in a priority queue in descending order of P P (n). Let 
be a distance function that reverses the preference ordering such that (P 1 )  (P2 )  P1  P2 .
SOLVE (X, D, C, A, P ) can then be described as an A* algorithm, where the nodes n in the priority
509

fiK EPPENS & S HEN

queue Q are ordered in ascending order of (P P (n)), such that (P P (n)) = (CP (n))  (h(n))
and (h(n)) is a lower bound on the distance between n and the optimal solution. Therefore, following the work by Hart, Nilsson and Raphael (1968), SOLVE(X, D, C, A, P ) is an admissible
algorithm, guaranteed to find a solution S with a minimal (P (S)) or a maximal P (S).
To illustrate algorithm 1, consider the problem of finding an ecological model that describes the
behaviour of two populations, one of which predates on the other. An aDPCSP is constructed for
the compositional modelling problem with the following attributes and domains. Note that section
3 demonstrates how the attributes, domains and constraints of this problem can be constructed
automatically and that section 4 illustrates these ideas in the context of a larger example.

X = {x1 , x2 , x3 , x4 , x5 , x6 }
Dx1 = {yes, no}
Dx2 = {yes, no}
Dx3 = {yes, no}
Dx4 = {other, logistic}
Dx5 = {other, logistic}
Dx6 = {Holling, Lotka-Volterra}
The attributes x1 , x2 and x3 respectvely describe the relevance of the following phenomena:
the change in size of the predator population, the change in size of the prey population and the
predation of the prey by the predator. The attributes x4 and x5 represent the choice of type of
population growth model. Two types of such models are incorporated in the problem: the logistic
one and the other. Finally, attribute x6 is associated with the choice of model type of the predation
phenomenon. Here, two types of model, the Holling model and the Lotka-Volterra model, are
included.
Because the Holling predation model presumes that logistic models are employed to describe
population growth, and because the Lotka-Volterra Model incorporates its own population growth
model, the combinations of assignments to x4 , x5 , and x6 are restricted. Hence, the aDPCSP
contains a set C = {c{x4 ,x6 } , c{x5 ,x6 } } of compatibility constraints, with:
c{x4 ,x6 } = {hx4 : other, x6 : Lotka-Volterrai, hx4 : logistic, x6 : Hollingi}
c{x5 ,x6 } = {hx5 : other, x6 : Lotka-Volterrai, hx5 : logistic, x6 : Hollingi}
Furthermore, a model type of predator/prey growth must be selected if and only if the corresponding population growth phenomenon is deemed relevant. Also, a model type of predation must be selected if and only if both population growth phenomena and the predation phenomenon are deemed relevant (because ecological models describing predation rely on submodels
describing population growth of the predator and the prey). Hence, the aDPCSP contains a set
A = {ax4 ,{x1 } , ax5 ,{x2 } , ax6 ,{x1 ,x2 ,x3 } } of activity constraints, with:
510

fiC OMPOSITIONAL M ODEL R EPOSITORIES

ax4 ,{x1 } = {hx1 : yes, active(x4 )i, hx1 : no, active(x4 )i}
ax5 ,{x2 } = {hx2 : yes, active(x5 )i, hx2 : no, active(x5 )i}
ax6 ,{x1 ,x2 ,x3 } = {hx1 : yes, x2 : yes, x3 : yes, active(x4 )i, hx1 : yes, x2 : yes, x3 : no, active(x4 )i,
hx1 : yes, x2 : no, x3 : yes, active(x4 )i, hx1 : yes, x2 : no, x3 : no, active(x4 )i,
hx1 : no, x2 : yes, x3 : yes, active(x4 )i, hx1 : no, x2 : yes, x3 : no, active(x4 )i,
hx1 : no, x2 : no, x3 : yes, active(x4 )i, hx1 : no, x2 : no, x3 : no, active(x4 )i}
Finally, let the preference calculus consist of two orders of magnitude O growth and Opredation ,
with Ogrowth  Opredation , where
Ogrowth ={pother , plogistic } with plogistic < pother
Opredation ={pHolling , pLotka-Volterra } with pLotka-Volterra < pHolling
The OMP assignments are as follows:
P (x4 : other) = P (x5 : other) =pother
P (x4 : logistic) = P (x5 : logistic) =plogistic
P (x6 : Holling) =pHolling
P (x6 : Lotka-Volterra) =pLotka-Volterra
When applied to this problem, algorithm 1 initialises the search by creating a node n 0 , where:
 Xu (n0 ), the set of currently active attributes, is initialised to {x1 , x2 , x3 }, because the activity
of these attributes does not depend on other attribute-value assignments.
 Xa (n0 ) and CP (n0 ) are initialised to the empty set and to 0 respectively, since no attributes
have been assigned yet.
 Finally, P P (n0 ) equals pother  pother  pHolling because this is the combination of highest
OMPs associated with each domain.
This initial node is enqueued in Q. Next, the algorithm proceeds through a number of iterations.
At each iteration, the node with most potential (as measured by P P and CP ) is dequeued, and its
children are generated and enqueued in Q. The nodes that are created in this way are depicted in
Figure 2. The number i in the subscript of each node ni indicates the order of node generation, and
the thick arrows show the order in which the search space is explored.
Note that there are three important features of the algorithm that could not be clearly demonstrated within Figure 2. Firstly, at node n5 , the initial set of unassigned attributes is exhausted:
Xu (n5 ) = {}. Therefore, the activity constraints are fired when n 5 is explored. Because n5 corresponds to the assignment {x1 : yes, x2 : yes, x3 : yes}, the remaining attributes are activated and
Xu (n5 ) is reset to {x4 , x5 , x6 }.
Secondly, node n12 corresponds to an assignment of all (active) attributes that is consistent with
the activity and compatibility constraints:
{x1 : yes, x2 : yes, x3 : yes, x4 : other, x5 : other, x6 : Lotka-Volterra}
511

fix1
yes

n1

P P = pother  pother  pHolling
CP = 0

no

n2
P P = pother
CP = 0

x2
yes

n3

n4

P P = pother  pother  pHolling
CP = 0

no

P P = pother
CP = 0

x3
n5

yes

P P = pother  pother
CP = 0

512

P P = pother  pother  pHolling
CP = 0

K EPPENS & S HEN

no

n6

x4
other

n7

P P = pother  pother  pHolling
CP = pother

n8

logistic

P P = plogistic  pother  pHolling
CP = plogistic

x5
n9

other

x5

n10

P P = pother  pother  pHolling
CP = pother  pother

logistic

P P = pother  plogistic  pHolling
CP = pother  plogistic

x6
n11

n12

Holling
inconsistent

P P = plogistic  pother  pHolling
CP = plogistic  pother

x6
Lotka-Volterra

P P = pother  pother  pLotka-Volterra
CP = pother  pother  pLotka-Volterra

n13

n16

logistic

P P = plogistic  plogistic  pHolling
CP = plogistic  plogistic

x6

n14

Holling
inconsistent

other

n15

Lotka-Volterra
inconsistent

n17

x6

n18

Holling
inconsistent

Lotka-Volterra
inconsistent

Figure 2: Search space explored by algorithm 1 when solving sample aDPCSP

n19

Holling

P P = plogistic  plogistic  pHolling
CP = plogistic  plogistic  pHolling

n20

Lotka-Volterra
inconsistent

fiC OMPOSITIONAL M ODEL R EPOSITORIES

This assignment is not a solution to the aDPCSP, because the corresponding preference is not guaranteed to be maximal (and, the assignment is, in fact, not optimal). After the creation of n 12 , the priority queue Q looks as follows (the ordering between n2 and n4 may vary since P P (n2 ) = P P (n4 )
and CP (n2 ) = CP (n4 )):
{n10 , n8 , n12 , n6 , n2 , n4 }
Therefore, the next node to be explored (after n9 and the subsequent creation of n12 ) is n10 .
Thirdly, node n19 does correspond with an optimal solution. After its creation, Q equals:
{n19 , n12 , n6 , n2 , n4 }
As a consequence, n19 is dequeued in the next iteration. Because no children of n 19 can be created
(Xu (n19 ) =  and the activity constraints activate no more attributes), n 19 is retained as a solution.
If the user is interested in finding multiple alternative solutions, the search may proceed until
Q contains no more nodes with a P P value that is not smaller than the maximum preference of
the first solution. In this case, P P (n12 )  CP (n19 ) and hence, there is only one solution to this
aDPCSP.

3. Compositional Model Repositories
The aDPCSPs discussed in the previous section provide the foundation for the development of the
compositional model repositories. This section specifies the problem that a compositional model
repository is built to solve and shows how it can be translated into an aDPCSP, and hence be resolved
using the proposed aDPCSP solution algorithm.
3.1 Background: assumption based truth maintenance
An ATMS is a mechanism that keeps track of how each piece of inferred information depends
on presumed information and facts and of how inconsistencies arise. In an ATMS, each piece of
information used or derived by the problem solver is stored as a node. Certain pieces of information
are not known to be true and cannot be inferred from other pieces of information, yet plausible
inference may be drawn from them. Such nodes are categorised by a special type and referred to as
assumptions.
Inferences between pieces of information are maintained within the ATMS as dependencies between the corresponding nodes. In its extended form (see de Kleer, 1988; or Keppens, 2002), the
ATMS can take inferences, called justifications of the form n i  . . .  nj  nk  . . .  nl  nm ,
where ni , . . . , nj , nk , . . . , nl , nm are nodes that the problem solver is interested in. An ATMS
can also take a specific type of justification, called nogood, that leads to an inconsistency, of the
form ni  . . .  nj  nk  . . .  nl   (meaning that at least one of the statements in
{ni , . . . , nj , nk , . . . , nl } must be false). In the ATMS, these nogoods are represented as justifications of a special node, called the nogood node.
Based on the given justifications and nogoods, the ATMS computes a label for each (nonassumption) node. A label is a set of environments and an environment is a set of assumptions.
In particular, an environment E depicts a possible world where all the assumptions in E are true.
Thus, the label L(n) of a node n describes all possible worlds in which n can be true. The label
computation algorithm of the ATMS guarantees that each label is:
513

fiK EPPENS & S HEN

 Sound - All assumptions in any environment within the label of a node being true is a sufficient
condition to derive that node:
E  L(n), [(ni E ni )  (ni E ni )] ` n
 Consistent - No environment in the label of a node, other than the nogood node, describes an
impossible world:
E  L(n), [(ni E ni )  (ni E ni )] 0 
 Minimal - The label does not contain possible worlds that are less general than one of the
other possible worlds it contains (i.e. environments that are supersets of other environments
in the label):
E  L(n)@E 0  L(n), E 0  E
 Complete - The label of each node, other than the nogood node, describes all possible worlds
in which that node can be inferred:
E,[(ni E ni )  (ni E ni ) ` n]
E 0  L(n), [(ni E 0 ni )  (ni E 0 ni ) ` n]
3.2 Knowledge Representation
As with any other knowledge-based approach, building a compositional modeller requires a formalism for the specification of its inputs, its outputs and its knowledge base. The work developed here
is loosely based on the compositional modelling language (Bobrow, Falkenhainer, Farquhar, Fikes,
Forbus, Gruber, Iwasaki, & Kuipers, 1996), a proposed standard knowledge representation formalism for compositional modellers, but adapted to meet the challenges of the ecological compositional
modelling problems identified in the introduction.
3.2.1 P RELIMINARY

CONCEPTS

The most primitive constructs in a compositional modeller are participants, relations and assumptions. This subsection summarises these concepts and explains how they are represented herein.
Participants2 refer to the objects of interest, which are involved in the scenario or its model.
These participants may be real-world objects or conceptual objects, such as variables that express
features of real-world objects in a mathematical model. For instance, a population of a species is
a typical example of a real-world object, and a variable that expresses the number of individuals
of this species forms an example of a conceptual object. It is natural to group objects that share
something in common into classes. Participants are herein grouped into participant classes, with
each representing a set of participants that share certain common features. Each class will be given
a name for easy reference.
Relations describe how the participants are related to one another. As with participants, some
relations represent a real-world relationship, such as:
2. Some of the previous work in compositional modelling refers to these as individuals and quantities, but such names
would not suit the present application. Ecological models typically describe the behaviour of populations rather than
that of individuals and it is often hard to distinguish between quantities.

514

fiC OMPOSITIONAL M ODEL R EPOSITORIES

predation(frog, insect)

(1)

Other relations may be conceptual in nature, such as equation (2), which describes an important
textbook model of logistic population growth (Ford, 1999):
d
size
change = parameter  size  (1 
)
dt
capacity

(2)

To be consistent with other compositional modelling approaches, this paper employs a LISPstyle notation for relations. As such, the above two sample relations become:

(predation frog insect)

(1)

(d/dt change (* change-rate size (- 1 (/ size capacity))))

(2)

Assumptions form a special type of relation that are employed to distinguish between alternative
model design decisions. Internally, assumptions will be stored in the form of assumption nodes in
the ATMS (see section 3.3.1), but in the knowledge base, assumptions appear as relations with a
specific syntax and semantics.
Two types of assumptions are employed in this article. Relevance assumptions state what phenomena are to be included in or excluded from the scenario model. Typical examples of phenomena
are the population growth and predation phenomena. The general format of a relevance assumption
is shown in (3). The phenomenon that is incorporated in the scenario model when describing a relevance assumption is identified by hnamei and is specific to the subsequent participants or relations.
For example, relevance assumption (4) states that the growth of participant ?population is to be
included in the model.

(relevant

hnamei

[{hparticipanti} | hrelationi])

(relevant growth ?population)

(3)
(4)

Model assumptions specify which type of model is utilised to describe the behaviour of a certain
participant or relation. Typical examples of model types include the exponential (Malthus, 1798)
and the logistic (Verhulst, 1838) model types of population growth. The formal specification of a
model assumption is given in (5). Often the hnamei in (5) corresponds to the name of a known
(partial) model of the phenomenon or process being described. The example in (6) states that the
population ?population is being modelled using the logistic approach.
(model

[hparticipanti | hrelationi]

hnamei)

(model ?population logistic)

515

(5)
(6)

fiK EPPENS & S HEN

Predators
natality

mortality
mortalityrate

natalityrate
preyrequirement

capacity

Prey
mortality

natality

natalityrate

predation

mortalityrate
capacity
searchrate
preyhandlingtime

Figure 3: Stock flow diagram of predator prey scenario model
3.2.2 S CENARIOS AND SCENARIO MODELS
As formalised by Keppens and Shen (2001b), a compositional modeller takes two inputs and produces one output. The first input is a representation (which is itself a model) that describes the
system of interest by means of an accessible formalism. This model, which normally consists of
(mainly) real-world participants and their interrelationships, is called the scenario. The second input
is the task description. It is a formal description of the criteria by which the adequacy of the output
is evaluated. The output is a new model that describes the scenario in a more detailed formalism,
usually a set of variables and equations, which the model-based reasoner can employ readily. Such a
model, which normally contains conceptual participants and interrelationships, is called a scenario
model. The aim of any compositional modeller is to translate the scenario into a scenario model, by
means of the task description.
In this work, a model is formally defined by a tuple hP, Ri, where P is a set of participants and
R is a set of relations over the participants in P . This definition applies to both the scenario and the
scenario model. A typical example of a scenario is a description of a predator population, a prey
population and a predation relation between the predator and the prey. This scenario is a model
hP, Ri with:
P = {predator, prey}
R = {(predation predator prey)}
The aim of the compositional model repository is to translate a scenario into a scenario model.
Within this work, both systems dynamics stock-flow formalism (Forrester, 1968) and ordinary differential equations (ODEs) will be employed as the modelling formalisms. For example, a scenario
model that corresponds to the above scenario is depicted in Figure 3. Formally, a scenario model is
another model hP, Ri and in this case
P = {Npredator , Bpredator , Dpredator , Nprey , Bprey , Dprey , Pprey ,
bpredator , bprey , dpredator , dprey , Cpredator , Cprey ,
s(prey,predator) , t(prey,predator) , r(predator,prey) }
516

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Symbol
Npredator , Nprey
Bpredator , Bprey
Dpredator , Dprey
Pprey
bpredator , bprey
dpredator , dprey
Cpredator , Cprey
s(prey,predator)
t(prey,predator)
r(predator,prey)

Variable name
number of predators, prey
natality of predators, prey
mortality of predators, prey
predation of prey
natality-rate of predators, prey
mortality-rate of predators, prey
capacity of predators, prey
search-rate
prey-handling-time
prey-requirement

Table 1: Variables in the stock flow diagram and the mathematical model
R={

d
Npredator = Bpredator  Dpredator ,
dt
d
Nprey = Bprey  Dprey  Pprey ,
dt
Bpredator = bpredator  Npredator ,
Bprey = bprey  Nprey ,
Dpredator = dpredator  Npredator 

Npredator
,
Cpredator

Nprey
,
Cprey
s(prey,predator)  Nprey  Npredator
=
,
1 + s(prey,predator)  Nprey  t(prey,predator)

Dprey = dprey  Nprey 
Pprey

Cpredator = r(predator,prey)  Nprey ,
Cprey = Nprey }
The relation between the variables of the mathematical model and those used in the stock-flow diagram is given in table 1. Generally speaking, stock-flow diagrams are graphical representations of
systems of (ordinary or qualitative) differential equations. In the automated modelling literature in
general, and engineering and physical systems modelling in particular, more sophisticated representational formalisms have been developed to enable the identification of mathematical models of the
behaviour of dynamic systems from observations. Examples include bond graphs (Karnopp, Margolis, & Rosenberg, 1990) and generalised physical networks (Easley & Bradley, 1999). However,
the potential benefits of these more advanced formalisms are not exploited here, but remain as an
interesting future work. Instead, stock-flow diagrams are employed throughout this paper as they
are far more commonly used in ecological modelling (Ford, 1999).
It is often possible to construct multiple scenario models from a single given scenario, and the
task specification is employed to guide the search for the most appropriate one(s). In this work,
scenario models are selected on the basis of hard constraints and user preferences. The hard constraints stem from restrictions imposed on compositionality by the representational framework (see
section 3.2.3) and from properties the scenario model is required to satisfy (see section 3.2.3). The
517

fiK EPPENS & S HEN

Name
Addition
Multiplication
Selection

Syntax (infix notation)
?var = C + (formula)
?var = C  (formula)
?var = C  (formula)
?var = C  (formula)
?var = C if,p (antecedent, formula)
?var = C else (formula)

Syntax (prefix notation)
(== ?var (C-add formula))
(== ?var (C-sub formula))
(== ?var (C-mul formula))
(== ?var (C-div formula))
(== ?var (C-if antecedent formula :priority p))
(== ?var (C-else formula)

Table 2: Composable functors and composable relations
user preferences express the users subjective view as to which modelling approaches are more
appropriate in the context of the current scenario (see section 2.2).
3.2.3 T HE

KNOWLEDGE BASE

To construct scenario models from a given scenario, a compositional modeller relies on the use
of a knowledge base that is particular to the problem domain. To illustrate the ideas, this section
presents the constructs employed in the compositional modeller that is developed to synthesise
scenario models in the ecological domain.
Composable relations The knowledge base in this approach consists of partial models that can be
instantiated and composed into more complex scenario models. The composition of partial models
into a scenario model may involve the composition of partial relations (coming from different partial
models) in compounded relations. In the sample scenario model of section 3.2.2, the following
relation describes the changes of population size of the prey population
d
Nprey = Bprey  Dprey  Pprey
dt

(7)

In (7), Nprey is the population size, Bprey the number of births, Dprey the number of natural deaths
and Pprey the number of prey who died due to predation. Thus, relation (7) actually describes two
phenomena that affect the population size Nprey : natural population growth (Bprey  Dprey ) and
predation related deaths (Pprey ). When constructing the knowledge base, it is desirable to represent
these two phenomena in isolation because they do not always occur in combination. For example,
some species do not have predators, and it is therefore unnecessary to always include predation
as a cause of death. From this viewpoint, relation (7) can be seen as composed from different
composable relations in the knowledge base:
d
Nprey = C + (Bprey )
dt

d
Nprey = C  (Dprey )
dt

d
Nprey = C  (Pprey )
dt

The use of composable relations enables the knowledge base to cover as many combinations
of the phenomena that may affect a relation as possible, by representing each phenomenon individually rather than precompiling everything together. Because only the component parts (i.e. the
composable relations) of relations need to be represented, instead of all possible, and however complex, combinations of them, the knowledge base can be smaller and more effective. This section
describes how such composable relations are represented in the knowledge base, as well as whether
and how they can be composed to form compounded relations.
518

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Composable relations are those containing composable functors and for which a method of
composition exists (that describes how a complete set of composable relations can be composed).
The composable functors employed are those proposed by Bobrow et al. (1996) with a new addition:
composable selection. A summary of such composable relations is presented in table 2.
The composable relations introduced by Bobrow et al. (1996) are easy to understand. The
formulae f in v = C + (f ) and v = C  (f ) represent terms (respectively f and f ) of a sum, and
the formulae f in v = C  (f ) and v = C  (f ) represent factors (respectively f and f1 ) of a product.
However, ecological models in use typically contain selection statements which declare that
one certain equation must be employed when a condition is satisfied and some other one otherwise.
Formally, a selection is a relation of the form
if c1 then v = r1 else if c2 . . . else v = rn

(8)

where v is a participant, each ci (with i = 1, . . . , n1) is a relation describing a condition statement
and each rj (with j = 1, . . . , n) is a relation. This selection relation consists of the partial relations:
if ci then v = ri

with i = 1, . . . , n  1

else v = rn
Therefore, a selection relation can be composed from two types of composable relation. The first
is a composable if relation, which has the form v = C if,p (a, f ), where v is a participant, p is an
element taken from a total order, such as the set of natural numbers , which denotes the priority of
the composable if relation in the sequence, and a and f are two given relations. The second type
of composable relation is a composable else relation, which has the form v = C else (felse ), where
felse is a given relation assigned to v if none of the antecedents in the composable if relations is
true.
To illustrate this notation, the selection relation (8) can be composed from the following composable relations:
v = C if,p1 (c1 , r1 )
..
.
v = C if,pn1 (cn1 , rn1 )
v = C else (rn )
with p1 > . . . > pn1 .
To combine the composable relations, a number of rules are defined to implement the semantics
of the representational formalism. In theory, a set of rules can be generated that enables the aggregation of any set of composable relations. In practice, however, a trade-off must be made between
flexibility (the ability to combine many different types of composable relation) and comprehensibility (the use of a set of rules that is easily understood by the knowledge engineer who employs
composable relations). Thus, the types of composable relations that can be combined has to be
restricted.
Table 3 summarises what composable relations can be joined to form compounded relations.
The principle guiding the construction of this table is to allow only the composition of relations of
certain types for which a resulting compound relation is intuitively obvious. For example, according
519

fiK EPPENS & S HEN

C + (f1 )
C  (f1 )
C  (f1 )
C  (f1 )
C if,p1 (a1 , f1 )
C if,p2 (a1 , f1 )
C else (f1 )

C + (f2 )
yes
yes
no
no
no
no
no

C  (f2 )
yes
yes
no
no
no
no
no

C  (f2 )
no
no
yes
yes
no
no
no

C  (f2 )
no
no
yes
yes
no
no
no

C if,p2 (a2 , f2 )
no
no
no
no
yes
no
yes

C else (f2 )
no
no
no
no
yes
yes
no

Table 3: Composibility of composable relations
to Table 3, a composable addition relation x = C + (y) can be combined with a composable subtraction relation x = C  (z) because their combination is clearly x = y  z. However, according to
Table 3, a composable addition relation x = C + (y) can not be combined with a composable multiplication relation x = C  (z), because an arbitrary and non-intuitive rule would otherwise have to
be defined to decide whether the compound relation would be x = y + z or x = y  z.
The order in which the composable selections must be considered is defined by the priorities
(or is implicit in the case of C else ). Therefore, composable selections can be combined with one
another provided no two composable if relations have the same priority.
In order to derive the actual rules of composition, the sets of all composable relations with the
same functor for a given model hP, Ri are defined first:

R(v, C + ) = {v = C + (fi ) | (v = C + (fi ))  R}
R(v, C  ) = {v = C  (fi ) | (v = C  (fi ))  R}
R(v, C  ) = {v = C  (fi ) | (v = C  (fi ))  R}
R(v, C  ) = {v = C  (fi ) | (v = C  (fi ))  R}
R(v, C if ) = {v = C if,pi (ai , fi ) | (v = C if,pi (ai , fi ))  R}
R(v, C else ) = {v = C else (fi ) | (v = C else (fi ))  R}
From this, the rules of composition can be built as given in the expressions (9), (10) and (11).
They jointly state how a given set of composable relations can be rewritten as a single compound
relation. Each of these rules contains a complete set of all composable relations in the antecedent.
In particular, the antecedent of rule (9) contains the set of all composable addition and subtraction
relations with the same participant v in the left-hand side.
Similarly, the antecedent rule (10) contains the complete set of composable multiplication relations. Finally, the antecedent of rule (11) is satisfied for the complete set of composable if and else
relations with the same left-hand participant v, provided that the priorities are strictly ordered (i.e.
no two priorities are equal) and that there is only a single composable else relation. The latter two
conditions are added because two composable if relations with the same priority or two composable
else relations can not be compounded. The consequents of the rules of composition explain how
these complete sets of composable relations can be joined. This is simply a matter of applying the
appropriate mathematical operation to the provided terms.
520

fiC OMPOSITIONAL M ODEL R EPOSITORIES

R(v, C + ) = {v = C + (f1+ ), . . . , v = C + (fm+ )}
R(v, C  ) = {v = C  (f1 ), . . . , v = C  (fn )} 

(9)

v = f1+ + . . . + fm+  (f1 + . . . + fn )
R(v, C  ) = {v = C  (f1 ), . . . , v = C  (fm )}
R(v, C  ) = {v = C  (f1 ), . . . , v = C  (fn )} 
1  f1  . . .  fm
v=
f1  . . .  fn

(10)

R(v, C if ) ={v = C if,p1 (a1 , f1 ), . . . , v = C if,pm (am , fm )}
R(v, C else ) ={v = C else (felse )}  p1 > . . . > pm 

(11)

v =if a1 then f1 , else . . . , if am then fm , else felse
Property definitions Property definitions describe features of interest to the application requiring
a scenario model. A property definition  is a tuple hP s , , i where P s = {ps1 , . . . psm } is a set of
source-participants, a predicate calculus sentence  whose free variables are elements of P s , and
 is a relation, whose free variables are also elements of P s , such that
ps1 , . . . , psm   

A typical example of a feature of interest is the requirement that a certain variable in the model
is endogenous or exogenous. To be more specific, the property definitions below describe when a
variable ?v is endogenous and exogenous respectively.
(defproperty endogenous
:source-participants ((?v :type variable))
:structural-condition ((or (== ?v *) (d/dt ?v *)))
:property (endogenous ?v))
(defproperty exogenous
:source-participants ((?v :type variable))
:structural-condition ((not (endogenous ?v)))
:property (exogenous ?v))
d
?v = * is true (where * matches
The first definition states that whenever either ?v = * or dt
any constant or formula), ?v is deemed to be endogenous. The second property definition indicates
that a variable is said to be exogenous if such an object exists and it is not endogenous.
By describing such features formally in the knowledge base, property definitions enable them
to be imposed as criteria on the selection of scenario models. In this way, the variable describing
the size of a particular population in an eco-system, for instance, can be forced to be endogenous.
Note that required properties can be specified in two different ways: either globally as goals for
the scenario model construction or locally as a required purpose of a certain model fragment. The
latter use of model properties will be illustrated later.

521

fiK EPPENS & S HEN

Model fragments Model fragments are the building blocks with which scenario models are constructed. A model fragment  is a tuple hP s , P t , s , t , A, i where P s = {ps1 , . . . psm } is a
set of variables called source-participants, P t = {pt1 , . . . , ptn } is a set of variables called targetparticipants, s = {s1 , . . . , sv } is a set of relations, called structural conditions, whose free variables are elements of P s , t = {t1 , . . . , tx } is a set of relations, called postconditions, whose free
variables are elements of P s  P t , A = {a1 , . . . , ay } is a set of relations, called assumptions, and
 = is a set of relations, called purpose-required properties, such that:
ti  t , ps1 , . . . , psm , pt1 , . . . , ptn , s1  . . .  sv  (a1  . . .  ay  ti )
 

, ps1 , . . . , psm , pt1 , . . . , ptn ,

s1

 ... 

sv

 a1  . . .  ax    

(12)
(13)

Note that, in this work, each property definition hP s , , i is equivalent to a model fragment
hP s , {}, , {}, {}, {}i.
For example, the model fragment below states that a population ?p can be described by two
variables ?p-size (describing the size of ?p) and ?p-change (describing the rate of change in
population size) and a differential equation
d
?p-size = ?p-change
dt
The usage of this partial scenario model is subject to two conditions: (1) the growth phenomenon is
relevant with regard to ?p, and (2) the variable ?p-change is endogenous in the eventual scenario
model. The former requirement is indicated by the relevance assumption and the latter by the
purpose-required property:
(defModelFragment population-growth
:source-participants ((?p :type population))
:assumptions ((relevant growth ?p))
:target-participants ((?p-size :type variable)
(?p-change :type variable))
:postconditions ((size-of ?p-size ?p)
(change-of ?p-change ?p)
(d/dt ?p-size ?p-change))
:purpose-required ((endogenous ?p-change)))

The purpose-required property is usually satisfied by additional model fragments, such as the
one below:
(defModelFragment logistic-population-growth
:source-participants ((?p :type population)
(?p-size :type variable)
(?p-change :type variable))
:structural-conditions ((size-of ?p-size ?p)
(change-of ?p-births ?p))
:assumptions ((model ?p-size logistic))
:target-participants ((?r :type parameter)
(?k :type variable)
(?d :type variable))
:postconditions ((capacity-of ?k ?p)
(density-of ?d ?p-size)
(== ?d (C-add (/ ?p-size ?k)))
(== ?p-change (- (* ?r ?p-size (- 1 ?d))))))

522

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Model fragments are rules of inference that describe how new knowledge can be derived from
existing knowledge by committing the emerging model to certain assumptions. They are used
to generate a space of possible models. Model fragments are instantiated by matching sourceparticipants to existing participants in the scenario or an emerging model, and by matching the
structural conditions to corresponding relations. For each possible instantiation, a new instance is
generated for each of the target-participants, and where necessary, new instances are also created for
the postconditions and assumptions. Such instances, as well as the inferential relationships between
the instances of the source-participants, structural conditions and assumptions on the one hand, and
those of the target-participants and postconditions on the other, are stored in an ATMS, forming the
model space. This is to be further explained in section 3.3.1.
A model fragment is said to be applied if it is instantiated and the underlying assumptions
hold. If a model fragment is applied, the instances of the target-participants and postconditions
corresponding to the instantiation of that model fragment must be added to the resulting model. With
respect to the above example, the model fragment that implements the logistic population growth
model is instantiated whenever variables exist that describe the size and change in a population, and
it is applied if the logistic model for population size has also been selected.
Note that in most compositional modellers, such as the ones devised by Heller and Struss (1998,
2001); Levy, Iwasaki and Fikes (1997); Nayak and Joskowicz (1996); and Rickel and Porter (1997),
model fragments represent direct translations of components of physical systems into influences between variables. Because the compositional modeller presented herein aims to serve as an ecological
model repository, the contents of the model fragments employed differs from that of conventional
compositional modellers in two important regards:
Firstly, model fragments contain partial models describing certain phenomena instead of influences. These partial models normally correspond to those developed in ecological modelling
research. Typical examples include the logistic population growth model (Verhulst, 1838) and the
Holling predation model (Holling, 1959) devised in the population dynamics literature.
Secondly, the partial models contained in the model fragments often need to be composed incrementally. For example, the aforementioned sample model fragment logistic-populationgrowth requires an emerging scenario model, which may be generated by the other sample model
fragment population-growth. Thus, one model fragment, e.g. logistic-populationgrowth, can expand on the partial model contained in another, e.g. population-growth. Because of this feature, it is (correctly) presumed that no model fragment  generates new relations
that are preconditions of model fragments that  expands on. Violating this presumption would
make little sense in the context of the present application as it would imply a recursive extension of
an emerging scenario model with the same set of variables and equations.
3.2.4 PARTICIPANT CLASS DECLARATION AND PARTICIPANT TYPE HIERARCHIES
In general, participant classes need not be defined. However, certain types of participant may be
described in terms of other interesting participants, irrespective of the modelling choices. This
feature provides syntactic sugar for describing important relations between participants, making it
easier to declare required properties of a scenario model in terms of the participants of the scenario.
For example, the behaviour of a population may be described in terms of population size and growth
rate variables:
(defEntity population
:participants (size growth-rate))

523

fiK EPPENS & S HEN

Participant class declarations may also be employed within model fragments to provide a more
specific definition of the meaning of the source-participants and the target-participants. In this way,
participant specifications are constrained to be a feature of another participant by means of the
:entity statement, as the following example illustrates:
(defModelFragment define-population-growth-phenomenon
:source-participants ((?p :type population))
:target-participants
((?ps :type stock :entity (size ?p))
(?pg :type variable :entity (growth-rate ?p))
(?pb :type flow)
(?pd :type flow))
:assumptions ((relevant growth ?p))
:postconditions ((== ?pg (- ?pb ?pd))
(flow ?pb source ?pl)
(flow ?pd ?pl sink)))

Furthermore, participant class declarations may define one class to be an immediate subclass of
another. For example, the population participant class of holometabolous insects (e.g. butterflies)
may be defined as a subclass of the population participant class:
(defEntity holometabolous-insect-population
:subclass-of (population)
:participants
(larva-number pupa-number adult-number))

In this way, a participant type hierarchy is defined. Each subclass inherits all participants of its
superclasses (i.e. its immediate superclass and superclasses of superclasses).
In summary, a participant class declaration is a tuple  = h S , P i where S is a participant
class, called the immediate superclass of the participant class and P is a set of participants classes
that describe important features of the participant class.
3.3 Inference
The compositional modelling method presented herein employs a four step inference procedure:
1. Model space construction. The model space is an ATMS that efficiently stores all the participants, relations and model design decisions (represented in the form of relevance and model
assumptions) that may be part of the final scenario model, as well as the conditions under
which each of these participants and relations must or must not be part of the scenario model.
2. aDCSP construction. The model space contains a number of hard constraints on the participants and relations that may be combined. This inference step extracts such restrictions and
translates them into an aDCSP.
3. Inclusion of order-of-magnitude preferences. Preferences are associated with relevance and
model assumptions in the scenario space as they reflect the relative appropriateness of these
assumptions, resulting in an aDPCSP.
4. Scenario model selection. This inference step solves the aDPCSP. The resulting solutions
correspond to scenario models that are consistent according to the domain knowledge and
optimise the overall preference with respect to the order-of-magnitude preference calculus.
524

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Problem Specification

Compositional Model Repository

population(prey)
population(predator)
predation(predator,prey)

Application

STEP 1
Model Space Construction

Scenario
Model Space

Requirements and
Inconsistencies
Generation

Activitybased Dynamic Constraint
Satisfaction Problem Construction

Requirements
and Inconsistencies

Knowledge Base
STEP 2

Scenario Model
Construction
Dynamic Constraint
Satisfaction Problem

Scenario Model
STEP 3
Inclusion of OrderofMagnitude
Preferences

Preferences or
Preference Ordering

Dynamic Preference Constraint
Satisfaction Problem

Application

Prey
death
rate

birth
rate

crowding
max crowd
sustainable
population

fooddemand

consumption

STEP 4

Predator
death
rate

birth
rate

Scenario Model Selection
(aDCSP solver)

crowding

Assumption Set

Knowledge elements

Inference elements

Figure 4: Inference procedures of the compositional modeller

525

fiK EPPENS & S HEN

These four steps correspond to the four squares of the compositional model repository in Figure 4
In this section, each of these inference steps is discussed in detail and illustrated by means of
simple examples. The next section contains a more detailed example and shows how this procedure
can be applied to a non-trivial ecological modelling domain.
3.3.1 S CENARIO + K NOWLEDGE BASE = M ODEL S PACE
As previously stated, the aim of a compositional modeller is to translate a scenario into a scenario
model. Both are representations of the system of interest though they model the system at a different
level of detail. The knowledge base provides the foundation for translation. All the scenario models
that can be constructed from the given scenario, with regard to the knowledge base, are stored in the
model space.
A model space is an ATMS (de Kleer, 1986) containing all the participants, relations and assumptions that can be instantiated from a given scenario. In this work, the generalised version of
the ATMS, as introduced by de Kleer (1988), is employed as it allows the use of negations of nodes
in the justifications. The algorithm GENERATE M ODEL S PACE(hO, Ri) describes how such a model
space can be created from a scenario hO, Ri. It first initialises the model space  with the participant instances (O) and the relation instances (R) from the scenario. Then, for each model fragment whose source-participants and structural conditions match participants and relations already
in , new instances of its target-participants, assumptions and postconditions are added to . Because each property definition hP s , , i is equivalent to a model fragment hP s , {}, , {}, {}, {}i,
this procedure applies to property definitions as well as model fragments. Matching the sourceparticipants and structural conditions of a model fragment  to the emerging model space is performed by the function match(, , ) as specified below, where  is the model fragment being
matched, and  is a substitution from the source-participants of  to participant instances.


true if  = {ps1 /o1 , . . . , psm /om }





P s () = {ps1 , . . . , psm }

match(, , ) =
o1    . . .  om  



  s (),   




false otherwise
Each match, specified by a model fragment  and a substitution , is processed as follows:

 For each assumption a  A(), a new node, denoting the assumption instance a, is created
and added to .
 Then, a new node n(,) , denoting the instantiation of  via substitution , is created, added
to  and justified by the implication:
(aA() a)  (pP s () p)  (s () )  n(,)
 Finally, a new instance for each target-participant p  P t () and for each postcondition
  t (), provided  does not already exist in the model space , is created. For the
target-participants, this involves creating a new symbol for each new participant instance with
the function gensym() and extending  with the substitution {p/gensym()}. A new node n
526

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Algorithm 1:

GENERATE M ODEL S PACE(hO, Ri)

  new ATMS;
for each o  O, add-node(, o);
for each r  R, add-node(, r);
for each , , match(, , )

justification  ;




for each

 a  A()



newnode  add-node(, (a));


do


justification
 justification  {newnode};


for each p  P s ()





do justification  justification  {find-node(, (p))};



for each   s ()




do justification  justification  {find-node(, ())};




add-node(, n(,) );
do add-justification(, n(,) , njustificationn);

t


for each
 p  P ()



    {p/gensym()};




do o  add-node(, (p));





add-justification(, o, n(,) );


t


for each

    ()



if (  )







then o  get-node(, ());

 do


else
o  add-node(, ());





add-justification(, o, n(,) );
for each n1 , . . . , nm , inconsistent({n1 , . . . , nm )
do add-justification(, n , n1  . . .  nm );

{
{
{

a1

Instances of assumptions:
A() = {a1 , . . . , at }

..
.
pt1x

at

Instances of sourceparticipants:
P s () = {ps1 , . . . , psm }

Instances of structural
conditions:
s () = {s1 , . . . , sv }

ps1

..
.

..
.







ptn


t1

psm

..
.

s1

ts

..
.

}
}

Instances of target
participants:
P t () = {pt1 , . . . , ptn }

Instances of postconditions:
t () = {t1 , . . . , ts }

sv

Figure 5: Model fragment application

is created and added to  for each new participant instance p and for each new instantiated
relation . Each of these nodes is justified by the implication n (,)  n.
527

fiK EPPENS & S HEN

 is a global property that must by satisfied
by all consistent scenario models

 is a purpose-required property in a model fragment ,
and  is applied with a substitution .

r1 and r2 are
non-composable relations

v = r1 (. . .)

















(a) Inconsistency caused by a
global property



v = r2 (. . .)




(b) Inconsistency caused by a
purpose-required property

(c) Inconsistency caused by
non-composable relations

Figure 6: Sources of inconsistency
To illustrate this procedure, Figure 5 shows a graphical representation of the inferences that are
constructed by applying a model fragment  = hP s , P t , s , t , A, {}i with respect to a substitution
.
Once all possible applications of model fragments have been exhausted, the inconsistencies in
the model space are identified and recorded in the ATMS. In the algorithm, nogoods are generated
for each set {n1 , . . . , nm } of inconsistent nodes, denoted inconsistent({n1 , . . . , nm }). There are
three sources of inconsistencies that are each reported to the ATMS in a different way:
 Global properties: Let  be an instance of a global property that any scenario model must
satisfy. Then, any combination of assumptions and negations of assumptions that prevents 
from being satisfied is inconsistent. Therefore, inconsistent({}) must be reported for any
required global property . This type of inconsistency is depicted in Figure 6(a).
 Purpose-required properties: Any application of a model fragment  without satisfying its
purpose-required properties () yields an inconsistency (see (13)). Hence, for each node
n(,) denoting the instantiation of  via substitution , and for each node n  describing the
appropriate instance of a purpose-required property   (), inconsistent({n (,) , n })
is reported. This type of inconsistency is depicted in Figure 6(b).
 Non-composable relations: In any mathematical formalism designed to describe simulation
models of dynamic systems, certain combinations of relations may over-constrain the model,
and hence, be unsuitable for generating the behaviour of a system of interest. Within the
system dynamics and ODE formalisms used in this paper, assignments of relations to the
same variable are only composable if those relations are explicitly deemed composable. In
other words, two relations v = ri and v = rj can only be combined with one another if ri
and rj are composable. Examples of pairs of non-composable relations include
x = C + (y) and x = C  (z) because C + and C  relations are not composable, and
a = C + (b) and a = c + d because c + d is not a composable relation.
Combinations of such non-composable relations must be reported as an inconsistency as well.
This type of inconsistency is depicted in Figure 6(c).
528

fiC OMPOSITIONAL M ODEL R EPOSITORIES

assumption:
(relevant growth frog)
participant:
population frog
1 :
2 :
:

1

assumption:
(model nfrog logistic)

participant:
parameter rfrog

relation:
d
dt nfrog = cfrog

participant:
parameter kfrog

participant:
variable cfrog

relation:
(capacity-of kfrog frog)

participant:
variable nfrog

population-growth
model fragment
logistic-population-growth
model fragment
endogenous
property definition

cfrog = rfrog  nfrog  (1 

nfrog
)
kfrog

relation:
(change-of cfrog frog)
relation:
(size-of nfrog frog)

relation:
endogenous(cfrog )

relation:

2





relation:
(endogenous cfrog )



Figure 7: Partial model space
To illustrate the model space construction algorithm, Figure 7 presents a small sample model
space. It results from the application of the population-growth and logistic-population-growth model fragments and the endogenous property definition, which were described
earlier, for a single population frog. If a larger scenario involving multiple populations and relations between these populations were specified, a similar partial model space would be generated
for each individual population.
3.3.2 F ROM

MODEL SPACE TO A DCSP

Once the model space has been constructed, it can be translated into an aDCSP. The translation
procedure, summarised as algorithm CREATEA DCSP(), consists of three steps as described below:
Algorithm 2:

CREATEA DCSP()

comment:  is the set of substitutions
  {};
comment: Generate attributes and domains
for each
 A, assumption-class(A)
x  create-attribute();




D(x)
 {};




    {A/x};
do for each
 aA



v  create-value();



 do D(x)  D(x)  {v};



    {a/x : v};
comment: Generate activity constraints
for each
 A, assumption-class(A)
s  subject(A);
do for each {a1> , . . . , ap> , a1 , . . . , aq }  L(s)

do add(a1>  . . .  ap>  a1  . . .  aq  active(A));
comment: Generate compatibility constraints
for each {a1> , . . . , ap> , a1 , . . . , aq }  L(n )
do add(a1>  . . .  ap>  a1  . . .  aq  );

529

fiK EPPENS & S HEN

1. Generate the attributes and domain values from the assumptions. The aDCSP attributes correspond to the underlying assumption classes (i.e. groups of assumptions indicating alternative
choices with regards to the same model construction decision). A relevance assumption and
its negation jointly form an assumption class. For example, A 1 ={(relevant growth
frog), (relevant growth frog)} specifies such an assumption class. The set of
model assumptions involving the same participants/relations, but with different model names
and hence different descriptions, also form an assumption class. For instance, A 2 ={(model
nfrog exponential), (model nfrog logistic), (model nfrog other)}, where
nfrog is a variable denoting the size of a population, specifies such an assumption class. Running this step of the algorithm, an attribute is created for each assumption class, with the
domain of such an attribute consisting of all assumption instances in the assumption class.
2. Create activity constraints. The attributes and domain values generated in the previous step
are only meaningful in situations where the participant and/or relation instances contained in
the arguments of the corresponding assumptions exist. For example, the assumption (model
nfrog logistic) is only relevant if the participant instance nfrog exists. Clearly, all assumptions within one assumption class have the same participant and/or relation instances as
their arguments. Because each assumption class corresponds to one attribute, the attribute
can be activated if and only if the participant and/or relation instances associated with the related assumption class are active. Therefore, this step creates activity constraints that activate
an attribute based on the conjunction of the environments contained within the labels of the
participants/relations of the assumption class. For instance, as can be deduced from Figure
7, nfrog is activated when (relevant growth frog) is committed. Thus, the attribute
corresponding to assumption class A2 , defined in step 1, is activated under the attribute value
assignment associated with the (relevant growth frog) assumption.
3. Create compatibility constraints. In the ATMS (or model space), all sources of inconsistencies are contained in the label of the nogood node. Therefore, the compatibility constraints
are created directly by translating the environments in the label L() into the corresponding
conjunctions of attribute-value assignments.
3.3.3

A DCSP

+

PREFERENCES

= A DPCSP

The aDCSP produced as above formalises the hard requirements imposed upon the scenario models.
Among the scenario models that meet these requirements, some may be better than others, because
the underlying model design decisions may be deemed more appropriate by the user. Preferences
that express this (relative) level of appropriateness are attached to the assumptions that describe the
model design decisions, and by extension, to the attribute-value pairs in the aDCSP. As discussed in
section 2, such an extension to the aDCSP constitutes an aDPCSP.
More specifically, it is worth recalling that in section 2.2 an order-of-magnitude preference
calculus is presented that enables representation and reasoning with subjective user preferences for
different relevance and modelling assumption. Next, section 2.3 introduces a solution algorithm for
aDPCSPs that include an aDCSP, such as the ones constructed with the approach of section 3.3.2,
and are extended with subjective user preferences for alternative design decisions.
530

fiC OMPOSITIONAL M ODEL R EPOSITORIES

3.4 Outline analysis of complexity
The complexity of the work arises from four major sources: 1) model space construction, 2) label
propagation in the ATMS, 3) model space to aDCSP translation, and 4) aDPCSP solution.
GENERATE M ODEL S PACE (hO, Ri) essentially performs a fixed sequence of instructions and
produces a small set of nodes and inferences for each match of a model fragment. Therefore, its
time and space complexity are linear with respect to the number of possible matches of model
fragments. CREATEA DCSP() extracts certain information from the model space and rewrites it in
a different formalism without further manipulations. Therefore, its time and space complexity are
linear with respect to the size of the model space.
The label propagation algorithm of an ATMS is known to have an exponential time complexity.
However, because the model space is built up incrementally (by GENERATE M ODEL S PACE(hO, Ri))
from the root nodes of the ATMS network (i.e. those that correspond to facts and have no antecedents) to the leaf nodes (i.e. those that have have no consequents, other than the nogood node)
and because the inconsistencies are added at the end, this complexity only increases exponentially
with the depth of the network and the number of participants and relations in individual model fragments, rather than with the size of the model space. This fact significantly limits the complexity
impact of label propagation. Firstly, the depth of the ATMS network is restricted by the domain.
In many conventional compositional modellers, where model fragments are direct translations from
scenario components to scenario model equations, this depth would be only one. Empirically, constructing the model space for sophisticated eco-systems, the depth of a model space never exceeded
8. Secondly, the size of the individual model fragments does not change significantly with the size
of the knowledge base.
The fourth and final source of complexity is driven by the fact that the constraint satisfaction
algorithm must determine a consistent combination of assumptions in the model space. The space
of attribute value assignments increases exponentially with the size of the number of assumptions
and hence, with the model space. Thus, the overall complexity of the present approach is largely
dominated by the constraint satisfaction algorithm employed.
If the user does not specify any preference, the CSP is an aDCSP. Recently, a number of efficient
methods have been devised for solving aDCSPs as presented by Minton et al. (1992); Mittal and
Falkenhainer (1990); and Verfaillie and Schiex (1994). This helps minimise the overhead incurred
for compositional modelling.
With preferences, the CSP becomes an aDPCSP. As argued in section 2, this presents a new
problem that has not yet been studied in detail. In this work, an A* algorithm has been proposed to
implement the CSP solution method. This approach is known to be the most efficient in terms of
the proportion of the search space the algorithm needs to explore before finding an optimal solution,
when compared to other search methods that are based on the same heuristic (Hart et al., 1968). A
disadvantage is that it incurs an exponential space complexity. As explained by Miguel and Shen
(2001a, 2001b); and Tsang (1993), a wide range of alternative solution techniques exist for ordinary
CSPs and many of these could also be extended to solve aDPCSPs. A detailed examination of these
techniques is a topic of future research.
3.5 Automated modelling and scientific discovery
As mentioned previously, a compositional model repository is designed in order to compose models
from a systems structure and relevant domain knowledge. As such, this approach gives rise to a po531

fiK EPPENS & S HEN

tentially beneficial means to operationalise the outcomes of scientific discovery. More specifically,
the resultant compositional model repositories will allow existing knowledge on model construction
to be applied to unexperienced scenarios and to support investigation into situations which may be
physically difficult to replicate or create but which may be synthesised in computational representations.
The present work has been applied to the vegetation component of the MODMED n-species
model (Legg, Muetzelfeldt, & Heathfield, 1995). This n-species model offers a system dynamics
representation of populations of Mediterranean vegetations and of how they are affected by populations of farm animals, climate and environmental management. The purpose of the model is to
be instantiated with respect to various Mediterranean communities, and to serve as a component
of a very large scale simulation that is designed to simulate the effects of various environmental
policies on the Mediterranean landscape. A knowledge base containing approximately 60 model
fragments and 4 property definitions has been constructed, on the basis of the most complex parts
of the n-species model in about two man-weeks. This knowledge base can be employed to reconstruct variations of the n-species model to accommodate a variety of possible scenarios, as well as
to examine simplifications of the original n-species model which exclude certain phenomena.
The compositional model repository is most closely related to the seminal work on compositional modelling (Falkenhainer & Forbus, 1991). That approach has a similar functionality but
it is devised specifically for physical systems and relies on a component-connection formalism to
represent scenarios.
Another approach which has recently been developed and applied to the ecological domain by
Heller and Struss (1998, 2001). This work derives a systems structure from observations of its
behaviour and domain knowledge. Therefore, it is able to perform diagnosis of ecological systems
and therapy suggestion. Another important distinction of this work from the present study is that
it presumes that each process can only be described in just one way instead of allowing multiple
alternative models.
In the machine learning community, a number of approaches have been devised by Bradley,
Easley and Stolle (2001); Langley et al. (2002); and Todorovski and Dzeroski (1997, 2001) to
induce sets of differential equations from a) observations of behaviour, b) domain knowledge represented in the form of hypothetical equations, and c) a description of the structure of the system.
These approaches aim at scientific discovery by generalising observed behaviour into mathematical
models. The specifications of the scenario and the domain knowledge in these methods are similar
to those used in this article. This is especially true for the work by Langley et al. (2002); and Todorovski and Dzeroski (1997, 2001), because that work has also been applied to population dynamics.
However, the internal mechanisms of these approaches are very different as they essentially rely on
exhaustive search procedures instead of constraint satisfaction techniques.

4. A Population Dynamics Example
The examples used throughout the previous sections were taken from a more extensive application
study of the present work. The application was aimed to construct a repository of basic population
dynamic models, describing the phenomena of growth, predation and competition. This section
presents an overview of how the proposed approach is employed in this application to show the
ability of the work to scale to larger problems.
532

fiC OMPOSITIONAL M ODEL R EPOSITORIES

4.1 Knowledge base
This subsection illustrates how a set of model fragments can be constructed. The challenge of
this task lies in the fact that model fragments must encompass a sufficiently general and reusable
component part of the ecological models. In instances of models found in the literature on ecological
modelling, the boundaries of the recurring component parts are hidden, and it is therefore up to the
knowledge engineer to identify them.
First, a hierarchy of entity types is set up. The system dynamics models shown earlier contain
only three types of participant: variables, stocks and flows. Here, stocks and flows are a special
type of variable with a predetermined meaning. That is, a flow f into a stock s corresponds to the
d
d
s = C + (f ) and a flow f out of a stock s denotes dt
s = C  (f ). Hence, stocks and
equation dt
flows are defined as subclasses of the participant class variable:
(defEntity variable)
(defEntity stock
:subclass-of (variable))
(defEntity flow
:subclass-of (variable))

The sample properties defined in section 3.2.3, which describe the condition under which a
variable is endogenous or exogenous, are employed in this knowledge base:
(defproperty endogenous-1
:source-participants ((?v :type variable))
:structural-conditions ((== ?v *))
:property (endogenous ?v))
(defproperty endogenous-2
:source-participants ((?v :type variable))
:structural-conditions ((d/dt ?v *))
:property (endogenous ?v))
(defproperty exogenous
:source-participants ((?v :type variable))
:structural-conditions ((not (endogenous ?v)))
:property (exogenous ?v))

The next three model fragments contain the rules of the stock-flow diagrams employed by systems dynamics models. They respectively describe that:
 A flow ?flow into a stock ?stock corresponds to the composable differential equation:
d
?stock = C + (?flow)
dt
 A flow ?flow out of a stock ?stock corresponds to the composable differential equation:
d
?stock = C  (?flow)
dt
 A flow ?flow from one stock ?stock1 to another stock ?stock2 corresponds to the
composable differential equations:
d
d
?stock1 = C  (?flow) and ?stock2 = C + (?flow)
dt
dt
533

fiK EPPENS & S HEN

(defModelFragment inflow
:source-participants
((?stock :type stock)
(?flow :type flow))
:structural-conditions
((flow ?flow source ?stock))
:postconditions
((d/dt ?stock (C-add ?flow))))
(defModelFragment outflow
:source-participants
((?stock :type stock)
(?flow :type flow))
:structural-conditions
((flow ?flow ?stock sink))
:postconditions
((d/dt ?stock (C-sub ?flow))))
(defModelFragment inflow
:source-participants
((?stock1 :type stock)
(?stock2 :type stock)
(?flow :type flow))
:structural-conditions
((flow ?flow ?stock1 ?stock2))
:postconditions
((d/dt ?stock1 (C-sub ?flow))
(d/dt ?stock2 (C-add ?flow))))

Once the above declarations are in place, the knowledge base of model fragments can be defined. The first model fragment describes the population growth phenomenon. Note that all of the
aforementioned growth, predation and competition models contain a stock representing population
size and two flows, one flow of births into the stock and another flow of deaths out of the stock. This
common feature of models on population dynamics is contained in a single model fragment.
(defModelFragment population-growth
:source-participants
((?population :type population))
:assumptions
((relevant growth ?population))
:target-participants
((?size :type stock :name size)
(?birth-flow :type flow :name births)
(?death-flow :type flow :name deaths))
:postconditions
((flow ?birth-flow source ?size)
(flow ?death-flow ?size sink)
(size-of ?size ?population)
(births-of ?birth-flow ?population)
(deaths-of ?death-flow ?population))
:purpose-required
((endogenous ?birth-flow)
(endogenous ?death-flow)))

The variables ?birth-flow and ?death-flow become endogenous if the model contains
an equation describing birth flow and death flow. These equations differ between population growth
models. Two types of population growth model are the exponential growth model (Malthus, 1798),
which is shown in Figure 8(a), and the logistic growth model (Verhulst, 1838), which is shown in
Figure 8(b). The following two model fragments formally describe these component models:
534

fiC OMPOSITIONAL M ODEL R EPOSITORIES



	 	 
 fffi



  




  fffi!
"



(a) Exponential growth




(b) Logistic growth

Figure 8: Population growth models
(defModelFragment exponential-population-growth
:source-participants
((?population :type population)
(?size :type variable)
(?birth-flow :type variable)
(?death-flow :type variable))
:structural-conditions
((size-of ?size ?population)
(births-of ?birth-flow ?population)
(deaths-of ?death-flow ?population))
:assumptions
((model ?size exponential))
:target-participants
((?birth-rate :type variable :name birth-rate)
(?death-rate :type variable :name death-rate))
:postconditions
((== ?birth-flow (* ?birth-rate ?size))
(== ?death-flow (* ?death-rate ?size))))
(defModelFragment logistic-population-growth
:source-participants
((?population :type population)
(?size :type variable)
(?birth-flow :type variable)
(?death-flow :type variable))
:structural-conditions
((size-of ?size ?population)
(births-of ?birth-flow ?population)
(deaths-of ?death-flow ?population))
:assumptions
((model ?size logistic))
:target-participants
((?birth-rate :type variable :name birth-rate)
(?death-rate :type variable :name death-rate)
(?density :type variable :name total-population)
(?capacity :type variable :name capacity))
:postconditions
((== ?birth-flow (* ?birth-rate ?size))
(== ?death-flow (* ?death-rate ?size ?density))
(== ?density (C-add (/ ?size ?capacity)))
(density-of ?density ?population)
(capacity-of ?capacity ?population)))

There is one twist in compositional modelling of population growth. Sometimes, the actual
growth model is implicitly contained within another type of model. In such cases, the growth
phenomenon and the corresponding differential equations are still relevant, but none of the dedicated
growth models can be employed. For example, as will be shown later, the Lotka-Volterra predation
model comes with its own equations describing growth.
535

fiK EPPENS & S HEN

The model fragment other-growth allows for an empty growth model, named other, to
be selected. However, due to the purpose-required property that any instance of ?p-change must
be endogenous, this empty model can only be selected if a growth model is implicitly included
elsewhere.
(defModelFragment other-growth
:source-participants
((?population :type population)
(?size :type variable)
(?birth-flow :type variable)
(?death-flow :type variable))
:structural-conditions
((size-of ?size ?population)
(births-of ?birth-flow ?population)
(deaths-of ?death-flow ?population))
:assumptions
((model ?population other)))

In addition to population growth, two other phenomena are included in the knowledge base:
predation and competition. Predation and competition relations between species are represented by
predicates over the populations: e.g. (predation foxes rabbits) and (competition
sheep cows). However the existence of a phenomenon does not necessarily mean that it must be
contained within the model. It would make little sense to model predation and competition without
modelling the size of the populations, because models of these phenomena relate population sizes
to one another. Therefore, the incorporation of the predation phenomenon is made dependent upon
the existence of variables representing population size. Also, human expert modellers may prefer
to leave a phenomenon out of the resulting model. To keep this choice open, the following two
model fragments construct a participant representing the phenomena of predation and competition,
and make it dependent upon a relevance assumption:
(defModelFragment predation-phenomenon
:source-participants
((?predator :type population)
(?prey :type population)
(?predator-size :type variable)
(?prey-size :type variable))
:structural-conditions
((predation ?predator ?prey)
(size-of ?predator-size ?predator)
(size-of ?prey-size ?prey))
:assumptions
((relevant predation ?predator ?prey))
:target-participant
((?predation-phenomenon :type phenomenon :name predation-phenomenon))
:postconditions
((predation-phenomenon ?predation-phenomenon ?predator ?prey))
:purpose-required ((has-model ?predation-phenomenon)))
(defModelFragment competition-phenomenon
:source-participants
((?population1 :type population)
(?population2 :type population)
(?size1 :type variable)
(?size2 :type variable))
:structural-conditions
((competition ?population1 ?population2)
(size-of ?size1 ?population1)
(size-of ?size2 ?population2))

536

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Bprey = bprey  Nprey

Bprey = bprey  Nprey

Dprey = dprey  Nprey 

Nprey
Kprey

Dprey = pprey  Nprey  Npred
d
dt Nprey

d
dt Nprey

= Bprey  Dprey  P

= Bprey  Dprey  P

bprey

P =

pprey

bprey

dprey

sNprey Npred
1+sNprey th

Kprey

s
th

Dpred = dpred  Npred 

Bpred = bpred  Npred

Dpred = dpred  Npred 

Bpred = ppred  Nprey  Npred
d
dt Npred

Npred
Kpred

d
dt Npred

Npred
Kpred

= Bpred  Dpred

= Bpred  Dpred
dpred

bpred

dpred

ppred

Kpred = k  Nprey

(b) Holling predation

(a) Lotka-Volterra predation

Figure 9: Predation models
:assumptions
((relevant competition ?population1 ?population2))
:target-participant
((?competition-phenomenon :type phenomenon :name competition-phenomenon))
:postconditions
((competition-phenomenon ?competition-phenomenon ?population1 ?population2))
:purpose-required
((has-model ?competition-phenomenon)))

Both model fragments have a purpose-required property of the form (has-model ?phen).
This property expresses the condition that a model must exist with respect to a phenomenon:
(defproperty has-model
:source-participants ((?p :type phenomenon))
:structural-conditions ((is-model-of ?p *))
:property (has-model ?p))

The next two model fragments implement such models (thereby satisfying the above has-model
purpose-required property) for the predation phenomenon between two populations. They describe
two well-known predation models: the Lotka-Volterra model (1925, 1926), which is shown in Figure 9(a), and the Holling model (1959), which is shown graphically in Figure 9(b).
(defModelFragment Lotka-Volterra
:source-participants
((?predation-phenomenon :type phenomenon)
(?predator :type population)
(?predator-size :type stock)
(?predator-birth-flow :type flow)
(?predator-death-flow :type flow)
(?prey :type population)
(?prey-size :type stock)
(?prey-birth-flow :type flow)
(?prey-death-flow :type flow))
:structural-conditions
((predation-phenomenon ?predation-phenomenon ?predator ?prey)

537

fiK EPPENS & S HEN

(size-of ?predator-size ?predator)
(births-of ?predator-birth-flow ?predator)
(deaths-of ?predator-death-flow ?predator)
(size-of ?prey-size ?prey)
(births-of ?prey-birth-flow ?prey)
(deaths-of ?prey-death-flow ?prey))
:assumptions
((model ?predation-phenomenon lotka-volterra))
:target-participants
((?prey-birth-rate :type variable :name birth-rate)
(?predator-factor :type variable :name predator-factor)
(?prey-factor :type variable :name prey-factor)
(?predator-death-rate :type variable :name death-rate))
:postconditions
((== ?prey-birth-flow (* ?prey-birth-rate ?prey-size))
(== ?predator-birth-flow (* ?predator-factor ?prey-size ?predator-size))
(== ?prey-death-flow (* ?prey-factor ?prey-size ?predator-size))
(== ?predator-death-flow (* ?predator-death-rate ?predator-size))
(is-model-of lotka-volterra ?predation-phenomenon)))

As mentioned earlier, the Lotka-Volterra model introduces its own growth model for the prey
and predator populations by assigning specific equations to the variables, which describe changes in
the sizes of the predator and prey populations, ?pred-change and ?prey-change respectively.
Thus, it satisfies the purpose-required property in the application of the population-growth
model fragment for the ?prey and ?pred populations.
(defModelFragment Holling
:source-participants
((?predation-phenomenon :type phenomenon)
(?predator :type population)
(?predator-size :type stock)
(?capacity :type variable)
(?prey :type population)
(?prey-size :type stock))
:structural-conditions
((predation-phenomenon ?predation-phenomenon ?predator ?prey)
(size-of ?predator-size ?predator)
(size-of ?prey-size ?prey)
(capacity-of ?capacity ?predator))
:assumptions
((model ?predation-phenomenon holling))
:target-participants
((?search-rate :type variable :name search-rate)
(?handling-time :type variable :name handling-time)
(?prey-requirement :type variable :name prey-requirement)
(?predation :type flow :name predation))
:postconditions
((flow ?predation ?prey-size sink)
(== ?predation
(/ (* ?search-rate ?prey-size ?predator-size)
(+ 1 (* ?search-rate ?prey-size ?handling-time))))
(== ?capacity (C-add (* ?prey-requirement ?prey)))
(is-model-of holling ?predation-phenomenon)))

The Holling model employs a variable denoting the capacity of a population. Such a variable
may be introduced by a logistic growth model. In practice, logistic growth models and Holling
predation models are often used in conjunction. The compositional modeller need not be aware of
such combinations of models, however. All it needs to know is the prerequisites of the individual
component models contained within each model fragment.
538

fiC OMPOSITIONAL M ODEL R EPOSITORIES

D1 = d 1  N 1 

B1 = b 1  N 1
d
dt N1

N1 +w12 N2
K1

= B1  D 1

d1

b1

w12
K1

D2 = d 2  N 2 

B2 = b 2  N 2
d
dt N2

w21 N1 +N2
K2

= B2  D 2

d2

b2

w21
K2

Figure 10: A species competition model

The final model fragment in the knowledge base implements a model of competition between
two species. It formally describes the competition model type depicted in Figure 10. As this model
fragment contains the only population competition model in the knowledge base, it does not contain
a model assumption to represent the model.

(defModelFragment competition
:source-participants
((?competition-phenomenon :type phenomenon)
(?population-1 :type population)
(?size-1 :type stock)
(?density-1 :type variable)
(?capacity-1 :type variable)
(?population-2 :type population)
(?size-2 :type stock)
(?density-2 :type variable)
(?capacity-2 :type variable))
:structural-conditions
((competition-phenomenon ?competition-phenomenon ?population-1 ?population-2)
(density-of ?density-1 ?size-1)
(capacity-of ?capacity-1 ?size-1)
(density-of ?density-2 ?size-2)
(capacity-of ?capacity-2 ?size-2))
:assumptions
((relevant competition ?population-1 ?population-2))
:target-participants
((?weight-12 :type variable :name weight)
(?weight-21 :type variable :name weight))
:postconditions
((== ?density-1 (C-add (/ (* ?weight-12 ?size-2) ?capacity-1)))
(== ?density-2 (C-add (/ (* ?weight-21 ?size-1) ?capacity-2)))))

539

fiK EPPENS & S HEN

relevant
growth predator

Growth

Predator

predation
predator,prey1
relevant
predation
predator,prey1

Exponential

model predator
is exponential

Logistic
model

Logistic

model predator
is logistic

"Other"
model

othergrowth

model predator
is other

predationphen:
predator,prey1

Growth

Stock +
Flows

predation
predator,prey2
relevant
predation
predator,prey2

Exponential
model

othergrowth

model predator
is other

Logistic
model

Logistic

model predator
is logistic

"Other"
model

Exponential

model predator
is exponential

Predation

predationphen:
predator,prey2

Growth

Stock +
Flows

Prey2
relevant
growth prey2

Exponential
model

Predation
Prey1
relevant
growth prey1

Stock +
Flows

Exponential
model

othergrowth

model predator
is other

Logistic
model

Logistic

model predator
is logistic

"Other"
model

Exponential

model predator
is exponential

relevant
competition
prey1,prey2

LotkaVolterra
model

LotkaVolterra

model comp.
is lotkavolterra

Holling
model

Holling

model comp.
is holling

LotkaVolterra
model

LotkaVolterra

model comp.
is lotkavolterra

Holling
model

Holling

model comp.
is holling

Competition

competitionphen:
prey1,prey2

competition
prey1,prey2

Figure 11: Model space for the 1 predator and 2 competing prey scenario
4.2 Model space
A model space is constructed when the knowledge base is instantiated with respect to a given scenario. Consider for example the following scenario, which describes a predator population that
preys on two other populations, prey1 and prey2, whilst the two prey populations compete with
one another:
(defScenario pred-prey-prey-scenario
:entities ((predator :type population)
(prey1 :type population)
(prey2 :type population))
:relations ((predation predator prey1)
(predation predator prey2)
(competition prey1 prey2)))

The full specification of the model space is too unwieldy to present here but an abstract graphical
representation of the model space for this scenario is shown in Figure 11. This model space contains
the following knowledge:
 From each of the three populations in the scenario, a set of three population growth models
(i.e. exponential, logistic and other) is derived. This inference is dependent upon
a relevance assumption of the population growth phenomenon, and a model assumption that
corresponds to one of the three population growth models.
540

fiC OMPOSITIONAL M ODEL R EPOSITORIES

 From both predation relations (i.e. (predation predator prey1) and (predation
predator prey2)), and the populations related by them, a set of two predation models
(i.e. Lotka-Volterra and Holling) is derived. This inference is dependent upon a relevance assumption of the predation phenomenon and a model assumption that corresponds to
one of the two predation models.
 From the competition relation (competition prey1 prey2), and the populations related by it, a competition model is derived. Because there is only one competition model,
the inference of the competition model is only dependent upon a relevance assumption that
corresponds to the competition phenomenon.
In addition to the hypergraph of Figure 11, the model space also contains a number of constraints
on the conjunctions of assumptions that are consistent. As explained earlier, these stem from two
sources: 1) non-composable relations and 2) purpose-required properties. An example will be given
of each type.
Let predation-phen-1 be the predation phenomenon between predator and prey1,
and prey1-size be the variable representing the size of the prey1 population. In this example, the model fragments exponential-population-growth and Lotka-Volterra
will each generate an equation for computing the value of a variable representing the change in
prey1-size. Because both equations can not be composed, the following inconsistency is generated:
(relevant growth prey1)  (model prey1-size exponential)
(relevant growth predator)  (relevant predation predator prey1)
(model predation-phen-1 lotka-volterra)  

Inconsistencies also arise from purpose-required properties. For example, if the model fragment predation-phenomenon is applicable and the predation relation is deemed relevant, then
the purpose-required property (has-model ?pred-phen) will become a condition for consistency. Under certain combinations of assumptions, this property may not be satisfied. Say, when the
Holling predation and exponential growth models are both selected, the Holling model is not generated because there is no ?capacity for which (capacity ?capacity ?pred) is true. No
predation model is created in this case (because the Holling model fragment can not be instantiated), even though the predation phenomenon is deemed relevant under this set of assumptions. This
is inconsistent with the has-model purpose-required property in the predation-phenomenon
model fragment, and the responsible combination of assumptions is therefore marked as nogood.
(relevant growth predator)  (model predator-size exponential)
(relevant growth prey1)  (model prey1-size exponential)
(relevant predation predator prey1)  (model predation-phen-1 holling)  

4.3 aDPCSP and solution
The resultant model space is translated into an aDCSP to enable the selection of a consistent set of
assumptions, using advanced CSP solution techniques. The aDCSP derived from the above model
space is depicted in Figure 12.
541

fiK EPPENS & S HEN

Attribute
x1
x2
x3
x4
x5
x6
x7
x8
x9
x10
x11

Meaning
(relevant growth prey1)
(relevant growth prey2)
(relevant growth predator)
(relevant predation predator prey1)
(relevant predation predator prey2)
(relevant competition prey1 prey2)
(model size-1 *)
(model size-2 *)
(model size-3 *)
(model predation-phen-1 *)
(model predation-phen-2 *)
Table 4: Attribute list

Domain
D1
D2
D3
D4
D5
D6
D7
D8
D9
D10
D11

Content
{d1,y , d1,n }
{d2,y , d2,n }
{d3,y , d3,n }
{d4,y , d4,n }
{d5,y , d5,n }
{d6,y , d6,n }
{d7,l , d7,e , d7,o }
{d8,l , d8,e , d8,o }
{d9,l , d9,e , d9,o }
{d10,h , d10,lv }
{d11,h , d11,lv }

Meaning
{population,none}
{population,none}
{population,none}
{(population,population),none}
{(population,population),none}
{(population,population),none}
{logistic,exponential,other}
{logistic,exponential,other}
{logistic,exponential,other}
{Holling,Lotka-Volterra}
{Holling,Lotka-Volterra}

Table 5: The aDCSP for the 1 predator and 2 competing prey scenario: domains and their contents
and meaning

This aDCSP contains 11 attributes. They are listed with the corresponding assumption classes
in table 4. The first 6 attributes correspond to the notion of relevance phenomenon: 3 population
growth phenomena, 2 predation phenomena and 1 competition phenomenon to be precise. The other
5 attributes correspond to 5 sets of model types: 3 sets of population growth models and 2 sets of
predation models.
The assumptions from which the attributes were generated form domains of values. The resulting domains of the aforementioned attributes are summarised in table 5.
The activity constraints in the aDCSP describe the conditions that instantiate the subject of the
assumptions that correspond to an attribute. Since each participant or relation has a label in the
model space, a minimal set of assumptions under which it becomes part of the emerging model
is available. When a participant or relation is the subject of an assumption, this label explicitly
describes the sets of assumptions under which the attribute that corresponds to that subject should
542

fiC OMPOSITIONAL M ODEL R EPOSITORIES

x1
d1,y

x4
d1,n

d4,y

x7
d7,l

d7,e

x6
d4,n

d6,y

x2
d6,n

d2,y

x10
d7,o

d10,lv

x5
d2,n

d5,y

x8
d10,h

d8,l

d8,e

x3
d5,n

d3,y

x11
d8,o

d11,lv

d3,n

x9
d11,h

d9,l

d9,e

d9,o

attribute
value
compatibility constraint
activity constraint

Figure 12: aDCSP derived from the models space reflecting the 1 predator and 2 competing prey
scenario

be activated. By translating the label of a subject into sets of attribute-value assignments, the antecedents of the activity constraints are constructed.
In this example, the relevance assumptions (attributes x1 , . . . , x6 ) take their subjects from the
scenario, and hence, they are always active. The attributes related to the model assumptions for
population growth are active if the corresponding assumptions denoting relevance of population
growth are true. That is,
x1 : d1,y  active(x7 )
x2 : d2,y  active(x8 )
x3 : d3,y  active(x9 )
The attributes related to the assumptions about the predation models are active if the corresponding
assumptions denoting relevance of predation, and the assumptions describing relevance of population growth, are true for the populations involved in the predation relation. That is,
x1 : d1,y  x3 : d3,y  x4 : d4,y  active(x10 )
x2 : d2,y  x3 : d3,y  x5 : d5,y  active(x11 )
Figure 12 shows a graphical representation of these activity constraints.
The compatibility constraints correspond directly to the inconsistencies in the nogood node.
These inconsistencies have been discussed in the previous section and are depicted in Figure 12.
Once the aDCSP is constructed, preferences may be attached to attribute-value assignments.
Suppose that preferences are only assigned to the standard population modelling choices, i.e. expo543

fiK EPPENS & S HEN

Attribute
x1 , . . . , x5
x6
x7
x8
x9
x10
x11

Preference assignments
no preference assignments
P (x6 : d6,y ) = pcompetition
P (x7 : d7,l ) = plogistic , P (x7 : d7,e ) = pexponential
P (x8 : d8,l ) = plogistic , P (x8 : d8,e ) = pexponential
P (x9 : d9,l ) = plogistic , P (x9 : d9,e ) = pexponential
P (x10 : d10,h = pholling , P (x10 : d10,lv ) = plotka-volterra
P (x11 : d11,h = pholling , P (x11 : d11,lv ) = plotka-volterra

Table 6: Preference assignments for the 1 predator and 2 competing prey problem
nential growth, logistic growth, lotka-volterra predation and holling predation, and to the relevance
of competition (because only one type model has been implemented for this phenomenon). For
example, the following BPQs could be employed:
pexponential < plogistic
plotka-volterra < pholling
pcompetition
The logistic and Holling models are preferred over the exponential and Lotka-Volterra models because the former are generally regarded as being more accurate. Note that the preferences have
been ordered in such a way that those corresponding to different phenomena are not related to one
another. The justification for this ordering is that, even though the models are structurally connected
(there are restrictions over which models can combined with one another), models of different phenomena inherently describe behaviours that can not be compared with one another. The preference
assignments for attribute value assignments are summarised in table 6.
Solving this aDPCSP is simple. First, the attributes x1 , . . . , x6 are activated. Each of these
attributes is assigned xi : di,y because that assignment maximises the potential preference. Then,
the attributes x7 , . . . , x11 are activated. Here, attributes x7 , . . . , x9 are assigned xi : di,l because the
logistic growth model has the highest preference. Finally, x 10 and x11 are assigned x10 : d10,h and
x11 : d11,h because the Holling models have the highest preference and are not inconsistent with the
logistic model committed earlier. The resulting solution satisfies the following set of assumptions:
{(relevant growth prey1),
(relevant growth prey2),
(relevant growth predator),
(relevant competition prey1 prey2),
(relevant predation predator prey1),
(relevant predation predator prey2),
(model size-1 logistic),
(model size-2 logistic),
(model size-3 logistic),
(model predation-phen-1 holling),
(model predation-phen-2 holling)}

544

fiC OMPOSITIONAL M ODEL R EPOSITORIES

SYMBOLS
relevant
growth predator

Growth

Nodes entailed by the
aDPCSP solution

Predator

predation
predator,prey1

Exponential

model predator
is exponential

Logistic
model

Logistic

model predator
is logistic

"Other"
model

othergrowth

model predator
is other

Nodes NOT entailed by the
aDPCSP solution
Applied model fragment

Predation

predationphen:
predator,prey1

LotkaVolterra
model

LotkaVolterra

model comp.
is lotkavolterra

Growth

Stock +
Flows

Holling
model

Holling

model comp.
is holling

Prey1

predation
predator,prey2
relevant
predation
predator,prey2

Exponential
model

othergrowth

model predator
is other

Logistic
model

Logistic

model predator
is logistic

"Other"
model

Exponential

model predator
is exponential

Predation

predationphen:
predator,prey2

LotkaVolterra
model

LotkaVolterra

model comp.
is lotkavolterra

Growth

Stock +
Flows

Holling
model

Holling

model comp.
is holling

Prey2
relevant
growth prey2

Exponential
model

Model fragment that is
not applied

relevant
predation
predator,prey1

relevant
growth prey1

Assumptions in the
aDPCSP solution

Stock +
Flows

Exponential
model

othergrowth

model predator
is other

Logistic
model

Logistic

model predator
is logistic

"Other"
model

Exponential

model predator
is exponential

relevant
competition
prey1,prey2

Competition

competitionphen:
prey1,prey2

competition
prey1,prey2

Figure 13: Deducing a scenario model from the model space, given a set of assumptions

4.4 Sample scenario model
Figure 13 shows how a scenario model can be deduced from the above set of assumptions by exploiting the model space. The nodes corresponding to the aforementioned assumptions and those
that logically follow from the assumption set are indicated in the Figure.
When combining the participants and relations in the resulting scenario model, the model given
in Figure 14 can be drawn. This model corresponds to the one that an ecologist would draw if the
logistic growth and Holling predation models were regarded to be appropriate for the task at hand.

5. Conclusion and Future Work
This article has presented a novel approach to compositional modelling that enables the construction
of models of ecological systems. This work differs from existing approaches in that it automatically
translates the compositional modelling problem into an aDCSP with (order-of-magnitude) preference valuations. There are several benefits to this method.
The use of a translation algorithm that converts the compositional modelling problem into an
aDCSP allows criteria to be formalised. More importantly, it also enables efficient, existing and
future, aDCSP solution techniques to be effectively applied to solving compositional modelling
problems.
545

fiGrowth

Growth

B1 = b1  N1

D1 = d 1  N 1   1
d
dt N1

B2 = b2  N2

D2 = d 2  N 2   2
d
dt N2

= B1  D1  P31

= B2  D2  P32

Holling

K EPPENS & S HEN

s31

K1

d1

1 =

N1
K1

+

P32 =

b2
s32

w12 N2
K1

th,31

K3

Logistic

3 =

K2

w21 N1
K2

+

N2
K2

Logistic

Growth

B3 = b 3  N 3

b3

2 =

th,32

N3
K3

D3 = d 3  N 3   3
d
dt N3

d2

s32 N2 N3
1+s32 N2 th,32

546

P31 =

b1

Holling

s31 N1 N3
1+s31 N1 th,31

= B3  D 3

d3
Logistic

Figure 14: Sample scenario model for the 1 predator and 2 competing prey scenario

fiC OMPOSITIONAL M ODEL R EPOSITORIES

The extension of the aDCSPs with (order-of-magnitude) preferences (to form aDPCSPs) also
permits the incorporation of softer requirements in the compositional modelling problem. In this
paper, order-of-magnitude preferences have been employed to express the appropriateness of alternative model types for certain phenomena. While such considerations may be described by hard
constraints in the physical systems domain3 , they are more subjective in less understood problem
domains, such as the ecological modelling domain. The approach presented herein provides a means
to capture and represent the subtlety of the flexible model design decisions.
The theoretical ideas presented in this article have been applied to real-world ecological modelling problems. In this paper, it has been demonstrated how the resultant compositional modeller
can be employed to create a repository of population dynamics models. The approach has also been
applied to automated model construction of large and complex ecosystems such as the MODMED
model of Mediterranean vegetation (Legg et al., 1995), as reported by Keppens (2002).
There are some practical and theoretical issues that need to be addressed, however. On the practical side, the types of ecological model design decisions, as represented by the assumptions and
assumption classes, and as supported by the inference mechanisms, should be extended. Ecological
systems tend to involve interrelated populations of individuals, instead of functional compositions of
individual components as with physical systems. One particularly important type of design decision
in ecological modelling is therefore granularity. This requires the introduction of novel representation formalisms and inference mechanisms such as aggregation and disaggregation. Initial work for
considering populations as single entities and for dividing such entities into sub-populations when
necessary has been carried out (Keppens & Shen, 2001a). Integration of such work into the present
aDPCSP framework requires further investigation.
On the theoretical side, the analysis of the complexity of the present approach is rather informal.
Much remains to be done in this regard, especially when comparing to the complexity of existing
compositional modellers. For this comparison, additional work will be required to adapt the current translation procedure to suit existing compositional modelling problems. Most compositional
modellers are of exponential complexity, however. As they employ problem-specific solution algorithms, little is known about opportunities for improving their efficiency. This work hopes to be a
first step toward further understanding this important issue.

Acknowledgments
This work is partly supported by the UK-EPSRC grant GR/S63267. The first author has also been
supported by a College of Science and Engineering scholarship at the University of Edinburgh.
We are very grateful to Robert Muetzelfeldt for helpful discussions and assistance in the research
reported, whilst taking the full responsibility of the views expressed here. Thanks also go to the
anonymous referees for their constructive comments which are very useful in revising the earlier
version of this paper.

References
Binger, B., & Hoffman, E. (1998). Microeconomics with Calculus. Longman.
3. These are the so-called operating conditions, stating the range of values of certain variables within which the use of
certain assumptions is permitted.

547

fiK EPPENS & S HEN

Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint satisfaction and optimization. Journal of the ACM, 44(2), 201236.
Bobrow, D., Falkenhainer, B., Farquhar, A., Fikes, R., Forbus, K., Gruber, T., Iwasaki, Y., & Kuipers,
B. (1996). A compositional modeling language. In Proceedings of the 10th International
Workshop on Qualitative Reasoning about Physical Systems, pp. 1221.
Bradley, E., Easley, M., & Stolle, R. (2001). Reasoning about nonlinear system identification.
Artificial Intelligence, 133, 139188.
Dague, P. (1993a). Numeric reasoning with relative orders of magnitude. In Proceedings of the
National Conference on Artificial Intelligence, pp. 541547.
Dague, P. (1993b). Symbolic reasoning with relative orders of magnitude. In Proceedings of the
13th International Joint Conference on Artificial Intelligence, pp. 15091514.
de Kleer, J. (1986). An assumption-based TMS. Artificial Intelligence, 28, 127162.
de Kleer, J. (1988). A general labeling algorithm for assumption-based truth maintenance. In
Proceedings of the 7th National Conference on Artificial Intelligence, pp. 188192.
Easley, M., & Bradley, E. (1999). Generalized physical networks for automated model building. In
Proceedings of the 16th International Joint Conference on Artificial Intelligence, pp. 1047
1053.
Falkenhainer, B., & Forbus, K. (1991). Compositional modeling: finding the right model for the
job. Artificial Intelligence, 51, 95143.
Ford, A. (1999). Modeling the Environment - An Introduction to System Dynamics Modeling of
Environmental Systems. Island Press.
Forrester, J. (1968). Principles of Systems. Wright-Allen Press, Cambridge, MA, USA.
Hart, P., Nilsson, N., & Raphael, B. (1968). A formal basis for the heuristic determination of
minimal cost paths. IEEE Transactions on Systems, Science and Cybernetics, SSC-4(2), 100
107.
Heller, U., & Struss, P. (1998). Diagnosis and therapy recognition for ecosystems - usage of modelbased diagnosis techniques. In Proceedings of the 12th International Symposium Computer
Science for Environment Protection.
Heller, U., & Struss, P. (2001). Transformation of qualitative dynamic models - application in hydroecology. In Hotz, L., Struss, P., & Guckenbienl, T. (Eds.), Intelligent Diagnosis in Industrial
Applications, pp. 95106. Shaker Verlag.
Holling, C. (1959). Some characteristics of simple types of predation and parasitism. Canadian
Entomologist, 91, 385398.
Karnopp, D., Margolis, D., & Rosenberg, R. (1990). System Dynamics: A United Approach (Second
Edition edition). John Wiley & Sons, Inc.
Keppens, J. (2002). Compositional Ecological Modelling via Dynamic Constraint Satisfaction with
Order-of-Magnitude Preferences. Ph.D. thesis, The University of Edinburgh.
Keppens, J., & Shen, Q. (2001a). Disaggregation in compositional modelling of ecological systems
via dynamic constraint satisfaction. In Proceedings of the 15th International Workshop on
Qualitative Reasoning about Physical Systems, pp. 2128.
548

fiC OMPOSITIONAL M ODEL R EPOSITORIES

Keppens, J., & Shen, Q. (2001b). On compositional modelling. Knowledge Engineering Review,
16(2), 157200.
Keppens, J., & Shen, Q. (2002). On supporting dynamic constraint satisfaction with order of magnitude preferences. In Proceedings of the 16th International Workshop on Qualitative Reasoning about Physical Systems, pp. 7582.
Langley, P., Sanchez, J., Todorovski, L., & Dzeroski, S. (2002). Inducing process models from
continuous data. In Proceedings of the 19th International Conference on Machine Learning,
pp. 347354.
Legg, C., Muetzelfeldt, R., & Heathfield, D. (1995). Modelling vegetation dynamics in mediterranean ecosystems: Issues of scale. In Proceedings of the 39th Symposium of the International
Association for Vegetation Science.
Levy, A., Iwasaki, Y., & Fikes, R. (1997). Automated model selection for simulation based on
relevance reasoning. Artificial Intelligence, 96, 351394.
Lotka, A. (1925). Elements of physical biology. Williams & Wilkins Co., Baltimore.
Malthus, T. (1798). An essay on the principle of population. Printed for J. Johnson in St. Pauls
Church Yard, London, England.
Miguel, I., & Shen, Q. (1999). Hard, flexible and dynamic constraint satisfaction. Knowledge
Engineering Review, 14(3), 199220.
Miguel, I., & Shen, Q. (2001a). Solution techniques for constraint satisfaction problems: Advanced
approaches. Artificial Intelligence Review, 15(4), 269293.
Miguel, I., & Shen, Q. (2001b). Solution techniques for constraint satisfaction problems: Foundations. Artificial Intelligence Review, 15(4), 243267.
Minton, S., Johnston, M., Philips, A., & Laird, P. (1992). Minimizing conflicts: A heuristic repair
method for constraint satisfaction and scheduling problems. Artificial Intelligence, 58, 161
205.
Mittal, S., & Falkenhainer, B. (1990). Dynamic constraint satisfaction problems. In Proceedings of
the 8th National Conference on Artificial Intelligence, pp. 2532.
Nayak, P., & Joskowicz, L. (1996). Efficient compositional modeling for generating causal explanations. Artificial Intelligence, 83, 193227.
Nicholson, A., & Bailey, V. (1935). The balance of animal populations. Proceedings of the Zoological Society of London, 1, 551598.
Raphael, B. (1990). A* algorithm. In Shapiro, S.C. (Ed.), Encyclopedia of Artificial Intelligence,
Vol. 1, pp. 13. John Wiley & Sons.
Rickel, J., & Porter, B. (1997). Automated modeling of complex systems to answer prediction
questions. Artificial Intelligence, 93, 201260.
Rogers, D. (1972). Random search and insect population models. Journal of Animal Ecology, 41,
369383.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued constraint satisfaction problems: Hard and
easy problems. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, pp. 631637.
549

fiK EPPENS & S HEN

Thompson, W. (1929). On the relative value of parasites and predators in the biological control of
insect pests. Bull. Etnomol. Res., 19, 343350.
Todorovski, L., & Dzeroski, S. (1997). Declarative bias in equation discovery. In Proceedings of
the 14th International Conference on Machine Learning, pp. 432439.
Todorovski, L., & Dzeroski, S. (2001). Using domain knowledge on population dynamics modeling for equation discovery. In Proceedings of the 12th European Conference on Machine
Learning, pp. 478490.
Tsang, E. (1993). Foundations of Constraint Satisfaction. Academic Press, London and San Diego.
Verfaillie, G., & Schiex, T. (1994). Solution reuse in dynamic constraint satisfaction problems. In
Proceedings of the 12th National Conference on Artificial Intelligence, pp. 307312.
Verhulst, P. (1838). Recherches mathematiques sur la loi daccroissement de la population. Nouveaux memoires de lacademie royale des sciences et belles-lettres de Bruxelles, 18, 138.
Volterra, V. (1926). Fluctuations in the abundance of a species considered mathematically. Nature,
118, 558560.

550

fiJournal of Artificial Intelligence Research 21 (2004) 319356

Submitted 11/02; published 03/04

Representation Dependence in Probabilistic Inference
Joseph Y. Halpern

halpern@cs.cornell.edu

Cornell University, Computer Science Department
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

Daphne Koller

koller@cs.stanford.edu

Stanford University, Computer Science Department
Stanford, CA 94035
http://www.cs.stanford.edu/ koller

Abstract
Non-deductive reasoning systems are often representation dependent: representing the
same situation in two different ways may cause such a system to return two different answers. Some have viewed this as a significant problem. For example, the principle of
maximum entropy has been subjected to much criticism due to its representation dependence. There has, however, been almost no work investigating representation dependence.
In this paper, we formalize this notion and show that it is not a problem specific to maximum entropy. In fact, we show that any representation-independent probabilistic inference
procedure that ignores irrelevant information is essentially entailment, in a precise sense.
Moreover, we show that representation independence is incompatible with even a weak default assumption of independence. We then show that invariance under a restricted class of
representation changes can form a reasonable compromise between representation independence and other desiderata, and provide a construction of a family of inference procedures
that provides such restricted representation independence, using relative entropy.

1. Introduction
It is well known that the way in which a problem is represented can have a significant impact
on the ease with which people solve it, and on the complexity of an algorithm for solving
it. We are interested in what is arguably an even more fundamental issue: the extent to
which the answers that we get depend on how our input is represented. Here too, there is
well known work, particularly by Tversky and Kahneman (see, for example, (Kahneman,
Slovic, & Tversky, 1982)), showing that the answers given by people can vary significantly
(and in systematic ways) depending on how a question is framed. This phenomenon is often
viewed as indicating a problem with human information processing; the implicit assumption
is that although people do make mistakes of this sort, they shouldnt. On the other hand,
there is a competing intuition that suggests that representation does (and should ) matter;
representation dependence is just a natural consequence of this fact.
Here we consider one type of reasoning, probabilistic inference, and examine the extent
to which answers depend on the representation. The issue of representation dependence is of
particular interest in this context because of the interest in using probability for knowledge
representation (e.g., (Pearl, 1988)) and because probabilistic inference has been the source
c
2004
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiHalpern & Koller

of many of the concerns expressed regarding representation. However, our approach should
be applicable far more generally.
We begin by noting that the notion of probabilistic inference has two quite different
interpretations. In one interpretation, which forms the basis for the Bayesian paradigm,
probabilitic inference consists basically of conditioning: We start out with a prior distribution over some event space, and then condition on whatever observations are obtained. In
the other interpretation, we are given only a set of probabilistic assertions, and our goal
is to reach conclusions about the probabilities of various events. For most of this paper,
we focus on the latter interpretation, although we discuss the relationship to the Bayesian
approach in Section 7.2.
Suppose that we have a procedure for making inferences from a probabilistic knowledge
base. How sensitive is it to the way knowledge is represented? Consider the following
examples, which use perhaps the best-known non-deductive notion of probabilistic inference,
maximum entropy (Jaynes, 1978).1
Example 1.1: Suppose that we have no information whatsoever regarding whether an
object is colorful. What probability should we assign to the proposition colorful ? Symmetry
arguments might suggest 1/2. Since we have no information, it seems that an object should
be just as likely to be colorful as non-colorful. This is also the conclusion reached by
maximum entropy provided that the language has only the proposition colorful . But now
suppose we know about the colors red, blue, and green, and have propositions corresponding
to each of these colors. Moreover, by colorful we actually mean red  blue  green. In this
case, maximum entropy dictates that the probability of red  blue  green is 7/8. Note that,
in both cases, the only conclusion that follows from our constraints is the trivial one: that
the probability of the query is somewhere between 0 and 1.
Example 1.2: Suppose that we are told that half of the birds fly. There are two reasonable ways to represent this information. One is to have propositions bird and fly, and
use a knowledge base KB fly
1 =def [Pr(fly | bird ) = 1/2]. A second might be to have as
basic predicates bird and flying-bird , and use a knowledge base KB fly
2 =def [(flying-bird 
bird )  Pr(flying-bird | bird ) = 1/2]. Although the first representation may appear more natural, it seems that both representations are intuitively adequate insofar as representing the
information that we have been given. But if we use an inference method such as maximum
entropy, the first representation leads us to infer Pr(bird ) = 1/2, while the second leads us
to infer Pr(bird ) = 2/3.
Examples such as these are the basis for the frequent criticisms of maximum entropy
on the grounds of representation dependence. But other than pointing out these examples,
there has been little work on this problem. In fact, other than the work of Salmon (1961,
1963) and Paris (1994), there seems to have been no work on formalizing the notion of representation dependence. One might say that the consensus was: whatever representation
independence is, it is not a property enjoyed by maximum entropy. But are there any
1. Although much of our discussion is motivated by the representation-dependence problem encountered
by maximum entropy, an understanding of maximum entropy and how it works is not essential for
understanding our discussion.

320

fiRepresentation Dependence

other inference procedures that have it? In this paper we attempt to understand the notion
of representation dependence, and to study the extent to which it is achievable.
To study representation dependence, we must first understand what we mean by a
representation. The real world is complex. In any reasoning process, we must focus on
certain details and ignore others. At a semantic level, the relevant distinctions are captured
by using a space X of possible alternatives or states (possible worlds). In Example 1.1, our
first representation focused on the single attribute colorful . In this case, we have only two
states in the state space, corresponding to colorful being true and false, respectively. The
second representation, using red , blue, and green, has a richer state space. Clearly, there
are other distinctions that we could make.
We can also interpret a representation as a syntactic entity. In this case, we typically capture relevant distinctions using some formal language. For example, if we use propositional
logic as our basic knowledge representation language, our choice of primitive propositions
characterizes the distinctions that we have chosen to make. We can then take the states
to be truth assignments to these propositions. Similarly, if we use a probabilistic representation language such as belief networks (Pearl, 1988) as our knowledge representation
language, we must choose some set of relevant random variables. The states are then then
possible assignments of values to these variables.
What does it mean to shift from a representation (i.e., state space) X to another representation Y ? Roughly speaking, we want to capture at the level of the state space a shift
from, say, feet to meters. Thus, in X distances might be described in terms of feet where
in Y they might be described in terms of meters. We would expect there to be a constraint
relating feet to meters. This constraint would not give any extra information about X; it
would just relate worlds in X to worlds in Y . Thus, we first attempt to capture representation independence somewhat indirectly, by requiring that adding constraints relating X to
Y that place no constraints on X itself should not result in different conclusions about X.
The resulting notion, called robustness, turns out to be surprisingly strong. We can show
that every robust inference procedure must behave essentially like logical entailment.
We then try to define representation independence more directly, by using a mapping f
from one representation to another. For example, f could map a world where an individual
is 6 feet tall to the corresponding world where the individual is 1.83 meters tall. Some
obvious constraints on f are necessary to ensure that it corresponds to our intuition of a
representation shift. We can then define a representation-independent inference procedure
as one that preserves inferences under every legitimate mapping f ; i.e., for any KB and ,
KB |  iff f (KB ) | f ().
This definition turns out to be somewhat more reasonable than our first attempt, in that
there exist nontrivial representation-independent inference procedures. However, it is still
a strong notion. In particular, any representation-independent inference procedure must
act essentially like logical entailment for a knowledge base with only objective information
(i.e., essentially non-probabilistic information). Moreover, we show that representation
independence is incompatible with even the simplest default assumption of independence.
Even if we are told nothing about the propositions p and q, representation independence
does not allow us to jump to the conclusion that p and q are independent.
These results suggest that if we want inference procedures that are capable of jumping
to nontrivial conclusions, then we must accept at least some degree of representation de321

fiHalpern & Koller

pendence. They add support to the claim that the choice of language does carry a great
deal of information, and that complete representation independence is too much to expect.
On a more positive note, we show that we can use the intuition that the choice of language
carries information to get limited forms of representation independence. The idea is that the
language should put further constraints on what counts as an appropriate representation
shift. For example, suppose that certain propositions represent colors while others represent
birds. While we may be willing to transform colorful to red  blue  green, we may not be
willing to transform red to sparrow . There is no reason to demand that an inference procedure behave the same way if we suddenly shift to a wildly inappropriate representation,
where the symbols mean something completely different. We provide a general approach to
constructing inference procedures that are invariant under a specific class of representation
shifts. This construction allows us to combine some degree of representation independence
with certain non-deductive properties that we want of our inference procedure. In particular, we present an inference method that supports a default assumption of independence,
and yet is invariant under a natural class of representation shifts.
The rest of this paper is organized as follows. In Section 2, we define probabilistic inference procedures and characterize them. In Section 3, we define robust inference procedures
and show that every robust inference procedure is essentially entailment. In Section 4, we
define representation independence, and show that representation independence is a very
strong requirement. In particular, we show that a representation-independent inference
procedure essentially acts like logical entailment on objective knowledge bases and that
representation independence is incompatible with a default assumption of independence.
Section 5 contains some general discussion of the notion of representation independence
and how reasonable it is to assume that the choice of language should affect inference.
While it may indeed seem reasonable to assume that the choice of language should affect
inference, we point out that this assumption has some consequences that some might view
as unfortunate. In Section 6, we discuss how limited forms of representation independence
can be achieved. We discuss related work in Section 7, and conclude in Section 8.

2. Probabilistic Inference
We begin by defining probabilistic inference procedures. As we discussed in the introduction,
there are two quite different ways in which this term is used. In one, we are given a prior
distribution over some probability space; our knowledge then typically consists of events
in that space, which can be used to condition that distribution and obtain a posterior. In
the other, which is the focus of our work, a probabilistic inference procedure takes as input
a probabilistic knowledge base and returns a probabilistic conclusion.
We take both the knowledge base and the conclusion to be assertions about the probabilities of events in some measurable space (X, FX ), where a measurable space consists of a
set X and an algebra FX of subsets of X (that is, FX is a set of subsets of X closed under
union and complementation, containing X itself).2 Formally, these assertions can be viewed
as statements about (or constraints on) probability measures on (X, FX ). For example, if
2. If X is infinite, we may want to consider countably-additive probability measures and take FX to be
closed under countable unions. This issue does not play significant role in this paper. For simplicity, we
restrict to finite additivity and require only that FX be closed under finite unions.

322

fiRepresentation Dependence

S  FX , a statement Pr(S)  2/3 holds only for distributions where S has probability
at least 2/3. Therefore, if (X,FX ) is the set of all probability measures on (X, FX ) (that
is, all probability measures with domain FX ), we can view a knowledge base as a set of
constraints on (X,FX ) . When FX is clear from context, we often omit it from the notation,
writing X rather than (X,FX ) .
We place very few restrictions on the language used to express the constraints. We
assume that it includes assertions of the form Pr(S)   for all subsets S  FX and rational
  [0, 1], and that it is closed under conjunction and negation, so that if KB and KB 0 are
knowledge bases expressing constraints, then so are KB  KB 0 and KB . (However, the
langauge could include many assertions besides those obtained by starting with assertions
of the form Pr(S)   and closing off under conjunction and negation.) Since the language
puts constraints on probability measures, we cannot directly say that S  FX must hold.
The closest approximation in the language is the assertion Pr(S) = 1. Thus, we call such
constraints objective. A knowledge base consisting of only objective constraints is called an
objective knowledge base. Since Pr(T1 ) = 1  Pr(T2 ) = 1 is equivalent to Pr(T1  T2 ) = 1,
without loss of generality, an objective knowledge base consists of a single constraint of the
form Pr(T ) = 1. Given a knowledge base KB placing constraints on X , we write  |= KB
if  is a measure in X that satisfies the constraints in KB . We use [[KB ]]X to denote all
the measures satisfying these constraints.
In practice, our knowledge is typically represented syntactically, using some logical language to describe the possible states. Typical languages include propositional logic, firstorder logic, or a language describing the values for some set of random variables. In general,
a base logic L defines a set of formulas L() for a given vocabulary . In propositional
logic, the vocabulary  is simply a set of propositional symbols. In probability theory, the
vocabulary can consist of a set of random variables. In first-order logic, the vocabulary is a
set of constant symbols, function symbols, and predicate symbols. To facilitate comparison
between vocabularies, we assume that for each base logic all the vocabularies are finite
subsets of one fixed infinite vocabulary  .
When working with a language, we assume that each state in the state space defines
an interpretation for the symbols in  and hence for the formulas in L(). In the case of
propositional logic, we thus assume that we can associate with each state a truth assignment
to the primitive propositions in . For first-order logic, we assume that we can associate
with each state a domain and an interpretation of the symbols in . In the probabilistic
setting, we assume that we can associate with each state an assignment of values to the
random variables. It is often convenient to assume that the state space is in fact some
subset W of W(), the set of all interpretations for (or assignments to) the vocabulary .
Note that the truth of any formula  in L() is determined by a state. If  is true in some
state w, we write w |= .
The probabilistic extension Lpr () of a base logic L() is simply the set of probability
formulas over L(). Formally, for each   L(), Pr() is a numeric term. The formulas in
Lpr () are defined to be all the Boolean combinations of arithmetic expressions involving
numeric terms. For example, Pr(fly | bird )  1/2 is a formula in Lpr ({fly, bird }) (where
we interpret a conditional probability expression Pr( | ) as Pr(  )/ Pr() and then
multiply to clear the denominator). By analogy with constraints, a formula of the form
Pr() = 1 is called an objective formula.
323

fiHalpern & Koller

Given a set W  W(), assume that FW is the algebra consisting of all sets of the
form [[]]W = {w : w |= }, for   L(). (In the case of propositional logic, where 
consists of a finite set of primitive propositions, FW = 2W . In the case of first-order logic,
not all sets are necessarily definable by formulas, so FW may be a strict subset of 2W .)
Let  be a probability measure on (W, FW ). We can then ascribe semantics to Lpr () in
the probability space (W, FW , ) in a straightforward way. In particular, we interpret the
numeric term Pr() as ({w  W : w |= }). Since a formula   L() describes an event
in the space W , a formula  in Lpr () is clearly a constraint on measures on W . We write
 |=  if the measure   W satisfies the formula .
A syntactic knowledge base KB  Lpr () can be viewed as a constraint on W in an
obvious way. Formally, KB represents the set of probability measures [[KB ]]  W , which
consists of all measures  on W such that  |= KB .
We say that KB (whether syntactic or semantic) is consistent if [[KB ]]X 6= , i.e., if
the constraints are satisfiable. Finally, we say that KB entails  (where  is another set of
constraints on X ), written KB |=X , if [[KB ]]X  [[]]X , i.e., if every measure that satisfies
KB also satisfies . We write |=X  if  is satisfied by every measure in X . We omit the
subscript X from |= if it is clear from context.
Entailment is well-known to be to be a very weak method of drawing conclusions from
a knowledge base, in particular with respect to its treatment of irrelevant information.
Consider the knowledge base consisting only of the constraint Pr(fly | bird )  0.9. Even
though we know nothing to suggest that red is at all relevant, entailment will not allow us
to reach any nontrivial conclusion about Pr(fly | bird  red ).
One way to get more powerful conclusions is to consider, not all the measures that satisfy
KB , but a subset of them. Intuitively, given a knowledge base KB , an inference procedure
picks a subset of the measures satisfying KB , and infers  if  holds in this subset. Clearly,
more conclusions hold for every measure in the subset than hold for every measure in the
entire set.
Definition 2.1 : An (X, FX )-inference procedure is a partial function I : 2(X,FX ) 7
2(X,FX ) such that I(A)  A for A  (X,FX ) and I(A) =  iff A =  for all A  2(X,FX ) in
the domain of I (i.e., for all A for which I is defined). We write KB |I  if I([[KB ]]X )  [[]]X .
When FX is clear from context or irrelevant, we often speak of X-inference procedures.
We remark that Paris (1994) considers what he calls inference processes. These are just
inference procedures as we have defined them that, given a a set A of probability measures,
return a unique probability measure in A (rather than an arbitrary subset of A). Paris
gives a number of examples of inference processes. He also considers various properties that
an inference process might have. Some of these are closely related to various properties of
representation indepedence that we consider. We discuss Pariss work in Section 7.
Entailment is the X-inference procedure defined on all sets determined by taking I to
be the identity. Maximum entropy is also an inference procedure in this sense.
Definition 2.2: Given a probability measure  on a finite space X (where all sets are
P
measurable), its entropy H() is defined as  xX (x) log (x). (The log is taken to the
me (A) consist of the measures in A
base 2 here.) Given a set A of measures in X , let IX
324

fiRepresentation Dependence

that have the highest entropy if there are measures in A whose entropy is at least as high
as that of any measure in A; if there are no such measures, inf me (A) is undefined.
It is easy to see that inf me (A) is defined if A is closed (in the topological sense; i.e., if
n is a sequence of probability measures in A and n converges to , then   A). Thus,
we could take the domain of inf me
X to consist only of the closed sets of measures in X .
There are also open sets A for which inf me (A) is defined, although it is not defined for all
open sets A. For example, suppose X = {x1 , x2 } and let A = { : (x1 ) < 1/2}. Let 0
be such that 0 (x1 ) = 1/2. It is easy to check that H(0 ) = 1, and H() < 1 for   A.
However, for all , there is some   A such that H() > 1  . It follows that there is no
measure in A whose entropy is higher than that of any other measure in A, so inf me (A) is
undefined. On the other hand, if A0 = { : (x1 ) < 2/3}, then there is a measure whose
entropy is maximum in the open set A0 , namely the measure 0 .
There are, of course, many inference procedures besides entailment and maximum entropy that can be defined on a measurable space. In fact, as the following proposition shows,
any binary relation | satisfying certain reasonable properties is an inference procedure of
this type.
Proposition 2.3: If I is an X-inference procedure then the following properties hold for
every KB , KB 0 , ,  over X such that KB is in the domain of I.
 Reflexivity: KB |I KB .
 Left Logical Equivalence: if KB is logically equivalent to KB 0 , i.e., if |= KB  KB 0 ,
then for every  KB |I  iff KB 0 |I .
 Right Weakening: if KB |I  and |=    then KB |I .
 And: if KB |I  and KB |I , then KB |I   .
 Consistency: if KB is consistent then KB |6I false.
Proof: Straightforward from the definitions.
Interestingly, these properties are commonly viewed as part of a core of reasonable
properties for a nonmonotonic inference relation (Kraus, Lehmann, & Magidor, 1990).
We would like to also prove a converse, showing that any relation | over probabilistic
constraints on some space X that satisfies the five properties above must have the form
|IX . This is not quite true, as the following example shows.
Example 2.4: Fix a measurable space (X, FX ). Let the language consist of all (finite)
Boolean combination of statements of the form Pr(S)  , where S  FX . Now fix one
nonempty strict subset S0 of X, and let n be the statement Pr(S0 )  1/n. Define an
inference procedure | as follows. If KB is not equivalent to true (i.e, if [[KB ]]X 6= X ),
then KB |  iff KB |= . On the other hand, true |  iff n |=  for all sufficiently large
n. That is, true |  if there exists an N such that for all n  N , we have n |= . It is
easy to check that all five properties in Proposition 2.3 hold for |. However, | is not |I
for an X-inference procedure I. For suppose it were. Note that n |= m for all n  m,
325

fiHalpern & Koller

so true | m for all m. Thus, we must have I(X )  [[n ]]X for all n. It follows that
IX (X )  [[Pr(S0 ) = 0]]X , and so true |I Pr(S0 ) = 0. However, n 6|= Pr(S) = 0 for any n,
so we do not have true | Pr(S) = 0. This contradicts the assumption that | = |I .
Essentially what we need to get the converse to Proposition 2.3 is an infinitary version of
V
the And Rule, which would say that if KB |I i for all i, then KB |I i i . If the language
were closed under infinite conjunctions, then this rule would in fact be just what we need.
Since we have not assumed that the language is closed under infinite conjunctions, we use
a variant of this rule.
 Infinitary And: For any set  of statements, if KB |I  for all    and  |= ,
then KB |I .
Proposition 2.5: Let | be a relation over probabilistic constraints on X for which the
properties Reflexivity, Left Logical Equivalence, Right Weakening, Infinitary And, and Consistency hold for all KB in the domain of | . (That is, if KB is in the domain of | in
that KB |  for some , then KB | KB , and so on.) Then | is |I for some X-inference
procedure I.
Proof: See Appendix A.1.
We are typically interested not just in an inference procedure defined on one space X,
but in a family of related inference procedures, defined on a number of spaces. For example,
entailment is an inference procedure that is defined on all spaces X; maximum entropy is
defined on all finite measurable spaces (X, 2X ).
Definition 2.6 : If X is a set of measurable spaces, an X -inference procedure is a set
{I(X,FX ) : (X, FX )  X }, where I(X,FX ) is an (X, FX )-inference procedure for (X, FX )  X .
We sometimes talk about an X -inference procedure I, and write KB |I  when (X, FX ) 
X is clear from context. However, it should be stressed that, formally, an X -inference procedure is a really a set of inference procedures (typically related in some natural way).
Clearly entailment is an X -inference procedure for any X , where IX is simply the identity
function for X  X . If X consists of finite measurable spaces where all sets are measurable,
then maximum entropy is an X -inference procedure. We typically denote this inference
procedure | me . Thus, KB | me  if  holds for all the probability measures of maximum
entropy satisfying KB .
Important assumptions: For the remainder of this paper, we deal only with X inference procedures I for which X satisfies two richness assumptions. These assumptions
hold for all the standard inference procedures that have been considered.
 We assume that X is closed under crossproducts, so that if (X, FX ), (Y, FY )  X ,
then (X  Y, FXY )  X , where FXY is the algebra formed by taking finite unions
of disjoint sets of the form S  T , for S  FX and T  FY . It is easy to see that
this is an algebra, since S  T = S  T  S  T  S  T and (S  T )  (S 0  T 0 ) =
(S  S 0 )  (T  T 0 ) (from which it also follows that any union of such sets can be
326

fiRepresentation Dependence

written as a disjoint union). Note that if X and Y are finite sets, FX = 2X , and
FY = 2Y , then FX  FY = 2XY . As we shall see, having (X  Y, FXY )  X if each
of (X, FX ) and (Y, FY ) is in X allows us to relate constraints on X to constraints on
Y in a natural way.
 We assume that X contain sets of all finite cardinalities; more precisely, for all n  2,
there exists a set (X, FX )  X such that |X| = n and FX = 2X . This assumption
is not actually needed for any of our results, since the assumption that X is closed
under crossproducts already implies that, for any finite n, there exists a measurable
space (X, FX )  X such that |X|  n; this already suffices to prove all the results
of the paper. However, assuming that X has sets of all cardinalities does make the
proofs easier.
We also want the domain of I to satisfy certain assumptions, but we defer stating these
assumptions until we have introduced some additional definitions and notation.

3. Robustness
In order to define robustness to representation shifts, we must first define the notion of
a representation shift. Our first attempt at this definition is based on the idea of using
constraints that specify the relationship between the two vocabularies. For example, in Example 1.1, we might have X = {colorful , colorless} and Y = {red , blue, green, colorless}. We
can specify the relationship between X and Y via a constraint that asserts that colorful 
(red  blue  green).
Of course, not every constraint is a legitimate mapping between representations. For
example, a formula that asserted colorful is obviously not a legitimate representation
shift. At a minimum, we must assume that the constraint does not give any additional
information about X as far as logical inference goes. At a syntactic level, we can use the
following definition. Given a knowledge base KB  Lpr (), we say that   Lpr (  0 ) is
-conservative over KB if, for all formulas   Lpr (), we have KB |=  iff KB   |= .
Thus, adding  to the knowledge base does not permit any additional logical inferences
in the vocabulary . An inference procedure I is robust if it is unaffected by conservative
extensions; that is, if KB ,   Lpr (), then KB |I  iff KB   |I  for all  that are
-conservative over KB . Roughly speaking, this says that getting new information that is
uninformative as far as logical inference goes does not affect default conclusions.
The formal definition of robustness, which uses semantic rather than syntactic concepts,
extends these intuitions to arbitrary constraints on measures (not just ones that can be
expressed in the language Lpr ).
Definition 3.1: For   X1 ...Xn , define Xi  Xi by taking Xi (A) = (X1     
Xi1  A  Xi+1      Xn ). A constraint  on Xi can be viewed as a constraint on
X1 ...Xn by taking [[]]X1 ...Xn = {  X1 ...Xn : Xi |= }. We frequently identify
constraints on Xi with constraints on X1  . . .  Xn in this way. For B  X1 Xn , define
proj Xi (B) = {Xi :   B}. A constraint  on X1 Xn is said to be Xi -conservative
over the constraint KB on Xi if proj Xi ([[KB  ]]X1 Xn ) = [[KB ]]Xi .
327

fiHalpern & Koller

To see that this definition generalizes the earlier language-oriented definition, note that
if  and KB are constraints on X and  is a constraint on XY , then KB   |=  iff
proj 1 ([[KB  ]]XY )  [[]]X , while KB |=  iff [[KB ]]X  [[]]X .
Definition 3.2: {IX : X  X } is a robust X -inference procedure if for all spaces X, Y  X ,
constraints KB and  on X , and constraints  on XY that are X-conservative over
KB , we have KB |IX  iff KB   |IXY . (Note that this definition implicitly assumes
that X  Y  X if X, Y  X , an assumption we made explicit earlier.)
At first glance, robustness might seem like a reasonable desideratum. After all, why
should adding a constraint on XY that places no restrictions on X change the conclusions that we might reach about X? Unfortunately, it turns out that this definition
is deceptively strong, and disallows any interesting inference procedures. In particular,
one property we may hope for in an inference procedure is to draw nontrivial conclusions
about probabilities of events, that is, conclusions that do not follow from entailment. For
example, maximum entropy (or any inference procedure based on symmetry) will conclude
Pr(p) = 1/2 from the empty knowledge base. We can show that inference procedures
that are robust do not really allow much in the way of nontrivial conclusions about the
probabilities of events.
Definition 3.3: An (X, FX )-inference procedure I is essentially entailment for the knowledge base KB  X if for all S  FX , if KB |I  < Pr(S) <  then KB |=   Pr(S)  .
I is essentially entailment for X if it is essentially entailment for all knowledge bases KB
in the domain of IX .
Thus, when entailment lets us conclude Pr(S)  [, ], an inference procedure that is
essentially entailment lets us draw only the slightly stronger conclusion Pr(S)  (, ). To
prove this, we need to make three assumptions about the domain of I. (For other results,
we need other assumptions about the domain of I.)
DI1.   Pr(S)   is in the domain of I(X,FX ) for all S  FX , ,   IR.
DI2. If KB is in the domain of IX , then it is also in the domain of IXY (when KB is
viewed as a constraint on XY .)
DI3. If KB 1 and KB 2 are in the domain of IX , then so is KB 1  KB 2 .
Note that sets of the form   Pr(S)   are closed sets. It certainly seems reasonable
to require that such sets be in the domain of an inference procedure; they correspond to
the most basic observations. DI2 seems quite innocuous; as observed earlier, we do want
to be able to view constraints on X as constraints on XY , and doing so should not
prevent them from being in the domain of I. DI3 also seems to be a reasonable assumption,
since if KB 1 and KB 2 correspond to possible observations, we want to be able to draw
conclusions from combining the observations. DI3 holds if the domain of I consists of
closed sets. But note that it does not hold for I me if we take its domain to consist of
all sets that have a measure whose entropy is maximum. For example, if X = {x1 , x2 },
A = {0 }  { : (x1 ) > 3/4}, and B = { : (x1 )  2/3}, where 0 (x0 ) = 1/2, then each
of A and B have a measure whose entropy is maximum, but A  B does not have a measure
whose entropy is maximum.
328

fiRepresentation Dependence

Theorem 3.4: If {IX : X  X } is a robust X -inference procedure that satisfies DI1, DI2,
and DI3, then IX is essentially entailment for all X  X .
Proof: See Appendix A.2.
It is possible to construct robust inference procedures that are almost but not quite
entailment, simply by strengthening some conclusions from Pr(S)  [, ] to Pr(S) 
(, ). Clearly, however, any robust inference procedure is extremely limited in its ability
to jump to conclusions. In the next section, we look at a definition that seems closer to
the intuitive notion of representation independence, and has somewhat more reasonable
consequences.

4. Representation Independence
4.1 Representation shifts
If X and Y are two different representations of the same phenomena then, intuitively,
there should be a way of relating states in X to corresponding states in Y . We want this
correspondence to respect the logical structure of events. Formally, we require that it be a
homomorphism with respect to complementation and intersection.
Definition 4.1: An (X, FX )-(Y, FY ) embedding f is a function f : FX 7 FY such that
f (S  T ) = f (S)  f (T ) and f (S) = f (S) for all S, T  FX .
As elsewhere, we talk about X-Y embeddings rather than (X, FX )-(Y, FY ) embeddings if
FX and FY do not play a significant role.
Our goal is to consider the effect of a transformation on probabilistic formulas. Hence,
we are interested in sets of states and their probabilities.
Definition 4.2: If f is an X-Y embedding,   X , and   Y , then  and  correspond
under f if (S) = (f (S)) for all events S  FX . We define a mapping f  : 2X 7 2Y as
follows. We first define f  on singleton sets (except that, for convenience, we write f  ()
rather than f  ({}) by taking f  () = {  Y : (f (S)) = (S) for all S  FX }. Thus,
f  () consists of all measures in Y that correspond to  under f . If D is an arbitrary
subset of 2X , define f  (D) = D f  () for D  X .
If  is a constraint on X expressed in some language, we typically write f  () rather than
f  ([[]]X ). We implicitly assume that the language is such that the constraint f  () is also
expressible. It is not hard to see that f  () is the constraint that results by replacing every
set S  FX that appears in  by f (S).
Example 4.3: In Example 1.1, we might have X = {colorful , colorless} and Y = {red , blue,
green, colorless}. In this case, we might have f (colorful ) = {red , blue, green} and f (colorless) =
{colorless}. Consider the measure   X such that (colorful ) = 0.7 and (colorless) =
0.3. Then f  () is the set of measures  such that the total probability assigned to the set of
states {red , blue, green} by  is 0.7. Note that there are uncountably many such measures.
It is easy to check that if  is a constraint on X such as Pr(colorful ) > 3/4, then f  () is
Pr({red , blue, green}) > 3/4.
329

fiHalpern & Koller

Embeddings can be viewed as the semantic analogue to the syntactic notion of interpretation defined in (Enderton, 1972, pp. 157162), which has also been used in the recent
literature on abstraction (Giunchiglia & Walsh, 1992; Nayak & Levy, 1995). Essentially,
an interpretation maps formulas in a vocabulary  to formulas in a different vocabulary
 by mapping the primitive propositions in  (e.g., colorful ) to formulas over  (e.g.,
red  blue  green) and then extending to complex formulas in the obvious way. The representation shift in Example 1.2 can also be captured in terms of an interpretation, this one
taking flying-bird to fly  bird .
Definition 4.4: Let  and  be two vocabularies. In the propositional case, a interpretation of  into  is a function i that associates with every primitive proposition p  
a formula i(p)  L(). A more complex definition in the same spirit applies to first-order
vocabularies. For example, if R is a k-ary predicate, then i(R) is a formula with k free
variables.
Given an interpretation i, we get a syntactic translation from formulas in L() to formulas
in L() using i in the obvious way; for example, i((p  q)  r) = (i(p)  i(q))  i(r)
(see (Enderton, 1972) for the details). Clearly an interpretation i from  to  induces an
embedding f from W1  W() to W2  W(): we map [[]]W1 to [[i()]]W2 .
Of course, not all embeddings count as legitimate representation shifts. For example,
consider an embedding f defined in terms of an interpretation that maps both the propositions p and q to the proposition r. Then the process of changing representations using
f gives us the information that p and q are equivalent, information that we might not
have had originally. Intuitively, f gives us new information by telling us that a certain
situationthat where p  q holdsis not possible.
More formally, the embedding f
has the following undesirable property: it maps the set of states satisfying p  q to the
empty set. This means a state where p  q holds does not have an analogue in the new
representation. We want to disallow such embeddings.
Definition 4.5: An X-Y embedding f is faithful if, for all S, T  FX , we have S  T iff
f (S)  f (T ).
This definition has the desired consequence of disallowing embeddings that give new
information as far as logical consequence goes.
Lemma 4.6: An X-Y embedding f is faithful if and only if for all constraints KB and ,
we have KB |=  iff f  (KB ) |= f  ().
Proof: See Appendix A.3.
It is clear that our embedding from Example 4.3 is faithful: f (colorful ) = {red , blue, green}
and f (colorless) = colorless. The following proposition gives further insight into faithful
embeddings.
Proposition 4.7: Let f be a faithful X-Y embedding. Then the following statements are
equivalent:
(a)  and  correspond under f ;
330

fiRepresentation Dependence

(b) for all formulas ,  |=  iff  |= f  ().
Proof: See Appendix A.3.
If the embedding f is a reasonable representation shift, we would like an inference
procedure to return the same answers if we shift representations using f .
Definition 4.8: If X, Y  X , then the X -inference procedure {IX : X  X } is invariant
under the X-Y embedding f if for all constraints KB and  on X , we have KB |IX  iff
f  (KB ) |IY f  (). (Note that, in particular, this means that KB is in the domain of | IX
iff f  (KB ) is in the domain of | IY .)
Definition 4.9: The X -inference procedure {IX : X  X } is representation independent if
it is invariant under all faithful X-Y embeddings for all X, Y  X .
Since the embedding for Example 4.3 is faithful, any representation-independent inference procedure would return the same answers for Pr(colorful ) as for Pr(red  blue  green).
The issue is somewhat more subtle for Example 1.2. There, we would like to have an embedding f generated by the interpretation i(flying-bird ) = fly  bird and i(bird ) = bird .
This is not a faithful embedding, since flying-bird  bird is not a valid formula, while
i(flying-bird  bird ) is (fly  bird )  bird which is valid. Looking at this problem semantically, we see that the state corresponding to the model where flying-bird  bird holds is
mapped to . But this is clearly the source of the problem. According to our linguistic intuitions for this domain, this is not a legitimate state. Rather than considering all the states
in W({flying-bird , bird }), it is perhaps more appropriate to consider the subset X consisting of the truth assignments characterized by the formulas {flying-bird  bird , flying-bird 
bird , flying-bird  bird }. If we now use i to embed X into W({fly, bird }), the resulting embedding is indeed faithful. So, as for the previous example, invariance under this
embedding would guarantee that we get the same answers under both representations.
4.2 Representation-independent inference procedures
Although the definition of representation independence seems natural, so did the definition
of robustness. How do the two definitions relate to each other? First, we show that representation independence is a weaker notion than robustness. For this result, we need to
consider inference procedures that satisfy two further assumptions.
DI4. If f is a faithful X-Y embedding, then KB is in the domain of IX iff f  (KB ) is in the
domain of IY .
DI5. If KB is in the domain of IXY , f is a faithful X-Y embedding, and 1 is a constraint
on X , then KB  (1  f  (1 )) is in the domain of IXY .
DI4 is very natural and is satisfied by all the standard inference procedures. It is easy to
check that if KB is closed iff f  (KB ) is closed. While DI5 may not appear so natural, it
does hold for domains consisting of closed sets, since it is not hard to check that   f  (1 )
is closed. DI5 would follow from DI3 and the assumption that   f  (1 ) is in the domain
of IXY , but it is actually weaker than the combination of these two assumptions. In
particular, it holds for the domain consisting of all sets on which there is a measure of
maximum entropy.
331

fiHalpern & Koller

Theorem 4.10: If an X -inference procedure is robust that satisfies DI2, DI4, and DI5,
then it is representation independent.
Proof: See Appendix A.3.
We have already shown that any robust inference procedure must be almost trivial. Are
there any interesting representation-independent inference procedures? As we shall see, the
answer is mixed. There are nontrivial representation-independent inference procedures, but
they are not very interesting.
Our first result shows that representation independence, like robustness, trivializes the
inference procedure, but only for some knowledge bases.
Theorem 4.11: If {IX : X  X } is a representation-independent X -inference procedure
then, for all X  X , IX is essentially entailment for all objective knowledge bases in its
domain.3
Proof: See Appendix A.3.
Corollary 4.12: If {IX : X  X } is a representation-independent X -inference procedure,
KB is objective, and KB |I  < Pr(S) <  for some   0 and   1, then  = 0 and
 = 1.
This result tells us that from an objective knowledge base Pr(T ) = 1, we can reach only
three possible conclusions about a set S. If T  S, then we can conclude that Pr(S) = 1;
if T  S, then we can conclude that Pr(S) = 0; otherwise, the strongest conclusion we can
make about Pr(S) is that is somewhere between 0 and 1.
We can construct a representation-independent inference procedure that is not entailment and has precisely this behavior if we restrict attention to countable state spaces. Suppose that X is countable. Given an objective knowledge base KB of the form Pr(T ) = 1,
where T  FX , let KB + consist of all formulas of the form 0 < Pr(S) < 1 for for
all nonempty strict subsets S of T in FX .4 We now define an X-inference procedure
0 as follows: If KB is equivalent to an objective knowledge base, then KB |  if
IX
I0
KB  KB + |= ; if KB is not equivalent to an objective knowledge base, then KB |I 0  if
0 is indeed an inference procedure.
KB |= . It follows easily from Proposition 2.5 that IX
Moreover, it is not equivalent to the standard notion of entailment; for example, we have
true |I 0 0 < Pr(p) < 1, while 6|=0 < Pr(p) < 1. Nevertheless, we can prove that I 0 is
representation independent.
0 : X  X } is a representationLemma 4.13: Let X consist of only countable sets. Then {IX
independent X -inference procedure.

3. In an earlier version of this paper (Halpern & Koller, 1995), we claimed that any representationindependent inference procedure that satisfied a minimal irrelevance property (implied by robustness,
but not equivalent to it) is essentially entailment for all knowledge bases. As Jaeger (1996) shows, an
inference procedure along the lines of I 1 described below can be constructed to show that this result is
not correct. We seem to need the full strength of robustness.
4. The requirement that X be countable is necessary here. If X is uncountable and every singleton is in FX ,
then KB + is inconsistent if both T and T are uncountable. It is impossible that each of an uncountable
collection of points has positive measure.

332

fiRepresentation Dependence

Proof: See Appendix A.3.
While objective knowledge bases may not appear so interesting if we restrict to propositional languages, for languages that include first-order and statistical information they
become quite interesting. Indeed, as shown in (Bacchus, 1990; Bacchus, Grove, Halpern, &
Koller, 1996), knowledge bases with first-order and (objective) statistical information allow
us to express a great deal of the information that we naturally encounter. For example, we
can express the fact that 90% of birds fly as an objective statement about the number of
flying birds in our domain relative to the overall number of birds. Of course, Theorem 4.11
applies immediately to such knowledge bases.
Theorem 4.11 also implies that various inference procedures cannot be representation
independent. In particular, since true | me Pr(p) = 1/2 for a primitive proposition p, it
follows that maximum entropy is not essentially entailment. This observation provides
another proof that maximum entropy is not representation independent.
It is consistent with Theorem 4.11 that there are representation-independent inference
procedures that are not almost entailment for probabilistic knowledge bases. For example,
1 defined as follows. Given A   , if there exists
consider the X-inference procedure IX
X
1 (A) = {   : (S)  1/3};
some S  FX such that A = {  X : (S)  1/4}, then IX
X
1 (A) = A. Thus, Pr(S)  1/4 | Pr(S)  1/3. Clearly, I 1 is not essentially
otherwise, IX
X
I1
entailment. Yet, we can prove the following result.

Lemma 4.14: Suppose that X consists only of measure spaces of the form (X, 2X ), where
1 : X  X } is a representation-independent X -inference procedure.
X is finite. Then {IX

Proof: See Appendix A.3.
Note that it follows from Theorem 3.4 that I 1 cannot be robust. Thus, we have shown
that representation independence is a strictly weaker notion than robustness.
This example might lead us to believe that there are representation-independent inference procedures that are interesting for probabilistic knowledge bases. However, as we
now show, a representation-independent inference procedure cannot satisfy one key desideratum: the ability to conclude independence by default. For example, an important feature of
the maximum-entropy approach to nonmononotic reasoning (Goldszmidt, Morris, & Pearl,
1993) has been its ability to ignore irrelevant information, by implicitly assuming independence. Of course, maximum entropy does not satisfy representation independence.
Our result shows that no approach to probabilistic reasoning can simultaneously assure
representation independence and a default assumption of independence.
We do not try to give a general notion of default assumption of independence here,
since we do not need it for our result. Rather, we give a minimal property that we would
hope an inference procedure might have, and show that this property is sufficient to preclude
representation independence. Syntactically, the property we want is that if  and  are
disjoint vocabularies, KB  Lpr (),   L(), and   L(), then KB |I Pr(  ) =
Pr()  Pr().
333

fiHalpern & Koller

Definition 4.15: An X -inference procedure {IX : X  X } enforces minimal default independence if, whenever X and Y are in X , KB is a constraint on X in the domain of |IX ,
S  FX , and T  FY , then KB |IXY Pr(S  T ) = Pr(S)  Pr(T ).5
This definition clearly generalizes the syntactic definition.
Clearly, entailment does not satisfy minimal default independence. Maximum entropy,
however, does. Indeed, a semantic property that implies minimal default independence is
used by Shore and Johnson (1980) as one of the axioms in an axiomatic characterization of
maximum-entropy.
Theorem 4.16: If {IX : X  X } is an X -inference procedure that enforces minimal default
independence and satisfies DI1, then IX is not representation independent.
Proof: See Appendix A.3.
This result is very interesting as far as irrelevance is concerned. We might hope that
learning irrelevant information does not affect our conclusions. While we do not attempt
to define irrelevance here, certainly we would expect that if KB 0 is in a vocabulary disjoint
from KB and , then, for example, KB |I Pr() =  iff KB  KB 0 |I Pr() = . If KB 0
is objective, then the standard probabilistic approach would be to identify learning KB 0
with conditioning on KB 0 . Suppose that we restrict to inference procedures that do indeed
condition on objective information (as is the case for the class of inference procedures we
consider in Section 6). Then KB  KB 0 |I Pr() =  exactly if KB |I Pr( | KB 0 ) = .
Thus, Theorem 4.16 tells us that inference procedures that condition on new (objective)
information cannot both be representation independent and ignore irrelevant information.
Thus, although representation independence, unlike robustness, does not force us to use
entirely trivial inference procedures, it does prevent us from using procedures that have
certain highly desirable properties.

5. Discussion
These results suggest that any type of representation independence is hard to come by. They
also raise the concern that perhaps our definitions were not quite right. We can provide
what seems to be even more support for the latter point.
Example 5.1: Let Q be a unary predicate and c1 , . . . , c100 , d be constant symbols. Suppose
that we have two vocabularies  = {Q, d} and  = {Q, c1 , . . . , c100 , d}. Consider the
interpretation i from  to  for which i(d) = d and i(Q(x)) = Q(x)  Q(c1 )  . . .  Q(c100 ).
Now, consider KB = xQ(x). In this case, i(KB ) = x(Q(x)  Q(c1 )  . . .  Q(c100 ).
Intuitively, since all the ci s may refer to the same domain element, the only conclusion we
can make with certainty from Q(c1 )  . . .  Q(c100 ) is that there exists at least one Q in the
domain, which gives us no additional information beyond KB . We can convert this example
into a general argument that the embedding f corresponding to i is faithful. Intuitively, for
5. Since we are working in the space X  Y , KB should be viewed as a constraint on XY here, Pr(S)
should be understood as Pr(S  Y ), while Pr(T ) should be understood as Pr(X  T ). Recall that, by
assumption, X  Y  X .

334

fiRepresentation Dependence

any KB , we can only get the conclusion Q(c1 )  . . .  Q(c100 ) from f  (KB ) if Q(x) appears
positively in KB ; but, in this case, we already know that there is at least one Q, so we
gain no new information from the embedding. But it does not seem unreasonable that an
inference procedure should assign different degrees of belief to Q(d) given KB = xQ(x) on
the one hand and given i(KB ) = x(Q(x)  Q(c1 )  . . .  Q(c100 )) on the other,6 particularly
if the domain is small. In fact, many reasoning systems explicitly adopt a unique names
assumption, which would clearly force different conclusions in these two situations.
This example suggests that, at least in the first-order case, even faithful embeddings
do not always match our intuition for a reasonable representation shift. One might
therefore think that perhaps the problem is with our definition even in the propositional
case. Maybe there is a totally different definition of representation independence that avoids
these problems. While this is possible, we do not believe it to be the case. The techniques
that we used to prove Theorem 4.16 and 3.4 seem to apply to any reasonable notion of
representation independence.7 To give the flavor of the type of argument used to prove these
theorems, consider Example 1.1, and assume that true |I Pr(colorful ) =  for   (0, 1).8
Using an embedding g such that g(colorful ) = red , we conclude that true |I Pr(red ) = .
Similarly, we can conclude Pr(blue) =  and Pr(green) = . But in order for |I to be
invariant under our original embedding, we must have true |I Pr(red  blue  green) = ,
which is completely inconsistent with our previous conclusions. But the embeddings we use
in this argument are very natural ones; we would not want a definition of representation
independence that disallowed them.
These results can be viewed as support for the position that representation dependence
is justified; the choice of an appropriate representation encodes significant information. In
particular, it encodes the bias of the knowledge-base designer about the world. Researchers
in machine learning have long realized that bias is an inevitable component of effective
inductive reasoning (i.e., learning from evidence). So we should not be completely surprised
if it turns out that other types of leaping to conclusions (as in our context) also depend on
the bias.
But we need to be a little careful here. For example, in some cases we can identify
the vocabulary (and hence, the representation) with the sensors that an agent has at its
disposal. It may not seem that unreasonable that an agent with a temperature sensor and
a motion sensor might carve up the world differently from an agent with a color sensor
and a distance sensor. But consider two agents with different sensors who have not yet
made any observations. Suppose that both of them can talk about the distance to a tree.
Is it reasonable that the two agents should reach different conclusions about the distance
just because they have different sensors (and thus use different vocabularies), although they
have not made any observations? It would then follow that the agents should change their
conclusions if they switched sensors, despite not having made any observations. This does
not seem so reasonable!
Bias and representation independence can be viewed as two extremes in a spectrum.
If we accept that the knowledge base encodes the users bias, there is no obligation to be
6. Actually, i(Q(d)) = Q(d)  Q(c1 )  . . .  Q(c100 ), but the latter is equivalent to Q(d) given KB .
7. They certainly applied to all of the many definitions that we tried!
8. In fact, it suffices to assume that true |I Pr(colorful )  [, ], as long as  > 0 or  < 1.

335

fiHalpern & Koller

invariant under any representation shifts at all. On the other hand, if we assume that the
representation used carries no information, coherence requires that our inference procedure
give the same answers for all equivalent representations. We believe that the right answer lies somewhere in between. There are typically a number of reasonable ways in which
we can represent our information, and we might want our inference procedure to return
the same conclusions no matter which of these we choose. It thus makes sense to require
that our inference procedure be invariant under embeddings that take us from one reasonable representation to another. But it does not follow that it must be invariant under all
embeddings, or even all embeddings that are syntactically similar to the ones we wish to
allow. We may be willing to refine colorful to red  blue  green or to define flying-bird
as fly  bird , but not to transform red to sparrow . In the next section, we show how to
construct inference procedures that are representation independent under a limited class of
representation shifts.

6. Selective invariance
As discussed above, we want to construct an inference procedure I that is invariant only
under certain embeddings. For the purposes of this section, we restrict attention to finite
spaces, where all sets are measurable. That is, we focus on X -inference procedures where
X consists only of measure spaces of the form (X, 2X ), where X is finite.
Our first step is to understand the conditions under which an X -inference procedure I
is invariant under a specific X-Y embedding f . When do we conclude  from KB  X ?
Recall that an inference procedure IX picks a subset DX = IX (KB ), and concludes  iff 
holds for every measure in DX . Similarly, when applied to f  (KB )  Y , IY picks a subset
DY = IY (f  (KB )). For I to be invariant under f with respect to KB , there has to be a
tight connection between DX and DY .
To understand this connection, first consider a pair of measures  on X and  on Y .
Recall from Proposition 4.7 that  and  correspond under f iff, for all formulas , we have
 |=  iff  |= f  (). To understand how the correspondence extends to sets of probability
measures, consider the following example:
Example 6.1: Consider the embedding f of Example 4.3, and let DX = {, 0 } where 
is as above, and 0 (colorful ) = 0.6. How do we guarantee that we reach the corresponding
conclusions from DX and DY ? Assume, for example, that DY contains some measure 
that does not correspond to either  or 0 , e.g., the measure that assigns probability 1/4
to all four states. In this case, the conclusion Pr(colorful )  0.7 holds in DX , because it
holds for both these measures; but the corresponding conclusion Pr(red blue green)  0.7
does not hold in DY . Therefore, every probability measure in DY must correspond to some
measure in DX . Conversely, every measure in DX must correspond to a measure in DY . For
suppose that there is no measure   DY corresponding to . Then we get the conclusion
Pr(blue  red  green) 6= 0.7 from DY , but the corresponding conclusion Pr(colorful ) 6= 0.7
does not follow from DX . Note that these two conditions do not imply that DY must be
precisely the set of measures corresponding to measures in DX . In particular, we might have
DY containing only a single measure  corresponding to  (and at least one corresponding
to 0 ), e.g., one with (red ) = 0.5, (blue) = 0, (green) = 0.2, and (colorless) = 0.3.
336

fiRepresentation Dependence

Based on this example, we use the following extension to our definition of correspondence.
Definition 6.2: We say that DX and DY correspond under f if for all   DY , there exists
a corresponding   DX (so that (S) = (f (S)) for all S  X), and for all   DX , there
exists a corresponding   DY .
Proposition 6.3: Suppose that f is a faithful X-Y embedding, DX  X , and DY  Y .
The following two conditions are equivalent:
(a) DX and DY correspond under f ;
(b) for all , DX |=  iff DY |= f  ().9
Proof: See Appendix A.4.
To produce an inference procedure that is invariant under some X-Y embedding f ,
we must ensure that for every KB , IX (KB ) and IY (KB ) correspond. At first glance, it
seems rather difficult to guarantee correspondence for every knowledge base. It turns out
that the situation is not that bad. In the remainder of this section, we show how, starting
with a correspondence for the knowledge base truethat is, starting with a correspondence
between IX (X ) and IY (Y )we can bootstrap to a correspondence for all KB s, using
standard probabilistic updating procedures.
First consider the problem of updating with objective information. The standard way
of doing this update is via conditioning. For a measure   X and an event S  X, define
|S to be the measure that assigns probability (w)/(S) to every w  S, and zero to all
other states. For a set of measures DX  X , define DX |S to be {|S :   DX }. The
following result is easy to show.
Proposition 6.4: Let S  X be an event and let f be a faithful X-Y embedding. If  and
 correspond under f , then |S and |f (S) also correspond under f .
Proof: Almost immediate from the definitions; left to the reader. (In any case, note that
this result follows from Theorem 6.4 below.)
Clearly, the result extends to sets of measures.
Corollary 6.5: If f is a faithful X-Y embedding, and DX and DY correspond under f ,
then DX |S and DY |f (S) also correspond under f .
What if we want to update on a constraint that is not objective? The standard extension
of conditioning to this case is via relative entropy or KL-divergence (Kullback & Leibler,
1951).
9. While (a) implies (b) for arbitrary spaces, the implication from (b) to (a) depends on the restriction to
finite spaces made in this section. For suppose that X is the natural numbers N , f is the identity, DX
consists of all probability measures on N , and DY consists of all measures but that measure 0 such
that 0 (n) = 1/2n+1 . If the language consists of finite Boolean combinations of assertions of the form
Pr(S)  , for S  N , then it is easy to see that DX |=  iff DY |=  for all formulas , but clearly DX
and DY do not correspond under the identity map.

337

fiHalpern & Koller

Definition 6.6: If  and 0 are measures on X, the relative entropy between 0 and ,
P
denoted KLX (0 k), is defined as xX 0 (x) log(0 (x)/(x)). For a measure  on X and
a constraint , let | denote the set of measures 0 satisfying  for which KLX (0 k) is
minimal.
Intuitively, the KL-divergence measures the distance from 0 to . A measure 0 satisfying  for which KLX (0 k) is minimal can be thought of as the closest measure to
 that satisfies . If  denotes an objective constraint, then the unique measure satisfying  for which KLX (0 k) is minimal is the conditional measure | (Kullback & Leibler,
1951). (That is why we have deliberately used the same notation here as for conditioning.)
Moreover, it is easy to show that KLX (0 k) = 0 iff 0 = . It follows that if   , then
| = .
Given a set of measure DX  X and a constraint  on X , define DX | to be DX |.
We can now apply a well-known result (see, e.g., (Seidenfeld, 1987)) to generalize Proposition 6.4 to the case of relative entropy.
Theorem 6.7: Let  be an arbitrary constraint on X . If f is a faithful X-Y embedding
and  and  correspond under f , then | and |f  () also correspond under f .
Proof: See Appendix A.4.
Again, this result clearly extends to sets of measures.
Corollary 6.8: If f is a faithful X-Y embedding, and DX and DY correspond under f ,
then DX | and DY |f  () also correspond under f .
These results give us a way to bootstrap invariance. We construct an inference procedure that uses relative entropy starting from some set of prior probability measures. Intuitively, these encode the users prior beliefs about the domain. As information comes in,
these measures are updated using cross-entropy. If we design the priors so that certain invariances hold, Corollary 6.8 guarantees that these invariances continue to hold throughout
the process.
Formally, a prior function P on X maps X  X to a set P(X) of probability measures
P (KB ) = P(X)|KB . Note that
in X . Define an inference procedure I P by taking IX
P (true) = P(X), so that when we have no constraints at all, we use P(X) as the basis
IX
for our inference. Most of the standard inference procedures are of the form I P for some
prior function P. It is fairly straightforward to verify, for example, that entailment is I P
for P(X) = X . (This is because, as observed earlier, |KB =  if   KB .) Standard
Bayesian conditioning (defined for objective knowledge bases) is of this form, where we take
P(X) to be a single measure for each space X. More interestingly, it is well known (Kullback
& Leibler, 1951) that maximum entropy is I Pu where Pu (X) is the singleton set containing
only the uniform prior on X.
So what can we say about the robustness of I P to representation shifts? Using Proposition 6.3 and Corollary 6.5, it is easy to show that if we want I P to be invariant under
some set F of embeddings, then we must ensure that the prior function has the right
correspondence property.
Theorem 6.9: If f is a faithful X-Y embedding, then I P is invariant under f iff P(X)
and P(Y ) correspond under f .
338

fiRepresentation Dependence

Proof: See Appendix A.4.
Theorem 6.9 sheds some light on the maximum entropy inference procedure. As we
mentioned, | me is precisely the inference procedure based on the prior function Pu . The
corollary asserts that | me is invariant under f precisely when the uniform priors on X
and Y correspond under f . This shows that maximum entropys lack of representation
independence is an immediate consequence of the identical problem for the uniform prior.
Is there a class F of embeddings under which maximum entropy is invariant? Clearly, the
answer is yes. It is easy to see that any embedding that takes the elements of X to (disjoint)
sets of equal cardinality has the correspondence property required by Theorem 6.9. It follows
that maximum entropy is invariant under all such embeddings. In fact, the requirement that
maximum entropy be invariant under a subset of these embeddings is one of the axioms in
Shore and Johnsons (1980) axiomatic characterization of maximum-entropy. (We remark
that Paris (1994, Theorem 7.10) proves that maximum entropy satisfies a variant of his
atomicity principle; his invariance result is essentially a special case of Theorem 6.9.)
If we do not like the behavior of maximum entropy under representation shifts, Theorem 6.9 provides a solution: we should simply start out with a different prior function.
If we want to maintain invariance under all representation shifts, P(X) must include all
non-extreme priors (i.e., all the measures  on X such that (A) 
/ {0, 1} for all A such
that A 
/ {, X}). This set of priors gives essential entailment as an inference procedure. If,
however, we have prior knowledge as to which embeddings encode reasonable representation shifts, we can often make do with a smaller class of priors, resulting in an inference
procedure that is more prone to leap to conclusions. Given a class of reasonable embeddings F, we can often find a prior function P that is closed under each f  F, i.e., for
each measure   P(X) and each X-Y embedding f  F we make sure that there is a
corresponding measure   P(Y ), and vice versa. Thus, we can guarantee that P has the
appropriate structure using a process of closing off under each f in F.
Of course, we can also execute this process in reverse. Suppose that we want to support
a certain reasoning pattern that requires leaping to conclusions. The classical example of
such a reasoning pattern is, of course, a default assumption of independence. What is the
most representation independence that we can get without losing this reasoning pattern?
As we now show, Theorem 6.9 gives us the answer.
We begin by providing one plausible formulation of the desired reasoning pattern. For
a finite space X, we say that X1      Xn is the product decomposition of X if X =
X1   Xn and n is the largest number for which X can be written as a product in this way.
(It is easy to see that if X is finite, then this maximal product decomposition is unique.)
A measure   X is a product measure on X if X1      Xn is the product decomposition
of X and there exist measures i  Xi for i = 1, . . . , n such that  = 1      n , that
Q
is, (U1      Un ) = ni=1 i (Ui ), if Ui  Xi , i = 1, . . . , n. Let P be the set of all product
measures on X. If P is the prior and the relative entropy rule is used to update the prior
given a knowledge base, then |P satisfies a form of minimal default independence. In
fact, it is easy to show that it satisfies the following stronger property.
339

fiHalpern & Koller

Proposition 6.10: Suppose that X1      Xn is the product decomposition on X and, for
each i = 1, . . . , n, KB i is a constraint on Xi , and Si is a subset of Xi . Then
n
^

KB i |IP Pr(S1  . . .  Sn ) =

i=1



n
Y

Pr(Si ).

i=1

Proof: See Appendix A.4.
Theorem 4.16 shows that |P cannot be invariant under all embeddings. Theorem 6.9
tells us that it is invariant under precisely those embeddings for which P is invariant. These
embeddings can be characterized syntactically in a natural way. Suppose that 1 , . . . , n is
a partition of a finite set  of primitive propositions. Note that a truth assignment to the
primitive propositions in  can be viewed as a crossproduct of truth assignments to the
primitive propositions in 1 , . . . , n . Under this identification, suppose that a set X of truth
assignments to  is decomposed as X1      Xn , where Xi consists of truth assignments
to i . In that case, if p  j and q, r  k for some j 6= k, then true |P Pr(p  q) =
Pr(p)  Pr(q), but since since q and r are in the same subset, we do not have true |P Pr(r 
q) = Pr(r)  Pr(q). Hence, P is not invariant under an interpretation i that maps p to
r and maps q to itself. Intuitively, the problem is that i is crossing subset boundaries;
it is mapping primitive propositions that are in different subsets to the same subset. If we
restrict to interpretations thatpreserve subset boundaries, then we avoid this problem.
We can get a semantic characterization of this as follows. If the product decomposition
of X is X1      Xn and the product decomposition of Y is Y1      Yn , then f is
an X-Y product embedding if f is an X-Y embedding and there are Xi -Yi embeddings fi ,
i = 1, . . . , n, and f (hx1 , . . . , xn i) = f1 (x1 )      fn (xn ). Product embeddings capture
the intuition of preserving subset boundaries; elements in a given subset Xi remain in
the same subset (Yi ) after the embedding. However, the notion of product embedding is
somewhat restrictive; it requires that elements in the ith subset of X map to elements in
the ith component of Y , for i = 1, . . . , n. We can still preserve default independence if the
components of a product are permuted. An g is a permutation embedding if there exists a
permutation  of {1, . . . , n} such that g(hx1 , . . . , xn i) = hx(1) , . . . , x(n) i.
Theorem 6.11: The inference procedure IP is invariant under faithful product embeddings
and under permutation embeddings.
Theorem 6.9 thus provides us with the basic tools to easily define an inference procedure
that enforces minimal default independence for constraints involving disjoint parts of the
language, while at the same time guaranteeing invariance under a large and natural class
of embeddings. Given our negative result in Theorem 4.16, this type of result is the best
that we could possibly hope for. In general, Theorem 6.9 provides us with a principled
framework for controlling the tradeoff between the strength of the conclusions that can be
reached by an inference procedure and invariance under representation shifts.

7. Related Work
As we mentioned earlier, there are two types of probabilistic inference. We partition our
discussion of related work along those lines.
340

fiRepresentation Dependence

7.1 Probabilistic Inference from a Knowledge Base
Given the importance of representation in reasoning, and the fact that one of the main criticisms of maximum entropy has been its sensitivity to representation shifts, it is surprising
how little work there has been on the problem of representation dependence. Indeed, to the
best of our knowledge, the only work that has focused on representation independence in
the logical sense that we have considered here prior to ours is that of Salmon and Paris.
Salmon (1961) defined a criterion of linguistic invariance, which seems essentially equivalent to our notion of representation independence. He tried to use this criterion to defend
one particular method of inductive inference but, as pointed out by Barker in the commentary at the end of (Salmon, 1961), his preferred method does not satisfy his criterion either.
Salmon (1963) then attempted to define a modified inductive inference method that would
satisfy his criterion but it is not clear that this attempt succeeded. In any case, our results
show that his modified method certainly cannot be representation independent in our sense.
As we said earlier, Paris (1994) considers inference processes, which given a constraint on
X , choose a unique measure satisfying the constraint. He then considers various properties
that an inference process might have. Several of these are closely related to properties that
we have considered here. (In describing these notions, we have made some inessential
changes so as to be able to express them in our notation.)
 An X -inference process I is language invariant if all X, Y  X and all constraints KB
and  on X , we have that KB |IX  iff KB |IXY . Clearly language invariance
is a special case of robustness. Paris shows that a center of mass inference process
(that, given a set A  X , chooses the measure that is the center of mass of A) is
not language invariant; on the other hand, it is well known that maximum entropy is
language invariant.
 An X -inference process I satisfies the principle of irrelevant information if for all
spaces X, Y  X , constraints KB and  on X , and constraints  on Y , we have
KB |IX  iff KB   |IXY . Again, this is a special case of robustness, since a
constraint  on Y must be X-conservative. Paris shows that maximum entropy
satisfies this principle. (He restricts the domain of the maximum entropy process to
closed convex sets, so that there is always a unique probability measure that maximizes
entropy.)
 An X -inference process I satisfies the renaming principle if, whenever X and Y are
finite spaces, g : X  Y is an isomorphism, and f : 2X  2Y is the faithful embedding
based on g (in that f (S) = {g(s) : s  S}), then for all constraints KB and  on X ,
we have KB |IX  iff f  (KB ) |IY f  (). Clearly, the renaming principle is a special
case of representation independence. Paris shows that a number of inference processes
(including maximum entropy) satisfy the renaming principle.
 An X -inference process I satisfies the principle of independence if, whenever X, Y ,
and Z are in X , S  FX , T  FY , U  FZ , and KB is the constraint Pr(U ) =
a  Pr(S|U ) = b  Pr(T |U ) = c, where a > 0, then KB | Pr(S  T |U ) = bc. Ignoring the conditional probabilities, this is clearly a special case of minimal default
independence. Paris and Vencovska (1990) show that maximum entropy is the unique
341

fiHalpern & Koller

inference process satisfying a number of principles, including renaming, irrelevant
information, and independence.
 An X -inference process I satisfies the atomicity principle if, for all X, Y1 , . . . , Yn in
X , whenever f 0 is an embedding from {0, 1} to X, and f is the obvious extension of
f 0 to an embedding from to {0, 1}  Y1  . . .  Yn to X  Y1  . . .  Yn , then for all
constraints KB and  on {0,1}Y1 ...Yn , we have KB |IX  iff f  (KB ) |IY f  ().
Clearly atomicity is a special case of representation independence. Paris shows that
there is no inference process that satisfies atomicity. The argument is similar in spirit
to that used to prove Theorems 4.11 and 4.16, but much simpler, since inference
processes return a unique probability measure, not a set of them.
More recently, Jaeger (1996), building on our definitions, has examined representation
independence for general nonmonotonic logics. He considers representation independence
with respect to a collection of transformations, and proves results about the degree to
which certain nonmonotonic formalisms, such as rational closure (Lehmann & Magidor,
1992), satisfy representation independence.
Another line of research that is relevant to representation independence is the work
on abstraction (Giunchiglia & Walsh, 1992; Nayak & Levy, 1995). Although the goal of
this work is again to make connections between two different ways of representing the same
situation, there are significant differences in focus. In the work on abstraction, the two ways
of representing the situation are not expected to be equivalent. Rather, one representation
typically abstracts away irrelevant details that are present in the other. On the other hand,
their treatment of the issues is in terms of deductive entailment, not in terms of general
inference procedures. It would be interesting to combine these two lines of work.
7.2 Bayesian Probabilistic Inference
Bayesian statistics takes a very different perspective on the issues we discuss in this paper.
As we discussed, the Bayesian approach generally assumes that we construct a prior, and use
standard probabilistic conditioning to update that prior as new information is obtained. In
this approach, the representation of the knowledge obtained has no effect on the conclusions.
Two pieces of information that are semantically equivalent (denote the same event) will have
precisely the same effect when used to condition a distribution.
In this paradigm, our analysis is more directly related to the step that precedes the
probabilistic conditioningthe selection of the prior. When we have very specific beliefs
that we want to encode in a prior distribution (as we do, for example, when constructing
a Bayesian network), we design our prior to reflect these beliefs in terms of the vocabulary
used. For example, if we have a particular distribution in mind over the location of an object,
we will encode it one way when representing the space in terms of Cartesian coordinates,
and in another way when using polar coordinates. In effect, we can view the representation
transformation as an embedding f , and the two priors as corresponding under f , in the
sense of Definition 4.2. Thus, the design of the prior already takes the representation into
account.
On the other hand, when we are trying to construct an uninformed prior for some class
of problems, the issue of representation independence becomes directly relevant. Indeed,
342

fiRepresentation Dependence

most of the standard problems with maximum entropy arise even in the simple case when
we simply do Bayesian conditioning starting with a uniform prior over our space.
A standard approach in Bayesian statistics is to use the invariance under certain transformations in order to define an appropriate uninformed prior. For example, we might
want a prior over images that is invariant to rotation and translation. In certain cases,
once we specify the transformation under which we want a measure to be invariant, the
measure is uniquely determined (Jaynes, 1968; Kass & Wasserman, 1993). In this case, the
argument goes, the uniquely determined measure is perforce the right one. This idea of
picking a prior using its invariance properties is in the same spirit as the approach we take
in Section 6. Indeed, as this approach simply uses standard probabilistic conditioning for
objective information (such as observations), the Bayesian approach with an uninformed
prior invariant to a set of embeddings is, in a sense, a special case. However, our approach
does not force us to choose a unique prior. Rather, we allow the use of a set of prior
distributions, allowing us to explore a wider spectrum of inference procedures.
This approach is also related to the work of Walley (1996), who observes that representation independence is an important desideratum in certain statistical applications involving
multinomial data. Walley proposes the use of sets of Dirichlet densities to encode ignorance
about a prior, and shows that this approach is representation independent in its domain of
application.

8. Conclusions
This paper takes a first step towards understanding the issue of representation dependence in probabilistic reasoning, by defining notions of invariance and representation independence, showing that representation independence is incompatible with drawing many
standard default conclusions, and defining limited notions of invariance that might that
allow a compromise between the desiderata of being able to draw interesting conclusions
(not already entailed by the evidence) and representation independence. Our focus here
has been on inference in probabilistic logic, but the notion of representation independence
is just as important in many other contexts. Our definitions can clearly be extended to
non-probabilistic logics. As we mentioned, Jaeger (1996) has obtained some results on representation independence in a more general setting, but there is clearly much more that can
be done. More generally, it would be of interest to understand better the tension between
representation independence and the strength of conclusions that can be drawn from an
inference procedure.

Acknowledgments
Thanks to Ed Perkins for pointing us to (Keisler & Tarski, 1964) and, in particular, the
result that a countably additive probability measure defined on a subalgebra of an algebra
F could not necessarily be extended to a countably additive probability measure on F.
Thanks to the reviewers of the paper for their perceptive comments and for pointing out
(Horn & Tarski, 1948). Much of Halperns work on the paper was done while he was at
the IBM Almaden Research Center. His recent work has been supported by NSF under
343

fiHalpern & Koller

grant IRI-96-25901 and IIS-0090145 and ONR under grant N00014-01-1-0795. Some of
Kollers work was done at U.C. Berkeley. Her research was sponsored in part by the Air
Force Office of Scientific Research (AFSC), under Contract F49620-91-C-0080, and by a
University of California Presidents Postdoctoral Fellowship. Daphne Kollers later work
on the paper was supported through the generosity of the Powell foundation, and by ONR
grant N00014-96-1-0718. A preliminary version of this appears in Proceedings of IJCAI 95,
pp. 18531860.

Appendix A. Proofs
A.1 Proofs for Section 2
Proposition 2.5: Let | be a relation on probabilistic constraints on X for which the
properties Reflexivity, Left Logical Equivalence, Right Weakening, Infinitary And, and Consistency hold for all KB in the domain of | . (That is, if KB is in the domain of | , in
that KB |  for some , then KB | KB , and so on.) Then | is |I for some X-inference
procedure I.
Proof: Define I as follows. If A  X , KB is in the domain of | , and A = [[KB ]]X
for some statement KB , then A is in the domain of I and I(A) = {[[]]X : KB | }.
Note that by Left Logical Equivalence, this is well defined, since if A = [[KB 0 ]]X , then
{[[]]X : KB | } = {[[]]X : KB 0 | }. If A 6= [[KB ]]X for some statement KB , then A is
not in the domain of I. It remains to check that I is an X-inference procedure (i.e., that
I(A)  A and that I(A) =  iff A =  for all A in the domain of I), and that | = |I .
To check that I is an X-inference procedure, suppose that A is in the domain of I. Thus,
A = [[KB ]]X By Reflexivity, it easily follows that I([[KB ]]X )  [[KB ]]X . Next suppose that
I([[KB ]]X ) = . It follows that {[[]]X : KB | } = . Thus, { : KB | } |= false. By
the Infinitary AND rule, we must have KB |I false. By the Consistency Rule, it follows
that [[KB ]]X = . Thus, I is indeed an X-inference procedure. Finally, note that if KB | 
then, by definition of I, I([[KB ]]X )  [[]]X , so KB |I . For the opposite inclusion, note
that if KB |I , then { : KB | } |= . Thus, by the Infinitary And rule, it follows that
KB | I .
A.2 Proofs for Section 3
To prove Theorem 3.4, we need the following lemma.
Lemma A.1: Given two spaces X0 and X1 , measures 0  (X0 ,FX0 ) and 1  (X1 ,FX1 ) ,
and subsets S0  FX0 and S1  FX1 such that 0 (S0 ) = 1 (S1 ), there exists a measure
2  (X0 X1 ,FX0 X1 ) such that 2Xi = i , for i = 1, 2, and 2 (S0  S1 ) = 1.10
Proof: For A  B  FX0  FX1 , define
2 (A  B) = (0 (A  S0 )1 (B  S1 )/1 (S1 )) + (0 (A  S0 )1 (B  S1 )/1 (S1 )),
where we take 0 (A  S0 )1 (B  S1 )/1 (S1 ) = 0 if 1 (S1 ) = 0 and take 0 (A  S0 )1 (B 
S1 )/1 (S1 ) = 0 if 1 (S1 ) = 0. Extend to disjoint unions of such sets by additivity. Since
10. If A and B are sets, we use the notation A  B to denote the set (A  B)  (A  B).

344

fiRepresentation Dependence

all sets in FX0 X1 can be written as disjoint unions of sets of the form A  B  FX0  FX1 ,
this suffices to define 2 . To see that 2 is actually a measure, note that 2 (X  Y ) =
0 (S0 ) + 0 (S0 ) = 1. Additivity is clearly enforced by the definition. Finally, to see that
2 has the desired properties, suppose that 1 (S1 ) 6= 0 and 1 (S1 ) 6= 0. (The argument is
easier if this is not the case; we leave details to the reader.) Then
2X0 (A) = 2 (A  Y ) = 0 (A  S0 )1 (S1 )/1 (S1 ) + 0 (A  S0 1 (S1 )/1 (S1 )
= 0 (A  S0 ) + 0 (A  S0 ) = 0 (A).
Since 0 (S0 ) = 1 (S1 ) by assumption (and so 0 (S0 ) = 1 (S1 )),
2X1 (B) = 2 (X  B) = 0 (S0 )1 (B  S1 )/1 (S1 ) + 0 (S0 )1 (B  S1 )/1 S1 )
= 1 (B  S1 ) + 1 (B  S1 ) = 1 (B).
This completes the proof.
Theorem 3.4: If {IX : X  X } is a robust X -inference procedure that satisfies DI1, DI2,
and DI3, then IX is essentially entailment for all X  X .
Proof: Suppose that {IX : X  X } is robust and IX is not essentially entailment for X  X .
Then there must be a constraint KB on X and a set S  FX such that KB |I  < Pr(S) <
 and KB 6|=   Pr(S)  . Thus, there must be some  
/ [, ] such that KB Pr(S) = 
is consistent. We can assume without loss of generality that  <  (otherwise we can replace
S by S).
We first construct a space Y0  X that has subsets U1 , . . . , Un with the following properties:
(a) There is no measure   Y0 such that (Ui ) > , for all i = 1, ..., n.
(b) For each i, there is some measure 0i  Y0 such that 0i (Ui ) = 1 and 0i (Uj ) >  for
all j 6= i.
We proceed as follows. Choose n and d such that  < (d  1)/(n  1) < d/n < . By
assumption, there exists a Y0  X such that |Y0 | = n!/(n  d)!. Without loss of generality,
we can assume that Y0 consists of all tuples of the form (a1 , . . . , ad ), where the ai s are all
distinct, and between 1 and n. Let Ui be consist of all the tuples in Y0 that have i somewhere
in the subscript; it is easy to see that there are d(n  1)!/(n  d)! such tuples. Suppose that
 is a probability measure in Y0 . It is easy to see that (U1 ) +    + (Un ) = d, since each
tuple in Y0 is in exactly d of the Ui s and so gets counted exactly d times, and the sum of the
probabilities of the tuples is 1. Thus, we cannot have (Ui ) > d/n for all i (and, a fortiori,
we cannot have (Ui ) >  for all i). This takes care of the first requirement. Next, consider
a probability distribution 0i that makes all the tuples making up Ui equally probable, and
gives all the other tuples probability 0. Then it is easy to see that 0i (Ui ) = 1. Moreover,
since it is straightforward to check that there are exactly d(d  1)(n  2)!/(n  d)! tuples
in Ui  Uj for j 6= i, we have 0i (Uj ) = [d(d  1)(n  2)!/(n  d)!]/[d(n  1)!/(n  d)!] =
(d  1)/(n  1). This takes care of the second requirement.
By assumption, there is also a measurable space Y  X such that |Y | = 2. Suppose
that Y = {y, y 0 }. Let Z = X n  Y0  Y n , where the n is the same as the n chosen in the
construction of Y0 . Again, by assumption, Z  X . For i = 1, . . . , n,
345

fiHalpern & Koller

 if A  X, let Ai = X i1  A  X ni  Y0  Y n  Z.
 let KB i = {  Z : Xi  KB };
 let Yi be the subset of Y n where the ith copy of Y is replaced by {y};
 let Vi be the subset of Z of the form X n  Ui  Yi (where U1 , . . . , Un are the subsets
of Yi constructed above).
Let  be the following constraint on Z :
KB 1  . . .  KB n  Pr(S1  V1 ) = 1  . . .  Pr(Sn  Vn ) = 1.
Let Xi denote the ith copy of X in Z. That is, for ease of exposition, we view Z as
being of the form X1      Xn  Y0  Y m , although all the Xi s are identical, since it is
helpful to be able to refer to a specific Xi . We claim that  is Xi -conservative over KB ,
for i = 1, . . . , n. Thus, we must show that proj Xi ([[KB i  ]]Z ) = [[KB ]]X . It is immediate
that proj Xi ([[KB i  ]]Z )  [[KB ]]X . For the opposite inclusion, suppose that   [[KB ]]X .
We must show that there exists some   [[KB i  ]]Z such that Xi = . We proceed as
follows.
Let 00 be a measure in Y0 such that 00 (Ui ) = 1 and 00 (Uj ) > , for j 6= i. By
construction of the Uj s, such a measure must exist. For j  {1, . . . , n}, let 0j be the measure
in Y such that 0i (y) = (S) and if j 6= i, then 0j (y) = /00 (Uj ) (and 0j (y 0 ) = 1  0j (y)).
Let 0 be the measure on Y0  Y n that is the crossproduct of 00 , 01 , . . . , 0n . That is,
0 (T0      Tn ) = 00 (T0 )      0n (Tn ). By construction, 0 (Vj ) =  for j 6= i and
0 (Vi ) = (S).
By assumption, there is a measure 0  X such that 0 |= KB  Pr(S) = . We
now proceed inductively to define a measure k  X k Y0 Y n such that (a) Pr((S1 
V1 )  . . .  (Sk  Vk )) = 1, (b) jY = 0 and jXj =  for j = 1, . . . , k. We define 0 = 0 .
For the inductive step, we simply apply Lemma A.1. Finally, we take  to be n . Our
construction guarantees that X j = , hence that  |= KB j . In addition, the construction
guarantees that  |= Pr(S1  V1 ) = 1  . . .  Pr(Sn  Vn ) = 1. Hence  |= , as desired.
It follows from DI1, DI2, and DI3 that  is in the domain of IZ . Since KB i   is
equivalent to , it follows that KB i   is also in the domain of IZ . Now, by robustness, for
any constraint  on Xi , we have KB i  |I  iff KB i |I . Since KB i |I Pr(Si ) >  and
KB i   is equivalent to , it follows that  |I Pr(Si ) >  for i = 1, . . . , n. By the And rule
(Proposition 2.3), it follows that  |I Pr(S1 ) >   . . .  Pr(Sn ) > . Since  |= Pr((S1 
V1 )  (Sn  Vn )) = 1, it easily follows that  |I Pr(U1 ) >   . . .  Pr(Un ) > . But our
construction guarantees that Pr(U1 ) > . . .Pr(Un ) >  is inconsistent. Thus,  |I false.
By robustness, it follows that KB i |I false. But this can happen only if KB |= false, which
implies that KB |=   Pr(S)  , contradicting our original assumption.
A.3 Proofs for Section 4
To prove Lemma 4.6, it is useful to first prove two additional results:
Lemma A.2: If f is an X-Y embedding, then f (X) = Y and f () = .
346

fiRepresentation Dependence

Proof: Suppose that f is an X-Y embedding. We first show that f () = . From the
definition of embedding, it follows that f () = f (X  ) = f (X)  f (). Thus, f ()  f (X).
But the definition of embedding also implies that f () = f (X) = f (X). Thus, we have
f (X)  f (X). This can happen only if f (X) = Y and f () = f (X) = .

Lemma A.3: If f is a faithful X-Y embedding, then
(a) for any   X , there is a measure   Y such that  corresponds to ;
(b) for any   Y , there is a measure   X such that  corresponds to .
Proof: To prove (a), consider the algebra of subsets of Y the form f (S), for S  FX .
Define a function  0 on the algebra via  0 (f (S)) = (S). This mapping is well defined,
for if f (S) = f (T ), then faithfulness guarantees that S = T . Moreover,  0 is a probability
measure on the algebra. To see this, note by Lemma A.2 that  0 (Y ) =  0 (f (X)) = (X) = 1.
Moreover, if f (S)  f (T ) = , then (by definition of embedding) f (S  T ) =  and so, since
f is faithful, S  T =  (for otherwise f (S  T ) = f () by Lemma A.2, but S  T 6= ).
Thus,
 0 (f (S)  f (T )) =  0 (f (S  T )) = (S  T ) = (S) + (T ) =  0 (f (S)) +  0 (f (T )).
As shown by Horn and Tarski (1948), it is possible to extend  0 to a probability measure 
on FY .11 By construction, we have that  corresponds to .
To prove (b), we use a very similar process. Define a function  on the algebra of sets
S  X via (S) = (f (S)). It is easy to see that  is already a probability measure in X ,
which by construction corresponds to .
We can now prove Lemma 4.6.
Lemma 4.6: An X-Y embedding f is faithful if and only if for all constraints KB and ,
we have KB |=  iff f  (KB ) |= f  ().
Proof: Suppose that f is faithful. To show that KB |=  iff f  (KB ) |= f  (), we must
show that [[KB ]]X  [[]]X iff [[f  (KB )]]Y  [[f  (]]Y . The only if direction is immediate
from the definition of f  . To prove the if direction, suppose not. Then there must exist
some   [[KB ]]X  [[]]X such that f  ()  [[f  ()]]Y . Let  be some probability measure
that corresponds to . Since   f  ()  f  (), there must be some 0  [[]]X such that
  f  (0 ). Since 0 6= , there must be some S  FX such that 0 (S) 6= (S). Since
  f  ()  f  (0 ), we must have both (f (S)) = (S) and (f (S)) = 0 (S). But this is a
contradiction. This completes the proof of the if direction.
For the converse, suppose we have KB |=  iff f  (KB ) |= f  () for all KB and . Given
S, T  FX , we have the following chain of equivalences:
11. It is critical for this result that we are working with finitely additive measures. There may not be a
countably additive measure  extending  0 , even if  0 is countably additive. For example, take FY0 to be
the Borel sets on [0, 1] and take FY to be all subsets of [0, 1]. Let  0 be Lebesgue measure. It is known
that, under the continuum hypothesis, there is no countably additive measure extending  0 defined on
all subsets of [0, 1] (Ulam, 1930) (see (Keisler & Tarski, 1964) for further discussion).

347

fiHalpern & Koller

ST
iff Pr(S) = 1 |= Pr(T ) = 1
iff f  (Pr(S) = 1) |= f  (Pr(T ) = 1) (by assumption)
iff Pr(f (S)) = 1 |= Pr(f (T )) = 1 (by definition of f  )
iff f (S)  f (T ).
Thus, f is faithful.
Proposition 4.7: Let f be a faithful X-Y embedding. Then the following statements are
equivalent:
(a)  and  correspond under f ;
(b) for all formulas ,  |=  iff  |= f  ().
Proof: We first show that (a) implies (b). So suppose that  and  correspond under f .
The only if direction of (b) is trivial: If  |=  then   f  ()  f  (), since f is faithful.
For the if direction, we proceed much as in the proof of Lemma 4.6. Assume that  |= f  ()
but that  6|= . Since   f  (), by definition of f  there must be some 0  [[]]X such that
  f  (0 ). Since 0 |=  whereas  6|= , we must have  6= 0 . Hence, there must be some
S  FX such that (S) 6= 0 (S). Since   f  ()  f  (0 ), it follows that (f (S)) = (S)
and that (f (S)) = 0 (S), which gives the desired contradiction.
We now show that (b) implies (a). Assume by contradiction that  and  do not
correspond under f . Then there must be some event S  FX such that (S) 6= (f (S)).
Let p = (S) and let  be the constraint Pr(S) = p. Then  |= , whereas  6|= f  (),
providing the desired contradiction.
Theorem 4.10: If an X -inference procedure is robust that satisfies DI2, DI4, and DI5,
then it is representation independent.
Proof: Suppose that {IX : X  X } is a robust X -inference procedure. We want to show
that it is representation independent. So suppose KB ,  are constraints on X and f is an
X-Y embedding, for some X, Y  X . We want to show that KB |IX  iff f  (KB ) |IY f  ().
Let  be the following constraint on XY :
(  f  ())  (KB  f  (KB )).
We claim that  is X-conservative over KB and Y -conservative over f  (KB ). Thus, we must
show that proj X ([[KB  ]]XY ) = [[KB ]]X and proj Y ([[f  (KB )  ]]XY ) = [[f  (KB )]]Y .
We show that proj X ([[KB  ]]XY ) = [[KB ]]X here; the argument that proj Y ([[f  (KB ) 
]]XY ) = [[f  (KB )]]Y is almost identical.
Clearly if   [[KB  ]]XY then X  [[KB ]]X , so proj X ([[KB  ]]XY )  [[KB ]]X .
For the opposite inclusion, suppose that   [[KB ]]X . We want to find a measure  0 
0 = . Let  00 be any measure in f  () and let  0  
[[KB  ]]XY ) such that X
XY
0 = . To
be the crossproduct of  and  00 ; that is,  0 (A  B) = (A) 00 (B). Clearly X
see that  0  [[KB  ]]XY ), it clearly suffices to show that  0 |= . But since  and  00
correspond under f , it is immediate from Proposition 4.7 that  |= KB iff  00 |= f  (KB )
and  |=  iff  00 |= f  (). Thus,  |= , as desired.
348

fiRepresentation Dependence

Now suppose that KB |IX . By DI2 and DI5, KB   is in the domain of IXY . By
robustness, KB   |IXY . Thus, I([[KB  ]]XY )  [[]]XY . Since I([[KB  ]]XY ) 
[[KB  ]]XY  [[  f  ()]]XY , it follows that I([[KB  ]]XY )  [[f  ()]]XY .
Moreover, KB   is equivalent to f  (KB )  , so I([[f  (KB )  ]]XY )  [[f  ()]]XY ,
i.e., f  (KB )   |IXY f  (). By DI4, f  (KB ) is in the domain of IY . Since  is Y conservative over f  (KB ), the robustness of {IX : X  X } implies that f  (KB ) |IY f  ().
The opposite implication (if f  (KB ) |IY f  () then KB |IX ) goes the same way. Thus,
{IX : X  X } is representation independent.
Next, we turn our attention to Theorems 4.11 and 4.16. Both of these results follow in
a relatively straightforward way from one key proposition. Before we state it, we need some
definitions.
Definition A.4: We say that a constraint KB on X depends only on S1 , . . . , Sk  FX
(the sets S1 , . . . , Sk are not necessarily disjoint) if, whenever , 0  X agree on S1 , . . . , Sk ,
then  |= KB iff 0 |= KB .
For example, if KB has the form Pr(S1 ) > 1/3  Pr(S2 )  3/4, then KB depends only
on S1 and S2 . Similarly, if KB has the form Pr(S1 | S2 ) > 3/4, then KB depends only on
S1 and S2 .
Definition A.5: Given S1 , . . . , Sk  FX , an atom over S1 , . . . , Sk is a set of the form
T1  . . .  Tk , where Ti is either Si or Si .
Proposition A.6: Suppose that {IX : X  X } is an X -inference procedure and, for some
X  X , there exist S, S1 , . . . , SK  FX and a consistent constraint KB on X that depends
only on S1 , . . . , Sk , such that the following two conditions are satisfied:
 both T  S and T  S are nonempty for every nonempty atom T over S1 , . . . , Sk ,
 KB |IX  < Pr(S) < , where either  > 0 or  < 1.
Then {IX : X  X } is not representation independent.
Proof: Suppose, by way of contradiction, that {IX : X  X } is a representation-independent
inference procedure but nevertheless, for some X  X , there exists sets S, S1 , . . . , Sk  FX
and a knowledge base KB that satisfies the conditions above, for some , . Assume that
 > 0 (a similar argument can be used to deal with the case that  < 1).
Let T1 , . . . , TM be the nonempty atoms over S1 , . . . , Sk . Choose N such that 1/N < .
Our goal is to find a collection f1 , . . . , fN of embeddings of X into some Y  X such that
each of these embeddings has the same effect on KB , but such that the sets fj (S) are disjoint.
Since KB |IX Pr(fj (S)) >  for j = 1, . . . , N , and fj (KB ) = f  (KB ) for j = 1, . . . , N , it
will follow that f  (KB ) |IY Pr(fj (S)) >  for j = 1, . . . , N , a contradiction. We proceed
as follows.
By assumption, there exists a set Z in X such that |Z| = M N . Let Y = X  Z.
Since X is closed under crossproducts, Y  X . Suppose that Z = {z1 , . . . , zM N }, and let
Zi = {zN (i1)+1 , . . . , zN i }, for i = 1, . . . , M . Thus, the Zi s partition Z into M disjoint sets,
each of cardinality N . Let Bi = X  Zi , and let Bij = X  {zN (i1)+j }, for j = 1, . . . , N .
It is easy to see that we can find faithful X-Y embeddings f1 , . . . , fN such that
349

fiHalpern & Koller

1. fj (Ti ) = Bi , for i = 1, . . . , M , j = 1, . . . , N ,
2. fj (Ti  S) = Bij , for i = 1, . . . , M , j = 1, . . . , N .
Notice that we need the assumption that both Ti S and Ti S are nonempty for T1 , . . . , TM
(that is, for each nonempty atom over S1 , . . . , Sk ) to guarantee that we can find such faithful
embeddings. For if Ti  S = , then since fj is an embedding, f (Ti  S) =  6= Bi ; and if
Ti  S = , then fj (Ti  S) = fj (Ti )  f (Ti  S)) = , which means that Bi = Bij , again
inconsistent with the construction.
It is easy to check that, since KB depends only on S1 , . . . , Sk , fj (KB ) depends only
on fj (S1 ), . . . , fj (Sk ), for j = 1, . . . , N . We next show that fj (Si ) is independent of j;
that is, fj (Si ) = fj 0 (Si ) for 1  j, j 0  N . Notice that for h = 1, . . . , k, we have that
fj (Sh ) = Ti Sh fj (Ti ) = {i:Ti Sh } Bi . Thus, fj (Sh ) is independent of j, as desired. Since
fj (KB ) depends only on fj (S1 ), . . . , fj (Sk ), it too must be independent of j. Let KB  be
f1 (KB ) (which, as we have just observed, is identical to f2 (KB ), . . . , fk (KB )).
Since, by assumption, {IX : X  X } is representation independent, and KB |IX P r(S) >
, we have that KB  |IY Pr(fj (S)) > , for j = 1, . . . , N . Thus, KB  |IY Pr(f1 (S)) >
  . . .  Pr(fN (S)) > . But note that, by construction, fj (S) = {i:Ti S6=} Bij . Thus, the
sets fj (S) are pairwise disjoint. Since  > 1/N , we cannot have N disjoint sets each with
probability greater than . Thus, KB  |IY false. But KB is consistent, so KB  = fj (KB )
must be as well. Thus, IY (KB  ) 6= , by assumption. But this contradicts our conclusion
that KB  |IY false. Thus, {IX : X  X } cannot be representation independent.
We can use Proposition A.6 to help prove Theorem 4.11.
Theorem 4.11: If {IX : X  X } is a representation-independent X -inference procedure
then, for all X  X , IX is essentially entailment for all objective knowledge bases in its
domain.
Proof: Suppose, by way of contradiction, that {IX : X  X } is representation independent
but IX is not essentially entailment for some X  X and objective knowledge base KB .
Then there must be some set S  FX such that KB |IX  < Pr(S) <  and KB 6|=  
Pr(S)  . Without loss of generality, we can assume that KB has the form Pr(T ) = 1 for
some T  FX . Moreover, we can assume that if T 6= , then T has a nonempty, measurable
strict subset. (For otherwise, choose Y = {y, y 0 }  X and consider the space X 0 = X  Y .
By assumption, X 0  X . Let f be the X-Y embedding that maps U  FX to U  Y . Since
I is representation independent, we have that Pr(T  Y ) = 1 |I  < Pr(S  Y ) < , and
T  {y}  T  Y .)
If T is nonempty, let Z be any nonempty, measurable strict subset of T (which exists by
assumption); otherwise let Z be the empty set. Let U be the set (T  S)  (T  Z). Notice
that S T = U T . Moreover, since, for any set V , Pr(T ) = 1  Pr(V ) = Pr(V T ) is valid,
it follows from Reflexivity and Right Weakening that KB |IX Pr(V ) = Pr(V  T ). Thus,
KB |IX Pr(S) = Pr(S  T ) = Pr(U  T ) = Pr(U ). It follows that KB |IX  < Pr(U ) < .
We now want to apply Proposition A.6. Note that KB depends only on T . Thus, we
must show that T  U and T  U are nonempty, and if T is nonempty, then T  U and
T  U are as well. As we observed above, T  U = T  S. Thus, if T  U = , then T  S,
contradicting our assumption that KB |I Pr(S) > 0. It is easy to see that T  U = T  S.
Again, we cannot have T  U = , for then T  S, contradicting our assumption that
350

fiRepresentation Dependence

KB |I Pr(S) < 1. By construction, T  U = T  Z = Z. By assumption, if T 6= , then
Z 6= . Finally, T  U = T  Z; again, by construction, this is a nonempty set if T 6= . It
now follows from Proposition A.6 that {IX : X  X } is not representation independent.
Corollary 4.12: If {IX : X  X } is a representation-independent X -inference procedure,
then for all X  X , if KB is an objective knowledge base putting constraints on X , and
KB |IX  < Pr(S) <  for some   0 and   1, then  = 0 and  = 1.
Proof: Assume the hypotheses of the corollary hold. Since KB is objective, it is of the
form Pr(T ) = 1 for some T  FX . Then there are three possibilities. Either (1) T  S, (2)
T  S, or (3) both T  S and T  S are nonempty. If (1) holds, we have KB |= Pr(S) = 1,
while if (2) holds, we have KB |= Pr(S) = 0. Thus, both (1) and (2) are incompatible
with KB |IX  < Pr(S) < . On the other hand, if (3) holds, it is easy to see that for
all , Pr(S) =  is consistent with KB (since there is a probability measure that assigns
probability  to T  S and probability 1   to T  S). Since KB |IX  < Pr(S) < , by
Theorem 4.11, we must have KB |=   Pr(S)  . It follows that the only choices of 
and  for which this can be true are  = 0 and  = 1.
Theorem 4.16: If {IX : X  X } is an X -inference procedure that enforces minimal
default independence and satisfies DI1, then IX is not representation independent.
Proof: Suppose that {IX : X  X } is an X -inference procedure that enforces minimal
default independence and satisfies DI1. Choose X = {x, x0 }  X and let KB be 1/3 
Pr(x)  2/3. By assumption, X  X  X . We can view KB as a constraint on XX ;
in this case, it should be interpreted as 1/3  Pr({x}  X)  2/3. by DI1, KB is is the
domain of IXX . Note that KB is equivalent to the constraint 1/3  Pr(x0 )  2/3. By
minimal default independence, we have that KB |IXX Pr((x, x)) > Pr(x  X)/3 and that
KB |IXX Pr((x0 , x0 )) > Pr(x0  X)/3. Applying straightforward probabilistic reasoning,
we get that KB |IXX Pr({(x, x), (x0 , x0 )}) > 1/3. We now apply Proposition A.6, taking
S to be {(x, x), (x0 , x0 )} and S 0 to be {(x, x), (x, x0 )}. Note that KB depends only on S 0 .
It is almost immediate from the definition of S and S 0 that all of S  S 0 , S  S 0 , S  S 0 ,
and S  S 0 are nonempty. Thus, by Proposition A.6, {IX : X  X } is not representation
independent.
0 : X  X } is a representationLemma 4.13: Let X consist of only countable sets. Then {IX
independent X -inference procedure.

Proof: As we said in the main part of the text, it easily follows from Proposition 2.5 that
0 is an inference procedure for all X  X , since it is easily seen to have the five propIX
erties described in the proposition. To see that I 0 is representation independent, suppose
that f is a faithful X-Y embedding, for X, Y  X . Clearly KB is objective if and only
if f  (KB ) is objective. If KB is not objective, then it is easy to see that KB |I 0  iff
f  (KB ) |I 0 f  (), since |I 0 reduces to entailment in this case. So suppose that KB is objective and has the form Pr(T ) = 1, for some T  FX . Then KB |I 0  iff KB KB + |= . By
Lemma 4.6, this holds iff f  (KB )f  (KB + ) |= f  (). On the other hand, f  (KB ) |I 0 f  ()
iff f  (KB )  (f  (KB ))+ |= f  () Thus, it suffices to show that f  (KB )  f  (KB + ) |= f  ()
iff f  (KB )  (f  (KB ))+ |= f  (). It is easy to show that (f  (KB ))+ implies f  (KB + ), so
that if f  (KB )  f  (KB + ) |= f  () then f  (KB )  (f  (KB ))+ |= f  (). It is not necessarily
351

fiHalpern & Koller

the case that f  (KB + ) implies (f  (KB ))+ . For example, consider the embedding described
in Example 4.3. In that case, if KB is the objective knowledge base Pr(colorful ) = 1,
KB + is empty, and hence so is f  (KB + ), while (f  (KB ))+ includes constraints such as
0 < Pr(green) < 1. Nevertheless, suppose that f  (KB )  (f  (KB ))+ |= f  () and, by way
of contradiction, there is some  such that  |= f  (KB )  f  (KB + )  f  (). Choose 
such that   f  (). Then  and  correspond, so  |= KB  KB +  . It is easy to
show that there exists  0  f  () such that 0 <  0 (S) < 1 for all nonempty subsets of S of
f (T ). To see this, note that if (x) 6= 0, then it suffices to ensure that  0 (f (x)) = (x) and
 0 (y) 6= 0 for all y in f (x). Since Y is countable, this is straightforward. Since  and  0
correspond, we must have that  0 |= f  ()  f  (KB ). By construction,  0 |= (f  (KB ))+ .
This contradicts the assumption that f  (KB )  (f  (KB ))+ |= f  ().
Lemma 4.14: Suppose that X consists only of measure spaces of the form (X, 2X ), where
1 : X  X } is a representation-independent X -inference procedure.
X is finite. Then {IX
Proof: Suppose that X, Y  X , KB and  are constraints on X , and f is an X-Y
embedding. We must show that KB |I 1  iff f  (KB ) |I 1 f  (). For the purposes of this
X
Y
proof, we say that a subset A of X is interesting if there exists some S  FX such that
A = {  X : (S)  1/4}. It is easy to see that if KB is interesting then f  (KB ) is
interesting. The converse is also true, given our assumption that X consists of only finite
spaces where all sets are measurable. For suppose that f  (KB ) is interesting. Then there is
a set T  Y such that f  (KB ) = {  Y : (T )  1/4}. Let A = {S 0  X : f (S 0 )  T }.
Since X is finite, so is A; it easily follows that S = A  A.12 Clearly if (S)  1/4, then
f  ()  f  (KB ), so   [[KB ]]X . Thus, [[KB ]]X  {  X : (S)  1/4}. On the other
hand, if   KB , then f  ()  f  (KB ). Thus, if   f  (), since S  A, it must be the
case that (S) = (f (S))  (T )  1/4. Thus, [[KB ]]X  {  X : (S)  1/4}. It
follows that KB is equivalent to Pr(S)  1/4, and so must be interesting. (We must also
have T = f (S), although this is not needed for the result.)
If KB is not interesting, then KB |I 1  iff KB |=  iff f  (KB ) |= f  () (since entailment
X
is representation independent) iff f  (KB ) |I 1 . On the other hand, if KB is interesting,
Y
then KB is equivalent to Pr(S)  1/4 for some S  X, and f  (KB ) is equivalent to
Pr(f (S))  1/4. Moreover, KB |I 1  iff Pr(S)  1/3 |=  iff Pr(f (S))  1/3 |= f  () iff
X
f  (KB ) |I 1 . Thus, we get representation independence, as desired.
Y

A.4 Proofs for Section 6
Proposition 6.3: Suppose that f is a faithful X-Y embedding, DX  X , and DY  Y .
The following two conditions are equivalent:
(a) DX and DY correspond under f ;
(b) for all , DX |=  iff DY |= f  ().
12. This is not in general true if X is infinite without the additional requirement that f (i Ai ) = i f (Ai )
for arbitrary unions.

352

fiRepresentation Dependence

Proof: To prove that (a) implies (b), assume by way of contradiction that, for some ,
DX |=  but DY 6|= f  (). Then there is some   DY such that  6|= f  (). Let   DX be
a measure corresponding to . Then, by Proposition 4.7, we have that  6|= , the desired
contradiction. The proof for the other direction of (a) is identical.
To prove that (b) implies (a), first consider a measure   DX . We must find a   DY
such that  corresponds to . Suppose that X = {x1 , . . . , xn } (recall that we are restricting
to finite spaces in Section 6) and that (xi ) = ai , i = 1, . . . , n. Let  be the constraint
ni=1 Pr({xi }) = ai . By our assumptions about the language, this constraint is in the
language. Clearly [[]]X = {}. Since   DX , we know that DX 6|= . Hence, DY 6|=
f  (), so that there exists   DY such that  6 f  (). Hence   f  () = f  ({}). By
definition of f  ,  corresponds to .
Now consider a measure   DY , and let  be the measure in X that corresponds
to . Assume by way of contradiction that  6 DX . Taking  as above, it follows that
DX |=  and, therefore, by assumption, DY |= f  (). Thus,  |= f  (). But  |=  and,
by assumption,  and  correspond. This contradicts Proposition 4.7.
Theorem 6.7: Let  be an arbitrary constraint on X . If f is a faithful X-Y embedding
and  and  correspond under f , then | and |f  () also correspond under f .
Proof: Assume that  and  correspond under f . Recall that we are assuming in this section
that X is a finite space; let X = {x1 , . . . , xn }. Let Yi = f (xi ). Given any distribution
 00  Y , define i00 =  00 |Yi and let (f  )1 ( 00 ) denote the unique 00  X such that
 00  f  (00 ).
Now suppose that 0  |. Define  0  Y to be the measure such that
 0 (y) = 0 (xi )  i (y),
where i is the index such that y  Yi . Since i = |Yi , it follows that i (Yi ) = 1. Thus,
 0 (Yi ) = (xi ), and  0 leaves the relative probabilities of elements within each Yi the same
as in . It is easy to verify that  0 and 0 correspond. Hence, by Proposition 4.7,  0 |= f  ().
We claim that  0  |f  (). To show that, we need show only that KLY ( 0 k) is minimal
among all KLY ( 00 k) such that  00 |= f  (). It follows from standard properties of relative
entropy (Cover & Thomas, 1991, Theorem 2.5.3) that for all  00  Y , we have
KLY ( 00 k) = KLX ((f  )1 ( 00 )k(f  )1 ()) +

n
X

KLY (i00 ki ).

(1)

i=1

Note that i = i0 , so KLY (i0 ki ) = 0, for i = 1, . . . , n. Thus, it follows from (1) that
KLY ( 0 k) = KLX (0 k).
Now, let  00  Y be such that  00 |= f  () and let 00 = (f  )1 (00 ). Since  00 and 00
correspond under f , it follows from Proposition 4.7 that 00 |= . Using (1) once again, we
have that
KLY ( 00 k) = KLX (00 k) +

n
X
i=1

 KLX (00 k).
353

KLY (i00 ki )

fiHalpern & Koller

But since 0  |, we know that KLX (0 k)  KLX (00 k). Hence we conclude that
KLY ( 00 k)  KLY ( 0 k),
so that  0  |f  ().
Theorem 6.9: If f is a faithful X-Y embedding, then I P is invariant under f iff P(X)
and P(Y ) correspond under f .
Proof: Suppose that f is a faithful X-Y embedding. By definition, I P is invariant under
f iff, for all KB , , we have
KB | I P  iff f  (KB ) | I P f  ().

(2)

By definition of I P , (2) holds iff
P(X)|KB  [[]]X iff P(Y )|f  (KB )  [[f  ()]]Y for all KB , .

(3)

By Proposition 6.3, (3) holds iff P(X)|KB and P(Y )|f  (KB ) correspond for all KB . By
Corollary 6.5, if P(X) and P(Y ) correspond, then P(X)|KB and P(Y )|f  (KB ) correspond
for all KB . On the other hand, if P(X)|KB and P(Y )|f  (KB ) correspond for all KB , then
P(X) and P(Y ) must correspond: simply take KB = true and observe that P(X)|KB ) =
P(X) and P(Y )|f  (KB ) = P(Y ).
Proposition 6.10: Suppose that X1      Xn is the product decomposition on X and,
for each i = 1, . . . , n, KB i is a constraint on Xi , and Si is a subset of Xi . Then
n
^
i=1

KB i |IP Pr(S1  . . .  Sn ) =


n
Y

Pr(Si ).

i=1

Proof: If KB i is a satisfiable constraint on Xi , for i = 1, . . . , n, then there exist product
V
measures on X satisfying the constraints ni=1 KB i . These product measures are precisely
Vn
the measures in P |( i=1 KB i ). Since each of these measures satisfies Pr(S1  . . .  Sn ) =
Qn
i=1 Pr(Si ) by assumption, the conclusion holds in this case. If any constraint KB i is not
satisfiable, then the result trivially holds.
Theorem 6.11: The inference procedure IP is invariant under faithful product embeddings and under permutation embeddings.
Proof: Suppose that f is a faithful X-Y product embedding, X1      Xn is the product
decomposition of X, and Y1      Yn is the product decomposition of Y . To show that
P is invariant under f , it suffices to show that P (X) and P (Y ) correspond under f .
Supposethat   P (Y ). Then  = 1      n , where i is a measure on Xi , i = 1, . . . , n.
Moreover, since f is a product embedding, there exist f1 , . . . , fn such that f = f1      fn .
Let i  fi (i ), for i = 1, . . . , n. It is easy to check that  = 1      n  f  ().
Conversely, suppose that   P (Y ). Then  = 1      n , where i  Yi for
i = 1, . . . , n. Define   Xi by setting i (S) = i (fi (S)). Since fi is a faithful Xi -Yi
354

fiRepresentation Dependence

embedding, is easy to check that i  Xi and that i  fi (i ). Thus,   f  (). This
completes the proof that P is invariant under faithful X-Y product embeddings.
The argument that P is invariant under faithful X-X permutation embeddings is
similar (and easier). We leave details to the reader.

References
Bacchus, F. (1990). Representing and Reasoning with Probabilistic Knowledge. MIT Press,
Cambridge, Mass.
Bacchus, F., Grove, A. J., Halpern, J. Y., & Koller, D. (1996). From statistical knowledge
bases to degrees of belief. Artificial Intelligence, 87 (12), 75143.
Cover, T. M., & Thomas, J. A. (1991). Elements of Information Theory. Wiley, New York.
Enderton, H. B. (1972). A Mathematical Introduction to Logic. Academic Press, New York.
Giunchiglia, F., & Walsh, T. (1992). A theory of abstraction. Artificial Intelligence, 56 (23),
323390.
Goldszmidt, M., Morris, P., & Pearl, J. (1993). A maximum entropy approach to nonmonotonic reasoning. IEEE Transactions of Pattern Analysis and Machine Intelligence,
15 (3), 220232.
Halpern, J. Y., & Koller, D. (1995). Representation dependence in probabilistic inference.
In Proc. Fourteenth International Joint Conference on Artificial Intelligence (IJCAI
95), pp. 18531860.
Horn, A., & Tarski, A. (1948). Measures in Boolean algebras. Transactions of the AMS,
64 (1), 467497.
Jaeger, M. (1996). Representation independence of nonmonotonic inference relations. In
Principles of Knowledge Representation and Reasoning: Proc. Fifth International
Conference (KR 96), pp. 461472.
Jaynes, E. T. (1968). Prior probabilities. IEEE Transactions on Systems Science and
Cybernetics, SSC-4, 227241.
Jaynes, E. T. (1978). Where do we stand on maximum entropy?. In Levine, R. D., & Tribus,
M. (Eds.), The Maximum Entropy Formalism, pp. 15118. MIT Press, Cambridge,
Mass.
Kahneman, D., Slovic, P., & Tversky, A. (Eds.). (1982). Judgment Under Uncertainty:
Heuristics and Biases. Cambridge University Press, Cambridge/New York.
Kass, R. E., & Wasserman, L. (1993). Formal rules for selecting prior distributions: A review
and annotated bibliography. Tech. rep. Technical Report #583, Dept. of Statistics,
Carnegie Mellon University.
355

fiHalpern & Koller

Keisler, J., & Tarski, A. (1964). From accessible to inaccessible cardinals. Fundamenta
Mathematica, 53, 225308.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models and cumulative logics. Artificial Intelligence, 44, 167207.
Kullback, S., & Leibler, R. A. (1951). On information and sufficiency. Annals of Mathematical Statistics, 22, 7686.
Lehmann, D., & Magidor, M. (1992). What does a conditional knowledge base entail?.
Artificial Intelligence, 55, 160.
Nayak, P. P., & Levy, A. Y. (1995). A semantic theory of abstractions. In Proc. Fourteenth
International Joint Conference on Artificial Intelligence (IJCAI 95), pp. 196203.
Paris, J. B. (1994). The Uncertain Reasoners Companion. Cambridge University Press,
Cambridge, U.K.
Paris, J., & Vencovska, A. (1990). A note on the inevitability of maximum entropy. International Journal of Approximate Reasoning, 4 (3), 183224.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, San
Francisco.
Salmon, W. (1961). Vindication of induction. In Feigl, H., & Maxwell, G. (Eds.), Current
Issues in the Philosophy of Science, pp. 245264. Holt, Rinehart, and Winston, New
York.
Salmon, W. (1963). On vindicating induction. In Kyburg, H. E., & Nagel, E. (Eds.),
Induction: Some Current Issues, pp. 2754. Wesleyan University Press, Middletown,
Conn.
Seidenfeld, T. (1987). Entropy and uncertainty. In MacNeill, I. B., & Umphrey, G. J. (Eds.),
Foundations of Statistical Inferences, pp. 259287. Reidel, Dordrecht, Netherlands.
Shore, J. E., & Johnson, R. W. (1980). Axiomatic derivation of the principle of maximum entropy and the principle of minimimum cross-entropy. IEEE Transactions on
Information Theory, IT-26 (1), 2637.
Ulam, S. (1930). Zur masstheorie in der allgemeinen mengenlehre. Fundamenta Mathematicae, 16, 140150.
Walley, P. (1996). Inferences from multinomial data: learning about a bag of marbles.
Journal of the Royal Statistical Society, Series B, 58 (1), 334. Discussion of the
paper by various commentators appears on pp. 3457.

356

fiJournal of Artificial Intelligence Research 21 (2004) 193-243

Submitted 09/03; published 02/04

Generalizing Boolean Satisfiability I: Background and
Survey of Existing Work
Heidi E. Dixon

dixon@cirl.uoregon.edu

CIRL
Computer and Information Science
1269 University of Oregon
Eugene, OR 97403 USA

Matthew L. Ginsberg

ginsberg@otsys.com

On Time Systems, Inc.
1850 Millrace, Suite 1
Eugene, OR 97403 USA

Andrew J. Parkes

parkes@cirl.uoregon.edu

CIRL
1269 University of Oregon
Eugene, OR 97403 USA

Abstract
This is the first of three planned papers describing zap, a satisfiability engine that
substantially generalizes existing tools while retaining the performance characteristics of
modern high-performance solvers. The fundamental idea underlying zap is that many
problems passed to such engines contain rich internal structure that is obscured by the
Boolean representation used; our goal is to define a representation in which this structure
is apparent and can easily be exploited to improve computational performance. This paper
is a survey of the work underlying zap, and discusses previous attempts to improve the
performance of the Davis-Putnam-Logemann-Loveland algorithm by exploiting the structure of the problem being solved. We examine existing ideas including extensions of the
Boolean language to allow cardinality constraints, pseudo-Boolean representations, symmetry, and a limited form of quantification. While this paper is intended as a survey, our
research results are contained in the two subsequent articles, with the theoretical structure
of zap described in the second paper in this series, and zaps implementation described in
the third.

1. Introduction
This is the first of a planned series of three papers describing zap, a satisfiability engine
that substantially generalizes existing tools while retaining the performance characteristics
of modern high-performance solvers such as zChaff (Moskewicz, Madigan, Zhao, Zhang,
& Malik, 2001).1 Many Boolean satisfiability problems incorporate a rich structure that reflects properties of the domain from which the problems themselves arise, and zap includes
a representation language that allows this structure to be described and a proof engine
that exploits the structure to improve performance. This first paper describes the work on
1. The second two papers have been published as technical reports (Dixon, Ginsberg, Luks, & Parkes,
2003b; Dixon, Ginsberg, Hofer, Luks, & Parkes, 2003a) but have not yet been peer reviewed.

c
2004
AI Access Foundation. All rights reserved.

fiDixon, Ginsberg & Parkes

which zap itself is based, and is intended to be a survey of existing results that attempt to
use problem structure to improve the performance of satisfiability engines. The results we
discuss include generalizations from Boolean satisfiability to include cardinality constraints,
pseudo-Boolean representations, symmetry, and a limited form of quantification. The second paper in this series (Dixon et al., 2003b) describes the theoretical generalization that
subsumes and extends these ideas, and the third paper (Dixon et al., 2003a) describes the
zap system itself.
Our intention is to review work on satisfiability from the introduction of the DavisPutnam-Logemann-Loveland algorithm (Davis, Logemann, & Loveland, 1962) to the present
day. Not all of this work (thankfully), but only that portion of the work that can be thought
of as an attempt to improve the performance of systematic methods by exploiting the general
structure of the problem in question.
We therefore include a description of recent work extending the language of Boolean
satisfiability to include a restricted form of quantification (Ginsberg & Parkes, 2000) or
pseudo-Boolean constraints (Barth, 1995, 1996; Chandru & Hooker, 1999; Dixon & Ginsberg, 2000; Hooker, 1988; Nemhauser & Wolsey, 1988); in each case, the representational
extension corresponds to the existence of structure that is hidden by the Boolean axiomatization. We discuss at length the interplay between the desire to speed search by exploiting
structure and the danger of slowing search by using unwieldy representations. Somewhat
surprisingly, we will see that the most effective representational extensions appear to incur little or no overhead as a result of implementation concerns. It was this observation 
that better representations can have better implementations  that led us to search for the
general sort of structure that zap exploits.
We will also discuss the attempts that have been made to exploit the symmetrical structure of some satisfiability problems (Brown, Finkelstein, & Paul Walton Purdom, 1988;
Crawford, 1992; Crawford, Ginsberg, Luks, & Roy, 1996; Joslin & Roy, 1997; Krishnamurthy, 1985; Puget, 1993). This work appears to have had only a modest impact on the
development of satisfiability engines generally, and we explain why: Most authors (Crawford, 1992; Crawford et al., 1996; Joslin & Roy, 1997; Krishnamurthy, 1985; Puget, 1993)
exploit only global symmetries, and such symmetries are vanishingly rare in naturally occurring problems. The methods that have been described for exploiting local or emergent
symmetries (Brown et al., 1988; Szeider, 2003) incur unacceptable computational overhead
at each node of the search. Our general arguments regarding the interplay between representation and search suggest that one should identify local symmetries when a problem is
formulated, and then exploit those symmetries throughout the search.
We will not discuss heuristic search or any of the substantial literature relating to it.
To our collective eye, just as a Boolean axiomatization can obscure the natural structure in
a search problem, so can heuristics. We have argued elsewhere (Ginsberg & Geddis, 1991)
that domain-dependent search control rules can never be more than a poor mans standin
for general principles based on problem structure. Our selection of survey material reflects
this bias.
We have remarked that this entry in the zap series is a survey paper; to the extent
that there is a research contribution, it is in the overall (and, we believe, novel) focus
we are taking. Our basic view is that the target of new work in this area should not
be a specific representational extension such as a pseudo-Boolean or first-order encoding,
194

fiBoolean Satisfiability Survey

but a direct exploitation of the underlying problem structure. This paper is original in
describing existing work in this way, for the first time viewing the first-order and pseudoBoolean extensions purely as structure-exploitation techniques. First-order and pseudoBoolean representations are effective not because of their history of usefulness, but because
 and to our mind only because  they allow the identification and capture of two particular
types of structure inherent in many classes of problems. It is our hope that the reader
views the material we are presenting here (and in the companion papers as well) in this
light: Recent progress in Boolean satisfiability is best thought of in terms of structure
exploitation. That is the perspective with which we approach this paper, and we hope that
you, the reader, will come to share it.
But let us return to the Davis-Putnam-Logemann-Loveland procedure itself (Davis et al.,
1962), which appears to have begun the body of work on the development of solvers that are
sufficiently powerful to be used in practice on a wide range of problems. Descendants of the
dpll algorithm are now the solution method of choice on many such problems including
microprocessor testing and verification (Biere, Clarke, Raimi, & Zhu, 1999; Copty, Fix,
Giunchiglia, Kamhi, Tacchella, & Vardi, 2001; Velev & Bryant, 2001), and are competitive
in other domains such as planning (Kautz & Selman, 1992).
We will return to the pure algorithmics of dpll and its successors shortly, but let us begin
by noting that in spite of impressive engineering successes on many difficult problems, there
are many easy problems with which Boolean satisfiability engines struggle. These include
problems involving parity, the well known pigeonhole problem (stating that you cannot
put n + 1 pigeons into n holes if each pigeon needs its own hole), and problems that are
described most naturally using a first-order as opposed to a ground representation.
In all of these cases, there is structure to the problem being solved and this structure
is lost when the ground encoding is built. While it is a testament to the power of Boolean
methods that they can solve large and difficult problems without access to this underlying
structure, it seems reasonable to expect that incorporating and using the structure would
improve performance further. Our survey of techniques that improve dpll will suggest that
this is in fact the case, since all of the techniques that underpin the performance of modern
Boolean satisfiability engines can be well understood in this way.
Before turning to the details of this analysis, however, let us flesh out our framework a
bit more. If any computational procedure is to have its performance improved, there seem
to be only three ways in which this can be done:
1. Replace the algorithm.
2. Reduce the time spent on a single iteration of the inner loop.
3. Reduce the number of times the inner loop must be executed.
The first approach is not our focus here; while there are many potential competitors to
dpll, none of them seems to outperform dpll in practice.2 Work on the second approach
2. Systematic alternatives include the original Davis-Putnam (1960) method, polynomial calculus solvers
(Clegg, Edmonds, & Impagliazzo, 1996) based on Buchbergers (1965, 1985) Groebner basis algorithm,
methods based on binary decision diagrams or bdds (Bryant, 1986, 1992), and direct first-order methods

195

fiDixon, Ginsberg & Parkes

has historically focused on reducing the amount of time spent in unit propagation, which
does indeed appear to represent the inner loop of most dpll implementations.
There are a variety of techniques available for reducing the number of calls to the inner
loop, which we will divide as follows:
3a. Algorithmic improvements that do not require representational changes.
3b. Algorithmic improvements requiring representational changes.
Attempts to improve dpll without changing the underlying Boolean representation have
focused on (i) the development of a mechanism for retaining information developed in one
portion of the search for subsequent use (caching or, more commonly, learning) and (ii) the
development of search heuristics that can be expected to reduce the size of the space being
examined. In all such work, however, using dpll to analyze problems where no solution
exists is equivalent to building a resolution proof of the unsatisfiability of the underlying
theory, so that the number of inference steps is bounded by the number of inferences in the
shortest such proof (Mitchell, 1998). These lengths are generally exponential in problem
size in the worst case.
Work involving representation change can overcome this difficulty by reducing the length
of the proof that dpll or a similar algorithm is implicitly trying to construct. Representations are sought for which certain problems known to require proofs of exponential length in
the Boolean case admit proofs of polynomial length after the representational shift is made.
This leads to a hierarchy of representational choices, where one representation r1 is said to
polynomially simulate or p-simulate another r2 if proofs using the representation r2 can be
converted to proofs using r1 in polynomial time. In general, representations that lead to
efficient proofs do so via more efficient encodings, so that a single axiom in the improved
representation corresponds to exponentially many in the original. There are many excellent
surveys of the proof complexity literature (Beame & Pitassi, 2001; Pitassi, 2002; Urquhart,
1995), and we will generally not repeat that material here.
Of course, it is not sufficient to simply improve the epistemological adequacy of a proof
system; its heuristic adequacy must be maintained or improved as well (McCarthy, 1977).
We therefore assume that any representation introduced for the purposes of navigating the
p-simulation hierarchy also preserves the basic inference mechanism of dpll (resolution) and
maintains, and ideally builds upon, the improvements made in propagation performance (2)
and learning (3a). It is in this context that our survey shall consider these representational
changes.
The representations that we will consider are the following:
 Boolean axiomatizations. This is the original representation used in dpll, and provides the basic setting in which progress in propagation, learning and branching has
taken place.
such as those employed by otter (McCune & Wos, 1997). Nonsystematic methods include the wsat
family (Selman, Kautz, & Cohen, 1993), which received a great deal of attention in the 1990s and still
appears to be the method of choice for randomly generated problems and some specific other sets of
instances. In general, however, systematic algorithms with their roots in dpll tend to outperform the
alternatives.

196

fiBoolean Satisfiability Survey

 Cardinality constraints. If a disjunctive Boolean axiom states that at least one of the
disjuncts is true, a cardinality constraint allows one to state that at least n of the
disjuncts are true for some integer n.
 Pseudo-Boolean constraints. Taken from operations research, a pseudo-Boolean constraint is of the form
X
wi li  k
i

where the wi are positive integral weights, the li are literals, and k is a positive integer.
Cardinality constraints are the special case where wi = 1 for all i; a Boolean constraint
has k = 1 as well.
 Symmetric representations. Some problems (such as the pigeonhole problem) are
highly symmetric, and it is possible to capture this symmetry directly in the axiomatization. A variety of authors have developed proof systems that exploit these
symmetries to reduce proof size (Brown et al., 1988; Crawford, 1992; Crawford et al.,
1996; Joslin & Roy, 1997; Krishnamurthy, 1985; Puget, 1993).
 Quantified representations. While there are many approaches to quantified satisfiability, we will focus only on those that do not change the underlying complexity
of the problem being solved.3 This requires that all domains of quantification be
finite, and is the focus of a propositional restriction of first-order logic known as
qprop (Ginsberg & Parkes, 2000).
Given the arguments regarding heuristic adequacy generally, our goal in this survey is
to complete the following table:
representational
efficiency

p-simulation
hierarchy

inference

unit
propagation

learning

SAT

cardinality
pseudo-Boolean
symmetry
QPROP

The first column simply names the representational system in question. Then for each,
we describe:
 Representational efficiency (3b): How many Boolean axioms can be captured in a
single axiom in the given representation?
 p-simulation hierarchy (3b): Where is the representation relative to others in the
p-simulation hierarchy?
 Inference: Is it possible to lift the basic dpll inference mechanism of resolution to the
new representation without incurring significant additional computational expense?
3. Problems involving quantified Boolean formulae, or qbf, are pspace-complete (Cadoli, Schaerf, Giovanardi, & Giovanardi, 2002) as opposed to the np-complete problems considered by dpll and its direct
successors.

197

fiDixon, Ginsberg & Parkes

 Unit propagation (2): Can the techniques used to speed unit propagation be lifted to
the new setting? Are new techniques available that are not available in the Boolean
case?
 Learning (3a): Can existing learning techniques be lifted to the new setting? Are new
techniques available that are not available in the Boolean case?
We cannot overstress the fact that no single column in our table is more important than
the others. A reduction in proof length is of little practical value if there is no associated
reduction in the amount of computation time required to find a proof. Speeding the time
needed for a single inference is hardly useful if the number of inferences required grows
exponentially.
The Boolean satisfiability community has pioneered many techniques used to reduce perinference running time and to understand learning in a declarative setting. In spite of the
fact that resolution and Boolean satisfiability are among the weakest inference systems in
terms of representational efficiency and their position in the p-simulation hierarchy (Pudlak,
1997), almost none of the more powerful proof systems is in wide computational use. Finding
proofs in these more sophisticated settings is difficult; even direct attempts to lift dpll to
a first-order setting (Baumgartner, 2000) seem fraught with complexity and an inability to
exploit recent ideas that have led to substantial improvements in algorithmic performance.
The most usable proof systems are often not the theoretically most powerful.
This paper is organized along the rows of the table we are trying to complete. Boolean
techniques are described in the next section; we recount the demonstration that the pigeonhole problem is exponentially difficult in this setting (Haken, 1985). We go on in Section 3
to discuss cardinality constraints and pseudo-Boolean methods, showing that the earlier
difficulties with the pigeonhole problem can be overcome using either method but that
similar issues remain in other cases. Following the descriptions of implemented pseudoBoolean reasoning systems (Barth, 1995; Dixon & Ginsberg, 2000), we show that the key
computational ideas from the Boolean case continue to be applicable in a pseudo-Boolean
setting.
Axiomatizations that attempt to exploit symmetry directly are discussed in Section 4.
We draw a distinction between approaches that require the existence of global symmetries,
which tend not to exist in practice, and those that use only local ones, which exist but are
difficult to find as inference proceeds.
In Section 5, we discuss axiomatizations that are Boolean descriptions of problems that
are more naturally represented using quantified axioms. We discuss the problems arising
from the fact that the ground theories tend to be exponentially larger than their lifted
counterparts, and show that working with the first-order axiomatization directly can lead
to large improvements in the efficiency of the overall system (Ginsberg & Parkes, 2000).
Concluding remarks are contained in Section 6.

2. Boolean Satisfiability
Definition 2.1 A variable is simply a letter (e.g., a) that can be either true or false. A
literal is either a variable or the negation of a variable. A clause is a disjunction of literals,

198

fiBoolean Satisfiability Survey

and a Boolean satisfiability problem (in conjunctive normal form), or a sat problem, is a
conjunction of clauses.
A solution to a sat problem C is an assignment of values to each of the letters so that
every clause in C is satisfied.
None of this should be new. Satisfiability of sat instances is well-known to be NPcomplete (Cook, 1971), and the language is a reasonably natural one for encoding realworld problems. As we remarked in the introduction, the classic algorithm for solving these
problems is depth-first search augmented with an ability to set variables whose values are
forced:
Procedure 2.2 (Davis-Putnam-Logemann-Loveland) Given a sat problem C and a
partial assignment P of values to variables, to compute dpll(C, P ):
1
2
3
4
5
6
7
8
9

P  Unit-Propagate(P )
if P contains a contradiction
then return failure
if P assigns a value to every variable
then return success
l  a literal not assigned a value by P
if dpll(C, P  {l = true}) = success
then return success
else return dpll(C, P  {l = false})

Variables are assigned values in two ways. In the first, unit propagation, the clause set
is examined under the existing partial assignment and new consequential assignments are
identified. Somewhat more specifically (see below), clauses are found that have no satisfied
literals and exactly one unvalued literal. In each such clause, the unvalued literal is valued
so as to satisfy the clause. This process is repeated until a contradiction is encountered, a
solution is found, or no more clauses meet the necessary conditions. If the unit propagation
function terminates without reaching a contradiction or finding a solution, then a variable
is selected and assigned a value, and the procedure recurs.
In practice, the choice of branch literal is crucial to the performance of the algorithm.
(Note that by choosing a branch literal l instead of l, we can also select the order in which
values are tried for the underlying variable.) Relatively early work on dpll focused on the
selection of branch variables that produced as many unit propagations as possible, thus
reducing the size of the residual problems that had to be solved recursively. As we will see
in Section 2.3, however, more recent ideas appear to be more effective.
Missing from Procedure 2.2, however, is a description of the propagation process. Here
it is:
Procedure 2.3 (Unit propagation) To compute Unit-Propagate(P ):
1
2
3
4

while no contradiction is found and there is a c  C that under P
has no satisfied literals and exactly one unassigned literal
do v  the variable in c unassigned by P
P  P  {v = V : V is selected so that c is satisfied}
return P
199

fiDixon, Ginsberg & Parkes

100

ZCHAFF data

% of time spent in UP

95

90

85

80

75

70

0

10

20

30

40
50
total CPU time (sec)

60

70

80

90

Figure 1: Fraction of CPU time spent in unit propagation
Dpll has a variety of well-known theoretical properties. It is sound and complete in
that every candidate solution returned is a solution of the original problem, and such a
solution will be returned if one exists (and failure eventually reported if no solution exists).
From a practical point of view, the running time of dpll is obviously potentially exponential in the size of the problem, since at each iteration, possibly only a single variable
is assigned a value before the routine is invoked recursively. In practice, of course, unit
propagation can reduce the number of branch points substantially, but the running time
remains exponential on difficult instances (Crawford & Auton, 1996).
We also point out that on difficult problem instances, most of the running time is
necessarily spent exploring portions of the search space in which there are no solutions.
After all, if P is a partial assignment that can be extended to a solution, the algorithm will
never backtrack away from P . (Indeed, it cannot and retain completeness, since P may
be the only variable assignment that extends to a full solution at this point.) Given that
there can be no backtrack away from a satisfiable partial assignment, and that the number
of backtracks is exponential in the problem size, it is clear that most of the time spent by
the program is indeed in evaluating unsatisfiable regions of the search space.
2.1 Unit Propagation: The Inner Loop
When the dpll algorithm 2.2 is implemented and run on practical problems, the bulk of the
running time is spent in unit propagation. As an example, Figure 1 gives the amount of time
spent by zChaff on a variety of microprocessor test and verification examples made available by Velev (http://www.ece.cmu.edu/mvelev).4 As the problems become more difficult,
an increasing fraction of the computational resources are devoted to unit propagation. For
this reason, much early work on improving the performance of dpll focused on improving
the speed of unit propagation.
4. The examples used to generate the graph are those solved by zChaff within 100 seconds using an Intel
Pentium 4M running at 1.6GHz. For those not solved within the 100 second limit, an average of 89.4%
of the time was spent unit propagating.

200

fiBoolean Satisfiability Survey

Within the unit propagation procedure 2.3, the bulk of the time is spent identifying
clauses that propagate; in other words, clauses that are not satisfied by the partial assignment and contain at most one unvalued literal:
Observation 2.4 Efficient implementations of dpll typically spend the bulk of their effort
searching for clauses satisfying the conditions required for unit propagation.
Before we go on to examine the techniques that have been used to speed unit propagation
in practice, let us remark that other implementations of sat solvers have similar properties.
Nonsystematic solvers such as wsat (Selman et al., 1993), for example, spend the bulk of
their time looking for clauses containing no satisfied or unvalued literals (or, equivalently,
maintaining the data structures needed to make such search efficient). We can generalize
Observation 2.4 to get:
Observation 2.5 Efficient implementations of sat solvers typically spend the bulk of their
effort searching for clauses satisfying specific syntactic conditions relative to a partial or
complete truth assignment.
While the focus of our survey is on systematic methods, we remark that because of the
similarity of the techniques used in dpll and in wsat, techniques that speed the inner loop
of one are likely to speed the inner loop of the other as well.
That said, let us describe the series of ideas that have been employed in speeding the
process of identifying clauses leading to unit propagations:
1. After binding a variable v, examine each clause to determine whether or not it satisfies
the conditions of Procedure 2.3.
2. Slightly more sophisticated is to restrict the search for a suitable clause to those clauses
c  C that include v as one of the disjuncts (assuming that v has been assigned the
value true). After all, if v appears in c, c is satisfied after v is set to true; if v is not
mentioned in c there can be no change in cs ability to unit propagate when vs value
is set.
3. When we set v to true above, as we examine clauses containing v, we have to walk
each such clause to determine just which literals are satisfied (if any) and which are
still unbound. It is more efficient to keep a record, for each clause c, of the number
s(c) of satisfied and the number u(c) of unbound literals.
In order to keep these counts current when we set a variable v to true, we need to
increment s(c) and decrement u(c) for each clause where v appears, and to simply
decrement u(c) for each clause where v appears. If we backtrack and unset v, we
need to reverse these adjustments.
Compared to the previous approach, we need to examine four times as many clauses
(those where v appears with either sign, and both when v is set and unset), but each
examination takes constant time instead of time proportional to the clause length. If
the average clause length is greater than four, this approach, due to Crawford and
Auton (1996), will be more effective than its predecessor.
201

fiDixon, Ginsberg & Parkes

4. Currently, the most efficient scheme for searching for unit propagations is the watched
literals family of implementations (Moskewicz et al., 2001; Zhang & Stickel, 2000).
For each clause c, we identify two watched literals l1 (c) and l2 (c); the basic idea
is that as long as these two literals are both either unvalued or satisfied, the clause
cannot produce a unit propagation.
It is only when one of the watched literals is set to false that the clause must be
examined in detail. If there is another unset (and unwatched) literal, we watch it. If
there is a satisfied literal in the clause, we need do nothing. If there is no satisfied
literal, the clause is ready to unit propagate.
If the average clause length is l, then when we set a variable v (say to true), the
probability is approximately 2/l that we will need to analyze a clause in which v
appears, and the work involved is proportional to the length of the clause. So the
expected amount of work involved is twice the number of clauses in which v appears,
an improvement on the previous methods. In fact, the approach is somewhat more
efficient than this cursory analysis suggests because the adjustment of the watched
literals tends to favor watching those that are set deep in the search tree.
Before we move on to discuss learning in Boolean satisfiability, let us remark briefly on
the so-called pure literal rule. To understand the rule itself, suppose that we have a theory
T and some partial variable assignment P . Suppose also that while a literal q appears in
some of the clauses in T that are not yet satisfied by P , the negation q does not appear
in any such clauses. Now while q may not be a consequence of the partial assignment P ,
we can clearly set q to true without removing any solutions from the portion of the search
space that remains.
The pure literal rule is not generally included in implementations of either the dpll or
the unit propagation procedure because it is relatively expensive to work with. Counts of the
number of unsatisfied clauses containing variables and their negations must be maintained
at all times, and checked to see if a literal has become pure. In addition, we will see in
Section 2.3 that many branching heuristics obviate the need for the pure literal rule to be
employed.
2.2 Learning and Relevance
Let us now turn to the final column of our table, considering the progress that has been made
in avoiding rework in Boolean satisfiability engines. The basic idea is to avoid situations
where a conventional implementation will thrash, solving the same subproblem many
times in different contexts.
To understand the source of the difficulty, consider an example involving a sat problem
C with variables v1 , v2 , . . . , v100 , and suppose also that the subset of C involving only
variables v50 , . . . , v100 in fact implies that v50 must be true.
Now imagine that we have constructed a partial solution that values the variables
v1 , . . . , v49 , and that we initially set v50 to false. After some amount of backtracking,
we realize that v50 must be true. Unfortunately, if we subsequently change the value of
one of the vi s for i < 50, we will forget that v50 needs to be true and are in danger of
setting it to false once again, followed by a repetition of the search that showed v50 to be a
202

fiBoolean Satisfiability Survey

consequence of C. Indeed, we are in danger of solving this subproblem not just twice, but
once for each search node that we examine in the space of vi s for i < 50.
As we have indicated, the solution to this problem is to cache the fact that v50 needs
to be true; this information is generally saved in the form of a new clause called a nogood .
In this case, we record the unary clause v50 . Modifying our original problem C in this
way will allow us to immediately prune any subproblem for which we have set v50 to false.
This technique was introduced by Stallman and Sussman (1977) in dependency directed
backtracking.
Learning new constraints in this way can prevent thrashing. When a contradiction
is encountered, the set of assignments that caused the contradiction is identified; we will
call this set the conflict set. A new constraint can then be constructed that excludes the
assignments in the conflict set. Adding this constraint to the problem will ensure that the
faulty set of assignments is avoided in the future.
This description of learning is fairly syntactic; we can also give a more semantic description. Suppose that our partial assignment contains {a, b, d, e} and that our problem
contains the clauses
a  b  c  d  e
(1)
and
c  d.

(2)

The first clause unit propagates to allow us to conclude c; the second allows us to conclude
c. This contradiction causes us to backtrack, learning the nogood
a  b  d  e.

(3)

From a semantic point of view, the derived nogood (3) is simply the result of resolving the
reason (1) for c with the reason (2) for c.
This is a general phenomenon. At any point, suppose that v is a variable that has
been set in the partial assignment P . If vs value is the result of a branch choice, there
is no associated reason. If vs current value is the result of a unit propagation, however,
we associate to v as a reason the clause that produced the propagation. If vs value is
the result of a backtrack, that value must be the result of a contradiction identified for
some subsequent variable v 0 and we set the reason for v to be the result of resolving the
reasons for v 0 and v 0 . At any point, any variable whose value has been forced will have
an associated reason, and these accumulated reasons will avoid the need to reexamine any
particular portion of the search space.
Modifying dpll to exploit the derived information requires that we include the derived clauses in the overall problem C, thus enabling new unit propagations and restricting
subsequent search. But there is an implicit change as well.
In our earlier example, suppose that we have set the variables v1 , . . . , v49 in that order,
and that we have learned the nogood
v7  v9

(4)

(presumably in a situation where v7 is false and v9 is true). Now as long as v7 remains false
and v9 remains true, unit propagation will fail immediately because (4) is unsatisfied. This
203

fiDixon, Ginsberg & Parkes

will allow us to backtrack directly to v9 in this example. This is the semantic justification
for a technique known as backjumping (Gaschnig, 1979) because the search jumps back
to a variable that is relevant to the problem at hand.5
While attractive in theory, however, this technique is difficult to apply in practice. The
reason is that a new nogood is learned with every backtrack; since the number of backtracks
is proportional to the running time of the program, an exponential number of nogoods can
be learned. This can be expected both to overtax the memory available on the system where
the algorithm is running, and to increase the time for each node expansion. As the number
of clauses containing any particular variable v grows without bound, the unit propagation
procedure 2.3 will grind to a halt.
Addressing this problem was the primary focus of work on systematic sat solvers during
the 1990s. Since it was impractical to retain all of the nogoods that had been learned, some
method needed to be found that would allow a polynomial number of nogoods to be retained
while others were discarded. The hope was that a relatively small number of nogoods could
still be used to prune the search space effectively.6
Length-bounded Learning The first method used to bound the size of the set of learned
clauses was to only retain clauses whose length is less than a given bound k (Dechter, 1990;
Frost & Dechter, 1994). In addition to providing a polynomial bound on the number of
nogoods retained, this approach was felt likely to retain the most important learned clauses,
since a clause of length l will in general prune 21l of the possible assignments of values to
variables. Length-bounded learning draws from this observation the conclusion that short
clauses should be retained in preference to long ones.
Relevance-bounded Learning Unfortunately, length may not be the best indicator
of the value of a particular learned clause. If we restrict our attention to any particular
subproblem in the search, some short clauses may not be applicable at all, while other
longer clauses may lead to significant pruning. As an example, consider a node defined by
the partial assignment P = {a, b, c} together with the two learned clauses:
abe

(5)

a  b  c  d  e

(6)

As long as the assignments in P are retained, the clause (5) cannot be used for pruning
because it is satisfied by P itself. In fact, this clause will not be useful until we backtrack
and change the values for both a and for b. The clause (6) is more likely to be useful in the
current subproblem, since it will lead to a unit propagation if either d or e is set to false.
If the subproblem below the node given by P is large, (6) may be used many times. Within
the context of this subproblem, the longer clause is actually the more useful.
5. In this particular example, it is also possible to backtrack over v8 as well, although no reason is recorded.
The branch point for v8 is removed from the search, and v9 is set to false by unit propagation. The
advantage of this is that there is now flexibility in either the choice of value for v8 or the choice of
branch variable itself. This idea is related to Bakers (1994) work on the difficulties associated with some
backjumping schemes, and is employed in zChaff (Moskewicz et al., 2001).
6. Indeed, the final column of our table might better be named forgetting than learning. Learning
(everything) is easy; its forgetting in a coherent way thats hard.

204

fiBoolean Satisfiability Survey

At some level, the appearance of a, b, and c in (6) shouldnt contribute to the
effective length of the learned clause because that all of these literals are currently false.
Length-bounded learning cannot make this distinction.
We see from this example that it is useful to retain clauses of arbitrary length provided
that they are relevant to the current search context. If the context subsequently changes,
we can remove some clauses to make room for new ones that are more suitable to the new
context. This is what relevance-bounded learning does.
In relevance-bounded learning, the effective length of a clause is defined in terms of
the current partial assignment. The irrelevance of a clause is defined as one less than the
number of unvalued or satisfied literals it contains. For example, the clause (6) under
the partial assignment P has an irrelevance of 1. The idea of relevance-bounded learning
originated in dynamic backtracking (Ginsberg, 1993), in which clauses were deleted if their
irrelevance exceeded 1. This idea was generalized by Bayardo and Miranker (1996), who
defined a general relevance bound and then deleted all clauses whose irrelevance exceeded
that bound. This generalization is implemented in the relsat satisfiability engine (Bayardo
& Schrag, 1997).
Like length-bounded learning, relevance-bounded learning retains all clauses of length
less than the irrelevance bound k, since the irrelevance of a clause can never exceed its
length. But the technique of relevance-bounded learning also allows the retention of longer
clauses if they are applicable to the current portion of the search space. Such clauses are
only removed when they are no longer relevant.
Returning to our example, if we backtrack from the original partial assignment with
{a, b, c} and find ourselves exploring {a, b, c}, the short nogood (5) will be 0-irrelevant
(since we can unit propagate to conclude e) and the long one (6) will be 4-irrelevant. Using
a relevance bound of 3 or less, this nogood would be discarded.
The condition that nogoods are only retained until their irrelevance exceeds a bound k
is sufficient to ensure that only a polynomial number of nogoods are retained at any point.7
Experimental results (Bayardo & Miranker, 1996) show that relevance-bounded learning is
more effective than its length-bounded counterpart and, even with a relevance bound of 1,
the results are comparable to those of learning without restriction.8
Hybrid Approaches Finally, we note that some solvers employ a hybrid approach. The
chaff algorithm (Moskewicz et al., 2001) uses both a relevance bound and a (larger) length
bound. Clauses must meet both the relevance bound and the length bound to be retained.
Yet another approach is taken by the berkmin algorithm (Goldberg & Novikov, 2002).
Here, the set of nogoods is partitioned into two separate groups based on how recently the
15
nogoods were acquired; 16
of the nogoods are kept in a recent group and the remaining
1
16 in an old group. A relatively large length bound is used to cull the recently acquired
nogoods while a smaller length bound is used to aggressively cull the smaller group of older
7. Although accepted wisdom, we know of no proof in the literature of this result; Bayardo and Mirankers
(1996) proof appears to assume that the order in which branch variables are chosen is fixed. We present
a general proof in the next paper in this series (Dixon et al., 2003b).
8. Results such as these necessarily become somewhat suspect as algorithmic methods mature; an unfortunate consequence of the extremely rapid progress in satisfiability engines over recent years is the lack of
careful experimental work evaluating the host of new ideas that have been developed.

205

fiDixon, Ginsberg & Parkes

nogoods. We are not aware of any studies comparing these hybrid approaches to pure
length-bounded or relevance-bounded methods.
2.3 Branching Heuristics
Let us now turn to an examination of the progress that has been made in the development
of effective heuristics for the selection of branch variables in dpll. As discussed in the
introduction, we focus not on specific heuristics that work in selected domains, but on
general ideas that attempt to exploit the structure of the axiomatization directly.
Prior to the development of successful learning techniques, branching heuristics were the
primary method used to reduce the size of the search space. It seems likely, therefore, that
the role of branching heuristics is likely to change significantly for algorithms that prune
the search space using learning. While the heuristics used in zChaff appear to be a first
step in this direction, very little is known about this new role.
Initially, however, the primary criterion for the selection of a branch variable was to
pick one that would enable a cascade of unit propagations; the result of such a cascade is a
smaller and more tractable subproblem.9
The first rule based on this idea is called the moms rule, which branches on the variable
that has Maximum Occurrences in clauses of Minimum Size (Crawford & Auton, 1996;
Dubois, Andre, Boufkhad, & Carlier, 1993; Hooker & Vinay, 1995; Jeroslow & Wang, 1990;
Pretolani, 1993). Moms provides a rough but easily computed approximation to the number
of unit propagations that a particular variable assignment might cause.
Alternatively, one can use a unit propagation rule (Crawford & Auton, 1996; Freeman,
1995), and compute the exact number of propagations that would be caused by a branching
choice. Given a branching candidate vi , the variable is separately fixed to true and to false
and the unit propagation procedure is executed for each choice. The precise number of unit
propagations caused is then used to evaluate possible branching choices. Unlike the moms
heuristic, this rule is obviously exact in its attempt to judge the number of unit propagations
caused by a potential variable assignment. Unfortunately, it is also considerably more
expensive to compute because of the expense of unit propagation itself. This led to the
adoption of composite approaches (Li & Anbulagan, 1997) where moms is used to identify
a small number of branching candidates, each of which is then evaluated exactly using the
more expensive unit propagation heuristic. On randomly generated problems, the composite
technique outperforms either heuristic in isolation.
Another strategy is to branch on variables that are likely to be backbone variables (Dubois
& Dequen, 2001). A backbone literal (also often referred to as a unary prime implicate of
a theory) is one that must be true in all solutions to a given problem. Given a problem C
and a partial assignment P , the backbone heuristic attempts to branch on variables that
are backbones of the subset of those clauses in C that are satisfied by P ; the likelihood that
any particular variable is a backbone literal is approximated by counting the appearances
9. This idea tends to obviate the need for use of the pure literal rule, as well. If p is a pure literal, there is
no particular reason to hurry to set p to true; the key thing is to avoid setting it to false. But if p is pure,
p cannot generate any unit propagations, so p will tend not to be selected as a branch variable. Pure
literals can obviously never be set false by unit propagation, so heuristics based on unit propagation
counts tend to achieve most of the advantages of the pure literal rule without incurring the associated
computational costs.

206

fiBoolean Satisfiability Survey

of that literal in the satisfied clauses in C. This heuristic outperforms those discussed in
the previous paragraphs.
The heuristics described thus far were developed when the communitys research emphasis was focused on the solution of randomly generated satisfiability problems. The
development of bounded learning methods enabled solvers to address the issue of thrashing,
and caused a natural shift in focus toward more structured, realistic problems. There are no
formal studies comparing the previously discussed heuristics on structured problems, and
the value of the studies that do exist is reduced because all of the implementations were of
dpll in isolation and without the learning techniques that have since proved so important.
Branching techniques and learning are deeply related, and the addition of learning to a dpll
implementation will have a significant effect on the effectiveness of any of these branching
strategies. As new clauses are learned, the number of unit propagations an assignment will
cause can be expected to vary; the reverse is also true in that the choice of branch variable
can affect which clauses the algorithm learns. A formal comparison of branching techniques
performance on structured problems and in the presence of learning would be extremely
useful.
Branching heuristics that are designed to function well in the context of a learning algorithm generally try to branch on variables about which things have been learned recently.
This tends to allow the implementation to keep making progress on a single section of the
search space as opposed to moving from one area to another; an additional benefit is that
existing nogoods tend to remain relevant, avoiding the inefficiencies associated with losing
the information present in nogoods that become irrelevant and are deleted. In zChaff,
for example, a count is maintained of the number of times each literal occurs in the theory
being solved. When a new clause is added, the count associated with each literal in the
clause is incremented. The branch heuristic then selects a variable that appears in as many
clauses as possible. By periodically dividing all of the counts by a constant factor, a bias is
introduced toward branching on variables that appear in recently learned clauses. Like the
moms rule, this rule is inexpensive to calculate.
The heuristic used in berkmin (Goldberg & Novikov, 2002) builds on this idea but
responds more dynamically to recently learned clauses. The berkmin heuristic prefers to
branch on variables that are unvalued in the most recently learned clause that is not yet
satisfied, with a zChaff-like heuristic used to break ties.
All told, there are many competing branching heuristics for satisfiability solvers, and
there is still much to be done in evaluating their relative effectiveness. The most interesting
experiments will be done using implementations that learn, and on realistic, structured
problems as opposed to randomly generated ones.
2.4 Proof Complexity
We have already commented briefly on the fact that proof systems can be evaluated based
on provable bounds on the proofs of certain classes of formulae, or by the development of
polynomial transformations from proofs in one system into proofs in another.

207

fiDixon, Ginsberg & Parkes

With regard to the first metric, there are at least three classes of problems known
to be exponentially difficult for conventional resolution-based provers (including any dpll
implementation):10
1. Pigeonhole problems (Haken, 1985)
2. Parity problems (Tseitin, 1970)
3. Clique coloring problems (Bonet, Pitassi, & Raz, 1997; Krajicek, 1997; Pudlak, 1997)
Before turning to a discussion of these problems specifically, however, let us point out
that there are many proof systems that are known to be more powerful than any of the
ones we discuss in this paper. From our perspective, the most interesting is extended
resolution and involves the introduction of new variables that correspond to arbitrary logical
expressions built up out of the original variables in the theory.
Since such logical expressions can always be built up term-by-term, it suffices to allow
the introduction of new variables corresponding to pairwise combinations of existing ones;
since disjunction can be replaced with conjunction using de Morgans laws, it suffices to
introduce new variables of the form
w xy
(7)
for literals x and y. Writing (7) in disjunctive normal form, we get:
Definition 2.6 (Tseitin, 1970) An extended resolution proof for a theory T is one where
T is first augmented by a collection of groups of axioms, each group of the form
x  y  w
x  w

(8)

y  w
where x and y are literals in the (possibly already extended) theory T and w is a new variable.
Following this, derivation proceeds using conventional resolution on the augmented theory.
There is no proof system known to be stronger than extended resolution; in fact, there
is no class of problems for which there are known to be no polynomially sized proofs in
extended resolution.
As we have stressed, however, the fact that a proof system is strong does not mean that
it works well in practice. We know of no implementation of extended resolution for the
simple reason that virtually nothing is known about how to select new variables so as to
shorten proof length.
Understanding why the introduction of these new variables can reduce proof length
is considerably simpler. As an example, suppose that during a resolution proof, we have
managed to derive the nogood ax, and that we have also derived ay. In order to complete
the proof, we need to perform lengthy  but identical  analyses of each of these nogoods,
eventually deriving simply x from the first and y from the second (and then resolving against
x  y, for example).
10. There are other hard problems as well, such as Hakens (1995) broken mosquito screen problem. The
three examples quoted here are sufficient for our purposes.

208

fiBoolean Satisfiability Survey

If we could replace the pair of nogoods a  x and a  y with the single nogood a  w
using (8), the two proofs from a  x and a  y could be collapsed into a single proof,
potentially halving the size of the proof in its entirety. Introducing still more variables can
repeat the effect, resulting in exponential reductions in proof size.
Another way to look at this is as an improvement in expressivity. There is simply no
way to write (a  x)  (a  y) or the equivalent a  (x  y) as a single Boolean axiom in
disjunctive normal form. The power of extended resolution rests on the fact that subexpression substitution makes it possible to capture expressions such as a  (x  y) in a single
axiom.
None of the proof systems being considered in this survey is as powerful as extended
resolution, and we will therefore evaluate them based on their performance on the three
problems mentioned at the beginning of this section. Let us therefore describe each of those
problems in some detail.
2.4.1 Pigeonhole problems
The pigeonhole problem involves showing that it is impossible to put n + 1 pigeons into n
holes if each pigeon must go into a distinct hole. If we write pij for the fact that pigeon i is
in hole j, then a straightforward axiomatization says that every pigeon must be in at least
one hole:
pi1  pi2      pin for i = 1, . . . , n + 1
(9)
and that no two pigeons can be in the same hole:
pik  pjk for 1  i < j  n + 1 and k = 1, . . . , n

(10)

Note that there are in all (n3 ) axioms of the form (10).
It is well known that there is no polynomial-sized proof of the unsatisfiability of the
axioms (9)(10) (Haken, 1985). The proof is technical, but the essential reason is that the
pigeonhole problem is all about counting. At some point, proving that you cant put
n + 1 pigeons into n holes requires saying that you cant put n pigeons into the last n  1
holes, thus n  1 pigeons into the last n  2 holes, and so on. Saying this in the language of
sat is awkward, and it is possible to show that no proof of the pigeonhole problem can be
completed without, at some point, working with extremely long individual clauses. Once
again, we see the connection to expressive efficiency; for readers interested in additional
details, Pitassis (2002) explanation is reasonably accessible.
2.4.2 Parity problems
By a parity problem, we will mean a collection of axioms specifying the parity of sets of
inputs. So we will write, for example,
x1      xn = 1

(11)

to indicates that an odd number of the xi are true; a right hand side of zero would indicate
that an even number were true. The  here indicates exclusive or.

209

fiDixon, Ginsberg & Parkes

Reduction of (11) to a collection of Boolean axioms is best described by an example.
The parity constraint x  y  z = 1 is equivalent to
xyz
x  y  z
x  y  z
x  y  z
In general, the number of Boolean axioms needed is exponential in the length of the parity
clause (11), but for clauses of a fixed length, the number of axioms is obviously fixed as
well.
For the proof complexity result of interest, suppose that G is a graph, where each node
in G will correspond to a clause and each edge to a literal. We label the edges with distinct
literals, and label each node of the graph with a zero or a one. Now if n is a node of the
graph that is labeled with a value vn and the edges e1n , . . . , ei(n),n incident on n are labeled
with literals l1n , . . . , li(n),n , we add to our theory the Boolean version of the clause
l1n      li(n),n = vn

(12)

Since every edge connects two nodes, every literal in the theory appears exactly twice
in axioms of the form (12). Adding all of these constraints therefore produces a value that
P
P
is equivalent to zero mod 2 and must be equal to n vn as well. If n vn is odd, the theory
is unsatisfiable. Tseitins (1970) principal result is to show that this unsatisfiability cannot
in general be proven in a number of resolution steps polynomial in the size of the Boolean
encoding.
2.4.3 Clique coloring problems
The last examples we will consider are known as clique coloring problems. These are
derivatives of pigeonhole problems where the exact nature of the pigeonhole problem is
obscured. Somewhat more specifically, the problems indicate that a graph includes a clique
of n + 1 nodes (where every node in the clique is connected to every other), and that the
graph must be colored in n colors. If the graph itself is known to be a clique, the problem is
equivalent to the pigeonhole problem. But if we know only that the clique can be embedded
into the graph, the problem is more difficult.
In the axiomatization, we use eij to describe the edges of the graph, cij to describe the
coloring of the graph, and qij to describe the embedding of the cliQue into the graph. The
graph has m nodes, the clique is of size n + 1, and there are n colors available. So the
axiomatization is:
eij  cil  cjl

for 1  i < j  m, l = 1, . . . , n

(13)

ci1      cin

for i = 1, . . . , m

(14)

qi1      qim

for i = 1, . . . , n + 1

(15)

for 1  i < k  n + 1, j = 1, . . . , m

(16)

for 1  i < j  m, 1  k 6= l  n + 1

(17)

qij  qkj
eij  qki  qlj

210

fiBoolean Satisfiability Survey

Here eij means that there is an edge between graph nodes i and j, cij means that graph
node i is colored with the jth color, and qij means that the ith element of the clique is
mapped to graph node j. Thus the first axiom (13) says that two of the m nodes in the
graph cannot be the same color (of the n colors available) if they are connected by an edge.
(14) says that every graph node has a color. (15) says that every element of the clique
appears in the graph, and (16) says that no two elements of the clique map to the same
node in the graph. Finally, (17) says that the clique is indeed a clique  no two clique
elements can map to disconnected nodes in the graph.
Since there is no polynomially sized resolution proof of the pigeonhole problem in
Boolean satisfiability, there is obviously no polynomially sized proof of the clique coloring problems, either. But as we shall see, clique coloring problems can in some cases be
used to distinguish among elements of the proof complexity hierarchy.
2.5 Boolean Summary
We summarize the results of this section by completing the first row of our table as follows:

SAT

rep. eff.
1

p-simulation
hierarchy
EEE

inference
resolution

unit
propagation
watched literals

learning
relevance

cardinality
PB
symmetry
QPROP

The entries are really just an informal shorthand:
 Representational efficiency: Boolean satisfiability is the benchmark against which
other languages will be measured; we give here the relative savings to be had by
changing representation.
 p-simulation hierarchy: We give the proof complexity for the three problem classes
discussed in Section 2.4. For Boolean satisfiability, all of the problems require proofs
of exponential length.
 Inference: The basic inference mechanism used by dpll is resolution.
 Propagation: Watched literals lead to the most efficient implementation.
 Learning: Relevance-based learning appears to be more effective than other polysized methods.

3. Pseudo-Boolean and Cardinality Constraints
The entries in the previous table summarize the fact that Boolean satisfiability is a weak
method that admits efficient implementations. The representation is relatively inefficient,
and none of our canonical problems can be solved in polynomial time. Some of these
difficulties, at least, can be overcome via a representational shift.

211

fiDixon, Ginsberg & Parkes

To understand the shift, note that we can write an axiom such as
x  y  z
as
x+y+z 1

(18)

where we are now thinking of x, y and z as variables with value either 0 (false) or 1 (true)
and have written z for 1  z or, equivalently, z. If v is a variable, we will continue to refer
to v as the negation of v.
All of the familiar logical operations have obvious analogs in this notation. If, for
example, we want to resolve
a  b  c
with
b  d
to get a  c  d, we simply add
a+b+c1
to
b+d1
and simplify using the identity b + b = 1 to get
a+c+d1
as required.
Whats nice about this notation is that it extends easily to more general descriptions.
P
If the general form of a disjunction li of literals is
li  1 as in (18), we can drop the
requirement that the right-hand side be 1:
Definition 3.1 A cardinality constraint or extended clause is a constraint of the form
X

li  k

i

where k is an integer and each of the li is required to have value 0 or 1.
The cardinality constraint simply says that at least k of the literals in question are true.
Proposition 3.2 (Cook, Coullard and Turan (1987)) There is an unsatisfiability proof
of polynomial length of the pigeonhole problem using cardinality constraints.
Proof. Cook et al. (1987) give a derivation in o(n3 ) steps; we have presented an o(n2 )
derivation elsewhere (Dixon & Ginsberg, 2000).
Of course, the fact that this extension to the sat language allows us to find polynomiallength derivations of pigeonhole problem does not necessarily show that the change will
have computational value; we need to examine the other columns of the table as well.
In the remainder of this section, we will show this and will go further, describing new
computational techniques that can only be applied in the broader setting that we are now
considering. Experimental results are also presented. But let us begin by examining the
first column of the table:
212

fiBoolean Satisfiability Survey

Proposition 3.3 (Benhamou, Sais, & Siegel, 1994) The cardinality constraint
x1 +    + xm  k
is logically equivalent to the set of

m 
k1

(19)

axioms

xi1 +    + ximk+1  1

(20)

for every set of m  k + 1 distinct variables {xi1 , . . . , ximk+1 }. Furthermore, there is no
more compact Boolean encoding of (19).
Proof. We first show that (19) implies (20). To see this, suppose that we have a set S of
m  k + 1 variables. Suppose also that T is the set of xi s that are true, so that T is of size
at least k. Since there are only m variables, S  T 6=  and at least one xi  S must be
true.
To see that (20) implies (19), suppose that (20) is true for all appropriate sets of xi s.
Now if (19) were false, the set of false xi s would be of size at least m  k + 1, so that some
instance of (20) would be unsatisfied.
To see that there is no more efficient encoding, first note that if (19) implies a Boolean
axiom
x1      xk  xk+1      xm
then it must also imply
x1      xk
since we can always change an xi from false to true without reducing the satisfiability
of (19).
Next, note that no axiom of length less than m  k + 1 is a consequence of (19), since
any such axiom can be falsified while satisfying (19) by setting every unmentioned variable
to true and the rest to false.
Finally, suppose that we leave out a single instance i of (20) but include all of the others
as well as every clause of length greater than m  k + 1. By setting the variables in i to false
and every other variable to true, all of the given clauses will be satisfied but (19)
will not
m 
be. It follows that any Boolean equivalent of (19) must include at least the k1
instances
of (20).
It follows from Proposition 3.3 that provided that no new variables are introduced, cardinality constraints can be exponentially more efficient than their Boolean counterparts.
Before discussing the other columns in the table, let us consider further extending our
representation to include what are known as pseudo-Boolean constraints:
Definition 3.4 A pseudo-Boolean constraint is an axiom of the form
X

wi li  k

(21)

i

where each wi and k is a positive integer and each of the li is required to have value 0 or 1.

213

fiDixon, Ginsberg & Parkes

Pseudo-Boolean representations typically allow both linear inequalities and linear equalities over Boolean variables. Linear equalities can easily be translated into a pair of inequalities of the form in the definition; we prefer the inequality-based description (Barth, 1996;
Chandru & Hooker, 1999, also known as pseudo-Boolean normal form) because of the better
analogy with Boolean satisfiability and because unit propagation becomes unmanageable
if equality constraints are considered. Indeed, simply determining if an equality clause is
satisfiable subsumes subset-sum and is therefore (weakly) NP-complete (Garey & Johnson,
1979).
Compare (21) with Definition 3.1; the wi are the weights attached to various literals. The
pseudo-Boolean language is somewhat more flexible still, allowing us to say (for example)
2a + b + c  2
indicating that either a is true or both b and c are (equivalent to the crucial representational
efficiency obtained in extended resolution). As we will see shortly, it is natural to make this
further extension because the result of resolving two cardinality constraints can be most
naturally written in this form.
3.1 Unit Propagation
Let us begin by discussing propagation techniques in a cardinality or pseudo-Boolean setting.11
A pseudo-Boolean version of unit propagation was first presented by Barth (1996) and
is described in a number of papers (Aloul, Ramani, Markov, & Sakallah, 2002; Dixon &
Ginsberg, 2000). In the Boolean case, we can describe a clause as unit if it contains no
satisfied literals and at most one unvalued one. To generalize this to the pseudo-Boolean
setting, we make the following definition, where we view a partial assignment P simply as
the set of literals that it values to true:
Definition 3.5 Let i wi li  k be a pseudo-Boolean clause, which we will denote by c.
Now suppose that P is a partial assignment of values to variables. We will say that the
current value of c under P is given by
P

X

curr(c, P ) =

wi  k

{i|li P }

If no ambiguity is possible, we will write simply curr(c) instead of curr(c, P ). In other
words, curr(c) is the sum of the weights of literals that are already satisfied by P , reduced
by the required total weight k.
In a similar way, we will say that the possible value of c under P is given by
X

poss(c, P ) =

wi  k

{i|li 6P }

11. As we have remarked, our table is designed to reflect the issues involved in lifting dpll to a more
expressive representation. Extending a nonsystematic search technique such as wsat to a pseudoBoolean setting has been discussed by Walser (1997) and Prestwich (2002).

214

fiBoolean Satisfiability Survey

If no ambiguity is possible, we will write simply poss(c) instead of poss(c, P ). In other
words, poss(c) is the sum of the weights of literals that are either already satisfied or not
valued by P , reduced by the required total weight k.12
Definition 3.6 Let c be a clause, and P a partial assignment. We will say that c is unit
if there is a variable v not appearing in P such that either P  {v} or P  {v} cannot be
extended to an assignment that satisfies c.
In this situation, the variable v is forced to take a value that will help satisfy the clause.
This creates a new consequential assignment. Note that if c is already unsatisfiable, we can
meet the conditions of the definition by choosing v to be any variable not assigned a value
by P . Note also that in the pseudo-Boolean case, a clause may actually contain more than
one variable that is forced to a specific value. It should be clear that in the Boolean case,
this definition duplicates the conditions of the original unit propagation procedure 2.3.
Lemma 3.7 A partial assignment P can be extended in a way that satisfies a clause c if
and only if poss(c, P )  0.
Proof. Assume first that poss(c, P )  0, and suppose that we value every remaining
variable in a way that helps to satisfy c. Having done so, every literal in c that is not
currently made false by P will be true, and the resulting value of c will be
X

wi li =

i

X

wi = poss(c, P ) + k  k

{i|li 6P }

so that c becomes satisfied.
Conversely, suppose that poss(c, P ) < 0. Now the best we can do is still to value the
unvalued literals favorably, so that the value of c becomes
X
i

wi li =

X

wi = poss(c, P ) + k < k

{i|li 6P }

and c is unsatisfiable.
Proposition 3.8 A clause c containing at least one unvalued literal is unit if and only if c
contains an unvalued literal li with weight wi > poss(c).
Proof. If there is a literal with weight wi > poss(c), setting that literal to false will reduce
poss(c) by wi , making it negative and thus making the c unsatisfiable. Conversely, if there
is no such literal, then poss(c) will remain positive after any single unvalued literal is set,
so that c remains satisfiable and is therefore not unit.
Given the above result, there is little impact on the time needed to find unit clauses.
We need simply keep the literals in each clause sorted by weight and maintain, for each
clause, the value of poss and the weight of the largest unvalued literal. If we value a literal
with different weight, we can apply the test in Proposition 3.8 directly. If we value a literal
of the given weight, a short walk along the clause will allow us to identify the new unvalued
literal of maximum weight, so that the proposition continues to apply.
12. Chai and Kuehlmann (2003) refer to poss as slack.

215

fiDixon, Ginsberg & Parkes

Watched literals Generalizing the idea of watched literals is no more difficult. We make
the following definition:
Definition 3.9 Let c be a clause. A watching set for c is any set S of variables with the
property that c cannot be unit as long as all of the variables in S are either unvalued or
satisfied.
Proposition 3.10 Given a clause c of the form
Then S is a watching set for c if and only if
X

P

i wi li

 k, let S be any set of variables.

wi  max wi  k
i

i

(22)

where the sum and maximum are taken over literals involving variables in S.
Proof. Suppose that all of the variables in S are unvalued or satisfied. Now let lj be any
P
unvalued literal in c. If lj 6 S, then poss(c)  wj + i wi  k and thus poss(c)  wj since
P
P
i wi 
i wi  maxi wi  k. If, on the other hand, lj  S, then
poss(c) 

X

wi  k

i

and
X

wi  wj 

X

wi  max wi  k
i

i

i

Combining these, we get
poss(c)  wj
Either way, we cannot have poss(c) < wj and Proposition 3.8 therefore implies that c
cannot be unit. It follows that S is a watching set.
P
The converse is simpler. If i wi  maxi wi < k, value every literal outside of S so as
P
to make c false. Now poss(c) = i wi  k, so if lj is the literal in S with greatest weight,
the associated weight wj satisfies wj > poss(c) and c is unit. Thus S cannot be a watching
set.
This generalizes the definition from the Boolean case, a fact made even more obvious
by:
Corollary 3.11 Given a cardinality constraint c requiring at least k of the associated literals
to be true, S is a watching set for c if and only if it includes at least k + 1 literals in c.
Proof. The expression (22) becomes
X
i

1  max 1  k
i

or
|S|  1  k.

216

fiBoolean Satisfiability Survey

3.2 Inference and Resolution
As with unit propagation, resolution also lifts fairly easily to a pseudo-Boolean setting. The
general computation is as follows:
Proposition 3.12 Suppose that we have two clauses c and c0 , with c given by
X

wi li + wl  k

(23)

wi0 li0 + w0 l  k 0

(24)

i

and c0 given by
X
i

Then it is legitimate to conclude
X
i

w0 wi li +

X

wwi0 li0  w0 k + wk 0  ww0

(25)

i

Proof. This is immediate. Multiply (23) by w0 , multiply (24) by w, add and simplify using
l + l = 1.
If all of the weights, k and k 0 are 1, this generalizes conventional resolution provided
that the sets of nonresolving literals in c and c0 are disjoint. To deal with the case where
there is overlap between the set of li and the set of li0 , we need:
Lemma 3.13 Suppose that c is clause i wi li  k. Then c is equivalent to
where the wi0 are given by:

wi , if wi < k;
wi0 (j) =
k, otherwise.
P

0
i wi li

P

 k,

Proof. If lj is a literal with wj  k, then both c and the rewrite are true if lj is satisfied.
If lj = 0, then c and the rewrite are equivalent.
In other words, we can reduce any coefficient that is greater than what is required to
satisfy the clause in its entirety, for example rewriting
3x + y + z  2
as
2x + y + z  2
because either is equivalent to x  (y  z).
Proposition 3.14 (Cook et al., 1987; Hooker, 1988) The construction of Proposition 3.12 generalizes conventional resolution.

217

fiDixon, Ginsberg & Parkes

Proof. We have already discussed the case where the sets of li and li0 are disjoint. If there
is a literal li in c that is the negation of a literal in c0 , then we will have li + li in (25),
which we can simplify to 1 to make the resolved constraint trivial; resolution produces the
same result. If there is a literal li in c that also appears in c0 , the coefficient of that literal
in the resolvent (25) will be 2 but can be reduced to 1 by virtue of the lemma.
Cardinality constraints are a bit more interesting. Suppose that we are resolving the
two clauses
a + b + c
 2
a +
c + d  1
which we add to get
2a + b + d  2

(26)

In other words, either a is true or b and d both are. The problem is that this is not a
cardinality constraint, and cannot be rewritten as one.
One possibility is to rewrite (26) as a pair of cardinality constraints
a+b  1

(27)

a+d  1

(28)

If, however, we want the result of resolving a pair of constraints to be a single axiom, we
must either select one of the above axioms or extend our language further.
3.3 Learning and Relevance Bounds
The idea of relevance also has a natural generalization to the pseudo-Boolean setting. Recall
the basic definition from Section 2.2:
Definition 3.15 Let c be a clause and P a partial assignment. Then c is i-irrelevant if the
number of literals in c that are either unvalued or true under P is at least i + 1.
Proposition 3.16 Given a partial assignment P and a Boolean clause c, c is i-irrelevant
if and only if poss(c, P )  i.
Proof. In the Boolean case, the number of literals in c that are either unvalued or true is
poss(c, P ) + 1 since the right hand side of the constraint is always 1. So the irrelevance
condition is
poss(c, P ) + 1  i + 1
and the result follows.
In the pseudo-Boolean case, additional learning techniques are also possible. Before
we present these ideas in detail, however, let us point out that some sort of inferential
extension is needed if we are to overcome the shortcomings of dpll as revealed by the
pigeonhole and other problems. After all, recall Proposition 3.14: pseudo-Boolean inference
generalizes Boolean resolution. So if we begin with a Boolean axiomatization (as we did
in the pigeonhole problem), any derivation using our techniques will be reproducible using
conventional resolution-based methods, and will therefore be of exponential length. (A
majority of the inference steps in the various proofs of Proposition 3.2 are not resolution
steps in that no literal cancellations occur.)
218

fiBoolean Satisfiability Survey

Strengthening The specific method that we will discuss is from operations research and
is used to preprocess mixed integer programming problems (Guignard & Spielberg, 1981;
Savelsbergh, 1994).
Suppose that after setting l0 to true and applying some form of propagation to our
P
constraint set, we discover that under this assumption a constraint c given by
wi li  r
becomes oversatisfied by an amount s in that the sum of the left hand side is greater
(by s) than the amount required by the right hand side of the inequality; in the terms
of Definition 3.5, curr(c) = s. The oversatisfied constraint c can now be replaced by the
following:
X
wi li  r + s
(29)
sl0 +
If l0 is true, we know that wi li  r + s, so (29) holds. If l0 is false, then sl0 = s and we
P
still must satisfy the original constraint wi li  r, so (29) still holds. The new constraint
implies the original one, so no information is lost in the replacement.
As we have remarked, the OR community uses this technique during preprocessing.
A literal is fixed, propagation is applied, and any oversatisfied constraint is strengthened.
Consider the following set of clauses:
P

a+b1
a+c1
b+c1
If we set a to false, we must then value both b and c true in order to satisfy the first two
constraints. The third constraint is now oversatisfied and can thus be replaced by
a+b+c2
The power of this method is that it allows us to build more complex axioms from a set
of simple ones. The strengthened constraint will often subsume some or all of the constraints involved in generating it. In this case, the new constraint subsumes all three of the
generating constraints.
Proposition 3.17 Let c be a constraint and P a partial assignment. Then if we can conclude that curr(c)  s for any solution to our overall problem that extends P , we can replace
c with
X
X
s
li +
wi li  r + s
(30)
P

where the first summation is over literals li  P .
Proof. For any truth assignment that extends P , (30) follows from the fact that curr(c) 
s. For any truth assignment P 0 that does not extend P , there is some lj  P that is false
in P 0 , and so
X
li  s
s
P

Combining this with the original constraint c once again produces (30).

219

fiDixon, Ginsberg & Parkes

Instance
2pipe
2pipe-1-ooo
2pipe-2-ooo
3pipe
3pipe-1-ooo
3pipe-2-ooo
3pipe-3-ooo
4pipe

zChaff
sec nodes
0
8994
1
10725
0
6690
7
48433
6
33570
9
41251
11
46504
244 411107

pbchaff
sec nodes
0
8948
1
9534
0
6706
12
57218
9
36589
16
45003
19
57370
263 382750

Table 1: Run time (seconds) and nodes expanded

Learning and inference Before we present some experimental results related to the
effectiveness of pseudo-Boolean inference, we should point out one additional problem that
can arise in this setting. It is possible that for some branch variable v, the result of resolving
the reasons for v and v is a new nogood that is not falsified by the partial assignment
above v in the search space.
As an example (Dixon & Ginsberg, 2002), suppose that we have a partial assignment
{a, b, c, d} and constraints
2e + a + c  2

(31)

2e + b + d  2

(32)

Now we can unit propagate to conclude e by virtue of (31) and e by virtue of (32); it isnt
hard to conclude that the conflict set is a  b in that either a or b must be true if (31) and
(32) are to be simultaneously satisfiable. But if we simply add (31) and (32) and simplify,
we get
a+b+c+d2
which still allows a and b to both be false. This difficulty can be addressed by deriving a
cardinality constraint that is guaranteed to be falsified by the current partial solution being
investigated (Dixon & Ginsberg, 2002); Chai and Kuehlmann (2003) have developed a still
stronger method.
Experimental results Many of the ideas that we have described have been implemented
in the pbchaff satisfiability solver. In an earlier paper (Dixon & Ginsberg, 2002), we compared results obtained using prs, a pseudo-Boolean version of relsat, and those obtained
using relsat (Bayardo & Miranker, 1996). Pbchaff is an updated version of prs that
is modeled closely on zChaff (Moskewicz et al., 2001). It implements watched literals for
cardinality constraints and applies the strengthening idea. Here we compare pbchaffs
performance to its Boolean counterpart zChaff.
Results on some (unsatisfiable) problem instances from the Velev suite discussed at the
beginning of Section 2.1 are shown in Table 1. As can be seen, performance is comparable; pbchaff pays a small (although noticeable) cost for its extended expressivity. The
220

fiBoolean Satisfiability Survey

Instance
hole8.cnf
hole9.cnf
hole10.cnf
hole11.cnf
hole12.cnf
hole20.cnf
hole30.cnf
hole40.cnf
hole50.cnf

zChaff
sec
nodes
0
3544
1
8144
17
27399
339 126962

Preprocess
sec
0
0
0
0
0
0
4
25
95

pbchaff
sec nodes
0
11
0
12
0
17
0
15
0
20
0
34
0
52
0
75
0
95

Table 2: Run time (seconds) and nodes expanded

experiments were run on a 1.5 GHz AMD Athlon processor, and both solvers used the same
values for the various tuning parameters available (relevance and length bounds, etc.).
Results for the pigeonhole problem appear in Table 2. In this case, pbchaff was
permitted to preprocess the problem using strengthening as described earlier in this section.
ZChaff was unable to solve the problem for twelve or more pigeons with a 1000-second
timeout using a 1.5 GHz Athlon processor. Not surprisingly, pbchaff with preprocessing
dramatically outperformed zChaff on these instances.13
3.4 Proof Complexity
We have already shown in Proposition 3.2 that pseudo-Boolean or cardinality-based axiomatizations can produce polynomially sized proofs of the pigeonhole problem. It is also
known that these methods do not lead to polynomially sized proofs of the clique coloring
problem (Bonet et al., 1997; Krajicek, 1997; Pudlak, 1997). The situation with regard to
parity constraints is a bit more interesting.
Let us first point out that it is possible to capture parity constraints, or modularity
constraints generally in a pseudo-Boolean setting:
Definition 3.18 A modularity constraint is a constraint c of the form
X

wi li  n(mod m)

(33)

i

for positive integers wi , n and m.
In the remainder of this section, we show that modularity constraints can be easily
encoded using pseudo-Boolean axioms, and also that constraint sets consisting entirely of
mod 2 constraints are easily solved either directly or using the above encoding, although it
is not clear how to recover the pseudo-Boolean encodings from the Boolean versions.
13. Without preprocessing, the two systems perform comparably on this class of problems. As we have
stressed, representational extensions are of little use without matching modifications to inference methods.

221

fiDixon, Ginsberg & Parkes

Modularity constraints and pseudo-Boolean encodings To encode a modularity
constraint in this way, we first note that we can easily capture an equality axiom of the
form
X
wi li = k
(34)
i

in a pseudo-Boolean setting, simply by rewriting (34) as the pair of constraints
X

wi li  k

i

X

wi li 

X

wi  k

i

i

In what follows, we will therefore feel free to write axioms of the form (34).
We now denote by bxc the floor of x, which is to say the smallest integer not greater
than x, and have:
Proposition 3.19 Suppose that we have a modularity constraint of the form (33). We set
P
w
w = i wi and introduce new variables si for i = 1, . . . , b m
c. Then (33) is equivalent to
X
i

wi li +

X

jwk

msi = m

i

m

+n

(35)

Proof. Reducing both sides of (35) mod m shows that (35) clearly implies (33). For the
P
converse, note if (33) is satisfied, there is some integer s such that i wi li = sm + n.
P
P
w
Further, since i wi li  i wi = w, it follows that sm + n  w, so that s  wn
m  m and
w
thus s  b m
c. We can therefore satisfy (35) by valuing exactly that many of the si to be
true.
Understand that the introduction of new variables here is not part of any intended
inference procedure; it is simply the fashion in which the modularity constraints can be
captured within a pseudo-Boolean setting.
In the case where all of the constraints are parity constraints, we have:
Proposition 3.20 A set of mod 2 constraints can be solved in polynomial time.
Proof. An individual constraint (recall that  corresponds to exclusive or, or addition
mod 2)
l  i li = n
can be viewed simply as defining
l = n  i li
and this definition can be inserted to remove l from the remaining constraints. Continuing
in this way, we either define all of the variables (and can then return a solution) or derive
1 = 0 and can return failure.
This result, which can be thought of as little more than an application of Gaussian
elimination, is also an instance of a far more general result of Schaefers (1978).
Proposition 3.21 A set of mod 2 constraints can be solved in polynomial time using the
pseudo-Boolean axiomatization given by (35).
222

fiBoolean Satisfiability Survey

Proof. The technique is unchanged. When we combine
l+

X

li + 2

X

i

si = n

i

and
l+

li0 + 2

X

X

i

s0i = n0

i

we get
X
i

li +

X

li0 + 2(

X

i

si +

X

i

s0i + l) = n + n0

i

and can now treat l as one of the auxiliary s variables. Eventually, we will get
2

X

si = n

i

for a large (but polynomially sized) set S of auxiliary variables and some n that is either
even or odd. If n is even, we can value the variables and return a solution; if n is odd and
there are k auxiliary variables, we have
X

si =

i

so
X

si 

i

n
2

n+1
2

(36)

since each si is integral. But we also have
2

X

si  2k  n

i

so that
X

si  k 

i

n1
2

(37)

Adding (36) and (37) produces k  k + 1, a contradiction.
Let us point out, however, that if a mod 2 constraint is encoded in a normal Boolean
way, so that x  y  z = 1 becomes
xyz

(38)

x  y  z
x  y  z
x  y  z

(39)

it is not obvious how the pseudo-Boolean analog can be reconstructed. Here is the problem
we mentioned at the beginning of this section: it is not enough to simply extend the
representation; we need to extend the inference methods as well. In fact, even the question
of whether families of mod 2 constraints can be solved in polynomial time by pseudo-Boolean
methods without the introduction of auxiliary variables as in (35) is open. Other authors
have also considered the problem of reasoning with these constraints directly (Li, 2000).
223

fiDixon, Ginsberg & Parkes

Pseudo-Boolean constraints and extended resolution Finally, let us clarify a point
that we made earlier. Given that there is an encoding of a(bc) as a single pseudo-Boolean
clause, how can it be that pseudo-Boolean inference is properly below extended resolution
in the p-simulation hierarchy?
The answer is as follows. While the fact that a  (b  c) is logically equivalent to
2a + b + c  2 allows us to remove one of the variables introduced by extended resolution,
we cannot combine this encoding with others to remove subsequent variables. As a specific
example, suppose that we learn both
a  (b  c)
and
d  (b  c)
and wish to conclude from this that
(a  d)  (b  c)

(40)

There is no single pseudo-Boolean axiom that is equivalent to (40).
3.5 Summary

SAT

cardinality
PB
symmetry

rep. eff.
1
exp
exp

p-simulation
hierarchy
EEE
P?E
P?E

inference
resolution
not unique
uniquely defined

unit
propagation
watched literals
watched literals
watched literals

learning
relevance
relevance
+ strengthening

QPROP

As before, a few notes are in order:
 While both cardinality and pseudo-Boolean representations can be exponentially more
efficient than their Boolean counterpart, it is not clear how often compressions of this
magnitude will occur in practice.
 The entries in the p-simulation column indicate that the pigeonhole problem is easy,
clique coloring remains hard, and the complexity of parity problems is unknown if no
new variables are introduced.
 The cardinality entry for inference is intended to reflect the fact that the natural
resolvent of two cardinality constraints need not be one.
 Pseudo-Boolean systems can use existing learning techniques, augmented with the
strengthening idea.

224

fiBoolean Satisfiability Survey

4. Symmetry
Given that the pigeonhole problem and clique-coloring problems involve a great deal of
symmetry in their arguments, a variety of authors have suggested extending Boolean representation or inference in a way that allows this symmetry to be exploited directly. We
will discuss the variety of approaches that have been proposed by separating them based
on whether or not a modification to the basic resolution inference rule is suggested. In any
event, we make the following definition:
Definition 4.1 Let T be a collection of axioms. By a symmetry of T we will mean any
permutation  of the variables in T that leaves T itself unchanged.
As an example, if T consists of the single axiom x  y, then T is clearly symmetric under
the exchange of x and y. If T contains the two axioms
ax
and
ay
then T is once again symmetric under the exchange of x and y.
Exploiting symmetry without changing inference One way to exploit symmetry is
to modify the set of axioms in a way that captures the power of the symmetry. In the
pigeonhole problem, for example, we can argue that since there is a symmetry under the
exchange of pigeons or of holes, we can assume without loss of generality that pigeon 1 is
in hole 1, and then by virtue of a residual symmetry that pigeon 2 is in hole 2, and so on.
The basic idea is to add so-called symmetry-breaking axioms to our original theory,
axioms that break the existing symmetry without affecting the overall satisfiability of the
theory itself. This idea was introduced by Crawford et al. (1996).
While attractive in theory, there are at least two fundamental difficulties with the
symmetry-breaking approach:
1. Luks and Roy (2002) have shown that breaking all of the symmetries in any particular problem may require the introduction of a set of symmetry-breaking axioms of
exponential size. This problem can be sidestepped by breaking only most of the
symmetries, although little is known about how the set of broken symmetries is to be
selected.
2. Far more serious, the technique can only be applied if the symmetry in question
is global. This is because the basic argument that satisfiability is unaffected by the
introduction of the new axioms requires that there be no additional axioms to consider.
In theoretical problems, global symmetries exist. But in practice, even the addition
of asymmetric axioms that constrain the problem further (e.g., you cant put pigeon 4 in
hole 7) will break the required global symmetry and render this method inapplicable. More
problematic still is the possibility of the symmetries being obscured by replacing the
single axiom
p11  p21
(41)
225

fiDixon, Ginsberg & Parkes

with the equivalent pair
a  p11  p21
and
a  p11  p21
from which (41) can obviously be recovered using resolution. Once again, the symmetry in
the original problem has vanished and the method cannot be applied.
These arguments could perhaps have been anticipated by consideration of our usual
table; since the inference mechanism itself is not modified (and it is possible to break global
symmetries), none of the entries has changed. Let us turn, then, to other techniques that
modify inference itself.
Exploiting symmetry by changing inference Rather than modifying the set of clauses
in the problem, it is also possible to modify the notion of inference, so that once a particular
nogood has been derived, symmetric equivalents can be derived in a single step. The basic
idea is due to Krishnamurthy (1985) and is as follows:
Lemma 4.2 Suppose that T |= q for some theory T and nogood q. If  is a symmetry of
T , then T |= (q).
It is not hard to see that this technique allows the pigeonhole problem to be solved in
polynomial time, since symmetric versions of specific conclusions (e.g., pigeon 1 is not in hole
1) can be derived without repeating the analysis that led to the original. The dependence
on global symmetries remains, but can be addressed by the following modification:
Proposition 4.3 Let T be a theory, and suppose that T 0 |= q for some T 0  T and nogood
q. If  is a symmetry of T 0 , then T |= (q).
Instead of needing to find a symmetry of the theory T in its entirety, it suffices to find a
local symmetry of the subset of T that was actually used in the proof of q.
This idea, which has been generalized somewhat by Szeider (2003), allows us to avoid the
fact that the introduction of additional axioms can break a global symmetry. The problem
of symmetries that have been obscured as in (41) remains, however, and is accompanied by
a new one, the need to identify local symmetries at each inference step (Brown et al., 1988).
While it is straightforward to identify the support of any new nogood q in terms of a
subtheory T 0 of the original theory T , finding the symmetries of any particular theory is
equivalent to the graph isomorphism problem (Crawford, 1992). The precise complexity
of graph isomorphism is unknown, but it is felt likely to be properly between P and N P
(Babai, 1995). Our basic table becomes:

SAT

cardinality
PB
symmetry

rep. eff.
1
exp
exp
1

p-simulation
hierarchy
EEE
P?E
P?E
EEE

inference
resolution
not unique
unique
not in P

QPROP

226

unit
propagation
watched literals
watched literals
watched literals
same as sat

learning
relevance
relevance
+ strengthening
same as sat

fiBoolean Satisfiability Survey

 It is not clear how the representational efficiency of this system is to be described, since
a single concluded nogood can serve as a standin for its image under the symmetries
of the proof that produced it.
 While specific instances of the pigeonhole problem and clique coloring problems can
be addressed using symmetries, even trivial modifications of these problems render
the techniques inapplicable. Hence the appearance of the asterisk in the above table: Textbook problem instances may admit polynomially sized proofs, but most
instances require proofs of exponential length. Parity problems do not seem to be
amenable to these techniques at all.
 As we have remarked, inference using Krishnamurthys or related ideas appears to
require multiple solutions of the graph isomorphism problem, and is therefore unlikely
to remain in P .
We know of no implemented system based on the ideas discussed in this section.

5. Quantification and QPROP
We conclude our survey with an examination of ideas that have been used in trying to
extend the Boolean work to cope with theories that are most naturally thought of using
quantification of some sort. Indeed, as Boolean satisfiability engines are applied to ever
larger problems, many of the theories in question are produced in large part by constructing
the set of ground instances of quantified axioms such as
xyz.[a(x, y)  b(y, z)  c(x, z)]

(42)

If d is the size of the domain from which x, y and z are taken, this single axiom has d3
ground instances. Researchers have dealt with this difficulty by buying machines with more
memory or by finding clever axiomatizations for which ground theories remain manageably
sized (Kautz & Selman, 1998). In general, however, memory and cleverness are both scarce
resources and a more natural solution needs to be found.
We will call a clause such as (42) quantified , and assume throughout this section that the
quantification is universal as opposed to existential, and that the domains of quantification
are finite.14
As we remarked at the beginning of this section, quantified clauses are common in
encodings of realistic problems, and these problems have in general been solved by converting
quantified clauses to standard propositional formulae. The quantifiers are expanded first
(possible because the domains of quantification are finite), and the resulting set of predicates
is then linearized by relabeling all of the atoms so that, for example, a(2, 3) might become
v24 . The number of ground clauses produced is exponential in the number of variables in
the quantified clause.
14. There appears to be no effective alternative but to treat existentially quantified clauses as simple disjunctions, as in (9).

227

fiDixon, Ginsberg & Parkes

5.1 Unit Propagation
Our primary goal here is to work with the quantified formulation directly, as opposed to its
much larger ground translation. Unfortunately, there are significant constant-factor costs
incurred in doing so, since each inference step will need to deal with issues involving the
bindings of the variables in question. Simply finding the value assigned to a(2, 3) might
well take several times longer than finding the value assigned to the equivalent v24 . Finding
all occurrences of a given literal can be achieved in the ground case by simple indexing
schemes, whereas in the quantified case this is likely to require a unification step. While
unification can be performed in time linear in the length of the terms being unified, it is
obviously not as efficient as a simple equality check. Such routine but essential operations
can be expected to significantly slow the cost of every inference undertaken by the system.
Our fundamental point here is that while there are costs associated with using quantified
axioms, there are significant savings as well. These savings are a consequence of the fact that
the basic unit propagation procedure uses an amount of time that scales roughly linearly
with the size of the theory; use of quantified axioms can reduce the size of the theory so
substantially that the constant-factor costs can be overcome.
We will make this argument in two phases. In Section 5.1.1, we generalize a specific
computational subtask that is shared by unit propagation and other satisfiability procedures
such as wsat. We will show this generalization to be NP-complete in a formal sense, and
we call it subsearch for that reason. The specific procedures for unit propagation and as
needed by wsat encounter this NP-complete subproblem at each inference step, and we
show that while subsearch is generally not a problem for randomly generated theories, the
subsearch cost can be expected to dominate the running time on more realistic instances.
In Section 5.1.2, we discuss other consequences of the fact that subsearch is NP-complete.
Search techniques can be used to speed the solution of NP-complete problems, and subsearch
is no exception. We show that quantified axiomatizations support the application of simple
search techniques to the subsearch problem, and argue that realistic examples are likely to
lead to subsearch problems of only polynomial difficulty although existing unit propagation
implementations solve them exponentially.
5.1.1 Subsearch
Each iteration of dpll (or wsat) involves a search through the original theory for clauses
that satisfy some numeric property. The specific examples that we have already seen of this
are the following:
1. In Procedure 2.2 (dpll) (and similarly in wsat), we need to determine if P is a
solution to the problem at hand. This involves searching for an unsatisfied clause.
2. In Procedure 2.3 (unit propagation), we need to find unsatisfied clauses that contain
at most one unvalued literal.
In addition, wsat needs to compute the number of clauses that will become unsatisfied
when a particular variable is flipped.
All of these tasks can be rewritten using the following:

228

fiBoolean Satisfiability Survey

Definition 5.1 Suppose C is a set of quantified clauses, and P is a partial assignment of
values to the atoms in those clauses. We will denote by Sus (C, P ) the set of ground instances
of C that have u literals unvalued by P and s literals satisfied by the assignments in P .15
We will say that the checking problem is that of determining whether Sus (C, P ) 6= . By
a subsearch problem, we will mean an instance of the checking problem, or the problem of
either enumerating Sus (C, P ) or determining its size.
Proposition 5.2 For fixed u and s, the checking problem is NP-complete.
Proof. Checking is in NP, since a witness that Sus (C, P ) 6=  need simply give suitable
bindings for the variables in each clause of C.
To see NP-hardness, we assume u = s = 0; other cases are not significantly different.
We reduce from a binary constraint satisfaction problem (csp), producing a single clause
C and set of bindings P such that S00 (C, P ) 6=  if and only if the original binary csp was
satisfiable. The basic idea is that each variable in the constraint problem will become a
quantified variable in C.
Suppose that we have a binary csp  with variables v1 , . . . , vn and with m binary
constraints of the form (vi1 , vi2 )  ci , where (vi1 , vi2 ) is the pair of variables constrained by
ci . For each such constraint, we introduce a corresponding binary relation ri (vi1 , vi2 ), and
take C to be the single quantified clause v1 , . . . , vn . i ri (vi1 , vi2 ). For the assignment P ,
we set ri (vi1 , vi2 ) to false for all (vi1 , vi2 )  ci , and to true otherwise.
Now note that since P values every instance of every ri , S00 (C, P ) will be nonempty if
and only if there is a set of values for vi such that every literal in i ri (vi1 , vi2 ) is false. Since
a literal ri (vi1 , vi2 ) is false just in the case the original constraint ci is satisfied, it follows
that S00 (C, P ) 6=  if and only if the original csp  was satisfiable.
Before moving on, let us place this result in context. First, and most important, note
that the fact that the checking problem is NP-complete does not imply that qprop is an
unwieldy representation; the subsearch problem does indeed appear to be exponential in
the size of the qprop axioms, but there are exponentially fewer of them than in the ground
case. So, as for similar results elsewhere (Galperin & Wigderson, 1983; Papadimitriou,
1994), there is no net effect on complexity.
Second, the result embodied in Proposition 5.2 appears to be a general phenomenon in
that propagation is more difficult for more compact representations. Our earlier discussion
of cardinality and pseudo-Boolean axioms, for which the complexity of unit propagation
was unchanged from the Boolean case, appears to be much more the exception than the
rule. As we have already remarked, if we extend the pseudo-Boolean representation only
slightly, so that in addition to axioms of the form
X

wi li  k

(43)

i

as in Definition 3.4 we allow axioms such as
X

wi li = k

i

15. In interpreting the expression Sus (C, P ), the set C of clauses and partial assignment P should generally
be clear from context. The superscript refers to the number of satisfied literals because satisfied literals
are super good and the subscript refers to the unvalued literals because unvalued literals arent so
good.

229

fiDixon, Ginsberg & Parkes

(replacing the inequality in (43) with an equality), determining whether a single axiom is
satisfiable becomes weakly NP-complete. Symmetry, the other example we have examined,
involves no effective change in the representational power of a single axiom.
Here is a recasting of unit propagation in terms of Definition 5.1:
Procedure 5.3 (Unit propagation) To compute Unit-Propagate(P ):
1
2
3
4
5

while S00 (C, P ) =  and S10 (C, P ) 6= 
do select c  S10 (C, P )
v  the variable in c unassigned by P
P  P  {v = V : V is selected so that c is satisfied}
return P

It is important to recognize that this recasting is not changing the procedure in any significant way; it is simply making explicit the subsearch tasks that were previously described
only implicitly. The procedure itself is unchanged, and other procedural details such as variable and value choice heuristics are irrelevant to the general point that unit propagation
depends on solving a subsearch instance at every step. Wsat is similar.
5.1.2 Subsearch and quantification
As we discussed in Section 2.1, efficient implementations of sat solvers go to great lengths
to minimize the amount of time spent solving subsearch problems. While the watched literal
idea is the most efficient mechanism known here, we will discuss the problem in terms of
a simpler scheme that maintains and updates poss and curr counts for each clause. As
discussed earlier, this scheme is about half as fast as the watched literal approach, and the
general arguments that we will make can be expected to lead to more than constant-factor
improvements.16
For notational convenience in what follows, suppose that C is a quantified theory and
that l is a ground literal. By Cl we will mean that subset of the clauses in C that include
terms of which l is an instance. If C contains quantified clauses, then Cl will as well; the
clauses in Cl can be found by matching the literal l against the clauses in C.
As discussed in Section 2.1, it is possible to compute Sus (C, P ) once during an initialization phase, and then update it incrementally. In terms of Definition 5.1, the update rule
might be one such as
S00 (C, P 0 ) = S00 (C, P )  S10 (Cl , P )
if the literal l is changed from unvalued to true. P 0 here is the partial assignment after the
update; P is the assignment before. To compute the number of fully assigned but unsatisfied
clauses after the update, we start with the number before, and add newly unsatisfied clauses
(unsatisfied clauses previously containing the single unvalued literal l).
As we argued previously, reorganizing the computation in this way leads to substantial
speedups because the subsearch problem being solved is no longer NP-complete in the size
16. We know of no effective way to lift the watched literal idea to the qprop setting. But as we will see when
we discuss the zap implementation (Dixon et al., 2003a), a still broader generalization allows watched
literals to return in an elegant and far more general way.

230

fiBoolean Satisfiability Survey

of C, but only in the size of Cl or Cl . These incremental techniques are essential to the performance of modern search implementations because the runtime of these implementations
is dominated by the time spent in propagation (i.e., subsearch).
Given that the subsearch computation time is potentially exponential in the size of the
subtheory Cl when the literal l is valued or unvalued, let us now consider the questions of
how much of a concern this is in practice, and of what (if anything) can be done about it.
After all, one of the primary lessons of recent satisfiability research is that problems that
are NP-hard in theory tend strongly not to be exponentially difficult in practice.
Let us begin by noting that subsearch is not likely to be much of an issue for the
randomly generated satisfiability problems that were the focus of research in the 1990s and
drove the development of algorithms such as wsat. The reason for this is that if n is the
number of clauses in a theory C and v is the number of variables in C, then random problems
are difficult only for fairly narrow ranges of values of the ratio n/v (Coarfa, Demopoulos,
San Miguel Aguirre, Subramanian, & Vardi, 2000). For 3-SAT (where every clause in C
contains exactly three literals), difficult random problems appear at n/v  4.2 (Kirkpatrick
& Selman, 1994). For such a problem, the number of clauses in which a particular literal
l appears will be small (on average 3  4.2/2 = 6.3 for random 3-SAT). Thus the size of
the relevant subtheory Cl or Cl will also be small, and while subsearch cost still tends
to dominate the running time of the algorithms in question, there is little to be gained by
applying sophisticated techniques to reduce the time needed to examine a relative handful
of clauses.
For realistic problems, the situation is dramatically different. Here is an axiom from a
logistics domain encoded in satplan style (Kautz & Selman, 1992):
at(o, l, t)  duration(l, l0 , dt) 
between(t, t0 , t + dt)  at(o, l0 , t0 )

(44)

This axiom says that if an object o is at location l at time t and it takes time dt to fly from
l to l0 , and t0 is between t and t + dt, then o cannot be at l0 at t0 .
A given ground atom of the form at(o, l, t) will appear in |t|2 |l| clauses of the above form,
where |t| is the number of time points or increments and |l| is the number of locations. Even
if there are only 100 of each, the 106 axioms created seem likely to make computing Sus (Cl , P )
impractical.
Let us examine this computation in a bit more detail. Suppose that we do indeed have
a variable a = at(O, L, T ) for fixed O, L and T , and that we are interested in counting the
number of unit propagations that will be possible if we set a to true. In other words, we
want to know how many instances of (44) will be unsatisfied and have a single unvalued
literal after we do so.
Existing implementations, faced with this problem (or an analogous one if wsat or
another approach is used), will now consider axioms of the form (44) for o, l and t bound
and as l0 , t0 and dt are allowed to vary. They examine every axiom of this form and simply
count the number of possible unit propagations.
The watched literal idea in isolation cannot help with this problem. If, for example, we
watch only the duration and between predicates in (44), we reduce by half the probability

231

fiDixon, Ginsberg & Parkes

that we need to solve a subsearch problem when a particular variable is valued, but in those
cases where the problem is encountered, it is as fierce as ever.
The existing approach to solving subsearch problems is taken because existing systems
use not quantified clauses such as (44), but the set of ground instances of those clauses.
Computing Sus (C, P ) for ground C involves simply checking each axiom individually; indeed,
once the axiom has been replaced by its set of ground instances, no other approach seems
possible.
Set against the context of a quantified axiom, however, this seems inappropriate. Computing Sus (C, P ) for a quantified C by reducing C to a set of ground clauses and then
examining each is equivalent to solving the original NP-complete problem by generate and
test  and if there is one thing that we can state with confidence about NP-complete problems, it is that generate and test is not in general an effective way to solve them.
Returning to our example with at(O, L, T ) true, we are looking for variable bindings for l0 , dt and t0 such that, amongst duration(L, l0 , dt), between(T, t0 , T + dt) and
at(O, l0 , t0 ), precisely two of these literals are false and the third is unvalued. Proposition 5.2 suggests that subsearch will be exponentially hard (with respect to the number of
quantifiers) in the worst case, but what is it likely to be like in practice?
In practice, things are going to be much better. Suppose that for some possible destination l0 , we know that duration(L, l0 , dt) is false for all dt except some specific value D.
We can immediately ignore all bindings for dt except for dt = D, reducing the size of the
subsearch space by a factor of |t|. If D depended on previous choices in the search (aircraft
loads, etc.), it would be impossible to perform this analysis in advance and thereby remove
the unnecessary bindings in the ground theory.
Pushing this example somewhat further, suppose that D is so small that T + D is
the time point immediately after T . In other words, between(T, t0 , T + D) will always be
false, so that between(T, t0 , T + D) will always be true and no unit propagation will be
possible for any value of t0 at all. We can backtrack away from the unfortunate choice of
destination l0 in our (sub)search for variable bindings for which unit propagation is possible.
Such backtracking is not supported by the generate-and-test subsearch philosophy used by
existing implementations.
This sort of computational savings is likely to be possible in general. For naturally
occurring theories, most of the variables involved are likely to be either unvalued (because
we have not yet managed to determine their truth values) or false (by virtue of the closedworld assumption, Reiter, 1978, if nothing else). Domain constraints will typically be of the
form a1      ak  l, where the premises ai are variables and the conclusion l is a literal
of unknown sign. Unit propagation (or other likely instances of the subsearch problem) will
thus involve finding a situation where at most one of the ai is unvalued, and the rest are
true. If we use efficient data structures to identify those instances of relational expressions
that are true, it is not unreasonable to expect that most instances of the subsearch problem
will be soluble in time polynomial in the length of the clauses involved, as opposed to
exponential in that length.

232

fiBoolean Satisfiability Survey

5.2 Inference and Learning
As in Section 3, working with a modified representation allows certain inference techniques
that are not applicable in the Boolean case.
As an example, suppose that we are resolving
a(A, B)  b(B, C)  c(C)
with
c(C)  d(C, D)
to conclude
a(A, B)  b(B, C)  d(C, D)

(45)

where the capital letters indicate ground elements of the domain as before and the resolvents
are actually ground instances of
a(x, y)  b(y, C)  c(C)

(46)

c(z)  d(z, w)

(47)

and
It is obviously possible to resolve (46) and (47) directly to obtain
a(x, y)  b(y, C)  d(C, w)

(48)

which is more general than (45). For a procedure that learns new nogoods and uses them to
prune the resulting search, the impact of learning the more general (48) can be substantial
and can easily outweigh the cost of the unification step required to conclude that c(C) and
c(z) resolve if z = C. We have also discussed this elsewhere (Parkes, 1999).
There are two new difficulties that arise when we implement these ideas. The first is
a consequence of the fact that resolution can be ambiguously defined for two quantified
clauses. Consider resolving
a(A, x)  a(y, B)
(49)
with
a(A, B)  b(A, B)

(50)

If we unify the first term in (50) with the first term in (49), we obtain a(y, B)  b(A, B) as
the resolvent; if we unify with the second term of (49), we obtain a(A, x)  b(A, B).
In practice, however, this need not be a problem:
Proposition 5.4 Let c1 and c2 be two lifted clauses, and g1 and g2 ground instances that
resolve to produce g. Then there is a unique natural resolvent of c1 and c2 of which g is a
ground instance.
Proof. If there is more than one pair of resolving literals in g1 and g2 the result of the
resolution will be vacuous, so we can assume that there is a single literal l in g1 with l in
g2 . If l is the ith literal in g1 and l the jth literal in g2 , it follows that we can resolve the
original c1 and c2 by unifying the ith literal in c1 and the jth literal in c2 . It is clear that
this resolution will be a generalization of g.
233

fiDixon, Ginsberg & Parkes

What this suggests is that the reasons being associated with literal values be not the
lifted nogoods that are retained as clauses, but ground instances thereof that were initially used to prune the search space and can subsequently be used to break ambiguities in
learning.
The second difficulty is far more substantial. Suppose that we have the axiom
a(x, y)  a(y, z)  a(x, z)
or, in a more familiar form, the usual transitivity axiom
a(x, y)  a(y, z)  a(x, z)
This might be used in reasoning about a logistics problem, for example, if it gave conditions
under which two cities were connected by roads.
Now suppose that we are trying to prove a(A, B) for an A and a B that are far apart
given the skeleton of the relation a that we already know. It is possible that we use resolution
to derive
a(A, x)  a(x, B)  a(A, B)
as we search for a proof involving a single intermediate location, and then
a(A, x)  a(x, y)  a(y, B)  a(A, B)
as we search for a proof involving two such locations, and so on, eventually deriving the
wonderfully concise
a(A, x1 )      a(xn , B)  a(A, B)
(51)
for some suitably large n.
The problem is that if d is the size of our domain, (51) will have dn ground instances
and is in danger of overwhelming our unit propagation algorithm even in the presence of
reasonably sophisticated subsearch techniques. Some technique needs to be adopted to
ensure that this difficulty is sidestepped in practice. One way to do this is to learn not the
fully general (51), but a partially bound instance that has fewer ground instances.
Procedure 5.5 To construct learn(c, g), the nogood that will be learned after a clause c
has been produced in response to a backtrack, with g the ground reason associated with c:
1
2
3
4

while c has a ground instance that is i-irrelevant
do v  a variable in c
bind v to its value in g
return c

We may still learn a nogood with an exponential number of ground instances, but at
least have some reason to believe that each of these instances will be useful in pruning
subsequent search. Note that there is a subsearch component to Procedure 5.5, since we
need to find ground instances of c that are irrelevant. This cost is incurred only once when
the clause is learned, however, and not at every unit propagation or other use.
234

fiBoolean Satisfiability Survey

It might seem more natural to learn the general (51), but to modify the subsearch algorithm used in unit propagation so that only a subset of the candidate clauses is considered.
As above, the most natural approach would likely be to restrict the subsearch to clauses of
a particular irrelevance or better. Unfortunately, this wont help, since irrelevant clauses
cannot be unit. Restricting the subsearch to relevant clauses is no more useful in practice
than requiring that any search algorithm expand only successful nodes.
Before moving on, let us note that a similar phenomenon occurs in the pseudo-Boolean
case. Suppose we have a partial assignment {b, c, d, e} and constraints
a+d+e  1

(52)

a+b+c  2

(53)

Unit propagation now causes the variable a to be simultaneously true (by virtue of (52))
and false (because of (53)). Resolving these reasons together as in Proposition 3.12 gives
us
(54)
b+c+d+e2
The conflict set here is easily seen to be {b, d, e}, and this is indeed prohibited by the
derived constraint (54). But (54) eliminates some additional bad assignments as well, such
as {c, d, e}. Just as in the lifted case, we have learned something about a portion of the
search space that has yet to be examined.
5.3 Summary

SAT

cardinality
PB
symmetry
QPROP

rep. eff.
1
exp
exp
1
exp

p-simulation
hierarchy
EEE
P?E
P?E
EEE
???

inference
resolution
not unique
unique
not in P
in P using reasons

unit
propagation
watched literals
watched literals
watched literals
same as sat
exp improvement

learning
relevance
relevance
+ strengthening
same as sat
+ first-order

As usual, there are a few points to be made.
 There is an important difference in practice between the exponential savings in representation provided by qprop and the savings provided by pseudo-Boolean or cardinality encodings. While the exponential savings in previous cases were mathematical
possibilities that were of uncertain use in practice, the savings provided by qprop can
be expected to be achieved in any axiomatization that is constructed by grounding
out a relative handful of universally quantified physical laws.
 It is not clear whether qprop leads to polynomially sized solutions to the pigeonhole and clique coloring problems. It appears at first blush that it should, since
quantification over pigeons or holes is the qprop analog of the identification of the
corresponding symmetry as in the previous section. We know of no detailed proof in
the literature, however, and our attempts to construct one have been unsuccessful.
Similar remarks apply to parity problems.

235

fiDixon, Ginsberg & Parkes

 Inference in qprop requires the introduction of a (linear complexity) unification step,
and is only uniquely defined if reasons are maintained for the choices made in the
search.
 The exponential savings claimed for unit propagation are obviously an average case
result, as opposed to a worst case one. They are a consequence of the fact that it
is possible to use subsearch as part of unit propagation, as opposed to the generate
and test mechanism used by ground methods.
 In addition to the usual idea of relevance-based learning, quantified methods can
extend the power of individual nogoods by resolving quantified clauses instead of
their ground instances.
Finally, we remark that a representation very similar to qprop has also been used in
Answer Set Programming (asp) (Marek & Truszczynski, 1999; Niemela, 1999) under the
name propositional schemata (East & Truszczynski, 2001, 2002). The approach used in
asp resembles existing satisfiability work, however, in that clauses are always grounded out.
The potential advantages of intelligent subsearch are thus not exploited, although we expect
that many of the motivations and results given here would also apply in asp. In fact, asp
has many features in common with sat:
 In the most commonly used semantics, that of (non-disjunctive) stable model logic
programming (Gelfond & Lifschitz, 1988), the representational power is precisely that
of NP (or N P N P for disjunctive programming).
 Cardinality constraints are allowed (East & Truszczynski, 2002; Simons, 2000).
 Solution methods (Leone, Pfeifer, & et al., 2002; Niemela, 1999; Simons, 2000) use
dpll and some form of propagation.
The most significant difference between conventional satisfiability work and asp with
stable model semantics is that the relevant logic is not classical but the logic of here and
there (Pearce, 1997). In the logic of here and there, the law of the excluded middle does
not hold, only the weaker p  p. This is sufficient for dpll to be applied, but does
imply that classical resolution is no longer valid. As a result, there seems to be no proof
theory for the resulting system, and learning within this framework is not yet understood.
Backjumping is used, but the mechanism does not seem to learn new rules from failed
subtrees in the search. In an analogous way, cardinality constraints are used but cutting
plane proof systems are not. Despite the many parallels between sat and asp, including
the approach in this survey seems to be somewhat premature.

6. Conclusion
Satisfiability algorithms have too often been developed against the framework provided by
either random instances or, worse still, instances that have been designed solely to show
that the technique being proposed has computational merit. The algorithms themselves
have thus tended to ignore problem features that dominate the computational requirements
when they are applied to real problems.
236

fiBoolean Satisfiability Survey

On such realistic problems, it is possible to both improve the speed of the algorithms
inner loops (via qprop and subsearch) and to reduce the number of times that the inner
loops need to be executed (via learning and a move up the p-simulation hierarchy). Both of
these classes of improvements arise because the problems in question have structure. The
structure can be learned as nogoods, or used to re-represent the problem using pseudoBoolean or quantified expressions.
It is true that the table in the previous subsection can be viewed as a survey of recent work on satisfiability, and it is also true that the table can be viewed as a rational
reconstruction of the goals of the researchers who have investigated various representational
extensions. But to our mind, the table is more accurately viewed as a report on the extent
to which these linguistic or semantic modifications successfully capture problem structure.
Every column in the table is about structure. Improved representational efficiency is
only possible if the problem itself has structure that a Boolean axiomatization typically
obscures. It is structure that allows progress to be made in terms of proof complexity. The
structure must be preserved by the basic inference mechanism of the system in question if
it is to remain useful, and qprops ability to speed the inner loop of unit propagation is
a direct consequence of the structure present in the subsearch problem. Finally, learning
itself can be thought of as a search for reasonably concise descriptions of large sections of
the search space that contain no solutions  in other words, learning is the discovery of
structure in the search space itself.
This is the setting against which the next two papers in this series are set. If so much
of the progress in satisfiability techniques can be thought of as structure exploitation, then
surely it is natural to attempt to understand and to exploit that structure directly. As
we will see, not only do the techniques we have discussed work by exploiting structure,
but they all exploit different instances of a single structure. The zap work is an attempt
to understand, generalize and streamline previous results by setting them in this uniform
setting.

Acknowledgments
We would like to thank the members of cirl, the technical staff of On Time Systems,
and Eugene Luks and David Hofer from the CIS department at the University of Oregon
for their assistance with the ideas in this series of papers. We would also like to thank
the anonymous reviewers for their comments and suggestions, which we found extremely
valuable.
This work was sponsored in part by grants from Air Force Office of Scientific Research
(afosr) number F49620-92-J-0384, the Air Force Research Laboratory (afrl) number
F30602-97-0294, Small Business Technology Transfer Research, Advanced Technology Institute (sttr-ati) number 20000766, Office of Naval Research (onr) number N00014-00-C0233, and the Defense Advanced Research Projects Agency (darpa) and the Air Force Research Laboratory, Rome, NY, under agreements numbered F30602-95-1-0023, F30602-971-0294, F30602-98-2-0181, F30602-00-2-0534, and F33615-02-C-4032. The views expressed
are those of the authors.

237

fiDixon, Ginsberg & Parkes

References
Aloul, F., Ramani, A., Markov, I., & Sakallah, K. (2002). PBS: A backtrack search pseudoBoolean solver. In Symposium on the Theory and Applications of Satisfiability Testing.
Babai, L. (1995). Automorphism groups, isomorphism, reconstruction. In Lovasz, L., Graham, R., & Grotschel, M. (Eds.), Handbook for Combinatorics, chap. 27, pp. 1447
1540. North-Holland-Elsevier.
Baker, A. B. (1994). The hazards of fancy backtracking. In Proceedings of the Twelfth
National Conference on Artificial Intelligence.
Barth, P. (1995). A Davis-Putnam based enumeration algorithm for linear pseudoboolean optimization. Tech. rep. MPI-I-95-2-003, Max Planck Institut fur Informatik,
Saarbrucken, Germany.
Barth, P. (1996). Logic-Based 0-1 Constraint Programming, Vol. 5 of Operations Research/Computer Science Interfaces Series. Kluwer.
Baumgartner, P. (2000). FDPLL  A First-Order Davis-Putnam-Logeman-Loveland Procedure. In McAllester, D. (Ed.), CADE-17  The 17th International Conference on
Automated Deduction, Vol. 1831, pp. 200219. Springer.
Bayardo, R. J., & Miranker, D. P. (1996). A complexity analysis of space-bounded learning
algorithms for the constraint satisfaction problem. In Proceedings of the Thirteenth
National Conference on Artificial Intelligence, pp. 298304.
Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques to solve real-world
SAT instances. In Proceedings of the Fourteenth National Conference on Artificial
Intelligence, pp. 203208.
Beame, P., & Pitassi, T. (2001). Propositional proof complexity: Past, present and future.
In Paun, G., Rozenberg, G., & Salomaa, A. (Eds.), Current Trends in Theoretical
Computer Science, Entering the 21th Century, pp. 4270. World Scientific.
Benhamou, B., Sais, L., & Siegel, P. (1994). Two proof procedures for a cardinality based
language in propositional calculus. In Proceedings of STACS94, volume 775 de Lecture
Notes in Computer Science.
Biere, A., Clarke, E., Raimi, R., & Zhu, Y. (1999). Verifying safety properties of a PowerPC microprocessor using symbolic model checking without BDDs. Lecture Notes in
Computer Science, 1633.
Bonet, M. L., Pitassi, T., & Raz, R. (1997). Lower bounds for cutting planes proofs with
small coefficients. Journal of Symbolic Logic, 62 (3), 708728.
Brown, C. A., Finkelstein, L., & Paul Walton Purdom, J. (1988). Backtrack searching in
the presence of symmetry. In Mora, T. (Ed.), Applied Algebra, Algebraic Algorithms
and Error-Correcting Codes, 6th Intl. Conf., pp. 99110. Springer-Verlag.
Bryant, R. E. (1986). Graph-based algorithms for Boolean function manipulation. IEEE
Transactions on Computers, C-35 (8), 677691.
Bryant, R. E. (1992). Symbolic Boolean manipulation with ordered binary-decision diagrams. ACM Computing Surveys, 24 (3), 293318.
238

fiBoolean Satisfiability Survey

Buchberger, B. (1965). Ein Algorithmus zum Auffinden der Basiselemente des Restklassenringes nach einum nulldimensionalen Polynomideal. Ph.D. thesis, University of Innsbruck, Innsbruck.
Buchberger, B. (1985). Grobner bases: An algorithmic method in polynomial ideal theory.
In Bose, N. (Ed.), Multidimensional Systems Theory. D. Reidel, Dordrecht, Holland.
Cadoli, M., Schaerf, M., Giovanardi, A., & Giovanardi, M. (2002). An algorithm to evaluate
quantified boolean formulae and its experimental evaluation. Journal of Automated
Reasoning, 28 (2), 101142.
Chai, D., & Kuehlmann, A. (2003). A fast pseudo-Boolean constraint solver. In Proceedings
of the 40th Design Automation Conference, pp. 830835.
Chandru, V., & Hooker, J. N. (1999). Optimization Mehtods for Logical Inference. WileyInterscience.
Clegg, M., Edmonds, J., & Impagliazzo, R. (1996). Using the Groebner basis algorithm
to find proofs of unsatisfiability. In Proceedings of the Twenty-Eighth Annual ACM
Symp. on Theory of Computing, pp. 174183.
Coarfa, C., Demopoulos, D. D., San Miguel Aguirre, A., Subramanian, D., & Vardi, M.
(2000). Random 3-SAT: The plot thickens. In Proceedings of the International Conference on Constraint Programming.
Cook, S. A. (1971). The complexity of theorem-proving procedures. In Proceedings of the
3rd Annual ACM Symposium on the Theory of Computing, pp. 151158.
Cook, W., Coullard, C., & Turan, G. (1987). On the complexity of cutting-plane proofs.
Discrete Applied Mathematics, 18, 2538.
Copty, F., Fix, L., Giunchiglia, E., Kamhi, G., Tacchella, A., & Vardi, M. (2001). Benefits
of bounded model checking in an industrial setting. In 13th Conference on Computer
Aided Verification, CAV01, Paris, France.
Crawford, J. M. (1992). A theoretical analysis of reasoning by symmetry in first-order logic
(extended abstract). In AAAI Workshop on Tractable Reasoning.
Crawford, J. M., & Auton, L. D. (1996). Experimental results on the crossover point in
random 3SAT. Artificial Intelligence, 81, 3157.
Crawford, J. M., Ginsberg, M. L., Luks, E., & Roy, A. (1996). Symmetry breaking predicates
for search problems. In Proceedings of the Fifth International Conference on Principles
of Knowledge Representation and Reasoning, Boston, MA.
Davis, M., & Putnam, H. (1960). A computing procedure for quantification theory. J.
Assoc. Comput. Mach., 7, 201215.
Davis, M., Logemann, G., & Loveland, D. (1962). A machine program for theorem-proving.
Communications of the ACM, 5 (7), 394397.
Dechter, R. (1990). Enhancement schemes for constraint processing: Backjumping, learning,
and cutset decomposition. Artificial Intelligence, 41, 273312.
Dixon, H. E., & Ginsberg, M. L. (2000). Combining satisfiability techniques from AI and
OR. Knowledge Engrg. Rev., 15, 3145.
239

fiDixon, Ginsberg & Parkes

Dixon, H. E., & Ginsberg, M. L. (2002). Inference methods for a pseudo-Boolean satisfiability solver. In Proceedings of the Eighteenth National Conference on Artificial
Intelligence.
Dixon, H. E., Ginsberg, M. L., Hofer, D., Luks, E. M., & Parkes, A. J. (2003a). Generalizing
Boolean satisfiability III: Implementation. Tech. rep., Computational Intelligence
Research Laboratory, Eugene, Oregon.
Dixon, H. E., Ginsberg, M. L., Luks, E. M., & Parkes, A. J. (2003b). Generalizing Boolean
satisfiability II: Theory. Tech. rep., Computational Intelligence Research Laboratory,
Eugene, Oregon.
Dubois, O., Andre, P., Boufkhad, Y., & Carlier, J. (1993). SAT versus UNSAT. In Second
DIMACS Challenge: Cliques, Colorings and Satisfiability, Rutgers University, NJ.
Dubois, O., & Dequen, G. (2001). A backbone-search heuristic for efficient solving of hard
3-SAT formulae. In Proceedings of the Seventeenth International Joint Conference on
Artificial Intelligence, pp. 248253.
East, D., & Truszczynski, M. (2001). Propositional satisfiability in answer-set programming.
Lecture Notes in Computer Science, 2174.
East, D., & Truszczynski, M. (2002). Propositional satisfiability in declarative programming. Extended version of papers that appeared in Proceedings of AAAI-2000 and
Proceedings of KI-2001. http://xxx.lanl.gov/abs/cs.LO/0211033.
Freeman, J. W. (1995). Improvements to propositional satisfiability search algorithms. Ph.D.
thesis, University of Pennsylvania, PA.
Frost, D., & Dechter, R. (1994). Dead-end driven learning. In Proceedings of the Twelfth
National Conference on Artificial Intelligence, pp. 294300.
Galperin, H., & Wigderson, A. (1983). Succinct representation of graphs. Information and
Control, 56, 183198.
Garey, M., & Johnson, D. (1979). Computers and Intractability. W.H. Freeman and Co.,
New York.
Gaschnig, J. (1979). Performance measurement and analysis of certain search algorithms.
Tech. rep. CMU-CS-79-124, Carnegie-Mellon University.
Gelfond, M., & Lifschitz, V. (1988). The stable semantics for logic programs. In Proceedings
of the 5th International Conference on Logic Programming, pp. 10701080. MIT Press.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal of Artificial Intelligence Research,
1, 2546.
Ginsberg, M. L., & Geddis, D. F. (1991). Is there any need for domain-dependent control
information?. In Proceedings of the Ninth National Conference on Artificial Intelligence.
Ginsberg, M. L., & Parkes, A. J. (2000). Search, subsearch and QPROP. In Proceedings of
the Seventh International Conference on Principles of Knowledge Representation and
Reasoning, Breckenridge, Colorado.

240

fiBoolean Satisfiability Survey

Goldberg, E., & Novikov, Y. (2002). Berkmin: A fast and robust SAT solver. In Design
Automation and Test in Europe (DATE), pp. 142149.
Guignard, M., & Spielberg, K. (1981). Logical reduction methods in zero-one programming.
Operations Research, 29.
Haken, A. (1985). The intractability of resolution. Theoretical Computer Science, 39, 297
308.
Haken, A. (1995). Counting bottlenecks to show monotone P 6= N P . In Proceedings 36th
Annual IEEE Symp. on Foundations of Computer Science (FOCS-95), pp. 3640,
Milwaukee, MN. IEEE.
Hooker, J. N. (1988). Generalized resolution and cutting planes. Annals of Operations
Research, 12, 217239.
Hooker, J. N., & Vinay, V. (1995). Branching rules for satisfiability. J. Automated Reasoning,
15, 359383.
Jeroslow, R., & Wang, J. (1990). Solving the propositional satisfiability problem. Annals
of Mathematics and Artificial Intelligence, 1, 167187.
Joslin, D., & Roy, A. (1997). Exploiting symmetry in lifted CSPs. In Proceedings of the
Fourteenth National Conference on Artificial Intelligence, pp. 197202.
Kautz, H., & Selman, B. (1998). BLACKBOX: A new approach to the application of
theorem proving to problem solving. In Artificial Intelligence Planning Systems: Proceedings of the Fourth International Conference. AAAI Press.
Kautz, H. A., & Selman, B. (1992). Planning as satisfiability. In Proceedings of the Tenth
European Conference on Artificial Intelligence (ECAI92), pp. 359363.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior in the satisfiability of random
Boolean expressions. Science, 264, 12971301.
Krajicek, J. (1997). Interpolation theorems, lower bounds for proof systems, and independence results for bounded arithmetic. J. Symb. Logic, 62 (2), 457486.
Krishnamurthy, B. (1985). Short proofs for tricky formulas. Acta Informatica, 22 (3), 253
275.
Leone, N., Pfeifer, G., & et al. (2002). The DLV system for knowledge representation and
reasoning. Tech. rep. 1843-02-14, Technical University of Vienna.
Li, C. M. (2000). Integrating equivalency reasoning into Davis-Putnam procedure. In
Proceedings of the Seventeenth National Conference on Artificial Intelligence, pp. 291
296.
Li, C. M., & Anbulagan (1997). Heuristics based on unit propagation for satisfiability
problems. In Proceedings of the Fifteenth International Joint Conference on Artificial
Intelligence, pp. 366371.
Luks, E., & Roy, A. (2002). Symmetry breaking in constraint satisfaction. In Intl. Conf. of
Artificial Intelligence and Mathematics, Ft. Lauderdale, Florida.
Marek, V. W., & Truszczynski, M. (1999). Stable models and an alternative logic programming paradigm..
241

fiDixon, Ginsberg & Parkes

McCarthy, J. (1977). Epistemological problems of artificial intelligence. In Proceedings
of the Fifth International Joint Conference on Artificial Intelligence, pp. 10381044,
Cambridge, MA.
McCune, W., & Wos, L. (1997). Otter - the CADE-13 competition incarnations. Journal
of Automated Reasoning, 18 (2), 211220.
Mitchell, D. G. (1998). Hard problems for CSP algorithms. In Proceedings of the Fifteenth
National Conference on Artificial Intelligence, pp. 398405.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
an efficient SAT solver. In 39th Design Automation Conference.
Nemhauser, G., & Wolsey, L. (1988). Integer and Combinatorial Optimization. Wiley, New
York.
Niemela, I. (1999). Logic programs with stable model semantics as a constraint programming
paradigm. Annals of Mathematics and Artificial Intelligence, 25, 241273.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.
Parkes, A. J. (1999). Lifted Search Engines for Satisfiability. Ph.D. thesis, University of
Oregon. Available from http://www.cirl.uoregon.edu/parkes.
Pearce, D. (1997). A new logical characterization of stable models and answer sets. In
Dix, J., Pereira, L., & Przymusinski, T. (Eds.), Non-monotonic Extensions of Logic
Programming, Vol. 1216 of Lecture Notes in Artificial Intelligence, pp. 5770.
Pitassi,
T.
(2002).
Propositional
proof
complexity
lecture
notes.
www.cs.toronto.edu/toni/Courses/Proofcomplexity/Lectures/Lecture1/lecture1.ps
(other lectures titled similarly).
Prestwich, S. (2002). Randomised backtracking for linear pseudo-Boolean constraint problems. In Proceedings of the 4th International Workshop on Integration of AI and
OR Techniques in Constraint Programming for Combinatorial Optimisation Problems
(CPAIOR-02), pp. 720.
Pretolani, D. (1993). Satisfiability and hypergraphs. Ph.D. thesis, Universita di Pisa.
Pudlak, P. (1997). Lower bounds for resolution and cutting planes proofs and monotone
computations. J. Symbolic Logic, 62 (3), 981998.
Puget, J.-F. (1993). On the satisfiability of symmetrical constrained satisfaction problems.
In In J. Komorowski and Z.W. Ras, editors, Proceedings of ISMIS93, pages 350361.
Springer-Verlag, 1993. Lecture Notes in Artificial Intelligence 689.
Reiter, R. (1978). On closed world data bases. In Gallaire, H., & Minker, J. (Eds.), Logic
and Data Bases, pp. 119140. Plenum, New York.
Savelsbergh, M. W. P. (1994). Preprocessing and probing for mixed integer programming
problems. ORSA Journal on Computing, 6, 445454.
Schaefer, T. J. (1978). The complexity of satisfiability problems. In Proceedings of the
Tenth Annual ACM Symposium on the Theory of Computing, pp. 216226.

242

fiBoolean Satisfiability Survey

Selman, B., Kautz, H. A., & Cohen, B. (1993). Local search strategies for satisfiability testing. In Proceedings 1993 DIMACS Workshop on Maximum Clique, Graph Coloring,
and Satisfiability.
Simons, P. (2000). Extending and implementing the stable model semantics.. Research
Report 58, Helsinki University of Technology, Helsinki, Finland.
Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning and dependency-directed
backtracking in a system for computer-aided circuit analysis. Artificial Intelligence,
9, 135196.
Szeider, S. (2003). The complexity of resolution with generalized symmetry rules. In Alt,
H., & Habib, M. (Eds.), Proceedings of STACS03, volume 2607 of Springer Lecture
Notes in Computer Science, pp. 475486.
Tseitin, G. (1970). On the complexity of derivation in propositional calculus. In Slisenko,
A. (Ed.), Studies in Constructive Mathematics and Mathematical Logic, Part 2, pp.
466483. Consultants Bureau.
Urquhart, A. (1995). The complexity of propositional proofs. Bull. Symbolic Logic, 1 (4),
425467.
Velev, M. N., & Bryant, R. E. (2001). Effective use of boolean satisfiability procedures in the
formal verification of superscalar and VLIW. In Proceedings of the 38th Conference
on Design Automation Conference 2001, pp. 226231, New York, NY, USA. ACM
Press.
Walser, J. P. (1997). Solving linear pseudo-Boolean constraint problems with local search.
In Proceedings of the Fourteenth National Conference on Artificial Intelligence, pp.
269274.
Zhang, H., & Stickel, M. E. (2000). Implementing the Davis-Putnam method. Journal of
Automated Reasoning, 24 (1/2), 277296.

243

fiJournal of Artificial Intelligence Research 21 (2004) 429-470

Submitted 07/03; published 04/04

Grounded Semantic Composition for Visual Scenes
Peter Gorniak
Deb Roy

pgorniak@media.mit.edu
dkroy@media.mit.edu

MIT Media Laboratory
20 Ames St.,Cambridge, MA 02139 USA

Abstract
We present a visually-grounded language understanding model based on a study of how
people verbally describe objects in scenes. The emphasis of the model is on the combination
of individual word meanings to produce meanings for complex referring expressions. The
model has been implemented, and it is able to understand a broad range of spatial referring
expressions. We describe our implementation of word level visually-grounded semantics and
their embedding in a compositional parsing framework. The implemented system selects
the correct referents in response to natural language expressions for a large percentage of
test cases. In an analysis of the systems successes and failures we reveal how visual context
influences the semantics of utterances and propose future extensions to the model that take
such context into account.

1. Introduction
We introduce a visually-grounded language understanding model based on a study of how
people describe objects in visual scenes of the kind shown in Figure 1. We designed the study
to elicit descriptions that would naturally occur in a joint reference setting and that are easy
to produce and understand by a human listener. A typical referring expression for Figure 1
might be, the far back purple cone thats behind a row of green ones. Speakers construct
expressions to guide listeners attention to intended objects. Such referring expressions
succeed in communication because speakers and listeners find similar features of the visual
scene to be salient, and share an understanding of how language is grounded in terms of
these features. This work is a step towards our longer term goals to develop a conversational
robot (Hsiao, Mavridis, & Roy, 2003) that can fluidly connect language to perception and
action.
To study the use of descriptive spatial language in a task similar to one our robots
perform, we collected several hundred referring expressions based on scenes similar to Figure
1. We analysed the descriptions by cataloguing the visual features that they referred to
within a scene, and the range of linguistic devices (words or grammatical patterns) that
they used to refer to those features. The combination of a visual feature and corresponding
linguistic device is referred to as a descriptive strategy. The example sentence above contains
several descriptive strategies that make use of colour, spatial relations, and spatial grouping.
These descriptive strategies are used in composition by the speaker to make reference to a
unique object.
We propose a set of computational mechanisms that correspond to the most commonly
used descriptive strategies from our study. The resulting model has been implemented as a
set of visual feature extraction algorithms, a lexicon that is grounded in terms of these visual
c
2004
AI Access Foundation. All rights reserved.

fiGorniak & Roy

Figure 1: A sample scene used to elicit visually-grounded referring expressions (if this figure
has been reproduced in black and white, the light cones are green in colour, the
dark cones are purple)

features, a robust parser to capture the syntax of spoken utterances, and a compositional
engine driven by the parser that combines visual groundings of lexical units. To evaluate
the system, we collected a set of spoken utterances from three speakers. The verbatim transcriptions of the speech, complete with speech repairs and various other ungrammaticalities
common in spoken language, were fed into the model. The model was able to correctly
understand the visual referents of 59% of the expressions (chance performance
assuming
P30
that a random object is selected on each of a sessions 30 trials was 1/30 i=1 1/i = 13%).
The system was able to resolve a range of linguistic phenomena that made use of relatively
complex compositions of spatial semantics. We provide a detailed analysis of the sources
of failure in this evaluation, based on which we propose a number of improvements that
are required to achieve human level performance. In designing our framework we build on
prior work in human reference resolution and integration of semantics during parsing. The
main contribution of this work lies in using visual features based on a study of human visual
and linguistic reference as the grounded semantic core of a natural language understanding
system.
While our previous work on visually-grounded language has centred on machine learning
approaches (Roy, Gorniak, Mukherjee, & Juster, 2002; Roy & Pentland, 2002; Roy, 2002),
we chose not to apply machine learning to the problem of compositional grounded semantics
in this investigation. Rather, we endeavoured to provide a framework that can process the
types of descriptive strategies and compositionality that were found in our study with human
participants. In future work, we will investigate how machine learning methods can be used
to acquire parts of this framework from experience, leading to more robust and accurate
performance.
430

fiGrounded Semantic Composition for Visual Scenes

1.1 Grounded Semantic Composition
We use the term grounded semantic composition to highlight that both the semantics of
individual words and the word composition process itself are visually-grounded. In our
model, each lexical entrys meaning is grounded through an association to a visual model.
For example, green is associated with a probability distribution function defined over a
colour space. We propose processes that combine the visual models of words, governed by
rules of syntax.
Given our goal of understanding and modelling grounded semantic composition, several
questions arise:
 What are the visual features that people use to describe objects in scenes such as
Figure 1?
 How do these features connect to language?
 How do features and their descriptions combine to produce whole utterances and
meanings?
 Are word meanings independent of the visual scene they describe?
 Is the meaning of the whole utterance based only on the meanings of its parts?
 Is composition of meanings a purely incremental process?
We assumed easy answers to some of these questions as a place to start our modelling
effort. Our current implementation assumes that the meaning of a whole utterance is
fully derived from the meanings of its parts, performs composition incrementally (without
backtracking), and does not let the visual context influence the interpretation of word
meanings. Despite these assumptions, the system handles relatively sophisticated semantic
composition. When evaluated on test data, the system correctly understood and chose
appropriate referents for expressions such as, the purple one behind the two green ones
and the left green cone in front of the back purple one.
After analysing our systems performance on human participants utterances, we found
that:
 Word meanings can be strongly dependent on the visual scene they describe. For
instance, we found four distinct visual interpretations for the word middle that are
linguistically indistinguishable, but instead depend on different visual contexts to be
understood.
 The meaning of an utterance may sometimes depend on more than the meanings of
its parts. Its meaning may also depend on the visual context in which the utterance
occurs, which can modify how parts compose. For example, some objects that are
referred to as frontmost left would be referred to neither as left or frontmost
in isolation, nor are they the result of a multiplicative joined estimation of the two.
 Composition of meanings in this task is not a purely incremental process. In some
cases we found it necessary to backtrack and reinterpret parts of the utterance when
431

fiGorniak & Roy

no good referents can be found at a later processing stage, or when ambiguities cannot
be resolved with the current interpretation. Due to a strictly feed forward model of
language understanding, our current implementation fails on such cases.
These results are similar to those reported in prior studies (Brown-Schmidt, Campana,
& Tanenhaus, 2002; Griffin & Bock, 2000; Pechmann, 1989). Although our model does
not currently address these issues of context-dependent interpretation and backtracking, we
believe that the framework and its approach to grounded compositional semantics provide
useful steps towards understanding spatial language. The system performs well in understanding spatial descriptions, and can be applied to various tasks in natural language and
speech based human-machine interfaces.
This paper begins by highlighting several strands of related previous work. In section 2,
we introduce the visual description task that serves as the basis for this study and model.
Section 3 presents our framework for grounded compositional semantics. Section 4 describes
the resulting computational model. An example of the whole system at work is given in
Section 5. We discuss the results of applying our system to human data from the spatial
description task in section 6, together with an analysis of the systems successes and failures.
This leads to suggestions for future work in Section 7, followed by a summary in section 8.
1.2 Related Work
Winograds SHRDLU is a well known system that could understand and generate natural
language referring to objects and actions in a simple blocks world (Winograd, 1970). Like
our system it performs semantic interpretation during parsing by attaching short procedures
to lexical units (see also Miller & Johnson-Laird, 1976). However, SHRDLU had access to a
clean symbolic representation of the scene, whereas the system discussed here works with a
synthetic vision system and reasons over geometric and other visual measures. Furthermore,
we intend our system to robustly understand the many ways in which human participants
verbally describe objects in complex visual scenes to each other, whereas SHRDLU was
restricted to sentences it could parse completely and translate correctly into its formalism.
SHRDLU is based on a formal approach to semantics in which the problem of meaning
is addressed through logical and set theoretic formalisms. Partee provides an overview of
this approach and to the problems of context based meanings and meaning compositionality
from this perspective (Partee, 1995). Our work reflects many of the ideas from this work,
such as viewing adjectives as functions. Pustejovskys theory of the Generative Lexicon
(GL) in particular takes seriously noun phrase semantics and semantic compositionality
(Pustejovsky, 1995). Our approach to lexical semantic composition was originally inspired
by Pustejovskys qualia structures. However, these formal approaches operate in a symbolic
domain and leave the details of non-linguistic influences on meaning unspecified, whereas
we take the computational modelling of these influences as our primary concern.
Research concerning human production of referring expressions has lead to studies related to the one described here, but without computational counterparts. Brown-Schmidt
e.a., for example, engage participants in a free-form dialogue (as opposed to the one-sided
descriptions in our task) producing referential descriptions to solve a spatial arrangement
problem (Brown-Schmidt et al., 2002). Due to the use of more complicated scenes and
complete dialogues, they find that their participants often engage in agreement behaviours
432

fiGrounded Semantic Composition for Visual Scenes

and use discourse and visual context to disambiguate underspecified referring expressions
more often than in our study. Similar tasks have been used in other studies of dialogue
and referring expressions (Pechmann, 1989; Griffin & Bock, 2000). We intentionally eliminated dialogue and used a simpler visual scene and task to elicit spatial descriptions (as
opposed to description by object attributes), and to be able to computationally model the
strategies our participants employ. Formal theories of vagueness support our findings in the
expressions produced by our participants (Kyburg & Morreau, 2000; Barker, 2002).
Word meanings have been approached by several researchers as a problem of associating
visual representations, often with complex internal structure, to word forms. Models have
been suggested for visual representations underlying colour (Lammens, 1994) and spatial
relations (Regier, 1996; Regier & Carlson, 2001). Models for verbs include grounding their
semantics in the perception of actions (Siskind, 2001), and grounding in terms of motor
control programs (Bailey, 1997; Narayanan, 1997). Object shape is clearly important when
connecting language to the world, but remains a challenging problem in computational
models of language grounding. In previous work, we have used histograms of local geometric
features which we found sufficient for grounding names of basic objects (dogs, shoes, cars,
etc.) (Roy & Pentland, 2002). This representation captures characteristics of the overall
outline form of an object that is invariant to in-plane rotations and changes of scale. Landau
and Jackendoff provide a detailed analysis of additional visual shape features that play a
role in language (Landau & Jackendoff, 1993). For example, they suggest the importance of
extracting the geometric axes of objects in order to ground words such as end, as in end
of the stick. Shi and Malik propose an approach to performing visual grouping on images
(Shi & Malik, 2000). Their work draws from findings of Gestalt psychology that provide
many insights into visual grouping behaviour (Wertheimer, 1999; Desolneux, Moisan, &
Morel, 2003). Engbers e.a. give an overview and formalization of the grouping problem
in general and various approaches to its solution (Engbers & Smeulders, 2003). In parallel
with the work presented in this paper, we also been studying visual grouping and will fold
the results into the systen described here (Dhande, 2003).
Our model of incremental semantic interpretation during parsing follows a tradition of
employing constraint satisfaction algorithms to incorporate semantic information starting
with SHRDLU and continued in other systems (Haddock, 1989). Most prior systems use
a declaratively stated set of semantic facts that is disconnected from perception. Closely
related to our work in this area is Schulers (2003), who integrates determination of referents
to the parsing process by augmenting a grammar with logical expressions, much like we
augment a grammar with grounded composition rules (see Section 3.4). Our emphasis,
however, is on a system that can actively ground word and utterance meanings through its
own sensory system. Even though the system described here senses a synthetic scene, it
makes continuous measurements during the parsing process and we are now integrating it
into an active vision system (Hsiao et al., 2003). Schulers system requires a human-specified
clean logical encoding of the world state, which ignores the noisy, complex and difficultto-maintain process linking language to a sensed world. We consider this process, which
we call the grounding process, one of the most important aspects of situated human-like
language understanding.
SAM (Brown, Buntschuh, & Wilpon, 1992) and Ubiquitous Talker (Nagao & Rekimoto,
1995) are language understanding systems that map language to objects in visual scenes.
433

fiGorniak & Roy

Similar to SHDRLU, the underlying representation of visual scenes is symbolic and loses
much of the subtle visual information that our work, and the work cited above, focus
on. Both SAM and Ubiquitous Talker incorporate a vision system, phrase parser and
understanding system. The systems translate visually perceived objects into a symbolic
knowledge base and map utterances into plans that operate on the knowledge base. In
contrast, we are primarily concerned with understanding language referring to the objects
and their relations as they appear visually.
We have previously proposed methods for visually-grounded language learning (Roy &
Pentland, 2002), understanding (Roy et al., 2002), and generation (Roy, 2002). However, the
treatment of semantic composition in these efforts was relatively primitive. For a phrase, the
visual models of each word in the phrase were individually evaluated and multiplied. This
method only works for phrases with conjunctive modifiers, and even in those cases, as we
discuss later, ordering of modifiers sometimes needs to be taken into account (i.e., leftmost
front does not always refer to what front leftmost does). While this simple approach
worked in the constrained domains that we have addressed in the past, it does not scale to
the present task. For example, the Describer system (Roy, 2002) encodes spatial locations
in absolute terms within the frame of reference of a visual scene. As a result, Describer
makes mistakes that humans would not make. Its grounding of the word highest, as an
example, is defined by a probability distribution centred at a specific height in the scene, so
that the object closest to that height is the best example of highest, not accounting for
the fact that there may be objects at greater height (depending on the relative sizes and
shapes of objects). In addition, Describers only interpretation of a phrase like the highest
green rectangle is to find an object that is both close to the center of the probability
distributions for highest and for green, not accounting for the fact that for a human
listener the highest green rectangle need not be high on the screen at all (but only higher
than the other green rectangles). A word such as highest requires a visual binding that
includes some notion of rank ordering. Such a move, however, requires a rethinking of how
to achieve semantic composition, which is addressed in the approach here.

2. A Spatial Description Task
We designed a task that requires people to describe objects in computer generated scenes
containing up to 30 objects with random positions on a virtual surface. The objects all had
identical shapes and sizes, and were either green or purple in colour. Each object had a
50% chance of being green, otherwise it was purple. We refer to this task as the Bishop
task, and to the resulting language understanding model and implemented system simply
as Bishop.
2.1 Motivation for Task Design
In our previous work, we have investigated how speakers describe objects with distinctive
attributes like colour, shape and size in a constraint speaking task and in scenes with a
constant number of objects (Roy, 2002). Speakers in such a task are rarely compelled to
use spatial relations and never use groups of objects, because in most cases objects can
be distinguished by listing their properties. In designing the Bishop task, our goal was
to naturally lead speakers to make reference to spatial aspects of the scene. Therefore,
434

fiGrounded Semantic Composition for Visual Scenes

we drastically increased the number of objects in the scene and decreased the number of
distinctive object attributes. We also let the number of objects vary throughout the trials to
cover both scenes cluttered with objects and scenes with only a few objects in our analysis.
In a variation of the task, we ran experiments in which the system chose objects at
random for the speaker to describer, rather than allowing the describer to make the choice.
We found that this made the task difficult and highly unnatural for the speaker as there
were often few visually salient arrangements that the randomly chosen objects took part
in. As a result, listeners make many more errors in resolving the reference in this variation
of the task (3.5% error when the speaker chose the object versus 13% when the system
chose). There are limits to the accuracy of pure linguistic reference which we appeared to
be reaching in the random selection version of the task. Speakers seemed to have a much
harder time finding visually salient landmarks, leading to long and less natural descriptions,
for example in the centre there are a bunch of green cones, four of them, um, actually there
are more than four, but, ah, theres one thats in the centre pretty much of the pile of them
up to the its at the top, ahm, how can you say this... or the seventh cone from the right
side (followed by the listener counting cones by pointing at the screen). To avoid collecting
such unnatural data, we decided not to use the random selection version of the task.
Another possible variant of the task would be to let the system choose objects in some
non-random manner based on the systems analysis of which objects would be more natural to describe. However, this approach would clearly bias the data towards objects that
matched preexisting models of the system.
Since we are interested in how people described objects spatially as well as which visual
features they found salient, we decided to let the listener pick objects that he or she felt
were concisely yet not trivially describable. We acknowledge that this task design eases
the difficulty of the understanding task; when speakers could not find an interesting object
that was easy to describe in other ways, they resorted to simpler choices like the leftmost
one. Yet, the utterances elicited through this task are relatively complex (see Appendix
A for a complete listing) and and provided serious challenges from an automatic language
understanding perspective.
Scenes were rendered in 3D instead of using an equivalent 2D scene in anticipation of
the transition of the understanding system to a camera driven vision system. The use
of 3D rendering introduces occlusion, shadows, and other sources of ambiguity that must
eventually be addressed if we are to transition to a real vision system. However, we note that
the scene did not include any interesting 3D spatial relations or other features, and that we
do not claim that the description task and thus the system presented here would generalize
directly to a true 3D setting. Furthermore, we did not use any 3D information about the
visual scene, so our system interprets all spatial relations in 2D. This errs on the 2D side
of the ambiguity inherent in a word like leftmost in reference to one of our scenes (the
interpretation can differ due to perspective effects: the leftmost object when interpreting
the scene as 2D might not be the leftmost when interpreting it as 3D. We believe the
task and the types of visually grounded descriptions it produced were challenging for a
computational system to understand, as we hope to show in the remainder of this paper.
Finally, we should note that our goal was not to design a task to study collaboration,
dialogue and agreement, which is the goal of other experiments and analyses (Carletta &
Mellish, 1996; Eugenio, Jordan, Thomason, & Moore, 2000). We use a speaker/listener dyad
435

fiGorniak & Roy

to ensure that the descriptions produced are understandable to a human listener, but we
purposefully did not allow listeners to speak. Their only feedback channel to speakers was
the successful or unsuccessful selection of the described object. While this does introduce
a minimal form of dialogue, the low error rate of listeners leads us to believe that negative
reinforcement was negligible for all speakers and that the task should not be viewed as
an exercise in collaboration. We cannot rule out that listeners adopted strategies used by
their partners when it was their turn to speak. However, the relative similarity of strategies
between pairs shows that this phenomenon does not make the data unrepresentative, and
even produces the types of shortenings and vagueness that we would expect to see in an
extended description task when speaking to a machine.
2.2 Data Collection
Participants in the study ranged in age from 22 to 30 years, and included both native and
non-native English speakers. Pairs of participants were seated with their backs to each
other, each looking at a computer screen which displayed identical scenes such as that in
Figure 1. In each pair, one participant served as describer, and the other as listener. The
describer wore a microphone that was used to record his or her speech. The describer used
a mouse to select an object from the scene, and then verbally described the selected object
to the listener. The listener was not allowed to communicate verbally or otherwise at all,
except through object selections. The listeners task was to select the same object on their
own computer display based on the verbal description. If the selected objects matched, they
disappeared from the scene and the describer would select and describe another object. If
they did not match, the describer would re-attempt the description until understood by
the listener. Using a describer-listener dyad ensured that speech data resembled natural
communicative dialogue. Participants were told they were free to select any object in the
scene and describe it in any way they thought would be clear. They were also told not to
make the task trivial by, for example, always selecting the leftmost object and describing
it as leftmost. The scene contained 30 objects at the beginning of each session, and a
session ended when no objects remained, at which point the describer and listener switched
roles and completed a second session (some participants fulfilled a role multiple times). We
found that listeners in the study made extremely few mistakes in interpreting descriptions,
and seemed to generally find the task easy to perform.
Initially, we collected 268 spoken object descriptions from 6 participants. The raw
audio was segmented using our speech segmentation algorithm based on pause structure
(Yoshida, 2002). Along with the utterances, the corresponding scene layout and target
object identity were recorded together with the times at which objects were selected. This
268 utterance corpus is referred to as the development data set. We manually transcribed
each spoken utterance verbatim, retaining all speech errors (false starts and various other
ungrammaticalities). Rather than working with grammatically controlled language, our
interest was to model language as it occurs in conversational settings since our longer term
goal is to transplant the results of this work into conversational robots where language
will be in spoken form. Off-topic speech events (laughter, questions about the task, other
remarks, and filled pauses) were marked as such (they do not appear in any results we
report).
436

fiGrounded Semantic Composition for Visual Scenes

We developed a simple algorithm to pair utterances and selections based on their time
stamps. This algorithm works backwards in time from the point at which the correct
object was removed from the scene. It collects all on-topic utterances that occurred before
this removal event and after the previous removal event and that are not more than 4
seconds apart. It fuses them into a single utterance, and sends the scene description, the
complete utterance and the identity of the removed object to the understanding system.
The utterance fusing is necessary because participants often paused in their descriptions.
At the same time, pauses beyond a certain length usually indicated that the utterances
before the pause contained errors or that a rephrase occurred. This pairing algorithm is
obviously of a heuristic nature, and we mark instances where it makes mistakes (wrongly
leaving out utterances or attributing utterances to the wrong selection event) in the analysis
of our data below. When we report numbers of utterances in data sets in this paper, they
correspond to how many utterance-selection pairs our pairing algorithm produces. This
means that due to errors by this algorithm the numbers of utterances we report are not
divisible by 30, the actual number of objects selected in each session.
The development corpus was analysed to catalogue the range of common referring strategies (see Section 2.3). This analysis served as a basis for developing a visually-grounded
language understanding system designed to replace the human listener in the task described
above. Once this implementation yielded acceptable results on the development corpus, we
collected another 179 spoken descriptions from three additional participants to evaluate generalization and coverage of our approach. We used exactly the same equipment, instructions
and collection protocol as in collecting the development data to collect the test data. The
average length of utterances in both the development and the test set was between 8 and
9 words. The discussion and analysis in the following sections focuses on the development
set. In Section 6 we discuss performance on the test set.
2.3 Descriptive Strategies for Achieving Joint Reference
As we noted earlier, we call a combination of a visual feature measured on the current scene
(or, in the case of anaphora, on the previous scene) together with its linguistic realization
a descriptive strategy. In this section, we catalogue the most common strategies that describers used to communicate to listeners. This analysis is based strictly on the development
data set. We discuss how our implemented system handles these categories in Section 4.
We distinguish three subsets of our development data:
 A set containing those utterance/selection pairs that contain errors. An error can be
due to a repair or mistake on the human speakers part, a segmentation mistake by
our speech segmenter, or an error by our utterance/selection pairing algorithm.
 A set that contains those utterance/selection pairs that employ descriptive strategies
other than those we cover in our computational understanding system (we cover those
in Sections 2.3.1 to 2.3.5).
 The set of utterance/selection pairs in the development data that are not a member
of either subset described above. We refer to this subset as the clean set.
437

fiGorniak & Roy

Note that the first two subsets are not mutually exclusive. In the following sections,
we report two percentages for each descriptive strategy. The first is the percentage of
utterance/selection pairs that employ a specific descriptive strategy relative to all the utterance/selection pairs in the development data set. The second is the percentage of utterance/selection pairs relative to the clean set of utterance/selection pairs, as described above.
All examples given in this paper are actual utterances and scenes from our development
and test sets.
2.3.1 Colour
Almost every utterance employs colour to pick out objects. While designing the task, we
intentionally trivialized the problem of colour reference. Objects come in only two distinct
colours, green and purple. Unsurprisingly, all participants used the terms green and
purple to refer to these colours. In previous work we have addressed the problems of
learning visually-grounded models of colour words (Roy & Pentland, 2002; Roy, 2002).
Here, our focus is semantic compositionality of terms, so we chose to simplify the colour
naming problem. Figure 2 shows one of the few instances where only colour is used to pick
out a referent. Most of the examples in subsequent sections will be of colour composed with
other descriptive strategies.
Syntactically, colours are expressed through adjectives (as mentioned: green and purple) that always directly precede the nouns they modify. That is, nobody ever said the
green left one in the data, but rather adjectives would commonly occur in the order the
left green one.
In our data, green and purple can also sometimes take the roles of nouns, or at least
be left dangling in a noun phrase with an ellipse like the leftmost purple. Although this
form of dangling modifier might seem unlikely, it does occur in spoken utterances in our
task. As the only objects in Bishop are cones, participants had no trouble understanding
such ellipsis, which occur in 7% of the data.
Participants used colour to identify one or more objects in 96% of the data, and 95% of
the clean data.

the purple cone
Figure 2: Example utterance using only colour

438

fiGrounded Semantic Composition for Visual Scenes

2.3.2 Spatial Regions and Extrema
The second most common descriptive strategy is to refer to spatial extremes within groups
of objects and to spatial regions in the scene. The left example in Figure 3 uses two spatial
terms to pick out its referent: closest and in the front, both of which leverage spatial
extrema to direct the listeners attention. In this example, selection of the spatial extremum
appears to operate relative to only the green objects, i.e. the speaker seems to first attend
to the set of green cones, then choose amongst them. Alternatively, closest and in the
front could pick several objects of any colour, and the colour specification could then filter
these spatial extrema to determine a final referent. In this case the two interpretations yield
the same referent, but there are cases in the corpus in which the second alternative (spatial
selection followed by colour selection) yields no referents at all.

the green one thats closest to us in the
front

the purple one on the left side

Figure 3: Example utterances specifying objects by referring to spatial extrema
The right example in Figure 3 shows that phrases not explicitly indicating spatial extrema are still sometimes intended to be interpreted as referring to extrema. If the listener
was to interpret on the left side as referring to the left side of the scene, the phrase would
be ambiguous since there are four purple cones on the left side of the scene. On the other
hand, the phrase is unambiguous if interpreted as picking out an extremum. Figure 4 shows
an instance where on the right hand side actually refers to a region on the board. The
first example in that figure shows the phrase on the right hand side combined with an
extremum term, lowest. Note that the referent is not the right extremum. In the second
example in Figure 4, the referent is not the bottommost green object, and, (arguably,
if taking the scene as existing in 3D), neither is it the leftmost. Regions on the board
seem to play a role in both cases. Often the local context of the region may play a stronger
role than the global one, as the referent in the second example in Figure 4 can be found
by attending to the front left area of the scene, then selecting the left bottom example
amongst the candidates in this area. Along the same lines, words like middle are largely
used to describe a region on the board, not a position relative to other cones.
Being rather ubiquitous in the data, spatial extrema and spatial regions are often used
in combination with other descriptive strategies like grouping, but are most frequently
combined with other extrema and region specifications. As opposed to when combined with
colour adjectives, multiple spatial specifications tend to be interpreted in left to right order,
that is, selecting a group of objects matching the first term, then amongst those choosing
objects that match the second term. The examples in Figure 4 could be understood as
439

fiGorniak & Roy

the lowest purple on the right hand side

the green cone at the left bottom

Figure 4: Example utterances specifying regions

the purple one in the front left corner
Figure 5: Extrema in sequence
simply ignoring the order of spatial specifications and instead finding a conjoined best fit, i.e.
the best example of both bottommost and leftmost. However, Figure 5 demonstrates
that this is not generally the case. This scene contains two objects that are best fits to
an unordered interpretation of front left, yet the human participant confidently picks the
front object. Possible conclusions are that extrema need to be be interpreted in sequence,
or that participants are demonstrating a bias preferring front-back features over left-right
ones. In our implementation, we choose to sequence spatial extrema in the order they occur
in the input.
Participants used single spatial extrema to identify one or more objects in 72% of the
data, and in 78% of the clean data. They used spatial region specifications in 20% of the
data (also 20% of the clean data), and combined multiple extrema or regions in 28% (30%
of the clean data).
2.3.3 Grouping
To provide landmarks for spatial relations and to specify sets of objects to select from, participants used language to describe groups of objects. Figure 6 shows two examples of such
grouping constructs, the first using an unnumbered group of cones (the green cones), the
second using a count to specify the group (three). The function of the group is different
in the two examples: in the left scene the participant specifies the group as a landmark
to serve in a spatial relation (see Section 2.3.4), whereas in the right scene the participant
first specifies a group containing the target object, then utters another description to select
within that group. Note that grouping alone never yields an individual reference, so participants compose grouping constructs with further referential tactics (predominantly extrema
and spatial relations) in all cases.
440

fiGrounded Semantic Composition for Visual Scenes

the purple cone in the middle to the left
of the green cones

theres three on the left side; the one in
the furthest back

Figure 6: Example utterances using grouping

Participants used grouping to identify objects in 12% of the data and 10% of the clean
data. They selected objects within described groups in 7.5% of the data (8% of the clean
data) and specified groups by number of objects (two, three, ...) in 8.5% of the data
(also 8.5% of the clean data).
2.3.4 Spatial Relations
As already mentioned in Section 2.3.3, participants sometimes used spatial relations between
objects or groups of objects. Examples of such relations are expressed through prepositions
like below or behind as well as phrases like to the left of or in front of. We already
saw an example of a spatial relation involving a group of objects in Figure 6, and Figure 7
further shows two examples that involve spatial relations between individual objects. The
first example is one of the few examples of pure spatial relations between two individual
objects referenced only by colour. The second example is a more typical one where the
spatial relation is combined with another strategy, here an extremum (as well as two speech
errors by the describer).

the green cone below the green cone

theres a purple cone thats its all the
way on the left hand side but its its
below another purple

Figure 7: Example utterances specifying spatial relations

Participants used spatial relations in 6% of the data (7% of the clean data).
441

fiGorniak & Roy

2.3.5 Anaphora
In a number of cases participants used anaphoric references to the previous object removed
during the description task. Figure 8 shows a sequence of two scenes and corresponding
utterances in which the second utterance refers back to the object selected in the first.

the closest purple one on the far left
side

the green one right behind that one

Figure 8: Example sequence of an anaphoric utterance

Participants employed spatial relations in 4% of the data (3% of the clean data).
2.3.6 Other
In addition to the phenomena listed in the preceding sections, participants used a small
number of other description strategies. Some that occurred more than once but that we
have not yet addressed in our computational model are selection by distance (lexicalised as
close to or next to), selection by neighbourhood (the green one surrounded by purple
ones), selection by symmetry (the one opposite that one), and selection by something
akin to local connectivity (the lone one). There are also additional types of groupings, for
example grouping by linearity (the row of green ones, the three purple on a diagonal)
and picking out objects within a group by number (the second one from the left in the row
of five purple ones) that we do not cover here. Each of these strategies occurs less often
in the data than anaphora does (it occurs in 4% of utterances, see the previous section).
We annotated 13% of our data as containing descriptive strategies other than the ones
covered in the preceding sections. However, these other devices are often combined with
the phenomena covered here. We marked 15% of our data as containing errors. Errors
come in the form of repairs by the speaker, as faulty utterance segmentation by our speech
segmenter, or through the misaligning of utterances with scenes by our system.
There are also a few instances of participants composing semantic phenomena in ways
that we do not handle. There were two instances of combining spatial relations (the one
below and to the right) and a few instances of specifying groups by spatial extrema and
regions (the group of the purple ones on the left). We did not count these as other in
our evaluation, but rather we counted them as errors; the reported success rate is correspondingly lower.
442

fiGrounded Semantic Composition for Visual Scenes

2.4 Summary
The preceding sections catalogue strategies participants employed in describing objects. A
computational system that understands utterances using these strategies must fulfill the
following requirements:
 The system must have access to the visual scene and be able to compute visual
features like those used by human speakers: natural groupings, inter-object distances,
orderings and spatial relations
 It must have a robust language parsing mechanism that discovers grammatical patterns associated with descriptive strategies
 Feeding into the parsing mechanism must be a visually grounded lexicon; each entry
in this lexicon must carry information as to which descriptive strategies it takes part
in, and how these descriptive strategies combine with others
 The semantic interpretation and composition machinery must be embedded into the
parsing process
 The system must be able to interpret the results of parsing an utterance and make a
best guess as to which object the whole utterance describes
We go on to describe our systems understanding framework, consisting of the visual
system, grounded lexical entries and the parser in Section 3. In Section 4 we discuss the
modules we implemented to understand human descriptive strategies.

3. The Understanding Framework
In this section we describe the components of our Bishop understanding system in detail,
with emphasis on how they fit together to work as a visually grounded understanding
system. We cover in turn Bishops vision system, its parser and lexicon and give a short
overview of how our implementation of descriptive strategies fits into the framework.
3.1 Synthetic Vision
Instead of relying on the information we use to render the scenes in Bishop, which includes
3D object locations and the viewing angle, we implemented a simple synthetic vision algorithm. This algorithm produces a map attributing each pixel of the rendered image to one
of the objects or the background. In addition, we use the full colour information for each
pixel drawn in the rendered scene. Our goal is to loosely simulate the view of a camera
pointed at a scene of real world objects, the situation our robots find themselves in. We
have in the past successfully migrated models from synthetic vision (Roy, 2002) to computer
vision (Roy et al., 2002) and plan on a similar route to deploy Bishop. Obviously, many of
the hard problems of object detection as well as lighting and noise robustness do not need
to be solved in the synthetic case, but we hope that the transfer back to a robots camera
will be made easier by working from a 2D image. We chose to work in a virtual world for
this project so that we could freely change colour, number, size, shape and arrangement of
443

fiGorniak & Roy

objects to elicit interesting verbal behaviours in our participants, without running into the
limitations of object detection algorithms or field of view problems.
Given an input image in which regions corresponding to objects have been segmented,
the features produced by the vision system are:
average RGB colour the average of the red, green and blue components of all the pixels
attributed to an object
centre of mass the average of the x and y pixel positions of an object
distance the euclidean distance between pairs of objects centres of mass
groups the groups of objects in the scene as determined by finding all sets of objects
that contain more than one object, and in which each object is less than a threshold
distance from another object in the group (distances are measured between centres of
mass)
pairs the same as groups, but filtered to produce only groups of two objects
triplets the same as groups, but filtered to produce only groups of three objects
convex hull the set of pixels forming the smallest convex region enclosing a set of objects
attentional vector sum (AVS) The AVS is a spatial relation measure between to objects. At extreme parameter settings it measures one of two angles, that formed
by the centres, the other formed by the closest points of two objects. We use a
parameter setting ( = 0.7) in between these two extremes, which produces an intermediate angle depending on the objects shape. The resulting direction is measured relative to a set of reference angles, in our system the four Cartesian vectors
(0, 1), (0, 1), (1, 0), (1, 0) (Regier & Carlson, 2001).
3.2 Knowledge Representation
Objects are represented as integer IDs in our system. For each ID or set of IDs the vision
system can compute the visual features described in Section 3.1 based on the corresponding
set of pixels in the image. The distinguishing ID together with the visual features represents
the systems total knowledge of the objects present in the scene. The system can further
instantiate new objects in the vision system from the convex hull of groups of other objects.
The system also remembers the ID of the object removed last, and can ask the vision
system to perform a feature computation on the visual scene as it was before the object
was removed.
Groups of objects have their own integer IDs so they can be treated as objects themselves
(all visual features are available for them). Their IDs are stored together with a list of their
constituent objects IDs, so that groups can be broken apart when necessary.
Finally, as visible in the lexicon file in Appendix B, each lexical item is stored with a set
of associated parameters. These parameters specify grammatical type, compositional arity
and reference behaviour (what the word sense can be taken as referring to on its own: a
single object, a group of objects or no objects.) Furthermore, the lexical item is associated
444

fiGrounded Semantic Composition for Visual Scenes

with a semantic composer (see Sections 3.3 and 4) which store their own sets of parameters,
such as those specifying a Gaussian together with its applicable dimensions in the case of
probabilistic composers.
3.3 Lexical Entries and Concepts
Conceptually, we treat lexical entries like classes in an object oriented programming language. When instantiated, they maintain an internal state that can be as simple as a tag
identifying the dimension along which to perform an ordering, or as complex as multidimensional probability distributions. Each entry also has a function interface that specifies how
it performs semantic composition. Currently, the interface definition consists of the number
and arrangement of arguments the entry is willing to accept, whereas type mismatches are
handled during composition rather than being enforced through the interface. Finally, each
entry can contain a semantic composer that encapsulates the actual function to combine
this entry with other constituents during a parse. These composers are described in-depth
in Section 4. The lexicon used for Bishop contains many lexical entries attaching different
semantic composers to the same word. For example, left can be either a spatial relation
or an extremum. The grammatical structure detected by the parser (see the next Section)
determines which compositions are attempted in a given utterance.
During composition, structures representing the objects that a constituent references
are passed between lexical entries. We refer to these structures as concepts. Each entry
accepts zero or more concepts, and produces zero or more concepts as the result of the
composition operation. A concept lists the entities in the world that are possible referents
of the constituent it is associated with, together with real numbers representing their ranking
due to the last composition operation. A composer can also mark a concept as referring to
a previous visual scene, to allow for anaphoric reference (see Section 4.5). It also contains
flags specifying whether the referent should be a group of objects or a single object (cones
vs. cone), and whether it should uniquely pick out a single object or is ambiguous in
nature (the vs. a). These flags are used in the post-processing stage to determine
possible ambiguities and conflicts.
Our lexicon, based on the development corpus, contains 93 words: 33 ADJ (adjectives), 2 CADJ (colour adjectives: green, purple), 38 N (nouns), 2 REL (relative
pronouns: that, which), 1 VPRES (present tense verbs: is), 2 RELVPRES (relative pronoun/present tense verb combinations: thats, its), 1 ART (the), 3 SPEC
(adjective specifiers: right (as in right above), just), 7 P (prepositions), 4 specific
prepositions (POF, PAT, and two versions of PIN). The complete lexicon specification is
reproduced in Appendix B.
3.4 Parsing
While in previous work we have used Markov models to parse and generate utterances
(Roy, 2002), we here employ to context free grammars. These grammars naturally let us
specify local compositional constraints and iterative structures. Specifically, they allow us to
naturally perform grounded semantic composition whenever a grammar rule is syntactically
complete, producing partial understanding fragments at every node of the parse tree. The
parse structure of an utterance thus dictates which compositions are attempted. We use a
445

fiGorniak & Roy

bottom-up chart parser to guide the interpretation of phrases (Allen, 1995). Such a parser
has the advantage that it employs a dynamic programming strategy to efficiently reuse
already computed subtrees of the parse. Furthermore, it produces all sub-components of a
parse and thus produces a useable result without the need to parse to a specific symbol.
By using a dynamic programming approach we are assuming that meanings of parts can
be assembled into meanings of wholes. We are not strictly committed to this assumption
and in the future will consider backtracking strategies as necessary. Also note that due
to the fact that our framework often produces functions to be applied at later stages of
interpretation (see section 4) we avoid some possible overcommitting decisions (excluding
the correct referent at an early stage of understanding).
Bishop performs only a partial parse, a parse that is not required to cover a whole
utterance, but simply takes the longest referring parsed segments to be the best guess.
Unknown words do not stop the parse process. Rather, all constituents that would otherwise
end before the unknown word are taken to include the unknown word, in essence making
unknown words invisible to the parser and the understanding process. In this way we recover
essentially all grammatical chunks and relations that are important to understanding in our
restricted task. For an overview of related partial parsing techniques, see the work of Abney
(1997).
The grammar used for the partial chart parser is shown in Figure 1. Together with
the grammar rules the table shows the argument structures associated with each rule. In
the given grammar there is only one argument structure per rule, but there can be any
number of argument structures. In the design of our grammar we were constrained by
the compositions that must occur when a rule is applied. This can especially be seen for
prepositional phrases, which must occur in a rule with the noun phrase they modify. The
chart parser incrementally builds up rule fragments in a left to right fashion during a parse.
When a rule is syntactically complete, it checks whether the composers of the constituents
in the tail of the rule can accept the number of arguments specified in the rule (as shown
in the last column of Table 1). If so, it calls the semantic composer associated with the
constituent with the concepts yielded by its arguments to produce a concept for the head
of the rule. If the compose operation fails for any reason (the constituent cannot accept
the arguments or the compose operation does not yield a new concept) the rule does not
succeed and does not produce a new constituent. If there are several argument structures
(not the case in the final grammar shown here) or if a compose operation yields several
alternative concepts, several instances of the head constituent are created, each with its
own concept.
We provide an example chart produced by this grammar in Figure 10 in Section 5, as
part of an example of the whole understanding process. The composition actions associated
with each lexical item, and thus with each rule completion using this grammar, are listed
in Appendix B.
3.5 Post-Parse Filtering
Once a parse has been performed, a post-parse filtering algorithm picks out the best interpretation of the utterance. First, this algorithm extracts the longest constituents from
the chart that are marked as referring to objects, assuming that parsing more of the utter446

fiGrounded Semantic Composition for Visual Scenes

ADJ
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
P
P
P





















T0
ADJ
ADJ
CADJ
N
ART
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
NP
SPEC
P
POF

T1
ADJ
NP
N

T2

NP
P
P
RELVPRES
P
REL
REL
REL
RELVPRES
REL
RELVPRES
REL
P
P

NP
ART
P
N
VPRES
P
VPRES
P
VPRES
ADJ
CADJ

T3

T4

T5

T6

N
ART
POF
NP
NP
P
NP
ADJ

POF
N
NP

NP
POF

NP

NP

Arg Structure
T1 (T0 )
T0 (T1 )
T0 (T1 )
T0 ()
T0 (T1 )
T1 (T0 , T2 )
T3 (T0 , T5 )
T3 (T0 , T5 )
T2 (T0 , T4 )
T1 (T0 , T3 )
T2 (T0 , T3 )
T3 (T0 , T4 )
T2 (T0 , T3 )
T3 (T0 )
T2 (T0 )
T2 (T0 )
T0 (T1 )
T1 ()
T0 ()

Table 1: Grammar used in Bishop
ance implies better understanding. The filtering process then checks these candidates for
consistency along the following criteria:
 All candidates must either refer to a group or to a single object
 If the candidates are marked as referring to an unambiguously specified single object,
they must unambiguously pick a referent
 The referent in the specified single object case must be the same across all candidates
 If the candidates are marked as selecting a group, each must select the same group
If any of these consistency checks fail, the filtering algorithm can provide exact information as to what type of inconsistency occurred (within-group ambiguity, contradicting
constituents, no object fulfilling the description), which constituents were involved in the
inconsistency and which objects (if any) are referenced by each candidate constituent. In
the future, we plan to use this information to resolve inconsistencies through active dialogue.
Currently, we enforce a best single object choice after the post processing stage. If the
filtering yields a single object, nothing needs to be done. If the filtering yields a group
of objects, we choose the best matching object (note that in this case we ignore the fact
of whether the resulting concept is marked as referring to a group or a single object). If
several inconsistent groups of referents remain after filtering, we randomly pick one object
from the groups.
447

fiGorniak & Roy

4. Semantic Composition
In this section we revisit the list of descriptive strategies from Section 2.3 and explain
how we computationally capture each strategy and its composition with other parts of the
utterance. Most of the composers presented follow the same composition schema: they take
one or more concepts as arguments and yield another concept that references a possibly
different set of objects. Concepts reference objects with real numbered values indicating
the strength of the reference. Composers may introduce new objects, even ones that do
not exist in the scene as such, and they may introduce new types of objects (e.g. groups
of objects referenced as if they were one object). To perform compositions, each concept
provides functionality to produce a single referent, or a group of referents. The single
object produced is simply the one having maximum reference strength, whereas a group is
produced by using a reference strength threshold below which objects are not considered as
possible referents of this concept. The threshold is relative to the minimum and maximum
reference strength in the concept. Most composers first convert an incoming concept to the
objects it references, and subsequently perform computations on these objects.
Furthermore, composers can mark concepts as not referring, as referring to a single
object or as referring to a group of objects. This is independent of the actual number of
objects yielded by the concept, and can be used to identify misinterpretations and ambiguities. We currently use these flags to delay composition with arguments that do not refer
to objects. For example, this constraint prevents the left green to cause any composition when green is considered to be an adjective. For such cases, new chaining semantic
composers are created that delay the application of a whole chain of compositions until a
referring word is encountered. These chaining composers internally maintain a queue of
composers. If during the argument for a composition operation does not refer to an object,
both the composer producing the argument and the composer accepting it are pushed onto
the queue. When the first referring argument is encountered, the whole queue of composers
is executed starting with the new argument and proceeding backwards in the order the
composers were encountered.
We plan to exploit these features further in a more co-operative setting than the one
described here, where the system can engage in clarifying dialogue with the user. We explain
in Section 3.5 how we converged on a single object reference in the task under discussion
here, and what the other alternatives would be.
4.1 Colour - Probabilistic Attribute Composers
As mentioned in Section 3.1, we chose not to exploit the information used to render the
scene, and therefore must recover colour information from the final rendered image. This
is not a hard problem because Bishop only presents virtual objects in two colours. The
renderer does produce colour variations in objects due to different angles and distances from
light sources and the camera. The colour average for the 2D projection of each object also
varies due to occlusion by other objects. In the interest of making our framework more easily
transferable to a noisier vision system, we worked within a probabilistic framework. We
separately collected a set of labelled instances of green and purple cones, and estimated
a three dimensional Gaussian distribution from the average red, green and blue values of
each pixel belonging to the example cones.
448

fiGrounded Semantic Composition for Visual Scenes

When asked to compose with a given concept, this type of probabilistic attribute composer assigns each object referenced by the source concept the probability density function
evaluated at the measured average colour of the object.
4.2 Spatial Extrema and Spatial Regions - Ordering Composers
To determine spatial regions and extrema, an ordering composer orders objects along a
specified feature dimension (e.g. x coordinate relative to a group) and picks referents at an
extreme end of the ordering. To do so, it assigns an exponential weight function to objects
according to
 i(1+v)
for picking minimal objects, where i is the objects position in the sequence, v is its value
along the feature dimension specified, normalized to range between 0 and 1 for the objects
under consideration. The maximal case is weighted similarly, but using the reverse ordering
subtracting the fraction in the exponent from 2,
 (imax i)(2v)
where imax is the number of objects being considered. For our reported results  = 0.38.
This formula lets referent weights fall off exponentially both with their position in the ordering and their distance from the extreme object. In that way extreme objects are isolated
except for cases in which many referents cluster around an extremum, making picking out
a single referent difficult. We attach this type of composer to words like leftmost and
top.
The ordering composer can also order objects according to their absolute position, corresponding more closely to spatial regions rather than spatial extrema relative to a group.
The reference strength formula for this version is
d

 (1+ dmax )
where d is the euclidean distance from a reference point, and dmax the maximum such
distance amongst the objects under consideration.
This version of the composer is attached to words like middle. It has the effect that
reference weights are relative to absolute position on the screen. An object close to the centre of the board achieves a greater reference weight for the word middle, independently
of the position of other objects of its kind. Ordering composers work across any number
of dimensions by simply ordering objects by their Euclidean distance, using the same exponential falloff function as in the other cases. The ordering composer for middle, for
example, computes distance from the board centre to the centres of mass of objects, and
thus prefers those that are centred on the screen.
4.3 Grouping Composers
For non-numbered grouping (e.g., when the describer says group or cones), the grouping
composer searches the scene for groups of objects that are all within a maximum distance
threshold from another group member. This threshold is currently set by hand based on
a small number of random scenes in which the designers identified isolated groups and
449

fiGorniak & Roy

adjusted the threshold to correctly find them but not others. It only considers objects
that are referenced by the concept it is passed as an argument. For numbered groups
(two, three), the composer applies the additional constraint that the groups have to
contain the correct number of objects. Reference strengths for the concept are determined
by the average distance of objects within the group. We acknowledge that this approach
to grouping is simplistic and we are currently investigating more powerful visual grouping
algorithms that take topological features into consideration. In spite of our simple approach,
we can demonstrate some instances of successfully understanding references to groups in
Bishop.
The output of a grouping composer may be thought of as a group of groups. To understand the motivation for this, consider the utterance, the one to the left of the group of
purple ones. In this expression, the phrase group of purple ones will activate a grouping
composer that will find clusters of purple cones. For each cluster, the composer computes
the convex hull (the minimal elastic band that encompasses all the objects) and creates
a new composite object that has the convex hull as its shape. When further composition
takes place to understand the entire utterance, each composite group serves as a potential
landmark relative to left.
However, concepts can be marked so that their behaviour changes to split apart concepts
refering to groups. For example, the composer attached to of sets this flag on concepts
passing through it. Note that of is only involved in composition for grammar rules of the
type NP  NP P NP, but not for those performing spatial compositions for phrases like
to the left of. Therefore, the phrase the frontmost one of the three green ones will pick
the front object within the best group of three green objects.
4.4 Spatial Relations - Spatial Composers
The spatial semantic composer employs a version of the Attentional Vector Sum (AVS)
suggested by Regier and Carlson (2001). The AVS is a measure of spatial relation meant
to approximate human judgements corresponding to words like above and to the left
of in 2D scenes of objects. It computes an interpolation between the angle between the
centres of masses of the objects and the angle between the two closest points of the objects,
in addition to a value depending on height relative to the top of the landmark object.
Despite our participants talking about 2D projections of 3D scenes we found that the AVS
distinguishes the spatial relations used in our data rather well when simply applied to the
2D projections. The participants often used spatial descriptors such as below, suggesting
that they sometimes conceptualized the scenes as 2D. In a 3D setting we would expect to
see consistent use of semantic patterns like in front of instead of below.
Given two concepts as arguments, the spatial semantic composer converts both into sets
of objects, treating one set as providing possible landmarks, the other as providing possible
targets. The composer then calculates the AVS for each possible combination of landmarks
and targets. The reference vector used for the AVS is specified in the lexical entry containing
the composer, e.g. (0, 1) for behind. Finally, the spatial composer divides the result by
the Euclidean distance between the objects centres of mass, to account for the fact that
participants exclusively used nearby objects to select through spatial relations.
450

fiGrounded Semantic Composition for Visual Scenes

4.5 Anaphoric Composers
Triggered by words like that (as in to the left of that one) or previous, an anaphoric
composer produces a concept that refers to a single object, namely the last object removed
from the scene during the session. This object specially marks the concept as referring not
to the current, but the previous visual scene, and any further calculations with this concept
are performed in that visual context.
For example, when the parser calls upon the anaphoric composer attached to the lexical entry for that to provide an interpretation of that one, this composer marks the
produced concept as referring back to the previous visual scene, and sets the previously selected object as the only possible referent. Now consider another composer, say the spatial
composer attached to left in the one to the left of that one. When it asks for spatial
relation features between the referents of the one and that one, these spatial relation
features (see Section 4.4) are computed on the previous visual scene with the object that
was removed due to the previous utterance as the only possible landmark of the spatial
relation.

5. Example: Understanding a Description

example scene

the purple one

one on the left

the purple one on the left

Figure 9: Example: the purple one on the left
To illustrate the operation of the overall system, in this section we step through some
examples of how Bishop works in detail. Consider the scene in the top left of Figure 9, and
the output of the chart parser for the utterance, the purple one on the left in Figure 10.
Starting at the top left of the parse output, the parser finds the in the lexicon as an ART
(article) with a selecting composer that takes one argument. It finds two lexical entries
for purple, one marked as a CADJ (colour adjective), and one as an N (noun). Each
of them have the same composer, a probabilistic attribute composer marked as P(), but
the adjective expects one argument whereas the noun expects none. Given that the noun
expects no arguments and that the grammar contains a rule of the form NP N, an NP
(noun phrase) is instantiated and the probabilistic composer is applied to the default set
of objects yielded by N, which consists of all objects visible. This composer call is marked
451

fiGorniak & Roy

P(N) in the chart. After composition, the NP contains a subset of only the purple objects
(Figure 9, top right). At this point the parser applies NP  ART NP, which produces the
NP spanning the first two words and again contains only the purple objects, but is marked
as unambiguously referring to an object. S(NP) marks the application of this selecting
composer called S.
the
ART:the

purple

one

on

the

left

CADJ:purple
N:purple
NP:P(N)
NP:S(NP)
N:one
NP:one
NP:P(N)
NP:S(NP)
P:on
ART:the
N:left
ADJ:left
N:left
NP:left
NP:left
NP:S(NP)
NP:S(NP)
NP:O.x.min(NP)
NP:O.x.min(NP)
NP:O.x.min(NP)

Figure 10: Sample parse of a referring noun phrase

The parser goes on to produce a similar NP covering the first three words by combining
the purple CADJ with one and the result with the. The on P (preposition) is left
dangling for the moment as it needs a constituent that follows it. It contains a modifying
semantic composer that simply bridges the P, applying the first argument to the second.
After another the, left has several lexical entries: in its ADJ and one of its N forms it
contains an ordering semantic composer that takes a single argument, whereas its second N
form contains a spatial semantic composer that takes two arguments to determine a target
and a landmark object. At this point the parser can combine the and left into two
possible NPs, one containing the ordering and the other the spatial composer. The first of
these NPs in turn fulfills the need of the on P for a second argument according to NP 
NP P NP, performing its ordering compose first on one (for one on the left), selecting all
the objects on the left (Figure 9, bottom left). The application of the ordering composer is
452

fiGrounded Semantic Composition for Visual Scenes

denoted as O.x.min(NP) in the chart, indicating that this is an ordering composer ordering
along the x axis and selecting the minimum along this axis. On combining with purple
one, the same composer selects all the purple objects on the left (Figure 9, bottom right).
Finally on the purple one, it produces the same set of objects as purple one, but marks
the concept as unambiguously picking out a single object. Note that the parser attempts
to use the second interpretation of left (the one containing a spatial composer) but fails
because this composer expects two arguments that are not provided by the grammatical
structure of the sentence.

6. Results and Discussion
In this section we first discuss our systems overall performance on the collected data, followed by a detailed discussion of the performance of our implemented descriptive strategies.
6.1 Overall Performance
For evaluation purposes, we hand-annotated the data, marking which descriptive strategies
occurred in each example. Most examples use several reference strategies. In Table 2
we present overall accuracy results, indicating for which percentage of different groups of
examples our system picked the same referent as the person describing the object. The first
line in the table shows performance relative to the total set of utterances collected. The
second one shows the percentage of utterances our system understood correctly excluding
those marked as using a descriptive strategy that was not listed in Section 4, and thus not
expected to be understood by Bishop. Some such examples are given in Section 2.3.6. The
final line in Table 2 shows the percentage of utterances for which our system picked the
correct referent relative to the clean development and testing sets, leaving out utterances
marked as other as well as those marked as containing some kind of error. As we defined
earlier, this could be a speech error that was still understood by the human listener, or due to
an error by the algorithm that pairs utterances with selection events. Additionally, relying
on automatic speech segmentation sometimes merged utterances into one that should have
been separate utterances. This mistakenly attributes the combination of two descriptions to
one object selection and leaves another object selection without a corresponding utterance.
Note, however, that due to our loose parsing strategy and the frequent redundancies in
speakers utterances our system was able to handle a good number of utterances marked as
either other or error.
Utterance Set
All
All except Other
All except Other and Errors (clean)

Accuracy - Development
76.5%
83.2%
86.7%

Accuracy - Testing
58.7%
68.8%
72.5%

Table 2: Overall Results

Using unconstrained speech primarily made writing a covering yet precise grammar difficult. This difficulty together with the loose parsing strategy made our system occasionally
attempt compositions that are not supported by the grammatical structure of the utterance.
453

fiGorniak & Roy

This overeager parsing strategy also produces a number of correct guesses that would not
be found by a tighter grammar, and we found during development that the tradeoff often
favoured looser parsing in terms of number of correct responses produced. Constructing
the grammar is an obvious area to be addressed with a machine learning approach in the
future. Using a speech segmenter together with an utterance reassembler produced very
few errors because we used the successful selection event as a strong guideline for deciding
which speech segments were part of a description. Errors of this type occur in less that 1%
of the data.
Bishop Performance

100

random guess mean
random guess mean +/ std dev

90
80

Average Accuracy

70
60
50
40
30
20
10
0

1

2

3

4

development all

development clean

test all

test clean

Figure 11: Results for the development and test corpora

Figure 11 graphs the results for each corpus and for a simulation of a uniform random
selection strategy. Each bar shows the mean performance on a data set, with error bars delimiting one standard deviation. The figure shows results from left to right for the complete
development corpus, the clean development corpus, the complete test corpus and the clean
test corpus. Our system understands the vast majority of targeted utterances and performs
significantly better than the random baseline. Given the unconstrained nature of the input
and the complexity of the descriptive strategies described in Section 2.3 we consider this an
important achievement.
Table 3 provides more detail for the various descriptive strategies and lists the percentage of correctly identified referents for utterances employing spatial extrema and regions,
454

fiGrounded Semantic Composition for Visual Scenes

combinations of more than one spatial extremum, grouping constructs, spatial relations
and anaphora. Note again that these categories are not mutually exclusive. We do not list
separate results for the utterances employing colour terms because colour terms are not a
source of errors (due to the synthetic nature of the vision system).
Utterance Set
Spatial Extrema
Combined Spatial Extrema
Grouping
Spatial Relations
Anaphora

Accuracy - Development
86.8% (132/152)
87.5% (49/56)
34.8% (8/23)
64.3% (9/14)
100% (6/6)

Accuracy - Test
77.4% (72/93)
75.0% (27/36)
38.5% (5/13)
40.0% (8/20)
75.0% (3/4)

Table 3: Detailed Results
Not surprisingly, Bishop makes more mistakes when errors are present or strategies
other than those we implemented occur. However, Bishop achieves good coverage even
in those cases. This is often a result of overspecification on the part of the describer.
This tendency towards redundancy shows even in simple cases, for example in the use of
purple even though only purple cones are left in the scene. It translates furthermore
into specifications relative to groups and other objects when a simple leftmost would
suffice. Overspecification in human referring expressions is a well-known phenomenon often
attributed to the incremental nature of speech production. Speakers may be listing visually
salient characteristics such as colour before determining whether colour is a distinguishing
feature of the intended referent (Pechmann, 1989).
The worst performance, that of the grouping composers, can be attributed both to
the fact that the visual grouping strategy is too simplistic for the task at hand, and that
this phenomenon is often combined in rather complex ways with other strategies. These
combinations also account for a number of mistakes amongst the other composer that
perform much better when combined with strategies other than grouping. We cover the
shortcomings of the grouping composers in more detail in Section 6.2.3.
Mistakes amongst the descriptive strategies we cover have several causes:
Overcommitment/undercommitment Some errors are due to the fact that the interpretation is implemented as a filtering process without backtracking. Each semantic
composer must produce a set of objects with attached reference strengths, and the
next composer works from this set of objects in a strictly feedforward manner. During
composition this strategy fails when the target object is left out at one stage (e.g. in
the leftmost one in the front, leftmost selects the leftmost objects, not including
the obvious example of front that is not a good example of leftmost). It also
fails when too many target objects are included (e.g. a poor example of leftmost
is included in the set that turns out to be an ideal example of front). Estimating
the group membership thresholds from the data will certainly decrease occurrence of
these errors, but the real solution lies in a backtracking strategy combined with composers that are sensitive to the visual scenery beyond their immediate function. Such
sensitive composers might take into account facts about the isolated nature of certain
455

fiGorniak & Roy

candidates as well as the global distribution of cones across the board. We discuss
specific cases in which global and local visual context influence the interpretations of
words in Section 6.2.
Insufficient grammar For some cases that contain many prepositional phrases (e.g. the
leftmost one in the group of purple ones on the right and to the bottom) our grammar
was not specific enough to produce unambiguous answers. The grammar might attach
on the right to the object rather than to the group of objects, not taking into account
the biases in parsing that human listeners showed.
Flawed composers Some of the composers we have implemented are not sufficient to
understand all facets of the corresponding human descriptive strategies. We will
mention these problems in the following section.
6.2 Performance of Composers
We will now go reconsider each descriptive strategy and discuss the successes and failures
of our composers that were designed to deal with each.
6.2.1 Colour
Due to the simple nature of colour naming in the Bishop task, the probabilistic composers
responsible for selecting objects based on colour made no errors.
6.2.2 Spatial Regions and Extrema
Our ordering composers correctly identify 100% of the cases in which a participant uses only
colour and a single spatial extremum in his or her description. We conclude that participants
follow a process that yields the same result as ordering objects along a spatial dimension
and picking the extreme candidate. Participants also favour this descriptive strategy, using
it with colour alone in 38% of the clean data. Figure 3 provides examples of this type that
our system handles without problems.
Description by spatial region occurs alone in only 5% of the clean data, and together
with other strategies in 15% of the clean data. Almost all the examples of this strategy
occurring alone use words like middle or centre. The left image in Figure 12 exemplifies
the use of middle that our ordering semantic composer models. The object referred to is
the one closest to the centre of the board. We do not model the fact that human speakers
only use this version of the descriptive strategy if there is an obvious single candidate object.
The right image in Figure 12 shows a different interpretation of middle: the object in the
middle of a group of objects. Note that the group of objects is linguistically not mentioned.
Also note that within the group there are two candidate centre objects, and that the one in
the front is preferred. Our composer only picks the correct object for this use of middle
if the target object also happens to be the one closest to the centre of the board.
Figure 13 shows another use of the word middle. This strategy seems related to the
last one (picking the object in the middle of a group), however here the scene happens to be
divided into two groups of objects with a single object in between them. Even though the
object is in the back and not the closest one to the centre of the board, due to the visual
456

fiGrounded Semantic Composition for Visual Scenes

the green one in the middle

the purple cone in the middle

Figure 12: Types of middles 1
context participants understand it to be the object in the middle. Our composer fails in
this case.

the purple one in the middle
Figure 13: Types of middles 2
Figure 14 shows a sequence of two scenes that followed each other during a data collection
session. The first scene and utterance are a clear example of an extremum combined with a
region specification, and our ordering composers easily pick out the correct object. In the
next scene, the listener identified the leftmost object to be the one right in the middle,
despite the scenes similarity to the right image in Figure 12, where the middle object
was in the middle of the group. We suspect that the use of middle in the scene before
biases the understanding of middle as being relative to the board in this case, providing
an example where not only visual, but also historical context influence the meanings of
words. (Note that right in the utterance right in the middle is interpreted to have
SPEC grammatical type by Bishop, and does not have a spatial role. See the grammar in
Table 1.)

the green one in the middle front

the purple one right in the middle

Figure 14: Types of middles 3
457

fiGorniak & Roy

In summary, we can catalogue a number of different meanings for the word middle
in our data that are linguistically indistinguishable, but depend on visual and historical
context to be correctly understood. More generally, it is impossible to distinguish regionbased uses from the various extrema-based uses of words based on the utterance alone in
our data. We made the decision to treat middle to signify regions and left, top, etc.
to signify extrema, but our examples of middle show that the selection of which meaning
of these words to use depends on far subtler criteria such as global and local visual context,
existence of an unambiguous candidate and past use of descriptive strategies.
Participants composed one or more spatial region or extrema references in 30% of the
clean data. Our ordering composers correctly interpret 85% of these cases, for example
those in Figure 4 in Section 2.3.2. The mistakes our composers make are usually due to
overcommitment and faulty ordering. Figure 15 shows an example that could be interpreted
as either problem (we indicate both the correct example and the object our system selects).
We should note that this example comes from a non-native English speaker who often
used to where native speakers would use in. Our system selects the purple object
closest to the back of the board instead of the indicated correct solution. This could be
interpreted as overcommitment, because the composer for back does not include the
target object, leaving the composer for left the wrong set of objects to choose from. A
better explanation perhaps is that the ordering of the composers should be reversed in this
case, so that the composer for back should take the objects selected by left as input.
However, this ordering violates the far more common left-to-right ordering of region and
extrema strategies in our data, which we selected to implement in our system. The question
thus becomes what causes the difference in ordering in cases like the one in Figure 15. Once
again, we suspect that visual context plays a role. Perhaps it is clear to the listener here
that the double spatial specification would be an overspecification for the object our system
selects (it is simply the purple one in the back). In response, the listener may seek an
object that needs the full utterance, such as the true target. However, this analysis is
hard to combine with the very common trend towards overspecification on the part of the
speaker, leaving us with the need to run a more focused study of these phenomena to pin
down the factors that play a role in their interpretation.

purple cone to the back on the left side
Figure 15: Misinterpreted utterance using composed extrema

458

fiGrounded Semantic Composition for Visual Scenes

6.2.3 Grouping
Our composers implementing the grouping strategies used by participants are the most simplistic of all composers we implemented, compared to the depth of the actual phenomenon
of visual grouping. The left scene in Figure 16 shows an example our grouping composer
handles without a problem. The group of two cones is isolated from all other cones in
the example, and thus is easily found by our distance thresholding algorithm. In contrast,
the right scene depicts an example that would require much greater sophistication to find
the correct group. The target group of three cones is not visually isolated in this scene,
requiring further criteria like colinearity to even make it a candidate. Furthermore, there
is a second colinear group of three cones that would easily be the best example of a row
of three purple cones in the absence of the target group. It is only the target groups
alignment with the vertical axis that let it stand out more as a row and make it the
most likely interpretation. Our algorithm currently fails to include such grouping hints,
and thus fails to pick the correct answer in this scene. Note that such hints are not always linguistically marked as they are here (through row), but often colinearity is silently
assumed as holding for groups, making our simple grouping operator fail. A rich source
of models for possible human grouping strategies like co-linearity comes from research in
Gestalt Grouping (Wertheimer, 1999).

the cone on the right in the pair of
cones

the purple cone on at the front of the
row of three purple cones

Figure 16: Easy and hard visual grouping

6.2.4 Spatial Relations

the green cone behind the purple cone
Figure 17: Successful spatial relation understanding
The AVS measure divided by distance between objects corresponds very well to human
spatial relation judgements in this task. All the errors that occur in utterances that contain
459

fiGorniak & Roy

spatial relations are due to the possible landmarks or targets not being correctly identified
(grouping or region composers might fail to provide the correct referents). Our spatial
relation composer picks the correct referent in all those cases where landmarks and targets
are the correct ones, for example in Figure 17. Also see the next section for a further correct
example of spatial relations. Obviously, there are types of spatial relations such as relations
based purely on distance and combined relations (to the left and behind) that we decided
not to cover in this implementation, but that occur in the data and should be covered in
future efforts.
6.2.5 Anaphora

the cone at the right front

the cone behind that on the left

Figure 18: Successful Anaphora Understanding
Our solution to the use of anaphora in the Bishop task performs perfectly in replicating
reference back to a single object in the clean data. This reference is usually combined with
a spatial relation in our data, as in Figure 18. Due to the equally good performance of our
spatial relation composer, we cover all cases of anaphora in the development data. However,
there are more complex variants of anaphora that we do not currently cover, for example
reference back to groups of objects such as in the sequence in Figure 19, which follows the
right example in Figure 16.

the next cone in the row

the last cone in the row

Figure 19: Group Based Anaphora

7. Future Directions
Given the analysis of Bishops performance, there are several areas of future improvements that may be explored. The descriptive strategies we classified as other should be
understood by the computational system:
460

fiGrounded Semantic Composition for Visual Scenes

Distance A simple implementation to understand this strategy has the grammatical behaviour of our spatial relation composers, but uses an inverted distance measure to
score target objects.
Symmetry Selection by symmetry only occurred for symmetry across the horizontal centre
of the board in our data. We thus propose to mirror the landmark object across the
horizontal centre, and scoring possible targets by their inverted distance to this mirror
image.
Numbered grouping We limited ourselves to groups of two and three objects, but the
same algorithm should work for higher numbers.
In-group numbering A descriptive strategy like the second in the row can be understood with a slight modification to our ordering composer that can put the peak of
its exponential distribution not only at the ends and at the middle of the sequences,
but rather at arbitrary points.
Connectivity A simple way to understand the lonely cone could measure distance to
the closest objects within the group of possible referents. An better solution might
construct a local connectivity graph and look for topologically isolated objects.
Furthermore, we have already mentioned several areas of possible improvement to the
existing system due to faulty assumptions:
Individual composers Every one of our semantic composers attempts to solve a separate
hard problem, some of which (e.g. grouping and spatial relations) have seen long
lines of work dedicated to more sophisticated solutions than ours. The individual
problems were not the emphasis of this paper. We believe that improvements in their
implementation will improve our system as a whole, if not as much as the following
possible techniques.
Backtracking The lack of backtracking in Bishop should be addressed. If a parse does
not produce a single referent, backtracking would provide an opportunity to revise
or loosen the decisions made at various stages of interpretation until a referent is
produced.
Visual context semantics Backtracking only solves problems in which the system knows
that it has either failed to obtain an answer, or knows that the answer it produced
is an unlikely one. However, there are numerous examples in the data where one
interpretation of an utterance produces a perfectly likely answer according to our
measurements, for example middle finds an object at the exact centre of the screen.
In many scenes this interpretation produces the correct answer, and a measurement
relative to the other objects would produce a wrong one. However, we observe that
participants only interpret middle in this way if there is no obvious structure to the
rest of the scene. If by chance the scene is divided into a group of objects on the left
and a group of objects on the right, middle will reliably refer to any isolated object
in between these to groups, even if another object is closer to the actual centre of
the screen. A future system should take into account local and global visual context
during composition to account for these human selection strategies.
461

fiGorniak & Roy

Lexical entries We have made the assumption that lexical entries are word-like entities
that contain encapsulated semantic information. Even in our relatively constrained
task, this is a somewhat faulty assumption. For example, the ambiguity in a word like
of is only resolved by careful design of our grammar (see section 4.3), but it may be
useful to treat entire phrases such as to the left of as single lexical entries, perhaps
with its own grammar to replace left with other spatial markers (Jackendoff has
proposed absorbing most rules of syntax into the lexicon, see Jackendoff, 2002).
Dialogue By constructing the parse charts we obtain a rich set of partial and full syntactic
and semantic fragments offering explanations for parts of the utterance. At present,
we largely ignore this information-rich resource when selecting the best referent. A
more successful approach might entail backtracking and revision as described above,
but also engage in clarification dialogue with the human speaker. The system could
use the fragments it knows about to check the validity of its interpretation (is this
the group of green ones you mean?) or could simply disambiguate directly (Which
of these two do you mean?) followed by an explanation of its confusion in terms of
the semantic fragments it formed.
Manual construction of a visually-grounded lexicon as presented here will be limited in
accuracy due to various structural and parametric decisions that had to be manually approximated. Machine learning algorithms may be used to learn many of the parameter settings
that were set by hand in this work, including on-line learning to adapt parameters during
verbal interaction. Although some thresholds and probability distribution functions may
be estimated from data using relatively straightforward methods, other learning problems
are far more challenging. For example, learning new types of composers and appropriate
corresponding grammatical constructs poses a difficult challenge for the future. Minimally,
we plan to automate the creation of new versions of old composers (e.g. applied to different
dimensions and attributes). Moving beyond this, it is not clear how, for example, the set
handling functionality used to determine groups of referents can expand automatically and
in useful ways. It will also be interesting to study how people learn to understand novel
descriptive strategies.
We are also continuing work in applying our results from grounded language systems to
multimodal interface design (Gorniak & Roy, 2003). We recently demonstrated an application of the Bishop system as described in this paper to the problem of referent resolution in
the graphical user interface for a 3D modelling application, Blender (Blender Foundation ,
2003). Using a Bishop/Blender hybrid, users can select sets of objects and correct wrong
mouse selections with voice commands such as select the door behind that one or show
me all the windows.

8. Summary
We have presented a model of visually-grounded language understanding. At the heart of
the model is a set of lexical items, each grounded in terms of visual features and grouping
properties when applied to objects in a scene. A robust parsing algorithm finds chunks
of syntactically coherent words from an input utterance. To determine the semantics of
phrases, the parser activates semantic composers that combine words to determine their
462

fiGrounded Semantic Composition for Visual Scenes

joint reference. The robust parser is able to process grammatically ill-formed transcripts of
natural spoken utterances. In evaluations, the system selected correct objects in response
to utterances for 76.5% of the development set data, and for 58.7% of the test set data. On
clean data sets with various speech and processing errors held out, performance was higher
yet. We suggested several avenues for improving performance of the system including better
methods for spatial grouping, semantically guided backtracking during sentence processing,
the use of machine learning to replace hand construction of models, and the use of interactive
dialogue to resolve ambiguities. In the near future, we plan to transplant Bishop into an
interactive conversational robot (Hsiao et al., 2003), vastly improving the robots ability to
comprehend spatial language in situated spoken dialogue.

Acknowledgments
Thanks to Ripley, Newt and Jones.

Appendix A. Utterances in the Test Data Set
The following are the 179 utterances we collected as our test data set. They are presented
in the correct order and as seen by the understanding system. This means that they include
errors due to faulty speech segmentation as well as due to the algorithm that stitches oversegmented utterances back together.
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the

green cone in the middle
purple cone behind it
purple cone all the way to the left
purple cone in the corner on the right
green cone in the front
green cone in the back next to the purple cone
purple cone in the middle front
purple cone in the middle
frontmost purple cone
green cone in the corner
most obstructed green cone
purple cone hidden in the back
purple cone on the right in the rear
green cone in the front
solitary green cone
purple cone on at the front of the row of three purple cones
next cone in the row
last cone in the row
cone on the right in the pair of cones
other cone
cone closest to the middle in the front
cone in the right set of cones furthest to the left
cone at the right front
463

fiGorniak & Roy

the cone behind that on the left
the frontmost left cone
the backmost left cone
the solitary cone
the cone on in the middle on the right
the front cone the cone
the frontmost green cone
the green cone in the front to the right of the purple cone
the green cone at the back of the row of four
the cone the green cone behind the purple cone
the purple cone behind the row of three green cones
the frontmost green cone on the right
the green cone in the corner in the back
the green cone in the back
the purple cone in the back to the right
the green cone at the front left
purple cone behind it
the purple cone behind that one
the green cone behind the purple cone
the green cone in between two purple cone
the purple cone in the front
the purple cone touching the green cone
the green cone in the front
purple cone at the left
the green cone in the back left
the purple cone in the middle in front of the other two purple cones
the purple cone to the left of the four green cones
the purple cone to the left of that leftmost
green cone
frontmost green cone
rear cone
rightmost cone
rearmost cone
the left green cone
the purple cone the green cone
the green cone
the furthestmost green cone in the exact middle
the frontmost green cone
the rightmost green cone in the clump of four green cones to the right
the green cone in front of the two purple cones near the left
the green cone between the two purple cones in the back middle
the frontmost purple cone
the leftmost of the two purple cones on the right I mean on the left,
sorry so that was the leftmost of the two purple cones on the left side
the green cone on the left halfway back
464

fiGrounded Semantic Composition for Visual Scenes

the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the
the

frontmost green cone in front of a purple cone
most middle purple cone
green cone on the most left to the most left
green cone in the middle in front of the other green cone
only green cone on the left
furthestmost purple cone on the left
furthest green cone
leftmost green cone
leftmost purple cone
middle green cone
green cone between the two other green cones
frontmost purple cone
backmost purple cone
green cone between the two purple cones nearest to the front
leftmost purple cone
green cone in the front
green cone
frontmost of the two back purple cones
rightmost purple cone
leftmost purple cone
purple cone in the front
last purple cone
frontmost purple cone in the clump of five purple cones
on the right
backmost green cone
the backmost purple cone
the green cone directly in front of the purple cone
the purple cone behind the green cone on the left
the green cone behind the purple cone on the left
the leftmost of the two left back corner green cones
the rightmost purple cone
the middle cone behind the frontmost purple cone
the green cone on the left front corner
the purple cone on the right back corner
the third green cone in the line of green cones near the middle
the green cone between the two purple cones near the back
the green cone in the back left
the only green cone in the back
the green cone behind the frontmost green cone
the frontmost green cone
the only green cone
the last of the line of four purple cones
the centre purple cone in the three cones on the left
the purple cone between the two purple cones
the middle purple cone
465

fiGorniak & Roy

the
the
the
the
the
the
the
the
the
the

leftmost purple cone
middle purple cone
front left purple cone
front right purple cone
second of the four purple cones
middle purple cone
purple cone on the left
last purple cone
green one in the middle all the way at the back
purple one its all the way in the middle but a little but
to the left and all the way in the back
the green one in the middle in the front thats in front of another
green one
the purple one in the middle thats behind the green one
on the on the right the purple one at the very front of the line of
purple ones
on the left the green one in between two purple ones in a line
and on the left the purple one in the middle of a row of I mean in the middle
of a line of three purple ones
the green one on the left thats hidden by a purple one
on the left the purple one thats all the way in the corner and its separate
in the middle towards the right theres a line of purple ones and then
theres a kink in the line and the one thats right where the lines turns
the purple one all the way on the right in the front
the purple one in the front in the middle
the green one in the middle
the purple in the front all the way on the right
and the rightmost green one
the leftmost green one
and then the last green one the last green one
the frontmost purple one on the right
the purple one in the back towards the left thats next to two other
purple ones
the purple one in the back towards the right thats not part of a pair
the purple one in the front of a group on the right
the purple one in the middle thats in front of a group one the right
the purple one on the left all the way in the back
the purple one on the left thats behind another purple one
the purple one on the left thats in the front the purple one
on the left thats by itself
the purple one on the right thats hidden by two other purple ones
the purple one all the way in the back corner on the right
the purple one thats in front on the right and the last one
and the last one
the purple on in the front on the right
466

fiGrounded Semantic Composition for Visual Scenes

the
the
the
the
the
the

only purple one all the way on the right
green one on the right thats in the middle of a bunch
green one all the way on the left thats almost totally obscured
last purple one on the left that in a crooked line of purple ones
first purple one on the left thats in a crooked line
purple one all the way one the all the way in the back towards
the left thats behind a green and a purple one all the way in
the back
the purple one towards the back thats pretty much in the back but
thats in front of a green and purple one
the purple one in the middle in the back
the purple one on the left thats furthest to the back
the green one in the middle thats furthest to the front
the purple one towards the in the middle but towards the left
thats closest
in the middle the purple one that stands out thats closest
of the purple ones in the middle and towards the right the one
at the corner
the purple one thats closest to the middle
all the way on the right the green one in the middle of a line of three
green ones
and then all the way on the right the closest green one
all the way on the right the only close green one
the green one all the way in the right corner in the back
the purple one thats towards the back and the left corner
the purple one in the front left corner
the purple one near the middle thats not with another purple one
the purple one thats in front of another purple one
and the only purple one on the right
the only purple one on the left
the green one in the middle thats just behind another green one
and the closest green one in the middle the green one thats closest to
the middle
the green one all the way in the back towards the right
the only close green one the only one left
the only one left

Appendix B
The following specifies the complete lexicon used in Bishop in XML format. The initial
comment explains the attributes of lexical entries.
see online appendix file lexicon.xml.

467

fiGorniak & Roy

References
Abney, S. (1997). Part-of-speech tagging and partial parsing. In Corpus-Based Methods in
Language and Speech, chap. 4, pp. 118136. Kluwer Academic Press, Dordrecht.
Allen, J. (1995). Natural Language Understanding, chap. 3. The Benjamin/Cummings
Publishing Company, Inc, Redwood City, CA, USA.
Bailey, D. (1997). When push comes to shove: A computational model of the role of motor
control in the acquisition of action verbs. Ph.D. thesis, Computer science division,
EECS Department, University of California at Berkeley.
Barker, C. (2002). The dynamics of vagueness. Linguistics and Philosophy, 25, 136.
Blender Foundation (2003). Blender 3D graphics creation suite. http://www.blender3d.org.
Brown, M., Buntschuh, B., & Wilpon, J. (1992). SAM: A perceptive spoken languageunderstanding robot. IEEE Transactions on Systems, Man and Cybernetics, 6 (22),
13901402.
Brown-Schmidt, S., Campana, E., & Tanenhaus, M. K. (2002). Reference resolution in the
wild. In Proceedings of the Cognitive Science Society.
Carletta, J., & Mellish, C. (1996). Risk-taking and recovery in task-oriented dialogue.
Journal of Pragmatics, 26, 71107.
Desolneux, A., Moisan, L., & Morel, J. (2003). A grouping principle and four applications.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 255 (4), 508513.
Dhande, S. (2003). A computational model to connect gestalt perception and natural
language. Masters thesis, Massachusetts Institure of Technology.
Engbers, E., & Smeulders, A. (2003). Design considerations for generic grouping in vision.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 255 (4), 445457.
Eugenio, B. D., Jordan, P. W., Thomason, R. H., & Moore, J. D. (2000). The agreement
process: An empirical investigation of human-human computer-mediated collaborative
dialogues. International Journal of Human-Computer Studies, 53 (6), 10171076.
Gorniak, P., & Roy, D. (2003). Augmenting user interfaces with adaptive speech commands.
In Proceedings of the International Conference for Multimodal Interfaces.
Griffin, Z., & Bock, K. (2000). What the eyes say about speaking. Psychological Science,
11, 274279.
Haddock, N. (1989). Computational models of incremental semantic interpretation. Language and Cognitive Processes, 4, 337368.
Hsiao, K., Mavridis, N., & Roy, D. (2003). Coupling perception and simulation: Steps
towards conversational robotics. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).
Jackendoff, R. (2002). Whats in the lexicon?. In Noteboom, S., Weerman, F., & Wijnen
(Eds.), Storage and Computation in the Language Faculty, chap. 2. Kluwer Academic
Press.
468

fiGrounded Semantic Composition for Visual Scenes

Kyburg, A., & Morreau, M. (2000). Fitting words: vague words in context. Linguistics and
Philosophy, 23, 577597.
Lammens, J. M. (1994). A computational model of color perception and color naming. Ph.D.
thesis, State University of New York.
Landau, B., & Jackendoff, R. (1993). what and where in spatial language and spatial
cognition. Behavioural and Brain Sciences, 2 (16), 217238.
Miller, G., & Johnson-Laird, P. (1976). Language and Perception. Harvard University Press.
Nagao, K., & Rekimoto, J. (1995). Ubiquitous talker: Spoken language interaction with
real world objects. In Proceeding of the International Joint Conference on Artificial
Intelligence.
Narayanan, S. (1997). KARMA: Knowledge-based Action Representations for Metaphor and
Aspect. Ph.D. thesis, Univesity of California, Berkeley.
Partee, B. H. (1995). Lexical semantics and compositionality. In Gleitman, L. R., & Liberman, M. (Eds.), An Invitation to Cognitive Science: Language, Vol. 1, chap. 11, pp.
311360. MIT Press, Cambridge, MA.
Pechmann, T. (1989). Incremental speech production and referential overspecification. Linguistics, 27, 89110.
Pustejovsky, J. (1995). The Generative Lexicon. MIT Press, Cambridge, MA, USA.
Regier, T. (1996). The Human Semantic Potential. MIT Press.
Regier, T., & Carlson, L. (2001). Grounding spatial language in perception: An empirical and computational investigation. Journal of Experimental Psychology: General,
130 (2), 273298.
Roy, D. (2002). Learning visually-grounded words and syntax for a scene description task.
Computer Speech and Language, 16 (3).
Roy, D., Gorniak, P. J., Mukherjee, N., & Juster, J. (2002). A trainable spoken language
understanding system. In Proceedings of the International Conference of Spoken Language Processing.
Roy, D., & Pentland, A. (2002). Learning words from sights and sounds: A computational
model. Cognitive Science, 26 (1), 113146.
Schuler, W. (2003). Using model-theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface. In Proceedings of the Association for Computational Linguistics.
Shi, J., & Malik, J. (2000). Normalized cuts and image segmentation. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 8 (22), 888905.
Siskind, J. M. (2001). Grounding the lexical semantics of verbs in visual perception using
force dynamics and event logic. Journal of Artificial Intelligence Research, 15, 3190.
Wertheimer, M. (1999). Laws of organization in perceptual forms. In A source book of
Gestalt psychology, pp. 7188. Routledge, New York.
Winograd, T. (1970). Procedures as a representation for data in a computer program for
understanding natural language. Ph.D. thesis, Massachusetts Institute of Technology.
469

fiGorniak & Roy

Yoshida, N. (2002). Utterance segmenation for spontaneous speech recognition. Masters
thesis, Massachusetts Institute of Technology.

470

fiJournal of Artificial Intelligence Research 21 (2004) 1-17

Submitted 7/03; published 1/04

Effective Dimensions of Hierarchical Latent Class Models
Nevin L. Zhang

lzhang@cs.ust.hk

Department of Computer Science
Hong Kong University of Science and Technology, China

Tomas Kocka

kocka@lisp.vse.cz

Laboratory for Intelligent Systems Prague
Prague University of Economics, Czech Republic

Abstract
Hierarchical latent class (HLC) models are tree-structured Bayesian networks where
leaf nodes are observed while internal nodes are latent. There are no theoretically well
justified model selection criteria for HLC models in particular and Bayesian networks with
latent nodes in general. Nonetheless, empirical studies suggest that the BIC score is a
reasonable criterion to use in practice for learning HLC models. Empirical studies also
suggest that sometimes model selection can be improved if standard model dimension is
replaced with effective model dimension in the penalty term of the BIC score.
Effective dimensions are difficult to compute. In this paper, we prove a theorem that
relates the effective dimension of an HLC model to the effective dimensions of a number
of latent class models. The theorem makes it computationally feasible to compute the
effective dimensions of large HLC models. The theorem can also be used to compute the
effective dimensions of general tree models.

1. Introduction
Hierarchical latent class (HLC) models (Zhang, 2002) are tree-structured Bayesian networks
(BNs) where leaf nodes are observed while internal nodes are latent. They generalize latent
class models (Lazarsfeld and Henry, 1968) and were first identified as a potentially useful
class of Bayesian networks by Pearl (1988). We are concerned with learning HLC models
from data. A fundamental question is how to select among competing models.
The BIC score (Schwarz, 1978) is a popular metric that researchers use to select among
Bayesian network models. It consists of a loglikelihood term that measures the fitness
to data and a penalty term that depends linearly upon standard model dimension, i.e.
the number of linearly independent standard model parameters. When all variables are
observed, the BIC score is an asymptotic approximation of (the logarithm) of the marginal
likelihood (Schwarz, 1978). It is also consistent in the sense that, given sufficient data, the
BIC score of the generative model  the model from which data were sampled  is larger
than those of any other models that are not equivalent to the generative model.
When latent variables are present, the BIC score is no longer an asymptotic approximation of the marginal likelihood (Geiger et al., 1996). This can be remedied, to some
extent, using the concept of effective model dimension. In fact if we replace standard model
dimension with effective model dimension in the BIC score, the resulting scoring function,
called the BICe score, is an asymptotic approximation of the marginal likelihood almost
everywhere except for some singular points (Rusakov and Geiger, 2002).
c
2004
AI Access Foundation. All rights reserved.

fiZhang & Kocka

Neither BIC nor BICe have been proved to be consistent for latent variable models. As
a matter of fact, it has not even been defined what it means for a model selection criterion
to be consistent for latent variable models. Empirical studies suggest that the BIC score is
well-behaved in practice for the task of learning HLC models. There are three related searchbased algorithms for learning HLC models, namely double hill-climbing (DHC) (Zhang,
2002), single hill-climbing (SHC) (Zhang et al., 2003), and heuristic SHC (HSHC) (Zhang,
2003). In the absence of a theoretically well justified model selection criterion, Zhang (2002)
tested DHC with four existing scoring functions, namely the AIC score (Akaike, 1974), the
BIC score, the Cheeseman-Stutz (CS) score (Cheeseman and Stutz, 1995), and the holdout
logarithmic score (HLS)(Cowell et al., 1999). Both real-world and synthetic data were used.
On the real-world data, BIC and CS have enabled DHC to find models that are regarded as
the best by domain experts. On the synthetic data, BIC and CS have enabled DHC to find
models that either are identical to or resemble closely the true generative models. When
coupled with AIC and HLS, on the other hand, DHC performed significantly worse. SHC
and HSHC were tested on synthetic data sampled from fairly large HLC models (as much
as 28 nodes). Only BIC was used in those tests. In all cases, BIC has enabled SHC and
HSHC to find models that either are identical to or resemble closely the true generative
models. Those empirical results not only indicate that the algorithms perform well, but
also suggest that the BIC is a reasonable scoring function to use for learning HLC models.
The experiments also reveal that model selection can sometimes be improved if the BICe
score is used instead of the BIC score. We will explain this in detail in Section 3
In order to use the BICe score in practice, we need a way to compute effective dimensions. This is not a trivial task. The effective dimension of an HLC model is the rank of
the Jacobian matrix of the mapping from the parameters of the model to the parameters
of the joint distribution of the observed variables. The number of rows in the Jacobian
matrix increases exponentially with the number of observed variables. The construction of
the Jacobian matrix and the calculation of its rank are both computationally demanding.
Moreover they have to be done algebraically or with very high numerical precision to avoid
degenerate cases. The necessary precision grows with the size of the matrix.
Settimi and Smith (1998, 1999) studied effective dimensions for two classes of models:
trees with binary variables and latent class (LC) models with two observed variables. They
have obtained a complete characterization of these two classes. Geiger et al. (1996) computed the effective dimensions of a number of models. They conjectured that it is rare for
the effective and standard dimensions of an LC model to differ. As a matter of fact, they
found only one such model. Kocka and Zhang (2002) found quite a number of LC models
whose effective and standard dimensions differ. They also proposed an easily computable
formula for estimating effective dimensions of LC models. The estimation formula has been
empirically shown to be very accurate.
In this paper, we prove a theorem that relates the effective dimension of an HLC model
to the effective dimensions of two other HLC models that contain fewer latent variables.
Repeated application of the theorem allows one to reduce the task of computing the effective
dimension of an HLC model to subtasks of computing effective dimensions of LC models.
This makes it computationally feasible to compute the effective dimensions of large HLC
models.
2

fiEffective Dimensions of HLC Models

We start in Section 2 with a formal definition of effective dimensions for Bayesian networks with latent variables. In Section 3, we provide empirical evidence that suggest the use
of BICe instead of BIC sometimes improves model selection. Section 4 presents the main
theorem and Section 5 is devoted to the proof of the theorem. In Section 6, we prove a theorem about effective dimensions of general tree models and explain how this and our main
theorem allows one to compute the effective dimension of arbitrary tree models. Finally,
concluding remarks are provided in Section 7.

2. Effective Dimensions of Bayesian Networks
In this paper, we use capital letters such as X and Y to denote variables and lower case
letters such as x and y to denote states of variables. The domain and cardinality of a
variable X will be denoted by X and |X| respectively. Bold face capital letters such as Y
denote sets of variables. Y denotes the Cartesian product of the domains of all variables
in the set Y. Elements of Y will be denoted by bold lower case letters such as y and will
sometimes be referred to as states of Y. We will consider only variables that have a finite
number of states.
Consider a Bayesian network model M that possibly contains latent variables. The
standard dimension ds(M ) of M is the number of linearly independent parameters in the
standard parameterization of M . The parameters denote, for each variable and each parent
configuration of the variable, the probability that the variable is in some state (except one)
given the parent configuration. Suppose M consist of k variables x1 , x2 , . . . , xk . Let ri and
qi be respectively the number of states of xi and the number of all possible combinations of
the states of its parents. If xi has no parent, let qi be 1. Then ds(M ) is given by
ds(M ) =

k
X

qi (ri  1).

i=1

~
For notational simplicity, denote the standard dimension of M by n. Let =(
1 , 2 , . . . , n )
be a vector of n linearly independent model parameters of M . Further let Y be the set of
observed variables. Suppose Y has m+1 possible states. We enumerate the first m states
as y1 , y1 , . . . , ym .
~ So we have a mapping from
For any i (1im), P (yi ) is a function of the parameters .
n
m
the n dimensional parameter space (a subspace of R ) to R , namely T : (1 , 2 , . . . , n ) 
(P (y1 ), P (y2 ), . . . , P (ym )). The Jacobian matrix of this mapping is the following mn
matrix:
~ = [Jij ] = [ P (yi ) ]
JM ()
j
], with the understanding
For convenience, we will often write the matrix as JM = [ P(Y)
j
that elements of the j-th column are obtained by allowing Y run over all its possible states
except one.
~ For most commonly used parameterizations of
For each i, P (yi ) is a function of .
~ Hence we make the following
Bayesian networks, it is actually a polynomial function of .
assumption:
3

fiZhang & Kocka

Assumption 1 The Bayesian network M is so parameterized that the parameters for the
joint distribution of the observed variables are polynomial functions of the parameters for
M.
An obvious consequence of the assumption is that elements of JM are also polynomial
~
functions of .
~ JM is a matrix of real numbers. Due to Assumption 1, the rank
For a given value of ,
of this matrix is some constant d almost everywhere in the parameter space (Geiger et al.,
1996. Also see Section 5.1.). To be more specific, the rank is d everywhere except in a set
of measure zero where it is smaller than d. The constant is called the regular rank of JM .
The regular rank of JM is also called the effective dimension of the Bayesian network
model M . Hence we denote it by de(M ). To understand the term effective dimension,
consider the subspace of Rm spanned by the joint probability P (Y) of observed variables,
or equivalently the range of the mapping T . The term reflects the fact that, for almost every
~ a small enough open ball around T ()
~ resembles Euclidean space of dimension d
value of ,
(Geiger et al., 1996).
There are multiple ways to parameterize a given Bayesian network model. However, the
choice of parameterization does not affect the space spanned by the joint probability P (Y).
Together with the interpretation of the previous paragraph, this implies that the definition
of effective dimension does not depend on the particular parameterization that one uses.

3. Selecting among HLC Models
A hierarchical latent class (HLC) model is a Bayesian network where (1) the network structure is a rooted tree and (2) the variables at the leaf nodes are observed and all the other
variables are not. The observed variables are sometimes referred to as manifest variables
and all the other variables as latent variables. Figure 1 shows the structures of two HLC
models. A latent class (LC) model is an HLC model where there is only one latent variable.
The theme of this paper is the computation of effective dimensions of HLC models. As
mentioned in the introduction, this is interesting because effective dimension, when used in
the BIC score, gives us a better approximation of the marginal likelihood. In this section,
we give an example to illustrate that the use of effective dimension sometimes also leads to
better model selection. We will also motivate and introduce the concept of regularity that
will be used in subsequent sections.
3.1 An Example of Model Selection
Consider the two HLC models shown in Figure 1. In one experiment, we instantiated the
parameters of M1 in a random fashion and sampled a set D1 of 10,000 data records on the
observed variables. Then we ran SHC and HSHC on the data set D1 under the guidance
of the BIC score. Both algorithms produced model M2 . In the following, we explain why,
based on D1 , one would prefer M2 over M1 if BIC is used for model selection and why M1
would be preferred if BICe is used instead. We argue that M1 should be preferred based on
D1 and hence BICe is a better scoring metric for this case.
4

fiEffective Dimensions of HLC Models

X1

X2

X2
Y1

Y2

X3
Y3

Y4

Y1

Y5

Y2

Y6

M1

Y3

X3

Y4

Y5

Y6

M2

Figure 1: Two HLC models. The shaded variables are latent, while the other variables are
observed. The cardinality of X1 is 2, while cardinalities of all other variables are
3.

The BIC and BICe scores of a model M given a data set D are defined as follows:
ds(M )
BIC(M |D) = logP (D|M, ~ ) 
logN,
2
de(M )
BICe(M |D) = logP (D|M, ~ ) 
logN
2
where ~ is the maximum likelihood estimate of the parameters of M based on D and N is
the sample size.
In our example, notice that M2 includes M1 in the sense that M2 can represent any
probability distributions of the observed variables that M1 can. In fact, if we make the
conditional probability distributions of the observed variables in M2 the same as in M1 and
set PM2 (X2 ) and PM2 (X3 |X2 ) such that
PM2 (X2 )PM2 (X3 |X2 ) =

X

PM1 (X1 )PM1 (X2 |X1 )PM1 (X3 |X1 ),

X1

then the probability distribution of the observed variables in the two models are identical.
Because M2 includes M1 , we have logP (D1 |M1 , ~1 )  logP (D1 |M2 , ~2 ). Together with
the fact that D1 is sampled from M1 , this implies that logP (D1 |M1 , ~1 )  logP (D1 |M2 , ~2 )
for sufficiently large enough sample size. The standard dimension of M1 is 45, while that
of M2 is 44. Hence
BIC(M1 |D1 ) < BIC(M2 |D1 ).
On the other hand, the effective dimensions of M1 and M2 are 43 and 44 respectively. Hence
BICe(M1 |D1 ) > BICe(M2 |D1 ).
Model M2 includes M1 . The opposite is clearly not true because the effective dimension
of M1 is smaller than that of M2 . So, M2 is in reality a more complex model than M1 . Both
model fit data D1 equally well. Hence the simpler one, i.e. M1 , should be preferred over
the other. This agrees with the choice of the BICe score, while disagrees with the choice of
the BIC score. Hence, BICe is more appropriate than BIC in this case.
5

fiZhang & Kocka

3.2 Regularity
Now consider another model M1 that is the same as M1 except that the cardinality of X1
is increased from 2 to 3. It is easy to show that M2 includes M1 and vice versa. So, the two
models are equivalent in terms of their capabilities of representing probability distributions
of the observed variables. They are hence said to be marginally equivalent. However, M1
has more standard parameters than M2 and hence we would always prefer M2 over M1 . To
formalize this consideration, we introduce a concept of regularity.
For a latent variable Z in an HLC model, enumerate its neighbors (parent and children)
as X1 , X2 , . . . , Xk . An HLC model is regular if for any latent variable Z,
|Z| 

Qk

i=1 |Xi |
,
maxki=1 |Xi |

(1)

and the strict inequality holds when Z has two neighbors and at least one of them is a
latent node. Models M1 and M2 are regular, while model M1 is not.
For any irregular model M there always exists a regular model that is marginally equivalent to M and has fewer standard parameters (Zhang, 2003b). The regular model can
be obtained from M as follows: For any latent node that has only two neighbors and its
cardinality is no smaller than that of one of the neighbors, then remove the latent node and
connect the two neighbors. For any latent node that has more than two neighbors and that
violates (1), reduce its cardinality to the quantity on the right hand side. Repeat both
steps until no more changes can be made.
It is also interesting to note that the collection of all regular HLC models for a given set
of observed variables is finite (Zhang, 2002). This provides a finite search space for the task
of learning regular HLC models.1 In the rest of this paper, we will consider only regular
HLC models.
Before ending this subsection, we point out a nice property of effective model dimension
in relation to model inclusion. If an HLC model includes another model, then its effective
dimension is no less than that of the latter. As a consequence, two marginally equivalent
models have the same effective dimensions and hence the same BICe score. The same is
not true for standard model dimension and the BIC score.
3.3 The CS and CSe Scores
We have argued on empirical grounds that the BIC score is a reasonable scoring function
to use for learning HLC models and that the BICe score can sometimes improve model
selection. But the two scores are not free of problems. One problem is that their derivation
as Laplace approximations of the marginal likelihood are not valid at the boundary of the
parameter space. The CS score in a way alleviates this problem. It involves the BIC score
based on completed data and the BIC score based on original data. In other words, it
involves two Laplace approximations of the marginal likelihood. It lets errors in the two
approximation cancel each other.
Chickering and Heckerman (1997) empirically found the CS score to be a quite accurate
approximation of the marginal likelihood and robust at the boundary of the parameter
1. The definition of regularity given in this paper is slightly different from the one given in Zhang (2002).
Nonetheless, the two conclusions mentioned in this paragraph remain true.

6

fiEffective Dimensions of HLC Models

X

Z

X

O

Y

O

M

Z

Z

X

Y
M2

M1

Figure 2: Problem reduction.
space. They realized the need for effective model dimension in the CS score, although they
did not actually use it. This would not have made any differences to their experiments
because, for the models they used, the standard and effective dimensions agree.
We use CSe to refer to the scoring function one obtains by replacing standard model
dimension in the CS score with effective model dimensions. Just as BICe is better than
BIC as approximations of the marginal likelihood (Geiger et al., 1996), CSe is better than
CS. To compute CSe, we also need to calculate effective dimensions.

4. Effective Dimensions of HLC Models
As we have seen, effective model dimension is interesting for a number of reasons. Our
main result in this paper is a theorem about the effective dimension de(M ) of a regular
HLC model M that contains more than one latent variable. Let X be the root of M , which
is a latent node. Because there are at least two latent nodes, there must exist another latent
node Z that is a child of X. In the following, we will use the terms X-branch and Z-branch
to respectively refer to the sets of nodes that are separated from Z by X or from X by Z.
Let Y be the set of observed variables in the Z-branch and let O be the set of all other
observed variables. Note that the X-branch doesnt contain the node X. The relationship
among X, Z, Y, and O is depicted in the left-most picture of Figure 2.
The standard parameterization of M includes parameters for P (X) and parameters for
P (Z|X). For convenience, we replace those parameters with parameters for P (X, Z). As
mentioned at the end of Section 2, such reparameterization does not affect the effective
dimension de(M ). To reflect the reparameterization, the edge between X and Z is not
directed in Figure 2.
(0)

(0)

(0)

Suppose P (X, Z) has k0 parameters 1 , 2 , . . . , k0 . Suppose the conditional distri(1)

(1)

(1)

butions of variables in the X-branch consists of k1 parameters 1 , 2 , . . . , k1 and the
(2)

(2)

conditional distributions of variables in the Z-branch consists of k2 parameters 1 , 2 ,
(2)
. . . , k2 . For convenience we will sometimes refer to those three groups of parameters using
three vectors ~(0) , ~(1) and ~(2) respectively.
In the following, we will define two other HLC models M1 and M2 starting from M and
establish a relationship between their effective dimensions and the effective dimension of
M . In this context, M , M1 , and M2 are regarded purely as Mathematical objects. The
semantics of their variables are of no concern. In particular, a variable H that is latent
7

fiZhang & Kocka

X1
X1 (6)
X2
X2 (3)

Y3 (3)

X4 (5)

X3 (3)

Y3

X3

X2
X4

X5 (5)

X3
X1

X1

X4
Y1 (3)

Y2 (2)

Y4 (2)

X5
X5

Y5 (6)
Y1

Y2

X2

X3

Y4

Y5

Figure 3: The picture on the left shows an HLC model with five observed and five latent
variables, each variable is annotated by its name and its cardinality. The picture
on the right shows the components we can decompose the HLC model into by
applying Theorem 1. Latent variables are shaded, while observed variables are
not.

in M might be designated to be observed in M1 or M2 as part of the definition of those
Mathematical objects.
We obtain a Bayesian network model B1 from M by deleting the Z-branch. Strictly
speaking B1 is not Bayesian network due to the parameterization it inherits from M : instead
of probability tables P (X) and P (Z|X), we have table P (X, Z). But P (X) and P (Z|X) can
readily be obtained from P (X, Z). With this in mind, we view B1 as a Bayesian network.
This network is obviously tree-structured. Its leaf variables include those in the set O and
the variable Z. We define M1 to be the HLC model that share the same structure as B1
and where the variable Z and all the variables in O are observed. The parameters of M1
are ~(0) and ~(1) .
Similarly let B2 be the Bayesian network model obtained from M by deleting the Xbranch. It is a tree-structure and its leaf variables include those in Y and the variable X.
We define M2 to be the HLC model that share the same structure as B2 and where the
variable X and all the variables in Y are observed. The parameters of M2 are ~(0) and ~(2) .
Theorem 1 Suppose M is a regular HLC model that contains two or more latent nodes.
Then the two HLC models M1 and M2 defined in the text are also regular. Moreover,
de(M ) = de(M1 )+de(M2 )[ds(M1 )+ds(M2 )ds(M )].

(2)

In words, the effective dimension of M equals the sum of the effective dimensions of M1
and M2 minus the number of common parameters that M1 and M2 share.
To appreciate the significance of this theorem, consider the task of computing the effective dimension of a regular HLC model that contains two or more latent nodes. By
8

fiEffective Dimensions of HLC Models

repeatedly applying the theorem, we can reduce the task into subtasks of calculating effective dimensions of LC models. As an example, consider the HLC model depicted by the
picture on the left in Figure 3. Theorem 1 allows us to, for the purpose of computing its
effective dimension, decompose the HLC model into five LC models, which are shown on
the right in Figure 3.
How might one compute the effective dimension of an LC model? One way is to use
the algorithm suggested by Geiger et al. (1996). The algorithm first symbolically computes
the Jacobian matrix, which is possible due to Assumption 1. Then it randomly assigns
values to the parameters, resulting a numerical matrix. The rank of the numerical matrix
is computed by diagonalization. Because the rank of Jacobian matrix equals the effective
dimension of the LC model almost everywhere, we get the regular rank with probability
one. This algorithm has recently been implemented by Rusakov and Geiger (2003). Kocka
and Zhang (2002) suggest an alternative algorithm that computes an upper bound. The
algorithm is fast and has been empirically shown to produce extremely tight bounds.
Going back to our example, the effective dimension of the LC models for X1 , X2 , X3 , X4
and X5 are 26, 23, 23, 34 and 17 respectively. Thus the effective dimension of the HLC model
in Figure 3 is 26+23+34+23+17(531)(361)(631)(351) = 61. In contrast,
the standard dimension of the model is 5+62+62+62+34+55+5+34+52+5 = 110.

5. Proof of Main Result
This section is devoted to the proof of Theorem 1. We begin with some properties of
Jacobian matrices of Bayesian network models.
5.1 Properties of Jacobian Matrices
Consider the Jacobian matrix JM of a Bayesian network model M . It is a matrix parameterized by the parameters ~ of M . Let v1 , v2 , . . . , vm be column vectors of JM .
Lemma 1 A number of column vectors v1 , v2 , . . . , vm of the Jacobian matrix JM are
either linearly dependent everywhere or linearly independent almost everywhere. They are
linearly dependent everywhere if and only if there exists at least one column vector vj that
can be expressed as a linear combination of other column vectors everywhere.
Proof: Consider diagonalizing the following transposed matrix:
[v1 , v2 , . . . , vm ]T .
~ Hence we would
According to Assumption 1, elements of the matrix are polynomials (of ).
multiply rows with polynomials or fraction of polynomials. Of course, we need also to add
one row to another row. At the end of the process, we get a diagonal matrix whose nonzero
elements are polynomials or fractions of polynomials. Suppose there are k nonzero rows
and suppose they correspond to v1 , v2 , . . . , vk .
Because elements of the diagonalized matrix are polynomials or fractions of polynomials,
~ If
they are well-defined 2 and nonzero almost everywhere (i.e. for almost all values of ).
k=m, then the m vectors are linearly independent of each other almost everywhere.
2. A fraction is not well defined if the denominator is zero.

9

fiZhang & Kocka

If k<m, there exist, for each j (k<jm), polynomials or fractions of polynomials ci
(1ik) such that
vj =

k
X

ci vi .

(3)

i=1

The coefficients ci s can be determined by tracing the diagonalization process. So vj can be
expressed as a linear combination of {vi |i = 1, . . . , k} everywhere 3 . 2
Although it might sound trivial, this lemma is actually quite interesting. This is because
JM is a parameterized matrix. The first part, for example, implies that there do not exist
two subspaces of the parameter space that both have nonzero measures such that the m
vectors are linearly independent in one subspace while linearly dependent in the other.
If m is the total number of column vectors of JM , we get the following lemma:
Lemma 2 In the Jacobian matrix JM , there exists a collection of column vectors that form
a basis of its column space almost everywhere. The number of vectors in the collection
equals to the regular rank of the matrix. Moreover, the collection can be chosen to include
any given set of column vectors that are linearly independent almost everywhere.
Proof: The first part has already been proved. The second part follows from the definition
of regular rank. The last part is true because we could start the diagonalization process
with the transpose of the vectors in the set on the top of the matrix. 2
5.2 Proof of Theorem 1
We now set out to prove Theorem 1. It is straightforward to verify that the HLC models
M1 and M2 are regular. So it suffices to prove equation (2). This is what we do in the rest
of this section.
The set of observed variables in M is O  Y, the set of observed variables in M1 is
O  {Z} and the set of observed variables in M2 is Y  {X}. Hence the Jacobian matrices
of models M , M1 , and M2 can be respectively written as follows:
JM

= [

JM1

= [

JM2

= [

P (O, Y)

,...,

P (O, Y) P (O, Y)
P (O, Y) P (O, Y)
P (O, Y)
;
;
]
,...,
,...,
(0)
(1)
(1)
(2)
(2)
k0
1
k1
1
k2

,...,

P (O, Z) P (O, Z)
P (O, Z)
;
]
,...,
(0)
(1)
(1)
k0
1
k1

(0)
1

P (O, Z)
(0)
1

P (X, Y)
(0)
1

,...,

P (X, Y) P (X, Y)
P (X, Y)
;
]
,...,
(0)
(2)
(2)
k0
1
k2

~ the ci s might be undefined for some
3. There is a subtle point here. Being fractions of polynomials of ,
~ So from equation (3) alone, we cannot conclude that vj linearly depends on {vi |i = 1, . . . , k}
values of .
everywhere.
The conclusion is nonetheless true for two reasons. First the set of ~ values where the ci s are
undefined has measure zero. Second, if vj does not linearly depend on {vi |i = 1, . . . , k} at one value of
~ then the same would be true in a sufficiently small and nonetheless measure-positive ball around that
,
value.

10

fiEffective Dimensions of HLC Models

It is clear that there is a one-to-one correspondence between the first k0 +k1 column vectors
of JM with the column vectors of JM1 and there is a one-to-one correspondence between
the first k0 and the last k2 column vectors of JM with the column vectors of JM2 . We will
first show
Claim 1: The first k0 vectors of JM (JM1 or JM2 ) are linearly independent
almost everywhere.
Together with Lemma 2, Claim 1 implies that there is a collection of column vectors in
JM1 that includes the first k0 vectors and that is a basis of the column space of JM1 almost
everywhere. In particular, this implies that de(M1 )k0 . Suppose de(M1 )=k0 +r. Without
loss of generality, suppose the basis vectors are
P (O, Z)
(0)
1

,...,

P (O, Z) P (O, Z)
P (O, Z)
;
.
,...,
(0)
(1)
(1)
k0
1
r

(4)

By symmetry, we can assume that de(M2 )=k0 +s where s0 and that the following column
vectors form a basis for JM2 almost everywhere:
P (X, Y)
(0)
1

,...,

P (X, Y) P (X, Y)
P (X, Y)
.
;
,...,
(0)
(2)
(2)
k0
1
s

(5)

Now consider the following list of vectors in JM :
P (O, Y)
(0)
1

,...,

P (O, Y) P (O, Y)
P (O, Y) P (O, Y)
P (O, Y)
;
;
.
,...,
,...,
(0)
(1)
(1)
(2)
(2)
k0
1
r
1
s

(6)

We will show
Claim 2: All column vectors of JM linearly depend on the vectors listed in (6)
everywhere.
Claim 3: The vectors listed in (6) are linearly independent almost everywhere.
Those two claims imply that the vectors listed in (6) form a basis of the column space of
JM almost everywhere. Therefore
de(M ) = k0 +r+s = de(M1 )+de(M2 )k0 .
It is clear that k0 =ds(M1 )+ds(M2 )ds(M ). Therefore Theorem 1 is proved. 2
5.3 Proof of Claim 1
Lemma 3 Let Z be a latent node in an HLC model M and Y be the set of the observed
nodes in the subtree rooted at Z. If M is regular, then we can set conditional distributions
of nodes in the subtree in such a way that they encode an injective mapping  from Z to
Y in the sense that P (Y=(z)|Z=z) = 1 for all z  Z .
11

fiZhang & Kocka

Proof: We prove this lemma by induction on the number of latent nodes in the subtree
rooted at Z. First consider the case when there is only one latent node, namely Z. In this
case, Z is the parent of all nodes in Y. Enumerate all these nodes as Y1 , Y2 , . . . , Yk . Because
Q
M is regular, we have |Z|  ki=1 |Yi |. Hence we can define an injective mapping  from
Q
Z to Y = ki=1 Yi . For each state z of Z, (z) can be written as y = (y1 , y2 , . . . , yk ),
where yi is a state of Yi . Now if we set
P (Yi =yi |Z=z) = 1,
then P (Y=(z)|Z=z) = 1.
Now consider the case when there are at least two hidden nodes in the subtree rooted
at Z. Let W be one such latent node that has no latent node descendants. Let Y (1) be
the set of observed nodes in the subtree rooted at W and Y(2) =Y\Y(1) . By the induction
hypothesis, we can parameterize the subtree rooted at W in such a way that it encodes an
injective mapping from W to Y(1) . Moreover, if all nodes below W are removed from M ,
M remains a regular HLC model. In that model, we can parameterize the subtree rooted at
Z in such a way that it encodes an injective mapping from Z to (W,Y(2) ) = W  Y(2) .
Together, those two facts prove the lemma. 2
Corollary 1 Let Z be a latent node in an HLC model M . Suppose Z have a latent neighbor
X. Let Y be the set of the observed nodes separated from X by Z. If M is regular, then
we can set probability distributions of nodes separated from X by Z in such a way that they
encode an injective mapping  from Z to Y in the sense that P (Y=(z)|Z=z) = 1 for
all z  Z .
Proof: The corollary follows readily from Lemma 3 and the property of the root-walking
operation (Zhang, 2002). 2
Proof of Claim 1: Consider the following matrix
[
(0)

(0)

P (X, Z)
(0)
1

...,

P (X, Z)
(0)

k0

]

(7)

(0)

Because 1 , 2 , . . . , k0 are the parameters for the joint distribution P (X, Z), this matrix
is the identity matrix if the rows are properly arranged. So its column vectors are linearly
independent almost everywhere.
(0)
(0)
Now consider the first k0 column vectors of JM : P (O, Y)/1 , . . . , P (O, Y)/k0 .
They must be linearly independent almost everywhere. If not, one of the vectors, say
(0)
P (O, Y)/k0 , would linearly depend on the rest everywhere according to Lemma 1.
Observe that for any i (1ik0 ),
P (O, Y)
(0)
i

=

X

P (O|X)P (Y|Z)

X,Z

P (X, Z)
(0)

i

.
(0)

Choose P (O|X) and P (Y|Z) as in Corollary 1. The vector P (O, Y)/i might contain zero elements. If we remove the zero elements, what remains of the vector is iden(0)
(0)
tical to P (X, Z)/i . So we can conclude that P (X, Z)/k0 linearly depends on
12

fiEffective Dimensions of HLC Models

(0)

(0)

P (X, Z)/1 . . . , P (X, Z)/k0 1 everywhere, which contradicts the conclusion of the
previous paragraph. Hence the first k0 vectors of JM must be linearly independent almost
everywhere.
It is evident that, using similar arguments, we can also show that the first k0 vectors of
JM1 (JM2 ) are linearly independent almost everywhere. Claim 1 is therefore proved. 2
5.4 Proof of Claim 2
Every column vector of JM1 linearly depends on vectors listed in (4) everywhere. Observe
that
P (O, Y)
(0)
i

X

P (Y|Z)

Z

P (O, Y)
(1)
i

=
=

X

P (Y|Z)

Z

P (O, Z)
(0)

, i = 1, . . . , k0

(1)

, i = 1, . . . , k1 .

i
P (O, Z)
i

Therefore every column vector of JM that corresponds to vectors in JM1 linearly depends
on the first k0 +r vectors listed in (6) everywhere.
By symmetry, every column vector of JM that corresponds to vectors in JM2 linearly
depends on the first k0 and the last s vectors listed in (6) everywhere. The claim is proved.
2
5.5 Proof of Claim 3
We prove this claim by contradiction. Assume the vectors listed in (6) were not linearly
independent almost everywhere. According to Lemma 1, one of them, say v, must linearly
depend on the rest everywhere. Because of Claim 1 and Lemma 2, we can assume that v is
(2)
among the last r+s vectors. Without loss of generality, we assume that v is P (O, Y)/s .
~ there exist real numbers ci (1ik0 ), c(1) (1ir), and c(2)
Then for any value of ,
i
i
(1is1) such that
P (O, Y)
(2)
s

=

k0
X
i=1

ci

P (O, Y)
(0)
i

+

r
X

(1) P (O, Y)
(1)
i
i=1

ci

+

s1
X

(2) P (O, Y)
.
(2)
i
i=1

ci

Note that in the last term on the right hand side, i runs from 1 to s1.
The parameter vector ~ consists of three subvectors ~(0) , ~(1) and ~(2) . Set the parameters
(1)
~ (for the X-branch) as in Lemma 3. Then there exists an injective mapping  from X
to O such that
P (O=(x)|X=x) = 1 for all x  X .

(8)

For each of the vectors in (6), consider the subvector consisting only of elements for
those states of O that are the images of states of X under the mapping . Such subvectors
(0)
(1)
(2)
will be denoted by P (OX , Y)/i , P (OX , Y)/i , and P (OX , Y)/i . For any
values of ~(0) and ~(2) , we still have
13

fiZhang & Kocka

P (OX , Y)

=

(2)
s

k0
X

ci

P (OX , Y)

i=1

(0)
i

+

r
X

(1) P (OX , Y)
(1)
i
i=1

ci

+

s1
X

(2) P (OX , Y)
.
(2)
i
i=1

ci

(9)

Consider the first two terms on the right hand side:
k0
X

ci

r
X

(1) P (OX , Y)
(1)
i
i=1
k0
r
X
X
P (OX , Z)
P (OX , Z) X
(1) X
c
ci
+
P (Y|Z)
P (Y|Z)
i
(0)
(1)
i
i
i=1
i=1
Z
Z
k0
r
X
X
P (OX , Z) X
(1) P (OX , Z)
ci
+
}
P (Y|Z){ ci
(0)
(1)
i
i
i=1
i=1
Z

P (OX , Y)
(0)
i

i=1

=
=

+

ci

P

Because of (8) and the fact that P (O, Z) =
X P (X, Z)P (O|X), the column vector
(0)
(0)
P (OX , Z)/i is identical to the vector P (X, Z)/i . As we have argued when proving
(0)
Claim 1, the vectors {P (X, Z)/i |i=1, . . . , k0 } constitute a basis for the k0 -dimensional
(1)
Euclidian space. This implies that, each of the vectors P (OX , Z)/i can be represented
(0)
as a linear combination of the vectors {P (OX , Z)/i |i = 1, . . . , k0 }. Consequently, there
exist ci (1ik0 ) such that
k0
X

ci

P (OX , Z)

i=1

(0)
i

k0
X

P (OX , Y)

+

r
X

(1) P (OX , Z)
(1)
i
i=1

ci

=

k0
X

ci

P (OX , Z)

ci

P (OX , Y)

i=1

(0)

i

Hence

i=1

ci

+

(0)
i

r
X

(1) P (OX , Y)
(1)
i
i=1

ci

=

k0
X
i=1

(0)

i

Combining this equation with equation (9), we get
P (OX , Y)
(2)
s

=

k0
X

ci

P (OX , Y)

i=1

(0)
i

+

s1
X

(2) P (OX , Y)
.
(2)

i=1
i

ci

P

Because of (8) and the fact that the fact that P (O, Y) = X P (X, Y)P (O|X), the column
(1)
(1)
vector P (OX , Y)/i is identical to the vector P (X, Y)/i and the column vector
(2)
(2)
P (OX , Y)/i is identical to the vector P (X, Y)/i . Hence
P (X, Y)
(2)
s

=

k0
X
i=1

ci

P (X, Y)
(0)
i

+

s1
X

(2) P (X, Y)
.
(2)
i
i=1

ci

This contradicts the fact that the vectors in the equation form a basis for the column space
of JM2 almost everywhere (see (5) in Section 5.2) Therefore, Claim 3 must be true. 2
14

fiEffective Dimensions of HLC Models

6. Effective Dimensions of Trees
Let us use the term tree model to refer to Markov random fields on undirected trees over
a finite number of random variables. If we root a tree model at any of its nodes, we get a
tree-structured Bayesian network model. In a tree model, define leaf nodes be those that
have only one neighbor. An HLC model is a tree model where all leaf nodes are observed
while all others are latent.
It turns out that Theorem 1 enables us to compute the effective dimension of any tree
model. Consider an arbitrary tree model. If some of its leaf nodes are latent, we can remove
such nodes without affecting its effective dimension.
After removing latent leaf nodes, all the leaf nodes are observed. If some non-leaf nodes
are also observed, we can decompose the model into submodels at any observed non-leaf
node. The following theorem tells us how the model and the submodels are related in terms
of effective dimensions.
Theorem 2 Suppose Y is an observed non-leaf node in a tree model M . If M decomposes
at Y into k submodels M1 , . . . , Mk , then
de(M ) =

k
X

de(Mi )  (k  1)(|Y |  1).

i=1

After all possible decompositions, the final submodels either do not contain latent nodes
or are HLC models. Effective dimensions of submodels with no latent variables are simply
their standard dimensions. If an HLC submodel is irregular, we make it regular by applying
the transformation mentioned at the end of Section 3.2. The transformation does not affect
the effective dimensions of the submodels. Finally, effective dimensions of regular HLC
submodels can be computed using Theorem 1.
Proof of Theorem 2: It is possible to prove this theorem starting from the Jacobian
matrix. Here we take a less formal but more revealing approach.
It suffices to consider case of k being 2. The two submodels M1 and M2 share only one
node, namely Y . Let O1 and O2 be respectively the sets of observed nodes in those two
submodels excluding Y . Root M at Y . Then we have
P (Y, O1 , O2 )P (Y ) = P (O1 , Y )P (O2 , Y ).
Let ~0 be the set of parameters in the distribution P (Y ), ~1 and ~2 be respectively the sets
of parameters in the conditional probability distributions of nodes in M1 and M2 . Consider
fixing ~0 and letting ~1 and ~2 vary. In this case, the space spanned by P (Y ) consists of only
one vector, namely ~0 itself. Moreover, there is a one-to-one correspondence between vectors
in the space spanned by P (Y, O1 , O2 ) and vectors in the Cartesian product of the spaces
spanned by P (O1 , Y ) and P (O2 , Y ). Now let ~0 vary. This adds |Y |1 dimensions to each
of the four spaces spanned by P (Y, O1 , O2 ), P (Y ), P (O1 , Y ), and P (O2 , Y ). Consequently,
we have
de(M ) = de(M1 ) + de(M2 )  (|Y |  1).
The theorem is proved. 2
15

fiZhang & Kocka

7. Concluding Remarks
In this paper we study the effective dimensions of HLC models. The work is motivated by
empirical evidence that the BIC behaves quite well when used with several hill-climbing
algorithms for learning HLC models and that the BICe score sometimes leads to better
model selection than the BIC score. We have proved a theorem that relates the effective
dimension of an HLC model to the effective dimensions of two other HLC models that
contain fewer latent variables. Repeated application of the theorem allows one to reduce
the task of computing the effective dimension of an HLC model to subtasks of computing
effective dimensions of LC models. This makes it computationally feasible to compute the
effective dimensions of large HLC models. In addition, we have proved a theorem about
effective dimensions of general tree models. This and our main theorem allows one to
compute the effective dimension of arbitrary tree models.
Acknowledgements
This work was initiated when the authors were visiting Department of Computer Science,
Aalborg University, Denmark. We thank Poul S. Eriksen, Finn V. Jensen, Jiri Vomlel,
Marta Vomlelova, Thomas D. Nielsen, Olav Bangso, Jose Pena, Kristian G. Olesen. We
are also grateful to the annonymous reviewers whose comments have helped us greatly in
improving this paper. Research on this paper was partially supported by GA CR grant
201/02/1269 and by Hong Kong Research Grant Council under grant HKUST6088/01E.

References
Akaike, H. (1974). A new look at the statistical model identification. IEEE Trans. Autom.
Contr., 19, 716-723.
Bartholomew, D. J. and Knott, M. (1999). Latent variable models and factor analysis, 2nd
edition. Kendalls Library of Statistics 7. London: Arnold.
Cheeseman, P. and Stutz, J. (1995). Bayesian classification (AutoClass): Theory and
results. In Fayyad, U., Piatesky-Shaoiro, G., Smyth, P., and Uthurusamy, R. (eds.),
Advancesin Knowledge Discovery and Data Mining, AAAI Press, Menlo Park, CA.
Chickering D. M. and Heckerman D. (1997). Efficient Approximations for the Marginal
Likelihood of Bayesian Networks with Hidden variables. Machine Learning, 29, 181212.
Cowell, R. G., Dawid, A. P., Lauritzen, S. L., and Spiegelhalter, D. J. (1999). Probabilistic
networks and expert systems, Springer.
Kocka, T. and Zhang, N. L. (2002). Dimension correction for hierarchical latent class
models. in Proc. of the 18th Conference on Uncertainty in Artificial Intelligence
(UAI-02).
Geiger D., Heckerman D. and Meek C. (1996). Asymptotic model selection for directed
networks with hidden variables. In Proc. of the 12th Conference on Uncertainty in
Artificial Intelligence, 283-290.
16

fiEffective Dimensions of HLC Models

Goodman, L. A. (1974). Exploratory latent structure analysis using both identifiable and
unidentifiable models. Biometrika, 61, 215-231.
Lazarsfeld, P. F., and Henry, N.W. (1968).
Mifflin.
Rusakov, D. and Geiger, D. (2002).
networks. UAI-02.

Latent structure analysis. Boston: Houghton

Asymptotic model selection for Naive Bayesian

Rusakov, D. and Geiger, D. (2003). Automated analytic asymptotic evaluation of marginal
likelihood for latent models. UAI-03.
Schwarz G. (1978). Estimating the dimension of a model. In Annals of Statistics, 6, 461-464.
Settimi, R. and Smith, J.Q. (1998). On the geometry of Bayesian graphical models with
hidden variables. In Proceedings of the Fourteenth Conference on Uncertainty in
Artificial Intelligence, Morgan Kaufmann Publishers, S. Francisco, CA, 472-479.
Settimi, R. and Smith, J.Q. (1999). Geometry, moments and Bayesian networks with hidden
variables. In Proceedings of the Seventh International Workshop on Artificial Intelligence and Statistics, Fort Lauderdale, Florida (3-6 January 1999), Morgan Kaufmann
Publishers, S. Francisco, CA.
Zhang N. L. (2002). Hierarchical latent class models for cluster analysis. AAAI-02, 230-237.
Zhang, N. L., Kocka, T., Karciauskas, G., and Jensen, F. V. (2003). Learning hierarchical
latent class models. Technical Report HKUST-CS03-01, Department of Computer
Science, Hong Kong University of Science and Technology.
Zhang, N. L. (2003).
Structural EM for Hierarchical Latent Class Models. Technical
Report HKUST-CS03-06, Department of Computer Science, Hong Kong University
of Science and Technology.
Zhang, N. L. (2003b). Hierarchical latent class models for cluster analysis. Journal of
Machine Learning Research, to appear.

17

fiJournal of Arti cial Intelligence Research 21 (2004) 631-670

Submitted 9/03 published 6/04

PHA*: Finding the Shortest Path with A* in An Unknown
Physical Environment
Ariel Felner

Department of Information Systems Engineering,
Ben-Gurion University of the Negev, Beer-Sheva, 85104, Israel

Roni Stern
Asaph Ben-Yair
Sarit Kraus
Nathan Netanyahu

Department of Computer Science, Bar-Ilan University
Ramat-Gan, Israel, 52900

felner@bgumail.bgu.ac.il
sternr2@cs.biu.ac.il
benyaya@cs.biu.ac.il
sarit@cs.biu.ac.il
nathan@cs.biu.ac.il

Abstract
We address the problem of nding the shortest path between two points in an unknown
real physical environment, where a traveling agent must move around in the environment
to explore unknown territory. We introduce the Physical-A* algorithm (PHA*) for solving
this problem. PHA* expands all the mandatory nodes that A* would expand and returns
the shortest path between the two points. However, due to the physical nature of the
problem, the complexity of the algorithm is measured by the traveling eort of the moving
agent and not by the number of generated nodes, as in standard A*. PHA* is presented as
a two-level algorithm, such that its high level, A*, chooses the next node to be expanded
and its low level directs the agent to that node in order to explore it. We present a
number of variations for both the high-level and low-level procedures and evaluate their
performance theoretically and experimentally. We show that the travel cost of our best
variation is fairly close to the optimal travel cost, assuming that the mandatory nodes of
A* are known in advance. We then generalize our algorithm to the multi-agent case, where
a number of cooperative agents are designed to solve the problem. Speci cally, we provide
an experimental implementation for such a system. It should be noted that the problem
addressed here is not a navigation problem, but rather a problem of nding the shortest
path between two points for future usage.

1. Introduction
In this paper we address the problem of nding the shortest path between two points
in an unknown real physical environment, in which a mobile agent must travel around
the environment to explore unknown territories. Search spaces of path- nding problems
are commonly represented as graphs, where states associated with the search space are
represented by graph nodes, and the transition between states is captured by graph edges.
Graphs can represent dierent environments, such as road maps, games, and communication
networks. Moving from one node of the graph to another can be done by applying logical
operators that manipulate the current state or by having an actual agent move from one
node to another. The sliding-tile puzzle and Rubik's Cube (Korf, 1999) are examples of the
c 2004 AI Access Foundation. All rights reserved.

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

rst type, while a road map is an example of the second type. Graphs in search problems
can be divided into the following three classes:

Fully known graphs: If all the nodes and edges of a graph are stored in the com-

puter, then the graph is fully known. The input for such problems is usually the
complete graph which is represented by an adjacency matrix or an adjacency list. A
relevant problem in this case would be to nd, for example, the shortest path in a
road map in which all the nodes and edges are known in advance.

Very large graphs: Graphs that due to storage and time limitations are not completely known and cannot be fully stored in any storage device. Many graphs for
search problems have an exponential number of nodes. For example, the 24-tile puzzle problem has 1025 states and cannot be completely stored on current machines.
The input for such problems is usually speci ed by the general structure of a state
in the search space, the dierent operators, an initial state, and a set of goal states.
Only very small portions of such graphs are visited by the search algorithms or are
stored in memory.

Small, partially known graphs: The third class contains graphs that represent a
partially known physical environment. For example, a mobile agent in an unknown
area without a map does not have full knowledge of the environment. Given enough
time, however, the agent can fully explore the environment since it is not very large.
Due to the partial knowledge, only a small portion of the graph is given as input.

For the class of fully-known graphs, classical algorithms, such as Dijkstra's single-source
shortest-path algorithm (Dijkstra, 1959) and the Bellman-Ford algorithm (Bellman, 1958),
can be used to nd the optimal path between any two nodes. These algorithms assume that
each node of the graph can be accessed by the algorithm in constant time. This assumption
is valid since all the nodes and edges of the graph are known in advance and are stored in
the computer's memory. Thus the time complexity of these algorithms is measured by the
number of nodes and edges that they process during the course of the search.
For the second class of graphs the above algorithms are usually not ecient, since the
number of nodes in the graph is very large (usually exponential). Also, only a very small
portion of the graph is stored in memory at any given time. The A* algorithm (Hart, Nilsson, & Raphael, 1968) and its linear space versions, e.g., IDA* (Korf, 1985) and RBFS (Korf,
1993), are the common methods for nding the shortest paths in large graphs. A* keeps an
open list of nodes that have been generated but not yet expanded, and chooses from it the
most promising node (the best node) for expansion. When a node is expanded it is moved
from the open list to the closed list, and its neighbors are generated and put in the open
list. The search terminates when a goal node is chosen for expansion or when the open
list is empty. The cost function of A* is f (n) = g(n) + h(n) where g(n) is the distance
traveled from the initial state to n, and h(n) is a heuristic estimate of the cost from node
n to the goal. If h(n) never overestimates the actual cost from node n to the goal, we say
that h(n) is admissible. When using an admissible heuristic h(n), A* was proved to be
admissible, complete, and optimally eective (Dechter & Pearl, 1985). In other words, with
such a heuristic, A* is guaranteed to always return the shortest path. Furthermore, any
632

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

other algorithm claiming to return the optimal path must expand at least all of the nodes
that are expanded by A* given the same heuristic.
An A* expansion cycle is carried out in constant time. This is because it takes a constant
amount of time to retrieve a node from the open list, and to generate all its neighbors. The
latter involves applying domain-speci c operators to the expanded node. Thus the time
complexity of A* can also be measured in terms of the number of generated nodes.1
In this paper we deal with nding the shortest path in graphs of the third class, i.e.,
small, partially known graphs which correspond to a real physical environment. Unlike
graphs of the other two classes, where a constant number of computer operations are done
for node expansion, we cannot assume, for this type of graphs, that visiting a node takes
constant time. Many of the nodes and edges of this graph are not known in advance.
Therefore, to expand a node that is not known in advance, a mobile agent must rst travel
to that node in order to explore it and learn about its neighbors. The cost of the search in
this case is the cost of moving an agent in a physical environment, i.e., it is proportional
to the distance traveled by the agent. An ecient algorithm would therefore minimize the
distance traveled by the agent until the optimal path is found. Note that since small graphs
are considered here, we can omit the actual computation time and focus only on the travel
time of the agent. In this paper we introduce the Physical-A* algorithm (PHA*) for solving
this problem. PHA* expands all the mandatory nodes that A* would expand and returns
the shortest path between the two points. However, the complexity of the algorithm is
measured by the traveling eort of the moving agent. In order to minimize the traveling
As will be shown, PHA* is designed to to minimize the traveling eort of the agent by
intelligently choosing the next assignment of the traveling agent. As described below, many
times the agent chooses to rst move to nearby nodes even though they do not immediately
contribute to the proceeding of A*.
Unlike ordinary navigation tasks (Cucka, Netanyahu, & Rosenfeld, 1996 Korf, 1990
Stentz, 1994 Shmoulian & Rimon, 1998), the purpose of the agent is not to reach the goal
node as soon as possible, but rather explore the graph in such a manner that the shortest
path will be retrieved for future usage. On the other hand, our problem is not an ordinary
exploration problem (Bender, Fernandez, Ron, Sahai, & Vadhan, 1998), where the entire
graph should be explored in order for it to be mapped out. Following are two motivating
examples of real world applications for our problem:

Example 1: A division of troops is ordered to reach a speci c location. The coordinates of the location are known. Navigating with the entire division through unknown
hostile territory until reaching its destination is unreasonable and inecient. It is common in such a case to have a team of scouts search for the best path for the division to
pass through. The scouts explore the terrain and report the best path for the division
to move along in order to reach its destination in an ecient manner.

1. In fact, for A*, if the open list is stored as a priority queue, then it would take logarithmic time to
retrieve the best node. However, for many problems, such as the sliding tile puzzles and Rubik's Cube,
a simple rst-in rst-out queue suces (Korf, 1993ff Taylor & Korf, 1993ff Korf, 1997). Likewise, for the
linear space versions, such as IDA* and RBFS (which are based on depth-rst search), the assumption
that it takes constant time per each node is valid. Also we assume that the number of neighbors is
bounded.

633

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

Example 2: Computer systems connected to networks can be on- or o-line at
dierent times, and their throughput can be seriously degraded due to busy communication channels. Therefore, many networks cannot be represented as xed, fully
known graphs. Transferring large amounts of data (e.g., multimedia les) between
two computers over a network can often be time consuming, since the data may be
routed through many communication channels and computer systems before reaching
their destination. Finding the optimal path between these computer systems could
improve the transfer time of large les. Since the network may not be fully known,
nding an optimal path between two nodes requires some exploration of the network.
An ecient and elegant solution might be to send small packets (operating as scouts)
to explore the network and return the optimal path, given that the network is stable
for at least a short period of time. Assuming that a computer system on the network
is recognized only by its neighboring systems, we are faced with the problem of nding
an optimal path in a real physical environment.2

In general, it would be worthwhile to search for the optimal path when the following
conditions hold:
Preliminary search (with the usage of scouts) is possible and cheap.
The optimal path is required for future usage.
Often one might settle for a suboptimal path. However, if the path is needed for a
considerable trac volume, e.g., the path should be traveled a large number of times or
the path should be traveled simultaneously by a large number of agents, then nding the
optimal path is essential. In this paper we focus on solving such a problem.
The paper is organized as follows. Section 2 provides a more speci c formulation of
the problem in question. Section 3 discusses related work, and Section 4 presents the
PHA* algorithm for a single mobile agent. Several (enhanced) variations are introduced
and discussed for this domain, followed by extensive empirical results that demonstrate the
superiority of the more enhanced variants pursued. In Section 5 we provide an analysis of
PHA* and an overall evaluation of its performance. In Section 6, we provide a number of
generalizations for the multi-agent case, where a number of traveling agents are available for
solving the problem. Experimental results for these schemes are presented and discussed.
Section 7 contains concluding remarks and discusses future research. A preliminary version
of this paper appeared earlier (Felner, Stern, & Kraus, 2002).
2. Our research is concerned with high-level, abstract graphs and we do not intend to provide here a new
applicable routing algorithm. Current routing technologies maintain large databases that store the best
paths from node to node, broadcast changes in the network, and update the paths if necessary, thus
making essentially the network graph fully known. Also, in some network domains one can create and
destroy packages at will and thus does not necessarily have a given number of agents. Our algorithm
may be relevant to future network architectures and routing technologies, where routers will not use
these databases. This is not far-fetched in view, for example, of the rapid growth of the Internet. It is
thus conceivable that in the future storing all the paths would become infeasible.

634

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

2. Problem Specication
As was mentioned in general terms, the problem is to nd the shortest path between two
nodes in an unknown undirected graph. More speci cally, we assume a weighted graph,
where each node is represented by a 2-dimensional coordinate (i.e., its location in the real
world), and the weight of an edge is the Euclidean distance between its two nodes. The
input to the problem consists of the coordinates of the initial and goal nodes. The other
nodes are assumed not to be known in advance. The agent is assumed to be located at
the start node. The task is to nd the shortest path in the (unknown) graph between the
initial node and the goal node for future usage. In order to accomplish that, the agent is
required to traverse the graph and explore its relevant parts leading to the desired solution.
The agent is allowed to visit nodes and travel from one node to another via existing edges.
We assume here that when a node v is visited by the search agent, the neighboring
nodes are discovered, as well as the edges connecting them to v. This assumption is not
unreasonable, considering, e.g., that (trac) signs at a road intersection often indicate its
neighboring destinations and the lengths of the corresponding road segments that connect
it with these locations. Even without road signs, as scouts reach a new location, they can
look around, observe the neighboring locations, and assess their distances from their current
location. In general, the assumption that the neighboring nodes are discovered instantly is
fairly common in search problems and algorithms.3
Since the goal of the search is to nd the best path to the goal, it is clear { given
an admissible heuristic { that the agent must expand all nodes expanded by A*, as A*
is optimally eective (Dechter & Pearl, 1985). Let C be the length of the shortest path
from the initial node to the goal node. A* will expand all the nodes, such that, f (n) =
g(n) + h(n) < C and some of the nodes for which f (n) = C . We will refer to these nodes
as the (set of mandatory) A* nodes. As stated above, the agent must visit all the A* nodes
in order to nd the shortest path. However, it may need to visit additional nodes.
We make the following fundamental observations with respect to the problem in question:
First, even if the set of A* nodes is known in advance, the agent may need to visit
additional nodes while traversing related portions of the graph. This is because the
shortest path between two of the A* nodes may include graph nodes that do not
belong to the A* nodes, i.e., their f value is greater than C . Given the A* nodes,
nding the shortest path that visits all of them { this should not be confused with
the shortest path between the origin node and the goal node { could be considered
as solving the traveling salesman problem (TSP) with respect to the set of A* nodes.
Note that the TSP solution may include nodes that do not belong to the A* nodes.
Second, the agent does not know the A* nodes in advance. These nodes are added to
the open list and they are expanded as the search progresses. Thus our agent cannot
use a solution to the TSP, since TSP assumes that the nodes to be visited are provided
as input.
3. There are, however, domains where this assumption may not hold. In such domains, a node becomes
fully known only when the agent reaches it physically. In this work we restrict ourselves to the above
assumption. Other domains will be addressed as part of future work.

635

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

In most of the cases, the order in which A* nodes are expanded is very dierent from
the order in which they are visited according to the TSP solution. Thus the minimal
path traversing the A* nodes cannot be used.
Third, when a node is added to the open list the agent cannot know whether or not it
belongs to the A* nodes, since C is known only after the search is concluded. Consider
a node n that is in the open list, but is not at the head of the open list. Suppose
further that the agent is physically located near that node. It should decide whether
to slightly extend its path and visit node n or skip n and continue to the node at
the head of the open list. If n turned out to belong to the A* nodes, then visiting it
now may prove very bene cial. (This is because n might reach the head of the open
list when the agent will be physically located far away from it, so that visiting n at
that point will incur a signi cant travel cost.) However, if it turns out that n does
not belong to the A* nodes, then the (small) detour of visiting it has proven useless.
Intuitively, however, a decision never to visit such would result in a very bad strategy.
Thus the agent may visit nodes that do not belong to the A* nodes because of future
expected bene ts. The actual decision as to whether or not to visit n will depend on
the distance between the agent's location and n (at the time of the decision) and on
the agent's estimate as to whether n belongs to the set of A* nodes.
In the following sections we present the PHA* algorithm for ecient exploration of a
graph, in order to nd the shortest path between two given nodes by a single traveling
agent, as well as by multiple agents. We study dierent heuristics that direct the agent to
make an intelligent decision, in an attempt to achieve a small overall travel cost.

3. Related Work
Much research has been devoted to guiding a mobile agent for exploring new and unknown
environments in order to study them and map them out. Our work is dierent, in the
sense that it explores merely the necessary regions of the graph in order to retrieve the
shortest path between two nodes and not the entire graph. Most of the literature in this
area deals with a physical mobile robot that moves in a real environment. The published
research focuses usually on the issue of assisting the robot to recognize physical objects in
its environment. We refer the reader to (Bender et al., 1998), which contains an extensive
survey of various related approaches and state of the art techniques.
Another class of algorithms is navigation algorithms. A navigation problem is concerned
with navigating a mobile agent to the goal as fast as possible, not necessarily via the shortest
(optimal) path. A navigator will always proceed towards the goal, ignoring whether the
trail traversed thus far lies on the shortest path. Deviations from the optimal path are
neglected since the navigation problem is reconsidered after every move with respect to a
new source node, i.e., the current position of the agent. A navigation algorithm halts when
the mobile agent reaches the goal. The path passed usually lacks importance and is usually
not optimal. Our problem, on the other hand, is to nd an optimal path to the goal node
for future usage. Even if the agent nds a path to the goal node, the search continues until
636

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

the shortest path to the goal is found. Next, we describe briey some of the work done on
navigation in partially known graphs.
(Cucka et al., 1996) have introduced navigation algorithms for sensory-based environments such as automated robots moving in a room. They have used depth rst search
(DFS)-based navigation algorithms, that use a heuristic function for choosing the next node
that the agent should go to.
Real-Time-A* (RTA*) (Korf, 1990) and its more sophisticated version, Learning RealTime-A* (LRTA*), are also algorithms for nding paths between two nodes in a graph.
However, they deal with large graphs and assume that there is a constraint on the time of
computation and that a move should be retrieve in a given constant time. Thus a limited
search is performed, and the node with best cost in the search frontier is picked. The
problem solver then moves one step along the path to that node. The search then continues
from the new state of the problem solver. The merit of node n (in RTA* and LRTA*) is
f (n) = g(n) + h(n), similarly to A*. Unlike A*, though, g(n) is the actual distance of node
n from the current state of the problem solver, rather than from the original initial state.
The dierence between RTA* and LRTA* is that after the search is terminated, LRTA*
also stores the heuristic estimation value of each node visited by the problem solver. Also
the method that successor nodes are chosen are dierent for the two variations. Korf (Korf,
1990) proves that over a large number of runs, where for each run the start node is selected
at random, the stored value of each node visited by the LRTA* problem solver converges
to the optimal distance to the goal. Both RTA* and LRTA* are signi cantly dierent from
our approach, as they assume that a node can be expanded in the computer's memory
without an agent having to physically visit that node. (Also, these algorithms are designed
for large graphs.) Furthermore, RTA* does not nd the optimal path to the goal. A trivial
version of LRTA* could be used to solve our problem, e.g., by limiting the search depth to
one level, so that every node visited by the agent could be physically expanded. However,
such a variant will not be competitive with our approach, as it will perform like a simple
hill-climbing procedure. In addition, in order to attain the optimal path, LRTA* has to
select many start nodes at random. This is not relevant in our case, as we are given only
one initial node.
MARTA* (Knight, 1993) is a multi-agent version of RTA*. In MARTA* every agent runs
RTA* independently. Kitamura et al. (Kitamura, Teranishi, & Tatsumi, 1996) have modi ed MARTA* by using coordination strategies based on attraction and repulsion. These
strategies are employed only in tie-breaking situations. When using a repulsion strategy,
the idea is to spread agents, such that each agent intends to maximize its distance from the
others. Again, the path provided by this algorithm is not optimal and also, agents do not
need to physically visit a node in order to expand it. This work has inspired the algorithms
presented in this paper, as far as handling our multi-agent mutual decision is concerned.
Life-long planing A* (LPA*) (Koenig & Likhachev, 2002b) is a remarkable algorithm
that generalizes A* to handle a dynamically changing graph. LPA* is activated every time
the graph was changed in order to nd the current shortest path from the same given start
and goal nodes. It utilizes the fact that much of the old data explored by previous runs of
LPA* are still valid in the current run. A* is a special case of LPA* where the entire graph
has not been explored yet.
637

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

D*-lite (Koenig & Likhachev, 2002a) applies LPA* to the case that a mobile robot needs
to nd the shortest path in an unknown environment or in an environment that changes
dynamically (i.e., where edges are added and deleted at all times). In LPA*, the start
node is identical for all the runs. In D*-lite, however, the robot moves along the path and
calculates a new shortest path from its current location. D*-lite modi es LPA* so that
old data from previous runs will be eciently used in the case that the start node is also
changed according to the new location of the robot. D*-Lite is actually a simpli ed version
of a previous algorithm D* by Stenz (Stentz, 1994).
The main dierence between these algorithms and our approach is that they, too, expand
a node in the computer's memory without requiring that the mobile agent physically visit
that node. Indeed, following every move of the robot in D* Lite, changes in the graph are
provided immediately  the robot does not need to physically visit nodes in order to gather
rsthand this information. The task of the agent, in the context of D*, is to repeatedly
determine the shortest path between the current location of the robot and the goal location
as the edge costs of the graph changes while the robot moves. D* lite does not nd a path
and returns it. It is simply a navigation algorithm that guides the agent to the goal node
based on previous and new information about the terrain.
An agent operating in the real world must often choose between maximizing its expected
utility (according to its current knowledge of the \world") and learning more about its
environment, in an attempt to improve its future gains. This problem is known as the tradeo between exploitation and exploration in reinforcement learning (Kaelbling & Moore,
1996). Argamon et al. (Argamon-Engelson, Kraus, & Sina, 1998, 1999) address the tradeo between exploration and exploitation for an agent that moves repeatedly between two
locations. They propose a utility-based on-line exploration algorithm which takes into
account both the cost of attempting to improve the currently best route known and an
estimate of the potential bene ts over future task repetitions. If the expected utility from
exploration is positive, then the agent takes actions to improve its route otherwise, it
continues using the known path. The authors compare the utility-based on-line exploration
with a heuristic backtracking search algorithm that exhaustively searches the graph before
starting to perform the task, and with a randomized interleaved exploration algorithm.
They assume that the agent knows a path between any two nodes, while we make no such
assumption.
Argamon et al. also suggest that the larger the number of times that the task is repeated,
the more the merit of interleaved exploration diminishes. If the agent is required to move
back and forth between two nodes a large number of times, there is no need to decide
on-line whether to exploit or explore instead, the shortest path should be found as soon
as possible. Thus a good search algorithm may prove useful. In this respect our work
complements Argamon et al., as it provides ecient search algorithms in situations where
the optimal path is needed in advance. In contrast, applying the techniques of Argamon et
al. in these situations yields poor results as demonstrated in their experiments.
Roadmap-A* (Shmoulian & Rimon, 1998) is a more sophisticated single agent navigation
algorithm. It chooses to navigate to a node that is assumed to be close to the goal node. The
algorithm is supervised by a high-level procedure called A" (Pearl & Kim, 1982). Instead
of always selecting the best node from the open list, A" allows the search agent to choose
from a set of \good nodes". This set is called the focal set. The focal is a set of nodes from
638

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

the open list whose f value is greater than the value of the best node by no more than ".
Once the focal nodes are determined, a local search is performed to navigate the agent to
one of these nodes, which is believed to be close to the goal node. The role of the high-level
phase is to prevent the navigating agent from going in the wrong direction by considering
also the path traveled thus far.
In Roadmap-A*, " is a pre-speci ed constant, which determines the trade-o between
the local search and A*. For example, A0 is A* while A1 is just a local search, choosing
at each iteration any node that is believed to be close to the goal node. This algorithm
halts when the goal node is reached, and thus for " > 0 the optimal path might not be
known. The paradigm of Roadmap-A* is similar to ours, in the sense that a node is known
only after the agent explores it. In fact, in the trivial case where " = 0, Roadmap-A* is
very similar to our approach with the simple heuristic \shortest-known path" (presented in
Subsection 4.1 below). Further comments as to the basic dierence between RoadmapA*
and PHA* are provided in Section 5.
In summary, most of the above listed algorithms are navigation algorithms, i.e., they do
not necessarily require an agent to physically visit a node in order to expand it, and do not
necessarily return the optimal path to the goal node. Thus they inherently solve a dierent
problem from the one pursued in this paper.

4. PHA* for a Single Agent

We now turn to the description of the PHA* algorithm, focusing rst on the case where
only a single mobile agent is available.
Nodes in the environment can be divided into explored and unexplored nodes. Exploring
a node means physically visiting that node by the agent, and learning about its location
and the location of its neighbors. Our new algorithm PHA* activates essentially A* on the
environment. However, in order to expand a node by A*, this node must rst be explored
by the agent in order to obtain the relevant data associated with it (i.e., neighboring nodes
and incident edges). Throughout the discussion in this paper we treat PHA* as a twolevel algorithm. Although in principle PHA* could also be viewed as a one-level algorithm
(see further discussion in Subsection 4.2), we nd its two-level presentation to be more
well-structured and better understood conceptually. The two-level framework consists of a
high-level and a low-level routine. The high level (which invokes the low level at various
stages of PHA*), acts essentially like a regular A* search algorithm. It chooses at each
cycle a node from the open list for expansion. The heuristic function h(n) used here is the
Euclidean distance between n and the goal node. (This heuristic is admissible of course, by
de nition.) If the node chosen by the high level has not been explored by the agent, the
low level, which is a navigation algorithm, is activated to navigate the agent to that node
and explore it. After a node has been explored by the low level it is expandable by the high
level. If the chosen node has already been explored, or if its neighbors are already known,
then it is readily expandable by the high level without the need to send the agent to visit
that node. The pseudo-code for the high level is given below.

639

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

.
.
.
.
.
.
.

g

high-level(open-list) f
(open-list is not empty) f
target = best node from open-list
target is unexplored
f
explore(target) by the low level

while

if

then

g

g

expand(target)

4.1 Low-Level Algorithms

The high-level algorithm, A*, chooses to expand the node with the smallest f value in the
open list, regardless of whether or not the agent has already visited that node. If the chosen
node has not been visited by the agent, the low level instructs the agent to visit that node.
We call this node the target node for the low level. In order to reach the target node, we
must use some navigation algorithm. We have implemented a number of navigation variants
for the low level. We rst describe simple algorithms which only use known information
about the graph. We then present more ecient algorithms, which also explore the graph
during the navigation and provide new information for the high level. We assume that the
agent is in the current node and that it needs to navigate to the target node.
4.1.1 Simple Navigation Algorithms

Tree path: Like every best- rst search, A* spans the nodes which it generates in a

tree which is called the search tree. Every known node is a node in the search tree. The
most trivial way to move from one node to the other is through the search tree. The
tree-path algorithm instructs the agent to move from the current node to the target
node through the shortest path between them in the search tree. In other words,
the agent will walk up the tree from the current node until it reaches an ancestor of
the target node, and then walk from that node to the target node. This is a trivial
algorithm, and is presented here mainly for comparison purposes.

Shortest known path: Some of the nodes of the search tree have already been

explored by the agent, so that all of their incident edges are known. The search tree
nodes plus the additional edges of the explored nodes can be viewed as a subgraph
that is fully known. All the nodes of this subgraph are connected because they are
all part of the search tree. Using this subgraph, we can calculate the shortest path to
the target node via known nodes and edges. As mentioned above, nding the shortest
path in a known graph can be done easily, so the agent simply computes this shortest
path to the target node and travels along that path.4

Aerial path: Assuming that the agent is able to move freely in the environment and

is not restricted to the edges of the graph, we can simply move the agent from the

4. This navigation algorithm is similar to the local A* search in Roadmap-A* for the trivial case where
" = 0. In Roadmap-A*, the shortest path to the target node is determined in the known graph and the
agent moves along that path.

640

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

current node to the target node via the straight line connecting these nodes. This
method may be relevant when the search agents are highly mobile, and they explore
the environment for agents that are restricted to travel only along the edges. Note
that the length due to \aerial path" can never be greater than the length due \shortest
known path".
4.1.2 DFS-Based Navigation Algorithms

In the simple navigation algorithms described above, the exploration of new nodes is done
only by the high-level algorithm. Thus the low level does not add any new knowledge about
the graph, and in that sense it is inecient. We propose here more intelligent navigation
approaches for nding a path to the target that can pass also trough unexplored nodes.
These approaches provide the following advantages: The paths that are currently known to
the agent may be much longer than other paths that have not been explored yet. It may
prove more ecient to navigate through unknown parts of the graph if they seem to lead to
a better path to the target. A more important advantage is that while navigating through
unknown parts of the graph, the agent might visit new nodes that have not been explored
and explore them on the y. This may save the need to travel back to those nodes at a
later time, should they be selected for expansion by the high-level algorithm.
The above advantages suggest the use of a DFS-based navigation for the low level. In
a DFS-based navigation algorithm, the search agent moves to a neighboring node, that has
not been visited, in a typical DFS manner. The algorithm backtracks upon reaching a deadend and the search continues until it reaches the target. If there is more than one neighbor,
we use a heuristic to evaluate which neighbor is more likely to lead faster to the target,
and visit that node rst. We have experimented with the following DFS-based navigation
algorithms that were proposed by (Cucka et al., 1996):

Positional DFS (P-DFS): This DFS-based navigation algorithm sorts the neighbors

according to their Euclidean distance from the target node, choosing the node with
minimum distance to the target node rst.

Directional DFS (D-DFS): This DFS-based navigation algorithm sorts the neigh-

bors according to the direction of the edges between them and the current node v. It
rst chooses the node u for which the dierence in angle between the line segments
(v u) and (v t) is the smallest, where t denotes the target node. In other words, the
nodes are prioritized by the directional dierence between them and the target node,
giving priority to nodes that dier the least.

A*DFS: A*DFS is an improved version of P-DFS. At each step the agent chooses

the neighbor w that minimizes the sum of the distances from the current node v to
w and from w to the target node t. We call it A*DFS since it uses a cost function
which is similar to that of A*, i.e., f (n) = g(n) + h(n).5 Note, however, that this cost
function is used here locally to nd a path from the current node to the target node.

5. A generalized version of navigating with a cost function similar to that of A* called \robotic A*" (RA*),
was also proposed by (Cucka et al., 1996)ff the node w is either a neighbor (of v) or an already visited
node.

641

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

This is dierent from the high-level A* which uses this cost function to nd a path
from the input initial state to the input goal state.
R
1

2
A

C

0000000000
T1111111111
0000000000
1111111111
11111111111
00000000000
0000000000
1111111111
00000000000
11111111111
0000000000D
1111111111
00000000000
11111111111
00000000000
11111111111
00000000000
11111111111

P

Figure 1: Illustration of various low-level navigation algorithms.
Figure 1 illustrates the navigation algorithms listed above. Let R denote the source
node, and suppose that the search agent is currently at node C , and that the high-level
procedure chooses to expand node T . The squared nodes have already been visited by the
agent, i.e., they have already been explored. These nodes and the edges connecting them
comprise the tree spanned by the high-level A* search. Since T has yet to be explored, the
low-level procedure will now navigate to the target node T . The tree path will navigate
along the path C ; 1 ; R ; 2 ; T , whereas the shortest known path will navigate along the
path C ; 1 ; 2 ; T . Note that since node A has yet to be explored, the path from C to T via
A is not known at this point. The aerial path will go directly from C to T . Using one of the
DFS-based navigations, the agent will move to T via P , D, or A depending, respectively,
on whether P-DFS, D-DFS, or A*DFS was used. The bene t of the DFS-based algorithms
is that they explore new nodes during the navigation (nodes P , D, and A in the above
example), and they will not revisit such nodes, should the high-level procedure expand
them at a later stage.

4.2 Enhanced PHA*
4.2.1 PHA* as a One-Level Procedure

As mentioned in the previous subsection, PHA* can be presented in principle as a one-level
algorithm. This can be done as follows. Whenever the best node in the open list is known
(i.e., it has been explored), an expansion cycle of A* takes place in the background, and
a new best node is determined. Upon arriving at a node, the agent makes a navigation
decision as follows:
If the best node in the open list is one of the current node's neighbors, then the agent
moves to that node.
Otherwise, the agent moves to the neighboring node that minimizes the relevant
heuristic function (among the variants proposed in the previous subsection).
642

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

Any of the these heuristics would be valid for a heuristic function of this one-level
algorithm. (The latter should not be confused with the heuristic function that is associated
with the A* expansion cycle.) For example, if the agent is at node v, then using A*DFS it
will visit the neighbor w that minimizes the sum of the distances from the current node v
to w and from w to the best current node in the open list.
The compact one-level presentation notwithstanding, we prefer { for reasons of clarity
{ to use the two-level formulation of PHA*. We believe that the clear distinction between
the high-level A* and the low-level navigation procedure provides an overall framework
that is well-structured and conceptually more clearly understood. In addition, the twolevel framework lends itself naturally to the two enhancements presented in the following
subsections.
These enhancements draw on the basic principle that navigation might proceed not
necessarily to the best node, but to a dierent node that is fairly close to the current
location of the agent. (The idea being that in the long run this would prove bene cial.) This
principle can be realized under two main scenarios: (1) When navigating to the best node,
the agent might choose rst to visit a nearby neighbor, and (2) the procedure might choose
to ignore the best node in the open list and select instead a dierent node from the open list
which is very close to the agent's location. In the context of the two-level framework, the
rst scenario corresponds to a low-level enhancement (see I-A*DFS below), and the second
scenario corresponds to a high-level enhancement (see WinA*, subsection 4.2.3).
For all of the above reasons, we choose to stick with our proposed two-level approach of
PHA*.
4.2.2 Improved Low Level: I-A*DFS

The DFS-based navigation algorithms explore new nodes as they traverse the graph, thereby
avoiding future navigations should these nodes be selected later for expansion by the high
level. While this is very bene cial, as can be seen from the experimental results of the next
subsection, we can take this approach much further.
Suppose that the agent is navigating to a target node. Along the way, it may pass near
nodes that have a small f value without visiting them, as they are not on the path to the
target node according to the navigation algorithm. This is counter-productive, since nodes
with small f values are likely to be chosen for expansion by the high level in the near future.
Visiting such nodes when the agent is nearby, may save a lot of traveling eort in the future.
In order to motivate the agent to visit such nodes, we want to identify them and arti cially
decrease their cost value (without changing the value of other nodes).
To incorporate this notion, we introduce the Improved A*DFS (I-A*DFS) variant. The
basic concept is that while navigating to a target, the low level will select the next node to
visit by considering not only its approximate distance from the target but also the node's f
value. On its way to the target, I-A*DFS should tend to visit, on the one hand, nodes with
a small f value, and avoid visiting, on the other hand, nodes that are completely o track.
Let T and n denote, respectively, the target node and the neighboring node that is being
currently evaluated. Also, let f (:) denote the f value of a node provided by the high-level
A*, and let c1 , c2 denote constants to be speci ed. We used the following heuristic function
for selecting the next node by I-A*DFS:
643

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu


 c2 
( 
A
DFS(
n
)
 1 ; c1 ff((Tn))
if n 2 OPEN
h(n) =
(1)

A DFS(n)
otherwise:
If a neighbor n is not in the open list, then its h(n) value due to A*DFS remains intact. If,

however, the neighboring node is in the open list, then I-A*DFS considers also the goodness
of its f value. The node's h(n) is adjusted according to a product term that decreases with
the node's f value (i.e., a node with a small f value will be assigned a smaller heuristic)6 .
Speci cally, the goodness of f is measured by the ratio f (T )=f (n). The target node T has
the smallest f value among the nodes in the open list (for otherwise it would not have been
selected for expansion by the high level) and therefore 0 < f (T )=f (n) < 1. If f (T )=f (n) is
close to 1, then f (n) is close to f (T ). In this case, it is highly probable that node n will be
visited by A* in the next few steps. Thus we want to assign a higher priority to such a node
to be visited by the agent, by decreasing its heuristic value. If, however, f (n) >> f (T )
(i.e., f (T )=f (n) ! 0), then it is highly unlikely that node n will be selected anytime soon
by the high level A*. It is of no interest to raise the node's priority, in such a case, and its
A*DFS heuristic should be retained, just like other nodes that are not in the open list.
The expression provided in (1) meets all of the above requirements. If f (n)  f (T ), then
the term 1 ; f (T )=f (n) becomes small, and the overall h value for such a node decreases.
This provides the agent with an option to visit nodes that are in the open list and which
have small f values, even though their A*DFS heuristic is not the best. If, on the other
hand, f (n) >> f (T ), then the term 1 ; f (T )=f (n) will approach 1, having a negligible eect
on h(n). The main reason for multiplying the A*DFS heuristic by 1 ; f (T )=f (n) (and not
by f (n)=f (T ), for example) is to leave intact the cost value of a node with a relatively large
f value, so that it can continue to compete (in a local heuristic sense) with nodes which
are not in the open list. The free parameters, c1 and c2 , do not aect qualitatively the
performance of I-A*DFS, but merely add to the module's overall exibility.
We have experimented with various constants for c1 and c2 , in an attempt to determine
optimal performance. Our extensive empirical studies have shown that c1 = 0:25 and
c2 = 2:5 produced the best performance. Our experiments have also demonstrated that
using I-A*DFS yielded better results than those obtained by the other navigation algorithms
listed in Subsection 4.1.2.
Figure 2 illustrates the dierence between A*DFS and I-A*DFS. The numeric values of
the nodes indicate the order by which they are expanded by A*. Suppose that the agent
is currently located at node C and that node 1 is the target. A*DFS will navigate to the
target via node 5, since this node has the best f (= g + h) value for the scenario described.
Once at node 1, the agent will have to travel back to the other side of the graph, as node 2
is selected (by the high level) to be expanded next. The agent will then go back to node 3
and eventually reach the goal via node 4. I-A*DFS, on the other hand, will navigate from
C to node 1 via node 2 although node 2 is not assumed to be on the shortest path to
node 1, it has a smaller f value than node 5. Thus I-A*DFS chooses to visit node 2 rst.
Incorporating this principle saves a considerable amount of travel cost. When the agent
will be located at node 1 and the next node to be expanded will be node 2, the high level
6. Since A*DFS(.) and f (:) measure distances on the graph, they represent, essentially, the same scale.
Thus they can be combined directly.

644

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

R

5
1

C

3

2
4

A*DFS
I-A*DFS

G

Figure 2: An example of A*DFS versus I-A*DFS navigation.
will expand it immediately, as it has been explored before by the agent, and will thus be
readily available. Thus the agent will travel directly from node 1 to node 3 and will avoid
navigating back and forth between opposite sides of the graph.
4.2.3 Improved High-Level: WinA*

A* expands the nodes from the open list in a best- rst order according to their f value.
This order is optimal when the complexity of expanding a node is O(1). However, in a real
physical environment, where node expansion requires an agent to perform costly tasks, it is
not always ecient to expand the current best node. Consider, for example, a nearby node
that is not the best node in the open list, but whose f value is suciently small, such that
with high probability it would be selected for expansion by A* in the next few iterations.
An intelligent agent will choose to explore such a node rst, even though it is not currently
the best node in the open list.

R
4
8

5
6

7

9

G
Figure 3: An example illustrating the disadvantage of A*.
The above principle is illustrated, for example, by the subgraph of Figure 3 which
contains two node clusters. The numeric label of each node is associated with its f value.
An agent visiting the nodes in a best- rst order (i.e., the order by which A* expands them),
will have to travel back and forth from one cluster to the other. A much better approach
645

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

would be to explore all the nodes in one cluster and then move to the other cluster, thereby
traveling only once from one cluster to the other.
In order to incorporate this capability into our algorithm, we generalized A* to what we
call Window A* (WinA*). While A* chooses to expand the node with the lowest f value,
WinA* creates a set (i.e., a window) of k nodes with the smallest f values and then chooses
one node from the set for expansion7 . Our window uses the same principle of A" (Pearl
& Kim, 1982) which was mentioned before. After constructing the window we select from
it a node for expansion. Our objective is to minimize the traveling eort of the agent,
and not to reduce, necessarily, the number of expanded nodes. Thus rather than selecting
only those nodes that have a small f value, we choose also nodes that are suciently close
to the location of the agent. Having experimented with a large number of combinations,
we concluded that the best way of capturing these two aspects was by simply taking their
product. Thus we order the nodes of the window by the cost function

c(n) = f (n)  dist(curr n)
where n is the node evaluated, f (n) is its f value, and dist(curr n) is the distance between n
and the current location of the agent. We choose to expand the node with the smallest cost c.
(It is sensible to combine f (n) and dist(curr n) in the above manner, as both are expressed
in the same distance units.) Note that if a node with a small f value is not chosen for
expansion, then its f value relative to other nodes in the open list will tend to decrease over
time. This is because the f value of newly generated nodes is monotonically increasing,
as the heuristic used is consistent and admissible. This property reduces the chance for
starvation. (At least we have not encountered this phenomenon in our experiments.)
Our intention was to demonstrate that combining these two factors, in a manner that
favors nearby nodes having a small f value, indeed yields enhanced performance. We have
tried many functions that combine the two factors (e.g. weighted sum) but choose in this
paper to only discuss the product, c(n) = f (n)  dist(curr n), since it provided the best
results.
Combining this modi ed high-level variant with the low-level navigation creates some
technical diculties, due to the fact that we no longer expand nodes from the open list
in a best- rst order. Recall that standard A* expands a node by generating its neighbors
and putting the node in the closed list. When a node v is in the closed list, the shortest
path from the source node to v is known. Hence, when the goal is expanded we have found
the shortest path to it, and the search can terminate. However, in WinA* a node may
be expanded although there exists another node with a smaller f value that has not been
expanded yet. In other words, when a node v is expanded, it does not necessarily imply
that the best path to v has been found. Expanding a node with a smaller f value might
discover a better path. Thus the search cannot simply terminate once the goal node is
chosen for expansion.
This problem is solved by splitting the standard node expansion stage into two phases:
7. In a related algorithm that we have derived, k-best rst search (KBFS) (Felner, Kraus, & Korf, 2003),
a window of size k is determined from the open list, and all of the window nodes are expanded at the
same stage. The neighbors of all the nodes are generated and added to the open list, and only then does
a new iteration begins.

646

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

1. Node expansion. Expanding a node means visiting the node, generating all its
neighbors, and adding them to the open list. This stage takes place immediately for
each node chosen by the high level.
2. Node closing. Closing a node means removing it from the open list and putting it
on the closed list. This takes place only after all the nodes with a smaller f value
have been explored. This ensures, essentially, that a node will be placed in the closed
list only when the best path to it from the source node has been found (See Section 5
for further comments). Thus the search will continue, even if the goal node has been
expanded, until it is placed in the closed list. Only when the goal node is placed in
the closed list, does the search terminate.
Following is the pseudo-code for WinA*. Note that the standard expansion is divided
according to the above two phases. At the end of each cycle, the algorithm attempts to
close as many nodes as possible.
WinA*() f
.
(goal is not in closed-list) f
.
target = node from window that minimizes (node)  dist(current node)
.
target is unexplored
.
explore(target) by low level
.
expand(target)
.
(best node (with minimal f value) in open-list was expanded)
.
close(best node)
.
g

while

if

f

then

while

g

4.3 Experimental Results

Figure 4: A 20-node Delaunay graph.
We have experimented with Delaunay graphs (Okabe, Boots, & Sugihara, 1992), which are
derived from Delaunay triangulations. The latter are computed over a set of planar point
patterns, generated by a Poisson point process (Okabe et al., 1992). Points are distributed
647

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

at random over a unit square, using a uniform probability density function. A Delaunay
triangulation of a planar point pattern is constructed by creating a line segment between
each pair of points (u v), such that there exists a circle passing through u and v that encloses
no other point. Such a triangulation can be characterized, in a sense, as one where each
point is joined by a line segment to each of its nearest neighbors but not to other points.
(We will refer to this type of Delaunay graphs as regular Delaunay graphs.) We have used
the Qhull software package (Barber, Dobkin, & Huhdanpaa, 1993) to construct Delaunay
triangulations (i.e., Delaunay graphs) over sets of points that were generated at random in
a unit square. Figure 4 illustrates a 20-node Delaunay graph.
In principle, the characteristic whereby each node is connected to all its neighbors seems
suitable for representing real road maps, which are the main object of our research. In
practice, however, additional characteristics should be accommodated to capture more adequately a real road map. Thus we have also pursued sparse and dense Delaunay graphs
that can be obtained from regular Delaunay graphs by random deletion and addition of
edges, respectively. (See Appendix A for a more detailed discussion.)
4.3.1 Low Level Experimental Results
90
Tree path
Shrtest known path
Aerial path
P-DFS
D-DFS
A*DFS
I-A*DFS

80
70

Search cost

60
50
40
30
20
10
0
500

1000

1500
2000
2500
3000
Number of nodes in the graph

3500

4000

Figure 5: Search cost versus the number of nodes of regular Delaunay graphs for various
low-level algorithms.
Figure 5 displays the traveling distance (or search cost) of the agent as a function of
the number of nodes in the Delaunay graph (i.e., 500, 1000, 2000, and 4000 nodes). The
graphs depicted correspond to the various low-level algorithms that PHA* was tested on.
Every data point (here and in all the other experiments) corresponds to an average of 250
dierent pairs of initial and goal nodes, that were picked at random. The average optimal
path observed was about 0.55.8 The gure clearly demonstrates the higher eciency of the
more involved algorithms. In particular, I-A*DFS is consistently superior to all the other
algorithms for all graph sizes. For a graph of size 4000, for example, it outperformed the
8. Note the closeness between the average optimal path observed (i.e., 0.55) and the expected arc length of
a random graph dened over the same set of points (i.e., 0.521) (Ghosh, 1951).

648

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

most simple algorithm by a factor of more than 10, and outperformed the basic A*DFS by
a factor of more than 2. Note that the search cost increases as the number of nodes grows,
i.e., as the domain becomes denser or more connected. This is attributed to the fact that as
the number of nodes grows, so does the number of nodes in the closed list that the I-A*DFS
procedure has to visit.
The relative performance of the various algorithms we have considered remained the
same for sparse and dense Delaunay graphs (see Appendix A).
4.3.2 Experimental Results for WinA*
6
500 nodes
1000 nodes
2000 nodes

5.5
5

Search cost

4.5
4
3.5
3
2.5
2
1.5
0

10

20

30

40
50
Window size

60

70

80

Figure 6: Search cost of WinA* versus window size for various sizes of regular Delaunay
graphs.
Our experiments show that using WinA* as the high-level procedure of PHA* leads to
a signi cant improvement of the eciency of our algorithm. Figure 6 presents the average
distance traveled by the search agent until the optimal path was found, as a function of
the window size. I-A*DFS was employed for the low-level algorithm. The results shown in
Figure 6 indicate that using a window of size larger than 1 (which corresponds to standard
A*) signi cantly improves the algorithm's performance for the various graph sizes that we
have experimented with. Also, we have found that the optimal size of the window tends to
vary with the size of the graph. Based on our empirical observations, setting the optimal
window size to (1=50) times the number of nodes in the graph seemed to provide a very
good approximation. (For example, the best window sizes observed for 500- and 2000-node
graphs were 10 and 40, respectively.) Note that as the window size becomes larger (i.e.,
the number of candidate nodes increases), the algorithm tends to select nodes with a large
f value, which results in performance degradation. Additional results for sparse and dense
Delaunay graphs are presented in Appendix A.
At a rst glance, the improvement of WinA* over standard A* (for the high level) seems
somewhat modest, as it does not exceed 30%. This is due to the fact that I-A*DFS explores
many nearby nodes, and is already very powerful to begin with. Both WinA* and I-A*DFS
are designed to assign high priority to nearby nodes. They do so at dierent stages of
the PHA* algorithm, but in a sense they \compete" for the same type of improvement.
649

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

Indeed, using any of the other navigating algorithms, the improvement of WinA* relative
to standard A* was much more signi cant. However, in dealing with real physical agents |
let alone humans | even the 30%-time reduction by WinA* (relative to I-A*DFS) should
be viewed as signi cant. Similar results were obtained for sparse and dense Delaunay graphs
(see Appendix A).

5. Analysis of PHA*
Analyzing the performance of PHA*, we distinguish between the following three parameters:
(1) Cost of returned path, (2) shortest possible path that the agent can travel, and (3) cost
of actual path traveled by the agent. In Subsection 5.1 we argue that the path reported by
PHA* (for future use) is optimal. In addition, we present in Subsection 5.2 an extensive
empirical study that compares between (2) and (3). Finally, we provide in Subsection 5.3
a brief discussion of PHA*'s underlying methodology and overall performance.

5.1 Optimality of Solution

Recall that A* expands nodes in a best- rst order according to their f value. If the heuristic
function, h(n), is admissible, then f (n) = g(n)+ h(n) is a lower bound on a path to the goal
via node n. It is well-known, under this paradigm, that once the goal node is selected for
expansion, A* has found an optimal path (Hart et al., 1968 Karp & Pearl, 1983 Dechter
& Pearl, 1985). Put dierently, if upon goal expansion f (goal) = c, then all other nodes
with estimated paths of f (n) < c have already been expanded and the length of the optimal
path to the goal is c (Karp & Pearl, 1983 Dechter & Pearl, 1985).
PHA* is supervised by the high level, which activates an admissible A*. (Recall that
h(n) is the Euclidean distance from n to the goal, i.e., it is admissible.) By design of the
algorithm, the high level terminates once the goal node is selected for expansion. Thus by
the properties of admissible A*, all the nodes having a smaller f value must have already
been expanded, and the f value of the goal is optimal. Note that this also holds for enhanced
PHA* with WinA* (see Subsection 4.2.3). Although WinA* does not necessarily expand
nodes according to the best f value, it is designed to remove a node from the open list only
if it has the smallest f value among the nodes on the list. The algorithm halts only after
the goal node has been expanded and removed from the open list, implying that its f value
is the smallest on the list. Thus our enhanced PHA* variant is also compatible with the
admissible A* paradigm, and the path it returns is optimal. The basic theoretical result of
the paper follows.
Theorem: PHA* and its enhanced versions return the optimal path between the start
node and the goal.

5.2 Performance Evaluation of PHA*
As demonstrated above, the more complex algorithmic schemes provided a dramatic improvement in search time. It is of interest to assess, at least to some extent, the performance
of our best navigation variant, i.e., WinA* (for the high level) in conjunction with I-A*DFS
(for the low level).
650

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

graph
size
30
50
75
100
150
200
250
300

closed
nodes
11.32
15.45
17.93
20.32
24.12
28.43
31.57
35.78

jTSP j
0

0.62
0.74
0.77
0.85
0.91
0.99
1.02
1.05

PHA* ratio
0.80
0.94
0.97
1.10
1.27
1.42
1.48
1.51

1.29
1.27
1.22
1.29
1.39
1.43
1.45
1.44

Table 1: Comparison between shortest paths through nodes in closed list and actual paths
obtained by PHA*.
The agent's task is to visit essentially all the nodes that are expanded by A*. These
nodes comprise the set of nodes that are in the closed list when the algorithm terminates.
In general, invoking A* on the subgraph induced by these nodes, with the same source and
goal states and the same heuristic function, will exhibit the same behavior and yield the
same open and closed lists. Thus given a static graph, the set of nodes which A* should visit
is xed. Ideally, we would like the agent to visit this set of closed nodes along the shortest
possible path. This is of course infeasible, since the nodes are not known in advance, but
rather determined on the y. However, in order to evaluate our algorithm's performance,
we can compare its output with the shortest possible path that travels through all these
nodes. The computation of the latter is carried out o-line, i.e., after the set of (closed)
nodes is known.
Speci cally, we have computed the shortest possible path in each case with respect to the
complete graph of the corresponding set of closed nodes. The weight w(ni nj ) associated
with an edge (ni nj ) (in the complete graph) was set to the length of the shortest path
from ni to nj (in the original Delaunay graph instance). Finding the shortest path that
travels via a given set of nodes is known as the traveling salesman problem (TSP), which
is notorious for its exponential running time. A conventional TSP path travels through all
the nodes and then returns to the start node. However, we are interested in a path that
travels through all the nodes without returning to the start node. We denote this path by
TSP to distinguish it from the conventional TSP tour. A TSP tour is actually a TSP tour
without the last edge. In view of the exponential nature of the problem, we have used a
simple branch-and-bound tree search to compute the desired paths. However, solving this
problem optimally was feasible only for relatively small graph sizes.
Table 1 provides a comparison between PHA* and the shortest path that travels through
all the closed nodes for various small sized graphs. The table indicates that our PHA*
algorithm is quite ecient for small graphs. Speci cally, the average travel cost (due to
PHA*) was not greater than the shortest possible path (passing through all the closed
0

0

651

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

nodes) by more than 45%. For graphs having 200 nodes or less, the number of closed
nodes observed was smaller than 30. The average cost in these cases was computed over 50
random instances. For graphs sizes greater than 200, the average cost was computed over
5 instances only.
In order to evaluate, however, the performance of PHA* for graphs of larger size (where
the optimal path could not be computed in a reasonable amount of time), we employed a
lower-bound approximation to the cost of TSP . Speci cally, we have computed a minimum
spanning tree (MST) of the complete graph (de ned by the set of closed nodes). Let jTSP j
and jMSTj denote, respectively, the costs associated with the desired path and the minimum
spanning tree.
0

0

Claim:

0:5  jTSP j < jMSTj  jTSP j:
0

0

Proof: The claim follows from basic graph theory (Cormen, Leiserson, Rivest, & Stein,

2001). Speci cally, the inequality on the right hand side stems from the fact that TSP is
a spanning tree of the complete graph. Thus the cost of a minimum spanning tree must be
smaller than (or equal to) jTSP j.
To prove the inequality on the left hand side, we note that the triangular inequality
holds with respect to the above de ned complete graph. (That is, for any three nodes, ni ,
nj , and nk , w(nj nk )  w(ni nj ) + w(nj nk ).) This can be easily shown, based on the fact
that the triangular inequality holds with respect to the original Delaunay graphs and by
de nition of an edge weight in the complete graph. Thus we can construct a tour that goes
twice around the MST and then use the triangular inequality to shortcut some of its edges.
Hence
2  jMSTj  jTSPj > jTSP j
0

0

0

and the inequality on the left hand side follows. 2
Given the infeasible computation of jTSP j, the claim suggests jMSTj, instead, as a
reasonably good approximation. Speci cally, the inequality on the right hand side implies
that if the travel cost of the agent performing PHA* is, say, c  jMSTj, then the travel cost
of PHA* is no greater than c  jTSP j. Given that this is merely a lower bound, PHA* is
expected to perform better in practice.
Table 2 provides a comparison between PHA* and the MST lower bound on the shortest
path as described above. The average cost entered for each graph size was computed over
250 randomly generated instances. The table indicates that, on the average, the cost of
PHA* is at most 2.74 times that of the best possible path for graph sizes up to 8000 nodes
and corresponding sets of closed nodes of up to 460 nodes.
0

0

5.3 Discussion

As was repeatedly noted, any algorithm that returns the optimal solution must expand at
least all the nodes that are expanded by A*. Drawing on this basic premise, our PHA*
algorithm was designed to visit the set of \mandatory" nodes as eciently as possible. The
rationale of visiting also nearby nodes (whose f value is not necessarily the smallest) is that
such nodes are likely to be expanded in the next few iterations. In contrast, there is no
652

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

graph
size
400
500
1000
2000
4000
8000

closed
nodes
40.27
43.00
62.72
131.56
233.26
460.66

jMSTj

approx.
1.05
1.15
1.42
2.01
2.52
3.45

PHA* ratio
1.91
1.97
3.03
4.89
6.76
9.44

1.82
1.87
2.13
2.43
2.69
2.74

Table 2: Comparison between lower bounds on shortest paths through nodes in closed list
and actual paths obtained by PHA*.
bene t to this enhanced variation in the context of a navigation algorithm that does not
presume to return an optimal solution.
Reconsider Roadmap-A*, for example. A" is only activated to prevent the local navigation phase from going in the wrong direction. However, since this algorithm is not designed
to return an optimal solution, it will not deviate at any stage from its promising route to
visit a nearby node that may be expanded later on. Put dierently, there is no notion here
of a set of mandatory nodes that the agent has to visit. Furthermore, as soon as the agent
reaches the goal, the search halts. In conclusion, although both PHA* and Roadmap-A*
are two-level navigation schemes, their objectives are dierent and they solve essentially
dierent problems.
Based on the properties of admissible A* and by design of our algorithm, we have
argued that (enhanced) PHA* returns a path (for future use) that is optimal. In addition,
in the absence of a theoretically known bound on the actual cost of PHA*, we have run
an extensive empirical study, comparing between observed costs and the best possible costs
computed o-line. Given that the agent lacks a priori information as to the set of mandatory
nodes, it is highly unlikely that there exists an on-line PHA*-like algorithm that performs as
eciently as an o-line version. Our extensive empirical study demonstrates, nevertheless,
that the actual cost associated with PHA* is on the same order of magnitude as the optimal
cost computed o-line.

6. MAPHA*: Multi-Agent PHA*
In this section we generalize the techniques discussed in the previous sections to the multiagent case, where a number of agents cooperate in order to nd the shortest path. We call
the resulting algorithm Multi-Agent Physical A* (MAPHA*).
We would like to divide the traveling eort between the agents in the most ecient way
possible. We can measure this eciency for the multi-agent case using two dierent criteria.
The rst is the overall global time needed to solve the problem. The second is the total
amount of fuel that is consumed by all agents during the search. If the requirement is to
minimize the cost of moving the agents and time is not important, then considering the fuel
653

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

cost of mobilizing the agents will be the cost function of choice. In this case, it may be wise
to move some agents while other agents remain idle. However, if the task is to nd the best
path to the goal, as soon as possible, idle agents seem wasteful, as they can better utilize
their time by further exploration of the graph. In such a case, all available agents should be
moving at all times. We introduce below two algorithms for these two perspectives, namely
a fuel-ecient algorithm and a time-ecient algorithm. Note that in the single agent case
these two criteria coincide.
We assume that each agent can communicate freely with all the other agents and share
data at any time. Thus any information gathered by one agent is available and known to
all of the other agents. This framework can be obtained by using a model of a centralized
supervisor that moves the agents according to the complete knowledge that was gathered
by all of them. This is a reasonable assumption since in many cases there is a dispatcher
or some centralized controller that gathers information from the agents and instructs them
accordingly. Another possible model for complete knowledge-sharing is that each agent
broadcasts any new data about the graph to all the other agents. Future research may
address a more restrictive communication model, by limiting the communication range or
inducing communication errors.
We also assume that the search terminates, as soon as the goal node is expanded and
moved to the closed list. Our objective is to minimize the travel eort up to that point,
and we do not care about moving all the agents to some pre-speci ed location (e.g., the
goal vertex or the start node), after the desired shortest path is identi ed. This convention
is in accordance with many algorithms which neglect to report the time spent to \reset" a
system (e.g., garbage collection), once the desired solution is arrived at.
The main idea of the MAPHA* algorithm is very similar to that of PHA* for a single
agent. We use again a two-level framework. The high level chooses which nodes to expand,
while the low level navigates the agents to these nodes. We have studied the multi-agent
case with our enhanced techniques only, i.e., WinA* for the high level and I-A*DFS for the
low level. The problem that we deal with below is how to assign the dierent agents to
explore eciently the dierent nodes.

6.1 MAPHA*: Fuel-Ecient Algorithm

For simplicity, we assume that the amount of fuel consumed by an agent is equal to its
traveling distance during the search. Since the purpose of the algorithm in this case is to
minimize the amount of fuel consumed by the agents, regardless of the overall search time,
there is no bene t to moving more than one agent at a time. This is because by moving
only one agent, that agent might gain new knowledge of the graph that would allow the
other agents to make more informed and intelligent moves.
At the beginning, all the agents are situated at the source node. Then, as in the case of
a single agent, the high level de nes a window of unexplored nodes from the open list that
are potential candidates for expansion. For each pair (a n), where a is an agent and n is a
node from the window, we compute the allocation cost function
c(a n) = f (n)  dist(a n)
where f (n) is the f value of node n and dist(a n) denotes the distance from the location of
agent a to node n. We then select an agent and a target node that minimize that allocation
654

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

function. In the case of tie-breaking (e.g., at the beginning of the search where all agents are
located at the initial state), we pick randomly one agent from the relevant candidates. At
this stage, the low-level algorithm navigates the selected agent to the target node selected
from the window in order to explore that node. As in the single-agent case, additional
knowledge about the graph is being obtained during the navigation as many unexplored
nodes are visited by the traveling agent. Only when the selected agent reaches its target is
a new cycle activated for the high- and low-level procedures.9 Following is the pseudo-code
for the fuel ecient algorithm.
fuel-efficient algorithm() f
.
(goal is not in closed-list) f
.
each agent i
.
select node i from the window that minimizes
.
best = agent that minimizes ( i)  dist( i i )
.
best is unexplored
.
explore( best ) by low level using best 
.
expand( best )
.
(best node in open-list was expanded)
.
close(best node)
.
g

while
for

a

a

if n

while

n

n

n

then

fn

a n

f (n)  dist(ai n)

a

g

6.2 MAPHA*: Time-Ecient Algorithm

The time-ecient algorithm is very similar to the above described fuel-ecient algorithm
with one basic modi cation. Instead of moving only one agent during each high-level cycle,
we now move all of the available agents since we only care about the time spent by the
agents and not about their fuel consumption. Having an idle agent will not save any time.
Every moving agent can only help gather more knowledge about the environment with no
additional cost, as the clock ticks away regardless and the time is measured globally.
We cannot use here the same allocation function that was used for the fuel-ecient
algorithm, as all agents are located initially at the same node, and the fuel-ecient allocation
function will choose the same node for all the agents. The main idea of the time-ecient
strategy is that all agents move simultaneously. Thus to ensure ecient performance we
need to distribute them as much as possible. Suppose that we have p available agents and k
nodes in the window. We would like to distribute these p agents to the k nodes as eciently
as possible. A brute-force approach will be to randomly distribute the agents to the nodes.
However, to provide an eective distribution, we incorporate the following three criteria
into our distribution formula for the time-ecient procedure:
1. Since the f values of neighboring nodes are somewhat correlated with each other,
nodes with a small f value are more likely to generate new nodes with a small f
9. We have also implemented a more complex variant, such that whenever a new unexplored node is reached,
a new high-level cycle is activated. Results obtained were not signicantly dierent, and we omit the
details of this variant for simplicity. See (Stern, 2001) for a comprehensive description.

655

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

values than nodes with a large f value. Therefore, the distribution should favor
assigning an agent to a node with a small f value.
2. Another attribute that should be taken into consideration is the distance of the target
node from an agent. We would like to assign an agent to one of the nodes in such
a manner, that the expected travel distance of the agent (for that assignment) is
minimized. In other words, an agent will be assigned, preferably, to a relatively closeby node.
3. In order to expand the entire window and prevent \starvation", we would also like our
distribution function to raise the priority of nodes that were assigned a small number
of agents. Thus we should keep track of the number of agents that were assigned to
each node and give preference to nodes with a small number of assignments.
Note that the rst and third criteria may contradict, i.e, the rst criterion will prefer
nodes with a small f value while the third criterion will favor nodes with a large f value,
as only a small number of agents was assigned to them.
We have found that taking the product of the values associated with these three criteria
gives a good distribution function with a suitable load balancing between these criteria.
Speci cally, the agent allocation procedure iterates through all the agents and picks, for
each agent, the node that minimizes the following allocation function:
alloc(agent node) = f (node)  dist(agent node)  (count(node) + 1)
where dist(node agent) is the Euclidean distance between the node and the agent, f (node)
is that node's f value, and count(node) is a counter that keeps track of the number of agents
that have already been assigned to explore that node. count(node) is initially set to 0 and
is incremented every time an agent is assigned to that node. Thus a load balancing between
the three factors is being kept throughout the distribution process. At the beginning of
the search all the agents are located at the start node, and their initial allocation to the
dierent nodes is determined, essentially, by the count factor. (Without this factor, the
product f (n)  dist(agent n) would have returned the same node n for all agents.) As the
search progresses, the agents move to dierent locations and get assigned at each step to
nodes that are closer to their location and that have a small f value. Thus the product of
the above three factors creates a good distribution (of the agents) over dierent parts of
the graph.
Consider, for example, the case illustrated in Figure 7. Suppose that 100 agents are all
located at node x, and that the window consists of the three nodes a, b, and c that are located
at an equal distance from x. Suppose also that f (a) = 2, f (b) = 4 and, f (c) = 8. The
numbers of agents that are assigned to these nodes, using the above allocation procedure,
are 57, 29, and 17, respectively. This is a good balance between the various requirements.
We have tried many other variations for the distribution procedure and found that they
all performed well as long as the above three requirements were met. See (Stern, 2001) for
further discussion on agent distribution.
As before, each agent navigates to its assigned target using our enhanced low-level algorithm, I-A*DFS. Another high-level iteration begins as soon the the rst agent reaches
656

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

x
a

b

f(a)=2

c
f(c)=8

f(b)=4

Figure 7: An example of agent distribution according to the proposed allocation procedure.
its target node.10 Note that the computation time of the window and that of the agent
distribution/allocation can be neglected, since we only care about the travel time of the
agents. Following is the pseudo code for the time-ecient algorithm.
time-efficient algorithm() f
.
(goal is not in closed-list) f
.
each free agent i
.
select a window node i that minimizes dist( i
.
move all agents until an agent reaches a node
.
expand all nodes currently visited by an agent
.
(best node in open-list was expanded)
.
close(best node)
.
g

while
for

a

n

a n)  f (n)  (count(n +1))

while

g

6.3 Experimental Results

The experiments performed for the multi-agent case were also conducted on Delaunay
graphs with 500, 1000, 2000, 4000, and 8000 nodes. Additional results for sparse and
dense Delaunay graphs are provided in Appendix A.
6.3.1 MAPHA*: Results for the Fuel-Efficient Algorithm

We provide here results for the fuel-ecient algorithm of Subsection 6.1. The fuel consumption reported is the total fuel consumed by all the agents. (As before, the graphs were
generated on a unit square, for which the average optimal path observed was about 0.55.)
Figure 8 presents the costs of the fuel-ecient algorithm as a function of the number
agents for various sizes of regular Delaunay graphs. (Results for sparse graphs, as well
as graphs with edges added at random, are presented in Appendix A.) The gure clearly
10. We have observed that when a new iteration begins, almost every agent is assigned to the same node
that it was assigned to in the previous iteration. Typically this is because an agent's location becomes
closer to \its" target node, while the other criteria do not change. Thus in practice, most of the agents
go on to complete their (original) tasks, and only the agent that has reached its target is assigned a new
goal node. See (Stern, 2001) for a detailed discussion.

657

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

6.5
500 nodes
1000 nodes
2000 nodes
4000 nodes

6
5.5

Fuel consumption

5
4.5
4
3.5
3
2.5
2
1.5
1

2

3

4

5
6
Number of agents

7

8

9

Figure 8: Fuel consumption as a function of number of agents for various sizes of regular
Delaunay graphs.
demonstrates that as more agents are added, the overall fuel consumption decreases up
to a point where adding more agents tends to increase the overall consumption. Thus an
optimal number of agents exists for each of the graphs. This phenomenon is due to the fact
that A* is usually characterized by a small number of search regions. Therefore, a small
number of agents suces to cover these regions. As the number of agents increases, the fuel
consumption goes up. This phenomenon is explained as follows. A large number of agents
increases the likelihood that a nearby agent will be assigned to a speci c node, in which
case relatively little exploration of the graph takes place. Assigning, on the other hand,
a distant agent to the node would result in a larger degree of graph exploration, which is
essential, in the long run, for ecient navigation (especially if I-A*DFS is employed). Thus
a large number of agents navigating in a small graph (which has few search regions), would
result in excessive fuel consumption. See (Stern, 2001) for a more detailed explanation of
this phenomenon.
The optimal number of agents increases as the number of nodes in the graph increases.
While the optimal number of agents for a graph of 500 nodes is 2, this number increases up
to 7 for a graph of size 4000. This stems from the fact that larger graphs have more search
regions and thus more agents are needed to explore them.
As described before, only one agent is allowed to move in this experiment, at any point
in time. Up to now we have measured the total amount of fuel consumed by all of the
agents. It is of interest to nd out whether the work is uniformly distributed among the
agents, or whether a large portion of the work is carried out by a small number of agents.
Table 3 presents the distribution of the work among the agents when up to 14 agents were
active on Delaunay graphs of size 8000. For each graph instance, we sorted the agents in
decreasing order of their fuel consumption. The table shows the relative fuel consumption
of the agents for 3, 7, and 14 activated agents.
In general, we remark that while the overall work is not uniformly distributed, it is quite
balanced. For example, when 14 agents are activated, 40% of the work is done by only 4
658

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

Agent No. 3 agents %] 7 agents %] 14 agents %]
1
42.03
28.34
16.01
2
33.54
19.32
13.21
3
24.43
16.23
11.41
4
12.76
10.31
5
9.02
6.64
6
7.86
5.48
7
6.48
5.08
8
4.54
9
4.10
10
3.59
11
3.20
12
3.02
13
2.81
14
2.70
Table 3: Work distribution among multiple agents running our fuel-ecient algorithm on
Delaunay graphs of size 8000.
agents. A similar tendency was observed for graphs of other sizes, as well as for sparse and
dense Delaunay graphs (see Appendix A).
In order to improve the eciency of the fuel-ecient algorithm and to make the overall
work distribution more balanced, several improvements might be suggested. For example,
currently all the agents are positioned initially at the same source node. We might consider
to rst spread the agents in a number of directions and only then invoke the algorithm.
Notwithstanding the additional overhead that may be incurred by spreading the agents,
this technique can result in a more balanced work distribution and in a reduced overall fuel
consumption.
6.3.2 MAPHA*: Results for the Time-Efficient Algorithm

In this subsection we report the results for the time-ecient algorithm of Subsection 6.2.
As was explained, if our main objective is to conclude the task as fast as possible, such
that fuel consumption is of no concern, then all agents should always be moving, i.e., none
of them should be idle at any point in time. The overall search time in this case is the
maximal distance that either agent travels until the shortest path to the goal node is found.
Figure 9 shows the search time obtained by the time-ecient algorithm as a function of
the number of agents, for various regular Delaunay graphs. Note that the search time can
never be smaller than the time it takes to travel along the shortest path to the goal. As the
results indicate, adding more agents is always ecient since we only measure the overall
time that has elapsed until the goal is found. What makes our algorithm interesting and
ecient is the fact that as we add more agents, the search time converges asymptotically to
659

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

10
500 nodes
1000 nodes
2000 nodes
4000 nodes
8000 nodes

9
8

Search time

7
6
5
4
3
2
1
0
0

2

4

6
8
Number of agents

10

12

14

Figure 9: Time consumption as a function of the number of agents, for various regular
Delaunay graphs.
the length of the shortest path. Recall that the average length observed of the shortest path
was approximately 0.55. Indeed, a large number of agents will tend to nd the optimal path
within a time frame that approaches the above limit. While the overall time was 2.3 with
a single agent, it was reduced to 0.7 with 14 agents for graphs with 500 nodes for example.
Using our proposed agent allocation procedure, we note that asymptotically all paths
from the initial state are traveled in a breadth- rst search manner. This is to say that a
suciently large team of agents is likely to produce a single agent that will travel along the
actual shortest path with very little deviation from it. Similar results for the time- ecient
algorithm were also obtained for other types of graphs (see Appendix A).

6.4 Combined Requirements of Fuel and Time

While the distinction between the time-ecient algorithm and fuel-ecient algorithm is
reasonable, it may not be suitable in many practical situations. Practical considerations of
time and fuel resources may suggest a combined approach, as the one described below.
Consider, for example, a commander operating under a constraint of fuel consumption
but with no restriction on the number of troops that can be assigned to a certain task. In
order to complete the task as fast as possible, the commander may want to use the maximal
possible number of agents without exceeding the fuel consumption limit.
In essence, we seek to generalize MAPHA*, such that the agents will minimize a cost
function which is a combination of time and fuel consumption. We suggest a general cost
function that takes into account the requirements on both these measures. The objective
will be to activate MAPHA*, so as to minimize this cost function. Speci cally, we suggest
the following linear combination:

Ctotal = wt  time + wf  fuel
where wt and wf are the (normalized) weights attached, respectively, to the time and fuel
consumption (i.e., 0:0  wt wf  1:0 and wt + wf = 1:0). Ctotal is calculated globally, i.e.,
660

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

we measure the amount of time from the beginning of the task until the optimal path is
found, and the total amount of fuel consumed by all the agents. We then multiply these
quantities by their corresponding weights and report the combined cost.
Both wt and wf are prespeci ed by the user. If wt = 0, there is no time cost and the
fuel-ecient algorithm will be the appropriate one to use. If wf = 0, there is no fuel cost,
and we can use the time-ecient algorithm. Otherwise, if neither wt nor wf is 0, we should
use a dierent algorithm to minimize Ctotal.
We suggest two algorithms for this general case.
Simple combined algorithm.
This algorithm is actually identical to the time-ecient algorithm. The number of
participating agents is a parameter provided by the user. At each iteration of the
high level all the participating agents move according to the allocation function of
the time-ecient algorithm. Given the formulation of the total cost, Ctotal, we would
like to determine the optimal number of agents, for any wt and wf . Note that in the
trivial case where wf = 0, adding more agents is always valuable, since they do not
consume any resources, and can only reduce the time cost. However, as wf increases,
a large number of agents may increase the total cost.
Improved combined algorithm.
The main limitation of the simple combined algorithm is that even though cost is
incurred for fuel consumption, all the agents are always moving. The improved combined algorithm addresses this problem and suggests moving only some of the agents
simultaneously. Using this formalization, we rst determine p, i.e., the number of
agents that will participate in the task. Given p, we then determine m, i.e., the number of agents that will actually be distributed to nodes selected from the window (by
the high level). The remaining p ; m agents will stay idle. Note that for the simple
combined algorithm p an m coincide. We use the same mechanism of the time-ecient
allocation function, except that here the algorithm chooses only m (out of p) agents
that minimize this allocation function. As in the time-ecient algorithm, we rst
determine the size of the window, i.e., the number of nodes from the open list that
should be expanded. Then, we invoke the same allocation function. Whereas in the
time-ecient case the allocation terminates once all the agents are assigned to nodes,
here the allocation stops after m agents are selected. The selected agents are the best
m agents for this expansion cycle since they minimize the allocation function.

6.5 Results for the Combined Algorithm

We provide experimental results for the combined algorithm that was introduced in the
previous subsection. The results in Tables 4 and 5 were obtained for Delaunay graphs
of size 2000 each table entry represents the average of 250 problem instances. For each
column, the bold face number is the smallest total cost for the corresponding wt =wf ratio.
These minimal costs determine the optimal number of agents for a given wt =wf ratio.
Table 4 provides total costs for the simple combined algorithm as a function of the
number of agents for various wt =wf ratios. The leftmost column corresponds to the case
661

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

wt
wf

1.0
0.0

# agents
1
4.82
2
2.58
3
1.74
4
1.44
5
1.24
6
1.11
7
1.03
8
0.97
9
0.93
10
0.89
11
0.85
12
0.84
13
0.84
14
0.82

0.9
0.1

0.8
0.2

4.82
2.84
2.09
1.87
1.73
1.67

4.82
3.10
2.44
2.30
2.23

1.65
1.68
1.70
1.70
1.77
1.84
1.88

2.33
2.42
2.50
2.56
2.70
2.84
2.94

2.22
1.64 2.26

0.7
0.3

0.6
0.4

0.5
0.5

0.4
0.6

4.82 4.82 4.82 4.82
3.36 3.61 3.87 4.13
2.79 3.14 3.49 3.84
2.73 3.16 3.60 4.03
2.72 3.22 3.71 4.21
2.78 3.33 3.89 4.44
2.88 3.49 4.11 4.73
3.01 3.69 4.37 5.05
3.17 3.91 4.66 5.40
3.31 4.11 4.92 5.72
3.41 4.26 5.11 5.96
3.63 4.56 5.49 6.42
3.84 4.84 5.85 6.85
4.01 5.07 6.13 7.19

0.3
0.7

0.2
0.8

0.1
0.9

0.0
1.0

4.82 4.82 4.82
4.39 4.65 4.91
4.18 4.53 4.88
4.46 4.89 5.32
4.70 5.20 5.69
5.00 5.55 6.11
5.34 5.96 6.58
5.73 6.41 7.09
6.15 6.89 7.64
6.53 7.33 8.14
6.81 7.67 8.52
7.35 8.27 9.20
7.85 8.85 9.86
8.26 9.32 10.38

4.82

5.16
5.23
5.75
6.19
6.66
7.19
7.77
8.38
8.95
9.37
10.13
10.86
11.44

Table 4: Ctotal for the simple combined algorithm as a function of the number of agents,
for various ratio wt =wf ratios.

662

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

where only time matters. Thus its entries are identical to the values obtained by the timeecient algorithm. As fuel consumption becomes more signi cant, it is no longer bene cial
to increase the number of agents and thus the optimal number of agents decreases. For
wt = wf = 0:5, Ctotal = 0:5  time + 0:5  fuel, the optimal number of agents obtained
is three, for a total cost of 3.49. The more critical fuel consumption becomes, the more
bene cial it is to use a smaller number of agents. The rightmost column corresponds to the
other extreme case, where wf = 1:0, i.e., when only fuel consumption matters. Note that
the entries of this column dier from their counterpart costs obtained by the fuel-ecient
algorithm. The dierence stems from the fact that, in the context of the simple combined
algorithm, picking p agents means that they will all be moving simultaneously, whereas in
case the fuel-ecient algorithm is employed only one agent (out of p) will be allowed to
move at all times. Note that the fuel-ecient algorithm is essentially a special case of the
improved combined algorithm with m = 1.
Table 5 provides total costs for the improved combined algorithm as a function of the
number of agents for various wt =wf ratios. The number of participating agents was p = 14
(i.e., up to 14 available agents could move simultaneously). Each row corresponds to a
dierent m, i.e., to the actual number of moving agents. (Clearly, 1  m  p = 14.) As
before, for each column the bold face number is the smallest total cost for the corresponding
wt =wf ratio. These minimal costs determine the optimal number of moving agents for a
given wt =wf ratio.
The top entry of the rightmost column is identical to the cost obtained by the fuelecient algorithm, for 14 agents. In this case wf = 1, and only one agent is allowed to
move at any point in time. The bottom entry of the leftmost column is identical to the cost
obtained by the time-ecient algorithm, for 14 agents. In this case wt = 1, and all of the
14 participating agents are moving at all times.
The more signi cant fuel consumption becomes, the less bene cial it is to move many
agents. Thus the optimal number of moving agents decreases. For example, for wt = wf =
0:5, the optimal number of moving agents obtained was three, for a total cost of 3.23. As
fuel consumption becomes more crucial, it would be bene cial to move a smaller number of
participating agents.
Comparing the results of the simple combined algorithm with those of the improved
combined algorithm reveals that for the same wt =wf ratio and for the same number of
moving agents (which is equal to the number of all participating agents in the simple
combined case) the improved combined algorithm usually performs better. This is because
it can pick the moving agents from a larger sample. Also, it appears that the optimal number
of moving agents is smaller for the improved combined algorithm. In this algorithm, the
moving agents are picked in a clever manner at each cycle and thus can be better utilized.
Additional experiments were conducted for other graph sizes, as well as for sparse and
dense Delaunay graphs. The results obtained in all cases were rather consistent. Future
work will attempt to predict in advance the best number of agents.

7. Conclusions and Future Work
We have addressed the problem of nding the shortest path to a goal node in unknown
graphs that represent physical environments. We have presented the two-level algorithm,
663

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

wt
wf

1.0
0.0

# agents
1
4.02
2
2.26
3
1.61
4
1.31
5
1.13
6
1.00
7
0.92
8
0.85
9
0.82
10
0.79
11
0.77
12
0.76
13
0.75
14
0.75

0.9
0.1

0.8
0.2

0.7
0.3

4.02
2.49
1.94
1.70
1.58
1.49
1.47

4.02
2.72
2.26
2.09
2.03

4.02
2.94
2.58
2.49

2.48

1.99 2.49
2.02 2.57

1.45 2.05 2.65
1.47
1.50
1.54
1.59
1.64
1.72

2.12
2.21
2.31
2.42
2.54
2.69

2.77
2.92
3.07
3.25
3.44
3.67

0.6
0.4

0.5
0.5

0.4
0.6

0.3
0.7

4.02 4.02 4.02 4.02
3.17 3.40 3.62 3.85
2.91 3.23 3.55 3.88
2.88 3.27 3.67 4.06
2.93 3.38 3.83 4.28
2.99 3.49 3.98 4.48
3.13 3.68 4.23 4.78
3.25 3.85 4.44 5.04
3.43 4.08 4.73 5.39
3.63 4.34 5.05 5.76
3.84 4.61 5.38 6.15
4.09 4.92 5.75 6.58
4.33 5.23 6.13 7.02
4.64 5.61 6.59 7.56

0.2
0.8

0.1
0.9

0.0
1.0

4.02 4.02 4.02
4.08
4.20
4.45
4.73
4.98
5.33
5.64
6.04
6.47
6.92
7.41
7.92
8.53

4.30 4.53
4.52 4.84
4.84 5.24
5.18 5.63
5.48 5.98
5.88 6.43
6.24 6.84
6.69 7.34
7.18 7.89
7.69 8.46
8.25 9.08
8.82 9.71
9.51 10.48

Table 5: Total costs for the improved combined algorithm as a function of the number of
moving agents (out of 14 participating agents), for various wt =wf values.

664

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

PHA*, for such environments for a single search agent, and the MAPHA* algorithm for
multiple-agents. We have experimented with several variations of Delaunay graphs, containing up to 8000 nodes. The enhanced single agent algorithm yielded signi cantly better
results than the ones obtained by the simpler variants. The results for the fuel-ecient
algorithm show that using more agents is bene cial only to some extent. This is because all
the agents are initially located at the same source node and they all consume fuel for each
move they make. For the same reason, the bene t of using the optimal number of agents
as opposed to only one agent is modest. The results for the time-ecient algorithm are
very encouraging, since the search time converges quickly to the optimum as the number of
search agents increases. We have also introduced a cost function that combines both time
consumption and fuel consumption, and have presented two algorithms for this paradigm.
The results show that for each combination there exists an optimal number of agents which
tends to increase as the weight of the time cost increases.
Future work can be pursued along the following directions:
We have assumed that upon reaching a node, the agent can learn the locations of
all of its neighbors. In many domains this model may not be valid, and the location
of a node is known only when the agent actually visits it. Such a model was also
suggested in (Shmoulian & Rimon, 1998). Further research should be done in order
to implement our algorithms, in the context of such a model.
We have used traveling agents to solve the shortest path problem. A similar mechanism might be used for solving other known graph problems, such as the minimum
spanning tree, the traveling salesman problem, or any other problem that requires
consideration as to which node should be visited next.
We have proposed two algorithms for combining time consumption and fuel consumption. Both algorithms assume that the number of agents is determined a priori. Future
work can try to theoretically determine the optimal number of agents given the constraints. Also, future work can be done to see whether changing this number on the y
would increase the eciency of these algorithm. Also, we have assumed that agents
consume fuel only when they move, and have measured only the total performance
time of a task. Thus idle agents do not consume any resources. However, we can
think of a model where idle agents do consume resources (e.g., time and energy).
We have assumed a centralized model, where all the agents share their knowledge at
all times. Future work can assume other communication paradigms. In particular,
we are interested in a model where there is no communication at all between the
agents. This model is known as the ant-robotics model (Wagner & Bruckstein, 2000
Yanovski, Wagner, & Bruckstein, 2001). In this model, information is spread to other
agents by pheromones, i.e., data that are written by an agent at a node. Other agents
can read these pheromones when reaching those nodes. We are currently working
towards applying our MAPHA* algorithm to such a model. We believe that if we
increase the size of the data that are allowed to be written at each node, then each
agent will be able to write its complete knowledge at a node of the environment. The
challenge of applying A* in such a model lies in the fact that since A* maintains a
global open list, data from opposite sides of the graph can inuence the behavior of
665

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

the algorithm. Thus we need the knowledge sharing of such a system to be as large
as possible. For this purpose, we believe that a new type of communication agents
should be introduced. Agents of this type will not try to increase the search frontier
but rather move around the environment and spread the most recent data available.

Acknowledgments
A preliminary version of this paper appeared in Proceedings of the First International Joint
Conference on Autonomous Agents and Multi-Agent Systems, 2002 (Felner et al., 2002).
The work was carried out while the rst author was at Bar-Ilan University. This material is
based upon work supported in part by NSF under grant #0222914 and by ISF under grant
#8008.

Appendix A. Additional Experimental Results
As mentioned in Subsection 4.3, each node in a regular Delaunay graph is connected to
all its neighbors. This property may not always apply to a real road map. For example,
nearby geographic locations may not always be connected by a road segment, due to the
the existence of obstacles like a mountain or a river. In addition, distant locations are often
connected by highways. To capture these additional characteristics, we have also considered so-called sparse and dense Delaunay graphs. Instances of these variants can be easily
obtained from regular Delaunay graphs by random deletion and addition of edges, respectively. Speci cally, we have generated sparse Delaunay graph instances by deleting roughly
60% of the edges at random. Likewise, dense instances were generated by introducing 400
edges at random. (A new edge is created by selecting at random a pair of nodes.)
We have run all of the algorithms presented in the main body of the paper also on the
above Delaunay graph variants. The results obtained are presented here.
As can be expected, the more sparse the graph, the more often the agent runs into deadends. Indeed, all the algorithms required additional travel eort to nd the optimal path
after edges were removed. However, the ratio between the travel cost of any two algorithms
seems to remain the same (for the various Delaunay graph types), and I-A*DFS exhibits
superior performance for all graph instances. See Figures 10(a), (b). This behavior proved
consistent in all of our experiments, for both a single agent and a multi-agent environment.
Also, Figures 11(a), (b) exhibit similar behavior of search cost of WinA* versus window
size for sparse Delaunay graphs and dense Delaunay graphs, respectively, to that observed
for regular Delaunay graphs (see Figure 6).
Figures 12(a), (b) present the costs of the fuel-ecient algorithm as a function of the
number agents for various sizes of sparse and dense Delaunay graphs, respectively. The
overall fuel consumption recorded for the sparse Delaunay graphs is larger than the fuel
consumption recorded for their counterpart regular graphs (see Figure 8) by a factor of
about 1.5. For graphs simulating highways (i.e., the dense graphs) the fuel consumption
decreases relative to both sparse and regular Delaunay graphs.
Note that the optimal number of agents navigating in a sparse graph also increases, since
agents need to backtrack more often in this case. Thus having more agents will assist the
666

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

100

45
Tree path
Shrtest known path
Aerial path
P-DFS
D-DFS
A*DFS
I-A*DFS

90
80

35
30

60

Search cost

Search cost

70

Tree path
Shrtest known path
Aerial path
P-DFS
D-DFS
A*DFS
I-A*DFS

40

50
40

25
20
15

30

10

20

5

10
0
500

1000

1500
2000
2500
3000
Number of nodes in the graph

3500

0
500

4000

1000

1500
2000
2500
3000
Number of nodes in the graph

3500

4000

(a)
(b)
Figure 10: Search cost versus the number of nodes of: (a) Sparse Delaunay graphs, and (b)
dense Delaunay graphs for various low-level algorithms.

7

5
500 nodes
1000 nodes
2000 nodes

6.5

500 nodes
1000 nodes
2000 nodes

4.5

6
4

5

Search cost

Search cost

5.5

4.5
4
3.5

3.5

3

2.5

3
2
2.5
2

1.5
0

10

20

30

40
50
Window size

60

70

80

0

10

20

30

40
50
Window size

60

(a)
(b)
Figure 11: Search cost of WinA* versus window size for various sizes of: (a) Sparse Delaunay
graphs, and (b) dense Delaunay graphs.

667

70

80

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

7.5

3
500 nodes
1000 nodes
2000 nodes
4000 nodes

7
6.5

2.6
2.4
Fuel consumption

6
Fuel consumption

500 nodes
1000 nodes
2000 nodes
4000 nodes

2.8

5.5
5
4.5

2.2
2
1.8

4

1.6

3.5

1.4

3

1.2

2.5

1
1

2

3

4

5
6
Number of agents

7

8

9

1

2

3

4

5
6
Number of agents

7

8

9

(a)
(b)
Figure 12: Fuel consumption as a function of the number of agents for various sizes of: (a)
Sparse Delaunay graphs, and (b) dense Delaunay graphs.
search. On the other hand, adding random edges to the graphs causes the opposite eect,
i.e., less fuel is consumed and the optimal number of agents is reduced. This is explained
by the fact that new edges add more connections between nodes, i.e., many "shortcuts" are
created and the search can be carried out faster and with a smaller number of agents.
11

4.5
500 nodes
1000 nodes
2000 nodes
4000 nodes
8000 nodes

10
9

3.5

8
7

3
Search time

Search time

500 nodes
1000 nodes
2000 nodes
4000 nodes
8000 nodes

4

6
5

2.5
2

4
3

1.5

2
1

1
0

0.5
1

2

3

4

5
6
Number of agents

7

8

9

1

2

3

4

5
6
Number of agents

7

(a)
(b)
Figure 13: Time consumption as a function of the number of agents for various sizes of: (a)
Sparse Delaunay graphs, and (b) dense Delaunay graphs.
Figures 13(a), (b) present the costs of the time-ecient algorithm as a function of the
number agents for various sizes of sparse and dense Delaunay graphs, respectively. The
results con rm the same tendency that was observed for regular Delaunay graphs (see
668

8

9

fiPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment

Figure 9), namely that as the number of agents grows, the overall cost converges to the
length of the optimal path.

References
Argamon-Engelson, S., Kraus, S., & Sina, S. (1998). Utility-based on-line exploration for
repeated navigation in an embedded graph. Articial Intelligence, 101(1-2), 967{984.
Argamon-Engelson, S., Kraus, S., & Sina, S. (1999). Interleaved vs. a priori exploration
for repeated navigation in a partially-known graph. International Journal of Pattern
Recognition and Articial Intelligence, 13(7), 963{968.
Barber, C. B., Dobkin, D. P., & Huhdanpaa, H. (1993). The Quickhull algorithm for convex
hull. Tech. rep., Geometry Center Technical Report GCG53, University of Minnesota.
Bellman, R. (1958). On a routing problem. Quarterly of Applied Mathematics, 16 (1), 87{90.
Bender, M. A., Fernandez, A., Ron, D., Sahai, A., & Vadhan, S. P. (1998). The power
of a pebble: Exploring and mapping directed graphs. In Proceedings of the Thirtieth
Annual ACM Symposium on the Theory of Computing, pp. 269{278, Dallas, Texas.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction to Algorithms. MIT Press, Cambridge, Massachusetts. 2nd edition.
Cucka, P., Netanyahu, N. S., & Rosenfeld, A. (1996). Learning in navigation: Goal nding
in graphs. International Journal of Pattern Recognition and Articial Intelligence,
10(5), 429{446.
Dechter, R., & Pearl, J. (1985). Generalized best- rst search strategies and the optimality
of A*. Journal of the Association for Computing Machinery, 32(3), 505{536.
Dijkstra, E. W. (1959). A note on two problems in connexion with graphs. Numerische
Mathematik, 1, 269{271.
Felner, A., Kraus, S., & Korf, R. E. (2003). KBFS: K-best rst search. Annals of Mathematics and Articial Intelligence, in press.
Felner, A., Stern, R., & Kraus, S. (2002). PHA*: Performing A* in unknown physical environments. In Proceedings of the First International Joint Conference on Autonomous
Agents and Multi-Agent Systems, pp. 240{247, Bologna, Italy.
Ghosh, B. (1951). Random distances within a rectangle and between two rectangles. Bulletin
of the Culcutta Mathematical Society, 43, 17{24.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics,
SCC-4(2), 100{107.
Kaelbling, L. P., & Moore, A. W. (1996). Reinforcement learning: A survey. Journal of
Articial Intelligence Research, 4, 237{285.
Karp, R., & Pearl, J. (1983). Searching for an optimal path in a tree with random costs.
Articial Intelligence, 21(1-2), 99{116.
669

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

Kitamura, Y., Teranishi, K., & Tatsumi, S. (1996). Organizational strategies for multiagent real-time search. In Proceedings of the Second International Conference on
Multi-Agent Systems, 409{416.
Knight, K. (1993). Are many reactive agents better than a few deliberative ones?. In
Proceedings of the Thirteenth International Joint Conference on Articial Intelligence,
pp. 432{437, Chamb$ery, France.
Koenig, S., & Likhachev, M. (2002a). D* lite. In Proceedings of the Eighteenth National
Conference on Articial Intelligence (AAAI), pp. 476{483, Edmonton, Canada.
Koenig, S., & Likhachev, M. (2002b). Incremental A*. In Advances in Neural Information
Processing Systems 14 (NIPS). MIT Press, Cambridge, MA.
Korf, R. E. (1985). Depth- rst iterative-deepening: An optimal admissible tree search.
Articial Intelligence, 27(1), 97{109.
Korf, R. E. (1990). Real-time heuristic search. Articial Intelligence, 42(3), 189{211.
Korf, R. E. (1993). Linear-space best- rst search. Articial Intelligence, 62(1), 41{78.
Korf, R. E. (1997). Finding optimal solutions to Rubik's Cube using pattern databases.
In Proceedings of the Fourteenth National Conference on Articial Intelligence, pp.
700{705, Providence, Rhode Island.
Korf, R. E. (1999). Sliding-tile puzzles and Rubik's Cube in AI research. IEEE Intelligent
Systems, 14, 8{12.
Okabe, A., Boots, B., & Sugihara, K. (1992). Spatial Tessellations, Concepts, and Applications of Voronoi Diagrams. Wiley, Chichester, UK.
Pearl, J., & Kim, J. H. (1982). Studies in semi-admissible heursitics. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 4, 392{400.
Shmoulian, L., & Rimon, E. (1998). Roadmap-A*: An algorithm for minimizing travel eort
in sensor based mobile robot navigation. In Proceedings of the IEEE International
Conference on Robotics and Automation, pp. 356{362, Leuven, Belgium.
Stentz, A. (1994). Optimal and ecient path planning for partially-known environments.
In Proceedings of the IEEE International Conference on Robotics and Automation,
pp. 3310{3317, San Diego, CA.
Stern, R. (2001). Optimal Path Search in Unknown Physical Enviroments. M.Sc.
Thesis, Department of Computer Science, Bar-Ilan University, Israel available on
http://www.cs.biu.ac.il/felner.
Taylor, L., & Korf, R. (1993). Pruning duplicate nodes in depth- rst search. In Proceedings
of the Eleventh National Conference on Articial Intelligence, pp. 756{761, Washington, D.C.
Wagner, A., & Bruckstein, A. M. (2000). ANTS: Agents, networks, trees, and subgraphs.
Future Generation Computer Systems Journal, 16(8), 915{926.
Yanovski, V., Wagner, I. A., & Bruckstein, A. M. (2001). Vertex-ant-walk: A robust method
for ecient exploration of faulty graphs. Annals of Mathematics and Articial Intelligence, 31(1-4), 99{112.
670

fiJournal of Artificial Intelligence Research 21 (2004) 551-577

Submitted 09/02; published 04/04

On Polynomial Sized MDP Succinct Policies
Paolo Liberatore

paolo@liberatore.org

Dipartimento di Informatica e Sistemistica
Universita di Roma La Sapienza
Via Salaria 113, 00198, Roma, Italy

Abstract
Policies of Markov Decision Processes (MDPs) determine the next action to execute
from the current state and, possibly, the history (the past states). When the number of
states is large, succinct representations are often used to compactly represent both the
MDPs and the policies in a reduced amount of space. In this paper, some problems related
to the size of succinctly represented policies are analyzed. Namely, it is shown that some
MDPs have policies that can only be represented in space super-polynomial in the size of
the MDP, unless the polynomial hierarchy collapses. This fact motivates the study of the
problem of deciding whether a given MDP has a policy of a given size and reward. Since
some algorithms for MDPs work by finding a succinct representation of the value function,
the problem of deciding the existence of a succinct representation of a value function of a
given size and reward is also considered.

1. Introduction
Markov Decision Processes (MDPs) (Bellman, 1957) have been used in AI for planning
when the effects of actions are only probabilistically known (Puterman, 1994). The partially
observable extension (POMDP) formalizes scenarios in which the observations do not give
a complete description of the state.
The best plan in such domains may not be a simple sequence of actions. Indeed, the best
action to take may depend on the current state, which is known (partially, for POMDPs)
only when the previous actions have been executed. Such conditional plans are named
policies. Finding policies for MDPs is a problem that has been deeply investigated;
algorithms have been developed, e.g., value iteration, policy iteration, and methods based
on linear programming (Littman, Dean, & Kaebling, 1995). For POMDPs, variants of the
value iteration algorithm have been developed (Cassandra, Littman, & Zhang, 1997; Zhang
& Zhang, 2001).
Formally, an MDP is composed of a set of states, a set of actions, the specification of the
(probabilistic) effects of actions, and a measure of how good a state is considered (reward
function). Initially, MDPs were defined in an explicit form: the states are the elements of
a given set {s1 , . . . , sn }; what is true or false in each state si is not specified. The effects of
the actions and the reward function are represented in an explicit form, e.g., if there are n
states, a vector of n elements represents the reward function (each element of the vector is
the reward of a state.)
While such explicit representation is simple, it is not practical to use in many cases.
Indeed, many real-world scenarios can be described by a set of variables (state variables);
for example, a set of Boolean variables can specify what is true or false in the current

c
2004
AI Access Foundation. All rights reserved.

fiLiberatore

state. An explicit representation of such a domain is always of size exponential in the
number of state variables, as it contains an enumeration of all states. This is why succinct
representations are used instead: the states are assumed to be the possible evaluations
of a set of Boolean variables; the effects of the actions and the rewards of the states are
represented in some succinct form. The succinct representation considered in this paper uses
circuits (Mundhenk, Goldsmith, Lusena, & Allender, 2000), but others exist: decision trees,
stochastic STRIPS operators, two-stage Bayes networks, variants of BDDs (Boutilier, Dean,
& Hanks, 1999; Littman, 1997; Dean & Kanazawa, 1989; Dearden & Boutilier, 1997; Hansen
& Feng, 2000). Littman (1997) has shown that these representations can be polynomially
reduced to each other: the choice of circuits is motivated by their ease of use.
Typically, scenarios that can be expressed by MDPs can be informally represented in
an amount of space that is on the same scale as the number of variables. For example, the
domain in which there are ten coins and the ten actions of tossing them can be represented
very succinctly: it is only necessary to specify that action ai tosses coin i (e.g., the result
of ai is a state in which the side the coin is on is head or tail with probability 0.5 and all
other state variables are unchanged.) On the other hand, the explicit representation of this
domain contains the set of all 210 states and the representation of the transition function,
which in turns requires the specification of the probability of each action a to change a state
s into a state s0 for each pair of the 210 states and each of the ten actions. As a result, the
transition function contains a set of 210 210 10 = 10  220 probabilities.
Succinct representations, on the other hand, follow the intuition that a formal representation should not be too much larger than an informal representation of the same domain.
While explicit representations are always exponential in the number of state variables, an
informal representation may be very short: if this is the case, it is often also the case that
such an informal description can be converted into a formal succinct one that is not too
large.
Explicit and succinct representations lead to very different computational properties: for
example, some problems (e.g., checking the existence of a policy of a given expected reward)
are PSPACE-hard in the succinct representations (Mundhenk et al., 2000) but polynomial
in the explicit one (Papadimitriou & Tsitsiklis, 1987). This apparent simplification is only
due to the fact that complexity is measured relative to the size of the input of the problem,
and the explicit representation introduces an artificial blow-up of this size.
In this paper, MDPs are assumed to be in a succinct representation. In particular,
states are possible evaluations of a set of Boolean variables (state variables); the effects
of the actions and the reward function are described using circuits. Since the number of
states is exponential in the number of state variables, and a policy indicates the action
to execute in each state, an explicit representation of policies is always exponential in the
number of state variables. On the other hand, a succinct representation of an MDP may
take only polynomial space in the number of state variables. If this is the case, the policy
is exponentially larger than the MDP. However, as MDPs can be succinctly represented in
a small amount of space, policies can be expressed in some succinct form as well (Koller &
Parr, 1999). In this paper, policies are represented by circuits that take as input a state
and (possibly) the history (the past states), and output the next action to execute.
The first result proved in this paper (Section 4) is that optimal policies, even in a succinct
representation, may require an amount of space that is exponential in the size of the MDP.
552

fiOn Polynomial Sized MDP Succinct Policies

This result is new for MDPs in succinct form; in particular, the hardness of finding an
optimal policy does not imply anything about the policy size. Indeed, even in those cases in
which finding an optimal policy is undecidable (Madani, Hanks, & Condon, 1999), the policy
itself may be very short. Many hard problems, even some undecidable ones, are known to
have very short solutions: for example, the solution of the halting problem is a single bit,
but finding it is undecidable. Therefore, the impossibility of representing the solutions of a
problem in polynomial space does not follow from the complexity of the problem.
Given that optimal policies cannot always be represented in space polynomial in the
size of the MDP, a reasonable request is the best possible policy that can be represented
within a given space bound (Section 5). We show that bounding the size of policies simplifies the policy existence problem. Bounding the size of the succinct representation of
the value function (the function giving the expected reward of the states) further simplifies
the problem (Section 6). This second bound is intended to shed light on the complexity of
algorithms that work by estimating the expected reward of each state, such as the value iteration algorithm (Littman et al., 1995; Cassandra et al., 1997; Zhang & Zhang, 2001). We
complete the analysis (Section 7) by considering the problem of finding policies of a given
size and reward, when the size can be exponentially larger than the MDP. Implications and
discussions of the results of this paper are given in the last section (Section 8).

2. Markov Decision Processes
Markov Decision Processes formalize problems of planning in probabilistic domains. Their
components are: a set of states, a set of probabilistic actions, and a function that evaluates
states according to a notion of goodness (reward function).
Formally, an MDP is a 5-tuple M = hS, s0 , A, t, ri, where: S is a set of states, s0 is a
distinguished state (the initial state), A is a set of actions, t is a function representing the
effects of the actions, and r is a function giving the reward of the states.
The effects of the actions are not known for sure, but only according to a probability
distribution. Therefore, the effects of actions cannot be represented using a function that
maps a state into another state, given a specific action. The function t is instead a function
from actions and pairs of states to numbers in the interval [0, 1]. Such a function represents
the probability of transitions: t(s1 , s2 , a) = p means that the result of executing the action
a in the state s1 is the state s2 with probability p. The reward function is a measure of how
much a state matches our goals. Formally, it is a function from states to integer numbers.
MDPs are assumed to be represented in a succinct form. Namely, the states are assumed
to be represented by tuples of Boolean variables (state variables), i.e., the set of states is
the set of propositional interpretations over this set of variables. The functions t and r
are represented by Boolean circuits. While other representations are more commonly used
in practice (e.g., probabilistic STRIPS operators, two-stage Bayes network, etc.) Boolean
circuits have the advantage of being able to encode exactly all polynomial-time computable
functions. This fact makes them very suitable for a computational analysis: indeed, if a
transition or reward function is polynomial, then it can be encoded by a polynomial-size
circuit without having to show the details of the encoding (Mundhenk et al., 2000; Boutilier
et al., 1999). In order to encode some of the polynomial-time functions, on the other hand,

553

fiLiberatore

the other representations require the introduction of new variables and dummy time points
(Littman, 1997).
Definition 1 A succinct MDP is a 5-tuple M = hV, s0 , A, t, ri, where V is a set of Boolean
variables, s0 is a propositional interpretation over V, A is a set of actions, t is a circuit
whose input is a pair of interpretations over V and an element of A, and r is a circuit
whose input is an interpretation over V.
In a succinct MDP, the set of states is factored, i.e., it is the Cartesian product of the
possible values of the variables. This is why succinct MDPs have also been called factored
MDPs. The term succinct, however, is more appropriate, as t and r are not expressed
as a product of something. It is also important to note that the set of actions A is explicitly
represented: this affects the complexity of checking the consistency of a value function, i.e.,
Theorem 8.
A succinct MDP M = hV, s0 , A, t, ri represents the (explicit) MDP M0 = hS, s0 , A, t0 , r0 i,
where S is the set of propositional interpretations over variables V; the transition function
t0 is the function represented by the circuit t; the reward function r0 is the function represented by the circuit r. In other words, the value of t0 (s, s0 , a) is the output of the circuit t
when its inputs are s, s0 , and a Boolean representation of a. The same applies to r and r0 .
Planning in deterministic domains consists of finding a sequence of actions to reach a
goal state. Nondeterminism introduces two complications: first, the extent to which the
goal is reached can only be probabilistically determined; second, the state at some time
point cannot be uniquely determined from the initial state and the actions executed so far.
Planning in nondeterministic domains consists of finding the actions that lead to the
best possible states (according to the reward function). Since the effects of actions are not
known for sure, only an expected value of the reward can be determined. For example, if
the result of applying a in the state s0 is s1 with probability 1/3 and s2 with probability
2/3, then the expected reward of executing a is given by r(s0 ) + 1/3  r(s1 ) + 2/3  r(s2 ),
since r(s0 ), r(s1 ), and r(s2 ) are the rewards of s0 , s1 , and s2 , respectively. Formally, the
expected undiscounted reward is considered. This is the sum of the reward of each state
weighted by the probability of reaching it.
The second effect of nondeterminism is that the best action to execute depends on the
current state, which is not unambiguously determined from the initial state and the actions
executed so far, as the effects of the actions are only probabilistically known. For example,
executing a may lead to state s1 or s2 . After a is executed, the actual result is known. At
this point, it may be that the best action to execute in s1 is a0 , and is a00 in s2 : the optimal
choice depends on the current state, which cannot be unambiguously determined from the
initial state and the previous actions. In the simplest case, a policy is a function that gives
the best action to execute in each state. Such policies are called stationary. A policy may
also depend on the past states; such policies are called history dependent.
The reward associated with a policy is the expected average reward obtained by executing, in each state, the associated action. The horizon is assumed to be finite, i.e., only
what happens up to a given number of steps T is considered. The complexity of the problem changes according to whether the horizon T is in unary or binary notation (Mundhenk
et al., 2000). Informally, the assumption that the horizon is in unary notation means that
the number of steps to consider is a polynomial in the size of the instance of the problem.
554

fiOn Polynomial Sized MDP Succinct Policies

In this paper, T is assumed in unary notation. This assumption has been called short
horizon or polynomial horizon in other papers.
The size of the explicit representation of every policy for a succinct MDP is exponential in the number of state variables. However, some policies take less space in succinct
representations. In this paper, the succinct representation employing circuits is considered:
their input is the current state and (possibly) the history; their output is the next action
to execute. An example of a policy with a small succinct representation is that of always
executing the same action; such a policy is exponential in the explicit representation it is
necessary to specify an action for each state and the number of states is exponential in the
number of state variables.
The first question considered in this paper is whether it is always possible to represent
the optimal policy of a succinct MDP with a circuit of size polynomial in the size of the
MDP. Namely, a succinct policy is defined as a circuit that outputs, given the current state,
an action.
Definition 2 A succinct stationary policy P is a circuit that takes a state as input and
outputs the action to execute in the state.
A succinct policy is a circuit that represents a function from states to actions. Since (nonsuccinct) policies are functions from states to actions, succinct and non-succinct policies are
in correspondence. The expected reward of a succinct policy and its optimality can therefore
be defined in terms of the analogous concepts for non-succinct policies.
Succinct history-dependent policies are defined in a similar way: they are circuits from
sequences of states to actions (such a representation is possible because of the finite horizon.)
The expected reward and the optimality of a succinct history-dependent policy are defined
from the corresponding concepts for non-succinct policies.
The first result of this paper is that, if all MDPs have optimal succinct policies of polynomial size, then the polynomial hierarchy coincides with its complexity class p2 (considered
unlikely). The proof is based on compilability classes and reduction, which are summarized
in the next section.

3. Complexity, Compilability, and Circuits
The reader is assumed to be familiar with the complexity classes P, NP, and the other classes
of the polynomial hierarchy (Stockmeyer, 1976; Garey & Johnson, 1979). Some counting
classes are also used in this paper: PP is the class of the problems that can be polynomially
reduced to the problem of checking whether a formula is satisfied by at least half of the
possible truth assignments over its set of variables. An alternative definition is that a
problem is in PP if and only if it can be polynomially reduced to that of checking whether
P
V (M )  k, where k is an integer, V is a function from propositional interpretations to
integers that can be calculated in polynomial time, and the sum ranges over all possible
propositional interpretations (Johnson, 1990). The class NPPP is defined in terms of oracles:
it is the class of problems that can be solved in polynomial time by a non-deterministic
Turing machine that has access to a PP-oracle, which is a device that can solve a problem
in PP in one time unit.

555

fiLiberatore

Without loss of generality, instances of problems are assumed to be strings. The length
of a string x   is denoted by ||x||. The cardinality of a set S is instead denoted by |S|.
A function g is called poly-time if there exists a polynomial p and an algorithm A such
that, for all x, the time taken by A to compute g(x) is less than or equal to p(||x||). A
function f is called poly-size if there exists a polynomial p such that, for all strings x, it
holds ||f (x)||  p(||x||); whenever the argument of such a function f is a number, is is
assumed to be in unary notation. These definitions extend to functions with more than one
argument as usual.
Circuits are defined in the standard way. Whenever C is a circuit and s is a possible
assignment of its input gates, its output is denoted by C(s) its output. The formal definition
of circuits is not important in this paper, as we take advantage of a well-known result in
circuit complexity that relates poly-time functions with poly-size circuits. Informally, given
a circuit and the value of its inputs, we can determine its output in polynomial time. A
similar result holds in the other way around, that is, poly-time functions can be represented
by means of circuits (Boppana & Sipser, 1990).
Formally, however, a poly-time function from strings to strings has a string of arbitrary
length as argument, and a string of arbitrary length (in general) as output. Even considering
only functions that have a binary output (i.e., a single bit), the input may be arbitrarily
long. On the other hand, each circuit has a specified number of input gates. This is why
the correspondence between poly-time functions and poly-size circuits is not one-to-one.
However, the following correspondence holds: for any poly-time function from strings to
strings, there exists a uniform family of poly-size circuits {C0 , C1 , C2 , . . .}, where Ci is a
circuit with i input gates that calculates the result of f on all strings of length i; uniform
means that that there exists a function that calculates Ci from i and runs in time that is
bounded by a polynomial in the value of i.
As a result, the class P can be also defined as the set of problems that can be solved by
a uniform family of circuits. By replacing the assumption of the family to be uniform with
that of Ci being of size polynomial in the value of i, the definition gives the class P/poly.
In this paper, the problem of whether all succinct MDPs have an optimal succinct policy
of polynomial size is considered. Note that, for any given MDP, its succinct policies are
circuits that take as input a state (or, a sequence of at most T states). As a result, a policy
is a single circuit, not a family.
The question is given a (negative) answer using two different proofs, based on different
techniques: the first one is based on compilability classes (Cadoli, Donini, Liberatore, &
Schaerf, 2002), while the second one employs standard complexity classes. The compilability
classes have been introduced to characterize the complexity of intractable problems when
some preprocessing of part of the data is allowed. The problems characterized in this way
are those having instances that can be divided into two parts: one part is fixed (known
in advance) and one part is varying (known when the solution is needed.) The problem
of determining the action to execute in a specific state has this form: the MDP (with
the horizon) is the part known in advance, as it describes the domain; on the contrary,
the state is only determined once the previous actions have been executed. Compilability
classes and reductions formalize the complexity of such problems when the first part can
be preprocessed.

556

fiOn Polynomial Sized MDP Succinct Policies

As is common in complexity theory, only decision problems are considered, i.e., problems
whose solution is a single bit. Such problems are usually identified with languages (sets of
strings): a language L   represents the decision problem whose output is 1 for all x  L
and 0 for all x 6 L.
The problems whose instances are composed of two parts can be formalized as languages
of pairs (of strings): a language of pairs S is a subset of    . In order to characterize
these problems, the non-uniform compilability classes have been introduced (Cadoli et al.,
2002). These classes are denoted by k;C and read nu-comp-C, where C is an arbitrary
uniform complexity class, usually based on time bounds, such as P, NP, etc.
Definition 3 (k;C classes) k;C is composed of all languages of pairs S     such
that there exists a poly-size function f from pairs to strings to strings and a language of
pairs S 0  C such that, for all hx, yi     , it holds:
hx, yi  S iff hf (x, ||y||), yi  S 0
A problem is in k;C if it reduces to one in C after a suitable polynomial-size preprocessing (compiling) step. Any problem S     that is in C is also in k;C (i.e., f (x, n) = x
and S 0 = S). Preprocessing is useful if a problem in C is in k;C0 and C0  C: in this case,
preprocessing decreases the complexity of the problem. Such a reduction of complexity is
possible for some problems (Cadoli et al., 2002).
The tool used for proving that such a decrease of complexity is not possible is the
concept of hardness with respect to compilability classes, which is in turn based on a
definition of reductions. Since these general concepts are not really needed in this paper,
only the condition based on monotonic polynomial reductions is presented. This condition
is sufficient to prove that a problem in k;NP is not in k;P unless NP  P/poly, which is
currently considered unlikely.
Let us assume that hr, hi is a polynomial reduction from 3sat to a problem of pairs S,
that is, r and h are poly-time functions and  is satisfiable if and only if hr(), h()i  S.
This pair hr, hi is a monotonic polynomial reduction if, for any pair of sets of clauses 1
and 2 over the same literals, with 1  2 , it holds:
hr(1 ), h(1 )i  S iff hr(2 ), h(1 )i  S
Note that the second instance combines a part from 2 and a part from 1 : this is
intentional. Roughly speaking, such a reduction implies that the hardness of the problem
S comes from the second part of the instances only, as the first part r(1 ) of an instance
that is the result of a reduction can be replaced by another one r(2 ) without changing
its membership to S. If the complexity of a problem is due to a part of the instance only,
preprocessing the other part does not reduce the complexity of the problem. The formal
proof of the fact that the existence of such a reduction implies that S is not in k;P (unless
NP  P/poly) can be found elsewhere (Liberatore, 2001).

4. Super-polynomially Sized Policies
Suppose that it is always possible to find an optimal succinct policy P of polynomial size.
Since succinct policies are circuits by definition, deciding the action to execute in a state is
557

fiLiberatore

a polynomial-time problem: given s and P , just compute P (s), the output of the circuit P
when s is given as input. The whole two-step process of finding a policy and then using it
to find the next action in a specific state can be seen as an algorithm for finding the next
action to execute in the state. The first step (finding a policy) is likely to be very hard, but
the second one is polynomial-time computable. This means that the problem of deciding
the next action is compilable into k;P. What is done in the present paper is to prove
that this problem is instead not in k;P. This implies that succinct policies cannot always
be represented in polynomial space. To this aim, the formal definition of the problem of
deciding the next action to execute is given.
Definition 4 The next-action problem is the problem of deciding, given an MDP, a horizon
in unary notation, a state, and an action, whether the action is the one to execute in the
state according to some optimal policy.
The problem is proved NP-hard as an intermediate step. Actually, this result is easy to
derive from known theorems: what is interesting is the reduction used in the proof. Namely,
given a set of clauses , each clause being composed of three literals over a set of variables
X = {x1 , . . . , xn }, an instance of the next-action problem in polynomial time can be built
in polynomial time. This reduction is denoted by f ; formally, this is a function from sets
of clauses to quadruples hM, T, s, ai, where the first element is a succinct MDP, the second
one is a number in unary (the horizon), the third one is a state, and the fourth one is an
action. Let L be the set of literals over X, and let E = L  {sat, unsat}. The MDP M is
defined as:
M = hV, , A, t, ri
The components of M are defined as follows.
States: The set of states is in correspondence with the set of sequences of at most (2n)3 +
n + 1 elements of E; this is obtained by using the following set of variables:
V = {qi | 1  i  log((2n)3 + n + 1)}  {vij | 1  i  log(|E|), 1  j  (2n)3 + n + 1}.
The idea is that the variables qi represent the length of the sequence in binary, while
j
the variables v1j , . . . , vlog(|E|)
represent the j-th element of the sequence;
Initial state: The initial state is the interpretation representing the empty sequence ;
Actions: A contains three actions A, S, and U , and one action ai for each xi ;
Transition function: The action A does not change the current state if either sat or unsat
belong to the sequence that is represented by the current state; otherwise, its effect is
to randomly select (with equal probability) a literal of L and to add it to the sequence
representing the current state; the effect of S and U is to add sat and unsat to the
sequence, respectively (these are deterministic actions); the actions ai change the state
only if either sat or unsat, but not both, belong to the sequence; if this is the case, ai
adds either xi or xi to the sequence, with the same probability;

558

fiOn Polynomial Sized MDP Succinct Policies

Reward function: This is the most involved part of the MDP. Given a sequence of 3m
literals of L, the following 3cnf formula is considered:
C(l11 , l21 , l31 , . . . , l1m , l2m , l3m ) =
{l11  l21  l31 , . . . , l1m  l2m  l3m }.
Given that the number of possible distinct clauses over L is less than (2n)3 , any set
of clauses can be represented as a sequence of 3m literals, where m = (2n)3 . The
function C encodes all sets of clauses over L as sequences of literals.
The only sequences having reward different than zero are those composed of a sequence
s of 3m literals of E, followed by either sat or unsat, followed by a sequence s0 =
l1 , . . . , ln , where each li is either xi or xi . Namely, the sequence (s, unsat, s0 ) has
reward 2; the sequence (s, sat, s0 ) has reward 1 if the set of clauses C(s) is not satisfied
by the only model of s0 , and 2n+1 otherwise;
Note that most of the states have reward 0. While the expected reward is calculated
over all reached states, r is defined in such a way that, if a state has nonzero reward, then
all previous and succeeding states have reward zero. The reward function r is defined this
way for the sake of making the proof simpler; however, the expected reward is calculated
over all states, including intermediate ones.
This MDP has a single optimal policy: execute A for 3m times, then execute either U
or S, and then execute a1 , . . . , an . The choice between U and S that gives the greatest
expected reward depends on the result of the execution of A. Namely, each possible result
of the execution of the first 3m actions corresponds to a set of clauses. The next action of
the optimal policy is U if the set is unsatisfiable and S if it is satisfiable.
This is the definition of the MDP M. The instance of the next-action problem is
composed of an MDP, a horizon in unary, a state, and an action, and the problem is to
check whether the action is optimal in the state. The horizon we consider is T = (2n)3 +n+1,
the state is the one s corresponding to the sequence of literals such that C(s) = , and the
action is S. It is not possible to prove that the function f defined by f () = hM, T, s, Si
is a reduction from satisfiability to the next-action problem.
Theorem 1 If f () = hM, T, s, Si, then M has an unique (stationary or history-dependent)
optimal policy w.r.t. the horizon T , and  is satisfiable if and only if S is the action to execute from s in the optimal policy of M with horizon T .
Proof. All MDPs defined as above have policies with positive reward: the policy of executing
A3m U a1 , . . . , an has expected reward equal to 2, since all its leaves have reward 2 and all
internal nodes have reward 0. Such a sequence of actions can be executed by a stationary
policy because the history can be inferred from the current state.
The sequences of actions that end up in a state with a positive reward are very similar
to each other. Indeed, they all begin with 3m times the action A. Then, either U or S are
executed, followed by the sequence a1 , . . . , an . The only difference between these sequences
is this choice between U or S.
The optimal policies therefore execute A in the first 3m time points, regardless of the
generated state. They then execute either U or S, and then execute a1 , . . . , an . The choice
559

fiLiberatore

between U and S can be made differently in different states: a policy can execute U or S
depending on the state that results from the 3m executions of A.
sequence 1:

A
. . A} U a1 . . . an
| .{z

sequence 2:

A
. . A} S a1 . . . an
| .{z

3m
3m

Figure 1: Sequences leading to a state with reward > 0. All their fragments and extensions
give reward 0.
Let us now consider the state after the 3m executions of A. Since each execution of
A generates a random literal, at this point the state is a sequence of 3m literals. Such a
sequence represents the set of clauses that is later used by the reward function. Intuitively,
at this point the optimal policy should execute U if the set of clauses is unsatisfiable, and
S if it is satisfiable.
Let s be a state that results from the execution of A for 3m times, and let C(s) be the
corresponding formula. The expected reward of s in the policy that executes the sequence
U, a1 , . . . , an is 2 because this sequence leads to states that have all reward 2. On the other
hand, the reward of s when the policy executes A, a1 , . . . , an depends on the satisfiability
of the formula represented by the state. Namely, this sequence leads to a state for each
possible truth interpretation over X; the reward of such a state is 1 if C(s) is not satisfied
by the model, and 2n+1 otherwise. This means that the reward of s in this policy is 1 if the
formula is unsatisfiable, and at least (2n  1)/2n + 2n+1 /2n = (2n  1)/2n + 2 if the formula
has at least one model.
The optimal choice in s is therefore U if the formula C(s) is unsatisfiable (reward 2) and
S otherwise (reward greater than or equal to (2n  1)/2n + 2n+1 /2n > 2). Since the history
can be inferred from the state, the optimal choice does not depend on whether stationary
or history-dependent policies are considered.
Incidentally, this theorem implies that choosing the next action optimally is NP-hard.
What is important, however, is that the function f can be used to prove that the problem
of choosing the next action optimally cannot be simplified to P thanks to a preprocessing
step working on the MDP and the horizon only. This, in turn, implies the nonexistence of
a polynomially sized circuit representing the optimal policy.
A polynomial reduction from 3sat to a problem does not necessarily prove that the
problem cannot be efficiently preprocessed. Consider, however, the case in which the problem instances can be divided in two parts. The reduction itself can be decomposed in two
separate functions, one generating the part of the instance that can be preprocessed and
one generating the rest of the instance. In our case, M and T form the part that can be
preprocessed, while the state s and the action a are the rest of the instance. As a result, if
f () = hM, T, s, ai, the two functions are defined by:
r() = hM, T i
560

fiOn Polynomial Sized MDP Succinct Policies

J
J
 J

J

J

J
 execution of A J
at this level, each state
for
3m
times

J
represents a set of clauses

J

J


J 
S
U U U
A
 A
A a satisfiable formula
unsatisfiable

A
formulas

A


A
1 1 2n+12n+1
not models
models

Figure 2: The optimal policy of the MDP of the proof.

h() = hs, ai.
Provided that the polynomial hierarchy does not collapse, a problem is not in k;P if
there exists a monotonic Polynomial reduction from 3sat to the problem (Liberatore, 2001).
A polynomial reduction is monotonic if the two functions it is made of satisfy the following
condition: for every pair of sets of clauses 1 and 2 of three literals over the same set of
variables, if 1  2 then hr(1 ), h(1 )i is a yes instance if and only if hr(2 ), h(1 )i
is a yes instance. Note that the second instance is hr(2 ), h(1 )i, that is, it combines a
part derived from 2 and a part from 1 .
The specialization of this condition to the case of the next-action problem is as follows.
Let hM1 , T i = r(1 ) and hM2 , T i = r(2 ): the two horizons are the same because 1 and
2 are on the same alphabet. Let hs, ai = h(1 ). Monotonicity holds if, for any two sets
of clauses 1 and 2 over the same set of literals with 1  2 , a is the optimal action to
execute in the state s for M1 and T if and only if it is so for M2 and T . The reduction f
defined above satisfies this condition.
Theorem 2 The function f from sets of clauses to quadruples hM, T, s, ai is a monotonic
polynomial reduction.
Proof. Let 1 and 2 be two sets of clauses over the same set of variables, each clause being
composed of three literals, and let M1 and M2 be their corresponding MDPs. Since the
MDP corresponding to a set of clauses dependsby constructionon the set of variables
only, M1 and M2 are exactly the same MDP. Since the horizons of r(1 ) and r(2 ) are
the same, we have r(1 ) = r(2 ). As a result, for any state s and action a, the latter is the
optimal action to execute in M1 for the horizon T if and only if it is so for M2 , and this is
the definition of monotonicity for the case of MDPs.

561

fiLiberatore

This theorem implies that the next-action problem is hard for the compilability class
k;NP. In turn, this result implies that some MDPs do not have any optimal succinct policy
of size polynomial in that of the MDP and the horizon. More specifically, there is no way
for storing the optimal actions for all states in such a way the required space is polynomial
and the time needed to determine the action to execute in a state is polynomial as well.
Theorem 3 If there exists a data structure, of size polynomial in that of the MDP and the
horizon, that allows computing the best action to execute (either from the current state or
from the history) for any given MDP and horizon in unary notation in polynomial time,
then NP  P/poly.
Proof. If such a data structure exists, the next-action problem is in k;P: given the fixed
part of the problem only (the MDP and the horizon), it is possible determine such a data
structure in the preprocessing step; the result of this step makes determining the next action
a polynomial task. As a result, the next-action problem is in k;P. On the other hand,
the existence of a monotonic polynomial reduction from propositional satisfiability to the
next-action problem implies that if this problem is in k;P, then k;NP=k;P (Liberatore,
2001, Theorem 3). In turn, this result implies that NP  P/poly (Cadoli et al., 2002,
Theorem 2.12).
Note that NP  P/poly implies that p2 = p2 = PH, i.e., the polynomial hierarchy
collapses to its second level (Karp & Lipton, 1980). As a result, the above theorem implies
that one can always represent the optimal policies in space polynomial in that of the MDP
and the horizon only if the polynomial hierarchy collapses. Since the succinct representation
of policies based on circuits is a subcase of data structures allowing the determination of
the next action in polynomial time, the following corollary holds.
Corollary 1 If there exists a polynomial p such that every succinct MDP M with horizon
T has succinct optimal policies (either stationary or history dependent) of size bounded by
p(||M|| + T ), then NP  P/poly and p2 = p2 = PH.

5. Finding and Evaluating Succinct Policies
The problem considered in this section is that of checking the existence of succinct policies
of a given size and reward.
A subproblem of interest is that of evaluating a policy, that is, calculating its expected
reward. While Mundhenk et al. (2000) found the complexity of this problem for various
cases, they left open the case of full observability and succinct representation, which is
the one considered in this paper. This problem has instead been analyzed by Littman,
Goldsmith, and Mundhenk (1998) considering the succinct representation of plans based on
the ST plan representation (which is also equivalent to other succinct representation.) The
proof presented in the current paper could follow along similar lines.
Does the evaluation problem make sense, given that some MDPs do not have optimal
succinct policies of polynomial size? From a theoretical point of view, super-polynomiality
does not forbid a complexity analysis. Indeed, complexity is measured relative to the total
size of the problem instances; the instances of the policy evaluation problem include both
562

fiOn Polynomial Sized MDP Succinct Policies

the policy and the MDP. If a policy is exponentially larger than the MDP, this means that
the MDP is only a logarithmic part of the instance.
Formally, the problem of policy evaluation is: given an MDP, a policy, and a number k,
decide whether the expected reward of the policy is greater than k. This is a counting problem, as it amounts to summing up the evaluations that result from computing a polynomial
function over a set of propositional models. Not surprisingly, it is in PP.
Theorem 4 Given a succinct MDP M = hV, s0 , A, t, ri, a horizon T in unary notation, a
succinct policy P (either stationary or history dependent), and a number k, deciding whether
the policy P has expected reward greater than k is in PP.
Proof. The expected reward of the policy is a weighted sum of rewards of states. Let us
consider the sequence of states s0 , s1 , . . . , sd . The probability of this sequence of being the
actual history can be computed as follows: for each pair of consecutive states si , si+1 there
is a factor given by the probability t(si , si+1 , a), where a is the unique action that is chosen
by the policy in state si (or, when the history is s0 , . . . , si .) Multiplying all these factors,
the result is the probability of the whole sequence s0 , s1 , . . . , sd to be the actual history
up to point d. Since P (si ) denotes the output of the circuit P when si is its input, then
P (si ) represents the action that is executed in the state si . As a result, the probability of
s0 , s1 , . . . , sd of being the actual sequence of states is as follows:
H(s0 , s1 , . . . , sd ) =

Y

t(si , si+1 , P (si ))

i=0,...,d1

The same probability for history-dependent policies can be determined in the same way,
but P (si ) is replaced by P (s0 , . . . , si ). Given a specific sequence s0 , . . . , sd , it is possible
to determine H(s0 , . . . , sd ) in time polynomial in the size of the sequence plus that of the
MDP.
The expected reward of the policy can be calculated as the sum of the expected reward
of each state sd multiplied by the probability of a sequence ending with sd being the actual
history. This sum can be expressed as follows:
R(P ) = r(s0 ) +

d=1,...,T
X

H(s0 , . . . , sd )  r(sd ).

s1 ,...,sd S

The number d ranges from 1 to T to take into account all sequences up to length
T . This is how intermediate states of the sequences are dealt with: for each sequence
s0 , . . . , si , . . . , sd , the sum above contains a term for each subsequence s0 , . . . , si as well.
Roughly speaking, the membership in PP is due to the fact that the expected reward of
a policy is the result of a sum of an exponential number of terms, and each of those terms
can be determined in polynomial time in a uniform manner. Formally, what is proved is
that the problem can be expressed as the sum of terms V (M ), where V is a polynomial
function and M ranges over all propositional interpretations over a given alphabet. To
complete the proof, therefore, what is needed is to encode each possible sequence s0 , . . . , sd
as a propositional model, with the constraint that H(s0 , . . . , sd )  r(sd ) can be determined
from this model in polynomial time.
563

fiLiberatore

The employed encoding is the following one: the alphabet is X1      XT  Y , where
each set Xi is a set of variables in one-to-one correspondence with the variables of the MDP,
and Y is a set of variables of size log(T ). A model M represents the sequence whose length
is given by the values of Y and whose i-th state is given by the values of Xi .
What is only left to show is that the expected probability of each sequence can be
determined in polynomial time given the model that represents the sequence. This is true
because, given M, it is possible to rebuild the sequence from the model in time linear in the
size of the model, and then evaluate H. Since sequences can be represented by propositional
interpretations, and the function giving the weighted reward of each interpretation is polytime, the problem is in PP.
This theorem shows that the problem of policy evaluation for succinct MDPs and horizon
in unary notation is in PP. The problem can also be proved hard for the same class.
Theorem 5 Given a succinct MDP M, a horizon T in unary notation, a succinct policy
P , and a number k, deciding whether the expected reward of P is greater than k is PP-hard.
Proof. This theorem is proved by reduction from the problem of checking whether a formula
is satisfied by at least half of the possible truth assignments over its variables. Let Q be
a formula over the alphabet X = {x1 , . . . , xn }. We define the MDP M = hV, s0 , A, t, ri
in such a way that its states are in correspondence with the sequences of literals over X.
The actions are {a1 , . . . , an }, where each ai modifies the state by adding xi or xi to the
sequence represented by the state, with the same probability. The reward function assigns
1 to all sequences that represent models of Q, and 0 to all other sequences. Namely, if a
sequence contains a variable twice, or does not contain a variable, its corresponding state
has reward 0.
Let P be the policy of executing ai in each state composed of i  1 literals. The states
that result from the application of this policy at time i are consistent sets of literals on
the alphabet x1 , . . . , xi1 . If i < n  1, such a state has reward 0. Therefore, only the
states at time T = n  1 are relevant to the calculation of the expected reward of P . These
states are sets of literals that represent models over the alphabet X; their probability of
being the state at time T = n  1 is 1/2n . Given that the reward of a state is 1 if the
corresponding model satisfies Q and 0 otherwise, the expected reward of P is m/2n , where
m is the number of models of Q.
The very same proof can be used to prove that the problem of finding the expected
reward of a policy is #P-hard, but only decision problems are considered in this paper.
The above two theorems allow concluding that the problem is PP-complete.
Corollary 2 Given a succinct MDP, a horizon in unary notation, a succinct policy, and a
number k, deciding whether the expected reward of the policy is larger than k is PP-complete.
Let us now turn to the problem of checking the existence of a policy of a given size
and expected reward. The same problem without the size constraint is PSPACE-hard
(Mundhenk et al., 2000). The above corollary indicates that the size bound allows for a
guess-and-check algorithm having a slightly lower complexity.

564

fiOn Polynomial Sized MDP Succinct Policies

Theorem 6 Given a succinct MDP, a horizon in unary notation, a size bound z in unary
notation, and a reward bound k, checking the existence of a succinct policy of size bounded
by z and expected reward greater than or equal to k is NPPP -complete.
Proof. Membership is easy to prove: guess a circuit of size z representing a policy and check
whether its expected reward is greater than k. Note that z being in unary is essential.
Hardness is proved by reduction from e-majsat, a problem defined by Littman et al.
(1998) as follows: given a formula Q over variables X  Y , decide whether there exists a
truth assignment over X such that at least half of the interpretations extending it satisfy
Q. This problem is NPPP -complete (Littman et al., 1998).
Given an instance of e-majsat, its corresponding MDP is defined as follows: states
represent sequences of literals over X  Y (we assume, w.l.o.g., that |X| = |Y | = n.) There
is an action ai for each variable in Y . Each ai adds the literal yi or yi to the sequence
representing the current state with the same probability. Each variable xi is associated with
the actions bi and ci , which add xi and xi to the state, respectively. The reward of a state
is 1 only if it represents a sequence of the form []x1 , []x2 , . . . , []yn and all its literals
satisfy Q, that is, the sequence is a complete interpretation that satisfies Q.
A policy with expected reward greater than 0 can only be made of a sequence whose
i-th element (1  i  n) is either bi or ci , and its i + n-th element (1  i  n) is ai .
The expected reward of this policy over a horizon T = 2n is 1 only if at least half of the
completions of the model defined by the actions bi and cj satisfy Q. Therefore, the MDP
has a policy of reward 1 if and only if Q is in e-majsat.
This result can be used for an alternative proof of the claim that not all MDPs admit
polynomially sized optimal succinct policies. This proof is interesting because it employs a
different technique, and because it is conditioned differently than the previous one.
Theorem 7 If all MDPs have optimal succinct policies (either stationary or history dependent) of size polynomial in the sum of the size of the MDP and the length of the horizon
then PSPACE  NPPP .
Proof. Checking the existence of a policy of a given expected reward, regardless of its
size, is PSPACE-hard (Mundhenk et al., 2000). On the other hand, if all policies can be
represented in polynomial space, this problem coincides with that of checking the existence
of a policy with a given bound on its size, and the latter problem is in NPPP .
Theorem 7 is proved using the fact that the problems of evaluating a policy of a given size
and deciding the existence of a policy have different complexity characterizations. The same
technique has been used by Papadimitriou and Tsitsiklis (1987) for the case of POMDPs
in the explicit representation.
Precisely, the proof is composed of the following sequence of statements:
1. Evaluating the expected reward of a succinct policy is C1 -complete, where C1 is a
complexity class;
2. Deciding the existence of a policy (with no size bound) with a given expected reward
is C2 -complete, where C2 is a complexity class;
565

fiLiberatore

3. If any policy could be succinctly represented in space polynomial in the size of the
MDP and the value of the horizon, the second problem could be solved by guessing a
policy and then evaluating it; since the policy to guess has size polynomial in the size
of the instance of B, then C2  NPC1 .
What makes the proof worthy is the (probable) falsity of the conclusion C2  NPC1 .
In other words, the same proof can be applied to prove that a given data structure is not
always polynomially large if:
1. there is a problem A that is C1 -complete;
2. there is a problem B that is C2 -complete;
3. problem B can be expressed as: there exists a data structure satisfying problem A.
This proof schema is simply the generalization of the one above: the data structure is the
succinct policy; the first problem is that of evaluating a succinct policy; the second problem
is that of deciding the existence of a policy giving a given expected reward. By definition, an
instance satisfying B implies the existence of a data structure satisfying A. If it is possible
to replace the existence of a data structure with the existence of a polynomial-size data
structure in this sentence, then C2  NPC1 , as B can be solved by guessing that data
structure and then checking whether A is satisfied or not. If the conclusion C2  NPC1
is false, then there are instances satisfying B that are not related to any data structure
satisfying A that have size polynomial in the size of the instance of B.

6. Bounding the Value Function
Bounding the policy size is motivated by the fact that we are only interested in policies
that can actually be stored: a policy can be used only if its size is less than or equal to the
available storage space. In this section, a similar constraint is considered, motivated by how
some algorithms for MDPs work. Namely, programs based on the popular value iteration
algorithm (Littman et al., 1995; Cassandra et al., 1997; Koller & Parr, 1999; Zhang &
Zhang, 2001) work by finding the value function, which is the function giving the expected
reward that can be obtained from each state by executing the actions according to a given
policy.
Definition 5 The value function E of an MDP M = hS, s0 , A, t, ri with horizon T and
policy P is the function that gives the expected reward of a state s at i steps before the
horizon:
(

E(s, i) =

r(s)
if i = 0
P
r(s) + s0 S t(s, s0 , P (s))  E(s0 , i  1) otherwise.

A similar definition can be given for history-dependent policies by including the history
in the arguments of the value function and of the policy:
(

E(s0 , . . . , sj , i) =

r(sj )
if i = 0;
P
r(sj ) + s0 S t(sj , s0 , P (s0 , . . . , sj ))  E(s0 , i  1) otherwise.
566

fiOn Polynomial Sized MDP Succinct Policies

The value function for succinct MDPs is defined by simply replacing s0  S with s0 is
a propositional interpretation over V.
If the MDP and the policy are succinctly represented, the value function cannot necessarily be represented explicitly in polynomial space. Rather, some form of succinct representation is employed, usually by decomposition of the state space (for example, by grouping
states with the same expected reward.) As it has already been done for policies, value
functions are succinctly represented by circuits.
Definition 6 A succinct value function is a circuit E whose inputs are a state s and an
integer i and whose output is the expected reward of s at i points before the horizon.
Given a policy P , there always exists an associated value function, which gives the
expected reward that can be obtained from the state by executing the actions as specified
by the policy. The converse, however, is not always possible. Some value functions, indeed,
do not correspond to any policy. While any value function can be used to derive a policy
by selecting the actions that maximize the expected reward of the resulting states (this is
how value functions are often used), some value functions are completely unrelated to the
actual expected reward of states. As an example, if the reward of s0 is 0, and no action
changes the states (i.e., t(s, s, a) = 1 for all actions a and states s), then the value function
E such that E(s0 , T ) = 1000 does not correspond to any policy. In other words, some value
functions assign expected rewards to states in a way that is not consistent with the MDP,
i.e., there is no way to obtain such a reward by executing whichever actions. Therefore, a
value function may or may not be consistent, according to the following definition.
Definition 7 A value function E is consistent with an MDP M and horizon T if and only
there exists a policy P such that E is the value function of M, T , and P .
An interesting property of value functions is that, in some cases, they actually represent
policies. Indeed, a policy can be determined from a value function in polynomial time if the
degree of non-determinism is bounded, and a list of possible states that may result from
executing an action can be calculated in polynomial time. In particular, the set of states
resulting from applying a in s are assumed to be the result of a circuit na .
Definition 8 A bounded-action MDP is a 6-tuple M = hV, s0 , A, N , t, ri, where M0 =
hV, s0 , A, t, ri is a succinct MDP and N = {na } is a set of circuits, one na  N for each
a  A, such that na (s) is the list of states s0 such that t(s, s0 , a) > 0.
Beside N , the definition of bounded-action MDPs is the same as that of succinct MDPs.
The difference can be explained in two ways: intuitively, it is assumed that the possible
outcomes of actions can be determined in time polynomial in the size of the MDP; technically, the time needed to determine the possible states that result from applying an action
is included in the size of the input.
The proof of NPPP -hardness of the problem of policy existence only uses bounded-action
MDPs, and therefore still holds in this case. This seems to contradict the intuition that a
large degree of non-determinism is one of the sources of complexity of problems on MDPs.
The next results will explain this contradiction.
567

fiLiberatore

Given a bounded-action MDP M, a horizon, and a succinct value function E, we can
identify in polynomial time a succinct policy that corresponds to E, that is, a policy that
leads to the expected reward of states as specified by E. For the case of stationary policies,
P is determined as follows: for a given state s, we consider an action a and a time point i,
and check whether the result of executing a is consistent with the value function, assuming
that the time point is i. This is done by determining the sum of t(s, s0 , a)  E(s0 , i  1). If
this is equal to E(s, i)  r(s), then the action a is the action to execute, i.e., P (s) = a. The
whole process is polynomial, that is, P (s) can be determined in polynomial time.
If E is consistent with an MDP, then there are policies for which the expected reward
of each state s is E(s). As a result, a consistent value function E represents a group of
policies, all having the same expected reward. It therefore makes sense to consider the
problem of finding E rather than finding P . More precisely, since only decision problems
are considered, the analyzed problem is that of checking whether there exists E such that
the expected reward of the corresponding policies is greater than or equal to a given number.
Given E, the expected reward is simply given by E(s0 , T ). In order to check whether such
a reward can actually be obtained from the MDP, however, we also have to check whether
the value function E is consistent with the MDP. This is the point where the assumption
that the set of actions of a succinct MDP is not in a succinct representation is used.
Theorem 8 Checking whether a succinct value function E is consistent with a boundedaction MDP and a horizon in unary is coNP-complete, both for stationary and historydependent policies.
Proof. The problem is to check whether there exists a policy P that gives an expected
reward as specified by E. Namely, for all s and i, we have to check whether the equation
in Definition 5 holds for some policy P . In turn, the existence of a policy means that, for
each s, there exists an associated action a that satisfies the equation when P (s) is replaced
by a.
Formally, let M = hV, s0 , A, t, ri be the MDP, T be the horizon, and S be the set of
interpretations over the alphabet V. The condition can be formally expressed as follows.
For every state s, it holds that E(s, 0) = r(s), and:
s  S a  A i  {1, . . . , T } . E(s, i) = r(s) +

X

t(s, s0 , a)  E(s, i  1).

s0 S

This condition contains three alternating quantifiers; however, the second one ranges
over a  A, while the third one ranges over i = {1, . . . , T }. In both cases, the number of
possibilities is polynomial in the size of the MDP and the horizon.


s .

_

^

aA

i=1,...,T



E(s, i) = r(s) +

X

t(s, s0 , a)  E(s0 , i  1) .

s0 S

The number of terms s0  S in the sum is not, in general, polynomial. The bounded
action assumption, however, implies that the only states that are relevant are those s0 that
belongs to na (s), i.e., s0 is one of the elements of the list produced by the circuit na when
s is given as its input.
568

fiOn Polynomial Sized MDP Succinct Policies



s .

_

^

aA

i=1,...,T


X

E(s, i) = r(s) +

t(s, s0 , P (s))  E(s0 , i  1) .

s0 na (s)

Considering a given s only, the condition can be checked in polynomial time. Since this
condition have to be checked for all possible s  S, the problem is in coNP. The case of
history-dependent policies is dealt with by replacing s with s0 , . . . , sj and i with T  j.
Hardness can be proved as follows: given a formula Q over variables X = {x1 , . . . , xn },
we build the succinct MDP with V = X and with a single action a. This action takes
a number i  {1, . . . , n} with equal probability and changes the value of xi . The reward
function is 1 in a state if it satisfies Q, and 0 otherwise. The value function with E(s, i) = 0
for all s  S and i = 1, . . . , T is consistent with the MDP if and only if the formula Q is
unsatisfiable. Indeed, since the MDP only contains one action, the only possible stationary
or history-dependent policy is that of always executing the action a. Such a policy leads
to a random interpretation. The expected reward of this policy is 1 if and only if no
interpretation satisfies Q.
Checking the existence of a consistent succinct value function of size bounded by z and
expected reward bounded by k is therefore in p2 , as it can be done by guessing a succinct
value function E, checking its consistency with the MDP and the horizon, and determining
the expected reward of the initial state E(s0 , T ). Since consistency is in coNP for boundedaction MDPs, the problem is in p2 . The following theorem also shows that the problem is
complete for this class.
Theorem 9 Given a bounded-action MDP M, a horizon T in unary notation, a size bound
z in unary notation, and a reward bound k, checking the existence of a succinct value
function E that is consistent with M and T , of size bounded by z and expected reward
bounded by k is p2 -complete both for stationary and history-dependent policies.
Proof. Membership: guess a succinct value function E (i.e., guess a circuit with a state or
history and an integer as input) of size at most z; check whether it is consistent with the
MDP and the horizon, and whether E(s0 , T )  k. Since checking consistency in in coNP
for both stationary and history-dependent policies, the problem is in p2 in both cases.
Hardness is proved as in Theorem 6. We use the problem of checking whether there
exists a truth evaluation over X whose extensions to X  Y are all models of Q, where Q
is a formula over X  Y and |X| = |Y | = n.
The MDP that corresponds to Q has sequences of literals over X  Y as states. There
is an action ai for each variable in Y and two actions bi and ci for each variable in X. The
effect of ai is to add either yi or yi to the state, with the same probability. The actions bi
and ci add xi and xi , respectively, and are therefore deterministic actions. The reward of
a state is 1 if and only if the state is a sequence comprised of either x1 or x1 followed by
x2 or x2 , etc., and its literals form a model of Q. All other states have reward 0.
A policy with nonzero reward executes either bi or ci at time i, and then execute the
actions a1 , . . . , an in sequence. After the first n actions, the state is exactly a model over X.
The reward of the policy is the number of models that extend it and satisfy Q. Therefore,
569

fiLiberatore

there exists a policy with reward 1 if and only if there exists a model over X whose extensions
all satisfy Q.
This theorem shows that checking the existence of a succinct value function of a given
size and reward is in a complexity class in the second level of the polynomial hierarchy for
bounded-action MDPs. The corresponding problem for policies (instead of value functions)
remains NPPP -hard for bounded-action MDPs. Assuming that p2 6= NPPP , checking the
existence of bounded-size succinct policies is harder than checking the existence of value
functions, in the sense that more problems can be polynomially reduced to the latter problem
than to the former. Let us consider this result.
1. The problem is easier because of the additional constraint on the size of the value
function. Assuming p2 6= NPPP , this implies that there are succinct policies of size
polynomial in that of the MDP whose value function cannot be expressed as a circuit of
size polynomial in that of the MDP, for bounded-actions MDPs. Translating succinct
value functions into succinct policies is instead always feasible in polynomial space
for bounded-actions MDPs. Therefore, any succinct policy can be translated into a
succinct value function of polynomial size (in the size of the policy, the MDP, and the
horizon), while the inverse translation is not always polynomial in size.
2. Given that the amount of physical memory is always bounded, the problem that is
solved by algorithms finding the value function (such as value iteration) is actually
that of checking the existence of a succinct value function of bounded size. This
problem is easier than the similar problem with no bound, in the sense that the first
problem can be polynomially reduced to the former but not vice versa, provided that
p2 6= NPPP .
Roughly speaking, finding a bounded-size succinct value function is simpler than finding
a bounded-size succinct policy, but solving the former problem may produce solutions that
are worse, in term of the overall reward, than the solutions of the latter.

7. Exponential Bounds
In the previous sections, the size bounds have been assumed to be in unary notation. This
assumption has been made because, if it is not feasible to store the unary representation of
the size, it is not feasible to store a data structure of that size as well. The unary notation
formalizes the informal statement that the policy should take an amount of space that is
polynomial in the size of the instance.
Let us now consider the problem of checking the existence of a policy of a bounded size
and reward, where the bound on the reward is in binary notation: we are searching for a
policy that can be exponentially larger than the MDP, but still of size bounded by a given
number. This problem is of interest whenever an exponential succinct policy is acceptable,
but still there is a limit on its size.
An important observation about circuits is that it is not necessary to consider circuits
of arbitrary size. Indeed, any circuit with n inputs and m outputs is equivalent to a circuit
of size m2n . This is because any such circuit is equivalent to m circuits, each having the
same n inputs and one output. Any such circuit represents a Boolean function, which can
570

fiOn Polynomial Sized MDP Succinct Policies

therefore expressed by a DNF in which each term contains all variables. Each such term
represents a model: therefore, there are only 2n different such terms if the alphabet is
made of n variables; as a result, the function can be expressed as a circuit of size 2n . As a
result, any policy can be expressed as a circuit of size |A|2n , where n is the number of state
variables.
This fact has two consequences: first, it is not necessary to consider circuits of arbitrary
size, as any policy can be represented by a circuit of size |A|2n ; second, the problem of
finding a succinct policy of size bounded by z = |A|2n and bounded reward is the same as
finding an arbitrary policy with the same bound on the reward. As a result, the problem of
checking whether an MDP has a succinct policy of size bounded by z and reward bounded
by k is at least as hard as the same problems with no bound on the size of the policy. The
latter problem is PSPACE-hard; therefore, the former is PSPACE-hard as well. The same
result holds for history-dependent policies: instead of n input gates, there are nT input
gates. By this observation, the following result follows as a simple corollary of a result by
Mundhenk et al. (2000).
Corollary 3 Checking whether an MDP and a horizon in unary notation have a succinct
policy of expected reward greater than or equal to k, and having size bounded by z, is
PSPACE-hard, if z is in binary notation.
Membership of this problem in PSPACE appears to be not so simple to prove. This
is not surprising for the case of stationary policies, as the same question is still open for
the problem with no bound on size. However, the same problem for history-dependent
policies with no bound on size is known to be in PSPACE (incidentally, the problem with
stationary policies but infinite horizon is EXPTIME-complete, as proved by Littman, 1997.)
The proof of this result cannot however be modified to cover the addition of a bound on
size. Intuitively, we are not only looking for a policy with a given reward, but also of a
given size. The constraint on the reward is somehow easier to check, as it is done locally:
the expected reward of a state is obtained by summing up the reward of the possible next
states. On the other hand, the size of the circuit representing the policy cannot be checked
until the whole circuit has been determined, and this circuit can be exponentially large.
What it is proved in this section is that the EXPTIME-hardness of the problem for
history-dependent policies is related to an open conjecture in computational complexity
(P=PSPACE). Namely, it is proved that P = PSPACE implies that the problem is in P. This
result can be rephrased as: if the problem is not in P, then P 6= PSPACE. Since EXPTIMEhard problems are not in P, if the problem is EXPTIME-hard, then P 6= PSPACE. This
conclusion is not really unlikely: on the contrary, it is believed to be true. On the other
hand, proving the problem to be EXPTIME-hard is at least as hard as solving a conjecture
that has been open for more than twenty years. As an intermediate step, it is proved that
P = PSPACE implies the existence of polynomially-sized history-dependent policies for all
MDPs.
Theorem 10 If P = PSPACE, then every succinct MDP with a horizon in unary notation
has an optimal succinct history-dependent policy of size polynomial in the size of the MDP
and the horizon.

571

fiLiberatore

Proof. Let us consider a state that results from a sequence of actions. Since the considered
policies are history dependent, it is possible to find the optimal choices from this point on
by taking the current state as the new initial state of the MDP, reducing the horizon, and
determining the optimal policy of this modified MDP.
Since the problem of checking whether an MDP has a policy of a given reward is in
PSPACE (Mundhenk et al., 2000), it is in P by assumption. By binary search, it is possible to determine the expected optimal reward of an MDP in polynomial time. Since the
expected optimal reward of each state can be computed by finding the expected optimal
reward of an MDP, this problem is polynomial as well. The function that determines the
optimal expected reward from a state can be therefore represented by a polynomial circuit.
The best action in a state is the one that leads to the best possible next states. It can be
determined in polynomial space by checking, for each action, its possible next states, and
determining their expected reward. Therefore, the best action to execute is in PSPACE,
and is therefore in P by assumption. As a result, this optimal policy can be represented by
a polynomial circuit.
The following corollary is an immediate consequence.
Corollary 4 If P = PSPACE, then the problem of existence of a succinct history-dependent
policy of a given expected reward and with a size bound in binary notation is in P.
Proof. If P = PSPACE, any MDP has an optimal history-dependent policy of polynomial
size. The problem can therefore be solved by iterating over all possible circuits whose size is
bounded by this polynomial. The problem can therefore be solved with only a polynomial
amount of memory, and is therefore in PSPACE. By assumption, it is in P as well.
At a first look, this corollary seems to prove that the problem is in PSPACE. However,
it does not prove such a result. This is shown by the following related example: a problem
that is is p2 -complete is in P if P = NP; however, it is generally believed that p2 -complete
problems are not in NP.
An easy consequence of this result is that the EXPTIME-hardness of the problem would
imply that P 6= PSPACE. Indeed, if the problem is EXPTIME-hard then it is not in P, as
these two classes are known to be different thanks to the theorem by Hartmanis and Stearns
(1965). As a result, it cannot be that P=PSPACE, which has been proved to imply that
the problem is in P. In other words, if the problem of history-dependent policy existence
with a size bound in binary notation is EXPTIME-hard then P 6= PSPACE.

8. Conclusions
It is not always possible to represent the optimal policies of a succinct MDP using circuits
of size polynomial in that of the MDP and the horizon. This result affects the choice of
how policies are generated and executed. Indeed, planning in a nondeterministic scenario
can be done in two ways:
1. Determine the actions to execute in all possible states all at once (i.e., determine the
whole policy); in each state, the corresponding action is executed;

572

fiOn Polynomial Sized MDP Succinct Policies

2. Determine the best action to execute in the initial state only; execute it and observe
the resulting state; find the best action in the new state, etc.
Many algorithms for MDPs find a representation of the whole policy, and only a few
solve the next-action problem directly (Kearns, Mansour, & Ng, 2002). Our result formally
proves that the optimal policy cannot be always represented in polynomial space, unless
the polynomial hierarchy collapses. This result holds not only for the existing algorithms
(such as value iteration or policy iteration), but also for any other algorithm that finds the
whole policy all at once.
While the second solution can be theoretically optimal, it involves finding the best action
at each time step, and this problem is hard, as proved by Theorem 1. The advantage of the
first solution is that the only hard step is to find the optimal policy; finding the action to
execute in a state is then polynomial.
The impossibility of always representing the optimal policies in polynomial space raises
a new problem: since the size of physical memory is bounded, it is not feasible to search
for the best among all policies, but only among those it is possible to store, that is, those
bounded in size by the available memory size. The problem of checking whether a succinct
MDP has a succinct policy of a given size and reward is proved to be NPPP -complete, and
is therefore slightly easier than the same problem without a bound, which is PSPACEhard (Mundhenk et al., 2000). A similar result has been proved for a slightly different
formalization of non-deterministic planning by Littman et al. (1998).
This complexity result holds only if policies are represented in a particular succinct
form, that of circuits giving the next action from the current state and (possibly) the
history. Nevertheless, different representations of policies lead to different results. Namely,
some algorithms actually find a value function (a function determining the expected reward
in each state), which can be considered as a representation of a policy when the states
that result from the execution of an action can be listed in polynomial time. In particular,
algorithms based on value iteration, when applied with some form of decomposition, find
a succinct representation of the value function. Finding a succinct representation of such
a function, with a given bound on its size, has been proved easier than finding a succinct
policy, when the states that result from the execution of an action can be listed in polynomial
time: it is p2 -complete.
This result has two consequences: first, the problem these algorithms solve is in a
smaller complexity class than the problem with no bound on size; second, some policies can
be represented in polynomial space, while their associated value functions cannot: there
exists a trade-off between complexity and ability of finding good solutions. This result is
also interesting because it characterizes the complexity of a family of algorithms (those
determining the value function in some succinct form) rather than the complexity of a
problem. This result is therefore of a kind that is between the efficiency analysis of a single
algorithm (e.g., the big-O running time) and the inherent complexity of the problem (e.g.,
the NP-completeness). As such, it is similar to results about complexity of proof procedures
(Beame & Pitassi, 1998; Egly & Tompits, 2001). Our analysis is however limited to the
case of exact value functions. Approximation is an interesting open problem. The effects
of the various restrictions that can be done on the MDP are interesting open problems as
well.
573

fiLiberatore

The analysis with a bound on size has been initially done assuming that the bound
is polynomial in the size of the instance. This is justified by the fact that the resulting
policy should not be too much larger than the MDP. However, a moderate increase may
be tolerated. Therefore, we considered the same problem removing the assumption of
polynomiality of the bound. This is a new problem, but is PSPACE-hard just as the
problem with no bound on size is. However, it is not EXPTIME-hard unless P 6= PSPACE.
This result shows that proving such hardness result is at least as hard as proving a conjecture
that has been open for more than twenty years.
Let us now discuss how the results presented in this paper relate to similar ones in the
literature. As already remarked in the Introduction, the complexity of problems related to
finding a policy does not necessarily imply that policies cannot be compactly represented.
Namely, even a result of undecidability does not forbid compactness of policies. Therefore,
our result is not implied by previous complexity results in the literature. On the other
hand, a result of non-polynomiality of the size of policies of POMDPs already appeared
in the paper by Papadimitriou and Tsitsiklis (1987). Namely, they proved that, unless
PSPACE = p2 , there is no algorithm A and mapping  from POMDPs in explicit form to
strings of polynomial length that can be used by A to compute the optimal action. This
result basically proves the non-polynomiality of policies. However, it cannot imply ours, as
it holds for POMDPs in the explicit representation with only non-positive rewards; the same
problem that is PSPACE-hard in their formalization is polynomial in ours (Mundhenk et al.,
2000). More precisely, the two results cannot be derived from each other. Some related
results in the literature are about the non-representability (as opposite to the compactrepresentability studied in this paper): Littman (1997) has shown that (infinite horizon)
plan existence is EXPTIME-complete, while Littman et al. (1998) have shown that the
same problem restricted to looping plans is PSPACE-complete: as a result, infinite-horizon
policies cannot be represented at all as looping plans unless EXPTIME=PSPACE.
During the review period of this paper, a different proof of the impossibility of representing the optimal policies of all MDPs in polynomial space has been published (Allender,
Arora, Kearns, Moore, & Russell, 2002). This new proof improves over the ones presented
in this paper and in its conference version (Liberatore, 2002) in two ways: first, the condition under which the new result holds is PSPACE 6 P/poly instead of NP 6 P/poly and
PSPACE 6 NPPP ; second, the proof holds even for approximately optimal policies. The
other differences (the new proof is for the infinite horizon with a discount factor, the reward
function is linear, two-levels Bayes nets are used instead of circuits) are inessential, i.e., the
proofs can be modified in such a way they are not affected by these other differences. The
current paper also contains results on the problem with a bound on the policy or the value
function.
Let us now consider the other complexity results about MDPs in the literature. The
problem of deciding whether a succinct MDP with a horizon in unary notation has a policy of a given reward is PSPACE-hard, and is PSPACE-complete for history-dependent
policies. The same problem with a bound in unary notation on the size of the policy is
NPPP -complete. This class contains the class PPP , which in turn contains the whole polynomial hierarchy. Therefore, a problem that is NPPP -complete is hard for any class of the
574

fiOn Polynomial Sized MDP Succinct Policies

polynomial hierarchy. This means that a bound on size in unary notation does not decrease
the complexity of the problem much. On the other hand, bounding the size of the value
function representation decreases the complexity more, as the problem is p2 -complete.
To conclude, observe that negative results (impossibility of polynomial policies and
hardness results) hold for POMDPs, since MDPs are special cases of POMDPs in which
everything is observable. Our results, however, only apply to the case in which both the
POMDP and the policy are in succinct form. The case of explicit representation has been
studied by Papadimitriou and Tsitsiklis (1987) (their results are discussed above), and by
Mundhenk (1999), who considered the problem of deciding whether a POMDP in explicit
form has a c-small policy, given c, where c-small-ness includes a bound on size depending
on c.

Acknowledgments
Many thanks to Michael Littman and the anonymous referees for their suggestions. Part of
this work appeared in the proceedings of the Eighteenth National Conference on Artificial
Intelligence (AAAI-2002).

References
Allender, E., Arora, S., Kearns, M., Moore, C., & Russell, A. (2002). A note on the representational incompatability of function approximation and factored dynamics. In
Proceedings of the Sixteenth Annual Conference on Neural Information Processing
Systems (NIPS 2002).
Beame, P., & Pitassi, T. (1998). Propositional proof complexity: Past, present and
future. Tech. rep. 067, Electronic Colloquium on Computational Complexity,
http://www.eccc.uni-trier.de/eccc/.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Boppana, R., & Sipser, M. (1990). The complexity of finite functions. In van Leeuwen,
J. (Ed.), Handbook of Theoretical Computer Science, Vol. A, chap. 14, pp. 757804.
Elsevier Science Publishers (North-Holland), Amsterdam.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. Journal of Artificial Intelligence Research,
11, 194.
Cadoli, M., Donini, F. M., Liberatore, P., & Schaerf, M. (2002). Preprocessing of intractable
problems. Information and Computation, 176 (2), 89120.
Cassandra, A., Littman, M., & Zhang, N. (1997). Incremental pruning: a simple, fast, exact
method for partially observable Markov decision processes. In Proceedings of the
Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI97), pp. 5461.
Dean, T., & Kanazawa, K. (1989). A model for reasoning about persistence and causation.
Computational Intelligence, 5 (3), 142150.

575

fiLiberatore

Dearden, R., & Boutilier, C. (1997). Abstraction and approximate decision theoretic planning. Artificial Intelligence, 89 (1), 219283.
Egly, U., & Tompits, H. (2001). Proof-complexity results for nonmonotonic reasoning. ACM
Transactions on Computational Logic, 2 (3), 34038.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W.H. Freeman and Company, San Francisco, Ca.
Hansen, E., & Feng, Z. (2000). Dynamic programming for POMDPs using a factored state
representation. In Proceedings of the Fifth International Conference on Artificial
Intelligence Planning Systems (AIPS 2000), pp. 130139.
Hartmanis, J., & Stearns, R. E. (1965). On the computational complexity of algorithms.
Trans. Amer. Math. Soc. (AMS), 117, 285306.
Johnson, D. S. (1990). A catalog of complexity classes. In van Leeuwen, J. (Ed.), Handbook of
Theoretical Computer Science, Vol. A, chap. 2, pp. 67161. Elsevier Science Publishers
(North-Holland), Amsterdam.
Karp, R. M., & Lipton, R. J. (1980). Some connections between non-uniform and uniform
complexity classes. In Proceedings of the Twelfth ACM Symposium on Theory of
Computing (STOC80), pp. 302309.
Kearns, M., Mansour, Y., & Ng, A. (2002). A sparse sampling algorithm for near-optimal
planning in large markov decision processes. Machine Learning, 49 (23), 193208.
Koller, D., & Parr, D. (1999). Computing factored value functions for policies in structured
MDPs. In Proceedings of the Sixteenth International Joint Conference on Artificial
Intelligence (IJCAI99), pp. 13321339.
Liberatore, P. (2001). Monotonic reductions, representative equivalence, and compilation
of intractable problems. Journal of the ACM, 48 (6), 10911125.
Liberatore, P. (2002). The size of MDP factored policies. In Proceedings of the Eighteenth
National Conference on Artificial Intelligence (AAAI 2002), pp. 267272.
Littman, M. (1997). Probabilistic propositional planning: representations and complexity. In Proceedings of the Fourteenth National Conference on Artificial Intelligence
(AAAI97), pp. 748754.
Littman, M., Dean, T., & Kaebling, L. (1995). On the complexity of solving Markov
decision processes. In Proceedings of the Eleventh Annual Conference on Uncertainty
in Artificial Intelligence (UAI95), pp. 394402.
Littman, M., Goldsmith, J., & Mundhenk, M. (1998). The computational complexity of
probabilistic planning. Journal of Artificial Intelligence Research, 9 (1), 136.
Madani, O., Hanks, S., & Condon, A. (1999). On the undecidability of probabilistic planning
and infinite-horizon partially observable Markov decision problems. In Proceedings of
the Sixteenth National Conference on Artificial Intelligence (AAAI99), pp. 541548.
Mundhenk, M. (1999). The complexity of optimal small policies. Tech. rep. 9922, University
of Trier.

576

fiOn Polynomial Sized MDP Succinct Policies

Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (2000). Complexity of finitehorizon Markov decision processes problems. Journal of the ACM, 47 (4), 681720.
Papadimitriou, C., & Tsitsiklis, J. (1987). The complexity of Markov decision processes.
Mathematics of Operations Research, 12 (3), 441450.
Puterman, M. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons.
Stockmeyer, L. J. (1976). The polynomial-time hierarchy. Theoretical Computer Science,
3, 122.
Zhang, N., & Zhang, W. (2001). Speeding up the convergence of value iteration in partially
observable Markov decision processes. Journal of Artificial Intelligence Research, 14,
2951.

577

fiJournal of Artificial Intelligence Research 21 (2004) 595-629

Submitted 7/03; published 5/04

Concurrent Auctions Across The Supply Chain
mosheb@cs.huji.ac.il
noam@cs.huji.ac.il

Moshe Babaio
Noam Nisan
School of Computer Science and Engineering,
The Hebrew University of Jerusalem, Jerusalem 91904, Israel

Abstract
With the recent technological feasibility of electronic commerce over the Internet,
much attention has been given to the design of electronic markets for various types of
electronically-tradable goods. Such markets, however, will normally need to function in
some relationship with markets for other related goods, usually those downstream or upstream in the supply chain. Thus, for example, an electronic market for rubber tires for
trucks will likely need to be strongly inuenced by the rubber market as well as by the
truck market.
In this paper we design protocols for exchange of information between a sequence of markets
along a single supply chain. These protocols allow each of these markets to function separately, while the information exchanged ensures ecient global behavior across the supply
chain. Each market that forms a link in the supply chain operates as a double auction,
where the bids on one side of the double auction come from bidders in the corresponding
segment of the industry, and the bids on the other side are synthetically generated by the
protocol to express the combined information from all other links in the chain. The double
auctions in each of the markets can be of several types, and we study several variants of
incentive compatible double auctions, comparing them in terms of their eciency and of
the market revenue.

1. Introduction
The recent rush towards electronic commerce over the Internet raises many challenges, both
technological and conceptual. This paper deals with the conceptual challenge of coordination between electronic markets. Let us look only a few years into the technological future
of electronic commerce. It seems very likely that the following two key challenges will be
adequately solved by the industry:
 Supply Chain Integration: The enterprise information systems of businesses will
be able to securely and eciently share information and inter operate with the information systems of their suppliers, customers, and partners.
 Electronic Markets: Ecient, sophisticated, robust and liquid electronic markets
will be available for the trade of goods in most segments of the industry. Such markets
will interactively respond to changes in supply and demand, dynamically changing
trade quantities and prices.
We are interested in the conceptual question of how can markets for related goods
share information. Consider, for example, a ctional market for rubber tires for trucks,
and the two related markets for rubber and for trucks. One can imagine the following
c
2004
AI Access Foundation. All rights reserved.

fiBabaioff & Nisan

simplied supply chain forming: rubber manufacturers placing sell bids for rubber in the
rubber market; tire manufacturers placing buy orders on the rubber market and sell bids
on the tire market; truck manufacturers placing buy bids in the tire market and selling
trucks on the truck market; and nally customers bidding for trucks. One would expect the
combination of these markets together with the information systems of the manufacturers
to be able to automatically respond to markets changes in an economically ecient way.
Thus, for example, a surge in demand for a certain type of trucks, will raise their price in
the truck market causing manufacturers of this type of truck to automatically decide to
increase production, consequently and automatically raising their electronic bids for tires.
This, in turn, may increase tire prices in the tire market, etc., etc., leading, eventually
and indirectly, but still completely automatically, to increased rubber production by rubber
manufacturers.
Let us emphasize: the process just described occurs, slowly, in normal human trade
by the combined eects of a large number of self-interested decisions by the many people
involved in this supply chain. What we desire from the combination of the participating
information systems and electronic markets is to automatically (without human control)
and very rapidly (within the time-frames of electronic commerce), to reach similar results
or even more economically ecient ones than what humans usually achieve. These results
should be achieved despite the fact that the information systems of manufacturers will still
be self-interested  optimizing the companys prot and not the global economic eciency.
Seeing the invisible hand function in normal human economic activity, one would
certainly expect that electronic markets reach these types of results. However, a key conceptual design challenge emerges when bidders must be concurrently active in more than
one market. Tire manufacturers must concurrently participate as buyers in the rubber market and as sellers in the tire market. Clearly, the quantity of rubber they wish to buy at a
given price is determined by the amount of tires they can sell at a given price. Thus, the
price they bid for buying rubber must be intimately related to the price they bid for selling
tires  any increase in one of them will lead to a corresponding increase in the other. It is
theoretically impossible to dene a suggested bid for one without the other. Thus, if the
two markets operate independently, then the tires manufacturers are not able to reasonably
participate in any of them. If they operate sequentially, say rst rubber is bought and only
afterwards tires are sold, then a serious exposure problem emerges: tire manufacturers must
be conservative in their bids for rubber, as they do not know in advance what price they
will get in the tire market.
One approach for handling this inter-dependence of markets is to run the complete
supply chain as a single complex huge market. Conceptually this is in the spirit of the
recently popular vertical markets and vertical portals that try to vertically integrate
information and trade for a complete vertical segment of industry. The integration of all
these markets into a single complex market results in a complex optimization problem,
and some research has been done to address such problems as pure optimization problems.
Such a centralized solution has obvious advantages, but is also problematic due to necessity
of concentrating all information, communications, and decision making at a single point.
Such centralization of information is problematic both in the sense of distributed computing
systems and in the economic sense.
596

fiConcurrent Auctions Across The Supply Chain

In this paper we suggest an alternative approach: the supply chain is organized as a
sequence of separate markets (which do not act strategically) that communicate among
themselves using a xed protocol to create a distributed mechanism (for a general overview
of distributed algorithmic mechanism design, we refer the reader to Feigenbaum & Shenker,
2002). A similar approach has been suggested by Walsh and Wellman (2003) and by Walsh,
Wellman, and Ygge (2000), who formulate a general problem that is NP-complete and obtain
solutions that are not provably ecient, either in the computational sense or in the economic
sense. A much simpler problem of a linear supply chain was considered by Bosch-Domenech
and Sunder (1999), but no provably ecient protocol was suggested. We also consider the
linear supply chain problem, and obtain computationally ecient protocols which achieve
provably high economic eciency with budget balance (or full eciency with budget decit).
In our protocols, the intermediate markets along the chain transform one good into another.
Thus, for example, tire manufacturers place bids for the operation of transforming a unit
of rubber into a tire. The protocol between the dierent markets assures that the dierent
markets reach compatible decisions, i.e. that the amount of rubber units to tires that was
allocated is equal both to the amount of rubber manufactured and to the amount of tires
needed. Furthermore, these amounts achieve global economic eciency across the supply
chain. Finally, this result does not assume that the manufactures information systems have
any global knowledge or behavior, beyond their knowledge of their own cost structure and
their self-interested (rational) behavior.
This paper focuses on the case of a simple linear supply chain for discrete units of goods,
where each manufacturer is able to transform a single unit of one good into a single unit
of another good, incurring some cost for the transformation. Each consumer obtains value
from acquiring a single unit of the nal good. We assume that each agent has a quasi-linear
utility function, and his goal is to maximize his utility.
Each of our markets takes the form of a double auction (see Friedman & Rust, 1991,
for a study of double auction markets), and we consider several variants of double auctions.
These variants address four issues: Incentive Compatibility (IC): The double auction rules
motivate self-interested agents (the manufacturers and consumers) to reveal their costs /
values truthfully (we use the standard notions of dominant strategies IC from Mechanism
Design literature; Mas-Collel, Whinston, & Green, 1995; Osborne & Rubinstein, 1994).
Individual Rationality (IR): Every agent has a strategy which ensures a non-negative utility,
so agents participate voluntarily (Ex-Post individual rationality). Economic Eciency: The
desired outcome should optimize the sum of valuations of all participants. Budget Balance
(BB): The payment by each buyer does not necessarily equal to the payment received by
each seller, but we wish to ensure that the market mechanism itself does not subsidize the
trade. Thus, the total payment by the buyers should be at least as the total amount given
to sellers. By Myerson and Satterthwaite (1983) impossibility result, these four conditions
cannot apply simultaneously. The paper by Parkes, Kalagnanam, and Eso (2001) presents
mechanisms for combinatorial exchange which are BB and IR but fairly ecient and fairly
incentive compatible. We take a dierent approach and consider variants that are always
IR and IC and trade-o the last two conditions of eciency and budget balance. Such a
deterministic rule was previously suggested by McAfee (1992), but, surprisingly, this rule
turned out not to be compatible with our supply-chain protocols. Therefore we suggest two
new randomized double auction rules that can be used with our supply-chain protocols, and
597

fiBabaioff & Nisan

obtain budget balance or surplus but with a slight loss of eciency. We also provide some
simulation results comparing the eciency and budget surplus of the dierent variants of
double auctions.
The main contribution of this paper is the description of two alternative protocols that
allow a supply chain mechanism formed from double auctions to operate eciently. These
protocols are computationally ecient in terms of communication and computation time.
We prove that when these protocols are applied with a specic double auction rule (the
Trade Reduction rule), the resulting system exhibits the following three key properties:
1. Ex-post Individual Rationality and Incentive Compatibility (in the sense of dominant
strategies).
2. High global economic eciency (not optimal, but as good as the underlying double
auction which guarantees high fraction of the ecient allocation value).
3. Budget Balance.
With our new double auctions, an even higher global economic eciency can be achieved in
expectation, but with expected (ex-ante) budget balance rather than worst case (ex-post).
When these protocols use the VCG (Vickrey, 1961; Clarke, 1971; Groves, 1973) double
auction rule which is ecient, they maintain IR and IC and achieve full economic eciency
for the entire supply chain, but with a budget decit.
Clearly our stylized model is not the most general supply chain model and it is far too
simple to be a realistic model. Our purpose in analyzing this model is to present a rst step
towards a mechanism design approach to supply chain problems. As far as we know we are
the rst to design a mechanism that is IC, IR, BB and highly ecient for a supply chain
model.
The rest of this paper is structured as follows. In Section 2 we give a complete self
contained example of the organization of a simple supply chain and we demonstrate the
type of calculations and information transfer of one of our protocols. In Section 3 we
present the model and conditions for incentive compatibility. In Section 4 we summarize
the properties of several variants of incentive-compatible double auctions and present two
new randomized double auction rules. In Section 5 we present two alternative protocols
for supply chain coordination between markets, and prove the properties achieved by these
protocols, and in Section 6 we conclude with directions for future work.

2. The Lemonade-Stand Industry
Charlie Brown has decided to draw on his vast experience in the lemonade stand industry
and transform the whole industry by bringing it online to the Internet. Charlie Brown
has already struck partnerships with strategic players from the three core segments of the
industry:
 Lemon Pickers: Alice, Ann, and Abe can pick a lemon from the neighborhood lemon
tree (one lemon maximum per day).
 Lemonade Squeezers: Bob, Barb, and Boris know how to squeeze a single lemon
and make a glass of lemonade from it (one glass maximum per day).
598

fiConcurrent Auctions Across The Supply Chain

 Lemonade Consumers: Chris, Carol, and Cindy want to buy one glass of lemonade
each (per day).
Charlie Brown has obtained a preliminary version of this paper and has built his Internet
systems accordingly, using the Symmetric Protocol suggested here. Charlie Brown has
created three communicating electronic markets: A lemon market through which Alice,
Anna, and Abe will sell lemons. A squeezing market in which Bob, Barb, and Boris will
oer their squeezing services, and a juice market in which Chris , Carol, and Cindy can buy
lemonade.
In the rst day of operations each of the participants logged into his or her market and
entered a bid: Alice was asking for $3 in order to pick a lemon, while Ann wanted $6, and
Abe (who was living farthest from the tree) wanted $7. Bob, Barb, and Boris were asking
for, respectively, $1, $3, and $6 in order to squeeze a lemon, while Chris, Carol, and Cindy,
were willing to pay, respectively, $12, $11, and $7 for their glass of lemonade. Figure 1
presents the three markets, the supply curves in the lemon market (S L ) and the squeezing
market (S LJ ), and the demand curve in the juice market (DJ ). Knowing that the auction
works such that his optimal bidding strategy is to report his true value or cost, each agent
reports truthfully. Let us follow the operation of the system and see how it manages to reach
socially ecient allocation and decide how many lemons should be picked to be squeezed
into lemonade.
Lemon Market
Supply Demand
(S L )
(DL )
3
6
7

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
1
3
6

Juice Market
Supply Demand
(S J )
(DJ )
12
11
7

Figure 1: The Supply Chain bids
In the rst stage, the markets send information to each other in two phases. In the
rst phase, the lemon market aggregates the supply curve for lemons, S L , and sends this
information to the squeezing market. The squeezing market aggregates the supply curve
for squeezing services, S LJ , adds this vector, point-wise, to S L , and sends the sum to
the juice market. For the juice market, this sum represents the supply curve for juice, S J ,
aggregated over the complete supply chain. As can be seen in Figure 2, the cost of the rst
glass of lemonade is $4, since the rst lemon cost is $3 and the squeezing operation cost is
$1.
In the second phase, the juice market sends the demand curve for juice, DJ to the
squeezing market, which subtracts from it, point wise, the supply curve for squeezing services, sending the dierence vector to the lemon market, where this is interpreted as the
demand curve for lemons, DL , aggregated over the complete supply chain. As can be seen
in Figure 3, the demand for the rst lemon is $11, since the rst glass of lemonade has a
demand of $12 but the squeezing operation cost is $1.
The net demand curve for squeezing services, DLJ can now be calculated by the
squeezing market to be DJ  S L . As can be seen in Figure 4, the demand for the rst
599

fiBabaioff & Nisan

Lemon Market
Supply Demand
(S L )
(DL )
3
6
7

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
1
3
6
SL

Juice Market
Supply Demand
(S J )
(DJ )
4
12
9
11
13
7

S L +S LJ





Figure 2: The Supply Chain after supply graphs propagation
Lemon Market
Supply Demand
(S L )
(DL )
3
11
6
8
7
1

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
1
3
6

D J S LJ

Juice Market
Supply Demand
(S J )
(DJ )
4
12
9
11
13
7
DJ





Figure 3: The Supply Chain after demand graphs propogation
squeezing operation is $9 since the rst glass of lemonade has a demand of $12 but the rst
lemon has a cost of $3. This means that if the lowest cost of squeezing operation is less
than $9, at least one glass of lemonade can be manufactured.
Lemon Market
Supply Demand
(S L )
(DL )
3
11
6
8
7
1

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
1
9
3
5
6
0

Juice Market
Supply Demand
(S J )
(DJ )
4
12
9
11
13
7

Figure 4: The Supply Chain after constructing the supply and demand graphs
At this point all three markets have both a supply curve and a demand curve, and each
market can conduct a double auction.
Being an Internet startup, Charlie Brown has decided to subsidize the trade in his
markets, ignoring the sections of this paper that aim to eliminate any budget decit of the
markets. In each market he thus uses the VCG (Vickrey, 1961; Clarke, 1971; Groves, 1973)
double auction rule1 , derived from the Vickrey, Clarke and Groves general auction scheme.
The VCG double auction picks the highest value allocation in each market, so the winners
are the agents in the socially ecient allocation. The ecient allocation in each market
includes the two highest value (lowest cost) bidders, since each of the two trades has a
positive gain, and the third trade has a negative gain. The VCG double auction charges
1. A formal denition of the VCG double auction rule appears in Section 4

600

fiConcurrent Auctions Across The Supply Chain

each consumer (demand side) the minimal value the agent must bid in order to be in the
ecient allocation. Similarly, each supplier (supply side) receives a payment that equals
the maximal cost it may bid and still be in the ecient allocation. The payment takes into
account both the competition with other agents of the same class and competitiveness of
the bid with respect to bids of agents of the other classes. With that payment scheme, the
best strategy of each agent is to bid truthfully. In the lemon market, two lemons are sold
(by Alice and Ann) for $7 = min($7, $8) each (in order to win, each must bid a cost lower
than the cost of Abe, the rst non-winning lemon supplier, which is $7. Each must also bid
a cost lower than $8, otherwise the cost of her lemon will be too high to match the lowest
demand for a lemon). In the squeezing market, two squeezing contracts are awarded (to
Bob and Barb) for $5 = min($6, $5) each (since if one bids a cost higher than $5, there
will be no demand for his squeezing operation, and the squeezing operation cost of Boris
is $6, which is higher than $5). In the juice market, the VCG rule awards two glasses of
lemonade (to Chris and Carol) for the price of $9 = max($7, $9) each (since they must bid
at least $9 to match the supply of juice, and if they do, they also defeat Cindy).
Charlie Brown is thrilled: the dierent markets have all reached the same allocation
amount, 2, which, he has veried is indeed the social optimum: Societys net gains from
trade in his system are (12 + 11)  (1 + 3)  (3 + 6) = $10, which cant be beaten. Charlie
Browns investors are somewhat worried by the fact that the system subsidized every glass
of lemonade by $3 (= 7 + 5  9), but Charlie Brown assures them that changing the doubleauction rules to one of the other double auction rules suggested in this paper can lead to
a budget balance or even surplus, while maintaining high social gain. The nine trading
partners have evaluated carefully the operation of this chain of markets and have assured
themselves that they are best served by always bidding their true cost structure.

3. IC Mechanisms for Single-Minded Agents
Section 3.1 presents an abstract model for agents that partition the set of outcomes to two,
the case they win and the case they loss. Each agent has some valuation for the case he
wins, and this valuation is represented by a single parameter. The double auction model
and the supply chain model we consider are special cases of this model. The main theorem
in this section presents necessary and sucient conditions for incentive compatibility in this
abstract model. Mualem and Nisan (2002) have presented this theorem in the context of
combinatorial auction with agents that desire one specic bundle that is publicly known
(the Known Single Minded Model). The theorem is derived from a more general result for
agents with private bundles (the Single Minded Model), proved by Lehmann, OCallaghan,
and Shoham (2002). Similar result for a dierent general model with one-parameter agents
by Archer and Tardos (2001) appears in the Computer Science literature. For completeness,
we present the results that are relevant to our single-minded agents model.
In section 3.2 we farther restrict the model of the single-minded agents to the case of
sets of agents that can replace each other, and characterize non-discriminating mechanisms
for that case.
601

fiBabaioff & Nisan

3.1 General Model
In the Single-Minded agents model, there is a nite set of agents N and a set of outcomes
O. For each agent i  N , O is partitioned to two disjoint sets OiW and OiL , the outcomes
in which he Wins and the outcomes in which he Loses, respectively (this partition is public
knowledge). For any i there is an ordered set of values space Vi for the case he wins. Agent
i has a private value vi  Vi for any o  OiW (he wins) and a value of 0 for o  OiL
(he loses). The private values are the only private information, all other information is
publicly known to all participants and to the mechanism (and it is known that the rest of
the information is public). For technical reasons we assume that for any vi1 , vi2  Vi , such
that vi1 > vi2 , there exist vi3  Vi such that vi1 > vi3 > vi2 (For example Vi can be the set of
Real numbers or Rational numbers). When agent i wins and pays pi he has a quasi-linear
utility ui = vi  pi , and in normalized mechanisms he pays 0 and has 0 utility if he loses. We
assume that agents are self-interested and try to maximize their utility. Under this model,
an outcome o  O has a one-to-one mapping to a set of winners and is called an allocation

A, A = {i  N |o  OiW }. We say thatthe allocation A is ecient if iA vi is maximized.
vi
The eciency of the allocation A is iA v , where A is an ecient allocation. Let V be
iA i



the set of possible values of the agents, V = iN Vi . We work with mechanisms in which
agents are required to report their values, and the mechanism decides the allocation and
the payments to the agents in a deterministic way. The reported value bi  Vi of agent i is
called the bid of the agent and might be dierent from his private value vi . Let b  V be
the bids of all agents. An allocation rule R decides the allocation according to the reported
values b  V , R is a function R : V  O. A payment rule P decides the payment pi of agent
i, P is a function P : V  RN . A mechanism M denes an allocation and a payment rule,

M = (R, P ). Mechanism M is Budget Balanced (BB) if i pi  0 for any bids b  V . M is
Incentive-Compatible (IC) in dominant strategies if for any agent i, bidding vi maximizes
is utility over all possible bids of the other agents. M is normalized if losing agents have
a payment (and utility) of 0. M is (ex-post) Individually Rational (IR) if for any agent i
and value vi , there is a bid bi such that when he bids bi , ui  0 for all possible bids of the
other agents. Note that any normalized and incentive-compatible mechanism is individually
rational (since truthful bidding ensures a non negative utility).
Below we present necessary and sucient conditions for a mechanism to be incentive
compatible in dominant strategies under the single-minded agents model. These conditions
will later be used to prove properties of our double auctions and supply chain mechanisms
created by our protocols.
For bids b  V we denote b = (bi , bi ) where bi is the bids of all agents but i.
Denition 1. Allocation rule R is Bid Monotonic if for any bids b  V , any agent i and
any two possible bids of i, bi > bi , if i is in the allocation R(bi , bi ) then he is also in the
allocation R(bi , bi ).
A bid monotonic allocation rule ensures that no winning agent becomes a loser by
improving his bid. The following observation is a direct result from the above denition.
Observation 3.1. Let R be a bid monotonic allocation rule, let b  V be a set of bids of
the agents and let i be any agent with a bid bi .
602

fiConcurrent Auctions Across The Supply Chain

If there exists a bid bi for i such that i is in the allocation R(bi , bi ), then there exists
a critical value Ci such that i wins if he bids bi > Ci and i loses if he bids bi < Ci (Ci is
independent of the bid bi )2 .
Note that if the bid is equal to the critical value, the observation does not say if the
agent wins or not.
Lemma 3.2. Let M be a normalized and IC mechanism with allocation rule R. Then R is
Bid Monotonic.
Proof. Assume in contradiction that the auction is normalized and IC (thus also IR) but
the allocation is not bid monotonic. Then there exists an agent i and two values bH > bL ,
such that i wins the auction and pays PL if he bids bL , and loses the auction and pays zero
if he bids bH . The mechanism is IR therefore bL  PL  0. If is true value is bH he can
gain by misreporting his private value: if he reports his true value he loses the auction and
has utility zero, but if he bids bL he wins the auction and pays PL . In this case his utility
is bH  PL > bL  PL  0 in contradiction to the assumption that the auction is IC.
Theorem 3.3. A normalized mechanism M with allocation rule R is IC if and only if R
is Bid Monotonic and each trading agent i pays his critical value Ci (pi = Ci ).
Proof. Case if: Assume that M is normalized, R is bid monotonic and agent i with value vi
pays Ci if he wins. We rst show that the auction is IR, we show that i receives non-negative
utility from bidding truthfully. If i loses, he pays zero and has zero utility. If i wins the
auction by bidding truthfully, then by Observation 3.1, vi  Ci = pi , hence his utility is
vi  pi = vi  Ci  0.
To prove IC we prove that i cannot improve his utility by misreporting his value. Consider the case in which agent i wins the auction by bidding his true value vi . If i bids
untruthfully and loses, then he gets zero utility, which by IR cannot be better than his
utility with a truthful bid. If i bids untruthfully and wins the auction, then since he still
pays his critical value Ci his utility remains the same.
Now consider the case in which i loses the auction by bidding truthfully. His utility is
zero and vi  Ci by Observation 3.1. If i bids untruthfully and loses, his utility remains
zero. If i bids untruthfully and wins, his utility is vi  Ci  0. In both cases, we have shown
that an agent cannot improve his utility by bidding untruthfully, thus proving that M is
IC.
Case only if: Assume that the auction is normalized and IC (thus also IR). By Lemma 3.2
its allocation rule is bid monotonic, so we need to prove that each agent i with value vi
must pay his critical value Ci . Assume that pi = Ci for some agent i. If pi > Ci , then
if pi > vi > Ci and i bids truthfully, then by Observation 3.1 i wins but his utility is
vi  pi < 0 which contradicts individual rationality. If pi < Ci , then if pi < vi < Ci by
Observation 3.1 i loses and has zero utility if he bids truthfully. If i misreports his value
by bidding bi > Ci , he would win the auction and has utility vi  pi > 0 which contradicts
incentive compatibility.
So for normalized and IC mechanisms, the allocation rule which is bid monotonic
uniquely denes the critical values for all the agents and thus the payments.
2. Ci =  if i always wins

603

fiBabaioff & Nisan

Observation 3.4. Let M 1 and M 2 be two normalized and IC mechanisms with the same
allocation rule. Then M 1 and M 2 must have the same payment rule, which means that M 1
and M 2 are the same mechanisms.
3.2 Non-Discriminating Mechanisms
We are interested in the subclass of mechanisms for single-minded agents which do not
discriminate between agents that have the same roll in the outcome. These are agents
that can always replace each other.
Denition 2. Agent i has the same class as agent j, if for every allocation A such that
i  A and j 
/ A, the allocation A = A \ {i}  {j} is also in O, and for every allocation A
such that i 
/ A and j  A, the allocation A = A \ {j}  {i} is also in O.
Note that the class of an agent is an equivalence class.
Denition 3. Let M be a mechanism, T be any class of agents and i, j be two agents of
class T . M is non-discriminating by identity if for any bids b  V , if i wins when he bids
bi and bj > bi then j also wins.
M has non-discriminating pricing if for any bids b  V and every class T there is a
value pT , such that if agent i of class T has a bid bi and bi > pT then i wins and pays pT .
M is non-discriminating (ND) if it is non-discriminating by identity and has nondiscriminating pricing.
Non-discriminating mechanisms are also called Envy-Free mechanisms by Goldberg and
Hartline (2003), since no loser envies any winner for the fact that he won the auction or for
the price he paid. In this paper we only consider mechanisms that are non-discriminating
by identity, which means that agents of the same class are picked by their bid order, from
high to low. Also note that if M is IR and has non-discriminating pricing then any agent
of class T that bids below pT must lose the auction (otherwise he has a negative utility
contradicting IR).
The following observation is a direct result of Theorem 3.3.
Observation 3.5. Let normalized mechanism M be IC and ND. Let pT be the payment of
winners of class T . Then the critical value for all winning agents of class T is pT .
For normalized, IC and ND mechanisms, we prove that the payment of winners of the
same class are independent of their bids.
Lemma 3.6. Let normalized M be an IC and ND mechanism. For every agent class T , if
agent j of class T wins and pays pT when he bids bj > pT and a winning agent i of class T
bids bi  pT , then j also wins and pays pT if i bids bi > bi .
Proof. Since M is normalized and IC, then by Theorem 3.3 it is bid monotonic and by
Observation 3.5 pT is the critical value for i and j. By Observation 3.1 pT is independent
of the bid bi , so i must pay pT if he bids bi > bi . Since M is non-discriminating, j must
also win (since bj > pT ) and pay pT .
604

fiConcurrent Auctions Across The Supply Chain

4. Incentive Compatible Double Auctions
Each of the markets along our supply chain performs a double auction (for a study of
double auctions see Friedman & Rust, 1991). Our protocols for supply chains can work
with a wide variety of double auction rules, and in this section we present several double
auction rules that were suggested in the literature, and two new randomized double auction
rules that we later use to create supply chain mechanisms. A double auction rule decides
the trading agents and the payments to the agents.
We rst give a description of the Double Auction (DA) model. It is a single-minded
agents model with the following specications of possible outcomes, value spaces and classes
of agents. There is some homogeneous good g that is traded in discrete quantities, and
agents that are of one of two classes of agents. An agent is either a seller or a buyer of one
unit of a good g. Seller i has a single unit of g and has some non-negative cost si (vi = si )
if he sells his unit. Buyer i has a non-negative value bi (vi = bi ) if he receives one unit of
good g. The set of possible allocations are the set of materially balanced allocations, which
are allocations with the same number of sellers and buyers.
A DA begins by agents reporting their values for one unit of the good. Each seller i
reports a cost Si which might be dierent from his real cost si . Each buyer i reports a value
Bi which might be dierent from his real value bi . All DA rules are non-discriminating by
identity, so they rst construct the supply and demand curves by sorting the supply bids
s.t. S1  S2  . . . and the demand bids s.t. B1  B2  . . .. If agents report truthfully then
in order to maximize eciency, once the trade quantity q is set, the trading agents must
be the rst q sellers and the rst q buyers. The optimal trade quantity l is dened to be
maximal such that Bl  Sl . Trading l units maximizes the eciency if the agents bids are
the agents true values. In all double auctions we consider non-trading agents pay zero.
After setting the trade quantity to the optimal trade quantity, most real markets proceed
by choosing a market clearing price anywhere in [Sl , Bl ]. For example setting the price
at (Bl + Sl )/2  the 1/2-Double Auction which is a special case of The k-Double
Auction (Wilson, 1985; Chatterjee & Samuelson, 1983; Satterthwaite & Williams, 1989).
In general, the k-Double Auction is a double auction in which before the auction begins,
a parameter k is chosen such that k  [0, 1]. k is used to calculate a clearing price P =
k  Sl + (1  k)  Bl . l units of the good are traded at the uniform price of P for both sellers
and buyers. This pricing scheme is not incentive compatible (in dominant strategies), but
with additional strong assumptions on the agents values (all from a known distribution),
it has been shown to perform reasonably well in many cases under strategic behavior of
the participants (Rustichini, Satterthwaite, & Williams, 1994; Satterthwaite & Williams,
1991). Nevertheless, even when assuming a uniform distribution of the agents values, there
is a non zero eciency loss in the Bayesian Nash equilibrium achieved (and this equilibrium
concept is much weaker than the dominant strategies equilibrium we discuss in this paper).
One may alternatively use The VCG Double Auction rule, which also sets the trade
quantity to the optimal trade quantity l. This rule is non-discriminating, l winning buyers
pay pB = max(Sl , Bl+1 ) and l winning sellers receive pS = min(Sl+1 , Bl ). VCG mechanisms
(Vickrey, 1961; Clarke, 1971; Groves, 1973) in general, and the VCG DA mechanism as a
special case, are all IR and IC. Incentive compatibility leads to maximal eciency since
the trade is of the optimal size l, but it also leads to a budget decit since pB  pS . By
605

fiBabaioff & Nisan

Observation 3.4 any normalized, IC and ecient mechanism must have the same payments
as the VCG DA and thus the mechanism is not budget-balanced.
Myerson and Satterthwaite (1983) have shown that as long as individual rationality or
participation constraints are met (e.g. if non-traders pay 0), an incentive compatible
mechanism that always achieves the ecient outcome lead to a budget decit (even for
more general model and weaker solution concept that we consider). We now turn to look
at several normalized and IC double auction rules that achieve budget balance (sometimes
even surplus) at the price of achieving slightly sub-optimal eciency (by reducing the trade
quantity).
The simplest auction with this property is The Trade Reduction (TR) DA. In this
non-discriminating auction, l  1 units of the good are traded. Each trading buyer pays
pB = Bl , and each trading seller receives pS = Sl . Since Bl  Sl this auction is BB. A
rule which is an extension of the Trade Reduction DA rule, was previously suggested by
S
+B
McAfee (1992). By McAfees DA rule, if a suggested clearing price p = l+1 2 l+1 is
accepted by the l buyer and seller (p  [Sl , Bl ]) then l units of the good are traded at the
price of p, otherwise the TR rule is used. Both the Trade Reduction DA rule and McAfees
rule are normalized, bid monotonic and the payments are by the critical values, thus they
are IC (and IR) by applying Theorem 3.3. Both rules have eciency of at least (l  1)/l
for any agents values, since only the unit with the lowest trade value might not be traded.
McAfees rule turned out not to be compatible with our protocols  we expand on this in
appendix A.
We suggest two new normalized and randomized double auctions, which capture the
tradeo between the auction eciency and the budget balance with one parameter . Unlike
McAfees rule, these rules can be used with our supply-chain protocols, and they achieve
higher eciency than the Trade Reduction DA in expectation. For a carefully chosen
parameter  they also achieve exact budget balance (zero balance) on expectation (Ex ante
Budget-Balanced).
In The  Reduction DA, for a xed 0    1, the bids are submitted and then
with probability  the Trade Reduction DA rule is used, and with probability 1   the
VCG DA rule is used. This randomized double auction is universally incentive compatible
(dened by Nisan & Ronen, 1999), which means that the agents bid truthfully even if they
know the randomization result. This can be seen from the fact that bidding truthfully is a
dominant strategy in both the Trade Reduction DA rule and the VCG DA rule. It is also
normalized and ND since both Trade Reduction DA and VCG DA are normalized and ND.
The  Payment DA is another randomized double auction which has the same distribution of the allocation as the former auction (and therefore the same expected eciency),
but the payment of each agent is his expected payment of The  Reduction DA (so the
expected budget of both auctions is the same). In this auction, a parameter  is chosen as
in the  Reduction DA. Then the bids are submitted and the allocation and payments are
decided. l  1 units are traded between buyers, each paying   Bl + (1  )  max(Bl+1 , Sl ),
and the sellers, each receiving   Sl + (1  )  min(Sl+1 , Bl ). With probability  another
unit of the good is traded between the l buyer which pays max(Bl+1 , Sl ) and the l seller
which receives min(Sl+1 , Bl ). This auction is discriminating since the l buyer pays a dierent price than the rest of the winning buyers if he wins the auction (and the same holds for
the sellers). The  Payment DA has a much lower variance in most of the agents payments
606

fiConcurrent Auctions Across The Supply Chain

than the  Reduction DA, and it hides its randomized character from almost all the
agents. The allocation and payment of all agents but the l buyer and seller are independent
of the coin toss, thus have zero variance. This auction is individually rational and incentive
compatible; but not universally.
Theorem 4.1. The  Payment DA is an incentive compatible randomized DA, but it is
not a universally incentive compatible randomized DA.
Proof. Since the  Reduction DA is universally incentive compatible, truth telling maximizes the expected utility of any agent in the  Reduction DA. The  Payment DA has
the same probability distributions of the allocation and payments as the  Reduction DA,
therefore truth telling maximizes the expected utility of any agent in the  Payment DA as
well.
The  Payment DA is not a universally incentive compatible randomized DA. Assume
that a seller which is one of the rst l  1 sellers knows that the randomization will result
in a VCG allocation, so he is now facing a deterministic auction. By Observation 3.4 there
is a unique payment rule which ensures dominant strategy IC for normalized mechanism
with the ecient allocation (the VCG allocation), this is the VCG payment rule. The 
Payment DA is normalized and gives a dierent payment to that agent, therefore it cannot
be incentive compatible in dominant strategies.
Both auctions have eciency of at least (l  1)/l, since at least l  1 of the l units
are traded. As  grows from zero to one, the expected revenue increases from negative to
positive and the expected eciency decreases (linearly). If the distribution D of the agents
values is known prior to the beginning of the auction, the parameter  = (D) can be
chosen such that the expected revenue is zero (dierent distributions have dierent values
of (D), in this paper we do not solve the problem of nding (D) analytically). We denote
this value as  (D). For the uniform distribution of agents values in [0, 1] we denote this
value as a .
In Table 1 we present a summary of the properties of the double auction rules.
DA rule
k-DA
VCG
Trade Reduction
 (D) Reduction
 (D) P ayment
McAfee

Incentive compatible
no
yes
yes
yes, universally
yes, not universally
yes

Revenue
0
decit
surplus
0 (expected)
0 (expected)
surplus

eciency loss
0
0
LFT
 (D) LF T (expected)
 (D) LF T (expected)
not more than LFT

Table 1: Double Auction Rules comparison table
Notes : a) in the k-DA we assume that the agents bid truthfully, if they do not, there is a non zero eciency
loss in equilibrium. b) LFT means Least Favorable Trade which is Bl  Sl .

We have run simulations comparing the dierent DA rules with respect to the market


revenue ( i pi ) and to the total social eciency ( iA vi ). In Figures 5 and 6 we show
the results for the average of 100 random executions of an auction with a given number of
607

fiBabaioff & Nisan

buyers and sellers, with all values drawn uniformly and independently at random in [0, 1].
We have calculated the  Reduction DA eciency to revenue ratios for   {0.25, 0.5, 0.75}.
Note that in expectation, the same results would have been obtained for the  Payment
DA, since it has the same expected eciency and revenue as the  Reduction DA. We
have calculated a =  (U ) (where U is the uniform distribution of agents values in [0, 1])
by simulations using binary search. Note that in both gures, the values of the Trade
Reduction DA, the dierent  Reduction DA, the VCG DA as well as the a Reduction
DA, all lay on a linear curve. The point representing McAfees DA lays above this line
and in both simulations has lower eciency than the a Reduction DA. Our a Reduction
DA extracts more eciency than McAfees DA, while still being budget balanced. The
simulations also show that in the symmetric case where the number of buyers and sellers is
the same, all auctions extract a very high fraction of the eciency (more than 99%). On
the other hand in the asymmetric case where the number of buyers is much larger than the
number of sellers, the Trade Reduction DA as well as McAfees DA extract a signicantly
lower eciency than the a Reduction DA (about 5% less).
0.7

0.6

0.5

0.4

Revenue

0.3

0.2

0.1
VCG
Trade Reduction

0

0.25 Reduction
0.5 Reduction

0.1

0.75 Reduction
McAfee

0.2

a*
0.3
6.06

6.07

6.08

6.09
6.1
Social Efficiency

6.11

6.12

6.13

6.14

Figure 5: 25 buyers and 25 sellers
Revenue/Eciency tradeo simulations results

5. The Supply Chain Protocols
We begin by presenting the linear supply chain model, in which any unit of an initial good
can be converted to a unit of the nal good through a sequence of unit to unit conversions.
Our supply chain model is a single-minded agents model with the following specications of
possible outcomes, value spaces and classes of agents. There is an ordered set G (|G| = t)
of homogeneous goods that are traded in discrete quantities. Each agent i is of one of the
following t + 1 classes. An initial supplier can supply one unit of the rst good and has a
608

fiConcurrent Auctions Across The Supply Chain

0.7

0.6

0.5

Revenue

0.4

0.3

0.2

VCG
Trade Reduction

0.1

0.25 Reduction
0.5 Reduction
0.75 Reduction

0

McAfee
a*

0.1
2.1

2.15

2.2
Social Efficiency

2.25

2.3

2.35

Figure 6: 50 buyers and 5 sellers
Revenue/Eciency tradeo simulations results

non-negative cost si (vi = si ) if he trades. A converter of one unit of good r  {1, . . . , t1}
to one unit of good r + 1 has a non-negative cost si (vi = si ) if he converts a unit. A
consumer has a non-negative value bi (vi = bi ) if he receives one unit of the nal good. A
market is the set of agents of the same class. The allocation A is materially balanced if for
each good, the number of units produced is the same as the number of units consumed. This
means that the number of winners of any class of agents is the same. Clearly the number
of winners in any market cannot exceed the minimal number of bidders in any market n,
so we can assume that all markets have only n bidders (n can be found by a single message
between any market and the next market. The message includes the minimal size seen so
far. The consumer market then sends n backwards in the chain to all other markets).
We suggest two protocols that can be used to conduct an auction in a chain of markets
in a distributed manner: The Symmetric Protocol and The Pivot Protocol. Both
protocols run on servers connected by a network with a linear chain topology. Each server
represents one market and receives bids from only one class of agents (suppliers, consumers
or converters from some specied good to the next good in the chain). The servers do not
act strategically, and follow the specied protocols (they are all owned by the same entity).
We denote the supply market as M 1 and each conversion market from a good r to the
following good r + 1 as M rr+1 . The consumer (demand) market is marked by M t . Each
of the conversion markets is connected with bi-directional communication channels to the
market that supplies its input good and to the market which demands its output good.
We denote the supply and demand curves for a good r as S r and Dr respectively, and the
supply and demand curves for the conversion of a good r to a good r + 1 as S rr+1 and
D rr+1 respectively.
609

fiBabaioff & Nisan

All agents must bid before some xed deadline. The input to our protocols is the supply
bids for the rst good, the conversion bids for all the conversion markets and the demand
bids for the nal good. The protocols decide the allocation and the payments of the trading
agents (the protocols are normalized, losing agents pay zero). Both our protocols are generic
and can operate with various normalized DA rules.
In the Symmetric Protocol, each of the markets conducts a double auction, after constructing its demand and supply curves. Each agent views the supply chain auction as a
double auction since each market conducts a double auction and there is no central market that makes the allocation and payments decisions. In order for the protocol to create
a materially balanced allocation, some restriction are imposed on the double auction rule
used by the Symmetric Protocol, as we later describe. This protocol can use either a discriminating or a non-discriminating DA rule. We present the protocol as using an abstract
discriminating DA rule that takes supply and demand curves as inputs, and returns the
trade quantity q and two price vectors, PS for the sellers and PB for the buyers.
In the Pivot Protocol, only one market (the demand market) constructs its demand
and supply curves, this market applies the double auction allocation and payments rule,
and sends the results of the auction to it predecessor. Each market uses the information
it receives and the bids in the market to send its predecessor information that are used to
calculate its allocation and payments. Unlike the Symmetric Protocol, the Pivot Protocol
must use a non-discriminating DA rule, but it creates a materially balanced allocation with
any DA rule. For many DA rules, this protocol can be improved such that it has a much
lower communication burden than the Symmetric Protocol, as we show in Section 5.3. We
present the protocol as using an abstract non-discriminating double auction rule that takes
supply and demand curves as inputs, and returns the trade quantity q and a single price
PS for the trading sellers and another price PB for the trading buyers.
5.1 The Symmetric Protocol
As we have seen in the example in Section 2, after the bids are submitted the Symmetric
Protocol begins with supply curve propagation along the supply chain, from the supply
market to the consumer market. The protocol continues with demand curve propagation
along the supply chain in the other way (demand curves propagation may be done concurrently with the supply curves propagation). During this process each of the markets builds
its supply and demand curves from the information it receives. At this point each of the
markets has its supply and demand curves, and a double auction is conducted. If the rule
is randomized, we assume that the random coins are public, which means that all markets
have access to the same random coins (a public coin is created by one market tossing the
coin and then propagating the result to all other markets along the supply chain). The formal protocol for the supply market M 1 , the conversion markets M rr+1 and the demand
market M t are described in Figures 7, 8 and 9, respectively.
A DA rule decides on the trade size in each market according to the supply and demand
curves created by the protocol. The allocation is materially balanced only in the case that
the same trade size was decided in all the markets.
Denition 4. Let S(M ) and D(M ) be the supply and demand curves created by the Symmetric Protocol in market M . Let q(M ) be the trade size obtained by applying the DA rule
610

fiConcurrent Auctions Across The Supply Chain

Symmetric Protocol for the Supply Market M 1 .
1. S 1  sort the list of supply bids in non-decreasing order.
2. Send S 1 to demand market M 12 .
3. Receive D1 from demand market M 12 .
4. Apply the DA Rule on (S 1 , D1 ) to obtain (q, PS , PB ).
5. Output: The q lowest bidders sell a unit each and pay by the vector PS .

Figure 7: Symmetric Protocol for the Supply Market

Symmetric Protocol for a Conversion Market M rr+1
1. S rr+1  sort the list of supply bids in non-decreasing order.
2. When receiving S r from M r1r ,
send S r+1 = S r + S rr+1 to M r+1r+2 .
3. When receiving Dr+1 from M r+1r+2 ,
send Dr = Dr+1  S rr+1 to M r1r .
4. Construct the market demand curve Drr+1 = Dr+1  S r .
5. Apply the DA Rule on (S rr+1 , Drr+1 ) to obtain (q, PS , PB ).
6. Output: The q lowest bidders convert a unit each and pay by the vector PS .

Figure 8: Symmetric Protocol for a Conversion Market

Symmetric Protocol for the Demand Market M t
1. Dt  sort the list of demand bids in non-increasing order.
2. Send Dt to supply market M t1t .
3. Receive S t from supply market M t1t .
4. Apply the DA Rule on (S t , Dt ) to obtain (q, PS , PB ).
5. Output: The q highest bidders buy a unit each and pay by the vector PB .

Figure 9: Symmetric Protocol for the Demand Market

611

fiBabaioff & Nisan

R on (S(M ), D(M )). A DA rule R is called consistent if q(M 1) = q(M 2) for any two
markets M 1 and M 2.
The following Lemma shows that the optimal trade size in all markets is the same, so
any rule that set the trade size as function of the optimal trade size is consistent.
Lemma 5.1. Let l(M ) be the optimal trade size in market M . For any two markets M 1
and M 2, l(M 1) = l(M 2). We denote this optimal trade size by l.
Proof. By the denition of the optimal trade size, l(M ) is the maximal index such that
Bl(M ) (M )  Sl(M ) (M ). It is enough to show that for any two markets M 1 and M 2,
B(M 1)  S(M 1) = B(M 2)  S(M 2) (as vectors).
For any r:

mm+1 )  S r  S rr+1 =
D rr+1  S rr+1 = (Dr+1  S r )  S rr+1 = (Dt  t1
m=r+1 S

mm+1 ) = D t  S t
D t  (S r + S rr+1 + t1
m=r+1 S
Similar argument shows that D1  S 1 = Dt  S t
We conclude that if the trade size qM decided by DA rule R in any market M is just
a function of the optimal trade size lM = l, then R is consistent. Clearly a consistent DA
rule always creates a materially balanced allocation.
Since the trade size decided by the VCG DA rule is l, then this rule is consistent.
Similarly the Trade Reduction DA rule is consistent since the trade size is l  1. Not all
double auction rules are consistent, McAfees DA is an example for an inconsistent rule (a
specic example of inconsistency is presented in appendix A). The intuitive reason that it
is not consistent is because the trade size is dependent on the comparison between some
function of the l + 1 bids and the l bids, which might be dierent between markets. On the
other hand our two new randomized DA, the  Reduction DA and the  Payment DA are
consistent. This is because all markets share a public coin, so either the trade size is l  1
in all the markets, or it is l in all the markets.
Following is the main theorem regarding the Symmetric Protocol.
Theorem 5.2. Any normalized DA rule R that is consistent can be used by the Symmetric
Protocol to create a supply chain mechanism that is normalized and materially balanced. If
R is also IC then the mechanism created by the Symmetric Protocol is IC (thus also IR) and
its eciency is the eciency of R. If R is also non-discriminating, then the mechanism is
also non-discriminating.
Proof. Since R is consistent the allocation is materially balanced by denition. The payments are normalized by denition, we show that if R is IC then the mechanism is also IC.
By Theorem 3.3 the DA rule R is bid monotonic and the payments are by critical values.
For any agent, the supply and demand curves (disregarding his bid) are independent of his
bid by the way they are built by the protocol. So the mechanism is bid monotonic and
the payments are by critical values (from the agent point of view, he submits his bid to
a DA), therefore by the other direction of Theorem 3.3 the supply chain mechanism is IC
(and IR). By IC and the way that costs are aggregated by the protocol, the eciency of
the mechanism is the same as the eciency of R. If the R is non-discriminating, then the
payments of all the winning agents in the any market are the same, so the mechanism is
non-discriminating.
612

fiConcurrent Auctions Across The Supply Chain

Note that the same normalized, IC and consistent DA rule must be used in all the
markets for the mechanism to be materially balanced, normalized and IC. The DA rule is
just a function of the supply and demand curves in the market. If any two of the supplier
and conversion markets get the same supply bids, they also get the same demand curves
so for consistency both must have the same allocation. Since both are normalized and IC
by Observation 3.4 both must also have the same payment rule. The demand market must
have the same DA rule as the supply market, since in the case that all converters have
a zero cost, both markets have the same supply and demand curves. Applying the same
argument presented above to these markets, proves that they must have the same DA rule.
5.2 The Pivot Protocol
The Pivot Protocol is a supply chain protocol that creates a normalized materially balanced
supply chain mechanism from any non-discriminating normalized double auction rule. If the
DA rule is also incentive compatible then the protocol creates an incentive compatible supply
chain mechanism. Unlike the Symmetric Protocol, the Pivot Protocol is not restricted to
using consistent double auction rules, so in that sense it is less restricted than the Symmetric
Protocol. On the other hand, unlike the Symmetric Protocol it is restricted to use nondiscriminating double auction rules. The use of randomized double auctions is also more
natural in the Pivot Protocol, since only one market (the Pivot market) uses the random
coins and there is no need for public coins created by distribution of the random coins of
one market to all other markets.
Before dening the Pivot Protocol formally, we explain its execution on the Lemonadestand industry example of Section 2. As in the Symmetric Protocol, the protocol begins
with supply curve propagation along the supply chain to the juice market (see Figure 2).
Figure 10 presents the information propagation of the Pivot Protocol after the supply curve
propagation stage, and is explained below.
Lemon Market
Supply Demand
(S L )
(DL )
3
6
8
7

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
1
3
5
6

(V,q)=(8,2)

Juice Market
Supply Demand
(S J )
(DJ )
4
12
9
11
13
7

(V,q)=(11,2)





Figure 10: The Pivot Protocol for the Lemonade-stand industry
Unlike in the Symmetric Protocol, the demand curve is not propagated backwards,
but rather, the juice market, which has its supply and demand curves at that stage, now
conducts a non-discriminating double auction. For example, running the VCG double
auction results with ecient trade of size 2 in the juice market. This trade size is propagated
to all other markets and is set to be the trade size in each market along the supply chain,
ensuring a materially balanced allocation (the trade size is denoted by q in Figure 10). The
VCG DA rule charges the two winning consumers in the juice market for $9 = max($9, $7)
613

fiBabaioff & Nisan

each (since they must bid at least $9 to match the supply of juice, and if they do, they also
defeat Cindy, the losing consumer). There is no single agent that has a juice supplier role in
the juice market, rather, a juice supplier is an aggregation of a lemon picker and a juice
squeezer. We use the price that the double auction would have charged a supplier in the
juice market to nd the prices for lemon pickers and juice squeezers. Each market sends to it
predecessor in the chain the highest price the winning agents are willing to pay for one unit
of the input good. A supplier in the juice market should be paid $11 = min($13, $11),
the maximal cost a winning supplier can charge for juice. So, $11 is the highest cost for
juice, and the juice market informs the squeezing market that the trade size is 2 and that
the price of juice should not exceed $11 (V in the gure marks this propagated value). The
squeezing market informs the lemon market that the trade size is 2 and that the price in
the lemon market should be at most $8 = $11  $3, since the highest cost of a winner in the
squeezing market is $3. The price in the squeezing market cannot exceed $5 = $11  $6,
since the price of juice cannot exceed $11 and the cost of lemon for a winning lemon picker
might be as high as $6. Also, the price in the squeezing market cannot exceed $6, the cost
of the loser in that market, so the price is set to $5 = min($6, $5). The price in the lemon
market is set to $7 = min($7, $8), since the price cannot exceed $7, the cost of the loser in
that market, which is lower than the propagated maximal cost of $8.
Note that when we use the VCG double auction rule, the Lemonade-stand industry
allocation and payments of the Pivot Protocol are exactly the same as the allocation and
payments of the Symmetric Protocol presented in Section 2. We later show (Theorem 5.5)
that this is a general phenomena which happens for any normalized DA incentive compatible
rule that can be used by both protocols, that is, a DA rule that is non-discriminating and
consistent (if the DA rule is inconsistent, like the McAfees DA rule, the allocation created
by the Symmetric Protocol is not materially balanced. If on the other hand the rule is
discriminating, it cannot be used by the Pivot Protocol since there are dierent maximal
unit costs for dierent winning agents in the same market).
We now turn to the general denition of the Pivot Protocol. In the Pivot Protocol, one
of the markets is chosen as a pivot and the double auction is only held there. Any market
may be chosen as a pivot; we describe the case where the pivot is the consumer market.
After all bids are submitted, the protocol begins with supply curves propagation along the
supply chain as in the Symmetric Protocol. At this point the consumer market has its
supply and demand curves, and a non-discriminating double auction is conducted in this
market. The DA sets the trade size, the price the mechanism charges the consumers, and
the highest cost of a unit of the good (suppliers price), which is sent to the predecessor
market of the consumer market. After that, starting with the consumer market which is
now viewed as the demand market of its predecessor, each of the demand markets sends to
its supply market the size of trade and the highest price that the demand market is willing
to pay for one unit of its input good, without reducing the trade quantity. The payment in
each market is set to the maximal cost in each market that results with the same trade size,
and is calculated as the minimum of two terms. The rst term is the dierence between the
propagated maximal cost of the market output and the maximal cost of the market input.
The second term is the highest cost of a loser in that market. We show below that this
payment scheme creates a normalized, incentive compatible and non-discriminating supply
614

fiConcurrent Auctions Across The Supply Chain

Pivot Protocol for Pivot Market M t
1. Dt  sort the list of demand bids in non-increasing order.
2. Receive S t from supply market M t1t .
3. apply DA Rule on (S t , Dt ) to obtain (q, PS , PB ).
// Send results to the other markets:
4. Send (PS , q) to market M t1t .
5. Output: The q highest bidders buy for price PB .

Figure 11: The Pivot Protocol for Pivot Market
Pivot Protocol for a Conversion Market M rr+1
1. S rr+1  sort the list of supply bids in non-decreasing order.
2. When receiving S r from M r1r ,
send S r+1 = S r + S rr+1 to M r+1r+2 .
3. When receiving the pair (V, q) from M r+1r+2 ,
send (V  Sqrr+1 , q) to M r1r .

rr+1
4. Output: The q lowest bidders sell for price min(V  Sqr , Sq+1
).

Figure 12: Pivot Protocol for a Conversion Market
chain mechanism, given a normalized, incentive compatible and non-discriminating double
auction rule.
The formal protocol for the pivot market, the conversion markets and the supply market
are presented in Figures 11, 12 and 13, respectively.
The following theorem shows how the properties of the mechanism created by the Pivot
Protocol are derived from the properties of the DA rule used by the pivot market.
Theorem 5.3. Any normalized DA rule R that is non-discriminating can be used by the
Pivot Protocol to create a normalized supply chain mechanism that is materially balanced
and non-discriminating. If R is also IC then the mechanism created by the Pivot Protocol
is IC (thus also IR) and its eciency is the eciency of R.
Pivot Protocol for the Supply Market M 1
1.
2.
3.
4.

S 1  sort the list of supply bids in non-decreasing order.
Send S 1 to demand market M 12 .
Receive the pair (V, q) from the demand market M 12 .
1
).
Output: The q lowest bidders sell for price min(V, Sq+1

Figure 13: Pivot Protocol for the Supply Market
615

fiBabaioff & Nisan

Proof. From the protocol denition the mechanism is materially balanced, normalized and
non-discriminating. Assume that the DA rule is normalized and IC. Then, since by the
protocol denition the supply curve in the pivot market is independent of the bids of the
consumers, the mechanism is normalized and IC for the consumers. We prove that it is
IC for initial suppliers, the proof for the converters is similar (so it will be omitted), and
we conclude that the mechanism is normalized and IC (thus also IR). We show that the
mechanism is bid monotonic and the payments are by critical values, thus by Theorem 3.3
the mechanism is IC.
Assume supplier i bids Si1 and wins. Assume the trade size is q (q  i since i wins) and
PS is the price to the sellers in the pivot market. The allocation is bid monotonic since
if he bids a lower cost he is still one of the q lowest bidding suppliers and his bid change
can only reduce the cost of the q lowest bidding sellers in the pivot market. By applying
Lemma 3.6 on the DA rule, PS remains the same, and is corresponding seller bid is still
lower than PS so he remains a winner. Let Ci1 be the critical value for supplier i.
By the Pivot Protocol the payment to a winning supplier in the supply market is
p1i

= min(PS 

t1


1
Sqrr+1 , Sq+1
)

r=1

We need to show that Ci1 = p1i to prove that the payments are by critical values. Assume
that i changes his bid to X and he is now the j bid in his market under the new order of
the bids. We show that if X < p1i he wins and if X > p1i he loses (note that here we
consider costs, not values). This means that p1i is the critical value for supplier Si1 to win
the auction.
1
and the supplier is still one of the q highest bidders
 If X < p1i then X < Sq+1
in his market (j  q). By the way the protocol builds the supply curve in the
pivot market, his bid change can only change the q highest sellers bids in the pivot
market. All the q highest sellers bids in the pivot market are still below PS , since

S rr+1 < PS , and even if he is the q bidder by the assumption
originally Sq1 + t1
t1 rr+1 r=1 q
< PS . By Lemma 3.6 applied on the DA rule, PS remains the same
X + r=1 Sq
and since is corresponding seller bid is below PS , the supplier wins the auction. This
proves that Ci1  p1i
1 , then j  q + 1. For him to win when bidding X it must be that
 If X > Sq+1


rr+1
rr+1
1
1
, but then Ci1 > Sq+1
+ t1
which by ND means
Ci > X + t1
r=1 Sj
r=1 Sq+1
that the original q + 1 supplier (which is now the q supplier) must win if i bids X.
By Lemma 3.6 the original q + 1 supplier must also win if i bids Si1 which contradicts
the assumption that the trade size is q when i bids Si1 .



rr+1 and X  S 1
 If X > PS  t1
q+1 then j  q (without loss of generality he
r=1 Sq

rr+1 > P and
is ordered before the q + 1 bid if there is a tie). Since X + t1
S
r=1 Sq

t1 rr+1
1
1
(the original q supplier wins when i bids Si ) we conclude
PS  Sq + r=1 Sq
that X > Sq1 which means that he is now the q bidder (j = q). So his corresponding

rr+1 > P , which is not high enough to win the
seller bid in the DA is X + t1
S
r=1 Sq
DA and therefore the agent loses.

616

fiConcurrent Auctions Across The Supply Chain

We conclude that any agent which wins the auction pays his critical value, and therefore
the auction is IR and IC. By IC and the way that costs are aggregated by the protocol, the
eciency of the mechanism is the same as the eciency of R.
Theorem 5.3 has presented the relationship between incentive compatibility of the DA
rule and the resulting supply chain auction created by the Pivot Protocol. This brings up
the question of whether the budget balance of the DA rule ensures budget balance of the
supply chain mechanism. It turn out not to be so! In appendix A we present an example of
a DA rule (McAfees rule) which has a revenue surplus, but the Pivot Protocol using that
rule creates a mechanism with a revenue decit.
The next theorem gives a condition on the DA rule which is sucient to ensure that the
supply chain mechanism created by the Pivot Protocol is budget-balanced. It also shows
that a DA rule with budget decit creates a mechanism with a decit.
Theorem 5.4. Let R be a normalized DA rule that is IC and non-discriminating. Let M
be the supply chain mechanism created by the Pivot Protocol using the rule R . For any
supply and demand curves, let q be the trade size decided by R, and let PS and PB be the
sellers and buyers prices respectively.
If PB  Sq+1 holds for all supply and demand curves, then M is budget-balanced. If
PB < PS for some supply and demand curves (R has budget decit) then M has budget
decit.
Proof. We rst show that if PB  Sq+1 holds for all supply and demand curves, then
M is budget-balanced. We divide the supply chain allocation to q disjoint procurement
sets. Each set has a single winner from each market. We show that the total payment
from each procurement set is non-negative, therefore the auction is BB. By Theorem 5.3
the mechanism is non-discriminating, so all procurement sets have the same payments.
Let P be the total payments to all agents in a procurement set, except for the consumer.
t
t
 P  PS . If PB  Sq+1
then PB  P , and
Lemma B.1 (see appendix B) shows that Sq+1
we conclude that PB  P  0 and M is BB.
Similarly if for some supply and demand curves R has budget decit, then every procurement set has a decit. If PB < PS for some supply and demand curves, then PB < P
and we conclude that the total payment for each procurement set is PB  P < 0, which
means that M has a budget decit.
Note that for a double auction rule R to be BB, it is sucient that PB  PS . To
prove that the supply chain mechanism is budget balanced, the theorem relies on a stronger
condition that PB  Sq+1 (it is always true that Sq+1  PS as Lemma B.1 shows). While
McAfees DA satises PB  PS , the stronger condition PB  Sq+1 does not always hold,
and indeed the example in Appendix A shows that the supply chain mechanism has a
budget decit in some cases. On the other hand, the Trade Reduction DA rule satises
both constraints since q = l  1 (recall that l is the optimal trade size) and PB = Bq+1 =
Bl  Sl = Sq+1 = PS .
Clearly a DA rule that has budget decit might create a supply chain mechanism with
budget decit if used by the Symmetric Protocol. This is since double auction is a special
case of a supply chain. We were not able to present a parallel sucient condition for the
Symmetric Protocol to ensure a budget-balanced supply chain mechanism. For a case that
617

fiBabaioff & Nisan

a normalized DA rule is incentive compatible, consistent and non-discriminating, the next
theorem proves that the two protocols create the same mechanism, which implies that the
above sucient condition for budget balance holds also for the Symmetric Protocol with
such DA rules.
We now turn to look at the relationship between the two protocols. In case that the
normalized DA rule is consistent and non-discriminating it can be used by both protocols.
The following theorem shows that if the rule is also IC, then the Symmetric Protocol and
the Pivot Protocol create the same mechanism:
Theorem 5.5. Let R be a normalized DA rule that is non-discriminating and consistent.
If R is IC then the mechanism created by the Pivot Protocol using R is the same as the
mechanism created by the Symmetric Protocol using R (for any set of bids, both have the
same allocation and payments). Thus, the eciency and the budget of both mechanisms are
equal.
Proof. Since the supply and demand curves of the demand market M t are built in the same
way, and the DA rule used by the demand market is the same in both protocols, the market
trade sizes decided by the rule are the same in both mechanisms. The Symmetric Protocol
is consistent, therefore the trade sizes in all the markets are the same. Since the mechanism
is non-discriminating, the allocations are the same in all the markets in both protocols. By
Observation 3.4 both mechanisms must have the same payments, since they have the same
allocation.
5.3 Communication Complexity
A naive implementation of a supply chain mechanism as a centralized mechanism would
have required sending (tn) bids to one centralized point (t is the number of goods and n
is the minimal number of agents in any market). Both protocols that we have described
have much lower communication of O(n) prices received and sent to each market (note that
if a bid of a single agent requires k bits, then the prices communicated do not grow too
much and have at most k + t bits). For many interesting DA rules we can further reduce
the communication of each market to only O(log(n)) prices by the improved Pivot Protocol
we present below. Thus, for these DA rules the Pivot Protocol can be implemented for
exponentially larger markets when still using the same bandwidth. For example, we can
use the improved protocol if the size of trade q set by the DA rule can be calculated from
the Optimal Trade Quantity l, and the payments are dependent on the l and l + 1 bids in
the supply and demand curves only (this is the case for all DA rules we have presented).
Theorem 5.6. Let R be a normalized DA rule that is IC and non-discriminating. Assume
that the trade size decided by this rule is a function of the Optimal Trade Size l only, and
the payments can be decided using O(1) prices when knowing l. Then the Pivot Protocol
can be implemented with only O(log(n)) messages sent and received by each market, where
each message contains a single price.
Proof. The Pivot Protocol can be improved by using binary search to nd l and thus sending
only the few values needed from the supply curves, instead of passing entire supply curves
along the chain. The search for l can be preformed by a binary search while sending only
618

fiConcurrent Auctions Across The Supply Chain

O(log(n)) messages between any two consecutive markets. In the improved protocol, rst
S tn is passed to the pivot market, for n which is the minimal number of bids in any market
2
(known to all markets by the protocol explained in the beginning of this section). Then
the pivot market checks if this value is smaller or greater than Dtn and asks for the 3n
4 or
2
the n4 element of the supply curves respectively. The pivot market receives the requested
value and continues in a similar way with the search, until l is found. Then O(1) prices
needed from the supply curve to nd the payments (which are only a function of l by our
assumption) are propagated to the pivot market by its request.
Similar results can be presented for the Symmetric Protocol with the same restrictions
on the DA rule used by the protocol. The Symmetric Protocol is the protocol of choice
when the DA rule is discriminating, but in this case it is more likely that entire supply and
demand curves are needed in order to nd the prices for all winners.
5.4 Global Properties of the Dierent DA Types
In this section we examine the properties of the mechanisms created by the supply chain
protocols using dierent double auction rules.
Chain of VCG Double Auctions is created by running the Symmetric Protocol
using the VCG DA rule. This creates a local VCG double auction in each of the markets.
Since VCG DA rule is IR, IC, consistent and non-discriminating, by Theorem 5.5 the Pivot
Protocol with the VCG DA rule creates the same mechanism.
The following proposition summarizes the properties of the supply chain mechanism
using the VCG double auction rule.
Proposition 5.7. Chain of VCG Double Auctions is IR, IC, non-discriminating, Socially
Ecient and has a revenue decit. (RChain V CG  0)
Proof. Since VCG DA rule is normalized, IC and non-discriminating, by Theorem 5.3 the
mechanism created is IR, IC and non-discriminating. The outcome maximizes the sum
of valuations (Socially Ecient), since agents bid truthfully, the trade size is the Optimal
Trade Size and the highest value bidders in each of the markets are chosen as winners.
By the fact that VCG DA has budget decit and Theorem 5.4 we conclude that the
Chain of VCG DAs has budget decit.
Note that by Observation 3.4 the mechanism created using VCG DA rule is VCG in
the global sense presented by Vickrey, Clarke and Groves (A mechanism that is IR, IC and
ecient).
Chain of Trade Reduction Double Auctions is created by running the Symmetric
Protocol using the Trade Reduction DA Rule. This creates a local Trade Reduction double
auction in each of the markets, and those double auctions are chained. Since the Trade
Reduction DA rule is normalized, IC, consistent and non-discriminating, by Theorem 5.5
the Pivot Protocol with the Trade Reduction DA rule creates the same mechanism.
Proposition 5.8. Chain of Trade Reduction Double Auctions is IR, IC , non-discriminating,
has a revenue surplus of
RChain

T rade Reduction

= (l  1)  (Dlt  Slt )  0
619

fiBabaioff & Nisan

the reduction in the Social Eciency is Dlt  Slt and its eciency is at least (l  1)/l of the
maximal eciency.
Proof. Since the Trade Reduction DA rule is normalized, IC and ND, by Theorem 5.3 the
mechanism created is IR, IC and non-discriminating.
The revenue is the sum of the payments which is
(l  1)  (Dlt 

t1


Slrr+1  Sl1 ) = (l  1)  (Dlt  Slt )

r=1

and it is non-negative since Dlt  Slt by the denition of The Optimal Trade Quantity l.
The reduction in social eciency is Dlt  Slt , since the l unit is not traded, so as in the
Trade Reduction DA the l  1 highest trades out of the optimal l trades are conducted,
giving eciency of at least (l  1)/l.
Chain of  Reduction Double Auctions is created by running the Pivot Protocol
using the  Reduction Rule, which creates a randomized mechanism. This mechanism is
a probability distribution over two mechanisms - the Chain of Trade Reduction DA and
the Chain of VCG DA. The mechanisms are used according to a random variable  that
is one with probability  and zero otherwise. The rst mechanism is chosen if  is one
(with probability ), and the second mechanism is chosen if  is zero (which happens with
probability 1  ).
This auction can also be preformed using the Symmetric Protocol under the public coin
assumption (which can be created by distributing a random coin, tossed by one of the
markets). In this case the random variable  is shared by all the markets, meaning that
either the Trade Reduction rule is used by all the markets, or by non of the markets. This
ensures trade consistency and creates the same mechanism.
Chain of  Reduction Double Auctions achieves the allocation and payments of the
Chain of Trade Reduction DA with probability , and with probability 1   it achieves
the allocation and payments of the Chain of VCG DA.
Proposition 5.9. Chain of  Reduction Double Auctions is an individually rational and
universally incentive compatible randomized mechanism. Its expected revenue is
RChain

 Reduction

=   RChain

T rade Reduction

+ (1  )  RChain

V CG

its eciency is at least (l  1)/l of the maximal eciency. Its expected reduction in the
Social Eciency is   (Dlt  Slt ) when the expectation is over the random choice of .
Proof. The mechanism is individually rational and universally incentive compatible randomized mechanism, since both the Chain of Trade Reduction DAs and the Chain of VCG
DAs are normalized and incentive compatible by Proposition 5.8 and Proposition 5.7.
It is easy to verify that the expected revenue and the reduction in social eciency are
as claimed.
Chain of  Payment Double Auctions is created by running the Symmetric Protocol, and in each market running the  Payment Double Auction, which creates a randomized
620

fiConcurrent Auctions Across The Supply Chain

mechanism (again under the public coin assumption). The mechanism has the same expected revenue and social eciency as The Chain of  Reduction DAs, and each of the
agents has the same probability of winning the auction and the same expected utility as in
The Chain of  Reduction DAs. Note that since the  Payment DA rule is discriminating,
the Pivot Protocol as dened above cannot be used to create a supply chain mechanism.
Proposition 5.10. Chain of  Payment Double Auctions is an individually rational and
incentive compatible randomized mechanism. Its expected revenue and its expected social
eciency is the same as The Chain of  Reduction Double Auctions.
Proof. The Chain of  Payment Double Auctions has the same distribution of the allocation
and payments as The Chain of  Reduction Double Auctions, therefore each agent is facing
the same mechanism in expectation so he bids truthfully. Since the expected payment to
each agent is the same in both mechanisms, the expected revenue is the same. Since the
allocation is the same in both mechanisms, the expected social eciency is the same.
Unfortunately, chaining McAfees Double Auction does not preserve the nice properties
McAfees DA rule has. If we run the Symmetric Protocol using McAfees DA Rule, we
might get an inconsistent trade. On the other hand, if we run the Pivot Protocol using
McAfees DA rule, we have a revenue decit! (See examples in appendix A). However a
weaker claim can be made - this mechanism has revenue at least as high as the chain of
VCG DA, and has eciency at least as high as the chain of Trade Reduction DA.
Chain of McAfees Double Auction is created by running the Pivot Protocol using
McAfees Rule.
Proposition 5.11. Chain of McAfees Double Auction is IR, IC, ND, its revenue is never
smaller than the revenue of the Chain of VCG Double Auction, and its reduction in the
Social Eciency is never greater than the reduction of the Chain of Trade Reduction Double
Auction.
Proof. Chain of McAfees Double Auction is IR, IC and ND by Theorem 5.3 and the fact
that McAfees DA rule is normalized, IC and ND.
The mechanism revenue is never smaller than the revenue of the Chain of VCG Double
Auctions since if there is trade reduction, then there is a revenue surplus by Proposition 5.8,
and we know that Chain of VCG Double Auctions has a revenue decit by Proposition 5.7.
In the case of no trade reduction, the revenue is never smaller than the revenue of the Chain
St

+D t

of VCG Double Auctions, since each winning buyer pays p = PB = PS = l+1 2 l+1 which
t
t
> Dl+1
so
is at least as much as he pays in the VCG mechanism. This is because Sl+1
t
t
t
t
t
Sl+1 > p > Dl+1 and Sl  p and therefore max(Dl+1 , Sl )  p. Each winning seller of
1 , D 1 ) which he receives in the VCG
the supply good, never receives more than min(Sl+1
l
t
t
mechanism. This is since p  min(Sl+1 , Dl ) and he receives
1
,p 
min(Sl+1

t1


1
t
Slrr+1 )  min(Sl+1
, min(Dlt , Sl+1
)

r=1
1
, Dlt 
min(Sl+1

t1


Slrr+1 ) =

r=1
t1


t
Slrr+1 , Sl+1


r=1

t1

r=1

621

1
Slrr+1 ) = min(Sl+1
, Dl1 )

fiBabaioff & Nisan





rr+1
rr+1
t
Where the last equality holds since Dl1 = Dlt  t1
and Sl+1
 t1

r=1 Sl
r=1 Sl

t1
rr+1
t
1
= Sl+1 . A similar argument shows that each winning convert never
Sl+1  r=1 Sl+1
receives more than in the VCG mechanism.
The reduction in the social eciency is never greater than the reduction in the Chain of
Trade Reduction Double Auction, since the trade size is never smaller than the trade size
in this auction, which is the l  1.

Table 2 summarizes the properties of the supply chain mechanisms created by the two
protocols using dierent double auction rules. For normalized mechanisms, if one cares
about incentive compatibility and eciency but not about budget balance, then the VCG
mechanism should be used. If budget balance must be ensured for every execution of an
incentive compatible mechanism, then the Trade Reduction auction is the mechanism of
choice. If one wants the mechanism to be incentive compatible for every execution, but can
settle for expected budget balance instead of ensured one, then higher expected eciency
can be achieved by the  (D) Reduction, assuming the right choice of  (D). Finally, if
the variance in the agents payments is important, then the  (D) P ayment should be used
in order to lower the variance for most agents. This has a cost, since now the mechanism
is not incentive compatible for every execution (universally), but rather, it is incentive
compatible when the agents only care about expected utility. The table also presents the
McAfee supply chain mechanism, to point out the fact that the budget of the supply chain
mechanism might be dierent from the budget of the underlying double auction.
DA rule
VCG
Trade Red.
 (D) Reduction
 (D) P ayment
McAfee

Incentive Comp.
yes
yes
yes, universally
yes, not universally
yes

Revenue
decit
surplus
0 (expected)
0 (expected)
surplus or decit

Eciency loss
0
LFT
 (D) LF T (expected)
 (D) LF T (expected)
not more than LFT

Table 2: Supply Chain Auctions
Notes: a) McAfees rule can not be used by the Symmetric Protocol, the table presents its properties under
the Pivot Protocol. b) LFT (least favorable trade) in the context of supply chain, means the net total utility
of the least favorable item. c) The distribution D is over all agents in the supply chain. d)  (D) P ayment
has a lower variance in the payments than the  (D) Reduction.

When comparing the properties of the chain mechanisms in Table 2 with the properties
of the original double auction rules in Figure 1, one can see the following. The incentive
compatibility and the eciency properties are preserved by the protocols, while achieving
a revenue surplus requires a stronger condition on the DA rule, as we have shown in Theorem 5.4. The consistency property, which enables chaining of the markets by the Symmetric
Protocol, applies to the rst two deterministic rules, and the two randomized rules under
the assumption of common coin toss. It does not exist in McAfees rule since this rule sets
its trade quantity as a function of the bids submitted, in such a way that the trade quantity
can be dierent in two dierent markets. The k-DA is not presented in the table since it is
622

fiConcurrent Auctions Across The Supply Chain

not incentive compatible and therefore it cannot be used by the protocols (the two protocols
create dierent mechanisms with this rule).

6. Discussion and Future Work
In this paper we have presented two distributed protocols that create supply chain mechanisms using double auction rules. Our protocols are generic and can use dierent double
auction rules to create dierent mechanisms. We have characterized the properties of the
supply chain mechanisms which derive from the properties of the underlining double auction
rule. The protocols can use the VCG DA to achieve IR, IC and full eciency with budget
decit. They can also use the Trade Reduction DA to ensure budget balance or surplus
with high eciency. An even higher eciency while maintaining BB in expectation can be
achieved using our two new randomized double auction rules.
Our work concentrated on the simple case of indivisible homogeneous goods, where each
of the agents desires only one good or desires to convert one unit of good to one unit of
another good, and the supply chain has a linear form. Our Pivot Protocol is easily extended
to the case of trees in which each good can be created from one of several goods (but no
good is used to create two dierent goods). For example, we might have a lemon market in
Florida and another lemon market in California, and also separate squeezing markets in both
states, but only one lemonade market. The tree of auctions decides how many lemonade
glasses will be produced, and how many of the glasses will be produced from Florida lemons
and from California lemons. Since the main ideas in this extension are similar to the ones
presented in this paper, we omit the technical details and refer the interested reader to
Babaio (2001) for the details. Babaio (2001) also discusses an extension of the model
to the case that an agent is allowed to bid for multiple units in its market, by bidding the
maximal quantity it is willing to trade and the price per unit.
A paper by Babaio and Walsh (2004) extends our model to the case that each item
is produced from a combination of several items of several dierent goods, but each good
is still produced in exactly one market. They have presented a specic auction (unlike
this work which presents generic protocols for supply chain formation) that is individually
rational, incentive compatible, budget-balanced, yet highly ecient.
Similar results (IR, IC, BB and high eciency) have been presented by Babaio, Nisan,
and Pavlov (2004) to a related model of Spatially Distributed Market. In this model a single
good is traded in a set of independent markets, where shipment between markets is possible
but incurs a publicly known cost (but in their model there are no strategic producers as in
our model).
One interesting challenge is to stay with the unit-to-unit conversion model, but extend
our model to allow a general directed a-cyclic supply chain graph topology. Yet another
important challenge is to extend the model to a case where agents are not single-minded
agents, and can submit exclusive or non exclusive bids in several markets.
623

fiBabaioff & Nisan

Acknowledgments
This research was supported by grants from the Israeli Ministry of Science, the Israeli
Academy of Sciences and the USA-Israel Bi-national Science Foundation. The rst author
(Babaio) was also supported by Yeshaya Horowitz Association.
We thank William Walsh, Daniel Lehmann, Hila Babaio and the anonymous reviewers
for their helpful comments.

Appendix A. Problems with Chaining McAfees Double Auction
The Consistency Problem: The following example of supply chain auction using McAfees
rule shows that not all double auction rules are consistent. Figure 14 shows the supply and
demand curves in the three markets after the supply and demand curves propagation.
Lemon Market
Supply Demand
(S L )
(DL )
10
20
20
10

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
5
15
7
-3

Juice Market
Supply Demand
(S J )
(DJ )
15
25
27
17

Figure 14: Chaining McAfees DA example
The optimal trade quantity in this example is 1, as can be seen in Figure 14. McAfees
= 22  [15, 25]. On the
rule in the Lemonade Market set the trade size to 1, since 27+17
2
other hand, if we use McAfees rule on the Squeezing Market, trade reduction should be
= 2 
/ [5, 15] and the trade quantity is zero, in contradiction to the
made since 7+(3)
2
previous decision. We conclude that there exists a non-consistent DA rule that cannot be
used by the Symmetric Protocol.
The Revenue Problem: The same example with the Pivot Protocol presented in
Figure 15 shows that the fact that the DA rule has revenue surplus, does not ensure that
the supply chain mechanism created by the Pivot Protocol using the DA rule has a revenue
surplus as well.
Lemon Market
Supply Demand
(S L )
(DL )
10
20

Squeezing Market
Supply Demand
(S LJ )
(DLJ )
5
7

(V,q)=(17,1)

Juice Market
Supply Demand
(S J )
(DJ )
15
25
27
17

(V,q)=(22,1)





Figure 15: Pivot Protocol with McAfees rule
In this example, McAfees rule in the Lemonade Market sets the trade size to 1, since
= 22  [15, 25]. The buyer in this market should pay 22. By following the Pivot
Protocol, the squeezer that has a bid of 5 should be paid 7 = min(7, 22  10) and the
27+17
2

624

fiConcurrent Auctions Across The Supply Chain

supplier in the supply market that has a bid of 10 should be paid 17 = min(17, 20). The
total revenue is 22  7  17 = 2 which means that there is a revenue decit.

Appendix B. Supply Chain Payments
In this appendix we prove Lemma B.1 which is used in the proof of Theorem 5.4.
Lemma B.1. If the double auction rule used by the Pivot Protocol is IR, IC and nondiscriminating, and PS is the sellers price in this double auction, then the total payment
P to a supplier and converters (one from each market) which create one unit of the nal
t .
good satises PS  P  Sq+1
Proof. By induction, each conversion market of C m to C m+1 receives the pair (PS 
t1
rr+1 , q) from its demand market, and the payment to a winning converter is
r=m+1 Sq
min(PS 

t1


mm+1
Sqrr+1  Sqm , Sq+1
)

r=m+1

Similarly, the supply market M 1 receives the pair (PS 
ment to a winning supplier is
min(PS 

t1


t1

rr+1 , q),
r=1 Sq

and the pay-

1
Sqrr+1 , Sq+1
)

r=1

We conclude that the total payment to the converters and supplier of one unit is
P =

t1

m=1

min(PS 

t1


mm+1
Sqrr+1  Sqm , Sq+1
) + min(PS 

r=m+1

t1


1
Sqrr+1 , Sq+1
)

r=1

t
since
First notice that P  Sq+1

P 

t1


mm+1
1
t
Sq+1
+ Sq+1
= Sq+1

m=1

Secondly we should prove that PS  P . The idea of the proof is that this holds if there was
only one conversion from C 1 to C t (as we show in Lemma B.2), and by splitting a conversion
to two consecutive conversions, the total payment to all the converters only grows (as we
show in Lemma B.3).
Lemma B.2. Assume that there was only one conversion market from C 1 to C t , which

rr+1
then
means that for every i, Si1t = t1
r=1 Si
1t
1
) + min(PS  Sq1t , Sq+1
)
PS  P = min(PS  Sq1 , Sq+1

Proof. Note that the double auction in the pivot market is the same as in the original
auction, since the supply curve of the pivot market is the same, and therefore PS is the
same.
We prove that this claim is true by checking the four possible cases:
625

fiBabaioff & Nisan

1t and P  S 1t  S 1 , then
1. if PS  Sq1  Sq+1
S
q
q+1

P = (PS  Sq1 ) + (PS  Sq1t ) = PS + (PS  (Sq1 + Sq1t ))  PS
since PS  Sq1 + Sq1t = Sqt , because the DA rule is non-discriminating.
1t and S 1
1t , then
2. if PS  Sq1  Sq+1
q+1  PS  Sq
1
1
= PS + (Sq+1
 Sq1 )  PS
P = (PS  Sq1 ) + Sq+1
1
since Sq+1
 Sq1
1t  P  S 1 and P  S 1t  S 1 , then
3. if Sq+1
S
S
q
q
q+1
1t
1t
+ (PS  Sq1t ) = PS + (Sq+1
 Sq1t )  PS
P = Sq+1
1t  S 1t .
since Sq+1
q
1t  P  S 1 and S 1
1t , then
4. if Sq+1
S
q
q+1  PS  Sq
1t
1
+ Sq+1
 PS
P = Sq+1
1t + S 1
t
since Sq+1
q+1 = Sq+1  PS , because the DA rule is non-discriminating.

So we have proven that P  PS in the case of one conversion market.
Lemma B.3. Assume that a conversion market from C k to C t is split into two conversion
markets - one from C k to C k+1 and the other from C k+1 to C t , then the payment for
conversion of one unit from C k to C t can only grow, which means that
P kt  P kk+1 + P k+1t
where P wz is the cost of conversion of one w unit to one z unit. In other words, it is
always true that
kk+1
k+1t
kt
)  min(PS  Sqk+1t  Sqk , Sq+1
) + min(PS  Sqk+1 , Sq+1
)
min(PS  Sqk , Sq+1

where Sikt =

t1

r=k

Sirr+1

Proof. Note that the double auction in the pivot market is the same as in the original
auction, since the supply curve of the pivot market is the same, and therefore PS is the
same.
We prove that this claim is true by checking the four possible cases:
kk+1
k+1t
and PS  Sqk+1  Sq+1
, then
1. if PS  Sqk+1t  Sqk  Sq+1
kk+1
k+1t
kt
kt
+ Sq+1
= Sq+1
 min(PS  Sqk , Sq+1
) = P kt
P kk+1 + P k+1t = Sq+1

626

fiConcurrent Auctions Across The Supply Chain

kk+1
k+1t
2. if PS  Sqk+1t  Sqk  Sq+1
and PS  Sqk+1  Sq+1
, then
k+1t
=
P kk+1 + P k+1t = (PS  Sqk+1t  Sqk ) + Sq+1
k+1t
(PS  Sqk ) + (Sq+1
 Sqk+1t )  PS  Sqk  P kt
k+1t
since Sq+1
 Sqk+1t .
kk+1
k+1t
3. if PS  Sqk+1t  Sqk  Sq+1
and PS  Sqk+1  Sq+1
, then
kk+1
+ (PS  Sqk+1 ) =
P kk+1 + P k+1t = Sq+1
kk+1
 Sqkk+1 )  (PS  Sqk )  P kt
(PS  Sqk ) + (Sq+1
kk+1
since Sq+1
 Sqkk+1 .
kk+1
k+1t
and PS  Sqk+1  Sq+1
, then
4. if PS  Sqk+1t  Sqk  Sq+1

P kk+1 + P k+1t = (PS  Sqk+1t  Sqk ) + (PS  Sqk+1 ) =
(PS  Sqk ) + (PS  Sqk+1  Sqk+1t )  (PS  Sqk )  P kt
since PS  Sqk+1 + Sqk+1t = Sqt .
So we have proven that the payment can only grow by splitting a conversion market.
We conclude that the cost of one unit of C t is never smaller than PS , since by the
rst lemma, it is true if there was only one conversion, and by induction and the second
lemma, splitting the conversion market into all t  1 conversion markets can only increase
the cost.

References
Archer, A., & Tardos, E. (2001). Truthful mechanisms for one-parameter agents. In Proceedings of the 42nd IEEE symposium on foundations of computer science, pp. 482491.
Babaio, M. (2001).
Concurrent auctions across the supply chain. m.sc. thesis, department of computer science, hebrew university of jerusalem, israel.
http://www.cs.huji.ac.il/mosheb.
Babaio, M., Nisan, N., & Pavlov, E. (2004). Mechanisms for a spatially distributed market.
In 5th ACM Conference on Electronic Commerce, pp. 920.
Babaio, M., & Walsh, W. E. (2004). Incentive-compatible, budget-balanced, yet highly
ecient auctions for supply chain formation. In Decision Support Systems. In press.
Partial version appeared in EC03.
Bosch-Domenech, A., & Sunder, S. (1999). Tracking the invisible hand: Convergence of
double auctions to competitive equilibrium. Tech. rep., Carnegie Mellon University.
627

fiBabaioff & Nisan

Chatterjee, K., & Samuelson, W. (1983). Bargaining under incomplete information. Operations Research, 31, 835851.
Clarke, E. H. (1971). Multipart pricing of public goods. Public Choice, 1733.
Feigenbaum, J., & Shenker, S. (2002). Distributed algorithmic mechanism design: Recent
results and future directions. In 6th International Workshop on Discrete Algorithms
and Methods for Mobile Computing and Communications, pp. 113.
Friedman, D., & Rust, J. (1991). The Double Auction Market Institutions, Theories, and
Evidence. Addison-Wesley Publishing Company.
Goldberg, A. V., & Hartline, J. D. (2003). Envy-free auctions for digital goods. In 4st ACM
Conference on Electronic Commerce, pp. 2935. ACM Press.
Groves, T. (1973). Incentives in teams. Econometrica, 617631.
Lehmann, D. J., OCallaghan, L. I., & Shoham, Y. (2002). Truth revelation in approximately
ecient combinatorial auctions. Journal of the ACM, 49 (5), 577602.
Mas-Collel, A., Whinston, W., & Green, J. (1995). Microeconomic Theory. Oxford university press.
McAfee, R. (1992). A dominant strategy double auction. Journal of Economic Theory, 56,
434450.
Mualem, A., & Nisan, N. (2002). Truthful approximation mechanisms for restricted combinatorial auctions.. In AAAI (poster), 2002. also presented at Dagstuhl workshop on
Electronic Market Design.
Myerson, R. B., & Satterthwaite, M. A. (1983). Ecient mechanisms for bilateral trading.
Journal of Economic Theory, 29, 265281.
Nisan, N., & Ronen, A. (1999). Algorithmic mechanism design. In Proceedings of STOC
1999, pp. 129140.
Osborne, M. J., & Rubinstein, A. (1994). A Course in Game Theory. MIT press.
Parkes, D. C., Kalagnanam, J., & Eso, M. (2001). Achieving budget-balance with vickreybased payment schemes in exchanges. In IJCAI, pp. 11611168.
Rustichini, A., Satterthwaite, M. A., & Williams, S. R. (1994). Convergence to eciency
in a simple market with incomplete information. Econometrica, 62 (5), 10411063.
Satterthwaite, M., & Williams, S. (1989). Bilateral trade with the sealed bid k-double
auction: Existence and eciency. Journal of Economic Theory, 48, 107133.
Satterthwaite, M. A., & Williams, S. R. (1991). The bayesian theory of the k-double auction.
In The Double Auction Market Institutions, Theories, and Evidence, pp. 99124.
Vickrey, W. (1961). Counterspeculation, auctions and competitive sealed tenders. Journal
of Finance, 837.
628

fiConcurrent Auctions Across The Supply Chain

Walsh, W., & Wellman, M. (2003). Decentralized supply chain formation: A market protocol
and competitive equilibrium analysis. Journal of Articial Intelligence Research, 19,
513567.
Walsh, W. E., Wellman, M. P., & Ygge, F. (2000). Combinatorial auctions for supply chain
formation. In 2nd ACM Conference on Electronic Commerce, pp. 260269.
Wilson, R. (1985). Incentive eciency of double auctions. Econometrica, 53, 11011115.

629

fiJournal of Artificial Intelligence Research 21 (2004) 287-317

Submitted 06/03; published 03/04

IDL-Expressions:
A Formalism for Representing and Parsing
Finite Languages in Natural Language Processing
Mark-Jan Nederhof

markjan@let.rug.nl

Faculty of Arts, University of Groningen
P.O. Box 716
NL-9700 AS Groningen, The Netherlands

Giorgio Satta

satta@dei.unipd.it

Dept. of Information Engineering, University of Padua
via Gradenigo, 6/A
I-35131 Padova, Italy

Abstract
We propose a formalism for representation of finite languages, referred to as the class
of IDL-expressions, which combines concepts that were only considered in isolation in
existing formalisms. The suggested applications are in natural language processing, more
specifically in surface natural language generation and in machine translation, where a
sentence is obtained by first generating a large set of candidate sentences, represented in
a compact way, and then filtering such a set through a parser. We study several formal
properties of IDL-expressions and compare this new formalism with more standard ones.
We also present a novel parsing algorithm for IDL-expressions and prove a non-trivial upper
bound on its time complexity.

1. Introduction
In natural language processing, more specifically in applications that involve natural language generation, the task of surface generation consists in the process of generating an output sentence in a target language, on the basis of some input representation of the desired
meaning for the output sentence. During the last decade, a number of new approaches for
natural language surface generation have been put forward, called hybrid approaches. Hybrid approaches make use of symbolic knowledge in combination with statistical techniques
that have recently been developed for natural language processing. Hybrid approaches
therefore share many advantages with statistical methods for natural language processing,
such as high accuracy, wide coverage, robustness, portability and scalability.
Hybrid approaches are typically based on two processing phases, described in what
follows (Knight & Hatzivassiloglou, 1995; Langkilde & Knight, 1998; Bangalore & Rambow,
2000 report examples of applications of this approach in real world generation systems).
In the first phase one generates a large set of candidate sentences by a relatively simple
process. This is done on the basis of an input sentence in some source language in case
the process is embedded within a machine translation system, or more generally on the
basis of some logical/semantic representation, called conceptual structure, which denotes
the meaning that the output sentence should convey. This first phase involves no or only

c
2004
AI Access Foundation. All rights reserved.

fiNederhof & Satta

few intricacies of the target language, and the set of candidate sentences may contain many
that are ungrammatical or that can otherwise be seen as less desirable than others. In the
second phase one or more preferred sentences are selected from the collection of candidates,
exploiting some form of syntactic processing that more heavily relies on properties of the
target language than the first phase. This syntactic processing may involve language models
as simple as bigrams or it may involve more powerful models such as those based on contextfree grammars, which typically perform with higher accuracy on this task (see for instance
work presented by Charniak, 2001 and references therein).
In hybrid approaches, the generation of the candidate set typically involves a symbolic
grammar that has been quickly hand-written, and is quite small and easy to maintain.
Such a grammar cannot therefore account for all of the intricacies of the target language.
For instance, frequency information for synonyms and collocation information in general
is not encoded in the grammar. Similarly, lexico-syntactic and selectional constraints for
the target language might not be fully specified, as is usually the case with small and midsized grammars. Furthermore, there might also be some underspecification stemming from
the input conceptual structure. This is usually the case if the surface generation module
is embedded into a larger architecture for machine translation, and the source language is
underspecified for features such as definiteness, time and number. Since inferring the missing
information from the sentence context is a very difficult task, the surface generation module
usually has to deal with underspecified knowledge.
All of the above-mentioned problems are well-known in the literature on natural language
surface generation, and are usually referred to as lack of knowledge of the system or of the
input. As a consequence of these problems, the set of candidate sentences generated in the
first phase may be extremely large. In real world generation systems, candidate sets have
been reported to contain as many as 1012 sentences (Langkilde, 2000). As already explained,
the second processing phase in hybrid approaches is intended to reduce these huge sets to
subsets containing only a few sentences. This is done by exploiting knowledge about the
target language that was not available in the first phase. This additional knowledge can
often be obtained through automatic extraction from corpora, which requires considerably
less effort than the development of hand-written, purely symbolic systems.
Due to the extremely large size of the set of candidate sentences, the feasibility of hybrid
approaches to surface natural language generation relies on
 the compactness of the representation of a set of candidate sentences that in real world
systems might be as large as 1012 ; and
 the efficiency of syntactic processing of the stored set.
Several solutions have been adopted in existing hybrid systems for the representation
of the set of candidate sentences. These include bags of words (Brown et al., 1990) and
bags of complex lexical representations (Beaven, 1992; Brew, 1992; Whitelock, 1992), word
lattices (Knight & Hatzivassiloglou, 1995; Langkilde & Knight, 1998; Bangalore & Rambow,
2000), and non-recursive context-free grammars (Langkilde, 2000). As will be discussed in
detail in Section 2, word lattices and non-recursive context-free grammars allow encoding
of precedence constraints and choice among different words, but they both lack a primitive
for representing strings that are realized by combining a collection of words in an arbitrary
288

fiIDL-Expressions: A Formalism for Finite Languages

order. On the other hand, bags of words allow the encoding of free word order, but in
such a representation one cannot directly express precedence constraints and choice among
different words.
In this paper we propose a new representation that combines all of the above-mentioned
primitives. This representation consists of IDL-expressions. In the term IDL-expression,
I stands for interleave, which pertains to phrases that may occur interleaved, allowing
freedom on word order (a precise definition of this notion will be provided in the next
section); D stands for disjunction, which allows choices of words or phrases; L stands
for lock, which is used to constrain the application of the interleave operator. We study
some interesting properties of this representation, and argue that the expressivity of the
formalism makes it more suitable than the alternatives discussed above for use within hybrid
architectures for surface natural language generation. We also associate IDL-expressions
with IDL-graphs, an equivalent representation that can be more easily interpreted by a
machine, and develop a dynamic programming algorithm for parsing IDL-graphs using a
context-free grammar. If a set of candidate sentences is represented as an IDL-expression
or IDL-graph, the algorithm can be used to filter out ungrammatical sentences from the
set, or to rank the sentences in the set according to their likelihood, in case the context-free
grammar assigns weights to derivations. While parsing is traditionally defined for input
consisting of a single string, we here conceive parsing as a process that can be carried out
on an input device denoting a language, i.e., a set of strings.
There is a superficial similarity between the problem described above of representing
finite sets in surface generation, and a different research topic, often referred to as discontinuous parsing. In discontinuous parsing one seeks to relax the definition of context-free
grammars in order to represent the syntax of languages that exhibit constructions with uncertainty on word or constituent order (see for instance work reported by Daniels & Meurers,
2002 and references therein). In fact, some of the operators we use in IDL-expressions have
also been exploited in recent work on discontinuous parsing. However, the parsing problem
for discontinuous grammars and the parsing problem for IDL-expressions are quite different: in the former, we are given a grammar with productions that express uncertainty on
constituent order, and need to parse an input string whose symbols are totally ordered; in
the latter problem we are given a grammar with total order on the constituents appearing in each production, and need to parse an input that includes uncertainty on word and
constituent order.
This paper is structured as follows. In Section 2 we give a brief overview of existing
representations of finite languages that have been used in surface generation components.
We then discuss some notational preliminaries in Section 3. In Section 4 we introduce IDLexpressions and define their semantics. In Section 5 we associate with IDL-expressions an
equivalent but more procedural representation, called IDL-graphs. We also introduce the
important notion of cut of an IDL-graph, which will be exploited later by our algorithm.
In Section 6 we briefly discuss the Earley algorithm, a traditional method for parsing a
string using a context-free grammar, and adapt this algorithm to work on finite languages
encoded by IDL-graphs. In Section 7 we prove a non-trivial upper bound on the number
of cuts in an IDL-graph, and on this basis we investigate the computational complexity of
our parsing algorithm. We also address some implementational issues. We conclude with
some discussion in Section 8.
289

fiNederhof & Satta

2. Representations of Finite Languages
In this section we analyze and compare existing representations of finite languages that have
been adopted in surface generation components of natural language systems.
Bags (or multisets) of words have been used in several approaches to surface generation.
They are at the basis of the generation component of the statistical machine translation
models proposed by Brown et al. (1990). Bags of complex lexical signs have also been used
in the machine translation approach described by Beaven (1992) and Whitelock (1992),
called shake-and-bake. As already mentioned, bags are a very succinct representation of
finite languages, since they allow encoding of more than exponentially many strings in the
size of a bag itself. This power comes at a cost, however. Deciding whether some string
encoded by an input bag can be parsed by a CFG is NP-complete (Brew, 1992). It is not
difficult to show that this result still holds in the case of a regular grammar or, equivalently,
a regular expression. An NP-completeness result involving bags has also been presented
by Knight (1999), for a related problem where the parsing grammar is a probabilistic model
based on bigrams.
As far as expressivity is concerned, bags of words have also strict limitations. These
structures lack a primitive for expressing choices among words. As already observed in
the introduction, this is a serious problem in natural language generation, where alternatives in lexical realization must be encoded in the presence of lack of detailed knowledge
of the target language. In addition, bags of words usually do not come with precedence
constraints. However, in natural language applications these constraints are very common,
and are usually derived from knowledge about the target language or, in the case of machine translation, from the parsing tree of the source string. In order to represent these
constraints, extra machinery must be introduced. For instance, Brown et al. (1990) impose,
for each word in the bag, a probabilistic distribution delimiting its position in the target
string, on the basis of the original position of the source word in the input string to be
translated. In the shake and bake approach, bags are defined over functional structures,
each representing complex lexical information from which constraints can be derived. Then
the parsing algorithm for bags is interleaved with a constraint propagation algorithm to
filter out parses (e.g., as done by Brew, 1992). As a general remark, having different layers
of representation requires the development of more involved parsing algorithms, which we
try to avoid in the new proposal to be described below.
An alternative representation of finite languages is the class of acyclic deterministic finite automata, also called word lattices. This representation has often been used in hybrid
approaches to surface generation (Knight & Hatzivassiloglou, 1995; Langkilde & Knight,
1998; Bangalore & Rambow, 2000), and more generally in natural language applications
where some form of uncertainty comes with the input, as for instance in speech recognition (Jurafsky & Martin, 2000, Section 7.4). Word lattices inherit from standard regular
expressions the primitives expressing concatenation and disjunction, and thereby allow the
encoding of precedence constraints and word disjunction in a direct way. Furthermore, word
lattices can be efficiently parsed by means of CFGs, using standard techniques for lattice
parsing (Aust, Oerder, Seide, & Steinbiss, 1995). Lattice parsing requires cubic time in
the number of states of the input finite automaton and linear time in the size of the CFG.
Methods for lattice parsing can all be traced back to Bar-Hillel, Perles, and Shamir (1964),

290

fiIDL-Expressions: A Formalism for Finite Languages

who prove that the class of context-free languages is closed under intersection with regular
languages.
One limitation of word lattices and finite automata in general is the lack of an operator
for free word order. As we have already discussed in the introduction, this is a severe
limitation for hybrid systems, where free word order in sentence realization is needed in
case the symbolic grammar used in the first phase fails to provide ordering constraints.
To represent strings where a bag of words can occur in every possible order, one has to
encode each string through an individual path within the lattice. In the general case, this
requires an amount of space that is more than exponential in the size of the bag. From
this perspective, the previously mentioned polynomial time result for parsing is to no avail,
since the input structure to the parser might already be of size more than exponential in the
size of the input conceptual structure. The problem of free word order in lattice structures
is partially solved by Langkilde and Knight (1998) by introducing an external recasting
mechanism that preprocesses the input conceptual structure. This has the overall effect
that phrases normally represented by two independent sublattices can now be generated
one embedded into the other, therefore partially mimicking the interleaving of the words in
the two phrases. However, this is not enough to treat free word order in its full generality.
A third representation of finite languages, often found in the literature on compression
theory (Nevill-Manning & Witten, 1997), is the class of non-recursive CFGs. A CFG
is called non-recursive if no nonterminal can be rewritten into a string containing the
nonterminal itself. It is not difficult to see that such grammars can only generate finite
languages. Non-recursive CFGs have recently been exploited in hybrid systems (Langkilde,
2000).1 This representation inherits all the expressivity of word lattices, and thus can
encode precedence constraints as well as disjunctions. In addition, non-recursive CFGs can
achieve much smaller encodings of finite languages than word lattices. This is done by
uniquely encoding certain sets of substrings that occur repeatedly through a nonterminal
that can be reused in several places. This feature turns out to be very useful for natural
language applications, as shown by experimental results reported by Langkilde (2000).
Although non-recursive CFGs can be more compact representations than word lattices,
this representation still lacks a primitive for representing free word order. In fact, a CFG
generating the finite language of all permutations of n symbols must have size at least
exponential in n.2 In addition, the problem of deciding whether some string encoded by
a non-recursive CFG can be parsed by a general CFG is PSPACE-complete (Nederhof &
Satta, 2004).
From the above discussion, one can draw the following conclusions. In considering the
range of possible encodings for finite languages, we are interested in measuring (i) the compactness of the representation, and (ii) the efficiency of parsing the obtained representation
by means of a CFG. At one extreme we have the naive solution of enumerating all strings
in the language, and then independently parsing each individual string using a traditional
string parsing algorithm. This solution is obviously unfeasible, since no compression at all
is achieved and so the overall amount of time required might be exponential in the size of
1. Langkilde (2000) uses the term forests for non-recursive CFGs, which is a different name for the same
concept (Billot & Lang, 1989).
2. An unpublished proof of this fact has been personally communicated to the authors by Jeffrey Shallit
and Ming-wei Wang.

291

fiNederhof & Satta

the input conceptual structure. Although word lattices are a more compact representation,
when free word order needs to be encoded we may still have representations of exponential
size as input to the parser, as already discussed. At the opposite extreme, we have solutions
like bags of words or non-recursive CFGs, which allow very compact representations, but
are still very demanding in parsing time requirements. Intuitively, this can be explained
by considering that parsing a highly compressed finite language requires additional bookkeeping with respect to the string case. What we then need to explore is some trade-off
between these solutions, offering interesting compression factors at the expense of parsing
time requirements that are provably polynomial in the cases of interest. As we will show in
the sequel of this paper, IDL-expressions have these required properties and are therefore
an interesting solution to the problem.

3. Notation
In this section we briefly recall some basic notions from formal language theory. For more
details we refer the reader to standard textbooks (e.g., Harrison, 1978).
For a set , || denotes the number of elements in ; for a string x over some alphabet,
|x| denotes the length of x. For string x and languages (sets of strings) L and L0 , we let
x  L = {xy | y  L} and L  L0 = {xy | x  L, y  L0 }. We remind the reader that
a string-valued function f over some alphabet  can be extended to a homomorphism
over   by letting f () =  and f (ax) = f (a)f (x) for a   and x    . We also let
f (L) = {f (x) | x  L}.
We denote a context-free grammar (CFG) by a 4-tuple G = (N , , P, S), where N is a
finite set of nonterminals,  is a finite set of terminals, with   N = , S  N is a special
symbol called the start symbol, and P is a finite set of productions having the form A  ,
with A  N and   (  N ) . Throughout the paper we assume the following conventions:
A, B, C denote nonterminals, a, b, c denote terminals, , , ,  denote strings in (  N )
and x, y, z denote strings in   .
The derives relation is denoted G and its transitive closure +
G . The language generated by grammar G is denoted L(G). The size of G is defined as
X
|G| =
|A| .
(1)
(A)P

4. IDL-Expressions
In this section we introduce the class of IDL-expressions and define a mapping from such
expressions to sets of strings. Similarly to regular expressions, IDL-expressions generate sets
of strings, i.e., languages. However, these languages are always finite. Therefore the class of
languages generated by IDL-expressions is a proper subset of the class of regular languages.
As already discussed in the introduction, IDL-expressions combine language operators that
were only considered in isolation in previous representations of finite languages exploited
in surface natural language generation. In addition, some of these operations have been
recently used in the discontinuous parsing literature, for the syntactic description of (infinite) languages with weak linear precedence constraints. IDL-expressions represent choices
among words or phrases and their relative ordering by means of the standard concatenation
292

fiIDL-Expressions: A Formalism for Finite Languages

operator  from regular expressions, along with three additional operators to be discussed
in what follows. All these operators take as arguments one or more IDL-expressions, and
combine the strings generated by these arguments in different ways.
 Operator k, called interleave, interleaves strings resulting from its argument expressions. A string z results from the interleaving of two strings x and y whenever z
is composed of all and only the occurrences of symbols in x and y, and these symbols
appear within z in the same relative order as within x and y. As an example, consider strings abcd and efg. By interleaving these two strings we obtain, among many
others, the strings abecfgd, eabfgcd and efabcdg. In the formal language literature, this operation has also been called shuffle, as for instance by Dassow and Paun
(1989). In the discontinuous parsing literature and in the literature on head-driven
phrase-structure grammars (HPSG, Pollard & Sag, 1994) the interleave operation is
also called sequence union (Reape, 1989) or domain union (Reape, 1994). The
interleave operator also occurs in an XML tool described by van der Vlist (2003).
 Operator , called disjunction, allows a choice between strings resulting from its
argument expressions. This is a standard operator from regular expressions, where it
is more commonly written as +.
 Operator , called lock, takes a single IDL-expression as argument. This operator
states that no additional material can be interleaved with a string resulting from its
argument. The lock operator has been previously used in the discontinuous parsing
literature, as for instance by Daniels and Meurers (2002), Gotz and Penn (1997),
Ramsay (1999), Suhre (1999). In that context, the operator was called isolation.
The interleave, disjunction and lock operators will also be called I, D and L operators,
respectively. As we will see later, the combination of the I and L operators within IDLexpressions provides much of the power of existing formalisms to represent free word order,
while maintaining computational properties quite close to those of regular expressions or
finite automata.
As an introductory example, we discuss the following IDL-expression, defined over the
word alphabet {piano, play, must, necessarily, we}.
k((necessarily, must), we  (play  piano)).

(2)

IDL-expression (2) says that words we, play and piano must appear in that order in any
of the generated strings, as specified by the two occurrences of the concatenation operator.
Furthermore, the use of the lock operator states that no additional words can ever appear
in between play and piano. The disjunction operator expresses the choice between words
necessarily and must. Finally, the interleave operator states that the word resulting from
the first of its arguments must be inserted into the sequence we, play, piano, in any of the
available positions. Notice the interaction with the lock operator, which, as we have seen,
makes unavailable the position in between play and piano. Thus the following sentences,
among others, can be generated by IDL-expression (2):

293

fiNederhof & Satta

necessarily we play piano
must we play piano
we must play piano
we play piano necessarily.
However, the following sentences cannot be generated by IDL-expression (2):
we play necessarily piano
necessarily must we play piano.
The first sentence is disallowed through the use of the lock operator, and the second sentence
is impossible because the disjunction operator states that exactly one of the arguments must
appear in the sentence realization. We now provide a formal definition of the class of IDLexpressions.
Definition 1 Let  be some finite alphabet and let E be a symbol not in . An IDLexpression over  is a string  satisfying one of the following conditions:
(i)  = a, with a    {E};
(ii)  = ( 0 ), with  0 an IDL-expression;
(iii)  = (1 , 2 , . . . , n ), with n  2 and i an IDL-expression for each i, 1  i  n;
(iv)  = k(1 , 2 , . . . , n ), with n  2 and i an IDL-expression for each i, 1  i  n;
(v)  = 1  2 , with 1 and 2 both IDL-expressions.
We take the infix operator  to be right associative, although in all of the definitions in
this paper, disambiguation of associativity is not relevant and can be taken arbitrarily. We
say that IDL-expression  0 is a subexpression of  if  0 appears as an argument of some
operator in .
We now develop a precise semantics for IDL-expressions. The only technical difficulty
in doing so arises with the proper treatment of the lock operator.3 Let x be a string over
. The basic idea below is to use a new symbol , not already in . An occurrence of 
between two terminals indicates that an additional string can be inserted at that position.
As an example, if x = x0  x00 x000 with x0 , x00 and x000 strings over , and if we need to
interleave x with a string y, then we may get as a result string x0 yx00 x000 but not string
x0  x00 yx000 . The lock operator corresponds to the removal of every occurrence of  from a
string.
More precisely, strings in (  {}) will be used to represent sequences of strings over
; symbol  is used to separate the strings in the sequence. Furthermore, we introduce a
string homomorphism lock over (  {}) by letting lock(a) = a for a   and lock() = .
An application of lock to an input sequence can be seen as the operation of concatenating
together all of the strings in the sequence.
3. If we were to add the Kleene star, then infinite languages can be specified, and interleave and lock can be
more conveniently defined using derivatives (Brzozowski, 1964), as noted before by van der Vlist (2003).

294

fiIDL-Expressions: A Formalism for Finite Languages

We can now define the basic operation comb, which plays an important role in the sequel.
This operation composes two sequences x and y of strings, represented as explained above,
into a set of new sequences of strings. This is done by interleaving the two input sequences
in every possible way. Operation comb makes use of an auxiliary operation comb0 , which
also constructs interleaved sequences out of input sequences x and y, but always starting
with the first string in its first argument x. As any sequence in comb(x, y) must start with a
string from x or with a string from y, comb(x, y) is the union of comb0 (x, y) and comb0 (y, x).
In the definition of comb0 , we distinguish the case in which x consists of a single string and
the case in which x consists of at least two strings. In the latter case, the tail of an output
sequence can be obtained by applying comb recursively on the tail of sequence x and the
complete sequence y. For x, y  (  {}) , we have:
comb(x, y) = comb0 (x, y)  comb0 (y, x)

{x  y}, if x    ;



{x0 }  comb(x00 , y),
comb0 (x, y) =
if there are x0    and x00



such that x = x0  x00 .
As an example, let  = {a, b, c, d, e} and consider the two sequences a  bb  c and d  e.
Then we have
comb(a  bb  c, d  e) =
{a  bb  c  d  e, a  bb  d  c  e, a  bb  d  e  c,
a  d  bb  c  e, a  d  bb  e  c, a  d  e  bb  c,
d  a  bb  c  e, d  a  bb  e  c, d  a  e  bb  c,
d  e  a  bb  c}.
For languages L1 , L2 we define comb(L1 , L2 ) = xL1 ,yL2 comb(x, y). More generally, for
languages L1 , L2 , . . . , Ld , d  2, we define combdi=1 Li = comb(L1 , L2 ) for d = 2, and
combdi=1 Li = comb(combd1
i=1 Li , Ld ) for d > 2.
Definition 2 Let  be some finite alphabet. Let  be a function mapping IDL-expressions
over  into subsets of (  {}) , specified by the following conditions:
(i) (a) = {a} for a  , and (E) = {};
(ii) (()) = lock(());
(iii) ((1 , 2 , . . . , n )) = ni=1 (i );
(iv) (k(1 , 2 , . . . , n )) = combni=1 (i );
(v) (   0 ) = ()  ( 0 ).
The set of strings that satisfy an IDL-expression , written L(), is given by L() =
lock(()).

295

fiNederhof & Satta

As an example for the above definition, we show how the interleave operator can be
used in an IDL-expression to denote the set of all strings realizing permutations of a given
bag of symbols. Let  = {a, b, c}. Consider a bag ha, a, b, c, ci and IDL-expression
k(a, a, b, c, c).

(3)

By applying Definition 2 to IDL-expression (3), we obtain in the first few steps
(a) = {a},
(b) = {b},
(c) = {c},
(k(a, a)) = comb({a}, {a}) = {a  a},
(k(a, a, b)) = comb({a  a}, {b}) = {b  a  a, a  b  a, a  a  b}.
In the next step we obtain 3  4 sequences of length 4, each using all the symbols from
bag ha, a, b, ci. One more application of the comb operator, on this set and set {c}, provides all possible sequences of singleton strings expressing permutations of symbols in bag
ha, a, b, c, ci. After removing symbol  throughout, which conceptually turns sequences of
strings into undivided strings, we obtain the desired language L(k(a, a, b, c, c)) of permutations of bag ha, a, b, c, ci.
To conclude this section, we compare the expressivity of IDL-expressions with that of
the formalisms discussed in Section 2. We do this by means of a simple example. In
what follows, we use the alphabet {NP, PP, V}. These symbols denote units standardly
used in syntactic analysis of natural language, and stand for, respectively, noun phrase,
prepositional phrase and verb. Symbols NP, PP and V should be rewritten into actual words
of the language, but we use these as terminal symbols to simplify the presentation. Consider
a language having the subject-verb-object (SVO) order and a sentence having the structure
[S NP1 V NP2 ],
where NP1 realizes the subject position and NP2 realizes the object position. Let PP1 and
PP2 be phrases that must be inserted in the above sentence as modifiers. Assume that we
know that the language at hand does not allow modifiers to appear in between the verbal
and the object positions. Then we are left with 3 available positions for the realization
of a first modifier, out of the 4 positions in our string. After the first modifier is inserted
within the string, we have 5 positions, but only 4 are available for the realization of a second
modifier, because of our assumption. This results in a total of 3  4 = 12 possible sentence
realizations.
A bag of words for these sentences is unable to capture the above constraint on the
positioning of modifiers. At the same time, a word lattice for these sentences would contain
12 distinct paths, corresponding to the different realizations of the modifiers in the basic
sentence. Using the IDL formalism, we can easily capture the desired realizations by means
of the IDL-expression:
k(PP1 , PP2 , NP1  (V  NP2 )).

296

fiIDL-Expressions: A Formalism for Finite Languages

Again, note the presence of the lock operator, which implements our restriction against
modifiers appearing in between the verbal and the object position, similarly to what we
have done in IDL-expression (2).
Consider now a sentence with a subordinate clause, having the structure
[S NP1 V1 NP2 [S0 NP3 V2 NP4 ]],
and assume that modifiers PP1 and PP2 apply to the main clause, while modifiers PP3 and
PP4 apply to the subordinate clause. As before, we have 3  4 possible realizations for the
subordinate sentence. If we allow main clause modifiers to appear in positions before the
subordinate clause as well as after the subordinate clause, we have 45 possible realizations
for the main sentence. Overall, this gives a total of 3  42  5 = 240 possible sentence
realizations.
Again, a bag representation for these sentences is unable to capture the above restrictions on word order, and would therefore badly overgenerate. Since the main sentence
modifiers could be placed after the subordinate clause, we need to record for each of the
two modifiers of the main clause whether it has already been seen, while processing the 12
possible realizations of the subordinate clause. This increases the size of the representation
by a factor of 2  2 = 4. On the other hand, the desired realizations can be easily captured
by means of the IDL-expression:
k(PP1 , PP2 , NP1  (V1  NP2 )  (k(PP3 , PP4 , NP3  (V2  NP4 )))).
Note the use of embedded lock operators (the two rightmost occurrences). The rightmost
and the leftmost occurrences of the lock operator implement our restriction against modifiers appearing in between the verbal and the object position. The occurrence of the lock
operator in the middle of the IDL-expression prevents any of the modifiers PP1 and PP2
from modifying elements appearing within the subordinate clause. Observe that when we
generalize the above examples by embedding n subordinate clauses, the corresponding word
lattice will grow exponentially in n, while the IDL-expression has linear size in n.

5. IDL-Graphs
Although IDL-expressions may be easily composed by linguists, they do not allow a direct
algorithmic interpretation for efficient recognition of strings. We therefore define an equivalent but lower-level representation for IDL-expressions, which we call IDL-graphs. For this
purpose, we exploit a specific kind of edge-labelled acyclic graphs with ranked nodes. We
first introduce our notation, and then define the encoding function from IDL-expressions to
IDL-graphs.
The graphs we use are denoted by tuples (V, E, vs , ve , , r), where:
 V and E are finite sets of vertices and edges, respectively;
 vs and ve are special vertices in V called the start and the end vertices, respectively;
  is the edge-labelling function, mapping E into the alphabet   {, `, a};
 r is the vertex-ranking function, mapping V to N, the set of non-negative integer
numbers.
297

fiNederhof & Satta

Label  indicates that an edge does not consume any input symbols. Edge labels ` and a
have the same meaning, but they additionally encode that we are at the start or end, respectively, of what corresponds to an I operator. More precisely, let  be an IDL-expression
headed by an occurrence of the I operator and let () be the associated IDL-graph. We
use edges labelled by ` to connect the start vertex of () with the start vertices of all the
subgraphs encoding the arguments of I. Similarly, we use edges labelled by a to connect
all the end vertices of the subgraphs encoding the arguments of I with the end vertex of
(). Edge labels ` and a are needed in the next section to distinguish occurrences of the
I operator from occurrences of the D and L operators. Finally, the function r ranks each
vertex according to how deeply it is embedded into (the encoding of) expressions headed
by an occurrence of the L operator. As we will see later, this information is necessary for
processing locked vertices with the correct priority.
We can now map an IDL-expression into the corresponding IDL-graph.
Definition 3 Let  be some finite alphabet, and let j be a non-negative integer number.
Each IDL-expression  over  is associated with some graph j () = (V, E, vs , ve , , r)
specified as follows:
(i) if  = a, a    {E}, let vs , ve be new nodes; we have
(a) V = {vs , ve },
(b) E = {(vs , ve )},
(c) ((vs , ve )) = a for a   and ((vs , ve )) =  for a = E,
(d) r(vs ) = r(ve ) = j;
(ii) if  = ( 0 ) with j+1 ( 0 ) = (V 0 , E 0 , vs0 , ve0 , 0 , r0 ), let vs , ve be new nodes; we have
(a) V = V 0  {vs , ve },
(b) E = E 0  {(vs , vs0 ), (ve0 , ve )},
(c) (e) = 0 (e) for e  E 0 , ((vs , vs0 )) = ((ve0 , ve )) = ,
(d) r(v) = r0 (v) for v  V 0 , r(vs ) = r(ve ) = j;
(iii) if  = (1 , 2 , . . . , n ) with j (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), 1  i  n, let vs , ve be
new nodes; we have
(a) V = ni=1 Vi  {vs , ve },
(b) E = ni=1 Ei  {(vs , vi,s ) | 1  i  n}  {(vi,e , ve ) | 1  i  n},
(c) (e) = i (e) for e  Ei , ((vs , vi,s )) = ((vi,e , ve )) =  for 1  i  n,
(d) r(v) = ri (v) for v  Vi , r(vs ) = r(ve ) = j;
(iv) if  = k(1 , 2 , . . . , n ) with j (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), 1  i  n, let vs , ve be
new nodes; we have
(a) V = ni=1 Vi  {vs , ve },
(b) E = ni=1 Ei  {(vs , vi,s ) | 1  i  n}  {(vi,e , ve ) | 1  i  n},
298

fiIDL-Expressions: A Formalism for Finite Languages

v1



v2

necessarily

0

v0



0

v5



0


v3

vs

v4

must

0

0
ve

0

0

0
v6

we

0

v7

0



v8



0

v9 playv10

1

 v11 pianov12

1

1

Figure 1: The
IDL-graph
associated
with
the
k((necessarily, must), we  (play  piano)).

 v13

1

0

IDL-expression

(c) (e) = i (e) for e  Ei , ((vs , vi,s )) = ` and ((vi,e , ve )) = a for 1  i  n,
(d) r(v) = ri (v) for v  Vi , r(vs ) = r(ve ) = j;
(v) if  = 1 2 with j (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), i  {1, 2}, let vs = v1,s and ve = v2,e ;
we have
(a) V = V1  V2 ,
(b) E = E1  E2  {(v1,e , v2,s )},
(c) (e) = i (e) for e  Ei for i  {1, 2}, ((v1,e , v2,s )) = ,
(d) r(v) = ri (v) for v  Vi , i  {1, 2}.
We let () = 0 (). An IDL-graph is a graph that has the form () for some IDLexpression  over .
Figure 1 presents the IDL-graph (), where  is IDL-expression (2).
We now introduce the important notion of cut of an IDL-graph. This notion is needed
to define the language described by an IDL-graph, so that we can talk about equivalence
between IDL-expressions and IDL-graphs. At the same time, this notion will play a crucial
role in the specification of our parsing algorithm for IDL-graphs in the next section. Let
us fix some IDL-expression  and let () = (V, E, vs , ve , , r) be the associated IDLgraph. Intuitively speaking, a cut through () is a set of vertices that we might reach
simultaneously when traversing () from the start vertex to the end vertex, following the
different branches as prescribed by the encoded I, D and L operators, and in an attempt to
produce a string of L().
In what follows we view V as a finite alphabet, and we define the set V to contain those
strings over V in which each symbol occurs at most once. Therefore V is a finite set and
for each string c  V we have |c|  |V |. If we assume that the outgoing edges of each vertex
in an IDL-graph are linearly ordered, we can represent cuts in a canonical way by means of
strings in V as defined below.
299

fiNederhof & Satta

Let r be the ranking function associated with (). We write c[v1    vm ] to denote a
string c  V satisfying the following conditions:
 c has the form xv1    vm y with x, y  V and vi  V for 1  i  m; and
 for each vertex v within c and for each i, 1  i  m, we have r(v)  r(vi ).
In words, c[v1    vm ] indicates that vertices v1 , . . . , vm occur adjacent in c and have the
maximal rank among all vertices within string c. Let c[v1    vm ] = xv1    vm y be a string
0  V be a second string such that no symbol v 0 , 1  i  m0 ,
defined as above and let v10    vm
0
i
0 ] to denote the string xv 0    v 0 y  V .
appears in x or y. We write c[v1    vm := v10    vm
0
1
m0
The reason we distinguish the vertices with maximal rank from those with lower rank is
that the former correspond with subexpressions that are nested deeper within subexpressions headed by the L operator. As a substring originating within the scope of an occurrence
of the lock operator cannot be interleaved with symbols originating outside that scope, we
should terminate the processing of all vertices with higher rank before resuming processing
of those with lower rank.
We now define a relation that plays a crucial role in the definition of the notion of cut,
as well as in the specification of our parsing algorithm.
Definition 4 Let  be some finite alphabet, let  be an IDL-expression over , and let
() = (V, E, vs , ve , , r) be its associated IDL-graph. The relation ()  V ( {}) V
is the smallest satisfying all of the following conditions:
(i) for each c[v]  V and (v, v 0 )  E with ((v, v 0 )) = X    {}, we have
(c[v], X, c[v := v 0 ])  () ;

(4)

(ii) for each c[v]  V with the outgoing edges of v being exactly (v, v1 ), . . . , (v, vn )  E, in
this order, and with ((v, vi )) = `, 1  i  n, we have
(c[v], , c[v := v1    vn ])  () ;

(5)

(iii) for each c[v1    vn ]  V with the incoming edges of some v  V being exactly
(v1 , v), . . . , (vn , v)  E, in this order, and with ((vi , v)) = a, 1  i  n, we have
(c[v1    vn ], , c[v1    vn := v])  () .

(6)

Henceforth, we will abuse notation by writing  in place of () . Intuitively speaking,
relation  will be used to simulate a one-step move over IDL-graph (). Condition (4)
refers to moves that follow a single edge in the graph, labelled by a symbol from the alphabet
or by the empty string. This move is exploited, e.g., upon visiting a vertex at the start of
a subgraph that encodes an IDL-expression headed by an occurrence of the D operator. In
this case, each outgoing edge represents a possible next move, but at most one edge can be
chosen. Condition (5) refers to moves that simultaneously follow all edges emanating from
the vertex at hand. This is used when processing a vertex at the start of a subgraph that
encodes an IDL-expression headed by an occurrence of the I operator. In fact, in accordance
300

fiIDL-Expressions: A Formalism for Finite Languages

with the given semantics, all possible argument expressions must be evaluated in parallel
by a single computation. Finally, Condition (6) refers to a move that can be read as the
complement of the previous type of move.
Examples of elements in  in the case of Figure 1 are (vs , , v0 v6 ) following
Condition (5) and (v5 v13 , , ve ) following Condition (6), which start and end the
evaluation of the occurrence of the I operator. Other elements are (v0 v6 , , v1 v6 ),
(v1 v9 , play, v1 v10 ) and (v1 v13 , necessarily, v2 v13 ) following Condition (4). Note that, e.g.,
(v1 v10 , necessarily, v2 v10 ) is not an element of  , as v9 has higher rank than v1 .
We are now ready to define the notion of cut.
Definition 5 Let  be some finite alphabet, let  be an IDL-expression over , and let
() = (V, E, vs , ve , , r) be its associated IDL-graph. The set of all cuts of (), written
cut(()), is the smallest subset of V satisfying the following conditions:
(i) string vs belongs to cut(());
(ii) for each c  cut(()) and (c, X, c0 )   , string c0 belongs to cut(()).
Henceforth, we will abuse notation by writing cut() for cut(()). As already remarked,
we can interpret a cut v1 v2    vk  cut(), vi  V for 1  i  k, as follows. In the
attempt to generate a string in L(), we traverse several paths of the IDL-graph (). This
corresponds to the parallel evaluation of some of the subexpressions of , and each vi in
v1 v2    vk refers to one such subexpression. Thus, k provides the number of evaluations that
we are carrying out in parallel at the point of the computation represented by the cut. Note
however that, when drawing a straight line across a planar representation of an IDL-graph,
separating the start vertex from the end vertex, the set of vertices that we can identify is
not necessarily a cut.4 In fact, as we have already explained when discussing relation  ,
only one path is followed at the start of a subgraph that encodes an IDL-expression headed
by an occurrence of the D operator. Furthermore, even if several arcs are to be followed at
the start of a subgraph that encodes an IDL-expression headed by an occurrence of the I
operator, some combinations of vertices will not satisfy the definition of cut when there are
L operators within those argument expressions. These observations will be more precisely
addressed in Section 7, where we will provide a mathematical analysis of the complexity of
our algorithm.
Examples of cuts in the case of Figure 1 are vs , ve , v0 v6 , v1 v6 , v3 v6 , v0 v7 , etc. Strings
such as v1 v3 are not cuts, as v1 and v3 belong to two disjoint subgraphs with sets of vertices
{v1 , v2 } and {v3 , v4 }, respectively, each of which corresponds to a different argument of an
occurrence of the disjunction operator.
Given the notion of cut, we can associate a finite language with each IDL-graph and
talk about equivalence with IDL-expressions. Let  be an IDL-expression over , and let
() = (V, E, vs , ve , , r) be the associated IDL-graph. Let also c, c0  cut() and w    .
We write w  L(c, c0 ) if there exists q  |w|, Xi    {}, 1  i  q, and ci  cut(),
0  i  q, such that X1    Xq = w, c0 = c, cq = c0 and (ci1 , Xi , ci )   for 1  i  q.
4. The pictorial representation mentioned above comes close to a different definition of cut that is standard
in the literature on graph theory and operating research. The reader should be aware that this standard
graph-theoretic notion of cut is different from the one introduced in this paper.

301

fiNederhof & Satta

We also assume that L(c, c) = {}. We can then show that L(vs , ve ) = L(), i.e., the
language generated by the IDL-expression  is the same as the language that we obtain in
a traversal of the IDL-graph (), as described above, starting from cut vs and ending in
cut ve . The proof of this property is rather long and does not add much to the already
provided intuition underlying the definitions in this section; therefore we will omit it.
We close this section with an informal discussion of relation  and the associated notion
of cut. Observe that Definition 4 and Definition 5 implicitly define a nondeterministic finite
automaton. Again, we refer the reader to Harrison (1978) for a definition of finite automata.
The states of the automaton are the cuts in cut() and its transitions are given by the
elements of  . The initial state of the automaton is the cut vs , and the final state is the
cut ve . It is not difficult to see that from every state of the automaton one can always reach
the final state. Furthermore, the language recognized by such an automaton is precisely the
language L(vs , ve ) defined above. However, we remark here that such an automaton will
never be constructed by our parsing algorithm, as emphasized in the next section.

6. CFG Parsing of IDL-Graphs
We start this section with a brief overview of the Earley algorithm (Earley, 1970), a wellknown tabular method for parsing input strings according to a given CFG. We then reformulate the Earley algorithm in order to parse IDL-graphs. As already mentioned in the
introduction, while parsing is traditionally defined for input consisting of a single string, we
here conceive parsing as a process that can be carried out on an input device representing
a language, i.e., a set of strings.
Let G = (N , , P, S) be a CFG, and let w = a1    an    be an input string to be
parsed. Standard implementations of the Earley algorithm (Graham & Harrison, 1976) use
so called parsing items to record partial results of the parsing process on w. A parsing item
has the form [A    , i, j], where A   is a production of G and i and j are indices
identifying a substring ai+1    aj of w. Such a parsing item is constructed by the algorithm
if and only if there exist a string   (N  ) and two derivations in G having the form
S G a1    ai A
G a1    ai ;
 G ai+1    aj .
The algorithm accepts w if and only if it can construct an item of the form [S   , 0, n], for
some production S   of G. Figure 2 provides an abstract specification of the algorithm
expressed as a deduction system, following Shieber, Schabes, and Pereira (1995). Inference
rules specify the types of steps that the algorithm can apply in constructing new items.
Rule (7) in Figure 2 serves as an initialization step, constructing all items that can
start analyses for productions with the start symbol S in the right-hand side. Rule (8)
is very similar in purpose: it constructs all items that can start analyses for productions
with nonterminal B in the left-hand side, provided that B is the next nonterminal in some
existing item for which an analysis is to be found. Rule (9) matches a terminal a in an item
with an input symbol, and the new item signifies that a larger part of the right-hand side
has been matched to a larger part of the input. Finally, Rule (10) combines two partial

302

fiIDL-Expressions: A Formalism for Finite Languages

[S   , 0, 0]



S

(7)

[A    B, i, j] 
B
[B   , j, j]

(8)

[A    a, i, j] 
a = aj+1
[A  a  , i, j + 1]

(9)

[A    B, i, j]
[B   , j, k]
[A  B  , i, k]

(10)

Figure 2: Abstract specification of the parsing algorithm of Earley for an input string
a1    an . The algorithm accepts w if and only if it can construct an item of
the form [S   , 0, n], for some production S   of G.

analyses, the second of which represents an analysis for symbol B, by which the analysis
represented by the first item can be extended.
We can now move to our algorithm for IDL-graph parsing using a CFG. The algorithm
makes use of relation  from Definition 4, but this does not mean that the relation is
fully computed before invoking the algorithm. We instead compute elements of  onthe-fly when we first visit a cut, and cache these elements for possible later use. This has
the advantage that, when parsing an input IDL-graph, our algorithm processes only those
portions of the graph that represent prefixes of strings that are generated by the CFG at
hand. In practical cases, the input IDL-graph is never completely unfolded, so that the
compactness of the proposed representation is preserved to a large extent.
An alternative way of viewing our algorithm is this. We have already informally discussed in Section 5 how relation  implicitly defines a nondeterministic finite automaton
whose states are the elements of cut() and whose transitions are the elements of  . We
have also mentioned that such an automaton precisely recognizes the finite language L().
From this perspective, our algorithm can be seen as a standard lattice parsing algorithm,
discussed in Section 2. What must be emphasized here is that we do not precompute the
above finite automaton prior to parsing. Our approach consists in a lazy evaluation of the
transitions of the automaton, on the basis of a demand on the part of the parsing process.
In contrast with our approach, full expansion of the finite automaton before parsing has
several disadvantages. Firstly, although a finite automaton generating a finite language

303

fiNederhof & Satta

might be considerably smaller than a representation of the language itself consisting of a
list of all its elements, it is easy to see that there are cases in which the finite automaton
might have size exponentially larger than the corresponding IDL-expression (see also the
discussion in Section 2). In such cases, full expansion destroys the compactness of IDLexpressions, which is the main motivation for the use of our formalism in hybrid surface
generation systems, as discussed in the introduction. Furthermore, full expansion of the
automaton is also computationally unattractive, since it may lead to unfolding of parts of
the input IDL-graph that will never be processed by the parsing algorithm.
Let G = (N , , P, S) be a CFG and let  be some input IDL-expression. The algorithm
uses parsing items of the form [A    , c1 , c2 ], with A   a production in P and
c1 , c2  cut(). These items have the same meaning as those used in the original Earley
algorithm, but now they refer to strings in the languages L(vs , c1 ) and L(c1 , c2 ), where vs
is the start vertex of IDL-graph (). (Recall from Section 5 that L(c, c0 ), c, c0  cut(),
is the set of strings whose symbols can be consumed in any traversal of () starting from
cut c and ending in cut c0 .) We also use items of the forms [c1 , c2 ] and [a, c1 , c2 ], a  ,
c1 , c2  cut(). This is done in order to by-pass traversals of () involving a sequence of zero
or more triples of the form (c1 , , c2 )   , followed by a triple of the form (c1 , a, c2 )   .
Figure 3 presents an abstract specification of the algorithm, again using a set of inference
rules. The issues of control flow and implementation are deferred to the next section.
In what follows, let vs and ve be the start and end vertices of IDL-graph (), respectively. Rules (11), (12) and (15) in Figure 3 closely resemble Rules (7), (8) and (10) of the
original Earley algorithm, as reported in Figure 2. Rules (13), (16) and (17) have been introduced for the purpose of efficiently computing traversals of () involving a sequence of zero
or more triples of the form (c1 , , c2 )   , followed by a triple of the form (c1 , a, c2 )   ,
as already mentioned. Once one such traversal has been computed, the fact is recorded
through some item of the form [a, c1 , c2 ], avoiding later recomputation. Rule (14) closely
resembles Rule (9) of the original Earley algorithm. Finally, by computing traversals of
() involving triples of the form (c1 , , c2 )   only, Rule (18) may derive items of the
form [S   , vs , ve ]; the algorithm accepts the input IDL-graph if and only if any such
item can be derived by the inference rules.
We now turn to the discussion of the correctness of the algorithm in Figure 3. Our
algorithm derives a parsing item [A    , c1 , c2 ] if and only if there exist a string
  (N  ) , integers i, j with 0  i  j, and a1 a2    aj    such that the following
conditions are all satisfied:
 a1    ai  L(vs , c1 );
 ai+1    aj  L(c1 , c2 ); and
 there exist two derivations in G of the form
S G a1    ai A
G a1    ai 
 G ai+1    aj .
The above statement closely resembles the existential condition previously discussed for the
original Earley algorithm, and can be proved using arguments similar to those presented for
304

fiIDL-Expressions: A Formalism for Finite Languages

[S   , vs , vs ]



S

(11)

[A    B, c1 , c2 ] 
B
[B   , c2 , c2 ]

(12)

[A    a, c1 , c2 ]
[c2 , c2 ]

(13)

[A    a, c1 , c2 ]
[a, c2 , c3 ]
[A  a  , c1 , c3 ]
[A    B, c1 , c2 ]
[B   , c2 , c3 ]
[A  B  , c1 , c3 ]
[c1 , c2 ] 
(c2 , , c3 )  
[c1 , c3 ]

[c1 , c2 ]
[a, c1 , c3 ]



(c2 , a, c3 )   ,
a

[S   , c0 , c1 ] 
(c1 , , c2 )  
[S   , c0 , c2 ]

(14)

(15)

(16)

(17)

(18)

Figure 3: An abstract specification of the parsing algorithm for IDL-graphs. The algorithm
accepts the IDL-graph () if and only if some item having the form [S   
, vs , ve ] can be derived by the inference rules, where S   is a production of G
and vs and ve are the start and end vertices of (), respectively.

305

fiNederhof & Satta

instance by Aho and Ullman (1972) and by Graham and Harrison (1976); we will therefore
omit a complete proof here. Note that the correctness of the algorithm in Figure 3 directly
follows from the above statement, by taking item [A    , c1 , c2 ] to be of the form
[S   , vs , ve ] for some production S   from G.

7. Complexity and Implementation
In this section we provide a computational analysis of our parsing algorithm for IDL-graphs.
The analysis is based on the development of a tight upper bound on the number of possible
cuts admitted by an IDL-graph. We also discuss two possible implementations for the
parsing algorithm.
We need to introduce some notation. Let  be an IDL-expression and let () =
(V, E, vs , ve , , r) be the associated IDL-graph. A vertex v  V is called L-free in () if,
for every subexpression  0 of  such that j ( 0 ) = (V 0 , E 0 , vs0 , ve0 , 0 , r0 ) for some j, V 0  V ,
E 0  E, and such that v  V 0 , we have that  0 is not of the form ( 00 ). In words, a vertex
is L-free in () if it does not belong to a subgraph of () that encodes an IDL-expression
headed by an L operator. When () is understood from the context, we write L-free in
place of L-free in (). We write 0-cut() to denote the set of all cuts in cut() that only
contain vertices that are L-free in (). We now introduce two functions that will be used
later in the complexity analysis of our algorithm. For a cut c  cut() we write |c| to denote
the length of c, i.e., the number of vertices in the cut.
Definition 6 Let  be an IDL-expression. Functions width and 0-width are specified as
follows:
width() =

max |c| ,

ccut()

0-width() =

max
c0-cut()

|c| .

Function width provides the maximum length of a cut through (). This quantity gives
the maximum number of subexpressions of  that need to be evaluated in parallel when
generating a string in L(). Similarly, function 0-width provides the maximum length of a
cut through () that only includes L-free nodes.
Despite the fact that cut() is always a finite set, a computation of functions width and
0-width through a direct computation of cut() and 0-cut() is not practical, since these
sets may have exponential size in the number of vertices of (). The next characterization
provides a more efficient way to compute the above functions, and will be used in the proof
of Lemma 2 below.
Lemma 1 Let  be an IDL-expression. The quantities width() and 0-width() satisfy the
following equations:
(i) if  = a, a    {E}, we have
width() = 1,
0-width() = 1;
306

fiIDL-Expressions: A Formalism for Finite Languages

(ii) if  = ( 0 ) we have
width() = width( 0 ),
0-width() = 1;
(iii) if  = (1 , 2 , . . . , n ) we have
n

width() = max width(i ),
i=1
n

0-width() = max 0-width(i );
i=1

(iv) if  = k(1 , 2 , . . . , n ) we have
n

width() = max (width(j ) +
j=1

0-width() =

n
X

X

0-width(i )),

i:1ini6=j

0-width(j );

j=1

(v) if  = 1  2 we have
width() = max {width(1 ), width(2 )},
0-width() = max {0-width(1 ), 0-width(2 )}.
Proof. All of the equations in the statement of the lemma straightforwardly follow from
the definitions of  and cut() (Definitions 4 and 5, respectively). Here we develop at
length only two cases and leave the remainder of the proof to the reader. In what follows
we assume that () = (V, E, vs , ve , , r).
In case  = (1 , 2 , . . . , n ), let (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), 1  i  n. From
Definition 4 we have (vs , , vi,s )   and (vi,e , , ve )   , for every i, 1  i  n. Thus
we have cut() = ni=1 cut(i )  {vs , ve } and, since both vs and ve are L-free in (),
0-cut() = ni=1 0-cut(i )  {vs , ve }. This provides the relations in (iii).
In case  = k(1 , 2 , . . . , n ), let (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), 1  i  n. From
Definition 4 we have (vs , , v1,s    vn,s )   and (v1,e    vn,e , , ve )   . Thus every
c  cut() must belong to {vs , ve } or must have the form c = c1    cn with ci  cut(i ) for
1  i  n. Since both vs and ve are L-free in (), we immediately derive
0-cut() = {vs , ve }  0-cut(1 )    0-cut(n ),
P
and hence 0-width() = nj=1 0-width(j ). Now observe that, for each c = c1    cn specified
as above there can never be indices i and j, 1  i, j  n and i 6= j, and vertices v1 and v2
occurring in ci and cj , respectively, such that neither v1 nor v2 are L-free in ().
We thereby derive
cut() = {vs , ve } 
cut(1 )0-cut(2 )    0-cut(n ) 
0-cut(1 )cut(2 )    0-cut(n ) 
..
.
0-cut(1 )0-cut(2 )    cut(n ).
307

fiNederhof & Satta

P
Hence we can write width() = maxnj=1 (width(j ) + i:1ini6=j 0-width(i )). 
Now consider quantity |cut()|, i.e., the number of different cuts in IDL-graph ().
This quantity is obviously bounded from above by |V |width() . We now derive a tighter
upper bound on this quantity.
Lemma 2 Let  be a finite alphabet, let  be an IDL-expression over , and let () =
(V, E, vs , ve , , r) be its associated IDL-graph. Let also k = width(). We have


|cut()| 

|V |
k

k

.

Proof. We use below the following inequality. For any integer h  2 and real values xi > 0,
1  i  h, we have
h
Y

xi 

Ph

i=1

i=1

h

xi

!h

.

(19)

In words, (19) states that the geometric mean is never larger than the arithmetic mean.
We prove (19) in the following equivalent
form. For any real values c > 0 and yi ,
P
1  i  h and h  2, with yi > c and hi=1 yi = 0, we have
h
Y

(c + yi )  ch .

(20)

i=1

We start by observing that if the yi are all equal to zero, then we are done. Otherwise there
must be i and j with 1  i, j  h such that yi yj < 0. Without loss of generality, we assume
i = 1 and j = 2. Since yi yj < 0, we have
(c + y1 )(c + y2 ) = c(c + y1 + y2 ) + y1 y2 < c(c + y1 + y2 ).
Since

Qh

i=3 (c

(21)

+ yi ) > 0, we have
(c + y1 )(c + y2 )

h
Y

(c + yi ) < c(c + y1 + y2 )

i=3

h
Y

(c + yi ).

(22)

i=3

We now observe that the right-hand side of (22) has the same form as the left-hand side
of (20), but with fewer yi that are non-zero. We can therefore iterate the above procedure,
until all yi become zero valued. This concludes the proof of (19).
Let us turn to the proof of the statement of the lemma. Recall that each cut c  cut()
is a string over V such that no vertex in V has more than one occurrence in c, and c is
canonically represented, i.e., no other permutation of the vertices in c is a possible cut. We
will later prove the following claim.
Claim. Let , V and k be as in the statement of the lemma. We can partition V into
subsets V [, j], 1  j  k, having the following property. For every V [, j], 1  j  k, and
every pair of distinct vertices v1 , v2  V [, j], v1 and v2 do not occur together in any cut
c  cut().
308

fiIDL-Expressions: A Formalism for Finite Languages

We can then write
|cut()| 

Qk

j=1



 Pk

=



|V [, j]|

j=1

|V |
k

k

|V [,j]|
k

k

(by our claim and the canonical
representation of cuts)
(by (19))

.

To complete the proof of the lemma we now need to prove our claim above. We prove
the following statement, which is a slightly stronger version of the claim. We can partition
set V into subsets V [, j], 1  j  k = width(), having the following two properties:
 for every V [, j], 1  j  k, and every pair of distinct vertices v1 , v2  V [, j], v1 and
v2 do not occur together in any cut c  cut();
 all vertices in V that are L-free in () are included in some V [, j], 1  j 
0-width(). (In other words, the sets V [, j], 0-width() < j  width(), can only
contain vertices that are not L-free in ().)
In what follows we use induction on #op (), the number of operator occurrences (I, D, L
and concatenation) appearing within .
Base: #op () = 0. We have  = a, with a   {E}, and V = {vs , vf }. Since width() = 1,
we set V [, 1] = V . This satisfies our claim, since cut() = {vs , vf }, all vertices in V are
L-free in () and we have 0-width() = 1.
Induction: #op () > 0. We distinguish among three possible cases.
Case 1:  = (1 , 2 , . . . , n ). Let (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), 1  i  n. By Lemma 1
we have width() = maxni=1 width(i ). For each i, 1  i  n, let us define V [i , j] =  for
every j such that width(i ) < j  width(). We can then set
V [, 1] = (ni=1 V [i , 1])  {vs , ve };
V [, j] = ni=1 V [i , j], for 2  j  width().
The sets V [, j] define a partition of V , since V = (ni=1 Vi )  {vs , ve } and, for each i, the
sets V [i , j] define a partition of Vi by the inductive hypothesis. We now show that such a
partition satisfies the two conditions in our statement.
Let v1 and v2 be two distinct vertices in some V [, j]. We have already established in
the proof of Lemma 1 that cut() = (ni=1 cut(i ))  {vs , ve }. If either v1 or v2 belongs
to the set {vs , ve }, then v1 and v2 cannot occur in the same cut in cut(), since the only
cuts in cut() with vertices in the set {vs , ve } are vs and ve . Let us now consider the case
v1 , v2  ni=1 Vi . We can distinguish two subcases. In the first subcase, there exists i such
that v1 , v2  V [i , j]. The inductive hypothesis states that v1 and v2 cannot occur in the
same cut in cut(i ), and hence cannot occur in the same cut in cut(). In the second
subcase, v1  V [i , j] and v2  V [i0 , j] for distinct i and i0 . Then v1 and v2 must belong
to different graphs (i ) and (i0 ), and hence cannot occur in the same cut in cut().
Furthermore, every vertex in ni=1 Vi that is L-free in some (i ) belongs to some
V [i , j] with 1  j  0-width(i ), by the inductive hypothesis. Since 0-width() =

309

fiNederhof & Satta

maxni=1 0-width(i ) (Lemma 1) we can state that all vertices in V that are L-free in ()
belong to some V [, j], 1  j  0-width().
Case 2:  = ( 0 ) or  = 1  2 . The proof is almost identical to that of Case 1, with
n = 1 or n = 2, respectively.
Case 3:  = k(1 , 2 , . . . , n ). Let (i ) = (Vi , Ei , vi,s , vi,e , i , ri ), 1  i  n. By Lemma 1
we have
0-width() =

n
X

0-width(j ),

j=1
n

width() = max (width(j ) +
j=1

X

0-width(i )).

i:1ini6=j

The latter equation can be rewritten as
width() =

n
X

n

0-width(j ) + max (width(j )  0-width(j )).
j=1

j=1

(23)

For each i with 1  i  n, let us define V [i , j] =  for every j with width(i ) < j  width().
We can then set
V [, 1] = V [1 , 1]  {vs , ve };
V [, j] = V [1 , j], for 2  j  0-width(1 );
V [, 0-width(1 ) + j] = V [2 , j], for 1  j  0-width(2 );
..
.
Pn1
V [, Pi=1 0-width(i ) + j] = V [n , j], for 1  j  0-width(n );
V [, ni=1 0-width(i ) + j] = ni=1 V [i , 0-width(i ) + j],
for 1  j  maxnj=1 (width(j )  0-width(j )).
The sets V [, j] define a partition of V , since V = (ni=1 Vi )  {vs , ve } and, for each i, the
sets V [i , j] define a partition of Vi by the inductive hypothesis. We now show that such a
partition satisfies both conditions in our statement.
Let v1 and v2 be distinct vertices in some V [, j], 1  j  n. We have already established
in the proof of Lemma 1 that a cut c in cut() either belongs to {vs , ve } or else must have
the form c = c1    cn with ci  cut(i ) for 1  i  n. As in Case 1, if either v1 or v2 belongs
to the set {vs , ve }, then v1 and v2 cannot occur in the same cut in cut(), since the only
cuts in cut() with vertices in the set {vs , ve } are vs and ve . Consider now the case in which
v1 , v2  ni=1 Vi . We distinguish two subcases.
In the first subcase, there exists i such that v1 , v2  V [i , j]. If there exists a cut
c  cut() such that v1 and v2 both occur within c, then v1 and v2 must both occur within
some c0  cut(i ). But this contradicts the inductive hypothesis on i .
In the second subcase, v1  V [i0 , j 0 ] and v2  V [i00 , j 00 ], for distinct i0 and i00 . Note
that this can only happen if 0-width() < j  width(), 0-width(i0 ) < j 0  width(i0 ) and
0-width(i00 ) < j 00  width(i00 ), by our definition of the partition of V and by (23). By the
inductive hypothesis on i0 and i00 , v1 is not L-free in (i0 ) and v2 is not L-free in (i00 ),
which means that both v1 and v2 occur within the scope of some occurrence of the lock
310

fiIDL-Expressions: A Formalism for Finite Languages

operator. Note however that v1 and v2 cannot occur within the scope of the same occurrence
of the lock operator, since they belong to different subgraphs (i0 ) and (i00 ). Assume
now that there exists a cut c  cut() such that v1 and v2 both occur within c. This would
be inconsistent with the definitions of  and cut (Definitions 4 and 5, respectively) since
two vertices that are not L-free and that are not within the scope of the same occurrence
of the lock operator cannot belong to the same cut.
Finally, it directly follows from the definition of our partition on V and from the inductive hypothesis on the i that all vertices in V that are L-free in () belong to some
V [, j] with 1  j  0-width(). This concludes the proof of our statement. 
The upper bound reported in Lemma 2 is tight. As an example, for any i  1 and k  2,
let i,k = {a1 , . . . , aik }. Consider now the class of IDL-expressions
i,k = k(a1 a2    ai , ai+1 ai+2    a2i , . . . , ai(k1)+1 ai(k1)+2    aik ).
Let also Vi,k be the vertex set of the IDL-graph (i,k ). It is not difficult to see that
|Vi,k | = 2  i  k + 2, width(i,k ) = k and
2
|cut(i,k )| = (2  i)k + 2  (2  i + )k ,
k
where the inequality results from our upper bound. The coarser upper bound presented
before Lemma 2 would give instead |cut(i,k )| < (2  i  k + 2)k .
We can now turn to the discussion of the worst case running time for the algorithm in
Figure 3. To simplify the presentation, let us ignore for the moment any term that solely
depends on the input grammar G.
To store and retrieve items [A    , c1 , c2 ], [a, c1 , c2 ] and [c1 , c2 ] we exploit some
data structure T and access it using cut c1 and cut c2 as indices. In what follows we make
the assumption that each access operation on T can be carried out in an amount of time
O(d(k)), where k = width() and d is some function that depends on the implementation
of the data structure itself, to be discussed later. After we access T with some pair c1 , c2 ,
an array is returned of length proportional to |G|. Thus, from such an array we can inquire
in constant time whether a given item has already been constructed.
The worst case time complexity is dominated by the rules in Figure 3 that involve the
maximum number of cuts, namely rules like (15) with three cuts each. The maximum
number of different calls to these rules is then proportional to |cut()|3 . Considering our
assumptions on T , the total amount of time that is charged to the execution of all these
rules is then O(d(k) |cut()|3 ). As in the case of the standard Earley algorithm, when the
working grammar G is taken into account we must include a factor of |G|2 , which can be
reduced to |G| using techniques discussed by Graham, Harrison, and Ruzzo (1980).
We also need to consider the amount of time required by the construction of relation
 , which happens on-the-fly, as already discussed. This takes place at Rules (16), (17) and
(18). Recall that elements of relation  have the form (c1 , X, c2 ) with c1 , c2  cut() and
X    {}. In what follows, we view  as a directed graph whose vertices are cuts, and
thus refer to elements of such a relation as (labelled) arcs. When an arc in  emanating
from a cut c1 with label X is visited for the first time, then we compute this arc and the
reached cut, and cache them for possible later use. However, in case the reached cut c2
already exists because we had previously visited an arc (c01 , X 0 , c2 ), then we only cache the
311

fiNederhof & Satta

new arc. For each arc in  , all the above can be easily carried out in time O(k), where
k = width(). Then the total time required by the on-the-fly construction of relation  is
O(k | |). For later use, we now express this bound in terms of quantity |cut()|. From the
definition of  we can easily see that there can be no more than one arc between any two
cuts, and therefore | |  |cut()|2 . We obviously have k  |V |. Also, it is not difficult to
prove that |V |  |cut()|, using induction on the number of operator occurrences appearing
within . We thus conclude that, in the worst case, the total time required by the on-the-fly
construction of relation  is O(|cut()|3 ).
From all of the above observations we can conclude that, in the worst case, the algorithm
in Figure 3 takes an amount of time O(|G| d(k) |cut()|3 ). Using Lemma 2, we can then
state the following theorem.
Theorem 1 Given a context-free grammar G and an IDL-graph () with vertex set V
and with k = width(), the algorithm in Figure 3 runs in time O(|G| d(k)( |Vk | )3k ).
We now more closely consider the choice of the data structure T and the issue of its
implementation. We discuss two possible solutions. Our first solution can be used when
|cut()| is small enough so that we can store |cut()|2 pointers in the computers randomaccess memory. In this case we can implement T as a square array of pointers to sets of
our parsing items. Each cut in cut() is then uniquely encoded by a non-negative integer,
and such integers are used to access the array. This solution in practice comes down to
the standard implementation of the Earley algorithm through a parse table, as presented
by Graham et al. (1980). We then have d(k) = O(1) and our algorithm has time complexity
O(|G| ( |Vk | )3k ).
As a second solution, when |cut()| is quite large, we can implement T as a trie (Gusfield,
1997). In this case each cut is treated as a string over set V , viewed as an alphabet, and we
look up string c1 #c2 in T (# is a symbol not in V ) in order to retrieve all items involving
cuts c1 and c2 that have been induced so far. We then obtain d(k) = O(k) and our algorithm
has time complexity O(|G| k( |Vk | )3k ).
The first solution above is faster than the second one by a factor of k. However, the first
solution has the obvious disadvantage of expensive space requirements, since not all pairs
of cuts might correspond to some grammar constituent, and the array T can be very sparse
in practice. It should also be observed that, in the natural language processing applications
discussed in the introduction, k can be quite small, say three or four.
To conclude this section, we compare the time complexity of CFG parsing as traditionally
defined for strings and the time complexity of parsing for IDL-graphs. As reference for string
parsing we take the Earley algorithm, which has already been presented in Section 6. By a
minor change proposed by Graham et al. (1980), the Earley algorithm can be improved to
have time complexity O(|G|  n3 ), where G is the input CFG and n is the length of the input
string. We observe that, if we ignore the factor d(k) in the time complexity of IDL-graph
parsing (Theorem 1), the two upper bounds become very similar, with function ( |Vk | )k in
IDL-graph parsing replacing the input sentence length n from the Earley algorithm.
We observe that function ( |Vk | )k can be taken as a measure of the complexity of the
internal structure of the input IDL-expression. More specifically, assume that no precedence
constraints at all are given for the words of the input IDL-expression. We then obtain IDLexpressions with occurrences of the I operator only, with a worst case of k = |V2 |  1.
312

fiIDL-Expressions: A Formalism for Finite Languages

Then O(( |Vk | )k ) can be written as O(c|V | ) for some constant c > 1, resulting in exponential
running time for our algorithm. This comes at no surprise, since the problem at hand then
becomes the problem of recognition of a bag of words with a CFG, which is known to be
NP-complete (Brew, 1992), as already discussed in Section 2.
Conversely, no I operator may be used in the IDL-expression , and thus the resulting
representation matches a finite automaton or word lattice. In this case we have k = 1 and
function ( |Vk | )k becomes |V |. The resulting running time is then a cubic function of the
input length, as in the case of the Earley algorithm. The fact that (cyclic or acyclic) finite
automata can be parsed in cubic time is also a well-known result (Bar-Hillel et al., 1964;
van Noord, 1995).
It is noteworthy to observe that in applications where k can be assumed to be bounded,
our algorithm still runs in polynomial time. As already discussed, in practical applications
of natural language generation, only few subexpressions from  will be processed simultaneously, with k being typically, say, three or four. In this case our algorithm behaves in a
way that is much closer to traditional string parsing than to bag parsing.
We conclude that the class of IDL-expressions provides a flexible representation for bags
of words with precedence constraints, with solutions in the range between pure word bags
without precedence constraints and word lattices, depending on the value of width(). We
have also proved a fine-grained result on the time complexity of the CFG parsing problem
for IDL-expressions, again depending on values of the parameter width().

8. Final Remarks
Recent proposals view natural language surface generation as a multi-phase process where
finite but very large sets of candidate sentences are first generated on the basis of some input
conceptual structure, and then filtered using statistical knowledge. In such architectures, it
is crucial that the adopted representation for the set of candidate sentences is very compact,
and at the same time that the representation can be parsed in polynomial time.
We have proposed IDL-expressions as a solution to the above problem. IDL-expressions
combine features that were considered only in isolation before. In contrast to existing
formalisms, interaction of these features provides enough flexibility to encode strings in
cases where only partial knowledge is available about word order, whereas the parsing
process remains polynomial in practical cases.
The recognition algorithm we have presented for IDL-expressions can be easily extended
to a parsing algorithm, using standard representations of parse forests that can be extracted
from the constructed parse table (Lang, 1994). Furthermore, if the productions of the CFG
at hand are weighted, to express preferences among derivations, it is easy to extract a parse
with the highest weight, adapting standard Viterbi search techniques as used in traditional
string parsing (Viterbi, 1967; Teitelbaum, 1973).
Although we have only considered the parsing problem for CFGs, one may also parse
IDL-expressions with language models based on finite automata, including n-gram models. Since finite automata can be represented as right-linear context-free grammars, the
algorithm in Figure 3 is still applicable.
Apart from natural language generation, IDL-expressions are useful wherever uncertainty on word or constituent order is to be represented at the level of syntax and has to be

313

fiNederhof & Satta

linearized for the purpose of parsing. As already discussed in the introduction, this is an
active research topic both in generative linguistics and in natural language parsing, and has
given rise to several paradigms, most importantly immediate dominance and linear precedence parsing (Gazdar, Klein, Pullum, & Sag, 1985), discontinuous parsing Daniels and
Meurers (2002), Ramsay (1999), Suhre (1999) and grammar linearization (Gotz & Penn,
1997; Gotz & Meurers, 1995; Manandhar, 1995). Nederhof, Satta, and Shieber (2003)
use IDL-expressions to define a new rewriting formalism, based on context-free grammars
with IDL-expressions in the right-hand sides of productions. By means of this formalism,
fine-grained results were proven on immediate dominance and linear precedence parsing.5
IDL-expressions are similar in spirit to formalisms developed in the programming language literature for the representation of the semantics of concurrent programs. More
specifically, so called series-parallel partially ordered multisets, or series-parallel pomsets,
have been proposed by Gischer (1988) to represent choice and parallelism among processes.
However, the basic idea of a lock operator is absent from series-parallel pomsets.

Acknowledgments
A preliminary version of this paper has appeared in the Proceedings of the 7th Conference
on Formal Grammars (FG2002), Trento, Italy. The notions of IDL-graph and cut, central
to the present study, are not found in the earlier paper. We wish to thank Michael Daniels,
Irene Langkilde, Owen Rambow and Stuart Shieber for very helpful discussions related to
the topics in this paper. We are also grateful to the anonymous reviewers for helpful comments and pointers to relevant literature. The first author was supported by the PIONIER
Project Algorithms for Linguistic Processing, funded by NWO (Dutch Organization for
Scientific Research). The second author was supported by MIUR under project PRIN No.
2003091149 005.

References
Aho, A., & Ullman, J. (1972). Parsing, Vol. 1 of The Theory of Parsing, Translation and
Compiling. Prentice-Hall.
Aust, H., Oerder, M., Seide, F., & Steinbiss, V. (1995). The Philips automatic train
timetable information system. Speech Communication, 17, 249262.
Bangalore, S., & Rambow, O. (2000). Exploiting a probabilistic hierarchical model for generation. In The 18th International Conference on Computational Linguistics, Vol. 1,
pp. 4248, Saarbrucken, Germany.
Bar-Hillel, Y., Perles, M., & Shamir, E. (1964). On formal properties of simple phrase
structure grammars. In Bar-Hillel, Y. (Ed.), Language and Information: Selected
Essays on their Theory and Application, chap. 9, pp. 116150. Addison-Wesley.
Beaven, J. (1992). Shake-and-bake machine translation. In Proc. of the fifteenth International Conference on Computational Linguistics, Vol. 2, pp. 602609, Nantes.
5. In the cited work, the lock operator was ignored, as it did not affect the weak generative capacity nor
the compactness of grammars.

314

fiIDL-Expressions: A Formalism for Finite Languages

Billot, S., & Lang, B. (1989). The structure of shared forests in ambiguous parsing. In 27th
Annual Meeting of the Association for Computational Linguistics, Proceedings of the
Conference, pp. 143151, Vancouver, British Columbia, Canada.
Brew, C. (1992). Letting the cat out of the bag: generation for Shake-and-Bake MT. In
Proc. of the fifteenth International Conference on Computational Linguistics, Vol. 2,
pp. 610616, Nantes.
Brown, P., et al. (1990). A statistical approach to machine translation. Computational
Linguistics, 16 (2), 7985.
Brzozowski, J. (1964). Derivatives of regular expressions. Journal of the ACM, 11 (4),
481494.
Charniak, E. (2001). Immediate-head parsing for language models. In 39th Annual Meeting
and 10th Conference of the European Chapter of the Association for Computational
Linguistics, Proceedings of the Conference, pp. 116123, Toulouse, France.
Daniels, M., & Meurers, W. (2002). Improving the efficiency of parsing with discontinuous
constituents. In Wintner, S. (Ed.), Proceedings of NLULP02: The 7th International
Workshop on Natural Language Understanding and Logic Programming, Vol. 92 of
Datalogiske Skrifter, pp. 4968, Copenhagen. Roskilde Universitetscenter.
Dassow, J., & Paun, G. (1989). Regulated Rewriting in Formal Language Theory. SpringerVerlag.
Earley, J. (1970). An efficient context-free parsing algorithm. Communications of the ACM,
13 (2), 94102.
Gazdar, G., Klein, E., Pullum, G., & Sag, I. (1985). Generalized Phrase Structure Grammar.
Harvard University Press, Cambridge, MA.
Gischer, J. (1988). The equational theory of pomsets. Theoretical Computer Science, 61,
199224.
Gotz, T., & Meurers, W. (1995). Compiling HPSG type constraints into definite clause
programs. In 33rd Annual Meeting of the Association for Computational Linguistics,
Proceedings of the Conference, pp. 8591, Cambridge, Massachusetts, USA.
Gotz, T., & Penn, G. (1997). A proposed linear specification language. Volume 134 of
Arbeitspapiere des SFB 340, Universitat Tubingen.
Graham, S., & Harrison, M. (1976). Parsing of general context free languages. In Advances
in Computers, Vol. 14, pp. 77185. Academic Press, New York, NY.
Graham, S., Harrison, M., & Ruzzo, W. (1980). An improved context-free recognizer. ACM
Transactions on Programming Languages and Systems, 2 (3), 415462.
Gusfield, D. (1997). Algorithms on Strings, Trees and Sequences. Cambridge University
Press, Cambridge, UK.
Harrison, M. (1978). Introduction to Formal Language Theory. Addison-Wesley.
Jurafsky, D., & Martin, J. (2000). Speech and Language Processing. Prentice-Hall.
Knight, K. (1999). Decoding complexity in word-replacement translation models. Computational Linguistics, 25 (4), 607615.
315

fiNederhof & Satta

Knight, K., & Hatzivassiloglou, V. (1995). Two-level, many-paths generation. In 33rd
Annual Meeting of the Association for Computational Linguistics, Proceedings of the
Conference, pp. 252260, Cambridge, Massachusetts, USA.
Lang, B. (1994). Recognition can be harder than parsing. Computational Intelligence,
10 (4), 486494.
Langkilde, I. (2000). Forest-based statistical sentence generation. In 6th Applied Natural
Language Processing Conference and 1st Meeting of the North American Chapter
of the Association for Computational Linguistics, pp. 170177 (Section 2), Seattle,
Washington, USA.
Langkilde, I., & Knight, K. (1998). Generation that exploits corpus-based statistical knowledge. In 36th Annual Meeting of the Association for Computational Linguistics and
17th International Conference on Computational Linguistics, Vol. 1, pp. 704710,
Montreal, Quebec, Canada.
Manandhar, S. (1995). Deterministic consistency checking of LP constraints. In Seventh
Conference of the European Chapter of the Association for Computational Linguistics,
Proceedings of the Conference, pp. 165172, Belfield, Dublin, Ireland.
Nederhof, M.-J., & Satta, G. (2004). The language intersection problem for non-recursive
context-free grammars. Information and Computation. Accepted for publication.
Nederhof, M.-J., Satta, G., & Shieber, S. (2003). Partially ordered multiset context-free
grammars and free-word-order parsing. In 8th International Workshop on Parsing
Technologies, pp. 171182, LORIA, Nancy, France.
Nevill-Manning, C., & Witten, I. (1997). Compression and explanation using hierarchical
grammars. The Computer Journal, 40 (2/3), 103116.
Pollard, C., & Sag, I. (1994). Head-Driven Phrase Structure Grammar. University of
Chicago Press.
Ramsay, A. (1999). Direct parsing with discontinuous phrases. Natural Language Engineering, 5 (3), 271300.
Reape, M. (1989). A logical treatment of semi-free word order and bounded discontinuous
constituency. In Fourth Conference of the European Chapter of the Association for
Computational Linguistics, Proceedings of the Conference, pp. 103110, Manchester,
England.
Reape, M. (1994). Domain union and word order variation in german. In Nerbonne, J.,
Netter, K., & Pollard, C. (Eds.), German in Head-Driven Phrase Structure Grammar,
pp. 151197. CSLI Publications.
Shieber, S., Schabes, Y., & Pereira, F. (1995). Principles and implementation of deductive
parsing. Journal of Logic Programming, 24, 336.
Suhre, O. (1999). Computational aspects of a grammar formalism for languages with freer
word order. Diplomarbeit, Department of Computer Science, University of Tubingen.
Published in 2000 as Volume 154 of Arbeitspapiere des SFB 340.

316

fiIDL-Expressions: A Formalism for Finite Languages

Teitelbaum, R. (1973). Context-free error analysis by evaluation of algebraic power series.
In Conference Record of the Fifth Annual ACM Symposium on Theory of Computing,
pp. 196199.
van der Vlist, E. (2003). RELAX NG. OReilly.
van Noord, G. (1995). The intersection of finite state automata and definite clause grammars. In 33rd Annual Meeting of the Association for Computational Linguistics,
Proceedings of the Conference, pp. 159165, Cambridge, Massachusetts, USA.
Viterbi, A. (1967). Error bounds for convolutional codes and an asymptotically optimum
decoding algorithm. IEEE Transactions on Information Theory, IT-13 (2), 260269.
Whitelock, P. (1992). Shake-and-Bake translation. In Proc. of the fifteenth International
Conference on Computational Linguistics, Vol. 2, pp. 784790, Nantes.

317

fiJournal of Articial Intelligence Research 21 (2004) 37-62

Submitted 03/03; published 01/04

K-Implementation
Dov Monderer
Moshe Tennenholtz

dov@ie.technion.ac.il
moshet@ie.technion.ac.il

Faculty of Industrial Engineering and Management
Technion  Israel Institute of Technology
Haifa 32000, Israel

Abstract
This paper discusses an interested party who wishes to inuence the behavior of agents
in a game (multi-agent interaction), which is not under his control. The interested party
cannot design a new game, cannot enforce agents behavior, cannot enforce payments by the
agents, and cannot prohibit strategies available to the agents. However, he can inuence
the outcome of the game by committing to non-negative monetary transfers for the dierent
strategy proles that may be selected by the agents. The interested party assumes that
agents are rational in the commonly agreed sense that they do not use dominated strategies.
Hence, a certain subset of outcomes is implemented in a given game if by adding nonnegative payments, rational players will necessarily produce an outcome in this subset.
Obviously, by making suciently big payments one can implement any desirable outcome.
The question is what is the cost of implementation? In this paper we introduce the notion
of k-implementation of a desired set of strategy proles, where k stands for the amount of
payment that need to be actually made in order to implement desirable outcomes. A major
point in k-implementation is that monetary oers need not necessarily materialize when
following desired behaviors. We dene and study k-implementation in the contexts of games
with complete and incomplete information. In the latter case we mainly focus on the VCG
games. Our setting is later extended to deal with mixed strategies using correlation devices.
Together, the paper introduces and studies the implementation of desirable outcomes by
a reliable party who cannot modify game rules (i.e. provide protocols), complementing
previous work in mechanism design, while making it more applicable to many realistic CS
settings.

1. Introduction
The design and analysis of interactions of self-interested parties are central to the theory and
application of multi-agent systems. In particular, the theory of economic mechanism design
or, more generally, implementation theory (Maskin, 1999; Maskin & Sjostrom, 2002) has
become a standard tool for researchers in the areas of multi-agent systems and e-commerce
(Rosenschein & Zlotkin, 1994; Nisan & Ronen, 1999; Shoham & Tennenholtz, 2001; Feigenbuam & S, 2002; Tennenholtz, 1999; Papadimitriou, 2001). In classical mechanism design1
a center denes an interaction for self-motivated parties that will allow it to obtain some
desired goal (such as maximizing revenue or social welfare) taking the agents incentives
1. See e.g., Fudenberg and Tirole (1991), Chapter 7, or Mas-Colell, Whinston, and Green (1995), Chapter
23.
c
2004
AI Access Foundation. All rights reserved.

fiMonderer & Tennenholtz

into account. This perspective has been largely motivated by the view of the center as a
government or a seller that can dene and control the rules of interaction. However, in
many distributed systems and multi-agent interactions, interested parties cannot control
the rules of interactions. A network manager for example cannot simply change the communication protocols in a given distributed systems in order to lead to desired behaviors,
and a broker cannot change the rules in which goods are sold by an agency auctioneer to the
public. The focus of this paper is on how a reliable interested party, which cannot change
the rules of interaction, and cannot enforce behavior, can obtain its desired goals (in service
of the community or for its own benets). The reliable party has only one source of power:
its reliability. It can commit to payments to the dierent agents, when certain observable
outcomes will be reached, and the agents can be sure that they will be paid appropriately.
In our work we introduce the study of implementation of desired behaviors by interested
party as above.2 There are two major issues that make the task non-trivial and challenging:
1. The interested party may wish to assume as little as possible about agents rationality.
Ideally, all that will be assumed is that an agent does not adopt a strategy if it is dominated
by another strategy.
2. The interested party may wish to minimize its expenses.
Consider the following simple congestion setting.3 Assume that there are two agents,
1 and 2, that have to select among two service providers (e.g., machines, communication
lines, etc.) One of the service providers, f , is a fast one, while the other, s, is a slower one.
We capture this by having an agent obtaining a payo of 6 when he is the only one that
uses f , and a payo of 4 when he is the only one who uses s. If both agents select the same
service provider then its speed of operation decreases by a factor of 2, leading to half the
payo. That is, if both agents use f then each one of them obtains a payo of 3, while if
both agents use s then each one of them obtains 2. In a matrix form, this game is described
by the following bimatrix:

f

s

3

6

f
3

4

M=
4

2

s
6

2

2. For another interesting use of an interested party see Naor, Pinkas, and Sumner (1999).
3. Congestion in the context of self-motivated parties is a central topic in the recent CS literature (Koutsoupias & Papadimitriou, 1999; Roughgarden, 2001; Roughgarden & Tardos, 2002), as well as in the
game theory literature (Rosenthal, 1973; Monderer & Shapley, 1996). This example is used for purposes
of illustration only; however, the technique used in this example can be extended to arbitrary complex
games, as we will later show.

38

fiK-Implementation

Assume that our reliable interested party may wish to prevent the agents from using the
same service provider (leading to low payos for both). Then it can do as follows: it can
promise to pay agent 1 a value of 10 if both agents will use f , and promise to pay agent 2
a value of 10 if both agents will use s. These promises transform M to the following game:

f

s

13

6

f
3

M =
4

4
2

s
6

12

Notice that in M  , strategy f is dominant for agent 1, and strategy s is dominant for
agent 2. As a result the only rational strategy prole is the one in which agent 1 chooses f
and agent 2 chooses s. Hence, the interested party implements one of the desired outcomes.
Moreover, given that the strategy prole (f, s) is selected the interested party will have to
pay nothing. It has just implemented (in dominant strategies) a desired behavior (obtained
in one of the Nash equilibria) with zero cost, relying only on its creditability, without
modifying the rules of interactions or enforcing any type of behavior.
Similar simple examples can be found in other contexts (see e.g., Segal (1999), footnote
30, and Dybvig and Spatt (1983), Spiegler (2000)). Our work advocates the following line
of thought. Instead of reasoning about how agents will behave in the given protocol, we
may wish to cause agents to follow particular behaviors by making them desirable, using
monetary oers. An important point is that the monetary oers need not necessarily be
fully materialized when agents follow the desired behavior.
More formally, in this paper we introduce the notion and study of k-implementation
of a desired set of strategy proles, where k stands for the amount of payment that need
to be actually made in order to implement the desirable outcomes.4 Section 3 provides
a characterization of k-implementation of a single pure strategy prole for nite games
and innite regular games with complete information. This provides an eective algorithm
for determining the optimal monetary oers to be made in order to implement a desired
outcome, while minimizing expenses. In Section 4 we address the problem of nding a kimplementation of a set of strategy proles. We show that the general problem in this regard
4. Notice that this perspective is in the spirit of work on Articial Social Systems in AI (see e.g., Shoham
and Tennenholtz (1995)), where we search for some form of modication to the system, such that
given the modied system, and assuming agents tend to work individually, a desirable outcome will be
obtained.

39

fiMonderer & Tennenholtz

is NP-hard, and consider a modication of k-implementation, titled exact implementation,
under which the problem becomes tractable.5
Games with incomplete information introduce further challenges. In particular, in Section 5 we consider the VCG mechanisms for combinatorial auctions 6 . This setting has
interesting characteristics since the interested party cannot in general see the agents types
and needs to decide on appropriate payment only based on observed behaviors. We show
that in general 0-implementation (i.e. implementation with zero cost) in settings with incomplete information is impossible, but any ex-post equilibrium of a frugal VCG mechanism
is 0-implementable.
In Section 6 we study the important case of mixed strategies. In that context, unless
we assume algorithmic observability, the interested party can observe only the actions selected and not the probabilistic process leading to the selection, and therefore our earlier
results do not apply. For example, consider the simple routing problem above, one may
wish to consider the implementation of a more fair outcome, such as the one obtained
in the mixed strategy Nash equilibrium of the game M . In order to address this issue, we
introduce the concept of implementation devices, and show that any mixed strategy equilibrium is 0-implementable with an implementation device. We also show that any correlated
equilibrium has this property.

2. k-implementation
A pre-game in strategic form is a pair G = (N, X), where N = {1, 2,    , n} is the set of
players, X = X1  X2     Xn , where for every i, Xi is the set of strategies available to
player i. Let i be a player, the set of strategy proles of all other players is denoted by Xi ,
and a generic element in Xi is denoted by xi .
A payo function vector is an n-tuple U = (U1 , U2 ,    , Un ), where Ui : X   is the
payo function of player i. We assume that the payos of the players are represented by
some common monetary unit, and that the payo functions are bounded7 .
A pre-game G and a payo function vector U denes a game in strategic form denoted
by G(U ). The game G(U ) is nite if the strategy sets are nite.
Let xi , yi be strategies of player i in the game G(U ).
xi dominates yi if Ui (xi , xi )  Ui (yi , xi ) for every xi  Xi , and there exists xi 
Xi for which a strict inequality holds. yi is a dominated strategy if it is dominated by some
other strategy of i. xi is a dominant strategy for i if it dominates every other strategy of i.
A prole of strategies x is a (Nash) equilibrium if for every player i, xi is a best-response
5. Complexity of implementation when the organizer controls the structure of the game is discussed by
Conitzer and Sandholm (2002).
6. The VCG mechanisms (Vickrey, 1961; Clarke, 1971; Groves, 1973) have been widely discussed in the
context of combinatorial auctions, a topic which received much attention in the recent multi-agent
systems and e-commerce literature, e.g., (Nisan, 2000; Sandholm, Suri, Gilpin, & Levine, 2001; Parkes,
1999)
7. If the game is nite the payo functions are automatically bounded.

40

fiK-Implementation

to xi . That is,
Ui (xi , xi )  Ui (yi , xi )

for every i  N and yi  Xi .

That is, if every player i believes that all other players act according to x, he is better o
by playing according to x. Modern economic theory has made an (some times implicit)
assumption that economic interactions are in equilibrium. However, the rationale for this
assumption is in debate in many cases, and it is particulary so when there exist multiple
equilibrium proles. In contrast, using a non-dominated strategy is a rational behavior in
any reasonable denition of rationality. Moreover, refraining from the use of dominated
strategies is taken as the most basic idea and agreed upon technique in decision theory.
Let G = (N, X) be a pre-game. For every vector of payo functions V , let Xi (V )
be the set of non-dominated strategies of i in the game G(V ), and let X(V ) = X1 (V ) 
X2 (V ),    , Xn (V ). G(V ) is the game (N, X, V ), where, by an innocent abuse of notations
V denotes the vector of the payo functions restricted to X. A vector V of payo functions
is non-negative (V  0) if Vi (x)  0 for every player i and for every x  X.
Consider a set of desired strategy proles O  X in the game G(U ). A non-negative
vector of payo functions V implements O in G(U ) if
   X(U + V )  O.
Such a V is called a k-implementation of O in G(U ), if in addition


n

i=1 Vi (x)

 k for every x  X(U + V ).

Obviously, by paying every player i sucient amount of money for playing the strategy
associated with a particular strategy prole in O, one can implement O.
That is, the interested party commits herself to certain non-negative payos V , in such
a way that rational players will only choose strategy proles in O, and such that in the
worst case the interested party will have to pay at most k.
Note that implicitly we have made two important assumptions :
 Output observability: The interested party can observe the actions chosen by the
players.
 Commitment power: The interested party is reliable in the sense that the players
believe that she will indeed pay the additional payo dened by V .
However, the requirement V  0 means that the interested party cannot force players
to make payments based on their actions. In addition, the interested party cannot modify
the set of available strategies, or enforce behavior in any way. He can just reliably promise
positive monetary transfers conditioned on the observed outcome.
Let k(O) be the price of implementing O. That is, k(O) is the greatest lower bound
(GLB) of all non-negative numbers q for which there exists a q- implementation. That is,
41

fiMonderer & Tennenholtz

k(O) = k implies that for every  > 0 O has a (k + )- implementation vector V  , and O
does not have a k  - implementation for any k  < k. V is an optimal implementation of O if
V implements O and
n

max
Vi (x) = k(O).
xX(U +V )

i=1

V is an  optimal implementation of O if V implements O and
max
xX(U +V )

n


Vi (x)  k(O) + .

i=1

3. k-Implementation of singletons
When O is a singleton, that is O = {z}, we sometimes abuse notations and we will say
that z (instead of {z}) has a k-implementation in G(U ), and we refer to k(z) as the price
of implementing z.
3.1 Finite games
In this section we focus on nite games, and on the characterization of optimal k implementation of singletons.
Theorem 1 Let G(U ) be a nite game with at least two strategies to every player. Every
strategy prole z has an optimal implementation V , and moreover:
k(z) =

n

i=1

max (Ui (xi , zi )  Ui (zi , zi )) .

xi Xi

3.1.1

Proof : Let z  X and let V implements z. Let i  N . If for some xi 	= zi , for some
xi , Vi (xi , xi ) > 0, then one can modify Vi by changing this term to 0, and get a cheaper
implementation of z. Hence, we can assume without loss of generality that we deal with
payo function vectors V for which, for every i, Vi (xi , ) = 0 for every xi 	= zi .
As zi is a dominant strategy for i in G(U + V ),
Vi (zi , xi )+Ui (zi , xi )  Vi (xi , xi )+Ui (xi , xi )

for every xi  Xi , and for every xi  Xi .

Since for xi 	= zi , Vi (xi , ) = 0, a necessary condition for an implementation is
Vi (zi , xi ) + Ui (zi , xi )  Ui (xi , xi )

for every xi  Xi .

That is,
Vi (zi , xi )  max (Ui (xi , xi )  Ui (zi , xi )).
xi Xi

42

fiK-Implementation

One can use xi 	= zi in order to get a costless strict inequality required by the denition
of domination ( here we use our assumption that every player has at least two strategies).
Hence, an optimal implementation vector for z, V is dened for every i by: Vi (xi , ) = 0 for
xi 	= zi , and Vi (zi , xi ) = maxxi Xi (Ui (xi , zi )  Ui (zi , zi )) + (xi ), where  : Xi  
is a nonnegative function that satises (zi ) = 0, and for some xi 	= zi , (xi ) > 0.
Therefore (3.1.1) is satised. 
Note that z is in equilibrium if and only if for every player i, maxxi Xi (Ui (xi , zi ) 
Ui (zi , zi )) = 0. Hence the following characterization of equilibrium is a corollary of Theorem 1:
Corollary 1 Let G(U ) be a nite game with at least two strategies to every player, and let
z  X. z is in equilibrium if and only if z has a zero- implementation.
3.2 Innite games
When the game G(U ) is innite, one can get phenomena that contradicts our intuition. For
example, it is possible that Xi = {zi } but zi is not a dominant strategy. E.g., consider the
two-person game in which player 1 can choose the strategy z1 , or any number 0 < x1 < 1,
and player 2 can choose z2 or x2 . U1 (z1 , z2 ) = 0.5, U1 (z1 , x2 ) = 10, U1 (x1 , ) = x1 . U2 is
an arbitrary function. It is easily seen that every x1 is dominated by a bigger number in
the open interval (0,1), z1 is not dominated, and hence X1 = {z1 }. However, z1 does not
dominate x1 for x1 > 0.5. Moreover, the max operator used in the proofs of Theorem 1 and
2 may not be well-dened for innite games. A game G(U ) = (N, X, U ) is called regular if
every Xi is a compact metric space, and the payo functions are continuous on X endowed
with the product metric.
Theorem 2 Theorems 1 holds for regular games.
Proof : The proof requires very standard techniques, and therefore it is omitted.
We then immediately get:
Corollary 2 Corollary 1 holds for regular games.
3.3 Mixed strategies
For every nite set B we denote by (B) the set of
probability distributions over B. That is,
(B) consists of all functions q : B  [0, 1] with bB q(b) = 1. Let G(U ) = (N, X, U ) be
a nite game. The mixed extension of G(U ) is the innite game Gm (U m ) = (N, X m , U m ),
where X m = (X1 )  (X2 )      (Xn ), and for every player i, Uim (p1 , p2 ,    , pn ) =

m
xX p1 (x1 )p2 (x2 )    pn (xn )Ui (x). That is, Ui (p) is the expected payo of player i when
every player j (including i) is choosing his strategy ( independently of the other players)
with a randomizing device that chooses each strategy xj with probability pj (xj ).
A prole of mixed strategies p  X m is called a mixed-strategy equilibrium in G(U ) if
p is in equilibrium in the game Gm (U m ). By Nash (1950) every nite game possesses a
43

fiMonderer & Tennenholtz

mixed strategy equilibrium. Note that every strategy xi  Xi of i can be identied with
the mixed strategy in which i chooses xi with probability 1. In this sense, Xi is a subset of
Xim . When we deal with an environment in which mixed strategies are considered, we refer
to every strategy xi  Xi as a pure strategy of i.
Note that the possibility of using mixed strategies does not destroy our previous results.
That is, if xi is a dominant (dominated) strategy in G(U ), it continues to be a dominant
(dominated) strategy in Gm (U m ).
As Gm (U m ) is a regular game we can apply Theorem 2 Corollary 2 and deduce:
Theorem 3 Let G(U ) be a nite game in strategic form with at least two strategies for every
player. Let p be a prole of mixed strategies in G(U ). p is a mixed strategy equilibrium in
G(U ) if and only if p has a 0-implementation in Gm (U m ).
Hence, technically, the case of mixed strategies follows from the theorems regarding pure
strategies in innite games. However, the reader should notice that in this case our output
observability assumption has a strong implication. Implementing a mixed strategy prole in
Gm (U m ) actually means algorithm observability in G(U ). That is, the interested party can
observe the mixed strategies used by the players. This is a realistic assumption if we think
about the interested party as a systems administrator that deploys algorithms submitted
by users. The designer is not allowed to alter the users algorithms, but can verify the exact
content of these algorithms. Hence, for example, in such a setting, if a users algorithm
ips a coin in order to decide on its course of action, then the exact randomized algorithms,
including the particular coin ipping, can be viewed by the interested party. The interesting
case in which the interested party cannot observe the mixed strategies will be discussed in
Section 6.

4. k-implementation of sets
In the previous sections we dealt with some properties of k- implementation. In particular
we emphasized the interesting cases of k-implementations of singletons. However, from a
computational perspective, given a game G(U ), and a set of desired strategy prole O, it
may be of interest to nd the smallest integer k  0 for which a k- implementation exists.
We can show:
Theorem 4 Given a game G(U ), a set of desired strategy proles O, and an integer k  0,
deciding whether there exists a k implementation of O in G(U ) is NP-hard.
Proof : In order to prove the above theorem, we use a reduction from the SAT problem.
Given a set of primitive propositions {x1 , x2 , . . . , xn }, consider a CNF formula. A CNF
formula is a conjunction of clauses C1  C2  . . .  Cm , where Ci = l1i  li2  . . .  lisi (si  2)
and where ljq = xi or ljq = xi for some i (for every 1  j  m and 1  q  sj ). The SAT
problem is the following decision problem: given a CNF formula, is there a truth assignment
to the primitive propositions that satises it? This problem is known to be NP-complete.
44

fiK-Implementation

We will now show a polynomial reduction from SAT to the problem of deciding whether a
2- implementation exists, where the games are 2-person games. This will suce to prove
our result. Without loss of generality we restrict our attention to CNF formulas where both
xi and xi appear in the formula, and no clause refers to both xi and xi (1  i  n).
Both agents will have a strategy ci associated with clause Ci , for every 1  i  m.
In addition, both agents will have strategies yi , zi , associated with the literals xi and xi ,
respectively (1  i  n).
The payo of agent 1, p1 , will be dened as follows. For any strategy prole of the form
(ci , yj ) the payo will be 3 if xj appears in clause i and 0 otherwise. For any strategy prole
of the form (ci , zj ) the payo will be 3 if xj appears in clause i and 0 otherwise. For any
strategy prole of the form (ci , cj ) the payo will be 50 if i = j and 0 otherwise. For any
strategy prole of the form (yi , yj ) the payo will be 2 if i = j and 3 otherwise. For any
strategy prole of the form (zi , zj ) the payo will be 2 if i = j and 3 otherwise. For any
strategy prole of the form (yi , zj ) or the form (zi , yj ) the payo will be 1 if i = j and 3
otherwise. For any strategy prole of the form (yi , cj ) the payo will be 51 if xi or xi
appear in clause Cj and 0 otherwise. For any strategy prole of the form (zi , cj ) the payo
will be 51 if xi or xi appears in clause Cj and 0 otherwise.
The payo to agent 2, p2 , will be as follows. The payo for any strategy prole of the
form (yi , yi ) or (zi , zi ) will be 101; the payo for any strategy prole of the form (yi , zi ) or
(zi , yi ) will be 100; the payo for any strategy prole of the form (yi , zj ) or (zi , yj ) where
i 	= j will be 0. The payo for any strategy prole of the form (ci , cj ) will be 50 if i = j,
and 0 otherwise. For any strategy prole of the form (yi , cj ), (zi , cj ) the payo will be 50 if
i = j and 0 otherwise. The payo for any strategy prole of the form (ci , yj ), (ci , zj ) will be
0.
The set O of desired strategy proles will include all strategy proles excluding the
following: All strategy proles of the form (ci , s),(yi , zi ),(zi , yi ) (where s is any strategy)
will be prohibited.
If the formula is satisable then there is 2- implementation: add 1 to the payo obtained
by agent 1 in any strategy prole of the form (yi , s) if xi is true in the satisfying assignment,
and add 1 to the payo obtained by agent 1 in any strategy prole of the form (zi , s) if xi it
false. As for agent 2, increase its payo by 1 for (zi , yi ) if xi is true, and increase its payo
by 1 for (yi , zi ) if xi is false.
Notice that given the above construction the strategies of the form ci of agent 1 will
become dominated and will be removed. In addition, if xi has been assigned true (resp.
false) then strategy zi (resp. yi ) will become dominated. The corresponding strategies of
agent 2 (i.e. zi if xi is true and yi if xi is false) will become dominated too, which yield the
desired behavior.
Similarly, notice that since we must remain with at least one yi or zi for agent 1, it
must be the case that at least one yi or zi will be removed for agent 2, and that this cannot
be obtained with a payment of 1 (increasing the payo from 100 to 101). Hence, in a 2implementation the payment of agent 2 should be 1. However, notice that we must add 1
to the payo of agent 1 for at least one of the elements of the form (yi , yi ) or (zi , zi ) which
45

fiMonderer & Tennenholtz

correspond to an xi or xi that appear in clause j (i.e. for at least one of the literals in
clause j, we need to add 1 to a strategy prole of the form (yi , yi ) or (zi , zi ) associated with
that literal). Notice that this is based on the fact that the strategy ci of agent i cannot
be removed by adding a payment of 1 to the outcome of any strategy of the form yj , zj , cj
of agent 1, where xj and xj do not appear in Ci , since the payo of agent 1 for (yj , ci )
and for (zj , ci ) is 0, while the payo of agent 1 for (ci , ci ) is 50. Moreover, if we add 1 to
the payo that agent 1 obtains for both (yi , yi ) and (zi , zi ) then both yi and zi will not be
dominated for agent 1, which will result in the possibility of playing a strategy prole which
is not desired(given that it is impossible to remove both yi and zi for agent 2). Hence, the
implementation corresponds to a sound truth assignment to the CNF formula, where xi is
assigned true i the payo for agent 1 at (yi , yi ) has been augmented by 1.

Notice that the previous result applies already in the case where we have a constant
number of agents. The previous result suggests one may wish to consider relaxations of the
optimal implementation problem that will be tractable.8 One interesting relaxation9 is the
following one:
A non-negative vector of payo functions V is called a k- exact implementation of O in
G(U ), if the following two conditions are satised:
 X(U + V ) = O.
n

i=1 Vi (x)  k for every x  O.
Hence, V implements O means that the set of non-dominated strategies in G(U + V ) is a
subset of O, while V is an exact implementation of O if this set equals O. When dealing
with singletons the concepts of implementation and exact implementation coincide.
Notice that the concept of exact implementation makes sense only when O = O1 
O2     On  X = X1  X2     Xn since otherwise it will be impossible to (exactly)
implement O. We also assume that Oi is strictly contained in Xi for every agent i, and that
Oi does not contain two strategies such that one dominates the other. We can show:
Theorem 5 Computing the optimal k for which an exact implementation exists is polynomial.
The algorithm leading to the above result is now illustrated for the case of two agents.
We construct the game matrix G , where the payo function of agent i is denoted by pi ;
pi describes the payment to agent i for the dierent strategy proles (if/when selected).
The matrix G will be the matrix of perturbations (non-negative monetary promises), while
G will denote the perturbed matrix generated. Let M = K + 1 where K is the maximal
element in the original game matrix.
The optimal perturbation [OP] algorithm:
8. Another approach may be to search for good approximation techniques.
9. See the discussion in the last section.

46

fiK-Implementation

1. Let (e1 , . . . , ek ) the list of possible dierences between an agents payos in the original
game (i.e. the possible results one obtains by subtracting two possible payos of an
agent in the given game) , sorted from small to large.
2. Let p1 (a, b) := M for every a  O1 and b  X2 \ O2 , and let p1 (a, b) = 0 whenever
a  X1 \ O1 or b  O2 .
3. Let p2 (a, b) := M for every b  O2 and a  X1 \ O1 , and let p2 (a, b) := 0 whenever
b  X2 \ O2 or a  O1 ,
4. Let i:=1
5. Let e := ei
6. Let p1 (a, b) := e for every strategy prole of the form (a, b) where a  O1 and b  O2
7. Let G := G + G
8. If the non-dominated strategies for agent 1 in G do not coincide with O1 then let
i:=i+1 and return to 5
9. Let i:=1
10. Let e := ei
11. Let p2 (a, b) := e for every a  O1 and b  O2
12. Let G = G + G
13. If the non-dominated strategies for agent 2 in G do not coincide with O2 then let
i:=i+1 and return to 10

5. Incomplete information
In previous sections we dealt with games with complete information. However, in many
real life situations the players ( and the interested party) have incomplete information
about certain parameters of the game. In the economic literature this phenomenon has
been mainly modelled by a Bayesian setting. In this setting every player receives some
private signal, which is correlated with the unknown parameters, and the joint distribution
of signals is commonly known to all players (and to the interested party). In the following
subsection we deal with Bayesian games without probabilistic information. Such games are
called games in informational form.
5.1 Games in informational form
The precise denition of games in informational form will not be given in this paper, in
which we focus on a particular type of such games  combinatorial auctions. However, a
typical example is shown in Figure 1.
47

fiMonderer & Tennenholtz

Figure 1: A game in informational form

L1
s1

U1
D1

t1

U2
D2

s2

a1111

R1

L2

a1112
b1111

a1121

a1211

a1212
b1212

b1122

b1121

a1222
b1222

b2112

a2211
b2211

a2212
b2212

b2122

a2221
b2221

a2222
b2222

a1122

a2111

a1221

a2112
b2111

a2121

a2122
b2121

R2

b1211

b1112

b1121

t2

In this game, Player 1 is about to receive one of the signals s1 or t1 , and Player 2 is
about to receive one of the signals10 , s2 or t2 . The true game to be played is determined by
the pair (c1 , d2 ), where c, d  {s, t}. However, neither player knows the exact game. Given
s1 (s2 ) player 1 (player 2) has to choose an action in {U1 , D1 } ({L1 , R1 }), and given t1 (t2 )
player 1 (player 2) has to choose an action in {U2 , D2 } ({L2 , R2 }). The payos are shown
in the gure. A Bayesian game is obtained from a game in informational form by adding a
probability distribution over the pairs of signals as described in Figure 2. The probability
that 1 receives the signal c1 , and 2 receives d2 equals pij , where i = 1 if c = s, i = 2 if c = t,
j = 1 if d = s, j = 2 if d = t.

s2
a1111

s1

U1
D1

L1

Figure 2: A Bayesian Game

t2

R1

b1111
a1121

a1211

b1112

a1212
b1211

a1122
b1121

R2

L2

a1112

a1221

b1122

b1212
a1222

b1121

b1222

p11

t1

U2
D2

a2111

a2112
b2111

a2121

p12

a2211
b2112

a2122
b2121

a2212
b2211

a2221
b2122

a2222
b2221

p21

10. These signals are some times called types.

48

b2212
b2222
p22

fiK-Implementation

A strategy of a player is a function dened on the set of signals, which assigns to every
signal an action11 in the games that are consistent with this signal. For example, in the game
in Figure 1, a strategy of player 1 is a function b1 : {s1 , t1 }  {U1 , D1 , U2 , D2 }, with the
property that b1 (s1 )  {U1 , D1 } and b1 (t1 )  {U2 , D2 }. A strategy of player 2 is analogously
dened as a function b2 : {s2 , t2 }  {L1 , R1 , L2 , R2 }. The concepts of domination and of
equilibrium ( traditionally referred to as ex post equilibrium) are naturally dened. For
example, in Figure 3 The strategy of player 1 in which she chooses U1 when she receives the
signal s1 , and she chooses D2 given t1 dominates each of the other four strategies of player
1.

Figure 3: Domination
R1
5, 2

t2
L2 R2
5, 0 1, 1

D1 0, 5

4, 4

4, 4

0, 5

U2 0, 5

4, 4

4, 4

0, 5

D2 1, 1

5, 0

5, 0

1, 1

L1
U1 1, 1
s1

t1

s2

That is, given s1 , independently of the other players signal and action, choosing U1 is
at least as good as choosing D1 , and for at least one signal and action of Player 2, choosing
U1 is strictly better than choosing D1 .
Figure 4 demonstrate an ex post equilibrium.

11. In an environment in which complex strategies exist, we refer to the choices of a player at a game in
strategic form as actions.

49

fiMonderer & Tennenholtz

Figure 4: Ex Post Equilibrium

L
2, 8

R
5, 1

L
0, 5

R
3, 6

D 1, 5

6, 4

7, 2

1, 4

U 0, 2

5, 2

5, 0

2, 4

1, 1

6, 0

4, 2

3, 3

U

D

Note that even under the output observability assumption a player does not have to
reveal her strategy. The signal of a player is her private knowledge, and she reveals only
the action she chooses. The interested party does not observe the signals; therefore, if the
action sets in all games are the same ( as is the case in Figure 4) the interested party does
not receive any information about the true game to be played. Hence, the only thing he
can do is to use the same vector V at all games. Therefore:
Claim For every k  0 It is impossible to k-implement the ex post equilibrium described
in Figure 4.
Proof The interested party wishes to make U a dominant strategy at the game (s1 , t2 ), and
she wishes to make D a dominant strategy at (t1 , t2 ). Assume V1 (U, L) = x and V1 (D, L) =
y, then the following two contradictory inequalities should be satised: 0 + x  7 + y, and
5 + x  4 + y.
As is stated in the next subsection, when the game in informational form has a particular
structure, our results for the complete information case are generalized.
5.2 The VCG combinatorial auctions
Combinatorial auctions constitute a special class of games in informational form. Our
notations and denitions are taken from Holzman and Monderer (2002).
In a combinatorial auction there is a seller, denoted by 0, who wishes to sell a set of m
goods A = {a1 , . . . , am }, m  1, that she owns. We denote by 2A the family of all bundles
of goods (i.e., subsets of A). There is a set of n buyers N = {1, . . . , n}, n  1. An allocation
of the goods is an ordered partition  = (0 , 1 , . . . , n ) of A.12 We denote by  the set of
all allocations.
12. Note that the goods are allocated among the buyers and the seller. We assume, however, that the seller
derives no utility from keeping any of the goods, and that she does not set strategic reserve prices.

50

fiK-Implementation

A buyers valuation function is a function v : 2A  , satisfying v() = 0 and
B  C, B, C  2A  v(B)  v(C).
When buyer i with the valuation function vi receives the set of goods B, and pays a monetary
transfer ci   his utility is vi (B)  ci . Every buyer knows his valuation function.
We denote by V the set of all possible valuation functions. The set V N , the n-fold
product of the set V , is the set of all proles of valuations v = (v1 , . . . , vn ), one for each
buyer.
For an allocation  = (0 , 1 , . . . , n )   and a prole of valuations v = (v1 , . . . , vn ) 
VN we denote by S(v, ) the total social surplus of the buyers, that is,

S(v, ) =
vi (i ).
iN

We also denote
Smax (v) = max S(v, ),


and we refer to an allocation  that achieves this maximum as an optimal allocation for v.
A Vickrey-Clarke (VC) auction mechanism is described as follows. Every buyer i is re = (
quired to report a valuation function vi . Based on the reported valuations v
v1 , . . . , vn ) 
N
v) = (d0 (
v), . . . , dn (
v))  , which is optimal for
V the mechanism selects an allocation d(
 . Because ties are possible, such an allocation may not be unique, and therefore there is
v
v, d(
v)) = Smax (
v)
more than one VC mechanism. Every function d : V N   satisfying S(
N
  V determines uniquely a VC mechanism, which we refer to as the VC mechafor all v
nism d. This mechanism assigns to buyer i the bundle di (
v) and makes him pay cdi (
v) to
the seller, where


cdi (
v) = max
vj (j ) 
vj (dj (
v)).


j=i

j=i

This represents the loss to the other agents total surplus caused by agent is presence.
A Vickrey-Clarke-Groves (VCG) auction mechanism is parameterized by a VC mechanism d, and by an n-tuple h = (h1 , . . . , hn ) of functions hi : V N \{i}  . The mechanism
selects an allocation according to the allocation function d, and the transfer function of
buyer i is
cd,h
v) = cdi (
v) + hi (
vi ).
i (
Hence, a VC auction mechanism is a special type of VCG auction mechanism, in which hi
is the function that is identically equal to zero for every i.
Let AM = (d, h) be a VCG mechanism. The utility of i with the valuation vi depends
i ), and it is denoted by ui (vi , vi , v
i ). That
 = (vi , v
on the vector of reported valuations v
is,
i ) = vi (di (
ui (vi , vi , v
v))  cd,h
v).
i (
The behavior of buyer i in a mechanism AM is described by a strategy bi : V  V .
51

fiMonderer & Tennenholtz

A strategy bi is a dominant strategy for i if the following two conditions hold:13
i  V N \{i}
 For every vi  V , and for every v
i )  ui (vi , vi , v
i )
ui (vi , bi (vi ), v

for every vi  V .

i  V N \{i} such that
 For every vi  V , there exists v
i ) > ui (vi , vi , v
i ).
ui (vi , bi (vi ), v
A strategy prole (b1 , . . . , bn ) forms an ex post equilibrium if for every prole of valuations v = (v1 , . . . , vn )  VN , and for every buyer i,
ui (vi , bi (vi ), bi (vi ))  ui (vi , vi , bi (vi ))

for every vi  V ,

where bi (vi ) = (bj (vj ))j=i . The prole (b1 , . . . , bn ) is symmetric if bi = bj for every two
buyers i, j  N .
It is well-known that every VCG auction mechanism is truth-telling in the sense that
for every buyer i, the strategy bi (vi ) = vi of revealing the true valuation is a dominant
strategy.14
Special type of strategies were considered by Holzman et al. (2003), Holzman and Monderer (2002). A bundling strategy for buyer i is parameterized by a subfamily i of 2A such
that   i , and is denoted by f i . It maps every v  V to v i  V dened by
v i (B) =

max

CB,Ci

v(C)

for every B  2A .

This has the eect of pretending that the agent cares only about bundles in i (for which
he announces his true valuation), and derives his valuation for other bundles by maximizing
over the bundles in i that they contain.
A valuation v i that satises the above equalities is said to be based on i ( or, simply
i -based). The set of all -based valuation function is denoted by V  .
A subfamily  of 2A such that    is a quasi eld if it satises the following two
conditions:
B    A \ B  ,
B, C   and B  C =   B  C  .
In the work by Holzman and Monderer (2002) it was proven that every ex post equilibrium in the VCG mechanisms is a bundling equilibrium in the following sense: For every
13. In classical mechanism design the second condition is not required. We use it here for the sake of
consistency with the rest of this paper.
14. This is one of the reasons to the fact that the concept of ex post equilibrium in the VCG auction
mechanisms with private values has largely been ignored in the economics literature. However, the truth
telling strategy is induces a high communication complexity; It requires each player to communicate 2m
numbers. Hence, from the computer science perspective, an ex post equilibrium with less communication
complexity is desirable. The tradeo between communication complexity and economic eciency is
discussed by Holzman, Kr-Dahav, Monderer, and Tennenholtz (2003).

52

fiK-Implementation

n  3, every prole (b1 , b2 ,    , bn ) of strategies, which satises that any subprole (bi )iN  ,
N   N , is an ex post equilibrium in all VCG mechanisms is a symmetric prole of bundling
strategies. That is, there exists     2A such that bi = f  for every i  N , and moreover,
it was proved by Holzman et al. (2003) that this  must be a quasi eld.
5.3 0-Implementation of ex post equilibrium in frugal VCG auction
mechanisms
We begin with a formal denition of a frugal VCG combinatorial auction:
Denition of Frugal VCG mechanisms A VCG mechanism (d, h) is called frugal if d
 = (
does not allocate unnecessary goods to the buyers. That is, for every v
v1 , . . . , vn )  V N

the mechanism selects an allocation d(
v) = (d0 (
v), . . . , dn (
v))  , which is optimal for v
and satises in addition:
 For every player i, and for every Bi  i ,
vi (Bi ) < vi (i ),
where i = di (
v).
Intuitively, in a frugal VCG mechanism the center never allocates unnecessary goods.
If an agent has a bid for a bundle B1 and the same bid for a superset of it, B2 , the center
will never allocate B2 to that agent (the bid for B2 should be strictly higher than the bid
for B1 in order that allocating B2 to that agent will be a possibility.)
Consider an interested party who wishes to 0-implement the ex post equilibrium b =
(b1 , b2 ,    , bn ) in the VCG auction mechanism (d, h). Given the result by Holzman and
Monderer (2002) stated at the end of the previous subsection we can assume almost without
loss of generality that bi = f  for every i  N . The interested party wishes to promise a
positive payment to every buyer i whenever he follows the recommendation to play according
to bi , and at least one of the players, say j, does not play according to bj . However, the
interested party does not know the valuation functions. Hence, how could she know whether
a player follows the recommendation? Indeed she cannot. However, since  is known to the
interested party she can partially monitor the players strategies, because, independently of
a players valuation function his reported valuation function must be -based. Hence, the
best the interested party can do is to oer every player i a positive payment if his reported
valuation is -based, and at least one of the other players reported a valuation function,
which is not -based. These payments can be made arbitrarily high so that reporting a
-based valuation function will yield a higher payo for i than any other, non -based
valuation function if at least one of the other players does not report a -based valuation
function. However, player i can cheat within the set of -based valuations without being
caught! It turns out that when the VCG mechanism is frugal, every player is better o not
cheating.
Lemma 1 Let (d, h) be a frugal VCG mechanism, let  be a quasi eld, and let i  N . For
i
every prole of reported valuations of the other players, v
i )  ui (vi , wi , v
i )
ui (vi , vi , v
53

for every wi  V  .

fiMonderer & Tennenholtz

Proof : Without loss of generality we can assume that hj is constantly 0 for every j.
Hence, the VCG mechanism is actually a VC mechanism. If vj is -based for every j, j 	= i,
the inequality follows from the fact that f  induces an ex post equilibrium. However, our
i ) be the allocation chosen by the auctioneer
proof does not use this fact. Let  = d(vi , v


when i reports vi , and let  = d(wi , vi ). Denote

vj (j ).
t = max


j=i

As the VCG mechanism is frugal, we have that i   and i  . Therefore we have
i ) =
that vi (i ) = vi (i ), and vi (i ) = vi (i ). By denition we have that ui (vi , vi , v



i , )  t. Now since vi (i ) = vi (i ) we have that ui (vi , vi , v
i ) = S(vi , v
i , )  t.
S(vi , v
i , )  t  S(vi , v
i , )  t. However, since
By the optimality of  we get that S(vi , v
frugality also implies that vi (i ) = vi (i ), we get the following equation and the desired
inequality:
i , )  t = S(vi , v
i , )  t = ui (vi , wi , v
i ).
S(vi , v
.
Hence, in the proof of Lemma 1 we used the fact that a frugal VCG mechanism must
allocate a subset of goods in  to every player who reports a -based valuation function.
The next example shows that Lemma 1 does not hold for an arbitrary VCG mechanism.
Example
There are two buyers and four goods a,b,c,d.
 = {, ab, cd, abcd}.
The valuation function of 1 is v1 , and the reported valuation of 2 is v2 . Consider a VC
auction mechanism that allocate ab to 1 and cd to 2 when 1 reports v1 , and it allocates abc
to 1, and d to 2, when 1 reports the -based valuation function w1 . In both cases 1 pays
0. Hence, reporting v1 yields a utility of 1, while cheating yields 1.1. Note that the VC
mechanism is not frugal because when 1 declares w1 he receives abc, and w1 (ab) = w1 (abc).

v1
v2
v1
w1


0
0
0
0

a
0
0
0
0

b
0
0
0
0

c
d
ab ac ad bc bd
cd abc abd acd bcd abcd
0
0
1 0
0
0
0
0
1.1
1
0
0
1.1
0 0.75 0 0 0.75 0 0.75 0.75 0 0.75 0.75 0.75 0.75
0
0
1 0
0
0
0
0
1
1
0
0
1.1
0
0
1 0
0
0
0
0.1
1
1
0.1 0.1 1.1

We need the following terminology. Let (d, h) be a VCG combinatorial auction, and let
M > 0. We denote by (d, h, M ) the direct combinatorial auction with the rules induced by
(d, h) in which, the set of feasible valuation functions ( and the set of bids) is V (M ), which
is the set of all valuation functions v satisfying v(A) < M . The assumption of an upper
bound is natural but not common in the literature of mechanism design. It can be veried
that Lemma 1 holds for a VCG combinatorial auctions with bounded valuation functions.
54

fiK-Implementation

Theorem 6 Let (d, h, M ) be a frugal VCG auction mechanism with at least two buyers.
Let  be a quasi elds of bundles. Then the symmetric ex post equilibrium induced by  is
0-implementable.
Proof : For every player i, the interested party promises i a very high payo ( e.g., 2M + 1
if he reports a valuation function in V  , and at least one of the other players does not
report a -based valuation function. Player i is promised no payment if all players report
valuation functions in V  . By Lemma 1, f  is a dominant strategy for every player.

6. Implementation devices
As we mentioned in Section 3, the proof of our result (Theorem 3) that every mixed strategy
equilibrium is 0-implementable relies on the assumption that the interested party observes
the mixed strategies used by the players. In this section we prove this result without this
assumption. That is, the interested party can observe only the actions generated by the
mixed strategies, but not the algorithms that generate them. In order to deal with this
issue we dene a new type of implementation by an implementation device.
Let G(U ) = (N, X, U ) be a nite game in strategic form. An implementation device
for G(U ) is a tuple I = (S, h, V ), where S = S1  S2     Sn , h  (S) is a probability
distribution over S, and V : S  X  n+ . Si is the nite15 set of signals that can be sent to
i. The interested party uses the implementation device I as follows: She makes the device
public, she secretly runs a randomizing scheme that chooses every s  S with a probability
h(s). If s = (s1 , s2 ,    , sn ) is chosen, she sends player i the signal si . If the strategy prole
x is selected then agent i is paid Vi (s, x). The implementation device generates a new game
G(U, I). This is actually a Bayesian game. A strategy for i in this game is a function
bi : Si  Xi . For every si and xi , and a vector bi of the other players let Wi (xi |si , bi ) be
the expected payo of i in the game G(U, I) if it chooses xi given that it receives the signal
si and all other players use bi . That is,
Wi (xi |si , bi ) = Esi (Ui (xi , bi (si )) + Vi (si , si , xi , bi (si )|si ) ,
where si = (sj )j=i , and bi (si ) = (bj (sj ))j=i . A strategy
 bi is a dominant strategy for i
if for every signal si with a positive probability ( that is tS,ti =si h(t) > 0), and for every
bi
Wi (bi (si )|si , bi )  Wi (xi |si , bi ) for every xi  Xi ,
and there exists a prole bi of the other players for which a strict inequality holds.
Every prole b = (bi )iN determines a probability distribution probb over X dened as
follows:
probb (x) = h(b1 = x1 , b2 = x2 ,    , bn = xn ).
15. If S is an innite set, we must specify additional parameters required in probability theory. We associate
with each Si a -algebra of events i , we endow S with the product -algebra, , and we dene h over
.

55

fiMonderer & Tennenholtz

Let  be a desired probability distribution over X. We say that I implements  in G(U ),
if in G(U, I) every player i has a dominant strategy bi , and probb = . We say that I is a
k-implementation of  in G(U ) if I implements , and for every s with h(s) > 0,
n


Vi (si , bi (si ))  k.

i=1

6.1 Mixed Strategies: Removing the algorithm observability assumption
Let p = (p1 , p2 ,    , pn ) be a mixed strategy prole in a nite game G(U ). p generates a
probability distribution p over S as follows:
p (x) = p1 (x1 )p2 (x2 )    pn (xn )

for every x  X.

We say that an implementation device I implements p if it implements p .
In order to implement a mixed strategy equilibrium , the interested party employs an
implementation device I, in which the set of signals Si is the set of actions of i, Xi . h
is the product probability of p. That is, h(x) = p1 (x1 )p2 (x2 )    pn (xn ), and the function
Vi : Si  Xi  + is designated in such a way that the strategy bi (si ) = si , si  Xi , is a
dominant strategy for every player i.
Hence, the interested party ips a coin for each player i according to the probability
pi in the prole she wishes to implement, and she sends the outcome of this coin ipping
to i. Thus, the signals sent to the players are just recommendations to play. The payo
functions Vi , i  N are designed in such a way that obeying the recommendation is a
dominant strategy for every player.
Theorem 7 Let G(U ) be a nite game with at least two actions for every player. Every
mixed strategy equilibrium prole p is 0-implementable in G(U ) with an appropriate implementation device I = (S, h, V ) in which S = X, and h = p is the product probability on X
dened by p.
Proof : Denote by bi the strategy of i in which it obeys every recommendation. That is
bi (si ) = si for every si  Xi . The function Vi should satisfy for every vector di of the other
players strategies,
Wi (si |si , di )  Wi (xi |si , di ) xi  Xi .
We can assume without loss of generality that for every player i, Vi (si , si , xi , yi ) = 0 for
every xi 	= si . Therefore the above inequality can be written as follows:




Esi Vi (si , si , si , di (si ))  Esi Ui (xi , di (si ))  Ui (si , di (si )) .
If di = bi , that is dj (sj ) = sj for every j 	= i and for every sj  Xj , the right-hand-side
of the above inequalities are non-positive because p is a mixed strategy equilibrium. Hence,
we may dene Vi (s, s) = 0 for every s  X. To make sure that the inequalities hold in all
other cases (i.e., for all di ), we can dene Vi (s, si , xi ) = 2M + 1 for every xi 	= si ,
where M > 0 is an upper bound on the absolute value of all players payo functions. The
choice of 2M + 1 (rather then 2M ) ensures the existence of a strict inequality required by
the denition of domination.
56

fiK-Implementation

6.2 0-implementations of correlated equilibrium
Aumann (1974) introduced the concept of correlated equilibrium. We provide one of the
many equivalent denitions:
Denition Let G(U ) = (N, X, U ) be a nite game in strategic form. A correlated equilibrium of G(U ) is a probability distribution  over X (  (X)) such that the strategies
bi (si ) = si , si  Xi , i  N , form an equilibrium in the game G(U, I), where I = (S, h, V ) is
the following implementation device:
 S = X,
 h = ,
 Vi (s, x) = Ui (x) for every i  N and for every s, x  X.
Hence,  forms a correlated equilibrium if a mediator who makes no changes in the
players payo can run a randomization device according to , picks a prole of pure actions
s, and sends every player i the recommendation to play si , and every player is better o
obeying the recommendation if she believes that all other players obey the recommendations.
It is well-known ( and it was implicitly used in the proof of Theorem 7) that if p is a mixed
strategy equilibrium, p is a correlated equilibrium. Moreover, going over the proof of
Theorem 7 reveals that the only property of the mixed-strategy equilibrium p that we use
is the fact that p is a correlated equilibrium. Hence we get:
Theorem 8 Let G(U ) = (N, X, U ) be a nite game with at least two actions for every
player. Every correlated equilibrium prole  is 0-implementable in G(U ) with an appropriate implementation device I = (S, h, V ) in which, S = X and h = .
Note that eventually, when the interested party implements a mixed strategy equilibrium
or a correlated equilibrium with the implementation device I, the players are using pure
strategies in the game G(U, I). Because the expected value operator is linear, it can be
easily seen that obeying the recommendation remains a dominant strategy for every player
even if this player believes that the other players use mixed strategies in G(U, I), where
a mixed strategy of i in G(U, I) is a probability distribution Qi over the set of his pure
strategies. A mixed strategy is not a natural description of behavior in G(U, I). A more
natural, and less computational demanding concept is the one of behavior strategy: A
behavior strategy of i in the game G(U, I) is a function ci : Si  (Xi ). Hence, a player
who is using a behavioral strategy chooses a mixed strategy in a game in strategic form as
a function of his signal, while a player who is using a mixed strategy in G(U, I) is picking a
pure strategy in G(U, I) with a randomization device before he receives the signal. The sets
of mixed and behavioral strategies are not technically related to each other. However, by
Kuhn (1953) ( see also Hart (1992) for details), for every player i, for every strategy bi of i
and for every prole Qi = (Qj )j=i of mixed strategies of the other players, there exists a
prole ci = (cj )j=i of behavioral strategies of the other players such that for every signal
57

fiMonderer & Tennenholtz

si the expected utility of i when using bi given that all other players are using Qi equals
his expected utility when all other players are using ci , and vice versa.16
Hence, theorems 7 and 8 remain valid in an environment that allows the utilization of
either mixed or behavioral strategies in G(U, I).

7. Conclusions, discussion and further research
One may distinguish between two main lines of research in multi-agent systems. One line
of research has to do with the design of mechanisms and protocols. In this context we
in fact deal with the design of games, such that when agents are assumed to behave in
particular way (e.g., be law-abiding, playing in equilibrium, reinforcement learners, etc.)
then a desired behavior (e.g., revenue maximization, the maximization of social surplus,
etc.) will be obtained. The other line of research deals with the study of the behavior of
agents in a given game. In economic theory the leading paradigm in the last decades has
been that agents use equilibrium strategies. However, this paradigm implicitly assumes that
agents are rational and moreover, that agents believe that the other agents are rational.17
In this paper we introduced an intermediate approach. The game/interaction is given,
and agents are not provided with newly designed protocol. The inuence on agents behavior
is only through credible promises for positive monetary transfers conditioned on the actions
selected by the agents in the game. We also assume:
1. Minimal rationality: we would like to assume as little as possible on agent rationality.
Indeed all that we assume is that an agent will not use a strategy if it is dominated
by another strategy.
2. Minimal expenses: we assume that the interested party wishes to minimize its expenses
while leading the agents to the desired behavior.
The notion of k-implementation captures the above basic ideas. In the paper we have
provided several basic results about k-implementation. We have provided full characterization of k-implementation for the case of implementation of singletons in games with
complete information. In particular we have shown a formula for computing the optimal k,
which will yield the desired agent behavior, and fully specied a procedure for implementation. Our result is also applicable to a general class of games with innitely many strategies.
We have shown that such characterization is likely to be impossible for the implementation
of sets of strategies. In particular, we have shown that the problem of whether the desired
behavior can be implemented with a cost of k is NP-hard. This led us to considering exact
k-implementation that we have shown to be tractable. Exact k-implementation requires
that every desirable strategy prole will be rational as a result of the promises for monetary
16. Actually, the theorem presented by Kuhn (1953) is stronger than the one we quote here.
17. In computer science the issue of how should an agent choose its action , unless he has a dominant strategy,
is a central one and no general satisfactory solution is known. Researchers appeal in this case to the
concept of competitive analysis (Borodin & El-Yaniv, 1998). In the context of games, some promising
results in this direction are presented by Tennenholtz (2002).

58

fiK-Implementation

transfers (in addition to the requirement that no undesirable strategy prole will remain
rational). In a sense, exact implementation requires that the number of strategies that
the system will remove will be minimal. This is consistent with basic ideas of normative systems where in order to obtain desired behavior we would like to have minimal laws
that leave maximal freedom to the agents as long as they will enable to obtain the desired
(social) behavior. For a discussion of this issue see (Fitoussi & Tennenholtz, 2000).
The extension of our results to the context of mixed strategies can be interpreted as
a strong evidence for the importance of Nash equilibrium from the normative perspective,
and not only as a descriptive approach that attempts to explain/predict agent behavior in
economic contexts. The fact that any mixed strategy equilibrium can made into a dominant
one with zero payments given that we have a credible interested party, who cannot force
behaviors or punish agents, tells us that in many practical situations Nash equilibrium has
a special merit also from the normative perspective.
The games of incomplete information discussed in this section are games in informational form, rather than Bayesian games. This is in the spirit of work in computer science
that tries to minimize probabilistic assumptions about the economic environment, and in
particular the use of those as part of a solution concept. In this context the VCG mechanisms are probably the most central and widely studied mechanisms and we turn our
attention to the study of k-implementation in the context of these mechanisms. Indeed, as
we show, unlike in the case of nite games with complete information where there is always
some large k that (if paid) can lead to any desired behavior, this is no longer true in games
with incomplete information. The VCG mechanisms turn out to be very complex in their
equilibrium analysis. As recent work has shown (Holzman et al., 2003) there are exponentially many equilibria of the VCG mechanisms that dier from truth telling. These are of
special interest since these other equilibria exhibit lower communication complexity than
the standard truth revealing equilibrium. Notice that these equilibria are obtained without
any restriction on the possible bids by the agents (this is the so called no imposition property). The interested party has no access to the VCG protocol, and can inuence it only
indirectly. We have proved 0-implementation of any ex-post equilibrium of any frugal VCG
mechanism, and that the frugality requirement is necessary.
There are many things left to be done. In particular, it will be interesting to further
develop the study of k-implementation for better understanding the case of k > 0. For
example, it may be interesting to study the eects of the cost of implementation on economic
eciency. Further study of tractable cases is also of interest. We are interested also in
extending our study of k-implementation to games in informational form beyond the VCG
mechanisms. The issue of collusion may have very interesting ramications in the context
of k-implementation. Collusive agreements may make benet of the promises made by the
interested party. Similarly, if failures in the system are possible, then the interested party
might nd itself paying its oers which he was hoping to ignore given rational behavior of
the agents. We have also assumed that there is only one interested party. In a case that
there are several interested parties who may wish to lead to dierent desired behaviors then
a new strategic situation emerges. We believe that these issues are of signicant importance.
We hope to address some of them in future work, and that others will join us in the study of
59

fiMonderer & Tennenholtz

k-implementation and in exploring the spectrum between the system and agent perspectives
in multi-agent systems.

Acknowledgements
We thank Assaf Cohen for helpful comments. The rst author thanks the Israeli Science
Foundation for partial support of this research through a BIKURA grant, and the second
author thanks the Israeli Science Foundations for partial support of this research by ISF
individual grants. A preliminary version of this paper appears in the proceedings of the 4th
ACM Conference on Electronic Commerce (EC03).

References
Aumann, R. (1974). Subjectivity and correlation in randomized strategies. Journal of
Mathematical Economics, 1, 6796.
Borodin, A., & El-Yaniv, R. (1998). On-Line Computation and Competitive Analysis. Cambridge University Press.
Clarke, E. (1971). Multipart pricing of public goods. Public Choice, 18, 1933.
Conitzer, V., & Sandholm, T. (2002). Complexity of mechanism design. In Proceedings of
the 18th conference on uncertainity in Articial Intelligence (UAI-02), pp. 103110.
Dybvig, P., & Spatt, C. (1983). Adoption externalities as public goods. Journal of Public
Economics, 20, 231247.
Feigenbuam, J., & S, S. (2002). Distributed Algorithmic Mechanism Design: Recent Results
and Futute Directions. In Proceedings of the 6th International Workshop on Discrete
Algorithms and Methods for Mobile Computing and Communications, pp. 113.
Fitoussi, D., & Tennenholtz, M. (2000). Choosing Social Laws for Multi-Agent Systems:
Minimality and Simplicity. Articial Intelligence, 119 (12), 61101.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Groves, T. (1973). Incentives in teams. Econometrica, 41, 617631.
Hart, S. (1992). games in extensive and strategic forms. In Aumann, R., & Hart, S. (Eds.),
Handbook of Game Theory, chap. 2, pp. 1940. North Holland, Amsterdam.
Holzman, R., Kr-Dahav, N., Monderer, D., & Tennenholtz, M. (2003). Bundling Equilibrium in Combinatorial Auctions. Games and Economic Behavior, to appear. Working
paper Technion http://ie.technion.ac.il/dov.phtml.
Holzman, R., & Monderer, D. (2002). Characterization of ex post equilibrium in the VCG
combinatorial auctions. Game and Economic Bahavior, to appear. Working Paper,
Technion, http://ie.technion.ac.il/dov.phtml.
60

fiK-Implementation

Koutsoupias, E., & Papadimitriou, C. (1999). Worst-Case Equilibria. In STACS.
Kuhn, H. (1953). Extensive games and the problem of information. Annals of Mathematics
Studies, 48.
Mas-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.
Maskin, E. (1999). Nash equilibrium and welfare optimality. Review of Economic Studies,
66, 2338.
Maskin, E., & Sjostrom, T. (2002). Implementation theory. In Arrow, K. J., Sen, A. K.,
& Suzumura, K. (Eds.), Handbook of Social Choice Theory and Welfare Volume 1.
North-Holland, Amsterdam.
Monderer, D., & Shapley, L. (1996). Potential games. Games and Economic Behavior, 14,
124143.
Naor, M., Pinkas, B., & Sumner, R. (1999). Privacy Preserving Auctions and Mechanism
Design. In Proceedings of EC99, pp. 129139.
Nash, J. (1950). Equilibrium points in n-person games. Proceedings of the National Academy
of Sciences of the United States of America, 36, 4849.
Nisan, N. (2000). Bidding and allocation in combinatorial auctions. In ACM Conference
on Electronic Commerce, pp. 112.
Nisan, N., & Ronen, A. (1999). Algorithmic mechanism design. Proceedings of STOC-99.
Papadimitriou, C. H. (2001). Algorithms,Games,and the Internet. In STOC 2001.
Parkes, D. C. (1999). ibundle: An ecient ascending price bundle auction. In ACM
Conference on Electronic Commerce, pp. 148157.
Rosenschein, J. S., & Zlotkin, G. (1994). Rules of Encounter. MIT Press.
Rosenthal, R. (1973). A class of games possessing pure-strategy nash equilibria. International Journal of Game Theory, 2, 6567.
Roughgarden, T. (2001). The price of anarchy is independent of the network topology. In
Proceedings of the 34th Annual ACM Symposium on the Theory of Computing, pp.
428437.
Roughgarden, T., & Tardos, E. (2002). How bad in selsh routing?. Journal of the ACM,
49 (2), 236259.
Sandholm, T., Suri, S., Gilpin, A., & Levine, D. (2001). Cabob: A fast optimal algorithm for combinatorial auctions. In 17th International Joint Conference on Articial
Intelligence, pp. 11021108.
Segal, I. (1999). Contracting with externalities. The Quarterly Journal of Economics,
CXIV (2), 337388.
61

fiMonderer & Tennenholtz

Shoham, Y., & Tennenholtz, M. (1995). Social Laws for Articial Agent Societies: O-line
Design. Articial Intelligence, 73.
Shoham, Y., & Tennenholtz, M. (2001). On rational computability and communication
complexity. Games and Economic Behavior, 35, 197211.
Spiegler, R. (2000). Extracting intercation-created surplus. Games and Economic Behavior,
30, 142162.
Tennenholtz, M. (1999). Electronic commerce: From game-theoretic and economic models
to working protocols. In IJCAI-99.
Tennenholtz, M. (2002). Competive Safety Analyis: robust decision-making in multi-agent
systems. Journal of Articial Intelligence Research, 17, 363378.
Vickrey, W. (1961). Counterspeculations, auctions, and competitive sealed tenders. Journal
of Finance, 16, 1527.

62

fiJournal of Artificial Intelligence Research 21 (2004) 135191

Submitted 03/03; published 02/04

CP-nets: A Tool for Representing and Reasoning with
Conditional Ceteris Paribus Preference Statements
Craig Boutilier

cebly@cs.toronto.edu

Department of Computer Science
University of Toronto
Toronto, ON, M5S 3H8, Canada

Ronen I. Brafman

brafman@cs.bgu.ac.il

Department of Computer Science
Ben-Gurion University
Beer Sheva, Israel 84105

Carmel Domshlak

dcarmel@cs.cornell.edu

Department of Computer Science
Cornell University
Ithaca, NY 14853, USA

Holger H. Hoos

hoos@cs.ubc.ca

Department of Computer Science
University of British Columbia
Vancouver, BC, V6T 1Z4, Canada

David Poole

poole@cs.ubc.ca

Department of Computer Science
University of British Columbia
Vancouver, BC, V6T 1Z4, Canada

Abstract
Information about user preferences plays a key role in automated decision making. In
many domains it is desirable to assess such preferences in a qualitative rather than quantitative way. In this paper, we propose a qualitative graphical representation of preferences
that reflects conditional dependence and independence of preference statements under a
ceteris paribus (all else being equal) interpretation. Such a representation is often compact
and arguably quite natural in many circumstances. We provide a formal semantics for this
model, and describe how the structure of the network can be exploited in several inference
tasks, such as determining whether one outcome dominates (is preferred to) another, ordering a set outcomes according to the preference relation, and constructing the best outcome
subject to available evidence.

1. Introduction
Extracting preference information from users is generally an arduous process, and human
decision analysts have developed sophisticated techniques to help elicit this information
(Howard & Matheson, 1984). A key goal in the study of computer-based decision support is
the construction of tools that allow the preference elicitation process to be automated, either
partially or fully. Methods for extracting, representing and reasoning about the preferences
of naive users are particularly important in AI applications, ranging from collaborative
c
2004
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiBoutilier, Brafman, Domshlak, Hoos & Poole

filtering (Lashkari, Metral, & Maes, 1994) and recommender systems (Nguyen & Haddawy,
1998) to product configuration (DAmbrosio & Birmingham, 1995) and medical decision
making (Chajewska, Getoor, Norman, & Shahar, 1998). In many of these applications
users cannot be expected to have the patience (or sometimes the ability) to provide detailed
preference relations or utility functions. Typical users may not be able to provide much
more than qualitative rankings of fairly circumscribed outcomes.
In this paper we describe a novel graphical representation, CP-nets, that can be used
for specifying preference relations in a relatively compact, intuitive, and structured manner
using conditional ceteris paribus (all else being equal) preference statements. CP-nets can
be used to specify different types of preference relations, such as a preference ordering
over potential decision outcomes or a likelihood ordering over possible states of the world,
for example, as in Shohams (1987) preference semantics. However, it is mainly the first
typepreferences over the outcomes of decisionsthat motivates the development of CPnets. The inference techniques for CP-nets described in this paper focus on two important,
related questions: how to perform preferential comparison between outcomes, and how to
find the optimal outcome given a partial assignment to the problem attributes.
Ideally, a preference representation should capture statements that are natural for users
to assess, be reasonably compact, and support effective inference. Our conditional ceteris
paribus semantics requires that the user specify, for any specific attribute A of interest,
which other attributes can impact her preferences for values of A. For each instantiation
of the relevant attributesthe parents of Athe user must specify her preference ordering
over values of A conditional on the parents assuming the instantiated values; for instance,
a1 may be preferred to a2 when b1 and c2 hold. Such a preference is given a ceteris paribus
interpretation: a1 is preferred to a2 given b1 and c2 all else being equal. In other words, for
any fixed instantiation of the remaining attributes, an outcome where a1 holds is preferred
to one where a2 holds (assuming b1 and c2 ). Such statements are arguably quite natural
and appear in several places (e.g., in e-commerce applications). For instance, the product
selection service offered by Active Buyers Guide1 asks for (unconditional) ceteris paribus
statements in assessing a users preference for various products. The tools there also ask
for certain semi-quantitative information about preferences. Conditional expressions offer
even greater flexibility.
Preference elicitation is a complex task and is a key focus of work in decision analysis
(Keeney & Raiffa, 1976; Howard & Matheson, 1984; French, 1986), especially elicitation
involving non-expert users. Automating the process of preference extraction can be very
difficult. There has been considerable work on exploiting the structure of preferences and
utility functions in a way that allows them to be appropriately decomposed (Keeney &
Raiffa, 1976; Bacchus & Grove, 1995, 1996; La Mura & Shoham, 1999). For instance, if
certain attributes are preferentially independent of others (Keeney & Raiffa, 1976), one can
assign degrees of preference to these attribute values without worrying about other attribute
values. Furthermore, if one assumes more stringent conditions, often one can construct
an additive value function in which each attribute contributes to overall preference to a
specificdegree (the weight of that attribute) (Keeney & Raiffa, 1976). For instance, it
is common in some engineering design problems to make such assumptions and simply
1. See www.activebuyersguide.com.

136

fiCP-Nets

require users to assess the weights (DAmbrosio & Birmingham, 1995). This allows the
direct tradeoffs between values of different attributes to be assessed concisely. Case-based
approaches have also recently been considered (Ha & Haddawy, 1998).
Models such as these make the preference elicitation process easier by imposing specific
requirements on the form of the utility or preference function. We consider our CP-net representation to offer an appropriate tradeoff between allowing flexible preference expression
and imposing a particular preference structure. Specifically, unlike much of the work cited
above, CP-nets capture conditional preference statements.
The remainder of the paper is organized as follows. Section 2 provides background on
preference orderings, and important notions such as preferential independence and conditional ceteris paribus preference statements. We then define CP-nets, discussing their
semantics and expressive power in depth, and some of the models properties. In Section 3
we present an algorithm for outcome optimization in CP-nets and provide an example of an
application of CP-nets that illustrates the optimization process. Section 4 introduces two
kinds of queries for preferential comparison, namely, ordering and dominance queries, and
investigates their computational properties. Section 5 discusses several general techniques
for answering dominance queries that exploit the structure of a CP-net. In Section 6 we
discuss the applicability of our complexity results and algorithms to a slight generalization
of CP-nets that allow incompletely specified local preferences and/or statements of preferential indifference. Finally, in Section 7 we examine some related work and applications of
CP-nets, and discuss a number of interesting directions for future theoretical research and
applications.

2. Model Definition
Philosophical treatment of many intuitive qualitative preferential statements began in 1957
in a pioneering work of Hallden (1957), and was continued by Castaneda (1958), von Wright
(1963, 1972), Kron and Milovanovic (1975), Trapp (1985), and Hansson (1996). The reason
for such an intensive analysis of these statements is expressed concisely in the opening of
Hanssons (1996) paper:
When discussing with my wife what table to buy for our living room, I said:
A round table is better than a square one. By this I did not mean that
irrespectively of their other properties, any round table is better than any
square-shaped table. Rather, I meant that any round table is better (for our
living room) than any square table that does not differ significantly in its
other characteristics, such as height, sort of wood, finishing, price, etc. This
is preference ceteris paribus or everything else being equal. Most of the
preferences that we express or act upon seem to be of this type. [Emphasis
added.]
An important property of ceteris paribus preferential statements is their intuitive nature
for users of all types. Independently of the work of philosophers in this area, reasoning about
ceteris paribus statements has drawn the attention of AI researchers. For example, Doyle
et al. (1991) introduced a logic of relative desire to treat preference statements under a
ceteris paribus assumption. This logic bears some similarity to von Wrights (1963) logic
137

fiBoutilier, Brafman, Domshlak, Hoos & Poole

of preferences, but supports more complicated inferences.2 However, to the best of our
knowledge, no serious attempt has been made to exploit preferential independence for the
compact and efficient representation of such ceteris paribus statements. In this paper, we
take steps toward structured modeling of qualitative ceteris paribus preferential statements.
We start by defining the notion of a (qualitative) preference relation and a number of
basic preference independence concepts, followed by the introduction of CP-nets and their
semantics.
2.1 Preference Relations
We focus our attention on single-stage decision problems with complete information, ignoring in this paper any issues that arise in multi-stage, sequential decision analysis and any
considerations of risk that arise in the context of uncertainty.3 We begin with an outline of
relevant notions from decision theory. We assume that the world can be in one of a number
of states S and at each state s there are a number of actions As that can be performed. Each
action, when performed at a state, has a specific outcome (we do not concern ourselves with
uncertainty in action effects or knowledge of the state). The set of all outcomes is denoted
by O. A preference ranking is a total preorder  over the set of outcomes: o1  o2 means
that outcome o1 is equally or more preferred to the decision maker than o2 . We use o1  o2
to denote the fact that outcome o1 is strictly more preferred by the decision maker than o2
(i.e., o1  o2 and o2 6 o1 ), while o1  o2 denotes that the decision maker is indifferent to o1
and o2 (i.e., o1  o2 and o2  o1 ). We will use the terms preference ordering and relation
interchangeably with ranking.
The aim of decision making under certainty is, given knowledge of a specific state, to
choose the action that has the most preferred outcome. We note that the ordering  will
vary across decision makers. For instance, two customers might have radically different
preferences for computer system configurations that a sales program is helping them construct.
Often, for a state s, certain outcomes in O cannot result from any action a  As : those
outcomes that can be obtained are called feasible outcomes (given s). In many instances,
the mapping from states and actions to outcomes can be quite complex. In other decision
scenarios, actions and outcomes may be equated: a user is allowed to directly select a
feasible outcome (e.g., select a product with a desirable combination of attributes). Often
states play no role (i.e., there is a single state).
One thing that makes decision problems difficult is the fact that outcomes of actions and
preferences are usually not represented so directly. For example, actions may be represented
as a set of constraints over a set of decision variables. We focus here on preferences. We
assume a set of variables (or features or attributes) V = {X1 , . . . , Xn } over which the
decision maker has preferences. Each variable Xi is associated with a domain Dom(Xi ) =
{xi1 , . . . , xini } of values it can take. An assignment x of values to a set X  V of variables
(also called an instantiation of X) is a function that maps each variable in X to an element of
its domain; if X = V, x is a complete assignment, otherwise x is called a partial assignment.
2. For a more detailed discussion on this issue, we refer the reader to Doyle and Wellman (1994).
3. Such issues include assigning preferences to sequences of outcome states, assessing uncertainty in beliefs
and system dynamics, and assessing the users attitude towards risk.

138

fiCP-Nets

We denote the set of all assignments to X  V by Asst(X). If x and y are assignments to
disjoint sets X and Y, respectively (X  Y = ), we denote the combination of x and y by
xy. If X  Y = V, we call xy a completion of assignment x. We denote by Comp(x) the set
of completions of x. Complete assignments correspond directly to the outcomes over which
a user possesses preferences. For any outcome o, we denote by o[X] the value x  Dom(X)
assigned to variable X by that outcome.
Given a problem defined over n variables with domains Dom(X1 ), . . . , Dom(Xn ), there
are |Dom(X1 )|      |Dom(Xn )| assignments. Thus direct assessment of a preference
function is usually infeasible due to the exponential number of outcomes. Fortunately, a
preference function can be specified (or partially specified) concisely if it exhibits sufficient
structure. We describe certain standard types of structure here, referring to Keeney and
Raiffa (1976) for a detailed description of these (and other) structural forms and a discussion
of their implications. A set of variables X is preferentially independent of its complement
Y = V  X iff, for all x1 , x2  Asst(X) and y1 , y2  Asst(Y), we have
x1 y1  x2 y1 iff x1 y2  x2 y2 .
In other words, the structure of the preference relation over assignments to X, when all
other variables are held fixed, is the same no matter what values these other variables take.
If the relation above holds, we say x1 is preferred to x2 ceteris paribus. Thus, one can
assess the relative preferences over assignments to X once, knowing these preferences do
not change as other attributes vary.
We define conditional preferential independence analogously. Let X, Y, and Z be
nonempty sets that partition V. X is conditionally preferentially independent of Y given
an assignment z to Z iff, for all x1 , x2  Asst(X) and y1 , y2  Asst(Y), we have
x1 y1 z  x2 y1 z iff x1 y2 z  x2 y2 z.
In other words, X is preferentially independent of Y when Z is assigned z. If X is conditionally preferentially independent of Y for all z  Asst(Z), then X is conditionally preferentially
independent of Y given the set of variables Z.
Note that the ceteris paribus component of these definitions ensures that the statements
one makes are relatively weak. In particular, they do not imply a stance on specific value
tradeoffs. Consider two variables A and B that are preferentially independent, so that
the preferences for values of A and B can be assessed separately; for instance, suppose
a1  a2 and b1  b2 . Clearly, a1 b1 is the most preferred outcome and a2 b2 is the least;
but if feasibility constraints make a1 b1 impossible, we must be satisfied with one of a1 b2 or
a2 b1 . We cannot tell which is most preferred using these separate assessments. However,
under stronger conditions (e.g., additive preferential independence) one can construct an
additive value function in which weights are assigned to different attributes (or attribute
groups). Such a decomposition of a preference function allows one to identify the most
preferred outcomes rather readily, and this, as well as some other special forms of preference
structure, are especially appropriate when attributes take on numerical values. For an
extensive discussion of various special forms of preference functions we refer to Keeney and
Raiffa (1976), as well as Bacchus and Grove (1995, 1996) and Shoham (1997).
139

fiBoutilier, Brafman, Domshlak, Hoos & Poole

2.2 CP-Networks
Our representation for preferences is graphical in nature, and exploits conditional preferential independence in structuring preferences of a user. The model is similar to a Bayesian
network (Pearl, 1988) on the surface; however, the nature of the relation between nodes
within a network is generally quite weak (e.g., compared with the probabilistic relations
in Bayes nets). Others have defined graphical representations of preference relations; for
instance Bacchus and Grove (1995, 1996) have shown some strong results pertaining to
undirected graphical representations of additive independence. Our representation and semantics is rather distinct, and our main aim in using the graph is to capture statements
of qualitative conditional preferential independence. We note that reasoning about ceteris
paribus statements has been explored in AI (Doyle et al., 1991; Wellman & Doyle, 1991;
Doyle & Wellman, 1994), though not in the context of network representations or exploiting
preferential independence in a computational fashion.
For each variable Xi , we ask the user to identify a set of parent variables Pa(Xi ) that can
affect her preference over various values of Xi . That is, given a particular value assignment
to Pa(Xi ), the user should be able to determine a preference order for the values of Xi ,
all other things being equal. Formally, given Pa(Xi ) we have that Xi is conditionally
preferentially independent of V  (Pa(Xi )  {Xi }). Given this information, we ask the user
to explicitly specify her preferences over the values of Xi for all instantiations of the variable
set Pa(Xi ). We use the above information to create an annotated directed graph in which
nodes stand for the problem variables, and every node Xi has Pa(Xi ) as its immediate
ancestors. The node Xi is annotated with a conditional preference table (CPT) describing
the users preferences over the values of the variable Xi given every combination of parent
values. In other words, letting Pa(Xi ) = U, for each assignment u  Asst(U), we assume
that a total preorder iu is provided over the domain of Xi : for any two values x and x, either
x ju x0 , x0 ju x, or x ju x0 . For simplicity of presentation, we ignore indifference in our
algorithms. Though treatment of indifference is straightforward semantically, consistency
of arbitrary networks with indifference cannot be assumed, as we discuss in Section 2.5.
Likewise, we assume that CPTs for all variables are fully specified, though we discuss
partially specified CPTs in Section 6.
We call these structures conditional preference networks or CP-networks (CP-nets, for
short).
Definition 1 A CP-net over variables V = {X1 , . . . , Xn } is a directed graph G over
X1 , . . . , Xn whose nodes are annotated with conditional preference tables CPT(Xi ) for each
Xi  V. Each conditional preference table CPT(Xi ) associates a total order iu with each
instantiation u of Xi s parents P a(Xi ) = U.
We illustrate the CP-net semantics and some of its consequences with several small
examples. For ease of presentation, all variables in these examples are boolean, though our
semantics is defined for features with arbitrary finite domains.
Example 1 (My Dinner I) Consider the simple CP-net in Figure 1(a) that expresses my
preference over dinner configurations. This network consist of two variables S and W ,
standing for the soup and wine, respectively. Now, I strictly prefer fish soup (Sf ) to vegetable soup (Sv ), while my preference between red (Wr ) and white (Ww ) wine is conditioned
140

fiCP-Nets

89:;
?>=<
S


?>=<
89:;
W



Sv  Ww 

Sf  Sv




S

Wr 
v

Sf
Sv

Ww  Wr
Wr  Ww




S

Wr 
f

 z 

S

Ww 
f


(a)
(b)

Figure 1: (a) CP-net for My Dinner I: Soup and Wine; (b) the induced preference graph.

on the soup to be served: I prefer red wine if served a vegetable soup, and white wine if
served a fish soup.
Figure 1(b) shows the preference graph over outcomes induced by this CP-net. An arc
in this graph directed from outcome oi to oj indicates that a preference for oj over oi can
be determined directly from one of the CPTs in the CP-net. For example, the fact that
Sv  Wr is preferred to Sv  Ww (as indicated by the direct arc between them) is a direct
consequence of the semantics of CPT(W ). The top element (Sv  Ww ) is the worst outcome
while the bottom element (Sf  Ww ) is the best. 

Example 2 (My Dinner II) Figure 2(a) extends the chain CP-net of Example 1 by adding
the main course M as another variable. In this example, my preference over the options
for the main course is clear: I strictly prefer a meat course Mmc to a fish course Mf c . In
addition, I prefer not to have two fish courses in one dinner; thus my preference between
vegetable and fish soup is conditioned on the main course: I prefer to open with fish soup if
the main course is meat, and with vegetable soup if the main course is fish. As in Example 1,
Figure 2(b) shows the corresponding induced preference graph over outcomes. 

Example 3 (Evening Dress) Figure 3(a) illustrates another CP-net that expresses my preferences for evening dress. It consists of three variables J, P , and S, standing for the jacket,
pants, and shirt, respectively. I unconditionally prefer black to white as a color for both the
jacket and the pants, while my preference between the red and white shirts is conditioned
on the combination of jacket and pants: if they have the same color, then a white shirt
will make my outfit too colorless, thus I prefer a red shirt. Otherwise, if the jacket and the
pants are of different colors, then a red shirt will probably make my outfit too flashy, thus
I prefer a white shirt. Figure 3(b) shows the corresponding preference graph. 
141

fiBoutilier, Brafman, Domshlak, Hoos & Poole

89:;
?>=<
M

Mmc  Mf c


?>=<
89:;
S

Mmc
Mf c


89:;
?>=<
W

Sf
Sv

(a)

Sf  Sv
Sv  Sf

Ww  Wr
Wr  Ww


Mf c  Sf

 Wr 





Mf c  Sf

 Ww 






Mfmc  Sv  Ww 
mmm
mmm
m
m
m
ff vmmm

M

S

W
v
r 
 f c



 Sv  Ww 
Mmc
l
l
l
l
lll
lll
l
l

vll 

Mmc  Sv  Wr 


q
Mmc  Sf  QWQr 
QQQ
QQQ
QQQ
Q
 ~

 Q(
M
 mc  Sf  Ww 
(b)

Figure 2: (a) CP-net for My Dinner II; (b) the induced preference graph.

142

fiCP-Nets



Jw  Pw  Sw 

Jb  Jw




Jw  Pw  Sr 

Pb  Pw

89:;
?>=<
?>=<
89:;
J3
P
33
ff
ff
33
ff
33 ffffff
 ff
89:;
?>=<
S
Jb  Pb
Jw  Pb
Jb  Pw
Jw  Pw

Sr  Sw
Sw  Sr
Sw  Sr
Sr  Sw






Jw  Pb  Sr 
iJb  Pw  Sr 
i
i
i
iiii
iiii
i
i
i
iiii
iiii
i

t
" 
i




Jb  Pw LSw 
Jw  Pb  Sw 
LLL
LL
LLL
LLL
LL
 & 

Jb  Pb  Sw 

(a)

 | 

Jb  Pb  Sr 
(b)

Figure 3: (a) CP-Net for Evening Dress: Jacket, Pants and Shirt; (b) the induced preference graph.

2.3 Semantics
The semantics of a CP-net is straightforward. It is defined in terms of the set of preference
rankings that are consistent with the set of preference constraints imposed by its CPTs.
Definition 2 Let N be a CP-net over variables V, Xi  V be some variable, and U  V
be the parents of Xi in N . Let Y = V  (U  {Xi }). Let iu be the ordering over Dom(Xi )
dictated by CPT(Xi ) for any instantiation u  Asst(U) of Xi s parents. Finally let  be a
preference ranking over Asst(V).
A preference ranking  satisfies iu iff we havefor all y  Asst(Y) and all x, x0 
Dom(Xi ) yxu  yx0 u whenever x iu x0 . A preference ranking  satisfies the CPT
CPT(Xi ) iff it satisfies iu for each u  Asst(U). A preference ranking  satisfies the
CP-net N iff is satisfies CPT(Xi ) for each variable Xi .
A CP-net N is satisfiable iff there is some preference ranking  that satisfies it.
Thus a network N is satisfied by  iff  satisfies each of the conditional preferences expressed
in the CPTs of N under the ceteris paribus interpretation.
Theorem 1 Every acyclic CP-net is satisfiable.
143

fiBoutilier, Brafman, Domshlak, Hoos & Poole

Proof: We prove this constructively by building a satisfying preference ordering. This proof
is by induction on the number of variables. The theorem trivially holds for one variable, as
the total ordering is specified directly by the CP-net.
Suppose the theorem holds for all CP-nets with fewer than n variables. Let N be a
network with n variables. If N is acyclic, there is at least one variable with no parents;
let X be such a variable. Let x1  x2  . . .  xk be the ordering over Dom(X) dictated
by CP T (X). For each xi , construct a CP-net, Ni , with the n  1 variables V  {X} by
removing X from the initial CP-net, and for each variable Y that is a child of X, revising
its CPT by restricting each row to X = xi . By the inductive hypothesis, we can construct
a preference ordering i for each of the reduced CP-nets Ni .
We can now construct a preference ordering for the original network N as follows. We
rank every outcome with X = xi as preferred to any outcome with X = xj if xi  xj
in CPT(X). For any outcomes with identical values xi of X, we rank them according to
the ordering i associated with Ni (ignoring the value of X). It is easy to see that this
preference ordering satisfies N . 
For example, consider the CP-net of Example 1 (Figure 1). Somewhat surprisingly, the
information captured by this network is sufficient to totally order the outcomes:
S f  Ww  S f  Wr  S v  Wr  S v  Ww
since this is the only ranking that satisfies this CP-net. However, this need not be the case
in general, a satisfiable CP-net can be satisfied by more than one ranking. For instance,
consider the CP-net in Figure 4.4 There are two rankings that satisfy this network:
abc  abc  abc  abc  abc  abc  abc  abc
abc  abc  abc  abc  abc  abc  abc  abc
Preferential entailment in a CP-net is defined in a standard way.
Definition 3 Let N be a CP-net over variables V, and o, o0  Asst(V) be any two outcomes. N entails o  o0 (i.e., that outcome o is preferred to o0 ), written N |= o  o0 , iff
o  o0 holds in every preference ordering that satisfies N .
Lemma 2 Preferential entailment is transitive. That is, if N |= o  o0 and N |= o0  o00
then N |= o  o00 .
Proof: If N |= o  o0 and N |= o0  o00 then o  o0 and o0  o00 in all preference rankings
satisfying N . As each of these rankings is transitive, we must have o  o00 in all satisfying
rankings. 
For example, consider the CP-net N in Figure 4(a) and the following three outcomes:
o = abc, o0 = abc, and o00 = abc. The outcomes o and o0 assign the same values to all
variables except of B. In addition, given the value of Pa(B) = {A} in o and o0 , the value of
B in o (B = b) is preferred to the value of B (B = b) in o0 , all else being equal. Therefore,
we have that N |= o  o0 . In the case of o0 and o00 , the same argument with respect to the
4. This is the network from Example 2 (My Dinner II) with the variables renamed.

144

fiCP-Nets

abc

89:;
?>=<
A


  
 abc
 


  t abc
 tt
 zttt

a  a

a
a


?>=<
89:;
B

b  b
b  b

abc


b
b


?>=<
89:;
C

c  c
c  c



abc
t

t
tt
ztt

abc
 

abc KK

KK
KK
%  

(a)

abc

(b)
Figure 4: A simple chain-structured CP-network.
variable C will show that N |= o0  o00 as well. Observe that o  o00 cannot be derived
directly from the CPTs of N . However, from Lemma 2, it follows that this relation can be
inferred by taking the transitive closure of the direct relations o  o0 and o0  o00 .
Notice that, given a CP-net, we can assess each outcome in terms of the conditional
preferences it violates. For example, in the CP-net of Example 1: the outcome Sf  Ww
violates none of the preference constraints; Sf  Wr violates the conditional preference for
W ; Sv Wr violates the preference for S; and Sv Ww violates both. Somewhat surprisingly,
the ceteris paribus semantics implicitly ensures that violating the preference for S is worse
than violating that for W , since Sf  Wr  Sv  Wr . That is, the parent preferences have
higher priority than the child preferences. This property has important implications for
inference as we will see below.
2.4 Cyclic Networks
As mentioned, nothing in the semantics of the CP-net model forces it to be acyclic. However,
according to Theorem 1, the acyclicity of the network automatically confers an important
property to the model: the network is satisfiable (i.e., there exists a preference ordering
that satisfies all ceteris paribus preference assertions imposed by the CPTs).
For cyclic CP-nets, the situation is much more complicated. For example, consider a
binary-valued cyclic CP-net structure in Figure 5(e). If the CPTs for this network are
specified as in Figure 5(a), then the induced preference graph (see Figure 5(b)) can be
extended to a complete preference ordering consistently. However, if the CPTs are specified
as in Figure 5(c), then the network is unsatisfiable (the induced preference graph, shown in
145

fiBoutilier, Brafman, Domshlak, Hoos & Poole

Figure 5(d) cannot be completed consistently). This example shows that the consistency of
cyclic CP-nets is not guaranteed, and depends on the actual nature of the CPTs.

a1 : b1  b2
a2 : b2  b1
b1 : a1  a2
b2 : a2  a1

a2 b1F
a1 b1

(a)
a1 : b1  b2

a1 b2

FF xx
FxFx
xx FFF
x
 |x
" 

a2 b2

(b)
a1O b1

/ a1 b2

a2 b1 o

a2 b2

a2 : b2  b1
b1 : a2  a1
b2 : a1  a2
(c)

?>=<
89:;
AU


?>=<
89:;
B



(d)

(e)

Figure 5: Examples of a satisfiable and an unsatisfiable cyclic CP-net over binary variables.

Recently, initial results on consistency testing for cyclic CP-nets were presented by
Domshlak and Brafman (2002a). In particular, a wide class of cyclic, binary-valued CPnets was identified to be efficiently testable for consistency. However, these results cover
only part of the spectrum, and further research on cyclic CP-nets is needed.
Beyond the open computational questions that cyclic CP-nets raise, their usefulness
requires further analysis. One can argue that it is possible to cluster the variables to
preserve acyclicity. Although this approach is technically feasible and probably useful in
many domains, it cannot provide a general solution. First, such clustering will affect the
space requirements of problem description and thus, it will generally degrade the efficiency
of reasoning about preferences. Second, in certain domains, it may be more natural to
express cyclic preferences even if an acyclic representation could be used. For example,
this seems to be the case in work on preference-based presentation of web page content
(Domshlak, Brafman, & Shimony, 2001), where it is argued that the preferred presentation
of a certain component of a web page may depend on the presentation of its neighbors in
the page, whose preferred presentation depend on its presentation, and so on.
One could argue that preferences naturally exhibit cyclic structure and that acyclic nets
are of theoretical interest only. Our experience indicates the opposite. Acyclic CP-nets are
shown to be effective and natural in the above-mentioned work on web page presentation
(Domshlak et al., 2001), as well as in a related project that deals with the presentation
of multi-media content in a medical domain (Gudes, Domshlak, & Orlov, 2002)a more
extensive example from this latter domain is presented in the next section. Moreover, in
other domains, we have found it difficult to generate intuitively reasonable cyclic networks.
This is due to the fact that a cycle implies that all variables in it are equally important.
146

fiCP-Nets

Typically, this is not the case. Thus, because of the apparent utility of acyclic networks,
the fact that we can use composite variables made by clustering primitive variables, and
the additional complexity involved in cyclic networks, we consider only acyclic CP-nets in
the remainder of this paper. However, further investigation of cyclic CP-nets, as well as a
characterization of the different classes of utility functions that can be represented by cyclic
and acyclic networks, remains of interest.
2.5 Indifference
We have so far assumed that the preference constraints in each CPT of a CP-net totally
order the outcomes of the variable in question. Specifically, for any variable Xi with parents
U, and any u  Asst(U), we assume that iu is a total order over Dom(Xi ). The general
definition of a CP-net can allow an arbitrary total preorder iu over Dom(Xi ), thus allowing
the user to express indifference between two values of variable X, say x and x0 , given u.
We denote this by x  x0 in CPT(X).
It turns out that the ceteris paribus semantics is quite strong when we say that two
variable values are equally preferred.
Example 4 Consider the following two CPTs for a network over variables A and B, with
A being a parent of B:
a  a;
a : b  b; a : b  b;
These assert that the user is indifferent between a and a, but should a hold, prefers b, and
should a hold, prefers b. We can derive the following preferences over outcomes:
ab  ab  ab  ab  ab
These statements are not consistent with any preference ranking, hence this network is not
satisfiable. One way to interpret this is that if someone really did have the preferences:
a : b  b; a : b  b;
they cannot be indifferent between a and a, ceteris paribus. 
This points to a potential difficulty with the use of indifference in CP-nets. One must
be careful not to express indifference between two values of a variable (A in this case), yet
express a (strict) conditional preference for a child of that variable (B) that depends on the
values for which the user is indifferent. Intuitively, in this case, it seems that the user is
expressing the fact that they would like the value of B to match that of A (with respect to
their sign), but intends no preference for ab over ab (or vice versa). If this is the case,
then making A a parent of B expresses that the preference for B is subsidiary to that of A,
which is not the intent. In this case, either a cyclic network (indeed the satisfiable network
discussed in Section 2.4) or the clustering of variables A and B seems appropriate.
Despite this, indifference can be used safely as follows. Let Xi be any variable in
network N with parents U, and let Xj be any child of Xi . Let Y denote the remaining
147

fiBoutilier, Brafman, Domshlak, Hoos & Poole

parents of Xj (those excluding Xi ). Suppose that for some u  Asst(U), and x, x0 
Dom(Xi ), we have x  x0 in iu . Then as long as the local orderings in CPT(Xj ) for a fixed
instantiation of Y are identical whether x or x0 holds, then the network N is satisfiable.
More precisely, if jxy =jx0 y for each y  Asst(Y), then network N is satisfiable. Thus,
if we are indifferent between x and x0 , then our preferences over values of Xi s children,
should exhibit indifference whether the context includes x or x0 .5
For simplicity of presentation, for the remainder of the paper we continue to assume that
preference constraints in each CPT of a CP-net totally order the outcomes of the variable in
question. However, in Section 6, we do discuss the applicability of our results to satisfiable
CP-nets that capture statements of preferential indifference.

3. Outcome Optimization
One of the principal properties of CP-nets is that, given a CP-net N , we can easily determine
the best outcome among those preference rankings that satisfy N . We call such a query an
outcome optimization query. This turns to be a simple task in CP-nets.
3.1 An Algorithm for Outcome Optimization
Intuitively, to generate an optimal outcome we simply need to sweep through the network
from top to bottom (i.e., from ancestors to descendents) setting each variable to its most
preferred value given the instantiation of its parents. Indeed, while the network does not
generally determine a unique ranking, it does determine a unique best outcome (assuming no
indifference). More generally, suppose we are given evidence constraining possible outcomes
in the form of an instantiation z of some subset Z  V of the network variables. Determining
the best completion of z (that is, the best outcome consistent with z) can be achieved in a
similar fashion, as we now outline.
Outcome optimization queries can be answered using the following forward sweep procedure, taking time linear in the number of variables. Assume a partial instantiation
z  Asst(Z), and the goal of determining the (unique) o  Comp(z) such that N |= o  o0
for all o0  Comp(z)  {o}. This can be effected by a straightforward sweep through the
network. Let X1 , . . . , Xn be any topological ordering of the network variables. We set
Z = z, and instantiate each Xi 6 Z in turn to its maximal value given the instantiation of
its parents. This procedure exploits the considerable power of both the ceteris paribus semantics and the graphical modeling of the preferential statements to easily find an optimal
outcome given certain observed evidence (or imposed conjunctive constraints).
Lemma 3 The forward sweep procedure constructs the most preferred outcome in Comp(z).
Proof: Let vz be any outcome in the set of completions of z. Define a sequence of outcomes
vi , 0  i  n, as follows: (a) v0 = vz ; (b) if Xi 6 Z, vi is constructed by setting the
value of Xi to its most preferred value given the instantiation of its parents in vi1 , with
all other variables retaining their values from vi1 ; (c) if Xi  Z, then vi = vi1 . By
construction, vi  vi1 . The last outcome vn is precisely that constructed by the forward
5. This restriction can be relaxed somewhat if we take into account the fact that some of Xj s parents could
lie in the set U, in which case these rankings need not agree for every indifference pair x and x0 .

148

fiCP-Nets

sweep algorithm. Notice that we arrive at the same outcome irrespective of our starting
point vz (by assumption, there can be no ties). Since vn  vz for any outcome vz consistent
with the evidence, the forward sweep procedure yields the optimal outcome. 
3.2 An Example Application
We now turn to an illustration of the use of CP-nets in the context of a CP-net based system
for adaptive multimedia document presentation. Applications based on this system for the
presentation of web-based content and multi-media medical data were recently presented
by Domshlak et al. (2001) and Gudes et al. (2002). Through this example we demonstrate
the simplicity of preference specification using CP-nets, the utility of acyclic networks, and
the use of the optimization algorithm described above.
The system consists of two toolsthe authoring tool, and the viewing tool. The central
part of the authoring tool is a module for the specification of a CP-net corresponding to
the created and/or edited multimedia document. Using this CP-net, a content provider
express her preferences regarding the presentation of the document content. For example,
the content provider may prefer that some material be presented if and only if some other
material is not presented. The result of such preference-based multimedia document design
is a meta-document specifying both what to present and how to present it.
The description of the content providers preferences, as captured by an acyclic CP-net,
becomes a static part of the document, and sets the parameters for its initial presentation.
Given such a document, the viewing tool is responsible for reasoning about these preferences;
specifically, it must determine an optimal reconfiguration of the document context after
interaction of the viewer with the document. In this process, the users k most recent
content choices are viewed as constraints of the form these items must appear as I specified.
Subject to these constraints, an optimal document presentation with respect to the content
providers CP-net must then be generated. Thus, for each particular session, the actual
presentation changes dynamically based on the users choices. More precisely, whenever
new user input is obtained, the optimization algorithm constructs the best presentation of
all document components with respect to the content providers preferences among those
presentations that conform to the users recent viewing choices. This process uses the
forward sweep procedure described above.
Example 5 (Multimedia Document) Consider a medical record that consists of six components: two components correspond to a set of medical tests conducted in 2001an X-ray
image and textual notes of a physicianand four components correspond to a set of medical
tests from 2002a CT (computerized tomography) image, an X-ray image, a graph illustrating results of electromyography, and textual notes of a physician. For the purposes of
illustration, we assume the preferences of a content provider (e.g., the latter physician) over
the presentation options of these components can be captured using the CP-net shown in
Figure 7. The specific details of the preferencesthe nature of the preferential dependencies
and the precise details of the CPTs are summarized as follows:
 CT-image [CT image, 2002] consist of four CT images of different parts of the body,
and it is shown in Figure 6(a). There are six presentation options for CT-image: it can
be either completely presented (ctplain ), or completely hidden (cthide ), or presented by
149

fiBoutilier, Brafman, Domshlak, Hoos & Poole

(a)

(b)

(c)

(d)

Figure 6: Document components in Multimedia Document example.


CTimage
GG 
GG
GG
GG
GG
GG
 #

Xray
ww
ww
w
w
ww
ww
w

  {w


Graph
Xrayold

   
Notes




Notesold

Figure 7: Multimedia Document CP-net.
a zoom-in on one of its four parts (ctlt , ctrt , ctlb , and ctrb , standing for left-top, righttop, left-bottom, and right-bottom parts, respectively). The physicians preference
over the presentation options of CT-image is unconditional:
cthide  ctlt  ctrt  ctlb  ctrb  ctplain
 X-ray [X-ray, 2002] can be either hidden (xrayhide ), or presented as is (xrayplain ), or
presented after a segmentation (xraysegm ); the image and its segmentation are depicted
in Figures 6(b) and 6(c), respectively. The preference over the presentation options
of X-ray depends on the presentation of CT-image:
ctplain
(ctplain  cthide )
cthide

xrayhide  xrayplain  xraysegm
xrayplain  xraysegm  xrayhide
xraysegm  xrayplain  xrayhide
150

fiCP-Nets

 Graph [Electromyography, 2002] is shown in Figure 6(d), and it can be either presented
(graphplain ), or hidden (graphhide ). The preference over the presentation options of
Graph depends on the presentation of both CT-image and X-ray:
(ctlt  ctrt  ctlb  ctrb )  xraysegm
otherwise

graphplain  graphhide
graphhide  graphplain

 Notes [Textual notes, 2002] can be either fully presented (notesplain ), or summarized
(notessumm ), or omitted all together (noteshide ). The preference over the presentation
options of Notes depends on the presentation of both CT-image and Graph:
cthide
(cthide )  graphplain
otherwise

noteshide  notessumm  notesplain
notessumm  notesplain  noteshide
noteshide  notessumm  graphplain

 X-ray-old [X-ray, 2001] can be either hidden (xrayoldhide ), or presented as is (xrayoldplain );
the image is depicted below. The preference over the presentation options of X-ray-old
depends on the presentation of X-ray:

xrayhide
(xrayhide )

xrayoldhide  xrayoldplain
xrayoldplain  xrayoldhide

 Notes-old [Textual notes, 2001] can be either presented (notesoldplain ), or omitted
all together (notesoldhide ). The preference over the presentation options of Notes-old
depends on the presentation of X-ray-old:
xrayoldhide
xrayoldplain

notesoldplain  notesoldhide
notesoldhide  notesoldplain


At the beginning of a viewing session, the initial presentation of the document, depicted
in Figure 8(a), is determined using the forward sweep procedure with Z = : each component is set to its preferred presentation given the presentation of its immediate parents in
the CP-net. For example, CT-image is hidden, since it is the most preferred option for this
component. Subsequently, the X-ray image is presented segmented, since CT-image is not
presented, and, in turn, the electromyography Graph is presented because of the above decision on the presentation options for CT-image and X-ray. Suppose that the viewer chooses
151

fiBoutilier, Brafman, Domshlak, Hoos & Poole

ct 
 hide MM
MMM
MMM
M&
xray

 segm 
q
q
qqq
qqq

q
x


 

graphplain  xrayoldplain

" 
notes
 

plain  notesold hide 


(a)
NNN
NNN
NNN
&
xray

 plain 
q
qq
qqq
q
q
 xq  



graphplain  xrayoldplain
ctrt


# 

notes
 
summ  notesold hide 


(b)
OOO
OOO
OOO
O'
xrayhide
pp
p
p
pp
 xppp 



graphplain  xrayoldhide 
ctrt


# 

notes
 
summ  notesold plain 


(c)
ctplain

MMM
MMM
MMM
&
xrayhide
qq
qqq
q
q
 xqq 



graphhide  xrayoldhide 

# 

notes
 
hide  notesold plain 


(d)
Figure 8: Document presentations after various user choices.

152

fiCP-Nets

to look at the right-top part of the CT-image.6 In terms of the forward sweep procedure,
this choice sets Z = {CTimage}, and z = {ctrt }. The result of the forward sweep procedure appears in Figure 8(b); here and in what follows, the shaded nodes stand for the
evidence-constrained variables Z. Now, the X-ray image is presented without segmentation
because of a zoom-in on the right-top part of CT-image, and Notes are summarized since
both the electromyography Graph is presented, and CT-image is not hidden.
Suppose that the viewer consequently chooses to hide the X-ray image. If the number
of recent viewer choices taken to constrain the presentation is greater than one, then this
choice will set Z = {CTimage, Xray}, and z = {ctrt , xrayhide }. The result of the forward
sweep procedure appears in Figure 8(c). If consequently the viewer chooses to see the whole
CT-image, then z = {ctplain , xrayhide }, and the updated presentation is shown in Figure 8(d).

4. Comparing Outcomes
Outcome optimization is not the only task that should be supported by a preference representation model. Another basic query with respect to such a model is preferential comparison between outcomes. Two outcomes o and o0 can stand in one of three possible relations
with respect to a CP-net N : either N |= o  o0 ; or N |= o0  o; or N 6|= o  o0 and
N 6|= o0  o.7 The third case, specifically, means that the network N does not contain
enough information to prove that either outcome is preferred to the other (i.e., there exist
preference orderings satisfying N in which o  o0 and in which o0  o). There are two
distinct ways in which we can compare two outcomes using a CP-net:
1. Dominance queries  Given a CP-net N and a pair of outcomes o and o0 , ask whether
N |= o  o0 . If this relation holds, o is preferred o0 , and we say that o dominates o0
with respect to N .
2. Ordering queries  Given a CP-net N and a pair of outcomes o and o0 , ask if N 6|=
o0  o. If this relation holds, there exists a preference ordering consistent with N in
which o  o0 . In other words, it is consistent with the knowledge expressed by N to
order o over o0 (i.e., assert that o is preferred to o0 ). In such a case we say o is
consistently orderable over o0 with respect to N .
Ordering queries are clearly weaker than dominance queries. Indeed, if N |= o  o0 ,
then N 6|= o0  o. But it may be the case that N 6|= o0  o even though N 6|= o  o0 .
While dominance queries are typically more useful, ordering queries are sufficient in many
applications where one may be satisfied knowing only that outcome o can be consistently
ordered over o0 . For example, consider a set of products that a human or automated seller
would like to present to a customer in some non-increasing order of customer preference.
There seems to be no reason to use the strong dominance relation to sort such products.
In some applications, dominance queries cannot be replaced by ordering queries. For instance, dominance queries were shown to be an integral part of constraint-based preferential
optimization in CP-nets (Boutilier, Brafman, Geib, & Poole, 1997).
6. A document explorer (which is a part of the viewing tool) is not illustrated here in order to make the
snapshots smaller.
7. Recall that, for the time being, we do not consider CP-nets with indifference in CPTs; hence two outcomes
cannot be proven equally preferred.

153

fiBoutilier, Brafman, Domshlak, Hoos & Poole

We begin by showing that ordering queries with respect to acyclic CP-nets can be
answered in time linear in the number of variables. In addition, we show that a set of
outcomes can be sorted in a consistent non-increasing order with respect to an acyclic
CP-net using ordering queries only. We then provide a complexity analysis of dominance
queries. First, we introduce and study a particular form of reasoning, namely search for
flipping sequences, that can be used to answer dominance queries. Using this technique,
and focusing on binary-valued CP-nets, we show connections between the structure of the
CP-net graph and the worst-case complexity of dominance queries. We discuss dominance
queries in more detail in Section 5, where we present some general search techniques for
flipping sequences.
4.1 Ordering Queries Are Easy
Here we show that ordering queries with respect to acyclic (not necessarily binary-valued)
CP-nets can be answered in time linear in the number of variables. The corresponding
algorithm exploits the graphical structure of the model. Likewise, we show that with acyclic
CP-nets, we can construct a non-increasing ordering over outcomes, consistent with a CPnet, using only ordering queries.
Corollary 4 Let N be an acyclic CP-net, and o, o0 be a pair of outcomes. If there exists a
variable X in N , such that:
1. o and o0 assign the same values to all ancestors of X in N , and
2. given the assignment provided by o (and o0 ) to Pa(X), o assigns a more preferred
value to X than that assigned by o0
then N 6|= o0  o.
Proof: The construction in Theorem 1 provides a preference ordering satisfying N such
that o  o0 . Thus o0  o is not true in all models of N , and is not a consequence of N . 
Corollary 4 presents a condition which is sufficient but not necessary for the truth of the
ordering query N 6|= o0  o. For instance, consider Example 2, and let o = Mmc  Sv  Ww
and o0 = Mf c Sv Wr . These two outcomes are incomparable according to the CP-network
(i.e., neither can be proven to be preferred to the other), but o 6 o0 cannot be deduced
using the conditions of Corollary 4, because M is the root variable of this chain CP-net,
and o assigns it a more preferred value than that assigned by o0 .
Despite the fact that the condition provided by Corollary 4 for N 6|= o0  o is not
necessary for consistent orderability, we can show that it is sufficient to provide a consistent
ordering of any pair of outcomes.
Theorem 5 Given an acyclic CP-net N , and two outcomes o and o0 over the variables of
N , the complexity of determining truth of at least one of the ordering queries, N 6|= o0  o
or N 6|= o  o0 , is O(n).
Proof: For any variable Xi , let Pa(Xi ) = U in N and u and u denote the assignment
to U made by outcomes o and o0 , respectively. All variables Xi , such that o and o0 assign
different values to Xi but the same values to all ancestors of Xi in N , can be identified in
154

fiCP-Nets

O(n) time by a top-down traversal of N . (Note that u = u0 for all such Xi ). If for all such
Xi we have that o[Xi ] iu o0 [Xi ], then using Corollary 4 we can deduce that N 6|= o0  o.
Otherwise, there exist two variables of this type, Xi and Xj , for which o[Xi ] iu o0 [Xi ] and
o[Xj ] iu o0 [Xj ]; in this case, Corollary 4 implies that both N 6|= o0  o and N 6|= o  o0

Corollary 4 provides an effective algorithm for answering ordering queries; however,
its computational efficiency comes at a price: it is soundif the algorithm says that o is
consistently orderable over o0 , then indeed, N 6|= o0  o; but it is incompleteif it provides a
negative response to query N 6|= o0  o, it still may be the case that N 6|= o0  o. Theorem 5
provides an effective algorithm that is sound, and partially complete in the sense that it
will return a positive answer for at least one of N 6|= o0  o or N 6|= o  o0 . In other words,
it will allow us to determine that at least one outcome can be consistently ordered over the
other.
Though the incompleteness of the algorithm for single ordering queries is problematic,
the partial completeness of the algorithm for paired queries is sufficient to allow one to
find a consistent ordering of all outcomes in polynomial time, at least in the case of an
acyclic CP-net. We first introduce some notation. We write N `oq o  o0 to represent
that the algorithm for paired ordering queries tells us that N 6|= o0  o holds (i.e., o is
consistently orderable over o0 ) but N 6|= o0  o does not (i.e., o0 is not orderable over o).
When N `oq o  o0 , we can be assured that o is indeed orderable over o0 ; but due to the
incompleteness of the algorithm, we cannot be sure that o0 is not orderable over o. We write
N `oq o ' o0 to denote that the algorithm returns a positive response for both ordering
queries (i.e., it tells us that both outcomes are consistently orderable over the other). The
soundness of the algorithm ensures that both outcomes can indeed be consistently preferred
in this case. Note that partial completeness ensures that either N `oq o  o0 , N `oq o0  o,
or N `oq o ' o0 . This will be sufficient to allow us to produce a consistent ordering of any
set of outcomes.
Theorem 6 Given an acyclic CP-net N over the variable set V, and a set of outcomes
o1 , . . . , om over V, ordering these outcomes consistently with N can be done using ordering
queries only.
Proof: Define two binary relations over outcomes: o  o0 iff N `oq o  o0 and o ' o0 iff
N `oq o ' o0 . We first show that the transitive closure of the relation  is asymmetric.
Assume to the contrary that there exists a set of outcomes o1 , . . . , ok such that:
o1  o2      ok  o1

(1)

For 1  i  k, let V (oi ) be the set of all variables X such that the value assigned to X by oi
can be improved given the assignment provided by oi to Pa(X). Let Ni be the subgraph of N
consisting of those variables in V (oi ) and their descendants in N . Observe that Corollary 4
implies Ni  Ni+1 for 1  i < k, and Nk  N1 . To see this, notice that if, for some i, we
have Ni 6 Ni+1 , then there exists a variable X such that: (i) all ancestors of X are assigned
their most preferred values by both oi and oi+1 ; and (ii) given oi [Pa(X)] = oi+1 [Pa(X)],
X is assigned its most preferred value by oi+1 and one of its less preferred values by oi .
155

fiBoutilier, Brafman, Domshlak, Hoos & Poole

However, in this case, an ordering query will determine N 6|= oi  oi+1 , which contradicts
our assumption that oi  oi+1 .
If one of the graph containment relations Ni  Ni+1 is strict, the initial assumption (1)
is trivially contradicted. Therefore, we are left with the case of:
N1 = N2 =    = Nk = N 0
Recalling that N 0 is acyclic, consider a variable Xj  N 0 that has no ancestors in N 0 . Let
U = Pa(Xj ) be the parents of Xj in the original network N (note that U  N 0 = ). By
construction of the Ni we have:
o1 [U] = o2 [U] =    = ok [U] = u
This must be the case since all the ancestors of Xj are assigned to their unique optimal
assignment (of which u is a part) since none of these variables is improvable. This entails
o1 [Xj ] ju o2 [Xj ] ju    ju ok [Xj ] ju o1 [Xj ],
which is inconsistent with the definition of a CP-net.
We exploit the asymmetric nature of the relation  as follows. If N |= o  o0 , then we
must have o  o0 . Therefore, the relation N representing the induced preference graph
of N is a subset of . Thus any total ordering of o1 , . . . , om consistent with  will be
consistent with N . 
An immediate consequence of Theorems 5 and 6 is that, given a set of m outcomes and
a CP-net N , the complexity of ordering these outcomes consistently with the preference
graph induced by N is O(nm2 ) (i.e., the cost of comparing every pair of outcomes and
ordering them accordingly).
4.2 Dominance Queries and Flipping Sequences
The ceteris paribus semantics of CP-nets allows one to directly use information in the
CPT of a variable X to alter or flip the value of X within an outcome to directly obtain
an improved (preferred) or worsened (dispreferred) outcome. A sequence of improving flips
from one outcome to another provides a proof that one outcome is preferred, or dispreferred,
to another in all rankings satisfying the network. Before defining this notion more precisely,
we illustrate the intuitions with an example.
Example 6 Consider again the CP-net from Figure 4. The following are the only two
rankings that satisfy this network:
z }| {
abc  abc  abc  abc  abc  abc  abc  abc
abc  abc  abc  |abc {z
 abc}  abc  abc  abc
Thus, the only two outcomes not totally ordered are abc and abc. Notice that if we remove
either abc or abc from each of these chains of outcomes, we can move from one outcome to
the next in the chain by flipping the value of exactly one variable according to the preference
156

fiCP-Nets

information in its CPT given the instantiation of its parents. For example, to move from
the first outcome in these sequences (abc) to the second (abc), we use the fact that c  c
given b to prove that the second outcome is dispreferred to the first; that is we flip C to
a less preferred value given the instantiation b of its parent B. Conversely, we can move
backwards through this sequence by flipping c in the second outcome to c, thereby obtaining
the more preferred first outcome.
Recall that Corollary 4 demonstrates that violating the preference constraints for a
parent variable is less preferred than violating the preference constraints for any of its
children. This greater importance of parent variables is implicit in the ceteris paribus
semantics. Now consider the two outcomes abc and abc, which are unordered by the CPnet in Figure 4. The outcome abc violates the preference over the values of A, while the
outcome abc violates the preferences over the values of B and C; and A is an ancestor
of both B and C. The semantics of CP-nets does not specify which of these outcomes is
preferredintuitively, though the preference for A has higher priority than B or C, two
or more violations of lower priority preferences may not be preferred to the violation of a
single higher priority preference. 
For any two outcomes o and o0 , every improving flipping sequence from o0 to o uniquely
corresponds to some directed path from the node o0 to the node o in the preference graph
induced by the CP-net. For instance, consider the CP-net in Figure 9(a), which is exactly
the network of the Evening Dress example (Example 3), with simpler variable names.
There are four alternative flipping sequences from the outcome abc to the outcome abc,
corresponding to the four paths between these outcomes in the induced preference graph,
depicted in Figure 9(b):
abc  abc  abc
abc  abc  abc  abc  abc
abc  abc  abc
abc  abc  abc  abc  abc
Therefore, abc  abc is a consequence of this CP-net. In contrast, there is no flipping
sequence (directed path) from abc to abc, hence these two outcomes are incomparable.
These examples suggest that the construction of such a flipping sequence can be used
to prove dominance.
Definition 4 Let N be a CP-net over variables V, with Xi  V, U the parents of Xi ,
and Y = V  (U  {Xi }). Let uxy  Asst(V) be any outcome, where x  Dom(Xi ),
u  Asst(U), and y  Asst(Y). An improving flip of outcome uxy with respect to variable
Xi is any outcome ux0 y such that x0 iu x. (Note that an improving flip w.r.t. Xi does not
exist if x is the most preferred value of Xi given u.)
An improving flipping sequence with respect to N is any sequence of outcomes o1 , . . . , ok
such that, for each i < k, oi+1 is an improving flip of oi with respect to some variable. An
improving flipping sequence from an outcome o to an outcome o0 is any improving sequence
o1 , . . . , ok with o1 = o and ok = o0 .
157

fiBoutilier, Brafman, Domshlak, Hoos & Poole

a  a

b  b

abc


89:;
?>=<
?>=<
89:;
A3
B
33
ff
ff
33
ff
33 ffffff
 ff
89:;
?>=<
C
ab
ab
ab
ab

abc




abc

abc
jjjj

jj
jjj j
j
j
j
tjj
abc
abc JJ
JJ
JJ
%  


c  c
c  c
c  c
c  c

abc

 }

abc
(b)

(a)

Figure 9: Evening Dress CP-net from Example 2 with simpler names.
One can define worsening flips and worsening flipping sequences in an entirely analogous
way. Obviously, any worsening flipping sequence is the reverse of an improving flipping
sequence, and vice versa.
There are two important things to notice about the examples above. First, an improving (or worsening) flipping sequence can be used to show that one outcome is better than
another. Second, preference violations are worse (i.e., have a larger negative impact on the
preference of an outcome) the higher up they are in the network, although we cannot compare always two (or more) lower level violations to violation of a single ancestor constraint.
These observations underlie the inference algorithms below.
Theorem 7 (soundness) If there is an improving flipping sequence for CP-net N from
outcome o to o0 , then N |= o0  o.
Proof: If there is an improving flip from outcome o1 to another outcome o2 then N |=
o2  o1 by the definition of |=. The theorem follows from the transitivity of preferential
entailment (Lemma 2). 
Theorem 8 (completeness) If N is an acyclic CP-net and there is no improving flipping
sequence for N from outcome o to o0 , then N 6|= o0  o.
Proof: Let G be a graph whose nodes are all outcomes (i.e., complete assignments to the
variable set V), with a directed edge from o1 to o2 iff there is an improving flip of o1 to o2
sanctioned by network N . Clearly, directed paths in G are equivalent to improving flipping
sequences with respect to N .
Next, we show that any total preference ordering  that respects the paths in G (that
is, if there is a path from o1 to o2 in G, then we have o2  o1 ) satisfies network N : if  does
not satisfy N , there must exist some variable X with parents U, instantiation u  Asst(U),
158

fiCP-Nets

values x, x0  Dom(X), and instantiation y of the remaining variables Y = V  (U  {X}),
such that:
(a) uxy  ux0 y;
(b) but CPT(X) dictates that x0  x given u.
This is a direct consequence of the definition of satisfaction. However, if N requires that
x0  x given u, there is a direct flip from xuy to x0 uy, contradicting the fact that  extends
the graph G.
Based on this observation, we can now prove the theorem: If there is no improving
flipping sequence from o to o0 , then there is no directed path in G from o to o0 . Therefore,
there exists a preference ordering  respecting the paths in G in which o  o0 . But this
preference ordering also satisfies N , which implies N 6|= o0  o. 
4.3 Flipping Sequences as Plans
Searching for flipping sequences can be seen as a type of planning problem: given a CPnet N , and a variable X with parents Pa(X) in N , each row in CP T (X) is a conditional
preference statement of the form
u : x1  x2      xd
where u  Asst(Pa(X)), and d = |Dom(X)|. Such a statement can be converted into a set of
planning operators for improving the value of X. In particular, this conditional preference
statement can be converted into a set of d1 planning operators of the form (for 1 < i  d):
Preconditions: u  xi
Postconditions:
Delete list: xi
Add list: xi1
This corresponds to the action of improving xi to xi1 in the context of u. (An inverse
set of operators would be created for worsening sequences).
Given a query N |= x  y, we treat y as the start state and x as the goal state of a
planning problem. It is readily apparent that the query is a consequence of the CP-net if
and only if there is a plan for the associated planning problem, since a plan corresponds to
a flipping sequence.
The planning problem over multi-valued variables with discrete, finite domains is known
to be pspace-complete (Backstrom & Nebel, 1995), and it remains pspace-complete under
the assumption that all the variables are binary (Bylander, 1994) (i.e., planning problems in
strips formalism with negative effects). However, this upper bound is not very informative
with respect to dominance queries, since the planning problems generated from them will
generally look quite different in form from standard AI planning problems, as there are
many more actions, and each action is directed toward achieving a particular proposition
and requires very specific preconditions. Thus dominance queries with respect to binaryvalued CP-nets correspond to a specific class of strips planning problems, the complexity
159

fiBoutilier, Brafman, Domshlak, Hoos & Poole

of which was recently analyzed by Domshlak and Brafman (2002b, 2003). We now explain
this relationship.
First, we divide the preconditions of every operator in a planning problem into two types:
prevailing conditions, which are variable values that are required prior to the execution of
the operator and are not affected by the operator, and preconditions, which are affected
by the operator. Second, we introduce the notion of a causal graph (Knoblock, 1994), a
directed graph whose nodes stand for the problem variables. An edge (X, Y ) appears in
the causal graph if and only if some operator that changes the value of Y has a prevailing
condition involving X.
The complexity analysis of Brafman and Domshlak (2003) addresses planning problems
with binary variables, unary operators (i.e., operators that affect only a single variable),
and acyclic causal graphs. In the planning problem generated for a dominance query with
respect to a binary-valued CP-net, we have:
1. all the operators are unary, because each flip improves the value of a single variable;
and
2. the causal graph of the problem is exactly the graph of the CP-net, since the values
of Pa(X) required by a value flip of X are exactly the prevailing conditions of the
corresponding planning operator.
Therefore, in our computational analysis of dominance queries for binary-valued acyclic
CP-nets we can use some of the results and techniques of Brafman and Domshlak (2003).
4.4 Complexity of Dominance Queries for Binary-valued, Acyclic CP-nets
In this section we analyze the complexity of dominance testing with respect to binaryvalued CP-nets, showing a connection between the structure of the CP-net graph and the
worst-case complexity of dominance queries. In particular, we show that:
 When a binary-valued CP-net forms a directed tree, the complexity of dominance
testing is quadratic in the number of variables.
 When a binary-valued CP-net forms a polytree (i.e., the induced undirected graph is
acyclic), dominance testing is polynomial in the size of the CP-net description.
 When a binary-valued CP-net is directed-path singly connected (i.e., there is at most
one directed path between any pair of nodes), dominance testing is np-complete. The
problem remains hard even if node in-degree in the network is bounded by a low
constant.
 Dominance testing for binary-valued CP-nets remains np-complete if the number of
alternative paths between any pair of nodes in a CP-net is polynomially bounded.
The exact complexity of dominance testing in multiply connected, binary-valued, acyclic
CP-nets remains an open problemat this stage it is not clear whether this problem is in
np or harder.
In what follows, we make the assumption that the number of parents for each variable
(i.e., node in-degree in the CP-net) is bounded by some constant. This assumption is
160

fiCP-Nets

justified as the CPTs are part of the problem description, and the size of a CP T (X) is
exponential in |Pa(X)|.
4.4.1 Some General Properties
We start with some notation and two useful lemmas. First, given a CP-net N and a pair
of outcomes o, o0 with respect to N , an improving flipping sequence F from o0 to o will be
called irreducible if any subsequence F 0 of F obtained by deletion of any entries except the
endpoints o, o0 of F is not an improving flipping sequence.8
Given a CP-net N , let F be the set of all irreducible improving flipping sequences
among outcomes. We denote by MaxFlip(Xi ) the maximal number of times that a variable
Xi changes its value in any flipping sequence in F. Formally, let Flip(F, Xi ) be the number
of value flips of Xi in the flipping sequence F . Then,
MaxFlip(Xi ) = max {Flip(F, Xi )}
F F

Lemma 9 below formalizes our first observation about irreducible flipping sequences with
respect to binary-valued CP-nets.
Lemma 9 For every variable Xi in a binary-valued CP-net N , we have:
MaxFlip(Xi ) 

X

1 +

MaxFlip(Xj )

Xj :Xi Pa(Xj )

Proof: Let F be an irreducible flipping sequence with respect to N (from some outcome
o0 to some outcome o), such that MaxFlip(Xi ) = Flip(F, Xi ). Consider the subsequence
F 0 = f1 , f2 , . . . , fk  F that consists of all value flips of the children of Xi in N . Observe
that: (i) every fl  F 0 requires Xi to take one of its two possible values; and (ii) no value
flip in F  F 0 depends on the value of Xi .
Now, for 1  l < k, if fl and fl+1 require the same value of Xi , then there are no value
flips of Xi in F between fl and fl+1 : If there are such flips, they are simply redundant, and
this contradicts our assumption that F is irreducible. (Recall that fl and fl+1 are adjacent
in F 0 , but may be separated by several flips in the original sequence F .) Alternatively, if
fl and fl+1 require different values of Xi , due to the irreducibility of F , there is exactly
one value flip of Xi in F between fl and fl+1 . Similarly we can show that there is at most
one value flip of Xi in F before f1 , and there is at most one value flip of Xi in F after
fk . The latter flip is necessary when fk requires Xi to take the value o[Xi ], thus, after
supporting the immediate successors, Xi still should flip its value once, in order to obtain
the value required by o.
The above implies that:
MaxFlip(Xi ) = Flip(F, Xi )  1 +

X

Flip(F, Xj )

Xj :Xi Pa(Xj )

8. Note that removing any proper initial or final subsequence of F results in a valid flipping sequence. We
refer here to the deletion of arbitrary elements from the sequence, excluding the endpoints.

161

fiBoutilier, Brafman, Domshlak, Hoos & Poole

and thus, by definition of MaxFlip, we have:
X

MaxFlip(Xi )  1 +

MaxFlip(Xj )

Xj :Xi Pa(Xj )


Adopting the terminology of Domshlak and Shimony (2003) and Shimony and Domshlak
(2002), a directed acyclic graph G is directed-path singly connected if, for every pair of nodes
s, t  G, there is at most one directed path from s to t. Using Lemma 9, we can prove
that if a binary-valued CP-net forms a directed-path singly connected DAG then, for every
variable Xi , MaxFlip(Xi ) can be bounded by n (the number of variables).
Lemma 10 If a binary-valued CP-net N forms a directed-path singly connected DAG, then,
for every variable Xi  N , we have:
MaxFlip(Xi )  n
where n is the number of variables in N .
Proof: In what follows, denote MaxFlip(Xi ) in N as MaxFlipN (Xi ). The proof is by induction on n. For n = 1 it is obvious that MaxFlip(X1 )  1. Assume that when a binary-valued,
directed-path singly connected CP-net N consists of n  1 variables, then, for every Xi  N ,
MaxFlipN (Xi )  n  1
Let N 0 be some binary-valued, directed-path singly connected CP-net over n variables.
Without loss of generality, let the variables {X1 , . . . Xn } of N 0 be topologically ordered
based on the (acyclic) graph of N 0 . Clearly, Xn is a leaf node, and we will denote by N the
CP-net obtained by removing Xn from N 0 . From Lemma 9, we have:
MaxFlipN 0 (Xn )  1
Observe that there are no directed paths between any predecessors of Xn in N 0 , since N 0 is
assumed to be directed-path singly connected. Therefore, by Lemma 9, for each parent Xi
of Xn in N 0 , we have:
MaxFlipN 0 (Xi )  MaxFlipN (Xi ) + MaxFlipN 0 (Xn )
and thus:
MaxFlipN 0 (Xi )  MaxFlipN (Xi ) + 1
Generally, since N is directed-path singly connected, for each variable Xi  N 0 ,

MaxFlipN (Xi ) + 1, if there is a path from Xi to Xn
MaxFlipN 0 (Xi ) 
MaxFlipN (Xi ),
otherwise
and thus, for each Xi  N 0 , we have:
MaxFlipN 0 (Xi )  n

162

fiCP-Nets

TreeDT (JN |= o  o0 K)
Initialize the variables in V to outcome o0 .
Loop:
Iteratively remove all leaf variables from V that have assigned to
them their values in o.
If V = , then return yes.
Find a variable X s.t. its value can be improved, and no value of its
descendants in N can be improved, given the current assignment to V.
If no such variable was found, then return no.
Otherwise, change the value of X.
Figure 10: Flipping sequence search algorithm for binary-valued, tree-structured CP-nets

4.4.2 Tree-structured CP-nets
We start by presenting a flipping sequence search algorithm for the class of binary-valued,
tree-structured CP-nets, and prove its correctness. Then we show that the time complexity
of this algorithm is O(n2 ), and show that this is actually a lower bound for flipping-sequence
search over binary-valued, tree-structured CP-nets.
Figure 10 presents our TreeDT algorithm for binary-valued, tree-structured CP-nets.
Informally, TreeDT starts by initializing all the variables in V to their values in the (purported) less preferred outcome o0 , and continues with an incremental, bottom-up conversion
of this initial assignment to the assignment induced by the (purported) more preferred outcome o. Each step starts by iteratively removing from N all leaf variables (i.e., its maximal
fringe or canopy) that are already consistent with o. If at some iteration this step removes
all variables in N , then all variables are assigned to their values in o, and thus the required
improving flipping sequence from o0 to o has been generated.
Otherwise, let N 0 stand for the updated N (with nodes removed). A node X  N 0 is a
candidate variable if: (i) the value of X can be flipped; and (ii) no descendant of X in N 0
can have its value flipped, given the current assignment to the variables of N 0 . We then flip
the value of an arbitrary candidate variable (if one exists) and repeat with node removal; or
we report that there is no improving flipping sequence from o0 to o if there are no candidate
variables.
The TreeDT algorithm is deterministic and backtrack-free. Below we show that TreeDT
is complete for binary-valued, tree-structured CP-nets, and generates only irreducible flipping sequencesthus the time complexity of TreeDT is O(n2 ). The fact that it generates
irreducible flipping sequences ensures its soundness (since by generating only valid flipping
sequences it can only provide correct positive answers to dominance queries).
Theorem 11 The algorithm TreeDT is sound and complete for binary-valued, tree-structured
CP-nets.
Proof: Consider an execution of TreeDT on a dominance query N |= o  o0 with respect
to a binary-valued, tree-structured CP-net N .
163

fiBoutilier, Brafman, Domshlak, Hoos & Poole

First, suppose we iteratively remove from the tree any leaf variables that have as values
those required by the target outcome o. It is easy to see that this does not affect the
completeness of the algorithm: because N is acyclic, the variables in the fringe are not the
ancestors of any other variables. Hence, the value of the variables in the fringe does not
influence our ability to flip the values of any other variables (hence it does not remove any
improving flipping sequence from consideration).
Second, consider a variable X such that, after iteratively removing variables as above,
its value can be improved, yet none of its descendents in N can be improved, given the
current assignment v to V. If X is a leaf node, then changing its value does not influence
our ability to flip values of any other variables. In addition, the current value v[X] of X
is different from o[X], otherwise X would have been part of the removed fringe. Therefore,
the (improving) change of Xs value at this point is necessary in any improving flipping
sequence. Alternatively, suppose that X is not a leaf node. Since the leaf nodes in the
subtree of N rooted at X were not a part of the removed fringe, (at least) their values
remain to be changed. Because N is a tree, X completely separates its descendents in N
from all other variables; so no improving flip in the subtree of X will be possible until we
change the value of X. Hence the value of X must be changed in any flipping sequence
from this point before the value of any descendent of X.
What remains to be shown is that when there are several candidate variables that can
be flipped, it does not matter which one we flip first. If there is more than one candidate
variable, each one of them will have to be flipped at some pointeach such flip is necessary
for flipping the children of the corresponding variable. However, any changes made to one
of these candidates or below it has no affect on the other candidates or their descendants.
Thus, the evaluation order of the candidate flips is irrelevant, and cannot prevent us from
finding a flipping sequence if one exists.
Thus the algorithm is complete. The soundness of the algorithm should be clear from
the proof as well. The flip generated at each step of the algorithm is a valid improving flip
given the current outcome v. 
Theorem 12 The time complexity of the flipping-sequence search over binary-valued, treestructured CP-nets is O(n2 ), where n is the number of variables in the CP-net.
Proof: Since the algorithm TreeDT is backtrack-free, the only thing that remains to be
shown in addition to Lemma 10 and Theorem 11 is that (on binary-valued, tree-structured
CP-nets) TreeDT generates only irreducible flipping sequences. However, the proof of this
subclaim is straightforward since we have already shown that:
1. TreeDT flips the value of each variable X either to achieve the value of X in the
(purported) more preferred outcome of the query, or to allow the required value flips
of the descendants of X, and
2. The role of the latter flips of X cannot be fulfilled by value flips of any other variables.
Therefore, given an improving flipping sequence F generated by TreeDT, removing any
subset of value flips from F makes F either illegal, or its ends are not (o0 , o), respectively.
Hence, any improving flipping sequence generated by the TreeDT algorithm is irreducible.

164

fiCP-Nets

Theorem 13 below shows that even when limiting ourselves to chain binary-valued CPnets, there are dominance queries whose minimal flipping sequences have quadratic length.
Thus TreeDT is asymptotically optimal.
Theorem 13 (n2 ) is a lower bound for the flipping-sequence search over binary-valued
tree-structured CP-nets.
Proof: For the proof see Appendix A. The proof is by example, providing a dominance
query on a binary-valued, tree CP-net for which the size of a minimal flipping sequence is
(n2 ).

4.4.3 Polytree CP-nets
DAGs with no cycles in the underlying undirected graphs, also known as polytrees, offer a
minimal extension of directed trees. Unfortunately, the TreeDT procedure is not complete
for polytree CP-nets unless extended with some form of backtracking (even when restricted
to binary variables). This is due to the fact that several parents of a given node may each
be allowed to have their values flipped, but only one of the choices may lead to the target
outcome while the others lead to a dead end. For instance, consider the CP-net N from
Figure 9 and the query N |= abc  abc. Starting with the outcome abc, in the first iteration
of TreeDT, we have the choice of flipping either A or B. If B is chosen, the assignment is
changed to abc. However, this cannot lead to the target, since there is no way to flip B
back to b. Thus, a dead end is reached. On the other hand, if A is chosen then TreeDT will
successfully generate the improving flipping sequence abc  abc  abc. Thus, an incorrect
choice of improving variable may require backtracking.
However, dominance testing for binary-valued, polytree CP-nets remains polynomial
time, although the algorithm for its solution is more complicated than TreeDT. An algorithm
is adapted from the corresponding algorithm for planning problems with binary variables,
unary operators, and polytree causal graphs described by Domshlak and Brafman (2003).
Theorem 14 Dominance testing for binary-valued, polytree CP-nets is in p.
Proof: According to the reduction from the CP-net dominance queries to the classical
planning problems (see Section 4.3), every dominance query with respect to a binary-valued,
polytree CP-net can be compiled into a propositional planning problem with unary operators
and polytree causal graph. An algorithm for the latter problem is presented by Brafman
and Domshlak (2003), and the time complexity of this algorithm is O(22 n2+3 ), where 
is the maximal in-degree of the causal graph.
Recall our assumption that the in-degree of the CP-net is bounded by some constant (in
this case, ). This assumption is justified as the CPTs are part of the problem description,
and the size of a CP T (X) is exponential in |Pa(X)|. Therefore, the complexity of the
algorithm of Brafman and Domshlak (2003) on CP-nets is polynomial in the size the CPnet. 
165

fiBoutilier, Brafman, Domshlak, Hoos & Poole

4.4.4 Intractable dominance queries
While dominance testing for binary-valued, polytree CP-nets is polynomial, we can show
that for binary-valued, directed-path singly connected CP-nets, this problem is np-complete.9
This can be proved using a CP-net-oriented extension of the proof for the corresponding
claim with respect to planning problems (Brafman & Domshlak, 2003). These results also
entail that dominance testing for binary-valued CP-nets remains in np if the number of
distinct paths between any pair of nodes in the CP-net is polynomially bounded.
Theorem 15 Dominance testing for binary-valued, directed-path singly connected CP-nets
is np-complete.
Proof: For the proof see Appendix A.
An immediate extension of directed-path singly connected DAGs are max--connected
DAGs: a directed graph is max--connected if the number of different directed paths between any two nodes in the graph is bounded by .
Theorem 16 Dominance testing for binary-valued, max--connected CP-nets, where  is
polynomially bounded in the size of the CP-net, is np-complete.
Proof: The theorem is immediately entailed by the corresponding result for planning
of Brafman and Domshlak (2003); for the proof in terms of CP-nets, see Appendix A.

Theorem 15 implies that dominance testing for binary-valued, acyclic CP-nets is hard.
However, the exact complexity of this problem is still an open questionit is not clear
whether this problem is in np or if it is harder. Some preliminary analysis of this problem (Domshlak & Brafman, 2002a) shows a connection between the complexity of the flipping sequence search for binary-valued, acyclic CP-nets and the diameters of some specific
graphs. A complementary result with respect to these graphs (Domshlak, 2002b), namely recursively directed hypercubes, shows that dominance queries with respect to binary-valued,
acyclic CP-nets with unbounded node in-degree may require flipping sequences of size exponential in n, where n is the number of variables in the CP-net.
It has been shown that the most general class of planning problems with binary variables,
unary operators and acyclic causal graphs is harder than np (Brafman & Domshlak, 2003).
However, this result does not imply that answering dominance queries is harder than np as
well, as we do not know of a reduction from this class of planning problems into CP-nets.

5. Search Techniques for Dominance Queries
In the previous section we showed that dominance testing is generally hard even for binaryvalued CP-nets, and that tractable algorithms exist only for specific problem classes. However, CP-nets impose a rich structure on preferences that can be exploited by various search
strategies and heuristics which often significantly reduce search effort, and allow the effective solution of many problem instances. In this section we discuss the search for flipping
9. While every polytree is directed-path singly connected, the converse is not true.

166

fiCP-Nets

sequences and several rules that allow significant pruning of the search tree without impacting soundness or completeness of the search procedure. These rules are described in
the context of improving flipping sequences, but they can be applied to worsening search
mutatis mutandis.
Given a CP-net N , and an outcome o, we define the improving search tree of o, T (o), as
follows: T (o) is rooted at o, and the children of every node o0 in T (o) are those outcomes that
can be reached by a single improving flip from o0 . It is easy to see that every rooted path
in T (o) corresponds to some improving flipping sequence from the outcome o (with respect
to N ), and vice versa.10 For example, consider the preference graph shown in Figure 11(a),
which is induced by the CP-net in Figure 4. Figure 11(b) depicts the improving search
tree T (abc) with respect to this preference graph. Clearly, we can treat every dominance
query N |= o  o0 as searching T (o0 ) for a node associated with the outcome o, starting
from the root node o0 . For instance, in the example above, given the dominance query
N |= abc  abc, any of the dotted paths shown in Figure 11(c) bring us to outcome abc.
However, taking a different direction during the tree traversal would lead to a dead end,
requiring backtracking in order to find a suitable flipping sequence. Any generic search
algorithm can be used to traverse the improving search tree to find an improving sequence
that supports a dominance query.
5.1 Suffix Fixing
Suffix fixing is a rule that allows certain moves in T (o) to be pruned from the search
tree without impacting completeness of the search. Let N be a CP-net over the variables
V = {X1 , . . . , Xn }, numbered according to an arbitrary topological ordering consistent with
the network N . We define an rth suffix of an outcome o  Asst(V), for any r  1, to be
the subset of the outcome values o[Xr ]o[Xr+1 ]    o[Xn ]. Notice that the rth suffix of an
outcome depends on the topological ordering of variables used. Finally, we say that the rth
suffixes of outcomes o and o0 match iff o[Xj ] = o0 [Xj ] for all r  j  n.
Let o be a node in an improving search tree T (o0 ), and let o be the target of the search;
in other words, we are attempting to find a flipping sequence that proves N |= o  o0 . The
suffix fixing rule requires that if the rth suffix of o and o matches, for some value r, no
neighbors of o can be explored whose rth suffix does not also match o. This is equivalent
to ruling out the exploration of any flipping sequences that destroy the suffix of an outcome
that matches the target outcome o. The following lemma ensures that pruning such branches
of the search tree T (o0 ) when searching for a path to o does not affect completeness.
Lemma 17 Let N be a CP-net, and o and o be outcomes whose rth suffix matches (for
any topologically consistent ordering X1 ,    , Xn of the variables in N ). If there is path in
T (o ) from root o to o, then there is a path from root o to o such that every outcome on
that path assigns the same values to Xr ,    Xn (i.e., with the same suffix match).
Proof: The proof is straightforward: Because N is acyclic, no suffix variable is an ancestor
of any non-suffix variables. Hence, the value of the suffix variables does not influence (for
better or worse) our ability to flip values of the remaining variables. 
10. The corresponding worsening search tree of o can be defined similarly using the worsening flips.

167

fiBoutilier, Brafman, Domshlak, Hoos & Poole

abc


  
 abc
 


  t abc
 tt
 zttt

abc

abc E
EE
y
EE
yy
y
E"
y

y|
abc

abc D






abc

abc

abc
abc



abc D

DD
DD
"






z
zz

z| z

abc


tt
tt
t
z
t

abc

DD
DD
"

abc

abc

abc

abc

abc

abc

abc


abc

 

abc KK



KKK
K%  

abc




abc


abc

abc
(a)

(b)

abc

abc

yy
yy 
y
|
y

abc

abc






abc

"

abc

abc

abc
"

abc




abc

abc

abc


abc

abc
"



abc

yy
yy 
y| y

abc

abc

abc

abc

z
zz

|z
z


abc


abc




abc


abc

(c)

(d)

Figure 11: (a) The preference graph induced by a CP-net; (b) the improving search tree
T (abc); (c) paths to outcome abc; and (d) pruning T (abc) by suffix fixing.

168

fiCP-Nets

Suppose, given query N |= o  o0 , there is a path in T (o0 ) to an outcome o of the type
mentioned in the lemma above. Since the subtree of T (o0 ) rooted at o is just T (o ), we are
assured that if any path from o0 to o passes through o , there is a path from o0 to o that
passes through o in which the suffix of o is preserved on the subpath from o to o. From
this we conclude:
Proposition 18 Any complete search algorithm for the improving search tree remains complete if pruning using the suffix rule is used.
The suffix fixing rule effectively prunes the search tree under a node o as described above
to contain only paths that retain the suffix values of the target o. Though backtracking
over choices that lead to o may be required, as may those choices at o that preserve
suffixes, consideration of the full search tree under o will not be required (if there is a
nontrivial suffix match). For example, the improving search tree T (abc) for the query
N |= abc  abc discussed above, pruned using the suffix fixing rule and the variable ordering
A, B, C, appears in Figure 11(d). As we can see, this pruning can dramatically reduce the
size of the effective search tree.
5.2 Least-Variable Flipping
An extension of the suffix fixing rule is the least-variable flipping rule, defined as follows.
Suppose we have a CP-net N , and a query N |= o  o0 . Let o be an outcome, and for
any variable Xj , let u denote the instantiation of U = Pa(Xj ) in o . We say Xj is a
least-improvable variable in o if there is some value x  Dom(Xj ) such that x ju o [Xj ],
and no descendent of Xj in N has this property. Intuitively, a least-improvable variable is
one that is the lowest in N that can be flipped to produce an outcome that is preferred
to o . Naturally, there may be several such variables. We say Xj is least improvable with
respect to the target o iff Xj is the least improvable variable among those not part of a suffix
match with o. In other words, if some suffix of o and o matches, we apply the definition
of least-improvable variable, restricting attention to those variables that are not part of the
matching suffix. The least-variable flipping rule requires that the only neighbors of a node
o that can be expanded in the search for an improving sequence with target o are those in
which some least improvable variable with respect to o is improved.
The following lemma ensures that for binary-valued, directed-path singly connected
CP-nets, pruning an improving search tree using the least-variable rule does not affect the
completeness of any search procedure.
Lemma 19 Let N be a binary-valued, directed-path singly connected CP-net, and o and o
be outcomes whose rth suffix matches (for any topologically consistent ordering X1 ,    , Xn
of the variables in N ). Let {o1 , . . . , om } (m  n) be the set of all outcomes reachable from
o via some least-variable flip that does not affect the matched suffix. If there is path in
T (o ) from root o to o, then there is a path from some os (s  m) to o.
Proof: Without loss of generality and based on our earlier observations, we can assume no
suffix match between o and o (if so, restricting attention to the set of non-suffix variables
does not affect our argument).
169

fiBoutilier, Brafman, Domshlak, Hoos & Poole

Now assume, contradicting the statement of the theorem, that none of the least-variable
flips os of o have a path to o, but there does exist a path from o to o. This implies that
none of these least-variable flips involve leaf variables in the network N . Otherwise, we
could flip the value of such a leaf variable at o without any effect on our ability to flip
other variables, and thus be able to construct a path from o to o that passes through any
of the os that flip leaves.
Now, consider a leaf variable Xi in N . Since we are dealing with binary variables, on
any irreducible flipping sequence from o to o the value of Xi should be flipped exactly
once. However, the current assignment o [Pa(Xi )] does not allow us to perform this flip
(see observation above). Thus, we must achieve another assignment to Pa(Xi ) before we
can flip the value of Xi , making it a part of a suffix match.
Let NXi be the subnetwork of N induced by Xi and all ancestors of Xi in N . Because
N is directed-path singly connected, NXi forms a tree, directed toward its root Xi . Now
we reduce NXi further by removing all subtrees NXj of NXi , such that no variable in NXj
can be flipped in o . Note that this step cause no loss of generality, since (due to acyclicity
of N ) the assignment o to the variables in NXj cannot be flipped first in any improving
flipping sequence beginning with o . Likewise, let Xi1 , . . . , Xim0 , m0  m, be the variables
corresponding to the least-variable flips of o in NXi , and, for 1  k  m0 , let ik be the
(single) directed path
from Xik to
 Xi .
Sm0 
Let  = j=1 NXij \ {Xij } . Because NXi is a tree, for 1  j  m0 , the variable Xij
separates the variables in NXij \ {Xij } and the paths i1 , . . . , im0 . Therefore:
(i) No set of flips of the variables in  will enable us to flip the values of the variables on
i1 , . . . , im0 ; in particular a flip of Pa(Xi ) cannot be enabled. Thus, to enable a flip of
Xi , eventually we will have to flip the value of at least one variable from Xi1 , . . . , Xim0 .
(ii) No value flip of Xi1 , . . . , Xim0 will affect (neither positively nor negatively) our ability
to flip the values of the variables in . Thus, if there is an improving flipping sequence
from o to o, then at least one such sequence starts with a value flip of a variable from
Xi1 , . . . , Xim0 .
This last observation contradicts the assumption that there is a flipping sequence from o
to o that does not pass through at least one os . 
The least-variable flipping rule does not distinguish the flips of different candidate least
improvable variables; it simply restricts flips to such variables. In general, not all leastvariable flips are suitablesome may lead to dead-ends, requiring backtracking (a point
illustrated in Section 4.4.3). However, when we backtrack, we need only consider other
least-variable flips, not all flips, thus significantly reducing the size of the search tree and the
expected amount of backtracking. We observe that the TreeDT algorithm for binary-valued,
tree-structured CP-nets essentially implements the least-variable flipping rule, which is,
therefore, a complete and backtrack-free search procedure for binary-valued, tree-structured
networks.
Examples 7 and 8 below show that Lemma 19 presents probably the widest class of CPnets for which the least-variable flipping rule is complete: Example 7 shows that the leastvariable flipping rule does not preserve completeness in binary-valued, max-2-connected
170

fiCP-Nets

CP-nets, while Example 8 shows the same for multi-valued, directed-path singly connected
CP-nets. Note that the CP-net in Example 8 forms a chain. Therefore, binary-valued, treestructured CP-nets are probably the widest class of CP-nets for which the least-variable
flipping rule is both complete and backtrack-free.
Example 7 Consider the binary-valued CP-net in Figure 12, where Figure 12(a) depicts
the graph of the CP-net, and Figure 12(b) shows the corresponding CPTs. Given query
 we work in the improving tree rooted at abcde.

N |= abcde  abcde,
The only least
improvable variable that can be flipped at the root outcome is B (while A and E can
be flipped, they are not least improvable). Unfortunately, flipping B to value b leads to
 from which the target abcde is unreachable:
outcome abcde,
(i) In order to reach the target value d for the variable D, first we should achieve the
assignment b  c to the variables B and C;
(ii) Achieving the assignment b  c after the flip in question from b to b (given a  e) is
possible only by restoring the value b for B, which requires a  e; and
(iii) Flipping the value of B from b to b given a  e will lead us to a situation in which we
can no longer flip B, preventing us from achieving the target value b.
Thus the least-variable flipping rule will not allow the discovery of an improving flipping
sequence.
 to abcde that proves the
On the other hand, there is a flipping sequence from abcde
query:
  abcde
  abcde
  abcde  abcde  abcde
abcde
This sequence requires that A be flipped at the root, despite the fact that it is not a
least-improvable variable. 
Example 8 Consider a chain CP-net with three variables A, B, and C, such that A is
the parent of B, and B is the parent of C. Suppose A has domain {a, a}, B has domain
{b1 , b2 , b3 }, and C has domain {c, c}, with the following conditional preferences:
a  a;
a : b 3  b2  b1 ;
a : b3  b1  b2 ;
b1 : c  c b2 : c  c; b3 : c  c
Consider the query N |= ab3 c  ab1 c. The value c cannot be improved in the context of b1 ,
but b1 can be improved to b3 in the context of a; in fact this is the only least-improvable
variable flip for outcome ab1 c. Unfortunately, this flip leads to outcome ab3 c from which no
path to the target ab3 c exists. In contrast, flipping the non-least-improving variable A to
a first allows the discovery of a successful improving path: after flipping a to a, we change
b1 to b2 , c to c, and finally b2 to b3 . 
171

fiBoutilier, Brafman, Domshlak, Hoos & Poole

89:;
?>=<
?>=<
89:;
A>
E
>>
>>
>>
>>
>>
> 

89:;
?>=<
89:;
?>=<
C/
B
//


//

//


// 
 
89:;
?>=<
D

(a)

Variable
A

CPT
a  a

B

a  e : b  b
a  e : b  b

C

a : c  c
a : c  c

D

c  b : d  d
c  b : d  d

E

e  e
(b)

Figure 12: A multiply connected CP-net for which the least-variable flipping rule causes
incompleteness.

Though for multiply-connected networks, and networks with multi-valued variables, the
least-variable flipping rule is not complete, we believe that it can provide useful heuristic
guidance in these cases. The least-variable-first heuristic is a heuristic for ordering children
in an improving search treeit requires that when expanding a node o (with respect to
some target o), the children corresponding to least-improving variables be explored first.
This will typically reduce the number of nodes expanded in the tree, because the leastvariable-first heuristic can be viewed as embodying a form of least commitment. Flipping
the values of a least-improving variable can be seen as leaving maximum flexibility in flipping
the values of other variables. An upstream variable limits the possible flipping sequences
more drastically than a downstream variable since altering a variable does not limit the
ability to flip the values of its non-descendants.
For multivalued networks, the least commitment strategy can be used to extend the
least-variable-first heuristic using the least improving rule: alternative improving flips of
the same least-improvable variable are considered from the least improving flip to the most
improving flip (i.e., first the flip that leads to the least preferred improving value is adopted).
This allows greater flexibility in the movement of downstream variables. While one can
always further improve the value of the variable in question from its less preferred value to
a more preferred value (provided that parent values are maintained), skipping values may
prevent us from setting descendants to their desired values. In fact, this was illustrated in
Example 8, where, after the crucial flip of variable A, using the least improving rule as a
heuristic leads directly to the target outcome.
172

fiCP-Nets

5.3 Forward Pruning
In a search procedure for an improving flipping sequence, no matter whether this procedure
adopts the above heuristics or not, one can use a general forward pruning technique. This
technique has a number of desirable properties:
(a) it often quickly shows that no flipping sequence is possible;
(b) it prunes the domains of the variables to reduce the flipping search space;
(c) it doesnt compromise soundness or completeness; and
(d) it is relatively cheap: its time complexity is O(nrd2 ), where n is the number of variables,
r is the maximum number of conditional preference rules for each variable, and d is the
size of the largest variable domain.
The general idea is to sweep forward through the network, pruning any values of a variable
that cannot appear in any improving flipping sequence for a given query. Intuitively, we
consider the set of flips possible, ignoring interdependence of the parents and the number
of times the parents can change their values.
We consider the variables in an order consistent with the network topology (so that
parents of a node are considered before the node). For each variable Xj with parents
U, we build a domain transition graph with nodes corresponding to the possible values
xi  Dom(Xj ). For each conditional preference relation ju over Dom(Xj ) of the form:
xu1  xu2      xud
such that u contains only unpruned values of the parents U of Xj , we include directed
arcs between the successive values in the ordering ju (i.e., an arc from xi to xi1 , for each
1 < i  d).
When answering query N |= o  o0 , we can prune any value of Xj that is not on a
directed path from o0 [Xj ] to o[Xj ] in the domain transition graph for Xj . This can be
implemented by running the well-known Dijkstras algorithm (Cormen, Lierson, & Rivest,
1990) twice: once to find the nodes reachable from o0 [Xj ] and again to find the nodes that
can reach o[Xj ]. These sets of nodes can be intersected to find the possible values for Xj
along any path from o0 [Xj ] to o[Xj ] in T (o0 ) (i.e., along any improving sequence from o0 [Xj ]
to o[Xj ] with respect to N ). If the intersection is empty, the dominance query fails: there
is no legal flipping sequence from o0 [Xj ] to o[Xj ]. This often results in quick failure for
straightforward queries, so that we only carry out the search for non-obvious cases.
Example 9 Consider any CP-net N in which A and B are both binary root variables,
and the preferences over the values of A and B are a  a and b  b. Given a query
N |= ab . . .  ab . . ., first we consider A. The domain transition graph for A consists of an
arc a  a, thus no values of A are pruned. If the example were changed slightly so that A
had a third value a, where a  a  a, then this third value could be pruned from A, thus
simplifying the tables for all the children of A.
We then consider B, whose domain transition graph consists of a single arc b  b. Since
the value of B in the (purported) more preferred outcome of the query (b) is not reachable
in the domain transition graph of B from the value of B in the (purported) less preferred
outcome of the query (b), the query fails quickly without looking at the other variables. 
173

fiBoutilier, Brafman, Domshlak, Hoos & Poole

6. Incompletely Specified Preferences and Indifference
In many practical applications, one expects to see reluctance on behalf of the user to provide
complete CPTs or to totally order the values of each variable in every possible context.
Thus, it is natural to ask how our results and techniques can be applied in these cases.
It turns out that all the results presented in this paper, except for the linear time procedure for ordering queries, can be easily extended to work both on CP-nets with partially
specified CPTs, and on satisfiable CP-nets that capture statements of preferential indifference. For instance, all the results presented in Section 4.4 with respect to dominance queries
remain applicable as is, because almost all of these results were shown by Brafman and
Domshlak (2003) to be valid in more general setting of classical planning. The only case
that was not analyzed by Domshlak and Brafman is the case of tree CP-nets. However,
the correctness of the TreeDT procedure for extended CP-nets can be easily verified, and
its complexity remains quadratic. This stems from the fact that Lemma 10 is valid in the
more general planning setting (Brafman & Domshlak, 2003). The only point that requires
clarification is the difference between partial specification and indifference with respect to
flipping sequences: Given a variable X with parents U, and two values x1 , x2  Dom(X),
if x1 and x2 are equally preferred given u  Asst(U), then given u we can flip the value
of X from x1 to x2 , and vice versa. Alternatively, if x1 and x2 are incomparable given
u  Asst(U), then given u we cannot flip the value of X from x1 to x2 , nor from x2 to x1 .
The complexity of dominance testing in the context of indifference and incompletely
specified CPTs remains an open problem. However, Theorem 20 below shows that the
flipping sequence search over multi-valued CP-nets with partially specified preferences is
not in np, even if the CP-net forms a chain and the variables are three-valued only.
Theorem 20 Flipping sequence search over multi-valued CP-nets with partially specified
preferences is not in np.
Proof: For the proof see Appendix A.
Now, consider outcome optimization queries. When the CPTs are allowed to be partially
specified, or the statements of indifference are allowed, the CP-net may induce more than
one nondominated outcome. For instance, consider again Example 1 (My Dinner I). If the
preference for the type of wine given fish soup is not specified, or the decision maker considers
both red and white wine to go equally well with fish soup, then this CP-net induces two
nondominated outcomes: fish soup with white wine, and fish soup with red wine.
The forward sweep procedure for the outcome optimization queries presented in Section 3
can be easily extended for the cases of partial specification and/or indifference by adding
branching on each variable X for which the (already generated) assignment on Pa(X)
induces more than one nondominated value from Dom(X). The complexity of the resulting
algorithm is O(n), where n is the number of variables in the CP-net, and  is the number
of nondominated outcomes induced by the CP-net. Of course,  can be exponential in
the size of the CP-net.11 However, our adapted forward sweep procedure has the anytime
propertythe solutions are generated iteratively, and the time to add a new nondominated
11. The tight upper bound of  = 2n can be shown for any CP-net by simply leaving all CPTs unspecified.

174

fiCP-Nets

outcome to the current set of generated solutions is O(n). Therefore, the complexity of
generating k nondominated solutions is linear in k.
Finally, an important query that can be answered efficiently in standard CP-nets is the
outcome ordering query (see Section 4.1). Although the basic Corollary 4 remains valid
in the case of CP-nets with partial specifications or statements of indifference, this is not
the case for Theorem 5. Therefore, the computational complexity of ordering queries for
extended CP-nets remains an open question, and we conjecture that this problem is hard.

7. Concluding Remarks
In this paper we introduced CP-nets, a new graphical model for representing qualitative
preference orderings which reflects conditional dependence and independence of preference
statements under a ceteris paribus semantics. This formal framework offers a compact
and arguably natural representation of preference information, and allows us to efficiently
answer some of the principal forms of preference queries.
We described several types of queries and algorithms for answering them with respect
to a specific CP-net. In particular, outcome optimization and outcome ordering queries
were shown to be solvable in time linear in the number of variables in the network. For the
dominance queries, however, the situation is more complicated. First, we demonstrated the
equivalence of answering dominance queries with the task of determining existence of an
improving (or worsening) sequence of variable value flips with respect to the given CP-net.
Then, we reduced the latter task to a special subclass of classical planning problems. These
insights allowed us to show that, in general, answering dominance queries is np-hard, but
that polynomial algorithms exist for tree and polytree-structured, binary-valued CP-nets.
In addition, we presented several techniques that one can use in a generic search procedure for an improving flipping sequence. Some of these techniques were shown to have no
impact on soundness or completeness of the search for any CP-net, while other techniques
have this property only for binary-valued CP-nets. However, we argued that latter techniques can be modified into general purpose heuristics that are likely to reduce significantly
the size of the expanded search tree.
Finally, we analyzed the applicability of our results for CP-nets that allow partially
specified preferences and/or capture statements of indifference.
7.1 Applications
Our goal in developing the CP-nets formalism is to facilitate the development of applications.
One such applicationpreference-driven, adaptive multimedia document presentationwas
recently developed at Ben-Gurion University (Domshlak et al., 2001; Gudes et al., 2002). We
described the central components of this system in Section 3.2. Another application in which
both conceptual and computational properties of CP-nets seem to be useful is a distributed
meeting scheduler. A basic prototype for such a system has been implemented at BenGurion University (Brafman & Domshlak, 2001). We are currently extending this system,
while working on the related theoretical issue of multi-agent preference-based optimization.
Another potential application for qualitative preferences in general, and thus for CPnets in particular, is sorting a product database according to user-specified preferences.
This problem is highly relevant in the context of electronic commerce. Several rather
175

fiBoutilier, Brafman, Domshlak, Hoos & Poole

conceptually simplistic, though quite interesting, commercial applications that rely on
unconditional preference statements are available on the World Wide Web; examples include Active Sales AssistantTM (see www.activebuyersguide.com) and PersonalogicTM (see
www.personalogic.com). The general idea is to assist a user in selecting a specific product
from a product database according to her preferences. Here, it is very important to use
compact and natural representations for preference information. CP-nets extend current
models (which typically dont allow conditional preference statements), yet offer efficiency
in ordering a given set of alternatives. Another important aspect of this problem is that
the given database precisely defines the products (represented as vectors of attribute values) available, and preference information is only required to the extent that it narrows the
choice of product to a sufficiently small selection of products from this database. Both the
graphical properties of CP-nets underlying the efficiency of the ordering queries, and the
various dominance testing strategies, can be exploited in this context to find a subset of
products that are not dominated by any other product in the database, given the (conditional) preference information extracted from the user. Here, an interactive and dynamic
approach appears to be most promising, where the user is prompted for additional preference statements until the ordering of the products in the database is sufficiently constrained
by the preference information to offer a reasonably small selection of products.

Another growing application area for CP-nets is automated constraint-based product
configuration (Sabin & Weigel, 1998). The task is to assemble a number of components
that compose a product such that given compatibility constraints are satisfied. A simple
example of this is the assembly of components for a computer system where, for instance,
the type of system bus constrains the choice of video and sound cards. While there has
been a wide and growing body of research in modeling configuration problems and efficient
problem solving methods, there is still a need for more work on modeling and learning
user preferences, and using these to achieve configurations that are not only feasible, but
also satisfactory from the user point of view. These issues are emphasized in many papers
on configuration (Freuder & OSullivan, 2001; Haag, 1998; Junker, 1997, 2001; Soininen
& Niemela, 1998), especially when high-level configurators for specific, real-life domains
are discussed (Haag, 1998). The importance of incorporating user preferences into the
configuration problem stems from the fact that many such problems are weakly constrained
and have numerous feasible solutions (DAmbrosio & Birmingham, 1995). The value of these
solutions, from the subjective point of view of a particular user, may vary significantly.

CP-nets can be used to represent user preferences which will be used together with
compatibility constraints to search for most preferred, feasible configurations. In contrast
to the database sorting application above, here the set of possible vectors of feature values
(i.e., configurations) is not explicitly given, but implicitly specified by the compatibility
constraints. A CP-net based search algorithm by Boutilier et al. (1997) was specifically
designed to address this problem. For the description of this algorithm, as well as for analysis
of its computational properties we refer the reader to Boutilier et al. (1997), Brafman and
Domshlak (2001).
176

fiCP-Nets

7.2 Related Work
A number of lines of research are related to CP-nets. In addition to the conceptual work in
philosophy and philosophical logic described in Section 2, in AI, Doyle and Wellman (1991,
1994) explored ceteris paribus assertions and their logical properties. However, their work
did not exploit the notions of preferential independence, and in particular did not considered
graphical representations of preference statements. To the best of our knowledge, there are
no computational results known for this formalism. Therefore, it is not clear whether useful
queries can be answered efficiently in this framework.
On the surface, CP-nets are reminiscent of Bayesian networks (Pearl, 1988), which are
also graphical structures capturing conditional independence assertions. Indeed, Bayesian
networks and their utilization of probabilistic independence provide important motivation
to our work, but the two structures differ considerably in their properties and the type of
information they present.
Motivated by the same considerations driving our work, Bacchus and Grove (1995) and
La Mura and Shoham (1999) study different notions of independence and their associated
graphical representations. Both representations allow for quantitative assessments, unlike
CP-nets (at least in their current form) and differ from CP-nets in the precise nature of the
independence concept studied. In particular, Bacchus and Grove concentrate on the notion
of conditional additive independence. Additive independence is a very strong property,
requiring that the utility of an outcome be the sum of the utilities of the different variable
values of the outcome. Conditional additive independence is a weaker requirement, and
thus more promising in practice. Bacchus and Grove show that the conditional additive
independence properties of a domain can be captured by an undirected graph where for set
of nodes A, B, C, A is independent of B given C if C separates between the nodes in A and
B. La Mura and Shoham (1999) define the concept of u-independence using a ceteris paribus
comparison operator over utilities. This operator measures the intensity of preference for
specific values of certain variables given some fixed value for the other variables and with
respect to a fixed reference point. They also define an undirected graphical structure,
expected utility networks, in which u-independence is represented using the notion of node
separation.
Finally, recent work by Benferhat, Dubois and Prade (2001) provides a preliminary investigation of the potential of possibilistic logic in qualitative decision analysis, and more specifically in qualitative preference representation. The possibilistic approach takes utilities into
account, as well as probabilities, but provides a qualitative approach to decision problems
by replacing numeric preferences and probabilities with linear orderings. For discussion of
this approach to utilities and preference representation, see Benferhat et al. (2001), Dubois,
Godo, Prade, and Zapico (1998b), Dubois, Berre, Prade, and Sabbadin (1998a), Dubois,
Prade, and Sabbadin (1997), and for related qualitative models, see Boutilier (1994), Tan
and Pearl (1994).
7.3 Future Work
We see a number of potential extensions to the work described in this paper. In particular,
our work leaves a number of interesting open theoretical questions. First, the worst case
complexity of dominance testing with respect to acyclic, binary-valued CP-nets needs to
177

fiBoutilier, Brafman, Domshlak, Hoos & Poole

be establishedit is still an open question whether this problem is in np. Second, the
complexity of dominance queries with respect to multi-valued CP-nets remains an open
problem. Third, it is not clear how hard ordering queries are for CP-nets that capture
partial preference specification and/or the statements of preferential indifference. Finally,
there is a need to understand the expressive power of CP-nets better, specifically: what
sort of partial orderings are and are not representable by CP-nets; and among orderings
representable by CP-nets, which ones are can only be represented by a cyclic network.
Cyclic networks present another important challenge. Such networks can arise in applications where a natural notion of neighborhood is defined on the set of variables such
that preferences for one variable value depend on the value of its neighboring variables.
In such cases, the user may find it more natural to provide a cyclic preference structure
and we must be able to determine whether the specified network is satisfiable. In addition,
inference methods for such networks need to be developed or, alternatively, methods for
reducing cyclic networks to acyclic networks without significant blow-up in size. A number
of recent papers have started to deal with this question, with some interesting insights and
results (Domshlak, 2002a; Domshlak & Brafman, 2002a; Brafman & Dimopoulos, 2003;
Domshlak, Rossi, Venable, & Walsh, 2003).
We are working on various extensions of the framework presented here. These extensions include the use of conditional preference statements that contain a small amount of
quantitative information. Existing applications (such as online interactive consumer guides)
suggest that a limited amount of such quantitative preference information might be relatively easy to extract from the user in a natural way, and is very useful for inducing stronger
preference orderings. Preliminary work on this topic has been undertaken (Boutilier, Bacchus, & Brafman, 2001).
Another interesting extension of CP-nets are TCP-nets (Brafman & Domshlak, 2002).
TCP-nets add importance relations and conditional relative importance statements to the
the conditional ceteris paribus statements supported by CP-nets. Conditional importance
statements have the form if A = a then optimizing B is more important to me than
optimizing C. For example, If I will be flying at night, then having a better seat is more
important than getting a more preferred carrier.
Finally, preference-based optimization presents an interesting tradeoff between the amount
of user interaction required for extracting preference information and the amount of computation needed to determine the most preferred feature vectors. By asking very specific
questions about particular, potentially complex preferences, finding most preferred feature
vectors can become much easier. On the other hand, asking too many questions, especially
those not really necessary for establishing relevant preferences, will annoy the user and make
the system less usable. Thus, finding good tradeoffs between the amount of user-interaction
and computation time for answering queriessuch as finding most preferred items from a
database of optimal configurationsseems to be a promising direction for future research.
This is related to the motivation underlying goal programming (Dyer, 1972; Ignizio, 1982).
The structure of CP-nets can be exploited in determining preference elicitation strategies.
This has been explored in the context of CP-nets with quantitative information (Boutilier
et al., 2001); it remains to be seen how to use such techniques in a purely qualitative setting.
178

fiCP-Nets

Acknowledgments
Some parts of this paper appeared in C. Boutilier, R. Brafman, H. Hoos, and D. Poole,
Reasoning with Conditional Ceteris Paribus Preference Statements, Proceedings of the
Fifteenth Conference on Uncertainty in Artificial Intelligence, pp.7180, Stockholm, 1999;
and in C. Domshlak and R. Brafman, CP-netsReasoning and Consistency Testing, Proceedings of the Eighth International Conference on Principles of Knowledge Representation
and Reasoning, pp.121132, Toulouse, 2002. Thanks to Chris Geib for his contributions
to earlier, related models of CP-nets, and to the anonymous referees for their many useful
suggestions. Boutilier, Hoos and Poole were supported by the Natural Sciences and Engineering Research Council, and the Institute for Robotics and Intelligent Systems. Brafman
acknowledges the support of the Paul Ivanier Center for Robotics Research and Production
Management.

Appendix A.
Theorem 13 (n2 ) is a lower bound for the flipping-sequence search over binary-valued,
tree-structured CP-nets.
Proof: The proof is by example of a dominance testing query over a binary-valued, tree
CP-net for which the size of a minimal flipping sequence is (n2 ).
Consider the following CP-net N defined over binary variables {X1 , . . . , Xn }, where
n = 2k + 1 for some k  N. The domain of each variable Xi is D(Xi ) = {xi , xi }. For
1  i  n, Pa(Xi ) = {Xi1 }, thus N forms a directed chain. The CPTs capturing the
preferences over the values of {X1 , . . . , Xn } are shown in Figure 13(a).
Now consider the dominance testing query JN |= o  o0 K, where, for 1  i  n:
o[Xi ] = xi

xi , i = 2m,
0
o [Xi ] =
xi , i = 2m + 1

mN

The length of the minimal (and actually the only) flipping sequence from o0 to o is k2 +2k+1,
proving the required lower bound. The jth flip on this sequence changes the value of the
variable Xk+1+ , where:
 = bj/(k + 1)c
 = (j  1) mod (k + 1)
Informally, the first k + 1 flips change the values of Xk+1 , . . . , Xn (in this order), next k + 1
flips change the values of Xk , . . . , Xn1 , then Xk1 , . . . , Xn2 , etc. Finally, the last k + 1
flips change the values of X1 , . . . , Xk+1 . There are k + 1 such sets, of k + 1 flips each, the
length of the above flipping sequence is thus k2 + 2k + 1.
Figure 13(b-c) illustrates o and o0 , and the corresponding flipping sequence for k = 2
(i.e., n = 5). In Figure 13(c), each variable Xi is annotated with its value flips along the
flipping sequence: Arrows between the values stand for the value flips, and the sequential
numbers of the flips along the flipping sequence appear as the arrow labels.
179

fiBoutilier, Brafman, Domshlak, Hoos & Poole

89:;
?>=<
X1

x1

7

/ x1


?>=<
89:;
X2

x2

4

/ x2

8

/ x2


?>=<
89:;
X3

x3

1

/ x3

5

/ x3

x4

2

/ x4

6

(a)


?>=<
89:;
X4

/ x4

o = x1 x2 x3 x4 x5
o0 = x1 x2 x3 x4 x5


?>=<
89:;
X5

x5

3

/ x5

Variable

CPT

i=1

xi 

1<ik+1

k+1<in

x0i

xi1

:

xi  xi

xi1

:

xi  xi

xi1

:

xi  xi

xi1

:

xi  xi

(b)

9

/ x3

(c)

Figure 13: Illustration for the proof of Theorem 13: (a) CPTs for n variables; (b) o and o0
for k = 2; and (c) flipping sequence for k = 2.

Now we prove that the size of the minimal flipping sequence for this example (with
n = 2k + 1) is k2 + 2k + 1. We divide the proof into two steps, and show that on a minimal
flipping sequence from o0 to o:
1. For 1  i  k + 1, every variable Xk+i (last k + 1 variables) must change its value at
least k + 2  i times, and
2. For 1  j  k, every variable Xj (first k variables) must change its value at least j
times.
(1) The proof of the first claim is by induction on i. For i = k + 1, the variable X2k+1 (i.e.,
Xn ) must change its value at least once since o[X2k+1 ] 6= o0 [X2k+1 ].
Now, we assume the induction hypothesis that, for l  i  k + 1, every variable Xk+i
must change its value at least k + 2  i times, and prove the claim for Xk+l1 . Recall that
Xk+l1 is the only parent of Xk+l , thus every pair of successive flips of Xk+l must require
different values of Xk+l1 .
Assume that k + l is even. Then, the first flip of Xk+l is from xk+l to xk+l , requiring
Xk+l1 to take the value xk+l1 while o0 [Xk+l1 ] = xk+l1 . Therefore, the first flip of Xk+l
may be performed only after the first flip of Xk+l1 , and therefore, before the flip number
k + 2  l of Xk+l , the variable Xk+l1 will have to change its value at least k + 2  l times.
Now, since k + l is even, then so is k + 2  l. Thus, after k + 2  l flips, the variable Xk+l1
will be assigned the value o0 [Xk+l1 ] = xk+l1 . However, o[Xk+l1 ] = xk+l1 , thus Xk+l1
will have to change its value at least one more time.
The proof for the case of k + l odd is similar: The first flip of Xk+l is from xk+l to xk+l ,
requiring Xk+l1 to take the value xk+l1 while o0 [Xk+l1 ] = xk+l1 . Therefore, before the
180

fiCP-Nets

flip number k+2l of Xk+l , the variable Xk+l1 will have to change its value at least k+2l
times. Now, since k + l is odd, then so is k + 2  l. Thus, after k + 2  l flips, the variable
Xk+l1 will be assigned to the value xk+l1 . However, o[Xk+l1 ] = o0 [Xk+l1 ] = xk+l1 ,
thus Xk+l1 will have to change its value at least one more time. Hence, we proved that,
for i = l  1, Xk+i has to change its value at least k + 2  i (= k + 3  l) times.
(2) The proof of the second claim is by induction on j. First, we show that Xk must change
its value at least k times. From the first claim we have that Xk+1 changes its value at least
k + 1 times. Therefore, since every pair of successive flips of Xk+1 requires different values
of Xk , the variable Xk must change its value at least k times.
Now, we assume the induction hypothesis that, for l  j  k, every variable Xj must
change its value at least j times, and prove the claim for Xl1 . Again, since every pair of
successive flips of Xl requires different values of Xl1 , the variable Xl1 must change its
value at least l  1 times. 
Theorem 15 Dominance testing for binary-valued, directed-path singly connected CP-nets
is np-complete.
Proof: First we show the membership in np. Given a dominance query  = JN |= o  o0 K,
let MinFS() denote the size of a minimal (= shortest) improving flipping sequence from o0
to o. Using the MaxFlip property of the variables, the following upper bound for MinFS()
is straightforward from the Lemma 10:
X
MinFS() 
MaxFlip(Xi )  n2
(2)
Xi V

Thus, if we guess a minimal improving flipping sequence for a given solvable problem, we
can verify it in low order polynomial time.
The proof of hardness is by reduction from 3-sat, i.e., problem of finding a satisfying
assignment for a propositional formula in conjunctive normal form in which each conjunct
(clause) has at most three literals.
Let F = c1  . . .  cn be a 3-sat propositional formula, and x1 , . . . , xm be the variables
used in F. Our equivalent problem can be constructed as follows:
 V = {V1 , V1 , . . . , Vm , Vm }  {C1 , . . . , Cn }, where for 1  i  2m + n, the domain
D(Xi ) = {f, t} (f and t stand for false and true, respectively).
 P a(Vi ) = P a(Vi ) = 
 P a(Ci ) = {Vi1 , Vi1 , Vi2 , Vi2 , Vi3 , Vi3 }, where xi1 , xi2 , and xi3 are the variables that
participate in the ith clause of F.
 Outcome o0 assigns f to all variables in V.
 Outcome o assigns t to all variables in V.
For any variable Vi or Vi , 1  i  m, the value t is (unconditionally) preferred to the
value f . In turn, for 1  i  n, the value t is preferred to the value f for the variable Ci if
there exist a j, 1  j  3, such that:
181

fiBoutilier, Brafman, Domshlak, Hoos & Poole

1. Vij 6= Vij
2. if the literal xij (and not xij ) belongs to the clause ci then Vij = t, otherwise Vij = t
For all other assignments to Pa(Ci ), the value f is preferred to the value t for the variable
Ci .
The constructed inference problem has a directed-path singly connected, binary-valued
CP-net in which for 1  i  n, |Pa(Xi )|  6. Let us show that an improving flipping
sequence from o0 to o exists if and only if a satisfying assignment for F can be found.
 Given a satisfying assignment , the improving flipping sequence is as follows: First,
for 1  j  m, if xj = t in , then flip the value of the variable Vj from f to t. Otherwise, if
xj = f in , then flip the value of the variable Vj from f to t. The actual ordering of these
flips is irrelevant since these variables are mutually independent. Then, for 1  i  n, flip
the value of Ci from f to t. Here also, the ordering of these flips is not significant. Finally,
flip the values of all variables Vj and Vj that still have the value f .
 Let S be an improving flipping sequence from o0 to o. If the value of a variable Ci is
flipped on S while variables Vj , Vj  Pa(Ci ) had the values t, f , respectively, then variable
xj is set to true in . Otherwise, if Ci is flipped on S while variables Vj , Vj  Pa(Ci ) had
the values f, t, respectively, then variable xj is set to false in . Existence of such a j is
ensured by the construction of CP T (Ci ).
In turn, for 1  j  m, neither Vj nor Vj can achieve the value f after achieving the
value t. Hence, if there is an outcome o1  S such that {Vj = t, Vj = f }  o1 , then there
will be no outcome o2  S such that {Vj = f, Vj = t}  o2 , and vice versa. This shows
that the value of each variable Ci is flipped on S from f to t in a context consistent with
. Therefore, for each close ci , there is a literal lij  ci , 1  j  3, such that lij  . 
Theorem 16 Dominance testing for binary-valued, max--connected CP-nets, where  is
polynomially bounded in the size of the CP-net, is np-complete.
Proof: We prove this theorem by showing that, for any acyclic, binary-valued CP-net N ,
and for any variable Xi  N , we have:
MaxFlip(Xi )  1 +

n
X

(Xi , Xj )

(3)

j=i+1

where (Xi , Xj ) denotes the total number of different, not necessary disjoint, paths from Xi
to Xj . For simplicity of presentation, we assume that the variables {X1 , . . . , Xn } of N are
numbered according to a topological order induced by the graph of N , and rewrite Eq. 3
into:
n
X
MaxFlip(Xi )  1 +
(Xi , Xj )
(4)
j=i+1

The proof is by induction on i. For i = n it is obvious that MaxFlip(Xn )  1, since Xn
is a leaf node in N . Now we assume that the lemma holds for any i > k, and prove it for
i = k. Without loss of generality, assume that there exist at least one variable Xj such that
Xk  Pa(Xj ). Otherwise, we simply have that MaxFlip(Xk )  1.
182

fiCP-Nets

Denote by succ(Xk ) the immediate successors of Xk in N , i.e. Xik  succ(Xk ) iff Xk 
Pa(Xik ). The proof is straightforward:
MaxFlip(Xk )

Lemma 9



X

1 +

MaxFlip(Xik ) 

Xik succ(Xk )
I.H.



X

1 + |succ(Xk )| +

Xik succ(Xk )

=

1+

n
X

n
X

(Xik , Xj ) =

j=ik +1

(Xk , Xj )

j=k+1

Now, if a binary-valued CP-net is max--connected, and the variables of a given problem
 are considered in a topological ordering induced by N , then from Eq. 4 it follows that,
for any variable Xi  N , we have:
MaxFlip(Xi )  n + 1

(5)

Let MinFS() denote the size of a minimal (= shortest) improving flipping sequence for
. From Eq. 5 follows that MinFS()  n2 + n. Hence, if  is polynomially bounded in
the size of , then we can guess and verify a minimal improving flipping sequence for  in
polynomial time, and thus this class of dominance testing queries is in np. 
Theorem 20 Flipping sequence search over multi-valued CP-nets with partially specified
preferences is harder than np.
Proof: The proof is by example of a dominance query over a multi-valued, chain CP-net
with partially specified preferences, for which the minimal flipping sequence is exponentially
long.
Consider the following CP-net N defined over three-valued variables {X1 , . . . , Xn },
i }.
where n = 2k + 1 for some k  N. The domain of each variable Xi is D(Xi ) = {xi , xi , x
For 1  i  n, Pa(Xi ) = {Xi1 }, thus N forms a directed chain. The CPTs capturing the
preferences over the values of {X1 , . . . , Xn } are shown in Figure 14.
Now consider the dominance testing query JN |= o  o0 K, where, for 1  i  n,
i . Let the sequence {ai } be defined as:
o[Xi ] = xi and o0 [Xi ] = x
(
2,
i=1
ai =
(6)
2ai1 + 2, i  2
The length of a minimal flipping sequence from o0 to o as above is greater than:
k
X

n

ai > 2 2

i=1

Figure 15 illustrates the corresponding flipping sequence for k = 2 (i.e., n = 5), where
each variable Xi is annotated with its value flips along the flipping sequence: Arrows between
183

fiBoutilier, Brafman, Domshlak, Hoos & Poole

Variable
i=1

CPT
i
xi  xi  x

1<ik+1

i
xi1 : xi  xi  x
i  xi  xi
xi1 : x
i1 : xi  xi  x
i
x

xi1 :

k+1<in


i1 :
x

xi  xi
i
xi  x
xi  xi
i  xi
x

Figure 14:
89:;
?>=<
X1

1
x

10

/ x1

18

/ x1


?>=<
89:;
X2

2
x

3

/ x2

7

/ x2

11

/ x2

15

/ x2

19

/ x2

22

/ x2


?>=<
89:;
X3

3
x

1

/ x3

4

/ x3

8

/ x3

12

/ x3

16

/ x3

20

/ x3


?>=<
89:;
X4

4
x

2

/ x4

5

/ x4

9

/ x4

13

/ x4

17

/ x4

21

/ x4


?>=<
89:;
X5

5
x

6

/ x5

14

/ x5

23

/ x3

Figure 15:

the values stand for the value flips, and the sequential numbers of the flips along the flipping
sequence appear as the arrow labels.
Now we prove that the
P size of the minimal flipping sequence for the dominance query
as above is greater than ki=1 ai . We divide the proof into four steps, where the first step
P
shows the necessity of ki=1 ai flips for any flipping sequence from o0 to o as above, and the
subsequent three steps prove the existence of a flipping sequence from o0 to o. Recall that,
since N forms a chain, for 1 < i  n, Xi1 is the only parent of Xi , thus the value flips of
Xi depend only on the value of Xi1 .
The steps of the proof are as follows:

184

fiCP-Nets

(1) On a flipping sequence from o0 to o, for 2  i  k + 1, every variable Xk+i (last k
variables) must change its value at least ak+2i times, such that if f1k+i, . . . , fak+i
is
k+2i
the corresponding sequence of flips of Xi , then, for 1  j  ak+2i , we have:




xi  xi , j = 4k + 1

x  x , j = 4k + 2
i
i
fjk+i =
kN
(7)

x

x
,
j
=
4k
+
3
i
i



x  x
i , j = 4k
i
(2) For 1  i  k, every variable Xi (first k variables) can change its value ai times, such
that if f1i , . . . , fai i is the corresponding sequence of flips of Xi , then, for 1  j  ai ,
every flip fji is consistent with Eq. 7.
(3) Given the sequence of flips for Xk as in (2), the variable Xk+1 can change its value
ak + 1 times, such that if f1k+1 , . . . , fak+1
is the corresponding sequence of flips of Xk+1 ,
k +1
then, for 1  j  ak + 1, we have:
(
k+1  xk+1 , j = 2k + 1
x
fjk+1 =
kN
(8)
k+1 , j = 2k
xk+1  x
(4) The sequence of flips for Xk+2 as in (1) is feasible given the sequence of flips for Xk+1
as in (3).
Step (1): The proof is by induction on i. For i = k + 1, the variable X2k+1 (i.e., Xn ) must
2k+1  x2k+1 . The only
change its value at least twice, since no value of X2k induces x
2k+1 to x2k+1 is to flip X2k+1 first from x
2k+1 to
way to change the value of X2k+1 from x
x2k+1 , and then from x2k+1 to x2k+1 . Note that these flips are consistent with Eq. 7 and
ak+2(k+1) = a1 = 2, thus we established the induction base.
Now, we assume that the induction hypothesis that, for 2 < l  i  k + 1, every variable
Xi must change its value at least ak+2i times according to Eq. 7, and prove this claim for
Xk+l1 .
Consider the sequence of flips of Xk+l that we assumed to be necessary, i.e., f1k+l , . . . , fak+l
.
k+2l
According to CP T (Xk+l ) we have that:
(i) every pair of successive flips of Xk+l require different values of Xk+l1 ,
k+l1 , xk+l1 }, and
(ii) the required values of Xk+l1 are {x
k+l to xk+l ) requires Xk+l1 = xk+l1 , while o0 [Xk+l1 ] =
(iii) the first flip of Xk+1 (from x
k+l1 .
x
k+l1 to xk+l1 and back, in
Therefore, Xk+l1 must perform ak+2l value changes from x
order to support the required value changes of Xk+l . In addition, after supporting the value
k+l1 to
changes of Xk+l , the variable Xk+l1 must perform another value change from x
0
k+l1 and o[Xk+l1 ] = xk+l1 .
xk+l1 , since ak+2l is even (see Eq. 6), while o [Xk+l1 ] = x
185

fiBoutilier, Brafman, Domshlak, Hoos & Poole

k+l1 to xk+l1
Finally, according to CP T (Xk+l1 ), every value change of Xk+l1 from x
k+l1 consists of two flips: from the initial value to xk+l1 , and
and from xk+l1 to x
from xk+l1 to the target value. Thus the proved that Xk+l1 must perform at least
2(ak+2l + 1) = ak+3l value changes, and that these value changes are consistent with
Eq. 7.
Step (2): The proof is by induction on i. For X1 the proof is straightforward, since o0 [X1 ] =
1 , o[X1 ] = x1 , and CP T (X1 ) allows us to flip the value of X1 from x
1 to x1 , and then
x
from x1 to x1 .
Now we assume the induction hypothesis that, for 1  i < k, every variable Xi can
change its value ai times according to Eq. 7, and prove the claim for Xi+1 . The proof is
apparent from CP T (Xi+1 ), the outcomes o and o0 in query, and the induction hypothesis.
For every value achieved by Xi along its sequence of ai flips (including the initial value
i ), Xi+1 can flip its value twice: Given Xi = x
i or Xi = xi , we can flip the value
o0 [Xi ] = x
i+1 to xi+1 , and then from xi+1 to xi+1 . Alternatively, given Xi = xi ,
of Xi+1 first from x
i+1 . Therefore,
we can flip the value of Xi+1 from xi+1 to xi+1 , and then from xi+1 to x
Xi+1 can flip its value 2(ai + 1) = ai+1 times, and it is easy to see that these value flips of
Xi+1 are consistent with Eq. 7.
Step (3): Given the sequence of ak flips f1k , . . . , fakk of Xk as in Eq. 7, let val(fjk )  Dom(Xk )
be the value of Xk achieved by the flip fjk , for 1  j  ak . CP T (Xk+1 ) entails that, for any
k , f k , 1  j  a  2,
triple of values of Xk achieved by a triple of successive flips fjk , fj+1
k
j+2
we have either:
val(fjk )

:

k+1
xk+1  x

k
val(fj+1
)

:

k+1  xk+1
x

k
val(fj+2
)

:

k+1
xk+1  x

val(fjk )

:

k+1  xk+1
x

k
val(fj+1
)

:

k+1
xk+1  x

k
val(fj+2
)

:

k+1  xk+1
x

or

In addition, we know that:
k : xk+1  x
k+1
o0 [Xk ] = x
and
k+1  xk+1
val(f1k ) = xk : x
The above entails that Xk+1 can change its value ak + 1 times according to Eq. 8.
Step (4): The proof of this subclaim is straightforward from CP T (Xk+2 ). Given the sequence of Xk+2 value flips f1k+2 , . . . , fak+2
as in Eq. 7, observe that, for 1  j  ak , if
k
186

fiCP-Nets

j = 2k + 1 for some k  N, then fjk+2 can be supported by the value xk+1 of Xk+1 , otherk+1 of Xk+1 . Now, since
wise, if j = 2k, k  N, then fjk+2 can be supported by the value x
for 1  l  ak + 1,
(
xk+1 , l = 2m + 1
val(flk+1 ) =
mN
k+1 , l = 2m
x
it is apparent that the sequence of ak value flips of Xk+2 as in Eq. 7 is feasible given the
sequence of ak + 1 value flips12 of Xk+1 as in Eq. 8.
0
The above entails
size of the minimal flipping sequence from
Pk that N |= o  o , and that the
n
0
o to o in N is i=1 ai , which is greater than 2 2 . In fact, it can be show that the value flips
for X1 , . . . , Xk+1 , constructed in steps (2)-(3), are the part of the minimal flipping sequence
from o0 to o, thus the length of this sequence is greater than:

2

k
X

ai + (ak + 1)

i=1

However, the result achieved in step (1) already proves our claim that there exist dominance
queries on multi-valued CP-nets with partially specified preferences, for which there are
exponentially sized minimal flipping sequences. 

References
Bacchus, F., & Grove, A. (1995). Graphical models for preference and utility. In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, pp. 310,
Montreal.
Bacchus, F., & Grove, A. (1996). Utility independence in qualitative decision theory. In
Proceedings of the Sixth International Conference on Principles of Knowledge Representation and Reasoning, pp. 542552, Cambridge.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Benferhat, S., Dubois, D., & Prade, H. (2001). Towards a possibilistic logic handling of
preferences. Applied Intelligence, 303317.
Boutilier, C. (1994). Toward a logic for qualitative decision theory. In Proceedings of
the Fifth International Conference on Principles of Knowledge Representation and
Reasoning, pp. 7586, Bonn.
Boutilier, C., Bacchus, F., & Brafman, R. I. (2001). UCP-Networks: A directed graphical
representation of conditional utilities. In Proceedings of the Seventeenth Conference
on Uncertainty in Artificial Intelligence, pp. 5664, Seattle.
Boutilier, C., Brafman, R., Geib, C., & Poole, D. (1997). A constraint-based approach to
preference elicitation and decision making. In AAAI Spring Symposium on Qualitative
Decision Theory, Stanford.
12. In fact, only ak value flips of Xk+1 are used in order to perform ak value flips of Xk+2 as required. The
last flip of Xk+1 is used in order to achieve the value o[Xk+1 ] for Xk+1 after supporting Xk+2 .

187

fiBoutilier, Brafman, Domshlak, Hoos & Poole

Brafman, R., & Domshlak, C. (2001). CP-networks for preference-based CSP. In Proceedings
of the Workshop on Modelling and Solving Problems with Soft Constraints (in CP-01),
pp. 3142, Paphos, Cyprus.
Brafman, R., & Domshlak, C. (2002). Introducing variable importance tradeoffs into CPnets. In Proceedings of the Eighteenth Annual Conference on Uncertainty in Artificial
Intelligence, pp. 6976, Edmonton, Canada.
Brafman, R., & Domshlak, C. (2003). Structure and complexity in planning with unary
operators. Journal of Artificial Intelligence Research. to appear.
Brafman, R. I., & Dimopoulos, Y. (2003). A new look at the semantics and optimization
methods of CP-networks. In Proceedings of of the Eighteenth International Joint
Conference on Artificial Intelligence, Acapulco, Mexico. to appear.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69 (1-2), 165204.
Castaneda, H. N. (1958). Review of Hallden On the Logic of Better. Philosophy and
Phenomenological Research, 19, 266.
Chajewska, U., Getoor, L., Norman, J., & Shahar, Y. (1998). Utility elicitation as a classification problem. In Proceedings of the Fourteenth Conference on Uncertainty in
Artificial Intelligence, pp. 7988, Madison, WI.
Cormen, T. H., Lierson, C. E., & Rivest, R. L. (1990). Introduction to Algorithms. MIT
Press, Cambridge, MA.
DAmbrosio, J. G., & Birmingham, W. P. (1995). Preference-directed design. Journal for
Artificial Intelligence in Engineering Design, Analysis and Manufacturing, 9, 219230.
Domshlak, C. (2002a). Modeling and Reasoning about Preferences with CP-nets. Ph.D.
thesis, Ben-Gurion University. (forthcoming).
Domshlak, C. (2002b). On recursively directed hypercubes. The Electronic Journal of
Combinatorics, 9 (1).
Domshlak, C., & Brafman, R. (2002a). CP-nets - reasoning and consistency testing. In
Proceedings of the Eighth International Conference on Principles of Knowledge Representation and Reasoning, pp. 121132, Toulouse, France.
Domshlak, C., & Brafman, R. (2002b). Structure and complexity in planning with unary operators. In Proceedings of the Sixth International Conference on Artificial Intelligence
Planning and Scheduling, pp. 6069, Toulouse, France.
Domshlak, C., Brafman, R., & Shimony, S. E. (2001). Preference-based configuration of
web page content. In Proceedings of Seventeenth International Joint Conference on
Artificial Intelligence, pp. 14511456, Seattle.
Domshlak, C., Rossi, F., Venable, C., & Walsh, T. (2003). Reasoning about soft constraints
and conditional preferences: Complexity results and approximation techniques. In
Proceedings of of the Eighteenth International Joint Conference on Artificial Intelligence, Acapulco, Mexico. to appear.
188

fiCP-Nets

Domshlak, C., & Shimony, S. E. (2003). Efficient probabilistic reasoning in bayes nets with
mutual exclusion and context specific independence. In to appear in Proceedings of the
Sixteenth International FLAIRS Conference, Special Track on Uncertain Reasoning.
Doyle, J., Shoham, Y., & Wellman, M. (1991). A logic of relative desire (preliminary report).
In Proceedings of the Sixth International Symposium on Methodologies for Intelligent
Systems (ISMIS91), Lecture Notes in Computer Science, pp. 1631. Springer-Verlag.
Doyle, J., & Wellman, M. (1994). Representing preferences as ceteris paribus comparatives.
In Proceedings of the AAAI Spring Symposium on Decision-Theoretic Planning, pp.
6975, Stanford.
Dubois, D., Berre, D. L., Prade, H., & Sabbadin, R. (1998a). Logical representation and
computation of optimal decisions in a qualitative setting. In Proceedings of the Fifteenth National Conference on Artificial Intelligence, pp. 588593, Madison, WI.
Dubois, D., Godo, L., Prade, H., & Zapico, A. (1998b). Making decision in a qualitative
setting: From decision under uncertainty to case-based decision. In Proceedings of the
International Conference on Principles of Knowledge Representation and Reasoning,
pp. 594605. Morgan-Kauffman.
Dubois, D., Prade, H., & Sabbadin, R. (1997). A possibilistic logic machinery for qualitative
decision. In AAAI Spring Symposium on Qualitative Preferences in Deliberation and
Practical Reasoning, pp. 4754, Stanford.
Dyer, J. S. (1972). Interactive goal programming. Management Science, 19, 6270.
French, S. (1986). Decision Theory. Halsted Press, New York.
Freuder, E., & OSullivan, B. (2001). Modeling and generating tradeoffs for constraintbased configuration. In Proceedings of 4th Workshop on Configuration (IJCAI-01),
pp. 3844, Seattle.
Gudes, E., Domshlak, C., & Orlov, N. (2002). Remote conferencing with multimedia objects.
In Proceedings of the Second International Workshop on Multimedia Data Document
Engineering (MDDE02).
Ha, V., & Haddawy, P. (1998). Toward case-based preference elicitation: Similarity measures
on preference structures. In Proceedings of the Fourteenth Conference on Uncertainty
in Artificial Intelligence, pp. 193201, Madison, WI.
Haag, A. (1998). Sales configuration in business processes. IEEE Intelligent Systems and
their Applications, 13 (4), 7885.
Hallden, S. (1957). On the Logic of Better. Lund.
Hansson, S. O. (1996). What is ceteris paribus preference. Journal of Philosophical Logic,
25 (3), 307332.
Howard, R. A., & Matheson, J. E. (Eds.). (1984). Readings on the Principles and Applications of Decision Analysis. Strategic Decision Group, Menlo Park, CA.
Ignizio, J. P. (1982). Linear Programming in Single and Multiple Objective Systems.
Prentice-Hall, Englewood Cliffs.
189

fiBoutilier, Brafman, Domshlak, Hoos & Poole

Junker, U. (1997). A cumulative-model semantics for dynamic preferences on assumptions.
In Proceedings of the Fifteen International Joint Conference on Artificial Intelligence,
pp. 162167, Nagoya, Japan.
Junker, U. (2001). Preference programming for configuration. In Proceedings of 4th Workshop on Configuration (IJCAI-01), pp. 5056, Seattle.
Keeney, R. L., & Raiffa, H. (1976). Decisions with Multiple Objectives: Preferences and
Value Trade-offs. Wiley, New York.
Knoblock, C. A. (1994). Automatically generating abstractions for planning. Artificial
Intelligence, 68, 243302.
Kron, A., & Milovanovic, V. (1975). Preference and choice. Theory and Decision, 6, 185196.
La Mura, P., & Shoham, Y. (1999). Expected utility networks. In Proceedings of the
Fifteenth Conference on Uncertainty in Artificial Intelligence, pp. 366373, Stockholm.
Lashkari, Y., Metral, M., & Maes, P. (1994). Collaborative interface agents. In Proceedings
of the Twelfth National Conference on Artificial Intelligence, pp. 444449, Seattle.
Nguyen, H., & Haddawy, P. (1998). The decision-theoretic video advisor. In AAAI-98
Workshop on Recommender Systems, pp. 7780, Madison, WI.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, San Mateo.
Sabin, D., & Weigel, R. (1998). Product conguration frameworks - a survey. IEEE Intelligent
Systems and their Applications, 13 (4), 4249.
Shimony, S. E., & Domshlak, C. (2002). Complexity of probabilistic reasoning in (directedpath) singly connected (not polytree!) Bayes networks. submitted for publication.
Shoham, Y. (1987). A semantical approach to nonmonotonic logics. In Proceedings of Tenth
International Joint Conference on Artificial Intelligence, pp. 388392.
Shoham, Y. (1997). Conditional utility, utility independence, and utility networks. In Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intelligence,
pp. 429436, San Francisco, CA. Morgan Kaufmann Publishers.
Soininen, T., & Niemela, I. (1998). Formalizing configuration knowledge using rules with
choices. In Seventh International Workshop on Nonmonotonic Reasoning, Trento.
Tan, S.-W., & Pearl, J. (1994). Specification and evaluation of preferences for planning
under uncertainty. In Proceedings of the Fifth International Conference on Principles
of Knowledge Representation and Reasoning, pp. 530539, Bonn.
Trapp, R. (1985). Utility theory and preference logic. Erkenntnis, 22, 331339.
von Wright, G. H. (1963). The Logic of Preference: An Essay. Edinburgh University Press.
von Wright, G. H. (1972). The logic of preference reconsidered. Theory and Decisions, 3,
140167. Reprinted in (von Wright, 1984).
von Wright, G. H. (1984). Philosophical logic: Philosophical Papers, Volume II. Cornell
University Press, Ithaca, NY.
190

fiCP-Nets

Wellman, M., & Doyle, J. (1991). Preferential semantics for goals. In Proceedings of the
Ninth National Conference on Artificial Intelligence (AAAI-91), pp. 698703, Anaheim.

191

fiJournal of Artificial Intelligence Research 21 (2004) 393-428

Submitted 07/03; published 03/04

A Personalized System for Conversational Recommendations
Cynthia A. Thompson

cindi@cs.utah.edu

School of Computing
University of Utah
50 Central Campus Drive, Rm. 3190
Salt Lake City, UT 84112 USA

Mehmet H. Goker

mgoker@kaidara.com

Kaidara Software Inc.
330 Distel Circle, Suite 150
Los Altos, CA 94022 USA

Pat Langley

langley@isle.org

Institute for the Study of Learning and Expertise
2164 Staunton Court
Palo Alto, CA 94306 USA

Abstract
Searching for and making decisions about information is becoming increasingly difficult as the amount of information and number of choices increases. Recommendation
systems help users find items of interest of a particular type, such as movies or restaurants, but are still somewhat awkward to use. Our solution is to take advantage of the
complementary strengths of personalized recommendation systems and dialogue systems,
creating personalized aides. We present a system  the Adaptive Place Advisor  that
treats item selection as an interactive, conversational process, with the program inquiring about item attributes and the user responding. Individual, long-term user preferences
are unobtrusively obtained in the course of normal recommendation dialogues and used to
direct future conversations with the same user. We present a novel user model that influences both item search and the questions asked during a conversation. We demonstrate the
effectiveness of our system in significantly reducing the time and number of interactions
required to find a satisfactory item, as compared to a control group of users interacting
with a non-adaptive version of the system.

1. Introduction and Motivation
Recommendation systems help users find and select items (e.g., books, movies, restaurants)
from the huge number available on the web or in other electronic information sources (Burke,
1999; Resnick & Varian, 1997; Burke, Hammond, & Young, 1996). Given a large set of
items and a description of the users needs, they present to the user a small set of the items
that are well suited to the description. Recent work in recommendation systems includes
intelligent aides for filtering and choosing web sites (Eliassi-Rad & Shavlik, 2001), news
stories (Ardissono, Goy, Console, & Torre, 2001), TV listings (Cotter & Smyth, 2000), and
other information.
The users of such systems often have diverse, conflicting needs. Differences in personal
preferences, social and educational backgrounds, and private or professional interests are
pervasive. As a result, it seems desirable to have personalized intelligent systems that
c
2004
AI Access Foundation. All rights reserved.

fiThompson, Goker, & Langley

process, filter, and display available information in a manner that suits each individual
using them. The need for personalization has led to the development of systems that adapt
themselves by changing their behavior based on the inferred characteristics of the user
interacting with them (Ardissono & Goy, 2000; Ferrario, Waters, & Smyth, 2000; Fiechter
& Rogers, 2000; Langley, 1999; Rich, 1979).
The ability of computers to converse with users in natural language would arguably
increase their usefulness and flexibility even further. Research in practical dialogue systems,
while still in its infancy, has matured tremendously in recent years (Allen, Byron, Dzikovska,
Ferguson, Galescu, & Stent, 2001; Dybkjr, Hasida, & Traum, 2000; Maier, Mast, &
Luperfoy, 1996). Todays dialogue systems typically focus on helping users complete a
specific task, such as planning, information search, event management, or diagnosis.
In this paper, we describe a personalized conversational recommendation system designed to help users choose an item from a large set all of the same basic type. Our goal
is to support conversations that become more efficient for individual users over time. Our
system, the Adaptive Place Advisor, aims to help users select a destination (in this
case, restaurants) that meets their preferences.
The Adaptive Place Advisor makes three novel contributions. To our knowledge,
this is the first personalized spoken dialogue system for recommendation, and one of the
only conversational natural language interfaces that includes a personalized, long-term user
model. Second, it introduces a novel model for acquiring, utilizing, and representing user
models. Third, it is used to demonstrate a reduction in the number of system-user interactions and the conversation time needed to find a satisfactory item.
The combination of dialogue systems with personalized recommendation addresses weaknesses of both approaches. Most dialogue systems react similarly for each user interacting
with them, and do not store information gained in one conversation for use in the future.
Thus, interactions tend to be tedious and repetitive. By adding a personalized, long-term
user model, the quality of these interactions can improve drastically. At the same time,
collecting user preferences in recommendation systems often requires form filling or other
explicit statements of preferences on the users part, which can be difficult and time consuming. Collecting preferences in the course of the dialogue lets the user begin the task of
item search immediately.
The interaction between conversation and personalized recommendation has also affected our choices for the acquisition, utilization, and representation of user models. The
Adaptive Place Advisor learns information about users unobtrusively, in the course
of a normal conversation whose purpose is to find a satisfactory item. The system stores
this information for use in future conversations with the same individual. Both acquisition
and utilization occur not only when items are presented to and chosen by the user, but
also during the search for those items. Finally, the systems representation of models goes
beyond item preferences to include preferences about both item characteristics and particular values of those characteristics. We believe that these ideas extend to other types of
preferences and other types of conversations.
In this paper, we describe our work with the Adaptive Place Advisor. We begin
by introducing personalized and conversational recommendation systems, presenting our
design decisions along the way. In Section 3 we describe the system in detail, while in

394

fiPersonalized Conversational Recommendation

Section 4 we present our experimental evaluation. In Sections 5 and 6 we discuss related
and future work, respectively, and in Section 7 we conclude and summarize the paper.

2. Personalized Conversational Recommendation Systems
Our research goals are two-fold. First, we want to improve both interaction quality in
recommendation systems and the utility of results returned by making them user adaptive
and conversational. Second, we want to improve dialogue system performance by means of
personalization. As such, our goals for user modeling differ from those commonly assumed
in recommendation systems, such as improving accuracy or related measures like precision
and recall. Our goals also differ from that of previous work in user modeling in dialogue
systems (Haller & McRoy, 1998; Kobsa & Wahlster, 1989; Carberry, 1990; Kass, 1991),
which emphasizes the ability to track the users goals as a dialogue progresses, but which
does not typically maintain models across multiple conversations.
Our hypothesis is that improvements in efficiency and effectiveness can be achieved by
using an unobtrusively obtained user model to help direct the systems conversational search
for items to recommend. Our approach assumes that there is a large database of items from
which to choose, and that a reasonably large number of attributes is needed to describe
these items. Simpler techniques might suffice for situations where the database is small or
items are easy to describe.
2.1 Personalization
Personalized user adaptive systems obtain preferences from their interactions with users,
keep summaries of these preferences in a user model, and utilize this model to generate
customized information or behavior. The goal of this customization is to increase the
quality and appropriateness of both the interaction and the result(s) generated for each
user.
The user models stored by personalized systems can represent stereotypical users (Chin,
1989; Rich, 1979) or individuals, they can be hand-crafted or learned (e.g., from questionnaires, ratings, or usage traces), and they can contain information about behavior such
as previously selected items, preferences regarding item characteristics (such as location or
price), or properties of the users themselves (such as age or occupation) (Kobsa & Wahlster,
1989; Rich, 1979). Also, some systems store user models only for the duration of one interaction with a user (Carberry, Chu-Carroll, & Elzer, 1999; Smith & Hipp, 1994), whereas
others store them over the long term (Rogers, Fiechter, & Langley, 1999; Billsus & Pazzani,
1998).
Our approach is to learn probabilistic, long-term, individual user models that contain
information about preferences for items and item characteristics. We chose learned models
due to the difficulty of devising stereotypes or reasonable initial models for each new domain
encountered. We chose probabilistic models because of their flexibility: a single user can
exhibit variable behavior and their preferences are relative rather than absolute. Long-term
models are important to allow influence across multiple conversations. Also, as already
noticed, different users have different preferences, so we chose individual models. Finally,
preferences about items and item characteristics are needed to influence conversations and
retrieval.
395

fiThompson, Goker, & Langley

Once the decision is made to learn models, another design decision relates to the method
by which a system collects preferences for subsequent input to the learning algorithm(s).
Here we can distinguish between two approaches. The direct feedback approach places the
burden on the user by soliciting preference information directly. For example, a system
might ask the user to complete a form that asks her to classify or weight her interests using
a variety of categories or item characteristics. A recent study (McNee, Lam, Konstan,
& Riedl, 2003) showed that forcing the user to provide ratings for items (movies, in this
case) that they choose, rather than those that the system chooses, can actually lead to
better accuracy rates and better user loyalty. However, users can be irritated by the need
to complete long questionnaires before they can even begin to enjoy a given service, and
the study was not in the context of a dialogue system but involved a simpler interaction.
Another, slightly less obtrusive, form of direct feedback encourages the user to provide
feedback as she continues to use a particular service.
The second approach to acquiring user models, and the one taken in the Adaptive
Place Advisor, is to infer user preferences unobtrusively, by examining normal online behavior (Fiechter & Rogers, 2000; Rafter, Bradley, & Smyth, 2000). We feel that unobtrusive
collection of preferences is advantageous, as it requires less effort from the user. Also, users
often cannot articulate their preferences clearly until they learn more about the domain. A
possible disadvantage to unobtrusive approaches is that users may not trust or understand
the systems actions when they change from one interaction to the next. This could be
addressed by also letting the user view and modify the user model (Kay & Thomas, 2000).
Systems typically take one of two approaches to preference determination. Contentbased methods recommend items similar to ones that the user has liked in the past (Segal &
Kephart, 1999; Pazzani, Muramatsu, & Billsus, 1996; Lang, 1995). In contrast, collaborative
methods select and recommend items that users similar to the current user have liked in
previous interactions (Cotter & Smyth, 2000; Billsus & Pazzani, 1998; Konstan, Miller,
Maltz, Herlocker, Gordon, & Riedl, 1997; Shardanand & Maes, 1995). Because collaborative
filtering bases recommendations on previous selections of other users, it is not suitable for
new or one-off items or for users with uncommon preferences. The content-based approach,
on the other hand, uses the item description itself for recommendation, and is therefore not
prone to these problems. However, content-based techniques tend to prefer the attribute
values that users have preferred in the past, though they do allow new combinations of
values. We feel that the benefits of a content-based approach outweigh the disadvantages; we
discuss methods for overcoming these disadvantages and for combining the two techniques
in Section 6.3.
Ultimately, personalization is about how one can utilize a learned user profile to search
for, identify, and present relevant information to the right user in the right way at the right
time. User models have been utilized in recommendation systems for content processing and
selection (information filtering), navigation support in web browsers (Pazzani et al., 1996),
and choice of modality and style of presentation and interaction (Brusilovsky & Maybury,
2002). The Adaptive Place Advisor adapts its information filtering and interaction
behavior, since these are most relevant for our application and since the majority of the
interaction is through natural language.

396

fiPersonalized Conversational Recommendation

2.2 Conversational Recommendation
The goal of recommendation systems is to help users find items of interest, and thus they
must eliminate some choices from consideration while keeping others. To achieve this, they
must either know or determine the interests of the current user, then present items that
satisfy those interests.
One of the most widely used approaches for information acquisition in recommendation
systems is the use of a simple form (usually a single query box) that the user fills in. Coupled
with this, a common presentation format is the ranked list approach. In this scheme, the
system presents a usually long list of results, ordered by their predicted relevance to the
user. The combined technique of information acquisition through a form and presentation
in a list originated in information retrieval, where it was used to help find documents or
reports during library research. The basic method, which we refer to as the ranked list
approach, is more general, however, and it underlies the simpler search engines for the
World Wide Web, which are used regularly for many different selection tasks.
In contrast, the Adaptive Place Advisor supports conversations as its mode of
interaction. In this approach, one conversational participant, which we call the inquirer,
asks a second participant, which we call the advisor, for assistance in selecting an item. For
example, if the inquirer is deciding on a restaurant at which to have dinner, the conversation
may proceed as follows:
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.

Inquirer: Where do you think I should eat tonight?
Advisor: What type of food would you like?
Inquirer: What types are there?
Advisor: You can say things like Chinese, Indian, and Mediterranean.
Inquirer: Oh, maybe a cheap Indian place.
Advisor: What kind of parking would you like?
Inquirer: I dont care, as long as its in Palo Alto.
Advisor: Im sorry, I dont know of any restaurants like that, would you like to search
for any price?
Inquirer: No, I think Id like Chinese instead.
Advisor: How does Mandarin Gourmet on 420 Ramona sound?1
Inquirer: No, what else do you have?
Advisor: How about Jing-Jing Szechwan Hunan Gourmet on 443 Emerson Street?
Inquirer: Sure, that sounds fine.

We will refer to systems that mimic this approach to recommendation as conversational
recommendation systems.
The interaction supported by conversational recommendation systems is quite different
from that found in the ranked list approach. The most important distinction is that the
interaction takes the form of a sequence of questions, most designed to eliminate some items
from consideration. Answering these questions plays a similar role to giving keywords in
a form, but the aim is to remove alternatives rather than to rank results in a list. This
1. Our system does not support this exact sample dialogue. For example, at this point in a conversation it
displays the information about the restaurant on the screen and asks How does this one sound? or a
similar question.

397

fiThompson, Goker, & Langley

conversational process can also help the inquirer better understand his own desires, since
thinking about possible questions and answers may clarify goals in ways that keyword entry
does not encourage. In addition, a conversation can support user variability by letting the
user control item and attribute choices in each conversation. Finally, the inquirer never
hears about a complete item until at most a few choices remain. This avoids presenting
a long list of items and lets the user narrow down the choices in an iterative, manageable
fashion.
Such dialogues seem better for recommendations that must be delivered by speech rather
than visually, for example those engaged in while the inquirer is driving. They also seem
ideal, independent of modality, for tasks like destination selection or help-desk support
(Goker & Roth-Berghofer, 1999; Aha & Breslow, 1997), in which the user needs to converge
on at most a few items. On the other hand, keyword entry and ranked list methods seem
more appropriate in situations where the user prefers to provide all requirements at once,
in situations where information can be presented visually, and in situations where the user
may want to examine many options.
By eliminating options, conversational recommendation systems ultimately direct their
users to a suitable solution. However, such a conversation can become tiring and the quality
of the first result returned may not be acceptable for each user. Just as interactions with
a friend who knows your concerns can be more directed and produce better results than
those with a stranger, dialogues with a conversational advisor should become more efficient
and effective over time. Our goals for user modeling include improvement of the subjective
quality and effectiveness of both the results (found items) and the conversation that leads
to these results. For example, after several conversations with the inquirer above, a new
interaction may proceed as follows, where the question about parking has been eliminated
and the item presentation order has changed:
1.
2.
3.
4.
5.
6.
7.

Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:

Where do you think I should eat tonight?
What type of food would you like?
Oh, maybe a Chinese place.2
What city do you prefer?
Do you have something in Palo Alto?
How does Jing-Jing Szechuan Gourmet on 443 Emerson sound?
Sure, that sounds fine.

We turn next to our design choices concerning the management of such conversations.
2.3 Conversation via Dialogue Management
Dialogue systems carry out conversations with users in natural language, whether spoken or
typed. The main tasks performed by dialogue systems are language interpretation, language
generation, and dialogue management. Natural language interpretation and generation
are topics onto themselves and we will not discuss them here; for two introductory texts,
see Allen (1995) and Jurafsky and Martin (2000). To enable a focus on user modeling,
our system allows moderately complex user utterances but has a pre-coded set of system
utterances, as discussed further in Section 3.3.
2. This response shows that the Inquirer will have learned how to use the system more efficiently as well.

398

fiPersonalized Conversational Recommendation

The simplest dialogue managers are based on finite-state automata in which the states
correspond to questions and arcs correspond to actions that depend on a user-provided
response (Stent, Dowding, Gawron, Bratt, & Moore, 1999; Winograd & Flores, 1986).
These systems support what are called fixed- or system-initiative conversations, in which
only one of the participants controls the actions, whether it be the system helping the user
or the user asking questions of the system. Next in complexity are frame- or template-based
systems in which questions can be asked and answered in any order (Bobrow et al., 1977).
Next, true mixed-initiative systems allow either dialogue participant to contribute to the
interaction as their knowledge permits (Allen, 1999; Haller & McRoy, 1998; Pieraccini,
Levin, & Eckert, 1997). Thus, the conversational focus can change at any time due to the
users (or systems) initiative of that change. Finally, some different approaches that support
sophisticated dialogues include plan-based systems (Allen et al., 1995; Cohen & Perrault,
1979) and systems using models of rational interaction (Sadek, Bretier, & Panaget, 1997).
To allow reasonably complex conversations while keeping the system design straightforward, we chose a frame-based approach to dialogue management. Thus, the Adaptive Place Advisor allows more conversational flexibility than a fully system-initiative
paradigm would allow. Users can fill in attributes other than or in addition to those suggested by the system. However, they cannot force the system to transition to new subtasks,
nor can the system negotiate with users to determine which participant should take the
initiative.
2.4 Interactive Constraint-Satisfaction Search
Constraint-satisfaction problems provide a general framework for defining problems of interest in many areas of artificial intelligence, such as scheduling and satisfiability (Kumar,
1992). In their most general form, constraint-satisfaction problems involve a set of variables
whose domains are finite and discrete, along with a set of constraints that are defined over
some subset of the variables and that limit the value combinations those variables can take.
The goal is to find an assignment of values to variables that satisfies the given constraints.
Cucchiara, Lamma, Mello, and Milano (1997) define the class of interactive constraintsatisfaction problems that involve three extensions to the standard formulation. First,
they include a constraint acquisition stage during which a user can incrementally add new
constraints to the problem being solved. Second, a variables domain can include both a
defined and undefined portion, and the user can add new values to the defined portion
during constraint acquisition. Third, they allow incremental update of a partial solution
based on the domain and constraint updates.
This framework can encompass the item search portion of the conversations managed by
the Adaptive Place Advisor; it does not include the item presentation portion. In our
setting, constraints are simply attribute-value specifications, such as cuisine = Chinese.
The Place Advisors search is not as fully general as this framework, in that it does
not incorporate the notion of undefined portions of domains. However, it does acquire
constraints via the users specifications during a conversation and incrementally updates
solutions in response.

399

fiThompson, Goker, & Langley

System Output
(Voice)

Prompts

User Input
(Voice)

Speech Generator

Speech Recognizer

System Operators
and Values

User Operators
and Values
Domain
Model

Dialogue Manager

Conversation History

User
Models

Initial Query

Recognition
Grammars

Results,
Attribute Information

User Modeling
System

Updated Query

Retrieval Engine

Item
Database

Figure 1: Components of the Adaptive Place Advisor and their interactions.

3. The Adaptive Place Advisor
In this section, we first present an overview of the Adaptive Place Advisors functioning,
then follow with details about its components.3 The system carries out a number of tasks
in support of personalized interaction with the user; in particular, it:










utilizes the user model to initialize a probabilistic item description as an expanded query,
generates context-appropriate utterances,
understands the users responses,
refines the expanded query with the explicit requirements (constraints) obtained from
the user during the conversation,
retrieves items matching the explicitly specified part of the query from a database,
calculates the similarity of the retrieved items to the query,
selects the next attribute to be constrained or relaxed during a conversation when the
number of highly similar items is not acceptable,
presents suitable items when the number of items is acceptable, and
acquires and updates the user model based on these interactions.

The responsibilities for these tasks are distributed among various modules of the system,
as shown in Figure 1. The Dialogue Manager generates, interprets, and processes conversations; it also updates the expanded query after each user interaction. The Retrieval Engine
is a case-based reasoning system (Aamodt & Plaza, 1994) that uses the expanded query to
retrieve items from the database and to measure their similarity to the users preferences.
The User Modeling System generates the initial (probabilistic) query and updates the longterm user model based on the conversation history. The Speech Recognizer and the Speech
Generator handle the users input and control the systems output, respectively.
3. As further discussed in Section 5.2, our approach to destination advice draws on an earlier analysis of
the task by Elio and Haddadi (1998, 1999).

400

fiPersonalized Conversational Recommendation

To find items to recommend to the user, the Place Advisor carries out an augmented
interactive constraint-satisfaction search. The goal of the entire conversation is to present
an item that will be acceptable to the user. During the constraint-satisfaction portion,
the system carries out a conversation to find a small set of such items. During the search
phase, two situations determine the systems search operators and thus its questions. First,
an under-constrained specification means that many items match the constraints, and the
system must obtain more information from the user. Second, if there are no matching items,
the system must relax a constraint, thus allowing items to contain any domain value for the
relaxed attribute.4 The system ends the search phase when only a small number of items
match the constraints and are highly similar (based on a similarity threshold) to the users
preferences. Item presentation (in similarity order) begins at this point, with a similarity
computation used to rank the items that satisfy the constraints.
The search and item presentation process is also influenced by the User Modeling System
and thus is personalized. The main mechanism for personalization is through the expanded
query, a probabilistic representation of the users preferences, both long-term (over many
conversations) and short-term (within a conversation). We will often just refer to this as the
query, but it always refers to constraints that are both explicitly and implicitly specified
by the user. Thus, the query is expanded beyond the explicit (short-term) constraints
using the (long-term) constraints implicit in the user model. In a sense, the initial query
represents what constraints the system thinks the user will probably want. The system
incrementally refines this query in the course of the conversation with the user, setting
explicit, firm constraints as the user verifies or disconfirms its assumptions. Over the long
term, the User Modeling System updates the user model based on the users responses to
the attributes and items offered during a conversation.
The Retrieval Engine searches the database for items that match the explicit constraints
in the query. It then computes the similarity of the retrieved items to the users preferences
as reflected in the expanded part of the query. Depending on the number of highly similar results, the Retrieval Engine also determines which attribute should be constrained or
relaxed.
In sum, the system directs the conversation in a manner similar to a frame-based system,
retrieves and ranks items using a case-based reasoning paradigm, and adapts the weights
in its similarity calculation based on past conversations with a user, thereby personalizing
future retrievals and conversations. In this section, we present the details of the Adaptive
Place Advisors architecture. After describing the user model, we elaborate on the
Retrieval Engine then the Dialogue Manager. Finally, we discuss how the system updates
the user model as the user interacts with it.
3.1 The User Model
Our focus on personalized conversation suggests a fine-grained model of user preferences,
emphasizing the questions a user prefers to answer and the responses he tends to give, in
addition to preferences about entire items. We now describe that model in more detail. In
later sections, we will describe how it influences item ranking and question ordering, which
4. Because other constraints can later be modified, the system lets the user later specify any value, even
the one that caused the over-constrained situation.

401

fiThompson, Goker, & Langley

Table 1: Example of a user model.
User Name

Homer

Attributes

wi

Cuisine

0.4

Values and probabilities
Italian

French

Turkish

Chinese

German

English

0.35

0.2

0.25

0.1

0.1

0.0

0.2

one

two

three

four

five

0.3

0.3

0.1

0.1

...

...

0.2
...

Parking

0.1

Price Range

Item Nbr.
Accept/Present

Valet

Street

Lot

0.5

0.4

0.1

0815

5372

7638

...

6399

23 / 25

10 / 19

33 / 36

...

12 / 23

in turn determine how quickly the system can stop asking questions and start presenting
items. In general, a user may tend to:





answer questions about some attributes more often than others,
provide some attribute values more often than others,
choose some items more often than others,
provide certain combinations of values more often than their independent distribution
would predict, and
 accept either large or small amounts of value and item diversity.

All of these tendencies are influenced by the users preferences, which in turn are captured
by our user model. Attribute preferences represent the relative importance a user places on
attributes (e.g., cuisine vs. price) while selecting an item. Preferred values show the users
bias towards certain item characteristics (e.g., Italian restaurants vs. French restaurants).
Item preferences are reflected in a users bias for or against a certain item, independent of its
characteristics. Combination preferences represent constraints on the combined occurrence
of item characteristics (e.g., accepts restaurants in San Francisco only if they have valet
parking). Diversity preferences model the time that needs to pass between an item or
characteristic being suggested again or the users tolerance for unseen values or items. Item
preferences are related to single items, whereas attribute, value, and combination preferences
are applicable to the search for those items in general. Diversity preferences relate to both
the items and the search.
Currently, the Adaptive Place Advisor models preferences that the user may have
about attributes, values, and items, but not combination or diversity preferences. The
former are easily captured by either probability distributions or counts, as illustrated in
Table 1. The Place Advisor maintains a probability distribution to represent attribute
preferences and independent probability distributions to represent preferences for each attributes set of values. For attribute preferences, the system uses domain knowledge to
initialize the weights; for example, price is usually considered as more important than park-

402

fiPersonalized Conversational Recommendation

ing. In the absence of such information, as is the case with value preferences, the system
begins with a uniform distribution.
The system represents item preferences as a ratio of the number of times an item was
accepted to the number of times it was presented; this is initialized by assuming that all
items have been presented and then accepted a large percentage (nine out of ten, or 90%) of
the time. While this may cause updates (see below) to have a small effect and undesirable
items to be suggested more than once, it has the effect of not quickly discounting alternatives
early in the learning process. This in turn encourages the user to explore alternatives,
allowing the system to learn more about additional items. In sum, item preferences represent
the probability of the user accepting a particular item after it is presented, rather than
representing a probability distribution over all items.
3.2 The Retrieval Engine
Once in place, the user model affects the behavior of the system through the Retrieval
Engine, which interacts with a database to retrieve the items, if any, that satisfy the currently agreed upon constraints. This module also interacts with the query to determine how
similar those items are to the users preferences and to determine the best ordering of the
attributes for constraining or relaxing, as appropriate. Both types of interactions with the
user model support the goal of quickly narrowing down the search for a satisfactory item.
Similar to the way a human advisor bases assumptions regarding the inquirer on their
previous interactions, our system uses its cumulative experience, reflected in the user model,
as a basis for its computation. The Retrieval Engine represents the users preferences and
requirements in the expanded query, a partial, probabilistic item specification determined
by both the conversation and the user model. The query is initialized from the user model,
and thus contains preference-based probabilities for the attributes and values the user has
not yet explicitly specified along with the users item preferences. In the course of the
conversation, the system updates the query to reflect the values the user specifies. For each
attribute, it sets the probability for each value agreed upon in the conversation to 1.0,
and all other probabilities to zero. For example, if the user says Chinese or Italian, the
system sets the value probabilities for both Chinese and Italian to 1.0, and all other cuisine
probabilities to zero. This is equivalent to a disjunction of probabilistic queries, one for
each value combination specified by the user.5
The first main aspect of the Retrieval Engine that is personalized is its item ranking
technique. Unlike a typical case-based similarity computation, which retrieves items beyond
those that match a query exactly, the computation used by the system restricts the retrieved
items to those most desirable to the user. The system filters the items to be included in the
current case base according to the characteristics explicitly specified by the user and sorts
the remaining items according to their similarity to items the user liked in the past.
Thus, the Engine first queries the database to retrieve all items that match the current
constraints exactly.6 Then, the Place Advisor uses the probability distributions in the
query to compute how likely the user is to choose an item. The system calculates the
5. In the user study described in Section 4, no users specified a disjunctive query.
6. For attributes where the user has selected more than one value, we assume that any supplied value would
be acceptable.

403

fiThompson, Goker, & Langley

similarity between the current query, Q, and an item, I using
Sim(Q, I) = RI 

n
X

wj  P (Vj ) ,

j=1

where RI is the users item preference ratio for item I, n is the number of attributes, wj
is the weight of attribute j in Q, Vj is the value of attribute j in I, and P (Vj ) is the
value preference (probability in Q) for this value. Similarity in this formula is based on
the user model and the search state. Thus, for each unconstrained attribute, it estimates
the probability that the user will accept the items value for that attribute. Once the
system calculates the similarity of each item, it compares an items similarity to a constant
similarity threshold, and only retains those items that exceed the threshold.
The second main personalized aspect of the Retrieval Engine is its ranking of attributes
in under- and over-constrained situations. This helps assure that the user is more likely
to respond informatively to the systems questions in under-constrained situations, and
to allow the suggested attribute to be relaxed in over-constrained situations. For both
situations, one option is to order attributes randomly, which is a technique used in some
simple dialogue systems. Another option is to use a conditional entropy measure to select
attributes (see Section 6.1). A third is to rank attributes in order by their desirability to
the user, as reflected in the user model, and we take this option.
In addition to using the long term user model to rank attributes, the system also uses
the attribute weights that are reflected in the query. We will see see later that the querys
attribute weights, while initialized from the user model, are also influenced by the conversation. In an over-constrained situation, the attribute ranking order is from highest to lowest,
and in an under-constrained situation, it is the reverse.7 Using the attribute weights rather
than the conditional entropy avoids pitfalls that arise from the continuously changing value
distribution in the data (new restaurants, restaurants going out of business, etc.). If this
did affect attribute rankings, the users may be confused by the resulting variability. But
even worse, it would not reflect the users preferences. Further, not every question that has
a high information gain is of high relevance for a user selecting a destination (e.g., parking
options may have a very high score but should only be asked after the user has decided on
cuisine and location.)
In summary, the user model influences item retrieval, item ranking, and attribute ranking, which in turn influence the systems utterances during the conversation.
3.3 Conversing with the User
As it converses with the user, the Dialogue Manager uses the results of the Retrieval Engines
functions. The system uses a frame containing a simple list of constraints to support the
interactive constraint-satisfaction search (see Jurafsky et al. 1994 or Dowding et al. 1993
for a similar formulation). As is usual in this type of system, the user can respond to
a system request to fill a constraint by ignoring that attribute and specifying the value
7. CBR systems do not necessarily use the same weighting factors for each of similarity computation and
question ordering. However, for our application area, it is correct to make the assumption that an
attributes importance is the same as its impact on the similarity computation.

404

fiPersonalized Conversational Recommendation

Table 2: Speech acts supported in the Adaptive Place Advisor.
System Speech Acts
Attempt-Constrain
Suggest-Relax
Recommend-Item
Quit-Start-Mod
Provide-Values
Clarify

Asks a question to obtain a value for an attribute.
Asks a question to remove all values for an attribute.
Recommends an item that satisfies the constraints.
States that no matching items remain and asks whether
to modify the search, start over, or quit.
Lists a small set of values for an attribute.
Asks a clarifying question.

User Speech Acts
Provide-Constrain
Accept
Reject
Provide-Relax
Start-Over
Quit
Query-Values

Provides a value for an attribute.
Accepts a relaxation suggestion or item generated by the system.
Rejects the systems proposed attribute, relaxation attempt, or item.
Provides an attribute value for removal.
Indicates a desire to reinitialize the constraints and begin again.
Indicates a desire to stop the conversation.
Asks for information about possible values of an attribute.

Table 3: Dialogue State.
Variable

Description

Constrained
Rejected
Fixed
Constrain
Relax
Query
Number-of-Items

Attributes whose values have been specified.
Attributes whose value the user has declined to provide.
Constrained attributes that the user has indicated should not be relaxed.
The next attribute to constrain, if any.
The next attribute to relax, if any.
Probability model of desired item constraints.
Number of database items matching the query and exceeding
the similarity threshold.
The matching items ranked in similarity order.
Items that the user has rejected.
The users most recently uttered speech act.
The systems most recently uttered speech act.

Ranked-Items
Rejected-Items
User-Move
System-Act

for different one(s) instead (Goddeau et al., 1996; Ward & Issar, 1996). The speech acts
supported are listed in Table 2.
There are two main phases of the dialogue, the interactive constraint-satisfaction portion
and the item presentation portion. The constraint-satisfaction portion is further divided
into over- and under-constrained situations. The dialogue state (Table 3) determines the
systems utterance and the range of responses expected at each point. The system updates
the dialogue states variables as appropriate throughout the conversation.

405

fiThompson, Goker, & Langley

Table 4: Sample Conversation.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.

Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:
Advisor:
price?
Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:

Where do you think I should eat tonight?
What type of food would you like?
What types are there?
You can say things like Chinese, Indian, and Mediterranean.
Oh, maybe a cheap Indian place.
What kind of parking would you like?
I dont care, as long as its in Palo Alto.
Im sorry, I dont know of any restaurants like that, would you like to search for any
No, I think Id like Chinese instead.
How does Mandarin Gourmet on 420 Ramona sound?
No, what else do you have?
How about Jing-Jing Szechwan Hunan Gourmet on 443 Emerson Street?
Sure, that sounds fine.

In more detail, the systems speech act (or move) during interactive constraint-satisfaction is determined by the Number-of-Items dialogue state variable. Further, its speech
act determines which speech recognition grammar to employ to interpret the users next
utterance. The most common situation is when many items (more than some small threshold, here three) match the current constraints.8 In this situation, the system makes an
Attempt-Constrain move, in which it asks the user to fill in the value for an attribute.
This move, if responded to appropriately by the user, would reduce the number of items
considered to be satisfactory to the user. The attribute to Constrain is the one ranked
highest by the Retrieval Engine that has not already been Constrained or Rejected. In
our first sample conversation, repeated in Table 4, utterances 2 and 6 illustrate AttemptConstrains by the system.
One user response to an Attempt-Constrain is a Provide-Constrain, in which he
provides a value for the specified attribute or for additional attributes, as in utterances 5
and 7. A second possible response is a Reject, in which the user indicates disinterest or
dislike in an attribute, as in the first part of utterance 7. As illustrated by some of these
examples, the user can combine more than one move in a single utterance.
A second situation, an over-constrained query, occurs when there are no items that
satisfy the agreed upon constraints and are similar enough to the users preferences, and
thus the Retrieval Engine returns an empty set (Number-of-Items = 0). In this case, the
system performs a Suggest-Relax move that informs the user of the situation and asks if
he would like to relax a given constraint. The attribute to Relax is chosen from the Retrieval
Engines highest ranked attribute9 that has not already been Fixed. This is illustrated in
utterance 8 of the conversation in Table 4. As in utterance 9 of that conversation, the user
can respond by rejecting (Reject) the systems suggestion or he can accept it (Accept).
In the former case, the attribute is Fixed so that the system will not try to relax it again.
8. When we discuss the number of items matching the constraints, we refer to those items that remain after
similarity filtering as discussed in Section 3.2.
9. Recall from Section 3.2 that this is actually the lowest ranking attribute in the user model.

406

fiPersonalized Conversational Recommendation

In combination with either of these speech acts, the user can specify other attributes to
relax in addition to, or instead of, the system-suggested attribute (Provide-Relax).
When only a few items satisfy the constraints, the system ends the interactive search
and begins to suggest items to the user (Recommend-Item) in order of similarity, as in
utterances 10 and 12 above. The user can either accept or reject an item. If the user
accepts an item (Accept), the system ends the conversation, having reached the goal
state. If the user rejects an item (Reject), the system presents an alternative, if any
remain. Note that there are three meanings for the Reject speech acts of the user, but
only two meanings for the Accept speech acts, since a user has to accept an AttemptConstrain by providing an explicit value for the attribute being constrained.
There are three special situations not covered by the above. The first is when the query
is over-constrained, but the user has Fixed all attributes that could be relaxed. The second
is when the user has rejected all items that match the constraints. In these two situations,
the system informs the user of the situation, asks him whether he would like to quit, start
over, or modify the search (Quit-Start-Mod), and reacts accordingly. The third special
situation is when Number-of-Items exceeds the presentation threshold, but all attributes
have been Constrained or Rejected. In that case, the Place Advisor begins to present
items to the user.
To support the spoken natural language input and output, we use a speech recognition package from Nuance Communications, Inc. This package lets us write a different
recognition grammar for each of the situations described above and to use human-recorded
prompts (rather than text-to-speech). The string of words recognized by the system is
parsed using recognition grammars that we wrote, which were used for all users without
adaptation. Future work could include personalized recognition grammars as well as personalized information preferences. The grammars use semantic tags to fill in each slot:
besides slots for each attribute, we define slots for rejection or acceptance of the systems
suggestions. In more complex domains, more sophisticated parsing methods may be required, but this simple scheme gives the user a reasonably diverse set of utterance options.
The Nuance modules also generate a response to user requests for help (Query-Values)
with a Provide-Values speech act, and enter clarification dialogues when the confidence
in a recognized utterance is below a given threshold (Clarify). These are currently simple
interactions where the system provides examples of answers to the most recently uttered
prompt, or asks the user to repeat themselves.
Finally, for the item presentation portion of the dialogue only, the system displays the
restaurant information (name, address, and phone number) on the screen, and outputs a
spoken prompt such as How about this one? We chose this presentation modality due to
our reluctance to use text-to-speech generation and the large number of prompts we would
have had to record to produce spoken language for each restaurant. However, note that
the user still responds with a spoken reply, and we do not feel that this presentation mode
substantially influenced the user-modeling behavior of the Place Advisor.
Each system-user interaction affects subsequent rounds of database retrieval and similarity calculation via updates to the expanded query. Table 5 shows the effects of relevant
speech acts on the query, which is in turn used in the similarity calculation as described in
Section 3.2. In the table, we have shortened the names of some of the system moves for the
sake of brevity.
407

fiThompson, Goker, & Langley

Table 5: The effects of speech acts on the query. Key: Constrain = AttemptConstrain, Relax = Suggest-Relax, Recommend = Recommend-Item.
System-Move

User-Move

Effect on Query

Constrain

ProvideConstrain

Constrain
Relax
Recommend
Relax
Recommend
Any
Any

Reject
Reject
Reject
Accept
Accept
Provide-Relax
Start-Over

Set probabilities of all provided values to one.
Set probability of other values for constrained attributes to
zero. If the attribute has been rejected previously, reset
its attribute probability from user model.
Drop attribute by setting its probability to zero.
No effect; Dialogue Manager selects next attribute.
Update item preference counts (see Section 3.4).
Reset value probabilities for the attribute from user model.
Update item preference counts (see Section 3.4).
Reset value probabilities for the attribute from user model.
Initialize from user model.

3.4 Updating the User Model
Our main contribution is the addition of personalization to the above conversational recommendation model. The user model (Section 3.1) represents this personalization, but the
Adaptive Place Advisor must update it appropriately. While some adaptive recommendation systems (Smyth & Cotter, 1999; Linden, Hanks, & Lesh, 1997; Pazzani et al.,
1996; Lang, 1995) require the user to provide direct feedback to generate the user model,
our basic approach is to unobtrusively derive the user preferences. Thus, the system does
not introduce unnecessary interactions, but learns from the interactions needed to support
item recommendation. We describe here how the system gathers item, attribute, and value
preferences. As described more fully below, the system modifies feature and value weights
(Fiechter & Rogers, 2000; Zhang & Yang, 1998; Bonzano, Cunningham, & Smyth, 1997;
Wettschereck & Aha, 1995) for the latter two, and increases the counts in the ratio of
accepted to presented items.
When determining the points in the dialogue at which to update the user model, we
considered several factors. We wanted to enable the system to acquire information quickly,
but to discourage it from making erroneous assumptions. We thought that users might
explore the search space the most while constraining attributes, so we decided not to have
the system update value preferences after each user-specified constraint. However, if we
instead chose to only allow model updates after an item suggestion, the learning process
might be too slow. The choices described below are, we feel, a good tradeoff between the
extremes.
The three circumstances that we chose for user model update were (1) after the users
Accept speech acts in a Suggest-Relax situation, (2) after the users Accept speech
acts in a Recommend-Item situation, and (3) after the users Reject speech act after a
Recommend-Item speech act by the system. First, we assume that when a user accepts an
item, he is indicating: (1) a preference for the item itself, (2) preferences for the attributes

408

fiPersonalized Conversational Recommendation

he constrained to find this item, and (3) preferences for the values he provided for those
attributes. Thus, when a user accepts an item presented by the system, the probabilities
for the appropriate item, attributes, and values are increased. For the item preference,
the system simply adds one to the presentation and acceptance counts. For attribute and
value preferences, the system increases the probability of the appropriate weight by a small
amount proportional to its current weight, then renormalizes all weights. Thus attribute
and value preferences are biased measures that avoid zero counts for values that the user
never chooses, as is typical for this type of probabilistic representation.
Second, when a user rejects an item presented by the system, we only assume that he
has a dislike for the particular item. We do not assume anything about the characteristics of
that item, since the user has specified some of those characteristics. Therefore, for rejected
items the system simply adds one to the presentation count.
The third situation in which the system updates the user model is when, after the query
has become over-constrained, it presents an attribute for relaxation and the user accepts
that relaxation. In this situation, we assume that, had there been a matching item, the
user would have been satisfied with it, since the characteristics specified in the conversation
so far were satisfactory. Therefore, before the relaxation occurs, the system increases the
attribute preferences for the constrained attributes and increases the value preferences for
user-specified values, in a manner similar to an Accept situation after a RecommendItem. This enables the Adaptive Place Advisor to more quickly make inferences about
the users preferences.

4. System Evaluation
As stated earlier, we believe that user modeling increases the effectiveness and efficiency
of conversations with the system over time. To test this hypothesis, we carried out an
experiment with a version of the Adaptive Place Advisor that recommends restaurants
in the San Francisco Bay Area. The system describes items using seven attributes: cuisine,
rating, price, location, reservations, parking options, and payment options. Most attributes
have few values, but cuisine and location have dozens. There are approximately 1900 items
in the database.
We asked several users, all from the Bay Area, to interact with the system to help them
decide where to go out to eat. The users were given no external guidance or instructions
on which types of restaurants to select, other than to look for and choose those that they
might actually patronize. An experimenter was present during all these interactions, which
were filmed, but his help was not needed except on rare occasions when a subject repeatedly
tried words that were not included in the speech recognition grammar.
4.1 Experimental Variables
To test our hypothesis about the benefits of personalization in the Adaptive Place Advisor, we controlled two independent variables: the presence of user modeling and the
number of times a user interacted with the system. First, because we anticipated that
users might improve their interactions with the Place Advisor over time, we divided
subjects into an experimental or modeling group and a control group. The 13 subjects in
the modeling group interacted with a version of the system that updated its user model as
409

fiThompson, Goker, & Langley

described in Section 3.4. The 11 subjects in the control group interacted with a version
that did not update the model, but that selected attributes and items from the default
distribution described in Section 3.1. Naturally, the users were unaware of their assigned
group. Second, since we predicted the systems interactions would improve over time, as
it gained experience with each user, we observed its behavior at successive points along
this learning curve. In particular, each subject interacted with the system for around 15
successive sessions. We tried to separate each subjects sessions by several hours, but this
was not always possible. However, in general the subjects did use the system to actually
help them decide where to eat either that same day or in the near future; we did not provide
constraints other than telling them that the system only knew about restaurants in the Bay
Area.
To determine each versions efficiency at recommending items, we measured several
conversational variables. One was the average number of interactions needed to find a
restaurant accepted by the user. We defined an interaction as a cycle that started with the
system providing a prompt and ended with the systems recognition of the users utterance
in response, even if that response did not answer the question posed by the prompt. We
also measured the time taken for each conversation. This began when a start transaction
button was pushed and ended when the system printed Done (after the user accepted an
item or quit).
We also collected two statistics that should not have depended on whether user modeling
was in effect. First was the number of system rejections, that is, the number of times that
the system either did not obtain a recognition result or that its confidence was too low.
In either case the system asked the user to repeat himself. Since this is a measure of
recognition quality and not the effects of personalization, we omitted it from the count of
interactions. A second, more serious problem was a speech misrecognition error in which
the system assigned an utterance a different meaning than the user intended.
Effectiveness, and thus the subjective quality of the results, was somewhat more difficult
to quantify. We wanted to know each users degree of satisfaction with the systems behavior.
One such indication was the rejection rate: the proportion of attributes about which the
system asked but the subject did not care (Rejects in Attempt-Constrain situations).
A second measure was the hit rate: the percentage of conversations in which the first item
presented was acceptable to the user. Finally, we also administered a questionnaire to users
after the study to get more subjective evaluations.
4.2 Experimental Results
The results of this experiment generally supported our hypothesis with respect to efficiency.
We provide figures that show average values over all users in a particular group, with error
bars showing the 95% confidence intervals. The x axis always shows the progression of users
interactions with the system over time: each point is for the nth conversation completed by
either finding an acceptable restaurant or quitting.
Figure 2 shows that, for the modeling group, the average number of interactions required
to find an acceptable restaurant decreased from 8.7 to 5.5, whereas for the control group
this quantity actually increased from 7.6 to 10.3. We used linear regression to characterize
the trend for each group and compared the resulting lines. The slope for the modeling line

410

fi4

6

8

Number of interactions
10
12
14
16

Personalized Conversational Recommendation

2

Modeling

0

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 2: Average number of interactions per conversation.
differed significantly (p = 0.017) from that for the control line, with the former smaller than
the latter, as expected.
The difference in interaction times (Figure 3) was even more dramatic. For the modeling
group, this quantity started at 181 seconds and ended at 96 seconds, whereas for the control
group, it started at 132 seconds and ended at 152 seconds. We again used linear regression
to characterize the trends for each group over time and again found a significant difference
(p = 0.011) between the two curves, with the slope for the modeling subjects being smaller
than that for the control subjects. We should also note that these measures include some
time for system initialization (which could be up to 10% of the total dialogue time). If we
had instead used as the start time the first system utterance of each dialogue, the difference
between the two conditions would be even clearer.
The speech recognizer rejected 28 percent of the interactions in our study. Rejections
slow down the conversation but do not introduce errors. The misrecognition rate was much
lower  it occurred in only seven percent of the interactions in our experiment. We feel
both of these rates are acceptable, but expanding the number of supported utterances
could reduce the first number further, while potentially increasing the second. In the most
common recognition error, the Adaptive Place Advisor inserted extra constraints that
the user did not intend.
The results for effectiveness were more ambiguous. Figure 4 plots the rejection rate as a
function of the number of sessions. A decrease in rejection rate over time would mean that,
as the system gains experience with the user, it asks about fewer features irrelevant to that
user. However, for this dependent variable we found no significant difference (p = 0.515)
between the regression slopes for the two conditions and, indeed, the rejection rate for
neither group appears to decrease with experience. These negative results may be due to the
rarity of rejection speech acts in the experiment. Six people never rejected a constraint and

411

fi50

100

Time per conversation
150
200
250

Thompson, Goker, & Langley

Modeling

0

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 3: Average time per conversation.
on average each person used only 0.53 Reject speech acts after an Attempt-Constrain
per conversation (standard deviation = 0.61).
Figure 5 shows the results for hit rate, which indicate that suggestion accuracy stayed
stable over time for the modeling group but decreased for the control group. One explanation for the latter, which we did not expect, is that control users became less satisfied
with the Place Advisors suggestions over time and thus carried out more exploration at
item presentation time. However, we are more concerned here with the difference between
the two groups. Unfortunately, the slopes for the two regression lines were not significantly
different (p = 0.1354) in this case.
We also analyzed the questionnaire presented to subjects after the experiment. The first
six questions (see Appendix A) had check boxes to which we assigned numerical values, none
of which revealed a significant difference between the two groups. The second part of the
questionnaire contained more open-ended questions about the users experience with the
Adaptive Place Advisor. In general, most subjects in both groups liked the system and
said they would use it fairly often if given the opportunity.
4.3 Discussion
In summary, our experiment showed that the Adaptive Place Advisor improved the
efficiency of conversations with subjects as it gained experience with them over time, and
that this improvement was due to the systems update of user models rather than to subjects
learning how to interact with the system. This conclusion is due to the significan differences
between the user modeling and control groups, for both number of interactions and time
per conversation. This significance holds even in the face of large error bars and a small
sample size. This in turn implies that the differences are large and the system could make
a substantial difference to users.
412

fiNumber of rejections
1.5
2
2.5

Personalized Conversational Recommendation

Modeling

0

0.5

1

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 4: Rejection rate for modeling and control groups.
The results for effectiveness were more ambiguous, with trends in the right direction
but no significant differences between the modeling and control groups. Subjects in both
conditions generally liked the system, but again we found no significant differences along
this dimension. A larger study may be needed to determine whether such differences occur.
Further user studies are warranted to investigate the source of the differences between
the two groups. One plausible explanation is that items were presented sooner, on average,
in the user modeling group than in the control group. We measured this value (i.e., the
average number of interactions before the first item presentation) in the current study and
found that it did decrease for the user modeling group (from 4.7 to 3.9) and increased for
the control group (from 4.5 to 5.8). This is a reasonably large difference but the difference
in slope for the two regression lines is not statistically significant (p=0.165). A larger study
may be needed to obtain a significant difference. In general, however, there is an interaction
between the user model and the order of questions asked, which in turn influences the
number of items matching at each point in the conversation. This in turn determines how
soon items are presented in a conversation. Therefore, if items are presented more often in
the user modeling group, then the largest influence on the user model is due to item accepts
and rejects.

5. Related Research
Previous research on related topics can be roughly broken up into three areas, the first
focusing on personalized recommendation systems, the second on conversational interfaces,
and the third on adaptive dialogue systems. We restrict our discussion here to the most
strongly related work.

413

fiHit rate
1.5

Thompson, Goker, & Langley

Modeling

0.0

0.5

1

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 5: Hit rate for modeling and control groups.
5.1 Personalized Recommendation Systems
Although research in personalized recommendation systems has become widespread only in
recent years, the basic idea can be traced back to Rich (1979), discussed below with other
work on conversational interfaces. Langley (1999) gives a more thorough review of recent
research on the topic of adaptive interfaces and personalization.
Several other adaptive interfaces attempt to collect user information unobtrusively. An
interesting example is the Casper project (Rafter et al., 2000), an online recruitment
service. The project investigates methods that translate click and read-time data into
accurate relevancy information, given that the raw data is inherently noisy. Similarly,
Goecks and Shavlik (2000) describe a technique for learning web preferences by observing
a users browsing behavior. Another example is the Adaptive Route Advisor (Rogers
et al., 1999), which recommends driving routes to a specified destination. The system
collects preferences about attributes such as number of turns and driving time on the basis
of the users selections and modifications of the systems proposed routes.
While the Adaptive Place Advisor uses constraint-based interaction to search for
items, this is not the only interaction approach for item search. An alternative is taken
by the candidate/critique, or tweaking, approach. Tweaking systems, such as the Find Me
suite (Burke, 1999), typically require the user to begin an interaction by filling in values for
a few predetermined attributes. They then present an item, at which point the user has the
opportunity to change some search parameters to try to find a more desirable item. Eaton,
Freuder, and Wallace (1997) take a similar approach in their Matchmaking system. In
addition, they exploit constraint satisfaction to manage the search. Neither the Find Me
suite nor the Matchmaking system, however, learns user models. A related system that
does include a learning component is that of Shearin and Lieberman (2001), which learns
attribute preferences unobtrusively. While tweaking is a valid method, it is not appropriate,
414

fiPersonalized Conversational Recommendation

we feel, in an environment in which speech is the only interaction mode, since presenting
the user with his options would be somewhat cumbersome. Even though our current system
also presents options once the search is constrained, it limits the number of items presented.
Even in a full speech version this does not seem onerous.
5.2 Conversational Interfaces
There is considerable ongoing work in the area of conversational systems, as evidenced
in the general surveys by Dybkjr et al. (2000) and Maier et al. (1996). Zukerman and
Litman (2001) give a more thorough overview of user modeling in dialogue systems. Rich
(1979) reported one of the earliest (typewritten) conversational interfaces, which focused
on book recommendation. At the beginning of an interaction, the system asked several
questions to place the user in a stereotype group, thereby initializing the user model. As
each conversation progressed, this model was adjusted, with the system using ratings to
represent uncertainty. However, the language understanding capabilities of the system were
limited, mostly allowing only yes/no user answers. More recently, dialogue systems utilize
models of users beliefs and intentions to aid in dialogue management and understanding,
though typically these systems maintain models only over the course of a single conversation
(Kobsa & Wahlster, 1989).
As noted in Section 2.3, an important distinction is whether only one conversational
participant keeps the initiative, or whether the initiative can switch between participants.
Two ambitious mixed-initiative systems for planning tasks are Trains (Allen et al., 1995)
and more recent Trips (Allen et al., 2001). Like the Place Advisor, these programs interact with the user to progressively construct a solution, though the knowledge structures
are partial plans rather than constraints, and the search involves operators for plan modification rather than for database contraction and expansion. Trains and Trips lack any
mechanism for user modeling, but the underlying systems are considerably more mature
and have been evaluated extensively.
Smith and Hipp (1994) describe another related mixed-initiative system with limited
user modeling, in this case a conversational interface for circuit diagnosis. Their system
aims to construct not a plan or a set of constraints, but rather a proof tree. The central
speech act, which requests knowledge from the user that would aid the proof process, is
invoked when the program detects a missing axiom that it needs for its reasoning. This
heuristic plays the same role in their system as does the Place Advisors heuristic for
selecting attributes to constrain during item selection. The interface infers user knowledge
during the course of only a single conversation, not over the long term as in our approach.
With respect to dialogue management, several previous systems have used a method
similar to our frame-based search. In particular, Seneff et al. (1998) and Dowding et al.
(1993) developed conversational interfaces that give advice about air travel. Like the Place
Advisor, their systems ask the user questions to reduce the number of candidates, treating
flight selection as the interactive construction of database queries. However, the question
sequence is typically fixed in advance, despite the clear differences among individuals in this
domain. Also, these systems usually require that all constraints be specified before item
presentation begins.

415

fiThompson, Goker, & Langley

An alternative technique for selecting which questions to ask during information elicitation is presented in Raskutti and Zukerman (1997). Their overall system necessitates
that the system recognize plans the user is attempting to carry out. Then the system must
decide how to best complete those plans. When insufficient information is available for plan
formation, their system enters an information seeking subdialogue similar to the constraintsatisfaction portion of our dialogues. Their system can decide which question to ask based
on domain knowledge or based on the potential informativeness of the question.
Another approach to dialogue management is conversational case-based reasoning
(Aha, Breslow & Munoz-Avila, 2001), which relies on interactions with the user to retrieve
cases (items) that will recommend actions to correct some problem. The speech acts and
basic flow of control have much in common with the Adaptive Place Advisor, in that
the process of answering questions increasingly constrains available answers. One significant
difference is that their approach generates several questions or items, respectively, at a time,
and the user selects which question to answer or which item is closest to his or her needs,
respectively.
Finally, our approach draws on an alternative analysis of item recommendation, described by Elio and Haddadi (1998, 1999). The main distinctions from that work are
that their approach does not include personalization, that they distinguish between search
through a task space and through a discourse space, while we combine the two, and that
they place a greater emphasis on user intentions. Keeping a distinction between the task
and the discourse space in a personalized system would unnecessarily complicate decisions
about when to perform user model updates and about how to utilize the model.
5.3 Adaptive Dialogue Systems
Finally, another body of recent work describes the use of machine learning or other forms
of adaptation to improve dialogue systems.10 Researchers in this area develop systems
that learn user preferences, improve task completion, or adapt dialogue strategies to an
individual during a conversation.
The closest such work also pursues our goal of learning user preferences. Carberry et al.
(1999) report one such example for consultation dialogues, but take a different approach.
Their system acquires value preferences by analyzing both users explicit statements of
preferences and their acceptance or rejection of the systems proposals. It uses discrete
preference values instead of our more fine-grained probability model. Also, their system does
not use preferences during item search but only at item presentation time to help evaluate
whether better alternatives exist. Finally, their evaluation is based on subjects judgements
of the quality of the systems hypotheses and recommendations, not on characteristics of
actual user interactions. We could, however, incorporate some of their item search ideas,
allowing near misses between user-specified constraints and actual items.
Another system that focuses on user preferences is an interactive travel assistant (Linden
et al., 1997) that carries out conversations via a graphical interface. The system asks
questions with the goal of narrowing down the available candidates, using speech acts similar
to ours, and also aims to satisfy the user with as few interactions as possible. Their approach
10. The work on adaptation of speech recognition grammars (e.g., Stolcke et al., 2000), while related, addresses a different problem and uses different learning techniques, so we do not discuss it here.

416

fiPersonalized Conversational Recommendation

to minimizing the number of interactions is to use a candidate/critique approach. From a
users responses, the system infers a model represented as weights on attributes such as price
and travel time. Unlike the Adaptive Place Advisor, it does not carry these profiles
over to future conversations, but one can envision a version that does so.
Several authors use reinforcement learning techniques to improve the probability of or
process of task completion in a conversation. For example, Singh et al. (2002) use this
approach to determine the systems level of initiative and the amount of confirmation of
user utterances. Their goal is to optimize, over all users, the percentage of dialogues for
which a given task is successfully completed. This system leverages the learned information
when interacting with all users, rather than personalizing the information. Also, Levin,
Pieraccini, and Eckert (2000) use reinforcement learning to determine which question to
ask at each point during an information seeking search, but do not demonstrate the utility
of their approach with real users.
Finally, a number of systems adapt their dialogue management strategy over the course
of a conversation based on user responses or other dialogue characteristics. For example,
Litman and Pan (2002) use a set of learned rules to decide whether a user is having difficulty
achieving their task, and modify the level of system initiative and confirmation accordingly.
Maloor and Chai (2000) present a help-desk application that first classifies the user as a
novice, moderate, or expert based on responses to prompts. It then adjusts the complexity
of system utterances, the jargon, and the complexity of the path taken to achieve goals.
Horvitz and Paek (2001) apply user modeling to a dialogue system that uses evidence
from the current context and conversation to update a Bayesian network. The network
influences the spoken language recognition hypothesis and causes appropriate adjustments
in the systems level of initiative. Chu-Carroll (2000) describes a system that adapts both
language generation and initiative strategies for an individual user within a single dialogue.
Also, Jameson et al. (1994) use Bayesian networks in a system that can take the role of
either the buyer or seller in a transaction, and that changes its inquiry or sales strategy
based on beliefs inferred from the other participants utterances.

6. Directions for Future Work
Our results to date with the Adaptive Place Advisor are promising but much remains
to be done. In this section, we discuss ways to make the search model more flexible, to
expand the conversational model, and to enrich the user model and learning technique. We
also consider more extensive evaluations of the system.
6.1 Search Model
With respect to the search mechanism, we first plan to investigate alternative techniques
for using item similarity values to determine which to return, for example by cutting off
items at the point at which similarity drops off most steeply, instead of our current use of
a threshold. We also note that work such as that of Cohen, Schapire, and Singer (1999)
on learning to rank instances could apply nicely to this work, augmenting our current
item ranking scheme. Additionally, we plan develop a version of the system that generates
alternative items or values in an over-constrained situation (Qu & Beale, 1999). One way
to do this would be to use the preferences to estimate the strength of a stated constraint,
417

fiThompson, Goker, & Langley

or to merge our preference-based similarity metric with a more traditional domain-specific
similarity metric (Pieraccini et al., 1997). We also plan to evaluate the effect of making
even stronger assumptions about user preferences. For example, if the system is certain
enough about a value preference, it may not have to ask a question about the associated
attribute.
A final improvement of the search mechanism concerns the techniques for ranking attributes for constraining and relaxing. For attribute constraint ranking, we have implemented but not yet evaluated a conditional entropy measure (Goker & Thompson, 2000).
The system selects the attribute to constrain by determining the attribute with the highest
conditional entropy among the unconstrained attributes. This scheme would not be useful
for ranking attributes to relax. Therefore, the system simply determines the size of the case
base that would result if each attribute were relaxed, ranks these case bases from smallest
to largest, and orders the attributes accordingly, excluding those attributes that, if relaxed,
would still result in an empty case base. We also plan to investigate the combination of
the user model with information gain, as well as with alternative attribute ranking techniques such as the one used by Abella, Brown, and Buntschuh (1996). Another option
is to add personalization to or otherwise adapt the variable selection techniques used by
constraint-satisfaction solvers.
6.2 Conversational Model
We plan to progress towards more complex dialogues with more complex constraints. First,
we plan to increase the number of speech acts available to the user. For example, we will add
confirmation dialogues and improve the current clarification dialogues, thus allowing other
types of adaptation strategies, as in Singh et al. (2002). In a longer term investigation, we
plan to extend our adaptation techniques to handle more complex travel planning dialogues
(Seneff, Lau, & Polifroni, 1999; Walker & Hirschman, 2000). These may require additions
to the user model, such as preferences regarding language and dialogue style, including
initiative, system verbosity, and vocabulary. These will in turn need to be appropriately
acquired and utilized by the system. In general, the insights we have already gained into
utilizing and acquiring user preferences at different junctures of the dialogue and search
process should prove useful in supporting personalization in other tasks.
6.3 User Model
To improve the user model, we first plan to add more types of preferences. As we discussed in
Section 3.1, combination and diversity preferences can capture more complex user behavior
than our current model, and we plan to incorporate both into the next version of our
system. Combination preferences can help it better predict either values or acceptable
attributes, based on previously provided constraints. The Place Advisor can model
value combination preferences by learning association rules (Agrawal, Imielinski, & Swami,
1993) or extending to a Bayesian network, either of which would then influence the query,
in turn influencing the similarity calculation and the case base. For preferences about
acceptable attribute combinations, the system can learn conditional probabilities based on
past interactions and use this to influence attribute ranking.

418

fiPersonalized Conversational Recommendation

While drifting preferences are not likely to cause problems in item selection applications as they might in ones like news updates, our model could be extended to handle
within-user diversity. One way to do this is to capture the users desired time interval between the suggestion of a particular item or value. We can calculate this by determining the
mean time interval between a users explicit selection or rejection of a value (value diversity
preferences) or item (item diversity preferences). We will incorporate both these diversity
preferences into the similarity calculation from Section 3.2 by extending RI and P (Vj ) in
that equation to incorporate time effects. We define RD (I) and PD (Vj ) as:
1

RD (I) = RI 

1+

PD (Vj ) = P (Vj ) 

ekI (ttI tID )
1

,
1+
where t is the current time, tI and tV are the time when the item or value was last selected,
and tID and tV D are the time differences the user wants to have between having the item
or value suggested again. RD and PD are in form of a sigmoid function where kI and kV
determine the curves slope. One empirical question is whether users also have attribute
diversity preferences. We hypothesize that diversity preferences differ for each value of
each attribute, and that this implicitly overrides attribute diversity. For example, a user
may have different preferences about the frequency with which expensive restaurants versus
cheap ones are suggested, but may not care about how often questions about price are asked.
We plan to investigate this hypothesis.
There are other improvements we might add to our user modeling technique. For example, the system may learn more quickly if it updates the user model in dialogue situations
other than the current three. Also, using collaborative user models to initialize individual
models could speed up the learning process. A more explicit combination of collaborative
and individual user models (Melville, Mooney, & Nagarajan, 2002; Jameson & Wittig, 2001)
is also a viable direction to explore.
ekV (ttV tV D )

6.4 Evaluation
Finally, we are planning to carry out a larger user study. We must further verify that the
differences in our study were not due to task difficulty differences since we did not control
for the difficulty of finding a particular item. In particular, different values for the same
constraints may not result in the same number of matching items. So even though two
users have answered the same number of questions, the number of matching items for one
user may be small enough for the system to begin presenting them, while the other user
may need to answer additional questions first. To support an expanded evaluation, we have
implemented a version of the system that recommends movies, which will let us draw from
a broader user base. This should help us measure user satisfaction more easily, as Walker
et al. (1998) have noted that efficiency is not the only important consideration, and that
users might tend to prefer more predictable interfaces.

419

fiThompson, Goker, & Langley

7. Conclusions
In this paper, we described an intelligent adaptive conversational assistant designed to help
people select an item. Overall, we made significant inroads into methods for unobtrusively
acquiring an individual, long term user model during recommendation conversations. We
expanded on previous work on adaptive recommendation systems that were not conversational, and on dialogue systems that were not user adaptive. Our long-term goal is to
develop even more powerful methods, capable of adapting to a users needs, goals, and
preferences over multiple conversations. While we leveraged off the feedback between conversation and recommendation, such feedback is likely to be present in other tasks such as
planning or scheduling.
The two key problems addressed by our research are the design of adaptive recommendation systems when conversations are the interaction mode, and the addition of personalization to dialogue systems, starting here with dialogues for recommendation. Thus, unlike
many recommendation systems that accept keywords and produce a ranked list, this one
carries out a conversation with the user to progressively narrow his options. In solving
these problems, we introduced a novel approach to the acquisition, use, and representation
of user models. Unlike many other adaptive interfaces, our system constructs and utilizes
user models that include information beyond complete item preferences. This is key for the
support of personalization in conversations. We used a relatively simple model of dialogue
to focus on the issues involved in personalization. We also described experimental results
showing the promise of our technique, demonstrating a reduction in both the number of
interactions and in the conversation time for users interacting with our adaptive system
when compared to a control group.
Of course, there are still several open questions and opportunities for improvement. The
user model, conversational model, and search models are functional but we plan to improve
them further. We are also extending our conversational approach to items other than
destinations, such as books and movies, and we plan to link the system to other assistants
like the Adaptive Route Advisor (Rogers et al., 1999). Our goal for such additions is to
provide new functionality that will make the Adaptive Place Advisor more attractive
to users, but also to test the generality of our approach for adaptive recommendation. In
turn, this should bring us closer to truly flexible computational aides that carry out natural
dialogues with humans.

Acknowledgments
This research was carried out while the first author was at the Center for the Study of
Language and Information, Stanford University, and the other authors were at the DaimlerChrysler Research and Technology Center in Palo Alto, California. We thank Renee Elio,
Afsaneh Haddadi, and Jeff Shrager for the initial conception and design of the Adaptive
Place Advisor, Cynthia Kuo and Zhao-Ping Tang for help with the implementation effort,
and Stanley Peters for enlightening discussions about the design of conversational interfaces.
Robert Mertens and Dana Dahlstrom were crucial in carrying out the user studies.

420

fiPersonalized Conversational Recommendation

Appendix A. Questionnaire
1. What did you think about the interaction with the system, did it
0
1
talk
too
much

2

3

4
5
right
amount of
talking

6

7

8
not
enough
talking

2. How easy was it to find a restaurant you liked?
0
1
very
easy

2

4
not
easy

3. Did the system deliver restaurants you liked?
0
yes

1

2

4
no

4. Please rate the interaction with the system on a scale between standard humancomputer-interaction and a person to person conversation via telephone.
0
1
2
humancomputer
interaction

3

4

5

6
phone
conversation

5. Do you think the APA is a useful system?
0
yes

1

2

3

4
no

6. Do you think the conversation was significantly more distracting than a similar conversation with a real person?
0
no

1

2

3

4
yes

421

fiThompson, Goker, & Langley

References
Aamodt, A., & Plaza, E. (1994). Case-based reasoning: Foundational issues, methodological
variations, and system approaches. Artificial Intelligence Communications, 7, 3959.
Abella, A., Brown, M. K., & Buntschuh, B. (1996). Development principles for dialog-based
interfaces. In Proceedings of the ECAI-96 Spoken Dialog Processing Workshop, pp.
17. Budapest, Hungary.
Agrawal, R., Imielinski, T., & Swami, A. (1993). Mining association rules between sets of
items in large databases. In Buneman, P., & Jajodia, S. (Eds.), Proceedings of the
1993 ACM SIGMOD International Conference on Management of Data, pp. 207216.
Washington, D.C. ACM Press.
Aha, D., & Breslow, L. (1997). Refining conversational case libraries. In Proceedings of the
Second International Conference on Case-Based Reasoning, pp. 267278. Providence,
RI. Springer Verlag.
Aha, D., Breslow, L., & Munoz Avila, H. M. (2001). Conversational case-based reasoning.
Applied Intelligence, 14, 932.
Allen, J. (1999). Mixed-initiative interaction. IEEE Intelligent Systems, September/October,
1416.
Allen, J., Byron, D., Dzikovska, M., Ferguson, G., Galescu, L., & Stent, A. (2001). Towards
conversational human-computer interaction. AI Magazine, 22, 2737.
Allen, J., Schubert, L., Ferguson, G., Heeman, P., Hwang, C. H., Kato, T., Light, M.,
Martin, N., Miller, B., Poesio, M., & Traum, D. (1995). The TRAINS project: A
case study in building a conversational planning agent. Journal of Experimental and
Theoretical AI, 7, 748.
Allen, J. F. (1995). Natural language understanding (second edition). Benjamin/Cummings,
Menlo Park, CA.
Ardissono, L., & Goy, A. (2000). Tailoring the interaction with users in web stores. User
Modeling and User-Adapted Interaction, 10, 251303.
Ardissono, L., Goy, A., Console, L., & Torre, I. (2001). An adaptive system for the personalized access to news. AI Communications, 14, 129147.
Billsus, D., & Pazzani, M. (1998). Learning collaborative information filters. In Proceedings
of the Fifteenth International Conference on Machine Learning, pp. 4654. Madison,
WI. Morgan Kaufmann.
Bobrow, D., Kaplan, R., Kay, M., Norman, D., Thompson, H., & Winograd, T. (1977).
Gus, a frame driven dialog system. Artificial Intelligence, 8, 155173.

422

fiPersonalized Conversational Recommendation

Bonzano, A., Cunningham, P., & Smyth, B. (1997). Using introspective learning to improve
retrieval in CBR: A case study in air traffic control. In Proceedings of the Second International Conference on Case-Based Reasoning, pp. 413424. Providence, RI. Springer
Verlag.
Brusilovsky, P., & Maybury, M. (2002). Introduction to special section on the adaptive web.
Communications of the ACM, 45, 3033.
Burke, R. (1999). The Wasabi personal shopper: A case-based recommender system. In
Proceedings of the Sixteenth National Conference on Artificial Intelligence, pp. 844
849. Orlando, FL. AAAI Press.
Burke, R., Hammond, K., & Young, B. (1996). Knowledge-based navigation of complex
information spaces. In Proceedings of the Thirteenth National Conference on Artificial
Intelligence, pp. 462468. Portland, OR. AAAI Press.
Carberry, S. (1990). Plan recognition in natural language dialogue. MIT Press, Cambridge,
MA.
Carberry, S., Chu-Carroll, J., & Elzer, S. (1999). Constructing and utilizing a model of
user preferences in collaborative consultation dialogues. Computational Intelligence
Journal, 15, 185217.
Chin, D. (1989). KNOME: Modeling what the user knows in UC. In Kobsa, A., & Wahlster,
W. (Eds.), User models in dialog systems, pp. 74107. Springer Verlag, Berlin.
Chu-Carroll, J. (2000). MIMIC: An adaptive mixed initiative spoken dialogue system for
information queries. In Proceedings of the Sixth Conference on Applied Natural Language Processing, pp. 97104. Seattle, WA. AAAI Press.
Cohen, P. R., & Perrault, C. (1979). Elements of a plan-based theory of speech acts.
Cognitive Science, 3, 177212.
Cohen, W., Schapire, R., & Singer, Y. (1999). Learning to order things. Journal of Artificial
Intelligence Research, 10, 243270.
Cotter, P., & Smyth, B. (2000). PTV: Intelligent personalized TV guides. In Proceedings of
the Twelfth Innovative Applications of Artificial Intelligence Conference, pp. 957964.
Austin, TX. AAAI Press.
Cucchiara, R., Lamma, E., Mello, P., & Milano, M. (1997). Interactive constraint satisfaction. Tech. rep. DEIS-LIA-97-00, University of Bologna.
Dowding, J., Gawron, J., Appelt, D., Bear, J., Cherny, L., Moore, R., & Moran, D. (1993).
Gemini: A natural language system for spoken-language understanding. In Proceedings of the Thirty-first Annual Meeting of the Association for Computational Linguistics, pp. 5461. Columbus, OH. Association for Computational Linguistics.
Dybkjr, L., Hasida, K., & Traum, D. (Eds.). (2000). Proceedings of the 1st SIGdial
Workshop on Discourse and Dialogue, Hong Kong. Association for Computational
Linguistics.
423

fiThompson, Goker, & Langley

Eaton, P., Freuder, E., & Wallace, R. (1997). Constraint-based agents: Assistance, cooperation, compromise. In Proceedings of the CP97 Workshop on Constraint Reasoning
on the Internet. Schloss Hagenberg, Austria.
Eliassi-Rad, T., & Shavlik, J. (2001). A system for building intelligent agents that learn to
retrieve and extract information. User Modeling and User-Adapted Interaction, 13,
3588.
Elio, R., & Haddadi, A. (1998). Dialog management for an adaptive database assistant.
Tech. rep. 98-3, Daimler-Benz research and Technology Center, Palo Alto, CA.
Elio, R., & Haddadi, A. (1999). On abstract task models and conversation policies. In
Proceedings of the Agents99 Workshop on Specifying and Implementing Conversation
Policies. Seattle, WA.
Ferrario, M., Waters, K., & Smyth, B. (2000). Collaborative maintenance in ULYSSES.
In Proceedings of the International Conference on Adaptive Hypermedia and Adaptive
Web-based Systems, pp. 301304. Trento, Italy.
Fiechter, C., & Rogers, S. (2000). Learning subjective functions with large margins. In
Proceedings of the Seventeenth International Conference on Machine Learning, pp.
287294. Stanford University, CA. Morgan Kaufmann.
Goddeau, D., Meng, H., Polifroni, J., Seneff, S., & Busayapongchai, S. (1996). A form-based
dialogue manager for spoken language applications. In Proceedings of the Fourth International Conference on Spoken Language Processing, Vol. 2, pp. 701704. Philadelphia, PA.
Goecks, J., & Shavlik, J. (2000). Learning users interests by unobtrusively observing their
normal behavior. In Proceedings of the 2000 International Conference on Intelligent
User Interfaces, pp. 129132. New Orleans, LA. ACM Press.
Goker, M., & Roth-Berghofer, T. (1999). The development and utilization of the case-based
help-desk support system HOMER. Engineering Applications of Artificial Intelligence,
12, 665680.
Goker, M., & Thompson, C. (2000). Personalized, conversational case-based recommendation. In Proceedings of the Fifth European Workshop on Case-Based Reasoning, pp.
99111. Trento Italy. Springer Verlag.
Haller, S., & McRoy, S. (1998). Preface to the special issue computational models of mixedinitiative interaction. User Modeling and User-Adapted Interaction, 8, 167170.
Horvitz, E., & Paek, T. (2001). Harnessing models of users goals to mediate clarification dialog in spoken language systems. In Proceedings of the Eighth International
Conference on User Modeling, pp. 201210. Sonthofen, Germany. Springer.
Jameson, A., Kipper, B., Ndiaye, A., Schafer, R., Simons, J., Weis, T., & Zimmermann,
D. (1994). Cooperating to be noncooperative: The dialog system PRACMA. In
424

fiPersonalized Conversational Recommendation

Proceedings of KI-94: Advances in Artificial Intelligence, pp. 106117. Seattle, WA.
Morgan Kaufmann.
Jameson, A., & Wittig, F. (2001). Leveraging data about users in general in the learning of individual user models. In Proceedings of the Seventeenth International Joint
Conference on Artificial Intelligence, pp. 11851192. Seattle, WA. Morgan Kaufmann.
Jurafsky, D., & Martin, J. (2000). Speech and language processing. Prentice Hall.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., Fosler, E., & Morgan, N.
(1994). The Berkeley restaurant project. In Proceedings of the International Conference on Spoken Language Processing, pp. 21392142. Yokohama, Japan.
Kass, R. (1991). Building a user model implicitly from a cooperative advisory dialog. User
Modeling and User-Adapted Interaction, 3, 203258.
Kay, J., & Thomas, R. C. (2000). Personal usability based upon a scrutable, dynamic,
individual user model. In Proceedings of the Australasian Computer Human Interfaces
Conference, pp. 292298.
Kobsa, A., & Wahlster, W. (Eds.). (1989). User models in dialog systems. Springer, New
York.
Konstan, J., Miller, B., Maltz, D., Herlocker, J., Gordon, L., & Riedl, J. (1997). Grouplens:
Applying collaborative filtering to usenet news. Communications of the ACM, 40,
7787.
Kumar, V. (1992). Algorithms for constraint-satisfaction problems: A survey. The AI
Magazine, 13, 3244.
Lang, K. (1995). NewsWeeder: Learning to filter netnews. In Proceedings of the Twelfth
International Conference on Machine Learning, pp. 331339. San Francisco, CA. Morgan Kaufmann.
Langley, P. (1999). User modeling in adaptive interfaces. In Proceedings of the Seventh
International Conference on User Modeling, pp. 357370. Banff, Alberta. Springer.
Levin, E., Pieraccini, R., & Eckert, W. (2000). A stochastic model of human-machine
interaction for learning dialog strategies. IEEE Transactions on Speech and Audio
Processing, 8, 1123.
Linden, G., Hanks, S., & Lesh, N. (1997). Interactive assessment of user preference models:
The automated travel assistant. In Proceedings of the Sixth International Conference
on User Modeling, pp. 6778. Chia Laguna, Sardinia. Springer.
Litman, D., & Pan, S. (2002). Designing and evaluating an adaptive spoken dialogue system.
User Modeling and User-Adapted Interaction, 12, 111137.
Maier, E., Mast, M., & Luperfoy, S. (Eds.). (1996). Proceedings of the ECAI96 workshop on
Dialogue processing in spoken language systems, Budapest, Hungary. Springer Verlag.
425

fiThompson, Goker, & Langley

Maloor, P., & Chai, J. (2000). Dynamic user level and utility measurement for adaptive
dialog in a help-desk system. In Proceedings of the 1st SIGdial Workshop on Discourse
and Dialogue, pp. 94101 Hong Kong. Association for Computational Linguistics.
McNee, S., Lam, S., Konstan, J., & Riedl, J. (2003). Interfaces for eliciting new user preferences in recommender systems. In Proceedings of the Ninth International Conference
on User Modeling, pp. 178188. Johnstown, PA. Springer.
Melville, P., Mooney, R., & Nagarajan, R. (2002). Content-boosted collaborative filtering
for improved recommendations. In Proceedings of the Eighteenth National Conference
on Artificial Intelligence, pp. 187192. Edmonton, Canada. AAAI Press.
Pazzani, M., Muramatsu, J., & Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. In Proceedings of the Thirteenth National Conference on Artificial
Intelligence, pp. 5461. Portland, OR. AAAI Press.
Pieraccini, R., Levin, E., & Eckert, W. (1997). AMICA: The AT&T mixed initiative
conversational architecture. In Proceedings of the European Conference on Speech
Communication and Technology, pp. 18751878. Rhodes, Greece.
Qu, Y., & Beale, S. (1999). A constraint-based model for cooperative response generation
in information dialogues. In Proceedings of the Sixteenth National Conference on
Artificial Intelligence, pp. 148155. Orlando, FL. AAAI Press.
Rafter, R., Bradley, K., & Smyth, B. (2000). Personalized retrieval for online recruitment
services. In Proceedings of the Twenty-second Annual Colloquium on Information
Retrieval. Cambridge, UK.
Raskutti, B., & Zukerman, I. (1997). Generating queries and replies during informationseeking interactions. International Journal of Human Computer Studies, 47, 689734.
Resnick, P., & Varian, H. (1997). Recommender systems. Communications of the ACM,
40 (3), 5658.
Rich, E. (1979). User modeling via stereotypes. Cognitive Science, 3, 329354.
Rogers, S., Fiechter, C., & Langley, P. (1999). An adaptive interactive agent for route
advice. In Proceedings of the Third International Conference on Autonomous Agents,
pp. 198205. Seattle, WA. ACM Press.
Sadek, M., Bretier, P., & Panaget, F. (1997). ARTIMIS: Natural dialogue meets rational
agency. In Proceedings of the Fifteenth International Joint Conference on Artificial
Intelligence, pp. 10301035. Nagoya, Japan. Morgan Kaufmann.
Segal, R., & Kephart, J. (1999). Mailcat: An intelligent assistant for organizing e-mail. In
Proceedings of the Third International Conference on Autonomous Agents, pp. 276
282. Seattle, WA. ACM Press.

426

fiPersonalized Conversational Recommendation

Seneff, S., Hurley, E., Lau, R., Pao, C., Schmid, P., & Zue, V. (1996). Galaxy-II: A
reference architecture for conversational system development. In Proceedings of the
International Conference on Spoken Language Processing, pp. 931934. Sydney, Australia.
Seneff, S., Lau, R., & Polifroni, J. (1999). Organization, communication, and control in the
Galaxy-II conversational system. In Proceedings of Eurospeech 1999, pp. 12711274.
Budapest, Hungary.
Shardanand, U., & Maes, P. (1995). Social information filtering: Algorithms for automating
word of mouth. In Proceedings of the Conference on Human Factors in Computing
Systems, pp. 210217. Denver, CO. ACM Press.
Shearin, S., & Lieberman, H. (2001). Intelligent profiling by example. In Proceedings of the
International Conference on Intelligent User Interfaces, pp. 145152. Santa Fe, NM.
ACM Press.
Singh, S., Litman, D., Kearns, M., & Walker, M. (2002). Optimizing dialogue management with reinforcement learning: Experiments with the NJFun system. Journal of
Artificial Intelligence Research, 16, 105133.
Smith, R., & Hipp, D. (1994). Spoken natural language dialog systems: A practical approach.
Oxford University Press, New York, NY.
Smyth, B., & Cotter, P. (1999). Surfing the digital wave, generating personalized TV listings
using collaborative, case-based recommendation. In Proceedings of the Third International Conference on Case-Based Reasoning, pp. 561571. Monastery, Germany.
Springer Verlag.
Stent, A., Dowding, J., Gawron, J., Bratt, E., & Moore, R. (1999). The CommandTalk
spoken dialogue system. In Proceedings of the Thirty-seventh Annual Meeting of the
Association for Computational Linguistics, pp. 183190. College Park, MD. Association for Computational Linguistics.
Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., Taylor, P., Martin,
R., Ess-Dykema, C. V., & Meteer, M. (2000). Dialog act modeling for automatic
tagging and recognition of conversational speech. Computational Linguistics, 26, 339
373.
Walker, M., Fromer, J., Fabbrizio, G., Mestel, C., & Hindle, D. (1998). What can I say?:
Evaluating a spoken language interface to email. In Proceedings of ACM CHI 98
Conference on Human Factors in Computing Systems, pp. 582589. Los Angeles, CA.
ACM Press.
Walker, M., & Hirschman, L. (2000). Evaluation for DARPA communicator spoken dialogue
systems. In Proceedings of the Second International Conference on Language Resources
and Evaluation. Athens, Greece.

427

fiThompson, Goker, & Langley

Ward, W., & Issar, S. (1996). Recent improvements in the CMU spoken language understanding system. In Proceedings of the ARPA Human Language Technology Workshop,
pp. 213216.
Wettschereck, D., & Aha, D. (1995). Weighting features. In Proceedings of the First International Conference on Case-Based Reasoning, pp. 347358. Sesimbra, Portugal.
Springer Verlag.
Winograd, T., & Flores, F. (1986). Understanding computers and cognition: A new foundation for design. Ablex Publishing, Northwood, NJ.
Zhang, Z., & Yang, Q. (1998). Towards lifetime maintenance of case base indexes for
continual case based reasoning. In Proceedings of the 1998 International Conference
on AI Methodologies, Systems and Applications, pp. 489500. Bulgaria. Springer.
Zukerman, I., & Litman, D. (2001). Natural language processing and user modeling: Synergies and limitations. User Modeling and User-Adapted Interaction, 11, 129158.

428

fiJournal of Artificial Intelligence Research 21 (2004) 245286

Submitted 07/2003; published 03/2004

Coherent Integration of Databases
by Abductive Logic Programming
Ofer Arieli

oarieli@mta.ac.il

Department of Computer Science, The Academic College of Tel-Aviv,
4 Antokolski street, Tel-Aviv 61161, Israel.

Marc Denecker
Bert Van Nuffelen
Maurice Bruynooghe

Marc.Denecker@cs.kuleuven.ac.be
Bert.VanNuffelen@cs.kuleuven.ac.be
Maurice.Bruynooghe@cs.kuleuven.ac.be
Department of Computer Science, Katholieke Universiteit Leuven,
Celestijnenlaan 200A, B-3001 Heverlee, Belgium.

Abstract
We introduce an abductive method for a coherent integration of independent datasources. The idea is to compute a list of data-facts that should be inserted to the amalgamated database or retracted from it in order to restore its consistency. This method
is implemented by an abductive solver, called Asystem, that applies SLDNFA-resolution
on a meta-theory that relates different, possibly contradicting, input databases. We also
give a pure model-theoretic analysis of the possible ways to recover consistent data from
an inconsistent database in terms of those models of the database that exhibit as minimal
inconsistent information as reasonably possible. This allows us to characterize the recovered databases in terms of the preferred (i.e., most consistent) models of the theory. The
outcome is an abductive-based application that is sound and complete with respect to a
corresponding model-based, preferential semantics, and  to the best of our knowledge  is
more expressive (thus more general) than any other implementation of coherent integration
of databases.

1. Introduction
Complex reasoning tasks often have to integrate information that is coming from different
sources. One of the major challenges with this respect is to compose contradicting sources of
information such that what is obtained would properly reflect the combination of the datasources on one hand1 , and would still be coherent (in terms of consistency) on the other
hand. There are a number of different issues involved in this process, the most important
of which are the following:
1. Unification of the different ontologies and/or database schemas, in order to get a fixed
(global) schema, and a translation of the integrity constraints2 of each database to
the new ontology.
2. Unification of translated integrity constraints in a single global set of integrity constraints. This means, in particular, elimination of contradictions among the translated
1. This property is sometimes called compositionality (Verbaeten, Denecker, & De Schreye, 1997, 2000).
2. I.e., the rules that represent intentional truths of a database domain.
c
2004
AI Access Foundation. All rights reserved.

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

integrity constraints, and inclusion of any global integrity constraint that is imposed
on the integration process.
3. Integration of databases w.r.t. the unified set of integrity constraints, computed according to the previous item.
Each one of the issues mentioned above has its own difficulties and challenges. For
instance, the first issue is considered, e.g., by Ullman (2000) and Lenzerini (2001, 2002),
where questions such as how to express the relations between the global database schema
and the source (local) schemas, and how this influences query processing with respect to
the global schema (Bertossi, Chomicki, Cortes, & Gutierrez, 2002), are dealt with3 .
The second issue above is concerned with the construction of a single, classically consistent, set of integrity constraints, applied on the integrated data. In database context, it
is common to assume that such a set is pre-defined, and consists of global integrity constraints that are imposed on the integration process itself (Bertossi et al., 2002; Lenzerini,
2002). In such case there is no need to derive these constraints from the local databases.
When different integrity constraints are specified in different local databases, it is required
to integrate not only the database instances (as specified in issue 3 above), but also the
integrity constraints themselves (issue 2). The reason for separating these two topics is that
integrity constraints represent truths that should be valid in all situations, while a database
instance exhibits an extensional truth, i.e., an actual situation. Consequently, the policy of
resolving contradictions among integrity constraints is often different than the one that is
applied on database facts, and often the former is applied before the latter.
Despite their different nature, both issues are based on some formalisms that maintain contradictions and allow to draw plausible conclusions from inconsistent situations.
Roughly, there are two approaches to handle this problem:
 Paraconsistent formalisms, in which the amalgamated data may remain inconsistent,
but the set of conclusions implied by it is not explosive, i.e.: not every fact follows
from an inconsistent database, and so the inference process does not become trivial
in the presence of contradictions. Paraconsistent procedures for integrating data, like
those of Subrahmanian (1994) and de Amo, Carnielli, and Marcos (2002), are often
based on a paraconsistent reasoning systems, such as LFI (Carnielli & Marcos, 2001),
annotated logics (Subrahmanian, 1990; Kifer & Lozinskii, 1992; Arenas, Bertossi, &
Kifer, 2000), or other non-classical proof procedures (Priest, 1991; Arieli & Avron,
1996; Avron, 2002; Carnielli & Marcos, 2002)4 .
 Coherent (consistency-based) methods, in which the amalgamated data is revised in
order to restore consistency (see, e.g., Baral, Kraus, & Minker, 1991; Baral, Kraus,
Minker, & Subrahmanain, 1992; Benferhat, Dubois, & Prade, 1995; Arenas, Bertossi,
3. For surveys on schema matching and related aspects, see also (Batini, Lenzerini, & Navathe, 1986) and
(Rahm & Bernstein, 2001).
4. See also (Decker, 2003) for a historical perspective and some computational remarks on this kind of
formalisms.

246

fiCoherent integration of databases by abductive logic programming

& Chomicki, 1999; Arieli & Avron, 1999; Greco & Zumpano, 2000; Liberatore &
Schaerf, 2000; Bertossi & Schwind, 2002; Arieli, Denecker, Van Nuffelen, & Bruynooghe,
2004). In many cases the underlying formalisms of these approaches are closely related to the theory of belief revision (Alchourron, Gardenfors, & Makinson, 1995;
Gardenfors & Rott, 1995). In the context of database systems the idea is to consider
consistent databases that are as close as possible to the original database. These repaired instances of the spoiled database correspond to plausible and compact ways
of restoring consistency.
In this paper we follow the latter approach, and consider abductive approaches that handle the third issue above, namely: coherent methods for integrating different data-sources
(with the same ontology) w.r.t. a consistent set of integrity constraints5 . The main difficulty in this process stems from the fact that even when each local database is consistent,
the collective information of all the data-sources may not remain consistent anymore. In
particular, facts that are specified in a particular database may violate some integrity constraints defined elsewhere, and so this data might contradict some elements in the unified
set of integrity constraints. Moreover, as noted e.g. in (Lenzerini, 2001; Cali, Calvanese,
De Giacomo, & Lenzerini, 2002), the ability to handle, in a plausible way, incomplete and
inconsistent data, is an inherent property of any system for data integration with integrity
constrains, no matter which integration phase is considered. Providing proper ways of gaining this property is a major concern here as well.
Our goal is therefore to find ways to properly repair a combined (unified) database,
and restore its consistency. For this, we consider a pure declarative representation of the
composition of distributed data by a meta-theory, relating a number of different input
databases (that may contradict each other) with a consistent output database. The underlying language of the theory is that of abductive logic programming (Kakas, Kowalski,
& Toni, 1992; Denecker & Kakas, 2000). For reasoning with such theories we use an abductive system, called Asystem (Kakas, Van Nuffelen, & Denecker, 2001; Van Nuffelen &
Kakas, 2001), which is an abductive solver implementing SLDNFA-resolution (Denecker &
De Schreye, 1992, 1998). The composing system is implemented by abductive reasoning
on the meta-theory. In the context of this work, we have extended this system with an
optimizing component that allows us to compute preferred coherent ways to restore the
consistency of a given database. The system that is obtained induces an operational semantics for database integration. In the sequel we also consider some model-theoretic aspects
of the problem, and define a preferential semantics (Shoham, 1988) for it. According to
this semantics, the repaired databases are characterized in terms of the preferred models
(i.e., the most-consistent valuations) of the underlying theory. We relate these approaches
by showing that the Asystem is sound and complete w.r.t. the model-based semantics. It is
also noted that our framework supports reasoning with various types of special information,
such as timestamps and source identification. Some implementation issues and experimen5. In this sense, one may view this work as a method for restoring the consistency of a single inconsistent
database. We prefer, however, to treat it as an integration process of multiple sources, since it also has
some mediating capabilities, such as source identification, making priorities among different data-sources,
etc. (see, e.g., Section 4.6).

247

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

tal results are discussed as well.
The rest of this paper is organized as follows: in the next section we formally define
our goal, namely: a coherent way to integrate different data-sources. In Section 3 we set
up a semantics for this goal in terms of a corresponding model theory. Then, in Section 4
we introduce our abductive-based application for database integration. This is the main
section of this paper, in which we also describe how a given integration problem can be
represented in terms of meta logic programs, show how to reason with these programs by
abductive computational models, present some experimental results, consider proper ways
of reasoning with several types of special data, and show that our application is sound and
complete with respect to the model-based semantics, considered in Section 3. Section 5
contains an overview of some related works, and in Section 6 we conclude with some further
remarks, open issues, and future work6 .

2. Coherent Integration of Databases
We begin with a formal definition of our goal. In this paper we assume that we have a
first-order language L, based on a fixed database schema S, and a fixed domain D. Every
element of D has a unique name. A database instance D consists of atoms in the language
L that are instances of the schema S. As such, every instance D has a finite active domain,
which is a subset of D.
Definition 1 A database is a pair (D, IC), where D is a database instance, and IC, the
set of integrity constraints, is a finite and classically consistent set of formulae in L.
Given a database DB = (D, IC), we apply to it the closed word assumption, so only
the facts that are explicitly mentioned in D are considered true. The underlying semantics
corresponds, therefore, to minimal Herbrand interpretations.
Definition 2 The minimal Herbrand model HD of a database instance D is the model of
D that assigns true to all the ground instances of atomic formulae in D, and false to all the
other atoms.
There are different views on a database. One view is that it is a logic theory consisting
of atoms and, implicitly, the closed world assumption (CWA) that indicates that all atoms
not in the database are false. Another common view of a database is that it is a structure
that consists of a certain domain and corresponding relations, representing the state of the
world. Whenever there is a complete knowledge and all true atoms are represented in the
database, both views coincide: the unique Herbrand model of the theory is the intended
structure. However, in the context of independent data-sources, the assumption that each
local database represents the state of the world is obviously false. However, we can still
view a local database as an incomplete theory, and so treating a database as a theory rather
than as a structure is more appropriate in our case.
6. This is a combined and extended version of (Arieli, Van Nuffelen, Denecker, & Bruynooghe, 2001) and
(Arieli, Denecker, Van Nuffelen, & Bruynooghe, 2002).

248

fiCoherent integration of databases by abductive logic programming

Definition 3 A formula  follows from a database instance D (alternatively, D entails ;
notation: D |= ) if the minimal Herbrand model of D is also a model of .
Definition 4 A database DB = (D, IC) is consistent if every formula in IC follows from D
(notation: D |= IC).
Our goal is to integrate n consistent local databases, DB i = (Di , IC i ) (i = 1, . . . n) to one
consistent database that contains as much information as possible from the local databases.
The idea, therefore, is to consider the union of the distributed data, and then to restore its
consistency in such a way that as much information as possible will be preserved.
Notation 1 Let DB i = (Di , IC i ), i = 1, . . . n, and let I(IC 1 , . . . , IC n ) be a classically
consistent set of integrity constraints. We denote:
UDB = (

n
[

Di , I(IC 1 , . . . , IC n )).

i=1

In the notation above, I is an operator that combines the integrity constraints and eliminates contradictions (see, e.g., Alferes, Leite, Pereira, & Quaresma, 2000; Alferes, Pereira,
Przymusinska, & Przymusinski, 2002). As we have already noted, how to choose this operator and how to apply it on a specific database is beyond the scope of this paper. In cases
that the union of all the integrity constraints is classically consistent, it makes sense to take
I as the union operator. Global consistency of the integrity constraints is indeed a common
assumption in the database literature (Arenas et al., 1999; Greco & Zumpano, 2000; Greco,
Greco, & Zumpano, 2001; Bertossi et al., 2002; Konieczny & Pino Perez, 2002; Lenzerini,
2002), but for the discussion here it is possible to take, instead of the union, any operator
I for consistency restoration.
A key notion in database integration is the following:
Definition 5 A repair of a database DB = (D, IC) is a pair (Insert, Retract), such that:
1. Insert  D = ,
2. Retract  D7 ,
3. (D  Insert \ Retract, IC) is a consistent database.
Intuitively, Insert is a set of elements that should be inserted into D and Retract is a set
of elements that should be removed from D in order to have a consistent database.
As noted above, repair of a given database is a key notion in many formalisms for
data integration. In the context of database systems, this notion was first introduced by
Arenas, Bertossi, and Chomicki (1999), and later considered by many others (e.g., Greco
& Zumpano, 2000; Liberatore & Schaerf, 2000; Franconi, Palma, Leone, Perri, & Scarcello,
2001; Bertossi et al., 2002; Bertossi & Schwind, 2002; de Amo et al., 2002; Arenas, Bertossi,
& Chomicki, 2003; Arieli et al., 2004). Earlier versions of repairs and inclusion-based
consistency restoration may be traced back to Dalal (1988) and Winslett (1988).
7. Note that by conditions (1) and (2) it follows that Insert  Retract = .

249

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Definition 6 A repaired database of DB = (D, IC) is a consistent database of the form
(D  Insert \ Retract , IC), where (Insert, Retract) is a repair of DB.
As there may be many ways to repair an inconsistent database8 , it is often convenient
to make preferences among the possible repairs, and consider only the most preferred ones.
Below are two common preference criteria for preferring a repair (Insert, Retract) over a
repair (Insert0 , Retract0 ):
Definition 7 Let (Insert, Retract) and (Insert0 , Retract0 ) be two repairs of a given database.
 set inclusion preference criterion : (Insert0 , Retract0 ) i (Insert, Retract), if
Insert  Insert0 and Retract  Retract0 .
 minimal cardinality preference criterion: (Insert0 , Retract0 ) c (Insert, Retract), if
|Insert| + |Retract|  |Insert0 | + |Retract0 |.
Set inclusion is also considered in (Arenas et al., 1999; Greco & Zumpano, 2000; Bertossi
et al., 2002; Bertossi & Schwind, 2002; de Amo et al., 2002; Arenas et al., 2003; Arieli et al.,
2004, and others), minimal cardinality is considered, e.g., in (Dalal, 1988; Liberatore &
Schaerf, 2000; Arenas et al., 2003; Arieli et al., 2004).
In what follows we assume that the preference relation  is a fixed pre-order that
represents some preference criterion on the set of repairs (and we shall omit subscript
notations in it whenever possible). We shall also assume that if (, ) is a valid repair, it is
the -least (i.e., the best) one. This corresponds to the intuition that a database should
not be repaired unless it is inconsistent.
Definition 8 A -preferred repair of DB is a repair (Insert, Retract) of DB, s.t. for every
repair (Insert0 , Retract0 ) of DB, if (Insert, Retract)  (Insert0 , Retract0 ) then (Insert0 , Retract0 ) 
(Insert, Retract). The set of all the -preferred repairs of DB is denoted by !(DB, ).
Definition 9 A -repaired database of DB is a repaired database of DB, constructed from
a -preferred repair of DB. The set of all the -repaired databases is denoted by:
R(DB, ) = { (D  Insert \ Retract , IC) | (Insert, Retract)  !(DB, ) }.
Note that if DB is consistent and  is a preference relation, then DB is the only repaired database of itself (thus, there is nothing to repair in this case, as expected).
Note 1 It is usual to refer to the -preferred databases of DB as the consistent databases
that are as close as possible to DB itself (see, e.g., Arenas, Bertossi, & Chomicki, 1999;
Liberatore & Schaerf, 2000; de Amo, Carnielli, & Marcos, 2002; Konieczny & Pino Perez,
2002; Arenas, Bertossi, & Chomicki, 2003; Arieli, Denecker, Van Nuffelen, & Bruynooghe,
2004). Indeed, let
dist(D1 , D2 ) = (D1 \ D2 )  (D2 \ D1 ).
8. Some repairs may be trivial and/or useless, though. For instance, one way to eliminate the inconsistency
in (D, IC) = ({p, q, r}, {p}) is by deleting every element in D, but this is certainly not the optimal way
of restoring consistency in this case.

250

fiCoherent integration of databases by abductive logic programming

It is easy to see that DB 0 = (D0 , IC) is a i -repaired database of DB = (D, IC), if the set
dist(D0 , D) is minimal (w.r.t. set inclusion) among all the sets of the form dist(D00 , D),
where D00 |= IC. Similarly, if |S| denotes the size of S, then DB 0 = (D0 , IC) is a c -repaired
database of DB = (D, IC), if |dist(D0 , D)| = min{|dist(D00 , D)| | D00 |= IC}.
Given n databases and a preference criterion , our goal is therefore to compute the set
R(UDB, ) of the -repaired databases of the unified database, UDB (Notation 1). The
reasoner may use different strategies to determine the consequences of this set. Among the
common approaches are the skeptical (conservative) one, that it is based on a consensus
among all the elements of R(UDB, ) (see Arenas et al., 1999; Greco & Zumpano, 2000), a
credulous approach, in which entailments are determined by any element in R(UDB, ),
an approach that is based on a majority vote (Lin & Mendelzon, 1998; Konieczny &
Pino Perez, 2002), etc. In cases where processing time is a major consideration, one may
want to speed-up the computations by considering any repaired database. In such cases it
is sufficient to find an arbitrary element in the set R(UDB, ).
Below are some examples9 of the integration process10 .
Example 1 Consider a relation teaches of the schema (course name, teacher name), and
an integrity constraint, stating that the same course cannot be taught by two different
teachers:
IC = { XY Z (teaches(X, Y )  teaches(X, Z)  Y = Z) }.
Consider now the following two databases:
DB 1 = ( {teaches(c1 , n1 ), teaches(c2 , n2 )}, IC ),
DB 2 = ( {teaches(c2 , n3 )}, IC).
Clearly, the unified database DB 1  DB 2 is inconsistent. It has two preferred repairs, which
are (, {teaches(c2 , n3 )}) and (, {teaches(c2 , n2 )}). The corresponding repaired databases
are the following:
R1 = ( {teaches(c1 , n1 ), teaches(c2 , n2 )}, IC ),
R2 = ( {teaches(c1 , n1 ), teaches(c2 , n3 )}, IC ).
Thus, e.g., teaches(c1 , n1 ) is true both in the conservative approach and the credulous
approach to database integration, while the conclusion teaches(c2 , n2 ) is supported only by
credulous reasoning.
Example 2 Consider databases with relations class and supply, of schemas (item, type)
and (supplier, department, item), respectively. Let
DB 1 = ({supply(c1 , d1 , i1 ), class(i1 , t1 )}, IC),
DB 2 = ({supply(c2 , d2 , i2 ), class(i2 , t1 )}, ),
where IC = { XY Z (supply(X, Y, Z)class(Z, t1 )  X = c1 ) } states that only supplier
9. See, e.g., (Arenas et al., 1999; Greco & Zumpano, 2000; Bertossi & Schwind, 2002) for further discussions
on these examples.
10. In all the following examples we use set inclusion as the preference criterion, and take the operator I
that combines integrity constraints (see Notation 1) to be the union operator.

251

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

c1 can supply items of type t1 . Again, DB 1  DB 2 is inconsistent, and has two preferred
repairs: (, {supply(c2 , d2 , i2 )}) and (, {class(i2 , t1 )}). It follows that there are two repairs
of this database:
R1 = ( {supply(c1 , d1 , i1 ), class(i1 , t1 ), class(i2 , t1 )}, IC ),
R2 = ( {supply(c1 , d1 , i1 ), supply(c2 , d2 , i2 ), class(i1 , t1 )}, IC ).
Example 3 Let D1 = {p(a), p(b)}, D2 = {q(a), q(c)}, and IC = {X(p(X)  q(X))}. Again,
(D1 , )  (D2 , IC) is inconsistent. The corresponding preferred repairs are ({q(b)}, ) and
(, {p(b)}). Thus, the repaired databases are the following:
R1 = ( {p(a), p(b), q(a), q(b), q(c)}, IC ),
R2 = ( {p(a), q(a), q(c)}, IC ).
In this case, then, both the consensus approach and the credulous approach allow to
infer, e.g., that p(a) holds, while p(b) is supported only by credulous reasoning, and p(c) is
not supported by either of these approaches.

3. Model-based Characterization of Repairs
In this section we set up a semantics for describing repairs and preferred repairs in terms
of a corresponding model theory. This will allow us, in particular, to give an alternative
description of preferred repairs, this time in terms of a preferential semantics for database
theory.
As database semantics is usually defined in terms of two-valued (Herbrand) models
(cf. Definition 2 and the discussion that proceeds it), it is natural to consider two-valued
semantics first. We show that arbitrary repairs can be represented by two-valued models
of the integrity constraints. When a database is inconsistent, then by definition, there
is no two-valued interpretation which satisfies both its database instance and its integrity
constraints. A standard way to cope with this type of inconsistencies is to move to multiplevalued semantics for reasoning with inconsistent and incomplete information (see, e.g.,
Subrahmanian, 1990, 1994; Messing, 1997; Arieli & Avron, 1999; Arenas, Bertossi, & Kifer,
2000; de Amo, Carnielli, & Marcos, 2002). What we will show below, is that repairs can be
characterized by three-valued models of the whole database, that is, of the database instance
and the integrity constraints. Finally, we concentrate on the most preferred repairs, and
show that a certain subset of the three-valued models can be used for characterizing preferred repairs.
Definition 10 Given a valuation  and a truth value x. Denote:
 x = {p | p is an atomic formula, and (p) = x}11 .
The following two propositions characterize repairs in terms of two-valued structures.
Proposition 1 Let (D, IC) be a database and let M be a two-valued model of IC. Let
Insert = M t \ D and Retract = D \ M t . Then (Insert, Retract) is a repair of (D, IC).
11. Note, in particular, that in terms of Definition 2, if  = HD and x = t, we have that  x = D.

252

fiCoherent integration of databases by abductive logic programming

Proof: The definitions of Insert and Retract immediately imply that Insert  D =  and
Retract  D. For the last condition in Definition 5, note that D  Insert \ Retract = D 
(M t \D)\(D\M t ) = M t . It follows that M is the least Herbrand model of DInsert\Retract
and it is also a model of IC, therefore D  Insert \ Retract |= IC.
2
Proposition 2 Let (Insert, Retract) be a repair of a database (D, IC). Then there is a
two-valued model M of IC such that Insert = M t \ D and Retract = D \ M t .
Proof: Consider a valuation M , defined for every atom p as follows:
(

M (p) =

t

if p  D  Insert \ Retract,

f

otherwise.

By its definition, M is a minimal Herbrand model of D  Insert \ Retract. Now, since
(Insert, Retract) is a repair of (D, IC), we have that D  Insert \ Retract |= IC, thus M
is a (two-valued) model of IC. Moreover, since (Insert, Retract) is a repair, necessarily
Insert  D =  and Retract  D, hence we have the following:
 M t \ D = (D  Insert \ Retract) \ D = Insert,
2

 D \ M t = D \ (D  Insert \ Retract) = Retract.

When a database is inconsistent, it has no models that satisfy both its integrity constraints and its database instance. One common method to overcome such an inconsistency
is to introduce additional truth-values that intuitively represent partial knowledge, different
amounts of beliefs, etc. (see, e.g., Priest, 1989, 1991; Subrahmanian, 1990; Fitting, 1991;
Arieli, 1999; Arenas et al., 2000; Avron, 2002). Here we follow this guideline, and consider
database integration in the context of a three-valued semantics. The benefit of this is that,
as we show below, any database has some three-valued models, from which it is possible to
pinpoint the inconsistent information, and accordingly construct repairs.
The underlying three-valued semantics considered here is induced by the algebraic structure T HREE, shown in the double-Hasse diagram of Figure 112 .
k
6

>

u
@
@
@
@
@
@u

u

f

t



-t

Figure 1: The structure T HREE
Intuitively, the elements t and f in T HREE correspond to the usual classical values
true and false, while the third element, >, represents inconsistent information (or belief).
12. This structure is used for reasoning with inconsistency by several other three-valued formalisms, such as
LFI (Carnielli & Marcos, 2001, 2002) and LP (Priest, 1989, 1991).

253

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Viewed horizontally, T HREE is a complete lattice. According to this view, f is the minimal
element, t is the maximal one, and > is an intermediate element. The corresponding order relation, t , intuitively represents differences in the amount of truth that each element
exhibits. We denote the meet, join, and the order reversing operation on t by , , and
 (respectively). Viewed vertically, T HREE is a semi-upper lattice. In this view, > is
the maximal element and the two classical values are incomparable. This partial order,
denoted by k , may be intuitively understood as representing differences in the amount
of knowledge (or information) that each element represents13 . We denote by  the join
operation on k 14 .
Various semantic notions can be defined on T HREE as natural generalizations of similar
classical ones: a valuation  is a function that assigns a truth value in T HREE to each
atomic formula. Given a valuation , truth values xi  {t, f, >}, and atomic formulae pi ,
we shall sometimes write  = {pi : xi } instead of (pi ) = xi (i = 1, 2 . . .). Any valuation is
extended to complex formulae in the obvious way. For instance, () = (), (  ) =
()  (), and so forth15 . The set of the designated truth values in T HREE (i.e., those
elements in T HREE that represent true assertions) consists of t and >. A valuation 
satisfies a formula  iff () is designated. A valuation that assigns a designated value to
every formula in a theory T is a (three-valued) model of T .
Lemma 1 Let  and  be three-valued valuations s.t. for every atom p, (p) k (p). Then
for every formula , () k ().
2

Proof: By induction on the structure of .

We shall write  k , if  and  are three-valued valuations, for which the condition of
Lemma 1 holds.
Lemma 2 If  k  and  is a model of some theory T , then  is also a model of T .
Proof: For every formula   T , () is designated. Hence, by Lemma 1, for every formula
  T () is also designated, and so  is a model of T .
2
Next we characterize the repairs of a database DB by its three-valued models:
Proposition 3 Let (D, IC) be a database and let M be a two-valued model of IC. Consider
the three-valued valuation N , defined for every atom p by N (p) = HD (p)  M (p), and let
Insert = N > \ D, Retract = N >  D. Then:
1. N is a three-valued model of D  IC, and
13. See (Belnap, 1977; Ginsberg, 1988; Fitting, 1991) for a more detailed discussion on these orders and
their intuitive meaning.
14. We follow here the notations of Fitting (1990, 1991).
15. As usual, we use here the same logical symbol to denote the connective that appear on the left-hand
side of an equation, and the corresponding operator on T HREE that appear on the right-hand side of
the same equation.

254

fiCoherent integration of databases by abductive logic programming

2. (Insert, Retract) is a repair of (D, IC).
Proposition 3 shows that repairs of a database (D, IC) may be constructed in a standard
(uniform) way by considering three-valued models that are the k -least upper bounds of
two two-valued valuations: the minimal Herbrand model of the database instance, and a
two-valued model of the integrity constraints. Proposition 4 below shows that any repair
of (D, IC) is of this form.
Before we give a proof for Proposition 3, lets demonstrate it by a simple example.
Example 4 Let DB = ({p, r} , {p  q}). Then HD = {p : t, q : f, r : t}, and the two-valued
models of IC = {p  q} are {p : t, q : t, r : t}, {p : t, q : t, r : f }, {p : f, q : t, r : t}, {p : f, q : t, r : f },
{p : f, q : f, r : t}, and {p : f, q : f, r : f }. Thus, the (three-valued) models of the form HD  M ,
where M is a two-valued model of IC, are {p : t, q : >, r : t}, {p : t, q : >, r : >}, {p : >, q : >, r : t},
{p : >, q : >, r : >}, {p : >, q : f, r : t} and {p : >, q : f, r : >}. By Proposition 3, the pairs
({q}, {}), ({q}, {r}), ({q}, {p}), ({q}, {p, r}), ({}, {p}), and ({}, {p, r}), are repairs of DB.
Proof of Proposition 3: Since by the definition of N , N k HD , and since HD is a model
of D, Lemma 2 implies that N is a model D. Similarly, N k M , and M is a model of IC,
thus by the same lemma N is also a model of IC.
For the second part, we observe that Insert = N > \ D = M t \ D and Retract = N >  D =
f
M  D = D \ M t . Now, M is a two-valued model of IC and hence, by Proposition 1,
(Insert, Retract) is a repair of (D, IC).
2
Note that the specific form of the three-valued valuations considered in Proposition 3
is essential here, as the proposition does not hold for every three-valued model of D  IC.
To see this consider, e.g., D = {}, IC = {p , p  q}, and a three valued valuation N that
assigns > to p and t to q. Clearly, N is a model of D  IC, but the corresponding update,
(N > \ D , N >  D) = ({p}, {}) is not a repair of (D, IC), since ({p}, IC) is not a consistent
database.
Again, as we have noted above, it is possible to show that the converse of Proposition 3
is also true:
Proposition 4 Let (Insert, Retract) be a repair of a database (D, IC). Then there is a
three-valued model N of D  IC, such that Insert = N > \ D and Retract = N >  D.
Proof: Consider a valuation N , defined for every atom p as follows:
N (p) =



 >

if p  Insert  Retract,

t

if p 6 Insert  Retract but p  D,




f

otherwise.

By the definition of N and since (Insert, Retract) is a repair of (D, IC), we have that N > \D =
(Insert  Retract) \ D = Insert and N >  D = (Insert  Retract)  D = Retract.
It remains to show that N is a (three-valued) model of D and IC. It is a three-valued
model of D because for every p  D, N (p)  {t, >}. Regarding IC, (Insert, Retract) is a
255

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

repair of (D, IC), thus every formula in IC is true in the least Herbrand model M of
D0 = D  Insert \ Retract. In particular, M (q) = t for every q  D0 . But since for every
p  DInsert we have that N (p)  {t, >} and D0  DInsert, necessarily q  D0 N (q)  {t, >}.
It follows that for every q  D0 , N (q) k M (q) = t, thus by Lemma 1 and Lemma 2, N must
also be a (three-valued) model of D0 . Hence N is a model of IC.
2
The last two propositions characterize the repairs of UDB in terms of pairs that are
associated with certain three-valued models of D  IC. We shall denote the elements of
these pairs as follows:
Notation 2 Let N be a three-valued model and let DB = (D, IC) be a database. Denote:
InsertN = N > \ D and RetractN = N >  D.
We conclude this model-based analysis by characterizing the set of the -preferred
repairs, where  is one of the preference criteria considered in Definition 7 (i.e., set inclusion
or minimal cardinality). As the propositions below show, common considerations on how
inconsistent databases can be properly recovered (e.g., keeping the amount of changes
as minimal as possible, being as close as possible to the original instance, etc.) can be
captured by preferential models in the context of preferential semantics (Shoham, 1988).
The idea is to define some order relation on the set of the (three-valued) models of the
database. This relation intuitively captures some criterion for making preferences among
the relevant models. Then, only the most preferred models (those that are minimal with
respect to the underlying order relation) are considered in order to determine how the
database should be repaired. Below we formalize this idea:
Definition 11 Given a database DB = (D, IC), denote:
MDB = {N | N k HD  M for some classical model M of IC}16 .
Example 5 Consider again the database DB = ({p, r} , {p  q}) of Example 4. As we
have shown, there are six valuations of the form HD  M , for some two-valued model M of
IC, namely:
{p : t , q : >, r : t},

{p : t , q : >, r : >},

{p : >, q : >, r : t},

{p : >, q : >, r : >},

{p : >, q : f, r : t},

{p : >, q : f, r : >}.

The k-minimal models among these models are {p : t, q : >, r : t} and {p : >, q : f, r : t}, thus
MDB = {N | N (p) k t, N (q) = >, N (r) k t}  {N | N (p) = >, N (q) k f, N (r) k t}.
Preference orders should reflect some normality considerations applied on the relevant
set of valuations (MDB , in our case);  is preferable than , if  describes a situation
that is more common (plausible) than the one described by . Hence, a natural way to
define preferences in our case is by minimizing inconsistencies. We thus get the following
definition:
Definition 12 Let S be a set of three-valued valuations, and N1 , N2  S.
16. Note that N is a three-valued valuation and M is a two-valued model of IC.

256

fiCoherent integration of databases by abductive logic programming

 N1 is i -more consistent than N2 , if N1>  N2> .
 N1 is c -more consistent than N2 , if |N1> | < |N2> |.
 N  S is i -maximally consistent in S (respectively, N is c -maximally consistent in
S), if there is no N 0  S that is i -more consistent than N (respectively, no N 0  S is
c -more consistent than N ).
The following propositions show that there is a close relationship between most consistent models of MDB and the preferred repairs of DB.
Proposition 5 If N is a i -maximally consistent element in MDB , then (InsertN , RetractN )
is a i -preferred repair of DB.
Proof: By Proposition 3, (InsertN , RetractN ) is a repair of DB. If it is not a i -preferred
repair of DB, then there is a repair (Insert, Retract) s.t. Insert  InsertN , Retract  RetractN ,
and InsertRetract  InsertN RetractN . By Proposition 4 and its proof, there is an element
0
0
0
0
N 0  MDB s.t. Insert = InsertN , Retract = RetractN , and (N 0 )> = InsertN  RetractN . It
follows, then, that (N 0 )>  N > , and so N is not a maximally consistent in MDB , but this
is a contradiction to the definition of N .
2
Proposition 6 Suppose that (Insert, Retract) is a i -preferred repair of DB. Then there is
a i -maximally consistent element N in MDB s.t. Insert = InsertN and Retract = RetractN .
Proof: The pair (Insert, Retract) is in particular a repair of DB, thus by Proposition 2 there
is a classical model M of IC such that Insert = M t \ D and Retract = D \ M t . Consider the
following valuation:
(

N (p) =

>

if p  M t \ D or p  D \ M t

M (p)

otherwise.

First we show that N = HD  M . This is so since if M (p) = HD (p), then since HD is a
minimal Herbrand model of D, necessarily p 6 M t \ D and p 6 D \ M t , thus N (p) = M (p) =
M (p)  M (p) = M (p)  HD (p). Otherwise, if M (p) 6= HD (p), then either M (p) = t and
HD (p) = f , i.e., p  M t \ D, or M (p) = f and HD (p) = t, i.e., p  D \ M t . In both cases,
N (p) = > = M (p)  HD (p)17 . Thus N = HD  M , and so N  MDB . Now, by Proposition 2
again, and by the definition of N , InsertN = N > \ D = [(M t \ D)  (D \ M t )] \ D = M t \ D =
Insert, and RetractN = N >  D = [(M t \ D)  (D \ M t )]  D = D \ M t = Retract.
It remains to show that N is i -maximally consistent in MDB . Suppose not. Then there
0
0
is an N 0  MDB s.t. (N 0 )>  N > = Insert  Retract. By Proposition 3, (InsertN , RetractN )
is also a repair of DB. Moreover,
0
 InsertN = (N 0 )> \ D  N > \ D = InsertN = Insert,
0
 RetractN = (N 0 )>  D  N >  D = RetractN = Retract,
0
0
 InsertN  RetractN = (N 0 )>  N > = InsertN  RetractN = Insert  Retract.
0
0
Hence (InsertN , RetractN ) <i (Insert, Retract), and so (Insert, Retract) is not a i -preferred
repair of (D, IC), a contradiction.
2
Propositions 5 and 6 may be formulated in terms of c as follows:
17. Here we use the fact that t  f = >.

257

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Proposition 7 If N is a c -maximally consistent element in MDB , then (InsertN , RetractN )
is a c -preferred repair of DB.
Proposition 8 Suppose that (Insert, Retract) is a c -preferred repair of DB. Then there is
a c -maximally consistent element N in MDB s.t. Insert = InsertN and Retract = RetractN .
The proofs of the last two propositions are similar to those of Propositions 5 and 6,
respectively.
Example 6 Consider again Example 3. We have that:
UDB = (D, IC) = ( {p(a), p(b), q(a), q(c)}, {X(p(X)  q(X))} ).
HD

Thus,
= {p(a) : t, p(b) : t, p(c) : f, q(a) : t, q(b) : f, q(c) : t}, and the classical models of
IC are those in which either p(y) is false or q(y) is true for every y  {a, b, c}. Now, since in
HD neither p(b) is false nor q(b) is true, it follows that every element in MU DB must assign
> either to p(b) or to q(b). Hence, the i -maximally consistent elements in MU DB (which
in this case are also the c -maximally consistent elements in MU DB ) are the following:
M1 = { p(a) : t, p(b) : >, p(c) : f, q(a) : t, q(b) : f, q(c) : t },
M2 = { p(a) : t, p(b) : t, p(c) : f, q(a) : t, q(b) : >, q(c) : t }.
By Propositions 5 and 6, then, the i -preferred repairs of UDB (which are also its c preferred repairs) are (InsertM1 , RetractM1 ) = (, {p(b)}) and (InsertM2 , RetractM2 ) =
({q(b)}, ) (cf. Example 3).
Example 7 In Examples 4 and 5, the i -maximally consistent elements (and the c maximally consistent elements) of MDB are N1 = {p : t, q : >, r : t} and N2 = {p : >, q : f, r : t}.
It follows that the preferred repairs in this case are ({q}, ) and (, {p}).
To summarize, in this section we have considered a model-based, three-valued preferential semantics for database integration. We have shown (Propositions 5  8) that common
and natural criteria for making preferences among possible repairs (i.e., set inclusion and
minimal cardinality) can be expressed by order relations on three-valued models of the
database. The two ways of making preferences (among repairs on one hand and among
three-valued models on the other hand) are thus strongly related, and induce two alternative approaches for database integration. In the next section we shall consider a third
approach to the same problem (aimed to provide an operational semantics for database
integration) and relate it to the model-based semantics, discussed above.

4. Computing Repairs through Abduction
In this section we introduce an abductive system that consistently integrates possibly contradicting data-sources. This system computes, for a set of data-sources and a preference
criterion , the corresponding -repaired databases18 . Our framework is composed of
an abductive logic program (Denecker & Kakas, 2000) and an abductive solver Asystem
(Kakas, Van Nuffelen, & Denecker, 2001; Van Nuffelen & Kakas, 2001) that is based on the
18. It is important to note already in this stage that for computing the -repaired databases it wont be
necessary to produce all the repaired databases.

258

fiCoherent integration of databases by abductive logic programming

abductive refutation procedure SLDNFA (Denecker & De Schreye, 1992, 1998). In the first
three parts of this section we describe these components: in Section 4.1 we give a general
description of abductive reasoning, in Section 4.2 we show how it can be applied to encode
database repairs, and in Section 4.3 we describe the computational platform. Then, in
Section 4.4 we demonstrate the computation process by a comprehensive example, and in
Section 4.5 we specify soundness and completeness results of our approach (with respect to
the basic definitions of Section 2 and the model-based semantics of Section 3). Finally, in
Section 4.6 we consider some ways of representing special types of data in the system.
4.1 Abductive Logic Programming
We start with a general description of abductive reasoning in the context of logic programming. As usual in logic programming, the language contains constants, functions, and
predicate symbols. A term is either a variable, a constant, or a compound term f (t1 , . . . , tn ),
where f is an n-ary function symbol and ti are terms. An atom is an expression of the form
p(t1 , . . . , tm ), where p is an m-ary predicate symbol and ti (i = 1,. . ., m) are terms. A literal
is an atom or a negated atom. A denial is an expression of the form X( F ), where F
is a conjunction of literals and X is a subset of the variables in F . The free variables in
F (those that are not in X) can be considered as place holders for objects of unspecified
identity (Skolem constants). Intuitively, the body F of a denial X( F ) represents an
invalid situation.
Definition 13 (Kakas et al., 1992; Denecker & Kakas, 2000) An abductive logic theory is
a triple T = (P , A , IC), where:
 P is a logic program, consisting of clauses of the form h  l1  . . .  ln , where h is
an atomic formula and li (i = 1, . . . , n) are literals. These clauses are interpreted as
definitions for the predicates in their heads,
 A is a set of abducible predicates, i.e., predicates that do not appear in the head of
any clause in P,
 IC is a set of first-order formulae, called integrity constraints.
All the main model semantics of logic programming can be extended to abductive logic
programming. This includes two-valued completion (Console, Theseider Dupre, & Torasso,
1991) and three-valued completion semantics (Denecker & De Schreye, 1993), extended
well-founded semantics (Pereira, Aparicio, & Alferes, 1991), and generalized stable semantics (Kakas & Mancarella, 1990b). These semantics can be defined in terms of arbitrary
interpretations (Denecker & De Schreye, 1993), but generally they are based on Herbrand
interpretations. The effect of this restriction on the semantics of the abductive theory is
that a domain closure condition is imposed: the domain of interpretation is known to be
the Herbrand universe. A model of an abductive theory under any of these semantics is
a Herbrand interpretation H, for which there exists a collection of ground abducible facts
, such that H is a model of the logic program P   (with respect to the corresponding
semantics of logic programming) and H classically satisfies any element in IC.

259

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Similarly, for any of the main semantics S of logic programming, one can define the
notion of an abductive solution for a query and an abductive theory.
Definition 14 (Kakas et al., 1992; Denecker & Kakas, 2000) An (abductive) solution for
a theory (P , A , IC) and a query Q is a set  of ground abducible atoms, each one having
a predicate symbol in A, together with an answer substitution , such that the following
three conditions are satisfied:
a) P   is consistent in the semantics S,
b) P   |=S IC,
c) P   |=S Q.
In the next section we will use an abductive theory with a non-recursive program to
model the database repairs. The next proposition shows that for such abductive theories all
Herbrand semantics coincide, and models correspond to abductive solutions for the query
true.
Proposition 9 Let T = (P , A , IC) be an abductive theory, such that P is a non-recursive
program. Then H is a Herbrand model of the three-valued completion semantics, iff H is a
Herbrand model of the two-valued completion semantics, iff H is a generalized stable model
of T , iff H is a generalized well-founded model of T .
If H is a model of T , then the set  of abducible atoms in H is an abductive solution
for the query true. Conversely, for every abductive solution for true, there exists a unique
model H of T , such that  is the set of true abducible atoms in H.
Proof: The proof is based on the well-known fact that for non-recursive logic programs, all
the main semantics of logic programming coincide. In particular, for a non-recursive logic
program P there is a Herbrand interpretation H, which is the unique model under each
semantics (see, for example, Denecker & De Schreye, 1993).
Let H be a model of T = (P , A , IC) under any of the four semantics mentioned above.
Then there exists a collection of ground abducible facts , such that H is a model of the
logic program P   under the corresponding semantics of logic programming. Since P is
non-recursive, so is P  . By the above observation, H is the unique model of P   under
any of the above mentioned semantics. Hence, H is a model of T under any of the other
semantics. This proves the first part of the proposition.
When H is a Herbrand model of T , there is a set  of abducible atoms such that H is
a model of P  . Clearly,  must be the set of true abducible atoms in H. Then P  
is obviously consistent, and it entails the integrity constraints of T , which entails true.
Hence,  is an abductive solution for true. Conversely, for any set  of abducible atoms,
P   has a unique model H and the set of true abducible atoms in H is . When  is an
abductive solution for true, H satisfies the integrity constraints, and hence H is a model
of T . Consequently, H is the unique model of T , and its set of true abducible atoms is . 2
In addition to the standard properties of abductive solutions for a theory T and a query
Q, specified in Definition 14, one frequently imposes optimization conditions on the solutions
260

fiCoherent integration of databases by abductive logic programming

, analogous to those found in the context of database repairs. Two frequently used criteria
are that the generated abductive solution  should be minimal with respect to set inclusion
or with respect to set cardinality (cf. Definition 7). The fact that the same preference
criteria are used for choosing appropriate abductive solutions and for selecting preferred
database repairs does not necessarily mean that there is a natural mapping between the
corresponding solutions. In the next sections we will show, however, that meta-programming
allows us to map a database repair problem into an abductive problem (w.r.t. the same
type of preference criterion).
4.2 An Abductive Meta-Program for Encoding Database Repairs
The task of repairing the union of n given databases DB i with respect to the integration of the local integrity constraints IC, can be represented by an abductive theory
T = (P , A , IC 0 ), where P is a meta-program encoding how a new database is obtained
by updating the existing databases, A is the set {insert, retract} of abducible predicates
used to describe updates, and IC 0 encodes the integrity constraints. In P, facts p that
appear in at least one of the databases are encoded by atomic rules db(p), and facts p that
appear in the updated database are represented by atoms fact(p). The latter predicate is
defined as follows:
fact(X)  db(X)  retract(X)
fact(X)  insert(X)
To assure that the predicates insert and retract encode a proper update of the
database, the following integrity constraints are also specified:
 An inserted element should not belong to a given database:
 insert(X)  db(X)
 A retracted element should belong to some database:
 retract(X)  db(X)
The set of integrity constraints IC 0 is obtained by a straightforward transformation
from IC: every occurrence of a database fact p in some integrity constraint is replaced by
fact(p)19 .
Example 8 (Example 1, revisited) Figure 2 contains the meta-program encoding Example 1 (the codes for Examples 2 and 3 are similar).
As noted in Section 4.1, under any of the main semantics of abductive logic programing
there is a one to one correspondence between repairs of the composed database DB and the
Herbrand models of its encoding, the abductive meta theory T . Consequently, abduction
can be used to compute repairs. In the following sections we introduce an abductive method
for this purpose.
19. Since our abductive system (see Section 4.3) will accept integrity constraints in a denial form, in case
that the elements of IC 0 are not in this form, the Lloyd-Topor transformation (Lloyd & Topor, 1984)
may also be applied here; we consider this case in Section 4.3.2.

261

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

% System definitions:
defined(fact( ))
defined(db( ))
abducible(insert( ))
abducible(retract( ))
% The composer:
fact(X)  db(X)  retract(X)
fact(X)  insert(X)
 insert(X)  db(X)
 retract(X)  db(X)
% The databases:
db(teaches(c1,n1))
db(teaches(c2,n2))
db(teaches(c2,n3))
Y = Z  fact(teaches(X,Y))  fact(teaches(X,Z))

% D1
% D2
% IC

Figure 2: A meta-program for Example 1

4.3 The Abductive Computational Model (The Asystem)
Below we describe the abductive system that will be used to compute database repairs. The
Asystem (Kakas, Van Nuffelen, & Denecker, 2001; Van Nuffelen & Kakas, 2001) is a tool
combining abductive logic theories and constraint logic programming (CLP). It is a synthesis
of the refutation procedures SLDNFA (Denecker & De Schreye, 1998) and ACLP (Kakas
et al., 2000), together with an improved control strategy. The essence of the Asystem is a
reduction of a high level specification to a lower level constraint store, which is managed by a
constraint solver. See http://www.cs.kuleuven.ac.be/dtai/kt/ for the latest version
of the system20 . Below we review the theoretical background as well as some practical
considerations behind this system. For more information, see (Denecker & De Schreye,
1998) and (Kakas, Van Nuffelen, & Denecker, 2001).
4.3.1 Abductive Inference
The input to the Asystem is an abductive theory T = (P, A, IC), where IC consists of
universally quantified denials. The process of answering a query Q, given by a conjunction
of literals, can be described as a derivation for Q through rewriting states. A state is a pair
(G , ST ), where G, the set of goal formulae, is a set of conjunctions of literals and denials.
During the rewriting process the elements in G (the goals) are reduced to basic formulae
20. This version runs on top of Sicstus Prolog 3.10.1 or later versions.

262

fiCoherent integration of databases by abductive logic programming

that are stored in the structure ST . This structure is called a store, and it consists of the
following elements21 :
 a set  that contains abducibles a(t).
 a set  that contains denials of the form X( a(t)  Q), where a(t) is an abducible.
Such a denial may contain free variables.
 a set E of equalities and inequalities over terms.
The consistency of E is maintained by a constraint solver that uses the Martelli and Montanari unification algorithm (Martelli & Montanari, 1982) for the equalities and constructive
negation for the inequalities.
A state S = (G , ST ) is called consistent if G does not contain false and ST is consistent (since  and  are kept consistent with each other and with E, the latter condition
is equivalent to the consistency of E). A consistent state with an empty set of goals (G = )
is called a solution state.
A derivation starts with an initial state (G0 , ST 0 ), where every element in ST 0 is empty,
and the initial goal, G0 , contains the query Q and all the integrity constraints IC of the
theory T . Then a sequence of rewriting steps is performed. A step starts in a certain state
Si = (Gi , ST i ), selects a goal in Gi , and applies an inference rule (see below) to obtain a
new consistent state Si+1 . When no consistent state can be reached from Si the derivation
backtracks. A derivation terminates when a solution state is reached, otherwise it fails (see
Section 4.4 below for a demonstration of this process).
Next we present the inference rules in the Asystem, using the following conventions:
 Gi = Gi  {F }, where F is the selected goal formula.
 OR and SELECT denote nondeterministic choices in an inference rule.
 Q is a conjunction of literals, possibly empty. Since an empty conjunction is equivalent
to true, the denial  Q with empty Q is equivalent to false.
 If ,  , and E are not mentioned, they remain unchanged.
The inference rules are classified in four groups, named after the leftmost literal in the
selected formula (shown in bold). Each group contains rules for (positive) conjunctions of
literals and rules for denials.
1. Defined predicates:
The inference rules unfold the bodies of a defined predicate. For positive conjunctions
this corresponds to standard resolution with a selected clause, whereas in the denial
all clauses are used because every clause leads to a new denial.
D.1 p(t)  Q:
Let p(si )  Bi  P (i = 1, . . . , n) be n clauses with p in the head. Then:
Gi+1 = Gi  {t = s1  B1  Q} OR . . . OR Gi+1 = Gi  {t = sn  Bn  Q}
21. The actual implementation of the Asystem also contains a store for finite domain constraint expressions.
This store is not needed for the application here, and hence it is omitted.

263

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

D.2 X( p(t)  Q):
Gi+1 = Gi  {X, Y ( t = s  B  Q) | there is p(s)  B  P with variables Y }
2. Negations:
Resolving negation corresponds to switching the mode of reasoning from a positive
literal to a denial and vice versa. This is similar to the idea of negation-as-failure in
logic programming.
N.1 p(t)  Q:
Gi+1 = Gi  {Q,  p(t)}
N.2 X( p(t)  Q) and t does not contain variables in X:
Gi+1 = Gi  {p(t)} OR Gi+1 = Gi  { p(t), X( Q)}
3. Abducibles:
The first rule is responsible for the creation of new hypotheses. Both rules ensure that
the elements in  are consistent with those in  .
A.1 a(t)  Q:
SELECT an arbitrary a(s)   and define Gi+1 = Gi  {Q}  {s = t}
OR Gi+1 = Gi  {Q}  {X( s = t  R) | X( a(s)  R)  i } 
{ (t = s) | a(s)  i } and i+1 = i  {a(t)}
A.2 X( a(t)  Q):
Gi+1 = Gi  {X( s = t  Q) | a(s)  i } and i+1 = i  {X( a(t)  Q)}
4. Equalities:
These inference rules isolate the (in)equalities, so that the constraint solver can evaluate them. The first rule applies to equalities in goal formulae:
E.1 s = t  Q:
Gi+1 = Gi  {Q} and Ei+1 = Ei  {s = t}
The following three rules handle equalities in denials. Which rule applies depends on
whether s or t contain free or universally quantified variables. In these rules Q[X/t]
denotes the formula that is obtained from Q by substituting the term t for X.
E.2 X( s = t  Q):
If s and t are not unifiable then Gi+1 = Gi ;
Otherwise, let Es be the equation set in solved form representing a most general
unifier of s and t (Martelli & Montanari, 1982). Gi+1 = Gi  {X( Es  Q)}.
E.3 X, Y( X = t  Q) where t is a term not containing X:
Gi+1 = Gi  {Y ( Q[X/t])}
E.4 X, Y( X = t  Q) where X is a free variable and X is the set of universally
quantified variables in a term t:
Ei+1 = Ei  {X(X 6= t)} OR Gi+1 = Gi  {X = t}  {Y ( Q[X/t])}22 .
22. In its first branch the inference E.4 explores the condition X(X 6= t). In the second branch, the negation
of this condition is explored. Here X is identical to t, for some values assigned to X. This is why in the
second branch, the universally quantified variables X are turned into free variables which may appear
free in Y ( Q[X/t]).

264

fiCoherent integration of databases by abductive logic programming

As usual, one has to check for floundering negation. This occurs when the inference rule
N.2 is applied on a denial with universally quantified variables in the negative literal p(t).
Floundering aborts the derivation.
An answer substitution , derived from a solution state S, is any substitution  of the
free variables in S which satisfies E (i.e. (E) is true) and grounds . Note that, in case
of an abductive theory without abducibles and integrity constraints, computed answers
as defined by Lloyd (1987) are most general unifiers of E and correct answers are answer
substitutions as defined above.
Proposition 10 (Kakas, Van Nuffelen, & Denecker, 2001) Let T = (P, A, IC) be an abductive theory, Q a query, S a solution state of a derivation for Q, and  an answer
substitution of S. Then the pair consisting of the ground abducible atoms ((S)) and of
the answer substitution  is an abductive solution for T and Q.
4.3.2 Constraint Transformation to Denial Form
Since the inference rules of the Asystem are applied only on integrity constraints in denial
form, the integrity constraints IC in the abductive theory T must be translated to this
form. This is done by applying a variant of the Lloyd-Topor transformation (Lloyd &
Topor, 1984) on the integrity constraints (see Denecker & De Schreye, 1998). This is the
same procedure as the well-known procedure used in deductive databases to convert a first
order quantified query Q into a logically equivalent pair of an atomic query and a nonrecursive datalog procedure. The transformation is defined as a rewriting process of sets of
formulae: the initial set is { F |F  IC}, and the transformation is done by applying De
Morgan and various distribution rules. New predicates and rules may be introduced during
the transformation in order to deal with universal quantifications in denials. Below we
illustrate the transformation in the case of the integrity constraints of the running example.
Example 9 Consider the following extension of the integrity constraints of Example 1:
IC = { XY Z (teaches(X, Y )  teaches(X, Z)  Y = Z) ,
X (teacher(X)  Y teaches(Y, X)) }.
Note that in addition to the original integrity constraint of Example 1, here we also demand
that every teacher has to give at least one course.
 Lloyd-Topor transformation on the first integrity constraint:
(1)  X Y Z (teaches(X, Y )  teaches(X, Z)  Y = Z)
(2)  X Y Z (teaches(X, Y )  teaches(X, Z)  Y 6= Z)
(3) X Y Z ( teaches(X, Y )  teaches(X, Z)  Y 6= Z)
 Lloyd-Topor transformation on the second integrity constraint:
(1)  X (teacher(X)  Y teaches(Y, X))
(2) X ( teacher(X)  Y teaches(Y, X))
265

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

(3) X ( teacher(X)  gives courses(X)) where gives courses is defined by:
gives courses(X)  Y teaches(Y, X)
(4) X ( teacher(X)  gives courses(X)), and
gives courses(X)  teaches(Y, X)
4.3.3 Control Strategy
The selection strategy applied during the derivation process is crucial. A Prolog-like selection strategy (left first, depth first) often leads to trashing, because it is blind to other
choices, and it does not result in a global overview of the current state of the computation.
In the development of the Asystem the main focus was on the improvement of the control
strategy. The idea is to apply first those rules that result in a deterministic change of the
state, so that information is propagated. If none of such rules is applicable, then one of
the left over choices is selected. By this strategy, commitment to a choice is suspended
until the moment where no other information can be derived in a deterministic way. This
resembles a CLP-solver, in which the constraints propagate their information as soon as a
choice is made. This propagation can reduce the number of choices to be made and thus
often dramatically increases the performance.
4.3.4 Implementation
In this section we describe the structure of our implementation. Figure 3 shows a layered
view. The upper-most level consists of the specific abductive logic theory of the integration
task, i.e., the database information and the integrity constraints. This layer together with
the composer form the abductive meta-theory (see Section 4.2) that is processed by the
Asystem.

6

DB 1

DB 2



6

DB n

Input

Abductive
Theory

?
6

Composer
?
6

Optimizer

Composing
System

Abductive
System
Asystem (based on SLDNFA)

Sicstus Prolog
?

?

Figure 3: A schematic view of the system components.
266

fiCoherent integration of databases by abductive logic programming

As noted above, the composer consists of a meta-theory for integrating the databases
in a coherent way. It is interpreted here as an abductive theory, in which the abducible
predicates provide the information on how to restore the consistency of the amalgamated
data.
The abductive system (enclosed by dotted lines in Figure 3) consists of three main
components: a finite domain constraint solver (part of Sicstus Prolog), an abductive metainterpreter (described in the previous sections), and an optimizer.
The optimizer is a component that, given a preference criterion on the space of the
solutions, computes only the most-preferred (abductive) solutions. Given such a preference
criterion, this component prunes on the fly those branches of the search tree that lead to
solutions that are worse than others that have already been computed. This is actually a
branch and bound filter on the solutions space, that speeds-up execution and makes sure
that only the desired solutions will be obtained23 . If the preference criterion is a pre-order,
then the optimizer is complete, that is, it can compute all the optimal solutions (more about
this in Section 4.5). Moreover, this is a general-purpose component, and it may be useful
not only for data integration, but also for, e.g., solving planning problems.
4.3.5 Complexity
It is well-known that in general, the task of repairing a database is not tractable, as there
may be an exponential number of different ways of repairing it. Even in cases where integrity constraints are assumed to be single-headed dependencies (Greco & Zumpano, 2000),
checking whether there exists a -repaired database in which a certain query Q is satisfied, is in P2 . Checking if a fact is satisfied by all the -repaired databases is in P2 (see
Greco & Zumpano, 2000). This is not surprising in light of the correspondence between
computations of -minimal repairs and computations of entailment relations defined by
maximally consistent models (see Propositions 58), also known to be on the second level
of the polynomial hierarchy.
A pure upper bound for the Asystem is still unknown, since  to the best of our knowledge  no complexity results on SLDNFA refutation procedure are available.
4.4 Example: A Derivation of Repairs by the Asystem
Consider again Example 9. The corresponding meta-theory (assuming that the Lloyd-Topor
transformation has been applied on it) is given in Figure 4. In this case, and in what follows,
we shall assume that all variables in the denials are universally quantified, and so, in order
to reduce the amount of notations, universal quantifiers are omitted from the denial rules.
We have executed the code of Figure 4, as well as other examples from the literature in
our system. As Theorem 2 in Section 4.5 guarantees, the output in each case is the set of
the most preferred solutions of the corresponding problem. In what follows we demonstrate
23. See also the third item of Note 2 (at the end of Section 4.4).

267

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

db(teacher(n1 ))
db(teacher(n2 ))
db(teacher(n3 ))
db(teaches(c1 ,n1 ))
db(teaches(c2 ,n2 ))
db(teaches(c2 ,n3 ))
 fact(teaches(X,Y))  fact(teaches(X,Z))  (Y 6= Z) (ic1)
 fact(teacher(X))  gives courses(X)
(ic2)
gives courses(X)  fact(teaches(Y,X))
fact(X)  db(X)  retract(X)
fact(X)  insert(X)
 insert(X)  db(X)
 retract(X)  db(X)

(composer-ic1)
(composer-ic2)

Figure 4: A meta-theory for Example 9.
how some of the most preferred solutions for the meta-theory above are computed.
We follow one branch in the refutation tree, starting from the initial state (G0 , ST 0 ),
where the initial set of goals is G0 = {true0 , ic1, ic2, composer-ic1, composer-ic2},
and the initial store is ST 0 = (, , ). Suppose that the first selected formula is
F1 = ic1 =  fact(teaches(X, Y))  fact(teaches(X, Z))  (Y 6= Z).
Then, by D.2,
G1 = G0 \ F1 
{  db(teaches(X, Y))  retract(teaches(X, Y))  fact(teaches(X, Z))  (Y 6= Z),
 insert(teaches(X, Y))  fact(teaches(X, Z))  (Y 6= Z) },
and ST 1 = ST 0 . Now, pick
F2 =  db(teaches(X, Y))  retract(teaches(X, Y))  fact(teaches(X, Z))  (Y 6= Z).
Select db(teaches(X,Y)), unfold all the corresponding atoms in the database, and then,
again by D.2, followed by E.2 and E.3,
G2 = G1 \ F2 
{  retract(teaches(c1 , n1 ))  fact(teaches(c1 , Z))  (n1 6= Z),
 retract(teaches(c2 , n2 ))  fact(teaches(c2 , Z))  (n2 6= Z),
 retract(teaches(c2 , n3 ))  fact(teaches(c2 , Z))  (n3 6= Z) },
268

fiCoherent integration of databases by abductive logic programming

and still ST 2 = ST 1 . Pick then the second denial among the new goals that were added
to G2 . Denote this denial F3 . Since F3 starts with a negated literal, N.2 applies, and the
derivation process splits here to two branches. The second branch contains
G3 = G2 \ F3  {  retract(teaches(c2 , n2 )),  fact(teaches(c2 , Z))  (n2 6= Z) },
and still ST 3 = ST 2 . Choose now the first new goal, i.e.,
F4 =  retract(teaches(c2 , n2 )).
Now, since 3 = , the only option is to add F4 to 3 . Thus, by A.2,
G4 = G3 \ F4 and ST 4 = (, {F4 }, ).
Assume, now, that we take the second new goal of G3 :
F5 =  fact(teaches(c2 , Z))  (n2 6= Z).
Following a similar process of unfolding data as described above, using db(teaches(c2 , n3 )),
we end-up with
 retract(teaches(c2 , n3 ))  (n2 6= n3 ).
Selecting the negative literal (n2 6= n3 ), N.2 applies again. The first branch quickly results in failure after adding (n2 = n3 ) to E. The second branch adds  (n2 = n3 ) and
retract(teaches(c2 , n3 )) to the set of goals. The former one is added to the constraint
store, as (n2 6= n3 ), and simplifies to true. Assume the latter is selected next. Let this be
the i-th step. We have that by now i1 (the set of abducible predicates produced until the
current step) is empty, thus the only option is to abduce retract(teaches(c2 , n3 )). Thus,
by A.1, ST i consists of:
i = {retract(teaches(c2 , n3 ))},

i = {F4 } = { retract(teaches(c2 , n2 ))},

Ei = Ei1 , and
Gi = Gi1 \ {retract(teaches(c2 , n3 ))}  { teaches(c2 , n2 ) = teaches(c2 , n3 )}.
As the last goal is certainly satisfied, ic1 is resolved in this branch.
Now we turn to ic2. So:
Fi+1 = ic2 =  fact(teacher(X))  gives courses(X).
The evaluation of Fi+1 for either x = n1 or x = n2 is successful, so the only interesting case is
when x = n3 . In this case the evaluation leads to the goal gives courses(X). Unfolding this
goal yields that fact(teaches(Y, n3 )) appears in the goal set. In order to satisfy this goal,
it should be resolved either with one of the composers rules (using D.1). The first rule (i.e.,
fact(X)  db(X)  retract(X)) leads to a failure (since retract(teaches(c2 , n3 )) is
already in ), and so the second rule of the composer, fact(X)  insert(X), must be
applied. This leads to the abduction of insert(teaches(Y, n3 )). By ic1, Y 6= c1 and Y 6= c2
is derived24 . Also, composer-ic1 and composer-ic2 are satisfied by the current state,
so eventually the solution state that is reached from the derivation path described here,
24. One can verify that these constraints are indeed detected during the derivations process. We omit the
details here in order to keep this example tractable.

269

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

contains the following sets:
 = {retract(teaches(c2 , n3 )), insert(teaches(Y, n3 ))},
E = {Y 6= c1 , Y 6= c2 },
which means retraction of teaches(c2 , n3 ) and insertion of teaches(Y, n3 ) for some Y 6= c1
and Y 6= c2 . The other solutions are obtained in a similar way.
Note 2 Below are some remarks on the above derivation process.
1. The solution above contains a non-ground abducible predicate. This indeed is the
expected result, since this solution resolves the contradiction with the integrity constraint ic1 by removing the assumption that teacher n3 teaches course c2 . As a result,
teacher n3 does not teach any course. Thus, in order to assure the other integrity constraint (ic2), the solution indicates that n3 must teach some course (other than c1
and c2 ).
2. One possible (and realistic) explanation for the cause of the inconsistency in the
database of Example 9 and Figure 4, is a typographic error. It might happen, for
instance, that c2 was mistakenly typed instead of, say, c3 , in teaches(c2 ,n3 ). In this
case, the database repair computed above pinpoints this possibility (in our case, then,
Y should be equal to c3 )25 . This explanation cannot be explicitly captured, unless
particular repairs with non-ground solutions are constructed, as indeed is the case
here. While some other approaches that have been recently introduced (e.g., Bravo &
Bertossi, 2003; Cali, Lembo, & Rosati, 2003) properly capture cases such as those of
Example 9, to the best of our knowledge, no other application of database integration
has this ability.
3. Once the system finds a solution that corresponds to a goal state Sg = (Gg , ST g ) with
Gg =  and ST g = (g , g , Eg ), the i -optimizer may be used such that whenever a
state S = (Gs , (s , s , Es )) is reached, and |g | < |s |, the corresponding branch of
the tree is pruned26 .
4.5 Soundness and Completeness
In this section we give some soundness and completeness results for the Asystem, and relate
these results to the model-based preferential semantics, considered in Section 3.
In what follows we denote by T an abductive meta-theory (constructed as described
in Section 4.2) for composing n given databases DB 1 , . . . , DB n . Let also ProcALP be some
sound abductive proof procedure for T 27 . The following proposition shows that ProcALP
provides a coherent method for integrating the databases that are represented by T .
Proposition 11 Every abductive solution that is obtained by ProcALP for the query true
on a theory T , is a repair of UDB.
25. The variable Y is free and {Y/c3 } is an answer substitution as it grounds  and satisfies E.
26. As the size of s can only increase along the derivation, the state S cannot lead to a solution that is
better than the one induced by Sg , and so the corresponding branch of the tree can indeed be pruned.
27. That is, ProcALP is a process for computing only the abductive solutions of T , in the sense of Definition 14.

270

fiCoherent integration of databases by abductive logic programming

Proof: By the construction of T it is easy to see that all the conditions that are listed in
Definition 5 are satisfied. Indeed, the first two conditions are assured by the integrity constraints of the composer. The last condition is also met since by the soundness of ProcALP
it produces abductive solutions i for a query true on T . Thus, by the second property
in Definition 14, for every such solution i = (Inserti , Retracti ) we have that P  i |= IC.
Since P contains a data section with all the facts, it follows that D  i |= IC, i.e. every
integrity constraints follows from D  Inserti \ Retracti .
2
As SLDNFA is a sound abductive proof procedure (Denecker & De Schreye, 1998), it
can be taken as the procedure ProcALP , and so Proposition 11 provides a soundness theorem
for the current implementation of the Asystem. When an optimizer is incorporated in the
Asystem, we have the following soundness result for the extended system:
Theorem 1 (Soundness) Every output that is obtained by the query true on T , where
the Asystem is executed with a c -optimizer [respectively, with an i -optimizer], is a c preferred repair [respectively, an i -preferred repair] of UDB.
Proof: Follows from Proposition 11 (since the Asystem is based on SLDNFA which is a
sound abductive proof procedure), and the fact that the c -optimizer prunes paths that
lead to solutions that are not c -preferable. Similar arguments hold for systems with an
i -optimizer.
2
Proposition 12 Suppose that the query true has a finite SLDNFA-tree w.r.t. T . Then
every c -preferred repair and every i -preferred repair of UDB is obtained by running T
in the Asystem.
Outline of proof: The proof that all the abductive solutions with minimal cardinality are
obtained by the system is based on Theorem 10.1 of Denecker & De Schreye, 1998, where it
is shown that SLDNFAo , which is an extension of SLDNFA, aimed for computing solutions
with minimal cardinality, is complete; see Denecker & De Schreye, 1998, Section 10.1, for
further details. Similarly, the proof that all the abductive solutions which are minimal
w.r.t. set inclusion are obtained by the system is based on Theorem 10.2 of Denecker &
De Schreye, 1998, that shows that SLDNFA+ , which is another extension of SLDNFA,
aimed for computing minimal solutions w.r.t. set inclusion, is also complete; see Denecker
& De Schreye, 1998, Section 10.2, for further details.
Now, the Asystem is based on the combination of SLDNFAo and SLDNFA+ . Moreover, as this system does not change the refutation tree (but only controls the way rules
are selected), Theorems 10.1 and 10.2 in Denecker and De Schreye (1998) are applicable
in our case as well. Thus, all the c - and the i -minimal solutions are produced. This in
particular means that every c -preferred repair as well as every i -preferred repair of UDB
is produced by our system.
2
It should be noted that the last proposition does not guarantee that non-preferred repairs
will not be produced (as this is not true in general). However, as the following theorem
shows, the use of an optimizer excludes this possibility.
271

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Theorem 2 (Completeness) In the notations of Proposition 12 and under its assumptions,
the output of the execution of T in the Asystem together with a c -optimizer [respectively,
together with an i -optimizer] is exactly !(UDB, c ) [respectively, !(UDB, i )].
Proof: We shall show the claim for the case of c ; the proof w.r.t. i is similar.
Let (Insert, Retract)  !(UDB, c ). By Proposition 12,  = (Insert, Retract) is one of
the solutions produced by the Asystem for T . Now, during the execution of the system
together with the c -optimizer, the path that corresponds to  cannot be pruned from
the refutation tree, since by our assumption (Insert, Retract) has a minimal cardinality
among the possible solutions, so the pruning condition is not satisfied. Thus  will be
produced by the c -optimized system. For the converse, suppose that (Insert, Retract) is
some repair of UDB that is produced by the c -optimized system. Suppose for a contradiction that (Insert, Retract) 6 !(UDB, c ). By the proof of Proposition 12, there is
some 0 = (Insert0 , Retract0 )  !(UDB, c ) that is constructed by the Asystem for T , and
(Insert0 , Retract0 ) <c (Insert, Retract). But |0 | < ||, and so the c -optimizer would prune
the path of the  solution once its cardinality becomes bigger than |0 |. This contradicts
our assumption that (Insert, Retract) is produced by the c -optimized system.
2
Note 3 The SLDNFA-resolution on which the Asystem is based is an extension of SLDNFresolution (Lloyd, 1987) and coincides with it for logic programs with empty sets of abducible predicates. SLDNF-resolution is complete only if its computation always terminates. SLDNFA inherits this property. This is the reason why the condition of a finite
SLDNFA-tree is imposed in Proposition 12 and Theorem 2. Like SLDNF, the termination
of SLDNFA can be guaranteed by imposing syntactic conditions on the program. We refer
to (Verbaeten, 1999), where some conditions are proposed to guarantee the existence of a
finite SLDNFA-tree.
In the context of our paper, floundering would arise in the presence of unsafe integrity
constraints (e.g., x p(x)). One way to eliminate this problem is to use a unary domain
predicate dom, ranging over the objects of the database, and to add a range for each
quantified variable in the integrity constraints, so that we obtain formulae of the form
x(dom(x)  (x)) and x(dom(x)  (x)).
The following results immediately follow from the propositions above and those of Section 3 (unless explicitly said, the Asystem is without optimizer).
Corollary 1 Suppose that the query true has a finite SLDNFA refutation tree w.r.t. input
theory T . Then:
1. for every output (Insert, Retract) of the Asystem there is a classical model M of IC
s.t. Insert = M t \ D and Retract = D \ M t .
2. for every output (Insert, Retract) of the Asystem there is a 3-valued model N of D IC
s.t. InsertN = Insert and RetractN = Retract.
Corollary 2 In the notations of Corollary 1 and under its assumption, we have that:
272

fiCoherent integration of databases by abductive logic programming

1. for every output (Insert, Retract) that is obtained by running the Asystem together with
an i -optimizer [respectively, together with a c -optimizer], there is an i -maximally
consistent element [respectively, a c -maximally consistent element] N in MU DB s.t.
InsertN = Insert and RetractN = Retract.
2. for every i -maximally consistent element [respectively, c -maximally consistent element] N in MUDB there is a solution (Insert, Retract) that is obtained by running
the Asystem together with an i -optimizer [respectively, together with a c -optimizer]
s.t. Insert = InsertN and Retract = RetractN .
The last corollaries show that the operational semantics, induced by the Asystem, can
also be represented by a preferential semantics, in terms of preferred models of the theory.
The set R(UDB, ) that represents the intended meaning of how to -recover the database
UDB, can therefore be obtained computationally, by the set
{(Insert, Retract) | (Insert, Retract) is an output of the Asystem with an -optimizer},
or, equivalently, it can be described in terms of preferred models of the theory, by the
following set:
{(InsertN , RetractN ) | N is -maximally consistent in MU DB }.
4.6 Handling Specialized Information
The purpose of this section is to demonstrate the potential usage of our system in more
complex scenarios, where various kinds of specialized data are incorporated in the system.
In particular, we briefly consider time information and source identification. We also give
some guidelines on how to extend the system with capabilities of handling these kinds of
information.
4.6.1 Timestamped Information
Many database applications contain temporal information. This kind of data may be divided in two types: time information that is part of the data itself, and time information
that is related to database operations (e.g., records on database update time). Consider,
for instance, birth day(John,15/05/2001)16/05/2001 . Here, Johns date of birth is an instance
of the former type of time information, and the subscripted data that describes the time in
which this fact was added to the database, is an instance of the latter type of time information.
In our approach, timestamp information can be integrated by adding a temporal theory
describing the state of the database at any particular time point. One way of doing so
is by using situation calculus. In this approach a database is described by some initial
information and a history of events performed during the database lifetime (see Reiter,
1995). Here we use a different approach, which is based on event calculus (Kowalski &
Sergot, 1986). The idea is to make a distinction between two kinds of events, add db and
del db, that describe the database modifications, and the composer-driven events insert
273

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

and retract that are used for constructing database repairs. In this view, the extended
composer has the following form:
holds at(P,T)  initially(P)  clipped(0,P,T)
holds at(P,T)  add(P,E)  E<T  clipped(E,P,T)
clipped(E,P,T)  del(P,C)  EC, C<T
add(P,T)
add(P,T)
del(P,T)
del(P,T)






add db(P,T)
insert(P,T)
del db(P,T)
retract(P,T)

 insert(P,T)  retract(P,T)
 insert(P,T)  add db(P,T)
 retract(P,T)  del db(P,T)
Note that in the above extended representation, the integrity constraints must be carefully specified. Consider, e.g. the statement that a person can be born only on one date:
 holds at(birth day(P,D1),T)  holds at(birth day(P,D2),T)  D16=D2
The problem here is that to ensure consistency, this constraint must be checked at every
point in time. This may be avoided by a simple rewriting that ensures that the constraint
will be verified only when an event for that person occurs:
ic(P,T)  holds at(birth day(P,D1),T)  holds at(birth day(P,D2),T)  D16=D2
 add db(birth day(P, ),T)  NT = T+1  ic(P,NT)
 insert(birth day(P, ),T)  NT = T+1  ic(P,NT)
 ic(P,0)
Note 4 In the last example we have used temporal integrity constraints in order to resolve
contradicting update events. Clearly, contradicting events do not necessarily yield a classically inconsistent database, and so the role of such integrity constraints is to express possible
events in terms of time and causation, and  if necessary  describe their consequence as a
violation of consistency.
Instead of using temporal integrity constraints and event calculus, one could repair
a database with time-stamps by using some time-based criterion for making preferences
among its repairs. For instance, denote by db(x1 , . . . , xn )t that the data-fact db(x1 , . . . , xn )
has a timestamp t, and suppose that (Insert, Retract) and (Insert0 , Retract0 ) are two repairs of a database (D, IC). A time-based criterion for preferring (Insert, Retract) over
(Insert0 , Retract0 ) could state, e.g., that for every data-fact db(x1 , . . . , xn ) and timestamps
t1 , t2 s.t. db(x1 , . . . , xn )t1 follows from D  Insert \ Retract and db(x1 , . . . , xn )t2 follows from
D  Insert0 \ Retract0 , necessarily t1  t2 . A more detailed treatment of this issue is outside
the scope of this paper.
The interested reader may refer, e.g., to (Sripada, 1995; Mareco & Bertossi, 1999) for a
detailed discussion on the use of logic programming based approaches to the specification
of temporal databases. Such specifications can be easily combined with those for repairs,
given above.
274

fiCoherent integration of databases by abductive logic programming

4.6.2 Keeping Track of Source Identities
There are cases in which it is important to preserve the identity of the database from which
a specific piece of information was originated. This is useful, for instance, when one wants
to make preferences among different sources, or when some specific source should be filtered out (e.g, when the corresponding database is not available or becomes unreliable).
This kind of information may be decoded by adding another argument to every fact, which
denotes the identity of its origin. This requires minor modifications in the basic composer,
since the composer controls the way in which the data is integrated. As such, it is the only
component that can keep track on the source of the information.
Suppose, then, that for every database fact we add another argument that identifies its
source. I.e., db(X,S) denotes that X is a fact originated from a database S. The composer
then has the following form:
fact(X,S)  db(X,S)  retract(X)
fact(X,composer)  insert(X)
 insert(X)  db(X,S)
 retract(X)  db(X,S)
Note that the composer considers itself as an extra source that inserts brand new data
facts. Now it is possible, e.g., to trace information that comes from a specific source, make
preferences among different sources (by specifying appropriate integrity constraints), and
filter data that comes from certain sources. The last property is demonstrated by the next
rule:
validFact(X)  fact(X,S)  trusted source(S)
where trusted source enumerates all reliable sources of the data.
Note that the last example of source identification can be further extended in order to
make preferences among different sources (and not only ignoring some unreliable sources).
By introducing a new predicate, trust(Source,Amount), that attaches a certain level of
reliability to each source, it is possible, in case of conflicts, to prefer sources with higher
reliability as follows:
 fact(X,S)  db(X,S0 )  S 6= S0  more trusted(S0 ,S)
more trusted(S0 ,S)  trust(S0 ,A0 )  trust(S,A)  A0 > A
This method is particularly useful when the integrity constraint above acts as a functional dependency on specific facts. The following example (originally introduced in Subrahmanian, 1994) demonstrates this.
Example 10 Consider the following simple scenario of target recognition, where three
sensors of an autonomous vehicle, which have different degrees of reliability, should identify
objects in the vehicles neighborhood:
trust(radar,10)
trust(gunchar,8)
275

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

trust(speedometer,5)
db(observe(object1,t72),radar)
db(observe(object1,t60),gunchar)
db(observe(object1,t80),speedometer)
 fact(observe(O,V1 ),S)  db(observe(O,V2 ),S0 )  S6=S0  more trusted(S0 ,S)
As the radar has the highest reliability, its observation will be preserved. The observations of the other sensors will be retracted from the database.

5. Discussion and an Overview of Related Works
The interest in systems for coherent integration of databases has been continuously growing
in the last few years (see, e.g, Olive, 1991; Baral et al., 1991, 1992; Revesz, 1993; Subrahmanian, 1994; Bry, 1997; Gertz & Lipeck, 1997; Messing, 1997; Lin & Mendelzon, 1998;
Liberatore & Schaerf, 2000; Ullman, 2000; Greco & Zumpano, 2000; Greco et al., 2001;
Franconi et al., 2001; Lenzerini, 2001, 2002; Arenas et al., 1999, 2003; Bravo & Bertossi,
2003; Cali et al., 2003, and many others). Already in the early works on this subject it became clear that the design of systems for data integration is a complex task, which demands
solutions to many questions from different disciplines, such as belief revision, merging and
updating, reasoning with inconsistent information, constraint enforcement, query processing and  of course  many aspects of knowledge representation. In this section we shall
address some of these issues.
One important aspect of data integration systems is how concepts in the independent
(stand-alone) data-sources and those of the unified database are mapped to each other.
A proper specification of the relations between the source schemas and the schema of the
amalgamated data exempts the potential user from being aware where and how data is
arranged in the sources. One approach for this mapping, sometimes called global-centric
or global-as-view (Ullman, 2000), requires that the unified schema should be expressed in
terms of the local schemas. In this approach, every term in the unified schema is associated
with a view (alternatively, a query) over the sources. This approach is taken by most of the
systems for data integration, as well as ours. The main advantage of this approach is that
it induces a simple query processing strategy that is based on unfolding of the query, and
uses the same terminology as that of the databases. This indeed is the case in the abductive
derivation process, defined in Section 4.3.1. The other approach, sometimes called sourcecentric or local-as-view (used, e.g., in Bertossi et al., 2002), considers every source as a view
over the integrated database, and so the meaning of every source is obtained by concepts
of the global database. In particular, the global schema is independent of the distributed
ones. This implies, in particular, that an addition of a new source to the system requires
only to provide local definitions and not necessarily involves changes in the global schema.
The main advantage of the latter approach is, therefore, that it provides a better setting for
maintenance. For a detailed discussion on this topic, see (Ullman, 2000; Lenzerini, 2001;
Cali et al., 2002; Van Nuffelen et al., 2004). More references and a survey on different approaches to data integration appear in the papers of Batini, Lenzerini, and Navathe (1986),
276

fiCoherent integration of databases by abductive logic programming

Rahm and Bernstein (2001), and Lenzerini (2002).
Another major issue that has to be addressed is the ability of data integration systems
to properly cope with dynamically evolving worlds. In particular, the domain of discourse
should not be fixed in advance, and information may be revised on a regular basis. The last
issue is usually handled by methods of belief revision (Alchourron et al., 1995; Gardenfors &
Rott, 1995) and nonmonotonic reasoning. In the context of belief revision it is common to
make a distinction between revisions of integrity constraints and changes in the sets of the
data-facts, since the two types of information have different nature and thus may require
different approaches for handling dynamic changes. When the set of integrity constraints
is given in a clause form, methods of dynamic logic programing (Alferes et al., 2000, 2002)
may be useful for handling revisions. As noted in (Alferes et al., 2002), assuming that each
local database is consistent (as in our case), dynamic logic programing (together with a
proper language for implementing it, like LUPS (Alferes et al., 2002)) provides a way of
avoiding contradictory information, and so this may be viewed as a method of updating a
database by a sequence of integrity constraints that arrive at different time points.
When the types of changes are predictable, or can be characterized in some sense, temporal integrity constraints (in the context of temporal databases) can be used in order to
specify how to treat new information. This method is also useful when the revision criteria
are known in advance (e.g., in case of collisions, prefer the more recent data, cf. Section
4.6.1). See, e.g., (Sripada, 1995; Mareco & Bertossi, 1999) for a detailed discussion on temporal integrity constraints and temporal databases in a logic programming based formalisms.
The second type of revisions (i.e., modifications of data-facts) is obtained here through
the (preferred) repairs of the unified database, which induce corresponding modifications of
data-facts. A repair is usually induced by a method of restoring (or assuring) consistency of
the amalgamated database by a minimal amount of change. As in our case, the minimization
criterion is often determined by the aspiration to remain as close as possible to the set of
the collective information. This is a typical kind of a repair goal , and the standard ways of
formally expressing it are by enumeration methods, such as the following28 :
 Minimizing the Hamming distance between the (propositional) models of the unified
database and its repairs (Liberatore & Schaerf, 2000), or minimizing the distance between the corresponding three-valued interpretations (de Amo et al., 2002) according
to a suitable generalization of Hamming distance.
 Minimizing the symmetric distance between the sets of consequences of the corresponding databases (Arenas, Bertossi, & Chomicki, 1999; Arenas, Bertossi, & Kifer,
2000; Bertossi, Chomicki, Cortes, & Gutierrez, 2002) or, equivalently, minimizations
in terms of set inclusion (Greco & Zumpano, 2000).
 When the underlying data is prioritized, the corresponding quantitative information
is also considered in the computations of distances (see, for instance, the work of
Liberatore & Schaerf, 2000).
28. See also (Gertz & Lipeck, 1997, Section 5) for a discussion on repair strategies.

277

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Various ways of computing (preferred/minimal) repairs are described in the literature,
among which are proof-theoretical (deductive) methods (Bertossi & Schwind, 2002; de Amo
et al., 2002), abductive methods (Kakas & Mancarella, 1990a; Inoue & Sakama, 1995;
Sakama & Inoue, 1999, 2000), and algorithmic approaches that are based on computations
of maximal consistent subsets (Baral et al., 1991, 1992), or use techniques from model-based
diagnosis (Gertz & Lipeck, 1997). A common approach is to view a database as a logic
program, and to adopt standard techniques of giving semantics to logic programs in order to compute database repairs. For instance, stable-model semantics on disjunctive logic
programs is used for computing repairs in (Greco & Zumpano, 2000; Greco et al., 2001;
Franconi et al., 2001; Arenas et al., 2003), and resolution-based procedures for integrating
several annotated databases are introduced by Subrahmanian (1990, 1994). As it follows
from Section 4, the application introduced here is also based on an extended resolution
strategy, applied on logic programs that may contain negation-as-failure operators and abducible predicates.
As repairing a database means in particular elimination of contradictions, reasoning with
inconsistent information has been a major challenge for data integration systems. First, it
is important to note in this respect that not every formalism for handling inconsistency
is acceptable in the context of databases, even if the underlying criterion for handling
inconsistency is the same as one of the repair goals mentioned above. The following example
demonstrates such a case:
Example 11 (Arenas, Bertossi, & Chomicki, 1999) Consider the following (inconsistent)
database: DB = ({p, q}, {(p  q)}). In the approach of Lin (1996), for instance, p  q
may be inferred as the repaired database, following a strategy of minimal change. However,
in this approach none of p, q, and (p  q) holds in the repaired database. In particular
(since in (Lin, 1996) there is no distinction between data-facts and integrity constraints),
the integrity constraint {(p  q)} itself cannot be inferred, which violates the intended
meaning of an integrity constraint in databases.
Many techniques for consistency enforcement and repairs of constraint violations have
been suggested, among which are methods for resolving contradictions by quantitative considerations, such as majority vote (Lin & Mendelzon, 1998; Konieczny & Pino Perez, 2002)
or qualitative ones (e.g., defining priorities on different sources of information or preferring
certain data over another, as in Benferhat, Cayrol, Dubois, Lang, & Prade, 1993, and Arieli,
1999). Another common method of handling inconsistent (and incomplete) information is
by turning to multi-valued semantics. Three-valued formalisms such as the one considered
in Section 3 are used as a semantical basis of paraconsistent methods to construct database
repairs (de Amo, Carnielli, & Marcos, 2002) and are useful in general for pinpointing inconsistencies (Priest, 1991). Other approaches use lattice-based semantics to decode within
the language itself some meta-information, such as confidence factors, amount of belief for
or against a specific assertion, etc. These approaches combine corresponding formalisms of
knowledge representation, such as annotated logic programs (Subrahmanian, 1990, 1994;
Arenas et al., 2000) or bilattice-based logics (Fitting, 1991; Arieli & Avron, 1996; Messing, 1997), together with non-classical refutation procedures (Fitting, 1989; Subrahmanian,
278

fiCoherent integration of databases by abductive logic programming

1990; Kifer & Lozinskii, 1992) that allow to detect inconsistent parts of a database and
maintain them.

6. Summary and Future Work
In this paper we have developed a formal declarative foundation for rendering coherent
data, provided by different databases, and presented an application that implements this
approach. Like similar applications (e.g., Subrahmanian, 1994; Bertossi, Arenas, & Ferretti,
1998; Greco & Zumpano, 2000; Liberatore & Schaerf, 2000), our system mediates among
the sources of information and also between the reasoner and the underlying data.
Composition of several data-sources is encoded by meta-theories in the form of abductive
logic programs, and it is possible to extend these theories by providing meta-information
on the data-facts, such as time-stamps and source identities. Moreover, since the reasoning
process of the system is based on a pure generalization of classical refutation procedures,
no syntactical embedding of first-order formulae into other languages, nor any extension of
two-valued semantics, is necessary.
Due the inherent modularity of the system, each component is independent and can be
modified to meet different needs. Thus, for instance, the underlying solver may be replaced
with any other solver that is capable of dealing with the meta-theory, and any improvement
of the optimizer will affect the whole system and its efficiency, regardless the nature of
its input. Also, the way of keeping data coherent is encapsulated in the component that
integrates the data (i.e., the composer). This implies, in particular, that no input from the
reasoner nor any other external policy for making preferences among conflicting sources is
compulsory in order to resolve contradictions.
As we have shown, the operational semantics for inconsistent databases, induced by
the Asystem, is strongly related to (multi-valued) preferential semantics. As preferential
semantics provides the background for many non-monotonic and paraconsistent formalisms
(e.g., Shoham, 1988; Priest, 1989, 1991; Kifer & Lozinskii, 1992; Arieli & Avron, 1996;
Arieli, 1999, 2003), this implies that the Asystem may be useful for reasoning with general
uncertain theories (not necessarily in the form of databases).
It is important to note that our composing system inherits the functionality of the
underlying solver. The outcome of this is flexibility, modularity, simple interaction with
different sources of information, and the ability to reason with any set of first-order formulae of integrity constraints29 . To the best of our knowledge no other application of data
integration has this ability.
There are several directions for further exploration. First, as we have already noted, two
more phases, which have not been considered here, might be needed for a complete process
of data integration:
29. Provided, of-course, that the constraints do not lead to floundering.

279

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

a) translation of difference concepts to a unified ontology, and
b) integration of integrity constraints.
So far, formalisms for dealing with the first item (e.g., Lenzerini, 2001, 2002; Van Nuffelen
et al., 2004) mainly focus on the mutual relations between the global schema and the source
(local) schemas, in particular how concepts of each ontology map to each other. On the
other hand, formalisms for handling the second item concentrate on nonmonotonic reasoning for dynamically evolving (and mutually inconsistent) worlds. A synthesis of the main
ideas behind these approaches, and incorporating them in our system, is a major challenge
for future work.
Another important issue that deserves attention is the repair of inconsistency in the
context of deductive databases with integrity constraints and definitions of predicates, often called view predicates. We refer to (Denecker, 2000) for a sketch on how this may be
done. This kind of data may be further combined with (possibly inconsistent) temporal
information, (partial) transactions, and (contradictory) update information.
Finally, since different databases may have different information about the same predicates, it is reasonable to use some weakened version of the closed word assumption as part
of the integration process (for instance, an assumption that something is false unless it is
in the database, or unless some other database has some information about it).

Acknowledgements
We would like to thank the anonymous reviewers for many helpful comments and suggestions. This research was supported by the Research Fund K.U.Leuven and by FWO
Vlaanderen.

References
Alchourron, C. E., Gardenfors, P., & Makinson, D. (1995). On the logic of theory change:
Partial meet contraction and revision function. Journal of Symbolic Logic, 50, 510
530.
Alferes, J. J., Leite, J. A., Pereira, L. M., & Quaresma, P. (2000). Planning as abductive updating. In Proc. of the Symposium on AI Planning and Intelligent Agents (AISB00),
pp. 18.
Alferes, J. J., Pereira, L. M., Przymusinska, H., & Przymusinski, T. C. (2002). LUPS  a
language for updating logic programs. Artificial Intelligence, 138 (12), 87116.
Arenas, M., Bertossi, L., & Chomicki, J. (1999). Consistent query answers in inconsistent
databases. In Proc. 18th ACM Symp. on Principles of Database Systems (PODS99),
pp. 6879.
Arenas, M., Bertossi, L., & Chomicki, J. (2003). Answer sets for consistent query answering
in inconsistent databases. Theory and Practice of Logic Programming, 3 (45), 393
424.
280

fiCoherent integration of databases by abductive logic programming

Arenas, M., Bertossi, L., & Kifer, M. (2000). Applications of annotated predicate calculus
to querying inconsistent databases. In Lloyd, J., et al. (Eds.), Proc. 1st Int. Conf. on
Computational Logic (CL2000), No. 1861 in LNAI, pp. 926941. Springer.
Arieli, O. (1999). Four-valued logics for reasoning with uncertainty in prioritized data. In
Bouchon-Meunier, B., Yager, R. R., & Zadeh, L. (Eds.), Information, Uncertainty,
Fusion, pp. 263309. Kluwer.
Arieli, O. (2003). Reasoning with different levels of uncertainty. Journal of Applied NonClassical Logics, 13 (34), 317343.
Arieli, O., & Avron, A. (1996). Reasoning with logical bilattices. Journal of Logic, Language,
and Information, 5 (1), 2563.
Arieli, O., & Avron, A. (1999). A model theoretic approach to recover consistent data from
inconsistent knowledge-bases. Journal of Automated Reasoning, 22 (3), 263309.
Arieli, O., Denecker, M., Van Nuffelen, B., & Bruynooghe, M. (2002). Repairing inconsistent
databases: A model-theoretic approach and abductive reasoning. In Proc. ICLP02
Workshop on Paraconsistent Computational Logic (PCL02), Federated Logic Conference (FLOC02), pp. 5165.
Arieli, O., Denecker, M., Van Nuffelen, B., & Bruynooghe, M. (2004). Database repair by
signed formulae. In Seipel, D., & Turell-Torres, J. (Eds.), Proc. 3rd Int. Symp. on
Foundations of Information and Knowledge Systems (FoIKS04), No. 2942 in LNCS,
pp. 1430. Springer.
Arieli, O., Van Nuffelen, B., Denecker, M., & Bruynooghe, M. (2001). Coherent composition
of distributed knowledge-bases through abduction. In Nieuwenhuis, A., & Voronkov,
A. (Eds.), Proc. 8th Int. Conf. on Logic Programming, Artificial Intelligence and Reasoning (LPAR01), No. 2250 in LNCS, pp. 620635. Springer.
Avron, A. (2002). Classical gentzen-type methods in propositional many-valued logics.
In Fitting, M., & Orlowska, E. (Eds.), Theory and Applications in Multiple-Valued
Logics, pp. 113151. Springer.
Baral, C., Kraus, S., & Minker, J. (1991). Combining multiple knowledge bases. IEEE
Trans. on Knowledge and Data Enginnering, 3 (2), 208220.
Baral, C., Kraus, S., Minker, J., & Subrahmanain, V. S. (1992). Combining multiple knowledge bases consisting of first order theories. Computational Intelligence, 8, 4571.
Batini, C., Lenzerini, M., & Navathe, S. B. (1986). A comparative analysis of methodologies
for database schema integration. ACM Computing Surveys, 18 (4), 323364.
Belnap, N. D. (1977). How a computer should think. In Ryle, G. (Ed.), Contemporary
Aspects of Philosophy, pp. 3056. Oriel Press.
Benferhat, S., Cayrol, C., Dubois, D., Lang, J., & Prade, H. (1993). Inconsistency management and prioritized syntax-based entailment. In Proc. 13th Int. Joint Conf. on
Artificial Intelligence (IJCAI93), pp. 640645.
Benferhat, S., Dubois, D., & Prade, H. (1995). How to infer from inconsistent beliefs without
revising?. In Proc. 14th Int. Joint Conf. on Artificial Intelligence (IJCAI95), pp.
14491455.
281

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Bertossi, L., Arenas, M., & Ferretti, C. (1998). SCDBR: An automated reasoner for specifications of database updates. Intelligent Information Systems, 10 (3), 253280.
Bertossi, L., Chomicki, J., Cortes, A., & Gutierrez, C. (2002). Consistent answers from integrated data sources. In Andreasen, A., et al. (Eds.), Proc. Flexible Query Answering
Systems (FQAS2002), No. 2522 in LNCS, pp. 7185. Springer.
Bertossi, L., & Schwind, C. (2002). Analytic tableau and database repairs: Foundations.
In Proc. 2nd Int. Symp. on Foundations of Information and Knowledge Systems
(FoIKS02), No. 2284 in LNCS, pp. 3248. Springer.
Bravo, L., & Bertossi, L. (2003). Logic programming for consistently querying data integration systems. In Gottlob, G., & Walsh, T. (Eds.), Proc. Int. Jont Conf. on Artificial
Intelligence (IJCAI03), pp. 1015.
Bry, F. (1997). Query answering in information systems with integrity constraints. In Proc.
Int. Conf. on Integrity and Control in Information Systems (IICIS97), pp. 113130.
Cali, A., Calvanese, D., De Giacomo, G., & Lenzerini, M. (2002). Data integration under
integrity constraints. In Proc. 14th Conf. on Advanced Information Systems Engineering (CAiSE 2002), pp. 262279.
Cali, A., Lembo, D., & Rosati, R. (2003). Query rewriting and answering under constraints
in data integration systems. In Gottlob, G., & Walsh, T. (Eds.), Proc. Int. Jont Conf.
on Artificial Intelligence (IJCAI03), pp. 1621.
Carnielli, W. A., & Marcos, J. (2001). Tableau systems for logics of formal inconsistency.
In Proc. Int. Conf. on Artificial Intelligence (IC-AI01), Vol. II, pp. 848852. CSREA
Press.
Carnielli, W. A., & Marcos, J. (2002). A taxonomy of C-systems. In Carnielli, W. A.,
Coniglio, M. E., & DOttaviano, I. M. (Eds.), Paraconsistency  The Logical Way
to the Inconsistent, No. 228 in Lecture Notes in Pure and Applied Mathematics, pp.
194. Marcel Dekker.
Console, L., Theseider Dupre, D., & Torasso, P. (1991). On the relationship between abduction and deduction. Journal of Logic and Computation, 1 (5), 661690.
Dalal, M. (1988). Investigations into a theory of knowledge base revision. In Proc. National
Conference on Artificial Intelligence (AAAI98), pp. 475479. AAAI Press.
de Amo, S., Carnielli, W. A., & Marcos, J. (2002). A logical framework for integrating inconsistent information in multiple databases. In Proc. 2nd Int. Symp. on Foundations
of Information and Knowledge Systems (FoIKS02), No. 2284 in LNCS, pp. 6784.
Springer.
Decker, H. (2003). Historical and computational aspects of paraconsistency in view of the
logic foundations of databases. In Proc. Semantics in Databases, No. 2582 in LNCS,
pp. 6381. Springer.
Denecker, M. (2000). Extending classical logic with inductive definitions. In Lloyd, J., et al.
(Eds.), Proc. 1st Int. Conf. on Computational Logic (CL2000), No. 1861 in LNAI,
pp. 703717. Springer.
282

fiCoherent integration of databases by abductive logic programming

Denecker, M., & De Schreye, D. (1992). SLDNFA an abductive procedure for normal
abductive programs. In Apt, K. R. (Ed.), Proc. Int. Joint Conf. and Symp. on Logic
Programming, pp. 686700. MIT Press.
Denecker, M., & De Schreye, D. (1993). Justification semantics: a unifying framework for the
semantics of logic programs. In Proc. of the Logic Programming and Nonmonotonic
Reasoning Workshop, pp. 365379. MIT Press.
Denecker, M., & De Schreye, D. (1998). SLDNFA an abductive procedure for abductive
logic programs. Journal of Logic Programming, 34 (2), 111167.
Denecker, M., & Kakas, A. C. (2000). Abductive Logic Programming. A special issue of the
Journal of Logic Programming, Vol.44(13).
Fitting, M. (1989). Negation as refutation. In Proc. 4th Annual Symp. on Logic in Computer
Science (LICS89), pp. 6370. IEEE Press.
Fitting, M. (1990). Kleenes logic, generalized. Journal of Logic and Computation, 1, 797
810.
Fitting, M. (1991). Bilattices and the semantics of logic programming. Journal of Logic
Programming, 11 (2), 91116.
Franconi, E., Palma, A. L., Leone, N., Perri, D., & Scarcello, F. (2001). Census data repair:
A challenging application of disjunctive logic programming. In Nieuwenhius, A., &
Voronkov, A. (Eds.), Proc. 8th Int. Conf. on Logic Programming, Artificial Intelligence
and Reasoning (LPAR01), No. 2250 in LNCS, pp. 561578. Springer.
Gardenfors, P., & Rott, H. (1995). Belief revision. In Gabbay, D. M., Hogger, J., & Robinson,
J. A. (Eds.), Handbook of Logic in Artificial Intelligence and Logic Programming, pp.
35132. Oxford University Press.
Gertz, M., & Lipeck, U. W. (1997). An extensible framework for repairing constraint violations. In Proc. Int. Conf. on Integrity and Control in Information Systems (IICIS97),
pp. 89111.
Ginsberg, M. L. (1988). Multi-valued logics: A uniform approach to reasoning in AI. Computer Intelligence, 4, 256316.
Greco, G., Greco, S., & Zumpano, E. (2001). A logic programming approach to the integration, repairing and querying of inconsistent databases. In Proc. 17th Int. Conf. on
Logic Programming (ICLP01), No. 2237 in LNCS, pp. 348363. Springer.
Greco, S., & Zumpano, E. (2000). Querying inconsistent databases. In Proc. Int. Conf. on
Logic Programming and Automated Reasoning (LPAR2000), No. 1955 in LNAI, pp.
308325. Springer.
Inoue, K., & Sakama, C. (1995). Abductive framework for nonmonotonic theory change. In
Proc. 14th Int. Joint Conf. on Artificial Intelligence (IJCAI95), pp. 204210.
Kakas, A., Kowalski, R. A., & Toni, F. (1992). Abductive logic programming. Journal of
Logic and Computation, 2 (6), 719770.
Kakas, A., & Mancarella, P. (1990a). Database updates through abduction. In Proc. 16th
Int. Conf. on Very Large Data Bases (VLDB90), pp. 650661.
283

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Kakas, A., & Mancarella, P. (1990b). Generalised stable models: A semantics for abduction.
In Proc. of the European Conference on Artificial Intelligence (ECAI90), pp. 385391.
John Wiley and sons.
Kakas, A., Michael, A., & Mourlas, C. (2000). ACLP: Abductive constraint logic programming. Journal of Logic Programming, 44 (13), 129177.
Kakas, A., Van Nuffelen, B., & Denecker, M. (2001). A-System: Problem solving through
abduction. In Proc. 17th Int. Joint Conf. on Artificial Intelligence (IJCAI01), pp.
591596. Morgan Kaufmann Publishers.
Kifer, M., & Lozinskii, E. L. (1992). A logic for reasoning with inconsistency. Journal of
Automated Reasoning, 9 (2), 179215.
Konieczny, S., & Pino Perez, R. (2002). Merging information under constraints: A logical
farmework. Journal of Logic and Computation, 12 (5), 773808.
Kowalski, R. A., & Sergot, M. J. (1986). A logic-based calculus of events. New Generation
Computing, 4 (1), 6795. Reprinted in Foundations of Knowledge Base Management
Systems (1989), pp. 2353. Springer-Verlag.
Lenzerini, M. (2001). Data integration needs reasoning. In Eiter, T., Faber, W., &
Truszczynski, T. (Eds.), Proc Int. Conf. on Logic Programming and Non-Monotonic
Reasoning (LPNMR01), No. 2173 in LNAI, pp. 5461. Springer.
Lenzerini, M. (2002). Data integration: A theoretical perspective. In Proc. ACM Symp. on
Principles of Database Systems (PODS02), pp. 233246.
Liberatore, P., & Schaerf, M. (2000). BReLS: A system for the integration of knowledge
bases. In Proc Int. Conf. on Principles of Knowledge Representation and Reasoning
(KR2000), pp. 145152. Morgan Kaufmann Publishers.
Lin, J. (1996). A semantics for reasoning consistently in the presence of inconsistency.
Artificial Intelligence, 86 (1), 7595.
Lin, J., & Mendelzon, A. (1998). Merging databases under constraints. Int. Journal of
Cooperative Information Systems, 7 (1), 5576.
Lloyd, J. W. (1987). Foundations of Logic Programming. Springer-Verlag.
Lloyd, J. W., & Topor, R. W. (1984). Making Prolog more expressive. Journal of Logic
Programming, 1 (3), 225240.
Mareco, C. A., & Bertossi, L. (1999). Specification and implementation of temporal
databases in a bitemporal event calculus. In Advance in Conceptual Modeling, No.
1727 in LNCS, pp. 7485. Springer.
Martelli, A., & Montanari, U. (1982). An efficient unification algorithm. ACM Trans. on
Programming Languages and Systems, 4 (2), 258282.
Messing, B. (1997). Combining knowledge with many-valued logics. Data and Knowledge
Engineering, 23, 297315.
Olive, A. (1991). Integrity checking in deductive databases. In Proc. 17th Int. Conf. on
Very Large Data Bases (VLDB91), pp. 513523.
284

fiCoherent integration of databases by abductive logic programming

Pereira, L. M., Aparicio, J. N., & Alferes, J. J. (1991). Hypothetical reasoning with well
founded semantics. In Proc. 3th Scandinavian Conference on AI, pp. 289300. IOS
Press.
Priest, G. (1989). Reasoning about truth. Artificial Intelligence, 39, 231244.
Priest, G. (1991). Minimally inconsistent LP. Studia Logica, 50, 321331.
Rahm, E., & Bernstein, P. (2001). A survey of approaches to automatic schema matching.
VLDB Journal, 10 (4), 334350.
Reiter, R. (1995). On specifying database updates. Journal of Logic Programming, 25 (1),
5391.
Revesz, P. Z. (1993). On the semantics of theory change: Arbitration between old and new
information. In Proc. 12th ACM Symp. on Principles of Database Systems (PODS93),
pp. 7182.
Sakama, C., & Inoue, K. (1999). Updating extended logic programs through abduction.
In Proc 5th Int. Conf. on Logic Programming and Non-Monotonic Reasoning (LPNMR99), pp. 147161.
Sakama, C., & Inoue, K. (2000). Abductive logic programming and disjunctive logic programming: their relationship and transferability. Journal of Logic Programming, 44 (1
3), 75100.
Shoham, Y. (1988). Reasoning about change: time and causation from the standpoint of
artificial intelligence. MIT Press.
Sripada, S. M. (1995). Efficient implementation of the event calculus for temporal database
applications. In Proc. Int. Conf. on Logic Programming (ICLP95), pp. 99113.
Subrahmanian, V. S. (1990). Mechanical proof procedures for many valued lattice-based
logic programming. Journal of Non-Classical Logic, 7, 741.
Subrahmanian, V. S. (1994). Amalgamating knowledge-bases. ACM Trans. on Database
Systems, 19 (2), 291331.
Ullman, J. (2000). Information integration using logical views. Theoretical Computer Science, 239 (2), 189210.
Van Nuffelen, B., Cortes, A., Denecker, M., Arieli, O., & Bruynooghe, M. (2004). Data
integration using ID-logic. In Proc. 16th Int. Conf. on Advanced Information Systems
Engineering (CAiSE04), LNCS. Springer. To appear.
Van Nuffelen, B., & Kakas, A. (2001). A-system: Declarative programming with abduction. In Proc. Int. Conf. on Logic Programming and Non-Monotonic Reasoning (LPNMR01), No. 2173 in LNAI, pp. 393396. Springer.
Verbaeten, S. (1999). Termination analysis for abductive general logic programs. In De Schreye, D. (Ed.), Proc. Int. Conf. on Logic Programming (ICLP99), pp. 365379. MIT
Press.
Verbaeten, S., Denecker, M., & De Schreye, D. (1997). Compositionality of normal open logic
programs. In Maluszynski, J. (Ed.), Proc. Int. Logic Programming Symp. (ILPS97),
pp. 371386. MIT Press.
285

fiArieli, Denecker, Van Nuffelen, & Bruynooghe

Verbaeten, S., Denecker, M., & De Schreye, D. (2000). Compositionality of normal open
logic programs. Journal of Logic Programming, 41 (3), 151183.
Winslett, M. (1988). Reasoning about action using a possible models approach. In Proc.
National Conference on Artificial Intelligence (AAAI98), pp. 8993. AAAI press.

286

fiJournal of Artificial Intelligence Research 21 (2004) 63-100

Submitted 8/03; published 2/04

Competitive Coevolution through Evolutionary
Complexification
Kenneth O. Stanley
Risto Miikkulainen

kstanley@cs.utexas.edu
risto@cs.utexas.edu

Department of Computer Sciences
The University of Texas at Austin
Austin, TX 78712 USA

Abstract
Two major goals in machine learning are the discovery and improvement of solutions to
complex problems. In this paper, we argue that complexification, i.e. the incremental elaboration of solutions through adding new structure, achieves both these goals. We demonstrate the power of complexification through the NeuroEvolution of Augmenting Topologies
(NEAT) method, which evolves increasingly complex neural network architectures. NEAT
is applied to an open-ended coevolutionary robot duel domain where robot controllers compete head to head. Because the robot duel domain supports a wide range of strategies, and
because coevolution benefits from an escalating arms race, it serves as a suitable testbed for
studying complexification. When compared to the evolution of networks with fixed structure, complexifying evolution discovers significantly more sophisticated strategies. The
results suggest that in order to discover and improve complex solutions, evolution, and
search in general, should be allowed to complexify as well as optimize.

1. Introduction
Evolutionary Computation (EC) is a class of algorithms that can be applied to open-ended
learning problems in Artificial Intelligence. Traditionally, such algorithms evolve fixedlength genomes under the assumption that the space of the genome is sufficient to encode
the solution. A genome containing n genes encodes a single point in an n-dimensional search
space. In many cases, a solution is known to exist somewhere in that space. For example,
the global maximum of a function of three arguments must exist in the three dimensional
space defined by those arguments. Thus, a genome of three genes can encode the location
of the maximum.
However, many common structures are defined by an indefinite number of parameters.
In particular, those solution types that can contain a variable number of parts can be
represented by any number of parameters above some minimum. For example, the number
of parts in neural networks, cellular automata, and electronic circuits can vary (Miller, Job,
& Vassilev, 2000a; Mitchell, Crutchfield, & Das, 1996; Stanley & Miikkulainen, 2002d). In
fact, theoretically two neural networks with different numbers of connections and nodes can
represent the same function (Cybenko, 1989). Thus, it is not clear what number of genes is
appropriate for solving a particular problem. Researchers evolving fixed-length genotypes
must use heuristics to estimate a priori the appropriate number of genes to encode such
structures.

c
2004
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiStanley & Miikkulainen

A major obstacle to using fixed-length encodings is that heuristically determining the
appropriate number of genes becomes impossible for very complex problems. For example,
how many nodes and connections are necessary for a neural network that controls a pingpong playing robot? Or, how many bits are needed in the neighborhood function of a
cellular automaton that performs information compression? The answers to these questions
can hardly be based on empirical experience or analytic methods, since little is known
about the solutions. One possible approach is to simply make the genome extremely large,
so that the space it encodes is extremely large and a solution is likely to lie somewhere
within. Yet the larger the genome, the higher dimensional the space that evolution needs to
search. Even if a ping-pong playing robot lies somewhere in the 10,000 dimensional space
of a 10,000 gene genome, searching such a space may take prohibitively long.
Even more problematic are open-ended problems where phenotypes are meant to improve indefinitely and there is no known final solution. For example, in competitive games,
estimating the complexity of the best possible player is difficult because such an estimate
implicitly assumes that no better player can exist, which we cannot always know. Moreover,
many artificial life domains are aimed at evolving increasingly complex artificial creatures
for as long as possible (Maley, 1999). Such continual evolution is difficult with a fixed
genome for two reasons: (1) When a good strategy is found in a fixed-length genome, the
entire representational space of the genome is used to encode it. Thus, the only way to
improve it is to alter the strategy, thereby sacrificing some of the functionality learned over
previous generations. (2) Fixing the size of the genome in such domains arbitrarily fixes
the maximum complexity of evolved creatures, defeating the purpose of the experiment.
In this paper, we argue that structured phenotypes can be evolved effectively by starting evolution with a population of small, simple genomes and systematically elaborating
on them over generations by adding new genes. Each new gene expands the search space,
adding a new dimension that previously did not exist. That way, evolution begins searching
in a small easily-optimized space, and adds new dimensions as necessary. This approach
is more likely to discover highly complex phenotypes than an approach that begins searching directly in the intractably large space of complete solutions. In fact, natural evolution
utilizes this strategy, occasionally adding new genes that lead to increased phenotypic complexity (Martin 1999; Section 2). In biology, this process of incremental elaboration is called
complexification, which is why we use this term to describe our approach as well.
In evolutionary computation, complexification refers to expanding the dimensionality
of the search space while preserving the values of the majority of dimensions. In other
words, complexification elaborates on the existing strategy by adding new structure without
changing the existing representation. Thus the strategy does not only become different, but
the number of possible responses to situations it can generate increases (Figure 1).
In the EC domain of neuroevolution (i.e. evolving neural networks), complexification
means adding nodes and connections to already-functioning neural networks. This is the
main idea behind NEAT (NeuroEvolution of Augmenting Topologies; Stanley and Miikkulainen 2002b,c,d), the method described in this paper. NEAT begins by evolving networks
without any hidden nodes. Over many generations, new hidden nodes and connections are
added, complexifying the space of potential solutions. In this way, more complex strategies
elaborate on simpler strategies, focusing search on solutions that are likely to maintain
existing capabilities.
64

fiCompetitive Coevolution through Evolutionary Complexification

Alteration
Original Strategy

Strategy Fails

Altered Strategy

Strategy Fails

Elaboration
Original Strategy

Strategy Fails

Elaborated Strategy

Skill Remains!

Figure 1: Alteration vs. elaboration example.

The dark robot must evolve to avoid the
lighter robot, which attempts to cause a collision. In the alteration scenario (top), the
dark robot first evolves a strategy to go around the left side of the opponent. However,
the strategy fails in a future generation when the opponent begins moving to the left.
Thus, the dark robot alters its strategy by evolving the tendency to move right instead
of left. However, when the light robot later moves right, the new, altered, strategy fails
because the dark robot did not retain its old ability to move left. In the elaboration
scenario (bottom), the original strategy of moving left also fails. However, instead of
altering the strategy, it is elaborated by adding a new ability to move right as well. Thus,
when the opponent later moves right, the dark robot still has the ability to avoid it by
using its original strategy. Elaboration is necessary for a coevolutionary arms race to
emerge and it can be achieved through complexification.

Expanding the length of the size of the genome has been found effective in previous
work (Cliff, Harvey, & Husbands, 1993; Harvey, 1993; Koza, 1995; Lindgren & Johansson,
2001). NEAT advances this idea by making it possible to search a wide range of increasingly complex network topologies simultaneously. This process is based on three technical
components: (1) Keeping track of which genes match up with which among differently sized
genomes throughout evolution; (2) speciating the population so that solutions of differing
complexity can exist independently; and (3) starting evolution with a uniform population
of small networks. These components work together in complexifying solutions as part of
the evolutionary process. In prior work, NEAT has been shown to solve challenging reinforcement learning problems more efficiently than other neuroevolution methods (Stanley
and Miikkulainen 2002b,c,d). The focus of these studies was on optimizing a given fitness
function through complexifying evolution.

65

fiStanley & Miikkulainen

In this paper, we focus on open-ended problems that have no explicit fitness function;
instead, fitness depends on comparisons with other agents that are also evolving. The goal
is to discover creative solutions beyond a designers ability to define a fitness function. It is
difficult to continually improve solutions in such coevolutionary domains because evolution
tends to oscillate between idiosyncratic yet uninteresting solutions (Floreano & Nolfi, 1997).
Complexification encourages continuing innovation by elaborating on existing solutions.
In order to demonstrate the power of complexification in coevolution, NEAT is applied
to the competitive robot control domain of Robot Duel. There is no known optimal strategy
in the domain but there is substantial room to come up with increasingly sophisticated
strategies. The main results were that (1) evolution did complexify when possible, (2)
complexification led to elaboration, and (3) significantly more sophisticated and successful
strategies were evolved with complexification than without it. These results imply that
complexification allows establishing a coevolutionary arms race that achieves a significantly
higher level of sophistication than is otherwise possible.
We begin by reviewing biological support for complexification, as well as past work in
coevolution, followed by a description of the NEAT method, and experimental results.

2. Background
The natural process of complexification has led to important biological innovations. Its
most natural application in EC is in competitive coevolution, as will be reviewed below.
2.1 Complexification in Nature
Mutation in nature not only results in optimizing existing structures: New genes are occasionally added to the genome, allowing evolution to perform a complexifying function over
and above optimization. In addition, complexification is protected in nature in that interspecies mating is prohibited. Such speciation creates important dynamics differing from
standard GAs. In this section, we discuss these characteristics of natural evolution as a
basis for our approach to utilizing them computationally in genetic algorithms.
Gene duplication is a special kind of mutation in which one or more parental genes are
copied into an offsprings genome more than once. The offspring then has redundant genes
expressing the same proteins. Gene duplication has been responsible for key innovations in
overall body morphology over the course of natural evolution (Amores, Force, Yan, Joly,
Amemiya, Fritz, Ho, Langeland, Prince, Wang, Westerfield, Ekker, & Postlethwait, 1998;
Carroll, 1995; Force, Lynch, Pickett, Amores, lin Yan, & Postlethwait, 1999; Martin, 1999).
A major gene duplication event occurred around the time that vertebrates separated
from invertebrates. The evidence for this duplication centers around HOX genes, which
determine the fate of cells along the anterior-posterior axis of embryos. HOX genes are
crucial in shaping the overall pattern of development in embryos. In fact, differences in
HOX gene regulation explain a great deal of the diversity among arthropods and tetrapods
(Carroll, 1995). Invertebrates have a single HOX cluster while vertebrates have four, suggesting that cluster duplication significantly contributed to elaborations in vertebrate bodyplans (Amores et al., 1998; Holland, Garcia-Fernandez, Williams, & Sidow, 1994; Nadeau
& Sankoff, 1997; Postlethwait, Yan, Gates, Horne, Amores, Brownlie, & Donovan, 1998;
Sidow, 1996). The additional HOX genes took on new roles in regulating how vertebrate
66

fiCompetitive Coevolution through Evolutionary Complexification

anterior-posterior axis develops, considerably increasing body-plan complexity. Although
Martin (1999) argues that the additional clusters can be explained by many single gene duplications accumulating over generations, as opposed to massive whole-genome duplications,
researchers agree that gene duplication in some form contributed significantly to body-plan
elaboration.
A detailed account of how duplicate genes can take on novel roles was given by Force et al.
(1999): Base pair mutations in the generations following duplication partition the initially
redundant regulatory roles of genes into separate classes. Thus, the embryo develops in the
same way, but the genes that determine the overall body-plan are confined to more specific
roles, since there are more of them. The partitioning phase completes when redundant
clusters of genes are separated enough so that they no longer produce identical proteins
at the same time. After partitioning, mutations within the duplicated cluster of genes
affect different steps in development than mutations within the original cluster. In other
words, duplication creates more points at which mutations can occur. In this manner,
developmental processes complexify.
Gene duplication is a possible explanation how natural evolution indeed expanded the
size of genomes throughout evolution, and provides inspiration for adding new genes to
artificial genomes as well. In fact, gene duplication motivated Koza (1995) to allow entire
functions in genetic programs to be duplicated through a single mutation, and later differentiated through further mutations. When evolving neural networks, this process means
adding new neurons and connections to the networks.
In order to implement this idea in artificial evolutionary systems, we are faced with
two major challenges. First, such systems evolve differently sized and shaped network
topologies, which can be difficult to cross over without losing information. For example,
depending on when new structure was added, the same gene may exist at different positions,
or conversely, different genes may exist at the same position. Thus, artificial crossover may
disrupt evolved topologies through misalignment. Second, with variable-length genomes,
it may be difficult to find innovative solutions. Optimizing many genes takes longer than
optimizing only a few, meaning that more complex networks may be eliminated from the
population before they have a sufficient opportunity to be optimized.
However, biological evolution also operates on variable-length genomes, and these problems did not stop complexification in nature. How are these problems avoided in biological
evolution? First, nature has a mechanism for aligning genes with their counterparts during
crossover, so that data is not lost nor obscured. This alignment process has been most
clearly observed in E. coli (Radding, 1982; Sigal & Alberts, 1972). A special protein called
RecA takes a single strand of DNA and aligns it with another strand at genes that express
the same traits, which are called homologous genes. This process is called synapsis.
Second, innovations in nature are protected through speciation. Organisms with significantly divergent genomes never mate because they are in different species. If any organism
could mate with any other, organisms with initially larger, less-fit genomes would be forced
to compete for mates with their simpler, more fit counterparts. As a result, the larger,
more innovative genomes would fail to produce offspring and disappear from the population. In contrast, in a speciated population, organisms with larger genomes compete for
mates among their own species, instead of with the population at large. That way, organisms that may initially have lower fitness than the general population still have a chance
67

fiStanley & Miikkulainen

to reproduce, giving novel concepts a chance to realize their potential without being prematurely eliminated. Because speciation benefits the evolution of diverse populations, a
variety of speciation methods have been employed in EC (Goldberg & Richardson, 1987;
Mahfoud, 1995; Ryan, 1994).
It turns out complexification is also possible in evolutionary computation if abstractions
of synapsis and speciation are made part of the genetic algorithm. The NEAT method
(section 3) is an implementation of this idea: The genome is complexified by adding new
genes which in turn encode new structure in the phenotype, as in biological evolution.
Complexification is especially powerful in open-ended domains where the goal is to
continually generate more sophisticated strategies. Competitive coevolution is a particularly
important such domain, as will be reviewed in the next section.
2.2 Competitive Coevolution
In competitive coevolution, individual fitness is evaluated through competition with other
individuals in the population, rather than through an absolute fitness measure. In other
words, fitness signifies only the relative strengths of solutions; an increased fitness in one
solution leads to a decreased fitness for another. Ideally, competing solutions will continually
outdo one another, leading to an arms race of increasingly better solutions (Dawkins &
Krebs, 1979; Rosin, 1997; Van Valin, 1973). Competitive coevolution has traditionally been
used in two kinds of problems. First, it can be used to evolve interactive behaviors that
are difficult to evolve in terms of an absolute fitness function. For example, Sims (1994)
evolved simulated 3D creatures that attempted to capture a ball before an opponent did,
resulting in a variety of effective interactive strategies. Second, coevolution can be used
to gain insight into the dynamics of game-theoretic problems. For example, Lindgren &
Johansson (2001) coevolved iterated Prisoners Dilemma strategies in order to demonstrate
how they correspond to stages in natural evolution.
Whatever the goal of a competitive coevolution experiment, interesting strategies will
only evolve if the arms race continues for a significant number of generations. In practice, it
is difficult to establish such an arms race. Evolution tends to find the simplest solutions that
can win, meaning that strategies can switch back and forth between different idiosyncratic
yet uninteresting variations (Darwen, 1996; Floreano & Nolfi, 1997; Rosin & Belew, 1997).
Several methods have been developed to encourage the arms race (Angeline & Pollack, 1993;
Ficici & Pollack, 2001; Noble & Watson, 2001; Rosin & Belew, 1997). For example, a hall
of fame or a collection of past good strategies can be used to ensure that current strategies
remain competitive against earlier strategies. Recently, Ficici and Pollack (2001) and Noble
and Watson (2001) introduced a promising method called Pareto coevolution, which finds
the best learners and the best teachers in two populations by casting coevolution as a multiobjective optimization problem. This information enables choosing the best individuals
to reproduce, as well as maintaining an informative and diverse set of opponents.
Although such techniques allow sustaining the arms race longer, they do not directly
encourage continual coevolution, i.e. creating new solutions that maintain existing capabilities. For example, no matter how well selection is performed, or how well competitors
are chosen, if the search space is fixed, a limit will eventually be reached. Also, it may

68

fiCompetitive Coevolution through Evolutionary Complexification

occasionally be easier to escape a local optimum by adding a new dimension to the search
space than by searching for a new path through the original space.
For these reasons, complexification is a natural technique for establishing a coevolutionary arms race. Complexification elaborates strategies by adding new dimensions to the
search space. Thus, progress can be made indefinitely long: Even if a global optimum
is reached in the search space of solutions, new dimensions can be added, opening up a
higher-dimensional space where even better optima may exist.
To test this idea experimentally, we chose a robot duel domain that combines predator/prey interaction and food foraging in a novel head-to-head competition (Section 4).
We use this domain to demonstrate how NEAT uses complexification to continually elaborate solutions. The next section reviews the NEAT neuroevolution method, followed by a
description of the robot duel domain and a discussion of the results.

3. NeuroEvolution of Augmenting Topologies (NEAT)
The NEAT method of evolving artificial neural networks combines the usual search for
appropriate network weights with complexification of the network structure. This approach
is highly effective, as shown e.g. in comparison to other neuroevolution (NE) methods in the
double pole balancing benchmark task (Stanley & Miikkulainen, 2002b,c,d). The NEAT
method consists of solutions to three fundamental challenges in evolving neural network
topology: (1) What kind of genetic representation would allow disparate topologies to
crossover in a meaningful way? Our solution is to use historical markings to line up genes
with the same origin. (2) How can topological innovation that needs a few generations
to optimize be protected so that it does not disappear from the population prematurely?
Our solution is to separate each innovation into a different species. (3) How can topologies
be minimized throughout evolution so the most efficient solutions will be discovered? Our
solution is to start from a minimal structure and add nodes and connections incrementally.
In this section, we explain how each of these solutions is implemented in NEAT.
3.1 Genetic Encoding
Evolving structure requires a flexible genetic encoding. In order to allow structures to complexify, their representations must be dynamic and expandable. Each genome in NEAT
includes a list of connection genes, each of which refers to two node genes being connected.
(Figure 2). Each connection gene specifies the in-node, the out-node, the weight of the connection, whether or not the connection gene is expressed (an enable bit), and an innovation
number, which allows finding corresponding genes during crossover.
Mutation in NEAT can change both connection weights and network structures. Connection weights mutate as in any NE system, with each connection either perturbed or not.
Structural mutations, which form the basis of complexification, occur in two ways (Figure
3). Each mutation expands the size of the genome by adding gene(s). In the add connection
mutation, a single new connection gene is added connecting two previously unconnected
nodes. In the add node mutation, an existing connection is split and the new node placed
where the old connection used to be. The old connection is disabled and two new connections are added to the genome. The connection between the first node in the chain and the
new node is given a weight of one, and the connection between the new node and the last
69

fiStanley & Miikkulainen

Genome (Genotype)
Node
Genes
Connect.

Genes

Node 1 Node 2 Node 3 Node 4 Node 5
Sensor Sensor Sensor Output Hidden
In 1
Out 4
Weight 0.7
Enabled
Innov 1

In 2
Out 4
Weight0.5
DISABLED
Innov 2

Network (Phenotype)
1

In 3
Out 4
Weight 0.5
Enabled
Innov 3

In 2
Out 5
Weight 0.2
Enabled
Innov 4

In 5
Out 4
Weight 0.4
Enabled
Innov 5

In 1
Out 5
Weight 0.6
Enabled
Innov 6

In 4
Out 5
Weight 0.6
Enabled
Innov 11

4
5
2

3

Figure 2: A NEAT genotype to phenotype mapping example. A genotype is depicted that
produces the shown phenotype. There are 3 input nodes, one hidden, and one output
node, and seven connection definitions, one of which is recurrent. The second gene is
disabled, so the connection that it specifies (between nodes 2 and 4) is not expressed in
the phenotype. In order to allow complexification, genome length is unbounded.

node in the chain is given the same weight as the connection being split. Splitting the connection in this way introduces a nonlinearity (i.e. sigmoid function) where there was none
before. When initialized in this way, this nonlinearity changes the function only slightly,
and the new node is immediately integrated into the network. Old behaviors encoded in the
preexisting network structure are not destroyed and remain qualitatively the same, while
the new structure provides an opportunity to elaborate on these original behaviors.
Through mutation, the genomes in NEAT will gradually get larger. Genomes of varying
sizes will result, sometimes with different connections at the same positions. Crossover must
be able to recombine networks with differing topologies, which can be difficult (Radcliffe,
1993). The next section explains how NEAT addresses this problem.
3.2 Tracking Genes through Historical Markings
It turns out that the historical origin of each gene can be used to tell us exactly which genes
match up between any individuals in the population. Two genes with the same historical
origin represent the same structure (although possibly with different weights), since they
were both derived from the same ancestral gene at some point in the past. Thus, all a
system needs to do is to keep track of the historical origin of every gene in the system.
Tracking the historical origins requires very little computation. Whenever a new gene
appears (through structural mutation), a global innovation number is incremented and
assigned to that gene. The innovation numbers thus represent a chronology of every gene
in the system. As an example, let us say the two mutations in Figure 3 occurred one after
70

fiCompetitive Coevolution through Evolutionary Complexification

1

2

3

4

5

6

1>4 2>4 3>4 2>5 5>4 1>5
DIS

1

2

3

Mutate Add Connection

4

1

2

2

1

3

3

4

5

6

5

6

7

1

2

2

3

3

4

8

9

1>4 2>4 3>4 2>5 5>4 1>5 3>6 6>4
DIS DIS

Mutate Add Node

4

4

5
2

6

5

1>4 2>4 3>4 2>5 5>4 1>5
DIS

1

5

4

5
1

4

1>4 2>4 3>4 2>5 5>4 1>5 3>5
DIS

5
1

3

2

6

3

Figure 3: The two types of structural mutation in NEAT. Both types, adding a connection
and adding a node, are illustrated with the genes above their phenotypes. The top number
in each genome is the innovation number of that gene. The bottom two numbers denote
the two nodes connected by that gene. The weight of the connection, also encoded in the
gene, is not shown. The symbol DIS means that the gene is disabled, and therefore not
expressed in the network. The figure shows how connection genes are appended to the
genome when a new connection and a new node is added to the network. Assuming the
depicted mutations occurred one after the other, the genes would be assigned increasing
innovation numbers as the figure illustrates, thereby allowing NEAT to keep an implicit
history of the origin of every gene in the population.

another in the system. The new connection gene created in the first mutation is assigned
the number 7, and the two new connection genes added during the new node mutation
are assigned the numbers 8 and 9. In the future, whenever these genomes crossover, the
offspring will inherit the same innovation numbers on each gene. Thus, the historical origin
of every gene in the system is known throughout evolution.
A possible problem is that the same structural innovation will receive different innovation
numbers in the same generation if it occurs by chance more than once. However, by keeping
a list of the innovations that occurred in the current generation, it is possible to ensure that
when the same structure arises more than once through independent mutations in the
same generation, each identical mutation is assigned the same innovation number. Through
extensive experimentation, we established that resetting the list every generation as opposed
to keeping a growing list of mutations throughout evolution is sufficient to prevent an
explosion of innovation numbers.
Through innovation numbers, the system now knows exactly which genes match up
with which (Figure 4). Genes that do not match are either disjoint or excess, depending on
whether they occur within or outside the range of the other parents innovation numbers.
When crossing over, the genes with the same innovation numbers are lined up and are

71

fiStanley & Miikkulainen

Parent1
1
2
3
1>4 2>4 3>4
DISAB

Parent2

4
2>5

8
5
5>4 1>5

3
6
1
2
4
5
1>4 2>4 3>4 2>5 5>4 5>6
DISAB
DISAB

10
1>6

6

5
2

9
3>5

4

4

1

7
6>4

5

3

1

2

3

disjoint

Parent1
Parent2

1
2
3
1>4 2>4 3>4
DISAB

4
2>5

8
1>5

5
5>4

3
6
1
2
4
5
1>4 2>4 3>4 2>5 5>4 5>6
DISAB
DISAB

9
3>5

7
6>4

excess excess

disjointdisjoint

Offspring

3
1
2
4
5
6
1>4 2>4 3>4 2>5 5>4 5>6
DISAB
DISAB

7
6>4

10
1>6

8
1>5

9
3>5

10
1>6

4
6
5
1

2

3

Figure 4: Matching up genomes for different network topologies using innovation numbers. Although Parent 1 and Parent 2 look different, their innovation numbers (shown
at the top of each gene) tell us that several of their genes match up even without topological analysis. A new structure that combines the overlapping parts of the two parents
as well as their different parts can be created in crossover. In this case, equal fitnesses
are assumed, so the disjoint and excess genes from both parents are inherited randomly.
Otherwise they would be inherited from the more fit parent. The disabled genes may
become enabled again in future generations: There is a preset chance that an inherited
gene is disabled if it is disabled in either parent.

randomly chosen for the offspring genome. Genes that do not match are inherited from the
more fit parent, or if they are equally fit, from both parents randomly. Disabled genes have
a 25% chance of being reenabled during crossover, allowing networks to make use of older
genes once again.1
Historical markings allow NEAT to perform crossover without the need for expensive
topological analysis. Genomes of different organizations and sizes stay compatible throughout evolution, and the problem of comparing different topologies is essentially avoided. This
1. See Appendix A for specific mating parameters used in the experiments in this paper.

72

fiCompetitive Coevolution through Evolutionary Complexification

methodology allows NEAT to complexify structure while still maintaining genetic compatibility. However, it turns out that a population of varying complexities cannot maintain
topological innovations on its own. Because smaller structures optimize faster than larger
structures, and adding nodes and connections usually initially decreases the fitness of the
network, recently augmented structures have little hope of surviving more than one generation even though the innovations they represent might be crucial towards solving the
task in the long run. The solution is to protect innovation by speciating the population, as
explained in the next section.
3.3 Protecting Innovation through Speciation
NEAT speciates the population so that individuals compete primarily within their own
niches instead of with the population at large. This way, topological innovations are protected and have time to optimize their structure before they have to compete with other
niches in the population. In addition, speciation prevents bloating of genomes: Species with
smaller genomes survive as long as their fitness is competitive, ensuring that small networks
are not replaced by larger ones unnecessarily. Protecting innovation through speciation follows the philosophy that new ideas must be given time to reach their potential before they
are eliminated.
Historical markings make it possible for the system to divide the population into species
based on topological similarity. We can measure the distance  between two network encodings as a linear combination of the number of excess (E) and disjoint (D) genes, as well
as the average weight differences of matching genes (W ):
=

c1 E c2 D
+
+ c3  W .
N
N

(1)

The coefficients c1 , c2 , and c3 adjust the importance of the three factors, and the factor
N , the number of genes in the larger genome, normalizes for genome size (N can be set
to 1 if both genomes are small). Genomes are tested one at a time; if a genomes distance
to a randomly chosen member of the species is less than t , a compatibility threshold, it
is placed into this species. Each genome is placed into the first species from the previous
generation where this condition is satisfied, so that no genome is in more than one species.
If a genome is not compatible with any existing species, a new species is created. The
problem of choosing the best value for t can be avoided by making t dynamic; that is,
given a target number of species, the system can raise t if there are too many species, and
lower t if there are too few.
As the reproduction mechanism for NEAT, we use explicit fitness sharing (Goldberg &
Richardson, 1987), where organisms in the same species must share the fitness of their niche.
Thus, a species cannot afford to become too big even if many of its organisms perform well.
Therefore, any one species is unlikely to take over the entire population, which is crucial for
speciated evolution to maintain topological diversity. The adjusted fitness fi0 for organism
i is calculated according to its distance  from every other organism j in the population:
fi
.
j=1 sh((i, j))

fi0 = Pn

73

(2)

fiStanley & Miikkulainen

The sharing function sh is set to 0 when distance
P (i, j) is above the threshold t ;
otherwise, sh((i, j)) is set to 1 (Spears, 1995). Thus, nj=1 sh((i, j)) reduces to the number
of organisms in the same species as organism i. This reduction is natural since species
are already clustered by compatibility using the threshold t . Every species is assigned
a potentially different number of offspring in proportion to the sum of adjusted fitnesses
fi0 of its member organisms. Species reproduce by first eliminating the lowest performing
members from the population. The entire population is then replaced by the offspring of
the remaining organisms in each species.
The net effect of speciating the population is that structural innovation is protected.
The final goal of the system, then, is to perform the search for a solution as efficiently as
possible. This goal is achieved through complexification from a simple starting structure,
as detailed in the next section.
3.4 Minimizing Dimensionality through Complexification
Unlike other systems that evolve network topologies and weights (Angeline, Saunders, &
Pollack, 1993; Gruau, Whitley, & Pyeatt, 1996; Yao, 1999; Zhang & Muhlenbein, 1993),
NEAT begins with a uniform population of simple networks with no hidden nodes, differing
only in their initial random weights. Speciation protects new innovations, allowing topological diversity to be gradually introduced over evolution. Thus, because NEAT protects
innovation using speciation, it can start in this manner, minimally, and grow new structure
over generations.
New structure is introduced incrementally as structural mutations occur, and only those
structures survive that are found to be useful through fitness evaluations. This way, NEAT
searches through a minimal number of weight dimensions, significantly reducing the number of generations necessary to find a solution, and ensuring that networks become no
more complex than necessary. This gradual production of increasingly complex structures
constitutes complexification. In other words, NEAT searches for the optimal topology by
incrementally complexifying existing structure.
In previous work, each of the three main components of NEAT (i.e. historical markings,
speciation, and starting from minimal structure) were experimentally ablated in order to
demonstrate how they contribute to performance (Stanley & Miikkulainen, 2002b,d). The
ablation study demonstrated that all three components are interdependent and necessary
to make NEAT work. In this paper, we further show how complexification establishes the
arms race in competitive coevolution. The next section describes the experimental domain
in which this result will be demonstrated.

4. The Robot Duel Domain
Our hypothesis is that the complexification process outlined above allows discovering more
sophisticated strategies, i.e. strategies that are more effective, flexible, and general, and
include more components and variations than do strategies obtained through search in a
fixed space. To demonstrate this effect, we need a domain where it is possible to develop
a wide range increasingly sophisticated strategies, and where sophistication can be readily
measured. A coevolution domain is particularly appropriate because a sustained arms race
should lead to increasing sophistication.
74

fiCompetitive Coevolution through Evolutionary Complexification

In choosing the domain, it is difficult to strike a balance between being able to evolve
complex strategies and being able to analyze and understand them. Pursuit and evasion
tasks have been utilized for this purpose in the past (Gomez & Miikkulainen, 1997; Jim
& Giles, 2000; Miller & Cliff, 1994; Reggia, Schulz, Wilkinson, & Uriagereka, 2001; Sims,
1994), and can serve as a benchmark domain for complexifying coevolution as well. While
past experiments evolved either a predator or a prey, an interesting coevolution task can
be established if the agents are instead equal and engaged in a duel. To win, an agent must
develop a strategy that outwits that of its opponent, utilizing structure in the environment.
In this paper we introduce such a duel domain, in which two simulated robots try to
overpower each other (Figure 5). The two robots begin on opposite sides of a rectangular
room facing away from each other. As the robots move, they lose energy in proportion to
the amount of force they apply to their wheels. Although the robots never run out of energy
(they are given enough to survive the entire competition), the robot with higher energy wins
when it collides with its competitor. In addition, each robot has a sensor indicating the
difference in energy between itself and the other robot. To keep their energies high, the
robots can consume food items, arranged in a symmetrical pattern in the room.
The robot duel task supports a broad range of sophisticated strategies that are easy to
observe and interpret. The competitors must become proficient at foraging, prey capture,
and escaping predators. In addition, they must be able to quickly switch from one behavior
to another. The task is well-suited to competitive coevolution because naive strategies such
as forage-then-attack can be complexified into more sophisticated strategies such as luring
the opponent to waste its energy before attacking.
The simulated robots are similar to Kheperas (Mondada et al. 1993; Figure 6). Each
has two wheels controlled by separate motors. Five rangefinder sensors can sense food and
another five can sense the other robot. Finally, each robot has an energy-difference sensor,
and a single wall sensor.
The robots are controlled with neural networks evolved with NEAT. The networks receive all of the robot sensors as inputs, as well as a constant bias that NEAT can use to
change the activation thresholds of neurons. They produce three motor outputs: Two to
encode rotation either right or left, and a third to indicate forward motion power. These
three values are then translated into forces to be applied to the left and right wheels of the
robot.
The state st of the world at time t is defined by the positions of the robots and food,
the energy levels of the robots, and the internal states (i.e. neural activation) of the robots
neural networks, including sensors, outputs, and hidden nodes. The subsequent state st+1
is determined by the outputs of the robots neural network controllers, computed from the
inputs (i.e. sensor values) in st in one step of propagation through the network. The robots
change their position in st+1 according to their neural network outputs as follows. The
change in direction of motion is proportional to the difference between the left and right
motor outputs. The robot drives forward a distance proportional to the forward output
on a continuous board of size 600 by 600. The robot first makes half its turn, then moves
forward, then completes the second half of its turn, so that the turning and forward motions
are effectively combined. If the robot encounters food, it receives an energy boost, and the
food disappears from the world. The loss of energy due to movement is computed as the
sum of the turn angle and the forward motion, so that even turning in place takes energy. If
75

fiStanley & Miikkulainen

Figure 5: The Robot Duel Domain. The robots begin on opposite sides of the board facing
away from each other as shown by the arrows pointing away from their centers. The
concentric circles around each robot represent the separate rings of opponent sensors
and food sensors available to each robot. Each ring contains five sensors. The robots
lose energy when they move around, and gain energy by consuming food (shown as
small sandwiches). The food is always placed in the depicted horizontally symmetrical
pattern around the middle of the board. The objective is to attain a higher level of
energy than the opponent, and then collide with it. Because of the complex interaction
between foraging, pursuit, and evasion behaviors, the domain allows for a broad range
of strategies of varying sophistication. Animated demos of such evolved strategies are
available at www.cs.utexas.edu/users/nn/pages/research/neatdemo.html.

the robots are within a distance of 20, a collision occurs and the robot with a higher energy
wins (see Appendix B for the exact parameter values used).
Since the observed state ot taken by the sensors does not include the internal state
of the opponent robot, the robot duel is a partially-observable Markov decision process
(POMDP). Since the next observed state ot+1 depends on the decision of the opponent, it
is necessary for robots to learn to predict what the opponent is likely to do, based on their
past behavior, and also based on what is reasonable behavior in general. For example, it
is reasonable to assume that if the opponent robot is quickly approaching and has higher
energy, it is probably trying to collide. Because an important and complex portion of s is
not observable, memory, and hence recurrent connections, are crucial for success.
This complex robot-control domain allows competitive coevolution to evolve increasingly
sophisticated and complex strategies, and can be used to understand complexification, as
will be described next.

76

fiCompetitive Coevolution through Evolutionary Complexification

Figure 6: Robot Neural Networks. Five food sensors and five robot sensors detect the presence
of objects around the robot. A single wall sensor indicates proximity to walls, and
the energy difference sensor tells the robot how its energy level differs from that of its
opponent. This difference is important because the robot with lower energy loses if the
robots collide. The three motor outputs are mapped to forces that control the left and
the right wheel.

5. Experiments
In order to demonstrate how complexification enhances performance, we ran thirty-three
500-generation runs of coevolution in the robot duel domain. Thirteen of these runs were
based on the full NEAT method. Complexification was turned off in the remaining 20 runs
(although networks were still speciated based on weight differences), in order to see how
complexification contributes evolving sophisticated strategies. The competitive coevolution
setup is described first, followed by an overview of the dominance tournament method for
monitoring progress.
5.1 Competitive Coevolution Setup
The robot duel domain supports highly sophisticated strategies. Thus, the question in
such a domain is whether continual coevolution will take place, i.e. whether increasingly
sophisticated strategies will appear over the course of evolution. The experiment has to be
set up carefully for this process to emerge, and to be able to identify it when it does.
In competitive coevolution, every network should play a sufficient number of games to
establish a good measure of fitness. To encourage interesting and sophisticated strategies,
networks should play a diverse and high quality sample of possible opponents. One way
to accomplish this goal is to evolve two separate populations. In each generation, each
population is evaluated against an intelligently chosen sample of networks from the other
population. The population currently being evaluated is called the host population, and
the population from which opponents are chosen is called the parasite population (Rosin &

77

fiStanley & Miikkulainen

Belew, 1997). The parasites are chosen for their quality and diversity, making host/parasite
evolution more efficient and more reliable than one based on random or round robin tournament.
In the experiment, a single fitness evaluation included two competitions, one for the east
and one for the west starting position. That way, networks needed to implement general
strategies for winning, independent of their starting positions. Host networks received a
single fitness point for each win, and no points for losing. If a competition lasted 750 time
steps with no winner, the host received zero points.
In selecting the parasites for fitness evaluation, good use can be made of the speciation
and fitness sharing that already occur in NEAT. Each host was evaluated against the four
highest species champions. They are good opponents because they are the best of the
best species, and they are guaranteed to be diverse because their distance must exceed the
threshold t (section 3.3). Another eight opponents were chosen randomly from a Hall of
Fame composed of all generation champions (Rosin & Belew, 1997). The Hall of Fame
ensures that existing abilities need to be maintained to obtain a high fitness. Each network
was evaluated in 24 games (i.e. 12 opponents, 2 games each), which was found to be effective
experimentally. Together speciation, fitness sharing, and Hall of Fame comprise an effective
competitive coevolution methodology.
It should be noted that complexification does not depend on the particular coevolution
methodology. For example Pareto coevolution (Ficici & Pollack, 2001; Noble & Watson,
2001) could have been used as well, and the advantages of complexification would be the
same. However, Pareto coevolution requires every member of one population to play every
member of the other, and the running time in this domain would have been prohibitively
long.
In order to interpret experimental results, a method is needed for analyzing progress in
competitive coevolution. The next section describes such a method.
5.2 Monitoring Progress in Competitive Coevolution
A competitive coevolution run returns a record of every generation champion from both
populations. The question is, how can a sequence of increasingly sophisticated strategies
be identified in this data, if one exists? This section describes the dominance tournament
method for monitoring progress in competitive coevolution (Stanley & Miikkulainen, 2002a)
that allows us to do that.
First we need a method for performing individual comparisons, i.e. whether one strategy
is better than another. Because the board configurations can vary between games, champion
networks were compared on 144 different food configurations from each side of the board,
giving 288 total games for each comparison. The food configurations included the same
9 symmetrical food positions used during training, plus an additional 2 food items, which
were placed in one of 12 different positions on the east and west halves of the board. Some
starting food positions give an initial advantage to one robot or another, depending on how
close they are to the robots starting positions. Thus, the one who wins the majority of
the 288 total games has demonstrated its superiority in many different scenarios, including
those beginning with a disadvantage. We say that network a is superior to network b if a
wins more games than b out of the 288 total games.

78

fiCompetitive Coevolution through Evolutionary Complexification

Given this definition of superiority, progress can be tracked. The obvious way to do it is
to compare each network to others throughout evolution, finding out whether later strategies
can beat more opponents than earlier strategies. For example, Floreano & Nolfi (1997) used
a measure called master tournament, in which the champion of each generation is compared
to all other generation champions. Unfortunately, such methods are impractical in a timeintensive domain such as the robot duel competition. Moreover, the master tournament
only counts how many strategies can be defeated by each generation champion, without
identifying which ones. Thus, it can fail to detect cases where strategies that defeat fewer
previous champions are actually superior in a direct comparison. For example, if strategy A
defeats 499 out of 500 opponents, and B defeats 498, the master tournament will designate
A as superior to B even if B defeats A in a direct comparison. In order to decisively
track strategic innovation, we need to identify dominant strategies, i.e. those that defeat
all previous dominant strategies. This way, we can make sure that evolution proceeds
by developing a progression of strictly more powerful strategies, instead of e.g. switching
between alternative ones.
The dominance tournament method of tracking progress in competitive coevolution
meets this goal (Stanley & Miikkulainen, 2002a). Let a generation champion be the winner
of a 288 game comparison between the host and parasite champions of a single generation. Let dj be the jth dominant strategy to appear over evolution. Dominance is defined
recursively starting from the first generation and progressing to the last:
 The first dominant strategy d1 is the generation champion of the first generation;
 dominant strategy dj , where j > 1, is a generation champion such that for all i < j,
dj is superior to di (i.e. wins the 288 game comparison with it).
This strict definition of dominance prohibits circularities. For example, d4 must be superior to strategies d1 through d3 , d3 superior to both d1 and d2 , and d2 superior to d1 .
We call dn the nth dominant strategy of the run. If a network c exists that, for example,
defeats d4 but loses to d3 , making the superiority circular, it would not satisfy the second
condition and would not be entered into the dominance hierarchy.
The entire process of deriving a dominance hierarchy from a population is a dominance
tournament, where competitors play all previous dominant strategies until they either lose
a 288 game comparison, or win every comparison to previous dominant strategies, thereby
becoming a new dominant strategy. Dominance tournament allows us to identify a sequence
of increasingly more sophisticated strategies. It also requires significantly fewer comparisons
than the master tournament (Stanley & Miikkulainen, 2002a).
Armed with the appropriate coevolution methodology and a measure of success, we
can now ask the question: Does the complexification result in more successful competitive
coevolution?

6. Results
Each of the 33 evolution runs took between 5 and 10 days on a 1GHz Pentium III processor,
depending on the progress of evolution and sizes of the networks involved. The NEAT
algorithm itself used less than 1% of this computation: Most of the time was spent in
79

fiStanley & Miikkulainen

240

16
Connections in Highest Dom.
Random Fitness Min. Connections
Random Fitness Max. Connections

220

180

12

160

10

140

Nodes

Connections

200

Nodes in Highest Dom.
Random Fitness Min. Nodes
Random Fitness Max. Nodes

14

120

8

100

6

80

4

60
2

40
20

0

50

100

150

200 250 300
Generation

350

400

450

0

500

0

50

100

150

200 250 300
Generation

350

400

450

500

Figure 7: Complexification of connections and nodes over generations. The hashed lines
depict the average number of connections and the average number of hidden nodes in the
highest dominant network in each generation. Averages are taken over 13 complexifying
runs. A hash mark appears every generation in which a new dominant strategy emerged
in at least one of the 13 runs. The graphs show that as dominance increases, so does
complexity. The differences between the average final and first dominant strategies are
statistically significant for both connections and nodes (p < 0.001). For comparison the
dashed lines depict the sizes of the average smallest and largest networks in the entire
population over five runs where the fitness is assigned randomly. These bounds show that
the increase in complexity is not inevitable; both very simple and very complex species
exist in the population throughout the run. When the dominant networks complexify,
they do so because it is beneficial.

evaluating networks in the robot duel task. Evolution of fully-connected topologies took
about 90% longer than structure-growing NEAT because larger networks take longer to
evaluate.
In order to analyze the results, we define complexity as the number of nodes and connections in a network: The more nodes and connections there are in the network, the more
complex behavior it can potentially implement. The results were analyzed to answer three
questions: (1) As evolution progresses does it also continually complexify? (2) Does such
complexification lead to more sophisticated strategies? (3) Does complexification allow better strategies to be discovered than does evolving fixed-topology networks? Each question
is answered in turn below.
6.1 Evolution of Complexity
NEAT was run thirteen times, each time from a different seed, to verify that the results
were consistent. The highest levels of dominance achieved were 17, 14, 17, 16, 16, 18, 19,
15, 17, 12, 12, 11, and 13, averaging at 15.15 (sd = 2.54).
At each generation where the dominance level increased in at least one of the thirteen
runs, we averaged the number of connections and number of nodes in the current dominant
strategy across all runs (Figure 7). Thus, the graphs represent a total of 197 dominance
transitions spread over 500 generations. The rise in complexity is dramatic, with the average
number of connections tripling and the average number of hidden nodes rising from 0 to
80

fiCompetitive Coevolution through Evolutionary Complexification

almost six. In a smooth trend over the first 200 generations, the number of connections
in the dominant strategy grows by 50%. During this early period, dominance transitions
occur frequently (fewer prior strategies need to be beaten to achieve dominance). Over the
next 300 generations, dominance transitions become more sparse, although they continue
to occur.
Between the 200th and 500th generations a stepped pattern emerges: The complexity
first rises dramatically, then settles, then abruptly increases again (This pattern is even
more marked in individual complexifying runs; the averaging done in Figure 7 smooths
it out somewhat). The cause for this pattern is speciation. While one species is adding a
large amount of structure, other species are optimizing the weights of less complex networks.
Initially, added complexity leads to better performance, but subsequent optimization takes
longer in the new higher-dimensional space. Meanwhile, species with smaller topologies have
a chance to temporarily catch up through optimizing their weights. Ultimately, however,
more complex structures eventually win, since higher complexity is necessary for continued
innovation.
Thus, there are two underlying forces of progress: The building of new structures, and
the continual optimization of prior structures in the background. The product of these two
trends is a gradual stepped progression towards increasing complexity.
An important question is: Because NEAT searches by adding structure only, not by
removing it, does the complexity always increase whether it helps in finding good solutions
or not? To demonstrate that NEAT indeed prefers simple solutions and complexifies only
when it is useful, we ran five complexifying evolution runs with fitness assigned randomly
(i.e. the winner of each game was chosen at random). As expected, NEAT kept a wide
range of networks in its population, from very simple to highly complex (Figure 7). That is,
the dominant networks did not have to become more complex; they only did so because it
was beneficial. Not only is the minimum complexity in the random-fitness population much
lower than that of the dominant strategies, but the maximum complexity is significantly
greater. Thus, evolution complexifies sparingly, only when the complex species holds its
own in comparison with the simpler ones.
6.2 Sophistication through Complexification
To see how complexification contributes to evolution, let us observe how a sample dominant
strategy develops over time. While many complex networks evolved in the experiments,
we follow the species that produced the winning network d17 in the third run because its
progress is rather typical and easy to understand. Let us use Sk for the best network in
species S at generation k, and hl for the lth hidden node to arise from a structural mutation
over the course of evolution. We will track both strategic and structural innovations in order
to see how they correlate. Let us begin with S100 (Figure 8a), when S had a mature zerohidden-node strategy:
 S100 s main strategy was to follow the opponent, putting it in a position where it might
by chance collide with its opponent when its energy is up. However, S100 followed the
opponent even when the opponent had more energy, leaving S100 vulnerable to attack.
S100 did not clearly switch roles between foraging and chasing the enemy, causing it
to miss opportunities to gather food.
81

fiStanley & Miikkulainen

Figure 8: Complexification of a Winning Species. The best networks in the same species are
depicted at landmark generations. Nodes are depicted as squares beside their node numbers, and line thickness represents the strength of connections. Over time, the networks
became more complex and gained skills. (a) The champion from generation 10 had no
hidden nodes. (b) The addition of h22 and its respective connections gave new abilities.
(c) The appearance of h172 refined existing behaviors.

 S200 . During the next 100 generations, S evolved a resting strategy, which it used
when it had significantly lower energy than its opponent. In such a situation, the robot
stopped moving, while the other robot wasted energy running around. By the time
the opponent got close, its energy was often low enough to be attacked. The resting
strategy is an example of improvement that can take place without complexification:
It involved increasing the inhibition from the energy difference sensor, thereby slightly
modifying intensity of an existing behavior.
 In S267 (Figure 8b), a new hidden node, h22 , appeared. This node arrived through
an interspecies mating, and had been optimized for several generations already. Node
h22 gave the robot the ability to change its behavior at once into an all-out attack.
Because of this new skill, S267 no longer needed to follow the enemy closely at all
times, allowing it to collect more food. By implementing this new strategy through a
new node, it was possible not to interfere with the already existing resting strategy, so
that S now switched roles between resting when at a disadvantage to attacking when
high on energy. Thus, the new structure resulted in strategic elaboration.
 In S315 (Figure 8c), another new hidden node, h172 , split a link between an input sensor
and h22 . Replacing a direct connection with a sigmoid function greatly improved S315 s
ability to attack at appropriate times, leading to very accurate role switching between
attacking and foraging. S315 would try to follow the opponent from afar focusing on
resting and foraging, and only zoom in for attack when victory was certain. This final
structural addition shows how new structure can improve the accuracy and timing of
existing behaviors.
The analysis above shows that in some cases, weight optimization alone can produce
improved strategies. However, when those strategies need to be extended, adding new
82

fiCompetitive Coevolution through Evolutionary Complexification

Figure 9: Sophisticated Endgame.

Robot S313 dashes for the last piece of food while S210
is still collecting the second-to-last piece. Although it appeared that S313 would lose
because S210 got the second-to-last piece, (gray arrow), it turns out that S210 ends with
a disadvantage. It has no chance to get to the last piece of food before S313 , and S313
has been saving energy while S210 wasted energy traveling long distances. This way,
sophisticated strategies evolve through complexification, combining multiple objectives,
and utilizing weaknesses in the opponents strategy.

structure allows the new behaviors to coexist with old strategies. Also, in some cases
it is necessary to add complexity to make the timing or execution of the behavior more
accurate. These results show how complexification can be utilized to produce increasing
sophistication.
In order to illustrate the level of sophistication achieved in this process, we conclude
this section by describing the competition between two sophisticated strategies, S210 and
S313 , from another run of evolution. At the beginning of the competition, S210 and S313
collected most of the available food until their energy levels were about equal. Two pieces
of food remained on the board in locations distant from both S210 and S313 (Figure 9).
Because of the danger of colliding with similar energy levels, the obvious strategy is to rush
for the last two pieces of food. In fact, S210 did exactly that, consuming the second-to-last
piece, and then heading towards the last one. In contrast, S313 forfeited the race for the
second-to-last piece, opting to sit still, even though its energy temporarily dropped below
S210 s. However, S313 was closer to the last piece and got there first. It received a boost
of energy while S210 wasted its energy running the long distance from the second-to-last
piece. Thus, S313 s strategy ensured that it had more energy when they finally met. Robot
S313 s behavior was surprisingly deceptive, showing that high strategic sophistication had
evolved. Similar waiting behavior was observed against several other opponents, and also
evolved in several other runs, suggesting that it was a robust result.
This analysis of individual evolved behaviors shows that complexification indeed elaborates on existing strategies, and allows highly sophisticated behaviors to develop that
balance multiple goals and utilize weaknesses in the opponent. The last question is whether
complexification indeed is necessary to achieve these behaviors.

83

fiStanley & Miikkulainen

6.3 Complexification vs. Fixed-topology Evolution and Simplification
Complexifying coevolution was compared to two alternatives: standard coevolution in a
fixed search space, and to simplifying coevolution from a complex starting point. Note
that it is not possible to compare methods using the standard crossvalidation techniques
because no external performance measure exists in this domain. However, the evolved neural
networks can be compared directly by playing a duel. Thus, for example, a run of fixedtopology coevolution can be compared to a run of complexifying coevolution by playing the
highest dominant strategy from the fixed-topology run against the entire dominance ranking
of the complexifying run. The highest level strategy in the ranking that the fixed-topology
strategy can defeat, normalized by the number of dominance levels, is a measure of its
quality against the complexifying coevolution. For example, if a strategy can defeat up to
and including the 13th dominant strategy out of 15, then its performance against that run
13
is 15
= 86.7%. By playing every fixed-topology champion, every simplifying coevolution
champion, and every complexifying coevolution champion against the dominance ranking
from every complexifying run and averaging, we can measure the relative performance of
each of these methods.
In this section, we will first establish the baseline performance by playing complexifying
coevolution runs against themselves and demonstrating that a comparison with dominance
levels is a meaningful measure of performance. We will then compare complexification with
fixed-topology coevolution of networks of different architectures, including fully-connected
small networks, fully-connected large networks, and networks with an optimal structure
as determined by complexifying coevolution. Third, we will compare the performance of
complexification with that of simplifying coevolution.
6.3.1 Complexifying Coevolution
The highest dominant strategy from each of the 13 complexifying runs played the entire
dominance ranking from every other run. Their average performance scores were 87.9%,
83.8%, 91.9%, 79.4%, 91.9%, 99.6%, 99.4%, 99.5%, 81.8%, 96.2%, 90.6%, 96.9%, and 89.3%,
with an overall average of 91.4% (sd=12.8%). Above all, this result shows that complexifying
runs produce consistently good strategies: On average, the highest dominant strategies
qualify for the top 10% of the other complexifying runs. The best runs were the sixth,
seventh, and eighth, which were able to defeat almost the entire dominance ranking of
every other run. The highest dominant network from the best run (99.6%) is shown in
Figure 10.
In order to understand what it means for a network to be one or more dominance levels
above another, Figure 11 shows how many more games the more dominant network can
be expected to win on average over all its 288-game comparisons than the less dominant
network. Even at the lowest difference (i.e. that of one dominance level), the more dominant network can be expected to win about 50 more games on average, showing that each
difference in dominance level is important. The difference grows approximately linearly:
A network 5 dominance levels higher will win 100 more games, while a network 10 levels
higher will win 150 and 15 levels higher will win 200. These results suggest that dominance
level comparisons indeed constitute a meaningful way to measure relative performance.

84

fiCompetitive Coevolution through Evolutionary Complexification

Figure 10: The Best Complexifying Network.
The highest dominant network from the sixth complexifying coevolution run was able to
beat 99.6% of the dominance hierarchy of the other 12 runs. The network has 11 hidden
units and 202 connections (plotted as in figure 8), making significant use of structure.
While it still contains the basic direct connections, the strategy they represent has been
elaborated by adding several new nodes and connections. For example, lateral and
recurrent connections allow taking past events into account, resulting in more refined
decisions. While such structures can be found reliably through complexification, it
turns out difficult to discover them directly in the high dimensional space through
fixed-topology evolution or through simplification.

6.3.2 Fixed-Topology Coevolution of Large Networks
In fixed-topology coevolution, the network architecture must be chosen by the experimenter.
One sensible approach is to approximate the complexity of the best complexifying network.
(Figure 10). This network included 11 hidden units and 202 connections, with both recurrent connections and direct connections from input to output. As an idealization of this
structure, we used 10-hidden-unit fully recurrent networks with direct connections from
inputs to outputs, with a total of 263 connections. A network of this type should be able to
approximate the functionality of the most effective complexifying strategy. Fixed-topology
coevolution runs exactly as complexifying coevolution in NEAT, except that no structural
mutations can occur. In particular, the population is still speciated based on weight differences (i.e. W from equation 1), using the usual speciation procedure.
Three runs of fixed-topology coevolution were performed with these networks, and their
highest dominant strategies were compared to the entire dominance ranking of every complexifying run. Their average performances were 29.1%, 34.4%, and 57.8%, for an overall
average of 40.4%. Compared to the 91.4% performance of complexifying coevolution, it is

85

fiStanley & Miikkulainen

300

Average Score

250
200
150
100
50
0

Average Score Difference (out of 288)
Standard Deviation
0

2

4

6
8
10
12
Dominance Level Difference

14

16

18

Figure 11: Interpreting Differences in Dominance Levels.

The graph shows how many
games in a 288-game comparison a more dominant network can be expected to win,
averaged over all runs at all dominance levels of complexifying coevolution. For example,
a network one level higher wins 50 more games out of 288. A larger difference in
dominance levels translates to a larger difference in performance approximately linearly,
suggesting that dominance levels can be used as a measure of performance when an
absolute measure is not available.

clear that fixed-topology coevolution produced consistently inferior solutions. As a matter
of fact, no fixed-topology run could defeat any of the highest dominant strategies from the
13 complexifying coevolution runs.
This difference in performance can be illustrated by computing the average generation of
complexifying coevolution with the same performance as fixed-topology coevolution. This
generation turns out to be 24 (sd = 8.8). In other words, 500 generations of fixed-topology
coevolution reach on average the same level of dominance as only 24 generations of complexifying coevolution! In effect, the progress of the entire fixed-topology coevolution run
is compressed into the first few generations of complexifying coevolution (Figure 12).
6.3.3 Fixed-Topology Coevolution of Small Networks
One of the arguments for using complexifying coevolution is that starting the search directly
in the space of the final solution may be intractable. This argument may explain why the
attempt to evolve fixed-topology solutions at a high level of complexity failed. Thus, in
the next experiment we aimed at reducing the search space by evolving fully-connected,
fully-recurrent networks with a small number of hidden nodes as well as direct connections
from inputs to outputs. After considerable experimentation, we found out that five hidden
nodes (144 connections) was appropriate, allowing fixed-topology evolution to find the best

86

fiCompetitive Coevolution through Evolutionary Complexification

Complexifying
Coevolution

Dom. Level

15

0

1

Dom. Level

500

10 Hidden Unit
Fixed Topoloogy
Coevolution

15

0

Equivalent
Performance

1

Generations

500

Figure 12: Comparing Typical Runs of Complexifying Coevolution and Fixed-Topology
Coevolution with Ten Hidden Units. Dominance levels are charted on the y-axis
and generations on the x-axis. A line appears at every generation where a new dominant
strategy arose in each run. The height of the line represents the level of dominance. The
arrow shows that the highest dominant strategy found in 10-hidden-unit fixed-topology
evolution only performs as well as the 8th dominant strategy in the complexifying run,
which was found in the 19th generation. (Average = 24, sd = 8.8) In other words, only
a few generations of complexifying coevolution are as effective as several hundred of
fixed-topology evolution.

solutions it could. Five hidden nodes is also about the same number of hidden nodes as the
highest dominant strategies had on average in the complexifying runs.
A total of seven runs were performed with the 5-hidden-node networks, with average
performances of 70.7%, 85.5%, 66.1%, 87.3%, 80.8%, 88.8%, and 83.1%. The overall average
was 80.3% (sd=18.4%), which is better but still significantly below the 91.4% performance
of complexifying coevolution (p < 0.001).
In particular, the two most effective complexifying runs were still never defeated by any
of the fixed-topology runs. Also, because each dominance level is more difficult to achieve
than the last, on average the fixed-topology evolution only reached the performance of
the 159th complexifying generation (sd=72.0). Thus, even in the best case, fixed-topology

87

fiStanley & Miikkulainen

Complexifying
Coevolution

Dom. Level

15

0

1
Equivalent
Performance

Dom. Level

15

0

1

5 Hidden Unit
Fixed Topoloogy
Coevolution

Generations

500

500

Figure 13: Comparing Typical Runs of Complexifying Coevolution and Fixed-Topology
Coevolution with Five Hidden Units.
As in figure 12, dominance levels are
charted on the y-axis and generations on the x-axis, a line appears at every generation
where a new dominant strategy arose in each run, and the height of the line represents
the level of dominance. The arrow shows that the highest dominant strategy found in
the 5-hidden-unit fixed-topology evolution only performs as well as the 12th dominant
strategy in the complexifying run, which was found in the 140th generation (Average
159, sd = 72.0). Thus, even in the best configuration, fixed-topology evolution takes
about twice as long to achieve the same level of performance.

coevolution on average only finds the level of sophistication that complexifying coevolution
finds halfway through a run (Figure 13).
6.3.4 Fixed-Topology Coevolution of Best Complexifying Network
One problem with evolving fully-connected architectures is that they may not have an
appropriate topology for this domain. Of course, it is very difficult to guess an appropriate
topology a priori. However, it is still interesting to ask whether fixed-topology coevolution
could succeed in the task assuming that the right topology was known? To answer this
question, we evolved networks as in the other fixed-topology experiments, except this time
using the topology of the best complexifying network (Figure 10). This topology may
88

fiCompetitive Coevolution through Evolutionary Complexification

constrain the search space in such a way that finding a sophisticated solution is more likely
than with a fully-connected architecture. If so, it is possible that seeding the population
with a successful topology gives it an advantage even over complexifying coevolution, which
must build the topology from a minimal starting point.
Five runs were performed, obtaining average performance score 86.2%, 83.3%, 88.1%,
74.2%, and 80.3%, and an overall average of 82.4% (sd=15.1%). The 91.4% performance
of complexifying coevolution is significantly better than even this version of fixed-topology
coevolution (p < 0.001). However, interestingly, the 40.4% average performance of 10hidden-unit fixed topology coevolution is significantly below best-topology evolution, even
though both methods search in spaces of similar sizes. In fact, best-topology evolution
performs at about the same level as 5-hidden-unit fixed-topology evolution (80.3%), even
though 5-hidden-unit evolution optimizes half the number of hidden nodes. Thus, the results
confirm the hypothesis that using a successful evolved topology does help constrain the
search. However, in comparison to complexifying coevolution, the advantage gained from
starting this way is still not enough to make up for the penalty of starting search directly in
a high-dimensional space. As Figure 14 shows, best-topology evolution on average only finds
a strategy that performs as well as those found by the 193rd generation of complexifying
coevolution.
The results of the fixed-topology coevolution experiments can be summarized as follows:
If this method is used to search directly in the high-dimensional space of the most effective
solutions, it reaches only 40% of the performance of complexifying coevolution. It does
better if it is allowed to optimize less complex networks; however, the most sophisticated
solutions may not exist in that space. Even given a topology appropriate for the task, it
does not reach the same level as complexifying coevolution. Thus, fixed-topology coevolution does not appear to be competitive with complexifying coevolution with any choice of
topology.
The conclusion is that complexification is superior not only because it allows discovering
the appropriate high-dimensional topology automatically, but also because it makes the
optimization of that topology more efficient. This point will be discussed further in Section
7.
6.3.5 Simplifying Coevolution
A possible remedy to having to search in high-dimensional spaces is to allow evolution to
search for smaller structures by removing structure incrementally. This simplifying coevolution is the opposite of complexifying coevolution. The idea is that a mediocre complex
solution can be refined by removing unnecessary dimensions from the search space, thereby
accelerating the search.
Although simplifying coevolution is an alternative method to complexifying coevolution
for finding topologies, it still requires a complex starting topology to be specified. This
topology was chosen with two goals in mind: (1) Simplifying coevolution should start
with sufficient complexity to at least potentially find solutions of equal or more complexity
than the best solutions from complexifying coevolution, and (2) with a rate of structural
removal equivalent to the rate of structural addition in complexifying NEAT, it should be
possible to discover solutions significantly simpler than the best complexifying solutions.

89

fiStanley & Miikkulainen

Complexifying
Coevolution

Dom. Level

15

0

1
Best Solution
Fixed Topology
Coevolution

Dom. Level

15

0

1

Equivalent
Performance

Generations

500

500

Figure 14: Comparing Typical Runs of Complexifying Coevolution and Fixed-Topology
Coevolution of the Best Complexifying Network. Dominance levels are charted
as in figure 12. The arrow shows that the highest dominant strategy found by evolving
the fixed topology of the best complexifying network only performs as well as the dominant strategy that would be found in the 193rd generation of complexifying coevolution
(Average 193, sd = 85). Thus, even with an appropriate topology given, fixed-topology
evolution takes almost twice as long to achieve the same level of performance.

Thus, we chose to start search with a 12-hidden-unit, 339 connection fully-connected fullyrecurrent network. Since 162 connections were added to the best complexifying network
during evolution, a corresponding simplifying coevolution could discover solutions with 177
connections, or 25 less than the best complexifying network.
Thus, simplify coevolution was run just as complexifying coevolution, except that the
initial topology contained 339 connections instead of 39, and structural mutations removed
connections instead of adding nodes and connections. If all connections of a node were
removed, the node itself was removed. Historical markings and speciation worked as in
complexifying NEAT, except that all markings were assigned in the beginning of evolution.
(because structure was only removed and never added). A diversity of species of varying
complexity developed as before.

90

fi149

Dom. Level

15

0

1
Simplifying
Coevolution

Dom. Level

15

0

1

Equivalent
Performance

500

39

339

Generations

500

227

Connections in Dom.

Complexifying
Coevolution

Connections in Dom.

Competitive Coevolution through Evolutionary Complexification

Figure 15: Comparing Typical Runs of Complexifying Coevolution and Simplifying Coevolution. Dominance levels are charted as in figure 12. In addition, the line plot
shows the complexity of each dominance level in terms of number of connections in the
networks with scale indicated in the y-axis at right. In this typical simplifying run, the
number of connections reduced from 339 to 227 connections. The arrow shows that the
highest dominant strategy found in simplifying coevolution only performs as well as the
9th or 10th dominant strategy of complexifying coevolution, which is normally found
after 56 generations (sd = 31). In other words, even though simplifying coevolution
finds more dominance levels, the search for appropriate structure is less effective than
that of complexifying coevolution.

The five runs of simplifying coevolution performed at 64.8%, 60.9%, 56.6%, 36.4%, and
67.9%, with an overall average of 57.3% (sd=19.8%). Again, such performance is significantly below the 91.4% performance of complexifying coevolution (p < 0.001). Interestingly,
even though it started with 76 more connections than fixed-topology coevolution with ten
hidden units, simplifying coevolution still performed significantly better (p < 0.001), suggesting that evolving structure through reducing complexity is better than evolving large
fixed structures.
Like Figures 1214, Figure 15 compares typical runs of complexifying and simplifying
coevolution. On average, 500 generations of simplification finds solutions equivalent to 56
generations of complexification. Simplifying coevolution also tends to find more dominance
levels than any other method tested. It generated an average of 23.2 dominance levels per
run, once even finding 30 in one run, whereas e.g. complexifying coevolution on average
finds 15.2 levels. In other words, the difference between dominance levels is much smaller in
91

fiStanley & Miikkulainen

Coevolution Type Ave. Highest Ave. Highest
Average
Dom. Level
Generation Performance

Equivalent
Generation
(out of 500)
91.4%
343
40.4%
24

Complexifying
15.2
353.6
Fixed-Topology
12.0
172
10 Hidden Node
Fixed-Topology
13.0
291.4
80.3%
159
5 Hidden Node
Fixed-Topology
14.0
301.8
82.4%
193
Best Network
Simplifying
23.2
444.2
57.3%
56
Table 1: Summary of the performance comparison. The second column shows how
many levels of dominance were achieved in each type of coevolution on average. The third
specifies the average generation of the highest dominant strategy, indicating how long innovation generally continues. The fourth column gives the average level in the complexifying
coevolution dominance hierarchy that the champion could defeat, and the fifth column shows
its average generation. The differences in performance (p < 0.001) and equivalent generation (p < 0.001) between complexifying coevolution and every other method are significant.
The main result is that the level of sophistication reached by complexifying coevolution is
significantly higher than that reached by fixed-topology or simplifying coevolution.
simplifying coevolution than complexifying coevolution. Unlike in other methods, dominant
strategies tend to appear in spurts of a few at a time, and usually after complexity has
been decreasing for several generations, as also shown in Figure 15. Over a number of
generations, evolution removes several connections until a smaller, more easily optimized
space is discovered. Then, a quick succession of minute improvements creates several new
levels of dominance, after which the space is further refined, and so on. While such a process
makes sense, the inferior results of simplifying coevolution suggest that simplifying search
is an ineffective way of discovering useful structures compared to complexification.
6.3.6 Comparison Summary
Table 1 shows how the coevolution methods differ on number of dominance levels, generation of the highest dominance level, overall performance, and equivalent generation. The
conclusion is that complexifying coevolution innovates longer and finds a higher level of
sophistication than the other methods.

7. Discussion and Future Work
What makes complexification such a powerful search method? Whereas in fixed-topology
coevolution, as well as in simplifying coevolution, the good structures must be optimized
in the high-dimensional space of the solutions themselves, complexifying coevolution only
searches high-dimensional structures that are elaborations of known good lower-dimensional
structures. Before adding a new dimension, the values of the existing genes have already
been optimized over preceding generations. Thus, after a new gene is added, the genome is

92

fiCompetitive Coevolution through Evolutionary Complexification

already in a promising part of the new, higher-dimensional space. Thus, the search in the
higher-dimensional space is not starting blindly as it would if evolution began searching in
that space. It is for this reason that complexification can find high-dimensional solutions
that fixed-topology coevolution and simplifying coevolution cannot.
Complexification is particularly well suited for coevolution problems. When a fixed
genome is used to represent a strategy, that strategy can be optimized, but it is not possible
to add functionality without sacrificing some of the knowledge that is already present. In
contrast, if new genetic material can be added, sophisticated elaborations can be layered
above existing structure, establishing an evolutionary arms race. This process was evident
in the robot duel domain, where successive dominant strategies often built new functionality
on top of existing behavior by adding new nodes and connections.
The advantages of complexification do not imply that fixed-sized genomes cannot sometimes evolve increasingly complex phenotypic behavior. Depending on the mapping between
the genotype and the phenotype, it may be possible for a fixed, finite set of genes to represent
solutions (phenotypes) with varying behavioral complexity. For example, such behaviors
have been observed in Cellular Automata (CA), a computational structure consisting of a
lattice of cells that change their state as a function of their own current state and the state
of other cells in their neighborhood. This neighborhood function can be represented in a
genome of size 2n+1 (assuming n neighboring cells with binary state) and evolved to obtain
desired target behavior. For example, Mitchell et al. (1996) were able to evolve neighborhood functions to determine whether black or white cells were in the majority in the CA
lattice. The evolved CAs displayed complex global behavior patterns that converged on a
single classification, depending on which cell type was in the majority. Over the course of
evolution, the behavioral complexity of the CA rose even as the genome remained the same
size.
In the CA example, the correct neighborhood size was chosen a priori. This choice is
difficult to make, and crucial for success. If the desired behavior had not existed within the
chosen size, even if the behavior would become gradually more complex, the system would
never solve the task. Interestingly, such a dead-end could be avoided if the neighborhood
(i.e. the genome) could be expanded during evolution. It is possible that CAs could be
more effectively evolved by complexifying (i.e. expanding) the genomes, and speciating to
protect innovation, as in NEAT.
Moreover, not only can the chosen neighborhood be too small to represent the solution,
but it can also be unnecessarily large. Searching in a space of more dimensions than
necessary can impede progress, as discussed above. If the desired function existed in a
smaller neighborhood it could have been found with significantly fewer evaluations. Indeed,
it is even possible that the most efficient neighborhood is not symmetric, or contains cells
that are not directly adjacent to the cell being processed. Moreover, even the most efficient
neighborhood may be too large a space in which to begin searching. Starting search in a
small space and incrementing into a promising part of higher-dimensional space is more
likely to find a solution. For these reasons, complexification can be an advantage, even if
behavioral complexity can increase to some extent within a fixed space.
The CA example raises the intriguing possibility that any structured phenotype can
be evolved through complexification from a minimal starting point, historical markings,
and the protection of innovation through speciation. In addition to neural networks and
93

fiStanley & Miikkulainen

CA, electrical circuits (Miller et al., 2000a; Miller, Job, & Vassilev, 2000b), genetic programs (Koza, 1992), robot body morphologies (Lipson & Pollack, 2000), Bayesian networks
(Mengshoel, 1999), finite automata (Brave, 1996), and building and vehicle architectures
(OReilly, 2000) are all structures of varying complexity that can benefit from complexification. By starting search in a minimal space and adding new dimensions incrementally,
highly complex phenotypes can be discovered that would be difficult to find if search began
in the intractable space of the final solution, or if it was prematurely restricted to too small
a space.
The search for optimal structures is a common problem in Artificial Intelligence (AI).
For example, Bayesian methods have been applied to learning model structure (Attias, 2000;
Ueda & Ghahramani, 2002). In these approaches, the posterior probabilities of different
structures are computed, allowing overly complex or simplistic models to be eliminated.
Note that these approaches are not aimed at generating increasingly complex functional
structures, but rather at providing a model that explains existing data. In other cases,
solutions involve growing gradually larger structures, but the goal of the growth is to form
gradually better approximations. For example, methods like Incremental Grid Growing
(Blackmore & Miikkulainen, 1995), and Growing Neural Gas (Fritzke, 1995) add neurons
to a network until it approximates the topology of the input space reasonably well. On the
other hand, complexifying systems do not have to be non-deterministic (like NEAT), nor do
they need to be based on evolutionary algorithms. For example, Harvey (1993) introduced a
deterministic algorithm where the chromosome lengths of the entire population increase all
at the same time in order to expand the search space; Fahlman & Lebiere (1990) developed
a supervised (non-evolutionary) neural network training method called cascade correlation,
where new hidden neurons are added to the network in a predetermined manner in order to
complexify the function it computes. The conclusion is that complexification is an important
general principle in AI.
In the future, complexification may help with the general problem of finding the appropriate level of abstraction for difficult problems. Complexification can start out with
a simple, high-level description of the solution, composed of general-purpose elements. If
such an abstraction is insufficient, it can be elaborated by breaking down each high-level
element into lower level and more specific components. Such a process can continue indefinitely, leading to increasingly complex substructures, and increasingly low-level solutions
to subproblems. Although in NEAT the solutions are composed of only connections and
nodes, it does provide an early example of how such a process could be implemented.
One of the primary and most elusive goals of AI is to create systems that scale up. In
a sense, complexification is the process of scaling up. It is the general principle of taking a
simple idea and elaborating it for broader application. Much of AI is concerned with search,
whether over complex multi-dimensional landscapes, or through highly-branching trees of
possibilities. However, intelligence is as much about deciding what space to search as it is
about searching once the proper space has already been identified. Currently, only humans
are able to decide the proper level of abstraction for solving many problems, whether it be a
simple high-level combination of general-purpose parts, or an extremely complex assembly
of low-level components. A program that can decide what level of abstraction is most
appropriate for a given domain would be a highly compelling demonstration of Artificial

94

fiCompetitive Coevolution through Evolutionary Complexification

Intelligence. This is, we believe, where complexification methods can have their largest
impact in the future.

8. Conclusion
The experiments presented in this paper show that complexification of genomes leads to
continual coevolution of increasingly sophisticated strategies. Three trends were found in
the experiments: (1) As evolution progresses, complexity of solutions increases, (2) evolution uses complexification to elaborate on existing strategies, and (3) complexifying coevolution is significantly more successful in finding highly sophisticated strategies than
non-complexifying coevolution. These results suggest that complexification is a crucial
component of a successful search for complex solutions.

Acknowledgments
This research was supported in part by the National Science Foundation under grant IIS0083776 and by the Texas Higher Education Coordinating Board under grant ARP-003658476-2001. Special thanks to an anonymous reviewer for constructive suggestions for noncomplexifying comparisons.

Appendix A. NEAT System Parameters
Each population had 256 NEAT networks, for a total of 512. The coefficients for measuring
compatibility were c1 = 1.0, c2 = 1.0, and c3 = 2.0. The initial compatibility distance was
t = 3.0. However, because population dynamics can be unpredictable over hundreds of
generations, we assigned a target of 10 species. If the number of species grew above 10, t
was increased by 0.3 to reduce the number of species. Conversely, if the number of species
fell below 10, t was decreased by 0.3 to increase the number of species. The normalization
factor N used to compute compatibility was fixed at one. In order to prevent stagnation,
the lowest performing species over 30 generations old was not allowed to reproduce. The
champion of each species with more than five networks was copied into the next generation
unchanged. There was an 80% chance of a genome having its connection weights mutated, in
which case each weight had a 90% chance of being uniformly perturbed and a 10% chance of
being assigned a new random value. (The system is tolerant to frequent mutations because
of the protection speciation provides.) There was a 75% chance that an inherited gene was
disabled if it was disabled in either parent. In 40% of crossovers, the offspring inherited
the average of the connection weights of matching genes from both parents, instead of
the connection weight of only one parent randomly. In each generation, 25% of offspring
resulted from mutation without crossover. The interspecies mating rate was 0.05. The
probability of adding a new node was 0.01 and the probability of a new link mutation
1
was 0.1. We used a modified sigmoidal transfer function, (x) = 1+e4.9x
, at all nodes.
These parameter values were found experimentally, and they follow a logical pattern: Links
need to be added significantly more often than nodes, and an average weight difference
of 0.5 is about as significant as one disjoint or excess gene. Performance is robust to

95

fiStanley & Miikkulainen

moderate variations in these values. NEAT software is available in the software section at
http://nn.cs.utexas.edu.

Appendix B. Robot Duel Domain Coefficients of Motion
The turn angle  is determined as  = 0.24|lr|, where l is the output of the left turn neuron,
and r is the output of the right turn neuron. The robot moves forward a distance of 1.33f
on the 600 by 600 board, where f is the forward motion output. These coefficients were
calibrated through experimentation to achieve accurate and smooth motion with neural
outputs between zero and one.

References
Amores, A., Force, A., Yan, Y.-L., Joly, L., Amemiya, C., Fritz, A., Ho, R. K., Langeland,
J., Prince, V., Wang, Y.-L., Westerfield, M., Ekker, M., & Postlethwait, J. H. (1998).
Zebrafish HOX clusters and vertebrate genome evolution. Science, 282, 17111784.
Angeline, P. J., & Pollack, J. B. (1993). Competitive environments evolve better solutions for
complex tasks. In Forrest, S. (Ed.), Proceedings of the Fifth International Conference
on Genetic Algorithms (pp. 264270). San Francisco, CA: Morgan Kaufmann.
Angeline, P. J., Saunders, G. M., & Pollack, J. B. (1993). An evolutionary algorithm
that constructs recurrent neural networks. IEEE Transactions on Neural Networks, 5,
5465.
Attias, H. (2000). A variational bayesian framework for graphical models. In Advances
in Neural Information Processing Systems, 12 (pp. 209215). Cambridge, MA: MIT
Press.
Blackmore, J., & Miikkulainen, R. (1995). Visualizing high-dimensional structure with the
incremental grid growing neural network. In Prieditis, A., & Russell, S. (Eds.), Machine
Learning: Proceedings of the 12th Annual Conference (pp. 5563). San Francisco, CA:
Morgan Kaufmann.
Brave, S. (1996). Evolving deterministic finite automata using cellular encoding. In Koza,
J. R., Goldberg, D. E., Fogel, D. B., & Riolo, R. L. (Eds.), Genetic Programming
1996: Proceedings of the First Annual Conference (pp. 3944). Stanford University,
CA, USA: MIT Press.
Carroll, S. B. (1995). Homeotic genes and the evolution of arthropods and chordates.
Nature, 376, 479485.
Cliff, D., Harvey, I., & Husbands, P. (1993). Explorations in evolutionary robotics. Adaptive
Behavior, 2, 73110.
Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics
of Control, Signals, and Systems, 2 (4), 303314.

96

fiCompetitive Coevolution through Evolutionary Complexification

Darwen, P. J. (1996). Co-Evolutionary Learning by Automatic Modularisation with Speciation. Doctoral Dissertation, School of Computer Science, University College, University
of New South Wales.
Dawkins, R., & Krebs, J. R. (1979). Arms races between and within species. Proceedings
of the Royal Society of London Series B, 205, 489511.
Fahlman, S. E., & Lebiere, C. (1990). The cascade-correlation learning architecture. In
Touretzky, D. S. (Ed.), Advances in Neural Information Processing Systems 2 (pp.
524532). San Francisco, CA: Morgan Kaufmann.
Ficici, S. G., & Pollack, J. B. (2001). Pareto optimality in coevolutionary learning. In
Kelemen, J. (Ed.), Sixth European Conference on Artificial Life. Berlin; New York:
Springer-Verlag.
Floreano, D., & Nolfi, S. (1997). God save the red queen! Competition in co-evolutionary
robotics. Evolutionary Computation, 5.
Force, A., Lynch, M., Pickett, F. B., Amores, A., lin Yan, Y., & Postlethwait, J. (1999).
Preservation of duplicate genes by complementary, degenerative mutations. Genetics,
151, 15311545.
Fritzke, B. (1995). A growing neural gas network learns topologies. In G.Tesauro,
D.S.Touretzky, & T.K.Leen (Eds.), Advances in Neural Information Processing Systems 7 (pp. 625632). Cambridge, MA: MIT Press.
Goldberg, D. E., & Richardson, J. (1987). Genetic algorithms with sharing for multimodal
function optimization. In Grefenstette, J. J. (Ed.), Proceedings of the Second International Conference on Genetic Algorithms (pp. 148154). San Francisco, CA: Morgan
Kaufmann.
Gomez, F., & Miikkulainen, R. (1997). Incremental evolution of complex general behavior.
Adaptive Behavior, 5, 317342.
Gruau, F., Whitley, D., & Pyeatt, L. (1996). A comparison between cellular encoding and
direct encoding for genetic neural networks. In Koza, J. R., Goldberg, D. E., Fogel,
D. B., & Riolo, R. L. (Eds.), Genetic Programming 1996: Proceedings of the First
Annual Conference (pp. 8189). Cambridge, MA: MIT Press.
Harvey, I. (1993). The Artificial Evolution of Adaptive Behavior . Doctoral Dissertation,
School of Cognitive and Computing Sciences, University of Sussex, Sussex.
Holland, P. W., Garcia-Fernandez, J., Williams, N. A., & Sidow, A. (1994). Gene duplications and the origin of vertebrate development. Development Supplement, pp. 125133.
Jim, K.-C., & Giles, C. L. (2000). Talking helps: Evolving communicating agents for the
predator-prey pursuit problem. Artificial Life, 6 (3), 237254.

97

fiStanley & Miikkulainen

Koza, J. (1995). Gene duplication to enable genetic programming to concurrently evolve
both the architecture and work-performing steps of a computer program. In Proceedings of the 14th International Joint Conference on Artificial Intelligence. Morgan
Kaufmann.
Koza, J. R. (1992). Genetic Programming: On the Programming of Computers by Means
of Natural Selection. Cambridge, MA: MIT Press.
Lindgren, K., & Johansson, J. (2001). Coevolution of strategies in n-person prisoners
dilemma. In Crutchfield, J., & Schuster, P. (Eds.), Evolutionary Dynamics - Exploring
the Interplay of Selection, Neutrality, Accident, and Function. Reading, MA: AddisonWesley.
Lipson, H., & Pollack, J. B. (2000). Automatic design and manufacture of robotic lifeforms.
Nature, 406, 974978.
Mahfoud, S. W. (1995). Niching Methods for Genetic Algorithms. Doctoral Dissertation,
University of Illinois at Urbana-Champaign, Urbana, IL.
Maley, C. C. (1999). Four steps toward open-ended evolution. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-1999) (pp. 13361343). San
Francisco, CA: Morgan Kaufmann.
Martin, A. P. (1999). Increasing genomic complexity by gene duplication and the origin of
vertebrates. The American Naturalist, 154 (2), 111128.
Mengshoel, O. J. (1999). Efficient Bayesian Network Inference: Genetic Algorithms,
Stochastic Local Search, and Abstraction. Doctoral Dissertation, University of Illinois
at Urbana-Champaign Computer Science Department, Urbana-Champaign, IL.
Miller, G., & Cliff, D. (1994). Co-evolution of pursuit and evasion i: Biological and gametheoretic foundations. Tech. Rep. CSRP311, School of Cognitive and Computing Sciences, University of Sussex, Brighton, UK.
Miller, J. F., Job, D., & Vassilev, V. K. (2000a). Principles in the evolutionary design of
digital circuits  Part I. Journal of Genetic Programming and Evolvable Machines,
1 (1), 835.
Miller, J. F., Job, D., & Vassilev, V. K. (2000b). Principles in the evolutionary design of
digital circuits  Part II. Journal of Genetic Programming and Evolvable Machines,
3 (2), 259288.
Mitchell, M., Crutchfield, J. P., & Das, R. (1996). Evolving cellular automata with genetic
algorithms: A review of recent work. In Proceedings of the First International Conference on Evolutionary Computation and Its Applications (EvCA96). Russian Academy
of Sciences.
Mondada, F., Franzi, E., & Ienne, P. (1993). Mobile robot miniaturization: A tool for investigation in control algorithms. In Proceedings of the Third International Symposium
on Experimental Robotics (pp. 501513).
98

fiCompetitive Coevolution through Evolutionary Complexification

Nadeau, J. H., & Sankoff, D. (1997). Comparable rates of gene loss and functional divergence
after genome duplications early in vertebrate evolution. Genetics, 147, 12591266.
Noble, J., & Watson, R. A. (2001). Pareto coevolution: Using performance against coevolved opponents in a game as dimensions for parerto selection. In et al, L. S. (Ed.),
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2001).
San Francisco, CA: Morgan Kaufmann.
OReilly, U.-M. (2000). Emergent design: Artificial life for architecture design. In 7th
International Conference on Artificial Life (ALIFE-00). Cambridge, MA: MIT Press.
Postlethwait, H. H., Yan, Y. L., Gates, M. A., Horne, S., Amores, A., Brownlie, A., &
Donovan, A. (1998). Vertebrate genome evolution and the zebrafish gene map. Nature
Genetics, 18, 345349.
Radcliffe, N. J. (1993). Genetic set recombination and its application to neural network
topology optimization. Neural computing and applications, 1 (1), 6790.
Radding, C. M. (1982). Homologous pairing and strand exchange in genetic recombination.
Annual Review of Genetics, 16, 405437.
Reggia, J. A., Schulz, R., Wilkinson, G. S., & Uriagereka, J. (2001). Conditions enabling
the evolution of inter-agent signaling in an artificial world. Artificial Life, 7, 332.
Rosin, C. D. (1997). Coevolutionary Search Among Adversaries. Doctoral Dissertation,
University of California, San Diego, San Diego, CA.
Rosin, C. D., & Belew, R. K. (1997). New methods for competitive evolution. Evolutionary
Computation, 5.
Ryan, C. (1994). Pygmies and civil servants. In Kinnear, Jr., K. E. (Ed.), Advances in
Genetic Programming (Chap. 11, pp. 243263). MIT Press.
Sidow, A. (1996). Gen(om)e duplications in the evolution of early vertebrates. Current
Opinion in Genetics and Development, 6, 715722.
Sigal, N., & Alberts, B. (1972). Genetic recombination: The nature of a crossed strandexchange between two homologous DNA molecules. Journal of Molecular Biology,
71 (3), 789793.
Sims, K. (1994). Evolving 3D morphology and behavior by competition. In Brooks, R. A.,
& Maes, P. (Eds.), Proceedings of the Fourth International Workshop on the Synthesis
and Simulation of Living Systems (Artificial Life IV) (pp. 2839). Cambridge, MA:
MIT Press.
Spears, W. (1995). Speciation using tag bits. In Handbook of Evolutionary Computation.
IOP Publishing Ltd. and Oxford University Press.

99

fiStanley & Miikkulainen

Stanley, K. O., & Miikkulainen, R. (2002a). The dominance tournament method of monitoring progress in coevolution. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2002) Workshop Program. San Francisco, CA: Morgan
Kaufmann.
Stanley, K. O., & Miikkulainen, R. (2002b). Efficient evolution of neural network topologies.
In Proceedings of the 2002 Congress on Evolutionary Computation (CEC02). IEEE.
Stanley, K. O., & Miikkulainen, R. (2002c). Efficient reinforcement learning through evolving neural network topologies. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2002). San Francisco, CA: Morgan Kaufmann.
Stanley, K. O., & Miikkulainen, R. (2002d). Evolving neural networks through augmenting
topologies. Evolutionary Computation, 10 (2), 99127.
Ueda, N., & Ghahramani, Z. (2002). Bayesian model search for mixture models based on
optimizing variational bounds. Neural Networks, 15, 12231241.
Van Valin, L. (1973). A new evolutionary law. Evolution Theory, 1, 130.
Yao, X. (1999). Evolving artificial neural networks. Proceedings of the IEEE, 87 (9), 1423
1447.
Zhang, B.-T., & Muhlenbein, H. (1993). Evolving optimal neural networks using genetic
algorithms with Occams razor. Complex Systems, 7, 199220.

100

fiJournal of Artificial Intelligence Research 21 (2004) 1936

Submitted 7/03; published 1/04

Price Prediction in a Trading Agent Competition
Michael P. Wellman
Daniel M. Reeves
Kevin M. Lochner
Yevgeniy Vorobeychik

WELLMAN @ UMICH . EDU
DREEVES @ UMICH . EDU
KLOCHNER @ UMICH . EDU
YVOROBEY @ UMICH . EDU

University of Michigan, Artificial Intelligence Laboratory
Ann Arbor, MI 48109-2110 USA

Abstract
The 2002 Trading Agent Competition (TAC) presented a challenging market game in the domain of travel shopping. One of the pivotal issues in this domain is uncertainty about hotel prices,
which have a significant influence on the relative cost of alternative trip schedules. Thus, virtually
all participants employ some method for predicting hotel prices. We survey approaches employed
in the tournament, finding that agents apply an interesting diversity of techniques, taking into account differing sources of evidence bearing on prices. Based on data provided by entrants on their
agents actual predictions in the TAC-02 finals and semifinals, we analyze the relative efficacy of
these approaches. The results show that taking into account game-specific information about flight
prices is a major distinguishing factor. Machine learning methods effectively induce the relationship between flight and hotel prices from game data, and a purely analytical approach based on
competitive equilibrium analysis achieves equal accuracy with no historical data. Employing a new
measure of prediction quality, we relate absolute accuracy to bottom-line performance in the game.

1. Introduction
Many market decision problems involve some anticipation or forecast of future prices. Price prediction is particularly important, for example, in committing to a binding offer to purchase a good
that has complements to be purchased at a later date. This sort of scenario arises whenever there are
sequential or overlapping auctions for related goods. Although market forecasting techniques are in
widespread use over a broad range of applications, we are unaware of studies exploring the problem
in a context reminiscent of multi-auction environments.
The annual Trading Agent Competition (TAC) (Wellman et al., 2003) provides a convenient
medium for studying approaches to price prediction. As an open-invitation tournament, it has attracted a diverse community of researchers interested in many aspects of trading agent strategy.
Price prediction has turned out to be a pivotal issue in the TAC market game, 1 and an interesting array of approaches has emerged from agent designers efforts over three years of competition. Since
TAC defines a controlled, regular, repeatable, and transparent environment for observing trading
agent behavior, it is also uncommonly amenable to analysis.

1. We refer to the original (classic) TAC game, a scenario in the domain of travel shopping. Sadeh et al. (2003)
introduced a second game (TAC/SCM), in the domain of supply chain management, and we expect that further
domains will be the subject of trading competitions in coming years.

c 2004 AI Access Foundation. All rights reserved.

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

2. TAC Travel-Shopping Game
The TAC market game presents a travel-shopping task, where traders assemble flights, hotels, and
entertainment into trips for a set of eight probabilistically generated clients. Clients are described
by their preferred arrival and departure days (pa and pd), the premium (hp) they are willing to pay
to stay at the Towers (T) hotel rather than Shanties (S), and their values for three different types
of entertainment events. The agents objective is to maximize the value of trips for their clients, net
of expenditures in the markets for travel goods.
Flights. A feasible trip includes round-trip air, which consists of an inflight day and outflight
 
. Flights in and out each day are sold independently, at prices determined by
day  ,
a stochastic process. The initial price for each flight is    , and follows a random walk
thereafter with an increasingly upward bias.
Hotels. Feasible trips must also include a room in one of the two hotels for each night of the
clients stay. There are 16 rooms available in each hotel each night, and these are sold through
ascending 16th-price auctions. When the auction closes, the units are allocated to the 16 highest
offers, with all bidders paying the price of the lowest winning offer. Each minute, the hotel auctions
issue quotes, indicating the 16th- (ASK) and 17th-highest (BID) prices among the currently active
unit offers. Each minute, starting at 4:00, one of the hotel auctions is selected at random to close,
with the others remaining active and open for bids.
Entertainment. Agents receive an initial random allocation of entertainment tickets (indexed by
type and day), which they may allocate to their own clients or sell to other agents through continuous
double auctions.
A feasible client trip  is defined by an inflight day in , outflight day out , and hotel type ( ,
which is 1 if T and 0 if S). Trips also specify entertainment allocations, but for purposes of this paper
we summarize expected entertainment surplus  as a function of trip days. (The paper describing
our agent (Cheng et al., 2004) provides details on  as well as some other constructs glossed
here.) The value of this trip for client  (with preferences pa, pd, hp) is then given by
	  

	   pa  in  
 pd  out  
 hp   
 


(1)

At the end of a game instance, the TAC server calculates the optimal allocation of trips to clients
for each agent, given final holdings of flights, hotels, and entertainment. The agents game score is
its total client trip utility, minus net expenditures in the TAC auctions.

3. Price Prediction
TAC participants recognized early on the importance of accurate price prediction in overall performance (Stone & Greenwald, 2004). The prices of hotels are highly variable from game to game,
yet a hotels price is not finalized until its auction closessome minutes into the game, depending
on the random closing order. Because agents tend not to submit serious hotel bids until the first
closing is imminent, no useful information is revealed by price quotes until the fourth minute of
play. Complementarity among goods dictates that outcomes of early auctions significantly affect
the value an agent places on a particular hotel later in the game, and conversely, the prices of hotels
available later dictate whether an agent had bid wisely early in the game.
Anticipating hotel prices is a key element in several decisions facing a TAC agent, in particular:
20

fiTAC P RICE P REDICTION

1. Selecting trip itineraries. Because flight prices tend to increase, agents have a great incentive
to commit to traveling on particular days early in the game. Yet the quality of day choices
depends crucially on the hotel prices of the included travel days.
2. Bidding policy. The likelihood of obtaining a good with a given bid depends obviously on the
resulting clearing price. Moreover, the value of any particular good is in general a function of
the price of others. For example, the value of obtaining a room at hotel (S, ) is an increasing
function of the projected cost of the alternative hotel on that day, (T, ), and a decreasing
function of the projected cost of complementary hotel rooms on the adjacent days, (S,  )
and (S, 
 ).
Given the importance of price prediction, it is not surprising that TAC researchers have explored
a variety of approaches. Stone et al. (2003) noted a diversity of price estimation methods among
TAC-01 agents. Our particular interest in the problem is certainly connected to our own TAC-02
agent, Walverine, which introduced a method quite distinct from those reported previously. Thus,
we were highly motivated to characterize performance on this price prediction task.
Indeed, if competitions such as TAC are to be successful in facilitating research, it will be necessary to separately evaluate techniques developed for problem subtasks (Stone, 2002). Although
interesting subtasks tend not to be strictly separable in such a complex game, the price-prediction
component of trading strategy may be easier to isolate than most. In particular, the problem can be
formulated in its own terms, with natural absolute accuracy measures. And in fact, as we see below,
most agent developers independently chose to define price prediction as a distinct task in their own
agent designs.
We divide price prediction into two phases: initial and interim. Initial refers to the beginning
of the game, before any hotel auctions close or provide quote information. Interim refers to the
method employed thereafter. Since the information available for initial prediction (flight prices,
client preferencessee Section 5.2) is a strict subset of that available for interim (which adds transaction and hotel price data), most agents treat initial prediction as just a (simpler) special case.
Initial prediction is relevant to bidding policy for the first hotel closing, and especially salient for
trip choices as these are typically made early in the game. Interim prediction supports ongoing revision of bids as the hotel auctions start to close. Our analysis and report focus on initial prediction,
mainly because it is the simpler of the two tasks, involving less potential information. Moreover,
agents initially have relatively comparable information sets, thus providing for a cleaner analysis.
Interim prediction is also quite important and interesting, and should be the focus of further work.

4. TAC-02 Agents
The nineteen agents who participated in the TAC-02 tournament are listed in Table 1. The table
presents raw average scores from the finals and semifinals, and weighted averages for the seeding
round. For overviews of most of these agents, see the survey edited by Greenwald (2003a).
The seeding rounds were held during the period 1-12 July, each agent playing 440 games.
Weights increased each day, so that later games counted more than earlier, and the lowest 10 scores
for each agent were dropped. The top 16 agents advanced to the semifinals, held on 28 July in
Edmonton, Canada. There were two semifinal heats: H1 comprising agents seeded 1-4 and 13-16,
with the 5-12 seeds placed in heat H2. The top four teams from each heat (14 games, lowest score
21

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

Agent
ATTac
BigRed
cuhk
harami
kavayaH
livingagents
PackaTAC
PainInNEC
RoxyBot
sics
SouthamptonTAC
Thalis
tniTac
TOMAhack
tvad
UMBCTAC
Walverine
WhiteBear
zepp

Affiliation
AT&T Research (et al.)
McGill U
Chinese U Hong Kong
Bogazici U
Oracle India
Living Systems AG
N Carolina State U
NEC Research (et al.)
Brown U
Swedish Inst Comp Sci
U Southampton
U Essex
Poli Bucharest
U Toronto
Technion
U Maryland Baltimore Cty
U Michigan
Cornell U
Poli Bucharest

Seeding
3131
696
3055
2064
2549
3091
2835
2319
2855
2847
3129
3000
2232
2809
2618
3118
2772
2966
2098

Semifinals
H1: 3137

H2: 3266

H1: 3200
H1: 3310
H2: 3250
H1: 2193
H2: 3160
H2: 3146
H1: 3397
H2: 3199
H1: 3108
H2: 2843
H1: 2724
H1: 3208
H2: 3287
H2: 3324


Finals


3069

3099
3181




3385
3246



3236
3210
3413


Table 1: TAC-02 tournament participants, and their scores by round.

dropped) proceeded to the finals, which ran for 32 games the same day. Further details about the
TAC-02 tournament are available at http://www.sics.se/tac.

5. Price Prediction Survey
Shortly after the TAC-02 event, we distributed a survey to all the entrants eliciting descriptions and
data documenting their agents price-prediction methods. Sixteen out of 19 teams responded to the
survey, including 14 of 16 semifinalists, and all eight finalists. The result provides a detailed picture
of the prediction techniques employed, and enables some comparison of their efficacy with respect
to a common experiencethe TAC-02 finals and semifinals.
Thirteen out of the 16 respondents reported that their agents did indeed form explicit price predictions for use in their trading strategies. These thirteen are listed in Table 2, along with some
high-level descriptors of their approach to the initial prediction task. 2 In addition, tniTac and zepp
responded that price predictions were part of their agent designs, but were not developed sufficiently
to be deployed in the tournament. TOMAhack reported an ambitious design (also not actually employed) based on model-free policy learning, which does account for other agents bidding behavior
but without formulating explicit price predictions.
2. Though we address only initial prediction in this report, our survey also solicited descriptions about interim methods.

22

fiTAC P RICE P REDICTION

Agent
ATTac
cuhk
harami
kavayaH
livingagents
PackaTAC
RoxyBot
sics
SouthamptonTAC
Thalis
UMBCTAC
Walverine
WhiteBear

Approach
machine learning
historical
historical
machine learning
historical
historical
historical
historical
historical
historical (?)
historical
competitive
historical

Form
prob
priceline
prob
point
point
prob
prob
priceline
point
point
point
point
point

Notes
boosting
moving average
neural net

classification to reference categories
survey incomplete
equilibrium analysis

Table 2: Agents reporting prediction of hotel prices in TAC-02.

5.1 Forms of Prediction
One distinction observed in TAC-01 was that some agents explicitly formulated predictions in terms
of probability distributions over prices, rather than point estimates. Predictions in this form enable
the agent to properly account for price uncertainty in decision making. Thus, we asked entrants
about the form of their predictions in our survey.
Although most agents generate point predictions, there are notable exceptions. ATTacs boosting algorithm (Stone et al., 2003) expressly learns probability distributions associated with game
features. RoxyBot tabulates game price statistics for a direct estimation of deciles for each hotel
auction. PackaTAC and harami measure historical variance, combining this with historical averaging to define a parametric distribution for each hotel price. Walverine predicts point prices, but its
hedging approach for some decisions amounts to forming an effective distribution around them.
Given a prediction in the form of a distribution, agents may make decisions by sampling or
through other decision-analytic techniques. The distribution may also facilitate the interim prediction task, enabling updates based on treating observations such as price quotes as evidence.
However, the first controlled experiment evaluating the distribution feature, in the context of ATTac
(Stone et al., 2003), did not find an overall advantage to decision-making based on distributions
compared to using mean values. The authors offered several possible explanations for the observed
performance, including (1) that their implementation employs insufficient samples, and (2) that their
use of distributions makes the unrealistic assumption that subsequent decisions can be made with
full knowledge of the actual price values. Greenwald (2003b) also found that bidding marginal utility based on means outperformed bidding expected marginal utility based on distributions, this time
implemented in the context of RoxyBot. We have since performed analogous trials using Walverinewhich generates and applies distributions in yet a third wayand also found bidding based
on means to be superior to the distribution-based bidding the agent actually employed in TAC-02.
Although the source of this deficiency has not been conclusively established, we speculate that the
second reason adduced by the ATTac designers is most plausible.
23

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

Despite this evidence, alternative ways of using the distributions may well prove beneficial. The
study by Greenwald (2003b) demonstrated an advantage to RoxyBots 2002 strategy of evaluating
candidate bid sets with respect to distributions, compared to its 2000 strategy of evaluating them
with respect to means.
Nevertheless, for agents that predict probability distributions, we take the mean of these distributions as the subject of our analysis. This may discount potential advantages, but based on
the discussion above, we suspect thatwith the possible exception of RoxyBotagents did not
actually benefit from predicting distributions in TAC-02.
Another variation in form is the prediction of prices as a function of quantity demanded. From
the first TAC, entrants recognized that purchasing additional units may cause the price to increase,
and so introduced the concept of pricelines, which express estimated prices by unit (Boyan & Greenwald, 2001; Stone & Greenwald, 2004). Agents sics and cuhk reported predicting pricelines. 3 In
both cases, the agent started with a baseline point prediction for the first unit of each hotel, and
derived the remainder of the priceline according to some rule. For example, sics predicted the price
for the ffth unit (i.e., price given it demands ff units) to be fi  , where fi is the baseline prediction
and  is 1.15 for hotels on day 1 or 4, and 1.25 for hotels on day 2 or 3.
In the succeeding analysis, we evaluate predictions in terms of baseline prices only. As noted
below, our accuracy measures applied to pricelines would not reflect their actual value.
5.2 Information Employed
The set of information potentially available at the beginning of the game includes all data from past
games, the initial vector of flight prices, and the agents own client preferences. For TAC-02, all
agents except Walverine reported using historical information in their predictions. Only ATTac,
kavayaH, and Walverine employ flight prices. All agents that construct pricelines effectively take
account of own client preferences. Walverine does not construct pricelines but does factor in its
own client preferences as part of its equilibrium calculations.
The identities of other agents participating in a game instance are not known during the TAC
preliminary (qualifying and seeding) rounds, as agents are drawn randomly into a round-robin tournament. However, the semifinal and final rounds fixed a set of eight agents for a series of games,
and so the identity of other agents was effectively observable. ATTac is the only agent to exploit the
availability of this information.

6. Approaches to Price Prediction
Based on survey responses, we divide TAC-02 prediction techniques into three categories.
6.1 Historical Averaging
Most agents took a relatively straightforward approach to initial price prediction, estimating the
hotel clearing prices according to observed historical averages. For example, harami calculates the
mean hotel prices for the preceding 200 games, and uses this as its initial prediction. The respective
agents classified as adopting the historical approach in Table 2 differ on what set of games they
3. WhiteBear also reported using pricelines for interim prediction (Vetsikas & Selman, 2003), but initial predictions
were essentially points.

24

fiTAC P RICE P REDICTION

include in the average, but most used games from the seeding round. Given a dataset, agents tend
to use the sample mean or distribution itself as the estimate, 4 at least as the baseline.
The majority of averaging agents fixed a pool of prior games, and did not update the averages
during the finals. An exception was cuhk, which employed a moving average of the previous ten
games in the current round, or from previous rounds at the beginning of a new round.
UMBCTAC reported employing mean prices as predictions with respect to decisions about trips
of two or more days, but median prices (which tended to be lower) for decisions about one-day
trips. For the semifinals they based their statistics on the last 100 seeding games. For the finals
their dataset comprised the 14 games of their semifinal heat. In our analysis below, we attribute
predictions to UMBCTAC based on the mean values from these samples.
The approach taken by SouthamptonTAC (He & Jennings, 2003) was unique among TAC
agents. The SouthamptonTAC designers partitioned the seeding-round games into three categories, competitive, non-competitive, and semi-competitive. They then specified a reference
price for each type and day of hotel in each game category. The agent then chooses a category for
any game based on its monitoring of recent game history. In the actual tournament, SouthamptonTAC began the semifinals predicting the semi-competitive reference prices, maintaining this stance
until switching to non-competitive for the last eight games of the finals.
6.2 Machine Learning
A couple of TAC-02 agents employed machine learning techniques to derive relationships between
observable parameters and resulting hotel prices. The premise of this approach is that game-specific
features provide potentially predictive information, enabling the agent to anticipate hotel price directions before they are manifest in price quotes themselves. Not surprisingly, as noted in Section 5.2,
the two learning agents employed more kinds of information than typical TAC-02 agents.
ATTac predicts prices using a sophisticated boosting-based algorithm for conditional density
estimation (Stone et al., 2003). Development of the technique was expressly motivated by the TAC
price-prediction problem, though the resulting algorithm is quite general. ATTac learns a predictor
for each hotel type and day category (i.e., days 1 and 4 are treated symmetrically, as are 2 and 3).
The predictor applied at the beginning of the game maps the following features into a predicted
price for that hotel:





identity of agents participating in the game,
initial flight prices, and
closing time of each hotel room.

Since the hotel closing times are unknown at game start, this predictor induces a distribution over
price predictions, based on the distribution of hotel closing sequences. This distribution constitutes
ATTacs initial price prediction.
kavayaH (Putchala et al., 2002) predicts initial hotel prices using neural networks trained via
backpropagation. The agent has a separate network for each hotel. The output of each network
4. Several of these agents complement this simple initial prediction with a relatively sophisticated approach to interim
prediction, using the evidence from price quotes to gradually override the initial estimate. All else equal, of course,
straightforwardness is an advantage. Indeed, simplicity was likely a significant ingredient of livingagentss success
in TAC-01 (Fritschi & Dorer, 2002; Wellman et al., 2003).

25

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

is one of a discrete set of prices, where the choice set for each hotel (type, day) was specified by
kavayaHs designers based on historical prices. The inputs for each network are based on initial
flight prices, specifically thresholded differences between flights on adjacent days. For example,
hotel T1 might have a binary input that indicates whether the price difference between inflights on
days 1 and 2 is greater than 50. Hotel S2 might have this input, as well as another based on the
difference in flight prices on days 2 and 3. kavayaHs designers selected the most relevant inputs
based on experiments with the agent.
6.3 Competitive Analysis
Walverines overall approach to TAC markets is to presume that they are well-approximated by
a competitive economy (Cheng et al., 2004). Its method for predicting hotel prices is a literal
application of this assumption. Specifically, it calculates the Walrasian competitive equilibrium of
the TAC economy, defined as the set of prices at which all markets would clear, assuming other
agents behave as price takers (Katzner, 1989). Taking into account the exogenously determined
flight prices, Walverine finds a set of hotel prices that support such an equilibrium, and returns
these values as its prediction for the hotels final prices.
Let  be a vector of hotel prices, consisting of elements fi  denoting the price of hotel type  on
day . Let   denote agent  s demand for hotel  day at these prices, and write the vector of
such demands as  . Aggregate demand is simply the sum of agent demands,  	   .
Prices  constitute a competitive equilibrium if aggregate demand equals aggregate supply for
all hotels. Since there are 16 rooms available for each hotel on each day, we have that in competitive
equilibrium,  	 .
Starting from an initial guess   , Walverine searches for equilibrium prices using the tatonnement protocol, an iterative price adjustment mechanism originally conceived by Walras (Arrow
& Hahn, 1971). Given a specification of aggregate demand, tatonnement iteratively computes a
revised price vector according to the following difference equation:

 	  
     

(2)

Although equilibrium prices are not guaranteed to exist given the discreteness and complementarities of the TAC environment, we have found that this procedure typically produces an approximate
equilibrium well within the 300 iterations Walverine devotes to the prediction calculation.
A critical step of competitive analysis is determining the aggregate demand function. Walverine estimates  as the sum of (1) its own demand based on the eight clients it knows about,
and (2) the expected demand for the other agents (56 clients), based on the specified TAC distribution of client preferences. Our calculation of expected demand for the others is exact, modulo a
summarization of entertainment effects, given an assumption that agent demands are separable by
client (Cheng et al., 2004). This assumption is true at the beginning of the game (hence for initial
prediction), but is invalidated once agents accumulate holdings of flights and hotels. Although the
analytic expression of this expected demand is somewhat complicated, deriving it is not conceptually or computationally difficult.
Note that the larger component of Walverines demand estimation is an expectation over the
defined distribution of client preferences. Therefore, the prices it derives should properly be viewed
as an equilibrium over the expectation, rather than the expected equilibrium prices. The latter might
actually be a more appropriate measure for price prediction. However, since expected equilibrium
26

fiTAC P RICE P REDICTION

is much more computationally expensive than equilibrium of the expectation (and we suspect the
difference would be relatively small for 56 i.i.d. clients), we employ the simpler measure.

7. Predictions
As part of the survey, entrants provided the predictions their agents actually employed in the TAC02 finals and semifinals: a total of 60 games. In many cases, predictions are constant (i.e., the
same for every game), so it is straightforward to evaluate them with respect to the full slate of
final and semifinal games. In two of the cases where initial predictions change every game (ATTac
and Walverine), entrants were able to construct what their agent would have predicted for each
of these games, whether or not they actually participated. In one case (kavayaH), we have partial
data. kavayaH reported its predictions for the 32 final games, and for the semifinal heat in which it
participated (H1), except for one game in which its predictor crashed.
We include two versions of ATTac, corresponding to predictors learned from the 2001 and
2002 preliminary rounds. ATTac01 and ATTac02, respectively, represent the prediction functions
employed in the TAC-01 and TAC-02 finals. In applying the ATTac01 predictor to the TAC-02
finals, its use of agent identity information was disabled.
The price vectors supplied by entrants and employed in our analysis are presented in Table 3.
Prices are rounded to the nearest integer for display, though our analysis employed whatever precision was provided. Agents who condition on game-specific information produce distinct vectors in
each instance, so are not tabulated here.
Agent
harami
livingagents
PackaTAC
RoxyBot5
sics
WhiteBear
SouthamptonTAC S
SouthamptonTAC N
UMBCTAC semifinals
UMBCTAC finals
Actual Mean
Actual Median
Best Euc Dist
Best EVPP
Walverine const

S1
21
27
21
20
30
19
50
20
20
37
68
9
18
28
28

S2
58
118
116
103
100
102
100
30
133
75
85
48
73
51
76

S3
80
124
119
103
100
96
100
30
124
87
97
38
57
67
76

S4
16
41
38
20
40
28
50
20
45
29
52
8
15
0
28

T1 T2 T3 T4
47 108 101
64
73 163 164 105
76 167 164
97
76 152 152
76
95 160 155 110
75 144 141
81
100 150 150 100
50
80
80
50
83 192 158 110
113 141
95
71
121 124 154 109
59 105
98
59
71 111
95
69
80 103 100
84
73 113 113
73

Table 3: Predicted price vectors: Shoreline Shanties, followed by Tampa Towers, each for days 1
4. The first ten rows represent predictions employed by agents in the tournament. The last
five represent various benchmarks, discussed below.

27

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

The first six rows of Table 3 (harami through WhiteBear) correspond to constant predictions
for their associated agents. As noted above, SouthamptonTAC switched between two prediction
vectors: S represents the reference prices for its semi-competitive environment, and N its
non-competitive prices. UMBCTAC as well switched prediction vectors within the 60 gamesin
their case introducing for the finals a prediction based on average semifinal (H1) prices.
The rows labeled Actual Mean and Actual Median, respectively, present the average and
median hotel prices actually resulting from the 60 games of interest. Although clairvoyance is obviously not an admissible approach to prediction, we include them here as a benchmark. In a direct
sense, the actual central tendencies represent the best that agents taking the historical averaging
approach can hope to capture.
The price vectors labeled Best Euc Dist, Best EVPP, and Walverine const are discussed
in Section 8.2.

8. Evaluating Prediction Quality
8.1 Accuracy Measures
It remains now to assess the efficacy of the various prediction approaches, in terms of the agents
price predictions in the actual TAC-02 final and semifinal games. In order to do so, we require some
ff given the actual prices  of a given game.
measure characterizing the accuracy of a prediction 
8.1.1 E UCLIDEAN D ISTANCE
A natural measure of the closeness of two price vectors is their Euclidean distance:


ff
    ff





fi



 fi


 




where   indexes the price of hotel   S T	 on day     fi 	. Clearly, lower values of 
are preferred, and for any ,   	 .
Calculating  is straightforward, and we have done so for all of the reported predictions for
ff is in the form of a distribution, the Euclidean distance of the mean
all 60 games. Note that if 
provides a lower bound on the average distance of the components of this distribution. Thus, at
least according to this measure, our evaluation of distribution predictions in terms of their means
provides a bias in their favor.
 for a set of games
It is likewise the case that among all constant predictions, the actual mean 
minimizes the aggregate squared distance for those games. That is, if   is the actual price vector

,
for game  ,

 


	





	  





 ff  
	












5. RoxyBots prediction is based on statistics from the seeding rounds, expressed as cumulative price distributions
for each hotel, discretized into deciles. RoxyBot reportedly based its decisions on samples from this distribution,
taking each decile value to occur with probability 0.1. This tends to overestimate prices, however, as the decile values
correspond to upper limits of their respective ranges. The prediction vector presented in Table 3 (and analyzed below)
corresponds to an adjusted value, obtained by dropping the top decile and averaging the remaining nine.

28

fiTAC P RICE P REDICTION

There is no closed form for the prediction minimizing aggregate , but one can derive it numerically
for a given set of games (Bose et al., 2002).
8.1.2 E XPECTED VALUE OF P ERFECT P REDICTION
Euclidean distance  appears to be a reasonable measure of accuracy in an absolute sense. However,
the purpose of prediction is not accuracy for its own sake, but rather to support decisions based on
these predictions. Thus, we seek a measure that relates in principle to expected TAC performance.
By analogy with standard value-of-information measures, we introduce the concept of value of
perfect prediction (VPP).
Suppose an agent could anticipate perfectly the eventual closing price of all hotels. Then, among
other things, the agent would be able to purchase all flights immediately with confidence that it
had selected optimal trips for all clients. 6 Since many agents apparently commit to trips at the
beginning of the game anyway, perfect prediction would translate directly to improved quality of
these choices.7 We take this as the primary worth of predictions, and measure quality of a prediction
in terms of how it supports trip choice in comparison with perfect anticipation. The idea is that
VPP will be particularly high for agents that otherwise have a poor estimate of prices. If we are
already predicting well, then the value of obtaining a perfect prediction will be relatively small.
This corresponds to the use of standard value-of-information concepts for measuring uncertainty:
for an agent with perfect knowledge, the value of additional information is nil.
Specifically, consider a client  with preferences pa pd hp. A trips surplus for client  at
prices ,    is defined as value minus cost,
 

  	   cost 

where cost  is simply the total price of flights and hotel rooms included in trip . Let

       

 

denote the trip that maximizes surplus for  with respect to prices . The expression



  ff 



ff , but evaluated with respect to prices
then represents the surplus of the trip chosen based on prices 
. From this we can define value of perfect prediction,

        ff 

VPP ff

(3)

Note that our VPP definition (3) is relative to client preferences, whereas we seek a measure
applicable to a pair of price vectors outside the context of a particular client. To this end we define
6. Modulo some residual uncertainty regarding availability of entertainment tickets, which we ignore in this analysis.
7. We compiled statistics on the temporal profile of flight purchases for the eight agents in the TAC-02 finals. Four of
the agents purchased 16 flights (enough for round trips for all clients) within 45 seconds on average. All eight agents
purchased more than half their flights by that time, on average. Vetsikas and Selman (2003) verified experimentally
that predicting prices benefits agents who commit to flights early to a greater extent than it does those who delay
flight purchases.

29

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

the expected value of perfect prediction, EVPP, as the expectation of VPP with respect to TACs
distribution of client preferences:
EVPPff
 


	

 

 VPP ff 


  

         ff

(4)

Note that as for , lower values of EVPP are preferred, and for any , EVPP  	 .
From (4) we see that computing EVPP reduces to computing    ff
 . We can derive
this latter value as follows. For each (pa,pd) pair, determine the best trip for hotel S and the best trip
ff ignoring any contribution from hotel premium, hp. From this
for hotel T, respectively, at prices 
we can determine the threshold value of hp (if any) at which the agent would switch from S to T.
We then use that boundary to split the integration of surplus (based on prices ) for these trips, with
respect to the underlying distribution of hp. Note that this procedure is analogous to Walverines
method for calculating expected client demand (Cheng et al., 2004) in its competitive equilibrium
computation.
8.2 Results
Figure 1 plots the thirteen agents for whom we have prediction data according to our two quality
measures. With one exception, the  and EVPP values shown represent averages over the 60 games
of TAC-02 finals and semifinals. Since kavayaH predicted only 45 games, we normalized its average  and EVPP values to account for the relative difficulty of the games it omitted compared to the
games it predicted. The normalization multiplied its raw average by the ratio of prediction qualities
for these game sets by another representative agent (ATTac01, which was the most favorable choice
for kavayaH, though other normalizations would have produced similar results).
The two dashed lines in Figure 1 represent best-achievable constant predictions with respect to
the two accuracy measures. Best Euc Dist minimizes average Euclidean distance, as indicated
by the vertical line. For EVPP, we performed hill-climbing search from a few promising candidate vectors to derive a local minimum on that measure, represented by the horizontal line. Both
reference vectors are provided in Table 3. Note that in principle, only agents that varied their predictions across game instances (ATTac, kavayaH, cuhk, and Walverine, and to a coarser degree,
SouthamptonTAC and UMBCTAC) have the potential to perform outside the upper-right quadrant.
To assess the significance of the accuracy rankings among agents, we performed paired-sample
t-tests on all pairs of agents for both of our measures. The differences between Walverine and
ATTac01 do not reach a threshold of statistical significance on either measure. Walverine beats
ATTac01 for  at fi 	 
  while ATTac01 beats Walverine for EVPP at fi 	 
 . Walverine

fi) outperforms all other agents on both measures. ATTac01 significantly
significantly (fi

 ) outperforms all other agents for EVPP, but for  it is not statistically distinguishable
(fi
(fi 
 
) from kavayaH, harami, or cuhk. For EVPP, Walverine and ATTac01 are the only
agents that beat Best EVPP (fi 	 
  and fi 	 
), and Best EVPP in turn beats all other
agents (all but cuhk significantly). For , Walverine is the only agent to significantly (fi  
 )
beat Best Euclidean Distance, which in turn beats every other agent but ATTac01 and kavayaH.
No agent but Walverine does significantly better than Actual Mean, with ATTac01, kavayaH, and
harami statistically indistinguishable.
The large discrepancy in performance between ATTac01 and ATTac02 is unexpected, given
that their predictors are generated from the same boosting-based learning algorithm (Stone et al.,
30

fiTAC P RICE P REDICTION

livingagents
PackaTAC
Southampton

Best Euc. Dist.

Expected value of perfect prediction

65
60

RoxyBot

whitebear

UMBCTAC

ATTac02

55

SICS

50
harami
45
40

kavayaH

cuhk
Best EVPP

Walverine

35

ATTac01
190

200

210
220
230
Euclidean distance to actual prices

240

Figure 1: Prediction quality for eleven TAC-02 agents. Dashed lines delimit the accuracy achievable with constant predictions: best Euclidean distance and best EVPP for the two
respective measures. The diagonal line is a least-squares fit to the points. Observe that
the origin of this graph is at (190,32).

2003). This might be explained if the 2002 preliminary rounds were somehow less predictive of the
TAC-02 finals than was the case in 2001. The relative success of another learning agent, kavayaH,
is evidence against this, however. The more likely hypothesis is that the 2002 agent suffered from a
bug emerging from a last-minute change in computing environments.
To directly evaluate a prediction in the form of pricelines, we would need to know the initial
demand of this agent corresponding to the priceline. We did obtain such information from sics, but
found that the accuracy of the priceline prediction according to these measures was far worse than
that of the baseline prediction. Our impression is that the pricelines may well be advantageous with
respect to the decisions the agents based on them, but do not improve basic accuracy. Note that
EVPP inherently is based on an interpretation of prices as linear, thus it may not provide a proper
evaluation of priceline predictions.
8.3 The Influence of Flight Prices
Observe that the three best price predictorsATTac01, Walverine, and kavayaHare exactly
those agents that take flight prices into account. Initial flight prices potentially affect hotel prices
through their influence on agents early trip choices. In theory, lower flight prices should increase
the tendency of agents to travel on those days, all else equal, thus increasing the prices of hotels on
31

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

the corresponding days of stay. Indeed, capturing this effect of flight prices was one of the main
motivations for Walverines price-equilibrium approach. ATTac and kavayaH attempt to induce
the relationship from game data. kavayaHs designers, in particular, explored neural network models based on their hypotheses about which flights were likely to affect which hotel prices (Putchala
et al., 2002).
To isolate and quantify the effect of flight prices, we investigated the contribution of different
factors employed by Walverine in its predictions. We defined three additional versions of Walverines prediction model, each of which ignores some information that Walverine takes into account:





Walv-no-cdata ignores its own client knowledge, effectively treating own demand as based
on the same underlying client preference distribution assumed for the other agents.
Walv-constF ignores the initial flight prices, assuming that they are set at the mean of the
initial flight distribution (i.e., 325) in every game instance.
Walverine const ignores its own client knowledge and takes flight prices at their mean rather
than actual values. The result is a constant prediction vector, presented in Table 3.

Figure 2 plots the prediction qualities of these agents. Ignoring client knowledge degraded prediction quality only slightly, increasing EVPP from 38.0 to 38.6. Neglecting initial flight prices,
however, significantly hurt predictions, increasing EVPP to 47.9. Ignoring both, Walverine const
incurred an average EVPP of 49.1.
50

Walverine_Const
Actual_Mean

Expected value of perfect prediction

48

Walv_constF

46
Best_EucDist
Actual_Median

44

Best_EVPP

42

40
Walv_no_cdata
38

Walverine
197.5

200

202.5
205
207.5
210
Euclidean distance to actual prices

212.5

215

Figure 2: Prediction quality for Walverine variants and various central tendency benchmarks.
The results confirm the predictive value of flight prices. On the EVPP measure, Walverine does
not gain a significant advantage from considering own client data, but cannot beat Best EVPP
32

fiTAC P RICE P REDICTION

without considering initial flight prices. For , client data does make a significant (fi 	 
fi) difference when also considering flight data. Flight data significantly (fi  
 ) affects Walverines
prediction quality for the  metric, regardless of client data.
8.4 Relating Accuracy to Performance
As indicated by the scatter plot of Figure 1, our two accuracy measures are highly correlated
( 	 
). Given that EVPP is value-based, this does suggest that accuracy translates somewhat
proportionally to performance. However, EVPP is a highly idealized proxy for actual scores, and so
does not definitively establish the relation of prediction accuracy to overall TAC performance.
Such a relation was observed in prior work by Stone et al. (2003), who evaluated the predictive
accuracy and overall performance of four variations on ATTac01 in an experimental trial. Employing a different measure of prediction quality than ours above, they found that average score was
related monotonically to average predictive accuracy.
In an effort to more directly connect our accuracy measures to the bottom line, we regressed the
actual TAC-02 game scores against the accuracy measures for all reported predictionsone data
point per agent per game. We controlled for favorability of random client preferences, employing
the same summary statistics used to construct the client preference adjustment in our analysis
of the TAC-01 tournament (Wellman et al., 2003). In two separate regressions, we found highly
significant coefficients (fi    ) for both  and EVPP. Predictive accuracy explained score

 ), however, as might be expected given all the other unmodeled
variance quite poorly ( 
variation across agents.
To reduce the variation, we undertook a series of controlled trials involving variants of Walverine (Cheng et al., 2004). Each trial comprised a set of games with a fixed configuration of agents.
The agents were constant within trials, but varied across, as they were conducted weeks or months
apart while Walverine was undergoing modifications. For each trial, we regressed the actual score
of the first agent on EVPP, controlling as above for favorability of random client preferences. We
considered only one agent per game, since the data points for the other agents would be dependent
given their common game instance. The results of our linear regression are summarized in Table 4.
Trial
1
2
3



200
151
110

Mean EVPP
70.4
32.2
59.5

EVPP Coeff
-8.89
-11.59
-10.26





0.57
0.26
0.65

Table 4: Regression of score on EVPP in three trials.
The EVPP coefficient was highly significant in all cases (fi    ). Note that since EVPP is
measured per-client in the same units as scores, a direct translation would equate reducing EVPP
by one with an increase of eight score points. Our regressions yielded coefficients ranging from
-8.89 to -11.59, which we take as a rough confirmation of the expected relationship. If anything,
the results indicate that EVPP understates the value of predictionwhich we might expect since it
addresses only initial trip choice. Interestingly, the regression model seems to provide a better fit
(as measured by  ) for the trials involving worse price predictors (as measured by mean EVPP).
This suggests that as prediction is optimized, other unmodeled factors may have relatively greater
incremental influence on score.
33

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

It should be noted that these games appear to be quite unrepresentative of TAC tournament
games. Since the agents are all versions of Walverine, they tend to make trip choices on the same
basis.

9. Limitations
It is important to emphasize several limitations of this study, which must qualify any conclusions
drawn about the efficacy of prediction methods evaluated here.
First, we have focused exclusively on initial price prediction, whereas many agents placed
greater emphasis on the interim prediction task.
Second, in many cases we have represented agents predictions by an abstraction of the actual
object produced by their prediction modules. In particular, we reduce probability distributions to
their means, and consider only the first unit of a priceline prediction. More generally, we do not
account for the very different ways that agents apply the predictions they generate. Without question
even the measure we introduce, EVPP, is inspired by our thinking in terms of how Walverine uses
its predictions. Perhaps measures tailored to the processes of other agents would (justifiably) show
their predictions in a more favorable light.
Third, it should be recognized that despite the desirability of isolating focused components of an
agent for analysis, complete separation is not possible in principle. Prediction evaluation is relative
not only to how the agent uses its prediction, but also how it makes other tradeoffs (e.g., when it
commits to flights), and ultimately its entire strategy, in all its complexity. Studies such as this
must strive to balance the benefits of decomposition with appreciation for the interconnections and
synergies among elements of a sophisticated agents behavior.

10. Conclusions
We have presented a comprehensive survey of approaches to initial price prediction in TAC-02, with
quantitative analysis of their relative accuracy. Our analysis introduces a new measure, expected
value of perfect prediction, which captures in an important sense the instrumental value of accurate
predictions, beyond their nominal correspondence to realized outcomes.
We draw several conclusions about price prediction in TAC from this exercise. First, the results
clearly demonstrate that instance-specific information can provide significant leverage over pure
background history. Three agents use instance-specific information to perform better on at least
one measure than any constant prediction. In particular, the initial flight prices provide substantial
predictive value. This can be induced and verified empirically, as seen through the success of the
machine-learning agents. The predictive value flows from the influence of flight prices on demand
for hotels, as indicated by the success of competitive analysis in capturing this relationship.
We believe it striking that a purely analytical approach, without any empirical tuning, could
achieve accuracy comparable to the best available machine-learning method. Moreover, many
would surely have been skeptical that straight competitive analysis could prove so successful, given
the manifest unreality of its assumptions as applied to TAC. Our analysis certainly does not show
that competitive equilibrium is the best possible model for price formation in TAC, but it does
demonstrate that deriving the shape of a market from an idealized economic theory can be surprisingly effective.
34

fiTAC P RICE P REDICTION

There are several advantages to model-based reasoning, most obviously the ability to perform
with minimal or no empirical data. Even when historical information is available, it can be misleading to rely on it in a nonstationary environment. A tournament setup like TAC naturally violates
stationarity, as the agent pool evolves over time, through selection as well as individual learning
and development. Of course, dealing with time-variance, particularly in multiagent environments,
is an active area of current research, and ultimately the best methods will combine elements of
model-based and data-based reasoning.
Finally, we suggest that the present study represents evidence that research competitions can in
the right circumstances produce knowledge and insights beyond what might emerge from independent research efforts. We hope that additional researchers will be inspired to bring their innovative
ideas on trading strategy to the next TAC, and look forward to investigating the results of such
interplay in future work.

Acknowledgments
This study would not have been possible without the generous cooperation of the TAC-02 entrants.
The research was supported in part by NSF grant IIS-9988715, as well as a STIET fellowship to the
third author, under an NSF IGERT grant.

References
Arrow, K. J., & Hahn, F. H. (1971). General Competitive Analysis. Holden-Day, San Francisco.
Bose, P., Maheshwari, A., & Morin, P. (2002). Fast approximations for sums of distances, clustering
and the Fermat-Weber problem. Computational Geometry: Theory and Applications, 24,
135146.
Boyan, J., & Greenwald, A. (2001). Bid determination in simultaneous auctions: An agent architecture. In Third ACM Conference on Electronic Commerce, pp. 210212, Tampa, FL.
Cheng, S.-F., Leung, E., Lochner, K. M., OMalley, K., Reeves, D. M., & Wellman, M. P. (2004).
Walverine: A Walrasian trading agent. Decision Support Systems, To appear.
Fritschi, C., & Dorer, K. (2002). Agent-oriented software engineering for successful TAC participation. In First International Joint Conference on Autonomous Agents and Multi-Agent Systems,
Bologna.
Greenwald, A. (2003a). The 2002 trading agent competition: An overview of agent strategies. AI
Magazine, 24(1), 8391.
Greenwald, A. (2003b). Bidding under uncertainty in simultaneous auctions. In IJCAI-03 Workshop
on Trading Agent Design and Analysis, Acapulco.
He, M., & Jennings, N. R. (2003). SouthamptonTAC: An adaptive autonomous trading agent. ACM
Transactions on Internet Technology, 3, 218235.
Katzner, D. W. (1989). The Walrasian Vision of the Microeconomy. University of Michigan Press.
Putchala, R. P., Morris, V. N., Kazhanchi, R., Raman, L., & Shekhar, S. (2002). kavayaH: A trading
agent developed for TAC-02. Tech. rep., Oracle India.
Sadeh, N., Arunachalam, R., Eriksson, J., Finne, N., & Janson, S. (2003). TAC-03: A supply-chain
trading competition. AI Magazine, 24(1), 9294.
35

fiW ELLMAN , R EEVES , L OCHNER , & VOROBEYCHIK

Stone, P. (2002). Multiagent competitions and research: Lessons from RoboCup and TAC. In Sixth
RoboCup International Symposium, Fukuoka, Japan.
Stone, P., & Greenwald, A. (2004). The first international trading agent competition: Autonomous
bidding agents. Electronic Commerce Research, To appear.
Stone, P., Schapire, R. E., Littman, M. L., Csirik, J. A., & McAllester, D. (2003). Decision-theoretic
bidding based on learned density models in simultaneous, interacting auctions. Journal of
Artificial Intelligence Research, 19, 209242.
Vetsikas, I. A., & Selman, B. (2003). A principled study of the design tradeoffs for autonomous
trading agents. In Second International Joint Conference on Autonomous Agents and MultiAgent Systems, pp. 473480, Melbourne.
Wellman, M. P., Greenwald, A., Stone, P., & Wurman, P. R. (2003). The 2001 trading agent competition. Electronic Markets, 13, 412.

36

fi