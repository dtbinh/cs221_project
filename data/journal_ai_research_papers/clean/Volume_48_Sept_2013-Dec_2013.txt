Journal of Artificial Intelligence Research 48 (2013) 635-669

Submitted 11/12; published 11/13

Reasoning about Explanations for
Negative Query Answers in DL-Lite
Diego Calvanese

calvanese@inf.unibz.it

Free University of Bozen-Bolzano, Italy

Magdalena Ortiz

ortiz@kr.tuwien.ac.at

Vienna University of Technology, Austria

Mantas Simkus

simkus@dbai.tuwien.ac.at

Vienna University of Technology, Austria

Giorgio Stefanoni

Giorgio.Stefanoni@cs.ox.ac.uk

University of Oxford, United Kingdom

Abstract
In order to meet usability requirements, most logic-based applications provide explanation facilities for reasoning services. This holds also for Description Logics, where research
has focused on the explanation of both TBox reasoning and, more recently, query answering. Besides explaining the presence of a tuple in a query answer, it is important to explain
also why a given tuple is missing. We address the latter problem for instance and conjunctive query answering over DL-Lite ontologies by adopting abductive reasoning; that is, we
look for additions to the ABox that force a given tuple to be in the result. As reasoning
tasks we consider existence and recognition of an explanation, and relevance and necessity
of a given assertion for an explanation. We characterize the computational complexity of
these problems for arbitrary, subset minimal, and cardinality minimal explanations.

1. Introduction
Ontology-based data access (OBDA) systems are a new form of information systems that
use an ontology, a set of logical constraints, to mediate the access to data. The role of
the ontology in an OBDA system is twofold. On the one hand, it is an intermediate layer
between the domain user and the physical data providing a unified view of the information
held in the various data sources. In many cases, the ontology extends the data vocabulary
by introducing new intensional predicates that can be used to query information in a more
succinct and declarative way. On the other hand, the ontology provides constraints, which
are taken into account while answering queries and which may contribute to enrich the
obtained answers. Hence, potentially relevant implicit knowledge that can be derived from
the data, plus the ontology, can be made explicit by using specifically tailored reasoning
algorithms. Most existing OBDA systems are based on the DL-Lite family of lightweight
Description Logics (DLs), introduced by Calvanese, De Giacomo, Lembo, Lenzerini, and
Rosati (2007), which is also the basis for the QL profile of the OWL 2 ontology language
(Motik, Fokoue, Horrocks, Wu, Lutz, & Grau, 2009).
As argued by McGuinness and Patel-Schneider (1998), in order to meet usability requirements set by domain users, knowledge-based systems should be equipped with explanation algorithms for reasoning services. This holds also for Description Logics, where
c
2013
AI Access Foundation. All rights reserved.

fiCalvanese, Ortiz, Simkus & Stefanoni

research has focused on the explanation of TBox reasoning (cf., McGuinness & Borgida,
1995; Borgida, Franconi, & Horrocks, 2000; Penaloza & Sertkaya, 2010; Horridge, Parsia, &
Sattler, 2008). Additionally, Borgida, Calvanese, and Rodriguez-Muro (2008) studied the
problem of explaining positive query answers to conjunctive queries over DL-Lite ontologies. In particular, they outlined a procedure for computing the reasons for a tuple to be
in the answer to a query, and for minimizing the corresponding explanation shown to the
user. In addition, Borgida et al. (2008) suggested that OBDA systems, besides explaining
positive query answers, should also explain negative query answers; that is, those tuples
that a user expects to be in the result but actually do not occur there. As OBDA systems
answer queries under ontological constraints, explaining negative query answers is not trivial: these constraints need to be taken into account to understand why a required tuple is
missing from the answers. A procedure for explaining negative query answers would then
improve the usability of OBDA systems.
For this reason, we formalize this explanation problem in the context of query answering
over DL ontologies. Following Eiter and Gottlob (1995), we adopt abductive reasoning; that
is, explanations are set of facts that need to be asserted in the ABox to force the required
tuple to be in the result. Such explanations help users in debugging a negative answer by
giving an effective way of repairing the OBDA system in terms of updates to the data layer.
Since ontologies can be used to enrich the data vocabulary, we consider also restrictions
to the vocabulary over which the additional assertions can be constructed. More precisely,
given a DL TBox T , an ABox A, a query q, and a set  of predicates, an explanation for
a given tuple ~c is a new ABox E, all whose predicates occur in , such that the answer
to q over the ontology hT , A  Ei contains ~c. According to the Occams razor principle,
an important aspect in explanations is to provide users with solutions that are simple to
understand and free of redundancy, hence as small as possible. To address this requirement,
we study various restrictions on explanations, in particular, we focus on subset minimal and
cardinality minimal ones. We consider standard decision problems associated to logic-based
abduction: (i) existence of an explanation, (ii) recognition of a given ABox as being an
explanation, and (iii) relevance and (iv) necessity of an ABox assertionthat is, whether
it occurs in some or all explanations. At first, the latter two problems may appear rather
artificial, however, they provide valuable information to the user when debugging negative
answers. Relevance can be used to test whether an assertion the user deems related to the
negative answer is indeed so; whereas, necessity can be used to test whether an assertion is
intrinsically related to the negative answer.
The idea of restricting the vocabulary of explanations is an adaptation of a concept
introduced by Baader, Bienvenu, Lutz, and Wolter (2010), who study among others the
query emptiness problem. That is, given a query q over a TBox T decide whether for all
ABoxes A over a given signature , we have that evaluating q over hT , Ai leads to an
empty result. In Section 3, we shall see that in our framework deciding the existence of an
explanation relates to the query non-emptiness problem. In fact, for many DLs, deciding
whether a query is non-empty w.r.t. a TBox reduces to checking whether there exists an
explanation for a missing answer.
The purpose of this paper is to shed light on the computational complexity of explaining
missing answers to queries over ontologies formulated in DL-Lite A an expressive member
of the DL-Lite family of DLs. To this end, we consider two important classes of queries
636

fiReasoning about Explanations for Negative Query Answers in DL-Lite

that is, instance queries and unions of conjunctive queries (UCQs)and we provide computational complexity results for the four decision problems defined above. Moreover, we
perform our complexity analysis under two different explanation settings. We consider the
case in which the explanation vocabulary is a strict subset of the vocabulary of the ontology
and the data, as well as the case in which explanations can be constructed over arbitrary
predicates. In Section 4, we show that when we consider instance queries as input, the
relevant decision problems are NL-complete, irrespective of the chosen explanation setting
and of the particular minimality criterion applied over explanations. In Section 5, we analyze the complexity of the problem when we admit UCQs as input, and we show that the
complexity varies with respect to both the chosen explanation setting and the minimality
criterion. Our complexity results for UCQs are summarized in Table 5.1.

2. Preliminaries
In this section, we first introduce ontologies formulated in DLs, with a particular focus on the
DL DL-Lite A . We then introduce the languages for querying ontologies that we consider,
and we recall some important properties of DL-Lite A that will be used throughout the
paper. Finally, we briefly present some of the less known complexity classes that will be
mentioned later.
2.1 Description Logic Ontologies
As usual in DLs, we consider countably infinite sets NC , NR , and NI of atomic concepts,
atomic roles, and individuals, respectively. Whenever the distinction between atomic concepts and roles is immaterial, we call an element of NC  NR a predicate.
A DL TBox T is a finite set of axioms, whose form depends on the specific DL being
considered; for DL-Lite A , the DL adopted in this paper, the definition is given below. A
DL ABox A is a finite set of ABox assertions, which are expressions of the form A(c) or
P (c, d), where A is an atomic concept, P is an atomic role, and c and d are individuals. A
DL ontology is a pair O = hT , Ai, where T is a DL TBox and A is a DL ABox.
The semantics of DL ontologies is based on first-order interpretations I = hI , I i, where
I
 is a non-empty set called the domain and I is the interpretation function mapping each
individual c  NI to an object cI  I , each atomic concept A  NC to a set AI  I ,
and each atomic role P  NR to a binary relation P I  I  I .
An interpretation I satisfies an ABox assertion A(c) if cI  AI , and it satisfies an
assertion P (c, d) if hcI , dI i  P I . Satisfaction of TBox axioms is also defined according to
their form in each specific DL; we define it below for DL-Lite A . An interpretation I is a
model of hT , Ai, if it satisfies all the axioms in T and all the assertions in A. We call hT , Ai
consistent if it admits at least one model, and inconsistent otherwise. Also, an ABox A is
consistent with a TBox T if the ontology hT , Ai is consistent.
2.1.1 DL-Lite A
DL-Lite A is a member of the DL-Lite family of DLs (Calvanese et al., 2007; Calvanese,
De Giacomo, Lembo, Lenzerini, Poggi, Rodriguez-Muro, & Rosati, 2009), which has been
designed for dealing efficiently with large amounts of extensional information. In DL-Lite A ,
637

fiCalvanese, Ortiz, Simkus & Stefanoni

concept expressions (or, concepts) C, denoting sets of objects, and role expressions (or,
roles) R, denoting binary relations between objects, are formed according to the following
syntax, where A denotes an atomic concept and P an atomic role.1
R  P | P 

C  A | R

A DL-Lite A TBox consists of axioms of the following form.
C1 v C2
R1 v R2

C1 v C2
R1 v R2

(funct R)

Axioms in the first column are called positive inclusions (among concepts and roles, respectively), those in the second column disjointness axioms, and those in the third column
functionality assertions on roles. In order to retain tractability of reasoning, DL-Lite A
TBoxes must satisfy the additional restriction that roles that are functional or inverse functional cannot be specialized. Formally, if a DL-Lite A TBox contains (funct P ) or (funct P  ),
then for each role R it does not contain R v P or R v P  (Calvanese et al., 2007).
The semantics of concept expressions is specified as follows.
(R)I

= {o  I | o0  I : ho, o0 i  RI }

(P  )I

= {ho, o0 i  I  I | ho0 , oi  P I }

An interpretation I satisfies axiom 1 v 2 if 1I  2I , it satisfies axiom 1 v 2 if
1I  2I = , and it satisfies axiom (funct R) if RI is a partial functionthat is, for each
set of objects {o, o1 , o2 }  I , if ho, o1 i  RI and ho, o2 i  RI , then o1 = o2 .
Following the common practice for the DLs of the DL-Lite family (Calvanese et al.,
2007), we usually adopt the unique name assumption (UNA)that is, for each interpretation I and individual pair c 6= d, we require that cI 6= dI . Whenever we drop this
assumption, we will explicitly say so. Under the UNA, the problem of checking whether a
DL-Lite A ontology is consistent is NL-complete, whereas without the UNA, the problem
becomes PTime-complete (Artale, Calvanese, Kontchakov, & Zakharyaschev, 2009).
2.2 Instance Queries and Conjunctive Queries
Let NV be a countably infinite set of variables. Together NI and NV form the set of terms.
Expressions of the form A(t) or P (t, t0 ), where A is an atomic concept, P is an atomic role,
and t, t0 are terms, are called atoms.
A conjunctive query (CQ) q of arity n  0 is an expression q(x1 , . . . , xn )  a1 , . . . , am ,
where, for each i  {1, . . . , m}, we have that ai is an atom. The tuple hx1 , . . . , xn i is the
tuple of answer variables of q. Let NV (q) be the set of variables occurring in q, let NI (q)
be the set of individuals in q, let at(q) = {a1 , . . . , am }, and let |q| be the number of terms
occurring in q. We consider safe CQsthat is, each answer variable xi of q occurs in at
least one of the atoms of q. A Boolean conjunctive query is a CQ with arity 0, and we shall
write it simply as a set of atoms. An instance query q(x) is a conjunctive query whose body
consists of a single unary atom A(x). A union of conjunctive queries (UCQ) is a set of CQs
1. We ignore here the distinction between data values and objects present in DL-Lite A and OWL 2 QL,
since it is immaterial for our results. That is, we do not consider value domains and attributes.

638

fiReasoning about Explanations for Negative Query Answers in DL-Lite

of the same arity, and we assume w.l.o.g. that all CQs in a UCQ have the same tuple of
answer variables. In the following, we denote with IQ the set of all instance queries and
with CQ the set of all UCQs.
A match for an n-ary CQ q in an interpretation I is a mapping  : NV (q)  NI (q)  I
such that
(i) (c) = cI , for each c  NI (q),
(ii) (t)  AI , for each A(t)  at(q), and
(iii) h(t), (t0 )i  P I , for each P (t, t0 )  at(q).
An n-tuple of individuals hc1 , . . . , cn i is an answer to q in I, if there exists a match
 for q in I such that hcI1 , . . . , cIn i = h(x1 ), . . . , (xn )i. We let ans(q, I) denote the set
of all answers to q in I. A Boolean CQ returns as answer either , representing the
value false,S or the empty tuple hi, representing the value true. For a UCQ q, we let
ans(q, I) = q0 q ans(q 0 , I). The certain answer to a UCQ q of arity n over ontology hT , Ai
is defined as
cert(q, T , A) = {~c  (NI )n | ~c  ans(q, I), for each model I of hT , Ai}.
2.3 Query Answering in DL-Lite A
The problem of query answering in DLs is the problem of computing the certain answer
to a given query over a given DL ontology. Formulated in this way, query answering is a
computation problem and not a decision problem. Since in this paper we are interested in
establishing computational complexity results, we identify query answering with its decision
problem, sometimes called the recognition problem, in which the input is constituted by a
DL ontology hT , Ai, a query q(~x), and a tuple ~c of arity |~x|, and the task is to determine
whether ~c  cert(q, T , A). In the special case of instance queries, this problem is also known
as instance checking. Notice that, since we consider both the ontology and the query as
part of the input, we are considering so-called combined complexity (Vardi, 1982).
In many DLs, instance checking can be reduced to the problem of deciding ontology
consistency. This holds also for DL-Lite A and, thus, answering an instance query can be
done in nondeterministic logarithmic space. In contrast, the problem of answering a UCQ
(and hence a CQ) q over a DL-Lite A ontology hT , Ai can be solved in nondeterministic
polynomial time by adopting a pure query rewriting approach (Calvanese et al., 2007, 2009).
This technique works in two steps. In the first step, we compute the perfect reformulation
Rq,T of q w.r.t. T that is, we rewrite the input query q with respect to the TBox T into
a UCQ Rq,T . In this rewriting step, the portion of the TBox relevant for answering q is
compiled into Rq,T . In the second step, we simply evaluate the computed rewriting Rq,T
over the ABox Aseen as a first order interpretation. This is captured by the proposition
below, which makes use of the notion of interpretation associated to an ABox, formalized
in the following definition.
Definition 2.1. Given an ABox A, let DB A be the interpretation whose domain DB A is
the set of individuals occurring in A, and
(i) cDB A = c, for all individuals c occurring in A;
639

fiCalvanese, Ortiz, Simkus & Stefanoni

(ii) ADB A = {c | A(c)  A}, for all A  NC ;
(iii) P DB A = {hc, di | P (c, d)  A}, for all P  NR .
The following proposition summarizes the results about query answering based on rewriting that have been shown for the logics of the DL-Lite family (and for DL-Lite A in particular) and that we will exploit in the following.
Proposition 2.1. (Calvanese et al., 2007, 2009) Let hT , Ai be a DL-LiteA ontology, let q
be a UCQ, and let max(q) = maxqi q |at(qi )|. It is possible to construct a UCQ Rq,T , called
the perfect reformulation of q w.r.t. T , such that
cert(q, T , A) = ans(Rq,T , DB A ).
Moreover, Rq,T satisfies the following properties.
 All predicates occurring in Rq,T occur in T or in q.
 Each qr  Rq,T has at most max(q) atoms and at most 2  max(q) terms.
 If q consists of a single instance query, then each qr  Rq,T has only one atom.
 Each qr  Rq,T can be obtained in nondeterministic polynomial time in the combined
size of T and q.
 Deciding whether a given tuple of individuals is in ans(Rq,T , DB A ) can also be achieved
in nondeterministic polynomial time in the combined size of T and q.
2.4 Complexity Theory
We briefly outline the definition of some non-canonical complexity classes used in the paper;
for more details, we refer the reader to standard textbooks on computational complexity
(e.g., Papadimitriou, 1994). The class P2 is a member of the Polynomial Hierarchy: it is
the class of all decision problems solvable in nondeterministic polynomial time using an NP
oracle. The class PNP
k contains all decision problems that can be solved in polynomial time
with an NP oracle, where all oracle calls must be first prepared and then issued in parallel.
The class DP contains all problems that, considered as languages, can be characterized as
the intersection of a language in NP and a language in coNP. Additionally, the class NL
contains all decision problems that can be solved by a nondeterministic Turing machine using
P
a logarithmic amount of space. It is believed that NL  PTime  NP  DP  PNP
k  2
is a strict hierarchy of inclusions. Here we make such an assumption.
As usual, we use reductions between problems to infer complexity bounds throughout
the paper. Unless stated otherwise, these are all many-one logarithmic space reductions.

3. Explaining Negative Query Answers
In this section, we formalize as an abductive task the problem of finding explanations for
negative answers to queries over DL ontologies.
For a DL TBox T , a DL ABox A, and a query q from IQ  CQ, we let (T , A, q) denote
the set of all those predicates that occur in T , A, or q. A signature  is a non-empty finite
subset of NC  NR . Furthermore, an ABox A is a -ABox if all the assertions in A use
only predicates from ; that is, if (, A, )  .
640

fiReasoning about Explanations for Negative Query Answers in DL-Lite

Definition 3.1. Let hT , Ai be a DL ontology, q(~x) a query from IQ  CQ, ~c a tuple of
individuals of arity |~x|, and  a signature. We call P = hT , A, q, ~c, i a Query Abduction
Problem (QAP). An explanation for (or, a solution to) P is a -ABox E such that
(i) the ontology hT , A  Ei is consistent, and
(ii) ~c  cert(q, T , A  E).
The set of all explanations for P is denoted by expl(P). The predicates in  are the ones
allowed in explanations, hence we call them abducible predicates. If (T , A, q)  , we say
that P has unrestricted explanation signature; otherwise, if  does not contain all symbols
in (T , A, q), we say that P has restricted explanation signature.
For such a QAP, we call tuple ~c a negative answer to q over hT , Ai, if ~c 
/ cert(q, T , A).
Clearly, query q over ontology hT , Ai admits a negative answer only if hT , Ai is consistent.
Also, by condition (i), if the ontology is inconsistent, then P does not admit explanations.
Ontology languages, such as DL-Lite A , which allow for the specification of existential
restrictions and negative constraints (e.g., disjointness axioms), sometimes require explanations to introduce fresh individuals that do not occur within the QAP. We next precisely
characterize these individuals.
Definition 3.2. Let P = hT , A, q, ~c, i be a QAP and let E be a solution to P. An arbitrary
individual u occurring in E is anonymous if it does not occur in T , A, q, and in ~c.
Now, we use an example to highlight how query abduction problems can be useful in
debugging negative query answers.
Example 3.1. Let Au be the following set of assertions about a particular university.
DPhil(Anna)
enroll(Anna, KR)
enroll(Luca, IDB )

DPhil(Beppe)
teach(Marco, KR)
teach(Carlo, IDB )

That is, Anna and Beppe are doctoral students, Anna is enrolled in the KR course, which
is taught by Marco, and Luca is enrolled in the introductory DB course (IDB ), which is
taught by Carlo. Now, consider the following DL-Lite A TBox Tu formalizing the university
domain, of which Au is a (partial) instance.
enroll v Student
enroll v Course
DPhil v Student

teach v Lecturer
teach v Course
Course v teach

Tu models that objects in the domain of enroll are Students, and objects in the domain of
teach are Lecturers, whereas objects in the range of enroll or of teach are Courses. Among
the students we have DPhil students. Finally, every Course must be taught by someone.
Now, assume that the university administration is interested in finding all those who
are teaching a course in which at least one of the enrolled students is a doctoral student,
which is captured by the following query.
qu (x)  teach(x, y), enroll(z, y), DPhil(z)
641

fiCalvanese, Ortiz, Simkus & Stefanoni

Assume that Carlo is expected to be part of the result. This is not the case, as Luca is the
only student of Carlo and he is not known to be a DPhil student. Hence Carlo 
/ cert(q, T , A)
and Carlo is a negative answer. Suppose that we have complete information on all the
predicates but enroll and teachthat is, only the latter predicates are abducible. It is easy
to see that
Eu = {teach(Carlo, c), enroll(Beppe, c), enroll(Luca, c)}
is an explanation for the QAP Pu = hTu , Au , qu , Carlo, {enroll, teach}i, which suggests the
existence of a course, represented by the anonymous individual c, that does not occur in
the ABox Au .
The above example shows that certain explanations may be too assumptive in that they
include assertions that are not required to solve the problem. Indeed, in the examples
explanation there is no reason to assume that Luca is enrolled in the anonymous course
c. In the following, we will examine various restrictions to expl(P) to reduce redundancy
in explanations, achieved by introducing a preference relation among explanations. This
relation is reflexive and transitivethat is, we have a pre-order among explanations. For
such a pre-order  on expl(P), we write E  E 0 if E  E 0 and E 0  E.
Definition 3.3. The preferred explanations expl (P) of a QAP P under the pre-order ,
called -explanations or (-solutions), are defined as follows.
expl (P) = { E  expl(P) | there is no E 0  expl(P) such that E 0  E }
We consider two preference orders that are commonly adopted when comparing abductive solutions: the subset-minimality order, denoted by , and the minimum explanation
size order, denoted by . The latter order is defined by E  E 0 iff |E|  |E 0 |. Considering
that, by the definition, explanations are finite, for an arbitrary QAP P, we have that each
-solution to P is also a -solution to P; that is, expl (P)  expl (P).
Example 3.2. As we already argued, the ABox Eu is a redundant solution to the QAP Pu
introduced in Example 3.1. Next, we introduce two minimal solutions. First, we consider
the solution asserting Carlo to teach an anonymous course c and Beppe to be enrolled in
that course. This ABox Eu0 = {teach(Carlo, c), enroll(Beppe, c)} is a -explanation. Second,
we consider the solution asserting Beppe to be enrolled in the IDB course. This ABox
Eu00 = {enroll(Beppe, IDB )} is a -explanation (and hence also a -explanation).
In the context of logic-based abduction, four main decision problems have been considered of interest (Eiter & Gottlob, 1995), and they are parametrized according to the chosen
preference order .
~ over abducible predicate , and
Definition 3.4. Given a QAP P, an ABox assertion (d)
an ABox E, we define the following decision problems.
 -exist(ence): Does there exist a -explanation for P?
~ occur in all -explanations for P?
 -nec(essity): Does assertion (d)
~ occur in some -explanation for P?
 -rel(evance): Does assertion (d)
642

fiReasoning about Explanations for Negative Query Answers in DL-Lite

 -rec(ognition): Is ABox E a -explanation for P?
Whenever no preference is applied (i.e., when  is the identity), we omit to write  in
front of the problems names.
In this paper, we study the complexity of the above reasoning problems for query abduction. We start by highlighting, in the remaining part of this section, interesting properties
of query abduction problems and important connections between reasoning tasks.
3.1 Reductions between Reasoning Problems
We now show that some of the introduced problems can be reduced to each other. Unless
otherwise stated, the reductions we present work for all DLs, for both instance queries and
UCQs, and for both restricted and unrestricted explanation signatures.
We start by showing that nec is at least as hard as non-exist (i.e., the complement of
the exist problem).
Proposition 3.1. For every DL, non-exist is reducible to nec.
~ be an arbitrary ABox assertion,
Proof. Assume a QAP P = hT , A, q, ~c, i and let (d)
~ is
such that  and d~ do not occur in P. The following holds: P has no explanation iff (d)
0
necessary for P = hT , A, q, ~c,   {}i. By the construction, it follows that each solution
to P is also a solution to P 0 ; furthermore, for each solution E 0 to P 0 ,  6 (, E 0 , ) implies
that E 0 is a solution to P. By the definition of P 0 and since  and d~ are globally fresh,
~ is an
for each ABox E, we have that E is an explanation for P 0 if and only if E \ {(d)}
0
explanation for P . The correctness of the reduction immediately follows.
For QAPs with restricted explanation signatures, we next show that nec reduces to
non-exist. The reduction works for every DL that allows for disjointness axioms.
Proposition 3.2. For every DL that allows for concept and role disjointness axioms, and
under restricted explanation signatures, nec is reducible to non-exist.
Proof. Consider an instance of nec given by a QAP P = hT , A, q, ~c, i where  might be
~ Next, we show how to construct a QAP P 0 such
restricted, and by an ABox assertion (d).
0
~
that (d) is necessary for P iff P does not admit solutions. To this end, let 0 and  be
two globally fresh predicates of the same arity as ; furthermore, let TBox T 0 , ABox A0 ,
and signature 0 be as follows.
T 0 := T  {0 v }  { v 0 }

~
A0 := A  {(d)}

0 := {   |  6= }  {0 }

Finally, let P 0 := hT 0 , A0 , q, ~c, 0 i. Now, we show the correctness of the reduction; that is,
~ is necessary for P iff P 0 does not admit solutions.
(d)
() We prove the contrapositive. Suppose that P 0 has a solution E 0 . By the definition
~ 6 E 0 and that predicate  does not occur in E 0 .
of hT 0 , A0 i and of 0 , we have that 0 (d)
Let ABox E be defined as follows.
E := {(~t)  E 0 |  6= 0 }  {(~t) | 0 (~t)  E 0 }
643

fiCalvanese, Ortiz, Simkus & Stefanoni

~ It remains to show that
By the construction, E is a -ABox that does not contain (d).
E is a solution to P. To this end, please observe that each model J of hT 0 , A0  E 0 i is
a model of hT , A  Ei, since 0 v   T 0 . In addition, each model I of hT , A  Ei can
be extended to a model J of hT 0 , A0  E 0 i by setting 0J := {(~t)J | 0 (~t)  E 0 } and
~ J }. It follows that hT 0 , A0  E 0 i is a conservative extension of hT , A  Ei. Given
J := {(d)
that ~c  cert(q, T 0 , A0  E 0 ) and that q is over hT , Ai, we obtain that ~c  cert(q, T , A  E).
Furthermore, since hT 0 , A0  E 0 i is consistent, we also have that hT , A  Ei is consistent; so
~ as required.
E is a solution to P that does not contain assertion (d),
() We prove the contrapositive. Suppose that a solution E to P exists such that
~
(d) 6 E. Let ABox E 0 be defined as follows.
E 0 := {(~t)  E |  6= }  {0 (~t) | (~t)  E}
~ It remains to show
By the construction, E 0 is a 0 -ABox which does not contain 0 (d).
0
0
0
0
0
that E is a solution to P . As we have seen before, hT , A  E i is a conservative extension of hT , A  Ei. Given that ~c  cert(q, T , A  E), we obtain that ~c  cert(q, T 0 , A0  E 0 ).
~ 6 E 0 , we also have that hT 0 , A0  E 0 i
Furthermore, since hT , A  Ei is consistent and 0 (d)
is consistent; so E 0 is a solution to P 0 , as required.
A simple modification of Proposition 3.2 shows that this result applies also to DLs that
allow for negative ABox assertions of the form A(c) and P (c, c0 ) instead of disjointness
axioms. We next show that rel and exist are mutually reducible.
Proposition 3.3. For every DL, rel and exist are mutually reducible.
Proof. First, we show that we can reduce rel to exist. Let P be an arbitrary QAP of
~ be an arbitrary ABox assertion such that   . We
the form hT , A, q, ~c, i and let (d)
0
~ is relevant to P if and only if P 0 admits a solution.
construct a QAP P such that (d)
~
To this end, let A0 be the ABox defined as A0 = A  {(d)}.
Then, we define QAP P 0 as
0
0
P = hT , A , q, ~c, i. Next, we prove the correctness of the reduction. The only-if direction
is immediate. For the if direction, suppose that P 0 admits a solution E 0 . It follows, by the
~ is consistent with TBox T . Moreover, this latter
definition of P 0 , that -ABox E 0  {(d)}
ABox is also a solution to P and, therefore, the given assertion is relevant.
Second, we prove that exist is reducible to rel. Let P be an arbitrary QAP of the
form hT , A, q, ~c, i, let  be an arbitrary predicate from , and let d~ be an arbitrary tuple
of individuals not occurring in P such that d~ is of the same arity as predicate . We prove
~ is relevant for P. The if direction follows by the definition
that P admits a solution iff (d)
~
of relevance. To show the only-if direction, suppose that P admits a solution E. If (d)
~
occurs in E, it is relevant for P. Otherwise, since individuals d do not occur in P and   ,
~ is also a solution to P, and hence (d)
~ is relevant for P.
ABox E  {(d)}
Moreover, -nec and nec are also mutually reducible.
Proposition 3.4. For every DL, -nec and nec are mutually reducible.
~ we have that (d)
~
Proof. For an arbitrary QAP P and an arbitrary ABox assertion (d),
~
occurs in all -minimal explanations for P iff (d) occurs in all explanations for P. Thus,
nec and -nec are equivalent problems.
644

fiReasoning about Explanations for Negative Query Answers in DL-Lite

Finally, since our preference orders prefer smaller explanations and, by the definition,
explanations are finite, our orders are well-founded. It immediately follows that there exists
an explanation for an arbitrary QAP P if and only if P admits a minimal explanation under
both our preference orders.
Proposition 3.5. For every DL, -exist, -exist, and exist are mutually reducible.
3.2 QAPs and the Query Emptiness Problem
As mentioned in the introduction, deciding the existence of an explanation is related to the
query emptiness problem studied by Baader et al. (2010). Since we will rely on that problem
to infer some complexity bounds throughout the paper, we briefly introduce it here.
Definition 3.5. Let T be a DL TBox, Q  {IQ, CQ} a query language, and  a signature.
We say that a Q-query q is empty for  given T if for every -ABox A that is consistent
with T we have that cert(q, T , A) = . Otherwise, we say that q is non-empty for  given
T . The Q non-emptiness problem consists in deciding, for input T , q, and , whether q is
non-empty for  given T .
Next, we first show that, for every DL, and for both instance queries and Boolean UCQs,
query non-emptiness reduces to exist. Then, we show that for the DL-Lite A case this holds
even for arbitrary UCQs.
Proposition 3.6. For every DL and both instance queries and Boolean UCQs, Q nonemptiness is reducible to exist.
Proof. Let T be an arbitrary DL TBox, let q  IQ  CQ be an arbitrary query such that
q  CQ implies that q is a Boolean UCQ, and let  be an arbitrary signature. We show
how to construct a QAP P such that q is non-empty for  given T iff P admits a solution.
To this end, let ~c be an arbitrary tuple such that q  CQ implies that ~c = hi, and q  IQ
implies that ~c = hai where a is a globally fresh individual. Clearly, we have that q is
non-empty for  given T iff P = hT , , q, ~c, i admits a solution.
The relationship between CQ non-emptiness and exist can tightened, when we restrict
our attention to DL-Lite A TBoxes.
Proposition 3.7. For DL-LiteA , CQ non-emptiness is reducible to exist.
Proof. Consider a DL-Lite A TBox T , a signature , and this time an n-ary query q  CQ.
W.l.o.g., we assume that q is a CQ. Then, we cannot immediately extend the proof given
for Boolean CQs by introducing n (distinct) individuals since we might be forced to match
distinct answer variables of q to the same individual in an ABox witnessing non-emptiness
of q. However, we can adapt the proof to this case as follows. We let N be a fresh atomic
concept not occurring in (T , , q). We define 0 = {N } and we let q 0 be the Boolean
CQ such that at(q 0 ) = at(q)  {N (x1 ), . . . , N (xn )}. Finally, we let P = hT , , q 0 , hi, 0 i be a
QAP. In the following, we show that q is non-empty for  given T iff P admits a solution.
() Suppose that q is non-empty for  given T . That is, there exists a -ABox A such
that hT , Ai is consistent and there exists some n-ary tuple ~a = ha1 , . . . , an i of individuals
645

fiCalvanese, Ortiz, Simkus & Stefanoni

such that ~a  cert(q, T , A). Now, consider the 0 -ABox E = A  {N (ai ) | 1  i  n}.
Since N is a fresh predicate, we have that hT , Ei is a conservative extension of hT , Ai.
That is, each model of hT , Ai can be extended to be a model of hT , Ei, and every model
of hT , Ei is also a model of hT , Ai. By the assumption that hT , Ai is consistent and that
~a  cert(q, T , A), we conclude that E is a solution to P.
() Suppose that P admits a solution E. It follows that hT , Ei is consistent and that
for each model I of hT , Ei, there exists a match  for q 0 such that I |= q 0 . Since N is
a fresh predicate not occurring in T and for each answer variable xi of q the atom N (xi )
is contained in q 0 , we have that (xi ) = aIi for some ai  NI such that N (ai )  E. It
follows that ~a  cert(q, T , E). Consider the -ABox A obtained from E by removing all the
assertions over N ; it immediately follows that hT , Ei is a conservative extension of hT , Ai.
Therefore, also ~a  cert(q, T , A) and, thus, q is non-empty for  given T .
Proposition 3.7 can be generalized to Horn DLsthat is, to all those DLs for which
answering instance and conjunctive queries reduces to evaluating the input query over a
single, canonical model of the ontology. It follows that for DL-Lite A and, more in general,
for all Horn-DLs, deciding exist generalizes the query non-emptiness problem. Hence,
all the hardness results for non-emptiness obtained by Baader et al. (2010) that hold for
instance queries and UCQs apply also to the exist problem under restricted explanation
signatures. However, since we also consider ABoxes and we require a specific tuple to be in
the query answer, the converse does not hold and we can not always transfer their upper
bounds to our setting.
3.3 Canonical Explanations
Before studying the complexity of reasoning over query abduction problems, we first show
that we can restrict the search for explanations. In order to do so, we define the notion of
instantiation of a conjunctive query.
Definition 3.6. Let q be an n-ary CQ with answer variables hx1 , . . . , xn i; furthermore, let
~c = hc1 , . . . , cn i be a tuple of individuals. Let  be a mapping from the terms of q to NI such
that  is identity over NI and for each answer variable xj of q we have that (xj ) = cj .
Then, we call the ABox
E = {A((t)) | A(t)  at(q)}  {R((s), (t)) | R(s, t)  at(q)}
a ~c-instantiation of q. Given a DL ontology O, if we additionally have that, for each
quantified variable y, (y) is a distinct anonymous individual uy not occurring in q and O,
then we say that E is direct for O.
Note that in the following we do not distinguish between instantiations that differ only
in the assignment of anonymous individuals to variables. Hence, a CQ has only a finite
number of distinct instantiations, and a unique direct one.
3.3.1 Unrestricted Explanation Signature
To obtain an explanation for a QAP P with unrestricted explanation signature, we can
iterate over the set of all possible instantiations to the input query, searching for one such
646

fiReasoning about Explanations for Negative Query Answers in DL-Lite

instantiation that is consistent with the input ontology. In the absence of the UNA, we
can even consider one single instantiation of each CQ: the direct instantiation, where all
existentially quantified variables are mapped to distinct anonymous individuals. In the
presence of the UNA, if our underlying DL is expressive enough to enforce inequalities over
the individuals occurring in P (e.g., by means of disjointness axioms), we can again reduce
the problem to searching for a CQ whose direct instantiation is consistent with the input
ontology, when the UNA is dropped.
Proposition 3.8. Let O = hT , Ai be an arbitrary DL ontology and let P = hT , A, q, ~c, i
be an arbitrary QAP with unrestricted explanation signature. Furthermore, for each qi  q,
let Eqi be the direct ~c-instantiation of qi for O. The following hold:
1. Under the UNA, a solution to P exists iff a ~c-instantiation E of some qi  q exists
such that hT , A  E i is consistent.
2. Without the UNA, a solution to P exists iff a query qi  q exists such that hT , A  Eqi i
is consistent.
3. Furthermore, suppose that the DL supports concept disjointness axioms. Under the
UNA, a solution to P exists iff a query qi  q exists such that hT 0 , A0  Eqi i is consistent without the UNA, where A0 and T 0 extend A and T with a quadratic number of
assertions and axioms, respectively.
Proof. Consider an arbitrary qi  q and let E be an arbitrary ~c-instantiation of qi . We
first prove that consistency of hT , A  E i (with or without the UNA) implies that E is a
solution to P (with or without the UNA, resp.). This shows the if direction of 1 and 2. Let
 be the mapping generating E and suppose that hT , A  E i is consistent. Let I be an
arbitrary model of hT , A  E i. Then we build a match  for qi in I by setting (t) = (t)I
for each term t in qi . As (xj ) = (xj )I = cIj for each answer variable xj , the match 
witnesses ~c  ans(q, I). Hence ~c  cert(q, T , A  E ) and E is a solution to P, as desired.
For the only-if direction of 1, we assume an arbitrary solution E to P, and use it to
show that there exists a ~c-instantiation E of some qi  q such that hT , A  E i is consistent.
Since E is a solution to P, by definition, there exists a model I of hT , A  Ei under the
UNA. Without loss of generality, we assume that I = NI and that for each c  NI we have
that cI = c. Moreover, the interpretation I admits a match  for some qi  q witnessing
~c  ans(qi , I). To define the mapping , we let (t) = (t) for each term t occurring in qi .
Then I is a model of E . Since it is also a model of hT , Ai, it is a model of hT , A  E i and
shows that the latter is consistent, as desired.
The only-if direction of 2 is shown similarly. Suppose that P admits a solution E.
Then there exists a model I of hT , A  Ei (without the UNA) that admits a match  for
some qi  q witnessing ~c  ans(qi , I). To obtain an interpretation J that is a model of
hT , A  Eqi i, we extend I as follows. For every anonymous individual uy that was introduced
in Eqi due to an existentially quantified variable y, we let uy J = (y). The resulting
interpretation is a model of Eqi , and since these individuals uy do not occur in the ontology,
modelhood for hT , Ai is preserved.
For 3, we use the extended ABox A0 and TBox T 0 to enforce the UNA over the individuals occurring in P. The ABox A0 extends A with an assertion Ac (c) for each individual
647

fiCalvanese, Ortiz, Simkus & Stefanoni

c occurring in P, where each Ac is a fresh concept name. The TBox T 0 consists of axioms
Ac v Ac0 for all pairs c 6= c0 of individuals occurring in P. Since the interpretations of
hT , Ai under the UNA and of hT 0 , A0 i without the UNA coincide, the claim easily follows
from statement 2 above.
A direct consequence of this proposition is that, for all DLs, we can restrict our search
to explanations that result from instantiating the input query.
Corollary 3.9. Let P = hT , A, q, ~c, i be a QAP with unrestricted explanation signature,
let max(q) = maxqi q |at(qi )|, and let max-terms(q) = maxqi q |qi |. If P has an explanation,
then P has an explanation with concepts and roles only from q, at most max(q) atoms, and
at most max-terms(q) individuals.
3.3.2 Restricted Explanation Signature
If we allow for restricted explanation signatures, then Proposition 3.8 does not hold anymore,
and the search space for possible explanations becomes significantly larger. As we will see
in the following sections, this has a notable effect on the complexity of the different decision
problems. However, in the case of DL-Lite A , we can still show a weaker version of the
proposition that allows us to restrict our search to the instantiations of the queries in the
perfect reformulation of the input query q. Moreover, every -minimal explanation can be
obtained this way.
Proposition 3.10. Let P = hT , A, q, ~c, i be a QAP where hT , Ai is a DL-LiteA ontology,
and let Rq,T be the perfect reformulation of q w.r.t. T . A solution to P exists if and only
if a ~c-instantiation E of some qr  Rq,T exists such that (i) hT , A  E i is consistent,
and (ii) E \ A is a -ABox. Moreover, E 0 is a -minimal explanation implies that query
qr  Rq,T and ABox E exist such that E is a ~c-instantiation of qr and E 0 = E \ A.
Proof. The first part of the claim is shown analogously to item 1 of Proposition 3.8 (recall
that in DL-Lite A we make the UNA). For the if direction, consider an arbitrary qr  Rq,T
and let E be a ~c-instantiation of qr generated from a mapping . We assume that hT , A  E i
is consistent and that E \ A is a -ABox. Then, to show that E \ A is a solution to P, it
suffices to show the existence of a match  for qr in DB AE witnessing ~c  cert(q, T , AE ).
This  is easily obtained by setting (t) = (t)I for each term t in qr . For the only-if
direction, we assume an arbitrary solution E to P and use it to show that there exists a ~cinstantiation E of some qr  Rq,T that satisfies conditions (i) and (ii). Since E is a solution
to P, by definition, E is a -ABox, hT , A  Ei is consistent, and ~c  cert(q, T , A  E). By
Proposition 2.1, it follows that there exists a query qr  Rq,T and a match  for qr in
DB AE that witness ~c  ans(qr , DB AE ). We define a mapping  by setting (t) = (t) for
each term t in qr . Then, for the resulting ~c-instantiation E we have that E  E  A, which
implies the consistency of hT , A  E i and that E \ A is also a -ABox as desired.
To show the second part of the claim, suppose E is a -minimal solution to P. By
Proposition 2.1, we have that there exists some qr  Rq,T for which there exists a match 
witnessing ~c  ans(qr , DB AE ). We construct a ~c-instantiation E of qr as follows:
E = {A((t))  A  E | A(t)  at(qr )}  {R((t), (t0 ))  A  E | R(t, t0 )  at(qr )}
By the minimality of E, we have that E = E \ A.
648

fiReasoning about Explanations for Negative Query Answers in DL-Lite

Similarly as above, this implies that we can consider only small explanations whose size
is linear in the size of the input query q, but now their signature depends not only on q,
but also on the signature of the input TBox T .
Corollary 3.11. Let P = hT , A, q, ~c, i be a QAP where hT , Ai is a DL-LiteA ontology.
Furthermore, let max(q) = maxqi q |at(qi )|. If P = hT , A, q, ~c, i has an explanation, then
P has an explanation with concepts and roles only from T and q, at most max(q) atoms,
and at most 2  max(q) individuals.

4. Complexity for Instance Queries
We now study the complexity of reasoning over query abduction problems. We consider the
complexity under both unrestricted and restricted explanation signatures, and we consider
the different minimality criteria over abductive solutions. We measure the complexity of
a QAP P = hT , A, q, ~c, i in terms of the combined size of T , A, q, and that is, we
consider combined complexity. In this section, we investigate the complexity of reasoning
over QAPs when the body of the input query consists of a single unary atomthat is, we
consider instance queries. In the following section, we shall turn our attention to UCQs.
4.1 Existence of Explanations
Before giving the first complexity results, we show that, for instance queries, -minimal and
-minimal explanations coincide. To see this, consider an arbitrary QAP P = hT , A, q, c, i
such that q  IQ and let qr be an arbitrary CQ in the perfect reformulation Rq,T . By Propositions 2.1 and 3.10, it follows that each ~c-instantiation of qr that is consistent with hT , Ai
contains an explanation for P; moreover, each -minimal explanation for P can be obtained
in this way. As these explanations contain at most one assertion (cf. Proposition 2.1), and -minimal explanations are both of size at most one, and we obtain the following result.
Proposition 4.1. Let P = hT , A, q, ~c, i be a QAP such that hT , Ai is a DL-LiteA ontology
and q  IQ, and let E be an arbitrary -ABox. Then, E is a solution to P implies that a
solution E 0  E to P exists such that |E 0 |  1. Hence, expl (P) = expl (P).
Now we consider the complexity of deciding existence of an explanation.
Theorem 4.2. For DL-LiteA , instance queries, and under both unrestricted and restricted
explanation signatures, exist, -exist, and -exist are NL-complete.
Proof. By Proposition 3.5, it suffices to show the result for exist. We first provide an
algorithm that yields the desired upper bound, even with restricted explanation signatures.
Then we show that the problem is NL-hard already for the case of unrestricted signatures.
(membership) Let P = hT , A, q, c, i be a QAP such that q  IQ. To decide exist in
non-deterministic logarithmic space, we can exploit Proposition 4.1 and test all candidate
singleton explanations by iterating over , the individuals occurring in P, and at most
two anonymous individuals. This results in at most polynomially many candidate solutions E of constant size. For each of them we test whether hT , A  Ei is consistent and
c  cert(q, T , A  E). Since for DL-Lite A both ontology consistency and instance checking
can be solved in non-deterministic logarithmic space, exist is in NL.
649

fiCalvanese, Ortiz, Simkus & Stefanoni

Algorithm 1 isNEC
~ such that hT , Ai is a DL-Lite A ontology,
Input: QAP P = hT , A, q, ~c, i and assertion (d)
q  IQ  CQ,  is unrestricted, and   .
~ is necessary for P.
Output: yes iff (d)
1: Let  be a globally fresh predicate of the same arity as .
~
2: Let T 0 := T  { v } and let A0 := A  {(d)}.
0
0
3: If hT , A , q, ~
c, i admits a solution, then return no.
~
4: Let I be the set of all individuals occurring in P and d.
Let u be a globally fresh anonymous individual.
~ 6 E  do
for all -ABoxes E  over the individuals in I  {u} s.t. |E  |  1 and (d)
~ and hT , A  E  , q, ~c, i admits a solution, then return no.
7:
If hT , A  E  i |= (d)
8: end for
9: Return yes.

5:
6:

(hardness) We reduce the DL-Lite A ontology consistency problem (under the UNA)
to exist. Consider an arbitrary DL-Lite A ontology hT , Ai. Furthermore, consider an
arbitrary atomic concept A not occurring in hT , Ai, let q = A(x), let c  NI be an arbitrary
individual, and let P = hT , A, q, c, i be a QAP with unrestricted . We show that hT , Ai
is consistent if and only if P admits a solution. The if direction is trivial. For the onlyif direction, suppose that hT , Ai is consistent, and consider E = {A(c)}. Since hT , Ai is
consistent and A is fresh, hT , A  Ei is also consistent. As each model I of hT , A  Ei
satisfies the assertion A(c), E is a solution to P.
4.2 Deciding Necessity
In Section 3.1, we have seen that for QAPs with restricted explanation signatures and
DLs that allow for disjointness axioms, nec reduces to non-exist. For the case of QAPs
with unrestricted explanation signatures but ontologies restricted to DL-Lite A , we provide
in Algorithm 1 a Turing reduction to (non-)exist; that is, a procedure that solves nec by
employing a subroutine for solving exist. The following proposition proves its correctness.
Proposition 4.3. For DL-LiteA , instance queries and UCQs, and under unrestricted explanation signatures, algorithm isNEC decides nec.
Proof. Let P = hT , A, q, ~c, i be a QAP such that hT , Ai is a DL-Lite A ontology, query
~ be an assertion over
q  IQ  CQ, and signature  is unrestricted; furthermore, let (d)
~
abducible predicate   . We prove that (d) is necessary for P iff isNEC returns yes.
For the only-if direction, we prove the contrapositive. Suppose that isNEC returns no
~ 6 E. According
on the given instance; we show that a solution E to P exists such that (d)
to the construction of isNEC, we consider two alternative cases.
 QAP hT 0 , A0 , q, ~c, i admits a solution E. For DL-Lite A , Calvanese et al. (2009)
showed that negative inclusion axioms affect only the consistency of the given ontology,
but do not contribute towards computing the certain answer; that is, ~c  cert(q, T 0 , A0 )
~ is over a
iff hT 0 , A0 i is consistent and ~c  cert(q, T , A0 ). Then, since assertion (d)
0
0
predicate not occurring in P and hT , A i is consistent, we have that E is also a solution
650

fiReasoning about Explanations for Negative Query Answers in DL-Lite

~ since
to P = hT , A, q, ~c, i. By the definition, such solution does not contain (d),
0
0
0
~ and  v   T .
hT , A i |= (d)
 QAP hT 0 , A0 , q, ~c, i has no solution. Since isNEC returns no, a -ABox E  ex~ 6 E  , hT , A  E  i |= (d),
~ and QAP hT , A  E  , q, ~c, i
ists such that |E  |  1, (d)
~ is entailed by hT , A  E  i we have that
has a solution E. Given that assertion (d)
0
~
E := E \ {(d)} is also a solution to hT , A  E  , q, ~c, i. We conclude that E 0  E  is
~ as required.
a solution to hT , A, q, ~c, i that does not contain (d),
For the if direction, we prove the contrapositive. Suppose that a -ABox E exists such
~ 6 E; we show that isNEC returns no. W.l.o.g., the
that E is a solution to P and (d)
~ we have that E is
individual u of Algorithm 1 does not occur in E. Now, if hT , A  Ei 6|= (d),
0
0
a solution to QAP hT , A , q, ~c, i, so isNEC returns no, as required. Otherwise, consider
~ and take the conjunctive query q 0 (~x)  (~x). By the
the case in which hT , A  Ei |= (d)
assumption, we have that d~  cert(q 0 , T , A  E). By Proposition 2.1, a query r  Rq0 ,T and
a match  for r exist such that r contains a single atom and d~  ans(r, DB AE ) is witnessed
by . Let (~y ) be the unique atom occurring in r such that ~x  ~y and let (~t) be the
assertion obtained from (~y ) by replacing each variable y  ~y with (y). Clearly, we have
that (~t)  A  E. Next, we distinguish among two cases.
 For each variable y  ~y we have that (y)  I. Then, let E  := , if (~t)  A,
~ 6 E  , that
and let E  := {(~t)}, if (~t)  E. In either case, we have that (d)


~ and that E  E. Hence, E is a solution to QAP hT , A  E  , q, ~c, i;
hT , A  E i |= (d),
so isNEC returns no, as required.
 Variable y  ~y exists such that (y) 6 I. Given that d~  I, d~  ans(r, DB AE ), and
predicates have arity at most 2, we have that d~ is of the form d~ := hdi,   NC , and
  NR . It follows that CQ r is of the form r(x)  (x, y) or r(x)  (y, x). Next,
we consider the former case only, as the other case is symmetrical. Then, assertion
(~t) is of the form (d, (y)). Since (y) 6 I, we have that (d, (y))  E. Now, let
E 0 be the ABox obtained from E by replacing each occurrence of individual (y) with
the individual u of Algorithm 1. Since E 0 is obtained from solution E by uniformly
replacing an anonymous individual with an individual that does not occur in E and P,
we have that E 0 is also a solution to P. By the definition, (d) 6 E 0 and (d, u)  E 0 .
Now, let E  := {(d, u)}. Since d  ans(r, DB AE ) is witnessed by  and by the
definition of E  , we have that hT , A  E  i |= (d). At last, since E   E 0 and E 0 is a
solution to P, we conclude that ABox E 0 is a solution to hT , A  E  , q, ~c, i. Hence,
isNEC returns no, as required.
Next, we use Algorithm 1 and Propositions 3.1 and 3.2 to characterize the complexity
of nec in the presence of instance queries.
Theorem 4.4. For DL-LiteA , instance queries, and under both unrestricted and restricted
explanation signatures, nec, -nec, and -nec are NL-complete.
Proof. For the NL upper bound for nec and under restricted signatures, observe that, by
Proposition 3.2, nec reduces to non-exist. In Theorem 4.2, we proved that exist is in NL.
651

fiCalvanese, Ortiz, Simkus & Stefanoni

Given that NL = coNL, we have that nec is in NL as well. The NL upper bound in the
case of unrestricted signature can be established using algorithm isNEC and Proposition 4.3.
Indeed, given that NL = coNL, that non-exist is in coNL, and that checking whether an
assertion is entailed by a DL-Lite A ontology is in coNL as well, we immediately obtain that
isNEC runs in nondeterministic logarithmic space. The coNL-hardness and thus also NLhardness of nec follows from Proposition 3.1 and Theorem 4.2. In addition, Proposition 3.4
states that nec and -nec are equivalent and, thus, also -nec is NL-complete. Finally,
by Proposition 4.1, we conclude that -nec is NL-complete.
4.3 Deciding Relevance
By Proposition 3.3, deciding the relevance of an assertion to a QAP is equivalent to assessing
whether a QAP admits a solution. We already showed this latter problem to be NL-complete
(see Theorem 4.2). Therefore, the following result easily follows.
Theorem 4.5. For DL-LiteA , instance queries, and under both unrestricted and restricted
explanation signatures, rel is NL-complete.
In the next theorem, we show that the complexity of the problem does not change even
when we apply a minimality criterion over solutions.
Theorem 4.6. For DL-LiteA , instance queries, and under both restricted and unrestricted
explanation signatures, -rel and -rel are NL-complete.
Proof. By Proposition 4.1, it suffices to show that -rel is NL-complete.
~ be an
(membership) Let P = hT , A, q, c, i be a QAP such that q  IQ and let (d)
~ is -relevant to P if and only
ABox assertion over abducible predicate . We argue that (d)
~
~
if (i) c 6 cert(q, T , A), (ii) hT , A  {(d)}i is consistent, and (iii) c  cert(q, T , A  {(d)}).
We show the only-if direction, since the if direction directly follows by Proposition 4.1 and
~ is -relevant to P. By the definition
by the definition of solution. Suppose that (d)
of minimal solution, it follows that c 6 cert(q, T , A). Also, by Proposition 4.1, it follows
~ is a -solution to P. But then, we have that c  cert(q, T , A  {(d)})
~
that {(d)}
and
~
that the ontology hT , A  {(d)}i is consistent. Since conditions (i-iii) can be decided in
non-deterministic logarithmic space for DL-Lite A ontologies, we conclude that, for instance
queries and (un)restricted explanation signatures, -rel is in NL.
(hardness) Hardness can be proved by employing the same reduction as in Theorem 4.2
and by taking A(c) to be the assertion to be shown relevant. By Proposition 4.1, we have
that hT , Ai is consistent if and only if A(c) is -relevant for P.
4.4 Deciding Recognition
Finally, we consider the problem of deciding whether a given ABox is a solution to a QAP.
Theorem 4.7. For DL-LiteA , instance queries, and under both unrestricted and restricted
explanation signatures, rec is NL-complete.
Proof. (membership) Let P = hT , A, q, c, i be a QAP (where  may be restricted) such
that q  IQ and let E be an ABox. By the definition of solution to a QAP, we can decide
652

fiReasoning about Explanations for Negative Query Answers in DL-Lite



-exist
unrestr.

restr.

none



PTime

NP

-nec

-rel

-rec

unrestr.

restr.

unrestr.

restr.

PTime

coNP

PTime

NP

PNP
k
PTime

PNP
k
coNP

in P2

unrestr.

restr.

NP
DP

P2

DP

Table 5.1: Complexity of reasoning over QAPs with UCQs for DL-Lite A . All entries in the
table denote completeness results, except for -rel under unrestricted explanation signatures.

whether E  expl(P) in three steps: (i) check that E is a -ABox, (ii) check that hT , A  Ei
is consistent, and (iii) check that c  cert(q, T , A  E). For DL-Lite A ontologies, we can
perform these three steps in non-deterministic logarithmic space. Thus, for instance queries
and under both restricted and unrestricted signatures, rec is in NL.
(hardness) We provide a reduction from the consistency problem of DL-Lite A ontologies. Consider an arbitrary ontology hT , Ai. Then, we let A be a fresh concept name not
occurring in the ontology and we let c be a fresh individual. Furthermore, let q(x)  A(x)
be our instance query. Finally, we let P = hT , A, q, c, i be our query abduction problem
with unrestricted explanation signature and we let E = {A(c)} be our target ABox. It is
not too difficult to see that hT , Ai is consistent iff E is a solution to P.
Unsurprisingly, the complexity does not change when we consider a minimality criterion
over solutions.
Theorem 4.8. For DL-LiteA , instance queries, and under both unrestricted and restricted
explanation signatures, -rec and -rec are NL-complete
Proof. By Proposition 4.1, we focus only on -rec.
(membership) In order to decide whether E  expl (P) we first check that E is indeed
a solution to P, which we can do in non-deterministic logarithmic space (see Theorem 4.7).
Then, by Proposition 4.1, we need to check that |E|  1 and that E is the empty ABox
whenever c  cert(q, T , A). Since instance checking in DL-Lite A is in NL, we conclude that
-rec is in NL as well.
(hardness) We can reuse the reduction to consistency in DL-Lite A provided in Theorem 4.7 to show that, for instance queries and under unrestricted explanation signatures,
-nec is NL-hard. We conclude that, under both restricted and unrestricted explanation
signature, -nec and -nec are NL-complete.

5. Complexity for Unions of Conjunctive Queries
In this section, we consider the more general problem of reasoning over query abduction
problems that admit UCQs in the input. We establish the complexity of the various rea653

fiCalvanese, Ortiz, Simkus & Stefanoni

Algorithm 2 someExplanation
Input: QAP P = hT , A, q, ~c, i.
Output: yes iff P has an explanation.
1: Guess a CQ qr in the perfect reformulation Rq,T of q w.r.t. T .
2: Guess a ~
c-instantiation E of qr .
3: If E \ A is a -ABox and hT , A  E i is consistent, then return yes.
4: Return no.
soning tasks for these problems in DL-Lite A , under both unrestricted and restricted explanation signatures, and under the different minimality criteria. The results in this section
are summarized in Table 5.1.
5.1 Existence of Explanations
We first focus on the problem of deciding whether a query abduction problem with unrestricted signature admits at least one explanation.
It follows from Proposition 3.8 that the complexity of this problem coincides with the
complexity of deciding consistency without the UNA in the underlying DL. By Proposition 3.5, this extends to -exist, and -exist. Since reasoning without the UNA is
PTime-complete for DL-Lite A (Artale et al., 2009), we obtain the following result.
Theorem 5.1. For every DL L, UCQs, and under unrestricted explanation signatures,
exist, -exist, and -exist have the same complexity as consistency checking without
the UNA in L. Hence for DL-LiteA , the mentioned problems are PTime-complete.
If we allow for restricted explanation signatures, then deciding exist becomes harder.
For DL-Lite A , the complexity increases from PTime to NP.
Theorem 5.2. For DL-LiteA , UCQs, and under restricted explanation signatures, exist,
-exist, and -exist are NP-complete. NP-hardness holds already in the following restricted settings:
1. QAPs where the TBox contains only concept inclusions of the forms A1 v A2 and
A1 vA2 for concept names A1 and A2 , the ABox is empty, and the query is a Boolean
CQ consisting of a conjunction of unary atoms over a single quantified variable.
2. QAPs with an empty TBox.
Proof. By Proposition 3.5, it is sufficient to show that exist is NP-complete.
(membership) The upper bound follows from guess-and-check Algorithm 2, which is
immediate by Proposition 3.10. It guesses non-deterministically a CQ qr in the perfect
reformulation Rq,T of q w.r.t. T , and a ~c-instantiation E of qr . The algorithm then checks
in polynomial time that E \ A is a -ABox and that the ontology hT , A  E i is consistent;
it was shown by Calvanese et al. (2009) that the latter check is polynomial.
(hardness) Next, we provide the two hardness results. The first one follows directly
from Proposition 3.7 and the hardness proof for CQ query emptiness for the sublogic of
654

fiReasoning about Explanations for Negative Query Answers in DL-Lite

DL-LiteA known as DL-Litecore given in Theorem 17 by Baader et al. (2010). For showing hardness in the second setting, we reduce the following NP-complete problem: given a
pair of directed graphs G = (V, E) and G0 = (V 0 , E 0 ), decide whether there exists an homomorphism from G to G0 . To this end, let A = {e(ca , cb ) | (a, b)  E 0 } be an ABox.
Furthermore, for B an arbitrary atomic concept and c a globally fresh individual, let
q = {e(xa , xb ) | (a, b)  E}  {B(c)} be a Boolean CQ and  = {B} be a signature. Finally, let PG,G0 = h, A, q, i be a QAP; we show that there exists a homomorphism from
G to G0 iff there is a solution to PG,G0 . Indeed, if there is a homomorphism from G to G0 ,
then {B(c)} is a solution to P. For the other direction, assume there is an explanation E
for P. Since binary atoms are prohibited from occurring in E by the selection of , there
must exist a match  from q to DB A . Such a mapping  also witnesses the existence a
homomorphism from G to G0 .
5.2 Deciding Necessity
Now, we consider the problem of checking whether an assertion occurs in all the solutions
to a QAP P; that is, whether an assertion is necessary for P. For the case of restricted
explanation signatures, we use the reductions from Section 3.1 and Theorem 5.2 to derive
that nec and -nec are coNP-complete. For the case of unrestricted explanation signatures, we use the procedure for solving nec described in Algorithm 1 to show that nec and
-nec are PTime-complete.
Theorem 5.3. For DL-LiteA , UCQs, and under unrestricted explanation signatures, nec
and -nec are PTime-complete. Furthermore, under restricted explanation signatures,
nec and -nec are coNP-complete.
Proof. In Theorem 5.1 and Theorem 5.2, we proved that the problems of deciding the existence of a solution to a QAP with unrestricted and with restricted explanation signatures
are PTime-complete and NP-complete, respectively. By applying the reduction in Proposition 3.1, we have that nec is PTime-hard under unrestricted and coNP-hard under
restricted explanation signatures.
For the upper bound, we first consider the case of restricted explanation signatures. By
Proposition 3.2, nec reduces to non-exist. By Theorem 5.2, this latter problem can be
solved in nondeterministic polynomial time. We readily obtain that nec is in coNP. For
the case of unrestricted signatures, Proposition 4.3 states that algorithm isNEC solves nec,
even when we consider UCQs in input. By the definition, isNEC requires checking whether
polynomially many QAPs do not admit a solution, and whether polynomially many DLLite A ontologies entail a given assertion. Since for DL-Lite A , instance checking is in PTime
and, by Theorem 5.1, non-exist is in PTime, we conclude that isNEC runs in polynomial
time. Thus, nec under unrestricted signatures is in PTime.
We conclude that nec is PTime-complete under unrestricted and coNP-complete under
restricted explanation signatures.
Finally, Proposition 3.4 states that nec and -nec are equivalent and, thus, also -nec
is PTime-complete under unrestricted and coNP-complete under restricted explanation
signatures.
655

fiCalvanese, Ortiz, Simkus & Stefanoni

Now, we consider the complexity of -nec and we show that, under common assumptions, the problem is harder than nec. Intuitively, this is because one has to first compute
the minimal size of an explanation, and then inspect all the explanations of that size. In
the following, we will use [i..j] to denote the integer interval {i, . . . , j}.
Theorem 5.4. For DL-LiteA , UCQs, and under both unrestricted and restricted explanation signatures, -nec is PNP
k -complete. The hardness holds already for QAPs with an
empty TBox and a CQ.
Proof. We structure the proof as follows. First, we show that -nec is in PNP
k . Then, we
NP
prove that the problem is Pk -hard under restricted signatures. Finally, we argue that the
same reduction can also be used in the particular case of unrestricted signatures.
(membership) Consider an arbitrary QAP P = hT , A, q, ~c, i (where the signature
may be restricted) and let  be an arbitrary ABox assertion. From Corollary 3.9, we know
that if P has an explanation, then there exists an explanation whose size m is bounded
by max(q) = maxqi q |at(qi )|. Observe that hP, i is a negative instance of -nec iff there
is an i  [0..m] such that (a) P has an explanation E with |E| = i and  6 E, and (b) E
is -minimal. Thus, we use an auxiliary problem size-out, which is to decide given a
tuple hP 0 , 0 , n0 i, where P 0 is a QAP, 0 is an assertion, and n0 is an integer, whether there
exists an explanation E 0 for P 0 such that |E 0 | = n0 and 0 6 E 0 . Furthermore, the problem
no-smaller is to decide, given a tuple hP 0 , n0 i of a QAP and an integer, whether there
is no explanation E 0 for P 0 such that |E 0 | < n0 . Observe that size-out is in NP, while
no-smaller is in coNP. Take the tuple S = hA0 , B0 , . . . , Am , Bm i, where Ai = hP, , ii
and Bi = hP, ii, for all i  [0..m]. Due to the above observation,  occurs in all -minimal
explanations E for P iff for all i  [0..m], one of the following holds: (i) Ai is a negative
instance of size-out, or (ii) Bi is a negative instance of no-smaller. S can be built in
polynomial time in the size of the input, and whether all instances instances in S satisfy (i)
and (ii) above can be decided by making 2m parallel calls to an NP oracle. Thus we obtain
membership in PNP
k .
(hardness) We give a reduction from OddMinVertexCover, which is PNP
k -complete
(Wagner, 1987). An instance of this problem is given by a graph G = (V, E), and we are
asked whether the least cardinality over all vertex covers in G is odd. That is, is there an
odd integer k  [1..|V |] such that G has a vertex cover C with |C| = k, and there is no
vertex cover C 0 in G with |C 0 | < k?
In the reduction we exploit the following property. Given an integer k and a directed
graph G = (V, E) with m vertices, construct a new graph G0 = ([1..m], E 0 ) such that there
exist two symmetric edges between each i  [1..k] and j  [1..m]. The following holds: if
there is an injective homomorphism h from G to G0 , then G has a vertex cover of size k.
Indeed, take C = {v  V | h(v)  k}. Due to injectivity, |C| = k. Assume an arbitrary
edge {v1 , v2 }  E. Since h is a homomorphism, due to the selection of edges we must have
h(v1 )  k or h(v2 )  k. Then {v1 , v2 }  C 6=  by the selection of C.
Assume an arbitrary graph G = (V, E) with vertices V = {v1 , . . . , vm }. W.l.o.g.,
G is connected, directed, and has at least 2 nodes. We construct next a QAP PG =
h, A|V | , qG , hi, G i and an assertion G such that G is a positive instance of OddMinVertexCover iff G is -necessary for PG . In the reduction we use individuals odd , even, cij ,
where i, j  [0..m], concept names M , L, and roles P , 6=, Edge.
656

fiReasoning about Explanations for Negative Query Answers in DL-Lite

odd
A0
L

L

A1
L

L

L

A2
L

L

L

A3
L

A4

L

even

Figure 1: The structure of A|V | for a graph G = (V, E) with 4 vertices. Solid arcs in
A` represent assertions Egde(a, b) in A` introduced in (b). A dashed arc from
an ABox A` to the individual par (`) represents the collection of assertions that
relate each individual in A` to par (`) via the role P .
Let qG be the Boolean query consisting of atoms
(i) Edge(xi1 , xi2 ), for each edge (vi1 , vi2 )  E,
(ii) 6=(xi1 , xi2 ), for each i1 , i2  [1..m], i1 6= i2 , and
(iii) L(x1 ), . . . , L(xm ) and P (x1 , y), M (y).
Intuitively, in (i) we represent the graph G in the query. We will use atoms in (ii) to
ensure that different variables are mapped to distinct elements. The atoms L(xi ) will be
used to measure the size of vertex covers, while the atoms P (x1 , y) and M (y) will be used
to determine their parity. We allow explanations only over concept names, and thus set
G = {M, L}.
To define A|V | , we first construct a collection A0 , . . . , Am of ABoxes, where each Aj
consists of the assertions
(a) L(cji ), for each i  [j..m],
(b) Edge(cji1 , cji2 ), for all i1 , i2  [1..m] with i1  j or i2  j, and
(c) 6=(cji1 , cji2 ), for all i1 , i2  [1..m] with i1 6= i2 .
For an integer k, let par (k) = odd if k is odd, and par (k) = even, otherwise. Let A0 =
{P (cji , par (j)) | i, j  [0..m]}. Then A|V | = A0      Am  A0 . See Figure 1 for an example.
Finally, we let G = M (odd ). To prove the correctness of the reduction, we define
up(k) = {L(ck1 ), . . . , L(ckk ), M (par (k))}, and claim the following:
claim 1: If C is a vertex cover in G of size k, then up(k) is an explanation for PG .
Let A = A|V |  up(k). It suffices to show the existence of a match  for qG in DB A . Take
an enumeration z1 , . . . , zm of variables x1 , . . . , xm such that {z1 , . . . , zk } = {xi | vi  C}.
Take the mapping  such that (zi ) = cki for all i  [1..m], and (y) = par (k). Assume
an atom Edge(xi1 , xi2 ) in qG . Due to (b) in the definition of Aj , it suffices to show that
(xi1 ) = ck` or (xi2 ) = ck` for some `  k. Indeed, since C is a vertex cover, vi1  C or
vi2  C. Then due to the enumeration of variables, xi1 = z` or xi2 = z` for some `  k.
Due to the definition of , (xi1 ) = ck` or (xi2 ) = ck` for `  k. The atoms 6=(xi1 , xi2 ) in
qG are properly mapped due to (c) in the construction of Aj and the fact that  is injective
657

fiCalvanese, Ortiz, Simkus & Stefanoni

by construction. For an atom L(xi ) in qG we have two options. If (xi ) = ck` with `  k,
then L(ck` )  up(k) by the definition of up(k). Otherwise, if ` > k, then L(ck` )  Ak by the
definition of Ak . The atom P ((x1 ), (y)) belongs to A due to the definition of A0 , while
M ((y))  up(k) by construction of up(k).
claim 2: Assume up(k) is an explanation for PG . Then G has a vertex cover of size k.
Let A = A|V | up(k) and let  be a match for qG in DB A . Observe that due irreflexivity of
the role 6= and the atoms (ii) in qG ,  must be injective. Observe also that for all `  [1..m],
where ` 6= k, we have |{c`i | L(c`i )  A` }| < m. Due to the connectedness of G and atoms
L(x1 ), . . . , L(xm ) in qG ,  must use only the atoms in Ak  A0  up(k). That is,  is also a
match for qG in DB Ak A0 up(k) . Let C = {vi  V | (xi ) = ckn , n  [1..k]}. Then |C| = k
due to the injectivity of . To see that C is a vertex cover, assume an edge (vi1 , vi2 )  E.
By construction, qG has the atom Edge(xi1 , xi2 ). Since  is a match in DB Ak A0 up(k) ,
Edge((xi1 ), (xi2 ))  Ak . Then, by construction of Ak , we have (xi1 ) = ckn or (xi2 ) = ckn
with n  k. Then by the selection of C, {(xi1 ), (xi2 )}  C 6= .
claim 3: Assume E is a -minimal explanation for PG with size k. Then E = up(k 
1). Since G is connected and E is -minimal, there exist an index `  [1..m] such that
E  {L(c`1 ), . . . , L(c`m ), M (par (`))} and there is a match for qG in A`  A0  E. Since
L(c`i )  A` for i  [`+1..m] by the definition of A` , we have by cardinality minimality that
E  {L(c`1 ), . . . , L(c`` ), M (par (`))}. By the definition of A` , |{c`i | L(c`i )  A` }| = m  `.
Thus, due to the injectivity of any match  for qG , we must have |{c`i | L(c`i )  E}|  `.
Hence, E = {L(c`1 ), . . . , L(c`` ), M (par (`))} = up(`). Since |E| = k, we have ` = k  1.
We can now finalize the correctness proof:
() Suppose there exists an odd integer k  [1..|V |] such that G has a vertex cover C
with |C| = k, and there is no vertex cover C 0 in G with |C 0 | < k. By claim 1, up(k) is
an explanation for PG . We make sure that up(k) is -minimal. Suppose there exists an
explanation E 0 with size |E 0 | < |up(k)|, i.e., |E 0 | = ` for some `  k. We can assume that
E 0 is -minimal. Then by claim 3, E 0 = up(`  1). It follows from claim 2 that G has a
vertex cover of size `  1. Since `  1 < k, we arrive at a contradiction to the assumption
that G has no vertex cover of size < k. Thus up(k) is -minimal. Since k is odd, we have
M (odd )  up(k). By claim 3, apart from up(k) there is no other -minimal explanation
for PG . That is, M (odd ) occurs in all -minimal explanations for PG .
() Assume M (odd ) occurs in all -minimal explanations for PG . By claim 3, we
know that up(k) is the unique -minimal explanation, for some integer k. Since M (odd ) 
up(k), we get that k is odd. Then, by claim 2, there is a vertex cover C with size k. It
remains to ensure that there is no vertex cover C 0 of size ` < k. Assume the opposite.
Then by claim 1 we have that up(`) is an explanation with size |up(`)| < |up(k)|, which
contradicts the assumption that up(k) is -minimal. Thus G is a positive instance of
OddMinVertexCover.
The definition of G prohibits binary atoms from occurring in -minimal explanations.
The same effect can be achieved by using G = (, A|V | , qG ) and by modifying A|V | and qG
to make it prohibitively expensive to have binary atoms in -minimal explanations. Simply
replace each binary assertion r(c, d) in A|V | by fresh assertions r1 (c, d), . . . , rm+2 (c, d), and
each binary r(x, y) in qG by r1 (x, y), . . . , rm+2 (x, y). In this way the lower-bound can be
shown for unrestricted explanation signatures.
658

fiReasoning about Explanations for Negative Query Answers in DL-Lite

5.3 Deciding Relevance
Using Theorems 5.1 and 5.2, and the reductions in Section 3, we obtain the following results.
Theorem 5.5. For DL-LiteA , UCQs, and under unrestricted explanation signatures, rel
is PTime-complete. Under restricted explanation signatures, rel is NP-complete.
Unsurprisingly, for UCQs, -rel has the same complexity as -nec. Indeed, the two
problems share the same source of complexity, namely the need to inspect all explanations
up to a computed size, which allows us to reduce the OddMinVertexCover problem. In
fact, PNP
k -hardness can be shown using the same reduction as in the proof of Theorem 5.4,
and a matching upper bound can be obtained by slightly modifying the algorithm for -nec.
Theorem 5.6. For DL-LiteA , UCQs, and under both unrestricted and restricted explaNP
nation signatures, -rel is PNP
k -complete. Pk -hardness holds already for QAPs with an
empty TBox and a CQ.
Proof. First, we show that, under restricted explanation signatures, the problem -rel is in
NP
PNP
k . Second, we argue that, under unrestricted explanation signatures, -rel is Pk -hard.
(membership) -rel can be tackled in a way similar to -nec. In fact, the algorithm
described in Theorem 5.4 can be modified in order to solve this problem. Let size-in solve
the following problem: given a tuple hP, , ni, where P is a QAP,  an assertion, and n
an integer, decide whether there exists an explanation E, with |E| = n and   E. Then,
we change the positivity condition of the -nec algorithm as follows:  occurs in some
-minimal explanation E for P iff for some i  [0..m] it holds that: (i) Ai is a positive
instance of size-in, and (ii) Bi is a positive instance of no-smaller. It is easy to see
that size-in is solvable in NP, hence the whole problem is again in PNP
k .
(hardness) Recall the reduction from OddMinVertexCover to -nec in the proof
of Theorem 5.4. We argue that exactly the same reduction also shows PNP
k -hardness of
-rel. Assume a directed graph G and let PG and G be the QAP and the assertion
resulting in the reduction. To prove the claim it suffices to show the following equivalence:
G is -necessary for PG iff G is -relevant for PG . This equivalence follows directly from
claim 3, which states that PG has a unique -minimal explanation.
We now turn our attention to -rel. For this problem we obtain a precise complexity
characterization for the case of restricted explanation signatures, but we leave it open
whether for unrestricted signatures the P2 upper bound shown below is tight.2 We note
that for the latter case, a coNP lower bound can be easily shown, for instance, by a
reduction from the non-existence of a homomorphism between two graphs.
Theorem 5.7. For DL-LiteA , UCQs, and under both unrestricted and restricted explanation signatures, -rel is in P2 . Under restricted explanation signatures, -rel is P2 -hard,
and the hardness holds already for QAPs with an empty TBox and a CQ.
Proof. (membership) Let P = hT , A, q, ~c, i be a QAP and let  be an ABox assertion. We
now provide an extended version of the algorithm solving existence, which decides whether 
2. The proof of the P2 lower bound under unrestricted signatures in Theorem 2 by Calvanese, Ortiz, Simkus,
and Stefanoni (2011) is incorrect.

659

fiCalvanese, Ortiz, Simkus & Stefanoni

is -relevant for P. Let has-subexpl solve the problem of deciding whether a given explanation E has a subset which is itself an explanation. In our modified algorithm, similarly to
Algorithm 2, first we non-deterministically guess a CQ qr in the perfect reformulation Rq,T
of q w.r.t. T and a ~c-instantiation E of qr such that   E . Additionally to the consistency
test and to checking that E is a -ABox, we also check the complement of has-subexpl
for E, in order to assure that E is -minimal. It follows that  is -relevant. Since checking
the complement of has-subexpl can be done in coNP, the problem is solvable in P2 .
(hardness) We reduce the P2 -complete problem non-cert3col (Stewart, 1991, see
also Bonatti, Lutz, & Wolter, 2009). An instance of non-cert3col is given by a graph
G = (V, E) with vertices V = {1, . . . , n} such that every edge is labelled with a disjunction
of two literals over the Boolean propositions {p(i,j) | 1  i, j  n}. We say that edge e  E
evaluates to true under truth assignment  if  satisfies the disjunction labelling e. Then,
graph G is a positive instance to non-cert3col iff a truth assignment  exists such that
graph  (G)obtained from G by including only those edges that evalute to true under
 is not 3-colorable. Assume an instance G of non-cert3col. We show how to build in
polynomial time a QAP PG = hTG , AG , qG , ~cG , G i and an ABox assertion G . We first
present all relevant definitions, after which we discuss the intuition behind the reduction
and prove its correctness.
In the construction, we use an empty TBox and a Boolean CQ, thus TG =  and ~cG = hi.
In order to define the ABox AG , let L be a function that assigns to each edge e  E the
set {l1 , l2 } of literals occurring in its label. Moreover, we let T(e) (resp., F(e)) be the set
containing each truth assignment  to the literals in L(e) such that edge e evaluates to true
(resp., false) under  . Finally, for each truth assignment  and each literal l occurring in
G, we define the image of l w.r.t.  , written img (l), as follows.
(
l if  (l) = t
img (l) :=
l otherwise
We are now ready to define the ABox AG . In the definition, we use individuals a1 , . . . , a4 ;
moreover, for each literal l in G, we use individuals l and l to denote ls truth value. Also,
for all 1  k  `  4, each edge e  E, and each truth assignment   T(e)  F(e), we let
e,
k,`
be a fresh individual. ABox AG consists of four distinct components A , AtT , AfT , and
AC which we introduce next.
A ={d(l, l), d(l, l) | literal l occurs in G} 
{B(ak ) | 1  k  3}
e,
e,
AtT ={Re (ak , k,`
), Re (k,`
, a` ) | e  E,   T(e), 1  k < `  3} 
e,
{P (k,`
, img (l)) | e  E,   T(e), l  L(e), 1  k < `  3}
e,
e,
AfT ={Re (ak , k,`
), Re (k,`
, a` ) | e  E,   F(e), 1  k  `  3} 
e,
{P (k,`
, img (l)) | e  E,   F(e), l  L(e), 1  k  `  3}
e,
e,
AC ={Re (a4 , 4,4
), Re (4,4
, a4 ) | e  E,   T(e)  F(e)} 
e,
{P (4,4
, img (l)) | e  E,   T(e)  F(e), l  L(e)}

660

fiReasoning about Explanations for Negative Query Answers in DL-Lite

Next, we define the Boolean query qG . To this end, for each vertex i  V , let xi be a
distinct variable; for each edge hi, ji  E, let yi,j be a distinct variable; and, for each literal
l occurring in G, let zl and zl be two distinct variables. Then, for each edge hi, ji  E, let
qG contain the following atoms.
{B(xi ), Re (xi , yi,j ), Re (yi,j , xj ), B(xj )}  {P (yi,j , zl ), Al (zl ), d(zl , zl ) | l  L(e)}
Finally, we let G = B(a4 ) be the assertion we want to show to be relevant and let
G = {Al | literal l occurs in G}  {B} be the signature.
Now, we outline the main idea behind this construction. ABox AG encodes two structures: a triangular structure AtT  AfT and a cyclic structure AC . The former structure
over individuals a1 , a2 , and a3 is such that edges in G that evaluate to true according to an
arbitrary truth assignment  can be mapped only to non-reflexive edges (cf. AtT ). In contrast, edges of G that evaluate to false according to  can be mapped to an arbitrary edge
(cf. AfT ). The latter, cyclic, structure AC over individual a4 (which is not asserted to be
member of B) is such that G can be mapped over AC under all possible truth assignments.
Query qG is obtained from graph G by requiring that each vertex of the graph is a
member of concept B, by reifying edges of the graph, and by incorporating the disjunction
over literals. In particular, for each literal l in G, variables zl and zl represent the truth
values of l and atom Al (zl ) is used to enforce a particular truth assignment. Since ABox AG
does not contain assertions over concept Al , each minimal explanation E for PG corresponds
to a truth assignment  for G. That is, such E contains, for each literal l in G, either Al (l)
or Al (l). Also, by the definition of the ABox, query qG can be mapped over AtT  AfT
under minimal explanation E implies that  (G) is 3-colorable. In contrast, for every truth
assignment  , we can map query qG over the cyclic structure AC , provided that explanation
E asserts the individual a4 to be a member of B. We are now ready to formally prove the
correctness of our reduction.
() Suppose there is a truth assignment  such that  (G) is not 3-colorable; we show
that assertion B(a4 ) is -relevant for PG . Consider the -ABox E = {B(a4 )}  E , where
E = {Al (l) |  (l) = t}  {Al (l) |  (l) = f }. Clearly, E is an explanation. Indeed, we can
match the query qG over the cyclic structure AC by mapping all variables xi of qG to
(interpretation of) a4 . Suppose there is a smaller explanation E 0  E. Observe that E  E 0 .
This is because, for each literal l, concept Al does not occur in AG but does occur in qG .
Then, E \ {B(a4 )} must be an explanation. Then qG can be matched over the triangular
structure encoded in AG . Thus,  (G) is 3-colorable which contradicts the assumption.
() Let E be a -minimal explanation for PG containing B(a4 ); we show that there
exists a truth assignment  such that  (G) is not 3-colorable. We first argue that for each
literal l we have that either Al (l)  E or Al (l)  E. This follows from three considerations.
First, due to the signature restriction, predicate d cannot occur in E. Second, for each literal
l, query qG contains atoms Al (zl ) and d(zl , zl ), whereas ABox AG contains assertions d(l, l)
and d(l, l). Third, for each literal l, concept Al occurs in qG with one and only variable
zl . Therefore, since E is a minimal solution, we know that exactly one of Al (l)  E and
Al (l)  E holds. Next, we define the truth assignment  to the literals occurring in G. For
each literal l in G, let  (l) = t if Al (l)  E, and  (l) = f if Al (l)  E. It is not difficult
to argue that t(G) is not 3-colorable and thus G is a positive instance of non-cert3col.
661

fiCalvanese, Ortiz, Simkus & Stefanoni

Indeed, if  (G) was 3-colorable, qG could be mapped over the triangle structure of AG
making E \ {B(a4 )} a smaller explanation, which is a contradiction.
5.4 Recognizing Explanations
Unsurprisingly, for UCQs and under both unrestricted and restricted explanation signatures,
rec is in NP. Indeed, in order to solve the problem, we need to check consistency of the
explanation with the ontology, and check whether the given tuple is in the certain answer
to the query. The former is polynomial and the latter in NP.
Theorem 5.8. For DL-LiteA , UCQs, and under both restricted and unrestricted explanation signatures, we have that rec is NP-complete. NP-hardness holds already for QAPs
with an empty TBox and a CQ.
Proof. As usual, we first show that, under (un)restricted explanation signatures, rec is
in NP. Then, we argue that, under unrestricted explanation signatures, the problem is
NP-hard.
(membership) Given a QAP P = hT , A, q, ~c, i and an ABox E, we devise an algorithm
deciding rec as follows. Firstly, the procedure checks that E is indeed a -ABox; this check
is linear in E. Then it makes sure that extending the ontology with ABox E does not lead
to an inconsistent theory; this can be checked in polynomial time (Artale et al., 2009). At
last, it decides whether ~c occurs in cert(q, T , A  E); by Proposition 2.1 this is feasible in
NP. Hence overall the algorithm runs in non-deterministic polynomial time.
(hardness) We use essentially the same reduction from the existence of a homomorphism between directed graphs G and G0 as in the proof of Theorem 5.2, the only difference
being that instead of reducing it to the existence of an explanation over the signature
 = {B}, we leave the signature unrestricted (that is,  = (T , A, q)), and reduce the
problem to deciding whether E = {B(c)} is an explanation.
In case a preference order is in place, to recognize an explanation one has to check minimality as well. This check is coNP-hard for - and -minimality, leading to completeness
for DP.
Theorem 5.9. For DL-LiteA , UCQs, and under both restricted and unrestricted explanation signatures, we have that -rec and -rec are DP-complete. DP-hardness holds
already for QAPs with an empty TBox and a CQ.
Proof. We first argue that, under (un)restricted explanation signatures, the two problems
are in DP. Then, under unrestricted explanation signatures, we prove that -rec and
-rec are DP-hard.
(membership) Membership of a problem  in DP can be shown by providing two
languages L1  NP and L2  coNP, such that the set of all yes-instances of  is L1  L2 .
For -rec, simply let
L1 = {(P, E) | E  expl(P)}
L2 = {(P, E) | P has no explanation E 0 s.t. |E 0 | < |E|}
For -rec, we take L1 as above and L2 = {(P, E) | P has no explanation E 0 s.t. E 0 ( E}.
662

fiReasoning about Explanations for Negative Query Answers in DL-Lite

(hardness) DP-hardness is shown by a reduction from the problem HP-noHP. An
instance of HP-noHP is given by two directed graphs G = (V, E) and G0 = (V 0 , E 0 ), where
hG, G0 i is a positive instance iff G has an Hamilton path and G0 does not have one. For
such a pair hG, G0 i, we define a QAP P = h, A, q, hi, i and a -ABox E such that:
(a) hG, G0 i is a positive instance of HP-noHP iff E is a -minimal explanation for P, and
(b) hG, G0 i is a positive instance of HP-noHP iff E is a -minimal explanation for P.
W.l.o.g., nodes in G and G0 are disjoint and are ordinary individuals. Construct an ABox
AG = {e(vi , vj ) | (vi , vj )  E}  {d(vi , vj ) | vi , vj  V, vi 6= vi }. Intuitively, an assertion
e(vi , vj ) encodes an edge (vi , vj ) in the graph G, whereas an assertion d(vi , vj ) encodes that
nodes vi and vj are distinct. The ABox AG0 encodes G0 in a similar way as before, using roles
e0 instead of e, and in addition it has an assertion A(vi0 ) for each vi0  V 0 . Take a set of fresh
individuals O = {o1 , . . . , o|V 0 | } and an ABox AC = {e0 (oi , oj ), d(oi , oj ) | 1  i 6= j  |V 0 |}.
Then the ABox A in P is defined as A = AG  AG0  AC .
Let q = q1  q10  q2  q20  q3 be a Boolean CQ with
q1
q10
q2
q20
q3

=
=
=
=
=

{e(x1 , x2 ), e(x2 , x3 ), . . . , e(x|V |1 , x|V | ))},
{d(xi , xj ) | vi , vj  V, vi 6= vj },
{e0 (y1 , y2 ), e0 (y2 , y3 ), . . . , e0 (y|V 0 |1 , y|V 0 | )},
{d(yi , yj ) | vi0 , vj0  V 0 , vi0 6= vj0 },
{A(y1 ), . . . , A(y|V 0 | )}.

Intuitively, q1 q10 asks for a simple path with |V | vertices related via the role e. Analogously,
q2  q20 asks for a simple path with |V 0 | vertices related via the role e0 . Additionally, q3 asks
that each node on the latter path satisfies A.
Finally, we let E = {A(oi ) | oi  O} and we let  = (T , A, q).
() Assume that hG, G0 i is a positive instance of HP-noHP, and let a1 , . . . a|V | be a
Hamilton path in G. We show that E is a -minimal and a -minimal explanation for P.
To this end, first take a mapping  for variables in q such that (x1 ) = a1 , . . . , (x|V | ) = a|V |
and (y1 ) = o1 , . . . , (y|V 0 | ) = o|V 0 | . Then clearly  is a match for q in DB AE , and hence
E is an explanation to P. Indeed, the subquery q1  q10 of q is fulfilled because a1 , . . . a|V |
is a Hamilton path in G, q2  q20 is fulfilled because AC has a clique of size |V 0 |, while q3
is fulfilled by E. To assure minimality, assume towards a contradiction that there is an
explanation E 0 with |E 0 | < |E| or |E 0 |  |E|. In any case, |E 0 | < |V 0 |. Assume  0 is a match
for q in DB AE 0 . Note that AG and AG0 do not share individuals. Since q3  q20 asks for
|V 0 | elements satisfying A and |E 0 | < |V 0 |,  0 must map the variables y1 , . . . , y|V 0 | to the |V 0 |
distinct individuals of AG0 . Then the presence of q2 in q implies the existence of a Hamilton
path in G0 . Contradiction.
() Assume that E  expl (P) (resp., E  expl (P)) and  is a match for q in DB AE .
Note that e0 does not occur in AG and e does not occur in AG0  AC . Then by construction
of q1  q10 and AG ,  maps the variables x1 , . . . , x|V | to the |V | distinct constants of AG and
G must have a Hamilton path. Towards a contradiction suppose G0 also has a Hamilton
path. Then by construction of AG0 , q2  q20  q3 has a match in DB AG0 . This means we can
build a match  0 for q in DB AG0 , which in turn means that  is an explanation to P. This
contradicts the assumption that E is -minimal (resp., -minimal).
663

fiCalvanese, Ortiz, Simkus & Stefanoni

6. Discussion
In this section, we discuss some issues that remain for further investigation.
6.1 Computing Explanations
In our complexity analysis for DL-Lite A , we have not considered the problem of computing
solutions to query abduction problems. Nevertheless, we can infer upper bounds on the
complexity of computing solutions to a QAP P from the presented results. If the input
query in P is an instance query, then both computing an arbitrary solution and computing
all minimal3 solutions is easy, since by Proposition 3.10, we only need to consider singleton candidate explanations, and their number is polynomially bounded. The problem of
computing an arbitrary solution E remains polynomial for UCQs if the signature of P is
unrestricted, since we can always obtain E by creating a suitable direct instantiation of
one of the CQs in input (see Section 3.3). Instead, under restricted signatures, the total
number of (minimal) solutions is in general exponential in the size of the signature  and
in the maximal size of each query occurring in the input UCQ; so computing all of them
requires in general exponential time. It remains to be investigated whether these solutions
can be enumerated with a polynomial delay (cf., Penaloza & Sertkaya, 2010). In the case of
a restricted signature, however, the NP-harness result established in Theorem 5.2 implies
that to compute a solution E one essentially essentially cannot do better than guessing the
ABox E and deciding whether E  expl (P).
6.2 Data Complexity
In this work we have focused on combined complexity. With respect to data complexity
(i.e., when the complexity is measured with respect to the size of the ABox only, while both
the query and the TBox are considered fixed) and ontology complexity (i.e., when only the
query is considered fixed), we observe that those inference tasks that we have shown to be
NP-complete essentially rely on checking ontology consistency, and hence are in AC0 in data
complexity (Calvanese et al., 2009). Moreover, by Corollaries 3.9 and 3.11, one can restrict
the attention to explanations that are bounded by the size of the query, it follows that for
a fixed query, there are only polynomially many explanations to be considered. Hence all
our reasoning tasks are polynomial both in data complexity and in ontology complexity.
6.3 Other Description Logics.
All the lower bounds proved in the paper do not rely on properties that are exclusive to
DL-Lite A , hence they hold for other DLs as well. In fact, as we have mentioned, many
lower bounds hold even in the absence of a TBox. As for the upper bounds, we have
relied on DL-Lite A and on the existence of the perfect reformulation of a given query (see
Proposition 2.1) only to argue that canonical explanations are small and have a restricted
signature (more specifically, that they can be obtained by instantiating CQs in the perfect
reformulation of the input query) and that query answering can be done in NP. For this
reason, we expect our results to carry over to other DLs that admit small explanations
3. Since every ABox that is a superset of a solution is itself a solution, if we dont impose any minimality
condition, there will always be an exponential number of solutions, provided that one exists.

664

fiReasoning about Explanations for Negative Query Answers in DL-Lite

and for which query answering is in NP. For instance, both the lower and the upper bounds
we have established hold for OWL 2 QL, which is obtained from DL-Lite A by forbidding
functionality assertions and dropping the unique name assumption (as our results do not
rely on functionality axioms, the unique name assumption is irrelevant).
For more expressive DLs, some bounds on the complexity of our reasoning tasks can also
be inferred. In Corollary 5.1, we showed that for QAPs under unrestricted explanation signatures, deciding the existence of an explanation has the same complexity as ontology consistency without the UNA. Hence, the problem is ExpTime-complete for all the extensions
of ALC in which standard reasoning (with or without the UNA) is also ExpTime-complete,
like the well known SHIQ. If we consider restricted explanation signatures, the problem
becomes significantly harder. This is witnessed by the lower bounds by Baader et al. (2010)
stemming from CQ-emptiness (see Proposition 3.6): exist is already 2ExpTime hard for
ALCI (Theorem 28 of Baader et al., 2010), and undecidable for ALCF (Theorem 29). For
ALC, the authors have recently improved the lower bound of CQ-emptiness from ExpTime
to NExpTime (personal communication). As mentioned in Section 3, their upper bounds
do not apply directly to our setting (although we expect some of them to extend), and the
precise characterization of the reasoning problems considered in this paper for expressive
DLs remains open.

7. Related Work
The problem of explaining missing query answers was first considered by the database
community (Jagadish, Chapman, Elkiss, Jayapandian, Li, Nandi, & Yu, 2007). In the
literature, we found three different models of explanation for missing answers, which differ
on the notion of solution. First, Chapman and Jagadish (2009) have proposed a model in
which explanations are those relational operations (e.g., natural joins or selections) that are
responsible for preventing the given tuple to be returned in the answers. Second, Tran and
Chan (2010) have defined solutions to be refinements to the input query such that the given
tuple is an answer to the relaxed query over the database. Third, Huang, Chen, Doan,
and Naughton (2008) have defined solutions to be sequences of database update operations
such that the result of answering the given conjunctive query over the updated relational
instance includes the missing answer. Herschel and Hernandez (2010) have generalized
this latter model by considering UCQs with aggregation and grouping. Although this
explanation model is closely related to ours, both the work by Huang et al. and by Herschel
and Hernandez tackle the problem from the point of view of computing solutions, whereas
we are interested in outlining the computational complexity of the problem. Moreover, in
the spirit of abductive reasoning, our solutions are of a declarative rather than operational
naturethat is, solutions are databases rather than a sequence of database operations.
In classical logic, abductive reasoning is a form of non sequitur argument, in which a
conclusion B is not a logical consequence of the premises  ( 6|= B), even though B is
assumed to follow from the theory (Eiter & Gottlob, 1995). The aim is to find a set of
formulas A such that   A |= B. Abductive reasoning is important also in the context of
Description Logics (Elsenbroich, Kutz, & Sattler, 2006), where three orthogonal abductive
problems have been studied. First, abduction has been studied to explain conceptsthat
is, given two concepts C and D and a TBox T , concept abduction amounts to finding a
665

fiCalvanese, Ortiz, Simkus & Stefanoni

concept H such that T |= C u H v D and C u H is satisfiable w.r.t. T (Noia, Sciascio, &
Donini, 2009; Bienvenu, 2008). Second, Hubauer, Grimm, Lamparter, and Roshchin (2012)
have applied TBox abductive reasoning to diagnosis of complex systems. In particular,
given a TBox T , a set of abducible axioms Ax , and a set of axioms O, TBox abduction
amounts to finding a subset A of Ax such that T  A |= O. Third, Klarman, Endriss, and
Schlobach (2011) have studied the problem of ABox abduction over ALC ontologies. This
problem consists in finding which additions need to be made to the ABox in order to force
a set of ABox assertions to be logically entailed by the ontology. Along the same line, Du,
Qi, Shen, and Pan (2011a) have considered this problem from a more practical perspective.
More recently, Du, Wang, Qi, Pan, and Hu (2011b) have defined the problem of abductive
conjunctive query answering, which they use as the basis for a new approach to semantic
matchmaking. Given a satisfiable DL ontology O and a CQ q, a tuple ~c is called an abductive
answer to q w.r.t. O if there exists a set E of ABox assertions such that O  E |= q(~c).
Similarly to our approach, the authors allow to restrict the signature over which abductive
solutions can be constructed. In addition, one can limit the impact of E on O by specifying
a set of closed predicates; for each assertion  over a closed predicate we require that
O  E |=  if and only if O |= . The main contribution of the paper is a procedure for
computing abductive answers to CQs over ontologies formulated in the DLP fragment of
OWL 2, which is a fragment orthogonal to DL-Lite A in terms of expressiveness. Considering
closed predicates in the context of DL-Lite A and QAPs is an interesting research direction.

8. Conclusions
In this paper we have studied the problem of explaining negative answers to user queries
over DL-Lite A ontologies. We have formalized the problem as an abductive task: given
a (U)CQ q, a consistent ontology O and a tuple of constants ~c such that ~c is not in the
certain answers of q over O, an explanation is defined as a set of ABox assertions that,
when added to O, preserve its consistency and result in ~c being in the certain answers.
We considered the special cases of allowing only a restricted signature for the assertions
in the explanation, and having only an instance query rather than a full (U)CQ in the
input. We have also considered preference orders between explanations, and studied two
such orders: subset minimal and cardinality minimal explanations. For all these cases,
we have obtained complexity bounds for four decision problems inspired in knowledge base
abduction: deciding existence of an explanation (exist), deciding whether a given assertion
occurs in all (nec) or some (rel) explanations, and recognizing explanations (rec). All
our complexity bounds are tight, with the exception of rel for subset minimal explanations
under unrestricted signatures, for which we leave open a gap between coNP-hardness and
membership in P2 .
Specifically, we have shown that in the case of instance queries all these decision problems are tractable, and in fact NL-complete, even when restricted explanations signatures
and preference orders are simultaneously considered. The picture is significantly different
for (U)CQs, as the results in Table 5.1 show. Indeed, tractability is always lost as soon as
one considers restricted explanations signatures. If the signatures are not restricted, considering a preference order also results in intractability for most cases, the only exceptions
being exist, which is always tractable, and nec, which is polynomial for subset minimal
666

fiReasoning about Explanations for Negative Query Answers in DL-Lite

explanations but PNP
k for cardinality minimal ones. In contrast to nec, rel is harder, under
common assumptions, for subset minimal than for cardinality minimal explanations. rec
is hard even when the explanations signature is not restricted and no preference order is
considered.
It would be interesting to apply this framework to other lightweight description logics,
starting with those of the EL-family. Also, we would like to investigate other minimality
criteria. For instance, semantic criteria allow one to reward explanations that are less/more
constraining in terms of the models of an ontology.
Acknowledgments
The authors would like to thank the anonymous referees for their careful reading of the
submitted manuscript and their valuable comments. This work was partially supported by
the Austrian Science Fund (FWF) grants P20840 and T515, the EU FP7 projects ACSI
(Artifact-Centric Service Interoperation), grant agreement n. FP7-257593, and Optique
(Scalable End-user Access to Big Data), grant agreement n. FP7-318338, and by AlcatelLucent and EPSRC.

References
Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). The DL-Lite family
and relations. J. of Artificial Intelligence Research, 36, 169.
Baader, F., Bienvenu, M., Lutz, C., & Wolter, F. (2010). Query and predicate emptiness
in description logics. In Proc. of the 12th Int. Conf. on the Principles of Knowledge
Representation and Reasoning (KR 2010).
Bienvenu, M. (2008). Complexity of abduction in the EL family of lightweight description
logics. In Proc. of the 11th Int. Conf. on the Principles of Knowledge Representation
and Reasoning (KR 2008), pp. 220230. AAAI Press.
Bonatti, P. A., Lutz, C., & Wolter, F. (2009). The complexity of circumscription in description logics. J. of Artificial Intelligence Research, 35, 717773.
Borgida, A., Franconi, E., & Horrocks, I. (2000). Explaining ALC subsumption. In Proc.
of the 14th Eur. Conf. on Artificial Intelligence (ECAI 2000).
Borgida, A., Calvanese, D., & Rodriguez-Muro, M. (2008). Explanation in the DL-Lite family of description logics. In Proc. of the 7th Int. Conf. on Ontologies, DataBases, and
Applications of Semantics (ODBASE 2008), Vol. 5332 of Lecture Notes in Computer
Science, pp. 14401457. Springer.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Poggi, A., Rodriguez-Muro, M.,
& Rosati, R. (2009). Ontologies and databases: The DL-Lite approach. In Tessaris,
S., & Franconi, E. (Eds.), Semantic Technologies for Informations Systems  5th Int.
Reasoning Web Summer School (RW 2009), Vol. 5689 of Lecture Notes in Computer
Science, pp. 255356. Springer.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning and efficient query answering in description logics: The DL-Lite family. J.
of Automated Reasoning, 39 (3), 385429.
667

fiCalvanese, Ortiz, Simkus & Stefanoni

Calvanese, D., Ortiz, M., Simkus, M., & Stefanoni, G. (2011). The complexity of conjunctive
query abduction in DL-Lite. In Proc. of the 24th Int. Workshop on Description Logic
(DL 2011), Vol. 745 of CEUR Electronic Workshop Proceedings, http://ceur-ws.
org/.
Chapman, A., & Jagadish, H. V. (2009). Why not?. In Proc. of the ACM SIGMOD Int.
Conf. on Management of Data, pp. 523534.
Du, J., Qi, G., Shen, Y.-D., & Pan, J. Z. (2011a). Towards practical ABox abduction in
large OWL DL ontologies. In Proc. of the 25th AAAI Conf. on Artificial Intelligence
(AAAI 2011). AAAI Press.
Du, J., Wang, S., Qi, G., Pan, J. Z., & Hu, Y. (2011b). A new matchmaking approach
based on abductive conjunctive query answering. In Proc. of the Joint Int. Semantic
Tech. Conf. (JIST 2011), pp. 144159.
Eiter, T., & Gottlob, G. (1995). The complexity of logic-based abduction. J. of the ACM,
42 (1), 342.
Elsenbroich, C., Kutz, O., & Sattler, U. (2006). A case for abductive reasoning over
ontologies. In Proc. of the 2nd Int. Workshop on OWL: Experiences and Directions (OWLED 2006), Vol. 216. CEUR Electronic Workshop Proceedings, http:
//ceur-ws.org/.
Herschel, M., & Hernandez, M. A. (2010). Explaining missing answers to SPJUA queries.
Proc. of the VLDB Endowment, 3 (1), 185196.
Horridge, M., Parsia, B., & Sattler, U. (2008). Laconic and precise justifications in OWL.
In Proc. of the 7th Int. Semantic Web Conf. (ISWC 2008), Vol. 5318 of Lecture Notes
in Computer Science, pp. 323338. Springer.
Huang, J., Chen, T., Doan, A., & Naughton, J. (2008). On the provenance of non-answers
to queries over extracted data. Proc. of the VLDB Endowment, 1 (1), 736747.
Hubauer, T., Grimm, S., Lamparter, S., & Roshchin, M. (2012). A diagnostics framework
based on abductive description logic reasoning. In Proc. of the IEEE Int. Conf. on
Industrial Technology, (ICIT 2012), pp. 1047 1054.
Jagadish, H. V., Chapman, A., Elkiss, A., Jayapandian, M., Li, Y., Nandi, A., & Yu, C.
(2007). Making database systems usable. In Proc. of the ACM SIGMOD Int. Conf.
on Management of Data, pp. 1324.
Klarman, S., Endriss, U., & Schlobach, S. (2011). ABox abduction in the description logic
ALC. J. of Automated Reasoning, 46 (1), 4380.
McGuinness, D. L., & Borgida, A. (1995). Explaining subsumption in description logics. In
Proc. of the 14th Int. Joint Conf. on Artificial Intelligence (IJCAI 1995), pp. 816821.
McGuinness, D. L., & Patel-Schneider, P. F. (1998). Usability issues in knowledge representation systems. In Proc. of the 15th Nat. Conf. on Artificial Intelligence (AAAI 1998),
pp. 608614. AAAI Press/The MIT Press.
Motik, B., Fokoue, A., Horrocks, I., Wu, Z., Lutz, C., & Grau, B. C. (2009). OWL 2 Web
Ontology Language Profiles. W3C Recommendation, World Wide Web Consortium.
668

fiReasoning about Explanations for Negative Query Answers in DL-Lite

Noia, T. D., Sciascio, E. D., & Donini, F. M. (2009). A tableaux-based calculus for abduction
in expressive description logics: Preliminary results. In Proc. of the 22rd Int. Workshop
on Description Logic (DL 2009), Vol. 477. CEUR Electronic Workshop Proceedings,
http://ceur-ws.org/.
Papadimitriou, C. H. (1994). Computational Complexity. Addison Wesley Publ. Co.
Penaloza, R., & Sertkaya, B. (2010). Complexity of axiom pinpointing in the DL-Lite
family of description logics. In Proc. of the 19th Eur. Conf. on Artificial Intelligence
(ECAI 2010), pp. 2934. IOS Press.
Stewart, I. A. (1991). Complete problems involving boolean labelled structures and projection transactions. J. of Logic and Computation, 1 (6), 861882.
Tran, Q. T., & Chan, C.-Y. (2010). How to ConQueR why-not questions. In Proc. of the
ACM SIGMOD Int. Conf. on Management of Data, pp. 1526.
Vardi, M. Y. (1982). The complexity of relational query languages. In Proc. of the 14th
Symp. on Theory of computing (STOC 1982), pp. 137146.
Wagner, K. W. (1987). More complicated questions about maxima and minima, and some
closures of NP. Theoretical Computer Science, 51 (12), 5380.

669

fiJournal of Artificial Intelligence Research 48 (2013) 733-782

Submitted 04/13; published 11/13

Unsupervised Sub-tree Alignment
for Tree-to-Tree Translation
Tong Xiao
Jingbo Zhu

xiaotong@mail.neu.edu.cn
zhujingbo@mail.neu.edu.cn

College of Information Science and Engineering
Northeastern University
No 3-11, Wenhua Road, Heping District
Shenyang, China

Abstract
This article presents a probabilistic sub-tree alignment model and its application to
tree-to-tree machine translation. Unlike previous work, we do not resort to surface heuristics or expensive annotated data, but instead derive an unsupervised model to infer the
syntactic correspondence between two languages. More importantly, the developed model
is syntactically-motivated and does not rely on word alignments. As a by-product, our
model outputs a sub-tree alignment matrix encoding a large number of diverse alignments
between syntactic structures, from which machine translation systems can efficiently extract translation rules that are often filtered out due to the errors in 1-best alignment.
Experimental results show that the proposed approach outperforms three state-of-the-art
baseline approaches in both alignment accuracy and grammar quality. When applied to
machine translation, our approach yields a +1.0 BLEU improvement and a -0.9 TER reduction on the NIST machine translation evaluation corpora. With tree binarization and
fuzzy decoding, it even outperforms a state-of-the-art hierarchical phrase-based system.

1. Introduction
Recent years have witnessed increasing interest in syntax-based methods for many Artificial Intelligence (AI) and Natural Language Processing (NLP) applications ranging from
text summarization to Machine Translation (MT). In particular, syntax-based models have
been intensively investigated in Statistical Machine Translation (SMT). Approaches include
string-to-tree MT (Galley, Hopkins, Knight, & Marcu, 2004; Galley, Graehl, Knight, Marcu,
DeNeefe, Wang, & Thayer, 2006), tree-to-string MT (Liu, Liu, & Lin, 2006; Huang, Kevin,
& Joshi, 2006) and tree-to-tree MT (Eisner, 2003; Zhang, Jiang, Aw, Li, Tan, & Li, 2008;
Liu, Lu, & Liu, 2009a; Chiang, 2010), all of which train on tree-string/tree-tree pairs and
seek to model the translation equivalency relations learned from parsed data. As a part of
the focus on syntax-based MT, tree-to-tree models that use synchronous context free grammars or synchronous tree substitution grammars have received growing interest, showing
very promising results on several well-established evaluation tasks (Zhang et al., 2008; Liu
et al., 2009a; Chiang, 2010). For example, recent studies (Chiang, 2010) have demonstrated
that modern tree-to-tree systems can significantly outperform the hierarchical phrase-based
counterpart in large scale Chinese-English and Arabic-English translation.
In tree-to-tree MT, the translation problem can be broadly regarded as transformation
from a source-language syntax tree to a target-language syntax tree. To model this process,
c
2013
AI Access Foundation. All rights reserved.

fiXiao & Zhu

most tree-to-tree systems resort to the general framework of synchronous grammars, where
a pair of trees is generated with derivations of synchronous grammar rules (or translation
rules). In such a model, the goal of translation is to build the underlying derivations for
all pairs of trees and output the target string encoded in the most likely derivation. Figure
1 shows an intuitive example to illustrate the generation process of a tree pair using a
sample grammar, where both the source and target-language sentences are associated with
the phrase structure trees generated using automatic parsers.1
Previous work has shown that the acquisition of good translation rules is one of the essential factors contributing to the success of syntax-based systems (DeNeefe, Knight, Wang,
& Marcu, 2007). To date, several research groups have addressed the issue of rule acquisition and designed effective algorithms to extract high-coverage grammars from bilingual
parsed data (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010). Despite their differences
in detailed modeling, all these approaches rely on syntactic alignments that align tree nodes
in the syntactic parse tree in one language to tree nodes in the other, and these alignments
could be employed by standard tree-to-tree rule extraction algorithms (Liu et al., 2009a;
Chiang, 2010).
While current tree-to-tree models heavily depend on syntactic alignments between two
languages, all these alignments are induced indirectly from word alignments and tree-to-tree
systems are very sensitive to the word alignment behavior. Unfortunately, word alignments
are in general far from perfect from the viewpoint of syntactic alignment (Fossum, Knight,
& Abney, 2008). In some cases, even one spurious word alignment can prevent a large
number of desirable rules from extraction. For example, Figure 2(a) shows some tree-totree translation rules extracted using the word alignment produced by GIZA++. This
alignment incorrectly aligns the source word  (a past tense marker in Chinese) to the
target word the. This spurious word alignment produces an incorrect rule AS() 
DT(the) and blocks the extraction of more high-level syntactic transfer rules, such as
IP(NN1 VP2 )  S(NP1 VP2 ).
Obviously, a more desirable solution is to directly infer node correspondences from
the source and target parse trees, namely sub-tree alignment. As syntactic parse trees can
explain the underlying structure of sentences well, performing alignment in sub-tree level can
make more benefits from the high-level structural information and syntactic categorization.
For example, consider the alignment in Figure 2(b). It links up the nodes in the two parse
trees (in Chinese and English), rather than aligning them in word level. In this example, it
is very confident to align the VP sub-tree (spanning   ) in the source tree
to the VP sub-tree (spanning have drastically fallen) in the target tree.2 We therefore
1. In a phrase structure tree, the leaf nodes are words of the sentence. The internal tree nodes followed by
leaf nodes are labeled with Part-Of-Speech (POS) tags, while other tree nodes are labeled with syntactic
categories defined in treebanks (see appendix for meanings of the POS tags and syntactic categories used
in this work). In NLP, many well-developed parsers are available for automatic parsing. Also, several
good-quality phrase structure treebanks across languages can be used to train parsing models, such as
the Penn English and Chinese Treebanks (Marcus, Santorini, & Marcinkiewicz, 1993; Xue, Xia, Chiou,
& Palmer, 2005). Note that in addition to phrase structure syntax, there are other popular formalisms
(e.g., dependency syntax) can be used in syntax-based MT. But the discussion on different formalisms
of syntactic parsing is beyond the scope of this article. We instead focus on tree-to-tree MT based on
phrase structure trees throughout this work.
2. Both Chinese and English follow the subject-verb-object structure. The verb phrases in a Chinese
sentence are frequently aligned to the verb phrases in its English translation.

734

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

NP

VP

NP

VP

PRP

VBD

he

was

Target-language Side
(English)

S

VP
VBN

PP

satisfied
PP
IN

NP

with

r1

r4

DT

NNS

the

answers

r2


(ta)


(huida)

P

NN


(biaoshi)


(manyi)

VV

NN

PP

PN

PP

VP

NP

VP

NP

VP

Source-language Side
(Chinese)

r3

(dui)

IP

Synchronous Grammar Used
ID
r1
r2
r3
r4

Source-language Side
NP(PN())
PP(P() NN())
VP(PP1 VP(VV() NN()))
IP(NP1 VP2 )

Target-language Side
NP(PRP(he))
PP(IN(with) NP(DT(the) NNS(answers)))
VP(VBD(was) VP(VBN(satisfied) PP1 ))
S(NP1 VP2 )

Figure 1: Example derivation of tree-to-tree translation rules. All the rules are represented
as aligned pairs of tree-fragments (linked with dotted lines). The subscripts on
both language sides of the grammar rules indicate the alignments of frontier nonterminals. On each language side of the derivation, the round-head lines link up
the frontier non-terminals that are rewritten during translation.
know that the child nodes in the source-language VP are likely to be aligned with the child
nodes in the target-language VP. This means that once the two VPs are aligned, their
children should not be aligned outside the VP sub-tree structure, i.e., we can prevent the
alignment between the Chinese tree node AS and the English tree node DT due to its
inconsistency with the VP-VP alignment. In this case, AS is correctly aligned to VBP.
735

fiXiao & Zhu

S

S
NP
DT

NP

VP

NNS

VBP

DT

ADVP

the imports have

RB

VP

NNS

VBP

ADVP

the imports have

VBN

RB

drastically fallen

drastically fallen








VV

AS

AD

NN

VBN




VP



VV

AS

AD

NN

VP



VP
VP

IP

IP

(Minimal) Rules Extracted

(Minimal) Rules Extracted
r1

AS()  DT(the)

r3

AD()  RB(drastically)

r2

NN()  NNS(imports)

r4

VV()  VBN(fallen)

r3

AD()  RB(drastically)

r6

AS()  VBP(have)

r4

VV()  VBN(fallen)

r7

NN()  NP(DT(the) NNS(imports))

r5

IP(NN1 VP(AD2 VP(VV3 AS4 ))) 

r8

VP(AD1 VP(VV2 AS3 )) 
VP(VBP3 ADVP(RB1 VBN2 ))

S(NP(DT4 NNS1 ) VP(VBP(have) ADVP(RB2 VBN3 )))

r9

(a) word alignment and extracted rules

IP(NN1 VP2 )  S(NP1 VP2 )

(b) sub-tree alignment and extracted rules

Figure 2: Tree-to-tree translation rules extracted via word alignment (a) or sub-tree alignment (b). The dashed lines represent word alignment links, and the dotted lines
represent sub-tree alignment (or node alignment) links.
As a result, the bad rule AS()  DT(the) is ruled out, and a few more desirable rules
are extracted using the sub-tree alignment (including the desirable rules that are blocked
in Figure 2(a)).
Actually, researchers have been aware of the sub-tree alignment problem and tried to
explore solutions (Tinsley, Zhechev, Hearne, & Way, 2007; Sun, Zhang, & Tan, 2010b,
2010a). For example, they proposed to judge whether two nodes should be aligned or not. In
their work, the alignment confidence is first calculated using lexical translation probabilities
or classifiers trained on labeled data, and then the final alignment is determined according to
node-level alignment score. However, the inference of sub-tree alignment in these approaches
relies on heuristic algorithms, and their models are essentially not optimized within a unified
probabilistic framework.
Moreover, when the alignment result is applied to tree-to-tree translation, most systems
suffer from another problem that translation rules are extracted using the 1-best alignment
only (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010). This problem significantly affects
736

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

the rule-set coverage rate due to alignment errors. A simple solution to this issue is to use
k-best alignments instead. However, k-best alignments often have few variations and many
redundancies. Most of them differ in only a few alignment links. It is obviously inefficient
to extract rules from those similar alignments.
In this article we address the sub-tree alignment issue in a principled way and investigate
methods to effectively apply the sub-tree alignment result to tree-to-tree MT. In particular,
 We develop an unsupervised approach to learning a probabilistic sub-tree alignment
model from bi-lingual parsed data.
 We investigate different methods for integrating sub-tree alignment to tree-to-tree
machine translation. Specifically, we develop a sub-tree alignment matrix encoding
an exponentially large number of diverse sub-tree alignments, and extract multiple
alternative translation rules using alignment posteriors from the sub-tree alignment
matrix.
The advantages of our approach are three-fold. First, our approach does not rely on
heuristic algorithms or labeled data. Second, the developed sub-tree alignment model has
the same structure as the model used in MT, i.e., both are based on synchronous tree
substitution grammars. It means that MT systems can directly make benefits from the subtree alignment model, especially for rule extraction and MT parameter estimation. Third,
by accessing the sub-tree alignment matrix which encodes a large number of alignments,
we can efficiently obtain rules that are often filtered out due to the errors within the 1best/k-best alignment result. We experiment with our approach in Chinese-English subtree alignment and translation tasks. For sub-tree alignment, it significantly outperforms
three state-of-the-art baselines. For machine translation, our approach obtains significant
improvements for a tree-to-tree system in both rule quality and translation quality. For
example, it yields a +1.0 BLEU improvement and a -0.9 TER reduction on the NIST MT
evaluation corpora. Finally, our system even outperforms a state-of-the-art hierarchical
phrase-based system when equipped with tree binarization (Wang, Knight, & Marcu, 2007b)
and fuzzy decoding (Chiang, 2010) techniques.
The rest of the article is structured as follows. Section 2 briefly introduces the subtree alignment task. Section 3 describes our unsupervised approach to sub-tree alignment.
Then, Section 4 investigates effective methods for applying our alignment model to tree-totree translation. Then, Section 5 presents experimental evaluation of our approach. After
reviewing the related work in Section 6, some interesting issues are discussed in Section 7.
Finally, the article is concluded with a summary in Section 8.

2. Problem Statement
In general, sub-tree alignment can be defined as a task that we find an alignment from the
nodes in a tree to the nodes of another tree.3 While we restrict ourselves to machine translation in this article, sub-tree alignment is actually not a task that must be tightly coupled
with specific applications. For example, in addition to machine translation, there are other
3. In this work term tree refers to a data structure that can be defined recursively as a collection of nodes
starting at a root node. Each node has a list of edges pointing to nodes (or its children), with the
constraint that no edge is duplicated or points to the root (Knuth, 1997).

737

fiXiao & Zhu

NLP tasks which can make benefits from sub-tree alignment, including sentence simplification (Cohn & Lapata, 2009; Woodsend & Lapata, 2011), paraphrasing (Das & Smith,
2009), question answering (Wang, Smith, & Mitamura, 2007a), and parser adaptation and
projection (Smith & Eisner, 2009).
Ideally, we would like a sub-tree alignment system that is language independent and
application independent. Given a parallel corpus of training examples, we should be able
to learn an alignment model and use it to infer the syntactic correspondence for any tree
pairs. Broadly speaking, any alignments between paired linguistic tree structures can be
regarded as instances of sub-tree alignment. For example, the alignment can be performed
between dependency trees (Eisner, 2003; Nakazawa & Kurohashi, 2011) or phrase structure
trees (Tinsley et al., 2007; Sun et al., 2010b).
Although the sub-tree alignment problem includes a number of tasks that seek alignments between syntactic tree structures, we are particularly interested in aligning the tree
nodes of phrase structure trees in this work. We focus on phrase structure sub-tree alignment because: 1) phrase structure parsing is one of the most popular syntactic analysis
formalisms. Several state-of-the-art full parsing models/tools have been developed for many
languages; 2) phrase structure trees are the basis of many successful syntax-based MT systems. While other alternatives, such as dependency trees, can also benefit MT systems,
the constituency-based models are of interest to a relatively larger portion of the MT community and show state-of-the-art performance in recent tree-to-tree systems (Zhang et al.,
2008; Liu et al., 2009a; Chiang, 2010).
In natural language processing, a phrase structure parse tree is an ordered and rooted
tree. It represents the syntactic structure of a sentence according to some phrase structure grammars (or constituency grammars) which describe the way words combine to form
phrases and sentences (Chiswell & Hodges, 2007). Generally, phrase structure parse trees
distinguish between terminal and non-terminal nodes. The leaf nodes are labeled by terminal categories (or words), while the internal nodes are labeled by non-terminal categories of
the grammar (or phrasal categories). For example, in the English parse tree in Figure 2(b),
imports is a terminal, while nodes NP and NNS are two non-terminals indicating
the noun phrase and the plural form of nouns respectively.4 In the following description
and experiments, we take the Penn Treebank for the standard of tree annotation. Here we
choose the Penn Treebank because it is one of the most popular tree-annotated corpora
used in syntactic parsing and of good quality and quantity for several languages, such as
Chinese and English.
Based on the above definition, a sub-tree alignment can be defined as the alignments
between non-terminals in the source and target-language (phrase structure) parse trees.5
More formally, given a source-language parse tree S and a target-language parse tree T , a
sub-tree alignment (denoted as A(S, T ) or A for short) is a set of node-to-node links between
S and T . For any node pair (u, v) in (S, T ), a good alignment should follow three criteria
(Tinsley et al., 2007):
1. u (or v) can only be aligned once (indicating 1-to-1 alignment).
4. Note that the non-terminals that are always followed by leaf nodes are also called pre-terminals and
labeled by part-of-speech tags. E.g., the NNS node is followed by the terminal node imports and
thus is a pre-terminal.
5. In contrast, a word alignment can be regarded as the alignments between terminals in two languages.

738

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

2. if u is aligned to v, the descendants of u can only be aligned to the descendants of v.
3. if u is aligned to v, the ancestors of u can only be aligned to the ancestors of v.
Such criteria prevent from aligning constituents that cross each other. This property
is very similar to that of some bi-parsing formalisms, such as synchronous context free
grammars and synchronous tree substitution grammars. Its advantage is that it enables the
use of powerful synchronous grammars in modeling the sub-tree alignment problem. As is
shown in the very next section, based on the above constraints we can take synchronous
tree substitution grammars as the basis of our proposed model.
According to Tinsley et al.s (2007) work, the alignments satisfying the above criteria
are called well-formed alignments. An alignment is ill-formed when it violates any of these
criteria. In this work we focus on the well-formed alignments. Hence the sub-tree alignment
task can be stated as: given a pair of parse trees (S, T ), we search for the most likely wellformed alignment between S and T
A = arg max P(A | S, T )

(1)

A(S,T )

where (S, T ) is the set of well-formed alignments, and P(A | S, T ) can be viewed as an
alignment model which predicts the probability for every alignment A given S and T .
In what follows, we describe our approach to sub-tree alignment for tree-to-tree translation, including the alignment model, the training and inference methods, and the effective
use of our model in tree-to-tree MT systems.

3. Unsupervised Sub-tree Alignment
In this section we present our unsupervised sub-tree alignment model. We first define
the base model of sub-tree alignment in the framework of synchronous tree substitution
grammars, and then describe the model parameterization, training and inference methods.
3.1 Base Model
The fundamental question of sub-tree alignment is how to define the correspondence between
nodes of the source-language parse tree and nodes of the target-language parse tree. Here we
address the issue using Synchronous Tree Substitution Grammars (STSGs) which have been
widely adopted to model the transformation process between source and target-language
parse trees in MT (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010). In the general
framework of STSGs (Chiang & Knight, 2006), it is assumed that a pair of source and
target parse trees can be simultaneously generated using a derivation of STSG rules (or
tree-to-tree transfer rules). For example, the grammar in Figure 1 is an STSG and the
rules in it can be used to generate a pair of sentences. More formally, an STSG is a system
hNs , Nt , Ws , Wt , i, where Ns and Nt are sets of non-terminals in the source and target
languages, Ws and Wt are sets of terminals (or words) in the source and target languages,
 is a finite set of productions. Each production is an STSG rewrite rule (denoted as r) for
a pair of source and target-language non-terminals (snt , tnt ):
hsnt , tnt i  hsr , tr , r i
739

fiXiao & Zhu

where sr is a source-language tree-fragment, whose frontier nodes are either words in Ws or
non-terminals in Ns (labeled by x); tr is the corresponding target-language tree-fragment;
and r is a set of 1-to-1 alignments that connect the frontier non-terminals of sr to the
frontier non-terminals of tr . For example, for r5 in Figure 2(a), we have
snt = IP
tnt = S
sr = IP(NN:x VP(AD:x VP(VV:x AS:x)))
tr = S(NP(DT:x NNS:x) VP(VBP(have) ADVP(RB:x VBN:x)))
r = {1-2, 2-3, 3-4, 4-1}
Note that the non-terminals on the left-hand side of the rule are actually the roots of
the corresponding tree-fragments on the right hand side. This means that the rule contains
exactly the same information no matter whether the root nodes (snt , tnt ) are explicitly
represented or not. So in the following parts of this article we use hsr , tr , r i for a simpler representation of STSG rules. Beyond this, STSG rules can be written in a more
compact form where the alignment r is encoded in the numbers assigned to the frontier
non-terminals of sr and tr . For example, in Figures 1 and 2, the subscripts on both language
sides of the STSG rules indicate the aligned pairs of frontier non-terminals.
In the STSG model, frontier non-terminals are also called substitution nodes. When
applying STSGs, we can rewrite an aligned pair of substitution nodes with the tree-fragment
pair encoded in an STSG rule. The only constraint in this operation is that the labels of
the substituted non-terminals must match the root labels of the rewrite rules. For example,
the round-head lines in Figure 1 show the substitution operations used in a derivation.
By using STSG rules, we can parse any tree pair and generate the corresponding derivations. The generation process is trivial: we start with the pair of root symbols and repeatedly rewrite pairs of non-terminal symbols using STSG rules. For example, for the tree pair
in Figure 2(b), we start with the root labels of the source and target-language parse trees
(the superscript indicates the node index in the tree)
h IP[1] , S[1] i
Then we apply rule r9 .
IP[1] S[1]

 h IP(NN[2] VP[3] ), S(NP[2] VP[3] ) i
r9

IP[1] S[1]

where  represents the operation that rewrites the aligned node pair IP[1] and
r9

S[1] with r9 (denoted as IP[1]  S[1] ). This process proceeds by repeatedly rewriting the
remaining frontier non-terminals until we get the complete source and target-language trees,
like so:
740

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

NN[2] NP[2]


r7

VP[3] VP[3]


r8

h IP(NN() VP[3] ), S(NP(DT(the) NNS(imports)) VP[3] ) i
h IP(NN() VP(AD

[4]

[5]

VP(VV

AS[6] ))),

S(NP(DT(the) NNS(imports)) VP(VBP
AD[4] RB[4]


r3

h IP(NN() VP(AD() VP(VV

[5]

S(NP(DT(the) NNS(imports)) VP(VBP
[5]

VV

[6]

ADVP(RB

[4]

VBN[5] ))) i

AS[6] ))),

[6]

ADVP(RB(drastically) VBN[5] ))) i

[5]

VBN

 h IP(NN() VP(AD() VP(VV() AS[6] ))),
r4

S(NP(DT(the) NNS(imports)) VP(VBP

[6]

ADVP(RB(drastically) VBN(fallen)))) i
AS[6] VBP[6]


r6

h IP(NN() VP(AD() VP(VV() AS()))),
S(NP(DT(the) NNS(imports)) VP(VBP(have)
ADVP(RB(drastically) VBN(fallen)))) i

In the above process, each rewrite rule indicates a node alignment. More importantly,
derivations from this model have two very nice properties: first, for each node u in the
source-language (or target-language) parse tree, there is at most one node of the targetlanguage (or source-language) parse tree which is aligned with u; second, the hierarchical
structure behind the alignment avoids links between constituents that cross each other.
Consequently, for any well-formed sub-tree alignment A, we can always find a derivation d
that encodes the alignment A. It means that the sub-tree alignment problem is essentially
the same as the problem of finding the most likely STSG derivation. Thus the sub-tree
alignment task (see Equation (1)) can be restated as finding the most likely derivation for
a given pair of parse trees.
To model the derivation probability, we follow the formulation adopted in statistical
word alignment (Brown, Pietra, Pietra, & Mercer, 1993; Vogel, Ney, & Tillmann, 1996).
The transformation from a source-language tree S to a target-language tree T is described
by the following equation.
X
P(T | S) =
P (T, d|S)
(2)
dD(S,T )

where D(S, T ) is the set of all derivations transforming S into T (say, aligning the nodes
of S to the nodes of T ), P (T, d|S) is the probability of transforming from S to T using a
derivation d  D(S, T ), and  is the parameters of the model. Here we use the notation
P () to express the dependence of the model on the parameters. In general, the optimal
value of  is learned from parsed parallel data by some training criteria. For example, in
the context of unsupervised learning, we can optimize the model parameters by maximizing
the probability of the observed data (known as maximum likelihood training).
Given a set of optimal parameters , the best sub-tree alignment for (S, T ) is determined
P (T,d|S)
by choosing a derivation for which P (d | S, T ) is greatest. Since P (d | S, T ) = P (T |S)


741

fiXiao & Zhu

and P (T | S) is a constant for given (S, T ) and , finding the best derivation d is the same
as finding a derivation so as to make P (T, d | S) as large as possible. Hence we reach the
fundamental equation of sub-tree alignment.
d = arg max P (T, d | S)

(3)

dD(S,T )

The above formulation implies three fundamental issues of sub-tree alignment, including
modeling of derivation probability (i.e., P (T, d|S)), learning of model parameters (i.e., )
and finding the best alignment given the learned model (i.e., the arg max operation). In
the following parts of this section, we describe our solutions to these issues.
3.2 Parameterization
In the simplest case, our alignment model has one parameter for each instance of derivation.
However, this model would have an unmanageable set of parameters since the number of
derivations is exponential in the length of the input sentences. Here we choose a simple
solution to this issue which decomposes the base model into a product of trainable submodels. We start with an assumption that rules are conditionally independent for the given
source-language parse tree S, then the probability P(T, d | S) can be defined as a product
of rule probabilities (for conciseness, we will drop the subscript  from now on).
Y
P(T, d | S) 
P(r | S)
(4)
rd

Nevertheless complex tree-to-tree mappings still result in an extremely large number of
rules, which causes both the computational problem and the degenerate analysis of the
data.6 To control the number of parameters at a reasonable level, we further decompose
the rule probability into simpler probability factors under independence assumptions.
First we assume that the generation of a rule r is independent of the input tree S, when
conditioned on the source-language side of the rule, that is,
P(r | S)  P(r | sr )

(5)

Note that this is a strong assumption that the generation of a synchronous grammar
rule depends only on its source-language side. It is similar to those used in statistical
modeling of machine translation (Brown et al., 1993; Koehn, Och, & Marcu, 2003; Galley
et al., 2004; Chiang, 2005) where the generation of atomic alignment/translation units are
conditioned on the associated source-language words or tree-fragments, rather than the
whole input sentence or tree. In SMT, the independence assumptions based on phrases or
translation rules are generally used to decompose the parallel corpus into manageable units
for parameter estimation. As they have been successfully used in most of modern SMT
systems, we adopt a similar assumption here to ease the parameter estimation process of
our model.
Then we further decompose P(r | sr ) with additional assumptions. Since r = hsr , tr , r i,
P(r | sr ) can be written into another form using the chain rule:
6. Here degenerate analysis refers to the case where using models that are too complex results in overfitting
and a poor generalization ability on unseen data.

742

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

P(r | sr ) = P(sr , tr , r | sr )
= P(r | sr , tr )  P(tr | sr )

(6)

Equation (6) indicates two sub-models, including a reordering model of frontier nonterminals P(r | sr , tr ), and a tree-fragment translation model P(tr | sr ).
To model P(r | sr , tr ), we view frontier non-terminal reordering as a problem of aligning
the elements between two vectors of non-terminals. Let vnt() be a function that returns
the vector of leaf non-terminals for a given tree-fragment. r defines a 1-to-1 alignment
between the non-terminals in vnt(sr ) and vnt(tr ). For example, for r5 in Figure 2(a), the
frontier non-terminal vectors of sr5 and tr5 are:
vnt(sr5 ) = (NN, AD, VV, AS)
vnt(tr5 ) = (DT, NNS, RB, VBN)
Then r5 = {1-2, 2-3, 3-4, 4-1} indicates an alignment between vnt(sr5 ) and vnt(tr5 ), say,
NN is aligned to NNS, AD is aligned to RB and so on. Here we opt for a simple model
for selecting r . It models the non-terminal reordering probability on the condition of the
frontier non-terminal vectors on both language sides, as follows7
P(r | tr , sr )  Preorder (r | vnt(sr ), vnt(tr ))

(7)

We then turn to the problem of modeling the tree-fragment translation P(tr | sr ) (i.e.,
the second sub-model defined in Equation (6)). We define that a tree-fragment  consists of
two parts: words lex() (i.e., terminals of ) and a tree structure tree() without lexicons
involved. For example, for r5 in Figure 2(a), the target-language tree-fragment contains
two elements lex(tr5 ) and tree(tr5 ):
lex(tr5 ) = have
tree(tr5 ) = S(NP(DT:x NNS:x) VP(VBP ADVP(RB:x VBN:x)))
Let root() be a function that returns the root for a given tree-fragment. We can write
P(tr | sr ) as:
P(tr | sr ) = P(lex(tr ), tree(tr ) | sr )
= P(root(tr ) | sr ) 
P(tree(tr ) | root(tr ), sr ) 
P(lex(tr ) | tree(tr ), root(tr ), sr )

(8)

It is worth noting that Equation (8) is not an approximation. Here we just choose
one of the many ways in which P(tr | sr ) can be written as the product of a series of
7. The reordering model defined here ensures that arbitrary 1-to-1 alignments can be handled. But it might
result in a very large model with sparse parameter distributions if big tree-fragments are involved. In
considering this issue, we choose several pruning methods for better control of rule size in our sub-tree
alignment system. See Section 5.2.2 for the pruning settings in this work.

743

fiXiao & Zhu

conditional probabilities. We simply assert this equation that when generating a targetlanguage tree-fragment for a source-language tree-fragment, first we can choose the root
symbol of the target-language tree-fragment given the source-language tree-fragment (in
probability of P(root(tr ) | sr )). Then we can choose the tree-structure of the target-language
tree-fragment given its root symbol and the source-language tree-fragment (in probability of
P(tree(tr ) | root(tr ), sr )). Then we can choose the target-language terminals associated with
the tree-fragment given the target-language tree-structure, target-language root symbol and
source-language tree-fragment (in probability of P(lex(tr ) | tree(tr ), root(tr ), sr )).
Another note is that Equation (8) actually does not reduce the model complexity. For
example, P(lex(tr ) | tree(tr ), root(tr ), sr ) essentially indicates all the combinations of source
and target-language tree-fragments. A simpler model is required for a feasible solution
for parameter estimation. To do this, we introduce additional assumptions to relax the
conditions of these probabilities and reduce the number of parameters to a reasonable level.
1. P(root(tr ) | sr ) depends only on root(sr ), i.e.,
P(root(tr ) | sr )  Pnt (root(tr ) | root(sr ))

(9)

This assumption implies the node correspondence between the source and targetlanguage parse trees.
2. P(tree(tr ) | root(tr ), sr ) depends only on root(tr ), i.e.,
P(tree(tr ) | root(tr ), sr )  Ptree (tree(tr ) | root(tr ))

(10)

The second assumption results in a monolingual model of generating target-language
tree-structures, where the generation of a tree-fragment is only conditioned on its
root. It can be viewed as an analogy to the generative model used in standard TSGs.
3. P(lex(tr ) | tree(tr ), root(tr ), sr ) only depends on source words lex(sr ), i.e.,
P(lex(tr ) | tree(tr ), root(tr ), sr )  Plex (lex(tr ) | lex(sr ))

(11)

This allows us to directly model the terminal correspondence between the two languages.
Then, we substitute Equations (9)-(11) into Equation (8), and get
P(tr | sr )  Pnt (root(tr ) | root(sr )) 
Ptree (tree(tr ) | root(tr )) 
Plex (lex(tr ) | lex(sr ))
By using Equations (6), (7) and (12), Equation (4) can be finally written as:
744

(12)

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

id

rule

probability

r3

AD()  RB(drastically)

Pnt (RB | AD)  Plex (drastically | )

r4

VV()  VBN(fallen)

Pnt (VBN | VV)  Plex (fallen | )

r6

AS()  VBP(have)

Pnt (VBP | AS)  Plex (have | )

r7

NN() 

Pnt (NP | NN)  Plex (the imports | )

NP(DT(the) NNS(imports))

Ptree (NP(DT NNS) | NP)

VP(AD1 VP(VV2 AS3 )) 

Pnt (VP | VP)  Ptree (VP(VBP ADVP(RB VBN)) | VP)

VP(VBP3 ADVP(RB1 VBN2 ))

Preorder (1-2, 2-3, 3-1 | (AD, VV, AS), (VBP, RB, VBN))

IP(NN1 VP2 )  S(NP1 VP2 )

Pnt (S | IP)  Ptree (S(NP VP) | S)

r8
r9

Preorder (1-1, 2-2 | (NN, VP), (NP, VP))

Table 1: Rule probabilities for the sample derivation d = {r3 , r4 , r6 , r7 , r8 , r9 } in Figure 2(b)
P(T, d | S) 

Y

Pnt (root(tr ) | root(sr )) 

rd

Ptree (tree(tr ) | root(tr )) 
Plex (lex(tr ) | lex(sr )) 
Preorder (r | vnt(sr ), vnt(tr ))

(13)

This is a simplified model for the generative story described in this section. It takes
the rule generation probability as a product of four probability factors: Pnt () is the nonterminal mapping probability, which roughly captures the syntactic correspondence of subtrees between the two languages; Ptree () is the probability of generating the tree structure
of T ; Plex () is the probability of the terminal mappings between the two language sides of
a rule; and Preorder () is the probability of the frontier non-terminal reordering encoded in
a rule. See Table 1 for rule probabilities of a sample derivation.
In our model all parameters are assumed to be multinomial distributions. The calculation of Pnt (), Ptree () and Preorder () is straightforward: they can be directly used
without any further decompositions and assumptions. To calculate Plex (), we choose the
form adopted in the popular models of word alignment (Och & Ney, 2004; Thayer, Ettelaie, Knight, Marcu, Munteanu, Och, & Tipu, 2004), where the probability is defined as a
product of word-based translation probabilities:
l
m
Y
1 X
Plex (t1 ...tl | s1 ...sm )  Plength (l | m)
Pw (ti | sj )
m
i=1

(14)

j=1

where ti is a target word, and sj is a source word. Plength () is used to control the number of
target words produced from a given number of source words. Pw () is the word translation
probability. This sub-model is in principle doing something rather similar to conventional
word-based translation tables, as in IBM Models (Brown et al., 1993).
3.3 Node Deletion and Insertion
Word (or sub-tree) deletion/insertion is common in real-world alignment and translation
tasks. To add flexibility to modeling this problem, we allow for the production of empty
745

fiXiao & Zhu

sub-trees on either source or target-language side of a rule in our model. More formally, for
a rule whose target-language side is an empty sub-tree, its probability is defined as:
P(r | S)  Pnt (root() | root(sr )) 
Ptree (tree() | root()) 
Plex (lex() | lex(sr )) 
Preorder ( | vnt(sr ), vnt())

(15)

where  is a special symbol that indicates nothing. Factors Pnt (root() | root(sr )) and
Plex (lex() | lex(sr )) model the deletion probability at different levels of a tree-fragment.
Ptree (tree() | root()) is the probability of generating an empty tree-fragment. Factor
Preorder ( | vnt(sr ), vnt()) regards  as a special reordering pattern  which aligns all
frontier non-terminals on the source side to a virtual node NULL. Obviously, the values of
Ptree (tree() | root()) and Preorder ( | vnt(sr ), vnt()) are both simply 1.
Similarly, for a rule whose source side is an empty sub-tree, its probability is defined as:
P(r | S)  Pnt (root(tr ) | root()) 
Ptree (tree(tr ) | root(tr )) 
Plex (lex(tr ) | lex()) 
Preorder ( | vnt(), vnt(tr ))

(16)

where the value of Preorder ( | vnt(), vnt(tr )) is also 1.
It is worthwhile to note that word deletion and insertion problems are very important
in MT in spite of relatively less discussion in recent studies on tree-to-tree translation.
What we are doing here is actually an analogy to the NULL-alignment used in IBM Models
(Brown et al., 1993). For word/phrase-based models, removing some words from alignment
can leave more space for correctly aligning other words in the sentence.8 This is even more
necessary for (1-to-1) sub-tree alignment because the alignment has to respect the syntactic
constraints on both language sides, e.g., sub-tree alignments are not allowed to break the
constraints imposed by neighbouring parts of the tree. In some cases, we cannot obtain a
correct 1-to-1 alignment for the tree pair due to only one or two bad nodes which are not
necessarily to be aligned with a valid node in the counterpart tree. Instead, some nodes
can be skipped in alignment and thus do not impose bad constraints to other parts of
the tree if node deletion/insertion is allowed. This is especially true when we align sentence
pairs with very flat tree structures or free translations. In this work we found that node
deletion and insertion operations were necessary to achieve satisfactory sub-tree alignment
result. We therefore used them in our implementation by default.
3.4 Training
We now turn to the training problem. As discussed in Section 3.1, we focus on unsupervised
learning of model parameters, that is, the optimal values of parameters are estimated given
8. Note that current phrase-based approaches (Koehn et al., 2003; Och & Ney, 2004) allow NULL-aligned
words to appear at the boundary of a phrase, which can be viewed as a way of implicit modeling of the
word insertion/deletion problem

746

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

a collection of tree pairs without any annotation of sub-tree level alignment. In this work we
choose two approaches for estimating parameters of the sub-tree alignment model, including
the Maximum Likelihood Estimation (MLE) approach and the Bayesian approach.
3.4.1 Maximum Likelihood Training
MLE is one of the most popular methods of parameter estimation for statistical models. Its
basic idea is that, given a model and a set of parameters, the MLE method selects the values
of parameters to generate a distribution that gives the highest probability to the observed
data. MLE is a general approach to parameter estimation which has been widely adopted in
many AI and NLP tasks, such as part-of-speech tagging. In the case of sub-tree alignment,
MLE can be simply described as finding the optimal values of parameters that lead to the
maximum probability of aligning the tree nodes from a source-language parse tree to a
target-language parse tree. More formally, given a set of tree pairs {(S1 , T1 ), ..., (Sn , Tn )},
the objective of the MLE-based training is defined to be:
 = arg max


n
Y

X

P (Ti , d | Si )

(17)

i=1 dD(Si ,Ti )

We choose here Expectation Maximization (EM, Dempster, Laird, & Rubin, 1977) as
the algorithm to solve the above optimization problem. Basically the EM algorithm is an
iterative training method for finding the maximum likelihood estimates of model parameters,
where it is assumed that the observed data depends on some latent variables. The algorithm
performs by iteratively calling two sub-routines, namely the Expectation (E)-step and the
Maximization (M)-step. In the E-step, it calculates the expected value of the likelihood
function associated with the parameters and observed data, with respect to the distribution
of latent variables given the observed data and current estimates of parameters. In the
M-step, it seeks for the parameters that maximize the expected likelihood found in the
E-step.
When applying the EM algorithm to our case, we can view the input pairs of parse
trees {(S1 , T1 ), ..., (Sn , Tn )} as observed data, the underlying derivations of rules as latent
variables, and the distributions Pnt (), Ptree (), Preorder () and Plex () (i.e., Plength () and
Pw ()) as unknown parameters. See Figure 3 for the pseudo-code of the training algorithm
for Pnt () (denoted as tnt |snt ). Because this algorithm is directly applicable to the estimation
of all parameters in our model, we skip the description of learning the remaining parameters
here. For a more detailed description of the EM-based training of all model parameters we
refer the reader to the appendix.
In the algorithm, snt and tnt represent a source-language non-terminal symbol and a
target-language non-terminal symbol, u and v represent a source-language tree node and
a target-language tree node, EC() represents the expected count of the given variable,
P(k) (T, d | S) represents the derivation probability based on the parameters obtained in
the k-th round. In each EM iteration, the E-step of the algorithm accumulates the expected
count over all pairs of parse trees. Then, the M-step finds the maximum likelihood estimate
using this quantity. The only nontrivial part in this algorithm is the computation of the
expected count in the E-step. Roughly speaking, the physical meaning of the right-hand
side of line 9 is the relative probability that a derivation contains rule r (with root node
747

fiXiao & Zhu

1: Function TrainModelWithEM ({(S1 , T1 ), ..., (Sn , Tn )})
(0)
2: Set {tnt |snt } = an initial model
3: For k = 0 to K  1 do
4:
Foreach non-terminal symbol pair (snt , tnt ) do
5:
EC(tnt |snt ) = 0
6: E-step:
6:
Foreach tree pair (S, T ) in sequence {(S1 , T1 ), ..., (Sn , Tn )} do
7:
Foreach node pair (u, v) with symbol pair (tnt , snt ) in (S, T ) do
8:
Foreach rule r rooted
P at (u, v) do
P

is rooted at (u,v) 
9:
EC(tnt |snt ) + = d: rd  r P
0
d0 P (k) (T,d |S)
8: M-step:
10:
Foreach non-terminal symbol pair (snt , tnt ) do

11:
12:

(k+1)

tnt |snt =

P

(k) (T,d|S)

EC(tnt |snt )
EC(t0 |s )

t0nt

nt

nt

(K)

return {tnt |snt }
Figure 3: The EM-based training algorithm (for Pnt ())

P
pair (u, v)). The numerator d: rd  r is rooted at (u,v) P(k) (T, d | S) is the probability sum
P
over all the derivations that involve r , while the denominator d0 P(k) (T, d0 | S) is the
overall probability of the alignment from S to T . However, the brute-force computation of
expected counts is very inefficient because it requires the sum over all possible derivations
whose number is exponential in the length of the input sentences.
In this work we use the bilingual version of the inside and outside probabilities (Manning
& Schutze, 1999) to avoid the naive enumeration of all possible derivations in computing
various probabilities. The inside probability of (u, v) (denoted as (u, v)) measures how
likely we generate the sub-tree pair inside the node pair (u, v). The outside probability
(denoted as (u, v)) is a dual of the inside probability. It measures how likely we generate
the remaining parts of the tree pair (S, T ) from the start symbols. Like the formulation
used in monolingual parsing (Manning & Schutze, 1999), (u, v) and (u, v) can be defined
using the following recursive forms:


X
Y
(u, v) =
P(r | S) 
(p, q)
(18)
r:root(r)=(u,v)

(u, v) =

X

(p,q)yield(r)



(root(r))  P(r | S) 

r:(u,v)yield(r)

Y

(p, q)



(19)

(p,q)yield(r)
 (p,q)6=(u,v)

where root(r) is the abbreviation of the node pair (root(sr ), root(tr )), and yield(r) is the
set of the aligned frontier non-terminal pairs yielded by r. Based on the above recursive
definitions, both (u, v) and (u, v) can be efficiently computed with dynamic programming.
By using the inside and outside probabilities, it is easy to address the computation
problem mentioned above. Let (u, v) denote the probability that the tree node u is aligned
with the tree node v. This probability can be expressed in an inside-outside fashion:
748

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

(u, v) =

X

P(T, d | S)

d: (u,v) is
aligned in d

= (u, v)  (u, v)

(20)

In this way, the overall alignment probability from S to T (i.e., the denominator of the
right-hand side of line 9) can be simply written as:
X

P(T, d | S) = (root(S), root(T ))  (root(S), root(T ))

(21)

d

For the numerator of the right-hand side of line 9, let us view it in another angle. In the
E-Step of the algorithm, the expected count is accumulated over rules whose root is (u, v).
As all the rules rooted at (u, v) indicate the same node alignment between u and v, lines
8-9 in principle imply the probability of all derivations aligning u to v, or more precisely
the node alignment probability of (u, v). This probability can be written in a very simple
form using the inside and outside probabilities:
X
X
P(T, d | S) = (u, v)
r: r is rooted d: rd
at (u,v)

= (u, v)  (u, v)

(22)

Together with the result in Equation (21), the E-step can be efficiently implemented by
replacing lines 8-9 with the following equation
EC(tnt |snt ) + =

(u, v)  (u, v)
(root(S), root(T ))  (root(S), root(T ))

(23)

where (snt , tnt ) is the symbol pair of (u, v). Note that for each (snt , tnt ), the E-step step
(u,v)(u,v)
increases EC(tnt |snt ) by the sum of (root(S),root(T
))(root(S),root(T )) over all node pairs (u, v)
whose symbols are snt and tnt . This means that if (snt , tnt ) is aligned at different positions
in the input tree pair, the above method considers the alignment of (snt , tnt ) for multiple
times and updates EC(tnt |snt ) accordingly.
It is also worth noting that there are several methods for initializing the model parameters before the EM-style training begins. For example, the model can be initialized by
uniform or random distributions. In this work we initialize all parameters in our sub-tree
alignment model by the model obtained using the word alignment result. This is a standard way adopted in many unsupervised models where a simpler model is used for a good
starting point in the training process. It is very helpful when the optimization procedure is
sensitive to the initial setting of model parameters (e.g., EM for non-convex objective functions). In our experiments we found that using the GIZA++ word alignment for parameter
initialization resulted in better performance and fewer iterations for convergence than the
uniform initial distributions. As the word alignment can be obtained in an unsupervised
manner, it does not change the training condition of our approach. Thus we chose this
method for initializing the model parameters in our implementation.
749

fiXiao & Zhu

3.4.2 The Bayesian Approach
While MLE is one of the standard approaches to training unsupervised models, it is well
known for its tendency to overfit the data. The overfitting problem becomes more severe
for complex models since they have more parameters and fit the training data better. In
the case of STSGs, this is likely to result in the degenerate analysis of the data, i.e., rare
and big rules dominate the ML solution of STSGs, while they are considered to be noisy
and generalize poorly on the unseen data (Cohn & Blunsom, 2009; Liu & Gildea, 2009).
A natural solution to this problem is to incorporate constraints or proper priors into the
training process. Here we take the Bayesian approach as an alternative solution for the
training problem.
Unlike MLE, the Bayesian approach does not plug a single optimum point estimate of
the parameter into the distribution of a data point, but instead account for any uncertainty
in the value of the parameter. In Bayesian models, the parameters are assumed to be
drawn from some probability distributions or priors. The parameters of these extra prior
distributions are called hyperparameters, and are denoted by . As the parameters of
our model are viewed mathematically as multinomials, we choose Dirichlet distributions
(Ferguson, 1973) for the prior over model parameters. The advantage of using Dirichlet
distributions is that they are conjugate to multinomial distributions and inference with
such priors is easier.
Following the previous description, we use  to denote the model parameters which are
multinomial with outcomes {1, ..., K} (i.e., k is the probability of outcome k  {1, ..., K}).
From this multinomial distribution we sample a set of outcomes {x1 , ..., xn } with probability
P(xi = k) = k . As the Dirichlet prior is a distribution over multinomials, each sample
from the prior is actually a set of parameter values . Therefore the distribution can be
modeled as:
xi |   Multinomial()

(24)

 |   Dirichlet()

(25)

Here Equation (24) means that xi is distributed according to a multinomial with parameters
. Similarly, Equation (25) can be read as  is distributed according to a Dirichlet distribution with parameters .  = {1 , ..., K } is the hyperparameter vector corresponding to the
outcomes. In this work we use a symmetric Dirichlet prior ( i.e., 1 , ..., K share the same
value), and use  to represent the single hyperparameter instead of the hyperparameter
vector.
Using this model, we can compute the conditional distribution of a new observation
xn+1 given previous observations {x1 , ..., xn } and the hyperparameter , as follows:
Z
P(xn+1 | x1 , ..., xn , ) = P(xn+1 | x1 , ..., xn , ) P( | ) d
(26)
The big advantage of the Bayesian approach is to introduce a prior distribution over
the unknown parameters of the model, which is meant to capture the knowledge and beliefs
about the model before seeing the data (Neal, 1998). It is especially important in our case
where we need a bias towards some preferred situations. For example, we expect that
our model can favor high frequency rules and dislike rare and big rules. This goal can be
750

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

easily achieved by using the Bayesian approach and an appropriate choice of priors, say, a
Dirichlet prior with a low concentration parameter . However, the introduction of priors
generally makes it intractable to estimate the posterior analytically. In practical systems
based on the Bayesian approach, a widely-used solution is to use approximate methods to
seek a compromise between exact inference and computational resources. In this work we
choose Variational Bayes for approximate inference. Variational Bayes is a good method
that preserves the benefits of introducing the prior but with a tractable inference procedure
(Attias, 2000; Beal, 2003). It has been successfully applied to several NLP-related models,
such as Hidden Markov Models (HMMs) and IBM Models (Beal, 2003; Riley & Gildea,
2010). One more good thing is that Variational Bayes can be seen as an extension of the
EM algorithm and resembles the usual forms used in EM. The resulting procedure looks a lot
like the EM algorithm with a modified M-step, which is very convenient for implementation.
Here we follow the approach presented in previous work (Beal, 2003; Riley & Gildea, 2010)
where variational Bayesian algorithms are applied to similar tasks. All we need is only a
very slight change to the M-step of the original EM algorithm presented in Section 3.4.1.
In the original EM algorithm (see Figure 3), the M-step normalizes the expected counts
collected in the E-step as standard MLE. The variational Bayesian version of the M-step
slightly modifies this formula and performs an inexact normalization by passing counts
through function f (x) = exp((x)).

tnt |snt =

f (EC(tnt |snt ) + )
P
f ( t0 (EC(t0nt |snt ) + ))

(27)

nt

where (x) is the digamma function (Johnson, 2007). It has an approximate effect of
subtracting 0.5 from its argument. The choice of  controls the behavior of this estimation.
When  is set to a low value, it performs estimation as a way of anti-smoothing. As
about 0.5 is subtracted from the rule counts, small counts corresponding to rare events are
penalized heavily, while large counts corresponding to frequent events are not be affected
very much. For example, low values of  make Equation (27) favor the non-terminal pairs
which are aligned frequently and distrust the non-terminal pairs which are aligned rarely.
In this way, the variational Bayesian method could control the overfitting caused by abusing
rare events. On the other hand, a larger  can be used when smoothing is required.
The above method is applicable to training all the parameters in our model. It only
requires a replacement of the M-step in Figure 3 with the variational Bayesian M-step (as
in Equation (27)). In our implementation, after the variational Bayes-based training, we
perform an additional round of normalization without variational Bayes to normalize rule
probabilities to sum to one.9
9. The additional normalization process makes the posterior probabilities directly comparable with those
obtained in other training methods, such as the EM-based training. Note that here we convert the result
of Bayesian inference into some probability distributions for a good explanation of various probability
factors in our model. On the other hand, this technical trick results in a pseudo-Bayesian procedure
that is not doing Bayesian inference exactly though it shows good results in our empirical study. One
can remove the additional round of normalization for a pure Bayesian approach. But all these changes
do not affect the overall pipeline of our approach (from a practical standpoint).

751

fiXiao & Zhu

1: Function Decode
(S, T )

2:
[], [] = GetInsideOutsideProbabilities (S, T )
3:
Foreach node u in S in bottom-up order do
4:
Foreach node v in T in bottom-up order do
5:
[u, v] = [u, v]  [u, v]
6:
Foreach tree-fragment sr rooted at u do
7:
Foreach tree-fragment tr rooted at v do
8:
Foreach frontier non-terminal alignment a between sr and ts do
9:
r = CreateRule(s
Q r , tr , a)
10:
score = P(r | S)  (p,q)yield(r) P(d[p, q])
11:
If score > P(d[u, v]) then
12:
d[u, v] = CreateDerivation(r, {d[p, q] : (p, q)  yield(r)})
13: return (d[], [])
14: Function GetInsideOutsideProbabilities (S, T )
15: Foreach node u in S in bottom-up order do
16:
Foreach node v in T in bottom-up order do
17:
Set [u, v] according to Equation (18)
18: Foreach node u in S in top-down order do
19:
Foreach node v in T in top-down order do
20:
Set [u, v] according to Equation (19)
21: return ([], [])
Figure 4: Decoding algorithm of the proposed sub-tree alignment model for both 1-best
and posterior-based outputs
3.5 Decoding
Inference with our model is straightforward. The simplest case is inferring the 1-best subtree alignment. Given a set of learned parameters, we first visit every node pair (u, v) in
a bottom-up fashion, and compute the posterior probability of aligning the sub-tree pair
rooting at (u, v). This procedure is the same as the dynamic program used in the trainer.
We then select the derivation with the maximum sub-tree alignment probability for the
input tree pair. Also, we can generate a list of k-best derivations in a similar manner.
In addition to the 1-best/k-best output, our model is able to output the alignment
posterior probability for every pair of tree nodes. To do this, we only need to record the
probability (u, v) for each node pair after we obtain the inside and outside probabilities.
Note that outputting alignment posterior probabilities is also commonly used in statistical
word and phrasal aligners. It provides a flexible way of making use of the alignment result
for the downstream components, such as the rule extraction system. As is presented in the
very next sections, tree-to-tree MT systems can make great benefits from the posteriorbased alignment output, which results in a very effective rule extraction method as well as
better translation results.
Figure 4 depicts the pseudo-code of the decoding algorithm for both 1-best and posteriorbased outputs. In this algorithm, d[x, y] is a data structure that records the best derivation rooted at (x, y). [x, y], [x, y] and [x, y] are data structures that record the inside
probabilities, output probabilities and alignment posterior probabilities, respectively. Cre752

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

ateRule() creates a rule with a pair of tree-fragments (sr , tr ) and a frontier non-terminal
alignment a, and calculates the rule probability. CreateDerivation() builds a derivation
using the input rules. For output, we can access the 1-best alignment by traversing from
d[root(S), root(T )], and access the alignment posterior through [].
Given a pair of trees (S, T ), the outer two loops of the algorithm iterates over each pair
of nodes in the two trees, resulting in time complexity of O(|S|  |T |) where |  | represents the
2 ), where N
size of the input tree. Generating all pairs of tree-fragments requires O(Ntree
tree
is the maximum number of tree-fragments given a tree node. Computing the alignment
between (sr , tr ) requires O(L!) where L is the maximum number of leaf non-terminals in a
2
rule. Therefore the time complexity of this algorithm is O(|S|  |T |  Ntree
 L!), quadratic
in the size of the input trees. Note that the actual time complexity of this algorithm could
be very high if all potential alignments are considered. For example, Ntree is generally an
exponential function of the depth of the input tree-fragment, and a very deep tree could
results in an extremely large space of alignments. To make practical sub-tree alignment
systems, pruning techniques are taken into account in this work. For example, in our
implementation, we restrict the depth of tree-fragment to a reasonable number (see Section
5.2.2). In addition, as is commonly-used in phrasal alignment and related tasks, we consider
word alignments in pruning and discard the sub-tree alignments which violate a certain
number of word alignments. For example, we throw away the sub-tree alignments if there
are more than two word alignment links outside the spans covered by the aligned sub-trees.

4. Applying Sub-tree Alignment to Tree-to-Tree Translation
Once sub-tree alignment is obtained, current tree-to-tree systems can directly learn translation rules from node-aligned tree pairs. In this section we investigate methods of applying
sub-tree alignment to tree-to-tree rule extraction.
4.1 Rule Extraction Using 1-best/k-best Sub-tree Alignments
To data, several methods have been developed for tree-to-tree rule extraction (Zhang et al.,
2008; Liu et al., 2009a; Chiang, 2010). The most popular of these is the GHKM-like
method which extends the idea of extracting syntactic translation rules from string-tree pairs
(Galley et al., 2004). In GHKM-like extraction, we first compute the set of the minimallysized translation rules that can explain the mappings between the source-language tree
and the target-language tree while respecting the alignment and reordering between the
two languages. Larger rules are then learned by composing two or more minimal rules. For
example, in Figure 2(b), r7 and r9 are two minimal rules extracted according to the sub-tree
alignment. We can compose these rules to form a larger rule, like this:
IP(NN() VP1 )  S(NP(DT(the) NNS(imports)) VP1 )
In this work we use the tree-to-tree version of GHKM-like extraction which is described
in Liu et al.s (2009a) work. See Figure 5(a) for the pseudo-code of rule extraction with
1-best sub-tree alignment. We choose this method because it has been widely used in
most tree-to-tree systems. Note that rule extraction in tree-to-tree translation is generally
not restricted to be performed on the 1-best sub-tree alignment result. The GHKM-like
753

fiXiao & Zhu

1: Function OneBestExtract (S, T , A)
2:
Foreach node u in S do
3:
Foreach node v in T do
4:
Foreach tree-fragment pair (sr , tr )
4:
rooted at (u, v) do
5:
a = OneToOneAlign(sr , tr , A)
6:
If a is not empty then
7:
r = CreateRule(sr , tr , a)
8:
rules.Add(r)
9:
return rules
10: Function OneToOneAlign(sr , tr , A)
11: If frontier non-terminals of (sr , tr ) have
11:
1-to-1 alignments in A then
12:
return frontier alignment of (sr , tr )
13: Else
14:
return 

1: Function MatrixExtract (S, T , M )
2:
Foreach node u in S do
3:
Foreach node v in T do
4:
If IsExtractable({(u, v)}, M ) do
5:
next loop
6:
Foreach tree-fragment pair (sr , tr )
6:
rooted at (u, v) do
7:
Foreach frontier alignment a
7:
between (sr , tr ) do
8:
If IsExtractable(a, M ) then
9:
r = CreateRule(sr , tr , a)
10:
rules.Add(r)
11: return rules
12: Function IsExtractable(a, M )
13: Foreach alignment (p, q) in a do
14:
If probability of (p, q) in M < Pmin then
15:
return false
16: return true

(a) 1-best Extraction

(b) Matrix-based Extraction

Figure 5: The 1-best and matrix-based rule extraction algorithms
extraction method can be employed when a list of k-best sub-tree alignments is provided.
In k-best extraction we only need to repeat the procedure of 1-best extraction for each
sub-tree alignment in the k-best list.
4.2 Rule Extraction Using Sub-tree Alignment Matrices
Previous work has pointed out that current MT systems suffer from error propagation due
to the alignment errors made within 1-best alignment (Venugopal, Zollmann, Smith, &
Stephan, 2008). As sub-tree alignment is an early-stage step in the training pipeline, the
errors in 1-best alignment are likely to be propagated to translation rule extraction and
parameter estimation of the translation model. Though this problem can be alleviated by
using k-best alignments, the limited scope of k-best alignments still results in inefficient
learning of translation rules. For example, our preliminary experiment shows that 95.8% of
the extracted rules are redundant when 100-best alignments are involved.
Here we instead present a simple but efficient method, namely matrix-based rule extraction. In this method, we use the posterior-based output of our aligner and represent the
sub-tree alignment with a compact structure - call it sub-tree alignment matrix or alignment
matrix for short (Liu, Xia, Xiao, & Liu, 2009b; de Gispert, Pino, & Byrne, 2010).
See Figure 6(a) for two example sub-tree alignment matrices made from a pair of sentence segments. In the matrices, each entry is indexed by a pair of source and target nodes.
The score in an entry is the posterior probability of the alignment between the corresponding node pair, i.e., the (u, v) probability defined in Equation (20). This probability is
straightforwardly accessible in the output of the inference algorithm described in Section
3.5. In principle (u, v) can be viewed a measure of sub-tree alignment confidence: a higher
value indicates a more confident alignment between the two nodes. In this way we can
754

fihave

RB

[4]

VBN

drastically



1

fallen





VV[4]

AS[5]

AD[2]

.1

AS[5]

4]

5]

VP[1]

.1

AD[2]

.8

.1

.1

.6

.1

.2

VP[3]

.3

.7

VV[4]

.4

AS[5]

1 VV[4]
1

VB
N[

1]

VB
P [2]
AD
VP [
3]
RB [

.9

AD[2]
VP[3]

VP[3]
VP[1]

VP[1]

1

[5]

VP [

ADVP[3]

VB

VBP[2]

VP [

1]

VP[1]

P [2]
AD
VP [
3]
RB [
4]
VB
N [5]

Unsupervised Sub-tree Alignment for Tree-to-Tree Translation

.6

 = fixed alignment

 = possible alignment

Matrix 1: 1-best alignment

Matrix 2: posterior

(a) Sub-tree alignment matrices for a sample sub-tree pair
Minimal Rules
Extracted from Matrix 2 (posterior)
r3
AD()  RB(drastically)
r4
VV()  VBN(fallen)
r6
AS()  VBP(have)
r8
VP(AD1 VP(VV2 AS3 )) 
VP(VBP3 ADVP(RB1 VBN2 ))
r10 VP(VV() AS())  VBN(fallen)
r11 VP(AD1 VP2 )  VP(VBP1 ADVP2 )

Minimal Rules
Extracted from Matrix 1 (1-best)
r3 AD()  RB(drastically)
r4 VV()  VBN(fallen)
r6 AS()  VBP(have)
r8 VP(AD1 VP(VV2 AS3 )) 
VP(VBP3 ADVP(RB1 VBN2 ))

...
(b) Rules extracted using 1-best alignment and alignment posterior
Figure 6: Matrix-based representation of sub-tree alignment and sample rules extracted.
Matrix 1 shows the case of 1-best sub-tree alignment, and Matrix 2 shows the
case of sub-tree alignment posterior.
access all possible sub-tree alignments (with different probabilities), rather than a limited
number of them.
We then extract rules using the sub-tree alignment matrix. The method is simple: we
collect the rules associated with each entry from the matrix. The core algorithm of this
method is in essential the same as that used in 1-best/k-best extraction. The only difference
from 1-best/k-best extraction is that the matrix-based method considers all possible node
pairs for extraction, rather than visiting some of them only. See Figure 5(b) for the pseudocode of the sub-tree alignment matrix-based rule extraction algorithm, where M represents
a sub-tree alignment matrix for the pair of trees (S, T ). Compared to extracting rules from
k-best alignments, this method can efficiently obtain additional rules whose extraction is
blocked in k-best extraction. For example, on the right side of Figure 6(b) two new rules
r10 and r11 are extracted, which cannot be obtained from the 1-best alignment result. To
prevent the extraction of a great number of noisy rules with low alignment probabilities, we
755

fiXiao & Zhu

prune away those rules whose alignment probabilities are below a pre-specified threshold.
More formally, given a pair of nodes (u, v), rule extraction can be executed at (u, v) only
when it satisfies:
(u, v)
< Pmin
(28)
(root(S), root(T ))
This expression measures the relative probability of alignment (u, v) with respect to the
sum of probabilities over all possible derivations. Pmin is an empirical threshold to control
how often rules to be pruned (a larger Pmin means more rules are thrown away). In this
work, it is set to 107 by default. Therefore, all those entries with a zero score in Figure
6(a) (denoted as a dot) are excluded in rule extraction.
However, discarding rules with relatively low probabilities in turn results in an incompleteness problem, that is, the extracted rules might be unable to transform a given source
parse-tree, even in the training set. Nonetheless, this problem is not very severe in our
case. In our experiments we observed that most parse-tree pairs (over 90%) in the training
corpus could be recovered by the extracted rules when Pmin chose its default value, and
the contribution to translation accuracy from those low confidence rules was very limited
(generally less than 0.1 BLEU points).
Another note on sub-tree alignment matrix-based extraction. The advantage of this
method is that it follows the general and well-developed framework of syntax-based MT,
i.e., word/syntactic alignment + rule extraction/parameter estimation + MT decoding. All
we need is to replace the rule extraction component with our sub-tree alignment matrixbased system, while preserve other components of the pipeline. This means that we can still
use some heuristics to obtain additional useful rules from the result of sub-tree alignment
matrix-based extraction, such as rule composing (Galley et al., 2006) and SPMT extraction
(Marcu, Wang, Echihabi, & Knight, 2006). Also, the posterior probability encoded in the
matrix can be used for better estimation of various MT-oriented features.10
Note that the basis of our approach is the STSG model, and all rules in the sub-tree
alignment model resemble the general forms of the translation rules used in tree-to-tree MT
systems. So, as an alternative but simple way of rule induction, we can directly infer translation rules from our sub-tree alignment model and take the corresponding rule probabilities
as features of the translation model for MT decoding. However, in tree-to-tree MT this
method suffers from several problems. First, our sub-tree alignment model requires computation of all possible aligned tree-fragments, which results in very high time complexity
for both training and decoding procedures. As a result, aggressive pruning has to be used
for a reasonable size of search space, e.g., we consider only relatively small tree-fragments
in our implementation for acceptable running speed. As a side effect, many relatively large
rules (e.g., composed rules and SPMT rules) are absent in our sub-tree alignment model,
while they are available if we use the traditional alignment + extraction heuristics pipeline.
From an engineering standpoint, it is not efficient to directly infer translation rules from
the sub-tree alignment model, compared to inferring rules using a pruned and fixed subtree alignment matrix plus some heuristics. Second, the rule probability and optimization
objective for sub-tree alignment is very different from those used in MT systems. For example, we use a generative model and a maximum-likelihood/Bayesian approach in sub-tree
10. See Section 4.3 for more detailed discussion of the parameter estimation issue.

756

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

alignment, but use a discriminative model and minimum error rate training in MT. Many
features employed in the MT decoder are not considered in our sub-tree alignment model.
All the above issues might lead to unsatisfactory MT performance. As shown in our experiments (see Section 5.3.5), directly inferring translation rules from the sub-tree alignment
model does not achieve promising results.
4.3 Learning Features for Machine Translation
In previous work on syntax-based MT, it is proved that syntax-based systems can make great
benefits from MT-oriented features, even some of them are not necessarily well explained
in the syntactic parsing viewpoint (e.g., phrase-based translation probabilities). However,
most of these features are not available in the word/sub-tree alignment model. Instead we
need to learn these features using an additional step of parameter estimation for MT. To
do this, we follow the commonly-used framework which estimates values of various MToriented features on the extracted rule set using MLE. This procedure is simple: once all
translation rules are extracted, we obtain the maximum-likelihood (or relative-frequency)
estimate of parameters according to the definition of each feature function.
However, in traditional tree-to-tree systems each rule extracted from a tree pair has
a count of unit one, which is then used to calculate the values of various features. Such
a approach might enlarge the influence of noisy rules extracted from sub-tree alignment
matrices. E.g., a rule with a high alignment probability has an equal weight as a rule with
a low alignment probability, and thus has a unreasonably large impact on MT systems. A
more desired solution is that a rule extracted from a derivation having a low probability is
penalized accordingly in feature learning. Motivated by this idea, we use fractional counts
to estimate the appearance for each rule (Mi & Huang, 2008). Given a node pair (u, v) in
(S, T ), the alignment probability of a rule r rooted at (u, v) is defined to be (denoted as
(r; u, v)):
X
(r; u, v) =
P(T, d | S)
(29)
dD(S,T )
 rd

where (r; u, v) is regarded as the probability sum over all derivations involving r at (u, v).
Also, we can rewrite Equation (29) in an inside-outside fashion:
Y
(r; u, v) = (u, v) 
(p, q)  P(r | S)
(30)
(p,q)yield(r)

Then we define the probability that r is involved in the derivations of (S, T ) as:
X
(r) =
(r; u, v)

(31)

u,v

Equation (31) is the sum of probabilities of r over all node pairs. This means that the
rule probability can be considered for multiple times if some particular derivations contain
r more than once. By using (r), the fractional count of r is defined to be:
c(r) =

(r)
(root(S), root(T ))

757

(32)

fiXiao & Zhu

Equation (32) reflects the probability how likely r is involved in a derivation given a
pair of trees. For a set of bilingual parse trees, c(r) can be accumulated over each tree pair.
Obviously, c(r) can be used to estimate the parameters of the MT model, that is, once
translation rules are weighted, the parameter estimation procedure can proceed as usual,
but with weight counts. In this work c(r) is employed to learn five features used in the
MT decoder, including the bi-directional phrase-based conditional translation probabilities
(Marcu et al., 2006) and three syntax-based conditional probabilities (Mi & Huang, 2008).
Let () be a function that returns the sequence of frontier nodes for an input tree-fragment.
These probabilities can be computed by the following equations:
P
00
r00 :(sr00 )=(sr )(tr00 )=(tr ) c(r )
P
Pphrase (tr | sr ) =
(33)
0
r0 :(sr0 )=(sr ) c(r )
P
00
r00 :(sr00 )=(sr )(tr00 )=(tr ) c(r )
P
Pphrase (sr | tr ) =
(34)
0
r0 :(t 0 )=(tr ) c(r )
r

c(r)

P(r | root(r)) =

P

P(r | sr ) =

P

r0 :root(r0 )=root(r) c(r

c(r)
r0 :sr0 =sr

P(r | tr ) =

c(r0 )

c(r)
P

r0 :tr0 =tr

c(r0 )

0)

(35)
(36)
(37)

5. Experiments
For evaluation, we first experimented with our approach on a Chinese-English sub-tree
alignment task, then tested its effectiveness in a state-of-the-art tree-to-tree MT system.
5.1 Baselines
Three unsupervised sub-tree alignment methods were chosen as baselines in our experiments.
 WordAlign-1 : WordAlign-1 is based on a GHKM-like method (Galley et al., 2004)
that uses word alignments to infer syntactic correspondences. In our implementation,
both the GIZA++ toolkit and the grow-diag-final-and method were used to obtain
the symmetric word alignment from sentence pairs. The sub-tree alignments were
then heuristically induced by selecting those node correspondences that are consistent
with the word alignment result (i.e., sub-tree alignments that do not violate any word
alignments). We chose this method because it has been widely adopted in modern
tree-to-tree systems.
 WordAlign-2 : the second baseline is essentially the same as WordAlign-1. The only
difference from WordAlign-1 is that we improved the word alignment system using
link-deletion techniques (Fossum et al., 2008). The basic idea is to delete harmful
alignment links from an initial word alignment result (e.g., deleting the link between
 and the in Figure 2(a)). In our experiments we only considered the most likely
deletion between the top-10 most common Chinese words (including {, , , ,
758

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

, , , , , }) and the top-10 most common English words (including {the,
of, and, to, in, a, is, that, for, on}).
 HeuristicAlgin: HeuristicAlgin is a re-implementation of the approach proposed in
Tinsley et al.s (2007) work. In this method the alignment confidence of every node
pair is first computed with lexical translation probabilities, and then used to obtain
node correspondences via a heuristic algorithm. Because this method does not require
a training process and has been successfully adopted in several translation tasks, such
as French-English translation, it was chosen as another baseline for comparison.
5.2 Experimental Setup
The settings of our experiments are described as follows.
5.2.1 Data Preparation
Our bilingual corpus consists of 1.06 million sentence pairs.11 As mentioned above, we
used GIZA++ and the grow-diag-final-and heuristics to generate 1-best/k-best word
alignments, which were then used as our baseline word alignment results. The parse trees in
both Chinese and English were generated using the Berkeley Parser.12 A publicly available
corpus was used to evaluate the sub-tree alignment result.13 It consists of 736 node-aligned
sentence pairs (with gold-standard parse trees on both language sides) in LDC2003E07
which is also included in our bilingual data. This corpus was divided into two parts: a
held-out set used for finding an appropriate setting of hyperparameters (99 sentences in
articles 301-309), and a test set used for evaluating the sub-tree alignment systems (637
sentences in articles 001-066). For MT experiments, a 5-gram language model was trained
on the Xinhua portion of the Gigaword corpus in addition to the English part of the LDC
bilingual training data.14 We used the NIST 2003 MT evaluation corpus as our development
set (919 sentences) and the newswire portion of the NIST 2004-2006 MT evaluation corpora
as our test set (3,486 sentences).
5.2.2 Sub-tree Alignment
All parameters of the sub-tree alignment model were initialized with the add-one smoothing
on the rule-set extracted using word alignments (i.e., the WordAlign-1 baseline). Then, the
model was trained on the parse trees of the bilingual corpus using the EM algorithm or
the Variational Bayes (VB) approach. In our implementation of the VB-based training, all
hyperparameters are assumed to share the same value.15 This leads to a setting of  = 0.01
11. LDC category: LDC2003E14, LDC2005T10, LDC2003E07, LDC2005T06, LDC2005E83, LDC2006E26,
LDC2006E34, LDC2006E85, LDC2006E92 and LDC2004T08. See http://www.ldc.upenn.edu/ for more
details.
12. Note that for the LDC2003E07 corpus we reused the gold-standard parse trees provided in the Chinese
and English treebanks.
13. Available from http://www.nlplab.com/resources/nodealigned-bitreebank.html
14. LDC category of the English Gigaword corpus: LDC2003T05
15. Although we could adopt different hyperparameters for finer control over the priors of model parameters, we found that setting those hyperparameters to the same value could also lead to satisfactory
performance.

759

fiXiao & Zhu

which is an optimal value on the held-out set. By default, we trained our model for 5 EM or
Variational EM iterations. To speed-up the training process and further avoid degenerate
analysis caused by too large rules, we restricted ourselves to rules with reasonable sizes rules with at most five frontier non-terminals and depth of three. For rules having more
than five frontier non-terminals, we only considered the tree-fragments of depth one but did
not restrict the number of frontier non-terminals involved, that is, for flat tree structures,
we only used the associated height-one tree-fragments. Besides, we discarded the sub-tree
alignment between every node pair whose terminals are aligned outside the corresponding
spans for more than two times in WordAlign-1.
5.2.3 Machine Translation
We used the NiuTrans open-source toolkit (Xiao, Zhu, Zhang, & Li, 2012) to build our
tree-to-tree MT system. For rule extraction, we used an extension of the GHKM method
to extract minimal tree-to-tree transformation rules (Liu et al., 2009a) and obtained larger
rules by composing two or three minimal rules (Galley et al., 2006). We used a CKY-style
decoder with cube pruning (Huang & Chiang, 2005) and beam search to decode Chinese
sentences. By default the beam size was set to 50. In addition to the features described in
Equations (33)-(37), we also used several other features in our MT system, including the
5-gram language model, the rule number bonus, the target length bonus and two binary
features - lexicalized rule and low frequency rule (Marcu et al., 2006). These features are
combined in a log-linear fashion and optimized using Minimum Error Rate Training (MERT,
Och, 2003).
5.3 Results
In the following part of this section, we present our experimental results, including evaluations of sub-tree alignments, extracted rules, and MT systems. Also, we show results of
several improved methods for the effective use of our approach in tree-to-tree MT.
5.3.1 Evaluation of Alignments
First we evaluated the alignment quality of various sub-tree alignment approaches in terms
of precision (P), recall (R) and F-1 score.16 See Table 2 for results of the three baseline
systems and our sub-tree alignment system. By those measures, our VB-based system
significantly improves both the overall recall and F-1 score, slightly degrading in precision
compared to WordAlign-1/2. Also, the VB-based training outperforms the EM-based counterpart due to the priors introduced into the learning process. The interesting observation
here is that, though the EM training of our model suffers from the degenerate analysis of the
data, it does not show extremely bad results in our experiment. This phenomenon is due
to our restriction on the size of tree-fragment in training. As described in Section 5.2.2, we
restricted the translation rules to those reasonable-size tree-fragments in several ways (e.g.,
16. Let predicted be the number of alignments in system output, correct be the number of correct alignments
in system output, gold be the number of alignments in gold-standard. The measure of precision, recall
2
)precisionrecall
correct
and F- score can be defined as: precision = predicted
, recall = correct
and F- = (1+
.
gold
 2 precision+recall
Here  is a parameter that controls the preference for recall (i.e.,  > 1) or precision (i.e., 0   < 1).
In most NLP tasks  is set to 1, indicating equal weights of recall and precision.

760

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

Entry
Overall
NP  NP
NN  NN
VP  VP
PU  ,
IP  S
PU  .
NP  NN
NP  PP
NN  NNS
NR  NNP
NN  NP
PP  PP
NN  JJ
P  IN
QP  NP

WordAlign-1
P
R
F-1
75.4 63.6 69.0
86.9 59.0 70.3
83.9 75.6 79.5
75.3 61.9 68.0
84.7 76.5 80.4
92.5 87.5 89.9
98.5 98.7 98.6
77.6 71.5 74.4
46.8 63.8 54.0
84.2 76.0 79.9
69.4 41.2 51.8
65.1 59.8 62.4
84.6 68.4 75.7
90.7 76.5 83.0
81.5 69.8 75.2
72.2 64.9 68.3

WordAlign-2
P
R
F-1
76.3 64.5 69.9
87.0 62.1 72.5
83.6 77.0 80.2
74.9 61.9 67.8
84.7 76.5 80.4
92.3 87.7 89.9
98.5 98.7 98.6
83.0 71.5 76.8
49.7 63.5 55.7
83.8 76.5 80.0
69.9 41.7 52.3
65.9 61.0 63.3
85.1 69.2 76.3
90.4 76.3 82.7
82.3 68.3 74.7
72.6 65.2 68.7

HeuristicAlgin
P
R
F-1
65.7 67.7 66.7
79.1 73.6 76.3
76.2 74.1 75.1
71.3 71.8 71.6
69.6 71.3 70.3
90.6 90.7 90.6
98.5 98.7 98.6
59.3 77.5 67.2
53.1 31.9 39.8
77.8 75.5 76.7
63.4 57.4 60.2
71.8 50.4 59.2
79.3 72.6 75.8
83.9 81.7 82.8
81.2 72.2 76.4
67.1 65.6 66.4

Ours (EM)
P
R
F-1
79.8 46.2 58.5
84.2 48.2 61.3
81.8 63.7 71.6
80.5 49.0 60.9
82.7 67.7 74.5
90.4 76.8 83.0
94.7 86.8 90.6
75.4 62.3 68.2
43.2 42.1 42.6
83.7 58.3 68.7
57.7 41.5 48.3
70.5 48.1 57.2
85.6 56.9 68.4
84.2 69.1 75.9
79.9 57.9 67.1
78.3 42.2 54.8

Ours (VB)
P
R
F-1
72.6 75.1 73.8
88.7 75.3 81.4
81.1 79.9 80.5
75.7 75.8 75.7
82.5 80.7 81.6
90.0 92.4 91.2
98.5 98.5 98.6
75.9 78.9 77.4
54.5 70.1 61.3
81.0 77.6 79.2
67.2 56.3 61.3
71.1 67.7 69.4
85.4 82.5 83.9
85.9 81.2 83.5
84.7 76.1 80.2
74.9 71.7 73.3

Table 2: Evaluation results of sub-tree alignment for our system and the baselines. All
measures are reported in percentage.
we set a parameter of maximum depth). While such constraints reduce the number of rules
involved in training, it prevents the use of rare and large rules. Our result here indicates
the fact that the tree-fragment size constraint is actually not only important for efficiency
but also crucial for learning. As discussed in previous work, without these constraints or
imposing a proper prior, the solution of EM is degenerate (Marcu & Wong, 2002; DeNero,
Gillick, Zhang, & Klein, 2006).
In addition, Table 2 shows the result for the 15 most common types of sub-tree alignment. As expected, the VB-based system achieves the best F-1 score in most cases. More
interestingly, it is observed that our approach obtains significantly better performance in
handling the PP (Prepositional Phrase) alignment that seems to be a difficult problem for
baselines due to the unclear boundary indicators in aligning the PP structures. We attribute
this to the better use of syntactic information on both language sides in our model, which
are generally ignored in traditional models based on surface heuristics and word alignments.
5.3.2 Evaluation of Extracted Rules
We then applied the sub-tree alignment result to our tree-to-tree system to study the impact
of sub-tree alignment on MT. As discussed in Section 4, rule extraction is a downstream
component of sub-tree alignment in the current tree-to-tree MT pipeline. We therefore
chose to evaluate the quality of the rules obtained from various sub-tree alignment results.
To determine the goodness of extracted grammars, we computed the rule precision, recall,
and F-1 scores for our approach and the baseline approaches on the same test set used in
the (1-best) alignment quality evaluation. To make a gold-standard grammar, we chose
the method used in Fossum et al.s (2008) work where the grammar was automatically
generated from the manually-annotated alignment result, that is, the rules extracted using
the annotated sub-tree alignments were regarded as the gold-standard in computing various
evaluation scores. Table 3 shows the evaluation result for the grammars extracted with
761

fimatrix

1best

Xiao & Zhu

Entry
WordAlign-1
WordAlign-2
HeuristicAlgin
Ours (EM)
Ours (VB)
Ours (VB + Pmin
Ours (VB + Pmin
Ours (VB + Pmin
Ours (VB + Pmin

= 105 )
= 106 )
= 107 )
= 108 )

Rule P
51.9
52.3
55.8
61.9
54.9
79.6
53.0
41.3
34.9

Rule R
60.8
61.8
55.3
49.2
65.2
34.5
70.0
75.6
79.5

Rule F-1
55.9
56.6
55.5
54.8
59.6
48.2
60.3
53.4
48.5

Table 3: Evaluation results of rules obtained from various sub-tree alignment approaches.
All measures are reported in percentage.
different sub-tree alignment approaches. We see that the improvements persist when our
sub-tree alignments are employed in translation rule extraction. Our VB-based approach
produces grammars with a higher rule F-1 score than all three of the baselines.
In addition to the 1-best extraction, we studied how rule extraction behaves under the
sub-tree alignment matrix-based extraction method. Table 3 also shows the result of the
sub-tree matrix-based extraction method with different choices of the pruning parameter
Pmin . We see that smaller values of Pmin result in grammars with higher rule recall. Also,
better rule F-1 scores can be achieved by adjusting Pmin and seeking a good balance between
rule precision and rule recall , e.g., Pmin = 106 or 107 .
The above scores are informative as a measure of grammar quality, but we also investigated some of the differences in the rule sets obtained from our model compared to the
baseline approaches, following Levenberg, Dyer, and Blunsoms (2012) method. Figure 7
shows the most probable rules (frequency  2) obtained from our bilingual corpus using
the VB-based alignment approach that do not appear in the model from the WordAlign-2
alignment and vice versa. We asked two annotators of sub-tree alignment to estimate the
rule quality based on the syntactic correspondence and adequacy of frontier node sequence
between the two languages sides. A rule was labeled as good only if both judges considered it to be of good quality. From the figure, we see that eight of the top-10 rules extracted
using our approach but absent in the WordAlign-2 grammar are good rules. In contrast,
only four of the top-10 rules in the baseline model are of good quality in a sense of human
preference. Furthermore, we examined the top-100 most probable rules that appear in the
two grammars individually. Again, the top-100 rules extracted using our proposed model
are of better quality. It results in 61 good rules. By contrast, only 44% of the top-ranking
rules induced using the WordAlign-2 alignment are good translation rules.
5.3.3 Evaluation of Translations
We also evaluated the translations generated by the MT system for different sub-tree alignment approaches. Since the VB-based training shows the best performance in the previous
experiments, we chose it as a default setting of our approach in the following experiments.
Table 4 shows the evaluation result where the translation quality is estimated using caseinsensitive IBM-version BLEU4 (Papineni, Roukos, Ward, & Zhu, 2002) and TER (Snover,
762

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

The
1*
2*
3*
4
5*
6*
7*
8*
9*
10

top-10 highest probability rules (for MT) in our approach but absent in WordAlign-2
NP(DNP1 NN())  VP(ADVP1 VP(VBD(improved)))
NP(PU( ) NP(CD() NN()) PU())  NP(DT(the) CD(two) NNS(sessions))
NP(NP(QP1 NP(NN())) NP2 )  NP(X2 NP(CD1 NP(NNS(represents))))
NP(NN() NP1 )  VP(VB(desire) NNP1 )
NP(PU() NP(NR1 NN()) PU())  NP(() NP(NNP1 NN(independence)) ())
NP(VP1 DEC() NP(NN() NN()))
 NP(ADJP(ADJP1 JJ(ideological)) NN(struggle))
NP(NP(QP1 NP2 ) NP(ADJP(JJ()) NP(NN())))
 NP(NP(DT(the) JJ(important) NN(thinking)) IN(of) SBAR(WHNP1 S2 ))
NP(IP1 DEG() NP(NN() NN()))  NP(ADJP(ADJP1 JJ(practical))
NN(significance))
NP(NP(PU() NP(QP1 NN()) PU()) NP(ADJP2 NN()))
 NP(NP(DT(the) JJ2 NN(idea)) PP(IN(of) NP(DT(the) CD1 NNS(represents))))
NP(PU() NN() PU1 )  VP(VBG(joining) NP(DT(the) NN1 ))

The top-10 highest probability rules (for MT) in WordAlign-2 but absent in our approach
1
LCP(QP1 LC())  ADJP(JJ1 )
2*
NP(DNP1 NN())  VP(ADVP1 VBP(changes))
3*
NP(NN() NN1 )  NP(CD(three) NNS(links) X1 )
4
NP(DNP(IP1 DEC()) NP(NN()))  NP(ADJP1 NN(significance))
5
VP(ADVP1 VP(VV2 NP(NN() NN3 )))
 VP(ADVP1 VP(VP(VV2 ) NP(DT(the) JJ(mass) NN3 )))
6
IP(NP1 VP(VV() NP(NN() NN2 )))  NP(NP(NNS1 ) PP(IN(for) NP2 ))
7
NP(VP1 DEG() NN())  ADJP(JJ1 )
8
NP(NP(PU() NT1 PU()) NP(NN()) NR())
 NP(NP(PRP$(his)) QP(CD1 ) NN(speech))
9*
VP(VP(ADVP1 VP(VV() CC() VV())) NP2 )
 VP(ADVP1 VP(VP(VB(strengthen) CC(and) VB(improve)) NP2 ))
10* NP(NP(PU() NN() PU()) NP1 )
 NP(NP(() NP(NN(taiwan) NN(independence)) ()) NNS1 )

Figure 7: The top-10 highest probability rules built from the proposed sub-tree alignment
approach that are not in the WordAlign-2 baseline grammar, and the top-10 rules
in the WordAlign-2 baseline grammar that are not obtained using the proposed
sub-tree alignment approach. * = a good translation rule.
Dorr, Schwartz, Makhoul, Micciula, & Weischedel, 2005), and the significance test is performed using the bootstrap resampling method (Koehn, 2004). Moreover, the efficiency of
rule extraction is reported in terms of rule-set-size/extraction-time. For comparison, we
also report the result of rule extraction using word alignment matrices (Liu et al., 2009b)
on WordAlign-1 and WordAlign-2.
Table 4 indicates that our approach outperforms the baselines by the BLEU and TER
measures for both 1-best and 30-best extraction. In addition, the matrix-based method is
much more efficient than the k-best method. For example, compared with 30-best extraction, extracting rules from sub-tree alignment matrices is 9 times more efficient. However,
when all rules are counted as unit one in parameter estimation of the translation model,
using alignment matrices does not show significant BLEU improvements or TER reductions in comparison with the 30-best counterpart (see rows marked with unitcount). This
is because many of those additionally extracted rules are not utilized in real translation.
For example, we observed that only 7.3% of the rules used in generating the final (1-best)
763

fiXiao & Zhu

Entry
WordAlign-1 (1-best)
WordAlign-2 (1-best)
HeuristicAlgin (1-best)
WordAlign-1 (30-best)
WordAlign-2 (30-best)
HeuristicAlgin (30-best)
WordAlign-1 (matrix)
WordAlign-2 (matrix)
Ours (1-best + unitcount)
Ours (30-best + unitcount)
Ours (matrix + unitcount)
Ours (1-best + posterior)
Ours (30-best + posterior)
Ours (matrix + posterior)

Dev

Test

BLEU4[%] TER[%]

BLEU4[%] TER[%]

36.2
36.2
35.7
36.3
36.4
35.4
36.9*
36.8*
36.7*
36.8*
36.9*
36.9*
37.0*
37.4**

34.2
34.2
33.8
34.4
34.6*
33.9
35.0*
35.1*
34.9*
35.0*
35.3**
35.0*
35.2**
35.6**

57.0
56.9
57.2
57.2
57.0
57.2
56.5
56.6
56.6
56.6
56.3*
56.4*
56.2**
55.9**

58.3
58.1
58.3
58.2
58.0
58.0
57.9*
57.7*
57.8
57.6*
57.5*
57.4*
57.0**
57.1**

Rule-set
size
24.8M
25.3M
22.7M
32.7M
33.0M
32.4M
50.2M
53.8M
27.0M
37.4M
54.9M
27.0M
37.4M
54.9M

Efficiency
(rule/sec)

75.4
75.9
72.0
3.8
3.9
3.8
35.8
37.9
78.8
4.1
37.7
78.8
4.1
37.7

Table 4: Evaluation of translations for different alignment approaches. For BLEU, higher
is better. For TER, lower is better. unitcount means that we take each rule
occurrence as unit one in parameter estimation, and posterior means that we use
rule posterior probabilities as fractional counts in parameter estimation. * or **
= significantly better than all three of the 1-best baselines (p < 0.05 or 0.01).
translations were indeed extracted from the alignments that were not seen in the 30-best
alignments. It thus indicates the fact that naively increasing the number of rules might not
be effective for improving the translation quality.
The last three rows in Table 4 show the result of using alignment posterior probabilities
in parameter estimation (i.e., the method described in Section 4.3). We see that alignment
posterior probabilities are very helpful in improving translation quality because the system
can weight more on those rules with more confidence (entries with unitcount vs. entries
with posterior ). By using sub-tree alignment matrices in rule extraction and alignment
posterior probabilities in parameter estimation, our approach finally achieves a +1.0 BLEU
improvement and a -0.9 TER reduction over the 30-best case of the baselines. It even
outperforms the word alignment matrix-based counterpart by +0.5 BLEU points and -0.6
TER points (both are significant at p < 0.05).
Further, the effectiveness of the proposed approach is demonstrated in terms of BLEU
and TER scores under the same rule-set size. Figure 8 compares our approach and the
baseline approaches in different numbers of unique rules extracted.17 Clearly, in the same
number of unique rules, the proposed sub-tree alignment approach leads to better translations than those of the baselines.
5.3.4 The Impact of Alignment and Grammar Quality on MT Performance
The above experiments demonstrate the effectiveness of the proposed approach in terms
of different measures individually. The next natural question is how sub-tree alignment
17. To do this, we adjusted Pmin to obtain grammars with different sizes for our approach. For other
approaches, we used different k-best lists for rule extraction.

764

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

43

1 - TER[%]

BLEU4[%]

36

35

34

HeuristicAlgin
WordAlign-2
WordAlign-1
Ours

42

HeuristicAlgin
WordAlign-2
WordAlign-1
Ours
41

33
10

20

30

40

50

60

70

10

20

30

40

50

60

70

Rule-set size (million)

Rule-set size (million)

Figure 8: BLEU and 1-TER against rule-set size
and rule extraction affect the translation quality. The study of this issue is very important
when we optimize the upstream systems of MT decoding and select appropriate evaluation
metrics for a good prediction of MT performance.
We therefore carried out another set of experiments which compares the translation
quality in different sub-tree alignment and rule extraction settings. To generate diverse
sub-tree alignment and rule extraction results, we varied the values of  and Pmin for
sub-tree alignment and rule extraction respectively. In this way, we obtained ensembles of
sub-tree alignments and grammars with different precision and recall scores.18 We chose
F- score as the evaluation metric for both the sub-tree alignment system and the rule
extraction system. Instead of fixing  to be 1, we varied the  value from 0.5 to 3. Since
the parameter  can control the bias towards precision or recall, choosing different values for
 is very helpful in seeking a good tradeoff between precision and recall. Then we can find
an appropriate evaluation measure of sub-tree alignment and rule extraction for predicting
MT performance well.
Figures 9 and 10 plot the F- scores as measures of MT performance for sub-tree alignment and rule extraction. From Figure 10, we see that the rule F-3 score correlates best
with the translation quality measures, which indicates that the MT system prefers rule
recall-biased metrics. This agrees with our observation in Figure 8 that the MT system
can make benefits from more rules. On the other hand, the curves in Figure 9 show a
better correlation between sub-tree alignment F-2/F-3 score and translation quality measures, implying a preference for relatively higher sub-tree alignment recall. This result is
reasonable because in our framework more node alignment links can result in more aligned
tree-fragments (or rules) extracted. A high-recall sub-tree alignment generally results in a
big grammar with high rule recall, and thus better BLEU and TER results. We also com18. For example, a larger value of  generally results in higher alignment precision, while a small value
prefers higher alignment recall. For rule extraction, a larger value of Pmin generally leads to a grammar
with higher rule precision, while choosing a smaller Pmin can generate a grammar with higher rule recall.

765

fiXiao & Zhu

80

sub-tree alignment F-[%]

sub-tree alignment F-[%]

80

70

60

F-0.50
F-0.75
F-1.00
F-2.00
F-3.00

50

40
33.5

34

34.5

35

35.5

70

60

F-0.50
F-0.75
F-1.00
F-2.00
F-3.00

50

40

36

41

BLEU4[%]

42

43

1 - TER[%]

70

70

60

60

rule F-[%]

rule F-[%]

Figure 9: BLEU and 1-TER against sub-tree alignment F- measure

50
40

F-0.50
F-0.75
F-1.00
F-2.00
F-3.00

30
20
34

34.5

35

50
40

F-0.50
F-0.75
F-1.00
F-2.00
F-3.00

30
20

35.5

41.5

BLEU4[%]

42

42.5

43

1 - TER[%]

Figure 10: BLEU and 1-TER against rule F- measure

puted the Pearsons correlation coefficients between sub-tree alignment/rule F-3 score and
BLEU/TER. For sub-tree alignment F-3, its correlation coefficients with BLEU and TER
are 0.971 and -0.962 respectively. For rule F-3, its correlation coefficients with BLEU and
TER are 0.983 and -0.963 respectively. Both of them show good correlations with the translation quality measures. Another interesting observation here is that the MT performance
is more sensitive to the change of rule F- score than to the change of sub-tree alignment
F- score. This may lie in that rule extraction is a direct upstream step of decoding and
impacts more on the output of MT systems. In contrast, sub-tree alignment is a front-end
step of the MT pipeline and has an indirect effect on the actual translation process.
766

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

System
Hierarchical phrase-based
Tree 1-best word alignment (WordAlign-2)
to
Word alignment matrix
tree Sub-tree alignment matrix

Dev

Test

BLEU4[%] TER[%]

BLEU4[%] TER[%]

37.2
36.8
37.0
37.9*

35.2
35.3
35.2
36.0**

57.3
56.4*
56.3*
55.8**

58.0
57.7
57.5*
56.8**

Table 5: MT Evaluation results of rules obtained from various alignment approaches. For
BLEU, higher is better. For TER, lower is better. * or ** = significantly better
than the hierarchical phrase-based baseline (p < 0.05 or 0.01).
5.3.5 Further Improvements
Previous work has pointed out that the straightforward implementation of tree-to-tree MT
suffers from the problems of too few rules and too few derivations in either rule extraction or
decoding process (Chiang, 2010). To further advance the tree-to-tree system and compare
it with the state-of-the-art, we employed tree binarization (Wang et al., 2007b) and fuzzy
decoding (Chiang, 2010) in our system. As our alignment approach can be equipped with
the general framework of tree-to-tree translation, it is trivial to conduct another set of
experiments to investigate the effectiveness of our approach in a stronger system.19 Table
5 shows the BLEU and TER scores of our system enhanced with the above methods.20 For
comparison, we also report the result of a state-of-the-art MT system that implements the
hierarchical phrase-based model (Chiang, 2007) and our tree-to-tree system that extracts
rules using the word alignment matrices (Liu et al., 2009b). Table 5 indicates the superiority
of our approach when tree binarization and fuzzy decoding are involved. It significantly
outperforms the hierarchical phrase-based system (+0.7 BLEU points and -1.2 TER points)
and the tree-to-tree system based on the word alignment matrices (+0.8 BLEU points and
-0.7 TER points).
As discussed in Section 4, the transfer rules in our sub-tree alignment model resembles
the general form of STSGs which can be directly used in MT. Instead of resorting to an
explicit step of rule extraction, we can use the rules in the sub-tree alignment model for
MT decoding, i.e., sub-tree alignment is cast as a grammar induction step. We therefore
built another system which directly acquires translation rules from the sub-tree alignment
step. To do this, we only need to output all the rules from the derivation forest generated
by our alignment model. All rule probabilities can be obtained using the inside and output
probabilities, and pruning is performed by throwing away rules whose probability is below
Pmin . In addition to rule probability, we reused the n-gram language model, the rule number
bonus, the target length bonus, the lexicalized rule and low frequency rule indicators in our
base tree-to-tree system as additional features for a fair comparison. To obtain a good and
reasonable result, we employed both fuzzy decoding and tree binarizaiton in the experiment.
19. We did not choose this setting in the previous experiments because our gold-standard alignment annotation was on the Penn Treebank-style trees only. It was difficult to evaluate the alignment and grammar
quality on binarized trees due to the lack of benchmark data. In our experiments we first conducted the
experiments on each individual tasks (see Sections 5.3.1-5.3.3), and studied their correlations in a simple
but reasonable setting for a consistent result of sub-tree alignment and MT (see Section 5.3.4). Then we
investigated the effectiveness of our approach on an advanced tree-to-tree system (see Section 5.3.5).
20. In our implementation all parse trees were binarized in a head-out fashion.

767

fiXiao & Zhu

Entry
Baseline (explicit rule extraction)
Rules from the sub-tree alignment model
Rules from the sub-tree alignment model + MERT
Baseline + sub-tree alignment features

Dev

Test

BLEU4[%] TER[%]

BLEU4[%] TER[%]

37.9
36.2
36.7
38.2

36.0
34.3
34.9
36.1

55.8
57.9
57.3
55.8

56.8
58.8
58.0
56.9

Table 6: MT Evaluation results of obtaining rules from the sub-tree alignment model and
obtaining rules with the traditional rule extraction pipeline
Table 6 compares the results of sub-tree alignment matrix-based rule extraction and inducing rules from the alignment model (Row 1 vs. Row 2). Unfortunately, straightforwardly
inferring rules and their probabilities from the sub-tree alignment model underperforms the
baseline. This might be attributed to several reasons. First, due to the large derivation
space, we cannot enumerate all relatively large tree-fragments in the sub-tree alignment
step, instead we only access the tree-fragments with limited depths. By contrast, our baseline system extracts basic rules using sub-tree alignment matrices and then obtains more
large rules with some heuristics (e.g., rule composing). The additional rules obtained in
our baseline framework of rule extraction are in general very useful to modern syntax-based
systems (Galley et al., 2006; Marcu et al., 2006; DeNeefe et al., 2007). Second, the rule
probability in our sub-tree alignment model is defined as a product of probability factors
for a good generation story. However, MT systems usually use features which are not required to form a generative model, such as the features shown in Equations (33)-(37). In
consequence, many well-developed features can be used by the baseline system but they
are not available in our sub-tree alignment model. Third, our sub-tree alignment model
is trained by maximizing the likelihood or other criteria, which is not consistent with that
adopted by the MT system (i.e., minimizing an evaluation-related error rate function). To
further study these issues, we improved the system in two ways. First, we treated all four
of the probability factors in the sub-tree alignment model (See Equation (13)) as different
features in the MT decoder, and tuned their weights using MERT. Row 3 in Table 6 shows
that this method achieves better results than the system employing unweighted probability
factors. However, its performance is still worse than that of the baseline, which indicates
that the MT-oriented features and rule extraction heuristics are crucial to the success of
our tree-to-tree system. Finally we added the probabilistic factors of our sub-tree alignment
model to the baseline system as additional features. As shown in the last row of Table 6,
the enhanced system yields modest BLEU improvements over the baseline, but no TER
improvement is achieved. All the above results give us two interesting messages - 1) rule
extraction heuristics, MT-oriented features and objectives of learning are key factors contributing to a good tree-to-tree system; 2) and it is better to use our sub-tree alignment
model as an upstream module of rule extraction and decoding, rather than using it as a
simple step for grammar induction.
The last issue we investigate here is whether our sub-tree alignment model can make
benefits from labeled data. Although we focus on unsupervised learning in this work,
the proposed model does not require a strictly unsupervised condition. Instead it can be
enhanced with the use of labeled data. The idea is simple: we combine the probability
factors of our sub-tree alignment model in a log-linear weighted fashion. It means that
768

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

Entry
Unweighted
Weighted (weights are learned on labeled data)

Dev

Test

BLEU4[%] TER[%]

BLEU4[%] TER[%]

37.9
38.3

36.0
36.1

55.8
55.6

56.8
56.9

Table 7: Comparison of the unweighted and weighted sub-tree alignment models
all probability factors of our sub-tree alignment model are taken as real valued feature
functions, and their feature weights can be learned on labeled data by supervised methods.
In this way, our unweighted generative model (i.e., each factor has a weight of one) is
transformed into a weighted model (i.e., each factor has an individual weight). Note that
this weighted model has almost the same form as those used in SMT systems. The only
difference from the SMT model is that no language model is needed because the targetlanguage side is fixed in the sub-tree alignment step. To avoid bias towards too few or
too many rules, we also added the rule number as an additional feature to our new model.
For training and test, we divided our node-aligned gold-standard data into two parts - the
first 310 sentences were selected for weight training, and the remaining 327 sentences were
selected for testing the system. To learn feature weights in a supervised manner, we chose
MERT which is one of the most powerful tools for training log-linear models. The error
function used in MERT is defined by one minus sub-tree alignment F-1 score.
On the 327-sentence test data (with the tree annotation of the Penn Treebanks), the
weighted model achieves an alignment F-1 score of 75.4% and a rule F-1 score of 60.0%,
respectively. This result is better than that of the unweighed (and unsupervised) model
which obtains an alignment F-1 score of 72.4% and a rule F-1 score of 59.2% on the same
data set. Finally we tested the MT performance in our best setting (i.e., sub-tree alignment
matrix-based rule extraction + tree binarization + fuzzy decoding).21 Table 7 shows that
the weighted sub-tree alignment model leads to a better BLEU score on the tuning set but
does not show promising improvements on the test data. As the size of our labeled corpus
is small, we expect better results if more labeled data is available. Also it is worth studying
more sophisticated supervised methods to learn better weights, such as the kernel-based
methods (Sun et al., 2010b). As supervised/semi-supervised learning is not the focus of
this work, we leave these interesting issues to future investigations.

6. Related Work
Syntax-based approaches have been widely adopted in machine translation over the last
ten years. Many successful syntactic MT systems have been developed and shown good
results on several translation tasks (Eisner, 2003; Galley et al., 2004, 2006; Liu et al.,
2006; Huang et al., 2006; Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010). Despite
differences in modeling and implementation details, all these models require an alignment
step to acquire the syntactic correspondence between the source and target languages. As
is standard in SMT, most syntax-based MT systems use word alignments to infer syntactic
alignments from string-tree/tree-tree pairs. However, word alignments are generally not of
good quality from the viewpoint of syntactic alignment. It makes more sense to directly
21. As we did not have sub-tree-aligned data for binarized trees, we reused the weights learned on the Penn
Treebank-style trees for all four of the probability factors in our sub-tree alignment model.

769

fiXiao & Zhu

induce sub-tree level alignments from pairs of sentences with the syntactic information on
either language side or both. This is especially true for tree-to-tree MT where what we
actually need is the alignment between sub-trees in two languages, rather than the surface
alignment of words. There are several lines of work that address the syntactic alignment
problem and make better use of various alignment results for tree-to-tree translation.
6.1 Word and Sub-tree Alignment for Machine Translation
The earliest efforts in syntactic alignment focus on enhancing word alignment models with
syntactic information. To date, several research groups (Fraser & Marcu, 2007; DeNero
& Klein, 2007; May & Knight, 2007; Fossum et al., 2008; Haghighi, Blitzer, DeNero, &
Klein, 2009; Burkett, Blitzer, & Klein, 2010; Riesa, Irvine, & Marcu, 2011) have proposed
syntax-augmented models to advance their word alignment systems. Although these models
achieved promising improvements, they still address the alignment problem in word level.
As discussed in Section 1, such methods might not be desirable choices for learning the
correspondence between tree nodes in two languages. As an alternative and more straightforward solution, researchers tried to infer sub-tree level alignments for pairs of syntactic
trees. For example, Imamura (2001), Groves, Hearne, and Way (2004), and Tinsley et al.
(2007) defined several scoring functions to measure the similarity between the source and
target sub-trees, and aligned the tree nodes with greedy algorithms. Their approaches,
though simple to implement, are not derived in a principled way. For example, all these
models do not have an explicit optimization procedure, as in a general framework of statistical learning. Instead, the model parameters are obtained using additional alignment
models or lexicons. In another line of research, Sun et al. (2010a, 2010b) attempted to address the sub-tree alignment problem with supervised/semi-supervised models. They used
tree kernels and various syntactic features to advance their sub-tree alignment system and
showed promising results on Chinese-English translation tasks. However, this approach still
relies on heuristic algorithms for inferring node correspondences between two parse trees.
Beyond this, to train the tree kernels, their approach requires additional labeled data which
is generally very expensive to build. Unlike these studies, we derive our sub-tree model in a
principled way and develop an unsupervised sub-tree alignment framework for tree-to-tree
MT.
6.2 Unsupervised Syntactic Alignment
There are also previous studies that do not resort to labeled data for sub-tree alignment.
The earliest of these was Eisners (2003) work. He designed an unsupervised approach
to modeling the sub-tree alignment problem in the STSG formalism. However, since no
detailed derivation and model decomposition is provided, this model is computationally
expensive, even difficult to be applied to current tree-to-tree systems where complex tree
structures are involved. Gildea (2003) also applied STSGs to tree-to-tree/tree-to-string
alignment. He developed a loosely tree-based alignment method to address the issue of
parse-tree isomorphism in bitext. But his work only targets the word alignment rather
than modern syntactic MT systems. Recently Nakazawa and Kurohashi (2011) proposed
a Bayesian approach for sub-tree alignment between dependency trees, and tested it in a
Japanese-English MT system. Actually their model has much in common with the model
770

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

presented in this work. For example, they both apply unsupervised learning methods and
Bayesian models to sub-tree alignment. On the other hand, the two studies differ in some
important aspects. First, Nakazawa and Kurohashi (2011) restricted themselves to sub-tree
alignment between dependency trees, which is very different from aligning tree nodes in
phrase structure trees. Since phrase structure trees involve more complex structures and
syntactic categories, the alignment problem in phrase structure trees are relatively more
difficult than the dependency-based counterpart. Second, our model makes benefits from
the recent advances in STSGs and is directly applicable to current state-of-the-art tree-totree systems.
Another related work to what is presented here is Pauls, Klein, Chiang, and Knights
(2010) work. They factored a node-to-string alignment model over components that each
generates a target side of a synchronous rule from a source side. Moreover, the probability of
a rule fragment was factored into a lexical and structural component in their work. Actually,
their model and our proposed model are two variants on a theme. But there appear to
be obvious differences between them. First, our focus is sub-tree alignment for tree-to-tree
translation, while Pauls et al. (2010) addressed the alignment issue for tree-to-string/stringto-tree translation. In our model, we parse both language sides independently, rather than
parsing only one side and projecting syntactic categories. As a result, inference is faster
in this work since we do not need to consider all possible parse trees of the unparsed side
during alignment. Second, the permutation model presented in this work is more general
in order to handle non-ITG trees. Third, we investigate methods for the effective use of
sub-tree alignment in MT. In particular, we present a rule extraction approach to obtaining
additional translation rules using sub-tree alignment posteriors, rather than learning rules
only from the 1-best sub-tree alignment.
6.3 Rule Extraction Using Various Alignment Results
In machine translation, word and syntactic alignments are used to extract translation rules
or phrases. In the traditional pipeline of rule and phrase extraction, only the 1-best alignment result is considered, which suffers from the limited scope of the single alignment. To
efficiently obtain diverse alignment/parsing results, packed data structures were adopted to
improve 1-best pipeline MT systems in recent years (Mi & Huang, 2008; Liu et al., 2009a;
Zhang, Zhang, Li, Aw, & Tan, 2009). For example, Liu et al. (2009b) and de Gispert et al.
(2010) used alignment posterior probabilities for phrase or hierarchical phrase extraction.
The development of sub-tree alignment matrices is actually motivated by a similar idea
from word alignment matrices. The difference from the above work is that we use sub-tree
on both language sides to infer alignment posterior probabilities, while these probabilities
are calculated in word/phrase-level in previous work (Liu et al., 2009b; de Gispert et al.,
2010). Moreover, to our knowledge, the effectiveness of sub-tree alignment matrix has not
been systematically studied in the case of tree-to-tree translation.
Note that the approach presented in this work is also doing something similar to synchronous grammar induction. For example, our model results in an STSG which has the
same formalism as that used in MT. Recent studies on Bayesian models (Blunsom, Cohn,
Dyer, & Osborne, 2009; Cohn & Blunsom, 2009; Levenberg et al., 2012) have shown very
promising results in directly learning synchronous grammars from bilingual data for hierar771

fiXiao & Zhu

chical phrase-based and string-to-tree systems, rather than extracting synchronous grammar
rules based on an explicit word/syntactic alignment step. However it is rare to see related
work on tree-to-tree MT. In principle this article is different from previous work on synchronous grammar induction. For example, the aim of this work is to learn a sub-tree
alignment model, which can be applied to many potential applications except MT, such as
sentence compression for paraphrasing and test summarization (Jing, 2000; Cohn & Lapata,
2009). Unlike synchronous grammar induction where the alignment is implicitly encoded
in the learning process, we treat sub-tree alignment as a separate task. This eases the
development and tuning of the alignment system because we actually do not resort to MT
systems which are slow and difficult to optimize. Another advantage is that our approach
can make benefits from more compact models, rather than those used in MT where a great
number of rules are involved. Take our implementation as instance. The alignment model
is learned on a relatively small set of grammar rules (rules with limited depths), while the
MT system accesses a much larger grammar where many additional rules are involved by
rule composing. Such a method can result in an efficient alignment system and is likely to
alleviate the degenerate analysis of the data, with no cost of degrading in MT performance.

7. Discussion
The underlying assumption of our proposed model is that 1-to-1 sub-tree alignments can
be achieved based on the constraints imposed by neighboring parts of the tree (see Section
2). This makes sense in the standpoint of linguistically-motivated models, yet it in turn
faces a problem that the constraints make it difficult to align some sentences/trees correctly,
particularly if they are free translations. There are several reasons that can explain why
our approach works nice with tree-to-tree MT and why it does not suffer greatly from
the structure divergence between languages. First, our model is flexible and allows for
node deletion/insertion in alignment. It means that in some levels of the tree it is not
necessary to require that every node is aligned to a valid node in the other language side,
instead nodes can be dropped as needed. The advantage of such a method is that if
we cannot confidently align a node to any node in the counterpart tree, we can align it
to a virtual node and do not enforce bad constraints to aligning other parts of the tree.
This is very useful when there are very flat tree structures or partial translations which
are not syntactically well-formed. Second, the main purpose of our approach is to infer
sub-tree alignment probabilities which can be used in pruning sub-tree alignment matrices
and extracting rules for MT systems. Though 1-to-1 alignment is required for training the
sub-tree alignment model, what we actually do is to access a large number of alignment
alternatives for rule extraction, even if some of them cannot appear in the same derivation
due to our alignment constraints. Third, our model can work with any phrase structure
trees. Instead of the Penn Treebank-style trees which are difficult for alignment in some
cases, our sub-tree alignment system works well with binarized trees and shows promising
improvements over various baselines. Note that tree binarization is a very effective method
to alleviate the structure divergence problem, especially for Chinese-English translation.
Also, it might be interesting to investigate other methods for dealing with differences in
syntactic structures between languages, such as the forest-based methods (Mi & Huang,
2008; Liu et al., 2009a).
772

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

Another note on our approach. If implemented naively, the speed of the sub-tree alignment system will be very slow since our model needs the calculation of the alignment probability over all pairs of tree-fragments. Fortunately, with the thought of computation, several
optimizations can make the system much more efficient in practice. First, as is described in
this work, pruning methods can be employed to restrict the number of tree-fragments to a
reasonable level. In our experiments, the system with pruning achieved a speed of 1.82.2
sentence/second on a single core of the Intel Xeon 3.16-GHz CPU. Another way for speed
improvement is parallel processing. A very good property of the EM-style algorithms is
that the E-step can be easily implemented in parallel computation environment. What we
need is to divide the training data set into a number of smaller parts, and then run the
inside-outside algorithm on these parts in parallel (i.e., a Map procedure). The expected
counts of model parameters can be accumulated over the results of all the parts (i.e., a
Reduce procedure). Then the M-step can be performed as usual. In our implementation
we used 40 threads for parallel training. The running time of one training iteration over
our 1-million-sentence corpus was about 14-17 hours. Note that further system speed-up
can be expected if more powerful distributed infrastructures are available (e.g., clusters +
Hadoop), and it is not difficult to scale up our approach to handle millions of sentence pairs
using the current training framework.

8. Conclusions
We have proposed an unsupervised probabilistic sub-tree alignment approach for tree-totree translation. By factoring the alignment model over several components, the resulting
model can be easily learned using the EM algorithm and the variational Bayesian approach.
Also, we have investigated different ways of applying the proposed model to tree-to-tree
translation. In particular, we developed a sub-tree alignment matrix which encodes an
exponentially large number of alignments. From this representation of sub-tree alignment,
desirable rules can be extracted more efficiently than using the k-best sub-tree alignment
result. Our experiments showed that the proposed model achieved significant improvements
in both alignment quality and grammar quality over several baselines. On the NIST ChineseEnglish evaluation corpora, it achieved a +1.0 BLEU improvement and a -0.9 TER reduction
on top of a state-of-the-art tree-to-tree system. The improved MT system even significantly
outperformed a state-of-the-art hierarchical phrase-based system when equipped with tree
binarization and fuzzy decoding.

Acknowledgments
This work was supported in part by the National Science Foundation of China (Grants
61073140 and 61272376), the Natural Science Foundation for the Youth of China (Grant
61300097), the China Postdoctoral Science Foundation (Grant 2013M530131), the Specialized Research Fund for the Doctoral Program of Higher Education (Grant 20100042110031),
and the Fundamental Research Funds for the Central Universities (Grant N100204002). The
authors would like to thank the anonymous reviewers for their pertinent and insightful comments, Keh-Yih Su for his great help in improving the early version of this article, Ji Ma for
773

fiXiao & Zhu

helpful discussions, and Chunliang Zhang and Tongran Liu for language refinement. The
corresponding author of this article is Jingbo Zhu.

Appendix A. Part-of-speech Tags and Phrase Structure Labels
In this work the annotation of POS tagging and phrase structure parsing follows the standard defined in the Penn English and Chinese Treebanks (Marcus et al., 1993; Xue et al.,
2005). See Tables 8-11 for lists of POS tags and constituent labels used in the example
trees in this article.
POS Tag
AD
AS
NN
NR
P
PN
PU
VV

Description
Adverb
Aspect Particle
Noun (except proper nouns and temporal nouns)
Proper Noun
Preposition
Pronoun
Punctuation
Verb (except stative verbs, copulas, and the main
verbs of ,  and )

Table 8: Chinese POS tags used in the examples
POS Tag
DT
IN
JJ
NNP
NNS
PRP
RB
VBD
VBN
VBP
,
.

Description
Determiner
Preposition
Adjective
Proper noun (singular)
Noun (plural)
Personal Pronoun
Adverb
Verb (past tense)
Verb (past participle)
Verb (non-3rd person singular present)
Comma
Period

Table 9: English POS tags used in the examples
Syntactic Label
IP
NP
PP
QP
VP

Description
Single Clause
Noun Phrase
Preposition Phrase
Quantity Phrase
Verb Phrase

Table 10: Chinese constituent labels used in the examples

774

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

Syntactic Label
ADVP
NP
PP
S
VP

Description
Adverb Phrase
Noun Phrase
Preposition Phrase
Sentence
Verb Phrase

Table 11: English constituent labels used in the examples
Distribution
Pnt ()
Ptree ()
Preorder ()

Notation
tnt |snt
ttree |tnt
tvnt |svnt

Plength ()
Pw ()

l|m
tw |sw

Description
snt and tnt are source and target-language non-terminal symbols
ttree is a target-language tree-fragment
svnt and tvnt are vectors of non-terminal symbols in source
and target-languages
m and l are numbers of source and target terminals (or words)
sw and tw are source and target terminals (or words)

Table 12: Notations of model parameters

Appendix B. EM-based Training for the Sub-tree Alignment Model
As described in Section 3, the proposed sub-tree alignment model has five types of parameters, including the non-terminal mapping probability Pnt (), the target-language treefragment generation probability Ptree (), the frontier non-terminal reordering probability
Preorder (), the word number probability Plength () and the word mapping probability Pw ().
For convenience we use a new set of notations to denote these model parameters in the following description. See Table 12 for a symbol list.
Here we follow the same framework of the EM-based training as that described in Figure
3. See Figure 11 for a complete version of the EM algorithm for all parameters of the model.
In this algorithm, EC() represents the expected count of the input variable. (X = x) is
a 0-1 function that returns 1 if variable X takes a value of x, 0 otherwise.  (k) (r; u, v)
and  (k) (S, T ) are the rule probability (see Equation (29)) and the probability of the subtree alignment between S and T (see Equation (20)), where k indicates that all these
probabilities are calculated based on the parameters in the k-th iteration. tree(), vnt()
and lex() are the functions that return the tree-structure, frontier non-terminal vector, and
terminal sequence of the input tree-fragment, respectively (see Section 3.2).
The basic idea of the E-step is that we check each rule r (given a pair of tree nodes u
(r;u,v)
and v) and update EC() by its relative probability (root(S),root(T
)) . This can be applied
to the update rules for the parameters tnt |snt , ttree |tnt , tvnt |svnt and l|m (see lines 8-11).
The only exception is tw |sw . As defined in Equation (14), Pw (ti | sj ) is not a direct
product factor,Pinstead we use the sum over all terminals of the source-language treefragment (i.e., m
j=1 Pw (ti | sj )). Here we follow the result of IBM Model 1 and make the
P|lex(s )|
update magnitude proportional to Pw (ti | sj )/ j 0 =1 r Pw (ti | sj 0 ). We refer the reader
to Brown et al.s (1993) work for detailed derivation of the expected count in IBM Model
1. It is also worth noting that the above algorithm performs parameter update based on
different choices of (u, v) and r in the E-step. This means that if a rule instance is involved
in a particular derivation for more than one time (e.g., the same tree-fragment appears at
775

fiXiao & Zhu

1: Function TrainModelWithEM ({(S1 , T1 ), ..., (Sn , Tn )})
(0)
(0)
(0)
(0)
(0)
2: Initialize {tnt |snt , ttree |tnt , tvnt |svnt , l|m , tw |sw }
3: For k = 0 to K  1 do
4:
Set EC() = 0 for all model parameters
6: E-step:
5:
Foreach tree pair (S, T ) in sequence {(S1 , T1 ), ..., (Sn , Tn )} do
6:
Foreach node pair (u, v) in (S, T ) do
7:
Foreach rule r rooted at (u, v) do
 (k) (r;u,v)(snt =u)(tnt =v)
 (k) (root(S),root(T ))

8:

EC(tnt |snt )

+=

9:

EC(ttree |tnt ) + =

 (k) (r;u,v)(tnt =v)(ttree =tree(tr ))
 (k) (root(S),root(T ))

10:

EC(tvnt |svnt ) + =

 (k) (r;u,v)(svnt =vnt(sr ))(tvnt =vnt(tr ))
 (k) (root(S),root(T ))

11:

EC(l|m )

 (k) (r;u,v)(m=|lex(sr )|)(l=|lex(tr )|)
 (k) (root(S),root(T ))

12:

Foreach word pair (sj , ti ) in position (j, i) of (lex(sr ), lex( tr )) do

+=

(k)
P
(ti |sj )
(sw =sj )(tw =ti )
r P(k) (t |s )
w
i j0
j 0 =1

 (k) (r;u,v) P|lex(sw)|

13:

EC(tw |sw ) + =

 (k) (root(S),root(T ))

10: M-step:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:

Foreach non-terminal symbol pair (snt , tnt ) do
(k+1)

tnt |snt

=

EC(tnt |snt )
P

t0nt



EC t0

nt |snt

Foreach target non-terminal symbol tnt and tree-fragment structure ttree do
EC(ttree |tnt )

(k+1)

ttree |tnt =

P

t0tree



EC t0

tree |tnt

Foreach pair of non-terminal symbol vectors (svnt , tvnt ) do
EC(tvnt |svnt )

(k+1)

tvnt |svnt =

P

t0vnt



EC t0

vnt |svnt

Foreach pair of word numbers (m, l) do
(k+1)

l|m

=

EC(l|m )
P

l0

EC l0 |m



Foreach pair of words (sw , tw ) do
(k+1)

tw |sw

(K)

=

EC(tw |sw )
P

t0w

(K)

EC t0



w |sw

(K)

(K)

(K)

return {tnt |snt , ttree |tnt , tvnt |svnt , l|m , tw |sw }
Figure 11: The EM-based training algorithm for all model parameters

different positions), the update of the corresponding parameters would be carried out for
multiple times.
Another note on the EM algorithm. The expected counts of all the parameters can be
efficiently calculated using the inside and outside probabilities according to lines 8-11 and
776

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

13. But for some parameters there are more efficient ways. For example, as is discussed in
Section 3.4.1, the expected count of tnt |snt can be obtained without checking each individual
rule, that is, we can omit the loop for r in this case. This technique can be considered for
further speed-up of the sub-tree alignment system.

References
Attias, H. (2000). A variational bayesian framework for graphical models. In Solla, S. A.,
Leen, T. K., & K., M. (Eds.), Advances in Neural Information Processing Systems 12,
pp. 209215. MIT Press.
Beal, M. J. (2003). Variational algorithms for approximate bayesian inference. Masters
thesis, University College London.
Blunsom, P., Cohn, T., Dyer, C., & Osborne, M. (2009). A gibbs sampler for phrasal
synchronous grammar induction. In Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th International Joint Conference on Natural
Language Processing of the AFNLP (ACL-IJCNLP), pp. 782790, Suntec, Singapore.
Brown, P. E., Pietra, S. A. D., Pietra, V. J. D., & Mercer, R. L. (1993). The mathematics
of statistical machine translation: Parameter estimation. Computational Linguistics,
19, 263311.
Burkett, D., Blitzer, J., & Klein, D. (2010). Joint parsing and alignment with weakly synchronized grammars. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics
(HLT:NAACL), pp. 127135, Los Angeles, California, USA.
Chiang, D. (2005). A hierarchical phrase-based model for statistical machine translation.
In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pp. 263270, Ann Arbor, Michigan, USA.
Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33,
4560.
Chiang, D. (2010). Learning to translate with source and target syntax. In Proceedings
of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),
pp. 14431452, Uppsala, Sweden.
Chiang, D., & Knight, K. (2006). An introduction to synchronous grammars. In Tutorials of
the 21st International Conference on Computational Linguistics and the 44th Annual
Meeting of the Association for Computational Linguistics (COLING-ACL).
Chiswell, I., & Hodges, W. (2007). Mathematical Logic. Oxford University Press.
Cohn, T., & Blunsom, P. (2009). A Bayesian model of syntax-directed tree to string grammar induction. In Proceedings of the 2009 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pp. 352361, Singapore.
Cohn, T., & Lapata, M. (2009). Sentence compression as tree transduction. Journal of
Artificial Intelligence Research, 34, 637674.
Das, D., & Smith, N. A. (2009). Paraphrase identification as probabilistic quasi-synchronous
recognition. In Proceedings of the Joint Conference of the 47th Annual Meeting of the
777

fiXiao & Zhu

ACL and the 4th International Joint Conference on Natural Language Processing of
the AFNLP (ACL-IJCNLP), pp. 468476, Suntec, Singapore.
de Gispert, A., Pino, J., & Byrne, W. (2010). Hierarchical phrase-based translation grammars extracted from alignment posterior probabilities. In Proceedings of the 2010
Conference on Empirical Methods in Natural Language Processing (EMNLP), pp.
545554, Cambridge, MA, USA.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood from incomplete data via
the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological),
39, 138.
DeNeefe, S., Knight, K., Wang, W., & Marcu, D. (2007). What can syntax-based MT
learn from phrase-based MT?. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pp. 755763, Prague, Czech Republic.
DeNero, J., Gillick, D., Zhang, J., & Klein, D. (2006). Why generative phrase models underperform surface heuristics. In Proceedings on the Workshop on Statistical Machine
Translation (WMT), pp. 3138, New York city, USA.
DeNero, J., & Klein, D. (2007). Tailoring word alignments to syntactic machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational
Linguistics (ACL), pp. 1724, Prague, Czech Republic.
Eisner, J. (2003). Learning non-isomorphic tree mappings for machine translation. In The
Companion Volume to the Proceedings of 41st Annual Meeting of the Association for
Computational Linguistics (ACL), pp. 205208, Sapporo, Japan.
Ferguson, T. S. (1973). A bayesian analysis of some nonparametric problems. The Annals
of Statistics, 1, 209230.
Fossum, V., Knight, K., & Abney, S. (2008). Using syntax to improve word alignment
precision for syntax-based machine translation. In Proceedings of the Third Workshop
on Statistical Machine Translation (WMT), pp. 4452, Columbus, Ohio, USA.
Fraser, A., & Marcu, D. (2007). Getting the structure right for word alignment: LEAF. In
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language
Processing and Computational Natural Language Learning (EMNLP-CoNLL), pp. 51
60, Prague, Czech Republic.
Galley, M., Graehl, J., Knight, K., Marcu, D., DeNeefe, S., Wang, W., & Thayer, I. (2006).
Scalable inference and training of context-rich syntactic translation models. In Proceedings of the 21st International Conference on Computational Linguistics and the
44th Annual Meeting of the Association for Computational Linguistics (COLINGACL), pp. 961968, Sydney, Australia.
Galley, M., Hopkins, M., Knight, K., & Marcu, D. (2004). Whats in a translation rule?. In
Susan Dumais, D. M., & Roukos, S. (Eds.), Proceedings of the 2004 Human Language
Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT:NAACL), pp. 273280, Boston, Massachusetts, USA.
778

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

Gildea, D. (2003). Loosely tree-based alignment for machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pp.
8087, Sapporo, Japan.
Groves, D., Hearne, M., & Way, A. (2004). Robust sub-sentential alignment of phrasestructure trees. In Proceedings of the 20th International Conference on Computational
Linguistics (COLING), pp. 10721078, Geneva, Switzerland.
Haghighi, A., Blitzer, J., DeNero, J., & Klein, D. (2009). Better word alignments with
supervised itg models. In Proceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint Conference on Natural Language
Processing of the AFNLP (ACL-IJCNLP), pp. 923931, Suntec, Singapore.
Huang, L., & Chiang, D. (2005). Better k-best parsing. In Proceedings of the Ninth International Workshop on Parsing Technology (IWPT), pp. 5364, Vancouver, British
Columbia, Canada.
Huang, L., Kevin, K., & Joshi, A. (2006). Statistical syntax-directed translation with
extended domain of locality. In Proceedings of the 7th Conference of the Association for
Machine Translation in the Americas (AMTA), pp. 6673, Cambridge, Massachusetts,
USA.
Imamura, K. (2001). Hierarchical phrase alignment harmonized with parsing. In Proceedings
of the 6th NLP Pacific Rim Symposium, pp. 377384.
Jing, H. (2000). Sentence reduction for automatic text summarization. In Proceedings of
the 6th Applied Natural Language Processing Conference, pp. 310315.
Johnson, M. (2007). Why doesnt EM find good HMM POS-taggers?. In Proceedings of
the 2007 Joint Conference on Empirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-CoNLL), pp. 296305, Prague,
Czech Republic.
Knuth, D. (1997). The Art of Computer Programming: Fundamental Algorithms. AddisonWesley.
Koehn, P. (2004). Statistical significance tests for machine translation evaluation. In Lin,
D., & Wu, D. (Eds.), Proceedings of the 2004 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pp. 388395, Barcelona, Spain.
Koehn, P., Och, F., & Marcu, D. (2003). Statistical phrase-based translation. In Proceedings of the 2003 Human Language Technology Conference of the North American
Chapter of the Association for Computational Linguistics (HLT:NAACL), pp. 4854,
Edmonton, Canada.
Levenberg, A., Dyer, C., & Blunsom, P. (2012). A bayesian model for learning scfgs with
discontiguous rules. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning
(EMNLP-CoNLL), pp. 223232, Jeju Island, Korea.
Liu, D., & Gildea, D. (2009). Bayesian learning of phrasal tree-to-string templates. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing
(EMNLP), pp. 13081317, Singapore.
779

fiXiao & Zhu

Liu, Y., Liu, Q., & Lin, S. (2006). Tree-to-string alignment template for statistical machine
translation. In Proceedings of the 21st International Conference on Computational
Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL), pp. 609616, Sydney, Australia.
Liu, Y., Lu, Y., & Liu, Q. (2009a). Improving tree-to-tree translation with packed forests.
In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Language Processing of the AFNLP
(ACL-IJCNLP), pp. 558566, Suntec, Singapore.
Liu, Y., Xia, T., Xiao, X., & Liu, Q. (2009b). Weighted alignment matrices for statistical
machine translation. In Proceedings of the 2009 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pp. 10171026, Singapore.
Manning, C. D., & Schutze, H. (1999). Foundations of Statistical Natural Language Processing. The MIT Press.
Marcu, D., Wang, W., Echihabi, A., & Knight, K. (2006). Spmt: Statistical machine translation with syntactified target language phrases. In Proceedings of the 2006 Conference
on Empirical Methods in Natural Language Processing (EMNLP), pp. 4452, Sydney,
Australia.
Marcu, D., & Wong, D. (2002). A phrase-based,joint probability model for statistical machine translation. In Proceedings of the 2002 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pp. 133139.
Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1993). Building a large annotated
corpus of english: The penn treebank. Computational Linguistics, 19, 313330.
May, J., & Knight, K. (2007). Syntactic re-alignment models for machine translation.
In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),
pp. 360368, Prague, Czech Republic.
Mi, H., & Huang, L. (2008). Forest-based translation rule extraction. In Proceedings of the
2008 Conference on Empirical Methods in Natural Language Processing (EMNLP),
pp. 206214, Honolulu, Hawaii, USA.
Nakazawa, T., & Kurohashi, S. (2011). Bayesian subtree alignment model based on dependency trees. In Proceedings of 5th International Joint Conference on Natural Language
Processing (IJCNLP), pp. 794802, Chiang Mai, Thailand.
Neal, R. (1998). Philosophy of Bayesian Inference. http://www.cs.toronto.edu/radford/
res-bayes-ex.html.
Och, F. (2003). Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics
(ACL), pp. 160167, Sapporo, Japan.
Och, F., & Ney, H. (2004). The alignment template approach to statistical machine translation. Computational Linguistics, 30, 417449.
Papineni, K., Roukos, S., Ward, T., & Zhu, W. (2002). Bleu: a method for automatic
evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the
780

fiUnsupervised Sub-tree Alignment for Tree-to-Tree Translation

Association for Computational Linguistics (ACL), pp. 311318, Philadelphia, Pennsylvania, USA.
Pauls, A., Klein, D., Chiang, D., & Knight, K. (2010). Unsupervised syntactic alignment
with inversion transduction grammars. In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association
for Computational Linguistics (HLT:NAACL), pp. 118126, Los Angeles, California,
USA.
Riesa, J., Irvine, A., & Marcu, D. (2011). Feature-rich language-independent syntax-based
alignment for statistical machine translation. In Proceedings of the 2011 Conference
on Empirical Methods in Natural Language Processing (EMNLP), pp. 497507, Edinburgh, Scotland, UK.
Riley, D., & Gildea, D. (2010). Improving the performance of giza++ using variational
bayes. Tech. rep., University of Rochester.
Smith, D. A., & Eisner, J. (2009). Parser adaptation and projection with quasi-synchronous
grammar features. In Proceedings of the 2009 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pp. 822831, Singapore.
Snover, M., Dorr, B., Schwartz, R., Makhoul, J., Micciula, L., & Weischedel, R. (2005).
A Study of Translation Error Rate with Targeted Human Annotation. Tech. rep.
LAMP-TR-126,CS-TR-4755,UMIACS-TR-2005-58, University of Maryland, College
Park and BBN Technologies.
Sun, J., Zhang, M., & Tan, C. L. (2010a). Discriminative induction of sub-tree alignment
using limited labeled data. In Proceedings of the 23rd International Conference on
Computational Linguistics (COLING), pp. 10471055, Beijing, China.
Sun, J., Zhang, M., & Tan, C. L. (2010b). Exploring syntactic structural features for sub-tree
alignment using bilingual tree kernels. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics (ACL), pp. 306315, Uppsala, Sweden.
Thayer, I., Ettelaie, E., Knight, K., Marcu, D., Munteanu, D., Och, F., & Tipu, Q. (2004).
The isi/usc mt system. In Proceedings of International Workshop on Spoken Language
Translation 2004, pp. 5960.
Tinsley, J., Zhechev, V., Hearne, M., & Way, A. (2007). Robust language pair-independent
sub-tree alignment. In Proceedings of Machine Translation Summit XI, pp. 467474,
Copenhagen, Denmark.
Venugopal, A., Zollmann, A., Smith, N. A., & Stephan, V. (2008). Wider pipelines: n-best
alignments and parses in mt training. In Proceedings of the Eighth Conference of the
Association for Machine Translation in the Americas (AMTA), pp. 192201.
Vogel, S., Ney, H., & Tillmann, C. (1996). Hmm-based word alignment in statistical translation. In Proceedings of the 16rd International Conference on Computational Linguistics (COLING), pp. 836841.
Wang, M., Smith, N. A., & Mitamura, T. (2007a). What is the Jeopardy model? a quasisynchronous grammar for QA. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pp. 2232, Prague, Czech Republic.
781

fiXiao & Zhu

Wang, W., Knight, K., & Marcu, D. (2007b). Binarizing syntax trees to improve syntaxbased machine translation accuracy. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), pp. 746754, Prague, Czech Republic.
Woodsend, K., & Lapata, M. (2011). Learning to simplify sentences with quasi-synchronous
grammar and integer programming. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 409420, Edinburgh,
Scotland, UK.
Xiao, T., Zhu, J., Zhang, H., & Li, Q. (2012). Niutrans: An open source toolkit for phrasebased and syntax-based machine translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics System Demonstrations (ACL),
pp. 1924, Jeju Island, Korea.
Xue, N., Xia, F., Chiou, F.-d., & Palmer, M. (2005). The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Language Engineering, 11, 207238.
Zhang, H., Zhang, M., Li, H., Aw, A., & Tan, C. L. (2009). Forest-based tree sequence to
string translation model. In Proceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint Conference on Natural Language
Processing of the AFNLP (ACL-IJCNLP), pp. 172180, Suntec, Singapore.
Zhang, M., Jiang, H., Aw, A., Li, H., Tan, C. L., & Li, S. (2008). A tree sequence alignmentbased tree-to-tree translation model. In Proceedings of the 46th Annual Meeting
of the Association for Computational Linguistics: Human Language Techonologies
(ACL:HLT), pp. 559567, Columbus, Ohio, USA.

782

fiJournal of Artificial Intelligence Research 48 (2013) 175-230

Submitted 05/13; published 10/13

An Online Mechanism for Multi-Unit Demand and its
Application to Plug-in Hybrid Electric Vehicle Charging
Valentin Robu
Enrico H. Gerding
Sebastian Stein

vr2@ecs.soton.ac.uk
eg@ecs.soton.ac.uk
ss2@ecs.soton.ac.uk

University of Southampton, SO17 1BJ, Southampton, UK

David C. Parkes

parkes@eecs.harvard.edu

Harvard University, Cambridge, MA 02138, USA

Alex Rogers

acr@ecs.soton.ac.uk

University of Southampton, SO17 1BJ, Southampton, UK

Nicholas R. Jennings

nrj@ecs.soton.ac.uk

University of Southampton, SO17 1BJ, Southampton, UK
King Abdulaziz University, Jeddah, Saudi Arabia

Abstract
We develop an online mechanism for the allocation of an expiring resource to a dynamic agent population. Each agent has a non-increasing marginal valuation function for
the resource, and an upper limit on the number of units that can be allocated in any
period. We propose two versions on a truthful allocation mechanism. Each modifies the
decisions of a greedy online assignment algorithm by sometimes cancelling an allocation of
resources. One version makes this modification immediately upon an allocation decision
while a second waits until the point at which an agent departs the market. Adopting a
prior-free framework, we show that the second approach has better worst-case allocative
efficiency and is more scalable. On the other hand, the first approach (with immediate
cancellation) may be easier in practice because it does not need to reclaim units previously allocated. We consider an application to recharging plug-in hybrid electric vehicles
(PHEVs). Using data from a real-world trial of PHEVs in the UK, we demonstrate higher
system performance than a fixed price system, performance comparable with a standard,
but non-truthful scheduling heuristic, and the ability to support 50% more vehicles at the
same fuel cost than a simple randomized policy.

1. Introduction
Designing mechanisms for allocating scarce resources to self-interested agents is a central
research topic in artificial intelligence (Sandholm, 2002; Engel & Wellman, 2010). The
aim of this work is to devise mechanisms that satisfy certain desirable properties, such
as truthfulness and efficiency. Many settings where such mechanisms can be applied are
characterised by dynamic supply and demand, i.e., agents arrive and leave the market over
time, and the availability of supply also changes over time. This has led the field of online
mechanism design, in which agents are incentivised to report truthfully not only their value
c
2013
AI Access Foundation. All rights reserved.

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

for a given allocation, but also the period they are available in the market (Parkes, 2007).
However, to date, most of the existing work in this field assumes that the valuations of
the agents for a certain allocation can be described by a single parameter, the so-called
single-valued domains. Existing approaches that do consider multi-valued domains rely on
access to a probabilistic model of supply and demand and the ability to compute an optimal
allocation policy, which becomes computationally infeasible for realistic settings.
To address these shortcomings, we extend the state of the art by developing a novel
model-free mechanism (i.e., which assumes no knowledge of future demand or supply) for
multi-valued demand. In particular, we consider domains with multi-unit demand and
agents with non-increasing marginal values. In such domains, the first units allocated to an
agent have a higher (or equal) marginal value for this agent compared to any subsequent
units. In the online settings we consider, resources are continuously produced and perishable,
thus the available supply must be allocated in each period. Moreover, the supply available
in each period is not known in advance, but only at the start of that period.
Examples of settings with non-increasing marginal values and perishable resources occur in many real-life settings. One such example is cloud computing, where jobs arrive
over time and perishable computational resources must be allocated to these jobs (Porter,
2004; Stein, Gerding, Rogers, Larson, & Jennings, 2011). In particular, the non-increasing
marginal value model applies naturally to large-scale data processing or optimisation with
any-time computation. In such a setting, the first unit of computation provides a solution
of a certain quality, while subsequent units allow improving this solution, up to a level
when further computation is no longer useful. Hence, the first units are more valuable, as
they already provide a good approximation of the desired solution, while subsequent units
increase this value, but by a marginally non-increasing amount. Another example is online
advertising, where impressions need to be allocated as soon as users visit a webpage (Constantin, Feldman, Muthukrishnan, & Pal, 2009). The non-increasing marginal values also
applies in this setting, since additional exposure of a set of users to the same ad will likely
have a decreasing impact.
A third example, studied extensively in this paper, is the allocation of electricity for the
charging of plug-in hybrid electric vehicles (PHEVs). Similar to pure (non-hybrid) electric
vehicles (pure EVs), these vehicles can be charged directly at an electric charging point. The
difference is that PHEVs have both an electric motor and an internal combustion engine,
and are widely seen as a solution to the problem of range anxiety, i.e., fear that a car will run
out of electricity in the middle of nowhere (Eberle & von Helmolt, 2010).1 However, with
the associated increase in demand for electricity, there are significant concerns within the
electricity distribution industries regarding the widespread use of such vehicles, since the
high charging rates that PHEVs require (up to three times the maximum current demand of
a typical home) could overload local electricity distribution networks at peak times (Fairley,
2010). One approach to address this concern (e.g., adopted by the Pacific Gas and Electric
Company in California) is to introduce time-of-use pricing plans that seek to shift demand.
A more sophisticated approach that takes into account the valuations of self-interested
owners, is to design an online mechanism which schedules access dynamically in order to
prevent network overload. The assumption of decreasing marginal values is justified here
1. Practical examples of PHEVs include versions of cars such as the Toyota Prius and Honda Insight, that
can drive on petrol, but whose batteries can also be charged directly at an electrical charging point.

176

fiAn Online Mechanism for Multi-Unit Demand

because a vehicle owner is more likely to use the first units of electricity, and can always
use the combustion engine as an alternative in case she runs out of electricity (and so the
car can still be used even if it is not fully charged). Against this background, the main
contributions of our work are:
 We develop a new model-free online mechanism for settings where participating agents
have non-increasing marginal values for units of a perishable good. We adopt a greedy
algorithm coupled with a method to modify the allocation to ensure incentive compatibility. This involves cancelling part of the proposed allocation, and we explore
two ways of performing this cancellation: immediately, i.e., at each time step before a resource is actually allocated, or on departure of an agent from the market
(at which point we must take back allocated items). Both variants are (weakly)
dominant-strategy incentive compatible (DSIC), so that participants have no incentive
to misreport their valuations or arrival-departure dynamics.
 We analyse the worst-case performance achieved by the mechanisms relative to the
optimal offline allocation, considering both the number of units that need to remain
unallocated in order to achieve incentive compatibility and the total value of the
allocation (i.e., the allocative efficiency). The variation with on-departure cancellation
results in higher allocative efficiency, and is more tractable, but may involve additional
practical challenges. For example, in the PHEV charging domain, this occasionally
requires a vehicles battery to be partially discharged prior to departure.
 We evaluate the online mechanism through numerical simulations of an abstract domain and the PHEV charging domain, and compare the results to several benchmarks
that assume non-strategic agents, including an optimal offline solution, a scheduling
heuristic and a greedy algorithm without cancellation. The simulations of the PHEV
domain are based on real data from a large-scale trial of (pure) EVs in the UK. Valuations are derived from real monetary savings, by considering factors such as fuel prices,
the distance that the owner expects to travel, and the energy efficiency of the vehicle. The results establish that the mechanism outperforms a fixed-price mechanism
in terms of allocative efficiency in both domains, while performing only slightly worse
than the non-incentive compatible scheduling solutions. In addition, the mechanism
with on-departure cancellation scales easily to hundreds of agents.
We focus on allocative efficiency rather than revenue, as this is appropriate to many
domains of interest. For example, in the PHEV charging domain, it is reasonable that
the goal is to allocate capacity efficiently in order to maximise value to the user base of a
power company, given the significant constraints on charging capacity. Moreover, in many
cloud computing applications (for example, in large-scale scientific computing), the goal is
to allocate capacity to the jobs that are most urgent or important. However, if in practice
the seller wants to guarantee a a minimum revenue from each unit sold, it would be easy
to include a reserve price. If this minimum price is set the same for all units and all time
points, this would not affect the properties of our mechanism.
The remainder of this paper is organised as follows. We first discuss related work
(Section 2), before formally introducing the model (Section 3). In Section 4, we define the
177

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

online mechanisms and study their strategic properties. Then, in Section 5, we develop the
worst-case analytical results, followed in Section 6 by a discussion of how to compute the
allocations and payments in practice. Using both real and synthetic input data, we present
the results of the experimental evaluation of our mechanisms in Section 7, and we conclude
in Section 8.

2. Related Work
In this section, we first review existing work on online mechanism design (Section 2.1), and
then provide a background to the PHEV charging application, along with an overview of
previous work that considers this problem (Section 2.2).
2.1 Online Mechanism Design
One line of work in online mechanism design aims to develop online variants of the VickreyClarke-Groves (VCG) mechanism. In this context, Parkes and Singh (2003) consider the
problem of maximising the long-term allocative efficiency of a system of self-interested agents
that arrive and depart dynamically. They model the online mechanism design problem as a
Markov decision process (MDP), whose solutions can be used to implement optimal policies
in a truth-revealing Bayes-Nash equilibrium. In related work, Gershkov and Moldovanu
(2010) examine the allocation of a set of goods to a dynamic population of randomly arriving
buyers. They consider two settings: one in which there is a common deadline for allocating
objects to all buyers, and a second one without a firm deadline, but in which buyers are
impatient, assigning higher value to items allocated sooner.
Unlike both Parkes and Singh (2003), and Gershkov and Moldovanu (2010), the mechanism proposed in this paper is model-free (which has the advantage that no prior knowledge or distribution is required about the other agents types or future allocations), and we
focus on the stronger concept of dominant-strategy incentive compatibility (where reporting truthfully is a best response regardless of what other agents are doing, even if they are
irrational). Such an approach requires fewer assumptions, and makes computing allocations
more tractable compared to VCG-like approaches. This is because VCG generally requires
the allocations to be optimal in expectation (perhaps in a constrained space of policies),
whereas, as we will show, we can use greedy heuristics.
Model-free settings are considered by Hajiaghayi et al. (2005), Parkes (2007) and Porter
(2004). The work of Porter examines the scheduling of jobs on a single machine and proposes
an incentive compatible mechanism for this setting. However, his work assumes a setting
where the results of a job are released to an agent only on completion or by the agents
reported deadline. While this assumption is reasonable for scheduling computational jobs
on a server, it is not suitable for our setting, since the goods (i.e. electricity units) must
be allocated instantly when they become available.
The work which considers an online setting most similar to the one we consider is by
Hajiaghayi et al. (2005). They study the problem of online scheduling of a single, re-usable
resource over a finite time period, in which each agent has an arrival-departure window
when they are active in the market. Agents may misreport both their valuation, as well
as their arrival and departure, subject to an assumption of limited misreports (i.e., no
early arrival or later departure misreports are possible). For this setting, they characterise
178

fiAn Online Mechanism for Multi-Unit Demand

truthful allocation and payment policies, and prove worst-case approximation ratios with
respect to the optimal offline allocation. A key limitation is that the mechanism proposed by
Hajiaghayi et al. concerns single-valued domains, whereas we consider a multi-unit setting
with decreasing marginal values. We show that their mechanism does not directly apply to
the multi-unit case, requiring, in some cases, additional cancellation rules to be applied to
ensure truthfulness.
Multi-unit demand is considered in the work of Lavi and Nisan (2004), who propose an
online auction model in which the mechanism is required to make decisions about each bid
as it is received. They provide a characterisation of incentive compatibility in such domains
in terms of supply curves, a concept which relates closely to our threshold mechanism
characterisation. However, in their online auctions model, the auctioneer must respond
to each bid immediately, before considering other bids. In this response, the mechanism
determines both the quantity to be sold and the price to be paid. This would not be
applicable to the setting presented in this paper, where there is a limit on the number of
perishable units that can be allocated in each time interval. Moreover, the window-based
allocation allows the prices to be determined dynamically, based on the bids observed from
the other agents until departure. In a similar vein, Babaioff, Blumrosen, and Roth (2010)
consider an online auction model where future supply is unknown, and characterise several
subclasses of truthful mechanisms. Their domain is different from ours, as bidders in their
model do not specify multi-dimensional demands and non-increasing marginal values.
Other related work on online mechanism design adapts the consensus algorithm for
online stochastic optimisation proposed by Bent and Van Hentenryck (2004) to a setting
with self-interested agents. In this context, Parkes and Duong (2007), and Constantin and
Parkes (2009) first propose the idea of modifying the decision of an algorithm by cancelling
part of the allocation in order to ensure incentive compatibility. Unlike the present paper,
the setting assumes single-valued private information and the approaches are not applicable
to agents with non-increasing marginal values. Also for single-valued settings and for the
pure EV domain, Stein, Gerding, Robu, and Jennings (2012) propose a model-based online
mechanism that assumes knowledge of future supply and uses pre-commitment to ensure
online allocations are truthful.
2.2 Electric Vehicle Charging
Multi-agent systems and AI techniques are increasingly used to address challenges in the
Smart Grid (e.g., Vytelingum, Voice, Ramchurn, Rogers, & Jennings, 2011; Robu, Kota,
Chalkiadakis, Rogers, & Jennings, 2012), and EV charging is one of the most important
application areas. Work on the automatic scheduling of EV charging typically allows individual vehicle owners to indicate the times at which the car will be available for charging,
enabling automatic scheduling while satisfying the constraints of the distribution network.
In this vein, Clement, Haesen, and Driesen (2009) propose a centralised scheduler, which
makes optimal use of the network capacity when vehicle owners report their expected future
vehicle use to the system. Sundstrom and Binding (2012) tackle the problem of charging
multiple electric vehicles considering distribution grid constraints, formalise the underlying optimisation problem and propose a novel method based on load flow to solve it. But
strategic behaviour remains possible in these approaches; e.g., an owner may indicate an
179

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

earlier departure time or further travel distances in order to receive preferential charging.
This can result in a high cognitive load for car owners, and may lead to inefficient schedules
that are not based on actual user requirements, leading to an efficiency loss.
The potential for speculation by strategic agents has been identified as a crucial problem
in other scheduling problems, such as scheduling computational jobs on a cluster (Porter,
2004), scheduling of computation-intensive services on the cloud (Stein et al., 2011) or
market-based scheduling of loads in transportation logistics (Robu, Noot, La Poutre, & van
Schijndel, 2011). With the increase in the number of EVs requiring charging, the potential
for manipulation will become an increasingly pressing problem in PHEV scheduling as well.
Other approaches to EV scheduling include the lottery-based solution proposed by Vasirani and Ossowski (2011), in which the decision of whether to charge a vehicle or not is
determined through a lottery system, designed to ensure a level of fairness in the resulting
allocation. Unlike our work, however, the authors do not use game-theoretic principles
to prove that participating vehicles have an incentive to report their preferences truthfully,
thus in their scheme agents may have an incentive to speculate. Moreover, the experimental
analysis reported by Vasirani and Ossowski does not adopt real data to derive EV driving
patterns, charging capacities or network constraints.
Other recent work investigates using grid-integrated electric vehicles (GIVs) to sell power
and storage capacity back to the grid  a concept known as vehicle-to-grid (V2G) (c.f.
Kamboj, Kempton, & Decker, 2011). That work is different from ours, as it does not study
the problem of coordinated charging of PHEVs under local network capacity constraints.
In subsequent work to the model in the present paper (which first appeared as Gerding,
Robu, Stein, Parkes, Rogers, & Jennings, 2011, and Robu, Stein, Gerding, Parkes, Rogers,
& Jennings, 2011), we study the problem of charging pure EVs, that must receive a set
amount of charge, otherwise they derive no value from the allocation (Stein et al., 2012). A
second paper studies the problem of two-sided markets, where both PHEVs and charging
stations compete to be matched (Gerding, Stein, Robu, Zhao, & Jennings, 2013). Unlike
the present model, these papers only consider single-minded bidders, and the work of Stein
et al. assumes access to a probabilistic model of the environment.

3. The Model
We consider an online mechanism design setting with discrete time steps, where in each
period, multiple indivisible units of a perishable good are being sold, and each agent requires
multiple units within a certain period. As we will show in Section 3.1, this model can also be
used for continuously available resources, such as electricity and computational resources.
In that case, an allocation decision consists of the amount of resource to be consumed by
each agent over the next period until the following time point.
For convenience, an overview of the notation is provided in Table 1. Formally, let S(t)
denote the supply available at time t. Let I(t) = {1, 2, . . .} denote the set of agents that
are in the market at time t or have already left the market. We do not assume access
to a probabilistic model of future arrivals, departures or future supply beyond the current
time period t. Agents are numbered according to their arrival time. An agent i  I(t)s
type is described by the tuple i = hvi , ai , di , ri i  , where vi is the marginal valuation
vector, ai and di , with di  ai , are the arrival and departure times (the earliest and latest
180

fiAn Online Mechanism for Multi-Unit Demand

times that the agent is available in the market), ri is the maximum consumption rate (i.e.,
the maximum number of units agent i can consume at any time t), and  is the set of
all admissible types. Upon arrival, an agent needs to report a valuation function and a
maximum consumption rate. These two aspects of an agents reported type are required to
remain unchanged while the agent is present, although her departure time can be modified
(it only becomes known to the mechanism on the actual departure).
Each element vi,k of valuation vi is called a marginal valuation, and represents the
agents willingness to pay for the k th unit of the good, given that it has acquired k  1 units.
We require:
Assumption 1. Marginal valuations are non-increasing, i.e., i, k : vi,k  vi,k+1 .
Given this, an agents utility functionPis U (k, x, i ) = V (k, i )  x, where x is the agents
payment to the mechanism, V (k, i ) = kj=1 vi,j is the total value derived given its type,
and k is the number of units allocated to this agent between its arrival and departure.
A mechanism asks agents to report their types and, based on this information, decides
on an allocation of the supply and a payment for units received. Since agents can misreport
their type, our aim is to design a mechanism that incentivises the agents to make truthful
reports. We denote the reported type by i = hvi , ai , di , ri i. Our results use a common
assumption in the online mechanism design literature (Hajiaghayi et al., 2005), that agents
cannot report an earlier arrival or a later departure. In addition, we assume that agents
cannot misreport a higher maximum consumption rate.
Assumption 2. Limited Misreports: Agents cannot report an earlier arrival, a later
departure, or a higher maximum consumption rate, i.e., ai  ai , di  di , ri  ri must hold.
In the following, reports that satisfy both Assumption 1 and Assumption 2 are said to be
admissible. Given this assumption, our aim is to develop a mechanism which is dominantstrategy incentive compatible (DSIC), i.e., agents are best off reporting i = i , no matter
what other agents report.
Formally, let I = {i |i  I(t)} denote the types of all agents at time t, and i =
{j |j  I(t), j 6= i} the types of all agents except i, and similarly, I and i denote the
corresponding reported types. Note that, for brevity, we remove the dependence on t in this
hti
notation. Furthermore, ki denotes the endowment (or number of units allocated so far)
hti hti
at the beginning of time t, not including the allocation at time t, and khti = hk1 , k2 , . . .i.

hd+1i

Furthermore, ki = ki

denotes agent is endowment upon its reported departure.
hti

A mechanism is defined by an allocation policy, i (I |khti ), i  I(t), which determines
the number of units allocated to agent i at time t given the current endowment, and a
payment policy, xi (i |ki ), i  I(t), which calculates the total payment for the allocated
units. The allocation is made online, but the payment only needs be finalised upon the
ht+1i
hti
hti
reported departure of an agent. Note that ki
= ki + i (I |khti ). We also use i (i ) =
Pdi
hti
hti
t=ai i (I |k ) to denote the total number of units allocated to agent i, given its reported
type.
The aim is to find a mechanism satisfying the following property:
181

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Definition 1. (Dominant-Strategy Incentive Compatible (DSIC)) A mechanism is DSIC if
reporting truthfully, i.e., i = i , is a weakly dominant strategy. Formally, for all agents i,
all admissible i , i   and for all i :
V (i (i ), i )  xi (i |i (i ))  V (i (i ), i )  xi (i |i (i ))

(1)

3.1 Application to Plug-In Hybrid Electric Vehicle Charging
In applying the model to the PHEV charging domain, agents compete for a limited charging
capacity on behalf of their EV owners within a neighbourhood. We assume that the market
for electricity for PHEV charging is separate from that for regular household consumption.
Given this, the available supply, S(t), for charging the PHEV is the residual supply once
regular household consumption has been removed. The supply can also include electricity
from uncertain sources, such as a shared renewable generator, e.g., a shared neighbourhood
wind turbine or a solar panel installation.
In this scenario, a unit of electricity is defined as the amount of kWh when charging at
the lowest rate during that interval (e.g., if the lowest rate is 6.5 A, then for 230 V and
hourly slots, a unit is 6.5 A  230 V  1 h = 1.495 kWh). Charging points typically allow
for the charging to occur at different rates, and so the maximum consumption rate, ri ,
refers to the maximum charging rate of the charging point given the battery. Since units
are indivisible, this means that the charging rate needs to be a multiple of the lowest rate.
For example, if an agent is allocated 2 units in a single time step, then the charging rate is
twice the lowest charging rate for that time interval. Given the focus on network capacity,
supply is assumed perishable and capacity left unused at time t cannot be allocated later.
The time between arrival, ai , and departure, di , refers to the interval where the vehicle
is available for charging (i.e., it is at home and not being used). However, if the agent
believes that it can benefit from delaying its arrival, then it can wait before plugging the
vehicle into the electricity network. Therefore, the arrival report ai is the time at which
the owner physically plugs a vehicle into the electricity network, and a misreport consists of
not plugging in on arrival. Similarly, the reported departure, di , simply represents the time
when the vehicle is unplugged from the electricity network. Although arrival and departure
are modeled as part of the reported type, in practice these do not need to be communicated
in advance to the mechanism, and are simply observed as they occur, i.e., when the owner
plugs in or unplugs the vehicle.
The limited misreports assumption (Assumption 2) is reasonable in this context, since
agents cannot physically plug in the EV if it is not at home. The requirement that ri  ri is
also natural for PHEV charging. While most electric batteries can be configured to charge
at a slower rate, charging them at a faster rate than the one allowed by the manufacturer
might destroy them.
At the time of arrival, an agent needs to report its marginal valuation vector vi . There
is a clear interpretation of the marginal valuation because PHEVs can always use petrol
as a substitute for electricity. The marginal value for an additional unit of charge is the
expected money saved by not having to incur the cost of petrol.2 In determining the exact
value, we also need to consider the amount of purchased electricity the owner will use in
2. Note that we implicitly assume that petrol (i.e. gasoline) is always available as a substitute, and that
there are sufficient refueling points so that the vehicle does not run out of petrol.

182

fiAn Online Mechanism for Multi-Unit Demand

v1 = h10, 4i
v2 = h5i

Agent 1
Agent 2
Agent 3

v3 = h2i
S(t1 ) = 1

S(t2 ) = 1

Figure 1: Example showing arrivals, departures, and valuation vectors of 3 agents.
expectation. For example, if she is certain to use the first unit of electricity, her maximum
willingness to pay would be equal to the equivalent cost of petrol. As units become less likely
to be used, their expected value decreases. The value of a marginal unit is the expected
savings compared to using the petrol alternative. In Section 7 we provide a detailed analysis,
confirming the non-increasing marginal value (Assumption 1) for hybrid EVs.

4. The Online Mechanism
In this section, we first present a simple greedy allocation policy, that we show cannot be
coupled with a payment rule to provide truthfulness. Continuing, we combine it with two
variations on the idea of modifying the allocation generated by the greedy rule, and provide
a theoretical analysis of their properties.
4.1 Greedy Allocation Policy
hti

Let the vector vi

= hvi,khti +1 , . . . , vi,khti +r i denote agent is reported marginal values for
i

i

i

hti

the next ri units, given its endowment ki at time t. This is the agents reported willingness
hti
to pay for any units available at time t and, in what follows, we refer to vector vi as the
active (reported) marginal valuations at time t. Furthermore, let V hti denote the multiset
of such values from all agents that are present in the market at time t, i.e., from all i  I(t)
such that ai  t  di . Next, we define a set operator maxhki V to return the highest k
elements of multiset V (or, if |V| < k, to return V). Then, the greedy allocation policy is:
Definition 2 (Greedy Allocation Policy). At each time step t, allocate the S(t) units so
that every agent receives one unit of the good for each of its active marginal valuations
included in maxhS(t)i V hti .
We ignore issues with tie breaking throughout this paper to simplify the exposition.
We note, however, that all results presented hold when implementing either a random tie
breaking rule, or a first come, first served rule, that breaks ties in favour of the agent
that arrived in the market first.
To provide an example for the greedy allocation, consider the active marginal valuations
given in Table 2. In this case, the multiset of active marginal valuations consists of V hti =
h7, 6i  h10, 6, 6i  h8i = h7, 6, 10, 6, 6, 8i (in no particular order). Then, if S(t) = 3, the
highest active marginal values it will allocate the resources to are the agents with marginal
values 10, 8, and 7. Thus, in this example, each agent will receive 1 unit.
In order to show why greedy is not always DSIC, consider the example illustrated in
Figure 1, involving 2 time steps and 3 agents. Suppose that supply is S(t) = 1 at each time
183

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Supply, Agents and Preferences (Section 3)
Supply of perishable units at time t
The set of agents who have arrived so far at time t
Type of agent i
Marginal valuation vector, where vi,k is the value for the k th unit
Arrival time, departure time, and maximum consumption rate
Set of all admissible types, i.e., subject to Assumptions 1 and 2
The types of all agents i  I(t)

S(t)
I(t) = {1, 2, ...}
i = hvi , ai , di , ri i
vi = hvi,1 , vi,2 , ...i
a i , d i , ri

I = {i |i  I(t)}
i = {j |j  I(t),
j 6= i}
, I , i
P
V (k, i ) = kj=1 vi,j
U (k, x, i ) =
V (k, i )  x
hti
ki
hti hti
khti = hk1 , k2 , ...i

hd+1i
ki = ki

The types of all agents j  I(t) except i
Reported types
Total value given k units are allocated to i between ai and di
Agent utility, where x is the payment to the mechanism
General Mechanisms (Section 3)
Agent is endowment at the beginning of time t
The endowment of all agents i  I(t) at the beginning of time t

Agent is endowment on reported departure
Allocation policy, i.e., number of units allocated to i at time t
hti
i (I |khti )
given all agents reports I and current endowments khti
Payment policy, i.e., agent is payment given the reported types
xi (i |ki )
of other agents, and agent is endowment on departure.
Greedy Policy and DSIC Mechanism (Sections 4 and 4.2)
hti
vi =
Agent is reported active marginal values
hvi,khti +1 , ..., vi,khti +r i
i

i

i

Vi0

Multiset of reported active marginal values (where the union operator is used as a multiset operator throughout the paper)
Active reported marginal values if agent i would never have been
present in the market
hti
Zeros are added to this multiset to ensure that |Vi0 |  S(t)

max V, min V

Returns the highest respectively lowest k elements of multiset V

V hti =

S

hti
iI(t) vi

hti

Vi
hti

hki

hki

 Externality imposed by agent i on others, i.e., the marginal valuations of those that are missing out due to agent i being allocated
= min max
hri i
hS(t)i
min(ri , S(t)) units at time t


hti
Vector of marginal payments at time t, where pi,k is the price that
t
[

hti
ht i
pi = incr 
Ei  agent i is charged for the k th unit, and the operator incr orders
t =ai
elements from a multiset in increasing order

hti
Ei



hti
Vi0

hdi i

pi = pi

Marginal payment vector on reported departure of agent i

Table 1: Main notation with references to sections where it is first introduced.
184

fiAn Online Mechanism for Multi-Unit Demand

agent (i)
1
2
3

ri
2
3
1

vi
h8, 7, 6, 5i
h10, 6, 6, 4, 4i
h9, 8, 8, 7i

hti

ki
1
0
2

hti

vi
h7, 6i
h10, 6, 6i
h8i
hti

Table 2: Example of three agents active marginal valuations vi , given their marginal
hti
valuations vi , endowments ki , and maximum consumption rates ri .

step and ri = 1 for all agents i. Assuming truthful agents, greedy would then allocate both
units to agent 1, because agent 1 has the highest active marginal value at both time steps
h1i
h1i
h2i
h2i
(v1 = h10i > v2 = h5i, and v1 = h4i > v3 = h2i).
Now, consider the question of finding a payment policy that makes the greedy allocation
policy DSIC. How much should agent 1 pay? To answer this, note that the payment for the
unit allocated at time t = 1 has to be at least 5. Otherwise, if agent 1 were present in the
market only at time t = 1 and had a valuation v1,1  (5  , 5), it would have an incentive
to misreport v1,1 > 5 and still win. Similarly, the payment for the unit allocated at time
t = 2 has to be at least 2. Thus, the minimum payment of agent 1 if allocated two units is
x1 (|1 = 2) = 7.
On the other hand, how much should agent 1 pay if it were allocated only one unit
instead? We argue no more than 2. Suppose, for contradiction, that the payment were set
at some larger value x1 (|1 = 1) = 2 +  (where  > 0). Then if the agents first marginal
value v1,1 were instead 2 < v1,1 < 2 +  (with remaining marginal values zero), then it
would win in period 2, but it would pay 2 +  and hence have negative utility. However,
if x1 (|1 = 2)  7 and x1 (|1 = 1)  2, then agent 1 wants only one unit, not two,
as allocated by the greedy mechanism (its utility for one unit is greater than for two, as
10  2 > 10 + 4  7). Hence, the greedy allocation policy cannot be made DSIC by setting
payments.
The above example shows that the problem is not with a particular payment policy, but
is intrinsic to the greedy allocation policy. In particular, the problem is that the allocation
policy does not satisfy the necessary property of W-MON (Bikhchandani, Chatterji, Lavi,
Mualem, Nisan, & Sen, 2006):
Definition 3 (Weak Monotonicity (W-MON)). An allocation policy , is W-MON if, for
every i  I(t), i = hvi , ai , di , ri i, i = hvi , ai , di , ri i  , i  N 1 , where  is the set of
all types subject to non-increasing marginal valuations, the following equation holds:
V (i (i ), i )  V (i (i ), i )  V (i (i ), i )  V (i (i ), i )

(2)

In words, if changing an agent is type (while keeping the types of other agents fixed)
from a type i to another type i changes the allocation of i from i (i ) to i (i ), then
the resulting difference in utilities of the new and original outcomes evaluated at the new
type of agent i (denoted by function V (, i )) must be no less than this difference in utilities
185

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

evaluated at the original type of agent i (denoted by function V (, i )). Using this notion
we will now demonstrate that the greedy allocation policy is not DSIC in our setting.
Theorem 1. The greedy allocation policy is not DSIC in multi-valued domains with nonincreasing marginal valuations.
Proof. From Bikhchandani et al. (2006, Lemma 1) we know that a necessary condition for
any DSIC allocation policy is that it should satisfy W-MON (see Definition 3). If Equation 2
is true, then it can be shown that the following must hold:
i (i )

if

i (i )

> i (i ) then

X

i (i )

vi,k



k=i (i )+1

X

vi,k

(3)

k=i (i )+1

In words, more units should only be allocated to one type compared to another type, if
that type also has higher marginal values for those units. Consider again the example in
Figure 1, where we look at the W-MON condition for agent 1 by varying its type. We keep
the arrival and departure fixed, i.e., ai = ai , di = di . Suppose that v1 = h10, 4i as in the
example, but v1 = h4 + , 4 + i, where 0 <  < 1. Note that 1 (1 ) = 2, and (1 ) = 1
(agent 1 is not allocated the unit in the first time step if its type were changed from 1 to
1 ). Since 1 is allocated an additional unit (compared to 1 ), W-MON requires that 1
 < v , thereby
values the second unit higher or equal to 1 . However, we can see that v1,2
1,2
violating Equation 3. This example demonstrates that the greedy allocation policy is not
W-MON, and therefore not DSIC.
4.2 Achieving Truthfulness Through Cancellation
Addressing the problem with W-MON, we consider two types of modifications to the allocation decision of the greedy policy, both designed to achieve monotonicity. The first
is immediate cancellation, where units are simply left unallocated, i.e., none of the agents
receive the unit, even if there is a demand. The second is on-departure cancellation, where
units are initially allocated using the greedy approach, but then on departure of the agent,
any overallocated units are removed.3
The model with on-departure cancellation is more efficient because it generally requires
fewer cancellations, and is also more computationally efficient in calculating the payments
and allocations. However, depending on the domain, it may not always be possible to
remove units once they are allocated.
In the following, we detail the allocation policies and explain how payments are computed. We then give an example that shows the difference between the two mechanisms
and, lastly, we provide an analysis of the economic properties of the mechanisms.
In defining the allocation policies, we show how we can compute an agents marginal
payment vector, which determines, for each additional unit, the price the agent would need
to pay for that unit. These marginal payments are then used to determine both when to
cancel an allocation, as well as an agents total payment for a given allocation.
3. In the PHEV setting, this corresponds to first charging the battery and later discharging any overallocated
units.

186

fiAn Online Mechanism for Multi-Unit Demand

A necessary condition for truthfulness is that payments cannot depend on an agents
report except on the effect it has on the allocation; e.g., see the work of Nisan, Roughgarden,
hti
Tardos, and Vazirani (2007, Proposition 9.27). To this end, let Vi denote the multiset of
the active marginal valuations of all agents in the market at time t, if agent i were removed
and the market were rerun from ai  t onwards.
hti
We cannot simply derive Vi from V hti since removing agent i could affect the endowments of the other agents at earlier time steps. For example, for the setting from Table 2,
both agents 1 and 3 have endowments at time t and therefore removing either of these agents
is likely to increase the endowments of the other agents, thereby changing the dynamics of
hti
the entire market. To ensure that Vi is truly independent of agent i, the market needs
to be re-run from the very point when agent i first entered the market, and this process
needs to be repeated for each agent i  I(t) such that ai  t  di , whose payments we are
computing.
hti
In case |Vi | < S(t), we furthermore add a number of zero-valued bids and refer to this
hti

hti

enlarged set as Vi0 , to ensure that |Vi0 |  S(t). Next, similar to the operator maxhki ,
we define the set operator minhki V to return the lowest k elements of multiset V (or, if
|V| < k, to return V). We define the externality that agent i would impose on other agents
if it won min(ri , S(t)) out of S(t) units at time t as:


hti
hti
Ei = min max Vi0
hri i

hS(t)i

hti

hti

Note that the cardinality of Ei is equal to |Ei | = min(ri , S(t)). Intuitively, the multiset
hti
Ei contains the marginal values from other agents that would lose out if agent i were to
hti
win ri units at time t. For example, let V1 = h1, 4, 5, 7, 9, 10i (sorted for convenience),
hti

S(t) = 4, and r1 = 2. Then, E1 = h5, 7i.
If an agent were active for only a single time step, then the externality would specify the
payment for each unit. That is, using the same example, if agent 1 were allocated a single
unit by the mechanism, its payment would be 5. On the other hand, if it were allocated 2
units, its payment would be 5 + 7 = 12. The intuition here is the same as in the regular
Vickrey-Clarke-Groves (VCG) mechanism, because the total payment corresponds to the
sum of the externalities.
To compute the overall payments online, we need to combine these externalities across
all time steps in the agents active period up to current time t. To do this, we define an
hti
ordered vector of marginal payments, pi , as follows:

S
ht i
hti
t
E
,
pi = incr

t =ai i
where incr is an operator that orders elements from a multiset in increasing order, and we
use the union symbol to denote the union of multisets (and so the same element can appear
multiple times).
hti
Now, pi,k is the price that agent i is charged for the k th unit of the good. Intuitively, this
is the minimum valuation that the agent could report for winning this unit by time t. These
prices are adjusted in each time step. In particular, since the vector is in increasing order,
187

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

hti

and elements are only added as time increases, pi,k either stays the same or decreases for a
given k, but can never increase. In the following, we use pi,k to denote agent is marginal
payment of the k th unit at time di .
Given this, the decision and payment policies are defined as follows:
 Allocation Policy The decision to allocate consists of two stages:
Stage 1 At each time step t, pre-allocate using the greedy allocation policy (see
Definition 2).
Stage 2 We consider two variations of how to decide to cancel the pre-allocation:
 Immediate Cancellation (IM). Leave any unit unallocated whenever the marginal payment at time t for this unit is greater than the marginal value, i.e.,
whenever:
hti

hti

hti

hti

vi,k < pi,k for ki < k  ki + i

 On-Departure Cancellation (OD). For each departing agent, cancel the allocation of any unit k  ki where vi,k < pi,k .
 Payment Policy Payment always occurs on reported departure. Given that ki units
are allocated to agent i, the payment collected from i is:
xi (i |ki ) =

Xki

k=1

pi,k

(4)

In the following, we refer to our two mechanisms with immediate and on-departure
cancellation by IM and OD respectively, and the corresponding allocation policies by  im
and  od . If no distinction between the two mechanisms is made,  is used.
The payment policy mirrors the allocation policy. For example, if immediate cancellation
hti
is used, then for each agent i and for all times t, the values of the pi vector are computed
by re-running the market, in the absence of agent i using immediate cancellation, based on
the reports of the other agents. Conversely, if on-departure cancellation is used, the same
policy should be used in computing the pi prices.
4.3 Examples
To demonstrate how the two mechanisms work, we present two examples. The aim of the
first example is to show the difference between immediate and on-departure cancellation.
The second example illustrates the effect of changing the maximum consumption rates. The
example shows that in specific instances, increasing an agents maximum consumption rate
can actually increase the number of cancellations.
4.3.1 Example 1
The first example extends the setting shown in Figure 1 to include a third time step, t = 3.
Both agents 1 and 3 remain in the market at t = 3 (i.e., d1 = d3 = 3) and no new agents
arrive. Furthermore, S(t) = 1 in t  {1, 2, 3}, and so there are now three units to be
allocated in total. As before, we suppose that ri = 1 for all agents. Table 3 shows the
188

fiAn Online Mechanism for Multi-Unit Demand

t=1

t=2

t=3
IM

t=3
OD

agent 1:
a1 = 1, d1 = 3,
v1 = h10, 4i, r1 = 1
h1i
h1i
k1 = 0, v1 = h10i
h1i
h1i
V1 = E1 = h5i
h1i
p1 = h5i
imh1i
odh1i
1
= 1
=1
h2i
h1i
k1 = 1, v1 = h4i
h2i
h2i
V1 = E1 = h2i
h2i
p1 = h2, 5i
imh2i
1
=0
odh2i
1
=1
h3i
h1i
k1 = 1, v1 = h4i
h3i
h3i
V10 = E1 = h0i
h3i
p1 = h0, 2, 5i
imh3i
1
=1
h3i

agent 2:
a2 = 1, d2 = 1,
v2 = h5i, r2 = 1
h1i
h1i
k2 = 0, v2 = h5i
h1i
h1i
V2 = E2 = h10i
h1i
p2 = h10i
imh1i
odh1i
2
= 2
=0

agent 3:
a3 = 2, d3 = 3,
v3 = h2i, r3 = 1

h2i

h1i

h3i

h1i

h3i

h1i

k3 = 0, v3 = h2i
h2i
h2i
V3 = E3 = h4i
h2i
p3 = h4i
imh2i
odh2i
3
= 3
=0
k3 = 0, v3 = h2i
h3i
h3i
V3 = E3 = h4i
h3i
p3 = h4, 4i
imh3i
3
=0

h1i

k1 = 2, v3 = hi
h3i
h3i
V10 = E1 = h0i
h3i
p1 = h0, 2, 5i
odh3i
1
=0

k3 = 0, v3 = h2i
h3i
h3i
V30 = E3 = h0i
h3i
p3 = h0, 4i
odh3i
3
=1

Table 3: Example run of the mechanism with 3 agents and 3 time steps for the IM and
OD mechanisms. Grey cells indicate different values for IM and OD policies.
hti

hti

hti

endowments ki , the active marginal valuations Vi , the externalities, Ei , the marginal
hti

hti

payments pi , and the allocation decisions i at different time steps.
We start by considering the allocations and payments using immediate cancellation.
At time t = 1, Stage 1 of the mechanism pre-allocates the unit to agent 1, and since
h1i
v1,1 = 10  p1,1 = 5, this pre-allocation is not cancelled in the second stage. At time
t = 2, the unit again gets pre-allocated to agent 1 since its active marginal value is greater
h2i
h2i
h2i
than that of agent 3, i.e., v1 = h4i > v3 = h2i. However, V1 = h2i is inserted at the
h2i

h2i

beginning of the p1 vector, and as a result v1,2 = 4 < p1,2 = 5 (at these prices, agent
1 prefers to be allocated one unit instead of two). Consequently, this pre-allocation gets
cancelled and the unit goes to neither of the agents.
h3i
At time t = 3, the active marginal value of agent 1 is still v1 = h4i, since its endowment
is unchanged, and since agent 1 still has the highest active marginal value, it is again preallocated the unit. To calculate the marginal payment of agent 1, recall that the allocation
policy needs to be recomputed with agent 1 entirely removed from the market. In that case
agent 3 would have been allocated a unit at time t = 2, and thus at time t = 3 the active
h3i
marginal value of this agent is 0. Thus, the value of 0 is inserted in the p1 vector. At
h3i
t = 3, however, now v1,2 = 4  p1,2 = 2, and therefore the pre-allocation is not cancelled.
An interesting exercise is to see what happens to the marginal payment vector of agent
3 at t = 3. To calculate this, we have to remove agent 3 and rerun the market from t = 2. In
189

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

agent1
agent2
agent3

v1 = h10, 8, 3i
v2 = h7i
v3 = h1i
S(t1 ) = 2

S(t2 ) = 1

Figure 2: Example showing arrivals, departures, and valuation vectors of 3 agents.

h2i

this case, at time t = 2, the marginal payment vector of agent 1 becomes p1 = h0, 5i. Since
h2i
the marginal payment for the second unit, p1,2 , remains unchanged, the pre-allocation is
still cancelled! Therefore, even when agent 3 is not in the market, the second unit remains
h3i
unallocated, and agent 1s active marginal value at t = 3 is again v1 = h4i, and so
h3i
h3i
V3 = h4i. Given this, agent 3s marginal payments become p3 = h4, 4i. Note that the
marginal payment for the first unit (4) is higher than the marginal value for this unit (2),
and this is consistent with the allocation. Otherwise, if the marginal payment had been
lower, agent 3 would have an incentive to overreport and win the unit at t = 3.
So, in case of immediate cancellation, two out of three units are allocated to agent 1,
h3i
h3i
and that agent pays x1 = p1,1 + p1,2 = 0 + 2 = 2. The third unit is not allocated to any
agent. Note that this unit cannot go to agent 3, because the payment would have been
h3i
p3,1 = 4, resulting in a negative utility for agent 3.
Now consider the same setting but with on-departure cancellation. The first two time
steps are as before, except that there is no cancellation at t = 2 (since this will be done on
departure if needed). This changes the endowment state of agent 1 at t = 3, and therefore
h3i
the active marginal value of agent 1 at t = 3 is equal to v1 = hi, and this is the same if
agent 3 is removed from the market. Therefore, the unit is pre-allocated to agent 3, and the
h3i
h3i
payment for this unit is p3,1 = p3,1 = 0. The vector p1 remains unchanged compared to the
immediate case. At this point, there is no longer a need to cancel one of the pre-allocations
of agent 1, since it has received k = 2 units, the same allocation as with the immediate
cancellation policy, and note that v1,2 > p1,2 .
No pre-allocations are cancelled with the on-departure policy, and so this policy is more
efficient. As we will show in the remainder of the paper, the on-departure policy never
cancels more, and typically cancels fewer pre-allocations compared to the immediate one.
Still, it is possible to construct examples where, in the worst case, half of the pre-allocations
need to be cancelled, even with the on-departure policy.
Furthermore, note that some units are given away for free (i.e., the payment for these
units is zero). This is a standard problem with auctions if there is insufficient competition,
and can be trivially resolved by e.g. introducing a minimum price or reserve price for each
unit of the good. However, this will reduce efficiency since units will remain unallocated
if they fall below the reserve price. We do not consider reserve prices in this paper, but
the economic properties of the mechanism continue to hold with reserve prices, as long as
the reserve prices are the same for all time points (otherwise there could be an incentive to
misreport the arrival time).
190

fiAn Online Mechanism for Multi-Unit Demand

4.3.2 Example 2
The next example, depicted in Figure 2, again shows a setting with two time steps and three
agents, but with different preferences and now the supply in the first step is two units, and
we change the maximum consumption rate of agent 1. We consider two cases:
The maximum consumption rate of agent 1 is r1 = 1.4 In this case, at most one marginal
value is taken from each agent per time step. At time t1 , marginal valuations v1,1 = 10 of
agent 1, and v2,1 = 7 of agent 2 are pre-allocated, while at time t2 , marginal value v1,2 = 8
of agent 1 is pre-allocated. The prices charged to agent 1 are: p1 = h0, 1i, because without
agent 1 in the market, there would be a free, spare unit at time t1 and the available unit at
t2 would sell to agent 3 for 1. No pre-allocation gets cancelled in this case, and the actual
allocation is equivalent to the optimal offline allocation.
The maximum consumption rate of agent 1 is r1 = 2. Then, at time t1 , the greedy
policy described above allocates the two marginal values of agent 1: v1,2 = 10 and v1,2 = 8,
as they are both higher than v2,1 = 7, and agent 2 drops out of the market. At time t2 , the
unit is again pre-allocated to agent 1 (due to the marginal value of 3 being higher than 1).
However, now the marginal payments vector required from agent 1 is p1 = h0, 1, 7i, while
the marginal valuations are v1 = h10, 8, 3i. Given the prices, agent 1 prefers two units to
three (because 10 + 8  1 > 10 + 8 + 3  1  7), so the third is cancelled. The overall
efficiency is lower, as the pre-allocation of the third available unit is now cancelled, whereas
with r1 = 1 it was allocated to agent 2. Note, however, that although the efficiency is much
lower, agent 1 has an incentive to declare its true maximum consumption rate r1 = 2 as, in
this case, its payment does not change.
4.4 Establishing Truthfulness
In this section we prove that the above mechanisms are DSIC under the assumptions of
non-increasing marginal valuations (Assumption 1) and limited misreports (Assumption 2).
In the following, we will first establish DSIC with respect to valuations only, and prove
truthful reporting of arrival and departure times separately. In more detail, we proceed in
the following 3 stages:
(i) We define the concept of a threshold policy, and show that, when coupled with an
appropriate payment policy, and given any admissible pair hai , di i, if an allocation policy is
a threshold policy, then the mechanism is DSIC with respect to the valuations (Lemma 1).
(ii) We show that our allocation policy is a threshold policy (Lemma 2).
(iii) We show that if agents truthfully report their valuations, reporting ai = ai , di = di ,
and ri = ri is a weakly dominant strategy (Lemma 3).
These results are combined in Theorem 2 to show that our mechanism is DSIC.
Definition 4 (Threshold Policy). An allocation policy  is a threshold policy if, for a given
agent i with fixed hai , di , ri i and i , there exists a marginally non-decreasing threshold
vector  , independent from the report vi made by agent i, such that following holds: k, vi :
i (i , i )  k if and only if vi,k  k .
4. Note that the other two agents only desire one unit, so their maximum consumption rate is irrelevant in
this example.

191

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

In other words, a threshold policy has a potentially different threshold k for each k,
such that agent i will receive at least k units if and only if its reported valuation for the k th
item is at least k .
A threshold policy satisfies W-MON, which is sufficient for DSIC in this domain since
we have bounded agent valuations and the domain is completely ordered, meaning that all
payoff types agree on the same weak preference ordering on all allocations (i.e., more is
always weakly better than less), and indifference to the way goods are allocated to other
agents (Bikhchandani et al., 2006). We show that our allocation policy has the threshold property, and thus satisfies W-MON, and that it also handles misreports of arrivals,
departures and maximum charging rates.
Importantly, the vector  has to be non-decreasing, i.e., k+1  k , and should be
independent of the reported valuation vector vi . Both of these properties are satisfied by
the pi vector, and we will use this to show that our mechanism is a threshold policy.
First, however, we show that a threshold policy with appropriate payments is DSIC with
respect to the valuations:
Lemma 1. Fixing admissible haj , dj , rj i for all j  I and fixing i , if  is a threshold
policy coupled with a payment policy:
xi (i , i ) =

Pi (i ,i )
k=1

k ,

then if vi is marginally non-increasing, reporting vi truthfully is a weakly dominant strategy.
Proof. Agent is utility can be rewritten as:
Pi (i ,i )
ui (i ; i ) = k=1
(vi,k  k )

Since  is independent of vi , agent i can only potentially benefit by changing the allocation,
i (i , i ). Since the values of k+1  k (non-decreasing threshold vector) and vi,k+1  vi,k
(non-increasing marginal values), by Definition 4 we have vi,k  k  0 for any k  i (i )
and vi,k  k  0 for any k > i (i ). Suppose that, by misreporting agent i is allocated
i (i ) > i (i ), then ui (i ; i ) < ui (i ; i ) since:
Pi (i ,i )

k=i (i ,i )+1

(vi,k  k ) < 0

Similarly, misreporting such that i (i , i ) < i (i , i ) results in ui (i ; i ) < ui (i ; i )
since:
Pi (i ,i )
(vi,k  k )  0
k=i (i ,i )+1

If misreporting has no effect on the allocation, the utility remains the same. Therefore,
there is no incentive for agent i to misreport its valuations.

Note that the greedy allocation policy is not a threshold policy. Indeed, we have shown
already that it does not satisfy W-MON. The next lemma shows that the threshold condition
holds if we cancel some allocations according to our policies, and if we set the threshold
values to k = pi,k .
192

fiAn Online Mechanism for Multi-Unit Demand

Lemma 2. Given non-increasing marginal valuations, the allocation policy  in Section 4.2
is (for either cancellation policy) a threshold policy where k = pi,k .
hti

hti

Proof. First, from the definition of vector pi and pi from Section 4.2, the values of pi are
independent of the reports vi made by agent i. This is because each of its component values
ha i
hti
Vii , . . . , Vi are computed based only on the reports of the other agents, by first removing
hti

agent i from the market. Note that pi and pi are also affected by the reported arrival
time, departure time, and maximum consumption rate of agent i, but in this lemma we
are only concerned with truthful reporting of the agents valuations, and take the reported
arrival and deadline as given, and do not require these to be truthful at this point.
Second, we need to show two inequalities, thus the proof is done in two parts. Part 1:
Whenever vi,k  pi,k , i allocates at least k units to agent i. Part 2: Whenever vi,k < pi,k ,
i allocates strictly fewer than k units to agent i.
Part 1: Let vi,k  pi,k . Suppose that agent i has uniform marginal values, vi,k , for the
hti
first k units (i.e., vi,1 = vi,2 = . . . = vi,k ). Note that externality Ei contains the marginal
values at time t that agent i will displace when winning up to ri units of the good in time
step t (that is, these marginal values will reappear in the next time step if the same agents
remain in the market). Given this, as long as agent i has fewer than k units then, in Stage
1 of the mechanism, and at each time step that agent i is in the market, it will win exactly
hti
those units where the marginal values in Ei are less than vi,k , i.e. it will win all units
hti
hti
1  j  |Ei | where vi,k  Ei,j (ignoring tie breaking). Note that the externalities (and
thus the marginal payments) are calculated by removing agent i from the market from the
very first time it entered, and so do not contain any displaced marginal values. However,
even when, by winning a unit, agent i displaces the losing marginal value to a future time
step, since this value is less or equal to vi,k , it will not affect the allocations of the first k
units in future time steps for agent i since it will continue to have a higher marginal value.
Now, because pi,j  pi,k for j  k (by definition), there must be at least k units for which
hti
hti
pi,k  Ei,j , 1  j  |Ei | in the period ai  t  di , and since vi,k  pi,k , agent i wins at
least k units in Stage 1.
Furthermore, whenever j units are won at a particular time step, the marginal payments
for those units appear as within the first k  + j first elements of the pti vector, where k  is
the number of units won at earlier time steps (since these are the values with the the lowest
clearing payment, and they are ordered ascendingly). Because agent i wins a unit with
hti
hti
externality Ei,j in Stage 1 if and only if vi,k  Ei,j (given uniform valuations), it follows
that vi,k = vi,j  pi,j whenever it wins a unit in Stage 1. Therefore, no pre-allocations are
cancelled in Stage 2.
The above holds if agent i has uniform marginal values of vi,k for the first k units. In
fact, however, because of non-increasing valuations, we have vi,j  vi,k , for all 1  j  k,
and thus the allocation policy will allocate at least k units to agent i.
Part 2: Let vi,k < pi,k . First consider the on-departure cancellation case. As per the
definition of Stage 2 of the mechanism, the allocation of unit k is cancelled. However, we still
need to show that any pre-allocated units j > k are cancelled as well. Since pi,j  pi,k (by
definition) and vi,j  vi,k (since valuations are marginally non-increasing by assumption)
for all j > k, it follows that vi,j < pi,j for all j > k. Therefore even if Stage 1 pre-allocates
193

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

k or more units, these will be cancelled in Stage 2, and thus strictly fewer than k units
remain.
hti
Now consider the immediate cancellation case. Note that pi,k  pi,k for tk  t  di ,
where tk is the time when the k th unit was allocated. That is, marginal payment values can
ht i
only decrease over time. Since vi,k < pi,k (by assumption) and pi,k  pi,kk , it follows that
ht i

hti

vi,k  pi,kk . Thus it follows that vi,k < pi,k for any (ai + k  1)  t  di . Consider a case
where, at time tk , the k th unit is allocated in Stage 1. As a result, pre-allocation of the k th
unit will always be cancelled at time tk in Stage 2 of the allocation policy. Therefore, the
final result is an allocation of strictly fewer than k units.
By setting k = pi,k , the payment policy in Equation 4 corresponds to the payment
policy in Lemma 1. Therefore the proposed mechanism is shown to be DSIC in valuations.
We complete the proof by showing that truthful reporting of the arrival and departure
times are also DSIC given limited misreports, now assuming truthful reporting of vi .
Lemma 3. Given limited misreports, and assuming that truthfully reporting vi = vi is a
dominant strategy for any given arrival,departure and maximum consumption rate reports
hai , di , ri i, then (subject to limited misreports) it is a dominant strategy to report ai = ai ,
di = di , and ri = ri .
ha ,d ,r i

Proof. Let pi i i i denote the vector of increasingly ordered marginal clearing values (computed without i), given the agent reports i = hvi , ai , di , ri i. By reporting type i , the agent
Pi (i ) hai ,di ,ri i
is allocated i (i ) items, and its total payment is:
. For each agent i, misj=1 pi,j
reporting from i to i results in one of two cases:
i (i ) = i (i ): Misreporting by agent i cannot change the values in pi , but can
only ever decrease the size of the pi vector. In particular, due to limited misreports we
ha ,d ,r i
have ai  ai , di  di and ri  ri , and thus p i i i contains a subset of the elements
i

hai ,di ,ri i

from pi

. As these vectors are by definition increasingly ordered, it follows that
hai ,di ,ri i
hai ,di ,ri i
pi,j
 pi,j
, j  (di  ai + 1). Since the payment consists of the first ki = ki
elements, this can only increase by misreporting.
i (i ) 6= i (i ): First, we show that i (i ) > i (i ) could never occur. Since the
threshold values remain the same, but the agent can win fewer units per time step (when
reporting a lower maximum consumption rate), and/or the number of time steps in which
allocations occur decreases (when reporting a later arrival and/or earlier deadline), Stage
1 of the mechanism can only allocate fewer or equal numbers of units. Furthermore, since
ha ,d ,r i

ha ,d ,r i

pi,ji i i  pi,ji i i , the possibility of cancelling can only increase in Stage 2. Thus, it
always holds that i (i )  i (i ).
Now, we consider the case i (i ) < i (i ). First, as shown for the case i (i ) = i (i )
Pi (i ) hai ,di ,ri i Pi (i ) hai ,di ,ri i
above, we know that j=1
pi,j
 j=1 pi,k
(i.e., the payment for those units
won can only increase by misreporting arrival and/or departure). Furthermore, we know
that the allocation i (i ) is preferable to any other allocation i (i ) < i (i ), otherwise
reporting the true valuation vector vi would not be a dominant strategy. Since the payment
for these items is potentially even higher when misreporting, the agent cannot benefit by
winning fewer items.
194

fiAn Online Mechanism for Multi-Unit Demand

Theorem 2. Given non-increasing marginal valuations and limited misreports, both the ondeparture cancellation and immediate cancellation policies with payment policy according to
Equation 4 are DSIC.
Proof. The proof of this theorem follows directly from the above lemmas. Lemmas 1 and
2 show that, for any triple of arrival/departure/consumption rate (mis)-reports, hai di , ri i,
the allocation policy is truthful in terms of the valuation vector vi , given an appropriate
payment policy. Furthermore, the payments in Equation 4 correspond to those in Lemma 2,
and therefore they truthfully implement the mechanism. Finally, Lemma 3 completes this
reasoning, by showing that, for a truthful report of valuation vector vi , agents cannot benefit
from misreporting arrivals/departures.
4.5 Implications for the PHEV Domain
Since we assume the units to be perishable, it may not always be possible to cancel units
once they are allocated. Whereas this is not a problem for immediate cancellation, since
units are never allocated to begin with, the on-departure cancellation policy requires the
battery to be partially discharged before departure of the vehicle. Although this may be
undesirable, it is in the agents best interest to avoid paying for these units given the design
of the mechanism, since the marginal value for these units is less than the marginal payment.
An agent could avoid discharging by unplugging before the units are discharged, but then
the agent will end up paying for these relatively expensive units. This noted, in Section 7,
in addition to comparing the IM and OD mechanisms, we also evaluate to what extent the
mechanisms would be manipulable if they were designed with the simple greedy allocation
policy, and without assuming any cancellation.

5. Theoretical Bounds on Allocative Efficiency
An important question given the online nature of the allocation is how the allocative efficiency compares to that of an optimal offline allocation, assuming full knowledge of the
future. As discussed in Sections 3  4.2, in our online setting, it is not possible to achieve an
optimal allocation, because agents arrive and leave the market continuously. Moreover, in a
multi-dimensional online setting, the allocation of some units needs to be cancelled in order
to maintain truthfulness. Nevertheless, the optimal offline allocation represents a useful
upper bound of what could be achieved in terms of allocative efficiency, if the preferences
and availability constraints of all agents were known in advance.
To this end, in the following, we study the theoretical worst-case performance of both
IM and OD. More precisely, for each of these policies, we consider two types of inefficiencies:
 Worst-case cancellation ratio. This is the fraction of units from those allocated to any
single agent that need to be cancelled in the worst case (and, to maintain the incentive
properties, cannot be allocated to any other agent). Formally, let I be the set of all
agents present in the market at any time point during the time interval over which
the bound is computed. Denote by ipre (I ) the total number of units pre-allocated
to agent i  I in Stage 1 of the policy over the entire active period of this agent, and
by icanc (I ) = ipre (I )  i (I ) the number of units that were cancelled in Stage 2.
195

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Given this, the cancellation ratio for a specific agent i is RC,i (I ) =

icanc (I )
.
ipre (I )

Then

we define the worst-case cancellation ratio over all agents i  I and types I  |I|
as:
 canc (I )
max
.
RC
= max max ipre
I |I| iI i (I )
 Competitive ratio of allocative efficiency. Whereas the cancellation ratio considers the
worst-case for an individual agent, the competitive ratio compares the social welfare of
our mechanism with the social welfare achieved by the optimal offline mechanism, with
full information about future arrivals. Here, social welfare is defined as the sum of the
valuations obtained by all agents (i.e., the sum of utilities excluding any payments). In
more detail, following the work of Parkes (2007), the competitive ratio for our setting
is defined as follows. Let ion (I ) denote the number of units allocated by our online
mechanism on departure of agent i given the types of all agents, I  |I| , and iof f (I )
denote the number of units allocated by the optimal offline mechanism to agent i. The
P Pion
social welfare of the allocations is then defined as: V on (I ) = iI k=1
vi,k for the
of f
P
P
i
online case, respectively V of f (I ) =
iI
k=1 vi,k for the offline case. Now, a
competitive analysis assumes the existence of an adversary that can choose from
a set of inputs, and in our case the adversary can choose any set of agent types
I  |I| . Given this, an online mechanism is said to be onc-competitive for efficiency,
if there exists a constant c  1 such that: I  |I| : VVof f((I ))  1c . We can also say
I

that our online mechanism is guaranteed to achieve within a fraction of
of the optimal offline algorithm.

1
c

of the value

Our motivation for studying these two metrics is as follows. First, as outlined in Section
4.2, both variants of the mechanism we propose require that part of the allocation of some
agents is sometimes cancelled, in order to ensure truthfulness. It is natural to ask what is
the worst-case fraction of the number of units allocated to any agent that will need to be
cancelled, under both types of mechanisms (i.e., with immediate and on-departure cancellation), for any market set-up. For the second criteria (i.e., the competitive ratio of allocative
efficiency), we follow the metric proposed by Hajiaghayi et al. (2005) and Parkes (2007) for
online domains, with the caveat that deriving this bound for the multi-dimensional case is
considerably more involved than for the single-dimensional one, due to the required cancellations. In Section 5.1 we study these issues for the mechanism with immediate cancellation,
and in Section 5.2 for the mechanism with on-departure cancellation.
5.1 Worst-Case Bounds for the Mechanism with Immediate Cancellation
The following theorem shows that, when using the online mechanism with immediate cancellation, the worst-case cancellation ratio goes to 1 as the number of units required by a
single agent goes to infinity.
max = 1, where n is the maximum
Theorem 3. Using the IM allocation policy, limn RC
demand.

Proof. The proof is by example. Consider the following setting consisting of an agent A
with marginal valuation vector vA = hv1 , v2 , ...vn i, where these values are strictly decreasing,
196

fiAn Online Mechanism for Multi-Unit Demand

i.e., v1 > v2 > .... > vn . We assume that this agent arrives at time aA = 1, departs at dA ,
where dA = n  (n + 1)/2, and has a maximum charging speed of rA = 1. Agent A faces a
sequence of cursory (i.e. local) agents, where each of these agents desires exactly one unit,
is present in the market for only one timestep and departs immediately afterwards. At any
one time there is exactly one of these cursory agents in the market. The valuations of these
agents are as follows. The first agent has a valuation of v1 = hv1  i, the next two agents,
i = 2 and i = 3, have valuations of vi = hv2  i, the next three agents, i  {4, 5, 6}, have
valuations vi = hv3  i, the next four agents, i  {7, 8, 9, 10}, vi = hv4  i, etc. Thus, in
total, there is a sequence of n  (n + 1)/2 of these agents. Here,  is sufficiently small such
that v1   > v2 . As a result, agent A imposes the following externality at each timestep:
hv1  , v2  , v2  , v3  , v3  , v3  , v4  , v4  , v4  , v4  , ...i (noting that, since the
cursory agents are only present in the market for a single time step, cancelling an allocation
does not affect the externality, nor the marginal payment).
The allocation for this settings then proceeds as follows. In the first time step, the unit
is pre-allocated to agent A (since v1 > v1  ) and there is no cancellation. In the second
time step, the unit is again pre-allocated to agent A (since v2 > v2  ), but at this point
h2i
the marginal payment is pi = hv2  , v1  i. Since the marginal value for the second unit
is less than the marginal payment for this unit, i.e., v2 < v1  , the unit gets cancelled.
Therefore, at time t = 3, the marginal value of agent A is still v2 , and the third unit also
gets allocated to the agent, and this time it is not cancelled. However, in the next two
time-steps, the units are pre-allocated and cancelled both times. To see this, note that
h2i
the marginal payment at time t = 5 is pi = hv3  , v3  , v2  , v2  , v1  i. Since
h2i
v3 < pi,3 = v2  , this unit gets cancelled.
More generally, for every k th unit which is allocated and not cancelled, the marginal
value of agent A becomes vk+1 , and the next k units will be first pre-allocated (since the
marginal value of the cursory agents are vk+1  ), but then subsequently cancelled (since
these all have a marginal payment of vk  ). Only the (k + 1)th unit will be allocated and
not cancelled, but then the next k + 1 units will be cancelled, and so on.
pre
= 1 + 2 + 3 + 4 + . . . + n = n  (n + 1)/2 units will be pre-allocated.
As a result, all A
canc = 0 + 1 + 2 + 3 + . . . + (n  1) = (n  1)  n/2 will be cancelled, and
Of those units A
A = n will remain allocated. Therefore, the ratio of number of units cancelled as n  
is:
canc
A
n1
n2  n
= lim
=1
pre = lim
n 
n n + 1
n n2 + n
A

RC,A = lim

The above theorem shows that the worst-case result for an individual agent is unbounded. We can use this result (and the example constructed in the proof) to derive a
similarly negative result for the allocative efficiency (i.e., the overall efficiency of the system):
Theorem 4. For the mechanism with immediate cancellation, the competitive ratio of the
allocation efficiency is unbounded. That is, there exists no finite c, such that:
I  |I| :

1
V on (I )

of
f
c
V
(I )
197

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Proof. Generally, there are two potential sources of inefficiency w.r.t. the offline allocation:
either the units are pre-allocated and subsequently cancelled, or some units are allocated to
agents that have less utility for them than the agents who would be allocated in the offline
case. Our proof is based on the former source of inefficiency and uses the same example
given in Theorem 3.
In the example of Theorem 3 we showed that it is possible to construct an example
where, given n  (n + 1)/2 units of supply, (n  1)  n of these are cancelled (and thus not
allocated to any agent) and n are allocated. Now, suppose that the valuations for these
units by all agents (including agent A) are between [v, v], where v/v = r is a finite constant.
Since using the optimal offline allocation all units will be allocated, the total value will be
at least: V of f  v  n  (n + 1)/2. On the other hand, the online allocation using the online
allocation using immediate cancellation will have a value of at most: V on  v  n.
Given this, the following holds:
2r
vn
V on
 lim
= lim
=0
n v  n  (n + 1)/2
n n + 1
n V of f
lim

Therefore, for any constant c, it is always possible to find a counter example where the
worst-case efficiency is lower than 1/c.
Thus, there is no theoretical bound on the efficiency loss when using the immediate
cancellation allocation policy. However, the proof relies on there being an agent who is
infinitely patient, has infinite demand, and has a higher valuation than all other bidders
for each unit. In practice, such an extreme situation would never occur. To consider more
practical scenarios, therefore, in Section 7 we use simulations to investigate realistic settings. After showing the worst-case bounds with immediate cancellation, in the remainder
of Section 5 we derive theoretical bounds for the on-departure cancellation mechanism.
Specifically, we will show that this mechanism provides much better bounds. In fact, the
competitive bounds for the efficiency are the same as those for single-unit demand settings,
where no cancellation occurs.
5.2 Worst-Case Bounds for the Mechanism with On-Departure Cancellation
This section is divided into two parts: in Section 5.2.1 we discuss the worst-case cancellation
ratio for a particular agent and provide a tight bound, while in Section 5.2.2 we consider
the bound on allocative efficiency for the entire market.
5.2.1 Worst-Case Cancellation Ratio
This section is organised as follows. First, we show that at most half of the units are
cancelled for any particular agent. Then we go on to show that there exist examples where
half of them are cancelled. Note that, for convenience, the following lemma is formulated
in terms of units retained instead of units cancelled.
Lemma 4. Using on-departure cancellation, suppose that an agent i is pre-allocated n units
by the departure time di , and k of these units are kept in Stage 2 (and so the mechanism
cancels n  k units). Then, for any type profile I  |I| , and any agent i  I, k  n/2
(i.e., at least half of the units are allocated).
198

fiAn Online Mechanism for Multi-Unit Demand

Proof. To prove this property, we start by deriving two inequalities which hold for any value
of k. First, since k is defined as the number of units kept, and the remaining ones (n  k)
are cancelled, it must hold that vi,k+1 < pi,k+1 (otherwise the (k + 1)th unit would not be
cancelled, contradicting the definition).
The second inequality is given by vi,k+1  pi,nk and is less obvious. To see why this
always holds, we need an observation about how greedy allocation works. Recall that n
is the number of units pre-allocated by the greedy allocation policy. Therefore, each of
the active marginal values, vi,1 , . . . , vi,n , were at some point t  [ai , di ] among the top S(t)
highest marginal values. Consequently, the lowest marginal value of the ones pre-allocated,
vi,n , must be greater than the marginal payment of at least one unit (otherwise it could
not have won the unit). Since the marginal payments are sorted in an increasing order,
it must therefore hold that vi,n  pi,1 . Similarly, for the next-lowest value, it must hold
that vi,n1  pi,2 , and so on. In general we can write vi,nj+1  pi,j , j  {1, n}. If we set
j = n  k, we get vi,k+1  pi,nk .
Therefore, in order for the greedy policy to allocate n units and for the mechanism to
subsequently cancel the units from positions k + 1 to n (assuming k + 1 < n, otherwise
no cancelling will take place on departure of agent i), the following inequalities must be
satisfied:
(
vi,k+1 < pi,k+1
(5)
vi,k+1  pi,nk
Given this, we now show that k  n/2 by contradiction. Suppose that k = n/2  1,
i.e., strictly more than n/2 are cancelled. Then the above conditions become:
(
vi,n/2 < pi,n/2
(6)
vi,n/2  pi,nn/2+1
To show the contradiction, we need to consider separately the cases where n is even and
where n is odd. If n is even, then we have n = n/2 + n/2, and the above system
becomes:
(
vi,n/2 < pi,n/2
(7)
vi,n/2  pi,n/2+1
This implies pi,n/2+1 < pi,n/2 , but since the marginal price vector pi is weakly increasing
by definition, this leads to a contradiction. For the case where n is odd, we have that
n = n/2 + n/2  1, and the conditions become:
(
vi,n/2 < pi,n/2
(8)
vi,n/2  pi,n/2
Clearly, both equations cannot be satisfied simultaneously, leading to a contradiction.
Note that any value of k < n/2 would lead to such a contradiction due to pi being
increasing, hence we necessarily have that k  n/2, completing the proof.
To complete our analysis, we show that this bound is tight, i.e., that there exist settings
in which half of the units allocated to an agent are cancelled.
199

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Lemma 5. There exist settings in which the mechanism with on-departure cancellation
cancels the allocation of n/2 units, or no more than n/2 units are kept, on departure of
an agent i, where n is the number of pre-allocated units.
Proof. The proof for this is done by constructing such a worst-case example. Consider a
single agent, A, who is in the market for n time periods, and has a demand for n units, where
n is even. The first n/2 marginal valuations are equal to 4, and the remaining ones are 2. For
example, for n = 8, the marginal valuation vector becomes vA = h4, 4, 4, 4, 2, 2, 2, 2i. Similar
to the proof of Theorem 3, this agent is faced, in each time step, by a different, single cursory
agent, which participates only in that time step. The valuations of the first n/2 cursory
agents in the sequence is given by vi = h3i, and the second half of the agents has vi = h1i.
Thus, for n = 8, the marginal payment of agent A would be pA = h1, 1, 1, 1, 3, 3, 3, 3i. In
such a setting, the mechanism with on-departure cancellation would pre-allocate all units
to agent A (since vA,k = 4 > vk,1 = 3 for k  n/2 and vA,k = 2 > vk,1 = 1 for k > n/2).
However, on departure of agent A, exactly half of the units allocated are cancelled (since
vA,k = 2 < pA,k = 3 for k > n/2).
Finally, we unify the results from Lemmas 4 and 5 in the following theorem.
Theorem 5. In a setting with on-departure cancellation and non-increasing marginal values, for any number of units and agents present, the worst case cancellation-ratio for the
max = 1 .
number of units allocated to an agent i is RC
2
Proof. Lemma 4 shows that, regardless of set-up, no more than half of the units allocated
max  1 , regardless of the setting
to any agent can be cancelled on its departure, thus RC
2
(i.e., the possible input types of the agents). Lemma 5 shows there exist settings where the
max = 1 , completing the proof.
cancellation ratio is exactly RC
2
Note that in practice and for smaller settings, significantly fewer than half of the units
are cancelled. The worst case cancellation ratio 1/2 allocations occurs only in a very specifically constructed example, and, as shown in the experimental analysis, for most realistic
distributions in our application domain, the actual performance is much better.
5.2.2 Competitive Bound on Allocative Efficiency
The previous section discusses the cancellation problem from the perspective of single
agents, not the whole market. In this section, we show that, in the case that agents have
weakly decreasing marginal values, the allocation returned by the on-departure cancellation
mechanism is 2-competitive with the optimal offline allocation. This result means that the
multi-unit demand case with on-departure cancellation is no worse in terms of worst-case
competitive bound than the single-unit demand problem discussed by Hajiaghayi et al.
(2005), and Parkes (2007), despite the fact that for a single unit demand there is no need
for cancellation to ensure incentive compatibility. Formally, we can state this through the
following theorem:
Theorem 6. The mechanism with on-departure cancellation is 2-competitive with the optimal offline allocation, for a setting with non-increasing marginal values.
200

fiAn Online Mechanism for Multi-Unit Demand

Proof. In order to establish a competitive bound with the optimal offline allocation, we use
a charging argument similar to that of Hajiaghayi et al. (2005).5 The basic idea is to
charge (or match) all the marginal value units of each agent that are allocated in the
offline case with another, higher-valued unit that is allocated both offline and online. This
is either the unit itself, or the higher value unit that causes it not to be allocated in the
online market. Formally, consider all units vi,p (belonging to some agent i in position p)
which are allocated both in the offline and online case. If each such unit vi,p can be charged
at most twice, once to itself, and once to a lower valued unit allocated offline but not online,
then it follows that the worst-case social welfare ratio between the the online vs. offline
allocation cannot drop below 1:2.
Now, for agents with single-unit demand (such as the case discussed by Hajiaghayi et al.,
2005), it is easy to see this property always holds, because each unit vi,p can be allocated
online at most once, thus it can displace at most one other unit vj,q . Crucially, no units are
cancelled. In a multi-unit demand setting, the argument becomes more involved, because
each unit vi,p (allocated both online and offline) can affect the online market in several ways:
 It can displace another unit vj,q that would be allocated offline, where by displace
we mean specifically that unit vj,q is never pre-allocated online (hence cancellation
does not apply to it).
 It can cause the cancellation of another unit vj,q . In this second case, unit vj,q is
pre-allocated, but its allocation is cancelled due to the presence of unit vi,p in the
market (meaning that its pre-allocation would not have been cancelled on departure
of agent j, if unit vi,p were not present).
The main issue that remains to be shown is that unit vi,p can only displace or cause
the cancellation of at most one other unit that would be allocated offline. Thus, it cannot
displace two or more other units that are allocated offline, but are not allocated online, due
to the presence of unit vi,p .
We show this by contradiction. Formally, suppose there are three units: vi,p , vj,q and
vk,r all allocated in the offline case (with vj,q < vi,p and vk,r < vi,p ). Unit vi,p is allocated in
the online case (i.e., pre-allocated and not cancelled). Units vj,q and vk,r are not allocated
in the online case if unit vi,p is present, but are allocated online if unit vi,p is not present.
Given this set-up, there are three possible cases:
1. Neither units vj,q or vk,r are pre-allocated online when unit vi,p is present (hence, there
is no cancellation of either vj,q or vk,r ).
2. Unit vj,q is never pre-allocated online, but unit vk,r is pre-allocated and its allocation
is cancelled later (i.e., on departure of agent k from the market), if unit vi,p is present.
3. Both units vj,q and vk,r are pre-allocated, but their pre-allocations are cancelled on
the departure from the market agents j, respectively k, if unit vi,p is present.
5. Here the term charging does not refer to electricity charging, but represents the name of a proof device
used in online mechanism design.

201

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

In all cases, if unit vi,p is not present, both units vj,q and vk,r are pre-allocated and not cancelled in the online case. In order to complete the proof we need to show, by contradiction,
that each of these three cases could not occur.
Case 1 is very similar to the case of single unit demand discussed by Hajiaghayi et al.
(2005), as no cancellation occurs for these units. It is relatively straightforward to see this
cannot occur, as any unit vi,p can be pre-allocated at most once (at some time t), thus it
can displace at most one other unit that would have been allocated otherwise. This can be
either the unit allocated online at time time t, if this unit is allocated online later on, the
unit which is, in turn, displaced by it.
Case 2: Suppose that vj,q (belonging to some agent j active between [aj , dj ]) is the
unit assumed not pre-allocated at all when vi,p is present, and unit vk,r is the unit that
is allocated and then cancelled. There are two subcases to consider here, which require
separate discussion.
Case 2A: First, consider that vj,q > vk,r . In this case, agent k has a lower marginal
value than that of agent j, but its value vk,r is still pre-allocated by our essentially greedy
allocation policy, while vj,q is not. This means that agent k must be more patient than
agent j, hence dj < dk , otherwise vj,q would have been pre-allocated instead.
Now, if we denote by pk the payment vector of agent k, defined as in Section 4.2. For
unit vk,r to be cancelled it must hold that vk,r < pk,r . Now, denote by pk<i> the vector
of marginal payments of agent k when agent i is not present in the market, and recall our
assumption that now the value vj,q is allocated. Thus, we have:
pk<i> = incr(pk \{vi,p }  {vj,q })
where incr is the operator that orders elements in increasing order. Since vj,q > vk,r , it
<i>
follows that vk,r
< pk,r , thus the allocation of unit vk,r would still be cancelled, even
without unit vi,p .
Case 2B: For the second subcase, we consider vj,q  vk,r , i.e., the value of the unit
that is displaced by agent i is lower than that the one pre-allocated and cancelled. First
note that, for this case to occur, unit vj,q but be allocated online within [ak , dk ], the active
window of agent k. This is an obvious condition: if agent j is allocated online outside this
window (and is displaced there when agent i is in the market, but the displacement occurs
outside [ak , dk ]), then units vj,q or vi,p cannot influence the cancellation of unit vk,r (because
each unit can be pre-allocated at most once, and in this case the pre-allocation of vi,p would
happen outside [ak , dk ]).
As previously, recall the condition for unit vk,r < pk,r , required for unit vk,r to be
cancelled. Note that this means there are at least k units between [ak , dk ] that are higher in
value than unit vk,r , and thus, in an offline allocation (which is our benchmark) would need
to take priority over it. In our setting, one of these units is vi,p . But even after removing
vi,p from it, vector pk<i> = incr(pk \{vi,p }  {vj,q }) must contain at least k  1 values higher
than vk,r . In an offline allocation without unit vi,p , these k  1 values must be given priority,
together with at least unit vk,r . However, this means that unit vj,q cannot be allocated
offline between [ak , dk ], being lower in value than vk,r . This gives a contradiction with
our initial assumption that both units vi,j and vk,r are allocated offline (as well as online)
without unit vi,p present.
202

fiAn Online Mechanism for Multi-Unit Demand

To explain this intuitively, what this means is that a unit vi,p can cause both the displacement (non-allocation) of a unit vj,q and the cancellation of another one vk,r , but its
not possible that both of these units were high enough value to be allocated in the offline
case as well. Thus, at most one other offline-allocated unit is not allocated online because
of the presence of unit vi,p in the market.
Case 3: In this final case, both units would need to be pre-allocated and cancelled, in
the absence of value vi,p . The contradiction for this case can be shown similarly to Case 2A
from above. Considering the marginal price vectors of agents j and k without vi,p in the
market:
pj<i> = incr(pj \{vi,p }  {vk,r })
pk<i> = incr(pk \{vi,p }  {vj,q })
It is easy to see that, regardless whether the value vj,q or vk,r is lower, for that value
the cancellation would still occur on departure in a market without agent i, leading to a
contradiction.
To summarise, we have now exhaustively shown that the contradiction holds in all
possible cases. Thus, a unit vi,p allocated both online and offline can at most displace
(or lead to the cancellation of) one other unit allocated offline. Thus, at most two units
allocated offline can be charged to any unit allocated online, completing the proof.

6. Computational Aspects
In this section, we consider the implications of implementing the mechanisms in practice, including the computational complexity of our algorithms. We will examine both on-departure
and immediate cancellation separately, as they differ fundamentally in their complexity.
6.1 Implementing On-Departure Cancellation
Algorithm 1 briefly outlines an implementation of our mechanism with on-departure cancellation (OD). Here, we assume that the first time step is denoted by t0 , the second by
t1 = t0 + 1, and so on. For simplicity, we use I throughout this section to denote the
full set of all agents arriving over all time points, but we note that no algorithm explicitly
uses information about future arrivals. Initially, the algorithm sets the endowments of all
agents to 0 (line 2), as no units have been allocated. Then, for every time step t, the
algorithm first pre-allocates units using the greedy allocation policy (line 4). This can be
done in O(N rmax ) using the well known linear-time selection algorithm described by Blum,
Floyd, Pratt, Rivest, and Tarjan (1973), where N = |I| is the total number of agents and
rmax = maxiI ri is the maximum consumption rate.
Next, the algorithm computes the marginal payments up to time step t by rerunning
the market without each active agent (line 6). In rerunning the market for a particular
hti
agent i, it is important to note that only the pre-allocations have an effect on pi  any
cancellations are irrelevant, because they do not affect the future development of the market.
Therefore, it is only necessary to compute the greedy allocation with each agent i removed,
which has a total run-time, for all active agents, in O(N 2  rmax ) (assuming results from
hti
previous time steps are re-used). Updating pi with the new marginal payments can be
203

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Algorithm 1 Mechanism with On-Departure Cancellation (OD).
1: procedure OnDepartureMechanism(I , S)
ht i
2:
kht0 i  h0, 0, . . . , 0i
 Initial endowments, ki 0 = 0, for all i  I
3:
for all t  {t0 , t1 , . . .} do
4:
kht+1i  GreedyAllocation(I , S(t), khti )
 Run greedy allocation

5:
for all i  {j  I|aj  t  dj  t} do
 Iterate through active agents
hti
6:
update pi using i
 Run market without i
7:
if di = t then
 If agent is departing
ht+1i hti
8:
k i , pi  k i
, pi
 Final pre-allocation and marginal payments
9:
while vi,ki < pi,ki do
10:
ki  ki  1
 Cancel units while necessary
11:
end while P
i
pi,k
 Final payment for agent i
12:
xi (i |ki )  kk=1
13:
end if
14:
end for
15:
end for
16: end procedure

done using a simple insertion algorithm, and, noting that only the lowest |vi | payments for
each agent i need to be kept, this can be done, for all agents, in O(N  rmax  vmax ), where
vmax is the maximum length of any agents valuation vector.
Finally, on departure, in lines 811, any units that have a lower valuation than their
corresponding marginal payments are cancelled, and the final payment is calculated in
line 12. This can be done in O(N  vmax ) by simply iterating through the values.
In summary, the time complexity of our algorithm for the OD mechanism is O(N 2 rmax +
N  rmax  vmax + N  vmax ) for each time step. If rmax and vmax are assumed to be constant6 ,
this simplifies to O(N 2 ). Generally, this means that the algorithm can be executed quickly,
even for large numbers of agents.
6.2 Implementing Immediate Cancellation
Next, we consider our mechanism with immediate cancellation (IM), as shown in Algorithm 2. The key difference to the OD mechanism here is that units are potentially cancelled
at every time step that an agent is active (lines 79), rather than only on departure. This
small modification has a significant impact on the computational tractability of the mechanism. Unlike the previous mechanism, when computing the marginal payments in line 6, the
cancellations of other agents now affect the payments. This feature was already highlighted
in the example in Section 4.3.1, where the cancellation of the second unit pre-allocated to
agent 1 causes a change in the marginal payments to agent 3. More generally, cancellations
have an immediate effect on the endowments of agents and this directly affects the active
marginal valuations V hti in subsequent time steps.
6. This is reasonable, as they are limited by technological constraints in practice. In particular, rmax is
limited by battery and infrastructure constraints, while vmax is related to the petrol savings achievable
by an EV (as will be detailed in Section 7.3.3).

204

fiAn Online Mechanism for Multi-Unit Demand

Algorithm 2 Mechanism with Immediate Cancellation (IM).
1: procedure ImmediateMechanism(I , S)
ht i
2:
kht0 i  h0, 0, . . . , 0i
 Initial endowments, ki 0 = 0, for all i  I
3:
for all t  {t0 , t1 , . . .} do
4:
kht+1i  GreedyAllocation(I , S(t), khti )
 Run greedy allocation

5:
for all i  {j  I|aj  t  dj  t} do
 Iterate through active agents
hti
6:
update pi using i
 Run market without i
hti
7:
while vi,kht+1i < p ht+1i do
i

8:
9:
10:
11:
12:
13:
14:
15:
16:

ht+1i
ki

i,ki
ht+1i
ki
1


end while
if di = t then
ht+1i hti
k i , pi  k i
,p
P ii
xi (i |ki )  kk=1
pi,k
end if
end for
end for
end procedure

 Cancel units immediately
 If agent is departing
 Final allocation and marginal payments
 Final payment for agent i

Now, in order to determine cancellations when rerunning the market without each active
agent i, it is necessary to again compute the marginal payments for all agents in those
markets (effectively executing the full algorithm again with i ). Clearly, this leads to a
recursion that potentially sees all possible subsets of agents evaluated. In the worst case,
therefore, the cancellation decisions need to be executed for every agent in every possible
subset of I, or N  2(N 1) times.7 Simplifying and again assuming vmax and rmax to be
constant, this leads to a runtime complexity of O(N  2N ).
A runtime that is exponential in the number of agents is clearly a problem when applying
the mechanism in realistic settings with more than a handful of agents. However, to tackle
such problems, it is possible to use a technique akin to branch-and-bound that enters the
recursion in line 6 only when necessary. We present this in the following section.
6.3 Speeding Up Immediate Cancellation Using Bounds
To obtain a faster algorithm for the IM mechanism, instead of calculating all marginal
hti
payments pi at every time step, we find and iteratively refine lower and upper bounds
for these payments. The intuition behind this approach is to choose initial bounds that
are easily calculated without resorting to recursion. If an agents reported valuation for a
pre-allocated unit, vi,k , lies outside the bounds, we can immediately determine whether the
unit is cancelled or not. On the other hand, if vi,k lies between the bounds, we further refine
7. In practice, this recursion only occurs over the set of agents that are active at the same time as the
agent i that is being evaluated, as previous decisions are not affected by agent is presence and similarly
agents arriving after di have no affect on i. This means that settings with large numbers of agents may
still be tractable if there is little overlap between the active agents, but for the sake of the analysis in
this section, we assume the worst case, that all N agents are active concurrently.

205

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

them by iteratively calculating the actual marginal payments for some of the agents active
time steps until the cancellation decision is unambiguous.
ht,si
ht,si
In more detail, we use pi
and pi
to denote the lower and upper bounds, respechti
tively, for pi . Here, s indicates the level of refinement, or up to which time step the actual
marginal payments have been calculated, with ai  1  s  t. Analogous to the actual
hti
ht,si
ht,si
pi vector, pi
and pi
are vectors in increasing order, and they represent bounds
hti
ht,si
hti
ht,si
for pi , such that pi,k  pi,k  pi,k , for all k and s. As the level of refinement, s, is
hti

increased, the bounds become tighter, eventually converging to pi,k . In the following, we
describe in detail how to calculate the initial bounds (with s = ai  1, indicating that no
actual payments have been calculated yet):
ht,a 1i

 In order to calculate the initial lower bounds, pi i , we rerun the market without
i from ai to t using only the greedy allocation policy without cancellations. The
marginal payments in this market (as described in Section 4.2) are then used as lower
hti
bounds. These payments are not necessarily the same as the actual payments pi , as
there may be cancellations in the latter, which cause the active marginal valuations
to change in subsequent time steps. However, it can be seen easily that they indeed
represent a lower bound. Specifically, any cancellations either have no influence or
cause an increase in one or more elements in the externality vector E hti (since agents
have a lower endowment after cancellations and therefore an equal or higher value for
obtaining additional units).
ht,a 1i

 To calculate the initial upper bounds, pi i , we now consider the actual market including agent i from time step ai to t, calculate the externality that agent i
would impose on others for winning each available unit throughout this time interval and then use these to derive upper bounds for the payments. More formally, we
hti
define a new multiset set of valuations, Vi0 , which is derived by simply removing
all elements corresponding to agent i from V hti and padding it with zeroes, if necessary, until its size is at least S(t). Then, we proceed in a similar manner as in
Section 4.2 by defining the externality agent i would impose on others in time step
hti
hti
t as Ei = minhri i (maxhS(t)i Vi0 ). Given this, the final vector of upper bounds is
S
ht,a 1i
ht i
then pi i
= incr( tt =ai Ei ).

Unlike the actual marginal payments, these upper bounds now include the effect agent
i has on the market, as it may be allocated units that would have been allocated to
others, or, through its presence, cause the cancellation of other units, which, in turn,
affect the active valuations of other agents in subsequent time steps. However, as its
only effect is to reduce the supply available to other agents, including agent i in the
ht,a 1i
market can only increase the active valuations of other agents, and therefore pi i
hti
is an upper bound for pi .

Given these bounds, we can now quickly test if an agents marginal valuation vi,k for
ht,a 1i
a pre-allocated unit falls outside these bounds. If vi,k < pi,k i , then the unit is canht,ai 1i

celled immediately, while if vi,k  pi,k

, it is definitely not cancelled. However, if

206

fiAn Online Mechanism for Multi-Unit Demand

Algorithm 3 Mechanism with Immediate Cancellation (IM) and Bounds.
1: procedure BoundedImmediateMechanism(I , S)
ht i
2:
kht0 i  h0, 0, . . . , 0i
 Initial endowments, ki 0 = 0, for all i  I
3:
for all i  I do
4:
si  ai  1
 Initial refinement of bounds
5:
end for
6:
for all t  {t0 , t1 , . . .} do
7:
kht+1i  GreedyAllocation(I , S(t), khti )
 Run greedy allocation
8:
for all i  {j  I|aj  t  dj  t} do
 Iterate through active agents
ht,s i
ht,s i
9:
Calculate pi i and pi i
 Add initial bounds for time t
10:
repeat
ht,si i
then
11:
if vi,kht+1i < p ht+1i
i

ht+1i
ki

12:



else if vi,kht+1i

13:

i

15:
16:
17:

i

19:
20:
21:
22:
23:
24:
25:
26:
27:

 Unit definitely cancelled

i,ki

 Refine bounds

i,ki

if di = t then
 If agent is departing
ht+1i
ki  ki
 Final allocation
ht,si i
ht,si i
while x  {1, 2, . . . , ki }, pi,x
6= pi,x
do
si  si + 1
 Refine for final payments
end while P
ht,s i
i
 Final payment for agent i
pi,k i
xi (i |ki )  kk=1
end if
end for
end for
end procedure

ht,ai 1i

pi,k

1
ht,si i
< p ht+1i
then

si  si + 1
ht,s i
ht,s i
Update pi i and pi i
end if
ht,si i
until vi,kht+1i  p ht+1i

14:

18:

i,ki
ht+1i
ki

ht,ai 1i

 vi,k < pi,k

, then the bounds are ambiguous and need to be further refined.
ht,si

ht,si

We obtain these refined bounds pi
and pi
by computing the actual marginal payments up to some specified time s, after which the bounds are calculated as above. This
effectively replaces some of the initial bounds with actual marginal payments, resulting in
ht,si
hti
ht,si
more accurate overall bounds. Eventually, when s = t, we have pi
= pi = pi
.
S
ht,si
ht i
More formally, the refined lower bounds are calculated as pi
= incr(( st =ai Ei ) 
S
ht i
hti
( tt =ai +1 Ei )), where Ei is the externality vector in the market without i, using immehti

diate cancellations (as used for actual payments), while Ei is the corresponding vector in
the market without i and without any cancellations. Similarly, the refined upper bounds
S
S
ht,si
ht i
ht i
hti
are calculated as pi
= incr(( st =ai Ei )  ( tt =ai +1 Ei )), where Ei
is as defined
above.
207

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Full details for the IM mechanism using bounds are given in Algorithm 3. This keeps
track of the level of refinement for the bounds of each agent i (as si , which is initialised to
ai  1 in line 4). Then, instead of updating the actual payments, lines 1017 repeatedly
compare the marginal valuation of the last unit that was pre-allocated (vi,kht+1i ) to the
i
current upper and lower bounds, refining them as necessary. Note here, that previous
calculations of the bounds can be reused, as the algorithm checks them iteratively, either
increasing t (when the next time step is calculated) or si by 1 (when the bounds are refined).
In each case, this means that only the active valuations of one additional time step have to
be added to the existing bounds. This loop repeats until the statement in line 17 becomes
true, which captures both cases when the last pre-allocated unit is definitely not cancelled
(in which case any other pre-allocated units will also not be cancelled, as their marginal
valuations will be at least as high, while their respective payments will be equal or lower),
or when all pre-allocated units in this time step are cancelled.
Finally, when an agent departs, its final allocation and payments are calculated in
lines 1824. Here, it is now important to calculate the actual marginal payments for all
ki allocated units. This is achieved by further refining the bounds until the first ki upper
and lower bounds are equal. While this can incur further computational effort, it is not
hti
equivalent to computing the complete pi vector as in Algorithm 2. The payments only
need to be calculated for the units that are actually allocated on departure, the upper and
lower bounds may be equal without needing to compute actual payments, and importantly,
they are only required for the full set of agents and not recursively for all subsets of agents.
In practice, this algorithm with bounds significantly reduces the computational runtime of the mechanism (typically by 99% or more throughout the experiments conducted
in Section 7), as it often avoids re-running the market with all possible subsets of agents.
However, it is important to note that the worst-case run-time is still equivalent to Algorithm 2, i.e., O(N  2N ), or exponential in the number of agents. In the best case, when no
recursion is necessary, the run-time reduces to O(N 2 ).

7. Experimental Evaluation
In this section, we quantify the performance of our mechanisms, as compared to a number of
benchmarks, by applying them to a range of settings. While we investigated the theoretical
performance bounds of our mechanisms in Section 5, the purpose of this section is to evaluate
their performance in realistic settings.
Specifically, in Section 7.2, we consider a general setting that is easily reproducible and
show how our mechanisms perform as we vary both supply and demand for a good. Then,
in Section 7.3, we turn to the PHEV domain. For this, we first show how we can derive an
agents preferences based on the vehicle owners driving behaviour. Then, we use real data
collected during the first large-scale trial of pure electric vehicles (EVs) in the UK to show
that the same trends continue to hold in a realistic application setting. Furthermore, we look
at how the gradual introduction of fast-charging PHEVs would affect a neighbourhood with
limited electricity supply, both in terms of social welfare (which translates to the overall fuel
savings within the neighbourhood) and the financial savings of individuals. Throughout the
experiments, we also consider a simpler greedy allocation mechanism without cancellation
and quantify the potential benefits an agent would be able to achieve by misreporting in such
208

fiAn Online Mechanism for Multi-Unit Demand

a mechanism. This demonstrates whether there is actually scope for strategic misreporting
in realistic settings and whether cancellation is needed in practice.
Before we consider the two specific settings, we briefly outline the common parameters
and benchmarks used in all experiments.
7.1 Experimental Setup
To evaluate our mechanisms, we simulate different settings where a number of agents compete for a limited supply of a good that is allocated on an hourly basis over a 24-hour
period. In order to test scenarios with varying supply and demand, we sample these agents
randomly from fixed probability distributions and use a range of supply functions (these
are outlined in more detail in Sections 7.2 and 7.3). In order to ensure statistical significance of our results, we re-sample the agents 1,000 times for each setting, and we plot 95%
confidence intervals throughout this section.
In addition to the two mechanisms proposed in this paper, with immediate cancellation
(IM) and on-departure cancellation (OD), we evaluate a number of benchmark mechanisms:
 Fixed is a fixed-price mechanism that allocates units to those agents that have a
valuation of at least a given constant p, and the price they pay for each unit is p.
When demand exceeds supply, each unit is allocated to an agent chosen uniformly at
random from the set of all agents with a sufficiently high valuation. Here, an agent
may receive multiple units, up to its maximum consumption rate, ri . This mechanism
is DSIC and so it constitutes a direct comparison to our mechanisms. However, to
optimise the performance of the fixed-price mechanism, p must be carefully chosen.
Thus, for each given setting, we test all possible values (in steps of 0.01) and select the
p that achieves the highest average efficiency (over 1,000 trials). Thus, when showing
the results of Fixed, this constitutes an upper bound of what could be achieved with
this mechanism.
 Random is a special case of Fixed, with p = 0. Thus, using this baseline benchmark,
units are allocated randomly and agents do not pay anything.
 Greedy is a simple greedy allocation policy, as described in Section 4. Payments
are calculated using pi prices (as for IM and OD), but there are no cancellations.
Thus, this mechanism is not truthful, but it constitutes an interesting comparison to
our mechanisms, as it allows us to quantify the loss of efficiency that is caused by
cancellations, as well as the potential benefits an agents has when misreporting in the
absence of cancellations.
 Heuristic allocates units such that a weighted combination of an agents valuation
and urgency (proximity to its departure time) is maximised. Here, an   [0, 1]
parameter denotes the importance of the urgency, such that  = 1 corresponds to the
well-known earliest-deadline-first heuristic in scheduling (Pinedo, 2008), while  = 0
indicates that units are always allocated to the agent with the highest valuation. This
is not a truthful mechanism and we do not impose payments here, as its primary
purpose is as a benchmark for our approach. Again, we always select the best  by
testing all values in steps of 0.01 for each setting.
209

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

 Optimal assumes complete knowledge of all future arrivals and supply, then allocates
units to agents to maximise the overall allocative efficiency. Clearly, this mechanism
is not possible because it assumes knowledge of the future and it is also not truthful
(again we impose no payments), but it serves as an upper bound for the efficiency
that could be achieved.
7.2 General Allocation Setting
First, we consider a general synthetic setting, in which we generate agents and the supply
function from simple distributions. The main reason for examining such a scenario before
turning to a more realistic setup is to generate results that are easily reproducible and that
are not tied to a specific application domain. In the following, we outline the distributions
from which we sample the supply and agents (Section 7.2.1), and then we discuss our results
(Section 7.2.2).
7.2.1 Synthetic Setup
In this setting, we generate the supply function S(t) by randomly drawing from the discrete
uniform distribution on {1, 2, 3, . . . , s}, where we vary s in our experiments to represent
different amounts of a good that is being produced. For each agent i, we sample its arrival
time ai from the discrete uniform distribution on {0, 1, 2, . . . , 23} and its departure time
from {ai , ai + 1, . . . , 23}. We sample its maximum consumption rate ri from {1, 2, 3, 4, 5},
and finally, we generate vi by first selecting a number of required units uniformly at random from {1, 2, 3, . . . , 20}. Then, the first valuation vi,1 is sampled from an exponential
distribution with rate 1, and the remaining valuations are drawn uniformly at random from
the continuous interval [0, vi,1 ] (ordered appropriately to ensure non-increasing marginal
valuations).
7.2.2 Synthetic Results
In Figure 3, we examine the allocative efficiency of the mechanisms as we increase the number of agents competing for a limited supply of electricity. The figure shows the allocative
efficiency both of a setting with low supply (left), where s = 1, i.e., one unit is available per
time step, and of a setting with high supply (right), where s = 20, i.e., up to 20 units are
available per time step. We choose these two extreme settings to show the full spectrum of
potential supply scenarios (and focus on supply settings based on real data in Section 7.3).
Note that due to its run-time complexity, we plot IM only in the smaller setting with one
unit of supply. When supply is very high (s = 20), each agent is typically allocated a large
hti
number of units, causing IM to require more frequent refinements of the bounds for the pi
vectors and thus leading to a computational bottleneck. As the non-truthful Heuristic approach consistently achieves around 99% of the Optimal with full information when s = 1,
we do not plot it for readability, and we also use it as an approximation of the Optimal
when s = 20 (where Optimal also becomes computationally infeasible).
Several trends emerge in these results. First, when s = 1, the simple but not truthful
Greedy approach performs very well (around 99% of the Optimal). Next, we note that both
our truthful mechanisms, IM and OD also perform well, achieving around 95% and 96% of the
210

fiAn Online Mechanism for Multi-Unit Demand

Allocative Efficiency (% of Optimal)

Approximate Allocative Efficiency (% of Heuristic)

100%

100%

90%

90%

80%

80%
Greedy
OD
IM
Fixed
Random

70%
60%
50%

70%
60%
50%

40%

40%

30%

30%

20%

20%
0

25

50 75 100 125 150 175 200
Number of Agents

0

25

50 75 100 125 150 175 200
Number of Agents

Figure 3: Allocative efficiency in synthetic setting (low supply, with s = 1, on the left, and
high supply, with s = 20, on the right).

Optimal, respectively. This is slightly lower than Greedy, which indicates that about a 3
4% loss in efficiency is incurred due to cancellations. The difference in performance between
IM and OD is as expected here, as IM can cancel more units (see Section 5); however, despite
the unfavourable worst-case performance of IM, it is surprising that the difference is not
significant in practice. Overall, the results are promising, indicating that our mechanisms
work well in these settings, because the specific conditions that cause cancellations (i.e.,
when the valuations of allocated units effectively cross over with the marginal payments)
do not occur frequently in practice.
The fixed price mechanism, Fixed, performs significantly worse than our proposed mechanisms, achieving only 81%  83% of the Optimal. This is because, in order to remain
truthful, the mechanism sets a single fixed price that does not respond dynamically to
changes in supply and demand from time step to time step. This also explains why the
mechanism performs worst when there is some, but not much, competition, e.g., around
30 agents. Here, the fixed price starts to rise, to ensure agents with higher valuations are
allocated first, but there is still considerable variance in the valuations at each time step,
sometimes leaving high-value agents unallocated, while other times units are not allocated
at all. In contrast to this, both IM and OD always allocate all available units to the agents
with the highest valuations. Furthermore, it should be noted that Fixed, unlike IM and OD,
assumes a priori knowledge of the distributions from which agents are drawn. This may not
always be available in practice, which can further decrease its performance.
Finally, the Random mechanism performs worst of all, which is not surprising, as it uses
no information about the agents valuations at all. However, its poor performance demon211

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

10%

Proportion of PreAllocated Units Cancelled
10%
OD
IM

OD

5%

5%

0%

0%
0

50

100

150

200

Number of Agents

0

50

100

150

200

Number of Agents

Figure 4: Proportion of initially allocated units cancelled (s = 1 on the left, and s = 20 on
the right).

strates clearly the potential perils of using poorly designed non-truthful mechanisms, where
strategically misreported valuations may have no relation to the agents actual valuations.
In the setting with more abundant supply, when s = 20, the same broad trends are
observed. The OD mechanism still achieves around 97% of the near-optimal Heuristic and
slightly less than Greedy, while the Fixed and Random perform significantly worse. However,
the gap in performance is smaller this time, as there is less competition and often there
are sufficient units to satisfy most of the agents. In such settings, the benefit of always
allocating to the agents with the highest valuations is generally lower. Note that while IM
was infeasible in these settings due to its high run-time complexity, OD took, on average,
less than 100ms to execute all 24 time steps in even the most complex settings with s = 20
and 200 agents.
Next, to further illustrate that actual cancellations by the IM and OD mechanisms are far
from the worst-case bounds established in Section 5, Figure 4 shows the average proportion
of pre-allocated units cancelled. This is generally low, ranging from 0% to 7%. As expected,
the OD mechanism cancels fewer units than the IM mechanism. Furthermore, there is a
general trend to cancel few units when competition is low (as there are usually sufficient
hti
units to satisfy all agents, leading to mostly 0 valuations in the pi vectors). Cancellations
then peak for medium levels of competition, after which they start to drop again slightly.
hti
This peak can be explained by the large variations in the pi vectors in these settings
and also because agents are generally allocated more units than in settings with more
competition (leading similarly to a higher variation in the valuations of an agents allocated
units).
In Figure 5, we next consider the potential benefits of misreporting when no cancellations
are used (as in the Greedy mechanism). We measure this by computing the utility of each
agent had on-departure cancellations been used and compare this to the actual utility gained
in the Greedy mechanism. This constitutes the best deviation a single agent could have
achieved with perfect hindsight of the actual pi prices. Here we plot the proportion of
cases where an agent can achieve any gain from misreporting (light blue), the conditional
212

fiAn Online Mechanism for Multi-Unit Demand

Potential Gain in Utility When Misreporting
25%

25%

20%

20%

15%

15%

10%

10%

5%

5%

0%

Proportion of Gains
Conditional Utility Increase
Overall Utility Increase

0%
0

25

50

75 100 125 150 175 200
Number of Agents

0

25

50

75 100 125 150 175 200
Number of Agents

Figure 5: Potential gains when misreporting in the Greedy mechanism (s = 1 on the left,
and s = 20 on the right).

proportional increase in utility when a gain from misreporting exists (dark red), and the
product of the two, i.e., the overall average proportional increase in utility, including cases
where there is no gain (light red).
The results indicate that without cancellations, there are often cases where an agent can
benefit from misreporting  in up to 67% of all cases when s = 1 and up to 20% of cases
when s = 20. This provides a clear motivation for using incentive compatible mechanisms
in these settings. However, although individual gains can lead to an average increase in
utility of up to 1520%, when considering the overall average utility increase (including
cases where agents do not benefit), this is only up to 12% and significantly less in many
specific settings. This offers some promise for settings where cancellations are infeasible,
for example because immediate cancellations are not computationally feasible in very large
settings, or because on-departure cancellations cannot practically be implemented. For
low expected gains of 12% or less, an agent may not wish to exert additional efforts to
strategise. Furthermore, these gains represents an upper bound of what can be achieved
with perfect foresight of the prices, which is likely to be unavailable in practice. We also
note that the expected gain from misreporting fluctuates significantly, depending on the
specific setting  similar to the cancellations, this fluctuation is caused by variations in the
pi vectors and also in the valuations of the allocated units.
To conclude this section, Figure 6 further explores the performance gap between our
proposed mechanisms and the benchmarks as supply is increased. Here, we fix the number
of agents at 50 and then vary the maximum number of available units of the good per
time step, s, from 1 to 70. Due to the complexity of this setting, we again omit Optimal
and IM from our analysis. It is clear here that the relative benefit the OD mechanism has
over the other truthful benchmarks decreases as supply is increased. This is not surprising,
as eventually all agents can be completely satisfied, even in a random allocation policy.
213

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Approximate Allocative Efficiency (% of Heuristic)
100%
90%
80%
Greedy
OD
Fixed
Random

70%
60%
50%
40%
30%
0

10

20

30
40
Supply (Maximum Units)

50

60

70

Figure 6: Approximate allocative efficiency as the maximum supply per time step (s) is
increased.

However, there is still a significant benefit in using OD up to relatively high supply levels of
around s = 45, and it is never outperformed by the truthful benchmarks, while consistently
performing close to the near-optimal Heuristic (over 99% in some cases) and close to the
Greedy mechanism without cancellations. In terms of potential gains for deviations, similar
trends as discussed previously are observed and so we omit a detailed figure.
So far, we have concentrated on describing the general performance of our mechanisms
in a synthetic, easily reproducible setting. In the following, we apply it to data from a real
EV setting.
7.3 PHEV Setting
In this section, we use data from a real (pure) EV trial to simulate typical charging patterns.8 Doing this allows us to verify that the trends discussed in the previous section
continue to hold in a realistic setting. Furthermore, basing our experiments on actual
PHEV characteristics enables us to quantify the actual utility of drivers in real terms (i.e.,
as a monetary gain or the fuel saved). We will also investigate whether the introduction
of faster charging speeds will lead to any benefits in the settings we consider. Such an
investigation is interesting, because fast chargers are already available for domestic settings
and allow vehicles to charge at twice the normal rate (or faster).9 However, their impact in
our settings is unclear, as they are still constrained by the overall supply of electricity.
In the following, we first present a principled approach for deriving an agents marginal
valuation vector and show that this approach satisfies the non-increasing marginal valuation
assumption (Section 7.3.1). We then describe the real-world data that we use for our
8. Note that, whereas the simulation is based on PHEVs, it uses real-world experimental data from pure
EVs. However, we believe it is reasonable to assume that the charging behaviour would be similar.
9. See, for example, http://www.pod-point.com/ or http://www.charging-solutions.com/.

214

fiAn Online Mechanism for Multi-Unit Demand

experiments (Section 7.3.2), followed by an outline of how this is used to sample PHEVs
(Section 7.3.3). Finally, we discuss our results (Section 7.3.4).
7.3.1 Deriving an Agents Marginal Valuation Vector
An important part of our overall model is a method for computing the marginal valuation
vector, vi , based on real data. To do so, we combine data about the sampled cars actual
journey distances with a principled approach for calculating the expected economic benefit
of charging for PHEVs. In detail, we first derive a probability density function, p(m), from
the data, which describes the probability of the distance travelled to be m miles (described
in Sections 7.3.2 and 7.3.3). Given this distribution, the price of fuel (in /litre), pp , the
internal combustion engine efficiency (in miles/litre), ep , and the efficiency of the electric
engine (in miles/kWh), ee , we can then calculate the expected utility of a certain amount
of charge (in kWh), ce , as follows:
Z 
Z 
pp
pp
 m  p(m)dm 
 (m  ce  ee )  p(m)dm,
(9)
E(u(ce )) =
e
p
ce ee ep
0
where the first term is the expected fuel cost without any charge, and the second term is
the expected cost with a battery charge of ce . Therefore, the utility function represents the
expected savings in terms of real money for a given battery charge (without taking the cost
of the charge into account). Given this, and a unit size (in kWh), se , it is straight-forward
to calculate the marginal valuation of the k th unit as follows:
vk = E(u(k  se ))  E(u((k  1)  se ))

(10)

Recall that, in our model, we assume that valuations are marginally non-increasing. We
now show that, using the above approach, this assumption is automatically satisfied. To do
so, we need to show that Equation 9 is non-decreasing (i.e., the first derivative is positive)
and concave (i.e., the second derivative is negative). The first derivative is given by:
Z 
pp
dE(u(ce ))
=
 ee 
p(m)
(11)
dce
ep
ce ee
The second derivative is given by:
pp
d2 E(u(ce ))
=   ee 2  p(ce  ee )
dce 2
ep

(12)

Clearly, both conditions are satisfied, which means that the valuations are always positive
and marginally non-increasing. In what follows, we describe how we derive the experimental
settings, such as the supply function, the arrival and departure of agents, and the travel
distance probability distributions from a real-world dataset. We also provide examples of
the marginal valuation vectors using this data.
7.3.2 The CABLED Dataset
We base our experiments on data gathered by the CABLED (Coventry And Birmingham
Low Emissions Demonstration) project,10 which is the first large-scale endeavour in the
10. See http://cabled.org.uk/.

215

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

All Cars

Frequency

15 %

Arrivals
Departures

10 %

5%

0%

:
22

:
20

:
18

:
16

:
14

:
12

:
10

:
08

:
06

:
04

:
02

:
00

00

00

00

00

00

00

00

00

00

00

00

00

Time

Figure 7: Distributions of arrival and departure times for all 56 EVs in the CABLED dataset
(assigning equal weight to each EV).

UK to record and study the driving and charging behaviours of EV owners. As part of
this project, 110 EVs were loaned to the public and equipped with GPS and data loggers
to record comprehensive usage information, such as trip durations and distances, home
charging patterns and energy consumption.
From this data, we focus on the period from March to June 2011, for which we were
provided with information from 63 distinct vehicles, with a total of 13,273 journeys. For
each journey, this includes the times when the ignition was turned on and off again, the total
mileage (as derived from GPS readings that were taken every 60 seconds), as well as labels
for the starting and end location, when this was available (such as home or work).
The vehicles in the CABLED trial were charged at various locations  mostly at home,
but also at work. For the purpose of our experiments, we will assume that all charging
of the vehicles takes place at a single location. This is because our work focuses on coordinating the charging of EVs within a specific neighbourhood and considering the effect
of multiple markets for electricity is beyond the scope of this work. When available, we
choose this charging location to be the one labeled home in the data.11 Given this, and
since we are only interested in the arrival and departure times at this charging location, as
well as the consumption patterns between visits to the charging location, we aggregate all
intermediate journeys between the departure from a charging location until the next return
to this location into a single journey.
Aggregating the data in this way and discarding vehicles without a clear charging location results in 4,302 distinct journeys for 56 different EVs, covering a total distance travelled
of close to 72,500 miles. The overall distribution of all recorded arrival and departure times
11. Some vehicles in the dataset lack this, as they were used as shared fleet vehicles for an organisation 
in these cases, we use an appropriate alternative location label, where most of the charging took place,
or discard the vehicle when no suitable label can be identified.

216

fiAn Online Mechanism for Multi-Unit Demand

Frequency

EV 1

EV 2

Arrivals
Departures

30 %

30 %

20 %

20 %

10 %

10 %

0%

0%

Frequency

EV 4

30 %

30 %

20 %

20 %

10 %

10 %

0%

0%

0

:0

20
0

:0

16
0

:0

12
0

:0

08
0

:0

04
0

:0

00

0

:0

20
0

:0

16
0

:0

12
0

:0

08
0

:0

04
0

:0

00

EV 5
Frequency

0

:0

20
0

:0

16
0

:0

12
0

:0

08
0

:0

04
0

:0

00

0

:0

20
0

:0

16
0

:0

12
0

:0

08
0

:0

04
0

:0

00

EV 3

EV 6
60 %

40 %

40 %
20 %

20 %

0%

0%

Time

Figure 8: Example distributions of arrival and departure times for six EVs.

217

0

0

:0

20

0

:0

16

0

:0

12

0

:0

08

0

:0

04

:0

00

0

0

:0

20

0

:0

16

0

:0

12

0

:0

08

0

:0

04

:0

00

Time

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Empirical Distribution Function (CDF)

1
0.9
0.8
0.7
0.6

All Cars
Car 1
Car 2
Car 3
Car 4
Car 5
Car 6

0.5
0.4
0.3
0.2
0.1
0
0.01

0.1

1

10

100

1000

Miles per Journey

Figure 9: Empirical distribution functions of distances travelled between successive visits
to home charging locations. Six example EVs and the combined summary of all
56 EVs, with equal weights assigned to all cars (in red), are shown.

at the charging location is shown in Figure 7.12 Here, almost all arrivals happen between
9am and 11pm, with a clear peak in the late afternoon and evening (4pm  9pm). Departures take place throughout the day with a peak around 8am  10am. To show how
individual driving patterns vary between the recorded cars, Figure 8 details the arrival and
departure time distributions for six individual EVs from the data set. Most of these reflect
the general trends shown in the previous figure, with arrivals generally occurring in the
evening and most departures in the morning. However, EVs 2 and 3 deviate from this
pattern. This is because those vehicles are shared fleet vehicles, which are collected and
returned to their main charging location throughout the day.
Figure 9 shows the distribution of the distances the vehicles travelled between visits to
their home charging location (red line), as well as the corresponding functions of the six
EVs from Figure 8 (interrupted lines).13 Overall, the average distance travelled is about 41
miles, while the median is around 9 miles (assigning uniform probabilities to each car type).
The six sample EVs here show significantly different typical travel distances, ranging from
an average of 4.19 miles (EV 1) to over 100 miles (EV 6).
In the following, we discuss how we use the data from the CABLED project to instantiate
our EV charging simulations.
12. As we will allocate electricity in hourly units, all arrival and departure times are here rounded up to the
next full hour.
13. Note that the distance of some journeys here exceeds the range of typical electric cars. This is because
they were charged at alternative locations during the CABLED trial, which we ignore in our experiments.
Since we focus on PHEVs in this work, in practice, the shortfall here would be made up by the combustion
engine.

218

fiAn Online Mechanism for Multi-Unit Demand

Units (3 kWh each)

15

High Supply
Low Supply

10
5
0

0
:0
00
0
:0
22
0
:0
20
0
:0
18
0
:0
16
0
:0
14
0
:0
12
0
:0
10
0
:0
08
0
:0
06
0
:0
04
0
:0
02
0
:0
00
Time

Figure 10: Number of 3 kWh units available for PHEV charging in two scenarios with
varying supply (high and low ), based on a neighbourhood of 30 households.

7.3.3 Generating Experiments
For each experimental run, we simulate a small neighbourhood of 30 households with a
variable number of PHEVs over a 24-hour period, starting at 8:00 am in the morning until
8:00 am the following day. We assume that electricity is allocated in hourly time steps,
where each unit corresponds to 3 kWh (which is the approximate energy obtained through
a standard 13 A BS 1363 household socket in the UK when charging for an hour).
To obtain the supply function S(t), we first compute the overall average electricity
consumption throughout the neighbourhood (without PHEVs), based on the average consumption of a single UK household during a weekday in high summer.14 Then, we assume
that overall electricity supply is limited by the capacity of the local transformer, such that
the electricity available for PHEV charging, S(t), is the difference between this capacity
(possibly including some additional safety margin) and the current overall consumption.
In more detail, we consider two possible scenarios: (1) a high supply scenario, where the
capacity limit is set such that it covers 150% of the peak consumption (at about 10:00 pm),
resulting in 615 kWh available for PHEV charging; and (2) a low supply scenario, where the
capacity limit is 80% of peak consumption, resulting in 99 kWh available for charging.15
The corresponding units available for PHEV charging in these two scenarios are shown in
Figure 10.
Furthermore, we use the specific empirical distribution of journey distances corresponding to that cars type as that cars travel distance distribution, p(m) (for example, if the
sampled car is based on car 3, we use the dashed dark blue distribution function in Figure 9). We then use Equations 9 and 10 to derive the marginal valuations. In this case, as
the empirical distribution function is discrete, the integrals in Equation 9 are replaced by
sums over the data points. Furthermore, we will initially assume that ri is drawn uniformly
14. We used the data available at http://data.ukedc.rl.ac.uk/browse/edc/Electricity/LoadProfile/
data.
15. Local transformers are often undersized in this way since prior to PHEV use, they could cool during
overnight periods of low demand.

219

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

at random from the discrete set ri  {1, 2, 3, 4}, that is, cars can charge between one to four
units of electricity per hour (corresponding to 3  12 kWh).
To generate agents with a variety of marginal valuations, we note that ee and ep depend
on the specific make and type of the PHEV. To simulate this, we draw ee uniformly at
random from 2  4 miles/kWh and ep is drawn from 9  18 miles/litre. Next, we draw
the capacity of a car battery from 15  25 kWh. These are realistic values modelled on
the Chevrolet Volt, the first mass-produced PHEV. However, we include some variance to
account for other vehicle types. Throughout the experiments, we hold the price of petrol
constant at pp = 1.30 per litre.
Table 4 shows example valuations corresponding to the same six cars considered previously (fixing ep = 13.5 miles/litre, ee = 3 miles/kWh and the battery capacity at 20 kWh).
These highlight how longer expected journeys generally translate to higher marginal valuations, but also how variable the valuations can be for an individual agent. As an example,
car 4 values the first 3 kWh of electricity at 0.67, but the seventh unit is only worth
0.038, as it is far less likely to be used.
Car
1
2
3
4
5
6
..
.

vi,1
0.340
0.304
0.481
0.670
0.727
0.839
..
.

vi,2
0.136
0.178
0.157
0.453
0.620
0.797
..
.

vi,3
0.001
0.162
0.073
0.333
0.582
0.767
..
.

vi,4

vi,5

vi,6

vi,7

0.114
0.062
0.312
0.540
0.711
..
.

0.033
0.035
0.263
0.498
0.630
..
.

0.134
0.445
0.555
..
.

0.038
0.445
0.540
..
.

Table 4: Example marginal valuations (in ).
To set up an experimental run, we then randomly generate a set of N PHEV agents,
where we vary N from 1 to 60 to simulate different levels of demand.16 For each agent i, we
first choose one of the 56 available cars uniformly at random from the CABLED dataset,
which we base that agents type on. Then, we randomly select one of the cars recorded
journeys and use the time of day of the cars arrival at the charging location as ai (at or after
8:00 am in the time window we consider). To ensure that the correlation between arrival
times and subsequent departure times in the dataset are preserved, we use the departure
time of the journey immediately following the sampled journey as di (or 10 hours after
arrival, whichever is sooner).
7.3.4 PHEV Results
First, we are interested in general trends of the mechanisms and whether these are similar to
the trends discussed in Section 7.2.2. To this end, Figure 11 shows the allocative efficiency
for all mechanisms in a setting with low supply (where it is feasible to run both the Optimal
16. Note that this is a realistic number of PHEVs within a neighbourhood served by a single distribution
transformer (Huang & Infield, 2010).

220

fiAn Online Mechanism for Multi-Unit Demand

Allocative Efficiency (% of Optimal)
100%

90%
Optimal
Heuristic
Greedy
OD
IM
Fixed
Random

80%

70%

60%
0

5

10

15

20

25

30

35

40

45

50

55

60

Number of EVs

Figure 11: Allocative efficiency in a small neighbourhood of 30 households.
and the IM mechanisms). This demonstrates the same broad trends as in our previous
synthetic setup  the OD and IM mechanisms clearly dominate the other truthful mechanism
(with IM achieving slightly worse results due to its higher cancellation rates). This, again,
is due to the ability of the mechanisms to always allocate to the agents with the highest
valuations.
However, although they still consistently achieve around 90% of the Optimal, the relative
performance of the OD and IM mechanisms here is slightly lower. This drop in performance,
also witnessed by the Heuristic and Greedy mechanism, is due to the more constrained
real-world settings, where electricity is only available in abundance at certain times (i.e.,
during the night), and where some agents are significantly less patient than others. In such
settings, it can often pay off to delay more patient agents, even if they have higher valuations,
in favour of less patient ones. Furthermore, because valuations are directly related to the
fuel costs saved by a unit of electricity, there is less variance in the real-world valuations,
causing the gap between the OD and IM mechanisms and the other truthful benchmarks to
narrow slightly. Turning to the potential gains of misreporting in this setting, Figure 12
again confirms the same patterns observed previously. The magnitude of the gains are
slightly higher here due to the different setting (reaching up to 3% in terms of overall gains
and up to 30% in the conditional case).
A key advantage of applying the mechanisms to real-world data is that it allows us to
determine the actual fuel savings agents could achieve in these settings. Thus, Figure 13
shows the average fuel savings of each agent under the various mechanisms, or, in other
words, the average amount each agent would have spent on fuel, had they not been allocated
any electricity. Initially, this is high (around 1.15), as there is little competition, but starts
dropping as more PHEV owners compete for the same amount of electricity. Of key interest
here is the horizontal separation between the different mechanisms. For a given fuel saving
per agent, our mechanism can sustain a significantly larger number of agents than the other
truthful mechanisms. For example, to save at least 0.40 per agent, Random can support
221

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Potential Gain in Utility When Misreporting
35%

Proportion of Gains
Expected Benefit on Gain
Expected Benefit Overall

30%
25%
20%
15%
10%
5%
0%
5

10

15

20

25

30

35

40

45

50

55

60

Number of EVs

Figure 12: Potential gains when misreporting in the Greedy mechanism in a small neighbourhood of 30 households.

Fuel Savings per Agent per Day (in )
Optimal
Heuristic
Greedy
OD
IM
Fixed
Random

1.25

1

0.75

0.5

0.25
0

5

10

15

20

25

30

35

40

45

50

55

60

Number of EVs

Figure 13: Saving per agent per day in a small neighbourhood of 30 households.
up to 40 PHEV owners, while IM and OD achieve the same threshold for around 60 PHEV
owners (an approximately 50% improvement).
Finally, we consider in more detail how the presence of fast-charging vehicles affects
the overall neighbourhood, in terms of overall fuel savings, the occurrence of cancellations
and the utilities of individual agents. To this end, we now fix the number PHEVs at 60
222

fiAn Online Mechanism for Multi-Unit Demand

Social Welfare / Fuel Savings (per Day, in )
90
30

Optimal
Heuristic
Greedy
OD

IM
Fixed Price
Random

85
80

25

75
20

70
65
0

10
20 30 40 50 60
Number of FastCharging EVs

0

10 20 30 40 50 60
Number of FastCharging EVs

Figure 14: Social welfare when introducing fast-charging cars into a neighbourhood with
low supply (left) and high supply (right).

Units Cancelled per Day (% of Total Allocated)
30%

30%

IM
OD

20%

20%

10%

10%

0%

0%
0

10 20 30 40 50 60
Number of FastCharging EVs

0

10
20
30
40
50
Number of FastCharging EVs

60

Figure 15: Cancellations when introducing fast-charging cars into a neighbourhood with
low supply (left) and high supply (right).

and consider both the low and high demand settings shown in Figure 10. Due to their
computational cost, we again only test the Optimal and IM mechanisms in the setting with
low supply. To investigate the impact of fast-charging, we assume there are two agent types
 the first, normal, can charge a single unit of 3 kWh per time step, while the second,
fast, are equipped with fast chargers that can charge up to four such units per time step.
223

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Utility Per Agent (per Day, in p = 0.01)
1.25

14p

12p

1

10p
OD (Fast)
OD (Normal)
Greedy (Fast)
Greedy (Normal)

8p

0.75

0.5
0

10 20 30 40 50 60
Number of FastCharging EVs

0

10 20 30 40 50 60
Number of FastCharging EVs

Figure 16: Individual agent utility when introducing fast-charging cars into a neighbourhood with low supply (left) and high supply (right).

Throughout the experiments, we vary the number of fast-charging PHEVs (out of the total
60). Figure 14 first shows the resulting social welfare (i.e., overall fuel savings) for both
supply scenarios with low supply (left) and high supply (right). First, we note that the
trends for the two scenarios are different  when supply is low, the introduction of more
fast-charging vehicles has little effect on overall social welfare for most mechanisms, while
when supply is high, most mechanisms display increased savings. This happens because the
first scenario is highly constrained, with the low supply resulting in few occasions where an
agent could charge more than a single unit per time step. In contrast, when supply is high,
agents are often allocated multiple units, thus enabling impatient agents in particular to
achieve higher overall fuel savings.
In addition to this, it is interesting to note that our proposed mechanisms OD and IM
benefit in both settings (achieving additional fuel savings of almost two litres per day in
the low supply setting, and up to seven litres in the high supply setting). The reason
for this becomes evident when considering the proportion of units cancelled as more fastcharging PHEVs are introduced  for both mechanisms and in both settings, the number
of units cancelled are consistently reduced by around 7080% as all cars are replaced by
fast-charging PHEVs (shown in Figure 15). This occurs mainly because there are more
hti
active marginal valuations at each time step to populate the pi vectors, thus reducing the
number of cancellations. This also causes the gap between our mechanisms and the Greedy
mechanism to shrink, as fewer cancellations take place.
With respect to the utility of individual agents (including payments to the mechanism),
Figure 16 shows that agents in both settings always have an incentive to switch to fast224

fiAn Online Mechanism for Multi-Unit Demand

Potential Gain in Utility When Misreporting
40%

40%

Proportion of Gains
Conditional Utility Increase
Overall Utility Increase

35%

35%

30%

30%

25%

25%

20%

20%

15%

15%

10%

10%

5%

5%

0%

0%
0

10
20 30 40 50 60
Number of FastCharging EVs

0

10 20 30 40 50 60
Number of FastCharging EVs

Figure 17: Potential gains when misreporting in the Greedy mechanism in a neighbourhood
with low supply (left) and high supply (right).

charging PHEVs (e.g., by purchasing a domestic fast charger), and this applies for both the
OD mechanism and the Greedy mechanism. With low supply, the expected daily saving when
switching to a fast-charging PHEV is approximately 0.020.03, while with high supply,
this is around 0.200.25. In both cases, this benefit is the result of increasing available
supply per time step, as well as increasing the size of the price vector. Furthermore, even
if the entire population were to switch from slow charging PHEVs to fast-charging PHEVs,
individuals would, on average, achieve a higher utility. Note that the differences between the
utility in the OD and Greedy mechanisms are significantly smaller for fast-charging vehicles,
indicating that fast-charging agents can expect lower gains from misreporting when there
are no cancellations.
Figure 17 further investigates the individual gains from misreporting when there are no
cancellations. This shows an interesting trend  while initial gains are high (reaching over
8% in one setting), they decrease significantly as more fast-charging PHEVs are introduced
(to around 0.2% in the same setting). This is clearly due to the significant reduction in
cancellations that are witnessed in those settings. Furthermore, we note, by comparing OD
and Greedy in Figure 16, that the agents who can gain from misreporting tend to be only the
slow-charging ones. Overall, this is a promising result for settings where cancellations are
not feasible  by increasing the consumption rate of PHEVs (within realistic parameters
that are achievable by current technological trends), the scope and potential benefits from
strategising in a simple greedy mechanism can be reduced significantly. In this particular
example, when supply is high, a fast-charging PHEV can expect to gain less than 1 over
the course of an entire year by strategising optimally.
225

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

8. Conclusions
The contributions in this paper are both theoretical and practical. On the theoretical
side, we propose a novel online, model-free mechanism for perishable goods where agents
have multi-unit demand and non-increasing marginal valuations. We show that, in order
to ensure dominant strategy incentive compatibility in such a setting, our mechanism occasionally requires units to remain unallocated (we say their pre-allocation is cancelled),
even if there is demand for these units. We define two ways in which cancellation can be
performed: immediate, i.e., before the actual allocation, or on departure of the agent from
the market. We study the properties of these two variants, both in terms of their incentives
and allocative efficiency. Furthermore, we present algorithms for computing the payments
and allocations of both mechanisms, and analyse their computational tractability.
The on-departure cancellation mechanism has better computational tractability, and has
the same worst-case competitive bound, in terms of allocation efficiency, as the single-unit
demand case. However, this mechanism requires any cancellations to be done on departure
of an agent from the market which is not always feasible. A nave approach to computing
payments in the mechanism with immediate cancellations requires time that is exponential
in the number of agents. To address this, we proposed a branch-and-bound algorithm that
allows payments to be computed in the immediate cancellation policy for many realistically
sized settings. Another potential problem with the immediate cancellation policy is that
there is no worst-case bound in terms of the efficiency of the allocation.
On the practical side, we show how our mechanism can be applied within the smart grid
to solve the important problem of integrating an increasing number of high-consumption
PHEVs into the electricity grid. In addition to a synthetic setting, we empirically evaluate
our mechanism using real-world data from a large-scale trial of electric vehicles in the UK.
We show that the proposed mechanism is highly robust, scalable (in particular, the ondeparture variant) and achieves better allocative efficiency than any fixed-price benchmark,
while only being slightly less efficient than an established cooperative scheduling heuristic.
Specifically, we demonstrate that our mechanism can sustain up to 50% more vehicles at the
same fuel cost than can be achieved using a simple randomised mechanism. Both variants
also consistently achieve an efficiency of around 90%, compared to a hypothetical optimal
offline solution. Given the theoretical results regarding their bounds, this is a surprising
result, suggesting that the specific conditions that cause cancellations do not often occur
in practice and that our allocation policies perform well in realistic settings. Furthermore,
we consider the introduction of fast chargers within a neighbourhood, and we show that
this leads to a significant increase in overall fuel savings and that it further reduces the
occurrence of cancellations. Finally, since on-departure cancellation requires discharging
the battery of the PHEV, we consider the the potential gains from misreporting if the units
are not cancelled (and assuming full knowledge of the types of other agents). From the
settings we considered, the average potential gain is between 1% and 8% overall, but could
go up to 30% on average when only considering those cases where misreporting is beneficial,
and could be even higher for individual cases. The gain becomes smaller as the number of
competing agents increases and, interestingly, fast-charging PHEVs have particularly low
incentives for misreporting.
226

fiAn Online Mechanism for Multi-Unit Demand

Taken together, our mechanisms represent a versatile range of tools, some of which may
be more suitable for specific scenarios than others. For example, in medium-sized settings
where allocations cannot be cancelled on departure, the IM mechanism may be the most
suitable (e.g., in the low-supply PHEV settings outlined in Section 7.3). In other settings
where on-departure cancellation is feasible, the OD mechanism leads to a higher average and
worst-case efficiency, and is also more scalable. Here, it is also important to emphasize that
on-departure cancellation only occurs when this is in the users best interest thus, it is
entirely possible to achieve through an optional action. Finally, as we show in the results,
even when both IM and OD are infeasible, a mechanism without cancellations may still be
viable in some settings, and it may even be possible to significantly reduce the scope for
manipulation by adjusting some of the system parameters; e.g., by introducing fast chargers
in the PHEV setting or by increasing supply.
There are several directions for extending this work. In related work, Stein et al. (2012)
discuss an alternative model, which uses probabilistic information about future arrivals and
is designed to elicit truthful reporting from pure EVs, rather than PHEVs. That model,
however, requires knowledge about future supply and assumes single-minded bidders; i.e.,
the preferences are single-dimensional and so it is not possible to specify different values
for different amounts of charge received. In future work, we intend to explore mechanisms
that combine the benefits of both approaches.
In addition, we intend to test our mechanism using a real-world trial. As we have seen
(see Section 7.3), we can design an agent which elicits information regarding the intended use
(a probability distribution of the driving distance), and combines this with other information
such as the price of petrol and the efficiency of the vehicle, to derive the owners marginal
valuation vector. Such an agent can also participate in the mechanism on the owners behalf,
avoiding the need for the owner to understand the details of the mechanism. This is in the
spirit of the work on hidden market design (Seuken, Parkes, Horvitz, Jain, Czerwinski, &
Tan, 2012), where the aim is to design the user interface such that the users cognitive
load is reduced by hiding details of the underlying market. In the trial, we intend to
approach participants owning regular (non EV) cars, and install GPS trackers in these cars.
Participants will then be asked to predict their driving requirements, and their agent will
use this information, as well as learned historic driving patterns, to derive the users utility
function and participate in the mechanism on their behalf. Although the trial will be with
regular cars, the users will be able to see how much they would have hypothetically saved
by providing accurate (and truthful) information about their intended use.

Acknowledgments
This work was supported by the iDEaS (www.ideasproject.info) and ORCHID (www.orchid.ac.uk )
projects at the University of Southampton. David Parkes was supported in part through
the Harvard SEAS TomKat fund.

References
Babaioff, M., Blumrosen, L., & Roth, A. (2010). Auctions with online supply. In Proceedings
of the 11th ACM Conference on Electronic Commerce (EC10), pp. 1322.
227

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Bent, R., & Van Hentenryck, P. (2004). The value of consensus in online stochastic scheduling. In Proceedings of the 14th International Conference on Automated Planning and
Scheduling (ICAPS04), pp. 219226.
Bikhchandani, S., Chatterji, S., Lavi, R., Mualem, A., Nisan, N., & Sen, A. (2006). Weak
monotonicity characterizes deterministic dominant-strategy implementation. Econometrica, 74 (4), 11091132.
Blum, M., Floyd, R. W., Pratt, V., Rivest, R. L., & Tarjan, R. E. (1973). Time bounds for
selection. Journal of Computer and System Sciences, 7 (4), 448  461.
Clement, K., Haesen, E., & Driesen, J. (2009). Coordinated charging of multiple plug-in hybrid electric vehicles in residential distribution grids. In Proceedings of the IEEE/PES
Power Systems Conference and Exposition (PSCE09), pp. 17.
Constantin, F., Feldman, J., Muthukrishnan, S., & Pal, M. (2009). An online mechanism for
ad slot reservations with cancellations. In Proceedings of the ACM-SIAM Symposium
on Discrete Algorithms (SODA09), pp. 12651274.
Constantin, F., & Parkes, D. C. (2009). Self-correcting sampling-based dynamic multi-unit
auctions. In Proceedings of 10th ACM Conference on Electronic Commerce (EC09),
pp. 8998.
Eberle, U., & von Helmolt, R. (2010). Sustainable transportation based on electric vehicle
concepts: a brief overview. Energy & Environmental Science, 3, 689699.
Engel, Y., & Wellman, M. P. (2010). Multiattribute auctions based on generalized additive
independence. Journal of Artificial Intelligence Research (JAIR), 37, 479525.
Fairley, P. (2010). Speed bumps ahead for electric-vehicle charging. IEEE Spectrum, 47 (1),
1314.
Gerding, E., Stein, S., Robu, V., Zhao, D., & Jennings, N. R. (2013). Two-sided online
markets for electric vehicle charging. In Proceedings of 12th International Confernece
on Autonomous Agents and Multiagent Systems (AAMAS13), pp. 989996.
Gerding, E., Robu, V., Stein, S., Parkes, D., Rogers, A., & Jennings, N. (2011). Online
mechanism design for electric vehicle charging. In Proceedings of the 10th International
Conference on Autonomous Agents and Multi-Agent Systems (AAMAS11), pp. 811
818.
Gershkov, A., & Moldovanu, B. (2010). Efficient sequential assignment with incomplete
information. Games and Economic Behavior, 68 (1), 144154.
Hajiaghayi, M., Kleinberg, R., Mahdian, M., & Parkes, D. C. (2005). Online auctions with
re-usable goods. In Proceedings of 6th ACM Conference on Electronic Commerce
(EC05), pp. 165174.
Huang, S., & Infield, D. (2010). The impact of domestic plug-in hybrid electric vehicles on
power distribution system loads. In Proceedings of the International Conference on
Power System Technology (POWERCON 2010), pp. 17.
Kamboj, S., Kempton, W., & Decker, K. S. (2011). Deploying power grid-integrated electric
vehicles as a multi-agent system. In Proceedings of the 10th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS11), pp. 1320.
228

fiAn Online Mechanism for Multi-Unit Demand

Lavi, R., & Nisan, N. (2004). Competitive analysis of incentive compatible on-line auctions.
Theoretical Computer Science, 310, 159180.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. (2007). Algorithmic Game Theory.
Cambridge University Press.
Parkes, D. C. (2007). Online mechanisms. In Nisan, N., Roughgarden, T., Tardos, E., &
Vazirani, V. (Eds.), Algorithmic Game Theory, pp. 411439.
Parkes, D. C., & Duong, Q. (2007). An ironing-based approach to adaptive online mechanism design in single-valued domains. In Proceedings of the 22nd National Conference
on Artificial Intelligence (AAAI07), pp. 94101.
Parkes, D. C., & Singh, S. (2003). An MDP-based approach to online mechanism design. In Proceedings of the 17th Conference on Neural Information Processing Systems
(NIPS03), pp. 791798.
Pinedo, M. (2008). Scheduling: Theory, Algorithms, and Systems (3rd edition). Springer.
Porter, R. (2004). Mechanism design for online real-time scheduling. In Proceedings of the
5th ACM Conference on Electronic Commerce (EC04), pp. 6170.
Robu, V., Stein, S., Gerding, E., Parkes, D., Rogers, A., & Jennings, N. (2011). An online mechanism for multi-speed electric vehicle charging. In Proceedings of the 2nd
International Conference on Auctions, Market Mechanisms and their Applications
(AMMA11), pp. 100112.
Robu, V., Kota, R., Chalkiadakis, G., Rogers, A., & Jennings, N. R. (2012). Cooperative
virtual power plant formation using scoring rules. In Proceedings of the 22nd AAAI
Conference on Artificial Intelligence (AAAI12).
Robu, V., Noot, H., La Poutre, J. A., & van Schijndel, W. (2011). A multi-agent platform
for auction-based allocation of loads in transportation logistics. Expert Systems with
Applications, 38 (4), 34833491.
Sandholm, T. (2002). Algorithm for optimal winner determination in combinatorial auctions. Artificial Intelligence, 135 (1-2), 154.
Seuken, S., Parkes, D. C., Horvitz, E., Jain, K., Czerwinski, M., & Tan, D. (2012). Market user interface design. In Proceedings of the 13th ACM Conference on Electronic
Commerce, pp. 898915. ACM.
Stein, S., Gerding, E., Robu, V., & Jennings, N. R. (2012). A model-based online mechanism
with pre-commitment and its application to electric vehicle charging. In Proceedings
of the 11th International Conference on Autonomous Agents and Multiagent Systems
(AAMAS12), pp. 669676.
Stein, S., Gerding, E., Rogers, A., Larson, K., & Jennings, N. R. (2011). Algorithms and
mechanisms for procuring services with uncertain durations using redundancy. Artificial Intelligence, 175, 20212060.
Sundstrom, O., & Binding, C. (2012). Flexible charging optimization for electric vehicles
considering distribution grid constraints. IEEE Transactions on the Smart Grid, 3 (1),
2637.
229

fiRobu, Gerding, Stein, Parkes, Rogers & Jennings

Vasirani, M., & Ossowski, S. (2011). A computational monetary market for plug-in electric
vehicle charging. In Proceedings of the 2nd International Conference on Auctions,
Market Mechanisms and their Applications (AMMA11), pp. 8899.
Vytelingum, P., Voice, T., Ramchurn, S. D., Rogers, A., & Jennings, N. R. (2011). Theoretical and practical foundations of large-scale agent-based micro-storage in the smart
grid. Journal of Artificial Intelligence Research (JAIR), 42, 765813.

230

fiJournal of Artificial Intelligence Research 48 (2013) 475-511

Submitted 04/13; published 11/13

Horn Clause Contraction Functions
James P. Delgrande

jim@cs.sfu.ca

School of Computing Science,
Simon Fraser University,
Burnaby, B.C., V5A 1S6
Canada

Renata Wassermann

renata@ime.usp.br

Dept. of Computer Science
University of Sao Paulo
05508-090 Sao Paulo,
Brazil

Abstract
In classical, AGM-style belief change, it is assumed that the underlying logic contains
classical propositional logic. This is clearly a limiting assumption, particularly in Artificial
Intelligence. Consequently there has been recent interest in studying belief change in approaches where the full expressivity of classical propositional logic is not obtained. In this
paper we investigate belief contraction in Horn knowledge bases. We point out that the
obvious extension to the Horn case, involving Horn remainder sets as a starting point, is
problematic. Not only do Horn remainder sets have undesirable properties, but also some
desirable Horn contraction functions are not captured by this approach. For Horn belief set
contraction, we develop an account in terms of a model-theoretic characterisation involving
weak remainder sets. Maxichoice and partial meet Horn contraction is specified, and we
show that the problems arising with earlier work are resolved by these approaches. As
well, constructions of the specific operators and sets of postulates are provided, and representation results are obtained. We also examine Horn package contraction, or contraction
by a set of formulas. Again, we give a construction and postulate set, linking them via a
representation result. Last, we investigate the closely-related notion of forgetting in Horn
clauses. This work is arguably interesting since Horn clauses have found widespread use in
AI; as well, the results given here may potentially be extended to other areas which make
use of Horn-like reasoning, such as logic programming, rule-based systems, and description
logics. Finally, since Horn reasoning is weaker than classical reasoning, this work sheds
light on the foundations of belief change.

1. Introduction
The area of belief change in knowledge representation studies how a rational agent may
alter its beliefs in the presence of new information. The best-known approach in this area
is the so-called AGM paradigm (Alchourron, Gardenfors, & Makinson, 1985; Gardenfors,
1988), named after the original developers. This work focused primarily on two belief
change operations, belief contraction, in which an agent may reduce its stock of beliefs, and
belief revision, in which new information is consistently incorporated into the agents belief
corpus. A fundamental assumption of this approach is that the underlying logic governing
c
2013
AI Access Foundation. All rights reserved.

fiDelgrande & Wassermann

the agents beliefs subsumes classical propositional logic. However, in artificial intelligence
(AI) a major concern is with efficient, limited, and ideally tractable reasoning. Hence
there has been significant effort in studying limited reasoners, including Horn clause based
approaches, limited epistemic reasoning involving explicit belief (Lakemeyer & Levesque,
2000), and description logics (Baader, Calvanese, McGuiness, Nardi, & Patel-Schneider,
2007). Moreover, since a knowledge base will evolve, it is crucially important that change
in a knowledge base be managed in a principled fashion. However, the AGM approach
cannot be used as a guide to change in any approach, such as those mentioned above, that
does not subsume classical propositional logic.
In this paper we address belief change in the expressively-weak language of Horn clauses,
where a Horn clause can be written as a rule in the form a1  a2      an  a for n  0,
and where a, ai (1  i  n) are atoms. (Thus, expressed in conjunctive normal form,
a Horn clause will have at most one positive literal.) In our approach, an agents beliefs
are represented by a Horn clause knowledge base, and the input is a conjunction of Horn
clauses. We focus on belief contraction (and, later, operators related to contraction) in
which the agents stock of beliefs decreases.
The topic of Horn clause contraction (and the general topic of Horn belief change in
general) is interesting for several reasons. First, Horn clause reasoners constitute an important class of AI systems, and Horn clauses have found extensive use in artificial intelligence
and database theory, in areas such as logic programming, truth maintenance systems, and
deductive databases. Horn clause belief change also sheds light on the theoretical underpinnings of belief change, in that it weakens the assumption that the underlying logic contains
propositional logic. Hence results obtained here may be relevant to belief change in other
areas of limited reasoning. For example, approaches to explicit belief often derives much of
their inspiration from relevance logic (Anderson & Belnap Jr., 1975); and description logics,
while constituting fragments of classical first-order logic, nonetheless in many cases do not
support full propositional reasoning.1
Creignou, Papini, Pichler, and Woltran (2012) provide further motivation for the study
of belief change in tractable fragments of propositional logic:
In many applications, the language is restricted a priori. For instance, a rulebased formalization of expert knowledge is much easier to handle for standard
users. In case users want to revise some rules, they indeed expect that the
outcome is still in the easy-to-read format they are used to. Many fragments
of propositional logic allow for efficient reasoning methods. Suppose an agent
who frequently has to answer queries about his beliefs. This should be done
efficiently thus the beliefs are stored as a formula known to be in a tractable
class. In case the beliefs of the agent are undergoing a revision, it is desired that
the result of such an operation yields a formula in the same fragment. Hence,
the agent still can use the dedicated solving method he is equipped with for this
fragment. In case such changes are performed rarely, we do not bother whether
the revision itself can be performed efficiently, but it is more important that the
outcome can still be evaluated efficiently.
1. In fact, as Booth, Meyer, and Varzinczak (2009) point out, results here are also relevant to belief change
in description logics, a topic that has also elicited recent interest.

476

fiHorn Clause Contraction Functions

Horn clause contraction has become a topic of interest in belief change in recent years
(Delgrande, 2008; Delgrande & Wassermann, 2010, 2011; Booth et al., 2009; Booth, Meyer,
Varzinczak, & Wassermann, 2011; Zhuang & Pagnucco, 2010a, 2011, 2012). As we discuss
in the next section, most of this work centers on the notion of a remainder set, or a maximal
subset of a knowledge base that fails to imply a given formula. We show that remainder
sets in the Horn case are too restricted and cannot give all feasible contraction operators.
As well they yield contraction operators with undesirable properties.
We propose the notion of a weak remainder set that serves as a basis for generating
all Horn maxichoice contraction operators. Contraction is also considered in terms of the
underlying model theory, a viewpoint that proves highly enlightening for studying Horn
belief change. Given a specification for maxichoice contraction based on weak remainders,
we go on to develop a specification for partial meet Horn contractions, and consider package
contraction and forgetting. In all the contraction operators developed, we provide postulate
sets along with constructions, and show representation results. Consequently we present a
comprehensive exploration of the landscape of Horn contraction.
The next section introduces belief change while the following section discusses reasoning
in Horn clause theories. The main approach is presented in Section 4, while Section 5
discusses considerations pertaining to the supplementary contraction postulates. Section 6
covers the related operators of package contraction and forgetting on Horn theories. The
paper concludes with a discussion and a concluding section. Proofs are given in an appendix.
Some of this material was presented previously by Delgrande (2008) and Delgrande and
Wassermann (2010, 2011).

2. Background
In this section, we introduce the main concepts of the area of Belief Change which we will
need throughout the paper.
2.1 Belief Change
As previously mentioned, the AGM approach (Alchourron et al., 1985; Gardenfors, 1988)
is the original and best-known approach to belief change.2 The goal in this approach is to
describe belief change at the knowledge level, that is, on an abstract level and independent of
how beliefs are represented and manipulated. Belief states are modelled by sets of sentences,
called belief sets, closed under the logical consequence operator of a logic that includes
classical propositional logic in a language L. Thus a belief set K satisfies the constraint:
If K logically entails  then   K.
The central operators3 addressed are contraction, in which an agent reduces its set of beliefs,
and revision, in which an agent consistently incorporates a new belief. In revision, since the
new belief may be inconsistent with an agents beliefs, some beliefs may need to be dropped
in order to maintain a consistent set of beliefs. A third operator, belief expansion was also
2. As well, Peppas (2008) provides an excellent survey.
3. In this paper, we use the terms operator and f unction interchangeably when refering to belief change
operations.

477

fiDelgrande & Wassermann

introduced: For belief set K and formula , the expansion of K by , denoted K + , is
the deductive closure of K  {}. Expansion captures the simplest form of belief change; it
can be reasonably applied when new information is consistent with a belief set
These operators are characterised by two means. On the one hand, a set of rationality
postulates for a belief change function may be provided; these postulates stipulate constraints that should govern any rational belief change function. On the other hand, specific
constructions for a belief change function are given. Representation results are then provided, showing that a set of rationality postulates exactly captures the operator given by a
particular construction.
We review these notions for belief contraction. Informally, the contraction of a belief set
by a formula is a belief set in which that formula is not believed. Formally, a contraction
function  is a function from 2L  L to 2L satisfying the following postulates.
(K 1) K  is a belief set.
(K 2) K   K.
(K 3) If  6 K, then K  = K.
(K 4) If 6` , then  6 K .
(K 5) If   K, then K  (K ) + .
(K 6) If   , then K  = K .
(K 7) K   K   K (  ).
(K 8) If  6 K (  ) then K (  )  K .
Thus, contraction yields a belief set (K 1) in which the sentence for contraction  is
not believed (unless  is a tautology) (K 4). No new sentences are believed (K 2), and
if the formula is not originally believed then contraction has no effect (K 3). The fifth
postulate, the so-called recovery postulate, states that nothing is lost if one contracts and
expands by the same sentence. This postulate is controversial, as discussed, for example
by Hansson (1999). The sixth postulate asserts that contraction is independent of how
a sentence is syntactically expressed. The last two postulates express relations between
contracting by conjunctions and contracting by the constituent conjuncts. Hence (K 7)
says that if a formula is in the result of contracting by each of two formulas then it is in
the result of contracting by their conjunction. (K 8) says that if a conjunct is not in the
result of contracting by a conjunction, then, in the presence of (K 7), contracting by that
conjunct is the same as contracting by the conjunction. The first six postulates are referred
to as the basic postulates while the last two are referred to as the supplementary postulates.
Revision represents the situation in which new information may be inconsistent with
the reasoners beliefs K, and needs to be incorporated in a consistent manner, the one
exception being when the formula for revision itself is inconsistent. A revision function
 is a function from 2L  L to 2L satisfying a set of postulates analogous to those for
contraction. Contraction is usually taken as being the more fundamental operator for belief
478

fiHorn Clause Contraction Functions

change. Moreover, revision and contraction are interdefinable. Revision can be defined in
terms of contraction by means of the Levi Identity:
K   = (K ) + .

(1)

Thus, to revise by , make K consistent with  then expand by . Contraction can be
similarly defined in terms of revision by the Harper identity:
K  = K  (K  ).
Since we do not consider revision functions in this paper, we refer the reader to to the work
of Gardenfors (1988) and Peppas (2008) for details.
Various constructions have been proposed to characterise belief change. The original
construction was in terms of remainder sets, where a -remainder of K is a maximal subset
of K that fails to imply . Formally:
Definition 1 Let K  L and let   L.
K   is the set of sets of formulas s.t. K 0  K   iff
1. K 0  K
2. K 0 6` 
3. For any K 00 s.t. K 0  K 00  K, it holds that K 00 ` .
Each K 0  K   is a -remainder of K.
Thus K   is the class of all maximal -nonimplying subsets of K. When there is no
ambiguity, we will also refer to K 0  K   as simply a remainder of K.
Two classes of contraction functions are relevant for our concerns. In maxichoice contraction, contraction is defined to correspond to a single selected remainder. In partial meet
contraction, contraction corresponds to the intersection of some subset of the remainders.
Consequently, any maxichoice contraction is a partial meet contraction but not vice versa.
From a logical point of view, the -remainders comprise equally-good candidates for
a contraction of  from K. Selection functions are introduced to reflect the extra-logical
factors that need to be taken into account, to obtain the best or most plausible remainders.
In maxichoice contraction, the selection function determines a single selected remainder as
the contraction. In partial meet contraction, the selection function returns a subset of the
remainders, the intersection of which constitutes the contraction. Thus if the selection
function is denoted by (), then the contraction of K by formula  can be expressed by
\
K  =
(K  ).
(2)
For belief set K and function  from 2L  L to 2L , it proves to be the case that  is a
partial meet contraction function iff it satisfies the basic contraction postulates (K 1)
(K 6). Last, let  be a transitive relation on 2K , and let the selection function be defined
by:
(K  ) = {K 0  K   | K 00  K  , K 00  K 0 }.
 is a transitively relational selection function, and  defined in terms of such a  is a
transitively relational partial meet contraction function. Then we have:
479

fiDelgrande & Wassermann

Theorem 1 (Alchourron et al., 1985) Let K be a belief set and let  be a function from
2L  L to 2L . Then
1.  is a partial meet contraction function iff it satisfies the contraction postulates
(K 1)(K 6).
2.  is a transitively relational partial meet contraction function iff it satisfies the contraction postulates (K 1)(K 8).
The second major construction for contraction functions is called epistemic entrenchment. The general idea is that extra-logic factors related to contraction are given by an
ordering on formulas in the agents belief set, reflecting how willing the agent would be to
give up a formula. Then a contraction function can be defined in terms of removing less
entrenched formulas from the belief set. Gardenfors and Makinson (1988) show that for
logics including classical propositional logic, the two types of constructions, selection functions over remainder sets and epistemic entrenchment orderings, capture the same class of
contraction functions.
Two other constructions were also proposed in the literature and shown to be equivalent
to transitively relational partial meet contraction: safe contraction (Alchourron & Makinson, 1985; Rott, 1992) and systems of spheres (Grove, 1988). We do not address either
construction in this paper.
2.2 Belief Change and Horn Clause Theories
Earlier work on belief change and Horn theories focussed on specific aspects of the problem,
rather than on a general characterisation of Horn clause belief change. For example, the
complexity of specific approaches to revising knowledge bases has been addressed by Eiter
and Gottlob (1992). This includes the case where the knowledge base and formula for
revision are conjunctions of Horn clauses, although the results of revision may not be Horn.
Not unexpectedly, results are generally better in the Horn case. Liberatore (2000) considers
the problem of a compact representation for revision in the Horn case. Given a knowledge
base K and formula , both Horn, the main problem addressed is whether the knowledge
base, revised according to a given operator, can be expressed by a propositional formula
whose size is polynomial with respect to the sizes of K and .
Langlois, Sloan, Szorenyi, and Turan (2008) approach the study of revising Horn formulas by characterising the existence of a complement of a Horn consequence; such a complement corresponds to the result of a contraction operator. This work may be seen as a specific
instance of a general framework developed by Flouris, Plexousakis and Antoniou (2004).
They study belief change under a broad notion of logic. In particular, they give a criterion
for the existence of a contraction operator satisfying the basic AGM postulates in terms of
decomposability.
The present paper builds on and extends (Delgrande, 2008; Delgrande & Wassermann,
2010, 2011). Delgrande (2008) addresses maxichoice belief contraction in Horn clause theories, where contraction is defined in terms of remainder sets, using Definition 1, but expressed in terms of derivations among Horn clauses. Booth, Meyer, and Varzinczak (2009)
and then Booth, Meyer, Varzinczak, and Wassermann (2011) further develop this area, by
480

fiHorn Clause Contraction Functions

considering other versions of contraction, all based on remainder sets: partial meet contraction, a generalisation of partial meet, and package contraction. Horn contraction based on
remainders was found to be inadequate by Delgrande and Wassermann (2010), and instead
they developed a notion of weak remainder. The work by Zhuang and Pagnucco (2010a,
2012) follows another line, focusing on epistemic entrenchment and model-based constructions. These approaches are discussed and compared in more detail once we have introduced
our overall approach.
Recently, revision operations for Horn theories have also been developed (Delgrande &
Peppas, 2011), and revision in other fragments of propositional logic has also been explored
(Creignou et al., 2012). However the relation of this work with the contraction operations
described in this paper is still unclear.

3. Horn Clause Theories
We will deal with languages based on finite sets of atoms, or propositional letters P =
{a, b, c, . . . }, where P includes the distinguished atom . L is the language of propositional
logic over P and with the usual connectives , , , and .4 LHC is the restriction of L
to Horn formulas, where a Horn formula is a finite conjunction of Horn clauses. LHC is the
least set given by:
1. a1  a2      an  a, where n  0, and a, ai (1  i  n) are atoms, is a Horn clause.
2. Every Horn clause is a Horn formula.
3. If  and  are Horn formulas then so is   .
As well, for convenience, > will be taken as denoting a  a for some specific atom a. For
a Horn clause r as in 1 above, if n = 0 then r is a fact, and  a is also written as a.
For a Horn clause r as in 1 above, head(r) is a, and body(r) is the set {a1 , a2 , . . . , an }. If
a is a fact, then head(r) is a, and body(r) is empty. If for a Horn clause r we have that
head(r) = , then r is an integrity constraint. Allowing conjunctions of clauses, as given in
3, adds nothing of interest to the expressibility of the language with respect to reasoning.
However, it adds to the expressibility of contraction, as we are able to contract by more
than a single Horn clause.
Semantics: An interpretation of L is a function from P to {true, f alse} such that 
is assigned f alse. Sentences of L are true or false in an interpretation according to the
standard rules of propositional logic. An interpretation M is a model of a sentence  (or set
of sentences), written M |= , just if  is true in M . M od() is the set of models of formula
(or set of formulas) ; thus M od(>) is the set of interpretations of L. An interpretation is
usually identified with the atoms true in that interpretation. Thus, for the language given by
P = {p, q, r, s}, the interpretation expressed by {p, q} is that in which p and q are true and
r and s are false. For convenience, we also will express interpretations by juxtaposition of
atoms. Thus the set of interpretations {{p, q}, {p}, {}} will usually be written as {pq, p, }.
All of these notions are inherited by the corresponding Horn formula language LHC . A
key point concerning Horn theories is that such theories are characterised semantically by
4. To avoid clutter, and because no ambiguity results, we dont parameterize L by P.

481

fiDelgrande & Wassermann

the fact that their models are closed under intersections of positive atoms in an interpretation. That is, a Horn theory H satisfies the constraint:
If M1 , M2  M od(H) then M1  M2  M od(H).
This leads to the notion of the characteristic models (Khardon, 1995) of a Horn formula or
set of formulas: M is a characteristic model of formula  just if for every M1 , M2  M od(),
M1  M2 = M implies that M = M1 or M = M2 . Thus for example, {p  q  , r}
has models {pr, qr, r} and characteristic models {pr, qr}. Since pr  qr = r, r isnt a
characteristic model of .
Proof Theory: We assume a suitable inference relation ` for classical propositional logic.
The following axioms and rules give an inference relation for Horn formulas, where for
simplicity, a and b, possibly subscripted, are taken as ranging over atoms.
Axioms:

a

aa

Rules:
1. From a1      an  a and b1      bn  a1
infer b1      bn  a2      an  a
2. From a1      an  a infer a1      an  b  a
3. For Horn clauses r1 , r2 , if body(r1 ) = body(r2 ) and head (r1 ) = head (r2 ) then
from r1 infer r2 .
4. (a) From
(b) From

   infer  and 
 and  infer   

Rule 1 is an extended version of modus ponens, while Rule 2 is strengthening of the antecedent. Rule 3 states that the order of atoms in the body of a Horn clause is irrelevant,
as are repeated atoms.
A formula  can be derived from a set of formulas A, written A `HC , just if  can
be obtained from A by a finite number of applications of the above rules and axioms; for
simplicity we drop the subscript and write A ` . If A = {} is a singleton set then we
just write  ` . A set of formulas A  LHC is inconsistent just if A ` . We use   
to represent logical equivalence, that is  `  and  ` .
Notation: We collect here for reference notation that is used in the paper. Lower-case
Greek characters , , . . ., possibly subscripted, denote arbitrary formulas of either L or
LHC . Upper case Roman characters A, B, . . . , possibly subscripted, denote arbitrary sets
of formulas. H, H1 , H 0 , etc. denote Horn belief sets, so that   H iff H `HC .
Cn(A) is the (classical, propositional) deductive closure of A where A is a formula or
set of formulas of propositional logic. Cnh (A) is the deductive closure of a Horn formula
or set of formulas A under Horn derivability. For set of formulas A, Horn(A) = {  A |
 is a Horn formula}.
We use m (possibly subscripted) to denote a maximal consistent Horn theory; that
is, m 6`  and for every Horn formula , either   m or m  {} ` . Hence such a
482

fiHorn Clause Contraction Functions

m has exactly one model. We often use maximal consistent sets of formulas in place of
interpretations, as it makes the statement and proof of various results easier. || is the set
of maximal, consistent Horn theories that contain .
M (M1 , M 0 , etc.) will denote (classical, propositional) interpretations over some understood language. M od(A) is the set of models of A. Arbitrary sets of interpretations will
be denoted M (M0 etc.). Cl (M) is the intersection closure of a set of interpretations M;
that is, Cl (M) is the least set of interpretations such that
1. M  Cl (M) and
2. M1 , M2  Cl (M) implies that M1  M2  Cl (M).
Note that M denotes an interpretation expressed as a set of atoms, while m denotes
a maximal consistent set of Horn formulas. Thus the logical content is the same, in that
an interpretation defines a maximal consistent set of Horn formulas, and vice versa. We
retain these two interdefinable notations, since each is useful in the subsequent development.
Similar comments apply to M od() vs. ||; we also make use of the fact that there is a 1-1
correspondence between elements of || and of M od().
Last, since P is finite, a (Horn or propositional logic) belief set may be finitely represented, that is, for X a belief set, there is a formula  such that Cn() = X.

4. Horn Clause Belief Set Contraction
In this section, we examine the possible constructions for the operation of contraction of
Horn belief sets. We begin by operations based on remainde sets and proceed to introducing
the concept of a weak remainder set.
4.1 Horn Clause Contraction and Remainder Sets
The most straightforward way to define a Horn contraction function is by adapting a construction used in classical logic for contraction. To this end, Delgrande (2008) developed a
remainder-set approach to Horn contraction, which was subsequently generalised by Booth,
Meyer and Varzinczak (2009). It proves to be the case that these approaches are not sufficiently expressive for general Horn contraction; as well, contraction based on remainder
sets can be shown to have undesirable properties. We review the pertinent aspects of these
approaches here, and in particular consider why the results of (classical, AGM) contraction
do not readily extend to the Horn case.
The definition of remainder sets for Horn clause belief sets (called e-remainder sets in
Delgrande, 2008) is the same as that for a remainder set (Definition 1) but with respect
to Horn clauses and Horn derivability. For H a Horn belief set and   LHC , the set of
e-remainders with respect to H and  is denoted by H e .
Definition 2 Let H  LHC and let   LHC .
H e  is the set of sets of formulas such that H 0  H e  iff
1. H 0  H
2. H 0 6` 
483

fiDelgrande & Wassermann

3. For any H 00 such that H 0  H 00  H it holds that H 00 ` .
Each H 0  H e  is an -e-remainder with respect to H.
Usually such a H 0 will just be referred to simply as a remainder, since the Horn context
and underlying formula are clear.
Observation 1 If H e 1 = H e 2 , then for any H 0  H, 1  Cnh (H 0 ) iff 2 
Cnh (H 0 ).
Observation 2 (Upper bound property) If X  H and  6 Cnh (X), then there is some
X 0 such that X  X 0  H e .
Horn remainders as given in Definition 2 can be regarded as comprising a set of candidate
contractions for H by a formula ; a single such remainder then could be selected as the
maxichoice contraction of H by . Booth, Meyer, and Varzinczak (2009) subsequently argue
that maxichoice contraction is not sufficient for an account of Horn contraction functions.
In classical AGM contraction, the set of partial meet contraction functions is defined by
taking the intersection of some of the remainders. However, Booth, Meyer, and Varzinczak
also argue that the set of Horn partial meet contractions is not sufficient to capture the full
range of possible contraction functions. Instead they define infra remainder sets, as follows:
Definition 3 For belief sets H and X, X  H e 5 iff there is some X 0  H e  such that
\

H e   X  X 0 .
The elements of H e  are the infra e-remainder sets of H with respect to .
Thus an infra e-remainder set is any belief set that contains the intersection of Horn remainders, and is contained in some Horn remainder. All e-remainder sets are clearly infra
e-remainder sets, as is the intersection of any set of e-remainder sets. That is:
T
Observation 3 Let H  LHC ,   LHC , and let X  H e . Then ( X)  H e .
Example 1 For P = {a, b, c}, let H = Cnh (a  b).
Consider candidates for H (a  b).
It can be verified that there are three remainder sets:
Cnh (a  (c  b)),
Cnh (b  (c  a)),
Cnh ((a

and

 b)  (b  a)  (c  a)  (c  b)).

As well, any remainder set and any infra remainder set must contain the closure of
(c  a)  (c  b).
5. Booth, Meyer, and Varzinczak (2009) write X  H e  where  is a set of Horn clauses.

484

fiHorn Clause Contraction Functions

To see the last part of the example, note that both (c  a) and (c  b) are in all remainders,
and so in the intersection of the remainders. This however leads to a significant blemish. Call
p inessential in H if for any conjunction of atoms body not containing p, H ` p  body  a
implies that either ` p  body  a or H ` body  a. For contraction defined in terms
of remainder sets, or intersections of remainder sets, or infra remainder sets, we have the
result:6
Theorem 2 Let  be a Horn contraction function defined via a selection function as in
(2) and based on (infra) remainder sets.
For   H and p inessential in H, we obtain that (H ) + p ` .
The following example (based on an example in Hansson, 1999) illustrates the problem:
1. You believe Cleopatra had a son and a daughter (s  d).
2. You learn that the source of information was unreliable, so you remove this belief; i.e.
you compute the contraction H (s  d).
3. You learn that it is raining outside (r).
4. You conclude that Cleopatra had a son and daughter (s  d)
This behaviour is clearly undesirable. However, consider what this example implies
about Horn contraction to this point: We have that H (s  d) + r entails s  d. Hence,
regardless of how  is defined in terms of (infra) remainders, all models of H (s  d) in
which r is true must have that s and d is also true. What this in turn means is that sdr
cannot be a model of any s  d-remainder. This last point is curious, in that sdr is clearly
a counter-model of s  d, yet it does not take part in any remainder, and so does not take
part in any contraction.
In AGM contraction, we have that each -remainder of a belief set K can be characterized by the set of models of K together with a single countermodel of , and vice versa
(e.g., see Gardenfors, 1988, p. 86). What the above example shows is that this equivalence
between the proof-theoretic notion of remainders and the semantic notion of minimallyextended sets of models breaks down in the Horn case.
So, consider what is going on in the Horn case: Assume that H |=  and we wish to find a
maximal belief set H 0 such that H 0  H and H 0 6|= . That is, H 0 is to be a -remainder set
of H. As described, in classical AGM (maxichoice) contraction, from the semantic side one
adds a countermodel of  to the models of H; this set of models characterises a candidate
theory for maxichoice contraction.
Consider the analogous process for Horn theories. Since a remainder set must be a
Horn theory, and the models of a Horn theory are closed under intersection, we would
need to make sure that this constraint holds here. So, intuitively, to carry out maxichoice
Horn contraction, we would add a countermodel of the formula for contraction, and close
the result under intersection. However, the theories resulting from this approach do not
correspond to those obtained via remainder sets. To see this, consider again Example 1,
and where the pertinent results are summarised in Figure 1.
6. This result would also be obtained in package contraction, discussed in Section 6, if package contraction
were defined in terms of infra remainder sets.

485

fiDelgrande & Wassermann

countermodel
ac
a
bc
b
c


induced
models
a
b


resulting KB

remainder
set?

a
a  (c  b)
b
b  (c  a)
(a  b)  (b  a)
(a  b)  (b  a)  (c  a)  (c  b)





Figure 1: Example: Candidates for Horn contraction
We have that ac (viz. abc) is a countermodel of  = ab; this is given in the first entry
of the first row of the table. Since H has a model ab, the intersection of these models,
ab  ac = a must also be included; this is the item in the second column. The resulting
belief set is characterised by the interpretations M od(H)  {ac, a} = {abc, ab, ac, a}, which
is the set of models of formula a, given in the third column. The result isnt a remainder
set, since Cnh (a  (c  b)) is a logically stronger belief set that fails to imply a  b. This last
belief set, Cnh (a  (c  b)) appears in the second row of the table. It can be observed that
the models of this belief set is made up of the models of H together with the countermodel
a, that is, the induced model in the first row.
As previously noted, there are three remainder sets, as indicated in the last column.
As discussed, this result is problematic for the approaches of both Delgrande (2008) and
Booth, Meyer, and Varzinczak (2009). For example, in none of the approaches in these
papers is it possible to obtain H e (a  b)  a, nor is it possible to obtain H e (a  b) 
((a  b)  (b  a)). But these possibilities would be desirable as potential contractions.
The diagnosis of the problem is now presumably clear. In the example, and for the
countermodel given by abc, it is not possible to have a set of interpretations M satisfying:
1. M is closed under intersections
2. M = M od(H)  abc
The solution also seems clear: From a semantic point of view, one wants the characteristic
models of maxichoice candidates for H e  to consist of the characteristic models of H
together with a single interpretation from M od(>) \ M od(). The resulting theories, called
weak remainder sets, would correspond to the theories given in the third column in Figure 1;
we explore this notion in the next subsection.
To conclude we note that it has been shown that (maxichoice) contraction based on
remainder sets alone suffers from a triviality result analogous to that in AGM contraction.
Theorem 3 (Makinson, 2009) Let a  P be an atom, and let H be a Horn belief set with
a    H. Let  be a maxichoice Horn contraction function based on remainder sets.
Then for every atom b, at least one of b and b   is in H (a  ) + a.
Hence if a is false according to H, then contracting by a   and then expanding by a
yields a belief set in which every atom is believed to be true or believed to be false. This is
clearly far too unrealistic to be useful.
486

fiHorn Clause Contraction Functions

4.2 Horn Clause Contraction and Weak Remainder Sets
The previous section showed that basing Horn contractions solely on remainder sets (or infra
remainder sets) is problematic. We then suggested that an adequate version of contraction
should be based on weak remainder sets where for belief set H and formula   H, there is
a 1-1 correspondence between countermodels of  and weak remainder sets. In this section
we develop Horn contraction based on weak remainder sets. We first give two constructions
for weak remainder sets, in terms of belief sets and in terms of sets of models, and show
that the constructions are equivalent. We then characterise maxichoice Horn contraction in
terms of weak remainder sets, showing via a representation result that the characterisations
are equivalent. Following this we similarly characterise partial meet contraction.
Definition 4 Let H be a Horn belief set, and let  be a Horn formula.
He  is the set of sets of formulas such that
1. If   H then: H 0  He  iff H 0 = H  m for some m  |>| \ ||.
2. Otherwise He  = {H}.
H 0  He  is a weak remainder set of H and .
Observation 4 If H 0  He , then H 0 is a belief set, i.e., H 0 = Cnh (H 0 ).
In the above definition, m is a maximal consistent set of formulas, and so corresponds
to the set of formulas true in some interpretation. In this case the underlying interpretation
would belong to M od(>)\M od(), which is to say that the underlying interpretation would
be a countermodel of .
Example 2 For P = {a, b, c}, let H = Cnh (a  b) and  = a  b.
For m1 = Cnh (a  b  c)  |>| \ ||, we have H  m1 = Cnh (a  (c  b)).
For m2 = Cnh (a  b  c)  |>| \ ||, we have H  m2 = Cnh (a).
Note that (H  m2 )  (H  m1 ), and also that full propositional closure gives Cn(H 
m2 ) = Cn(a  (b  c)).
The previous definition specifies weak remainder sets in terms of maximal consistent
sets of formulas. The next definition is similar, but is expressed directly in terms of countermodels of a formula.
Definition 5 Let H be a Horn belief set, and let  be a Horn formula. Define H ||e  by:
1. If   H then: H ||e  is the set of sets of formulas such that H 0  H ||e  iff there is
M 6 M od() such that M od(H 0 ) = Cl (M od(H)  {M }).
2. Otherwise H ||e  = {H}.
In our running example, H ||e  is given by the closure of the formulas in column 3 in
Figure 1.
Perhaps not surprisingly, these two characterisations prove to be equivalent:
487

fiDelgrande & Wassermann

Theorem 4 For H a Horn belief set and  a Horn formula:
He  = H ||e .
We are now in a position to define a Horn contraction operator. We start by defining a
selection function, basically as is done in the AGM approach. Given a selection function, it
is straightforward to define a maxichoice contraction operator, and following this, a partial
meet contraction operator.
Definition 6 Let H be a Horn belief set.  is a selection function for H if, for every
  LHC ,
1. If He  6=  then  =
6 (He )  He .
2. If He  =  then (He ) = {H}.
Definition 7 Let  be a selection function on H such that (He ) = {H 0 } for some
H 0  He .
The maxichoice Horn contraction based on weak remainders is given by:
H w  = (He )
Hence the result of a maxichoice contraction is characterised by a single weak remainder
set.
We obtain the following representation result, relating the construction to a postulate
set characterising contraction:
Theorem 5 Let H be a Horn belief set. Then w is an operator of maxichoice Horn
contraction based on weak remainders iff w satisfies the following postulates.
(H w 1) H w  is a Horn belief set.

(closure)

(H w 2) If not ` , then  6 H w .

(success)

(H w 3) H w   H.

(inclusion)

(H w 4) If  6 H, then H w  = H.

(vacuity)

(H w 5) If `  then H w  = H

(failure)

(H w 6) If   , then H w  = H w .

(extensionality)

(H w 7) If H 6= H w  then   LHC such that {, } ` , H w   Cnh () and H 0
s.t H w   H 0  H we have H 0 
6 Cnh ().
(maximality)
The first four postulates and (H w 6) have obvious counterparts in the AGM contraction
postulates. Notably, we do not obtain the recovery postulate. The following provides a
counterexample.
488

fiHorn Clause Contraction Functions

Example 3 Let H = Cn(p  q) and  = p  r  q.
Then H w  6` p  q, since p  q ` p  r  q.
Thus H w  can be at most Cn({p  r  i  q | i  P \ {p, r}}.)
But H w  +   Cn({p  r  i  q | i  P \ {p, r}) +  6` p  q
and hence H w  +  6` p  q.
Postulate (H w 5) is derivable using the AGM postulates, but relies on the recovery postulate (K 5) for its proof. Since we lack the recovery postulate, it is required here as a
postulate, covering a special case, in its own right.
Postulate (H w 7) is more complicated than the others, but it expresses the basic defining characteristic for maxichoice revision: If contraction is nontrivial (viz. H 6= H w ),
then some countermodel of  is a model of H w . This is expressed by , in that  and 
are mutually inconsistent, H w  is a subset of the closure of , and H w  is a maximal
set of formulas for which this holds. This in turn means that, even though the recovery
postulate does not hold, nonetheless the trivial contraction, in which the entire belief set
is discarded, is excluded as a legal contraction operator. It can be verified that in Example 1 (see also Figure 1) that both countermodels abc and abc fulfill the conditions on  in
(H w 7), which is to say, this postulate captures the notion of weak remainder set.
We turn next to partial meet Horn contraction. The definition for partial meet Horn
contraction is analogous to that in AGM contraction, but based on weak remainder sets:
Definition 8 Let  be a selection function on H such that (He )  (He ).
The partial meet Horn contraction based on weak remainders is given by:
H pm  =

\

(He )

A representation result involves a modification of the last postulate for maxichoice contraction:
Theorem 6 Let H be a Horn belief set. Then pm is an operator of partial meet Horn
contraction based on weak remainders iff pm satisfies the postulates (H w 1)  (H w 6)
and:
(H pm 7) If   H \(H pm ), then there is some H 0 such that H pm   H 0 ,  6 Cnh (H 0 )
and   Cnh (H 0  {})
(weak relevance)
Example 4 For our running example, the partial meet given by the first and last weak
remainder sets in Figure 1 is given by
Cnh ((b  a)  (c  a)).
In terms of models, it is characterised by the models of a  b, together with the two countermodels given by atoms ac and , and closed under intersections.
489

fiDelgrande & Wassermann

5. Supplementary Postulates
In this section we investigate how the different proposals for Horn contraction operations
behave with respect to the supplementary postulates (K 7) and (K 8). Throughout this
section, we assume all selection functions to be transitively relational.
First we consider the operation of Horn partial meet e-contraction (Delgrande, 2008).
The following example shows that, considering e as defined by Delgrande (see also Definition 2), Horn partial meet e-contraction does not satisfy (K 7):
Example 5 Let H = Cnh ({a  b, b  c, a  d, d  c}).
We then have
H e (a  c) = {H1 , H2 , H3 , H4 }
H e (b  c) = {H5 }
where:
H1
H2
H3
H4
H5

= Cnh ({a  b, a  d}),
= Cnh ({a  b, a  c  d, d  c}),
= Cnh ({b  c, a  c  b, a  d}),
= Cnh ({a  c  b, b  c, a  c  d, d  c, a  d  b, a  b  d}), and
= Cnh ({a  b, a  d, d  c})

Note that the two first elements of H e (a  c) are subsets of the single element of
H e (b  c) and hence, cannot belong to H e (a  c  b  c).
H e (a  c  b  c) = {H3 , H4 , H5 }
If we take a selection function based on a transitive relation between remainder sets that
gives priority in the order in which they appear in this example, i.e., H5  H4  H3 
H2  H1 , we have:
H  (a  c) = H1
H  (b  c) = H5
H  (a  c  b  c) = H3
And we see that
H  (a  c)  H  (b  c) = H1 6 H3 = H  (a  c  b  c)
The same example shows that the operation does not satisfy (K 8):
a  c 6 H  (a  c  b  c) but H  (a  c  b  c) 6 H  (a  c).
If there are no further restrictions on the selection function, the same example also
shows that contraction based on infra-remainders does not satisfy the supplementary postulates. Note that each remainder set in the example is also an infra-remainder and that
the selection function always selects a single element. It suffices to assign all the remaining
infra-remainders lower priority.
Now we can show that the operation of partial meet based on weak remainders (PMWR)
has a better behaviour with respect to the supplementary postulates:
490

fiHorn Clause Contraction Functions

Theorem 7 Partial meet based on weak remainders and a transitive relational selection
function satisfies (K 7) and (K 8).
More recently, Zhuang and Pagnucco (2010a) have addressed Horn contraction from the
point of view of epistemic entrenchment. They compare AGM contraction via epistemic
entrenchment in classical propositional logic with contraction in Horn logics. A postulate
set is provided and shown to characterise entrenchment-based Horn contraction. The fact
that AGM contraction allows disjunctions of formulas, which in general will not be Horn, is
handled by considering Horn strengthenings in their postulate set, which is to say, logically
weakest Horn formulas that subsume the disjunction. In contrast to earlier work, their
postulate set includes equivalents to the supplemental postulates, and so goes beyond the
set of basic postulates. In more detail, Zhuang and Pagnucco (2010a) have the following:
Definition 9 For a given clause , the set of its Horn strengthenings ()H is the set such
that   ()H if and only if  is a Horn clause and there is no Horn clause  0 such that
   0  .
Of the ten postulates given by Zhuang and Pagnucco (2010a) to characterize epistemic
entrenchment Horn contraction (EEHC), postulates (H 1), (H 2), (H 4), (H 6), (H 7)
and (H 8) correspond exactly to the AGM postulates with the same numbers. (H 1),
(H 2), (H 3), (H 4) and (H 6) correspond to postulates (H w 1)-(H w 6) characterizing partial meet contraction based on weak remainders just defined. The three new postulates are:
(H 5) If   H    then   H     
(H 9) If   H \ H  then   (  )H ,  6 H 
(H 10) If   (  )H ,  6 H    then  6 H \ H 
Subsequently, Zhuang and Pagnucco (2010b) have shown that transitively relational
PMWR as defined above is more general than EEHC. This means that any operation
satisfying their set of 10 postulates (which include (K 7) and (K 8)) is a PMWR. We
have seen that PMWR satisfies (K 7) and (K 8), hence, in order to compare PMWR and
EEHC, we need to know whether PMWR satisfies (H 5), (H 9) and (H 10).
Theorem 8 PMWR satisfies (H 5).
Zhuang (2012) has shown that weak relevance implies (H 9), hence, PMWR satisfies
(H 9). PMWR in general does not satisfy (H 10), as the following example shows:
Example 6 Let H = Cnh ({a, b}).
Then we have
He a = {H1 , H3 } and
He (a  b) = {H1 , H2 , H3 },
where
491

fiDelgrande & Wassermann

H1 = Cnh ({b  a, a  b}),
H2 = Cnh ({a}) and
H3 = Cnh ({b}).
Assuming a selection function based on a transitive relation such that H1  H2 and
H1  H3 (and H2  H3 and H3  H2 ), we have
H  a = H3 and H  (a  b) = H2  H3
Since (ab)H = {a, b}, we have that for any   (ab)H ,  6 H (ab), but b  H a.

6. Other Operators
In this section we consider two contraction-like operators. The first, package contraction, is
like contraction, but it is defined with respect to a set of formulas. The second operator,
forget, can be regarded as a removal of an atom or set of atoms from the language of
discourse.
6.1 Package Contraction
In AGM-style belief change in propositional logic, given a belief set K and a set of formulas
, the package contraction K p  is a form of contraction in which no (non-tautological)
member of  is in K p . In propositional logic the effect of package contraction may be
nearly, but not quite, obtained by contracting by the disjunction of elements in . To see
the difference, consider where  = {, }. Clearly,    6 K (  ) whereas it seems
that a simultaneous contraction K p {, } should allow for the possibility of    being
true in the outcome.
As Booth, Meyer, and Varzinczak (2009) note, package contraction is of interest in Horn
clause theories, given the limited expressivity of such theories. That is, if ,  are Horn
formulas, H (  ) will be undefined whenever    is non-Horn (which, of course, will
be most of the time). On the other hand, expressing a contraction of both  and  by
H p {, } seems to be perfectly fine.
Our development of Horn package contraction is analogous to that of maxichoice Horn
contraction based on weak remainders. Essentially, for a package contraction H p , we
ensure that for each    a countermodel of  is among the models of H p .
Definition 10 Let H be a Horn belief set, and let  = {1 , . . . , n } be a finite7 set of Horn
formulas.
Hp  is the set of sets of formulas such that H 0  Hp  iff
For every 1  i  n, mi such that:
if 6` i and i  H then mi  |>| \ |i |; otherwise mi = LHC ;
T
and H 0 = H  ni=1 mi .
In the next definition, the notion of a selection function on H (Definition 6) is extended in
the obvious fashion to apply to a set of Horn formulas.

7. Since we assume that the underlying language is finite, any set of formulas will be equivalent to a finite
set of formulas, under logical equivalence of formulas.

492

fiHorn Clause Contraction Functions

Definition 11 Let  be a selection function on H such that (Hp ) = {H 0 } for some
H 0  Hp .
The (maxichoice) package Horn contraction based on weak remainders is given by:
H p  = (Hp )
if  =
6   H 6 Cnh (>); and H otherwise.
The following result relates elements of Hp  to weak remainders.
Theorem 9 Let H be a Horn belief set and let  = {1 , . . . , n } be a set of Horn formulas
where for 1  i  n we have 6` i .
T
Then H 0  Hp  iff for 1  i  n there are Hi  He i and H 0 = ni=1 Hi .
It follows immediately from this that any maxichoice Horn contraction defines a package
contraction, and vice versa.
Corollary 1 Let p be an operator of maxichoice Horn package contraction. Then
H  = H p 

for  = {}

is an operator of maxichoice Horn contraction based on weak remainders.
Corollary 2 Let  be an operator of maxichoice Horn contraction based on weak remainders. Then
\
H p  =
H 


is an operator of maxichoice Horn package contraction.
Example 7 Consider the Horn belief set H = Cnh ({a, b}) over P = {a, b, c}. We want to
determine elements of
Hp  = Cnh ({a, b})p {a, b}.
There are a total of 14 elements in Hp  and so 14 candidate package contractions. These
candidates can be described as follows:
1. There are 4 countermodels of a, given by:
A = {bc, b, c, }.
Thus there are four weak remainders corresponding to these countermodels, and so
four candidates for maxichoice Horn contraction by a.
2. Similarly there are 4 countermodels of b:
B = {ac, a, c, }.
493

fiDelgrande & Wassermann

3. Members of Hp  are given by
Cl (M od(H)  {x}  {y})
for x  A and y  B.
For example, for x = bc, y = , we have that Cl (M od(H)  {x}  {y}) = {abc, ab, bc, b, },
which is the set of models of (c  b)  (a  b).
For x = bc, y = ac, we have that Cl (M od(H)  {x}  {y}) = Cnh (>); this holds for
no other choice of x and y.
What this example indicates informally is that there is a great deal of choice with respect
to candidates for package contraction. To some extent, such a combinatorial explosion of
possibilities is to be expected, given the fact that a formula will in general have a large
number of countermodels, and that this is compounded by the fact that each formula in a
package contraction will be associated with its own countermodel. However, it can also be
noted that some candidate package contractions contain redundancies, in that a selected
countermodel of a may also be a countermodel of b, in which case there seems to be no
reason to allow the possible incorporation of a separate countermodel of b. Consequently,
we also consider versions of package contraction that in some sense yield a maximal belief
set. However, first we provide results regarding package contraction.
We have the following result:
Theorem 10 Let H be a Horn belief set. Then p is an operator of maxichoice Horn
package contraction based on weak remainders iff p satisfies the following postulates:
(H p 1) H p  is a belief set.

(closure)

(H p 2) For   , if not ` , then  6 H p 

(success)

(H p 3) H p   H

(inclusion)

(H p 4) H p  = H p (H  )

(vacuity)

(H p 5) H p  = H p ( \ Cnh (>))

(failure)

(H p 5b) H p  = H

(triviality)

(H p 6) If   , then
H p (  {}) = H p (  {})

(extensionality)

(H p 7) If H 6= H p  then for
0 = ( \ Cnh (>))  H = {1 , . . . , n }
there is  = {1 , . . . , n } where for 1  i  n,
{i , i } `  and H p   Cnh (i ) and
H 0 s.t H p   H 0  H,    such that H 0 6 Cnh ()
494

(maximality)

fiHorn Clause Contraction Functions

With the exception of the last postulate, these postulates are clear and reasonable: As
usual, the result of package contraction is a belief set (H p 1). Moreover, each non-tautology
in a set  is not believed following contraction (H p 2), and no formulas are added (H p 3).
Contracting a formula not originally in H has no effect on the contraction (H p 4), as does
attempting to contract a tautology (H p 5). An empty contraction unsurprisingly has no
effect (H p 5b). As in other knowledge-level accounts, contraction is independent of the
syntactic expression of formulas to be contracted (H p 6). The last postulate (H p 7)
corresponds to the maximality postulate for contraction based on weak remainders. If a
package contraction H p  is nontrivial then each of the nontautologies in  that appear
in H satisfy the same maximality condition as the formula for contraction does for regular
Horn contraction based on weak remainder sets. That is, package contraction essentially
extends contraction to a set of formulas. This result is to be expected, given Theorem 9
which related elements of Hp  to weak remainders.
As discussed, a characteristic of maxichoice package contraction is that there are a large
number of members of Hp , some of which may be logically quite weak. However it proves
to be the case that we can eliminate some candidates via pragmatic concerns. We have that
a package contraction H p  is a belief set H 0  Hp  such that, informally, models of H 0
contain a countermodel for each i   along with models of H. In general, some interpretations will be countermodels of more than one member of , T
and so pragmatically, one can
select minimal sets of countermodels. Hence
in
the
case
that
i (M od(>) \ M od(i )) 6= , a
T
single countermodel, that is some m  i (M od(>) \ M od(i )), would be sufficient to yield
a package contraction.
T
Now, it may be that i (M od(>) \ M od(i )) is empty. A simple example illustrates this
case:
Example 8 Let H = Cnh (a  b, b  a) where P = {a, b}. Then H p {a  b, b  a} =
Cnh (>). That is, the sole countermodel of a  b is {a} while that of b  a is {b}. The
intersection closure of these interpretations with those of H is {ab, a, b, } = M od(>).
Informally one can get around this by simply selecting a minimal set of models such that
a countermodel of each member of  is in the set. These considerations yield the following
definition:
Definition 12 Let H be a Horn belief set, and let  = {1 , . . . , n } be a set of Horn
formulas.
HS(), the set of (minimal) hitting sets of interpretations with respect to , is defined
by:
S  HS() iff
1. S  |>|
2. For every 1  i  n where 6` i and i  H, S  (|>| \ |i |) 6= 
3. For S 0  S, S 0  (|>| \ |i |) =  for some 1  i  n.
Thus we look for sets of sets of interpretations; elements of such a set S are interpretations represented as maximal consistent sets of formulas (Condition 1). As well, this set S
495

fiDelgrande & Wassermann

contains a countermodel for each member of  (Condition 2) and moreover S is a subsetminimal set that satisfies these conditions (Condition 3). Thus S  HS() corresponds to
a minimal set of countermodels of members of . As an aside, it can be noted that the
notion of a hitting set is not new in general (Garey & Johnson, 1979) nor in AI (Reiter,
1987).
Definition 13 Hph  is the set of sets of formulas such that
T
H 0  Hph  iff H 0 = H  mS for some S  HS().
Definition 14 Let  be a selection function on H such that (Hph ) = {H 0 } for some
H 0  Hph .
Define:
H ph  = (Hph )
if  =
6   H 6 Cnh (>); and H otherwise.
The following result follows straightforwardly.
Theorem 11 H ph  is an operator of maxichoice Horn package contraction.
Example 9 Consider the case where H = Cnh (a, b), P = {a, b, c}.
1. Let  = {a, b}.
It can be verified that the hitting sets are given by:
{ {ac, bc}, {a, bc}, {ac, b}, {a, b}, {c}, {} }
The corresponding elements of Hph  are given by:
Hph  = { Cnh (>),
Cnh (c  a),
Cnh (c  b),
Cnh (c  a, c  b),
Cnh (a  b, b  a),
Cnh (a  b, b  a, c  a, c  b) }.
Compare this with Example 7, where we have 14 candidate package contractions.
2. Let  = {a, a  b}. We obtain that
Hph  = { Cnh (b),
Cnh (b  (c  a)),
Cnh (a  b, b  a),
Cnh (a  b, b  a, c  a, c  b) }.
496

fiHorn Clause Contraction Functions

Any set of formulas that satisfies Definition 13 clearly also satisfies Definition 11. One
can further restrict the set of candidate package contractions by replacing S 0  S by |S 0 | <
|S| in the third part of Definition 12. In this case, the package contraction in Example 9,
Part 1 would yield just the two candidates Cnh (a  b, b  a) and Cnh (a  b, b  a, c 
a, c  b). As well, of course, one could continue in the obvious fashion to define a notion of
partial meet Horn package contraction. Given the limited use of such an operator, we omit
the details.
6.2 Forgetting in Horn Formulas
This section examines another means of removing beliefs from an agents belief set, that
of forgetting (Lin & Reiter, 1994; Lang & Marquis, 2002). Forgetting is an operation on
belief sets and atoms of the language; the result of forgetting an atom can be regarded as
decreasing the language by that atom.
In addressing forgetting, it will be easier to work with a set of Horn clauses, rather
than Horn formulas. Since there is no confusion, we will freely switch between sets of Horn
clauses and the corresponding Horn formula comprising the conjunction of clauses in the
set. Thus any time that a set appears as an element in a formula, it can be understood
as standing for the conjunction of members
of the V
set. Thus for sets of clauses S1 and
V
S2 , S1  S2 will stand for the formula ( S1 )  ( S2 ). Of course, all such sets are
guaranteed to be finitely representable, since our language is finite.
We introduce the following notation for this section, where S is a set of Horn clauses,
and > is now taken as a distinguished atom true in all interpretations.
 For t  {, >}, S[p/t] is the result of uniformly substituting t for atom p in every
  S.
 Sp = {  S | p does not occur in }
Assume without loss of generality that for Horn clause   S, that head () 6 body().
The following definition adapts the standard definition, attributed to George Boole, to
forgetting in Horn clauses.
Definition 15 For set of Horn clauses S and atom p, define f orget(S, p) to be S[p/] 
S[p/>].
This is not immediately useful for us, since a disjunction is generally not Horn. However, the
next result shows that this definition nonetheless leads to a Horn-definable forget operator.
Recall that for clauses c1 and c2 , expressed as sets of literals where p  c1 and p  c2 , that
the resolvent of c1 and c2 is the clause (c1 \ {p})  (c2 \ {p}). As well, recall that if c1 and
c2 are Horn, then so is their resolvent.
In the following, Res(S, p) is the set of Horn clauses obtained from S by carrying out
all possible resolutions with respect to p.
Definition 16 Let S be a set of Horn clauses and p an atom. Define
Res(S, p) = { | 1 , 2  S such that
p  body(1 ) and p = head (2 ), and
 = (body(1 ) \ {p}  body(2 ))  head (1 )}
497

fiDelgrande & Wassermann

Theorem 12 f orget(S, p)  Sp  Res(S, p).
Corollary 3 Let S be a set of Horn clauses and p an atom. Then f orget(S, p) is equivalent
to a set of Horn clauses.
Corollary 4 Let S1 and S2 be sets of Horn clauses and p an atom. Then S1  S2 implies
that f orget(S1 , p)  f orget(S2 , p).
There are several points of interest about these results. The theorem is expressed in
terms of arbitrary sets of Horn clauses, and not just deductively-closed Horn belief sets.
Hence the second corollary states a principle of irrelevance of syntax for the case for forgetting for belief bases. As well, the expression Sp  Res(S, p) is readily computable, and so
the theorem in fact provides a means of computing f orget. Further, the approach clearly
iterates for more than one atom. We obtain the additional result:8
Corollary 5
f orget(f orget(S, p), q)  f orget(f orget(S, q), p).
Given this, we can define for a set of atoms A that f orget(S, ) = S and that
f orget(S, A) = f orget(f orget(S, a), A \ {a})
where a  A. On the other hand, forgetting an atom may result in a quadratic blowup of
the knowledge base.
Finally, it might seem that the approach allows for the definition of a revision operator
 and a procedure for computing a revision  by using something akin to the Levi Identity.
Let A() be the set of atoms appearing in (formula or set of formulas) . Then:
def

FRevise(S, ) = f orget(S, A()) + .
In fact, this does yield a revision operator, but an operator that in general is far too drastic
to be useful. To see this, consider a taxonomic knowledge base which asserts that whales
are fish, whale  f ish. Of course, whales are mammals, but in using the above definition
to repair the knowledge base, one would first forget all knowledge involving whales, for
example, that whales have fins, breathe air, give live birth, and so on. Such an example
doesnt prove that there are no reasonable revision operators definable via forget, but it does
show that a nave approach is problematic. Moreover, these problems are not particular to
Horn formulas, but rather any revision operator defined in terms of forgetting with respect
to any underlying logic would be similarly problematic.

7. Comparison among Constructions for Horn Contraction
This section provides a technical summary of the differences between the various contraction
operations defined on Horn belief sets:
 Every e-remainder is a weak remainder, but the converse is not true.
8. In fact, this is an easy consequence of the definition of forget.

498

fiHorn Clause Contraction Functions

This is clearly seen in Figure 1. For a Horn theory H and formula , the e-remainders are the
maximal subsets of H that do not imply . The weak remainders are characterised by the
models of H together with a single countermodel of , and then closed under intersection.
In propositional logic these notions would coincide; here they do not. As well, this means
that weak remainders and partial meet are distinct notions, the latter corresponding to
intersections of weak remainders.
Similarly, we obtain the following:
 Every e-remainder is an infra-remainder, but the converse is not true.
This is clear from Definition 3, and illustrated in Example 1.
We also have:
 Not all infra-remainders are weak-remainders.
Looking again at Figure 1, we see that the set Cnh ({c  a, c  b, a  b}) is an infraremainder but not a weak remainder. It can however be obtained as the intersection of two
remainders.
Consider Example 3.2 presented by Booth, Meyer and Varzinczak (2009), where H =
h
Cn ({p  q, q  r}) and one wants to contract by p  r: In this case, the weak remainders
coincide with the remainders. The set {p  q  r, p  r  q} is an infra-remainder and
cannot be obtained as the intersection of weak-remainders. The authors claim that this set
is a desirable result of the contraction, but do not give any strong motivation.
Last, we have:
 Not all weak remainders are infra-remainders.
Infra-remainders, by definition, must contain full-meet and be contained in some remainder.
Weak remainders are contained in some remainder (or are a remainder) but do not always
contain full meet, as can be seen in the table in Figure 1. Full-meet in that example would
contain {c  a, c  b} and there are two weak remainders (Cnh (a) and Cnh (b)) which do
not contain both formulas.
The last two items show that weak remainders and infra-remainders are independent
concepts and their relation should be studied in more detail. These various relations are
illustrated in Figure 2.

weak remainders

eremainders

Figure 2
499

infra remainders

fiDelgrande & Wassermann

The aforecited example of Booth, Meyer, and Varzinczak (2009) raises another point
that deserves attention: For H = Cnh ({p  q, q  r}), we have H e (p  r) = He (p 
r) = {Cnh ({p  q}), Cnh ({q  r, p  r  q})}. There is an asymmetry here  while
it is possible to obtain Cnh ({p  q}) as the result of contraction, e-remainders, weak
remainders or infra-remainders do not allow for Cnh ({q  r}) as a possible outcome. This
has motivated the study of Horn belief base contraction (Delgrande & Wassermann, 2010),
where one may obtain Cnh ({q  r}), and where we think we may find other interesting
alternatives.
Zhuang and Pagnucco have studied several forms of Horn Contraction, such as the
Epistemic Entrenchment Horn Contraction (EEHC) mentioned earlier (2010a), Transitively
Relational Partial-Meet Horn Contraction (TRPMHC) (2011) and Model-based Horn Contraction (MHC) (2012). These different operations are compared by Zhuang (2012). Partial
meet based on weak remainders is more general than EEHC and MHC. However, when the
selection function is required to be transitively relational, we obtain TRPMHC, which is
equivalent to MHC.

8. Conclusion
In this paper we have explored belief contraction, and operators related to belief contraction,
with respect to Horn theories. In the AGM approach there are two principal means of
constructing contraction functions, via remainders or maximal subsets of a belief set that fail
to imply a formula, and epistemic entrenchment, which incorporates a preference ordering
on formulas. Here we focus on Horn contraction functions that can be defined by remainderlike constructions.
It proves to be the case that basing contraction directly on remainder sets, yielding what
we call e-remainders, is problematic, in that the resulting approach is inexpressive and has
undesirable properties. We also show that an alternative that has been proposed, of infra
remainders suffers from the same problems. Based on an examination of model-theoretic
considerations we developed an account of maxichoice Horn contraction in terms of weak
remainder sets. The idea here is that the models of a contraction of a Horn belief set H by
a Horn formula  are given by the models of H together with a countermodel of , closed
under intersection (so as to yield a Horn theory). We then provided representation results
for maxichoice Horn contraction as well as partial meet contraction, and compared them to
other proposals in the literature.
We also study two other kinds of operators for giving up beliefs in Horn theories: package
contraction and forgetting. The former involves contracting by a set of formulas, so that no
formula in the set is believed, Again, we give a construction and postulate set, along with
a corresponding representation result. The second operator, forgetting, can be thought of
as a shrinking of the language of discourse.
This work is interesting since Horn clauses have found widespread use in areas such
as logic programming, rule-based systems, deductive databases, and description logics. As
well, since Horn reasoning is weaker than classical reasoning, this work sheds light on the
foundations of belief change. A natural topic for future work is to consider Horn revision
operators and study their relation to Horn contraction. A second topic for future work is
to consider belief change in other logics which do not contain classical propositional logic.
500

fiHorn Clause Contraction Functions

Acknowledgments
The first author was partially supported by a Canadian NSERC Discovery Grant. The
second author was partially supported by the Brazilian National Research Council (CNPq),
through grants 304043/2010-9 and 471666/2010-6. We thank Tommie Meyer, Marcio
Ribeiro, David Makinson, and the anonymous reviewers for their helpful comments.

Appendix A. Proofs of the Main Results
Theorem 2: Let  be a Horn contraction function defined via a selection function as in
(2) and based on (infra) remainder sets.
For   H and p inessential in H, we obtain that (H ) + p ` .
Proof: Let  = 1      n where each i is a Horn clause. For Horn conjunct i of ,
we have H e  |= p  i . (To see this, note first that i is a Horn clause, and so is of the
form body  a for conjunction of atoms body and atom a. Since body  a  H and H is a
Horn belief set, so also p  body  a  H. Since by assumption p is not in body, it follows
that p  body  a is in any remainder set of H with respect to . Then, p  body  a is
logically equivalent to p  (body  a), whence H e  |= p  i .) Thus (H e )  {p} |= i
or (H e ) + p |= i for each conjunct of , and so (H e ) + p |= . 
Theorem 3: Let a  P be an atom, and let H be a Horn belief set with a    H.
Let  be a maxichoice Horn contraction function based on remainder sets. Then for every
atom b, at least one of b and b   is in H (a  ) + a.
Proof: Suppose that for some atom b, neither of b and b   is in H (a  ) + a,
where a    H. Since a is an atom, a   is not a tautology, and as a    H,
by construction, H (a  ) is an element of H e (a  ). This, together with the
assumption b, b   6 H (a  ), gives us (1) (H (a  ))  {b} ` a   and (2)
(H (a  ))  {b  } ` a  . (Results (1) and (2) are a consequence of the fact
that since H (a  ) is a remainder set, it is a maximal set that fails to imply a  .)
From (1) and (2) together, we have that (H (a  )) ` a  , contradicting the success
postulate. 
Lemma 1 Let T be a set of propositional formulas. Then
Cl (M od(T )) = M od(Horn(Cn(T ))).
Proof:
We have that Cl (M od(T )) is the least set of models such that M od(T ) 
Cl (M od(T )) and where Cl (M od(T )) = M od(H) for some Horn theory H. But this
theory is just the least upper Horn approximation T h of T (Selman & Kautz, 1996), given
by
T h = { | T `  where  is a Horn prime implicate of T }.
We have that Cnh (T h ) = Horn(Cn(T )) from which the result follows. 
Theorem 4: For H a Horn belief set and  a Horn formula:
He  = H ||e .
Proof:
501

fiDelgrande & Wassermann

1. He   H ||e :
If  6 H or `  then He  = H ||e  = {H}.
So assume that   H and 6` .
Let H 0  He ; we show that H 0  H ||e .
Since H 0  He , by definition H 0 = H m for some m  |>|\||, and so M od(H 0 ) =
M od(H  m). H and m are Horn theories, thus H  m is a Horn theory.
Using the fact that for Horn belief set T , T = Horn(Cn(T )), we have that H  m =
Horn(Cn(H  m)) and so M od(H 0 ) = M od(Horn(Cn(H  m)).
Applying Lemma 1 to Hm we obtain that M od(Horn(Cn(Hm)) = Cl (M od(Cn(H
m))). Now, Cl (M od(Cn(Hm))) = Cl (M od(Hm)) = Cl ((M od(H)M od(m))).
By definition of m as a maximal consistent Horn theory, there is M  M od(>)
such that M od(m) = {M }. Putting the above together we get that M od(H 0 ) =
Cl ((M od(H)  M )), that is, H 0  H ||e .
2. H ||e   He :
This part follows immediately by essentially taking the preceding part in reverse order.


Lemma 2 Maximality (H w 7) is equivalent to the following property, which we will call
(H w 70 ):
If H 6= H w  then m  |>| \ || s.t. H w   m and H 0 s.t. H w   H 0  H we
have H 0 6 m.
Proof: It is straightforward to show that the property implies (H w 7): Let  be the
conjunction of literals appearing in m. Our language is finite, so  is a well-defined formula.
So Cnh () = m, and thus (H w 7) holds.
For the other direction, assume that (H w 7) holds.
Claim: For given H and , if  satisfies the conditions in (H w 7) then for any p  P,
either   p or   (p  ) also satisfies these conditions in (H w 7).
Proof of Claim: Clearly, if {, } is inconsistent then so is {,   l} for l 
{p, p  }; and if H    Cnh () then H 0  Cnh (  l) for l  {p, p  }.
So we just need to show that for Horn theory H 0 where H    H 0  H, either
H 0 6 Cnh (  p) or H 0 6 Cnh (  (p  )).
Towards a contradiction, assume otherwise. Then H 0  Cnh (  p) and H 0 
Cnh (  (p  )) and so H 0  Cnh (  p)  Cnh (  (p  )). But Cnh () =
Cnh (  p)  Cnh (  p  ), and consequently H 0  Cnh (). This contradicts
that  satisfies (H w 7) for H and .
Hence our assumption was incorrect, and so H 0 6 Cnh (  p) or H 0 6 Cnh ( 
(p  )).
502

fiHorn Clause Contraction Functions

We have just shown that if  satisfies (H w 7) for given H and , then so does one of
  p or   (p  ). An induction over (the finite set) P then establishes that if  satisfies
(H w 7) for given H and , then so does some  0 where  0 ` p or  0 ` (p  ) for every
p  P. Hence  0 is such that Cnh ( 0 )  |>| \ ||, and thus taking m = Cnh ( 0 ) satisfies the
property. 
Theorem 5: Let H be a Horn belief set. Then w is an operator of maxichoice Horn
contraction based on weak remainders iff w satisfies the following postulates.
(H w 1) H w  is a Horn belief set.

(closure)

(H w 2) If not ` , then  6 H w .

(success)

(H w 3) H w   H.

(inclusion)

(H w 4) If  6 H, then H w  = H.

(vacuity)

(H w 5) If `  then H w  = H

(failure)

(H w 6) If   , then H w  = H w .

(extensionality)

(H w 7) If H 6= H w  then   LHC such that {, } ` , H w   Cnh () and H 0
s.t H w   H 0  H we have H 0 
6 Cnh ().
(maximality)
Proof:
1. Construction to Postulates:
That the construction satisfies the first five postulates follows directly from the definitions of weak remainders and selection functions. To see that it satisfies (H w 6) we
only have to note that    implies that He  = He  and since  is a function,
H w  = H w .
To see that the construction satisfies (H w 7), suppose H 6= H w . This means that
He  6=  and hence, there is m  |>| \ || such that H w  = H  m. Let  be
the conjunction of all literals appearing in m. Then, since Cnh () = m, we have
that {, } is inconsistent, H w   Cnh () and H 0 s.t H w   H 0  H we have
H 0 6 Cnh ().
2. Postulates to Construction:
The proof uses (H w 70 ) rather than (H w 7), as they were shown to be equivalent in
Lemma 2.
Let w be an operator that satisfies Cn(H w 1)  (H w 70 ).
Let  be defined by (He ) = {H w }.
To show that  is a function:
503

fiDelgrande & Wassermann

Assume that He  = He ; we need to show that (He ) = (He ).
If  6 H, then He  = {H} and since He  = He , we have that
He  = H, and hence  6 H or ` . Then, by (H w 4) or (H w 5),
H w  = H w  = H and by definition (He ) = (He ).
Now let us consider the case where ,   H. Since He  = He  we have
that {H  m | m  |>| \ ||} = {H  m | m  |>| \ ||}.
It follows that |>| \ || = |>| \ ||. To see this, suppose that {H  m | m 
|>| \ ||} = {H  m | m  |>| \ ||} and |>| \ || =
6 |>| \ ||. Without loss
of generality, suppose there is m0  |>| \ || such that m0 6 |>| \ ||. Then
m0 is a maximal consistent theory that contains . Since   H, we know
that   H  m0 . This means that H  m0  {H  m | m  |>| \ ||}, but
H  m0 6 {H  m | m  |>| \ ||}, as for any m  |>| \ || by definition
 6 m. This contradicts the initial hypothesis.
Since |>| \ || = |>| \ || we get that || = || and so   . From (H w 6)
we have H w  = H w , and so (He ) = (He ).
If  6 H, then from (H w 4) we have that H w  = H. Similarly, if ` , then from
(H w 5) we again have that H w  = H.
Consequently assume that   H and not ` . We need to show that H w   He ,
that is, H w  = H  m for some m  |>| \ ||.
Since not ` , from (H w 2) we have  6 H w ; since   H we then have that
H 6= H w .
Since H 6= H w , from (H w 70 ) we get that there is m  |>| \ || such that H w  
m.
As well, (H w 3) gives H w   H, and so this with H w   m implies that H w  
(m  H).
We need to show that H w  = (m  H). Towards a contradiction assume that
H w  6= (m  H), that is to say, H w   (m  H).
Let   (m  H) \ (H w ). Then
H w   Cnh (H w   {})  m  H  H.
But, substituting Cnh (H w   {}) for H 0 in (H w 70 ) we get that Cnh (H w  
{}) 6 m, contradiction.
Hence the assumption that H w  6= (m  H) is incorrect; hence H w  = (m  H)
where (m  H)  He , which was to be shown. 
Theorem 6: Let H be a Horn belief set. Then pm is an operator of partial meet Horn
contraction based on weak remainders iff pm satisfies the postulates (H w 1)  (H w 6)
and:
(H pm 7) If   H \(H pm ), then there is some H 0 such that H pm   H 0 ,  6 Cnh (H 0 )
and   Cnh (H 0  {})
(weak relevance)
504

fiHorn Clause Contraction Functions

Proof:
1. Construction to Postulates:
(H w 1) follows from the fact that the intersection of Horn theories is a Horn theory. Postulates (H w 2)  (H w 6) follow immediately from the definitions of weak
remainder, selection function and partial meet contraction.
To see that the construction satisfies weak relevance, note that if   H \ H  ,
then there is some X  (He ) such that  6 X. Since   H, then there is some
m  |>| \ || such that  6 m and X = H  m. Take H 0 = m. Then H    H 0 ,
 6 Cnh (H 0 ) and   Cnh (H 0  {}) = Cnh ().
2. Postulates to Construction:
Let (He ) = {X  He  | H pm   X} if He  6=  and (He ) = {H}
otherwise.
T We have to show that: (1)  is a function; (2)  is a selection function;
and (3) (He ) = H  .
T
If  6 H, by (H w 4), H pm  = H = (He ). Assume then that   H.
(1) Let He 1 = He 2 . We must show that (He 1 ) = (He 2 ). As in the
proof for maxichoice contraction, He 1 = He 2 implies that 1  2 and then, by
Postulate (H w 6), H1 = H2 . By the construction of , (He 1 ) = (He 2 ).
(2) From the construction of , we know that (He )  He . So we have to show
that if He  6= , then (He ) 6= , and otherwise (He ) = {H}.
(i) If He  6= , then H 6=  and |>| \ || =
6 . By (H w 1) and (H w 2),
 6 Cn(H  ). Then there is m  |>| \ || such that H    m. By (H w 3),
H    H, hence, H    H  m  (H).
(ii) If He  = , then `  and by (H w 5), H   = H.
T
T
(3) We know thatTH    (He ). Suppose there is   (He ) such that
 6 H  . Since (He )  H,   H \ (H  ) and by weak relevance we know
that there is some H 0 such that H    H 0 ,  6 Cnh (H 0 ) and   Cnh (H 0  {}).
Then there is m  |>| \ || such that H 0  m and  6 m. Take X = H  m. Then
X  He  and from (H w 3) we have that H    X and hence, X  (He ).
But  6 X, which leads to a contradiction. 
Theorem 7: Partial meet based on weak remainders and a transitive relational selection
function satisfies (K 7) and (K 8).
Proof:
Let  be a selection function based on a transitive relation .
Since |>| \ |  | = (|>| \ ||)  (|>| \ ||) and hence, He    = He   He , in
order to show that PMWR satisfies postulate (K-7), it suffices to show that
(*) (He   )  (He )  (He ).9
9. This is called Choice-distributivity in the literature.

505

fiDelgrande & Wassermann

Take X  (He   ). We know that X  He  or X  He . Suppose that
X  He , we have to show that X  (He ). If X 6 (He ), then there is X 0  He 
such that X  X 0 . But then X 0  He    and X 6 (He   ). The case where
X  He  is analogous, thus X  (He ) or X  (He ), which proves (*).
In order to show that PMWR satisfies postulate (K-8), let  6 H    . We have to
show that
(**) (He )  (He   )
From  6 H     we know that (He   ) contains at least one element of He .
Since He   He    and  is based on , we have that (He )  (He   ). 
Theorem 8: PMWR satisfies (H 5).
Proof:
To see that PMWR satisfies (H 5), first we have to note that He   He  .
From   H    , we know that   X for every X  (He   ). We have to show
that   X for every X  (He     ). Let X  (He     ). If X 6 He   ,
then X = H  m for m a maximal, consistent Horn theory that does not contain     
but contains   . Hence,   X. Otherwise, i.e., if X  He   , we have to show that
X  (He   ). Suppose that X 6 (He   ), then there is X 0  He    such that
X 0 < X. But then X 0  He      and X cannot be an element of (He     ).
Hence, for every X  (He  ), we know that   X and therefore,   H  .

Theorem 9: Let H be a Horn belief set and let  = {1 , . . . , n } be a set of Horn formulas
where for 1  i  n we have 6` i .
T
Then H 0  Hp  iff for 1  i  n there are Hi  He i and H 0 = ni=1 Hi .
Proof: Let H be a Horn belief set and  = {1 , . . . , n }  LHC .
= Let H 0  Hp .
From Definition 10 we have that m1 , . . . , mn such that H 0 =

Tn

i=1 (H

 mi ) where

1. if i  H and 6` i then mi  |>| \ |i |;
2. otherwise mi = LHC .
For each i, 1  i  n, as above,
1. if i  H and 6` i then by Definition 4, Hi = H  mi satisfies the conditions for
Hi  He i ;
2. otherwise we have mi = LHC and so Hi = H  mi = H  LHC = H satisfies the
conditions for Hi  He i , again by Definition 4.
= Consider some i   and let Hi  He i .
From Definition 4 we have that
1. if i  H and 6` i then Hi = H  m for some m  |>| \ |i |;
506

fiHorn Clause Contraction Functions

2. if i 6 H or ` i then Hi = H or equivalently Hi = H  mi where mi = LHC .
T
Consequently for each i, 1  i  n, as above, H 0 = ni=1 Hi satisfies the conditions
for H 0  Hp  in Definition 10. 
Theorem 10: Let H be a Horn belief set. Then p is an operator of maxichoice Horn
package contraction based on weak remainders iff p satisfies the following postulates:
(H p 1) H p  is a belief set.

(closure)

(H p 2) For   , if not ` , then  6 H p 

(success)

(H p 3) H p   H

(inclusion)

(H p 4) H p  = H p (H  )

(vacuity)

(H p 5) H p  = H p ( \ Cnh (>))

(failure)

(H p 5b) H p  = H

(triviality)

(H p 6) If   , then
H p (  {}) = H p (  {})

(extensionality)

(H p 7) If H 6= H p  then for
0 = ( \ Cnh (>))  H = {1 , . . . , n }
there is  = {1 , . . . , n } where for 1  i  n,
{i , i } `  and H p   Cnh (i ) and
H 0 s.t H p   H 0  H,    such that H 0 6 Cnh ()

(maximality)

Proof:
1. Construction to Postulates:
(H p 1) is obvious.
For (H p 2), if   H, then Definition 10 ensures that for any H 0  Hp  that H 0 6` 
and so  6 H 0 .
For (H p 3) we have that H 0  Hp  implies that H 0 is of the form H  X; consequently H 0  H.
(H p 4) and (H p 5) are a direct consequence of the special cases in Definition 10 for
   where  6 H or `  respectively.
(H p 5b) is vacuously satisfied by Definition 10, while for (H p 6), the form of any
H 0  Hp  is easily seen to be independent of the syntactic form of members of .
For (H p 7), let X  Hp  where  = {1 , . . . , n }. By appeal to (H p 4) and
(H p 5) we can assume without loss of generality that    implies that 6`  and
  H. Let m1 , . . . , mn be as specified in Definition 10. Then m1 , . . . , mn satisfy
507

fiDelgrande & Wassermann

the conditions
T on 1 , . . . , n in (H p 7): Since mi  |>| \ |i |, so {i , i } ` . Since
X = H  ni=1 mi , so X  Cnh (mi ) = mi . Last, we need to show that for any belief
0
h
set H 0 where X  H 0  H, that for some mi in our list,
Tn H 6 Cn (mi ) = mi . But
this is a direct consequence of the fact that X = H  i=1 mi .
2. Postulates to Construction:
Let p satisfy Postulates (H p 1)(H p 7), and let H be a Horn belief set and  
LHC . Let  be as specified in (H p 7) and for   , define H   by:
(a) If `  or  6 H then H   = H.
(b) Otherwise for the    corresponding to , H   is the maximum set of
formulas such that H p   H    H and H    Cnh ().
Using Theorem 5, it is easily shown that  is an operator of maxichoice Horn contraction.
This implies that there is a selection function  such that H   = (He ) for every
  .
T
Therefore, by Theorem 9 we have that H p  =  H   = H 0 is such that
H 0  Hp . 
Theorem 12: f orget(S, p)  Sp  Res(S, p).
Proof: Let S be a finite set of nontautological Horn clauses. For p  P, define:
Sh = {c  S | p = head(c)}
Sb = {c  S | p  body(c)}
As well, we have already defined: Sp = {c  S | p does not occur in c}.
We obtain:
f orget(S, p)  S[p/]  S[p/>]
 (Sh [p/]  Sb [p/]  Sp [p/]) 
(Sh [p/>]  Sb [p/>]  Sp [p/>])
 (Sh [p/]  {>}  Sp )  ({>}  Sb [p/>]  Sp )
 (Sh [p/]  Sp )  (Sb [p/>]  Sp )
 Sp  (Sh [p/]  Sb [p/>])
 Sp  {c1  c2 | c1  Sh [p/] and c2  Sb [p/>]}
 Sp  Res(S, p) 

References
Alchourron, C. E., & Makinson, D. (1985). On the logic of theory change: Safe contraction.
Studia Logica, 44 (4), 405422.
508

fiHorn Clause Contraction Functions

Alchourron, C., Gardenfors, P., & Makinson, D. (1985). On the logic of theory change:
Partial  meet contraction and revision functions. Journal of Symbolic Logic, 50 (2),
510530.
Anderson, A., & Belnap Jr., N. (1975). Entailment: The Logic of Relevance and Necessity,
Vol. I. Princeton University Press.
Baader, F., Calvanese, D., McGuiness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2007).
The Description Logic Handbook (second edition). Cambridge University Press.
Booth, R., Meyer, T., Varzinczak, I., & Wassermann, R. (2011). On the Link between Partial
Meet, Kernel, and Infra Contraction and its Application to Horn Logic. Journal of
Artificial Intelligence Research, 42, 3153.
Booth, R., Meyer, T., & Varzinczak, I. (2009). Next steps in propositional Horn contraction.
In Proceedings of the International Joint Conference on Artificial Intelligence, pp.
702707, Pasadena, CA.
Creignou, N., Papini, O., Pichler, R., & Woltran, S. (2012). Belief revision within fragments
of propositional logic. In Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proceedings
of the Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning. AAAI Press.
Delgrande, J., & Wassermann, R. (2010). Horn clause contraction functions: Belief set and
belief base approaches. In Lin, F., & Sattler, U. (Eds.), Proceedings of the Twelfth International Conference on the Principles of Knowledge Representation and Reasoning,
pp. 143152, Toronto. AAAI Press.
Delgrande, J. (2008). Horn clause belief change: Contraction functions. In Brewka, G., &
Lang, J. (Eds.), Proceedings of the Eleventh International Conference on the Principles
of Knowledge Representation and Reasoning, pp. 156165, Sydney, Australia. AAAI
Press.
Delgrande, J., & Peppas, P. (2011). Revising Horn Theories. In Twenty-Second International
Joint Conference on Artificial Intelligence, pp. 839844.
Delgrande, J., & Wassermann, R. (2011). Topics in Horn contraction: Supplementary postulates, package contraction, and forgetting. In IJCAI-11 Workshop on Nonmonotonic
Reasoning, Action and Change (NRAC-11), pp. 8794, Barcelona, Spain.
Eiter, T., & Gottlob, G. (1992). On the complexity of propositional knowledge base revision,
updates, and counterfactuals. Artificial Intelligence, 57 (2-3), 227270.
Flouris, G., Plexousakis, D., & Antoniou, G. (2004). Generalizing the AGM postulates: Preliminary results and applications. In Proceedings of the 10th International Workshop
on Non-Monotonic Reasoning (NMR-04), pp. 171179, Whistler BC, Canada.
Gardenfors, P. (1988). Knowledge in Flux: Modelling the Dynamics of Epistemic States.
The MIT Press, Cambridge, MA.
Gardenfors, P., & Makinson, D. (1988). Revisions of knowledge systems using epistemic
entrenchment. In Proc. Second Theoretical Aspects of Reasoning About Knowledge
Conference, pp. 8395, Monterey, Ca.
509

fiDelgrande & Wassermann

Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-Completeness. W.H. Freeman and Co., New York.
Grove, A. (1988). Two Modellings for Theory Change. Journal of Philosophical Logic, 17,
157170.
Hansson, S. O. (1999). A Textbook of Belief Dynamics. Applied Logic Series. Kluwer
Academic Publishers.
Khardon, R. (1995). Translating between Horn representations and their characteristic
models. Journal of Artificial Intelligence Research, 3, 349372.
Lakemeyer, G., & Levesque, H. (2000). The Logic of Knowledge Bases. MIT Press, Cambridge, MA.
Lang, J., & Marquis, P. (2002). Resolving inconsistencies by variable forgetting. In Proceedings of the Eighth International Conference on the Principles of Knowledge Representation and Reasoning, pp. 239250, San Francisco. Morgan Kaufmann.
Langlois, M., Sloan, R., Szorenyi, B., & Turan, G. (2008). Horn complements: Towards
Horn-to-Horn belief revision. In Proceedings of the AAAI National Conference on
Artificial Intelligence, Chicago, Il.
Liberatore, P. (2000). Compilability and compact representations of revision of Horn knowledge bases. ACM Transactions on Computational Logic, 1 (1), 131161.
Lin, F., & Reiter, R. (1994). Forget it!. In AAAI Fall Symposium on Relevance, New
Orleans.
Makinson, D. (2009) Personal communication.
Peppas, P. (2008). Belief revision. In van Harmelen, F., Lifschitz, V., & Porter, B. (Eds.),
Handbook of Knowledge Representation, pp. 317359. Elsevier Science, San Diego,
USA.
Reiter, R. (1987). A theory of diagnosis from first principles. Artificial Intelligence, 32 (1),
5796.
Rott, H. (1992). On the logic of theory change: More maps between different kinds of
contraction functions. In Gardenfors, P. (Ed.), Belief Revision, No. 29 in Cambridge
Tracts in Theoretical Computer Science, pp. 122141. Cambridge University Press.
Selman, B., & Kautz, H. (1996). Knowledge compilation and theory approximation. Journal
of the ACM, 43 (2), 193224.
Zhuang, Z., & Pagnucco, M. (2010a). Horn contraction via epistemic entrenchment. In
Janhunen, T., & Niemela, I. (Eds.), Logics in Artificial Intelligence - 12th European
Conference (JELIA 2010), Vol. 6341 of Lecture Notes in Artificial Intelligence, pp.
339351. Springer Verlag.
Zhuang, Z., & Pagnucco, M. (2010b). Two methods for constructing Horn contractions.
In Li, J. (Ed.), AI 2010: Advances in Artificial Intelligence - 23rd Australasian Joint
Conference, Vol. 6464 of Lecture Notes in Artificial Intelligence, pp. 7281. Springer
Verlag.
510

fiHorn Clause Contraction Functions

Zhuang, Z. (2012). Belief Change Under the Horn Fragment of Propositional Logic. Ph.D.
thesis, School of Computer Science and Engineering  University of New South Wales.
Zhuang, Z., & Pagnucco, M. (2011). Transitively relational partial meet Horn contraction.
In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, pp. 11321138, Barcelona, Spain.
Zhuang, Z., & Pagnucco, M. (2012). Model based Horn contraction. In Proceedings of the
Thirteenth International Conference on the Principles of Knowledge Representation
and Reasoning, Rome, Italy.

511

fiJournal of Artificial Intelligence Research 48 (2013) 671-715

Submitted 04/13; published 11/13

Generating Natural Language Descriptions from OWL
Ontologies: the NaturalOWL System
Ion Androutsopoulos

ion@aueb.gr

Department of Informatics,
Athens University of Economics and Business, Greece
Digital Curation Unit  Institute for the Management of Information Systems,
Research Centre Athena, Athens, Greece

Gerasimos Lampouras

lampouras06@aueb.gr

Department of Informatics,
Athens University of Economics and Business, Greece

Dimitrios Galanis

galanisd@aueb.gr

Department of Informatics,
Athens University of Economics and Business, Greece
Institute for Language and Speech Processing,
Research Centre Athena, Athens, Greece

Abstract
We present Naturalowl, a natural language generation system that produces texts
describing individuals or classes of owl ontologies. Unlike simpler owl verbalizers, which
typically express a single axiom at a time in controlled, often not entirely fluent natural
language primarily for the benefit of domain experts, we aim to generate fluent and coherent multi-sentence texts for end-users. With a system like Naturalowl, one can publish
information in owl on the Web, along with automatically produced corresponding texts
in multiple languages, making the information accessible not only to computer programs
and domain experts, but also end-users. We discuss the processing stages of Naturalowl,
the optional domain-dependent linguistic resources that the system can use at each stage,
and why they are useful. We also present trials showing that when the domain-dependent
linguistic resources are available, Naturalowl produces significantly better texts compared
to a simpler verbalizer, and that the resources can be created with relatively light effort.

1. Introduction
Ontologies play a central role in the Semantic Web (Berners-Lee, Hendler, & Lassila, 2001;
Shadbolt, Berners-Lee, & Hall, 2006). Each ontology provides a conceptualization of a
knowledge domain (e.g., consumer electronics) by defining the classes and subclasses of the
individuals (entities) in the domain, the types of possible relations between them etc. The
current standard to specify Semantic Web ontologies is owl (Horrocks, Patel-Schneider,
& van Harmelen, 2003), a formal language based on description logics (Baader, Calvanese,
McGuinness, Nardi, & Patel-Schneider, 2002), rdf, and rdf schema (Antoniou & van
Harmelen, 2008), with owl2 being the latest version of owl (Grau, Horrocks, Motik, Parc
2013
AI Access Foundation. All rights reserved.

fiAndroutsopoulos, Lampouras, & Galanis

sia, Patel-Schneider, & Sattler, 2008). Given an owl ontology for a knowledge domain, one
can publish on the Web machine-readable data pertaining to that domain (e.g., catalogues of
products, their features etc.), with the data having formally defined semantics based on the
conceptualization of the ontology.1 Following common practice in Semantic Web research,
we actually use the term ontology to refer jointly to terminological knowledge (TBox) that
establishes a conceptualization of a knowledge domain, and assertional knowledge (ABox)
that describes particular individuals.
Several equivalent owl syntaxes have been developed, but people unfamiliar with formal
knowledge representation often have difficulties understanding them (Rector, Drummond,
Horridge, Rogers, Knublauch, Stevens, Wang, & Wroe, 2004). For example, the following
statement defines the class of St. Emilion wines, using the functional-style syntax of owl,
one of the easiest to understand, which we also adopt throughout this article.2
EquivalentClasses(:StEmilion
ObjectIntersectionOf(:Bordeaux
ObjectHasValue(:locatedIn :stEmilionRegion) ObjectHasValue(:hasColor :red)
ObjectHasValue(:hasFlavor :strong)
ObjectHasValue(:madeFrom :cabernetSauvignonGrape)
ObjectMaxCardinality(1 :madeFrom)))

To make ontologies easier to understand, several ontology verbalizers have been developed
(Schwitter, 2010a). Verbalizers usually translate the axioms (in our case, owl statements) of
the ontology one by one to controlled, often not entirely fluent English statements, typically
without considering the coherence of the resulting texts, and mostly for the benefit of domain
experts. By contrast, in this article we present a system that aims to produce fluent and
coherent multi-sentence texts describing classes or individuals of owl ontologies, with the
texts intended to be read by end-users (e.g., customers of on-line retail sites). For example,
our system can generate the following text from the owl statement above, if the ontology
has been annotated with domain-dependent linguistic resources discussed below.
St. Emilion is a kind of Bordeaux from the St. Emilion region. It has red color and strong flavor. It is
made from exactly one grape variety: Cabernet Sauvignon grapes.

Our system, called Naturalowl, is open-source and supports both English and Greek.
Hence, Greek texts can also be generated from the same owl statements, as in the following
product description, provided that appropriate Greek linguistic resources are also available.
By contrast, owl verbalizers typically produce only English (or English-like) sentences.
ClassAssertion(:Laptop :tecraA8)
ObjectPropertyAssertion(:manufacturedBy :tecraA8 :toshiba)
ObjectPropertyAssertion(:hasProcessor :tecraA8 :intelCore2)
DataPropertyAssertion(:hasMemoryInGB :tecraA8 "2"^^xsd:nonNegativeInteger)
DataPropertyAssertion(:hasHardDiskInGB :tecraA8 "110"^^xsd:nonNegativeInteger)
DataPropertyAssertion(:hasSpeedInGHz :tecraA8 "2"^^xsd:float)
DataPropertyAssertion(:hasPriceInEuro :tecraA8 "850"^^xsd:nonNegativeInteger)

[English description:] Tecra A8 is a laptop, manufactured by Toshiba. It has an Intel Core 2 processor,
2 gb ram and a 110 gb hard disk. Its speed is 2 ghz and it costs 850 Euro.
1. See http://owl.cs.manchester.ac.uk/repository/ for a repository of owl ontologies.
2. Consult http://www.w3.org/TR/owl2-primer/ for an introduction to the functional-style syntax of owl.

672

fiGenerating Natural Language Descriptions from OWL Ontologies

[Greek description:]  Tecra A8    ,    Toshiba.
  Intel Core 2, 2 gb ram    110 gb.     2 ghz 
 850 .

The examples above illustrate how a system like Naturalowl can help publish information on the Web both as owl statements and as texts generated from the owl statements.
This way, information becomes easily accessible to both computers, which can process
the owl statements, and end-users speaking different languages; and changes in the owl
statements can be automatically reflected in the texts by regenerating them. To produce
fluent, coherent multi-sentence texts, Naturalowl relies on natural language generation
(nlg) methods (McKeown, 1985; Reiter & Dale, 2000) to a larger extent compared to existing owl verbalizers; for example, it includes mechanisms to avoid repeating information,
to order the facts to be expressed, aggregate smaller sentences into longer ones, generate
referring expressions etc. Although nlg is an established area, this is the first article to
discuss in detail an nlg system for owl ontologies, excluding simpler verbalizers. We do
not propose novel algorithms from a theoretical nlg perspective, but we show that there are
several particular issues that need to be considered when generating from owl ontologies.
For example, some owl statements lead to overly complicated sentences, unless they are
converted to simpler intermediate representations first; there are also several owl-specific
opportunities to aggregate sentences (e.g., when expressing axioms about the cardinalities
of properties); and referring expression generation can exploit the class hierarchy.
Naturalowl can be used with any owl ontology, but to obtain texts of high quality
domain-dependent generation resources are required; for example, the classes of the ontology
can be mapped to natural language names, the properties to sentence plans etc. Similar
linguistic resources are used in most nlg systems, though different systems adopt different
linguistic theories and algorithms, requiring different resources. There is little consensus on
exactly what information nlg resources should capture, apart from abstract specifications
(Mellish, 2010). The domain-dependent generation resources of Naturalowl are created
by a domain author, a person familiar with owl, when the system is configured for a new
ontology. The domain author uses the Protege ontology editor and a Protege plug-in that
allows editing the domain-dependent generation resources and invoking Naturalowl to view
the resulting texts.3 We do not discuss the plug-in in this article, since it is very similar to
the authoring tool of m-piro (Androutsopoulos, Oberlander, & Karkaletsis, 2007).
owl ontologies often use English words or concatenations of words (e.g., manufacturedBy)
as identifiers of classes, properties, and individuals. Hence, some of the domain-dependent
generation resources can often be extracted from the ontology by guessing, for example,
that a class identifier like Laptop in our earlier example is a noun that can be used to refer
to that class, or that a statement of the form ObjectPropertyAssertion(:manufacturedBy X
Y ) should be expressed in English as a sentence of the form X was manufactured by Y .
Most owl verbalizers follow this strategy. Similarly, if domain-dependent generation resources are not provided, Naturalowl attempts to extract them from the ontology, or it uses
3. Consult http://protege.stanford.edu/ for information on Protege. Naturalowl and its Protege plugin are freely available from http://nlp.cs.aueb.gr/software.html. We describe Naturalowl version 2
in this article; version 1 (Galanis & Androutsopoulos, 2007) used a less principled representation of its
domain-dependent generation resources, without supporting owl2.

673

fiAndroutsopoulos, Lampouras, & Galanis

generic resources. The resulting texts, however, are of lower quality; also, non-English texts
cannot be generated, if the identifiers of the ontology are English-like. There is a tradeoff
between reducing the effort to construct domain-dependent generation resources for owl
ontologies, and obtaining higher-quality texts in multiple languages, but this tradeoff has
not been investigated in previous work. We present trials we performed to measure the
effort required to construct the domain-dependent generation resources of Naturalowl and
the extent to which they improve the resulting texts, also comparing against a simpler
verbalizer that requires no domain-dependent generation resources. The trials show that
the domain-dependent generation resources help Naturalowl produce significantly better
texts, and that the resources can be constructed with relatively light effort, compared to
the effort typically needed to construct an ontology.
Overall, the main contributions of this article are: (i) it is the first detailed discussion of
a complete, general-purpose nlg system for owl ontologies and the particular issues that
arise when generating from owl ontologies; (ii) it shows that a system that relies on nlg
methods to a larger extent, compared to simpler owl verbalizers, can produce significantly
better natural language descriptions of classes and individuals, provided that appropriate
domain-dependent generation resources are available; (iii) it shows how the descriptions can
be generated in more than one languages, again provided that appropriate resources are
available; (iv) it shows that the domain-dependent generation resources can be constructed
with relatively light effort. As already noted, this article does not present novel algorithms
from a theoretical nlg perspective. In fact, some of the algorithms that Naturalowl uses
are of a narrower scope, compared to more fully-fledged nlg algorithms. Nevertheless, the
trials show that the system produces texts of reasonable quality, especially when domaindependent generation resources are provided. We hope that if Naturalowl contributes
towards a wider adoption of nlg methods on the Semantic Web, other researchers may
wish to contribute improved components, given that Naturalowl is open-source.
Naturalowl is based on ideas from ilex (ODonnell, Mellish, Oberlander, & Knott,
2001) and m-piro (Isard, Oberlander, Androutsopoulos, & Matheson, 2003). The ilex
project developed an nlg system that was demonstrated mostly with museum exhibits, but
did not support owl.4 The m-piro project produced a multilingual extension of the system
of ilex, which was tested in several domains (Androutsopoulos et al., 2007). Attempts to
use the generator of m-piro with owl, however, ran into problems (Androutsopoulos,
Kallonis, & Karkaletsis, 2005). By contrast, Naturalowl was especially developed for owl.
In the remainder of this article, we assume that the reader is familiar with rdf, rdf
schema, and owl. Readers unfamiliar with the Semantic Web may wish to consult an
introductory text first (Antoniou & van Harmelen, 2008).5 We also note that the recently
very popular Linked Data are published and interconnected using Semantic Web technologies.6 Most Linked Data currently use only rdf and rdf schema, but owl is in effect a
superset of rdf schema and, hence, the work of this paper also applies to Linked Data.
4. Dale et al. (1998) and Dannels (2008, 2012) also discuss nlg for museums.
5. A longer version of this article, with more background for readers who are unfamiliar with owl and the
Semantic Web, is available as a technical report (Androutsopoulos, Lampouras, & Galanis, 2012); see
http://nlp.cs.aueb.gr/publications.html.
6. Consult http://linkeddata.org/. See also the work of Duma and Klein (2013).

674

fiGenerating Natural Language Descriptions from OWL Ontologies

Section 2 below briefly discusses some related work; we provide further pointers to
related work in the subsequent sections. Section 3 then explains how Naturalowl generates
texts, also discussing the domain-dependent generation resources of each processing stage.
Section 4 describes the trials we performed to measure the effort required to construct the
domain-dependent generation resources and their impact on the quality of the generated
texts. Section 5 concludes and proposes future work.

2. Related Work
We use the functional-style syntax of owl in this article, but several equivalent owl syntaxes exist. There has also been work to develop controlled natural languages (cnls), mostly
English-like, to be used as alternative owl syntaxes. Sydney owl Syntax (sos) (Cregan,
Schwitter, & Meyer, 2007) is an English-like cnl with a bidirectional mapping to and from
the functional-style syntax of owl; sos is based on peng (Schwitter & Tilbrook, 2004).
A similar bidirectional mapping has been defined for Attempto Controlled English (ace)
(Kaljurand, 2007). Rabbit (Denaux, Dimitrova, Cohn, Dolbear, & Hart, 2010) and clone
(Funk, Tablan, Bontcheva, Cunningham, Davis, & Handschuh, 2007) are other owl cnls,
mostly intended to be used by domain experts when authoring ontologies (Denaux, Dolbear,
Hart, Dimitrova, & Cohn, 2011). We also note that some owl cnls cannot express all the
kinds of owl statements (Schwitter, Kaljurand, Cregan, Dolbear, & Hart, 2008).
Much work on owl cnls focuses on ontology authoring and querying (Bernardi, Calvanese, & Thorne, 2007; Kaufmann & Bernstein, 2010; Schwitter, 2010b); the emphasis is
mostly on the direction from cnl to owl or query languages.7 More relevant to our work
are cnls like sos and ace, to which automatic mappings from normative owl syntaxes are
available. By feeding an owl ontology expressed, for example, in functional-style syntax
to a mapping that translates to an English-like cnl, all the axioms of the ontology can be
turned into English-like sentences. Systems of this kind are often called ontology verbalizers.
This term, however, also includes systems that translate from owl to English-like statements that do not belong in an explicitly defined cnl (Halaschek-Wiener, Golbeck, Parsia,
Kolovski, & Hendler, 2008; Schutte, 2009; Power & Third, 2010; Power, 2010; Stevens,
Malone, Williams, Power, & Third, 2011; Liang, Stevens, Scott, & Rector, 2011b).
Although verbalizers can be viewed as performing a kind of light nlg, they typically
translate axioms one by one, as already noted, without considering the coherence (or topical cohesion) of the resulting texts, usually without aggregating sentences nor generating
referring expressions, and often by producing sentences that are not entirely fluent or natural. For example, ace and sos occasionally use variables instead of referring expressions
(Schwitter et al., 2008). Also, verbalizers typically do not employ domain-dependent generation resources and typically do not support multiple languages. Expressing the exact
meaning of the axioms of the ontology in an unambiguous manner is considered more important in verbalizers than composing a fluent and coherent text in multiple languages,
partly because the verbalizers are typically intended to be used by domain experts.
7. Conceptual authoring or wysiwym (Power & Scott, 1998; Hallett, Scott, & Power, 2007), which has been
applied to owl (Power, 2009), and round-trip authoring (Davis, Iqbal, Funk, Tablan, Bontcheva, Cunningham, & Handschuh, 2008) are bidirectional, but focus mostly on ontology authoring and querying.

675

fiAndroutsopoulos, Lampouras, & Galanis

Figure 1: The processing stages and sub-stages of Naturalowl.
Some verbalizers use ideas and methods from nlg. For example, some verbalizers include
sentence aggregation (Williams & Power, 2010) and text planning (Liang, Scott, Stevens, &
Rector, 2011a). Overall, however, nlg methods have been used only to a very limited extent
with owl ontologies. A notable exception is ontosum (Bontcheva, 2005), which generates
natural language descriptions of individuals, but apparently not classes, from rdf schema
and owl ontologies. It is an extension of miakt (Bontcheva & Wilks, 2004), which was
used to generate medical reports. Both were implemented in gate (Bontcheva, Tablan,
Maynard, & Cunningham, 2004) and they provide graphical user interfaces to manipulate
domain-dependent generation resources (Bontcheva & Cunningham, 2003). No detailed
description of ontosum appears to have been published, however, and the system does
not seem to be publicly available, unlike Naturalowl. Also, no trials of ontosum with
independently created ontologies seem to have been published. More information on how
ontosum compares to Naturalowl can be found elsewhere (Androutsopoulos et al., 2012).
Mellish and Sun (2006) focus on lexicalization and sentence aggregation, aiming to
produce a single aggregated sentence from an input collection of rdf triples; by contrast,
Naturalowl produces multi-sentence texts. In complementary work, Mellish et al. (2008)
consider content selection for texts describing owl classes. Unlike Naturalowl, their system
does not express only facts that are explicit in the ontology, but also facts deduced from
the ontology. Nguyen et al. (2012) discuss how the proof trees of facts deduced from owl
ontologies can be explained in natural language. It would be particularly interesting to
examine how deduction and explanation mechanisms could be added to Naturalowl.

3. The Processing Stages and Resources of NaturalOWL
Naturalowl adopts a pipeline architecture, which is common in nlg (Reiter & Dale, 2000),
though the number and purpose of its components often vary (Mellish, Scott, Cahill, Paiva,
Evans, & Reape, 2006). Our system generates texts in three stages, document planning,
micro-planning, and surface realization, discussed in the following sections; see Figure 1.
3.1 Document Planning
Document planning consists of content selection, where the system selects the information
to convey, and text planning, where it plans the structure of the text to be generated.
3.1.1 Content Selection
In content selection, the system first retrieves from the ontology all the owl statements
that are relevant to the class or individual to be described, it then converts the selected
676

fiGenerating Natural Language Descriptions from OWL Ontologies

owl statements to message triples, which are easier to express as sentences, and it finally
selects among the message triples the ones to be expressed.
OWL statements for individual targets
Let us first consider content selection when Naturalowl is asked to describe an individual
(an entity), and let us call that individual the target. The system scans the owl statements
of the ontology, looking for statements of the forms listed in the left column of Table 1.8
In effect, it retrieves all the statements that describe the target directly, as opposed to
statements describing another individual or a (named) class the target is related to.
owl allows arbitrarily many nested ObjectUnionOf and ObjectIntersectionOf operators, which may lead to statements that are very difficult to express in natural language.
To simplify text generation and to ensure that the resulting texts are easy to comprehend,
we do not allow nested ObjectIntersectionOf and ObjectUnionOf operators in the ontologies the texts are generated from. In Table 1, this restriction is enforced by requiring class
identifiers to appear at some points where owl also allows expressions that construct unnamed classes using operators. If an ontology uses unnamed classes at points where Table 1
requires class identifiers (named classes), it can be easily modified to comply with Table 1
by defining new named classes for nested unnamed ones.9 In practice, nested ObjectUnionOf
and ObjectIntersectionOf operators are rare; see the work of Power et al. (Power, 2010;
Power & Third, 2010; Power, 2012) for information of the frequencies of different types of
owl statements.10
Statements of the form ClassAssertion(Class target ) may be quite complex, because
Class is not necessarily a class identifier. It may also be an expression constructing an
unnamed class, as in the following example. This is why there are multiple rows for
ClassAssertion in Table 1.
ClassAssertion(
ObjectIntersectionOf(:Wine
ObjectHasValue(:locatedIn :stEmilionRegion)
ObjectHasValue(:hasColor :red)
ObjectHasValue(:madeFrom :cabernetSauvignonGrape)
:chateauTeyssier2007)

ObjectHasValue(:hasFlavor :strong)
ObjectMaxCardinality(1 :madeFrom))

Naturalowl would express the owl statement above by generating a text like the following.
The 2007 Chateau Teyssier is a wine from the St. Emilion region. It has red color and strong flavor. It
is made from exactly one grape variety: Cabernet Sauvignon grapes.

Recall that the texts of Naturalowl are intended to be read by end-users. Hence, we
prefer to generate texts that may not emphasize enough some of the subtleties of the owl
8. Some owl statements shown in Table 1 with two arguments can actually have more arguments, but they
can be converted to the forms shown.
9. It is also easy to automatically detect nested unnamed classes and replace them, again automatically,
by new named classes (classes with owl identifiers). The domain author would have to be consulted,
though, to provide meaningful owl identifiers for the new classes (otherwise arbitrary identifiers would
have to be used) and natural language names for the new classes (see Section 3.2.1 below).
10. One could also refactor some nested operators; for example, t  ((A  B)  (C  D)) is equivalent to
t  (A  B) and t  (C  D). The conversion to message triples, to be discussed below, in effect
also performs some refactoring, but it cannot cope with all the possible nested union and intersection
operators, which is why we disallow them as a general rule.

677

fiAndroutsopoulos, Lampouras, & Galanis
owl statements

Message triples

ClassAssertion(NamedClass target )
ClassAssertion(
ObjectComplementOf(NamedClass ) target )
ClassAssertion(
ObjectOneOf(indiv1 indiv2 ...) target )
ClassAssertion(
ObjectHasValue(objProp indiv ) target )
ClassAssertion(
ObjectHasValue(dataProp dataValue ) target )
ClassAssertion(ObjectHasSelf(objProp ) target )
ClassAssertion(
ObjectMaxCardinality(number prop [NamedClass ])
target )
ClassAssertion(
ObjectMinCardinality(number prop [NamedClass ])
target )
ClassAssertion(
ObjectExactCardinality(number prop [NamedClass ])
target )
ClassAssertion(
ObjectSomeValuesFrom(objProp NamedClass ) target )
ClassAssertion(
ObjectAllValuesFrom(objProp NamedClass ) target )
ClassAssertion(
ObjectIntersectionOf(C1 C2 ...) target )

<target, instanceOf, NamedClass >

ClassAssertion(
ObjectUnionOf(C1 C2 ...)

target )

ObjectPropertyAssertion(objProp target indiv )
DataPropertyAssertion(dataProp target dataValue )
NegativeObjectPropertyAssertion(
objProp target indiv )
NegativeDataPropertyAssertion(
dataProp target dataValue )
DifferentIndividuals(target indiv )
DifferentIndividuals(indiv target )
SameIndividual(target indiv )
SameIndividual(indiv target )

<target, not(instanceOf), NamedClass >
<target, oneOf,
or(indiv1, indiv2, ...)>
<target, objProp, indiv >
<target, dataProp, dataValue >
<target, objProp, target >
<target, maxCardinality(prop ),
number [:NamedClass ]>
<target, minCardinality(prop ),
number [:NamedClass ]>
<target, exactCardinality(prop ),
number [:NamedClass ]>
<target, someValuesFrom(objProp ),
NamedClass >
<target, allValuesFrom(objProp ),
NamedClass >
convert (ClassAssertion(C1 target ))
convert (ClassAssertion(C2 target )) ...
or(convert (ClassAssertion(C1 target )),
convert (ClassAssertion(C2 target )),
...)
<target, objProp, indiv >
<target, dataProp, dataValue >
<target, not(objProp ), indiv >
<target, not(dataProp ), dataValue >
<target,
<target,
<target,
<target,

differentIndividuals, indiv >
differentIndividuals, indiv >
sameIndividual, indiv >
sameIndividual, indiv >

Notation: Square brackets indicate optional arguments, and convert () a recursive application of the
conversion to . NamedClass is a class identifier; objProp , dataProp , and prop are identifiers of object
properties, datatype properties, and properties; indiv , indiv1 , . . . are identifiers of individuals;
dataValue is a datatype value; and C , C1 , . . . are class identifiers, or expressions constructing classes
without ObjectIntersectionOf or ObjectUnionOf.

Table 1: owl statements for an individual target, and the corresponding message triples.
statements, in order to produce more readable texts. An owl expert might prefer, for
example, the following description of chateauTeyssier2007, which mirrors more closely the
corresponding owl statements.
The 2007 Chateau Teyssier is a member of the intersection of: (a) the class of wines, (b) the class of
individuals from (not necessarily exclusively) the St. Emilion region, (c) the class of individuals that have
(not necessarily exclusively) red color, (d) the class of individuals that have (not necessarily exclusively)
strong flavor, (e) the class of individuals that are made exclusively from Cabernet Sauvignon grapes.

678

fiGenerating Natural Language Descriptions from OWL Ontologies

Stricter texts of this kind, however, seem inappropriate for end-users. In fact, it could be
argued that even mentioning that the wine is made from exactly one grape variety in the
text that Naturalowl produces is inappropriate for end-users. Our system can be instructed
to avoid mentioning this information via user modeling annotations, discussed below.
OWL statements for class targets
If the system is asked to describe a class, rather than an individual, it scans the ontology
for statements of the forms listed in the left column of Table 2. The class to be described
must be a named one, meaning that it must have an owl identifier, and Target denotes
its identifier. Again, to simplify the generation process and to avoid producing complicated
texts, Table 2 requires class identifiers to appear at some points where owl also allows
expressions that construct unnamed classes using operators. If an ontology uses unnamed
classes at points where Table 2 requires class identifiers, it can be easily modified.
In texts describing classes, it is difficult to express informally the difference between
EquivalentClasses and SubClassOf. EquivalentClasses(C1 C2 ) means that any individual
of C1 also belongs in C2 , and vice versa. By contrast, SubClassOf(C1 C2 ) means that any
member of C1 also belongs in C2 , but the reverse is not necessarily true. If we replace
EquivalentClasses by SubClassOf in the definition of StEmilion of page 672, any member
of StEmilion is still necessarily also a member of the intersection, but a wine with all the
characteristics of the intersection is not necessarily a member of StEmilion. Consequently,
one should perhaps add sentences like the ones shown in italics below, when expressing
EquivalentClasses and SubClassOf, respectively.
St. Emilion is a kind of Bordeaux from the St. Emilion region. It has red color and strong flavor. It is
made from exactly one grape variety: Cabernet Sauvignon grapes. Every St. Emilion has these properties,
and anything that has these properties is a St. Emilion.
St. Emilion is a kind of Bordeaux from the St. Emilion region. It has red color and strong flavor. It is
made from exactly one grape variety: Cabernet Sauvignon grapes. Every St. Emilion has these properties,
but something may have these properties without being a St. Emilion.

Naturalowl produces the same texts, without the sentences in italics, for both SubClassOf
and EquivalentClasses, to avoid generating texts that sound too formal. Also, it may
not mention some of the information of the ontology about a target class (e.g., that a St.
Emilion has strong flavor), when user modeling indicates that this information is already
known or that the text should not exceed a particular length. Hence, the generated texts
express necessary, not sufficient conditions for individuals to belong in the target class.
OWL statements for second-level targets
In some applications, expressing additional owl statements that are indirectly related
to the target may be desirable. Let us assume, for example, that the target is the individual
exhibit24, and that the following directly relevant statements have been retrieved from the
ontology. Naturalowl would express them by generating a text like the one below.
ClassAssertion(:Aryballos :exhibit24)
ObjectPropertyAssertion(:locationFound :exhibit24 :heraionOfDelos)
ObjectPropertyAssertion(:creationPeriod :exhibit24 :archaicPeriod)
ObjectPropertyAssertion(:paintingTechniqueUsed :exhibit24 :blackFigureTechnique)
ObjectPropertyAssertion(:currentMuseum :exhibit24 :delosMuseum)

679

fiAndroutsopoulos, Lampouras, & Galanis
owl statements

Message triples

EquivalentClasses(Target C )
EquivalentClasses(C Target )
SubClassOf(Target NamedClass )
SubClassOf(Target ObjectComplementOf(NamedClass ))
SubClassOf(Target
ObjectOneOf(indiv1 indiv2 ...))
SubClassOf(Target ObjectHasValue(objProp indiv ))
SubClassOf(Target
ObjectHasValue(dataProp dataValue ))
SubClassOf(Target ObjectHasSelf(objProp ))
SubClassOf(Target
ObjectMaxCardinality(number prop [NamedClass ]))
SubClassOf(Target
ObjectMinCardinality(number prop [NamedClass ]))
SubClassOf(Target
ObjectExactCardinality(number prop [NamedClass ]))
SubClassOf(Target
ObjectSomeValuesFrom(objProp NamedClass ))
SubClassOf(Target
ObjectAllValuesFrom(objProp NamedClass ))
SubClassOf(Target
ObjectIntersectionOf(C1 C2 ...))

convert (SubClassOf(Target C ))
convert (SubClassOf(Target C ))
<Target, isA, NamedClass >
<Target, not(isA), NamedClass >
<Target, oneOf,
or(indiv1, indiv2, ...)>
<Target, objProp, indiv >

SubClassOf(Target
ObjectUnionOf(C1 C2 ...))
DisjointClasses(Target NamedClass )
DisjointClasses(NamedClass Target )

<Target, dataProp, dataValue >
<Target, objProp, Target >
<Target, maxCardinality(prop ),
number [:NamedClass ]>
<Target, minCardinality(prop ),
number [:NamedClass ]>
<Target, exactCardinality(objProp ),
number [:NamedClass ]>
<Target, someValuesFrom(objProp ),
NamedClass >
<Target, allValuesFrom(objProp ),
NamedClass >
convert (SubClassOf(C1 Target ))
convert (SubClassOf(C2 Target )) ...
or(convert (SubClassOf(C1 Target )),
convert (SubClassOf(C2 Target )),
...)
<Target, not(isA), NamedClass >
<Target, not(isA), NamedClass >

Notation: Square brackets indicate optional arguments, and convert () a recursive application of the
conversion to . NamedClass is a class identifier; objProp , dataProp , and prop are identifiers of object
properties, datatype properties, and properties; indiv , indiv1 , . . . are identifiers of individuals;
dataValue is a datatype value; and C , C1 , . . . are class identifiers, or expressions constructing classes
without ObjectIntersectionOf or ObjectUnionOf.

Table 2: owl statements for a class target, and the corresponding message triples.
This is an aryballos, found at the Heraion of Delos. It was created during the archaic period and it was
decorated with the black-figure technique. It is currently in the Museum of Delos.

The names of classes and individuals can be shown as hyperlinks to indicate that they can
be used as subsequent targets. Clicking on a hyperlink would be a request to describe
the corresponding class or individual. Alternatively, we may retrieve in advance the owl
statements for the subsequent targets and add them to those of the current target.
More precisely, assuming that the target is an individual, the subsequent targets, called
second-level targets, are the targets class, provided that it is a named one, and the individuals the target is directly linked to via object properties. Naturalowl considers second-level
targets only when the current target is an individual, because with class targets, second-level
targets often lead to complicated texts. To retrieve owl statements for both the current
and the second-level targets (when applicable), or only for the current target, we set the
maximum fact distance to 2 or 1, respectively. Returning to exhibit24, let us assume that
the maximum fact distance is 2 and that the following owl statements for second-level
targets have been retrieved.11
11. Consult http://www.w3.org/TR/owl-time/ for more principled representations of time in owl.

680

fiGenerating Natural Language Descriptions from OWL Ontologies

SubClassOf(:Aryballos :Vase)
SubClassOf(:Aryballos
ObjectHasValue(:exhibitTypeCannedDescription
"An aryballos was a small spherical vase with a narrow neck, in which the athletes
kept the oil they spread their bodies with"^^xsd:string))
DatatypePropertyAssertion(:periodDuration :archaicPeriod "700 BC to 480 BC"^^xsd:string)
DatatypePropertyAssertion(:periodCannedDescription :archaicPeriod
"The archaic period was when the Greek ancient city-states developed"^^xsd:string)
DataPropertyAssertion(:techniqueCannedDescription :blackFigureTechnique
"In the black-figure technique, the silhouettes are rendered in black on the pale
surface of the clay, and details are engraved"^^xsd:string)

To express all the retrieved owl statements, including those for the second-level targets,
Naturalowl would now generate a text like the following, which may be preferable, if this
is the first time the user encounters an aryballos and archaic exhibits.
This is an aryballos, a kind of vase. An aryballos was a small spherical vase with a narrow neck, in
which the athletes kept the oil they spread their bodies with. This aryballos was found at the Heraion of
Delos and it was created during the archaic period. The archaic period was when the Greek ancient citystates developed and it spans from 700 bc to 480 bc. This aryballos was decorated with the black-figure
technique. In the black-figure technique, the silhouettes are rendered in black on the pale surface of the
clay, and details are engraved. This aryballos is currently in the Museum of Delos.

We note that in many ontologies it is impractical to represent all the information in
logical terms. In our example, it is much easier to store the information that An aryballos
was a small. . . bodies with as a string, i.e., as a canned sentence, rather than defining
classes, properties, and individuals for spreading actions, bodies, etc. and generating the
sentence from a logical meaning representation. Canned sentences, however, have to be
entered in multiple versions, if several languages or user types need to be supported.
Converting OWL statements to message triples
Tables 1 and 2 also show how the retrieved owl statements can be rewritten as triples
of the form hS, P, Oi, where S is the target or a second-level target; O is an individual,
datatype value, class, or a set of individuals, datatype values, or classes that S is mapped
to; and P specifies the kind of mapping. We call S the semantic subject or owner of the
triple, and O the semantic object or filler ; the triple can also be viewed as a field named
P , owned by S, and filled by O. For example, the owl statements about exhibit24 shown
above, including those about the second-level targets, are converted to the following triples.
<:exhibit24, instanceOf, :Aryballos>
<:exhibit24, :locationFound, :heraionOfDelos>
<:exhibit24, :creationPeriod, :archaicPeriod>
<:exhibit24, :paintingTechniqueUsed, :blackFigureTechnique>
<:exhibit24, :currentMuseum, :delosMuseum>
<:Aryballos, isA, :Vase>
<:Aryballos, :exhibitTypeCannedDescription, "An aryballos was a... bodies with"^^xsd:string>
<:archaicPeriod, :periodDuration, "700 BC to 480 BC"^^xsd:string>
<:archaicPeriod, :periodCannedDescription, "The archaic period was..."^^xsd:string>
<:blackFigureTechnique, :techniqueCannedDescription, "In the black-figure..."^^xsd:string>

More precisely, P can be: (i) a property of the ontology; (ii) one of the keywords isA,
instanceOf, oneOf, differentIndividuals, sameIndividuals; or (iii) an expression of the
form modifier(), where modifier may be not, maxCardinality etc. (see Tables 1 and 2)
681

fiAndroutsopoulos, Lampouras, & Galanis

Figure 2: Graph view of message triples.
and  is a property of the ontology. We hereafter call properties all three types of P ,
though types (ii) and (iii) are strictly not properties in the terminology of owl. When
we need to distinguish between the three types, we use the terms property of the ontology,
domain-independent property, and modified property, respectively.
Every owl statement or collection of owl statements can be represented as a set of rdf
triples.12 The triples of Tables 12 are similar, but not the same as rdf triples. Most notably, expressions of the form modifier() cannot be used as P in rdf triples. To avoid confusion, we call message triples the triples of Tables 12, to distinguish them from rdf triples.
As with rdf triples, message triples can be viewed as forming a graph. Figure 2 shows the
graph for the message triples of exhibit24; the triple linking blackFigureTechnique to a
canned sentence is not shown to save space. The second-level targets are the classes and
individuals at distance one from the target (exhibit24).13 By contrast, the graph for the
rdf triples representing the owl statements would be more complicated, and second-level
targets would not always be at distance one from the target.
Each message triple is intended to be easily expressible as a simple sentence, which is
not always the case with rdf triples representing owl statements. The message triples also
capture similarities of the sentences to be generated that may be less obvious when looking
at the original owl statements or the rdf triples representing them. For example, the
ClassAssertion and SubClassOf statements below are mapped to identical message triples,
apart from the identifiers of the individual and the class, and the similarity of the message
triples reflects the similarity of the resulting sentences, also shown below.
ClassAssertion(ObjectMaxCardinality(1 :madeFromGrape) :product145)
<:product145, maxCardinality(:madeFromGrape), 1>

Product 145 is made from at most one grape.

12. See http://www.w3.org/TR/owl2-mapping-to-rdf/.
13. Instead of retrieving the owl statements about the target and second-level targets and then converting
them to message triples, one could equivalently convert all the owl statements of the ontology to message
triples and select the message triples connecting the target to nodes up to distance two from the target.

682

fiGenerating Natural Language Descriptions from OWL Ontologies

SubClassOf(:StEmilion ObjectMaxCardinality(1 :madeFromGrape))
<:StEmilion, maxCardinality(:madeFromGrape), 1>

St. Emilion is made from at most one grape.

By contrast, without the conversion to message triples, the owl statements and the rdf
triples representing them would lead to more difficult to follow sentences like the following:
Product 145 is a member of the class of individuals that are made from at most one grape.
St. Emilion is a subclass of the class of individuals that are made from at most one grape.

As a further example, Tables 1 and 2 discard ObjectIntersectionOf operators, producing
multiple message triples instead. For example, the EquivalentClasses statement defining
StEmilion on page 672 would be converted to the following message triples.
<:StEmilion,
<:StEmilion,
<:StEmilion,
<:StEmilion,
<:StEmilion,
<:StEmilion,

isA, :Bordeaux>
:locatedIn, :stEmilionRegion>
:hasColor, :red>
:hasFlavor, :strong>
:madeFromGrape, :cabernetSauvignonGrape>
maxCardinality(:madeFromGrape), 1>

The resulting message triples correspond to the sentences below, where subsequent references to StEmilion have been replaced by pronouns to improve readability; the sentences
could also be aggregated into longer ones, as discussed in later sections.
St. Emilion is a kind of Bordeaux. It is from the St. Emilion region. It has red color. It has strong flavor.
It is made from Cabernet Sauvignon grape. It is made from at most one grape variety.

By contrast the original owl statement of page 672 and the rdf triples representing it
would lead to the stricter text of page 678, which is inappropriate for end-users, as already
noted. Notice, also, that Table 2 converts EquivalentClasses and SubClassOf statements to
identical triples, where P is isA, since Naturalowl produces the same texts for both kinds
of statements, as already discussed.
Tables 1 and 2 also replace ObjectUnionOf operators by disjunctions of message triples.
The following owl statement is mapped to the message triple shown below:
ClassAssertion(
UnionOf(ObjectHasValue(:hasFlavor :strong) ObjectHasValue(:hasFlavor :medium))
:houseWine)
or(<:houseWine, :hasFlavor, :strong>, <:houseWine, :hasFlavor, :medium>)

which leads to the first sentence below; the sentence can then be shortened during aggregation, leading to the second sentence below.
The house wine has strong flavor or it has medium flavor.
The house wine has strong or medium flavor.

683

fiAndroutsopoulos, Lampouras, & Galanis

By contrast, the owl statement and the corresponding rdf triples in effect say that:
The house wine is a member of the union of: (i) the class of all wines that have strong flavor, and (ii) the
class of all wines that have medium flavor.

Interest scores and repetitions
Expressing all the message triples of all the retrieved owl statements is not always
appropriate. Let us assume, for example, that the maximum fact distance is 2 and that a
description of exhibit24 of Figure 2 has been requested by a museum visitor. It may be the
case that the visitor has already encountered other archaic exhibits, and that the duration
of the archaic period was mentioned in previous descriptions. Repeating the duration of
the period may, thus, be undesirable. We may also want to exclude message triples that
are uninteresting to particular types of users. For example, there may be message triples
providing bibliographic references, which children would probably find uninteresting.
Naturalowl provides mechanisms allowing the domain author to assign an importance
score to every possible message triple, and possibly different scores for different user types
(e.g., adults, children). The score is a non-negative integer indicating how interesting a user
of the corresponding type will presumably find the information of the message triple, if the
information has not already been conveyed to the user. In the museum projects Naturalowl
was originally developed for, the interest scores ranged from 0 (completely uninteresting) to
3 (very interesting), but a different range can also be used. The scores can be specified for
all the message triples that involve a particular property P (e.g., P = madeFrom), or for all
the message triples that involve semantic subjects S of a particular class (e.g., S  Statue
or S = Statue) and a particular property P , or for message triples that involve particular
semantic subjects (e.g., S =exhibit37) and a particular property P . For example, we may
wish to specify that the materials of the exhibits in a collection are generally of medium
interest (P = madeFrom, score 2), that the materials of statues are of lower interest (S 
statue, P = madeFrom, score 1), perhaps because all the statues of the collection are made
from stone, but that the material of the particular statue exhibit24 is very important (S =
exhibit10, P = madeFrom, score 3), perhaps because exhibit24 is a gold statue.
We do not discuss the mechanisms that can be used to assign interest scores to message
triples in this article, but a detailed description of these mechanisms can be found elsewhere
(Androutsopoulos et al., 2012). We also note that when human-authored texts describing
individuals and classes of the ontology are available along with the owl statements or, more
generally, the logical facts they express, statistical and machine learning methods can be
employed to learn to automatically select or assign interest scores to logical facts (Duboue &
McKeown, 2003; Barzilay & Lapata, 2005; Kelly, Copestake, & Karamanis, 2010). Another
possibility (Demir, Carberry, & McCoy, 2010) would be to compute the interest scores with
graph algorithms like PageRank (Brin & Page, 1998).
The domain author can also specify how many times each message triple has to be
repeated, before it can be assumed that users of different types have assimilated it. Once a
triple has been assimilated, it is never repeated in texts for the same user. For example, the
domain author can specify that children assimilate the duration of a historical period when
it has been mentioned twice; hence, the system may repeat, for example, the duration of
the archaic period in two texts. Naturalowl maintains a personal model for each end-user.
The model shows which message triples were conveyed to the particular user in previous
684

fiGenerating Natural Language Descriptions from OWL Ontologies

texts, and how many times. Again, more information about the user modeling mechanisms
of Naturalowl can be found elsewhere (Androutsopoulos et al., 2012).
Selecting the message triples to convey
When asked to describe a target, Naturalowl first retrieves from the ontology the relevant owl statements, possibly also for second-level targets. It then converts the retrieved
statements to message triples, and consults their interest scores and the personal user models to rank the message triples by decreasing interest score, discarding triples that have
already been assimilated. If a message triple about the target has been assimilated, then all
the message triples about second-level targets that are connected to the assimilated triple
are also discarded; for example, if the creationPeriod triple (edge) of Figure 2 has been assimilated, then the triples about the archaic period (the edges leaving from archaicPeriod)
are also discarded. The system then selects up to maxMessagesPerPage triples from the most
interesting remaining ones; maxMessagesPerPage is a parameter whose value can be set to
smaller or larger values for types of users that prefer shorter or longer texts, respectively.
Limitations of content selection
owl allows one to define the broadest possible domain and range of a particular property,
using statements like the following.
ObjectPropertyDomain(:madeFrom :Wine)

ObjectPropertyRange(:madeFrom :Grape)

In practice, more specific range restrictions are then imposed for particular subclasses of
the propertys domain. For example, the following statements specify that when madeFrom
is used with individuals from the subclass GreekWine of Wine, the range (possible values) of
madeFrom should be restricted to individuals from the subclass GreekGrape of Grape.
SubClassOf(:GreekWine :Wine) SubClassOf(:GreekGrape :Grape)
SubClassOf(:GreekWine AllValuesFrom(:madeFrom :GreekGrape))

Naturalowl considers AllValuesFrom and similar restrictions (see Tables 1 and 2), but not
ObjectPropertyDomain and ObjectPropertyRange statements. The latter typically provide
too general and, hence, uninteresting information from the perspective of end-users.
More generally, Naturalowl does not consider owl statements that express axioms
about properties, meaning statements declaring that a property is symmetric, asymmetric,
reflexive, irreflexive, transitive, functional, that its inverse is functional, that a property is
the inverse of, or disjoint with another property, that it is subsumed by a chain of other
properties, or that it is a subproperty (more specific) of another property. Statements of
this kind are mostly useful in consistency checks, in deduction, or when generating texts
describing the properties themselves (e.g., what being a grandparent of somebody means).14
3.1.2 Text Planning
For each target, the previous mechanisms produce the message triples to be expressed,
with each triple intended to be easily expressible as a single sentence. The text planner of
Naturalowl then orders the message triples, in effect ordering the corresponding sentences.
14. Subproperties without sentence plans, discussed below, could inherit sentence plans from their superproperties, but in that case we automatically extract sentence plans from the ontology instead.

685

fiAndroutsopoulos, Lampouras, & Galanis

Global and local coherence
When considering global coherence, text planners attempt to build a structure, usually
a tree, that shows how the clauses, sentences, or larger segments of the text are related to
each other, often in terms of rhetorical relations (Mann & Thompson, 1998). The allowed
or preferred orderings of the sentences (or segments) often follow, at least partially, from
the global coherence structure. In the texts, however, that Naturalowl is intended to
generate, the global coherence structures tend to be rather uninteresting, because most of
the sentences simply provide additional information about the target or the second-level
targets, which is why global coherence is not considered in Naturalowl.15
When considering local coherence, text planners usually aim to maximize measures that
examine whether or not adjacent sentences (or segments) continue to focus on the same entities or, if the focus changes, how smooth the transition is. Many local coherence measures
are based on Centering Theory (ct) (Grosz, Joshi, & Weinstein, 1995; Poesio, Stevenson,
& Di Eugenio, 2004). Consult the work of Karamanis et al. (2009) for an introduction to
ct and a ct-based analysis m-piros texts, which also applies to the texts of Naturalowl.
When the maximum fact distance of Naturalowl is 1, all the sentence-to-sentence transitions are of a type known in ct as continue, which is the preferred type. If the maximum
fact distance is 2, however, the transitions are not always continue. We repeat below the
long aryballos description of page 681 without sentence aggregation. For readers familiar
with ct, we show in italics the most salient noun phrase of each sentence un , which realizes
the discourse entity known as the preferred center cp (un ). The underlined noun phrases realize the backward looking center cb (un ), roughly speaking the most salient discourse entity
of the previous sentence that is also mentioned in the current sentence.
(1) This (exhibit) is an aryballos. (2) An aryballos is a kind of vase. (3) An aryballos was a small
spherical vase with a narrow neck, in which the athletes kept the oil they spread their bodies with. 
(4) This aryballos was found at the Heraion of Delos. (5) It was created during the archaic period. (6)
The archaic period was when the Greek ancient city-states developed. (7) It spans from 700 bc to 480
bc.  (8) This aryballos was decorated with the black-figure technique. (9) In the black-figure technique,
the silhouettes are rendered in black on the pale surface of the clay, and details are engraved.  (10)
This aryballos is currently in the Museum of Delos.

In sentence 4, where cp (u4 ) is the target exhibit, cb (u4 ) is undefined and the transition from
sentence 3 to 4 is a nocb, a type of transition to be avoided; we mark nocb transitions with
bullets. In sentence 6, cp (u6 ) = cb (u6 ) 6= cb (u5 ), and we have a kind of transition known as
smooth-shift (Poesio et al., 2004), less preferred than continue, but better than nocb.
Another nocb occurs from sentence 7 to 8, followed by a smooth-shift from sentence 8
to 9, and another nocb from sentence 9 to 10. All the other transitions are continue.
The text planner of Naturalowl groups together sentences (message triples) that describe a particular second-level target (e.g., sentences 23, 67, and 9) and places each
group immediately after the sentence that introduces the corresponding second-level target
(immediately after sentences 1, 5, and 8). Thus the transition from a sentence that introduces a second-level target to the first sentence that describes the second-level target (e.g.,
15. Liang et al. (2011a) and Power (2011) seem to agree that very few rhetorical relations are relevant when
generating texts from owl ontologies.

686

fiGenerating Natural Language Descriptions from OWL Ontologies

from sentence 1 to 2, from 5 to 6, from 8 to 9) is a smooth-shift (or a continue in the
special case from the initial sentence 1 to 2). A nocb occurs only at sentences that return
to providing information about the primary target, after a group of sentences that provide
information about a second-level target. All the other transitions are of type continue.
A simple strategy to avoid nocb transitions would be to end the generated text once
all the message triples that describe a second-level target have been reported, and record
in the user model that the other message triples that content selection provided were not
actually conveyed. In our example, this would generate sentences 1 to 3; then if the user
requested more information about the exhibit, sentences 4 to 7 would be generated etc.
Topical order
When ordering sentences, we also need to consider the topical similarity of adjacent
sentences. Compare, for example, the following two texts.
{locationSection The Stoa of Zeus Eleutherios is located in the western part of the Agora. It is located
next to the Temple of Apollo Patroos.} {buildSection It was built around 430 bc. It was built in the Doric
style. It was built out of porous stone and marble.} {useSection It was used during the Classical period,
the Hellenistic period, and the Roman period. It was used as a religious place and a meeting point.}
{conditionSection It was destroyed in the late Roman period. It was excavated in 1891 and 1931. Today it
is in good condition.}
The Stoa of Zeus Eleutherios was built in the Doric style. It was excavated in 1891 and 1931. It was
built out of porous stone and marble. It is located in the western part of the Agora. It was destroyed in
the late Roman period. It was used as a religious place and a meeting point. It is located next to the
Temple of Apollo Patroos. It was built around 430 bc. Today it is in good condition. It was used during
the Classical period, the Hellenistic period, and the Roman period.

Even though both texts contain the same sentences, the second text is more difficult to
follow, if at all acceptable. The first one is better, because it groups together topically
related sentences. We mark the sentence groups in the first text by curly brackets, but the
brackets would not be shown to end-users. In longer texts, sentence groups may optionally
be shown as separate paragraphs or sections, which is why we call them sections.
To allow the message triples (and the corresponding sentences) to be grouped by topic,
the domain author may define sections (e.g., locationSection, buildSection) and assign
each property to a single section (e.g., assign the properties isInArea and isNextTo to
locationSection). Each message triple is then placed in the section of its property. An
ordering of the sections and of the properties inside each section can also be specified, causing the message triples to be ordered accordingly (e.g., we may specify that locationSection
should precede buildSection, and that inside locationSection, the isInArea property should
be expressed before isNextTo). The sections, the assignments of the properties to sections,
and the order of the sections and the properties are defined in the domain-dependent generation resources (Androutsopoulos et al., 2012).
The overall text planning algorithm
Naturalowls text planning algorithm is summarized in Figure 3. If the message triples
to be ordered include triples that describe second-level targets, i.e., triples hS, P, Oi whose
owner S is a second-level target, then the triples of the primary and each second-level target
687

fiAndroutsopoulos, Lampouras, & Galanis

procedure orderMessageTriples
inputs:
t[0]: primary target
t[1], ..., t[n]: second-level targets
L[0]: unordered list of triples describing t[0]
...
L[n]: unordered list of triples describing t[n]
SMap: mapping from properties to sections
SOrder: partial order of sections
POrder: partial order of properties within sections
output:
ordered list of message triples
steps:
for i := 0 to n { orderMessageTriplesAux(L[i], SMap, SOrder, POrder) }
for i := 1 to n { insertAfterFirst(<t[0], _, t[i]>, L[0], L[i]) }
return L[0]
procedure orderMessageTriplesAux
inputs:
L: unordered list of triples about a single target
SMap: mapping from properties to sections
SOrder: partial order of sections
POrder: partial order of properties within sections
local variables:
S[1], ..., S[k]: lists, each with triples of one section
output:
ordered list of message triples about a single target
steps:
<S[1], ..., S[k]> := splitInSections(L, SMap)
for i := 1 to k { S[i] := orderTriplesInSection(S[i], POrder) }
<S[1], ..., S[k]> := reorderSections(S[1], ..., S[k], SOrder)
return concatenate(S[1], ..., S[k])

Figure 3: The overall text planning algorithm of Naturalowl.

are ordered separately, using the ordering of properties and sections. The ordered triples of
each second-level target are then inserted into the ordered list of the primary target triples,
immediately after the first triple that introduces the second-level target, i.e., immediately
after the first triple whose O is the second-level target.
Further related work on text planning
The ordering of properties and sections is similar to text schemata (McKeown, 1985),
roughly speaking domain-dependent patterns that specify the possible arrangements of different types of sentences (or segments). Sentence ordering has been studied extensively in
text summarization (Barzilay, Elhadad, & McKeown, 2002). Duboue and McKeown (2001)
discuss methods that could be used to learn the order of sentences or other segments in
nlg from semantically tagged training corpora. Consult also the work of Barzilay and Lee
(2004), Elsner et al. (2007), Barzilay and Lapata (2008), and Chen et al. (2009).
688

fiGenerating Natural Language Descriptions from OWL Ontologies

Figure 4: A lexicon entry for the verb to find.
3.2 Micro-planning
The processing stages we have discussed so far select and order the message triples to
be expressed. The next stage, micro-planning, consists of three sub-stages: lexicalization,
sentence aggregation, and generation of referring expressions; see also Figure 1 on page 676.
3.2.1 Lexicalization
During lexicalization, nlg systems usually turn the output of content selection (in our case,
the message triples) to abstract sentence specifications. In Naturalowl, for every property
of the ontology and every supported natural language, the domain author may specify one or
more template-like sentence plans to indicate how message triples involving that property
can be expressed. We discuss below how sentence plans are specified, but first a slight
deviation is necessary, to briefly discuss the lexicon entries of Naturalowl.
Lexicon entries
For each verb, noun, or adjective that the domain author wishes to use in the sentence
plans, a lexicon entry has to be provided, to specify the inflectional forms of that word.16
All the lexicon entries are multilingual (currently bilingual); this allows sentence plans to be
reused across similar languages when no better option is available, as discussed elsewhere
(Androutsopoulos et al., 2007). Figure 4 shows the lexicon entry for the verb whose English
base form is find, as viewed by the domain author when using the Protege plug-in of
Naturalowl. The identifier of the lexicon entry is toFindLex. The English part of the entry
shows that the base form is find, the simple past is found etc. Similarly, the Greek
part of the lexicon entry would show the base form of the corresponding verb ()
and its inflectional forms in the various tenses, persons etc. The lexicon entries for nouns
and adjectives are very similar.
Most of the English inflectional forms could be automatically produced from the base
forms by using simple morphology rules. We hope to exloit an existing English morphology
component, such as that of simplenlg (Gatt & Reiter, 2009), in future work. Similar
morphology rules for Greek were used in the authoring tool of m-piro (Androutsopoulos et
al., 2007), and we hope to include them in a future version of Naturalowl. Rules of this kind
would reduce the time a domain author spends creating lexicon entries. In the ontologies
we have considered, however, a few dozens of lexicon entries for verbs, nouns, and adjectives
16. No lexicon entries need to be provided for closed-class words, like determiners and prepositions.

689

fiAndroutsopoulos, Lampouras, & Galanis

suffice. Hence, even without facilities to automatically produce inflectional forms, creating
the lexicon entries is rather trivial. Another possibility would be to exploit a general-purpose
lexicon or lexical database, like WordNet (Fellbaum, 1998) or celex, though resources of
this kind often do not cover the highly technical concepts of ontologies.17
The lexicon entries and, more generally, all the domain-dependent generation resources
of Naturalowl are stored as instances of an owl ontology (other than the ontology the texts
are generated from) that describes the linguistic resources of the system (Androutsopoulos
et al., 2012). The domain author, however, interacts with the plug-in and does not need to
be aware of the owl representation of the resources. By representing the domain-dependent
generation resources in owl, it becomes easier to publish them on the Web, check them for
inconsistencies etc., as with other owl ontologies.
Sentence plans
In Naturalowl, a sentence plan is a sequence of slots, along with instructions specifying how to fill them in. Figure 5 shows an English sentence plan for the property
usedDuringPeriod, as viewed by the domain author when using the Protege plug-in of Naturalowl. The sentence plan expresses message triples of the form hS, usedDuringPeriod, Oi
by producing sentences like the following.
[slot1 This stoa] [slot2 was used] [slot3 during] [slot4 the Classical period].
[slot1 The Stoa of Zeus Eleutherios] [slot2 was used] [slot3 during] [slot4 the Classical period, the Hellenistic
period, and the Roman period].

The first slot of the sentence plan of Figure 5 is to be filled in with an automatically
generated referring expression for the owner (S) of the triple. For example, if the triple to
express is <:stoaZeusEleutherios, :usedDuringPeriod, :classicalPeriod>, an appropriate
referring expression for S may be a demonstrative noun phrase like this stoa, a pronoun
(it), or the monuments natural language name (the Stoa of Zeus Eleutherios). We
discuss the generation of referring expressions below, along with mechanisms to specify
natural language names. The sentence plan also specifies that the referring expression must
be in nominative case (e.g., it or this stoa, as opposed to the genitive case expressions
its or this stoas, as in This stoas height is 5 meters).
The second slot is to be filled in with a form of the verb whose lexicon identifier is
toUseVerb. The verb form must be in the simple past and passive voice, in positive polarity
(as opposed to was not used). Its number must agree with the number of the expression
in the first slot; for example, we want to generate The Stoa of Zheus Eleutherios was
used, but Stoas were used. The third slot is filled in with the preposition during.
The fourth slot is filled in with an expression for the filler (O) of the message triple, in
accusative case.18 With <:stoaZeusEleutherios, :usedDuringPeriod, :classicalPeriod>,
the slot would be filled in with the natural language name of classicalPeriod.19 The
sentence plan also allows the resulting sentence to be aggregated with other sentences.
17. See http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC96L14 for celex.
18. English prepositions usually require noun phrase complements in accusative (e.g., on him). In Greek
and other languages, cases have more noticeable effects.
19. Future versions of Naturalowl may allow a referring expression for O other than its natural language
name to be produced (e.g., a pronoun), as with S.

690

fiGenerating Natural Language Descriptions from OWL Ontologies

Figure 5: A sentence plan for the property usedDuringPeriod.
More generally, the instructions of a sentence plan may indicate that a slot should be
filled in with one of the following (ivii):
(i) A referring expression for the S (owner) of the message triple. A sentence plan may
specify a particular type of referring expression to use (e.g., always use the natural language
name of S) or, as in the example of Figure 5, it may allow the system to automatically
produce the most appropriate type of referring expression depending on the context.
(ii) A verb for which there is a lexicon entry, in a particular form, possibly a form that
agrees with another slot. The polarity of the verb can also be manually specified or, if the
filler (O) of the message triple is a Boolean value, the polarity can be automatically set to
match that value (e.g., to produce It does not have a built-in flash when O is false).
(iii) A noun or adjective from the lexicon, in a particular form (e.g., case, number), or
in a form that agrees with another slot.
(iv) A preposition or (v) a fixed string.
(vi) An expression for the O (filler) of the triple. If O is an individual or class, then the
expression is the natural language name of O; if O is a datatype value (e.g., an integer),
then the value itself is inserted in the slot; and similarly if O is a disjunction or conjunction
of datatype values, individuals, or classes.
(vii) A concatenation of property values of O, provided that O is an individual. For
example, we may need to express a message triple like the first one below, whose (anonymous
in the rdf sense) object :n is linked to both a numeric value (via hasAmount) and an
individual standing for the currency (via hasCurrency).
<:tecra8, :hasPrice, _:n>

<_:n, :hasAmount, "850"^^xsd:float>

<_:n, :hasCurrency, :euroCurrency>

We would want the sentence plan to include a slot filled in with the concatenation of the
hasAmount value of :n and the natural language name of the hasCurrency value of :n (e.g.,
850 Euro in English, 850  in Greek).
Default sentence plan
If no sentence plan has been provided for a particular property of the ontology, Naturalowl uses a default sentence plan, consisting of three slots. The first slot is filled in
with an automatically generated referring expression for the owner (S) of the triple, in
nominative case. The second slot is filled in with a tokenized form of the owl identifier of
the property. The third slot is filled in with an appropriate expression for the filler (O) of
691

fiAndroutsopoulos, Lampouras, & Galanis

the triple, as discussed above, in accusative case (if applicable). For the following message
triple, the default sentence plan would produce the sentence shown below:
<:stoaZeusEleutherios, :usedDuringPeriod, and(:classicalPeriod, :hellenisticPeriod, :romanPeriod)>

Stoa zeus eleutherios used during period classical period, hellenistic period, and roman period.

Notice that we use a single message triple with an and(...) filler, instead of a different
triple for each period. This kind of triple merging is in effect a form of aggregation, discussed
below, but it takes place during content selection. Also, we assumed in the sentence above
that the natural language names of the individuals have not been provided either; in this
case, Naturalowl uses tokenized forms of the owl identifiers of the individuals instead.
The tokenizer of Naturalowl can handle both CamelCase (e.g., :usedDuringPeriod) and
underscore style (e.g., :used during period). When other styles are used in the identifiers
of properties, classes, and individuals, the output of the tokenizer may be worse than the
example suggests, but the resulting sentences can be improved by providing sentence plans
and by associating classes and individuals with natural language names, discussed below.
Using rdfs:label strings
owl properties (and other elements of owl ontologies) can be labeled with strings in
multiple natural languages using the rdfs:label annotation property, defined in the rdf and
owl standards. For example, the usedDuringPeriod property could be labeled with was
used during as shown below; there could be similar labels for Greek and other languages.
AnnotationAssertion(rdfs:label :usedDuringPeriod "was used during"@en)

If an rdfs:label string has been specified for the property of a message triple, Naturalowl
uses that string in the second slot of the default sentence plan. The quality of the resulting
sentences can, thus, be improved, if the rdfs:label strings are more natural phrases than
the tokenized property identifiers. With the rdfs:label shown above, the default sentence
plan would produce the following sentence.
Stoa zeus eleutherios was used during classical period, hellenistic period, and roman period.

Even with rdfs:label strings, the default sentence plan may produce sentences with disfluencies. Also, the rdfs:label strings do not indicate the grammatical categories of their
words, and this does not allow the system to apply many of the sentence aggregation rules
discussed below. A further limitation of the default sentence plan is that it does not allow
the slots for S and O to be preceded or followed, respectively, by any other phrase.
Sentence plans for domain-independent and modified properties
The domain author does not need to provide sentence plans for domain-independent
properties (e.g., instanceOf, isA, see Tables 12). These properties have fixed, domainindependent semantics; hence, built-in sentence plans are used. The English built-in sentence plans, which also serve as further examples of sentence plans, are summarized in
Table 3; the Greek built-in sentence plans are similar. To save space we show the sentence
plans as templates in Table 3, and we do not show the sentence plans for negated domainindependent properties (e.g., not(isA)), which are similar. Additional slot restrictions not
692

fiGenerating Natural Language Descriptions from OWL Ontologies

Forms of message triples and the
Example message triples and
corresponding built-in sentence plans
possible resulting sentences
<S, instanceOf, O >
<:eos450d, instanceOf, :PhotographicCamera>
ref(S) toBeVerb name(indef, O)
The eos 450d is a photographic camera.
<S, instanceOf, O >
<:eos450d, instanceOf, :Cheap>
ref(S) toBeVerb name(adj, O)
The eos 450d is cheap.
<S, oneOf, O >
<:WineColor, oneOf, or(:white, :rose, :red)>
ref(S) toBeVerb name(O)
A wine color is white, rose, or red.
<S, differentIndividuals, O >
<:n97, differentIndividuals, :n97mini>
ref(S) toBeVerb not identical to name(O)
The n97 is not identical to the n97 mini.
<S, sameIndividual, O >
<:eos450d, sameIndividual, :rebelXSi>
ref(S) toBeVerb identical to name(O)
It is identical to the Rebel xsi.
<S, isA, O >
<:StEmilion, isa, :Bordeaux>
ref(S) toBeVerb a kind of name(noarticle, O)
St. Emilion is a kind of Bordeaux.
<S, isA, O >
<:StEmilion, isa, :Red>
ref(S) toBeVerb name(adj, O)
St. Emilion is red.
Notation: ref() stands for a referring expression for ; name() is the natural language name of ;
name(indef, ) and name(noarticle, ) mean that the name should be a noun phrase with an indefinite
or no article. Sentence plans involving name(adj, ) are used when the natural language name of 
is a sequence of one or more adjectives; otherwise the sentence plan of the previous row is used.

Table 3: Built-in English sentence plans for domain-independent properties.
shown in Figure 3 require, for example, subject-verb number agreement and the verb forms
(is or was) to be in present tense. Information provided when specifying the natural
language names of individuals and classes, discussed below, shows if definite or indefinite
articles or no articles at all should be used (e.g., the n97 mini, exhibit 24, a St. Emilion or the St. Emilion or simply St. Emilion), and what the default number of each
name is (e.g., A wine color is or Wine colors are). It is also possible to modify the
built-in sentence plans; for example, in a museum context we may wish to generate An
aryballos was a kind of vase instead of An aryballos is a kind of vase.
The sentence plans for modified properties (e.g., minCardinality(manufacturedBy), see
Tables 12) are also automatically produced, from the sentence plans of the unmodified
properties (e.g., manufacturedBy).
Specifying the appropriateness of sentence plans
Multiple sentence plans may be provided for the same property of the ontology and the
same language. Different appropriateness scores (similar to the interest scores of properties)
can then be assigned to alternative sentence plans per user type. This allows specifying, for
example, that a sentence plan that generates sentences like This amphora depicts Miltiades is less appropriate when interacting with children, compared to an alternative sentence
plan with a more common verb (e.g., shows). Automatically constructed sentence plans
inherit the appropriateness scores of the sentence plans they are constructed from.
Related work on sentence plans
The sentence plans of Naturalowl are similar to expressions of sentence planning languages like spl (Kasper & Whitney, 1989) that are used in generic surface realizers, such as
fuf/surge (Elhadad & Robin, 1996), kpml (Bateman, 1997), realpro (Lavoie & Ram693

fiAndroutsopoulos, Lampouras, & Galanis

bow, 1997), nitrogen/halogen (Langkilde, 2000), and openccg (White, 2006). The
sentence plans of Naturalowl, however, leave fewer decisions to subsequent stages. This
has the disadvantage that our sentence plans often include information that could be obtained from large-scale grammars or corpora (Wan, Dras, Dale, & Paris, 2010). On the
other hand, the input to generic surface realizers often refers to non-elementary linguistic concepts (e.g., features of a particular syntax theory) and concepts of an upper model
(Bateman, 1990); the latter is a high-level domain-independent ontology that may use a very
different conceptualization than the ontology the texts are to be generated from. Hence,
linguistic expertise, for example in Systemic Grammars (Halliday, 1994) in the case of kpml
(Bateman, 1997), and effort to understand the upper model are required. By contrast, the
sentence plans of Naturalowl require the domain author to be familiar with only elementary linguistic concepts (e.g., tense, number), and they do not require familiarity with an
upper model. Our sentence plans are simpler than, for example, the templates of Busemann and Horacek (1999) or McRoy et al. (2003), in that they do not allow, for instance,
conditionals or recursive invokation of other templates. See also the work of Reiter (1995)
and van Deemter et al. (2005) for a discussion of template-based vs. more principled nlg.
When corpora of texts annotated with the message triples they express are available,
templates can also be automatically extracted (Ratnaparkhi, 2000; Angeli, Liang, & Klein,
2010; Duma & Klein, 2013). Statistical methods that jointly perform content selection,
lexicalization, and surface realization have also been proposed (Liang, Jordan, & Klein,
2009; Konstas & Lapata, 2012a, 2012b), but they are currently limited to generating single
sentences from flat records.
Specifying natural language names
The domain author can assign natural language (nl) names to the individuals and
named classes of the ontology; recall that by named classes we mean classes that have owl
identifiers. If an individual or named class is not assigned an nl name, then its rdfs:label
or a tokenized form of its identifier is used instead. The nl names that the domain author
provides are specified much as sentence plans, i.e., as sequences of slots. For example, we
may specify that the English nl name of the class ItalianWinePiemonte is the concatenation
of the following slots; we explain the slots below.
[indef an] [adj Italian] [headnoun wine] [prep from] [def the] [noun Piemonte] [noun region]

This would allow Naturalowl to generate the sentence shown below from the following
message triple; a tokenized form of the identifier of wine32 is used.
<:wine32, instanceOf, :ItalianWinePiemonte>

Wine 32 is an Italian wine from the Piemonte region.

Similarly, we may assign the following nl names to the individuals classicalPeriod, stoa
ZeusEleutherios, gl2011, and the classes ComputerScreen and Red. Naturalowl makes no
distinction between common and proper nouns; both are entered as nouns in the lexicon,
and may be multi-word (e.g., Zeus Eleutherios). Naturalowl can also be instructed to
capitalize the words of particular slots (e.g., Classical).
694

fiGenerating Natural Language Descriptions from OWL Ontologies

[def the] [adj Classical] [headnoun period] , [def the] [headnoun stoa] [prep of] [noun Zeus Eleutherios],
[headnoun GL-2011] , [indef a] [noun computer] [headnoun screen] , [headadj red]

These nl names could be used to express the message triples shown below:
<:stoaZeusEleutherios, :usedDuringPeriod,

:classicalPeriod>

The Stoa of Zeus Eleutherios was used during the Classical period.
<:gl2011, instanceOf, :ComputerScreen>

<:gl2011, instanceOf, :Red>

GL-2011 is a computer screen. GL-2011 is red.

More precisely, each nl name is a sequence of slots, with accompanying instructions
specifying how the slots are to be filled in. Each slot can be filled in with:
(i) An article, definite or indefinite. The article in the first slot (if present) is treated as
the article of the overall nl name.
(ii) A noun or adjective flagged as the head (main word) of the nl name. Exactly one
head must be specified per nl name and it must have a lexicon entry. The number and case
of the head, which is also taken to be the number and case of the overall nl name, can be
automatically adjusted per context. For example, different sentence plans may require the
same nl name to be in nominative case when used as a subject, but in accusative when used
as the object of a verb; and some aggregation rules, discussed below, may require a singular
nl name to be turned into plural. Using the lexicon entries, which list the inflectional forms
of nouns and adjectives, Naturalowl can adjust the nl names accordingly. The gender of
head adjectives can also be automatically adjusted, whereas the gender of head nouns is
fixed and specified by their lexicon entries.
(iii) Any other noun or adjective, among those listed in the lexicon. The nl name may
require a particular inflectional form to be used, or it may require an inflectional form that
agrees with another slot of the nl name.
(iv) A preposition, or (v) any fixed string.
As with sentence plans, the domain author specifies nl names by using the Protege
plug-in of Naturalowl. Multiple nl names can be specified for the same individual or class,
and they can be assigned different appropriateness scores per user type; hence, different
terminology (e.g., common names of diseases) can be used when generating texts for nonexperts, as opposed to texts for experts (e.g., doctors). The domain author can also specify,
again using the plug-in, if the nl names of particular individuals or classes should involve
definite, indefinite, or no articles, and if the nl names should be in singular or plural by
default. For example, we may prefer the texts to mention the class of aryballoi as a single
particular generic object, or by using an indefinite singular or plural form, as shown below.
The aryballos is a kind of vase. An aryballos is a kind of vase. Aryballoi are a kind of vase.

695

fiAndroutsopoulos, Lampouras, & Galanis

3.2.2 Sentence Aggregation
The sentence plans of the previous section lead to a separate sentence for each message triple.
nlg systems often aggregate sentences into longer ones to improve readability. In Naturalowl, the maximum number of sentences that can be aggregated to form a single longer
sentence is specified per user type via a parameter called maxMessagesPerSentence. In the
museum contexts our system was originally developed for, setting maxMessagesPerSentence
to 3 or 4 led to reasonable texts for adult visitors, whereas a value of 2 was used for children. The sentence aggregation of Naturalowl is performed by a set of manually crafted
rules, intended to be domain-independent. We do not claim that this set of rules, which
was initially based on the aggregation rules of m-piro (Melengoglou, 2002), is complete,
and we hope it will be extended in future work; see, for example, the work of Dalianis
(1999) for a rich set of aggregation rules.20 Nevertheless, the current rules of Naturalowl
already illustrate several aggregation opportunities that arise when generating texts from
owl ontologies.
To save space, we discuss only English sentence aggregation; Greek aggregation is similar. We show mostly example sentences before and after aggregation, but the rules actually
operate on sentence plans and they also consider the message triples being expressed. The
rules are intended to aggregate short single-clause sentences. Sentence plans that produce
more complicated sentences may be flagged (using the tickbox at the bottom of Figure
5) to signal that aggregation should not affect their sentences. The aggregation rules apply almost exclusively to sentences that are adjacent in the ordering produced by the text
planner; the only exception are aggregation rules that involve sentences about cardinality
restrictions. Hence, depending on the ordering of the text planner there may be more or
fewer aggregation opportunities; see the work of Cheng and Mellish (2000) for related discussion. Also, the aggregation rules of Naturalowl operate on sentences of the same topical
section, because aggregating topically unrelated sentences often sounds unnatural.
The aggregation of Naturalowl is greedy. For each of the rules discussed below, starting
from those discussed first, the system scans the original (ordered) sentences from first to
last, applying the rule wherever possible, provided that the rules application does not lead
to a sentence expressing more than maxMessagesPerSentence original sentences. If a rule can
be applied in multiple ways, for example to aggregate two or three sentences, the application
that aggregates the most sentences without violating maxMessagesPerSentence is preferred.
Avoid repeating a noun with multiple adjectives: Message triples of the form hS, P, O1 i, . . . ,
hS, P, On i will have been aggregated into a single message triple hS, P, and(O1 , . . . , On )i.
If the nl names of O1 , . . . , On are, apart from possible initial determiners, sequences of
adjectives followed by the same head noun, then the head noun does not need to be repeated.
Let us consider the following message triple. Assuming that the nl names of the three
periods are as in the first sentence below, the original sentence will repeat period three
times. The aggregation rule omits all but the last occurrence of the head noun.
<:stoaZeusEleutherios, :usedDuringPeriod, and(:classicalPeriod, :hellenisticPeriod, :romanPeriod)>

It was used during the Classical period, the Hellenistic period, and the Roman period.

 It was used

during the Classical, the Hellenistic, and the Roman period.
20. When appropriate corpora are available, it may also be possible to train aggregation modules (Walker,
Rambow, & Rogati, 2001; Barzilay & Lapata, 2006).

696

fiGenerating Natural Language Descriptions from OWL Ontologies

Cardinality restrictions and values: This is a set of rules that aggregate all the sentences (not
necessarily adjacent) that express message triples of the form hS, M (P ), Oi and hS, P, Oi, for
the same S and P , with M being any of minCardinality, maxCardinality, exactCardinality.
When these rules are applied, MaxMessagesPerSentence is ignored. For example, these rules
perform aggregations like the following.
Model 35 is sold in at most three countries. Model 35 is sold in at least three countries. Model 35 is sold
in Spain, Italy, and Greece.

 Model 35 is sold in exactly three countries: Spain, Italy, and Greece.

Class and passive sentence: This rule aggregates (i) a sentence expressing a message triple
hS, instanceOf, Ci or hS, isA, Ci and (ii) a passive immediately subsequent sentence expressing a single triple of the form hS, P, Oi, for the same S, where P is an (unmodified) property
of the ontology. The subject and auxiliary verb of the second sentence are omitted.
Bancroft Chardonnay is a kind of Chardonnay. It is made in Bancroft.

 Bancroft Chardonnay is a

kind of Chardonnay made in Bancroft.

Class and prepositional phrase: The second sentence now involves the verb to be in the
active simple present, immediately followed by a preposition; the other conditions are as in
the previous rule. The subject and verb of the second sentence are omitted.
Bancroft Chardonnay is a kind of Chardonnay. It is from Bancroft.

 Bancroft Chardonnay is a kind

of Chardonnay from Bancroft.

Class and multiple adjectives: This rule aggregates (i) a sentence of the same form as in
the previous two rules, and (ii) one or more immediately preceding or subsequent sentences,
each expressing a single message triple hS, Pi , Oi i, for the same S, where Pi are (unmodified)
properties of the ontology. Each of the preceding or subsequent sentences must involve the
verb to be in the active simple present, immediately followed by only an adjective. The
adjectives are absorbed into sentence (i) maintaining their order.
This is a motorbike. It is red. It is expensive.

 This is a red, expensive motorbike.

Same verb conjunction/disjunction: In a sequence of sentences involving the same verb
form, each expressing a single message triple hS, Pi , Oi i, where S is the same in all the
triples and Pi are (unmodified) properties of the ontology, a conjunction can be formed by
mentioning the subject and verb once. The and is omitted when a preposition follows.
 It has medium body and moderate flavor.
He was born in Athens. He was born in 1918.  He was born in Athens in 1918.
It has medium body. It has moderate flavor.

A similar rule applies to sentences produced from disjunctions of message triples, as illustrated below. A variant of the first aggregation rule is then also applied.
The house wine has strong flavor or it has medium flavor.
flavor.

 The house wine has strong or medium flavor.
697

 The house wine has strong flavor or medium

fiAndroutsopoulos, Lampouras, & Galanis

Different verbs conjunction: When there is a sequence of sentences, not involving the same
verb form, each expressing a message triple hS, Pi , Oi i, where S is the same in all the triples
and Pi are (unmodified) properties of the ontology, a conjunction can be formed:
Bancroft Chardonnay is dry. It has moderate flavor. It comes from Napa.

 Bancroft Chardonnay is

dry, it has moderate flavor, and it comes from Napa.

3.2.3 Generating Referring Expressions
A sentence plan may require a referring expression to be generated for the S of a message
triple hS, P, Oi. Depending on the context, it may be better, for example, to use the nl
name of S (e.g., the Stoa of Zeus Eleutherios), a pronoun (e.g., it), a demonstrative
noun phrase (e.g., this stoa) etc. Similar alternatives could be made available for O,
but Naturalowl currently uses O itself, if it is a datatype value; or the nl name of O, its
tokenized identifier, or its rdfs:label, if O is an entity or class; and similarly for conjunctions
and disjunctions in O. Hence, below we focus only on referring expressions for S.
Naturalowl currently uses a limited range of referring expressions, which includes only
nl names (or tokenized identifiers or rdfs:label strings), pronouns, and noun phrases
involving only a demonstrative and the nl name of a class (e.g., this vase). For example,
referring expressions that mention properties of S (e.g., the vase from Rome) are not
generated. Although the current referring expression generation mechanisms of Naturalowl
work reasonably well, they are best viewed as placeholders for more elaborate algorithms
(Krahmer & van Deemter, 2012), especially algorithms based on description logics (Areces,
Koller, & Striegnitz, 2008; Ren, van Deemter, & Pan, 2010).
Let us consider the following generated text, which expresses the triples hSi , Pi , Oi i
shown below. We do not aggregate sentences in this section, to illustrate more cases where
referring expressions are needed; aggregation would reduce, however, the number of pronouns, making the text less repetitive. For readers familiar with ct (Section 3.1.2), we
show again in italics the noun phrase realizing cp (un ), we show underlined the noun phrase
realizing cb (un ), and we mark nocb transitions with bullets.
(1) Exhibit 7 is a statue. (2) It was sculpted by Nikolaou. (3) Nikolaou was born in Athens. (4) He was
born in 1918. (5) He died in 1998.  (6) Exhibit 7 is now in the National Gallery. (7) It is in excellent
condition.
<:exhibit7,
<:nikolaou,
<:nikolaou,
<:exhibit7,

instanceOf, :Statue>
<:exhibit7, :hasSculptor, :nikolaou>
:cityBorn, :athens>
<:nikolaou, :yearBorn, "1918"^^xsd:integer>
:yearDied, "1998"^^xsd:integer>
<:exhibit7, :currentLocation, :nationalGallery>
:currentCondition, :excellentCondition>

Naturalowl pronominalizes Sn (for n > 1) only if Sn = Sn1 , as in sentences 2, 4, 5, and
7. Since typically cp (ui ) = Si , we obtain cp (un ) = cp (un1 ), whenever Sn is pronominalized, if the pronoun is resolved by the reader as intended. People tend to prefer readings
where cp (un ) = cp (un1 ), if no other restriction is violated (e.g., gender, number, world
knowledge). This helps the pronouns that Naturalowl generates to be correctly resolved
by readers, even when they would appear to be potentially ambiguous. For example, the
pronoun of sentence 7 is most naturally understood as referring to the exhibit, as it is intended to, not the gallery, even though both are neuter and can be in excellent condition.
698

fiGenerating Natural Language Descriptions from OWL Ontologies

Note that with both referents, the transition from sentence 6 to 7 is a continue; hence,
transition type preferences play no role. The gender of each generated pronoun is the gender
of the (most appropriate) nl name of the S that the pronoun realizes.21 If S does not have
an nl name, Naturalowl uses the gender of the (most appropriate) nl name of the most
specific class that includes S and has an nl name (or one of these classes, if they are many).
nl names can also be associated with sets of genders, which give rise to pseudo-pronouns
like he/she; this may be desirable in the nl name of a class like Person.
With some individuals or classes, we may not wish to use nl names, nor tokenized
identifiers or rdfs:label strings. This is common, for example, in museum ontologies, where
some exhibits are known by particular names, but many other exhibits are anonymous and
their owl identifiers are not particularly meaningful. Naturalowl allows the domain author
to mark individuals and classes as anonymous, to indicate that their nl names, tokenized
identifiers, and rdfs:label strings should be avoided. When the primary target is marked as
anonymous, Naturalowl uses a demonstrative noun phrase (e.g., this statue) to refer to
it. The demonstrative phrase involves the nl name of the most specific class that subsumes
the primary target, has an nl name, and has not been marked as anonymous. Especially
in sentences that express isA or instanceOf message triples about the primary target, the
demonstrative phrase is simply this, to avoid generating sentences like This statue is
a statue. The marking of anonymous individuals and classes currently affects only the
referring expressions of the primary target.
3.3 Surface Realization
In many nlg systems, the sentences at the end of micro-planning are underspecified; for
example, the order of their constituents or the exact forms of their words may be unspecified.
Large-scale grammars or statistical models can then be used to fill in the missing information
during surface realization, as already discussed (Section 3.2.1). By contrast, in Naturalowl
(and most template-based nlg systems) the (ordered and aggregated) sentence plans at the
end of micro-planning already completely specify the surface (final) form of each sentence.
Hence, the surface realization of Naturalowl is mostly a process of converting internal,
but fully specified and ordered sentence specifications to the final text. Punctuation and
capitalization are also added. Application-specific markup (e.g., html tags, hyperlinks) or
images can also be added by modifying the surface realization code of Naturalowl.

4. Trials
In our previous work, Naturalowl was used mostly to describe cultural heritage objects.
In the xenios project, it was tested with an owl version of an ontology that was created
during m-piro to document approximately 50 archaeological exhibits (Androutsopoulos et
al., 2007).22 The owl version comprised 76 classes, 343 individuals (including cities, persons
etc.), and 41 properties. In xenios, Naturalowl was also embedded in a robotic avatar
that presented the exhibits of m-piro in a virtual museum (Oberlander, Karakatsiotis,
21. In languages like Greek that use grammatical instead of natural genders, the pronouns genders cannot
be determined by consulting the ontology (e.g., to check if the referent is animate or inanimate).
22. xenios was co-funded by the European Union and the Greek General Secretariat of Research and Technology; see http://www.ics.forth.gr/xenios/.

699

fiAndroutsopoulos, Lampouras, & Galanis

Isard, & Androutsopoulos, 2008). More recently, in the indigo project, Naturalowl was
embedded in mobile robots acting as tour guides in an exhibition about the ancient Agora
of Athens.23 An owl ontology documenting 43 monuments was used; there were 49 classes,
494 individuals, and 56 properties in total.
In xenios and indigo, the texts of Naturalowl were eventually indistinguishable from
human-authored texts. We participated, however, in the development of the ontologies, and
we may have biased them towards choices (e.g., classes, properties) that made it easier for
Naturalowl to generate high-quality texts. Hence, in the trials discussed below, we wanted
to experiment with independently developed ontologies. We also wanted to experiment with
different domains, as opposed to cultural heritage.
A further goal was to compare the texts of Naturalowl against those of a simpler verbalizer. We used the owl verbalizer of the swat project (Stevens et al., 2011; Williams,
Third, & Power, 2011), which we found to be particularly robust and useful.24 The verbalizer produces an alphabetical glossary with an entry for each named class, property, and
individual, without requiring domain-dependent generation resources. Each glossary entry
is a sequence of English-like sentences expressing the corresponding owl statements of the
ontology. The swat verbalizer uses a predetermined partial order of statements in each
glossary entry; for example, when describing a class, statements about equivalent classes
or super-classes are mentioned first, and individuals belonging in the target class are mentioned last.25 The verbalizer actually translates the owl ontology to Prolog, it extracts
lexicon entries from owl identifiers and rdfs:label strings, and it uses predetermined sentence plans specified as a dcg grammar. It also aggregates, in effect, message triples of the
same property that share one argument (S or O) (Williams & Power, 2010).
Our hypothesis was that the domain-dependent generation resources would help Naturalowl produce texts that end-users would consider more fluent and coherent, compared
to those produced by the swat verbalizer, but also those produced by Naturalowl without
domain-dependent generation resources. We also wanted to demonstrate that high-quality
texts could be produced in both English and Greek, and to measure the effort required
to create the domain-dependent generation resources of Naturalowl for existing ontologies. This effort had not been measured in our previous work, because the development
of the domain-dependent generation resources was combined with the development of the
ontologies. Since the time needed to create the domain-dependent generation resources
depends on ones familiarity with Naturalowl and its Protege plug-in, exact times are not
particularly informative. Instead, we report figures such as the number of sentence plans,
lexicon entries etc. that were required, along with approximate times. We do not evaluate
23. indigo was an fp6 ist project of the European Union; consult http://www.ics.forth.gr/indigo/.
Videos of the robots of xenios and indigo are available at http://nlp.cs.aueb.gr/projects.html.
Two aueb students, G. Karakatsiotis and V. Pterneas, won the Interoperability Challenge of the 2011
Microsoft Imagine Cup with a similar mobile phone application, called Touring Machine, which uses
Naturalowl; see http://www.youtube.com/watch?v=PaNAmNC7dZw.
24. The swat verbalizer can be used on-line at http://swat.open.ac.uk/tools/. We used the generalpurpose version that was on-line in July and August 2011; a similar verbalizer from owl to ace (Section
2) is available at http://attempto.ifi.uzh.ch/site/docs/owl to ace.html. A domain-specific version
of swat for the snomed biomedical ontology has also been developed (Liang et al., 2011a, 2011b).
25. The verbalizer also organizes the English-like sentences of each glossary entry under sub-headings like
Definition, Taxonomy, Description, Distinctions (Williams et al., 2011). We discarded these subheadings, whose meanings were not entirely clear to us, but we retained the order of the sentences.

700

fiGenerating Natural Language Descriptions from OWL Ontologies

the usability of the Protege plug-in of Naturalowl, since it is very similar to the authoring
tool of m-piro. Previous experiments (Androutsopoulos et al., 2007) showed that computer
science graduates with no expertise in nlg could learn to use effectively the authoring tool
of m-piro to create the necessary domain-dependent generation resources for existing or
new ontologies, after receiving the equivalent of a full-day introduction course.
4.1 Trials with the Wine Ontology
In the first trial, we experimented with the Wine Ontology, which is often used in Semantic
Web tutorials.26 It comprises 63 wine classes, 52 wine individuals, a total of 238 classes and
individuals (including wineries, regions, etc.), and 14 properties.
We submitted the Wine Ontology to the swat verbalizer to obtain its glossary of Englishlike descriptions of classes, properties, and individuals. We retained only the descriptions
of the 63 wine classes and the 52 wine individuals. Subsequently, we also discarded 20 of
the 63 wine class descriptions, as they were for trivial classes (e.g., RedWine) and they were
stating the obvious (e.g., A red wine is defined as a wine that has as color Red).27 In
the descriptions of the remaining 43 wine classes and 52 wine individuals, we discarded
sentences expressing axioms that Naturalowl does not consider, for example sentences
providing examples of individuals that belong in a class being described. The remaining
sentences express the same owl statements that Naturalowl expresses when its maximum
fact distance is set to 1. Two examples of texts produced by the swat verbalizer follow.
Chenin Blanc (class): A chenin blanc is defined as something that is a wine, is made from grape the
Chenin Blanc Grape, and is made from grape at most one thing. A chenin blanc both has as flavor
Moderate, and has as color White. A chenin blanc both has as sugar only Off Dry and Dry, and has as
body only Full and Medium.
The Foxen Chenin Blanc (individual): The Foxen Chenin Blanc is a chenin blanc. The Foxen Chenin
Blanc has as body Full. The Foxen Chenin Blanc has as flavor Moderate. The Foxen Chenin Blanc has
as maker Foxen. The Foxen Chenin Blanc has as sugar Dry. The Foxen Chenin Blanc is located in the
Santa Barbara Region.

Subsequently, we generated texts for the 43 classes and 52 individuals using Naturalowl
without domain-dependent generation resources, hereafter called Naturalowl(), setting
the maximum fact distance to 1; the resulting texts were very similar to swats.
We then constructed the domain-dependent generation resources of Naturalowl for the
Wine Ontology. The resources are summarized in Table 4. They were constructed by the
second author, who devoted three days to their construction, testing, and refinement.28
Our experience is that it takes weeks (if not longer) to develop an owl ontology the size
of the Wine Ontology (acquire domain knowledge, formulate the axioms in owl, check for
inconsistencies, populate the ontology with individuals etc.); hence, a period of a few days is
26. See http://www.w3.org/TR/owl-guide/wine.rdf.
27. Third (2012) discusses how owl axioms leading to undesirable sentences of this kind might be detected.
28. Some of the resources were constructed by editing directly their owl representations, rather than using
the Protege plug-in, which was not fully functional at that time. By using the now fully functional
plug-in, the time to create the domain-dependent generation resources would have been shorter.

701

fiAndroutsopoulos, Lampouras, & Galanis
Resources
Sections
Property assignments to sections
Interest score assignments
Sentence plans
Lexicon entries
Natural language names

English

Greek
2
7
8

5
67
41





Table 4: Domain-dependent generation resources created for the Wine Ontology.
relatively light effort, compared to the time needed to develop an owl ontology of this size.
Only English texts were generated in this trial; hence, no Greek resources were constructed.
We defined only one user type, and we used interest scores only to block sentences stating
the obvious, by assigning zero interest scores to the corresponding message triples; we also
set maxMessagesPerSentence to 3. Only 7 of the 14 properties of the Wine Ontology are used
in the owl statements that describe the 43 classes and 52 individuals. We defined only 5
sentence plans, as some of the 7 properties could be expressed by the same sentence plans.
We did not define multiple sentence plans per property. We also assigned the 7 properties
to 2 sections, and ordered the sections and properties. We created nl names only when
the automatically extracted ones were causing disfluencies. The extracted nl names were
obtained from the owl identifiers of classes and individuals; no rdfs:label strings were
available. To reduce the number of manually constructed nl names further, we declared
the 52 individual wines to be anonymous (and provided no nl names for them). Most of
the 67 lexicon entries were used in the remaining 41 nl names of classes and individuals;
nl names were very simple, having 2 slots on average. We used Naturalowl with the
domain-dependent resources, hereafter called Naturalowl(+), to re-generate the 95 texts,
again setting the maximum fact distance to 1; example texts follow.
Chenin Blanc (class): A Chenin Blanc is a moderate, white wine. It has only a full or medium body. It
is only off-dry or dry. It is made from exactly one wine grape variety: Chenin Blanc grapes.

The Foxen Chenin Blanc (individual): This wine is a moderate, dry Chenin Blanc. It has a full body. It
is made by Foxen in the Santa Barbara County.

The resulting 285 texts (95  3) of the three systems (swat verbalizer, Naturalowl(),
Naturalowl(+)) were shown to 10 computer science students (both undergraduates and
graduate students), who were not involved in the development of Naturalowl; they were all
fluent in English, though not native English speakers, and they did not consider themselves
wine experts. The students were told that a glossary of wines was being developed for people
who were interested in wines and knew basic wine terms (e.g., wine colors, wine flavors),
but who were otherwise not wine experts. Each one of the 285 texts was given to exactly
one student. Each student was given approximately 30 texts, approximately 10 randomly
selected texts from each system. The owl statements that the texts were generated from
were not shown, and the students did not know which system had generated each text.
Each student was shown all of his/her texts in random order, regardless of the system that
had generated them. The students were asked to score each text by stating how strongly
they agreed or disagreed with statements S1 S5 below. A scale from 1 to 3 was used (1:
disagreement, 2: ambivalent, 3: agreement).
702

fiGenerating Natural Language Descriptions from OWL Ontologies
Criteria
Sentence fluency
Referring expressions
Text structure
Clarity
Interest

swat
2.00  0.15
1.40  0.13
2.15  0.16
2.66  0.13
2.30  0.15

Naturalowl()
1.76  0.15
1.15  0.09
2.20  0.16
2.55  0.13
2.14  0.16

Naturalowl(+)
2.80  0.10
2.72  0.13
2.94  0.05
2.74  0.11
2.68  0.12

Table 5: Results for texts generated from the Wine Ontology by the swat verbalizer and
Naturalowl with (+) and without () domain-dependent generation resources.
(S1 ) Sentence fluency: The sentences of the text are fluent, i.e., each sentence on its own is grammatical
and sounds natural. When two or more smaller sentences are combined to form a single, longer sentence,
the resulting longer sentence is also grammatical and sounds natural.
(S2 ) Referring expressions: The use of pronouns and other referring expressions (e.g., this wine) is
appropriate. The choices of referring expressions (e.g., when to use a pronoun or other expression instead
of the name of an object) sound natural, and it is easy to understand what these expressions refer to.
(S3 ) Text structure: The order of the sentences is appropriate. The text presents information by moving
reasonably from one topic to another.
(S4 ) Clarity: The text is easy to understand, provided that the reader is familiar with basic wine terms.
(S5 ) Interest: People interested in wines, but who are not wine experts, would find the information
interesting. Furthermore, there are no redundant sentences in the text (e.g., sentences stating the obvious).29

S5 assesses content selection, the first processing sub-stage; we expected the differences
across the three systems to be very small, as they all reported the same information, with the
exception of redundant sentences blocked by using zero interest assignments in Naturalowl.
S3 assesses text planning, the second sub-stage; again we expected small differences, as many
of the wine properties can be mentioned in any order, though there are some properties (e.g.,
maker, location) that are most naturally reported separately from others (e.g., color, flavor),
which is why we used two sections (Table 4). S1 assesses lexicalization and aggregation; we
decided not to use separate statements for these two stages, since it might have been difficult
for the students to understand exactly when aggregation takes place. S2 assesses referring
expression generation. S4 measures the overall perceived clarity of the texts. There was no
statement for surface realization, as this stage had a rather trivial effect.
Table 5 shows the average scores of the three systems, with averages computed on the
95 texts of each system, along with 95% confidence intervals (of sample means). For each
criterion, the best score is shown in bold; the confidence interval of the best score is also
shown in bold if it does not overlap with the other confidence intervals.30
As expected, the domain-dependent generation resources clearly help Naturalowl produce more fluent sentences and much better referring expressions. The text structure scores
show that the assignment of the ontologys properties to sections and the ordering of the
sections and properties had a greater impact on the perceived structure of the texts than
we expected. The highest score of the swat verbalizer was obtained in the clarity criterion, which agrees with our experience that one can usually understand what the texts of
the swat verbalizer mean, even if their sentences are often not entirely fluent, not particularly well ordered, and keep repeating proper names. Naturalowl(+)had the highest clarity
29. The students were told not to consider whether or not additional information should have been included.
30. When two intervals do not overlap, the difference is statistically significant. When they overlap, the
difference may still be statistically significant; we performed paired two-tailed t-tests ( = 0.05) in these
cases. In a pilot study, we also measured the inter-annotator agreement of two of the students on a sample
of 30 texts (10 from each system). Agreement was very high (sample Pearson correlation r  0.91) in all
five criteria. A similar pilot study was performed in the next trial, also indicating very high agreement.

703

fiAndroutsopoulos, Lampouras, & Galanis

score, but the difference from the swat verbalizer, which had the second highest score, is not
statistically significant. Naturalowl(+)also obtained higher interest scores than the other
two systems, with statistically significant differences from both; these differences, which are
larger than we expected, can only be attributed to the zero interest score assignments of
the domain-dependent generation resources, which blocked sentences stating the obvious,
because otherwise all three systems report the same information.
The swat verbalizer obtained higher scores than Naturalowl(), with the text structure score being the only exception. Only the difference in the referring expression scores
of the two systems, though, is statistically significant. Both systems, however, received
particularly low scores for their referring expressions, which is not surprising, given that
they both always refer to individuals and classes by extracted names; the slightly higher
score of the swat verbalizer is probably due to its better tokenization of owl identifiers.
4.2 Trials with the Consumer Electronics Ontology
In the second trial, we experimented with the Consumer Electronics Ontology, an owl ontology for consumer electronics products and services.31 The ontology comprises 54 classes
and 441 individuals (e.g., printer types, paper sizes, manufacturers), but no information
about particular products. We added 60 individuals describing 20 digital cameras, 20 camcorders, and 20 printers. The 60 individuals were randomly selected from a publicly available
dataset of 286 digital cameras, 613 camcorders, and 58 printers, whose instances comply
with the Consumer Electronics Ontology.32
We submitted the Consumer Electronics Ontology with the additional 60 individuals
to the swat verbalizer, and retained only the descriptions of the 60 individuals. Again,
we removed sentences expressing axioms Naturalowl does not consider. We also renamed
the string values of some datatype properties to make the texts easier to understand (e.g.,
cmt became cm). An example description follows.
The Sony Cyber-shot DSC-T90 is a digital camera.
The Sony Cyber-shot DSC-T90 has as manufacturer Sony.
The Sony Cyber-shot DSC-T90 has as data interface type Usb2 0.
The Sony Cyber-shot DSC-T90 has as depth Depth. Depth has as unit of measurement cm. Depth has as value
float 9.4.
The Sony Cyber-shot DSC-T90 has as digital zoom factor the Digital Zoom Factor. The Digital Zoom Factor has
as value float 12.1. [. . . ]
The Sony Cyber-shot DSC-T90 has as feature Video Recording, Microphone and the Automatic Picture Stabilizer.
The Sony Cyber-shot DSC-T90 has as self timer true. [. . . ]

In this ontology, many properties have composite values, expressed by using auxiliary individuals. In the example above, a property (hasDepth) connects the digital camera to an
auxiliary individual Depth (similar to the anonymous node :n of the property concatenation
price example of page 691), which is then connected via two other properties (hasValueFloat
31. Consult http://www.ebusiness-unibw.org/ontologies/consumerelectronics/v1.
32. See http://rdf4ecommerce.esolda.com/ for the dataset that we used. A list of similar datasets is
available at http://wiki.goodrelations-vocabulary.org/Datasets.

704

fiGenerating Natural Language Descriptions from OWL Ontologies

and hasUnitOfMeasurement) to the float value 9.4 and the unit of measurement (centimeters), respectively. We obtained the descriptions of the auxiliary individuals (e.g., Depth),
which are different entries in the glossary of the swat verbalizer, and we copied them immediately after the corresponding sentences that introduce the auxiliary individuals. We
also formatted each text as a list of sentences, as above, to improve readability.
We then generated texts for the 60 products using Naturalowl(), setting the maximum
fact distance to 1. Descriptions of auxiliary individuals were also generated and copied
immediately after the sentences introducing them. The texts were very similar to those of
the swat verbalizer, and they were formatted in the same manner.
In this trial, we also wanted to consider a scenario where the set of individuals to be
described changes frequently (e.g., the products sold by a reseller change, new products arrive etc.) along with changes in other connected individuals (e.g., new manufacturers may
be added), but nothing else in the ontology changes, i.e., only the assertional knowledge
changes. In this case, it may be impractical to update the domain-dependent generation
resources whenever the population of individuals changes. Our hypothesis was that by considering a sample of individuals of the types to be described (printers, cameras, camcorders,
in our case), it would be possible to construct domain-dependent generation resources (e.g.,
sections, the ordering of sections and properties, sentence plans, the nl names of classes)
that would help Naturalowl generate reasonably good descriptions of new (unseen) individuals (products), without updating the domain-dependent generation resources, using the
tokenized owl identifiers or rdfs:label strings of the new individuals as their nl names.
To simulate this scenario, we randomly split the 60 products in two non-overlapping sets,
the development set and the test set, each consisting of 10 digital cameras, 10 camcorders,
and 10 printers. Again, the second author constructed and refined the domain-dependent
generation resources of Naturalowl, this time by considering a version of the ontology that
included the 30 development products, but not the 30 test products, and by viewing the
generated texts of the 30 development products only. This took approximately six days (for
two languages).33 Hence, relatively light effort was again needed, compared to the time it
typically takes to develop an ontology of this size, with terminology in two languages. Texts
for the 30 products of the test set were then also generated by using Naturalowl and the
domain-dependent generation resources of the development set.
As in the previous trial, we defined only one user type, and we used interest scores only
to block sentences stating the obvious. The maximum messages per sentence was again 3.
We constructed domain-dependent generation resources for both English and Greek; the
resources are summarized in Table 6. We created sentence plans only for the 42 properties
of the ontology that were used in the development set (one sentence plan per property); the
test set uses two additional properties, for which the default sentence plans of Naturalowl
(for English and Greek) were used. We also assigned the 42 properties to 6 sections, and
ordered the sections and properties. We created nl names only when the automatically
extracted ones were causing disfluencies in the development texts. Unlike the previous
trial, the products to be described were not declared to be anonymous individuals, but the
number of nl names that had to be provided was roughly the same as in the previous trial,
33. Again, some of the domain-dependent generation resources were constructed by editing their owl representations. As a test, the second author later reconstructed the domain-dependent generation resources
from scratch using the fully functional Protege plug-ing, this time in four days.

705

fiAndroutsopoulos, Lampouras, & Galanis
Resources
Sections
Property assignments to sections
Interest score assignments
Sentence plans
Lexicon entries
Natural language names

English

Greek

6
42
12
42
19
36

42
19
36

Table 6: Domain-dependent generation resources for the Consmer Electronics Ontology.
since fewer automatically extracted names were causing disfluencies; in particular, all the
products had reasonably good rdfs:label strings providing their English names.
An example description from the development set produced by Naturalowl(+)follows.
We formatted the sentences of each section as a separate paragraph, headed by the name of
the section (e.g., Other features:); this was easy, because Naturalowl can automatically
mark up the sections in the texts. The maximum fact distance was again 1, but the sentence
plans caused Naturalowl to automatically retrieve additional message triples describing
the auxiliary individuals at distance 1; hence, we did not have to retrieve this information
manually, unlike the texts of the swat verbalizer and Naturalowl().
Type: Sony Cyber-shot DSC-T90 is a digital camera.
Main features: It has a focal length range of 35.0 to 140.0 mm, a shutter lag of 2.0 to 0.0010 sec and
an optical zoom factor of 4.0. It has a digital zoom factor of 12.1 and its display has a diagonal of 3.0 in.
Other features: It features an automatic picture stabilizer, a microphone, video recording and it has a
self-timer.
Energy and environment: It uses batteries.
Connectivity, compatibility, memory: It supports USB 2.0 connections for data exchange and it has
an internal memory of 11.0 GB.
Dimensions and weight: It is 5.7 cm high, 1.5 cm wide and 9.4 cm deep. It weighs 128.0 grm.

The 180 English texts that were generated by the three systems for the 30 development
and 30 test products were shown to the same 10 students of the first trial. The students
were now told that the texts would be used in on-line descriptions of products in the Web
site of a retailer. Again, the owl statements that the texts were generated from were not
shown to the students, and the students did not know which system had generated each
text. Each student was shown 18 randomly selected texts, 9 for products of the development
set (3 texts per system) and 9 for products of the test set (again 3 texts per system). Each
student was shown all of his/her texts in random order, regardless of the system that had
generated them. The students were asked to score the texts as in the previous trial.
Table 7 shows the results for the English texts of the development set.34 As in the previous trial, the domain-dependent generation resources clearly help Naturalowl produce
much more fluent sentences, and much better referring expressions and sentence orderings.
The text structure scores of the swat verbalizer and Naturalowl()are now much lower
than in the previous trial, because there are now more message triples to express per individual and more topics, and the texts of these systems jump from one topic to another
making the texts look very incoherent; for example, a sentence about the width of a camera
may be separated from a sentence about its height by a sentence about shutter lag. This
34. When a confidence interval is 0.00, this means that all the students gave the same score to all texts.

706

fiGenerating Natural Language Descriptions from OWL Ontologies
Criteria
Sentence fluency
Referring expressions
Text structure
Clarity
Interest

swat
1.97  0.15
1.10  0.06
1.67  0.15
1.97  0.15
1.77  0.14

Naturalowl()
1.93  0.27
1.10  0.11
1.33  0.19
2.07  0.26
1.73  0.29

Naturalowl(+)
2.90  0.08
2.87  0.08
2.97  0.04
3.00  0.00
3.00  0.00

Table 7: English development results for the Consumer Electronics Ontology.
Criteria
Sentence fluency
Referring expressions
Text structure
Clarity
Interest

swat
2.03  0.15
1.10  0.06
1.57  0.13
2.07  0.15
1.83  0.17

Naturalowl()
1.87  0.15
1.10  0.06
1.37  0.12
1.93  0.15
1.60  0.14

Naturalowl(+)
2.87  0.08
2.87  0.08
2.93  0.05
2.97  0.04
2.97  0.04

Table 8: English test results for the Consumer Electronics Ontology.
incoherence may have also contributed to the much lower clarity scores of these two systems, compared to the previous trial. The interest scores of these two systems are also much
lower than in the previous trial; this may be due to the verbosity of their texts, caused by
their frequent references to auxiliary individuals in the second trial, combined with the lack
(or very little use) of sentence aggregation and pronoun generation. By contrast, the clarity and interest of Naturalowl(+)were judged to be perfect; the poor clarity and interest
of the other two systems may have contributed to these perfect scores though. Again, the
swat verbalizer obtained slightly better scores than Naturalowl without domain-dependent
generation resources, except for clarity, but the differences are not statistically significant.
Table 8 shows the results for the English texts of the test set. The results of the swat
verbalizer and Naturalowl()are very similar to those of Table 7, as one would expect.
Also, there was only a very marginal decrease in the scores of Naturalowl(+), compared to
the scores of the same system for the development set in Table 7. There is no statistically
significant difference, however, between the corresponding cells of the two tables, for any
of the three systems. These results support our hypothesis that by considering a sample
of individuals of the types to be described one can construct domain-dependent generation
resources that can be used to produce high-quality texts for new individuals of the same
types, when the rest of the ontology remains unchanged. The fact that all the products (but
not the other individuals) had rdfs:label strings providing their English names probably
contributed to the high results of Naturalowl(+)in the test set, but rdfs:label strings of
this kind are common in owl ontologies.
We then showed the 60 Greek texts that were generated by Naturalowl(+)to the same
10 students, who were native Greek speakers; the swat verbalizer and Naturalowl()cannot

Criteria
Sentence fluency
Referring expressions
Text structure
Clarity
Interest

Naturalowl(+),
development data
2.87  0.12
2.77  0.20
3.00  0.00
3.00  0.00
2.97  0.06

Naturalowl(+),
test data
2.83  0.09
2.80  0.11
3.00  0.00
2.93  0.05
3.00  0.00

Table 9: Greek results for the Consumer Electronics Ontology.
707

fiAndroutsopoulos, Lampouras, & Galanis
No.
1
2
3
4
5
6
7

System Configuration
Naturalowl(+)
 interest scores
 ref. expr. gen.
 nl names
 aggregation
 sentence plans
 sections, ordering

Sentence Fluency
4.80  0.12
4.53  0.16
3.93  0.28
3.71  0.29
3.64  0.33
2 .07  0 .37
1.89  0.36

Ref. Expressions
5.00  0.00
4.95  0.06
1 .53  0 .22
1.48  0.21
1.33  0.19
1.33  0.19
1.33  0.19

Text Structure
4.82  0.15
4.78  0.12
4.80  0.12
4.71  0.15
4.67  0.16
4.60  0.18
1 .53  0 .24

Clarity
4.78  0.12
4.62  0.17
4.51  0.24
4.24  0.25
4.24  0.25
2 .49  0 .36
2.33  0.33

Interest
4.89  0.09
4.20  0.19
4.07  0.22
3.98  0.26
3.93  0.26
2 .38  0.35
1.89  0.28

Table 10: Ablation English test results for the Consumer Electronics Ontology. Each
configuration removes one component or resource from the previous configuration.
generate Greek texts from the Consumer Electronics ontology. Table 9 shows the results
we obtained for the Greek texts of the development and test sets. There is no statistically
significant difference from the corresponding results for English (cf. the last columns of Tables 7 and 8). There is also no statistically significant difference in the results for the Greek
texts of the development and test sets (Table 9). We note, however, that it is common to
use English names of electronics products in Greek texts, which made using the English
rdfs:label names of the products in the Greek texts acceptable. In other domains, for
example cultural heritage, it might be unacceptable to use English names of individuals;
hence, one would have to provide Greek nl names for new individuals.
4.3 Ablation Trials with the Consumer Electronics Ontology
In the last trial, we studied how the quality of the generated texts is affected when various components and domain-dependent generation resources of Naturalowl are gradually
removed. We used the Consumer Electronics Ontology, with the domain-dependent generation resources that we had constructed for the 30 development products of the previous
trial. We also used 45 new test products (15 digital cameras, 15 camcorders, and 15 printers, from the same publicly available dataset), other than the 30 development and the 30
test products of the previous trial.
We generated English texts for the 45 new test products, using the 7 configurations of
Naturalowl of Table 10. The resulting 457 = 315 texts were shown to 7 students, who had
the same background as in the previous trials. Each student was shown the 7 texts of 6 or 7
test products (42 or 49 texts per student). For each product, the 7 texts were shown side by
side in random order, and the students were instructed to take into account the differences
of the 7 texts. The students did not know which system had generated which text. The
same criteria (statements S1 S5 of Section 4.1) were used again, but a scale from 1 to 5
was used this time (1: strong disagreement, 2: disagreement, 3: ambivalent, 4: agreement,
5: strong agreement), to make it easier to distinguish between the 7 configurations.
The first configuration (Naturalowl(+)) is Naturalowl with all of its components enabled, using all the available domain-dependent generation resources. As in the previous
trial (see Table 8), the texts of this configuration were judged to be near-perfect by all the
criteria. The second configuration was the same, but without the interest score assignments.
The results of the second configuration were very close to the results of the first one, since
interest score assignments were used only to avoid generating sentences stating the obvious
(e.g., Sony Cyber-shot DSC-T90 is manufactured by Sony). The biggest decrease was in
the interest criterion, as one would expect, but the scores for sentence fluency and clarity
were also affected, presumably because the sentences that state the obvious sound unnatural
708

fiGenerating Natural Language Descriptions from OWL Ontologies

and seem to introduce noise. There were very small differences in the scores for referring
expressions and text structure, which seem to suggest that when the overall quality of the
texts decreases, the judges are biased towards assigning lower scores in all of the criteria.35
The third configuration was the same as the second one, but the component that generates pronouns and demonstrative noun phrases was disabled, causing Naturalowl to always
use the nl names of the individuals and classes, or names extracted from the ontology. There
was a big decrease in the score for referring expresions, showing that despite their simplicity, the referring expression generation methods of Naturalowl have a noticeable effect;
we mark big decreases in italics in Table 10. The scores for sentence fluency, interest, and
clarity were also affected, presumably because repeating the names of the individuals and
classes made the sentences look less natural, boring, and more difficult to follow. There was
almost no difference (a very small positive one) in the text structure score.
In the fourth configuration, the nl names of the individuals and classes were also removed, forcing Naturalowl to always use automatically extracted names. There was a
further decrease in the score for referring expressions, but the decrease was small, because
the referring expressions were already poor in the third configuration. Note, also, that
the nl names are necessary for Naturalowl to produce pronouns and demonstrative noun
phrases; hence, the higher referring expression score of the third configuration would not
have been possible without the nl names. The sentence fluency and clarity scores were also
affected in the fourth configuration, presumably because the automatically extracted names
made the texts more difficult to read and understand. There were also small decreases in the
scores for interest and even text structure, suggesting again that when the overall quality
of the texts decreases, the judges are biased towards lower scores in all of the criteria.
In the fifth configuration, aggregation was turned off, causing Naturalowl to produce
a separate sentence for each message triple. With sentences sharing the same subject no
longer being aggregated, more referring expressions for subjects had to be generated. Since
the component that generates pronouns and demonstrative noun phrases had been switched
off and the nl names had been removed, more repetitions of automatically extracted names
had to be used, which is why the score for referring expressions decreased further. Sentence
fluency was also affected, since some obvious aggregations were no longer being made, which
made the sentences look less natural. There was also a small decrease in the score for the
perceived text structure and interest, but no difference in the score for clarity. Overall, the
contribution of aggregation to the perceived quality of the texts seems to be rather small.
In the sixth configuration, all the sentence plans were removed, forcing Naturalowl to
use the default sentence plan and tokenized property identifiers. There was a sharp decrease
in sentence fluency and clarity, as one would expect, but also in the perceived interest of
the texts. There was also a small decrease in the perceived text structure, and no difference
in the score for referring expressions. Overall, these results indicate that sentence plans are
a very important part of the domain-dependent generation resources.
In the seventh configuration, the sections, assignments of properties to sections, and the
ordering of sections and properties were removed, causing Naturalowl to produce random
35. In all of the criteria, all the differences from one configuration to the next one are statistically significant, with the only exceptions being the differences in clarity between configurations 4 and 5, and the
differences in the scores for referring expressions between configurations 56 and 67. Again, when the
95% confidence intervals overlapped, we performed paired two-tailed t-tests ( = 0.05).

709

fiAndroutsopoulos, Lampouras, & Galanis

orderings of the message triples. There was a very sharp decrease in the score for text
structure. The scores for the perceived interest, clarity, but also sentence fluency were also
affected, again suggesting that when the overall quality of the texts decreases, the judges
are biased towards lower scores in all of the criteria.
We conclude that the sections and ordering information of the domain-dependent generation resources are, along with the sentece plans, particularly important. We note, however,
that the best scores were obtained by enabling all the components and using all the available
domain-dependent generation resources.

5. Conclusions and Future Work
We provided a detailed description of Naturalowl, an open-source nlg system that produces English and Greek texts describing individuals or classes of owl ontologies. Unlike
simpler verbalizers, which typically express a single axiom at a time in controlled, often
not entirely fluent English primarily for the benefit of domain experts, Naturalowl aims to
generate fluent and coherent multi-sentence texts for end-users in more than one languages.
We discussed the processing stages of Naturalowl, the optional domain-dependent generation resources of each stage, as well as particular nlg issues that arise when generating
from owl ontologies. We also presented trials we performed to measure the effort required
to construct the domain-dependent generation resources and the extent to which they improve the resulting texts, also comparing against a simpler owl verbalizer that requires no
domain-dependent generation resources and employs nlg methods to a lesser extent. The
trials showed that the domain-dependent generation resources help Naturalowl produce
significantly better texts, and that the resources can be constructed with relatively light
effort, compared to the effort that is typically needed to develop an owl ontology.
Future work could compare the effort needed to construct the domain-dependent generation resources against the effort needed to manually edit the lower quality texts produced
without domain-dependent generation resources. Our experience is that manually editing
texts generated by a verbalizer (or Naturalowl()) is very tedious when there is a large
number of individuals (e.g., products) of a few types to be described, because the editor has
to repeat the same (or very similar) fixes. There may be, however, particular applications
where post-editing the texts of a simpler verbalizer may be preferable.
We also aim to replace in future work the pipeline architecture of Naturalowl by a global
optimization architecture that will consider all the nlg processing stages in parallel, to avoid
greedy stage-specific decisions (Marciniak & Strube, 2005; Lampouras & Androutsopoulos,
2013a, 2013b). Finally, we hope to test Naturalowl with biomedical ontologies, such as the
Gene Ontology and snomed.36

References
Androutsopoulos, I., Kallonis, S., & Karkaletsis, V. (2005). Exploiting OWL ontologies in the
multilingual generation of object descriptions. In 10th European Workshop on NLG, pp. 150
155, Aberdeen, UK.
36. See http://www.geneontology.org/ and http://www.ihtsdo.org/snomed-ct/.

710

fiGenerating Natural Language Descriptions from OWL Ontologies

Androutsopoulos, I., Lampouras, G., & Galanis, D. (2012). Generating natural language descriptions
from OWL ontologies: A detailed presentation of the NaturalOWL system. Tech. rep., NLP
Group, Department of Informatics, Athens University of Economics and Business, Greece.
Androutsopoulos, I., Oberlander, J., & Karkaletsis, V. (2007). Source authoring for multilingual
generation of personalised object descriptions. Nat. Language Engineering, 13 (3), 191233.
Angeli, G., Liang, P., & Klein, D. (2010). A simple domain-independent probabilistic approach to
generation. In Conf. on Empirical Methods in NLP, pp. 502512, Cambridge, MA.
Antoniou, G., & van Harmelen, F. (2008). A Semantic Web Primer. MIT Press.
Areces, C., Koller, A., & Striegnitz, K. (2008). Referring expressions as formulas of description logic.
In 5th Int. Nat. Lang. Generation Conf., pp. 4249, Salt Fork, OH.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2002). The
Description Logic Handbook. Cambridge Univ. Press.
Barzilay, R., Elhadad, N., & McKeown, K. (2002). Inferring strategies for sentence ordering in
multidocument news summarization. Journal of AI Research, 17, 3555.
Barzilay, R., & Lapata, M. (2005). Collective content selection for concept-to-text generation. In
Human Lang. Technology Conf. and Conf. on Empirical Methods in Nat. Language Processing,
pp. 331338, Vancouver, British Columbia, Canada.
Barzilay, R., & Lapata, M. (2006). Aggregation via set partitioning for natural language generation.
In Human Lang. Technology Conf. of NAACL, pp. 359366, New York, NY.
Barzilay, R., & Lapata, M. (2008). Modeling local coherence: An entity-based approach. Comput.
Linguistics, 34 (1), 134.
Barzilay, R., & Lee, L. (2004). Catching the drift: Probabilistic content models, with applications to
generation & summarization. In 43rd Annual Meeting of ACL, pp. 113120, Ann Arbor, MI.
Bateman, J. (1990). Upper modelling: A general organisation of knowledge for nat. lang. processing.
In 5th Int. Workshop on NLG, pp. 5461, Dawson, PA.
Bateman, J. (1997). Enabling technology for multilingual nat. lang. generation: the KPML development environment. Nat. Lang. Engineering, 3 (1), 1556.
Bernardi, R., Calvanese, D., & Thorne, C. (2007). Lite natural language. In 7th Int. Workshop on
Comput. Semantics, Tilburg, The Netherlands.
Berners-Lee, T., Hendler, J., & Lassila, O. (2001). The Semantic Web. Sc. American, May, 3443.
Bontcheva, K. (2005). Generating tailored textual summaries from ontologies. In 2nd European
Semantic Web Conf., Heraklion, Greece.
Bontcheva, K., & Cunningham, H. (2003). The Semantic Web: a new opportunity and challenge
for human language technology. In Workshop on Human Lang. Tech. for the SW and Web
Services, 2nd Int. Semantic Web Conf., Sanibel Island, FL.
Bontcheva, K., Tablan, V., Maynard, D., & Cunningham, H. (2004). Evolving GATE to meet new
challenges in language engineering. Nat. Lang. Eng., 10 (3/4), 349373.
Bontcheva, K., & Wilks, Y. (2004). Automatic report generation from ontologies: the MIAKT
approach. In 9th Int. Conf. on Applications of Nat. Language to Information Systems, pp.
324335, Manchester, UK.
Brin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual Web search engine. Computer
Networks and ISDN Systems, 30 (1-7), 107117.
Busemann, S., & Horacek, H. (1999). A flexible shallow approach to text generation. In 9th Int.
Workshop on Nat. Lang. Generation, pp. 238247, New Brunswick, NJ.
711

fiAndroutsopoulos, Lampouras, & Galanis

Chen, H., Branavan, S., Barzilay, R., & Karger, D. (2009). Content modeling using latent permutations. Journal of Artificial Intelligence Research, 36, 129163.
Cheng, H., & Mellish, C. (2000). Capturing the interaction between aggregation and text planning
in two generation systems. In 1st Int. Conf. on Nat. Lang. Generation, pp. 186193, Mitzpe
Ramon, Israel.
Cregan, A., Schwitter, R., & Meyer, T. (2007). Sydney OWL syntax  towards a controlled natural
language syntax for OWL. In OWL Experiences and Directions Workshop, Innsbruck, Austria.
Dale, R., Green, S., Milosavljevic, M., Paris, C., Verspoor, C., & Williams, S. (1998). Dynamic
document delivery: generating natural language texts on demand. In 9th Int. Conf. and
Workshop on Database and Expert Systems Applications, pp. 131136, Vienna, Austria.
Dalianis, H. (1999). Aggregation in nat. lang. generation. Comput. Intell., 15 (4), 384414.
Dannells, D. (2012). On generating coherent multilingual descriptions of museum objects from
Semantic Web ontologies. In 7th International NLG Conf., pp. 7684, Utica, IL.
Dannels, D. (2008). Generating tailored texts for museum exhibits. In Workshop on Language
Technology for Cultural Heritage Data of the Language Resources and Evaluation Conf., Marrakech, Morocco.
Davis, B., Iqbal, A., Funk, A., Tablan, V., Bontcheva, K., Cunningham, H., & Handschuh, S. (2008).
Roundtrip ontology authoring. In 7th Int. Conf. on the Semantic Web, pp. 5065, Karlsruhe,
Germany.
Demir, S., Carberry, S., & McCoy, K. (2010). A discourse-aware graph-based content-selection
framework. In 6th Int. NLG Conf., pp. 1725, Trim, Co. Meath, Ireland.
Denaux, R., Dimitrova, V., Cohn, A., Dolbear, C., & Hart, G. (2010). Rabbit to OWL: Ontology
authoring with a CNL-based tool. In Fuchs, N. (Ed.), Controlled Nat. Language, Vol. 5972 of
Lecture Notes in Computer Science, pp. 246264. Springer.
Denaux, R., Dolbear, C., Hart, G., Dimitrova, V., & Cohn, A. (2011). Supporting domain experts
to construct conceptual ontologies. Web Semantics, 9 (2), 113127.
Duboue, P., & McKeown, K. (2001). Empirically estimating order constraints for content planning
in generation. In 39th Meeting of ACL, pp. 172179, Toulouse, France.
Duboue, P., & McKeown, K. (2003). Statistical acquisition of content selection rules for natural
language generation. In Conf. on Empirical Methods in Nat. Language Processing, pp. 121
128, Sapporo, Japan.
Duma, D., & Klein, E. (2013). Generating nat. lang. from Linked Data: Unsupervised template
extraction. In 10th Int. Conf. on Computational Semantics, pp. 8394, Potsdam, Germany.
Elhadad, M., & Robin, J. (1996). SURGE: A reusable comprehensive syntactic realization component. In 8th Int. NLG Workshop, Herstmonceux Castle, Sussex, UK.
Elsner, M., Austerweil, J., & Charniak, E. (2007). A unified local and global model for discourse
coherence. In Human Lang. Technologies Conf. of the North American Chapter of ACL, pp.
436443, Rochester, New York.
Fellbaum, C. (Ed.). (1998). WordNet: an Electronic Lexical Database. MIT Press.
Funk, A., Tablan, V., Bontcheva, K., Cunningham, H., Davis, B., & Handschuh, S. (2007). CLOnE:
Controlled language for ontology editing. In 6th Int. Semantic Web and 2nd Asian Semantic
Web Conf., pp. 142155, Busan, Korea.
Galanis, D., & Androutsopoulos, I. (2007). Generating multi-lingual descriptions from linguistically
annotated OWL ontologies: the NaturalOWL system. In 11th European Workshop on Nat.
Lang. Generation, Schloss Dagstuhl, Germany.
712

fiGenerating Natural Language Descriptions from OWL Ontologies

Gatt, A., & Reiter, E. (2009). SimpleNLG: A realisation engine for practical applications. In 12th
European Workshop on NLG, pp. 9093, Athens, Greece.
Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U. (2008). OWL 2: The
next step for OWL. Web Semantics, 6, 309322.
Grosz, B., Joshi, A., & Weinstein, S. (1995). Centering: a framework for modelling the local coherence
of discourse. Comput. Linguistics, 21 (2), 203225.
Halaschek-Wiener, C., Golbeck, J., Parsia, B., Kolovski, V., & Hendler, J. (2008). Image browsing
and natural language paraphrases of semantic web annotations. In 1st Workshop on Semantic
Interop. in the European Digital Library, 5th European Semantic Web Conf., Tenerife, Spain.
Hallett, C., Scott, D., & Power, R. (2007). Composing questions through conceptual authoring.
Comput. Linguistics, 33, 105133.
Halliday, M. (1994). Introduction to Functional Grammar (2nd edition). Edward Arnold.
Horrocks, I., Patel-Schneider, P., & van Harmelen, F. (2003). From SHIQ and RDF to OWL: the
making of a Web Ontology Language. Web Semantics, 1 (1), 726.
Isard, A., Oberlander, J., Androutsopoulos, I., & Matheson, C. (2003). Speaking the users languages.
IEEE Intelligent Systems, 18 (1), 4045.
Kaljurand, K. (2007). Attempto Controlled English as a Semantic Web Language. Ph.D. thesis,
Faculty of Mathematics and Computer Science, University of Tartu, Estonia.
Karamanis, N., Mellish, C., Poesio, M., & Oberlander, J. (2009). Evaluating centering for information
ordering using corpora. Comput. Linguistics, 35 (1), 2946.
Kasper, R., & Whitney, R. (1989). SPL: A sentence plan language for text generation. Tech. rep.,
Information Sciences Institute, University of Southern California.
Kaufmann, E., & Bernstein, A. (2010). Evaluating the usability of nat. lang. query languages and
interfaces to Semantic Web knowledge bases. Web Semantics, 8, 377393.
Kelly, C., Copestake, A., & Karamanis, N. (2010). Investigating content selection for language
generation using machine learning. In 12th European Workshop on Nat. Lang. Generation,
pp. 130137, Athens, Greece.
Konstas, I., & Lapata, M. (2012a). Concept-to-text generation via discriminative reranking. In 50th
Annual Meeting of the ACL, pp. 369378, Jeju Island, Korea.
Konstas, I., & Lapata, M. (2012b). Unsupervised concept-to-text generation with hypergraphs. In
Human Lang. Technology Conf. of NAACL, pp. 752761, Montreal, Canada.
Krahmer, E., & van Deemter, K. (2012). Computational generation of referring expressions: A
survey. Comput. Linguistics, 38 (1), 173218.
Lampouras, G., & Androutsopoulos, I. (2013a). Using integer linear programming for content selection, lexicalization, and aggregation to produce compact texts from OWL ontologies. In
14th European Workshop on Nat. Lang. Generation, 51st Annual Meeting of ACL, pp. 5160,
Sofia, Bulgaria.
Lampouras, G., & Androutsopoulos, I. (2013b). Using integer linear programming in concept-to-text
generation to produce more compact texts. In 51st Annual Meeting of ACL (short papers),
pp. 561566, Sofia, Bulgaria.
Langkilde, I. (2000). Forest based statistical sentence generation. In 1st Conf. of the North American
Chapter of ACL, pp. 170177, Seattle, WA.
Lavoie, B., & Rambow, O. (1997). A fast and portable realizer for text generation systems. In 5th
Conf. on Applied Nat. Language Processing, pp. 265268, Washington DC.
713

fiAndroutsopoulos, Lampouras, & Galanis

Liang, P., Jordan, M., & Klein, D. (2009). Learning semantic correspondences with less supervision.
In 47th Meeting of ACL and 4th AFNLP, pp. 9199, Suntec, Singapore.
Liang, S., Scott, D., Stevens, R., & Rector, A. (2011a). Unlocking medical ontologies for non-ontology
experts. In 10th Workshop on Biomedical NLP, Portland, OR.
Liang, S., Stevens, R., Scott, D., & Rector, A. (2011b). Automatic verbalisation of SNOMED classes
using OntoVerbal. In 13th Conf. AI in Medicine, pp. 338342, Bled, Slovenia.
Mann, W., & Thompson, S. (1998). Rhetorical structure theory: A theory of text organization. Text,
8 (3), 243281.
Marciniak, T., & Strube, M. (2005). Beyond the pipeline: Discrete optimization in NLP. In 9th
Conf. on Comput. Nat. Language Learning, pp. 136143, Ann Arbor, MI.
McKeown, K. (1985). Text Generation. Cambridge Univ. Press.
McRoy, S., Channarukul, S., & Ali, S. (2003). An augmented template-based approach to text
realization. Nat. Language Engineering, 9 (4), 381420.
Melengoglou, A. (2002). Multilingual aggregation in the M-PIRO system. Masters thesis, School
of Informatics, University of Edinburgh, UK.
Mellish, C. (2010). Using Semantic Web technology to support NLG  case study: OWL finds RAGS.
In 6th Int. NLG Conf., pp. 8593, Trim, Co. Meath, Ireland.
Mellish, C., & Pan, J. (2008). Nat. lang. directed inference from ontologies. Artificial Intelligence,
172, 12851315.
Mellish, C., Scott, D., Cahill, L., Paiva, D., Evans, R., & Reape, M. (2006). A reference architecture
for nat. lang. generation systems. Nat. Language Engineering, 12, 134.
Mellish, C., & Sun, X. (2006). The Semantic Web as a linguistic resource: opportunities for nat.
lang. generation. Knowledge Based Systems, 19, 298303.
Nguyen, T., Power, R., Piwek, P., & Williams, S. (2012). Planning accessible explanations for
entailments in OWL ontologies. In 7th International NLG Conf., pp. 110114, Utica, IL.
Oberlander, J., Karakatsiotis, G., Isard, A., & Androutsopoulos, I. (2008). Building an adaptive
museum gallery in Second Life. In Museums and the Web, Montreal, Canada.
ODonnell, M., Mellish, C., Oberlander, J., & Knott, A. (2001). ILEX: an architecture for a dynamic
hypertext generation system. Nat. Language Engineering, 7 (3), 225250.
Poesio, M., Stevenson, R., & Di Eugenio, B. (2004). Centering: A parameter theory and its instantiations. Comput. Linguistics, 30 (3), 309363.
Power, R. (2009). Towards a generation-based semantic web authoring tool. In 12th European
Workshop on Nat. Lang. Generation, pp. 915, Athens, Greece.
Power, R. (2010). Complexity assumptions in ontology verbalisation. In 48th Annual Meeting of
ACL (short papers), pp. 132136, Uppsala, Sweden.
Power, R. (2011). Deriving rhetorical relationships from semantic content. In 13th European Workshop on Nat. Lang. Generation, Nancy, France.
Power, R. (2012). OWL simplified english: a finite-state language for ontology editing. In 3rd
International Workshop on Controlled Natural Language, pp. 4460, Zurich, Switzerland.
Power, R., & Scott, D. (1998). Multilingual authoring using feedback texts. In 17th Int. Conf. on
Comp. Ling. and 36th Meeting of ACL, pp. 10531059, Montreal, Canada.
Power, R., & Third, A. (2010). Expressing OWL axioms by English sentences: Dubious in theory,
feasible in practice. In 23rd Int. Conf. on Comput. Linguistics, pp. 10061013, Beijing, China.
714

fiGenerating Natural Language Descriptions from OWL Ontologies

Ratnaparkhi, A. (2000). Trainable methods for surface natural language generation. In 1st Conf. of
the North American Chapter of ACL, pp. 194201, Seattle, WA.
Rector, A., Drummond, N., Horridge, M., Rogers, J., Knublauch, H., Stevens, R., Wang, H., &
Wroe, C. (2004). OWL pizzas: Practical experience of teaching OWL-DL: Common errors and
common patterns. In 14th Int. Conf. on Knowledge Engineering and Knowledge Management,
pp. 6381, Northamptonshire, UK.
Reiter, E. (1995). NLG vs. templates. In 5th European Workshop on Nat. Lang. Generation, Leiden,
The Netherlands.
Reiter, E., & Dale, R. (2000). Building Natural Lang. Generation Systems. Cambridge Univ. Press.
Ren, Y., van Deemter, K., & Pan, J. (2010). Charting the potential of description logic for the
generation of referring expressions. In 6th Int. Nat. Lang. Generation Conf., pp. 115123,
Trim, Co. Meath, Ireland.
Schutte, N. (2009). Generating nat. language descriptions of ontology concepts. In 12th European
Workshop on Nat. Lang. Generation, pp. 106109, Athens, Greece.
Schwitter, R. (2010a). Controlled nat. languages for knowledge representation. In 23rd Int. Conf.
on Comput. Linguistics (posters), pp. 11131121, Beijing, China.
Schwitter, R. (2010b). Creating and querying formal ontologies via controlled nat. language. Applied
Artificial Intelligence, 24, 149174.
Schwitter, R., Kaljurand, K., Cregan, A., Dolbear, C., & Hart, G. (2008). A comparison of three
controlled nat. languages for OWL 1.1. In 4th OWL Experiences and Directions Workshop,
Washington DC.
Schwitter, R., & Tilbrook, M. (2004). Controlled natural language meets the Semantic Web. In
Australasian Language Technology Workshop, pp. 5562, Sydney, Australia.
Shadbolt, N., Berners-Lee, T., & Hall, W. (2006). The Semantic Web revisited. IEEE Intell. Systems,
21, 96101.
Stevens, R., Malone, J., Williams, S., Power, R., & Third, A. (2011). Automatic generation of
textual class definitions from OWL to English. Biomedical Semantics, 2 (S 2:S5).
Third, A. (2012). Hidden semantics: What can we learn from the names in an ontology?. In 7th
International NLG Conf., pp. 6775, Utica, IL.
van Deemter, K., Krahmer, E., & Theune, M. (2005). Real versus template-based natural language
generation: a false opposition?. Comput. Linguistics, 31 (1), 1524.
Walker, M., Rambow, O., & Rogati, M. (2001). Spot: A trainable sentence planner. In 2nd Annual
Meeting of the North American Chapter of ACL, pp. 1724, Pittsburgh, PA.
Wan, S., Dras, M., Dale, R., & Paris, C. (2010). Spanning tree approaches for statistical sentence
generation. In Krahmer, E., & Theune, M. (Eds.), Empirical Methods in Nat. Lang. Generation, pp. 1344. Springer.
White, M. (2006). CCG chart realization from disjunctive inputs. In 4th Int. Nat. Lang. Generation
Conf., pp. 1219, Sydney, Australia.
Williams, S., & Power, R. (2010). Grouping axioms for more coherent ontology descriptions. In 6th
Int. Nat. Lang. Generation Conf., pp. 197201, Trim, Co. Meath, Ireland.
Williams, S., Third, A., & Power, R. (2011). Levels of organization in ontology verbalization. In
13th European Workshop on Nat. Lang. Generation, pp. 158163, Nancy, France.

715

fiJournal of Artificial Intelligence Research 48 (2013) 415473

Submitted 05/13; published 11/13

Defeasible Inheritance-Based Description Logics
Giovanni Casini

GCasini@csir.co.za

Centre for Artificial Intelligence Research (CAIR)
CSIR Meraka Institute and UKZN, South Africa

Umberto Straccia

umberto.straccia@isti.cnr.it

Istituto di Scienze e Tecnologie dellInformazione (ISTI)
CNR, Italy

Abstract
Defeasible inheritance networks are a non-monotonic framework that deals with hierarchical knowledge. On the other hand, rational closure is acknowledged as a landmark of the
preferential approach to non-monotonic reasoning. We will combine these two approaches
and dene a new non-monotonic closure operation for propositional knowledge bases that
combines the advantages of both. Then we redene such a procedure for Description Logics
(DLs), a family of logics well-suited to model structured information. In both cases we will
provide a simple reasoning method that is built on top of the classical entailment relation
and, thus, is amenable of an implementation based on existing reasoners. Eventually, we
evaluate our approach on well-known landmark test examples.

1. Introduction
The notion of rational closure (Lehmann & Magidor, 1992) is acknowledged as a landmark
for non-monotonic reasoning due to its rm logical properties, but it has limited inference
capabilities: e.g. an exceptional class will not inherit any of the typical properties from its
superclass. Consider penguins: they are atypical birds, since they do not y, but they still
share a lot of typical properties of birds, e.g. they have wings. However, under rational
closure we may not infer that penguins have wings. On the other hand, Defeasible Inheritance Networks (INs) (Horty, 1994) are a non-monotonic framework appropriate for the
formalisation of hierarchical knowledge that does not have such a limitation, but exhibit
questionable logical properties (see Section 3.1).
We combine these two approaches and dene a new non-monotonic closure operation
for propositional knowledge bases that combines the advantages of both, and then we apply
the method to Description Logics (DLs) (Baader, Calvanese, McGuinness, Nardi, & PatelSchneider, 2003), a family of logics that are known to be well-suited to model structured
information.
1.1 Contributions and Roadmap
Section 2.1 is just a brief recap of a classical approach to inheritance nets, Hortys (1994)
skeptical extension, while Section 2.2 describes the classical rational closure for propositional
logic, generalising a method presented by Freund (1998). The remaining material addresses
our contributions that can be summarised as follows.
c
2013
AI Access Foundation. All rights reserved.

fiCasini & Straccia

1. In Section 3 we propose a new method to reason about INs that relies on the procedure for rational closure, and we present a Boolean extension of INs, called Boolean
defeasible Inheritance Networks (BINs).
2. Using BINs, we develop in Section 4 a defeasible inheritance-based propositional closure
that combines the advantages of both inheritance nets and rational closure.
3. Eventually, in Section 5 we apply the latter procedure to the case of defeasible inheritancebased description logics.
A major feature of the procedures we propose is that for propositional logic and DLs
we still maintain all desired logical properties of rational closure, but with more inferential
power with respect to exceptional classes. Moreover our method requires only the existence
of a decision procedure for classical entailment and, thus, can be implemented on top of
existing propositional SAT solvers and DL reasoners.
Please note that the present paper is a substantially revised and extended version of a
previous work (Casini & Straccia, 2011). Specically,
1. we provide an in-depth description of our reasoning model;
2. we extensively validate our approach w.r.t. to a series of landmark (test) examples
illustrated by Horty (1994) and Sandewall (2010) (see Appendix A);
3. we provide computational complexity results related to our reasoning procedures; and
4. we include the proofs supporting out major claims (see Appendix B); due to the
complexity of the notation, we add also a table summarising the meaning of the
symbols we use more frequently (Appendix C).
1.2 Related Work
We refer to two main approaches to non-monotonic reasoning: inheritance networks on one
hand and the preferential approach on the other.
Inheritance networks have been developed as a formalism for reasoning about taxonomic
information. From the original ideas of Touretzky (1986), the approach has richly developed
(Sandewall, 1986; Touretzky, Horty, & Thomason, 1987; Horty, Thomason, & Touretzky,
1987; Touretzky, Thomason, & Horty, 1991; Makinson, 1991; Simonet, 1996). See the works
by Horty (1994) and Thomason (1992) for an overview, while Gabbay and Schlecta (2009)
and Sandewall (2010) have more recently contributed to the eld. In particular, in order
to evaluate our proposal, we shall refer to the skeptical approach described by Horty (1987,
1994) as the landmark of the classical approach to inheritance networks.
On the other hand, Lehmann and Magidors rational closure falls into the preferential
approach to non-monotonic reasoning; such an approach, since the rst formulation by
Shoham (1988), has become a main representative of non-monotonic reasoning (Kraus,
Lehmann, & Magidor, 1990; Lehmann & Magidor, 1992; Makinson, 1994, 2005; Freund,
1998; Bochman, 2001; Rott, 2001; Schlechta, 2004), particularly appreciated for the solid
logical characterization of the consequence relation.
Eventually, our proposal shall be applied in the eld of description logics (Baader et al.,
2003). Several non-monotonic DLs exist (Baader & Hollunder, 1993; Bonatti, Faella, &
416

fiDefeasible Inheritance-Based Description Logics

Sauro, 2011c, 2011b; Brewka & Augustin, 1987; Britz, Heidema, & Meyer, 2008; Donini,
Nardi, & Rosati, 2002; Giordano, Olivetti, Gliozzi, & Pozzato, 2009; Giordano, Gliozzi,
Olivetti, & Pozzato, 2012b; Grimm & Hitzler, 2009; Knorr, Alferes, & Hitzler, 2011; Quantz
& Royer, 1992; Straccia, 1993), which integrate several kinds of non-monotonic reasoning
mechanism into DLs. Somewhat related to our proposal are the works by Britz et al. (2008)
and Giordano et al. (2009, 2012b), as they address the application of the preferential methods into the DL framework, but they do not refer to rational closure. In a previous publication (Casini & Straccia, 2010) we present a procedure to apply rational closure to DLs, and
such a procedure is at the basis of our actual proposal, but here we modify the approach in
order to amplify its inferential power.

2. Preliminaries
For completeness, we start with the basic notions about INs and propositional rational
closure we shall rely on.
2.1 Defeasible Inheritance Networks
In INs (Horty, 1994; Sandewall, 2010) there are classes (nodes), a strict subsumption relation
and a defeasible subsumption relation among such classes (links). We shall indicate nodes
by letters p, q . . ., and we shall describe an IN by a pair N = hS, U i, where S is a set of
strict links, while U is a set of defeasible links. Every link in N is a direct link, and it can
be strict or defeasible, positive or negative. Specically,
1. p  q: class p is subsumed by class q [positive strict link];
2. p 6 q: class p and class q are disjoint [negative strict link];
3. p  q: an element of the class p is usually an element of the class q [positive defeasible
link];
4. p 6 q: an element of the class p is usually not an element of the class q [negative
defeasible link].
Example 2.1. The typical penguin example could be represented as N = h{p  b}, {p 6
f, b  f, b  w}i, reading b as Bird, p as Penguin, f as Flying and w as has Wings.
In the presence of strict links only, the subsumption relation between the classes would
correspond simply to a transitive closure of the links: if p is subsumed by q and q is
subsumed by r, then p is subsumed by r. Instead, the presence of defeasible links implies
the possibility of potential inconsistencies in the hierarchy of classes, as in the penguin
example: a transitive closure of the subsumption relation would force us to conclude at
the same time that penguins are ying and non-ying creatures. Hence reasoning with
inheritance networks consists mainly in deciding which conclusions have to be considered
valid when faced with potential contradictions. In most of the classical approaches such
decisions are based on the notions of potential path and preemption (a procedure that,
given two conicting paths, allows to choose the one resting on more specic information,
invalidating the other). Among the various proposals, we shall briey present Hortys (1994)
417

fiCasini & Straccia

classical approach, to which we shall refer as a landmark. First, we recall the notion of path
that is shared by all the classical approaches to INs. We refer to the paths by means of
Greek letters (, , , ,  . . .), or with tuples indicating the sequence of the nodes involved.
For example, the triple  = hp, , qi indicates a path  that starts from the node p, passes
through the path , and ends into the node q.
Definition 2.1 (Potential Paths, Horty, 1994, p. 117). Given a net N = hS, U i, we can
define iteratively its paths (where 99K {, } and 699K {6, 6})1 :
 Every direct link in N is a simple path:
 If p 99K q  S, hp, qi is a positive path.
 If p 699K q  S, hp, qi is a negative path.
 Assume a path  = ht, , pi.
 If  is positive,
 If p 99K q  S, h, qi is a positive path.
 If p 699K q  S, h, qi is a negative path.
 If  is negative,
 If q  p  S, h, qi is a negative path.
If a path is composed only by strict links, it is a strict path, otherwise it is a defeasible
one.
A potential path represents a potential argumentation, and we have to decide if it is
valid or not. If the path is strict, it is automatically considered as valid, otherwise, in case
of potential conicts between the conclusions of distinct defeasible paths, we have to choose
which ones of them have to be considered as valid.
Using the notions of path and preemption, Horty denes an iterative construction of
an extension of a net, that is, of the set of the paths considered valid in the net. Due to
the complexity of the formal denition, we describe just roughly the procedure, referring to
Hortys work (1994, sect. 3), for a better insight.
The inductive construction of the paths is based on a notion of degree of paths. Once
we have identied the potential paths, we can dene also a notion of generalised path. That
is, a generalisation of defeasible paths that, given   {, 6, , , 6}, is dened as:
1. every direct link is a generalised path;
2. if  = h, pi is a generalised path, and p  q  N , then h, qi is a generalised path.
We associate to every defeasible path hp, , qi a number that corresponds to the number
of links in the longest generalised path between p and q, denoted as degN (hp, , qi).
In inheritance nets, the notion of contradiction corresponds to the notion of conflict:
we say that a path is conicted if there is another path with the same starting and end
points, but opposite polarity (i.e., we have two potential paths moving from a node p to a
1. We assume the link 6 to be symmetric, that is, if p 6 q  S, then q 6 p  S too.

418

fiDefeasible Inheritance-Based Description Logics

node q, but one is positive while the other is negative). If we are dealing with strict paths,
the presence of a conict points out an actual contradiction, while, dealing with defeasible
paths, the contradiction is just potential and could be resolved by the notion of preemption
(Horty, 1994, Def. 3.2.2) that allows to prefer the path relying on more specic information.
In the procedure dened by Horty we start with a net N , and, working iteratively on the
degree of the paths, we dene a sequence of pairs hN , Pi i, where Pi is the set of the paths
considered valid at the i-th step. In brief, given a net N = hS, U i, Hortys procedure results
into the construction of a sequence of sets of valid paths P0 , P1 , P2 , . . . where:
1. P0 = N ; and
2. Pn+1 is Pn united with all the paths of degree n + 1 and that are the extension of a
valid path of degree n and that preempt all the eventual conicting paths.
S
The skeptical extension of a net N is dened by 
n=1 Pn (Horty, 1994, sect. 2.2.2 and
3.3.2). To indicate that a (positive or negative, strict or defeasible) connection between two
nodes p and q is considered valid in Hortys skeptical extension we write N
p  q, with
  {, 6, , 6}.
Example 2.2. Consider example 2.1; following Hortys procedure we obtain a skeptical
extension of the net composed of the valid paths p  b, p 6 f, b  f, b  w, p  b  w.
Consistency. A net is considered inconsistent i we can validate two conicting paths,
that is, there is a pair of nodes p and q such that we can derive both a positive connection
(N
p  q or N
p  q) and a negative one (N
p 6 q or N
p 6 q) between
them.
2.2 Propositional Rational Closure
Non-monotonic systems can be analysed from the point of view of the properties of the consequence relations they dene (Makinson, 1994). From such a perspective INs do not satisfy
some desirable logical properties, presented below, such as (CM) and (CT) (Makinson, 1994,
pp. 56-57).
Even if the satisfaction of the structural properties we are going to present is not unanimously considered as a necessary condition for a formalization of defeasible reasoning,
since most of the interesting nonmonotonic logics do not satisfy some of them, we still consider their satisfaction as a desiderata: such properties are intuitive and give back a strong
logical characterization of the consequence relation, they have a solid semantic characterization based on preferential interpretation (Kraus et al., 1990; Lehmann & Magidor, 1992),
and have strong connections to the classic AGM approach to belief revision (Alchourron,
Gardenfors, & Makinson, 1985). Moreover the decision problem can be often reduced to
a procedure based on the classical decision problem (as in the proposal we are going to
present) allowing to implement the procedure on top of existing reasoners, and the systems
based on the preferential approach rarely give back counter-intuitive results. The main
problems are that the inferential power of such approaches is often too weak (we can often
point out conclusions that we would like to obtain, but that the system is not able to derive), and that the preferential approach has been developed for propositional logics, and
the attempts to extend it to rst-order languages have turned out to be quite problematic.
419

fiCasini & Straccia

The proposal we are going to present tries to overcome such inferential weaknesses, characteristic of the classical preferential approaches. After presenting it for the propositional
languages, we readapt the procedure to the expressivity of DLs since, even if the preferential approach cannot be easily reformulated for rst-order logics, it turns out to be still
appropriate for fragments of rst-order logic as DLs.
In what follows, we shall present a procedure for building the rational closure of a
knowledge base using the default-assumption approach (Poole, 1988; Makinson, 2005); such
an approach reduces the construction of the rational closure into a series of checks based on
the classical consequence relations. The procedure we are presenting heavily relies on the
one by Freund (1998).
Specically, consider a classical propositional language built on a nite set of propositional letters P = {p1 , . . . , pn }, using the classical connectives , , , , ; sentences will
be denoted by capital letters C, D, E . . ., while sets of sentences by capital Greek letters
, , . . ., and  and  will have the usual meaning of true and false; in the knowledge
bases, we shall indicate consequential information by means of C  D and C|D, respectively strict and defeasible conditionals, that have to be read respectively as If C, then
always D and If C, then typically D.  denotes the classical entailment relation, and,
given a set of formulae  or a set of strict conditionals T , we indicate by  and T the
monotonic entailment relations obtained adding to , respectively, the set of propositional
formulae  or the set of conditionals {C |= D | C  D  T } as extra information; we shall
use | also to indicate a generic non-monotonic consequence relation.
The knowledge base (KB) of an agent can be represented by means of conditionals or
by means of formulae; we call conditional knowledge base a pair hT , Di, where T is a nite
set of strict conditionals and D is a nite set of defeasible conditionals.
Example 2.3. The penguin example can be encoded as: K = hT , Di with T = {p  b} and
D = {p|f, b|f, b|w}.
Another way to formalize defeasible information may be based simply on formulae, using
the default-assumption approach: a default-assumption knowledge base is a pair h, i,
where  and  are sets of formulae representing respectively what the agent considers as
necessarily true and as typically true.
Example 2.4. The penguin example could be encoded as: K = h, i with  = {p  b}
and  = {b  f, p  f, b  w}.
We shall use the Greek letter  to distinguish default-assumption formulae (i.e., the
members of ). We next show how to map a conditional knowledge base into a defaultassumption knowledge base (we will transform KBs of the kind of the one in Example 2.3
into KBs of the kind in Example 2.4), and then we show a simple procedure to reason within
the latter, by relying only on a decision procedure for |=.
We proceed as follows: (i) we dene the notions of rational consequence relation and
rational closure, (ii) then, we describe a procedure to build a rational closure using a
default-assumption knowledge base.
420

fiDefeasible Inheritance-Based Description Logics

A consequence relation | is rational i it satises the following properties (Lehmann &
Magidor, 1992):
(REF)
(CT)

(CM)

(LLE)

(RW)

C|C for every C
C|D

Reexivity

C  D|F
C|F

C|D
C|F
C  D|F
C|F

C|D

Cautious Monotony

|= C  D
D|F

D |= F
C|F

Cut (Cumulative Transitivity)

Left Logical Equivalence

Right Weakening

(OR)

C|F
D|F
C  D|F

Left Disjunction

(RM)

C|F
C6|D
C  D|F

Rational Monotony

The rst six properties, (REF)(OR), characterise the class of the preferential consequence relations: that is, given a conditional base
D = {C1 |E1 , . . . , Cn |En } ,
we say that a conditional C|D is in the preferential closure P(D) i it is derivable from
D using the rules (REF)(OR) (Kraus et al., 1990). However, the preferential closure is
generally considered inferentially too weak to be satisfactory, and so it is natural to look
for stronger forms of closure.
The closure under the rule (RM) is considered, between the interesting rules, the
strongest one. However, given the form of such a rule (we have a negated conditional
between the premises), the rational extension of a conditional base D is not unique. Indeed,
we have multiple possibilities to close D under such a condition: for example, if we have
D = {C|F }, then neither C  D|F nor C|D are in D and we can choose to add to
D either of them in order to satisfy (RM); moreover, as this simple example shows, it is
possible that the consequence relation obtained from the intersection of dierent rational
extensions of a knowledge base does not satisfy (RM) anymore (in this particular case, the
intersection would not contain neither C  D|F nor C|D). Hence, to dene a rational
closure for a conditional base D, we have to choose one between the possible rational extensions of D. Lehmann and Magidor have dened a rational closure operation R that satises
a set of desiderata (Lehmann & Magidor, 1992, sect. 5.1-5.3).
1. P(D)  R(D). That is, the conditional base D and every conditional preferentially
derivable from it should be in the rational closure of D.
2. For every conditional of form C|, C|  R(D) i C|  P(D). Analogously, for
every conditional of form |C, |C  R(D) i |C  P(D). The conditionals of
421

fiCasini & Straccia

form C| dene what situations are simply considered impossible, while the conditionals of form |C indicate what is considered typical in general. Both such kinds
of information are properly managed by the preferential closure.
3. If we have that C|F  P(D), C|D, C D|F 
/ P(D), we prefer a closure operation
adding C  D|F instead of C|D: the sense of a rule as (RM) is to employ a constrained form of monotonicity (given C|F , we add C  D|F ), not to arbitrarily add
new defaults (the addition of C|D); hence, whenever possible, given a conditional
C|F we want to consider its strengthening C  D|F instead of the unmotivated
addition of a conditional C|D.
We shall not describe Lehmann and Magidors rational closure by referring to the original
formulation (Lehmann & Magidor, 1992). Instead, we shall directly refer to a correspondent
construction, heavily relying on the procedure dened by Freund (1998), and based on the
translation of a conditional KB into a default-assumption KB, which we illustrate next.
We start with a conditional KB K = hT , Di. The rst steps (Steps 1-3) are to dene
an exceptionality ranking for all the conditionals in the KB, following the analogous procedure by Lehmann and Magidor (1992): such a ranking will permit to distinguish correctly
the strict and the defeasible knowledge contained in the KB (Step 4), since part of the
strict knowledge could be implicitly contained in D. This will allow us to construct the
correspondent default-assumption KB (Steps 5-6). Specically:
Step 1. We translate the strict knowledge into defeasible conditionals, that is, we move
from a KB hT , Di to h, D  i, where
D  = D  {C  D| | C  D  T } .
Intuitively, in the preferential setting, saying that C  D is valid is equivalent to
saying that its negation is an absurdity ((C  D)|) (Bochman, 2001, sect. 6.5).
Step 2. We dene D  as the set of the materialisations of the conditionals in D  , i.e., the
material implications corresponding to such conditionals:
D  = {C  D | C|D  D  } .
Also, we indicate by AD the set of the antecedents of the conditionals in D  :
AD = {C | C|D  D  } .
Step 3. We dene an exceptionality ranking of the conditionals in D  (Lehmann & Magidor, 1992, sect. 2.6). We build such a ranking on the following notion of exceptionality.
Given a set of conditionals D, a formula C is exceptional for D i D preferentially
entails |C (i.e., |C  P(D)); recall that a conditional |C  R(D) i |C 
P(D).
A conditional C|D is said to be exceptional for D i its antecedent C is exceptional for D. The exceptionality of a proposition can be decided based on |= only
(Lehmann & Magidor, 1992, Corol. 5.22), as C is exceptional for a set of conditionals
422

fiDefeasible Inheritance-Based Description Logics

D (i.e., |C  P(D)) i D |= C, where D is the set of the materialisations of the
conditionals in D.
Let E(AD ) indicate the set of the antecedents that result exceptional w.r.t. D, that is
E(AD ) = {C  AD | D |= C} ,
and with E(D) the exceptional conditionals in D, i.e.,
E(D) = {C|D  D | C  E(AD )} .
Obviously, for every D, E(D)  D.
Step 3.1. Taking under consideration the knowledge base h, D  i, we can construct
iteratively a sequence E0 , E1 . . . of subsets of the conditional base D  in the following way:
E0 = D 
Ei+1 = E(Ei ) .
Since D  is a nite set, the construction will terminate with an (empty or nonempty) xed point of E, i.e., a set composed only of exceptional conditionals,
which materialisations negate all their own antecedents.
Step 3.2. Using such a sequence, we dene a ranking function r that associates to
every conditional in D  a number, representing its own level of exceptionality:
r(C|D) =



i
if C|D  Ei and C|D 
/ Ei+1
 if C|D  Ei for every i .

Step 4. In Step 3 we have dened the materialisation of D  and the rank of every conditional in it. Now,
Step 4.1. we can determine if D  is inconsistent. A conditional base D is inconsistent if from it we can derive the conditional |. We know from above that a
conditional of the form |C is in the rational closure of D i it is in its preferential closure, that is, given the result recalled in Step 3.1, we can check the
consistency of D  using D  : |  P(D  ) i D  |= ;
Step 4.2. if D  is consistent, we dene the background theory Te of the agent as2
Te = {  C | C|D  D  and r(C|D) = } .

Moreover, one may verify that for every conditional in T there is a logically
equivalent conditional in Te ;

2. One may easily verify the correctness of this definition referring to results in the work of Bochman
(2001, sect. 7.5.3, Definition 7.5.1, the definition of clash on p.178, Corollary 7.5.7, Definition 7.5.2, and
Lemma 7.5.5). It suffices to show that the set of the conditionals with  as ranking value represents
the greatest clash of D (the proof is quite immediate by the definition of the exceptionality ranking).

423

fiCasini & Straccia

e i.e., the
Step 4.3. once we have Te , we can also identify the set of conditionals D,

defeasible part of the information contained in D : i.e.,
e = {C|D  D  | r(C|D) < } (obviously, D
e  D) .
D

Essentially, so far we have moved into T the non-defeasible knowledge hidden in D,
e Moreover, we have the ranking values of all
obtaining a new conditional base hTe , Di.
e
the conditionals in D.

Step 5. Now we build the default-assumption characterization of the rational closure of
e To do so, we translate Te into a set of correspondent formulae ,
e i.e.,
hTe , Di.
e = {C |   C  Te } ,


e into a sequence of default-assumptions (i.e., formulae) .
e Specically, given
and D
e
the rank value of the conditionals in D, we construct a sequence of default assumptions
e = h0 , . . . , n i ,


e and
where n is the highest rank-value in D,
^
e and r(C|D)  i} .
i = {C  D | C|D  D

(1)

Dening the default-assumptions in this way, as presented by Freund (1998), we obtain
a set of default formulae, each one associated with a rank value, s.t. every default
formula is classically derivable from the preceding ones, that is,
i |= i+1 , for 0  i < n .
e and the default-assumption set ,
e according
Step 6. Given now the background theory 
e
e
to the steps dened so far, we associate to the agent the pair h, i. Combining such
steps with the main theorem in Freunds work (1998, Thm. 24), it can be shown that
e i
e is
the default-assumption characterisation of the agent by means of the pair h,
equivalent to the rational closure of the pair hT , Di dened by Lehmann and Magidor
(1992). That is,
Proposition 2.1. Given a knowledge base K = hT , Di,
C|D  R(K) ,
where R is the rational closure operation defined by Lehmann and Magidor (1992), iff
e  {i } |= D,
{C}  

e (we indicate it by
where i is the first formula in h0 , . . . , n i consistent with {C}  
C|h,
e i
e D).
424

fiDefeasible Inheritance-Based Description Logics

As a consequence, using the following knowledge base transformations
hT , Di

e
hTe , Di

h, D  i

e i
e ,
h,

()

e i
e by means of Proposition 2.1,
we can characterise the rational closure of hT , Di via h,
i.e.,
C|D  R(hT , Di) i C|h,
e i
e D .
So, we have a method to decide defeasible consequence under rational closure. Specically, given a defeasible knowledge base hT , Di and the propositions C and D,
1. once for all, apply to hT , Di the transformations () to obtain the defeasible knowle i;
e
edge base h,

e
e =
2. given C, determine i as the rst ({C}  )-consistent
formula of the sequence 
h0 , . . . , n i.
3. then decide if D follows under rational closure from C w.r.t. hT , Di by determining
e  {i }  D.
whether {C}  

Example 2.5. Consider again the case of the penguin, with the knowledge base of Example 2.3. First (Step1), we move the strict knowledge in T into the defeasible part, obtaining
D  = {p  b|, p|f, b|f, b|w} .
Then (Step2) we define the set of the materialisations
D  = {p  b  , p  f, b  f, b  w} ,
and the correspondent set of antecedents
AD = {p  b, b, p} .

We use the set of materialisations D  to determine the ranking value of the formulae in
AD and the conditionals in D  (Step3), obtaining
0 = r(b) = r(b|f ) = r(b|w)
1 = r(p) = r(p|f )
 = r(p  b) = r(p  b|) .
So (Step4), we define a conditional base

with

e = hTe , Di
e ,
K
Te = {  p  b}
e = {p|f, b|f, b|w}
D

(since in this case the strict and the defeasible part of the conditional base were correctly
e is the same as K).
separated already in the initial base K, we obtain that K
425

fiCasini & Straccia

Such a conditional base is translated into a knowledge base

(Step5), with

where

e i
e
h,
e = {p  b}

e = {0 , 1 } ,

0 = (p  f )  (b  f )  (b  w)
1 = p  f .

Using such default information, we conclude (Step6) that penguins do not fly, birds fly
and birds have wings.
Remark 1. Considering Example 2.5, it would be intuitive also to conclude that penguins
have wings (p|w), but in the rational closure a category that is recognized as atypical, as the
category of penguins in the present case (they are birds, but they dont fly, and consequently
r(p) = 1), cannot inherit any of the typical characteristics of their super classes. Hence we
are not allowed to conclude that, presumably, penguins have wings. Such a weak inferential
power is generally considered the main limit of the rational closure. On the other hand, as
we are going to see in the next section, INs manage successfully this kind of problems.
This procedure to determine the rational closure maintains the same computational
complexity as the classical decision procedure, since it is easily veried that all the transformations in () require at most O(|K|) entailment tests and, given also proposition 2.1
and the fact that the strict part can encode any (monotone) propositional theory, we have
that
Proposition 2.2. Deciding propositional defeasible consequence under rational closure (|, )
is coNP-complete.
Lehmann and Magidor (1992) specify also a semantic characterization of the propositional rational closure, and an alternative correspondent construction has been recently
presented by Giordano et al. (2012a). If we move from propositional logic to DLs, a version
of rational closure for the language ALC has previously been proposed (Casini & Straccia,
2010), and such a procedure can be semantically characterized by means of preferential DL
interpretations (Britz, Casini, Meyer, Moodley, & Varzinczak, 2013).
As seen above, rational closure denes a non-monotonic consequence relation with an intuitive behaviour and strong logical properties; however, as by Remark 1, it is also somewhat
weak, as often there are conclusions about exceptional situations that, despite intuitive, we
cannot derive. Such a behaviour is due to the fact that the procedure associates to a set of
premises only those conditionals that are at least as exceptional.
Next, we are going to rene rational closure in order to avoid such a loss of inferential
power w.r.t. exceptional premises. Our proposal is based on a modication of the initial
knowledge base: we add new conditionals that give information about exceptional cases that
426

fiDefeasible Inheritance-Based Description Logics

would be lost in the rational closure procedure. Such a renement is obtained using again
the ranking procedure, but applying it locally, that is, in order to decide if a conditional
C|D has to be added to our KB we apply the same procedure as in rational closure, but
we consider only the information that is relevant to the inferential connection between C
and D. For example, assume a knowledge base composed only of the set of conditionals
D = {p|q, q|r, q|t, p|t}; now, following the procedure for rational closure we obtain
that p is an exceptional proposition, the only one, and so we cannot derive neither p|r nor
p|t. But, while we do not want to derive p|t, as we already have p|t, intuitively we
do not have any reason to avoid the conclusion p|r. In fact, such a conclusion would be
desirable, since p is a q, and p being an r does not generate any conict with the rest of the
information in the knowledge base.
So, our aim is to specify a way to decide which information in the KB is relevant
w.r.t. a particular connection (in the above case, p|r). In order to determine such a local
relatedness we are going to consider INs: we use their graphical characterisation in order
to identify the relevant information w.r.t. the connection we want to investigate, and then
we apply the ranking procedure to the pieces of information recognised as relevant.

3. Boolean Defeasible Inheritance Networks
Here we present a new decision procedures for INs, based on classical propositional decisions,
that, in addition to being a main step in the nonmonotonic construction we are going to
present later on, turns out to be an interesting IN decision procedure per se.
In the following, we proceed as follows. At rst, we dene a procedure for INs, and then
we map it into propositional logic, obtaining the desired renement of rational closure.
3.1 Exceptionality Levels in Inheritance Nets
Our rst aim is to apply to INs a modied version of the decision procedure for rational
closure; we do this in order to dene a method for deciding validity in INs that rely on
propositional calculus so to allow easily (i) to extend such a method in order to include into
the language also the propositional connectives , , , and (ii) to integrate it with rational
closure, in order to extend the inferential power of rational closure without compromising
its logical properties. A non-negligible side product is that it is a propositional SAT-based
reasoning procedure.
We shall briey review the case of purely strict nets showing that this case is easily
manageable using propositional calculus, and then we shall focus on mixed nets.
3.1.1 Strict Nets
For the strict part of the nets we want to obtain the same valid connections as in all classical
proposals. If a net is composed only of strict links, i.e., N = hS, i, its valid connections and
its consistency can be easily checked using propositional calculus. Indeed, dene a classical
propositional language  using the nodes in N as propositional letters (call PN such a set
of propositional letters), and  and  as connectives, and translate the set of links S into
the set of the corresponding propositional implications
 = {p  q | p  q  S}  {p  q | p 6 q  S} .
427

fiCasini & Straccia

We indicate by l a literal in  (being a literal a propositional letter or its negation), and
we dene A as the set of the antecedents of the implications in , that is
A = {p | p  l  } .
Then we can derive the valid paths using  and classical consequence relation  3 .
Proposition 3.1. Consider a net N = hS, i and translate it into a set of propositional
implications . The following properties hold:
1. If N is a consistent net, there is a valid strict positive (resp., negative) path hp, , qi
from p to q, that is N
p  q (resp., N
p 6 q), iff   p  q (resp.,   p  q).
2. N is inconsistent iff   p for some p  A .
3. Deciding strict consequence can be done in polynomial time.
So we can treat the decision problem in strict nets by means of classical propositional
calculus, obtaining exactly the same valid strict paths as in the classical approaches to nets.
Note that there is a dierence in the notion of inconsistency between INs and propositional logic. As seen in Section 2.1, a net is considered inconsistent if there is a node p
that, simultaneously, is positively and negatively connected to another node q: p is and
is not, simultaneously, a subclass of q. In the inheritance nets, such a situation is interpreted as a contradiction, while in the propositional logic the correspondent situation
( |= (p  q)  (p  q)) would just force the negation of the propositional letter (i.e.,
node) p (  p), that would correspond to saying that no individual can fall under the
class p.
3.1.2 Mixed Nets
Now we consider nets with both strict and defeasible links. In what follows we will assume
that the strict part of a net N = hS, U i is inferentially closed, that is, if N
p  q (resp.,
if N
p 6 q) then p  q  S (resp. p 6 q  S).
Our procedure diers from the classical approaches to INs mainly because it is not based
on the notion of potential path; instead, we translate the nets links into propositional
formulae, and then we build an exceptionality ranking using a procedure that is similar to
the one dened for rational closure. The main dierence with the procedure dened for
rational closure lays on the local characterization of the exceptionality rankings: to check
if there is a valid connection between a pair of nodes p and q we proceed in dening an
exceptionality ranking of the nodes; however, we do not consider all the nodes in the net,
but only those related to p and q. Such a relation is determined by means of the notion
of course, that is a generalisation of the potential path.
Roughly, courses are simply routes on the net following the direction of the arrows,
without considering if each of them is a positive or a negative arrow.
Definition 3.1 (Course). Courses are defined as follows (where   {, 6, , 6}):
3. Note that strict links can be encoded as 2-CNF formulae, also called Krom formulae, and that the
propositional 2-SAT problem is in P .

428

fiDefeasible Inheritance-Based Description Logics

1. every link p  q in N is a course  = hp, qi in N ; and
2. if  = h, qi is a course and q  r is a link in N that does not already appear in ,
then   = h, ri is a course in N .
The omission of repetitions in courses is needed to guarantee the niteness of courses
even if the net contains cycles. So, given a net N dened by a nite number of links, there
is only a nite set C N of courses, that, in turn, are nite sequences of nodes. We denote
N the set of all the courses in N going from node p to the node q, i.e.,
with Cp,q
N
Cp,q
= {  C N |  = hp,   , qi for some   } .

We next provide a procedure that denes the validity of a defeasible connection between
two nodes p and q, via a mapping into propositional logic. Given a net N = hS, U i, we
dene a correspondent knowledge base
KN = hN , N i ,
where
N = {p  q | p  q  S}  {p  q | p 6 q  S}
and
N = {p  q | p  q  U }  {p  q | p 6 q  U } .
In the following, we may omit N if it is clear from the context.
We dene an exceptionality ranking of the nodes, that depends on the decision problem
with respect to p and q only.4
So, let
p,q = {r  t | r  t  ,   Cp,q } 
{r  t | r 6 t  ,   Cp,q } ,
and consider the set of relative antecedents (l being a literal)
Ap,q = {a | a  l  N  p,q } .
In the following, N will denote the supra classical entailment relation obtained adding
to  the set of propositional formulae N as extra axioms. For the strict part of the net, if
p N q (resp., p N q), then we say that q (resp., q) follows strictly from p in N , and
we indicate it by p N q (resp., p N q).
On the other hand, |N will indicate the inference relation for the defeasible part, that
is, p|N q has to be read as a member of the class p is typically also a member of the class
q in N . Analogously for p|N q in the negative case.
4. This is the main difference w.r.t. the procedure for propositional rational closure: while there we rank
all the information in the KB at once, here we rank only the information related to the connection we
are interested in, between p and q.

429

fiCasini & Straccia

Now, we use N and p,q to determine the exceptionality level. If we are investigating the connection between p and q, a node in Ap,q is exceptional if it is negated by the
information contained in  and p,q (compare with Step 3.2 in Section 2.2):
E(Ap,q ) = {a  Ap,q | p,q N a}
E(p,q ) = {a  b  p,q | a  E(Ap,q )} .
Therefore, like Step 3.3 of Section 2.2, we build a sequence
0 = Ap,q
i = E(i1 ) ,
and the corresponding sequence
E0 = p,q
Ei = E(Ei1 ) .
Since Ap,q and p,q are nite, and for every i i  i+1 and Ei+1  Ei , the sequences
terminate with an (empty or non-empty) xed point of the function E, as in Section 2.2.
Dene now a ranking function (like Step 3.4) r that associates to every implication in
p,q a number, representing its level of exceptionality:
rp,q (a) = i if a  i and a 
/ i+1
rp,q (a) =  if a  i for all i
rp,q (a  b) = i if (a  b)  Ei and (a  b) 
/ Ei+1
rp,q (a  b) =  if (a  b)  Ei for all i .
Clearly, r(a  b) = r(a) for every a  b  p,q . In the following, we assume that we
do not obtain any node with a ranking value of  (that is, the function E terminates with
an empty set). We will see later on (Proposition 3.6) that in this latter case the net is
inconsistent.
b p,q of the implications a  b  p,q that are at least as
We now consider the set 
exceptional as p,
b p,q = {a  b  p,q | r(a  b)  r(p)} ,


and eventually dene

b p,q  p  q
p|N q i 
N
b
p|N q i p,q N p  q .

In the language of the nets, we indicate the inference relation generated by such a
procedure by the symbol  . That is,
N



p  q i

p N q

N



p 6 q i

p N q

N
N



p  q i
p 6 q i

p|N q
p|N q .



So, given N = hS, U i and a pair of nodes hp, qi, our inference procedure for INs can be
summarised as follows:
430

fiDefeasible Inheritance-Based Description Logics

1. Close S under strict validity.
2. Check if there is a direct (and hence valid) link in N connecting p to q. If there is,
the connection is valid. Otherwise, proceed.
3. Determine the set Cp,q of the courses in N connecting p to q, map the links in S and
Cp,q into the sets of implications  and p,q , dene the set Ap,q of the antecedents of
the implications in   p,q .
4. Determine the ranking value of every proposition in Ap,q and every implication in
p,q .
b p,q of the implications that are at least as exceptional as p.
5. Dene the set 

6. Then decide N
b p,q  p  q).
(



p  q (N



b p,q  p  q
p 6 q) by determining whether 

Please note again that we rely on a decision procedure for  only. The examples below
illustrate the behaviour of our method.
Example 3.1. Consider Example 2.1 with additional links t  b and t  p (read t as
tweety).
w
b
f

t

p

Figure 1: Example 3.1
We translate the net into the following knowledge base
K = h, i ,
where
 = {t  b, t  p, p  b}
and
 = {p  f, b  f, b  w} .
Suppose now, we want to decide if t is connected to f (i.e., Tweety flies).
Since the link b  w does not appear in any course from t to f , we have
t,f

= {p  f, b  f }

At,f

= {t, b, p} ,
431

fiCasini & Straccia

and so we obtain
t,f  p and t,f  t .
Thus,
0 = r(b) = r(b  f )
1 = r(t) = r(p) = r(p  f )
So,
b t,f  t  f , we have
and, as 

b t,f = {p  f }

t|N f ,

as expected.
As next, we ask if t is connected to w (i.e., Tweety has wings). Now, we have
t,w = {b  w}
At,w = {t, b, p} .
As t,w does not imply the negation of any of the members of At,w , we have
0 = r(t) = r(p) = r(b) = r(b  w)
and

b t,w = t,w .


b t,w  t  w, we have
As 

t|N w ,

as expected.
Example 3.2. Consider the Nixon Diamond (see Figure 2), where n is Nixon, r is republican, q is quaker, and p is pacifist; it is another classical problem in nonmonotonic
reasoning, that is similar to the previous one but we are not informed if a path is more
specific of the other (while above the link p  b tells us that the information about the
penguins is more specific than the information about the birds). So, we do not want neither
n  p nor n 6 p validated.
q
p

n

r

Figure 2: Nixon diamond.
432

fiDefeasible Inheritance-Based Description Logics

The knowledge base K corresponding to the net is composed of
 = {n  r, n  q}
 = {r  p, q  p} .
We want to check if n is connected to p. So, n,p = , and the only negated antecedent is n
 n,p = . Since 
 n,p 6 n  p
(n,p  n): r(q  p) = r(r  p) = 0 while r(n) = 1, i.e., 
 n,p 6 n  p, we conclude that
and 
n 6 |N
n 6 |N

p
p .

The two following examples illustrate that our procedure and Hortys skeptical closure,
notwithstanding they often manifest similar results, do not always give back the same
results, nor one is included in the other.
Example 3.3. Consider the net in Figure 3.
f

g

x

p

a

m

n

y

Figure 3: Example 3.3
We want to investigate if there is a valid connection between a and p. According to
Hortys skeptical closure, we cannot conclude anything about a and p (N 6 a  p). Instead,
 a  p), since we have r(a) = r(f ) = r(g) =
with our approach we obtain a|K p (N
r(x) = 1.
Example 3.4. Consider the net in Figure 4.
p
c

t

e

f

b

Figure 4: Example 3.4
We want to investigate if there is a valid connection between p and b. According to
Horty (1994) we conclude N
p 6 b, while with our approach we cannot conclude anything.
433

fiCasini & Straccia

So, even if in many situations the results of the two approaches are the same, we can
obtain dierent results with them. Such dierent outcomes are mainly due to a dierence in
how conicts are interpreted. Consider Example 3.4, where we have an unresolved conict
between two paths from p to f , that is, no one of the two paths preempts the other, and so
none of them can be considered as valid, both in Hortys and in our approach. In Hortys
interpretation, such a conict prevents also the construction of paths starting at p and
passing through f : in order to be constructible a path has to be built augmenting a valid
shorter path, and thus we cannot construct any path starting from p and passing through
f (Horty, 1994, Def. 2.1.1). So, an unresolved conict totally eliminates the possibility to
consider such paths in more ample argumentations, where they could play some role. On
the other hand, in our approach we are not so radical about conicts: the fact that we
cannot conclude neither p  f nor p 6 f does not eliminate the possibility that in the
actual world one of such connections is true; simply we do not have enough information to
decide. The possibility of p  f to be eectively valid invites us to take under consideration
such a potential argumentation in moving from p to b. So, looking for a connection between
p and b in Example 3.4, while Horty cannot consider the path hp, c, t, f, bi, avoiding the
rise of a conict with the path hp, e, bi, in our approach we still consider the possibility
for hp, c, t, f i to be eectively true, allowing the path hp, c, t, f, bi to play a role in deciding
whether there is a valid connection between p and b. In such a way we have a potential
conict with hp, e, bi that prevents the validity of the latter. For other signicant examples
of our approach see Appendix A.
Notice that, even if it is built on the notion of courses, our procedure respects the
classical notion of potential path, that is, every valid connection corresponds to a potential
path on the net (Denition 2.1).
Proposition 3.2. Consider a net N . For every connection p|N q (resp., p|N q) validated
by our procedure, there is a corresponding positive (resp., negative) potential path from p to
q in the net N .
3.1.3 Inference Relation
Talking about nets, the structural properties characterizing rational consequence relations,
REF , CT , CM , and RM , take the following form5 :
(REF)
(CT)
(CM)
(RM)

N
N
N
N

p  q for every p  q  N
pq
N,p  q
rs
N
rs
pq
N
rs
N,p  q
rs
rs
N 6 pq
N , p6 q
rs

The meaning of the properties is still the same as the propositional case, simply readapted
to the expressivity of the INs: the net represents the information at our disposal, the
premises of the derivation, and the links are the informational atoms of our language.
5. with ,   {, 6}; N , a  b in the premises indicates the addition of the direct link a  b to the net N ;
6  indicates the opposite arrow of  (e.g. 6  is  iff  is 6)

434

fiDefeasible Inheritance-Based Description Logics

Hence, the sense of the rules is the same as before. (REF) indicates that whatever piece
of information (link) is in the premises, it appears also in the conclusions. (CT) is a cut
condition, that states that if the validity of a link can be derived from the links in the rest of
the net, such a link can be eliminated without aecting the set of the conclusions derivable
from the net. (CM) is a form of constrained monotony, opposite to (CT), that states that
whatever conclusion can be derived from the net, it can be added to the premises without
aecting the other conclusions. (CT) and (CM) have an intuitive appeal, and from the
logical point of view characterize
as a closure operation. The translation of (RM) is less
intuitive, since we do not have in INs a classical notion of negation, but we have only a
notion of conict; hence the sense of the rule is that, if p  q is not a consequence of N ,
then the addition of information conicting with p  q, i.e., p 6 q, should not aect the
defeasible consequences of the net N . The fact that INs do not share with classical logic
the notions of contradiction and negation makes this formulation of (RM) less intuitive and
interesting.
The proprieties (REF), (CT) and (CM) are often considered proprieties that a nonmonotonic consequence relation should satisfy (Kraus et al., 1990; Makinson, 1994), and so
it is interesting to check if they are satised in the IN formalism. We know that the classical
approaches to inheritance nets do not satisfy (CT) and (CM) (Makinson, 1994, pp. 56-57),
while our approach is logically more appealing.
Proposition 3.3.



satisfies (REF), (CT) and (CM).

While (RM) is not satised.
Proposition 3.4.



does not satisfy (RM).

The following example proves the proposition
Example 3.5. Consider the net in Figure 5. The net is composed of the links p  f ,
f  b, and p  t. We have N
p  b and N 6 t  b, but N , t 6 b 6 p  b.
b
f

t

p

Figure 5: Counterexample to RM.
This example actually shows that, dealing with the notion of negation and consistency
that characterize INs, (RM) does not look as a desirable property anymore, since the addition of t 6 b to the net creates a Nixon Diamond from which we do not want to derive
p  b (see Example 3.2).
435

fiCasini & Straccia

Other properties of logical consequence relations, left equivalence and right weakening,
have an analogous in the following properties:
(LE)
(RW)

N

pq N
pr N
N
rq
pq
N
qr
N
pr

N

rp

We also introduce a property that corresponds to the logical property of supra classicality (if C  D, then C|D), a rule satised by most non-monotonic consequence relations:
(Sup)

N
N

Proposition 3.5.

pq
pq


N
N

p 6 q
p 6 q

satisfies (LE), (RW ), and (Sup).

3.1.4 Consistency
As indicated at the end of Section 2.1, a net is considered inconsistent if we are forced
to conclude for some pair of nodes p, q that p and q are both positively and negatively
connected. Since, as seen above,  satises (Sup), we can say that a mixed net is consistent
i we cannot conclude both N  p  q and N  p 6 q for any pair of nodes p, q.
Now we are going to see that in order to check the consistency of a mixed net we can use
the ranking procedure: it is sucient to apply it to the whole net. As for the propositional
case (see Section 2.2), the ranking procedures dened on the nodes of a net terminates,
after a nite number of steps, into either an empty set n or a xed point of the function
E, i.e., the set of the nodes that result always exceptional. In such a case, we say that such
nodes have an innite ranking value (r(p) = ). If we want to check whether a net N is
consistent, it is sucient to apply the ranking procedure to the entire net, and see if there
are nodes with innite ranking.
Proposition 3.6. A net N is consistent iff we do not have a node p with r(p) = , that
is, we do not conclude both N  p  q and N  p 6 q for any pair p, q.
Example 3.6. The net in Figure 6 is an example of an inconsistent net, from which we
 t  f and N
 t 6 f . Such a net is translated into the
would conclude both N
b
f

t

p

Figure 6: An example of inconsistent net.
436

fiDefeasible Inheritance-Based Description Logics

knowledge base
 = {t  b, t  p, p  b, b  p}
 = {p  f, b  f } .
We proceed the ranking of the entire net, and we obtain that   p,   b and
  t, that is, E1 = . Hence,  is a fixed-point of the exceptionality ranking function,
and p, b, t have  as ranking value.
3.1.5 Properties
In the eld of inheritance networks, a taxonomy of the dierent approaches has been developed on the basis of some relevant properties (Horty, 1994). We briey check which of
them are satised by our approach.
 Purely defeasible / mixed nets. Cyclic / acyclic nets. Our procedure deals easily with
two properties that often create problems in the traditional approaches: the presence
of both strict and defeasible links (mixed nets), and the presence of cycles (cyclic
nets).
 Credulous / skeptical / directly skeptical approaches. Our approach corresponds to a
directly skeptical approach: given a net, we obtain a unique set of valid connections in
it (vs. the credulous approach, that allows for dierent sets of valid paths, possibly in
conict with each other), and such a unique set is not obtained from the intersection
of dierent possible extensions (as in some skeptical approaches), but it is obtained
from a single closure operation.
 Upward / downward chaining. For the denition of valid paths, we do not use any
form of induction on their length, neither starting from the initial node toward the
terminal node (upward chaining), nor in the reverse direction (downward chaining);
hence, no form of chaining is used in our procedure.
 On-path / off-path preemption. O-path preemption is the classical form of preemption, used also by Horty (1994, Def. 3.2.2), while on-path preemption is more
binding, requiring the preempting node to lie on the initial segment of the path it preempts (Horty, 1994, sect. 4.2.4). We do not exactly formalise a form of preemption,
since we do not confront directly the dierent paths between two nodes. However,
our procedure has a behaviour that is analogous to the use of o-path preemption.
3.1.6 Computational Complexity
To dene the overall complexity of our decision procedure over the nets, we have to consider
the complexity of the course-identication procedure, that is, given a net N = hS, U i and
two nodes s, t in N , which is the computational cost to identify s,t (note that  can easily
be computed in polynomial time), whose size is bounded polynomially by the size of N .
Given that the construction of courses is independent from the nature of the links (either
they are positive or negative, defeasible or strict), we can analyse the problem using simple
directed graphs. Given a net N = hS, U i, it is sucient to dene the correspondent directed
graph G = hV, Ei in the following way:
437

fiCasini & Straccia

 V is the set of nodes in N .
 E is a set of directed links ha, bi, with a, b  V , s.t. ha, bi  E i one of the following
holds:
a  b  S , a 6 b  S , a  b  U , a 6 b  U .
Recall that we have stated the presence of a 6 b in S implies that b 6 a is in S too. So,
for a 6 b  S we have both ha, bi and hb, ai in E.
Once we have dened G, let us recall a well-known result in graph theory saying that
in a directed graph, given two nodes p and q, determining if there is a path from p to q
can be determined in time O(|V | + |E|), e.g. using BFS (Breadth First Search) (Cormen,
Stein, Rivest, & Leiserson, 2001). Now, the following argument shows that indeed s,t can
be determined in polynomial time 6 . At rst, we check if there is a path between s and t.
If not, then s,t = . Otherwise, we call the procedure Delta(s) below:
Delta(s): for each outgoing edge hs, xi of s, such that both hs, xi and x are not marked,
do: if there is a path between x and t then mark both hs, xi and x, and recursively,
call Delta(x).
Once nished, s,t can immediately be build from the marked edges. Note that each edge
is marked once and each node is marked (i.e., explored) once and, thus, the algorithm is
bounded polynomially by the size of the graph.
Once we have found the set s,t and , we have to apply the decision procedure based
on the propositional rational closure to decide if there is a valid connection between p and
q (as for Section 2.2, the number of entailment tests is polynomially bounded by the size
of the net). As all formulae are 2-CNF, like Proposition 3.1, we obtain that the decision
procedure w.r.t. the net respects the complexity costs of the related propositional calculus.
Proposition 3.7. Deciding defeasible consequence under inheritance networks (
done in polynomial time.

)

can be

Eventually, if we want to determine all the valid links in the net N we have to consider
all the pairs of nodes in the net N . So, obtained the graph G = hV, Ei we have to repeat the
procedure for all the elements of the set of the pairs of nodes in the graph, whose cardinality
is |V |(|V |  1). Hence, again
Proposition 3.8. Computing all the valid connections in a net can be done in polynomial
time.
3.2 Boolean Inheritance Nets
We next extend INs by introducing in them the classical propositional connectives , , .
Despite such an extension has been felt as desirable, we are aware of just an attempt in this
direction (Horty & Thomason, 1990).
6. We are not interested here in figuring out a tight bound.

438

fiDefeasible Inheritance-Based Description Logics

c

c

cd

cd

d

d

Figure 7: Disjunction

Figure 8: Conjunction

3.2.1 Negation
So far, we have used the link 6 to indicate that two classes are disjoint: p 6 q has p  q
as logical meaning. We change the notation and substitute 6 with  , indicating with
p  q that class p and class q are complementary (i.e., p  q), and in general we
will indicate the complementary class of a class p with p. Hence, we can substitute every
link p 6 q in a net with four links: p  p, q  q, p  q, and q  p. Moreover, we
can eliminate the negative defeasible links, since p 6 q can be expressed as p  q  q.
So, we can transform an IN into a net using only the arrows , , and  . We shall
continue to use 6 as a macro indicating the valid negative strict connections obtained from
the composition of  and , that is, we indicate with p 6 q the presence of a path

. . d } q ,
p
| a {z. . .  b}  |c  .{z
n arrows

with n, m  0.

m arrows

3.2.2 Conjunction and Disjunction
Next, we extend inheritance nets to support conjunction and disjunction as well, by allowing
links a, b  c (conjunction of a and b is equivalent to c) and c  a, b (disjunction of a
and b is equivalent to c). We will assume that inheritance nets containing such kind of
links are closed according to the following rule: if there is a, b  c (resp., a, b  c) in
a net, then there are also c  a and c  b (resp., a  c and b  c) in the net. We call
these nets Boolean Defeasible Inheritance Networks (BINs). We shall use a  b and a  b
to indicate, respectively, that a node represents the conjunction or the disjunction of a and
b. Graphically, we indicate disjunctive and conjunctive links as in Figure 7 and Figure 8,
respectively.
We extend now our reasoning method to BINs. To do so, we need to amplify the notion
of course, introducing the notion of duct: we consider not only linear routes from one point
to another, but also parallel routes, in order to model the introduction of the conjunction
in the consequent and the introduction of the disjunction in the antecedent. Roughly,
 = hs,


, ti


will indicate a duct  that starts at node s and develops through the ducts  and   , both
reaching the node t.
439

fiCasini & Straccia

Definition 3.2 (Duct). Ducts are defined as follows (where   {, 6, , 6}):
1. every link p  q in N is a duct  = hp, qi in N ;
2. if  = h, qi is a duct and q  r is a link in N that does not already appear in , then
  = h, ri is a duct in N ;
3. if  = hq, i is a duct and r  q is a link in N that does not already appear in , then
  = hr, i is a duct in N ;
t,
4. if ht, , pi and hr,   , pi are ducts, then for s  t, r  S, hs, r,
 , pi is a duct; and

5. if hp, , ti and hp,   , ri are ducts, then for t, r  s  S, hp, ,t
 ,r , si is a duct.
Now our reasoning method for BINs is as follows. Given a net N = hS, U i, we can dene
a correspondent knowledge base K = h, i, where
 = {p  q | p  q  S}
 {p  q | p  q  S}
 {p  q  r | q, r  p  S}
 {p  q  r | p  q, r  S}
 {p  q | p 6 q  S}
 = {p  q | p  q  U } .
Now, we may proceed to the denition of |N as in Section 3.1, simply considering C N as
N (or simply C ) as the set of the ducts from p to q.
the set of the ducts in N , and Cp,q
p,q
Example 3.7. Consider the net N illustrated in Figure 9. The net N is mapped into the
e

d
g

a



b
c
f

Figure 9: Example 3.7
KB K = h, i, where

7

 = {c  d  g, f  g}
 = {a  b, b  c, b  d, b  e, a  f } .
7. To ease the reading, we have omitted the redundant implications such as g  c, obtained from c, d 
g, g  c  N .

440

fiDefeasible Inheritance-Based Description Logics

Now, we ask whether a is connected to c. It can be verified that
a,c = {a  b, b  c, b  d, a  f } .
Note that b  d  a,c , as there is a duct from a to c that passes through c and d in order
to reach g, and then back towards c. Now, the only negated antecedent is a (a,c  a)
and, thus,
b a,c = {a  b, a  f } .

b a,c 6 a  c and 
b a,c 6 a  c, we have
Since 

a6|N c and a6|N c .

In a similar way, we may show that a6|N d and a6|N d. This is the desirable result: since
a  f is a direct link, we have that a|N f (i.e., a|N (c  d)), and hence we know that
we cannot conclude both a|N c and a|N d. But, since we have no evidence whether one of
such conclusions has to be preferred to the other, we do not conclude either of them. The
result of our skeptical approach is that a6|N c, a6|N c, a6|N d, and a6|N d. On the other
hand, since the only duct connecting a to e is ha, b, ei (that is, the nodes c, d, g, and f do
not play any role in any possible argumentation connecting a to e), we can conclude a|N e.
3.2.3 Properties
We call BIN the inference relation dened by the just dened closure operation over BINs
and we have:
N

BIN

p  q i p  q

N

BIN

p 6 q i p  q

N

BIN

p  q i p|N q

N

BIN

p 6 q i p|N q .

BINs inherit the same structural properties of our INs, that is, (REF ), (CM ), and
(CT ). Analogously, (LE), (RW ), and (Sup) are still valid.
Proposition 3.9.
Proposition 3.10.

BIN

satisfies (REF ), (CM ), and (CT ).

BIN

satisfies (LE), (RW ), and (Sup).

Since the procedure dened in Section 3.1 is simply a special case of the procedure for
BINs, (RM) is falsied also for BINs by the same counter-example of proposition 3.4. Moreover, introduced conjunction and disjunction, we can express the analogous of the rules of
disjunction in the premises (OR) and conjunction in the consequent (AND):
(OR)

(AND)

N

BIN

pq N
N

N

BIN

sq N
BIN t  q

BIN

pq N
N

ps N
BIN p  t

BIN

441

BIN

t  p, s

BIN

q, s  t

fiCasini & Straccia

The sense is the same as in the propositional case, and it remains intuitive also in
the BIN environment: (OR) represents the validity of reasoning by cases, while (AND)
represents that the conjunction of distinct conclusions is still a valid conclusion from the
net.
Proposition 3.11.

BIN

satisfies (OR) and (AND).

3.2.4 Consistency
Also w.r.t. consistency, we obtain the same result as for INs, i.e., the net is consistent if the
ranking procedure terminates into an empty set.
Proposition 3.12. A BIN N is consistent iff we do not have any node p with r(p) = ,
that is, we cannot conclude both p  q and p 6 q for any pair p, q.
Remark 2. As seen in Section 3.1.4 the notion of consistency in inheritance nets is different from the notion of consistency for propositional logic. Using our procedure a net is
inconsistent if, applying the ranking function to the entire net, we obtain a node with  as
ranking value (see Proposition 3.6). Up to this point, if we find that a net is inconsistent,
we simply stop our decision procedure.
In what follows we are going to work with BINs in the framework of propositional logic.
So, in order to assimilate the notion of consistency with the one of propositional logic, from
now on we shall consider a modified version of our procedure for BINs. Suppose we have
to decide the validity of the connection between two nodes p, q in a net N . If N results
consistent, then we proceed as above, otherwise, if our net results inconsistent (some node
has infinite ranking value) we do not simply stop, but, in case r(p) < , we still apply our
procedure. Otherwise, if p itself has infinite ranking value (r(p) = ), we do not proceed
further.
3.2.5 Computational Complexity
As for INs, we have to determine s,t (computing  is again immediate) from the ducts
in a BIN. Now, it is not dicult to see that a recursive BFS graph travelling procedure
as the one devised for INs can be worked out for BINs as well. By illustration, refer to
Figure 9 and assume we are processing node b. Since from b, both d and c are reachable
and d, c  g  S, and, recursively, there is a path from g to c, we can mark hb, ci and hb, di,
and mark the conjunction d, c  g  S as visited. Again, all nodes and aggregated
nodes are visited at most ones, guaranteeing polynomial cost for computing s,t .
Now, while s,t and  can be determined in polynomial time, and as for Section 2.2,
the number of entailment tests is polynomially bounded by the size of the net, the strict
part may encode any propositional formula and, thus, unlike the case of INs, we have:
Proposition 3.13. Deciding defeasible consequence for BINs (
problem.

BIN )

is a coNP-complete

4. Defeasible Inheritance in Propositional Logic
Now, we depart from BINs and apply a similar reasoning procedure in the framework of
propositional logic, and show how to obtain a kind of closure of a knowledge base that
442

fiDefeasible Inheritance-Based Description Logics

results to be a rational consequence relation, but that is more informative than the classical
rational closure (Lehmann & Magidor, 1992).
We consider a propositional language with only , ,  as connectives. So, we start with
a conditional KB K = hT , Di (see Section 2.2), with T = {C1  D1 , . . . , Cn  Dn } and
D = {E1 |F1 , . . . , Em |Fm }.
Step 1. Given a conditional base K = hT , Di, check if K is preferentially consistent (that
is, check if its materialisation is consistent; Section 2.2, Step 4.1). If it is consistent,
we dene a BIN from K, i.e., a net NK = hSK , UK i, modelling the information in K
in the following way:
(i) we consider every formula C that appears as antecedent or as succedent in the
conditionals in K, and we create a node C representing each of them, modulo
logical equivalence (that is, a node C represents the class of the formulae logically
equivalent to C).
(ii) for each node we add also, if not already present, the complementary node (the
node representing its negation), and we link them by  ;
(iii) we add the strict links: if C  D  T we add the strict link C  D to the net;
we also add to SK all the strict links that correspond to the logical dependencies
between the formulae represented by the nodes w.r.t. the consequence relation
T . If  appears in a conditional, we add to the net a correspondent node ,
and, for every other node n in the net, we add a strict node n  . Analogously,
for  we add   n for every node n in the net.
(iv) eventually, for C|D  D, we add a defeasible link  from node C to node D.
Step 2. We apply the reasoning procedure for BINs to NK (Section 3.2) to identify all valid
defeasible connections C|N D and we add them as C|D to the conditional base K
to obtain a new conditional base K = hT , D  i 8 .
Step 3. Finally, we apply to K its rational closure (Section 2.2) and we dene a nonmonotonic consequence relation |K by
C|K D i C|D  R(K ) .
Now, we can show that
Proposition 4.1. |K is a rational consequence relation containing K.
Example 4.1. Consider again the penguin example. We modify it slightly in order to
consider also the use of the connectives. While birds (b) typically fly, live on trees, and have
wings (f , t, w), penguins do not fly and do not live on trees (f  t). So, our knowledge
base K = hT , Di will be:
T

= {p  b}

D = {b|f, b|t, b|w, p|f  t} .
8. We do not modify T , since all the strict connections valid in the net are classically derivable from T .

443

fiCasini & Straccia

Notwithstanding penguins atypicality as birds, penguins have wings, and we would like
to be able to derive it from the information at our disposal, that is, we would like to conclude
p|w. Please note that this is not possible using classical preferential approaches, but we
can obtain such a conclusion passing trough the first step of our closure operation, that is,
defining the corresponding net.
Specifically, from the knowledge base K we define the net in Figure 10 (the dashed arrows
are the strict arrows that are not explicit in the conditional base, but that are logically valid
and that are added to SK in the construction of the net NK ).
f  t



f


tf



p

t



f

t

p

b

w

w





b

Figure 10: Example 4.1
Using the procedure defined for BINs, from such a net we obtain a new knowledge base
K = hT , D  i ,
with
D  = {b|f, b|t, b|w, p|f  t, p|w, p|f, p|t, b|f  t} .
Note that, while the new conditionals
p|f,

p|t,

b|f  t

would be present also in the simple rational closure of K (we obtain them by Right Weakening), we have obtained also the conditional
p|w ,
444

fiDefeasible Inheritance-Based Description Logics

that would not be present in the rational closure of K (see Remark 1).
Now, following the procedure defined in Section 2.2, we compute the rational closure
of the new knowledge base K , obtaining a rational consequence relation that contains the
original K.
Please note that, if we were using only BINs, we could have not derived anything else,
since our vocabulary would be limited to the propositions expressed by the nodes; however,
by relying on the rational closure of propositional knowledge bases, we can reason using the
full expressivity of a propositional language, deriving new conditionals as, for example,
b  green|f ,
which can not be derived using BINs as green does not appear in the net.
The next example shows another characteristic of this approach. In the preferential
approach typicality is an absolute property of a proposition w.r.t. the agents knowledge
base, that is, if a class results atypical w.r.t. some other class (as penguins w.r.t. birds),
it results atypical w.r.t. the entire knowledge base. In our approach instead, typicality is
a comparative notion: we can consider a class as exceptional with respect to a superclass,
but absolutely typical with respect to another.
Example 4.2. Consider a red fish (r). It is both a fish (f ) and a pet (p). Typically, a fish
has gills (g) and scales (s), while pets are docile (d) and play with kids (k). Red fishes are
not typical pets, since they do not play with kids. So, the K = hT , Di is
T

= {r  f, r  p}

D = {r|k, p|k, p|d, f |g, f |s} .
In the rational closure red fishes, since they are atypical pets (they do not play with kids),
result atypical in general, and they cannot inherit any of the typical properties of all their
super classes.
Instead, we want red fishes to inherit, besides the properties of pets that are compatible
with them (d), also all the typical properties of fishes (g and s), since we consider them
typical fishes.
To do so, we translate our knowledge base into the net in Figure 11. From such a net
we obtain a new knowledge base K = hT , D  i, with
D  = {r|k, p|k, p|d, f |g, f |s, r|d, r|g, r|s}
and so we have derived exactly the desired conditionals.
Next, we compute the rational closure of K , following the procedure defined in Section
2.2, and we obtain a rational consequence relation containing K and more information about
red fishes, information that, as intuitive as it is, we would not be able to derive from the
simple rational closure of K.
Therefore, we have dened a new rational consequence relation for K that extends K,
as K  R(K ), and that contains intuitive conditionals not in the rational closure of K.
445

fiCasini & Straccia

g

g
f
f

s





s





p
d

r



r

d



p

k



k

Figure 11: Example 4.2
Consistency. Dened some inference procedure, a conditional base K is consistent i we
cannot derive |. We have seen (Section 2.2) that for rational closure a conditional base
is consistent i its preferential closure is consistent (|  R(K) i |  P(K)). Here,
given a base K, we obtain that our procedure preserves the preferential consistency of K:
as seen in Section 2.2, K is preferentially consistent i its rational closure is consistent (i.e.,
 6 |rc
K ), and we can prove the following.
Proposition 4.2. Given a conditional base K, |K  iff |  R(K).
By the results in Section 2.2, this corresponds to saying that |K  i K   (assuming
K = hT , Di, K = T  D).
Computational Complexity. Considering the procedures dened for the BINs, we can
conclude that the dened procedure has the same complexity of the rational closure, as it
is the composition of the procedure dened for BINs (Proposition 3.13) and a nal rational
closure operation (Proposition 2.2).
Proposition 4.3. For a propositional conditional base K, deciding C|K D is a coNPcomplete problem.

5. Defeasible Inheritance in DLs
Next, we apply our method to a signicant DL representative, namely ALC (Baader et al.,
2003, ch. 2). ALC corresponds to a fragment of rst order logic, using monadic predicates,
called concepts, and dyadic ones, called roles.
In order to stress the parallel between the procedure presented in Section 2.2 and the
proposal in ALC, we are going to use the same notation for the components playing an
analogous role in the two construction: we use p, q, r, . . . for concept names, and C, D, E, . . .
to indicate concepts in general, instead, respectively, of atomic propositions and propositions, and |= and | to indicate, respectively, the classical consequence relation of ALC and
446

fiDefeasible Inheritance-Based Description Logics

a non-monotonic consequence relation in ALC.  will indicate a default concept, that is, a
concept that we assume as applying to every individual, if not informed of the contrary.
We have a nite set of concept names C = {p, q, r, . . .}, a nite set of role names R =
{R, S, T, . . .} and the set L of ALC-concepts is dened inductively as follows: (i) C  L;
(ii) ,   L; (iii) C, D  L  C  D, C  D, C  L; and (iv) C  L, R  R 
R.C, R.C  L. Concept C  D is used as a shortcut of C  D. The symbols  and 
correspond, respectively, to the conjunction  and the disjunction  of classical logic.
Given a set of individuals O, indicated by bold letters a, b, c, . . ., an assertion is of
the form a:C (C  L) or of the form (a, b):R (R  R), respectively indicating that the
individual a is an instance of concept C, and that the individuals a and b are connected
by the role R.
A general inclusion axiom (GCI) is of the form C  D (C, D  L) and indicates that
any instance of C is also an instance of D. We use C = D as a shortcut of the pair of
C  D and D  C.
From a FOL point of view, assertions and inclusion axioms can easily be mapped in
FOL by the following transformation:
 (a:C) =  (a, C),
 (C  D) = x.( (x, C)   (x, D)),
 (x, A) = A(x),
 (x, C  D) =  (x, C)   (x, D),
 (x, R.C) = y.(R(x, y)   (y, C))
 (x, R.C) = y.(R(x, y)   (y, C))

 ((a, b):R) = R(a, b),
 (x, ) = (x),  (x, ) = (x),
 (x, C) =  (x, C),
 (x, C  D) =  (x, C)   (x, D),
where y is a new variable,
where y is a new variable .

Now, a classical knowledge base is dened by a pair K = hA, T i, where T is a nite
set of GCIs (the TBox ) and A is a nite set of assertions (the ABox ), whereas a defeasible
knowledge base is represented by a triple K = hA, T , Di, where additionally D is a nite
 D (an instance of a concept C is typically an instance of a concept
set of conditionals C 
9
D), with C, D  L .
Example 5.1. Consider again the penguin example. Just add a role P rey in the vocabulary,
where a role instantiation (a, b):P rey is read as a preys on b, and add also two more
concepts, i (insect) and f i (fish). An example of defeasible KB is
K = hA, T , Di
with
A = {a:p, b:b, (a, c):P rey, (b, c):P rey}
T = {p  b, i  f i}
 f, b  f, p  P rey.f i, b  P rey.i} .
D = {p 



The particular structure of a defeasible KB allows for the isolation of the pair hT , Di,
that we could call the conceptual system of the agent, from the information about the
individuals (formalized in A).
9. Since for the monotonic part we substitute the meta-linguistic conditionals C  D with formulae C  D,
we substitute also for the defeasible part of the knowledge base the conditionals C|D with conditional
 D, that we could call defeasible inclusion axioms.
formulae C 

447

fiCasini & Straccia

In what follows we are going to work with the information about concepts hT , Di rst,
exploiting the immediate analogy with the homonymous pair in the propositional setting,
and then we will address the case involving individuals as well. We show that by using
our method we overcome to the limits of classical rational closure, already presented for
ALC (Casini & Straccia, 2010), in a similar way as for the propositional case. Please note
that the procedure presented here is based on a slightly modied version of the procedure
for rational closure previously presented by Casini and Straccia (2010), i.e., on the one
presented by Britz et al. (2013). The latter is accompanied by a semantic characterization,
based on DL interpretations with a preferential relation dened over the individuals. Such a
semantic characterization of rational closure for ALC characterises all the steps of our procedure (the local applications of rational closure and the nal one). However, we still lack
a semantic characterization of the overall procedure, accounting also for the modularization
of the knowledge base done using the INs.
Step 1. Given a conceptual system K = hT , Di, check its preferential consistency, that is,
dene
T

= {C  D | C  D  T }

 D  D}
D = {C  D | C 

and construct a BIN NK from K. The process is the same as the one in Section 4,
just treat the concepts as propositions: nodes in NK represent the concepts appearing
as antecedents or consequents of the inclusion axioms in T and D (modulo logical
equivalence); for every node we add its complementary node, if not already present,
and we connect them by  ; every GCI C  D  T becomes a strict link C  D;
 D  D becomes a defeasible link C  D.
and every defeasible inclusion axiom C 
Moreover, consider the consequence relation T as the monotonic consequence relation
obtained adding the GCIs in T to , and add to the net the strict links representing
all the logical dependencies between nodes with respect to T 10 .
Step 2. Apply the reasoning procedure for BINs to NK (Section 3.2) to identify all the
 D to the conditional base
valid defeasible connections C  D, and add them as C 


K to obtain a new conditional base K = hT , D i.
Now, once we have augmented our knowledge base with new defeasible conditionals, we
proceed as follows.
  | C  D  T }.
Step 3. Dene D  = D   {C  D 
 D  D  } and let A  = {C | C  D  D  }.
Step 4. Dene D  = {C  D | C 
D


Step 5. Determine the exceptionality ranking of the conditionals in D  using the set of
the antecedents AD and the materialisations
in D  , where a concept C is exceptional
d
w.r.t. a set of conditionals D i |= D  C. The steps are the same of the propositional case (Step
3 in Section 2.2) by replacing the expression D |= C with the
d
expression |= D  C. In this way dene a ranking function r.
10. In order to create the strict part of the net it is possible to use the techniques introduced for the procedure
of classification of DL knowledge bases (Baader et al., 2003, ch. 9).

448

fiDefeasible Inheritance-Based Description Logics

Step 6. As Step 4.1, Section 2, verify if the KB is consistent, by checking the consistency
of D  . Then (as in Steps 4.2 - 4.3 in Section 2.2), dene the sets
 D  D  and r(C  D) = }
Te = {  C | C 





e
D = {C  D | C  D  D and r(C  D) < } .

e and ,
e with
Step 7. Dene (similarly to Step 5 in Section 2.2) the sets of concepts 

where
i =

l

e = {C |   C  T }

e = {0 , . . . , n } ,


D D
e and r(C
{C  D | C 




D)  i} .

As for Section 2, for every i , 0  i < n, |= i  i+1 .
Step 8. Now, we can dene the inference relation |K as
C|K D i |= C 

l

e  i  D,


e
where i is the rst {C}  -consistent
formula11 of the sequence h0 , . . . , n i. This is
the DL analogue as Step 6, Section 2.2.
Again, all steps require a decision procedure for the classical entailment relation |= of
DLs. We can redene the properties characterizing a rational consequence relation into the
framework of DLs.
We can show that
Proposition 5.1. |K is a rational consequence relation containing K.
That is, the analogous properties of the propositional rational consequence relation are
satised, namely:
(REF) C|K C
(LLE)

(CT)

C |K E

|=T C = D

D |K E

C  D |K E

(OR)
11. That is, 6|= C 

(RW)

C |K D

(CM)

C |K E
C |K E

D |K E

(RM)

C  D |K E
de
  i .

449

C |K D

|=T D  E

C |K E
C |K E

C |K D

C  D |K E
C |K D

C 6 |K E

C  E |K D

fiCasini & Straccia

Example 5.2. Consider example 5.1, where additionally we also add a role Born (Born(x, y)
is read as x is born from y), and a concept e (Egg). Consider
K = hT , Di ,
where
T

= {p  b, i  f i}

 P rey.f i  P rey., b  P rey.i  P rey., b  Born.e} .
D = {p 



p

b




Born.e

p



Born.e

b

P rey.f i  P rey.

P rey.i  P rey.



P rey.f i  P rey.

P rey.i  P rey.

Figure 12: Example 5.2
Now (Step 1), we build the correspondent net NK (figure 12), and we obtain (Step 2)
that
 Born.e} .
D  = D  {p 
Then we move to the rational closure. The pair hT , D  i is changed into (Step 3)
 , i  f i  ,
D  = { p  b 

 P rey.f i  P rey., b  P rey.i  P rey.,
p

 Born.e, p  Born.e} .
b


The set of the materialisations of D  is (Step 4)
D  = {p  b  , i  f i  , p  P rey.f i  P rey.,
b  P rey.i  P rey., b  Born.e, p  Born.e}
AD = {p  b, i  f i, p, b} .
We obtain now (Step 5) the exceptionality ranking of the conditionals:
 , i  f i  , p  P rey.f i  P rey.,
E0 = {p  b 


 P rey.i  P rey., b  Born.e, p  Born.e}
b


 , i  f i  , p  P rey.f i  P rey., p  Born.e}
E1 = {p  b 



 , i  f i  }
E2 = {p  b 

 , i  f i  } = E .
E3 = {p  b 
2


450

fiDefeasible Inheritance-Based Description Logics

From this we get the ranking values of every conditional in D  : namely,
 P rey.i  P rey.) = r(b  Born.e)
0 = r(b 

 P rey.f i  P rey.) = r(p  Born.e)
1 = r(p 

 ) = r(i  f i  ) .
 = r(p  b 


From this ranking, we obtain (Steps 6-7) a background theory
Te = {  (p  b),   (i  f i)} ,

e = {0 , 1 }, with
and a default-assumption set 

0 = (b  P rey.i  P rey.)  (b  Born.e) 

1

(p  P rey.f i  P rey.)  (p  Born.e)
= (p  P rey.f i  P rey.)  (p  Born.e)

to be used for the definition of the consequence relation |K (Step 8).
For example, we derive that typical penguins preys are fishes, i.e.,
p|K P rey.f i ,
and not insects, i.e.,
p|K P rey.i ,
and that also penguins are born from eggs, i.e.,
p|K Born.e ,
that would not be derivable from the rational closure, as presented by Casini and Straccia (2010).
Computational Complexity. From a computational complexity point of view, as deciding entailment in ALC is ExpTime-complete (Donini & Massacci, 2000) and, as for
Section 2.2, the number of entailment tests is polynomially bounded by the size of the
knowledge base, following exactly the same procedures dened for the propositional case,
we conclude that
Proposition 5.2. Deciding C|K D in ALC is an ExpTime-complete problem.
5.1 Closure Operation over Individuals
So far we left out the ABox, but we are going to consider it here. The procedure for the
ABox is built over the above procedure for the TBox, that is, we consider a knowledge base
hA, T , Di such that all the strict knowledge has already been moved into T , i.e., in D we
do not have axioms with  as ranking value (that is, they correspond to the sets Te and
e obtained using the procedure in the previous section). The basic idea of the following
D
procedure is to consider each individual named in the ABox as much typical as possible,
that is, to associate to it all the possible defeasible information that is consistent with the
rest of the knowledge base. In order to apply the defeasible information locally to each
451

fiCasini & Straccia

individual, we encode such information using the materialisations of the inclusion axioms,
e in the section
i.e., the set  = h1 , . . . , n i, s.t. |= i  i+1 for 1  i < n (the set 
12
above ). We want to be able to associate to each individual a  O (with O being the set
of the individuals named in the ABox) the strongest formula i that is consistent with the
e = hAD , T i, that we call
knowledge base. In such a way we dene a new knowledge base K
a ABox extension of the knowledge base hA, T , Di.
Definition 5.1 (ABox extension). Given a knowledge base K = hA, T , Di, a knowledge
base hAD , T i is an ABox extension of K = hA, T , Di iff
 hAD , T i is classically consistent and A  AD .
 AD \ A is composed of all the assertions a:C such that a  O and C = i for some i,
and for every h s.t. h < i,
hT , AD  {a:h }i |= 
The above denition identies the extensions of the original ABox A s.t. to every
individual is associated all the defeasible information that is consistent with the rest of the
knowledge base. Still, the main problem is that, since the individuals can be related to
each other through roles, the possibility of associating a default concept to an individual
can be inuenced by the default information associated to other individuals, as shown in
the following example.
 AR.A}
Example 5.3. Consider K = hA, Di, with A = {(a, b):R} and D = D0 = { 
(hence we have  = h0 i = hA  R.Ai). If we associate 0 to a, we obtain b:A and we
cannot associate 0 to b; on the other hand, if we apply 0 to b, we derive b:A and we are
not anymore able to associate 0 to a. Hence, we define two possible rational extensions of
K.


This implies that, given a knowledge base hA, T , Di, even if the closure of hT , Di is
always unique there is the possibility that we have more than one ABox extensions. A
simple procedure to obtain all the possible extensions of a knowledge base hA, T , Di, with
O the set of the individuals in named in A, is the following:
Definition 5.2 (Procedure for ABox extensions).
 Consider the set S of all the linear orders of the individuals in O;
 For each s = ha1 , . . . , am i in S do:
 Set j := 1
 Set AsD := A
 Repeat until j = m + 1:
 Find the first default i   such that hAsD  {aj :i }, T }i 6|=   .
 AsD := AsD  {aj :i }.
e and 
e must be done
12. Note that, given a conditional knowledge base, the procedure to determine Te , D
once for all.

452

fiDefeasible Inheritance-Based Description Logics

 j =j+1
 return hAsD , T i
where we indicate by AsD the ABox extension of A obtained using the sequence s.
Now, it can be shown that
Proposition 5.3. Given a linear order of the individuals in K, the above procedure determines an ABox extension of K. Vice-versa, every ABox extension of K corresponds to the
knowledge base generated by some linear order of the individuals in O.
e1 = hA{a:A  R.A}, i
For instance, related to Example 5.3, we obtain the extension K
e
from the order ha, bi, while K2 = hA  {b:A  R.A}, i is obtained from the order hb, ai.
Example 5.4. Refer to Example 5.1, and let K = {A, T , D}, where
A = {a:p, b:b, (a, c):P rey, (b, c):P rey}
T = {p  b, i  f i}
 f, b  P rey.i, p  f, p  P rey.f i}
D = {b 




From such a knowledge base we define a set  = {0 , 1 } with

0 = (b  f )  (b  P rey.i)  (p  f )  (p  P rey.f i)
1 = (p  f )  (p  P rey.f i) .
If we consider an order where a comes before b, then we associate 1 to a, and consequently c is presumed to be a fish and we are prevented in the association of 0 to b. If we
consider b before a, c is not a fish and we cannot apply 1 to a.
Now, if we x a priori a linear order s on the individuals, we can say that a:C is a
e |= a:C, where K
e is
defeasible consequence of K w.r.t. the order s, written K s a:C, i K
the ABox extension generated from K based on the order s.

For instance, related to Example 5.3 and order s1 = ha, bi, we may infer that K s1 a:A,
while with order s2 = hb, ai, we may infer that K s2 b:A.
The interesting point of such a consequence relation is that it still satises the properties
of a rational consequence relation in the following way.
453

fiCasini & Straccia

(REFDL )

hA, T , Di s a:C for every a:C  A

(LLEDL )

hA  {b:D}, T , Di s a:C
D=E
hA  {b:E}, T , Di s a:C

(RWDL )

hA, T , Di s a:C
CD
hA, T , Di s a:D

(CTDL )
(CMDL )

hA  {b:D}, T , Di s a:C
hA, T , Di s b:D
hA, T , Di s a:C
hA, T , Di s a:C
hA, T , Di s b:D
hA  {b:D}, T , Di s a:C

(ORDL )

hA  {b:D}, T , Di s a:C
hA  {b:E}, T , Di s a:C
hA  {b:D  E}, T , Di s a:C

(RMDL )

hA, T , Di s a:C
hA, T , Di 6s b:D
hA  {b:D}, T , Di s a:C

We can show that
Proposition 5.4. Given K and a linear order s of the individuals in K, the consequence
relation s satisfies the properties (REFDL )  (RMDL ).
Note that from a computational complexity point of view, as entailment w.r.t. a ALC TBox
is ExpTime-complete (Donini & Massacci, 2000) and the number of individuals in K is linearly bounded by |K|, we get immediately
Proposition 5.5. Deciding K s a:C in ALC is a ExpTime-complete problem.
In the presence of multiple ABox extensions, we can also dene the inference relation
, a more conservative inference relation independent from any order on the individuals,
that corresponds to the intersection of all the inference relations s modelling a rational
extension.
=

\

{s | s is a linear order on the elements of O}

However, there is the possibility that we lose the property of rational monotonicity, as
shown in the following example.
Example 5.5. Consider the knowledge base hA, Di s.t. A = {(a, b):R} and D = D0  D1 ,
 A  R.A,   B} and D = {A  B, R.A  B} (where D and D
with D0 = { 
1
0
1



are the sets of the conditionals of rank 0 and of the conditionals of rank 1, respectively).
We can define two sequences on the individuals, s = ha, bi and s = hb, ai, each of them


defining a different rational extension (s and s ), and let =s  s . We have that
B
hA, Di  a:B, since in both the extensions a:B holds (in s because of the axiom  


s
s

a:A.
6
and in  for the axiom r.A  B) while we have hA, Di 6 a:A, since hA, Di 
However, hA  {a:A}, Di 6 a:B, since hA  {a:A}, Di 6s a:B.
454

fiDefeasible Inheritance-Based Description Logics

We have no increase in the computational complexity of the decision procedure: assuming that the number of individuals named in the ABox is n, we have to perform a s -test
for each possible sequences s dened on the n individuals. That is, in the worst case we
k
need to do n! s tests, each of which can be done in time O(2|K| ) for some k. Now, it can
2
be shown that13 n! < 2n and, thus, the decision problem for  remains in ExpTime.
Proposition 5.6. Deciding K  a:C in ALC is a ExpTime-complete problem.
Notwithstanding, we conjecture that in many (probably most) of the real-world cases, a
knowledge base would have a single rational ABox extension, and in such cases (RMDL ) is
still valid. To check whether a knowledge base hA, T , Di has a single rational ABox extension, it is sucient to associate to each individual in O the strongest i modulo consistency
w.r.t hA, T , Di, exactly as in the procedure in Denition 5.2, but doing the consistency
check of aj :i w.r.t. the original A instead that w.r.t. AsD . In the end, check whether
hAsD , T i is consistent; in such a case we have obtained the only rational ABox extension of
hA, T , Di.
The following is a knowledge base with a unique ABox extension.
Example 5.6. Consider the KB in Example 5.4, where (b, c):P rey is replaced with (b, d):P rey.
Then, whatever is the order on the individuals, we obtain the following association between
the default formulae and the individuals: a:1 , b:0 , c:0 , and d:0 . Using the information
in these defaults, we obtain an unique default-assumption extension.

A semantic characterization of  and s , making use of preferential DL models, is
presented by Casini et al. (2013).
Now lets briey consider some heuristics that are useful in case we want to present to
the system specic ABox queries. Assume we want to know if a particular individual a
presumably falls under a concept C, and we want to draw the safest possible conclusion.
In the presence of multiple acceptable extensions, the classical solution is to use a skeptical
approach, i.e., to use the inference relation , corresponding to the intersection of all the
inference relations associated to each possible ordering s of the individuals appearing in A.
As we have seen above, in case of multiple rational extensions the computational complexity of the  decision problem does not rise w.r.t the classical ALC decision problem.
Moreover, in case of multiple extensions, the amount of defeasible information associable to
an individual a can be inuenced only by the individuals related to it by means of a role: it
is immediate to see that if there is no role-connection in the ABox between two individuals
a and b, then the information that is associated to a does not inuence at all the amount
of defeasible information that we can associate to b, and the other way around. Hence,
we can ease the decisions w.r.t. the ABox introducing the notion of cluster, i.e., a set of
individuals named in the ABox that are linked by means of a sequence of role connections.
To do so, given an ABox A, we indicate with Q the symmetric and transitive
S closure of all
the roles in our vocabulary, i.e., the symmetric and transitive closure of R.
Definition
5.3 (Cluster). Define Q as the reflexive, symmetric and transitive closure of
S
R. Given an individual a  O, we call the cluster of a the set [a] of the individuals

13. This can be shown by induction on n, or see e.g.http://lifecs.likai.org/2012/06/better-upper-bound-forfactorial.html.

455

fiCasini & Straccia

connected to a through Q:
[a] = {b  O | Q(a, b)} .
Hence, in order to know what we can presumably conclude about a, it is sucient to
determine s w.r.t. each sequence s of individuals in [a]. Let A[a] be the ABox obtained restricting A to the statements containing individuals in [a]; the query a:C is clearly decidable
using only A[a] .
Proposition 5.7. hA, T , Di  a:C iff hA[a] , T , Di s a:C for every ordering s of the
individuals in A[a] .
If we have a query about an individual a s.t. a is not named in the ABox (a 
/ O), we
do not have any constraints dened in the ABox about a, i.e., we only know a:; hence, for
each individual not appearing in the ABox, we can associate with it the strongest default
concept consistent with T , that is 0 : for any a s.t. a 
/ O, we can derive that presumably
a:C holds i hAa , T i |= a:C, where Aa = A  {a:0 }.

6. Comparison with Related Work
Between non-monotonic logics, the so-called preferential approach can be distinguished
from the other various proposals (as Reiters defaults, modal approaches, defeasible inheritance. . . ) mainly due its logical properties, since the former approach is committed to the
satisfaction of some desirable structural properties of the consequence relation (see Section
2.2). On the other hand, considering them from the point of view of the inferential capacity
the preferential approach often results weaker than other proposals, since often there are
desirable, intuitive conclusions that we cannot derive (see Remark 1).
In our proposal we have tried to combine the classical rational closure with inheritance
networks in order to overcome the inferential limits without prejudicing the logical properties
of the consequence relation.
In Section 3 we also present an alternative way to reason about defeasible inheritance.
Despite our proposal has been presented mainly to integrate it with propositional language
and rational closure, it results an interesting approach per se, and in Appendix A we
compare it with Hortys classical skeptical extension (Horty, 1994, sect. 2-3) and Sandewalls
landmark examples (Sandewall, 2010).
As indicated in the introduction, there have been many papers aimed at the implementation of non-monotonic reasoning into the DL formalisms. For most of such proposals the
comparison with our approach has to be done considering the dierent non-monotonic formalisms, independently from the DL-environment. So we refer to Makinsons work (1994)
for a comparison between the various non-monotonic approaches.
In the last years the main proposals for the implementation of nonmonotonic reasoning
in DLs have been connected to two approaches: the preferential one and circumscription.
In the preferential approach, the work by Britz and al. (Britz et al., 2008; Britz, Meyer,
& Varzinczak, 2011) on preferential DL semantics is strongly connected to our approach,
and one of the results has been the semantic characterization of rational closure cited above
(Britz et al., 2013).
Still very close to our approach is the work by Giordano et al. (2012b), that is based too
on a preferential approach. The conclusions that we can derive using the logic ALC+Tmin
456

fiDefeasible Inheritance-Based Description Logics

are intuitive, but the complexity of the decision problem for the ABox is co-NExpNP (Giordano et al., 2012b, Thm. 13), and the procedure cannot be reduced to classical entailment.
Among the proposals based on circumscription, the work by Bonatti et al. (2009) is
particularly representative. From the point of view of the quality of the inferences, in such
a proposal it results more dicult w.r.t. the preferential approach to draw the expected
conclusions. For example, assume that our knowledge base contains the information that
mammals typically live on land, but that whales are abnormal mammals that do not live
on the land, and the ABox contains the information a:M ammal  W hale. Not knowing
anything else about the individual a, we would like our reasoning system to reason on the
assumption that we are dealing with a typical mammal (since, moreover, it is specied that
a is not a whale) and hence being able to derive that a lives on the land. However, using
circumscription, the conclusions we can draw changes w.r.t. which concepts the user decides
to keep fixed or varying (a non-trivial choice), and the results can be that we are not able
to derive a:Habitat.Land, that we are able to derive it, or we can even derive that whales
do not exist (Bonatti et al., 2009, sect. 2.1). In our proposal instead, we can formalize the
problem with a knowledge base hA, T , Di with A = {a:M ammal} (we do not need to specify
that it is not a whale), T = {W hale  M ammal, W hale  Habitat.Land} and D =
 Habitat.Land}; without needing any kind of choice from the user, the system
{M ammal 
can derive automatically a:Habitat.Land. Moreover, we have seen that the computational
cost of our procedure involving an ABox is exponential, while in the circumscription case, for
languages analogous to ALC, the complexity of the instance problem is co-NExpNP (Bonatti
et al., 2009, sect. 4.1.1). Some of the issues just discussed have been addressed and solved
by Bonatti et al. (2010, 2011a), but only for circumscriptive systems that are specically
built for low-complexity DLs such as EL.
On the other hand, procedures based on circumscription are able to derive defeasible
information about individuals that are implicit in the ABox, that is, they can, for exam D that presumably a:R.D. Our procedure involving
ple, conclude from a:R.C and C 
ABoxes is not able to make such a kind of derivation, since we can add defeasible information
only to the individuals named in the ABox. We are working on a further renement of the
procedure in order to deal also with the implicit individuals; a rst attempt to take under
consideration also such individuals has been proposed in a previous publications (Casini &
Straccia, 2010, pp. 9-10), adding a completion procedure for the ABox in order to explicitly
name in the ABox the implicit individuals, but such a procedure needs to be rened.
Among the proposals regarding the introduction of probabilistic reasoning in DLs,
Lukasiewicz (2008) presents a combination of nonmonotonic and probabilistic reasoning.
The nonmonotonic part is based on the preferential approach, and he too presents a construction that augments the inferential power of rational closure. Let us consider his proposal by eliminating the probabilistic part, i.e., considering only conditionals associated to
probability 1 (conditionals (|)[1, 1] in his notation), since they convey the same meaning
as our defeasible conditionals. His procedure seems to give back the same results as ours in
most of the cases, but the two proposals dier in the general approach: he proceeds with a
renement of the ranking structure, while we use a renement of the content of the knowledge base. In fact, the behaviour of the two can dier. Consider for example a knowledge
 b, a  d, b  c, c  e, d  e} (in Lukasiewiczs notation it would
base h, Di, with D = {a 




correspond to a knowledge base with an empty TBox and a set P containing the conditionals
457

fiCasini & Straccia

(b|a)[1, 1], . . . ).14 In our construction we can derive a|c, since there is simply a duct ha, b, ci
from a to c, while in Lukasiewiczs approach we cannot, since we have to consider what follows from all the three preferred subset of the knowledge base that are consistent with
 b, a  d, b  c, c  e}, {a  b, a  d, b  c, d  e}, {a  b, a  d, c  e, d  e}),
a (that are {a 











and a|c does not follow from the latter.

7. Conclusions
By combining the classical rational closure with ideas from defeasible inheritance networks,
we have proposed a new rational consequence relation that overcomes some limits of both the
formalisms. By doing so, we have extended the defeasible inference capabilities by allowing
an atypical class still to inherit some properties from its superclass while maintaining the
desired logical properties of rational closure. The table below summarizes the structural
properties satised by the systems taken under consideration:15

REF
CT
CM
LE
RW
OR
RM

Horty





IN






BIN







PL








DL








As we can see, our proposals for defeasible inheritance-based propositional logic and
Description Logics still satisfy all axioms of classical rational closure. Another feature is
that our method does uniquely require the existence of a decision procedure of classical
entailment and, thus, can be implemented on top of exiting propositional SAT solvers and
DL reasoners. Since we have introduced a procedure that is interesting also from the point
of view of inheritance nets, we have presented the more comprehensive procedure for logical
knowledge bases making use of the nets formalism; notwithstanding, we are condent that
the procedure can be reformulated avoiding the shift from one formalism to another.
The procedure presented for ALC can be straightly extended to languages more expressive than ALC; on the other hand, at present the procedure needs a language that is
closed under propositional connectives, and hence we need to augment the expressivity of
the language in order to apply it to less expressive DL languages as EL, forcing in this way
an increase in the computational costs w.r.t. the classical decision problem.
Hence, looking for an adaptation of the procedure appropriate for dealing with tractable,
less expressive DLs is one of the main open problems of the present proposal, together with
a more proper semantic characterization of the procedure and the ability of reasoning in a
defeasible way about implicit individuals, as discussed in the previous section.
14. The example corresponds to the structure of Example.A.4 in Appendix A, just eliminating the link at
the center of the figure.
15. IN, BIN, PL, DL stand for our proposals for INs, Boolean INs, propositional logic and DLs, respectively.

458

fiDefeasible Inheritance-Based Description Logics

Appendix A. Examples
We are going to validate our decision procedures for inheritance nets against some signicant
examples proposed by Horty (1994) and Sandewall (2010). We shall use BINs, but, in order
to simplify the graphical representation, we shall also use 6 as a macro, as explained in
Section 3.2. As a side eect, we obtain an analogue behaviour for the propositional and DL
cases too.
Example A.1 (Horty, 1994, ex. 12 ). Consider the net in Figure 13. Horty claims that the
desirable conclusion should be a|p, since In the environment of mixed nets [. . . ] certain
kinds of compound defeasible paths can legitimately be thought to carry immediate information - namely, those paths consisting of a single defeasible link followed by a strict end
segment, of any length (Horty, 1994, p. 143). That corresponds to the condition of (RW ),
that, as we have seen in Section 3.1.2, our procedure satisfies.
r
s

p

a

t

Figure 13: Example A.1
Indeed, we translate the net into the KB K = h, i, with  = {a  s, s  t, r  p}
and  = {s  r, t  p}. We have a,p = , a,p |= s, and a,p |= a. So the only
implication in a,p with ranking grater than 0 is s  r, and, since s  r  a  p, we have
a|K p.
Example A.2 (Horty, 1994, ex. 18 ). Consider the net in Figure 14. In this example Horty
claims that we should not prefer the negative path ha, p, si over the positive path ha, r, si,
since the negative link a 6 q nullifies the path from p to r. Our procedure satisfies such a
claim.
p
a

q

s

r

Figure 14: Example A.2
Indeed, we translate the net into the KB K = h, i, with  =  and  = {a  p, a 
r, p  q, q  r, r  s, a  q, p  s}. We have a,s = , a,s  p, and a,p  a.
459

fiCasini & Straccia

Therefore, we have E1 = {a  p, a  r, a  q, p  q, p  s}. Now, E1  a, and a is the
only node of rank 2, with E2 = {a  p, a  r, a  q}. So we conclude neither a|s nor
a|s.
Example A.3 (Sandewall, 2010, ex. B.1, Double Diamond). Consider the net N = {S, U }
defined as (see Figure 15)
S = {s  s, r  r}
U

= {a  t, a  p, t  s, p  s, s  r, p  q, q  r}
s
r

t



s

r

q

a
p

Figure 15: Double diamond.
The net N is translated in the knowledge base K = {, } with  = {} and  = {a 
t, a  p, t  s, p  s, s  r, p  q, q  r}.
Using our method, from this net we derive neither a|r, nor a|r, as it should be.
However, we can derive a|q, which is a desirable result that is not derivable with Sandewalls
approach.
Example A.4 (Sandewall, 2010, ex. B.2, Simonets Scenario). Consider the net N = {S, U }
defined as (Figure 16)
S = {e  e}
U = {a  b, a  d, b  c, c  e, d  c, d  e} .
c
e

b


a

e
d

Figure 16: Simonets scenario.
460

fiDefeasible Inheritance-Based Description Logics

The net N is translated in the knowledge base K = {, } with  = {} and  = {a 
b, a  d, b  c, c  e, d  c, d  e}.
Using our method, from this net we derive a|e, as it should be, while Sandewall cannot
derive it. Moreover, he derives neither a|c nor b|e.
Example A.5 (Sandewall, 2010, ex. B.3, On-Path vs. O-Path Preemption). Consider the
net N = {S, U } defined as (see Figure 17)
S = {wa 6 ga}
U

= {c  re, c  ce, re  e, ce  e, e  ga, re  wa} .
e
ce

c

ga

wa
re

Figure 17: On-Path vs O-Path.
The net N is translated in the knowledge base K = {, } with  = {wa  ga} and
 = {c  re, c  ce, re  e, ce  e, e  ga, re  wa}.
The connection c  wa is valid only if we use a form of off-path preemption, while with
on-path preemptions it is not derivable. In our setting, we derive c|wa: even if we cannot
consider our method a form of preemption (at least explicitly), as said in Section 3.1.5 our
method gives back results that are analogous to those of off-path preemption.
The following examples use also conjunctions, so we are going to use BINs.
Example A.6 (Sandewall, 2010, ex. B.4, Juvenile Oender). The original Juvenile offender example is represented by the following net (see Figure 18) N = {S, U }, with
S = {b  g, b  m, p  p, m, g  m  g}
U

= {g  p, m  p} ,

where p is read as to be punished, g as guilty, m as is minor, b is Billy. We want
to express that m has the priority on g, and so that b N w. Since in our nets it is
possible to express conjunctions, we can solve the problem adding the link m  g  p and
m, g  m  g.
The net is translated in the knowledge base K = {, } with  = {b  g, b  m} and
 = {g  p, m  p, m  g  p}. From this knowledge base we derive b|p, as expected.
Example A.7 (Sandewall, 2010, ex. B.5, Campus Residence Scenario). As in example A.6,
in the Campus residence example there is the necessity to include priorities. We can solve
461

fiCasini & Straccia

m
mg

b



p

g

p

Figure 18: Juvenile oender.
the problem by inserting conjunctions. Indeed, the net N = {S, U } is composed by (see
Figure 19)
S = {t  ma, t  e, t  m, w 6 n, ma, e  ma  e}
U = {ma  e  w, m  n} ,
where ma is read as is married, e as employed, w as lives in west apartments, m as
male, n as lives in northern apartments, t is Tom. We want to express that ma  e has
the priority on m, and so that t  w results valid. to do so, we add the links mmae  w,
and m, ma  e  m  ma  e.
ma
ma  e
w

t

e

ma  e  m

n
m

Figure 19: Campus residence scenario.
The net is translated in the knowledge base K = {, } with  = {t  ma, t  e, t 
m, w  n} and  = {ma  e  w, m  n, m  ma  e  w}. From this knowledge base we
derive t|w, as expected.
We treat the last example as a propositional problem. Just to have a simpler net from
the graphical point of view we do not put the negation nodes that are useless for the
resolution, and we use a three-place conjunction link, just as a macro for the construction
of the conjunction of three nodes.
462

fiDefeasible Inheritance-Based Description Logics

Example A.8 (Sandewall, 2010, ex. B.6, Good Math Student Scenario). The knowledge
base K = {T , D} is composed by (see Figure 20)
T

= {t  gs, t  f m, t  mb, aa  ag}

D = {mb|ag, f m  ag|mm, mm  mb  gs|aa, f m|pm} ,

gs

mb
mm  mb  gs

t

ag
aa

f m  ag
mm
fm
pm

Figure 20: Good math student.
Sandewall identifies the following candidates for valid conclusions:
t|ag t|aa t|f m  ag
t|mm t|mm  mb t|mm  mb  gs

t|pm .

We cannot conclude any of the conditionals above. The point is that the net is highly
interconnected, especially by strict links, so that all the nodes have ranking 0, except for t
and mm  mb  gs that have ranking 1. Therefore, any of the conclusions above, with t as
premise, cannot be obtained.

Appendix B. Proofs
Proposition 3.1. Consider a net N = hS, i and translate it into a set of propositional
implications . The following properties hold:
1. If N is a consistent net, there is a valid strict positive (resp., negative) path hp, , qi
from p to q, that is N
p  q (resp., N
p 6 q), iff   p  q (resp.,   p  q).
2. N is inconsistent iff   p for some p  A .
463

fiCasini & Straccia

3. Deciding strict consequence can be done in polynomial time.
Proof. First, it is easy to prove by induction on the length of the paths that, if there is a
positive (resp., negative) path in S from p to q, then   p  q (resp.,   p  q). Hence
we have:
1a) If N is a consistent net and there is a valid strict positive (negative) path (p, , q)
from p to q, then   p  q (  p  q).
Moreover, if N is inconsistent, then we can conclude, for some p, q in it, p  q and
p 6 q, and so we have   p  q and   p  q, that is,   p. So we have one half of
the second statement.
2a) If  6 p for every p  A , then N is consistent.
Now we move to show the other halves of the statements.
1b) If N is a consistent net and   p  q (resp.,   p  q), then there is a valid strict
positive (resp., negative) path (p, , q) from p to q.
In order to model the classical consequence relation , we use the propositional resolution method. We use the symbol R to indicate the inferences in the resolution
method.
Every element of  has the forms p  q or p  q. Such implications correspond, in
the clause form, respectively to the clauses (i.e., sets of literals) {p, q} and {p, q}.
Call  the set of the clauses corresponding to . For example, if we assume that
 R {p, q} (that is,   p  q), we have that the set of clauses , {p}, {q} resolves
into the empty set (that is, , (p  q)  ).
1. Positive case (N
p  q): Assume   p  q for some p, q  PN . In order to
apply the refutational approach, p  q has to be negated, and, since (p  q)
is equivalent to p  q, we introduce the clauses {p}, {q}. So, in the resolution
approach   p  q is translated into , {p}, {q} R . We have also assumed
that  is consistent, and hence we have that  6R . Since the set  is composed
only of pairs of literals (of form {p, q} or {p, q}), every reduction step between
them gives back again a pair of literals (for example, from {p, q} and {q, r},
we obtain {p, r}). Therefore, in order to obtain the empty set we need to use
both {p} and {q} in the refutation procedure. So, the clause {q} must be
eliminated using a clause containing q. Such a clause must necessarily have the
form {ri , q} for some ri , and we obtain a new clause {ri }. Again, {ri } can
be eliminated only by a clause of form {rj , ri }, obtaining a clause {rj }. Since
the set  is nite, such a procedure has to terminate, and it can only be done if
we obtain a clause {p}, that can be resolved by {p}. That is, there has to be in
 a clause {p, rl }, for some rl , s.t. {rl } appears in the reduction procedure.
Now, the clauses of  used in the reduction process correspond to a chain of
links in the net S: p  rl , . . . , ri  q, that dene a valid path (p, , q) in S.
2. Negative case (N
p 6 q): assume   p  q for some p, q  PS . p  q has
to be negated and it is translated into the clauses {p}, {q}. {q} can be combined
464

fiDefeasible Inheritance-Based Description Logics

with a clause of form {q, ri } (that represents q  ri , that, in turn, represents
a link q 6 ri ) (case 1), or with a clause of form {q, ri } (i.e., q  ri , that, in
turn, is q  ri ) (case 2).
Case 1. We obtain the clause {ri }, and the procedure is the same of the positive
case. The clauses used in the reduction process correspond to a strict negative path of form: p  rl , . . . , rj  ri , ri 6 q.
Case 2. We obtain the clause {ri }, and we would have combine it with a clause of
form {ri , rj }, or of form {ri , rj }. In the former case we move to case
1, ending with a strict negative path p  rh , . . . , rl  rj , rj 6 ri , ri  q.
In the latter case we have a new clause {rj }, and we are again in case
2; however, such a procedure has to terminate, and, in order to terminate,
such a reduction procedure has at some point to move into the case 1. The
clauses used in the reduction procedure correspond to a path of form p 
ri , . . . , rj  rk , rk 6 rl , rl  rm , . . . , rn  q, where the link 6 corresponds
to the shift to the case 1.
2b) Automatically, we have also that if N is consistent, then  6 p for every p  A .
Otherwise, we would have   p  q and   p  q for some nodes p and q, that
would imply, by the procedure above, the inconsistency of N .
3) About the third point, consider that strict links can be encoded as 2-CNF formulae,
also called Krom formulae, and the propositional 2-SAT problem is in P .

Proposition 3.2. Consider a net N . For every connection p|N q (resp., p|N q) validated
by our procedure, there is a corresponding positive (resp., negative) potential path from p to
q in the net N .
b p,q . Our procedure states that p| q i 
b p,q    p  q (and
Proof. Dene the set 
N
b p,q    p  q). Following a procedure analogous to the one of the proof of
p|N q i 
proposition 3.1, we can show that the derivation of such implications is connected to the
presence of positive (negative) potential paths in the net.
Proposition 3.3.



satisfies (REF ), (CT ) and (CM ).

To prove this proposition we need rst to prove the following lemma.
 p  q (  {, 6}). Call  the set
Lemma B.1. Consider a net N = hS, U i s.t. N
of material implications corresponding to the links in S, and  the consequence relation
obtained adding to  the formulae in  as extra-axioms. Consider the net N  obtained
N
adding the link p  q in N . Then, for every pair of nodes r, s in N , we have that 
r,s and

N


r,s are equivalent w.r.t.  .

Proof. The two nets contain the same nodes. Given two nodes r and s, we have two possible
N  , we have C N  = C N  , and consequently
N  or p  q  C N  . If p  q 
/ Cr,s
cases: p  q 
/ Cr,s
r,s
r,s
r,s
 N  . If p  q  C N  , we have that C N   C N  , and consequently C N  C N , and the
N = 

r,s
p,q
r,s
r,s
r,s
r,s
r,s
465

fiCasini & Straccia





N and C N on one hand and C N and C N
correspondent sets of courses in the two nets (Cp,q
p,q
r,s
r,s
on the other) contain exactly the same nodes and the same links, apart, possibly, from p  q.
N
N
N
That corresponds to saying that N
p,q and p,q on one hand, and r,s and r,s on the other
contain exactly the same implications, apart, possibly, from p  lq (where lq  {q, q}),
and exactly the same set of antecedents.
 p  q, we have 
N
N
N
Since N
p,q  p  lq , and consequently p,q  p  lq . So, p,q


N
N
N
and N
p,q are  -equivalent, and then also r,s and r,s are  -equivalent. So, since r,s

N
and r,s are  -equivalent and contain the same set of antecedents, they generate the same
 N  are equivalent w.r.t.  .
 N and 
ranking, that is, 
r,s
r,s

Now we can prove Proposition 3.3.
Proof. The satisfaction of (REF ) is trivial, since every direct link is trivially valid.
(CT ): assume N  p  q and N , p  q  r  s. We call N  the net obtained adding p  q

N
in N . N   r  s means that 
r,s  r  ls (ls  {s, s}). By the lemma B.1 we have that
 N  r  ls , that is, N  r  s.
 N  are equivalent w.r.t.  , so we have also 
 N and 

r,s
r,s
r,s


(CM ): assume N
p  q and N
r  s. We call N  the net obtained adding p  q in
 N  r  ls . By the lemma B.1 we have that 
 N and 
 N
N . N  r  s means that 
r,s
r,s
r,s

 r  s.
N
are equivalent w.r.t.  , so we have also 

r

l
,
that
is,
N
,
p

q
s
r,s 
Proposition 3.5.



satisfies (LE), (RW ), and (Sup).

Proof. The proofs are immediate, considering our procedure and the fact that the implications corresponding to strict links are always present in each decision procedure.
Proposition 3.6 A net N is consistent iff we do not have a node p with r(p) = , that is,
we do not conclude both N  p  q and N  p 6 q for any pair p, q.
It is proved combining the following two lemmas.
Lemma B.2. Given a net N , and two nodes p and q in it, we can conclude both p|N q
and p|N q iff r(p) = .
Proof. From left to right. It is immediate from the denition of the ranking procedure: if
r(p) 6= , then the set of implications with at least the same ranking as p do not imply p,
and so they cannot imply both p  q and p  q for any q.
From right to left. If r(p) = , we have a set E 16 of implications (with p between
their antecedents) such that E  p. That implies E  p  q and E  p  q for
whichever q, that is, p|N q and p 6 |N q.
Lemma B.3. Every node with ranking  in a set of courses C has the same ranking value
in every set of courses extending C.
Proof. It is immediate from the monotony of the consequence relations N .
16. E is the set of -ranked defaults.

466

fiDefeasible Inheritance-Based Description Logics

From these lemmas we conclude that if a node p has innite ranking in a net, then the net is
inconsistent (p|N q and p|N q for some p and q), and, conversely, if a net is inconsistent,
then there is a node p with innite ranking.
Proposition 3.9

BIN

satisfies (REF ), (CM ), and (CT ).

Proof. The proof retraces the one for proposition 3.3.
Proposition 3.10

BIN

satisfies (LE), (RW ), and (Sup).

Proof. The proof retraces the one for proposition 3.5.
Proposition 3.11

BIN

satisfies (OR) and (AN D).

Proof. (OR): we have N BIN p  t and N BIN q  t, and we have p, q  s  S. Assume
 =. The case with  =6 is analogous.
 p,t  p  t and 
 q,t  q  t.
We have N BIN p  t and N BIN q  t, that is, 
Since N BIN p  t and N BIN q  t, by proposition 3.2 we have at least a duct between
p and t and one between q and t. So, since p, q  s, there is a duct from s to t. Moreover,
since there is at least a duct between s and t and p  s and q  s, every duct connecting
s to t allows for a duct connecting p to t and q to t. Hence, s,t  p,t and s,t  q,t
holds.
On the other hand, we have that, since p, q  s, s is connected to t by all the connections moving from p and from q. So, we have that p,t  s,t and q,t  s,t . Hence,
p,t = q,t = s,t holds and the ranking functions rs,t , rp,t , and rq,t are the same as they
work with the same sets of material implications.
At the propositional level, we have that  s  (p  q) and either rs,t (p)  rs,t (q) or
rs,t (q)  rs,t (p). Assume the former (the same reasoning applies in the other case). If
 q,t  
 p,t . Moreover, the least set in the exceptionality order
rs,t (p)  rs,t (q) we have that 
negating p does negate also q, and so is the least set in the exceptionality order negating
 p,t = 
 s,t . So, 
 s,t  p  t, and, since 
 q,t  
 p,t ,
t, that is, rs,t (t) = rs,t (p), and 


we have also s,t  q  t; hence by classical reasoning we obtain s,t  (p  q)  t,
 s,t  s  t. Eventually, N BIN s  t.
i.e., 
(AN D): we have N BIN p  q and N BIN p  s, and we have s, q  t  S. Every
duct connecting p to q and p to s are part of a duct connecting p to t by the addiction
of s, q  t, while every duct connecting p to t is part of a duct connecting p to q (resp.,
p to s) by the addiction of t  q (resp., t  s). So, p,q = p,s = p,t , and we obtain
N BIN p  t.
Proposition 3.12 A BIN N is consistent iff we do not have any node p with r(p) = ,
that is, we cannot conclude both p  q and p 6 q for any pair p, q.
Proof. The proof is similar to the one for proposition 3.6.
Proposition 4.1. |K is a rational consequence relation containing K.
Proof. |K has been obtained as the rational closure of K , so it is a rational consequence
relation. Moreover, R(K ) contains K , and, since K  K , it contains K too.
467

fiCasini & Straccia

Proposition 4.2. Given a conditional base K, |K  iff |  R(K).
Proof. It is sucient to prove that, given a conditional base K = hT , U i, and obtained its
extension K = hT , U  i (Steps 1-3), K is preferentially consistent i the conditional base K
is preferentially consistent too.
From right to left the proof is immediate, since K  K . From left to right, if K is
6 . Given that every conditional added in K corresponds
consistent that means that T D 
to an implication that is classically derivable from a subset of T  D, we have that T 
D   C(T  D) (where C is the classical closure operation associated to ). So we have
C(T  D  ) = C(T  D). Then,  
/ C(K ), and K is a consistent knowledge base too.
Proposition 5.1 |K is a rational consequence relation containing K.
Proof. It is sucient to show (1) that every inclusion axiom in T and in D is valid in |K ,
and (2) that |K satises the properties characterizing a rational consequence relation.
(1) By construction, if C  D  T , then   C  D  Te (that is, modulo logical
equivalence, T  Te ). Assume C|D  D. Then we have either r(C) = r(C|D) = ,
or r(C) = r(C|D)= i, for some i < . In the rst case we have   C  Te ,
e  D, which implies C| D. In the second case, we have that
and so  {C}  
K
 i  C  D, with i being the default-assumption associated to the premise C.
e  {i }  D, that is, C| D.
Hence we have  {C}  
K

(2) The consequence relation |K satises the properties of a rational consequence relation.
(REF ) is obviously satised, as (LLE) is. For (RW ), assume we have C|K D. That
e  {i }  D, that, given
means that for the rst C-consistent i in ,  {C}  
e
e D  E, implies  {C}    {i }  E, i.e., C|K E.

e  i  E, where i is the rst C 
(CT ) C  D|K E corresponds to  {C  D}  
D-consistent formula in . Analogously, C|K D means that for the rst Ce  {j }  D. Since  C  D  C, we have that
consistent j in ,  {C}  
j  i, that is,  j  i . Hence, we have that  {C  D}  T  {j }  E and
e  {j }  D, and, since  satises (CT ),  {C}  
e  {j }  E, that
 {C}  
is, C|K E.
e  {i }  E.
(CM ) C|K E means that for the rst C-consistent i in ,  {C}  
e  {i }  D for the same i . Hence, i
Analogously, C|K D means that  {C}  
e
is consistent with CD, and, by the monotony of , we have  {CD}{
i} 
E, that is, C  D|K E.
e  {i }  E.
(OR) C|K E means that for the rst C-consistent i in ,  {C}  
e
Analogously, D|K E means that  {D}    {j }  E for the rst D-consistent
j in . We have three options: j = i, j < i or i < j. In the rst case,
the default-assumption associated with C  D is i , and, since  satises OR,
 {C  D}  T  {i }  E, that is, C  D|K E. If j < i, we have that j  i , and
e
that j is the rst CD-consistent default in . Hence we have  {D}{
j} 
e
E, and, by monotonicity,  {C}    {j }  E. Since  satises OR, we have
e  {j }  E, that is, C  D| E.
 {C  D}  
K
468

fiDefeasible Inheritance-Based Description Logics

e
(RM ) C 6 |K E corresponds to 6 {C} {
i }  E, where i is the rst C-consistent
e  {i }, and so i
formula in . This means that E is consistent with {C}  
e
is the rst C  E-consistent formula in . Since  {C}    {i }  D, by the
e  {i }  D, that is, C  E| D.
monotonicity of  we have  {C  E}  
K
Proposition 5.3 Given a linear order of the individuals in K, our procedure determines an
ABox extension of K. Vice-versa, every ABox extension of K corresponds to the knowledge
base generated by some linear order of the individuals in O.
Proof. The rst statement is quite immediate. For the second statement, assume that there
is a rational extension hA , T i of hA, T , Di that cannot be generated by any sequence s of
the elements of O. A associates to every individual x a default concept from , that we
indicate as x .
Now, consider a generic rational extension hAD , T i of hA, T , Di that can be generated
using a sequence of elements of O. The following procedure allows to dene a sequence s
of the elements of O s.t. hAD , T i can be generated using s, i.e., hAD , T i = hAsD , T i.
Take each element of O and associate to it the strongest default concept in  consistent
with the knowledge base hA, T i (call it  x ). Look for an individual x s.t. x =  x , and
consider x the rst element of the sequence s. Update A with x:x , and repeat the procedure, until every individual has been associated to a default formula. With this procedure
we can generate a sequence over the dominion of the individuals that generates hAD , T i
from hA, T , Di.
Since there is no sequence s that can generate hA , T i, the above procedure has to fail,
that is, at some point it will not be possible to associate to any x a default  x s.t. x =  x .
That means that, for all the remaining x, x 6=  x ; for each such x, either x   x or
 x  x . The rst case is not possible, since hA , T i would be inconsistent ( x has to be a
maximally consistent default). Hence  x  x and x 6=  x for all the remaining x. In such
a case, hA , T i would not be a rational extension of hA, T , Di, since we could have another
consistent model with stronger defaults associated to some individuals.
Proposition 5.4 Given K and a linear order s of the individuals in K, the consequence
relation s satisfies the properties (REFDL )  (RMDL ).
Proof. For REFDL , LLEDL and RWDL the proof is quite immediate. For CTDL and
CMDL , assume hA, T , Di s b:D, that is hAsD , T i  b:D. Hence, b:D is consistent with
hAsD , T i; this implies that for the rst individual in the sequence s, let it be a, and for
every i  , a:i is consistent with hA, T i i it is consistent with hA  {b:D}, T i, and the
procedure associates to a the same default formula either we start with A or with A{b:D}.
The same happens for all the following individuals in the sequence s. So we have that
hAsD  {b:D}, T i = h(A  {b:D})sD , T i and hAsD  {b:D}, T i  a:C i h(A  {b:D})sD , T i 
a:C. Since  satises CT and CM , we have that hAsD , T i  a:C i h(A{b:D})sD , T i  a:C,
that is, hA, T , Di s a:C i hA  {b:D}, T , Di s a:C.
For ORDL , assume that hA  {b:D}, T , Di s a:C, hA  {b:E}, T , Di s a:C, and that
b is in the nth position in the sequence s. So, for the rst n  1 elements of s the association
with the default-formulae is the same in both the models. For b, assume that the procedure
469

fiCasini & Straccia

assigns b:i in case b:D, and b:j in case b:E. We can have either i = j ,  i  j , or
 j  i . In the rst case the procedure for the assignment of the defaults continues in the
same way in both the knowledge bases, and it is the same also if we have b:D  E, that
is, hA  {b:D}, T , Di, hA  {b:E}, T , Di, and hA  {b:D  E}, T , Di are completed exactly
with the same defaults, obtaining, respectively, the ABoxes (A  {b:D})sD = A  {b:D},
(A  {b:E})sD , = A  {b:E}, and (A  {b:D  E})sD = A  {b:D  E}, for some ABox
A . So we have that A  {b:D}  a:C and A  {b:E}  a:C, and, since  satises OR,
we obtain A  {b:D  E}  a:C, that is, h(A  {b:D  E})sD , T i  a:C. If i  j and
b:D  E, the procedure associates to b the strongest of the two defaults, that is, i . Since
i is not consistent with b:E, in every following consistency check the procedure will be
forced to consider that b:D holds, and the assignment of the defaults to the individuals will
proceed as in the case where b:D holds, and hA  {b:D  E}, T , Di will entail the same
formulae as hA  {b:D}, T , Di. Analogously, if j  i , the default-assumption extension of
hA  {b:D  E}, T , Di will correspond to the one of hA  {b:E}, T , Di.
Finally, for RMDL , b:D is consistent with hAsD , T i, so the presence of b:D in the
knowledge base does not inuence the association of the defaults to the individuals, and
AsD  (A  {b:D})sD . Eventually, hAsD , T i  a:C implies h(A  {b:D})sD , T i  a:C, i.e.
hA  {b:D}, T , Di s a:C.
Proposition 5.7 hA, T , Di  a:C iff hA[a] , T , Di s a:C for every ordering s of the individuals in A[a].
Proof. The proof is quite immediate. Assume hA[a] , T , Di 6s a:C for some s. Let s be a
sequence of the individuals named in A obtained using s as initial segment. Hence we have

that hA, T , Di 6s a:C, the implies hA, T , Di 6 a:C.
Now assume hA, T , Di 6 a:C. Hence, for some sequence s hA, T , Di 
6 s a:C. Let s be a

restriction of s to the individuals named in A[a] ; then we have that hA, T , Di 
6 s a:C.

Appendix C. Table of the Main Symbols
Since the paper considers dierent elds, the notation has turned out to be quite complex.
We add here a table to summarize the main symbols used in the paper.

N
Cp,q

IN/BIN
nodes
strict conditional
defeasible conditional
consequence relation
conjunction, disjunction
links in the courses/ducts
between p and q

PL
atoms
propositions
strict conditional
defeasible conditional
links in the ducts
between p and q

DL
concept names
concepts
individuals
strict conditional
defeasible conditional
links in the ducts
between p and q

N
p,q

materialisations of the
N
links in Cp,q

materialisations of the
N
links in Cp,q

materialisations of the
N
links in Cp,q

N

p,q

conditionals in N
p,q
as exceptional as p

conditionals in N
p,q
as exceptional as p

conditionals in N
p,q
as exceptional as p

p, q, . . .
C, D, . . .
a, b, . . .

|
, 

470

fiDefeasible Inheritance-Based Description Logics

References
Alchourron, C., Gardenfors, P., & Makinson, D. (1985). On the logic of theory change:
Partial meet contraction and revision functions. Journal of Symbolic Logic, 50, pp.
510530.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2003). The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press.
Baader, F., & Hollunder, B. (1993). How to prefer more specic defaults in terminological
default logic. In Proceedings of IJCAI-93, pp. 669674. Morgan Kaufmann Publishers.
Bochman, A. (2001). A logical theory of nonmonotonic inference and belief change. SpringerVerlag.
Bonatti, P. A., Lutz, C., & Wolter, F. (2009). The complexity of circumscription in description logic. Journal of Artificial Intelligence Research, 35, pp. 717773.
Bonatti, P. A., Faella, M., & Sauro, L. (2010). EL with default attributes and overriding. In
Patel-Schneider, P. F., Pan, Y., Hitzler, P., Mika, P., Zhang, L., Pan, J. Z., Horrocks,
I., & Glimm, B. (Eds.), International Semantic Web Conference (1), Vol. 6496 of
Lecture Notes in Computer Science, pp. 6479. Springer.
Bonatti, P. A., Faella, M., & Sauro, L. (2011a). Adding default attributes to EL++ . In
Burgard, W., & Roth, D. (Eds.), Proceedings of AAAI-11. AAAI Press.
Bonatti, P. A., Faella, M., & Sauro, L. (2011b). Defeasible inclusions in low-complexity
DLs. Journal of Artificial Intelligence Research, 42, pp. 719764.
Bonatti, P. A., Faella, M., & Sauro, L. (2011c). On the complexity of el with defeasible
inclusions. In Proceedings of IJCAI-11, pp. 762767. AAAI Press/IJCAI.
Brewka, G., & Augustin, D. S. (1987). The logic of inheritance in frame systems. In
Proceedings of IJCAI-87, pp. 483488. Morgan Kaufmann Publishers.
Britz, K., Casini, G., Meyer, T., Moodley, K., & Varzinczak, I. (2013). Ordered Interpretations and Entailment for Defeasible Description Logics. Tech. rep., CAIR, CSIR
Meraka and UKZN, South Africa.
Britz, K., Heidema, J., & Meyer, T. A. (2008). Semantic preferential subsumption. In
Brewka, G., & Lang, J. (Eds.), Proceedings of KR-08, pp. 476484. AAAI Press.
Britz, K., Meyer, T., & Varzinczak, I. J. (2011). Semantic foundation for preferential
description logics. In Wang, D., & Reynolds, M. (Eds.), Australasian Conference on
Artificial Intelligence, Vol. 7106 of Lecture Notes in Computer Science, pp. 491500.
Springer.
Casini, G., Meyer, T., Moodley, K., & Varzinczak, I. (2013). Nonmonotonic reasoning in
description logics. Rational closure for the ABox. In Proceedings of DL-13, pp. 7790.
CEUR Workshop Proceedings.
Casini, G., & Straccia, U. (2010). Rational closure for defeasible description logics. In
Janhunen, T., & Niemela, I. (Eds.), Proceedings of JELIA-10, Vol. 6341 of Lecture
Notes in Computer Science, pp. 7790. Springer.
471

fiCasini & Straccia

Casini, G., & Straccia, U. (2011). Defeasible inheritance-based description logics. In Proceedings of IJCAI-11, pp. 813818.
Cormen, T. H., Stein, C., Rivest, R. L., & Leiserson, C. E. (2001). Introduction to Algorithms
(2nd edition). McGraw-Hill Higher Education.
Donini, F. M., & Massacci, F. (2000). EXPTIME tableaux for ALC. Artificial Intelligence,
124 (1), pp. 87138.
Donini, F. M., Nardi, D., & Rosati, R. (2002). Description logics of minimal knowledge and
negation as failure. Transactions on Computational Logic, 3 (2), pp. 177225.
Freund, M. (1998). Preferential reasoning in the perspective of Poole default logic. Artificial
Intelligence, 98 (1-2), pp. 209235.
Gabbay, D. M., & Schlechta, K. (2009). Defeasible inheritance systems and reactive diagrams. Logic Journal of the IGPL, 17 (1), pp. 154.
Giordano, L., Gliozzi, V., Olivetti, N., & Pozzato, G. L. (2012a). A minimal model semantics
for nonmonotonic reasoning. In Proceedings of JELIA-12, Vol. 7519 of Lecture Notes
in Computer Science, pp. 228241. Springer.
Giordano, L., Gliozzi, V., Olivetti, N., & Pozzato, G. L. (2012b). A non-monotonic description logic for reasoning about typicality. Artificial Intelligence, 195, pp. 165202.
Giordano, L., Olivetti, N., Gliozzi, V., & Pozzato, G. L. (2009). ALC+T: a preferential
extension of description logics. Fundam. Inform., 96 (3), 341372.
Grimm, S., & Hitzler, P. (2009). A preferential tableaux calculus for circumscriptive ALCO.
In Proceedings of RR-09, pp. 4054. Springer-Verlag.
Horty, J. F. (1994). Some direct theories of nonmonotonic inheritance. In Handbook of
logic in artificial intelligence and logic programming: nonmonotonic reasoning and
uncertain reasoning, Vol. 3, pp. 111187. Oxford University Press.
Horty, J. F., & Thomason, R. H. (1990). Boolean extensions of inheritance networks. In
Proceedings of AAAI-90, pp. 633639. AAAI Press.
Horty, J. F., Thomason, R. H., & Touretzky, D. S. (1987). A skeptical theory of inheritance
in nonmonotonic semantic networks. In Proceedings of AAAI-87. AAAI Press.
Knorr, M., Alferes, J. J., & Hitzler, P. (2011). Local closed world reasoning with description
logics under the well-founded semantics. Artificial Intelligence, 175 (9-10), 15281554.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models and cumulative logics. Artificial Intelligence, 44 (1-2), pp. 167207.
Lehmann, D., & Magidor, M. (1992). What does a conditional knowledge base entail?.
Artificial Intelligence, 55 (1), pp. 160.
Lukasiewicz, T. (2008). Expressive probabilistic description logics. Artificial Intelligence,
172 (6-7), pp. 852883.
Makinson, D. (1994). General patterns in nonmonotonic reasoning. In Handbook of logic in
artificial intelligence and logic programming: nonmonotonic reasoning and uncertain
reasoning, Vol. 3, pp. 35110. Oxford University Press.
472

fiDefeasible Inheritance-Based Description Logics

Makinson, D. (2005). Bridges from Classical to Nonmonotonic Logic. Kings College Publications.
Makinson, D., & Schlechta, K. (1991). Floating conclusions and zombie paths. Artificial
Intelligence, 48, pp. 199209.
Poole, D. (1988). A logical framework for default reasoning. Artificial Intelligence, 36 (1),
2747.
Quantz, J., & Royer, V. (1992). A preference semantics for defaults in terminological logics.
In Proceedings of KR-92, pp. 294305.
Rott, H. (2001). Change, Choice and Inference: a study of belief revision and nonmonotonic
reasoning. Oxford University Press.
Sandewall, E. (1986). Nonmonotonic inference rules for multiple inheritance with exceptions.
In Proceedings of the IEEE-86, pp. 13451353.
Sandewall, E. (2010). Defeasible inheritance with doubt index and its axiomatic characterization. Artificial Intelligence, 18 (174), pp. 14311459.
Schlechta, K. (2004). Coherent Systems. Elsevier.
Shoham, Y. (1988). Reasoning about change: time and causation from the standpoint of
artificial intelligence. MIT Press.
Simonet, G. (1996). On sandewalls paper: Nonmonotonic inference rules for multiple inheritance with exceptions. Artificial Intelligence, 86, pp. 359374.
Straccia, U. (1993). Default inheritance reasoning in hybrid KL-ONE style logics. Proceedings of IJCAI-93, 676681.
Thomason, R. H. (1992). NETL and subsequent path-based inheritance theories. In
Lehmann, F. (Ed.), Semantic Networks in Artificial Intelligence, pp. 179204. Pergamon Press.
Touretzky, D. S. (1986). The mathematics of inheritance systems. Pitman.
Touretzky, D. S., Horty, J. F., & Thomason, R. H. (1987). A clash of intuitions: the current
state of nonmonotonic multiple inheritance systems. In Proceedings of IJCAI-87 Vol. 1, pp. 476482. Morgan Kaufmann Publishers.
Touretzky, D. S., Thomason, R. H., & Horty, J. F. (1991). A skeptics menagerie: conictors,
preemptors, reinstates, and zombies in nonmonotonic inheritance. In Proceedings of
IJCAI-91, pp. 478483. Morgan Kaufmann Publishers.

473

fiJournal of Artificial Intelligence Research 48 (2013) 253-303

Submitted 11/12; published 10/13

Optimizing SPARQL Query Answering over OWL Ontologies
Ilianna Kollia

ilianna2@mail.ntua.gr

University of Ulm, Germany and
National Technical University of Athens, Greece

Birte Glimm

birte.glimm@uni-ulm.de

University of Ulm, Germany

Abstract
The SPARQL query language is currently being extended by the World Wide Web
Consortium (W3C) with so-called entailment regimes. An entailment regime defines how
queries are evaluated under more expressive semantics than SPARQLs standard simple
entailment, which is based on subgraph matching. The queries are very expressive since
variables can occur within complex concepts and can also bind to concept or role names.
In this paper, we describe a sound and complete algorithm for the OWL Direct Semantics entailment regime. We further propose several novel optimizations such as strategies
for determining a good query execution order, query rewriting techniques, and show how
specialized OWL reasoning tasks and the concept and role hierarchy can be used to reduce
the query execution time. For determining a good execution order, we propose a cost-based
model, where the costs are based on information about the instances of concepts and roles
that are extracted from a model abstraction built by an OWL reasoner. We present two
ordering strategies: a static and a dynamic one. For the dynamic case, we improve the
performance by exploiting an individual clustering approach that allows for computing the
cost functions based on one individual sample from a cluster.
We provide a prototypical implementation and evaluate the efficiency of the proposed
optimizations. Our experimental study shows that the static ordering usually outperforms
the dynamic one when accurate statistics are available. This changes, however, when the
statistics are less accurate, e.g., due to nondeterministic reasoning decisions. For queries
that go beyond conjunctive instance queries we observe an improvement of up to three
orders of magnitude due to the proposed optimizations.

1. Introduction
Query answering is important in the context of the Semantic Web since it provides a mechanism via which users and applications can interact with ontologies and data. Several query
languages have been designed for this purpose, including RDQL (Seaborne, 2004), SeRQL
(Broekstra & Kampman, 2006) and, most recently, SPARQL. In this paper, we consider the
SPARQL query language (Prudhommeaux & Seaborne, 2008), which was standardized in
2008 by the World Wide Web Consortium (W3C) and which is currently being extended to
SPARQL 1.1 (Harris & Seaborne, 2013). Since 2008, SPARQL has developed into the main
query language for the Semantic Web and is now supported by most RDF triple stores.
The query evaluation mechanism defined in the SPARQL Query specification is based on
subgraph matching. This form of query evaluation is also called simple entailment since
it can equally be defined in terms of the simple entailment relation between RDF graphs
(Hayes, 2004). SPARQL 1.1 includes several entailment regimes (Glimm & Ogbuji, 2013)
c
2013
AI Access Foundation. All rights reserved.

fiKollia & Glimm

in order to use more elaborate entailment relations, such as those induced by RDF Schema
(RDFS) (Brickley & Guha, 2004) or OWL (Motik, Patel-Schneider, & Cuenca Grau, 2012b;
Schneider, 2012). Query answering under such entailment regimes is more complex as it
may involve retrieving answers that only follow implicitly from the queried graph, which is
seen as an OWL ontology when using OWL entailment. While several implementations for
SPARQLs RDFS entailment regime are available (e.g., Oracle 11g (Oracle, 2013), Apache
Jena (The Apache Software Foundation, 2013), or Stardog (Clark & Parsia, 2013b)), the
development of tools that provide full SPARQL support under OWL semantics is still an
ongoing effort.
Since we consider the OWL Direct Semantics entailment regime of SPARQL 1.1 in this
paper, when we talk about SPARQL queries or the evaluation of SPARQL queries, we
always assume that the OWL Direct Semantics entailment regime is used. In this setting,
the WHERE clause of a query can be seen as a set of extended OWL axioms (an extended
OWL ontology), which can have variables in place of concept, role or individual names.
The query answers contain each instantiation of the variables that leads to OWL axioms
that are entailed by the queried ontology. Thus, a naive query evaluation procedure can be
realized through OWLs standard reasoning task of entailment checking.
Please note that there are two types of individual variables in SPARQL; standard (distinguished) variables and anonymous individuals (aka blank nodes). The anonymous individuals are treated like distinguished variables with the difference that they cannot be
selected and, hence, their bindings cannot appear in the query answer. This is in contrast to
conjunctive queries, where anonymous individuals are treated as existential variables. On
the other hand, anonymous individuals can occur in the query answer as bindings to distinguished variables, i.e., SPARQL treats anonymous individuals from the queried ontology as
constants. This treatment of anonymous individuals has been chosen for compatibility with
SPARQLs standard subgraph matching semantics. For example, in order to implement
the RDF(S) entailment regime, systems can simply extend the queried graph with inferred
information (materialization) and can then use SPARQLs standard evaluation mechanism
over the materialized graph in order to compute the query results. Similarly, when users
move on to systems that support the OWL RL profile (Motik, Cuenca Grau, Horrocks, Wu,
Fokoue, & Lutz, 2012a), the OWL RL rule set from the OWL 2 specification can be used to
compute the query answers (again via materialization). If one were to change the semantics
of blank nodes for SPARQLs entailment regimes to reflect conjunctive query semantics, one
could no longer use materialization plus a standard SPARQL query processor to implement
the entailment regime. If one were to change the semantics of blank nodes only for the
OWL Direct Semantics entailment regime, where materialization cannot be used to implement the regime, users would not simply get more answers by moving from systems that
support RDF(S) to systems that support OWLs Direct Semantics, but it could also happen
that they get less answers by using a more expressive logic, which is counter-intuitive.
Over the last decade, much effort has been spent on optimizing standard reasoning tasks
such as entailment checking, classification, or realization (i.e., the computation of instances
of all concepts and roles) (Sirin, Cuenca Grau, & Parsia, 2006; Tsarkov, Horrocks, & PatelSchneider, 2007; Glimm, Horrocks, Motik, Shearer, & Stoilos, 2012). The optimization of
query answering algorithms has, however, mostly been addressed for conjunctive queries in
OWL profiles, most notably the OWL 2 QL profile (Calvanese, Giacomo, Lembo, Lenzerini,
254

fiOptimizing SPARQL Query Answering over OWL Ontologies

& Rosati, 2007; Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2010; Perez-Urbina,
Motik, & Horrocks, 2010; Rodriguez-Muro & Calvanese, 2012). An exception to this are
the works on nRQL and SPARQL-DL. The query language nRQL is supported by Racer
Pro (Haarslev, Moller, & Wessel, 2004) and SPARQL-DL is implemented in the Pellet
reasoner (Sirin, Parsia, Grau, Kalyanpur, & Katz, 2007). We discuss this in greater detail
in Section 8.
In this paper, we address the problem of efficient SPARQL query evaluation for OWL 2
DL ontologies by proposing a range of novel optimizations that deal in particular with the
expressive features of SPARQL such as variables in place of concepts or roles. We further
adapt common techniques from databases such as cost-based query planning. The costs
for our cost model are based on information about the instances of concepts and roles
that are extracted from a model abstraction built by an OWL reasoner. We present a
static and a dynamic algorithm for finding an optimal or near optimal execution order and
for the dynamic case, we improve the performance by exploiting an individual clustering
approach that allows for computing the cost functions based on one individual sample from
a cluster. We further propose query rewriting techniques and show how specialized OWL
reasoning tasks and the concept and role hierarchy can be used to reduce the query execution
time. We provide a prototypical implementation and evaluate the efficiency of the proposed
optimizations. Our experimental study shows that the static ordering usually outperforms
the dynamic one when accurate statistics are available. This changes, however, when the
statistics are less accurate, e.g., due to non-deterministic reasoning decisions. For queries
that go beyond conjunctive SPARQL instance queries, we observe an improvement of up to
three orders of magnitude due to the proposed optimizations.
Note that this paper combines and extends two conference papers: I. Kollia and B.
Glimm: Cost based Query Ordering over OWL Ontologies. Proceedings of the 11th International Semantic Web Conference, 2012 and I. Kollia, B. Glimm and I. Horrocks: SPARQL
Query Answering over OWL Ontologies. Proceedings of the 8th Extended Semantic Web
Conference, 2011. In the current paper we have, additionally to the first above mentioned
paper, defined cost functions for general SPARQL queries (i.e., not only for conjunctive instance queries) and added experimental results for these expressive queries. In comparison
to the second of the above mentioned papers, we have defined the notion of concept and role
polarity and presented theorems that let us prune the search space of possible mappings for
axiom templates based on the polarity together with an algorithm that shows the way we
use the optimization. Moreover, more experimental results have been added for complex
queries that make use of this optimization.
The remainder of the paper is organized as follows: we next present some preliminaries,
we then present a general query evaluation algorithm in Section 3 that serves as the basis
for further optimization. In Section 4, we present the foundations for our cost model, which
we then specify in Section 5. In Section 6, we present optimizations for complex queries that
cannot directly be mapped to specialized reasoner tasks. Finally, we evaluate our approach
in Section 7 and discuss related work in Section 8 before we conclude in Section 9.

255

fiKollia & Glimm

2. Preliminaries
In this section, we first give a brief introduction into Description Logics since the OWL
Direct Semantics is based on the Description Logic SROIQ (Horrocks, Kutz, & Sattler,
2006). The optimizations we present do not need all features of SROIQ. Hence, we only
present SHOIQ, which allows for a shorter and easier to follow presentation.
After introducing SHOIQ, we clarify the relationship between RDF, SPARQL and
OWL, we present SPARQLs OWL Direct Semantics entailment regime and we give an
overview of the model building tableau and hypertableau calculi.
2.1 The Description Logic SHOIQ
We first define the syntax and semantics of roles, and then go on to SHOIQ-concepts,
individuals, and ontologies/knowledge bases.
Definition 1 (Syntax of SHOIQ ). Let NC , NR , and NI be countable, infinite, and
pairwise disjoint sets of concept names, role names, and individual names, respectively.
We call S = (NC , NR , NI ) a signature. The set rol(S) of SHOIQ-roles over S (or roles
for short) is NR  {r  | r  NR }  {r , r }, where roles of the form r  are called inverse
roles, r is the top role (analogous to owl:topObjectProperty), and r is the bottom role
(analogous to owl:bottomObjectProperty). A role inclusion axiom is of the form r  s with
r, s roles. A transitivity axiom is of the form trans(r) for r a role. A role hierarchy H is a
finite set of role inclusion and transitivity axioms.
For a role hierarchy H, we define the function inv over roles as inv(r) := r  if r  NR
and inv(r) := s if r = s for a role name s  NR . Further, we define H as the smallest
transitive reflexive relation on roles such that r  s  H implies r H s and inv(r) H
inv(s). We write r H s if r H s and s H r. A role r is transitive w.r.t. H (notation
r + H r) if a role s exists such that r H s, s H r, and trans(s)  H or trans(inv(s))  H.
A role s is called simple w.r.t. H if there is no role r such that r is transitive w.r.t. H and
r H s.
Given a signature S = (NC , NR , NI ) and a role hierarchy H, the set of SHOIQconcepts (or concepts for short) over S is the smallest set built inductively over symbols
from S using the following grammar, where o  NI , A  NC , n  IN0 , s is a simple role
w.r.t. H, and r is a role w.r.t. H:
C ::=  |  | {o} | A | C | C  C | C  C | r.C | r.C | 6 n s.C | > n s.C.
We now define the semantics of SHOIQ concepts:
Definition 2 (Semantics of SHOIQ-concepts). An interpretation I = (I , I ) consists
of a non-empty set I , the domain of I, and a function I , which maps every concept name
A  NC to a subset AI  I , every role name r  NR to a binary relation r I  I  I ,
and every individual name a  NI to an element aI  I . The top role r is interpreted
as {h,  i | ,   I } and the bottom role r as . For each role name r  NR , the
I
interpretation of its inverse role (r  ) consists of all pairs h,  i  I  I for which
h , i  r I .
256

fiOptimizing SPARQL Query Answering over OWL Ontologies

The semantics of SHOIQ-concepts over a signature S is defined as follows:
I
(C)I
(r.C)I
(r.C)I
(6 n s.C)I
(> n s.C)I

=
=
=
=
=
=

I
I \ C I
{  I
{  I
{  I
{  I

I = 
({o})I = {oI }
I
I
I
(C  D) = C  D
(C  D)I = C I  D I

I

I
| if h,  i  r , then   C }
| there is a h,  i  r I with   C I }
| (sI (, C))  n}
| (sI (, C))  n}

where (M ) denotes the cardinality of the set M and sI (, C) is defined as
{  I | h,  i  sI and   C I }.
Definition 3 (Syntax and Semantics of Axioms and Ontologies, Entailment). For
C, D concepts, a (general) concept inclusion axiom (GCI) is an expression C  D. We
introduce C  D as an abbreviation for C  D and D  C. A finite set of GCIs is called
a TBox. An (ABox) (concept or role) assertion axiom is an expression of the form C(a),
r(a, b), r(a, b), a  b, or a 6 b, where C  NC is a concept, r  NR is a role, and a, b  NI
are individual names. An ABox is a finite set of assertion axioms. An ontology O is a
triple (T , H, A) with T a TBox, H a role hierarchy, and A an ABox. We use NCO , NRO ,
and NIO to denote, respectively, the set of concept, role, and individual names occurring in
O.
Let I = (I , I ) be an interpretation. Then I satisfies a role inclusion axiom r  s
if r I  sI , I satisfies a transitivity axiom trans(r) if r I is a transitive binary relation,
and a role hierarchy H if it satisfies all role inclusion and transitivity axioms in H. The
interpretation I satisfies a GCI C  D if C I  D I ; and I satisfies a TBox T if it satisfies
each GCI in T . The interpretation I satisfies an assertion axiom C(a) if aI  C I , r(a, b)
if haI , bI i  r I , r(a, b) if haI , bI i 
/ r I , a  b if aI = bI , and a 6 b if aI 6= bI ; I satisfies
an ABox if it satisfies each assertion in A. We say that I satisfies O if I satisfies T , H,
and A. In this case, we say that I is a model of O and write I |= O. We say that O is
consistent if O has a model.
Given an axiom , we say that O entails  (written O |= ) if every model I of O
satisfies .
Description Logics can further be extended with concrete domains, which correspond to
OWLs datatypes. In such a case, one distinguishes between abstract roles that relate two
individuals and concrete roles that relate an individual with a data value. The Description
Logic SROIQ further allows for a number of features such as role chains of the form
hasFather  hasBrother  hasUncle, support for the special concept Self, which can be
used in axioms of the form Narcissist  loves.Self, or for defining roles that are reflexive,
irreflexive, symmetric, or asymmetric.
Description Logic ontologies can equally be expressed in terms of OWL ontologies, which
in turn can be mapped into RDF graphs (Patel-Schneider & Motik, 2012). The other direction is, however, not always possible, i.e., a mapping from RDF graphs to OWL ontologies is
only defined for certain well-formed RDF graphs that correspond to an OWL 2 DL ontology.
257

fiKollia & Glimm

2.2 The Relationship between RDF, SPARQL, and OWL
SPARQL queries are evaluated over RDF graphs which remain the basic data structure
even when adopting a more elaborate semantic interpretation.
Definition 4 (RDF Graphs). RDF is based on the set I of International Resource
Identifiers (IRIs), the set L of RDF literals, and the set B of blank nodes. The set
T of RDF terms is I  L  B. An RDF graph is a set of RDF triples of the form
(subject, predicate, object)  (I  B)  I  T .
We generally abbreviate IRIs using prefixes rdf, rdfs, owl, and xsd to refer to the RDF,
RDFS, OWL, and XML Schema Datatypes namespaces, respectively. The empty prefix is
used for an imaginary example namespace, which we completely omit in Description Logic
syntax.
An example of a SPARQL query is
SELECT ?x FROM <ontologyIRI> WHERE { ?x rdf:type :C . ?x :r ?y }
The WHERE clause of the SPARQL query consists of a basic graph pattern (BGP): an
RDF graph written in Turtle syntax (Beckett, Berners-Lee, Prudhommeaux, & Carothers,
2013), where some nodes or edges are replaced by variables. A basic graph pattern is more
precisely defined as follows:
Definition 5 (Basic Graph Pattern). Let V be a countably infinite set of query variables
disjoint from T . A triple pattern is a member of the set (T  V )  (I  V )  (T  V ), and
a basic graph pattern (BGP) is a set of triple patterns.
We do not recall the complete surface syntax of SPARQL here since the only part
that is specific to the evaluation of SPARQL queries under OWLs Direct Semantics is
the evaluation of BGPs. More complex WHERE clauses, which use operators such as
UNION for alternative selection criteria or OPTIONAL to query for optional bindings
(Prudhommeaux & Seaborne, 2008), can be evaluated simply by combining the results
obtained by the BGP evaluation. Similarly, operations such as the projection of variables
from the SELECT clause is a straightforward operation over the results of the evaluation of
the WHERE clause. Therefore, we focus here on BGP evaluation only. For a more detailed
introduction to SPARQL queries and their algebra we refer interested readers to the work
of Hitzler, Krotzsch, and Rudolph (2009) or Glimm and Krotzsch (2010).
Since the Direct Semantics of OWL is defined in terms of OWL structural objects, i.e.,
OWL axioms, we map the BGPs of SPARQL queries into structural objects, which can have
variables in place of class (concept), object or data property (abstract or concrete role), or
individual names or literals. Since there is a direct mapping between OWL axioms and
Description Logic axioms, BGPs can be expressed as Description Logic axioms in which
variables can occur in place of concept, role and individual names. For example, the BGP
of the previous example is mapped to ClassAssertion(C ?x) and ObjectPropertyAssertion(r
?x ?y) in functional-style syntax or to C(?x) and r(?x, ?y) in Description Logic syntax.
For further details, we refer interested readers to the W3C specification that defines
the mapping between OWL structural objects and RDF graphs (Patel-Schneider & Motik,
2012) and to the specification of the OWL Direct Semantics entailment regime of SPARQL
258

fiOptimizing SPARQL Query Answering over OWL Ontologies

(Glimm & Ogbuji, 2013) that defines the extension of this mapping between BGPs and
OWL objects with variables.
2.3 SPARQL Queries
In the following, we directly write BGPs in Description Logic notation extended to allow for variables in place of concept, role and individual names in axioms. It is worth
reminding that SPARQL does not support existentially quantified variables, which is in
contrast to database-style conjunctive queries, where one typically also has existential/nondistinguished variables.
For brevity and without loss of generality, we assume here that neither the query nor
the queried ontology contains anonymous individuals. We further do not consider data
properties and literals, but the presented optimizations can easily be transferred to this
case.
Definition 6 (Query). Let S = (NC , NR , NI ) be a signature. A query signature Sq w.r.t.
S is a six-tuple (NC , NR , NI , VC , VR , VI ), where VC , VR , and VI are countable, infinite,
and pairwise disjoint sets of concept variables, role variables, and individual variables
disjoint from NC , NR , and NI . A concept term is an element from NC  VC . A role term
is an element from NR  VR . An individual term is an element from NI  VI . An axiom
template over Sq is a SROIQ axiom over S, where one can also use concept variables from
VC in place of concept names, role variables from VR in place of role names, and individual
variables from VI in place of individual names. A query q w.r.t. a query signature Sq is a
non-empty set of axiom templates over Sq . We use Vars(q) (Vars(at) for an axiom template
at) to denote the set of all variables in q (at) and |q| to denote the number of axiom templates
in q. Let t, t be individual terms; we call axiom templates of the form A(t) with A  NC ,
r(t, t ) with r  NR , or t  t query atoms. A conjunctive instance query q w.r.t. a query
signature Sq is a non-empty set of query atoms.
For a function , we use dom() to denote the domain of . Let O be an ontology over
S and q = {at1 , . . . , atn } a query over Sq consisting of n axiom templates. A mapping 
for q over O is a total function  : Vars(q)  NCO  NRO  NIO such that
1. (v)  NCO for each v  VC  dom(),
2. (v)  NRO for each v  VR  dom(),
3. (v)  NIO for each v  VI  dom(), and
4. O  (q) is a SROIQ ontology.
We write (q) ((at)) to denote the result of replacing each variable v in q (at) with
O
(v). The set O
q of the compatible mappings for q over O is defined as q := { |
 is a mapping for q over O}. A mapping  is a solution mapping or a certain answer for
q over O if O |= (q). We denote the set containing all solution mappings for q over O
with O
q . The result size or the number of answers of a query q over O is given by the
cardinality of the set O
q .
Note that the last condition in the definition of mappings is required to ensure decidability of query entailment. For example, without the condition, a reasoner might have to
259

fiKollia & Glimm

test instantiated axiom templates where a role variable has been replaced by a non-simple
role in a number restriction, which is not allowed in Description Logic axioms. Note also
that we do not indicate which variables are to be selected since we do not consider the
straightforward task of projection here.
Examples of queries according to the above definition are the following (where ?x is a
concept variable, ?y a role variable, and ?z an individual variable):
C  ?y.?x
(r.?x)(?z)
In the remainder, we use S for a signature (NC , NR , NI ), O to denote a SROIQ ontology
over S, A, B  NC for concept names from O, r, s  NR for role names from O, a, b  NI
for individual names from O, ?x, ?y for variables, c1 , c2 for concept terms, r1 , r2 for role
terms, t, t for individual terms, q = {at1 , . . . , atn } for a query with n axiom templates over
the query signature Sq = (NC , NR , NI , VC , VR , VI ), O
q for the compatible mappings and
O
for
the
solution
mappings
of
q
over
O.
q
2.4 Model-building (Hyper)Tableau Calculi
In this section, we give a brief overview over the main reasoning techniques for OWL DL
ontologies since our cost-based query planning relies on these techniques.
In order to check whether an ontology O entails an axiom , one typically checks whether
O  {} has a model. If that is not the case, then every model of O satisfies  and
O |= . For example, to check whether an individual a0 is an instance of a concept C
w.r.t. an ontology O, we check whether adding the concept assertion C(a0 ) to O leads
to an inconsistency. To check this, most OWL reasoners use a model construction calculus
such as tableau or hypertableau. In the remainder, we focus on the hypertableau calculus
(Motik, Shearer, & Horrocks, 2009), but a tableau calculus could equally be used and we
state how our results can be transferred to tableau calculi.
The hypertableau calculus starts from the initial set of ABox assertions and, by applying
derivation rules, it tries to construct (an abstraction of) a model of O. Derivation rules
usually add new concept or role assertion axioms, they may introduce new individuals, they
can be nondeterministic, leading to the need to choose between several alternative assertion
axioms to add or they can lead to a clash when a contradiction is detected. To show that
an ontology O is (in)consistent, the hypertableau calculus constructs a derivation, i.e., a
sequence of sets of assertions A0 , . . . , An , such that A0 contains all ABox assertions in O,
Ai+1 is the result of applying a derivation rule to Ai and An is the final set of assertions
where no more rules are applicable. If a derivation exists such that An does not contain a
clash, then O is consistent and An is called a pre-model of O. Otherwise O is inconsistent.
Each assertion in a set of assertions Ai is derived either deterministically or nondeterministically. An assertion is derived deterministically if it is derived by the application of a
deterministic derivation rule from assertions that were all derived deterministically. Any
other derived assertion is derived nondeterministically. It is easy to know whether an assertion was derived deterministically or not because of the dependency directed backtracking
that most (hyper)tableau reasoners employ. In the pre-model, each individual s0 is assigned
a label L(s0 ) representing the concepts it is (non)deterministically an instance of and each
260

fiOptimizing SPARQL Query Answering over OWL Ontologies

pair of individuals hs0 , s1 i is assigned a label L(hs0 , s1 i) representing the roles through which
individual s0 is (non)deterministically related to individual s1 .

3. Motivation
A straightforward algorithm to compute the answers for a query q is to test, for each
mapping , whether O |= (q). Since only terms that are used in O can occur in the range
of a mapping  for q over O, there are finitely many mappings to test. In the worst case,
however, the number of mappings that have to be tested is still exponential in the number
of variables in the query. Such an algorithm is sound and complete if the reasoner used to
decide entailment is sound and complete since we check all mappings for variables that can
constitute actual solution mappings.
Optimizations cannot easily be integrated into the above sketched algorithm since it uses
the reasoner to check for the entailment of the instantiated query as a whole and, hence,
does not take advantage of relations or dependencies that may exist between the individual
axiom templates in q. For a more optimized evaluation, one can evaluate the query axiom
template by axiom template. Initially, the solution set contains only the identity mapping,
which does not map any variable to a value. One then picks the first axiom template,
extends the identity mapping to cover the variables of the chosen axiom template and then
uses a reasoner to check which of the mappings instantiate the axiom template into an
entailed axiom. One then picks the next axiom template and again extends the mappings
from the previous round to cover all variables and checks which of those mappings lead to
an entailed axiom. Thus, axiom templates which are very selective and are only satisfied by
very few solutions reduce the number of intermediate solutions. Choosing a good execution
order, therefore, can significantly affect the performance.
For example, let q = {A(?x), r(?x, ?y)} with ?x, ?y  VI . The query belongs to the
class of conjunctive instance queries. We assume that the queried ontology contains 100
individuals, only 1 of which belongs to the concept A. This A instance has 1 r-successor,
while we have overall 200 pairs of individuals related with the role r. If we first evaluate
A(?x), we test 100 mappings (since ?x is an individual variable), of which only 1 mapping
satisfies the axiom template. We then evaluate r(?x, ?y) by extending the mapping with
all 100 possible mappings for ?y. Again only 1 mapping yields a solution. For the reverse
axiom template order, the first axiom template requires the test of 100  100 mappings. Out
of those, 200 remain to be checked for the second axiom template and we perform 10, 200
tests instead of just 200. Note also that the number of intermediate results when the query
is evaluated in the order A(?x), r(?x, ?y) is smaller than when it is evaluated in the reverse
order (2 versus 201).
In the context of databases or triple stores, cost-based ordering techniques for finding an
optimal or near optimal join ordering have been widely applied (Steinbrunn, Moerkotte, &
Kemper, 1997; Stocker, Seaborne, Bernstein, Kiefer, & Reynolds, 2008). These techniques
involve the maintenance of a set of statistics about relations and indexes, e.g., number of
pages in a relation, number of pages in an index, number of distinct values in a column,
together with formulas for the estimation of the selectivity of predicates and the estimation
of the CPU and I/O costs of query execution that depends amongst others, on the number
of pages that have to be read from or written to secondary memory. The formulas for the
261

fiKollia & Glimm

estimation of selectivities of predicates (result output size of axiom templates) estimate
the data distributions using histograms (Ioannidis & Christodoulakis, 1993), parametric
or sampling methods or combinations of them. Ordering strategies as implemented in
databases or triple stores are, however, not directly applicable in our setting. In the presence
of expressive schema level axioms, we cannot rely on counting the number of occurrences of
triples. We also cannot, in general, precompute all relevant inferences to base our statistics
on materialized inferences. Furthermore, we should not only aim at decreasing the number
of intermediate results, but also take into account the cost of checking or computing the
solutions. This cost can be very significant with OWL reasoning and its precise estimation
before query evaluation is difficult as this cost takes values from a wide range, e.g., due to
nondeterminism and the high worst-case complexity of the standard reasoning tasks.1
For several kinds of axiom templates we can, however, directly retrieve the solutions
from the reasoner instead of checking entailment. For example, for C(?x), reasoners typically have a method to retrieve concept instances. Although this might internally trigger
several tests, most methods of reasoners are highly optimized and avoid as many tests as
possible. Furthermore, reasoners typically cache several results such as the computed concept hierarchy and retrieving sub-concepts can then be realized with a cache lookup. Thus,
the actual execution cost might vary significantly. Notably, we do not have a straight correlation between the number of results for an axiom template and the actual cost of retrieving
the solutions as is typically the case in triple stores or databases. This requires cost models
that take into account the cost of the specific reasoning operations (depending on the state
of the reasoner) as well as the number of results.
As motivated above, we distinguish between simple and complex axiom templates. Simple axiom templates are those that correspond to dedicated reasoning tasks. Let c1 be a
concept term, C, C  (complex) concepts or concept variables, r1 , r2 role terms or role inverses and t, t individual terms. The set of simple axiom templates contains templates of
the form: C  C  , r1 .  c1 (domain restriction template),   r1 .c1 (range restriction
template), r1  r2 , C(t), r1 (t, t ), t  t , t 6 t . Complex axiom templates can, in contrast, not be evaluated by dedicated reasoning tasks and might require iterating over the
compatible mappings and by checking entailment for each instantiated axiom template. An
example of a complex axiom template is (r.?x)(?y).

4. Preprocessing for Extracting Information for Queries
In this section, we describe a way of preprocessing the queried ontology to extract information that is useful for ordering the axiom templates in a query. This preprocessing is useful
for axiom templates of the form c1 (t), r1 (t, t ), or t  t , where c1 is a concept term, r1 is a
role term and t, t are individual terms.
4.1 Extracting Individual Information from Reasoner Models
The first step in the ordering of query atoms is the extraction of statistics by exploiting
information generated by reasoners. We use the labels of an initial pre-model to pro1. For example, the description logic SROIQ, which underpins the OWL 2 DL standard, has a worst case
complexity of 2-NExpTime (Kazakov, 2008) and typical implementations are not worst case optimal.

262

fiOptimizing SPARQL Query Answering over OWL Ontologies

Algorithm 1 initializeKnownAndPossibleConceptInstances(O)
Input: a consistent SROIQ ontology O
1: An := buildM odelF or(O)
2: for all a  NIO do
3:
for all C  LAn (a) do
4:
if C was derived deterministically then
5:
K[C] := K[C]  {a}
6:
else
7:
P [C] := P [C]  {a}
8:
end if
9:
end for
10: end for
vide information about the concepts the individuals belong to or the roles with which one
individual is connected to another one. We exploit this information similarly as was suggested for determining known or possible (non-)subsumers for concepts during classification
(Glimm et al., 2012). In the hypertableau calculus, the following two properties hold for
each ontology O and each constructed pre-model An for O:
(P1) for each concept name C (role name r), each individual s0 (pair of individuals hs1 , s2 i)
in An , if C  LAn (s0 ) (r  LAn (hs1 , s2 i)) and the assertion C(s0 ) (r(s1 , s2 )) was
derived deterministically, then it holds O |= C(s0 ) (O |= r(s1 , s2 )).
(P2) for an arbitrary individual s0 in An (pair of individuals hs1 , s2 i in An ) and an arbitrary
concept name C (simple role name r), if C 6 LAn (s0 ) (r 6 LAn (hs1 , s2 i)), then
O 6|= C(s0 ) (O 6|= r(s1 , s2 )).
For simplicity, we assume here that equality () is axiomatized and  is treated as a
reflexive, symmetric, and transitive role. We use these properties to extract information
from the pre-model of a satisfiable ontology O.
Definition 7 (Known and Possible Instances). Let An be a pre-model for an ontology
O. An individual a is a known (possible) instance of a concept name C in An , denoted
a  KAn [C] (a  PAn [C]), if C  LAn (a) and C(a) is derived deterministically (nondeterministically) in An . A pair of individuals ha1 , a2 i is a known (possible) instance of a simple
role name r in An , denoted ha1 , a2 i  KAn (r), if r  LAn (ha1 , a2 i) and r(a1 , a2 ) is derived
deterministically (nondeterministically) in An . The individual a1 is (possibly) equal to the
individual a2 , written a1  K [a2 ] and a2  K [a1 ] (a1  P [a2 ] and a2  P [a1 ]) if
a1  a2 has been deterministically (nondeterministically) derived in O.
In the remainder, we assume that the known and possible instances are defined w.r.t.
some arbitrary pre-model An for O and we simply write K[C], K[r], K [a], P [C], P [r],
and P [a]. Intuitively, K[C] contains individuals that can safely be considered instances of
the concept name C. On the other hand, the possible instances require costly consistency
checks in order to decide whether they are real instances of the concept, while individuals
that neither belong to K[C] nor P [C] can safely be assumed to be non-instances of C.
263

fiKollia & Glimm

Algorithm 1 outlines a procedure to initialize the relations for known and possible concept instances. The information we extract involves the maintenance of the sets of known
and possible instances for all concepts of O. One can define a similar algorithm for initializing the known and possible instances of simple roles and for (possibly) equal individuals.
In our implementation, we use a more involved procedure to only store the direct types of
each individual, where a concept name C is a direct type of an individual a in an ontology
O if O |= C(a) and there is no concept name D such that O |= D  C, O |= D(a) and
O 6|= D  C.
Hypertableau and tableau reasoners typically do not deal with transitivity directly. In
order to deal with non-simple roles, O is expanded with additional axioms that capture
the semantics of the transitive relations before a pre-model is built. In particular, for each
individual a and non-simple role r, new concepts Ca and Car are introduced and the axioms
Ca (a) and Ca  r.Car are added to O. The consequent application of the transitivity
encoding (Motik et al., 2009) produces axioms that propagate Car to each individual b that
is reachable from a via an r-chain. The known and possible r-successors for a can then be
determined from the Car instances.
The technique presented in this paper can be used with any (hyper)tableau calculus for
which properties (P1) and (P2) hold. All (hyper)tableau calculi used in practice that we are
aware of satisfy property (P1). Pre-models produced by tableau algorithms as presented
in the literature also satisfy property (P2); however, commonly used optimizations, such
as lazy unfolding, can compromise property (P2), which we illustrate with the following
example. Let us assume we have an ontology O containing the axioms
A  r.(C  D)

(1)

B  r.C

(2)

A(a)

(3)

It is obvious that in this ontology A is a subconcept of B (hence, O |= B(a)) since every
individual that is r-related to an individual that is an instance of the intersection of C
and D is also r-related to an individual that is an instance of the concept C. However,
even though the assertion A(a) occurs in the ABox, the assertion B(a) is not added in the
pre-model when we use lazy unfolding. With lazy unfolding, instead of treating (2) as two
disjunctions B  r.C and B  r.(C) as is typically done for general concept inclusion
axioms, B is only lazily unfolded into its definition r.C once B occurs in the label of an
individual. Thus, although (r.(C  D))(a) would be derived, this does not lead to the
addition of B(a).
Nevertheless, most (if not all) implemented calculi produce pre-models that satisfy at
least the following weaker property:
(P3) for an arbitrary individual s0 in An and an arbitrary concept name C where C is
primitive in O,2 if C 6 LAn (s0 ), then O 6|= C(s0 ).
Hence, properties (P2) and (P3) can be used to extract (non-)instance information from
pre-models. For tableau calculi that only satisfy (P3), for each non-primitive concept name
2. A concept C is considered primitive in O if O is unfoldable (Tsarkov et al., 2007) and it contains no
axiom of the form C  E

264

fiOptimizing SPARQL Query Answering over OWL Ontologies

C in O we need to add to P [C] the individuals in O that do not include the concept C in
their label.
The proposed technique for determining known and possible instances of concept and
role names can be used in the same way with both tableau and hypertableau reasoners.
Since tableau algorithms often introduce more nondeterminism than hypertableau, one
might, however, find less deterministic derivations, which results in less accurate statistics.
4.1.1 Individual Clustering
In this section, we describe the procedure for creating clusters of individuals within an
ontology O using a constructed pre-model An of O. Two types of clusters are created:
concept clusters and role clusters. Concept clusters contain individuals having the same
concepts in their label and role clusters contain individuals with the same concept and role
labels. Role clusters are divided into three categories, those that are based on the first
individual of role instances, those based on the second individual and those based on both
individuals.
Definition 8 (Concept and Role Clusters). Let O be an ontology and An a pre-model
for O. We define the following two relations P1 and P2 that map an individual a from O
to the roles for which a has at least one successor or predecessor, respectively:
P1 (a) = {r | r  LAn (ha, bi) for some b  NIO }
P2 (a) = {r | r  LAn (hb, ai) for some b  NIO }
Based on these relations, we build three different partitions over NIO : concept clusters CC,
role successor clusters P C1 , and role predecessor clusters P C2 such that the clusters satisfy:
for each C  CC.(for each a1 , a2  C.(LAn (a1 ) = LAn (a2 )))
for each C  P C1 .(for each a1 , a2  C.(LAn (a1 ) = LAn (a2 ) and P1 (a1 ) = P1 (a2 )))
for each C  P C2 .(for each a1 , a2  C.(LAn (a1 ) = LAn (a2 ) and P2 (a1 ) = P2 (a2 ))).
We further partition NIO  NIO into role clusters P C12 such that the clusters satisfy:
for each C  P C12 .(for each ha1 , a2 i, ha3 , a4 i  C.(LAn (a1 ) = LAn (a3 ), LAn (a2 ) = LAn (a4 )
and LAn (ha1 , a2 i) = LAn (ha3 , a4 i))).
We use these clusters in the next section to optimize the dynamic query ordering strategy.

5. Query Answering and Axiom Template Ordering
In this section, we describe two different algorithms (a static and a dynamic one) for ordering
the axiom templates of a query based on some costs and then we deal with the formulation
of these costs. We first introduce the abstract graph representation of a query q by means
of a labeled graph Gq on which we define the computed statistical costs.
Definition 9 (Query Join Graph). A query join graph Gq for a query q is a tuple
(V, E, EL ), where
265

fiKollia & Glimm

 V = q is a set of vertices (one for each axiom template);
 E  V  V is a set of edges; such that hat1 , at2 i  E if Vars(at1 )  Vars(at2 ) 6=  and
at1 6= at2 ;
 EL is a function that assigns a set of variables to each hat1 , at2 i  E such that
EL (at1 , at2 ) = Vars(at1 )  Vars(at2 ).
In the remainder, we use Gq for the query join graph of q.
Our goal is to find a query execution plan, which determines the evaluation order for
axiom templates in q. Since the number of possible execution plans is of order |q|!, the
ordering task quickly becomes impractical. In the following, we focus on greedy algorithms
for determining an execution order, which prune the search space considerably. Roughly
speaking, we proceed as follows: We define a cost function, which consists of two components
(i) an estimate for the costs of the reasoning tasks needed for the evaluation of an axiom
template and (ii) an estimate for the intermediate result size, i.e., the number of results
that the evaluation of an axiom template will incur. Both components are combined to
induce an order among axiom templates. In this paper, we simply build the sum of the
two cost components, but different combinations such as a weighted sum of the two values
could also be used. For the query plan construction we distinguish static from dynamic
planning. For the former, we start constructing the plan by adding a minimal template
according to the order. Variables from this template are then considered bound, which
changes the cost function and might induce a different order among the remaining axiom
templates. Considering the updated order, we again select the minimal axiom template that
is not yet in the plan and update the costs. This process continues until the plan contains
all templates. Once a complete plan has been determined the templates are evaluated.
The dynamic case differs in that after selecting a template for the plan, we immediately
determine the solutions for the chosen template, which are then used to update the cost
function. While this yields accurate cost estimates, it can be very costly when all solutions
are considered for updating the cost function. Sampling techniques can be used to only test
a subset of the solutions, but we show in Section 7 that random sampling, i.e., randomly
choosing a percentage of the individuals from the so far computed solutions, is not adequate.
For this reason, we propose an alternative sampling approach that is based on the use of the
previously described individual clusters. We first present an example to make the difference
between static and dynamic planning clearer and justify why dynamic ordering can be
beneficial in our setting.
Example 1. Let O be an ontology and q = {C(?x), r(?x, ?y), D(?y)} a conjunctive instance
query over O. Suppose that for the known and possible instances of the query concepts and
roles we have
K[C] = {a}

K[r] = 

K[D] = {b}

P [C] = {c, e}

P [r] = {hc, di, he, f i}

P [D] = {f, g, h}

And let us assume that the possible instances of C, D and r are, in fact, real instances (note
that we do not have this information from the beginning). Please have in mind that the
possible instances of concepts or roles are more costly to evaluate than the known instances
266

fiOptimizing SPARQL Query Answering over OWL Ontologies

since they require expensive consistency checks in order to decide whether they are real
instances.
According to static planning, an ordering for query atoms is first determined. In particular, the atom r(?x, ?y) is chosen first since it has the least number of known and possible instances (0 known and 2 possible versus 1 known and 2 possible for C(?x) and
1 known and 3 possible for D(?y)). Then the atom C(?x) is chosen since it has less
known and possible instances than D(?y), i.e., 1 known and 2 possible versus 1 known
and 3 possible for D(?y). Hence the chosen execution plan in static planning is P =
(r(?x, ?y), C(?x), D(?y)). Afterwards, the query is evaluated according to the chosen execution plan, i.e., the atom r(?x, ?y) is evaluated first, which gives the solution mappings
1 = {{?x 7 c, ?y 7 d}, {?x 7 e, ?y 7 f }}. This requires 2 consistency checks for the 2
possible instances of r. Afterwards, we check which of the ?x mappings, c and e, are known
or possible instances of C. Since both c and e are possible instances, we check whether they
are real instances of C (this requires 2 consistency checks). Hence, the solution mappings
are 2 = 1 = {{?x 7 c, ?y 7 d}, {?x 7 e, ?y 7 f }}. In the end, we check which of
the ?y mappings, d and f , are known or possible instances of D. For the only possible
instance, f , we find after one consistency check that f is indeed an instance of D. Hence,
the solution mappings for q are O
q = {{?x 7 e, ?y 7 f }} and finding the solution required
5 consistency checks.
According to dynamic planning, an ordering is determined while we evaluate the query.
For the same reasons as before, the atom r(?x, ?y) is chosen to be evaluated first and the
solution mappings are, as before, 1 = {{?x 7 c, ?y 7 d}, {?x 7 e, ?y 7 f }} (this requires
2 consistency checks). We afterwards check which of the ?y mappings, d and f , are known
or possible instances of D. Note that this only requires a look-up since if we find d or f to be
among the possible instances, we do not check whether the individual is indeed an instance
or not. Here only f is a possible instance. We also check which of the ?x mappings, c and
e, are known or possible instances of C. Here, both c and e are possible instances, i.e., we
have 2 relevant possible instances for C(?x) and 1 for D(?y). Hence, the atom D(?y) is
chosen to be evaluated next, resulting in the solution sequence 2 = {{?x 7 e, ?y 7 f }} for
the (partial) execution plan (r(?x, ?y), D(?y)), requiring 1 consistency check. In the end,
we check whether the ?x mapping, e, is a known or possible instance of C. Since e is a
possible instance, we check whether it is a real instance (this requires 1 consistency check).
Hence, the solution mappings for q are O
q = {{?x 7 e, ?y 7 f }}, which have been found
by performing 4 consistency checks, one less than in the static case.
Note that in dynamic ordering we perform less checks than in static ordering, since in
this case we can exploit the results of joins of query atoms and more information regarding
the possible instances of atoms (i.e., which of them are real instances), which is determined
as a result of evaluating the atoms while ordering them.
We now make the process of query plan construction more precise, but we leave the
exact details of defining the cost function and the ordering it induces to later.
Definition 10 (Static and Dynamic Ordering). A static (dynamic) cost function w.r.t.
O
q over O is a function s : q  2V ars(q)  R  R (d : q  2q  R  R), where with O
q we
s
s
d
denote the set of compatible mappings for q over O. The two costs hEcat , Rsat i (hEcat , Rsdat i)
for an axiom template at  q are combined to yield a static ordering s ( dynamic ordering
267

fiKollia & Glimm

d ), which is a total order over the axiom templates of q such that, for at, at  q, we say
that at s at (at d at ) iff Ecsat + Rssat  Ecsat + Rssat (Ecdat + Rsdat  Ecdat + Rsdat ).
An execution plan for q is a duplicate-free sequence of axiom templates from q. The
initial execution plan is the empty sequence and a complete execution plan is a sequence
containing all templates of q. Let Pi = (at1 , . . . , ati ) with i < |q| be an execution plan for
q with query join graph Gq = (V, E, EL ). The set of bound variables of ati within Pi is
Vb (ati ) = Vars(ati )  Vars({at1 , . . . , ati1 }). Let Cq be the set of complex axiom templates
in q. We next define which axiom templates can be used to extend an incomplete execution
plan. Let at be an axiom template in Pi , the set suci (at) contains the axiom templates
that are connected to at and not yet in Pi , i.e., suci (at) = {at  q | hat, at i  E, at 
/
{at1 , . . . ati }}. Based on this, we define the set of connected successor axiom templates for
Pi as Si = {at | at  {at1 , . . . , ati } and at  suci (at )}. We further allow for including
axiom templates that are only connected to a complex axiom template from Si and define
the potential next templates qi for Pi w.r.t. Gq as qi = q if Pi is the initial execution plan
and otherwise
[
q i = Si 
suci (at).
at  Cq  Si

Given Pi , the static (dynamic) ordering induces an execution plan Pi+1 = (at1 , . . . , ati , ati+1 )
with ati+1  qi and ati+1 s at (ati+1 d at) for each at  qi such that at 6= ati+1 .
Note that according to the above definition, for Pi an execution plan, it can be the case
that qi contains templates that are assigned the same minimal cost by the cost function.
In such case, one can choose any of these atoms to add to Pi . Moreover, according to
the above definition for the case of queries containing only simple axiom templates we
have that, for i > 0, the set of potential next templates only contains templates that are
connected to a template that is already in the plan since unconnected templates cause
an unnecessary blowup of the number of intermediate results. For queries with complex
templates the set of potential next axiom templates can additionally contain templates that
do not share common variables with any template that is already in the plan. This different
handling of queries with complex templates is reasonable since, before evaluating a complex
axiom template that requires many consistency checks, we want to reduce the number of
candidate bindings, by first evaluating other simple (cheaper) templates that bind variables
which appear in the complex one.
Example 2. Let O be an ontology and q = {?x  A, ?y  r, B  ?y.?x} a query over
O. Assuming that systems usually precompute the concept and role hierarchies before they
accept queries, the evaluation of the first two templates, i.e., ?x  A and ?y  r, require
cheap cache lookups, whereas the axiom template B  ?y.?x, requires costly consistency
checks. Hence, it is reasonable to first evaluate the first two (cheap) templates to reduce the
mappings for ?x and ?y and then evaluate the third (expensive) template, by checking which
of the reduced mappings yield an entailed axiom.
An example that shows the actual gain we get from handling the ordering of complex
axiom templates in this way is presented in Section 7.
Let n = |q| and Pn = (at1 , . . . , atn ) be a complete execution plan for q over O determined
by static ordering. The procedure to find the solution mappings O
q for Pn is recursively
268

fiOptimizing SPARQL Query Answering over OWL Ontologies

defined as follows: Initially, our solution set contains only the identity mapping 0 = {0 },
which does not map any variable to any value. Assuming that we have evaluated the
sequence Pi = (at1 , . . . , ati ), i < n and we have found the set of solution mappings i ,
in order to find the solution mappings i+1 of Pi+1 , we use specific reasoning tasks to
extend the mappings in i to cover the new variables of ati+1 if ati+1 is a simple axiom
template or the entailment check service of reasoners if ati+1 does not contain new variables
or if ati+1 is a complex axiom template. In dynamic planning the difference is that the
execution plan construction is interleaved with query evaluation. In particular, let n = |q|
and Pi = (at1 . . . ati ) with i < n be a (partial) execution plan for q determined by dynamic
ordering and let i be the solution mappings of Pi . In order to find Pi+1 we extend Pi with
a new template, ati+1 , from q, i.e., Pi+1 = (at1 , . . . ati+1 ), which, according to the dynamic
cost function, has the minimal cost among the remaining templates q \ {at1 , . . . ati }. The
dynamic cost function assigns costs to templates at iteration i + 1 taking into account the
solution mappings i . We afterwards evaluate the atom ati+1 , i.e., we find the solution
mappings i+1 of Pi+1 by extending the solution mappings i of Pi in the same way as in
the static case. In Section 6.3 in Algorithm 3, we show the complete procedure we follow
to answer a query.
We now define the cost functions s and d more precisely, which estimate the cost of the
required reasoner operations (first component) and the estimated result output size (second
component) of evaluating an axiom template. The intuition behind the estimated value
of the reasoner operation costs is that the evaluation of possible instances is much more
costly than the evaluation of known instances since possible instances require expensive
consistency checks whereas known instances require cheap cache lookups. The estimated
result size takes into account the number of known and possible instances and the probability
that possible instances are actual instances.
The time needed for an entailment check can change considerably between ontologies
and even within an ontology (depending on the involved concepts, roles and individuals).
In order to more accurately determine the entailment cost we use different entailment cost
values depending on whether the template under consideration is a template of the form i)
c1 (t), ii) r1 (t, t ), iii) t  t , where c1 is a concept term, r1 is a role term and t, t are individual
terms, iv) one of the rest simple axiom templates (that require consistency checks to be
evaluated) or a complex axiom template. In the following we write CL to denote the cost of
a cache lookup in the internal structures of the reasoner, CE as a placeholder for the relevant
entailment cost value and PIS for the possible instance success, i.e, the estimated percentage
of possible instances that are actual instances. The costs CL and CE are determined by
recording the average time of previously performed lookups and entailment checks for the
queried ontology, e.g., during the initial consistency check, classification, or for previous
queries. The possible instance success, PIS , was determined by testing several ontologies
and checking how many of the initial possible instances were real ones, which was around
50% in nearly all ontologies.
Apart from the relations for the known and possible instances from Section 4.1, we use
the following auxiliary relations:
Definition 11 (Successor and Predecessor Relations). Let r be a role and a an individual. We define sucK[r] and preK[r] as the set of individuals with known r-successors and
269

fiKollia & Glimm

r-predecessors, respectively:
sucK[r] := {a | b.ha, bi  K[r]}

and

preK[r] := {a | b.hb, ai  K[r]}.

Similarly, we define sucK[r, a] and preK[r, a] as the known r-successors of a and the known
r-predecessors of a, respectively:
sucK[r, a] := {b | ha, bi  K[r]}

and

preK[r, a] := {b | hb, ai  K[r]}.

We analogously define the functions sucP[r], preP[r], sucP[r, a], and preP[r, a] by replacing
K[r] with P [r].
Next, we define the cost functions for the case of conjunctive instance queries, i.e.,
queries containing only query atoms. In Section 5.2 we extend the cost functions to deal
with general queries.
5.1 The Static and Dynamic Cost Functions for Conjunctive Instance Queries
The static cost function s takes two components as input: a query atom and a set containing
the variables of the query atom that are considered bound. The function returns a pair of
real numbers for the reasoning cost and the result size for the query atom.
Initially, all variables are unbound and we use the number of known and possible instances or successors/predecessors to estimate the number of required lookups and consistency checks for evaluating the query atom and for the resulting number of mappings. For
an input of the form hC(?x), i or hr(?x, ?y), i the resulting pair of real numbers for the
computational cost and the estimated result size is computed as
h|K[at]|  d  CL + |P [at]|  d  CE , |K[at]| + PIS  |P [at]|i,
where at denotes the predicate of the query atom (C or r). For at a concept (role) atom,
the factor d represents the depth of the concept (role) in the concept (role) hierarchy.
We use this factor since we only store the direct types of each individual (roles of which
individuals are instances) and, in order to find the instances of a concept (role), we may
need to check all its subconcepts (subroles) for known or possible instances. If the query
atom is a role atom with a constant in the first place, i.e., the input to the cost function is
of the form hr(a, ?x), i, we use the relations for known and possible successors to estimate
the computational cost and result size:
h|sucK[r, a]|  d  CL + |sucP[r, a]|  d  CE , |sucK[r, a]| + PIS  |sucP[r, a]|i.
Analogously, we use preK and preP instead of sucK and sucP for an input of the form
hr(?x, a), i. Finally, if the atom contains only constants, i.e., the input to the cost function
is of the form hC(a), i, hr(a, b), i, the function returns hd  CL , 1i if the individual is a
known instance of the concept or role, hd  CE , PIS i if the individual is a possible instance
and hd  CL , 0i otherwise, i.e., if the individual is a known non-instance.
For equality atoms of the form ?x ?y, a ?x, ?x  a or a  b, we again exploit
information from the initial pre-model as described in Section 4.1. Based on the cardinality
of K [a] and P [a], we can define cost functions for the different cases of query atoms and
270

fiOptimizing SPARQL Query Answering over OWL Ontologies

bound variables. For inputs of the form h?x  a, i and ha  ?x, i, the cost function is
defined as:
h|K [a]|  CL + |P [a]|  CE , |K [a]| + PIS  |P [a]|i.
For inputs of the form h?x  ?y, i, the cost function is computed as:
*
+
X
X
(|K [a]|  CL + |P [a]|  CE )/2,
(|K [a]| + PIS  |P [a]|)/2 .
aNIO

aNIO

For inputs of the form ha  b, i, the function returns hCL , 1i if b  K [a], hCE , PIS i if
b  P [a], and hCL , 0i otherwise (i.e., b is not equivalent to a).
After determining the cost of an initial query atom, at least one variable of a consequently considered atom is bound, since during the query plan construction we move over
atoms sharing a common variable and we assume that the query is connected. We now define the cost functions for atoms with at least one variable bound. We make the assumption
that atoms with unbound variables are more costly to evaluate than atoms with all their
variables bound. For a query atom r(?x, ?y) with only ?x bound, i.e., function inputs of
the form hr(?x, ?y), {?x}i, we use the average number of known and possible successors of
the role to estimate the computational cost and result size:


|P [r]|
|K[r]|
|P [r]|
|K[r]|
 d  CL +
 d  CE ,
+
 PIS .
|sucK[r]|
|sucP[r]|
|sucK[r]| |sucP[r]|
In case only ?y in r(?x, ?y) is bound, we use the predecessor functions preK and preP instead
of sucK and sucP. Note that we now work with an estimated average number of successors
(predecessors) for one individual.
For atoms with all their variables bound, we use formulas that are comparable to the
ones above for an initial plan, but normalized to estimate the values for one individual. For
an input query atom of the form C(?x) with ?x a bound variable we use


|K[C]|  d  CL + |P [C]|  d  CE |K[C]| + PIS  |P [C]|
,
.
|NIO |
|NIO |
Such a simple normalization is not always accurate, but leads to good results in most
cases as we show in Section 7. Similarly, we normalize the formulas for role atoms of the
form r(?x, ?y) such that {?x, ?y} is the set of bound variables of the atom. The two cost
components for these atoms are computed as


|K[r]|  d  CL + |P [r]|  d  CE |K[r]| + PIS  |P [r]|
,
.
|NIO |  |NIO |
|NIO |  |NIO |
For role atoms with a constant and a bound variable, i.e., atoms of the form r(a, ?x)
(r(?x, a)) with ?x a bound variable, we use sucK[r, a] and sucP[r, a] (preK[r, a] and preP[r, a])
instead of K[r] and P [r] in the above formulas and we normalize by |NIO |.
Similarly, we normalize the cost functions for inputs with equality atoms and bound
variables, depending on whether the atoms contain one or two bound variables. For inputs
of the form h?x  a, {?x}i, ha ?x, {?x}i, we divide the cost function components for inputs
271

fiKollia & Glimm

already executed
1
2
3
4
5
6
7

r(?x, ?y)
r(?x, ?y)
r(?x, ?y), D(?y)
r(?x, ?y), C(?x)

current atom at
C(?x)
r(?x, ?y)
D(?y)
C(?x)
D(?y)
C(?x)
D(?y)

K[at]
200
200
700
100
50
45
45

P [at]
350
200
600
150
50
35
40

real from P [at]
200
50
400
100
40
25
25

Table 1: Query Ordering Example
of the form h?x  a, i and ha ?x, i by |NIO |. For an input of the form h?x  y, {?x, ?y}i,
we divide the cost function components for input of the form h?x ?y, i by |NIO |  |NIO |.
For inputs of the form h?x ?y, {?x}i, and h?x ?y, {?y}i, we divide the cost function
components for input of the form h?x ?y, i by |NIO |.
The dynamic cost function d is based on the static function s, but only uses the first
equations, where the atom contains only unbound variables or constants. The function
takes a pair hat, i as input, where at is a query atom and  is the set of solution mappings
for the atoms that have already been evaluated, and returns a pair of real numbers using
matrix addition as follows:
X
d(at, ) =
s((at), )


When sampling techniques are used, we compute the costs for each of the potential next
atoms for an execution plan by only considering one individual of each relevant cluster.
Which cluster is relevant depends on the query atom for which we compute the cost function
and the previously computed bindings. For instance, if we compute the cost of a role atom
r(?x, ?y) and we have already determined bindings for ?x, we use the role successor cluster
P C1 . Among the ?x bindings, we then just check the cost for one binding per cluster and
assign the same cost to all other ?x bindings of the same cluster.
Example 3. Let us assume that we have a conjunctive instance query q and that we have
to find the cost (using the dynamic function) of the atom C(?x) within an execution plan
for q. We further assume that from the evaluation of previous query atoms in the plan
we have already determined a set of intermediate solutions  with the mappings a, b, or c
for ?x. Let us assume that a, b, and c belong to the same concept cluster. According to
dynamic ordering we need to find the cost of each instantiated atom using the static cost
function, i.e., d(C(?x), ) = s(C(a), ) + s(C(b), ) + s(C(c), ). If we additionally use
cluster based sampling, we find the cost for only one individual of each cluster, let us say a,
and then assign the same cost to all other individuals from the cluster which are mappings
for ?x in . Hence, the cost of the atom C(?x) when sampling is used, is computed as
d(C(?x), ) = 3  s(C(a), ) avoiding the computation of s(C(b), ) and s(C(c), ).
An example that is similar to Example 1 (but with a greater number of instances) and
shows how ordering is achieved by the use of the defined static and dynamic functions is
shown below. We assume that q is a query consisting of the three query atoms: C(?x),
272

fiOptimizing SPARQL Query Answering over OWL Ontologies

r(?x, ?y), D(?y). Table 1 gives information about the known and possible instances of
these atoms within a sequence. The second column shows already executed sequences
Pi1 = (at1 , . . . , ati1 ) for the atoms of q. Column 3 gives the current atom ati and column
4 (5) gives the number of mappings to known (possible) instances of at that satisfy at the
same time the atoms (at1 , . . . , ati1 ) from column 2. Column 6 gives the number of real
instances from the possible instances for the current atom. For example, row 4 says that we
have evaluated the atom r(?x, ?y) and, in order to evaluate C(?x), we only consider those
100 known and 150 possible instances of C that are also mappings for ?x. We further assume
that we have 10,000 individuals in our ontology O. We now explain, using the example,
how the above described formulas work. We assume that CL  CE , which is always the
case since a cache lookup is less expensive than a consistency check and that the CE values
are the same for all query concepts and roles. For ease of presentation, we further do not
consider the factor for the depth of the concept (role) within the concept (role) hierarchy.
In both techniques (static and dynamic) the atom r(?x, ?y) is chosen first since it has the
least number of possible instances (200) while it has the same (or smaller) number of known
instances (200) as the other atoms (0 is the initial solution mapping that does not map
any variable):
s(r(?x, ?y), ) = d(r(?x, ?y), {0 }) = h200  CL + 200  CE , 200 + PIS  200i,
s(C(?x), ) = d(C(?x), {0 }) = h200  CL + 350  CE , 200 + PIS  350i,
s(D(?y), ) = d(D(?y), {0 }) = h700  CL + 600  CE , 700 + PIS  600i.
In the case of static ordering, the atom C(?x) is chosen after r(?x, ?y) since C has less
possible (and known) instances than D (350 versus 600):


350
200 + 350  PIS
200
 CL +
 CE ,
,
s(C(?x), {?x}) =
10, 000
10, 000
10, 000


700
600
700 + 600  PIS
s(D(?y), {?y}) =
 CL +
 CE ,
.
10, 000
10, 000
10, 000
Hence, the order of evaluation in this case is P = (r(?x, ?y), C(?x), D(?y)) leading to
200 (row 2) + 150 (row 4) + 40 (row 7) entailment checks. In the dynamic case, after the
evaluation of r(?x, ?y), which gives a set of solutions 1 , the atom D(?y) has fewer known
and possible instances (50 known and 50 possible) than the atom C(?x) (100 known and
150 possible) and, hence, a lower cost:
d(D(?y), 1 ) = h50  CL + 150  CL + 50  CE , 50 + 0 + 50  PIS i,
d(C(?x), 1 ) = h100  CL + 0  CL + 150  CE , 100 + 0 + 150  PIS i.
Note that applying a solution   1 to D(?y) (C(?x)) results in a query atom with a
constant in place of ?y (?x). For D(?y), it is the case that out of the 250 r-instances, 200
can be handled with a look-up (50 turn out to be known instances and 150 turn out not
to be instances of D), while 50 require an entailment check. Similarly, when considering
C(?x), we need 100 lookups and 150 entailment checks. Note that we assume the worst
case in this example, i.e., that all values that ?x and ?y take are different. Therefore,
the atom D(?y) is chosen next, leading to the execution of the query atoms in the order
P = (r(?x, ?y), D(?y), C(?x)) and the execution of 200 (row 2) + 50 (row 5) + 35 (row 6)
entailment checks.
273

fiKollia & Glimm

5.2 Cost Functions for General Queries
We now explain how we order the remaining simple and complex axiom templates. We
again use statistics from the reasoner, whenever these are available. In case the reasoner
cannot give estimates, one can still work with statistics computed from explicitly stated
information or use upper bounds to estimate the reasoner costs and the result size of axiom
templates.
We first consider a general concept assertion axiom template. Let KC [a] be the concepts
of which a is a known instance, PC [a] the concepts of which a is a possible instance. These
sets are computed from the sets of known and possible instances of concepts. For an input
of the form h?x(a), i the cost function is defined as
h|KC [a]|  d  CL + |PC [a]|  d  CE , |KC [a]| + PIS  |PC [a]|i.
For an input of the form h?x(?y), i, the cost function is defined as
*
+
X
X
(|K[C]|  d  CL + |P [C]|  d  CE ),
(|K[C]| + PIS  |P [C]|) .
CNCO

CNCO

For inputs of the form h?x(a), {?x}i and h?x(?y), {?x, ?y}i, we normalize the above functions
by |NCO | and |NIO ||NCO | respectively. For inputs of the form h?x(?y), {?x}i and h?x(?y), {?y}i
we normalize the function for inputs of the form h?x(?y), i by |NCO | and |NIO | respectively.
For general role assertion axiom templates, there are several cases of cost functions depending on the bound variables. We next define the cost functions for some cases. The cost
functions for the other cases can similarly be defined. For an input of the form h?z(?x, ?y), i,
the cost function is defined as :
*
+
X
X
(|K[r]|  d  CL + |P [r]|  d  CE ),
(|K[r]| + PIS  |P [r]|) .
rNRO

rNRO

For inputs of the form h?z(a, ?y), i, the cost function is defined as:
*
+
X
X
(|sucK[r, a]|  d  CL + |sucP[r, a]|  d  CE ),
(|sucK[r, a]| + PIS  |sucP[r, a]|) .
rNRO

rNRO

For an input of the form h?z(?x, ?y), {?z}i, the cost function is defined as:
+
*
X |K[r]|  d  CL + |P [r]|  d  CE X |K[r]| + PIS  |P [r]|
,
.
|NRO |
|NRO |
O
O
rNR

rNR

Last, for inputs of the form h?z(?x, ?y), {?x}i, the two cost components are computed as:
*
+
X |K[r]|
X |K[r]|
|P [r]|
|P [r]|
(
 d  CL +
 d  CE ),
+
PIS ) .
(
|sucK[r]|
|sucP[r]|
|sucK[r]| |sucP[r]|
O
O
rNR

rNR

274

fiOptimizing SPARQL Query Answering over OWL Ontologies

For concept (role) inclusion axiom templates of the form c1  c2 (r1  r2 ), where c1 , c2
concept terms (r1 , r2 role terms), that contain only concept (role) names and variables we
need lookups in the computed concept (role) hierarchy in order to compute the answers
(assuming that the concept (role) hierarchy is precomputed).
One can define similar cost functions for other types of axiom templates by either using
the available statistics or by relying on told information from the ontology. For this paper,
however, we just define a cost function based on the assumption that we iterate over all
possible values of the respective variables and do one consistency check for each value.
Hence, we define the following general cost function for these cases:
h|N |  CE , |N |i,
where N  {NCO , NRO , NIO } as appropriate for the variable that is tested. As discussed in
Section 5.1, the dynamic function is based on the static one and is applied only to the above
described cases for an empty set of bound variables.
Proposition 1. Let q be a query over an ontology O, s and d the static and dynamic cost
functions defined in Sections 5.1 and 5.2. The ordering induced by s and d is a total order
over the axiom templates of q.
Proof. The cost functions s and d are defined for all kinds of axiom templates and return
two real numbers to each possible input. Since, according to Definition 10, the orders s
and d are based on the addition of the two real numbers, addition of reals yields again a
real number, and since  is a total order over the reals, we immediately get that s and
d are total orders.
It is obvious that the ordering of axiom templates does not affect soundness and completeness of a query evaluation algorithm.

6. Complex Axiom Template Optimizations
In this section, we first describe some optimizations that we have developed for complex
axiom templates (Sections 6.1, 6.2) and then we present the procedure for evaluating queries
(Section 6.3).
6.1 Axiom Template Rewriting
Some costly to evaluate axiom templates can be rewritten into axiom templates that can
be evaluated more efficiently and yield an equivalent result. Before we go on to describe the
axiom template rewriting technique, we define what a concept template is, which is useful
throughout the section.
Definition 12 (Concept Template). Let Sq = (NC , NR , NR , VC , VR , VI ) be a query
signature w.r.t. a signature S = (NC , NR , NI ). A concept template over Sq is a SROIQ
concept over S, where one can also use concept variables from VC in place of concept names,
role variables from VR in place of role names and individual variables from VI in place of
individual names.
275

fiKollia & Glimm

Definition 13 (Rewriting). Let O be an ontology, at  q an axiom template over Sq ,
t, t1 , . . . tn individuals or individual variables from Sq , and C, C1 , . . . , Cn concept templates
over Sq . The function rewrite takes an axiom template and returns a set of axiom templates
as follows:
 if at = (C1  . . .  Cn )(t), then rewrite(at) = {C1 (t), . . . , Cn (t)};
 if at = C  C1  . . .  Cn , then rewrite(at) = {C  C1 , . . . , C  Cn };
 if at = C1  . . .  Cn  C, then rewrite(at) = {C1  C, . . . , Cn  C};
 if at = t1  . . .  tn , then rewrite(at) = {t1  t2 , t2  t3 , . . . , tn1  tn }.
To understand the intuition behind such transformation, we consider a query with only
the axiom template: ?x  r.?y  A. Its evaluation requires a quadratic number of consistency checks in the number of concepts (since ?x and ?y are concept variables). The
rewriting yields: ?x  A and ?x  r.?y. The first axiom template is now evaluated with a
cheap cache lookup (assuming that the concept hierarchy has been precomputed). For the
second one, we only have to check the usually few resulting bindings for ?x combined with
all other concept names for ?y.
Note that Description Logics typically do not support n-ary equality axioms t1  . . . 
tn , but only binary ones, whereas in OWL, one can typically also write n-ary equality axioms.
Since our cost functions are only defined for binary equality axioms, we equivalently rewrite
an n-ary one into several binary ones. One could even further optimize the evaluation of
such atoms by just evaluating one binary equality axiom template and by then propagating
the binding for the found equivalent individuals to the other equality axioms. This is valid
since equality is a congruence relation.
6.2 Concept and Role Hierarchy Exploitation
The number of consistency checks required to evaluate a query can be further reduced
by taking the concept and role hierarchies into account. Once the concepts and roles are
classified (this can ideally be done before a system accepts queries), the hierarchies are
stored in the reasoners internal structures. We further use the hierarchies to prune the
search space of solutions in the evaluation of certain axiom templates. We illustrate the
intuition with the example Infection  hasCausalLinkTo.?x. If A is not a solution and
B  A holds, then B is also not a solution. Thus, when searching for solutions for ?x, we
choose the next binding to test by traversing the concept hierarchy top-down. When we find
a non-solution A, the subtree rooted in A of the concept hierarchy can safely be pruned.
Queries over ontologies with a large number of concepts and a deep concept hierarchy
can, therefore, gain the maximum advantage from this optimization. We employ similar
optimizations using the role hierarchies.
In the example above, we can prune the subconcepts of A because ?x has positive
polarity in the axiom template Infection  hasCausalLinkTo.?x., i.e., ?x occurs positively
on the right hand side of the axiom template. In case a variable ?x has negative polarity
in an axiom template of the form C1  C2 , i.e., ?x occurs directly or indirectly under a
negation on the right hand side of the axiom template or positively on the left-hand side of
an axiom template, one can, instead, prune the superconcepts.
276

fiOptimizing SPARQL Query Answering over OWL Ontologies

We next specify more precisely the polarity of a concept variable in a concept or axiom
template.
Definition 14 (Concept Polarity). Let ?x  VC be a concept variable and C, C1 , C2 , D
concept templates, r a role, and n  IN0 . We define the polarity of ?x in C as follows: ?x
occurs positively in ?x. Furthermore, ?x occurs positively (negatively)
 in D if ?x occurs negatively (positively) in D,
 in C1  C2 or C1  C2 if ?x occurs positively (negatively) in C1 or C2 ,
 in r.D, r.D, or > n r.D if ?x occurs positively (negatively) in D,
 in 6 n r.D if ?x occurs negatively (positively) in D
 in = n r.D if ?x occurs in D.
We further say that ?x occurs positively (negatively) in C1  C2 if ?x occurs negatively
(positively) in C1 or positively (negatively) in C2 . Note that ?x can occur both positively
and negatively in a concept template. We further define a partial function polc that maps
a concept variable ?x and a concept template C (axiom template of the form C1  C2 ) to
pos if ?x occurs only positively in C (C1  C2 ) and to neg if ?x occurs only negatively in
C (C1  C2 ).
Note that no matter whether ?x occurs positively or negatively in a concept template D,
in any concept template C of the form = n r.D, ?x occurs positively as well as negatively.
This is due to the fact that C is equivalent to the concept template 6 n r.D  > n r.D
in which ?x occurs positively as well as negatively. Since the function polc is not defined
for variables that appear both positively and negatively, the concept hierarchy cannot be
exploited in this case. For example, consider the concept template ?x  r.?x, (axiom
template ?x  r.?x), where ?x appears negatively in ?x and positively in r.?x. Now,
let   I be an arbitrary element from a model I = (I , I ) of the ontology. It is obvious
that if  is an instance of A  r.A and either A  B or B  A holds, we cannot deduce
that  is an instance of B  r.B.
Before proving the correctness of the proposed optimization, we first show the relationship between entailment and concept membership, which is used in the subsequent proofs.
Lemma 1. Let q be a query over O w.r.t. the query signature Sq = (NC , NR , NI , VC , VR , VI ),
at  q be an axiom template of the form C1  C2 where C1 and C2 are concept templates
and let  be a mapping for at over O. It holds that O 6|= (C1  C2 ) iff there exists an
interpretation I = (I , I ) and an element   I such that I |= O and  6 (C1  C2 )I .
Proof. O 6|= (C1  C2 ) holds iff there exists an interpretation I = (I , I ) and an element
  I such that I |= O and   (C1 )I and  6 (C2 )I , which holds iff   (C1 )I
and   (C2 )I , which is equivalent to   (C1  C2 )I , which is equivalent to  
((C1  C2 ))I , which holds iff  6 (C1  C2 )I .
The following theorem holds for every axiom template of the form C1  C2 . Note that
we assume here that concept assertion templates of the form C(a) are expressed as the
equivalent axiom templates {a}  C. We use C(?x)=A , where A is a concept name, to
denote the concept obtained by applying the extension of  that also maps ?x to A.
277

fiKollia & Glimm

Theorem 1. Let O be an ontology, A, B concept names such that O |= A  B, C1 , C2
concept templates, C1  C2 an axiom template, C = C1  C2 , ?x  VC a concept variable
occurring in C and  a mapping that covers all variables of C apart from ?x.
1. For polc (?x, C) = pos it holds that if O 6|= (C1  C2 )(?x)=B , then O 6|= (C1  C2 )(?x)=A .
2. For polc (?x, C) = neg it holds that if O 6|= (C1  C2 )(?x)=A , then O 6|= (C1  C2 )(?x)=B .
Proof. Due to Lemma 1, it suffices to show for some model I = (I , I ) of O and some
element   I the following (which is formalized in contrapositive form):
1. For polc (?x, C) = pos it holds that if   (C(?x)=A )I , then   (C(?x)=B )I .
2. For polc (?x, C) = neg it holds that if   (C(?x)=B )I , then   (C(?x)=A )I .
We prove the claim by induction on the structure of the concept template C:
 For C =?x, ?x occurs positively in C. Now, if   (?x(?x)=A )I , that is   AI , it is
easy to see that   B I since O |= A  B by assumption. Hence,   (?x(?x)=B )I .
 For C = D and polc (?x, C) = pos, if   (D(?x)=A )I , we have to show that
  (D(?x)=B )I . Note that polc (?x, D) = neg. In contrary to what is to be shown,
assume that   (D(?x)=B )I . Since O |= A  B and by induction hypothesis  
(D(?x)=A )I and   (D(?x)=A )I which is a contradiction. The proof is analogous
for polc (?x, C) = neg.
 For C = C1  C2 and polc (?x, C) = pos, if   ((C1  C2 )(?x)=A )I , then  
(C1(?x)=A )I and   (C2(?x)=A )I . Since O |= A  B and by induction hypothesis,   (C1(?x)=B )I and   (C2(?x)=B )I . Thus,   ((C1  C2 )(?x)=B )I . The
proof is analogous for polc (?x, C) = neg.
 The proof for C1  C2 is analogous to the one for C1  C2 .
 For C = r.D and polc (?x, C) = pos, if   ((r.D)(?x)=A )I , then  has at least one rsuccessor, say  , that is an instance of D(?x)=A . Since O |= A  B and by induction
hypothesis,   D(?x)=B . Hence,   (r.(D(?x)=B ))I = ((r.D)(?x)=B )I . The
proof is analogous for polc (?x, C) = neg.
 For C = r.D and polc (?x, C) = pos, if   ((r.D)(?x)=A )I , then   (r.(D)(?x)=A )I
and each r-successors of  is an instance of D(?x)=A . Since O |= A  B and by induction hypothesis, these r-successors are also instances of D(?x)=B . Hence,  
(r.(D(?x)=B ))I = ((r.D)(?x)=B )I . The proof is analogous for polc (?x, C) = neg.
 For C = > n r.D and polc (?x, C) = pos, if   ((> n r.D)(?x)=A )I , then  has at
least n distinct r-successors which are instances of D(?x)=A . Since O |= A  B and
by induction hypothesis, these successors are instances of D(?x)=B . Hence,  has
at least n distinct r-successors that are instances of D(?x)=B and, therefore,   (>
n r.(D)(?x)=B )I = ((> n r.D)(?x)=B )I . The proof is analogous for polc (?x, C) = neg.
278

fiOptimizing SPARQL Query Answering over OWL Ontologies

 For C = 6 n r.D and polc (?x, C) = pos, if   ((6 n r.D)(?x)=A )I , we have to show
that   ((6 n r.D)(?x)=B )I . Note that polc (?x, D) = neg. In contrary to what is to
be shown, assume that   ((6 n r.D)(?x)=B )I , i.e.,   ((> n + 1 r.D)(?x)=B )I .
Hence,  has at least n + 1 distinct r-successors which are instances of D(?x)=B .
Since polc (?x, D) = neg and by induction hypothesis, these D(?x)=B instances are
also D(?x)=A instances and   (> n + 1 r.(D)(?x)=A )I = ((> n + 1 r.D)(?x)=A )I ,
which is a contradiction. The proof is analogous for polc (?x, C) = neg.
 For C = (= n r.D), the polarity of ?x in C is always positive and negative, so
polc (?x, C) is undefined and the case cannot occur.
We now extend this optimization to the case of role variables and we first define the
polarity of a role variable in a concept or axiom template.
Definition 15 (Role Polarity). Let ?x  VR be a role variable, C, C1 , C2 , D concept
templates, r a role, and n  IN0 . We define the polarity of ?x in C as follows: ?x occurs
positively in ?x.D, ?x .D, > n ?x.D, > n ?x .D, = n ?x.D, and = n ?x .D; ?x
occurs negatively in ?x.D, ?x .D, 6 n ?x.D, 6 n ?x .D, = n ?x.D, and = n ?x .D.
Furthermore, ?x occurs positively (negatively)
 in D if ?x occurs negatively (positively) in D,
 in C1  C2 or C1  C2 if ?x occurs positively (negatively) in C1 or C2 ,
 in r.D, ?x.D, ?x .D, > n r.D, > n ?x.D, > n ?x .D, r.D, ?x.D, or ?x .D
if ?x occurs positively (negatively) in D,
 in 6 n r.D, 6 n ?x.D, or 6 n ?x .D if ?x occurs negatively (positively) in D,
 in = n r.D if ?x occurs in D.
We further say that ?x occurs positively (negatively) in C1  C2 if ?x occurs negatively
(positively) in C1 or positively (negatively) in C2 . We define a partial function polr that
maps a role variable ?x and a concept template C (axiom template of the form C1  C2 ) to
pos if ?x occurs only positively in C (C1  C2 ) and to neg if ?x occurs only negatively in
C (C1  C2 ).
Note also that we do not make any assumption about occurrences of ?x in D in the first
part of the definition.
We now show, that the hierarchy optimization is also applicable to role variables, provided they occur only positively or only negatively.
Theorem 2. Let O be an ontology, r, s role names such that O |= r  s, C1 , C2 concept
templates, C1  C2 an axiom template, C = C1  C2 , ?x  VR a role variable occurring
in C and  a mapping that covers all variables of C apart from ?x.
1. For polr (?x, C) = pos it holds that if O 6|= (C1  C2 )(?x)=s , then O 6|= (C1  C2 )(?x)=r .
2. For polr (?x, C) = neg it holds that if O 6|= (C1  C2 )(?x)=r , then O 6|= (C1  C2 )(?x)=s .
279

fiKollia & Glimm

Proof. Due to Lemma 1, it suffices to show for some model I = (I , I ) of O and some
element   I the following (which is formalized in contrapositive form):
1. For polr (?x, C) = pos it holds that if   (C(?x)=r )I , then   (C(?x)=s )I .
2. For polr (?x, C) = neg it holds that if   (C(?x)=s )I , then   (C(?x)=r )I .
We prove the claim by induction on the structure of the concept template C:
 For C = ?x.D, where D is a concept template that does not contain ?x. We have
polr (?x, C) = pos. Assume,   ((?x.D)(?x)=r )I , that is,   (r.(D))I . Then
there is some   I such that h,  i  r I and   (D)I . Since O |= r  s, we also
have h,  i  sI and, therefore,   (s.(D))I = ((?x.D)(?x)=s )I .
 For C = ?x.D, where D is a concept template that does not contain ?x. We have
polr (?x, C) = neg. If   ((?x.D)(?x)=s )I , we have to show that   ((?x.D)(?x)=r )I .
In contrary to what is to be shown, assume that   ((?x.D)(?x)=r )I , i.e.,  
(r.(D))I . Hence, there is some   I such that h,  i  r I and   (D)I .
Since O |= r  s, we also have h,  i  sI and, therefore,  
/ (s.(D))I =
I
((?x.D)(?x)=s ) , which is a contradiction.
 For C = > n ?x.D where D is a concept template that does not contain ?x. We have
polr (?x, C) = pos. Assume,   ((> n ?x.D)(?x)=r )I , that is   (> n r.(D))I and
 has at least n distinct r-successors which are instances of (D). Since O |= r  s
these r-successors are also s-successors of  and, therefore,   (> n s.(D))I = ((>
n ?x.D)(?x)=s )I .
 For C = 6 n ?x.D where C is a concept template that does not contain ?x. We
have polr (?x, C) = neg. If   ((6 n ?x.D)(?x)=s )I , we have to show that  
((6 n ?x.D)(?x)=r )I . In contrary to what is to be shown, assume that   ((6
n ?x.D)(?x)=r )I , i.e.,   (> n + 1 r.(D))I . Hence,  has at least n + 1 distinct
r-successors, which are instances of (D). Since O |= r  s, these r-successors are
also s-successors and   ((> n + 1 s.(D)))I = ((> n + 1 ?x.D)(?x)=s )I , which is a
contradiction.
 For C = C1 C2 and polr (?x, C) = pos, if   ((C1 C2 )(?x)=r )I , then   (C1 (?x)=r )I
and   (C2 (?x)=r )I . Since O |= r  s and by the induction hypothesis,  
(C1(?x)=s )I and   (C2(?x)=s )I . Thus,   ((C1  C2 )(?x)=s )I . The proof is
analogous for polr (?x, C) = neg.
 The proof for C1  C2 is analogous to the one for C1  C2 .
 For C = D and polr (?x, C) = pos, if   (D(?x)=r )I , we have to show that
  (D(?x)=s )I . Note that polr (?x, D) = neg. In contrary to what is to be shown,
assume that   (D(?x)=s )I . Since O |= r  s and by induction hypothesis  
(D(?x)=r )I and   (D(?x)=r )I which is a contradiction. The proof is analogous
for polr (?x, C) = neg.
280

fiOptimizing SPARQL Query Answering over OWL Ontologies

 For C = p.D and polr (?x, C) = pos, we also have polr (?x, D) = pos. Now, if
  ((p.D)(?x)=r )I , then  has at least one p-successor that is an instance of D(?x)=r .
Since O |= r  s and by induction hypothesis, this p-successor is an instance of
D(?x)=s . Hence,   ((p.D)(?x)=s )I . The proof is analogous for polr (?x, C) = neg.
 For C = ?x.D and polr (?x, C) = pos, we also have polr (?x, D) = pos. Note
that ?x occurs in D since otherwise the case is handled already above. Now, if
  ((?x.D)(?x)=r )I , then  has at least one r-successor which is an instance of
D(?x)=r . Since O |= r  s and by induction hypothesis,  has at least one s-successor
that is an instance of D(?x)=s . Hence,   ((?x.D)(?x)=s )I .
 For C = p.D and polr (?x, C) = pos, we also have polr (?x, D) = pos. Now, if  
((p.D)(?x)=r )I , then   (p.(D)(?x)=r )I and each p-successor of  is an instance
of D(?x)=r . Since O |= r  s and by induction hypothesis, these p-successors are also
instances of D(?x)=s . Hence,   (p.(D(?x)=s ))I = ((p.D)(?x)=s )I . The proof is
analogous for polr (?x, C) = neg.
 For C = ?x.D and polr (?x, C) = neg, we also have polr (?x, D) = neg. Note
that ?x occurs in D since otherwise the case is handled already above. Now, if
  ((?x.D)(?x)=s )I , we have to show that   ((?x.D)(?x)=r )I . In contrary to
what is to be shown, assume that  
/ ((?x.D)(?x)=r )I , i.e.,   (r.(D)(?x)=r )I .
Hence, there is some   I such that h,  i  r I and   ((D)(?x)=r )I . Since
O |= r  s,  is also an s-successor of  and, by induction hypothesis, we have
  ((D)(?x)=s )I which is a contradiction.
 For C = > n p.D and polr (?x, C) = pos, if   (( > n p.D)(?x)=r )I , then  has at
least n distinct p-successors that are instances of D(?x)=r . Since O |= r  s and
by induction hypothesis, these p-successors are also instances of D(?x)=s . Hence,
  (( > n p.D)(?x)=s )I . The proof is analogous for polr (?x, C) = neg
 For C = > n ?x.D and polr (?x, C) = pos, we also have polr (?x, D) = pos. Note
that ?x occurs in D since otherwise the case is handled already above. Now, if
  (( > n ?x.D)(?x)=r )I , then  has at least n distinct r-successors which are
instances of D(?x)=r . Since O |= r  s and by induction hypothesis,  has at least n
distinct s-successors that are instances of D(?x)=s . Hence,   (( > n ?x.D)(?x)=s )I .
 For C = 6 n p.D and polr (?x, C) = pos, if   ((6 n p.D)(?x)=r )I , we have to show
that   ((6 n p.D)(?x)=s )I . Note that polr (?x, D) = neg. In contrary to what is to
be shown, assume that   ((6 n p.D)(?x)=s )I , i.e.,   ((> n + 1 p.D)(?x)=s )I .
Hence,  has at least n + 1 distinct p-successors which are instances of D(?x)=s .
Since polr (?x, D) = neg and by induction hypothesis, these D(?x)=s instances are
also D(?x)=r instances and   (> n + 1 p.(D)(?x)=r )I = ((> n + 1 p.D)(?x)=r )I ,
which is a contradiction. The proof is analogous for polr (?x, C) = neg.
 For C = 6 n ?x.D and polr (?x, C) = neg, we have polr (?x, D) = pos. Note that
?x occurs in D since otherwise the case is handled already above. If   ((6
n ?x.D)(?x)=s )I we have to show that   ((6 n ?x.D)(?x)=r )I . In contrary
281

fiKollia & Glimm

Algorithm 2 getPossibleMappings(O, ?x, at, )
Input: O: the queried SROIQ ontology
?x: a concept or role variable
at: an axiom template in which ?x occurs
: a mapping with ?x  dom()
Output: a set of mappings
1: S := 
2: if ?x  VC then
3:
if polc (?x, at) = pos then
4:
S := { |  (?x) = A, A is a direct subconcept of (?x) in O,
 (?y) = (?y) for ?y  dom() \ {?x}}
5:
else
6:
S := { |  (?x) = A, A is a direct superconcept of (?x) in O,
 (?y) = (?y) for ?y  dom() \ {?x}}
7:
end if
8: else
9:
if polr (?x, at) = pos then
10:
S := { |  (?x) = r, r is a direct subrole of (?x) in O,
 (?y) = (?y) for ?y  dom() \ {?x}}
11:
else
12:
S := { |  (?x) = r, r is a direct superrole of (?x) in O,
 (?y) = (?y) for ?y  dom() \ {?x}}
13:
end if
14: end if
15: return S
to what is to be shown, assume that   ((6 n ?x.D)(?x)=r )I , i.e.,   ((>
n + 1 ?x.D)(?x)=r )I . Hence,  has at least n + 1 distinct r-successors which are instances of D(?x)=r . Since O |= r  s, and by induction hypothesis, these r-successors
are also s-successors and instances of D(?x)=s . Hence,   ((> n + 1 ?x.D)(?x)=s )I
and   ((6 n ?x.D)(?x)=s )I , which is a contradiction.
 For C = (= n ?x.D) or C = (= n r.D), the polarity of ?x in C is always positive
and negative, so polr (?x, C) is undefined and the case cannot occur.
 The cases for ?x occurring in the form of an inverse (?x ) are analogous, given that
O |= r  s iff O |= r   s .
Algorithm 2, which we explain in detail in Section 6.3, shows how we use the above
theorems to create possible concept and role mappings for a concept or role variable ?x
that appears only positively or only negatively in an axiom template C1  C2 .
6.3 Query Answering Algorithm
Algorithm 3 shows an optimized way of evaluating queries using static ordering. First,
axiom templates are simplified where possible (method rewrite in line 1). Next, the method
282

fiOptimizing SPARQL Query Answering over OWL Ontologies

Algorithm 3 evaluate(O, q)
Input: O: the queried SROIQ ontology
q: a query over O
Output: a set of solutions for evaluating q over O
1: At := rewrite(q)
2: At1 , . . . , Atm :=connectedComponents(At)
3: for j=1, . . . , m do
4:
Rj := {0 | dom(0 ) = }
5:
at1 , . . . , atn := order(Atj )
6:
for i = 1, . . . , n do
7:
R := 
8:
for each   Rj do
9:
if isSimple(ati ) and Vars(ati ) \ dom() 6=  then
10:
R := R  {   |   callSpecificReasonerTask((ati ))}
11:
else if Vars(ati ) \ dom() =  then
12:
if O |= (ati ) then
13:
R := R  {}
14:
end if
15:
else
16:
Vopt := {?x |?x 6 dom(), Theorem 1 or 2 applies to ?x and ati }
17:
B := initializeVariableMappings(O, ati , , Vopt )
18:
while B 6=  do
19:
 := removeMapping(B)
20:
if O |=  (ati ) then
21:
R := R  { |  (?x) =  (?x) if ?x 
/ Vopt and
 (?x) = C if ?x  Vopt  VC , O |= C   (?x) and
 (?x) = r if ?x  Vopt  VR , O |= r   (?x)}
22:
for each ?x  Vopt do
23:
B := B  getPossibleMappings(O, ?x, ati ,  )
24:
end for
25:
end if
26:
end while
27:
end if
28:
end for
29:
Rj := R
30:
end for
31: end for
32: Rans := {1  . . .  m | j  Rj , 1  j  m}
33: return Rans

connectedComponents (line 2) partitions the axiom templates into sets of connected components, i.e., within a component the templates share common variables, whereas between
components there are no shared variables. Unconnected components unnecessarily increase
the amount of intermediate results and, instead, one can simply combine the results for the
283

fiKollia & Glimm

Algorithm 4 initializeVariableMappings(O, at, , Vopt )
Input: O: the queried SROIQ ontology
at: an axiom template
: a partial mapping
Vopt : the variables of at to which Theorem 1 or 2 applies
Output: a set of mappings
1: S := {}
2: for each ?x  Vars(at) \ dom() do
3:
R := 
4:
if ?x  VC and ?x  Vopt then
5:
for each   S do
6:
if polc (?x, at) = pos then
7:
 (?x) := 
8:
else
9:
 (?x) := 
10:
end if
11:
R := R  { }
12:
end for
13:
else if ?x  VR and ?x  Vopt then
14:
for each   S do
15:
if polr (?x, at) = pos then
16:
 (?x) := r
17:
else
18:
 (?x) := r
19:
end if
20:
R := R  { }
21:
end for
22:
else
23:
R := { |  (?x) = a, a  NCO or a  NRO or a  NIO and  (?y) = 1 (?y)
for 1  S and ?y  dom(1 )}
24:
end if
25:
S := R
26: end for
27: return S

components in the end (line 32). For each component, we proceed as described below: we
first determine an order (method order in line 5) as described in Section 5. For a simple axiom template, which contains so far unbound variables, we call a specialized reasoner method
to retrieve entailed results, i.e., mappings for unbound variables (callSpecificReasonerTask
in line 10). Note that the mappings  do not assign values to any of the variables covered
by the already computed (partial) solution  since we instantiate the atom ati by . This
allows for defining the union of  and  by setting (   )(v) = (v) if v  dom(),
and (   )(v) =  (v) otherwise. For templates with all their variables bound, we check
whether the mappings lead to entailed axioms (lines 11 to 14). For all other cases, i.e.,
284

fiOptimizing SPARQL Query Answering over OWL Ontologies

for complex axiom templates with unbound variables, we check which compatible mappings
yield an entailed axiom (lines 15 to 27). In particular, we first initialize a set B of candidate mappings for the unbound variables of the axiom template (line 17, which refers to
Algorithm 4). Algorithm 4 initializes the unbound variables of axiom templates on which
Theorem 1 or 2 applies to  (r ) or  (r ) depending on whether the respective polarity
function returns pos or neg. For template variables on which the optimization is not applicable, all compatible mappings are returned. The method removeMapping (line 19) returns
a mapping from B and deletes this mapping from B. We then instantiate the axiom template and check entailment. In case the entailment holds, we first extend the set R with the
current mapping  and with mappings that map the optimization variables to equivalent
concepts or roles of the respective variable mappings in  (line 21) and we afterwards extend the set B of possible mappings for the variables to which the hierarchy optimization
is applicable (getPossibleMappings in line 23). For example, if we just checked a mapping 
that maps a concept variable ?x to the concept A and ?x only occurs positively in the axiom
template, then we add to the set B all mappings that map ?x to a direct subconcept3 of
A (see Algorithm 2 line 4). In the implementation we use a more involved procedure, i.e.,
in order to avoid checking entailment of an instantiated axiom template more than once
with the same mapping, which can be the case with the concept (role) hierarchy traversal
that we perform, we keep track of already processed mappings and check only those that
have not been checked in a previous iteration of the while loop (lines 18 to 26). For ease
of presentation, this is not shown in Algorithm 3. We then repeat the procedure until B is
empty (lines 18 to 26).
For the dynamic ordering, Algorithm 3 has to be changed as follows: We first compute
the number of axiom templates in Atj ; n := |Atj |. We then swap line 5 and line 6, i.e.,
instead of ordering all axiom templates before the loop that evaluates the axiom templates,
we order within the for loop. The function order gets as additional input parameter the
set of currently computed solutions and returns only the next cheapest axiom template
according to the dynamic ordering function. Hence, we have ati := order(Atj , Rj ) instead
of at1 , . . . , atn := order(Atj ). We further insert a line after calling order to remove the
cheapest axiom template from the current component: Atj := Atj \ {ati }. As a result, the
next iteration of the for loop will compute the cheapest axiom template amongst the not
yet evaluated templates until, in the last iteration, we only have one axiom template left.
Algorithm 3 is sound and complete. The soundness and completeness of the algorithm
is based on the following facts:
 The method rewrite (see Definition 13) does not affect the answers to a query q, since
it rewrites axiom templates to templates with the same set of answers.
 The method connectedComponents does not affect the answers of q; it just splits the
query into several components that are evaluated separately and we then take the
cartesian product of the answers.
 The method order does not change the query in any way; it just reorders the axiom
templates.
3. We say that a concept name A is a direct subconcept of a concept name B w.r.t. O, if O |= A  B and
there is no other concept name A such that O |= A  B, O |= A  A and O 6|= A  A . In a similar
way we can define the direct superconcept, the direct subrole and direct superrole.

285

fiKollia & Glimm

 For the actual axiom template evaluation, we iterate over all the templates of the
query by taking into account the mappings that have already been computed from
the evaluation of previous templates and we distinguish between three cases:
1. The axiom template is a simple one and contains unbound variables. We use
specialized reasoner tasks to compute entailed mappings and since we use a
sound and complete reasoner the result is indeed sound and complete.
2. The axiom template does not contain unbound variables. In this case, we simply
check entailment using a sound and complete reasoner.
3. The axiom template is a complex template that has at least one variable unbound.
For variables for which the optimization of Section 6.2 is applicable, we initialize
the variables to /r (/r ) and we traverse the concept/role hierarchy topdown (bottom-up). We prune mappings according to Theorems 1 and 2 in case
a checked mapping does not constitute a solution mapping. In this case, we do
not extend the set of possible mappings B. For variables of axiom templates
to which the hierarchy optimization is not applicable, we check all compatible
mappings. Thus, due to Theorem 1 and 2 the procedure is sound and complete.
Although the above algorithm was implemented in the HermiT reasoner, one can compute the answers of a query using any (hyper)tableau reasoner.

7. Evaluation
We tested the developed optimizations with standard benchmarks and a range of custom
queries that test complex axiom template evaluation over more expressive ontologies. All
experiments were performed on a Mac OS X Lion machine with a 2.53 GHz Intel Core i7
processor and Java 1.6 allowing 1GB of Java heap space. We measure the time for one-off
tasks such as classification separately since such tasks are usually performed before the
system accepts queries. The ontologies and all code required to perform the experiments
are available online (Kollia & Glimm, 2013). The developed system (Glimm & Kollia,
2013), called OWL-BGP, is implemented as a SPARQL Wrapper that can be used with
any reasoner that implements the OWLReasoner interface of the OWL API (Horridge &
Bechhofer, 2009). In Section 7.1 we compare the different ordering strategies that have been
developed on two benchmarks (LUBM and UOBM) that contain queries with variables only
in place of individuals (query atoms). We also show the effect of ordering on LUBM using
some custom queries with simple axiom templates created for SPARQL-DL (Kremen &
Sirin, 2008). In Section 7.2 we show the effect of the proposed optimizations for queries
with complex axiom templates. For the evaluation we have used the HermiT hypertableau
reasoner (Motik, Shearer, Glimm, Stoilos, & Horrocks, 2013). Other reasoners such as
Pellet (Clark & Parsia, 2013a) or Racer Pro (Racer Systems GmbH & Co. KG, 2013) could
equally well be used with our implementation as long as they provide an interface with the
required statistics, i.e., the number of known and possible instances of concepts and roles for
the computation of the cost functions used for query ordering. Without any optimizations,
providing this interface with statistics can easily be realized as described in the current
paper. The presented query ordering techniques can also be used when optimizations such
286

fiOptimizing SPARQL Query Answering over OWL Ontologies

as caching, pseudo model merging techniques, binary instance retrieval, or absorption are
employed. The cost functions might, however, require some adaptation to take the reduction
in the required number of consistency checks into account. For example, Pellet uses binary
instance retrieval, where testing possible instances of a concept A is realized by splitting
the candidate instances into two partitions. For each partition, a single consistency check
is performed. If the consistency check is successful, it is safe to consider all individuals
belonging to the partition as non-instances of the tested concept A. Otherwise, we further
split the partition and process the resulting partitions in the same way. In this case, one
performs one consistency check to potentially determine several (non-)instances of A, which
should be reflected in the cost functions.
It is also worth noting that the TrOWL reasoning framework (Thomas, Pan, & Ren,
2013) started to use our SPARQL wrapper to provide SPARQL support. An adaptation to
also provide statistics is, to the best of our knowledge, still outstanding, although this should
be straightforward. TrOWL is based on two approximate reasoners: one that underapproximates (computation of concept and role instances is sound, but incomplete) (Ren, Pan, &
Zhao, 2010) and one that overapproximates (computation of concept and role instances is
complete, but unsound) (Pan, Thomas, & Zhao, 2009). In such a setting, the underapproximation can straightforwardly be seen as the known instances and the overapproximation
minus the underapproximation as the possible instances.
7.1 Query Ordering
We tested our ordering techniques with the Lehigh University Benchmark (LUBM) (Guo,
Pan, & Heflin, 2005) as a case where no disjunctive information is present and with the
more expressive University Ontology Benchmark (UOBM) (Ma, Yang, Qiu, Xie, Pan, &
Liu, 2006).
We first used the 14 conjunctive ABox queries provided in LUBM. From these, queries
2, 7, 8, 9 are the most interesting ones in our setting since they contain many atoms and
ordering them can have an effect in running time. We tested the queries on LUBM(1,0) and
LUBM(2,0) which contain data for one or two universities respectively, starting from index
0. LUBM(1,0) contains 17,174 individuals and LUBM(2,0) contains 38,334 individuals.
LUBM(1,0) took 19 s to load and 0.092 s for classification and initialization of known and
possible instances of concepts and roles. The clustering approach for concepts took 1 s
and resulted in 16 clusters. The clustering approach for roles lasted 4.9 s and resulted in
17 role successor clusters, 29 role predecessor clusters and 87 role clusters. LUBM(2,0)
took 48.5 s to load and 0.136 s for classification and initialization of known and possible
instances. The clustering approach for concepts took 3.4 s and resulted in 16 clusters. The
clustering approach for roles lasted 16.3 s and resulted in 17 role successor clusters, 31 role
predecessor clusters and 102 role clusters. Table 2 shows the execution time for each of
the four queries for LUBM(1,0) and LUBM(2,0) for four cases: i) when we use the static
algorithm (columns 2 and 6), ii) when we use the dynamic algorithm (columns 3 and 7), iii)
when we use random sampling, i.e., taking half of the individuals that are returned (from
the evaluation of previous query atoms) in each run, to decide about the next cheapest atom
to be evaluated in the dynamic case and iv) using the proposed sampling approach that
is based on clusters constructed from individuals in the queried ontology (columns 4 and
287

fiKollia & Glimm

Q
2
7
8
9

Static
51
25
485
1,099

LUBM(1,0)
Dynamic RSampling
119
390
29
852
644
639
2,935
3,021

CSampling
37
20
551
769

Static
162
70
622
6,108

LUBM(2,0)
Dynamic RSampling
442
1,036
77
2,733
866
631
23,202
14,362

CSampling
153
64
660
3,018

Table 2: Query answering times in milliseconds for LUBM(1,0) and LUBM(2,0) using i) the
static algorithm ii) the dynamic algorithm, iii) 50% random sampling (RSampling),
iv) the constructed individual clusters for sampling (CSampling)

Q

PlansNo

2
7
8
9

336
14
56
336

Chosen Plan Order
Static Dynamic Sampling
2
1
1
1
1
1
1
1
1
173
160
150

Pellet Plan

Worst Plan

51
25
495
1,235

4,930
7,519
1,782
5,388

Table 3: Statistics about the constructed plans and chosen orderings and running times in
milliseconds for the orderings chosen by Pellet and for the worst constructed plans

8). The queries marked with (*) are the queries where the static and dynamic algorithms
result in a different ordering. In Queries 7 and 8 we observe an increase in running
time when the dynamic technique is used (in comparison to the static) which is especially
evident on Query 8 of LUBM(2,0), where the number of individuals in the ontology and
the intermediate result sizes are larger. Dynamic ordering also behaves worse than static
in Queries 2 and 9. This happens because, although the dynamic algorithm chooses a
better ordering than the static algorithm, the intermediate results (that need to be checked
in each iteration to determine the next query atom to be executed) are quite large and
hence the cost of iterating over all possible mappings in the dynamic case far outweighs the
better ordering that is obtained. We also observe that a random sampling for collecting the
ordering statistics in the dynamic case (checking only 50% of individuals in i1 randomly
for detecting the next query atom to be executed) leads to much worse results in most
queries than plain static or dynamic ordering. This happens since random sampling often
leads to the choice of a worse execution order. The use of the cluster based sampling method
performs better than the plain dynamic algorithm in all queries. In Queries 2 and 9, the
gain we have from the better ordering of the dynamic algorithm when sampling is used is
much more evident. This is the case since we use at most one individual from every cluster
for the cost functions computation and the number of clusters is much smaller than the
number of the otherwise tested individuals in each run.
In order to show the effectiveness of our proposed cost functions we compared the
running times of all the valid plans (plans that comply to the connectedness condition of
Definition 10, i.e., plans on which consecutive atoms share at least one common variable)
288

fiOptimizing SPARQL Query Answering over OWL Ontologies

LUBM(3,0) LUBM(4,0) LUBM(5,0) LUBM(6,0) LUBM(7,0) LUBM(8,0) LUBM(9,0)
55,664
78,579
102,368
118,500
144,612
163,552
183,425
Table 4: Number of individuals in LUBM with increasing number of universities
with the running time of the plan chosen by our method. In the following we show the results
for LUBM(1, 0), but the results for LUBM(2,0) are comparable. In Table 3 we show, for
each query, the number of valid plans that were constructed according to Definition 10
(column 2), the order of the plan chosen by the static, dynamic, and cluster based sampling
methods if we order the valid plans by their execution time (columns 3,4,5; e.g., a value
of 2 indicates that the ordering method chose the second best plan), the running time of
HermiT for the plan that was created by Pellet (column 6) as well as the running time of
the worst constructed plan (column 7).
The comparison of our ordering approach with the approach followed by other reasoners
that support conjunctive query answering such as Pellet or Racer Pro is not very straightforward. This is the case because Pellet and Racer have many optimizations for instance
retrieval (Sirin et al., 2007; Haarslev & Moller, 2008), which HermiT does not have. Thus,
a comparison between the execution times of these reasoners and HermiT would not convey
much information about the effectiveness of the proposed query ordering techniques. The
idea of comparing only the orderings computed by other reasoners with those computed by
our methods is also not very informative since the orderings chosen by different reasoners
depend much on the way that queries are evaluated and on the costs of specific tasks in
these reasoners and, hence, are reasoner dependent, i.e., an ordering that is good for one
reasoner and which leads to an efficient evaluation may not be good for another reasoner.
We should note that when we were searching for orderings according to Pellet, we switched
off the simplification optimization that Pellet implements regarding the exploitation of domain and range axioms of the queried ontology for reducing the number of query atoms to
be evaluated (Sirin & Parsia, 2006). This has been done in order to better evaluate the
difference of the plain ordering obtained by Pellet and HermiT since our cost functions take
into account all the query atoms.
We observe that for all queries apart from Query 9 the orderings chosen by our algorithms
are the (near)optimal ones. For Queries 2 and 7, Pellet chooses the same ordering as our
algorithms. For Query 8, Pellet chooses an ordering which, when evaluated with HermiT,
results in higher execution time. For Query 9, our algorithms choose plans from about the
middle of the order over all the valid plans w.r.t. the query execution time, which means that
our algorithms do not perform well in this query. This is because of the greedy techniques
we have used to find the execution plan which take into account only local information to
choose the next query atom to be executed. Interestingly, the use of cluster based sampling
has led to the finding of a better ordering, as we can see from the running time in Table 2
and the better ordering of the plan found with cluster based sampling techniques compared
to static or plain dynamic ordering (Table 3). The ordering chosen by Pellet for Query 9
does also not perform well. We see that, in all queries, the worst running times are many
orders of magnitude greater than the running times achieved by our ordering algorithms.
In general, we observe that in LUBM static techniques are adequate and the use of dynamic
ordering does not improve the execution time much compared to static ordering.
289

fiKollia & Glimm

Q LUBM(3,0) LUBM(4,0) LUBM(5,0) LUBM(6,0) LUBM(7,0) LUBM(8,0) LUBM(9,0)
2
0.35
0.62
1.26
1.71
2.26
3.11
4.18
7
0.11
0.16
0.23
0.32
0.33
0.33
0.40
8
0.77
0.91
1.27
1.29
1.34
1.44
1.65
9
18.49
42.98
85.54
116.88
181.07
235.06
312.71
all
20.64
55.16
90.99
138.84
213.59
241.85
323.15
Table 5: Query answering times in seconds for LUBM with increasing number of universities
Q Static Dynamic CSampling PlansNo
4 13.35
9 186.30
11
0.98
12
0.01
14 94.61
q1 191.07
q2 47.04

13.40
188.58
0.84
0.01
90.60
98.24
22.20

13.41
185.40
1.67
0.01
93.40
100.25
22.51

14
8
30
4
14
6
6

Chosen Plan Order
Pellet
Static Dynamic Sampling
Plan
1
1
1
13.40
1
1
1
636.91
1
1
1
0.98
1
1
1
0.01
2
1
1 > 30 min
2
1
1 > 30 min
2
1
1
22.2

Worst
Plan
271.56
636.91
> 30 min
> 30 min
> 30 min
> 30 min
> 30 min

Table 6: Query answering times in seconds for UOBM (1 university, 3 departments) and
statistics

In order to show the scalability of the system, we next run the LUBM queries with
different numbers of universities, i.e., LUBM(i,0) where i ranges from 3 to 9. Table 4 shows
the number of individuals appearing in each ABox of different university size. The running
times of Queries 2, 7, 8, 9 as well as the running time of all the 14 LUBM queries are
shown in Table 5. The results for LUBM(1,0) and LUBM(2,0) are shown in Table 2. Note
that the results shown are for the case that static ordering is performed. From this table
we see that for all queries, the running time increases when the number of individuals of
the ABox increases, which is reasonable. We observe that query answering over ontologies
is still not as scalable as query answering over databases and this is so, because of the more
expressive schema that has to be taken into account and the fact that we have incomplete
information in contrast to databases where we have complete information.
Unlike LUBM, the UOBM ontology contains disjunctions and the reasoner makes also
nondeterministic derivations. In order to reduce the reasoning time, we removed the nominals and only used the first three departments containing 6,409 individuals. The resulting
ontology took 16 s to load and 0.1 s to classify and initialize the known and possible instances. The clustering approach for concepts took 1.6 s and resulted in 356 clusters. The
clustering approach for roles lasted 6.3 s and resulted in 451 role successor clusters, 390
role predecessor clusters and 4,270 role clusters. We present results for the static and dynamic algorithms on Queries 4, 9, 11, 12 and 14 provided in UOBM, which are the most
interesting ones because they consist of many atoms. Most of these queries contain one
atom with possible instances. As we see from Table 6, static and dynamic ordering show
290

fiOptimizing SPARQL Query Answering over OWL Ontologies

similar performance in Queries 4, 9, 11 and 12. Since the available statistics in this case are
quite accurate, both methods find the optimal plans and the intermediate result set sizes
are small. For both ordering methods, atoms with possible instances for these queries are
executed last. In Query 14, the dynamic algorithm finds a better ordering which results in
comparable performance. The effect that the cluster based sampling technique has on the
running time is not as obvious as in the case of LUBM. This happens because in the current
experiment the intermediate result sizes are not very large and, most importantly, because
the gain obtained due to sampling is in the order of milliseconds whereas the total query
answering times are in the order of seconds obscuring the small improvement in running
time due to sampling. In all queries the orderings that are created by Pellet result in the
same or worse running times than the orderings created by our algorithms.
In order to illustrate when dynamic ordering performs better than static, we also created
the two custom queries:
q1 = { isAdvisedBy(?x,?y), GraduateStudent(?x), Woman(?y) }
q2 = { SportsFan(?x), GraduateStudent(?x), Woman(?x) }
In both queries, P [GraduateStudent], P [Woman] and P [isAdvisedBy] are non-empty, i.e.,
the query concepts and roles have possible instances. The running times for dynamic
ordering are smaller since the more accurate statistics result in a smaller number of possible
instances that have to be checked during query execution. In particular, for the static
ordering, 151 and 41 possible instances have to be checked in query q1 and q2 , respectively,
compared to only 77 and 23 for the dynamic ordering. Moreover, the intermediate results
are generally smaller in dynamic ordering than in static leading to a significant reduction
in the running time of the queries. Interestingly, query q2 could not be answered within the
time limit of 30 minutes when we transformed the three query concepts into a conjunction,
i.e., when we asked for instances of the intersection of the three concepts. This is because for
complex concepts the reasoner can no longer use the information about known and possible
instances and falls back to a more naive way of computing the concept instances. Again, for
the same reasons as before, the sampling techniques have no apparent effect on the running
time of these queries.
For each query of the SPARQL-DL tests issued over LUBM(1,0) (Kremen & Sirin, 2008)
(cf. Table 7), Table 8 shows the running time of the plan chosen by our method (column
2), the number of valid plans, i.e., plans that comply to the connectedness condition of
Definition 10 (column 3), the order of the chosen plan if we order the valid plans by their
execution times (column 4), the running time of HermiT for the plan that was created by
Pellet (column 5) as well as the running time of the worst constructed plan (column 6). The
queries as shown in Table 7 are ordered according to our static ordering algorithm. Since
reasoning for LUBM is deterministic, we use static planning to order the axiom templates.
Dynamic planning does not improve the execution times (actually it makes them worse)
since, as it has been explained before, with only deterministic reasoning we have most of the
important information for ordering from the beginning and the overhead caused by dynamic
ordering results in worse query execution time.
From the results of Table 8 one can observe that for Queries 1, 2, 3, 4 and 8 the
proposed ordering chooses the optimal plan among all valid plans. For Queries 5, 6, 7, 9
and 10 the optimal plan is not chosen according to the proposed cost estimation algorithm.
For Queries 5, 7, 9 and 10 this is due to the greedy techniques we have used for finding in
291

fiKollia & Glimm

GraduateStudent(?x)
?y(?x, ?z)
Course(?w)

1

GraduateStudent(?x)
?y(?x, ?w)
?z(?w)
GraduateCourse  ?z
7
?c  
?c(?x)
teachingAssistantOf(?x, ?y)
takesCourse(?x, ?y)
8
?c  Person
?c(?x)
advisor(?x, ?y)
9
?c  Person
?c(?x)
teachingAssistantOf(?x, ?y)
Course(?y)
10
?p  worksFor
?p(?y, ?w)
?c(?y)
?c  Faculty
advisor(?x, ?y)
GraduateStudent(?x)
memberOf(?x, ?w)
6

?c  Employee
?c(?x)
Student(?x)
undergraduateDegreeFrom(?x, ?y)
3
?y  memberOf
?y(?x, University0)
Person(?x)
4
?y(GraduateStudent5, ?w)
?z(?w)
?z  Course
2

?z  Course
?z(?w)
?y(?x, ?w)
GraduateStudent(?x)

5

Table 7: Queries used for SPARQL-DL tests
Query
1
2
3
4
5
6
7
8
9
10

Chosen Ordering
Time
0.36
0.03
0.05
0.01
26.10
10.49
0.42
0.23
0.19
0.80

PlansNo
2
14
4
4
8
8
14
4
8
812

Chosen Plan
Order
1
1
1
1
5
2
6
1
4
21

Pellet Plan
Time
0.36
0.37
5.44
0.01
0.95
10.49
2.68
0.23
0.19
0.80

Worst Plan
Time
0.58
0.61
5.45
11.46
454.25
499.65
2.68
0.80
0.47
992.77

Table 8: Query answering times in seconds for the queries of Table 7 over LUBM(1,0) and
statistics

each iteration of our ordering algorithm the next cheapest axiom template to be evaluated.
For example, the optimal plan for Query 10 starts with the template GraduateStudent(?x),
which is not the cheapest one according to our cost based technique and then, while moving
292

fiOptimizing SPARQL Query Answering over OWL Ontologies

over connected templates, a different order is chosen than the order chosen by our algorithm.
It turns out that all valid plans beginning with the atom GraduateStudent(?x) lead to better
execution times than the plan chosen by our algorithm resulting in the existence of several
better plans than the chosen one.
For Query 6 we do not find the optimal plan because we have overestimated the cost of
the disjoint axiom template and hence have missed the optimal ordering. Nevertheless, the
chosen plans lead to execution times for all queries that are up to three orders of magnitude
lower than those when the worst plans are chosen. For queries in which the proposed
ordering does not lead to the optimal plan, one has to additionally take into account the
time we saved from not computing the costs for the |q!| possible orderings, which can be
very high. Apart from Queries 4, 6 and 8, we observe that the plans produced by Pellet
are not optimal when evaluated with HermiT. As we have discussed before, this happens
because the statistics created for ordering are reasoner specific and hence a good ordering
for one reasoner may not be good for another reasoner.
7.2 Complex Axiom Template Optimizations
In the absence of suitable standard benchmarks for arbitrary SPARQL queries, we created
a custom set of queries as shown in Tables 10 and 12 for the GALEN and the FBbt XP
ontology, respectively. Systems that fully support the SPARQL Direct Semantics entailment
regime are still under development, which makes it hard to compare our results for these
kinds of queries with other systems.
GALEN is a biomedical ontology. Its expressivity is (Horn-)SHIF and it consists
of 2,748 concepts and 413 abstract roles. FBbt XP is an ontology taken from the Open
Biological Ontologies (OBO) Foundry (OBO Foundry, 2013). It falls into the SHI fragment
of SROIQ and consists of 7,221 concepts and 21 abstract roles. We only consider the
TBox part of FBbt XP since the ABox is not relevant for showing the different effects of
the proposed optimizations on the execution times of the considered queries. GALEN took
3.7 s to load and 11.1 s to classify (concepts and roles), while FBbt XP took 1.5 s to load
and 7.4 s to classify.
The execution times for the queries of Tables 10 and 12 are shown on the right-hand
side of Tables 9 and 11, respectively. We have set a time limit of 30 minutes for each
query. For each query, we tested the execution once without optimizations and once for
each combination of applicable optimizations from Sections 5 and 6. In Tables 9 and 11,
one can also see the number of consistency checks that were performed for the evaluation
of each query and each combination of the applicable optimizations as well as the number
of results of each query. In these tables we have taken the time of the worst ordering of
query atoms for the cases in which the ordering optimization is applicable but not enabled.
Note that only the complex axiom templates require consistency checks to be evaluated;
the simple ones (subsumption axiom templates in this case) need only cache lookups in the
reasoners internal structures since the concepts and roles are already classified.
GALEN Queries: As expected, an increase in the number of variables within an axiom
template leads to a significant increase in the query execution time because the number of
mappings that have to be checked grows exponentially in the number of variables. This can,
in particular, be observed from the difference in execution time between Query 1 and 2.
293

fiKollia & Glimm

Query
1
1
2
2
3
3
3
4
4
4
4
5
5
5

Reordering

Hierarchy
Exploitation

Rewriting

x
x
x

x
x
x
x
x

x
x
x
x
x

Consistency
Checks
2,750
50
1,141,250
1,291

x
x

19,250
3,073

x
x
x

16,135
197
1,883
1,883

x

Time

AnswersNo

1.68
0.18
578.98
9.85
>30 min
102.37
2.69
> 30 min
> 30 min
7.68
1.12
> 30 min
0.67
0.8

10
10
214
214
2,816
2,816

51
51
4,392
4,392

Table 9: Query answering times in seconds for the queries of Table 10 with and without
optimizations
1
Infection  hasCausalLinkTo.?x
2
Infection  ?y.?x
3
?x  Infection  hasCausalAgent.?y
4 NAMEDLigament  NAMEDInternalBodyPart  ?x
?x  hasShapeAnalagousTo?y  ?z.linear
5
?x  NonNormalCondition
?z  ModifierAttribute
Bacterium  ?z.?w
?y  StatusAttribute
?w  AbstractStatus
?x  ?y.Status
Table 10: Sample complex queries for the GALEN ontology
From these two queries, it is evident that the use of the hierarchy exploitation optimization
leads to a decrease in execution time of up to two orders of magnitude. Query 3 can only be
completed in the time limit if at least the query rewriting optimization is enabled. We can
get an improvement of up to three orders of magnitude in this query, by using rewriting in
combination with the hierarchy exploitation. Query 4 can only be completed in the given
time limit if at least reordering and rewriting is enabled. Rewriting splits the first axiom
template into the following two simple axiom templates, which are evaluated much more
efficiently:
NAMEDLigament  NAMEDInternalBodyPart
294

and

NAMEDLigament ?x

fiOptimizing SPARQL Query Answering over OWL Ontologies

After the rewriting, the ordering optimization has an even more pronounced effect since
both rewritten axiom templates can be evaluated with a simple cache lookup. Without
ordering, the complex axiom template could be executed before the simple ones, which
leads to the inability of answering the query within the time limit of 30 min. Without
a good ordering, Query 5 can also not be answered within the time limit. The ordering
chosen by our algorithm is shown below. Note that the query consists of two connected
components: one for the axioms containing ?z and ?w and another one for the axioms
containing ?x and ?y.
?z  ModifierAttribute
?w  AbstractStatus
Bacterium  ?z.?w
?y  StatusAttribute
?x  NonNormalCondition
?x  ?y.Status
In this query, the hierarchy exploitation optimization does not improve the execution time
since, due to the chosen ordering, the variables on which the hierarchy optimization can
be applied, are already bound when it comes to the evaluation of the complex templates.
Hence, the running times with and without the hierarchy exploitation are similar. The
number of consistency checks is significantly lower than the number of answers because the
overall results are computed by taking the cartesian products of the results for the two
connected components. Interestingly, for queries with complex axiom templates, it does
not make sense to require that the next axiom template to evaluate shares a variable with
the previously evaluated axiom templates, as in the case of simple axiom templates. For
example, if we would require that, the first connected component of the query would be
executed in the following order:
?z  ModifierAttribute
Bacterium  ?z.?w
?w  AbstractStatus
this results in 294,250 instead of 1,498 consistency checks since we no longer use a cheap
cache look-up check to determine the bindings for ?w, but first iterate over all possible
?w bindings and check entailment of the complex axiom template and then reduce the
computed candidates when processing the last axiom template.
Although our optimizations can significantly improve the query execution time, the
required time can still be quite high. In practice, it is, therefore, advisable to add as many
restrictive axiom templates (axiom templates which require only cache lookups) for query
variables as possible. For example, the addition of ?y  Shape to Query 4 reduces the
runtime from 1.12 s to 0.65 s. We observe, as expected, that the execution time for each
query and applicable optimization is analogous to the number of consistency checks that
are performed for the evaluation of the query.
FBbt XP Queries: For Queries 1, 2, 3, 5 and 6, on which the ordering optimization
is applicable, we observe a decrease in execution time up to two orders of magnitude when
295

fiKollia & Glimm

Query

Reordering

1
1
1
2
2
2
3
3
3
4
4
5
5
5
5
6
6
6
6

x
x
x
x
x
x

Hierarchy
Exploitation

Rewriting

x
x

11,262
14,446

x
x

12,637
72,230

x
x

54,186
166,129
1335
166,129
21,669
907
3

x
x
x
x
x
x

x
x
x
x
x

Consistency
Checks
151,683

x
x
x

43,338
32,490

Time

AnswersNo

44.13
> 30 min
5.64
37.38
> 30 min
39.20
357.59
> 30 min
252.41
486.81
17.03
457.84
19.68
11.74
0.01
> 30 min
183.66
> 30 min
152.38

7,243
7,243
7,224
7,224
188
188
68
68
0
0
0
0
43,338
43,338

Table 11: Query answering times in seconds for the queries of Table 12 with and without
optimizations

1 ?x  part of.?y
?x  FBbt 00005789
2 ?y  part of
?x  ?y.FBbt 00001606
3 ?x  ?y.FBbt 00025990
?y  overlaps

4 FBbt 00001606  ?y.?x
5 FBbt 00001606  ?y.?x
?y  develops from
6
?y  FBbt 00001884
?p  part of
?x  ?p.?y  ?w

Table 12: Sample complex queries for the FBbt XP ontology
the ordering optimization is used. The ordering optimization is important for answering
Queries 1, 2 and 3 within the time limit. For all queries, the additional use of the hierarchy
exploitation optimization leads to an improvement of up to three orders of magnitude.
We observe that in some queries the effect of the hierarchy exploitation is more profound
than in others. More precisely, the smaller the ratio of the result size to the number of
consistency checks without the hierarchy optimization, the more pronounced is the effect
when enabling this optimization. In other words, when more tested mappings are indeed
solutions, one can prune fewer parts of the hierarchy since pruning can only be performed
when we find a non-solution. In Query 2, we even observe a slight increase in running
296

fiOptimizing SPARQL Query Answering over OWL Ontologies

time when the hierarchy optimization is used. This is because the optimization can only
prune few candidate mappings, which does not outweigh the overhead caused by maintaining
information about which hierarchy parts have already been tested. In Query 6, the rewriting
optimization is important to answer the query within the time limit. When all optimizations
are enabled, the number of consistency checks is less than the result size (32,490 versus
43,338) since only the complex axiom template requires consistency checks.

8. Related Work
There is not yet a standardized and commonly implemented query language for OWL ontologies. Several of the widely deployed systems support, however, some query language.
Pellet supports SPARQL-DL (Sirin & Parsia, 2007), which is a subset of SPARQL, adapted
to work with OWLs Direct Semantics. The kinds of SPARQL queries that are supported in
SPARQL-DL are those that can directly be mapped to reasoner tasks. Therefore, SPARQLDL can be understood as queries that only use simple axiom templates in our terminology.
Similarly, KAON2 (Hustadt, Motik, & Sattler, 2004) supports SPARQL queries, but restricted to ABox queries/conjunctive instance queries. To the best of our knowledge, there
are no publications that describe any ordering strategies for KAON2. Racer Pro (Haarslev
& Moller, 2001) has a proprietary query language, called nRQL (Haarslev et al., 2004),
which allows for queries that go beyond ABox queries, e.g., one can retrieve sub- or superconcepts of a given concept. TrOWL (Thomas et al., 2013) is another system that supports
SPARQL queries, but the reasoning in TrOWL is approximate, i.e., an OWL DL ontology
is rewritten into an ontology that uses a less expressive language before reasoning is applied (Thomas, Pan, & Ren, 2010). TrOWL is based on the SPARQL framework presented
here, but instead of using HermiT as background reasoner, it uses its approximate reasoners for the OWL 2 EL and OWL 2 QL profiles. Furthermore, there are systems such as
QuOnto (Acciarri, Calvanese, De Giacomo, Lembo, Lenzerini, Palmieri, & Rosati, 2013) or
Requiem (Perez-Urbina, Motik, & Horrocks, 2013), which support profiles of OWL 2, and
which support conjunctive queries, e.g., written in SPARQL syntax, but with proper nondistinguished variables. Of the systems that support all of OWL 2 DL, only Pellet supports
non-distinguished variables as long as they are not used in cycles, since decidability of cyclic
conjunctive queries is to the best of our knowledge still an open problem.
The problem of finding good orderings for the templates of a query issued over an ontology has already been preliminarily studied (Sirin & Parsia, 2006; Kremen & Sirin, 2008;
Haarslev & Moller, 2008). Similarly to our work, Sirin and Parsia as well as Kremen and
Sirin exploit reasoning techniques and information provided by reasoner models to create
statistics about the cost and the result size of axiom template evaluations within execution
plans. A difference is that they use cached models for cheaply finding obvious concept
and role (non-)instances, whereas in our case we do not cache any model or model parts.
Instead we process the pre-model constructed for the initial ontology consistency check and
extract the known and possible instances of concepts and roles from it. We subsequently
use this information to create and update the query atom statistics. Moreover, Sirin and
Parsia and Kremen and Sirin compare the costs of complete execution plans after heuristically reducing the huge number of possible complete plans  and choose the one that is
most promising before the beginning of query execution. This is different from our cheap
297

fiKollia & Glimm

greedy algorithm that finds, at each iteration, the next most promising axiom template.
Our experimental study shows that this is equally effective as the investigation of all possible execution orders. Moreover, in our work we have additionally used dynamic ordering
combined with clustering techniques, apart from static ones, and have shown that these
techniques lead to better performance particularly in ontologies that contain disjunctions
and do now allow for purely deterministic reasoning.
Haarslev and Moller discuss by means of an example the ordering criteria they use
to find efficient query execution plans in Racer Pro. In particular, they use traditional
database cost based optimization techniques, which means that they take into account only
the cardinality of concept and role atoms to decide about the most promising ordering.
As previously discussed, this can be inadequate especially for ontologies with disjunctive
information.
A significant amount of work on the estimation of cost metrics and the search for optimal
orders for evaluating joins has been performed in the context of databases. As discussed
in Section 3, in databases, cost formulas are defined that estimate the CPU and I/O costs
(similar to our reasoning costs) and the number of returned tuples (similar to our result
sizes). These estimates are used to find good join orders. The System R query optimizer, for
example, is among the first works to use extended statistics and a novel dynamic programming algorithm to find effective (minimal) join orders of query atoms (Selinger, Astrahan,
Chamberlin, Lorie, & Price, 1979). A heuristic similar to ours (for the case of conjunctive
instance queries) is used in this work, according to which the join order permutations are
reduced by avoiding Cartesian products of result sets of query atoms. Regarding join order selection, apart from dynamic programming, also other algorithmic paradigms based on
branch-and-bound or simulated annealing have, since then, been presented in the literature.
Dynamic ordering has also been explored in the literature in the context of adaptive query
processing techniques (Gounaris, Paton, Fernandes, & Sakellariou, 2002), which have been
proposed to overcome the problems caused by the lack of necessary statistics, good selectivity estimates, knowledge for the runtime mappings of a query at compile time. These
techniques take into account changes that happen to the evaluation environment at runtime
and modify the execution plan at runtime (i.e., they change the used operators for joins or
the order in which the (remaining) query atoms are evaluated).

9. Conclusions
In the current paper, we presented a sound and complete query answering algorithm and
novel optimizations for the OWL Direct Semantics entailment regime of SPARQL 1.1. Our
prototypical query answering system combines existing tools such as ARQ, the OWL API,
and the HermiT OWL reasoner. Apart from the query ordering optimizationwhich uses
(reasoner dependent) statistics provided by HermiTthe system is independent of the reasoner used, and could employ any reasoner that supports the OWL API.
We propose two cost-based ordering strategies for finding (near-)optimal execution orders for conjunctive instance queries. The cost formulas are based on information extracted
from models of a reasoner (in our case HermiT). We show through an experimental study
that static techniques are quite adequate for ontologies in which reasoning is deterministic.
When reasoning is nondeterministic, however, dynamic techniques often perform better.
298

fiOptimizing SPARQL Query Answering over OWL Ontologies

The use of cluster based sampling techniques can improve the performance of the dynamic
algorithm when the intermediate result sizes of queries are sufficiently large, whereas random sampling is not beneficial and often leads to suboptimal query execution plans.
The presented approach can be used to find answers to queries issued over SROIQ
ontologies. Since it is based on entailment checking for finding answers to conjunctive
instance queries it is not as scalable as other techniques, such as query rewriting, which
are applied to ontologies of lower expressivity, such as DL-Lite. In other words, there is
a trade-off between scalability and ontology expressivity and one needs to consider if it is
more important for ones application to use a more scalable query answering system with a
less expressive ontology or a less scalable system with a more expressive ontology.
The module for ordering is based on the extraction of statistics from a reasoner model,
which is computed off-line. Any update of the ontology ABox would then cause the construction of a new model from scratch and the consequent recompilation of known and
possible instances of concepts and roles unless an incremental reasoner is used. An incremental reasoner could, for example, find modules of the pre-model that are affected by the
update and recompute only model parts. One could then also incrementally update the
statistics that are used for ordering. To the best of our knowledge, OWL DL reasoners only
partially support incremental reasoning and we have not considered this case in the current
paper.
For queries that go beyond conjunctive instance queries we further provide optimizations such as rewriting into equivalent, but simpler queries. Another highly effective and
frequently applicable optimization prunes the number of candidate solutions that have to
be checked by exploiting the concept and role hierarchies. One can, usually, assume that
these hierarchies are computed before a system accepts queries. Our empirical evaluation
shows that this optimization can reduce the query evaluation times up to three orders of
magnitude.

Acknowledgments
This work was done within the Transregional Collaborative Research Centre SFB/TRR
62 A Companion-Technology for Cognitive Technical Systems funded by the German
Research Foundation (DFG).

References
Acciarri, A., Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Palmieri, M., &
Rosati, R. (2013). QuOnto. Available at http://www.dis.uniroma1.it/quonto/.
Beckett, D., Berners-Lee, T., Prudhommeaux, E., & Carothers, G. (Eds.). (19 February
2013). Turtle  Terse RDF Triple Language. W3C Candidate Recommendation.
Available at http://www.w3.org/TR/turtle/.
Brickley, D., & Guha, R. V. (Eds.). (10 February 2004). RDF Vocabulary Description
Language 1.0: RDF Schema. W3C Recommendation. Available at http://www.w3.
org/TR/rdf-schema/.
299

fiKollia & Glimm

Broekstra, J., & Kampman, A. (2006). An RDF query and transformation language. In
Staab, S., & Stuckenschmidt, H. (Eds.), Semantic Web and Peer-to-Peer, pp. 2339.
Springer.
Calvanese, D., Giacomo, G. D., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning and efficient query answering in description logics: The DL-Lite family.
Journal of Automated Reasoning, 39 (3), 385429.
Clark & Parsia (2013a). Pellet. Available at http://clarkparsia.com/pellet/.
Clark & Parsia (2013b). Stardog. Available at http://stardog.com.
Glimm, B., Horrocks, I., Motik, B., Shearer, R., & Stoilos, G. (2012). A novel approach to
ontology classification. Journal of Web Semantics: Science, Services and Agents on
the World Wide Web, 14, 84101. Special Issue on Dealing with the Messiness of the
Web of Data.
Glimm, B., & Kollia, I. (2013). OWL-BGP. Available at http://code.google.com/p/owl-bgp/.
Glimm, B., & Krotzsch, M. (2010). SPARQL beyond subgraph matching. In Proceedings
of the 9th International Semantic Web Conference (ISWC10), Vol. 6414 of Lecture
Notes in Computer Science, pp. 241256. Springer.
Glimm, B., & Ogbuji, C. (2013). SPARQL 1.1 entailment regimes. W3C Recommendation.
Available at http://www.w3.org/TR/sparql11-entailment/.
Gounaris, A., Paton, N. W., Fernandes, A. A., & Sakellariou, R. (2002). Adaptive query
processing: A survey. In In 19th BNCOD, pp. 1125. Springer.
Guo, Y., Pan, Z., & Heflin, J. (2005). LUBM: A benchmark for OWL knowledge base
systems. Journal of Web Semantics, 3 (2-3), 158182.
Haarslev, V., & Moller, R. (2001). Racer system description. In Gor, R., Leitsch, A., & Nipkow, T. (Eds.), Proceedings of the 1st International Joint Conference on Automated
Reasoning (IJCAR01), Vol. 2083 of LNCS, pp. 701705. Springer.
Haarslev, V., & Moller, R. (2008). On the scalability of description logic instance retrieval.
Journal of Automated Reasoning, 41 (2), 99142.
Haarslev, V., Moller, R., & Wessel, M. (2004). Querying the semantic web with Racer
+ nRQL. In Proceedings of the KI-2004 International Workshop on Applications of
Description Logics.
Harris, S., & Seaborne, A. (Eds.). (2013). SPARQL 1.1 Query Language. W3C Recommendation. Available at http://www.w3.org/TR/sparql11-query/.
Hayes, P. (Ed.). (10 February 2004). RDF Semantics. W3C Recommendation. Available
at http://www.w3.org/TR/rdf-mt/.
Hitzler, P., Krotzsch, M., & Rudolph, S. (2009). Foundations of Semantic Web Technologies.
Chapman & Hall/CRC.
Horridge, M., & Bechhofer, S. (2009). The OWL API: A Java API for working with OWL
2 ontologies. In Patel-Schneider, P. F., & Hoekstra, R. (Eds.), Proceedings of the
OWLED 2009 Workshop on OWL: Experiences and Directions, Vol. 529 of CEUR
Workshop Proceedings. CEUR-WS.org.
300

fiOptimizing SPARQL Query Answering over OWL Ontologies

Horrocks, I., Kutz, O., & Sattler, U. (2006). The even more irresistible SROIQ. In Doherty, P., Mylopoulos, J., & Welty, C. A. (Eds.), Proceedings of the 10th International
Conference on Principles of Knowledge Representation and Reasoning (KR06), pp.
5767. AAAI Press.
Hustadt, U., Motik, B., & Sattler, U. (2004). Reducing SHIQ description logic to disjunctive datalog programs. In Proceedings of the 9th International Conference on
Principles of Knowledge Representation and Reasoning (KR04), pp. 152162. AAAI
Press.
Ioannidis, Y. E., & Christodoulakis, S. (1993). Optimal histograms for limiting worst-case
error propagation in the size of join results. ACM Transactions on Database Systems,
18 (4), 709748.
Kazakov, Y. (2008). RIQ and SROIQ are harder than SHOIQ. In Brewka, G., & Lang, J.
(Eds.), Proceedings of the 11th International Conference on Principles of Knowledge
Representation and Reasoning (KR08), pp. 274284. AAAI Press.
Kollia, I., & Glimm, B. (2013). Evaluation sources. Available at http://code.google.com/
p/query-ordering/.
Kontchakov, R., Lutz, C., Toman, D., Wolter, F., & Zakharyaschev, M. (2010). The combined approach to query answering in DL-Lite. In Lin, F., & Sattler, U. (Eds.),
Proceedings of the 12th International Conference on Principles of Knowledge Representation and Reasoning (KR10). AAAI Press.
Kremen, P., & Sirin, E. (2008). SPARQL-DL implementation experience. In Clark, K.,
& Patel-Schneider, P. F. (Eds.), Proceedings of the 4th OWLED Workshop on OWL:
Experiences and Directions Washington, Vol. 496 of CEUR Workshop Proceedings.
CEUR-WS.org.
Ma, L., Yang, Y., Qiu, Z., Xie, G., Pan, Y., & Liu, S. (2006). Towards a complete OWL
ontology benchmark. In The Semantic Web: Research and Applications, Lecture Notes
in Computer Science, chap. 12, pp. 125139. Springer.
Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (Eds.). (11
December 2012a). OWL 2 Web Ontology Language: Profiles. W3C Recommendation.
Available at http://www.w3.org/TR/owl2-profiles/.
Motik, B., Patel-Schneider, P. F., & Cuenca Grau, B. (Eds.). (11 December 2012b). OWL 2
Web Ontology Language: Direct Semantics. W3C Recommendation. Available at
http://www.w3.org/TR/owl2-direct-semantics/.
Motik, B., Shearer, R., Glimm, B., Stoilos, G., & Horrocks, I. (2013). HermiT. Available
at http://www.hermit-reasoner.com/.
Motik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau reasoning for description logics.
Journal of Artificial Intelligence Research, 36, 165228.
OBO Foundry (2013). The open biological and biomedical ontologies. Available at http:
//www.obofoundry.org/.
Oracle (2013). Oracle database documentation library 11g release 2. Available at http:
//www.oracle.com/pls/db112/homepage.
301

fiKollia & Glimm

Pan, J. Z., Thomas, E., & Zhao, Y. (2009). Completeness guaranteed approximation for owl
dl query answering. In Proceedings of the 2009 International Workshop on Description
Logics (DL09).
Patel-Schneider, P. F., & Motik, B. (Eds.). (11 December 2012). OWL 2 Web Ontology
Language: Mapping to RDF Graphs. W3C Recommendation. Available at http:
//www.w3.org/TR/owl2-mapping-to-rdf/.
Perez-Urbina, H., Motik, B., & Horrocks, I. (2010). Tractable query answering and rewriting
under description logic constraints. Journal of Applied Logic, 8 (2), 186209.
Perez-Urbina, H., Motik, B., & Horrocks, I. (2013). Requiem. Available at http://www.
comlab.ox.ac.uk/projects/requiem/home.html.
Prudhommeaux, E., & Seaborne, A. (Eds.). (15 January 2008). SPARQL Query Language for RDF. W3C Recommendation. Available at http://www.w3.org/TR/
rdf-sparql-query/.
Racer Systems GmbH & Co. KG (2013).
racer-systems.com.

RacerPro 2.0.

Available at http://www.

Ren, Y., Pan, J. Z., & Zhao, Y. (2010). Soundness preserving approximation for tbox
reasoning. In Proceedings of the 25th National Conference on Artificial Intelligence
(AAAI10). AAAI Press.
Rodriguez-Muro, M., & Calvanese, D. (2012). High performance query answering over
dl-lite ontologies. In Proc. of the 13th Int. Conf. on the Principles of Knowledge
Representation and Reasoning (KR 2012), pp. 308318.
Schneider, M. (Ed.). (11 December 2012). OWL 2 Web Ontology Language: RDFBased Semantics. W3C Recommendation. Available at http://www.w3.org/TR/
owl2-rdf-based-semantics/.
Seaborne, A. (9 January 2004). RDQL  A Query Language for RDF. W3C Member
Submission. Available at http://www.w3.org/Submission/RDQL/.
Selinger, P. G., Astrahan, M. M., Chamberlin, D. D., Lorie, R. A., & Price, T. G. (1979).
Access path selection in a relational database management system. In Bernstein,
P. A. (Ed.), Proceedings of the 1979 ACM SIGMOD International Conference on
Management of Data, Boston, Massachusetts, May 30 - June 1, pp. 2334. ACM.
Sirin, E., Cuenca Grau, B., & Parsia, B. (2006). From wine to water: Optimizing description logic reasoning for nominals. In Doherty, P., Mylopoulos, J., & Welty, C. A.
(Eds.), Proceedings of the 10th International Conference on Principles of Knowledge
Representation and Reasoning (KR06), pp. 9099. AAAI Press.
Sirin, E., & Parsia, B. (2006). Optimizations for answering conjunctive ABox queries: First
results. In Proceedings of the 2006 International Workshop on Description Logics
(DL06), Vol. 189 of CEUR Workshop Proceedings. CEUR-WS.org.
Sirin, E., & Parsia, B. (2007). SPARQL-DL: SPARQL query for OWL-DL. In Golbreich,
C., Kalyanpur, A., & Parsia, B. (Eds.), Proceedings of the OWLED 2007 Workshop on
OWL: Experiences and Directions, Vol. 258 of CEUR Workshop Proceedings. CEURWS.org.
302

fiOptimizing SPARQL Query Answering over OWL Ontologies

Sirin, E., Parsia, B., Grau, B. C., Kalyanpur, A., & Katz, Y. (2007). Pellet: A practical
OWL-DL reasoner. Journal of Web Semantics, 5 (2), 5153.
Steinbrunn, M., Moerkotte, G., & Kemper, A. (1997). Heuristic and randomized optimization for the join ordering problem. VLDB Journal, 6, 191208.
Stocker, M., Seaborne, A., Bernstein, A., Kiefer, C., & Reynolds, D. (2008). SPARQL basic
graph pattern optimization using selectivity estimation. In Proceedings of the 17th
International Conference on World Wide Web (WWW08), pp. 595604. ACM.
The Apache Software Foundation (2013). Apache jena. Available at http://jena.apache.org.
Thomas, E., Pan, J. Z., & Ren, Y. (2010). TrOWL: Tractable OWL 2 reasoning infrastructure. In Proceedings of the Extended Semantic Web Conference (ESWC10).
Thomas, E., Pan, J. Z., & Ren, Y. (2013). TrOWL. Available at http://trowl.eu.
Tsarkov, D., Horrocks, I., & Patel-Schneider, P. F. (2007). Optimizing terminological reasoning for expressive description logics. Journal of Automated Reasoning, 39 (3), 277316.

303

fiJournal of Artificial Intelligence Research 48 (2013) 583-634

Submitted 4/13; published 11/13

Protecting Moving Targets with Multiple Mobile Resources
Fei Fang
Albert Xin Jiang
Milind Tambe

feifang@usc.edu
jiangx@usc.edu
tambe@usc.edu

University of Southern California
Los Angeles, CA 90089 USA

Abstract
In recent years, Stackelberg Security Games have been successfully applied to solve resource allocation and scheduling problems in several security domains. However, previous
work has mostly assumed that the targets are stationary relative to the defender and the
attacker, leading to discrete game models with finite numbers of pure strategies. This paper
in contrast focuses on protecting mobile targets that leads to a continuous set of strategies
for the players. The problem is motivated by several real-world domains including protecting ferries with escort boats and protecting refugee supply lines. Our contributions include:
(i) A new game model for multiple mobile defender resources and moving targets with a
discretized strategy space for the defender and a continuous strategy space for the attacker.
(ii) An efficient linear-programming-based solution that uses a compact representation for
the defenders mixed strategy, while accurately modeling the attackers continuous strategy using a novel sub-interval analysis method. (iii) Discussion and analysis of multiple
heuristic methods for equilibrium refinement to improve robustness of defenders mixed
strategy. (iv) Discussion of approaches to sample actual defender schedules from the defenders mixed strategy. (iv) Detailed experimental analysis of our algorithms in the ferry
protection domain.

1. Introduction
In the last few years, game-theoretic decision support systems have been successfully deployed in several domains to assist security agencies (defenders) in protecting critical infrastructure such as ports, airports and air-transportation infrastructure (Tambe, 2011; Gatti,
2008; Marecki, Tesauro, & Segal, 2012; Jakob, Vanek, & Pechoucek, 2011). These decision support systems assist defenders in allocating and scheduling their limited resources
to protect targets from adversaries. In particular, given limited security resources it is not
possible to cover or secure all target at all times; and simultaneously, because the attacker can observe the defenders daily schedules, any deterministic schedule by the defender
can be exploited by the attacker (Paruchuri, Tambe, Ordonez, & Kraus, 2006; Kiekintveld,
Islam, & Kreinovich, 2013; Vorobeychik & Singh, 2012; Conitzer & Sandholm, 2006).
One game-theoretic model that has been deployed to schedule security resources in such
domains is that of a Stackelberg game between a leader (the defender) and a follower (the
attacker). In this model, the leader commits to a mixed strategy, which is a randomized
schedule specified by a probability distribution over deterministic schedules; the follower
then observes the distribution and plays a best response (Korzhyk, Conitzer, & Parr, 2010).
Decision-support systems based on this model have been successfully deployed, including
ARMOR at the LAX airport (Pita, Jain, Marecki, Ordonez, Portway, Tambe, Western,
c
2013
AI Access Foundation. All rights reserved.

fiFang, Jiang, & Tambe

Paruchuri, & Kraus, 2008), IRIS for the US Federal Air Marshals service (Tsai, Rathi,
Kiekintveld, Ordonez, & Tambe, 2009), and PROTECT for the US Coast Guard (Shieh,
An, Yang, Tambe, Baldwin, DiRenzo, Maule, & Meyer, 2012).
Most previous work on game-theoretic models for security has assumed either stationary
targets such as airport terminals (Pita et al., 2008), or targets that are stationary relative to
the defender and the attacker, e.g., trains (Yin, Jiang, Johnson, Kiekintveld, Leyton-Brown,
Sandholm, Tambe, & Sullivan, 2012) and planes (Tsai et al., 2009), where the players can
only move along with the targets to protect or attack them). This stationary nature leads
to discrete game models with finite numbers of pure strategies. In this paper we focus
on security domains in which the defender needs to protect a mobile set of targets. The
attacker can attack these targets at any point in time during their movement, leading to a
continuous set of strategies. The defender can deploy a set of mobile escort resources (called
patrollers for short) to protect these targets. We assume the game is zero-sum, and allow
the values of the targets to vary depending on their locations and time. The defenders
objective is to schedule the mobile escort resources to minimize attackers expected utility.
We call this problem Multiple mobile Resources protecting Moving Targets (MRMT).
The first contribution of this paper is a novel game model for MRMT called MRMTsg .
MRMTsg is an attacker-defender Stackelberg game model with a continuous set of strategies for the attacker. In contrast, while the defenders strategy space is also continuous, we
discretize it in MRMTsg for three reasons. Firstly, if we let the defenders strategy space
to be continuous, the space of mixed strategies for the defender would then have infinite
dimensions, which makes exact computation infeasible. Secondly, in practice, the patrollers
are not able to have such fine-grained control over their vehicles, which makes the actual
defenders strategy space effectively a discrete one. Finally, the discretized defender strategy space is a subset of the original continuous defender strategy space, so the optimal
solution calculated under our formulation is a feasible solution in the original game and
gives a lower-bound guarantee for the defender in terms of expected utility for the original continuous game. On the other hand, discretizing the attackers strategy space can be
highly problematic as we will illustrate later in this paper. In particular, if we deploy a
randomized schedule for the defender under the assumption that the attacker could only
attack at certain discretized time points, the actual attacker could attack at some other
time point, leading to a possibly worse outcome for the defender.
Our second contribution is CASS (Solver for Continuous Attacker Strategies), an efficient
linear program to exactly solve MRMTsg . Despite discretization, the defender strategy
space still has an exponential number of pure strategies. We overcome this shortcoming by
compactly representing the defenders mixed strategies as marginal probability variables.
On the attacker side, CASS exactly and efficiently models the attackers continuous strategy
space using sub-interval analysis, which is based on the observation that given the defenders
mixed strategy, the attackers expected utility is a piecewise-linear function. Along the way
to presenting CASS, we present DASS (Solver for Discretized Attacker Strategies), which
finds minimax solutions for MRMTsg games while constraining the attacker to attack at
discretized time points. For clarity of exposition we first derive DASS and CASS for the
case where the targets move on a one-dimensional line segment. We later show that DASS
and CASS can be extended to the case where targets move in a two-dimensional space.
584

fiProtecting Moving Targets with Multiple Mobile Resources

Our third contribution is focused on equilibrium refinement. Our game has multiple
equilibria, and the defender strategy found by CASS can be suboptimal with respect to uncertainties in the attackers model, e.g., if the attacker can only attack during certain time
intervals. We present two heuristic equilibrium refinement approaches for this game. The
first, route-adjust, iteratively computes a defender strategy that dominates earlier strategies. The second, flow-adjust, is a linear-programming-based approach. Our experiments
show that flow-adjust is computationally faster than route-adjust but route-adjust is more
effective in selecting robust equilibrium strategies.
Additionally, we provide several sampling methods for generating practical patrol routes
given the defender strategy in compact representation. Finally we present detailed experimental analyses of our algorithm in the ferry protection domain. CASS has been deployed
by the US Coast Guard since April 2013.
The rest of the article is organized as follows: Section 2 provides our problem statement.
Section 3 presents the MRMTsg model and an initial formulation of the DASS and CASS for
a one-dimensional setting. Section 4 discusses equilibrium refinement, followed by Section
5 which gives the generalized formulation of DASS and CASS for two-dimensional settings.
Section 6 describes how to sample a patrol route and Section 7 provides experimental
results in the ferry protection domain. Section 8 discusses related work, followed by Section
9, which provides concluding remarks, and Section 10, which discusses future work. At the
end of the article, Appendix A provides a table listing all the notations used in the article,
and Appendix B provides the detailed calculation for finding the intersection points in the
2-D case.

2. Problem Statement
One major example of the practical domains motivating this paper is the problem of protecting ferries that carry passengers in many waterside cities. Packed with hundreds of
passengers, these may present attractive targets for an attacker. For example, the attacker
may ram a suicide boat packed with explosives into the ferry as happened with attacks on
French supertanker Limburg and USS Cole (Greenberg, Chalk, & Willis, 2006). In this
case, the intention of the attacker can only be detected once he gets very close to the ferry.
Small, fast and well-armed patrol boats (patrollers) can provide protection to the ferries
(Figure 1(a)), by detecting the attacker and stopping him with the armed weapons. However, there are often limited numbers of patrol boats, i.e., they cannot protect the ferries
at all times at all locations. We first focus on the case where ferries and patrol boats move
in a one-dimensional line segment (this is a realistic setting and also simplifies exposition);
we will discuss the two-dimensional case in Section 5.
2.1 Domain Description
In this problem, there are L moving targets, F1 , F2 , ..., FL . We assume that these targets
move along a one-dimensional domain, specifically a straight line segment linking two terminal points which we will name A and B. This is sufficient to capture real-world domains
such as ferries moving back-and-forth in a straight line between two terminals as they do
in many ports around the world; an example is the green line shown in Figure 1(b). We
will provide an illustration of our geometric formulation of the problem in Figure 2.1. The
585

fiFang, Jiang, & Tambe

(a)

(b)

Figure 1: (a) Protecting ferries with patrol boats; (b) Part of the map of New York Harbor Commuter Ferry Routes. The straight line linking St. George Terminal and
Whitehall Terminal indicates a public ferry route run by New York City Department of Transportation.

targets have fixed daily schedules. The schedule of each target can be described as a continuous function Sq : T  D where q = 1, ..., L is the index of the target, T = [0, 1] is a
continuous time interval (e.g., representing the duration of a typical daily patrol shift) and
D = [0, 1] is the continuous space of possible locations (normalized) with 0 corresponding
to terminal A and 1 to terminal B. Thus Sq (t) denotes the position of the target Fq at a
specified time t. We assume Sq is piecewise linear.
The defender has W mobile patrollers that can move along D to protect the targets,
denoted as P1 , P2 , ..., PW . Although capable of moving faster than the targets, they have a
maximum speed of vm . While the defender attempts to protect the targets, the attacker will
choose a certain time and a certain target to attack. (In the rest of the paper, we denote the
defender as she and the attacker as he). The probability of attack success depends on
the positions of the patrollers at that time. Specifically, each patroller can detect and try
to intercept anything within the protection radius re but cannot detect the attacker prior
to that radius. Thus, a patroller protects all targets within her protective circle of radius
re (centered at her current position), as shown in Figure 2.1.
















Figure 2: An example with three targets (triangles) and two patrollers (squares). The
protective circles of the patrollers are shown with protection radius re . A patroller
protects all targets in her protective circle. Patroller P1 is protecting F2 and P2
is protecting F3 .

586

fiProtecting Moving Targets with Multiple Mobile Resources

Symmetrically, a target is protected by all patrollers whose protective circles can cover
it. If the attacker attacks a protected target, then the probability of successful attack is a
decreasing function of the number of patrollers that are protecting the target. Formally, we
use a set of coefficients {CG } to describe the strength of the protection.
Definition 1. Let G  {1, ..., W } be the total number of patrollers protecting a target Fq ,
i.e., there are G patrollers such that Fq is within radius re of each of the G patrollers. Then
CG  [0, 1] specifies the probability that the patrollers can successfully stop the attacker. We
require that CG1  CG2 if G1  G2 , i.e., more patrollers offer better protection.
As with previous work in security games (Tambe, 2011; Yin et al., 2012; Kiekintveld,
Jain, Tsai, Pita, Ordonez, & Tambe, 2009), we model the game as a Stackelberg game, where
the defender commits to a randomized strategy first, and then the attacker can respond to
such a strategy. The patrol schedules in these domains were previously created by hand;
and hence suffer the drawbacks of hand-drawn patrols, including lack of randomness (in
particular, informed randomness) and reliance on simple patrol patterns (Tambe, 2011),
which we remedy in this paper.
2.2 Defender Strategy
A pure strategy of the defender is to designate a movement schedule for each patroller.
Analogous to the targets schedule, a patrollers schedule can be written as a continuous
function Ru : T  D where u = 1, ..., W is the index the patroller. Ru must be compatible
with the patrollers velocity range. A mixed defender strategy is a randomization over the
pure strategies, denoted as f .
2.3 Attacker Strategy
The attacker conducts surveillance of the defenders mixed strategy and the targets schedules; he may then execute a pure strategy response to attack a certain target at a certain
time. The attackers pure strategy can be denoted as hq, ti where q is the index of target
to attack and t is the time to attack.
2.4 Utility Function
We assume the game is zero-sum. If the attacker performs a successful attack on target Fq
at location x at time t, he gets a positive reward Uq (x, t) and the defender gets Uq (x, t),
otherwise both players get utility zero. The positive reward Uq (x, t) is a known function
which accounts for many factors in practice. For example, an attacker may be more effective
in his attack when the target is stationary (such as at a terminal point) than when the target
is in motion. As the targets position is decided by the schedule, the utility function can be
written as Uq (t)  Uq (Sq (t), t). We assume that for each target Fq , Uq (t) can be represented
as a piecewise linear function of t.
2.5 Equilibrium
Since our game is zero-sum, the Strong Stackelberg Equilibrium can be calculated by finding
the minimax/maximin strategy (Fudenberg & Tirole, 1991; Korzhyk et al., 2010). That is,
587

fiFang, Jiang, & Tambe

we can find the optimal defender strategy by finding a strategy that minimizes the maximum
of attackers expected utility.
Definition 2. For single patroller case, the attacker expected utility of attacking target Fq
at time t given defender mixed strategy f is
AttEUf (Fq , t) = (1  C1 f (Fq , t))Uq (t)

(1)

Uq (t) is the reward for a successful attack, f (Fq , t) is the probability that the patroller
is protecting target Fq at time t and C1 is the protection coefficient of single patroller. We
drop the subscript if f is obvious from the context. As C1 and Uq (t) are constants for a given
attackers pure strategy hq, ti, AttEU(Fq , t) is purely decided by (Fq , t). The definition
with multiple patrollers will be given in Section 3.4. We further denote the attackers
maximum expected utility as
AttEUm
f = max AttEUf (Fq , t)
q,t

(2)

So the optimal defender strategy is a strategy f such that the AttEUm
f is minimized, formally
f  arg minf 0 AttEUm
f0

(3)

2.6 Assumptions
In our problem, the following assumptions are made based on discussions with domain
experts. Here we provide our justifications for these assumptions. While appropriate for the
current domain of application, relaxing these assumptions for future applications remains
an issue for future work; and we provide an initial discussion in Section 10.
 The attackers plan is decided off-line, i.e., the attacker does not take into account the
patrollers current partial route (partial pure strategy) in executing an attack: This
assumption is similar to the assumption made in other applications of security games
and justified elsewhere (An, Kempe, Kiekintveld, Shieh, Singh, Tambe, & Vorobeychik, 2012; Pita, Jain, Ordonez, Portway, Tambe, Western, Paruchuri, & Kraus,
2009; Tambe, 2011). One key consideration is that given that attackers have limited
resources as well, for them to generate and execute complex conditional plans that
change based on on-line observations of defenders pure strategy is both difficult
and risky.
 A single attacker is assumed instead of multiple attackers: This assumption arises
because performing even a single attack is already costly for the attacker. Thus,
having coordinating attackers at the same time will be even harder and therefore
significantly less likely for the attacker.
 The game is assumed to be zero-sum: In this case, the objectives of the defender and
attacker are in direct conflict: preventing an attack with higher potential damage is
a bigger success to the defender in our game.
588

fiProtecting Moving Targets with Multiple Mobile Resources

 The schedules for the targets are deterministic: For the domains we focus on, potential
delays in the targets schedules are usually within several minutes if any, and the
targets will try to catch up with the fixed schedules as soon as possible. Therefore,
even when delays occur, the deterministic schedule for a target can be viewed as a
good approximation of the actual schedule.

3. Models
In this section, we introduce our MRMTsg model that uses a discretized strategy space for
the defender and a continuous strategy space for the attacker. For clarity of exposition, we
then introduce the DASS approach to compute a minimax solution for discretized attacker
strategy space (Section 3.2), followed by CASS for the attackers continuous strategy space
(Section 3.3). We first assume a single patroller in Sections 3.1 through 3.3 and then
generalize to multiple patrollers in Section 3.4.
3.1 Representing Defenders Strategies
In this subsection, we introduce the discretized defender strategy space and the compact
representation used to represent the defenders mixed strategy. We show that the compact
representation is equivalent to the intuitive full representation, followed by several properties
of the compact representation.
Since the defenders strategy space is discretized, we assume that each patroller only
makes changes at a finite set of time points T = {t1 , t2 , ..., tM }, evenly spaced across the
original continuous time interval. t1 = 0 is the starting time and tM = 1 is the normalized
ending time. We denote by t the distance between two adjacent time points: t = tk+1 
tk = M11 . We set t to be small enough such that for each target Fq , the schedule Sq (t)
and the utility function Uq (t) are linear in each interval [tk , tk+1 ] for k = 1, . . . , M  1, i.e.,
the target is moving with uniform speed and the utility of a successful attack on it changes
linearly during each of these intervals. Thus, if t0 is a breakpoint of Sq (t) or Uq (t) for any
q, it can be represented as t0 = tK0 where K0 is an integer.
In addition to discretization in time, we also discretize the line segment AB that the
targets move along into a set of points D = {d1 , d2 , ..., dN } and restrict each patroller to be
located at one of the discretized points di at any discretized time point tk . Note that D is not
necessarily evenly distributed and the targets locations are not restricted at any tk . During
each time interval [tk , tk+1 ], each patroller moves with constant speed from her location di
at time tk to her location dj at time tk+1 . Only movements compatible with the speed limit
vm are possible. The points d1 , d2 , ..., dN are ordered by their distance to terminal A, and
d1 refers to A and dN refers to B. Since the time interval is discretized into M points, a
patrollers route Ru can be represented as a vector Ru = (dru (1) , dru (2) , ..., dru (M ) ). ru (k)
indicates the index of the discretized distance point where the patroller is located at time
tk .
As explained in Section 1, we discretized the defenders strategy space not only for
computational reasons. It is not even clear whether an equilibrium exists in the original
game with continuous strategy space for both players. The discretization is made also
because of the practical constraint of patrollers.
589

fiFang, Jiang, & Tambe

For expository purpose, we first focus on the case with a single defender resource and
then generalize to larger number of resources later. For a single defender resource, the
defenders mixed strategy in full representation assigns a probability to each of the patrol
routes that can be executed. Since at each time step a patroller can choose to go to at most
N different locations, there are at most N M possible patrol routes in total and this number
is achievable if there is no speed limit (or vm is large enough). The exponentially growing
number of routes will make any analysis based on full representation intractable.
Therefore, we use the compact representation of the defenders mixed strategy.
Definition 3. The compact representation for a single defender resource is a compact
way to represent the defenders mixed strategy using flow distribution variables {f (i, j, k)}.
f (i, j, k) is the probability of the patroller moving from di at time tk to dj at time tk+1 .
The complexity of the compact representation is O(M N 2 ), which is much more efficient
compared to the full representation.
Proposition 1. Any strategy in full representation can be mapped into a compact representation.
Proof sketch: If there are H possible patrol routes R1 , R2 , ..., RH , a mixed defender
strategy can be represented in full representation as a probability vector (p(R1 ), ...p(RH ))
where p(Ru ) is the probability of taking route Ru . Taking route Ru means the patroller
moves from dru (k) to dru (k+1) during time [tk , tk+1 ], so the edge ERu (k),Ru (k+1),k is taken
when route Ru is chosen. Then the total probability of taking edge Ei,j,k is the sum of
probabilities of all the routes Ru where Ru (k) = i and Ru (k + 1) = j. Therefore, given
any strategy in full presentation specified by the probability vector (p(R1 ), ...p(RH )), we
can construct a compact representation consisting of a set of flow distribution variables
{f (i, j, k)} where
X
f (i, j, k) =
p(Ru ).
(4)
Ru :Ru (k)=i and Ru (k+1)=j

Figure 3 shows a simple example illustrating the compact representation. Numbers on
the edges indicate the value of f (i, j, k). We use Ei,j,k to denote the directed edge linking
nodes (tk , di ) and (tk+1 , dj ). For example, f (2, 1, 1), the probability of the patroller moving
from d2 to d1 during time t1 to t2 , is shown on the edge E2,1,1 from node (t1 , d2 ) to node
(t2 , d1 ). While a similar compact representation was used earlier by Yin et al. (2012), we
use it in a continuous setting.
Note that different mixed strategies in full representation can be mapped to the same
compact representation. Table 1 shows two different mixed defender strategies in full representations that can be mapped to the same mixed strategy in compact representation as
shown in Figure 3. The probability of a route is labeled on all edges in the route in full
representation. Adding up the numbers of a particular edge Ei,j,k in all routes of a full
representation together, we can get f (i, j, k) for the compact representation.
Theorem 1. Compact representation does not lead to any loss in solution quality.
590

fi

Protecting Moving Targets with Multiple Mobile Resources






 






Figure 3: Compact representation: x-axis shows time intervals; y-axis the discretized
distance-points in the one-dimensional movement space.

R1 = (d1 , d1 , d1 )




R1 = (d1 , d1 , d1 )




Full Representation 1
R2 = (d1 , d1 , d2 )
R3 = (d2 , d1 , d1 )


R4 = (d2 , d1 , d2 )



Full Representation 2
R2 = (d1 , d1 , d2 )
R3 = (d2 , d1 , d1 )

R4 = (d2 , d1 , d2 )





Table 1: Two full representations that can be mapped into the same compact representation
shown in Figure 3.

Proof sketch: The complete proof of the theorem relies on the calculations in Section
3.2 and 3.3. Here we provide a sketch. Recall our goal is to find an optimal defender
strategy f that minimizes the maximum attacker expected utility AttEUm
f . As we will
show in the next subsections, (Fq , t) can be calculated from the compact representation
{f (i, j, k)}. If two defender strategies under the full representation are mapped to the same
compact representation {f (i, j, k)}, they will have the same  function and then the same
AttEU function according to Equation 1. Thus the value of AttEUm
f is the same for the
two defender strategies. So an optimal mixed defender strategy in compact representation
is still optimal for the corresponding defender strategies in full representation.
We exploit the following properties of the compact representation.
Property 1.
ForPany time interval [tk , tk+1 ], the sum of all flow distribution variables
PN
N
equals to 1:
i=1
j=1 f (i, j, k) = 1.
Property 2. The sum of flows that go into a particular node equals the sum
P of flows that
go out of the node. Denote the sum for node (tk , di ) by p(i, k), then p(i, k) = N
j=1 f (j, i, k 
PN
1) = j=1 f (i, j, k). Each p(i, k) is equal to the marginal probability that the patroller is at
location di at time tk .
P
Property 3. Combining Property 1 and 2, N
i=1 p(i, k) = 1.
591

fiFang, Jiang, & Tambe

3.2 DASS: Discretized Attacker Strategies
In this subsection, we introduce DASS, a mathematical program that efficiently finds minimax solutions for MRMTsg -based games under the assumption that the attacker will attack
at one of the discretized time points tk . In this problem, we need to minimize v where v
is the maximum of attackers expected utility. Here, v is the maximum of AttEU(Fq , t) for
any target Fq at any discretized time point tk .
From Equation (1), we know that AttEU(Fq , t) is decided by (Fq , t), the probability
that the patroller is protecting target Fq at time t. Given the position of the target Sq (t), we
define the protection range q (t) = [max{Sq (t)re , d1 }, min{Sq (t)+re , dN }]. If the patroller
is located within the range q (t), the distance between the target and the patroller is no
more than re and thus the patroller is protecting Fq at time t. So (Fq , t) is the probability
that the patroller is located within range q (t) at time t. For the discretized time points
tk , the patroller can only be located at a discretized distance point di , so we define the
following.

Definition 4. I(i, q, k) is a function of two values. I(i, q, k) = 1 if di  q (tk ), and
otherwise I(i, q, k) = 0.

In other words, I(i, q, k) = 1 means that a patroller located at di at time tk can protect target Fq . Note that the value of I(i, q, k) can be calculated directly from the input
parameters (di , Sq (t) and re ) and stored in a look-up table. In particular, I(i, q, k) is not
a variable in the formulations that follow. It simply encodes the relationship between di
and the location of target Fq at tk . The probability that the patroller is at di at time tk is
p(i, k). So we have
(Fq , tk ) =

X


AttEU(Fq , tk ) =

1  C1

i:I(i,q,k)=1

p(i, k),

X
i:I(i,q,k)=1


p(i, k) Uq (tk ).

(5)

(6)

Equation (6) follows from Equations (1) and (5), expressing attackers expected utility for
discretized time points. Finally, we must address speed restrictions on the patroller. We set
all flows corresponding to actions that are not achievable to zero,1 that is, f (i, j, k) = 0 if
|dj  di | > vm t. Thus, DASS can be formulated as a linear program. This linear program

1. Besides the speed limit, we can also model other practical restrictions of the domain by placing constraints
on f (i, j, k).

592

fiProtecting Moving Targets with Multiple Mobile Resources

solves for any number of targets but only one defender resource.
min

z

(7)

f (i,j,k),p(i,k)

f (i, j, k)  [0, 1],

i, j, k

(8)

f (i, j, k) = 0,

i, j, k such that |dj  di | > vm t

(9)

p(i, k) =

N
X

f (j, i, k  1),

i, k > 1

(10)

f (i, j, k),

i, k < M

(11)

k

(12)

q, k

(13)

j=1

p(i, k) =

N
X
j=1

N
X

p(i, k) = 1,

i=1

z  AttEU(Fq , tk ),

Constraint 8 describes the probability range. Constraint 9 describes the speed limit. Constraints 1011 describes Property 2. Constraint 12 is exactly Property 3. Property 1 can
be derived from Property 2 and 3, so it is not listed as a constraint. Constraint (13) shows
the attacker chooses the strategy that gives him the maximal expected utility among all
possible attacks at discretized time points; where AttEU() is described by Equation (6).
3.3 CASS: Continuous Attacker Strategies
In this subsection, we generalize the problem to one with continuous attacker strategy set
and provides a linear-programming-based solution CASS. CASS efficiently finds optimal
mixed defender strategy under the assumption that the attacker can attack at any time
in the continuous time interval T = [0, 1]. With this assumption, DASSs solution quality
guarantee may fail: if the attacker chooses to attack between tk and tk+1 , he may get
a higher expected reward than attacking at tk or tk+1 . Consider the following example,
with the defenders compact strategy between tk and tk+1 shown in Figure 4. Here the
defenders strategy has only three non-zero flow variables f (3, 4, k) = 0.3, f (3, 1, k) = 0.2,
and f (1, 3, k) = 0.5, indicated by the set of three edges E + = {E3,4,k , E3,1,k , E1,3,k }. A
target Fq moves from d3 to d2 at constant speed during [tk , tk+1 ]. Its schedule is depicted
by the straight line segment Sq . The dark lines L1q and L2q are parallel to Sq with distance
re . The area between them indicates the protection range q (t) for any time t  (tk , tk+1 ).
Consider the time points at which an edge from E + intersects one of L1q , L2q , and label them
r , r = 1 . . . 4 in Figure 4). Intuitively, these are all the time points at which a defender
as qk
patrol could potentially enter or leave the protection range of the target. To simplify the
0 and t
5
notation, we denote tk as qk
k+1 as qk . For example, a patroller moving from d3
0 to  1 because
to d4 (or equivalently, taking the edge E3,4,k ) protects the target from qk
qk
0 ,  1 ], during which the distance to the target is less or
E3,4,k is between L11 and L21 in [qk
qk
r and  r+1 , for
equal than protection radius re . Consider the sub-intervals between each qk
qk
r = 0 . . . 4. Since within each of these five sub-intervals, no patroller enters or leaves the
593

fiFang, Jiang, & Tambe

protection range, the probability that the target is being protected is a constant in each
sub-interval, as shown in Figure 5(a).





 



 




 









Figure 4: An example to show how a target moving from d3 to d2 during [tk , tk+1 ] is pror ,  r+1 ], a patroller either always protects the target
tected. In a sub-interval [qk
qk
or never protects the target. Equivalently, the target is either always within the
protective circle of a patroller or always outside the circle.

Suppose Uq (t) decreases linearly from 2 to 1 during [tk , tk+1 ] and C1 = 0.8. We can then
calculate the attackers expected utility function AttEU(Fq , t) for (tk , tk+1 ), as plotted in
Figure 5(b). AttEU(Fq , t) is linear in each sub-interval but the function is discontinuous at
1 , . . . ,  4 because of the patroller leaving or entering the protection
the intersection points qk
qk
r from the left as:
range of the target. We denote the limit of AttEU when t approaches qk
r
lim AttEU(Fq , t) = AttEU(Fq , qk
)

r
tqk

Similarly, the right limit is denoted as:
r+
lim AttEU(Fq , t) = AttEU(Fq , qk
)

r+
tqk

2 ,
If Fq is the only target, an attacker can choose to attack at a time immediately after qk
getting an expected utility that is arbitrarily close to 1.70. According to Equation (6), we
2+
can get AttEU(Fq , tk ) = 1.20 and AttEU(Fq , tk+1 ) = 1.00, both lower than AttEU(Fq , qk
).
Thus, the attacker can get a higher expected reward by attacking between tk and tk+1 ,
violating DASSs quality guarantee.
However, because of discontinuities in the attackers expected utility function, a maximum might not exist. This implies that the minimax solution concept might not be welldefined for our game. We thus define our solution concept to be minimizing the supremum
of AttEU(Fq , t).

594

fiProtecting Moving Targets with Multiple Mobile Resources





0.50

1.70
1.43
1.20
1.00

0.20
0.00
  






 



 
 



(a) Probability that the target is protected
is a constant in each sub-interval.








 


(b) The attackers expected utility is linear
in each sub-interval.

Figure 5: Sub-interval analysis in (tk , tk+1 ) for the example shown in Figure 4.]
Definition 5. The supremum of attackers expected utility is the smallest real number
that is greater than or equal to all elements of the infinite set {AttEU(Fq , t)}, denoted as
sup AttEU(Fq , t).
The supremum is the least upper bound of the function AttEU(Fq , t). So for CASS
model, Equation 2 should be modified as
AttEUm
f = sup AttEUf (Fq , t)

(14)

q,t

So a defender strategy f is minimax if AttEUm
f is maximized, i.e.,
f  arg minf 0 sup AttEUf 0 (Fq , t)
2+
)=
In the above example, the supremum of attackers expected utility in (tk , tk+1 ) is AttEU(Fq , qk
1.70. In the rest of the paper, we will not specify when supremum is used instead of maximum as it can be easily inferred from the context.
How can we deal with the possible attacks between the discretized points and find an
optimal defender strategy? We generalize the process above (called sub-interval analysis)
to all possible edges Ei,j,k . We then make use of the piecewise linearity of AttEU(Fq , t)
and the fact that the potential discontinuity points are fixed, which allows us to construct
a linear program that solves the problem to optimality. We name the approach CASS
(Solver for Continuous Attacker Strategies).
We first introduce the general sub-interval analysis. For any target Fq and any time
interval (tk , tk+1 ), we calculate the time points at which edges Ei,j,k and L1q , L2q intersect,
denoted as intersection points. We sort the intersection points in increasing order, denoted
r , r = 1 . . . M , where M
0
as qk
qk
qk is the total number of intersection points. Set qk = tk and
M

qkqk

+1

r ,  r+1 ), r = 0, ..., M .
= tk+1 . Thus (tk , tk+1 ) is divided into sub-intervals (qk
qk
qk

Lemma 1. For any given target Fq , AttEU(Fq , t) is piecewise-linear in t. Furthermore,
there exists a fixed set of time points, independent of the defenders mixed strategy, such
that AttEU(Fq , t) is linear between each adjacent pair of points. Specifically, these points
r defined above.
are the intersection points qk
595

fiFang, Jiang, & Tambe

r ,  r+1 ) for a target F , a feasible edge E
Proof: In each sub-interval (qk
q
i,j,k is either
qk
1
2
totally above or below Lq , and similarly for Lq . Otherwise there will be a new intersection
point which contradicts the definition of the sub-intervals. If edge Ei,j,k is between L1q and
L2q , the distance between a patroller taking the edge and target Fq is less than re , meaning
the target is protected by the patroller. As edge Ei,j,k is taken with probability f (i, j, k),
the total probability that the target is protected ((Fq , t)) is the sum of f (i, j, k) whose
corresponding edge Ei,j,k is between the two lines in a sub-interval. So (Fq , t) is constant
in t in each sub-interval and thus the attackers expected utility AttEU(Fq , t) is linear in
each sub-interval according to Equation 2 as Uq (t) is linear in [tk , tk+1 ]. Discontinuity can
only exist at these intersection points and an upper bound on the number of these points
for target Fq is M N 2 .
r ,  r+1 ), and 0
Define coefficient Arqk (i, j) to be C1 if edge Ei,j,k is between L1q and L2q in (qk
qk
otherwise. According to Equation (1) and the fact that (Fq , t) is the sum of f (i, j, k) whose
r ,  r+1 ).
corresponding coefficient Arqk (i, j) = C1 , we have the following equation for t  (qk
qk


N X
N
X

(15)
AttEU(Fq , t) = 1 
Arqk (i, j)f (i, j, k)  Uq (t)
i=1 j=1

Piecewise linearity of AttEU(Fq , t) means the function is monotonic in each sub-interval and
the supremum can be found at the intersection points. Because of linearity, the supremum
r ,  r+1 ) can only be chosen from the one-sided limits of the endpoints,
of AttEU in (qk
qk
(r+1)

r+
) and AttEU(Fq , qk
). Furthermore, if Uq (t) is decreasing in [tk , tk+1 ],
AttEU(Fq , qk
the supremum is
(r+1)
r+
) and otherwise it is AttEU(Fq , qk
). In other words, all other attackers
AttEU(Fq , qk
r+1
r or  r+1 . Thus, CASS
r
strategies in (qk , qk ) are dominated by attacking at time close to qk
qk
adds new constraints to Constraints 813 which consider attacks to occur at t  (tk , tk+1 ).
We add one constraint for each sub-interval with respect to the possible supremum value
in this sub-interval:

min

z

(16)

f (i,j,k),p(i,k)

subject to constraints (8 . . . 13)
(r+1)

r+
z  max{AttEU(Fq , qk
), AttEU(Fq , qk

)}

(17)

k  {1 . . . M }, q  {1 . . . L}, r  {0 . . . Mqk }
This linear program stands at the core of CASS and we will not differentiate the name
for the solver and the name for the linear program in the following. All the linear constraints included by Constraint 17 can be added to CASS using Algorithm 1. The input
of the algorithm include targets schedules {Sq }, the protection radius re , the speed limit
vm , the set of discretized time points {tk } and the set of discretized distance points {di }.
Function CalInt(L1q , L2q , vm ) in Line 1 returns the list of all intersection time points between
0 and
all possible edges Ei,j,k and the parallel lines L1q , L2q , with additional points tk as qk
M

+1

r ,  r+1 ) in Line 1 returns the coefficient
tk+1 as qkqk . Function CalCoef(L1q , L2q , vm , qk
qk
r
r
matrix Aqk . Aqk can be easily decided by checking the status at the midpoint in time. Set

596

fiProtecting Moving Targets with Multiple Mobile Resources

r +  r+1 )/2 and denote the patrollers position at t
tmid = (qk
mid when edge Ei,j,k is taken as
qk
Ei,j,tmid , thus Arqk (i, j) = C1 if Ei,j,tmid  q (tmid ). Lines 11 add a constraint with respect
(r+1)

r+
to the larger value of AttEU(Fq , qk
) and AttEU(Fq , qk
) to CASS for this sub-interval
r+1
r
(qk , qk ). It means when the attacker chooses to attack Fq in this sub-interval, his best
r ,  r+1 ).
choice is decided by the larger value of the two side-limits of AttEU in (qk
qk

Algorithm 1: Add constraints described in Constraint 17
Input: Sq , re , vm , {tk }, {di };
for k  1, . . . , M  1 do
for q  1, . . . , L do
L1q  Sq + re , L2q  Sq  re ;
M

+1

0 , . . . ,  qk
 CalInt(L1q , L2q , vm );
qk
qk
for r  0, . . . , Mqk do
r ,  r+1 );
Arqk  CalCoef(L1q , L2q , vm , qk
qk
if Uq (t) is decreasing in [tk , tk+1 ] then
r+
add constraint z  AttEU(Fq , qk
)
end
else
(r+1)
add constraint z  AttEU(Fq , qk
)
end
end
end
end

Theorem 2. CASS computes (in polynomial time) the exact solution (minimax) of the
game with discretized defender strategies and continuous attacker strategies.
Proof: According to Lemma 1, AttEU(Fq , t) is piecewise linear and discontinuity can
r . These intersection points divide the time space
only occur at the intersection points qk
into sub-intervals. Because of piecewise linearity, the supremum of AttEU(Fq , t) equals to
the limit of an endpoint of at least one sub-interval. For any defenders strategy f that is
feasible, a feasible z of the linear program 16-17 is no less than any of the limit values at the
intersection points according to Constraint 17 and values at the discretized time points tk
according to Constraint 13, and thus v can be any upper bound of AttEU(Fq , t) for f . As z
is minimized in the objective function, z is no greater than the supremum of AttEU(Fq , t)
given any defender strategy f , and further z will be the minimum of the set of supremum
corresponding to all defender strategies. Thus we get the optimal defender strategy f .
The total number of variables in the linear program is O(M N 2 ). The number of constraints represented in Algorithm 1 is O(M N 2 L) as the number of intersection points is at
most 2(M  1)N 2 for each target. The number of constraints represented in Constraints
813 is O(M N 2 ). Thus, the linear program computes the solution in polynomial time.
Corollary 1. The solution of CASS provides a feasible defender strategy of the original
continuous game and gives exact expected value of that strategy.
597

fiFang, Jiang, & Tambe

3.4 Generalized Model with Multiple Defender Resources
In this subsection, we generalize DASS and CASS to solve the problem with multiple defender resources. When there are multiple patrollers, the patrollers will coordinate with
each other. Recall the protection coefficient CG in Definition 1, a target is better protected
when more patrollers are close to it (within radius re ). So the protection provided to a
target is determined when all patrollers locations are known. Thus it is not sufficient to
calculate the probability that an individual edge is taken as in the single patroller case.
Under the presence of multiple patrollers, we need a more complex representation to explicitly describe the defender strategy. To illustrate generalization to the multiple defender
resources case, we first take two patrollers as an example. If there are two patrollers, the
patrol strategy can be represented using flow distribution variables {f (i1 , j1 , i2 , j2 , k)}. Here
the flow distribution variables are defined on the Cartesian product of two duplicated sets
of all feasible edges {Ei,j,k }. f (i1 , j1 , i2 , j2 , k) is the joint probability of the first patroller
moving from di1 to dj1 and the second patroller moving from di2 to di2 during time tk to
tk+1 , i.e., taking edge Ei1 ,j1 ,k and Ei2 ,j2 ,k respectively. The corresponding marginal distribution variable p(i1 , i2 , k) represents for the probability that the first patroller is at di1 and
the second at di2 at time tk . Protection coefficients C1 and C2 are used when one or two
patrollers are protecting the target respectively.
So the attackers expected utility can be written as
AttEU(Fq , t) = (1  (C1  1 (Fq , t) + C2  2 (Fq , t)))  Uq (t)
1 (Fq , t) is the probability that only one patroller is protecting the target Fq at time t
and 2 (Fq , t) is the probability that both patrollers are protecting the target. For attacks
that happen at discretized points tk , we can make use of I(i, q, k) in Definition 4 and
I(i1 , q, k) + I(i2 , q, k) is the total number of patrollers protecting the ferry at time tk .
X
1 (Fq , tk ) =
p(i1 , i2 , k)
i1 ,i2 :I(i1 ,q,k)+I(i2 ,q,k)=1
X
2 (Fq , tk ) =
p(i1 , i2 , k)
i1 ,i2 :I(i1 ,q,k)+I(i2 ,q,k)=2

Constraints for attacks occurring in (tk , tk+1 ) can be calculated with an algorithm that
looks the same as Algorithm 1. The main difference is in the coefficient matrix Arqk and
the expression of AttEU. We set the values in the coefficient matrix Arqk (i1 , j1 , i2 , j2 ) as C2
if both edges Ei1 ,j1 ,k and Ei2 ,j2 ,k are between L1q and L2q , and C1 if only one of the edges
r ,  r+1 ) is
protects the target. The attackers expected utility function in (qk
qk
X
AttEU(Fq , t) = (1 
Arqk (i1 , j1 , i2 , j2 )f (i1 , j1 , i2 , j2 , k))  Uq (t)
i1 ,j1 ,i2 ,j2

For a general case of W defender resources, we can use {f (i1 , j1 , ..., iW , jW , k)} to represent the patrol strategy.
Definition 6. The compact representation for multiple defender resources is a compact way
to represent the defenders mixed strategy using flow distribution variables {f (i1 , j1 , ..., iW , jW , k)}.
{f (i1 , j1 , ..., iW , jW , k)} is the joint probability that patroller moving from diu at time tk to
dju at time tk+1 for u = 1 . . . W .
598

fiProtecting Moving Targets with Multiple Mobile Resources

Given the generalized compact representation, we get the following equations for calculating the attackers expected utility function and the protection probability:


W
X
AttEU(Fq , t) = 1 
CQ  Q (Fq , t)  Uq (t)
Q=1

Q (Fq , tk ) =

X
i1 ,...,iW :

W
P

p(i1 , . . . , iW , k)
I(iu ,q,k)=Q

u=1

Q is the number of patrollers protecting the target. We can modify Algorithm 1 to apply
for the multiple defender resource case. Set Arqk (i1 , j1 , ..., iW , jW ) as CQ if Q of the edges
{Eiu ,ju ,k } are between L1q and L2q .
We conclude the linear program for generalized CASS for multiple patrollers as follows.
min

z

(18)

f (i1 ,j1 ,...,iW ,jW ,k),p(i1 ,...,iW ,k)

f (i1 , j1 , . . . , iW , jW , k) = 0, i1 , . . . , iW , j1 , . . . , jW such that u, |dju  diu | > vm t
(19)
n
n
X
X
p(i1 , . . . , iW , k) =
...
f (j1 , i1 , . . . , jW , iW , k  1), i1 , . . . , iW , k > 1
j1 =1

jW =1

n
X

n
X

(20)
p(i1 , . . . , iW , k) =

...

j1 =1

f (i1 , j1 , . . . , iW , jW , k), i1 , . . . , iW , k < M

jW =1

(21)
n
X
i1 =1

...

n
X

p(i1 , . . . , iW , k) = 1, k

(22)

iW =1

z  AttEU(Fq , tk ), q, k
z

(r+1)
r+
max{AttEU(Fq , qk
), AttEU(Fq , qk
)}, k, q, r

(23)
(24)

The number of variables in the linear program is O(M N 2W ) and the number of constraints is O(M N W ). It is reasonable to examine potentially more efficient alternatives.
We summarize the results of such an examination below concluding that using the current
linear program would appear to currently offer our best tradeoff in terms of solution quality and time at least for the current domains of application; although as discussed below,
significant future work might reveal alternatives approaches for other future domains.
The first question to examine is that of the computational complexity of the problem
at hand: generating optimal patrolling strategies for multiple patrollers on a graph. Unfortunately, despite significant attention paid to the topic, currently, the complexity remains
unknown. More specifically, the question of computational complexity of generating patrols
for multiple defenders on graphs of different types has received significant attention (Letchford, 2013; Korzhyk et al., 2010). These studies illustrate that in several cases the problem
is NP-hard, in some cases the problem is known to be polynomial time, but despite significant effort, the problem complexity in many cases remains unknown (Letchford & Conitzer,
599

fiFang, Jiang, & Tambe

2013). Unfortunately, our graph turns out to be different from the cases considered in their
work. Indeed, the DASS model can be explained as a game with homogeneous defender
resources patrolling on a graph, similar to the cases that have already been considered.
However, prior results cannot explain the complexity of our game as the structure of our
graph does not fit any of the prior graphs.
Given that computational complexity results are not directly available, we may examine
approaches to provide efficient approximations. Here we provide an overview of two such
approaches (providing experimental results in Section 7.1.6). Our first approach attempts
to provide a more compact representation in the hope of providing a speedup. To that end,
we apply an intuitive approach that uses individual strategy profile for each patroller and
then calculates a best possible mixed strategy combination. Unfortunately, this approach
is inefficient in run-time even for the DASS model and may result in a suboptimal solution.
Thus, although more compact, this approach fails to achieve our goal; we explain this
approach next.
Assume each patroller independently follows her own mixed strategy. Denote the individual mixed strategy for patroller u as fu (iu , ju , tk ), and the probability that a target is
protected by Q players can be represented as a polynomial expression of {fu (iu , ju , tk )} of
order Q. Then our optimization problem is converted to minimizing objective function z
with non-linear constraints. Assume we have two patrollers, and for a potential attack at
target q at time tk , we denote the probability that patroller u is protecting the target as
$u . $u is linear in fu , and the attackers expected utility for this attack can be represented
as
AttEU(Fq , tk ) = (1  C1 ((1  $1 )$2 + (1  $2 )$1 )  C2 $1 $2 )Uq (tk )
So a constraint z  AttEU(Fq , tk ) is quadratic in f , due to the fact that the joint probability
is represented by the product of the individual probability of each patroller. These constraints are not ensured to have a convex feasible region and there is no known polynomial
algorithms for solving this kind of non-convex optimization problems. We attempt to solve
the problem by converting it into a mathematical program with a non-convex objective function and linear constraints, i.e., instead of minimizing z with constraints z  AttEU(Fq , tk ),
we incorporate the constraints into the objective function as
z = max{AttEU(Fq , tk )}
q,k

(25)

The results in Section 7.1.6 show that when we solve this mathematical program in MATLAB using function fmincon with interior-point method for the DASS model, the algorithm
fails to get to a feasible solution efficiently and even when enough time is given, the solution
can still be suboptimal as it may get stuck at a local minimum. To conclude, although this
approach is more compact and helps in saving memory, it is inefficient in run-time and may
result in loss in solution quality.
Our second approach takes a further step to reduce the run-time complexity, making
it a polynomial approximation algorithm, but it can lead to a high degradation in solution quality. In this approach, we iteratively compute the optimal defender strategy for a
newly added resource unit given the existing strategies for the previous defender resources.
Namely, we first calculate f1 (i1 , j1 , tk ) as if only one patroller is available and then calculate
600

fiProtecting Moving Targets with Multiple Mobile Resources

f2 (i2 , j2 , tk ) given the value of f1 (i1 , j1 , tk ). In this way, we need to solve W linear programs
with complexity O(M N 2 ) so this approach is much faster compared to the former one. Unfortunately, this approach fails to capture the coordination between the patrollers effectively
and thus may result in a high degradation in solution quality. For example, suppose there
are only two targets of constant utility U , one target stays at terminal A and the other one
stays at terminal B. Further, suppose the protection coefficient is always 1 when a target
is protected by one or more patrollers. When two patrollers are available, the optimal solution would be each protect one of the targets all the way, so both targets are protected
with probability 1 and the expected utility function for the attacker is 0. If the defender
strategy is calculated for each patroller sequentially as discussed above, the solution would
be protect each target with probability 0.5 for both players, making the attackers expected
utility 0.25%U . In other words, we reach a suboptimal solution, wasting resources when
both patrollers end up protecting the same target with probability 0.25. In this case, we
can already see that there is a 0.25 probability that a target is unprotected when clearly
an optimal solution existed that protected all targets with probability 1. Thus, even with
just two patrollers this solution leads to a potentially significant loss in expected utility;
therefore, this solution clearly appears to be inadequate for our purposes.
Given the above discussion, it would appear that a fast approximation may lead to
significant losses in solution quality or may not be efficient enough. Fortunately for current
application domains, such as the current deployment of CASS for protecting ferries (e.g.,
the Staten Island Ferry in New York), the number of defender resources are limited. The
lack of resources is the main reason that optimization using security games becomes critical.
As a result, our current approach of CASS is adequate for current domains such as ferry
protection. Further research about scale-up is an issue for future work.

4. Equilibrium Refinement
A game often has multiple equilibria. Since our game is zero-sum, all equilibria achieve
the same objective value. However, if an attacker deviates from his best response, some
equilibrium strategies for the defender may provide better results than others.
Consider the following example game. There are two targets moving during [t1 , t2 ] (no
further discretization): one moves from d3 to d2 and the other moves from d1 to d2 (See
Figure 6(a)). Suppose d3  d2 = d2  d1 = d and re = 0.5d. There is only one patroller
available and the protection coefficient C1 = 1. Both targets utility functions decrease
from 10 to 1 in [t1 , t2 ] (See Figure 6(b)). In one equilibrium, f3,2,1 = f1,2,1 = 0.5, i.e., the
patroller randomly chooses one target and follows it all the way. In another equilibrium,
f3,3,1 = f1,1,1 = 0.5, i.e., the patroller either stays at d1 or at d3 . In either equilibrium,
the attackers best response is to attack at t1 , with a maximum expected utility of 5.
However, if an attacker is physically constrained (e.g., due to launch point locations) to
only attack no earlier than t0 and t0 > 11 (where 11 is the only intersection time point and
11 = (t1 + t2 )/2), against both defender strategies he will choose to attack either of the
targets at t0 . The attackers expected utility is Uq (t0 )/2 in the first equilibrium because
there is 50% probability that the patroller is following that target. However in the second
equilibrium, he is assured to succeed and get a utility of Uq (t0 ) because the distance between
the chosen target and d1 (or d3 ) is larger than re at t0 , i.e., the chosen target is unprotected
601

fiFang, Jiang, & Tambe

at t0 . In this case, the defender strategy in the first equilibrium is preferable to the one in
the second; indeed, the first defender strategy dominates the second one, by which we mean
the first is equally good or better than the second no matter what strategy the attacker
chooses. We provide a formal definition of dominance in Section 4.1.




 



10



  
1








 







(a) Two targets moves with schedules S1
and S2 .

 





(b) Utility function is the same for both
targets and is decreasing linearly over
time.

Figure 6: An example to show one equilibrium outperforms another when the attacker is
constrained to attack in [t0 , t2 ] if t0 > 11 .
Our goal is to improve the defender strategy so that it is more robust against constrained
attackers while keeping the defenders expected utility against unconstrained attackers the
same. This task of selecting one from the multiple equilibria of a game is an instance of
the equilibrium refinement problem, which has received extensive study in game theory
(van Damme, 1987; Fudenberg & Tirole, 1991; Miltersen & Srensen, 2007). For finite
security games, An, Tambe, Ordonez, Shieh, and Kiekintveld (2011) proposed techniques
that provide refinement over Stackelberg equilibrium. However there has been little prior
research on the computation of equilibrium refinements for continuous games.
In this section, we introduce two equilibrium refinement approaches: route-adjust
(Section 4.1) and flow-adjust (Section 4.2). Both approaches can be applied to improve
any feasible defender strategy and when they are applied to an optimal defender strategy
in an existing equilibrium, we will get new equilibria with more robust optimal defender
strategies.
For expository simplicity, we still use the single-resource case as an example, but both
methods are applicable to the multiple-resources case. The results shown in evaluation
section experimentally illustrates these two refinement methods can significantly improve
the performance.
4.1 Route Adjust
Given that f is the defender strategy of one equilibrium of the game, if we can find a defender
strategy f 0 such that for any attacker strategy (q, t), the defenders expected utility under
f 0 is equal to or higher than the one under f , and the one under f 0 is strictly higher than
the one under f for at least one specific attacker strategy, we say that f 0 dominates f .
Intuitively, the defender should choose f 0 instead of f as f 0 is at least as good as f for any
602

fiProtecting Moving Targets with Multiple Mobile Resources

attacker strategy and can achieve better performance for some attacker strategies. So an
equilibrium with strategy f 0 is more robust to unknown deviations on the attacker side. We
give the formal definition of dominance as follows.
Definition 7. Defender strategy f dominates f 0 if q, t, DefEUf (Fq , t)  DefEUf 0 (Fq , t),
and q, t, DefEUf (Fq , t) > DefEUf 0 (Fq , t); or equivalently in this zero-sum game, q, t,
AttEUf (Fq , t)  AttEUf 0 (Fq , t), and q, t, AttEUf (Fq , t) < AttEUf 0 (Fq , t).
Corollary 2. Defender strategy f dominates f 0 if q, t, (Fq , t)   0 (Fq , t) and q, t,
(Fq , t) >  0 (Fq , t).
Definition 7 simply restates the commonly used weak dominance definition in game
theory for this specific game. Corollary 2 follows from Equation (1).
In this section, we introduce the route-adjust approach which gives a procedure for
finding a defender strategy f 1 that dominates the given defender strategy f 0 . Route-adjust
provides final routes using these steps: (i) decompose flow distribution f 0 into component
routes; (ii) for each route, greedily find a route which provides better protection to targets;
(iii) combine the resulting routes into a new flow distribution, f 1 , which dominates f 0 if
f 1 is different from f0 . The detailed process is listed in Algorithm 2. We illustrate this
approach using a simple dominated strategy shown in Figure 3.
To accomplish step (i), we decompose the flow distribution by iteratively finding a route
that contains the edge with minimum probability. As shown in Figure 7, we first randomly
choose a route that contains edge E1,2,2 , as f (1, 2, 2) = 0.4 is the minimum among all flow
variables. We choose R2 = (d1 , d1 , d2 ), and set p(R2 ) = f (1, 2, 2) = 0.4. Then for each
edge of the route R2 we subtract 0.4 from the original flow, resulting in a residual flow. We
continue to extract routes from the residual flow until there is no route left. Denote by Z
the number of non-zero edges in the flow distribution graph, then Z is decreased by at least
1 after each iteration. So the algorithm will terminate in at most Z steps and at most Z
routes are found. The result of step (i) is a sparse description of a defender mixed strategy
in full representation. As we will discuss in Section 6, this decomposition constitutes one
method of executing a compact strategy.
For step (ii), we adjust each of the routes greedily. To that end, we first introduce the
r and the coefficient
dominance relation of edges and routes, using the intersection points qk
r
matrix Aqk (i, j) defined in Section 3.3.
Definition 8. Edge Ei,j,k dominates edge Ei0 ,j 0 ,k in [tk , tk+1 ] if Arqk (i, j)  Arqk (i0 , j 0 ),
q = 1..L, r = 0..Mqk , and q, r such that Arqk (i, j) > Arqk (i0 , j 0 ).
The dominance relation of edges is based on the comparison of protection provided to
the targets in each sub-interval. In the following dominance relation of routes, we denote
the edge Eru (k),ru (k+1),k as E(u, k) to simplify the notation, .
Definition 9. Route Ru = (dru (1) , . . . , dru (M ) ) dominates Ru0 = (dru0 (1) , . . . , dru0 (M ) ) if
k = 1 . . . M  1, E(u, k) = E(u0 , k) or E(u, k) dominates E(u0 , k) and k such that E(u, k)
dominates E(u0 , k).
Route Ru dominates Ru0 if each edge of Ru is either the same as or dominates the
corresponding edge in Ru0 and at least one edge in Ru dominates the corresponding edge
in Ru0 .
603

fiFang, Jiang, & Tambe

Algorithm 2: Route-Adjust
Input: a mixed defender strategy f
Output: an updated mixed defender strategy f 0
(i) Decompose f into multiple routes by iteratively finding a route that contains
the edge with minimum probability:
(a) Initialize the remaining flow distribution f = f and route set S = .
Initialize probability distribution over routes p(Ru ) = 0, u.
(b) while max f(i, j, k) > 0 do
i. Set (i0 , j0 , k0 ) = arg mini,j,k:f(i,j,k)>0 f(i, j, k).
ii. Set fmin = f(i0 , j0 , k0 ).
iii. Find an arbitrary route Ru0 such that ru0 (k0 1) = i0 and ru0 (k0 ) =
j0 (i.e., edge Ei0 ,j0 ,k0 is in the route) and f(ru0 (k), ru0 (k+1), k) > 0,
k (i.e., all edges in the route has non-zero remaining flow).
iv. Add Ru0 to S and set p(Ru0 ) = fmin .
v. Set f(i, j, k) = f(i, j, k)  fmin if ru0 (k  1) = i and ru0 (k) = j.
end
(ii) Adjust each route in S greedily to get a new set of routes S 0 and the corresponding new probability distribution p0 :
(a) Initialize the new set S 0 =  and new probability distribution p0 (Ru ) = 0,
u.
(b) while S 6=  do
i. Pick a route Ru from S.
ii. Adjust Ru to get new route Ru0 : for a given Ru and a specified
k  , set ru0 (k) = ru (k) if k 6= k  . Set ru0 (k  ) = i0 such that: 1)
E(u1 , k   1) and E(u1 , k  ) meet the speed constraint; 2) Ru0 dominates Ru with the choice of i0 ; 3) Ru0 is not dominated by a route
with any other choice of i0 . If no such i0 exists, set ru0 (k  ) = ru (k  )
iii. Add Ru to S 0 and set p0 (Ru0 ) = p(Ru ).
iv. Remove Ru from S.
end
(iii) Reconstruct a new compact representation f 0 from S 0 and p0 according to
Equation 4.

604

fiProtecting Moving Targets with Multiple Mobile Resources

   ,  , 
p R   0.4

   ,  , 
p R  0.2



















 


















   ,  , 
p R   0.4

 














Figure 7: Step (i): decomposition. Every time a route containing the minimal flow variable
is subtracted and a residual graph is left for further decomposition. The original flow distribution is thus decomposed into three routes R2 , R1 , and R3 with
probability 0.4, 0.2 and 0.4 respectively.

Denote the original route to be adjusted as Ru and the new route as Ru0 . A greedy
way to improve the route is to replace only one node in the route. If we want to replace
the node at time tk , then we have ru0 (k) = ru (k), k 6= k  and dru (k ) in the original
route is replaced with dru0 (k ) . So the patrollers route changes only in [tk 1 , tk +1 ]. Thus,
only edges E(u, k   1) and E(u, k  ) in the original route are replaced by E(u0 , k   1) and
E(u0 , k  ) in the new route.
We are trying to find a new route Ru0 that dominates the original route to provide equal
or more protection to the targets. So the selection of ru0 (k  ) needs to meet the requirements
specified in Algorithm 2. The first one describes the speed limit constraint. The second
one actually requires the changed edges E(u0 , k   1) and E(u0 , k  ) are either equal to or
dominate the corresponding edges in the original route (and dominance relation exist for at
least one edge). The third requirement attains a local maximum. If such a new node does
not exist for a specified k  , we return the original route Ru .
We can iterate this process for the new route and get a final route denoted by Ru0 after
several iterations or when the state of convergence is reached. When the state of convergence
is reached, the resulting route Ru0 keeps unchanged no matter which k  is chosen for the
next iteration.
For the example in Figure 7, assume the only targets moving schedule is d1  d1  d2 ,
d3  d2 = d2  d1 = d, re = 0.1d and utility function is constant. We adjust each route
for only one iteration by changing the patrollers position at time t3 , i.e., ru (3). As t3 is
the last discretized time point, only edge E(u, 2) may be changed. For R1 = (d1 , d1 , d1 ),
we enumerate all possible patrollers positions at time t3 and choose one according to the
three constraints mentioned above. In this case, the candidates are d1 and d2 , so the
corresponding new routes are R1 (unchanged) and R2 = (d1 , d1 , d2 ) respectively. Note that
edge Ed1 ,d2 ,2 dominates Ed1 ,d1 ,2 because the former one protects the target all the way in
[t2 , t3 ] and thus R2 dominates R1 . So d2 is chosen as the patrollers position at t3 and R2
605

fiFang, Jiang, & Tambe

is chosen as the new route. The adjustment for all routes with non-zero probability after
decomposition is shown in Table 2.
Ru
R1 = (d1 , d1 , d1 )
R2 = (d1 , d1 , d2 )
R3 = (d2 , d1 , d1 )

p(Ru ) after decomposition
0.2
0.4
0.4

Adjusted Routes
(d1 , d1 , d2 ) = R2
(d1 , d1 , d2 ) = R2
(d2 , d1 , d2 ) = R4

Table 2: Step (ii): Adjust each route greedily.

R1
R2
R3
R4

Ru
= (d1 , d1 , d1 )
= (d1 , d1 , d2 )
= (d2 , d1 , d1 )
= (d2 , d1 , d2 )

p0 (Ru ) after adjustment
0
0.6
0
0.4

Composed Flow Distribution




 




Table 3: Step (iii): compose a new compact representation.
The new routes we get after step (ii) are same as the original routes or dominate the
original routes. That is, whenever a route Ru is chosen according to the defender mixed
strategy resulting from step (i), it is always equally good or better to choose the corresponding new route Ru0 instead, because Ru0 provides equal or more protection to the
targets than Ru . Suppose there are H possible routes in the defender strategy after step
(i), denoted as R1 , ..., RH . After adjusting the routes, we get a new defender strategy
(p0 (R1 ), p0 (R2 ), ..., p0 (RH )) in full representation (See Table 3). Some routes are taken with
higher probability (e.g. p0 (R2 ) = 0.2 + 0.4 = 0.6) and some are with lower probability
(e.g. p0 (R3 ) = 0) compared to the original strategy. For step (iii), we reconstruct a new
compact representation according to Equation 4. This is accomplished via a process that
is the inverse of decomposition and is exactly the same as how we map a strategy in full
representation into compact representation. For the example above, the result is shown in
Table 3.
Theorem 3. After steps (i)(iii), we get a new defender strategy f 1 that dominates the
original one f 0 if f 1 is different from f 0 .
Proof: We continue to use the notation that the decomposition in step (i) yields the
routes R1 , ..., RH . For each flow distribution variable in the original distribution f 0 (i, j, k), it
is decomposed into H sub-flows {fu0 (i, j, k)} according to the route decomposition. fu0 (i, j, k) =
p(Ru ) if i = ru (k), j = ru (k + 1) and fu0 (i, j, k) = 0 otherwise. Thus we have the following
equation.
XH
f 0 (i, j, k) =
f 0 (i, j, k)
(26)
u=1 u
X
=
fu0 (i, j, k)
(27)
u:ru (k)=i,ru (k+1)=j

After adjust each route separately, each non-zero sub-flow fu0 (i, j, k) on edge E(u, k) is moved
to edge E(u0 , k) as route Ru is adjusted to Ru0 . Reconstructing the flow distribution f 1
606

fiProtecting Moving Targets with Multiple Mobile Resources

can also be regarded as adding up all the sub-flows after adjustment together on each edge.
That means, f 1 is composed of a set of sub-flows after adjustment, denoted as {fu1 (i0 , j 0 , k)}.
The subscript u represents for the index of the original route to indicate it is moved from
edge E(u, k). So fu1 (i0 , j 0 , k) = fu0 (ru (k), ru (k + 1), k), if i0 = Ru0 (k) and j 0 = Ru0 (k + 1);
otherwise fu1 (i0 , j 0 , k) = 0. Similarly to Equation 27, we have the following equation for f 1 .
f 1 (i0 , j 0 , k) =
=

XH

f 1 (i0 , j 0 , k)
u=1 u

X
u0 :ru0 (k)=i0 ,ru0 (k+1)=j 0

(28)
fu1 (i0 , j 0 , k)

(29)

Based on how the adjustment is made, Ru0 is same as or dominates Ru and thus E(u0 , k)
is same as or dominates E(u, k). So if edge E(u, k) protects target Fq at time t, the
corresponding edge E(u0 , k) after adjustment also protects target Fq at time t.
Recall from Section 3.3 that (Fq , t) is the sum of f (i, j, k) whose corresponding edge
Ei,j,k can protect the target Fq at time t. We denote by  0 (Fq , t) and  1 (Fq , t) the probabilities of protection corresponding to f 0 and f 1 respectively. According to Equation 27,
 0 (Fq , t) can be viewed as the sum of all the non-zero sub-flows fu0 (i, j, k) where the corresponding E(u, k) protects the target Fq at time t. If fu0 (i, j, k) is a term in the summation
to calculate  0 (Fq , t), it means E(u, k) protects Fq at t and thus the corresponding E(u0 , k)
protects Fq at t, so the corresponding sub-flow fu1 (ru0 (k), ru0 (k + 1), k) in f 1 is also a term in
the summation to calculate  1 (Fq , t). It leads to the conclusion  0 (Fq , t)   1 (Fq , t). Note
that if q, t,  0 (Fq , t) =  1 (Fq , t), then all routes kept unchanged in step (ii) as otherwise
it contradicts with the fact that the new route dominates the original route. According to
Corollary 2, we have f 1 dominates f 0 if it is different from f 0 .
In the example in Figure 7, f 0 (1, 1, 2) is decomposed into two non-zero terms f10 (1, 1, 2) =
0.2 and f30 (1, 1, 2) = 0.4 along with routes R1 and R3 (See Figure 7). After adjustment, we
get the corresponding subflows f11 (1, 2, 2) = 0.2, f31 (1, 2, 2) = 0.4. Recall that the targets
schedule is d1  d1  d2 . The flow distribution after adjustment (See Table 5) gives more
protection to the target in [t2 , t3 ]. Since the flow is equal from t1 to t2 (and therefore the
protection is the same), overall the new strategy dominates the old strategy.
Therefore, if we apply route-adjust to the optimal defender strategy calculated by CASS
we get a more robust equilibrium. While step (iii) allows us to prove Theorem 3, notice
that at the end of step (ii), we have a probability distribution over a set of routes from
which we can sample actual patrol routes. For two or more defender resources, a generalized
version of Definition 8 can be used to define the dominance relation on the edge tuple
(Ei1 ,j1 ,k , ..., EiW ,jW ,k ) with coefficient matrix for multiple patrollers Arqk (i1 , j1 , ..., iW , jW ).
There are other ways to adjust each route. Instead of adjusting only one node in the
route, we can adjust more consecutive nodes at a time, for example, we can adjust both
ru0 (k  ) and ru0 (k  + 1) by checking edges E(u0 , k   1), E(u0 , k  ) and E(u0 , k  + 1). However,
we need to tradeoff the performance and the efficiency of the algorithm. This tradeoff will
be further discussed in Section 7.
4.2 Flow Adjust
Whereas route-adjust tries to select an equilibrium that is robust against attackers playing
suboptimal strategies, the second approach, flow-adjust, attempts to select a new equilibri607

fiFang, Jiang, & Tambe

um that is robust to rational attackers that are constrained to attack during any time interval [tk , tk+1 ]. As we will discuss below, flow-adjust focuses on a weaker form of dominance,
which implies that a larger set of strategies are now dominated (and thus could potentially
be eliminated) compared to the standard notion of dominance used by route-adjust; however flow-adjust does not guarantee the elimination of all such dominated strategies. We
denote by DefEUkf the defender expected utility when an attacker is constrained to attack
during time interval [tk , tk+1 ] when the attacker provides his best response given the defender strategy f . Formally, DefEUkf = minq{1...L},t[tk ,tk+1 ] {DefEUf (Fq , t)}. We give the
following definition of local dominance.
Definition 10. Defender strategy f locally dominates f 0 if DefEUkf  DefEUkf 0 , k.2
Corollary 3. Defender strategy f locally dominates f 0 if
min
q{1...L},t[tk ,tk+1 ]

{DefEUf (Fq , t)} 

min
q{1...L},t[tk ,tk+1 ]

{DefEUf 0 (Fq , t)}, k,

or equivalently in this zero-sum game,
max
q{1...L},t[tk ,tk+1 ]

{AttEUf (Fq , t)} 

max
q{1...L},t[tk ,tk+1 ]

{AttEUf 0 (Fq , t)}, k.

Corollary 3 follows from the fact that the attacker plays a best response given the
defender strategy, and it means that f locally dominates f 0 if the maximum of attacker
expected utilities in each time interval [tk , tk+1 ] given f is no greater than that of f 0 .
Compared to Definition 7, which gives the standard condition for dominance, local
dominance is a weaker condition; that is, if f dominates f 0 then f locally dominates f 0 ,
however the converse is not necessarily true. Intuitively, whereas in Definition 7 the attacker
can play any (possibly suboptimal) strategy, here the attackers possible deviations from
best response are more restricted. As a result, the set of locally dominated strategies
includes the set of dominated strategies. From Definition 10, if f locally dominates f 0 , and
the attacker is rational (i.e., still playing a best response) but constrained to attack during
some time interval [tk , tk+1 ], then f is preferable to f 0 for the defender. A further corollary
is that even if the rational attacker is constrained to attack in the union of some of these
intervals, f is still preferable to f 0 if f locally dominates f 0 . One intuition for the local
dominance concept is the following: suppose we suspect the attacker will be restricted to
a (unknown) subset of time, due to some logistical constraints. Such logistical constraints
would likely make the restricted time subset to be contiguous or a union of a small number
of contiguous sets. Since such sets are well-approximated by unions of intervals [tk , tk + 1],
local dominance can serve as an approximate notion of dominance with respect to such
attackers.
Flow-adjust looks for a defender strategy f 1 that locally dominates the original defender
strategy f 0 . To achieve this, we simply adjust the flow distribution variables f (i, j, k) while
keeping the marginal probabilities p(i, k) the same. Figure 8 shows an example game with
two discretized intervals [t1 , t2 ] and [t2 , t3 ] (only the first interval is shown). Suppose the
maximal attacker expected utility is 5U0 in this equilibrium and is attained in the second
2. We dont require that there exists at least one k such that DefEUkf > DefEUkf 0 .

608

fiProtecting Moving Targets with Multiple Mobile Resources

interval [t2 , t3 ]. If the attackers utility for success is a constant U0 in the first interval
[t1 , t2 ], then the defender strategy in [t1 , t2 ] could be arbitrarily chosen because the attackers
expected utility in [t1 , t2 ] in worst case is smaller than that of the attackers best response in
[t2 , t3 ]. However, if a attacker is constrained to attack in [t1 , t2 ] only, the defender strategy
in the first interval will make a difference. In this example, there is only one target moving
from d1 to d2 during [t1 , t2 ]. The schedule of the ferry is shown as dark lines and the parallel
lines L11 and L21 with respect to protection radius re = 0.2(d2  d1 ) are shown as dashed
lines. The marginal distribution probabilities p(i, k) are all 0.5 and protection coefficient
C1 = 1. In f 0 , the defenders strategy is taking edges E1,1,1 and E2,2,1 with probability
0.5 and the attackers maximum expected utility is U0 , which can be achieved around time
(t1 + t2 )/2 when neither of the two edges E1,1,1 and E2,2,1 are within the targets protection
range. If we adjust the flows to edge E1,2,1 and E2,1,1 , as shown in Figure 8(b), the attackers
maximum expected utility in [t1 , t2 ] is reduced to 0.5U0 as edge E1,2,1 is within the targets
protection range all the way. So a rational attacker who is constrained to attack between
[t1 , t2 ] will get a lower expected utility given defender strategy f 1 than given f 0 , and thus
the equilibrium with f 1 is more robust to this kind of deviation on the attacker side.

 

 








 




 


(a) f 0 : the patroller is taking
edges E1,1,1 and E2,2,1 with
probability 0.5.










(b) f 1 : the patroller is taking
edges E1,2,1 and E2,1,1 with
probability 0.5.

Figure 8: An example of flow adjust. An rational attacker who is constrained to attack in
[t1 , t2 ] will choose to attack around time (t1 + t2 )/2 to get utility U0 given f 0 and
attack around t1 or t2 to get utility 0.5U0 given f 1 .

So in flow-adjust, we construct M  1 new linear programs, one for each time interval
[tk , tk +1 ], k  = 1 . . . M  1 to find a new set of flow distribution probabilities f (i, j, k  )
to achieve the lowest local maximum in [tk , tk +1 ] with unchanged p(i, k  ) and p(i, k  + 1).
609

fiFang, Jiang, & Tambe

The linear program for an interval [tk , tk +1 ] is shown below.
min v

f (i,j,k )

f (i, j, k  ) = 0, if |dj  di | > vm  t
n
X

p(i, k + 1) =
f (j, i, k  ), i  {1 . . . n}
j=1

p(i, k  ) =

n
X

f (i, j, k  ), i  {1 . . . n}

j=1

v  AttEU (Fq , tk ), q  {1 . . . L}, k  {k  , k  + 1}
(r+1)

r+
v  max{AttEU (Fq , qk
 ), AttEU (Fq , qk 

)}

q  {1 . . . L}, r  {0 . . . Mqk }
While the above linear program appears similar to the linear program of CASS, they have
significant differences. Unlike CASS, the marginal probabilities p(i, k  ) here are known
constants and are provided as input and as mentioned above, there is a separate program
for each [tk , tk +1 ]. Thus, we get f (i, j, k  ) such that the local maximum in [tk , tk +1 ] is
minimized. Denote the minimum as vk1 . From the original flow distribution f 0 , we get
AttEUf 0 (Fq , t) and we denote the original local maximum value in [tk , tk +1 ] as vk0 . As
the subset {f 0 (i, j, k  )} of the original flow distribution f 0 is a feasible solution of the linear
program above, we have vk1  vk0 , noting that the equality happens for the interval from
which the attackers best response is chosen.
Note that any change made to f (i, j, k) in an interval [tk , tk +1 ] will not affect the
performance of f in other intervals as the marginal probabilities p(i, k) are kept the same,
i.e., changing f (i, j, k  ) based on the linear program above is independent from any change
to f (i, j, k), k 6= k  . So we can solve the M  1 linear programs independently. After
calculating f (i, j, k  ) for all k  = 1..M  1, we can get the new defender strategy f 1 by
combining the solutions f (i, j, k  ) of the different linear programs together. As vk1  vk0 ,
we have
max
q{1...L},t[tk ,tk +1 ]

AttEUf 0 (Fq , t) 

max
q{1...L},t[tk ,tk +1 ]

AttEUf 1 (Fq , t)

for all k  = 1..M  1, i.e., f 1 locally dominates f 0 .
On the other hand, while we have restricted the strategies to have the same p(i, k),
there may exist another strategy f 2 with a different set of p(i, k) that locally dominates f 1 .
Finding locally dominating strategies with different p(i, k) from the original is a topic of
future research.
Although the two refinement approaches we provide do not necessarily lead to a nondominated strategy under the corresponding dominance definition, these two approaches
are guaranteed to find a more robust (or at least indifferent) equilibrium when faced with
constrained attackers compared to the original equilibrium we obtain from CASS. Clearly,
these two refinement approaches do not exhaust the space of refinement approaches 
other refinement approaches are possible that may lead to other equilibria that are better
610

fiProtecting Moving Targets with Multiple Mobile Resources

than (e.g. dominate) the one found by CASS. However, it is likely that different defender
strategies resulting from different equilibrium refinements are not comparable to each other
in terms of dominance, i.e., with some constrained attackers, one equilibrium might turn
out to be better and with other constrained attackers, another equilibrium might be better.
Their computational costs may differ as well. Thus, understanding this space of refinement
approaches in terms of their computational cost and output quality, and determining which
approach should be adopted under which circumstances is an important challenge for future
work.

5. Extension To Two-Dimensional Space
Both DASS and CASS presented in Section 3 are based on the assumption that both the
targets and the patrollers move along a straight line. However, a more complex model is
needed in some practical domains. For example, Figure 9 shows a part of the route map of
Washington State Ferries, where there are several ferry trajectories. If a number of patroller
boats are tasked to protect all the ferries in this area, it is not necessarily optimal to simply
assign a ferry trajectory to each of the patroller boat and calculate the patrolling strategies
separately according to CASS described in Section 3. As the ferry trajectories are close to
each other, a patrolling strategy that can take into account all the ferries in this area will be
much more efficient, e.g., a patroller can protect a ferry moving from Seattle to Bremerton
first, and then change direction halfway and protect another ferry moving from Bainbridge
Island back to Seattle.

Figure 9: Part of route map of Washington State Ferries
In this section, we extend the previous model to a more complex case, where the targets and patrollers move in a two-dimensional space and provide the corresponding linearprogram-based solution. Again we use a single defender resource as an example, and generalize to multiple defenders at the end of this section.
5.1 Defender Strategy for 2-D
As in the one-dimensional case, we need to discretize the time and space for the defender
to calculate the defenders optimal strategy. The time interval T is discretized into a set
of time points T = {tk }. Let G = (V, E) represents the graph where the set of vertices V
corresponds to the locations that the patrollers may be at, at the discretized time points in
T , and E is the set of feasible edges that the patrollers can take. An edge e  E satisfies
611

fiFang, Jiang, & Tambe

the maximum speed limit of patroller and possibly other practical constraints (e.g., a small
island may block some edges).
5.2 DASS for 2-D
When the attack only occurs at the discretized time points, the linear program of DASS
and described in Section 3 can be applied to the two-dimensional settings when the distance
in Constraint 9 is substituted with Euclidean distance in 2-D space of nodes Vi and Vj .
min

v

(30)

f (i,j,k),p(i,k)

f (i, j, k)  [0, 1], i, j, k

(31)

f (i, j, k) = 0, i, j, k such that ||Vj  Vi || > vm t

(32)

p(i, k) =

N
X

f (j, i, k  1), i, k > 1

(33)

f (i, j, k), i, k < M

(34)

j=1

p(i, k) =

N
X
j=1

N
X

p(i, k) = 1, k

(35)

i=1

v  AttEU(Fq , tk ), q, k

(36)

Note that f (i, j, k) now represents the probability that a patroller is moving from node Vi to
Vj during [tk , tk+1 ]. Recall in Figure 2.1, a patroller protects all targets within her protective
circle of radius re . However, in the one-dimensional space, we only care about the straight
line AB, so we used q (t) = [max{Sq (t)  re , d1 }, min{Sq (t) + re , dN }] as the protection
range of target Fq at time t, which is in essence a line segment. In contrast, here the whole
circle needs to be considered as the protection range in the two-dimensional space and the
extended protection range can be written as q (t) = {V = (x, y) : ||V  Sq (t)||  re }. This
change affects the value of I(i, q, k) and thus the value of AttEU (Fq , tk ) in Constraint 36.
5.3 CASS for 2-D
When the attacking time t can be chosen from the continuous time interval T , we need to
analyze the problem in a similar way as in Section 3.3. The protection radius is re , which
means only patrollers located within the circle whose origin is Sq (t) and radius is re can
protect target Fq . As we assume that the target will not change its speed and direction
during time [tk , tk+1 ], the circle will also move along a line in the 2-D space. If we track the
circle in a 3-D space where the x and y axes indicate the position in 2-D and the z axis is
the time, we get an oblique cylinder, which is similar to a cylinder except that the top and
bottom surfaces are displaced from each other (See Figure 10). When a patroller moves
from vertex Vi ( V ) to vertex Vj during time [tk , tk+1 ], she protects the target only when
she is within the surface. In the 3-D space we described above, the patrollers movement
can be represented as a straight line.
612

fiProtecting Moving Targets with Multiple Mobile Resources

d





V



V

  





  

r

Figure 10: An illustration of the calculation of intersection points in the two-dimensional
setting. The x and y axes indicates the position in 2-D and the z axis is the
time. To simplify the illustration, z axis starts from time tk . In this example,
there are two intersection points occurring at time points ta and tb .

Intuitively, there will be at most two intersection points between the patrollers route
in 3-D space and the surface. This can be proved by analytically calculating the exact
time of these intersection points. Assume the patroller is moving from V1 = (x1 , y1 ) to
V2 = (x2 , y2 ) and the target is moving from Sq (tk ) = (x1 , y1 ) to Sq (tk+1 ) = (x2 , y2 ) during
[tk , tk+1 ] (an illustration is shown in Figure 10). To get the time of the intersection points,
we solve a quadratic equation with these coordination parameters and protection radius
re . We present the detailed calculation in Appendix B. If a root of the quadratic equation
is within the interval [tk , tk+1 ], it indicates that the patrollers route intersects with the
surface at this time point. So there will be at most two intersection points. Once we find all
these intersection points, the same analysis in Section 3.3 applies and we can again claim
Lemma 1. So we conclude that we only need to consider the attackers strategies at these
r as in the one-dimensional case to denote
intersection points. We use the same notation qk
the sorted intersection points and get the following linear program for the 2-D case.
min

v

(37)

f (i,j,k),p(i,k)

subject to constraints(31 . . . 36)
(r+1)

r+
v  max{AttEU(Fq , qk
), AttEU(Fq , qk

)}

(38)

k  {1 . . . M }, q  {1 . . . L}, r  {0 . . . Mqk }
Algorithm 1 can still be used to add constraints to the linear program of CASS for the
2-D case. The main difference compared to CASS in the 1-D case is that since Euclidean
distance in 2-D is used in Constraint 32 we need to use the extended definition of q (t) in
2-D when deciding the entries in the coefficient matrix Arqk (i, j).
For multiple defender resources, again the linear program described in Section 3.4 is applicable when the extended definition of q (t) is used to calculate AttEU and Constraint 19
613

fiFang, Jiang, & Tambe

is substituted with the following constraint:
f (i1 , j1 , . . . , iW , jW , k) = 0, i1 , . . . , iW , j1 , . . . , jW such that u, kVju  Viu k > vm t.

6. Route Sampling
We have discussed how to generate an optimal defender strategy in the compact representation; however, the defender strategy will be executed as taking a complete route. So
we need to sample a complete route from the compact representation. In this section, we
give two methods of sampling and show the corresponding defender strategy in the full
representation when these methods are applied.
The first method is to convert the strategy in the compact representation into a Markov
strategy. A Markov strategy in our setting is a defender strategy such that the patrollers
movement from tk to tk+1 depends only on the location of the patroller at tk . We denote
by (i, j, k) the conditional probability of moving from di to dj during time tk to tk+1 given
that the patroller is located at di at time tk . In other words (i, j, k) represents the chance
of taking edge Ei,j,k given that the patroller is already located at node (tk , di ). Thus, given
a compact defender strategy specified by f (i, j, k) and p(i, k), we have
(i, j, k) = f (i, j, k)/p(i, k), if p(i, k) > 0.

(39)

(i, j, k) can be an arbitrary number if p(i, k) = 0. We can get a sampled route by first
determining where to start patrolling according to p(i, 1); then for each tk , randomly choose
where to go from tk to tk+1 according to the conditional probability distribution (i, j, k).
The distribution from this sampling procedure matches the given marginal variables as each
edge Ei,j,k is sampled with probability p(i, k)(i, j, k) = f (i, j, k). This sampling method
actually leads to a full representation where route Ru = (dru (1) , dru (2) , ..., dru (M ) ) is sampled
Q 1
with probability p(ru (1), 1) M
k=1 (ru (k), ru (k + 1), k), the product of the probability of
the initial distribution and the probability of taking each step. This method is intuitively
straightforward and the patrol route can be decided online during the patrol, i.e., the
position of the patroller at tk+1 is decided when the patroller reaches its position at tk ,
which makes the defender strategy more unpredictable. The downside of the method is
that the number of routes chosen with non-zero probability can be as high as N M . For
2-D case, the patroller is located at node Vi at time tk . The sampling process is exactly
the same when (i, j, k) is used to denote the probability of moving from Vi to Vj during
[tk , tk+1 ].
The second method of sampling is based on the decomposition process mentioned in
Section 4.1 (step (i)). As we discussed above for the first sampling method, sampling is
essentially restoring a full representation from the compact representation. As shown in
Table 1, there are multiple ways to assign probabilities to different routes and the decomposition process of route-adjust constructively defines one of them. So we can make use
of the information we get from the process, and sample a route according to the probability
assigned to each decomposed route. The number of routes chosen with non-zero probability
is at most N 2 M , much less than the first method and thus it becomes feasible to describe
the strategy in full representation, by only providing the routes that are chosen with positive probability. Different sampling approaches may be necessitated by different application
614

fiProtecting Moving Targets with Multiple Mobile Resources

requirements. Some applications might require that the defender obtain a strategy in full
representation and only be presented a small number of pure strategies. However, for other
applications, a strategy that can be decided on-line, potentially with a hand-held smartphone such as in (Luber, Yin, Fave, Jiang, Tambe, & Sullivan, 2013) may be preferred.
Therefore, based on the needs of the application, different sampling strategies might be
selected.

7. Evaluation
We use different settings in the ferry protection domain and compare the performance in
terms of the attackers expected utility AttEU(Fq , t). As it is a zero-sum game, a lower
value of AttEU indicates a higher value of defenders expected utility.
We will run experiments both for 1-D and 2-D setting. We will evaluate the performance
of CASS and show the sampling results. We will also evaluate the improvement of the two
refinement approaches for 1-D. Section 7.1 shows our results for the 1-D setting; Section
7.2 for the 2-D setting.
7.1 Experiments for One Dimensional Setting
For 1-D setting, we first evaluate the performance of the solvers and then show how much
the performance can be improved by using the refinement methods. We also show sampled
routes for an example setting and evaluate CASS for varying number of patrollers.
7.1.1 Experimental Settings
We used the following setting for the experiments in one dimensional case. This is a complex
spatio-temporal game; rather than a discrete security game as in most previous work. There
are three ferries moving between terminals A and B and the total distance AB = 1. The
simulation time is 30 minutes. The schedules of the ferries are shown in Figure 11, where
the x-axis indicates the time and the y-axis is the distance from terminal A. Ferry 1 and
Ferry 3 are moving from A to B while Ferry 2 is moving from B to A. The maximum speed
for patrollers is vm = 0.1/min and the protection radius is re = 0.1. Experiments in the
one-dimensional case are using 2 patrollers (where C1 = 0.8, and C2 = 1.0), except in
Section 7.1.5 where we report on experiments with different numbers of patrollers.

d  distance

1

0.5

0
0

Ferry1
Ferry2
Ferry3

10

t  time

20

30

Figure 11: Schedules of the ferries

615

fiFang, Jiang, & Tambe

7.1.2 Performance of Solvers
We compare the strategies calculated by CASS with DASS and a baseline strategy. In the
baseline strategy, the two patrollers choose a ferry with a probability of 1/3 (uniformly
random) and move alongside it to offer it full protection, leaving the other two unprotected
(strategy observed in practice). First we wished to stress-test CASS by using more complex
utility functions than in the realistic case that follows. Therefore, we tested under 4 different
discretization levels (details about discretization levels are included in Table 4) with random
utilities, and at each discretization level, we created 20 problem instances. The problem
instances are different across levels. In this ferry protection domain, the utility function for
each ferry usually depends on the ferrys position, so each instance has utilities uniformly
randomly chosen between [0, 10] at discretized distance points; an example is shown in
Figure 12(a). The chosen discretization levels have ensured that Uq (t) is linear in t in each
time interval [tk , tk+1 ] for each target Fq . In Figure 12(a), the x-axis indicates the distance d
from terminal A, the y-axis indicates the utility of a successful attack if the ferry is located
at distance d. In Figure 12(b), x-axis plots the four discretization levels and y-axis plots the
average attacker expected utility if he plays best response over the 20 instances for baseline,
DASS and CASS. CASS is shown to outperform DASS and baseline and the differences
are statistically significant (p < 0.01). Note that different sets of instances are generated
for different discretization levels, so we cannot compare the results across levels directly.
However, it is helpful in better understanding the models. From the figure, we find the
solution quality of DASS varies a lot and sometimes can be worse than the naive strategy
(e.g., level 1). This is because DASS calculates an optimal solution that considers only the
attacks at the discretized time points. In Figure 12(b), the solution quality is measured by
AttEU m , which is calculated as the maximum over the continuous attacker strategy set.
The gap between the optimal objective function of DASS and the actual AttEU m given the
optimal solution of DASS may vary for different strategies and different discretization levels.
Another interesting observation is that the average solution quality of CASS is almost the
same for all discretization levels. Despite the difference in instance sets, this result implies
that the improvement of a finer discretization may be limited for CASS.
Level
1
2
3
4

t (minutes)
10
5
2.5
2

M
4
7
13
16

d
0.5
0.25
0.125
0.1

N
3
5
9
11

Table 4: Details about discretization levels. In the experiments mentioned in this section,
the distance space is evenly discretized, parameterized by d = di+1  di .

Next we turn to more realistic utility function in this ferry domain, which is of U -shape
or inverse U -shape. Figure 13(a) shows a sample utility curve where the attacker gains
higher utility closer to the shore. We fix the utility at the shore as 10, vary the utility in
the middle (denoted as Umid ), which is the value on the floor of the U -shape or the top of
the inverse U -shape and evaluate the strategies. In Figure 13(b), Umid is shown on x-axis
616

fiProtecting Moving Targets with Multiple Mobile Resources

8

Ave(AttEUm)

U  utility

10

5

0
0

0.5
d  distance

1

(a) Randomized attacker utility function

NAIVE
DASS
CASS

6
4
2
0

Level1 Level2 Level3 Level4

(b) Average solution quality of different
strategies

Figure 12: Performance under different randomized utility function settings. The utility
function in this set of experiments is a function of the distance to Terminal A.
The utility function is piece-wise linear and the value at discretized distance
points di is chosen randomly between [0,10].

15
Sup(AttEU)

U  utility

10
8
6
4
0

0.5
d  distance

5
0
0

1

(a) Realistic attacker utility function with
Umid = 5

10

NAIVE
DASS
CASS

5

10
Umid

15

20

(b) Solution quality of different strategies

Figure 13: Performance under different realistic utility function settings. The utility function is U-shape or inverse U-shape. The utility around distance 0.5 is denoted
as Umid . We compare the defender strategy given by DASS and CASS with the
baseline when Umid is changing from 1 to 20.

and we compare performance of the strategies in terms of attackers expected utility when
he plays best response on the y-axis. We conclude that 1) the strategy calculated by CASS
outperforms the baseline and DASS; 2) DASS may actually achieve worse results than the
baseline.
Among all these different experiment settings of discretization and utility function, we
choose one instance and provide a more detailed analysis for it. We refer to this instance
as example setting in the following of this section. In this example setting, discretization
level 4 is used and the utility curve is as shown in Figure 13(a), other parameters involved
are described in Section 7.1.1. Figure 14 compares the attacker expected utility function
when DASS and CASS is used respectively. The x-axis indicates the time t, and the y-axis
indicates the attackers expected utility if he attacks Ferry 1 at time t. For the strategy calculated by DASS, the worst performance at discretized time points is 3.50 (AttEU(F1 , 20)),
however, the supremum of AttEU(F1 , t), t  [0, 30] can be as high as 4.99 (AttEU(F1 , 4+ )),
617

fiFang, Jiang, & Tambe

5

AttEU

4
3
2
1
0

DASS
CASS
10
20
t  time

30

Figure 14: The attackers expected utility function given the defender strategy calculated by
DASS vs CASS under example setting. The expected utilities at the discretized
time points are indicated by squares for CASS and dots for DASS. The maximum
of AttEU under CASS is 3.82, 30%less than the maximum of AttEU under
DASS, which is 4.99.

which experimentally shows that taking into consideration the attacks between the discretized time points is necessary. For the strategy calculated by CASS, the supremum of
AttEU(F1 , t) is reduced to 3.82.
7.1.3 Improvement Using Refinement Methods
We compare the refinement approaches described in Section 4 and analyze the tradeoff
between performance improvement and runtime. Three approaches are considered for comparison: route-adjust, flow-adjust and a variation of route-adjust, denoted by route-adjust2.
In step (ii) of route-adjust, we replace every node in the route one-by-one in sequence.3 In
step (ii) of route-adjust2, we replace every consecutive pair of nodes in the route in sequence.
We first show results for the example setting. In Figure 15(a), we compare the AttEU(Fq , t)
function of the defender strategy given by CASS and of the one after route-adjust for Ferry
1. It shows for an attack aiming at any target at any time, the defender strategy after
route-adjust refinement is equally good or better than the one in the original equilibrium,
and thus the defender performs equally or better no matter how the attacker is constrained
in time, i.e., the defender strategy after route-adjust dominates the original strategy. Figure
15(b) is the comparison between AttEU function of the defender strategy after route-adjust
and the one after route-adjust2 for Ferry 1. The one after route-adjust2 does not dominate
the one after route-adjust but overall the former appears to perform better than the latter
more frequently and by larger amounts. If we use the average value of AttEU function as a
metric of performance, we will show that route-adjust2 is better than route-adjust in this
example setting later in Table 5. Figure 15(c) shows the comparison between the AttEU
function of the defender strategy given by CASS and that of the defender strategy after
3. In supplementary experiments, we also tested route-adjust with more iterations, e.g., repeating the
process of replacing every node in sequence five times. The extra benefit is insignificant while the
runtime increases proportionally to the number of iterations. In light of this, we choose to replace each
node only once in the experiments reported in this article.

618

fi4

4

3

3

AttEU

AttEU

Protecting Moving Targets with Multiple Mobile Resources

2

CASS
RouteAdjust

1
0

10

t  time

20

2
1
0

30

(a) AttEU function of Ferry 1 after
route-adjust (one node at a time)

RouteAdjust
RouteAdjust2
10

t  time

20

30

(b) AttEU function of Ferry 1 after
route-adjust2 (two nodes at a time)

AttEU

4
3
2
1
0

CASS
FlowAdjust
10

t  time

20

30

(c) Performance of flow-adjust

Figure 15: Performance of equilibrium refinement approaches.
flow-adjust for Ferry 1. The strategy given by CASS is not dominated by the one after
flow-adjust under Definition 7, but if we investigate the maximum of AttEU in each time
interval [tk , tk+1 ], as shown in Table 6, we find that the defender strategy after flow-adjust
locally dominates the original strategy.
We list the worst case performance and the average performance of AttEU function over
all ferries in this example setting for four defender strategies (CASS, route-adjust, routeadjust2, flow-adjust) in Table 5, from which we conclude that 1) the worst case performance
of all strategies of flow-adjust is the same, which means the defender achieves exactly same
expected utility towards an unconstrained rational attacker; 2) the average performance
of flow-adjust is slightly better than the CASS, but is outperformed by route-adjust and
route-adjust2, while it takes much less time to run compared to the other two; 3) in this
example setting, when we adjust two consecutive nodes at a time, the performance is better
than adjusting only one node at a time, but the difference is not significant and it is much
more expensive in terms of run-time.
Strategies
CASS
Route-Adjust
Route-Adjust2
Flow-Adjust

Worst Case Performance
3.82
3.82
3.82
3.82

Average Performance
3.40
2.88
2.76
3.34

Runtime (minutes)
8.96
32.31
0.50

Table 5: Comparison of different refinement approaches in terms of average performance
and runtime. Only the runtime for the refinement process is calculated.

619

fiFang, Jiang, & Tambe

time interval [tk , tk+1 ]
[2, 4]
[4, 6]
[6, 8]
[8, 10]
[10, 12]
[12, 14]
[14, 16]

maximum
before
3.7587
3.8182
3.8153
3.8137
3.8052
3.8050
3.7800

maximum
after
3.6675
3.8182
3.6164
3.6316
3.6316
3.5664
3.2100

time interval [tk , tk+1 ]
[16, 18]
[18, 20]
[20, 22]
[22, 24]
[24, 26]
[26, 28]
[28, 30]

maximum
before
3.8111
3.8182
3.8182
3.8182
3.8182
3.8182
3.8182

maximum
after
3.7291
3.8182
3.8182
3.8182
3.8182
3.8182
3.8182

Table 6: The maximum of attackers expected utility in each time interval decreases after
flow-adjust is used.

Figure 16(a) and Figure 16(b) shows the maximum and the average improvement of
route-adjust, route-adjust2 and flow-adjust, averaged over all the 20 instances of Level 4
with randomized utilities that have been used for Figure 12(b); and Figure 16(c) shows the
average runtime. The maximum improvement is the largest difference between the AttEU
function given defender strategy calculated by CASS and the one after refinement. The
average improvement is the average difference between the two functions. The standard
deviations over all instances are shown as error bars. Figure 16 confirms that all the refinement approaches improve the defender strategy calculated by CASS in terms of both the
maximum performance and average performance and thus provide better defender strategies given possible constrained attackers. Route-adjust2 achieves the most improvement,
then route-adjust, and flow-adjust the least. Flow-adjust achieves much less improvement
compared to the other two approaches. One explanation for this is that the constraints are
very strong as they require all marginal probabilities to be unchanged so it is likely that
little changes are made to the original defender strategy. The difference between routeadjust2 and route-adjust is not as significant. In terms of run-time, flow-adjust is the least
expensive, route-adjust the second and route-adjust2 the most. Route-adjust2 is significantly more expensive compared to the other two. So we conclude that route-adjust is a
better choice considering the tradeoff between improvement and the runtime.
7.1.4 Sampled Routes
We first convert the defender strategy under the example setting into a Markov strategy
and sample 1000 pair of patrol routes. The defender strategy used here is the one after
route-adjust. In each sample, a pair of routes is chosen step by step for the two patrol
boats according to the joint conditional probability distribution {(i1, j1, i2, j2, k)}. The
routes for the two patrol routes are chosen simultaneously as they are coordinating with
each other. We cannot show each pair separately for all 1000 samples. Instead, Figure
17(a) shows the frequency of being taken out of the 1000 samples of each edge. The x-axis
indicates the time and the y-axis is the distance to terminal A. The width of the each edge
indicates the frequency of being chosen by at least one patroller. Although Figure 17(a)
does not precisely depict the samples, it provides a rough view of how the routes are taken
by the patrol boats.
620

fiProtecting Moving Targets with Multiple Mobile Resources

0.6

routeadjust
routeadjust2
flowadjust

2

Ave Improvement

Max Improvement

2.5

1.5
1
0.5

routeadjust
routeadjust2
flowadjust

0.4
0.2

0

0

Runtime (minutes)

(a) Average of maximal improvement

(b) Average of average improvement
routeadjust
routeadjust2
flowadjust

40
30
20
10
0

(c) Average of runtime

Figure 16: Comparison of refinement approaches.

Figure 17(b) shows the pair of routes that is of highest probability when we use the
decomposition method of sampling. The solid lines show the patrol boats routes and the
dashed lines show the ferries schedules. We get 3958 different pair of patrol routes in total
in the decomposition process and the shown pair of routes is chosen with probability 1.57%.

1

d  distance

d  distance

1
0.8
0.6
0.4
0.2
0
0

5

10

15

20

25

0.8
0.6

0.2
0
0

30

t  time

Patrol Boat 1
Patrol Boat 2

0.4

5

10

15

20

25

30

t  time

(a)

(b)

Figure 17: Results for sampling under the example setting: (a) Frequency of each edge is
chosen when the first sampling method based on Markov strategy is used. (b)
Decomposed routes with highest probability superimposed on ferry schedules
when the second sampling method based on decomposition is used.

621

fiAttacker EU

6
4

log(Runtime (seconds))

Fang, Jiang, & Tambe

1 patroller
2 patrollers
3 patrollers
4 patrollers

2
0

1
0
1

3

Attacker EU

4

(b) Runtime of Level 1
log(Runtime (seconds))

(a) Solution quality of Level 1
5

1 patroller
2 patrollers
3 patrollers
4 patrollers

2

1 patroller
2 patrollers
3 patrollers

3
2
1
0

(c) Solution quality of Level 2

3
2

1 patroller
2 patrollers
3 patrollers

1
0
1
2

(d) Runtime of Level 2

Figure 18: Performance with varying number of patrollers.

7.1.5 Number of Patrollers
Figure 18(a) shows the improvement in performance of CASS with increasing number of
patrollers under discretization Level 1. The x-axis shows the number of patrollers and the
y-axis indicates the average of attackers maximal expected utility, i.e., the expected reward
when he plays his best response. The results are averaged over 20 random utility settings
of discretization Level 1. With fewer patrollers, the performance of the defender varies a lot
depending on the randomized utility function (as indicated by standard deviation shown as
the error bar). But the variance gets much smaller with more patrollers, which means the
defender has sufficient resources for different instances. Figure 18(b) shows the run-time for
CASS. The y-axis indicates the average of natural logarithm of runtime. Not surprisingly,
the run-time increases when the number of patrollers increases.
Figure 18(c) and 18(d) show the average performance and run-time of CASS with discretization Level 2, using the same set of utility settings as used in Level 1. Only results for
1 to 3 patrollers are shown. The program runs out of memory for 4 patrollers as there are
N 8 M = 2734375 flow distribution variables and at least N 4 M = 8757 constraints. Note
that the average solution quality of Level 2 is better than the result of Level 1 (e.g., the
average attacker EU for 1 patroller is 4.81 in Level 1 and 4.13 in Level 2), which indicates
a higher level of granularity can improve the solution quality. However, granularity clearly
affect the ability to scale-up; which means that we need to consider the tradeoff between the
solution quality and the memory used and one way to combat the scaling-up problem is to
reduce the level of granularity. Nonetheless, the number of patrollers we have encountered
in real-world scenarios such as at New York is of the order of 3 or 4, so CASS is capable at
least for key real-world scenarios.
622

fiProtecting Moving Targets with Multiple Mobile Resources

7.1.6 Approximation Approach for Multiple Defender Resources
We tested the first approximation approach for multiple defender resources described in
Section 3.4 for the example setting. We used the fmincon function with interior-point
method in MATLAB to minimize the non-linear objective function (Equation 25). Table
7 lists different run-time and the value of the objective function achieved given different
iteration number (denoted as MaxIter ). The function is not ensured to provide a feasible
solution when the iteration number is not large enough, as shown in the first two rows.
We compared the result with our LP formulation of DASS, which was implemented in
MATLAB using linprog function. DASS can be solved within 8.032 seconds and provides
an optimal solution AttEUm = 3.5, this approximation approach is outperformed in both
run-time efficiency and solution quality. This approach fails to provide a feasible solution
efficiently and even when sufficient time is given (more than 400 times the run-time of the
LP formulation), the maximum attacker expected utility is 18% larger than the optimal
solution. This is mainly because the new formulation in the approximation approach is no
longer linear or convex, making it difficult to find a global maximum.
M axIter
3000
10000
900000

Run  time(sec)
4.14
17.21
3298

AttEUm
infeasible
infeasible
4.0537

Table 7: Performance of approximation approach.

7.2 Experiments for Two Dimensional Setting
The settings in 2-D space are more complex even with single patroller. Here we show
an example setting motivated by the ferry system between Seattle, Bainbridge island and
Bremerton as shown in Figure 9. In this example setting, three terminals (denoted as A,B
and C) are non-collinear in the 2-D space as shown in the Figure 19(a). Ferry 1 and Ferry
2 are moving on the trajectory between Terminal B and C (denoted as Trajectory 1) and
Ferry 3 and Ferry 4 are moving on the trajectory between Terminal B and A (denoted as
Trajectory 2). The schedules of the four ferries are shown in Figure 19(b), where the x-axis
is the time and the y-axis is the distance from the common terminal B. Ferry 1 moves
from C to B, Ferry 2 moves from B to C, Ferry 3 moves from B to A and Ferry 4 moves
from A to B. Similar to the one-dimensional scenario in ferry domain, we assume the utility
is decided by the ferrys position and the utility function is shown in Figure 19(c). The
x-axis is the distance from the common terminal B and the y-axis is the utility for the two
trajectories respectively. The 2-D space is discretized into a grid as shown in Figure 19(d)
with x = 1.5 and y = 1 indicating the interval in the x-axis and y-axis. A patroller will
be located at one of the intersection points of the grid graph at any discretized time points.
The simulation time is 60 minutes and M = 13, i.e., tk+1  tk = 5 minutes. The speed limit
for the patroller is ve = 0.38 and all the available edges that a patroller can take during
[tk , tk+1 ] are shown in Figure 19(d). Only one patroller is involved. The protection radius
is set to re = 0.5, and protection coefficient is C1 = 0.8.
623

fiFang, Jiang, & Tambe

C

2

y

distance from Terminal B

Terminals in 2D
Trajectory 1
B

1

Trajectory 2
0

A
0

1.5

3

4.5

x

Ferry Schedules
1

0.6
0.4
0.2
0
0

60

Edges Available
2

Ferry Trajectory1
Ferry Trajectory2

6

y

utility

40

(b) Ferry schedules

Utility Function
8

20

time

(a) Three terminals
10

Ferry1
Ferry2
Ferry3
Ferry4

0.8

1

4
2
0
0

0.2

0.4

0.6

0.8

0
0

1

1.5

3

4.5

x

distance from Terminal B
(c) Utility function

(d) Available edges

Figure 19: An example setting in two-dimensional space
Figure 20(a) compares the performance of DASS and CASS for Ferry 2. Ferry 2 is chosen
because in both strategies, the attackers best response is to attack Ferry 2. The x-axis is
the time t, and the y-axis is the attacker expected utility of attacking Ferry 1 at time t. The
maximum of AttEU of CASS is 6.1466, 12% lower compared to the result of DASS, which
is 6.9817. Figure 20(b) and 20(c) show two sampled route given the strategy calculated
by CASS on the 2-D map where the dashed lines represents for the ferry trajectories. The
patroller starts from the node with text start and follows the arrowed route, and ends at
the node with text end at the end of the patrol. She may stay at the nodes with text
stay. The patrol routes are shown in a intuitive way but can be ambiguous. The exact
route should be listed as a table with time and position. The routes are sampled based on
the converted Markov strategy, and the total number of patrol routes that may be chosen
with non-zero probability is 4.49  1010 .

8. Related Work
In this section we discuss literature related to our work. We will first discuss work on
the computation of game-theoretic patrolling strategies, then discuss work on continuous
games, and finally discuss work on equilibrium refinement.
As mentioned in the introduction, Stackelberg games have been widely applied to security domains, although most of this work has considered static targets (e.g., Korzhyk
et al., 2010; Krause, Roper, & Golovin, 2011; Letchford & Vorobeychik, 2012; Kiekintveld
624

fiProtecting Moving Targets with Multiple Mobile Resources

Sampled Route by CASS

7

stay

6
y

AttEU

2

4
0

stay
staystart
end

1

DASS
CASS

5

0

20
40
t  time

60

0

1.5

3

4.5

x

(a) Solution quality of DASSand CASS for
Ferry 2

(b) Sampled route 1 superimposed on ferry
trajectories

Sampled Route by CASS
staystart

y

2

stay
end

1

0
0

1.5

3

4.5

x
(c) Sampled route 2 superimposed on ferry
trajectories

Figure 20: Experimental results under two-dimensional settings

et al., 2013). Agmon, Kraus, and Kaminka (2008) proposed algorithms for computing
mixed strategies for setting up a perimeter patrol in adversarial settings with mobile robot
patrollers. Similarly, Basilico, Gatti, and Amigoni (2009) computed randomized leader strategies for robotic patrolling in environments with arbitrary topologies. Even when both
of the players are mobile, e.g., in hider-seeker games (Halvorson, Conitzer, & Parr, 2009),
infiltration games (Alpern, 1992) or search games (Gal, 1980), the targets (if any) were assumed to be static. Tsai et al. (2009) applied Stackelberg games to the domain of scheduling
federal air marshals on board flights. The targets (i.e., flights) in this domain are mobile,
but the players are restricted to move along the targets to protect or attack them. This
stationary nature leads to discrete game models with finite numbers of pure strategies.
Bosansky, Lisy, Jakob, and Pechoucek (2011) and Vanek, Jakob, Hrstka, and Pechoucek
(2011) studied the problem of protecting moving targets. However, they both considered
a model in which the defender, the attacker and targets have discretized movements on a
directed graph. Such discretization of attacker strategy spaces can introduce suboptimality
in the solutions, as we have shown with DASS. We, in our work, generalize the strategy space of the attacker to the continuous realm and compute optimal strategies even in
such a setting. Furthermore, while we provide an efficient and scalable linear formulation,
Bosansky et al. presented a formulation with non-linear constraints, which faced problems
scaling up to larger games even with a single defender resource.
625

fiFang, Jiang, & Tambe

Yin et al. (2012) considered the domain of patrolling in public transit networks (such
as the LA Metro subway train system) in order to catch fare evaders. Because the players
ride along trains that follow a fixed schedule, the domain is inherently discrete and they
modeled the patrolling problem as a finite zero-sum Bayesian game. Yin et al. proposed a
compact representation for defender mixed strategies as flows in a network. We adapt this
compact representation idea to a continuous domain. In particular, in our domain we need
to model the interaction between the defenders flow and attackers continuous strategy
space. Our proposed sub-interval analysis used spatio-temporal reasoning to efficiently
reduce the problem into a finite LP.
Games with continuous strategy spaces have been well-studied in game theory. Much of
the economics literature has focused on games whose equilibria can be solved analytically
(and thus the question of computation does not arise), for example the classical theory
of auctions (see e.g., Krishna, 2009). Recent computational approaches for the analysis
and design of auctions have focused on discretized versions of the auction games (e.g.,
Thompson & Leyton-Brown, 2009; Daskalakis & Weinberg, 2012). There has been research
on efficiently solving two-player continuous games with specific types of utility functions,
such as zero-sum games with convex-concave utility functions (Owen, 1995) and separable
continuous games with polynomial utility functions (Stein, Ozdaglar, & Parrilo, 2008).
Johnson, Fang, and Tambe (2012) studied a continuous game model for protecting forests
from illegal logging. In their model the target (i.e., the forest) is stationary, and with further
simplifying assumptions (e.g., the forest having a circular shape) they were able to solve
the game efficiently. In contrast to existing work, our game model has moving targets in a
continuous domain, and the resulting utility functions are discontinuous and thus existing
approaches are not applicable. Our CASS algorithm solves the game optimally without
needing to discretize the attackers strategy space.
There is an extensive literature on equilibrium refinement; however most existing work
on the computation of equilibrium refinement focuses on finite games. For simultaneousmove finite games, solution concepts such as perfect equilibrium and proper equilibrium
were proposed as refinements of Nash equilibrium (Fudenberg & Tirole, 1991). Miltersen
and Srensen (2007) proposed an efficient algorithm for computing proper equilibria in finite zero-sum games. For finite security games, An et al. (2011) proposed a refinement
of Stackelberg equilibrium and techniques for computing such refinements. The resulting
defender strategy is robust against possibilities of constrained capabilities of the attacker.
These existing approaches rely on the finiteness of action sets, and is thus not applicable to
our setting. Simon and Stinchcombe (1995) proposed definitions of perfect equilibrium and
proper equilibrium for infinite games with continuous strategy sets, however they did not
propose any computational procedure for the resulting solution concepts. Exact computation of equilibrium refinements of continuous games such as MRMTsg remains a challenging
open problem.

9. Conclusion
This paper makes several contributions in computing optimal strategies given moving targets and mobile patrollers. First, we introduce MRMTsg , a novel Stackelberg game model
that takes into consideration spatial and temporal continuity. In this model, targets move
626

fiProtecting Moving Targets with Multiple Mobile Resources

with fixed schedules and the attacker chooses his attacking time from a continuous time
interval. Multiple mobile defender resources protect the targets within their protection
radius, and bring in continuous space in our analysis. Second, we develop a fast solution
approach, CASS, based on compact representation and sub-interval analysis. Compact representations dramatically reduce the number of variables in designing the optimal patrol
strategy for the defender. Sub-interval analysis reveals the piece-wise linearity in attacker
expected utility function and shows there is a finite set of dominating strategies for the attacker. Third, we propose two approaches for equilibrium refinement for CASSs solutions:
route-adjust and flow-adjust. Route-adjust decomposes the patrol routes, greedily improves
the routes and composes the new routes together to get the new defender strategy. Flowadjust is a fast and simple algorithm that adjusts the flow distribution to achieve optimality
in each time interval while keeping the marginal probability at the discretized time points
unchanged. Additionally, we provide detailed experimental analyses in the ferry protection
domain. CASS has been deployed by the US Coast Guard since April 2013.

10. Future Work
There are several important avenues for future work. These include: (i) use a decreasing
function to model the protection provided to the targets instead of using a fixed protection
radius; (ii) handle practical constraints on patrol boat schedule as not all are easily implementable; (iii) efficiently handle more complex and uncertain target schedules and utility
functions.
Here we provide an initial discussion about the relaxation of the assumptions that we
listed in Section 2 and used throughout the paper:
 If we allow for complex and uncertain target schedules, we may model the problem as
a game where the targets follow stochastic schedules. Our framework may still apply
but may need to be enriched (e.g., using approaches such as use of MDPs to represent
defender strategies, see Jiang, Yin, Zhang, Tambe, & Kraus, 2013). Coordinating
multiple such defenders then becomes an important challenge. It may be helpful in
such cases to appeal to more of the prior work on multi-agent teamwork, given the
significant uncertainty in such cases leading to more need for on-line coordination
(Tambe, 1997; Stone, Kaminka, Kraus, & Rosenschein, 2010; Kumar & Zilberstein,
2010; Yin & Tambe, 2011).
 If we focus on environments where multiple attackers can coordinate their attacks,
then we may need to further enhance our framework. Prior results from Korzhyk,
Conitzer, and Parr (2011) over stationary targets and discrete time would be helpful
in addressing this challenge, although the case of moving targets in continuous space
and time in such cases provides a very significant challenge. Combining with the
previous item for future work, a complex multiple defender multiple attacker scenario
would appear to be a very significant computational challenge.

627

fiFang, Jiang, & Tambe

Acknowledgments
We thank the USCG officers, and particularly Craig Baldwin, Joe Direnzo and Francis
Varrichio and officers at sector New York, for their exceptional collaboration. The views
expressed herein are those of the author(s) and are not to be construed as official or reflecting
the views of the Commandant or of the U.S. Coast Guard. This research is supported by
US Coast Guard grant HSHQDC-10-D-00019 and MURI grant W911NF-11-1-0332. We
also thank the anonymous reviewers for valuable suggestions.
A preliminary version of this work appears as the conference paper (Fang, Jiang, &
Tambe, 2013). There are several major advances in this article: (i) Whereas the earlier work
confined targets to move in 1-D space, we provide a significant extension of our algorithms
(DASS and CASS) in this article to enable the targets and the patrollers to move in 2D space; we also provide detailed experimental results on this 2-D extension. (ii) We
provide additional novel equilibrium refinement approaches and experimentally compare
their performance with the equilibrium refinement approach offered in our earlier work;
this allows us to offer an improved understanding of the equilibrium refinement space. (iii)
We discuss several sampling methods in detail to sample actual patrol routes from the mixed
strategies we generate  a discussion that was missing in our earlier work. (iv) We provide
detailed proofs that were omitted in the previous version of the work.

628

fiProtecting Moving Targets with Multiple Mobile Resources

Appendix A. Notation Table

Notation
MRMT
MRMTsg
L
Fq
A, B
T
D
Sq (t)
W
Pu
vm
re
CG
Uq (t)
M
N
tk
di
t
Ru
ru (k)
f (i, j, k)
p(i, k)
Ei,j,k
p(Ru )
AttEU(Fq , t)
q (t)
(Fq , t)
I(i, q, k)
L1q ,L2q
r
qk
r
AttEU(Fq , qk
)
Mqk
Arqk (i, j)
E(u, k)

Meaning
The problem of multiple Mobile Resources protecting Moving Targets
Game model with a continuous set of strategies for the attacker for MRMT.
Number of ferries.
Ferry with index q.
Terminal points.
Continuous time interval or a finite set of time points.
Continuous space of possible locations or a set of distance points.
Ferry schedule. Position of the target Fq at a specified time t.
Number of patrollers.
Patroller with index u.
Speed limit of patroller.
Protection radius of patroller.
Probability that the attacker can be stopped with G patrollers.
Positive reward of a successful attack on target Fq at time t for the attacker.
Number of discretized time points.
Number of discretized distance points.
Discretized time point.
Discretized distance point.
Distance between two adjacent time points.
Patrol route for patroller Pu . Under discretization of the defenders strategy space,
Ru can be described as a vector.
The patroller is located at dru (k) at time tk .
Flow distribution variable. Probability that the patroller moves from di to dj
during time [tk , tk+1 ].
Marginal distribution variable. Probability that the patroller is located at di tk .
The directed edge linking nodes (tk , di ) and (tk+1 , dj ).
Probability of taking route Ru .
Attacker expected utility of attacking target Fq at time t.
Protection range of target Fq at time t
Probability that the patroller is protecting target Fq at time t.
Whether a patroller located at di at time tk is protecting target Fq .
Lines of Sq (t)  re .
The rth intersection point in [tk , tk+1 ] with respect to target Fq .
r .
Left/right-side limit of AttEU(Fq , t) at qk
Number of intersection points in [tk , tk+1 ] with respect to target Fq .
r ,  r+1 ]; 0 otherwise.
C1 if patroller taking edge Ei,j,k can protect target Fq in [qk
qk
Short for Eru (k),ru (k+1),k .
Table 8: Summary of notations involved in the paper.

629

fiFang, Jiang, & Tambe

Appendix B. Calculation of Intersection Points in CASS for 2-D Settings
We calculate the time where the patrollers route intersects with the protection range for
a target when the patroller is moving from V1 = (x1 , y1 ) to V2 = (x2 , y2 ) and the target
is moving from Sq (tk ) = (x1 , y1 ) to Sq (tk+1 ) = (x2 , y2 ) during [tk , tk+1 ]. The patrollers
position at a given time t  [tk , tk+1 ] is denoted as (x, y) and the targets position is denoted
as (x, y). Then we have
t  tk
(x2  x1 ) + x1 ,
tk+1  tk
t  tk
(x2  x1 ) + x1 ,
x =
tk+1  tk

t  tk
(y2  y1 ) + y1
tk+1  tk
t  tk
y =
(y2  y1 ) + y1
tk+1  tk

x=

y=

(40)
(41)

At an intersection point, the distance from the patrollers position to the targets position
equals to the protection radius re , so we are looking for a time t such that
(x  x)2 + (y  y)2 = re2

(42)

By substituting the variables in Equation 42 with Equations 4041, and denoting
(x2  x1 )  (x2  x1 )
,
tk+1  tk
(y2  y1 )  (y2  y1 )
A2 =
,
tk+1  tk
A1 =

B1 = x1  x1 ,
B2 = y1  y1 ,

Equation 42 can be simplified to
(A1 t  A1 tk + B1 )2 + (A2 t  A2 tk + B2 )2 = re2 .

(43)

Denote C1 = B1  A1 tk and C2 = B2  A2 tk , and we can easily get the two roots of this
quadratic equation, which are
p
2(A1 C1 + A2 C2 )  2 (A1 C1 + A2 C2 )2  (A21 + A22 )(C12 + C22  re2 )
ta,b =
.
(44)
2(A21 + A22 )
ta or tb is the time of a valid intersection point if and only if it is within the time interval
under consideration ([tk , tk+1 ]).

References
Agmon, N., Kraus, S., & Kaminka, G. A. (2008). Multi-robot perimeter patrol in adversarial
settings. In IEEE International Conference on Robotics and Automation (ICRA), pp.
23392345.
Alpern, S. (1992). Infiltration Games on Arbitrary Graphs. Journal of Mathematical Analysis and Applications, 163, 286288.
630

fiProtecting Moving Targets with Multiple Mobile Resources

An, B., Kempe, D., Kiekintveld, C., Shieh, E., Singh, S. P., Tambe, M., & Vorobeychik, Y.
(2012). Security games with limited surveillance. In Proceedings of the Twenty-Sixth
AAAI Conference on Artificial Intelligence, pp. 12411248.
An, B., Tambe, M., Ordonez, F., Shieh, E., & Kiekintveld, C. (2011). Refinement of strong
stackelberg equilibria in security games. In Proceedings of the Twenty-Fifth AAAI
Conference on Artificial Intelligence (AAAI), pp. 587593.
Basilico, N., Gatti, N., & Amigoni, F. (2009). Leader-follower strategies for robotic patrolling in environments with arbitrary topologies. In Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS) Volume 1, pp. 5764.
Bosansky, B., Lisy, V., Jakob, M., & Pechoucek, M. (2011). Computing time-dependent
policies for patrolling games with mobile targets. In The 10th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS) - Volume 3, pp. 989996.
Conitzer, V., & Sandholm, T. (2006). Computing the optimal strategy to commit to. In
Proceedings of the 7th ACM Conference on Electronic Commerce, EC 06, pp. 8290.
Daskalakis, C., & Weinberg, S. M. (2012). Symmetries and optimal multi-dimensional mechanism design. In Proceedings of the 13th ACM Conference on Electronic Commerce,
EC 12, pp. 370387.
Fang, F., Jiang, A. X., & Tambe, M. (2013). Optimal patrol strategy for protecting moving
targets with multiple mobile resources. In Proceedings of the 2013 International Conference on Autonomous Agents and Multi-agent Systems, AAMAS 13, pp. 957964.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Gal, S. (1980). Search Games. Academic Press, New York.
Gatti, N. (2008). Game theoretical insights in strategic patrolling: Model and algorithm in
normal-form. In Proceedings of the 18th European Conference on Artificial Intelligence
(ECAI), pp. 403407.
Greenberg, M., Chalk, P., & Willis, H. (2006). Maritime terrorism: risk and liability. Rand
Corporation monograph series. RAND Center for Terrorism Risk Management Policy.
Halvorson, E., Conitzer, V., & Parr, R. (2009). Multi-step Multi-sensor Hider-Seeker Games.
In IJCAI.
Jakob, M., Vanek, O., & Pechoucek, M. (2011). Using agents to improve international
maritime transport security. Intelligent Systems, IEEE, 26 (1), 9096.
Jiang, A. X., Yin, Z., Zhang, C., Tambe, M., & Kraus, S. (2013). Game-theoretic randomization for security patrolling with dynamic execution uncertainty. In Proceedings
of the 2013 international conference on Autonomous agents and multi-agent systems,
AAMAS 13, pp. 207214.
Johnson, M. P., Fang, F., & Tambe, M. (2012). Patrol strategies to maximize pristine forest
area. In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence
(AAAI), pp. 295301.
631

fiFang, Jiang, & Tambe

Kiekintveld, C., Islam, T., & Kreinovich, V. (2013). Security games with interval uncertainty. In Proceedings of the 2013 International Conference on Autonomous Agents
and Multi-agent Systems, AAMAS 13, pp. 231238.
Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ordonez, F., & Tambe, M. (2009). Computing
optimal randomized resource allocations for massive security games. In Proceedings
of The 8th International Conference on Autonomous Agents and Multiagent Systems
- Volume 1, AAMAS 09, pp. 689696.
Korzhyk, D., Conitzer, V., & Parr, R. (2010). Complexity of computing optimal Stackelberg
strategies in security resource allocation games. In Proceedings of the 24th National
Conference on Artificial Intelligence (AAAI), pp. 805810.
Korzhyk, D., Conitzer, V., & Parr, R. (2011). Security games with multiple attacker resources. In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence - Volume Volume One, IJCAI11, pp. 273279. AAAI Press.
Krause, A., Roper, A., & Golovin, D. (2011). Randomized sensing in adversarial environments. In Proceedings of the 22nd International Joint Conference on Artificial
Intelligence (IJCAI), pp. 21332139.
Krishna, V. (2009). Auction theory. Academic press.
Kumar, A., & Zilberstein, S. (2010). Anytime planning for decentralized POMDPs using
expectation maximization. In Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence, pp. 294301.
Letchford, J. (2013). Computational Aspects of Stackelberg Games. Ph.D. thesis, Duke
University.
Letchford, J., & Conitzer, V. (2013). Solving security games on graphs via marginal probabilities. In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI), pp. 591597.
Letchford, J., & Vorobeychik, Y. (2012). Computing optimal security strategies for interdependent assets. In The Conference on Uncertainty in Artificial Intelligence (UAI),
pp. 459468.
Luber, S., Yin, Z., Fave, F. D., Jiang, A. X., Tambe, M., & Sullivan, J. P. (2013). Gametheoretic patrol strategies for transit systems: the trusts system and its mobile app
(demonstration). In International Conference on Autonomous Agents and Multiagent
Systems (AAMAS)[Demonstrations Track], pp. 13771378.
Marecki, J., Tesauro, G., & Segal, R. (2012). Playing repeated stackelberg games with unknown opponents. In Proceedings of the 11th International Conference on Autonomous
Agents and Multiagent Systems, AAMAS 12, pp. 821828.
Miltersen, P. B., & Srensen, T. B. (2007). Computing proper equilibria of zero-sum games.
In Proceedings of the 5th International Conference on Computers and Games, CG06,
pp. 200211.
Owen, G. (1995). Game Theory (3rd ed.). Academic Press.
632

fiProtecting Moving Targets with Multiple Mobile Resources

Paruchuri, P., Tambe, M., Ordonez, F., & Kraus, S. (2006). Security in multiagent systems
by policy randomization. In Proceedings of the fifth international joint conference on
Autonomous agents and multiagent systems, AAMAS 06, pp. 273280.
Pita, J., Jain, M., Marecki, J., Ordonez, F., Portway, C., Tambe, M., Western, C., Paruchuri,
P., & Kraus, S. (2008). Deployed ARMOR protection: the application of a game theoretic model for security at the Los Angeles International Airport. In Proceedings of the
7th International Joint Conference on Autonomous Agents and Multiagent Systems:
Industrial Track, AAMAS 08, pp. 125132.
Pita, J., Jain, M., Ordonez, F., Portway, C., Tambe, M., Western, C., Paruchuri, P., &
Kraus, S. (2009). Using game theory for los angeles airport security.. AI Magazine,
30, 4357.
Shieh, E., An, B., Yang, R., Tambe, M., Baldwin, C., DiRenzo, J., Maule, B., & Meyer,
G. (2012). PROTECT: A deployed game theoretic system to protect the ports of the
United States. In Proceedings of the 11th International Conference on Autonomous
Agents and Multiagent Systems - Volume 1, AAMAS 12, pp. 1320.
Simon, L. K., & Stinchcombe, M. B. (1995). Equilibrium refinement for infinite normal-form
games. Econometrica, 63 (6), 14211443.
Stein, N. D., Ozdaglar, A., & Parrilo, P. A. (2008). Separable and low-rank continuous
games. International Journal of Game Theory, 37 (4), 475504.
Stone, P., Kaminka, G. A., Kraus, S., & Rosenschein, J. S. (2010). Ad hoc autonomous
agent teams: Collaboration without pre-coordination. In Proceedings of the 24th AAAI
Conference on Artificial Intelligence, pp. 15041509.
Tambe, M. (1997). Towards flexible teamwork. JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH, 7, 83124.
Tambe, M. (2011). Security and Game Theory: Algorithms, Deployed Systems, Lessons
Learned. Cambridge University Press.
Thompson, D. R. M., & Leyton-Brown, K. (2009). Computational analysis of perfectinformation position auctions. In Proceedings of the 10th ACM conference on Electronic commerce, EC 09, pp. 5160.
Tsai, J., Rathi, S., Kiekintveld, C., Ordonez, F., & Tambe, M. (2009). IRIS - a tool for
strategic security allocation in transportation networks. In The Eighth International
Conference on Autonomous Agents and Multiagent Systems - Industry Track, AAMAS
09, pp. 3744.
van Damme, E. (1987). Stability and Perfection of Nash equilibria. Springer-Verlag.
Vanek, O., Jakob, M., Hrstka, O., & Pechoucek, M. (2011). Using multi-agent simulation
to improve the security of maritime transit. In Proceedings of 12th International
Workshop on Multi-Agent-Based Simulation (MABS), pp. 116.
Vorobeychik, Y., & Singh, S. (2012). Computing stackelberg equilibria in discounted stochastic games. In Proceedings of the Twenty-Sixth Conference on Artificial Intelligence (AAAI), pp. 14781484.
633

fiFang, Jiang, & Tambe

Yin, Z., Jiang, A. X., Johnson, M. P., Kiekintveld, C., Leyton-Brown, K., Sandholm, T.,
Tambe, M., & Sullivan, J. P. (2012). TRUSTS: Scheduling randomized patrols for
fare inspection in transit systems. In Proceedings of the Twenty-Fourth Conference
on Innovative Applications of Artificial Intelligence (IAAI), pp. 23482355.
Yin, Z., & Tambe, M. (2011). Continuous time planning for multiagent teams with temporal
constraints. In Proceedings of the Twenty-Second international joint conference on
Artificial Intelligence - Volume Volume One, IJCAI11, pp. 465471. AAAI Press.

634

fiJournal of Artificial Intelligence Research 48 (2013) 1-22

Submitted 12/12; published 10/13

Natural Language Inference for Arabic Using Extended Tree
Edit Distance with Subtrees
Maytham Alabbas

maytham.alabbas@gmail.com

Department of Computer Science, University of Basrah,
Basrah, Iraq

Allan Ramsay

Allan.Ramsay@manchester.ac.uk

School of Computer Science, University of Manchester,
Manchester, M13 9PL, UK

Abstract
Many natural language processing (NLP) applications require the computation of similarities between pairs of syntactic or semantic trees. Many researchers have used tree edit
distance for this task, but this technique suffers from the drawback that it deals with single node operations only. We have extended the standard tree edit distance algorithm to
deal with subtree transformation operations as well as single nodes. The extended algorithm with subtree operations, TED+ST, is more effective and flexible than the standard
algorithm, especially for applications that pay attention to relations among nodes (e.g. in
linguistic trees, deleting a modifier subtree should be cheaper than the sum of deleting
its components individually). We describe the use of TED+ST for checking entailment
between two Arabic text snippets. The preliminary results of using TED+ST were encouraging when compared with two string-based approaches and with the standard algorithm.

1. Introduction
Tree edit distance has been widely used as a component of natural language processing (NLP)
systems that attempt to determine whether one text snippet supports an inference to another
(roughly speaking, whether the first entails the second), with the distance between pairs of
dependency trees being taken as a measure of the likelihood that one entails the other. We
extend the standard algorithm for calculating the distance between two trees by allowing
operations to apply to subtrees, rather than just to single nodes. This extension improves
the performance of our technique for Arabic by around 5% in F-score and around 4% in
accuracy compared with a number of well-known techniques. The relative performance
of the standard techniques on our Arabic testset replicates the results reported for these
techniques for English testsets. We have also applied our extended version of tree edit
distance, TED+ST, to the English RTE-2 testset, where it again outperforms the standard
algorithm.
Tree edit distance is a generalisation of the standard string edit distance metric, which
measures the similarity between two strings. It has been used to underpin several NLP
applications such as information extraction (IE), information retrieval (IR) and natural
language inference (NLI). The edit distance between two trees is defined as the minimum
cost sequence of edit operations to transform one tree to another. There have been numerous
approaches to calculating edit distance between trees, as reported by Selkow (1977), Tai
c
!2013
AI Access Foundation. All rights reserved.

fiAlabbas & Ramsay

(1979), Zhang and Shasha (1989), Klein (1998), Demaine, Mozes, Rossman, and Weimann
(2009) and Pawlik and Augsten (2011). We have chosen to work with Zhang-Shashas
algorithm (Zhang & Shasha, 1989) because the intermediate structures produced by this
algorithm allow us to detect and respond to operations on subtrees. When we refer to the
standard tree edit distance algorithm throughout the rest of this article, we mean ZhangShashas algorithm, for which we will use the short form ZS-TED.
Our ultimate goal is to develop an NLI system for Arabic (Alabbas, 2011).1 NLI is the
problem of determining whether a natural language hypothesis h can reasonably be inferred
from a natural language premise p. The challenges of NLI are quite different from those
encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic
knowledge, and variability of linguistic expression, rather than on long chains of formal
reasoning (MacCartney, 2009). A more recent, and better-known, formulation of the NLI
task is the recognising textual entailment challenge (RTE), described by Dagan and Glickman
(2004) as a task of determining, for two text snippets premise p and hypothesis h, whether
. . . typically, a human reading p would infer that h is most likely true. According to these
authors, entailment holds if the truth of h, as interpreted by a typical language user, can be
inferred from the meaning of p. A popular method that has been used in recent years for such
tasks is the use of tree edit distance, which compares sentence pairs by finding a minimal
cost sequence of editing operations to transform a tree representation of one sentence into a
tree for the other (Kouylekov, 2006; Heilman & Smith, 2010). Approximate tree matching
of this kind allows users to match parts of two trees, rather than demanding a complete
match of every element of each tree. However, one of the main drawbacks of tree edit
distance is that transformation operations are applied solely on single nodes (Kouylekov,
2006). Kouylekov and Magnini (2005) used the standard tree edit distance, which uses
transformation operations (insert, delete and exchange) solely on single nodes, to check
the entailment between two dependency trees. On the other hand, Heilman and Smith
(2010) extended the available operations in standard tree edit distance to INSERT-CHILD,
INSERT-PARENT, DELETE-LEAF, DELETE-&-MERGE, RELABEL-NODE and RELABEL-EDGE. These
authors also identify three new operations, MOVE-SUBTREE, which means move a node X
in a tree T to be the last child on the left/right side of a node Y in T (s.t. Y is not
a descendant of X ), NEW-ROOT and MOVE-SIBLING, to enable succinct edit sequences for
complex transformation. This extended set of edit operations allows certain combinations
of the basic operations to be treated as single steps, and hence provides shorter (and therefore
cheaper) derivations. The fine-grained distinctions between, for instance, different kinds of
insertions also make it possible to assign different weights to different variations on the same
operation. Nonetheless, these operations continue to operate on individual nodes rather than
on subtrees (despite its name, even MOVE-SUBTREE appears to be defined as an operation
on nodes rather than on subtrees). We have solved this problem by extending the basic
version of the algorithm so that the costs of operations that insert/delete/exchange subtrees
are derived by some appropriate function of the costs of the operations on their parts.
This makes TED+ST more effective and flexible than the standard algorithm, especially for
applications that pay attention to relations among nodes (e.g deleting a modifier subtree, in
linguistic trees, should be cheaper than the sum of deleting its components individually).
1. In particular, for Modern standard Arabic (MSA). When we refer to Arabic throughout this article, we
mean MSA.

2

fiNatural Language Inference for Arabic

The rest of the paper is organised as follows: Zhang-Shashas algorithm, ZS-TED, is
explained in Section 2. Section 3 presents TED+ST. Section 4 describes dependency trees
matching. Dataset preparation is explained in Section 5. The experimental results are
discussed in Section 6. Conclusions are given in Section 7.

2. Zhang-Shashas TED Algorithm
Our approach extends ZS-TED, which uses dynamic programming to provide an O(n4 )
algorithm for finding the optimal sequence of node-based edit operations for transforming
one tree into another. This section contains a brief recapitulation of this algorithma more
detailed description is given by Bille (2005).
Ordered trees are trees in which the left-to-right order among siblings is significant.
Approximate tree matching allows us to match a tree with just some parts of another tree.
There are three operations, namely deleting, inserting and exchanging a node, which can
transform one ordered tree to another. There is a nonnegative real cost associated with each
edit operation. These costs are changed to match the requirements of specific applications.
Deleting a node x means attaching its children to the parent of x. Insertion is the inverse
of deletion. This means an inserted node becomes a parent of a consecutive sub-sequence
in the left to right order of its parent. Exchanging a node alters its label. All these editing
operations are illustrated in Figure 1 (Bille, 2005).

(a)

l1

l2

(b)

l1

l1

l2

(b)

l1

l1
l2

Figure 1: (a) Relabeling the node label (l1  l2 ). (b) Deleting the node labeled (l2  ).
(c) Inserting a node labeled l2 as the child of the node labeled l1 (  l2 ).

Each operation is associated with a cost and is allowed on single nodes only. Selecting
a good set of costs for these operations is hard when dealing with complex problems. This
3

fiAlabbas & Ramsay

is because alterations in these costs or choosing a different combination of them can lead to
drastic changes in tree edit distance performance (Mehdad & Magnini, 2009).
In the ZS-TED algorithm, tree nodes are compared using a postorder traversal, which
visits the nodes of a tree starting with the leftmost leaf descendant of the root and proceeding
to the leftmost descendant of the right sibling of that leaf, the right siblings, and then the
parent of the leaf and so on up the tree to the root. The last node visited will always be
the root. An example of the postorder traversal and the leftmost leaf descendant of a tree is
shown in Figure 2. In this figure, there are two trees, T1 with m=7 nodes and T2 with n=7
nodes. The subscript for each node is considered the order of this node in the postorder
of the tree. So, the postorder of T1 is e,f,b,g,c,d,a and the postorder for T2 is g,c,y,z,x,d,a.
The leftmost leaf descendant of the subtrees of T1 headed by the nodes e,f,b,g,c,d,a are
1,2,1,4,4,6,1 respectively, and similarly the leftmost leaf descendants of g,c,y,z,x,d,a in T2
are 1,1,3,4,3,3,1.
a7

a7
c5

b3
e1

f2

d6

g4

c2

d6

g1

x5
y3

T1

z4

T2

Figure 2: Two trees T1 and T2 with their postorder traversal.
For all the descendants of each node, the least cost mapping has to be calculated before
the node is encountered, in order that the least cost mapping can be selected right away.
To achieve this, the algorithm pursues the keyroots of the tree, which are defined as a
set that contains the root of the tree plus all nodes having a left sibling. Concentrating
on the keyroots is critical to the dynamic nature of the algorithm, since it is the subtrees
rooted at keyroots that allow the problem to be split into independent subproblems of the
same general kind. The keyroots of a tree are decided in advance, permitting the algorithm
to distinguish between tree distance (the distance between two nodes when considered in
the context of their left siblings in the trees T1 and T2 ) and forest distance (the distance
between two nodes considered separately from their siblings and ancestors but not from
their descendants) (Kouylekov, 2006). For illustration, the keyroots in each tree in Figure 2
are marked in bold.
For each node, the computation to find the least cost mapping (the tree distance) between
a node in the first tree and one in the second depends solely on mapping the nodes and their
children. To find the least cost mapping of a node, then, one needs to recognise the least cost
mapping from all the keyroots among its children, plus the cost of its leftmost child. Because
the nodes are numbered according to the postorder traversal, the algorithm proceeds in the
following steps (Kouylekov, 2006): (i) the mappings from all leaf keyroots are determined;
(ii) the mappings for all keyroots at the next higher level are decided recursively; and (iii)
the root mapping is found. Algorithm 1 shows the pseudocode of ZS-TED algorithm (Zhang
& Shasha, 1989). The matrices D and F D are used for recording the results of individual
4

fiNatural Language Inference for Arabic

subproblems: D is used to store the tree distance between trees rooted at pairs of nodes
in the two trees, and F D is used to store the forest distance between sequences of nodes.
F D is used as a temporary store while the tree edit distance between pairs of keyroots
are being calculated. We have extended the standard algorithm, which computes the cost
of the cheapest edit sequence, so that it also records the edit operations themselves. This
involves adding two new matrices, DPATH and FDPATH, to hold the appropriate sequences
of edit operationsDPATH to hold the edit sequences for trees rooted at pairs of nodes and
FDPATH to hold the edit sequences for forests. D and DPATH are permanent arrays,
whereas F D and FDPATH are reinitialised for each pair of keyroots.
The algorithm iterates over keyroots, and is split into two main stages for each pair of
keyroots: the initialisation phase (lines 312) deals with the first row and column, where we
assume that every cell in the first row is reached by appending the insert operation i to the
cell to its left and every cell in the first column is reached by appending the delete operation
d to the cell above it, with appropriate costs. This is exactly parallel to the initialisation of
the standard dynamic time warping algorithm for calculating string edit distance, as though
we were treating the task of matching the subsets of the subtrees rooted at T1 [x] and T2 [y]
as a string matching problem between the nodes in these two trees as sequences enumerated
in post-order.
The second stage (lines 1337) traces the cost and edit sequence for transforming each
sub-sequence of the sequence of nodes dominated T1 [x] to each sub-sequence of the sequence
of nodes dominated T2 [x], by considering whether the nodes in these were reached from the
cell to the left by an insert, or from the cell above by a delete, or by the cell diagonally above
and left by either a match m or an exchange x. There are two cases to be considered
here:
i If the two sequences under consideration are both trees (tested at line 15), then we know
that we have considered every possible way of exchanging one into the other, and hence
we can record the cost in both F D and D, and the edit sequence in both FDPATH and
DPATH. In this case, we calculate the cost of moving along the diagonal by inspection
of the two nodes. See Figure 3 for an illustration of this notion.
ii If one or both of the sequences is a forest we retrieve the cost of moving along the diagonal
from DPATH, and we just store the cost in F D and the edit sequence in FDPATH.
In both cases, we gather the set of {cost, path} pairs that result from considering insert/delete/exchange operations on the preceding sub-sequences, and choose the best such
pair to store in the various arrays. This is again very similar to the corresponding element
of the string edit algorithm, with the added complication that calculating the tree edit costs
and sequences for a pair of keyroots involves calculating the costs and edit sequences for all
pairs of sub-sequences of the nodes below those roots. The results for pairs of keyroots are
stored permanently, and are utilised during the calculations for sub-sequences at the next
stage.
Bille (2005) provides detailed worked examples of the calculation of the costs of transforming one tree into another. Figure 4 shows how FDPATH grows as the algorithm iterates
through the keyroots for the trees T1 and T2 in Figure 2. In this figure, the cells representing
5

fiAlabbas & Ramsay

Algorithm 1 pseudocode for Zhang-Shashas TED algorithm with edit sequences
T [i, j]
ith to jth nodes in the post-order enumeration of tree T (T [i, i] is written T [i])
l(i)
the leftmost leaf descendant of the subtree rooted at i
K(T )
the keyroots of tree T, K(T ) = {k  T : k1 > k with l(k1 ) = l(k)}
D[i, j]
the tree distance between two nodes T1 [i] and T2 [j]
F D[T1 [i, i1 ], T2 [j, j1 ]]
the forest distance from nodes i to i1 in T1 to nodes j to j1 in T2
DP AT H[i, j]
edit sequence for trees rooted at two nodes T1 [i] and T2 [j]
F DAT H[T1 [i, i1 ], T2 [j, j1 ]] edit sequence for forests covered by nodes i to i1 in T1 to nodes j to j1 in T2
(T1 [i]  )
cost of deleting the ith node from T1
(  T2 [j])
cost of inserting the jth node of T2 into T1
(T1 [i]  T2 [j])
cost of exchanging the ith node of T1 with the jth node of T2
m, n
the number of nodes in T1 and T2 respectively
best
choose the best cost and path from a set of options
1: for x  1 to |K1 (T1 )| do
2:
for y  1 to |K2 (T2 )| do
3:
F D[, ]  0
4:
F DP AT H[, ]   
5:
for i  l1 (x) to x do
6:
F D[T1 [l1 (x), i], ]  F D[T1 [l1 (x), i-1], ] + (T1 [i]  )
7:
F DP AT H[T1 [l1 (x), i], ]  F DP AT H[T1 [l1 (x), i-1], ] + d
8:
end for
9:
for j  l2 (y) to y do
10:
F D[, T2 [l2 (y), j]]  F D[, T2 [l2 (y), y-1]] + (  T2 [j])
11:
F DP AT H[, T2 [l2 (y), j]]  F DP AT H[, T2 [l2 (y), y-1]] + i
12:
end for
13:
for i  l1 (x) to x do
14:
for j  l2 (y) to y do
15:
if (l1 (i) == l1 (x) and l2 (j) == l2 (y)) then
16:
cost, path  best({F D[T1 [l1 (x), i-1], T2 [l2 (y), j]] + (T1 [i]  ),
17:
F DP AT H[T1 [l1 (x), i-1], T2 [l2 (y), j]] + d},
18:
{F D[T1 [l1 (x), i], T2 [l2 (y), j-1]] + (  T2 [j]),
19:
F DP AT H[T1 [l1 (x), i], T2 [l2 (y), j-1]] + i},
20:
{F D[T1 [l1 (x), i-1], T2 [l2 (y), j-1]] + (T1 [i]  T2 [j])),
21:
F DP AT H[T1 [l1 (x), i-1], T2 [l2 (y), j-1]] + m/x})
22:
F D[T1 [l1 (x), i], T2 [l2 (y), j]]  cost
23:
D[i, j]  cost
24:
F DP AT H[T1 [l1 (x), i], T2 [l2 (y), j]]  path
25:
DP AT H[i, j]  path
26:
else
27:
cost, path  best({F D[T1 [l1 (x), i-1], T2 [l2 (y), j]] + (T1 [i]  ),
28:
F DP AT H[T1 [l1 (x), i-1], T2 [l2 (y), j]] + d},
29:
{F D[T1 [l1 (x), i], T2 [l2 (y), j-1]] + (  T2 [j]),
30:
F DP AT H[T1 [l1 (x), i], T2 [l2 (y), j-1]] + i},
31:
{F D[T1 [l1 (x), i-1], T2 [l2 (y), j-1]] + D[i, j]),
32:
F DP AT H[T1 [l1 (x), i-1], T2 [l2 (y), j-1]] + DP AT H[i][j]})
33:
F D[T1 [l1 (x), i], T2 [l1 (y), j]]  cost
34:
F DP AT H[T1 [l1 (x), i], T2 [l1 (y), j]]  path
35:
end if
36:
end for
37:
end for
38:
end for
39: end for
40: return D[n, m], DP AT H[n, m]

6

fiNatural Language Inference for Arabic

i-1,j-1

i,j-1

i-1,j
x/m

d

i

i,j

Figure 3: The edit operation direction used in our algorithm. Each arc that implies an edit
operation is labeled: i for an insertion, d for deletion, x for exchanging and
m for no operation (matching).

the optimal sequence of edit operations that transform T1 into T2 are highlighted in bold,
with the final optimal path shown in the last cell (at final row and column).
T1
e
f
b
g
c
d
a

T2
d
dd
ddd
dddd
ddddd
dddddd
ddddddd

g
i
x
xd
xdd
dddm
dddmd
dddmdd
dddmddd

c
ii
xi
xid
xdx
dddmi
dddmm
dddmmd
dddmmdd

y
iii
iix
xix
xdxi
xdxx
dddmmi
dddmmx
dddmmxd

z
iiii
iiix
iixx
iixxd
xdxxi
dddmmii
dddmmxi
dddmmxid

x
iiiii
iiixi
xiiix
iixxx
xdxixi
dddmmiii
dddmmxii
dddmmxiid

d
iiiiii
iiixii
xiiiix
iixxxi
xdxixii
xdxixix
dddmmiiim
dddmmiiimd

a
iiiiiii
iiixiii
xiiiixi
iixxxii
iixxxiid
xdxixixi
dddmmiiimi
dddmmiiimm

FDPATH

Figure 4: Computing the optimal path for the trees in Figure 2.
The mapping between two trees can be found from the final sequence of edit operations
by mapping the nodes corresponding to match operation m only.
The final distance is 6 which represents the final values (at final row and column) in D.2
The last value in DPATH represents the final sequence of edit operations, namely dddmmiiimm. According to this path, we can define an alignment between two postorder trees.
The alignment between two trees T1 and T2 is obtained by inserting a gap symbol (i.e. _)
into either T1 or T2 , according to the type of edit operation, so that the resulting strings S 1
and S 2 are the same length as the sequence of edit operations. The gap symbol is inserted
into S 2 when the edit operation is delete (d), whereas it is inserted in S 1 when the edit
operation is insert (i). Otherwise, the nodes of T1 and T2 are inserted into S 1 and S 2
respectively. The following is an optimal alignment between T1 and T2 :
S 1:
S 2:

e
d
_

f
d
_

b
d
_

g
m
g

c
m
c

_
i
y

_
i
z

_
i
x

d
m
d

a
m
a

2. For simplicity here, we assume that the each single operation will cost 1 except that matching will cost
0, as described by Zhang and Shasha (1989).

7

fiAlabbas & Ramsay

This means:
d:
d:
d:
m:
m:
i:
i:
i:
m:
m:

Delete (e) from T1
Delete (f ) from T1
Delete (b) from T1
Leave (g) without change
Leave (c) without change
Insert (y) into T1
Insert (z ) into T1
Insert (x ) into T1
Leave (d) without change
Leave (a) without change

The final mapping between T1 and T2 is shown in Figure 5. For each mapping figure
the insertion, deletion, matching and exchanging operations are shown with single, double,
single dashed and double dashed outline respectively. The matching nodes (or subtrees) are
linked with dashed arrows.

a7
c5

b3
e1

f2

a7
d6

g4

c2

d6

g1

x5
y3

T1

z4

T2

Figure 5: ZS-TED, mapping between T1 and T2 .

3. Extended TED with Subtree Operations
The main weakness of the ZS-TED algorithm is that it is not able to perform transformations
on subtrees (i.e. delete subtree, insert subtree and exchange subtree). The output of ZSTED is the lowest cost sequence of operations on single nodes. We extend this to find the
lowest cost sequence of operations on nodes and subtrees, TED+ST, as follows:
1. Run ZS-TED and compute the standard alignment from the results (Algorithm 1);
2. Go over the alignment and group subtree operations. Where a sequence of identical
operations applies to a set of nodes comprising a subtree, they are replaced by a
8

fiNatural Language Inference for Arabic

single operation, whose cost is determined by some appropriate function of the costs
of the individual nodes (Algorithm 2). A variety of functions could be applied here,
depending on the application. When using the algorithm for textual entailment we
use the costs in Figure 8, which are derived from those used by Punyakanok, Roth,
and Yih (2004), but for illustration in the current section we will simply take the cost
of a subtree operation to be half the sum of the costs of the individual operations that
make it up.
It should be noted here that while we apply this technique to modify Zhang-Shashas
O(n4 ) algorithm, it could also be applied to any other algorithm for finding tree edit distance,
e.g. Kleins O(n3 logn ) algorithm (Klein, 1998), Demaine et al. O(n3 ) algorithm (Demaine,
Mozes, Rossman, & Weimann, 2009) or Pawlik and Augsten O(n3 ) algorithm (Pawlik &
Augsten, 2011), since the extension operates on the output of the original algorithm. The
additional time cost of O(n2 ) is negligible since it is less than the time cost for any available
tree edit distance algorithm.
3.1 Find a Sequence of Subtree Edit Operations
Extending ZS-TED to cover subtree operations will give us more flexibility when comparing
trees (especially linguistic trees). The key to this algorithm is that we have to find maximal
sequences of identical edit operations which correspond to subtrees. A sequence of nodes
in postorder corresponds to a subtree if the following conditions are satisfied: (i) the first
node is a leaf; and (ii) the leftmost sibling of the last node in the sequence (i.e. the root
of a subtree) is the same as the first node in the sequence. These two conditions can be
checked in constant time, since the leftmost sibling of a node can determined for each node
in advance. We can hence find maximal sequences corresponding to subtrees by scanning
forwards through the sequence of node operations to find sequences of identical operations,
and then scanning backwards through such a sequence until we find the point at which it
covers a subtree. This involves potentially O(n2 ) stepsn forward steps to find sequences of
identical operations, and then possibly n-1 backward steps each time to find sub-sequences
corresponding to subtrees. As an example, the sequence of nodes e,f,b in tree T1 in Figure 2
is a subtree because e is a leaf and the leftmost of the last node b is 1, which represents
the first node e. On the other hand, the sequence of nodes g,c,d in the same tree is not a
subtree because g is a leaf, but the leftmost of the last node d is 6, which represents itself,
not the first node g.
Algorithm 2 contains the pseudocode to find the optimal sequence of single and subtree
edit operations for transforming T1 into T2 . Ep=1..L  {d, i, x, m} in this algorithm
is an optimal sequence of node edits for transforming T1 into T2 , obtained by applying the
technique in Section 2, and S 1 and S 2 are the alignments for T1 and T2 obtained after
applying this sequence of node edits.
As shown in Algorithm 2, to find the optimal single and subtree edit operations sequence
that transforms T1 into T2 , each maximal sequence of identical operations is checked to see
whether it contains subtree(s) or not. Checking whether such a sequence corresponds to a
subtree depends on the type of edit operation, according to the following rules: (i) if the
operation is d, the sequence is checked on the first tree; (ii) if the operation is i, the
sequence is checked on the second tree; and (iii) otherwise, the sequence is checked on both
9

fiAlabbas & Ramsay

Algorithm 2 pseudocode to find subtree edit operations
E
L
S1, S2

the sequence of edit operations that transform tree T1 into tree T2 , Ep=1..L  {d,i,x,m}
the length of the sequence of edit operations E
the optimal alignment for T1 and T2 respectively, when the length of S 1 = S 2 = L

1: repeat
2:
ERoot  EL
3:
F L
4:
repeat
5:
while (F  2 and EF 1 == ERoot) do
6:
F F 1
7:
end while
8:
if (F == L) then
9:
LL1
10:
ERoot  EL
11:
F L
12:
end if
13:
until (F < L and F  2 and EF 1 )= ERoot) or (L = 0)
14:
F0  F
15:
while (F < L) do
16:
while (F < L) do
17:
IsSubtree  true
18:
while (F < L and IsSubtree) do
1
19:
if (ERoot =d and SF1 ..SL
is subtree) or
2
2
20:
(ERoot =i and SF ..SL is subtree) or
1
2
21:
((ERoot in {x,m}) and (SF1 ..SL
and SF2 ..SL
are subtrees)) then
22:
Replace EF ..EL1 with +
23:
LF 1
24:
F  F0
25:
else
26:
IsSubtree  f alse
27:
end if
28:
end while
29:
F F +1
30:
end while
31:
L L1
32:
F  F0
33:
end while
34:
L  F0  1
35: until (L  0)
36: return E

trees. After that, if the sequence of operations corresponds to a subtree, then all the symbols
of the sequence are replaced by + except the last one (which represents the root of the
subtree). Otherwise, checking starts from a sub-sequence of the original, as explained below.
For instance, let us consider Eh , ..., Et , where 1  h < L, 1 < t  L, h < t, is a sequence of
the same edit operation, i.e. Ek=h..t  {d, i, x, m}. Let us consider h0 = h, we firstly
check nodes Sh1 , ..., St1 and Sh2 , ..., St2 to see whether or not they are the heads of subtrees. If
Ek is d, the nodes Sh1 , ..., St1 are checked, if it is i the nodes Sh2 , ..., St2 are checked, and
otherwise, the nodes Sh1 , ..., St1 and Sh2 , ..., St2 are checked. All edit operations Eh , ..., Et1
are replaced by + when this sequence corresponds to a subtree. Then, we start checking
from the beginning of another sequence from the left of the subtree Eh , ..., Et , i.e. t = h  1.
10

fiNatural Language Inference for Arabic

Otherwise, the checking is applied with the sequence starting from the next position, i.e.
h = h+ 1. The checking is continued until h = t. After that, when the (t  h) sequences that
start with different positions and end with t position do not contain a subtree, the checking
starts from the beginning with the new sequence, i.e. h = h0 and t = t  1. The process is
repeated until h = t.
To explain how the subtree operations are applied, let us consider the two trees T1 and
T2 in Figure 2.
According to TED+ST, the cost is 3 and the sequence of operation is as follows: there
is a sequence of d, m and i in the result. These sequences consist of three subtrees
(i.e. the three deleted nodes, the first two matched nodes and the three inserted nodes):
ddd mm iii mm. So, the final result is: ++d +m ++i mm. This means:
++d:
+m:
++i:
m:
m:

Delete subtree (e,f,b) from T1
Leave subtree (g,c) without change
Insert subtree (y,z,x ) into T1
Leave (d) without change
Leave (a) without change

The final mapping between T1 and T2 obtained using TED+ST is shown in Figure 6.

a7
c5

b3
e1

f2

a7
d6

g4

c2

d6

g1

x5
y3

T1

z4

T2

Figure 6: TED+ST, mapping between T1 and T2 .

4. Matching Dependency Trees
As mentioned above, our main goal is to design a textual entailment (TE) system for Arabic
to check whether one text snippet (i.e. premise p) entails another text (i.e. hypothesis h).
To match p and h dependency tree pairs effectively, we use TED+ST. This enables us to
find the minimum edit operations to transform one tree to another. This allows us to be
sensitive to the fact that the links in a dependency tree carry linguistic information about
relations between complex units, and hence to ensure that we are paying attention to these
relations when we compare two trees. For instance, this enables us to pay attention to the
11

fiAlabbas & Ramsay

fact that operations involving modifiers, in particular, should be applied to the subtree as
a whole rather than to its individual elements. Thus, we transform tree D1 to tree D2 in
Figure 7 by deleting in the park in a single operation, removing the modifier as a whole,
rather than three operations removing in, the and park one by one, using the costs
in Figure 8 as an initial test for edit operations in our experiments. These costs are an
updated version of the costs used by Punyakanok et al. (2004).3 These authors found that
using tree edit distance gives better results than bag-of-word scoring methods, when they
applied them for question answering.4
saw

saw
I

I

man

in

the

park

man
the

the
D1

D2

Figure 7: Two dependency trees, D1 and D2 .

By using the costs in Figure 8, the cost of transferring D1 into D2 according to ZS-TED
is 19 (i.e. one stop word the (5) and two words (14)), whereas according to TED+ST
operations it is 0. Therefore, it is easy to decide that D1 entails D2 , whereas the reverse is not
true. We also exploited the subset/superset relations encoded by Arabic WordNet (AWN)
(Black, Elkateb, Rodriguez, Alkhalifa, Vossen, Pease, & Fellbaum, 2006) when comparing
items in a tree. Roughly speaking, if comparing one tree to another requires us to swap
two lexical items, we will be happier doing so if the item in the source tree is a synonym or
hyponym of the one in the target treesince wombat is a hyponym of animal, swapping
wombat in a premise such as I saw a wombat at the zoo for animal in I saw an animal
at the zoo is a truth-preserving exchange.
Approaches that make use of lexical relations of this kind have to cope with the fact that
words often have multiple meanings. We follow Hobbs (2005) in assuming that if W1 has a
sense which is a hyponym of some sense of W2 then a sentence involving W1 will entail a
similar sentence involving W2 as shown in (1).
(1) p.
h.

I saw a peach at yesterdays party.
I saw a very attractive woman at yesterdays party.

3. The stop words here are a list that contains some of the most common Arabic words (e.g. the particle
( +,- ./0# "#! $ An Almdyr mwl  The director is indeed busy
"#! $ An indeed). For instance, %&'! )*
( +,- ./0# Almdyr mwl  The director is busy.
entails %&'! )*
4. The transcription of Arabic examples in this document follows Habash-Soudi-Buckwalter (HSB) transliteration scheme (Habash, Soudi, & Buckwalter, 2007) for transcribing Arabic symbols.

12

fiNatural Language Inference for Arabic

Cost

Single node

Subtree (more than one node)

Delete:

if X is a stop word then cost is 5,
else cost is 7
if a Y is a stop word then cost is
5,
else cost is 100
if X is subsumed by Y cost is 0,
elseif X is a stop word cost is 5,
elseif Y is subsumed by (or is an
antonym of) a X then cost is 100
else cost is 50

0

Insert:

Exchange:

double the sum of the costs of its parts

if S1 is identical to S2 then cost is 0
else half the sum of the costs of its parts

Figure 8: Edit operation costs.
In (1p), for instance, the word peach is ambiguous,5 a shade of pink tinged with yellow
(hypernym: Pink) or Downy juicy fruit with sweet yellowish or whitish flesh (hypernym:
Drupe, edible fruit, stone fruit) or a very attractive or seductive looking woman (hypernym:
Adult female, women) or cultivated in temperate regions (hypernym: Fruit tree). In the
context of (1h), however, any human reader would assume that the second interpretation of
peach was intended, despite the fact that it is in general a fairly unusual usage.
This reflects the widely accepted view that contextual information is the key to lexical
disambiguation. Within the RTE task, the premise provides the context for disambiguation
of the hypothesis, and the hypothesis provides the context for disambiguation of the premise.
Almost any human reader would, for instance, accept that (2p) entails (2h), despite the
potential ambiguity of the word bank.
(2) p.
h.

My money is all tied up at the bank.
I cannot easily spend my money.

5. Dataset Preparation
In order to train and test our TE system for Arabic, we need an appropriate dataset. To
our knowledge, no such datasets are available for Arabic, so we have had to develop one.
We have followed one of the procedures used for collecting the premise-hypothesis pairs in
the RTE tasks, with a slight alteration. The premises in RTE were collected from a variety
of sources, e.g. newswire text. They contain one or two sentences and tend to be fairly long
(e.g. averaging 25 words in RTE1, 28 words in RTE2, 30 words in RTE3 and 39 words in
RTE4). In contrast, the hypotheses are quite short single sentences (averaging 11 words in
RTE1, 8 words in RTE2 and 7 words in RTE3 and RTE4), which were manually constructed
for each premise. The first three RTE Challenges were presented as a binary classification
task yes or no with balanced numbers of yes and no problems. Beginning with RTE4,
there were three-way classifications (yes, no, or contradict, to distinguish cases in which
h contradicts p from those in which h is compatible with, but not entailed by p). In our
5. See Sages dictionary online: http://www.sequencepublishing.com/thesageonline.php. WordNet also
provides all these senses (and more) for peach.

13

fiAlabbas & Ramsay

dataset, we do not want to produce a set of p-h pairs by handpartly because doing so is a
lengthy and tedious process, but more importantly because hand-coded datasets are liable
to embody biases introduced by the developer. If the dataset is used for training the system,
then the rules that are extracted will be little more than an unfolding of information explicitly
supplied by the developers. If it is used for testing then it will only test the examples that
the developers have chosen, which are likely to be biased, albeit unwittingly, towards the
way they think about the problem.
Our set of Arabic p-h pairs for the TE task was created by a semi-automatic technique
through two stages. The first stage (Section 5.1) is responsible for automatically collecting
p-h pairs from news websites, while the second stage (Section 5.2) uses an online annotation
system that allows annotators to annotate our collected pairs manually. Both stages are
explained in detail below.
5.1 Collecting p-h Pairs
We collected candidate p-h pairs automatically by the so-called headline-lead paragraph
technique (Burger & Ferro, 2005) from the web (e.g. from newspaper corpora, pairing the
first paragraph of article, as p, with its headline, as h). This is based on the observation
that a news articles headline is very often a partial paraphrase of the first paragraph of this
article, conveying thus a comparable meaning. We use an updated version of the headlinelead paragraph strategy to improve the quality of the p-h pair.
The key idea here is that we pose queries to a search engine and automatically filter the
responses for text snippets that might entail the query. These pairs are then manually annotated for entailment/non-entailment, but the texts themselves are automatically collected
from freely occurring natural texts. This eliminates the possibility (indeed likelihood) of
unconscious bias that is introduced if the hypotheses are manually generated.
We built a corpus of p-h pairs by using headlines from the websites of Arabic newspapers
and TV channels as queries to be input to Google via the standard Google API, and then
selecting the first paragraph, which usually represents the most related text snippet(s) in
the article with the headline (Burger & Ferro, 2005), of each of the first 10 returned pages.
This technique produces a large number of potential pairs without any bias in either the
premises or the hypotheses. To improve the quality of the pairs that resulted from the query,
we use two conditions to filter the results: (i) the length of a headline must be at least five
words, to avoid very small headlines; and (ii) fewer than 80% of the words in the headline
should appear in the premise, to avoid having very similar sentences.
The problem here is that if p and h are very similar then there would be very little to
learn from them if they were used in the training phase of a TE system; and they would
be almost worthless as a test pairvirtually any TE system will get such a pair right, so
they will not serve as a discriminatory test pair. We therefore eliminate excessively similar
p-h pairs from both training and testing, which we assess in terms of the number of shared
uncommon words.
In order to overcome this problem, we matched headlines from one source with stories
from another. Major stories are typically covered by a range of outlets, usually with variations in emphasis or wording. Stories from different sources can be linked by looking for
common words in the headlinesit is unlikely that there will be two stories about, for in14

fiNatural Language Inference for Arabic

stance, neanderthals in the news at the same time, so very straightforward matching based
on low frequency words and proper names is likely to find articles about the same topic.
The terminology and structure of the first text snippets of these articles, however, are likely
to be quite different. Thus using a headline from one source and the first text snippet from
an article about the same story but from another source is likely to produce p-h pairs which
are not unduly similar. We can therefore link a headline from one newspaper with related
sentences from another.
5.2 Annotating p-h Pairs
The pairs that are collected in the first stage still have to be marked-up by human annotators,
but at least the process of collecting them is as nearly bias-free as possible. These pairs cover
a number of subjects such as politics, business, sport and general news. The annotation is
performed by eight expert and non-expert human annotators to identify the different pairs as
positive entailment examples yes, where p is judged to entails h, and as negative examples
no, where entailment does not hold. Those annotators follow nearly the same annotation
guidelines as those used for building the RTE task dataset (Dagan, Glickman, & Magnini,
2006).
Each pair was annotated by three annotators. The inter-annotator agreement (where all
annotators agree) is around 74% compared with 89% where each annotator agrees with at
least one co-annotator. This suggests that the annotators found this is a difficult task. The
fact that there was only 74% agreement when the annotations produced by three independent
annotators are taken into account sets an upper bound on what it is reasonable to expect of
an automatic system for carrying out this task. If human annotators can only agree in about
three quarters of the cases, then it is unlikely that a computer-based system can achieve
much more than 75% agreement with any given pair of annotators.6

6. Experiments
To check the effectiveness of TED+ST, we used it to check the entailment between p-h
Arabic pairs of text snippets and compared its results with two string-based approaches
(bag-of-words and Levenshtein distance) and ZS-TED on the same set of pairs. Checking
whether one Arabic text snippet entails another, however, is particularly challenging because
Arabic is more ambiguous than most languages, such as English. For instance, Arabic is
written without diacritics (short vowels), often leading to multiple ambiguities. This makes
morphological analysis very difficult (i.e. a single written form may easily correspond to as
many as ten different lexemes, see Alabbas & Ramsay, 2011a, 2011b, 2012a, 2012c). The
preliminary testing dataset contains 600 pairs, binary annotated as yes and no (a 50-50
split) using the technique explained in Section 5. The distribution of these pairs over p length
is summarised in Table 1, when the h average length is around 10 words and the average of
common words between p and h is around 4 words. The average length of sentence in this
dataset is 25 words per sentence, with some sentences containing 40+ words.
6. The dataset, including the dependency-tree analysis in CoNLL format, is available in the online appendices to this article or from http://www.cs.man.ac.uk/~ramsay/ArabicTE/

15

fiAlabbas & Ramsay

ps length
<20
20-29
30-39
>39
Total

#pairs
175
329
87
9
600

yes
83
171
43
3
300

no
92
158
44
6
300

Table 1: Distribution of sentence lengths in the testset.

In order to check the entailment between p-h pairs, we follow three steps. First, each
sentence is preprocessed by a tagger and a parser in order to convert both elements of the p-h
pair to dependency trees. A dependency tree is a tree where words are vertices and syntactic
relations are dependency relations. Each vertex therefore has a single parent, except the
root of the tree. A dependency relation holds between a dependent, i.e. a syntactically
subordinate vertex, and a head, i.e. another vertex on which it is dependent. Thus the
dependency structure is represented as a head-dependent relation between vertices that are
classified by dependency types such as SBJ subject, OBJ object, ATT attribute, etc.
We have carried out a number of experiments with state-of-the-art taggers such as
AMIRA (Diab, 2009), MADA (Habash, Rambow, & Roth, 2009) and an in-house maximumlikelihood (MXL) tagger (Ramsay & Sabtan, 2009) and parsers such as MALTParser (Nivre,
Hall, Nilsson, Chanev, Eryigit, Kbler, Marinov, & Marsi, 2007) and MSTParser (McDonald, Lerman, & Pereira, 2006).7 These experiments show in particular that merging MADA
(97% accuracy) with MSTParser gives better results (around 81% for labelled accuracy)
than the other tagger:parser combinations (Alabbas & Ramsay, 2012b). We therefore use
MADA+MSTParser in the current experiments.
After converting p-h pairs to dependency trees, we matched these dependency trees using
the ZS-TED and TED+ST algorithms, with two string-based algorithms (bag-of-words and
Levenshtein distance) to provide a baseline. The tree edit distance algorithms used the edit
operation costs defined in Figure 8 to find the cost of matching between p-h pairs. The
bag-of-words here measures the similarity between p and h as a number of common words
between them (either in surface forms or lemma forms), divided by the length of h. For all
four algorithms we use AWN as a lexical resource in order to take account of synonymy and
hyponymy relations when calculating the cost of an edit.
We carried out two kinds of experiments using these algorithms: the first was a simple
yes/no experiment, using a single threshold to decide whether the premise was similar enough
to the hypothesis for it to be safe to say that it entailed it, and the second with two thresholds
so that we could say yes/dont know/no. The results of these experiments are given below.

7. These parsers are data-driven dependency parsers. For Arabic they are usually trained on an Arabic
dependency treebank, such as Prague Arabic Dependency Treebank (PADT) (Smr, Bielicky, Kouilov,
Krmar, Haji, & Zemnek, 2008), or on some version of the Penn Arabic Treebank (PATB) (Maamouri
& Bies, 2004) that has been converted to dependency trees: scoring of such parsers is a matter of counting
dependency links.

16

fiNatural Language Inference for Arabic

6.1 Binary Decision (yes and no)
p entails h when the cost of matching is less (more in case of bag-of-words) than a threshold.
The results of these experiments, in terms of precision (P), recall (R) and F-score (F) for
yes class and overall accuracy, are shown in Table 2. This table shows the substantial
improvement obtained by using TED+ST over the bag-of-words (F-score for TED+ST is
around 1.16 times the F-score for bag-of-words, and accuracy is about 1.09 times better)
and ZS-TED (around 1.06 times better in F-score and 1.04 times better in total accuracy).
Method
Bag-of-words
Levenshtein distance
ZS-TED
TED+ST

Pyes
63.5%
64.7%
65.9%
69.7%

Ryes
43.7%
44.1%
51.2%
54.5%

Fyes
0.518
0.525
0.576
0.612

Accuracy
59.3%
60.2%
62.5%
65.5%

Table 2: Performance of TED+ST compared with the string-based algorithms and ZS-TED,
binary decision.
Although we are primarily interested in Arabic, we have carried out parallel sets of experiments on the English RTE2 testset, using the Princeton English WordNet (PWN) as a
resource for deciding whether a word in the premise may be exchanged for one in the hypothesis. Because the tree edit distance algorithms work with dependency tree analyses of the input texts, we have used a set that have been analysed using Minipar (Lin, 1998), downloaded
from http://u.cs.biu.ac.il/~nlp/RTE2 Datasets/RTE2 Preprocessed Datasets.html.
The RTE2 testset contains around 800 p-h pairs, but a number of the Minipar analyses have
multiple heads and hence do not correspond to well-formed trees, and there are also a
number of cases where the segmentation algorithm that was used produces multi-word expressions. After eliminating problematic pairs of this kind we are left with 730 pairs, split
evenly between positive and negative examples. Since we are mainly concerned here with
the difference between ZS-TED and TED+ST, we have omitted the Levenshtein distance
and have simply kept the basic bag-of-words algorithm as a baseline. Previous authors
have shown that tree edit distance consistently outperforms string-based approaches on this
dataset, and there is no need to replicate that result here.
Method
Bag-of-words
ZS-TED
TED+ST

Pyes
53.2%
52.9%
53.2%

Ryes
50.1%
62.5%
66.8%

Fyes
0.516
0.573
0.59

Accuracy
52.1%
53.5%
55.8%

Table 3: Performance of TED+ST compared with the simple bag-of-words and ZS-TED,
binary decision, RTE2 dataset.
The pattern in Table 3 is similar to that in Table 2. ZS-TED is better than bag-of-words,
TED+ST is a further improvement over ZS-TED. Most experiments on textual entailment
tasks only report accuracy: in certain situations it may be more important to have decisions
that are trustworthy (high precision, as in Table 2) or to be sure that you have captured as
17

fiAlabbas & Ramsay

many positive examples as possible (high recall8 , as in Table 3), or to have a good balance
between these (high F-score). It is easy to change the balance between precision and recall,
simply by changing the threshold that is used for determining whether it is safe to say
that p entails hwe could have chosen thresholds for Table 3 that increased the precision
and decreased the recall, so that the results more closely matched Table 2. The key point
here is that in both sets of experiments, the F-scores improve as we move from string-based
measures to ZS-TED and then again when we use TED+ST; and that they are remarkably
similar for the two datasets, despite the fact that they were collected by different means,
are in different languages, and are parsed using different parsers.
6.2 Making a Three-way Decision (yes, no and unknown)
For this task we use two thresholds, one to trigger a positive answer if the cost of matching is
lower than the lower threshold (exceeds the higher one for the bag-of-words algorithm) and
the other to trigger a negative answer if the cost of matching exceeds the higher one (mutatis
mutandis for bag-of-words). Otherwise, the result will be unknown. The reason for making
a three-way decision is to drive systems to make more precise distinctions. Note that we
are not distinguishing here between {h entails p, h and p are compatible, h contradicts p},
but between {h entails p, I dont know whether h entails p, h does not entail p}. This is
a more subtle distinction, reflecting the systems confidence in its judgement, but it can be
extremely useful when deciding how to act on its decision.
The results of this experiment, in terms of precision (P), recall (R) and F-score (F),
are shown in Table 4. Again, it shows the large improvement of using TED+ST over the
bag-of-words (F-score is around 1.10 times better) and ZS-TED (F-score around 1.06 times
better).
Method
Bag-of-words
Levenshtein distance
ZS-TED
TED+ST

P
58.9%
61.4%
65.1%
67.4%

R
56.7%
58.0%
56.0%
60.2%

F
0.578
0.597
0.602
0.636

Table 4: Performance of TED+ST compared with string-based algorithms and ZS-TED,
three-way decision.
The scores for the three-way decision on the RTE2 dataset are lower than for our Arabic
dataset, but again TED+ST outperforms ZS-TED on all three measures.

7. Conclusion
We have presented here an extended version, TED+ST, of tree edit distance that solved
one of the main drawbacks of standard tree edit distance, which is that it only supports
8. This might be useful, for instance, with TED+ST being used as a low cost filter in a question-answering
system, where the results of a query to a search engine might be filtered by TED+ST before being passed
to a system employing full semantic analysis and deep reasoning, which are high precision but are also
very time-consuming.

18

fiNatural Language Inference for Arabic

Method
Bag-of-words
ZS-TED
TED+ST

P
50.8%
52.3%
54.3%

R
48.3%
50.2%
52.7%

F
0.495
0.512
0.535

Table 5: Performance of TED+ST compared with the simple bag-of-word and ZS-TED,
three-way decision, RTE2 dataset.

edit operations (i.e. delete, insert and exchange) on single nodes. TED+ST deals with
subtree transformation operations as well as operations on single nodes: this leads to useful
improvements over the performance of the standard algorithm for determining entailment.
The key here is that subtrees tend to correspond to single information units. By treating
operations on subtrees as less costly than the corresponding set of individual node operations,
TED+ST concentrates on entire information units, which are a more appropriate granularity
than individual words for considering entailment relations.
The current findings, while preliminary, are quite encouraging. The fact that the results
on our original testset, particularly the improvement in F-score, were replicated for a testset
where we had no control over the parser that was used to produce dependency trees from
the p-h pairs provides some evidence for the robustness of the approach. We anticipate
that in both cases having a more accurate parser (our parser for Arabic attains around 81%
accuracy on the PATB, Minipar is reported to attain about 80% on the Suzanne corpus)
would improve the performance of both ZS-TED and TED+ST.
We are currently experimenting with different scoring algorithms for ZS-TED and TED+
ST. The performance of any variant of tree edit distance depends critically on the costs for
the various operations, and on the thresholds that are used for deciding whether h entails
p, and we are therefore investigating the use of various optimisation algorithms for choosing
these weights and thresholds. We also intend to use other Arabic lexical resources, such
as OpenOffice Arabic dictionary and MS Word Arabic dictionary, to provide us with more
information about relations between words, because the information in AWN, while very
useful, is sparse in comparison to PWN (Habash, 2010).

Acknowledgments
We would like to thank the reviewers for their valuable comments, in particular the reviewer
who suggested evaluating the approach on an English dataset as well as our Arabic one.
The extra work has provided support for our belief in the robustness of the approach to a
degree that we did not anticipate.
We would like to extend our thanks to our annotators for the time and effort they have
put into annotating our experimental dataset. Maytham Alabbas owes his deepest gratitude
to Iraqi Ministry of Higher Education and Scientific Research for financial support in his
PhD study. Allan Ramsays contribution to this work was partially supported by the Qatar
National Research Fund (grant NPRP 09 - 046 - 6 - 001).
19

fiAlabbas & Ramsay

References
Alabbas, M. (2011). ArbTE: Arabic textual entailment. In Proceedings of the Second Student
Research Workshop associated with RANLP 2011, pp. 4853, Hissar, Bulgaria. RANLP
2011 Organising Committee.
Alabbas, M., & Ramsay, A. (2011a). Evaluation of combining data-driven dependency
parsers for Arabic. In Proceeding of 5th Language & Technology Conference: Human
Language Technologies (LTC11), pp. 546550, Pozna, Poland.
Alabbas, M., & Ramsay, A. (2011b). Evaluation of dependency parsers for long Arabic
sentences. In Proceeding of International Conference on Semantic Technology and
Information Retrieval (STAIR11), pp. 243248, Putrajaya, Malaysia. IEEE.
Alabbas, M., & Ramsay, A. (2012a). Arabic treebank: from phrase-structure trees to dependency trees. In META-RESEARCH Workshop on Advanced Treebanking at the 8th
International Conference on Language Resources and Evaluation (LREC), pp. 6168,
Istanbul, Turkey.
Alabbas, M., & Ramsay, A. (2012b). Combining black-box taggers and parsers for modern standard Arabic. In Federated Conference on Computer Science and Information
Systems (FedCSIS-2012), pp. 19 26, Wroclaw, Poland. IEEE.
Alabbas, M., & Ramsay, A. (2012c). Improved POS-tagging for Arabic by combining diverse
taggers. In Proceedings of 8th Artificial Intelligence Applications and Innovations
(AIAI), pp. 107116, Halkidiki, Greece. Springer.
Bille, P. (2005). A survey on tree edit distance and related problems. Theoretical Computer
Science, 337 (1-3), 217239.
Black, W., Elkateb, S., Rodriguez, H., Alkhalifa, M., Vossen, P., Pease, A., & Fellbaum, C.
(2006). Introducing the Arabic WordNet project. In Proceedings of the 3rd International WordNet Conference (GWC-06), pp. 295299, Jeju Island, Korea.
Burger, J., & Ferro, L. (2005). Generating an entailment corpus from news headlines. In
Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and
Entailment, pp. 4954, Ann Arbor, Michigan, USA. Association for Computational
Linguistics.
Dagan, I., & Glickman, O. (2004). Probabilistic textual entailment: generic applied modeling of language variability. In PASCAL Workshop on Learning Methods for Text
Understanding and Mining, pp. 2629, Grenoble, France.
Dagan, I., Glickman, O., & Magnini, B. (2006). The PASCAL recognising textual entailment challenge. In Quionero-Candela, J., Dagan, I., Magnini, B., & dAlch Buc, F.
(Eds.), Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, Vol. 3944 of Lecture Notes in
Computer Science, pp. 177190. Springer Berlin, Heidelberg.
Demaine, E., Mozes, S., Rossman, B., & Weimann, O. (2009). An optimal decomposition
algorithm for tree edit distance. ACM Transactions on Algorithms (TALG), 6 (1),
2:12:19.
20

fiNatural Language Inference for Arabic

Diab, M. (2009). Second generation tools (AMIRA 2.0): fast and robust tokenization, POS
tagging, and base phrase chunking. In Proceedings of the 2nd International Conference
on Arabic Language Resources and Tools, pp. 285288, Cairo, Eygpt. The MEDAR
Consortium.
Habash, N. (2010). Introduction to Arabic Natural Language Processing. Synthesis Lectures
on Human Language Technologies. Morgan & Claypool Publishers.
Habash, N., Rambow, O., & Roth, R. (2009). MADA+TOKAN: a toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming and
lemmatization. In Proceedings of the 2nd International Conference on Arabic Language
Resources and Tools, Cairo, Eygpt. The MEDAR Consortium.
Habash, N., Soudi, A., & Buckwalter, T. (2007). On Arabic transliteration. Arabic Computational Morphology, 1522.
Heilman, M., & Smith, N. (2010). Tree edit models for recognizing textual entailments, paraphrases, and answers to questions. In Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the Association for Computational Linguistics, pp. 10111019, Los Angeles, California, USA. Association for Computational
Linguistics.
Hobbs, J. R. (2005). The handbook of pragmatics, chap. Abduction in Natural Language
Understanding, pp. 724740. Blackwell Publishing.
Klein, P. (1998). Computing the edit-distance between unrooted ordered trees. In Proceedings of the 6th Annual European Symposium on Algorithms (ESA 98), pp. 91102,
Venice, Italy. Springer-Verlag.
Kouylekov, M. (2006). Recognizing Textual Entailment with Tree Edit Distance: application
to Question Answering and Information Extraction. Ph.D. thesis, DIT, University of
Trento, Italy.
Kouylekov, M., & Magnini, B. (2005). Recognizing textual entailment with tree edit distance algorithms. In Proceedings of the1st Challenge Workshop Recognising Textual
Entailment, pp. 1720, Southampton, UK.
Lin, D. (1998). Dependency-based evaluation of minipar. In Workshop on the Evaluation of
Parsing systems, pp. 317330. Springer.
Maamouri, M., & Bies, A. (2004). Developing an Arabic treebank: methods, guidelines,
procedures, and tools. In Proceedings of the Workshop on Computational Approaches
to Arabic Script-based Languages, pp. 29, Geneva, Switzerland.
MacCartney, B. (2009). Natural Language Inference. Ph.D. thesis, Department of Computer
Science, Stanford University, USA.
McDonald, R., Lerman, K., & Pereira, F. (2006). Multilingual dependency parsing with a
two-stage discriminative parser. In 10th Conference on Computational Natural Language Learning (CoNLL-X), New York, USA.
Mehdad, Y., & Magnini, B. (2009). Optimizing textual entailment recognition using particle
swarm optimization. In Proceedings of the 2009 Workshop on Applied Textual Inference (TextInfer 09), pp. 3643, Suntec, Singapore. Association for Computational
Linguistics.
21

fiAlabbas & Ramsay

Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryigit, G., Kbler, S., Marinov, S., & Marsi,
E. (2007). MaltParser: a language-independent system for data-driven dependency
parsing. Natural Language Engineering, 13 (02), 95135.
Pawlik, M., & Augsten, N. (2011). RTED: a robust algorithm for the tree edit distance.
Proceedings of the VLDB Endowment, 5 (4), 334345.
Punyakanok, V., Roth, D., & Yih, W. (2004). Natural language inference via dependency
tree mapping: An application to question answering. Computational Linguistics, 6,
110.
Ramsay, A., & Sabtan, Y. (2009). Bootstrapping a lexicon-free tagger for Arabic. In Proceedings of the 9th Conference on Language Engineering (ESOLEC2009), pp. 202215,
Cairo, Egypt.
Selkow, S. (1977). The tree-to-tree editing problem. Information Processing Letters, 6 (6),
184186.
Smr, O., Bielicky, V., Kouilov, I., Krmar, J., Haji, J., & Zemnek, P. (2008). Prague
Arabic dependency treebank: a word on the million words. In Proceedings of the Workshop on Arabic and Local Languages (LREC 2008), pp. 1623, Marrakech, Morocco.
Tai, K. (1979). The tree-to-tree correction problem. Journal of the ACM (JACM), 26 (3),
422433.
Zhang, K., & Shasha, D. (1989). Simple fast algorithms for the editing distance between
trees and related problems. SIAM Journal of Computing, 18 (6), 12451262.

22

fiJournal of Artificial Intelligence Research 48 (2013) 813-839

Submitted 05/13; published 11/13

Single Network Relational Transductive Learning
Amit Dhurandhar
Jun Wang

adhuran@us.ibm.com
wangjun@us.ibm.com

IBM T.J. Watson Research
1101 Kitchawan Road, Yorktown Heights, NY-10598 USA

Abstract
Relational classification on a single connected network has been of particular interest
in the machine learning and data mining communities in the last decade or so. This is
mainly due to the explosion in popularity of social networking sites such as Facebook,
LinkedIn and Google+ amongst others. In statistical relational learning, many techniques
have been developed to address this problem, where we have a connected unweighted homogeneous/heterogeneous graph that is partially labeled and the goal is to propagate the
labels to the unlabeled nodes. In this paper, we provide a different perspective by enabling
the effective use of graph transduction techniques for this problem. We thus exploit the
strengths of this class of methods for relational learning problems. We accomplish this by
providing a simple procedure for constructing a weight matrix that serves as input to a rich
class of graph transduction techniques. Our procedure has multiple desirable properties.
For example, the weights it assigns to edges between unlabeled nodes naturally relate to a
measure of association commonly used in statistics, namely the Gamma test statistic. We
further portray the efficacy of our approach on synthetic as well as real data, by comparing
it with state-of-the-art relational learning algorithms, and graph transduction techniques
with an adjacency matrix or a real valued weight matrix computed using available attributes as input. In these experiments we see that our approach consistently outperforms
other approaches when the graph is sparsely labeled, and remains competitive with the
best when the proportion of known labels increases.

1. Introduction
Given the affluence of large connected relational graphs across diverse domains, single or
within network classification has been one of the popular endeavours in statistical relational
learning (SRL) research (Getoor & Taskar, 2007). Ranging from social networking websites
to movie databases to citation networks, large connected relational graphs1 are banal. In
single network classification, we have a partially labeled data graph and the goal is to extend
this labeling, as accurately as possible, to the unlabeled nodes. The nodes themselves may
or may not have associated attributes. An example where within network classification
could be useful is in forming common interest groups on social networking websites. For
instance, a group of people in the same geography may be interested in playing soccer and
they would be interested in finding more people who are likely to have the same interest.
In a different domain such as entertainment, one might be interested in estimating which
of the new movies is likely to make a splash at the box office. Based on the success of other
movies that had some of the same actors and/or the same director, one could provide a
reasonable estimate of which movies are most likely to be successful.
1. At least with a large connected component.
c
2013
AI Access Foundation. All rights reserved.

fiDhurandhar & Wang

Many methods that learn and infer over a data graph have been developed in SRL literature. Some of the more effective methods perform collective classification (Chakrabarti,
Dom, & Indyk, 1998), that is, besides using the attributes of the unlabeled node to infer its
label, they also use attributes and labels of related nodes/entities. These are thus a generalization of methods that assume that the data is independently and identically distributed
(i.i.d.). Examples of such methods are relational markov networks (RMNs) (Taskar, Abbeel,
& Koller, 2002), relational dependency networks (RDNs) (Neville & Jensen, 2007), markov
logic networks (MLNs) (Richardson & Domingos, 2006), probabilistic relational models
(PRMs) (Getoor, Koller, & Small, 2004). These all fall under the umbrella of markov networks. There have been simpler models suggested as baselines such as relational neighbor
classifiers (RN) (Macskassy & Provost, 2003, 2007; Chakrabarti et al., 1998; Sen, Namata,
Bilgic, Getoor, Gallagher, & Eliassi-Rad, 2008), which simply choose the most numerous
class label amongst their neighbors to more involved variants such as those using relaxation
labeling. Interestingly, these simple models perform quite well when the auto-correlation is
high, even though the graph maybe sparsely labeled. Recently, a pseudo-likelihood expectation maximization (PL-EM) (Xiang & Neville, 2008) method was introduced, which seems
to perform favorably to other methods when the graph has a moderate number (around
20-30%) of labeled nodes.
A different class of methods that could potentially address the problem at hand are
graph transduction methods (Zhu, Ghahramani, & Lafferty, 2003; Zhou, Bousquet, Lal,
Weston, & Schlkopf, 2004; Wang, Jebara, & fu Chang, 2008), which are a part of semisupervised learning methods. These methods typically perform well when we are given a
weighted graph and the linked nodes have mostly the same labels  unless apriori dissimilar
nodes are explicitly specified (Goldberg, Zhu, & Wright, 2007; Tong & Jin, 2007) , even if
only a small fraction of the labels are known. If a weighted graph is not readily available, it
is constructed from the (explanatory) attributes of the nodes. If an unweighted graph with
no attributes is given, then the adjacency matrix is passed as input.
There are multiple methods that learn weights based on attributes. The simplest is to
use a lp norm. More sophisticated techniques use specialized optimization functions based
on gaussian kernels (Jebara, Wang, & Chang, 2009; Jebara & Shchogolev, 2006) or loglikelihood (Xiang, Neville, & Rogati, 2010) to determine weights. These methods however,
are unsupervised (i.e. ignore labels) and are based on the fundamental assumption of
homophily, that is, linked or closeby datapoints have the same labels. This assumption is
not necessarily satisfied in real-world relational graphs.
There are other methods, which determine weights based on just linkage (Gallagher,
Tong, Eliassi-Rad, & Faloutsos, 2008). Here, besides the edges in the input graph, edges
are added between all labeled and unlabeled nodes. The weights are determined by making
multiple even length random walks starting at each unlabeled node. This strategy works
well for binary labeled graphs that may or may not satisfy the homophily assumption, but
is not necessarily effective when we have more than two labels. Moreover, the method is
still unsupervised and can be computationally expensive.
In literature concerning all the above methods that learn weights given an unweighted
graph, it is seen that an appropriate weighting scheme can help leverage graph semantics and
make the prediction algorithms more robust to noise compared to their unweighted counterparts. In fact, it has been well recognized (Maier, Von Luxburg, & Hein, 2008; Jebara
814

fiSingle Network Relational Transductive Learning

et al., 2009; Zhu, Lafferty, & Rosenfeld, 2005) that accurate edge weighting has significant
influence on various graph based machine learning tasks such as clustering and classification. Moreover, in our own experiments we see that using an unweighted graph leads
to substantially inferior results in most cases, as opposed to using our weighting scheme.
When comparing our scheme with these other methods that learn weights, ours is preferable
for at least the following reasons. First, our method uses the attribute information, link
information alongwith the labels to determine the weights. The other methods use either
the link information or the attribute information and tend to ignore the specific labeling.
Hence, our method is comprehensive and thus more robust as it takes into account all the
three sources of information. Second, our method can be used when data is heterogenous
and is not limited to only homogenous datasets. Third, as we will see in the experiments,
our method performs well across varied labeling percentages, while these other methods
tend to have a higher bias and are not able to fully exploit the settings where more label
information is available.
In relational learning, the graphs are typically unweighted and sometimes may not have
attributes. In many cases, the attributes may not accurately predict the labels, in which
case, weighting the edges solely on them may not provide acceptable results. The links with
the labeling could be viewed as an additional source of information to predict unlabeled
nodes. Some of these intuitions are captured in the relational gaussian process model (Chu,
Sindhwani, Ghahramani, & Keerthi, 2007), but it is limited to undirected graphs and as
mentioned in prior works (Xiang & Neville, 2008) the suggested kernel function is not easy
to adapt to relational settings where we may have heterogeneous data.
In this paper, we provide a lucid way to effectively leverage a rich class of graph transduction methods, namely those based on the graph laplacian regularization framework, for
within network relational classification. Among the existing graph transduction methods,
this class of methods is considered to be one of the most efficient and accurate in real applications (Jebara et al., 2009; Zhu et al., 2003; Zhou et al., 2004). In particular, we provide
a procedure to learn a weight matrix for a graph that may be directed or undirected, that
may exhibit positive or negative auto-correlation and where the edges in the graph may
be between labeled nodes, between unlabeled nodes or between a labeled and an unlabeled
node. The method is semi-supervised in the sense that it uses the label information as well
as the links and the attribute information to determine weights. Being semi-supervised,
the learned weights are robust and effectively capture dependencies much more so than the
unsupervised weight learning methods described above. Moreover, the learning procedure
naturally relates to commonly used statistical measures making it more principled than previous approaches. We first provide a solution for a graph where nodes have no attributes,
only class labels. We then extend the solution to include attributes (and heterogenous data)
by incorporating a conical weighting scheme that weighs importance of the links relative
to the attributes. The construction of the weight matrix assumes binary labeling, however,
recursive application of the chosen graph transduction method with reconstruction of the
weight matrix will accomplish multi-class classification as is witnessed in the experiments
on real data.
The rest of the paper is organized as follows: In Section 2, we describe the construction
of the weight matrix when the nodes just have labels but no attributes. In Section 3, we
discuss interesting characteristics of such a weighting scheme. In Section 4, we extend the
815

fiDhurandhar & Wang

-1

?

?

1

1
Figure 1: Example input graph (T ) to our construction method.
construction described in section 2 to be able to model attributes and data heterogeneity.
In Section 5, we suggest a modification to the graph transduction methods so that they
Figure 1
can effectively exploit the richness of our input weight matrix. In Section 6, we show the
efficacy of our ideas through experiments on synthetic and real data. In Section 7, we discuss
promising future directions and then summarize the contributions made in the current work.

2. Weight Matrix Construction
In this section we elucidate a way of constructing the weight matrix for a partially labeled
graph G(V, E, Y ) where V is the set of nodes, E is the set of edges and Y is the set of labels.
We assume that the labeling is binary, i.e any labeled node i has a label Yi  {1, 1}. As
mentioned before, the procedure of constructing the weight matrix W , which serves as
input to a graph transduction technique, could be applied recursively or iteratively to each
(binary) classified portion, to attain multi-class classification. Hence, the input in any run
to our weight matrix construction method is a partially (binary) labeled graph as shown in
Figure 1.
The weights Wij we learn for an edge between node i and node j signify the degree of
similarity/dissimilarity between the labels of these nodes. The weights lie in the interval
[1, 1], where a positive sign indicates that the nodes will tend have similar labels, while
a negative sign indicates that they will tend to have different labels. The numerical value
ignoring the sign indicates the magnitude of these tendencies. Formally,
Wij = f (Yi , Yj , G)

(1)

where Yi and Yj maybe known or unknown and f ()  [1, 1]. In our case, the value of f ()
depends on the type nodes the edge is connecting, i.e., if the nodes are labeled, unlabeled
or one is labeled and the other is unlabeled, along with the labeled portion of the graph.
The exact assignments of f () for edges connecting the 3 different types of nodes are given in
subsection 2.2. Loosely speaking, f () would be negative and close to -1 if most of the edges
connect nodes with different labels, while it would be positive and close to +1 if most of
the edges connect nodes with the same label. These semantics are consistent even when we
discuss extensions later in the paper, which involve learning these weights in the presence
of attributes and heterogenous data.
816

fiSingle Network Relational Transductive Learning

Symbol
Nq
Nqr

Graph Type
D, U
D

Nqr

U

Np

D, U

Psame

D, U

Popp

D, U

D

D, U

Semantics
# of nodes with label q
# of edges from node with
label q into node with
label r
When q = r,
# of edges between node
with label q and node
with label r
When q 6= r,
Half of the # of edges
between node with label
q and node with label r
Total # of labeled edges
i.e. edges where both
nodes are labeled
Ratio of the # of edges
between nodes with same
label to total # of
labeled edges
Ratio of the # of edges
between nodes with
different labels to total
# of labeled edges
Distribution over labeled
edges

Table 1: Above is the notation used in the paper. Under graph type, D stands for directed
and U stands for undirected.

Given our setup, a partially labeled graph G has 3 types of nodes and consequently 9
types of edges for a directed graph while 6 types of edges for an undirected one. A node
could be labeled 1 or 1 or may be unlabeled. An edge could be between two nodes with
the same label (i.e. (1  1) or (1  1)) or between two oppositely labeled nodes (i.e.
(1  1) or (1  1)) or between a labeled and unlabeled node (i.e. (1 ?) or (1 ?)
or (?  1) or (?  1)) or between two unlabeled nodes (i.e. (? ?)). An undirected
example graph T is shown in Figure 1. Our task then is to assign weights to each of these
types of edges.
817

fiDhurandhar & Wang

-1

?

?

1

1
Figure 2: Tw is a weighted version of graph T shown in figure 1.
2.1 Notation

Figureto2the different types of edges, we introduce some
Before we describe the weights we assign
notation. Given a graph G, let Nq denote the number of nodes with label q. Let Nqr denote
the number of edges from node with label q into node with label r. In an undirected graph,
this would be the number of edges between nodes labeled q and r, if q = r. If q 6= r, then
Nqr would be half of the number of edges between q and r. Let Np denote the total number
of labeled edges, i.e. the total number of edges where both nodes are labeled. In other
words, Np = N11 + N11 + N11 + N11 . With this let,
Psame =

N11 + N11
N11 + N11
, Popp =
Np
Np

(2)

Hence, Psame + Popp = 1. We denote this empirical distribution derived from labeled edges
by D. A summary of this notation for directed and undirected graphs is shown in table 1.
2.2 Assignment of Weights
We now describe our weight matrix construction which applies to both directed and undirected graphs. We partition the types of edges into 5 categories and suggest a way of
assigning weights to edges in each of these categories.
 Edges between nodes with the same label: If an edge is between nodes having the same
label, that is if node i and node j have the same label, we assign a weight Wij = Psame
to that edge. This makes intuitive sense since we want to weigh the edge based on
how likely it is to have nodes with the same label being connected.
It is worth mentioning that one might think of assigning label specific weights to edges.
For instance, one strategy would be to assign Wij = NN11
or Wij = N11
depending
Np
p
on if the labels were +1 or 1 respectively. However, this assignment seems to have a
conceptual issue even for the simple case, where we have a graph with connected nodes
mostly having the same labels. In such a case, the weights of the edges connecting
nodes having the same labels would be devalued undesirably. For example consider a
graph where, N11 = 10, N11 = 10 and N11 = 1. This is basically a graph with two
large clusters of connected nodes with same labels and one link connecting these two
818

fiSingle Network Relational Transductive Learning

clusters. In this case, the label specific strategy would give weights of Wij = 10
21  0.48,
while our strategy would give weights of Wij = 20

0.95
for
the
edges
with
nodes
21
having same labels. It is clear that the latter strategy is preferable since, either of the
labels have a high tendency of being connected to nodes with the same labels. Note
that this reasoning also applies to when N11 might be different than N11 , but the
graph exhibits high positive auto-correlation.
 Edges between nodes with opposite/different labels: If an edge is between nodes with
opposite labels, that is if node i and node j have different labels, we assign a weight
Wij = Popp to that edge. This is also intuitive since, we want to weigh the edge based
on how likely it is to have nodes with opposite labels connected. We assign a negative
sign since simply assigning the magnitude will not create a distinction between nodes
labeled alike and those with different labels.
 Edges between unlabeled nodes: If an edge is between unlabeled nodes, that is if node
i and node j do not have labels, we assign a weight Wij = ED [Yi , Yj ] to that edge.
ED [Yi , Yj ] denotes the expectation of labeled edges over the distribution D. Yi and
Yj  {1, 1} and hence,

ED [Yi , Yj ] =

X

qrP [Yi = q, Yj = r]

q,r{1,1}

= P [Yi = 1, Yj = 1]  P [Yi = 1, Yj = 1]+
P [Yi = 1, Yj = 1]  P [Yi = 1, Yj = 1]
N11 N11 N11 N11
=

+

Np
Np
Np
Np

(3)

Since we do not know the labels of any of the nodes for edges in this category, we
assign our most unbiased estimate which is the indicated expected value.
 Edges between an unlabeled node and a node with label 1: If an edge is between an
unlabeled node and a node with label 1, we assign a weight Wij = ED [Yi |Yj = 1] to
that edge. Here Yi  {1, 1}. In this case,
ED [Yi |Yj = 1] =

N11 N11 + N11

N1
N1

(4)

is our unbiased estimate given that one of the nodes has a label of 1.
 Edges between an unlabeled node and a node with label 1: If an edge is between an
unlabeled node and a node with label 1, we assign a weight Wij = ED [Yi |Yj = 1]
to that edge. Here Yi  {1, 1}. In this case,
ED [Yi |Yj = 1] =

N11 N11 + N11

N1
N1

is our unbiased estimate given that one of the nodes has a label of 1.
819

(5)

fiDhurandhar & Wang

A weighted version of our example graph T in Figure 1, is shown by graph Tw in Figure
2.

3. Characteristics of Matrix Construction
In the previous section, we elucidated a way of constructing a weight matrix for a partially
labeled graph. In this section, we discuss certain characteristics of this construction. We
discuss aspects such as relationships of the suggested weights to standard statistical measures and the tendencies of the weight matrix as a function of the connectivity and labeling
in the graph. As we will see, our construction seems to have desirable properties.
3.1 Relation to Standard Measures of Association
In the previous section, we described and provided a brief justification of the procedure
to assign weights. It turns out that the weights we assign to edges that have at least one
unlabeled node, besides being unbiased, have more (statistical) semantics.
Remark: The weights assigned to edges between unlabeled nodes equate to the gamma
test statistic () in the relational setting i.e. ED [Yi , Yj ] = .
The gamma test statistic  (Goodman & Kruskal, 1954), is a standard measure of association used in statistics. The value of this statistic ranges from [1, 1], where positive
values indicate agreement, negative values indicate disagreement/inversion and zero indicates absence of association. The statistic was historically used to compare the sorted order
of observations based on values of two attributes. However, it can also be used to measure
auto-correlation in relational data graphs. Hence, our assignment of weight to edges between unlabeled nodes is the auto-correlation in the graph, which makes intuitive sense. As
it turns out, the statistic also has an interesting relationship to the Student t distribution
(Goodman & Kruskal, 1954).
The weights assigned to edges with one labeled and one unlabeled node i.e. ED [Yi |Yj =
1] or ED [Yi |Yj = 1], based on equations 4 and 5 can be written as: (Psame |1)(Popp |1) = 1
and (Psame |  1)  (Popp |  1) = 1 . These could be considered as gamma test statistics
conditioned on one particular type of label and could be referred to as conditional gamma
test statistics.
3.2 Behavior of Weight matrix
We now analyze the behavior of the weight matrix as the labeled edges in our input graph
tend towards only connecting nodes with the same labels or analogously only connecting
nodes with different labels.
As our input graph tends to have only nodes with same labels being connected, it has
the following effect on our weight matrix. The weight of edges between nodes with the same
label tends to one, i.e. Psame  1. The weight of edges between nodes with different labels
tends to zero, i.e. Popp  0. The weight of edges between unlabeled nodes tends to 1, i.e.
  1. The weight of the remaining set of edges also tends to one, i.e. 1 , 1  1. Hence,
in this situation the weight matrix becomes an adjacency matrix in the extreme case, with
different labeled edges vanishing (i.e. being weighted 0) and all other edges getting a weight
820

fiSingle Network Relational Transductive Learning

-1

?

?

1

1
Figure 3: Ts is an instantiation of graph Tw , when the labeled edges have only nodes with
same labels.

-1
Figure 3

?

?

1

1
Figure 4: To is an instantiation of graph Tw , when the labeled edges have only nodes with
different labels.

Figure
4 graph T in Figure 2 becomes graph T in
of one. Consequently, our example
weighted
w
s
Figure 3.
As our input graph tends to have only nodes with different labels being connected, it
has the following effect on our weight matrix. The weight of edges between nodes with
the same label tends to zero, i.e. Psame  0. The weight of edges between nodes with
different labels tends to -1, i.e. Popp  1. The weight of edges between unlabeled nodes
tends to -1, i.e.   1. The weight of the remaining set of edges also tends to -1, i.e.
1 , 1  1. Since the graph in the extreme case has no positive weights, the negative
sign in the weights is superfluous in terms of graph structure and can be eliminated. Hence,
in this situation too the weight matrix becomes an adjacency matrix in the extreme case,
with same labeled edges vanishing (i.e. being weighted 0) and all other edges getting a
weight of one. Consequently, our example weighted graph Tw in Figure 2 becomes graph
To in Figure 4.
We thus have Ts  To = T , and the labeled edges in Ts and To complement each other
on the labeled portion with respect to the base graph T . We intuitively expect the labeled
edges between differently labeled nodes to slowly disappear while the other edges remain
821

fiDhurandhar & Wang

Paper

Paper

Author

Paper
Author

Title

Area

Age

Paper Title
Author

a)

Paper

b)

Figure 5: a) represents a relational schema with node types, Paper and Author. The relationship between them is many-to-many. The rounded boxes linked to these node
types denote their respective attributes. b) is the corresponding data graph, which
shows authors linked to the papers that they authored or co-authored.

present, as edges connecting nodes with the same label become predominant. We also
expect analogous behavior for the diametric case. As we have seen, these intuitions are
captured implicitly, in our modeling of the weight matrix, thus making the construction
procedure more acceptable.

4. Extensions
In the previous sections, we described a procedure for constructing the weight matrix for
a partially labeled graph with no attributes. In this section, we extend the weighting
scheme to include attribute information. Moreover, we also present a solution to handle
data heterogeneity using ideas from relational learning.
4.1 Modeling with Attributes
For data graphs that have attributes, we want to be able to leverage this information in
addition to the information learned from the connectivity of the graph, so as to possibly
further improve the performance of our procedure. In particular, we need to extend our
weight assignment procedure to be able to encapsulate attribute information. A simple way
of combining the already modeled connectivity information with the attributes, is to assign
a weight to an edge that is a conical combination of the weight based on connectivity and
a weight based on the affinity of attribute values of the connected nodes. Hence, if wc is
the weight assigned based on the connectivity for the particular edge type and wa is the
weight assigned based on attributes, then wc + wa is the new weight of that edge, where
,   0. wc is essentially a weight assignment described in section 2, viz. Psame or  etc.
wa is a function of the attributes of the nodes connected by the corresponding edge, which
we will soon define.  and  are parameters which can be determined through standard
model selection techniques such as cross-validation. A reasonable indicator for the value
of  could be the absolute value of the auto-correlation in the graph. While a reasonable
estimate of the value of  could be the absolute value of the cross-correlation between wa
and the labeling of the corresponding nodes i.e. if the labels are the same or different.
822

fiSingle Network Relational Transductive Learning

Figure 6: The above figure shows the transformed data graph with only Paper node type,
which is obtained from the data graph in Figure 5b.

In the absence of attributes, our weight assignment wc for any type of edge, has a value
in the interval [1, 1]. To effectively combine the aforementioned two sources of information,
wa needs to be of the same scale as wc . One obvious choice could be cosine similarity which
is commonly used in text analytics (Belkin, Niyogi, & Sindhwani, 2005). Cosine similarity
lies in [1, 1], where values close to 1 imply that the nodes are similar while values close
to 1 imply that the nodes are dissimilar. Other choices could be kernel functions (K)
such as gaussian kernel (Wang et al., 2008), which normalize popular distance metrics such
as euclidean distance and other lp norms to value in [0, 1]. Here, values close to 1 imply
similarity and values close to 0 imply dissimilarity. This range can be easily transformed to
our usual range of [-1,1] with the same semantics as before, by a simple linear transformation
of the form, 2K  1.
4.2 Modeling with Heterogeneous Data
If the data graph has multiple types of entities, resulting in different types of nodes, the
procedure previously described cannot be directly applied to construct the weight matrix.
In such cases, standard relational learning strategies such as collapsing portions of the graph
and using aggregation can be applied to reduce to a graph with a single type of node with
attributes (Getoor & Taskar, 2007; Dhurandhar & Dobra, 2012). To this new graph the
above extended procedure can be applied.
823

fiDhurandhar & Wang

For instance, in a citation graph we may have authors linked to papers, with papers
having multiple authors and vice-versa. An example of this is shown in Figure 5. In Figure
5a, we see that the node type Paper has two attributes, Title and Area, which denote the
title of the paper and the research area it belongs to respectively. Let the attribute Area
be the class label, i.e. we want to classify papers based on their research area. The node
type Author has attributes Paper Title and Age, which relates a particular paper to the
ages of the authors that wrote it. The Title attribute (a primary key) in Paper is the same
as the Paper Title attribute (a foreign key) in Author. Hence, each Paper node has three
attributes namely; Title, Area and Age. The attributes Title and Area are called intrinsic
attributes as they belong to node type Paper and the attribute Age is called a relational
attribute since it belongs to a different linked node type Author. Each paper can have
variable number of authors and thus each paper would be associated with multiple values of
Age. A popular solution to this problem is to aggregate the values of the attribute Age of
Author into a single value such that each paper is associated with only a single Age value.
An aggregation function such as average over the ages of the related authors for each paper
can be used. Now instead of the Age attribute we can introduce a new attribute AvgAge
which denotes average age. With this the attributes of Paper node are; Title, Area and
AvgAge. Linking papers that were co-authored by an author, we now have a data graph
that links only the Paper node type, with each node having two attributes and a class label
as is shown in Figure 6.
We will now see an example weight assignment to this transformed data graph by our
extended method. Let us assume that Paper 1 and Paper 2 are in the same area AI encoded
as 1 and Paper 3 is in systems encoded as 1. Let the average age corresponding to the
three papers (i.e. Paper 1, Paper 2 and Paper 3) be 30, 30.5 (average of the two authors)
and 31 respectively. Let the ascii value of the titles be 10, 11 and 15. Also let  = 0.1 and
||xi xj ||2

 = 0.5. If we use a gaussian radial basis kernel K = e 22
with  = 1 to compute wa ,
then the weights of the two edges W12 and W23 are as follows:

W12 = Psame + (2e

(3030.5)2 +(1011)2
2

 1)

= 0.1  0.5 + 0.5  0.071
= 0.086
W23 = (Popp ) + (2e

(30.535)2 +(1113)2
2

 1)

= 0.1  0.5 + 0.5  1
= 0.55
These weights would then be passed to the enhanced graph transduction framework
that we describe next. It is important to note that if we have heterogeneous link types,
then the described procedures can be applied independently to graphs formed from each
link type and the final result could be obtained by aggregating the individual decisions
through standard ensemble label consolidation techniques such as taking a majority vote
or a weighted majority based on the corresponding auto-correlations.
824

fiSingle Network Relational Transductive Learning

5. Enhancing Graph Transduction Techniques
The graph laplacian regularization based framework is one of the most efficient and popular
frameworks for semi-supervised learning in practical machine learning systems. It has shown
effectiveness in many applications, including those challenging cases with agnostics settings
(Jebara et al., 2009). In particular, graph based transductive learning approaches impose
a trade off between the fitting accuracy of the prediction function on labeled data and
the smoothness of the function over the graph. Typically, the smoothness measure of a
prediction function f over the graph G is calculated as (Zhou et al., 2004):
XX
kf k2G =
Wij kf (xi )  f (xj )k2
i

j

1
1
= f (X)> (D  W )f (X) = f (X)> Lf (X),
2
2

(6)

where Wij is the weight of the edge between nodes xi and xP
j , X is the input matrix denoting
the nodes, f (xi ) is the label of node xi , D = {Dii }, Dii = j Wij is a diagonal matrix and
f (X) = [f (x1 ),    , f (xn )]> . Then quantity L is called graph Laplacian, which can be
viewed as an operator on the space of the functions f (Chung, 1997).
Given the above measure of function smoothness, a graph laplacian based regularization
framework estimates the unknown function f as follows:
f opt = arg min Q(Xl , Yl , f ) + kf k2G

(7)

where Q(Xl , Yl , f ) is a loss function measuring the accuracy over the labeled set (Xl , Yl ).
For example, Q(Xl , Yl , f ) = kf (Xl )  Yl k2 i.e. squared loss, is a popular choice (Belkin,
Niyogi, & Sindhwani, 2006; Zhou et al., 2004).
Note that this graph regularization framework can not be directly applied to prediction
modeling in relational networks directly. This is because, the smoothness measure using
the graph laplacian is based on the assumption that connected nodes tend to have the same
class labels and hence the weights have to be non-negative (i.e. Wij  0 i, j). However, it is
well-known that edges in relational networks could connect any type of nodes, as described
earlier. A typical example can be observed in the WEBKB dataset (Craven, DiPasquo,
Freitag, McCallum, Mitchell, Nigam, & Slattery, 1998), where the faculty nodes are mostly
linked to student nodes instead of the same type of nodes, i.e. other faculty nodes. Although
some recent work modeled dissimilarity and incorporated it in their similarity measure to
derive the so called mix graph based prediction models (Tong & Jin, 2007; Goldberg et al.,
2007), they assumed that the similarity/dissimilary relations are apriori known. However,
in our case we automatically estimate the positive and negative correlations from the given
link and attribute information with partial labeling.
As indicated in Section 2, we derive a weighted graph containing both positive weighted
and negative weighted edges. To ensure compatibility with the graph Laplacian based
regularization framework, we modify the smoothness term (Goldberg et al., 2007) using our
derived relational edges as follows,
XX
kf k2G =
Wij kf (xi )  sgn(Wij )f (xj )k2 ,
(8)
i

j

825

fiDhurandhar & Wang

where we set Wij = |Wij | and the degree matrix D = {Dii } is computed as Dii =
accordingly. The positive semidefinite matrix M is defined as:
M = (D  W ) + (1  sgn(W ))  W.

P

j

Dij
(9)

The symbol  represents the Hadamard product. It is easy to see the modified smoothness
measure in Eq. 9 can be written in the matrix form as,
1
(10)
kf k2G = f (X)> M f (X).
2
With the above new smoothness measure, we can extend the existing approaches using the
derived weighted graph for prediction tasks.

6. Experiments
In the previous sections, we described a method to construct a weight matrix for relational
data that serves as input to a rich class of graph based transductive learning algorithms. In
this section, we assess the efficacy of our approach through empirical studies on synthetic
and real data. In these studies, we compare methods across three broad categories, namely:
a) sophisticated relational learning (RL) methods, b) sophisticated graph transduction
methods with the weight matrix computed using available attributes or adjacency matrix
(if no attributes) as input (GTA) and c) relational transductive methods where our learned
weight matrix is passed as input to (enhanced/modified) graph transduction techniques.
The situations where methods in category c) perform favorably to methods in the other two
categories would be the conditions under which, using our procedure would be justified.
When attributes are available we compute the weights using a well accepted method (Jebara et al., 2009). The relational learning methods we consider are: MLNs, RDNs, PL-EM
and RN. We learn MLNs using discriminative learning and the inference is performed using
Markov Chain Monte Carlo (1000 runs). The conditional probability distributions (CPDs)
in RDNs are learned using relational probability trees (RPTs), since they generally have
better performance than relational bayesian classifiers especially when the number of features is large (Neville & Jensen, 2007)). The inference is performed on the sample obtained
after performing Gibbs sampling (burn-in is 100, number of samples is 1000) using the
learned CPDs. The graph transduction methods we consider are: local global consistency
(LGC) method and harmonic functions gaussian fields (HFGF) method. We consider these
methods, since they have been well recognized to be more robust across varied settings in
comparison with other transduction and label propagation methods (Liu & Chang, 2009),
and are thus considered as suitable baselines (Wang, Jebara, & Chang, 2013). The parameter settings we use for these methods are the same as in these prior works (Zhou et al.,
2004; Zhu et al., 2003). The parameters for our method (, ) for datasets that are heterogenous or have attributes are found using 10 fold cross-validation, for each combination
of ,   [0, 1] varied independently in steps of 0.1.
In all of our experiments, we vary the percentage of known labels for training from 5%
to 10% to 30% to 70%. The errors for each of the methods are obtained by randomly
selecting (100 times) the labeled nodes for the specified proportions followed by averaging
the corresponding errors. To avoid clutter in the figures reporting the results, we plot only
the following 4 curves (rather than 8),
826

fiSingle Network Relational Transductive Learning

16

49
Best RL

48

15

Best RL

14
13
12

Percentage Error

Percentage Error

47
Best GTA

HFGFW
LGCW

46

Best GTA

45
44
43

HFGFW

LGCW

42
11
41
10
0

20
40
60
Percentage Labeled

40
0

80

Figure 7: Performance of the methods
in the 3 categories when the
graph is generated using preferential attachment and the
auto-correlation is high, are
shown above.

20
40
60
Percentage Labeled

80

Figure 8: Performance of the methods
in the 3 categories when the
graph is generated using preferential attachment and the
auto-correlation is low, are
shown above.

 the best performance at each labeled percentage of methods in category a) (BEST
RL)2 ,
 the best performance at each labeled percentage of methods in category b) (BEST
GTA),
 the LGC method with our constructed weight matrix as input (LGCW) and
 the HFGF method with our constructed weight matrix as input (HFGFW) i.e. methods in category c).

6.1 Synthetic Experiments
We generate graphs using well accepted random graph generation procedures that create
real world graphs, namely: forest fire (FF) (Leskovec, Kleinberg, & Faloutsos, 2007) and
2. When the percentage of labeled instances is  10% all the RL methods have roughly the same accuracies,
though RN is obviously most efficient. For moderate labeling i.e. 30% PL-EM is usually the best. For
high labeling i.e. 70% RDNs are the best in most cases.

827

fiDhurandhar & Wang

16

Best RL

45

Best GTA

14

Percentage Error

Percentage Error

15

50
Best RL

13
12
11
10
9
0

HFGFW

Best GTA

40

35

LGCW

LGCW

20
40
60
Percentage Labeled

HFGFW

30
0

80

Figure 9: Performance of the methods
in the 3 categories when the
graph is generated using forest
fire and the auto-correlation is
high, are shown above.

20
40
60
Percentage Labeled

80

Figure 10: Performance of the methods in the 3 categories when
the graph is generated using forest fire and the autocorrelation is low, are shown
above.

preferential attachment (PA) (Barabasi & Albert., 1999). These procedures add one node at
a time and as nodes get added, we assign a label to it based on an intuitive label generation
procedure which is described below.
6.1.1 Setup
We generate 100 graphs consisting of 1000 nodes for the two generation techniques mentioned above. The parameter settings for forest fire (forward probability = 0.37, backward
probability = 0.32) and preferential attachment (exponent  = 1.6) are derived from studies
(Leskovec et al., 2007; Barabasi & Albert., 1999) which indicate that these settings lead to
most realistic graphs.
On the labeling front, we generate a binary labeling  {1, 1} by a simple procedure
for each of these graphs. Whenever a new node is added, with probability p we assign
the majority class amongst its labeled neighbors and with probability 1  p we assign one
of the two labels uniformly at random. Hence, the labels generated are dependent on the
particular graph generation procedure and consequently the connectivity of the graph, as
is desired. Its easy to see that as p  1 the auto-correlation in the graph increases, leading
to more homogeneity or less entropy amongst connected nodes. For each of the two graph
828

fiSingle Network Relational Transductive Learning

Years

Publication

Publication

advisedby
taughtby

Person

Pname

Title

ta
Name

Course

Status
Id

Inphase

CT

Person
I

S

H

N

Level

Hasposition

Course
CId
L

b)

a)

Figure 11: a) represents a relational schema of a real dataset UW-CSE with types, Person, Course and Publication. The relationship between the related types is
many-to-many. The rounded boxes denote their respective attributes. b) is the
corresponding model graph which depicts the conditional dependencies between
the relevant attributes of the three types namely; Name (N), Status (S), Inphase
(I), Hasposition (H), Concatenated Titles (CT), Concatenated course Ids (CId)
and Level (L).

generation procedures, we create graphs where p is low i.e. 0.3 and where p is high i.e. 0.8.
The low p leads to an auto-correlation of about 0.2 i.e.   0.2 while the high p leads to an
auto-correlation of about 0.7 i.e.   0.7, which are calculated from the generated graphs.
The model graph for the relational methods in this case is trivial since, there are no
attributes and hence the labels for unknown nodes are generated based known labels of
neighbors.
6.1.2 Observations
From Figures 7, 8, 9 and 10 we see that given a particular graph generation procedure
irrespective of the level of auto-correlation the relative performance of the 3 different class
of methods is qualitatively similar. GTAs are known to perform particularly well when only
a few nodes are labeled (Zhou et al., 2004; Wang et al., 2008) and this is confirmed in our
experiments. As the percentage of known labels increases however, the relational learning
methods start performing better than standard graph transduction techniques. This is
probably due to the fact that most sophisticated relational learning methods have low bias
and relatively high variance, however, with increasing number of labeled nodes this variance
drops rapidly.
829

fiDhurandhar & Wang

Figure 12: a) represents a relational schema of a real dataset BREAD with Store type.
The rounded boxes denote their respective attributes. b) is the corresponding
model graph which depicts the conditional dependencies between the relevant
attributes namely; Sales Target (ST), Promotions (P), Orders (O) and Reclaims
(R).

The interesting part is though, that our weight matrix construction technique seems to
capture enough of the complexity of the labeling and the network structure that besides
performing exceedingly well when the graph is sparsely labeled, it remains competitive with
relational learning methods when the percentage of known labels is moderate to high.
6.2 Real Data Experiments
For experiments on real data we choose three datasets, namely: UW-CSE (Richardson &
Domingos, 2006), WEBKB (Craven et al., 1998) and a real industrial dataset, BREAD,
obtained from a large consumer retail company.
6.2.1 Setup
The UW-CSE dataset contains information about the UW computer science department.
The dataset consists of 442 people being either students or professors. The dataset has
information regarding which course is taught by whom, who are the teaching assistants
for a course, the publication record of a person, the phase in which a person is (i.e. prequalifier, post-qualifier), the position of a person (i.e. faculty, affiliate faculty etc.), years
in a program and the advisor (or temporary advisor) of a student (advisedby links). The
relational schema for this dataset is given in Figure 11a. The classification task is to find
out if a person is a Student or Professor. The dataset is divided into five parts; ai.db,
graphics.db, theory.db, language.db and systems.db. We run experiments on each part and
830

fiSingle Network Relational Transductive Learning

21
70

Best RL

HFGFW

65

Best RL

60
19
18
17

Percentage Error

Percentage Error

20

Best GTA

HFGFW

LGCW

55

Best GTA

50
45

LGCW

40
35

16

30
15
0

20

40
60
Percentage Labeled

25
0

80

Figure 13: Performance of the methods
in the 3 categories on the
UW-CSE dataset, are shown
above.

20
40
60
Percentage Labeled

80

Figure 14: Multi-class transductive performance of the methods
in the 3 categories on the
WEBKB dataset, are shown
above.

report error averaged over all the parts. A model graph showing the various conditional
dependencies is shown in Figure 11b. In the model graph we introduce two new attributes
not present in the relational schema namely, CT and CId which are formed by concatenating
the titles of papers written by a person and by concatenating Ids of courses taught (or ta)
by a person. The Year attribute is eliminated since it is not particularly discriminative.
The relational methods are trained based on this model graph, besides offcourse taking into
account labels of neighbors.
The WEBKB dataset has a collection of webpages obtained from computer science
departments of 4 US universities. Each webpage belongs to one of 7 categories namely;
course, faculty, student, staff, project, department or other. The other category webpages
were not used as input in the classification task, but were used to link webpages in the
remaining 6 classes (Macskassy & Provost, 2007). We performed experiments on the four
graphs formed  one for each university  and computed the average error over the four
universities for each of the learning methods. For WEBKB, which is a commonly used
dataset, we use the model graph constructed in prior works (Neville & Jensen, 2007) to
train the relational methods.
The BREAD dataset has sales information about bread products sold in different stores
in the northeastern United States. The dataset has information from 2347 stores. For each
831

fiDhurandhar & Wang

50
45

Best RL

Percentage Error

40
Best GTA

35
30
25
20

HFGFW
LGCW

15
10
0

20
40
60
Percentage Labeled

80

Figure 15: Performance of the methods
in the 3 categories on the
BREAD dataset, are shown
above.

store we know its location, we know if the store met3 or underachieved its target quarterly
sales, we know the amounts it had on promotion during that period, we know the quantity
ordered during that period and we know the amount reclaimed during that period. Based
on location, we can form a graph linking the closest stores together. With this, we have a
dataset of size 2347 and where each node in the graph has 4 attributes. Setting the attribute
indicating whether the sales met or underachieved the expected amount as our class label,
we obtain a graph where each node has three explanatory attributes. The relational schema
for this dataset is given in Figure 12a. The corresponding model graph showing the various
conditional dependencies is shown in Figure 12b. Here again, the relational methods are
trained based on this model graph, besides taking into account labels of neighbors.
6.2.2 Observations
On the UW-CSE and WEBKB datasets we see that the best GTA is better than the relational methods when a small percentage (< 20%) of labels are known, but the relational
methods quickly close this gap and start outperforming the GTAs with more label information. Our weight matrix construction method however, performs better than the other
two classes of methods at low label proportions and remains competitive with the rela3. This also includes cases where the sales exceeded the expected amount.

832

fiSingle Network Relational Transductive Learning

tional methods as this proportion increases, unlike the GTAs. This favorable behavior can
most likely be attributed to our method being able to effectively model the strength (i.e.
the numerical value) and direction (i.e. + or ) of dependencies between linked entities,
something GTAs seemingly fail to capture.
On the BREAD dataset we see that the GTAs are much worse than the other class of
methods. A possible reason for this is that stores near to one another typically compete
with each other for the same type of products and hence, our input graph exhibits strong
negative auto-correlation. Since, GTAs predominantly model similarity between linked
entities, their performance is practically unchanged even when the percentage of known
labels is increased. The relational methods perform much better than GTAs in this setting.
In contrast to GTAs, they effectively capture the dissimilarity between linked nodes as the
number of known labels increases. However, our weight matrix construction method seems
to capture this relationship much earlier with only a small percentage of labels known.

7. Discussion
In this paper, we have provided a simple yet novel way of constructing a weight matrix for
partially labeled relational graphs that may be directed or undirected, that may or may
not have attributes and that may be homogeneous or heterogeneous. We have described
the manner in which such a weight matrix can serve as input to a rich class of graph
transduction methods through a modified graph laplacian based regularization framework.
We have portrayed the desirable properties of this construction method and showcased its
effectiveness in capturing complex dependencies through experiments on synthetic and real
data.
The primary focus of this paper was how to learn effectively over unweighted graphs.
However, there are many real world problems, where we might be given a weighted graph.
For instance, in genome sequence analysis the connection strength between gene expressions
can be estimated from experiments coupled with expert knowledge. In such situations the
question arises as to how can we incorporate the known weights into our methodology? A
logical and consistent way of incorporating these weights into our modeling would be to
combine it with the computed connectivity based weight wc and attribute based weight
wa as a conical combination. This is consistent with the methodology described before
to combine just connectivity based weight and attribute based weight. Thus, if wk is the
known (normalized) weight, then the weight of the edge would be wc + wa + wk , where
, ,   0. Same as before, the free parameters can be computed using standard model
selection techniques or based on graph properties and domain knowledge.
In the future, it would be interesting to extend our procedure to perform multi-class
classification in a single shot, rather than having to perform multiple binary classification
tasks. This would most likely improve the actual running time, though not necessarily the
time complexity in terms of O(.). It would also be interesting to learn the weights based
on the local neighborhood of the graph than the entire graph. Thus, we would compute D
based on the local structure around each datapoint and then assign weights. Determining
the locality however, can be tricky especially when there are multiple link types.
On the theory side, it might be of some interest to analyze the synthetic label generation
procedure introduced in this paper, for different types of graphs. One could use ideas from
833

fiDhurandhar & Wang

the theory of random walks to determine tendencies of the label generation procedure. From
a learning theory perspective, one could potentially derive error bounds as functions of p
(amongst other parameters), and if one were to express p in terms of auto-correlation ,
one would have error bounds as functions of . This would be of some interest since  can
be computed from static graphs or given a snapshot of an evolving graph, where one does
not have to know the order in which the nodes were attached, thus making the error bound
applicable to graphs in a larger set of applications.
A related but orthogonal research problem is that of studying influence spread through
social networks (Castillo, Chen, & Lakshmanan, 2012; Kempe, Kleinberg, & Tardos, 2003).
This is an interesting research problem, where one of the primary goals is to study how
information flows through real networks. To that end it is interesting to find out which
nodes/people in the network are likely to be the most influential so that targetting these
people can lead to rapid information spread. This is something that marketing departments
of consumer product companies are very interested in for obvious reasons. Though there are
some commonalities between this research problem and ours, such as having to learn and
perform inference over real graphs, the objectives are quite different. In our case, we mainly
care about correctly labeling unknown nodes based on connectivity and attributes. We are
not really interested in how the information flow would be the fastest and consequently
which nodes to target to achieve this in the most efficient manner. In a certain sense, the
influence spread problem probably could be formulated as an active learning version of our
problem, where we want to choose a small number of nodes to query that would maximize
the performance of a particular class of within network classification algorithms. This is
definitely something interesting to pursue going forward.

Acknowledgments
We would like to thank Katherine Dhurandhar for proofreading the paper. We would also
like to thank the editor and the reviewers for their constructive comments.

Appendix A
We provide figures for the synthetic and real data experiments with plots for all the methods
not just the best. Figures 16, 17, 18 and 19 correspond to the synthetic experiments, while
figures 20, 21 and 22 correspond to the real data experiments.

834

fiSingle Network Relational Transductive Learning

50

16
RN

RN

PLEM

48
MLN

Percentage Error

Percentage Error

15

LGC

14

HFGF

13

HFGFW

RDN
LGCW

12

LGC

46

HFGF
HFGFW

RDN

44

LGCW
MLN

42

11
10
0

PLEM

20
40
60
Percentage Labeled

40
0

80

20
40
60
Percentage Labeled

80

Figure 16: Performance of all the methods

Figure 17: Performance of all the methods

for PA with high autocorrelation.

for PA with low autocorrelation.

16
15

50
RN

RDN

Percentage Error

Percentage Error

PLEM

14
LGC

13
MLN

12
HFGF

11
10
9
0

HFGFW
LGCW

45

LGC

HFGF
PLEM

40

MLN
RN

35

HFGFW
LGCW

RDN

20
40
60
Percentage Labeled

30
0

80

20
40
60
Percentage Labeled

80

Figure 18: Performance of all the methods

Figure 19: Performance of all the methods

for FF with high autocorrelation.

for FF with low autocorrelation.

835

fiDhurandhar & Wang

21
RN

70
MLN

19
18

PLEM

RN

60
HFGF

HFGFW
RDN

17

HFGFW

65

LGC

Percentage Error

Percentage Error

20

LGCW

HFGF

55

PLEM

50
45

LGC

LGCW

MLN

40
35

16

RDN

30
15
0

20

40
60
Percentage Labeled

25
0

80

Figure 20: Performance of all the methods

20
40
60
Percentage Labeled

Figure 21: Multi-class transductive perfor-

on the UW-CSE dataset.

mance of all the methods on the
WEBKB dataset.

50
RN

45
Percentage Error

PLEM

40
MLN

HFGF,LGC

35
30
25
20

RDN
HFGFW
LGCW

15
10
0

80

20
40
60
Percentage Labeled

80

Figure 22: Performance of all the methods
on the BREAD dataset.

836

fiSingle Network Relational Transductive Learning

References
Barabasi, A., & Albert., R. (1999). Emergence of scaling in random networks. Science, 286,
509512.
Belkin, M., Niyogi, P., & Sindhwani, V. (2005). On manifold regularization. In Int. Workshop on Artificial Intelligence and Statistics.
Belkin, M., Niyogi, P., & Sindhwani, V. (2006). Manifold Regularization: A Geometric
Framework for Learning from Labeled and Unlabeled Examples. Journal of Machine
Learning Research, 7, 23992434.
Castillo, C., Chen, W., & Lakshmanan, L. (2012).
Kdd2012 tutorial: Information and influence spread in social networks. http://research.microsoft.com/enus/people/weic/kdd12tutorial inf.aspx.
Chakrabarti, S., Dom, B., & Indyk, P. (1998). Enhanced hypertext categorization using
hyperlinks. In Proceedings of SIGMOD-98, ACM International Conference on Management of Data, pp. 307318, Seattle, US. ACM Press, New York, US.
Chu, W., Sindhwani, V., Ghahramani, Z., & Keerthi, S. (2007). Relational learning with
gaussian processes. In Advances in Neural Information Processing Systems 19, pp.
289296. MIT Press.
Chung, F. (1997). Spectral graph theory. No. 92. Amer Mathematical Society.
Craven, M., DiPasquo, D., Freitag, D., McCallum, A., Mitchell, T., Nigam, K., & Slattery,
S. (1998). Learning to extract symbolic knowledge from the world wide web. In Proceedings of the fifteenth national/tenth conference on Artificial intelligence/Innovative
applications of artificial intelligence, AAAI, pp. 509516. American Association for
Artificial Intelligence.
Dhurandhar, A., & Dobra, A. (2012). Distribution free bounds for relational classification.
Knowledge and Information Systems, 1.
Gallagher, B., Tong, H., Eliassi-Rad, T., & Faloutsos, C. (2008). Using ghost edges for classification in sparsely labeled networks. In KDD 08: Proc. of the 14th ACM SIGKDD
Intl. conf. on Knowledge discovery and data mining, pp. 256264, New York, NY,
USA. ACM.
Getoor, L., Koller, D., & Small, P. (2004). Understanding tuberculosis epidemiology using
probabilistic relational models. Journal of Artificial Intelligence in Medicine, 30, 233
256.
Getoor, L., & Taskar, B. (2007). Introduction to Statistical Relational Learning. MIT Press.
Goldberg, A., Zhu, X., & Wright, S. (2007). Dissimilarity in graph-based semi-supervised
classification. In Artificial Intelligence and Statistics (AISTATS).
Goodman, L., & Kruskal, W. (1954). Measures of association for cross classifications. Journal of the American Statistical Association, 49, 732764.
Jebara, T., & Shchogolev, V. (2006). B-matching for spectral clustering. In Proc. of the 17th
European conf. on Machine Learning, ECML06, Berlin, Heidelberg. Springer-Verlag.
837

fiDhurandhar & Wang

Jebara, T., Wang, J., & Chang, S. (2009). Graph construction and b-matching for semisupervised learning. In Proc. of the 26th Annual Intl. Conf. on Machine Learning,
ICML 09, pp. 441448, New York, NY, USA. ACM.
Kempe, D., Kleinberg, J., & Tardos, E. (2003). Maximizing the spread of influence through
a social network. In Proceedings of the ninth ACM SIGKDD international conference
on Knowledge discovery and data mining, KDD 03, pp. 137146, New York, NY,
USA. ACM.
Leskovec, J., Kleinberg, J., & Faloutsos, C. (2007). Graph evolution: Densification and
shrinking diameters. ACM Trans. Knowl. Discov. Data, 1 (1), 2.
Liu, W., & Chang, S. (2009). Robust multi-class transductive learning with graphs. In
Computer Vision and Pattern Recognition, 2009., pp. 381388. IEEE.
Macskassy, A., & Provost, F. (2003). A simple relational classifier..
Macskassy, S., & Provost, F. (2007). Classification in networked data: A toolkit and a
univariate case study. J. Mach. Learn. Res., 8, 935983.
Maier, M., Von Luxburg, U., & Hein, M. (2008). Influence of graph construction on graphbased clustering measures. In Proc. of Neural Infor. Proc. Sys.
Neville, J., & Jensen, D. (2007). Relational dependency networks. J. Mach. Learn. Res., 8,
653692.
Richardson, M., & Domingos, P. (2006). Markov logic networks. Mach. Learn., 62 (1-2),
107136.
Sen, P., Namata, G. M., Bilgic, M., Getoor, L., Gallagher, B., & Eliassi-Rad, T. (2008).
Collective classification in network data. AI Magazine, 29 (3).
Taskar, B., Abbeel, P., & Koller, D. (2002). Discriminative probabilistic models for relational
data. In In Proc. 18th Conference on Uncertainty in AI, pp. 485492.
Tong, W., & Jin, R. (2007). Semi-supervised learning by mixed label propagation. In
Proceedings of the National Conference on Artificial Intelligence.
Wang, J., Jebara, T., & Chang, S. (2013). Semi-supervised learning using greedy max-cut.
Journal of Machine Learning Research, 14, 729758.
Wang, J., Jebara, T., & fu Chang, S. (2008). Graph transduction via alternating minimization. In In Proceedings of International Conference on Machine Learning.
Xiang, R., & Neville, J. (2008). Pseudolikelihood em for within-network relational learning.
In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining,
pp. 11031108, Washington, DC, USA. IEEE Computer Society.
Xiang, R., Neville, J., & Rogati, M. (2010). Modeling relationship strength in online social
networks. In Proc. of the 19th Intl. conf. on World wide web, New York, NY, USA.
ACM.
Zhou, D., Bousquet, O., Lal, T., Weston, J., & Schlkopf, B. (2004). Learning with local
and global consistency. In Advances in Neural Information Processing Systems 16,
pp. 321328. MIT Press.
838

fiSingle Network Relational Transductive Learning

Zhu, X., Ghahramani, Z., & Lafferty, J. (2003). Semi-supervised learning using gaussian
fields and harmonic functions. In Proceedings of ICML, pp. 912919.
Zhu, X., Lafferty, J., & Rosenfeld, R. (2005). Semi-supervised learning with graphs. Ph.D.
thesis, Carnegie Mellon University, Language Technologies Institute, School of Computer Science.

839

fiJournal of Artificial Intelligence Research 48 (2013) 717-732

Submitted 6/13; published 11/13

Research Note
A Case of Pathology in Multiobjective Heuristic Search
Jose Luis Perez de la Cruz
Lawrence Mandow
Enrique Machuca

perez@lcc.uma.es
lawrence@lcc.uma.es
machuca@lcc.uma.es

Dpto. Lenguajes y Ciencias de la Computacion
Universidad de Malaga
Bulevar Louis Pasteur, 35. Campus de Teatinos, 29071
Malaga (Spain)

Abstract
This article considers the performance of the MOA* multiobjective search algorithm
with heuristic information. It is shown that in certain cases blind search can be more
efficient than perfectly informed search, in terms of both node and label expansions.
A class of simple graph search problems is defined for which the number of nodes grows
linearly with problem size and the number of nondominated labels grows quadratically. It
is proved that for these problems the number of node expansions performed by blind MOA*
grows linearly with problem size, while the number of such expansions performed with a
perfectly informed heuristic grows quadratically. It is also proved that the number of label
expansions grows quadratically in the blind case and cubically in the informed case.

1. Introduction
Heuristic search algorithms are central to problem solving in Artificial Intelligence and to
many practical applications in Operations Research. In heuristic search some additional
information is provided to the algorithm with the aim of reducing the computational effort
needed to find a solution.
However, sometimes this goal is not achieved. On the contrary, in certain cases it
has been shown that the use of better heuristics implies a worsening of performance. For
example, a well-known fact arising in some bipersonal games is that of lookahead pathology,
that is, that the deeper is the exploration performed (and hence the better is suppossedly
the heuristic minimax value assigned to the position), the worse is the decision taken (Nau,
1982). Recently, the same phenomenon was described in one-agent real-time search (Lustrek
& Bulitko, 2008; Nau, Lustrek, Parker, Bratko, & Gams, 2010).
Even with statically precomputed heuristics some pathologies have been found. For
instance, let us consider the standard A* algorithm (Hart, Nilsson, & Raphael, 1968). It
is known that the algorithm is admissible when provided with optimistic heuristic cost
estimates and that, when these estimates are also consistent, more informed heuristics
always result in equally or more efficient search (see Pearl, 1984, especially pp. 7585).
However, when the heuristic is optimistic but not consistent, algorithm A* can perform
O(2n ) node expansions when the search is performed on a graph with n nodes and arc costs
are not bounded (Martelli, 1977). Notice that if no heuristic is used, then A* performs like
Dijkstras algorithm and can never exhibit such exponential performance.
c
2013
AI Access Foundation. All rights reserved.

fiPerez de la Cruz, Mandow, & Machuca

This paper deals with a pathology arising in certain extension of A* to multiobjective
search problems. In decision making situations where more than one criterion is involved,
the concept of optimal solution is frequently replaced by Pareto optimality, that is, a solution is better than other if it improves with respect to at least one criterion without
worsening the others (Ehrgott, 2005). Since Pareto optimality is a partial order relation,
solving these problems usually results in a set of Pareto-optimal solutions, that represent
the optimal trade-offs between the criteria being optimized. The importance of research in
multiobjective search algorithms is two-fold. In the first place, many graph search problems can benefit directly from multiobjective analysis (De Luca Cardillo & Fortuna, 2000;
Gabrel & Vanderpooten, 2002; Refanidis & Vlahavas, 2003; Muller-Hannemann & Weihe,
2006; DellOlmo, Gentili, & Scozzari, 2005; Ziebart, Dey, & Bagnell, 2008; Wu, Campbell,
& Merz, 2009; Delling & Wagner, 2009; Fave, Canu, Iocchi, Nardi, & Ziparo, 2009; Mouratidis, Lin, & Yiu, 2010; Caramia, Giordani, & Iovanella, 2010; Boxnick, Klopfer, Romaus, &
Klopper, 2010; Klopper, Ishikawa, & Honiden, 2010; Wu, Campbell, & Merz, 2011; Machuca
& Mandow, 2011). On the other hand, other multicriteria preference models used in graph
search typically look for a subset of Pareto-optimal solutions (Mandow & Perez de la Cruz,
2003; Perny & Spanjaard, 2005; Galand & Perny, 2006; Galand & Spanjaard, 2007; Galand,
Perny, & Spanjaard, 2010). Therefore, improvements in performance of multiobjective algorithms can guide the development of efficient algorithms for other multicriteria decision
rules.
Two direct extensions of A* that accept general (multiobjective) heuristic functions have
been proposed in the literature: MOA* (Stewart & White, 1991) and NAMOA* (Mandow
& Perez de la Cruz, 2005). NAMOA* uses label selection to guide the exploration. From
a formal point of view, a recent analysis (Mandow & Perez de la Cruz, 2010a) has shown
that the algorithm is admissible with optimistic heuristics, and that its efficiency, measured
by the number of label expansions, improves with more informed consistent heuristics.
Furthermore, the number of such expansions is optimal with respect to a class of admissible
algorithms. In other words, NAMOA* inherits the beneficial properties of A*.
MOA* uses node selection (as opposed to label selection) to guide the exploration, and
is also known to be admissible with optimistic heuristics (Stewart & White, 1991). The
development of MOA* prompted a number of related formal developments and extensions
(Dasgupta, Chakrabarti, & DeSarkar, 1995, 1999; Perny & Spanjaard, 2002; Mandow &
Perez de la Cruz, 2003; Perny & Spanjaard, 2005), and is still cited as an algorithm of
choice in recent applications (De Luca Cardillo & Fortuna, 2000; Fave et al., 2009; Klopper
et al., 2010). A previous formal analysis showed that there exist problems for which blind
MOA* performs (2n ) node expansions on graphs with n nodes (Mandow & Perez de la
Cruz, 2010b). However, the formal analysis of MOA* remained incomplete. In particular,
the efficiency of the algorithm was never related to the precision of consistent heuristics. A
recent empirical analysis (Machuca, Mandow, Perez de la Cruz, & Ruiz-Sepulveda, 2010)
has shown that, in certain cases, MOA* performs much worse than NAMOA* over biobjective random problems with different correlations. Quite surprisingly, this analysis has
also revealed that heuristic MOA* actually performs consistently worse than uninformed
MOA*.
This paper is part of an investigation into the formal properties of MOA* and NAMOA*.
We formally show that the performance of MOA*, measured in terms of the number of
718

fiA Case of Pathology in Multiobjective Heuristic Search

label or node expansions, does not improve in general with more informed heuristics. More
precisely, we define a class of simple graph search problems and prove that the use of
perfect heuristic information in MOA* yields more computational effort than the use of no
heuristic information. In other words, blind MOA* is in these cases more efficient than
perfectly informed MOA*, in terms of both node and label expansions.
The article is organized as follows. First, some necessary concepts are presented and
algorithm MOA* is briefly described (Section 2). Then in Section 3 a class of simple
multiobjective search problems is defined. The performance of MOA* over this class of
problems is analyzed for blind and perfectly informed cases in Sections 4 and 5 in terms of
node expansions, and in Section 6 in terms of label expansions. Finally, some conclusions
and future work are described.

2. Background
In multiobjective decision problems each alternative is evaluated according to a set of q
different objectives usually grouped in a vector ~y = (y1 , y2 , . . . yq ), ~y  Rq . Preference
between vectors ~x, ~y is defined by the so-called Pareto order or dominance relation () as
follows: ~x  ~y if and only if for all objectives i it holds that xi  yi and at least for an
objective j it holds that xj < yj . Given a set of vectors Y , the subset of nondominated
vectors nd(Y ) in Y is defined as nd(Y ) = {~y  Y | @~x  Y ~x  ~y }.
The solution to a multiobjective problem consists of the set of Pareto-optimal or nondominated solutions, that is, the set of solutions such that their costs are nondominated in
the set of solution costs.
In a multiobjective graph search problem, a single source and a set of destination nodes
are designated in a given graph G = (N, A). Pairs of nodes n, n0  N may be joined by
directed arcs (n, n0 )  A labelled with vector costs ~c(n, n0 )  Rq . A path P in the graph is
any sequence of nodes joined by consecutive arcs and the cost ~c(P ) of P is the sum of the
costs of its component arcs. The solution to the problem is the set of all paths P joining
source and destination nodes and such that ~c(P ) is nondominated in the set of solution
costs.
2.1 MOA* Algorithm
MOA* is a well-known algorithm that performs multiobjective heuristic graph search (Stewart & White, 1991). Its pseudocode (slightly adapted from the original: Stewart & White,
1991) is presented in Table 1. MOA* presents many similarities with A*. Two sets of nodes
OP EN and CLOSED are used to control the search. Initially, the source node is the only
open node. Newly generated nodes create a pointer to their parents. However, MOA* does
not construct a search tree like A*, but rather an acyclic directed graph. This is due to the
fact that each node may be reached by several optimal (nondominated) paths. The scalar
cost functions g, h, f are generalized to functions G, H, F that return sets of vectors for each
node. Additionally, the LABEL(n0 , n) sets keep the subsets of vectors in G(n0 ) that arise
from paths to n0 coming from n.
Function G(n) refers to the set of nondominated cost vectors among all paths already
found to n. The heuristic function H(n) returns also a set of vectors, estimating the costs of
719

fiPerez de la Cruz, Mandow, & Machuca

1. INITIALIZE a set OP EN with the start node s, and empty sets, SOLN , C, CLOSED and LABEL.
2. CALCULATE the set N D of nodes n in OP EN such that at least one estimate f~  F (n) is not
dominated by the estimates of other open nodes or by any solution cost of C.
3. If N D is empty, then
Terminate returning the set of solution paths that reach nodes in SOLN with costs in C.
else
Choose a node n from N D using a domain-specific heuristic, breaking ties in favour of goal nodes,
and move n from OP EN to CLOSED.
4. Do bookkeeping to maintain accrued costs and node selection function values.
5. IDENTIFY SOLUTIONS. If n is solution node, then
Include n in SOLN and its current costs into C.
Remove dominated costs from C.
Go back to step 2.
6. EXPAND n and examine its successors. For all successors nodes m of n do:
(a) If m is a newly generated node, then
i.
ii.
iii.
iv.

Establish a pointer from m to n.
Set G(m) = LABEL(m, n).
Compute F (m).
Add m to OP EN .

(b) Otherwise, m is not new, so do the following,
i. If any potentially nondominated paths to m have been discovered, then, for each one, do
the following.
Ensure that its cost is in LABEL(m, n), and therefore in G(m).
If a new cost was added to G(m) then, purge from LABEL(m, n) dominated costs, and
if m was in CLOSED, then move it to OP EN .
7. Go back to step 2.

Table 1: MOA Algorithm.
all nondominated paths from n to destination nodes. The evaluation function F (n) returns
a set of cost estimates for n, F (n) = nd{~g + ~h | ~g  G(n)  ~h  H(n)}.
Later on it will be useful to define H  (n) as the function that returns the set of costs of
all actual nondominated paths from n to destinations nodes.
At each iteration MOA* computes ND, the subset of open nodes with a nondominated
cost estimate, and selects a node from this subset. The admissibility of the algorithm does
not depend on the particular selection procedure among nodes in ND. In the following, this
additional selection procedure for nondominated nodes will be called nd-selection rule.
When a destination node is selected, it is added to SOLN, and its costs to C. Values of
F (n) dominated by vectors in C are never considered in ND. Search terminates when ND
is empty, that is, all candidate nodes are dominated or have been explored.
The expansion of n generates all successors n0 of n in the graph and adequate G(n0 )
values for them. If n0 is new, then it is placed in OPEN, and the sets G(n0 ) and LABEL(n0 , n)
store the costs of all paths extended from n to n0 . If n0 is not new, then MOA* checks if
720

fiA Case of Pathology in Multiobjective Heuristic Search

a new nondominated value of G(n0 ) has been generated at the current step; if this is the
case, G(n0 ) and LABEL(n0 , n) are properly updated, and, if n0 was in CLOSED, it must
be moved back again to OPEN.
Each pair (n, ~g ) such that n is a node and ~g  G(n) is usually called a label. In MOA*
all labels of a node n are expanded simultaneously once n is selected. Therefore, all labels
reaching a single node at a given time are either simultaneously open or closed.
In the original paper (Stewart & White, 1991), some interesting properties of MOA*
were proved. For example, it was proved that MOA* is admissible when H(n) is optimistic.
Regarding comparison of admissible heuristics, a function H(n) is defined to be at least
as informed as another H 0 (n) whenever for all ~h0  H 0 (n) there exists some ~h  H(n) such
that ~h0  ~h. In such case, it was proved that the set of nodes expanded by MOA* with H is
a subset of those expanded with H 0 (theorem 4, p. 805). However, the authors recognized
that nodes may be reopened even when the heuristic function is consistent, and hence that
the set of expanded nodes is not a significant measure in the analysis of the performance of
MOA*.

Figure 1: Graph M (3, 10, 10, 2)

3. A Class of Multiobjective Search Problems
For every n  N, let us consider problem graphs (Figure 1) with 2n nodes labeled 1, . . . , 2n
1, 2n and with 3n  2 arcs. For every even node 2i (1  i < n) there are outgoing arcs
of form (2i, 2i + 1) and (2i, 2i + 2). For every odd node 2i + 1 (1  i < n  1) there is
an outgoing arc of the form (2i + 1, 2i + 2). There is also an arc (1, 2). The start node
is 1 and the goal node is 2n. The cost of an arc ~c(i, j) is defined as follows: choose 
to be either 2 or 4; then for every i > 0, ~c(2i, 2i + 2) = (, 6  ); and for every i > 0,
~c(2i, 2i + 1) = ~c(2i + 1, 2i + 2) = (3  /2, /2). In this way, we define only two possible
sets of costs for the arcs, with the exception of ~c(1, 2) = (1 , 2 ) that is not subject to any
restriction.
We shall refer to these problem graphs as multiobjective chain graphs. For every n, the
corresponding set of multiobjective chain graphs will be denoted Mn . We will denote as
M (n, 1 , 2 , ) the graph in Mn such that ~c(1, 2) = (1 , 2 ) and c(2i, 2i + 2) = (, 6  ).
For example, Figure 1 shows M (3, 10, 10, 2).
In a graph M  Mn there are always 2n1 different paths from the start to the goal
node. In fact, to go from 2i to 2i + 2 you can choose either the simple path < 2i, 2i + 2 >
(with cost (, 6  )) or the two-arc path < 2i, 2i + 1, 2i + 2 > (with cost (6  , )) and
there are n  1 independent choices like that. On the other hand, there are just n different
path costs given by c~n k = (1 , 2 ) + (2(n  1) + 2k, 4(n  1)  2k), for every k such that
721

fiPerez de la Cruz, Mandow, & Machuca

It. #
1
2
3
4
5
6

OPEN
1
2
3
4
4
5
6
6

G(n) = F (n)
(0, 0)
(10, 10)
(12, 11)
(12, 14)
(12, 14)(14, 12)
(14, 15)(16, 13)
(14, 18)(16, 16)
(14, 18)(16, 16)(18, 14)

Table 2: Trace of uninformed MOA* on M (3, 10, 10, 2)

0  k  n  1. In an M (n, 1 , 2 , 2) graph, the cost c~n k corresponds to a path with n  1  k
arcs (2i, 2i + 2) and k paths < 2i, 2i + 1, 2i + 2 >. We will denote Cn = {c~n 0 , . . . , c~n n1 }.
Notice that for every solution cost (y1 , y2 )  Cn it holds that y1 + y2 = 1 + 2 + 6(n  1),
so all solution costs for a given M lie in a line with negative slope and hence none of these
costs dominates another, that is, nd(Cn ) = Cn .

4. Blind MOA* on Mn
A sample run of MOA* over M (3, 10, 10, 2) (Figure 1) with H(n) = {~0} (uninformed case)
is provided in Table 2. Values of G(n) include all nondominated costs from generated paths
to the node. Since we are performing a blind search, values for F (n) are the same as for
G(n).
We can observe in this trace that a node i is not selected until all nodes j < i have
been selected. That means that every node i, 1  i  2n  1 is expanded once and just
once. In this way, in our example MOA* performs exactly 2n node selections and 2n  1
node expansions. This result is general and can be proved by induction on the number of
iterations for every graph M (n, 1 , 2 , ).
Lemma 1 If the input of MOA* is a graph M (n, 1 , 2 , ) and n H(n) = {~0}, then MOA*
performs exactly 2n  1 node expansions.
Proof. Let us consider the OPEN set at a certain iteration s (s = 1, . . .) of the execution
of MOA*. Let us call the level of s the integer L = bs/2c. It is easily proved by induction
on s that:
(i) at every odd iteration s of the algorithm (s = 3, . . .), OPEN = {s, s+1}, the labels of s
are {(a+3/2, b+/2) | (a, b)  CL }; the labels of s+1 are {(a+, b+6)| (a, b)  CL };
and the selected node is s.
(ii) At every even iteration s of the algorithm (s = 4, . . .), OPEN = {s}, the labels of s
are exactly CL and the selected node is s.
From this follows that every node is selected exactly once and therefore the number of
node expansions is exactly 2n  1.
/
722

fiA Case of Pathology in Multiobjective Heuristic Search

n
1
2
3
4
5
6

H  (n)
(14,18),(16,16),(18,14)
(4,8),(6,6),(8,4)
(4,5),(6,3)
(2,4),(4,2)
(2,1)
(0,0)

Table 3: Heuristic values for M (3, 10, 10, 2)

Figure 2: Search graph at iteration 2

5. Perfectly Informed MOA* on Mn
A sample run of MOA* over M (3, 10, 10, 2) (Figure 1) with H(n) = H  (n) (perfect information) is provided in Figures 2-9 and Table 4. Figures 2-9 show a trace of the search graph
at each iteration. Closed nodes are shown in gray. Values of G(n) are shown for each node
in the Figures only when they are created, or change from the previous iteration.
In Table 4, for each iteration all nodes in OPEN are displayed and also their G(n)
values (that is, nondominated costs of paths generated from the start to the node). Values
of F (n) are computed adding to G(n) values the estimations in Table 3. Since we are
assuming perfect heuristic information, F (n) values are always optimal solution costs, that
is, nondominated costs of solution paths from node 1 to node 6. Then, for every iteration
and every node n, F (n)  C3 .
Notice also that labels in C3 (and hence in F (n)) are all nondominated, so in general
there will be several open nondominated nodes. It is then necessary to provide an additional
heuristic rule (step 3-else of the algorithm in Table 1) or nd-selection rule. In the example in
Table 4, the following nd-selection rule is applied: select the node with the best lexicographic
nondominated alternative (remember that the lexicographic order is a total order defined
for the biobjective case as (y1 , y2 ) < (z1 , z2 ) if and only if y1 < z1 , or y1 = z1 and y2 < z2 ).
It is also possible that the same nondominated cost appears in several open nodes. Then
another procedure must be provided for breaking ties between open nodes with the same
f~-label. It can be done, for instance, at random, or by selecting the newest node, or the
oldest node in OPEN in a breadth-first fashion. The latter procedure has been followed in
Table 4.
We can observe that the order of node selection in the example is
124634656
The pattern is: MOA* selects even nodes until the goal node is reached; then it selects an
odd node 2i + 1 and selects again all even nodes 2j, j > i; and it is done again until every
odd node has been selected once. In this way even nodes are in general selected several
times. In our example node 4 is selected twice and node 6 is selected three times.
723

fiPerez de la Cruz, Mandow, & Machuca

It#
1
2
3
4

5
6
7
8
9

OPEN
1
2
3
4
3
5
6
3
5
4
5
5
6
5
6

G(n)
(0, 0)
(10, 10)
(12, 11)
(12, 14)
(12, 11)
(14, 15)
(14, 18)
(12, 11)
(14, 15)
(12, 14)(14, 12)
(14, 15)
(14, 15)(16, 13)
(14, 18)(16, 16)
(14, 15)(16, 13)
(14, 18)(16, 16)(18, 14))

F (n)
(14, 18)(16, 16)(18, 14)
(14, 18)(16, 16)(18, 14)
(16, 16)(18, 14)
(14, 18)(16, 16)
(16, 16)(18, 14)
(16, 16)
(14, 18)
(16, 16)(18, 14)
(16, 16)
(14, 18)(16, 16)(18, 14)
(16, 16)
(16, 16)(18, 14)
(14, 18)(16, 16)
(16, 16)(18, 14)
(14, 18)(16, 16)(18, 14)

Table 4: Trace of perfectly informed MOA* on M (3, 10, 10, 2)

Figure 3: Search graph at iteration 3

Figure 4: Search graph at iteration 4

Figure 5: Search graph at iteration 5

724

fiA Case of Pathology in Multiobjective Heuristic Search

Figure 6: Search graph at iteration 6

Figure 7: Search graph at iteration 7

Figure 8: Search graph at iteration 8

Figure 9: Search graph at iteration 9

725

fiPerez de la Cruz, Mandow, & Machuca

The concrete order of expansion will depend on nd-selection and tie-breaking rules.
However, we can prove some general results valid for any nd-selection rule that uses only
heuristic f~ values (irrespective of the tie-breaking rule). Notice that nd-selection rules
usually applied (as best lexicographic or best linear) are of this kind.
Lemma 2 (i) Let M (n, 1 , 2 , 2)  Mn . Let their nondominated solution costs be C =
{~
c 0 , . . . , c~ n1 }. If the nd-selection rule is such that c~ 0 is selected with preference to
{~
c 1 , . . . , c~ n1 }, then MOA* performs at least n + n(n1)
node expansions.
2
(ii) Analogously, let M (n, 1 , 2 , 4)  Mn . If the nd-selection rule is such that c~ n1 is
selected with preference to {~
c 0 , . . . , c~ n2 }, then MOA* performs at least n + n(n1)
node
2
expansions.
Proof. We will prove part (i) (proof of part (ii) is entirely analogous). Let M (n, 1 , 2 , 2) 
Mn . First remember that for each node j and each iteration s of the algorithm, the set
F (j) of estimated costs at j is a subset of Cn = {~
c 0 , . . . , c~ k , . . . , c~ n1 } = {(1 + (2(n 
1) + 2k, 2 + 4(n  1)  2k)) | 0  k  n  1}. Let us trace the first n + 1 iterations of the
algorithm. It can be shown that for every i > 0, c~ 0 will appear in F (2i), but c~ 0 will never
appear in F (2i + 1). Therefore, in the first iteration node 1 will be selected and expanded.
Then all even nodes will be selected and expanded sequentially until node 2i is selected.
That amounts to the first n expansions.
Elementary computations show that at this step, for every 0 < i  n, F (2i) = {~
c 0, . . . ,
ni
1
ni
c~
}; for every 0 < i  n1, F (2i+1) = {~
c , . . . , c~
}; and OP EN = {3, 5, . . . , 2n1}.
Two observations can be made at this step: i) Let us consider odd nodes. Since for every odd
node 2i + 1 (0 < i < n) there is an optimal path going through it, all these open nodes must
be selected and expanded before termination. That amounts to at least n  1 expansions,
even if no reexpansion is assumed for such nodes; ii) Let us consider now nongoal even
nodes {2, 4, . . . , 2n  2}. At this iteration the number of labels associated to 2i is n + 1  i.
Since through every even node there exist n optimal costs, at the termination the number of
labels for every even node must be exactly n, that is, there are 0 + 1 + . . . + (n  1) = n(n1)
2
labels for even nodes missing at this moment. If we prove that those labels are generated
one at a time, that is, one in every expansion, we will have proved that at least another
n(n1)
expansions are needed.
2
Let us call an episode the subsequence of node expansions comprised between two consecutive odd node expansions (or between the last odd node expansion and the last expansion).
In the example of Table 4, the episodes are < 1, 2, 4, 6 >, < 3, 4, 6 > and < 5, 6 >. When
an episode starts, there is no even node in OPEN (since an even node always has the ndselected label c~ 0 , an odd node never has the nd-selected label c~ 0 , and an odd node has been
selected). At the end of the episode, and by the same reason, there is again no even node in
OPEN. Let us consider an episode e =< 2j  1, 2j, 2j 0 , . . . , 2j n >. It is easily seen that the
expansion of an even node 2j originates the opening of just an even node, namely 2(j + 1),
so the episode is always of the form E =< 2j  1, 2j, 2(j + 1), 2(j + 2), . . . , 2(j + m) >.
We will prove by induction on episodes that when every episode starts, for every even
node 2i (1 < i  n) there exist integers p, q such that: i) F (2i) = {~
c 0 , . . . , ~cp }; ii)
F (2i  2) = {~
c 0 , . . . , c~ q } = F (2i  1)  {~
c 0 }; and iii) either q = p or q = p + 1. This is
obviously true when the first episode finishes and the second episode starts. Assume it is
726

fiA Case of Pathology in Multiobjective Heuristic Search

true when episode e starts. We will show it remains true when it finishes, that is, when
episode e + 1 starts.
Consider the odd node 2j  1 which starts the episode and assume q = p, that is,
that F (2j  1) = F (2j)  {~
c 0 }. Then no new label is added to F (2j), no reexpansion
is needed and no modification is done, hence the stated relation among labels continues
true. On the contrary, assume that q = p + 1, that is, that F (2j  1) = {~
c 1 , . . . , c~ p+1 },
0
p+1
0
p
F (2j  2) = {~
c , . . . , c~
}, and F (2j) = {~
c , . . . , c~ }. Therefore one label c~ p+1 is added
to 2j. The stated relation between labels remain true for 2j  2, 2j  1 and 2j (only that
we have now the other alternative p = q). However, F (2j) has been modified and we must
check the relation for F (2j), F (2j + 1) and F (2j + 2). By hypothesis it was F (2j + 1) =
{~
c 1 , . . . , c~ p }, and the expansion of 2j adds c~ p+1 to it, so also it becomes F (2j) = F (2j +1).
Concerning the relation between F (2j) and F (2j + 2), if it was F (2j + 2) = {~
c 0 , . . . , c~ p },
no further label is added to F (2j + 2), the relation holds (since F (2j + 2) has exactly one
label less than F (2j) now) and the episode finishes since no even node remains open. If it
was F (2j + 2) = {~
c 0 , . . . , c~ p1 }, one label c~ p is added to F (2j + 2) and the relation also
becomes true, but F (2j + 2) has been modified. By induction on the length of the episode
it could be proved that finally the relation holds for all modified nodes.
In any case, we see that each new added label immediately triggers the expansion of the
node and labels are added to even nodes one at a time. Therefore, at least n(n1)
expansions
2
are needed to complete the labels of even nodes. The first expansion of the episode was one
of an odd node, so it must not be computed; but the last expansion of the episode does not
add any label, so we can compute n(n1)
additional node expansions.
2
expansions,
Now, adding togheter all performed expansions, we have at least n + n(n1)
2
q. e. d.
/

Figure 10: Construction of a M (4, 1 , 2 , 2) graph for Lemma 3

727

fiPerez de la Cruz, Mandow, & Machuca

Now we can prove the main lemma:
Lemma 3 If the nd-selection rule depends only on f~ values, then for every n  N there
exists a graph M (n, 1 , 2 , ) such that when it is input to MOA* and H(n) = H  (n), then
MOA* performs at least n + n(n1)
node expansions.
2
Proof. The idea of the proof is as follows: Lemma 2 asserts that if we order lexicographically the optimal costs of a graph M (n, 1 , 2 , 2)  Mn and the selected one turns out to be
the first one, then MOA* performs at least n + n(n1)
node expansions (and analogously for
2
every graph M (n, 1 , 2 , 4)  Mn when the selected one is the last one). Then we will have
Lemma 3 proved if for every n and every selection rule depending only on f~ values we show
a graph M (n, 1 , 2 , 2)  Mn satisfying that condition (or a graph M (n, 1 , 2 , 4)  Mn
satisfying the analogous condition).
Let n  N. Let us consider the line y1 + y2 = 8(n  1) + 2 and a sequence of m = 2n  1
nondominated points on it, (F 0 , . . . , F m1 ) given by F i = (2(n1)+2i+1, 6(n1)2i+1)
(Figure 10 shows the line and the seven points F 0 , . . . , F 6 for n = 4). Any nd-selection
rule will select one of them, say F j , with preference over the others; in any case, for any
F j we can extract from (F 0 , . . . , F m1 ) a subsequence of n points (F j , F j+1 , . . . , F j+n1 )
or (F jn+1 , . . . , F j1 , F j ). Assume the first case (that is depicted in Figure 10 for j = 3;
the subsequence is F 3 , F 4 , F 5 , F 6 ). Then we will consider the graph M (n, 1 , 2 , 2) with
1 = 2j + 1 and 2 = 2(n  1  j) + 1 (in Figure 10 the point K is (1 , 2 ) = (7, 1)).
This is always possible, that is, for every n, j we have 1 , 2 > 0. But then we have for
every k, 0  k  n  1, that F j+k = (1 , 2 ) + (2(n  1) + 2k, 4(n  1)  2k) = c~ k , that
is, the extracted subsequence (F j , F j+1 , . . . , F j+n1 ) is exactly the set of solution costs for
M (n, 1 , 2 , 2), (~
c 0 , c~ 1 , . . . , c~ n1 ). Since F j is nd-selected over (F j+1 , . . . , F j+n1 ), by
Lemma 2 MOA* performs at least n + n(n1)
node expansions on M (n, 1 , 2 , 2).
2
Analogously we can prove the other case considering a graph of the form M (n, 3 , 4 , 4).
/
From Lemmas 1 and 3 we obtain immediately the following result.
Theorem 1 For every nd-selection rule depending only on f~ values, there exists a sequence
of graphs M1 , . . . , Mn , . . . such that:
(i) Every Mn has 2n nodes and 3n  2 arcs.
(ii) MOA performs (n) node expansions when applied to Mn and no heuristic information is given.
(iii) MOA performs (n2 ) node expansions when applied to Mn and perfect heuristic
information is given.

6. Label Counts
The basic operation of MOA is node expansion and every node expansion implies in
the general case the joint expansion of several labels. However, other algorithms (e.g.
NAMOA , Mandow & Perez de la Cruz, 2010a) use label expansion as the basic operation.
For this reason it could be interesting to analyse MOA also in terms of label expansions.
Lemma 4 If the input of MOA* is a graph M (n, 1 , 2 , ) and H(n) = {~0}, then MOA*
performs exactly n2  n + 1 label expansions.
728

fiA Case of Pathology in Multiobjective Heuristic Search

Proof. Consider again the reasoning for the proof of Lemma 1. It was then proved that,
when selected for expansion, every even node 2i has i labels
Pand every odd node 2i + 1
(with i  1) has i labels. Adding all together we have 1 + 2 1in1 i = 1 + n(n  1) =
n2  n + 1 label expansions.
/
Lemma 5 For every n  N there exists a graph M (n, 1 , 2 , ) such that when it is input to
MOA* and H(n) = H  (n), then MOA* performs at least n2 + n(n+1)(n1)
label expansions.
4
Proof. Every odd node 1, . . . , 2n  1 must have at termination n labels, and must be
expanded at least once. That amounts to at least n2 label expansions. On the other hand,
consider even nodes 2, 4, . . . , 2n  2. They must also have n labels at termination. Consider
again the reasoning for the proof of Lemma 2. It was then proved that: (i) the first time
an even node 2i is expanded, it has (n  i + 1) labels; (ii) each time an even node 2i is
expanded, it has exactly one more label. Therefore thePnumber of label expansions for node
2i is (n  i + 1) + (n  i + 2) + . . . + (n  i + i) = 1ji (n  i + j) = (n+1)i
2 . Adding
P
(n+1)i
togheter for all even nodes 2i with 1  i  n  1 we have 1in1 2 = n(n+1)(n1)
4
label expansions. Adding now the expansions of odd and even nodes we have at least
n2 + n(n+1)(n1)
q. e. d.
4
/
From Lemmas 4 and 5 we obtain immediately the following result.
Theorem 2 For every nd-selection rule depending only on f~ values, there exists a sequence
of graphs M1 , . . . , Mn , . . . such that:
(i) Every Mn has 2n nodes and 3n  2 arcs.
(ii) MOA performs (n2 ) label expansions when applied to Mn and no heuristic information is given.
(iii) MOA performs (n3 ) label expansions when applied to Mn and perfect heuristic
information is given.

7. Conclusions and Future Work
This paper considers the performance of the MOA* multiobjective heuristic search algorithm. Results show that performance can degrade with better heuristic information. A
class of problems is presented (multiobjective chain graphs) where the use of perfect heuristic information (a trivially consistent informed heuristic) does not result in a reduction in
the number of node or label expansions performed by the algorithm. On the contrary, the
performance of a perfectly informed version of the algorithm is worse than the performance
of the blind version.
Multiobjective chain graphs formalize a not so infrequent situation in practical multiobjective search, when a sequence of nodes is traversed by at least two conflicting paths. Our
analysis has revealed that when MOA* is combined with H  , the best possible heuristic,
the number of node expansions grows quadratically, while this number grows linearly when
no heuristic information is used; and the number of label expansions grows cubically, while
it grows quadratically when no heuristic information is provided.
729

fiPerez de la Cruz, Mandow, & Machuca

This pathology, together with other results both theoretical (Mandow & Perez de la
Cruz, 2010b) and empirical (Machuca, Mandow, Perez de la Cruz, & Ruiz-Sepulveda, 2012),
casts some doubts on the suitability of MOA* for performing heuristic multiobjective search.
In general, other alternatives (such as NAMOA*) for which it has been proved (Mandow
& Perez de la Cruz, 2010a) that those pathological behaviours cannot arise, should be
preferred.

Acknowledgments
Partially supported by Gobierno de Espana, grant TIN2009-14179. Partially funded by
Consejera de Innovacion, Ciencia y Empresa. Junta de Andaluca (Espana), P07-TIC03018.

References
Boxnick, S., Klopfer, S., Romaus, C., & Klopper, B. (2010). Multiobjective search for the
management of a hybrid energy storage system. In IEEE International Conference
on Industrial Informatics (INDIN), pp. 745750.
Caramia, M., Giordani, S., & Iovanella, A. (2010). On the selection of k routes in multiobjective hazmat route planning. IMA Journal of Management Mathematics, 21,
239251.
Dasgupta, P., Chakrabarti, P., & DeSarkar, S. (1995). Utility of pathmax in partial order
heuristic search. Information Processing Letters, 55, 317322.
Dasgupta, P., Chakrabarti, P., & DeSarkar, S. (1999). Multiobjective Heuristic Search.
Vieweg, Braunschweig/Wiesbaden.
De Luca Cardillo, D., & Fortuna, T. (2000). Dea model for the efficiency evaluation of
nondominated paths on a road network. European Journal of Operational Research,
121 (3), 549558.
Delling, D., & Wagner, D. (2009). Pareto paths with SHARC. In SEA, pp. 125136.
DellOlmo, P., Gentili, M., & Scozzari, A. (2005). On finding dissimilar Pareto-optimal
paths. European Journal of Operational Research, 162, 7082.
Ehrgott, M. (2005). Multicriteria Optimization. Springer.
Fave, F. M. D., Canu, S., Iocchi, L., Nardi, D., & Ziparo, V. A. (2009). Multi-objective
multi-robot surveillance. In 4th International Conference on Autonomous Robots and
Agents (ICARA), pp. 6873. IEEE.
Gabrel, V., & Vanderpooten, D. (2002). Enumeration and interactive selection of efficient
paths in a multiple criteria graph for scheduling an earth observing satellite. European
Journal of Operational Research, 139, 533542.
Galand, L., & Perny, P. (2006). Search for compromise solutions in multiobjective state
space graphs. In Proc. of the XVII European Conference on Artificial Intelligence
(ECAI2006), pp. 9397.
730

fiA Case of Pathology in Multiobjective Heuristic Search

Galand, L., Perny, P., & Spanjaard, O. (2010). Choquet-based optimisation in multiobjective shortest path and spanning tree problems. European Journal of Operational
Research, 204 (2), 303315.
Galand, L., & Spanjaard, O. (2007). Owa-based search in state space graphs with multiple
cost functions. In FLAIRS Conference 2007, pp. 8691.
Hart, P., Nilsson, N., & Raphael, B. (1968). A formal basis for the heuristic determination
of minimum cost paths. IEEE Trans. Systems Science and Cybernetics SSC-4, 2,
100107.
Klopper, B., Ishikawa, F., & Honiden, S. (2010). Service composition with pareto-optimality
of time-dependent QoS attributes. Lecture Notes in Computer Science, LNCS 6470,
635640.
Lustrek, M., & Bulitko, V. (2008). Thinking too much: Pathology in path finding. In et al.,
M. G. (Ed.), Proceedings of the European 18th Conference on Artificial Intelligence,
pp. 899900. IOS Press.
Machuca, E., Mandow, L., Perez de la Cruz, J. L., & Ruiz-Sepulveda, A. (2010). An
empirical comparison of some multiobjective graph search algorithms. In KI2010 LNAI 6359, pp. 238245.
Machuca, E., Mandow, L., Perez de la Cruz, J. L., & Ruiz-Sepulveda, A. (2012). A comparison of heuristic best-first algorithms for bicriterion shortest path problems. European
Journal of Operational Research, 217, 4453.
Machuca, E., & Mandow, L. (2011). Multiobjective route planning with precalculated
heuristics. In Proc. of the 15th Portuguese Conference on Artificial Intelligence (EPIA
2011), pp. 98107.
Mandow, L., & Perez de la Cruz, J. L. (2003). Multicriteria heuristic search. European
Journal of Operational Research, 150, 253280.
Mandow, L., & Perez de la Cruz, J. L. (2005). A new approach to multiobjective A*
search. In Proc. of the XIX Int. Joint Conf. on Artificial Intelligence (IJCAI05), pp.
218223.
Mandow, L., & Perez de la Cruz, J. L. (2010a). Multiobjective A* search with consistent
heuristics. Journal of the ACM, 57 (5), 27:125.
Mandow, L., & Perez de la Cruz, J. L. (2010b). A note on the complexity of some multiobjective A* search algorithms. In ECAI 2010, pp. 727731.
Martelli, A. (1977). On the complexity of admissible search algorithms. Artificial Intelligence, 8, 113.
Mouratidis, K., Lin, Y., & Yiu, M. (2010). Preference queries in large multi-cost transportation networks. In Proceedings - International Conference on Data Engineering,
pp. 533544.
Muller-Hannemann, M., & Weihe, K. (2006). On the cardinality of the Pareto set in bicriteria shortest path problems. Annals of OR, 147 (1), 269286.
Nau, D. S. (1982). An investigation of the causes of pathology in games. Artificial Intelligence, 19 (3), 257278.
731

fiPerez de la Cruz, Mandow, & Machuca

Nau, D. S., Lustrek, M., Parker, A., Bratko, I., & Gams, M. (2010). When is it better not
to look ahead?. Artificial Intelligence, 174 (1617), 13231338.
Pearl, J. (1984). Heuristics. Addison-Wesley, Reading, Massachusetts.
Perny, P., & Spanjaard, O. (2002). On preference-based search in state space graphs. In
Proc. Eighteenth Nat. Conf. on AI, pp. 751756. AAAI Press.
Perny, P., & Spanjaard, O. (2005). A preference-based approach to spanning trees and
shortest paths problems. European Journal of Operational Research, 162, 584601.
Refanidis, I., & Vlahavas, I. (2003). Multiobjective heuristic state-space search. Artificial
Intelligence, 145, 132.
Stewart, B. S., & White, C. C. (1991). Multiobjective A*. Journal of the ACM, 38 (4),
775814.
Wu, P.-Y., Campbell, D., & Merz, T. (2009). On-board multi-objective mission planning
for unmanned aerial vehicles. In IEEE Aerospace Conference Proceedings, pp. 110.
Wu, P.-Y., Campbell, D., & Merz, T. (2011). Multi-objective four-dimensional vehicle
motion planning in large dynamic environments. IEEE Transactions on Systems,
Man, and Cybernetics, Part B: Cybernetics, 41 (3), 621634.
Ziebart, B., Dey, A., & Bagnell, J. (2008). Fast planning for dynamic preferences. In ICAPS
2008 - Proceedings of the 18th International Conference on Automated Planning and
Scheduling, pp. 412419.

732

fiJournal of Artificial Intelligence Research 48 (2013) 953-1000

Submitted 09/13; published 12/13

A Constraint Solver for Flexible Protein Models
Federico Campeotto

campe8@nmsu.edu

Dept. Computer Science, New Mexico State University
Depts. Math. & Computer Science, University of Udine

Alessandro Dal Palu

alessandro.dalpalu@unipr.it

Dept. Math. & Computer Science, University of Parma

Agostino Dovier

agostino.dovier@uniud.it

Dept. Math. & Computer Science, University of Udine

Ferdinando Fioretto

ffiorett@cs.nmsu.edu

Dept. Computer Science, New Mexico State University
Depts. Math. & Computer Science, University of Udine

Enrico Pontelli

epontell@cs.nmsu.edu

Dept. Computer Science, New Mexico State University

Abstract
This paper proposes the formalization and implementation of a novel class of constraints aimed at modeling problems related to placement of multi-body systems in the
3-dimensional space. Each multi-body is a system composed of body elements, connected
by joint relationships and constrained by geometric properties. The emphasis of this investigation is the use of multi-body systems to model native conformations of protein
structureswhere each body represents an entity of the protein (e.g., an amino acid, a
small peptide) and the geometric constraints are related to the spatial properties of the
composing atoms. The paper explores the use of the proposed class of constraints to support
a variety of different structural analysis of proteins, such as loop modeling and structure
prediction.
The declarative nature of a constraint-based encoding provides elaboration tolerance
and the ability to make use of any additional knowledge in the analysis studies. The filtering
capabilities of the proposed constraints also allow to control the number of representative
solutions that are withdrawn from the conformational space of the protein, by means of
criteria driven by uniform distribution sampling principles. In this scenario it is possible to
select the desired degree of precision and/or number of solutions. The filtering component
automatically excludes configurations that violate the spatial and geometric properties of
the composing multi-body system. The paper illustrates the implementation of a constraint
solver based on the multi-body perspective and its empirical evaluation on protein structure
analysis problems.

1. Introduction
Constraint Programming (CP) is a declarative programming methodology that has gained
a predominant role in addressing large scale combinatorial and optimization problems. As
a paradigm, CP provides the tools necessary to guide the modeling and resolution of search
problemsin particular, it offers declarative problem modeling (in terms of variables and
constraints), the ability to rapidly propagate the effects of search decisions, and flexible
and efficient procedures to explore the search space of possible solutions. The field of CP
c
2013
AI Access Foundation. All rights reserved.

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

has its roots on the seminal work by Sutherland (1963) in the Sketchpad system, and the
successive efforts in systems like CONSTRAINTS (Sussmann & Steele, 1980) and ThingLab
(Borning, 1981). Over the years, CP has become a paradigm of choice to address hard search
problems, drawing and integrating ideas from diverse domains, like Artificial Intelligence
and Operations Research (Rossi, van Beek, & Walsh, 2006). The declarative nature of
CP enables fast and natural modeling of problems, facilitating not only development, but
the rapid exploration of different models and resolution techniques (e.g., modeling choices,
search heuristics).
In recent years, several research groups have started appreciating the potential of constraint programming within the realm of Bioinformatics. The field of Bioinformatics presents
a number of open research problems that are grounded in critical exploration of combinatorial search space, highly suitable to be manipulated through constraint-based search.
Constraint methodologies have been applied to analyze DNA sequences for instance, to
locate Cis-regulatory elements (Guns, Sun, Marchal, & Nijssen, 2010), to DNA restriction
maps construction (Yap & Chuan, 1993), and to pair-wise and multiple sequence alignment (Yang, 1998; Yap, 2001; Tsai, Huang, Yu, & Lu, 2004). Constraint methodologies
have been applied to biological networks (Corblin, Trilling, & Fanchon, 2005; Larhlimi &
Bockmayr, 2009; Ray, Soh, & Inoue, 2010; Gay, Fages, Martinez, & Soliman, 2011; Gebser,
Schaub, Thiele, & Veber, 2011) and to other biological inference problems, such as Haplotype inference (Graca, Marques-Silva, Lynce, & Oliveira, 2011; Erdem & Ture, 2008), and
phylogenetic inference (Erdem, 2011).
A particular area of Bioinformatics that has witnessed an extensive use of CP techniques
is the domain of structural biologyi.e., the branch of molecular biology and biochemistry
that deals with the molecular structure of nucleic acids and proteins, and how the structure
affects behavior and functions. Constraint Programming has progressively gained a pivotal
role in providing effective ways to explore the space of conformations of macromolecules,
to address problems like secondary and tertiary structure prediction, flexibility, motif discovery, docking (Backofen, Will, & Bornberg-Bauer, 1999; Krippahl & Barahona, 2002;
Thebault, de Givry, Schiex, & Gaspin, 2005; Dal Palu, Dovier, & Pontelli, 2007; Mann
& Dal Palu, 2010; Shih & Hwang, 2011; Krippahl & Barahona, 2005; Dal Palu, Spyrakis,
& Cozzini, 2012b; Chelvanayagam, Knecht, Jenny, Benner, & Gonnet, 1998; Yue & Dill,
2000). Two comprehensive surveys on the use of constraint-based methods in structural
Bioinformatics have been recently proposed (Dal Palu, Dovier, Fogolari, & Pontelli, 2012a;
Barahona & Krippahl, 2008).
Our focus in this work is on the use of constraint-based technology to support structural
studies of proteins. Proteins are macromolecules of fundamental importance in the way they
regulate vital functions in all biological processes. Their structural properties are critical in
determining the biological functions of proteins (Skolnick, Fetrow, & Kolinski, 2000; Baker
& Sali, 2001) and in investigating protein-protein interactions, which are central to virtually all cellular processes (Alberts, Johnson, Lewis, Raff, Roberts, & Walter, 2007). We
refer to the Protein Structure Prediction (PSP) problem as the problem of determining the
tertiary structure of a protein from knowledge of its primary structure and/or from knowledge of other structures (e.g., secondary structure components, templates from homologous
proteins). The PSP problem is also often broken down to specialized classes of problems
related to specific aspects of the tertiary structure of a protein, such as side-chain geometry
954

fiA Constraint Solver for Flexible Protein Models

prediction (Dunbrack, 2002), loop modeling prediction (Go & Scheraga, 1970; Xiang, Soto,
& Honig, 2002; Rufino, Donate, Canard, & Blundell, 1997; Soto, Fasnacht, Zhu, Forrest, &
Honig, 2008), and protein flexibility investigation (Bennett & Huber, 1984).
All these classes of problems share common rootsthe need to track the possible conformations of chains of amino acids. The variations of the problem relate to factors like the
length of the chain being considered (from short peptides in the case of loop modeling to
entire proteins in the general PSP case) and the diverse criteria employed in the selection
of the solutions, as, for instance, the lowest basin of the effective energy surface, composed
by the intra-molecular energy of the protein plus the solvation free energy (Karplus &
Shakhnovich, 1992; Lazaridis, Archontis, & Karplus, 1995).
Modeling the variability of a protein chain involves many degrees of freedom which are
needed to represent different protein conformations. Tracking this variability requires the
exploration of a vast conformational space. Model simplifications can be adopted to reduce
such computational cost, for instance backbone-only models represent only the backbone of
proteins, the side-chain representation could be simplified to a single central point (centroid)
describing its center of mass, or one can adopt approximated representation of the space
though lattice models.
Nevertheless, even under strong simplifications, the search space remains intractable
and prevents the use of brute-force search methods in the space of possible conformations
(Crescenzi, Goldman, Papadimitriou, Piccolboni, & Yannakakis, 1998).
Constraint programming methodologies have found natural use in addressing PSP and
related problemswhere structural and chemical properties have been modeled in terms
of constraints over spatial positions of atoms, transforming the search of conformations
into a constraint satisfaction/optimization problem. The proposed approaches range from
pure ab initio methods (Backofen et al., 1999; Dal Palu et al., 2007) to methods based on
NMR data (Krippahl & Barahona, 1999) to methods based on fragments assembly (Dal
Palu, Dovier, Fogolari, & Pontelli, 2010). In spite of all these efforts, the design of effective
approaches to filter the space of conformations and lead to a feasible search remains a
challenging and open problem.
In this work we present a constraint solver targeted at modeling a general class of protein
structure studies. In particular our solution is suitable to address protein structure analysis
study, requiring the generation of a set of unbiased sampled diverse conformations which
satisfy certain given restraints. One of the unique features of the solution presented in this
work is its capability to generate a uniformly distributed sampling of target protein regions
among a given portion of Cartesian space and with selected granularityaccounting both
for spatial and rotational properties.
We abstract the problem as a general multi-body system, where each composing body is
constrained by means of geometric properties and it is related to other bodies through joint
relationships. Each body can represent an entity in the protein, such as an individual amino
acid or a small peptide (e.g., a protein fragment). Bodies relate to the spatial positions and
organization of individual atoms composing it.
The view of the exploration of protein structures as multi-body systems suggests a number of different constraints, that can be used to model different classes of structural studies
and applied to filter infeasible (or unlikely) conformations. We propose an investigation of
several classes of constraints, in terms of both their theoretical properties and practical use
955

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

for filtering. Particular emphasis is given to the Joined-Multibody (JM) constraint, whose
satisfaction we prove to be NP-complete. Realistic protein models require the assembly of
hundreds of different body versions, making the problem intractable. We study an efficient
approximated propagator, called JM filtering (JMf), that allows us to efficiently compute
classes of solutions, partitioned by structural similarity and controlled tolerance for error.
This perspective is novel and holds strong potential. The structural problems we are investigating are computationally intractable; the use of global constraints specifically designed
to meet their needs enables a more effective exploration of the search space and a greater
potential for effective approximations.
The multi-body model provides an interesting perspective in exploring the space of
conformationswhile the actual search operates on discrete sets of alternatives (e.g., sets of
fragments), the filtering process avails of reasoning processes that operates with continuous
domain; this allows the propagation and filtering to be effective.
The proposed multi-body constraints and filtering techniques constitute the core of the
resolution engine of FIASCO (Fragment-based Interactive Assembly for protein Structure
prediction with Constraints), an efficient C++-based constraint solver. We demonstrate
the flexibility and efficiency of FIASCO by using its engine to model and solve a class
of problems derived from loop modeling instances. Throughout the paper we show the
ability of FIASCO of providing a uniform and efficient modeling platform for studying
different structural properties (that have been, so far, addressed only using significantly
distinct methods and tools). The declarative nature of constraint-based methods supports
a level of elaboration tolerance that is not offered by other frameworks for protein structure
prediction, facilitating the integration of additional knowledge in guiding the studies (e.g.,
availability of information about secondary structure elements).
The rest of the paper is organized as follows. In Section 2, we provide a high-level
background on the biological and chemical properties of proteins and review the most commonly used approaches to address structural studies. In Section 3, we develop the constraint
framework for dealing with fragments and multi-body structures. Section 4 describes the
implementation of the constraints and their propagation schemes in the FIASCO system.
In Section 5 we report the experimental results from using FIASCO on a collection of
benchmarks on loop modeling. Section 6 provides some concluding remarks.
A preliminary version of the research pursued in this paper was presented (Campeotto,
Dal Palu, Dovier, Fioretto, & Pontelli, 2012). While the work of Campeotto et al. focused
on one new class of constraints targeting the problem of loop closure, the work presented
in this paper provides a comprehensive constraint system, focused on modeling structural
protein properties and investigating different types of problems (e.g., structure prediction,
studies of flexibility). The present manuscript includes also a more precise and detailed
formalization and a more extensive experimentation and comparison.

2. Background, General Context, And Related Work
In this section we will briefly review some basic Biology notions, introduce the problems we
are tackling in this paper and refer to a selection of the related literature.
956

fiA Constraint Solver for Flexible Protein Models

H

side
chain

N

C

H

H

N
C'

H
C

O
C'
side
chain

O

Figure 1: A schematic sequence of two amino acids showing the amino acid backbone and
their side chains. The arrow from C 0 to N denotes the peptidic bond.
2.1 General Background
A protein is a molecule made of smaller building blocks, called amino acids. One amino acid
can be connected to another one by a peptidic bond. Several amino acids can be pairwise
connected into a linear chain that forms the whole protein. The backbone of a protein, as
illustrated in Figure 1, is formed by a sequence of N C C 0 atoms contained in each amino
acid. The backbone is rather flexible and it allows a large degree of freedom to the protein.
Each amino acid is characterized by a variable group of atoms that influences the specific
physical and chemical properties. This group, named side chain, ranges from 1 to 18 atoms
and connects to the C atom of each amino acid. There are 20 kinds of amino acids found
in common eukaryotic organisms.
Proteins can be made of 10 up to 1, 000 amino acids, while an average globular protein
is about 300 amino acids long. Each amino acid contains 724 atoms, therefore the number
of atoms and arrangements in the space can grow very easily beyond any computational
power. Since the beginning of protein simulation studies, different algorithms for exploring the conformations have been devised, such as molecular dynamics, local search, Monte
Carlo, genetic algorithms, constraint approaches, as well as different geometric representations (Neumaier, 1997).
In the literature, several geometric models for proteins have been proposed. One choice
that influences the quality and the complexity of computational approaches is the number
of points that describe a single amino acid.
The simplest representation is the one where each amino acid is represented by one
point, typically the C atom, given its robust geometric property: the distance between the
C atoms of two consecutive amino acids is preserved with a low variance (roughly 3.81A).
Usually, volumetric constraints are enforced over those points, in order to simulate the
average occupancy of each amino acid. This representation can be visualized as a chain of
beads that can be moved in the space.
More refined representation models store some (or all) the points of the backbone, plus
a centroid of mass (CG) that represents the whole side chain that connects to the C atom.
In these models, each amino acid is described by different C CG distances and CG volumes.
The centroid is an approximation of the side-chain flexibility and allows for more refined
energetic models, while the number of points to be taken care of is still low. In this paper

957

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure 2: The native structure of intact influenza virus M1 protein (indexed as 1EA3
in the PDB) modeled as full atom, with the 5@ model, and with the simple C C model
(from left to right). The secondary structures (-helices) are emphasized.

Figure 3: Amino acid concatenation in the 5@ model
we use a particular case of these simplified models, the 5@ model, described precisely
below. This is a particular instance of coarse-grained protein models (Clementi, 2008;
Shehu, 2010). At the end of the spectrum, each atom in the amino acid is represented by
one point. This representation is the most accurate, and at the same time allows for the
most accurate energetic considerations. The drawback is that the computational demand
for handling backbone and side-chain flexibility increases significantly.
In Figure 2 we report three representations for the same protein.
In this paper we select the intermediate representation for amino acids where the atoms
N, C , C 0 of the backbone and the centroid of the side chain (CG) are accounted for. We
also include an oxygen (O) atom attached to the C 0 atom, because this atom together with
the C 0 and N identifies a triangle that is chemically stable along the backbone and it is used
for the assembly of amino acids (see below for a complete formalization). The position of
the two H atoms in the backbone can be deduced by the position the other atoms and we
will not deal with them explicitly. In conclusion, we deal with 5 atomic elements per amino
acid: the 4 atoms N C C 0 O and the centroid CG. We briefly refer to this representation as to
the 5@ model. Figure 3 illustrates how these atoms are involved in the concatenation of
two consecutive amino acids. Inter-atomic distances between consecutive atoms are fixed
due to their chemical bonds; thus, the differences between these structures are identified
by the differences between the angles involved. It is common to find substructures of a

958

fiA Constraint Solver for Flexible Protein Models

protein where consecutive amino acids are arranged according to repeated and characteristic
patterns. This property is found in almost every protein; we refer to these typical patterns
as secondary structure elements. The most common examples are -helices and -sheets
(see Figure 2).
2.2 Context Of The Proposed Work
In this paper we present a tool for assembling and reasoning about amino acids in the
space. As in other similar approaches (e.g, Simons, Kooperberg, Huang, & Baker, 1997),
the system relies on a set of admissible elementary shapes (or fragments) that represents
the spatial dictionary of arrangements for every part of a protein.
Each element of the dictionary is general enough to describe the specific atomic structure
of either a single amino acid or a longer sequence (even hundreds of amino acids long). For
each amino acid sequence, several alternative arrangements are expected to populate the
database, so that to offer various hypothesis about the local shape of the sequence. The
protein is partitioned into contiguous fragments that can be arranged according to one of
the possible shapes recorded in the database.
A sequence of amino acids is free to rotate its bonds in the space (typically two degrees
of freedom along the backbone and several others along the side chain); however, due to
chemical properties and physical occupancy that are specific to the types of amino acids
involved and the surrounding environment, some arrangements are impossible and/or unlikely. The core assumption in assembling approaches is to rely on a statistical database of
arrangements to describe local and feasible behavior, in order to direct the search to candidates that have high probability and are energetically favorable. The presence of multiple
candidate fragments for every part of the protein requires a combinatorial search among the
possible choices that, once assembled together, leads to alternative putative configurations
for the protein. The search process is in charge of verifying the feasibility of each assembly,
since the combination of local arrangements could generate a non-feasible global shape, e.g.,
one that leads to a spatial clash between atoms from different fragments. If one (or more)
fragment is described by one single arrangement, that part of the protein is rigidly imposed.
This particular degenerate case can be exploited to describe rigid parts of the protein. A
specific combination of fragment length and number of instances for each fragment determines the type of protein problem being modeled. We can range from complete backbone
flexibility (fragments made of hundreds of choices for each amino acids) to secondary structure - loop models (interleaving of longer fragments modeling helices/-strands and shorter
fragments).
The library of fragments is usually derived from the content of the Protein Data Bank
(PDB, www.pdb.org) that contains more than 96,000 protein structures. The design adopted
in our study is parametric on the choice of the library of fragments to use. For example,
our experiments use a library of fragments derived from a subset of the PDB known as
top-500 (Lovell, Davis, Arendall, de Bakker, Word, Prisant, Richardson, & Richardson,
2003), which contains non redundant proteins and preserves statistical relevance. Alternative libraries of fragments can be obtained through the use of sophisticated protein database
search algorithms, such as FREAD (Choi & Deane, 2010). We retrieve information depending on the specific amino acid sequence, since local properties greatly influence the typical

959

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

arrangements observed. Moreover, we build libraries for different sequences lengths h, even
if for longer sequences the statistical coverage becomes weak. Nevertheless, Micheletti, Seno,
and Maritan (2000) conjectured that a relatively small set of fragment shapes (a few dozens)
of length 5, is able to describe virtually any protein. Handl, Knowles, Vernon, Baker, and
Lovell (2012) demonstrate how the size and the structure of the search space is affected
by the choice of the fragment length and how this can be used to optimize the search process. Similar considerations have been explored by others (Hegler, Latzer, Shehu, Clementi,
& Wolynes, 2009). Recent work show how to efficiently build such dictionaries (Fogolari,
Corazza, Viglino, & Esposito, 2012). These models can be easily accommodated into our
framework.
Each considered sequence is associated to several configurations of 5@ models, placed
according to a standardized coordinate system. In this activity, we also consider the C 0 O
group of the preceding amino acid and the N atom of the following amino acid. This
extra information is needed for fragments combination, assuming that the fragment will
be connected by two peptidic bonds. Therefore, for a specific sequence, we store all the
occurrences of
C 0 O N C C 0 O N
| {z }
h times
and relative positions. In order to reduce the impact of the specific properties of the
database used, we cluster this set in such a way that if two fragments have a RMSD1 less
than a given threshold, just one of them is stored. For example, for length h = 1 and a
RMSD threshold of .2A, we can derive a fragment database of roughly 90 fragments per
amino acid.
The CG information is added later using statistical considerations about side-chain mobility, that are not accounted for during the clustering described above (Fogolari, Esposito,
Viglino, & Cattarinussi, 1996).
2.3 Protein Structure Prediction
In the protein structure prediction problem, the sequence of amino acids composing a protein (known as the primary structure) is given as input; the task is to predict the three
dimensional (3D) shape (known as the native conformation or tertiary structure) of the
protein under standard conditions.
The common assumption, based on Anfinsens work (1973), is that the 3D structure
which minimizes some given energy function modeling the atomic force fields, is the candidate that best approximates the functional state of a protein. In such setting, the choice
of the number of atoms used to represent each amino acid controls the quality and the
computational complexity.
Moreover, the spatial domains where the proteins points (e.g., atoms, centroids) can
be placed have an impact on the type of algorithms and search that can be performed.
The domain can be either continuous, often represented by floating point coordinates, or
discrete, often derived from a discretization of the space based on a crystal lattice structure.
1. The Root Mean Square Deviation captures the overall similarity in space of corresponding atoms, by
performing an optimal roto-translation to best overlap the two structures.

960

fiA Constraint Solver for Flexible Protein Models

Once the geometric model has been determined, it is necessary to introduce an energy
function, mostly based on the atoms considered and their distances. In the structure prediction problem, the energy function is used to assign a score to each geometrically feasible
candidate; the candidate with the optimal score represents the solution of the prediction
problem.
Let us briefly review some popular approaches to this problem, with a particular emphasis on solutions that rely on constraint programming technology.
The natural approach of investigating protein conformations through simulations of
physical movements of atoms and molecules is, unfortunately, beyond the current computational capabilities (Jauch, Yeo, Kolatkar, & Clarke, 2007; Ben-David, Noivirt-Brik, Paz,
Prilusky, Sussman, & Levy, 2009; Kinch, Yong Shi, Cong, Cheng, Liao, & Grishin, 2011).
This has originated a variety of alternative approaches, many based on comparative modelingi.e., small structures from related protein family members are used as templates to
model the global structure of the protein of interest (Jones, 2006; Fujitsuka, Chikenji, &
Takada, 2006; Simons et al., 1997; Lee, Kim, Joo, Kim, & Lee, 2004; Karplus, Karchin,
Draper, Casper, Mandel-Gutfreund, Diekhans, & Source., 2003). In these methods, often
referred to as fragments assembly, a protein structure is assembled using small protein subunits as templates that present relevant sequence similarities (homologous affinity) w.r.t.
the target sequence.
In the literature, Constraint Programming (CP) techniques have shown their potential:
the structural variability of a protein can be modeled as constraints, and constraint solving
is performed in order to deduce the optimal structure (Backofen & Will, 2006; Barahona
& Krippahl, 2008; Dal Palu, Dovier, & Fogolari, 2004; Dal Palu et al., 2010). CP has
been used to provide approximated solutions for ab-initio lattice-based modeling of protein
structures, by using local search and large neighboring search (Shmygelska & Hoos, 2005;
Dotu, Cebrian, Van Hentenryck, & Clote, 2011); exact resolution of the problem on lattice
spaces using CP, along with with clever symmetry breaking techniques, has also been investigated (Backofen & Will, 2006). These approaches solve a constraint optimization problem
based on a simple energy function (HP). A more precise energy function has been used
by Dal Palu et al. (2004, 2007), where information on secondary structures (i.e., -helices,
-sheets) is also taken into consideration. Due to the approximation errors introduced by
lattice discretization, these approaches do not scale to medium-size proteins. Off-lattice
models, based on the idea of fragment assembly, and implemented using Constraint Logic
Programming over Finite Domains, have been presented (Dal Palu et al., 2010; Dal Palu,
Dovier, Fogolari, & Pontelli, 2011), and applied not only to structure prediction but also
to other structural analysis problems. For instance, Dal Palu et al. (2012b) use this approach to generate sets of feasible conformations for studies of protein flexibility. The use
of CP to analyze NMR data and the related problem of protein docking has also been
investigated (Barahona & Krippahl, 2008).
In the context of ab-initio prediction, a recent work (Olson, Molloy, & Shehu, 2011)
has shown that increasing the complexity of the conformational search spaceby using
a more refined fragment libraryin combination with a sampling strategy, enhances the
generation of near-native structure sets. The work of Shehu (2009) and Molloy, Saleh, and
Shehu (2013) illustrates various enhancement the fragment-based assembly process leading
to faster computations and an improved sampling of the conformation spacee.g., using
961

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

tree-based methods inspired from motion planning to guarantee progress towards minimal
energy conformations while maintaining geometrically separate conformations. In terms of
energy landscape, the native state has generally lower free energy than non-native structures,
but it is extremely difficult to locate. Hence, a targeted conformational sampling may aid
protein structure prediction in that different near-native structure can be used to guide
the search; several schemes based on Monte Carlo movements in sampling conformation
space through fragments assembly have been proposed (Shmygelska & Levitt, 2009; Xu &
Zhang, 2012; Debartolo, Hocky, Wilde, Xu, Freed, & Sosnick, 2010). Methods based on
non-uniform probabilistic mass functions (derived from previously generated decoys) have
been proposed to aid in this problem (Simoncini, Berenger, Shrestha, & Zhang, 2012).
Sampling, however, remains a great challenge for protein with complex topologies and/or
large sizes (Kim, Blum, Bradley, & Baker, 2009; Shmygelska & Levitt, 2009).
It is widely accepted that proteins, in their native state, should be considered as dynamic
entities instead of steady rigid structures. Indeed, in recent years the research focus has
shifted towards prediction schemes that take into account the non-static nature of proteins,
supported by recent observations based on magnetic resonance techniques. Processes such
as enzyme catalysis, protein transport and antigen recognition rely on the ability of proteins
to change conformation according to the required conditions. This dynamic nature can be
visualized as a set of different structures that coexist at the same time. The generation
of such sets that capture non-redundant structures (in pure geometric terms) is a great
challenge (Kim et al., 2009). Robotics and inverse kinematics methods have been extensively
explored both in sampling proteins conformational space (Zhang & Kavraki, 2002; Cortes
& Al-Bluwi, 2012) and for molecular simulations (Al-Bluwi, Simeon, & Cortes, 2012; Moll,
Schwarz, & Kavraki, 2007; Noonan, OBrien, & Snoeyink, 2005; Kirillova, Cortes, Stefaniu,
& Simeon, 2008).
A motivation for our work is to provide the ability of generating a protein set that
contains optimal and sub-optimal candidates, in order to capture dynamic information
about the behavior of a protein. A desirable property is that the conformations returned
in the pool are sufficiently diverse and uniformly distributed in the 3D space.
2.4 Protein Loop Modeling
The protein loop modeling problem is a restricted version of the structure prediction problem. We will use this problem as a working example in the remaining part of the paper.
In this context, the protein structure is already partially defined, e.g., a large number of
atoms are already placed in the space. Usually, this common scenario derives from an Xray crystallography analysis, where the spatial resolution of atoms degenerates in presence
of some regions of the protein that are exposed on the surface and presents an increased
instability. Since a crystal contains several copies of a protein in order to perform the measurement, such regions appear as more fuzzy, and therefore the placement of atoms in these
regions may be ambiguous. Usually, these regions, referred to as loops, are not involved in
secondary structures, which are instead more stable. When dealing with homology modeling, the same protein found in another organism, typically shows some variations in the
sequence due to evolution, especially in the loop regions, since they are less essential for
protein stability and functionality. Starting from an homologous protein structure, usually

962

fiA Constraint Solver for Flexible Protein Models

loops need to be recomputed with a specialized loop modeling approach and the use of
minimization techniques.
The length of a loop is typically in the range of 2 to 20 amino acids; nevertheless,
compared to secondary structures, the flexibility of loops produces very large, physically
consistent, conformation search spaces. Constraints on the mutual positions and orientations (dihedral angles) of the loop atoms can be deduced and used to simplify the search.
Such restrictions are defined as the loop closure constraints. In Figure 2, we have a (simple)
possible scenario where two macro-structures (two helices) are connected by a loop. In this
setting, we can assume to know the position of the two helices, while the loop atoms are to
be determined.
A procedure for protein loop modeling typically consists of 3 phases: sampling, filtering,
and ranking (Jamroz & Kolinski, 2010). Sampling is commonly based on a loop candidate generation, using dihedral angles sampled from structural databases (Felts, Gallicchio,
Chekmarev, Paris, Friesner, & Levy, 2008), and subsequent candidate modification in order
to satisfy the loop closure constraints. These conformations are checked w.r.t. the loop constraints and the geometries from the rest of the structure, and the loops that are detected
as physically infeasible, e.g., causing steric clashes, are discarded by a filtering procedure.
Popular methods used for loop modeling include the Cyclic Coordinate Descent (CCD)
method (Canutescu & Dunbrack, 2003), the algorithms based on inverse kinematics (Kolodny,
Guibas, Levitt, & Koehl, 2005; Shehu & Kavraki, 2012), the Self-Organizing (SOS) algorithm (Liu, Zhu, Rassokhin, & Agrafiotis, 2009), which can simultaneously satisfy loop
closure and steric clash restrictions by iteratively superimposing small fragments (amide
and C ) and adjusting distances between atoms, and the Wriggling method (Cahill, Cahill,
& Cahill, 2003), that employs suitably designed Monte Carlo local moves to satisfy the loop
closure constraints. Multi-method approaches have also been proposede.g., Lee, Lee,
Park, Coutsias, and Seok (2010) propose a loop sampling method which combines fragment
assembly and analytical loop closure, based on a set of torsion angles satisfying the imposed
constraints. Ab initio methods (Rapp & Friesner, 1999; Fiser, Do, & Sali, 2000; Jacobson,
Pincus, Rapp, Day, Honig, Shaw, & Friesner, 2004; Spassov, Flook, & Yan, 2008; Deane
& Blundell, 2001; Felts et al., 2008; Xiang et al., 2002) and methods based on templates
extracted from structural databases (Choi & Deane, 2010) have been explored.
Finally, a ranking stepe.g., based on statistical potential energy, like in DOPE (Shen
& Sali, 2006), DFIRE (Zhou & Zhou, 2002), or the one proposed in Fogolari et al. (2007),
is used to select the best loop candidates.
The sampling and filtering procedures should work together and direct the search towards structurally diverse and admissible loop conformations, in order to maximize the
probability of including a candidate close to the native one and to reduce the time needed
to analyze the candidates. Our work is motivated by the need of controlling the properties of the resulting set of candidates. In particular, we model structural diversity both in
distance and orientation of the backbone and make the sampling phase guided by the loop
constraints.
Fragment-based assembly methods have also been investigated in the context of loop
modeling (Lee et al., 2010; Zhang & Hauser, 2013). Shehu and Kavraki (2012) review in
great detail loop modeling techniques.

963

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure 4: On the left: two fragments B1 (light grey) and B2 (dark grey) such that
points(B1 ) = ((0, 0), (1, 0), (1, 1), (2, 1)) and points(B2 ) = ((4, 0), (3, 0), (3, 1), (4, 1), (4, 2)).
The arrows address their initial points. On the right: observe that by rotating B2 of 90 degrees and then translating it by -3 units on the x-axis, the last three points of B1 (last(B1 ))
and the first three points of B2 (first(B2 )) perfectly overlap. Thus, end(B1 ) _ front(B2 ).

3. Constraint Solving With 3D Fragments
We assume the reader to have familiarity with the basic principles of constraint programming and constraint satisfaction problems (CSP); the reader is referred, e.g., to the Handbook of Constraint Programming (Rossi et al., 2006). In this Section, we introduce the
formalization of an effective solution to tackle practical applications concerning with the
placement of 3D fragments. Such applications are described as combinatorial problems,
modeled as a set of variables, representing the entities the problem deals with, and a set of
constraints, representing the relationships among the entities. In the context of a constraint
programming system, variables and constraints are adopted to provide a solution for the
CSP, that is, an assignment to the variables that satisfies all the constraints. We extend this
concept by enabling the constraint solver to find a representative solution for the CSP that
satisfies some additional properties expressed among the variables of the whole solution set.
3.1 Some Terminology
A fragment B is composed of an ordered list of at least three (distinct) 3D points, denoted
by points(B). The number of points of a fragment is referred to as its length. The front- and
end-anchors of a fragment B, denoted by front(B) and end(B), are the two lists containing
the first three and the last three points of points(B). With B(i) we denote the i-th point
of the fragment B. For two ordered lists of points p~ and ~q, we write p~ _ ~q if they can
be perfectly overlapped by a rigid coordinate translation and/or rotation (briefly, a rototranslation)see Figure 4 (let us assume the z coordinate is 0 for all points and omitted
for simplicity).
A non-empty set of fragments with the same length is called a body. A body can be
used to model a set of possible shapes for a sequence of points. We say that a body has
length k if each fragment it contains has length k.
A multi-body is a sequence S1 , . . . , Sn of bodies.

964

fiA Constraint Solver for Flexible Protein Models

Figure 5: From left to right: the body S1 composed by an unique fragment, and the bodies
S2 and S3 composed by two fragments each. Arrows address the initial points of fragments.
~ = S1 , S2 , S3 constitutes a multi-body. In the rightmost
All the three bodies have length 4. S
figure we report the spatial shapes associated to the four rigid bodies that can be obtained
~ One of them is identified by full lines, the other three by dashed
from the multi-body S.
lines. Observe that the rigid body identified by ((0, 0), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0)) can
be obtained by a rotation of 180 degrees of the fragment ((2, 0), (3, 0), (3, 1), (4, 1)) of S2 on
the x axis (flipping) and by a translation of 1 units on x and of +1 units on y. Observe
moreover that the rigid body identified by ((0, 0), (1, 0), (1, 1), (2, 1), (2, 0), (1, 0)) contains
the same point (1, 0) twice.
~ = S1 , . . . , Sn , a rigid body from S
~ is a sequence of fragments
Given a multibody S
B1 , . . . , Bn , where Bi  Si for i = 1, . . . , n and end(Bi ) _ front(Bi+1 ), for all i = 1, . . . , n1.
A rigid body is uniquely identified by the sequence B1 , . . . , Bn ; however, when consecutive
fragments are overlapped, the rigid body can be alternatively identified by a list of points
that form a spatial shape. In Figure 5 we report examples of bodies, multi-bodies, and rigid
bodies. As in the previous example, we assume that the z coordinate is 0 for all points.
Remark 3.1 (Working Example) These concepts are related to the loop-modeling problem. Points are atoms. A fragment is a spatial shape of some atoms. If the last three atoms
of one fragment overlap with the first three atoms of another fragment, we can join them.
A body is a set of admissible shapes for a given list of atoms. A multi-body S1 , . . . , Sn is
a sequence of these elements, corresponding to a sequence of atoms (of amino acids). The
idea is that the last three atoms of a body Si are the same as the first three of the successive
body Si+1 . A rigid body is a possible complete shape of those atoms, provided the last three
atoms of the fragment selected in the set Si overlap with the first three atoms of the fragment
selected in Si+1 .
The overlapping points end(Bi ) and front(Bi+1 ) constitute the i-th joint of the rigid
body. The number of rigid bodies that can be obtained from a single multi-body S1 , . . . , Sn
is bounded by ni=1 |Si |. Figure 6 provides a schematic general representation of a rigid
body.
A rigid body is defined by the overlap of joints, and relies on a chain of relative rototranslations of its fragments. Each points in points(Bi ) is therefore positioned according
to the (homogeneous) coordinate system associated to a fragment Bi1 . Note that once
the reference system for B1 is defined, the whole rigid body is completely positioned.2 The
2. With the exception of the case where all points of a joint are collinear. Points p1 , . . . , pn , with n  3 are
collinear if the points p3 , p4 , . . . , pn belongs to the straight line containing the two points p1 and p2 .

965

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure 6: A schematic representation of a rigid body. The joints connecting two adjacent
fragments are emphasized. The points in points(B) of each fragment are represented by
circles. Each fragment extends from the first point of a joint to the last point of the
successive joint.
relative positions of two consecutive fragments Bi1 and Bi of a rigid body (2  i  n) can
be defined by a transformation matrix Ti  R44 . Each matrix depends on the standard
Denavit-Hartenberg parameters (Hartenberg & Denavit, 1995) obtained from the start and
end of the fragmentsthe reader is referred to the work of LaValle (2006) for details. We
denote the product T1  T2  . . .  Ti  (x, y, z, 1)T by Ti (x, y, z).
Let us analyze the first matrix T1 . The fragment B1 can be forced to start in a given
point and oriented in a given way; in this case the matrix T1 defines the roto-translation
of B1 fulfilling these constraints. In the absence of such constraints, we assume that B1 is
normalized by T1 i.e.,its first point is (0, 0, 0), the second point is aligned along the z axis
and the third belongs to the plane formed by the x and z axes. This orientation is referred
as the reference system 0 .
For i = 1, . . . , n, the coordinate system conversion (x0 , y 0 , z 0 ), for a point (x, y, z) 
points(Bi ) into the coordinate system of B1 , is obtained by:
(x0 , y 0 , z 0 , 1)T = T1  T2  . . .  Ti  (x, y, z, 1)T = Ti (x, y, z)

(1)

Homogeneous transformations are such that the last value of a tuple is always 1.
In the rest of the paper, we focus on the 5@ model; however the proposed formalization
and methods can be used also for other models, e.g., the C C model. In the latter
case, points(Bi ) contains at least 3 amino acids, and the joints are guaranteed to be noncolinear, due to the chemical properties of the backbone. When combining C fragments,
the specific rotational angles of the full-atom backbone are lost and a more imprecise multibody assembly is produced.
A fragment is a body associated to a sequence of amino acids. A fragment for a sequence
of h  1 amino acids is described by a body of length 4h + 3, modeling the concatenation
of the atoms represented by the regular expression: C 0 O(N C C 0 O)h N . In such representation the first and last sequence of C 0 ON atoms coincide with the front- and end-anchor,
respectively, and are employed during the process of assembling consecutive fragments (i.e.,
they are used in the roto-translation).
A discretized R3 space can be represented as a regular lattice, composed of cubic cells
with side length equal to a given parameter k. Each cell is referred to as a 3D voxel
(or, simply, voxel ); we assume that each voxel receives a unique identifier. We denote
with voxel(p, k) the identifier of the voxel that contains the 3D point p in the context of a
discretization of the space using cubes with side length equal to k. This spatial quantization
allows an efficient treatment of the approximated propagation required by some of the
geometric constraints introduced in the following sections.
966

fiA Constraint Solver for Flexible Protein Models

3.2 Variables And Domains
Let us now define the variables adopted to describe the entities of a problem with fragments.
The domain of a variable V is the set of allowable values for V , and it will be denoted by
DV . To deal with fragments placements in the 3D space we adopt two distinct types of
variables:
Finite Domain Variables (FDVs): The domain of a finite domain variable is a finite
set of non negative integer numbers.
Point Variables (PVs): These variables will assume the coordinates of a 3D point in R3 .
Their domains are, initially, 3D boxes identified by two opposite vertices hmin, maxi,
as done in the discrete solver COLA (Dal Palu, Dovier, & Pontelli, 2005, 2007).
Remark 3.2 (Working Example) Following Remark 3.1, FDVs are the identifiers of the
various fragments in a body, while PVs are used to represent the 3D coordinates assigned
to the various structural points (e.g., atoms, centroids) of interest for each molecule being
considered. Clearly, the values of PVs will depend deterministically on the values of FDVs
(and vice-versa).
A variable is assigned if its domain contains a unique value; in the case of point variables,
this happens if DV = hmin, maxi and min = max.
3.3 Constraints
In this section, we formalize the constraints that define the fragments placement, that can
be used to describe Protein Structure problems in the context of fragment assembly.
3.3.1 Distance Constraints
Distance constraints model spatial properties of point variables operating in the 3D space.
Point variables P and Q can be related by a distance constraint of the form
kP  Qk op d

(2)

where k  k is the Euclidean norm, d  R+ and op is  or .
The built-in global constraint alldistant associates a minimal radius di to each point
variable Pi (i = 1, . . . , n) and ensures that spheres surrounding each pair of point variables
do not intersect:
alldistant(P1 , . . . , Pn , d1 , . . . , dn ),
(3)
This constraint is equivalent to the constraints kPi Pj k  di +dj for all i, j  {1, . . . , n}, i <
j. It is used to avoid steric clashes among different atoms (and centroids), which have
different volumes. Checking consistency of the alldistant constraint (given the domains
of the variables Pi ) is NP-complete (Dal Palu, Dovier, & Pontelli, 2010)the proof is based
on an encoding of the bin-packing problem using the alldistant constraint, and holds true
even in this particular setting, where the point variables have intervals of R3 as domains.
Remark 3.3 (Working Example) The alldistant constraint is introduced to avoid clashes
when a rigid body is obtained from the multi-body S1 , . . . , Sn . The distance constraints are
967

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure 7: Fragments are assembled by overlapping the plane R , described by the rightmost
C 0 , O, N atoms of the first fragment (left), with the plane L , described by the leftmost
C 0 , O, N atoms of the second fragment (right), on the common nitrogen atom
useful when some extra information is known (e.g., one might have inferred by biological
arguments that a pair of amino acid should stay within a certain distance).
3.3.2 Fragment Constraint
Fragment constraints relate finite domain variables and point variables. Let us assume we
have a database F of fragments, where F [i] represents the i-th fragment in the database.
Thus, given an FDV variable V , F [V ] denotes the fragment indexed by V when V is
instantiated. The fragments are stored in F as an ordered list of 3D points.
Given a list of point variables P~ , the constraint:
fragment(V, P~ , F )

(4)

states that there exists a roto-translation Rot such that P~ = Rot  F [V ]namely, if V = i
then the list of points P~ should take the form of the fragment F [i]. For simplicity, we
will omit the database F when clear from the context. Intuitively, these constraints ensure
that any fragment choice will reproduce the correct shape for the associated 3D point,
regardless of the space orientation of the fragment. The orientation is determined by the
joined multi-body constraint presented in a following section.
3.3.3 Centroid Constraint
The centroid constraint enforces a relation among four PVs. Intuitively, the first three
of them are associated to the atoms N, C , C 0 of an amino acid and the fourth is related
to the centroid CG. The constraint is parametric w.r.t. the type a of an amino acid and
deterministically establishes the position of CG depending on the position of the other points:
centroid(PN , PC , PC 0 , PCG , a)

(5)

In Figure 7 the centroids are displayed along the backbone as purple circles and labeled
CG. This constraint can be used when the database of fragment contains only full backbone information. The centroid information is used in place of the missing full-atom side
chain. The side-chain centroid is computed by taking into account the average C -side-chain
center of mass distance, the average bend angle formed by the side-chain center-of-massC -C 0 , and the torsional angle formed by the N -C -C 0 -side-center of mass (Fogolari et al.,
968

fiA Constraint Solver for Flexible Protein Models

1996). This abstraction allows us to reduce the number of fragments to consider, removing
fragments that would geometrically conflict with the position of the CG. Consider that a
single side chain may have up to 100 main configurations (rotamers).
3.3.4 Table Constraint
This constraint is used to restrict the assignments of a set of FDVs (representing fragments)
to specific tuples of choices. This is useful when modeling a specific local and collaborative
behavior that involves more than one fragment; for example, this happens when modeling a
secondary structure multiple arrangements of underlying amino acids and/or when specific
approximation strategies are employed.
~ a k-tuple of FDVs. A table (or
Let F be a set of k-tuples of integer values and V
combinatorial) constraint, of the form
~ ,F)
table(V

(6)

~ assumes values restricted to the tuples listed in F , i.e.,
requires that the list of variables V
~
there exists t  F such that V [i] = t[i], with i in 0, . . . , k  1.
Remark 3.4 (Working Example) Going back to the loop-modeling problem, the role of
the fragment constraint is evident: it relates the (IDs of the) selected fragments of a multibody with the 3D positions of the various atoms involved. The centroid constraint is
instead introduced to add the position of the centroid that represents the side chain in the
5@ representation. table constraint is a common constraint in constraint languages and it
is useful when some info on consecutive fragments in a rigid body is known due to external
knowledge.
3.3.5 Joined Multibody Constraint
The Joined Multibody (JM) constraint enforces a relation over a list of FDVs encoding a
multibody. It limits the spatial domains of the various fragments composing the multibody
in order to retain those fragments that assemble properly and that do not compenetrate.
~ V
~ , A,
~ E,
~ i, where:
The joined-multibody (JM) constraint is described by a tuple: J = hS,
~ = S1 , . . . , Sn is a multi-body. Let B = {B1 , . . . , Bk } be the set of all fragments in S,
~
 S
Sn
i.e., B = i=1 Si .
~ = V1 , . . . , Vn is a list of FDVs, with domains DVi = {j : Bj  Si }.
 V
~ = A1 , A2 , A3 , and E~ = E1 , . . . , E3n are lists of sets of 3D points such that:
 A
 A1  A2  A3 is the set of admissible points for front(B), with B  S1 ;
 E3i2  E3i1  E3i is the set of admissible points for end(B), with B  Si , i = 1, . . . , n;
  is a constant, used to express a minimal distance constraint between different point.
~  {1, . . . , |B|} s.t. there exist
A solution for the JM constraint J is an assignment  : V
matrices T1 , . . . , Tn (used in T ) with the following properties:
Domain: For all i = 1, . . . , n, (Vi )  DVi .
Joint: For all i = 1, . . . , n  1, let (a1 , a2 , a3 ) = end(B(Vi ) ) and (b1 , b2 , b3 ) = front(B(Vi+1 ) ),
then it holds that (for j = 1, 2, 3):
Ti (ajx , ajy , ajz ) = Ti+1 (bjx , bjy , bjz )
969

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Spatial Domain: Let (a1 , a2 , a3 ) = front(B(V1 ) ), then T1  aj  Aj  {1}.3 For all i =
1, . . . , n, let (e1 , e2 , e3 ) = end(B(Vi ) ) then
Ti (ejx , ejy , ejz )  E3(i1)+j  {1}
where 1  j  3 and T2 , . . . , Ti (in Ti ) are the matrices that overlap end(B(Vi1 ) ) and
front(B(Vi ) )
Minimal Distance: For all j, ` = 1, . . . , n, j < `, and for all points a  points(B(Vj ) ) and
b  points(B(V` ) ), it holds that:4
kTj (ax , ay , az )  T` (bx , by , bz )k  
It has been proved that establishing consistencyi.e., existence of a solutionof JM
constraints is NP-complete (Campeotto et al., 2012). We have also proved that it remains
NP complete even assuming that all all the fragments of the problem have the same three
atoms with the same spatial position, and that the same holds for the last three atoms (of
course fragments are allowed to contain more than three atoms otherwise the problem is
trivial). The proof is reported in www.cs.nmsu.edu/fiasco/.
Remark 3.5 (Working Example) The JM constraint contains exactly all the ingredients
~ and the corresponding FDs
needed for modeling a loop problem. We have a multi-body S,
~ , we have a set of possible 3D points where the loop starts A
~ and a set of possible 3D
V
~
points where the loop ends E and a weak version of the alldistant constraint between pair of
~
atoms that avoid clashes, the solutions are the (non clashing) rigid bodies that starts in A
~
and ends in E.
Let us observe that the JM constraint does not explicitly forbid spatial positions to PVs
variables (save for the first three and the last three points of the loop). However, these
additional constraints can be explicitly required during domain definition of the PVs variables
used for the encoding.
Remark 3.6 The choice of using three points of overlap resembles the method proposed by
Kolodny, Guibas, Levitt, and Koehl (2005). On the other hand, we should observe that it is
only a technical exercise to modify the JM constraints and so that they allow a parametric
overlap between contiguous fragments.

4. The FIASCO Constraint Solver
We present the overall structure and implementation of a hybrid constraint solver capable
of handling the classes of constraints described in the previous section.
4.1 Constraint Solving
A distinctive feature of FIASCO is the possibility to handle continuous domains at the cost
of keeping a discrete library of choices (finite domain variables). The handling of fragments
allows us to reason about spatial properties in a more efficient and descriptive way than
the pure 3D domain modeling adopted in previous proposals. Moreover, FIASCO allows
3. The product {1} is necessary as we use homogeneous coordinates.
4. Let us observe that this is a weak form of the alldistant constraint where different distances for each
point are allowed. It is, in a sense, closer to the alldifferent constraint.

970

fiA Constraint Solver for Flexible Protein Models

the solver to uniformly sample the search space by means of a spatial equivalence relation
that is used to control the tradeoff between accuracy and efficiency. This is particularly
effective when the finite domains are heavily populated, and is a critical component to
model real-world problems.
The constraint solver builds on the classical prop-labeling tree exploration where constraint propagation phases are interleaved with non-deterministic branching phases used to
explore different value assignments to variables (Apt, 2009). The solver is able to handle
both point variables and finite domain variablesthis is the reason why we refer to it as
an hybrid solver. In particular, the assignments to finite domain variables guide the search;
their values imply assignments of the point variables, that in turn may propagate and reduce
the domains of both point variables and finite domain variables. Moreover, the propagation technique implemented for the JM constraint is not a classical filtering techniqueit
is an approximated technique that we describe later.
The presence of point variables allows, in principle, an infinite number of domain values
in R3 . However, we noted that the information carried by assembling fragments (encoded
by finite domain variables) is much more informative than any complex and demanding
model for 3D continuous space (e.g., Oct-trees, CSG, no-goods). In particular, the direct
kinematics encoded by a JM constraint is able to efficiently identify a set of admissible
regions of a point variable in a fast, approximated, and controlled way. Therefore, the
point variables can be seen as an internal aid to propagation. These variables are updated
during the JM propagation phase and can interact with the JM propagator to prune the
corresponding fragment variables. Distance constraints on point variables are included in a
standard AC3 propagation loop for domains updates.
The other aspect that extends the classical solver structure is the capability of controlling the amount of the search tree to be explored. The search tree contains a large number
of branches that are very similar, from the point of view of the geometric distance between
corresponding point variables. The goal is to produce a subset of feasible solutions that
exhibit significant 3D differences between themselves. This is accomplished by introducing
the possibility to explore a subtree of a given depth, by enumerating a specific and limited
number of branches, rather than following the standard recursion of propagation and expansion. To achieve this behavior, it is necessary to selectively interfere with the standard
recursive call to the solver, and implement a non-deterministic assignment of partial tuples
of finite domain variables. This resembles the implementation of a table constraint, which
is dynamically created during the search. This strategy allows us to significantly reduce
the number of branches explored in the subtree, and produces significant results when the
selection of the branches is controlled by an adequate partitioning function. In this work,
we propose an effective partitioning function based on a measure of 3D similarity for point
variables; this is used to direct the search along specific branches of controlled depth that
are adequately separated by the partitioning function. This is practically realized by
introducing a form of look-ahead, controlled by the JM propagator, that returns a set of
partial assignments as well as the filtered domains for the finite domain variables.
4.1.1 The Hybrid Solver

971

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

~ , P~ , D,
~ C, `)
Algorithm 1 search(V
~ , P~ , D,
~ C, `
Require: V
~ | then
1: if ` > |V
2:
output (P~ )
3:
return
4: end if
5: for each fragment index f in Dv` do
~ , P~ , D)
~ then
6:
if AC-3(C  {v` = f }, V
nm
7:
T
 get table from JM()
8:
if n > 0 then
9:
Non-deterministically select i in 1..n
10:
for j = 1..m do
11:
C  C  {v`+j = T [i][j]}
12:
end for
~ , P~ , D,
~ C, ` + m)
13:
search(V
14:
else
~ , P~ , D,
~ C, ` + 1)
15:
search(V
16:
end if
17:
end if
18: end for
The general structure of the solver is highlighted in Algorithm 1. The solver is designed
~ = v1 , . . . , vn of finite domains variables, together with the domains
to process a list V
Dv1 , . . . , Dvn for them. Intuitively, each domain is a set of indices for the set of fragments.
Moreover, the solver receives a list P~ = p1 , . . . , p5n of 5  n point variables, where the
variables p4i , . . . , p4i+4 are related to the fragment in the domain Dvi . Each point variable
~
pj has, in turn, a spatial domain Dpj . C represents the constraints between elements of V
and P~ . Finally, the solver receives also as input the current level ` in the exploration of
the search tree (set to 1 the first time the procedure is called). For the sake of simplicity,
the choice of variables to be assigned is based on their ordering in the input list (more
sophisticated selection strategies can be easily introduced). When we enter the level `, we
assume that the variables v1 , . . . , v`1 have already been assigned.
~ have already been assigned
Let us briefly describe the algorithm. If all the variables in V
(lines 14), then the search algorithm terminates and returns the computed solution, represented by the values assigned to the variables P~ . Otherwise, we non-deterministically select
a fragment index in the domain of the variable v` and assign it to the variable. Lines 67
indicate the execution of a standard constraint propagation step (using AC-3). If the propagation step fails, then we assume that another non-deterministic choice is made, if possible.
Every reference to a non-deterministic choice in the algorithm corresponds to the creation
of a choice-point that will be the target of backtracking in case of failure (for simplicity,
we assume chronological backtracking). If it succeeds, leading to a possible reduction of
~ then the computation will proceed. A table constraint might be produced
the domains D,
during the propagation of the JM constraint in the AC-3 procedure (see below for details).
If this is the case (lines 89), some (m) variables are non-deterministically assigned with
the values in the table (lines 912), and the search continues with m less variables to be
972

fiA Constraint Solver for Flexible Protein Models

assigned (line 13). If this is not the case, then the search will continue with only one less
variable (v` ) to be assigned (line 15).
A peculiar feature of our constraint solver (not reported in the abstract algorithm just
defined) is that it can be used to avoid the search of solutions too similar to each others.
Let us assume that the 3D space is partitioned in cubic voxels of size k A. Then, given a list
~ and a list of PVs P~ , the user can state:
of FDVs V
~ , P~ , k)
uniqueseq(V

(7)

This constraint forces the solver to prune the search tree in the following way. Given
~ be the variable to be assigned at the next step and
a partial assignment , let v  V
~
p1 , . . . , ph  P the PVs to be consequently instantiated. The constraint ensures that for
any two assignments 1 , 2 extending  to v, p1 , . . . , ph it holds that there exists at least
one i  {1, . . . , h} such that 1 (pi ) and 2 (pi ) do not belong to the same voxel.
4.2 Constraint Propagation
In this section, we discuss the propagation rules associated to the various constraints introduced in Section 3.3; these are applied within the call to the AC-3 procedure (line 6 of
Algorithm 1). The constraint propagation is used to reduce the domain size of the PVs and
FDVs, ensuring constraint consistency. AC-3 is a standard implementation of a fixpoint
propagation loop (Apt, 2009; Rossi et al., 2006).
4.2.1 Joined Multibody Constraint
The JM constraint is a complex constraint that is triggered when the leftmost points involved in the constraint (anchors) are instantiated. The JM propagation (JMf) is based on
the analysis of the distribution in the space of the points involved. The goal of the propagation is to reduce the domains of the FDVs through the identification of those fragments
that cannot contribute to the generation of a rigid body that is compatible with the corresponding Point Variable domains. This can be viewed as a form of hyper-arc consistency
over a set of fragments. Moreover, due to complexity and precision considerations, this
propagator is approximated by the use of a spatial equivalence relation (), that identifies
classes of tuples of fragments; these classes have the property to be spatially different
from one another.
This allows a compact handling of the combinatorics of the multi-body, while a controlled
error threshold allows us to select the precision of the filtering. The equivalence relation
captures those rigid bodies that are geometrically similar, allowing the search to compact
small differences among them.
~ V
~ , A,
~ E,
~ i, along with
The JMf algorithm receives as input a JM-constraint hS,
 A set G of points that are not available for the placement of bodies, and
 The equivalence relation .
For the sake of readability, we assume that the domain information for variables are avail~ , Tab). In this process, the algorithm
able. The algorithm builds a table constraint table (V
makes use of a function  (lines 7 and 8); this function takes as input two lists ~a and ~b of
3D points, and computes the homogeneous transformation to overlap ~b on ~a. A call to
973

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Algorithm 2 The JMf algorithm.
~ V
~ , A,
~ E,
~ , G, 
Require: S,
Ensure: Tab
~ |; Tab = 
1: n  |V


 
T1  start(B)  A1  A2  A3 






 T1  end(B)  E1  E2  E3



2: R1  (B, T1 ) B  S1 , T1 
 p  points(B).q  G. k(T1  p)  qk     





c  C involving p.consistent(c))
3: P1  {T1  end(B) | (B, T1 )  R1 }
4: for each i = 2, . . . , n do
5:
Pi = ; Ri = ;
6:
for each E 
Pi1 /  do

T = (E, start(B))  T 6= fail 






T  end(B)  E3i2  E3i1  E3i 
7:
Ri  Ri  B  Si
p  points(B).q  G. k(T  p)  qk    





c  C involving p.consistent(c))
8:
Pi  {(E, start(B))  end(B) | B  Ri }
9:
end for
10:
compute Pi /  and filter Ri accordingly
11: end for
12: for each representative L of Pn /  do
13:
Tab = Tab  (L)
14: end for
this function will fail if ~a 6_ ~b. For simplicity, the fourth component (always 1) of the
homogeneous transformation is not explicitly reported in the algorithm.
~ |, the algorithm computes the sets Ri and Pi , that will respectively
For i = 1, . . . , n = |V
contain the fragments from Si that can still lead to a solution, and the corresponding allowed
3D positions of their end-points. For each fragment B  Ri+1 we denote with parent(B)
the set of fragments B 0  Ri such that end(B 0 ) _ front(B) via . For each fragment B, we
denote with label(B) the corresponding FD value associated.
In computing/updating Ri and Pi , only fragments that have end-anchors contained in
the bounds E3i2 , E3i1 , E3i are kept. Fragments that would cause points to collapsei.e.,
due to a distance smaller than  from previously placed pointsare filtered out (lines 2 and
7). Moreover, the spatial positions of the points of the first fragment are validated against A
(line 2); finally, we enforce the consistency check of each constraint c  C involving points in
points(B)  Si to retain only those points that can potentially reach the admissible positions
(lines 2 and 7).
~ |  1 iterations (lines 411). First Ri and Pi are computed
The algorithm performs |V
on the basis of the sets of end-anchors of the previous level Pi1 and the starting point of
a selected fragment B, filtering out those that are not overlapping and those that lead to
wrong portions of space (lines 78). The filtering based on  is applied (line 10). During
this step, the set of triples of 3D points Pi is clustered using . A representative of each
equivalence class is chosen (within Pi ) and the corresponding fragment in Ri is identified;
all the other (non-identified) fragments are filtered out from Ri . Let us also note that the

974

fiA Constraint Solver for Flexible Protein Models

filtering based on clustering is not performed for the initial step P1 , as typically this is
already captured by the restrictions imposed by A.
Once the fragments reachable at last iteration are determined and their representatives
selected, we populate the Tab with the set of tuples associated to each representative L.
~ that allows us to overlap the last point to
The function (L) returns the assignments to V
L.
The JMf algorithm is parametric w.r.t. the clustering relation and the function selecting
the representative; they both express the degree of approximation of the rigid bodies to
be built. The proposed clustering relation for loop modeling takes into account two factors: (a) The positions of the end-anchors in the 3D space and (b) The orientation of the
plane formed by the fragments anchor L w.r.t. a fixed reference system 0 adopted by
FIASCO (c.f. Figure 7). This combination of clusterings allows to capture local geometrical
similarities, since both spatial and rotational features are taken into account.
The spatial clustering (a) used is the following. Given a set of fragments, three end
points C 0 ON (end anchors) of each cluster are considered, and the centroid of the triangle
C 0 ON is computed. We use three parameters: kmin , kmax  N, kmin  kmax , and r  R,
r  0. We start by selecting a set of kmin fragments, pairwise distant at least 2r. These
fragments are selected as representatives of an equivalence class for other fragments that fall
within a sphere of radius r centered in the centroid of the representative. This clustering
ensures a rather even initial distribution of clusters, however some fragments may not fall
within the kmin clusters. We allow to create up to kmax  kmin new clusters, each of
them covering a sphere of radius r. Remaining fragments are then assigned to the closest
cluster. The employed technique is a variant of the k-means clustering algorithm called
leader clustering algorithm; it allows a fast implementation and acceptable results.
The orientation clustering (b) partitions the fragments according to their relative orientation of planes R w.r.t. 0 . A plane spatial orientation is described by the Euler angles
, ,  of its frame w.r.t. 0 . This algorithm produces a variable number of partitions depending on . In particular, given a threshold  > 0 there are 3  (360/) possible partitions
describing equal regions on a sphere though the interval (  / 2 ,   / 2 ,   / 2 ). Each
fragment is allotted to the partition determined by .
The final cluster is the intersection of the two partitioning algorithms. This defines an
equivalence relation  depending on kmin , kmax , r, and . The representative selection
function selects the fragment for each partition according to some preferences (e.g., most
frequent fragment, closest to the center, etc.).
Note that for r = 0,  = 360, and kmax unbounded, no clustering is performed and
this would cause the combinatorial explosion of every possible end-anchor on the whole
problem. The spatial error introduced depends on r and . With  = 360, the error
introduced at each step can be bounded by 2r for each dimension. At each iteration the
errors are linearly increased, since a new fragment is placed with an initial error gathered
from previous iterations, thus resulting in a 2nr bound for the last end-anchor. Clearly this
bound is very coarse, and on average the experimental results show better performances.
Similar considerations can be argued for rotational errors, however the intersection of the
two clusterings, provide, in general, a much tighter bound.

975

fiF. Campeotto et al.

Campeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure
8: A graphical
representation
of the propagation
a JM constraint
theconstraint
variables Viover
, . . . , Vthe
i+3 .variables Vi , . . . , Vi+
Figure
9: A graphical
representation
of theofpropagation
of over
a JM
(a) A simultaneous placement of all the elements in the domain of the variable Vi+1 is simulated, by
(a) A simultaneous placement of all the elements in the domain of the variable Vi+1 is simulated,
overlapping each corresponding fragment with the end-anchor of the fragment associated to the element in
overlapping
eachsetcorresponding
fragment
the end-anchor
the fragment
to the element
the domain
of Vi . The
of points Pi+1 is
computedwith
and clustered
using theofrelation
 (pointsassociated
within
the domain
Vieach
. The
set one
of points
Pi+1
is computed
andchosen
clustered
using fragments
the relation  (points with
the dotted
ellipses). ofFor
cluster
fragment
representative
is hence
(highlighted
the dotted
ellipses).
Forcollection
each cluster
one fragment
representative
is hence
(highlighted fragmen
with filled
rightmost
circle). The
of representatives
constitutes
the set Ri+1
(b) Thechosen
previous
step iswith
performed
on the circle).
basis of the
end-anchors
to the fragmentsconstitutes
representatives
ini+1 (b) The previo
filled again
rightmost
The
collectionrelated
of representatives
thechosen
set R
the previous
The filled
box,on
represents
the of
setthe
of points
G that are
not available
the placement
step islevel.
performed
again
the basis
end-anchors
related
to thefor
fragments
representatives chosen
of bodies (for instance due to a distance constraint). and the fragment falling in such area are discarded.
the
previous
level.
The
filled
box,
represents
the
set
of
points
G
that
are
not
available
for the placeme
(c) In the last iteration of the JMf algorithm the set of points Pi+3 is not clustered, but only those that
of
bodies
(for
instance
due
to
a
distance
constraint).
and
the
fragment
falling
in
such
area
are discarde
reach the desired position are retained, for instance the front-anchor associated to the fragment of the next
(c)
In
the
last
iteration
of
the
JMf
algorithm
the
set
of
points
P
is
not
clustered,
but
only
those th
variable, and the sequence of fragments able to lead to such condition (marked by thick
i+3 lines) are selected
to populate
the
table
Tab.
reach the desired position are retained, for instance the front-anchor associated to the fragment of the ne
variable, and the sequence of fragments able to lead to such condition (marked by thick lines) are select
to populate the table Tab.
976

fiA Constraint Solver for Flexible Protein Models

P
||P-Q||d

Q
Figure 9: The effect of a distance constraint ||P  Q||  d propagation. Empty boxes
represent the original PVs domains and the full boxes represent the reduced PVs domains
after the effect of constraint propagation.
4.2.2 Distance Constraints
The propagation of the distance constraints is an approximated technique that reduces the
size of the box domains. We introduce the following operations over PVs box domains of
two variables P and Q that will be used to describe the propagation rule in this and in the
following subsections:
Domain intersection: DP  DQ = hmax(Pmin , Qmin ), min(Pmax , Qmax )i
Domain union: DP  DQ = hmin(Pmin , Qmin ), max(Pmax , Qmax )i
Domain dilatation:
DP + d = hPmin  d, Pmin + di
where max(P, Q) = (max(Px , Qx ), max(Py , Qy ), max(Pz , Qz )), (and similarly for min), and
P + d = (Px + d, Py + d, Pz + d).
Given two point variables P and Q, with domains DP and DQ , respectively, the simplification rule for the constraint ||P  Q||  d updates the domains as follows:
DP = ((DQ + d)  DP )

DQ = ((DP + d)  DQ )

(8)

which ensures that the points in DP and DQ are positioned within an approximation of a
sphere of radius d. The sphere is approximated by considering the box inscribing it (a cube
of side 2d), as illustrated in Figure 9.
The propagation of the constraint ||P  Q||  d is harder as the coarse representation
of the box domains adopted in this work to model PVs does not allow the description of
more complex polyhedron. We hence apply a simple form of bound consistency described
by the following rule:
	
(DP  DQ ) = hl, ui, ||u  l|| < d
 P
	
||P  Q||  d :
D = , DQ = 


that establishes unsatisfiability of the constraint.
977

(9)

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

4.2.3 Fragment Constraint
The propagation a fragment constraints fragment(V, P~ , T ) is exploited during the solution
search to enforce the assembly process of the fragment T [V ] along the point variables
P1 , . . . , Pn of P~ . Recall that DV is the domain of V containing the references {j1 , . . . , jk }
to the database of fragments T .
 P1
	
D = {p1 }, DP2 = {p2 }, DP3 = {p3 }, DV = {j1 , . . . , jk }
~

fragment(V, P , T ) : 
jk
n
^

[
{((p1 , p2 , p3 ), T [f ])  T [f ](i)}
DPi = DPi 


i=1

(10)

f =j1

where ((p1 , p2 , p3 ), T [f ]) is the roto-translation to be applied to overlap the first three
points of the fragment T [f ] with the start-anchor (p1 , p2 , p3 ).
The conjunction in the bottom part of the rule re-evaluates the domains for P1 , P2 , P3 ,
and it may reduce the singleton domains to empty whenever there is no compatible  for
the selected fragment.
4.2.4 Centroid Constraint
When the positions of the atoms N , C and C 0 for an amino acids a are determined, the
propagation algorithm enforces the value for the PV PCG involved in the centroid constraint.
	
 P
D N = {pN }, DC = {pC }, DPC 0 = {pC 0 }
	
centroid(PN , PC , PC 0 , PCG , a) :  P
(11)
D CG = (DPCG  {cg(pN , pC , pC 0 , a)})
where cg(pN , pC , pC 0 , a) is a support function which returns the center of the mass for
the side chain of the amino acid a by considering the points pN , pC , pC 0 , as described in
Sect. 3.3.3.
4.2.5 Some Implementation Details
The proposed solver relies on an efficient C++ implementation, and it is carefully designed
to allow additional tailored solving capability without the need of reshaping the core structures.
The internal representation of the domains of the finite domain variables can be abstracted by two arrays of the same length of the size of the initial domain. One array points
to the values and the other is a Boolean bit-mask that states whether a value is still in the
domain. If all flags are set to 0, the current partial assignment cannot be a part of a solution
of the overall constraint; if exactly one is set to 1, then the variable is assigned to a value.
This representation implies a linear scan of the domains during the propagation but it is
justified by the reasonably small size of the domains of the target application (typically less
than 100 values). The internal representation of the domains for point variables is simply a
pair hmin, maxi that uniquely characterizes a 3D box in R3 . Since these variables are used
mostly in distance constraints, this representation is expressive enough (Oct-trees have been
considered but with no significant advantage).
Point Variables propagation has been described above; these variables are instantiated
after fragment selection.
978

fiA Constraint Solver for Flexible Protein Models

For the management of the uniqueseq property (7) we implemented a dedicated data
structure based on hash tables. Every time a PV is assigned, its value is mapped into a 3D
voxel of fixed size. The 3D grid is implemented via a Hash Table with voxel indexes as keys
and points contained in such voxels as values. All the operations can be performed in O(1)
(amortized complexity).
4.3 One Or More JM Constraints
We briefly describe how we have modeled two problems with FIASCO. The JM constraint
is able to model geometrically assembly of fragments and therefore it is used for every
protein model. A single JM that covers a protein ensures its flexibility, however for long
proteins some computational and precision issues arise. It can be beneficial to model a
protein by multiple JM constraints, e.g. JM (i, j) and JM (j, k) so that the amino acids
from i to j are covered and the JM constraints overlap on a common amino acid. This
practical choice improves the approximate search and allows to increase the number of
different solutions produced. In practice, each protein section handled by a JM constraint
is potentially combined to the different arrangements for the other sections. Therefore, it
is expected that the number of solutions found grows exponentially in the number of JM
constraints. The other JM constraint parameters can be used to control clustering precision
and number of conformations found.

5. Experimental Results
We report on the experimental results obtained with the FIASCO system (available at
http://www.cs.nmsu.edu/fiasco). Experiments are conducted on a Linux Intel Core i7
860, 2.5 GHz, memory 8 GB, machine. The solver has been implemented in C++.
The fragment database adopted is the FREAD database which has been shown to be effective in loop structure prediction (Choi & Deane, 2010). For the parameters analysis 5.1.4
we use a database of fragments of length 1. These fragments are classified by their amino
acid class and their frequency of occurrence over the whole top-500.
We set the system to model the two applications described below. In particular, in
Section 5.1 we analyze the loop modeling scenario and we focus on the performances of JM
filtering by examining the filtering power and computational costs. Next, we compare the
quality of the loop conformations generated, by measuring the RMSD of the proposed loop
with respect to the native conformation. We then present some relationships among the
JM parameters to control quality and efficiency.
In Section 5.2 we show some examples of ab-initio protein structure prediction and we
conclude with a comparison of FIASCO against other constraint solvers, for protein models
that can be described by a common subset of constraints.
5.1 Loop Modeling
The loop modeling problem is formalized by the presence of two known (large) fragments
that are both fixed in the space. A sequence of amino acids of length n is given for connecting
these two parts of the protein. A JM constraint is defined over the sequence, with particular
attention to the starting and ending points that are fixed. The start of the first fragment
979

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure 10: An example of loop computed by our tool
and the end of the last fragment, namely a sequence C 0 ON (initial points) of coordinates
~a = (a1 , a2 , a3 ), and a sequence C 0 ON (final points) of coordinates ~e = (e1 , e2 , e3 ) are
known. There is one caveat about the end points: due to the discrete nature of fragment
assembly, it is unlikely to exactly reach the final points. We accommodate for some errors,
and require that the JM constraint produces results that fall within some threshold from
the corresponding final points.
In Figure 10 we show an Example of loop computed by our tool (the parts of the protein
to be connected are shown on the left and the connecting loop on the right).
Additional spatial constraints about points (e.g. no-good regions determined by presence
of other atoms) are given. The constant  (now  = 1.5A) asserts a minimum distance
between pairs of atoms.
5.1.1 Filtered Search Space And Performances
We selected 30 protein targets from a set of non-redundant X-ray crystallography structures
as done by Canutescu and Dunbrack (2003). We partitioned the proteins into 3 classes
according to their loop region lengths (n = 4, 8, and 12). We model a CSP that uses
fragment assembly to model the loop, in particular using the JM constraint over the loop
region.
To assess the filtering capabilities of FIASCO, we perform an exhaustive search generating all the solution for each of the protein targets. Using a clusterization of 0.2A, a number
of different fragments of length 1 is found for each amino acid (see Fig. 11). The size of
the domains for the corresponding FDVs is bound by 100this is an adequate sampling to
describe a reasonable amino acid flexibility. In those cases where the number of fragments
exceeds 100, the 100 most frequent ones are kept.
This increases the likelihood of generating a loop structure that is similar to the native
one. A loop of length n generates an exponential search space of size bounded by 100n . The
selected variable is the leftmost one. Fragments are selected in decreasing frequency order.
We have imposed a JM constraint for every 4 consecutive amino acids. The clustering
parameters are set as follows: the kmin value is equal to the size of the domains, while we

980

fi100 120 140
80
60
40
0

20

N. of different Fragments

A Constraint Solver for Flexible Protein Models

A

C

D

E

F

G

H

I

K

L

M

N

P

Q

R

S

T

V

W

Y

Amino acids

Figure 11: Number of different fragments (after clustering) per amino acid in the dataset
have used different values for kmax based on loop lengths. The values for r and  are set to
120 and 0.5 in each setting. A summary of the parameters is listed in Table 1.
In Table 1 we report the average times needed to exhaustively explore the loop search
space, and the average number of solutions generated.
n
4
8
12

# JM
1
2
3

JM Parameters
kmin kmax

100 1000 120
100
500 120
100
100 120

r
0.5
0.5
0.5

Full JM
# Solutions Time (s)
597
3.13
98507
10.12
328309
28.87

Table 1: Loop Modeling settings and average running times (in seconds) and number of
solutions generated.

5.1.2 JM Approximated Propagator Quality
Even if the approximated JM produces a small set of solutions, we show here that this is
a good representation of the overall variability of the protein structure. For this test, we
compare the solutions by means of RMSD from the original structures. The experiments
were carried out with the same 30 protein targets and settings described in Table 1, with
the only exception of kmax for the loop set of size 12, which was set to 500.
In Figure 12 we show the bar chart for the RMSD of the predictions for each protein
loop within the group of targets analyzed. Precisely, in the x-axis there are the 30 (10 for
each loop length) protein targets. Each bar reports the best RMSD (dark), the average
RMSD (grey), and the worst RMSD (light grey) found. Numbers over the bars represent
the number of loops found (multiplied by the factors indicated underneath). The results
are biased by the fragment database in use: we excluded from it the fragments that belong

981

fi2.1
0.15

1.1

3.7

0.3

0.38

6
5.6

4.7

1.3
0.78

0.59

0.96
1.3

1.3

1.1

0.67

0.65
0.83

0.64

0.68

0.31

0.77

0.71
0.2

0.52

0.19

1.3

6

0.92

8

Best Rmsd
Avg Rmsd
Worst Rmsd

4
0

2

RMSD (Angstrm)

2.9

Campeotto, Dal Palu, Dovier, Fioretto, & Pontelli

. 105

. 103

Length 4

Length 8

. 107

Length 12

Figure 12: RMSD comparison for each Loop Set (x-axis: the 30 protein targets)

to the deposited protein targets. Therefore, it is not possible to reconstruct the original
target loop and none of the searches are expected to reach a RMSD equal to 0.
For loops of length 8 and 12, the exploration of the whole conformational search space
using a simple search procedure would result in an excessively long computation time. This
enforces the need for a propagator such as JM, as its filtering algorithm successfully removes
redundant conformations and it allows us to cover the whole search space in a short period
of time.
In Fig. 12 loop predictions are calculated using fragments of length 1. To study how
this choice affects both time and accuracy of the sampling we also model the loops of length
12 using fragment of length 3, 6, and 9. Best RMSDs are reported in Figure 13. For these
experiments we kept the settings used above (kmax = 500). Moreover, each JM constraint
is imposed on the fragments in order to cover the whole fragment (e.g, for fragments of
length 3 we set a JM constraint every three consecutive amino acids) and we set a time-out
of 3600 Seconds.
Notice that increasing the length of the fragments the accuracy decreases due to the
reduced size of the domains. Nevertheless, the time is also reduced since the sampling is
performed on a smaller search space and the JM constraints cover longer sequences of amino
acids. The average times are: 1580.14, 0.98, and 0.74 seconds using fragments of length 3,
6, and 9 respectively.

982

fi3
2
0

1

RMSD (Angstrm)

4

5

A Constraint Solver for Flexible Protein Models

Len3

Len6

Len9

Figure 13: RMSD comparison for loop sampling on loops of length 12 using fragments of
length 3, 6, and 9.

983

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

5.1.3 Comparison With State-of-the-art Loop Samplers
In this section, we compare our method to three state-of-the-art loop samplers: the Cyclic
Coordinate Descent (CCD) algorithm (Canutescu & Dunbrack, 2003), the Self-Organizing
algorithm (SOS) (Liu, Zhu, Rassokhin, & Agrafiotis, 2009), and the FALCm method (Lee,
Lee, Park, Coutsias, & Seok, 2010).
Table 2 shows the average of the best RMSD for the benchmarks of length 4, 8 and 12
as computed by the four programs. We report the results as given in Table 2 of Canutescu
and Dunbrack for the CCD, Table 1 of Liu et al. for SOS, Table II of Lee et al. for the
FALCm method, and the RMSDs obtained adopting the settings for JMf that provided
the best results in the previous section (see also Subsection 5.1.5). It can be noted that our
results are in line with those produced by the other systems.
Loop
Length
4
8
12

Average (best) RMSD
CCD
SOS
FALCm
JMf
0.56
0.20
0.22
0.27
1.59
1.19
0.72
0.93
3.05
2.25
1.81
1.58

Table 2: Comparison of loop sampling methods
The execution time we reported appear to be very competitive (e.g., if we considered
the results reported in Soto et al., 2008).
5.1.4 JM Parameters Analysis
In this section, we analyze the impact of the JM parameters on the quality of the best
solutions found and on the execution times. In particular, the aim of these experiments is
to shed light on the relationship between the JM constraint settings and the results.
In Figure 14, we analyze the impact of the kmax on the execution times (left) and on
the precision (right) of the filtering of the JM constraint. From top to bottom, we use
 = 60, 120, 360. The tests are performed over the protein loops of length 4 (see section
above), adopting as cluster parameters, r in {0.5, 1.0, 3.0, 5.0}, and kmin = 100. Each dot in
the plots represents the average of the best RMSD found by each predictions (left) and the
average execution time (right). The RMSD values tend to decrease for smaller clustering
parameters r and  and as the number of clusters increases, while the filtering time increases
as kmax increases.
In Figure 15 we study the relation between the RMSD and both the number of JMs that
cover a given target loop or protein and the Voxel-side parameter. For these experiments
we used the values {100, 250, 500, 800, 1000} for the kmax , we set r = 1,  = 120, and we
averaged the RMSDs values on the resulting sample set of structures. The relation between
the RMSD and number of JM as well as the average and worst computational times are
shown in Fig. 15 left. Here we use a medium-length loop taken from the protein 1XPC
(res. 216-230) and we vary the number of JMs that cover the loop (the side of the voxel
has been set to 3A). From the figure we observe that increasing the number of JMs (i.e.
covering less amino acids with a single JM) the RMSD decreases but the computational
cost is higher. Notice that the best RMSD is given when the loop is covered by 4 JM

984

fiA Constraint Solver for Flexible Protein Models

0.9



50.0


0.8

0.6

10.0


r


0.5

r

Time (s)

)
RMSD (A

0.7

0.5
1.0
3.0
5.0



0.4



0.5
1.0
3.0
5.0

1.0


0.3

0.5


0.2





10000

100

0.1

100

1000

5000

1000

5000

JM kmax

10000

JM kmax

50.0


0.9


0.8
10.0

0.6

r



0.5
1.0
3.0
5.0



0.5

Time (s)

)
RMSD (A

0.7
r





1.0

0.4

0.5
1.0
3.0
5.0

0.5



0.3




0.2

100

1000

5000

10000

100

1000

JM kmax

5000

10000

JM kmax

0.9





0.8



0.6

r




0.5

0.5
1.0
3.0
5.0

Time (s)

)
RMSD (A

0.7

r

1.0



0.5

0.5
1.0
3.0
5.0

0.4



0.3




5000

10000

0.2

100

1000

100

JM kmax

1000

5000

10000

JM kmax

Figure 14: Comparison of the best RMSD values and execution times at varying of the
kmax clustering parameter for  = 60 (top), 120 (center), 360 (bottom)

985

fi7
RMSD

1LE0
1MXN
1FDF

0

0

1

2

3

2091.72 (3216.94)

1105.63 (2057.83)

194.70 (411.95)

9.53 (19.54)

11.73 (18.42)

4
2

RMSD

4

5

6

6

8

Campeotto, Dal Palu, Dovier, Fioretto, & Pontelli

1

2

3

4

5

0

N.of JM

20

40

60

80

100

VoxelSide

Figure 15: Left: RMSD (best and average) and Time (average and worst) values increasing
the number of JM constraints that completely cover a target loop of length 15. Right:
Average (dotted line) and best (solid line) RMSD for the targets 1LE0 of length 12 (top),
1MXN of length 16 (medium), and 1FDF of length 25 (low). The JM-Voxel-side parameter
for the voxels of the clustering varies from 3 to 100. The JM kmax parameter varies from
100 to 1000. The targets are completely covered by multiple JM-constraints.
constraint (i.e., a JM constraint each four consecutive amino acids). As a rule of thumb
we suggest to use a JM constraint to cover from 3 to 4 consecutive amino acids since this
setting produces the best results within an acceptable time. In Fig. 15 right we report the
best RMSD (solid line) and the average RMSD (dotted line) of the structures found using
multiple JM constraints that cover sequences of 4 consecutive amino acids through the whole
target proteins. Namely, if the protein target has length n, we set the JM constraints from
i to i + 3, where i = 3  j, 0  j < n/3. For these experiments, we considered three proteins
of relatively short length, in order to obtain a complete exploration of the search space in
reasonable computational time: 1LE0 (length 12), 1MXN (length 16), and 1FDF (length
24). Moreover we used the values {3, 5, 10, 20, 30, 50, 100} for the side of the voxels used for
the clustering.
From the Figure 15 we observe that the voxel size (enabled by the uniqueseq) has an
impact on the clustering for values lower than 30A (recall that these proteins have a diameter
less than 30A). For voxel sides lower than 3A we observe no substantial improvement in
terms of quality, while the time required by the solver to compute the solutions increases
exponentially.
5.1.5 Results Summary And Default Parameters
We now provide some guidelines that may be helpful to tune the JM parameters for a given
protein modeling problem. We suggest several levels of parametrization that might be used
according to the user needs with respect to running time or prediction accuracy. We stress

986

fiA Constraint Solver for Flexible Protein Models

that these are merely guidelines, outlined from our empirical evaluations, and that several
tests should be done to establish the desired tuning.
We suggest to set a JM to model a sequence of at least 3 amino acids and in general not
longer than 8, to payoff the computational load of the JM clustering. The default choice
for kmin is set to be the average size of the variable domains involved in a JM constraint,
while we suggest to set kmax to be at least as kmin and not greater than 10000. The latter,
together with the number of consecutive JM constraints, will have the greatest impact on the
computational cost and prediction accuracy. Computational costs will grow as the number
of consecutive JM increases, and at the same time it will also produce in general higher
accuracy. The same trend is exhibited by the growing kmax parameter. Table 3 illustrates
five basic settings that could be used incrementally to establish a trade off between running
times and prediction accuracy. The first level (Lev. 1) is associated to faster computational
times and lower accuracy while the last one (Lev. 5) is the slowest but also the most accurate.
The second column of the table indicates the length of the amino acid sequence modeled
by a single JM.
Lev.
1
2
3
4
5

n.JM
8
8
6
4
4

kmin
|D|
|D|
|D|
|D|
|D|

kmax
500
1000
100
500
1000


120
120
120
120
120

r
5
3
3
3
1

Speed
   
  
  



Accuracy



  
   

Table 3: JM default parameters

5.2 An Application In Protein Structure Prediction
In the protein structure prediction problem, we model a generic backbone through multiple
JM constraints. In principle, an unique JM constraint can model the whole problem. As
in the previous cases, we split it into smaller parts, moreover, the presence of secondary
structure is a valid help in the placement of JM constraints that can handle loops between
each consecutive pair. A simple search can generate a pool of conformations, then energy
scoring can select the best candidate. We have used a statistical energy function developed
for the 5@ model, but any other energy function can be used instead.
In this section, we study the applicability of FIASCO to the protein structure prediction
problem. In particular, we consider prediction problems where the secondary structure
elements of the protein are given. Furthermore, in order to assess the potential structure,
we introduce an energy functionthe same that we have adopted in previous studies, and
more precisely described in http://www.cs.nmsu.edu/fiasco.
For the modeling, we have used the information about the location and the type of
the secondary structure elements on the primary sequence provided directly by the Protein
Data Bank. We have imposed a sequence of JM constraints between every consecutive
pair of secondary structure elements. The number of consecutive JM constraints varied
according to the length of the unstructured sequence being modeled, covering at most 5
amino acids with a single JM constraint. In addition one JM constraint was imposed from
the first amino acid to the beginning of the first secondary structure element and another
987

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

from the end of the last secondary structure element and the last amino acid (the tails of
the protein). The domains for the initial and end points of the JM constraints are the set of
all admissible points (a box large enough to contain the protein). In the search phase, the
first secondary structure is deterministically set in the space. Then the labeling proceeds
with the JM constraint attached to it leading to the next secondary structure and so on.
Tails are instantiated at the end.
The propagation of the constraints generates a set of admissible structures, that represents the possible folds of the target protein. From this set, we select the structure with
minimum energy; we extract also the structure with minimum RMSD, in order to evaluate
the quality of the energy function. For these tests we adopt the FREAD database. Table 4
reports the best energy values found by FIASCO. In the RMSD columns is reported the
corresponding RMSD associated to the conformation with best energy found by the solver.
The #JM column reports the total number of JM used to model each protein, together
with the maximum number of consecutive JM adopted to model a contiguous sequence of
amino acids (within parentheses).
Protein ID
1ZDD
2GP8
2K9D
1ENH
2IGD
1SN1
1AIL
1B4R
1JHG

Len.
35
40
44
54
60
63
69
79
100

# JM
4(2)
4(2)
5(2)
4(1)
7(2)
7(3)
4(1)
11(2)
7(1)

Energy
100513
138110
204693
309896
295882
358874
411077
313590
572950

RMSD
2.05
6.28
2.52
8.21
10.50
5.55
4.59
6.11
4.51

Time (Min.)
11.42
8.55
2.69
31.67
26.47
14.82
4.46
8.41
4.50

Table 4: Ab initio prediction with FIASCO.
The results show that the quality of the predictions computed by FIASCO (6.3 as average
RMSD) is competitive (and, as shown in the following section, at par or better than what
produced by other methods). The results are particularly encouraging for proteins of longer
length, where the sampling of the search space aids in development of admissible structures.
The time required by FIASCO to completely explore the search space depends strongly on
the type and the mutual arrangement of secondary structure elements of the target. For
example, the protein 2K9D and the protein 1ENH have the same length, but FIASCO is
significantly faster on the first protein than on the second one. The same observation can
be made for the proteins 2IGD and 1SN1. The results reported in Table 4 are promising
and they suggest that this is a feasible approach to solve the ab initio prediction problem.
As a future work, we will explore the integration of local search techniques (e.g., largeneighboring search), in order to sample the search space and to further decrease the time
needed to explore it.

988

fiA Constraint Solver for Flexible Protein Models

5.3 A Comparison of FIASCO with State-of-the-Art Constraint Solvers
In this section, we motivate our choice of designing an ad-hoc solver instead of using a
general-purpose constraint solver. In particular we provide a comparison between FIASCO
and state-of-the-art constraint solving. The results justify the choice of implementing a new
solver from scratch instead of using an available constraint programming library or a constraint programming language. The solver chosen for this comparison is Gecode (Gecode
Team, 2013), a very efficient solver and the winner of the most recent MiniZinc challenges (Stuckey, Becket, & Fischer, 2010).
Gecode has recently introduced (in version 4.0) the handling of floating point variables.
Nevertheless, since Gecode is the fastest solver for FD variables, we have first encoded
the PSP by discretizing fragments and positions. In particular, we multiplied each real
number by a scaling factor (100) to obtain integer values. Each spatial position is encoded
by a triple of variables, representing the coordinates of the point. Each operation (e.g.,
multiplications) applied to such variables requires re-scaling of the result; this unfortunately
leads to ineffective propagation. This is particularly evident when dealing with distance
constraints, that require the implementation of Euclidean distance between pairs of triples
of variables.
In order to understand the solvers capabilities to propagate constraints on the placement of overlapping fragment we implemented three versions of the code, that considered
a different number of constraints, precisely:
1. An implementation that uses only JM constraint (JM only)
2. An implementation that adds the alldistant constraint and
3. An implementation that adds the alldistant and centroid constraints
In all cases we use a complete search (in particular, the clustering and tabling constraints
of lines 10 and 1214 of Algorithm 2 are disabled).
In Table 5, we report the execution times required by FIASCO and by Gecode (with the
same considered constraints) to determine an increasing number of solutions, from 1, 000
to 1, 000, 000. These solutions are computed for the target protein 1ZDD which has length
35. Table 5 shows that the execution time of both solvers increases proportionally with the
number of solutions found. However, FIASCO is one order of magnitude faster than Gecode
in the unconstrained case, and two orders of magnitude faster in the other cases. The main
reason is that FIASCO is specifically developed to handle the finite domains and 3D point
variables, while these are approximated by FD variables in Gecode. Constraints on these
approximations propagate poorly and slowly. Moreover, the approximation of fragments
using finite domain variables introduces approximation errors, that grow during the search
phase (and consequently, less solutions are returned in the constrained cases). These errors
may result in final structures that are relatively imprecise when the coordinates of the atoms
are converted back into real values.
In Table 6, we consider a small sequence of four amino acids (SER TRP THR TRPthe
first four amino acids of the protein 1LE0), and we generate all solutions. We report the
values of the best and the average RMSD among the structures of the sets of solutions computed using FIASCO and the Gecode implementation after a complete enumeration of the
989

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Number of
solutions
1000
10000
100000
1000000

JM only
0.030
0.312
3.006
29.859

FIASCO
alldistant alldistant + centroid
0.051
0.059
0.476
0.612
4.794
6.040
47.669
61.385

JM only
0.358
2.571
25.407
252.815

Gecode
alldistant alldistant + centroid
2.531
3.807
21.056
35.370
209.569
347.831
2186.83
3632.39

Table 5: Comparison of the execution times of FIASCO and Gecode, for increasing number
of solutions and with different sets of considered constraints.
domains. We can observe that FIASCO is significantly faster in exploring the search space,
moreover, the approximation introduces errors that leads to the loss of feasible solutions.

JM only
alldistant
alldistant + centroid

N. sol.
810000
805322
805322

FIASCO
Time (sec.) RMSD
20.493
0.167
33.493
0.167
38.953
0.167

Avg. RMSD
1.570
1.564
1.564

N. sol
810000
774463
169441

Gecode
Time (sec.) RMSD
181.102
0.190
252.974
0.190
140.644
0.580

Avg. RMSD
1.596
1.591
1.880

Table 6: Number of solutions, time, best RMSD, and average RMSD on the set of structures
found by FIASCO and Gecode after a complete enumeration of the solution space using
different constraints
We have encoded the same constraint satisfaction problem using the new version of
Gecode that allows to employ float variables. We labeled the finite domain variables that
allow to select fragments, while values for the point variables are obtained by constraint
propagation. Since constraint propagation of float variables is based on interval arithmetics,
it turns out that after few amino acids these intervals are too large for being able of reconstructing the protein and or evaluating the energy value. For instance, after a complete
assignment of the variables related to fragments of protein 1ZDD, while the domains of the
float variables associated with the position of the first two amino acids are singletons, those
related to the tenth amino acids are intervals with size from one to two A; even worse,
the domains of the atoms of the eleventh amino acids are unbounded. A further stage of
labeling of the float variables required computational time of orders of magnitude higher
than those reported in Table 6 for the finite domain Gecode implementation.
Constraint solvers like ECLiPSe (Cheadle, Harvey, Sadler, Schimpf, Shen, & Wallace, 2003) and Choco (Choco Team, 2008) also support the mixed use of integer and
real variables. ECLiPSe is a Prolog-based language which handles integer and real variables together. However, the great number of matrix operations required in our application does not fit well with a Prolog implementation. Furthermore, the current trend
of ECLiPSe is to replace a direct constraint solving with a translation to FlatZinc. In
the case of Choco, the current support of Real Variables is still under development (c.f.
http://choco.sourceforge.net/userguide.pdfpage 3). Things may change with the
next releases.
We also experimented with another constraint solver, by implementing the multi-body
constraints using the JaCoP library (JaCoP Team, 2012), in a similar way as done for
Gecode. Eventually, we tested the same protein used for the results reported in Table 5,

990

fiA Constraint Solver for Flexible Protein Models

and we did not observe any substantial difference in terms of execution time, from the
Gecode implementation.
In terms of protein structure prediction, the design of FIASCO has been influenced by
our own previous work on the TUPLES system (Dal Palu et al., 2011). TUPLES is also a
constraint solver for protein structure prediction, based on fragments assembly. Figure 16
compares the performance of TUPLES and FIASCO on the same set of proteins discussed
in Section 5.2. To make the comparison fair, we make use of the same energy function in
both systems and assume that the secondary structure elements are known. Note that there
are some important differences between the two systems. TUPLES is implemented using
constraint logic programming techniques, specifically, SICStus Prolog (Swedish Institute for
Computer Science, 2012); TUPLES does not make use of floating point variables; on the
other hand, TUPLES introduces a heuristic search mechanism based on large neighboring
search.
The results show that the quality of the predictions computed by FIASCO (6.3 as average
RMSD) is better than the quality of the predictions computed by TUPLES (9.4 as average
RMSD). The complete sampling of the search space allows us to obtain better results for
the proteins of longer length in the benchmark ( 63). Instead, for shorter proteins, we
obtain comparable results. The similarity of the quality depends on the use of the same
energy function for both the systems. Notice that the energy function used is designed for
the simpler model adopted in TUPLES (C C ). Moreover, TUPLES is based on a Prolog
implementation that does not provide floating point variables and hence each value must
be rounded and approximated. These aspects explain both the quality differences between
the RMSD and the Best RMSD found by FIASCO and the behavior for which for some
proteins (e.g., 1ZDD, 2GP8 ) the (energy) RMSD values are better in FIASCO even if their
corresponding energy (RMSD) values are higher than in TUPLES. The execution times of
FIASCO are significantly faster than TUPLES, in spite of FIASCOs lack of a sophisticated
search heuristic.
We also performed a comparison with the state-of-the-art online Robetta predictor (Raman, Vernon, Thompson, Tyka, Sadreyev, Pei, Kim, Kellogg, DiMaio, Lange, Kinch, Sheffler, Kim, Das, Grishin, & Baker, 2009) for the first four proteins of Table 6. We built
the dictionary for 3 and 9 amino acid long peptides through the Robetta interface, and we
disabled any homology inference, in order to maintain a fair comparison. The results are:
1ZDD computed in 21s with 5.92 RMSD, 2GP8 computed in 16s with 5.44 RMSD, 2K9D
computed in 22s with 4.65 RMSD, 1ENH computed in 39s with 2.74 RMSD. It can be noted
that our results are in line with Robetta predictor.
Let us conclude this section mentioning that the results reported in the previous section
(where we compared FIASCO with TUPLES) provide also an implicit comparison with another off-the-shelf solver, the SICStus Prolog constraint logic programming solver (Swedish
Institute for Computer Science, 2012).

6. Conclusions
In this paper, we presented a novel constraint (joined-multibody) to model rigid bodies
connected by joints, with constrained degrees of freedom in the 3D space. We presented a
polynomial time approximated filtering algorithm of the joined-multibody constraint, that
991

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Figure 16: Comparison of RMSD and Execution Time between TUPLES and FIASCO

992

fiA Constraint Solver for Flexible Protein Models

exploits the geometrical features of the rigid bodies. In particular, the filtering algorithm
is combined with search heuristics that can produce a pool of admissible solutions that are
uniformly sampled. This allows for a direct control of the quality and number of solutions.
The filtering algorithm is based on a 3D clustering procedure that is able to cope with
a high variability of rigid bodies, while preserving the computational cost. The practical
advantages of the joined-multibody constraint are shown by an extensive set of real protein
simulations for two main categories: protein loop reconstruction and structure prediction
(ab-initio). The tests showed how the parameters of the constraint are able to control
effectively the quality and computational cost of the search. In conclusion, the constraint
solver FIASCO is able to model effectively various common protein case-studies analyses.
As future work, from the applications side, we plan to explore the protein loop closure
problem, with the use of specific databases and scoring functions. For the close problem of
protein flexibility, we plan to use FIASCO solver to generate the conformational space of
long scale movements for nuclear receptors (Dal Palu et al., 2012b). Finally, we plan to use
FIASCO in the general context of protein structure prediction with the combination of local
search methods and protein-ligand spatial constraints. From the constraint side, we plan
to integrate the JM filtering algorithm with other distance constraints, in order to generate
more accurate clusters; we plan to integrate spatial constraints inferred from bounds on
energy terms (e.g., the favorable contributions provided by pairing secondary structure
elements translate into energy bounds and distance constraints). We plan to investigate the
use of multiple JM constraints to model super-secondary structures placement, which are
useful to capture important functional and structural protein features. The latter can be
thought of as imposing several spatial path preferences to a given chain of points. Finally,
we intend to integrate the constraint solver with a visual interface to make it easily available
to Biologist and other practitioners and porting some parts of this tool within a GPU-based
framework as recently explored by Campeotto, Dovier, and Pontelli (2013).

Acknowledgments
We thank Federico Fogolari for his comments on several parts of this work. The authors
would like to express gratitude to JAIR reviewers that helped us to sensibly improve the
presentation.

References
Al-Bluwi, I., Simeon, T., & Cortes, J. (2012). Motion Planning Algorithms for Molecular
Simulations: A Survey. Computer Science Review, 6 (4), 125143.
Alberts, B., Johnson, A., Lewis, J., Raff, M., Roberts, K., & Walter, P. (2007). Molecular
Biology of the Cell (5th Edition edition). Garland Science.
Anfinsen, C. B. (1973). Principles that Govern the Folding of Protein Chains. Science, 181,
223230.
Apt, K. (2009). Principles of Constraint Programming. Cambridge University Press.
Backofen, R., & Will, S. (2006). A Constraint-Based Approach to Fast and Exact Structure
Prediction in 3-Dimensional Protein Models. Constraints, 11 (1), 530.
993

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Backofen, R., Will, S., & Bornberg-Bauer, E. (1999). Application of Constraint Programming Techniques for Structure Prediction of Lattice Proteins with Extended Alphabet.
Bioinformatics, 15(3), 234242.
Baker, D., & Sali, A. (2001). Protein Structure Prediction and Structual Genomics. Science,
294 (5540), 9396.
Barahona, P., & Krippahl, L. (2008). Constraint Programming in Structural Bioinformatics.
Constraints, 13 (1-2), 320.
Ben-David, M., Noivirt-Brik, O., Paz, A., Prilusky, J., Sussman, J. L., & Levy, Y. (2009).
Assessment of CASP8 Structure Predictions for Template Free Targets. Proteins, 77,
5065.
Bennett, W., & Huber, R. (1984). Structural and Functional Aspects of Domain Motions
in Proteins. Crit. Rev. Biochem., 15, 291384.
Borning, A. (1981). The Programming Language Aspects of ThingLab, a ConstraintOriented Simulation Laboratory. ACM Transactions on Programming Languages and
Systems, 3 (4), 353387.
Cahill, S., Cahill, M., & Cahill, K. (2003). On the Kinematics of Protein Folding. Journal
of Computational Chemistry, 24 (11), 13641370.
Campeotto, F., Dovier, A., & Pontelli, E. (2013). Protein Structure Prediction on GPU:
a Declarative Approach in a Multi-agent Framework. In International Conference on
Parallel Processing (ICPP), pp. 474479. IEEE Computer Society Press.
Campeotto, F., Dal Palu, A., Dovier, A., Fioretto, F., & Pontelli, E. (2012). A Filtering
Technique for Fragment Assembly-Based Proteins Loop Modeling with Constraints.
In Milano, M. (Ed.), CP, Vol. 7514 of Lecture Notes in Computer Science, pp. 850866.
Springer.
Canutescu, A., & Dunbrack, R. (2003). Cyclic coordinate descent: a robotics algorithm for
protein loop closure. Protein Sci, 12, 963972.
Cheadle, A. M., Harvey, W., Sadler, A. J., Schimpf, J., Shen, K., & Wallace, M. G. (2003).
ECLiPSe: An Introduction. Technical report IC-Parc 031, IC-Parc, Imperial College
London.
Chelvanayagam, G., Knecht, L., Jenny, T., Benner, S., & Gonnet, G. (1998). A Combinatorial Distance-Constraint Approach to Predicting Protein Tertiary Models from
Known Secondary Structure. Folding and Design, 3, 149160.
Choco Team (2008). Choco: an Open Source Java Constraint Programming Library. In
Workshop on Open-Source Software for Integer and Constraint Programming. Available from http://www.emn.fr/z-info/choco-solver/.
Choi, Y., & Deane, C. M. (2010). FREAD Revisited: Accurate Loop Structure Prediction
Using a Database Search Algorithm. Proteins, 78 (6), 143140.
Clementi, C. (2008). Coarse-grained Models of Protein Folding: Toy Models or Predictive
Tools?. Curr Opin Struct Biol, 18, 1015.
994

fiA Constraint Solver for Flexible Protein Models

Corblin, F., Trilling, L., & Fanchon, E. (2005). Constraint Logic Programming for Modeling
a Biological System Described by a Logical Network. In Workshop on ConstraintBased Methods for Bioinformatics.
Cortes, J., & Al-Bluwi, I. (2012). A Robotics Apporach to Enhance Conformational Sampling of Proteins. In International Design Engineering Technical Conferences and
Computers and Information in Engineering Conference, Vol. 4, pp. 11771186. ASME.
Crescenzi, P., Goldman, D., Papadimitriou, C., Piccolboni, A., & Yannakakis, M. (1998).
On the Complexity of Protein Folding. In Proceedings of the Thirtieth Annual ACM
Symposium on the Theory of Computing, pp. 597603. ACM Press.
Dal Palu, A., Dovier, A., Fogolari, F., & Pontelli, E. (2012a). Protein Structure Analysis
with Constraint Programming. In Cozzini, P., & Kellogg, G. (Eds.), Computational
Approaches to Nuclear Receptors, chap. 3, pp. 4059. The Royal Society of Chemistry.
Dal Palu, A., Spyrakis, F., & Cozzini, P. (2012b). A New Approach for Investigating Protein
Flexibility Based on Constraint Logic Programming: The First Application in the Case
of the Estrogen Receptor. European Journal of Medicinal Chemistry, 49, 127140.
Dal Palu, A., Dovier, A., & Fogolari, F. (2004). Constraint Logic Programming Approach
to Protein Structure Prediction. BMC Bioinformatics, 5, 186.
Dal Palu, A., Dovier, A., Fogolari, F., & Pontelli, E. (2010). CLP-based protein fragment
assembly. Theory and Practice of Logic Programming, 10 (4-6), 709724.
Dal Palu, A., Dovier, A., Fogolari, F., & Pontelli, E. (2011). Exploring Protein Fragment
Assembly Using CLP. In Walsh, T. (Ed.), Proceedings of the International Joint
Conference on Artificial Intelligence, IJCAI, pp. 25902595. IJCAI/AAAI.
Dal Palu, A., Dovier, A., & Pontelli, E. (2005). A New Constraint Solver for 3D Lattices and
Its Application to the Protein Folding Problem. In International Conference on Logic
for Programming Artificial Intelligence and Reasoning, pp. 4863. Springer Verlag.
Dal Palu, A., Dovier, A., & Pontelli, E. (2007). A Constraint Solver for Discrete Lattices,
its Parallelization, and Application to Protein Structure Prediction. Software Practice
and Experience, 37 (13), 14051449.
Dal Palu, A., Dovier, A., & Pontelli, E. (2010). Computing Approximate Solutions of
the Protein Structure Determination Problem using Global Constraints on Discrete
Crystal Lattices. International Journal of Data Mining and Bioinformatics, 4 (1),
120.
Deane, C., & Blundell, T. (2001). CODA. A Combined Algorithm for Predicting the Structurally Variable Regions of Protein Models. Protein Sci, 10, 599612.
Debartolo, J., Hocky, G., Wilde, M., Xu, J., Freed, K., & Sosnick, T. (2010). Protein
Structure Prediction Enhanced with Evolutionary Diversity: SPEED. Protein Science,
19 (3), 520534.
Dotu, I., Cebrian, M., Van Hentenryck, P., & Clote, P. (2011). On Lattice Protein Structure
Prediction Revisited. IEEE/ACM Trans. Comput. Biology Bioinform, 8 (6), 1620
1632.
995

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Dunbrack, R. (2002). Rotamer Libraries in the 21st Century. Curr. Opin. Struct. Biol.,
12 (4), 431440.
Erdem, E. (2011). Applications of Answer Set Programming in Phylogenetic Systematics.
In Logic Programming, Knowledge Representation, and Nonmonotonic Reasoning, pp.
415431. Springer Verlag.
Erdem, E., & Ture, F. (2008). Efficient Haplotype Inference with Answer Set Programming.
In National Conference on Artificial Intelligence (AAAI), pp. 436441. AAAI/MIT
Press.
Felts, A., Gallicchio, E., Chekmarev, D., Paris, K., Friesner, R., & Levy, R. (2008). Prediction of Protein Loop Conformations using AGBNP Implicit Solvent Model and
Torsion Angle Sampling. J Chem Theory Comput, 4, 855868.
Fiser, A., Do, R., & Sali, A. (2000). Modeling of Loops in Protein Structures. Protein Sci,
9, 17531773.
Fogolari, F., Esposito, G., Viglino, P., & Cattarinussi, S. (1996). Modeling of Polypeptide
Chains as C Chains, C Chains with C , and C Chains with Ellipsoidal Lateral
Chains. Biophysical Journal, 70, 11831197.
Fogolari, F., Pieri, L., Dovier, A., Bortolussi, L., Giugliarelli, G., Corazza, A., Esposito, G.,
& Viglino, P. (2007). Scoring Predictive Models using a Reduced Representation of
Proteins: Model and Energy Definition. BMC Structural Biology, 7 (15), 117.
Fogolari, F., Corazza, A., Viglino, P., & Esposito, G. (2012). Fast Structure Similarity
Searches among Protein Models: Efficient Clustering of Protein Fragments. Algorithms
for Molecular Biology, 7, 16.
Fujitsuka, Y., Chikenji, G., & Takada, S. (2006). SimFold Energy Function for De Novo
Protein Structure Prediction: Consensus with Rosetta. Proteins, 62, 381398.
Gay, S., Fages, F., Martinez, T., & Soliman, S. (2011). A Constraint Program for Subgraph
Epimorphisms with Application to Identifying Model Reductions in Systems Biology.
In Workshop on Constraint-Based Methods for Bioinformatics.
Gebser, M., Schaub, T., Thiele, S., & Veber, P. (2011). Detecting Inconsistencies in Large
Biological Networks with Answer Set Programming. Theory and Practice of Logic
Programming, 11 (2-3), 323360.
Gecode Team (2013). Gecode: Generic Constraint Development Environment. Available
from http://www.gecode.org.
Go, N., & Scheraga, H. (1970). Ring Closure and Local Conformational Deformations of
Chain Molecules. Macromolecules, 3, 178187.
Graca, A., Marques-Silva, J., Lynce, I., & Oliveira, A. (2011). Haplotype Inference with
Pseudo-Boolean Optimization. Annals of OR, 184 (1), 137162.
Guns, T., Sun, H., Marchal, K., & Nijssen, S. (2010). Cis-regulatory Module Detection Using
Constraint Programming. In IEEE International Conference on Bioinformatics and
Biomedicine (BIBM), pp. 363368.
996

fiA Constraint Solver for Flexible Protein Models

Handl, J., Knowles, J., Vernon, R., Baker, D., & Lovell, S. (2012). The Dual Role of
Fragments in Fragment-Assembly Methods for De Novo Protein Structure Prediction.
Proteins: Structure, Function and Bioinformatics, 80 (2), 490504.
Hartenberg, R., & Denavit, J. (1995). A Kinematic Notation for Lower Pair Mechanisms
Based on Matrices. Journal of Applied Mechanics, 77, 215221.
Hegler, J., Latzer, J., Shehu, A., Clementi, C., & Wolynes, P. (2009). Restriction Versus
Guidance in Protein Structure Prediction. Proc Natl Acad Sci U.S.A., 106 (36), 15302
15307.
Jacobson, M., Pincus, D., Rapp, C., Day, T., Honig, B., Shaw, D., & Friesner, R. (2004). A
Hierarchical Approach to All-atom Protein Loop Prediction. Proteins, 55, 351367.
JaCoP Team (2012). JaCoP web page, visited November 2012..
http://www.jacop.eu.

Available from

Jamroz, M., & Kolinski, A. (2010). Modeling of Loops in Proteins: a Multi-method Approach. BMC Struct. Biol., 10 (5).
Jauch, R., Yeo, H., Kolatkar, P. R., & Clarke, N. D. (2007). Assessment of CASP7 Structure
Predictions for Template Free Targets. Proteins, 69, 5767.
Jones, D. (2006). Predicting Novel Protein Folds by using FRAGFOLD. Proteins, 45,
127132.
Karplus, K., Karchin, R., Draper, J., Casper, J., Mandel-Gutfreund, Y., Diekhans, M.,
& Source., R. H. (2003). Combining local structure, fold-recognition, and new fold
methods for protein structure prediction. Proteins, 53 (6), 491497.
Karplus, M., & Shakhnovich, E. (1992). Protein Folding: Theoretical Studies of Thermodynamics and Dynamics. In Protein Folding, pp. 127195. WH Freeman.
Kim, D. E., Blum, B., Bradley, P., & Baker, D. (2009). Sampling Bottlenecks in De novo
Protein Structure Prediction. Journal of Molecular Biology, 393 (1), 249  260.
Kinch, L., Yong Shi, S., Cong, Q., Cheng, H., Liao, Y., & Grishin, N. V. (2011). CASP9
assessment of free modeling target predictions. Proteins, 79, 5973.
Kirillova, S., Cortes, J., Stefaniu, A., & Simeon, T. (2008). An NMA-Guided Path Planning Approach for Computing Large-Amplitude Conformational Changes in Proteins.
Proteins: Structure, Function, and Bioinformatics, 70 (1), 131143.
Kolodny, R., Guibas, L., Levitt, M., & Koehl, P. (2005). Inverse Kinematics in Biology:
The Protein Loop Closure Problem. The International Journal of Robotics Research,
24 (2-3), 151163.
Krippahl, L., & Barahona, P. (2002). Psico: Solving Protein Structures with Constraint
Programming and Optimization. Constraints, 7 (4-3), 317331.
Krippahl, L., & Barahona, P. (2005). Applying Constraint Programming to Rigid Body
Protein Docking. In Principles and Practice of Constraint Programming, pp. 373
387. Springer Verlag.
Krippahl, L., & Barahona, P. (1999). Applying Constraint Programming to Protein Structure Determination. In Principles and Practice of Constraint Programming, pp. 289
302. Springer Verlag.
997

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Larhlimi, A., & Bockmayr, A. (2009). A New Constraint-Based Description of the SteadyState Flux Cone of Metabolic Networks. Discrete Applied Mathematics, 157 (10),
22572266.
LaValle, S. (2006). Planning Algorithms. Cambridge University Press.
Lazaridis, T., Archontis, G., & Karplus, M. (1995). Enthalpic Contribution to Protein
Stability: Atom-Based Calculations and Statistical Mechanics. Adv. Protein Chem.,
47, 231306.
Lee, J., Kim, S., Joo, K., Kim, I., & Lee, J. (2004). Prediction of Protein Tertiary Structure
using Profesy, a Novel Method Based on Fragment Assembly and Conformational
Space Annealing. Proteins, 56 (4), 704714.
Lee, J., Lee, D., Park, H., Coutsias, E., & Seok, C. (2010). Protein Loop Modeling by Using
Fragment Assembly and Analytical Loop Closure. Proteins, 78 (16), 34283436.
Liu, P., Zhu, F., Rassokhin, D., & Agrafiotis, D. (2009). A Self-organizing Algorithm for
Modeling Protein Loops. PLOS Comput Biol, 5 (8).
Lovell, S., Davis, I., Arendall, W., de Bakker, P., Word, J., Prisant, M., Richardson, J., &
Richardson, D. (2003). Structure Validation by C Geometry: ,  and C Deviation.
Proteins, 50, 437450.
Mann, M., & Dal Palu, A. (2010). Lattice Model Refinement of Protein Structures. In
Workshop on Constraint-Based Methods for Bioinformatics.
Micheletti, C., Seno, F., & Maritan, A. (2000). Recurrent oligomers in proteins: an optimal scheme reconciling accurate and concise backbone representations in automated
folding and design studies. proteins, 40 (4), 662674.
Moll, M., Schwarz, D., & Kavraki, L. (2007). Roadmap Methods for Protein Folding. Humana Press.
Molloy, K., Saleh, S., & Shehu, A. (2013). Probabilistic Search and Energy Guidance for
Biased Decoy Sampling in Ab-Initio Protein Structure Prediction. IEEE/ACM Trans.
Comput. Biology Bioinform, PrePrint.
Neumaier, A. (1997). Molecular Modeling of Proteins and Mathematical Prediction of
Protein Structure. SIAM Review, 39, 407460.
Noonan, K., OBrien, D., & Snoeyink, J. (2005). Protein Backbone Motion by Inverse
Kinematics. International Journal of Robotics Research, 24 (11), 971982.
Olson, B. S., Molloy, K., & Shehu, A. (2011). In Search of the Protein Native State with
a Probabilistic Sampling Approach. J. Bioinformatics and Computational Biology,
9 (3), 383398.
Raman, S., Vernon, R., Thompson, J., Tyka, M., Sadreyev, R., Pei, J., Kim, D., Kellogg, E.,
DiMaio, F., Lange, O., Kinch, L., Sheffler, W., Kim, B.-H., Das, R., Grishin, N. V.,
& Baker, D. (2009). Structure Prediction for CASP8 with All-atom Refinement using
Rosetta. Proteins, 77 (Suppl. 9), 8999.
Rapp, C. S., & Friesner, R. A. (1999). Prediction of Loop Geometries using a Generalized
Born Model of Solvation Effects. Proteins, 35, 173183.
998

fiA Constraint Solver for Flexible Protein Models

Ray, O., Soh, T., & Inoue, K. (2010). Analyzing Pathways Using ASP-Based Approaches. In
Algebraic and Numeric Biology, 4th International Conference, pp. 167183. Springer
Verlag.
Rossi, F., van Beek, P., & Walsh, T. (2006). Handbook of Constraint Programming. Elsevier
Science Inc.
Rufino, S., Donate, L., Canard, L., & Blundell, T. (1997). Predicting the Conformational
Class of Short and Medium Size Loops Connecting Regular Secondary Structures:
Application to Comparative Modeling. J. Mol. Biol., 267, 352367.
Shehu, A. (2009). An Ab-Initio Tree-Based Exploration to Enhance Sampling of Low-Energy
Protein Conformations. In Proceedings of Robotics: Science and Systems V.
Shehu, A. (2010). Conformational Search for the Protein Native State, pp. 431452. John
Wiley & Sons. Inc.
Shehu, A., & Kavraki, L. (2012). Modeling Structures and Motions of Loops in Protein
Molecules. Entropy, 14, 252290.
Shen, M., & Sali, A. (2006). Statistical Potential for Assessment and Prediction of Protein
Structures. Protein Sci, 15, 25072524.
Shih, E., & Hwang, M.-J. (2011). On the Use of Distance Constraints in Protein-Protein
Docking Computations. Proteins: Structure, Function, and Bioinformatics, 80 (1),
194205.
Shmygelska, A., & Hoos, H. (2005). An Ant Colony Optimisation Algorithm for the 2D
and 3D Hydrophobic Polar Protein Folding Problem. BMC Bioinformatics, 6, 3052.
Shmygelska, A., & Levitt, M. (2009). Generalized Ensemble Methods for De Novo Structure
Prediction. Proceedings of the National Academy of Science (USA), 106 (5), 1415
1420.
Simoncini, D., Berenger, F., Shrestha, R., & Zhang, K. (2012). A Probabilistic FragmentBased Protein Structure Prediction Algorithm. PLOS One, 7 (7), e38799.
Simons, K., Kooperberg, C., Huang, E., & Baker, D. (1997). Assembly of Protein Tertiary
Structures from Fragments with Similar Local Sequences using Simulated Annealing
and Bayesian Scoring Functions. J. Mol. Biol., 268, 209225.
Skolnick, J., Fetrow, J., & Kolinski, A. (2000). Structural Genomics and its Importance for
Gene Function Analysis. Nat. Biotechnology, 18 (3), 283287.
Soto, C., Fasnacht, M., Zhu, J., Forrest, L., & Honig, B. (2008). Loop Modeling: Sampling,
Filtering, and Scoring. Proteins: Structure, Function, and Bioinformatics, 70, 834
843.
Spassov, V., Flook, P., & Yan, L. (2008). LOOPER: A Molecular Mechanics-based Algorithm for Protein Loop Prediction. Protein Eng, 21, 91100.
Stuckey, P. J., Becket, R., & Fischer, J. (2010). Philosophy of the MiniZinc Challenge.
Constraints, 15 (3), 307316.
Sussmann, G., & Steele, G. (1980). CONSTRAINTS: A Language for Expressing AlmostHierarchical Descriptions. Artificial Intelligence, 14 (1), 139.
999

fiCampeotto, Dal Palu, Dovier, Fioretto, & Pontelli

Sutherland, I. (1963). Sketchpad: A Man-Machine Graphical Communication System. Tech.
rep. 296, Lincoln Laboratory, MIT.
Swedish Institute for Computer Science (2012). SICStus Prolog Home Page. http://www.
sics.se/sicstus/.
Thebault, P., de Givry, S., Schiex, T., & Gaspin, C. (2005). Combining Constraint Processing and Pattern Matching to Describe and Locate Structured Motifs in Genomic
Sequences. In Fifth Workshop on Modeling and Solving Problems with Constraints,
pp. 5360.
Tsai, Y., Huang, Y., Yu, C., & Lu, C. (2004). MuSiC: A Tool for Multiple Sequence
Alignment with Constraints. Bioinformatics, 20 (14), 23092311.
Xiang, Z., Soto, C., & Honig, B. (2002). Evaluating Conformal Energies: The Colony Energy
and its Application to the Problem of Loop Prediction. PNAS, 99, 74327437.
Xu, D., & Zhang, Y. (2012). Ab Initio Protein Structure Assembly Using Continuous
Structure Fragments and Optimized Knowledge-based Force Field. Proteins, 80 (7),
17151735.
Yang, R. (1998). Multiple Protein/DNA Sequence Alignment with Constraints. In International Conference on Practical Applications of Constraint Programming.
Yap, R. (2001). Parametric Sequence Alignment with Constraints. Constraints, 6, 157172.
Yap, R., & Chuan, H. (1993). A Constraint Logic Programming Framework for Constructing
DNA Restriction Maps. Artificial Intelligence in Medicine, 5 (5), 447464.
Yue, K., & Dill, K. (2000). Constraint Based Assembly of Tertiary Protein Structures from
Secondary Structure Elements. Proteins Science, 9 (10), 19351946.
Zhang, M., & Kavraki, L. (2002). A New Method for Fast and Accurate Derivation of
Molecular Conformations. Journal of Chemical Information and Computer Sciences,
42 (1), 6470.
Zhang, Y., & Hauser, K. (2013). Unbiased, Scalable Sampling of Protein Loop Conformations from Probabilistic Priors. BMC Structural Biology, (to appear http:
// www. indiana. edu/ ~ motion/ slikmc/ papers/ BMC_ Zhang. pdf ).
Zhou, H., & Zhou, Y. (2002). Distance-scaled, Finite Ideal-gas Reference State Improves
Structure-derived Potentials of Mean Force for Structure Selection and Stability Prediction. Protein Sci, 11, 27142726.

1000

fiJournal of Artificial Intelligence Research 48 (2013) 841-883

Submitted 06/13; published 11/13

Scalable and Efficient Bayes-Adaptive Reinforcement
Learning Based on Monte-Carlo Tree Search
Arthur Guez

aguez@gatsby.ucl.ac.uk

Gatsby Computational Neuroscience Unit
University College London
London, WC1N 3AR, UK

David Silver

d.silver@cs.ucl.ac.uk

Dept. of Computer Science
University College London
London, WC1E 6BT, UK

Peter Dayan

dayan@gatsby.ucl.ac.uk

Gatsby Computational Neuroscience Unit
University College London
London, WC1N 3AR, UK

Abstract
Bayesian planning is a formally elegant approach to learning optimal behaviour under
model uncertainty, trading off exploration and exploitation in an ideal way. Unfortunately,
planning optimally in the face of uncertainty is notoriously taxing, since the search space
is enormous. In this paper we introduce a tractable, sample-based method for approximate
Bayes-optimal planning which exploits Monte-Carlo tree search. Our approach avoids expensive applications of Bayes rule within the search tree by sampling models from current
beliefs, and furthermore performs this sampling in a lazy manner. This enables it to outperform previous Bayesian model-based reinforcement learning algorithms by a significant
margin on several well-known benchmark problems. As we show, our approach can even
work in problems with an infinite state space that lie qualitatively out of reach of almost
all previous work in Bayesian exploration.

1. Introduction
A key challenge in sequential decision-making is to understand how agents can learn to
collect rewards  and avoid costs  through interactions with the world. A natural way
to characterize these interactions is by a Markov Decision Process (mdp). mdps consist of
a set of states, a set of possible actions, and a transition model that stochastically decides
a successor state from a given state and action. In addition, a cost or reward is associated
with each state and action. The problem for learning arises when some aspects of the
transition model are unknown to the agent, implying uncertainty about the best strategy
for gathering rewards and avoiding costs. Exploration is therefore necessary to reduce this
uncertainty and ensure appropriate exploitation of the environment. Weighing the benefits
of exploring, to identify potentially better actions, against the benefits of exploiting known
sources of rewards is generally referred to as the exploration-exploitation trade-off.
The trade-off can be formalized in various different ways. One possible objective is to
control the number of suboptimal actions the agent ever performs; algorithms that with high
2013 AI Access Foundation. All rights reserved.

fiGuez, Silver, & Dayan

probability can bound the number of such suboptimal steps by a polynomial in the number
of states and actions are said to be pac-mdp (Strehl, Li, & Littman, 2009). Instead of
focusing on suboptimal actions, another objective is to minimize the so-called regret, which
is the expected loss relative to the optimal policy in the mdp (Jaksch, Ortner, & Auer,
2010). Lastly, Bayesian decision theory prescribes maximizing the expected discounted
sum of rewards in the light of a prior distribution over transition models; one way to
achieve this is by solving an augmented mdp, called the Bayes-Adaptive mdp (bamdp), in
which the corresponding augmented dynamics are known (Martin, 1967; Duff, 2002). The
augmentation is the posterior belief distribution over the dynamics, given the data so far
observed. The agent starts in the belief state corresponding to its prior and, by executing
the greedy policy in the bamdp whilst updating its posterior, acts optimally (with respect
to its beliefs) in the original mdp. The Bayes-optimal policy is the optimal policy of the
bamdp; it integrates exploration and exploitation in an ideal manner.
In general, these different objectives are not compatible  see for example the work of
Kolter and Ng (2009) for the incompatibility between pac-mdp and the Bayes-optimal solution. pac-mdp and regret frameworks have gained considerable traction in recent years,
while Bayesian exploration has been comparatively ignored. However, the Bayesian framework is attractive because structured prior knowledge can be incorporated into the solution
in a principled manner, providing the means to tackle, at least in theory, large and complex
unknown environments. Methods tailored for objectives such as pac-mdp or regret minimization cannot so far easily be adapted to exploit such priors. With no other assumption
about the environment, they are thus forced to explore every state and action at least once,
which is hopeless in large environments.
Unfortunately, exact Bayesian reinforcement learning (RL) is computationally intractable.
Various algorithms have been devised to approximate optimal learning, but often at rather
large cost. This computational barrier has restricted Bayesian RL to small domains with
simple priors. In this paper, we present a tractable approach that exploits and extends
recent advances in Monte-Carlo tree search (mcts) (Kocsis & Szepesvari, 2006), notably
to partially-observable mdps (Silver & Veness, 2010) of which the bamdp can be seen as a
special case. While mcts is capable of tackling large mdp problems when the dynamics are
known (Gelly, Kocsis, Schoenauer, Sebag, Silver, Szepesvari, & Teytaud, 2012), we show
that a naive application of mcts to the bamdp is not tractable in general and we propose
a set of principled modifications to obtain a practical algorithm, which is called bamcp for
Bayes-Adaptive Monte-Carlo Planner.
At each iteration in bamcp, as in the pomcp algorithm (Silver & Veness, 2010), a single
mdp is sampled from the agents current beliefs. This mdp is used to simulate a single
episode whose outcome is used to update the value of each node of the search tree traversed
during the simulation. By integrating over many simulations, and therefore many sample
mdps, the optimal value of each future sequence is obtained with respect to the agents
beliefs. We prove that this process converges to the Bayes-optimal policy, given infinite
samples. Since many of the priors that are appropriate in the Bayesian RL setting require
some form of approximate inference, we extend the convergence proof to show that bamcp
also converges when combined with a Markov Chain Monte Carlo-based inference scheme.
Our algorithm is more efficient than previous sparse sampling methods for Bayes-adaptive
planning (Wang, Lizotte, Bowling, & Schuurmans, 2005; Castro, 2007; Asmuth & Littman,
842

fiBayes-Adaptive Monte-Carlo Planning

2011), partly because it does not update the posterior belief state during the course of
each simulation. It thus avoids repeated applications of Bayes rule, which is expensive for
all but the simplest priors over the mdp. To increase computational efficiency further, we
introduce an additional innovation: a lazy sampling scheme that only samples the posterior
distribution for states traversed during the simulation.
We applied bamcp to a representative sample of benchmark problems and competitive algorithms from the literature. It consistently and significantly outperformed existing
Bayesian RL methods, and also recent non-Bayesian approaches, thus achieving state-ofthe-art performance.
Further, bamcp is particularly well suited to support planning in large domains in which
richly structured prior knowledge makes lazy sampling both possible and effective. This
offers the prospect of applying Bayesian RL at a realistically complex scale. We illustrate
this possibility by showing that bamcp can tackle a domain with an infinite number of
states and a structured prior over the dynamics, a challenging, if not radically intractable,
task for existing approaches. This example exploits bamcps ability to use Markov chain
Monte Carlo methods for inference associated with the posterior distribution over models.
The paper is organized as follows. First, we formally define the Bayesian model-based
RL problem and review existing methods; we then present our new algorithm in the context
of previous suggestions; and finally we report empirical results on existing domains and on
the new, infinite, task. Some of these results appeared in a short conference version of this
paper (Guez, Silver, & Dayan, 2012).

2. Model-Based Reinforcement Learning
We first briefly review model-based reinforcement learning and search algorithms in the
case that the model is known. We then introduce the formalism of Bayesian model-based
RL and provide a survey of existing approximation algorithms that motivate our approach.
2.1 Model-Based Reinforcement Learning with Known Model
An mdp is described as a 5-tuple M = hS, A, P, R, i, where S is the discrete set of states,
A is the finite set of actions, P : S  A  S  R is the state transition probability kernel,
R : S  A  R is a bounded reward function, and  is the discount factor (Szepesvari,
2010). A deterministic stationary mdp policy  is defined as a mapping  : S  A from
states to actions. The value function of a policy  at state s  S is its expected return,
defined as:
"
#
X


t
V (s)  E
 rt |s0 = s ,
(1)
t=0

where rt is the random reward obtained at time t when following policy  from state s
 E denotes the expectation operator that averages over all possible paths that policy
 implies. A related quantity is the action-value function of a policy  for executing a
843

fiGuez, Silver, & Dayan

particular action a  A at state s  S before executing :
"
#
X
X

0

t1
0
Q (s, a)  R(s, a) + 
P(s, a, s )EM
 rt |s1 = s
s0 S

= R(s, a) + 

X

(2)

t=1

P(s, a, s0 )V  (s0 ),

(3)

s0 S

implying the relation V  (s) = Q (s, (s)). The optimal action-value function, denoted Q ,
provides the maximum expected return Q (s, a) that can be obtained after executing action
a in state s. The optimal value function, V  , is similarly defined and is related to Q as
V  (s) = maxaA Q (s, a), s  S. An optimal policy   achieves the maximum expected
return from all states, and can be obtained from Q as:   (s) = argmaxaA Q (s, a),
breaking ties arbitrarily.
When all the components of the mdp tuple are known  including the model P 
standard mdp planning algorithms can be used to estimate the optimal policy off-line,
such as Value Iteration or Policy Iteration (Bellman, 1954; Ross, 1983; Sutton & Barto,
1998; Szepesvari, 2010). However, it is not always practical to find the optimal policy for
all states in large mdps in one fell swoop. Instead, there are methods that concentrate on
searching online for the best action at just the current state st . This is particularly common
for model-based Bayesian RL algorithms. We therefore introduce relevant existing online
search methods for mdps that are used as building blocks for Bayesian RL algorithms.
2.1.1 Online Search
Online search methods evaluate a tree of possible future sequences. The tree is rooted at
the current state and is composed of state and action nodes. Each state node, including the
root, has as its children all the actions that are legal from that state. In turn, each action
node has as its children all the successor states resulting from that action. The goal of the
forward search algorithm is recursively to estimate the value of each state and action node
in the tree. Ultimately, the value of each possible action from the root is used to select the
next action, and the process repeats using the new state at the root.
Online search methods may be categorised firstly by the backup method by which the
value of each node is updated, and secondly by the order in which the nodes of the tree are
traversed and backups are applied.
2.1.2 Full-Width Search
Classical online search methods are based on full-width backups, which consider all legal
actions and all possible successor states, for example using a Bellman backup,

V (s)  max R(s, a) + 
aA

X

P(s, a, s0 )V (s0 )

(4)

s0 S

Search efficiency is then largely determined by the order in which nodes are traversed.
One example is best-first, for which the current best is usually determined according to an
optimistic criterion. This leads to an algorithm resembling A (Hart, Nilsson, & Raphael,
844

fiBayes-Adaptive Monte-Carlo Planning

1968), which applies in the deterministic case. The search tree may also be truncated,
using knowledge of the most extreme reward and the discount factor to ensure that this is
provably benign (Davies, Ng, & Moore, 1998). If one is prepared to give up guarantees on
optimality, an approximate value function (typically described in the online search literature
as a heuristic function or evaluation function) can be applied at leaf nodes to substitute for
the value of the truncated subtree.
2.1.3 Sample-Based Search
Rather than expanding every tree node completely, sample-based search methods overcome
the curse of dimensionality by just sampling successor states from the transition distribution.
These have the generic advantage over full-width search that they expend little effort on
unlikely paths in the tree.
Sparse Sampling
Sparse Sampling (Kearns, Mansour, & Ng, 1999) is a sample-based online search algorithm.
The key idea is to sample C successor nodes from each action node, and apply a Bellman
backup to these sampled transitions, so as to update the value of the parent state node
from the values of the child nodes:
C
 X
Vd (s) = max R(s, a) +
Vd+1 (child(s, a, i)).
aA
C

(5)

i=1

The search tree is traversed in a depth-first manner, and an approximate value function
is employed at truncated leaf nodes, after some pre-defined depth D. Sparse Sampling
converges to a near-optimal policy given an appropriate choice of the parameters C and D.
FSSS
Although Sparse Sampling concentrates on likely transitions, it does not focus search on
nodes that have relatively high values or returns. In the work of Walsh, Goschin, and
Littman (2010), Forward Search Sparse Sampling (fsss) extends regular Sparse Sampling
by maintaining both lower and upper bounds on the value of each node:
Ld (s, a) = R(s, a) +
Ud (s, a) = R(s, a) +


C

C

X

Ld+1 (s0 )Count(s, a, s0 ),

(6)

Ud+1 (s0 )Count(s, a, s0 ),

(7)

s0 Child(s,a)

X
s0 Child(s,a)

Ld (s) = max Ld (s, a),

(8)

Ud (s) = max Ud (s, a),

(9)

aA

aA

where Child(s, a) is the set of successor states sampled from C draws of P(s, a, ), and
Count(s, a, s0 ) is the number of times each set element was sampled. Whenever a node
is created, the lower and upper bounds are initialized according to Ld (s, a) = Vmin and
845

fiGuez, Silver, & Dayan

Ud (s, a) = Vmax , i.e., the worst and best possible returns. The tree is traversed in a bestfirst manner according to these value bounds, starting from the root for each simulation
through the tree. At each state node, a promising action is selected by maximising the
upper bound on value. At each action (or chance) node, successor states are selected
from a sampled set of C candidates by maximising the uncertainty (upper minus lower
bound). This effectively prunes branches of the tree that have low upper bounds before
they are exhaustively explored, while still maintaining the theoretical guarantees of Sparse
Sampling.
Monte-Carlo Tree Search
Despite their theoretical guarantees, in practice, sparse sampling and fsss both suffer from
the fact that they truncate the search tree at a particular depth, and so experience bias
associated with the approximate value function they use at the leaves. Monte-Carlo Tree
Search (mcts) provides a way of reducing the bias by evaluating leaves exactly using the
model, but employing a sub-optimal, rollout policy. More formally, in mcts, states are
evaluated by averaging over many simulations. Each simulation starts from the root and
traverses the current tree until a leaf is reached, using a tree policy (e.g., greedy action
selection) based on information that has so far been gathered about nodes in the tree. This
results in a (locally) best-first tree traversal, where at each step the tree policy selects the
best child (best according to some exploration criterion) given the current values in the tree.
Rather than truncating the search and relying on a potentially biased value function at leaf
nodes, a different policy, called a rollout policy (e.g., uniform random) is employed from
the leaf node until termination or a search horizon. Each node traversed by the simulation
is then updated by a Monte-Carlo backup, which simply evaluates that node by the mean
outcome of all simulations that passed through that node. Specifically, the Monte-Carlo
backups update the value of each action node as follows:
Qd (s, a)  Qd (s, a) + (R  Qd (s, a))/Nd (s, a),

(10)

where R is the sampled discounted return obtained from the traversed action node s, a at
depth d and Nd (s, a) is the visitation count for the action node s, a (i.e., the update computes
the mean of the sampled returns obtained from that action node over the simulations).
A particular tree policy for mcts that has received much attention, and indeed underlies
our algorithm, is the uct (Upper Confidence bounds applied to Trees) policy (Kocsis &
Szepesvari, 2006). uct employs the ucb (Upper Confidence Bounds) algorithm (Auer,
Cesa-Bianchi, & Fischer, 2002), designed for multi-armed bandit problems, to select adaptively between actions at every state node according to:
p
argmax Qd (s, a) + c log(Nd (s))/Nd (s, a),
(11)
aA

where c is an exploration constant that needs to be set appropriately and Nd (s) is the
visitation count for the state node s. This tree policy treats the forward search as a metaexploration problem, preferring to exploit regions of the tree that currently appear better
than others, while continuing to explore unknown or less known parts of the tree. This leads
to good empirical results even for small numbers of simulations, because effort is expended
846

fiBayes-Adaptive Monte-Carlo Planning

where search seems fruitful. Nevertheless all parts of the tree are eventually visited infinitely
often, and therefore the algorithm can be shown to converge to the optimal policy in the
very long run.
Despite some negative theoretical results showing that uct can be slow to find optimal
policies in carefully designed counterexample mdps (Coquelin & Munos, 2007), uct has
been successful in many large mdp domains (Gelly et al., 2012).
2.2 Model-Based Bayesian Reinforcement Learning
The methods we have so far discussed depend on the agent having a model of the world, i.e.,
the dynamics P. The key concern for Bayesian RL is acting when this model is not fully
known. We first describe the generic Bayesian formulation of optimal decision-making in an
unknown mdp, following Martin (1967) and Duff (2002), and then consider approximations
inspired by the intractability of the full problem.
2.2.1 The Formalism
Given that the dynamics P  P (coming from the set of all possible models) are only
incompletely known, Bayesian RL treats them as a latent random variable which follows a
prior distribution P (P). Observations about the dynamics contained in the history ht (at
time t) of actions and states: ht  s1 a1 s2 a2 . . . at1 st , duly lead to a posterior distribution
over P via a likelihood.
The history ht influences the posterior distribution. Thus policies  that integrate
exploration and exploitation (called EE policies) for a Bayesian RL problem will generically
have to take this history into account, along with the current state, in order to specify what
action to take. That is, whereas when P is known, a policy  can be defined as a mapping
 : S  A  [0, 1] from just the current state and actions to a probability (of execution), for
Bayesian RL, EE policies are defined as mappings from history, current state, and action
to a probability  : S  H  A  [0, 1], where H is the set of possible histories.1 We denote
by  the set of all EE policies.
The objective for an EE policy under the Bayesian formulation is to maximize the
expected return (sum of discounted rewards), where the expectation is taken over the distribution of environments P (P) = P (P |), in addition to taking the usual expectation over
the stochasticity of the return induced by the dynamics. Formally, we define this expected
discounted return v starting from a state s after seeing history h when following an EE
policy  as:
"
#
X
v(s, h, ) = E
 t rt |s0 = s, h0 = h
(12)
t=0

Z
=
P

=

"
dP P (P |h) EM (P)

X
a0 A


X

#
 t rt |s0 = s, h0 = h

(13)

t=0

R(s, a0 ) + 

X

(s, h, a0 )v(s0 , ha0 s0 , )P(s, a0 , s0 , h),

(14)

s0 S

1. The redundancy in the state-history notation throughout this paper, namely that the current state could
be extracted from the history, is only present to ensure clarity of exposition.

847

fiGuez, Silver, & Dayan

R
where P(s, a, s0 , h)  P dP P (P |h) P(s, a, s0 ) denotes the probability of transitioning from
state s to s0 after executing a under a distribution of dynamics P (P |h), and M (P) denotes
the mdp associated with dynamics P.
Definition 1 Given S, A, R, , and a prior distribution P (P) over the dynamics of the
mdp M , let
v  (s, ) = sup v(s, , ).

(15)



Martin (1967, Thm. 3.2.1) shows that there exists a strategy     that achieves that
expected return (i.e., v(s, ,   ) = v  (s, )). Any such EE strategy   is called a Bayesoptimal policy.2
This formulation prescribes a natural recipe for computing the Bayes-optimal policy.
After observing history ht from the mdp, the posterior belief over P is updated using Bayes
rule P (P|ht )  P (ht |P)P (P) (or in recursive form P (P|ht )  P(st1 , at1 , st )P (P|ht1 )).
Thus, the uncertainty about the dynamics of the model can be transformed into certainty
about the current state inside an augmented state space S + = S  H, where S is the state
space in the original problem and H is the set of possible histories. The dynamics associated
with this augmented state space are described by
Z
P + (hs, hi, a, hs0 , h0 i) = 1[h0 = has0 ]
P(s, a, s0 )P (P|h) dP,
(16)
P

and the reward function is simply the projected reward function in the original mdp:
R+ (hs, hi, a) = R(s, a).

(17)

Together, the 5-tuple M + = hS + , A, P + , R+ , i forms the Bayes-Adaptive mdp (bamdp)
for the mdp problem M . Since the dynamics of the bamdp are known, it can in principle
be solved to obtain the optimal value function associated with each action:
"
#
X 0


t t
Q (hst , ht i, a) = max EM +

rt0 |at = a
(18)


t0 =t

from which the optimal action for each state can be readily derived. Optimal actions in the
bamdp are executed greedily in the real mdp M and constitute the best course of action
for a Bayesian agent with respect to its prior belief over P:
Proposition 1 (Silver, 1963; Martin, 1967) The optimal policy of the bamdp is the
Bayes-optimal policy, as defined in Definition 1.
It is obvious that the expected performance of the bamdp policy in the mdp M is
bounded above by that of the optimal policy obtained with a fully-observable model, with
2. The proof by Martin (1967) only covers finite state spaces, but it can be extended to specific kinds of
infinite state spaces such as the one we consider in Section 4.2, see Appendix D for details.

848

fiBayes-Adaptive Monte-Carlo Planning

equality occurring, for example, in the degenerate case in which the prior only has support
on the true model.
The Bayes-optimal policy is stationary as a function of the augmented state, but evolves
over time when observed in the context of the original mdp  as a function of the state in
S only. Since the uncertainty about the dynamics is taken into account in the optimization
of the return, the Bayes-optimal policy integrates exploration and exploitation optimally.
It can be useful to observe that the bamdp is a particular form of Partially Observable
mdp (pomdp). The state space of this pomdp is S  P, where P is the set of all possible
models P. The second component of the state space is static and hidden, and partially
observed through experienced transitions. Planning can be conducted in the belief space,
or equivalently in the space of sufficient statistics of the belief distribution, allowing decisions
to be taken in the light of their likely outcomes in gathering exploitable information about
the hidden state. In the case of bamdp, such actions gather information about the hidden
model P. However, the pomdp is not a discrete pomdp since its state space is continuous
(with discrete observations). Therefore, as pointed out by Duff (2002), many classical
solutions to pomdps cannot be directly applied to the bamdp.
From a practical perspective, solving the bamdp exactly is computationally intractable,
even for small state spaces. First, the augmented state space contains all possible histories
and is therefore infinite. Second, the transitions of the bamdp, described in Equation 16,
require an integration of transition models over the posterior. Although this operation can
be trivial for some simple probabilistic models (e.g., independent Dirichlet-Multinomial), it
is intractable for most priors of interest (see Section 4.2 for an example). However, certain
special cases of the bamdp are known to be somewhat more tractable. For example, the
celebrated Gittins indices provide a shortcut solution for bandit problems (Gittins, Weber,
& Glazebrook, 1989), although calculating these indices remains a challenge in general.
Further, the optimal solution to at least some finite-horizon linear-Gaussian control problems can be computed exactly (Tonk & Kappen, 2010). Nevertheless, it appears unlikely
that there exists a tractable exact algorithm to solve general bamdps, justifying a search
for sound and efficient approximations.
2.2.2 Approximate Bayes-Adaptive Algorithms
Three coarse classes of approximation methods have been developed, which we now review.
Note that all of them have analogues in solution methods for pomdps.
First are offline methods that toil mightily to provide execution policies that can be used
for any observed augmented state. Second and third are two sets of online methods that
concentrate on just the current augmented state. One set of methods uses sparse sampling
in the full tree of future states and actions associated with the bamdp, starting from the
current augmented state. The other samples and solves one or more mdps from the current
posterior over P, possibly correcting for the bias towards exploitation to which this typically
leads.
After describing these classes, we highlight what they currently lack, and so establish
the basis for our new algorithm, bamcp.
849

fiGuez, Silver, & Dayan

Offline Methods
One idea is to solve the entire bamdp offline, for every state and belief (or history). This
obviates the need for anything other than a simple value/policy lookup during execution.
However, this avenue for approximation has not led to much practical success  presumably
because of the difficulties associated with the size of the bamdp, including the fact that
gargantuan amounts of computation may be performed to find good policies in parts of the
space of histories that are actually not sampled in practice.
Existing approaches in this class include an actor-critic algorithm (Duff, 2003), which
does learning, and a point-based value iteration algorithm, called beetle (Bayesian Exploration Exploitation Tradeoff in LEarning) (Poupart, Vlassis, Hoey, & Regan, 2006).
beetle builds an approximate policy off-line by exploiting facets of the structure of the
value functions for bamdps, which they inherit from their broader, parent, class of pomdps.
More recently, Wang, Won, Hsu, and Lee (2012) propose to solve an offline pomdp by representing the latent dynamics as a discrete partially-observed state component, where the
value of this state component corresponds to one of K possible models sampled from the
prior. Their approach can fail if the true model is not well-represented in these K sampled
models.
Offline methods are particularly poorly suited to problems such as the infinite state task
we consider in section 4.2.
Online Methods: Sparse Sampling
Online methods reduce the dependency on the size of the bamdp by approximating the
bamdp solution around the current (augmented) state of the agent and running a planning
algorithm at each step.
One idea is to perform forms of forward search from the current state. Although these
methods concentrate on the current state, the search tree is still large and it can be expensive
to evaluate a given path in the tree. In partial alleviation of this problem, most approaches
rely on some form of sparse, non-uniform, tree exploration to minimize the search effort
(but see also Fonteneau, Busoniu, & Munos, 2013). While Section 2.1.3 described search
algorithms for mdps, here we present existing extensions to the bamdp setting. Analogous
methods for pomdps are reviewed by Ross, Pineau, Paquet, and Chaib-Draa (2008).
Wang et al. applied Sparse Sampling to search online in bamdps (Wang et al., 2005),
expanding the tree non-uniformly according to sampled trajectories. At each state node, a
promising action is selected via Thompson sampling (Thompson, 1933; Agrawal & Goyal,
2011)  i.e., sampling an mdp from the belief-state, solving the mdp and taking the optimal
action. As in Sparse Sampling, this fails to exploit information about the values of nodes
in prioritizing the sampling process. At each chance (action) node, a successor belief-state
is sampled from the transition dynamics of the bamdp.
Castro et al. applied Sparse Sampling to define a relevant region of the bamdp for the
current decision step. This leads to an optimization problem that is solved using Linear
Programming (Castro & Precup, 2007).
Asmuth and Littmans bfs3 algorithm (Asmuth & Littman, 2011) adapts Forward
Search Sparse Sampling (Walsh et al., 2010) to the bamdp (treated as a particular mdp).
Although bfs3 is described as Monte-Carlo tree search, it in fact uses a Bellman backup
850

fiBayes-Adaptive Monte-Carlo Planning

rather than Monte-Carlo evaluation. As in fsss, each Bellman backup updates both lower
and upper bounds on the value of each node.
Online Methods: Dual Optimism
Instead of applying sparse sampling methods in the tree of future states and actions, an
alternative collection of methods derives one or more simpler mdps from the posterior at a
current augmented state, whose solution is often computationally straightforward. By itself,
this leads to over-exploitation: corrections are thus necessary to generate sufficient exploration. Exploration can be seen as coming from optimism in the face of uncertainty  actions
that have yet to be tried sufficiently must look more attractive than their current mean.
Indeed, there are various heuristic forms of exploration bonus (Sutton, 1990; Schmidhuber,
1991; Dayan & Sejnowski, 1996; Kearns et al., 1999; Meuleau & Bourgine, 1999; Brafman
& Tennenholtz, 2003) that generalize the optimism inherent in optimal solutions such as
Gittins indices.
One such approximation was first derived in the work of Cozzolino, Gonzalez-Zubieta,
and Miller (1965), where the mean estimate of the transition probabilities (i.e., the mean of
the posterior) was employed as a certainty equivalence approximation. Solving the corresponding mean mdp induces some form of optimism, but it is not always sufficient to drive
exploration. This idea was revisited and linked to reinforcement learning formulations by
Dayan and Sejnowski (1996).
Another way to induce optimism is to exploit the variance in the posterior when sampling
mdps at an augmented state. One of these approaches is the Bayesian DP algorithm (Strens,
2000). At each step (or after every couple of steps), a single model is sampled from the
posterior distribution over transition models, and the action that is optimal in that model is
executed. Although a popular approach in practice, this algorithm does not have a known
theoretical guarantee relating it to the Bayes-optimal solution. In the Bandit case, this
reduces to Thompson Sampling. Optimism is generated because solving posterior samples
is likely to yield optimistic values in some unknown parts of the mdp (where posterior
entropy is large) and that will force the agent to visit these regions. The Best Of Sampled
Set (boss) algorithm generalizes this idea (Asmuth, Li, Littman, Nouri, & Wingate, 2009).
boss samples a number of models from the posterior and combines them optimistically. This
drives sufficient exploration to guarantee some finite-sample performance guarantees, but
these theoretical guarantees cannot be easily related to the Bayes-optimal solution. boss is
quite sensitive to its parameter that governs the sampling criterion, which is unfortunately
difficult to select. Castro and Precup proposed a variant, referred to as sboss, which
provides a more effective adaptive sampling criterion (Castro & Precup, 2010).
One can also see certain non-Bayesian methods in this light. For instance, Bayesian
Exploration Bonus (beb) solves the posterior mean mdp, but with an additional reward
bonus that depends on visitation counts (Kolter & Ng, 2009). This bonus is tailored such
that the method satisfies the so-called pac-bamdp property, which generalizes the pac-mdp
mentioned in the introduction, and implies limiting to a polynomial factor the number of
steps in which the EE policy is different than the Bayes-optimal policy. A more recent
approach is the bolt algorithm, which merges ideas from beb and boss, enforces optimism
in the transitions by (temporarily) adding fictitious evidence that currently poorly-known
851

fiGuez, Silver, & Dayan

actions lead to currently poorly-known states (Araya-Lopez, Buffet, & Thomas, 2012). bolt
also has the pac-bamdp property.
Discussion of Existing Methods
Despite the recent progress in approximation algorithms, tackling large domains with complex structured priors remains out of computational reach for existing Bayesian RL methods.
Unfortunately, it is exactly in these structured domains that Bayesian methods should shine,
since they have the statistical capacity to take advantage of the priors.
Methods that tackle the bamdp directly such as forward-search methods, suffer from
the repeated computation of the bamdp dynamics inside the search tree for most priors.
That is, to compute a single bamdp transition in Equation 16, one needs to apply Bayes
rule and perform an integration over all possible models. This can be done cheaply for
simple priors, but can be rather expensive for arbitrary priors.
On the other hand, optimism-based methods are attractive because they appear more
tractable  since they are dealing with smaller mdps. However, it turns out to be hard
to translate sophisticated prior knowledge into the form of a bonus  existing methods
are only compatible with simple Dirichlet-Multinomial models. Moreover, the behavior in
the early steps of exploration can be very sensitive to the precise parameter inducing the
optimism.
We therefore developed an approximation algorithm for Bayesian RL that is compatible
with complex priors, while maintaining efficiency and (Bayesian) soundness, so that large
EE tasks can be approached in a principled way. Our approach adapts the pomcp MonteCarlo tree search algorithm (Silver & Veness, 2010), which avoids expensive applications
of Bayes rule by only sampling at the root of the tree. It also extends the approach by
introducing a novel scheme for lazy sampling. This makes it possible to search locally in
finite portions of large or even infinite domains.

3. The BAMCP Algorithm
To reiterate, the goal of a bamdp planning method is to find, for each decision point hs, hi
encountered, the action a that at least approximately maximizes the future expected return
(i.e., find an optimal EE policy   (s, h)). Our algorithm, Bayes-Adaptive Monte-Carlo
Planning (BAMCP), does this by performing a forward-search in the space of possible
future histories of the bamdp using a tailored Monte-Carlo tree search.
We employ the uct algorithm, as presented in Section 2.1.3, to allocate search effort to
promising branches of the state-action tree, and use sample-based rollouts to provide value
estimates at each node. For clarity, let us denote by Bayes-Adaptive uct (ba-uct) the
algorithm that applies vanilla uct to the bamdp (i.e., the particular mdp with dynamics
described in Equation 16).3 Sample-based search in the bamdp using ba-uct requires the
generation of samples from P + for every step of each simulation  an expensive procedure
for all but the simplest generative models P (P). We avoid this cost by only sampling a
single transition model P i from the posterior at the root of the search tree at the start of
3. While using uct to solve bamdps is mentioned by Asmuth and Littman (2011), we are not aware of any
published work that evaluated the performance of ba-uct.

852

fiBayes-Adaptive Monte-Carlo Planning

each simulation i, and using P i to generate all the necessary samples during this simulation.
Sample-based tree search then acts as a filter, ensuring that the correct distribution of state
successors is obtained at each of the tree nodes, as if it was sampled from P + . This root
sampling method was originally introduced in the pomcp algorithm (Silver & Veness, 2010),
developed to solve discrete-state pomdps.
Combining ba-uct with a version of root sampling forms the basis of the proposed
bamcp algorithm; this is detailed in Section 3.1. In addition, bamcp also takes advantage
of lazy sampling to reduce sampling complexity at the root, this is detailed in Section 3.2.
Finally, bamcp integrates rollout learning to improve the rollouts online, this is detailed in
Section 3.3. In Section 3.4, we show that bamcp converges to the Bayes-optimal solution.
Subsequent sections provide empirical results.
3.1 BA-UCT with Root Sampling
The root node of the search tree at a decision point represents the current state of the
bamdp. The tree is composed of state nodes representing belief states hs, hi and action
nodes representing the effect of particular actions from their parent state node. The visit
counts: N (hs, hi) for state nodes, and N (hs, hi, a) for action nodes, are initialized to 0 and
updated throughout search. A value, Q(hs, hi, a), which is initialized to 0, is also maintained
for each action node.
Each simulation traverses the tree without backtracking
by following the uct policy
p
at state nodes defined by argmaxa Q(hs, hi, a) + c log(N (hs, hi))/N (hs, hi, a), where c is an
exploration constant that needs to be set appropriately. Given an action, the transition
distribution P i corresponding to the current simulation i is used to sample the next state.
That is, at action node (hs, hi, a), s0 is sampled from P i (s, a, ), and the new state node is
set to hs0 , has0 i.
When a simulation reaches a leaf, the tree is expanded by attaching a new state node
with its connected action nodes, and a rollout policy ro is used to control the mdp defined
by the current P i . This policy is followed to some fixed total depth (determined using the
discount factor). The rollout provides an estimate of the value Q(hs, hi, a) from the leaf
action node. This estimate is then used to update the value of all action nodes traversed
during the simulation: if R is the sampled discounted return obtained from a traversed
action node (hs, hi, a) in a given simulation, then we update the value of each action node
to Q(hs, hi, a)+ (R  Q(hs, hi, a))/N (hs, hi, a) (i.e., the mean of the sampled returns obtained from
that action node over the simulations).
A detailed description of the bamcp algorithm is provided in Algorithm 1. A diagram
example of bamcp simulations is presented in Figure 1. In Section 3.4, we show bamcp
eventually converges to the Bayes-optimal policy.
Finally, note that the history of transitions h is generally not the most compact sufficient statistic of the belief in fully observable mdps. It can, for instance, be replaced with
unordered transition counts , considerably reducing the number of states of the bamdp
and, potentially the complexity of planning. bamcp can search in this reduced search space,
which takes the form of an expanding lattice rather than a tree. We found this version of
bamcp to offer only a marginal improvement. This is a common finding for mcts, stemming from its tendency to concentrate search effort on one of several equivalent paths (up
853

fiGuez, Silver, & Dayan

1.

2.
Past

Past

Planning

Planning

Tree policy

Tree policy

Rollout
policy

Rollout
policy

0

0

0

4.

3.

0

2

Past

Past

Planning

Planning

Tree policy

Tree policy

Rollout
policy

Rollout
policy

0

0

2

0

Figure 1: This diagram presents the first 4 simulations of bamcp in an mdp with 2 actions from state
hst , ht i. The rollout trajectories are represented with dotted lines (green for the current rollouts,
and greyed out for past rollouts). 1. The root node is expanded with two action nodes. Action
a1 is chosen at the root (random tie-breaking) and a rollout is executed in P 1 with a resulting
value estimate of 0. Counts N (hst , ht i) and N (hst , ht i, a1 ), and value Q(hst , ht i, a1 ) get updated.
2. Action a2 is chosen at the root and a rollout is executed with value estimate 0. Counts and
value get updated. 3. Action a1 is chosen (tie-breaking), then s0 is sampled from P 3 (st , a1 , ).
State node hs0 , ht a1 s0 i gets expanded and action a1 is selected, incurring a reward of 2, followed
by a rollout. 4. The UCB rule selects action a1 at the top, the successor state s0 is sampled from
P 4 (st , a1 , ). Action a2 is chosen from the internal node hs0 , ht a1 s0 i, followed by a rollout using
P 4 and ro . A reward of 2 is obtained after 2 steps from that tree node. Counts for the traversed
nodes are updated and the MC backup updates Q(hs0 , ht a1 s0 i, a1 ) to R = 0+0+ 2 2+ 3 0+   =
2 2 and Q(hst , ht i, a1 ) to  + 2 3  /3 = 32 ( +  3 ).

854

fiBayes-Adaptive Monte-Carlo Planning

Algorithm 1: BAMCP

procedure Search( hs, hi )
repeat
P  P (P|h)
Simulate(hs, hi, P, 0)
until Timeout()
return argmax Q(hs, hi, a)
a

end procedure

procedure Rollout(hs, hi, P, d )
if  d Rmax <  then
return 0
end
a  ro (hs, hi, )
s0  P(s, a, )
r  R(s, a)
return
r+Rollout(hs0 , has0 i, P, d+1)
end procedure

procedure Simulate( hs, hi, P, d)
if  d Rmax <  then return 0
if N (hs, hi) = 0 then
for all a  A do
N (hs, hi, a)  0,
Q(hs, hi, a))  0
end
a  ro (hs, hi, )
s0  P(s, a, )
r  R(s, a)
R  r +  Rollout(hs0 , has0 i, P, d)
N (hs, hi)  1, N (hs, hi, a)  1
Q(hs, hi, a)  R
return R
end
q
(hs,hi))
a  argmax Q(hs, hi, b) + c log(N
N (hs,hi,b)
b

s0  P(s, a, )
r  R(s, a)
R  r +  Simulate(hs0 , has0 i, P, d+1)
N (hs, hi)  N (hs, hi) + 1
N (hs, hi, a)  N (hs, hi, a) + 1
Q(hs, hi, a)  Q(hs, hi, a) +

RQ(hs,hi,a)
N (hs,hi,a)

return R
end procedure

to transposition), implying a limited effect on performance of reducing the number of those
paths.
Note that an algorithm very similar to ba-uct with root sampling also appeared in the
work of Vien and Ertel (2012), shortly after bamcp was originally published by Guez et al.
(2012).
3.1.1 Root Sampling at Work in a Simple Example
We illustrate the workings of bamcp, in particular root sampling, in a simulated example
that showcases a crucial component of Bayes-adaptivity.
Consider a simple prior distribution on two mdps (P 0 and P 1 ), illustrated in Figure 2,
where P (P = P 0 ) = P (P = P 1 ) = 21 . The mdps are episodic and stop at the leaves,
and an episode starts in s0 . From state s1 or s2 , any action has an expected reward of
0 under the prior distribution over mdps. Nevertheless, the outcome of a transition from
action a0 in state s0 carries information about the identity of the mdp, and allows a Bayesadaptive agent to take an informed decision in state s1 or s2 . Using Bayes-rule, we have
that P (P = P 0 |s0 a0 s1 )  P (s0 a0 s1 | P = P 0 )P (P = P 0 ) = 0.8.
855

fiGuez, Silver, & Dayan

s0
a0

a1

s1 p = 0.8 s2 p = 0.2
a0

a1

s3 p = 1
+2

a0
s4 p = 1
2
(a)

s5 p = 1
0

a1

s4 p = 1
2

s3 p = 1
+2

P = P0
s0
a0

a1

s1 p = 0.2 s2 p = 0.8
a0

a1

s4 p = 1
2

a0
s3 p = 1
+2
(b)

s3 p = 1
+2

a1

s5 p = 1
0
s4 p = 1
2

P = P1

Figure 2: The two mdps of Section 3.1.1, with prior probability P (P = P 0 ) = P (P = P 1 ) =
1
2 . Differences between the two mdps are highlighted in blue.

We can therefore compute the optimal values:
(
2P (P = P 0 |h)  2P (P = P 1 |h)

V (h = s0 a0 s1 ) = max
2P (P = P 1 |h)  2P (P = P 0 |h)

(19)

= 2  0.8  2  0.2 = 1.2 (= V  (h = s0 a0 s2 ))
V  (h = s0 ) = max{0, 1.2} = 1.2.
We now simulate bamcp on this simple example for the first decision in state s0 . With
root sampling, bamcp only samples either P 0 or P 1 with equal probability at the root of the
tree, and does not perform any explicit posterior update inside the tree. Yet, as suggested
by Lemma 1, we expect to find the correct distribution P (P = P 0 |s0 a0 s1 ) of samples of
P at the tree node hs0 a0 s1 i. Moreover, bamcp should converge to the optimal values V 
according to Theorem 1. This is what is observed empirically in Figure 3.
In the second row of Figure 3, we observe that Q(s0 a0 s1 , a1 ) is slower to converge
compared to other values. This is because time is ticking more slowly for this non-optimal
node (i.e., a small fraction of simulations reach this node) so the value stays put for many
simulations.
3.2 Lazy Sampling
In previous work on sample-based tree search, indeed including pomcp (Silver & Veness,
2010), a complete sample state is drawn from the posterior at the root of the search tree.
However, this can be computationally very costly. Instead, we sample P lazily, generating
856

fiBayes-Adaptive Monte-Carlo Planning

2

2

1.5

1.5

Value

1

V
V
V
V

0.5
0
0.5
1

0

200

400

600

800

1000

1200

1400

( s 0a 0s 1)

( s 0a 0s 1)
( s 0)

( s 0)
1600

1800

1
0.5
0
0.5
2000

1

0

5

10
4

x 10
0.5

0.5

Q( s 0 a 0 s 1 , a 1 )
Q ( s 0a 0s 1, a 1)

Value

1

1.5

2

1

1.5

0

200

400

600

800

1000

1200

1400

1600

1800

2000

2

0

5

10
4

x 10
1

1

P s 0 a 0 s(1 P = P 1 )
P ( P = P 1| s 0a 0s 1)

Probability

0.8
0.6

0.8
0.6

P s 0 a 0 s(1 P = P 0 )
P ( P = P 0| s 0a 0s 1)

0.4

0.4

0.2
0

0.2
0

200

400

600

800

1000

1200

Number of simulations

1400

1600

1800

2000

0

0

5

10
4

x 10

Figure 3: Tracking of different internal variables of bamcp for the example of Section 3.1.1 with  = 0.9.
bamcp is run at the starting state for a number of simulations (x-axis) and with c = 20. The
first two rows show the evolution of values at tree nodes corresponding to different histories,
along with target values as computed in Equation 20. The bottom row shows the evolution of
Ps0 a1 s1 (P = P 0 ) = 1  Ps0 a1 s1 (P = P 1 ), the empirical distribution of mdps seen going through
PN (hs0 a1 s1 i)
1[P i = P 0 ]). (Left) The first 2000 simulations
tree node hs0 a1 s1 i (i.e., N (hs01a1 s1 i) i=0
(Right) Zoomed out view of 100,000 simulations, displaying empirical convergence to target
values.

857

fiGuez, Silver, & Dayan

only the particular transition probabilities that are required as the simulation traverses the
tree, and also during the rollout.
Consider P(s, a, ) to be parametrized by a latent variable s,a for each state and action
pair. These may depend on each other, as well as on
R an additional set of latent variables .
The posterior over P can be written as P (|h) =  P (|, h)P (|h), where  = {s,a |s 
S, a  A}. Define t = {s1 ,a1 ,    , st ,at } as the (random) set of  parameters required
during the course of a bamcp simulation that starts at time 1 and ends at time t. Using
the chain rule, we can rewrite
P (|, h) =P (s1 ,a1 |, h)
P (s2 ,a2 |1 , , h)
..
.
P (sT ,aT |T 1 , , h)
P ( \ T |T , , h)
where T is the length of the simulation and  \ T denotes the (random) set of parameters
that are not required for a simulation. For each simulation i, we sample P (|ht ) at the
root and then lazily sample the st ,at parameters as required, conditioned on  and all
t1 parameters sampled for the current simulation. This process is stopped at the end of
the simulation, typically long before all  parameters have been sampled. For example, if
the transition parameters for different states and actions are independent, we can simply
draw any necessary parameters individually for each state-action pair encountered during a
simulation. In general, transition parameters are not independent for different states, but
dependencies are likely to be structured. For example, the mdp dynamics could arise from a
mixture model where  denotes the mixture component and P (|h) specifies the posterior
mixture proportion. Then, if the transition parameters  are conditionally independent
given the mixture component, sampling i at the root for simulation i allows us to sample
the required parameters s,a independently from P (s,a |i , h) just when they are required
during the i-th simulation. This leads to substantial performance improvement, especially
in large mdps where a single simulation only requires a small subset of parameters (see for
example the domain in Section 4.2 for a concrete illustration). This lazy sampling scheme
is not limited to shallow latent variable models; in deeper models, we can also benefit from
conditional independencies to save on sampling operations for each simulation by sampling
only the necessary latent variables  as opposed to sampling all of .
3.3 Rollout Policy Learning
The choice of rollout policy ro is important if simulations are few, especially if the domain
does not display substantial locality or if rewards require a carefully selected sequence of
actions to be obtained. Otherwise, a simple uniform random policy can be chosen to provide
noisy estimates. In this work, we learn Qro , the optimal Q-value in the real mdp, in a modelfree manner, using Q-learning, from samples (st , at , rt , st+1 ) obtained off-policy as a result
of the interaction of the bamcp agent with the mdp at time t. For each real transition
858

fiBayes-Adaptive Monte-Carlo Planning

(st , at , rt , st+1 ) observed, we update
Qro (st , at )  Qro (st , at ) + (rt +  max Qro (st+1 , a)  Qro (st , at )),
a

(20)

where  is some learning rate parameter; this is the standard Q-learning rule (Watkins,
1989). Acting greedily according to Qro translates to pure exploitation of gathered knowledge. A rollout policy in bamcp following Qro could therefore over-exploit. Instead, similar
to the work of Gelly and Silver (2007), we select an -greedy policy with respect to Qro as
our rollout policy ro . In other words, after t steps in the mdp, we have updated Qro t
times and we use the following stochastic rollout policy for all mcts simulations at the t + 1
decision step:
(

1   + |A|
if a = argmaxa0 Qro (s, a0 )
ro (s, a) =
(21)

otherwise,
|A|
where ro (s, a) is the probability of selecting action a when in the mdp state s (i.e., history
is ignored) during a rollout. This biases rollouts towards observed regions of high rewards.
This method provides valuable direction for the rollout policy at negligible computational
cost. More complex rollout policies can be considered, for example rollout policies that
depend on the sampled model P i or on the history ht . However, these usually incur computational overhead, which may be less desired than running more simulations with worse
estimates.
3.4 Theoretical Properties
In this section, we show that bamcp converges to the Bayes-optimal policy. We first present
theoretical results in the case that exact posterior inference can be conducted to obtain
posterior samples of the dynamics (Section 3.4.1), we then extend the convergence guarantee
to the case where approximate inference (MCMC-based) is necessary to produce posterior
samples (Section 3.4.2).
The proof of Theorem 1 was present in the supplementary material by Guez et al. (2012).
Theorem 2 is a novel contribution of this paper.
3.4.1 Exact Inference Case
The main step is proving that root sampling does not alter the behavior of ba-uct. Our
proof is an adaptation of the pomcp proof by Silver and Veness (2010). We then provide
some intuition and some empirical evidence of convergence on simple Bandit problems 
where the Bayes-optimal solution is known.
Consider the ba-uct algorithm: uct applied to the Bayes-Adaptive mdp (its dynamics
are described in Equation 16). Let D (hT ) be the rollout distribution of ba-uct: the
probability that history hT is generated when running the ba-uct search from hst , ht i, with
ht a prefix of hT , T  t the effective horizon in the search tree, and  is an arbitrary EE

policy. Similarly define the quantities D (hT ): the probability that history hT is generated
when running the bamcp algorithm, and Ph (P): the distribution of P at node h when
859

fiGuez, Silver, & Dayan

running bamcp. The following lemma shows that these rollout statistics are the same
under bamcp as ba-uct.4
Lemma 1 D (hT ) = D (hT ) for all EE policies  : H  A.
Proof Let  be arbitrary. We show by induction that for all suffix histories h of ht , (a)
D (h) = D (h); and (b) P (P |h) = Ph (P), where P (P |h) denotes (as before) the posterior
distribution over the dynamics given h.
Base case: At the root (h = ht , suffix history of size 0), it is clear that Pht (P) = P (P |ht )
since we are sampling from the posterior at the root node and D (ht ) = D (ht ) = 1 since
all simulations go through the root node.
Step case:
Assume proposition true for all suffices of size j. Consider any suffix has0 of size j + 1,
where a  A and s0  S are arbitrary and h is an arbitrary suffix of size j ending in s. The
following relation holds:
Z

0

D (has ) = D (h)(h, a)
dP P (P |h) P(s, a, s0 )
(22)
ZP

= D (h)(h, a)
dP Ph (P) P(s, a, s0 )
(23)
P

= D (has0 ),

(24)

where the second line is obtained using the induction hypothesis, and the rest from the
definitions. In addition, we can match the distribution of the samples P at node has0 :
P (P |has0 ) = P (has0 | P)P (P)/P (has0 )

(25)

0

0

(26)

0

0

(27)

= P (h| P)P (P) P(s, a, s )/P (has )
= P (P |h)P (h) P(s, a, s )/P (has )
0

= ZP (P |h) P(s, a, s )
0

(28)

= Z Ph (P) P(s, a, s )

(29)

0

= Z Pha (P) P(s, a, s )

(30)

= Phas0 (P),

(31)

where Equation 29 is obtained from the induction hypothesis, Equation 30 is obtained from
the fact that the choice of action at each node is made independently of the samples P.
Finally, to obtain Equation 31 from Equation 30, consider the probability that a sample
P arrives at node has0 , it first needs to traverse node ha (this occurs with probability
Pha (P)) and then, from node ha, the state s0 needs to be sampled (this occurs with probability P(s, a, s0 )); therefore, Phas0 (P)  Pha (P) P(s, a, s0 ). Z is the normalization constant:
R
R
Z = 1/( P d P P(s, a, s0 )P (P |h)) = 1/( P d P P(s, a, s0 )Ph (P)). This completes the induction.


4. For ease of notation, we refer to a node with its history only, as opposed to its state and history as in
the rest of the paper.

860

fiBayes-Adaptive Monte-Carlo Planning

The proof of Lemma 1 does not make explicit the use of lazy sampling, since this method
for realizing the values of relevant random variables does not affect the rollout distribution
and so does not affect what is being computed, only how.
Define V (hs, hi) = max Q(hs, hi, a) hs, hi  S  H. We now show that bamcp conaA

verges to the Bayes-optimal solution.
Theorem 1 For all  > 0 (the numerical precision, see Algorithm 1) and a suitably chosen
max
c (e.g. c > R1
), from state hst , ht i, bamcp constructs a value function at the root node
p

that converges in probability to an 0 -optimal value function, V (hst , ht i)  V0 (hst , ht i),

. Moreover, for large enough N (hst , ht i), the bias of V (hst , ht i) decreases as
where 0 = 1
O(log(N (hst , ht i))/N (hst , ht i)).
Proof The uct analysis by Kocsis and Szepesvari (2006) applies to the ba-uct algorithm,
since it is vanilla uct applied to the bamdp (a particular mdp). It also applies for arbitrary rollout policies, including the one developed in Section 3.3. By Lemma 1, bamcp
simulations are equivalent in distribution to ba-uct simulations. The nodes in bamcp are
therefore evaluated exactly as in ba-uct, providing the result.

Lemma 1 provides some intuition for why belief updates are unnecessary in the search
tree: the search tree filters the samples from the root node so that the distribution of
samples at each node is equivalent to the distribution obtained when explicitly updating
the belief. In particular, the root sampling in pomcp (Silver & Veness, 2010) and bamcp is
different from evaluating the tree using the posterior mean. This is illustrated empirically
in Figures 4 and 5 in the case of simple Bandit problems.
3.4.2 Approximate Inference Case
In Theorem 1, we made the implicit assumption that bamcp is provided with true samples
drawn iid from the posterior. However, most sophisticated priors will require some form of
approximate sampling scheme (see, for example, the task in Section 4.2), such as Markov
Chain Monte Carlo (MCMC), which generally deliver correlated posterior samples after the
chain converges to the stationary distribution (Neal, 1993). Thus, it is necessary to extend
the proof of convergence of bamcp to deal with samples of this nature.
Theorem 2 When using an approximate sampling procedure based on a MCMC chain with
stationary distribution P (P |ht ) (e.g., Metropolis-Hastings or Gibbs sampling) to produce a
sample sequence P 1 , P 2 , . . . at the root node of bamcp, the value V (hst , ht i) found by
bamcp converges in probability to a (near-)optimal value function.
Proof Let  > 0 be the chosen numerical accuracy of the algorithm. We can choose a
finite depth T for the search tree as a function of , rmax , and  that guarantees the sum
total return after depth T amountsPto less than . Now consider any leaf Q-node i of
that tree, with mean value in = n1 nm=1 rm after n simulations, where rm is the reward
obtained from this node at the m-th simulation going through that node. Since ucb is
used throughout the tree, exploration never ceases and this guarantees that n   (see for
example Kocsis & Szepesvari, 2006, Thm. 3).
861

fiGuez, Silver, & Dayan

80

Discounted sum of rewards

Undiscounted sum of rewards

260

240

220

200

180

75

70

65

60
160
Bayesoptimal

BAMCP

Posterior Mean

(a)

55

Bayesoptimal

BAMCP

Posterior Mean

(b)

Figure 4: Performance comparison of bamcp (50000 simulations, 100 runs) against the posterior mean
decision on an 8-armed Bernoulli bandit with  = 0.99 after 300 steps. The arms success
probabilities are all 0.6 except for one arm which has success probability 0.9. The Bayes-optimal
result is obtained from 1000 runs with the Gittins indices (Gittins et al., 1989). a. Mean sum
of rewards after 300 steps. b. Mean sum of discounted rewards after 300 steps.

Root sampling filtering (Lemma 1) still holds despite the approximate sampling at the
root node; since it is a statement about the distribution of samples, not about the order in
which these samples arrive. Therefore, the distribution of dynamics at node i converges to
the right stationary distribution P (P |hi ), where hi is the history corresponding to node i.
Asymptotic results on Markov Chains (Law of large numbers for Markov Chains) guarantee
us that in  i a.s., where i is the true expected reward at leaf node i.
Given convergence at the leaves, we can work our way up the tree by backward induction
to show that the values at each node converge to their (near-)optimal values. In particular
the value at the root converges to an optimal value.


3.5 Possible Misuse of Latent Variable Information: a Counter-Example
When planning in a bamdp using a sample-based forward-search algorithm such as bamcp,
it could be tempting to use the knowledge available in the sampler when producing samples
(such as the value of latent variables in the model) to take better planning decisions. For
example, when generating a sample P iR of the dynamics according to a posterior distribution P (P |h) which can be written as  P (P |)P (|h), P i might have been generated by
sampling i from P (|h) before sampling P i from P (P |i ). Since the value of  is available
and contain high-level information, one natural question is to ask whether the search can
be informed by the value of .
862

fiBayes-Adaptive Monte-Carlo Planning

BAMCP  Number of simulations: 5000

BAMCP  Number of simulations: 250000

20

20

15





15

10

5

5

5

10



15

20

5

BAMCP  Number of simulations: 2500000

20

15





15



20

15

10

5

10

5

5

10



15

20

5

10

15



20

Posterior mean decision

Probability of correct decision

15



10

BAMCP  Number of simulations: 5000000

20

20

10

10

0

0.2

0.4

0.6

0.8

1

5

5

10



15

20

Figure 5: Evaluation of bamcp against the Bayes-optimal policy, for the case  = 0.95, when choosing
between a deterministic arm with reward 0.5 and a stochastic arm with reward 1 with posterior
probability p  Beta(, ). The result is tabulated for a range of values of , , each cell value
corresponds to the probability of making the correct decision (computed over 50 runs) when
compared to the Gittins indices (Gittins et al., 1989) for the corresponding posterior. The first
four tables corresponds to different number of simulations for bamcp and the last table shows
the performance when acting according to the posterior mean. In this range of ,  values, the
Gittins indices for the stochastic arm are larger than 0.5 (i.e., selecting the stochastic arm is
optimal) for    + 1 but also  =  + 2 for   6. Acting according to the posterior mean is
different from the Bayes-optimal decision when  >=  and the Gittins index is larger than 0.5.
bamcp is guaranteed to converge to the Bayes-optimal decision in all cases, but convergence is
slow for the edge cases where the Gittins index is close to 0.5 (e.g., For  = 17,  = 19, the
Gittins index is 0.5044 which implies a value of at most 0.5044/(1) = 10.088 for the stochastic
arm versus a value between 10 and 0.5 +   10.088 = 10.0836 for the deterministic arm).

863

fiGuez, Silver, & Dayan

Here, we outline one incorrect way of using the latent variable value during search.
Suppose we would want to split our search tree on the value of  (this would occur implicitly
if we were constructing history features based on the value of ), we provide below a simple
counter-example that shows that this is not a valid search approach.
Consider a simple prior distribution on two 5-state mdps, illustrated in Figure 6, where
P ( = 0|h0 ) = P ( = 1|h0 ) = 21 , and P (P |) is a delta function on the illustrated mdp.
s0
a0

s0
a1

a0

s1 p = 1
a0

s2 p = 1
+1

s1 p = 1

a1

s3 p = 1
+2

a0
s4 p = 1
2
(a)

a1
s2 p = 1
+1

a1

s4 p = 1
2

=0

s3 p = 1
+2
(b)

=1

Figure 6: The two possible mdps corresponding to the two settings of .

h0 = s0
a0

a1

s1

s2
+1

a0
1
2
s3

1
2

+2

a1
1
2
s4

1
2

2

Figure 7: bamdp, nodes correspond to belief(or history)-states.

There are 2 deterministic actions (a0 , a1 ) in each mdp, the episode length is 1 or 2 steps.
The only difference between the two mdps is the outcome of taking action a0 and a1 in state
s1 , as illustrated in Figure 6, so that a0 is rewarding when  = 0 and costly when  = 1,
and vice-versa for a1 . All the rewards are obtained from executing any action at any of the
terminal states (s2 , s3 , s4 ).
Observing the first transition is not informative, which implies that the posterior distribution is unchanged after the first transition: P (P |h0 ) = P (P |h0 a0 s1 ) = P (P |h0 a1 s2 ).
The bamdp corresponding to this problem is illustrated in Figure 7.
864

fiBayes-Adaptive Monte-Carlo Planning

At history-state h0 = s0 , the Bayes-optimal Q values can easily be computed:
Q (h0 , a1 ) = ,

(32)



Q (h0 a0 s1 , a0 ) = 0 +  (2  P (s3 |h0 a0 s1 a0 )  2  P (s4 |h0 a0 s1 a0 ))
= (1  1) = 0,

(33)
(34)



Q (h0 a0 s1 , a1 ) = 0 +  (2  P (s3 |h0 a0 s1 a0 )  2  P (s4 |h0 a0 s1 a0 ))

(35)

= (1  1) = 0,

(36)



(37)



Q (h0 , a0 ) = 0 +  max Q (h0 a0 s1 , a) = 0,
a

which implies that a1 =   (h0 ) for any . [We used the fact that P (s3 |h0 a0 s1 a0 ) = P ( =
0|h0 a0 s1 a0 )  P (s3 | = 0, s1 a0 ) + P ( = 1|h0 a0 s1 a0 )  P (s3 | = 1, s1 a0 ) = 21  1 + 12  0 = 12 ,
and similarly for P (s4 |h0 a0 s1 a0 )].
Note that, since belief updates only occur at the terminal states, forward-search with
or without root sampling will be equivalent. They both would construct a search tree as in
Figure 7 and compute the right value and right decision.
The problem comes in if we decide to split our search tree at chance nodes based on
the value of  in the generated samples going down the tree. For example, after taking
action a0 in state s0 , we would be using either an mdp for which  = 0 w.p 0.5 or an mdp
for which  = 1 w.p 0.5. Since multiple values of  go through the node h0 a0 , we would
branch the tree as illustrated in Figure 8. This search tree is problematic because the value
computed for Q (h0 , a0 ) becomes 2   2 , which is larger than Q (h0 , a1 ) =  for any  > 0.5.
Therefore, the policy that is computed at the root is no longer Bayes-optimal.

h0 = s0
a0
 = 0, s1

a1
s2

 = 1, s1

+1
a0
s3

a1

a0
s4

+2

a1

s3
2

s4
+2

2

Figure 8: A problematic search tree.

By branching on the latent variable value, we are creating spurious observations: we are
implying that the latent variable from the past will be observed in the future, which is not
the case.
To summarize, the Bayes-adaptive policy to be optimized must be a function of future
histories (i.e., things well actually observe in the future), and cannot be a function of future
unobserved latent variables. Ignoring this causes problems in simple domains such as the
one illustrated above, but similar scenarios would occur in more complex latent variable
models for the same reasons.
865

fiGuez, Silver, & Dayan

4. Experiments
We first present empirical results of bamcp on a set of standard problems with comparisons
to other popular algorithms. We then showcase bamcps advantages in a large scale task:
an infinite 2D grid with complex correlations between reward locations.
4.1 Standard Domains
The following algorithms were run on the standard domains: bamcp, sboss, beb, bfs3.
Details about their implementation and parametrization can be found in Appendix B. In
addition, we report results from the work of Strens (2000) for several other algorithms.
For all the following domains, we fix  = 0.95.
 The Double-loop domain is a 9-state deterministic mdp with 2 actions (Dearden,
Friedman, & Russell, 1998), 1000 steps are executed in this domain. It is illustrated
in Figure 9(a).
 Grid5 is a 5  5 grid with a reset state in one corner, and a single reward state
diametrically opposite to the reset state. Actions with cardinal directions are executed
with small probability of failure (pfailure = 0.2) for 1000 steps.

These expectacan be approxias derived fairly

 Grid10 is a 10  10 grid designed in the same way as Grid5. We collect 2000 steps
in this domain.
b,2
a,10
a,0

a,0

a,0

a,0

1 b,2 Maze
2
3
4
 Deardens
is a 264-states
maze
with 5
3 flags to collect (Dearden et al., 1998).
b,2
A special state provides
reward
equivalent
to
the number of flags collected since the
b,2
b,2
last visit. 20000 steps are executed in this domain5 . It is illustrated in Figure 9(b).

ed two possible
The first, modate, but might
ture update, is
ation.

(a) Task 1 [11].
b,2

a,10
1

6
b,0

b,0
a,0

2

b,2
b,2
b,2a,0
b,2

5

a,0

a,0

3

b,0

a,0

1

4

a,b,0
5

2

a,0

a,0

a,0

0

a,b,0

Figure 1. The Chain problem

algorithms conces to show that
es, and that the
is the case, then
-VPI strategies

nvergence proof
s tried infinitely
0

earning rate. If
shows that the
-values.
we use moment
ect mean.
finitely often in
updating, then
or every state

o prove that the

finitely often in

a,b,2
7
6.1 Problem
Descriptions

Figure

a,b,1

3

4 The arcs
Figure 1b,0
shows the 8
5-state Chain problem.
a,b,0are
labeled with the actions that cause that state transition,
and the associated rewards.
However
the agent has only
Figure 3. The  Maze problem.
(b) Task
(a) 2 [14].
(b)
abstract actions {1,2} available. Usually abstract action 1
causes real-world action a to take place, and abstract
a direction perpendicular to that intended (with
2 causes real-world action b. With probability 0.2,
S standard
F domains
Geffect.
9: action
Two
of the
described
Section
4.1: a) The
Double-loop
domain,
b) Deardens
probability
0.1). There
are 33 reachable
locations
in the
the
agent
slips
and its action
has the
opposite in
maze (including the goal) and there are up to 8
maze.
Figures
from
work
of Strens
The
optimal
behavior
is tothe
always
choose
action 1(2000).
(even
combinations for status of the flags at any time. This
though this sometimes results in the transitions labeled
yields 264 discrete states. The agent was given limited
with b). Once state 5 is reached, a reward of 10 is usually
layout information (identifying the immediate successors
received several times before the agent slips, and starts
of each
in order tothe
reduce
the complexity
of the
again at the
state performance
1. This problemofrequires
quantify
each effective
algorithm,
westate)
measured
total
undiscounted
posterior distribution for the Bayesian DP approach.
exploration and accurate estimation of discounted reward.

To
reward over many steps. We chose this measure of performance to enable fair comparisons
Figure 2 shows the Loop problem which involves two
6.2 Results
to be drawn
with
prior
work.
In fact,
we Two
areFactions
optimising
a different criterion  the discounted
loops
of length
5 joined
at a single
start state.
are available and transitions are deterministic. Taking

The experimental results show accumulated totals of

rewardDP
received
overStrens
learning(2000)
phases which
of
5. The result
reported
maze
with
theloop,
Bayesian
alg. by
is for consist
a different
action
a repeatedly
causes traversal
of the
right
F for Deardens
steps for Chain and Loop, and 20000 steps for
yielding
a reward
of 1the
for maze
every layout
5 actions
taken. to 1000
version of
the task
in which
is given
the agent.

Maze. Averages were taken over 256 runs for Chain and
Conversely,
taking actionproblem.
b repeatedly causesistraversal
of
(c) Task 3.
A navigation
the start
state.
The
Loop, and
16 runs for Maze. Table 1 summarizes
the left loop, yielding a reward of 2 for every 5 actions
comparative
performance after 1, 2, and 8 phases of
agent receives
a
reward
upon
reaching
based
on
the
number
taken. This problem requires a difficult compromise
866
learning. (Note that these results are pessimistic in that
between exploration and exploitation.
of flags collected.
they show the rewards actually received during learning
Figure 3 shows the  Maze problem. The agent can move

rather than the rewards which could be received with the

instantaneous greedy policy.) In the Bayesian DP method,
or down
by one square
in the
If it
Figureleft,
3: right,
Theupthree
domains
used
in maze.
our experiments.
a new hypothesis (for the MDP) was drawn each time the
attempts to move into a wall, its action has no effect. The
problem is to move from the start (top-left) to the goal
(top-right) collecting the flags on the way. When it

system entered the starting state. In Maze, a new
hypothesis was also obtained every 24 steps because there

fiBayes-Adaptive Monte-Carlo Planning

reward from the start state  and so we might expect this evaluation to be unfavourable to
our algorithm.
Although one major advantage of Bayesian RL is that one can specify priors about the
dynamics, for these domains, we used rather generic priors to enable comparisons with previous work. For the Double-loop domain, the Bayesian RL algorithms were run with a simple
1
Dirichlet-Multinomial model with symmetric Dirichlet parameter  = |S|
. For the grids
and the maze domain, the algorithms were run with a sparse Dirichlet-Multinomial model,
as described by Friedman and Singer (1999). For both these models, efficient collapsed
sampling schemes are available; they are employed for the ba-uct and bfs3 algorithms in
our experiments to compress the posterior parameter sampling and the transition sampling
into a single transition sampling step. This considerably reduces the cost of belief updates
inside the search tree when using these simple probabilistic models. Unfortunately, efficient collapsed sampling schemes are not available in general (see for example the model in
Section 4.2).
Sum of Rewards after 1000 steps

90

90

BAMCP

80

80

70

70

60

60

50

50

40

40

30

30

20

20

10

3

10

2

1

10

90

10

0

10

10

80

70

70

60

60

50

50

40

40

30

30

20

20
3

10

2

10

3

10

2

10

90

SBOSS

80

10

BFS3

1

10

0

10

10

1

10

1

10

10

0

BEB

3

10

2

10

Average Time per Step (s)

10

0

Figure 10: Performance of each algorithm on the Grid5 domain as a function of planning time. Each
point corresponds to a single run of an algorithm with an associated setting of the parameters.
Increasing brightness inside the points codes for an increasing value of a parameter (bamcp
and bfs3: number of simulations, beb: bonus parameter , sboss: number of samples K).
A second dimension of variation is coded as the size of the points (bfs3: branching factor C,
sboss: resampling parameter ). The range of parameters is specified in Appendix B.

A summary of the results is presented in Table 1. Figures 10 and 11 report the planning
time/performance trade-off for the different algorithms on the Grid5 and Maze domain.
867

fiUndiscounted sum of rewards after 20000 steps

Guez, Silver, & Dayan

1100
1000
900

BAMCP (BAUCT+RS+LS+RL)
BEB
BFS3
SBOSS

800
700
600
500
400
300
200
100
0

1

0

10

Average Time per Step (s)

10

Figure 11: Performance of each algorithm, as in Figure 10 but on Deardens Maze domain.

BAMCP
BFS3 (Asmuth & Littman, 2011)
SBOSS (Castro & Precup, 2010)
BEB (Kolter & Ng, 2009)
Bayesian DP* (Strens, 2000)
Bayes VPI+MIX* (Dearden et al., 1998)
IEQL+* (Meuleau & Bourgine, 1999)
QL Boltzmann*

Double-loop
387.6  1.5
382.2  1.5
371.5  3
386  0
377  1
326  31
264  1
186  1

Grid5
72.9  3
66  5
59.3  4
67.5  3
-

Grid10
32.7  3
10.4  2
21.8  2
10  1
-

Deardens Maze
965.2  73
240.9  46
671.3  126
184.6  35
817.6  29
269.4  1
195.2  20

Table 1: Experiment results summary. For each algorithm, we report the mean sum of rewards and
confidence interval for the best performing parameter within a reasonable planning time limit
(0.25 s/step for Double-loop, 1 s/step for Grid5 and Grid10, 1.5 s/step for the Maze). For
bamcp, this simply corresponds to the number of simulations that achieve a planning time just
under the imposed limit. * Results by Strens (2000) reported without timing information.

On all the domains tested, bamcp performed best. Other algorithms came close on
some tasks, but only when their parameters were tuned to that specific domain. This is
particularly evident for beb, which required a different value of exploration bonus to achieve
maximum performance in each domain. bamcps performance is stable with respect to the
choice of its exploration constant (c = 3) and it did not require fine tuning to obtain the
results.
bamcps performance scaled well as a function of planning time, as is evident in Figures 10 and 11. In contrast, sboss follows the opposite trend. If more samples are employed
to build the merged model, sboss actually becomes too optimistic and over-explores, de868

fi(a)

Undiscounted sum of rewards after 20000 steps

Bayes-Adaptive Monte-Carlo Planning

1100
1000

BAUCT + RL
BAUCT

900
800
700
600
500
400
300
200
100
0

1

10

Average Time per Step (s)

0

10

1100

BAUCT + RS + RL
1000

BAUCT + RS

900
800
700
600

(b)

500
400
300
200
100
0
1

10

1100
1000

0

10

BAUCT + RS + LS + RL (BAMCP)
BAUCT + RS + LS

900
800
700
600

(c)

500
400
300
200
100
0

1

10

0

10

Figure 12: Evolution of performance from ba-uct to bamcp on Deardens Maze domain. bamcp is present
on all plots for comparison, as also displayed in Figure 11. a. Performance of vanilla ba-uct
with and without rollout policy learning (RL) presented in Section 3.3. b. Performance of
ba-uct with Root Sampling (RS), as presented in Section 3.1, and with and without rollout
learning. c. Performance of ba-uct with Root Sampling and Lazy Sampling (LS), as presented
in Section 3.2. In addition with rollout policy learning, this is the bamcp algorithm.

869

fiGuez, Silver, & Dayan

grading its performance. beb cannot take advantage of prolonged planning time at all. The
performance of bfs3 generally improves with more planning time, given an appropriate
choice of parameters, but it is not obvious how to trade-off the branching factor, depth, and
number of simulations in each domain. bamcp greatly benefited from our lazy sampling
scheme in the experiments, providing a 35 speed improvement over the naive approach in
the maze domain for example; this is illustrated in Figure 12.
Deardens maze aptly illustrates a major drawback of forward search sparse sampling
algorithms such as bfs3. Like many maze problems, all rewards are zero for at least k steps,
where k is the solution length. Without prior knowledge of the optimal solution length,
all upper bounds will be higher than the true optimal value until the tree has been fully
expanded up to depth k  even if a simulation happens to solve the maze. In contrast, once
bamcp discovers a successful simulation, its Monte-Carlo evaluation will immediately bias
the search tree towards the successful trajectory.
Figure 12 confirms that, even on a moderate-sized domain with a simple prior (Independent Sparse Dirichlet-Multinomial), bamcp amply benefits from root sampling, lazy
sampling, and rollout learning. For more complex priors, as in the following section, ba-uct
becomes computationally intractable. Root sampling and lazy sampling are then mandatory
components.
4.2 Infinite 2D Grid Task
..
.





..
.
Figure 13: A portion of an infinite 2D grid task generated with Beta distribution parameters 1 = 1, 1 = 2
(columns) and 2 = 2, 2 = 1 (rows). Black squares at location (i,j) indicates a reward of 1,
the circles represent the corresponding parameters pi (blue) and qj (orange) for each row and
column (area of the circle is proportional to the parameter value). One way to interpret these
parameters is that following column i implies a collection of 2pi /3 reward on average (2/3 is
the mean of a Beta(2, 1) distribution) whereas following any row j implies a collection of qj /3
reward on average; but high values of parameters pi are less likely than high values parameters
qj . These parameters are employed for the results presented in Figure 14-c).

870

fiBayes-Adaptive Monte-Carlo Planning

It is perhaps not unfair to characterize all the domains in the previous section as being
of very limited scale. Indeed, this can be seen as a correct reflection of the state of the
art of Bayesian RL. However, bamcp, because of its root-based lazy sampling, can be
applied to considerably larger and more challenging domains. We therefore designed a new
problem that is well beyond the capabilities of prior algorithms since it has an infinite and
combinatorially structured state space, and an even more challenging belief space. Although
still abstract, this new task illustrates something of bamcps power.
4.2.1 Problem Description
The new problem is a class of complex mdps over an infinite grid. In a draw of a particular
mdp, each column i has an associated latent parameter pi  Beta(1 , 1 ) and each row j
has an associated latent parameter qj  Beta(2 , 2 ). The probability of grid cell ij having
a reward of 1 is pi qj , otherwise the reward is 0. The agent knows it is on a grid and is
always free to move in any of the four cardinal directions. Rewards are consumed when
visited; returning to the same location subsequently results in a reward of 0. As opposed to
the independent Dirichlet priors employed in standard domains, here, dynamics are tightly
correlated across states (i.e., observing a state transition provides information about other
state transitions).
The domain is illustrated in Figure 13. Although the uncertainty appears to concern
the reward function of the mdp rather than the dynamics, it can be viewed formally as uncertainty in the dynamics when the state is augmented with a binary variable that indicates
whether a reward is present.6
Formally, since rewards disappear after one visit, the description of the state in the
mdp needs to include information about the state of all the rewards (for example in the
form of a set of grid locations previously visited) in addition to the position of the agent
on the infinite grid. A state s is therefore the combination of the current agents location
(i, j), the unordered set of previously visited locations V , and the binary variable R = rij .
The dynamics P then deterministically updates the position of the agent and the visited
locations based on the agents action, and updates R according to the reward map. The
known reward function is then simply R(s, a) = s(R) for all a (i.e., as described before, the
agent gets a reward in position ij if rij = 1).
4.2.2 Inference
Posterior inference (of the dynamics P) in this model requires approximation because of
the non-conjugate coupling of the variables. To see this, consider the posterior probability
of a particular grid cell kl having a reward of 1 (denote this event rkl = 1), then
Z
pk ql P (pk , ql |O) dpk dql ,

P (rkl = 1|O) =

(38)

pk ,ql

where O = {(i, j)} is the set of observed reward locations, each associated with an observed
reward rij  {0, 1}. Sampling rkl is straightforward given access to posterior samples of
6. In fact, the bamdp framework can be straightforwardly extended to deal with more general, partiallyobserved, reward functions (Duff, 2002).

871

fiGuez, Silver, & Dayan

pk and ql . However, the posterior distribution on pk and ql , P (pk , ql |O), cannot be easily
sampled from, it is given by:
P (pk , ql |O)  P (O|pk , ql )P (pk )P (ql )
Z
Y
Y
P (O|PO , QO )
P (p)
P (q)
=
PO \pk ,QO \ql

Z
=

pPO

Y

(40)

qQO

(pi qj )rij (1  pi qj )1rij

PO \pk ,QO \ql (i,j)O

(39)

Y

Beta(p; 1 , 1 )

pPO

Y

Beta(q; 2 , 2 ),

qQO

(41)
where PO denotes the set of parameters pi for all observed columns i (columns where at least
one observation exists) and similarly for QO with rows. This posterior suffers from nonconjugacy (because of the multiplicative interaction between the two Beta distribution) but
also from a complicated dependence structure (pk and ql depend on observations outside of
column k and row l). For these reasons, the inference is done approximately via MetropolisHastings (details in Appendix C).
4.2.3 Results
Planning algorithms that attempt to solve an mdp based on sample(s) (or the mean) of the
posterior (e.g., boss, beb, Bayesian DP) cannot directly handle this large combinatorial
state space. Previous forward-search methods (e.g., ba-uct, bfs3) can deal with the state
space, but not the complex belief space: at every node of the search tree they must solve
an approximate inference problem to estimate the posterior beliefs. By contrast, bamcp
limits the posterior inference to the root of the search tree and is not directly affected by
the size of the state space or belief space, which allows the algorithm to perform well even
with a limited planning time. Note that lazy sampling is required in this setup since a full
sample of the dynamics involves infinitely many parameters.
Figure 14 demonstrates the planning performance of bamcp in this complex domain.
Performance improves with additional planning time. The quality of the prior clearly affects
the agents performance, bamcp can take advantage of correct prior information to gain
more rewards. In addition, the behavior of the agent is qualitatively different depending on
the prior parameters employed.
For example, for the case of Figure 14-a, rewards are often found in relatively dense
blocks on the map and the agent exploits this fact when exploring; this explains the high
frequency of short dwell times. For Figure 14-b, good rewards rates can be obtained by
following the rare rows that have high qj parameters, but finding good rows can be expensive
for at least two reasons: 1) good rows can be far from the agents current position and 2) it
takes longer to decide the value of a row if most observations lack rewards; this is because the
entropy of the posterior is larger given observations of no rewards (which can be explained
by either rows or columns being poor, or both at the same time) than given observations
of rewards (which can be explained with high probability by both rows and columns being
good, since rij  Bernoulli(pi qj )). Hence, the agent might settle on sub-optimal rows for
large periods of time, for example until it gains enough confidence that a better row is likely
to be found nearby (as in Bandit problems where the Bayes-optimal agent might settle on
872

fi60

50

30

1

10

0

10

Planning time (s)

45

40

35

30

25

20

15

1

10

0

10

Planning time (s)

8

6
5
4
2
10

70

60

50

40

30

20

1

10

0

10

Planning time (s)

1

10

1

10

0

10

Planning time (s)

1

10

7

0.05

0

50

100

150

200

50

100

150

200

50

100

150

200

Dwell Time (Horizontal)

0.05

6.5
6
5.5
5
4.5
4

0

3.5
3
2.5
2
2
10

1

80

0

7

10

90

10
2
10

9

1

50

10
2
10

10

10

Discounted sum of rewards after 200 steps

Undiscounted sum of rewards after 200 steps

20
2
10

Undiscounted sum of rewards after 200 steps

BAMCP
BAMCP Wrong prior
Random

11

Frequency

70

BAMCP
BAMCP Wrong prior

12

Frequency

80

0.05

13

1

10

0

10

Planning time (s)

1

10

13

0.05

0

Dwell Time (Horizontal)

0.05

12
11
10

Frequency

90

40

14

Discounted sum of rewards after 200 steps

100

Discounted sum of rewards after 200 steps

Undiscounted sum of rewards after 200 steps

Bayes-Adaptive Monte-Carlo Planning

9
8
7

0

6
5
4
3
2
10

1

10

0

10

Planning time (s)

1

10

0.05

0

Dwell Time (Horizontal)

Figure 14: Performance of bamcp as a function of planning time on the Infinite 2D grid task, for  = 0.97,
where each row corresponds to a different set of parameters generating the grid. The performance during the first 200 steps in the environment is averaged over 50 sampled environments
(5 runs for each sample) and is reported both in terms of undiscounted (left) and discounted
(center) sum of rewards. bamcp is run either with the correct generative model as prior (solid
green) or with an incorrect prior (dotted green). The performance of a uniform random policy
is also reported (blue). A small sample portion of a grid generated with these parameters is
displayed on each row, presented as in Figure 13. The frequency histogram of dwell times  the
number of consecutive steps the agent stays on a row before switching  is reported for each
scenario. The grids are generated with Beta parameters a) 1 =0.5, 1 =0.5, 2 =0.5, 2 =0.5,
b) 1 =0.5, 1 =0.5, 2 =1, 2 =3, and c) 1 =2, 1 =1, 2 =1, 2 =2. For the case of wrong priors (dot-dashed lines), bamcp is given the parameters a) 1 =4, 1 =1, 2 =0.5, 2 =0.5, b)
1 =1, 1 =3, 2 =0.5, 2 =0.5, and c) 1 =1, 1 =2, 2 =2, 2 =1.

873

fiGuez, Silver, & Dayan

a sub-optimal arm if it believes it likely is the best arm given past data). The heavier-tail
distribution of dwell times for this scenario, in Figure 14-b, reflects this behavior.
The case of Figure 14-c consists of a mixture of rich and poor rows. The agent can
determine moderately quickly if a row is not good enough, given what it expects to find,
and then switches to a nearby row. Once a good enough row is found, the agent can stick
to it for large periods of time. This is reflected in the bimodal nature of the distribution of
dwell times in Figure 14-c. In many cases, the agent is satisfied with one of the first rows
he visits, since it is likely that the agent starts on a good row. He then decides to stay on
it for the entire duration of the episode, which explains the peak towards 200.
When bamcps prior belief about the dynamics is not the same as the generative models
distribution (Wrong prior dot-dashed lines in Figure 14), then maladaptive behavior can be
observed. For instance, in Figure 14-a, the deluded agent expects most columns to be rich,
and some rows to be rich and others to be poor. Hence, a good strategy given this prior
belief is to find one of the good rows and exploit it by travelling horizontally. However,
since a lot of columns are actually poor in this generative model, the agent never encounters
the continuous sequence of rewards it expects to find on good rows. Given its wrong prior,
even if on what is actually a good row, it explains the observation by the row being poor
 rather than the column  and switches to a different row. This behavior is reflected in
the shorter horizontal dwell times plotted in Figure 14-a. Similar effects can be observed in
the Wrong prior cases of Figure 14-b,c.
It should be pointed out that the actual Bayes-optimal strategy in this domain is not
known  the behavior of bamcp for finite planning time might not qualitatively match the
Bayes-optimal strategy. Nevertheless, we speculate that some of the behavior we observe
with bamcp, including the apparently maladaptive behaviors, would also be found in the
Bayes-optimal solution.

5. Discussion
Bayesian model-based reinforcement learning addresses the problem of optimizing the discounted return of an agent when the dynamics are uncertain. By solving an augmented
mdp called the bamdp, the agent can optimally trade-off exploration and exploitation and
maximize its expected discounted return according to its prior beliefs. While formally attractive, this framework suffers from a major drawback: it is computationally intractable
to solve the bamdp exactly. While we are not aware of any formal complexity analysis
for solving bamdps, bamdps can be mapped to continuous-state pomdps with discrete observations (Duff, 2002). In general, solving discrete pomdps is known to be challenging
(Mundhenk, Goldsmith, Lusena, & Allender, 2000; Madani, Hanks, & Condon, 2003).
To approximate the Bayes-optimal solution efficiently, we suggested a sample-based
algorithm for Bayesian RL called bamcp that significantly surpassed the performance of
existing algorithms on several standard tasks. We showed that bamcp can tackle larger
and more complex tasks generated from a structured prior, where existing approaches scale
poorly. In addition, bamcp provably converges to the Bayes-optimal solution, even when
MCMC-based posterior sampling is employed.
The main idea is to employ Monte-Carlo tree search to explore the augmented Bayesadaptive search space efficiently. The naive implementation of that idea is an algorithm
874

fiBayes-Adaptive Monte-Carlo Planning

that we called ba-uct. However, ba-uct cannot cope with most priors because it employs
expensive belief updates inside the search tree. We therefore introduced three modifications
to obtain a computationally tractable sampled-based algorithm: root sampling, which only
requires beliefs to be sampled at the start of each simulation (as in Silver & Veness, 2010);
a model-free RL algorithm that learns a rollout policy; and a lazy sampling scheme which
enables the posterior beliefs to be sampled cheaply.
5.1 Future Work: Algorithms
Despite its excellent empirical performance in many domains (Gelly et al., 2012), the uct
algorithm is known to suffer several drawbacks. First, there is no finite-time regret bound.
It is possible to construct malicious environments, for example in which the optimal policy
is hidden in a generally low reward region of the tree, where uct can be misled for long
periods (Coquelin & Munos, 2007). Of course, in our setting, appropriate prior distributions
might help structure search more effectively. But, the issue of convergence of the MCMC
chain in approximate inference settings may hinder any effort to get finite-time guarantees.
Second, the uct algorithm treats every action node as a multi-armed bandit problem.
However, there is no actual benefit to accruing reward during planning, and so it is in
theory more appropriate to use pure exploration bandits (Bubeck, Munos, & Stoltz, 2009).
We focused on learning the dynamics (and implicitly the rewards in the infinite grid
task) of a fully observable mdp. If the states are not observed directly, then bamcp could be
extended to maintain beliefs over both the dynamics and the state. Both state and dynamics
would then be sampled from the posterior distribution, at the start of each simulation. This
setting is known as a Bayes-Adaptive Partially Observable mdp (bapomdp) (Ross, Pineau,
Chaib-draa, & Kreitmann, 2011).
In this work, we limited ourselves to the case of discrete-state mdps, since they already
present significant challenges for Bayesian exploration. bamcp cannot be straightforwardly
converted to deal with continuous-state mdps, but it remains to see whether the ingredients that make bamcp successful in the discrete setting could be reassembled into a
continuous-state solution, for example using some form of value function approximation
during simulation-based search (Silver, Sutton, & Muller, 2008).
5.2 Future Work: Priors
bamcp is able to exploit prior knowledge about the dynamics in a principled manner. It is
possible to encode many aspects of domain knowledge into the prior distribution, and so an
important avenue for future work is to explore rich, structured priors about the dynamics
of the mdp. As we showed, if this prior knowledge matches the class of environments that
the agent will encounter, then exploration can be significantly accelerated. It is therefore
important to understand how to select or learn appropriate priors so that large real-world
tasks can be tackled with Bayesian RL. One promising category of rich priors in this context
are non-parametric priors. For example, Doshi-Velez, Wingate, Roy, and Tenenbaum (2010)
and Wingate, Goodman, Roy, Kaelbling, and Tenenbaum (2011) have investigated this
direction, but as yet only in combination with myopic planning algorithms, rather than
Bayes-Adaptive planning.
875

fiGuez, Silver, & Dayan

5.3 Evaluation of Bayesian RL Algorithms
Bayesian RL algorithms have traditionally been tested on small, hand-crafted, domains.
Even though these domains can contain substantial structure, the priors given to the agent
are usually independent Dirichlet distributions that only generate unstructured random
worlds. This mismatch between the prior distribution and the domains is problematic to
evaluate, since a perfect Bayesian RL algorithm is not guaranteed to perform well given
incorrect priors. Since it is not tractable to compute the Bayes-optimal solution exactly, it
becomes impossible to decide whether an algorithm that obtains a low return compared to
other algorithms in some hand-crafted domain is a better or a worse approximation to the
Bayes-optimal solution.
For the purpose of algorithmic evaluation, the obvious solution is to design priors that
actually generate the tasks that we solve. When a Bayesian RL algorithm is given this
generative model as prior and is also tested on many of these generated tasks, then the
Bayes-optimal solution is guaranteed to obtain the best discounted return on average. In
this case, a higher mean return becomes synonymous with a better approximation  given
the goal of matching the Bayes-optimal solutions performance. We employed this method
of averaging across generated domains in Section 4.2 to evaluate the bamcp algorithm on
the Infinite Grid task. To understand the exploration performance of proposed algorithmic solutions truly, future comparisons between algorithms would likely benefit from such
evaluation schemes.
5.4 Conclusion
Bayes-adaptive planning is conceptually appealing but computationally very challenging.
The enormous computation required by prior approaches is largely due to the fact that
root values are computed from expectations and/or maximisations over the complete tree
of possible actions and states that follows on from the current history. In addition, these
values must integrate over the distribution of transition and potentially reward models at
each state in the search tree. As a result, computation typically grows exponentially with
search depth, at a rate determined by the action space, successor state space, and model
space.
Our new algorithm, bamcp, builds on previous work (Kearns et al., 1999; Kocsis &
Szepesvari, 2006; Silver & Veness, 2010) that solves these problems systematically by sampling these expectations, and notably on the pomcp algorithm of Silver and Veness (2010).
Only a tiny fraction of the future tree is actually explored, chosen by sampled actions according to their likely worth; and by sampling transitions from the dynamics. Additionally,
bamcp also solves the requirement of integrating over models: by sampling models from
the belief distribution; but only only at the root node, so as to avoid the need to compute
posteriors throughout the tree; and by lazily avoiding realizing random choices until the
last possible moment.
The result is an efficient algorithm that outperforms previous Bayesian model-based
reinforcement learning algorithms by a significant margin on several well-known benchmark
problems, and that can scale to problems with an infinite state space and a complex prior
structure.
876

fiBayes-Adaptive Monte-Carlo Planning

Acknowledgments
We acknowledge support for this project from the Gatsby Charitable Foundation (AG, PD),
the Natural Sciences and Engineering Research Council of Canada (AG), the Royal Society
(DS), and from the European Communitys Seventh Framework Programme (FP7/20072013) under grant agreement n 270327 (DS).

Appendix A: List of Acronyms
BAMCP
BAMDP
BA-UCT
BEB
BEETLE
BFS3
BOLT
BOSS
FSSS
IEQL
MCMC
MCTS
MDP
PAC
POMCP
POMDP
RL
SBOSS
UCB1
UCT

Bayes-Adaptive Monte-Carlo Planner (Algorithm name)
Bayes-Adaptive Markov Decision Process
Bayes-Adaptive UCT (Algorithm name)
Bayesian Exploration Bonus (Algorithm name)
Bayesian Exploration Exploitation Tradeoff in LEarning (Algorithm name)
Bayesian Forward Search Sparse Sampling (Algorithm name)
Bayesian Optimistic Local Transitions (Algorithm name)
Best Of Sampled Set (Algorithm name)
Forward Search Sparse Sampling (Algorithm name)
Interval Estimation Q-learning (Algorithm name)
Monte-Carlo Markov Chain
Monte-Carlo Tree Search (Algorithm name)
Markov Decision Process
Probably Approximately Correct
Partially-Observable Monte-Carlo Planner (Algorithm name)
Partially Observable Markov Decision Process
Reinforcement Learning
Smarter Best Of Sampled Set (Algorithm name)
Upper Confidence Bound 1 (Algorithm name)
Upper Confidence bounds applied to Trees (Algorithm name)

Appendix B: Algorithms Implementation
All algorithms below were implemented in C++ (code components were shared across algorithms as much as possible):
 BAMCP - The algorithm presented in Section 3, implemented with root sampling,
lazy sampling, and rollout learning. The algorithm was run for different number of
simulations (10 to 10000) to span different planning times. In all experiments, we
set ro to be an -greedy policy with  = 0.5. The uct exploration constant was
left unchanged for all experiments (c = 3), we experimented with other values of
c  {0.5, 1, 5} with similar results.
 SBOSS (Castro & Precup, 2010): for each domain, we varied the number of samples
K  {2, 4, 8, 16, 32} and the resampling threshold parameter   {3, 5, 7}.
 BEB (Kolter & Ng, 2009): for each domain, we varied the bonus parameter  
{0.5, 1, 1.5, 2, 2.5, 3, 5, 10, 15, 20}.
877

fiGuez, Silver, & Dayan

 BFS3 (Asmuth & Littman, 2011) for each domain, we varied the branching factor
C  {2, 5, 10, 15} and the number of simulations (10 to 2000). The depth of search
was set to 15 in all domains except for the larger grid and maze domain where it was
set to 50. We also tuned the Vmax parameter for each domain  Vmin was always set
to 0.
Code for this paper can be found online on the first authors website, or directly by
following this GitHub link https://github.com/acguez/bamcp.

Appendix C: Inference Details for the Infinite 2D Grid Task
We construct a Markov Chain using the Metropolis-Hastings algorithm to sample from the
posterior distribution of row and column parameters given observed transitions, following
the notation introduced in Section 4.2. Let O = {(i, j)} be the set of observed reward
locations, each associated with an observed reward rij  {0, 1}. The proposal distribution
chooses a row-column pair (ip , jp ) from O uniformly at random,
Pand samples pip  Beta(1 +
m1 , 1 + n1 ) and qjp  Beta(2 + m2 , 2 + n2 ), where m1 = (i,j)O
P 1i=ip rij (i.e., the sum

2
of rewards observed on that column) and n1 = (1  /2(2 + 2 )) (i,j)O 1i=ip (1  rij ), and
similarly for m2 , n2 (mutatis mutandis). The n1 term for the proposed column parameter
pi has this rough correction term, based on the prior mean failure of the row parameters,
to account for observed 0 rewards on the column due to potentially low row parameters.
Since the proposal is biased with respect to the true conditional distribution (from which we
cannot sample), we also prevent the proposal distribution from getting too peaked. Better
proposals (e.g., taking into account the sampled row parameters) could be devised, but
they would likely introduce additional computational cost and the proposal above generated
large enough acceptance probabilities (generally above 0.5 for our experiments). All other
parameters pi , qj such that i or j is present in O are kept from the last accepted samples
(i.e., pi = pi and qj = pj for these is and js), and all parameters pi , qj that are not linked to
observations are (lazily) resampled from the prior  they do not influence the acceptance
probability. We denote by Q(p, q  p, q) the probability of proposing the set of parameters
p and q from the last accepted sample of column/row parameters p and q. The acceptance
probability A can then be computed as A = min(1, A0 ) where:
P (p, q |h)Q(p, q  p, q)
P (p, q |h)Q(p, q  p, q)
P (p, q)Q(p, q  p, q)P (h| p, q)
=
P (p, q)Q(p, q  p, q)P (h| p, q)
Q
n1 m2
n2
rij
1rij
1
pm
(i,j)O 1[i = ip or j = jp ](pi qj ) (1  pi qj )
ip (1  pip ) qjp (1  qjp )
Q
= m1
2
rij
1rij .
n2
pip (1  pip )n1 qm
(i,j)O 1[i = ip or j = jp ](pi qj ) (1  pi qj )
jp (1  qjp )

A0 =

The last accepted sampled is employed whenever a sample is rejected. Finally, reward values
Rij are resampled lazily based on the last accepted sample of the parameters pi , qj , when
they have not been observed already. We omit the implicit deterministic mapping to obtain
the dynamics P from these parameters.
878

fiBayes-Adaptive Monte-Carlo Planning

Appendix D: On the Existence of the Bayes-Optimal Policy
As described in Definition 1, Martin (1967) proves the following statement for mdps with
finite state spaces.
Theorem 3 (Martin, 1967, Thm. 3.2.1) Let v(s, h, ) be the expected discounted return
in an mdp (with |S| and |A| finite) when the process starts from the augmented state hs, hi
and the EE policy  is used. Let
v  (s, h) = sup v(s, h, ).

(42)



Then there is a policy     such that v  (s, h) = v(s, h,   ).
The proof of Theorem 3 consists in proving that the set of EE policies  can be mapped
into the a compact subset of the real line, and that the mapping of the function v(s, h, )
is continuous on this set. The proof requires an ordering of histories that relies on the
finiteness of the state space. Let N = |S|, then the history ordering employed by Martin
(1967) is:
t0
X
st N t+1 ,
(43)
z(ht0 ) 
t=1

where z(h) is the number corresponding to history h in the order. In general |S| is not
finite, but in some scenarios we may bound by Nt the number of states the agent can be
in at time t (for example in the Infinite Grid scenario). For these scenarios we consider the
following ordering of histories:
0

w(ht0 ) 

t
X

st

t=1

t
Y

Nk1 ,

(44)

k=0

which reduces to w(h) = z(h) if Nt = N t. With this ordering, the proof of Theorem 3
can then be carried out as by Martin (1967) (with minimal modifications) to prove the
statement for these more general mdps - their state space is infinite but the possible states
of the agent grows in a controlled manner over time.
Although it is reassuring to know that the Bayes-optimal policy exists for these additional cases, in practice we are satisfied with  approximation to the Bayes-optimal policy
and the existence of -Bayes-optimal policies is likely to be guaranteed in even more general
scenarios.

879

fiGuez, Silver, & Dayan

References
Agrawal, S., & Goyal, N. (2011). Analysis of Thompson sampling for the multi-armed
bandit problem. Arxiv preprint.
Araya-Lopez, M., Buffet, O., & Thomas, V. (2012). Near-optimal BRL using optimistic
local transitions. In Proceedings of the 29th International Conference on Machine
Learning.
Asmuth, J., Li, L., Littman, M., Nouri, A., & Wingate, D. (2009). A Bayesian sampling
approach to exploration in reinforcement learning. In Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence, pp. 1926.
Asmuth, J., & Littman, M. (2011). Approaching Bayes-optimality using Monte-Carlo tree
search. In Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence,
pp. 1926.
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis of the multiarmed
bandit problem. Machine learning, 47 (2), 235256.
Bellman, R. (1954). The theory of dynamic programming. Bull. Amer. Math. Soc, 60 (6),
503515.
Brafman, R., & Tennenholtz, M. (2003). R-max-a general polynomial time algorithm for
near-optimal reinforcement learning. The Journal of Machine Learning Research, 3,
213231.
Bubeck, S., Munos, R., & Stoltz, G. (2009). Pure exploration in multi-armed bandits
problems. In Proceedings of the 20th international conference on Algorithmic learning
theory, pp. 2337. Springer-Verlag.
Castro, P., & Precup, D. (2010). Smarter sampling in model-based Bayesian reinforcement
learning. In Machine Learning and Knowledge Discovery in Databases, pp. 200214.
Springer.
Castro, P. (2007). Bayesian exploration in Markov decision processes. Ph.D. thesis, McGill
University.
Castro, P., & Precup, D. (2007). Using linear programming for Bayesian exploration in
Markov decision processes. In Proceedings of the 20th International Joint Conference
on Artificial Intelligence, pp. 24372442.
Coquelin, P., & Munos, R. (2007). Bandit algorithms for tree search. In Proceedings of the
23rd Conference on Uncertainty in Artificial Intelligence, pp. 6774.
Cozzolino, J., Gonzalez-Zubieta, R., & Miller, R. (1965). Markov decision processes with
uncertain transition probabilities. Tech. rep., 11, Operations Research Center, MIT.
Davies, S., Ng, A., & Moore, A. (1998). Applying online search techniques to reinforcement
learning. In Proceedings of the National Conference on Artificial Intelligence, pp.
753760.
Dayan, P., & Sejnowski, T. (1996). Exploration bonuses and dual control. Machine Learning,
25 (1), 522.
880

fiBayes-Adaptive Monte-Carlo Planning

Dearden, R., Friedman, N., & Russell, S. (1998). Bayesian Q-learning. In Proceedings of
the National Conference on Artificial Intelligence, pp. 761768.
Doshi-Velez, F., Wingate, D., Roy, N., & Tenenbaum, J. (2010). Nonparametric bayesian
policy priors for reinforcement learning. In Advances in Neural Information Processing
Systems (NIPS).
Duff, M. (2003). Design for an optimal probe. In Proceedings of the 20th International
Conference on Machine Learning, pp. 131138.
Duff, M. (2002). Optimal Learning: Computational Procedures For Bayes-Adaptive Markov
Decision Processes. Ph.D. thesis, University of Massachusetts Amherst.
Fonteneau, R., Busoniu, L., & Munos, R. (2013). Optimistic planning for belief-augmented
Markov decision processes. In IEEE International Symposium on Adaptive Dynamic
Programming and reinforcement Learning (ADPRL 2013).
Friedman, N., & Singer, Y. (1999). Efficient Bayesian parameter estimation in large discrete
domains. Advances in Neural Information Processing Systems (NIPS), 1 (1), 417423.
Gelly, S., Kocsis, L., Schoenauer, M., Sebag, M., Silver, D., Szepesvari, C., & Teytaud, O.
(2012). The grand challenge of computer Go: Monte Carlo tree search and extensions.
Communications of the ACM, 55 (3), 106113.
Gelly, S., & Silver, D. (2007). Combining online and offline knowledge in UCT. In Proceedings of the 24th International Conference on Machine learning, pp. 273280.
Gittins, J., Weber, R., & Glazebrook, K. (1989). Multi-armed bandit allocation indices.
Wiley Online Library.
Guez, A., Silver, D., & Dayan, P. (2012). Efficient Bayes-adaptive reinforcement learning
using sample-based search. In Advances in Neural Information Processing Systems
(NIPS), pp. 10341042.
Hart, P., Nilsson, N., & Raphael, B. (1968). A formal basis for the heuristic determination
of minimum cost paths. Systems Science and Cybernetics, IEEE Transactions on,
4 (2), 100107.
Jaksch, T., Ortner, R., & Auer, P. (2010). Near-optimal regret bounds for reinforcement
learning. The Journal of Machine Learning Research, 99, 15631600.
Kearns, M., Mansour, Y., & Ng, A. (1999). A sparse sampling algorithm for near-optimal
planning in large Markov decision processes. In Proceedings of the 16th international
joint conference on Artificial intelligence-Volume 2, pp. 13241331.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. In Machine
Learning: ECML, pp. 282293. Springer.
Kolter, J., & Ng, A. (2009). Near-Bayesian exploration in polynomial time. In Proceedings
of the 26th Annual International Conference on Machine Learning, pp. 513520.
Madani, O., Hanks, S., & Condon, A. (2003). On the undecidability of probabilistic planning
and related stochastic optimization problems. Artificial Intelligence, 147 (1), 534.
Martin, J. (1967). Bayesian decision problems and Markov chains. Wiley.
881

fiGuez, Silver, & Dayan

Meuleau, N., & Bourgine, P. (1999). Exploration of multi-state environments: Local measures and back-propagation of uncertainty. Machine Learning, 35 (2), 117154.
Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (2000). Complexity of finitehorizon markov decision process problems. Journal of the ACM (JACM), 47 (4),
681720.
Neal, R. M. (1993). Probabilistic inference using markov chain monte carlo methods. Tech.
rep., University of Toronto.
Poupart, P., Vlassis, N., Hoey, J., & Regan, K. (2006). An analytic solution to discrete
Bayesian reinforcement learning. In Proceedings of the 23rd international conference
on Machine learning, pp. 697704. ACM.
Ross, S., Pineau, J., Chaib-draa, B., & Kreitmann, P. (2011). A Bayesian approach for
learning and planning in Partially Observable Markov Decision Processes. Journal of
Machine Learning Research, 12, 17291770.
Ross, S., Pineau, J., Paquet, S., & Chaib-Draa, B. (2008). Online planning algorithms for
POMDPs. Journal of Artificial Intelligence Research, 32 (1), 663704.
Ross, S. (1983). Introduction to stochastic dynamic programming: Probability and mathematical. Academic Press, Inc.
Schmidhuber, J. (1991). Curious model-building control systems. In IEEE International
Joint Conference on Neural Networks, pp. 14581463.
Silver, D., & Veness, J. (2010). Monte-Carlo planning in large POMDPs. In Advances in
Neural Information Processing Systems (NIPS), pp. 21642172.
Silver, D., Sutton, R. S., & Muller, M. (2008). Sample-based learning and search with
permanent and transient memories. In Proceedings of the 25th international conference
on Machine learning, pp. 968975. ACM.
Silver, E. (1963). Markovian decision processes with uncertain transition probabilities or
rewards. Tech. rep., DTIC Document.
Strehl, A., Li, L., & Littman, M. (2009). Reinforcement learning in finite MDPs: PAC
analysis. The Journal of Machine Learning Research, 10, 24132444.
Strens, M. (2000). A Bayesian framework for reinforcement learning. In Proceedings of the
17th International Conference on Machine Learning, pp. 943950.
Sutton, R. (1990). Integrated architectures for learning, planning, and reacting based on
approximating dynamic programming. In Proceedings of the Seventh International
Conference on Machine Learning, Vol. 216, p. 224. Citeseer.
Sutton, R., & Barto, A. (1998). Reinforcement learning. MIT Press.
Szepesvari, C. (2010). Algorithms for reinforcement learning. Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan & Claypool Publishers.
Thompson, W. (1933). On the likelihood that one unknown probability exceeds another in
view of the evidence of two samples. Biometrika, 25 (3/4), 285294.
Tonk, S., & Kappen, H. (2010). Optimal exploration as a symmetry breaking phenomenon.
Tech. rep., Radboud University Nijmegen.
882

fiBayes-Adaptive Monte-Carlo Planning

Vien, N. A., & Ertel, W. (2012). Monte carlo tree search for bayesian reinforcement learning.
In Machine Learning and Applications (ICMLA), 2012 11th International Conference
on, Vol. 1, pp. 138143. IEEE.
Walsh, T., Goschin, S., & Littman, M. (2010). Integrating sample-based planning and
model-based reinforcement learning. In Proceedings of the 24th Conference on Artificial Intelligence (AAAI).
Wang, T., Lizotte, D., Bowling, M., & Schuurmans, D. (2005). Bayesian sparse sampling
for on-line reward optimization. In Proceedings of the 22nd International Conference
on Machine learning, pp. 956963.
Wang, Y., Won, K., Hsu, D., & Lee, W. (2012). Monte Carlo Bayesian reinforcement
learning. In Proceedings of the 29th International Conference on Machine Learning.
Watkins, C. (1989). Learning from delayed rewards. Ph.D. thesis, Cambridge.
Wingate, D., Goodman, N., Roy, D., Kaelbling, L., & Tenenbaum, J. (2011). Bayesian policy
search with policy priors. In Proceedings of the International Joint Conferences on
Artificial Intelligence.

883

fiJournal of Articial Intelligence Research 48 (2013) 783-812

Submitted 08/13; published 11/13

The Complexity of Optimal Monotonic Planning:
The Bad, The Good, and The Causal Graph
Carmel Domshlak
Anton Nazarenko

dcarmel@ie.technion.ac.il
anton.nazarenko@gmail.com

Faculty of Industrial Engineering & Management,
Technion - Israel Institute of Technology,
Haifa, Israel

Abstract
For almost two decades, monotonic, or delete free, relaxation has been one of the
key auxiliary tools in the practice of domain-independent deterministic planning. In the
particular contexts of both satiscing and optimal planning, it underlies most state-of-theart heuristic functions. While satiscing planning for monotonic tasks is polynomial-time,
optimal planning for monotonic tasks is NP-equivalent. Here we establish both negative and
positive results on the complexity of some wide fragments of optimal monotonic planning,
with the fragments being dened around the causal graph topology. Our results shed some
light on the link between the complexity of general optimal planning and the complexity
of optimal planning for the respective monotonic relaxations.

1. Introduction
In domain-independent deterministic (or classical) planning, the world states are represented by complete assignments to a set of variables, the operators allow for deterministic
modications of these assignments, and the objective is to nd a sequence of operators that
sequentially modies a given initial assignment to an assignment that satises a certain
predened goal property. In the last two decades, solvers for this problem have made spectacular advances in their empirical eciency, and this especially in the context of state-space
heuristic search planning techniques. This eciency has been made possible largely by the
ability to exploit monotonic, or delete-free, relaxations of the planning tasks (McDermott,
1999; Bonet & Gener, 2001; Homann & Nebel, 2001).
At a high level, monotonic relaxation replaces the regular value switching semantics of
planning operators with the value accumulating semantics. That is, if an operator switches
the value of a variable v from x to y, then the relaxed version of that operator extends
the value of v from {x} to {x, y}. The key point here is that applying operators under value
accumulating semantics does not reduce the applicability of operators in the future. Two
properties of monotonic relaxation make it especially valuable to automated planning. First,
while deterministic planning is PSPACE-complete even for rather conservative propositional
formalisms, planning for monotonic tasks is polynomial-time (Bylander, 1994), and thus can
be exploited for deriving heuristic estimates. Second, in numerous problems of practical
interest, plans for monotonic relaxations are not that distant from the true plans for these
problems (Homann, 2005; Helmert & Mattmuller, 2007; Helmert & Domshlak, 2009; Bonet
& Helmert, 2010). Hence, starting from the seminal HSP (Bonet & Gener, 2001) and
FF (Homann & Nebel, 2001) planning systems, exploiting, and in particular, explicitly
c
2013
AI Access Foundation. All rights reserved.

fiDomshlak & Nazarenko

planning for, monotonic relaxations became an important ingredient of most systems for
domain-independent deterministic planning. (For a comprehensive survey, see, e.g., Betz &
Helmert, 2009.)
Ideally, a planner reasoning about the cost of the plans for monotonic relaxations should
reason about the cost of optimal plans for monotonic relaxations. Unfortunately, while
regular planning for monotonic tasks is polynomial-time, optimal planning for these tasks
is NP-equivalent (Bylander, 1994), and constant-factor approximations for this problem are
provably hard as well (Betz & Helmert, 2009). Still, admissible heuristic estimates can in
principle exploit tractable fragments of optimal planning for monotonic relaxations (Katz
& Domshlak, 2010). However, to the best of our knowledge, no substantial fragments of
tractability have been revealed for monotonic optimal planning to date.
Identifying signicant fragments of tractability for optimal monotonic planning is precisely our focus here. Our special interest is in establishing connections between the complexity of optimal planning and that of optimal planning for the monotonic relaxations of
the respective planning tasks. This interest is motivated by the new and important role
of methods that combine tractable fragments of regular deterministic planning with monotonic relaxation heuristics (Helmert, 2004; Keyder & Gener, 2008a; Katz & Domshlak,
2010; Katz, Homann, & Domshlak, 2013a, 2013b; Katz & Homann, 2013). In turn, this
comparative perspective has brought us to consider planning tasks in terms of nite-domain
representations that go beyond the standard propositional representation formalisms such
as STRIPS (Fikes & Nilsson, 1971) and ADL (Pednault, 1989). Some explanation, and
possibly even justication, for this choice of analysis are in place here.
Due to their close relationship to rst-order and propositional logics, propositional representations have dominated the area of automated planning since the early days of AI research. For instance, the propositional PDDL language is still a de facto standard problem
description language in the planning community (Fox & Long, 2003). However, propositional languages blur a lot of important structure that is present in typical planning tasks of
interest. As we discuss later on, nite-domain representations (FDR) that go beyond propositional state variables (Backstrom & Klein, 1991; Backstrom & Nebel, 1995; Helmert,
2009) allowed for much deeper and much more discriminative analysis of automated planning complexity. In turn, some of these formal developments have already been translated
into practical advances in planning, allowing for the introduction of eective enhancements
of monotonic relaxation heuristics (Fox & Long, 2001; Helmert, 2004; Helmert & Gener,
2008; Keyder & Gener, 2008a; Cai, Homann, & Helmert, 2013; Katz et al., 2013a,
2013b), abstraction heuristics (Edelkamp, 2001; Helmert, Haslum, & Homann, 2007; Katz
& Domshlak, 2010), decomposition-based planning (Nissim, Brafman, & Domshlak, 2010;
Nissim & Brafman, 2012), search-topology analysis (Homann, 2011), and many others.
Nonetheless, under the value accumulating semantics of monotonic relaxation, FDR no
longer maintains its key advantage over propositional representations, because there no
longer seems to be any reason to prefer explicit representation of certain mutual exclusion
relationships between the propositions. Therefore, in principle, the results presented in
what follows can be phrased, and sometimes even extended, in the context of propositional
representations such as STRIPS. Why, then, have we chosen to view the complexity of
optimal relaxed planning through the lens of FDR? The primary reason is our interest in
comparative complexity analysis of optimal planning and optimal planning for the respective
784

fiThe Complexity of Optimal Monotonic Planning

monotonic relaxations. Departing from previously discovered fragments of tractability for
both satiscing and optimal planning, we approach the following two high-level questions:
1. For what fragments of deterministic planning, if any, is optimal planning hard but
optimal (monotonically) relaxed planning easy?
2. For what fragments of deterministic planning, if any, is optimal planning easy yet
optimal (monotonically) relaxed planning hard?
For regular planning, the best classication we have these days for its worst-case time
complexity exploits the properties of some graphical structures induced by the planning
tasks, together with various properties of the FDR state variables such as the size of their
domains. Hence, discussing optimal relaxed planning for FDR tasks keeps us in direct
relation to that well-explored complexity map of regular deterministic planning. Moreover,
we show that some known links between the planning complexity and graph-topological
properties of the FDR tasks are even stronger in the case of optimal relaxed planning.
The second reason for our choice is that recent work has already revealed interesting
interplays between (either complete or partial) monotonic relaxation of nite-domain variables and graphical structures induced by the FDR tasks. The respective results are in the
context of computational complexity of non-optimal planning (Katz et al., 2013b), heuristic estimates (Keyder & Gener, 2008b; Katz et al., 2013a; Katz & Homann, 2013), and
search-topology analysis (Homann, 2011). For instance, Homann (2011) showed that, if
the causal graph of the FDR task is acyclic, and every variable transition is invertible, then
the h+ heuristic induced by optimal relaxed plans from the evaluated states has no local
minima. This result in particular testies that examining monotonic relaxations through
the lens of FDR can lead to some crisp and concisely formulated results. The same can
be found in our work here: While we show how some of our results can be easily reformulated, and sometimes even generalized, in terms of STRIPS, some of our other results do
not conform so easily to STRIPS reformulation.
Finally, while the immediate value of our results in this work is mostly theoretical, we
would like to see them as a step towards exploiting optimal relaxed planning to devise
heuristic functions for deterministic planning. Some of our results, such as Theorem 4, can
in fact be directly used within the framework of implicit abstractions (Katz & Domshlak,
2010), while some other results can possibly be exploited within various frameworks of
partial monotonic relaxation such as, e.g., the recent red-black planning framework of Katz
et al. (2013b, 2013a). To what extent this will actually happen remains, of course, to
be seen. However, the very focus of both implicit abstractions and red-black planning on
nite-domain task representations should make it much easier to assess the relevance of our
results to these frameworks.

2. Formalism, Background, and Related Results
We use the notation [n] to refer to the set {1, . . . , n}. In directed graphs, the edge from x
to y is denoted by (x, y), and in undirected graphs, the edge between x and y is denoted by
{x, y}. By ||x|| we refer to the representation size of object x, not to be confused with |x|,
which denotes the number of elements in set x.
785

fiDomshlak & Nazarenko

2.1 FDR, MFDR, and Monotonic Relaxation
Here we adopt the terminology and notation of Katz et al. (2013b). A planning task
in nite-domain representation (FDR) is given by a quintuple  = V, A, I, G, cost,
where:
 V is a set of state variables, with each v  V being associated with a nite domain
D(v). A partial variable assignment p is a function on a variable subset V(p)  V that
assigns each v  V(p) a value p[v]  D(v) of its domain. A partial variable assignment
s is called a state if V(s) = V .
 I is an initial state. The goal G is a partial variable assignment to V .
 A is a nite set of actions. Each action a is a pair pre(a), e(a) of partial variable
assignments to V called precondition and eect, respectively.
 cost : A  R0+ is a real-valued, nonnegative action cost function.
Auxiliary notation:
 For a partial assignment p and a variable subset V   V(p), by p[V  ] we denote the
assignment provided by p to V  . For ease of presentation, we sometimes also specify
partial assignments as sets of constructs v  d, in which v  V and d  D(v).
 For a variable v  V , by Av  A we denote the actions aecting the value of v, that
is, Av = {a | v  V(e(a))}. For a sequence of actions  and a state variable v  V ,
by v we denote the restriction of  to the actions in Av .
The semantics of FDR tasks is as follows. An action a is applicable in a state s i
s[v] = pre(a)[v] for all v  V(pre(a)). Applying a in state s changes the value of every v 
V(e(a)) to e(a)[v]; the resulting state is denoted by sJaK. By sJa1 , . . . , ak K we denote the
state obtained from sequential application of the (respectively applicable) actions a1 , . . . , ak
starting at state s. Such an action sequence is an s-plan if sJa1 , . . . , ak K[V(G)] = G,
and it is an optimal s-plan if the sum of its action costs is minimal among all s-plans. The
computational task of (optimal) planning is nding an (optimal) I-plan. In what follows,
(optimal) I-plans are often referred simply as (optimal) plans for .
A monotonic nite-domain representation (MFDR) planning task is given by a
quintuple  = V, A, I, G, cost exactly as for FDR tasks, but the semantics is dierent.1
Informally, in MFDR tasks the state variables accumulate their values, rather than switching
between them. More specically, an MFDR state s is a function that assigns each v  V a
non-empty subset s[v]  D(v) of its domain. An MFDR action a is applicable in state s i
pre(a)[v]  s[v] for all v  V(pre(a)). Applying an MFDR action a in state s changes the
value of v  V(e(a)) from s[v] to s[v]  {e(a)[v]}. Respectively, an MFDR action sequence
a1 , . . . , ak  applicable in state s is an s-plan if G[v]  sJa1 , . . . , ak K[v] for all v  V(G).
In all other respects, MFDR and FDR semantics are identical.
1. It is not entirely clear to whom the original formulation of monotonic relaxation for multi-valued variable
domains should be attributed, but it can be traced back at least to the work of Helmert (2006) on the
Fast Downward planning system.

786

fiThe Complexity of Optimal Monotonic Planning

While FDR planning is PSPACE-complete even for propositional state variables, planning for MFDR tasks is polynomial time (Bylander, 1994). Starting with the HSP (Bonet
& Gener, 2001) and FF (Homann & Nebel, 2001) planning systems, exploiting this attractive property of MFDR for deriving heuristic estimates via the notion of monotonic
relaxation became a key ingredient of many planning systems. Given an FDR planning task
 = V, A, I, G, the monotonic relaxation of  is the MFDR task + = . For any
state s of , the optimal relaxation heuristic h+ (s) is dened to be the cost of the optimal
plan for the MFDR task V, A, s, G, and by (optimal) relaxed planning for  we refer
to (optimal) planning for + . If + is a plan for + , then + is referred to as a relaxed
plan for .
Finally, for both FDR and MFDR, we sometimes distinguish between planning tasks in
terms of a pair of standard graphical structures induced by the description of these tasks.
 The causal graph CG of  is a digraph over nodes V . An arc (v, v  ) is in CG i v =
v  and there exists an action a  A such that (v, v  )  V(e(a))V(pre(a))V(e(a)).
In this case, we say that (v, v  ) is induced by a. By succ(v) and pred(v) we respectively
denote the sets of immediate successors and predecessors of v in CG .
 The domain transition graph DTG(v, ) of a variable v  V is an arc-labeled
digraph over the nodes D(v) such that an arc (d, d ) labeled with pre(a)[V \ {v}]
and cost(a) belongs to the graph i both e(a)[v] = d , and either pre(a)[v] = d or
v  V(pre(a)).
2.2 Causal Graph Treewidth and Planning Complexity
Introduced by Halin (1976), tree-width went unnoticed until it was independently rediscovered by Robertson and Seymour (1984) and Arnborg, Cornell, and Proskurowski (1987). It
has since received widespread attention due to its numerous graph-theoretic and algorithmic
applications. Informally, the tree-width of a graph is a measure of how close the structure
of the graph is to a tree. For example, the tree-width of a tree is 1, regardless of its size,
whereas the tree-width of a complete graph over n nodes is n  1. Formally, the tree-width
of a graph is dened via the notion of tree decomposition as follows.
A tree decomposition of a connected undirected graph G = (V, E) is a pair T, , where
T = (V T , E T ) is a tree, i.e., a connected acyclic graph, and  : V T 7 2V such that:
1. For every v  V , the set {t  V T | v  (t)} in T is non-empty and connected.
2. For every (v, u)  E there is a t  V T such that {v, u}  (t).
The width of a tree decomposition T,  of G is max{|(t)| | t  V T }  1, and the treewidth of G, tw(G), is the minimum width over all tree decompositions of G. Following
what appears to be standard terminology, by tree-width of a digraph G we refer to the
tree-width of the undirected graph induced by G (Berwanger, Dawar, Hunter, Kreutzer, &
Obdzralek, 2012).
With the development of parametrized complexity analysis (Downey & Fellows, 1999;
Flum & Grohe, 2006), it has been shown that many NP-hard problems can be solved in
polynomial time when restricted to induce certain problem-specic graphical structures
of a xed tree-width. In particular, constraint satisfaction and constraint optimization
787

fiDomshlak & Nazarenko

problems over nite-domain variables can be solved in time polynomial in the size of the
explicit description of these problems, and exponential only in the tree-width of the induced
constraint graph (Dechter, 2003). Since the causal graph captures a high-level structure
of the planning problems, one would expect its tree-width to play a similar role in the
worst-case time complexity of both satiscing and optimal FDR planning. Unfortunately,
the results in this direction have mostly been negative.
 Under a standard assumption on parametric complexity hierarchy that W[1]  nu-FPT
(Flum & Grohe, 2006), Chen and Gimenez (2010) proved that, for any family of
digraphs C, FDR planning for tasks inducing causal graphs in C is polynomial-time if
and only if the size of connected components in C is bounded by a constant. As the
family of all digraphs with tree-width of 1 trivially fails to satisfy the latter condition,
the immediate corollary of this result is that even satiscing FDR planning restricted
to causal graphs with the tree-width of 1 is not polynomial.
 While the construction in the proof of Chen and Gimenez (2010) uses FDR tasks
with variable domains of parametric size, the work of Gimenez and Jonsson (2009b)
shows that the negative result for causal graphs with the tree-width of 1 holds even if
restricted to such planning tasks with xed variable domains. Specically, Gimenez
and Jonsson show that FDR planning over chain causal graphs is NP-hard even if
restricted to variables with domains of size 5.
These negative results on the role of the causal graphs tree-width in computational
tractability of FDR planning are strong, but apparently tell only part of the story. As
shown by Brafman and Domshlak (2006, 2013), the causal graphs tree-width does play
a role in the worst-case time complexity of FDR planning, but in a tight interplay with
another parameter called the tasks local depth. Informally, local depth of an FDR task 
captures a minmax amount of work required on a single variable in order to solve . Since
later we refer to this result of Brafman and Domshlak, a precise specication of local depth
is warranted here: denoting by P lans() the (possibly innite) set of all plans for an FDR
task , the local depth of  is
 =

min

max {|v |},

P lans() vV

that is,  is the maximal number of value changes of a single state variable, along a plan that
minimizes that quantity among the plans for . By Theorem 6 of Brafman and Domshlak
(2013), FDR tasks  can be solved in time polynomial in |||| and exponential only in
O(tw(CG )   ). Up to some possible stratications based on succinct representation of
internal variable domain dynamics, such as those suggested by Fabre, Jezequel, Haslum,
and Thiebaux (2010), this appears to be the strongest link discovered so far between the
complexity of general FDR planning and the graph-topological properties of the causal
graphs. Note also that this positive result applies only to satiscing planning; it is applicable
to optimal planning only in very limited settings (Fabre et al., 2010; Brafman & Domshlak,
2013).
788

fiThe Complexity of Optimal Monotonic Planning

3. Negative Results: The Bottleneck of Variable Domains
Our focus here is on connections between the worst-case time complexity of optimal relaxed
planning and the structure of the problems causal graphs. Note that the causal graphs
of FDR tasks are trivially invariant under monotonic relaxation: since + = , we have
CG+ = CG . As we just mentioned, previous works have already revealed certain connections between the structure of the causal graphs, and in particular its tree-width, and
the complexity of FDR planning. In what follows, we show that this link is even stronger
and somewhat more intriguing in the case of optimal relaxed planning. Having said that,
we begin with a set of negative results which, at least at rst glance, suggest that no such
link is actually likely.
Denition 1 A connected digraph G = (N, E) is a fork if it contains exactly one node
r  N with non-zero out-degree, that is, E = {(r, n) | n  N \ {r}}. Similarly, G is
an inverted fork if it contains exactly one node r  N with non-zero in-degree, that is,
E = {(n, r) | n  N \ {r}}. The respective special nodes r in fork and inverted-fork graphs
are called the roots of the graphs.
Considering FDR planning tasks with fork and inverted fork causal graphs, the rst
impression might be that these FDR fragments are restricted enough to allow for polynomialtime planning. This, however, is not the case: even non-optimal planning for FDR tasks
with such simple causal graphs is hard, and this even if all variables but the roots are further
restricted to be binary-valued (Domshlak & Dinitz, 2001). On the other hand, especially
since non-optimal relaxed planning for FDR is polynomial-time, these results have no direct
inuence on the complexity of optimal relaxed planning for the respective FDR fragments.
Nonetheless, surprisingly or not, this problem is hard.
Theorem 1 Optimal relaxed planning is NP-equivalent even if restricted to FDR tasks
with fork and inverted-fork structured causal graphs. Moreover, the result holds even if all
state variables but the roots are restricted to binary domains.
Proof: The proof is by polynomial reductions from the NP-equivalent problems of (minimum) Directed Steiner Tree and (minimum) Set Cover (Karp, 1972).
Directed Steiner Tree: Given a digraph G = (N, E) with arc weights w : E  R0+ , a
set of terminals Z  N , and a root vertex nr , nd a minimum weight arborescence
(directed tree) T rooted in nr  N such that all terminals Z are included in T .
Set Cover: Given a collection C of subsets of a nite set S, nd a minimum cardinality
subset C   C such that every element of S belongs to at least one member of C  .
Fragment I: Given a Directed Steiner Tree problem G = (N, E), w, Z, nr , the corresponding fork-structured FDR task  = V, A, I, G, cost is constructed as follows. The
variable set V contains a variable per terminal node in G, plus an extra variable r, that
is, V = {r}  VZ where VZ = {vz | z  Z}. The domain of r, D(r) = N , corresponds
to the nodes of G, and all other variables are binary-valued, with D(vz ) = {0, 1}. In the
initial state, I[r] = nr and I[v] = 0 for all v  VZ . The goal is to achieve value 1 for all
v  VZ . For each arc e = (x, y)  E, the action set A contains a root-changing action
789

fiDomshlak & Nazarenko

ae with pre(ae ) = {r  x}, e(ae ) = {r  y}, and cost(ae ) = w(e). Likewise, for each
terminal z  Z, A contains a vz -changing action az with pre(az ) = {r  z, vz  0},
e(az ) = {vz  1}, and cost(az ) = 0. This construction is clearly polynomial, the causal
graph of  forms a fork rooted at r, and the variable domains in  are as required by the
theorem. It also holds that:
(i) For any relaxed plan  for , the set of arcs {e | ae  r } in G induces a connected
sub-graph G  containing nr such that all terminals Z are included in G  (or otherwise
at least one of the leaf variables could not have been changed by  to its goal value).
Likewise, there is a directed path in G  from nr to every other node n in G  (or
otherwise the respective value n of the root variable r could not have been achieved
along ). Hence, in particular, G  contains an arborescence rooted in nr that includes
all terminals Z.
(ii) Vice versa, let T be an arborescence of G rooted in nr that includes all terminals
Z = {z1 , . . . , zm }, and let {e1 , . . . , ek } be a topological ordering of the arcs of T . Then
ae1 , . . . , aek , az1 , . . . , azm  is a relaxed plan for , and the cost of  is precisely the
weight of T .
Hence, optimal relaxed plans for  induce minimum directed Steiner trees for G = (N, E), w, Z, nr ,
and vice versa.
Fragment II: Given a Set Cover problem S, C with S = {1, 2, . . . , m} and |C| = n,
the corresponding inverted-fork structured FDR task  = V, A, I, G, cost is constructed as
follows. The variable set V contains a variable per member of C, plus an extra variable r,
that is, V = {r}{vc | c  C}. The domain of r is D(r) = {0}S, and all other variables are
binary-valued, with D(vc ) = {0, 1}. In the initial state, I[v] = 0 for all v  V . The goal is to
achieve value m for the special variable r. For i  S, and each subset c  C such that i  c,
the action set A contains a root-changing action ai;c with pre(ai;c ) = {r  (i  1), vc  1},
e(ai;c ) = {r  i}, and cost(ai;c ) = 0. Likewise, for each c  C, A contains a vc -changing
action ac with pre(ac ) = {vc  0}, e(ac ) = {vc  1}, and cost(ac ) = 1. The construction
is polynomial, the causal graph of  forms an inverted fork rooted at r, and the variable
domains in  are as required by the theorem. Note that, due to the chain-like structure of
the domain transition graphs in , there is no dierence between the plans for  and for
+ , and it is easy to verify that any plan for  induces a cover of S of the same cost, and
vice versa. Hence, optimal relaxed plans for  induce minimum set covers for S, C, and
vice versa.

Corollary 1 Optimal relaxed planning is NP-equivalent even if restricted to FDR tasks
with the causal-graph tree-width of 1.
This corollary is immediate from Theorem 1 as the undirected graphs induced by both
forks and inverted forks are a special case of trees and thus have tree-width of 1. At rst
glance, the message of Corollary 1 is discouraging with respect to our agenda: the structure
of the causal graphs does not seem to play a major role in the complexity of optimal
relaxed planning for FDR. Our next result, however, seems to be even more discouraging
with respect to the prospects of tractability of optimal relaxed planning for FDR.
790

fiThe Complexity of Optimal Monotonic Planning

Theorem 2 Optimal relaxed planning is NP-equivalent even if restricted to FDR tasks
with two state variables.
Proof: The proof is by a polynomial reduction from the (minimum) directed Steiner tree
problem, and in fact, the proof is very similar to that of the fork case of Theorem 1. Given
a Directed Steiner Tree problem G = (N, E), w, Z, nr  with Z = {z1 , . . . , zm }, we compile
it to an FDR task  = {v1 , v2 }, A, I, G, cost as follows. The domain of v1 corresponds
to the nodes of G, and the domain of v2 corresponds to the terminal nodes and the root
node, that is, D(v1 ) = N and D(v2 ) = Z  {nr }. In the initial state, both I[v1 ] = nr and
I[v2 ] = nr , and the goal is to achieve value zm for v2 . For each arc e = (x, y)  E, the
action set A contains a v1 -changing action ae with pre(ae ) = {v1  x}, e(ae ) = {v1  y},
and cost(ae ) = w(e). Likewise, denoting nr by z0 , for 1  i  m, A contains a v2 -changing
action azi with pre(azi ) = {v1  zi , v2  zi1 }, e(azi ) = {v2  zi }, and cost(azi ) = 0.
The construction is polynomial, and its correctness stems from analysis identical to that of
the proof of Theorem 1.

Theorem 2 shows that even the dimensionality of the FDR state spaces plays a secondary
role, if any, in the complexity of optimal relaxed planning. By that, however, it answers
one of the two macro-questions on our agenda:
Corollary 2 There exist fragments of FDR for which optimal planning is polynomial-time,
while optimal relaxed planning is NP-equivalent.
This corollary is immediate from Theorem 2 and polynomial-time solvability of optimal
planning for FDR tasks with a xed number of state variables.

4. Positive Results I: State Variables with Fixed-Size Domains
Depending on the readers background and intuitions, Theorem 2 can either surprise or seem
somewhat predictable. In any case, it was Theorem 2 that led us to consider a dierent
(and this time fruitful) fragmentation of optimal relaxed planning.
A closer look at Theorem 1 and Lemma 2 reveals that the size of the FDR variable
domains might be crucial in the complexity of optimal relaxed planning: While the proofs
of these two claims rely heavily on the parametric domain size of some of the state variables,
these proofs also imply that optimal relaxed planning is hard even if only a single FDR
variable comes with a parametric domain size. Departing from this observation, we now
show that, after all, the topology of the causal graph does play an interesting role in worstcase time complexity classication of optimal relaxed planning for FDR tasks. In particular,
it turns out that bounding the tree-width of the causal graph by a constant is all it takes
to achieve polynomial-time optimal relaxed planning for FDR tasks with xed-size variable
domains.
Theorem 3 For any family of directed graphs C, if the tree-width in C is bounded by a
constant, then optimal relaxed planning for FDR tasks with xed-size variable domains and
causal graphs in C is polynomial-time.
791

fiDomshlak & Nazarenko

Proof: The proof of Theorem 3 is inspired by and closely resembles the approach of Brafman
and Domshlak (2013) discussed in Section 2.2. Given an FDR task  = V, A, I, G, cost,
we compile it into a constraint optimization problem COP+ = (X , ) over nite-domain
variables X , functions , and the global objective to minimize  (X ). If + is unsolvable, then all the assignments to X evaluate the objective function to . Otherwise, the
optimum of the objective is obtained on and only on the assignments to X that correspond
to optimal plans for + , that is, to optimal relaxed plans for .
Let |V | = n,  = maxvV |D(v)|, and recall that pred(v) for state variable v  V denotes
the set of vs immediate predecessors in the causal graph.
 For each state variable v  V , X contains a variable xv that represents the choice of a
subset of actions from Av to participate in the plan we are looking for. These possible
choices form the domain D(xv ) of xv , and each such choice is represented by a set of
size smaller or equal to , with each element of that set being a quadruple
(d, id, a, t),
with d  D(v), id  {v}  pred(v), t  {1, . . . , n}, and, if id = v, then a  {a 
Av | e(a )[v] = d} and otherwise a =. At a high level, if we view state variables as
active decision makers, then d is a value that the relaxed variable v aims to achieve
and accumulate at time point t, either by itself using action a, or by delegating this
task to another variable id. As we show later on, no variable should accumulate more
than  values, and since the accumulated values are never lost, optimal plans for +
cannot be longer than n actions.
 For each state variable v  V ,  contains a non-negative, extended real-valued function v from D(xv ). Likewise, for each pair of state variables {v, w} such that the
causal graph CG contains either arc (v, w) or arc (w, v),  contains an indicator
function v,w : D(xv )  D(xw )  {0, }. To simplify the specication of v,w , we
dene a set of auxiliary constraints as follows.
(S1) [Precondition Constraint] An assignment v1 , . . . , vn  to X satises S1 i, for all
v  V , (d, v, a, t)  v implies that, for each w  V(pre(a)),
pre(a)[w]  {I[w]}  {d | (d , , , t )  w , t < t}.

(1)

(S2) [Delegation Constraint] An assignment v1 , . . . , vn  to X satises S2 i, for all v  V ,
(d, w, , t)  v implies that, for some a  Av  Aw with d  e(a)[v], (, w, a, t)  w .
(S3) [Goal Achievement Constraint] An assignment v1 , . . . , vn  to X satises S3 i, for
all v  V(G),
G[v]  {I[v]}  {d | (d, , , )  v }.
(2)
Constraint S1 ensures that preconditions of actions to which a variable is committed
are provided on time. Constraint S2 ensures that the outsourced value achievements are
fullled at the required time points. Finally, constraint S3 simply veries that the value of
v induced by v is a goal value. Importantly, S3 corresponds to a set of n unary constraints,
792

fiThe Complexity of Optimal Monotonic Planning

and S1 and S2 can both be represented as a set of binary constraints over X . Given that,
functions  are specied as

v (v ) =
cost(a),
(,v,a,)v

{
0, {v , w } satises S1(xv , xw ), S2(xv , xw ), S3(xv ) and S3(xw )
v,w (v , w ) =
,
, otherwise

(3)

where S1(xv , xw ), S2(xv , xw ), and S3(xv ) correspond to the binary and unary constraints
induced respectively by S1, S2, and S3 on the COP variables xv and xw .
Let us now take a closer look at COP+ constructed as above for the problems in the
scope of Theorem 3.
(1) The constraint network of COP+ corresponds to the undirected graph induced by the
causal graph CG+ (= CG ). Hence, since the tree-width of the latter is bounded by
a constant by the scope of the theorem, so is the tree-width of the constraint network
of COP+ . While nding an optimal tree decomposition of a graph G is NP-hard,
a tree decomposition of G with width c  tw(G) for a low constant c can be found
in time polynomial in the size of G (Robertson & Seymour, 1991; Becker & Geiger,
1996; Amir, 2010). Hence, COP+ can be solved in time polynomial in the size of its
representation using the standard message-passing algorithm for constraint optimization
over trees (Dechter, 2003).
(2) Recall that the values of the COP variable xv are sets of quadruples (d, id, a, t) of size
 . Then, the size of the xv s domain D(xv ) is upper-bounded by
(|D(v)|  |{z}
n  (|Av | + 1)  (n)) ,
| {z }
| {z } | {z }
d

id

a

(4)

t

and since  = O(1), we have |D(xv )| = O(poly(||||)). Together with (1), that implies
that COP+ can be solved in time O(poly(||||)).
We now prove the correctness of this compilation by showing that, if + is unsolvable,
then all the assignments to X evaluate the objective function  (X ) to , and otherwise, the objective is minimized on and only on the assignments to X that correspond to
optimal plans for + .
First, given an assignment  = v1 , . . . , vn  to X such that  () < , we show
that  induces a valid plan  for + of cost  (). Note that, since  () < ,
by Eq. 3 we have  satisfying constraints
S1-S3.

Consider the multi-set Z = vV {(a, t) | (, v, a, t)  v } induced by , and let
Z = {(a1 , t1 ), . . . , (am , tm )}, m = |Z|,
be an arbitrary ordering of Z such that, for 1  j < i  m, it holds that tj  ti . For
1  i  m, let v be the variable in charge of performing the action ai  in , that is,
(e(ai )[v], v, ai , ti )  v . For each w  V(pre(ai )), Eq. 1 in constraint S1 implies that either
pre(ai )[w] = I[w] or there is some (pre(ai )[w], id, a, t)  w with t < ti . In the latter case,
793

fiDomshlak & Nazarenko

if id = w, then by the construction of  , a = aj for some j < i, and by the denition
of D(xw ), pre(ai )[w] = e(aj )[w]. Otherwise, if id = w for some w = w, then by the
denition of S2, pre(ai )[w] = e(a )[w] for some (, w , a , t)  w . Thus, a = aj for some
j < i, and pre(ai )[w] = e(aj )[w]. Therefore, the action sequence
 = a1 , . . . , am 
is applicable in the initial state I of + , and given that,  satisfying S3 implies that 
is a plan for + . Finally, it is immediate from the construction of  and Eq. 3 that
cost( ) =  ().
We now show that any optimal plan  = a1 , . . . , am  for + induces an assignment
 = v1 , . . . , vn  to X such that  ( ) = cost(). By the denition of MFDR,
for 1  i  m and for each state variable v  V , IJa1 , . . . , ai1 K[v]  IJa1 , . . . , ai K[v].
By optimality of , for 1  i  m, there exists at least one variable v  V for which
IJa1 , . . . , ai1 K[v]  IJa1 , . . . , ai K[v]. In particular, that implies that actions {a1 , . . . , am }
are all dierent, and for each variable v  V , if


/v = {ai | IJa1 , . . . , ai1 K[v]  IJa1 , . . . , ai K[v]},
then2 |/v|  .
Adopting an arbitrary ordering {v1 , . . . , vn } of the state variables V , for 1  j  n, let
/vj = {aj1 , . . . , ajmj }. In turn, for 1  l  mj , let djl  D(vj ) be the value achieved and
accumulated for vj by the action ajl , i.e., IJa1 , . . . , ajl K[vj ] \ IJa1 , . . . , ajl 1 K[vj ] = {djl }. For

1  l  mj , if ajl  j1
k=1 /vk , then vj is set to contain (djl , vj , ajl , jl ), and otherwise, vj
is set to contain (djl , vk , , jl ) for k = min {k  | ajl  /vk }.
By the construction of  , each action a from  is present in the value of exactly one
variable xv , and by Eq. 3, v (v ) sums up the cost of a exactly once. Hence, if  satises
the constraints S1-S3 that are enforced by the step functions v,w , we have  ( ) =
cost(). The former also directly follows from the construction of  . For 1  j  n,
mj
let vj = {(djl , idjl , ajl , tjl )}l=1
. By the denition of the values djl as above, the set of
values {dj1 , . . . , djmj } is exactly the set of values of vj that gets accumulated by the relaxed
plan  from I, and thus satisfaction of S3 follows from  being a plan for + . Again, by
the construction of  , the sequence of time points {tj1 , . . . , tjmj } corresponds to the time
points of the rst achievements of {dj1 , . . . , djmj }, respectively, along , and for each such
rst achiever ajl along , it is captured and properly scheduled either by vi or by a neighbor
of vi in the causal graph. Hence, the constraints S1 and S2 are all satised as well. This
nalizes the proof for the compilation correctness, and thus of Theorem 3.

Note that Theorem 3 in particular answers the second macro-question on our agenda:
Corollary 3 There exist fragments of FDR for which (even satiscing) planning is NPequivalent, while optimal relaxed planning is polynomial-time.
2. That corresponds
to the well-known fact that, under our notation, optimal plans in MFDR cannot be

longer than vV |D(v)|  n.

794

fiThe Complexity of Optimal Monotonic Planning

This corollary is immediate from Theorem 3 and the discovery of Gimenez and Jonsson
(2009b) that FDR planning over chain causal graphs is NP-hard even if restricted to variables
with domains of size 5.
Following our STRIPS vs. FDR discussion in the introduction, Theorem 3 trivially
implies that optimal relaxed planning for STRIPS tasks  can be done in time polynomial
in |||| and exponential only in the tree-width of the causal graph. This is actually an
example of a tractability fragment for which one can only benet from switching to a
propositional representation: While the formulation of the result remains the same, the
coverage of the result grows because, if the size of the FDR variable domains is bounded by
 = O(1), then the tree-width of the causal graph under STRIPS representation is at most
 times larger than this under FDR. However, it can also be smaller, down to identical.
Later, however, we present some results that directly benet from the nite-domain input
representation of the planning tasks.
Our discussion in the remainder of this section addresses the readers familiar with the
work of Brafman and Domshlak (2013) in detail. This discussion can be skipped without
any loss of continuity.
At rst view, the compilation in the proof of Theorem 3 brings to mind the compilation in the algorithm
v1
v2
vn
behind the proof of Theorem 6 of Brafman and Domshlak (2013). One might thus naturally ask whether that
algorithm cannot be used directly for the proof of our
Theorem 3. As it stands, however, the algorithm of
vn+1
Brafman and Domshlak does not yield polynomialtime complexity on those tasks with which Theorem 3
is concerned. To see why, consider an FDR task  = V, A, I, G, cost with V = {v1 , . . . , vn+1 },
where, for all vi , D(vi ) = {0, 1}, I[vi ] = 0, and G[vi ] = 1, and A = {a1 , . . . , an } with
V(pre(ai )) = , V(e(ai )) = {vi , vn+1 }, and e(ai )[vi ] = e(ai )[vn+1 ] = 1. The causal graph
of , depicted above, has tree-width of 1. However, for any plan  for + , maxvV {|v |} 
n, and the local depth + is n. This is because + cannot be solved without applying each
of the n actions A at least once, and each of these actions aects the value of the variable
vn+1 . Hence, nding even a non-optimal plan for + using the algorithm of Brafman and
Domshlak (2013) will take time exponential in ||||.
As a nal note, it actually can be shown that the algorithm of Brafman and Domshlak
(2013) is optimal and polynomial-time on a sub-class of MFDR tasks like those in Theorem 3
but also restricted to single-eect operators. It is multiple-eect actions that complicate
matters, and require a dierent algorithmic approach to guarantee planning tractability.

5. Positive Results II: M-unfoldable State Variables
Despite the discouraging results in Section 3, we now return to consider FDR tasks with
parametric-size domains. Recall that, while the variable values of monotonic relaxation +
correspond to sets of values of the respective variables in , these large variable domains in
+ are given implicitly, via the variable domains D(v1 ), . . . , D(vn ) of . This conciseness of
representation, however, hides many aspects of the problem structure in + that otherwise
might have be exploited for planning eciency. In particular, reasoning about the domain
795

fiDomshlak & Nazarenko

transition graphs induced by the FDR tasks has been successfully exploited in complexity
analysis of FDR (Jonsson & Backstrom, 1998; Domshlak & Dinitz, 2001; Katz & Domshlak,
2008; Gimenez & Jonsson, 2009a). In contrast, in monotonic relaxations, the true domain
transition graphs of + , denoted henceforth as DTG(v, + ), cannot always be represented
explicitly because the number of nodes in these graphs is exponential in ||||. However,
this is not always, or does not always have to be, the case, and below we focus on planning
with such accessible monotonic variables.
Denition 2 Given an FDR planning task  = V, A, I, G, cost, the eective domain
D (v) of v  V in + consists of all value subsets   D+ (v) = 2D(v) \  that are reachable
from {I[v]} in DTG(v, + ). That is,   D (v) i
(i) I[v]  , and
(ii) for each value d  , there is a directed path from I[v] to d in the unlabeled digraph
induced by DTG(v, ) such that all the values along that path belong to .
The elements of D (v) are called the eective values of v in + .
Denition 3 Let  be an innite set of FDR tasks, and  be a property of state variables
that, for each task   , partitions the state variables of  into those that satisfy 
(referred as -variables), and those that do not satisfy . We say that -variables in  are
monotonically unfoldable (M-unfoldable) if there exists an integer k  N such that,
for every task    and every -variable v of , |D (v)| = O(||||k ).
 in Denition 3 can be any property of FDR state variables, and in particular, any
property dened with respect to the tasks causal graphs, such as root, sink, nodes
whose causal graph in-degrees are larger than their causal graph out-degrees, etc. Informally, -variables of a set of FDR tasks  are M-unfoldable if, for every task    and
every -variable v of , the relevant subgraph of DTG(v, + ) can be described explicitly
in space polynomial in the representation size of . For instance, v is trivially M-unfoldable
if the size of its domain in  is bounded by a constant, or even by O(log(||||)). More generally, let DTG (v, ) be the digraph obtained from the (labels ignored) domain transition
graph DTG(v, ) by unifying parallel edges. It is not hard to verify from Denitions 2 and 3
that v is M-unfoldable if and only if the number of arborescence subgraphs of DTG (v, )
rooted in I[v], and covering G[v] if v  V(G), is O(poly(||||)).
We now return to consider fork-structured FDR tasks. While in Theorem 1 we considered
fork-structured FDR tasks with only root variables being unrestricted, we now consider an
inverse fragment, corresponding to fork-structured FDR tasks with only root variables
being restricted. Optimal FDR planning for such tasks is polynomial-time for |D(r)| =
2 (Katz & Domshlak, 2010), but it is NP-equivalent for |D(r)| > 2 (Katz & Keyder, 2012).
In contrast, Theorem 4 below shows that optimal relaxed planning for fork-structured FDR
tasks is polynomial-time for a much wider class of root variables. Moreover, a simple
observation behind the construction in the proof of Theorem 4 is later generalized to capture
a much richer fragment of causal graphs.
Theorem 4 Optimal relaxed planning is polynomial time for any set of FDR tasks 
with fork-structured causal graphs and M-unfoldable root variables.
796

fiThe Complexity of Optimal Monotonic Planning

Proof: Let  = V, A, I, G, cost be a fork-structured FDR task with root r and Vleafs =
V \ {r} = {v1 , . . . , vn }. We assume that goal values are specied for all variables in Vleafs ;
this is because none of the leaves in Vleafs \ V(G) need to change their value at all, and thus
they can be schematically removed from the problem. Given such a FDR task , an optimal
plan for its relaxation + can be constructed as follows.
 All the eective values   D (r) consistent with the goal (that is, G[r]   if
r  V(G)) are processed one by one, independently. For each such eective value ,
we extract the following information.
(1) For the root variable r, we determine a cheapest path from I[r] to  in DTG(r, + ),
with () denoting the action sequence inducing that path.
(2) For each leaf variable v  Vleafs , we
(a) schematically remove from the domain transition graph DTG(v, ) all the
arcs labeled with actions a that are not supported by , that is, actions a
with r  V(pre(a)) and pre(a)[r]  , and then
(b) determine a cheapest path from I[v] to G[v] in that arc-reduced domain
transition graph, with  (G[v]) denoting the action sequence inducing that
path.
 Return the concatenation of action sequences ( )   (G[v1 ])  . . .   (G[vn ]) where
[
]
n


cost( (G[vi ])) ,
 = argmin cost(()) +
D (r)

i=1

and cost() for an action sequence  is the sum of the costs of actions along .
The algorithm is polynomial-time given an explicit description of the eective part of
DTG(r, + ), and thus it is polynomial-time if r is M-unfoldable. Recall that, since the
causal graph is acyclic, no action aects more than one variable. The correctness of the
algorithm stems from a simple observation that, for any relaxed plan  for a fork-structured
FDR task ,  = r  v1  . . .  vn is also a relaxed plan for , and (trivially) of identical
cost. Hence, while searching for an optimal relaxed plan for , we can restrict ourselves to
plans of the latter form, and it is immediate from the description of the algorithm that it
nds the cheapest such plan.

As an aside, following our STRIPS vs. FDR discussion, note that Theorem 4 provides
an example for exploiting value grouping induced by the FDR representation of the planning tasks. The simple algorithm in the proof exploits the fact that only the actions that
change the value of a leaf variable depend on its value, and this prevents restrictions from
being placed on either the size of the leaf domains, or on the structure of their domain
transition graphs. Of course, Theorem 4 can also be reformulated in terms of STRIPS, yet
this would require the respective partition of the propositions to be given/discovered, which
is essentially equivalent to starting with something like FDR input in the rst place.
While the scope of the tractability result in Theorem 4 is fairly limited in terms of
the causal graph structure, the nice property of the sets of optimal relaxed plans for forkstructured FDR tasks, exploited in the proof of Theorem 4, can be generalized to a much
797

fiDomshlak & Nazarenko

wider fragment of causal graphs. In turn, this generalization allows us to provide our next
tractability result for a wide fragment of optimal relaxed planning for FDR.
Lemma 1 Let  = V, A, I, G, cost be an FDR task with a directed acyclic causal graph,
and let {v1 , . . . , vn } be an arbitrary topological ordering of V with respect to CG . Then,
for any plan  for + ,  = v1  . . .  vn is also a plan for + .
Proof: Directed acyclicity of the causal graph in particular implies that no action aects
more than one variable. The proof of the lemma stems from combining this property with
(i) the fact that  preserves the order of the actions vi as in , and (ii) the core property
of monotonic relaxations + that, for any variable v, any value d  D(v), and any state s
of the relaxed task + , if d  s[v], then d  s [v] for any s reachable from s in + .
Since CG forms a DAG and the state variables are ordered according to a topological
ordering of CG , V(pre(a)[v1 ])  {v1 } for all actions a  v1 . Thus, order preservation of
v1 along  with respect to  implies that v1 is applicable in I, with IJv1 K[v1 ] = IJK[v1 ],
and IJv1 K[vi ] = I[vi ] for i > 1. Assume now that, for i  1, v1  . . .  vi is applicable in
I, and
{
IJK[vj ], j  i
IJv1  . . .  vi K[vj ] =
.
(5)
I[vj ],
j>i
Together with the topological ordering of V and order preservation of vi +1 along  with
respect to , Eq. 5 implies that vi+1 is applicable in IJv1  . . .  vi K, and
IJv1

{
IJK[vj ],
j =i+1
.
 . . .  vi KJvi+1 K[vj ] =
IJv1  . . .  vi K[vj ], otherwise

(6)

Putting Eqs. 5 and 6 together then proves the induction hypothesis, and for i = n, Eq. 5
boils down to
IJ K = IJv1  . . .  vn K = IJK.

Denition 4 Let  be an innite set of FDR tasks. We say that the tasks in  are Munfoldable if all state variables in  are M-unfoldable.
Theorem 5 Let  be an innite set of M-unfoldable FDR tasks with directed acyclic causal
graphs. If both the tree-width and node in-degree of the causal graphs in  are bounded by
a constant, then optimal relaxed planning for  is polynomial-time.
Proof: Similarly to the proof of Theorem 3, the proof of Theorem 5 is based on a planningto-COP compilation. Given an FDR task  = V, A, I, G, cost, we compile its monotonic
relaxation + into a constraint optimization problem COP+ = (X , ) over variables X ,
functions , and the global objective to minimize  (X ) such that, if + is unsolvable,
then all the assignments to X evaluate the objective function to , and otherwise, the
optimum of the objective is obtained on and only on the assignments to X that correspond
to optimal plans for + . The specic construction of COPs here relies on the property of
monotonic relaxations of DAG-structured FDR tasks expressed by Lemma 1.
798

fiThe Complexity of Optimal Monotonic Planning

Given an FDR task  = V, A, I, G, cost as in the theorem, COP+ = (X , ) is specied
as follows. For each state variable v  V ,
 X contains a variable xv with domain D(xv ) = D (v), that is, the eective domain
of v in + , and
  contains a non-negative, extended real-valued function v over v and its immediate
ancestors in the causal graph, that is, over {xv }  {xw | w  pred(v)}.
Assuming an arbitrary xed ordering {w1 , . . . , wk } of vs immediate ancestors pred(v), for
each pred  D (pred(v)) = D (w1 )      D (wk ), let DTG(v, + |pred ) denote the
restriction of DTG(v, + ) to only edges supported by pred : an edge marked with an
action a remains in DTG(v, + |pred ) if and only if, for each w  V(pre(a))\{v}, pre(a)[w] 
pred [w]. Given that, for each eective value   D (v) and each pred  D (pred(v)),
v (, pred ) =  if  is not reachable from I[v] in DTG(v, + |pred ), or if G[v] is specied
yet G[v]  . Otherwise, v (, pred ) equals the cost of a cheapest path from I[v] to 
in DTG(v, + |pred ). In what follows, the action sequence inducing that cheapest path is
denoted by (|pred ).
The properties of COP+ constructed as above for the problems in the scope of Theorem 5 are as follows.
(1) The constraint network of COP+ corresponds to (the undirected graph induced by)
the moral graph of the causal graph CG . Since both in-degree and tree-width of CG
are bounded by a constant, then so is the tree-width COP of the constraint network. As
we mentioned before, given a graph G, a tree decomposition of a graph G with width
c  tw(G) for a low constant c can be found in time polynomial in the size of G and
exponential only in tw(G). Hence, since COP = O(1), COP+ can be solved in time
polynomial in the size of its explicit representation.
(2) Since  is M-unfoldable, the domain size of each COP variable is O(poly(||||)). Together with (1), that implies that COP+ can be solved in time O(poly(||||)).
(3) By the denitions of monotonic relaxation and of domain transition graphs, explicit
description of all DTG(v, + ) for an M-unfoldable FDR task  is polynomial in ||||.
Hence, the construction of functional components , and thus of the entire COP+ , can
be done in time O(poly(||||)).
(4) By the construction of COP+ and Lemma 1, for any topological ordering {v1 , . . . , vn }
of V , every complete assignment  to the COP variables X such that

v ([v], [pred(v)]) =  = 
vV

induces a relaxed plan
([v1 ]|[pred(v1 )])  . . .  ([vn ]|[pred(vn )])
of cost  for , and vice versa. Thus, if + is solvable, then, given an assignment  
to X on which the minimization objective of COP+ is obtained, we can derive from it
(in O(poly(||||)) time) an optimal relaxed plan for . Otherwise, if + is unsolvable,
then all the assignments to X evaluate the objective function to .
799

fiDomshlak & Nazarenko

ONML
HIJK
v1


HIJK
ONML
v2


HIJK
ONML
v3

/ d1,2

d1,1
d1,1

d2,1

d1,2
d1,3

d2,2
d2,3

ONML
HIJK
HIJK
HIJK
/ ONML
/ ONML
o
d1,1 Qo Q
d1,3
d
BB QQQ | 1,2 BB
mm|
m
m
BB Q|Q|Q
B
|
m
m
BB|| QQQmmmmBBB|||
|B
mmQQQQ ||BB
|| BBmmm
Q| B
 }|||mmmmm BB!  }||| QQQQQBB! 
mv
(
HIJK
ONML
HIJK
HIJK
/ ONML
o
/ ONML
d2,1 Qo Q
d
d2,3
m
BB QQQ | 2,2 BB
m
m
|
m
BB Q|Q|Q
B
|
m
m
BB|| QQQmmmmBBB|||
|B
mmQQQQ ||BB
|| BBmmm
Q| B
 }|||mmmmm BB!  }||| QQQQQBB! 
mv
(
HIJK
ONML
HIJK
HIJK
/ ONML
/ ONML
d3,1 o
d3,2 o
d3,3

d1,1

#

/ d2,2
;

d2,1

d3,1

/ d1,3

d1,2
d1,3

#
/ d2,3
;

d2,1

#

/ d3,2
;

d2,2
d2,3

#
/ d3,3
;

(a)

(b)

Figure 1: Illustration for the example used in the discussion of Theorem 5.
This nalizes the proof of Theorem 5, and Corollary 4 below generalizes it to digraphs that
are almost DAGs.

Note that Theorem 5 provides yet another example of exploiting value grouping induced by the FDR representation of the planning tasks. Consider a planning task family
(n) = V, A, I, G, cost in which V = {v1 , . . . , vn }; for 1  i  n, D(vi ) = {di,1 , . . . , di,n };
I[vi ] = di,1 ; G[vi ] = di,n ; and actions

A=
{ai,k,j = {vi  di,k , vi1  di1,j }, {vi  di,k+1 }}.
|
{z
} |
{z
}
1i,jn
1kn1

pre

e

Figure 1a illustrates the causal graph and the domain transition graphs for the task (3) .
The causal graphs in (n) form directed chains, and thus both the tree-width and node
in-degree of the causal graphs in (n) equal 1. Likewise, the eective domain D (vi ) of
each vi in +
(n) is of size n, and thus the tractability of optimal relaxed planning for (n)
is directly covered by Theorem 5. In contrast, if each variable value di,j is represented by
a separate propositional variable, inducing the causal graph as in Figure 1b, then both the
tree-width and node in-degree in the family of the induced causal graphs are of the order
of n, and in fact, the causal graph is not even acyclic. Therefore, Theorem 5 is no longer
directly applicable.
Corollary 4 Let  be an innite set of M-unfoldable FDR tasks. If the size of the strongly
connected components, the tree-width, and the node in-degree of the causal graphs in  are
all bounded by a constant, then optimal relaxed planning for  is polynomial-time.
Proof: Any FDR task  with a causal graph whose strongly connected components (SCCs)
are of size at most k can be compiled into an equivalent FDR task m with a directed acyclic
causal graph by merging the variables of each SCC into a single variable (Seipp & Helmert,
2011). This compilation can be done in time polynomial in |||| and exponential only in k.
The causal graph CGm is obtained from the causal graph CG by contracting all nodes of
each SCC. Since node contraction can only decrease the tree-width, we have tw(CGm ) 
800

fiThe Complexity of Optimal Monotonic Planning

tw(CG ), and thus tw(CGm ) = O(1). Likewise, if the maximal node in-degree in CG
is c, then the maximal node in-degree in CGm is ck, and thus it is also O(1). Finally,
the domain of a variable u in m that is obtained by merging some s SCC {v1u , . . . , vku },
k   k, corresponds to the cross-product of the domains of these SCCs variables. It is
easy to verify from Denition 2 that D (u)  D (v1u )      D (vku ), and thus, together
with k = O(1), M-unfoldability of all v1u , . . . , vku implies |D (u)| = O(poly(||||)), tting3
Denition 3.

Returning now to the statement of Theorem 5, a few comments on its extensions beyond
Corollary 4 are in place. First, note that Theorem 5 as it is does not generalize Theorem 4 for
fork-structured FDR tasks because the latter allows for general, and not only M-unfoldable,
leaf variables. However, it is easy to see that Theorem 5 can be stratied to allow for
such generalization. Since no other variable depends on a leaf v, all we care about in v is
achieving G[v]. Thus, for any optimal relaxed plan , v induces a simple path, and not a
general arborescence, in DTG(v, ). Hence, using binary-valued (G[v] achieved: yes/no)
COP variables xv for the DAG leaf v, and specifying the respective functions v using the
procedure in the proof of Theorem 4, the scope of Theorem 5 is extended to generalize
Theorem 4.
Second, in the case of DAG-structured causal graphs, Denition 2 of eective domains,
on which the notion of M-unfoldability is based, is overly conservative. Instead of deriving
the eective domains for the variables in isolation, we can derive them in a topological order
of the causal graph, given the already derived eective domains of the immediate ancestors.
In specic domains, this can substantially extend the scope of M-unfoldability for FDR tasks
with DAG causal graphs.
Finally, Theorem 5 requires not only the tree-width, but also the in-degree of the causal
graph to be bounded by a constant. As such an extra condition, the latter is sucient,
but not necessary. Below, under the notion of prevail decomposability, we list two local
properties of state variables that guarantee polynomial-time optimal relaxed planning on
arbitrary acyclic causal graphs with a xed tree-width. It is very likely that other such
helpful properties exist, and thus the boundaries of prevail decomposability can be further
extended. Nicely, optimal relaxed planning will remain polynomial-time even if dierent
state variables satisfy dierent such properties, and even if some state variables are not
prevail decomposable, but have xed in-degree.
Denition 5 Let  be an innite set of FDR tasks, and  be a property of state variables
that, for each task   , partitions the state variables of  into those that satisfy 
(referred as -variables), and those that do not satisfy . We say that -variables in  are
prevail decomposable if, for every task    and every -variable v of , either
(i) the set PRv = {pre(a)[pred(v)] | a  Av } of preconditions of actions Av on variables
other than v is of size O(log(||||)), or
3. Note that it is possible that D (u)  D (v1u )  D  (vku ). For instance, if V = {x, y}, D(x) = D(y) =
{0, 1}, I = {x  0, y  0}, G = {x  1, y  1}, and A = {{x  0, y  1}, {x  1}, {y  0, x 
1}, {y  1}}, then D (x) = {{0}, {0, 1}}, D (y) = {{0}, {0, 1}}, but D (xy) = {{x  0, y  0}}. In
fact, this example can be easily extended so that the merged variable xy is M-unfoldable, while both
x and y are not.

801

fiDomshlak & Nazarenko

(ii) the set ARBv of arborescence subgraphs of DTG(v, ) rooted in I[v], and covering G[v]
if v  V(G), is of size O(log(||||)).
We say that the tasks in  are prevail decomposable if all state variables in  are
prevail decomposable.
Note that prevail decomposability of type (i) is tangential to the notion of M-unfoldability:
neither does the former imply the latter, nor the other way around. In contrast, prevail
decomposability of type (ii) is a direct stratication of M-unfoldability because the latter
considers a compacted version DTG (v, ) of DTG(v, ), and furthermore, allows for a
polynomial (rather than logarithmic) bound on the number of arborescence subgraphs.
Theorem 6 Let  be an innite set of M-unfoldable, prevail decomposable FDR tasks with
directed acyclic causal graphs. If the tree-width of the causal graphs in  is bounded by a
constant, then optimal relaxed planning for  is polynomial-time.
Proof: Here as well, our proof of Theorem 6 follows the planning-to-COP compilation
methodology. However, the compilation under prevail decomposability must dier from the
one in the proof of Theorem 5 since we can no longer rely on xed in-degree of the causal
graphs to derive the xed tree-width of the constraint networks from the xed tree-width
of the causal graphs. For ease of presentation, we rst specify the compilation assuming
all the state variables satisfy the specic condition (i) of Denition 5. We then extend the
specication to cover the alternative condition (ii) of Denition 5 as well.
For our construction we need to establish a certain graph-theoretic formalism and a
respective notation. Let G = (V, E) be a graph, and let N : V  2V be the node neighborhood function of G, that is, N (v) = {u | {v, u}  E}. The splitting of v  V with
the support S  N (v) transforms G by adding new vertex v  and edge {v, v  }, and, for all
u  S, removing edge {v, u} and adding edge {v  , u}. Informally, splitting can be seen as
a (non-unique) reverse process to edge contraction, and the nodes added to G by splittings
are called stretch nodes. For example, Figure 2b depicts the graph obtained from the graph
in Figure 2a by splitting the node v with the support of {x, y, u}  N (v) = {x, y, u, w},
adding a stretch node v(1) .
A graph G  is an expansion of G if G can be transformed to G  by a sequence of splittings.
For example, Figure 2c depicts the graph obtained from the graph in Figure 2a by rst
splitting the node v with the support of {x, y}  N (v) = {x, y, u, w}, and then splitting v
with the support of {u, w}  N (v) = {v(1) , u, w}. More specically, G  = (V  , E  ) is an
expansion of G = (V, E) if and only i there exist functions f : V   V and g : E  E 
such that
(a) For v  V , the subgraph of G  induced by f 1 (v) = {v   V  | f (v  ) = v} is a tree, and
(b) For {v, u}  E, if g({v, u}) = {v  , u } then f (v  ) = v and f (u ) = u.
The tree subgraph T  (v) of G  induced by f 1 (v) is called the stretch tree of v. There is a
bijective correspondence between the leaves of T  (v) and the neighbors N (v) of v via the
function g: for each {v, u}  E, there is exactly one edge in E  , g({v, u}), that directly
connects between T  (v) and T  (u). In other words, f induces a partition of V  , with each
part being the stretch tree T  (v) for some v  V , and g maps the edges of G to those edges
802

fiThe Complexity of Optimal Monotonic Planning

x-

y

-
-- 
- 
v/
  ///
//



u

w

(a)

x






v(1)

y

y

x ==

==

v(1)
v

x(1)

v

w

u(1)

@@
@

u

(b)

v(1)

y(1)

v

v(2)
u

y

x

w

(c)

v(2)

u

w(1)
w

(d)

Figure 2: Node splitting and graph expansions.
of G  that connect between the parts of this partition. Finally, if the node degree in G 
is bounded by 3, then G  is called sub-cubic. For example, the expansion in Figure 2c is
sub-cubic, while the expansion in Figure 2b is not.
The above terminology is mostly adopted from Markov and Shi (2011). In addition, we
call an expansion G  of G fully separating if the stretch trees in G  are connected only at
the stretch nodes, and not at the original nodes, of G. That is, G  = (V  , E  ) is a fully
separating expansion of G = (V, E) if there exists a function  : V  V  such that, for each
v  V , it holds that  (v)  f 1 (v) and, for each edge { (v), v  }  E  , v   f 1 (v). For
example, the expansion in Figure 2c is not fully separating, while the expansion in Figure 2d
is.4
Given the above notion of graph expansion, if we now have a problem to be solved on a
graph G, and eciency of solving this problem depends badly, possibly exponentially, on the
node degree in G, then we can try to reformulate this problem over a sub-cubic expansion
G  of G. However, if the eciency of the problem in question also depends badly on the
graphs tree-width, then the tree-width of G  should be as close as possible to that of G.
(The tree-width of G  cannot be smaller than the tree-width of G because G  has G as a
minor.) While there are numerous ecient schemes for sub-cubic graph expansion, most
of them can create expansions of arbitrarily larger tree-width than that of their expandees.
Recently, however, Markov and Shi (2011) showed that this negative side-eect can always
be eliminated, and sometimes even eciently.
Theorem 3.1 of Markov and Shi (2011) states their main result: there is a polynomialtime algorithm that, given a graph G and its tree decomposition of width w, computes a
sub-cubic expansion G  of G with tw(G  )  w + 1. In particular, this result implies that
any graph G admits a sub-cubic expansion whose tree-width is no more than tw(G) + 1, and
that this expansion can be constructed eciently for arbitrary graph families with a xed
4. Without any eective loss of generality, one can assume that  (v) = v, that is, the nodes in V are never
mapped to stretch nodes, but only to their mirrors in V  . However, here we decided to stick to the
explicit use of the  function to avoid confusion between the nodes V and the identically named nodes
in V  .

803

fiDomshlak & Nazarenko

tree-width.5 Moreover, it is straightforward to verify that any expansion can be transformed
in linear time into a fully separating expansion, without increasing the tree-width and node
degrees. Therefore, Theorem 3.1 of Markov and Shi (2011) holds even if we request fully
separating sub-cubic expansions.6
Our COP compilation exploits such tree-width friendly expansions of causal graphs.
Since our focus in Theorem 5 is on digraph families C with the tree-width in C being
bounded by a constant, by Theorem 3.1 of Markov and Shi (2011), any digraph G  C
can be eciently associated with a fully separating sub-cubic expansion G  with tree-width
 tw(G) + 1. Note, however, that the construction of G  ignores the orientation of the arcs
in G: while G is a digraph, G  is an undirected graph, and its construction is based on a
tree decomposition of the undirected graph induced by G. Since our COP compilation does
depend on the direction of the arcs in the causal graph, we will have to restore in G  the
relevant bits of this information about G.
But rst we give some auxiliary notation.
 Given a fully separating expansion G  of (the undirected graph induced by) a digraph
G = (V, E), we consider stretch trees T  (v) as if rooted in the respective nodes  (v),
and by Tv (v) we denote the subtree of T  (v) rooted at v   T  (v).
 Recalling that the graphs G of our interest here are DAGs, and that the leaves of T  (v)
are bijectively associated with the neighbors N (v) of v in G, let N in (v), N out (v) 
N (v) be the partition of vs neighbors in G into immediate ancestors and immediate
descendants of v, respectively.
out (v) we denote the respective neighbors of
 By Nvin (v)  N in (v) and Nvout
 (v)  N
v that are associated with the leaves of the stretch subtree Tv (v). That is, we have
 of T  (v) and some u  T  (u),
u  Nvin (v)  Nvout
 (v) if and only if, for some leaf v
v





G contains edge {v , u } (i.e., g({v, u}) = {v , u }).

We now proceed with specifying our COP compilation for the FDR tasks as in Theorem 6.
Given such a task  = V, A, I, G, cost, let G  = (V  , E  ) be a fully separating, sub-cubic
expansion G  of the causal graph CG with tree-width  tw(CG ) + 1. The respective
constraint optimization problem COP+ = (X , ) is specied as follows.
For each v  V , X contains a variable xv that is schematically associated with the root
 (v) of T  (v), and a variable xv /v for each stretch-tree node v   T  (v) \ { (v)}. The
domain of the variable xv is
{
{ |   D (v), G[v]  }, v  V(G)
D(xv ) =
.
(7)
D (v),
otherwise
The domain of each variable xv /v is
D(xv /v ) = {0, 1}mv  D(xv ),

(8)

5. While determining optimal tree decomposition of a graph is NP-hard, it can be done in polynomial time
for graph families having xed tree-width (Bodlaender, 1996).
6. Requiring the expansions to be fully separating is more of a luxury than a need: relying on this property
simplies the compilation scheme described next, but that scheme can also be modied so to not require
full separation.

804

fiThe Complexity of Optimal Monotonic Planning

where mv = |PRv |. That is, D(xv /v ) is a set of some pairs , , with   {0, 1}mv and  
D (v). For each   {0, 1}mv , by DTG(v, + |) we denote the restriction of DTG(v, + )
to edges supported by : Assuming an arbitrarily xed numbering of the elements of
PRv = {pr1 , . . . , prmv }, an edge marked with an action a such that pre(a)[pred(v)] = pri 
PRv remains in DTG(v, + |) if and only if [i] = 1. For   D (v), by c(|) we denote
the cost of a cheapest path from I[v] to  in DTG(v, + |); in case of unreachability,
c(|) = .
Similarly to the way each node of the causal graphs expansion G  is associated with a
COP variable, it is also associated with a non-negative, extended real-valued function. For
each state variable v  V :
(I) The stretch tree root  (v) is associated with a function v . The scope of v is
Q(v ) = {xv }  {xv /v | v   N  ( (v))},


where N  : V   2V is the node neighborhood function in G  . Note that |N  ( (v))| 
3 because G  is sub-cubic. For each   D(xv ) and each assignment  = {v , v }v N  ( (v))
to Q(v ) \ {xv },
{
c(|H() ), v   N  ( (v)) : v = 
v (, ) =
,
(9)
,
otherwise
where H() is the Hadamard, or entrywise, product of all the indicator vectors
{v }v N  ( (v)) in .
(II) Each leaf stretch node v   T  (v) is associated with a 0/ indicator function v /v ,
the scope of which is
Q(v /v ) = {xv /v , xu /u },
where u is the leaf node of T  (u) such that g({v, u}) = {v  , u }. Here the orientation
of the arcs within the causal graph CG matters. Specically, if {v, u} represents a
causal graph arc from u to v , then v /v zeroes on the assignments (v , , u , u )
such that
 the vector v enables all and only all the preconditions in PRv that are, passively
or actively, supported by the value u of u, and
 the vector u enables all the preconditions PRu , since v does not condition the
u-changing actions in our DAG-structured planning task .
That is, for each v , v   D(xv /v ) and each u , u   D(xu /u ),


0,

u = 1 
v /v (v , v , u , u ) =
1  i  mv : (v [i] = 0)  (u  V(pri )  pri [u]  u ) .


, otherwise
(10)
Note that the value of v /v is independent of the v component of v , v , u , u .
805

fiDomshlak & Nazarenko

Otherwise, if {v, u} represents a causal graph arc7 from v to u, then conversely,


0, v = 1 




v /v (v , v , u , u ) =
1  i  mu : (u [i] = 0)  (v  V(pri )  pri [v]  v ) .


, otherwise
(11)
(III) Each internal stretch node v   T  (v) is also associated with a 0/ indicator function
v /v , but its scope comprises the variable xv /v , together with all the variables xv /v
that correspond to the immediate descendants of v  in Tv (v). That is,
Q(v /v ) = {xv /v }  {xv /v | v   N  (v  )  Tv (v)}.
For each v , v   D(xv /v ) and each assignment  = {v , v } to Q(v /v ) \
{xv /v }, v /v zeroes on (v , v , ) if and only if the vector v enables all and
only all the preconditions in PRv that are (passively or actively) supported by all the
immediate ancestors u  Nvin (v) via the values these ancestors commit to at the
respective stretch-tree root COP variables xu . That is,
{
0, v = H()  v   N  (v  )  Tv (v) : v = v
v /v (v , v , ) =
. (12)
, otherwise
In other words, starting with Eqs. 10 and 11, the support provided by Nvin (v) to v is
communicated to v by the indicator vectors v in , and it is aggregated/summarized
in Eq. 12 by the Hadamard vector product H() .
Complexity-wise, the properties of the COP+ constructed as above are as follows.
(1) The constraint network of COP+ is obtained from the expansion G  by replacing each
 be a graph
subgraph of G  induced by nodes Q( ) with a clique over Q( ). Let GQ
with nodes Q( ), x  X , and edges {Q( ), Q( )} for (only) all pairs ,  such that
 is isomorphic to
Q( )  Q( ) = . By the construction of the COP functions , GQ

G . Likewise, since |Q( )  Q( )|  1 for all pairs of functions  ,  , the tree-width
 )  max |Q( )|. Together that implies
COP of the constraint network is  tw(GQ



COP  tw(GQ
)max |Q( )| = tw(G  )max |Q( )|  4tw(G  )  4(tw(CG )+1) = O(1).




Hence, since nding a constant-factor approximation to the graphs tree-width is polynomial in the size of the graph and exponential only in its tree-width, COP+ can be
solved in time polynomial in the size of its representation.
(2) By M-unfoldability of  and Eq. 7, for v  V , the domain size of each COP variable xv
is O(poly(||||)). The domain of each stretch node variable xv /v is a cross-product of
two sets. The size of the second set in Eq. 8 is O(poly(||||)) because so is the domain
size of the respective variable xv . The size of the rst set in Eq. 8 is 2|PRv | and, by
Denition 5, 2|PRv | = 2O(log(||||)) = O(poly(||||)). Together with (1), this implies that
COP+ can be solved in time O(poly(||||)).
7. Since Theorem 6 is devoted to directed acyclic causal graphs, we do not address here the case in which
CG contains both (v, u) and (u, v).

806

fiThe Complexity of Optimal Monotonic Planning

(3) By the denition of monotonic relaxation and the denition of domain transition graphs,
explicit description of all DTG(v, + ) for an M-unfoldable FDR task  is polynomial
in ||||. Hence, the construction of functional components  as in Eqs. 9-12, and thus
of the entire COP+ , can be done in time O(poly(||||)).

We now proceed to prove the correctness of COP+ = (X , ). That is, we will prove
that if + is unsolvable, then all the assignments to X evaluate the objective function
 (X ) to , and otherwise, the objective is minimized on and only on the assignments
to X that correspond to optimal plans for + .
First, given an assignment  to X such that  () < , we show that  induces
a valid plan  for + of cost  (). By Eqs. 9 and 12,  () <  implies that,
for each v  V and each xv /v in the stretch tree T  (v), [xv /v ]  {, [xv ]}. That is,
the relaxation value of v assigned by  to xv is consistently propagated to all the nodes of
T  (v), and in particular, to its leaves.
Let a leaf node xv /v in T  (v) connect T  (v) with T  (u) for some causal graph neighbor
u  N (v), and let [xv /v ] = v , [xv ]. If u  N in (v), then by Eq. 10, v /v () = 
implies that v encodes all and only all preconditions in PRv that are not disabled by the
relaxation value [xu ] of u. Otherwise, if u  N out (v), then, by the DAG structure of CG ,
u has nothing to do with preconditions of actions aecting v + , and by Eq. 11, v /v () = 
implies that v = 1 trivially enables all the preconditions in PRv .
Given that, for each (leaf or internal) stretch node in T  (v), let [xv /v ] = v , [xv ].
By the conjunctive structure of the preconditions in FDR and the Hadamard vector product
in Eq. 12, v /v () =  implies that v encodes all and only all the preconditions in PRv
that are notdisabled by the values [xu ] of all u  Nvin (v). Finally, by the denition of graph
expansion, v N  ( (v)) Nvin (v) = N in (v). Thus, by Eq. 11, v () =  implies that [xv ] is
reachable from I[v] in the properly restricted domain transition graph DTG(v, + |[Xv ])
where Xv = {xu | u  pred(v)}, and that v () equals the cost of the cheapest such
path. The rest follows from the DAG structure of CG and Lemma 1. The proof of the
opposite direction is straightforward from the construction of COP+ and the serialization
Lemma 1.


In our nal note we return to the denition of prevail decomposability, and specically, to
its second sucient condition that, for all state variables v  V , the set ARBv of arborescence
sugraphs of DTG(v, ) rooted in I[v], and covering G[v] if v  V(G), is of size O(log(||||)).
While this condition was not addressed in our COP construction so far, switching from
the rst to the second sucient condition of prevail decomposability requires only that
the semantics of the indicator vectors  be changed: Instead of encoding the support that
pred(v) provide to individual preconditions of actions in Av , they should encode the support
that pred(v) provide to the entire arborescences ARBv in DTG(v, ). Since the condition
requires |ARBv | = O(log(||||)), this support can be encoded and reasoned about eciently.
Note that the choice between the two conditions can be made on a variable-by-variable basis,
and thus the two conditions are not mutually exclusive but complementary.
807

fiDomshlak & Nazarenko


causal graph
extra condition
xed size
 = O(1)
|D(v)| = O(1)
 = O(1) & DAG |D(v)| = O(1)
 = O(1) & DAG in-degree = O(1)
 = O(1) & DAG

FDR
in P?
Yes
No
No
No
No

MFDR
in P?
No
Yes
Yes
Yes, if M-unfoldable
Yes, if M-unfoldable and
prevail decomposable

Th.
Th.
Th.
Th.
Th.

2
3
3
5
6

Table 1: A summary of our main results for optimal MFDR planning, contrasted with the
previously established complexity of the corresponding fragments of optimal FDR
planning. In the table,  is a fragment of FDR/MFDR planning, characterized
in terms of the causal graph tree-width , causal graph in-degree, and upper
bound |D(v)| on the size of the variable domains. M-unfoldability and prevail
decomposability are two properties of MFDR tasks that have been introduced and
exploited in this work.

6. Summary and Future Work
We took a step towards a ne-grained classication of worst-case time complexity of optimal
monotonic planning, with a focus on what gets harder and what gets easier when
switching from optimal planning to optimal relaxed planning, in the context of nite-domain
planning task representations. Along the way, we established both negative and positive
results on the complexity of some wide fragments of this problem, with the negative results
emphasizing the role of the structure of state variable domains, and the positive results
emphasizing the role of the causal graph topology. Table 1 lists our main results for optimal
monotonic planning, contrasted with the complexity of the corresponding fragments of
optimal FDR planning. The key conclusions are as follows.
1. Optimal planning for monotonic relaxations is hard even if restricted to very simple
causal graph structures, but the complexity there stems from the size of the state
variable domains.
2. Restricted to planning tasks with constant-bounded state variable domains, the problem becomes solvable in time exponential only in the tree-width of the causal graph,
while it is known to be very much not so even for non-optimal regular planning.
3. While the tree-width of digraphs is independent of the edge directions, exploiting
the directed structure of the causal graph together with its tree-width allows the
computational tractability to be expanded beyond xed-size state variable domains.
The latter conclusion opens an interesting venue for further investigation. While we
addressed only directed acyclic causal graphs, the scope of tractability can perhaps be expanded by exploiting some existing directed notions of graph width (Johnson, Robertson,
Seymour, & Thomas, 2001; Hunter & Kreutzer, 2008; Berwanger et al., 2012). This might
808

fiThe Complexity of Optimal Monotonic Planning

be especially appealing because the tree-width of most standard planning benchmarks under their natural FDR encodings does not appear to be xed across the respective families
of the tasks.
Another interesting direction would be to examine the results and techniques introduced here in a wider context: that of the recently introduced framework of red-black
relaxations (Katz et al., 2013b). In red-black (RB) planning, the variables are partitioned
into two sets: the black set adopts the regular, value switching semantics of FDR, while
the red set adopts the monotonic, value accumulating semantics of MFDR. In the context
of satiscing planning, complexity analysis of RB planning complexity through the lens of
causal graph topology has already led to some advances in the practice of heuristic-search
planning (Katz et al., 2013a; Katz & Homann, 2013). To take a similar step in optimal
planning, admissible heuristics that are based on RB relaxations must be devised. That, in
turn, calls for identifying tractable fragments of optimal RB planning. We are cautiously
optimistic that some of the results and techniques presented in this paper will be found valuable in the context of RB planning as well. For instance, the positive result in Theorem 4
for fork-structured MFDR tasks can be straightforwardly extended to RB tasks with only
root variables taking the monotonic semantics and all the leaves keeping their regular, FDR
semantics. Similarly, the positive result in Theorem 5 for DAG-structured MFDR tasks can
be straightforwardly extended to RB tasks with black-painted leaf variables. An interesting
question in that respect is whether computational tractability of optimal RB planning can
be extended to causal graphs in which some internal nodes get to keep their original FDR
semantics.

Acknowledgments
The work was partly supported by the Israel Science Foundation (ISF) grant 1045/12, and
the EOARD grant FA8655-12-1-2096.

References
Amir, E. (2010). Approximation algorithms for treewidth. Algorithmica, 56 (4), 448479.
Arnborg, S., Cornell, D. G., & Proskurowski, A. (1987). Complexity of nding embeddings
in a k-tree. SIAM Journal of Algebraic Discrete Methods, 8, 277284.
Backstrom, C., & Klein, I. (1991). Planning in polynomial time: The SAS-PUBS class.
Computational Intelligence, 7 (3), 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Becker, A., & Geiger, D. (1996). A suciently fast algorithm for nding close to optimal
junction trees. In Proceedings of the 12th Conference on Uncertainty in Articial
Intelligence (UAI), pp. 8189.
Berwanger, D., Dawar, A., Hunter, P., Kreutzer, S., & Obdzralek, J. (2012). The DAG-width
of directed graphs. Journal of Combinatorial Theory, Series B, 102 (4), 900923.
Betz, C., & Helmert, M. (2009). Planning with h+ in theory and practice. In Proceedings
of the 32nd Annual German Conference on Articial Intelligence (KI), pp. 916.
809

fiDomshlak & Nazarenko

Bodlaender, H. L. (1996). A linear-time algorithm for nding tree-decompositions of small
treewidth. SIAM Journal of Computing, 25 (6), 13051317.
Bonet, B., & Gener, H. (2001). Planning as heuristic search. Articial Intelligence, 129 (1
2), 533.
Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. In
Proceedings of the 19th European Conference on Articial Intelligence, pp. 329334,
Lisbon, Portugal.
Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, and when not.
In Proceedings of the 18th National Conference on Articial Intelligence (AAAI), pp.
809814, Boston, MA.
Brafman, R. I., & Domshlak, C. (2013). On the complexity of planning for agent teams and
its implications for single agent planning. Articial Intelligence, 198, 5271.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Articial Intelligence, 69 (1-2), 165204.
Cai, D., Homann, J., & Helmert, M. (2013). Enhancing the context-enhanced additive
heuristic with precedence constraints. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS), pp. 5057.
Chen, H., & Gimenez, O. (2010). Causal graphs and structurally restricted planning. Journal of Computer and System Sciences, 76 (7), 579592.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent o-line coordination: Structure and complexity. In Proceedings of Sixth European Conference on Planning (ECP), pp. 277288.
Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Springer-Verlag, New
York.
Edelkamp, S. (2001). Planning with pattern databases. In Proceedings of the European
Conference on Planning (ECP), pp. 1324.
Fabre, E., Jezequel, L., Haslum, P., & Thiebaux, S. (2010). Cost-optimal factored planning:
Promises and pitfalls. In Proceedings of the International Conference on Automated
Planning and Scheduling (ICAPS), pp. 6572.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Articial Intelligence, 2, 189208.
Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory. Springer-Verlag.
Fox, M., & Long, D. (2001). Stan4: A hybrid planning strategy based on subproblem
abstraction. AI Magazine, 22 (3), 8184.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning problems. Journal of Articial Intelligence Research, 20, 61124.
Gimenez, O., & Jonsson, A. (2009a). The inuence of k-dependence on the complexity of
planning. In Proceedings of the 19th International Conference on Automated Planning
and Scheduling (ICAPS), pp. 138145.
810

fiThe Complexity of Optimal Monotonic Planning

Gimenez, O., & Jonsson, A. (2009b). Planning over chain causal graphs for variables with
domains of size 5 is NP-hard. Journal of Articial Intelligence Research, 34, 675706.
Halin, R. (1976). s-functions for graphs. Journal of Geometry, 8, 171186.
Helmert, M. (2004). A planning heuristic based on causal graph analysis. In Proceedings
of the Fourteenth International Conference on Automated Planning and Scheduling
(ICAPS), pp. 161170.
Helmert, M. (2006). The Fast Downward planning system. Journal of Articial Intelligence
Research, 26, 191246.
Helmert, M. (2009). Concise nite-domain representations for PDDL planning tasks. Articial Intelligence, 173, 503535.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: Whats
the dierence anyway?. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS), pp. 162169.
Helmert, M., & Gener, H. (2008). Unifying the causal graph and additive heuristics. In Proceedings of the 18th International Conference on Automated Planning and Scheduling
(ICAPS), pp. 140147.
Helmert, M., Haslum, P., & Homann, J. (2007). Flexible abstraction heuristics for optimal
sequential planning. In Proceedings of the 17th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 200207.
Helmert, M., & Mattmuller, R. (2007). Accuracy of admissible heuristic functions in selected planning domains. In Proceedings of the 23rd AAAI Conference on Articial
Intelligence, pp. 938943.
Homann, J. (2005). When ignoring delete lists works: Local search topology in planning
benchmarks. Journal of Articial Intelligence Research, 24, 685758.
Homann, J. (2011). Analyzing search topology without running any search: On the connection between causal graphs and h+ . Journal of Articial Intelligence Research, 41,
155229.
Homann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Articial Intelligence Research, 14, 253302.
Hunter, P., & Kreutzer, S. (2008). Digraph measures: Kelly decompositions, games, and
orderings. Theoretical Computer Science, 399 (3), 206219.
Johnson, T., Robertson, N., Seymour, P. D., & Thomas, R. (2001). Directed tree-width.
Journal of Combinatorial Theory, Series B, 82 (1), 138154.
Jonsson, P., & Backstrom, C. (1998). State-variable planning under structural restrictions:
Algorithms and complexity. Articial Intelligence, 100 (12), 125176.
Karp, R. (1972). Reducibility among combinatorial problems. In Complexity of Computer
Computations, pp. 85103. Plenum Press, New York.
Katz, M., & Domshlak, C. (2008). New islands of tractability of cost-optimal planning.
Journal of Articial Intelligence Research, 32, 203288.
811

fiDomshlak & Nazarenko

Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal of Articial
Intelligence Research, 39, 51126.
Katz, M., & Homann, J. (2013). Red-black relaxed plan heuristics reloaded. In Proceedings
of the 6th Annual Symposium on Combinatorial Search (SOCS), pp. 105113.
Katz, M., Homann, J., & Domshlak, C. (2013a). Red-black relaxed plan heuristics. In
Proceedings of the 27th AAAI Conference on Articial Intelligence (AAAI), pp. 489
495.
Katz, M., Homann, J., & Domshlak, C. (2013b). Who said we need to relax all variables?. In Proceedings of the 23rd International Conference on Automated Planning
and Scheduling (ICAPS), pp. 126134.
Katz, M., & Keyder, E. (2012). Structural patterns beyond forks: Extending the complexity
boundaries of classical planning. In Proceedings of the 26th AAAI Conference on
Articial Intelligence (AAAI), pp. 17791785.
Keyder, E., & Gener, H. (2008a). Heuristics for planning with action costs revisited. In
Proceedings of the 18th European Conference on Articial Intelligence (ECAI), pp.
588592.
Keyder, E., & Gener, H. (2008b). Heuristics for planning with action costs revisited. In
Proceedings of the 18th European Conference on Articial Intelligence, pp. 588592.
Markov, I. L., & Shi, Y. (2011). Constant-degree graph expansions that preserve treewidth.
Algorithmica, 59, 461470.
McDermott, D. V. (1999). Using regression-match graphs to control search in planning.
Articial Intelligence, 109 (1-2), 111159.
Nissim, R., & Brafman, R. I. (2012). Multi-agent A for parallel and distributed systems.
In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 12651266.
Nissim, R., Brafman, R. I., & Domshlak, C. (2010). A general, fully distributed multiagent planning algorithm. In Proceedings of the 9th International Conference on
Autonomous Agents and Multiagent Systems (AAMAS), pp. 13231330.
Pednault, E. (1989). ADL: Exploring the middle ground between STRIPS and the situation calculus. In Proceedings of the 1st International Conference on Principles of
Knowledge Representation and Reasoning, pp. 324331.
Robertson, N., & Seymour, P. D. (1984). Graph minors III: Planar tree-width. Journal of
Combinatorial Theory, 36, 4963.
Robertson, N., & Seymour, P. D. (1991). Graph minors X: Obstructions to tree decomposition. Journal of Combinatorial Theory, Series B, 52 (2), 153190.
Seipp, J., & Helmert, M. (2011). Fluent merging for classical planning problems. In Proceedings of the ICAPS-2011 Workshop on Knowledge Engineering for Planning and
Scheduling (KEPS), pp. 4753.

812

fiJournal of Artificial Intelligence Research 48 (2013) 923-951

Submitted 7/13; published 12/13

A Smooth Transition from Powerlessness to Absolute Power
Elchanan Mossel

mossel@stat.berkeley.edu

University of California, Berkeley
Berkeley, CA 94720 USA
Weizmann Institute of Science
Rehovot, Israel

Ariel D. Procaccia

arielpro@cs.cmu.edu

Carnegie Mellon University
Pittsburgh, PA 15213 USA

Miklos Z. Racz

racz@stat.berkeley.edu

University of California, Berkeley
Berkeley, CA 94720 USA

Abstract
We study the phase transition of the coalitional manipulation problem for generalized
scoring rules. Previously it has been shown that,
 under some conditions on the distribution
of votes, if the number of manipulators is o ( n), where n is the number of voters, then
the probability that a random profile is manipulable by the coalition goes to zero
 as the
number of voters goes to infinity, whereas if the number of manipulators is  ( n), then
the probability that a random profile is manipulable
goes to one. Here we consider the

critical window, where a coalition has size c n, and we show that as c goes from zero to
infinity, the limiting probability that a random profile is manipulable goes from zero to
one in a smooth fashion, i.e., there is a smooth phase transition between the two regimes.
This result analytically validates recent empirical results, and suggests that deciding the
coalitional manipulation problem may be of limited computational hardness in practice.

1. Introduction
Finding good voting systems which satisfy some natural requirements is one of the main
goals in social choice theory. This problem is increasingly relevant in the area of artificial intelligence and in computer science more broadly, where virtual elections are now an
established tool for preference aggregation (see, e.g., Caragiannis & Procaccia, 2011).
A naturally desirable property of a voting system is strategyproofness (a.k.a. nonmanipulability): no voter should benefit from voting strategically, i.e., voting not according to
her true preferences. However, Gibbard (1973) and Satterthwaite (1975) showed that no
reasonable voting system can be strategyproof. Before stating their result, let us specify
the problem more formally.
We consider n voters electing a single winner among m candidates. The voters specify
their opinion by ranking the candidates, and the winner is determined according to some
n  [m] of all the voters rankings, where S
predefined social choice function (SCF) f : Sm
m
denotes the set of all possible total orderings of the m candidates. We call a collection of
rankings by the voters a ranking profile. We say that a SCF is manipulable if there exists a
c
2013
AI Access Foundation. All rights reserved.

fiMossel, Procaccia, & Racz

ranking profile where a voter can achieve a more desirable outcome of the election according
to her true preferences by voting in a way that does not reflect her true preferences.
The Gibbard-Satterthwaite theorem states that any SCF which is not a dictatorship
(i.e., not a function of a single voter), and which allows at least three candidates to be
elected, is manipulable. This has contributed to the realization that it is unlikely to expect
truthfulness in voting. Consequently, there have been many branches of research devoted
to understanding the extent of the manipulability of voting systems, and to finding ways of
circumventing the negative results.
One approach, introduced by Bartholdi, Tovey, and Trick (1989), suggests computational
complexity as a barrier against manipulation: a SCF may not be manipulable in practice if it
is hard for a voter to compute a manipulative vote. A significant body of work focuses on the
worst-case complexity of manipulation (see the survey by Faliszewski and Procaccia, 2010).
Here we are interested specifically in the coalitional manipulation problem, where a group
of voters can change their votes in unison, with the goal of making a given candidate
win. Various variations of this problem are known to be N P-hard under many of the
common SCFs (Conitzer, Sandholm, & Lang, 2007; Xia, Zuckerman, Procaccia, Conitzer,
& Rosenschein, 2009; Betzler, Niedermeier, & Woeginger, 2011).
Crucially, this line of work focuses on worst-case complexity. While worst-case hardness
of manipulation is a desirable property for a SCF to have, it does not tell us much about
typical instances of the problemis it usually easy or hard to manipulate? A recent line
of research on average-case manipulability has been questioning the validity of such worstcase complexity results. The goal of this alternative line of work is to show that there
are no reasonable voting rules that are computationally hard to manipulate on average.
Specifically, the goal is to rule out the following informal statement: there are good voting
rules that are hard to manipulate on average under any sufficiently rich distribution over
votes.
Taking this point of view, showing easiness of manipulation under a restricted class of
distributionssuch as i.i.d. votes or even uniform votes (the impartial culture assumption)
is interesting, even if these do not necessarily capture all possible real-world elections.
Specifically, if we show that manipulation is easy under such distributions, then any averagecase hardness result would necessarily have to make some unnatural technical assumptions
to avoid these distributions. Studying such restricted distributions over votes is indeed
exactly what some recent papers have done.
For the coalitional manipulation problem, Procaccia and Rosenschein (2007a) first suggested that it is trivial to determine whether manipulation is possible for most coalitional
manipulation instances, from a typical-case computational point of view; one can make a
highly informed guess purely based on the number of manipulators. Specifically, they studied a setting where there is a distribution over votes (which satisfies some conditions), and
concentrated on a family of SCFs known as positional scoring rules. They showed that if the

size of the coalition is o ( n), then with probability converging to 1 as n  , the coalition
is powerless, i.e., it cannot change the outcome of the election. In contrast, if the size of the

coalition is  ( n) (and o (n)), then with probability converging to 1 as n  , the coalition is all-powerful, i.e., it can elect any candidate. Later Xia and Conitzer (2008b) proved
an analogous result for so-called generalized scoring rules, a family that contains almost
all common voting rules. See also related work by Peleg (1979), Slinko (2004), Pritchard
924

fiA Smooth Transition from Powerlessness to Absolute Power

and Slinko (2006), and Pritchard and Wilson (2009). We discuss additional related work in
Section 1.2.
Our primary interest in this paper is to understand the critical window that these papers

leave open, when the size of the coalition is  ( n). Specifically, we are interested in the
phase transition in the probability of coalitional manipulation, when the size of the coalition

is c n and c varies from zero to infinity, i.e., the transition from powerlessness to absolute
power.
In the past few decades there has been much research on the connection between phase
transitions and computationally hard problems (see, e.g., Fu & Anderson, 1986; Cheeseman,
Kanefsky, & Taylor, 1991; Achlioptas, Naor, & Peres, 2005). In particular, it is often
the case that the computationally hardest problems can be found at critical values of a
sharp phase transition (see, e.g., Gomes & Walsh, 2006, for an overview). On the other
hand, smooth phase transitions are often found in connection with computationally easy
(polynomial) problems, such as 2-coloring (Achlioptas, 1999) and 1-in-2 SAT (Walsh, 2002).
Thus understanding the phase transition in this critical window may shed light on where
the computationally hardest problems lie.
Recently, Walsh (2011) empirically analyzed two well-known voting rulesveto and
single transferable vote (STV)and found that there is a smooth phase transition between
the two regimes. Specifically, Walsh studied coalitional manipulation with unweighted votes
for STV and weighted votes for veto, and sampled from a number of distributions in his
experiments, including i.i.d. distributions, correlated distributions, and votes sampled from
real-world elections. Our main result complements and improves upon Walshs analysis
in two ways; while Walshs results show how the phase transition looks like concretely for
veto and STV, we analytically show that the phase transition is indeed smooth for any
generalized scoring rule (including veto and STV) when the votes are i.i.d. This suggests
that deciding the coalitional manipulation problem may not be computationally hard in
practice.
1.1 Our Results
We now present our results, but first let us formally specify the setup of the problem.
n , and for a candidate a, define
We denote a ranking profile by  = (1 , . . . , n )  Sm
n | f () = a}, the set of ranking profiles where the outcome of f is a. Our
Wa = {  Sm
setup and assumptions are the following.
Assumption 1. We assume that the number of candidates, m, is constant.
Assumption 2. We assume that the SCF f is anonymous, i.e., it treats each voter equally.
Assumption 3. We assume that the votes of voters are i.i.d., according to some distribution
p on Sm . Furthermore, we assume that there exists  > 0 such that for every   Sm ,
p ()   (necessarily   1/m!).
If we were to assume only these, then our setup would include uninteresting cases, such
as when f is a constanti.e., no matter what the votes are, a specific candidate wins.
Another less interesting case is when the probability of a given candidate winning vanishes
as n  we can then essentially forget about this candidate for large n (in the sense
925

fiMossel, Procaccia, & Racz

that a coalition of size  (n) would be necessary to make this candidate win). To exclude
these and focus on the interesting cases, we make an additional assumption which concerns
both the SCF and the distribution of votes.
Assumption 4. We assume that there exists  > 0 such that for every n and for every
candidate a  [m], the probability of a being elected is at least  > 0, i.e., P (Wa )  
(necessarily   1/m).
All four assumptions are satisfied when the distribution is uniform (i.e., under the impartial culture assumption) and the SCF is close to being neutral (i.e., neutral up to some
tie-breaking rules); in particular, they hold for all commonly used SCFs. The assumptions
are somewhat more general than this, although the i.i.d. assumption remains a restrictive
one. However, as discussed earlier, even showing easiness of manipulation under such a
restricted class of distributions is interesting.

As mentioned before, we are interested in the case when the coalition has size c n for
some constant c. Define the probabilities


q n (c) := P some coalition of size c n can elect any candidate ,


q n (c) := P some coalition of size c n can change the outcome of the election ,


rn (c) := P a specific coalition of size c n can elect any candidate ,


rn (c) := P a specific coalition of size c n can change the outcome of the election ,
and let
q (c) := lim q n (c) ,
n

q (c) := lim q n (c) ,
n

r (c) := lim rn (c) ,
n

r (c) := lim rn (c) ,
n

provided these limits exist. Clearly q n (c)  q n (c), rn (c)  rn (c), rn (c)  q n (c), and
rn (c)  q n (c).
Before we describe our results, which deal with these quantities, we first explain how
these relate to the various variants of the coalitional manipulation problem. In the coalitional manipulation problem the coalition is fixed, and thus the relevant quantities are rn (c)
and rn (c). Closely related is the problem of determining the margin of victory, which is the
minimum number of voters who need to change their votes to change the outcome of the
election. Also related is the problem of bribery, the minimum number of voters who need
to change their votes to make a given candidate win. The main difference between these
problems is that in coalitional manipulation the coalition is fixed, whereas in the latter two
problems the coalition is not fixed. Hence the relevant quantities for studying the latter
two are q n (c) and q n (c). Our tools also allow us to deal with other related quantities (such
as microbribery, Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009), but we focus
our attention on the four quantities described above.

Our first result analyzes the case when the size of the coalition is c n for large c. We

show that if c is large enough, then with probability close to 1, a specific coalition of size c n
can elect any candidate. This holds for any SCF that satisfies the above (mild) restrictions.
Theorem 1.1. Assume that Assumptions 1, 2, 3, and 4 hold. For any  > 0 there exists a
constant c = c (, , , m) such that rn (c)  1   for every n. In particular, we can choose
hp
i
p
c = (4/) log (2m!/)
log (2m/) + log (2/) .
926

fiA Smooth Transition from Powerlessness to Absolute Power

It follows that
lim lim inf rn (c) = 1.

c

n

This result extends previous theorems of Procaccia and Rosenschein (2007a), and Xia
and Conitzer (2008b), from scoring rules and generalized scoring rules, respectively, to
anonymous SCFs.

Our second result deals with the case when the size of the coalition is c n for small
c, and the transition as c goes from 0 to . Here we assume additionally that f is a
generalized scoring rule (to be defined in Section 3.1.1); this is needed because there exist
(pathological) anonymous SCFs for which the result below does not hold (see the beginning
of Section 3 for an example).
Theorem 1.2. Assume that Assumptions 1, 2, 3, and 4 hold, and furthermore that f is a
generalized scoring rule. Then:
(1) The limits q (c), q (c), r (c) and r (c) exist.
(2) There exists a constant K = K (f, ) <  such that q (c)  Kc; in particular,
limc0 q (c) = 0.
(3) For all 0 < c < , 0 < q (c)  q (c) < 1 and 0 < r (c)  r (c) < 1, and furthermore
q (c), q (c), r (c) and r (c) are all continuously differentiable in c with bounded derivative.
In words, Part 2 means that if c is small enough then with probability close to 1 no

coalition of size c n can change the outcome of the election, and the statements about
r and r in Part 3 mean that the coalitional manipulation problem has a smooth phase
transition: as the number of manipulators increases, the probabilities that a coalition has
some power, and that it has absolute power, increase smoothly. Parts 1 and 2 of the theorem
simply make a result of Xia and Conitzer (2008b) more precise, by extending the analysis

to the ( n) regime. More importantly, in the proofs of these statements we introduce the
machinery needed to establish Part 3, which is our main result.
Since the coalitional manipulation problem does not have a sharp phase transition, Theorem 1.2 can be interpreted as suggesting that realistic distributions over votes are likely
to yield coalitional manipulation instances that are tractable in practice, even if the size

of the coalition concentrates on the previously elusive ( n) regime; this is true for any
generalized scoring rule, and in particular for almost all common social choice functions (an
exception is Dodgsons rule). This interpretation has a negative flavor in further strengthening the conclusion that worst-case complexity is a poor barrier to manipulation.
However, the complexity glass is in fact only half empty. The probability that the margin

of victory is at most c n is captured by the quantity q n , hence Part 3 of Theorem 1.2 also
implies that the margin of victory problem has a smooth phase transition. As recently
pointed out by Xia (2012a), efficiently solving the margin of victory problem could help
in post-election auditsused to determine whether electronic elections have resulted in an
incorrect outcome due to software or hardware bugsand its tractability is in fact desirable.
The methods we use are flexible, and can be extended to various setups of interest that do
not directly satisfy our assumptions above, for instance single-peaked preferences. Consider
a one-dimensional political spectrum represented by the interval [0, 1], and fix the location
927

fiMossel, Procaccia, & Racz

of the candidates. Assume voters are uniformly distributed on the interval, independently
of each other. For technical reasons, this distribution does not satisfy our assumptions,
since there will be rankings   Sm such that p () = 0; however, our tools allow us
to
setting
as well. For instance, if the locations of the m candidates are
 1deal3 with this
	
2m1
, then our results hold (with appropriate quantitative modifications).
2m , 2m , . . . , 2m
Similarly, if the locations were something else, then there would exist a subset of candidates
who have an asymptotically nonvanishing probability of winning, and the same results hold
restricted to this subset of candidates.
Finally, we discuss the role of tie-breaking in our setup, since this is often an important
issue when studying manipulation. However, since we consider manipulation by coalitions

of size c n, ties where there exist a constant number of voters such that if their votes are
changed appropriately there is no longer a tie, are not relevant. Indeed, our tools allow us
to extend the results of Theorem 1.2 to a class of SCFs slightly beyond generalized scoring
rules, and, in particular, these allow for arbitrary tie-breaking rules (see Section 3.2.1 for
details).
1.2 Additional Related Work
A recent line of research with an average-case algorithmic flavor also suggests that manipulation is indeed typically easy; see, e.g., the work of Kelly (1993), Conitzer and Sandholm (2006), Procaccia and Rosenschein (2007b), and Zuckerman et al. (2009) for results
on certain restricted classes of SCFs. A different approach, initiated by Friedgut, Kalai,
Keller and Nisan (2008, 2011), who studied the fraction of ranking profiles that are manipulable, also suggests that manipulation is easy on average; see further the work of Xia and
Conitzer (2008a), Dobzinski and Procaccia (2008), Isaksson, Kindler and Mossel (2012),
and Mossel and Racz (2012). We refer to the survey by Faliszewski and Procaccia (2010)
for a detailed history of the surrounding literature. See also related literature in economics,
e.g., the work of Good and Mayer (1975), Chamberlain and Rothschild (1981), and Myatt
(2007).
Recent work by Xia (2012a) is independent from, and closely related to, our work.
As mentioned above, Xias paper is concerned with computing the margin of victory in
elections. He focuses on computational complexity questions and approximation algorithms,
but one of his results is similar to Parts 1 and 2 of Theorem 1.2. However, our analysis is
completely different; our approach facilitates the proof of Part 3 of the theorem, which is our
main contribution. An even more recent (and also independent) manuscript by Xia (2012b)
considers similar questions for generalized scoring rules and captures additional types of
strategic behavior (such as control), but again, crucially, this work does not attempt to
understand the phase transition (nor does it subsume our Theorem 1.1).

2. Large Coalitions
Without further ado, we prove Theorem 1.1. The main idea is to observe that for i.i.d. distributions, the Hamming distance of a random ranking profile from a fixed subset of ranking
profiles concentrates around its mean. The theorem follows from standard concentration
inequalities.
928

fiA Smooth Transition from Powerlessness to Absolute Power

n , define
Proof of Theorem 1.1. For ,  0  Sm

d , 

0




1X 
=
1 i 6= i0 ,
n
n

i=1

i.e., d (,  0 ) is 1/n times the Hamming distance of  and  0 . If U is a subset of ranking
profiles and  is a specific ranking profile then define dU () = min0 U d (,  0 ). The
function dU is Lipschitz with constant 1/n, and therefore by McDiarmids inequality we
have the following concentration inequality:

P (|dU ()  EdU |  c)  2 exp 2c2 n
(1)
n . Suppose U  S n has measure at least , i.e., U is such that
for any c > 0 and U  Sm
m
p


P (  U )  , and take  such that 2 exp 2 2 n < , e.g., let  = log (2/)/ n. Then
(1) implies that there exists   U such that |dU ()  EdU |  , but since dU () = 0, this
means that EdU  . So for such a set U , we have

P (dU () >  + c)  exp 2c2 n
p

for any c > 0. Choosing c = B/ n and defining B 0 = B + log (2/) we get that

 
(2)
P dU () > B 0 / n  exp 2B 2 .

In the language of the usual Hamming distance, this means that the probability that the
0 n coordinates to be in U is at most
ranking profile
needs
to
be
changed
in
at
least
B

exp 2B 2 , which can be made arbitrarily small by choosing B large enough.
By our assumption, P (  Wa )   for every a, and therefore by (2) and a union bound
we get

 
P a : dWa () > B 0 / n  m exp 2B 2 .
p
By choosing B = log (2m/), this probability is at most /2.

Consider a specific coalition of size DB 0 n, where D = D (, m) will be chosen later.
Using Chernoffs bound and a union bound, with probability close to one, for every possible

ranking  the coalition has at least B 0 n voters with the ranking :



P   Sm : coalition of size DB 0 n has less than B 0 n voters with ranking 




 

 m!P Bin DB 0 n,  < B 0 n  m! exp  (1  1/D)2 DB 0 n/2


 m! exp  (1  1/D)2 D/2 ,


where Bin (DB 0 n, ) denotes a binomial random variable with parameters DB 0 n and ,
and where we used our assumption that for every voter the probability for every ranking is
at least  > 0. Choosing D = (4/) log (2m!/), this probability is at most /2.
By the anonymity of f , the outcome only depends on the number of voters voting
according to each ranking. Consequently, if  is such that it is at a distance of at most


B 0 / n away from each Wa , and where for each ranking  there are at least B 0 n voters in
the coalition with ranking , then the coalition is able to achieve any outcome. Using the
above and a union bound this happens with probability at least 1  .
929

fiMossel, Procaccia, & Racz

3. Small Coalitions and the Phase Transition
This section is almost entirely devoted to the proof of Theorem 1.2, but it also includes
some helpful definitions, examples, and intuitions.
Consider the following example of a SCF. For a  [m] let na () denote the number
of votersPwho ranked candidate a on top in the ranking profile . Define the SCF f by
f () = m
a=1 ana () mod m. This SCF is clearly anonymous (since it only depends on
the number of voters voting according to specific rankings), and moreover it is easy to see
that any single voter can always elect any candidate.
This example shows that, in general, we cannot have a matching lower bound for the

size of the manipulating coalition on the order of n. However, this is an artificial example
(one would not consider such a voting system in real life), and we expect that a matching
lower bound holds for most reasonable SCFs.
Xia and Conitzer (2008b) introduced a large class of SCFs called generalized scoring
rules, which include most commonly occurring SCFs. In the following we introduce this
class of SCFs, provide an alternative way of looking at them (as so-called hyperplane

rules), and show that for this class of SCFs if the coalition has size c n for small enough
c, then the probability of being able to change the outcome of the election can be arbitrarily
close to zero. At the end of the section we then prove the smooth transition as stated in
Part 3 of Theorem 1.2.
3.1 Generalized Scoring Rules, Hyperplane Rules, and their Equivalence
In this section we introduce generalized scoring rules and hyperplane rules and show their
equivalence.
3.1.1 Generalized Scoring Rules
We now define generalized scoring rules.
Definition 1. For any y, z  Rk , we say that y and z are equivalent, denoted by y  z, if
for every i, j  [k], yi  yj if and only if zi  zj .
Definition 2. A function g : Rk  [m] is compatible if for any y  z, g (y) = g (z).
That is, for any function g that is compatible, g (y) is completely determined by the
total preorder of {y1 , . . . , yk } (a total preorder is an ordering in which ties are allowed).
Definition 3 (Generalized scoring rules). Let k  N, f : Sm  Rk (called a generalized
scoring function), and g : Rk  [m] where g is compatible (g is called a decision function).
The functions f and g determine the generalized scoring rule GS (f, g) as follows: for
n , let
  Sm
!
n
X
GS (f, g) () := g
f (i ) .
i=1

From the definition it is clear that every generalized scoring rule (GSR) is anonymous.
930

fiA Smooth Transition from Powerlessness to Absolute Power

3.1.2 Hyperplane Rules
Preliminaries and notation. In the following, for a SCF let us write f  fn , i.e., let us
explicitly note that f is a function on n voters; also let us write    n . Since the SCF
fn is anonymous, the outcome only depends on the numbers of voters who vote according
to particular rankings. Let Dn denote the set of points in the probability simplex m! for
which all coordinates are integer multiples of 1/n. Let us denote a typical element of the
probability simplex m! by x = {x }Sm . For a ranking profile  n , let us denote the
corresponding element of the probability simplex by x ( n ), i.e., for all   Sm ,
1X
1 [i = ] .
n
n

x ( n ) =

i=1

By our assumptions the outcome of fn only depends on x ( n ), so by abuse of notation we
may write that fn : m! |Dn  [m] with fn ( n ) = fn (x ( n )).
We are now ready to define hyperplane rules.
Definition 4 (Hyperplane rules). Fix a finite set of affine hyperplanes of the simplex m! :
H1 , . . . , H` . Each affine hyperplane partitions the simplex into three parts: the affine hyperplane itself and two open halfspaces on either side of the affine hyperplane. Thus the affine
hyperplanes H1 , . . . , H` partition the simplex into finitely many (at most 3` ) regions. Let
F : m!  [m] be a function which is constant on each such region. Then the sequence of
n  [m], defined by
SCFs {fn }n1 , fn : Sm
fn ( n ) = F (x ( n ))
is called a hyperplane rule induced by the affine hyperplanes H1 , . . . , H` and the function F .
A function F : m!  [m] naturally partitions the simplex m! into m parts based on
the outcome of F . (For hyperplane rules this partition is coarser than the partition of m!
induced by the affine hyperplanes H1 , . . . , H` .) We abuse notation and denote these parts
by {Wa }a[m] . The following definition will be useful for us.
Definition 5 (Interior and boundaries of a partition induced by F ). We say that x  m!
is an interior point of the partition {Wa }a[m] induced by F if there exists  > 0 such that
for all y  m! for which |x  y|  , we have F (x) = F (y). Otherwise, we say that
x  m! is on the boundary of the partition, which we denote by B.
For a hyperplane rule the boundary B is contained in the union of the corresponding
affine hyperplanes. Conversely, suppose F : m!  [m] is an arbitrary function and the
n  [m] is defined by f ( n ) = F (x ( n )).
sequence of (anonymous) SCFs {fn }n1 , fn : Sm
n
If the boundary B of F is contained in the union of finitely many affine hyperplanes of
m! , then F is not necessarily a hyperplane rule, but there exists a hyperplane rule F such
that F and F agree everywhere except perhaps on the union of the finitely many affine
hyperplanes.
931

fiMossel, Procaccia, & Racz

3.1.3 Equivalence
Xia and Conitzer (2009) gave a characterization of generalized scoring rules: a SCF is a
generalized scoring rule if and only if it is anonymous and finitely locally consistent (see Xia
& Conitzer, 2009, Definition 5). This characterization is related to saying that generalized
scoring rules are the same as hyperplane rules, yet we believe that spelling this out explicitly
is important, because the geometric viewpoint of hyperplane rules is somewhat different,
and in this probabilistic context it is also more flexible.
Lemma 3.1. The class of generalized scoring rules coincides with the class of hyperplane
rules.
Proof. First let us show that every hyperplane rule is a generalized scoring rule. Let us
consider the hyperplane rule induced by affine hyperplanes H1 , . . . , H` of the simplex m! ,
and the function F : m!  [m]. The affine hyperplanes of m! can be thought of as
hyperplanes of Rm! that go through the originabusing notation we also denote these by
H1 , . . . , H` . Let u1 , . . . , u` denote unit normal vectors of these hyperplanes.
n,
We need to define functions f and g such that for every ranking profile  n  Sm
`+1
`+1
n
n
GS (f, g) ( ) = F (x ( )). We will have f : Sm  R
and g : R
 [m]. Coordinates
1, . . . , ` of f correspond to hyperplanes H1 , . . . , H` , while the last coordinate of f will always
be 0 (this is a technical necessity to make sure that the function g is compatible). Let us
look at the coordinate corresponding to hyperplane Hj with normal vector uj . For   Sm
define
(f ())j  (f ())Hj  (f ())uj := (uj ) ,
where the coordinates of Rm! are indexed by elements of Sm . Then
n

(f ( ))j :=

n
X
i=1

(f (i ))j =

n
X

(uj )i = n (uj  x ( n )) .

i=1

The sign of (f ( n ))j thus tells us which side of the hyperplane Hj the point x ( n ) lies
on. We define g (y) for all y  R`+1 such that y`+1 = 0; then the requirement that g be
compatible defines g for all y  R`+1 . For x  R, define sgn (x) to be 1 if x > 0, 1 if x < 0,
and 0 if x = 0.
To define g (y1 , . . . , y` , 0), look at the vector (sgn (y1 ) , . . . , sgn (y` )). This vector determines a region in m! in the following way: if sgn (yj ) = 1, then the region lies in the
same open halfspace as uj , if sgn (yj ) = 1 then the region lies in the open halfspace
which does not contain uj , and finally if yj = 0, then the region lies in the hyperplane
Hj . Now we define g (y1 , . . . , y` , 0) to be the value of F on the region of m! defined by
(sgn (y1 ) , . . . , sgn (y` )). The value of g (y1 , . . . , y` , 0) is well-defined since F is constant in
each such region. Moreover, if we take y  z with y`+1 = z`+1 = 0, then necessarily
(sgn (y1 ) , . . . , sgn (y` )) = (sgn (z1 ) , . . . , sgn (z` )), and thus g (y) = g (z): so g is compatible
(this is where we used the extra coordinate).
Now let us show that every generalized scoring rule is a hyperplane rule. Suppose a
generalized scoring rule is given by P
functions f : Sm P
 Rk and g : Rk  [m]. For a ranking
n
n
n
n
profile   Sm , define f ( ) := i=1 f (i ) = n Sm f () (x ( n )) ; in this way we
k
can view f as a function mapping Nm!
0 \ {0} to R (and hence can also view GS (f, g) as a
932

fiA Smooth Transition from Powerlessness to Absolute Power

function mapping Nm!
0 \ {0} to [m]). Since this mapping is homogeneous, we may extend
the domain of f (and hence that of GS (f, g)) to Qm!
0 \ {0} in the natural way.

	
m!
For a total preorder O, let RO = x  Q0 \ {0} : f (x)  O . By definition, if x, y  RO
then g (f (x)) = g (f (y)), i.e., GS (f, g) is constant in each region RO . Each region RO is
a Q-convex cone, i.e. if x, y  RO and   Q  [0, 1], then x + (1  ) y  RO , and
furthermore if   Q>0 , then x  RO (both of these properties follow immediately from
Definition 1). Thus we can write Qm!
0 \ {0} as the disjoint union of the Q-convex cones
{RO }O . The only way to do this is by taking finitely many hyperplanes of Rm! and cutting
Qm!
0 \ {0} using these hyperplanes; a precise statement of this can be found in Appendix A.
This essentially follows from a result by Kemperman (1986, Thm. 2)to keep the paper selfcontained we reproduce in Appendix A his results and proof, and show how the statement
above follows from his results. Since our function is homogeneous, we need only look at
m!
the values
 of GSm!(f,
	 g) on the simplex  . Bym!the above, the simplex is divided into
regions RO  
via affine hyperplanes of  , and the function GS (f, g) is constant
O
m!
on RO   for each total preorder O, so GS (f, g) is indeed a hyperplane rule.
3.1.4 Examples
Most commonly used SCFs are generalized scoring rules / hyperplane rules, including
all positional scoring rules, instant-runoff voting, Coombs method, contingent vote, the
Kemeny-Young method, Bucklin voting, Nansons method, Baldwins method, Copelands
method, maximin, and ranked pairs. Some of these examples were already shown by Xia
and Conitzer (2008b, 2009), but nevertheless in Appendix B we detail explanations of many
of these examples. The main reason for this is that the perspective of a hyperplane rule
arguably makes these explanations simpler and clearer. A rule that does not fit into this
framework is Dodgsons rule, which is not homogeneous (see, e.g., Brandt, 2009), and therefore it is not a hyperplane rule.
3.2 Small Coalitions for Generalized Scoring Rules

We now show that for generalized scoring rules, a coalition of size c n for small enough
c can only change the outcome of the election with small probability. By the equivalence
above, we can work in the framework of hyperplane rules.
We consider two metrics on m! : the L1 metric, denoted by d1 or kk1 , and the L2
metric, denoted by d2 or kk2 . The L1 metric is important in this setting, since changing
the votes of voters corresponds to moving in the L1 metric on m! ; this connection is
formalized in the following lemma.
n . Then d (x ( n ) , x ( n ))  2 d ( n ,  n ), where d
Lemma 3.2. Let  n ,  n  Sm
1
H denotes
n H
P
Hamming distance, i.e., dH ( n ,  n ) = ni=1 1 [i 6= i ]. Furthermore, if y  Dn , then there
n such that x ( n ) = y and d (x ( n ) , y) = 2 d ( n ,  n ).
exists  n  Sm
1
n H

Proof. Let  0 =  n , and for i = 1, . . . , n, define the ranking profile  i as
 i = (1 , . . . , i , i+1 , . . . , n ) .
933

fiMossel, Procaccia, & Racz

By definition,  n =  n . The desired inequality then follows from the triangle inequality:
n
 X



d1 (x ( n ) , x ( n )) = d1 x  0 , x ( n ) 
d1 x  i1 , x  i
i=1
n
X
2
2
1 [i 6= i ] = dH ( n ,  n ) .
=
n
n
i=1

For the second part of the lemma, construct  n as follows. For each   Sm , let I :=
{i  [n] : i = }. If x ( n )  y , then for every i  I , let i = . If x ( n ) > y , then
choose a subset of indices I0  I of size |I0 | = ny , and for every i  I0 , let i = . Finally,
define the rest of the coordinates of  n so that x ( n ) = y. The construction guarantees
that then d1 (x ( n ) , y) = n2 dH ( n ,  n ).
It is therefore natural to define distances from the boundary B using the L1 metric:
Definition 6 (Blowup of boundary). For  > 0, we define the blowup of the boundary B
by  to be
n
o
B + = y  m! : x  B such that kx  yk1   .
In order for some coalition to be able to change the outcome of the election at a given
ranking profile, the point on the simplex corresponding to this ranking profile needs to be
sufficiently close to the boundary B; this is formulated in the following lemma.
Lemma 3.3. Suppose we have n voters, a coalition of size k, and the ranking profile is
n , which corresponds to the point x ( n )  m! on the probability simplex. A
 n  Sm
necessary condition for the coalition to be able to change the outcome of the election from
this position is that x ( n )  B +2k/n . Conversely, if x ( n )  B +(2km!)/n , then there exists
a coalition of size k that can change the outcome of the election.
Proof. For any ranking profile  n that the coalition can reach, we have dH ( n ,  n )  k,
n / B +2k/n , then for every
and so by Lemma 3.2 we have d1 (x ( n ) , x ( n ))  2k
n . If x ( ) 
ranking profile  n which the coalition can reach, x ( n ) and x ( n ) are in the same region
determined by the hyperplanes, and so F (x ( n )) = F (x ( n )), i.e., the coalition cannot
change the outcome of the election.
Now suppose that x ( n )  B +(2km!)/n . Then by definition there exists y  B such
m!
that d1 (x ( n ) , y)  2km!
n . Since y  B, there exists y  Dn such that d1 (y, y)  n and
F (y) 6= F (x ( n )). By the triangle inequality, d1 (x ( n ) , y)  2k
n , and then by the second
n such that x ( n ) = y and d ( n ,  n )  k. The
part of Lemma 3.2 there exists  n  Sm
H
coalition consisting of voters with indices in I := {i  [n] : i 6= i } can thus change the
outcome of the election.
Corollary 3.4. If we have n voters, the probability that some coalition of size k can change
the outcome of the election is bounded from below by P x ( n )  B +(2km!)/n and from

above by P x ( n )  B +2k/n , where  n is drawn according to the probability distribution
satisfying the conditions of the setup.
934

fiA Smooth Transition from Powerlessness to Absolute Power

Gaussian limit. Due to the i.i.d.-ness of the votes, the multinomial random variable x ( n )
concentrates around its expectation, and the rescaled random variable
x ( n ) :=



n (x ( n )  E (x ( n )))

converges to a normal distribution, with zero mean and specific covariance structure. For
our analysis it is better to use this Gaussian picture, and thus we will reformulate the
preliminaries above in this limiting setting. First, let us determine the limiting distribution.
Lemma 3.5. We have x ( n ) n N (0, ), where the covariance structure is given by
 = diag (p)  ppT , where recall that p is the distribution of a vote.
Proof. It is clear P
that E (x ( n )) = 0. Computing the
 covariance structure, we first have
1
2
that E x = n2 ni,j=1 P (i = , j = ) = 1  n1 p ()2 + n1 p (), from which we have


Var (x ) = n1 p ()  p ()2 and thus Var (x ) = p ()  p ()2 . Then similarly for  6=  0
we have


n



1 X
1 X
1
0
0
E (x x0 ) = 2
p () p  0 ,
P i = , j =  = 2
p () p  = 1 
n
n
n
i,j=1

i6=j

from which we have that Cov (x , x0 ) =  n1 p () p ( 0 ) and thus

Cov (x , x0 ) = p () p  0 .
Note: because of the concentration of x ( n ) around its mean, and our assumption that
for every n and for every candidate a  [m], P (f ( n ) = a)  , it is necessary that for every
 > 0 and for every candidate a  [m] there exists y  m! such that ky  E (x (1 ))k1  
and F (y) = a.
Denote by  the distribution of N (0, ) and let X denote a random variable distributed
according to . Note that  is a degenerate multivariate normal distribution, as the support
of  concentrates on the hyperplane H0 where the coordinates sum to zero. (This is because
P
n
Sm x ( ) = 0.)
The underlying function F : m!  [m] corresponds to a function F : Rm! |H0  [m]
in the Gaussian limit, and this functionnF partitions
Rm! |H0 into m parts based on the
o
outcome of F . We denote these parts by Wa
. We will need the following definitions
a[m]

and properties of boundaries, analogous to those above.
Definition 7 (Interior and boundaries
of a partition). We say that x  Rm! |H0 is an
n o
interior point of the partition Wa
induced by F if there exists  > 0 such that for
a[m]

all y  R |H0 for which kx  yk1  , we have F (x) = F (y). Otherwise, we say that
x  Rm! |H0 is on the boundary of the partition, which we denote by B.
m!

Lemma 3.6. If the boundary B comes from a hyperplane rule, i.e., B is contained in the
union of ` affine hyperplanes in m! , then B is contained in the union of ` hyperplanes of
Rm! |H0 , where `  `.
935

fiMossel, Procaccia, & Racz

Proof. Two things can happen to an affine hyperplane H of m! when we take the Gaussian
limit: (1) if E (x ())  H, then translation by E (x ()) takes H into a hyperplane H of

Rm! |H0 , and since H goes through the origin, scaling (in particular by n) does not move
this hyperplane; (2) if E (x ()) 
/ H, then translation by E (x ()) takes H into an affine

m!
hyperplane H of R |H0 that does not go through the origin, and then scaling by n moves
H to an affine hyperplane of Rm! |H0 whose L2 distance from the origin is proportional to

n, so in the n   limit this affine hyperplane vanishes.
Definition 8 (Blowup of boundary). For  > 0, we define the blowup of the boundary B
by  to be
n
o
B + = y  Rm! |H0 : x  B such that kx  yk1   .

Let us focus specifically on a coalition of size c n for some (small) constant c. Corollary 3.4 implies the following.
Corollary 3.7. For hyperplane rules the limit of the probability that in an election
with n


voters some coalition of size c n can change the outcome of the election is  X  B +2c .
The following claim, together with Corollary 3.7, tells us that for hyperplane rules a

coalition of size c n can change the outcome of the election with only small probability,
given that c is sufficiently small, proving Part 2 of Theorem 1.2.
n oM
Claim 3.8. Suppose our SCF is a hyperplane rule, and in particular let Hi
be a
i=1
S
collection of hyperplanes in Rm! |H0 such that B  M
i=1 Hi . Then

 r 2 Mc
+c
 .
 X  B

 
Proof. By our condition and a union bound we have
M

 X


+c
 X  B

 X  Hi+c .
i=1

For a hyperplane H in Rm! |H0 , denote (one of) the corresponding unit normal vector(s) (in
the hyperplane H0 ) by u. Then
n
o
H = x  Rm! |H0 : u  x = 0
and since L1 distance is always greater than L2 distance, we have
n
o n
o
H +c  x  Rm! |H0 : y  H such that kx  yk2  c = x  Rm! |H0 : |u  x|  c .
Since X is a multidimensional Gaussian r.v., u  X is a one-dimensional Gaussian r.v. (which
is centered). Therefore




2c
 X  H +c   u  X  [c, c]  r

.
2 Var u  X
936

fiA Smooth Transition from Powerlessness to Absolute Power

We have that




2


Var u  X = E u  X = E uT X X T u = uT u,

and so all that remains to show is that
min
u:kuk=1,u1

uT u  ,

where 1 is the m!-dimensional vector having 1 in every coordinate.
Let 1 ()  2 ()      m! () denote the eigenvalues of . Since  is positive
semidefinite, all eigenvalues are nonnegative. We know that 0 is an eigenvalue of  (the
corresponding eigenvector is 1), so m! () = 0. By the variational characterization of
eigenvalues we have
min
uT u = m!1 () ,
u:kuk=1,u1

and so we need to show that m!1 ()  . To do this we use Weyls inequalities.
Lemma 3.9 (Weyls inequalities). For an n  n matrix M let 1 (M )  2 (M )     
n (M ) denote its eigenvalues. If A and C are n  n symmetric matrices then
j (A + C)  i (A) + ji+1 (C)

if i  j,

j (A + C)  i (A) + ji+n (C)

if i  j.

We use Weyls inequality for A = diag (p) and C = ppT . The eigenvalues of A are
{p ()}Sm , all of which are no less than . Since C has rank 1, all its eigenvalues but one are
zero, and the single nonzero eigenvalue is m! (C) = pT p. Since  = diag (p)ppT = A+C,
Weyls inequality tells us that

m!1 ()  m! (diag (p)) + m!1 ppT   + 0 = .

This implies that we have a lower bound of  ( n) for the size of the coalition needed in
order to change the outcome of the election for hyperplane rules. As mentioned before, most
commonly occurring SCFs are in this class of rules: see Appendix B for many examples.
3.2.1 Almost Hyperplane Rules
Furthermore, the Gaussian limiting setting above is not sensitive to small changes to the
voting rule for finite n. Consequently, for SCFs that are almost hyperplane rules (in a

sense we make precise below), the same conclusion holds: a coalition of size  ( n) is needed
in order to be able to change the outcome of the election with non-negligible probability.
In particular, the same result holds for SCFs with arbitrary tie-breaking rules for ranking
profiles which lie on one of the hyperplanes (e.g., the tie-breaking rule can depend on the
number of voters n).
Definition 9 (Almost hyperplane rules). Fix a finite set of affine hyperplanes of the
simplex m! : H1 , . . . , H` . These partition the simplex into finitely many regions. Let F :
m!  [m] be a function which is constant on each such region, and let B denote the
937

fiMossel, Procaccia, & Racz

n  [m], is called an
induced boundary. Then the sequence of SCFs {fn }n1 , fn : Sm

almost hyperplane rule if for every  n such that x ( n ) 
/ B +o(1/ n) , we have

fn ( n ) = F (x ( n )) .
This SCF is called an almost hyperplane rule induced by the affine hyperplanes H1 , . . . , H`
and the function F .
n  [m], is an almost
Lemma 3.10. Suppose the sequence of SCFs {fn }n1 , fn : Sm
hyperplane rule defined by ` hyperplanes. Then in the Gaussian limiting setting the boundary
B is contained in the union of ` hyperplanes of Rm! |H0 , where `  `.


Proof. For finite n, the induced boundary of fn in the simplex m! is contained in B +o(1/ n) ,


by definition. Since in the Gaussian limit we scale by n, the blowup by o (1/ n) of the
boundary B disappears in the limit, and hence we are back to the situation of Lemma 3.6.
Consequently, the affine hyperplanes corresponding to our almost hyperplane rule either
disappear to infinity or become hyperplanes of Rm! |H0 .
Corollary 3.11. Corollary 3.7 and Claim 3.8 hold for almost hyperplane rules as well.
3.3 Smoothness of the Phase Transition
In this final subsection our goal is to show Parts 1 and 3 of Theorem 1.2. The existence
of the limits in Part 1 follows immediately from the Gaussian limit described above; we do
not detail this, but rather give formulas for these limiting probabilities. These then imply
the properties described in Part 3 of the theorem.
In the following let the hyperplane rule be given by affine hyperplanes H1 , . . . , H` of
m! and the function F : m!  [m]; in the limiting setting denote by H1 , . . . , H` the
corresponding hyperplanes of Rm! |H0 and denote by F : Rm! |H0  [m] the corresponding
function.
3.3.1 The Quantities q and q
For x  Rm! |H0 define
 (x) :=

inf

d1 (x, y) ,

 (x) := max

inf

a[m] y:F (y)=a

y:F (y)6=F (x)

d1 (x, y) .

From the previous subsection it is then immediate that we can write

 

q (c) =  X :  X  2c ,

 

q (c) =  X :  X  2c .
It is important to note that the boundary B is contained in the union of finitely many
hyperplanes, H1 , . . . , H`, and thus the regions where F is constant are convex cones which
are the intersection of finitely many halfspaces.

Consequently  (x) is either d1 (x,0), where

m!
 where d1 x, Hj =
0 denotes the origin of R , or it is d1 x, Hj for some 1  j  `,
938

fiA Smooth Transition from Powerlessness to Absolute Power

inf yHj d1 (x, y). If we scale x by some positive constant , then the distance from the origin


and from every hyperplane scales as well (i.e., d1 (x, 0) = d1 (x, 0) and d1 x, Hj =


d1 x, Hj ), and thus for every  > 0, we have  (x) =  (x). Consequently, if we
write x = kxk2 s, where s  S m!1 , and S m!1 denotes the (m!  1)-sphere (not to be
n , the set of ranking profiles on n voters and m candidates), then we have
confused with Sm
 (x) = kxk2  (s).
The same scaling property holds for  as well, and hence we have
   


 
(3)
q (c) =  X : X   S  2c ,
 2  


 
q (c) =  X : X   S  2c .
(4)
2

Recall that our condition that for every a  [m], P (f () = a)  , implies that for every
 > 0 and for every a  [m] there exists x  Rm! |H0 such that kxk2   and F (x) = a.
Consequently for every x  Rm! |H0 we must
have  (x)  d1(x, 0) and  (x)  d1 (x, 0).
 In
m!1
particular, for s  S
we have d1 (s, 0)  m!d2 (s, 0) = m! and so  (s) ,  (s)  m!.
This immediately implies that for every c > 0 we have


 
2c
 
q (c)   X : X   
> 0.
2
m!
To show that q (c) < 1, note that since the boundary is contained in the union of finitely
many hyperplanes, there exists s  S m!1 such that  (s ) > 0. By continuity of , there
exists a neighborhood U  S m!1 of s such that for every s  U ,  (s)   (s ) /2. For
4c
any x such that x/ kxk2  U and kxk2 > (s
 ) , we have
 (x) = kxk2  (x/ kxk2 ) >

4c  (s )
= 2c.
 (s ) 2

So consequently


 
 
 
 
q (c)  1   X : X/ X   U, X  >
2

2

4c
 (s )


< 1.

Finally, the fact that q (c) and q (c) are continuously differentiable follows from the
formulas (3) and (4), since q (c) and q (c) are both written as the Gaussian volume of a
subset of Rm! |H0 , and in both cases this subset grows continuously as c increases. The
derivative of both q (c) and q (c) is bounded at zero (by Corollary 3.7 and Claim 3.8), while
as c   the derivative approaches zero, and since the derivative is continuous, it must be
bounded by a constant for the whole half-line.
3.3.2 The Quantities r and r


In the previous setup when the coalition of size c n was not specified, the ranking profile

could be changed arbitrarily within a Hamming ball of radius c n. On the probability

simplex m! this corresponded to an L1 ball of radius 2c/ n, and in the rescaled limiting
939

fiMossel, Procaccia, & Racz

setting it corresponded to an L1 ball in Rm! |H0 of radius 2c. When the coalition of size

c n is specified, things are slightly different. In particular, when we look at the probability
distribution on the probability simplex m! induced by the distribution on ranking profiles
(or, in the limiting setting, the Gaussian distribution on Rm! |H0 ), then we have lost track of
the votes of any specific coalition. Nonetheless, the Gaussian limiting setting still provides
formulas for the limiting probabilities r (c) and r (c).

We can first
 draw a random ranking profile for the other n  c n voters not in the
coalition,  nc n , and then the voters in the coalition can set their votes arbitrarily. The
question is, how can the coalition affect the outcome of the vote? In particular, (a) can
they change the outcome of the election, and (b) can they
 candidate?
 elect any

The ranking profile  nc n corresponds to a point x  nc n on the probability simplex m! , and by setting their votes
can move this point on the probability
 thecoalition

nc
n
simplex in some neighborhood of x 
. We omit the calculation for finite n and only
present the result in the limiting setting.
Suppose the limiting ranking profile of the voters other than the coalition corresponds
to the point x  Rm! |H0 . Then the set of points the coalition can reach is the following:
n
o
Rc (x) := y  Rm! |H0 :   Sm : y  x + cp ()  0 .
We can then define

n
o
 (x) := inf  : y  R (x) such that F (y) 6= F (x) ,
n
o
 (x) := inf  : a  [m] y  R (x) such that F (y) = a ,

and it follows immediately that we can then write

 

r (c) =  X :  X  c ,

 

r (c) =  X :  X  c .
In the same way as in Section 3.3.1 one can argue that  and  scale: if  > 0 then
 (x) =  (x) and  (x) =  (x). Hence we have
   


 
r (c) =  X : X   S  c ,
(5)
 2  


 
r (c) =  X : X   S  c .
(6)
2

For every 0 < c <  we have r (c)  q (c) < 1 (using Section 3.3.1). Let us now show that
also r (c) > 0. We claim that for all s  S m!1 |H0 ,  (s)  2 . This follows from the fact
that if s  S m!1 |H0 then S m!1 |H0  R 2 (s), which is true because if y  S m!1 |H0 then


for all   Sm , y  s + 2 p ()  1  1 + 2  = 0. Thus we have


 
c
 
r (c)   X : X  
>0
2
2
as claimed.
940

fiA Smooth Transition from Powerlessness to Absolute Power

Finally, the fact that r (c) and r (c) are continuously differentiable follows from the
formulas (5) and (6) using an argument given above: r (c) and r (c) are written as the
Gaussian volume of subsets of Rm! |H0 , and these subsets grow continuously as c increases.
The derivative of both r (c) and r (c) is bounded at zero (by Corollary 3.7 and Claim 3.8),
while as c   the derivative approaches zero, and since the derivative is continuous, it
must be bounded by a constant for the whole half-line.

Acknowledgments
We thank anonymous referees for helpful comments. E.M. is supported by NSF (DMS
1106999) and by DOD ONR grant N000141110140, and M.Z.R. is supported by a UC
Berkeley Graduate Fellowship and by NSF (DMS 0548249).

Appendix A. Decomposing Rd as the Disjoint Union of Finitely Many
Convex Cones: Only Via Hyperplanes
In order for the paper to be self-contained, we reproduce here the main definitions and
results of Kemperman (1986) that make precise the claim used in the proof of Lemma 3.1
that the only way to decompose Qd0 \ {0} into the disjoint union of finitely many Q-convex
cones is via hyperplanes. Kempermans paper deals with convex sets in general, but here
we summarize the results about convex cones that are relevant to us. Kempermans results
pertain to finite dimensional linear spaces and we will state them in this form; in the end
we show how results for Rd0 follow immediately from these, and as a consequence we also
obtain the claim used in the proof of Lemma 3.1.
Let us start with the main definitions. In the following, all linear spaces are over the
reals and are finite dimensional. Let X be a linear space. A convex cone is a subset K  X
such that x, y  K and  > 0 imply x + y  K and x  K. (We do not require that
0  K.) For a set A  X, denote its affine hull by aff (A), its convex hull by cvx (A), and
its closure by cl (A). Note that if K  X is a convex cone, then aff (K) is a linear subspace
of X.
We define two special types of convex cones: basic convex cones and elementary convex
cones.
Definition 10 (Basic convex cone). Let K be a convex cone in a finite dimensional linear
space X. We say that K is a basic convex cone (in X) if K is a member K = K0 of some
partition
 1  . . . K
 r
X = K0 K
of X into finitely many disjoint convex cones {Ki }ri=0 .
Note that any linear subspace Y of X is a basic convex cone, from which it immediately
follows that K is a basic convex cone in X if and only if it is a basic convex cone in aff (K).
In order to define elementary convex cones, we need a few more definitions.
Definition 11 (Open polyhedral convex cone). Let K be a convex cone in a finite dimensional linear space X. We say that K is an open polyhedral convex cone relative to X if K
941

fiMossel, Procaccia, & Racz

can be expressed as the intersection of finitely many open halfspaces H1 , . . . , H` of X, each
of which has the origin on its boundary. The whole linear space X is an open polyhedral
convex cone with ` = 0.
Definition 12 (Relatively open polyhedral convex cone). Let K be a convex cone in a
finite dimensional linear space X. Then K is a relatively open polyhedral convex cone if
either K =  or K is an open polyhedral convex cone relative to aff (K).
Definition 13 (Elementary convex cone). Let K be a convex cone in a finite dimensional
linear space X. We say that K is an elementary convex cone if K can be represented as a
disjoint union of finitely many relatively open polyhedral convex cones.
The main result of Kemperman concerning convex cones is the following (Kemperman,
1986, Thm. 2).
Theorem A.1. Let K be a convex cone in Rd . Then K is a basic convex cone if and only
if it is an elementary convex cone.
In Lemma 3.1 we only use the only if direction, and we thus leave the proof of the
if direction as an exercise for the reader.
Proof of only if  direction. Let X be a finite dimensional linear space and let K be a basic
convex cone in X of dimension d = dim (K) = dim (Y ), where Y = aff (K). We prove by
induction on d the following:
(i) The relative interior of K, denoted by K 0 , is a relatively open polyhedral convex cone.
(ii) If K 0 6= Y , then denote by F1 , . . . , F` the (d  1)-dimensional hyperplanes
 in Y cor0
responding to the finitely many faces of the polyhedron cl (K) = cl K . Then the
convex cones Fi  K, i = 1, . . . , `, are elementary convex cones of dimension at most
d  1 (but they need not be disjoint).
(iii) The convex cone K is also an elementary convex cone.
If K = , then properties (i) - (iii) hold. If d = 0, then necessarily K = {0}, since K is
a convex cone, and again K satisfies properties (i) - (iii) above.
So we may assume that d  1 and that each basic convex cone of dimension at most
d  1 satisfies properties (i) - (iii) above. Since K is a basic convex cone, there exists a
partition
 1  . . . K
 r
Y = K0 K
(7)
of Y into finitely many disjoint convex cones {Kj }rj=0 , with K0 = K. We may assume that
r  0 is minimal, and hence the Kj are non-empty. Note that K 0 is also non-empty since
dim (K) = dim (Y ).
If r = 0 then K = K0 = Y and the properties (i) - (iii) above are immediately satisfied,
so we may assume that r  1. For j = 1, . . . , r, let Hj be a hyperplane in Y which separates
the convex cone K = K0 with non-empty interior K 0 from the non-empty convex cone Kj .
(Such hyperplanes exist by the hyperplane separation theorem, and, moreover, each such
hyperplane goes through the origin, because each Kj contains at least one point from every
942

fiA Smooth Transition from Powerlessness to Absolute Power

open ball around the origin, since each Kj is a cone.) Let Hj0 be the associated open half
space in Y which contains the interior K 0 of K. Let
L0 = H10      Hr0 .
Then L0 is a polyhedral convex cone, which is open relative to Y , and contains the interior
K 0 of K.
We claim that L0 = K 0 . It is enough to show that L0  K, because then L0  K 0
follows from the definition of K 0 . Suppose on the contrary that there exists x  L0 such
that x 
/ K. Then from the partition (7) there must exist an index 1  j  r with x  Kj .
/ L0 , which is a contradiction. This proves (i).
This implies that x 
/ Hj0 and thus x 
Now let us show (ii). By (7), we can write the linear space Fi as the disjoint union of
the convex cones Fi  Kj , j = 0, . . . , r, and thus Fi  K is a basic convex cone and hence,
by induction, an elementary convex cone.
Finally, let us show that K is an elementary convex cone. Since K 0 is a polyhedral
convex cone which is open relative to Y , it only remains to show that K \ K 0 can be written
as a finite disjoint union of relatively open polyhedral convex cones. By (ii), we can write
K \ K 0 as the finite union of elementary convex cones:
K \ K 0 = `i=1 (Fi  K) ,
so what remains is to show that we can write this as a finite disjoint union of relatively
open polyhedral convex cones. We may assume w.l.o.g. that Fi  K 6=  for all i and that
(Fi  K) * (Fj  K) for all i 6= j (otherwise we can leave out Fi  K from the union).
We claim that then for every i,
[
(Fj  Fi  K) ,
(8)
rel int (Fi  K)  (Fi  K) \
j6=i

from which it immediately follows that rel int (Fi  K)  rel int (Fj  K) =  for i 6= j. To
show (8), let the two open halfspaces on either side of the hyperplane Fj be denoted by
Fj+ and Fj . W.l.o.g. assume that K  Fj = . Since (Fi  K) * (Fj  K), we must have
(Fi  K)  Fj+ 6= . Let x  (Fi  K)  Fj+ and let y  Fj  Fi  K. Since Fi  K is convex,
the interval from x to y is contained in Fi  K, but because (Fi  K)  Fj = , no points
on this line past the point y can be in Fi  K; hence y 
/ rel int (Fi  K).
Since Fi  K is a basic convex cone, rel int (Fi  K) is a relatively open polyhedral
convex cone by induction. If Fi  K = aff (Fi  K) then rel int (Fi  K) = Fi  K. If not,
then denote by Fi,1 , . . . , Fi,`i the hyperplanes in aff (Fi  K) corresponding to the finitely
many faces of the polyhedron cl (Fi  K). By induction, the convex cones Fi,j  Fi  K,
j = 1, . . . , `i , are elementary convex cones, and we can write

[

  `
`
i
K \ K 0 =  i=1 rel int (Fi  K)
i=1 `j=1
(Fi,j  Fi  K) .
i
What remains to be shown is that `i=1 `j=1
(Fi,j  Fi  K) can be written as a finite disjoint
union of relatively open polyhedral convex cones; this follows by iterating the previous
argument.

943

fiMossel, Procaccia, & Racz

Let us now show that Rd0 is a basic convex cone in Rd . For i = 1, . . . , d, define the

	

	
closed halfspace Hi0 = x  Rd : xi  0 and its complement Hi<0 = x  Rd : xi < 0 ,
and from these define the convex cones
0
Ki = H10      Hi1
 Hi<0 ,

i = 1, . . . , d.

Then we can write Rd as the disjoint union of the convex cones Rd0 and K1 , . . . , Kd , showing
that indeed Rd0 is a basic convex cone. This implies that if we can write Rd0 as the disjoint
union of the convex cones C1 , . . . , Cr , then each Ci is a basic convex cone, and hence, by
Theorem A.1, an elementary convex cone.
Now let us turn to the claim in the proof of Lemma 3.1. In Lemma 3.1, we write Qm!
0 \ {0}
m!
 1  . . . C
 r . For
as the disjoint union of finitely many Q-convex cones: Q0 \ {0} = C0 C
m!
i = 0, . . . , r, let Ci = cvx (Ci ). It is known (see, e.g., Young, 1975) that Ci = Q Ci . The
Ci are therefore disjoint convex cones which satisfy

and

C0  C1  . . .  Cr  Rm!
0

(9)

 
 
 
cl C0  cl C1      cl Cr = Rm!
0 .

(10)

Our goal is to show that each Ci is an elementary convex cone. Conditions (10) and (9)
are very similar to the definition of a basic convex cone; in this spirit let us introduce the
following definition.
Definition 14 (Basic convex cone up to closure). Let K0 be a convex cone in a finite
dimensional linear space X. We say that K0 is a basic convex cone up to closure (in X) if
there exist disjoint convex cones K1 , . . . , Kr such that
 1  . . . K
 rX
K0 K
and
cl (K0 )  cl (K1 )      cl (Kr ) = X.
Since Rd0 is a basic convex cone, the Ci above are basic convex cones up to closure.
In fact, every basic convex cone up to closure is an elementary convex cone; the proof is
exactly the same as the one shown above for the only if direction of Theorem A.1, one just
needs to replace basic convex cone with basic convex cone up to closure everywhere in
the proof, and make the appropriate changes. Moreover, the other direction of Theorem A.1
implies that actually every basic convex cone up to closure is a basic convex cone.
Hence the Ci are elementary convex cones, which is what we need in Lemma 3.1.

Appendix B. Most Voting Rules are Hyperplane Rules: Examples
In the following we show that all positional scoring rules, instant-runoff voting, Coombs
method, contingent vote, the Kemeny-Young method, Bucklin voting, Nansons method,
Baldwins method, and Copelands method are all hyperplane rules.
944

fiA Smooth Transition from Powerlessness to Absolute Power

 Positional scoring rules. Let w  Rm be a weight vector. Given
a ranking profile
P
vector , the (normalized) score of candidate a  [m] is sa = n1 ni=1 w i1 (a) . The
positional scoring rule associated to the weight vector w elects the candidate who has
the highest score. (In case of a tie, there is some tie-breaking rule, but we do not
care about this here.) We denote such a SCF on n voters by fnw . Examples include
plurality (with weight vector w = (1, 0, 0, . . . , 0)), Borda count (with weight vector
w = (m  1, m  2, . . . , 0)) and veto (with weight vector w = (1, 1, . . . , 1, 0)).
To a sequence of SCFs {fnw }n1 we can associate a function F w : m!  [m] in the
followingP
way. For a candidate
a  [m] and x  m! , define the (normalized) score

sa (x) = Sm x w  1 (a) , and let
F w (x) := arg max sa (x) ,
a[m]

if this arg max is unique, and if it is not unique, then there is some tie-breaking rule.
This construction guarantees that fnw = F w |Dn . For candidates a 6= b, define
n
o
Ha,b := x  m! : sa (x) = sb (x) ,
which is an affine hyperplane of the
probability simplex m! . Clearly the boundary

m
B w is contained in the union of 2 such affine hyperplanes:
[
Bw 
Ha,b .
a6=b[m]

 Instant-runoff voting. If a candidate receives absolute majority of first preference
votes, then that candidate wins. If no candidate receives an absolute majority, then
the candidate with fewest top votes is eliminated. In the next round the votes are
counted again, with each ballot counted as one vote for the advancing candidate who
is ranked highest on that ballot. This is repeated until the winning candidate receives
a majority of the vote against the remaining candidates.
The boundary corresponds to two kinds of situations: either (1) there is a tie at the
top at the end, when only two candidates remain; or (2) there is a tie for eliminating a
candidate at the end of one of the rounds. Technically situation (1) is also contained
in situation (2), since at the very end one can view choosing a winner as eliminating
the second placed candidate. One can see that if candidates a and b are tied for
elimination after candidates C  [m] \ {a, b} (where C =  is allowed) have been
eliminated, then necessarily
X
X
X
X
x =
x .
(11)
C 0 C {(1),...,(|C 0 |)}=C 0 ,
(|C 0 |+1)=a

C 0 C {(1),...,(|C 0 |)}=C 0 ,
(|C 0 |+1)=b

Consequently, denoting by sa,C (x) the quantity on the left hand side of (11), the
boundary B is contained in the union of at most m2 2m affine hyperplanes:
n
o
[
[
B
x  m! : sa,C (x) = sb,C (x) .
a6=b C[m]\{a,b}

945

fiMossel, Procaccia, & Racz

 Coombs method. This is similar to IRV, but the elimination rule is different. If
a candidate receives absolute majority of first preference votes, then that candidate
wins. If no candidate receives an absolute majority, then the candidate who is ranked
last by the most voters is eliminated. In the next round the votes are counted again,
with each ballot counted as one vote for the advancing candidate who is ranked highest
on that ballot. This is repeated until the winning candidate receives a majority of the
vote against the remaining candidates.
The boundary corresponds to two kinds of situations: either (1) there is a tie at the
top at the end, when only two candidates remain; or (2) there is a tie for eliminating a
candidate at the end of one of the rounds. Technically situation (1) is also contained
in situation (2), since at the very end one can view choosing a winner as eliminating
the second placed candidate. One can see that if candidates a and b are tied for
elimination after candidates C  [m] \ {a, b} (where C =  is allowed) have been
eliminated, then necessarily
X
X
X
X
x =
x .
(12)
C 0 C {(m),...,(m|C 0 |+1)}=C 0 ,
(m|C 0 |)=a

C 0 C {(m),...,(m|C 0 |+1)}=C 0 ,
(m|C 0 |)=b

Consequently, denoting by sa,C (x) the quantity on the left hand side of (12), the
boundary B is contained in the union of at most m2 2m affine hyperplanes:
B

[

[



	
x  m! : sa,C (x) = sb,C (x) .

a6=b C[m]\{a,b}

 Contingent vote. This is also similar to IRV, except here all but two candidates
get eliminated after the first round. If a candidate receives absolute majority of first
preference votes, then he/she wins. If no candidate receives an absolute majority, then
all but the top two leading candidates are eliminated and there is a second count, where
the votes of those who supported an eliminated candidate are redistributed among
the two remaining candidates. The candidate who then achieves absolute majority
wins.
Here the boundary B corresponds to two kinds of situations: either (1) there are
two distinct top candidates, and when the votes of the voters who voted for other
candidates are redistributed, then the two top candidates are in a dead heat; or (2)
there are two or more candidates who receive an equal number of votes in the first
round. Both of these situations can be described as subsets of affine hyperplanes, and
so B is contained in the union of at most m (m  1) affine hyperplanes:






[
X
X
X
X
m!
B
x :
x +
x =
x +
x





a6=b 
:(1)=a
:(1)=b
:(1){a,b},a
/
>b
:(1){a,b},b
/
>a



[
X
X

x  m! :
x =
x .


a6=b

:(1)=a

:(1)=b

946

fiA Smooth Transition from Powerlessness to Absolute Power

 Kemeny-Young method. Denote by K the Kendall tau distance, which is a metric
on permutations which counts the number of pairwise disagreements between the two
permutations, i.e.,
X
K (1 , 2 ) =
1 [a and b are in the opposite order in 1 and 2 ] ,
{a,b}

where the sum is over all unordered pairs of distinct candidates. Given a ranking
profile  n , the Kemeny-Young method selects the ranking which minimizes the sum
of Kendall tau distances from the votes:
 = arg min

n
X

K (i ,  ) ,

i=1

and then the winner of the election is declared to be  (1). For us it will be convenient
to write  as
X
 = arg min
x ( n ) K (,  ) .


Here if we are on the boundary
B then there
P
P must exist two rankings 1 and 2 such
that 1 (1) 6= 2 (1) and  x K (, 1 ) =  x K (, 2 ). Thus B is contained in the
union of at most (m!)2 affine hyperplanes:
(
)
X
X
[
m!
x :
x K (, 1 ) =
x K (, 2 ) .
B
1 6=2





 Bucklin voting. First every candidate gets a point from all the voters who ranked
them at the top. If there is a candidate who has a majority (i.e., more than n/2
points), then that candidate wins. If not, then every candidate gets a point from
all the voters who ranked them second. If there is a candidate who has more than
n/2 points after this, then the candidate with the most points wins (there might be
multiple candidates with more than n/2 points after a given round). This process is
iterated until there is a candidate with more than n/2 points.
Here a point on the boundary B corresponds to a situation where some pair of candidates have the same number of points after some number of rounds. Therefore B is
contained in the union of at most m2 (m  1) /2 affine hyperplanes:


m 
k
k

[ [
X
X
X
X
B
x  m! :
x =
x .


a6=b k=1

i=1 :(i)=a

i=1 :(i)=b

 Nansons method. This is Borda count combined with a variation of the instantrunoff voting procedure. First, the Borda scores of all candidates are computed, and
then those candidates with Borda score no greater than the average Borda score are
eliminated. Then the Borda scores of each remaining candidate are recomputed, as
if the eliminated candidates were not on the ballot. This is repeated until there is a
final candidate left.
947

fiMossel, Procaccia, & Racz

The boundary corresponds to situations when a candidates Borda score exactly equals
the average score after some candidates have been eliminated. For C  [m], denote by
sa,C (x) the score of candidate a after exactly the candidates in C have been eliminated
(sa,C (x) is a linear function of {x }Sm ), and denote by sC (x) the average score of
remaining candidates after exactly the candidates in C have been eliminated. The
boundary B is contained in the union of at most m2m affine hyperplanes:
n
o
[
[
B
x  m! : sa,C (x) = sC (x) .
a[m] C[m]\{a}

 Baldwins method. This is essentially Borda count combined with the instantrunoff voting procedure. First, the Borda scores of all candidates are computed, and
then the candidate with the lowest score is eliminated. Then the Borda scores of each
remaining candidate are recomputed, as if the eliminated candidate were not on the
ballot. This is repeated until there is a final candidate left.
The boundary corresponds to ties for eliminating a candidate at the end of one of the
rounds. Borrow the notation sa,C (x) from the previous example. The boundary B is
thus contained in the union of at most m2 2m affine hyperplanes:
n
o
[
[
B
x  m! : sa,C (x) = sb,C (x) .
a6=b C[m]\{a,b}

 Copelands method. This is a pairwise aggregation method: every candidate gets
1 point for each other candidate it beats in a pairwise majority election, and 1/2 a
point for each candidate it ties with in a pairwise majority election. The winner is
the candidate who receives the most points. This method
corresponds to cutting the

simplex m! up into finitely many regions via m
affine
hyperplanes, and in each
2
region the winner is the candidate with the most points.
While in the previous examples tie-breaking rules were not an issue, here it does
become important. We do not care about tie-breaking rules when we are on an
affine hyperplane where two candidates tie each other in a pairwise majority election.
However, there are open regions in the intersection of halfspaces defined by the affine
hyperplanes where candidates are tied at the top with having the same scores. In
this case, in order for Copeland to be a hyperplane rule, we need to break ties in
favor of the same candidate for the whole region. (This is also how ties are broken for
Copelands method in Xia & Conitzer, 2008b.)
Using this tie-breaking rule Copelands method is indeed a hyperplane rule, since the
boundary is contained in the union of at most m
2 affine hyperplanes:



[
X
X
B
x  m! :
x =
x .




a6=b

:a>b

948

:b>a

fiA Smooth Transition from Powerlessness to Absolute Power

References
Achlioptas, D. (1999). Threshold phenomena in random graph colouring and satisfiability.
Ph.D. thesis, Department of Computer Science, University of Toronto.
Achlioptas, D., Naor, A., & Peres, Y. (2005). Rigorous location of phase transitions in hard
optimization problems. Nature, 435 (7043), 759764.
Bartholdi III, J., Tovey, C., & Trick, M. (1989). The Computational Difficulty of Manipulating an Election. Social Choice and Welfare, 6 (3), 227241.
Betzler, N., Niedermeier, R., & Woeginger, G. J. (2011). Unweighted coalitional manipulation under the Borda rule is NP-hard. In Proceedings of the 22nd International Joint
Conference on Artificial Intelligence (IJCAI), pp. 5560.
Brandt, F. (2009). Some remarks on Dodgsons voting rule. Mathematical Logic Quarterly,
55 (4), 460463.
Caragiannis, I., & Procaccia, A. D. (2011). Voting almost maximizes social welfare despite
limited communication. Artificial Intelligence, 175 (910), 16551671.
Chamberlain, G., & Rothschild, M. (1981). A note on the probability of casting a decisive
vote. Journal of Economic Theory, 25 (1), 152162.
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). Where the really hard problems are.
In Proceedings of the 12th International Joint Conference on Artificial Intelligence
(IJCAI), pp. 331337.
Conitzer, V., & Sandholm, T. (2006). Nonexistence of Voting Rules That Are Usually
Hard to Manipulate. In Proceedings of the 21st National Conference on Artificial
Intelligence, Vol. 21, pp. 627634.
Conitzer, V., Sandholm, T., & Lang, J. (2007). When are elections with few candidates
hard to manipulate?. Journal of the ACM, 54 (3), 133.
Dobzinski, S., & Procaccia, A. (2008). Frequent Manipulability of Elections: The Case
of Two Voters. In Proceedings of the 4th International Workshop on Internet and
Network Economics, pp. 653664. Springer.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Llull and
Copeland Voting Computationally Resist Bribery and Constructive Control. Journal of Artificial Intelligence Research, 35, 275341.
Faliszewski, P., & Procaccia, A. (2010). AIs War on Manipulation: Are We Winning?. AI
Magazine, 31 (4), 5364.
Friedgut, E., Kalai, G., Keller, N., & Nisan, N. (2011). A Quantitative Version of the
Gibbard-Satterthwaite Theorem for Three Alternatives. SIAM J. Comput., 40 (3),
934952.
Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections can be manipulated often. In Proceedings of the 49th Annual Symposium on Foundations of Computer Science, pp.
243249. IEEE.
949

fiMossel, Procaccia, & Racz

Fu, Y., & Anderson, P. (1986). Application of statistical mechanics to NP-complete problems
in combinatorial optimisation. Journal of Physics A: Mathematical and General, 19,
16051620.
Gibbard, A. (1973). Manipulation of Voting Schemes: A General Result. Econometrica:
Journal of the Econometric Society, 587601.
Gomes, C., & Walsh, T. (2006). Randomness and Structure. In Rossi, F., van Beek, P.,
& Walsh, T. (Eds.), Handbook of Constraint Programming, Foundations of Artificial
Intelligence, pp. 639664. Elsevier.
Good, I., & Mayer, L. (1975). Estimating the efficacy of a vote. Behavioral Science, 20 (1),
2533.
Isaksson, M., Kindler, G., & Mossel, E. (2012). The Geometry of Manipulation: A Quantitative Proof of the Gibbard-Satterthwaite Theorem. Combinatorica, 32 (2), 221250.
Kelly, J. (1993). Almost all social choice rules are highly manipulable, but a few arent.
Social Choice and Welfare, 10 (2), 161175.
Kemperman, J. (1986). Decomposing Rd into finitely many semigroups. In Indagationes
Mathematicae (Proceedings), Vol. 89, pp. 7178. Elsevier.
Mossel, E., & Racz, M. (2012). A quantitative Gibbard-Satterthwaite theorem without
neutrality. In Proceedings of the 44th ACM Symposium on Theory of Computing
(STOC), pp. 10411060. ACM. Full version to appear in Combinatorica, available as
arXiv preprint at arXiv:1110.5888.
Myatt, D. (2007). On the theory of strategic voting. The Review of Economic Studies,
74 (1), 255281.
Peleg, B. (1979). A note on manipulability of large voting schemes. Theory and Decision,
11 (4), 401412.
Pritchard, G., & Slinko, A. (2006). On the average minimum size of a manipulating coalition.
Social Choice and Welfare, 27 (2), 263277.
Pritchard, G., & Wilson, M. (2009). Asymptotics of the minimum manipulating coalition
size for positional voting rules under impartial culture behaviour. Mathematical Social
Sciences, 58 (1), 3557.
Procaccia, A., & Rosenschein, J. (2007a). Average-case tractability of manipulation in voting via the fraction of manipulators. In Proceedings of the 6th International Conference
on Autonomous Agents and Multi-Agent Systems (AAMAS), pp. 718720.
Procaccia, A., & Rosenschein, J. (2007b). Junta Distributions and the Average-case Complexity of Manipulating Elections. Journal of Artificial Intelligence Research, 28,
157181.
Satterthwaite, M. (1975). Strategy-proofness and Arrows Conditions: Existence and Correspondence Theorems for Voting Procedures and Social Welfare Functions. Journal
of Economic Theory, 10 (2), 187217.
Slinko, A. (2004). How large should a coalition be to manipulate an election?. Mathematical
Social Sciences, 47 (3), 289293.
950

fiA Smooth Transition from Powerlessness to Absolute Power

Walsh, T. (2002). The Interface between P and NP: COL, XOR, NAE, 1-in-k, and Horn
SAT. In Proceedings of the 17th National Conference on AI (AAAI 2002), pp. 695
700.
Walsh, T. (2011). Where Are the Hard Manipulation Problems?. Journal of Artifical
Intelligence Research, 42, 129.
Xia, L. (2012a). Computing the margin of victory for various voting rules. In Proceedings
of the 13th ACM Conference on Electronic Commerce (EC), pp. 982999. ACM.
Xia, L. (2012b). How Many Vote Operations Are Needed to Manipulate A Voting System?.
Arxiv preprint arXiv:1204.1231.
Xia, L., & Conitzer, V. (2008a). A Sufficient Condition for Voting Rules to be Frequently
Manipulable. In Proceedings of the 9th ACM Conference on Electronic Commerce
(EC), pp. 99108. ACM.
Xia, L., & Conitzer, V. (2008b). Generalized Scoring Rules and the Frequency of Coalitional
Manipulability. In Proceedings of the 9th ACM Conference on Electronic Commerce
(EC), pp. 109118. ACM.
Xia, L., & Conitzer, V. (2009). Finite Local Consistency Characterizes Generalized Scoring
Rules. In Proceedings of the 9th International Joint Conference on Artificial Intelligence (IJCAI), pp. 336341.
Xia, L., Zuckerman, M., Procaccia, A. D., Conitzer, V., & Rosenschein, J. S. (2009). Complexity of unweighted coalitional manipulation under some common voting rules. In
Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI), pp. 348353.
Young, H. (1975). Social choice scoring functions. SIAM Journal on Applied Mathematics,
824838.
Zuckerman, M., Procaccia, A. D., & Rosenschein, J. S. (2009). Algorithms for the coalitional
manipulation problem. Artificial Intelligence, 173 (2), 392412.

951

fiJournal of Artificial Intelligence Research 48 (2013)

Submitted 5/2013; published 12/2013

Exact Query Reformulation over Databases
with First-order and Description Logics Ontologies
Enrico Franconi
Volha Kerhet
Nhung Ngo

franconi@inf.unibz.it
kerhet@inf.unibz.it
ngo@inf.unibz.it

Free University of Bozen-Bolzano, Italy

Abstract
We study a general framework for query rewriting in the presence of an arbitrary
first-order logic ontology over a database signature. The framework supports deciding the
existence of a safe-range first-order equivalent reformulation of a query in terms of the
database signature, and if so, it provides an effective approach to construct the reformulation based on interpolation using standard theorem proving techniques (e.g., tableau).
Since the reformulation is a safe-range formula, it is effectively executable as an SQL query.
At the end, we present a non-trivial application of the framework with ontologies in the
very expressive ALCHOIQ description logic, by providing effective means to compute
safe-range first-order exact reformulations of queries.

1. Introduction
We address the problem of query reformulation with expressive ontologies over databases.
An ontology provides a conceptual view of the database and it is composed by constraints
on a vocabulary extending the basic vocabulary of the data. Querying a database using
the terms in such a richer ontology allows for more flexibility than using only the basic
vocabulary of the relational database directly.
In this paper we study and develop a query rewriting framework applicable to knowledge
representation systems where data is stored in a classical finite relational database, in a way
that in the literature has been called the locally-closed world assumption (Etzioni, Golden,
& Weld, 1997), exact views (Marx, 2007; Nash, Segoufin, & Vianu, 2010; Fan, Geerts,
& Zheng, 2012), or DBox (Seylan, Franconi, & de Bruijn, 2009; Franconi, Ibanez-Garcia,
& Seylan, 2011). A DBox is a set of ground atoms which semantically behaves like a
database, i.e., the interpretation of the database predicates in the DBox is exactly equal
to the database relations. The DBox predicates are closed, i.e., their extensions are the
same in every interpretation, whereas the other predicates in the ontology are open, i.e.,
their extensions may vary among different interpretations. We do not consider here the
open interpretation for the database predicates (also called ABox or sound views). In an
ABox, the interpretation of database predicates contains the database relations and possibly
more. This notion is less faithful in the representation of a database semantics since it would
allow for spurious interpretations of database predicates with additional unwanted tuples
not present in the original database.
In our general framework an ontology is a set of first-order formulas, and queries are
(possibly open) first-order formulas. Within this setting, the framework provides precise
semantic conditions to decide the existence of a safe-range first-order equivalent reformulac
2013
AI Access Foundation. All rights reserved.

fiFranconi, Kerhet, & Ngo

tion of a query in terms of the database signature. It also provides an effective approach to
construct the reformulation with sufficient conditions. We are interested in safe-range reformulations of queries because their range-restricted syntax is needed to reduce the original
query answering problem to a relational algebra evaluation (e.g., via SQL) over the original
database (Abiteboul, Hull, & Vianu, 1995). Our framework points out several conditions on
the ontologies and the queries to guarantee the existence of a safe-range reformulation. We
show that these conditions are feasible in practice and we also provide an efficient method
to ensure their validation. Standard theorem proving techniques can be used to compute
the reformulation.
In order to be complete, our framework is applicable to ontologies and queries expressed
in any fragment of first-order logic enjoying finitely controllable determinacy (Nash et al.,
2010), a stronger property than the finite model property of the logic. If the employed logic
does not enjoy finitely controllable determinacy our approach would become sound but
incomplete, but still effectively implementable using standard theorem proving techniques.
We have explored non-trivial applications where the framework is complete; in this paper,
the application with ALCHOIQ ontologies and concept queries is discussed. We show how
(i) to check whether the answers to a given query with an ontology are solely determined
by the extension of the DBox predicates and, if so, (ii) to find an equivalent rewriting of the
query in terms of the DBox predicates to allow the use of standard database technology for
answering the query. This means we benefit from the low computational complexity in the
size of the data for answering queries on relational databases. In addition, it is possible to
reuse standard techniques of description logics reasoning to find rewritings, such as in the
paper by Seylan et al. (2009).
The query reformulation problem has received strong interest in classical relational
database research as well as modern knowledge representation studies. Differently from
the mainstream research on query reformulation (Halevy, 2001), which is mostly based
on perfect or maximally contained rewritings with sound views under relatively inexpressive constraints (see, e.g., the DL-Lite approach in Artale, Calvanese, Kontchakov, & Zakharyaschev, 2009), we focus here on exact rewritings with exact views, since it characterises
precisely the query answering problem with ontologies and databases, in the case when the
exact semantics of the database must be preserved. As an example, consider a ground negative query over a given standard relational database; by adding an ontology on top of it, its
answer is not supposed to changesince the query uses only the signature of the database
and additional constraints are not supposed to change the meaning of the querywhereas
if the database were treated as an ABox (sound views) the answer may change in presence
of an ontology. This may be important from the application perspective: a DBox preserves
the behaviour of the legacy application queries over a relational database. Moreover, by
focussing on exact reformulations of definable queries (as opposed to considering the certain
answer semantics to arbitrary queries, such as in DL-Lite), we guarantee that answers to
queries can be subsequently composed in an arbitrary way: this may be important to legacy
database applications.
This work extends the works on exact rewritings with exact views by Marx (2007) and
Nash et al. (2010) by focussing on safe-range reformulations and on the conditions ensuring
their existence, and by considering general first-order ontologies extending the database
signature, rather than just local as view constraints over the database predicates (Halevy,
886

fiExact Query Reformulation over DBs with FO and DL Ontologies

2001). This paper extends the papers by Franconi, Kerhet, and Ngo (2012a, 2012b) by
providing a precise semantic characterisation for the existence of an exact reformulation
(Theorem 4) as opposed to just sufficient conditions, by considering the much more expressive description logic ALCHOIQ, and by providing all the proofs.
The paper is organised as follows: section 2 provides the necessary formal background
and definitions; section 3 introduces the notion of a query determined by a database; section 4 introduces a characterisation of the query reformulation problem; in sections 5 and 6
the conditions allowing for an effective reformulation are analysed, and a sound and complete algorithm to compute the reformulation is introduced. Finally, we present the case of
ALCHOIQ ontologies. All the proofs are presented in details in the Appendix.

2. Preliminaries
Let FOL(C, P) be a classical function-free first-order language with equality over a signature
 = (C, P), where C is a finite set of constants and P is a set of predicates with associated
arities. In the rest of this paper we will refer to an arbitrary fragment of FOL(C, P), which
will be called L.
We denote with P{1 ,...,n } the set of all predicates occurring in the formulas 1 , . . . , n ,
with C{1 ,...,n } the set of all constants occurring in the formulas 1 , . . . , n ; for the sake of
brevity, instead of P{} (resp. C{} ) we write P (resp. C ). We denote with (1 , . . . , n )
the signature of the formulas 1 , . . . , n , namely the union of P{1 ,...,n } and C{1 ,...,n } .
We denote the arity of a predicate P as ar(P ). Given a formula , we denote the set of
all variables appearing in  as var(), and the set of the free variables appearing in  as
free(); we may use for  the notation [X] , where X = free() is the (possibly empty)
set of free variables of the formula.
A database (instance) DB is a finite set of ground atoms of the form P (c1 , . . . , cn ), where
P  P, n-ary predicate, and ci  C (1  i  n). The set of all predicates appearing in a
database DB is denoted as PDB , and the set of all constants appearing in DB is called the
active domain of DB, and is denoted as CDB . A (possibly empty) finite set KB of closed
formulas will be called an ontology.
As usual, an interpretation I = hI , I i includes a non-empty setthe domain I and
an interpretation function I defined over constants and predicates of the signature. We say
that interpretations I = hI , I i and J = hJ , J i are equal, written I = J , if I = J
and I = J . An interpretation I embeds a database DB, if it holds that aI = a for every
database constant a  CDB (the standard name assumption (SNA), customary in databases,
see Abiteboul et al., 1995) and that (c1 , . . . , cn )  P I if and only if P (c1 , . . . , cn )  DB. We
denote the set of all interpretations embedding a database DB as E(DB).
In other words, in every interpretation embedding a DB the interpretation of any
database predicate is always the same and it is given exactly by its content in the database;
this is, in general, not the case for the interpretation of the non-database predicates. We
say that all the database predicates are closed, while all the other predicates are open and
may be interpreted differently in different interpretations. We do not consider here the open
world assumption (the ABox ) for embedding a database in an interpretation. In an open
world, an interpretation I soundly embeds a database if it holds that (c1 , . . . , cn )  P I if
(but not only if) P (c1 , . . . , cn )  DB.
887

fiFranconi, Kerhet, & Ngo

In order to allow for an arbitrary database to be embedded, we generalise the standard
name assumption to all the constants in C; this implies that the domain of any interpretation
necessarily includes the set of all the constants C. The finiteness of C corresponds to the
finite ability of a database system to represent distinct constant symbols; C is meant to be
unknown in advance, since different database systems may have different limits. We will
see that the framework introduced here will not depend on the choice of C.
Given an interpretation I = hI , I i, we denote as I|S the interpretation restricted to
the smaller signature S  P  C, i.e., the interpretation with the same domain I and the
same interpretation function I defined only for the constants and predicates from the set
S. The semantic active domain of a signature  0  P  C in an interpretation I, denoted
adom( 0 , I), is the set of all elements of the domain I occurring in interpretations of
predicates and constants from  0 in I:
adom( 0 , I) :=

[

[

P  0 (a1 ,...,an )P I

{a1 , . . . , an } 

[

{cI }.

c 0

If  0  PDB  C, then for any interpretations I and J embedding DB we have:
adom( 0 , I) = adom( 0 , J ); so, for such a case we introduce the notation adom( 0 , DB) :=
adom( 0 , I), where I is any interpretation embedding the database DB. Intuitively
adom( 0 , DB) includes the constants from  0 and from DB appearing in the relations corresponding to the predicates from  0 .
Let X be a set of variable symbols and S a set; a substitution is a total function  : X 7 S
assigning an element in S to each variable in X, including the empty substitution  when
X = . Domain and image (range) of a substitution  are written as dom() and rng()
respectively. Given a subset of the set of constants C0  C, we write that a formula [X]
is true in an interpretation I with its free variables substituted according to a substitution
 : X 7 C0 as (I |= [X/] ). Given an interpretation I = hI , I i and a subset of
its domain   I , we write that a formula [X] is true in I with its free variables
interpreted according to a substitution  : X 7  as (I,  |= ). The extension domain of
aSformula [X] with respect to the interpretation I is defined as the set of domain elements
{rng() | dom() = X, rng()  , I,  |= [X] }.
As usual, an interpretation in which a closed formula is true is called a model for
the formula; the set of all models of a formula  (resp. KB) is denoted as M () (resp.
M (KB)). A database DB is legal for an ontology KB if there exists a model of KB embedding
DB. In the following, we will consider only consistent non-tautological ontologies and legal
databases.
2.1 Queries
A query is a (possibly closed) formula. Given a query Q[X] , we define its certain answer
over KB and DB as follows:
Definition 1 (Certain Answer). The (certain) answer of a query Q[X] to a database DB
under the ontology KB is the set of substitutions with constants:
{ | dom() = X, rng()  C,  I  M (KB)  E(DB) : I |= Q[X/] }.
888

fiExact Query Reformulation over DBs with FO and DL Ontologies

Query answering is defined as an entailment problem, and as such it is going to have the
same (high) complexity as entailment.
Note, that if a query Q is closed (i.e., a Boolean query), then the certain answer is {} if
Q is true in all the models of the ontology embedding the database, and  otherwise. In the
following, we assume that the closed formula Q[X/] is neither valid nor inconsistent under
the ontology KB, given a substitution  : X 7 C assigning to variables distinct constants
not appearing in Q, nor in KB, nor in CDB : this would lead to trivial reformulations.
We now show that we can weaken the standard name assumption for the constants by
just assuming unique names, without changing the certain answers. As we said before, an
interpretation I satisfies the standard name assumption if cI = c for any c  C. Alternatively, an interpretation I satisfies the unique name assumption (UNA) if aI 6= bI for
any different a, b  C. We denote the set of all interpretations satisfying standard name
assumption as I(SNA). We denote the set of all interpretations satisfying unique name
assumption as I(UNA). The following proposition allows us to freely interchange the standard name and the unique name assumptions with interpretations embedding databases.
This is of practical advantage, since we can encode the unique name assumption in classical
first-order logic reasoners, and many description logics reasoners do support natively the
unique name assumption as an extension to OWL.
Proposition 1 (SNA vs UNA). For any query Q[X] , ontology KB and database DB,
{ | dom() = X, rng()  C,  I  I(SNA)  M (KB)  E(DB) : I |= Q[X/] } =
{ | dom() = X, rng()  C,  I  I(UNA)  M (KB)  E(DB) : I |= Q[X/] }.
Since a query can be an arbitrary first-order formula, its answer may depend on the
domain, which we do not know in advance. For example, the query Q(x) = Student(x)
over the database Student(a), Student(b), with domain {a, b, c} has the answer {x = c},
while with domain {a, b, c, d} has the answer {x = c, x = d}. Therefore, the notion of
domain independent queries has been introduced in relational databases. Here we adapt
the classical definitions (Avron, 2008; Abiteboul et al., 1995) to our framework: we need
a more general version of domain independence, namely domain independence w.r.t an
ontology, i.e., restricted to the models of an ontology.
Definition 2 (Domain Independence). A formula Q[X] is domain independent with
respect to an ontology KB iff for every two models I and J of KB (i.e., I = hI , I i
and J = hJ , J i) which agree on the interpretation of the predicates and constants (i.e.
I = J ), and for every substitution  : X 7 I  J we have:
rng()  I and I,  |= Q[X] iff
rng()  J and J ,  |= Q[X] .
The above definition reduces to the classical definition of domain independence whenever
the ontology is empty.
A weaker version of domain independencewhich is relevant for open formulasis the
following.
Definition 3 (Ground Domain Independence). A formula Q[X] is ground domain independent iff Q[X/] is domain independent for every substitution  : X 7 C.
889

fiFranconi, Kerhet, & Ngo

For example, the formula P (x) is ground domain independent, but it is not domain independent.
The problem of checking whether a FOL formula is domain independent is undecidable
(Abiteboul et al., 1995). The well known safe-range syntactic fragment of FOL introduced
by Codd is an equally expressive language; indeed any safe-range formula is domain independent, and any domain independent formula can be easily transformed into a logically
equivalent safe-range formula. Intuitively, a formula is safe-range if and only if its variables
are bounded by positive predicates or equalities (for full details see Appendix A.3). For
example, the formula A(x)  B(x) is safe-range, while queries A(x) and x. A(x) are
not. To check whether a formula is safe-range, the formula is transformed into a logically
equivalent safe-range normal form and its range restriction is computed according to a set
of syntax based rules; the range restriction of a formula is a subset of its free variables, and
if this coincides with the free variables then the formula is said to be safe-range (Abiteboul
et al., 1995). Similar to domain independence, a formula is ground safe-range if any grounding of this formula is safe-range. An ontology KB is safe-range (domain independent), if
every formula in KB is safe-range (domain independent).
The safe-range fragment of first-order logic with the standard name assumption is
equally expressive to the relational algebra, which is the core of SQL (Abiteboul et al.,
1995).

3. Determinacy
The certain answer to a query includes all the substitutions which make the query true in
all the models of the ontology embedding the database: so, if a substitution would make the
query true only in some model, then it would be discarded from the certain answer. In other
words, it may be the case that the answer to the query is not necessarily the same among
all the models of the ontology embedding the database. In this case, the query is not fully
determined by the given source data; indeed, there is some answer which is possible, but
not certain. Due to the indeterminacy of the query with respect to the data, the complexity
to compute the certain answer in general increases up to the complexity of entailment in
the logic. In this paper we focus on the case when a query has the same answer over all the
models of the ontology embedding the database, namely, when the information requested
by the query is fully available from the source data without ambiguity. In this way, the
indeterminacy disappears, and the complexity of the process may decrease (see section 4).
The determinacy of a query w.r.t. a source database (Nash et al., 2010; Marx, 2007; Fan
et al., 2012) has been called implicit definability of a formula (the query) from a set of
predicates (the database predicates) by Beth (1953).
Definition 4 (Finite Determinacy or Implicit Definability). A query Q[X] is (finitely)
determined by (or implicitly definable from) the database predicates PDB under KB iff for
any two models I and J of the ontology KBboth with a finite interpretation to the
database predicates PDB whenever I|PDB C = J |PDB C then for every substitution
 : X 7 I we have: I,  |= Q[X] iff J ,  |= Q[X] .
Intuitively, the answer of an implicitly definable query does not depend on the interpretation of non-database predicates. Once the database and a domain are fixed, it is never
890

fiExact Query Reformulation over DBs with FO and DL Ontologies

the case that a substitution would make the query true in some model of the ontology
and false in others, since the truth value of an implicitly defined query depends only on
the interpretation of the database predicates and constants and on the domain (which are
fixed). In practice, by focussing on finite determinacy of queries we guarantee that the user
can always interpret the answers as being not only certain, but also exactnamely that
whatever is not in the answer can never be part of the answer in any possible world.
In the following we focus on ontologies and queries in those fragments of FOL(C, P) for
which determinacy under models with a finite interpretation of database predicates (finite
determinacy) and determinacy under models with an unrestricted interpretation of database
predicates (unrestricted determinacy) coincide. We say that these fragments have finitely
controllable determinacy: we require that whenever a query is finitely determined then it is
also determined in unrestricted models (the reverse is trivially true). Indeed, the results in
this paper would fail if finite determinacy and unrestricted determinacy do not coincide: it
can be shown (Gurevich, 1984) that Theorem 1 below fails if we consider only models with
a finite interpretation of database predicates.
Example 1 (Example from database theory). Let P = {P, R, A}, PDB = {P, R},
KB = {x, y, z. R(x, y)  R(x, z)  y = z,
x, y. R(x, y)  z. R(z, x),
(x, y. R(x, y)  z. R(y, z))  (x. A(x)  P (x))}.
The formula x, y. R(x, y)  z. R(y, z) is entailed from the first two formulas only over
finite interpretations of R. The query Q = A(x) is finitely determined by P (it is equivalent
to P (x) under the models with a finite interpretation of R), but it is not determined by any
database predicate under models with an unrestricted interpretation of R. This knowledge
base does not enjoy finitely controllable determinacy.
The exact reformulation of a query (Nash et al., 2010) (also called explicit definition by
Beth, 1953) is a formula logically equivalent to the query which makes use only of database
predicates and constants.
Definition 5 (Exact Reformulation or Explicit Definability). A query Q[X] is explicitly definable from the database predicates PDB under the ontology KB iff there is some
b[X] in FOL(C, P), such that KB |= X.Q[X]  Q
b[X] and (Q)
b  PDB . We call
formula Q
b[X] an exact reformulation of Q[X] under KB over PDB .
this formula Q
Determinacy of a query is completely characterised by the existence of an exact reformulation of the query: it is well known that a first-order query is determined by database
predicates if and only if there exists a first-order exact reformulation.
Theorem 1 (Projective Beth definability, Beth, 1953). A query Q is implicitly definable from the database predicates PDB under an ontology KB, iff it is explicitly definable as
b in FOL(C, P) over PDB under KB.
a formula Q
e the formula obtained from it by uniformly replacing
Let Q be any formula in L and Q
every occurrence of each non-database predicate P with a new predicate Pe. We extend this
renaming operator e to any set of formulas in a natural way. One can check whether a query
is implicitly definable by using the following theorem.
Theorem 2 (Testing Determinacy, Beth, 1953). A query Q[X] is implicitly definable
g |= X.Q[X]  Q
e[X] .
from the database predicates PDB under the ontology KB iff KB  KB

891

fiFranconi, Kerhet, & Ngo

4. Exact Safe-Range Query Reformulation
In this section we analyse the conditions under which the original query answering problem
corresponding to an entailment problem can be reduced systematically to a model checking
problem of a safe-range formula over the database (e.g., using a database system with
SQL). Given a database signature PDB , an ontology KB, and a query Q[X] expressed in L
and determined by the database predicates, our goal is to find a safe-range reformulation
b[X] of Q[X] in FOL(C, P), that when evaluated as a relational algebra expression over a
Q
legal database instance, gives the same answer as the certain answer of Q[X] to the database
under KB. This can be reformulated as the following problem:
Problem 1 (Exact safe-range Query Reformulation). Find an exact reformulation
b[X] of Q[X] under KB as a safe-range query in FOL(C, P) over PDB .
Q
Since an exact reformulation is equivalent under the ontology to the original query, the
certain answer of the original query and of the reformulated query are identical. More
precisely, the following proposition holds.
Proposition 2. Given a database DB, let Q[X] be implicitly definable from PDB under KB
b[X] be an exact reformulation of Q[X] under KB over PDB , then:
and let Q
{ | dom() = X, rng()  C,  I  M (KB)  E(DB) : I |= Q[X/] } =
b[X/] }.
{ | dom() = X, rng()  C,  I  M (KB)  E(DB) : I |= Q
From the above equation it is clear that in order to answer an exactly reformulated query,
one may still need to consider all the models of the ontology embedding the database, i.e.,
we still have an entailment problem to solve. The following theorem states the condition
to reduce the original query answering problembased on entailmentto the problem of
checking the validity of the exact reformulation over a single model: the condition is that
the reformulation should be domain independent. Indeed there is only one interpretation
(with a particular domain) embedding the database with the signature restricted to the
database predicates.
Theorem 3 (Adequacy of Exact safe-range Query Reformulation). Let DB be
b[X] is an exact domain
a database which is legal for KB, and let Q[X] be a query. If Q
independent (or safe-range) reformulation of Q[X] under KB over PDB , then:
{ | dom() = X, rng()  C,  I  M (KB)  E(DB) : I |= Q[X/] } =
b DB), I = hC, I i  E(DB) : I|P
{ | dom() = X, rng()  adom((Q),

DB C

b[X/] }.
|= Q

A safe-range reformulation is necessary to transform a first-order query to a relational
algebra query which can then be evaluated by using SQL techniques. The theorem above
shows in addition that being safe-range is also a sufficient property for an exact reformulation to be correctly evaluated as an SQL query. Let us now see an example in which we
cannot reduce the problem of answering an exact reformulation to model checking over a
database, if the exact reformulation is not safe-range.
Example 2. Let P = {P, A}, PDB = {P }, C = {a},
DB = {P (a, a)}, KB = {y. P (a, y)  A(y)},
b[X] = y. P (x, y) (i.e., X = {x}).
Q[X] = Q
892

fiExact Query Reformulation over DBs with FO and DL Ontologies

 C includes the active domain CDB (it is actually equal).
 DB is legal for KB because there is I = h{a}, I i such that P I = {(a, a)}, AI = 
and obviously, I  M (KB).
 { | dom() = X, rng()  C,  I  M (KB)  E(DB) : I |= Q[X/] } =  because
one can take I = h{a, b}, I i such that P I = {(a, a)}, AI = {b}; then I  M (KB) 
E(DB), but for the only possible substitution {x  a} we have: I 6|= y P (a, y).
 However,
b DB), I = hC, I i  E(DB) : I|P C |= Q
b[X/] } =
{ | dom() = X, rng()  adom((Q),
DB

{x  a}
As we have seen, answers to a query for which a reformulation exists will contain only
constants from the active domain of the database and the query; therefore, ground statements in the ontology involving non-database predicates and non-active domain constants
(for example, as ABox statements) will not play any role in the final evaluation of the
reformulated query over the database.

5. Conditions for an Exact Safe-Range Reformulation
We have just seen the importance of getting an exact safe-range query reformulation. In
this section we are going to study the conditions under which an exact safe-range query
reformulation exists.
First of all, we will focus on the semantic notion of safe-range namely domain independence. While implicit definability isas we already knowa sufficient condition for the
existence of an exact reformulation, it does not guarantee alone the existence of a domain
independent reformulation.
Example 3. Let P = {A, B}, PDB = {A}, KB = {x.B(x)  A(x)}, Q = B(x).
Then Q is implicitly definable from PDB under KB, and every exact reformulation of Q over
PDB under KB is logically equivalent to A(x) and not domain independent.
By looking at the example, it seems that the reason for the non domain independent
reformulation lies in the fact that the ontology, which is domain independent, cannot guarantee existence of an exact domain independent reformulation of the non domain independent
query. However, let us consider the following example:
Example 4. Let PDB = {A, C}, KB = {A(a),
y B(y)  C(x). It is easy to see that KB is
is implicitly definable from PDB under KB, and
independent reformulation of Q.

x. A(x)  B(x)} and let a query Q =
domain independent and Q is not. Q
b = A(a)  C(x) is an exact domain
Q

It is obvious that in spite of the fact that the query Q is not domain independent, it
is domain independent with respect to the ontology KB. In other words, in this case the
ontology guarantees the existence of an exact domain independent reformulation.
With queries that are domain independent with respect to an ontology, the following
theorem holds, giving the semantic requirements for the existence of an exact domain
independent reformulation.
893

fiFranconi, Kerhet, & Ngo

Theorem 4 (Semantic Characterisation). Given a set of database predicates PDB , a
domain independent ontology KB, and a query Q[X] , a domain independent exact reformub[X] of Q[X] over PDB under KB exists if and only if Q[X] is implicitly definable from
lation Q
PDB under KB and it is domain independent with respect to KB.
The above theorem shows us the semantic conditions to have an exact domain independent reformulation of a query, but it does not give us a method to compute such reformulation and its equivalent safe-range form. The following theorem gives us sufficient
conditions for the existence of an exact safe-range reformulation in any decidable fragment of
FOL(C, P) where finite and unrestricted determinacy coincide, and gives us a constructive
way to compute it, if it exists.
Theorem 5 (Constructive). If:
g |= X. Q[X]  Q
e[X] (that is, Q[X] is implicitly definable),
1. KB  KB
2. Q[X] is safe-range (that is, Q[X] is domain independent),
3. KB is safe-range (that is, KB is domain independent),
b[X] of Q[X] as a safe-range query in FOL(C, P)
then there exists an exact reformulation Q
over PDB under KB, that can be obtained constructively.
In order to constructively compute the exact safe-range query reformulation we use the
b[X] from a
tableau based method to find the Craigs interpolant (Fitting, 1996) to compute Q
gQ
e[X] ). See Section 6 for full details.
validity proof of the implication (KB  Q[X] )  (KB
Let us now consider a fully worked out example, adapted from the paper by Nash et al.
(2010).
Example 5. Given: P = {R, V1 , V2 , V3 , A}, PDB = {V1 , V2 , V3 , Adom} where Adom is the
active domain of DB,
KB = { x, y. V1 (x, y)  z, v. R(z, x)  R(z, v)  R(v, y),
x, y. V2 (x, y)  z. R(x, z)  R(z, y),
x, y. V3 (x, y)  z, v. R(x, z)  R(z, v)  R(v, y),
Q(x, y) = z, v, u. R(z, x)  R(z, v)  R(v, u)  R(u, y)}.
The conditions of the theorem are satisfied: Q(x, y) is implicitly definable from PDB under
KB; Q(x, y) is safe-range; KB is safe-range.
b y)
Therefore, with the tableau method one finds the Craigs interpolant to compute Q(x,
g
e
b
from a validity proof of the implication (KB  Q[X] )  (KB  Q[X] ) and obtain Q(x, y) =
z. V1 (x, z)  v. (V2 (v, z)  V3 (v, y))an exact ground safe-range reformulation. Since
b y)  Adom(x) 
the answer of Q is in the active domain, we also have KB |= Q(x,
b
Adom(y). Then KB |= Q(x, y)  Q(x, y)  Adom(x)  Adom(y). Therefore, z. V1 (x, z) 
v. (V2 (v, z)  V3 (v, y))Adom(x)Adom(y) is an exact safe-range reformulation of Q(x, y)
from PDB under KB.
894

fiExact Query Reformulation over DBs with FO and DL Ontologies

6. Constructing the Safe-Range Reformulation
In this section we introduce a method to compute a safe-range reformulation of an implicitly
definable query when conditions in theorem 5 are satisfied. The method is based on the
notion of interpolant introduced by Craig (1957).
Definition 6 (Interpolant). The sentence  is an interpolant for the sentence   
in FOL(C, P), if all predicate and constant symbols of  are in the set of predicate and
constant symbols of both  and , and both    and    are valid sentences in
FOL(C, P).
Theorem 6 (Craigs interpolation). If    is a valid sentence in FOL(C, P), and
neither  nor  are valid, then there exists an interpolant.
Note, that the Beth definability (Theorem 1) and Craigs interpolation theorem do not
hold for all fragments of FOL(C, P): an interpolant may not always be expressed in the
fragment itself, but obviously it is in FOL(C, P) (because of Theorem 6).
An interpolant is used to find an exact reformulation of a given implicitly definable
query as follows.
Theorem 7 (Interpolant as definition). Let Q[X] be a query with n  0 free variables
implicitly definable from the database predicates PDB under the ontology KB. Then, the
closed formula with c1 , ..., cn distinct constant symbols in C not appearing in KB or Q[X] :
^
^
g Q
e[X/c ,...,c ] )
(( KB)  Q[X/c1 ,...,cn ] )  (( KB)
(1)
n
1
b[c ,...,c /X] is an exact reformulation of Q[X] under KB over
is valid, and its interpolant Q
n
1
PDB .
Therefore, to find an exact reformulation of an implicitly definable query in terms of
database predicates it is enough to find an interpolant of the implication (1) and then to
substitute all the constants c1 , . . . , cn back with the free variables X of the original query.
An interpolant can be constructed from a validity proof of (1) by using automated theorem
proving techniques such as tableau or resolution. In order to guarantee the safe-range
property of the reformulation, we use a tableau method as in the book by Fitting (1996).
6.1 Tableau-based Method to Compute an Interpolant
In this section we recall in our context the tableau based method to compute an interpolant (Fitting, 1996).
Assume    is valid, therefore    is unsatisfiable. Then there is a closed tableau
corresponding to   . In order to compute an interpolant from this tableau one needs
to modify it to a biased tableau.
Definition 7 (Biased tableau). A biased tableau for formulas    is a tree T = (V, E)
where:
 V is a set of nodes, each node is labelled by a set of biased formulas. A biased formula
is an expression in the form of L() or R() where  is a formula. For each node n,
S(n) denotes the set of biased formulas labelling n.
895

fiFranconi, Kerhet, & Ngo

 The root of the tree is labelled by {L(), R()}
 E is a set of edges. Given 2 nodes n1 and n2 , (n1 , n2 )  E iff there is a biased
completion rule from n1 to n2 . We say there is a biased completion rule from n1 to
n2 if
 Y () is the result of applying a rule to X(), where X and Y refer to L or R
(for some rules, there are two possibilities of choosing Y ()), and
 S(n2 ) = (S(n1 ) \ {X()})  {Y ()}.
Let C be the set of all constants in the input formulas of the tableau. C par extends C
with an infinite set of new constants. A constant is new if it does not occur anywhere in
the tableau. With these notations, we have the following rules :
 Propositional rules
X()
X()

Negation rules
X(>)
X()

rule
X(1  2 )

X()
X(>)

X(1 )
X(2 )

rule
X((1  2 ))
X(1 ) | X(2 )

 First order rules
rule
X(x.)

rule
X(x.)

X((t))
for any t  C par

X((c))
for a new constant c

 Equality rules
reflexivity rule

replacement rule
X(t = u)
Y ((t))

X()
t

X(t = t)
occurs in 

Y ((u))

C par

A node in the tableau is closed if it contains X() and Y (). If a node is closed, no
rule is applied. In the other words, it becomes a leaf of the tree. A branch is closed if it
contains a closed node and a tableau is closed if all of its branches are closed. Obviously, if
the standard tableau for FOL is closed then so is the biased tableau and vice versa.
Given a closed biased tableau, the interpolant is computed by applying interpolant rules.
int
An interpolant rule is written as S  I, where I is a formula and
S = {L(1 ), L(2 ), ..., L(n ), R(1 ), R(2 ), ..., R(m )}.
 Rules for closed branches
int

int

r1. S  {L(), L()}  

r2. S  {R(), R()}  >

int

int

r3. S  {L()}  

r4. S  {R()}  >
int

int

r5. S  {L(), R()}  

r6. S  {R(), L()}  
896

fiExact Query Reformulation over DBs with FO and DL Ontologies

 Rules for propositional cases
int
S  {X()}  I
p1.

p4.

p6.

int

p2.

int

S  {X()}  I
int
S  {X(1 ), X(2 )}  I

S  {X(>)}  I
int

int

p3.

S  {X()}  I
int

S  {X()}  I
S  {X(>)}  I
int
int
S  {L(1 )}  I1 S  {L(2 )}  I2
p5.

int

int

S  {X(1  2 )}  I
S  {L((1  2 ))}  I1  I2
int
int
S  {R(1 )}  I1 S  {R(2 )}  I2
int

S  {R((1  2 ))}  I1  I2
 Rules for first order cases :
int
S  {X((p))}  I
f1.

f2.

f3.

f4.

f5.

where p is a parameter that does not occur in S or 

int

S  {X(x.(x))}  I
int
S  {L((c))}  I
int

if c occurs in {1 , ..., n }

S  {L(x.(x))}  I
int
S  {R((c))}  I
int

if c occurs in {1 , ..., m }

S  {R(x.(x))}  I
int
S  {L((c))}  I
int

S  {L(x.(x))}  x.I[c/x]
int
S  {R((c))}  I
int

if c does not occur in {1 , ..., n }
if c does not occur in {1 , ..., m }

S  {R(x.(x))}  x.I[c/x]
 Rules for equality cases
int
S  {X((p)), X(t = t)}  I
e1.

e3.

int

int

e2.

S  {X((p))}  I
int
S  {L((u)), R(t = u)}  I
int

S  {X((u)), X(t = u)}  I
int

S  {X((t)), X(t = u)}  I
if u occurs in (t), 1 , ..., m

S  {L((t)), R(t = u)}  t = u  I
int
S  {R((u)), L(t = u)}  I

if u occurs in (t), 1 , ..., m
int
S  {R((t)), L(t = u)}  t = u  I
int
S  {L((u)), R(t = u)}  I
e5.
if u does not occur in (t), 1 , ..., m
int
S  {L((t)), R(t = u)}  I[u/t]
int
S  {R((u)), L(t = u)}  I
e6.
if u does not occur in (t), 1 , ..., m
int
S  {R((t)), L(t = u)}  I[u/t]
e4.

In summary, in order to compute an interpolant of  and , one first need to generate
a biased tableaux proof of unsatisfiability of    using biased completion rules and then
apply interpolant rules from bottom leaves up to the root.
Let us consider an example to demonstrate how the method works.
Example 6. Let P = {S, G, U }, PDB = {S, U },
897

fiFranconi, Kerhet, & Ngo

KB = { x(S(x)  (G(x)  U (x)))
x(G(x)  S(x))
x(U (x)  S(x))
x(G(x)  U (x))}
Q(x) = G(x)
Obviously, Q is implicitly definable from S and U , since the ontology states that G and
U partition S. Now we will follow the tableau method to find its exact reformulation. For
int
compactness, we use the notation S I instead of S  I.
S0 = {L(x(S(x)  (G(x)  U (x)))),
L(x(G(x)  S(x))),
L(x(U (x)  S(x))),
L(x(G(x)  U (x))),
L(G(c)),
R(x(S(x)  (G1 (x)  U (x)))),
R(x(G1 (x)  S(x))),
R(x(U (x)  S(x))),
R(x(G1 (x)  U (x))),
R(G1 (c))}
By applying the rule for  and removing the implication, we have:
S1 = {L(S(c)  G(c)  U (c)),
L(G(c)  S(c))),
L(U (c)  S(c)),
L(G(c)  U (c)),
L(G(c)),
R(S(c)  G1 (c)  U (c)),
R(G1 (c)  S(c)),
R(U (c)  S(c)),
R(G1 (c)  U (c)),
R(G1 (c))}
and the interpolant of S1 can be computed as follows:
S4  {R(S(c)}S(c)

S4  {R(U (c))}U (c)

S4 = S3  {R(S(c)  U (c))}(S(c)U (c))



S3  {R(G1 (c))}>

(S(c)U (c))

B.7

S2  {L(G(c))}

S3 = S2  {L(U (c))}

(S(c)U (c))

S2 = S1  {L(S(c))}

(S(c)U (c))

B.5

S1  {L(G(c))}

B.3

S1

b
Therefore, S(c)U (c) is the interpolant and Q(x)
= S(x)U (x) is an exact reformulation
of Q(x).
898

fiExact Query Reformulation over DBs with FO and DL Ontologies

Algorithm 1 Safe-range Reformulation
Input: a safe-range KB, a safe-range and implicitly definable query Q[X] .
Output: an exact safe-range reformulation.
b[X] as in Theorem 7
1: Compute the interpolant Q
b[X] do
2: For each free variable x which is not bounded by any positive predicate in Q
b[X] := Q
b[X]  Adom b (x)
Q
Q
b[X]
3: Return Q

6.2 A Safe-Range Reformulation
Now we want to show that the reformulation computed by the above tableau based method
under the condition of Theorem 5 generates a ground safe-range query.
Theorem 8 (Ground safe-range Reformulation). Let KB be an ontology, and let Q be
a query which is implicitly definable from PDB . If KB and Q are safe-range then a rewritten
b obtained using the tableau method described in Section 6.1 is ground safe-range.
query Q
In other words, the conditions of Theorem 8 guarantee that all quantified variables in the
reformulation are range-restricted. We need to consider now the still unsafe free variables.
The theorem below will help us deal with non-range-restricted free variables. Let us first
define the active domain predicate of a query Q as the safe-range formula:
Adom Q (x) :=
 W
W
P PQ z1 , . . . , zar(P )1 . P (x, z1 , . . . , zar(P )1 )  . . .  P (z1 , . . . , zar(P )1 , x) 
cCQ (x = c).

Theorem 9 (Range of the query). Let KB be a domain independent ontology, and let
Q[x1 ,...,xn ] be a query which is domain independent with respect to KB. Then
KB |= x1 , . . . , xn . Q[x1 ,...,xn ]  Adom Q (x1 )  . . .  Adom Q (xn ).
Given a safe-range ontology, a safe-range and implicitly definable query is obviously
domain independent with respect to the ontology. In this case, Theorem 9 says that the
answer of the reformulation can only include active domain elements. Therefore, the active
domain predicate can be used as a guard for free variables which are not bounded by any
positive predicate.
Based on Theorem 8 and Theorem 9, we propose a complete procedure to construct a
safe-range reformulation in Algorithm 1.

7. The Guarded Negation Fragment of ALCHOIQ
ALCHOIQ is an extension of the description logic ALC with role hierarchies, individuals,
inverse roles, and qualified cardinality restrictions: it corresponds to the SHOIQ description logic without transitive roles; it is the logic at the basis of OWL. The syntax and
semantics of ALCHOIQ concept expressions is summarised in the Figure 1, where A is an
atomic concept, C and D are concepts, o is an individual name, P is an atomic role, and
R is either P or P  . The forall and the qualified and unqualified atmost operators can be
derived by using negation and the atleast operator in the usual way. A TBox in ALCHOIQ
899

fiFranconi, Kerhet, & Ngo

Syntax
A
{o}
P
P
C
C uD
C tD
 nR
 nR.C

Semantics
AI  I
{oI }  I
P I  I  I
{(y, x)|(x, y)  P I }
I \C I
C I  DI
C I  DI
{x|#({y|(x, y)  RI })  n}
{x|#({y|(x, y)  RI }  C I )  n}

Figure 1: Syntax and semantics of ALCHOIQ concepts and roles
is a set of concept inclusion axioms C v D and role inclusion axioms R v S (where C, D
are concepts and R, S are roles) with the usual description logics semantics.
In this section, we present an application of Theorem 5, by introducing the ALCHOIQGN
description logic, the guarded negation syntactic fragment of ALCHOIQ (Figure 2) which
happens to express exactly the domain independent concepts and TBoxes of ALCHOIQ.
The language restricts ALCHOIQ by just prescribing that negated concepts should be
guarded by some generalised atom (an atomic concept, a nominal, an unqualified atleast
number restriction), i.e., absolute negation is forbidden. Similarly, the derived forall and
atmost operators would be guarded by using their standard definition as the dual of the
atleast operator, but with the guarded negation. ALCHOIQGN is actually at the intersection of the GNFO fragment (Barany, ten Cate, & Otto, 2012) and ALCHOIQ (see
Appendix A.5 for details on GNFO).
ALCHOIQGN has the very important property of coinciding with the domain independent fragment of ALCHOIQ, therefore providing an excellent candidate language for
ontologies and queries satisfying the conditions of Theorem 5.
Theorem 10 (Expressive power equivalence). The domain independent fragment of
ALCHOIQ and ALCHOIQGN are equally expressive.
In other words the theorem says that any domain independent TBox axiom and any
domain independent concept query in ALCHOIQ is logically equivalent, respectively, to a
TBox axiom and a concept query in ALCHOIQGN , and vice-versa. This theorem provides
the description logics version of Codds theorem. Codds theorem states that the safe-range
syntactic fragment of FOL and the domain-independent fragment of FOL are precisely
equivalent in expressive power; that is, a database query can be formulated in one language
if and only if it can be expressed in the other.
R
B
C

::=
::=
::=

P | P
A | {o} |  nR
B |  nR.C |  nR.C | B u C | C u D | C t D
Figure 2: Syntax of ALCHOIQGN concepts and roles
900

fiExact Query Reformulation over DBs with FO and DL Ontologies

7.1 Applying the Constructive Theorem
We want to reformulate concept queries over an ontology with a DBox so that the reformulated query can be evaluated as an SQL query over the database represented by the DBox.
In this context, the database is a DBox, the ontology is an ALCHOIQGN TBox, and the
query is an ALCHOIQGN concept query. A concept query is either an ALCHOIQGN
concept expression denoting an open formula with one free variable, or an ALCHOIQGN
ABox concept assertion denoting a boolean query. As expected, a DBox includes ground
atomic statements of the form A(a) and P (a, b) (where A is an atomic concept and P is an
atomic role). From Theorem 10 we can draw the following corollary.
Corollary 1. ALCHOIQGN TBoxes and concept queries are domain independent.
We can also prove the following theorem.
Theorem 11. ALCHOIQGN TBoxes with concept queries have finitely controllable determinacy.
Therefore, we satisfy the conditions of Theorem 5, with a language which is like the
very expressive ALCHOIQ description logic, but with guarded negation.
We argue that non-guarded negation should not appear in a cleanly designed ontology,
and, if present, should be fixed. Indeed, the use of absolute negative informationsuch as,
e.g., in a non-male is a female ( male v female)should be discouraged by a clean
design methodology, since the subsumer would include all sorts of objects in the universe
(but the ones of the subsumee type) without any obvious control. Only guarded negative
information in the subsumee should be allowedsuch as in the axiom a non-male person
is a female (person u  male v female).
This observation suggests a fix for non-guarded negations: for every non-guarded negation users will be asked to replace it by a guarded one, where the guard may be an arbitrary
atomic concept, or nominal, or non-qualified existential. Therefore, the user is asked to make
explicit the type of that concept, in a way to make it domain independent; note that the
type could be also a fresh new atomic concept. We believe that the fix we are proposing
for ALCHOIQ is a reasonable one, and would make all ALCHOIQ ontologies eligible to
be used with our framework.
7.2 A Complete Procedure
ALCHOIQGN is a decidable logic and it is a feasible application of our general framework.
Given an ALCHOIQGN ontology KB and a concept query Q, we can apply the procedure
below to generate a safe-range reformulation over the database concepts and roles (based
on the constructive theorem, all the conditions of which are satisfied), if it exists.
Input: An ALCHOIQGN TBox KB, a concept query Q in ALCHOIQGN , and a
database signature (database atomic concepts and roles).
g |= Q  Q
e using
1. Check the implicit definability of the query Q by testing if KB  KB
a standard OWL2 reasoner (ALCHOIQGN is a sublanguage of OWL2). Continue if
this holds.
901

fiFranconi, Kerhet, & Ngo

b from the tableau proof generated in step 1 (see
2. Compute a safe-range reformulation Q
Section 6). This can be implemented as a simple extension of a standard DL reasoner
even in the presence of the most important optimisation techniques such as semantic
branching, absorption, and backjumping as explained by Seylan et al. (2009) and ten
Cate, Franconi, and Seylan (2011).
b expressed over the database signature.
Output: A safe-range reformulation Q
Note that the procedure for checking determinacy and computing the reformulation
could be run in offline mode at compile time. Indeed, it could be run for each atomic concept
in the ontology, and store persistently the outcome for each of them if the reformulation has
been successful. This pre-computation may be an expensive operation, sinceas we have
seenit is based on entailment, but the complexity involves only the size of the ontology
and not of the data.
In order to get an idea about the size of the reformulations, for the ALCF I description
logic there is a tableau-based algorithm computing explicit definitions of at most double
exponential size (ten Cate et al., 2011; ten Cate, Franconi, & Seylan, 2013); this algorithm is
optimal because it is also shown that the smallest explicit definition of an implicitly defined
concept may be double exponentially long in the size of the input TBox.
Clearly, similarly to DL-Lite reformulations, more research is needed in order to optimise
the reformulation step in order to make it practical. However, note that the framework
presented here has a clear advantage from the point of view of conceptual modelling since
implicit definitions (that is, queries) under general TBoxes can be double exponentially
more succinct than acyclic concept definitions (that is, explicit queries over the database).
There is also another interesting open problem about checking that a given database
is legal with respect to a given ontology. Remember that a database DB is legal for an
ontology KB if there exists a model of KB embedding DB. This check involves heavy
computations for which an optimised algorithm is still unknown: as a matter of fact, the
only known method today is to reduce the problem to a satisfiability problem where the
database is embedded in a TBox using nominals (Franconi et al., 2011). More research is
needed in order to optimise the reasoning with nominals in this special case.
Appendix A.5 contains all the definitions and theorems needed to prove theorems 10
and 11.

8. Conclusion
We have introduced a framework to compute the exact reformulation of first-order queries
to a database under ontologies. We have found the exact conditions which guarantee that
a safe-range reformulation exists, and we show that it can be evaluated as a relational
algebra query over the database to give the same answer as the original query under the
ontology. A non-trivial case study has been presented in the field of description logics, with
the ALCHOIQ language.
We have also implemented a tool based on the Prover9 theorem prover (McCune, 2011).
Given an arbitrary first-order ontology, a database signature, and an arbitrary first-order
query in TPTP syntax, the tool performs all the tests on them to check whether a reformulation can be computed, and it computes an optimal safe-range reformulation.
902

fiExact Query Reformulation over DBs with FO and DL Ontologies

This framework is useful in data exchange-like scenarios, where the target database
(made by determined relations) should be materialised as a proper database, over which
arbitrary queries should be performed. This is not achieved in a context with non-exact
rewritings preserving the certain answers. In our scenario with description logics ontologies,
rewritings of concept queries are pre-computed offline once. We have shown that our framework works in theory also in the case of arbitrary safe-range first-order queries, and our tool
shows that this is possible in practice. In the case of description logics, we are working on
extending the theoretical framework with conjunctive queries: we need finitely controllable
determinacy with conjunctive queries, which seems to follow for some description logic from
the works by Barany, Gottlob, and Otto (2010) and Rosati (2011).
In future work, we would like to study optimisations of reformulations. From the practical perspective, since there might be many rewritten queries from one original query, the
problem of selecting an optimised query in terms of query evaluation is very important. In
fact, one has to take into account which criteria should be used to optimise, such as: the
size of the rewritings, the numbers of used predicates, the priority of predicates, the number
of relational operators, and clever usage of duplicates. With the tool, we plan to evaluate
our proposed technique in a real context.
Concurrently, we are exploring the problem of fixing real ontologies in order to enforce
definability when it is known it should be the case (Franconi, Ngo, & Sherkhonov, 2012c).
This happens when it is intuitively obvious that the answer of a query can be found from
the available data (that is, the query is definable from the database), but the mediating
ontology does not entail the definability. We introduce the novel problem of definability
abduction and we solve it completely in the data exchange scenario.
We thank the anonymous reviewers for the very useful comments we got on earlier versions of this paper. We wish to thank Alex Borgida, Tommaso Di Noia, Umberto Straccia,
David Toman, and Grant Weddell for the fruitful discussions we had on the topics of this
paper.

Appendix A. Proofs
A.1 Proofs of Section 2
Proposition 1
Proof.

Let

Asna = { | dom() = X, rng()  C,  I  I(SNA)M (KB)E(DB) : I |= Q[X/] }
and
Auna = { | dom() = X, rng()  C,  I  I(UNA)M (KB)E(DB) : I |= Q[X/] }
Since SNA is stricter than UNA, i.e. I(SNA)  I(UNA), we have: Auna  Asna trivially.
Let   Asna . If  
/ Auna then there is an interpretation I = hI , I i embedding
DB and satisfying UNA such that I  M (KB) and I 6|= Q[X/] . Let us construct new


interpretation J = hJ , J i embedding DB as follows:


 J := (I \ {aI | a  C})  C;
903

fiFranconi, Kerhet, & Ngo



 for each constant a  C, aJ := a;


 for every predicate P  P, PJ is constructed from PI by replacing of each element
aI  PI , where a is some constant, with a.
Obviously, J satisfies SNA and J and I are isomorphic. Since first-order logic sentences cannot distinguish two isomorphic structures, J 6|= Q[X/] which contradicts with
the assumption   Asna . Therefore   Auna .
A.2 Proofs of Section 4
Proposition 2.
b[X] is an exact reformulation of Q[X] , KB |= X.Q[X]  Q
b[X] . Then, for any
Proof. Since Q
I
b[X] ,
model I  M (KB) and for any substitution  : X 7  we have: I,  |= Q[X]  Q
b[X] ).
which is equivalent to (I,  |= Q[X]  I,  |= Q
Now, let  be any substitution from { | dom() = X, rng() = C,  I  M (KB) 
E(DB) : I |= Q[X/] }, and I = h, I i be any model of the KB embedding the DB (if
there are any). Let  := I  a composition of the substitution  and the interpretation
function I (i.e. (x) = a   iff (x) = c  C and cI = a). Then I,  |= Q[X] 
b[X]  I |= Q
b
b
I |= Q[X/] and I,  |= Q
[X/] . Summing up: I |= Q[X/]  I |= Q[X/] .
b[X/] }. The
Hence,   { | dom() = X, rng() = C,  I  M (KB)  E(DB) : I |= Q
inverse inclusion can be proved similarly.
Theorem 3.
Proof. First of all recall that we assume SNA. In order to prove the theorem, one needs the
following two propositions.
Proposition 3 (Domain Independence). A query Q[X] is domain independent iff for
every two interpretations I = hI , I i and J = hJ , J i which agree on the interpretation
of the predicates from PQ (and all constants C), and for every substitution  : X 7 I J
we have:
rng()  I and I,  |= Q[X]
iff
rng()  J and J ,  |= Q[X] .
Proof. () Obviously, if the second part of the proposition holds, then the query is domain
independent.
() Suppose, the query is domain independent. Let I = hI , I i and J = hJ , J i
be any two interpretations, which agree on the interpretation of all the predicates from PQ
(and all constants C), that is I|PQ C = J |PQ C . Let us fix any substitution  : X 7 I J
(if the query is closed, we just omit everything, that concerns a substitution below in the
proof) such that:
rng()  I and I,  |= Q[X] .
(2)
904

fiExact Query Reformulation over DBs with FO and DL Ontologies

0

0

Let us consider interpretations I 0 = hI , I i and J 0 = hJ , J i, such that I|PQ C =
0
0
0
I 0 |PQ C

= J |PQ C = J |PQ C , and P  P \ PQ : P I =  = P J . Let us consider now I and
I 0 . They have the same domain and interpret all the predicates and constants, occurring
in Q[X] equally. Therefore, since I,  |= Q[X] (by (2)), I 0 ,  |= Q[X] .
Let us consider interpretations I 0 and J 0 . By construction, they agree on interpretation of all predicates and constants. Therefore, we can apply the definition of domain
independence to them. Then, since
rng()  I and I 0 ,  |= Q[X] ,

(3)

rng()  J and J 0 ,  |= Q[X] .

(4)

we have, that
Then again interpretations J and J 0 have the same domain and interpret all the predicates
and constants, occurring in Q[X] equally. Thus, because of (4),
rng()  J and J ,  |= Q[X] .

(5)

Therefore, (2) = (5). Similarly (5) = (2), and the proposition is proved.

Proposition 4. If Q[X] is domain independent, then for any interpretation I = h, I i
and any substitution  : X 7 , such that I,  |= Q[X] , the following holds:
rng()  adom((Q[X] ), I).
Proof. Assume, that X = {x}, that is Q has one free variable x (the proof can be easily
extended then to the general case).
Let us prove by contradiction. Suppose, there exists a substitution {x  b} such that
I, {x  b} |= Q(x) and b   \ adom((Q(x)), I). Let us consider interpretation I 0 =
h  {a}, I i, where a is any brand-new element, that does not appear in . Then I 0 , {x 
b} |= Q(x) because of domain independence of Q(x). Consider then another interpretation
00
I 00 = h  {a}, I i such that occurrence of b in interpretation of any predicate is replaced
with the element a. In other words, for any n-ary predicate P  P \ (Q(x)), (. . . , a, . . .) 
00
0
P I iff (. . . , b, . . .)  P I (since by supposition b does not appear in interpretations of
predicates in the query). Interpretations of all the other predicates and all the constants
are the same. Then I 00 satisfies SNA (even if b  C). Then, since I 0 , {x  b} |= Q[X] , by
construction of I 00 we have: I 00 , {x  a} |= Q(x), because we changed just interpretations
of predicates, that do not appear in the query. Then since I 0 and I 00 have the same domain
and agree on interpretations of all the predicates in Q(x) and all constants, the following
holds: I 0 , {x  a} |= Q(x).
Let us now consider interpretations I = h, I i and I 0 = h  {a}, I i. They have the
same interpretation function. Therefore, since Q(x) is domain independent and I 0 , {x 
a} |= Q(x), we have: rng({x  a})  . That is a  . It is a contradiction, because by
supposition a 6 .
905

fiFranconi, Kerhet, & Ngo

Now we prove the theorem itself.
L := { | dom() = X, rng()  C,  I  M (KB)  E(DB) : I |= Q[X/] };
b DB), I = hC, I i  E(DB) : I|P
R := { | dom() = X, rng()  adom((Q),

DB C

b[X/] }.
|= Q

b
Let   L. Then for any I  M (KB)  E(DB) we have: I |= Q[X/] and I |= Q
[X/] ,
because of Proposition 2.
Consider any J = hC, I i embedding DB. I and J agree on interpretations of C
b  P which is a subset of PDB .
(since we have SNA) and predicates from the set (Q)
b[X] is domain independent, by Proposition 3 we have: J |= Q
b
Then, since Q
[X/] . Since
b
b
b
(Q[X] )  PDB  C, J |P C |= Q
. Since Q[X] is domain independent, by Proposition
DB

[X/]

b[X] ), J ). adom((Q
b[X] ), J ) = adom((Q
b[X] ), DB), because
4 we have: rng()  adom((Q
b[X] )  PDB  C. Therefore, rng()  adom((Q
b[X] ), DB). Then
we assume SNA and (Q
  R and, hence, L  R.
b[X] ), DB)). Then for any J = hC, I i embedding DB we
Let   R (rng()  adom((Q
b
b
have: J |PDB C |= Q
[X/] . Then J |= Q[X/] . Consider any I  M (KB)  E(DB). Then J
b
and I agree on interpretations of C (since we have SNA) and PDB . Since (Q
)  PDB C
[X/]

b[X] is domain independent, by Proposition 3 we have: I |= Q
b
b
and Q
[X/] . Since Q[X] is exact
reformulation of Q[X] under KB over PDB , by Proposition 2 we have: I |= Q[X/] . Then
  L and, hence, R  L.
Theorem 3 is proved completely.
A.3 Definitions and Proofs of Section 5
Proposition 5. Let KB be a domain independent ontology. If interpretation I = hI , I i
is a model of KB, then any J = hJ , J i, such that I = J , is also a model of KB.
Proof. Let  be any sentence from KB. Then, since I is a model of KB, I |= .  is domain
independent, because KB is domain independent. Hence, since I = J , J |= . Thus, J is
a model of any sentence from KB. It means, that J is a model of KB.

Proposition 6. Let KB be an ontology, and let Q[X] be a query which is domain independent
with respect to KB. Any exact reformulation of Q[X] under KB (over any set of predicates)
is also domain independent with respect to KB.
b[X] be any exact reformulation of Q[X] under KB (over some set of predicates),
Proof. Let Q
I
I
I = h ,  i and J = hJ , J i be any two models of KB such that I = J , and
 : X 7 I  J be any substitution such that
b[X] .
rng()  I and I,  |= Q
b
Then, since Q[X] is exact reformulation of Q[X] , we have: I,  |= Q[X] . Then, since Q[X]
is domain independent with respect to KB, we have:
rng()  J and J ,  |= Q[X] .
b[X] is exact reformulation of Q[X] , we have: J ,  |= Q
b[X] . Thus, Q
b[X]
And again, since Q
is domain independent with respect to KB by definition.

906

fiExact Query Reformulation over DBs with FO and DL Ontologies

Lemma 1. Let KB be a domain independent ontology, and let Q[X] be a query which is
domain independent with respect to KB. Then for any I = h, I i which is a model of KB
and any substitution  : X 7  such that I,  |= Q[X] the following holds:
rng()  adom((Q[X] ), I).
Proof. Without loss of generality assume, that X = {x}, that is Q has one free variable x
(the proof can be easily extended then to the general case).
Let us prove by contradiction. Suppose that I, {x  b} |= Q(x), where b   \
adom((Q[X] ), I). Since KB is domain independent, for any brand-new element a, that
does not appear in , interpretation I = h  {a}, I i is also a model of KB by Proposition
5. Then, since Q(x) is domain independent with respect to KB and I and I have the same
interpretation function, I, {x  b} |= Q(x).
1
Consider a new interpretation I 1 = h  {a}, I i constructed from I such that occurrence of b in interpretation of any predicate is replaced by element a. In other words, for
1
any n-ary predicate P  P \ PQ , (. . . , a, . . .)  P I iff (. . . , b, . . .)  P I (since by supposition
b does not appear in interpretations of predicates in the query).
Then, since I, {x  b} |= Q(x) and by construction of I 1 we have: I 1 , {x  a} |= Q(x)
(since we simply replace b, that does not appear neither as a constant in Q(x) nor in
interpretations of predicates in Q(x), with a). Then, since I and I 1 have the same domain
  {a} and agree on interpretations of all the predicates from Q(x) and all the constants
(since we assume SNA), we have: I, {x  a} |= Q(x).
Let us now consider interpretations I = h, I i and I = h  {a}, I i. They are both
models of KB and have the same interpretation function I . So, since Q(x) is domain
independent with respect to KB and I, {x  a} |= Q(x), we have: a   and I, {x 
a} |= Q(x) by definition of domain independence with respect to an ontology. It is a
contradiction, because by supposition a 6 . The lemma is proved.
Let  be any set of formulas. Then Adom  is defined similarly to Adom Q , where Q is
a query.
Lemma 2. Let KB be a domain independent ontology, and let Q[X] (X = {x1 , ..., xn }) be a
query which is domain independent with respect to KB. Then the following holds:
KB |= X.Q[X]  Q[X] |Adom KBQ
where Q[X] |Adom KBQ is Q0 [X]  Adom KBQ (x1 )  ...  Adom KBQ (xn ), and Q0 [X] is Q[X]
such that:
 Every sub-formula of Q[X] in the form of x.(x) is replaced by x.(x)Adom KBQ (x)
 Every sub-formula of Q[X] in the form of x.(x) is replaced by x.Adom KBQ (x) 
(x)
Proof. Without loss of generality, we will prove the lemma when n = 1. In this case, we
write Q(x) instead of Q[X] . We prove by contradiction.
Assume there is a model I = hI , I i of KB and an element a  I such that I, {x 
a} |= Q(x) but I, {x  a} 6|= Q(x)|Adom KBQ .
907

fiFranconi, Kerhet, & Ngo

We construct a new interpretation J = hAdom IKBQ  C, J i such that for any predicate
P  PKBQ , P J := P I , and for any predicate P  P \ PKBQ , P J := .
Since KB is domain independent, J is also a model of KB by Proposition 5. Then,
J , {x  a} |= Q(x) because Q is domain independent with respect to KB. As a consequence, however, J , {x  a} |= Q(x)|Adom KBQ by the definition of Q(x)|Adom KBQ .
Q(x)|Adom KBQ is safe-range by construction (see Definition 10). Hence, it is domain
independent. Therefore I, {x  a} |= Q(x)|Adom KBQ . Contradiction.
Assume there is a model I = hI , I i of KB and an element a  I such that I, {x 
a} |= Q(x)|Adom KBQ but I, {x  a} 6|= Q(x). One can lead to a contradiction similarly
as above. Therefore, the lemma is proved.
Theorem 4.
Proof. The theorem can be proved after Theorem 5.
 The if direction. Based on Lemma 2, one can see that exact reformulations of Q[X]
are also exact reformulations of Q[X] |Adom KBQ . Since Q[X] |Adom KBQ is safe-range
and KB can always be transformed to a logically equivalent safe-range ontology KB 0 ,
b[X] found in Theorem 5 which takes
obviously the exact safe-range reformulation Q
0
KB and Q[X] |Adom KBQ as its input is the exact domain independent reformulation
of Q[X] .
 The only if direction.
b[X] of Q[X]
Suppose, that there exists an exact domain independent reformulation Q
over PDB under KB. Then it is domain independent with respect to KB. Hence, by
Proposition 6, Q[X] is domain independent with respect to KB. Since there exists an
exact reformulation of Q[X] , Q[X] is implicitly definable from PDB under KB by the
Theorem 1.
The theorem is proved completely.
In order to help readers follow easier, we recall here formal definitions of safe-range and
safe-range normal form (Abiteboul et al., 1995).
Definition 8 (safe-range normal form). denoted by SRNF
A first order formula can be transformed to SRNF by following steps :
 Variable substitution: no distinct pair of quantifiers may employ same variable.
 Remove universal quantifiers
 Remove implications
 Push negation
 Flatten and/or
908

fiExact Query Reformulation over DBs with FO and DL Ontologies

Definition 9 (Range restriction of a formula). denoted by rr
Input : a formula  in SRNF
Output : a subset of free() or 
Case  of
 R(e1 , ..., en ) : rr() = set of variables in e1 , ..., en
 x = a or a = x, where a is a constant : rr() = {x}
 x = y : rr() = 
 1  2 : rr() = rr(1 )  rr(2 )
 1  2 : rr() = rr(1 )  rr(2 )
 1  x = y : rr() = rr(1 ) if {x, y}  rr(1 ) = ; rr() = rr(1 )  {x, y} otherwise
 1 : rr() =   rr(1 )
 x1 : rr() = rr(1 )\{x} if x  rr(1 ); rr() =  otherwise
Note :   Z =   Z = \Z = Z\ = 
Definition 10 (safe-range). A formula  is safe-range iff rr(SRNF()) = free().
Definition 11 (ground safe-range). A formula  is ground safe-range iff after substitution of free variables of  with constants it becomes safe-range.
Observation 1.
1. For any query Q[X] and any interpretation I = h, I i the following holds:
Adom IQ = adom((Q[X] ), I).
2. Adom Q (x) is safe-range.
Theorem 5.
Proof. The theorem can be proved after Theorem 8 and Theorem 9.
We will use the following lemma in the proof.
Lemma 3. If KB is an ontology, Q[X] (X = {x1 , . . . , xn }) is ground safe-range query and
KB |= X. Q[X]  1 (x1 )  . . .  n (xn ),

(6)

b[X] := Q[X] 1 (x1 ). . .n (xn )
where 1 , . . . , n are n safe-range formulas, then the query Q
b
is safe-range and KB |= X. Q[X]  Q[X] .
909

fiFranconi, Kerhet, & Ngo

Proof. Let Q0[X] be a safe-range normal form of the query Q[X] , i.e. Q0[X] := SRNF(Q[X] ) =
Y. [XY] , where [XY] is in conjunctive normal form (the safe-range normal form of the
query is in prenex normal form). Then Q0[X] is ground safe-range, and KB |= Q0[X]  Q[X] .
Hence, KB |= X. Q0[X]  1 (x1 )  . . .  n (xn ). Let Q00[X] := Q0[X]  10 (x1 )  . . .  n0 (xn ),
where each i0 (xi ) = SRNF(i (xi )). Then by 6, KB |= Q0[X]  Q00[X] . On the other hand
b[X]  Q00 by construction. Summing up everything, we have: KB |= Q
b[X] 
KB |= X. Q
[X]

b[X] is safe-range.
Q[X] and the only thing we need to prove is that Q
00
0
One can see, that Q[X]  Y. ([XY] 1 (x1 ). . .n0 (xn )) which is a safe-range normal
b[X] . Since Q0 = Y. [XY] is ground safe-range, then rr([XY] ) \ X = Y0  Y,
form of Q
[X]

where for any y  Y\Y0 there exists a conjunct x = y in [XY] , for some x  X. Then, since
each i0 (xi ) is safe-range, by definition of range restriction rr([XY] 10 (x1 ). . .n0 (xn )) =
X  Y, and then rr(Y. ([XY]  10 (x1 )  . . .  n0 (xn ))) = X = free(Q00[X] ). Therefore,
b[X] is safeY. ([XY]  10 (x1 )  . . .  n0 (xn )) is safe-range by definition, and hence Q
range.
Let us continue to prove the theorem.
b by using
If X = , (Q is closed) then we build an exact safe-range reformulation Q
Theorem 8.
Suppose now, X = {x1 , . . . , xn }. Since Q[X] is safe-range and implicitly definable from
PDB , we apply Theorem 8 for Q[X] and construct a ground safe-range rewriting Q0[X] expressed over PDB such that KB |= X. Q[X]  Q0[X] . Since Q[X] is domain independent
(since it is safe-range), it is also domain independent with respect to KB. Hence, by Proposition 6, Q0[X] is also domain independent with respect to KB. Moreover, KB is safe-range
and, hence, domain independent. Then by Theorem 9:
KB |= X. Q0[X]  Adom Q (x1 )  . . .  Adom Q (xn ).
By the second item of Observation 1 Adom Q (x) is a safe-range formula. Then by Lemma 3
b[X] := Q0  Adom Q0 (x1 )  . . .  Adom Q0 (xn ) is safe-range and KB |= X. Q0 
the query Q
[X]
[X]
b[X] . Since KB |= X. Q[X]  Q0 , we have: KB |= X. Q[X]  Q
b[X] . Therefore, the
Q
[X]

b[X] is the one we were looking for.
constructed query Q
Theorem 5 is proved completely.
A.4 Proofs of Section 6
Theorem 7.
Proof. First we will prove that if Q is implicitly definable then the formula (1) is valid.
g |= X.Q[X]  Q
g
Applying syntactic definition of implicit definability: KB  KB
[X] . Therefore,
when
we
replace
X
by
a
set
of
constants
c
,
...,
c
,
the
following
formula
is valid
1
n
V
Vg
e[X/c ,...,c ] ). As a consequence, (1) is valid.
( KB  KB)
 (Q[X/c1 ,...,cn ]  Q
n
1
b[c ,...,c /X] ) where Q
b[X/c ,...,c ] is a Craig interNext, we have to prove KB |= (Q[X]  Q
n
0
n1
1
b[X/c ,...,c ] is an interpolant:
polant of (1). Since Q
1

n

910

fiExact Query Reformulation over DBs with FO and DL Ontologies

V
b[X/c ,...,c ]
1. (( KB)  Q[X/c1 ,...,cn ] )  Q
n
1
b[X/c ,...,c ] )
Then : KB |= (Q[X/c1 ,...,cn ]  Q
n
1
g Q
e[X/c ,...,c ] )
b[X/c ,...,c ]  ((V KB)
2. Q
n
n
1
1
g |= (Q
b[X/c ,...,c ]  Q
e[X/c ,...,c ] ).
Then : KB
n
n
1
1
b  PDB , the relation KB |= (Q
b[X/c ,...,c ]  Q[X/c ,...,c ] ) holds as well
Since (Q)
n
n
1
1
From(1)(2) we have the expected statement.
b[X/c ,...,c ] )  PDB then (Q
b[c ,...,c /X] )  PDB .
Last but not least, since (Q
n
n
1
1
b[c ,...,c /X] is really an explicit definition of Q
With above statements, Q
n
1
Theorem 8.
Proof. We need the following propositions to prove the theorem.
Proposition 7. 1  2 is safe-range and closed iff 1 and 2 are safe-range and closed.
Proof. We have:
 rr(1  2 ) = rr(1 )  rr(2 )
 free(1  2 ) = free(1 )  free(2 )
 rr(1 ) =  or rr(1 )  free(1 )
 rr(2 ) =  or rr(2 )  free(2 )
 1  2 is closed iff f ree(1 ) = free(2 ) = 
 1 is closed iff free(1 ) = 
 2 is closed iff free(2 ) = 
 1  2 is safe-range iff rr(1  2 ) = free(1  2 )
 1 is safe-range iff rr(1 ) = free(1 )
 1 is safe-range iff rr(2 ) = free(2 )
Therefore:
 1  2 is closed iff 1 and 2 are closed
 1  2 is closed, safe-range iff 1 and 2 are closed, safe-range.

Proposition 8. 1  2 is safe-range and closed iff 1 and 2 are safe-range and closed.
Proof. We have:
 rr(1  2 ) = rr(1 )  rr(2 )
911

fiFranconi, Kerhet, & Ngo

 free(1  2 ) = free(1 )  free(2 )
 rr(1 ) =  or rr(1 )  free(1 )
 rr(2 ) =  or rr(2 )  free(2 )
 1  2 is closed iff free(1 ) = free(2 ) = 
 1 is closed iff free(1 ) = 
 2 is closed iff free(2 ) = 
 1  2 is safe-range iff rr(1  2 ) = free(1  2 )
 1 is safe-range iff rr(1 ) = free(1 )
 1 is safe-range iff rr(2 ) = free(2 )
Therefore:
 1  2 is closed iff 1 and 2 are closed
 1  2 is closed, safe-range iff 1 and 2 are closed, safe-range.

Proposition 9. ~x(~x) is closed and safe-range then (~t) is closed and safe-range where
~t are constants.
Proof. Obviously, if ~x(~x) is closed then (~t) is closed.
Assume that (~t) is not safe-range. Since its closed rr(SRNF((~t))) = 
 SRNF((~t)) must contain a subformula which is in the form ~z0 (~t, ~z)
where ~z 6 rr(SRNF(0 (~t, ~z)))
 SRNF((~x)) must contain a subformula which is in the form ~z0 (~x, ~z)
where ~z 6 rr(SRNF(0 (~x, ~z)))
 SRNF((~x)) must contain a subformula which is in the form ~z0 (~x, ~z)
where ~z 6 rr(SRNF(0 (~x, ~z))) because pushing negation does not effect the formula under

 rr(SRNF((~x))) = 
 rr(SRNF(~x(~x))) = 
 rr(SRNF(~x(~x))) = 
~x(~x) is not safe-range
 contradiction.
Proposition 10. ~x(~x) is closed and safe-range then (~t) is closed and safe-range where
~t are constants.
Proof. Undoubtedly, if ~x(~x) is closed then (~t) is closed.
Assume that (~t) is not safe-range. Since it is closed, rr(SRNF((~t))) = 
 SRNF((~t)) must contain a subformula which is in the form ~z0 (~t, ~z)
where ~z 6 rr(SRNF(0 (~t, ~z)))
912

fiExact Query Reformulation over DBs with FO and DL Ontologies

 SRNF((~x)) must contain a subformula which is in the form ~z0 (~x, ~z)
where ~z 6 rr(SRNF(0 (~x, ~z)))
 rr(SRNF((~x))) = 
 rr(SRNF(~x(~x))) = 
~x(~x) is not safe-range
 contradiction.
Based on these propositions, we prove Theorem 8 as follows.
First, we will show that if  and  are closed and safe-range and    is valid then
so is their interpolant. Assume T is a biased tableau of of   . Therefore the root node
of T is S = {L(), R()}. Based on all the tableau expansion rules and above propositions, at every expansion step where S = {L(1 ), ..., L(n ), R(1 ), ..., R(m )}, 1 , ..., n
and 1 , ..., m are safe-range and closed(*) .
Now we need to prove that the interpolant at each step is safe-range and closed (**) by
induction on the shape of proof and the set of rules in Section 6.
 Rules for closed branches: Its trivial because  and  are safe-range and closed
because of (*)
 Rules for propositional case :
For the rule (p1)(p2)(p3)(p4) nothing changes, so one does not need to prove.
For the rule (p5), apply the Proposition 8, (**) holds.
For the rule (p6), apply the Proposition 7,(**) holds.
 Rules for first order case :
For the rule (f1) (f2) (f3) nothing changes, so one does not need to prove.
For the rule (f4), since c does not occur in {1 , ..., n } then the only case to have c in
int
I is that S contains R((c)). Therefore S  {L((c))}  I = (c). Since x.(x) is
safe-range (due to (*)) then x.I[c/x] is safe-range too
For the rule (f5), since c does not occur in {1 , ..., m } then the only case to have c in
int
I is that S contains L((c)). Therefore S  {R((c))}  I = (c). Since x.(x)
is safe-range (due to (*)) then x.I[c/x] is safe-range too
 Rules for equality : Because all the input formulas are closed and do not contain
function symbols, all equations are ground. Therefore, they do not influence the
safe-range property of interpolant in each step.
As a consequence, because Q(~c), KB, KB 0 ,Q0 (~c) are closed and safe-range then so is the
b c) of KB  Q(~c) and KB 0  Q0 (~c).
interpolant Q(~
Theorem 9.
Proof. As a consequence of Lemma 1, Theorem 9 holds.
913

fiFranconi, Kerhet, & Ngo

A.5 Definitions and Proofs of Section 7
The safe-range fragment of ALCHOIQ. We call any axiom (concept) in ALCHOIQ
(ground) safe-range, if the corresponding logically equivalent (open) formula in FOL(C, P)
is (ground) safe-range. For any concept C we denote the corresponding logically equivalent
formula in FOL(C, P) with one free variable x as C(x). Unfortunately concept inclusion
axioms in ALCHOIQ ontologies may not be safe-range: for example, the axiom  male v
female is not safe-range. It is easy to see that an axiom C v D is not safe-range if and only
if C(x) is not safe-range and D(x) is safe-range: just observe that the axiom is logically
equivalent to the formula x. C(x)  D(x) in FOL(C, P) (which is actually in a saferange normal form). The following proposition provides recursive rules deciding whether
an ALCHOIQ concept is safe-range.
Proposition 11. Let A be an atomic concept, let C and D be ALCHOIQ concepts, and
let R be either an atomic role or an inverse atomic role. Then:
1. A, {o},  nR,  nR.C are safe-range;
2. C u D is safe-range if and only if C is safe-range or D is safe-range;
3. C t D is safe-range if and only if C is safe-range and D is safe-range;
4. C is safe-range if and only if C is not safe-range.
Proof. It is enough to prove the proposition just for atomic roles because the order of
variables in binary atoms of a first-order logic translation of an ALCHOIQ concept does
not affect the safe-range property of the translation. Therefore hereafter we assume that R
is an atomic role.
 Since A is an atomic concept, A(x) is safe-range.
 {o}(x) = (x = o) - safe-range.
 ( nR)(x) = x1 , . . . , xn . R(x, x1 )  . . .  R(x, xn )  (x1 6= x2 )  . . .  (xn1 6= xn ) safe-range.
 ( nR.C)(x) = x1 , . . . , xn . R(x, x1 )  . . .  R(x, xn )  C(x1 )  . . .  C(xn )  (x1 6=
x2 )  . . .  (xn1 6= xn ) - safe-range.
 Let us prove, that (C u D)(x) = C(x)  D(x) is safe-range if and only if C(x) is
safe-range or D(x) is safe-range.
) Let C(x) or D(x) be safe-range and let both of them be in safe-range normal
forms. Then
C(x)  D(x) is safe-range by definition.
) Let C(x)  D(x) be safe-range and in safe-range normal form (i.e. both C(x) and
D(x) are in safe-range normal form). Let us prove by contradiction. Suppose, both
C(x) and D(x) are not safe-range. Then C(x)  D(x) is not safe-range by definition.
It is a contradiction. Therefore, C(x) is safe-range or D(x) is safe-range.
914

fiExact Query Reformulation over DBs with FO and DL Ontologies

 Let us prove, that (C t D)(x) = C(x)  D(x) is safe-range if and only if C(x) is
safe-range and D(x) is safe-range.
) Let C(x) and D(x) be both safe-range and in safe-range normal forms. Then
C(x)  D(x) is safe-range by definition.
) Let C(x)  D(x) be safe-range and in safe-range normal form (i.e. both C(x) and
D(x) are in safe-range normal form). Let us prove by contradiction. Suppose, C(x)
or D(x) is not safe-range. Then C(x)  D(x) is not safe-range by definition. It is a
contradiction. Therefore, C(x) is safe-range and D(x) is safe-range.
 Let us prove, that C(x) is safe-range if and only if C(x) is not safe-range.
) Let C(x) be safe-range. Let us prove by contradiction. Let C(x) be also saferange. Then both C(x) and C(x) are domain independent. But one can easily see
(looking at the definition of domain independence), that it is impossible. Therefore,
C(x) is not safe-range. ) We need to prove, that if C(x) is not safe-range, then
C(x) is safe-range.
Let us prove by induction on structure of the formula. Suppose, the item is true for
any subformula of the formula C(x).
Suppose, C(x) is not safe-range. Let us consider (using already proved items) all the
possible cases, when C(x) is not safe-range.
 C(x) = (R.D)(x) = y. R(x, y)  D(y)  y.R(x, y)D(y) - not safe-range,
where D is any (possibly complex) concept. Then C(x) = y.R(x, y)  D(y)
is safe-range by definition.
 Suppose, C(x) = (D u F )(x) is not safe-range. Then D(x) is not safe-range and
F (x) is not safe-range. Since both D(x) and F (x) are subformulas of C(x), by
applying the current item we get: D(x) and F (x) are safe-range. C(x) 
(D(x)  F (x))  D(x)  F (x) - safe-range, because D(x) and F (x) are
safe-range.
 Suppose, C(x) = (D t F )(x) is not safe-range. Then D(x) is not safe-range or
F (x) is not safe-range. Since both D(x) and F (x) are subformulas of C(x), by
applying the current item we get: either D(x) or F (x) is safe-range. C(x) 
(D(x)  F (x))  D(x)  F (x) - safe-range, because either D(x) or F (x)
is safe-range.
 Suppose, C(x) = D(x) is not safe-range. We need to prove, that C(x)  D(x)
is safe-range. Let us prove by contradiction. Suppose, D(x) is not safe-range.
Then, since D(x) is a subformula of C(x), by applying the current item we get:
D(x)  C(x) is safe-range. It is a contradiction. Hence, C(x) is safe-range.
The item is proved completely.
The proposition is proved completely.
Proposition 12. All ALCHOIQ role inclusion axioms are safe-range.
915

fiFranconi, Kerhet, & Ngo

Proof. Let S v R be any role inclusion axiom in ALCHOIQ. The formula x, y. S(x, y) 
R(x, y) is a first-order logic translation of the axiom, where (x, y) stands for (x, y) if the
preceding role is atomic and (x, y) stands for (y, x) if the preceding role is inverse atomic.
This formula is safe-range.
Guarded negation first-order logic. We recall the definition of guarded negation firstorder logic (GNFO) given in the paper by Barany et al. (2012). GNFO is a fragment of
first-order logic consisting of all formulas generated by the following recursive definition:
 ::= R(t1 , . . . , tn ) | t1 = t2 | 1  2 | 1  2 | x.  |   

(7)

where each ti is either a variable or a constant,  in    is an atomic formula (possibly
an equality statement) containing all free variables of .
Guarded negation fragment of ALCHOIQ. Now we consider ALCHOIQGN - a
guarded negation fragment of ALCHOIQ (i.e. an intersection of GNFO and ALCHOIQ).
We say, that
 a concept C is an ALCHOIQGN concept if C is an ALCHOIQ concept and the
corresponding first-order logic translation C(x) is expressed in GNFO;
 a concept inclusion axiom C v D is an ALCHOIQGN concept inclusion axiom if
C and D are ALCHOIQ concepts and the formula x. C(x)  D(x) (which is
equivalent to the first-order translation of C v D) is expressed in GNFO;
 a role inclusion axiom S v R is an ALCHOIQGN role inclusion axiom if S and R are
roles (atomic or inverse atomic) and the formula x, y. S(x, y)  R(x, y) , where
(x, y) stands for (x, y) if the preceding role is atomic and (x, y) stands for (y, x) if
the preceding role is inverse atomic, is expressed in GNFO.
It is easy to see, that any ALCHOIQ role inclusion axiom is an ALCHOIQGN role inclusion
axiom. Then because of Proposition 12 the following holds.
Proposition 13.

 All ALCHOIQGN role inclusion axioms are safe-range.

 All safe-range role inclusion axioms in ALCHOIQ are in ALCHOIQGN .
From the definition of GNFO and ALCHOIQ it follows, that the complex concept C
of the logic ALCHOIQGN is recursively defined as follows:
B ::= A | {o} |  nR
C ::= B |  nR.C |  nR.C | B u C | C u D | C t D

(8)

where A is an atomic concept, R is an atomic role or an inverse atomic role, and C and D
are ALCHOIQGN concepts (possibly complex).
Note, that in general, according to the definition (7) of GNFO all formulas with atleast
operator for n  2 are not in GNFO because of non-guarded inequality statements xi 6=
xj . We fix this by assuming that inequality relation is actually a special binary database
predicate. This assumption is usual for databases.
916

fiExact Query Reformulation over DBs with FO and DL Ontologies

Also strictly speaking  nR u C is not in GNFO. Indeed, the formula
(x1 , . . . , xn . R(x, x1 )  . . .  R(x, xn )  (x1 6= x2 )  . . .  (xn1 6= xn ))  C(x) is not in
GNFO (R(x, y) here stands for P (x, y) if R stands for an atomic role P , and R(x, y) stands
for P (y, x) if R stands for an inverse atomic role P  ), but it can be easily transformed to a
logically equivalent GNFO one by simply shifting the parentheses: x1 , . . . , xn . (R(x, x1 ) 
. . .  R(x, xn )  (x1 6= x2 )  . . .  (xn1 6= xn )  C(x)). So, we can assume, that the formula
 nR u C is in ALCHOIQGN .
Proposition 14. All ALCHOIQGN concepts are safe-range.
Proof. Let us prove by induction on the structure of ALCHOIQGN concepts defined by
(8).
1. A, {o},  nR,  nR.C,  nR.C (C is an ALCHOIQGN concept) are safe-range
because of the item 1 of Proposition 11.
2. For any atomic concept A, any individual o any role R and any natural number n the
concepts A u C, {o} u C and  nR u C are safe-range because of the item 3 of
Proposition 11 and since A, {o} and  nR are safe-range by the first item.
3. Suppose, that ALCHOIQGN concepts C and D are safe-range. Then the concepts
C u D and C t D are safe-range by the items 2 and 3 of Proposition 11 respectively.
The proposition is proved.
Lemma 4. For any safe-range concept C in ALCHOIQ the following holds:
C v B1 t . . . t Bn ,
where Bi appears as a subconcept in C and is one of the following concepts:
 an atomic concept A;
 {o}, where o is an individual name;
  nR, where R is an atomic role or inverse atomic role, n is a natural number.
Proof. Let us prove the proposition by induction for all safe-range concepts of ALCHOIQ.
 A, {o},  nR,  nR.C are safe-range by Proposition 11. A v A, {o} v {o},  nR v
 nR,  nR.C v  nR.
Suppose now that C is a complex safe-range concept and the proposition holds for all
safe-range subconcepts of C.
1. C = C1 u C2 - safe-range. Then either C1 or C2 is safe-range. Let C1 be safe-range.
Hence, C1 v B1 t . . . t Bm , where Bi is a concept of the aforementioned type. Then
C1 u C2 v C1 v B 1 t . . . t B m .
2. C = C1 t C2 - safe-range. Then C1 and C2 are safe-range. Hence, C1 v B1 t . . . t Bk
and C2 v Bk+1 t . . . t Bm , where Bi is a concept of the aforementioned type. Then
C1 t C2 v (B1 t . . . t Bk ) t (Bk+1 t . . . t Bm ) v B1 t . . . t Bm .
917

fiFranconi, Kerhet, & Ngo

3. C = D is safe-range. By Proposition 11 it is possible if and only if D is not saferange. That is one of the following cases takes place.
 D = D1 u D2 . Then D  D1 t D2 . And we reduced this case to the item 2.
 D = D1 t D2 . Then D  D1 u D2 . And we reduced this case to the item 1.
 D = D1 . Then D  D1  D1 . Hence, D1 is a safe-range subconcept of D.
Then the proposition holds for D1 and, hence, also for C, because C  D  D1 .
The lemma is proved completely.
Lemma 5. For any ALCHOIQ concept C there exists an ALCHOIQGN concept C 0 such
that either C  C 0 or C  C 0 .
Proof. Suppose that the lemma holds for all ALCHOIQ subconcepts of the ALCHOIQ
concept C. Let us prove it for C.
1. Base. A, {o},  nR are ALCHOIQGN concepts by the definition of ALCHOIQGN
concept (8).
2. C =  nR.D and D0 is an ALCHOIQGN concept such that D  D0 or D 
D0 . Then C  nR.D0 or C  nR.D0 .  nR.D0 and  nR.D0 are both
ALCHOIQGN concepts. Hence, the item is proved.
3. C = D and D0 is an ALCHOIQGN concept such that D  D0 or D  D0 . Then
C  D0 or C  D0  D0 . The item is proved.
4. C = C1 u C2 and C10 is an ALCHOIQGN concept such that C1  C10 or C1  C10 , C20
is an ALCHOIQGN concept such that C2  C20 or C2  C20 . Consider all possible
cases.
(a) C1  C10 and C2  C20 . Then C  C 0 , where C 0 = C10 u C20 is an ALCHOIQGN
concept (because C10 and C20 are ALCHOIQGN concepts).
(b) C1  C10 and C2  C20 . Then C  C10 u C20  (C10 t C20 ) = C 0 , where
C 0 = C10 tC20 is an ALCHOIQGN concept (because C10 and C20 are ALCHOIQGN
concepts).
(c) C1  C10 and C2  C20 (the case when C1  C10 and C2  C20 is the similar
one). Then C  C10 u C20 . Since C10 is an ALCHOIQGN concept by Proposition
14 it is safe-range and, hence, by Lemma 4 C10 v B1 t . . . t Bn , where each Bi is
either an atomic concept A or {o} or R. Then C10  C10 u (B1 t . . . t Bn ) and,
hence, C  C10 u (B1 t . . . t Bn ) u C20  C10 u (B1 u C20 t . . . t Bn u C20 ). Each
disjunct Bi u C20 is an ALCHOIQGN concept (because C2 is ALCHOIQGN
concept and by the definition (8) of ALCHOIQGN concepts). Then C 0 = C10 u
(B1 u C20 t . . . t Bn u C20 ) is an ALCHOIQGN concept. C  C 0 . The item is
proved.
5. C = C1 t C2  (C1 u C2 ). This case is reduced to the items 3 and 4.
918

fiExact Query Reformulation over DBs with FO and DL Ontologies

The lemma is proved completely.
Corollary 2. For any ALCHOIQ concept C and any concept B, which is either an atom
A or {o} or  nR, the concept B u C is equivalent to some ALCHOIQGN concept.
Proof. By Lemma 5 there exists an ALCHOIQGN concept C 0 such that either C  C 0
or C  C 0 . Then B u C  B u C 0 or B u C  B u C 0 . Both B u C 0 and B u C 0
are ALCHOIQGN concepts (by the definition (8) of ALCHOIQGN concepts). Hence, the
corollary is proved.
Proposition 15. Any safe-range ALCHOIQ concept is equivalent to some ALCHOIQGN
concept.
Proof. Let C be any safe-range ALCHOIQ concept. By Lemma 4 C v B1 t . . . t Bn ,
where each Bi is either an atom A or {o} or  nR. Then C  C u (B1 t . . . t Bn ) 
B1 uCt. . .tBn uC. By the corollary 2 for each disjunct Bi uC there exists an ALCHOIQGN
concept Di such that Bi u C  Di . Then C  D1 t . . . t Dn . The concept D1 t . . . t Dn is an
ALCHOIQGN concept as a disjunction of ALCHOIQGN concepts. Hence, the proposition
is proved.
Proposition 16. All ALCHOIQGN concept inclusion axioms are safe-range.
Proof. Let C v D be any concept inclusion axiom in ALCHOIQGN . It means that the
corresponding first-order logic translation x. C(x)  D(x) is in GNFO. Hence, C(x) 
D(x) is in GNFO or, that is the same, C u D is in ALCHOIQGN . It is easy to see, that
x. C(x)  D(x) is safe-range if and only if the formula C(x)  D(x) is safe-range, that
is if and only if the corresponding ALCHOIQGN concept C u D is safe-range. But by
Proposition 14 any ALCHOIQGN concept is safe-range. The proposition is proved.
Lemma 6. For any safe-range ALCHOIQ concept C and any ALCHOIQ concept D the
concept C u D is equivalent to some ALCHOIQGN concept C 0 u D0 , where C 0 and D0 are
ALCHOIQGN concepts.
Proof. Since C is safe-range by Lemma 4 C v B1 t . . . t Bn , where each Bi is either an
atomic concept A or {o} or R. Then C  C u (B1 t . . . t Bn ) and, hence, C u D 
C u (B1 t . . . t Bn ) u D  C u (B1 u D t . . . t Bn u D). By the corollary 2 each disjunct
Bn uD is an ALCHOIQGN concept. Hence, D0 := B1 uDt. . .tBn uD is an ALCHOIQGN
concept. Since C is s safe-range by Proposition 15 there exists an ALCHOIQGN concept
C 0 such that C  C 0 . Then C u D  C 0 u D0 , and C 0 u D0 is an ALCHOIQGN concept,
where C 0 and D0 are ALCHOIQGN concepts.
Proposition 17. Any safe-range ALCHOIQ concept inclusion axiom C v D can be transformed to a concept inclusion axiom C 0 v D0 , where C 0 and D0 are ALCHOIQGN .
Proof. Let C v D be any safe-range ALCHOIQ concept inclusion axiom. Then the corresponding formula x. C(x)  D(x) is safe-range. Then the first-order logic formula
C(x)  D(x) is safe-range, or, that is the same, the ALCHOIQ concept C u D is saferange. By Proposition 11 we have that C is safe-range or D is safe-range.
919

fiFranconi, Kerhet, & Ngo

 C is safe-range. Then by Lemma 6 there exist two ALCHOIQGN concepts C 0 and
D0 such that C u D is logically equivalent to the ALCHOIQGN concept C 0 u D0 .
Then x. C(x)  D(x) is logically equivalent to x. C 0 (x)  D0 (x). Hence, C v D
is logically equivalent to C 0 v D0 (C 0 and D0 are ALCHOIQGN concepts).
 D is safe-range. The proof is similar to the previous item.
The proposition is proved completely.
Proposition 18. For any two ALCHOIQGN concepts C and D the axiom C v D is an
ALCHOIQGN concept inclusion axiom.
Proof. The axiom C v D is logically equivalent to the first-order logic formula x. C(x)
D(x), where C(x) and D(x) are in GNFO. Then x. C(x)  D(x) is also in GNFO. Hence,
by the definition of ALCHOIQGN concept inclusion axiom the axiom C v D is an
ALCHOIQGN concept inclusion axiom.
Propositions 17 and 18 imply the following.
Proposition 19. Any safe-range ALCHOIQ concept inclusion axiom is equivalent to some
ALCHOIQGN concept inclusion axiom.
We consider a connection between safe-range fragment of ALCHOIQ and guarded negation fragment of ALCHOIQ, that is ALCHOIQGN . When we say fragment, we mean a
set of TBox assertions (concept and role inclusion axioms) and concepts (open formulas) of
ALCHOIQ satisfying a particular property (e.g safe-range or guarded negation). Taking
into account propositions 14, 15, 16, 19 and 13, we have the following theorem.
Proposition 20. The safe-range fragment of ALCHOIQ and ALCHOIQGN are equally
expressive.
This proves Theorem 10:
Theorem 10 (Expressive power equivalence). The domain independent fragment of
ALCHOIQ and ALCHOIQGN are equally expressive.
Theorem 11. ALCHOIQGN TBoxes have finitely controllable determinacy of concept
queries.
Proof. We need to prove, that for any ALCHOIQGN TBox T (ontology), any concept
query Q in ALCHOIQGN and any set of database predicates PDB , whenever the query is
finitely determined by the database predicates under the ontology then it is also determined
in unrestricted models.
Suppose, that Q is finitely determined by PDB under T . Then from Theorem 2 it
e where |=fin P means entailment over models with a
follows, that T  Te |=fin PDB Q v Q,
DB
e
finite interpretation to the database predicates. Hence, in particular T  Te |=fin Q v Q,
where |=fin means entailment over finite models. Hereafter let  be one sentence, that is a
first-order logic translation of a conjunction of all axioms in the TBox T . Then from the
aforementioned entailment we have:
e
|=fin (  e
 )  (x. Q(x)  Q(x)).
920

(9)

fiExact Query Reformulation over DBs with FO and DL Ontologies

e
By Proposition 14 Q(x) is safe-range. Hence, Q(x)  Q(x)
is safe-range, hence the
e is safe-range and, hence, by Proposition 15 there exists an
ALCHOIQ concept Q u Q
e  C 0 . Then x. Q(x)  Q(x)
e
ALCHOIQGN concept C 0 such that Q u Q
 x.C 0 (x)
and the following holds:
|=fin (  e
 )  (x.C 0 (x)).
(10)
x.C 0 (x) is in GNFO, because C 0 (x) is in GNFO. Since all the axioms in T are ALCHOIQGN
TBox axioms, the sentences  and e are in GNFO. Then the sentence   e
 is in GNFO.
Therefore the right hand side of the entailment (10) is in GNFO. Then ((  e
) 
(x.C 0 (x))) is also in GNFO and by the entailment (10) does not have a finite model.
Then, since GNFO has the finite model property, ((  e
 )  (x.C 0 (x))) is unsatisfiable. Hence, we have:
|= (  e
 )  (x.C 0 (x)).
e
Since x.C 0 (x)  x. Q(x)  Q(x),
the following holds:
e
|= (  e
 )  (x. Q(x)  Q(x)).
e By Theorem 2 it means, that the query Q is determined in
Then T  Te |= Q v Q.
unrestricted models by the database predicates PDB under the ontology T .
The proposition is proved.

References
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations of Databases. Addison-Wesley.
Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). The DL-Lite family
and relations. J. Artif. Intell. Res. (JAIR), 36, 169.
Avron, A. (2008). Constructibility and decidability versus domain independence and absoluteness. Theor. Comput. Sci., 394, 144158.
Barany, V., Gottlob, G., & Otto, M. (2010). Querying the guarded fragment. In Proceedings
of the 25th Annual IEEE Symposium on Logic in Computer Science (LICS 2010), pp.
110.
Barany, V., ten Cate, B., & Otto, M. (2012). Queries with guarded negation (full version).
CoRR, abs/1203.0077.
Beth, E. (1953). On Padoas method in the theory of definition. Indagationes Mathematicae,
15, 330339.
Craig, W. (1957). Three uses of the Herbrand-Gentzen theorem in relating model theory
and proof theory. J. Symb. Log., 22 (3), 269285.
Etzioni, O., Golden, K., & Weld, D. S. (1997). Sound and efficient closed-world reasoning
for planning. Artif. Intell., 89, 113148.
Fan, W., Geerts, F., & Zheng, L. (2012). View determinacy for preserving selected information in data transformations. Inf. Syst., 37, 112.
Fitting, M. (1996). First-order logic and automated theorem proving (2nd edition). Springer.
921

fiFranconi, Kerhet, & Ngo

Franconi, E., Ibanez-Garcia, Y. A., & Seylan, Inanc. (2011). Query answering with DBoxes
is hard. Electronic Notes in Theoretical Computer Science, Elsevier, 278, 7184.
Franconi, E., Kerhet, V., & Ngo, N. (2012a). Exact query reformulation over SHOQ DBoxes.
In Proc. of the 2012 International workshop on Description Logics (DL-2012).
Franconi, E., Kerhet, V., & Ngo, N. (2012b). Exact query reformulation with first-order ontologies and databases. In Logics in Artificial Intelligence - 13th European Conference,
JELIA 2012, pp. 202214.
Franconi, E., Ngo, N., & Sherkhonov, E. (2012c). The definability abduction problem for
data exchange. In Web Reasoning and Rule Systems - 6th International Conference
RR 2012.
Gurevich, Y. (1984). Toward logic tailored for computational complexity. In Computation
and Proof Theory, Vol. 1104, pp. 175216. Springer.
Halevy, A. Y. (2001). Answering queries using views: A survey. The VLDB Journal, 10,
270294.
Marx, M. (2007). Queries determined by views: pack your views. In Proceedings of the 26th
ACM symposium on Principles of Database Systems, PODS 07, pp. 2330.
McCune, W. (20052011).
prover9.

Prover9 and Mace4.

http://www.cs.unm.edu/~mccune/

Nash, A., Segoufin, L., & Vianu, V. (2010). Views and queries: Determinacy and rewriting.
ACM Trans. Database Syst., 35, 21:121:41.
Rosati, R. (2011). On the finite controllability of conjunctive query answering in databases
under open-world assumption. J. Comput. Syst. Sci., 77 (3), 572594.
Seylan, Inanc., Franconi, E., & de Bruijn, J. (2009). Effective query rewriting with ontologies over DBoxes. In Proc. of the 21st International Joint Conference on Artificial
Intelligence (IJCAI 2009), pp. 923925.
ten Cate, B., Franconi, E., & Seylan, Inanc. (2011). Beth definability in expressive description logics. In Proc. of the 22nd International Joint Conference on Artificial
Intelligence (IJCAI 2011), pp. 10991106.
ten Cate, B., Franconi, E., & Seylan, Inanc. (2013). Beth definability in expressive description logics. Journal of Artificial Intelligence Research (JAIR), 48, 347414.

922

fiJournal of Artificial Intelligence Research 48 (2013) 347-414

Submitted 05/13; published 11/13

Beth Definability in Expressive Description Logics
Balder ten Cate

btencate@ucsc.edu

UC Santa Cruz

Enrico Franconi

franconi@inf.unibz.it

Free University of Bozen-Bolzano

Inanc Seylan

seylan@informatik.uni-bremen.de

University of Bremen

Abstract
The Beth definability property, a well-known property from classical logic, is investigated in the context of description logics: if a general L -TBox implicitly defines an
L -concept in terms of a given signature, where L is a description logic, then does there
always exist over this signature an explicit definition in L for the concept? This property
has been studied before and used to optimize reasoning in description logics. In this paper
a complete classification of Beth definability is provided for extensions of the basic description logic ALC with transitive roles, inverse roles, role hierarchies, and/or functionality
restrictions, both on arbitrary and on finite structures. Moreover, we present a tableaubased algorithm which computes explicit definitions of at most double exponential size.
This algorithm is optimal because it is also shown that the smallest explicit definition of an
implicitly defined concept may be double exponentially long in the size of the input TBox.
Finally, if explicit definitions are allowed to be expressed in first-order logic, then we show
how to compute them in single exponential time.

1. Introduction
We address the Beth definability property (Beth, 1953) in the context of description logics
(DLs). The Beth definability property relates two notions of definability in a logic L ,
implicit definability and explicit definability. Implicit definability is a semantic notion: it
asks whether the interpretation of a given L -formula  is fully determined by the universe
of discourse and the interpretation of some given predicates  in all models of a theory
T . Explicit definability on the other hand is more syntactic: it asks whether there is some
L -formula  over the set of predicates  that is equivalent to  under T . Clearly, explicit
definability implies implicit definability. If the converse holds as well, then the logic L is
said to have the Beth definability property. Logics having this property are considered to be
well-balanced in terms of their syntax and semantics since it connects the model-theoretic
notion of implicit definability to explicit definability.
The Beth definability property can be naturally formulated for DLs by slightly changing the terminology in the paragraph above: formulas become concepts, theories become
TBoxes, and  consists of unary and binary predicates (respectively called concept names
and role names).
c
2013
AI Access Foundation. All rights reserved.

fiTen Cate, Franconi, & Seylan

Example 1.1. Consider the following ALC-TBox T .
Parent
Parent
Father
Mother
Man



v
v
v

hasChild.>
Father t Mother
Man
Woman
Woman

The concept name Mother is implicitly definable from  = {hasChild, Woman} under T .
Precisely what we mean by this will be clear once we present Definition 4.1; intuitively, we
mean that the instances of Mother in a model I of T can be exactly determined once we know
the domain of I and the instances of  in I. In fact, we can spell this implicit definition out
as the ALC-concept Woman u hasChild.>. This concept is an explicit definition of Mother
from  under T because T |= Mother  Woman u hasChild.> (cf. Definition 4.5).
Beth definability in DLs has found applications in optimizing reasoning. The first application is related to extracting an equivalent acyclic L -terminology from a general TBox
in L (Baader & Nutt, 2003; ten Cate, Conradie, Marx, & Venema, 2006). An acyclic
terminology consists only of acyclic definitions for concept names and they are of particular
interest because reasoning with them is easier than with general TBoxes. For example, satisfiability of an ALC-terminology is a PSpace-complete problem whereas the same problem
for general ALC-TBoxes is ExpTime-complete (Donini, 2003). The second application is
related to an ontology-based data access setting, which assumes the existence of a database
instance (also referred to as DBox in this context) and a TBox that may speak about
more predicates than the database instance (Seylan, Franconi, & de Bruijn, 2009). In this
setting, the user may ask concept queries over the signature of the TBox; and the idea is
to find an equivalent rewriting of the original query in terms of the predicates that appear
in the DBox. If such a rewriting exists, then determining the certain answers of the query
can be reduced to query answering in relational databases, which is known to be in AC0 in
data complexity in contrast to the general coNP-completeness of concept querying in ALC
with DBoxes (Seylan et al., 2009).
Both of these applications involve computing explicit definitions on the basis of implicit
definitions. Here, the problem is that this may not always be possible for some DLs, i.e.,
some DLs may lack the Beth definability property.
Example 1.2. In this example, we model a scenario about cars, their owners, and the
relationships between the owners and their cars. Consider the following ALCH-TBox T
consisting of the concept inclusion axioms
SportsCar
FuelEfficientCar
SportsCar
proudOwner.Car

v
v
v
v

Car
Car
FuelEfficientCar
(loves.SportsCar u owns.SportsCar)) t
(loves.FuelEfficientCar u owns.FuelEfficientCar))

and the role inclusion axioms
proudOwner v owns
proudOwner v loves
348

fiBeth Definability in Expressive Description Logics

The concept proudOwner.Car is implicitly definable from  = {owns, loves} under T , in the
sense that the instances of proudOwner.Car in a model I of T can be exactly determined
once we know the domain of I and the instances of the roles in . Indeed, an individual
is a proud owner of a car if and only if the individual owns something that he/she loves.
The fact that the left-to-right direction of this equivalence holds in every model of T follows
immediately from the role inclusion axioms, and similarly, the fact that the (contrapositive
of the) right-to-left direction holds in models of T follows immediately from the other TBox
axioms. This implicit definition can be made explicit using the role conjunction operator
as the concept (owns u loves).>. However, it can be shown that no ALCH-concept is an
explicit definition of proudOwner.Car from  under T . We will not formally prove this
here, but see the proof of Theorem 4.18 in Section 4.2 for a similar example. In particular,
this shows that ALCH lacks the Beth definability property.
A natural research agenda in this case is to identify DLs that have the Beth definability
property. Since this property is useful for computing explicit definitions on the basis of
implicit definitions, a vital question then is the complexity of this task, both in terms of
the time needed to compute the explicit definitions, and in terms of the size of the explicit
definitions obtained. This question was first studied by ten Cate et al. (2006) for a weaker
Beth definability property, which considers only concept names in the signature. In this
paper we are interested in the more general Beth definability property that takes into
account role names in the signature. We believe that this is more natural for DLs because
in a DL knowledge base, role names are considered to be a part of the signature. We present
a worst-case optimal algorithm for constructing explicit definitions.
Since the work of Craig (1957), it has been customary to establish Beth definability
via an interpolation theorem; and our work is no exception. In particular, we obtain our
positive results on Beth definability through a worst-case optimal algorithm for constructing
interpolants in the description logics that we consider.
Our contributions in this paper are as follows.
 We obtain a complete classification of the Beth definability property for extensions
of ALC with transitive roles, inverse roles, role hierarchies, and/or functionality restrictions, both on arbitrary structures (BP) and on finite structures (BPF). These
results are summarized in Table 1. Note that the finite model property (FMP) of all
sub-logics of SHOQ is shown by Lutz, Areces, Horrocks, and Sattler (2005); FMP
of all sub-logics of SHIO+ by Duc and Lamolle (2010); and the failure of FMP in
ALCF I and all its extensions is well-known (cf. Calvanese & Giacomo, 2003).
 We present a constructive algorithm based on an interpolating tableau calculus to
compute explicit definitions in ALC and all of its considered extensions having the
Beth definability property. This algorithm runs in double exponential time and computes in the worst case an explicit definition of double exponential size if the concept
is implicitly definable. In this respect, the algorithm is optimal because we also show
that the smallest explicit definition of an implicitly defined concept may be double
exponentially long in the size of the input TBox for each of these DLs.
 We consider the case where explicit definitions are allowed to be expressed in firstorder logic. This is particularly relevant for the use case for computing certain answers
349

fiTen Cate, Franconi, & Seylan

S

H

I

F









































FMP
+
+
+
+
+
+
+
+
+
+
+
+
-

BP
+
+
+
+
+
+
+
+
-

BPF
+
+
+
+
+
+
-

Table 1: BP and BPF from ALC to SHIF

of a query given a DBox and a TBox. We present an algorithm that computes a firstorder explicit definition of an implicitly defined concept in single exponential time for
all DLs with BP or BPF.

1.1 Related Work
The Beth definability property, in the general sense, has been first shown to hold for firstorder logic (Beth, 1953). Beth definability comes in different flavors and the one we are
interested in is related more to projective Beth definability. Here, projective refers to the
ability to specify the set of predicates . The projective version is known be stronger than
Beths original formulation (cf. Hoogland, 2001) and first shown to hold for first-order logic
by Craig (1957). Since the seminal works of Beth and Craig, Beth definability has been
studied for many other logics.
Lang and Marquis (2008), also motivated from AI, study the propositional variant. The
modal and temporal variants have been extensively studied (cf. Gabbay & Maksimova,
2005). The k-variable fragment of first-order logic, for k  2, is known to lack the Beth
definability property, whereas the Guarded and Packed Fragments satisfy a non-projective
version of the Beth property (cf. Hoogland, 2001). The guarded-negation fragment was
recently shown to have the Beth definability property as well (Barany, Benedikt, & ten
Cate, 2013).
Beth definability has practical applications in relational databases for query rewriting
using exact views (Nash, Segoufin, & Vianu, 2010; Afrati, 2011; Marx, 2007; Pasaila, 2011;
Barany et al., 2013). Here, the idea is to decide if the answers to a given query can be inferred
from the content of a collection of views (that is, whether the theory consisting of the view
definitions implicitly defines the query in terms of the view predicates), and, if this is indeed
the case, to rewrite the query into a query over the schema consisting of the view predicates
350

fiBeth Definability in Expressive Description Logics

(that is, an explicit definition of the query in terms of the view predicates). View-based
query rewriting naturally arises in various settings, including query optimization, querying
under access restrictions, data integration, and privacy analysis.
Beth definability has also been studied in the DL literature. Similarly to the relational
database case, it finds applications in computing explicit definitions on the basis of implicit
definitions (Baader & Nutt, 2003; ten Cate et al., 2006; Seylan et al., 2009; Seylan, Franconi, & de Bruijn, 2010). Some of these papers also present results on the size of explicit
definitions that can be obtained for implicitly defined concepts. Ten Cate et al. establish
a single exponential lower bound and a triple exponential upper bound for ALC. It is not
hard to see that the lower bound proof by ten Cate et al. carries to the Beth definability
property we consider. A matching single exponential upper bound on the size of explicit
definitions was claimed to be established by Seylan et al. (2010) in Theorem 1; however,
this theorem is wrong since a crucial step for its proof, namely Lemma 1, is erroneous.
In this paper, we improve the single exponential lower bound of ten Cate et al. to double
exponential and correct the single exponential upper bound of Seylan et al. to double exponential, thus obtaining tight complexity bounds. These bounds in DLs are in sharp contrast
to first-order logic since there is no recursive bound on the minimal number of quantifier
alternations in explicit definitions in first-order logic (Friedman, 1976). BP has been first
shown to hold for ALC by Seylan et al. (2009) and it is stronger than the variant studied by
ten Cate et al.. Specifically, we show that all DLs we consider that support role hierarchies
actually lack BP, whereas they satisfy the variant of BP studied by ten Cate et al.. In this
respect, Theorem 10 by Seylan et al. (2010) claiming that these DLs have BP is erroneous.
The mistake in the proof is that Theorem 9, which presents a reduction from the concept
satisfiability problem w.r.t. TBoxes in SHI to the same problem in ALC, can not actually
be used for computing SHI-interpolants.
Since the work of Craig (1957), it has been customary to establish Beth definability
via an interpolation lemma; and our work is no exception. An interpolation lemma is
usually established by a model-theoretic or a proof-theoretic argument (Hoogland, 2001).
The advantage of the latter over the former is that it yields a procedure to construct the
interpolant. Several interpolation properties formulated for general TBoxes were studied
in the ALC- (ten Cate et al., 2006; Ghilardi, Lutz, & Wolter, 2006; Konev, Lutz, Walther,
& Wolter, 2009a; Seylan et al., 2009; Konev, Lutz, Ponomaryov, & Wolter, 2010; Lutz
& Wolter, 2011) and EL-family of DLs (Konev, Walther, & Wolter, 2009b; Lutz, Piro,
& Wolter, 2010; Nikitina & Rudolph, 2012; Lutz, Seylan, & Wolter, 2012a). A notable
variant is the uniform interpolation property. A uniform interpolant of a given L -TBox
T and a set of predicates  is another L -TBox T 0 such that T 0 uses only predicates from
 and the logical consequences of T and T 0 formulated over  coincide. In this paper,
we do not consider uniform interpolation because it is not the right interpolation property
for establishing tight bounds on the size of explicit definitions. This is witnessed by the
following observations. Deciding the existence of a uniform interpolant for a given ALCTBox and a set of predicates is known to be 2-ExpTime-complete (Lutz & Wolter, 2011),
whereas the same problem formulated for the interpolation property we study here is in
ExpTime. In the simpler DL EL, uniform interpolants are also more expensive than the
non-uniform ones. In particular, deciding the existence of uniform interpolants in EL is
ExpTime-complete (Lutz et al., 2012a); and Nikitina and Rudolph (2012) establish triple
351

fiTen Cate, Franconi, & Seylan

exponential tight bounds on the size of uniform interpolants. On the other hand, deciding
the existence of interpolants, as we consider in this paper but for the description logic EL,
is in PTime because this problem can be reduced to concept subsumption w.r.t. a TBox in
EL by Lemma 3 of Lutz, Seylan, and Wolter (2012b).
Most of the results in this paper were announced by ten Cate, Franconi, and Seylan
(2011) in an extended abstract. The current paper extends this work by full proofs of the
claimed results and the new material in Section 4.4.
1.2 Outline
We start by introducing in Section 2 the DLs for which we study BP and some reasoning
problems that are relevant for us in this paper. We also fix in this section our first-order
notation and the standard translation of DLs to first-order logic. We will be using firstorder logic extensively in Section 3.3. The hammer with which we nail all the positive
results, i.e., +, to the columns BP and BPF in Table 1, is a worst-case optimal algorithm
for constructing interpolants. Section 3 is dedicated to this interpolation result. Finally, all
our results about BP are presented in Section 4. Since the interpolation results are used to
prove BP, Section 3 naturally comes before Section 4, but the reader who is less interested
in the interpolation results may prefer to skip Section 3 initially.

2. Preliminaries
In this section, we introduce the description logics that we will study. They are frequently
used logics in the expressive ALC-family of description logics.
2.1 Description Logics
Let NC and NR be countably infinite and mutually disjoint sets of concept names and
role names, respectively. For reasons that will become clear in a moment, we also assume a
countably infinite subset of NR , denoted by NR+ , where NR \ NR+ is also countably infinite.
The role names in NR+ are, intuitively, designated as being transitive, and are allowed to
be used only in description logics with transitive roles. An element of NC or NR is also
called a predicate, and a set   NC  NR of concept and role names is called a signature.
To ease the exposition, we first introduce the description logic ALCF I, and we then
define the other description logics that we study. The concept language of ALCF I is defined
as follows:
Concepts:
Roles:

C, D ::= > | A | C | C u D | R.C |  1R
R
::= P | P 

where A  NC and P  NR \ NR+ . The concept constructors , t, R.C, and  2R
are defined as abbreviations in the usual way. Also, by a slight abuse of notation, we will
sometimes write (P  ) , for P  NR , in which case it refers to the role name P itself. An
ALCFI-TBox T is a finite set of concept inclusion axioms (CIAs) C v D, where C and D
are ALCF I-concepts.
The semantics of ALCF I-concepts and roles is given in terms of interpretations. An
interpretation is a pair I = hI , I i where I is a non-empty set called the domain of
352

fiBeth Definability in Expressive Description Logics

>I
(C)I
(C u D)I
(R.C)I
( 1R)I
(P  )I

=
=
=
=
=
=

I ,
I \ C I ,
C I  DI ,
{s  I | there exists t  I such that hs, ti  RI and t  C I },
{s  I | for all t, u  I , if hs, ti  RI and hs, ui  RI then t = u},
{hs, ti | ht, si  P I }.

Table 2: Semantics of complex ALCF I-concepts and roles
I, and I is a function that maps each concept name A  NC to a subset AI of I and
each role name P  NR to a binary relation P I on I . In anticipation of the discussion of
description logics with transitive roles below, we require also that for each P  NR+ , the
relation P I is transitive. The map I is extended to complex concepts and roles by means
of the inductive definitions provided in Table 2.
An interpretation I satisfies (or, is a model of) a CIA C v D if C I  DI , and I satisfies
(or, is a model of) a TBox T if it satisfies every CIA in T . We use the notation I |= C v D
and I |= T to express that I satisfies C v D, respectively, that I satisfies T .
The description logic ALCF I that we defined above is a member of a larger family of
description logics. The basic description logic ALC is defined as ALCF I without inverse
roles (i.e., without roles of the form P  ) and without functionality restrictions (i.e., without
concepts of the form  1R). For X  {S, H, I, F}, the description logic ALCX extends
ALC with
1. Functionality restrictions (as in ALCF I) if F  X,
2. Inverse roles (as in ALCF I) if I  X,
3. Transitive roles if S  X. By this, we mean that the role names in NR+ are allowed
to be used.
4. Role hierarchies if H  X. By this, we mean that a TBox may contain role inclusion
axioms (RIAs) of the form R v S, where R and S are roles, which are satisfied in an
interpretation I if RI  S I .
For DLs that include both transitive roles (S) and functionality restrictions (F), a further
syntactic restriction is imposed: whenever  1R occurs in a concept, then R is required to
be a simple role with respect to the TBox at hand (Horrocks, Sattler, & Tobies, 2000). A
simple role is, intuitively, a role does not have a transitive subrole. The formal definition of
simplicity is as follows: let us write R vT S if either R = S or there are roles R1 , . . . , Rn
such that R1 = R, Rn = S, and for all 1  i < n, T contains either the RIA Ri v Ri+1

or the RIA Ri v Ri+1
. We say R is simple with respect to T if there does not exist
a role S such that S vT R and such that S is of the form P or P  with P  NR+ .
The motivation for this standard syntactic restriction is that, without it, basic decision
problems such as satisfiability and concept subsumption with respect to a TBox (defined
below) quickly become undecidable (Horrocks et al., 2000).
353

fiTen Cate, Franconi, & Seylan

For X  {S, H, I, F} with S  X, it is customary to omit the prefix ALC in the notation ALCX. In particular, the description logic ALCSHIF (which is the most expressive
description logic we consider in this paper) is referred to simply as SHIF. SHIF is also
the theoretical basis of the Web Ontology Language OWL-Lite (Horrocks, Patel-Schneider,
& van Harmelen, 2003), which makes it an important DL from a practical viewpoint.
For an L -concept C, the set sub(C) consists of C and all its subconcepts. For a concept
C and a TBox T , rol(C, T ) denotes the set of roles occurring in C or T ; and sig(C, T )
denotes the set of concept names and role names occurring in C or T , i.e., the signature
of C and T . We use sig(C) as an abbreviation for sig(C, ). The size of an L -concept C
(L -role R), written |C| (resp. |R|), is the number of occurrences of symbols needed to write
C (resp. R). The size of an L -TBox T , written |T |, is defined analogously. Later on, in
Section 3.3 we will also consider other, more succinct, ways of representing concepts.
There are alternative ways to represent functionality restrictions and transitive roles in
the DL literature. For example, functionality and transitivity axioms of the form funct R
or Trans(R) are sometimes treated as axioms in the TBox. Although such syntactic differences can be considered minor as far as the standard reasoning tasks (cf. Section 2.2)
are concerned, interpolation results are sensitive to changes in the language. For example,
opting for TBox axioms of the form funct R instead of freely allowing  1R as a construct
in the concept language would change the expressive power of languages we consider. In
Section 3.1, we show that ALCF has the interpolation property. The interested reader
is invited to check if our proof can be adapted to the case where we allow functionality
restrictions only as TBox axioms.
2.2 Decision Problems
A concept C is satisfiable with respect to TBox T if there exists a model I of T such that
C I 6= . A CIA C v D follows from a TBox T (denoted by T |= C v D), if every model
of T is a model of C v D. We write T |= C  D if both T |= C v D and T |= D v C hold
true.
The following decision problems will be relevant for us:
 Concept satisfiability with respect to a TBox :
Given C and T , to determine if C is satisfiable w.r.t. T .
 Concept subsumption with respect to a TBox :
Given C v D and T , to determine if T |= C v D.
Both problems are parametrized by a description logic L , in which the input concept(s)
and TBox are specified. The two problems are reducible to each (or, more accurately, to
each others complement) for all the logics we consider, due to the fact that their concept
languages are closed under negation. In fact, both problems are ExpTime-complete for
each of the description logics that we consider (Tobies, 2001).
The same decision problems can also be considered over the restricted class of finite
interpretations, i.e., interpretations whose domain is a finite set. We will refer to these
variants of the above decision problems as finite concept satisfiability and finite concept
subsumption. Thus, finite concept satisfiability with respect to a TBox is the problem of
deciding whether a given concept has a non-empty denotation in some finite model of a
354

fiBeth Definability in Expressive Description Logics

given TBox. It is known (Lutz, Sattler, & Tendera, 2005) that finite concept satisfiability
and finite concept subsumption are also ExpTime-complete for all the description logics we
consider here.
When the finite concept satisfiability problem coincides with the unrestricted satisfiability problem, then we say that the description logic in question has the finite model
property.
Definition 2.1 (Finite model property). A DL L is said to have the finite model property
(FMP) if for every L -concept C and every L -TBox T , if C is satisfiable w.r.t. T , then
there is some finite interpretation I such that I is a model of T and C I 6= .
It is well-known that ALCF I and its extensions lack the finite model property (Calvanese
& Giacomo, 2003).
2.3 First-Order Translation
It is well-known from the correspondence theory of modal/description logics that description
logic concepts can, in general, be translated into first-order logic formulae with one free
variable (Sattler, Calvanese, & Molitor, 2003). In this translation, each concept name A is
viewed as a unary predicate symbol and each role name R is viewed as a binary predicate
symbol of our first-order language. An interpretation, then, corresponds to a first-order
structure.
We assume that the reader is familiar with basic notation and terminology for first-order
logic. In particular, we will use the notation I,  |=  to express that the first-order formula
 is satisfied in the structure I under the first-order variable assignment . Sometimes, it
will be convenient to use a different notation to express the same thing: if (x1 , . . . , xn ) is a
first-order formula whose free variables are x1 , . . . , xn , and if a1 , . . . , an are elements of the
domain of a structure I, we will write I |=  [a1 , . . . , an ] to express that  is satisfied in I
under the variable assignment that sends each variable xi to the corresponding element ai .
Note that this notation implicitly assumes an order on the free variables of , which will
always be clear from the context.
Definition 2.2. The mapping x from SHIF-concepts to first-order formulae is defined
as follows:
x (>) = >,
x (A) = A(x),
x (C) = x (C),
x (C u D) = x (C)  x (D),
x (P.C) = y[P (x, y)  y (C)],
x (P  .C) = y[P (y, x)  y (C)],
x ( 1P ) = z1 z2 [P (x, z1 )  P (x, z2 )  z1 = z2 ],
x ( 1P  ) = z1 z2 [P (z1 , x)  P (z2 , x)  z1 = z2 ],
355

fiTen Cate, Franconi, & Seylan

where y is obtained from the above definition by replacing
all occurrences of x by y and
V
vice versa. For a SHIF-TBox T , (T ) is defined as T (), where
(C v D) = x[x (C)  x (D)]
(R v S) = xy[xy (R)  xy (S)]
where, for P  NR , xy (P ) = P (x, y) and xy (P  ) = P (y, x).
The translation above is model-preserving, i.e., for all SHIF-concepts C, interpretations
I, and first-order assignments  for I, we have (x)  C I iff I,  |= x (C); and similarly
for CIAs, RIAs, and TBoxes.

3. Constructive Interpolation with Tableaux
This section provides a constructive proof of an interpolation property in the DLs we are
interested in. This property will be the essential part of the proof of BP in these DLs (cf.
Definition 4.7). Resorting to interpolation to show the Beth definability property in a logic
has been a standard technique since the seminal work of Craig (1957). We start by defining
this interpolation property.
Definition 3.1 (Interpolation property). A DL L is said to have the interpolation property
if and only if for all L -concepts C1 , C2 and all L -TBoxes T1 , T2 , if T1  T2 |= C1 v C2 ,
then there is some L -concept I such that
 sig(I)  sig(C1 , T1 )  sig(C2 , T2 ),
 T1  T2 |= C1 v I, and
 T1  T2 |= I v C2 .
Such a concept is called an interpolant of C1 and C2 under hT1 , T2 i.
The interpolation property we consider is defined specifically to prove BP. Normally,
the Craig interpolation property for first-order logic is stated as follows: for all first-order
formulae  and , if  |= , then there exists a first-order formula  such that sig() 
sig()  sig(),  |= , and  |= . We can however relate the interpolation property we
consider to first-order Craig interpolation using the standard translation of Definition 2.2.
Given L -concepts C1 , C2 and L -TBoxes T1 , T2 , we have by the standard translation the
following equivalences:
T1  T2 |= C1 v C2
(T1 )  (T2 ) |= x (C1 )  x (C2 )
(T1 )  x (C1 ) |= (T2 )  x (C2 )
Thus, by setting  = (T1 )  x (C1 ) and  = (T2 )  x (C2 ), we know by Craigs
Interpolation Theorem for first-order logic that we always have a first-order interpolant 
for  and , if  |=  (Craig, 1957). However, we do not know in general whether such
an interpolant can be expressed as an L -concept. Because of this reason we will work in
356

fiBeth Definability in Expressive Description Logics

the DL setting instead of full first-order. Our proofs are constructive in the sense that we
present effective procedures for computing the interpolants. This also allows us to establish
upper bounds on the size of interpolants.
This section is organized as follows. In Section 3.1, we show directly that the interpolation property holds for ALC and ALCF using a worst-case optimal tableau (plural:
tableaux) algorithm in the style of Gore and Nguyen (2007). Then in Section 3.2, we show
that the interpolation property also holds in the extensions of ALC and ALCF with transitive and inverse roles. Instead of establishing these results directly using tableaux, we
make use of some satisfiability and signature preserving reductions to ALC and ALCF.
Our main result says that the interpolants in these logics can be computed in double exponential time. In Section 3.3, we study what happens when interpolants are allowed to be
expressed in full first-order logic and show that first-order interpolants can be computed in
single exponential time.
3.1 A Direct Algorithm for Computing Interpolants in ALCF
In this section, we assume that ALCF-concepts are defined recursively as in Section 2.1 using
also , t, R.C, and  2R as primitives, i.e., we assume that, e.g.,  2R is a constructor of
our concept language and not an abbreviation for ( 1R) anymore. Moreover, we assume
that all concepts are in negation normal form (NNF), i.e., the negation occurs only in front
of concept names. It is well-known that every ALCF-concept can easily be transformed
to an equivalent one in NNF by pushing the negation inwards using the dualities between
concept constructors (Tobies, 2001), e.g., R.C and R.C. The NNF of the complement
of a concept C is written as C.

Another assumption we make is that ALCF-TBoxes
consist only of axioms of the form > v C. These assumptions make our tableau notation
more compatible with the standard tableau notation for DLs. More precisely, we want to
have a separate rule for each concept constructor in the language (Horrocks et al., 2000).
The main result we present in this section, namely Theorem 3.10, can easily be shown to
hold in the case where we do not make these assumptions.
Definition 3.2. Let C be an ALCF-concept and let T be an ALCF-TBox. The concept
closure cl(C, T ) of C and T is the smallest set of concepts satisfying the following conditions:
 C  cl(C, T );
 if > v D  T , then D  cl(C, T );
 if D  cl(C, T ) and E  sub(D), then E  cl(C, T );
 if R.D  cl(C, T ) then R.D  cl(C, T ).
For the rest of this section, fix two ALCF-concepts C0 , D0 and two ALCF-TBoxes Tl ,
Tr . We will denote the union Tl  Tr by T . l stands for left and r for right and it is a
naming scheme adopted from Fitting (1996). It will allow us to identify from which TBox
(Tl or Tr ) or concept (C0 or D0 ) an inference is made. A biased concept is an expression of
the form C  , where C is an ALCF-concept and   {l, r} is a bias. Two relevant biased
concept closures cll and clr are defined as follows.
cll = {C l | C  cl(C0 , Tl )} and clr = {C r | C  cl(D
 0 , Tr )}.
357

fiTen Cate, Franconi, & Seylan

We use the Greek letters ,  to denote a bias.
Our tableau rules will be producing subsets of cll  clr in a systematic way. To this aim,
we make use of the metaphor of a burden and relief. Intuitively, a subset  of cll  clr has
a burden if the satisfiability of  depends on the satisfiability of one or more subsets of
cll  clr that we call the reliefs of .
Definition 3.3. Let   cll  clr. Then
 (C1 u C2 ) is an u-burden of  iff (C1 u C2 )   and {(C1 ) , (C2 ) } 6 ;
 (C1 t C2 ) is an t-burden of  iff (C1 t C2 )   and {(C1 ) , (C2 ) }   = ;
 ( 1R) is an  1-burden of  iff ( 1R)   and {(R.C) | (R.C)  } 6 ;
 (R.C) is an -burden of  iff (R.C) is in ;
 ( 2R) is an  2-burden of  iff ( 2R) is in .
A burden of  is any type of burden from above.
Definition 3.4. Let   cll  clr, C  be a burden of , and S = {Dl | > v D  Tl }  {Dr |
> v D  Tr }. Then   cll  clr is called a C  -relief of  if
 C = (C1 u C2 ) and  = {(C1 ) , (C2 ) }  ;
 C = (C1 t C2 ) and either  =   {(C1 ) } or  =   {(C2 ) };
 C = ( 1R) and  =   {(R.C) | (R.C)  };
 C = (R.C) and  = {C  }  {D | (R.D)  }  S;
 C = ( 2R) and  = {D | (R.D)  }  S.
A biased hC0 v D0 , T i-tableau (hC0 v D0 , T i-tableau for short) is a vertex-labeled
directed graph hV, Ei with the labeling content : V  2cllclr . Intuitively, for all edges hg, g 0 i
constructed by our algorithm, g 0 .content will correspond to some C  -relief of g.content. Note
that a tableau is neither required to be a tree nor a directed acyclic graph (DAG) because
cycles may occur in general. We say that a node g in a tableau contains a clash if and only
if either one of the following holds.
   g.content,
 {A , (A) }  g.content,
 {( 1R) , ( 2R) }  g.content.
The tableau expansion rules given in Figure 1 expand a tableau by making use of the
semantics of concepts. A rule is said to be applicable to a node g if and only if its condition
is satisfied in g, no rule was applied to g before, and g does not contain a clash. In order to
guarantee a finite expansion, we use proxies in the following way. Whenever a rule creates
a new node g 0 from g, before attaching the edge hg, g 0 i to E, the tableau is searched for a
358

fiBeth Definability in Expressive Description Logics

The Ru rule
Condition:
Action:
The Rt rule
Condition:
Action:

(C1 u C2 ) is an u-burden of g.content.
E  E  {hg, g 0 i} and g 0 .content  , where  is the (C1 u C2 ) -relief
of g.content.
(C1 t C2 ) is an t-burden of g.content.
E  E  {hg, g1 i, hg, g2 i}, g1 .content  1 , and g2 .content  2 ,
where 1 , 2 are (C1 t C2 ) -reliefs of g.content.

The R1 rule
Condition:
( 1R) is an  1-burden of g.content.
Action:
E  E  {hg, g 0 i} and g 0 .content  , where  is the ( 1R) -relief of
g.content.
The R rule
Condition:
 = {(C1 )1 , . . . , (Cn )n } such that C    iff C  is an - or  2-burden
of g.content.
Action:
E  E  {hg, gi i | 1  i  n} and for 1  i  n,
gi .content  i , where i is the (Ci )i -relief of g.content.
Figure 1: Tableau expansion rules for ALCF
node g 00  V such that g 0 .content = g 00 .content. If such a g 00 is found, then the edge hg, g 00 i
is added to E and g 0 is discarded.
We are interested in deciding T |= C0 v D0 . The tableau algorithm consists of two
phases. The first phase starts with the initial hC0 v D0 , T i-tableau T = h{g0 }, i, where
g0 .content = {(C0 )l , (D
 0 )r }  {E l | > v E  Tl }  {E r | > v E  Tr }. T is then
expanded by repeatedly applying the tableau expansion rules in such a way that if more
than one rule is applicable to a node at the same time, then the first applicable rule in the
list [Ru , Rt , R1 , R ] is chosen. The first phase continues as long as some rule is applicable
to T. A hC0 v D0 , T i-tableau is called complete if and only if it is the output of the first
phase of the tableau algorithm.
Lemma 3.5. The first phase of the tableau algorithm terminates in time 2O(n) , where
n = |cll  clr|. Moreover for the complete hC0 v D0 , T i-tableau T = hV, Ei it produces, we
have |V|  2n and |E|  2O(n) .
Proof. By definition, the first phase continues as long as some rule is applicable to some
node in the tableau. Then by the definition of applicability, we have that at most one rule
is applied to a node in the tableau.
Let n = |cll  clr|. By the definition of a proxy, we have |V|  2n since there are 2n
distinct subsets of cll  clr. Combining this with the fact that there is at most one rule
application per node, we obtain 2n as a bound on the number of rule applications. Now,
it is easy to see that each rule executes in time polynomial in n, i.e., the execution time of
each rule is bounded by nk , where k is a constant. Then we have that the whole running
359

fiTen Cate, Franconi, & Seylan

time of the first phase is 2n  nk . That is,
k

2n  nk = 2n+log n

= 2n+klog n
 2O(n) .
It only remains to show the bound on |E|. By the definition of tableau rules, the out-degree
of a node cannot exceed n. Therefore, |E|  n  2n , i.e., |E|  2O(n) .
Let T be the complete hC0 v D0 , T i-tableau obtained from the first phase of the algorithm. The purpose of the second phase of the tableau algorithm, i.e., Algorithm 1, is to
construct the following functions:
1. status : V  {sat, unsat} is a total function,
2. int is a partial function from V to ALCF-concepts.
For a g  V, the values that are assigned to g by thesedfunctions are denoted by g.status
and int(g). Intuitively, the status of a node g denotes if C  g.content C is satisfiable or not
w.r.t. T ; and int(g), if defined, is an interpolant of g.content in the following sense.
Definition 3.6. Let   cll  clr. A concept I is called an interpolant of  if and only if
F
d
 T |= C l  C v I and T |= I v C r  C
d
F
 sig(I)  sig( C l  C)  sig( C r  C),
By the definition of Algorithm 1, it will be that for all g  V, int(g) is defined if, and only
if, g.status = unsat. In order to compute int(g) for a node g  V with g.status = unsat,
Algorithm 1 uses the interpolant calculation rules that are presented in Figures 2, 3, 4. The
rules in Figure 2 compute int(g) based solely on g.content; ones in Figure 3 take into account
g.content and for some successor g 0 of g, the values g 0 .content and int(g 0 ); and finally, ones
in Figure 4 take into account g.content and for every successor g 0 of g, the values g 0 .content
and int(g 0 ). We invite the reader to verify that, indeed, whenever Algorithm 1 assigns unsat
to g.status, for a node g of the tableau, then there is an interpolant calculation rule that
can be applied to compute int(g). Furthermore, each interpolant calculation rule is easily
seen to be sound. For example, the interpolant calculation rule Cu in Figure 3 is sound
because, if for a successor g 0 of g, g 0 .content is the (C1 u C2 ) -relief of g.content and int(g 0 )
is an interpolant of g 0 .content (in the sense of Definition 3.6) then it is necessarily also an
interpolant of g.content.
Let T = hV, Ei be a complete hC0 v D0 , T i-tableau which is an output of the second
phase. T is said to be open if and only if g0 .status = sat; and it is said to be closed if and
only if g0 .status = unsat. If T is determined to be open after the second phase, then the
tableau algorithm returns T 6|= C0 v D0 , otherwise it returns T |= C0 v D0 .
The next three results establish some important properties of our tableau algorithm and
we use them to prove Theorem 3.10. The proofs of these results require the introduction
of standard but substantial amount of notation from the DL and modal logic literature. In
order to present Theorem 3.10 more clearly, we defer these proofs to Appendix C.
360

fiBeth Definability in Expressive Description Logics

Algorithm 1 Second phase of the tableau algorithm
Propagate:
do
 done  true.
 For every g  V with g.status 6= unsat:
 if g contains a clash, then
1. g.status  unsat,
lr
rl
2. apply one of {Cl , Cr , Cll , Crr
 , C , C }, one whose condition is satisfied, to
calculate int(g),
3. done  false.
 if g 0  V with hg, g 0 i  E, g 0 .status = unsat, and g 0 .content is some (C1 u C2 ) -,
( 1R) -, (R.C) , or ( 2R) -relief of g.content, then
1. g.status  unsat,
r6R
R
R
l6R
rR
lR
rR
2. apply one of {Cu , Cl61
, Cr61
, ClR
1 , C1 , C , C , C , C }, one whose condition is satisfied, to calculate int(g),
3. done  false.
 if g1 , g2  V with g1 6= g2 , hg, g1 i, hg, g2 i  E, gi .status = unsat for each
i  {1, 2}, gi .content is a (C1 t C2 ) -relief of g.content for each i  {1, 2}, then
1. g.status  unsat,
2. apply one of {Clt , Crt }, one whose condition is satisfied, to calculate int(g),
3. done  false.
while done = false.
Assign:
For every g  V with g.status 6= unsat, g.status  sat.

361

fiTen Cate, Franconi, & Seylan

The Cl rule
Condition:
Action:
The Cr rule
Condition:
Action:
The Cll rule
Condition:
Action:
The Crr
 rule
Condition:
Action:
The Clr
 rule
Condition:
Action:
The Crl
 rule
Condition:
Action:

l  g.content.
int(g)  
r  g.content.
int(g)  >
{C l , (C)
 l }  g.content, for a C of the form A or  1R.
int(g)  
{C r , (C)
 r }  g.content, for a C of the form A or  1R.
int(g)  >
{C l , (C)
 r }  g.content, for a C of the form A or  1R.
int(g)  C
{C r , (C)
 l }  g.content, for a C of the form A or  1R.
int(g)  C


Figure 2: Interpolant calculation rules for ALCF (content dependent rules)
Lemma 3.7. Let T = hV, Ei be the output of the second phase. For all g  V, if g.status =
unsat, then
1. g.content is unsatisfiable w.r.t. T ;
2. int(g) is defined and it is an interpolant of g.content; and
n

3. |int(g)|  O(22 ), where n = |cll  clr|.
The next lemma establishes a double exponential upper bound for the runtime of Algorithm 1. This is a consequence of interpolant calculation and our double exponential upper
bound on the size of these interpolants (cf. Lemma 3.7).
Lemma 3.8. The second phase of the tableau algorithm, i.e., Algorithm 1, runs in time
n
O(22 ), where n = |cll  clr|.
The next proposition establishes the soundness and the completeness of our algorithm
for concept subsumption w.r.t. TBoxes in ALCF.
Proposition 3.9. T is a closed hC0 v D0 , T i-tableau if and only if T |= C0 v D0 .
The tableau algorithm we presented in this section with the two phases is actually
an algorithm to compute interpolants of at most double exponential size in ALCF. This
upper bound is optimal because the results we establish in Section 4 imply that smallest
interpolants can be of double exponential size.
362

fiBeth Definability in Expressive Description Logics

The Cu rule
Condition:
g 0 .content is the (C1 u C2 ) -relief of g.content.
Action:
int(g)  int(g 0 ).
R
The Cl61
rule
Condition:
g 0 .content is the ( 1R)l -relief of g.content and
there is no biased concept of the form (R.C)r  g.content.
Action:
int(g)  int(g 0 ).
r6R
The C1 rule
Condition:
g 0 .content is the ( 1R)r -relief of g.content and
there is no biased concept of the form (R.C)l  g.content.
Action:
int(g)  int(g 0 ).
lR
The C1 rule
Condition:
g 0 .content is the ( 1R)l -relief of g.content and
there is some biased concept of the form (R.C)r  g.content.
Action:
int(g)  int(g 0 )u  1R.
The CrR
1 rule
Condition:
g 0 .content is the ( 1R)r -relief of g.content and
there is some biased concept of the form (R.C)l  g.content.
Action:
int(g)  int(g 0 )t  2R.
l6R
The C rule
Condition:
g 0 .content is the (R.C)l - or ( 2R)l -relief of g.content,
there is no biased concept of the form (R.D)r  g.content.
Action:
int(g)  .
The Cr6R rule
Condition:
g 0 .content is the (R.C)r - or ( 2R)r -relief of g.content,
there is no biased concept of the form (R.D)l  g.content.
Action:
int(g)  >.
The ClR
rule

Condition:
g 0 .content is the (R.C)l - or ( 2R)l -relief of g.content,
there is some biased concept of the form (R.D)r  g.content.
Action:
int(g)  R.int(g 0 ).
The CrR
 rule
Condition:
g 0 .content is the (R.C)r - or ( 2R)r -relief of g.content,
there is some biased concept of the form (R.D)l  g.content.
Action:
int(g)  R.int(g 0 ).
Figure 3: Interpolant calculation rules for ALCF (single successor dependent rules)
Theorem 3.10. For all ALCF-concepts C, D and all ALCF-TBoxes T1 , T2 if T1  T2 |=
C v D then there exists an interpolant of C and D under hT1 , T2 i that can be computed in
time double exponential in |T1 | + |T2 | + |C| + |D|.
Proof. Suppose C, D are ALCF-concepts and T1 , T2 , and T are ALCF-TBoxes such that
T1  T2 = T and T |= C v D. Then by Proposition 3.9, there is a closed hC v D, T i363

fiTen Cate, Franconi, & Seylan

The Clt rule
Condition:
Action:
The Crt rule
Condition:
Action:

g1 .content, g2 .content are (C1 t C2 )l -reliefs of g.content.
int(g)  int(g1 ) t int(g2 ).
g1 .content, g2 .content are (C1 t C2 )r -reliefs of g.content.
int(g)  int(g1 ) u int(g2 ).

Figure 4: Interpolant calculation rules for ALCF (multiple successor dependent rules)
tableau T = hV, Ei. This means g0 .status = unsat, and thus by Lemma 3.7, there is
some d
ALCF-concept I suchFthat int(g0 ) = I and I is an interpolant of g0 .content. Let
X = >vET1 E and Y = >vET2 E. Since I is an interpolant of g0 .content, we have
T |= C u X v I, T |= I v D t Y , and sig(I)  sig(C u X)  sig(D t Y ). Then by the
fact that T |= X  > and T |= Y  , we obtain T |= C v I and T |= I v D; and by
sig(I)  sig(C u X)  sig(D t Y ), we obtain sig(I)  sig(C, T1 )  sig(D, T2 ). Hence I is an
interpolant of C and D under hT1 , T2 i. Finally by Lemma 3.8, I can be computed in time
double exponential in |T1 | + |T2 | + |C| + |D|.
We end this section with a discussion of the techniques we used. The tableau algorithm
we defined is based on a tableau algorithm by Gore and Nguyen (2007). Here we extended
this algorithm for ALCF and added more machinery to compute interpolants. In general
interpolation follows as a corollary to a cut-free sequent or tableau calculus1 for a logic (e.g.,
see Rautenberg, 1983; Fitting, 1996; Kracht, 2007); but such a corollary does not give upper
bounds on the size and computation time of interpolants unless the calculus is combined
with a decision procedure. In this section, our goal was to obtain tight upper bounds on the
size and computation time of interpolants in ALCF. More traditional tableau algorithms
for DLs, e.g., the one by Horrocks et al. (2000), can also be used to establish similar results
(Seylan et al., 2009). Here the crucial idea is that the tableau algorithm should provide
an explicit representation of the tableau rule applications so that an interpolant can be
calculated by induction on the rule applications. We chose a non-traditional DL tableau
algorithm for our purposes because it is based on a non-labeled2 tableau calculus and such
calculi are actually more commonly used for proving interpolation results in modal logics
(e.g., Rautenberg, 1983).
3.2 Extending Interpolation to Transitive and Inverse Roles
In this section, we extend Theorem 3.10 to more logics in order to obtain our main interpolation result Theorem 3.22. To this aim, we present various polynomial reductions from
reasoning in one DL to another. The purpose of these reductions is to eliminate some constructors in the language. The technique we use for these reductions is well-known in the DL
literature and it is called the axiom schema instantiation technique (Calvanese, Giacomo,
& Rosati, 1998; Calvanese, Giacomo, Lenzerini, & Nardi, 2001). Similar techniques also
1. A tableau calculus is defined as a set of tableau rules.
2. A non-labeled tableau calculus provides no explicit representation of individuals in the interpretations.

364

fiBeth Definability in Expressive Description Logics

appear in modal logic (Kracht, 2007). The idea behind this technique can be summarized
as follows.
DLs are syntactic variants of modal logics. It is well-known that an axiom schema that
is valid in a modal logic corresponds to a certain condition on the accessibility relation in the
frames of that logic (Blackburn, de Rijke, & Venema, 2001). For example the axiom schema
4 : 2  22 defines the class of transitive frames. The axiom schema instantiation
technique is based on instantiating an axiom schema a finite number of times for each
concept in cl or a relevant concept closure, and adding these instances to the TBox to
obtain an equi-satisfiable TBox. The resulting TBox will then be free of the constructor in
the language for which we instantiated the axiom schema.
We note that the input in these reductions is normally a concept and a TBox; but
for interpolation, we are given a pair of concepts C1 , C2 and a pair of TBoxes T1 , T2 .
Therefore, we require from these reductions that they do not mix the signature of sig(C1 , T1 )
and sig(C2 , T2 ) in an uncontrolled way. What exactly we mean by this will be clear in
Lemma 3.14 and Lemma 3.19. Naturally, this calls for extra notation.
Definition 3.11. An injective function  : X  NR , where X is a finite subset of NR 
{P  | P  NR }, is called a role renaming if for all P  NR , we have {P, P  } 6 X. A role
renaming  is called safe for a signature  if range()   = .
Given an L -concept C and a role renaming , Z (C) is the concept obtained from C by
replacing every occurrence of every R  dom() by (R).
Intuitively, we use role renamings, as the name suggests, to rename roles in concepts. We
need to make sure that the renaming operation is well-defined and thus, we avoid mappings
where a role and its inverse are in the domain of the mapping. Safeness of the mapping
w.r.t. a signature is a property that we desire in the following reductions. We start with
transitive roles and thus, instantiate the axiom schema 2  22.
Definition 3.12. Let C0 be a SIF-concept, T be a SIF-TBox, and  be a safe role
renaming for sig(C0 , T ) with dom() = sig(C0 , T )  NR+ and range()  NR+ = . Then
S (C0 , T , ) is defined as the ALCF I-TBox S1 (C0 , T , )S2 (C0 , T , ), where S1 (C0 , T , ) =
{> v Z (C) | > v C  T } and
S2 (C0 , T , ) = {Z (R.C) v Z (R.R.C) | R.C  cl(C0 , T ) and {R, R }  NR+ 6= }
Note that in the definition above, the signature of the resulting ALCF I-TBox will not be
equal to the signature of the original SIF-TBox T if C0 or T contains transitive roles.
Introducing these new non-transitive role names is necessary because we are not allowed
to use symbols from NR+ in logics without transitive roles (cf. Section 2.1). Although the
formulation of the following proposition is slightly different from the one of Lemma 6.23 by
Tobies (2001), the proof idea is the same.
Proposition 3.13. A SIF-concept C0 is satisfiable w.r.t. a SIF-TBox T if and only if
the ALCF I-concept Z (C0 ) is satisfiable w.r.t. the ALCF I-TBox S (C0 , T , ), where  is a
safe role renaming for sig(C0 , T ) with dom() = sig(C0 , T )  NR+ and range()  NR+ = .
The reduction (for concept satisfiability w.r.t. TBoxes) in Definition 3.12 satisfies the
following property that will be essential for extending our interpolation results to logics
365

fiTen Cate, Franconi, & Seylan

with transitive roles. In this respect, it also resembles the splitting reduction functions of
Kracht (2007).
Lemma 3.14. Let T1 , T2 be SIF-TBoxes and let C1 , C2 be SIF-concepts. Then
T1  T2 |= C1 v C2 iff S (C1 , T1 , )  S (C
 2 , T2 , ) |= Z (C1 ) v Z (C2 )
where  is a safe role renaming for sig(C1 u C
 2 , T1  T2 ) with dom() = sig(C1 u C
 2 , T1 
T2 )  NR+ and range()  NR+ = .
Proof. Let  be a safe role renaming for sig(C1 u C
 2 , T1  T2 ) as specified in the lemma.
We will use the following claims for the proof.
Claim 3.15. S (C1 u C
 2 , T1  T2 , ) = S (C1 u C
 2 , T1 , )  S (C1 u C
 2 , T2 , ).
Proof of claim. () Suppose C v D  S (C1 u C
 2 , T1  T2 , ). Then either C v D 
2
1
 2 , T1  T2 , ). If the former holds, then we
 2 , T1  T2 , ) or C v D  S (C1 u C
S (C1 u C
immediately obtain the desired result; thus, suppose the latter holds. Then C v D is of the
form Z (R.C) v Z (R.R.C), R.C  cl(C1 u C
 2 , T1  T2 ), and {R, R }  NR+ 6= . By
Definition 3.2 and R.C  cl(C1 u C
 2 , T1  T2 ), we obtain R.C is in cl(C1 u C
 2 , T1 ) or
cl(C1 u C
 2 , T2 ). Then by Definition 3.12 and the fact that either R  NR+ or R  NR+ ,
we have that Z (R.C) v Z (R.R.C)  S (C1 u C
 2 , T1 , )  S (C1 u C
 2 , T2 , ), which
is what we wanted to show.
() It is rather easy to see that this direction of the claim holds.

a

Claim 3.16. S (C1 u C
 2 , T1 , )  S (C1 u C
 2 , T2 , ) = S (C1 , T1 , )  S (C
 2 , T2 , ).
Proof of claim. () Suppose C v D  S (C1 , T1 , )  S (C
 2 , T2 , ). The desired result
0
follows immediately if C v D = > v Z (C ), for some > v C 0  T1 T2 . Otherwise, we have
by Definition 3.12 that C v D is of the form Z (R.C) v Z (R.R.C), R.C  cl(C1 , T1 )
cl(C
 2 , T2 ) and either R  NR+ or R  NR+ . Then by R.C  cl(C1 , T1 )  cl(C
 2 , T2 )
and cl(C1 , T1 )  cl(C
 2 , T2 )  cl(C1 u C
 2 , T1 )  cl(C1 u C
 2 , T2 ), we obtain R.C  cl(C1 u
C
 2 , T1 )  cl(C1 u C
 2 , T2 ). Then by Definition 3.12 and the fact that either R  NR+ or

R  NR+ , we have Z (R.C) v Z (R.R.C)  S (C1 u C
 2 , T1 , )  S (C1 u C
 2 , T2 , ),
which is what we wanted to show.
() Suppose C v D  S (C1 u C
 2 , T1 , )  S (C1 u C
 2 , T2 , ). The desired result follows
immediately if C v D = > v Z (C 0 ), for some > v C 0  T1  T2 . Otherwise, we have
by Definition 3.12 that C v D is of the form Z (R.C) v Z (R.R.C), R.C  cl(C1 u
C
 2 , T1 )  cl(C1 u C
 2 , T2 ), and either R  NR+ or R  NR+ . Then by R.C  cl(C1 u
C
 2 , T1 )  cl(C1 u C
 2 , T2 ), the fact that C1 u C
 2 6= R.C, and Definition 3.2, we obtain
R.C  cl(C1 , T1 )  cl(C
 2 , T2 ). Then by Definition 3.12 and the fact that either R  NR+
or R  NR+ , we have Z (R.C) v Z (R.R.C)  S (C1 , T1 , )  S (C
 2 , T2 , ), which is
what we wanted to show.
a
Now the lemma can be shown in the following way.
 T1  T2 |= C1 v C2 , iff
366

fiBeth Definability in Expressive Description Logics

 C1 u C
 2 is unsatisfiable w.r.t. T1  T2 , iff
 Z (C1 u C
 2 ) is unsatisfiable w.r.t. S (C1 u C
 2 , T1  T2 , ) (Proposition 3.13), iff
 Z (C1 u C
 2 ) is unsatisfiable w.r.t. S (C1 u C
 2 , T1 , )  S (C1 u C
 2 , T2 , ) (first
claim), iff
 Z (C1 u C
 2 ) is unsatisfiable w.r.t. S (C1 , T1 , )  S (C
 2 , T2 , ) (second claim), iff
 S (C1 , T1 , )  S (C
 2 , T2 , ) |= Z (C1 ) v Z (C2 ).

We need a similar reduction to eliminate inverse roles. De Giacomo (1996) presents a
method to reduce converse-PDL satisfiability to PDL satisfiability using the axiom schema
instantiation technique. Since DLs are notational variants of PDLs, this technique can
easily be adapted to DLs as done by Calvanese et al. (1998, 2001). The idea is to instantiate
the converse-PDL axiom schemas   []h i and   [ ]hi.
Definition 3.17. Let C0 be an ALCF I-concept, let T be an ALCF I-TBox, and  be
a safe role renaming for sig(C0 , T ) with dom() consisting of all inverse roles appearing
in C0 or T , and range()  NR+ = . Then I (C0 , T , ) is defined as the ALCF-TBox
I1 (C0 , T , )  I2 (C0 , T , ), where I1 (C0 , T , ) = {> v Z (C) | > v C  T } and
I2 (C0 , T , ) = {Z (C)

v Z (R .R.C)

| R.C  cl(C0 , T )}
Note that in the definition above, the signature of the resulting ALCF-TBox will not be
equal to the signature of the original ALCF I-TBox T if C0 or T contains inverse roles.
Proposition 3.18 establishes the correctness of this reduction for concept satisfiability w.r.t.
TBoxes. A full proof of this proposition is given by Seylan (2012).
Proposition 3.18. An ALCF I-concept C0 is satisfiable w.r.t. an ALCF I-TBox T if and
only if the ALCF-concept Z (C0 ) is satisfiable w.r.t. the ALCF-TBox I (C0 , T , ), where 
is a safe role renaming for sig(C0 , T ) with dom() consisting of all inverse roles appearing
in C0 or T and range()  NR+ = .
The following property of this reduction will be useful in our interpolation results.
Lemma 3.19. Let T1 , T2 be ALCF I-TBoxes and let C1 , C2 be ALCF I-concepts. Then
T1  T2 |= C1 v C2 iff I (C1 , T1 , )  I (C
 2 , T2 , ) |= Z (C1 ) v Z (C2 )
where  is a safe role renaming for sig(C1 u C
 2 , T1  T2 ) with dom() consisting of all
inverse roles appearing in C1 u C
 2 or T1  T2 and range()  NR+ = .
Proof. The following claims can be shown analogously to Claim 3.15 and Claim 3.16, respectively.
Claim 3.20. I (C1 u C
 2 , T1  T2 , ) = I (C1 u C
 2 , T1 , )  I (C1 u C
 2 , T2 , ).
Claim 3.21. I (C1 u C
 2 , T1 , )  I (C1 u C
 2 , T2 , ) = I (C1 , T1 , )  I (C
 2 , T2 , ).
367

fiTen Cate, Franconi, & Seylan

Then the argument is the same as the last step in the proof of Lemma 3.14.
Theorem 3.22. Let L be ALC or any of its extensions with constructors from {S, I, F}.
For all L -concepts C1 , C2 and all L -TBoxes T1 , T2 , if T1  T2 |= C1 v C2 , then there exists
an interpolant of C1 and C2 under hT1 , T2 i that can be computed in time double exponential
in |T1 | + |T2 | + |C1 | + |C2 |.
Proof. Theorem 3.10 already covers the case for L = ALCF.
For L = ALC. The tableau algorithm for ALCF (with which we proved Theorem 3.10)
can be used without modification to decide concept satisfiability w.r.t. a TBox in ALC.
In other words, given ALC-concepts C1 , C2 and an ALC-TBox T = T1  T2 , we can check
if T |= C1 v C2 using the same algorithm. Observe that during the execution of the
algorithm, R1 will never be applied and there will be no clashes involving a concept of the
form  1R. If the algorithm constructs a closed hC1 v C2 , T i-tableau, then the interpolant
calculation algorithm will calculate an interpolant in ALCF. Since R1 was never applied
in the first phase and there is no clash involving a concept of the form  1R in the resulting
tableau, the interpolant calculation rules producing concepts of the form  1R or  2R,
rR
namely ClR
1 , C1 , and the ones in Figure 2, will never be applied in the second phase. Hence
the resulting interpolant is actually an ALC-concept. That there is always an interpolant
if T1  T2 |= C1 v C2 and the double exponential upper bound on its computation time can
be shown as in Theorem 3.10.
For L  {ALCI, ALCF I}. Let C1 , C2 be L -concepts and T1 , T2 be L -TBoxes such
that T1  T2 |= C1 v C2 . Let  be a role renaming as specified in Lemma 3.19: such a role
renaming always exists. Then by Lemma 3.19, I (C1 , T1 , )  I (C
 2 , T2 , ) |= Z (C1 ) v
Z (C2 ), where C1 , C2 are ALC-concepts (ALCF-concepts) and I (C1 , T1 , ), I (C
 2 , T2 , )
are ALC-TBoxes (respectively ALCF-TBoxes). We compute an interpolant I of Z (C1 )
and Z (C2 ) under hI (C1 , T1 , ), I (C
 2 , T2 , )i in time that is at most double exponential
in the size of the input. We have
1. sig(I)  sig(Z (C1 ), I (C1 , T1 , ))  sig(Z (C2 ), I (C
 2 , T2 , )),
2. I (C1 , T1 , )  I (C
 2 , T2 , ) |= Z (C1 ) v I,
3. I (C1 , T1 , )  I (C
 2 , T2 , ) |= I v Z (C2 ).
Let 1 be the restriction of  to rol(C1 , T1 ) and 2 be the restriction of  to rol(C
 2 , T2 );
and set 1 = range(1 ) and 2 = range(2 ). Intuitively, 1 and 2 are exactly the sets of
new role names we introduced in I (C1 , T1 , ) and I (C
 2 , T2 , ), respectively. It is easy
to see that sig(Z (C1 ), I (C1 , T1 , ))  sig(C1 , T1 )  1 , and sig(Z (C2 ), I (C
 2 , T2 , )) 
sig(C2 , T2 )  2 . Then by item 1 above, we have
sig(I)  (sig(C1 , T1 )  1 )  (sig(C2 , T2 )  2 )
By a simple distributivity argument, we obtain
sig(I)  (sig(C1 , T1 )  sig(C2 , T2 ))  (1  2 ) 
(sig(C1 , T1 )  2 )  (sig(C2 , T2 )  1 )
368

fiBeth Definability in Expressive Description Logics

Since sig(C1 , T1 )  2 =  and sig(C2 , T2 )  1 = ,
sig(I)  (sig(C1 , T1 )  sig(C2 , T2 ))  (1  2 )
Now let D be the L -concept that is obtained from I by replacing all occurrences of each
role name P  1  2 by the only role R such that (R ) = P . Since  is injective, this
is well defined. Moreover, we have Z (D) = I.
We claim that for every P  1  2 , the role name R with (R ) = P is in sig(C1 , T1 ) 
sig(C2 , T2 ). Suppose P  1  2 . Then P  range(1 )  range(2 ). Since 1 and 2
are defined as restrictions of  to rol(C1 , T1 ) and rol(C2 , T2 ), respectively, there is some
R  rol(C1 , T1 )  rol(C2 , T2 ) such that (R ) = P . But then R  sig(C1 , T1 )  sig(C2 , T2 ).
Now by the claim we have just shown, sig(I)  (sig(C1 , T1 )  sig(C2 , T2 ))  (1  2 ), and
the construction of D, we have sig(D)  sig(C1 , T1 )  sig(C2 , T2 ). Moreover, by Z (D) = I,
items 2 and 3 above, and Lemma 3.19, we obtain T1  T2 |= C1 v D and T1  T2 |= D v C2 .
Hence D is an interpolant of C1 and C2 under hT1 , T2 i. It is easy to see that the time
required to compute D is as stated in the theorem.
For L  {S, SI, SF, SIF}. In what follows, let L 0 be L without the transitive role
constructor, e.g., if L = SIF, then L 0 = ALCF I. We know by now that L 0 satisfies what
is stated in the theorem. Suppose that C1 , C2 are L -concepts and T1 , T2 are L -TBoxes
such that T1  T2 |= C1 v C2 . The proof proceeds analogously to the inverse role case,
except of course we use Lemma 3.14.
To conclude, we have shown for each logic L stated in the theorem a constructive way
to compute an interpolant, if one exists, in time double exponential in the size of the input.
Hence the theorem follows.
3.3 Shorter First-Order Interpolants
We will now show that our interpolation algorithm can be adapted to compute first-order
interpolants in single exponential time. The proof will proceed along the following lines.
First we will show that the double exponential size of the interpolants is only due to the
repeated occurrence of subformulas and that our algorithm yields single exponential size
interpolants using a succinct (DAG-shaped as opposed to tree-shaped) concept representation. Next we apply an idea implicit in the work of Avigad (2003), namely that succinctly
represented first-order formulas can be transformed in polynomial time into equivalent ordinary tree-shaped first-order formulas over structures with at least two elements. This
allows us to compute single exponential first-order interpolants over structures with at least
two elements. After that, we show that single exponential interpolants over structures with
one element can be constructed by a reduction to propositional logic. By combining the interpolants obtained via these two methods, we finally obtain the desired single exponential
first-order interpolant over arbitrary structures.
Step 1: Singly-exponential interpolants via succinct representation We start by
defining the notions that will allow us to represent DAG-shaped concepts.
Definition 3.23. Fix a description logic L . An axiom of the form A  C, where A  NC
and C is an L -concept, is called a concept definition axiom in L (or, an L -CDA). Let 
369

fiTen Cate, Franconi, & Seylan

be a signature. An acyclic terminology over  in L is a set of L -CDAs
T = {A1  C1 , . . . , An  Cn }
where {A1 , . . . , An }   =  and sig(Ci )    {A1 , . . . , Ai1 } for i  {1, . . . , n}.
A succinct-L -concept over  is a pair hA, T i, where T is an acyclic terminology over
 in L and A is a concept name belonging to sig(T ) \ . The unfolding of a succinct-L concept hA, T i is the L -concept over  that is obtained from A by repeatedly applying
the CDAs in T , i.e., replacing occurrences of their left-hand side by their right-hand side,
until no more CDA can be applied.
Note that acyclic terminologies are well-known in the DL literature (Baader & Nutt,
2003).
Example 3.24. Let T consist of the following.
Woman  Person u Female
Man  Person u Male
Human  Woman t Man
Then T is an acyclic terminology over {Person, Female, Male}. The unfolding of the succinctconcept hHuman, T i is
(Person u Female) t (Person u Male).
The unfolding of a succinct-concept is in general exponentially longer.
Proposition 3.25. Let L be any description logic. For each succinct-L -concept hA, T i
O(1)
with unfolding C, |C|  2|T | .
Theorem 3.26. Let L be ALC or any of its extensions with constructors from {S, I, F}.
For all L -concepts C1 , C2 and all L -TBoxes T1 , T2 , if T1  T2 |= C1 v C2 , then there exists
a succinct-L -concept hA, T i over sig(C1 , T1 )  sig(C2 , T2 ) such that
 the unfolding of hA, T i is an interpolant of C1 and C2 under hT1 , T2 i, and
 hA, T i can be computed in time single exponential in |T1 | + |T2 | + |C1 | + |C2 |.
Proof. Let L be one of the DLs mentioned in the theorem, let T1  T2 |= C1 v C2 , where
T1 , T2 are L -TBoxes and C1 , C2 are L -concepts, and let m = |T1 | + |T2 | + |C1 | + |C2 |. As
in the proof of Theorem 3.22, we first reduce T1  T2 |= C1 v C2 to T10  T20 |= D1 v D2 ,
where T10 , T20 are ALC-TBoxes (ALCF-TBoxes) and D1 , D2 are ALC-concepts (resp. ALCFconcepts).
We show that the interpolant calculation step in Algorithm 1 for ALCF (and thus ALC,
see Figures 2, 3, 4) can be modified to compute a succinct-concept of single exponential size
as an interpolant, instead of a concept.
We associate to every node g in the tableau a distinct fresh concept name Xg . The
new algorithm still uses the same interpolation calculation rules but instead of directly
assigning an interpolant to every node g with g.status = unsat, we construct an acyclic
terminology T 0 over sig(D1 , T10 )  sig(D2 , T20 ), where the acyclic terminology makes use of
370

fiBeth Definability in Expressive Description Logics

the new concept names Xg , and such that the unfolding of the succinct-concept hXg , T 0 i is
an interpolant for g.content whenever g.status = unsat. The set T 0 is initialized as an empty
set, and throughout the computation of the algorithm, T 0 is extended in the natural way.
For instance, suppose Clt is applied to g. Then Clt adds to T 0 the CDA Xg  Xg1 t Xg2 ,
where g1 and g2 are the successors of the node g in the tableau. Another example is a
l 
r }  g.content. Then Clr adds to
clash rule. Suppose Clr
 is applied to g for some {C , (C)

0
0
T the CDA Xg  C. By Lemma 3.5, it follows that |T |  2O(m) ; and by the definition
of Algorithm 1, it follows that T 0 is an acyclic terminology over sig(D1 , T10 )  sig(D2 , T20 ).
Moreover, by T10  T20 |= D1 v D2 , there is some Xg0  C  T 0 . Then hXg0 , T 0 i is a
succinct-concept over sig(D1 , T10 )  sig(D2 , T20 ) and its unfolding can easily be shown to be
an interpolant of D1 and D2 under T10  T20 .
In a way similar to the proof of Theorem 3.22, i.e., by replacing back the newly introduced role names for inverse and transitive roles in T 0 with the originals, we obtain a new
terminology T 00 . Then the unfolding of hXg0 , T 00 i is guaranteed to be an interpolant of C1
and C2 under hT1 , T2 i. Moreover, hXg0 , T 00 i is of size single exponential in m.
For the rest of the section, our purpose is to obtain an equivalent first-order formula from
a given succinct-concept in polynomial time. We will make use of the standard translation
(see Definition 2.2). In the following, we will not distinguish between DL interpretations
and first-order structures (we choose the unary and binary predicates of our first-order
language to be the symbols in NC and NR , respectively).
Step 2: Singly-exponential FO interpolants for interpretations with two elements For a first-order formula (x) and an interpretation I = hI , I i with s  I , we
write I, s |= (x) if and only if there is some first-order assignment  such that (x) = s
and I,  |= (x). By |=2 , we denote the restriction of the relation |= that only considers
interpretations I = hI , I i where |I |  2. Similarly, by |==1 , we denote the restriction
of the relation |= that only considers interpretations I = hI , I i where |I | = 1.
The proof of the following theorem is inspired by a result of Avigad (2003), which
states that, over structures with at least two elements, one can efficiently eliminate acyclic
definitions from proofs. Theorem 3.27 can be viewed as an adaptation of this result to the
first-order translation of succinct-concepts in description logic.
Theorem 3.27. Given a succinct-SHIF-concept hB, T i over a signature , we can construct in polynomial time a first-order formula (x) over , such that |=2 (x)  x (C),
where C is the unfolding of hB, T i.
Our proof of Theorem 3.27 will be based on a lemma that we state next. For expository
reasons, it is more convenient to state the lemma in terms of structures with constant
symbols. These constant symbols are not needed for Theorem 3.27. They are only used to
make the statement and proof of the following lemma more readable.
Lemma 3.28. Given an acyclic terminology T = {A1  C1 , . . . , An  Cn } in SHIF, we
can construct in polynomial time a first-order formula T (x, y1 , . . . , yn , z) with additional
constant symbols 0 and 1, such that, for all interpretations I satisfying 0I 6= 1I , and for
all elements a, ~b, c  I (where ~b = b1 , . . . , bn ),
371

fiTen Cate, Franconi, & Seylan

I |= T

(
1I
[a, ~b, c] if and only if ~b = k for some k  {1, . . . , n}, and c =
0I

if a  CkI
otherwise

I
  0I} 1I |0I {z
where k = 0
  0I} and Ck is the unfolding of the succinct-concept hAk , T i.
| {z
k1 times

nk times

Proof. We define T by induction on the number n of CDAs in T . If n = 1, then we can
simply define T (x, y, z) as
T (x, y, z) = (y = 1)  ((x (C1 )  z = 1)  (x (C1 )  z = 0))
Now, let n > 1 and let T 0 be obtained from T by removing the last CDA. In other words,
let T = T 0  {An  Cn }. By induction hypothesis, there is a formula T 0 (u, ~v , w) satisfying
the required conditions w.r.t. T 0 (where ~v = v1 , . . . , vn1 ). We can distinguish the following
cases:
1. Cn is an atomic concept or functionality restriction over the signature . In this case,
we can define T as follows, where ~y = y1 . . . yn and ~v = v1 . . . vn1 .
T (x, ~y , z) = u, ~v , w(T 0 (u, ~v , w)  x = u  ~y = ~v 0  z = w) 
(~y = 0    01  ((x (Cn )  z = 1)  (x (Cn )  z = 0))))
V
Here, ~y = ~v 0 is a shorthand for the formula
i<n yi = vi  yn = 0, and, similarly,
V
~y = 0    01 is shorthand for the formula i<n yi = 0  yn = 1.
2. Cn is of the form Ai with i < n. In this case, we can define T as follows:
T (x, ~y , z) = u, ~v , w T 0 (u, ~v , w) 
((x = u  ~y = ~v 0  z = w) 

(~y = 0    01  u = x  ~v = i  ((w = 1  z = 0)  (w = 0  z = 1))))
Here, the same notation conventions apply as in V
the previous item. In addition, ~v = i
is used as a shorthand for the formula vi = 1  j6=i vj = 0. The notations will also
be used in the following items.
3. Cn is of the form Ai uAj with i, j < n. As a first attempt, define T (x, ~y , z) as follows:
T (x, ~y , z) = u, ~v , w u0 , ~v 0 , w0 T 0 (u, ~v , w)  T 0 (u0 , ~v 0 , w0 ) 
((x = u  ~y = ~v 0  z = w) 
(~y = 0    01  u = u0 = x  ~v = i  ~v 0 = j 

(w = w0 = z = 1  ((w = 0  w0 = 0)  z = 0))))
This works, except for the fact that T 0 occurs twice in the formula, which may
result in an exponential blowup. We solve this problem by replacing the conjunction
T 0 (u, ~v , w)  T 0 (u0 , ~v 0 , w0 ) by
u00 , ~v 00 , w00 ((u00 = u~v 00 = vw00 = w)(u00 = u0 ~v 00 = v 0 w00 = w0 )  T 0 (u00 , ~v 00 , w00 ))
372

fiBeth Definability in Expressive Description Logics

4. Cn is of the form P.Ai with i < n. This is the most difficult case. The following
formula expresses the required property:
T (x, ~y , z) = u, ~v , w T 0 (u, ~v , w) 
((x = u  ~y = ~v 0  z = w) 
(~y = 0    01  z = 1  P xu  ~v = i  w = 1) 
(~y = 0    01  z = 0

u0 , ~v 0 , w0 (T 0 (u0 , ~v 0 , w0 )  P xu0  ~v 0 = i  w0 = 0)))
However, as before, this formula still has the problem that it contains two copies of
T 0 . We fix this in two steps. First, we bring the universal quantifiers to the front,
and transform the above formula into the following equivalent formula:
u, ~v , w u0 , ~v 0 , w0 T 0 (u, ~v , w)  T 0 (u0 , ~v 0 , w0 ) 
((x = u  ~y = ~v 0  z = w) 
(~y = 0    01  z = 1  P xu  ~v = i  w = 1)  
(~y = 0    01  z = 0  (P xu0  ~v 0 = i  w0 = 0)))
Finally, as before, we replace the conjunction T 0 (u, ~v , w)  T 0 (u0 , ~v 00 , w0 ) by
u00 , ~v 00 , w00 ((u00 = u~v 00 = vw00 = w)(u00 = u0 ~v 00 = v 0 w00 = w0 )  T 0 (u00 , ~v 00 , w00 ))
5. Cn is of the form P  .Ai with i < n. This case is handled like the previous one.
Note that, in general, Cn could be a complex concept in which various Ai with i < n occur.
However, such complex CDAs can always be decomposed into multiple simpler CDAs of
the above kinds, at the cost of a polynomial increase in the size of the terminology.
It is clear from the construction that the formula T obtained as above satisfies the
conditions stated in the lemma. That T is obtained from T in polynomial-time follows
from the fact that, in the above inductive definition of T , the previously constructed
formula T 0 occurs only once.
We are now ready for the proof of Theorem 3.27.
Proof of Theorem 3.27. Let a succinct-concept hAi , T i be given, where T = {A1  C1 , . . . ,
An  Cn }. Let (x) = T (x, i, 1) and let (x) = u, v(u 6= v  0 (x)), where 0 (x) is
obtained from (x) by replacing 0 and 1 by u and v, respectively. Then we have that, for
every interpretation I with a domain of at least two elements, and for every a  I , the
following conditions are all equivalent:
1. I, a |= (x)
2. I 0 , a |= (x), for some interpretation I 0 that extends I by mapping the constant
symbols 0 and 1 to distinct elements of I .
3. I 0 , a |= C, where C is the unfolding of hAi , T i.
4. I, a |= C, where C is the unfolding of hAi , T i.
373

fiTen Cate, Franconi, & Seylan

The equivalence of 1 and 2 is immediate from the construction of . The equivalence of 2
and 3 follows from Lemma 3.28. The equivalence of 3 and 4 is immediate, since 0 and 1 do
not occur in C. This concludes the proof.
Definition 3.29. Let C, D be L -concepts and let T1 , T2 be L -TBoxes such that T1  T2 |=
C v D. A first-order formula (x) is called a FO interpolant of C and D under hT1 , T2 i if
the following conditions hold:
 sig((x))  sig(C, T1 )  sig(D, T2 ),
 (T1 )  (T2 ) |= x.x (C)  (x), and
 (T1 )  (T2 ) |= x.(x)  x (D).
FO |=2 -interpolant and FO |==1 -interpolant are defined in the same way as above, except
that we replace all occurrences of |= by |=2 and |==1 , respectively.
Proposition 3.30. Let L be ALC or any of its extensions with constructors from {S, I, F}.
For all L -concepts C1 , C2 and all L -TBoxes T1 , T2 , if T1  T2 |= C1 v C2 , then there exists
a FO |=2 -interpolant of C1 and C2 under hT1 , T2 i that can be computed in time single
exponential in |T1 | + |T2 | + |C1 | + |C2 |.
Proof. Suppose T1  T2 |= C1 v C2 . By Theorem 3.26, there is some succinct-concept
hA, T i over sig(C1 , T1 )  sig(C2 , T2 ) such that the unfolding I of hA, T i is an interpolant
of C1 and C2 under hT1 , T2 i, and hA, T i can be computed in time single exponential in
|T1 |+|T2 |+|C1 |+|C2 |. Then by Theorem 3.27, there is some first-order formula (x) that can
be constructed in time polynomial in |T | (hence single exponential in |T1 |+|T2 |+|C1 |+|C2 |)
such that
 sig((x))  sig(I),
 |=2 (x)  x (I).
It follows that (x) is a FO |=2 -interpolant of C1 and C2 under hT1 , T2 i whose size is single
exponential in |T1 | + |T2 | + |C1 | + |C2 |.
Step 3: Singly-exponential FO interpolants for interpretations with one element
We still have to obtain interpolants over structures with only one element. We will show
how to do this in Proposition 3.35. The essential idea is that interpolants over structures
with singleton domains are not much different from propositional interpolants. First, we
give a reduction from concept subsumption w.r.t. TBoxes over interpretations with singleton
domains to entailment in propositional logic.
Definition 3.31. Let C be a SHIF-concept. Then the mapping PL (C) is defined inductively as follows.
PL (>) = >,
PL (A) = A,
PL (C) = PL (C),
PL (C u D) = PL (C) u PL (D),
PL (R.C) = AR u PL (C),
PL ( 1R) = >,
374

fiBeth Definability in Expressive Description Logics

where AP = AP  is a fresh concept name for every role name P  NR . For a SHIF-TBox
T , we define
PL (T ) = {PL (C) v PL (D) | C v D  T }  {AR v AS | R v S  T }.
Here, the concept name AP , intuitively, expresses the non-emptiness of the role P .
Note that all transitive roles are ignored in the above translation, as their semantics is
trivially satisfied in interpretations whose domain is a singleton set. For a SHIF-concept
C, PL (C) is an ALC-concept without role constructors. We view PL (C) as a propositional
formula (where the concept names are the propositions, and we identify u and t with the
propositional connectives  and , respectively). Similarly, for a SHIF-TBox T , PL (T )
is a set of ALC CIAs without role constructors, which we view as a set of propositional
formulae.
Proposition 3.32. Let T be a SHIF-TBox and let C, D be SHIF-concepts. Then
T |==1 C v D

if and only if

PL (T ) |= PL (C) v PL (D).

Proof. () Let T |==1 C v D, and suppose I |= PL (T ), and s  PL (C)I . We need to
show that s  PL (D)I . Let J be obtained by restricting the domain of I to the element
s and reading off the interpretation of each role name P from the concept name AP .
Formally,
 J = {s};
 for all A  NC , s  AJ iff s  AI ;
 for all P  NR , P J = {hs, si} if s  AIP , and P J = , otherwise.
By the definition above, it trivially follows for every P  NR+ that P J is transitive. Moreover, for every role R, we have
hs, si  RJ if and only if s  AIR .

(1)

To see this, suppose first hs, si  RJ . If R = P for some P  NR , then s  AIP , i.e., s  AIR ;
and if R = P  for some P  NR , then again s  AIP and by the fact that AP = AP 
(see Definition 3.31), we obtain s  AIR . Hence s  AIR . For the other direction, suppose
s  AIR . If R = P for some P  NR , then hs, si  P J , i.e., hs, si  RJ ; and if R = P  for
some P  NR , then by the fact that AP = AP  , we have hs, si  P J and thus, hs, si  RJ .
Hence (1) follows.
Claim 3.33. For every SHIF-concept C 0 , we have s  PL (C 0 )I if and only if s  (C 0 )J .
Proof of claim. The proof is by induction on the structure of C 0 . The base case, where
C 0 = A or C 0 = >, is trivial, and the boolean cases follow immediately by the inductive
hypothesis. For C 0 = R.D0 , we have the following equivalences:
 s  PL (C 0 )I ;
 s  AIR and s  PL (D0 )I (by semantics);
375

fiTen Cate, Franconi, & Seylan

 hs, si  RJ and s  (D0 )J (by (1) and the inductive hypothesis);
 s  (C 0 )J (by semantics).
Finally, for C 0 = 1R, since PL (C 0 ) = > and s  I , we have s  PL (C 0 )I . Moreover, by
the definition of J , we have s  (C 0 )J . But then s  PL (C 0 )I iff s  (C 0 )J , which is what
we wanted to show.
a
We now show that J |= T , i.e., J satisfies every CIA and RIA in T . That J satisfies
every CIA in T is a direct consequence of the previous claim; so we proceed with the case
for RIAs. Let R v S  T and hs, ti  RJ . By the definition of J , we have s = t. Hence
w.l.o.g. suppose that hs, si  RJ . Then by (1), s  AIR . Since AR v AS  PL (T ) and
I |= PL (T ), we then have s  AIS . By (1) again, this implies hs, si  S J . Hence J satisfies
R v S.
Now we proceed towards our goal s  PL (D)I as follows. By I |= PL (T ), s  PL (C)I ,
and the previous claim, we obtain s  C J . Since J |= T , it follows by T |= C v D that
s  DJ . Then using the previous claim, we conclude that s  PL (D)I .
() Let PL (T ) |= PL (C) v PL (D), and suppose I |= T , and s  C I , where I = {s}.
We need to show that s  DI . Define the interpretation J as follows:
 J = {s};
 for all A  NC , AJ = AI
 for all P  NR , (AP )J = {s} if P I = {hs, si}, and (AP )J =  otherwise
We first show for every role R that
I
s  AJ
R if and only if hs, si  R .

(2)

I
For left-to-right, suppose s  AJ
R . If R = P for some P  NR , then hs, si  P , i.e.,
hs, si  RI ; and if R = P  for some P  NR , then by the fact that AP = AP  , we have
I
I
s  AJ
P , which implies hs, si  R . Hence hs, si  R . For the other direction, suppose
J
 for some
hs, si  RI . If R = P for some P  NR , then s  AP , i.e., s  AJ
R ; and if R = P
J
I
P  NR , then hs, si  P , which implies by AP = AP  that s  AR . Hence (2) follows.

Claim 3.34. For every SHIF-concept C 0 , we have s  (C 0 )I if and only if s  PL (C 0 )J .
Proof of claim. The proof is by induction on the structure of C 0 . The base case, where
C 0 = A or C 0 = >, is trivial, and the boolean cases follow immediately by the inductive
hypothesis. For C 0 = R.D0 , we have the following equivalences
 s  (C 0 )I ;
 hs, si  RI and s  (D0 )I (by semantics and I = {s});
0 J
 s  AJ
R and s  PL (D ) (by (2) and the inductive hypothesis).

 s  PL (C 0 )J (by semantics).
376

fiBeth Definability in Expressive Description Logics

Finally, for C 0 = 1R, since I = {s}, we have I |= > v 1R, and thus, s  (C 0 )I .
Moreover, by PL (C 0 ) = >, we have s  PL (C 0 )J . But then s  (C 0 )I iff s  PL (C 0 )J . a
We now show that J |= PL (T ). By definition, every CIA in PL (T ) is of the form (i)
PL (C 0 ) v PL (D0 ), where C 0 v D0  T ; or of the form (ii) AR v AS , where R v S  T .
That J satisfies CIAs of the form (i) is a direct consequence of the previous claim; so
we focus on CIAs of the form (ii). Let AR v AS  PL (T ) and s  AJ
R . Then by (2),
hs, si  RI . Since I |= T and R v S  T , we then have hs, si  S I . Then by (2) again,
s  AJ
S . Hence J satisfies AR v AS .
Now we proceed towards our goal s  DI as follows. By s  C I and the previous claim,
we have s  PL (C)J . Then by J |= PL (T ) and PL (T ) |= PL (C) v PL (D), we obtain
s  PL (D)J . Using the previous claim again, we conclude that s  DI .
Proposition 3.35. Let L be ALC or any of its extensions with constructors from {S, H, I, F}.
For all L -concepts C1 , C2 and all L -TBoxes T1 , T2 , if T1  T2 |= C1 v C2 , then there exists
a FO |==1 -interpolant of C1 and C2 under hT1 , T2 i that can be computed in time single
exponential in |T1 | + |T2 | + |C1 | + |C2 |.
Proof. Let L be one of the DLs mentioned in the theorem and let C1 , C2 be L -concepts
and let T1 , T2 be L -TBoxes such that T1  T2 |= C1 v C2 . Then it immediately follows
that T1  T2 |==1 C1 v C2 . By Proposition 3.32, T1  T2 |==1 C1 v C2 implies PL (T1 ) 
PL (T2 ) |= PL (C1 ) v PL (C2 ). Now by Theorem 3.10, there is some interpolant I of PL (C1 )
and PL (C2 ) under hPL (T1 ), PL (T2 )i that can be computed in time double exponential in
|T1 |+|T2 |+|C1 |+|C2 |. However, in this case we are only dealing with propositional formulae
and the tableau algorithm can easily be modified to construct a tree-shaped proof instead of
a general graph-shaped one by eliminating the use of proxies. In fact, we have just described
a standard tableau algorithm for propositional logic. It is well-known that each node in
the tree has a polynomial out-degree in the size of the input and the height of the tree is
polynominal in the size of the input. By inspecting the proof of Theorem 3.10, one can easily
see that in this case I can be computed in time single exponential in |T1 | + |T2 | + |C1 | + |C2 |.
Finally let D be the concept obtained from I by replacing each occurrence of a concept name
AR by R.>. We have that x (D) is a FO |==1 -interpolant of C1 and C2 under hT1 , T2 i. It
is easy to see that the time required to compute x (D) is as stated in the proposition.
Step 4: Putting it all together The result that we were after now follows, by putting
the FO |==1 -interpolants and the FO |=2 -interpolants together:
Theorem 3.36. Let L be ALC or any of its extensions with constructors from {S, I, F}.
For all L -concepts C, D and L -TBoxes T1 , T2 , if T1  T2 |= C v D, then there exists an
FO interpolant (x) of C and D under hT1 , T2 i and (x) can be computed in time single
exponential in |T1 | + |T2 | + |C| + |D|.
Proof. Let L be one of the DLs mentioned in the theorem, let C, D be L -concepts,
and let T1 , T2 be L -TBoxes such that T1  T2 |= C v D. By Proposition 3.35, there is
some FO |==1 -interpolant (x) of C and D under hT1 , T2 i that can be computed in time
single exponential in |T1 | + |T2 | + |C| + |D|; and by Proposition 3.30, there is some FO |=2 interpolant (x) of C and D under hT1 , T2 i that can be computed in time single exponential
377

fiTen Cate, Franconi, & Seylan

in |T1 | + |T2 | + |C| + |D|. Let
(x) = (yz(y 6= z)  (x))  (yz(y = z)  (x)).
Claim 3.37. (T1 )  (T2 ) |= x.x (C)  (x)

and

(T1 )  (T2 ) |= x.(x)  x (D).

Proof of claim. We prove the first part. The proof of the second part is analogous.
Let I = hI , I i be a model of T1  T2 , i.e., of (T1 )  (T2 ), and  be a first-order
variable assignment with I,  |= x (C). We need to show that I,  |= (x). To this aim,
we show I,  |= (yz(y 6= z)  (x)) and I,  |= (yz(y = z)  (x)).
First suppose that I,  |= yz(y 6= z). We are done if we prove that I,  |= (x).
I,  |= yz(y 6= z) implies |I |  2. Then by I,  |= x (C) and (T1 )  (T2 ) |=2
x.x (C)  (x), we obtain I,  |= (x), and we are done.
Now suppose that I,  |= yz(y = z). We are done if we prove that I,  |= (x).
I,  |= yz(y = z) implies |I | = 1. Then by I,  |= x (C) and (T1 )  (T2 ) |==1
x.x (C)  (x), we obtain I,  |= (x), and we are done.
Thus, both of the conjuncts of (x) are satisfied by I, . But then I,  |= (x).
a
By assumption we have that sig((x)), sig((x))  sig(C, T1 )  sig(D, T2 ). Since the
formulas yz(y 6= z) and yz(y = z) do not introduce new predicates, we have that
sig((x))  sig(C, T1 )  sig(D, T2 ). Therefore, (x) is a FO interpolant for C and D under
hT1 , T2 i. Moreover, since both of its conjuncts can be computed in single exponential time,
so can (x). Hence the theorem follows.

4. Results on Beth Definability
In this section, we present the main technical contributions of the paper. We first introduce
the notions of implicit and explicit definability for concepts and define the (projective) Beth
definability property, which are in fact the primary notions of interest in this paper. In what
follows, L denotes any of the description logics ALCX with X  {S, H, I, F}.
Definition 4.1 (Implicit definability). Let C be an L -concept, T an L -TBox, and  
sig(C, T ). C is implicitly definable from  under T if, for every two models I and J of T
satisfying I = J and, for all P  , P I = P J , it holds that C I = C J .
In other words, given a TBox, a concept C is implicitly definable if the set of all its
instances depends only on the extension of the predicates in  and the domain of discourse.
Deciding implicit definability in L means, given an L -concept C, L -TBox T , and a set of
predicates   sig(C, T ), to check whether C is implicitly definable from  under T . For
every predicate P  sig(C, T ) \ , introduce a new predicate P 0 which is not in sig(C, T ).
e (respectively, Te ) be the concept (respectively, TBox) obtained by replacing every
Now let C
occurrence of a predicate P 6  in C (respectively, in T ) by P 0 . Lemma 4.2, whose proof is
a routine adaptation of an analogous result for first-order logic (Boolos, Burgess, & Jeffrey,
2007), provides a characterization of implicit definability in terms of entailment. This wellknown characterization is often used as a definition of implicit definability (Hoogland &
Marx, 2002; Conradie, 2002).
Lemma 4.2. Let C be an L -concept, T be an L -TBox, and   sig(C, T ). Then C is
e
implicitly definable from  under T if and only if T  Te |= C  C.
378

fiBeth Definability in Expressive Description Logics

In particular, Lemma 4.2 reduces implicit definability in L to the concept subsumption
problem in L w.r.t. TBoxes. It is also possible to reduce the concept subsumption problem
in L w.r.t. TBoxes to the problem of deciding implicit definability in L .
Lemma 4.3. Let C v D be an L -CIA, T be an L -TBox,  = sig(C u D, T ), and
A0  NC \ . Then T |= C v D if and only if A0 is implicitly definable from  under
T  {A0 v C u D}.
Proof. () Suppose T |= C v D. Let I and J be models of T  {A0 v C u D} such that
I = J and for all P  , we have P I = P J . Obviously, I and J are also models of T .
Then by T |= C v D, we have that (C u D)I = (C u D)J = . But then AI0 = AJ
0 = .
Hence, A0 is implicitly definable from  under T  {A0 v C u D}.
() We show the contrapositive, i.e., if T 6|= C v D, then A0 is not implicitly definable
from  under T  {A0 v C u D}. Suppose T 6|= C v D. Then there is some model I of
T and some s  I such that s  (C u D)I . Let I1 = hI1 , I1 i and I2 = hI2 , I2 i be
such that
 I1 = I2 = I ;
 AI1 = AI2 = AI , for all A  (NC \ A0 );
 RI1 = RI2 = RI , for all R  NR ;
 AI0 1 = {s} and AI0 2 = .
It is easy to see that I1 and I2 are models of T  {A0 v C u D}. Also observe that I1
and I2 are two interpretations with the same domain and they agree on what they assign
to predicates in . But AI0 1 6= AI0 2 . Hence A0 is not implicitly definable from  under
T  {A0 v C u D}.
Using Lemma 4.2 (for the upper bound) and Lemma 4.3 (for the lower bound), the following theorem follows immediately, since the concept subsumption problem w.r.t. TBoxes
is ExpTime-complete for the description logics in question (Tobies, 2001).
Theorem 4.4. In ALC and any of its extensions with constructors from {S, H, I, F},
implicit definability is ExpTime-complete.
Explicit definability is the syntactic counterpart of implicit definability. Given a concept
C, signature , and TBox T , it asks for the existence of a concept D formulated over 
such that the C and D denote the same set in every model of T .
Definition 4.5 (Explicit definability). Let C be an L -concept, T a L -TBox, and  
sig(C, T ). We say that C is explicitly definable from  under T if there is some L -concept
D such that T |= C  D and sig(D)  . Such a concept D is called an explicit definition
of C from  under T .
Proposition 4.6. Let C be an L -concept, T an L -TBox, and   sig(C, T ). If C is
explicitly definable from  under T , then C is implicitly definable from  under T .
379

fiTen Cate, Franconi, & Seylan

Proof. Suppose C is explicitly definable from  under T . Then there is some concept D
e and sig(D)   that
such that T |= C  D. This implies by the definition of Te and C,
e
e
e
e
e
T |= C  D. Then we have T  T |= C  D and T  T |= C  D by the monotonicity
e Then by Lemma 4.2, C is implicitly definable from 
of |=. These yield T  Te |= C  C.
under T .
Definition 4.7 (Beth definability property). L has the Beth definability property (BP) if
for all L -concepts C, all L -TBoxes T , and all signatures   sig(C, T ), if C is implicitly
definable from  under T , then C is explicitly definable from  under T .
Observe that, in the above definition,  restricts the concept names and the role names
that are allowed to appear in the explicit definition. We can obtain a weaker version of the
Beth definability property by restricting only the concept names occurring in the explicit
definition. This is called the concept-name Beth definability property (CBP). In other words,
the CBP refers to the existence of explicit definitions over signatures of the form   NR .
As we will explain later, we also have reasons to be interested in whether description
logics satisfy the Beth definability property over the restricted class of finite interpretations. It is known that the Beth definability property, when restricted to finite structures,
fails for first-order logic (see e.g., Hoogland, 2001), in spite of the fact that it holds in the
unrestricted case. We will specifically investigate Beth definability for description logics
restricted to finite interpretations. We call this the Beth definability property in the finite
(BPF). Formally, BPF is defined in the same way as BP, except that we replace, in the
definition, all occurrences of the word interpretation or model by finite interpretation or
finite model, and we replace the symbol |= by |=f , where |=f considers only finite interpretations. In addition, we will speak about f-implicit definability and f-explicit definability.
It follows from Lemma 4.2 that, if L has FMP, then BP are BPF are equivalent for L .
Hence it only makes sense to specifically study BPF for logics without FMP.
4.1 Bounds on the Size of Explicit Definitions
We start by a positive result on BP which is a direct application of the interpolation theorem,
i.e., Theorem 3.22.
Theorem 4.8 (BP). Let L be ALC or any of its extensions with constructors from
{S, I, F}. Then for all L -concepts C, all L -TBoxes T , and all signatures   sig(C, T ),
if C is implicitly definable from  under T , then C is explicitly definable from  under T ,
and the explicit definition of C can be computed in time double exponential in |T | + |C|.
Proof. Let L be one of the DLs stated in the theorem, C be an L -concept, T be an
L -TBox, and   sig(C, T ) such that C is implicitly definable from  under T . By
e (where Te and C
e are obtained from T and C,
Lemma 4.2, we have that T  Te |= C  C
respectively, by replacing all occurrences of predicates P 6  by fresh predicates P 0 that
e under
are not in sig(C, T )). Now by Theorem 3.22, there is an interpolant I of C and C
e
e
e
hT , T i that can be computed in time double exponential in |T | + |T | + |C| + |C|. Since it
e Te ) = , and both (a) T  Te |= C v I and
is an interpolant, sig(I)  sig(C, T )  sig(C,
e By (b) and T  Te |= C
e v C, we have T  Te |= I v C, from which
(b) T  Te |= I v C.
e
T  T |= C  I follows by (a). From the structure of Te , it now straightforwardly follows
that T |= C  I.
380

fiBeth Definability in Expressive Description Logics

e = 2  (|T | + |C|).
As for the time needed to compute I, observe that |T | + |Te | + |C| + |C|
Hence I can be computed in time double exponential in |T | + |C|.
The proof of Theorem 4.8 uses Theorem 3.22. Similarly, if we use Theorem 3.36 instead, we can show that first-order explicit definitions of implicitly defined concepts can
be computed in single exponential time. Note that Theorem 4.8 also establishes a double
exponential upper bound on the size explicit definitions in the considered logics. This upper
bound is optimal because we show in Theorem 4.11 below that explicit definitions in L
may need to be double exponentially big.
An essential tool in the proof of Theorem 4.11, will be the path-set construction that
was previously used by Lutz (2006) to characterize the succinctness of public announcement
logic compared to epistemic logic. The path-set construction has also been used by Ghilardi
et al. (2006) to establish a lower bound on the size of concepts witnessing that a TBox is
not a conservative extension of another TBox.
Definition 4.9. If C is an ALC-concept, then the path-set PC of C is defined by structural
induction as follows, where  denotes the empty sequence and  denotes concatenation of
finite sequences:
 P> = PA = {}, for A  NC ;
 PC = PC ;
 PCuD = PC  PD ;
 PR.C = {}  {R  p | p  PC }.
Intuitively, PC describes the nestings of role constructors in C. We will use PC as a tool
for establishing lower bounds on the size of concepts.
Lemma 4.10. For every ALC-concept C, we have |C|  |PC |.
Proof. The proof is by induction on the structure of C.
If C is an atomic concept of the form > or A (with A  NC ), then, by definition, |C| = 1
and |PC | = 1 since PC = {}. Hence |C|  |PC |.
Next, let C = D. By the inductive hypothesis, we have |D|  |PD |. Then by |PD | =
|PD |, we obtain |D|  |PD |. Finally, by the fact that |D| = |D| + 1, we obtain |D| 
|PD |. Hence |C|  |PC |.
Next, let C = C1 u C2 . By the inductive hypothesis, we have |C1 |  |PC1 | and |C2 | 
|PC2 |. This implies |C1 |+|C2 |  |PC1 |+|PC2 |. Then by the fact that |C1 uC2 | = |C1 |+|C2 |+1,
we obtain |C1 uC2 |  |PC1 |+|PC2 |. Finally, by |PC1 |+|PC2 |  |PC1 uC2 |, we have |C1 uC2 | 
|PC1 uC2 |. Hence |C|  |PC |.
Finally, let C = R.D. By the inductive hypothesis, we have |D|  |PD |. This implies
|D| + 2  |PD | + 2. Then by the fact that |R.D| = |D| + 2, we obtain |R.D|  |PD | + 2.
Finally, by |PD | + 1 = |PR.D |, we have |R.D|  |PR.D |. Hence |C|  |PC |.
Theorem 4.11 (Explicit definition lower bound). Let  = {R, S}  NR . Then for every
n  N, there is an ALC-concept Cn and an ALC-TBox Tn such that   sig(Cn , Tn ), |Tn |
and |Cn | are polynomial in n, Cn is implicitly definable from  under Tn , and the smallest
explicit definition of Cn from  under Tn is double exponentially long in n.
381

fiTen Cate, Franconi, & Seylan

Proof. Fix an n  N. Let A1 , . . . , An be pairwise distinct concept names. We use these
concept names and their negations to represent in binary format a number in {0, . . . , 2n 1}.
More precisely, An u . . . u A1 represents 0, An u An1 . . . u A1 represents 1, and
so on. Obviously, this implies that the least significant bit is at position 1. For every
i  {0, . . . , 2n  1}, we denote the concept that represents i by Ci . Note that in each Ci ,
either Aj or Aj is a conjunct of Ci , for all j  {1, . . . , n}.
For k  {1, . . . , n},
 let Xk = A1 u . . . u Ak1 u Ak and
 let Yk = A1 u . . . u Ak1 u Ak .
Note that Xk and Yk are not concept names and we will use them only to abbreviate our
CIAs. We define Tn as the ALC-TBox consisting of the following CIAs.
 An u . . . u A1 v R. u S.
 A1 t . . . t An v R.> t S.>
 For every k  {1, . . . , n} and   ,
Xk v .Yk u
l
((Al u .Al ) t (Al u .Al ))
k<ln

Intuitively, the last item above allows us to decrease the counter value by one by flipping
the respective bits. Note that |Tn | is polynomial in n and that Tn is satisfiable. In fact, we
present models of Tn in Claim 4.14. If I is a model of Tn , we have for every s  I and
every i  {1, . . . , n}, either s  AIi or s  (Ai )I by the virtue of I being an interpretation.
Therefore, for every s  I there is exactly one i  {0, . . . , 2n  1} such that s  CiI .
Claim 4.12. Let i  {1, . . . , 2n  1}. Then
1. Tn |= Ci v R.Ci1 u S.Ci1
2. Tn |= Ci  R.Ci1 t S.Ci1
Proof of claim. For 1, suppose I = hI , I i is a model of Tn , s  I with s  CiI , and
  {R, S} = . It suffices to show that s  (.Ci1 )I . If there is no t  I such that
hs, ti   I then we are done immediately; therefore, suppose hs, ti   I . We need to show
I .
t  Ci1
We have that Ci = Bn u . . . u B1 , where Bj = Aj or Bj = Aj , for each j  {1, . . . , n}.
Denote by B j the concept Aj if Bj = Aj , or else the concept Aj if Bj = Aj . Since
s  CiI , there is exactly one k  {1, . . . , n} such that s  XkI . Then by the CIA
Xk v .Yk u
l
((Al u .Al ) t (Al u .Al ))
k<ln

382

fiBeth Definability in Expressive Description Logics

in Tn , we have that t  (Bn u . . . u Bk+1 u B k u . . . u B 1 )I . It is not hard to see that
Ci1 = Bn u . . . u Bk+1 u B k u . . . u B 1 .
I , which is what we wanted to show.
Hence we conclude that t  Ci1

For 2. () Suppose I = hI , I i is a model of Tn and s  I with s  CiI . Since i 6= 0,
by A1 t . . . t An v R.> t S.>  Tn , Ci  (R.>)I or Ci  (S.>)I . That is, there is
I
some t  I such that either hs, ti  RI or hs, ti  S I . In both cases, t  Ci1
by 1. Hence
I
s  (R.Ci1 t S.Ci1 ) .
() Suppose I = hI , I i is a model of Tn and s  I with s  (R.Ci1 t S.Ci1 )I .
I
This means there is some t  I such that t  Ci1
and either hs, ti  RI or hs, ti  S I .
We proceed towards a contradiction so further suppose that s 6 CiI , i.e., s  (Ci )I . Then
by the definition of an interpretation, s  CjI , where j 6= i and j  {0, . . . , 2n  1}. If j = 0,
then by An u . . . u A1 v R. u S.  Tn , we immediately get a contradiction. If j 6= 0,
I . Since i 6= j, we have (i  1) 6= (j  1). Thus, the binary representation
then by 1, t  Cj1
I
I
of i  1 and j  1 must differ in at least one bit. This implies by t  Cj1
and t  Ci1
that
I
I
a
there is some k  {1, . . . , n} such that t  Ak and t 6 Ak . Hence a contradiction.
Now define concepts D0 . . . D2n 1 inductively as follows.
D0 = R. u S.
Di = R.Di1 t S.Di1
Intuitively, Di has the shape of a binary tree (due to role names R, S) and the height of the
tree is O(i). This implies |C2n 1 | is double exponential in n.
Claim 4.13. For every i  {0, . . . , 2n  1}, we have Tn |= Ci  Di .
Proof of claim. The proof is by induction on i. The base case is when i = 0. Then by the
axioms in Tn , it trivially follows that Tn |= A1 u . . . An  R. u S.. In other words,
Tn |= C0  D0 . Hence the claim holds in the base case.
For the inductive step, suppose i > 0. By the previous claim, Tn |= Ci  R.Ci1 t
S.Ci1 ; and by the inductive hypothesis, Tn |= Ci1  Di1 . But then Tn |= Ci 
R.Di1 t S.Di1 which is what we wanted to show.
a
By the previous claim, we have that for all i  {0, . . . , 2n 1}, Di is an explicit definition
of Ci from  = {R, S} under Tn . Then by Proposition 4.6, Ci is implicitly definable from 
under Tn . In the rest of the proof, we show that each explicit definition of Ci from  under
Tn is at least double exponentially long. To this aim, we introduce interpretations that are
based on some elements of  , where  denotes the set of all strings over the symbols in
. More precisely, for every p   with 0  |p|  2n  1, we define the interpretation Ip
as follows.
 Ip = {p0   | p0 is a prefix of p};
 for all A  NC ,
383

fiTen Cate, Franconi, & Seylan

 if A = Aj for some j  {1, . . . , n}, then
AIp = {p0  Ip | A is a conjunct of C|p||p0 | },
 if A 6= Aj for all j  {1, . . . , n}, then AIp = ;
 for all T  NR ,
 T Ip = {hp1 , p2 i  Ip  Ip | p2 = p1  T }, if T  ,
 T Ip = , if T  NR \ .
The following claim is easy to show.
Claim 4.14. For every p   with 0  |p|  2n  1, we have
 Ip |= Tn , and
I

   C|p|p .
Denote for every i  {0, . . . , 2n  1}, the set of all p   such that |p| = i by i .
Claim 4.15. Let i  {0, . . . , 2n  1} and let C be an ALC-concept such that sig(C)   =
{R, S} and Tn |= Ci  C. Then i  PC .
Proof of claim. Suppose first i = 0. Then i = {}. Moreover, by definition we have
  PC . Hence i  PC , which is what we wanted to show.
Now suppose i > 0. We proceed towards a contradiction. Suppose that there is some
pa  i \ PC . Let pb be the prefix of pa with |pb | = i  1. Since i > 0, pb is well-defined.
We claim that for all s  Ipb  Ipa and D  sub(C) such that {s  p | p  PD }  PC ,
s  DIpb if and only if s  DIpa .

(3)

The proof is by induction on the structure of D. Since the base and the boolean cases are
trivial, we only treat the case D = .E, where   .
 (). Suppose s  DIpb . Then there is a t  Ipb such that hs, ti   Ipb and t  E Ipb .
Since t is in Ipa as well, the former yields hs, ti   Ipa . It thus remains to show
that t  E Ipa . By definition, t = s   and PD = {}  {  p | p  PE }. Thus, our
assumption {s  p | p  PD }  PC yields {s}  {t  p | p  PE }  PC . This implies
{t  p | p  PE }  PC . Then by the induction hypothesis and t  E Ipb , we obtain
t  E Ipa , which is what we wanted to show for this direction of the proof.
 (). Suppose s  DIpa . Then there is a t  Ipa such that hs, ti   Ipa and
t  E Ipa . By definition, t = s   and PD = {}  {  p | p  PE }. Thus, our
assumption {s  p | p  PD }  PC yields {s}  {t  p | p  PE }  PC . This implies
{t  p | p  PE }  PC .

(4)

By (4) and   PE , we obtain t  PC . Since pa 6 PC , this means t 6= pa . But then
t  Ipb and hs, ti   Ipb . By (4), t  E Ipa , and the induction hypothesis, we have
t  E Ipb . Hence s  (.E)Ipb .
384

fiBeth Definability in Expressive Description Logics

Thus, we have shown that (3) holds. Now we arrive at a contradiction as follows. By
Ip
I
Claim 4.14, we have   Ci pa and   Ci1b , since |pa | = i and |pb | = i  1, respectively.
Ip

Ip

  Ci1b implies by the definition of Ci that  6 Ci b . Then by Tn |= Ci  C and Claim 4.14,
we obtain   C Ipa and  6 C Ipb . But this contradicts with an immediate consequence of
(3), namely   C Ipb iff   C Ipa . Hence a contradiction. Thus, we conclude that i  PC
for i > 0.
a
To show the theorem, we argue as follows. Suppose that C is an ALC-concept such
n
that Tn |= C2n 1  C and sig(C)  . Then by the previous claim 2 1  PC . By its
n
n
n
n
definition, |2 1 | = 22 1 and thus, 22 1  |PC |. Then by Lemma 4.10, 22 1  |C|.
Hence the theorem follows.
Remark 4.16. With the role disjunction constructor, which is not present in ALC, Cn
would admit a single exponentially long explicit definition from  under Tn in Theorem 4.11.
Remark 4.17. The lower bound argument in Theorem 4.11 works for CBP as well by just
setting  = .
Combined with Theorem 4.8, Theorem 4.11 implies that implicit definitions using general TBoxes are exactly double exponentially more succinct than explicit definitions using
acyclic terminologies. This closes the open problem of ten Cate et al. (2006) about the size
of explicit definitions. Moreover, the same theorems establish an exact bound on the size of
equivalent rewritings of concept queries as considered by Seylan et al. (2009). Theorem 4.11
also shows that Theorem 1 by Seylan et al. (2010), which claims a single exponential upper
bound on the size of explicit definitions in ALC, is wrong. The source of the problem in
the proof of Theorem 1 is Lemma 1, which claims a single exponential upper bound on the
size of interpolants in ALC.
4.2 Failure of Beth Definability in the Presence of Role Hierarchies
We now show that BP fails in the description logics that we consider that include role
hierarchies (H). This shows that BP is indeed a stronger property than CBP because the
same logics have CBP (ten Cate et al., 2006).
Theorem 4.18. Let L be ALCH or any of its extensions with constructors from {S, I, F}.
Then L does not have BP.
Proof. Let  = {R1 , R2 } and consider the ALCH-TBox T that consists of
S v R1
S v R2
R1 .A u S. v R2 .A
R1 .A u S. v R2 .A
It is easy to see that T is satisfiable. In fact, we will present two models of T below.
Claim 4.19. S.> is implicitly definable from  under T .
385

fiTen Cate, Franconi, & Seylan

R1
s

S

R1

a

w

t

R2

R2

R2
v

b

R1

Figure 5: Interpretations I and J that are used for disproving BP for ALCH
Proof of claim. Define XI = {s  I | t  I .hs, ti  R1I  R2I }. We will show that,
whenever I |= T , then (S.>)I = XI . This establishes the claim, since XI depends only
on R1I and R2I .
First, we show (S.>)I  XI . Suppose that s  (S.>)I . Then there is some t  I
such that hs, ti  S I . By the RIAs in T , we then have that hs, ti  R1I  R2I . Hence s  XI .
Next, we show XI  (S.>)I . For contradiction, suppose that s  XI and s 6 (S.>)I ,
i.e., s  (S.)I . Then there is some t  I such that hs, ti  R1I  R2I and hs, ti 6 S I .
By the definition of an interpretation, either (i) t  AI or (ii) t  (A)I . If (i), then
by R1 .A u S. v R2 .A  T , we have t  (A)I , which is a contradiction. If (ii),
then by R1 .A u S. v R2 .A  T , we have t  AI , which is a contradiction. Hence
XI  (S.>)I .
a
Let I = hI , I i be the interpretation where
 I = {s, t},
 R1I = R2I = S I = {hs, ti};
 RI = , for all R  NR \ (  {S});
 B I = , for all B  NC .
Let J = hJ , J i be the interpretation where
 J = {w, v, a, b},
 R1J = {hw, ai, hv, bi}, R2J = {hw, bi, hv, ai};
 RJ = , for all R  NR \ ;
 AJ = {a};
 B J = , for all B  (NC \ {A}).
The interpretations I and J are depicted in Figure 5. It is not hard to see that I and J
are models of T . Furthermore, the two structures are indistinguishable by concepts in the
signature , in the following sense:
Claim 4.20. For all SHIF-concepts C with sig(C)   = {R1 , R2 }, we have
1. s  C I if and only if w  C J ;
386

fiBeth Definability in Expressive Description Logics

2. s  C I if and only if v  C J ;
3. t  C I if and only if a  C J ;
4. t  C I if and only if b  C J
The proof of this claim is straightforward, by simultaneous induction on the structure
of the concept C (alternatively, bisimulations can be used to establish the same result).
Since s  (S.>)I and w 6 (S.>)J , it follows that there is no SHIF-concept C such
that sig(C)   and T |= S.>  C. In summary, we have that the ALCH-concept S.> is
implicitly definable from  under the ALCH-TBox T , but S.> is not explicitly definable
from  under T in SHIF. We can conclude that BP fails for every description logic that
includes ALCH and that is included in SHIF.
Theorem 4.18 shows that Theorem 10 by Seylan et al. (2010), which claims that ALCH
and its extensions with S and/or I have BP, is incorrect. The mistake in the proof is
that Theorem 9, which presents a reduction from the concept satisfiability problem w.r.t.
TBoxes in SHI to the same problem in ALC, can not actually be used for computing
SHI-interpolants.
4.3 Failure of Beth Definability in the Finite
We now consider BPF (the analogue of Beth Definability over finite structures). Before
we start, we explain our motivations. Seylan et al. (2009) consider an ontology-based data
access setting, where traditional ABoxes are replaced by DBoxes. Syntactically, DBoxes
are defined in the same way as ABoxes, but their semantics is different: while an ABox
is merely assumed to express true facts, a DBox is assumed to list all true facts for some
specified subset of the signature (known as the set of data predicates). Thus, for example,
D = {A(a), R(a, b)} is a DBox for data predicates A and R, and, by the definition of the
semantics of DBoxes, we have that, in every model I of D, AI = {aI } and RI = {haI , bI i}.
In this setting, the TBox may contain other predicates than the data predicates and the
authors use BP to determine whether a concept query over the signature of the TBox can be
rewritten to an equivalent first-order query over the data predicates. When this is possible,
computing the certain answers of the original query can then be reduced to computing
the answers of the rewriting over the DBox, viewed as a database. In the setting we have
described here, and for DLs without FMP, it is more natural to consider BPF than BP. The
reason is that, in every interpretation of a DBox, the data predicates are, by definition, finite
relations. In fact, the appropriate analogue of BP in this setting is one that is restricted
to interpretations in which the data predicates are finite and the rest of the signature is
unrestricted. This variant of BP can be viewed as a common generalization of BP and BFP.
We do not study it here, but the negative results that we will present below for BFP apply
to it as well.
Theorem 4.21 below establishes that BPF fails in L , where L is any DL (among the
ones we consider) lacking FMP. More precisely, we show that there is an L -TBox T , L concept C, and signature  such that C is f-implicitly definable from  under T , and that
there is no f-explicit definition in L , i.e., there is no L -concept D such that sig(D)  
and T |=f C  D. Intuitively, the reason for the failure of BPF in these logics will be that
387

fiTen Cate, Franconi, & Seylan

they can not express the transitive closure of a role (see also the discussion below after the
proof of Theorem 4.21).
Theorem 4.21. Let L be ALCF I or any of its extensions with constructors from {S, H}.
Then L does not have BPF.
Proof. We will, in fact, prove something stronger: we will construct an implicit definition
for which there is no corresponding explicit definition even in full first-order logic.
Let A, B, X be concept names and let R be a role name. Suppose  = {R, A}. Consider
the ALCF I-TBox T that consists of the following.
> v  1R u  1R
B v R.B
A v X
R.(A u B) v X
R.X v X
We will show that some concept is f-implicitly definable from  under T but it is not
f-explicitly definable from  under T . The concept in question is A u B. Note that this
concept is finitely satisfiable w.r.t. T , i.e., there is some finite model I of T such that
(A u B)I 6= . In fact, we provide such a model In below.
For an interpretation I = hI , I i. A sequence s0 , . . . , sn of elements of I is called
a finite R-path if n > 0 and hsi , si+1 i  RI for all i < n. An infinite R-path is defined
analogously. An R-path such that the start and the end nodes are the same is called an
R-cycle. Now we will show two claims that will be useful for the proof of the theorem.
Claim 4.22. Let I be a finite model of T . If s  B I , then hs, si  (RI )+ , where (RI )+ is
the transitive closure of RI .
Proof of claim. Suppose that s  B I . Then the axiom B v R.B  T implies the existence
of the following infinite R-path:
p = s0 , s1 , . . .
where s0 = s and for all i  0, we have si  B I .
Since I is finite, there is some 0  n < m such that sn = sm . If n = 0, we immediately
have that hs, si  (RI )+ . Otherwise, we claim that for all pairs hsi , sj i in the sequence
hsn , sm i, hsn1 , sm1 i, . . . , hs0 , smn i, we have si = sj . The base case follows immediately
from sn = sm . For the inductive step, we have by the inductive hypothesis that sni =
smi = t, for some t  I . Then by the definition of p, hsni1 , ti  RI and hsmi1 , ti 
RI , which imply by the axiom > v 1R  T and I |= T that sni1 = smi1 . Hence
we have that s = s0 = smn . But then hs, si  (RI )+ , which is what we wanted to show. a
Claim 4.23. A u B is f-implicitly definable from  under T .
Proof of claim. For all interpretations I, define
YI = {s  I | hs, si  (RI )+  s  AI }.
388

fiBeth Definability in Expressive Description Logics

We will show that, for all finite models I of T , (A u B)I = YI . This implies the claim, since
YI depends only on RI and AI .
() Suppose s  (A u B)I . By Claim 4.22, we know that hs, si  (RI )+ . But then
s  YI .
() Suppose s  YI . Then s  AI and hs, si  (RI )+ . Since s  AI , it is enough to
show that s  B I . By the definition of an interpretation, either s  B I or s  (B)I . If
s  (B)I , then by hs, si  (RI )+ , s  (A u B)I , and the axioms R.(A u B) v X  T
and R.X v X  T , we have s  (X)I which would be a contradiction by s  AI and
A v X  T . So it must be that s  B I .
a
The rest of the proof is all about showing that there is no f-explicit definition of A u B
from  under T . To this aim, we start by defining an interpretation In , parameterized by
a natural number n > 0.
 In = {s0 , . . . , s2n+1 }  {t0 , . . . , t2n+1 }
 RIn = {hsi , si+1 i | 0  i  2n}  {hti , ti+1 i | 0  i  2n}  {ht2n+1 , t0 , }i
 AIn = {sn , tn }
 B In = X In = {ti | 0  i  2n + 1}
Claim 4.24. For every first-order formula (x) there is an n > 0 such that In |=  [sn ] if
and only if In |=  [tn ].
Proof. We apply the Gaifman locality theorem (cf. Libkin, 2004). In the present setting,
where we only have unary and binary relations, and we are concerned with formulas in a
single free variable, the Gaifman locality theorem is particularly easy to state. Given an
interpretation I and elements a, b  I , we say that a and b have distance at most n relative
to a signature , if there is a sequence s0 , . . . , sm with 0  m  n such that s0 = a, sm = b,
and for all 0  i < m, pair hsi , si+1 i belongs to P I  (P I ) for some binary relation (i.e.,
role name) P  . For any interpretation I, element a  I , and natural number n  0,
we denote by I a,n the interpretation whose domain consists of the elements from I that
have distance at most n from a, and whose relations are the ones from I restricted to this
subset of the domain. The Gaifman locality theorem can then be stated as follows: for
every first-order formula (x), there is a natural number n > 0 such that, for all structures
I and elements a, b  I , if I a,n is isomorphic to I b,n , via an isomorphism that maps a
to b, then I |=  [a] if and only if I |=  [b].
Now, let (x) be any first-order formula, and let n > 0 be the natural number given by
the Gaifman locality theorem. Consider the instance In that we constructed earlier. It is
immediately clear from the construction of In that In sn ,n is isomorphic to In tn ,n , via an
isomorphism that maps sn to tn . Therefore, In |=  [sn ] if and only if In |=  [tn ].
Claim 4.25. There is no SHIF-concept C such that sig(C)   and T |=f (A u B)  C.
Proof of claim. We proceed towards a contradiction. Suppose C is an ALCF I-concept such
that sig(C)   = {R, A} and T |=f A u B  C. Let (x) = x (C). Since sn  (A u B)In ,
T |=f A u B  C, and the fact that In is a finite model of T , we have In 6|=  [sn ]; and
389

fiTen Cate, Franconi, & Seylan

by the same reasoning, we have In |=  [tn ]. But by the previous claim, In |=  [sn ] if and
only if In |=  [tn ], which is a contradiction.
a
In summary, we have that the ALCF I-concept A u B is f-implicitly definable from 
under the ALCF I-TBox T , but A u B is not f-explicitly definable from  under T even in
SHIF (or in first-order logic, for that matter). It follows that, if L is any proper extension
of ALCF I with constructors from {S, H}, then L does not have BPF.
We point out that the specific counterexample to BPF described in the proof of Theorem 4.21 actually admits an explicit definition if one were to allow the use of transitive
closure. Specifically, it can be shown that A u (R.>) u (R+ .R.>) is an explicit
definition, where R+ denotes the transitive closure of the role R.
4.4 The Transitive Closure Operator
The proof of Theorem 4.21 suggests that the failure of BPF in the considered logics may
be caused by the fact that they can not express transitive closure. This raises the question
whether one can regain BPF by adding the transitive closure constructor to ALCF I. In
this section, we show that ALCF I extended with the transitive closure constructor still
lacks BPF.
In the following, we denote by L+ the language obtained from L by additionally allowing R+ as a role for every role R in L . This allows us to include such roles in the
inductive definition of concepts. However, if L includes functionality restrictions, then, as
usual, we forbid the use of transitive closure inside these functionality restrictions. In other
words, in concepts of the form  1R, R is not allowed to make use of the transitive closure
constructor.
The semantics of the transitive closure construct is as expected, namely, (R+ )I is the
relation
{hs, ti | there are s1 , . . . , sn (n > 1) with s1 = s, sn = t, and hsi , si+1 i  RI for 1  i < n}.
Theorem 4.26. ALCF I + does not have BPF.
Proof. Consider the following ALCF I + -TBox T .
> v  1R
> v R.>
> v R+ .A

A v B
R.B v B
R.B v B

It is easy to see that T is finitely satisfiable, i.e., T has a finite model. In fact, we provide
finite models In , for n > 0, of T below. We first show that the concept name B is f-implicitly
definable from  = {R, A} under T and then show that there is no f-explicit definition of
this concept from  in the language. For an interpretation I, an R-path and R-cycle in I
are defined as in the proof of Theorem 4.21.
Claim 4.27. Let I be a finite model of T . Then for all s  I , we have hs, si  (R+ )I .
Proof of claim. Identical to the proof of Claim 4.22 in the proof of Theorem 4.21.

390

a

fiBeth Definability in Expressive Description Logics

Claim 4.28. We have
(a) T |=f > v R .>, and
(b) T |=f > v 1R.
Proof of claim. Part (a) follows immediately from the previous claim.
To prove part (b), suppose, for the sake of a contradiction that T 6|=f > v  1R. Then
there is some finite model I of T and s, t, u  I such that t 6= u and hs, ti, hs, ui  RI .
Since > v  1R  T and I |= T and by part (a) of our claim, we have that (R )I is
the graph of a total function on I . Since t 6= u and hs, ti, hs, ui  RI , we also know that
the cardinality of the image Y of this function must be strictly smaller than the cardinality
of the domain, i.e., |Y | < |I |. This implies that Y ( I . But this contradicts with
> v R.>  T and I |= T . Hence we conclude that T |=f > v  1R.
a
For s, t  I , we write odd(s, t) if there is an R-path of odd length from s to t, that is,
an R-path s0 , . . . , sn such that s = s0 , t = sn , and n is odd. Note that in an R-path like
s0 , . . . , sn , we always have n > 0.
Claim 4.29. For all finite models I of T , we have
B I = {s  I | t  I .odd(s, t)  t  AI }.
Proof of claim. () Suppose s  B I . By the first claim, there is some R-cycle p = s0 , . . . , sn ,
where s0 = sn = s and n > 0. Since > v R+ .A  T and I |= T , there is some t  I
such that hs, ti  (R+ )I and t  AI . We claim that t = si , for some i  {1, . . . , n  1}. To
show this, we proceed towards a contradiction.
Suppose that our claim does not hold. Then there is some R-path t0 , . . . , tm , where
t0 = s and tm = t. Obviously, this path is different from the R-cycle p since t does not
occur in p. Now by using T |=f > v 1R from the previous claim, we can show that every
individual ti actually appears in p, which contradicts with the fact that t does not appear
in p. Hence we conclude that there is some i  {1, . . . , n  1} such that si = t.
We will now show that i is odd. By A v B  T , I |= T , and t  AI , we have t 6 B I .
Then by using s  B I and the axioms R.B v B  T , R.B v B  T , one can easily
show by induction that i is odd. This implies odd(s, t).
Hence there is some t  I such that odd(s, t) and t  AI , which is what we wanted to
show.
() Suppose s  I such that there is some t  I with odd(s, t) and t  AI . This implies
that there is some R-path s0 , . . . , sn such that s0 = s, sn = t, and n is odd. By t  AI ,
A v B  T , and I |= T , we have t 6 B I . Then by using the fact that n is odd, the axioms
R.B v B  T and R.B v B  T , one can easily show by induction that s  B I . a
Claim 4.29 implies that B is f-implicitly definable from  under T . The rest of the proof
shows that there is no f-explicit definition of B from  under T . For each n  0, let In be
the following interpretation:
 In = {s0 , . . . , s2n+3 }
391

fiTen Cate, Franconi, & Seylan

 RIn = {hsi , si+1 i | 0  i < 2n + 3}  {hs2n+3 , s0 i}
 AIn = {sn+2 },
 B In = {si | 0  i  2n + 3 and odd(si , sn+2 )}.
Intuitively, In is an R-cycle of (even) length 2n + 4, some of whose elements satisfy the
concept name A and/or B. Observe that In , for n  0, is a model of T . Define the function
d : In  N as follows.

i  (n + 2) if i  n + 2
d(si ) =
(n + 2)  i if i < n + 2
In other words, d(s) is the distance between s and sn+2 .
For each ALCF I + -concept C, we will denote by md(C) the modal depth of C, that is,
the maximal nesting depth of role constructors in C. Formally,
 md(A) = md(>) = md( 1R) = 0
 md(C) = md(C)
 md(C u D) = max{md(C), md(D)}
 md(R.C) = md(R+ .C) = md(C) + 1
where A  CA and R is of the form P or P  with P  NR .
Claim 4.30. For all i  {0, . . . , n} and all s, s0  In \ {s  In | d(s)  i}, we have
s  C In iff s0  C In
for all ALCF I + -concepts with md(C)  i and sig(C)  .
Proof of claim. Let i  {0, . . . , n}, s, s0  In \ {s  In | d(s)  i}, and C be an
ALCFI + -concept with md(C)  i and sig(C)  . The proof is by induction on i.
For i = 0. Since md(C) = 0 and sig(C)  , C obeys the following grammar:
C ::= > | A | 1S | C | C u C
where S = R or S = R (recall that we forbid the use of transitive closure inside functionality restrictions).
By induction on the structure of C, we show that s  C In iff s0  C In .
 C = >. By the definition of an interpretation, we have s  >In and s0  >In . Hence
s  >In iff s0  >In .
 C = A (recall that A is the only concept name in ). By assumption, we have s 6= sn+2
and s0 6= sn+2 . Then by the definition of In , we obtain s 6 AIn and s0 6 AIn . Hence
s  AIn iff s0  AIn .
 C = 1S. By the definition of In , we have for all t  In that |S In (t)| = 1. Then in
particular, |S In (s)| = |S In (s0 )| = 1. Hence s  ( 1S)In iff s0  ( 1S)In .
392

fiBeth Definability in Expressive Description Logics

 C = D. Follows easily by the inductive hypothesis for C.
 C = C1 u C2 . Follows easily by the inductive hypothesis for C.
Hence we conclude that s  C In iff s0  C In , for i = 0.
Next, consider the case that i > 0, and let md(C)  i and sig(C)  . Then we have
that C obeys the following grammar:
C ::= S.E | S + .E | C | C u C
where md(E)  i  1, and S = R or S = R . By induction on the structure of C, we show
that s  C In iff s0  C In .
 C = S.E with md(E)  i  1, and S = R or S = R . By the definition of In , we
have that there is exactly one t  In with hs, ti  S In and exactly one t0  In with
hs0 , t0 i  S In . Moreover, t, t0  In \ {s  In | d(s)  i  1}. We have that the
following are equivalent:
 s  (S.E)In
 t  E In (since t is the only individual with hs, ti  S In )
 t0  E In (by the inductive hypothesis for i)
 s0  (S.E)In (since t is the only individual with hs0 , t0 i  S In ).
 D = S + .E with md(E) = i  1, and S = R or S = R . Suppose first s  (S + .E)In .
Then there is some t  I such that hs, ti  (S In )+ and t  E In . We distinguish the
following cases:
 t 6= s0 . Then by the definition of In , we immediately obtain hs0 , ti  (S In )+ ; and
by t  E In this implies s0  (S + .E)In .
 t = s0 . By the definition of In , we have hs0 , si  (S In )+ . Moreover, s, s0 
In \ {s  In | d(s)  i  1}. Then by the inductive hypothesis on i and
s0  E In , we have s  E In , which implies by hs0 , si  (S In )+ that s0  (S + .E)In .
Hence s0  (S + .E)In in both cases, which is what we wanted to show. The direction
from right to left can be shown analogously.
 The other cases can be shown easily by the inductive hypothesis on C.
a

Hence the claim follows.

Claim 4.31. There is no ALCF I + -concept C such that sig(C)  {A, R} and T |=f B  C.
Proof of claim. We proceed towards a contradiction so suppose the existence of such a
concept C. By definition, md(C) = n, for some n  0; and s0 , s1  In \ {s  In | d(s) 
n}. Then by the previous claim, we have s0  C In iff s1  C In . Then by the fact that In
is a finite model of T and T |=f B  C, we have s0  B In iff s1  B In . This implies by the
definition of In and Claim 4.29 that odd(s0 , sn+2 ) iff odd(s1 , sn+2 ), which is a contradiction.
Hence we conclude that there exists no ALCF I + -concept C such that sig(C)  {A, R} and
T |= B  C.
a
393

fiTen Cate, Franconi, & Seylan

Now the proof of the theorem is as follows. By Claim 4.29, B is f-implicitly definable
from  = {A, R} under T . But by Claim 4.31, B is not f-explicitly definable from  under
T . Hence ALCF I + does not have BPF.

5. Concluding Remarks
In this paper, we studied BP in expressive DLs with commonly used concept constructors.
All of these constructors appear in the Web Ontology Language OWL-Lite (Horrocks et al.,
2003). OWL-Lite is now superseded by OWL 2, which supports some other important constructors such as nominals, denoted by O in the language, and qualified number restrictions,
denoted by Q in the language. There are already some results available regarding BP in
logics having Q or O.
Q is a generalization of F and ten Cate et al. (2006) show via a model-theoretic argument
that CBP holds in ALCQ. We believe that BP can also be shown to hold for ALCQ and
ALCQI using a model-theoretic argument; although such an argument gives no upper
bound on the size of explicit definitions. Extending our upper bound results on the size of
explicit definitions to these logics appears to be more difficult because of the unavailability
of a natural and optimal tableau algorithm for these logics.
In logics with O, besides the concept and role names, we assume a set NI = {i, j, . . .}
of nominals. Syntactically, nominals are treated as atomic concepts but semantically each
nominal is interpreted as a singleton set. The presence of nominals gives rise to two different Beth definability properties. In the first one, we are allowed to restrict the nominals
appearing in implicit/explicit definitions by making them part of the signature ; in the
second one, definitions are allowed to use any nominal from NI . Obviously, the first one
is a stronger property. Ten Cate et al. (2006) show that even the second property fails in
ALCO. They also observe that extending ALCO with concepts of the form @i C is enough
to regain CBP. Intuitively, @i C says that the point satisfying the nominal i also satisfies
the concept C.
In a similar way, one can try to identify an extension of ALCH that has BP. In the
proof of Theorem 4.18, our argument for the failure of BP in the considered logics was that
they can not express role conjunction. It remains open if ALCH extended with the role
conjunction constructor has BP. Another interesting open question is to identify a minimal
extension of ALCF I having BPF.
By Theorem 3.36, we know how to compute first-order explicit definitions of single
exponential size, given that a concept is implicitly defined under a TBox. We leave as
another open problem the existence of a matching lower bound, i.e., is there a family of
TBoxes implicitly defining a concept such that smallest explicit definitions in first-order
logic are single exponentially big?

Acknowledgments
We are grateful to Carsten Lutz and Maarten Marx for helpful discussions on the topic. A
substantial part of the research was carried out during an extended visit of Inanc Seylan to
394

fiBeth Definability in Expressive Description Logics

UC Santa Cruz in 2010, and we thank Phokion Kolaitis for his hospitality. We also thank
the anonymous reviewers for their extensive comments.
Balder ten Cate was supported by the NSF grants IIS-0905276 and IIS-1217869.

Appendix A. Quasimodels
Decision procedures based on semantic tableau do not construct a model of the given formula/concept, but a finite representation of a model from which the model can be unfolded.
In this paper, we will use the term quasimodel to denote such a finite representation following Andreka, Nemeti, and van Benthem (1998). Various other names have been used in the
literature, including Hintikka structures (Schwendimann, 1998), model graph (Gore, 1999),
and even tableau (Horrocks & Sattler, 2007). Modulo some differences, the building blocks
of these structures are sets of finite concepts each of which is a subset of a relevant concept
closure. We will be using the definition of concept closure cl(C, T ) given in Section 3.1.
Remark A.1. For the rest of the appendix, we assume that ALCF-concepts are defined
recursively as in Section 2.1 using also , t, R.C, and  2R as primitives; all concepts
are in NNF; and ALCF-TBoxes consist only of axioms of the form > v C. For a discussion
of these assumptions, we refer the reader to the beginning of Section 3.1.
Not every subset of the concept closure is suitable to take part in a quasimodel. Depending on the logic at hand, these sets satisfy some basic consistency requirements. Following,
e.g., Lutz et al. (2005), we will use the term type to denote these sets satisfying these requirements. Note, however, that the non-membership of a concept in a type does not imply
the membership of the negation of the concept in the type. In this respect, our types are
similar to Hintikka sets, which are also called downward-saturated sets (cf. Fitting, 1996).
Definition A.2. Let C0 be an ALCF-concept and let T be an ALCF-TBox. A  
cl(C0 , T ) is called an hC0 , T i-type for ALCF if and only if for all A, C, C1 , C2 , R.C, 
2R,  1R  cl(C0 , T ),
(P )  6  ;
(P ) {A, A} 6  ;
(Pu ) if C1 u C2   , then C1   and C2   ;
(Pt ) if C1 t C2   , then C1   or C2   ;
(Pv ) if > v C  T , then C   ;
(P./ ) { 1R,  2R} 6  ;
(P1 ) if { 1R, R.C}   , then R.C   .
When a type belongs to a quasimodel, it may force some other type to also belong to
the quasimodel, for instance to witness an existential statement. In fact, a quasimodel is a
collection of types coherent with each other in this sense.
395

fiTen Cate, Franconi, & Seylan

Definition A.3. Let C0 be an ALCF-concept, T an ALCF-TBox and ,  two hC0 , T itypes for ALCF.
R.C

 We write  ===  if R.C   and {C}  {C 0 | R.C 0   }  .
2R

 We write  ===  if  2R   and {C 0 | R.C 0   }  .
 A set Q of hC0 , T i-types for ALCF is a hC0 , T i-quasimodel for ALCF if it satisfies:
(a) there is some 0  Q such that C0  0 ;
R.C

(b) for every   Q and R.C   , there is a type   Q such that  === ; and
2R

(c) for every   Q and  2R   , there is a type   Q such that  === .
The following theorem will be useful in soundness and completeness proofs of the tableau
and interpolation algorithms. Its proof is inspired by Marx and Venema (2007).
Theorem A.4. An ALCF-concept C0 is satisfiable w.r.t. an ALCF-TBox T if and only if
there is some hC0 , T i-quasimodel for ALCF.
Proof. () Given a model I = hI , I i of T with C0I 6= , we carve out for all s  I , a
set of concepts L(s)  cl(C0 , T ) as follows.
L(s) = {C  cl(C0 , T ) | s  C I }.
Now let Q = {L(s) | s  I }.
Claim A.5. Each   Q is a hC0 , T i-type for ALCF.
Proof of claim. Suppose   Q. Then  = L(s) for some s  I . We verify the conditions
in Definition A.2.
 By definition, I =  and thus s 6 I and thus  6 L(s). Hence (P ) is satisfied.
 By the virtue of I being an interpretation, it is not the case that s  AI and s  (A)I .
Hence (P ) is satisfied.
 If C1 u C2  L(s), then s  (C1 u C2 )I . Since I is an interpretation, s  C1I and
s  C2I . But then C1 , C2  L(s). Hence (Pu ) is satisfied.
 If C1 t C2  L(s), then s  (C1 t C2 )I . Since I is an interpretation, s  C1I or s  C2I .
But then C1  L(s) or C2  L(s). Hence (Pt ) is satisfied.
 If > v C  T , then I  C I and thus s  C I . But then C  L(s). Hence (Pv ) is
satisfied.
 Suppose for a contradiction that (P./ ) does not hold. Then s  ( 1R)I and s  (
2R)I . But this is a contradiction. Hence (P./ ) is satisfied.
 Suppose { 1R, R.C}   . By assumption s  ( 1R)I and s  (R.C)I . Then it
follows that there is exactly one t  I such that hs, ti  RI and t  C I . But then
s  (R.C)I . Hence (P1 ) is satisfied.
396

fiBeth Definability in Expressive Description Logics

Since we have shown that all the conditions in Definition A.2 are satisfied, we conclude that
 is a hC0 , T i-type for ALCF.
a
We claim that Q is a hC0 , T i-quasimodel. By Claim A.5, if   Q, then  is a hC0 , T i-type
for ALCF. Thus it remains to show that condition (a), (b), and (c) from Definition A.3 are
satisfied.
For (a), since C0I 6= , there is some s0  I such that s0  C0I and by the construction
of Q, L(s0 ) is in Q. Hence, condition (a) is satisfied.
For condition (b), suppose R.C  L(s) for some s  I . This means s  (R.C)I ,
i.e., there is some individual t such that hs, ti  RI and t  C I . Then by the construction
of Q, we have C  L(t). Now let R.D  L(s). Then by the construction of Q, we have
s  (R.D)I . This implies by hs, ti  RI that t  DI . By the construction of Q again, we
R.C

obtain D  L(t). Hence, L(s) === L(t); and we conclude that (b) is satisfied.
The proof for (c) is analogous.
() Suppose that Q is a hC0 , T i-quasimodel for ALCF. The idea of the proof is to construct
an interpretation I inductively using Q and then show that I |= T and C0I 6= . For this
construction, we need to introduce some notation first.
Let I be an interpretation and let L : I  Q. A pair hs, Ci with s  I and
C  cl(C0 , T ) is called a defect of I w.r.t. L, if and only if,
 R.C  L(s) and there is no t  I such that hs, ti  RI and C  L(t), or
  2R  L(s) and |{t  I | hs, ti  RI }| < 2.
Fix a map f : cl(C0 , T )  N, and let  be any linear order on the Cartesian product N  N
of order type  (recall that a countably infinite linear order is said to have order type  if
for each element in the order there are only finitely many elements that are less than it; it
is well known that there are linear orders on N  N of order type ).
We are now ready to define by induction the interpretations Ii = hIi , Ii i with Ii  N
and mappings Li : Ii  Q, for i  N.
Base case. By condition (a) from Definition A.3, there is some type 0  Q with C0  0 .
Define the interpretation I0 as follows.
 I0 = {s}, for some s  N;
 for all A  NC ,
 if A  0 , then AI0 = {s},
 if A 6 0 , then AI0 = ;
 for all R  NR , RI0 = .
Set L0 = {s 7 0 }.
Inductive step. If there is no defect of Ii w.r.t. Li , then set Ii+1 = Ii and Li+1 = Li ;
otherwise, let hs, Ci be the least defect of Ii w.r.t. Li , i.e., for every defect ht, Di of Ii w.r.t.
Li , we have hs, f (C)i  ht, f (D)i (using the fact that  has order type ). By Li (s)  Q
C

and conditions (b) and (c) from Definition A.3, there is some   Q such that Li (s) =
 .
If C = R.D, then let t  N \ Ii and define
397

fiTen Cate, Franconi, & Seylan

 Ii+1 = Ii  {t},
 for all A  NC ,
 if A   , then AIi+1 = AIi  {t},
 if A 6  , then AIi+1 = AIi ;
 for all S  NR ,
 if S = R, then S Ii+1 = {hs, ti}  S Ii ,
 if S 6= R, then S Ii+1 = S Ii .
Also set Li+1 = Li  {t 7  }. If C = 2R, then let t1 , t2  N \ Ii with t1 6= t2 and define
 Ii+1 = Ii  {t1 , t2 },
 for all A  NC ,
 if A   , then AIi+1 = AIi  {t1 , t2 },
 if A 6  , then AIi+1 = AIi ;
 for all S  NR ,
 if S = R, then S Ii+1 = {hs, t1 i, hs, t2 i}  S Ii ,
 if S 6= R, then S Ii+1 = S Ii .
Also set Li+1 = Li  {t1 7 , t2 7  }. This finishes our inductive construction. Now define
the interpretation I as follows:
S
 I = i0 Ii ,
S
 for all P  NC  NR , P I = i0 P Ii .
S
Also set L = i0 Li . Observe that L is a total mapping from I to Q.
Claim A.6. For all concepts C  cl(C0 , T ) and all s  I , if C  L(s) then s  C I .
Proof of claim. Let s and C be as stated in the claim. Suppose C  L(s). Then by the
definition of L, there is some i  N such that C  Li (s); let i be the smallest natural number
satisfying C  Li (s), i.e., Ii is the interpretation that we introduced s. By induction on the
structure of C, we show that s  C I . Since for all   Q, we have  6  by (P ), it follows
that C 6= . Hence, we consider the remaining cases for C.
 C = >. We have by assumption that s  I , i.e., s  >I .
 C = A, for some A  NC . Then by the definition of Ii and A  Li (s), it immediately
follows that s  AIi . This implies by the definition of I that s  AI .
 C = A, for some A  NC . Since Li (s)  Q, Li (s) satisfies (P ). Then by A  Li (s),
we have A 6 Li (s). One can now easily show by induction that for all k  i, we have
s 6 AIk . This implies by our assumption about i that for all k  N, s 6 AIk . Then
by the definition of I, we obtain s 6 AI , i.e., s  (A)I .
398

fiBeth Definability in Expressive Description Logics

 C = C1 u C2 . Follows easily by the inductive hypothesis and (Pu ).
 C = C1 t C2 . Follows easily by the inductive hypothesis and (Pt ).
 C = R.D. Let t  I such that hs, ti  RI . We need to show that t  DI . By
hs, ti  RI , there is some k  N such that hs, ti  RIk ; w.l.o.g. assume that Ik is the
interpretation that we introduced t. It follows that there is some E  cl(C0 , T ) such
E

that hs, Ei is a defect of Ik1 w.r.t. Lk1 and Lk (s) =
 Lk (t). This implies D  Lk (t).
Then by the definition of L, we obtain D  L(t). By the inductive hypothesis, this
implies t  DI . Hence, s  (R.D)I .
 C = R.D. By our assumption about i, we have that hs, Ci is a defect of Ii w.r.t. Li .
By the definition of , there are finitely many pairs ht, Ei with t  N and E  cl(C0 , T )
such that ht, f (E)i  hs, f (C)i. This implies that there is some k > i such that we
fix the defect hs, Ci at step k. Then there is some t  Ik such that hs, ti  RIk and
D  Lk (t). By the definition of I, we then have hs, ti  RI and D  L(t). By the
inductive hypothesis, the latter implies t  DI . Hence, s  (R.D)I .
 C = 1R. Suppose for a contradiction that there are t1 , t2  I such that t1 6= t2
and hs, t1 i, hs, t2 i  RI . Then there are k1 , k2  N such that hs, ti i  RIki and Iki
is the interpretation that we introduced ti , for each i  {1, 2}. By our construction,
this implies that there are concepts C1 , C2  cl(C0 , T ) such that hs, Ci i is a defect
C

i
of Iki 1 w.r.t. Lki 1 and Lki (s) =
Lki (ti ), for each i  {1, 2}. It follows that
Ci 6= 2R, for each i  {1, 2}; otherwise, we would obtain a contradiction by (P./ ).
Thus, C1 = R.D1 and C2 = R.D2 . Then by the definition of cl(C0 , T ), we have
R.D1 , R.D2  cl(C0 , T ); and by (P1 ), this implies R.D1 , R.D2  Lk1 (s) =
Lk2 (s). Suppose w.l.o.g. that k1 < k2 . Then D2  Lk1 (t1 ). But this contradicts with
the fact that hs, R.D2 i is a defect of Ik2 1 w.r.t Lk2 1 .

 C = 2R. This case can be shown similarly to the case C = R.D.
Since we considered all the possible cases, we conclude that the claim holds.

a

Using Claim A.6, this direction of the Theorem can now be shown easily as follows. By
the base case of our inductive construction, there is some s  I0 such that C0  L0 (s).
This implies C0  L(s) and then by Claim A.6, we obtain s  C0I . Moreover, by Claim A.6
and (Pv ), we have I |= T . Hence C0 is satisfiable w.r.t. T .

Appendix B. Useful Lemmas for Tableau Correctness and Interpolation
For all   cll  clr, we define
(l) = {C | C l    cll} and (r) = {C | C r    clr}.
() is a shorthand for (l)  (r). In the following
S the signature of a set of ALCFconcepts S will be of concern. We define sig(S) = CS sig(C). Let  be a finite set of
ALCF-concepts
and T be an ALCF-TBox. We say that  is satisfiable w.r.t. T if and only
d
if D D is satisfiable w.r.t. T . Moreover a   cll  clr is satisfiable w.r.t. T if and only
if () is satisfiable w.r.t. T .
399

fiTen Cate, Franconi, & Seylan

Lemma B.1. Let   cll  clr be satisfiable w.r.t. T . We have
 if  is an ?-burden of  for ?  {u,  1, ,  2} and  is the -relief of , then  is
satisfiable w.r.t. T ;
 if  is an t-burden of , then there is some -relief  of  such that  is satisfiable
w.r.t. T .
Proof. Suppose that  is as stated in the Theorem, i.e., it is satisfiable w.r.t. T . This
means () is satisfiable w.r.t. T . By Theorem
A.4 we then have that there is some
d
hC, T i-quasimodel Q for ALCF, where C = D() D. This means there is some   Q
such that ()   . We will also use the term h, T i-quasimodel for Q.
Assume that (C1 u C2 ) is an u-burden of . Then the (C1 u C2 ) -relief of  is  =
  {(C1 ) , (C2 ) }. By (Pu ), {C1 , C2 }   and thus ()   . Hence () is satisfiable
w.r.t. T .
Assume that ( 1R) is an  1-burden of . Then the ( 1R) -relief of  is  =
  {(R.C) | (R.C)  }. If (R.C)  , then R.C   and by (P1 ), R.C   .
Hence ()   and  is satisfiable w.r.t. T .
Assume that (R.C) is an -burden of . ()   so by condition (b) of Definition A.3, there is some   Q such that   {C}  {D | R.D  ()}; and by (Pv ),
{E | > v E  T }  . Let  be the (R.C) -relief of . Then we have ()  . Hence
 is satisfiable w.r.t. T .
Assume that ( 2R) is an  2-burden of . ()   so by condition (b) of Definition A.3, there is some   Q such that   {D | R.D  ()}; and by (Pv ),
{E | > v E  T }  . Let  be the  2R-relief of . Then we have ()  .
Hence  is satisfiable w.r.t. T .
Assume that (C1 t C2 ) is an t-burden . Then for some (C1 t C2 ) -relief  of , we
have ()   by (Pt ). Hence, there is some (C1 t C2 ) -relief of  that is satisfiable w.r.t.
T.
Proposition B.2. Let T be an ALCF-TBox and C0 , C1 , . . . , Cn , D be ALCF-concepts.
1. If T |= C0 u C1 u . . . u Cn v D, then
T |= R.C0 u R.C1 u . . . u R.Cn v R.D.
2. If T |= D v C1 t . . . t Cn , then
T |= R.D v R.C1 t . . . t R.Cn .
3. If T |= C1 u . . . u Cn v D, then
T |= 2R u R.C1 u . . . u R.Cn v R.D.
Proof. For 1, we proceed towards a contradiction. Suppose T |= C0 u C1 u . . . u Cn v D
and T 6|= R.C0 u R.C1 u . . . u R.Cn v R.D. Then there is some model I of T such that
I |= C0 u C1 u . . . u Cn v D and I 6|= R.C0 u R.C1 u . . . u R.Cn v R.D. By the latter
400

fiBeth Definability in Expressive Description Logics

there is some s  I such that s  (R.C0 u R.C1 u . . . u R.Cn )I and s 6 (R.D)I . That
is, there is some t  I such that hs, ti  RI , t  (C0 u C1 u . . . u Cn )I , and t  (D)I .
But this contradicts with I |= C0 u C1 u . . . u Cn v D.
For 2, we proceed towards a contradiction. Suppose T |= D v C1 t . . . t Cn and
T 6|= R.D v R.C1 t . . . t R.Cn . Then there is some model I of T such that I |= D v
C1 t . . . t Cn and I 6|= R.D v R.C1 t . . . t R.Cn . By the latter there is some s  I
such that s  (R.D)I and s 6 (R.C1 t . . . t R.Cn )I . That is there is some t  I
such that hs, ti  RI , t  DI , and t  (C1 u . . . u Cn )I . But this contradicts with
I |= D v C1 t . . . t Cn .
Proposition B.3. Let C be an ALCF-concept and R be a role name. Then
|= 1R u R.C u R.C  1R u R.C.
Proof. That |= 1R u R.C u R.C v 1R u R.C is trivial. For the other direction,
suppose for a contradiction that 6|= 1R u R.C v 1R u R.C u R.C. This means there
is some interpretation I = hI , I i such that I 6|= 1R u R.C v 1R u R.C u R.C.
Thus there is some s  I such that s  ( 1R)I , s  (R.C)I , and s  (R.C)I . By
the last two there are t1 , t2  I such that hs, t1 i, hs, t2 i  RI , t1  C I , and t2  (C)I .
But by s  ( 1R)I , t1 = t2 which is a contradiction.
Lemma B.4. Let   cll  clr. We have
1. if l  , then  is an interpolant of ;
2. if r  , then > is an interpolant of ;
3. for a concept C of the form A or  1R,
(a) if {C l , (C)
 l }  , then  is an interpolant of ;
(b) if {C r , (C)
 r }  , then > is an interpolant of ;
(c) if {C l , (C)
 r }  , then C is an interpolant of ;
(d) if {C r , (C)
 l }  , then C
 is an interpolant of ;
4. if  is the (C1 u C2 ) -relief of  and I is an interpolant of , then I is an interpolant
of ;
5. if 1 and 2 are (C1 t C2 )l -reliefs of , and I1 , I2 are interpolants of 1 , 2 respectively, then I1 t I2 is an interpolant of ;
6. if 1 and 2 are (C1 t C2 )r -reliefs of , and I1 , I2 are interpolants of 1 , 2 respectively, then I1 u I2 is an interpolant of ;
7. if  is the ( 1R)l -relief of , there is no biased concept of the form (R.C)r  ,
and I is an interpolant of , then I is an interpolant of ;
8. if  is the ( 1R)r -relief of , there is no biased concept of the form (R.C)l  ,
and I is an interpolant of , then I is an interpolant of ;
401

fiTen Cate, Franconi, & Seylan

9. if  is the ( 1R)l -relief of , there is some biased concept of the form (R.C)r  ,
and I is an interpolant of , then Iu  1R is an interpolant of ;
10. if  is the ( 1R)r -relief of , there is some biased concept of the form (R.C)l  ,
and I is an interpolant of , then It  2R is an interpolant of ;
11. if  is the (R.C)l -relief of , I is an interpolant of , and there is no biased concept
of the form (R.D)r  , then  is an interpolant of ;
12. if  is the (R.C)r -relief of , I is an interpolant of , and there is no biased concept
of the form (R.D)l  , then > is an interpolant of ;
13. if  is the (R.C)l -relief of , I is an interpolant of , and there is some biased
concept of the form (R.D)r  , then R.I is an interpolant of ;
14. if  is the (R.C)r -relief of , I is an interpolant of , and there is some biased
concept of the form (R.D)l  , then R.I is an interpolant of ;
15. if  is the ( 2R)l -relief of , I is an interpolant of , and there is no biased concept
of the form (R.D)r  , then  is an interpolant of ;
16. if  is the ( 2R)r -relief of , I is an interpolant of , and there is no biased concept
of the form (R.D)l  , then > is an interpolant of ;
17. if  is the ( 2R)l -relief of , I is an interpolant of , and there is some biased
concept of the form (R.D)r  , then R.I is an interpolant of ;
18. if  is the ( 2R)r -relief of , I is an interpolant of , and there is some biased
concept of the form (R.D)l  , then R.I is an interpolant of .
Proof. For 1. Suppose (l) = {X1 , . . . , Xn }  {} and (r) = {Y1 , . . . , Ym }. But T |=
 u X1 u . . . , Xn v  and T |=  v Y1 t . . . t Ym hold trivially. Since  is a logical
constant,  = sig()  sig((l))  sig((r)). Hence 1 is satisfied.
For 2. Suppose (r) = {Y1 , . . . , Ym }  {} and (l) = {X1 , . . . , Xn }. But T |=
X1 u . . . , Xn v > and T |= > v Y1 t . . . t Ym t > hold trivially. Since > is a logical
constant,  = sig(>)  sig((l))  sig((r)). Hence 2 is satisfied.
For 3a. Suppose (l) = {X1 , . . . , Xn }  {C, C}

and (r) = {Y1 , . . . , Ym }. But T |=
X1 u . . . , Xn u C u C
 v  and T |=  v Y1 t . . . t Ym hold trivially. Since  is a logical
constant,  = sig()  sig((l))  sig((r)). Hence 3a is satisfied.
The argument for 3b is analogous to the previous case.
For 3c. Suppose (l) = {X1 , . . . , Xn }  {C} and (r) = {Y1 , . . . , Ym }  {C}.

But T |=
X1 u . . . u Xn u C v C, T |= C v Y1 t . . . t Ym t (C),

and sig(C)  sig((l))  sig((r))
hold trivially. Hence 3c is satisfied.
The argument for 3d is analogous to the previous case.
For 4. Suppose  is a (C1 uC2 )l -relief of , I is an interpolant of , (l) = {X1 , . . . , Xn }
{C1 uC2 }, and (r) = {Y1 , . . . , Ym }. By assumption, T |= X1 u. . .uXn u(C1 uC2 )uC1 uC2 v
I, i.e., T |= X1 u. . .uXn u(C1 uC2 ) v I and T |= I v Y1 t. . .tYm . By assumption again,
sig((l)) = sig((l)) and sig((r)) = sig((r)), and thus sig(I)  sig((l))  sig((r)).
402

fiBeth Definability in Expressive Description Logics

Therefore I is an interpolant of . The case for when  is a (C1 u C2 )r -relief of  and I is
an interpolant of  can be shown analogously. Hence 4 is satisfied.
For 5. Suppose 1 and 2 are (C1 t C2 )l -reliefs of , I1 , I2 are interpolants of 1 , 2
respectively, (l) = {X1 , . . . , Xn }  {C1 t C2 }, and (r) = {Y1 , . . . , Ym }. By assumption,
T |= X1 u . . . u Xn u (C1 t C2 ) u C1 v I1 and T |= X1 u . . . u Xn u (C1 t C2 ) u C2 v I2 .
Then we have the following.
T |= I1 t I2 w (X1 u . . . u Xn u (C1 t C2 ) u C1 ) t
(X1 u . . . u Xn u (C1 t C2 ) u C2 )
T |= I1 t I2 w (X1 u . . . u Xn u (C1 t C2 )) u (C1 t C2 )
T |= I1 t I2 w X1 u . . . u Xn u (C1 t C2 )
For the other half, by assumption T |= I1 v Y1 t . . . t Ym and T |= I2 v Y1 t . . . t Ym .
But then T |= I1 t I2 v Y1 t . . . t Ym . Clearly, sig(I1 t I2 )  sig((l))  sig((r)). Hence
5 is satisfied.
The argument for 6 is analogous to the previous case.
For 7. Suppose
  is a ( 1R)l -relief of ,
 I is an interpolant of ,
 (l) = {X1 , . . . , Xn }  { 1R}  {R.C1 , . . . , R.Ck }, where {R.C1 , . . . , R.Ck } =
{R.C  (l)},
 (r) = {Y1 , . . . , Ym },
 there is no biased concept of the form (R.C)r  .
Let E = R.C1 u . . . u R.Ck . By assumption,
T |= X1 u . . . u Xn u  1R u R.C1 u . . . u R.Ck u E v I.
Then by Proposition B.3
T |= X1 u . . . u Xn u  1R u R.C1 u . . . u R.Ck v I
which is what we wanted to show. For the other half, since there is no biased concept of
the form (R.C)r  , we have (r) = (r). But then
T |= I v Y1 t . . . t Ym
which is what we wanted to show. By assumption sig((l)) = sig((l)) and sig((r)) =
sig((r)), and thus sig(I)  sig((l))  sig((r)). Therefore I is an interpolant of . Hence
7 is satisfied.
8 can be shown analogously to the previous case.
For 9. Suppose
  is a ( 1R)l -relief of ,
403

fiTen Cate, Franconi, & Seylan

 I is an interpolant of ,
 (l) = {X1 , . . . , Xn }  { 1R}  {R.C1 , . . . , R.Ck }, where {R.C1 , . . . , R.Ck } =
{R.C  (l)},
 (r) = {Y1 , . . . , Ym }  {R.D1 , . . . , R.Dl }, where {R.D1 , . . . , R.Dl } = {R.C 
(r)},
 there is some biased concept of the form (R.C)r  .
Let E = R.C1 u . . . u R.Ck . By assumption,
T |= X1 u . . . u Xn u  1R u R.C1 u . . . u R.Ck u E v I.
Also, we trivially have the following.
T |= X1 u . . . u Xn u  1R u R.C1 u . . . u R.Ck u E v 1R.
Combining these two, we get
T |= X1 u . . . u Xn u  1R u R.C1 u . . . u R.Ck u E v Iu  1R

which is what we wanted to show.
For the other half, let F = R.C1 t . . . t R.Cl . By the assumption about I,
T |= I v Y1 t . . . t Ym t R.C1 t . . . t R.Cl t F.
From this, we trivially get
T |= I v Y1 t . . . t Ym t R.C1 t . . . t R.Cl t F t  2R.

Then by Proposition B.3,
T |= I v Y1 t . . . t Ym t R.C1 t . . . t R.Cl t  2R,
which implies
T |= Iu  1R v Y1 t . . . t Ym t R.C1 t . . . t R.Cl ,
and this is what we wanted to show. By assumption sig((l)) = sig((l)) and sig((r)) =
sig((r)), and thus sig(I)  sig((l))  sig((r)). Moreover, since there is some biased
concept of the form (R.C)r  , R  sig((l))  sig((r)). In conclusion, sig(Iu  1R) 
sig((l))  sig((r)). Hence 9 is satisfied.
10 can be shown analogously to the previous case.
For 11. Suppose the following:
  is the (R.C)l -relief of ,
 I is an interpolant of ,
d
F
 E = >vCTl C, F = >vCTr C,
404

fiBeth Definability in Expressive Description Logics

 (l) = {X1 , . . . , Xn }  {R.C}  {R.D1 , . . . , R.Dk }, where {R.D1 , . . . , R.Dk } =
{R.D  (l)},
 there is no biased concept of the form (R.D)r  .
By the last assumption, (r) = {C | > v C  Tr }. By assumption, T |= I v F . Since
T |= F v , we have that T |= I   and thus T |= R.I  . By assumption again
T |= C u D1 u . . . u Dk u E v I. Since T |= > v E, we have that T |= C u D1 u . . . u Dk v I.
By Proposition B.2
T |= R.C u R.D1 u . . . u R.Dk v R.I.
However by T |= R.I   this means
T |= R.C u R.D1 u . . . u R.Dk v .
Hence,
T |= X1 u . . . u Xn u R.C u R.D1 u . . . u R.Dk v 
which is what we wanted to show. For the other half, let (r) = {Y1 , . . . , Ym }. Since
T |= I  , we have trivially
T |=  v Y1 t . . . t Ym
As the final step, we need to show that
sig()  sig((l))  sig((r)).
But this follows easily since  is a logical constant. Hence 11 is satisfied.
For 12. Suppose the following:
  is the (R.C)r -relief of ,
 I is an interpolant of ,
d
F
 E = >vCTl C, F = >vCTr C,
 (r) = {Y1 , . . . , Ym }  {R.C}  {R.D1 , . . . , R.Dk }, where {R.D1 , . . . , R.Dk } =
{R.D  (r)},
 there is no biased concept of the form (R.D)l  .
By the last assumption, (l) = {C | > v C  Tl }. By assumption, T |= E v I. Since
T |= > v E, we have that T |= I  > and thus T |= R.I  >. By assumption again T |=
I v CtD1 t. . .tDk tF . Since T |= F v , we have that T |= I v CtD1 t. . .tDk .
By Proposition B.2
T |= R.I v R.C t R.D1 t . . . t R.Dk .
However by T |= >  R.I, this means
T |= > v R.C t R.D1 t . . . t R.Dk .
405

fiTen Cate, Franconi, & Seylan

Hence,
T |= > v Y1 t . . . t Ym t R.C t R.D1 t . . . t R.Dk
which is what we wanted to show. For the other half, let (l) = {X1 , . . . , Xn }. Since
T |= I  >, we have trivially
T |= X1 u . . . u Xn v >
As the final step, we need to show that
sig(>)  sig((l))  sig((r)).
But this follows easily since > is a logical constant. Hence 12 is satisfied.
For 13. Suppose the following:
  is the (R.C)l -relief of ,
 I is an interpolant of ,
d
F
 E = >vCTl C, F = >vCTr C,
 (l) = {X1 , . . . , Xn }  {R.C}  {R.D1 , . . . , R.Dk }, where {R.D1 , . . . , R.Dk } =
{R.D  (l)},
 (r) = {Y1 , . . . , Ym }  {R.C1 , . . . , R.Cl }, where l  1 and {R.C1 , . . . , R.Cl } =
{R.C  (r)}.
By assumption, T |= C u D1 u . . . u Dk u E v I. Since T |= > v E, we have that
T |= C u D1 u . . . u Dk v I. By Proposition B.2
T |= R.C u R.D1 u . . . u R.Dk v R.I

(5)

Now by (5), we have
T |= X1 u . . . u Xn u R.C u R.D1 u . . . u R.Dk v R.I
which is what we wanted to show. Now we argue for the other half. By assumption,
T |= I v C1 t . . . t Cl t F . Since T |= F v , we have that T |= I v C1 t . . . t Cl .
By Proposition B.2
T |= R.I v R.C1 t . . . t R.Cl
(6)
Now by (6), we have
T |= R.I v Y1 t . . . t Ym t R.C1 t . . . t R.Cl
which is what we wanted to show. As the final step, we need to show that
sig(R.I)  sig((l))  sig((r)).
But this follows easily since by assumption sig(I)  sig((l))  sig((r)) and R  sig((l)) 
sig((r)), where the latter is a consequence of l  1.
The argument for 14 is analogous to the previous case. Moreover 15, 16, 17, 18 can be
shown similarly to 11, 12, 13, 14, respectively.
406

fiBeth Definability in Expressive Description Logics

Appendix C. Tableau Correctness, Termination, and Interpolation
Lemma C.1. Let T = hV, Ei be the output of the second phase. Then for every node g  V:
1. g.status is either sat or unsat.
2. If g.status = unsat, then either one of the following holds.
 g is a sink node3 containing a clash;
 there is exactly one successor of g 0 of g such that for some (C1 uC2 )  g.content,
g 0 .content is a (C1 u C2 ) -relief of g.content and g 0 .status = unsat;
 there is exactly one successor of g 0 of g such that for some ( 1R)  g.content,
g 0 .content is a ( 1R) -relief of g.content and g 0 .status = unsat;
 there are exactly n successors g1 , . . . , gn of g, where n is the cardinality of the
set {(C1 )1 , . . . , (Cn )n } of all - or  2-burdens of g.content, gi .content is the
(Ci )i -relief of g.content for i  {1, . . . , n}, and there is some i  {1, . . . , n} such
that gi .status = unsat; or
 there are exactly two successors g1 , g2 of g such that for some (C1 t C2 ) 
g.content, gi .content is a (C1 tC2 ) -relief of g.content for i  {1, 2}, g1 .content 6=
g2 .content, and gi .status = unsat for i  {1, 2}.
3. If g.status = sat, then either one of the following holds.
 g is a sink node not containing a clash,
 there is exactly one successor of g 0 of g such that for some (C1 uC2 )  g.content,
g 0 .content is a (C1 u C2 ) -relief of g.content and g 0 .status = sat;
 there is exactly one successor of g 0 of g such that for some ( 1R)  g.content,
g 0 .content is a ( 1R) -relief of g.content and g 0 .status = sat;
 there are exactly n successors g1 , . . . , gn of g, where n is the cardinality of the
set {(C1 )1 , . . . , (Cn )n } of all - or  2-burdens of g.content, gi .content is the
(Ci )i -relief of g.content for i  {1, . . . , n}, and for all i  {1, . . . , n} we have
gi .status = sat; or
 there are exactly two successors g1 , g2 of g such that for some (C1 t C2 ) 
g.content, gi .content is a (C1 tC2 ) -relief of g.content for i  {1, 2}, g1 .content 6=
g2 .content, and there is some i  {1, 2} such that gi .status = sat.
Proof. 1 clearly follows from the fact that every node that is not assigned the status unsat
during the Propagate step of Algorithm 1 gets the status sat at the end (Assign) of Algorithm 1.
Let g  V. By the definition of the tableau algorithm, g satisfies exactly one of the
following structural conditions:
 g is a sink node;
3. a node with no outgoing edges

407

fiTen Cate, Franconi, & Seylan

 there are exactly two successors g1 , g2 of g such that for some (C1 t C2 )  g.content,
gi .content is a (C1 t C2 ) -relief of g.content for i  {1, 2};
 there is exactly one successor of g 0 of g such that for some (C1 u C2 )  g.content,
g 0 .content is a (C1 u C2 ) -relief of g.content;
 there is exactly one successor of g 0 of g such that for some ( 1R)  g.content,
g 0 .content is a ( 1R) -relief of g.content;
 there are exactly n successors g1 , . . . , gn of g, where n is the cardinality of the set
{(C1 )1 , . . . , (Cn )n } of all - or  2-burdens of g.content, and gi .content is the (Ci )n relief of g.content for i  {1, . . . , n}.
Suppose first g.status = unsat then g clearly respects 2 because these are the only ways
for a node to get status unsat in Propagate. Suppose now g.status = sat. Then g.status is
determined in Assign of Algorithm 1. We distinguish between the structural properties of
g above.
Suppose g is a sink node. This means that no rule is applied to g. Then by g.status =
sat, we immediately obtain that g.status does not contain a clash; because if g.status
contains a clash, we would have g.status = unsat and this contradicts with the fact that
for every node g  V, the value of g.status is only calculated once.
Suppose there are exactly two successors g1 , g2 of g such that for some (C1 t C2 ) 
g.content, gi .content is a (C1 t C2 ) -relief of g.content for i  {1, 2}. Since g.status = sat,
g.status was undefined right before Assign. This implies that there is some i  {1, 2}
such that gi .status was undefined because otherwise g.status = unsat. Then after Assign,
gi .status = sat. Hence, g satisfies 3.
Suppose there is exactly one successor of g 0 of g such that for some (C1 u C2 ) 
g.content, g 0 .content is a (C1 u C2 ) -relief of g.content. Since g.status = sat, g.status was
undefined right before Assign. This implies that, g 0 .status was undefined before Assign
because otherwise g.status = unsat. Then after Assign, g 0 .status = sat. Hence, g satisfies
3.
The remaining cases can be shown analogously. Hence the lemma follows.
Proof of Lemma 3.7. We start with some observations. Algorithm 1 assigns the status
unsat to nodes in V during the Propagate phase. These status assignment steps induce a
sequence 0, 1, 2. . . .. To each assignment step i, we can associate a set Vi such that Vi are
all the nodes with status unsat so far. Observe that from step i to step i + 1, we extend
Vi by a single node only. By induction on the number of status assignment steps, we first
show that for all g  Vi ,
 g.content is unsatisfiable w.r.t. T ;
 there is some ALCF-concept C such that
 int(g) = C,
 C is an interpolant of g.content,
 |int(g)|  2i+2  1.
408

fiBeth Definability in Expressive Description Logics

As the base case, we have that V0 = {g} for some sink node g  V containing a clash.
Obviously, g.content is unsatisfiable. The interpolant calculation rules of Figure 2 cover all
the cases for this clash and thus, some ALCF-concept is assigned to int(g). By Lemma B.4,
int(g) is an interpolant of g.content. We claim that |int(g)|  2. For int(g) of the form >,
, A, or A, this is clear; and for int(g) of the form  1R (or  2R), we observe that
it can be encoded using one symbol for  1 (resp.  2) and one symbol for R. Hence,
|int(g)|  2  2i+2  1 and the inductive hypothesis holds for the base case.
For the inductive step, let Vi+1 = Vi  {g}. The inductive hypothesis holds for every
g 0  Vi , trivially; thus, we only consider the case for g. By Lemma C.1, we have five cases
to distinguish:
1. g is a sink node containing a clash. This can be shown analogously to the base case.
2. There is exactly one successor of g 0 of g such that for some (C1 u C2 )  g.content,
g 0 .content is a (C1 u C2 ) -relief of g.content and g 0 .status = unsat. By the inductive
hypothesis, g 0 .content is unsatisfiable w.r.t. T , int(g 0 ) is an interpolant of g 0 , and
|int(g 0 )|  2i+2  1. Then by (the contrapositive version of) Lemma B.1, g.content
is unsatisfiable w.r.t. T . Moreover, Cu was applied to calculate int(g) and int(g) =
int(g 0 ). By Lemma B.4, int(g) is an interpolant of g.content. We have by int(g) =
int(g 0 ) and |int(g 0 )|  2i+2  1 that |int(g)|  2i+3  1. Hence the inductive hypothesis
holds for this case.
3. There are exactly two successors g1 , g2 of g such that for some (C1 t C2 )  g.content,
gj .content is a (C1 t C2 ) -relief of g.content for j  {1, 2}, g1 .content 6= g2 .content,
and gj .status = unsat for j  {1, 2}. By the inductive hypothesis, gj .content is
unsatisfiable w.r.t. T , int(gj ) is an interpolant of gj , and |int(gj )|  2i+2  1, for j 
{1, 2}. Then by (the contrapositive version of) Lemma B.1, g.content is unsatisfiable
w.r.t. T . Moreover, depending on , either Clt or Crt was applied to calculate int(g).
By Lemma B.4, int(g) is an interpolant of g.content. We have that |int(g)| = |int(g1 )|+
|int(g2 )| + 1. Then by the inductive hypothesis, we obtain
|int(g)|  (2i+2  1) + (2i+2  1) + 1 = 2i+3  1.
Thus, the inductive hypothesis holds for this case.
4. The other cases can be shown similarly.
Hence, our claim follows.
Now, we use the claim that we have just shown to prove the lemma. Let g  V with
g.status = unsat. By Lemma 3.5, we have |V|  2n , where n = |cll  clr|. Thus, in the
worst case, there are 2n status assignment steps in Propagate because then V2n = V. Since
g.status = unsat, it follows that g  V2n . Then by our claim, g.content is unsatisfiable w.r.t.
n
n
T , int(g) is defined and it is an interpolant of g.content, and |int(g)|  22 +2 1 = 422 1.
n
But then int(g)  O(22 ). Hence the lemma follows.
Proof of Lemma 3.8. Algorithm 1 consists of two stages: Propagate and Assign.
In Assign, we make 2n assignments because by Lemma 3.5 the number of nodes in the
tableau is bounded by that number. Moreover, each assignment step takes a constant time.
So the whole Assign stage takes time O(2n ).
409

fiTen Cate, Franconi, & Seylan

In Propagate, we have a for loop inside a do-while loop. The for loop iterates over 2n
nodes and assigns, if possible, the status unsat to a node by checking in the worst case n
direct successors of the node. If the algorithm assigns the status unsat to a node g, then it
n
also assigns a concept to int(g). By Lemma 3.7, |int(g)|  O(22 ). Thus it spends most of
its time calculating int(g). Suppose the for loop finished its iteration over all nodes in the
tableau. Now if during its execution, none of the nodes got the status unsat, the do-while
loop terminates because done = true. In the worst case, a status will be assigned only to
one node in each iteration of the do-while loop. Hence the do-while loop iterates at most 2n
n
times and as we discussed each iteration takes time at most O(22 ) because of interpolation
calculation. Since this dominates the runtime of Algorithm 1, the lemma follows.
Lemma C.2 (Soundness). If T is a closed hC0 v D0 , T i-tableau, then T |= C0 v D0 .
Proof. Let T be a closed hC0 v D0 , T i-tableau. Since T is closed, g0 .content = unsat. By
g0 .content = {(C0 )l , (D
 0 )r }  {E l | > v E  Tl }  {E r | > v E  Tr } and Lemma 3.7,
this implies
G
l
T |= C0 u
E v D0 t
E
>vETl

>vETr

But then T |= C0 v D0 .
Definition C.3. Let T = hV, Ei be the output of the second phase. We say that a node
g  V is saturated if and only if
 g.status = sat and g is a sink node, or
 g.status = sat and R was applied to g.
For g, g 0  V , g 0 is called a saturation of g if and only if g 0 is saturated, and there is a path
g = g0 , g1 , . . . , gk = g 0 with k  0 in T such that for each 0  i < k, we have gi .status = sat
and the edge hgi , gi+1 i was created by an application of a rule in {Ru , Rt , R1 }.
Lemma C.4. Let T = hV, Ei be a complete tableau for hC0 v D0 , T i. Then we have
1. If g  V is saturated, then g.content() is a hC0 u D
 0 , T i-type.
2. If g  V with g.status = sat, then there is some saturation g 0 of g with g 0 .content 
g.content.
Proof. For 1, suppose that g is saturated. We need to show that g.content() satisfies
Definition A.2. We start with g.content()  cl(C0 u D
 0 , T ). Let C  g.content(). Then
it follows that C   g.content, for some   {l, r}. Since g.content  cll  clr, we have that
C   cll  clr. This implies C  cl(C0 , Tl )  cl(D
 0 , Tr ). But then C  cl(C0 u D
 0 , T ),
which is what we wanted to show.
Now we show that the properties in Definition A.2 are satisfied. By definition, g.status =
sat. g does not contain a clash because otherwise g.status = unsat which would contradict
our assumption. Hence, (P ), (P ), and (P./ ) are satisfied. By definition, g is a sink node
or R was applied to g. In both cases, we have that none of {Ru , Rt , R1 } is applicable
to g: for the former, this follows from the fact that no rule is applicable to g; and for the
410

fiBeth Definability in Expressive Description Logics

latter, this follows from our rule precedence. Hence, (Pu ), (Pt ), (P1 ) are satisfied. Finally,
we have {C | > v C  T }  g.content() as an easy consequence of the definition of the
tableau algorithm. This means (Pv ) is satisfied. Hence, we conclude that 1 holds.
For 2, suppose g  V with g.status = sat. That there is some saturation g 0 of g with
g 0 .content  g.content follows easily by Lemma C.1.
Lemma C.5 (Completeness). If T is an open hC0 v D0 , T i-tableau, then T 6|= C0 v D0 .
Proof. Suppose T = hV, Ei is an open hC0 v D0 , T i-tableau. Since T is open, we have
g0 .status = sat. Then by Lemma C.4, there is some saturation g? of g0 such that g? .content 
g0 .content. Since g? is saturated, it follows by Lemma C.4 that g? .content() is a hC0 u
D
 0 , T i-type. Let 0 = {C0 u D
 0 }g? .content(). We claim that 0 is also a hC0 u D
 0 , T itype. Suppose for a contradiction that it is not. Since g? .content() is such a type, it follows
that (Pu ) is violated for C0 u D
 0  0 , i.e., {C0 , D
 0 } 6 0 . Then by the definition of 0 ,
this means {C0 , D
 0 } 6 g? .content(). But we know that {C0 , D
 0 }  g0 .content() and
by g? .content  g0 .content, this implies {C0 , D
 0 }  g? .content(), i.e., a contradiction.
Hence we conclude that 0 is a hC0 u D
 0 , T i-type. Define
Q = {0 }  {g.content() | g  V is saturated}.
We show that Q is a hC0 u D
 0 , T i-quasimodel because then T 6|= C0 v D0 follows by
Theorem A.4. It is easy to see that Q is a set of hC0 u D
 0 , T i-types: we have already
shown that 0 is such a type; and for g.content() with g  V is saturated, this fact
follows immediately by Lemma C.4. It remains to show that conditions (a), (b), (c) from
Definition A.3 hold.
Condition (a) holds since 0  Q and C0 u D
 0  0 .
Suppose that R.C   for some   Q. We distinguish between  = 0 and  =
g.content() for some saturated g  V. We first argue for the latter. Since g is saturated
and R.C  g.content(), R was applied to g; since g is saturated, we have g.status = sat.
Then by Lemma C.1, there is some successor g 0 of g in T such that {C}  {D | R.D 
 }  g 0 .content() and g 0 .status = sat. Then by Lemma C.4, there is some saturation g 00 of
g 0 such that g 00 .content  g 0 .content. Since g 00 is saturated, we have that g 00 .content()  Q
R.C

and g 00 .content() is a hC0 u D
 0 , T i-type. But then  === g 00 .content(). The case for
 = 0 follows analogously by using the fact that there is some successor g 0 of g? in T such
that {C}  {D | R.D   }  g 0 .content() and g 0 .status = sat. Hence condition (b) from
Definition A.3 is satisfied.
That condition (c) holds can be shown very similarly to the previous case; we leave it
to the reader to verify this. Hence, we conclude that Q is a hC0 u D
 0 , T i-quasimodel.
Proposition 3.9 now follows immediately from Lemma C.2 and Lemma C.5.

References
Afrati, F. N. (2011). Determinacy and query rewriting for conjunctive queries and views.
Theoretical Computer Science, 412 (11), 10051021.
Andreka, H., Nemeti, I., & van Benthem, J. (1998). Modal languages and bounded fragments
of predicate logic. Journal of Philosophical Logic, 27, 217274.
411

fiTen Cate, Franconi, & Seylan

Avigad, J. (2003). Eliminating definitions and skolem functions in first-order logic. ACM
Transactions on Computational Logic, 4, 402415.
Baader, F., & Nutt, W. (2003). Basic description logics. In The Description Logic Handbook,
pp. 4395. Cambridge University Press.
Barany, V., Benedikt, M., & ten Cate, B. (2013). Rewriting guarded negation queries. In
MFCS13, pp. 98110.
Beth, E. W. (1953). On Padoas methods in the theory of definitions. Indagationes Mathematicae, 15, 330339.
Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal logic. Cambridge University
Press.
Boolos, G. S., Burgess, J. P., & Jeffrey, R. C. (2007). Computability and Logic. Cambridge
University Press.
Calvanese, D., & Giacomo, G. D. (2003). Expressive description logics. In The Description
Logic Handbook, pp. 178218. Cambridge University Press.
Calvanese, D., Giacomo, G. D., Lenzerini, M., & Nardi, D. (2001). Reasoning in expressive
description logics. In Handbook of Automated Reasoning, pp. 15811634.
Calvanese, D., Giacomo, G. D., & Rosati, R. (1998). A note on encoding inverse roles
and functional restrictions in ALC knowledge bases. In Description Logics, Vol. 11.
CEUR-WS.org.
ten Cate, B., Conradie, W., Marx, M., & Venema, Y. (2006). Definitorially complete description logics. In KR, pp. 7989.
ten Cate, B., Franconi, E., & Seylan, I. (2011). Beth definability in expressive description
logics. In IJCAI, pp. 10991106.
Conradie, W. (2002). Definability and changing perspectives: The beth property for three
extensions of modal logic. Masters thesis, University of Amsterdam.
Craig, W. (1957). Three uses of the Herbrand-Gentzen theorem in relating model theory
and proof theory. The Journal of Symbolic Logic, 22 (3), 269285.
De Giacomo, G. (1996). Eliminating converse from Converse PDL. Journal of Logic,
Language and Information, 5 (2), 193208.
Donini, F. M. (2003). Complexity of reasoning. In The Description Logic Handbook, pp.
96136. Cambridge University Press.
Duc, C. L., & Lamolle, M. (2010). Decidability of description logics with transitive closure
of roles in concept and role inclusion axioms. In Description Logics, Vol. 573, pp.
372383. CEUR-WS.org.
Fitting, M. (1996). First-order logic and automated theorem proving (2nd ed.). SpringerVerlag.
Friedman, H. (1976). The complexity of explicit definitions. Advances in Mathematics,
20 (1), 1829.
Gabbay, D. M., & Maksimova, L. (2005). Interpolation and Definability in Modal Logics
(Oxford Logic Guides). Clarendon Press.
412

fiBeth Definability in Expressive Description Logics

Ghilardi, S., Lutz, C., & Wolter, F. (2006). Did I damage my ontology? A case for conservative extensions in description logics. In KR, pp. 187197.
Gore, R. (1999). Tableau methods for modal and temporal logics. In Handbook of Tableau
Methods, pp. 297396. Kluwer.
Gore, R., & Nguyen, L. A. (2007). Exptime tableaux with global caching for description
logics with transitive roles, inverse roles and role hierarchies. In TABLEAUX, pp.
133148.
Hoogland, E. (2001). Definability and Interpolation: Model-theoretic investigations. Ph.D.
thesis, University of Amsterdam.
Hoogland, E., & Marx, M. (2002). Interpolation and definability in guarded fragments.
Studia Logica, 70 (3), 373409.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). From SHIQ and RDF
to OWL: The making of a web ontology language. Journal of Web Semantics, 1 (1),
726.
Horrocks, I., & Sattler, U. (2007). A tableau decision procedure for SHOIQ. Journal of
Automated Reasoning, 39 (3), 249276.
Horrocks, I., Sattler, U., & Tobies, S. (2000). Practical reasoning for very expressive description logics. Logic Journal of the IGPL, 8 (3), 239264.
Konev, B., Lutz, C., Ponomaryov, D., & Wolter, F. (2010). Decomposing description logic
ontologies. In KR, pp. 236246.
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2009a). Formal properties of modularisation.
In Modular Ontologies, pp. 2566. Springer.
Konev, B., Walther, D., & Wolter, F. (2009b). Forgetting and uniform interpolation in
large-scale description logic terminologies. In IJCAI, pp. 830835.
Kracht, M. (2007). Modal consequence relations. In Handbook of Modal Logic, pp. 491545.
Elsevier.
Lang, J., & Marquis, P. (2008). On propositional definability. Artificial Intelligence, 172,
9911017.
Libkin, L. (2004). Elements of Finite Model Theory. Springer.
Lutz, C. (2006). Complexity and succinctness of public announcement logic. In AAMAS,
pp. 137143.
Lutz, C., Areces, C., Horrocks, I., & Sattler, U. (2005). Keys, nominals, and concrete
domains. Journal of Artificial Intelligence Research, 23, 667726.
Lutz, C., Piro, R., & Wolter, F. (2010). Enriching EL-concepts with greatest fixpoints. In
ECAI, pp. 4146.
Lutz, C., Sattler, U., & Tendera, L. (2005). The complexity of finite model reasoning in
description logics. Information and Computation, 199 (1-2), 132171.
Lutz, C., Seylan, I., & Wolter, F. (2012a). An automata-theoretic approach to uniform
interpolation and approximation in the description logic EL. In KR.
413

fiTen Cate, Franconi, & Seylan

Lutz, C., Seylan, I., & Wolter, F. (2012b). Mixing open and closed world assumption in
ontology-based data access: Non-uniform data complexity. In Description Logics, Vol.
846, pp. 268278. CEUR-WS.org.
Lutz, C., & Wolter, F. (2011). Foundations for uniform interpolation and forgetting in
expressive description logics. In IJCAI, pp. 989995.
Marx, M. (2007). Queries determined by views: pack your views. In PODS, pp. 2330.
Marx, M., & Venema, Y. (2007). Local variations on a loose theme: Modal logic and
decidability. In Finite Model Theory and Its Applications, pp. 371426. Springer.
Nash, A., Segoufin, L., & Vianu, V. (2010). Views and queries: Determinacy and rewriting.
ACM Transactions on Database Systems, 35 (3).
Nikitina, N., & Rudolph, S. (2012). Expexpexplosion: Uniform interpolation in general EL
terminologies. In ECAI, pp. 618623.
Pasaila, D. (2011). Conjunctive queries determinacy and rewriting. In ICDT, pp. 220231.
Rautenberg, W. (1983). Modal tableau calculi and interpolation. Journal of Philosophical
Logic, 12 (4), 403423.
Sattler, U., Calvanese, D., & Molitor, R. (2003). Relationships with other formalisms. In
The Description Logic Handbook, pp. 137177. Cambridge University Press.
Schwendimann, S. (1998). A new one-pass tableau calculus for PLTL. In TABLEAUX, pp.
277292.
Seylan, I. (2012). DBoxes and Beth Definability in Description Logics. Ph.D. thesis, Free
University of Bozen-Bolzano.
Seylan, I., Franconi, E., & de Bruijn, J. (2009). Effective query rewriting with ontologies
over DBoxes. In IJCAI, pp. 923929.
Seylan, I., Franconi, E., & de Bruijn, J. (2010). Optimal rewritings in definitorially complete
description logics. In Description Logics, Vol. 573, pp. 125136. CEUR-WS.org.
Tobies, S. (2001). Complexity Results and Practical Algorithms for Logics in Knowledge
Representation. Ph.D. thesis, RWTH-Aachen.

414

fiJournal of Artificial Intelligence Research 48 (2013) 67-113

Submitted 3/13; published 10/13

A Survey of Multi-Objective Sequential Decision-Making
Diederik M. Roijers

d.m.roijers@uva.nl

Informatics Institute
University of Amsterdam
Amsterdam, The Netherlands

Peter Vamplew

p.vamplew@ballarat.edu.au

School of Science,
Information Technology and Engineering
University of Ballarat
Ballarat, Victoria, Australia

Shimon Whiteson

s.a.whiteson@uva.nl

Informatics Institute
University of Amsterdam
Amsterdam, The Netherlands

Richard Dazeley

r.dazeley@ballarat.edu.au

School of Science,
Information Technology and Engineering
University of Ballarat
Ballarat, Victoria, Australia

Abstract
Sequential decision-making problems with multiple objectives arise naturally in practice and pose unique challenges for research in decision-theoretic planning and learning,
which has largely focused on single-objective settings. This article surveys algorithms designed for sequential decision-making problems with multiple objectives. Though there is
a growing body of literature on this subject, little of it makes explicit under what circumstances special methods are needed to solve multi-objective problems. Therefore, we
identify three distinct scenarios in which converting such a problem to a single-objective
one is impossible, infeasible, or undesirable. Furthermore, we propose a taxonomy that
classifies multi-objective methods according to the applicable scenario, the nature of the
scalarization function (which projects multi-objective values to scalar ones), and the type
of policies considered. We show how these factors determine the nature of an optimal solution, which can be a single policy, a convex hull, or a Pareto front. Using this taxonomy,
we survey the literature on multi-objective methods for planning and learning. Finally, we
discuss key applications of such methods and outline opportunities for future work.

1. Introduction
Sequential decision problems, commonly modeled as Markov decision processes (MDPs)
(Bellman, 1957a), occur in a range of real-world tasks such as robot control (Kober &
Peters, 2012), game playing (Szita, 2012), clinical management of patients (Peek, 1999),
military planning (Aberdeen, Thiebaux, & Zhang, 2004), and control of elevators (Crites
& Barto, 1996), power systems (Ernst, Glavic, & Wehenkel, 2004), and water supplies
(Bhattacharya, Lobbrecht, & Solomantine, 2003). Therefore, the development of algorithms
c
2013
AI Access Foundation. All rights reserved.

fiRoijers, Vamplew, Whiteson & Dazeley

for automatically solving such problems, either by planning given a model of the MDP (e.g.,
via dynamic programming methods, Bellman, 1957b) or by learning through interaction
with an unknown MDP (e.g., via temporal-difference methods, Sutton & Barto, 1998), is
an important challenge in artificial intelligence.
In most research on these topics, the desirability or undesirability of actions and their
effects are codified in a single, scalar reward function. Typically, the objective of the
autonomous agent interacting with the MDP is then to maximize the expected (possibly
discounted) sum of these rewards over time. In many tasks, a scalar reward function is the
most natural, e.g., a financial trading agent could be rewarded based on the monetary gain
or loss in its holdings over the most recent time period. However, there are also many tasks
that are more naturally described in terms of multiple, possibly conflicting objectives, e.g.,
a traffic control system should minimize latency and maximize throughput; an autonomous
vehicle should minimize both travel time and fuel costs. Multi-objective problems have
been widely examined in many areas of decision-making (Zeleny & Cochrane, 1982; Vira &
Haimes, 1983; Stewart, 1992; Diehl & Haimes, 2004; Roijers, Whiteson, & Oliehoek, 2013)
and there is a growing, albeit fragmented, literature addressing multi-objective decisionmaking in sequential settings.
In this article, we present a survey of the algorithms that have been devised for such
settings. We begin in Section 2 by formalizing the problem as a multi-objective MDP
(MOMDP). Then, in Section 3, we motivate the multi-objective perspective on decisionmaking. Little of the existing literature on multi-objective algorithms makes explicit why a
multi-objective approach is beneficial and, crucially, which cases cannot be trivially reduced
to a single-objective problem and solved with standard algorithms. To address this, we
describe three motivating scenarios for multi-objective algorithms.
Then, in Section 4, we present a novel taxonomy that organizes multi-objective problems
in terms of their underlying assumptions and the nature of the resulting solutions. A key
difficulty with the existing literature is that authors have considered many different types
of problems, often without making explicit the assumptions involved, how these differ from
those of other authors, or the scope of applicability of the resulting methods. Our taxonomy
aims to fill this void.
Sections 5 and 6 survey MOMDP planning and learning methods, respectively, organizing them according to the taxonomy and identifying some key differences between the
approaches examined in the planning and learning areas. Section 7 surveys applications
of these methods, covering both specific applications and more general classes of problems
where MOMDP methods can be applied. Section 8 discusses future directions for the field
based on gaps in the literature identified in Sections 5 and 6, and Section 9 concludes.

2. Background
A finite single-objective Markov decision process (MDP) is a tuple hS, A, T, R, , i where:
 S is a finite set of states,
 A is a finite set of actions,
 T : S  A  S  [0, 1] is a transition function specifying, for each state, action, and
next state, the probability of that next state occurring,
68

fiA Survey of Multi-Objective Sequential Decision-Making

 R : S  A  S   is a reward function, specifying, for each state, action, and next
state, the expected immediate reward,
  : S  [0, 1] is a probability distribution over initial states, and
   [0, 1) is a discount factor specifying the relative importance of immediate rewards.
The goal of an agent that acts in this environment is to maximize the expected return
Rt , which is some function of the rewards received from timestep t and onwards. Typically,
the return is additive (Boutilier, Dean, & Hanks, 1999), i.e., it is a sum of these rewards. In
an infinite horizon MDP, the return is typically an infinite sum, with each term discounted
according to :

X
 k rt+k+1 ,
Rt =
k=0

where rt is the reward obtained at time t. The parameter  thus quantifies the relative
importance of short-term and long-term rewards.
In contrast, in a finite horizon MDP, the return is typically an undiscounted finite sum,
i.e., after a certain number of timesteps, the process terminates and no more reward can be
obtained. While single- and multi-objective methods have been developed for finite horizon,
discounted infinite horizon, and average reward settings (Puterman, 1994), for the sake of
brevity we formalize only infinite horizon discounted reward MDPs in this article.1
An agents policy  determines which actions it selects at each timestep. In the broadest
sense, a policy can condition on everything that is known to the agent. A state-indepedent
value function V  specifies the expected return when following  from the initial state:
V  = E[R0 | ].

(1)

If the policy is stationary, i.e., it conditions only on the current state, then it can be
formalized as  : S  A  [0, 1]: it specifies, for each state and action, the probability of
taking that action in that state. We can then specify the state value function of a policy :
V  (s) = E[Rt | , st = s],
for all t when st = s. The Bellman equation restates this expectation recursively for
stationary policies:
X
X
T (s, a, s )[R(s, a, s ) + V  (s )].
V  (s) =
(s, a)
a

s

Note that the Bellman equation, which forms the heart of most standard solution algorithms
such as dynamic programming (Bellman, 1957b) and temporal-difference methods (Sutton
& Barto, 1998), explicitly relies on the assumption of additive returns. This is important
because, as we explain in Section 4.2.2, some multi-objective settings can interfere with
this additivity property, making planning and learning methods that rely on the Bellman
equation inapplicable.
1. For formalizations of the other settings, see for example the overview by Van Otterlo and Wiering (2012).

69

fiRoijers, Vamplew, Whiteson & Dazeley

State value functions induce a partial ordering over policies, i.e.,  is better than or
equal to   if and only if its value is greater for all states:


     s, V  (s)  V  (s).
A special case of a stationary policy is a deterministic stationary policy, in which one
action is chosen with probability 1 for every state. A deterministic stationary policy can be
seen as a mapping from states to actions:  : S  A. For single-objective MDPs, there is
always at least one optimal policy , i.e.,   :     , that is stationary and deterministic.
Theorem 1. For any additive infinite-horizon single-objective MDP, there exists a deterministic stationary optimal policy (see e.g., Howard, 1960; Boutilier et al., 1999).
If more than one optimal policy exists, they share the same value function, known as
the optimal value function V  (s) = max V  (s). The Bellman optimality equation defines
the optimal value function recursively:
X
T (s, a, s )[R(s, a, s ) + V  (s )].
V  (s) = max
a

s

Note that, because it maximizes over actions, this equation makes use of the fact that there
is an optimal deterministic stationary policy. Because an optimal policy maximizes the
value for every state, such a policy is optimal regardless of the initial state distribution .
However, the state-independent value (Equation 1) may very well be different for different
initial state distributions. Using , the state value function can be translated back into the
state-independent value function (Equation 1):
X
V =
(s)V  (s).
sS

A multi-objective MDP (MOMDP)2 is an MDP in which the reward function R : S 
A  S  n describes a vector of n rewards, one for each objective, instead of a scalar.
Similarly, a value function V in an MOMDP specifies the expected cumulative discounted
reward vector:

X
 k rk+1 | ],
(2)
V = E[
k=0

where rt is the vector of rewards received at time t. The only difference between the single
objective value (Equation 1) and the multi-objective value (Equation 2) of a policy is that
the return, and the underlying sum of rewards, is now a vector rather than a scalar. For
stationary policies, we can also define the multi-objective value of a state:
V (s) = E[


X

 k rt+k+1 | , st = s].

(3)

k=0

In a single-objective MDP, state value functions impose only a partial ordering because

policies are compared at different states, e.g., it is possible that V  (s) > V  (s) but V  (s ) <
2. Multi-objective MDPs should not be confused with mixed-observability MDPs (Ong, Png, Hsu, & Lee,
2010), which are also sometimes abbreviated with MOMDP.

70

fiA Survey of Multi-Objective Sequential Decision-Making



V  (s ). But for a given state, the ordering is complete, i.e., V  (s) must be greater than,

equal to, or less than V  (s). The same is true of state-independent value functions.
In contrast, in an MOMDP, the presence of multiple objectives means that the value
function V (s) for a state s is a vector of expected cumulative rewards instead of a scalar.
Such value functions supply only a partial ordering, even for a given state. For example,


it is possible that, for some state s, Vi (s) > Vi (s) but Vj (s) < Vj (s). Similarly, for


state-independent value functions, it may be that Vi > Vi but Vj < Vj . Consequently,
unlike in an MDP, we can no longer determine which values are optimal without additional
information about how to prioritize the objectives. Such information can be provided in
the form of a scalarization function, which we discuss in the following sections.
Though not the focus of this article, there are also MOMDP variants in which constraints
are specified on some objectives (see e.g., Feinberg & Shwartz, 1995; Altman, 1999). The
goal of the agent is then to maximize the regular objectives while meeting the constraints
on the other objectives. Constrained objectives are fundamentally different from regular
objectives because they are explicitly prioritized over the regular objectives, i.e., any policy
that fails to meet a constraint is inferior to any policy that meets all constraints, regardless
of how well the policies maximize the regular objectives.

3. Motivating Scenarios
While the MOMDP setting has received considerable attention, it is not immediately obvious why it is a useful addition to the standard MDP or why specialized algorithms for
it are needed. In fact, some researchers argue that modeling problems as explicitly multiobjective is not necessary, and that a scalar reward function is adequate for all sequential
decision-making tasks. The most direct formulation of this perspective is Suttons reward
hypothesis, which states that all of what we mean by goals and purposes can be well
thought of as maximization of the expected value of the cumulative sum of a received scalar
signal (reward).3
This view does not imply that multi-objective problems do not exist. Indeed, that
would be a difficult claim, since it is so easy to think of problems that naturally possess
multiple objectives. Instead, the implication of the reward hypothesis is that the resulting
MOMDPs can always be converted into single-objective MDPs with additive returns. Such
a conversion process would involve two steps. The first step is to specify a scalarization
function.
Definition 1. A scalarization function f , is a function that projects the multi-objective
value V to a scalar value.
Vw (s) = f (V (s), w),
where w is a weight vector parameterizing f .
For example, f may compute a linear combination of the values, in which case each element
of w quantifies the relative importance of the corresponding objective (this setting is discussed further in Section 4.2.1). The second step is to define a single-objective MDP with
3. http://rlai.cs.ualberta.ca/RLAI/rewardhypothesis.html

71

fiRoijers, Vamplew, Whiteson & Dazeley

Figure 1: The three motivating scenarios for MOMDPs: (a) the unknown weights scenario,
(b) the decision support scenario, (c) the known weights scenario.

additive returns such that, for all  and s, the expected return equals the scalarized value
Vw (s).
Though it rarely, if ever, makes the issue explicit, all research on MOMDPs rests on the
premise that there exist tasks for which one or both of these conversion steps is impossible,
infeasible, or undesirable. In this section, we discuss three scenarios in which this can occur
(see Figure 1).
The first scenario, which we call the unknown weights scenario (Figure 1a), occurs when
w is unknown at the moment when planning or learning must occur. Consider for example
a public transport system that aims to minimize both latency (i.e., the time that commuters
need to reach their destinations) and pollution costs. In addition, assume that the resulting
MOMDP can be scalarized by converting each objective into monetary cost: economists
can compute the cost of lost productivity due to commuting and pollution incurs a tax that
must be paid in pollution credits purchased at a given price. Assume also that those credits
are traded on an open market and therefore the price constantly fluctuates. If the transport
system is complex, it may be infeasible to compute a new plan every day given the latest
prices. In such a scenario, it can be preferable to use a multi-objective planning method
that computes a set of policies such that, for any price, one of those policies is optimal
(see the planning or learning phase in Figure 1a). While doing so is more computationally
expensive than computing a single optimal policy for a given price, it needs to be done
only once and can be done in advance, when more computational resources are available.
Then, when it is time to select a policy, the current weights, i.e., the price of the pollution
72

fiA Survey of Multi-Objective Sequential Decision-Making

credits, are used to determine the best policy from the set (the selection phase). Finally,
the selected policy is employed in the task (the execution phase).
In the unknown weights scenario, scalarization is impossible before planning or learning
but trivial once a policy actually needs to be used because w is known by that time.
In contrast, in the second scenario, which we call the decision support scenario (Figure
1b), scalarization is infeasible throughout the entire decision-making process because of the
difficulty of specifying w, or even f . For example, economists may not be able to accurately
compute the cost of lost productivity due to commuting. The user may also have fuzzy
preferences that defy meaningful quantification. For example, if the transport system could
be made more efficient by building a new train line that obstructs a beautiful view, then a
human designer may not be able to quantify the loss of beauty. The difficulty of specifying
the exact scalarization is especially apparent when the designer is not a single person but
a committee or legislative body whose members have different preferences and agendas.
In such a system, the MOMDP method is used to calculate an optimal solution set with
respect to the known constraints about f and w. As Figure 1b shows, the decision support
scenario proceeds similarly to the unknown weights scenario except that, in the selection
phase, the user or users select a policy from the set according to their arbitrary preferences,
rather than explicit scalarization according to given weights.
In all these cases, one can still argue that scalarization before planning or learning is
possible in principle. For example, the loss of beauty can be quantified by measuring the
resulting drop in housing prices in neighborhoods that previously enjoyed an unobstructed
view. However, the difficulty with scalarization is not only that doing so may be impractical
but, more importantly, that it forces the users to express their preferences in a way that may
be inconvenient and unnatural. This is because selecting w requires weighing hypothetical
trade-offs, which can be much harder than choosing from a set of actual alternatives. This
is a well understood phenomenon in the field of decision analysis (Clemen, 1997), where
the standard workflow involves presenting alternatives before soliciting preferences. That
is why subfields of decision analysis such as multiple criteria decision-making and multiattribute utility theory focus on multiple objectives (Dyer, Fishburn, Steuer, Wallenius, &
Zionts, 1992). For the same reasons, algorithms for MOMDPs can provide critical decision
support. Rather than forcing the users to specify w in advance, these algorithms just
prune policies that would not be optimal for any w. Then, they offer the users a range of
alternatives from which they can select according to preferences whose relative importance
is not easily quantified.
In the third scenario, which we call the known weights scenario (Figure 1c), we assume
that w is known at the time of planning or learning and thus scalarization is both possible
and feasible. However, it may be undesirable because of the difficulty of the second step
in the conversion. In particular, if f is nonlinear, then the resulting single-objective MDP
may not have additive returns (see Section 4.2.2). As a result, the optimal policy may be
non-stationary (see Section 4.3.2) or stochastic (see Section 4.3.3), which cannot occur in
single-objective, additive, infinite-horizon MDPs (see Theorem 1). Consequently, the MDP
can be difficult to solve, as standard methods are not applicable. Converting the MDP to
one with additive returns may not help either as it can cause a blowup in the state space,
73

fiRoijers, Vamplew, Whiteson & Dazeley

which also leaves the problem intractable.4 Therefore, even though scalarization is possible
when w is known, it may still be preferable to use methods specially designed for MOMDPs
rather than to convert the problem to a single-objective MDP. In contrast to the unknown
weights and the decision support scenarios, in the known weights scenario, the MOMDP
method only produces one policy, which is then executed, i.e., there is no separate selection
phase, as shown in Figure 1c.
Note that Figure 1 assumes an off-line scenario: planning or learning occurs only once,
before execution. However, multi-objective methods can also be employed in on-line settings
in which planning or learning are interleaved with execution. In the on-line version of the
unknown weights scenario, the weights are better characterized as dynamic, rather than
unknown. In an on-line scenario, the agent must already have seen weights in all timesteps
t > 1 since this is a prerequisite for execution in timesteps 1, . . . , t  1. However, if the
weights change over time, the agent may not yet know the weights that will be used in
timestep t when it is in the planning or learning phase of that timestep.

4. Problem Taxonomy
So far, we have described the MOMDP formalism and proposed three motivating scenarios
for it. In this section, we discuss what constitutes an optimal solution. Unfortunately, there
is no simple answer to this question, as it depends on several critical factors. Therefore,
we propose a problem taxonomy, shown in Table 1, that categorizes MOMDPs according
to these factors and describes the nature of an optimal solution in each category. Our
taxonomy is based on what we call the utility-based approach, in contrast to many other
multi-objective papers that follow an axiomatic approach to optimality in MOMDPs.
The utility-based approach rests on the following premise: before the execution phases
of the scenarios in Section 3, one policy is selected by collapsing the value vector of a policy
to a scalar utility, using the scalarization function. The application of the scalarization
function may be implicit and hidden, e.g., it may be embedded in the thought-process of
the user, but it nonetheless occurs. The scalarization function is part of the notion of utility,
i.e., what the agent should maximize. Therefore, if we find a set with an optimal solution
for each possible weight setting of the scalarization function, we have solved the MOMDP.
The utility-based approach derives the optimal solution set from the assumptions that are
made about the scalarization function, which policies the user allows, and whether we need
one or multiple policies.
By contrast, the axiomatic approach begins with the axiom that the optimal solution set
is the Pareto front (see Section 4.2.2).5 This approach is limiting because, as we demonstrate
in this section, there are some settings for which other solution concepts are more suitable.
Thus, we take a utility-based approach because it makes it possible to derive the solution
concept, rather than just assuming it. When the Pareto front is in fact the correct solution
4. Since non-additive returns can depend on the agents entire history, the immediate reward function in
the converted MDP may also depend on that history and thus the state representation in the converted
MDP must be augmented to include it.
5. For an example of an axiomatic approach to multi-objective reinforcement learning, see the survey by
Liu, Xu, and Hu (2013).

74

fiA Survey of Multi-Objective Sequential Decision-Making

single policy
(known weights)
deterministic
linear
scalarization

multiple policies
(unknown weights or decision support)

stochastic

one deterministic stationary
policy (1)

monotonically one
increasing
deterministic
scalarization
non-stationary
policy (3)

deterministic

stochastic

convex coverage set of
deterministic stationary policies
(2)

one mixture
policy of two
or more
deterministic
stationary
policies (4)

Pareto
coverage set of
deterministic
non-stationary
policies (5)

convex
coverage set of
deterministic
stationary
policies (6)

Table 1: The MOMDP problem taxonomy showing the critical factors in the problem and
the nature of the resulting optimal solution. The columns describe whether the
problem necessitates a single policy or multiple ones, and whether those policies
must be deterministic (by specification) or are allowed to be stochastic. The rows
describe whether the scalarization function is a linear combination of the rewards
or, whether this cannot be assumed and the scalarization function is merely a
monotonically increasing function of them. The contents of each cell describe
what an optimal solution for the given setting looks like.

concept, the utility-based approach provides a justification for it. When it is not, it allows
for a more appropriate solution concept to be derived instead.
Our taxonomy categorizes problem classes based on the assumptions about the scalarization function, which policies the user allows, and whether one or multiple policies are
required. We show that this leads different solution concepts, underscoring the importance
of carefully considering the choice of solution concept based on all the available information.
We discuss the three factors that constitute our taxonomy in the following order. In
Section 4.1, we discuss the first factor: whether one or multiple policies are sought, a choice
that follows directly from which motivating scenario is applicable. The known weights
scenario (Figure 1c) implies a single-policy approach while the unknown weights and decision
support scenarios (Figure 1a and 1b) imply a multiple-policy approach. In Section 4.2, we
discuss the second factor: whether the scalarization function is a linear combination of the
rewards or merely a monotonically increasing function of them. In Section 4.3, we discuss
the third factor: whether stochastic or only deterministic policies are permitted.
The goal of the taxonomy is to cover most research on MOMDPs while remaining simple
and intuitive. However, due to the diversity of research on MOMDPs, some research does
not fit neatly in our taxonomy. We note these discrepancies when discussing such research
in Sections 5 and 6.
75

fiRoijers, Vamplew, Whiteson & Dazeley

4.1 Single versus Multiple Policies
Following the approach of Vamplew et al. (2011), we first distinguish problems in which
only one policy is sought from ones in which multiple policies are sought. Which case holds
depends on which of the three motivating scenarios discussed in Section 3 applies.
In the unknown weights and decision support scenarios, the solution to an MOMDP
consists of multiple policies. Though these two scenarios are conceptually quite different,
from an algorithmic perspective they are identical. The reason is that they are both characterized by a strict separation of the decision-making process into two phases: the planning
or learning phase and the execution phase (though in on-line settings, the agent may go
back and forth between the two).
In the planning or learning phase, w is unavailable. Consequently, the planning or learning algorithm must return not a single policy but a set of policies (and the corresponding
multi-objective values). This set should not contain any policies that are suboptimal for all
scalarizations, i.e. we are only interested in undominated policies.
Definition 2. For an MOMDP m and a scalarization function f , the set of undominated
policies, U (m ), is the subset of all possible policies m for m for which there exists a w
for which the scalarized value is maximal:


U (m ) = { :   m  w(   m ) Vw  Vw }.

(4)

U (m ) is sufficient to solve m, i.e., for each w, it contains a policy with the optimal
scalarized value. However, it may contain redundant policies that, while optimal for some
weights, are not the only optimal policy in the set for w. Such policies can be removed
while still ensuring the set contains an optimal policy for all w. In fact, in order to solve
m, we need only a subset of the undominated policies such that, for any possible w, at
least one policy in the set is optimal. This is sometimes called a coverage set (CS) (Becker,
Zilberstein, Lesser, & Goldman, 2003).
Definition 3. For an MOMDP m and a scalarization function f , a set CS(m ) is a
coverage set if it is a subset of U (m ) and if, for every w, it contains a policy with maximal
scalarized value, i.e., if:


m
m
m

m


CS( )  U ( )  (w)()   CS( )  (   ) Vw  Vw .
(5)
Note that U (m ) is automatically a coverage set. However, while U (m ) is unique, CS(m )
need not be. When there are multiple policies with the same value, U (m ) contains all of
them, while a coverage set need contain only one. In addition, for a given CS(m ), there

may exist a policy   
/ CS(m ) for which V is different from V for all   CS(m )
but which has the same scalarized value as a   CS(m ) for all w at which   is optimal.
In contrast to single-objective MDPs, in MOMDPs whether or not a policy is in a CS(m )
can depend on the initial state distribution . It is thus important to accurately specify 
when formulating an MOMDP.
Ideally, an MOMDP algorithm should find the smallest CS(m ). However, doing so
might be harder than just finding one smaller than U (m ). In Section 4.2, we specialize
the coverage set for two classes of scalarization functions.
76

fiA Survey of Multi-Objective Sequential Decision-Making

In the execution phase, a single policy is chosen from the set returned in the planning or
learning phase and executed. In the unknown weights scenario, we assume that w is revealed
after planning or learning is complete but before execution begins. Selecting a policy then
requires only maximizing over the scalarized value of each policy in the returned set:
  = argmax Vw .
CS(m )

In the decision support scenario, this set is manually inspected by the user(s), who select a
policy for execution informally, making an implicit trade-off between the objectives.
In the known weights scenario, w is known before planning or learning begins. Therefore,
returning multiple policies is unnecessary. However, as mentioned in Section 3 and discussed
further in Section 4.2.2, scalarization can yield a single-objective MDP that is difficult to
solve.
4.2 Linear versus Monotonically Increasing Scalarization Functions
The second critical factor affecting what constitutes an optimal solution to an MOMDP is
the nature of the scalarization function. In this section, we discuss two types of scalarization
function: those that are linear combinations of the rewards and those that are merely
monotonically increasing functions of them.
4.2.1 Linear Scalarization Functions
A common assumption about the scalarization function (e.g., Natarajan & Tadepalli, 2005;
Barrett & Narayanan, 2008), is that f is linear, i.e., it computes the weighted sum of the
values for each objective.
Definition 4. A linear scalarization function computes the inner product of a weight vector
w and a value vector V
Vw = w  V .
(6)
Each element of w specifies how much one unit of value for the corresponding objective
contributes to the scalarized value. The elements of the weight vector w are all positive real
numbers and constrained to sum to 1.
Linear scalarization functions are a simple and intuitive way to scalarize. One common
situation in which they are applicable is when rewards can be easily translated into monetary
value. For example, consider a mining task in which different policies yield different expected
quantities of various minerals. If the prices per kilo of those minerals fluctuate daily, then
the task can be formulated as an MOMDP, with each objective corresponding to a different
mineral. Each element of V then reflects the expected number of kilos of that mineral
that are mined under  and the scalarized value Vw corresponds to the monetary value
of everything that is mined. Vw can be computed only when w, corresponding to the
(normalized) current price per kilo of each mineral, becomes known.
In the single-policy setting, where w is known, the presence of multiple objectives poses
no difficulties given a linear f . Instead, f can simply be applied to each reward vector in the
77

fiRoijers, Vamplew, Whiteson & Dazeley

MOMDP. Because the inner product computed by f distributes over addition, the result is
a single-objective MDP with additive returns. In the infinite horizon setting this leads to:
Vw = w  V = w  E[


X

 k rt+k+1 ] = E[


X

 k (w  rt+k+1 )].

(7)

k=0

k=0

Since this single-objective MDP has additive returns, it can be solved with standard methods, yielding a single policy, as reflected in the box labeled (1) in Table 1. Due to Theorem
1, a determinstic stationary policy suffices. However, a multi-objective approach can still
be preferable in this case, e.g., V may be easier to estimate than Vw in large or continuous
MOMDPs where function approximation is required (see Section 6.1).
In the multiple policy setting, however, we do not know w during planning or learning
and therefore want to find a coverage set. If f is linear, then U (m ), which is automatically
a coverage set, consists of the convex hull. Substituting Equation 6 in the definition of the
undominated set (Definition 2), we obtain the definition of the convex hull:
Definition 5. For an MOMDP m, the convex hull (CH) is the subset of m for which
there exists a w for which the linearly scalarized value is maximal:


CH(m ) = { :   m  w(   m ) w  V  w  V }.

(8)

Figure 2a illustrates the concept of a convex hull for stationary deterministic policies. Each
point in the plot represents the multi-objective value of a given policy for a two-objective
MOMDP. The axes represent the reward dimensions. The convex hull is shown as a set
of filled circles, connected by lines that form a convex surface.6 Given a linear f , the
scalarized value of each policy is a linear function of the weights. This is illustrated in
Figure 2b, where the x-axis represents the weight for dimension 0 (w[1] = 1  w[0]), and
the y-axis the scalarized value of the policies. To select a policy, we need only know the
values of the convex hull policies, which form the upper surface of the scalarized value,
as illustrated by the black solid lines, and correspond to the three convex hull policies in
Figure 2a. The upper surface forms a piecewise linear and convex function. Such functions
are also well-known from the literature on partially-observable Markov decision processes
(POMDPs), whose relationship to MOMDPs we discuss in Section 5.2.
Like any U (m ), CH(m ) can contain superfluous policies. However, we can also define
the convex coverage set (CCS) as the specification of the coverage set when f is linear. This
is reflected in box (2) in Table 1 (we explain why the policies in this set are deterministic
and stationary in Section 4.3.1).
Definition 6. For an MOMDP m, a set CCS(m ) is a convex coverage set if it is a
subset of CH(m ) and if, for every w, it contains a policy whose linearly scalarized value
is maximal, i.e., if:



CCS(m )  CH(m )  (w)()   CCS(m )  (   m ) w  V  w  V . (9)
6. Note that the term convex hull has a slightly different meaning in the multi-objective literature than
its standard geometric definition. In geometry, the convex hull of a finite set S of points in Euclidean
space is the minimal subset of S so that each of the other points in S can be expressed as a convex
combination of the points in the convex hull. In a multi-objective setting, we are only interested in a
particular subset of the geometric convex hull; those points of which its convex combinations are strictly
bigger (in all dimensions) than any other point in S, i.e., all points that are optimal for some weight.

78

fiA Survey of Multi-Objective Sequential Decision-Making

(a)

(b)

Figure 2: Example of the convex hull and Pareto front. Each point in (a) represents the
multi-objective value of a given policy and each line in (b) represents the linearly
scalarized value of a policy across values of w. The convex hull is shown as black
filled circles in (a), and black lines in (b). The Pareto front consists of all filled
points (circles and squares) in (a), and both the dashed and solid black lines in
(b). The unfilled points in (a) (grey lines in (b)) are dominated.

For deterministic stationary policies, the difference between CH(m ) and CCS(m ) may
often be small. Therefore, the terms are often used interchangeably. However, in the case
of non-stationary or stochastic policies, the difference is quite significant, as the CH can
contain infinitely many policies, while it is possible to construct a finite CCS, as we show
in Section 4.3.1.
4.2.2 Monotonically Increasing Scalarization Functions
While linear scalarization functions are intuitive and simple, they are not always adequate
for expressing the users preferences. For example, suppose in the mining task mentioned
above, there are two minerals that can be mined and only three policies are available: 1
sends the mining equipment to a location where only the first mineral can be mined, 2 to
a location where only the second mineral can be mined, and 3 to a location where both
minerals can be mined. Suppose the owner of the equipment prefers 3 , e.g., because it at
least partially appeases clients with different interests. However, it may be the case that,
because the location corresponding to 3 has fewer minerals, the convex hull contains only
1 and 2 . Thus, the owners preference of 3 implies that he or she, implicitly or explicitly,
employs a nonlinear scalarization function.
Here, we consider the case in which f can be nonlinear, and corresponds to a common
notion of the relationship between reward and utility. This class of possibly nonlinear scalarizations are the strictly monotonically increasing scalarization functions. These functions
adhere to the constraint that if a policy is changed in such a way that its value increases in
79

fiRoijers, Vamplew, Whiteson & Dazeley

one or more of the objectives, without decreasing in any other objectives, then the scalarized
value also increases.
Definition 7. A scalarization function f is strictly monotonically increasing if:






(i, Vi  Vi  i, Vi > Vi )  (w, Vw > Vw ).

(10)

Linear scalarization functions (with non-zero positive weights) are included in this class
of functions. The condition on the left-hand side of Equation 10 is more commonly known
as Pareto dominance (Pareto, 1896).
Definition 8. A policy  Pareto-dominates another policy   when its value is at least as
high in all objectives and strictly higher in at least one objective:






V P V  i, Vi  Vi  i, Vi > Vi .

(11)

Demanding that f is strictly monotonically increasing is quite a minimal constraint, as it
requires only that, all other things being equal, getting more reward for a certain objective
is always better. In fact, it is difficult to think of any f that violates this constraint without
employing a highly unnatural notion of reward.7
Three observations are in order about strictly monotonically increasing scalarization
functions and the related concept of Pareto dominance. First, unlike in the linear case, we
do not necessarily know the exact shape of f . Instead, we know only that it belongs to a
particular class of functions. The solution concept that follows thus applies to any strictly
monotonically increasing f . In cases where stronger assumptions about f can be made,
more specific solution concepts are possible. However, except for linearity, we are not aware
of any such properties of f that have been exploited in solving MOMDPs.
Second, the notions of optimality introduced in Section 4.2.1 are no longer appropriate.
The reason is that, even though the vector-valued returns are still additive (Equation 2), the
scalarized returns may not be because f may no longer be linear. As an example, consider
the well-known Tchebycheff scalarization function (Perny & Weng, 2010)8 :
X
(V , p, w) =  max wi |pi  Vi |  
wi |pi  Vi |,
(12)
i1...n

i1...n

where p is an optimistic reference point, w are weights, and  is an arbitrarily small positive
constant greater than 0. Note that the sum on the righthand side is what makes the function
strictly monotonically increasing. Now, if p = (3, 3),P = 0.01, r1 = (0, 3), r2 = (3, 0),
k
w = (0.5, 0.5) and  = 1, then f (V , w) = 0 but E[ 
k=0  f (rt+k+1 , w)] = (1.515) +
(1.515) = 3.03. This loss of additivity of the scalarized returns when applying a nonlinear
f has important consequences for which methods can be applied, as we show in Section 4.3.2.
Third, we can still identify and prune policies that are not optimal for any w for any
strictly monotonically increasing f , even though it may be nonlinear. Consider the three
7. In addition, if f is not strictly monotonically increasing and no other assumptions are made, then no
policies can be pruned from the coverage set. Thus, computing the value of every policy in this coverage
set, which is required by the selection phase, is likely to be intractable.
8. Our definition differs slightly from that of Perny and Weng (2010): it is multiplied by 1 to express
maximization instead of minimization, for the sake of consistency with the rest of this article.

80

fiA Survey of Multi-Objective Sequential Decision-Making

labeled policies in Figure 2a (note that Figure 2b does not apply, because the scalarization
function is no longer linear). B has a higher value than A in one objective, but a lower
value in the other. We therefore cannot tell whether A or B ought to be preferred without
knowing w. However, C has a lower value than A in both objectives, and thus A Paretodominates C: A P C. Because f is strictly monotonically increasing, the scalarized value
of A is greater than that of C for all w and thus we can discard C.
For now, we defer a full discussion of what constitutes an optimal solution for an
MOMDP with a strictly monotonically increasing scalarization function (i.e., boxes (3)-(6)
in Table 1) because this depends, not only on whether the single or multiple policy setting
applies, but also on whether only deterministic or also stochastic policies are considered,
which is addressed in Section 4.3.
However, we can already observe that, given any strictly monotonically increasing f , we
can use the Pareto front as a set of viable policies. The Pareto front consists of all policies
that are not Pareto dominated.
Definition 9. For an MOMDP m, the Pareto front is the set of all policies that are not
Pareto dominated by any other policy in m :


P F (m ) = { :   m  (   m ), V P V }.

(13)

Note that P F (m ) is not the set of undominated policies U (m ) for all specific strictly
monotonically increasing f . We have already seen that for the special case of linear f ,
U (m ) = CH(m ), which is a subset of P F (m ). (For example, in Figure 2, the Pareto
front consists of the convex hull plus B.) However, for any strictly monotonically increasing
f , we know that a policy that is not in the P F (m ) is dominated with respect to f , i.e.,
 6 P F (m )   6 U (m ). This is because, for strictly monotonically increasing f and

/ P F (m ), there cannot exist a w for which  is optimal, since by definition there exists

a   such that V P V and, since f is strictly monotonically increasing, this implies

that Vw > Vw .
However, if we know only that f is strictly monotonically increasing, we cannot settle
for a subset of P F (m ) either, because there exist strictly monotonically increasing f for
which U (m ) = P F (m ). Perny and Weng (2010) show that U (m ) = P F (m ) for the
Tchebycheff function (Equation 12), which is strictly monotonically increasing. Therefore,
we cannot discard policies from the P F (m ) and retain an undominated set U (m ) for all
strictly monotonically increasing f .
A Pareto coverage set (PCS) of minimal size can be constructed by retaining only one
policy of the policies with identical vector values in the P F (m ). We can formally define
the PCS as follows:
Definition 10. For an MOMDP m, a set P CS(m ) is a Pareto coverage set if it is a subset
of P F (m ) and if, for every policy    m , it contains a policy that either dominates  
or has equal value to   , i.e., if:




P CS(m )  P F (m )  (   m )()   P CS(m )  (V P V  V = V ) . (14)
Again, for deterministic stationary policies the difference between a P CS(m ) and P F (m )
may be minor. Note that P F (m ) is automatically a P CS(m ). Most papers in the
literature therefore take P F (m ) as the solution.
81

fiRoijers, Vamplew, Whiteson & Dazeley

We can also slightly relax the constraint on f , without having to change which policies
are in the P CS(m ). Specifically, we can define a monotonically increasing scalarization

function as a function for which the following property holds: (i, Vi  Vi )  (w, Vw 

Vw ). This relaxation influences the set of undominated policies: while policies that are not
in the P F (m ) are always dominated under a strictly monotonically increasing f , they need
not be under any monotonically increasing f . Consider for example f (V , w) = 0, which
is monotonically increasing but not strictly monotonically increasing. For this function
there are no dominated policies, as every policy has the same scalarized value. However,
because the scalarized value of a policy   6 P F (m ) cannot be greater than the scalarized
function of a policy   P CS(m ), we can use the P CS(m ) for (non-strict) monotonically
increasing f . Therefore, in this article, we focus on monotonically increasing f , as this is
the broader class of functions.
Because the P F (m ), and even a P CS(m ), may be prohibitively large and contain
many policies whose values differ by negligible amounts, Chatterjee et al. (2006) and Brazdil
et al. (2011) introduce a slack parameter , and use this to define an -approximate Pareto
front, P F (m ). P F (m ) contains all values of policies such that for every possible policy

   m there is a policy   P F (m ) such that i Vi (s) +   Vi (s). By weakening
the requirements for domination, this approach yields a smaller set that can be calculated
more efficiently.
Another option for finding a smaller set than P F (m ) is making additional assumptions
about the scalarization function. For example, Perny, Weng, Goldsmith, and Hanna (2013)
introduce the notion of fairness between objectives, leading to Lorentz optimality. The
additional assumption is that if the sum of the values over all objectives stays the same,
making the difference between two objectives smaller yields a higher scalarized value. This is
of course a strong assumption that does not apply as broadly as Pareto optimality. However,
when it does apply, it can help reduce the size of the optimal solution set.
4.3 Deterministic versus Stochastic Policies
The third critical factor affecting what constitutes an optimal solution to an MOMDP is
whether only deterministic polices are considered or stochastic ones are also allowed. While
in most applications there is no reason to exclude stochastic policies a priori, there can be
cases when stochastic policies are clearly undesirable or even unethical. For example, if the
policy determines the clinical treatment of a patient, e.g., as in work of Lizotte, Bowling,
and Murphy (2010) and Shortreed, Laber, Lizotte, Stroup, Pineau, and Murphy (2011),
then flipping a coin to determine the course of action may be inappropriate. We denote the
m
set of deterministic policies m
D and the set of stationary policies S . Both sets are subsets
m
m
m
m
of all policies: D    S   . Finally the set of policies that are both deterministic
m
m
and stationary is the intersection of both these sets, denoted m
DS = D  S .
In single-objective MDPs, this factor is not critical because, due to Theorem 1, we can
restrict our search to deterministic stationary policies, i.e. the optimal attainable value

V  . However, the
is attainable with a deterministic stationary policy: maxm V  = max
m


 DS

situation is more complex in MOMDPs. In this section, we discuss how the focus on
stochastic or deterministic policies affects each setting considered in our taxonomy.
82

fiA Survey of Multi-Objective Sequential Decision-Making

4.3.1 Deterministic and Stochastic Policies with Linear Scalarization
Functions
When f is linear, a result similar to Theorem 1 holds for MOMDPs due to the following
corollary:
m
Corollary 1. For an MOMDP m, any CCS(m
DS ) is also a CCS( ).

Proof. If f is linear, we can translate the MOMDP to a single-objective MDP, for each
possible w. This is done by treating the inner product of the reward vector and w as the
new rewards, and leaving the rest of the problem as is. Since the inner product distributes
over addition, the scalarized returns remain additive (Equation 7). Thus, for every w
there exists a translation to a single-objective MDP, for which an optimal deterministic and
stationary policy must exist, due to Theorem 1. Hence, for each w there exists an optimal
deterministic stationary policy. Therefore, there exists a   CCS(m
DS ) that  is optimal

m
m
for that w. Consequently, there cannot exist a    \ DS such that w  V > w  V
m
and thus CCS(m
DS ) is also a CCS( ).
Any CCS(m
DS ) is thus sufficient for solving MOMDPs with linear f , even when stochastic and non-stationary policies are allowed. This is reflected in box (2) in Table 1. It also
applies to box (1) since the optimal policy in that case is just a member of this CCS(m
DS ),
i.e., the one that is best for the given known w.
Unfortunately, no result analogous to Corollary 1 holds for MOMDPs with monotonically increasing f . In the rest of this section, we discuss why this is so and the consequences
for the nature of an optimal MOMDP solution for boxes (3)-(6) in Table 1.
4.3.2 Multiple Deterministic Policies with Monotonically Increasing
Scalarization Functions
In the multiple-policy setting when only deterministic policies are allowed and f is nonlinear,
non-stationary policies may be better than the best stationary ones.
Theorem 2. In infinite-horizon MOMDPs, deterministic non-stationary policies can Paretodominate deterministic stationary policies that are undominated by other deterministic stationary policies (White, 1982).
To see why, consider the following MOMDP, denoted m1, adapted from an example by
White (1982). There is only one state and three actions a1 , a2 , and a3 , which yield rewards
(3, 0), (0, 3), and (1, 1), respectively. If we allow only deterministic stationary policies,
then there are three possible policies 1 , 2 , 3  m1
DS , each corresponding to always taking
one of the actions, all of which are Pareto optimal. These policies have the following
state-independent values (Equation 2): V1 = (3/(1  ), 0), V2 = (0, 3/(1  )), and
V3 = (1/(1  ), 1/(1  )). However, if we now consider the set of possibly non-stationary
m1
m1
policies m1
D (including non-stationary ones), we can construct a policy ns  D \ DS
that alternates between a1 and a2 , starting with a1 , and whose value is Vns = (3/(1 
 2 ), 3/(1   2 )). Consequently, ns P 3 when  > 0.5 and thus we cannot restrict our
83

fiRoijers, Vamplew, Whiteson & Dazeley

attention to stationary policies.9 Consequently, in the multiple deterministic policies case
with monotonically increasing f , we need to find a P CS(m
D ), which includes non-stationary
policies, as shown in box (5) of Table 1.
In addition to having to consider a broader class of policies, another consequence is
that defining a policy indirectly via the value function is no longer possible. In standard
single-objective methods, the optimal policy can be found by doing local action selection
with respect to the value function: i.e., for every state, the policy selects the action that
maximizes the expected value. However, for local selection to yield a non-stationary policy, the value function must also be non-stationary, i.e., it must condition on the current
timestep. While this is standard in the finite-horizon setting, where a different value function is computed for each timestep, it is not possible in the infinite-horizon setting. We
discuss how to address this difficulty in Sections 5 and 6.
4.3.3 Multiple Stochastic Policies with Monotonically Increasing
Scalarization Functions
In the multiple policy setting where stochastic non-stationary policies, i.e., the full set m ,
are allowed, we again cannot consider only deterministic stationary policies. However, we
can employ stochastic stationary policies instead of deterministic non-stationary ones. In
particular, we can employ a mixture policy (Vamplew, Dazeley, Barker, & Kelarev, 2009)
m that takes a set of N deterministic
policies, and selects the i-th policy from this set, i
P
with probability pi , where N
p
=
1.
This leads to values that are a linear combination
i=0 i
of the values of the constituent policies. In our previous example, we can replace ns by a
policy m that chooses 1 with probability p1 and 2 otherwise, resulting in the following
values:


3p1 3(1  p1 )
m
1
2
V = p1 V + (1  p1 )V =
,
.
1
1
Fortunately, it is not necessary to explicitly represent an entire P CS(m ) explicitly.
Instead, it is sufficient to compute a CCS(m
DS ). The necessary stochastic policies to
create a P CS(m ) can then be easily constructed by making mixture policies from those
policies on the CCS(m
DS ).
Corollary 2. In an infinite horizon discounted MOMDP, an infinite set of mixture policies
PM can be constructed from policies that are on a CCS(m
DS ), such that this set PM , is a
m
P CS( ) (Vamplew et al., 2009).
Proof. We can construct a policy with any value vector on the convex surface, e.g., the
10 Thereblack lines in Figure 2a, by mixing policies on a CCS(m
DS ), e.g., the black dots.
fore, we can always construct a mixture policy that dominates a policy with a value under
this surface, e.g., B. We can show by contradiction that there cannot be any policy above
9. White (1982) shows this in an infinite-horizon discounted setting, but the arguments hold also for the
finite-horizon and average-reward settings.
10. Note that we should always mix policies that are adjacent; the line between any pair of the policies
we mix should be on the convex surface. E.g. mixing the policy represented by the leftmost black dot
in Figure 2a and the policy represented by the rightmost black dot does not lead to optimal policies, as
the line connecting these two points is under the convex surface.

84

fiA Survey of Multi-Objective Sequential Decision-Making

the convex surface. If there was, it would be optimal for some w if f was linear. Consequently, by Corollary 1, there would be a deterministic stationary policy with at least
equal value. But since the convex surface spans the values on the CCS(m
DS ), this leads
to a contradiction. Thus, no policy can Pareto-dominate a mixture policy on the convex
surface.
Thanks to Corollary 2, it is sufficient to compute a CCS(m
DS ) to solve an MOMDP, as
reflected in box (6) of Table 1. A surprising consequence of this fact, which to our knowledge
is not made explicit in the literature, is that Pareto optimality, though the most common
solution concept associated with multi-objective problems, is actually only necessary in one
specific problem setting:
Observation 1. The multiple policy setting when f is monotonically increasing and only
deterministic policies are considered (box (5) of Table 1), requires computing a Pareto coverage set. When either f is linear or stochastic policies are allowed, a CCS(m
DS ) suffices.
Wakuta (1999) proves the sufficiency of a CCS(m
DS ) for monotonically increasing
scalarizations with multiple stochastic policies (box (6) of Table 1) in infinite horizon
MOMDPs, but in a different way. Instead of the mixture policies in Corollary 2, he uses stationary randomizations over deterministic stationary policies. Wakuta and Togawa (1998)
provide a similar proof for the average reward case.
Note that, while it is common to consider non-stationary or stochastic policies when f
is nonlinear, such policies typically condition only on the current state, or the current state
and time, not the agents reward history. However, in this setting, policies that condition
on that reward history can dominate those that do not. For example, suppose there are two
objectives which can take only positive values and f simply selects the smaller of the two, i.e.,
f (V , w) = mini Vi . Suppose also that, in a given state, two actions are available, which
yields rewards of (4, 4) and (0, 5) respectively. Finally, suppose that the agent can arrive at
that state with one of two reward histories, whose discounted sums are either (5, 0) or (3, 3).
A policy that conditions on these discounted reward histories can outperform policies that
do not, i.e., the optimal policy selects the action yielding (4, 4) when the reward history sums
to (3, 3) and the action yielding (0, 5) when the reward history sums to (5, 0). So, while for
single objective MDPs the Markov property and additive returns are sufficient to restrict our
attention to policies that ignore history, in the multi-objective case, the scalarized returns
are no longer additive and therefore the optimal policy can depend on the history. Examples
of methods that exploit this fact are the steering approach (Mannor & Shimkin, 2001) and
the reward-augmented-state thresholded lexicographic ordering method by Geibel (2006),
which are discussed in Section 6.1.
4.3.4 Single Deterministic and Stochastic Policies with Monotonically
Increasing Scalarization Functions
All that remains to address is the single-policy setting with monotonically increasing f .
The nature of the optimal solution in this case follows directly from the reasoning given for
the multiple-policy setting.
If only deterministic policies are considered, then the single policy that is sought may
be non-stationary, as reflected in box (3) of Table 1, for the reasons elucidated by Whites
85

fiRoijers, Vamplew, Whiteson & Dazeley

example. Again, it is hard to define such a non-stationary policy by local action selection,
due to the risk of circular dependencies in the Q-values.
If stochastic policies are allowed, then the optimal policy may be stochastic, but this
can be represented as a mixture policy of two or more deterministic stationary policies, as
reflected in box (4) of Table 1, for the same reasons given in Corollary 2. In both cases,
policies can potentially benefit from conditioning on the reward history.

5. Planning in MOMDPs
In this section, we survey some key approaches to planning in MOMDPs, i.e., computing
an optimal policy or the coverage set of undominated policies given a complete model of
the MOMDP. Following the taxonomy presented in Section 4, we first consider single-policy
methods and then turn to multiple-policy methods for linear and monotonically increasing
scalarization functions.
5.1 Single-Policy Planning
In the known weights scenario, w is known before planning begins, and so only a single
policy, optimal for w, must be discovered. Since the MOMDP can be transformed to a
single-objective MDP when f is linear (see Section 4.2.1), we focus here on single-policy
planning for nonlinear f .
As discussed in Section 4.2.2, nonlinear f can cause the scalarized return to be nonadditive. Consequently, single-objective dynamic programming and linear programming
methods, which exploit the assumption of additive returns by employing the Bellman equation, are not applicable. However, different linear programming formulations for singlepolicy planning in MOMDPs are possible. A key feature of such methods is that they
can produce stochastic policies, which, as discussed in Section 4, can be optimal when the
scalarization function is nonlinear. While we are not aware of any single-policy planning
methods that work for arbitrary nonlinear f , methods have been developed for two special
cases. In particular, Perny and Weng (2010) propose a linear programming method for
MOMDPs scalarized using the Tchebycheff function mentioned in Section 4.2.2. Because
the Tchebycheff function always has a w for which any Pareto-optimal policy is optimal,
this approach can find any (single) policy on the Pareto front. In addition, Ogryczak, Perny,
and Weng (2011) propose an analogous method for the ordered weighted regret metric. This
metric calculates the regret of each objective with respect to an estimated ideal reference
point, sorts these into descending order, and calculates a weighted sum in which the weights
are also in descending order.
Other researchers have proposed single-policy methods for MOMDPs with constraints.
Feinberg and Shwartz (1995) consider MOMDPs with one regular objective and M objectives with inequality constraints. They show that if a feasible policy exists for this setting,
it can be deterministic and stationary after some finite number of timesteps N and that,
prior to timestep N , at most M random actions must be performed. They call this a (M, N )
policy, show that all Pareto-optimal values can be achieved by (M, N ) policies, and propose
a linear programming algorithm that finds -approximate policies for this setting. More
general MOMDPs with constraints have also been considered. In particular, Altman (1999)
proposes several linear programming approaches for such settings.
86

fiA Survey of Multi-Objective Sequential Decision-Making

Furnkranz, Hullermeier, Cheng, and Park (2012) propose a framework for MDPs with
qualitative reward signals, which are related to MOMDPs but do not fit neatly in our
taxonomy. Qualitative reward signals indicate a preference between policies or actions
without directly ascribing a numeric value to them. Since such preferences induce a partial
ordering between policies, the policy iteration method the authors propose for this setting
may be applicable to MOMDPs with nonlinear f , as Pareto dominance also induces partial
orderings. However, the authors note that multi-objective tasks generally do have numeric
feedback that can be exploited. Thus, they suggest that quantitative MOMDPs can be
viewed as a subset of preference-based MDPs, and as such methods designed specifically
for MOMDPs may be more efficient than general preference-based methods.
5.2 Multiple-Policy Planning with Linear Scalarization Functions
In the multiple-policy setting with linear f , we seek a CCS(m
DS ). Note however, the
distinction between the convex hull and a convex coverage set is usually not made in the
literature.
One might argue that explicitly multi-objective methods are not necessary in this setting, because one could repeatedly run single-objective methods to obtain a CCS(m
DS ).
However, since there are infinitely many possible w, it is not obvious that all possible values for w can be covered. It might be possible to devise a way to run the single-objective
methods a finite number times and still guarantee that a CCS(m
DS ) is produced. However,
this would be a nontrivial result and the corresponding algorithm would in essence be a
multi-objective method that happens to use single-objective methods as subroutines.
One approach that has been attempted to find a minimally sized CCS(m
D ), i.e., a convex
coverage set of deterministic but not necessarily stationary policies, originally proposed by
White and Kim (1980), is to translate the MOMDP into a partially observable Markov
decision process (POMDP) (Sondik, 1971). An intuitive way to think about this translation
is to imagine that there is in fact only one true objective but the agent is unaware which of
the objectives in the MOMDP it is. This is modeled in the POMDP by defining the state
as a tuple hs1 , s2 i where s1 is the state in the MOMDP and s2  {1 . . . n} indicates which is
the true objective. The observations thus identify s1 exactly but give no information about
s2 . Note that this translation from MOMDPs to POMDPs is one-way only. Not every
POMDP can be translated to an equivalent MOMDP.
Typically, an agent interacting with a POMDP maintains a belief, i.e., a probability
distribution over states. In a POMDP derived from an MOMDP, this belief can be decomposed into a belief about s1 and a belief about s2 . The former is degenerative because s1 is
known. The latter is a vector of size n in which the i-th element specifies the probability
that the i-th objective is the true one. This vector is analogous to w for a linear f . In
fact, this is the reason why Figure 2b resembles the piecewise linear value functions often
depicted for POMDPs; the only difference is whether the x-axis is interpreted as w or as a
belief.
White and Kim (1980) show that, in the finite horizon case, the solution for every belief
is exactly the solution for each w, and that the solutions for the resulting POMDP are
exactly those for the original MOMDP. The infinite horizon case is more difficult because
infinite horizon POMDPs are undecidable (Madani, Hanks, & Condon, 1999). However,
87

fiRoijers, Vamplew, Whiteson & Dazeley

for a sufficiently large horizon, the solution to a finite horizon POMDP can be used as an
approximate solution to an infinite horizon MOMDP.
To solve the resulting POMDP, White and Kim (1980) propose a combination of Sondiks
one-pass algorithm (Smallwood & Sondik, 1973) and policy iteration for POMDPs (Sondik,
1978). However, any POMDP planning method can be used as long as it (1) does not
require an initial belief about the POMDP state (which would correspond to initializing
not only the MOMDP state but also w) and (2) computes the optimal policy for every
possible belief. More recently developed exact methods, e.g., Cassandra, Littman, and
Zhang (1997) and Kaelbling, Littman, and Cassandra (1998), meet these conditions and
could thus be employed. Approximate point-based POMDP methods (Spaan & Vlassis,
2005; Pineau, Gordon, & Thrun, 2006) do not meet conditions (1) and (2) but could be
adapted to compute an approximate convex hull, by choosing a prior distribution for the
weights from which they could sample. Online POMDP planning methods (Ross, Pineau,
Paquet, & Chaib-draa, 2008) are not applicable because they plan only for a given belief.
Converting to a POMDP thus allows the use of some but not all POMDP methods for
solving MOMDPs with linear f . However, this approach can be inefficient because it does
not exploit the characteristics that distinguish such MOMDPs from general POMDPs, i.e.,
that part of the state, s1 , is known and that no observations give any information about
s2 . For example, methods that compute policies trees, e.g., (Kaelbling et al., 1998) do not
exploit the fact that only deterministic policies that are stationary functions of the state
are needed for MOMDPs with linear f . Furthermore, as mentioned before, general infinite
horizon POMDPs are undecidable, but for MOMDPs it is in fact possible to compute the
CCS(m
DS ) exactly.
For these reasons, researchers have also developed specialized planning methods for this
setting. Viswanathan, Aggarwal, and Nair (1977) propose a linear programming approach
for episodic MOMDPs. Wakuta and Togawa (1998) propose a policy iteration approach
that has three phases. The first phase uses policy iteration to narrow down the set of
possibly optimal policies. The second phase uses linear programs to check for optimality.
Since this does not necessarily give a definitive answer, the third phase uses another linear
program to handle any undetermined solutions left after the second phase.
Barrett and Narayanan (2008) propose convex hull value iteration (CHVI), which computes the CH(m
), in every state. CHVI extends conventional value iteration by storing a
 DS
set of vectors, Q (s, a) for each state-action pair, representing the convex hull of policies involving that action. These sets of vectors correspond to the Q-values in the single-objective
setting; they contain the optimal Q-values for all possible w. When a backup operation is
performed, the Q-hulls at the next state s are propagated back to s. For each possible next
S 
state s , all possible actions a are considered (i.e. the union of convex hulls a Q (s , a ) is
taken), and weighted by the probability of s occurring when taking action a in state s. This
procedure is very similar to the witness algorithm (Kaelbling et al., 1998) for POMDPs.
Lizotte et al. (2010) propose a value-iteration approach for the finite-horizon setting
that computes a different value function for each timestep. In addition, it uses a piecewise
linear spline representation of the value functions. The authors prove this offers asymptotic
time and space complexity improvements over the representation used by CHVI and also
enables application of this algorithm to MOMDPs with continuous states. However, the
88

fiA Survey of Multi-Objective Sequential Decision-Making

algorithm is only applicable to problems with two objectives. This limitation is addressed
in the authors subsequent work (Lizotte, Bowling, & Murphy, 2012) which extends the
algorithm to an arbitrary number of objectives and provides a detailed implementation for
the case of three objectives.
5.3 Multiple-Policy Planning with Monotonically Increasing Scalarization
Functions
In this section, we consider planning in MOMDPs with monotonically increasing f . As discussed in Section 4.3, when stochastic policies are allowed, mixture policies of deterministic
stationary policies are sufficient. Therefore, we focus on the case when only deterministic
policies are allowed and consider methods that compute a P CS(m
D ), which can include
non-stationary policies. The distinction between the P F (m
)
and
P
CS(m
D
D ) is usually not
made in the literature.
As in the linear case, scalarizing for every w and obtaining a P CS(m
D ) by the singleobjective methods is problematic. Again there are infinitely many w to consider but, unlike
the linear case, there is the additional difficulty that the scalarized returns may no longer
be additive, which can make single-objective methods inapplicable.
Daellenbach and Kluyver (1980) present an algorithm for multi-objective routing tasks
(essentially deterministic MOMDPs). Their approach uses dynamic programming in conjunction with an augmented state space to find all non-Pareto-dominated policies iteratively,
where the number of iterations equals the maximum number of steps in the route. The algorithm finds undominated sub-policies in parallel. The authors use two alternative explicit
scalarization functions, which they call the weighted minsum and weighted minmax operators. First, the values of all solutions are translated : for each objective, the new value
becomes the fractional difference between the optimal values for that objective across all
solutions. Then, the value for that objective is multiplied by a positive weight. Finally,
either the minimum of the sum (minsum) or the minimum of the maximal value (minmax )
of these new weighted fractional differences is chosen as the scalarization. Note that both
scalarization functions are monotonically increasing in all objectives, as the optimal value
for each objective individually does not depend on the scalarization function.
White (1982) extends this work by proposing a dynamic programming method that
approximately solves infinite horizon MOMDPs. It does so by repeatedly backing up according to a multi-objective version of the Bellman equation. Since the policies can be
non-stationary, the size of the Pareto front grows rapidly in the number of backups applied.
However, White notes that this number need not be too large before acceptable approximations are reached. Nonetheless, this approach is feasible only for small MOMDPs.
Wiering and De Jong (2007) address this difficulty with a dynamic programming method
called CON-MODP for deterministic MOMDPs that computes optimal stationary policies.
CON-MODP works by enforcing consistency during DP updates: a policy is consistent if
it suggests the same action at all timesteps for a given state. If an inconsistent policy is
inconsistent only in one state-action pair, CON-MODP makes it consistent by forcing the
current action to be taken each time the current state is visited. If the inconsistency runs
deeper, the policy is discarded.
89

fiRoijers, Vamplew, Whiteson & Dazeley

By contrast, Gong (1992) proposes a linear programming approach that finds the Paretofront of stationary policies. However, as the authors note, this approach is also suitable
only to small MOMDPs because the number of constraints and decision variables in the
linear program increase rapidly as the state space grows.
As mentioned in Section 4.2.2, one way to cope with intractably large Pareto fronts is
to compute instead an -approximate Pareto front, which can be much smaller. Chatterjee
et al. (2006) propose a linear programming method that computes the -approximate front
for an infinite horizon MOMDP, while Chatterjee (2007) propose an analogous algorithm
for the average reward setting. In both cases, stationary stochastic policies are shown to be
sufficient.
Another way to improve scalability in this setting is to give up on planning for the whole
state space and instead plan on-line for the agents current state, using a Monte Carlo tree
search approach (Kocsis & Szepesvari, 2006). Such approaches, which have proven very
successful, e.g., in the game of Go (Gelly & Silver, 2011), are increasingly popular for
single-objective MDPs. Wang and Sebag (2013) propose a Monte Carlo tree search method
for deterministic MOMDPs. Single-objective tree search methods typically optimistically
explore the tree by selecting actions that maximize the upper confidence bound of their
value estimates. The multi-objective variant does the same, but with respect to a scalar
multi-objective value function whose definition is based on the hypervolume indicator induced by the proposed action together with the set of Pareto optimal policies computed so
far. The hypervolume indicator (Zitzler, Thiele, Laumanns, Fonseca, & da Fonseca, 2003)
measures the hypervolume that is Pareto-dominated by a set of points. Since the Pareto
front maximizes the hypervolume indicator, this optimistic action selection strategy focuses
the tree search on the branches most likely to compliment the existing archive.

6. Learning in MOMDPs
The methods reviewed in Section 5 assume that a model of the transition and reward
dynamics of the MOMDP are known. In cases where such a model is not directly available,
multi-objective reinforcement learning (MORL) can be used instead.
One way to carry out MORL is to take a model-based approach, i.e., use the agents
interaction with the environment to learn a model of the transition and reward function of
the MOMDP and then apply multi-objective planning methods such as those described in
Section 5. Though such an approach seems well suited to MORL, only a few papers have
considered it, (e.g., Lizotte et al., 2010, 2012). We discuss opportunities for future work
in model-based MORL in Section 8.1. Instead, most of the work in MORL has focused on
model-free methods, where a model of the transition and reward function is never explicitly
learned.
In this section, we survey some key MORL approaches. While the majority of these
methods are for the single-policy setting, multiple-policy methods have also been developed. At first glance, it may seem that multiple-policy methods are unlikely to be effective
in the learning setting, since finding more policies would increase sample costs, not just
computational costs, and the former is typically a much scarcer resource. However, modelbased methods can obviate this issue: once enough samples have been gathered to learn a
useful model, finding policies optimal for more weights requires only computation. Model90

fiA Survey of Multi-Objective Sequential Decision-Making

free methods can also be practical for the multiple-policy setting if they employ off-policy
learning (Sutton & Barto, 1998; Precup, Sutton, & Dasgupta, 2001), which makes it possible to learn about one policy using data gathered by another. In this way, policies for
multiple weight settings can be optimized using the same data.
6.1 Single-Policy Learning Methods
In the known weights scenario, a MORL algorithm aims to learn a single policy that is
optimal for the given weights. As discussed in Section 5.1, under linear scalarization this
is equivalent to learning the optimal policy for a single-objective MDP and so standard
temporal-difference (TD) methods (Sutton, 1988) such as Q-learning (Watkins, 1989) can
easily be applied.
However, even though no specialized methods are needed to address this setting, it
is nonetheless the most commonly studied setting for MORL. Linear scalarization with
uniform weights, i.e., all the elements of w are equal, forms the basis of the work of Karlsson
(1997), Ferreira, Bianchi, and Ribeiro (2012), Aissani, Beldjilali, and Trentesaux (2008) and
Shabani (2009) amongst others, while non-uniform weights have been used by authors such
as Castelletti et al. (2002), Guo et al. (2009) and Perez et al. (2009). The majority of this
work uses TD methods, which work on-line, although Castelletti et al. (2010) extend off-line
Fitted Q-Iteration (Ernst, Geurts, & Wehenkel, 2005) to multiple objectives.
In most cases, the only change made to the underlying RL algorithm is that, rather than
scalarizing the reward function and then learning a scalar value function in the resulting
single-objective MDP, a vector-valued value function is learned in the original MOMDP and
then scalarized only when selecting actions. The argument for this approach is that the
values of individual objectives may be easier to learn than the scalarized value, particularly
when function approximation is employed (Tesauro et al., 2007). For example, each function
approximator can ignore any state variables that are irrelevant to its objective, reducing
the size of the state space and thereby speeding learning.
As discussed in Section 4.2.2, linear scalarization may not be appropriate for some scenarios. Vamplew, Yearwood, Dazeley, and Berry (2008) demonstrate empirically that this
can have practical consequences for MORL. Therefore, MORL methods that can work with
nonlinear scalarization functions are of substantial importance. Unfortunately, as illustrated
in Section 4.2.2, coping with this setting is especially challenging, since algorithms such as
TD methods that are based on the Bellman equation are inherently incompatible with
nonlinear scalarization functions due to the non-additive nature of the scalarized returns.
Four main classes of single-policy MORL methods using non-linear scalarization have
arisen, which differ in how they deal with this issue. The first class simply applies TD
methods without modification. These approaches either resign themselves to being heuristics that are not guaranteed to converge or impose restrictions on the environment to ensure
convergence. The second class modifies either the TD algorithm or the state representation
such that the issue of non-additive returns is avoided. The third class uses TD methods
to learn multiple policies using linear scalarization with different values for w, and then
forms a stochastic or non-stationary meta-policy from them that is optimal with respect
to a nonlinear scalarization. The fourth class uses policy-search methods, which do not
91

fiRoijers, Vamplew, Whiteson & Dazeley

make use of the Bellman equation and hence can be directly applied in combination with
nonlinear scalarizations.
The first class includes methods that model the problem as a multi-agent system, with
one agent per objective. Each agent learns and recommends actions on the basis of the
return for its own objective. A global switch then selects a winning agent, whose recommended action is followed for the current state. Examples include a simple winner-takes-all
approach in which the agent whose recommended action has the highest Q-value is selected,
or more sophisticated approaches such as W-learning (Humphrys, 1996) where the selected
action is the one that will incur the most loss if it is not followed. One key weakness of
such approaches was pointed out by Russell and Zimdars (2003): they do not allow for the
selection of actions that, while not optimal for any single objective, offer a good compromise
between multiple objectives. Another key weakness is that, since the actions selected at
different timesteps may be recommended by different agents, the resulting behavior corresponds to a policy that combines elements of those learned by each agent. This combination
may not be optimal even for a single objective, i.e., it may be Pareto dominated and perform
arbitrarily poorly.
TD has also been used directly with nonlinear scalarization functions that do allow for
the consideration of all actions, not just those which are optimal with regards to individual
objectives. Scalarization functions based on fuzzy logic have been proposed for problems
with discrete actions by Zhao, Chen, and Hu (2010) and for problems with continuous
actions by Lin and Chung (1999). A widely cited approach to nonlinear scalarization is
that of Gabor, Kalmar, and Szepesvari (1998), which is designed for tasks where constraints
must be satisfied for some objectives. A lexicographic ordering of the objectives is defined
and a threshold value is specified for all objectives except the last. State-action values for
each objective that exceed the corresponding threshold are clamped to that threshold value
prior to applying the lexicographic ordering. Thus, this thresholded lexicographic ordering
(TLO) approach to scalarization maximizes performance on the last objective subject to
meeting constraints on the other objectives as specified by the thresholds.
While methods combining TD with nonlinear scalarization may converge to a suitable
policy under certain conditions, they can also converge to a suboptimal policy or even fail
to converge under other conditions. For example, Issabekov and Vamplew (2012) demonstrate empirically that TLO can fail to converge to a suitable policy for episodic tasks if a
constrained objective receives non-zero rewards at any timestep other than the end of the
episode. In general, methods based on the combination of TD and nonlinear scalarization
must be regarded as heuristic in nature, or applicable only to restricted classes of problems.
The second class avoids the problems caused by non-additive scalarized returns by modifying either the TD algorithm or the state representation. To our knowledge, two approaches
proposed by Geibel (2006) to address the limitations of TLO are the only members of this
class. Both require that the reward accumulated for each objective over the current episode
be stored. In the first algorithm, local decision-making is based on the scalarized value of
the sum of the cumulative reward and the current state-action values. This eliminates the
problem of non-additive returns, but yields a policy that is non-stationary with respect to
the observed state, meaning the algorithm may not converge. The second approach augments the state representation with the cumulative reward. This approach converges to the
correct policy but learns slowly, due to the increase in the size of the state space.
92

fiA Survey of Multi-Objective Sequential Decision-Making

The third class uses TD methods only to learn policies based on linear scalarizations.
A policy selection mechanism based on a nonlinear scalarization is then used to form a
meta-policy from these base policies. The Multiple Directions Reinforcement Learning
(MDRL) algorithm of Mannor and Shimkin (2001, 2004) uses such an approach in the
context of on-line learning for non-episodic tasks. The user specifies a target region within
which the long-term average reward should lie. An initial active policy is chosen arbitrarily
and followed until the average reward moves outside of the target region and the agent is
in a specified reference state. At this point, the direction from the current average reward
vector to the closest point of the target set is calculated, and the policy whose direction best
matches this target direction is selected as the active policy. In this way, the average reward
is steered towards the users specified target region. While the underlying base policies
utilize linear scalarization, the nature of the policy-selection mechanism means that the
overall non-stationary policy formed from these base policies is optimal for the nonlinear
scalarization specified by the users defined target set. Vamplew et al. (2009) suggest a
similar approach for episodic tasks, with TD used first to learn policies that are optimal
under linear scalarization for a range of different w, before a stochastic mixture policy is
constructed that is optimal with regards to a nonlinear scalarization.
The fourth class uses policy-search algorithms that directly learn a policy without learning a value function. For single-policy MORL, research on policy-search approaches has
focused on policy-gradient methods (Sutton, McAllester, Singh, & Mansour, 2000; Kohl &
Stone, 2004; Kober & Peters, 2011). In such methods, a policy is iteratively adjusted in the
direction of the gradient of the value with respect to the parameters (usually probability
distributions over actions per state) of a policy. Shelton (2001) proposes an algorithm that
first learns the optimal policy for each individual objective. These are used as base policies to form an initial mixture policy that stochastically selects a base policy at the start
of each episode. A hill-climbing method based on a weighted convex combination of the
normalized objective gradients iteratively improves the mixture policy. This approach does
not directly fit our taxonomy because the returns themselves are never scalarized. Instead,
the weights are used to find a step direction relative to the current policy parameters. From
a practical perspective, its behavior is akin to that of single-policy RL using a nonlinear
scalarization function, as it converges to a single Pareto-optimal policy that need not lie
on the convex hull. Uchibe and Doya (2009) also propose a policy-gradient method for
MORL called Constrained Policy Gradient RL (CPGRL) which uses a gradient projection technique to find policies whose average reward satisfies constraints on one or more of
the objectives. Like Sheltons approach, CPGRL learns stochastic policies and works with
nonlinear scalarization functions.
6.2 Multiple-Policy Learning with Linear Scalarization Functions
In the unknown weights and decision support scenarios, if f is linear, then MORL algorithms
aim to learn a CCS of the possible policies. A simple but inefficient approach used by
Castelletti et al. (2002) is to run TD multiple times with different values of w. In the
simplest case, the runs are conducted sequentially to gradually build up an approximate
CCS. Natarajan and Tadepalli (2005) showed that this approach can be made more efficient
by reusing the policies learned on the earlier runs for the most similar w. They show that
93

fiRoijers, Vamplew, Whiteson & Dazeley

this improves greatly on sample costs when learning a policy for w similar to those already
visited in previous runs. However, many samples are typically still required before a good
approximate CCS is obtained.
A more sophisticated approach to approximating a convex coverage set is to learn multiple policies in parallel. Several algorithms have been proposed to achieve this within a
TD learning framework. The approach of Hiraoka, Yoshida, and Mishima (2009) is similar
to the CHVI planning algorithm of Barrett and Narayanan (2008) (see Section 5.2) in that
it learns in parallel the optimal value function for all w, using a convex hull representation.
This approach is prone to infinite growth in the number of vertices in convex hull polygons,
and so a threshold margin is applied to the hull representations on each iteration, eliminating points that contribute little to the hulls hypervolume. Hiraoka et al. (2009) present an
algorithm to adapt the margins during learning to improve efficiency, but note that many
parameters must be tuned for effective performance. Mukai, Kuroe, and Iima (2012) present
a similar extension of CHVI to a learning context. They address the problematic growth
in the number of values stored by pruning vectors after each Q-value update: a vector is
selected at random from the set of vectors stored for the given state-action pair and all
others lying within a threshold distance of it are deleted.
The approaches of both Hiraoka et al. (2009) and Mukai et al. (2012) are designed for
on-line learning. By contrast, Multi-Objective Fitted Q-Iteration (MOFQI) (Castelletti,
Pianosi, & Restelli, 2011, 2012) is an off-line approach to learning multiple policies. MOFQI
is a multi-objective extension of the Fitted Q-Iteration (FQI) algorithm (Ernst et al., 2005)
which uses a combination of historical data about the single-step transition dynamics of the
environment, an initial function approximator, and the Q-learning update rule to construct
a dataset that maps state-action pairs to their expected return. This dataset is then used
to train an improved function approximator and the process repeats until the values of the
function approximator converge. MOFQI provides a computationally efficient extension of
FQI to multiple objectives by including w in the input to the function approximator and
constructing an expanded training data set containing training instances with randomly
generated ws. Since the learned function generalizes across weight space in addition to
state-action space, it can be used to construct a policy for any w.
As discussed in Section 5.3, Lizotte et al. (2010) and Lizotte et al. (2012) describe a valueiteration algorithm to find the convex hull of policies for finite horizon tasks. They note that
this method can be applied in a learning context by estimating a model of the state transition
probabilities and immediate rewards on the basis of experience of the environment. This
approach is demonstrated for the task of analyzing randomized drug trial data by producing
these estimates from the historical data gathered during the clinical trials.
6.3 Multiple-Policy Learning with Monotonically Increasing Scalarization
Functions
If f is nonlinear, then MORL algorithms for the unknown weights and decision support scenarios should aim to learn a PCS. As in the linear scalarization case, the simplest approach
is to run single-objective algorithms multiple times with varying w. Shelton (2001) demonstrates this approach with a policy-gradient algorithm, while Vamplew et al. (2011) do the
same with the TLO method of Gabor et al. (1998). This approach however, requires that
94

fiA Survey of Multi-Objective Sequential Decision-Making

f is explicitly known to the learning algorithm, which may be undesirable in the decision
support scenario.
To our knowledge, there are currently no methods for learning multiple policies with
nonlinear f using a value-function approach. While it might seem possible to adapt convex
hull methods such as CHVI by using Pareto-dominance operators in place of convex-hull
calculations, doing so is not straightforward. Because the scalarized values of policies in a
certain state are non-additive, we cannot restrict ourselves to stationary policies if we want
to find all deterministic Pareto-optimal policies (as mentioned in Section 4.3.2). However,
for the Bellman equation from CHVI to work, additivity, and the resulting sufficiency of
deterministic policies, is required. We discuss options for developing multiple-policy learning
methods for nonlinear f in Sections 8.1 and 8.2.
Given the extensive research on both multi-objective evolutionary algorithms (MOEAs)
(Coello Coello, Lamont, & Van Veldhuizen, 2002; Tan, Khor, Lee, & Sathikannan, 2003;
Drugan & Thierens, 2012) and evolutionary methods for RL (Whiteson, 2012), there is surprisingly little work on evolutionary approaches to MORL. As these methods are populationbased, they are well suited to approximating Pareto fronts, and would thus seem a natural
fit when f is nonlinear. To our knowledge, Handa (2009b) was the first to apply MOEAs
to MORL, by extending Estimation of Distribution (EDA) evolutionary algorithms to handle multiple objectives. EDA-RL (Handa, 2009a) uses Conditional Random Fields (CRF)
to represent probabilistic policies. An initial set of policies are used to generate a set of
episodes. The best episodes from this set are selected and CRFs that are likely to produce these trajectories are generated. The policies formed from these CRFs then constitute
the next generation. Handa (2009b) extends EDA-RL to MOMDPs by using a Paretodominance based fitness metric to select the best episodes.
Soh and Demiris (2011) also apply MOEAs to MORL. Policies are represented as
Stochastic Finite State Controllers (SFSC) and are optimized using two different MOEAs:
NSGA2, a standard evolutionary algorithm, and MCMA, an EDA. The use of SFSCs gives
rise to a large search space, necessitating the addition of a local search operator. The local
search generates a random w, uses it to scalarize the rewards, and performs gradient-based
search on the SFSC. Empirical comparisons on multi-objective variants of three POMDP
benchmarks demonstrate that the evolutionary methods are generally superior to the purely
local-search approach, and that local search combined with evolution usually outperforms
the purely evolutionary methods. This is one of very few papers to directly consider partially
observable MOMDPs.

7. MOMDP Applications
Multi-objective methods for planning and learning have been employed in a wide range
of applications, both in simulation and real-world settings. In this section, we survey
these applications. For the sake of brevity, this list is not comprehensive but instead aims
to provide an illustrative range of examples. First, we discuss the use of multi-objective
methods in specific applications. Second, we discuss research that has identified broader
classes of problems in which multi-objective methods can play a useful role.
95

fiRoijers, Vamplew, Whiteson & Dazeley

7.1 Specific Applications
An important factor driving interest in multi-objective decision-making is the increasing
social and political emphasis on environmental concerns. More and more, decisions must
be made that trade off economic, social, and environmental objectives. This is reflected in
the fact that a substantial proportion of applications of multi-objective methods have an
environmental component.
Perhaps the most extensively researched application is the water reservoir control problem considered by Castelletti et al. (2002), Castelletti, Pianosi, and Soncini-Sessa (2008),
Castelletti et al. (2011, 2012) and Castelletti, Pianosi, and Restelli (2013). The general
task is to find a control policy for releasing water from a dam while balancing multiple uses
of the reservoir, including hydroelectric production and flood mitigation. Management of
hydroelectric power production has also been examined by Shabani (2009). Another environmental application is that of forest management to balance the economic benefits of
timber harvesting with environmental or aesthetic objectives, which has been demonstrated
in simulation by both Gong (1992) and Bone and Dragicevic (2009).
Several researchers have also considered environmentally-motivated applications concerning the management of energy consumption. The SAVES system developed by Kwak
et al. (2012) controls various aspects of a commercial building (lighting, heating, airconditioning, and computer systems) to provide a suitable trade-off between energy consumption and the comfort of the buildings occupants. Simulation results indicate that
SAVES can reduce energy consumption approximately 30% compared to a manual control
system, while maintaining or slightly improving occupant comfort. Both Tesauro et al.
(2007) and Liu et al. (2010) consider the problem of controlling a computing server, with
the objectives of minimizing both response time to user requests and power consumption.
Guo et al. (2009) apply MORL to develop a broker agent in the electricity market. The
broker sets caps for a group of agents that sit below it in a hierarchy and manage energy
consumption at a device level, and must balance energy cost and system stability.
Shelton (2001) also examines the application of MORL to developing broker agents.
However, in this case the agents task is financial rather than environmental, acting as a
market maker that sets buy and sell prices for resources in a market. The aim is to balance
the objectives of maximizing profit and minimizing spread (the difference between the buy
and sell prices) as that will lead to a larger volume of trades11 .
Computing and communications applications have also been widely considered. Perez
et al. (2009) apply MORL to the allocation of resources to jobs in a cloud computing scenario, with the objectives of maximizing system responsiveness, utilization of resources, and
fairness amongst different classes of user. Comsa et al. (2012) consider how to maximize
system throughput and ensure user equity in the context of a Long Term Evolution mobile
communications packet scheduling protocol. Tong and Brown (2002) use constraint-based
scalarization to address the tasks of call access control and routing in a broadband multimedia network. Their system aims to maximize profit (a function of throughput) while
satisfying constraints on quality of service metrics (capacity constraints and fairness constraints), and uses methods similar to that of Gabor et al. (1998). Zheng, Li, Qiu, and Gong
11. Sheltons model of the market does not directly model trading volume, and so spread is used as a proxy
for volume.

96

fiA Survey of Multi-Objective Sequential Decision-Making

(2012) also use constrained MORL methods to make routing decisions in a cognitive radio
network, aiming to minimize average transmission delay while maintaining an acceptably
low packet loss rate.
Industrial and mechanical control, an important application for single-objective MDP
methods, has also been explored by MOMDP researchers. Aoki, Kimura, and Kobayashi
(2004) apply distributed RL to control a sewage flow system, exploiting the systems hierarchical structure to find a solution that minimizes violation of stock levels at each node
in the flow system, while smoothing variation in flow at the source. Aissani et al. (2008)
apply MORL to maintenance scheduling within a manufacturing plant to minimize the time
taken to complete all maintenance tasks and machine downtime. Aissani, Beldjilali, and
Trentesaux (2009) build on this work by applying it to a simulation of a real petroleum refinery and demonstrating the ability to adapt to unscheduled corrective maintenance required
due to equipment failures. The control of a wet clutch in heavy-duty transmission systems
is examined by Van Vaerenbergh et al. (2012). There are twin objectives of minimizing
engagement time, while also making the transition smooth.
Robotics are also a popular application for MOMDPs, though most work so far has been
in simulation rather than on real robots. Maravall and de Lope (2002) consider the control
of a two-limbed brachiating robot, with the objectives of moving in a desired direction
while avoiding collisions12 . Nojima, Kojima, and Kubota (2003) also attempt to balance
the objectives of progress to a target and collision avoidance. Their agent makes use of
predefined behavioral modules for target tracing, collision avoidance, and wall following,
with MORL used to dynamically adjust the weighting of the modules. Meisner (2009)
identifies social robots as a promising application of MOMDP methods: their behavior is
inherently multi-objective because they must carry out a task without causing anxiety or
discomfort for humans.
MORL has also been applied to the control of traffic infrastructure. Yang and Wen
(2010) apply it to the control of freeway on-ramps and vehicle management systems, aiming
to maximize both the throughput and equity of a freeway system. Multiple agents with
shared policies are used, with action selection occurring via negotiation between agents.
Similarly, Dusparic and Cahill (2009) apply MORL to control traffic lights at intersections
in an urban environment to minimize waiting time of two different classes of vehicles. Yin,
Duan, Li, and Zhang (2010) and Houli, Zhiheng, and Yi (2010) also apply MORL to traffic
light control. The novelty of their approach lies in considering different objectives based
on the current state of the road system; minimizing vehicle stops is prioritized when traffic
is free-flowing; minimizing waiting time is emphasized when the system is at medium load;
and minimizing queue length at intersections is targeted when the system is congested.
Lizotte et al. (2010, 2012) consider a medical application: prescribing an appropriate
drug regime for a patient so as to achieve an acceptable trade-off between the drugs effectiveness and the severity of its side effects. Their system learns multiple policies based on
12. In many robotic applications it may be ideal to avoid collisions completely, but in some environments
this may not be possible (e.g., in the presence of moving obstacles whose velocity is both faster than that
of the robot, and difficult to predict, such as may be the case for humans or human-controlled vehicles)
and so reducing both the likelihood and impact of collisions may be more reasonable than attempting
to find a collision-free policy. See for example Holenstein and Badreddin (1991) and Pervez and Ryu
(2008).

97

fiRoijers, Vamplew, Whiteson & Dazeley

static data produced during randomized controlled drug trials. The selection of the best
treatment for a specific patient is then made by a doctor based on that patients individual circumstances. This application is an excellent example of a problem where stochastic
approaches like mixture policies are inappropriate. A policy that maximizes both symptom relief and also side effects for one patient and then minimizes side effects but also
symptom relief for the next patient may appear to give excellent results when averaged
across episodes. However, the experience of each individual patient will likely be regarded
as undesirable.
7.2 Applications within Broader Planning and Learning Tasks
In addition to the specific applications discussed above, several authors have identified more
general classes of tasks in which multi-objective sequential decision-making can be applied.
7.2.1 Probabilistic and Risk-Aware Planning
Cheng, Subrahmanian, and Westerberg (2005) argue that decision-making under uncertainty is inherently multi-objective in nature. Even if there is only a single reward to be
considered (such as profit), the environmental uncertainty means that the expected value
alone is insufficient to support good decision-making; the decision-maker must also consider
the variance of the return. Similarly, Bryce (2008) states that probabilistic planning is
inherently multi-objective due to the need to optimize both the cost and the probability of
success of the plan. He criticizes approaches that either aggregate these factors or bound one
and then optimize the other, arguing in favor of explicitly multi-objective methods. The
aptly named Probabilistic Planning is Multi-objective! paper by Bryce, Cushing, and
Kambhampati (2007) demonstrates how this might be achieved, describing a method based
on multi-objective dynamic programming over belief states, and a multi-objective extension
of the Looping AO* search algorithm to find the set of Pareto-optimal plans. Recent work
by Kolobov, Mausam, and Weld (2012) and Teichteil-Konigsbuch (2012b) examine the extension of stochastic shortest path (SSP) methods to problems where dead-end states exist.
SSP methods assume that at least one policy exists which is guaranteed to reach the goal;
in the presence of dead-ends no such policy exists, and so the authors propose algorithms
which aim to both maximize the probability of reaching the goal and minimize the cost of
the paths found to that goal.
Bryce (2008) notes that a probabilistic plan fails when the environment enters a non-goal
absorbing state. Hence, multi-objective probabilistic planning has strong parallels with the
research into risk-aware RL carried out by Geibel (2001) and Geibel and Wysotzki (2005),
which add a second reward signal indicating the transition of the environment into an error
state. Defourny, Ernst, and Wehenkel (2008) also provide useful insights into the incorporation of risk-awareness into MDP methods. They review a range of criteria proposed
for constraining risk, and note that many of these are nonlinear and produce non-additive
scalarized returns that are incompatible with the local decision-making of methods based
on the Bellman equation. They recommend that custom risk-control requirements should
be mostly enforced heuristically, by altering policy optimization procedures and checking
the compliance of the policies with the initial requirements. Multi-policy MOMDP methods treating risk as an additional objective would satisfy this requirement: having iden98

fiA Survey of Multi-Objective Sequential Decision-Making

tified the coverage set, any risk-aware metric can then be used to select the best policy.
However, some measures of risk may not be expressed directly as discounted cumulative
rewards. For example, an agent may wish to minimize the variance in the expected return for a particular reward signal rather than its discounted cumulative value. Methods
based on multi-objective probabilistic model checking (Courcoubetis & Yannakakis, 1998;
Forejt, Kwiatkowska, Norman, Parker, & Qu, 2011; Forejt, Kwiatkowska, & Parker, 2012;
Teichteil-Konigsbuch, 2012a), which evaluate whether a system modelled as an MDP satisfies multiple, possibly conflicting, properties, may be suitable for such tasks.
7.2.2 Multi-Agent Systems
The use of MDPs within multi-agent systems has been widely explored (Bosoniu, Babuska,
& Schutter, 2008), and several authors have proposed approaches that are strongly related
to MOMDPs. In a multi-agent system, each agent has its own objective, but for effective
overall performance must also consider how its actions will affect the other agents. If the
agents are not completely self-interested, then this problem can be framed as an MOMDP by
treating the effects on other agents as additional objectives. For example, Mouaddib (2006)
uses multi-objective dynamic programming to facilitate cooperation between multiple agents
whose underlying goals may be conflicting. For each state-action pair, each agent stores
three values: its local utility, the gain other agents receive, and the penalty it inflicts on
other agents. The policy for each agent is then established by converting these vector values
to regret ratios and applying a leximin ordering to these ratios.
Dusparic and Cahill (2010) compare the application of MORL to multi-agent tasks with
other multi-agent methods such as evolutionary and ant-colony algorithms. Dusparic and
Cahill (2009) extend the W-Learning algorithm of Humphrys (1996). Each agent learns
both local policies (one for each of its own objectives) and remote policies (one for each
local policy of each of its neighboring agents). At each timestep, all local policies and all
active remote policies of each agent nominate actions, and a winning action is selected by
combining action values across all nominating policies. A weighting term is applied to the
values of remote policies to determine the level of cooperation each agent offers its neighbor.
Experimental results in an urban traffic control simulator show substantial improvement
when the level of cooperation is non-zero. This work is similar to that of Schneider, Wong,
Moore, and Riedmiller (1999), which addresses the use of multiple agents in a distributed
network such as a power distribution grid, where the aim is to maximize a global reward
formed from a combination of each agents local reward. They demonstrate that if each
agent focuses only on its own local reward, the policies learned may not maximize the global
reward, and that performance is improved by having each agent perform linearly scalarized
learning using both its own local reward and the rewards of its neighboring agents.
7.2.3 Multi-Objective Optimization using Reinforcement Learning
Reinforcement learning is primarily applied to sequential decision-making tasks in a dynamic
environment. However it can also be employed to control search mechanisms for static optimization tasks such as scheduling (Carchrae & Beck, 2005). Multi-objective optimization
for static tasks such as design is a well-established field and, while the majority of this work
99

fiRoijers, Vamplew, Whiteson & Dazeley

has employed mathematical or evolutionary approaches (Coello Coello et al., 2002), a few
authors have explored the application of reinforcement learning in such contexts.
Mariano and Morales (1999, 2000b, 2000a) investigate the use of RL methods (Ant-Q
and Q-learning) as a search mechanism for optimization of multi-objective design tasks. The
values of the decision variables are considered as the current state, and actions are defined
that alter the values of those variables. Multiple agents explore the state space in parallel.
Agents are divided into families, where each family focuses on a single objective. At the
end of an episode, the final states found by each agent are evaluated. Undominated solutions are kept in an archive and the agents that discovered those solutions are rewarded,
increasing the likelihood of similar policies being followed in the future. The method is
shown to work on a small number of test problems from the evolutionary multi-objective
optimization literature. Liao, Wu, and Jiang (2010) apply RL to search for static control
settings for a power generation system with the objectives of reducing fuel usage and ensuring voltage stability. They propose an RL algorithm that is formulated specifically for tasks
with high-dimensional state spaces, and compare its performance against an evolutionary
multi-objective algorithm, finding that the RL method discovers fronts that are both more
accurate and better distributed, while also improving the speed of search.
Note that to effectively apply RL to multi-objective optimization, assumptions are usually made about the nature of the environment. For example, Liao et al. (2010) require
that each action increases or decreases the value of precisely one state variable. As a result,
these methods are likely to have limited applicability to the more general MORL problems
described earlier.

8. Future Work
In this section, we enumerate some of the possibilities for future research in multi-objective
planning and learning.
8.1 Model-Based Methods
As mentioned in Section 6, there has been very little work on model-based approaches to
MORL. Given the breadth of planning methods for MOMDPs, which could be employed in
model-based MORL methods as subroutines, this is surprising. To our knowledge, the only
work in this area is that of Lizotte et al. (2010, 2012), where a model of the MOMDPs
transition probabilities and reward function is derived from historical data, and then a
spline-based multi-objective value iteration approach is applied to that model. In general,
learning such models seems only negligibly harder than in the single-objective setting, since
estimates of each reward function can just be learned separately. The problem of learning
the transition function, generally considered the hard part of model learning, is identical to
the single-objective setting. Especially in multiple-policy scenarios, model-based approaches
to MORL could greatly reduce sample costs: once the model has been learned, an entire
CCS or PCS can be computed off-line, without requiring additional samples.
100

fiA Survey of Multi-Objective Sequential Decision-Making

8.2 Learning Multiple Policies with Monotonically Increasing Scalarization
Functions using Value Functions
As mentioned in Section 6.3, we are not aware of any methods that use a value function
approach to learn multiple policies on the PCS. When stochastic policies are permitted,
the problem is easier because we can learn CCS(m
DS ), and use either mixture policies
(Vamplew et al., 2009) or stationary randomizations (Wakuta, 1999) of the policies on
this CCS (see Section 4.3.3). However, when only deterministic policies are permitted, the
problem is more difficult. One option could be to use a finite-horizon approximation to the
infinite horizon problem. By planning backwards from the planning horizon, the expected
reward of t timesteps to go approximates the infinite-horizon value better and better as
t  . As mentioned in Section 5.2, similar approaches have been used in the POMDP
setting. Another way to find good approximations to non-stationary policies could be to
learn stationary policies (perhaps by extending CON-MDP (Wiering & De Jong, 2007) to
the learning setting), and prefix them by t timesteps of non-stationary policy.
8.3 Many-Objective Sequential Decision-Making
The majority of the research reviewed in this article, both theoretical and applied, deals with
MOMDPs with only a few objectives. This mirrors the state of early evolutionary multiobjective research, which focused almost exclusively on problems with two or at most three
objectives. However, over the last decade there has been growing interest in evolutionary
methods for so-called many-objective problems, which have at least four and sometimes
more than fifty objectives (Ishibuchi, Tsukamoto, & Nojima, 2008). This research has
shown that many algorithms that perform well for a few objectives scale poorly in the
number of objectives, necessitating special algorithms for the many-objective setting.
While many-objective MDPs have received little consideration so far, there are numerous real-world control problems that can be naturally modeled in this way. For example,
Fleming et al. (2005) point out that many-objective control problems commonly arise in
engineering, and give the example of a jet engine control system with eight objectives. As
with the many-objective problems considered in evolutionary computation, it seems likely
that at least some of the methods explored so far will scale poorly in the number of objectives. For example, the multi-policy MOMDP planning algorithm described by Lizotte
et al. (2010) is limited to problems with two objectives.
A key challenge posed by many-objective problems is that the number of undominated
solutions typically grows exponentially in the number of objectives. This is particularly
problematic for multiple-policy MOMDP methods. Fleming et al. (2005) note that one
of the most effective approaches used in many-objective evolutionary computation is to
incorporate user preferences to restrict the search space to a small region of interest. In
particular, they recommend interactive preference articulation in which the user interactively steers the system towards a desirable solution during optimization. While Vamplew
et al. (2011) raise the possibility of incorporating such an approach into MORL, we are not
aware of any research that has actually done so.
101

fiRoijers, Vamplew, Whiteson & Dazeley

(3,0)

(0,3)

B

C
A

(1,1)

D
Figure 3: An MOMDP with two objectives and four states.
8.4 Expectation of Scalarized Return
In Section 3, we defined the scalarized value Vw (s) to be the result of applying the scalarization function f to the multi-objective value V (s) according to w, i.e., Vw (s) = f (V (s), w).
Since V (s) is itself an expectation, this means that the scalarization function is applied
after the expectation is computed, i.e.,
Vw (s) = f (V (s), w) = f (E[


X

 k rk | , s0 = s], w).

k=0

This formulation, which we refer to as the scalarization of the expected return (SER) is
standard in the literature. However, it is not the only option. It is also possible to define
Vw (s) as the expectation of the scalarized return (ESR):
Vw (s) = E[f (


X

 k rk , w) | , s0 = s]

k=0

Which definition is used can critically affect which policies are preferred. For example,
consider the following MOMDP, illustrated in Figure 3. There are four states (A, B, C, and
D) and two objectives. The agent starts in state A and has two possible actions: a1 transits
to state B or C, each with probability of 0.5, and a2 transits to state D with probability 1.
Both actions lead to a (0, 0) reward. In states B, C and D there is only one action, which
leads to a deterministic reward of (3, 0) for B, (0, 3) for C, and (1, 1) for D.
The scalarization function just multiplies the two objectives together. Thus, under SER,
Vw (s) = V1 (s)V2 (s),
and under ESR,
Vw (s) = E[


X
k=0

 k rk1


 X
k=0

102


 k rk2 | , s0 = s],

fiA Survey of Multi-Objective Sequential Decision-Making

where rki is the reward for the i-th objective on timestep k (w is not needed in this example
since f involves no constants). If 1 (A) = a1 and 2 (A) = a2 , then the multi-objective
values are V1 (A) = (1.5/(1  ), 1.5/(1  )) and V2 (A) = (/(1  ), /(1  )).
Under SER, this leads to scalarized values of V 1 (A) = (1.5/(1  ))2 and V 2 (A) =
(/(1  ))2 and consequently 1 is preferred. Under ESR, however, we have V 1 (A) = 0
and V 2 (A) = (/(1  ))2 and thus 2 is preferred.
Intuitively, the SER formulation is appropriate when the policy will be used many times
and return accumulates across episodes, e.g., because the same user is using the policy each
time. Then, scalarizing the expected reward makes sense and 1 is preferable because in
expectation it will accumulate more return in both objectives. However, if the policy will
only be used a few times or the return does not accumulate across episodes, e.g., because
each episode is conducted for a different user, then the ESR formulation is more appropriate.
In this case, the expected return before scalarization is not of interest and 2 is preferable
because 1 will always yield zero scalarized return on any given episode.
To our knowledge, there is no literature on MOMDPs that employs the ESR formulation,
even though there are many real-world scenarios in which it seems more appropriate. For
example, in the medical application of Lizotte et al. (2010) mentioned in Section 7, each
patient gets only one episode to treat his or her illness, and is thus clearly interested in
maximizing ESR, not SER. Thus, we believe that developing methods for MOMDPs under
the ESR formulation is a critical direction for future research.

9. Conclusions
This article presented a survey of algorithms designed for sequential decision-making problems with multiple objectives.
In order to make explicit under what circumstances special methods are needed to
solve multi-objective problems, we identified three distinct scenarios in which converting
such a problem to a single-objective one is impossible, infeasible, or undesirable. As well as
providing motivation for the need for multi-objective methods, these scenarios also represent
the three main ways these methods are applied in practice.
We proposed a taxonomy that classifies multi-objective methods according to the applicable scenario, the scalarization function (which projects multi-objective values to scalar
ones), and the type of policies considered. We showed how these factors determine the
nature of an optimal solution, which can be a single policy, or a coverage set (convex or
Pareto). Our taxonomy is based on a utility-based approach, which sees the scalarization
function as part of the utility, and thus part of the problem definition. This contrasts with
the so-called axiomatic approach, which usually assumes the Pareto front is the appropriate
solution. We showed that the utility-based approach can be used to justify the choice for
a solution set. Following this line of thought, we observed (Observation 1) that computing
the Pareto front is often not necessary, and that in many cases a convex coverage set of
deterministic stationary policies is sufficient.
Using our taxonomy, we surveyed the literature on multi-objective methods for planning
and learning. An interesting observation is that most of the learning methods use a modelfree rather than a model based approach, identifying the latter as an understudied class of
103

fiRoijers, Vamplew, Whiteson & Dazeley

methods. Another part of the taxonomy which has not yet been widely studied is learning
in the case of monotonically increasing scalarization functions.
We discussed key applications of MOMDP methods as motivation for the importance
of such methods. Applications were identified in a diverse range of fields including environmental management, financial markets, information and communications technology, and
control of industrial processes, robotic systems and traffic infrastructure. In addition connections were identified between multi-objective sequential decision-making and other broad
areas of research such as probabilistic planning and model-checking, multi-agent systems
and more general multi-objective optimization.
Finally, we outlined several opportunities for future work, which include understudied
areas (model-based methods, learning in monotonically increasing scalarization settings,
and many-objective sequential decision-making), and a reformulation of the objective for
MOMDPs  the Expectation of Scalarized Return  which is particularly important to
optimize when a policy can be executed only once.

Acknowledgments
We would like to thank Matthijs Spaan, Frans Oliehoek, Matthijs Snel, Marie D. Manner
and Samy Sa, as well as the anonymous reviewers, for their valuable feedback. This work
is supported by the Netherlands Organisation for Scientific Research (NWO): DecisionTheoretic Control for Network Capacity Allocation Problems (#612.001.109) project.

References
Aberdeen, D., Thiebaux, S., & Zhang, L. (2004). Decision-theoretic military operations
planning. In Proc. ICAPS, Vol. 14, pp. 402411.
Aissani, N., Beldjilali, B., & Trentesaux, D. (2008). Efficient and effective reactive scheduling of manufacturing system using Sarsa-multi-objective agents. In MOSIM08: 7th
Conference Internationale de Modelisation et Simulation, pp. 698707.
Aissani, N., Beldjilali, B., & Trentesaux, D. (2009). Dynamic scheduling of maintenance
tasks in the pretroleum industry: A reinforcement approach. Engineering Applications
of Artificial Intelligence, 22, 10891103.
Altman, E. (1999). Constrained Markov Decision Processes. Chapman and Hall/CRC,
London.
Aoki, K., Kimura, H., & Kobayashi, S. (2004). Distributed reinforcement learning using
bi-directional decision making for multi-criteria control of multi-stage flow systems.
In The 8th Conference on Intelligent Autonomous Systems, Vol. 2004.03, pp. 281290.
Barrett, L., & Narayanan, S. (2008). Learning all optimal policies with multiple criteria.
In Proceedings of the 25th International Conference on Machine Learning, pp. 4147,
New York, NY, USA. ACM.
Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2003). Transition-Independent
Decentralized Markov Decision Processes. In Proc. of the 2nd Intl Joint Conf. on
Autonomous Agents & Multi-Agent Systems.
104

fiA Survey of Multi-Objective Sequential Decision-Making

Bellman, R. E. (1957a). A Markov decision process. Journal of Mathematical Mech., 6,
679684.
Bellman, R. (1957b). Dynamic Programming. Princeton University Press.
Bhattacharya, B., Lobbrecht, A. H., & Solomantine, D. P. (2003). Neural networks and reinforcement learning in control of water systems. Journal of Water Resources Planning
and Management, 129 (6), 458465.
Bone, C., & Dragicevic, S. (2009). GIS and intelligent agents for multiobjective natural
resource allocation: A reinforcement learning approach. Transactions in GIS, 13 (3),
253272.
Bosoniu, L., Babuska, R., & Schutter, B. D. (2008). A comprehensive survey of multiagent
reinforcement learning. IEEE Transactions on Systems, Man, and Cybernetics - Part
C: Applications and Reviews, 38 (2), 156172.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. Journal of Artificial Intelligence Research,
11, 194.
Brazdil, T., Brozek, V., Chatterjee, K., Forejt, V., & Kucera, A. (2011). Two views on
multiple mean-payoff objectives in Markov decision processes. CoRR, abs/1104.3489.
Bryce, D. (2008). The value(s) of probabilistic plans. In Workshop on a Reality Check for
Planning and Scheduling under Uncertainty, ICAPS-08.
Bryce, D., Cushing, W., & Kambhampati, S. (2007). Probabilistic planning is multiobjective!. Technical report 08-006, Arizona State University.
Carchrae, T., & Beck, J. C. (2005). Applying machine learning to low-knowledge control of
optimization algorithms. Computational Intelligence, 21 (4), 372387.
Cassandra, A., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: A simple, fast,
exact method for partially observable markov decision processes. In Proceedings of
the Thirteenth conference on Uncertainty in artificial intelligence, pp. 5461.
Castelletti, A., Pianosi, F., & Restelli, M. (2013). A multiobjective reinforcement learning
approach to water resources systems operation: Pareto frontier approximation in a
single run. Water Resources Research.
Castelletti, A., Corani, G., Rizzolli, A., Soncini-Sessa, R., & Weber, E. (2002). Reinforcement learning in the operational management of a water system. In IFAC Workshop
on Modeling and Control in Environmental Issues, pp. 325330.
Castelletti, A., Galelli, S., Restelli, M., & Soncini-Sessa, R. (2010). Tree-based reinforcement learning for optimal water reservoir operation. Water Resources Research,
46 (W09507).
Castelletti, A., Pianosi, F., & Restelli, M. (2011). Multi-objective Fitted Q-Iteration: Pareto
frontier approximation in one single run. In International Conference on Networking,
Sensing and Control, pp. 260265.
Castelletti, A., Pianosi, F., & Restelli, M. (2012). Tree-based Fitted Q-iteration for multiobjective Markov decision processes. In IEEE World Congress on Computational
Intelligence.
105

fiRoijers, Vamplew, Whiteson & Dazeley

Castelletti, A., Pianosi, F., & Soncini-Sessa, R. (2008). Water reservoir control under economic, social and environmental constraints. Automatica, 44, 15951607.
Chatterjee, K. (2007). Markov decision processes with multiple long-run average objectives.
In FSTTCS, Vol. LNCS 4855, pp. 473484.
Chatterjee, K., Majumdar, R., & Henzinger, T. A. (2006). Markov decision processes with
multiple objectives. In Proceedings of the 23rd Annual conference on Theoretical
Aspects of Computer Science, STACS06, pp. 325336, Berlin, Heidelberg. SpringerVerlag.
Cheng, L., Subrahmanian, E., & Westerberg, A. (2005). Multiobjective decision processes
under uncertainty: Applications, formulations and solution strategies. Industrial and
Engineering Chemistry Research, 44 (8), 24052415.
Clemen, R. T. (1997). Making Hard Decisions: An Introduction to Decision Analysis (2
edition). South-Western College Pub.
Coello Coello, C. A., Lamont, G. B., & Van Veldhuizen, D. A. (2002). Evolutionary Algorithms for Solving Multi-Objective Problems. Kluwer Academic Publishers.
Comsa, I., Aydin, M., Zhang, S., Kuonen, P., & Wagen, J.-F. (2012). Multi objective resource scheduling in LTE networks using reinforcement learning. International Journal
of Distributed Systems and Technologies, 3 (2), 3957.
Courcoubetis, C., & Yannakakis, M. (1998). Markov decision processes and regular events.
IEEE Transactions on Automatic Control, 43 (10), 13991418.
Crites, R. H., & Barto, A. G. (1996). Improving elevator performance using reinforcement
learning. In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), Advances in
Neural Information Processing Systems 8, pp. 10171023. MIT Press.
Daellenbach, H. G., & Kluyver, C. A. D. (1980). Note on multiple objective dynamic
programming. Journal of the Operational Research Society, 31, 591594.
Defourny, B., Ernst, D., & Wehenkel, L. (2008). Risk-aware decision making and dynamic
programming. In NIPS 2008 Workshop on Model Uncertainty and Risk in RL.
Diehl, M., & Haimes, Y. Y. (2004). Influence diagrams with multiple objectives and tradeoff analysis. Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE
Transactions on, 34 (3), 293304.
Drugan, M. M., & Thierens, D. (2012). Stochastic pareto local search: Pareto neighbourhood
exploration and perturbation strategies. Journal of Heuristics, 18 (5), 727766.
Dusparic, I., & Cahill, V. (2009). Distributed W-learning: Multi-policy optimization in selforganizing systems. In Third IEEE International Conference on Self-Adaptive and
Self-Organizing Systems, pp. 2029.
Dusparic, I., & Cahill, V. (2010). Multi-policy optimization in self-organizing systems. In
SOAR 2009, LNCS 6090, pp. 101126.
Dyer, J. S., Fishburn, P. C., Steuer, R. E., Wallenius, J., & Zionts, S. (1992). Multiple criteria decision making, multiattribute utility theory: The next ten years. Management
Science, 38 (5), 645654.
106

fiA Survey of Multi-Objective Sequential Decision-Making

Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.
Journal of Machine Learning Research, 6, 503556.
Ernst, D., Glavic, M., & Wehenkel, L. (2004). Power systems stability control: Reinforcement learning framework. IEEE Transactions on Power Systems, 19 (1), 427435.
Feinberg, E. A., & Shwartz, A. (1995). Constrained Markov decision models with weighted
discounted rewards. Mathematics of Operations Research, 20 (2), 302320.
Ferreira, L., Bianchi, R., & Ribeiro, C. (2012). Multi-agent multi-objective reinforcement
learning using heuristically accelerated reinforcement learning. In 2012 Brazilian
Robotics Symposium and Latin American Robotics Symposium, pp. 1420.
Fleming, P., Purshouse, R., & Lygoe, R. (2005). Many-objective optimization: An engineering design perspective. In Evolutionary Multi-Criterion Optimization: Lecture Notes
in Computer Science, Vol. 3410, pp. 1432.
Forejt, V., Kwiatkowska, M., Norman, G., Parker, D., & Qu, H. (2011). Quantitative
multi-objective verification for probabilistic systems. In Tools and Algorithms for the
Construction and Analysis of Systems, pp. 112127. Springer Berlin Heidelberg.
Forejt, V., Kwiatkowska, M., & Parker, D. (2012). Pareto curves for probabilistic model
checking. In Automated Technology for Verification and Analysis, pp. 317332.
Springer Berlin Heidelberg.
Furnkranz, J., Hullermeier, E., Cheng, W., & Park, S.-H. (2012). Preference-based reinforcement learning: a formal framework and a policy iteration algorithm. Machine
Learning, 89 (1-2), 123156.
Gabor, Z., Kalmar, Z., & Szepesvari, C. (1998). Multi-criteria reinforcement learning. In
The Fifteenth International Conference on Machine Learning, pp. 197205.
Geibel, P., & Wysotzki, F. (2005). Risk-sensitive reinforcement learning applied to control
under constraints. Journal of Artificial Intelligence Research, 24, 81108.
Geibel, P. (2001). Reinforcement learning with bounded risk. In Proceeding of the 18th
International Conference on Machine Learning, pp. 162169.
Geibel, P. (2006). Reinforcement learning for MDPs with constraints. In European Conference on Machine Learning, Vol. 4212, pp. 646653.
Gelly, S., & Silver, D. (2011). Monte-carlo tree search and rapid action value estimation in
computer go. Artificial Intelligence, 175 (11), 18561875.
Gong, P. (1992). Multiobjective dynamic programming for forest resource management.
Forest Ecology and Management, 48, 4354.
Guo, Y., Zeman, A., & Li, R. (2009). A reinforcement learning approach to setting multiobjective goals for energy demand management. International Journal of Agent Technologies and Systems, 1 (2), 5570.
Handa, H. (2009a). EDA-RL: Estimation of distribution algorithms for reinforcement learning problems. In ACM/SIGEVO Genetic and Evolutionary Computation Conference,
pp. 405412.
107

fiRoijers, Vamplew, Whiteson & Dazeley

Handa, H. (2009b). Solving multi-objective reinforcement learning problems by EDA-RL acquisition of various strategies. In Proceedings of the Ninth Internatonal Conference
on Intelligent Sysems Design and Applications, pp. 426431.
Hiraoka, K., Yoshida, M., & Mishima, T. (2009). Parallel reinforcement learning for weighted
multi-criteria model with adaptive margin. Cognitive Neurodynamics, 3, 1724.
Holenstein, A. A., & Badreddin, E. (1991). Collision avoidance in a behavior-based mobile
robot design. In Robotics and Automation, 1991. Proceedings., 1991 IEEE International Conference on, pp. 898903. IEEE.
Houli, D., Zhiheng, L., & Yi, Z. (2010). Multiobjective reinforcement learning for traffic
signal control using vehicular ad hoc network. EURASIP Journal on Advances in
Signal Processing.
Howard, R. A. (1960). Dynamic programming and Markov decision processes. MIT Press.
Humphrys, M. (1996). Action selection methods using reinforcement learning. In Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior, pp.
135144.
Ishibuchi, H., Tsukamoto, N., & Nojima, Y. (2008). Evolutionary many-objective optimisation: A short review. In IEEE Congress on Evolutionary Computation, pp. 24192426.
Issabekov, R., & Vamplew, P. (2012). An empirical comparison of two common multiobjective reinforcement learning algorithms. In AI2012: The 25th Australasian Joint
Conference on Artificial Intelligence, pp. 626636.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning and acting in
partially observable stochastic domains. Artificial Intelligence, 101, 99134.
Karlsson, J. (1997). Learning to Solve Multiple Goals. Ph.D. thesis, University of Rochester.
Kober, J., & Peters, J. (2011). Policy search for motor primitives in robotics. Machine
Learning, 12, 171203.
Kober, J., & Peters, J. (2012). Reinforcement learning in robotics: A survey. In Wiering,
M., & Otterlo, M. (Eds.), Reinforcement Learning, Vol. 12 of Adaptation, Learning,
and Optimization, pp. 579610. Springer Berlin Heidelberg.
Kocsis, L., & Szepesvari, C. (2006). Bandit based monte-carlo planning. In 17th European
Conference on Machine Learning, pp. 282293. Springer.
Kohl, N., & Stone, P. (2004). Policy gradient reinforcement learning for fast quadrupedal
locomotion. In Proceedings of the IEEE International Conference on Robotics and
Automation, pp. 26192624.
Kolobov, A., Mausam, & Weld, D. S. (2012). A theory of goal-oriented mdps with dead
ends. In Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial
Intelligence.
Kwak, J., Varakantham, P., Maheswarn, R., Tambe, M., Jazizadeh, F., Kavulya, G., Klein,
L., Becerik-Gerber, B., Hayes, T., & Wood, W. (2012). SAVES: A sustainable multiagent application to conserve building energy considering occupants. In 11th International Conference on Autonomous Agents and Multiagent Systems, pp. 2128.
108

fiA Survey of Multi-Objective Sequential Decision-Making

Liao, H., Wu, Q., & Jiang, L. (2010). Multi-objective optimization by reinforcement learning
for power system dispatch and voltage stability. In Innovative Smart Grid Technologies
Conference Europe.
Lin, C.-T., & Chung, I.-F. (1999). A reinforcement neuro-fuzzy combiner for multiobjective
control. IEEE Transactions on Systems, Man and Cyberbetics - Part B, 29 (6), 726
744.
Liu, C., Xu, X., & Hu, D. (2013). Multiobjective reinforcement learning: A comprehensive
overview. Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE
Transactions on, PP (99), 113.
Liu, W., Tan, Y., & Qiu, Q. (2010). Enhanced q-learning algorithm for dynamic power
management with performance constraints. In DATE10, pp. 602605.
Lizotte, D. J., Bowling, M., & Murphy, S. A. (2010). Efficient reinforcement learning with
multiple reward functions for randomized clinical trial analysis. In 27th International
Conference on Machine Learning, pp. 695702.
Lizotte, D. J., Bowling, M., & Murphy, S. A. (2012). Linear fitted-q iteration with multiple
reward functions. Journal of Machine Learning Research, 13, 32533295.
Madani, O., Hanks, S., & Condon, A. (1999). On the undecidability of probabilistic planning
and infinite-horizon partially observable Markov decision problems. In Proceedings of
the National Conference on Artificial Intelligence (AAAI), pp. 541548.
Mannor, S., & Shimkin, N. (2001). The steering approach for multi-criteria reinforcement
learning. In Neural Information Processing Systems, pp. 15631570.
Mannor, S., & Shimkin, N. (2004). A geometric approach to multi-criterion reinforcement
learning. Journal of Machine Learning Research, 5, 325360.
Maravall, D., & de Lope, J. (2002). A reinforcement learning method for dynamic obstacle
avoidance in robotic mechanisms. In Computational Intelligent Systems for Applied
Research: Proceedings of the 5th International FLINS Conference, pp. 485494, Singapore. World Scientific.
Mariano, C., & Morales, E. (1999). MOAQ an Ant-Q algorithm for multiple objective
optimization problems. In GECCO-99: Proceedings of the Genetic and Evolutionary
Computation Conference, pp. 894901.
Mariano, C., & Morales, E. (2000a). A new approach for the solution of multiple objective
optimization problems based on reinforcement learning. In Advances in Artificial
Intelligence, International Joint Conference, 7th Ibero-American Conference on AI,
15th Brazilian Symposium. Springer.
Mariano, C., & Morales, E. (2000b). A new distributed reinforcement learning algorithm for
multiple objective optimisation problems. In Lecture Notes in AI Vol 1952: Proceedings of the Mexican International Conference on Artficial Intelligence, pp. 212223.
Springer.
Meisner, E. M. (2009). Learning Controllers for Human-Robot Interaction. Ph.D. thesis,
Rensselaer Polytechnic Institute.
109

fiRoijers, Vamplew, Whiteson & Dazeley

Mouaddib, A.-I. (2006). Collective multi-objective planning. In Proceedings of the IEEE
Workshop on Distributed Intelligent Systems: Collective Intelligence and Its Applications (DIS06), pp. 4348, Washington, DC, USA. IEEE Computer Society.
Mukai, Y., Kuroe, Y., & Iima, H. (2012). Multi-objective reinforcement learning method
for acquiring all Pareto optimal policies simultaneously. In IEEE International Conference on Systems, Man and Cybernetics, pp. 19171923.
Natarajan, S., & Tadepalli, P. (2005). Dynamic preferences in multi-criteria reinforcement
learning. In International Conference on Machine Learning, pp. 601608.
Nojima, Y., Kojima, F., & Kubota, N. (2003). Local episode-based learning of multiobjective behavior coordination for a mobile robot in dynamic environments. In The
12th IEEE International Conference on Fuzzy Systems, Vol. 1, pp. 307312.
Ogryczak, W., Perny, P., & Weng, P. (2011). On minimizing ordered weighted regrets
in multiobjective Markov decision processes. In 2nd International Conference on
Algorithmic Decision Theory, pp. 190204.
Ong, S. C., Png, S. W., Hsu, D., & Lee, W. S. (2010). Planning under uncertainty for robotic
tasks with mixed observability. The International Journal of Robotics Research, 29 (8),
10531068.
Pareto, V. (1896). Manuel dEconomie Politique. Giard, Paris.
Peek, N. B. (1999). Explicit temporal models for decisiontheoretic planning of clinical
management. Artificial Intelligence in Medicine, 15 (2), 135154.
Perez, J., Germain-Renaud, C., Kegl, B., & Loomis, C. (2009). Responsive elastic computing. In International Conference on Autonomic Computing, pp. 5564.
Perny, P., & Weng, P. (2010). On finding compromise solutions in multiobjective Markov
decision processes. In ECAI Multidisciplinary Workshop on Advances in Preference
Handling, pp. 5560.
Perny, P., Weng, P., Goldsmith, J., & Hanna, J. P. (2013). Approximation of lorenz-optimal
solutions in multiobjective markov decision processes. In Workshops at the TwentySeventh AAAI Conference on Artificial Intelligence.
Pervez, A., & Ryu, J. (2008). Safe physical human robot interaction-past, present and
future. Journal of Mechanical Science and Technology, 22 (3), 469483.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations for large
POMDPs. Journal of Artificial Intelligence Research, 27 (1), 335380.
Precup, D., Sutton, R. S., & Dasgupta, S. (2001). Off-policy temporal-difference learning
with function approximation. In Proceedings of the 18th International Conference on
Machine Learning, pp. 417424.
Puterman, M. L. (1994). Markov decision processes: Discrete stochastic dynamic programming. John Wiley & Sons, Inc.
Roijers, D. M., Whiteson, S., & Oliehoek, F. A. (2013). Computing convex coverage sets
for multi-objective coordination graphs. In ADT 2013: Proceedings of the Third International Conference on Algorithmic Decision Theory. To appear.
110

fiA Survey of Multi-Objective Sequential Decision-Making

Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms for
POMDPs. Journal of Artificial Intelligence Research, 32, 663704.
Russell, S., & Zimdars, A. L. (2003). Q-decomposition for reinforcement learning agents. In
Proceedings of the 20th International Conference on Machine Learning, pp. 656663.
Schneider, J., Wong, W.-K., Moore, A., & Riedmiller, M. (1999). Distributed value functions. In Proceedings of the 16th International Conference on Machine Learning, pp.
371378, San Francisco, CA. Morgan Kaufmann.
Shabani, N. (2009). Incorporating flood control rule curves of the Columbia River hydroelectric system in a multireservoir reinforcement learning optimization model. Masters
thesis, University of British Columbia.
Shelton, C. R. (2001). Importance sampling for reinforcement learning with multiple objectives. AI Technical Report 2001-003, MIT.
Shortreed, S., Laber, E., Lizotte, D., Stroup, T., Pineau, J., & Murphy, S. (2011). Informing
sequential clinical decision-making through reinforcement learning: an empirical study.
Machine Learning, 84, 109136.
Smallwood, R., & Sondik, E. (1973). The optimal control of partially observable Markov
processes over a finite horizon. Operations Research, 21 (5), 10711088.
Soh, H., & Demiris, Y. (2011). Evolving policies for multi-reward partially observable
Markov decision processes (MR-POMDPs). In GECCO11 Proceedings of the 13th
Annual Conference on Genetic and Evolutionary Computation, pp. 713720.
Sondik, E. (1971). The optimal control of partially observable processes over a finite horizon.
Ph.D. thesis, Stanford University, Stanford, California.
Sondik, E. (1978). The optimal control of partially observable Markov processes over the
infinite horizon: Discounted costs. Operations Research, 26 (2), 282304.
Spaan, M., & Vlassis, N. (2005). Perseus: Randomized point-based value iteration for
POMDPs. Journal of Artificial Intelligence Research, 24 (1), 195220.
Stewart, T. J. (1992). A critical survey on the status of multiple criteria decision making
theory and practice. Omega, 20 (5), 569586.
Sutton, R. S. (1988). Learning to predict by the methods of temporal differences. Machine
Learning, 3 (1), 944.
Sutton, R. S., & Barto, A. G. (1998). Introduction to Reinforcement Learning (1st edition).
MIT Press, Cambridge, MA, USA.
Sutton, R., McAllester, D., Singh, S., & Mansour, Y. (2000). Policy gradient methods for
reinforcement learning with function approximation. In NIPS, pp. 10571063.
Szita, I. (2012). Reinforcement learning in games. In Wiering, M., & Otterlo, M. (Eds.),
Reinforcement Learning, Vol. 12 of Adaptation, Learning, and Optimization, pp. 539
577. Springer Berlin Heidelberg.
Tan, K. C., Khor, E. F., Lee, T. H., & Sathikannan, R. (2003). An evolutionary algorithm
with advanced goal and priority specification for multi-objective optimization. Journal
of Artificial Intelligence Research, 18, 183215.
111

fiRoijers, Vamplew, Whiteson & Dazeley

Teichteil-Konigsbuch, F. (2012a). Path-constrained markov decision processes: bridging the
gap. In Proceedings of the Twentieth European Conference on Artificial Intelligence.
Teichteil-Konigsbuch, F. (2012b). Stochastic safest and shortest path problems. In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence.
Tesauro, G., Das, R., Chan, H., Kephart, J. O., Lefurgy, C., Levine, D. W., & Rawson, F.
(2007). Managing power consumption and performance of computing systems using
reinforcement learning. In Neural Information Processing Systems.
Tong, H., & Brown, T. X. (2002). Reinforcement learning for call admission control and
routing under quality of service constraints in multimedia networks. Machine Learning, 49, 111139.
Uchibe, E., & Doya, K. (2009). Constrained Reinforcement Learning from Intrinsic and
Extrinsic Rewards, pp. 155166. Theory and Novel Applications of Machine Learning.
I-Tech, Vienna, Austria.
Vamplew, P., Dazeley, R., Barker, E., & Kelarev, A. (2009). Constructing stochastic mixture
policies for episodic multiobjective reinforcement learning tasks. In AI09: The 22nd
Australasian Conference on Artificial Intelligence, pp. 340349.
Vamplew, P., Dazeley, R., Berry, A., Dekker, E., & Issabekov, R. (2011). Empirical evaluation methods for multiobjective reinforcement learning algorithms. Machine Learning,
84 (1-2), 5180.
Vamplew, P., Yearwood, J., Dazeley, R., & Berry, A. (2008). On the limitations of scalarisation for multi-objective reinforcement learning of Pareto fronts. In AI08: The 21st
Australasian Joint Conference on Artificial Intelligence, pp. 372378. Springer.
Van Otterlo, M., & Wiering, M. (2012). Reinforcement learning and markov decision processes. In Reinforcement Learning: State of the Art, chap. 1, pp. 342. Springer.
Van Vaerenbergh, K., Rodriguez, A., Gagliolo, M., Vrancx, P., Nowe, A., Stoev, J.,
Goossens, S., Pinte, G., & Symens, W. (2012). Improving wet clutch engagement
with reinforcement learning. In International Joint Conference on Neural Networks,
IJCNN 2012.
Vira, C., & Haimes, Y. Y. (1983). Multiobjective decision making: theory and methodology.
No. 8. North-Holland.
Viswanathan, B., Aggarwal, V. V., & Nair, K. P. K. (1977). Multiple criteria Markov
decision processes. TIMS Studies Management Science, 6, 263272.
Wakuta, K., & Togawa, K. (1998). Solution procedures for Markov decision processes. Optimization: A Journal of Mathematical Programming and Operations Research, 43 (1),
2946.
Wakuta, K. (1999). A note on the structure of value spaces in vector-valued Markov decision
processes.. Mathematical Methods of Operations Research, 49 (1), 7785.
Wang, W., & Sebag, M. (2013). Hypervolume indicator and dominance reward based multiobjective monte-carlo tree search. Machine Learning, 127.
Watkins, C. J. C. H. (1989). Learning from Delayed Rewards. Ph.D. thesis, Cambridge
University.
112

fiA Survey of Multi-Objective Sequential Decision-Making

White, C. C., & Kim, K. M. (1980). Solution procedures for solving vector criterion Markov
decision processes. Large Scale Systems, 1, 129140.
White, D. (1982). Multi-objective infinite-horizon discounted Markov decision processes.
Journal of Mathematical Analysis and Applications, 89 (2), 639  647.
Whiteson, S. (2012). Evolutionary computation for reinforcement learning. In Wiering,
M. A., & van Otterlo, M. (Eds.), Reinforcement Learning: State of the Art, chap. 10,
pp. 325352. Springer, Berlin.
Wiering, M., & De Jong, E. (2007). Computing optimal stationary policies for multiobjective Markov decision processes. In IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning, pp. 158165. IEEE.
Yang, Z., & Wen, K. (2010). Multi-objective optimization of freeway traffic flow via a
fuzzy reinforcement learning method. In 3rd International Conference on Advanced
Computer Theory and Engineering, Vol. 5, pp. 530534.
Yin, S., Duan, H., Li, Z., & Zhang, Y. (2010). Multi-objective reinforcement learning for
traffic signal coordinate control. In 1th World Conference on Transport Research.
Zeleny, M., & Cochrane, J. L. (1982). Multiple criteria decision making, Vol. 25. McGrawHill New York.
Zhao, Y., Chen, Q., & Hu, W. (2010). Multi-objective reinforcement learning algorithm for
MOSDMP in unknown environment. In Proceedings of the 8th World Congress on
Intelligent Control and Automation, pp. 31903194.
Zheng, K., Li, H., Qiu, R. C., & Gong, S. (2012). Multi-objective reinforcement learning
based routing in cognitive radio networks: Walking in a random maze. In International
Conference on Computing, Networking and Communications, pp. 359363.
Zitzler, E., Thiele, L., Laumanns, M., Fonseca, C. M., & da Fonseca, V. G. (2003). Performance assessment of multiobjective optimizers: An analysis and review. Evolutionary
Computation, IEEE Transactions on, 7 (2), 117132.

113

fiJournal of Artificial Intelligence Research 48 (2013) 231  252

Submitted 4/2013; published 10/2013

Optimal Implementation of Watched Literals
and More General Techniques
Ian P. Gent

ian.gent@st-andrews.ac.uk

School of Computer Science, St Andrews University
St Andrews, Fife KY16 9SX, UK

Abstract
I prove that an implementation technique for scanning lists in backtracking search
algorithms is optimal. The result applies to a simple general framework, which I present:
applications include watched literal unit propagation in SAT and a number of examples
in constraint satisfaction. Techniques like watched literals are known to be highly space
efficient and effective in practice. When implemented in the circular approach described
here, these techniques also have optimal run time per branch in big-O terms when amortized
across a search tree. This also applies when multiple list elements must be found. The
constant factor overhead of the worst case is only 2. Replacing the existing non-optimal
implementation of unit propagation in MiniSat speeds up propagation by 29%, though this
is not enough to improve overall run time significantly.

1. Introduction
In many backtrack search procedures, a given list must contain an element satisfying some
property. I call this an acceptable element. If no acceptable element exists in the list,
some relevant action is triggered, such as assigning a unit clause in SAT (Boolean Satisfiability). This paper considers only monotonic acceptability properties: i.e. if an element is
unacceptable at a node in the search tree, it remains unacceptable at all descendant nodes.
This description is general, but applies to vital components in modern search techniques.
As well as unit propagation in SAT, a typical application in CSP (Constraint Satisfaction
Problem) is support for a variable-value pair in a general purpose arc consistency algorithm,
e.g. MGAC2001/3.1 (Bessiere, Regin, Yap, & Zhang, 2005). Once no acceptable element
(support) is available, the triggered action is that the variable-value pair must be pruned.
A common technique for maintaining acceptability is to keep a pointer to a known
acceptable element. If this element becomes unacceptable during the search process, we
scan the list for a new acceptable element. If we find one we change the pointer. If not, we
can trigger the necessary action. After backtracking, we must guarantee that the pointer
points to an acceptable element. There are several methods for achieving this. One is
to reset the pointer before each list scan. A second is to store the current value of the
pointer and to restore this value on backtracking. This paper focuses on a third method,
the backtrack-stable approach, as used in watched literals in SAT.
The backtrack-stable approach is very simple: no changes are made to the pointer except
when we are scanning the list for a new acceptable element. Watched literals in SAT, the
classic example of this approach, have proven to be highly effective in practice (Moskewicz,
Madigan, Zhao, Zhang, & Malik, 2001). Its correctness depends on acceptability being
monotonic. If we move the pointer to a new acceptable element at a particular node, the
c
2013
AI Access Foundation. All rights reserved.

fiGent

new element must be acceptable at all ancestor nodes. When we backtrack we thus still
have an acceptable element, even if it is different to the one we entered the node with.
Unfortunately, down any branch (i.e. sequence of nodes from root to leaf node), we can no
longer guarantee that a single pass of the list is enough. At a given node the pointer may
move due to moves at children nodes, meaning we may have missed elements. Indeed, on a
single branch we may need to check every value of the list many times.
This paper shows that a simple, circular, implementation of the backtrack-stable approach is optimal in big-O terms when amortised across all branches of a tree, a significantly
better theoretical property than has previously been suggested. The amortisation applies to
any search tree explored in a depth-first style, independent of the size of the search tree. The
constant increase in worst case complexity is only 2. Applicability to existing code depends
on low-level implementation details. I discuss some such cases in detail. In some cases existing implementations are shown to be optimal, while in others an optimal implementation of
watched literals was not used. For example I show empirically that implementing watched
literals optimally speeds up unit propagation in MiniSat by 29%, although the effect does
not lead to a statistically significant improvement in overall MiniSat solution time.
Section 2 describes a simple framework for scanning lists in backtracking search and
gives pseudocode for the three methods compared in this paper, and gives a worked example to motivate the proof that the circular approach is optimal. Section 3 gives that proof
and related results, including detailed comparisons with the state restoration method. Section 4 generalises the result to multiple acceptable elements. Later sections discuss applications to constraint satisfaction, and to watched literal unit propagation in SAT, including
experiments on MiniSat. Appendices gives proofs omitted from the main text, detailed
methodology of the SAT experiments, results on another method of list scanning, and a
summary of the Online Appendix for this paper.

2. Simple Framework for List Scanning Algorithms
We have a list list of length N .1 We assume there is a boolean function acceptable(list,i)
to check list elements, returning true if list[i] is acceptable and false if not. Throughout
this paper, this function is required to be monotonic, in the following sense.
Definition 1 (Monotonicity of Acceptability). Acceptability is monotonic if, whenever
acceptable(list,i) fails at a node, then acceptable(list,i) would also fail if called for
the remainder of the search process at that node and at all its descendant nodes.
Note that this definition allows elements in list to be moved, as long as unacceptability at each index is maintained: this flexibility will be important in Section 4. When
unacceptability is detected we must find a new acceptable element, or guarantee that none
exists. This is achieved by one of three variants of a function findNewElement (sometimes abbreviated to FNE). Each variant updates the value of a pointer last, and either
succeeds with an acceptable value of list[last], or fails with a guarantee that no acceptable value in list exists. The execution environment is assumed to guarantee that, at any
1. In this paper I assume a computational model in which the word size is at least log N bits, and that
standard operations on words take O(1) time. This is not ideal from a complexity-theoretic point of
view, but is a standard assumption in the literature, although unfortunately not usually clearly stated.

232

fiOptimal Implementation of Watched Literals

node of the search tree, if list[last] changes from being acceptable to unacceptable, then
findNewElement(list) will be called before the next node is visited, except when backtracking occurs from this node before any descendant node is visited. For the purposes of
this paper, detection of unacceptability is not counted as a call to acceptable: whatever
cost this detection has is the same for each approach studied here. We assume an initialisation phase in which O(N ) calls to acceptable are made to find the initial value of last:
these calls are considered as preprocessing and not charged to any node in the search tree.
We also assume that calls to findNewElement are only made during initialisation and
after unacceptability has been detected.
Each variant of findNewElement has to ensure the following invariant is maintained.
Note that this invariant means when one of the first two cases holds, the value list[last] is
unacceptable iff there is no acceptable element in the list.
Invariant 2. At all times at least one of the following is true:
 the value list[last] is acceptable; or
 there is no acceptable element in list; or
 the initialisation process has not completed; or
 the value list[last] has become unacceptable at the current node but findNewElement has not yet been called and completed.
Many calls to findNewElement may happen at a single node, because facts about
acceptability may not become known at the same time. For example, in the case of unit
propagations in SAT, the current watched literal (i.e. list[last]) may become unsatisfiable
(unacceptable), so we have to scan for a new watched literal (value of last). But later
propagations at the same node can make this new value unsatisfiable, leading to new scans.
This paper compares three implementations of findNewElement and shows the good
properties of the last one. The differences arise from how last is dealt with in between
invocations of findNewElement. The simplest variant is shown in Procedure 1: each
time it is called the previous value of last is discarded and the list searched from the
beginning.
Procedure 1: FNE-NoState(list)
1: last := -1
2: repeat
3:
last := last + 1
4:
if acceptable(list,last) then return true
5: until last = N
6: return false
Procedure 1 is simple, certainly maintains Invariant 2, and is highly space-efficient. It
has a significant disadvantage in that its worst case is to require (N 2 ) calls to acceptable
at every leaf node, stated here as Proposition 3 and proved in Appendix E. (Appendix E is
omitted from the main text but is available online, see Appendix D.)
233

fiGent

Proposition 3. The procedure FNE-NoState maintains Invariant 2. It makes O(N 2 )
calls to acceptable per branch of a search tree, but requires (N 2 ) in the worst case.
(Proof in Appendix E online.)
The remaining two variants both use FNE-NoState to initialise last, but make different
calls thereafter. The second variant is based on state restoration. Each call continues search
from the most recent value of last found at the current node or any of its ancestors. Since
the value of last may be changed by descendent nodes, some mechanism of the backtracking
search solver must be exploited to restore the value of last when backtracking occurs. What
this method is will vary between solvers, and is not critical for this paper. Given this, this
method is shown as Procedure 2.
Procedure 2: FNE-RestoreState(list)
1: repeat
2:
last := last + 1
3:
if acceptable(list,last) then return true
4: until last = N
5: return false
Since acceptability is monotonic and last is always restored to the value it had previously,
the invariant is guaranteed. We have the following, for which no proof should be necessary.
Proposition 4. The procedure FNE-RestoreState maintains Invariant 2. On any given
branch of the search tree from root to leaf node, at most N calls to acceptable are made.
In the final, backtrack-stable, variant, we do not restore former values of last on
backtracking. We now have the problem that down a branch, or even at a single node, the
value of last can be moved by later nodes and not restored when we return to the current
node. To deal with this correctly, we have to allow every element of list to be checked
even if some may have already been checked higher on the current branch or even at the
same node. The focus of this paper is the circular method for checking all elements: at
the end of the list we circle around from the end of the list to zero, and continue checking
until we hit the value that last had when the call was made. For initialisation we call the
above procedure FNE-NoState. All subsequent calls are to the following.
Procedure 3: FNE-Circular(list)
1: last-cache := last
2: repeat
3:
last := last + 1
4:
if last = N then last := 0
5:
if acceptable(list,last) then return true
6: until last = last-cache
7: return false
No claim is made for originality of the circular method: it was used by Gent, Jefferson,
and Miguel (2006b) and probably by earlier authors. Unlike the previous variants, the
invariant does not hold for all search algorithms. Correctness will be proved in Section 3
below, in the context of downwards-explored search trees, as defined in Definition 5.
234

fiOptimal Implementation of Watched Literals

.
One difference between Procedures 2 and 3 should be noted. At a given node of the
search tree, Procedure 2 can make at most N calls to acceptable. However, Procedure
3 can, perhaps counterintuitively, require almost 2N calls at a single node. For example,
suppose at a given node we have last = 0. If this value becomes unacceptable and the only
other acceptable value is N  1, this requires N  1 calls to set last = N  1. Further
propagation may later make N  1 unacceptable also. The resulting new call to Procedure
3 cannot find an acceptable value, but must still check all values from 0 to N 2 as it has no
memory of the previous call. (The variable last-cache is local to each call of the Procedure.)
This is a further N  1 calls to acceptable, for a total of 2N  2 at the node.
2.1 Worked Example
I present a worked example of Procedure 3, showing how we can amortize the count of calls
to acceptable in a way which will form the basis of the optimality results of this paper.
Figure 1 shows an example search using the circular approach. In the example we assume
node id = 0 :last=14, cost = 14X
last=17

8 :14, 17X

1 :14, 0
last=19

2 :17, 3X

last=16

5 :17, 18X

9 :16, 21X

12 :14, 18X

last=18

3 :17, 19

P

= 36

0,1,2,3

4 :19, 2X

P
0,1,2,4

= 19

6 :18, 20X

P
0,1,5,6

= 52

last=15

7 :17, 19X

P
0,1,5,7

10 :16, 0

P

= 51

0,8,9,10

= 52

11 :16, 0

P
0,8,9,11

= 52

13 :15, 1X

P
0,8,12,13

= 50

14 :14, 38X

P

= 87

0,8,12,14

Figure 1: A search using the circular approach. See main text for description.
that the list being searched has 20 elements, indexed from 0 to 19. and that initialisation
sets last = 0. The box at a node indicates the node number (italics), the value of last
after any calls to FNE-Circular (bold), and the cost of those calls in total at the node
(measured as number of calls to acceptable), including a failed call if there is one. A X
indicates a successful call was made, while a  indicates an unsuccessful call. Both can occur
at the same node, if the value of last is moved by a successful call, while that value later
becomes unacceptable, and another call to FNE-Circular fails. A branch is annotated
with a value of last if the search to the left changed the value of last. For example, at node
5 the value of last was 17, but the left child set it to 18, meaning that it had changed when
we branched right. The total cost for each branch is listed, e.g. 87 for the last branch.
In the example, the first 14 elements become unacceptable at the root, so calls to FNE
must check 14 elements in order to set last = 14. If we restored last the maximum cost
235

fiGent

down any branch would be the number of elements in the list, in this case 20. If we used
FNE-Circular, but searched only one branch, the maximum cost would be almost double,
38. This could happen if we eventually settle on last = 19, this becomes unacceptable and
we do a failed call which costs 19. By contrast, the extreme right hand branch costs
14 + 17 + 18 + 38 = 87, more than twice the maximum if search took only a single branch.
Summing the number of checks in FNE on each branch, we get 36 + 19 + 52 + 51 + 52 +
52 + 50 + 87 = 399, almost 50 times the number of branches, 8. However, this counts
many costs twice. By summing at each node, the total number of checks across the tree is
14 + 0 + 3 + 19 + 2 + 18 + 20 + 19 + 17 + 21 + 0 + 0 + 18 + 1 + 38 = 190. This is more than 20
times the number of branches, but less than 40 times the number of branches. I will show
that the latter bound is always true: we can never look at more list elements than 2kN , if
N is the number of list elements and k is the number of branches.
A left branch segment (LBS) is a segment of a branch with all left branching decisions
ending at a leaf node. In this paper, the left child of a given internal node is taken to mean
whichever child node is explored first.2 Figure 2 shows the same search tree as Figure 1,
but showing the LBSs and the cost across each LBS. Crucial points to note are: each
left branch segment contains consecutively numbered nodes; the cost of each left branch
segment is never more than 38 = 2N  2; and the total cost summed over left branch
segments (36 + 2 + 38 + 19 + 38 + 0 + 19 + 38 = 190) is identical to the total cost across the
tree as calculated earlier. All of these observations about the tree are provable in general.

3. Formal Results
While the worked example showed binary branching, this is not necessary. After the left
hand child of a node there may be any number of later nodes (including zero at a unary
node.) A leaf node is simply a node with no children. I will prove correctness and optimality
of FNE-Circular when search algorithms build trees of the following type:
Definition 5 (Downwards-Explored Search Tree). A search tree is Downwards-Explored
if: for any node n0 in the tree, all nodes descending from n0 are visited later than n0 , and
for any node n1 not descended from n0 and visited later than n0 , all nodes in the tree that
descend from n0 are visited after n0 but before n1 .
Depth-first search certainly defines a downwards-explored tree, but so do many variants
such as conflict-directed backjumping (Prosser, 1993). A less obvious case is a single restart
of a modern Conflict-Driven Clause Learning (CDCL) SAT solver (Marques-Silva, Lynce, &
Malik, 2009). When backtracking, search returns to the level of the tree chosen by conflictanalysis, and it is guaranteed that all intermediate parts of the search tree are unsatisfiable,
and will never be visited again, resulting in a downwards-explored search tree. CDCL solvers
undertake restarts, as do other major algorithms such as Iterative Deepening (Korf, 1985)
and Limited Discrepancy Search (Harvey & Ginsberg, 1995; Prosser & Unsworth, 2011). In
all three of these examples each iteration considered separately gives a downward-explored
tree. The results of the current paper therefore apply to a single iteration or restart of each
algorithm. They will also apply to multiple restarts or iterations if one counts separately
2. An algorithm may regard its first branching choice as the right branch, e.g. limited discrepancy search
going against its heuristic, but for this paper the left child is defined as whichever one is explored first.

236

fiOptimal Implementation of Watched Literals

node id = 0 : last=14, cost = 14X
last=17

8 :14, 17X

1 :14, 0
last=19

2 :17, 3X

last=16

5 :17, 18X

9 :16, 21X

12 :14, 18X

last=18

3 :17, 19

P
0,1,2,3

= 36

4 :19, 2X

P
4

=2

6 :18, 20X

P
5,6

= 38

last=15

7 :17, 19X

P
7

= 19

10 :16, 0

11 :16, 0

P

P

8,9,10

= 38

11

=0

13 :15, 1X

P
12,13

= 19

14 :14, 38X

P

= 38

14

Figure 2: The example from Figure 1 with additional annotations. A double line indicates
a left hand branch, while a wavy line the right hand branch. A sequence of double
lines indicates a left branch segment. A solid box around a node indicates the
start of a left branch segment. Finally, the sums of costs are made only over the
left branch segment ending at each leaf node.

for each iteration, i.e. counting a branch twice even if it is a duplicate of a branch from
a previous iteration. Some major algorithms do not explore downwards: e.g. breadth-first
or best-first search. In such algorithms, at consecutive nodes last, which is not contained
in the search state, moves from pointing to an acceptable to an unacceptable value. The
results of this paper therefore do not apply in any way to such algorithms.
The first result is correctness of the FNE-circular method, slightly generalised so
that it will also apply to the middle-out Procedure 5 in Appendix B.
Definition 6 (Locally Correct). A findNewElement procedure is locally correct iff:
1. if any element of list is acceptable then the procedure sets last to point at an acceptable
value and succeeds;
2. if no element of list is acceptable then the procedure fails and exits with last set to
the same value it had on entry.
Specifically, FNE-Circular is locally correct by design, and therefore its global correctness is a corollary of the following theorem.
Theorem 7. (Correctness) If the search algorithm defines a downwards-explored search
tree, and if procedure findNewElement is locally correct, Invariant 2 is true at all times.
(Proof in Appendix E online.)
Definition 8 (LBS). The left branch segment ending at a leaf node n LBS(n) is defined
recursively as follows:
237

fiGent

 n  LBS(n)
 if m1  LBS(n) and m1 is the left hand child of a parent node m2 , then m2  LBS(n).
For convenience, if a parent node has only one child we call this the left hand child.
 LBS(n) is the minimal set of nodes satisfying the above properties.
Note that for a leaf node m which is not the left hand child of its parent, the definitions
trivially give LBS(m) = {m}. Every internal node has exactly one left child, so we can
proceed as follows.
Lemma 9. Every node in the tree is contained in exactly one left branch segment. In
a downwards-explored search tree, nodes in a left branch segment are visited consecutively
without search visiting any other nodes. (Proof in Appendix E online.)
Theorem 10. In a downwards-explored search tree, there are no more than N  1 calls to
acceptable made by successful calls to FNE-Circular in a left branch segment.
Proof. The proof relies on the monotonicity of acceptability down the tree. Because all
nodes in an LBS are explored sequentially without interruption, from Lemma 9, all calls to
FNE-Circular and therefore changes to last, are consecutive. The definition of FNECircular means that to check more than N  1 elements on a single LBS, last must be
incremented at least N times, meaning that every value is checked at least once in the LBS,
including the original value last at entry to LBS. Call this value i. Say the root of the LBS is
m1 , and the element i is checked again at node m2 with either m1 = m2 or m1 an ancestor
of m2 . Between entry to m1 and the call to acceptable(list, i) at m2 , every list element
must have been checked. Furthermore, for each value j, either the check of j in FNECircular failed, or it succeeded and later on the value had become unacceptable causing
another call to FNE-Circular. If this was not the case then the value of last would not
have moved on from j. Therefore, for any j, the list element j cannot be acceptable when
the check of i was made at node m2 . Therefore, the call to FNE-Circular which makes
the second check of i must fail. As required, we have shown that if there are more than
N  1 calls to acceptable in an LBS, there is an unsuccessful call to FNE-Circular.
Corollary 11. In a downwards-explored search tree, calls to FNE-Circular in an LBS
make no more than 2N  2 calls to acceptable.
Proof. By Theorem 10, the maximum number of list elements checked in successful calls
in any LBS is N  1. The first unsuccessful call to FNE-Circular will check N  1: all
elements of the list except list[last]. No more calls are necessary in the LBS, since no
element can become acceptable again. So the total cost is bounded above by 2N  2.
Theorem 12. For a downwards-explored search tree containing k branches, calls to FNECircular make at most k(2N  2) calls to acceptable.
Proof. Any call to FNE-Circular occurs at some node in the search tree. Each node in
the search tree is in exactly one LBS. Therefore every call to FNE-Circular occurs in
exactly one LBS. There are at most 2N  2 acceptability checks in each LBS. In a tree
with k branches there are exactly k LBSs, meaning that the total number of list elements
checked in the tree is bounded above by k(2N  2).
238

fiOptimal Implementation of Watched Literals

We therefore have optimality in the following sense:
Theorem 13. (Optimality) In any downwards-explored search tree, the circular approach
requires space for one last pointer and has a worst case of O(N ) calls to acceptable per
branch of the tree, and no algorithm can require o(N ) calls per branch. (Proof in Appendix E
online.)
While these results show that restoring state and circular are equivalent in worst case
time complexity in big-O terms across a tree, we can compare them more precisely.
Proposition 14. For circular, there can be as many as 2k(N  2) calls to acceptable in
a downwards-explored search tree. For state restoration, the number of calls to acceptable
is bounded above by kN and there can be k(N  1) calls to acceptable in a tree. (Proof
in Appendix E online.)
Thus we have that the worst case number of list element checks where we do not backtrack last is twice the worst case number of list checks where we do backtrack it. But this
does not apply on an instance by instance basis, as the following result shows.
Proposition 15. (Non Dominance) Both techniques can check less than the other across
a downwards-explored search tree. The circular method can take (k) times fewer calls to
acceptable across the tree than state restoration, while state restoration can need (N )
times fewer calls than circular. (Proof in Appendix E online.)
In the language of Likitvivatanavong, Zhang, Shannon, Bowen, and Freuder (2007), in
any LBS, circular can have no positive repeats (duplicate successful calls to acceptable).
It can have negative repeats (duplicate failed calls) only if the last call to FNE-Circular
fails, so there will be no failed call to FNE when there is an acceptable element at a leaf
node. This reduces significantly the chance of more than N calls in an LBS. For example,
in SAT, consider a clause with r literals. Under a random boolean assignment, there is a 21r
chance of no literals being valid under a full assignment, and 2rr of exactly one literal being
valid. With two or more valid literals, there can be no failed call. So the chance of a call to
FNE failing is no more than r+1
2r on any LBS. If clauses have 10 literals then under random
assignments there is a maximum of a just over 1% chance of negative repeats in each LBS.

4. Generalisation to Multiple Acceptable Elements
An important case is that we need to maintain multiple acceptable elements in a list.
Specifically, we must ensure that at least W different elements of list are acceptable, or
trigger some action if less than W are. The classic example is watched literals in SAT,
where W = 2 and the action is unit propagation, but examples arise in constraints with
higher W as discussed in Section 5. Not only can the circular approach be generalised, but
the bound on number of calls to acceptable per branch is independent of W .
The implementation technique is to maintain two lists. The first, called watched, is of
length W  1, and the second list, unwatched, is of length N . The union of these two lists
is the original list list of length N + W  1. Initialisation is assumed to either make all
elements in watched plus unwatched[last] acceptable, or (if that is not possible) to trigger
the necessary action. The solver infrastructure is assumed to ensure correct notification of
239

fiGent

findNewElement: we must maintain the position of each element in watched, but this
can be done in O(1) time per move of an element using O(N + W ) space. We now assume
that if any element in watched changes from being acceptable to unacceptable, or the single
value unwatched[last] does, then FNE-Circular-W will be called with the appropriate
parameters before the next node is visited, unless backtracking occurs before then. We also
assume that if more than one such event happens at a node, a separate call happens for
each event. Given these assumptions, implementation is almost trivial, as follows.
FNE-Circular-W(list,elt,i)
1:
// elt is the value in list which is newly unacceptable
2:
// i is the index of elt in watched unless elt = unwatched[last ]
3: if elt 6= watched[i] then
4:
watched[i] := unwatched[last]
5:
unwatched[last] := elt
6: return FNE-Circular(unwatched)
Everything that follows depends on the fact that, despite swapping elements, acceptability is monotonic in the list unwatched.
Procedure 4:

Proposition 16. Acceptability in unwatched is monotonic if acceptability in list is.
Proof. Because acceptability in list is monotonic, the only way nonmonotonicity could
occur is when an element of unwatched is replaced with one from watched. This can
only happen in FNE-Circular-W at Line 5. But the value unwatched[last] is replaced
by elt, and elt becoming unacceptable is the reason that FNE-Circular-W was called.
Therefore, a call to acceptable(list,last) must return false, whether or not it would have
succeeded before the replacement. By Definition 1, monotonicity is therefore respected.
Proposition 16 and Corollary 11 make the following immediate. It is remarkable that
the bound in Corollary 17 is independent of W , the number of acceptable elements required.
Initialisation does need O(N + W ) calls to acceptable, but this is done only once.
Corollary 17. In a downwards-explored search tree, calls to FNE-Circular-W in an
LBS make no more than 2N  2 calls to acceptable.
We must also show correctness, and this is done with a revised invariant. If the first
clause holds, we have the W required acceptable elements, while if the second does, there
can be no more than W  1 acceptable elements so we can trigger the necessary action.
Invariant 18. At all times at least one of the following is true:
 all elements in watched  {unwatched[last]} are acceptable; or
 there is no acceptable element in unwatched; or
 the initialisation process has not completed; or
 at the current node, at least one element in watched{unwatched[last]} has become
unacceptable but the corresponding call to findNewElement has not yet completed.

240

fiOptimal Implementation of Watched Literals

Lemma 19. In a downwards-explored search tree, each call to FNE-Circular-W either
returns false or reduces by one the number of unacceptable elements in the set watched 
{unwatched[last]}. (Proof in Appendix E online.)
Theorem 20. (Correctness) In a downwards-explored search tree, FNE-Circular-W
maintains Invariant 18. (Proof in Appendix E online.)
Chai and Kuehlmann (2003) described multiple watches for a pseudo-boolean solver,
although the current results do not apply because the number of watches varied during
search. Chai and Kuehlmann did not give implementation details: the implementation
described here follows Gent et al. (2006b) for a sum of boolean variables.

5. Application to Constraint Satisfaction
The first application is in constraint propagation, specifically maintaining generalised arc
consistency. The optimal algorithm GAC2001/3.1 can easily be turned into the algorithm
MGAC2001/3.1 which maintains GAC during search (Bessiere et al., 2005).
Corollary 21. For a constraint of arity r where each variable is domain size d, in a
downwards-explored search tree the circular approach to maintaining the last pointer in
MGAC2001/3.1 can be achieved using space to store O(dr) last pointers (beyond the storage
space for the constraint itself ), and requires time to check O(rdr ) tuples per branch. (Proof
in Appendix E online.)
A reasonable assumption is that it takes time O(r) to check a tuple since it is arity
r (Bessiere et al., 2005).3 On this basis we get time O(r2 dr ) per branch. Bessiere et al.
report the same time complexity O(r2 dr ) for GAC2001/3.1 and require the same number
of last pointers. This shows that the amortized worst case big-O time per branch for
MGAC2001/3.1 is the same as that needed simply for the one-off algorithm GAC2001/3.1,
and using the same space. Bessiere (2004) reports using state restoration techniques in
his implementation of MAC2001 (Bessiere & Regin, 2001). This therefore used additional
space, since many copies of last must be stored instead of just one.
My results improve on those given by van Dongen (2004). For binary constraints (r = 2),
he gives an upper bound for space complexity of O(d min (n, d)) per constraint for a time
optimal implementation using time O(d2 ) per branch, where d is domain size and n is the
number of variables in a problem. Corollary 21 gives the same O(d2 ) time and improved
O(d) space, although van Dongens results remain valid as they were given as upper bounds.
There are several studies of the time complexity of maintaining arc consistency down
a branch, but no suggestion that leaving last pointers alone can be so good theoretically.
Some existing circular implementations can now be seen to be optimal. For example, Gent
et al. (2006b, p. 185) wrote: There is one general disadvantage that should be mentioned
with watched triggers, . . . it is often not possible to use a propagation algorithm which is
optimal in the worst case in terms of propagation work performed down a single branch. An
3. If constraints are stored extensionally, then this will be true, and space requirement to store the constraint
will be O(rdr ). However constraints may also be stored intensionally or procedurally, in which case
checking time can be either larger or smaller, and space requirement can be arbitrarily small.

241

fiGent

example is our variant of GAC-2001/3.1 below. In fact, this implementation of MGAC2001/3.1 was time optimal amortized across branches and had better space complexity than
van Dongen (2004) reports for optimal implementations of MAC-2001/3.1.
Regin (2005) studied maintaining arc consistency during search without backtracking
the last pointer. He writes: If the last values are not restored after backtracking then
the time complexity of AC-6 and AC-7 algorithms is in O(d3 ) (Regin, 2005, p. 528), and
he gives an example similar to the right hand branch of Figure 1. In this context d is
domain size and constraints are binary so the maximum length of list N = d2 . Regin is
entirely correct. My contribution is to show that the lack of optimality down a branch is
compensated by amortization by a factor of d. Regin writes also: Currently [i.e. before
his paper], there is no MAC version of these algorithms capable to keep the optimal time
complexity on every branch of the tree search (O(d2 ) per constraint, where d is the size of
the largest domain), without sacrificing the space complexity. His method can recompute
a correct value of last on backtracking without storing it, by comparing the current value of
last with values restored to domain on backtracking. This is elegant but does not generalise
in an obvious way to non-binary constraints as the number of combinations of restored
values can be exponential.
Likitvivatanavong et al. (2007) discuss the cost of Arc Consistency during search. They
give ACS-resOpt, which uses an instance of the list scanning framework given here, and
report that while it is optimal at a given node, it is not optimal down the branch of a
tree (which they call path-forward complexity). By reordering domains during search,
Adaptive Domain Ordering (ADO) enforces MAC for binary constraints with the optimal
property of O(ed2 ) worst-case time complexity on any branch of the search tree (Likitvivatanavong, Zhang, Bowen, & Freuder, 2005). Unfortunately it did not perform well in
empirical tests (Likitvivatanavong et al., 2007), and combined with its reordering of domains during search, this militates against widespread adoption in constraint solvers.
There are other applications in constraints. Nightingale, Gent, Jefferson, and Miguel
(2013) use the circular technique to avoid restoring state in GAC algorithms exploiting
short supports. Jefferson, Moore, Nightingale, and Petrie (2010) use it for a propagator for
a generalised or constraint. Gent et al. (2006b) used the circular approach for propagating
the element constraint. They also used the generalisation to W literals for a sum of booleans
constraint. All these examples can be seen in the code for the Minion constraint solver
(Gent, Jefferson, & Miguel, 2006a), version 0.15, as can some not described in papers such
as the constraint litsumgeq. All are now seen to have excellent theoretical properties.

6. Application to Satisfiability
The second application is watched literal unit propagation in SAT (Moskewicz et al., 2001).
A clause is a list of literals. An acceptable element is one that represents either an unassigned
or a satisfied literal. In standard two-literal watching we must maintain two acceptable elements. Modern CDCL SAT solvers quickly learn large numbers of large clauses, and thus
benefit greatly from having to maintain only two pointers in a clause. The approach of Section 4 can be applied easily. However, this is not normally done in SAT solvers.4 Successful
solvers often implement the search for new watches in a non-optimal way. To see this, we
4. I am grateful to a reviewer of this paper for pointing this fact out to me.

242

fiOptimal Implementation of Watched Literals

must examine their code, because the necessary level of implementation detail is not given
in papers. For example MiniSat (Een & Sorensson, 2003) and tinisat (Huang, 2007) implement watched literals in the following non-optimal way. The core of the implementation is
shown as Procedure 5: a key change is that all watched elements are in the list watched
instead of all but one in Procedure 4. Some details of MiniSats implementation are not
in Procedure 5: the most important is the maintenance of blocked literals, which I will
discuss further below. Proposition 3 does not technically apply, but nevertheless I state
without proof that this approach leads to (N 2 ) calls to acceptable per branch in the
worst case.
FNE-NoState-W(list,elt,i)
// elt is the value in list which is newly unacceptable
// i is the index of elt in watched
result = FNE-NoState(unwatched)
if result then
watched[i] := unwatched[last]
unwatched[last] := elt
return result

Procedure 5:
1:
2:
3:
4:
5:
6:
7:

To compare practical performance, I adapted MiniSat version 2.2.0 with optimal unit
propagation using Procedure 4. I call this Circular MiniSat and the original Stock
MiniSat. Appendix A gives full methodology and more detailed results. The key results
are as follows. First, Circular unit propagates notably faster than Stock when features of
MiniSat not related to unit propagation were removed. For searching 594 instances up to
10 million conflicts, Circulars mean time was 141.6s, compared to a mean 182.6s for Stock,
so Stock takes 29.1% more time. Median performance is much closer, 73.1s for Circular
compared to 78.1s for Stock. The larger disparity in mean is because Stock is never more
than 15% faster, but Circular can be as much as 9.5 times faster than Stock. Second, when
all features of MiniSat were restored, the improved propagation speed of Circular did not
translate into improved performance. On 330 instances, there was no statistical support to
reject the null hypothesis that the two solvers have equivalent performance.
It is interesting to look at how many watched literal scans are blocked, a term used in
MiniSats code. A clause scan is blocked if the other watched literal (at the time this watch
was set up) is a valid literal now, so the clause is satisfied and no new watch is needed. This
saves accessing the memory relating to the clause. For each instance I measured the ratio
b/u between blocked and unblocked watched scans. A higher b/u is better since it results in
less watched scans. I computed the ratio  between the b/u values obtained for Circular and
Stock MiniSat,  = (bc /uc )/(bs /us ). Figure 3 shows  plotted against obtained speedup.
Behaviour is very different in two regions. For   1.2 (123 instances) the median speedup
is 1.48 and mean is 1.86. There is a high correlation between  and speedup, r2 = 0.88. For
 < 1.2 (471 instances) we get no correlation between  and speedup, r2 = 0.01. Compared
to Stock MiniSat the median speedup is 0.97 and mean of 0.98, i.e. slight slowdowns. This
analysis indicates that most of the speedup occurs in instances where Circular is much
better than Stock MiniSat at setting watches on literals which are likely to be valid later
in search and thus block watched literal scans. It would be interesting to investigate this
result theoretically, since it does not follow from the results of this paper. It may be related
243

fiGent

10
8
6
5
4
3
2

1
0.8
Circular:Stock
0.548x + 0.523

0.6
0.5
0.5 0.6

0.8

1

1.2

2

3

4

5

6

8

10

20

Figure 3: Scatterplot of  (x-axis) against speedup ratio in conflicts per second of Circular
over Stock MiniSat (y-axis). The vertical line shows  = 1.2. The line 0.548x +
0.523 is the best-fit line in the region   1.2.

to the fact that Circular sets watches to arbitrary literals in a clause, while Stock MiniSat
will tend to set watches to literals appearing early in a clause. Therefore if a good blocking
literal is late in a clause, Circular has more chance of watching it.
Head-tail lists were an important advance in implementation of unit propagation in
SAT (Zhang & Stickel, 2000). Pointers to the first unassigned literal in a clause (head) and
the last (tail) are maintained by state-restoration. Head-tail lists led to watched literals
(Moskewicz et al., 2001), in which there are two pointers to arbitrary (but different) unassigned literals. Watched literals (or variants thereof) have become the standard technique
for efficient implementation of unit propagation in SAT solvers. When implemented as described in this paper, the theoretical properties of watched literals are now seen to be very
nearly as good as head-tail lists in time, with much reduced space overheads.
A variant implementation of watched literals is in JQuest (Lynce & Marques-Silva,
2005). Scans go from last to the end of the list, but restart from last backwards to 0. This
middle-out search can be big-O optimal provided that the current direction of search is
persistent between calls. However, if the direction of search is always initially in one direction, it can require (N 2 ) checks per branch, and this is the case in JQuest. Full algorithmic
details and proofs of these statements are in Appendix B. Lynce and Marques-Silva (2005)
also introduced literal sifting to attempt to get the best of both worlds: literals in a clause
are reordered during search to avoid repeating checks and backtracking pointers. Lynce and
Marques-Silva report slightly better empirical performance with literal sifting (although as
just noted the comparison was with a non-optimal watched literal implementation). Generalising literal sifting to arbitrary number of acceptable elements and performing further
theoretical and experimental comparisons with the circular approach is open as future work.
244

fiOptimal Implementation of Watched Literals

Another application which is now seen to be optimal, if implemented in a circular style,
is Van Gelders (2002) three literal watching to detect binary clauses.

7. Conclusions
I have shown that the circular approach to scanning lists in backtracking search has desirable
theoretical properties. It is big-O optimal in time (measured as number of acceptability
checks) when amortized across a search tree. The worst case constant is only a factor of
two. The results are not an average case but apply to every search tree with any number of
branches. The results generalise to maintaining multiple acceptable elements in a single list,
and the complexity is independent of the number of elements required. This result is relevant
to practically important algorithms in applications such as SAT and CSP. Techniques like
watched literals in SAT are known to be successful in practice, and certainly have reduced
space overheads compared to state restoration methods. When implemented appropriately,
they can be newly understood to have essentially no theoretical disadvantages in time
either. Some existing implementations are now seen to be optimal even though this was not
realised by their implementers. Some implementations of unit propagations in real world
SAT solvers are not optimal, e.g. MiniSat. Replacing with an optimal implementation in
MiniSat can improve propagation speed by a mean of 29%. Experiments suggested that the
circular approach was better able to find watched literals likely to be true at future nodes.
However, improved propagation speed did not result in improved speed in the full solver.

Acknowledgments
I thank Chris Jefferson and Peter Nightingale for help with this paper in many ways, for
example C++ coding advice and suggestions on how to implement variants of watched
literals in MiniSat. I thank the JAIR editor of this paper, Holger Hoos, and anonymous
reviewers for suggestions leading to the comparison with MiniSat and study of the middleout approach, and for requiring much more precise presentation of my results. I thank
authors of MiniSat, tinisat, and JQuest for making their code available for study.

Appendix A. Experiments in MiniSat
This appendix describes methodology and gives detailed results for experiments on watched
literal implementation in MiniSat version 2.2.0. Two variants of MiniSat were implemented.
The first, Circular, implements two literal watching algorithm using the approach described
in Section 4. The second, TwoPointer, is a variant in which two independent pointers are
maintained, based on an method in a preprint of this paper. Since it has worse properties
both in practice and theory, TwoPointer is described further only in Appendix C.
Timings reported here were performed on a single Apple MacPro (MacPro4,1), with
two Quad-Core Intel Xeon chips 2.26GHz, L2 Cache 256KB per core, L3 Cache 8MB per
processor, 32GB DDR3 RAM 1066MHz, 7200 RPM hard drive, MacOS 10.6. MiniSat 2.2.0
was used as the codebase, with compile time flags as in the distribution. Instances from the
245

fiGent

100

Circular ratio
TwoPointer ratio

10

1

0.1

0.01
0.01

0.1

1

10

100

1000

Figure 4: Scatterplot of relative performance of Circular and TwoPointer variants compared
with Stock MiniSat. The x-axis gives run time of Stock MiniSat in seconds. The
y-axis gives ratio of Stock time to Circular/TwoPointer time. Ratios above 1
mean that the alternative was faster, and below 1 that Stock MiniSat was faster.

SAT 2005 competition (Le Berre & Simon, 2006) were used.5 The reasons for this choice
were that MiniSat did very well in that competition, so is unlikely to be a straw man, and
that it provides a large but manageable set of benchmarks: by using the entire available
set there is no chance of selection bias. While there have been significant advances in SAT
solvers since 2005, I am not aware of major changes in propagation, which are the focus of
the current paper. Code and results are available online, see Appendix D.
In the first experiment, most features of MiniSat were cut out, e.g. clause learning,
conflict analysis, heuristics. By eliminating all other aspects of the solver, each variant
searches identical spaces and the differences in speed must be due to differing speeds of
propagation. No optimisations were applied to exploit the cut-down solver, so that the
propagators being tested are the same as those used in the second experiment. However,
since they must be propagated when running full MiniSat, a set of learnt clauses should
be included. To do this, standard MiniSat was run on each instance for 60s (on a different
Linux machine). For the 594 instances unsolved after 60s, the clause set was saved to give
a realistic but static instance for the cut-down versions of MiniSat. Two versions of each
propagator were created: one in which all instrumentation was switched off, to maximise
speed; and one in which several additional counters were added to provide more metrics on
the nature of the search for watched literals. For reporting cpu times the first version was
used (with times being the median of three runs). Search was performed until a limit of
107 conflicts was reached (excepting one instance solved in 7.75  106 conflicts).
For tests of unrestricted MiniSat, three runs were performed for each algorithm-instance
combination. MiniSat default settings were used with a cpu timeout of 1200s and memory5. http://www.lri.fr/~simon/contest/results/download/distrib-benchs-random-sat2005.tar.bz2,
distrib-benchs-crafted-sat2005.tar.bz2, and distrib-benchs-industrial-sat2005.tar.bz2.

246

fiOptimal Implementation of Watched Literals

out of 1GB. For 87 instances, taking more than 0.01s and max-to-min deviation for some
algorithm more than 10% of its median, another 18 runs were performed for each algorithm,
and the median of all 21 runs used. Instances which no algorithm solved within the timeout,
or all did in less than 0.01s, were discarded. 330 instances remained. Results are shown
for both Circular and TwoPointer in Figure 4. There is huge variation between runtimes
on the same instance, up to almost 100 times. Each propagation method can find different
conflicting clauses, leading to different sets of learnt clauses and heuristics. The instances
vertically above and diagonally below x = 1200 are those where one method timed-out and
the other did not. A paired t-test was performed between Circular and Stock MiniSat,
with null hypothesis that the distributions have the same mean. This gave t = 0.127,
p = 0.899, i.e. a highly insignificant result. Because the assumption of normality is invalid,
the t-test was randomised 100,000 times (Cohen, 1995). Of these, 48.3% gave a lower tvalue and 51.7% a higher value. Similar results were obtained with TwoPointer and Stock
MiniSat. The conclusion must be that there is no statistical evidence that either Circular
or TwoPointer is either better or worse than Stock MiniSat in the fully featured solver.

Appendix B. Middle-Out List Scanning
This appendix gives formal presentation of algorithms and proofs for middle-out scanning
for watched literals as discussed in Section 6.
Procedure 5: FNE-MiddleOut-Helper(list,delta)
Require: delta equals 1 or +1
1: last-cache := last
2: repeat
3:
last := last + delta
4:
if acceptable(list,last) then return true
5: until last = 0 or last = N
6: last:= last-cache
7: return false
Procedure 6: FNE-MiddleOut(list)
Require: delta is persistent between calls and equals 1 or +1, initialised to either
1: if FNE-MiddleOut-Helper(delta) then
2:
return true
3: else
4:
delta := delta
5:
if FNE-Helper(delta) then
6:
return true
7:
else
8:
return false
First, note that FNE-MiddleOut is locally correct (Definition 6). Therefore by Theorem 7, FNE-MiddleOut maintains Invariant 2 at all times. FNE-MiddleOut turns out
to be optimal in big-O terms, as follows from the analogue of Theorem 10.

247

fiGent

Theorem 22. In a downwards-explored search tree, the total number of calls to acceptable made by successful calls to FNE-MiddleOut in an LBS is no more than 2N . (Proof
in Appendix E online.)
From this result we can follow similar development as for circular, with analogous results,
I omit these results except for the most important, which I state without proof.
Theorem 23. (Optimality) In any downwards-explored search tree, the Middle-Out approach requires space for one last pointer and has a worst case of O(N ) calls to acceptable
per branch of the tree.
The persistence of delta between executions is critical. If we add a line 0 : delta = +1
to Procedure 6 to give FNE-MiddleOut-Fixed, we get the following worse result.
Proposition 24. In a downwards-explored search tree, the total number of calls to acceptable made by FNE-MiddleOut-Fixed can be (N 2 ) per branch of the search tree.
(Proof in Appendix E online.)
The solver JQuest by Lynce and Marques-Silva (2005) implements watched literals in
the style of FNE-MiddleOut-Fixed, so is non-optimal. This cannot be deduced from the
cited paper but can be seen from http://sat.inesc.pt/sat/soft/jquest/jquest-src.
tgz in file ClauseSCImplWL.java: a flag controls which direction to move first in, but this
is swapped at most once in a search for the first watch in a clause and never for the second.

Appendix C. Maintaining Multiple Pointers: Theory and Experiment
Compared with that described in Section 4, a more naive approach to implementing multiple
watches is to have a separate last pointer for each one. To unit propagate correctly in SAT
we have two watched literals. Crucially, we cannot allow two pointers to settle on the same
element. A correct method to achieve this for unit propagation is as follows. If a pointer
becomes unacceptable, then store its current value i and call FNE-Circular. If it fails the
clause is entirely false. If it succeeds with a different value to the other pointer do nothing.
If it succeeds with the value of the other pointer then call FNE-Circular again. If this
second call fails then we must reset the value of the first pointer to the stored value i and
unit propagate with the literal represented by the second pointer. To prove the optimality
of this approach I need a more general version of Theorem 10.
Theorem 25. Suppose that W pointers last1 , last2 , . . . lastW to the same list are maintained
simultaneously, with the same definition of acceptability, and that calls to FNE for a pointer
lasti are made only when it points to an unacceptable element or to the same value as another
pointer currently has. Then: if more than cN calls to acceptable are made in any LBS
in a downwards-explored search tree, either at least one of the calls to FNE-Circular fails
or at least two of the pointers take the same value. (Proof in Appendix E online.)
Theorem 25 leads to the correctness of the unit propagation procedure described above.
It guarantees that when only one satisfiable literal remains in a clause, both pointers will
settle on it and so unit propagation can be performed. The space requirement is O(1) per
last pointer. Detection of unacceptability can also be done in O(1) time by maintaining a
list of all occurrences of literals, to be consulted when a literal is set false. This gives:
248

fiOptimal Implementation of Watched Literals

Corollary 26. Unit propagation using watched literals in a clause with N literals can be
implemented in O(1) space using O(N ) time per branch of a search tree.

10
8
6
5
4
3
2

1
0.8
TwoPointer:Stock
0.437x + 0.572

0.6
0.5
0.5 0.6

0.8

1

1.2

2

3

4

5

6

8

10

20

Figure 5: Scatterplot of  (x-axis) against speedup ratio of conflicts per second of TwoPointer over Stock MiniSat (y-axis). The line 0.437x + 0.572 is the best-fit line
in the region   1.2. The vertical line shows  = 1.2.

The development following Theorem 10 now follows as before. I state without proof:
Theorem 27. In the conditions of Theorem 25, for a search tree containing k branches,
calls to FNE-Circular make at most k((c + 1)N  1) calls to acceptable.
TwoPointer unit propagates faster than Stock. When searching 594 instances in cutdown MiniSat up to 10 million conflicts, TwoPointer took a mean of 155.9s against 182.6s
for Stock, so Stock takes 17.1% more time. This was about 10% slower than Circulars
mean time of 141.6s. Circular is never more than 13% slower than TwoPointer or more
than 35% faster. Both mean and median speedups of Circular over TwoPointer are 1.10.
The median performance of Stock was slightly better than TwoPointer (78.1s to 81.1s) but
Stock is never more than 22% faster while TwoPointer can be as much as 7.7 times faster.
We see similar results on the effect of blocked watches as with Circular. Results for
Circular and definition of  are given in the main paper in Section 6. Where   1.2 (122
instances),  correlates very strongly with speedup in conflicts per second, with correlation
coefficient r2 = 0.86. Median speedup in this region is 1.32 and mean is 1.65. The best fit
line is shown in Figure 5. For  < 1.2 (472 instances), there is no correlation between  and
speedup, with r2 = 0.07. Median and mean speedups are 0.88 and 0.90 (so are slowdowns
not speedups.) In all regions, there is an extremely high correlation between TwoPointer
and Circular, r2 > 0.996. As with Circular, this analysis indicates that most of the speedup
occurs in instances where TwoPointer is much better than Stock MiniSat at setting watches
on literals which are likely to be valid later in search and thus block watched literal search.
249

fiGent

Results for TwoPointer in the full version of MiniSat were similar to those with Circular.
Under the methodology described in Appendix A, the raw t-value is 1.54, p = 0.124.
Randomisation 100,000 times gave 26.2% lower t-values and 73.8% higher values.

Appendix D. Description of Online Appendices
Two Online Appendices are available. The first is a textual Appendix E with proofs omitted
from the main text (Gent13a-appendix1.pdf).6 The second contains the results tables, full
MiniSat outputs, and graphs used for this paper (Gent13a-appendix2.tgz).7 A fuller version
of this appendix, including code for each variant of MiniSat and scripts to run and analyse
experiments, is available separately.8 The file is about 4MB and unpacks to about 12MB.
Separately, a 2.4GB compressed tar file is available containing the clausesets written out
after 60s failed search.9

References
Bessiere, C., Regin, J.-C., Yap, R., & Zhang, Y. (2005). An optimal coarse-grained arc
consistency algorithm. Artificial Intelligence, 165, 165185.
Bessiere, C. (2004). Personal communication to Marc van Dongen.. Described by (van
Dongen, 2004).
Bessiere, C., & Regin, J.-C. (2001). Refining the basic constraint propagation algorithm.
In Nebel, B. (Ed.), Proceedings of the Seventeenth International Joint Conference on
Artificial Intelligence, IJCAI 2001, Seattle, Washington, USA, August 4-10, 2001, pp.
309315. Morgan Kaufmann.
Chai, D., & Kuehlmann, A. (2003). A fast pseudo-boolean constraint solver. In Proceedings
of the 40th Design Automation Conference, DAC 2003, Anaheim, CA, USA, June
2-6, 2003, pp. 830835. ACM.
Cohen, P. R. (1995). Empirical methods for artificial intelligence. MIT Press.
Een, N., & Sorensson, N. (2003). An extensible SAT-solver. In Giunchiglia, E., & Tacchella, A. (Eds.), SAT, Vol. 2919 of Lecture Notes in Computer Science, pp. 502518.
Springer.
Gent, I. P., Jefferson, C., & Miguel, I. (2006a). Minion: A fast scalable constraint solver.
In Brewka, G., Coradeschi, S., Perini, A., & Traverso, P. (Eds.), ECAI, Vol. 141 of
Frontiers in Artificial Intelligence and Applications, pp. 98102. IOS Press.
Gent, I. P., Jefferson, C., & Miguel, I. (2006b). Watched literals for constraint propagation
in Minion. In Benhamou, F. (Ed.), CP, Vol. 4204 of Lecture Notes in Computer
Science, pp. 182197. Springer.
Harvey, W. D., & Ginsberg, M. L. (1995). Limited discrepancy search. In Proceedings
of the Fourteenth International Joint Conference on Artificial Intelligence, IJCAI 95,
6.
7.
8.
9.

Also available at http://ipg.host.cs.st-andrews.ac.uk/JAIR/Gent13a-appendix1.pdf
Also available at http://ipg.host.cs.st-andrews.ac.uk/JAIR/Gent13a-appendix2.tgz
http://ipg.host.cs.st-andrews.ac.uk/JAIR/Gent13a-appendix2-full.tgz
http://ipg.host.cs.st-andrews.ac.uk/JAIR/writtenclausesets.tgz

250

fiOptimal Implementation of Watched Literals

Montreal Quebec, Canada, August 20-25 1995, 2 Volumes, Vol. 1, pp. 607615. Morgan
Kaufmann.
Huang, J. (2007). A case for simple SAT solvers. In Bessiere, C. (Ed.), Principles and
Practice of Constraint Programming - CP 2007, 13th International Conference, CP
2007, Providence, RI, USA, September 23-27, 2007, Proceedings, Vol. 4741 of Lecture
Notes in Computer Science, pp. 839846. Springer.
Jefferson, C., Moore, N. C. A., Nightingale, P., & Petrie, K. E. (2010). Implementing logical
connectives in constraint programming. Artificial Intelligence, 174 (16-17), 14071429.
Korf, R. E. (1985). Depth-first iterative-deepening: An optimal admissible tree search.
Artificial Intelligence, 27 (1), 97109.
Le Berre, D., & Simon, L. (2006). Special volume on the SAT 2005 competitions and
evaluations. JSAT, 2 (1-4).
Likitvivatanavong, C., Zhang, Y., Bowen, J., & Freuder, E. C. (2005). Maintaining arc consistency using adaptive domain ordering. In Kaelbling, L. P., & Saffiotti, A. (Eds.),
IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence, Edinburgh, Scotland, UK, July 30-August 5, 2005, pp. 15271528.
Professional Book Center.
Likitvivatanavong, C., Zhang, Y., Shannon, S., Bowen, J., & Freuder, E. C. (2007). Arc
consistency during search. In Veloso, M. M. (Ed.), IJCAI 2007, Proceedings of the 20th
International Joint Conference on Artificial Intelligence, Hyderabad, India, January
6-12, 2007, pp. 137142.
Lynce, I., & Marques-Silva, J. P. (2005). Efficient data structures for backtrack search SAT
solvers. Ann. Math. Artif. Intell., 43 (1), 137152.
Marques-Silva, J. P., Lynce, I., & Malik, S. (2009). Conflict-driven clause learning sat
solvers. In Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.), Handbook
of Satisfiability, Vol. 185 of Frontiers in Artificial Intelligence and Applications, pp.
131153. IOS Press.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: engineering an efficient SAT solver. In Proceedings of the 38th annual Design Automation
Conference, DAC 01, pp. 530535, New York, NY, USA. ACM.
Nightingale, P., Gent, I. P., Jefferson, C., & Miguel, I. (2013). Short and long supports for
constraint propagation. J. Artif. Intell. Res. (JAIR), 46, 145.
Prosser, P. (1993). Hybrid algorithms for the constraint satisfaction problem. Computational
Intelligence, 9(3), 268299.
Prosser, P., & Unsworth, C. (2011). Limited discrepancy search revisited. J. Exp. Algorithmics, 16, 1.6:1.11.6:1.18.
Regin, J.-C. (2005). MAC algorithms during the search without additional space cost. In
Proc. 11th Principles and Practice of Constraint Programming (CP 2005), pp. 520
533.
van Dongen, M. R. C. (2004). Saving support-checks does not always save time. Artif.
Intell. Rev., 21 (3-4), 317334.
251

fiGent

Van Gelder, A. (2002). Generalizations of watched literals for backtracking search. In
Seventh Intl Symposium on AI and Mathematics.
Zhang, H., & Stickel, M. E. (2000). Implementing the Davis-Putnam method. J. Autom.
Reasoning, 24 (1/2), 277296.

252

fiJournal of Artificial Intelligence Research 48 (2013) 513-582

Submitted 12/12; published 11/13

AI Methods in Algorithmic Composition:
A Comprehensive Survey
Jose David Fernndez
Francisco Vico

josedavid@geb.uma.es
fjv@geb.uma.es

Universidad de Mlaga, Calle Severo Ochoa, 4, 119
Campanillas, Mlaga, 29590 Spain

Abstract
Algorithmic composition is the partial or total automation of the process of music composition by using computers. Since the 1950s, different computational techniques related to
Artificial Intelligence have been used for algorithmic composition, including grammatical
representations, probabilistic methods, neural networks, symbolic rule-based systems, constraint programming and evolutionary algorithms. This survey aims to be a comprehensive
account of research on algorithmic composition, presenting a thorough view of the field for
researchers in Artificial Intelligence.

1. Introduction
Many overly optimistic, but ultimately unfulfilled predictions were made in the early days
of Artificial Intelligence, when computers able to pass the Turing test seemed a few decades
away. However, the field of Artificial Intelligence has grown and got matured, developing
from academic research and reaching many industrial applications. At the same time, key
projects and challenges have captivated public attention, such as driverless cars, natural
language and speech processing, and computer players for board games.
The introduction of formal methods have been instrumental in the consolidation of many
areas of Artificial Intelligence. However, this presents a disadvantage for areas whose subject
matter is difficult to define in formal terms, which naturally tend to become marginalized.
That is the case of Computational Creativity (also known as Artificial Creativity), which
can be loosely defined as the computational analysis and/or synthesis of works of art, in a
partially or fully automated way. Compounding the problem of marginalization, the two
communities naturally interested in this field (AI and the arts) speak different languages
(sometimes very different!) and have different methods and goals1 , creating great difficulties in the collaboration and exchange of ideas between them. In spite of this, small
and sometimes fragmented communities are active in the research of different aspects of
Computational Creativity.
The purpose of this survey is to review and bring together existing research on a specific
style of Computational Creativity: algorithmic composition. Interpreted literally, algorithmic composition is a self-explanatory term: the use of algorithms to compose music. This
is a very broad definition, because for centuries musicians have been proposing methods
that can be considered as algorithmic in some sense, even if human creativity plays a key
1. Related to this problem, it is not uncommon for engineering concepts to become bent in strange ways
when interpreted by artists. See Footnote 28 in page 550 for a particularly remarkable example.
c
2013
AI Access Foundation. All rights reserved.

fiFernndez & Vico

role. Some commonly cited examples include dArezzos Micrologus, species counterpoint,
Mozarts dice games, Schoenbergs twelve-tone technique, or Cages aleatoric music. Readers interested in these and other pre-computer examples of algorithmic composition are
referred to the introductory chapters of almost any thesis or book on the subject, such as
Daz-Jerezs (2000), Aschauers (2008) or Nierhauss (2009). In this survey, we will use the
term algorithmic composition in a more restricted way, as the partial or total automation
of music composition by formal, computational means. Of course, pre-computer examples
of algorithmic composition can be implemented on a computer, and some of the approaches
reviewed in this survey implement a classical methodology. In general, the focus will be
on AI techniques, but self-similarity and cellular automata will also be reviewed as modern
computational techniques that can be used for generating music material without creative
human input.
1.1 Motivation
Some useful starting points for researching the past and present of computer music are the
Computer Music Journal, the International Computer Music Conference 2 annually organized by the International Computer Music Association 3 , and some books such as Machine
Models of Music (Schwanauer & Levitt, 1993), Understanding music with AI (Balaban
et al., 1992), Music and Connectionism (Todd & Loy, 1991), and the anthologies of selected
articles from the Computer Music Journal (Roads & Strawn, 1985; Roads, 1992). However,
these resources are not only about algorithmic composition, but computer music in general.
For more specific information on algorithmic composition, surveys are a better option.
There are many surveys reviewing work on algorithmic composition. Some review both
analysis and composition by computer with AI methods (Roads, 1985), while others discuss
algorithmic composition from a point of view related to music theory and artistic considerations (Collins, 2009), or from the personal perspective of a composer (Langston, 1989;
Dobrian, 1993; Pope, 1995; Maurer, 1999). Some of them provide an in depth and comprehensive view of a specific technique for algorithmic composition, as Anders and Miranda
(2011) do for constraint programming, as Ames (1989) does for Markov chains, or as Santos
et al. (2000) do for evolutionary techniques, while some others are specialized in the comparison between paradigms for computational research on music, as Toiviainen (2000). Others
offer a wide-angle (but relatively shallow) panoramic of the field (Papadopoulos & Wiggins,
1999), review the early history of the field (Loy & Abbott, 1985; Ames, 1987; Burns, 1994),
or analyze methodologies and motivations for algorithmic composition (Pearce et al., 2002).
There are also works that combine in depth and comprehensive reviews for a wide range of
methods for algorithmic composition, such as Nierhauss (2009) book.
In this context, a natural question arises: why yet another survey? The answer is
that no existing survey article fulfills the following criteria: (a) to cover all methods in
a comprehensive way, but from a point of view primarily focused on AI research, and
(b) to be centered on algorithmic composition.4 Nierhauss (2009) book on algorithmic
2. The archives are available at http://quod.lib.umich.edu/i/icmc/
3. http://www.computermusic.org/
4. Many surveys conflate the discussion on algorithmic composition (synthesis of music) with the computational analysis of music, as in the work of Roads (1985), Nettheim (1997) or Toiviainen (2000). This
can become somewhat distracting if the reader is interested just in algorithmic composition.

514

fiAI Methods in Algorithmic Composition

composition comes close to fulfilling these criteria with long, detailed expositions for each
method and comprehensive reviews of the state of the art. In contrast, this survey is
intended to be a reasonably short article, without lengthy descriptions: just a reference
guide for AI researchers. With these aims in mind, this survey is primarily structured
around the methods used to implement algorithmic composition systems, though early
systems will also be reviewed separately.
A second, more practical motivation is accessibility. Since Computational Creativity
balances on the edge between AI and the arts, the relevant literature is scattered across
many different journals and scholarly books, with a broad spectrum of topics from computer
science to music theory. As a very unfortunate consequence, there are many different
paywalls between researchers and relevant content, translating sometimes into a lot of hassle,
only partially mitigated by relatively recent trends like self-archiving. This survey brings
together a substantial body of research on algorithmic composition, with the intention of
conveying it more effectively to AI researchers.

2. Introducing Algorithmic Composition
Traditionally, composing music has involved a series of activities, such as the definition of
melody and rhythm, harmonization, writing counterpoint or voice-leading, arrangement or
orchestration, and engraving (notation). Obviously, this list is not intended to be exhaustive
or readily applicable to every form of music, but it is a reasonable starting point, especially
for classical music. All of these activities can be automated by computer to varying degrees,
and some techniques or languages are more suitable for some of these than others (Loy &
Abbott, 1985; Pope, 1993).
For relatively small degrees of automation, the focus is on languages, frameworks and
graphical tools to provide support for very specific and/or monotone tasks in the composition process, or to provide raw material for composers, in order to bootstrap the composition
process, as a source of inspiration. This is commonly known as computer-aided algorithmic composition (CAAC), and constitutes a very active area of research and commercial
software development: many software packages and programming environments can be
adapted to this purpose, such as SuperCollider (McCartney, 2002), Csound (Boulanger,
2000), MAX/MSP (Puckette, 2002), Kyma (Scaletti, 2002), Nyquist (Simoni & Dannenberg, 2013) or the AC Toolbox (Berg, 2011). The development of experimental CAAC
systems at the IRCAM5 (such as PatchWork, OpenMusic and their various extensions)
should also be emphasized (Assayag et al., 1999). Arizas comprehensive repository of software tools and research resources for algorithmic composition6 constitutes a good starting
point (Ariza, 2005a) to explore this ecosystem, as well as algorithmic composition in general.
Earlier surveys (such as Pennycook, 1985 and Pope, 1986) are also useful for understanding
the evolution of the field, especially the evolution of graphical tools to aid composers.
Our survey, on the other hand, is more concerned with algorithmic composition with
higher degrees of automation of compositional activities, rather than typical CAAC. In other
words, we focus more on techniques, languages or tools to computationally encode human
musical creativity or automatically carry out creative compositional tasks with minimal or
5. http://www.ircam.fr/
6. http://www.flexatone.net/algoNet/

515

fiFernndez & Vico

no human intervention, instead of languages or tools whose primary aim is to aid human
composers in their own creative processes.
Obviously, the divide between both ends of the spectrum of automation (CAAC representing a low degree of automation, algorithmic composition a high degree of automation) is
not clear, because any method that automates the generation of creative works can be used
as a tool to aid composers, and systems with higher degrees of automation can be custombuilt on top of many CAAC frameworks.7 Furthermore, a human composer can naturally
include computer languages and tools as an integral part of the composition process, such
as Brian Enos concept of generative music (Eno, 1996). To conclude these considerations,
this survey is about computer systems for automating compositional tasks where the user
is not expected to be the main source of creativity (at most, the user is expected to set
parameters for the creative process, encode knowledge about how to compose, or to provide examples of music composed by humans to be processed by the computer). This also
includes real-time automatic systems for music improvisation, such as in jazz performance,
or experimental musical instruments that automate to a certain extent the improvisation
of music.
Finally, a few more considerations, to describe what this survey is not about:
 Although music can be defined as organized sound, a composition written in traditional staff notation does not fully specify how the music actually sounds: when a
piece of music is performed, musicians add patterns of small deviations and nuances in
pitch, timing and other musical parameters. These patterns account for the musical
concept of expressiveness or gesture, and they are necessary for the music to sound
natural. While the problem of automatically generating expressive music is important
in itself, and involves creativity, it is clearly not within the boundaries of algorithmic
composition as reviewed in this survey. The reader is referred to Kirke and Mirandas
(2009) review of this area for further information.
 The computational synthesis of musical sounds, or algorithmic sound synthesis, can be
understood as the logical extension of algorithmic composition to small timescales; it
involves the use of languages or tools for specifying and synthesizing sound waveforms,
rather than the more abstract specification of music associated with traditional staff
notation. The line between algorithmic composition and algorithmic sound synthesis
is blurred in most of the previously mentioned CAAC systems, but this survey is not
concerned with sound synthesis; interested readers may refer to Roadss (2004) book
on the subject.
 In computer games (and other interactive settings), music is frequently required to
gracefully adapt to the state of the game, according to some rules. This kind of
music is commonly referred to as non-linear music (Buttram, 2003) or procedural
audio (Farnell, 2007). Composing non-linear music presents challenges of its own, not
specifically related to the problem of algorithmic composition, so we will not review
the literature on this kind of music.
7. This is the case of many of the systems for algorithmic composition described here. For example,
PWConstraints (described in Section 3.2.3) is built on top of PatchWork, as described by Assayag et al.
(1999).

516

fiAI Methods in Algorithmic Composition

These three scenarios (automated expressiveness, algorithmic sound synthesis and nonlinear music) will be sparingly mentioned in this survey, only mentioned when innovative
(or otherwise notable) techniques are involved.
2.1 The Early Years
In this section, we will review early research published on algorithmic composition with
computers, or with a clear computational approach. While these references might have
been discussed by methodology in the following sections, it is useful to group them together
here, since it is difficult to find a survey discussing all of them.
The earliest use of computers to compose music dates back to the mid-1950s, roughly
at the same time as the concept of Artificial Intelligence was coined at the Darmouth
Conference, though the two fields did not converge until some time later. Computers were
expensive and slow, and also difficult to use, as they were operated in batch mode.
One of the most commonly cited examples is Hiller and Isaacsons (1958) Illiac Suite,
a composition that was generated using rule systems and Markov chains, late in 1956. It
was designed as a series of experiments on formal music composition. During the following
decade, Hillers work inspired colleagues from the same university to further experiment
with algorithmic composition, using a library of computer subroutines for algorithmic composition written by Baker (also a collaborator of Hiller), MUSICOMP (Ames, 1987). This
library provided a standard implementation of the various methods used by Hiller and
others.
Iannis Xenakis, a renowned avant-garde composer, profusely used stochastic algorithms
to generate raw material for his compositions, using computers since the early 1960s to
automate these methods (Ames, 1987). Though his work can be better described as CAAC,
he still deserves being mentioned for being a pioneer. Koenig, while not as well known as
Xenakis, also was a composer that in 1964 implemented an algorithm (PROJECT1) using
serial composition (a musical theory) and other techniques (as Markov chains) to automate
the generation of music (Ames, 1987).
However, there were also several other early examples of algorithmic composition, though
not so profusely cited as Hiller and Xenakiss. Push Button Bertha, composed in 1956
(Ames, 1987) around the same time as Hillers Illiac Suite, is perhaps the third most
cited example: a song whose music was algorithmically composed as a publicity stunt by
Burroughs (an early computer company), generating music similar to a previously analyzed
corpus. However, there is at least one earlier, unpublished work by Caplin and Prinz in 1955
(Ariza, 2011), which used two approaches: an implementation of Mozarts dice dame and
a generator of melodic lines using stochastic transitional probabilities for various aspects
of the composition. Another commonly cited example by Brooks et al. (1957) explored the
potential of the Markoff 8 chain method.
Several other early examples are also notable. Olsons (1961) dedicated computer was
able to compose new melodies related to previously fed ones, using Markov processes. While
the work was submitted for publication in 1960, they claimed to have built the machine in
the early 1950s. Also of interest is Gills (1963) algorithm, implemented at the request of the
8. Markov and Markoff are alternative transliterations of the Russian surname . The spelling
Markov has been prevalent for decades, but many older papers used Markoff.

517

fiFernndez & Vico

BBC, which represents a hallmark in the application of classical AI techniques to algorithmic
composition: it used a hierarchical search with backtracking to guide a compositional process inspired by Schoenbergs twelve-tone technique. Finally, it is worth mentioning what
may represent the first dissertation on algorithmic composition: Padbergs (1964) Ph.D.
thesis implemented a compositional framework (based in formal music theory) in computer
code. Her work is unusual in that, instead of using random number generators, she used
raw text input to drive procedural techniques in order to generate all the parameters of the
composition system.
Non-scholarly early examples also exist, though they are difficult to assess because of
the sparsity of the published material, and the fact that they are mostly not peer-reviewed.
For example, Pinkerton (1956) described in Scientific American a Banal Tune-Maker, a
simple Markov chain created from several tens of nursery tunes, while Sowa (1956) used
a GENIAC machine9 to implement the same idea (Cohen, 1962), and Raymond Kurzweil
implemented in 1965 (Rennie, 2010) a custom-made device that generated music in the style
of classical composers. Another example, unfortunately shrouded in mystery, is Raymond
Scotts Electronium (Chusid, 1999), an electronic device whose development spanned
several decades, reportedly able to generate abstract compositions. Unfortunately, Scott
never published or otherwise explained his work.
As machines became less expensive, more powerful and in some cases interactive, algorithmic composition slowly took off. However, aside from the researchers at Urbana (Hillers
university), there was little continuity in research, and reinventing the wheel in algorithmic
composition techniques was common. This problem was compounded by the fact that initiatives in algorithmic composition often came from artists, who tended to develop ad hoc
solutions, and the communication with computer scientists was difficult in many cases.

3. The Methods
The range of methodological approaches used to implement algorithmic composition is
notably wide, encompassing many, very different methods from Artificial Intelligence, but
also borrowing mathematical models from Complex Systems and even Artificial Life. This
survey has been structured by methodology, devoting a subsection to each one:
3.1

Grammars

3.2

Symbolic, Knowledge-Based Systems

3.3

Markov Chains

3.4

Artificial Neural Networks

3.5

Evolutionary and Other Population-Based Methods

3.6

Self-Similarity and Cellular Automata

Figure 1 summarizes the taxonomy of the methods reviewed in this survey. Together,
Sections 3.1 and 3.2 describe work using symbolic techniques that can be characterized
as classical good old-fashioned AI. Although grammars (Section 3.1) are symbolic and
9. A GENIAC Electric Brain, an electric-mechanic machine promoted as an educational toy. Despite being
marketed as a computer device, all the computing was performed by the human operator.

518

fiAI Methods in Algorithmic Composition

Artificial intelligence
Symbolic AI

Optimization

(Knowledge-based, Rule-based)
Sections 3.1, 3.2

Computational methods
for automatic generation
of music material
(not based on models
of human creativity)

Population-based methods
Grammars

Rule learning

Section 3.1

Section 3.2.1

Evolutionary algorithms

L-systems

Sections 3.1.2, 3.2.2, 3.4.1, 3.5

Section 3.1.1

Constraint
satisfaction

Related
methods

Automatic

Interactive

Section 3.5.1

Section 3.5.2

Section 3.2.3

Section 3.1.3

Complex systems
Case-based
reasoning

Concurrency
models

Section 3.2.4

Section 3.2.5

Other population-based methods
Section 3.5.3

Self-similarity
Section 3.6

Machine learning
Markov chains
Related statistical methods
Section 3.3

Cellular automata
Artificial neural networks

Section 3.6.1

Section 3.4

Figure 1: Taxonomy of the methods reviewed in this survey
knowledge-based, and thus should be included as part of Section 3.2, they have been segregated in a separate subsection because of their relative historical importance in algorithmic
composition. Sections 3.3 and 3.4 describe work using various methodologies for machine
learning, and Section 3.5 does the same for evolutionary algorithms and other populationbased optimization methods. Although the methodologies described in Section 3.6 are not
really a form of Artificial Intelligence, they have been included because of their importance in algorithmic composition as automatic sources of music material (i.e., they do not
depend on any model of human creativity for generating music material).
There have been other attempts to systematize algorithmic composition, such as the
taxonomies of Papadopoulos and Wiggins (1999) and Nierhaus (2009). Our taxonomy
is roughly similar to Nierhauss, with some differences, such as including L-systems as
grammars instead of self-similar systems. The reader may be surprised to find that many
methods for machine learning and optimization are missing from our taxonomy. There are
several reasons for this. In some cases, some methods are subsumed by others. For example,
in machine learning, many different methods have been formulated in the mathematical
framework of artificial neural networks. In other cases, a method has been used only rarely,
almost always together with other methods. For example, in optimization, this is the case
of tabu search, which has been used a few times in the context of constraint satisfaction
problems (Section 3.2.3), and simulated annealing, which has been occasionally combined
with constraint satisfaction, Markov processes and artificial neural networks.
It is difficult to neatly categorize the existing literature in algorithmic composition with
any hierarchical taxonomy, because the methods are frequently hybridized, giving rise to
many possible combinations. This is specially true for evolutionary methods, which have
519

fiFernndez & Vico

been combined with almost every other method. Additionally, some papers can be considered to belong to different methodologies, depending on the selected theoretical framework10 , while others are unique in their approaches11 , further complicating the issue. Finally, the lines between some methods (as rule systems, grammars and Markov chains) are
frequently blurred: in some cases, ascribing a work to one of them becomes, in the end, a
largely arbitrary exercise depending on the terminology, intentions and the domain of the
researchers. Each method will be presented separately (but also presenting existing hybridizations with other methods), describing the state of the art in a mostly chronological
order for each method.
Although this classification is not fully comprehensive, we have only found one (arguably
remote) example using a method that is not related to the ones listed above: Amiot et al.
(2006), who applied the Discrete Fourier Transform (DFT) to generate variations of musical
rhythms. Given a rhythm as a sequence of numerical symbols, they represented it in the
frequency domain by computing its DFT. Variations on that rhythm were generated by
slightly perturbing the coefficients of the transform and converting back to the time domain.
3.1 Grammars and Related Methods
In broad terms, a formal grammar may be defined as a set of rules to expand high-level
symbols into more detailed sequences of symbols (words) representing elements of formal
languages. Words are generated by repeatedly applying rewriting rules, in a sequence of
so-called derivation steps. In this way, grammars are suited to represent systems with hierarchical structure, which is reflected in the recursive application of the rules. As hierarchical
structures can be recognized in most styles of music, it is hardly surprising that formal
grammar theory has been applied to analyze and compose music for a long time12 , despite recurring concerns that grammars fail to capture the internal coherency and subtleties
required for music composition (Moorer, 1972).
To compose music using formal grammars, an important step is to define the set of
rules of the grammar, which will drive the generative process. The rules are traditionally
multi-layered, defining several subsets (maybe even separated in distinct grammars) of rules
for different phases of the composition process: from the general themes of the composition,
down to the arrangement of individual notes. While early authors derived the rules by hand
from principles grounded in music theory, other methods are possible, like examining a corpus of pre-existing musical compositions to distill a grammar able to generate compositions
in the general style of the corpus, or using evolutionary algorithms. Another important
aspect is the mapping between the formal grammar and the musical objects that it generates, which usually relates the symbols of the derived sequences with elements of the music
composition, as notes, chords or melodic lines. However, other mappings are possible, as
using the derivation tree to define the different aspects of the musical composition. Another
important aspect of the automatic composition process is the election of the grammatical
10. For example, Markov chains can be formulated as stochastic grammars; some self-similar systems can be
characterized as L-system grammars; rule learning and case-based reasoning are also machine learning
methods; etc.
11. For example, Kohonens method (Kohonen et al., 1991), which is neither grammatical nor neural nor
Markovian, but can be framed in either way, according to its creator.
12. See, e.g., the survey by Roads (1979).

520

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Lidov & Gabura, 1973

melody

early proposal

Rader, 1974

melody

early proposal,
very detailed grammar

Ulrich, 1977

jazz chord identification

integrated in an ad hoc system
(to produce jazz improvisations)

Baroni & Jacoboni, 1978

grammar for Bach chorales

early proposal

Leach & Fitch, 1995
(XComposer)

structure, rhythm and melody

uses chaotic non-linear systems
(self-similarity)

Hamanaka et al., 2008

generate variations on two melodies
(by altering the derivation tree)

inspired by Lerdahl et al.s (1983)
GTTM

Roads, 1977

structure, rhythm and melody

grammar compiler

Holtzman, 1981

structure, rhythm and melody

grammar compiler

Jones, 1980

structure

space grammars
(uses the derivation tree)

Bel, 1992
(Bol Processor)

improvisation of tabla rhythms

tool for field research

Kippen & Bel, 1989

improvisation of tabla rhythms

grammatical inference

Cruz-Alczar & Vidal-Ruiz,
1998

melody

grammatical inference

Gillick et al., 2009

jazz improvisation

grammatical inference.
Implemented as an extension to
Keller and Morrisons (2007)
ImprovGenerator

Kitani & Koike, 2010
(ImprovGenerator)

real-time drum rhythm improvisation

online grammatical inference

Keller & Morrison, 2007
(Impro-Visor)

jazz improvisation

sophisticated GUI interface

Quick, 2010

classical three-voice counterpoint

integrated in a Schenkerian
framework

Chemillier, 2004

jazz chord sequences

implemented in OpenMusic and
MAX

Table 1: References for Section 3.1 (algorithmic composition with grammars), in order of
appearance.

rules to be applied. While many approaches are possible, the use of activation probabilities
for the rules (stochastic grammars) is common. In the process of compiling information
for this survey, it has been noted that almost all research has been done on regular and
context-free grammars, as context-sensitive and more general grammars seem to be very
difficult to implement effectively, except for very simple toy systems.
Lidov and Gabura (1973) implemented an early example of a formal grammar to compose simple rhythms. Another early example was implemented by Rader (1974): he defined
a grammar by hand from rather simple music concepts, enriching the rules of the grammar
with activation probabilities. Other early examples used grammars driven by rules from
music theories, either as a small part of a synthesis engine, as Ulrichs (1977) grammar
521

fiFernndez & Vico

for enumerating jazz chords, or by inferring the rules from classical works, as Baroni and
Jacobonis (1978) grammar to generate melodies. A Generative Theory of Tonal Music
(Lerdahl et al., 1983), a book presenting a grammatical analysis of tonal music, is a relatively early theoretical work that can be said to have influenced the use of grammars for
algorithmic composition, though it is not directly concerned with algorithmic composition,
but with a grammatical approach to the analysis of music. This book has been widely popular, and has had a lasting impact on the field and high citation rates. Examples of later
work inspired by this book include Popes (1991) T-R Trees, Leach and Fitchs (1995)
event trees, and Hamanaka et al.s (2008) melody morphing.
In the 1980s, some proposed approaches more in line with computer science, abstracting
the process to generate the grammars instead of codifying them by hand, though at the cost
of producing less interesting compositions. Roads (1977) proposed a framework to define,
process and use grammars to compose music, while Holtzman (1981) described a language
to define music grammars and automatically compose music from them. Meanwhile, Jones
(1980) proposed the concept of space grammars, in conjunction with a novel mapping
technique: instead of using the terminal symbols as the building blocks of the composition,
he used the derivation tree of the terminal sequence to define the characteristics of the
composition. This approach was unfortunately not developed far enough to yield significant
results. In spite of these early efforts, most research on grammatical representations of
music was focused on analysis rather than synthesis. Some instances, such as Steedmans
(1984) influential grammar for the analysis of jazz chord progressions, were later adapted
for synthesis (see below).
The problem with a grammatical approach to algorithmic composition is the difficulty
to manually define a set of grammatical rules to produce good compositions. This problem
can be solved by generating the rules of the grammar (and the way they are applied) automatically. For example, although Bel (1992) implemented the BOL processor to facilitate
the creation by hand of more or less sophisticated music grammars13 , he also explored the
automated inference of regular grammars (Kippen & Bel, 1989). Later, Cruz-Alczar and
Vidal-Ruiz (1998) implemented several methods of grammatical inference: analyze a corpus of pre-existing classical music compositions, represented with a suitable set of symbols,
then inducing stochastic regular grammars (Markov chains) able to parse the compositions
in the corpus, and finally applying these grammars to generate new compositions that are
in a similar style to the compositions in the corpus. Gillick et al. (2009) used a similar
approach (also Markovian) to synthesize jazz solos, but with a more elaborated synthesis
phase. Kitani and Koike (2010) provide another example of grammatical inference, in this
case used for real-time improvised accompaniment.
However, others still designed their grammars by hand, carefully choosing the mapping between terminal symbols and musical objects, as Keller and Morrison (2007) did
for jazz improvisations. Another approach is to take a pre-existing music theory with a
strong hierarchical methodology, as designing a grammar inspired in Schenkerian analysis
(Quick, 2010), or using Lerdhals grammatical analysis to derive new compositions from two
previously existing ones by altering the derivation tree (Hamanaka et al., 2008), or even de13. Initially to represent and analyze informal knowledge about Indian tabla drumming, but later also to
represent other music styles.

522

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Prusinkiewicz, 1986

melody

mapping turtle graphics to music scores

Nelson, 1996

melody

mapping turtle graphics to music scores

Mason & Saffle, 1994

melody (counterpoint is suggested)

mapping turtle graphics to music scores

Soddell & Soddell, 2000

aural representations
of biological data

L-system modulates pitch intervals

Morgan, 2007

composition for a large
instrumental ensemble

ad hoc symbolic mapping

Langston, 1989

melody

L-system is interpreted to arrange
pre-specified fragments

Worth & Stepney, 2005

melody

several mappings and L-system types

Manousakis, 2006

melody (sound synthesis)

complex, multi-dimensional mapping.
Implemented in MAX.

McCormack, 1996

melody, polyphonies

contex-sensitive L-systems

DuBois, 2003

real-time accompaniment

implemented in MAX

Wilson, 2009

melody

mapping turtle graphics to music scores

McGuire, 2006

arpeggiator

simple symbolic mapping

Watson, 2008

base chord progression

L-systems are used the context of a
larger, multi-stage system

Gogins, 2006

voice leading

Musical theory (pitch spaces).
Implemented in Csound

Bulley & Jones, 2011

arpeggiator

part of a real-time art installation.
Implemented in MAX

Pestana, 2012

real-time accompaniment

implemented in MAX

Table 2: References for Section 3.1.1, in order of appearance.

veloping a jazz on-the-fly improviser (Chemillier, 2004) by adapting Steedmans grammar,
previously implemented for analysis purposes.
3.1.1 L-Systems
Lindenmayer Systems, commonly abbreviated to L-systems, are a specific variant of formal
grammar, whose most distinctive feature is parallel rewriting, i.e., at each derivation step,
not one but all possible rewriting rules are applied at once. They have been successfully
applied in different scenarios, specially to model microbial, fungi and plant growth and
shapes, because they are particularly well-suited to represent the hierarchical self-similarity
characteristic of these organisms. This ability to represent self-similar structures, together
with the fact that L-systems are easier to understand and apply than traditional formal
grammars, have made L-systems fairly popular in algorithmic composition.
Arguably, the most visually stunning way to use L-systems has been the synthesis of
2D and 3D renderings of plants, using a mapping from sequences of symbols to graphics
based on turtle graphics (Prusinkiewicz & Lindenmayer, 1990). It is only natural that
the first application of L-systems to algorithmic composition used turtle graphics to render
an image that was then interpreted into a musical score (Prusinkiewicz, 1986), mapping
523

fiFernndez & Vico

coordinates, angles and edge lengths into musical objects. This approach has been used
by music composers, as Nelsons (1996) Summer Song and Mason and Saffles (1994) idea
of using different rotations and stretchings of the image to implement counterpoint. As a
funny side note, Soddell and Soddell (2000) generated aural renditions of their biological
L-system models, to explore new ways to understand them. Additionally, other composers
used new approaches not dependent upon the graphical interpretation of the L-systems,
such as Morgans (2007) symbolic mapping. One popular is to pre-generate a collection
of short fragments and/or other musical objects, and define an algorithm to interpret the
final sequence of symbols as instructions that transform and arrange the fragments into a
composition. This approach has been used by Langston (1989) and Kyburz (Supper, 2001),
while Edwards (2011) used a more convoluted but ultimately similar mapping.
However, these two approaches (the graphics-to-music and the pre-generated sequences)
only scratch the surface of the technical possibilities to generate music with L-systems; many
other mappings are possible (Worth & Stepney, 2005). In some cases, these mappings can
become exceedingly complex, such as the implementation of Manousakis (2006), whose
L-systems drove a multidimensional automata whose trajectory was then interpreted as
music. While most composers and researchers experimented with context-free L-systems,
McCormack (1996, 2003a) used context-sensitive, parametric L-systems to increase the
expressiveness of the compositions and enable the implementation of polyphony. He also
used a rich and comprehensive mapping from the symbol sequence to the musical score,
interpreting the symbols in the sequence as instructions to modulate the parameters of
an automata driving a MIDI synthesizer, though the grammars were ultimately specified
by hand. DuBois (2003) used a simpler but also rich approach, mapping the symbols
to elemental musical objects (as notes or instruments) or simple transformations applied
to them, using brackets to encode polyphony. He also used L-systems to drive real-time
synthetic accompaniment, by extracting features from the audio signal of a performer (as
the pitch and loudness of the notes), encoding them as symbols to be expanded by L-system
rules, and using the resulting symbol sequences to drive MIDI synthesizers. In spite of these
developments, new mappings based on the images rendered by the turtle method are still
investigated (Wilson, 2009).
L-systems can also be used to implement tools to assist the compositional process by
solving just a part of it, as generating more complex arpeggios than off-the-shelf arpeggiators
(McGuire, 2006), or providing just the base chord progression of a composition (Watson,
2008), sometimes applying elements of music theory to implement the rules (Gogins, 2006).
Another area of research is the implementation of real-time improvisers, either for limited
parts of the composition process (Bulley & Jones, 2011), or for accompaniment (Pestana,
2012).
3.1.2 Grammars and Evolutionary Algorithms
Evolutionary methods have also been used together with grammars. In this case, a common
approach is to evolve the grammatical rules, as in GeNotator (Thywissen, 1999), in which
the genomes are grammars specified through a GUI and the fitness function is interactive
(the user assigns the fitness of the grammars). A more exotic example by Khalifa et al.
524

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Thywissen, 1999
(GeNotator)

structure

the grammar is the genotype
in an interactive evolutionary algorithm

Khalifa et al., 2007

melody

the grammar is part of the fitness function

Ortega et al., 2002

melody

grammatical evolution

Reddin et al., 2009

melody

grammatical evolution

Shao et al., 2010
(Jive)

melody

interactive grammatical evolution

Bryden, 2006

melody

interactive evolutionary algorithm with L-systems

Fox, 2006

melody

interactive evolutionary algorithm with L-systems

Peck, 2011

melody

evolutionary algorithm with L-systems

Dalhoum et al., 2008

melody

grammatical evolution with L-systems

Table 3: References for Section 3.1.2, in order of appearance.
(2007) uses the grammar as part of the fitness function instead of the generation of the
compositions.
Some evolutionary methods are specifically adapted to handle grammars. This is the
case of grammatical evolution, a method in which the genomes are sequences of numbers
or symbols controlling the application of rules of a pre-defined (and possibly stochastic)
grammar. The most common approach is to represent the music as the output from the
grammar, which can range from very general to specific for a given music style. Several
instances of this method have been developed: from an early, bare-bones implementation
(Ortega et al., 2002) to a more elaborated one using a simple fitness function based on general concepts from music theory (Reddin et al., 2009). However, there are other approaches,
such as the system implemented by Shao et al. (2010), whose grammar is used to produce
intermediate code, which is then used to generate the music.
As in the more general case of formal grammars, evolutionary algorithms have been
used to create L-systems. However, most examples use an interactive fitness function (the
fitness is assigned by a human), like the basic implementation of Bryden (2006) and the
approach based on genetic programming used by Fox (2006). Others use very simplistic
fitness functions, with modest results (Peck, 2011). A more sophisticated approach was
used by Dalhoum et al. (2008), using grammatical evolution with a fitness function based on
a distance metric of the synthesized compositions to a pre-specified corpus of compositions.
3.1.3 Related Methods
Finally, this subsection presents a few examples that do not exactly use grammars, but
utilize similar or borderline approaches.
The first one is the application of Kohonens Dynamically Expanding Context (DEC)
method to algorithmic composition (Kohonen et al., 1991). In DEC, a set of music examples
is fed to the algorithm, which infers a model from the structure of the examples that may
be construed as a stochastic context-sensitive grammar. The model is as parsimonious as
possible, that is, the rules have as little contextual information as possible. Then, the
inferred grammar is used to generate new compositions. Drewes and Hgbergs (2007)
525

fiFernndez & Vico

Reference

Composition task

Comments

Kohonen et al., 1991

melody

Uses Kohonens Dynamically Expanding Context

Drewes & Hgberg, 2007

generate variations on
a melody

applies tree-based algebraic transformations

Cope, 1992 (EMI),
2000 (SARA, ALICE),
2005 (Emily Howell)

melody

EMI uses Augmented Transition Networks

Table 4: References for Section 3.1.3, in order of appearance.
work is also borderline, using regular tree grammars to generate a basic scaffold that is
then modified by algebraic operations to generate a final music composition.
But the more famous example in this category is Copes (1992) Experiments in Musical
Intelligence (EMI), a software application able to analyze a set of musical compositions in a
specific style (for example, Bachs) and to derive an Augmented Transition Network (ATN),
i.e., a finite state automaton able to parse relatively complex languages. EMI then applies
pattern-matching algorithms to extract signatures or short musical sequences characteristic
of the style of the set of examples being analyzed, determining how and when to use these
signatures in compositions with that style. After this analysis, the synthesis phase generates
new music compositions that comply with the specifications encoded in the inferred ATN,
with quite impressive results. He iterated EMIs design in other applications, like SARA
and ALICE (Cope, 2000), but ultimately tried a new approach with yet another application,
Emily Howell. Cope (2005) reported that Emily Howell developed a unique style by
a process of trial and error guided by human input; however, other researchers (Wiggins,
2008) have disputed the validity of his methodology.
3.2 Symbolic, Knowledge-Based Systems and Related Methods
Here, knowledge-based system is used as an umbrella term encompassing various rule-based
systems under several different paradigms, with the common denominator of representing
knowledge as more or less structured symbols. Since knowledge about musical composition
has traditionally been structured as sets of more or less formalized rules for manipulating
musical symbols (Anders & Miranda, 2011), knowledge-based and rule systems come as a
natural way to implement algorithmic composition. In fact, it is extremely common for
algorithmic composition systems to include some kind of composition rules at some point
of the workflow. The most known early work on algorithmic composition is an example:
classical rules for counterpoint were used in the generation of the first and second movements
of the Illiac Suite (Hiller & Isaacson, 1958). Because of this, this subsection is mostly
confined to the description of systems with strong foundations in AI (as expert systems),
sidestepping to a certain degree the works of composers that are difficult to categorize,
because of the ad hoc nature of their approaches and the very different language they use.
Starting with an exposition of early work, Gills (1963) paper, already cited in Section 2.1, presented the first application of classical AI heuristics to algorithmic composition: he used a hierarchical search with backtracking to guide a set of compositional rules
from Schoenbergs twelve-tone technique. Another notable example is Rothgebs (1968)
Ph.D. thesis: he encoded in SNOBOL a set of rules extracted from eighteenth century
526

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Gill, 1963

Schoenbergs twelve-tone
technique

hierarchical search with backtracking

Rothgeb, 1968

unfigured bass

implemented in SNOBOL

Thomas, 1985
(Vivace)

four-part harmonization

implemented in LISP

Thomas et al., 1989
(Cantabile)

Indian raga style

implemented in LISP

Steels, 1986

four-part harmonization

uses Minskys frames

Riecken, 1998
(Wolfgang)

melody

uses Minskys SOM

Horowitz, 1995

jazz improvisation

uses Minskys SOM

Fry, 1984
(Flavors Band)

jazz improvisation and other
styles

phrase processing networks (networks of
agents encoding musical knowledge)

Gjerdingen, 1988
(Praeneste)

species counterpoint

implements a theory of how composers work

Schottstaedt, 1989

species counterpoint

constraint-based search with backtracking

Lthe, 1999

piano minuets

set of rules extracted from a classical textbook

Ulrich, 1977

jazz improvisation

also uses a grammar (for jazz chords)

Levitt, 1981

jazz improvisation

Criticized by Horowitz (1995)
for being overly primitive

Hirata & Aoyagi, 1988

jazz improvisation

uses logic programming

Rowe, 1992
(Cypher)

interactive jazz
improvisation

uses Minskys SOM

Walker, 1994
(ImprovisationBuilder)

interactive jazz
improvisation

implemented in SmallTalk

Ames & Domino, 1992
(Cybernetic Composer)

jazz, rock

also uses Markov chains for rhythm

Table 5: References for Section 3.2, in order of appearance.
music treatises to harmonize the unfigured bass, that is to say, determine adequate chords
from a sequence of bass notes.14 He discovered that the classical rules were incomplete and
incoherent to a certain extent.
These were recurring problems for many others implementing rules of composition
straight from musical theory. For example, Thomas (1985) designed a rule-based system
for four-part chorale harmonization implemented in Lisp15 , with the intent of clarifying the
musical rules she taught to her students. Later, she designed another rule system (Thomas
et al., 1989) for simple melody generation in the Indian raga style. Another example in
harmonization is the use of Minskys paradigm of frames by one of his students to encode a
set of constraints to solve a relatively simple problem from tonal harmony, finding a passing chord between two others (Steels, 1979), and later to tackle the problem of four-part
harmonization (Steels, 1986). Minsky developed other paradigms, such as K-lines and the
14. It should be noted that this stems from the practice of not completely specifying the harmonization, a
problem that performers were expected to solve by improvisation.
15. All the systems discussed in this paragraph were implemented in Lisp.

527

fiFernndez & Vico

Reference

Composition task

Comments

Schwanauer, 1993
(MUSE)

four-part
harmonization

presents the learning techniques in a similar way to
Roads (1985, sect. 8.2)

Widmer, 1992

harmonization

based on user evaluations of a training corpus

Spangler, 1999

real-time four-part
harmonization

prioritizes harmonic errors by severity,
in order to refine the results

Morales & Morales, 1995

species counterpoint

uses logic programming

Table 6: References for Section 3.2.1, in order of appearance.
Society of Mind (SOM), which also influenced the work on algorithmic composition of two
of his students, Riecken and Horowitz. Riecken (1998) used them in a system that composed monophonic melodies according to user-specified emotional criteria, while Horowitz
(1995) used them in a system that improvised jazz solos. Frys (1984) phrase processing
networks, while not directly based on SOM, were specialized procedural representations of
networks of agents implementing musical transformations to encode knowledge about jazz
improvisation and other styles.
Other researchers have also explored different ways to generate species counterpoint
with rule-based systems: Gjerdingen (1988) implemented a system based on the use of
several pre-specified musical schemata, implementing a theory of how composers work,
while Schottstaedt (1989) used a more formal approach: a constraint-based search with
backtracking. He followed a classical rulebook on species counterpoint, to the point of
bending some rules and creating new ones in order to get as close as possible to the scores
serving as examples in that book. Also on the formal side, Lthe (1999) extracted a set of
rules from a classical textbook for composing minuets.
Other music styles demanded different approaches: as jazz performances are improvisations over existing melodies, knowledge-based systems for jazz were structured as more or
less sophisticated analysis-synthesis engines. For example, the work of Ulrich (1977): his
system analyzed a melody and fitted it to a harmonic structure. Another student of Minsky
(Levitt, 1981) implemented a rule-based jazz improviser formulating some of the rules as
constraints, while Hirata and Aoyagi (1988) encoded the rules in logic programming, trying
to design a more flexible system. Rowe (1992) used a SOM architecture16 for Cypher, an
analysis-synthesis engine able to play jazz interactively with a human performer, notable for
its flexibility and the musical knowledge encoded into it. Also, Walker (1994) implemented
an object-oriented analysis-synthesis engine able to play jazz interactively with a human
performer, and Ames and Domino (1992) implemented a hybrid system (using rules and
Markov chains) for the generation of music in several popular genres.
3.2.1 Rule Learning
While the knowledge implemented in rule-based systems is usually static, part of the knowledge may be dynamically changed or learned. The natural term for this concept is machine
learning, but its meaning is unfortunately vague, because it is used as a catch-all for many
methods, including neural networks and Markov chains.
16. He was not a student of Minsky, though.

528

fiAI Methods in Algorithmic Composition

A few examples of rule-based learning systems have been developed. For example,
Schwanauer (1993) implemented MUSE, a rule-based system for solving several tasks in fourpart harmonization. While the core ruleset was static, a series of constraints and directives
for the composition process where also built in the system, and their application was also
used to dynamically change the rule priorities. Additionally, when the system successfully
solved a task, it was able to deduce new composite rules by extracting patterns of rule
application. Widmer (1992) implemented another example: a system for the harmonization
of simple melodies. It was based on user evaluations of a training corpus: from a hierarchical
analysis of the training melodies and theirs evaluations, it extracted rules of harmonization.
Spangler (1999) implemented a system for generating rule systems for harmonizing fourpart chorales in the style of Bach, with the constraint of doing the harmonization in real
time. The rulesets were generated by analyzing databases of examples with algorithms that
applied formal concepts of information theory for distilling the rules, and the violations of
harmonic rules were prioritized in order to refine the results. Using the framework of logic
programming, Morales and Morales (1995) designed a system that learned rules of classical
counterpoint from musical examples and rule templates.
3.2.2 Rule-Based Methods and Evolutionary Algorithms
The most intuitive way to hybridize rule-based knowledge systems and evolutionary algorithms is to craft a fitness function from the ruleset. This can be done efficiently for domains
whose rules have been adequately codified, and compliance with the rules can be expressed
as a graduated scale, instead of a binary (yes/no) compliance.
A good example is four-part baroque harmonization for a pre-specified melody, which
lends itself particularly well to this approach. McIntyre (1994) extracted a set of rules for
performing this harmonization from classical works, and codified them as a set of scoring
functions. The fitness was a weighted sum of these scores, with a tiered structure: some
scores were not added unless other specific scores had values above some thresholds (because they were more critical or prerequisites to produce good harmonizations). A slightly
different approach was used by Horner and Ayers (1995): they defined two classes of rules:
one for defining acceptable voicings for individual chords, used to enumerate all possible
voicings, and another for defining how the voices are allowed to change between successive chords. An evolutionary algorithm was used to find music compositions, whose search
space was constructed with the enumeration of voicings (first class of rules). The fitness
of each candidate solution was simply the amount of violated rules from the second class.
Phon-Amnuaisuk et al. (1999) also did four-part harmonization using a set of rules to build
the fitness function and musical knowledge to design the genotype and the mutation and
crossover operators, but the lack of global considerations in the fitness function led to modest results. In contrast, Maddox and Otten (2000) got good results implementing a system
very similar to McIntyres (1994), but using a more flexible representation, resulting in a
larger search space of possible individuals, and without the tiered structure in the fitness
function, enabling a less constrained search process.
Another good example is species counterpoint: Polito et al. (1997) extracted rules for
species counterpoint from a classic eighteenth century music treatise, using them to define
fitness functions in a multi-agent genetic programming system: each agent performed a
529

fiFernndez & Vico

Reference

Composition task

Comments

McIntyre, 1994

four-part harmonization

explores several schemes to combine
rules into the fitness function

Horner & Ayers, 1995

four-part harmonization

two stages: enumeration of possible
chord voicings, evolutionary algorithm
for voice-leading rules

Phon-Amnuaisuk et al., 1999

four-part harmonization

criticizes vanilla evolutionary algorithms
for generating unstructured
harmonizations

Maddox & Otten, 2000

four-part harmonization

similar to McIntyres (1994)

Polito et al., 1997

species counterpoint

multi-agent genetic programming system

Gwee, 2002

species counterpoint

fuzzy rules

Table 7: References for Section 3.2.2, in order of appearance.
set of composition or transformation operations on a given melody specified as a seed,
and they cooperated to produce the composition. Gwee (2002) exhaustively studied the
computational complexity of problems related to the generation of species counterpoint
with rulesets, and implemented an evolutionary algorithm whose fitness function was based
on a set of fuzzy rules (although he also experimented with trained artificial neural networks
as fitness functions).
3.2.3 Constraint Satisfaction
Gradually (in a process that spanned the 1980s and 1990s), some researchers on algorithmic
composition with rule-based systems adopted formal techniques based on logic programming. For example, Boenn et al. (2008) used answer set programming to encode rules for
melodic composition and harmonization. However, most of the work on logic programming
has been under a different paradigm: the formulation of algorithmic composition tasks as
constraint satisfaction problems (CSPs). Previously referenced work, as Steelss (1979),
Levitts (1981), Schottstaedts (1989) and Lthes (1999) can be seen as part of a gradual
trend towards the formulation of musical problems as CSPs17 , although constraint logic
programming (CLP) came to be the tool of choice to solve CSPs. Good surveys on CLP
for algorithmic composition have been written by Pachet and Roy (2001) and Anders and
Miranda (2011).
Ebciolu worked for many years in this area, achieving notable results. In a first work
implemented in Lisp (Ebciolu, 1980), he translated rules of fifth-species strict counterpoint
to composable Boolean functions (he had to add rules of his own to bring the system into
producing acceptable results, though), and used an algorithm that produced an exhaustive
enumeration of the compositions satisfying a previously arranged set of rules: basically, he
implemented a custom engine for logic programming in Lisp. Over the next decade, he
the tackled the problem of writing four-part chorales in the style of J. S. Bach. Finally, he
produced CHORAL, a monumental expert system (Ebciolu, 1988), distilling into it 350
rules to guide the harmonization process and the melody generation. To keep the problem
17. While Gills (1963) implementation was formulated as a CSP, it was somewhat primitive by later standards.

530

fiAI Methods in Algorithmic Composition

tractable, he designed a custom logic language (BSL) with optimizations over standard logic
languages, as backjumping. His system received substantial publicity, and was supposed to
reach the level of a talented music student, in his own words.
Following Ebciolus work, many constraint systems have been implemented for harmonization or counterpoint. Tsang and Aitken (1991) implemented a CLP system using Prolog
to harmonize four-part chorales. However, their system was grossly inefficient.18 Ovans and
Davison (1992) described an interactive CSP system for first-species counterpoint, where
a human user drove the search process, and the system constrained the possible outputs
(according to counterpoint rules) as the search progressed. They took care of efficiency
by using arc-consistency in the resolution of the constraints. Ramrez and Peralta (1998)
solved a different problem: given a monophonic melody, their CLP system generated a
chord sequence to harmonize it. Phon-Amnuaisuk (2002) implemented a constraint system
for harmonizing chorales in the style of J. S. Bach, but with an innovation over previous
systems: to add knowledge to the system about how to apply the rules and control the
harmonization process explicitly, thus modulating the search process in an explicit and
flexible way. Anders and Miranda (2009) analyzed a Schoenbergs textbook on the theory
of harmony, programming a system in Strasheela (see below) to produce self-contained harmonic progressions, instead of harmonizing pre-existing melodies, as most other constraint
systems do.
While many CLP systems have been implemented to solve classical problems in harmonization or counterpoint, some researchers have studied the application of CLP techniques to
different problems. In a very simple application, Wiggins (1998) used a CLP system to generate short fragments of serial music. Zimmermann (2001) described a two-stage method,
where both stages used CLP: the first stage (AARON) took as input a storyboard to specify the mood of a composition as a function of time, and generated a harmonic progression
and a sequence of directives. The second (COMPOzE) generated a four-part harmonization
according to the previously arranged progression and directives; the result was intended as
background music. Laurson and Kuuskankare (2000) studied constraints for the instrumentation19 of guitars and trumpets (i.e., constraints for composing music easily playable
in these instruments). Chemillier and Truchet (2001) analyzed two CSPs: a style of Central African harp music, and Ligeti textures. They used heuristic search in their analyzes
instead of backtracking, heralding OMClouds approach to constraint programming (see
below). Sandred (2004) proposed the application of constraint programming to rhythm.
Several general-purpose constraint programming systems for algorithmic composition
have been proposed (i.e., languages and environments to program the constraints). One
of the earliest examples was Courtots (1990) CARLA, a CLP system for generating polyphonies with a visual front-end and a rich, extendable type system designed to represent
relationships between different musical concepts. Pachet and Roy (1995) implemented another general-purpose musical CLP (Backtalk) in an object-oriented framework (MusES),
designing a generator of four-part harmonizations on top of it. Their key contribution
was a hierarchical arrangement of constraints on notes and chords, dramatically decreasing the (both cognitive and computational) complexity of the resulting constraint system.
18. In spite of using just 20 rules, it required up to 70 megabytes of memory to harmonize a phrase of 11
notes.
19. That is to say, take into account the way an instrument is played when composing its part.

531

fiFernndez & Vico

Reference

Composition task

Comments

Boenn et al., 2008

melody and harmonization

answer set programming

Ebciolu, 1980

species counterpoint

implemented in LISP

Ebciolu, 1988
(CHORAL)

four-part harmonization

implemented in a custom logic language (BSL)

Tsang & Aitken, 1991

four-part harmonization

very inefficient

Ovans & Davison, 1992

species counterpoint

interactive search

Ramrez & Peralta, 1998

melody harmonization

simpler constraint solver

Phon-Amnuaisuk, 2002

four-part harmonization

explicit control over the search process

Anders & Miranda, 2009

Schoenbergs Theory of
Harmony

implemented in Strasheela

Wiggins, 1998

Schoenbergs twelve-tone
technique

very simple demonstration

Zimmermann, 2001
(Coppelia)

structure, melody,
harmonization, rhythm

two stages: harmonic plan (Aaron) and
execution (Compoze)

Laurson & Kuuskankare,
2000

guitar and trumpet
instrumentation

implemented with PWConstraints

Chemillier & Truchet, 2001

African harp and Ligeti
textures

implemented in OpenMusic

Sandred, 2004

rhythm

implemented in OpenMusic

Courtot, 1990
(CARLA)

polyphony, general purpose

early general-purpose system

Pachet & Roy, 1995
(BackTalk)

four-part harmonization

implemented in MusEs

Rueda et al., 1998

polyphony, general purpose

describes PWConstraints (implemented in
PatchWork) and Situation (implemented in
OpenMusic)

Rueda et al., 2001

general purpose

describes PiCO
describes ntcc

Olarte et al., 2009

general purpose

Allombert et al., 2006

interactive improvisation

uses ntcc

Rueda et al., 2006

interactive improvisation

uses ntcc and Markovian models

Pachet et al., 2011

melody

integrates Markovian models and constraints

Truchet et al., 2003

general purpose

describes OMClouds

Anders, 2007

general purpose

describes Strasheela

Sandred, 2010

general purpose

describes PWMC.
Implemented in PatchWork

Carpentier & Bresson, 2010

orchestration

uses multi-objective optimization
to discover candidate solutions.
Interfaces with OpenMusic and MAX

Yilmaz & Telatar, 2010

harmonization

fuzzy logic

Aguilera et al., 2010

species counterpoint

probabilistic logic

Geis & Middendorf, 2008

four-part harmonization

multi-objective Ant Colony Optimization

Herremans & Sorensena,
2012

species counterpoint

variable neighborhood with tabu search

Davismoon & Eccles, 2010

melody, rhythm

uses simulated annealing to combine
constraints with Markov processes

Martin et al., 2012

interactive improvisation

implemented in MAX

Table 8: References for Section 3.2.3, in order of appearance.

532

fiAI Methods in Algorithmic Composition

Rueda et al. (1998) reviewed two other early general-purpose systems, PWConstraints and
Situation. PWConstraints was able to (relatively easily) handle problems in polyphonic
composition through a subsystem (score-PMC), while Situation was more flexible and implemented more optimizations in its search procedures. PiCO (Rueda et al., 2001) was
an experimental language for music composition that seamlessly integrated constraints,
object-oriented programming and a calculus for concurrent processes. The idea was to use
constraint programming to specify the voices in a composition, and to use the concurrent
calculus to harmonize them. The authors also implemented a visual front-end to PiCO for
ease of use, Cordial. In a similar way to PiCO, ntcc was another language for constraint
programming that implemented primitives for defining concurrent systems, although it was
not specifically designed for algorithmic composition. ntcc has been proposed to generate
rhythm patterns and as a more expressive alternative to PiCO (Olarte et al., 2009), and
has mainly been used for machine improvisation: Allombert et al. (2006) used it as the
improvisation stage of their two-stage system (the first stage used a temporal logic system
to compose abstract temporal relationships between musical objects, while the ntcc stage
generated concrete music realizations), and Rueda et al. (2006) used ntcc to implement
a real-time system that learned a Markovian model (using a Factor Oracle) from musicians and concurrently applied it to generate improvisations. Not related to ntcc, Pachet
et al. (2011) has also proposed a framework to combine constraint satisfaction and Markov
processes.
OMClouds (Truchet et al., 2003) was another general-purpose (but purely visual) constraint system for composition, but its implementation set it apart from most other formal
systems: internally, the constraints are translated to cost functions. Instead of the optimized tree search with backtracking usual in CLP, an adaptive tabu search was performed,
seeking to minimize a solution with minimal cost. This avoids some problems inherent to
constraint programming, such as overconstraining, but it cannot be guaranteed to completely navigate the search space. Anders (2007) implemented Strasheela, a system that
was expressly designed to be highly flexible and programmable, aiming to overcome a perceived limitation of previous general-purpose systems: the difficulty to implement complex
with constraints related to multiple aspects of the compositions process. Finally, another
purely visual constraint system, PWMC, was proposed by Sandred (2010) to overcome perceived limitations of score-PMC. It was able to handle constraints concerning not only pitch
structure as score-PMC, but also rhythm and metric structure.
It should be stressed that, while CLP has become the tool of choice to solve CSPs,
other approaches are also used. Previously cited OMClouds is just one of these. Carpentier
and Bresson (2010) implemented a mixed system for orchestration that worked in a curious way: the user fed the system with a target sound and a set of symbolic constraints; a
multi-objective evolutionary algorithm found a set of orchestration solutions matching the
target sound, and a local search algorithm filtered out the solutions not complying with
the constraints. Yilmaz and Telatar (2010) implemented a system for simple constraint
harmonization with fuzzy logic, while Aguilera et al. (2010) used probabilistic logic to solve
first-species counterpoint. More exotic solutions have been proposed, as the use of Ant
Colony Optimization with a multi-objective approach to solve the constraints of Baroque
harmonization (Geis & Middendorf, 2008), variable neighborhood with tabu search to solve
soft constraints for first-species counterpoint (Herremans & Sorensena, 2012), or simulated
533

fiFernndez & Vico

Reference

Composition task

Comments

Pereira et al., 1997

Baroque music

hierarchical analysis and representation

Ribeiro et al., 2001
(MuzaCazUza)

Baroque music

generates a melody from a harmonic line

Ramalho & Ganascia, 1994

jazz improvisation

uses a rule-based system for analysis

Parikh, 2003

jazz improvisation

also uses a rule system to analize music

Eigenfeldt & Pasquier, 2010

jazz chord progressions

also uses Markovian models

Sabater et al., 1998

harmonization

also uses a rule system

Table 9: References for Section 3.2.4, in order of appearance.
annealing to combine constraints with Markov processes (Davismoon & Eccles, 2010). Finally, Martin et al. (2012) presented an even more exotic approach: a real-time music
performer that reacted to its environment. While some of the aspects of the music where
controlled by Markov chains, others where expressed as a CSP. To solve this CSP in real
time, a solution was calculated at random (but quickly) using binary decision diagrams.
3.2.4 Case-Based Reasoning
Case-based reasoning (CBR) is another formal framework for rule-based systems. In the
CBR paradigm, the system has a database of cases, that can be defined as instances of
a problem with their corresponding solutions. Usually, a case also contains structured
knowledge about how the problem is solved in that case. When faced with a new problem,
the system matches it against the case database. Unless the new problem is identical to
one recorded in the case database, the system will have to select a case similar to the new
problem, and adapt the corresponding solution to the new problem. If the new solution is
deemed appropriate, a new case (recording the new problem along with the new solution)
may be included in the database.
Several researchers have used CBR for algorithmic composition. Pereira et al. (1997)
implemented a system that generated its case database from just three Baroque music
pieces, which were analyzed into hierarchical structures; the cases were their nodes. The
system composed just the soprano melodic line of the piece, searching for similar cases in its
case database. The results were comparable to the output of a first-year student, according
to music experts consulted by the authors. An intersecting set of researchers implemented
a simpler CBR composing system (Ribeiro et al., 2001) that generated a melody from a
harmonic line, this time with a case database generated from just six Baroque pieces. Cases
were represented in a different way, tough: each case represented the rhythm, the melody
and other attributes associated to a chord in a given context. To generate a new music piece,
a harmonic line was specified, and the system fleshed out the music piece by matching the
cases to the harmonic line.
Hybrid systems have also been proposed. Ramalho and Ganascia (1994) proposed a jazz
improviser that used a rule system to analyze incoming events (for example, the ongoing
sequence of chords) and a CBR engine to improvise. The case database was assembled by
extracting patterns from transcriptions of jazz recordings, and consisted of descriptions of
contexts and how to play in these contexts. During the improvisation, the current context
534

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Haus & Sametti, 1991
(Scoresynth)

melody

Petri nets

Lyon, 1995

melody

Petri nets to encode Markov chains

Holm, 1990

melody, sound synthesis

inspired in CSP process algebra

Ross, 1995
(MWSCCS)

melody

custom process algebra

Rueda et al., 2001

general purpose

describes PiCO

Allombert et al. (2006)

interactive improvisation

uses ntcc

Rueda et al., 2006

interactive improvisation

uses ntcc and Markovian models

(Olarte et al., 2009)

general purpose, rhythms

describes ntcc

Table 10: References for Section 3.2.5, in order of appearance.

was analyzed by the rule system, and those cases applying in the current context were
extracted from the database and combined to determine the output of the improviser. Considering that Ramalho and Ganascias system was too inflexible, Parikh (2003) implemented
another jazz improviser, intending to use a large case database containing jazz fragments
from various sources, in order to get a system with a style of its own. Eigenfeldt and
Pasquier (2010) used a case-based system to generate variable-order Markov models for
jazz chord progressions.
Outside the jazz domain, a hybrid system for harmonizing melodies of popular songs
was implemented by Sabater et al. (1998): given a melody, the system sequentially decided
the chords to harmonize it. If the CBR module failed to match a case, the system fell back
to a simple heuristic rule system to select an appropriate chord. As the harmonized output
was added to the case database, the CBR module gradually learned over time from the rule
system.
3.2.5 Concurrency Models
Concurrency models can be described as formal languages to specify, model and/or reason
about distributed systems. They provide primitives to precisely define the semantics of
interaction and synchronization between several entities. Their main application has been
modeling and designing distributed or concurrent computer systems, but they have also
been used as languages to partially or fully model the composition process, because music
composition can be formulated as an endeavor to carefully synchronize streams of music
events produced by several interacting entities. Concerning algorithmic composition, the
most used concurrency models have been Petri nets and several kinds of process algebras,
also known as process calculi. Detailed descriptions of these models are beyond the scope of
this survey; see for example Reisigs (1998) book on Petri nets and Baetens (2005) survey
on process algebras for more information.
Petri nets have been used as the basis for Scoresynth (Haus & Sametti, 1991), a visual
framework for algorithmic composition in which Petri nets were used to describe transformations of musical objects (sequences of notes and musical attributes), and the synchronization
535

fiFernndez & Vico

between musical objects was implicit in the structure of the net. Petri nets have also been
used as an efficient and compact way to implement Markov chains (Lyon, 1995).
Process algebras were first used for algorithmic composition by Holm (1990), although
his model (inspired by Hoares algebra, CSP) was more geared towards sound synthesis
than music composition. A more proper example is Rosss (1995) MWSCCS, an extension (adding concepts for music composition) of a previously existing algebra (WSCCS).
Specifications for algorithmic composition written in MWSCCS were meant to resemble
grammatical specifications, but with a richer expressive power. Later examples have also
been cited in Section 3.2.3, as the PiCO language (Rueda et al., 2001), which integrated
logical constraints and a process algebra. Also cited in that Section, ntcc is a process algebra that has been used to implement machine improvisation (Allombert et al., 2006) and
to drive a Markovian model (using a Factor Oracle) for real-time machine learning and
improvisation (Rueda et al., 2006). It has also been proposed to generate rhythm patterns,
and as a more expressive alternative to PiCO (Olarte et al., 2009).
3.3 Markov Chains and Related Methods
Conceptually, a Markov chain is a simple idea: a stochastic process, transiting in discrete
time steps through a finite (or at most countable) set of states, without memory: the next
state depends just on the current state, not on the sequence of states that preceded it
or on the time step. In their simplest incarnations, Markov chains can be represented as
labeled directed graphs: nodes represent states, edges represent possible transitions, and
edge weights represent the probability of transition between states. However, Markov chains
are more commonly represented as probability matrices.
When Markov chains are applied to music composition, the probability matrices may
be either induced from a corpus of pre-existing compositions (training), or derived by hand
from music theory or by trial-and-error. The former is the most common way to use them in
research, while the latter is more used in software tools for composers. An important design
decision is how to map the states of the Markov chain to musical objects. The simplest
(but fairly common) mapping just assigns a sequential group of notes to each state, with
the choice of just one note (instead of a larger sequence) being fairly common.
It is also common to extend the consideration of the current state: in an n-th order
Markov chain, the next state depends on the last n states, not just the last one. As a
consequence, the probability matrix has n + 1 dimensions. In algorithmic composition,
Markov chains are mostly used as generative devices (generating a sequence of states), but
they can also be used as analysis tools (evaluating the probability of a sequence of states).
In the latter case, the term n-gram is also used, though strictly speaking it refers to a
sequence of N states.
Markov chains were a very popular method in the early years of algorithmic composition.
Early examples have already been reviewed in Section 2.1; additionally, Ames (1989) also
provides a good survey. However, Markov chains generated from a corpus of pre-existing
compositions captured just local statistical similarities, and their limitations soon became
apparent (Moorer, 1972): low-n Markov chains produced strange, unmusical compositions
that wandered aimlessly, while high-n ones essentially rehashed musical segments from the
corpus and were also very computationally expensive to train.
536

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Tipei, 1975

melody

Markov chains are part of a larger,
ad hoc system

Jones, 1981

melody

very simple introduction for composers

Langston, 1989

melody

dynamic weights

North, 1991

melody

Markov chains are part of a larger,
ad hoc system

Ames & Domino, 1992
(Cybernetic Composer)

jazz, rock

uses Markov chains for rhythms

Visell, 2004

real-time generative art
installation

Liberal use of the concept of HMM.
Implemented in MAX

Zicarelli, 1987
(M and Jam Factory)

interactive improvisation

commercial GUI applications
alternative representation for transition
matrices. Implemented in athenaCL

Ariza, 2006
Ponsford et al., 1999

composing sarabande pieces

adds symbols to expose the structure
of the pieces

Lyon, 1995

melody

implements Markov chains
with Petri nets

Verbeurgt et al., 2004

melody

two stages: a Markovian model
and an artificial neural network

Thom, 2000
(BoB)

interactive jazz improvisation

statistical machine learning

Lo & Lucas, 2006

melody

evolutionary algorithm, Markov chains
used in the fitness function

Werner & Todd, 1997

melody

co-evolutionary algorithm, Markov
chains used as evolvable fitness functions

Thornton, 2009

melody

grammar-like hierarchy
of Markov models

Cruz-Alczar and Vidal-Ruiz
(1998)

melody

analysis with grammatical inference,
generation with Markovian models

Gillick et al. (2009)

jazz improvisation

analysis with grammatical inference,
generation with Markovian models

Eigenfeldt & Pasquier, 2010

jazz chord progressions

uses case-based reasoning

Davismoon & Eccles, 2010

melody, rhythm

uses simulated annealing to combine
constraints with Markov processes

Pachet et al., 2011

melody

integrates Markovian models and
constraints

Grachten, 2001

jazz improvisation

integrates Markovian models
and constraints

Manaris et al., 2011

interactive melody improvisation

Markov chains generate candidates
for an evolutionary algorithm

Wooller & Brown, 2005

transitioning between two melodies

alternates Markov chains
from the two melodies

Table 11: References for Section 3.3, in order of appearance.
Because of this, Markov chains came to be seen as a source of raw material, instead of a
method to truly compose music in an automated way, except for some specialized tasks such
537

fiFernndez & Vico

as rhythm selection (McAlpine et al., 1999). Therefore, while research interest in Markov
chains receded in subsequent years as these limitations became apparent and other methods
were developed, they remained popular among composers. However, citing even a relevant
subset of all the works were composers use Markov chains as part of their compositional
process would inflate the reference list beyond reasonable length. A few typical examples of
Markov chains used by composers (sometimes as part of a larger automatic compositional
framework or software system) are the papers of Tipei (1975), Jones (1981), Langston (1989,
although he used dynamically computed weights), North (1991) and Ames and Domino
(1992). It should be noted that composers sometimes deconstruct formal methods to adapt
them to their own purposes, as when Visell (2004) used the concept of a Hidden Markov
Model (described below) to implement a manually-tuned real-time generative art system.
In addition, many software suites use Markov chains to provide musical ideas to composers, even if the probabilities are specified by hand instead of generated from a corpus.
Ariza (2006) gives a compact list of software suites and experimental programs using Markov
chains, while his thesis (Ariza, 2005b) provides a comprehensive view of the field. Much
has been done for usability in this field, by using GUI interfaces (Zicarelli, 1987), but also
developing more effective ways to encode the probability matrices, for example as compact
string specifications (Ariza, 2006).
However, novel research on Markov chains for algorithmic compositions has still been
carried out in several ways. For example, Ponsford et al. (1999) used a corpus of sarabande
pieces (relatively simple dance music) to generate new compositions using Markov models20 ,
but with a pre-processing stage to automatically annotate the compositions of the corpus
with symbols to make explicit their structure, and a post-processing stage using a template
to constrain the structure of the synthesized composition, in order to generate minimally
acceptable results. Another way is the hybridization of Markov chains with other methods.
For example, Lyon (1995) used Petri nets as an efficient and compact way to implement
Markov chains, while Verbeurgt et al. (2004) used Markov chains21 to generate a basic
pattern for the melody, which was then refined with an artificial neural network. In the
BoB system (Thom, 2000), Markov chains were trained by statistical learning: from a set of
jazz solos, statistical signatures were extracted for pitches, melodic intervals and contours.
Then, these signatures were used to define the transition probabilities of a Markov chain
whose output was sampled to generate acceptable solos. Lo and Lucas (2006) trained
Markov chains with classic music pieces, but, instead of generating compositions with them,
used them as fitness evaluators in an evolutionary algorithm to evolve melodies encoded
as sequences of pitches. Werner and Todd (1997) also used Markov chains to evaluate
simple (32-note) melodies, but with the particularity that the chains themselves were also
subject to evolution, to investigate sexual evolutionary dynamics. Thornton (2009) defined
a set of grammar-like rules from an existing composition, inferring a hierarchy of Markov
models to use statistical patterns of the analyzed composition at multiple levels. As already
mentioned in Section 3.1, Cruz-Alczar and Vidal-Ruiz (1998) and Gillick et al. (2009) used
grammatical inference with Markovian models. Regarding symbolic methods, Eigenfeldt
and Pasquier (2010) used a case-based system to generate Markov processes for jazz chord
20. Their work is commonly cited in the literature as grammatical, but their methodology is thoroughly
statistical.
21. Also reviewed in Section 3.4.

538

fiAI Methods in Algorithmic Composition

progressions, (Davismoon & Eccles, 2010) used simulated annealing to combine constraints
and Markov processes, and Pachet et al. (2011) proposed a framework to combine Markovian
generation of music with rules (constraints) to produce better results.
Additionally, Markov chains remained a feasible option for restricted problems (for example, real-time performances, as jazz improvisation), as their limitations were less apparent
in these cases than in the generation of whole compositions. For example, Grachten (2001)
developed a jazz improviser where Markov chains generated duration and pitches, and then a
system of constraints refined the output, and pre-defined licks (short musical patterns) were
inserted at appropriate times. Manaris et al. (2011) also implemented an improviser, using a
Markov model trained with user input to generate a population of candidate melodies, feeding them into an evolutionary algorithm, whose fitness function rewarded melodies whose
metrics were similar to the user inputs metrics. A different (but also restricted) problem
was studied by Wooller and Brown (2005): applying Markov chains to generate musical
transitions (morphings) between two different pieces in a simple application of non-linear
music, by stochastically alternating between two Markov chains, each one trained with one
of the pieces.
3.3.1 Related Methods
More sophisticated Markovian models (and related statistical methods; see the survey in
Conklin, 2003) have also been applied for algorithmic composition, as in Pachets (2002)
Continuator, a real-time interactive music system. The Continuator departs from common
Markov chain implementations in that it uses variable-order (also known as mixed-order)
Markov chains22 , which are not constrained to a fixed n value, and can be used to get the best
of low and high-n chains. Conklin and Witten (1995) implemented a sophisticated variableorder scheme23 , whose main feature was the consideration in parallel of multiple viewpoints
or sequences of events in the compositions (for example, pitches, durations, contours, etc.),
instead of integrating them all in a unique sequence of symbols, as it was common for most
implementations of Markov chains. Variable-order Markov chains have also been used as
part of a larger real-time music accompaniment system (Martin et al., 2012). Other variableorder schemes used in algorithmic composition, formulated in a machine learning framework,
are Prediction Suffix Trees (PSTs, Dubnov et al., 2003), more space-efficient structures like
Factor Oracles 24 (Assayag & Dubnov, 2004), and Multiattribute Prediction Suffix Graphs
(MPSGs, Trivio Rodrguez & Morales-Bueno, 2001), which can be considered an extension
of PSTs to consider multiple viewpoints as in Conklin and Wittens work. Sastry (2011)
also used multiple viewpoints and PSTs to modelize Indian tabla compositions, though his
model could also be used to generate new compositions.
Hidden Markov Models (HMMs) also are generalizations of Markov chains that have
been used for algorithmic composition. A HMM is a Markov chain whose state is unobservable, but some state-dependent output is visible. Training a HMM involves not only
22. It should be noted that Kohonens method (Kohonen et al., 1991), reviewed in Section 3.1.3, is similar
(in some ways) to variable-order chains.
23. Conklin and Wittens method has also been described as grammatical, but they are included here because
their emphasis in formal statistical analysis.
24. Also implemented with a concurrent constraint paradigm by Rueda et al. (2006). See Section 3.2.3 and
Section 3.2.5 for more details.

539

fiFernndez & Vico

Reference

Composition task

Comments

Pachet, 2002
(Continuator)

interactive improvisation

variable-order

Conklin & Witten, 1995

Bach chorales

multiple viewpoint systems

Martin et al., 2012

interactive improvisation

variable-order; implemented in MAX

Dubnov et al., 2003

melody

Prediction Suffix Trees.
Implemented in OpenMusic

Rueda et al., 2006

interactive improvisation

uses ntcc and Factor Oracles

Assayag & Dubnov, 2004

melody

Factor Oracles.
Implemented in OpenMusic

Trivio Rodrguez &
Morales-Bueno, 2001

melody

Multiattribute Prediction Suffix Graphs

Sastry, 2011

improvisation of tabla rhythms

multiple viewpoints and Prediction
Suffix Trees.
Implemented in MAX

Farbood & Schoner, 2001

species counterpoint

Hidden Markov Models

Biyikoglu, 2003

four-part harmonization

Hidden Markov Models

Allan, 2002

four-part harmonization

Hidden Markov Models

Morris et al., 2008
(SongSmith)

melody harmonization

Hidden Markov Models

Schulze, 2009
(SuperWillow)

melody, rhythm, two-voice
harmonization

Hidden Markov Models
and Prediction Suffix Trees

Yi & Goldsmith, 2007

four-part harmonization

Markov Decision Processes

Martin et al., 2010

interactive improvisation

Partially Observable
Markov Decision Processes

Table 12: References for Section 3.3.1, in order of appearance.
determining a matrix of transition probabilities, but also a matrix of output probabilities
(that is, for each state, the probability of each possible output). Then, given a sequence
of outputs, it is possible to compute the most likely sequence of states to produce that sequence of outputs, using the Viterbi dynamic programming algorithm. In this way, HMMs
find a globally optimized sequence of states, while simpler Markov methods perform just local optimization. When applied to algorithmic composition, HMMs are appropriate to add
elements to an existing composition (most commonly, counterpoint and harmonization),
given a set of pre-existing examples: the composition is modeled as a sequence of outputs
of the HMM, and the additions are computed as the most likely sequence of states of the
HMM.
Farbood and Schoner (2001) implemented the earliest example of a HMM for algorithmic
composition: they trained a second-order HMM to generate Palestrina-style first-species
counterpoint (the simplest way to write counterpoint), defining the training set from rules
used to teach counterpoint. A related problem is to train HMMs with a set of chorale
harmonizations in the style of J.S. Bach in order to get more Bach-like harmonizations.
This problem has been researched by Biyikoglu (2003) and Allan (2002); the latter divided
the problem of harmonization into the same three subtasks as in HARMONET (Hild et al.,
1992). For Microsofts SongSmith software, Morris et al. (2008) trained a HMM with
540

fiAI Methods in Algorithmic Composition

300 lead sheets (specifications for song melodies) to generate chords to accompany a userspecified vocal melody, parametrizing the resulting system with a very intuitive interface
for non-technical users. Schulze (2009) generated music in several styles using mixed-order
Markov chains to generate the melodies, and HMMs to harmonize them.
Markov Decision Processes (MDPs) are another generalization of Markov models, in
which an agent maximizes some utility function by taking actions to probabilistically influence the next state, and Partially Observable MDPs (POMDPs) represent the corresponding
generalization of HMMs. Experimental systems for algorithmic composition have been implemented with MDPs (Yi & Goldsmith, 2007) and POMDPs (Martin et al., 2010), though
it is not clear that these sophisticated models offer definitive advantages over simpler ones.
3.4 Artificial Neural Networks and Related Methods
Artificial Neural Networks (ANNs) are computational models inspired in biological neural
networks, consisting of interconnected sets of artificial neurons: very simple computational
devices that aggregate numeric inputs into a single numeric output using a (generally)
simple but nonlinear function. Some neurons have connections that are set externally
(input connections), while other have output signals intended to be read as the result
of the networks computation (output connections). Typically, neurons are organized in
recurrent networks (some or all neurons have inputs that come from other neurons) with
several interconnected layers, and many variations can be found in the literature. ANNs
are typically used as a machine learning method, using a set of examples (input patterns)
to train the network (i.e., to set the weights of the connections between neurons), in order
to use it to recognize or generate similar patterns. Effectively, this means that neural
networks need a pre-existing corpus of music compositions (all of them in a very similar
style, generally); therefore they can at most imitate the style of the training examples. Most
papers use a supervised learning approach, meaning that the examples in the training set
are associated with a signal, and the ANN learns this association. An important aspect
of ANN design is the modelization of musical composition, that is, the mapping between
music or music notation and the inputs and outputs of the network. Another important
aspect is the way in which compositions are fed to the ANNs: they may be presented as
temporal patterns in the network inputs, which are usually windowed in segments, but in
some cases they are fed at once (as wholes) to the ANNs (these implementations do not
scale well, though, because of the big ANNs needed to model long compositions).
ANNs were first used during the 1970s and 1980s to analyze musical compositions, creating artificial models of cognitive theories of music (Todd & Loy, 1991), but they were later
adapted for music composition. The first example was implemented by Todd (1989), who
used a three-layered recurrent ANN designed to produce a temporal sequence of outputs
encoding a monophonic melody, each output signal of the network representing an absolute
pitch. Given a set of one or more composition examples, the ANN was trained to associate
a single input configuration to the output temporal sequence of the corresponding composition. Then, feeding input configurations different to the ones used during the training
created melodies interpolated between the ones used during the training. If just one melody
was used during the training, the result was an extrapolation from it. Later that year, Duff
(1989) published another early example, but using a different approach, encoding relative
541

fiFernndez & Vico

Reference

Composition task

Comments

Todd, 1989

melody

three layers, recurrent

Duff, 1989

melody

two layers, recurrent

Mozer, 1991
(CONCERT)

melody

psychologically-grounded representation
of pitch
feedforward model, used as the fitness
function in an optimization algorithm

Lewis, 1991
Shibata, 1991

harmonization

feedforward model

Bellgard & Tsang, 1992

harmonization

effective Boltzmann machine

Melo, 1998

harmonization

the ANN is trained
to model music tension

Toiviainen, 1995

jazz improvisation

recurrent model

Nishijimi & Watanabe, 1993

jazz improvisation

feedforward model

Franklin, 2001

jazz improvisation

recurrent model

Hild et al., 1992
(HARMONET)

four-part harmonization

three-layered architecture
(two ANNs and a constraint system)

Feulner & Hrnel, 1994
(MELONET)

four-part harmonization

uses HARMONET and another ANN
for melodic variations

Goldman et al., 1996
(NETNEG)

species counterpoint

ANN for basic melody, an ensemble of
agents refine the melody

Verbeurgt et al., 2004

melody

two stages: a Markovian model
and an ANN

Adiloglu & Alpaslan, 2007

species counterpoint

feedforward model

Browne & Fox, 2009

melody

simulated annealing with an ANN
to measure musical tension

Coca et al., 2011

melody

recurrent model, uses chaotic non-linear
systems to introduce variation

Table 13: References for Section 3.4, in order of appearance.

instead of absolute pitches (as Todds work) in the mapping, for composing music in Bachs
style.
As a machine learning paradigm, ANNs can be used in many different ways, so Todds
approach is not the only possible; indeed, other early papers provide different examples. For
example, Mozer (1991) developed a recurrent ANN with a training program devised to capture both local and global patterns in the set of training examples. The model also featured
in the output mapping a sophisticated multidimensional space for pitch representation, to
capture a formal psychological notion of similarity between different pitches. In this way,
similar output signals are mapped to similar pitches, in order to facilitate the learning phase
and improve the composition phase. Lewis (1991) proposed another ANN framework: creation by refinement, in which a feedforward ANN was trained with a set of patterns ranging
from random to very good music, associating each pattern with a (possibly) multidimensional musicality score. In this way, the training phase generated a mapping function from
patterns to musicality scores. Then, to create new compositions, the mapping was inverted:
starting from a purely random pattern, a gradient-descent algorithm used the ANN as a
542

fiAI Methods in Algorithmic Composition

critique, reshaping the random pattern to maximize the musicality score in the hope of
finally producing a pleasant composition. Unfortunately, this paradigm had a prohibitive
computational cost, so it was tested only with fairly simple and short compositions.
Most of the early examples described above were experiments at composing more or less
full-fledged monophonic compositions. However, ANNs were also used to automate other
tasks in music composition, as harmonization of pre-existing melodies. Shibata (1991) implemented an early example: a feedforward ANN that represented chords using their component tones, trained for harmonizing simple MIDI music, whose performance was measured
by human listeners. A more sophisticated ANN used for harmonization, the effective Boltzmann machine (EBM), also provided a measure of the quality of the output relative to the
training set (Bellgard & Tsang, 1992). Melo (1998) also harmonized classical music, but
with a notable twist: in order to model the tension25 in the music to be harmonized, he
measured the tension curve reported by several human subjects while listening to the music,
and then used an averaged tension curve to train an ANN, such that the chord progressions
generated by the ANN matched the tension level suggested by the curve. As it can be seen,
harmonization was a popular test case, but other problems were also tried. For example,
Toiviainen (1995) used ANNs to generated jazz improvisations based on a set of training
examples. The ANNs were able to create new jazz melodic patterns based on the training
set. In a similar way, Nishijimi and Watanabe (1993) trained a set of feedforward ANNs
to produce jazz improvisations in a jam session, by modeling several music features of jazz
and using examples of modeled jazz improvisations to train the ANNs. Franklin (2001)
used a recurrent ANNs to improvise jazz (trade four solos with a jazz performer), trained
in two phases: a first phase training an ANN with a set of pre-specified examples, and a
second phase where the ANN is reconfigured and trained by reinforcement learning, where
the reinforcement values are obtained by applying a set of heuristic rules.
Some researchers came to use hybrid systems, combining ANNs with other methods.
One of the first examples was HARMONET (Hild et al., 1992): a model designed to solve
a more complex task: four-part choral harmonization in Bachs style. HARMONET had
a three-layered architecture: the first component was a feedforward ANN with a sophisticated encoding of musical information (optimized for harmonization functions instead of
individual pitches), which was used to extract harmonization information. The output was
fed to the second component, a rule-based constraint satisfaction algorithm to generate the
chords, and the final component was another ANN designed to add quaver ornaments to
the previously generated chords. As an evolution of HARMONET, MELONET (Feulner &
Hrnel, 1994; improved by Hrnel & Degenhardt, 1997) not only harmonized chorales, but
also generated melodic variations for their voices, using HARMONET as a first processing
stage for the harmonization, then used another neural network to generate the melodic
variations.
NETNEG (Goldman et al., 1996) was another hybrid system that used an ANN trained
with sixteenth century classical music compositions. The ANN generated a basic melody by
segments. After each segment was created, an ensemble of agents generated a polyphonic
elaboration of the segment. The agents had rule-based systems crafted from music theoret25. An important property of music, rather difficult to define. At each point in time, the tension is related
to the interplay between structure and uncertainty perceived by the listener in the flow of the music.
Informally, it can be defined as the unfinishedness of the music if it were stopped at that point.

543

fiFernndez & Vico

ical considerations, and coordinated to maintain a coherent global output. ANNs can also
be combined with probabilistic methods: in the work of Verbeurgt et al. (2004), a set of
training sequences was decomposed into musical motifs, encoded in relative pitch. Then, a
Markov chain was constructed, whose states were the motifs. New compositions were generated by the Markov chain, but to assign the absolute pitches to the motifs in the resulting
composition, they trained an ANN. Adiloglu and Alpaslan (2007) used feedforward ANNs
to generate two-voice counterpoint, applying notions of music theory to the representation
of musical information in the networks. In Browne and Foxs (2009) system, simulated
annealing was used to arrange small fragments (motifs) of classical music, trying to get
a profile of musical tension (the same metric as in Melo, 1998) similar to the profile of a
pre-specified composition, measured using an ANN specialized in music perception. Finally,
another hybrid system was implemented by Coca et al. (2011), which used ANNs trained
with pre-existing compositions together with pseudo-random musical input generated from
a chaotic system, in order to generate more complex compositions in the synthesis phase.
3.4.1 ANNs with Evolutionary Algorithms
Among hybrid systems, those combining ANNs with evolutionary algorithms quickly became the most popular. Usually, an ANN was trained to act as the fitness function of an
evolutionary algorithm. This is the case of the earliest example of these hybrid systems,
NEUROGEN (Gibson & Byrne, 1991). Its fitness function was the composed result of two
ANNs, one for judging the intervals between pitches and the other for the overall structure. A genetic algorithm with a rather rigid, classical binary representation was used,
severely limiting the applicability of the whole implementation. However, there are also
inverted frameworks where the evolving individuals are ANNs. For example, Hrnel and
Ragg (1996) evolved HARMONET networks, but the fitness was the network performance
in training and harmonization. In another example (Chen & Miikkulainen, 2001), recurrent
three-layered ANNs evolved to compose music, and the fitness was computed from a set of
rules from music theory.
Given the modular nature of evolutionary algorithms and the perceived complexity of
ANNs, it is not uncommon that the evolutionary framework is laid down in a first research
work, and only in subsequent developments ANNs are used to replace the original fitness
function.26 For example, Spector and Alpern (1994) developed a genetic programming (GP)
framework for jazz improvisations: the individuals were programs composed by collections
of transformations that produced improvisations upon being fed previously existing jazz
melodies, and the fitness function aggregated several simple principles from jazz music
theory. The following year (Spector & Alpern, 1995), they updated their model to train an
ANN to be used as their fitness function. However, this scheme does not always fare well,
specially if the initial framework uses interactive fitness. This is the case of GenJam (Biles,
1994), an evolutionary algorithm for generating jazz melodies with an interactive fitness
function. Later on (Biles et al., 1996), as the interactive fitness evaluation represented a
severe fitness bottleneck, ANNs were tried to partially offload evaluation from human users,
with no success, as the ANNs failed to satisfactorily generalize the evaluations from their
26. This approach is risky, though, because evolutionary algorithms tend to find and exploit unexpected and
undesired quirks in any fitness evaluation function; more so if the evaluator is an ANN.

544

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Gibson & Byrne, 1991

melody, rhythm

Two ANNs to define the fitness function

Hrnel & Ragg, 1996

melody harmonization

evolves HARMONET, the fitness is the ANNs
performance in training and harmonization

Chen & Miikkulainen, 2001

melody

evolves recurrent networks,
the fitness is computed from a set of rules

Spector & Alpern, 1994

melody

genetic programming, ANNs as fitness functions

Biles et al., 1996

jazz improvisation

ANNs as fitness functions

Johanson & Poli, 1998
(GP-Music)

melody

genetic programming, ANNs as fitness functions

Klinger & Rudolph, 2006

melody

ANNs and decision trees as fitness functions

Manaris et al., 2007

melody

genetic programming, ANNs as fitness functions

Burton, 1998

drum rhythms

Adaptive Resonance Theory
(unsupervised learning) as fitness function

Phon-Amnuaisuk et al., 2007

melody

genetic programming, self-organinzing map
(unsupervised learning) as fitness function

Table 14: References for Section 3.4.1, in order of appearance.

training sets. In the case of the GP-Music System (Johanson & Poli, 1998), which used
GP with procedural representations of short melodies, the trained ANNs were not a failure,
but decidedly below par with respect to the performance of the algorithm with interactive
fitness. Klinger and Rudolph (2006) compared the performance of feedforward ANNs with
learned decision trees, finding that the latter performed better and their ratings were easier
to understand. In spite of these examples, more successful instances do exist: Manaris et al.
(2007) extracted several statistical metrics from music compositions and trained an ANN
to recognize compositions whose metrics distributions featured Zipfs law, then used it as
the fitness function in a GP framework whose individuals were procedural representations
of polyphonic compositions. The results were validated as aesthetically pleasing by human
testers.
All the research described up to this point uses ANNs with supervised learning. However,
methods using unsupervised learning also exist. Burton (1998) proposed a genetic algorithm
with a classical binary representation for generating multi-voice percussion rhythms, whose
fitness function presented an unconventional feature mix. It used Adaptive Resonance Theory (ART), an ANN with unsupervised learning, initially trained to perform automatic
clustering of a set of drum rhythms. Then, during the execution of the genetic algorithm,
the unsupervised learning continued. The fitness was a measure of how near was the individual to some cluster. If the individual represented a brand new rhythm so different as to add
a new cluster, the rhythm was presented to the user to decide if it was musically acceptable.
In this way, Burton tried to get the best of interactive and automatic fitness evaluation.
A different example with unsupervised learning was presented by Phon-Amnuaisuk et al.
(2007), able to generate variations over a pre-specified composition. It used GP whose individuals were procedural representations of melodies, while the fitness was the similarity
to the pre-specified composition, as measured by a self-organizing map (SOM) previously
trained with musical elements of the pre-specified composition.
545

fiFernndez & Vico

Reference

Composition task

Comments

Baggi, 1991

jazz improvisation

ad hoc connectionist expert system

Laine, 2000

simple rhytms

uses central pattern generators

Dorin, 2000

poly-rhythmic musical patterns

uses Boolean networks

Hoover et al., 2012

acompaniment

uses CPPNs

Table 15: References for Section 3.4.2, in order of appearance.

3.4.2 Related Methods
Finally, this subsection presents methods that may be considered roughly similar to ANNs,
or more generally, connectionist. For example, Neurswing (Baggi, 1991) may be described
as an ad hoc expert system for jazz improvisation crafted in a connectionist framework.
Surprisingly, many research papers cite Neurswing as an ANN framework, despite Baggis
disclaimer: [Neurswing], though only vaguely resembling a neural net or a connectionist
system, [. . . ] (Baggi, 1991). Laine (2000) used very simple ANNs to implement Central
Pattern Generators, whose output patterns where then interpreted as more or less simple
rhythms (motion patterns in his terminology).
Boolean networks are another connectionist paradigm in which each node has a binary
state and the edges between nodes are directed; each nodes state changes in discrete steps
according to a (usually randomly chosen) Boolean function whose inputs are the states of
the nodes with connections to that node. They may be considered as generalizations of
cellular automata, and depending on the wiring and the distribution of Boolean functions,
their states can change in very complex patterns, with potentially complex responses to external forcing. Because of these properties, Dorin (2000) used Boolean networks to generate
complex poly-rhythmic musical patterns, modulable in real time by the user.
Hoover et al. (2012) proposed another connectionist approach: compositional pattern
producing networks (CPPNs). These are feedforward networks where each neuron may
use a different, arbitrary function, instead of the classical sigmoid function. They are usually
designed by interactive evolutionary methods, and can be used to generate or modulate
highly complex patterns. In the cited paper, they were fed a pre-existing simple composition
as input, in order to generate an accompaniment for it.
3.5 Evolutionary and Other Population-Based Methods
Most evolutionary algorithms (EAs) approximately follow a common pattern: a changing
set of candidate solutions (a population of individuals) undergoes a repeated cycle of evaluation, selection and reproduction with variation. The first step is to generate the candidate
solutions of the initial set, either from user-specified examples or in a more or less random
way. Each candidate is then evaluated using a fitness function, a heuristic rule to measure
its quality. The next phase is selection: a new set of candidate solutions is generated by
copying candidate solutions from the old one; each candidate solution is copied a number
of times probabilistically proportional to its fitness. This step decreases the diversity of
the population, which is restored by applying (to a fraction of the candidate solutions)
some operators designed to increase the variation (for example, mutation or recombination
546

fiAI Methods in Algorithmic Composition

operators). These steps are applied iteratively; as a result, best and mean fitness gradually
tend to increase.
While this algorithmic pattern is common to all EAs, there exist many different algorithms using different sets of selection rules, variation operators and solution encoding. In
an EA, the encoded form of a candidate solution is the genotype, while the phenotype is
the translation of that coded form into a solution. Hollands original formulation of genetic algorithms is strongly associated with a plain and direct encoding of genotypes as
binary strings, but this is not the case in most papers using EAs. Because of this, the
term evolutionary is preferred over genetic in this paper. Another popular variant, Kozas
genetic programming, represents genotypes as tree structures, often encoding expressions of
a programming language, while the phenotype is the result of evaluating these expressions.
Since EAs are particularly prone to be hybridized with other methods, they are also
reviewed in the other sections: with grammars in Section 3.1.2, with ANNs in Section 3.4.1,
with Markov chains in Section 3.3 , with rule-based systems in Section 3.2.2, and with
cellular automata in Section 3.6.1 . In general, the papers cited in these sections will not
be discussed here. We also recommend some literature to learn more about evolutionary
computer music: Burton and Vladimirova (1999) wrote a survey with long, thorough descriptions of the referenced papers, while the survey of Santos et al. (2000) is more similar
to ours in style, packed with brief descriptions. Miranda and Biless (2007) book is more
recent, but also contains work on other optimization methods (as swarm optimization) and
algorithmic composition techniques (as cellular automata).
3.5.1 Evolution with Automatic Fitness Functions
The difficulty to define automatic fitness functions has been a constant issue, frequently
limiting the application of evolutionary methods to well-defined and restricted problems
in composition. Horner and Goldberg (1991) provided one of the first examples: they
implemented an EA for thematic bridging, a composition technique consisting of defining
a sequence (with a pre-specified preferred length) of small musical patterns such that the
first and the last ones are pre-specified, and each pattern is the result of applying a simple
transformation to the previous one. Naturally, the individuals in the EA were defined as
lists of operations applied to the initial pattern to generate the sequence of patterns. The
fitness measured how close the final pattern (generated from the operations) was to the
pre-specified final pattern, plus the difference between actual and preferred lengths of the
sequence. Essentially the same work (with differences in the underlying representation and
operation set) was reported by Ricanek et al. (1993).
A common way to implement a fitness function is as a weighted sum of features of the
composition (although tuning the weights to optimize the EA can prove difficult except for
toy problems). For example, Marques et al. (2000) composed short polyphonic melodies
using a very direct representation for the genotypes and also a simple fitness function,
with a rather simple, ad hoc evaluation of harmony and melodic value. The results were
reportedly acceptable. Johnson et al. (2004) also composed short melodies using an EA
. Only a few examples of evolutionary algorithms were described in this section, not warranting a dedicated
subsection for them.
. Same case as in the previous note.

547

fiFernndez & Vico

Reference

Composition task

Comments

Horner & Goldberg, 1991

thematic bridging

fitness: distance to original melodies

Ricanek et al., 1993

thematic bridging

fitness: distance to original melodies

Marques et al., 2000

polyphony

fitness: combination of features

Johnson et al., 2004

melody

fitness: combination of features

Papadopoulos & Wiggins,
1998

jazz improvisation

fitness: combination of features

Harris, 2008
(JazzGen)

jazz improvisator

fitness: combination of features

Towsey et al., 2001

melodic extension

fitness: combination of features
(only fitness, no evolutionary algorithm)

Birchfield, 2003

melody, rhythm

fitness: combination of features

Garay Acevedo, 2004

species counterpoint

fitness: combination of features

Lozano et al., 2009

melody
harmonization

fitness: combination of features

De Prisco et al., 2010

unfigured bass

multi-objective optimization

Freitas & Guimares, 2011

melody
harmonization

multi-objective optimization

Gartland-Jones, 2002

generate variations
on two melodies

fitness: distance to a melody

Alfonseca et al., 2005

melody

fitness: distance to corpus of melodies

zcan & Eral, 2008
(AMUSE)

generate variations
on a melody

fitness: combination of features

Wolkowicz et al., 2009

melody

fitness: distance to corpus of melodies

Laine & Kuuskankare, 1994

melody

fitness: distance to a melody. Genetic programming

Spector & Alpern, 1994

jazz improvisation

fitness: combination of features. Genetic programming

Dahlstedt, 2007

contemporary
classical music

fitness: combination of features. Genetic programming

Esp et al., 2007

melody

fitness: combination of features extracted fropm a
corpus of melodies. Genetic programming

Jensen, 2011

melody

fitness: distance to a corpus of melodies.
Genetic programming

Daz-Jerez, 2011;
Snchez-Quintana et al.,
2013

contemporary
classical music, other
genres

sophisticated indirect encoding

Table 16: References for Section 3.5.1, in order of appearance.
with a fitness function that was a weighted sum of a series of very basic, local features
of the melody. Papadopoulos and Wiggins (1998) implemented a system that, given a
chord progression, evolved jazz melodies by relative pitch encoding, using as fitness function
a weighted sum of eight evaluations of characteristics of the melody, ranging from very
simple heuristics about the speed and the position of the notes to user-specified contour and
similarity to user-specified music fragments. A similar approach was implemented by Harris
(2008), with modest (if promising) results. While Towsey et al. (2001) did not actually
implement an EA, they discussed how to build a fitness function for melodic extension
548

fiAI Methods in Algorithmic Composition

(given a composition, extend it for a few bars): they proposed to extract 21 statistical
characteristics from a corpus of pre-specified compositions, defining the fitness function as
a weighted sum of the distance between the individual and the mean of the characteristic.
In a similar vein, Birchfield (2003) implemented a fitness function as a giant weighted sum
of many features in a hierarchical EA, with multiple population levels, each individual in
a population being composed of individuals from lower populations (similar to the model
described in Biles, 1994; see Section 3.5.2). He used the output of the EA as material
to arrange a long composition for ten instruments. Garay Acevedo (2004) implemented a
simple EA to compose first species counterpoint, but the features weighted in the fitness
function were too simplistic, leading to modest results. Lozano et al. (2009) generated chord
sequences to harmonize a pre-specified melody in two steps: first a simple EA generated a
set of possible solutions according to simple local considerations (appropriateness of each
chord for the corresponding part of the melody) between the chords and the notes of the
melody, and then a variable neighborhood search was used to establish a chord progression
according to global considerations.
The alternative to implementing the fitness function as a weighted sum of musical features is to use multi-objective evolutionary algorithms (MOEAs). However, these have very
rarely been used, most probably because they are harder to implement, both conceptually and in practice. MOEAs have been used by De Prisco et al. (2010) to harmonize the
unfigured bass27 and by Freitas and Guimares (2011) for harmonization.
Another approach consists of measuring the fitness as the distance to a target composition or corpus of compositions. For example, Gartland-Jones (2002) implemented an EA
to compose hybrids between two pre-specified compositions (a goal similar to Hamanaka
et al.s, 2008, cited in Section 3.1) by using one to seed the initial population, and the
distance to the other (sum of difference in pitch for each note) as the fitness function. Alfonseca et al. (2005) used a more sophisticated evaluation: the fitness of each composition
in the population was the sum of distances to a corpus of pre-specified target compositions. The metric was the normalized compression distance, a measure of how different two
symbol strings are, based on their compressed lengths (both concatenated and separated).
zcan and Eral (2008) used a simple genetic representation and a fitness function based
on a weighted sum of a long list of simple musical characteristics, reportedly being able
to generate improvisations over a pre-specified melody with a given harmonic context, but
they did not specify how the evolved melodies were related to the pre-specified music. In
the EA implemented by Wolkowicz et al. (2009), individuals were encoded using relative
pitches, and a sophisticated statistical analysis of n-gram sequences in a pre-specified corpus
of compositions was used to implement the fitness function.
Genetic programming has also been used with fitness functions based on comparisons
with pre-specified music. In the work of Laine and Kuuskankare (1994), the individuals
were discrete functions of time whose output (phenotype) was interpreted as a sequence of
pitches. The fitness was simply the sum of differences in pitches between a pre-specified
target composition and the phenotype of each individual, in a similar way to GartlandJones (2002). However, it is frequent to find fitness functions based on the analysis of
characteristics of the compositions evolving in the algorithm, often comparing them against
27. For a description of the unfigured bass, see the discussion of Rothgebs (1968) work in Section 3.2.

549

fiFernndez & Vico

characteristics of a pre-specified training set of compositions. Spector and Alpern (1994)
used genetic programming for jazz improvisation, trading fours: the individuals were
functions that took as input a four and produced another one by applying a series of
transformations to it. The fitness was determined by applying a series of score functions
that measured the rhythm, tonality and other features of the produced four, comparing
them against a database of high-quality examples from renowned artists.
Also using genetic programming, Dahlstedt (2007) composed relatively short contemporary classical music pieces, with a simple fitness function: a set of target values were
assigned for several statistics of the compositions (as note density or pitch standard deviation, among others), and the fitness was a weighted sum of the differences between the
target values and the values for each individual. The individuals were trees whose nodes
represented notes and different operations over musical sequences (using a developmental
process from genotype to phenotype). Reportedly, the generated pieces were of acceptable
quality, because the genotype model was especially well suited for contemporary classical
music. Esp et al. (2007) used a simple tree representation for compositions (but without
indirect encoding), defining the fitness function as a weighted sum of sophisticated statistical models for melody description (measuring the distance to the values of a set of
pre-specified compositions) and several relatively simple characteristics of the composition.
Jensen (2011) also used a simple tree representation for compositions; the fitness was calculated measuring frequency distributions of simple events in the compositions, rating them
according to Zipfs law and similarity to pre-specified compositions.
One of the latest and most successful results in evolutionary computer music follows
an evo-devo strategy. Iamus is a computer cluster which hybridizes bioinspired techniques:
compositions evolve in an environment ruled by formal constraints and aesthetic principles (Daz-Jerez, 2011). But compositions also develop from genomic encodings in a way
that resembles embryological development (hence the evo-devo), providing high structural
complexity at a relatively low computational cost. Each composition is the result of an
evolutionary process where only the instruments involved and a preferred duration have
been specified, and are included in the fitness function. Iamus can write professional scores
of contemporary classical music, and it has published its debut album in September 2012
(Ball, 2012; Coghlan, 2012), with ten works interpreted by first-class musicians (including the LSO for the orchestra piece). Melomics, the technology behind this avant-garde
computer-composer, is also mastering other genres and transferring the result to industry
(Snchez-Quintana et al., 2013). After compiling a myriad of musical fragments of most
essential styles in a browsable, web-based repository (Stieler, 2012). For the first time,
Melomics is offering music as a real commodity (priced by size of its MIDI representation),
where ownership over a piece is directly transferred to the buyer.
3.5.2 Musical IGAs
From the previous exposition, it is apparent that designing an objective and convenient
fitness function for evaluating music compositions is a very difficult problem.28 If the music
is to be evaluated in terms of subjective aesthetic quality, it may become impractical or
28. To the point that artists sometimes find unconventional ways around this problem: Waschka (1999)
argued to have solved the problem by assigning a purely random fitness value to the individuals.

550

fiAI Methods in Algorithmic Composition

Reference

Composition task

Comments

Hartmann, 1990

melody

inspired by Dawkins biomorphs

Nelson, 1993

melody

inspired by Dawkins biomorphs

Horowitz, 1994

rhythms

inspired by Dawkins biomorphs

Pazos et al., 1999

rhythms

binary genotype

Degazio, 1996

melody

binary genotype; graphical representation

Biles, 1994
(GenJam)

jazz improvisation

two hierarchically structured populations
(measures and jazz phrases)

Tokui & Iba, 2000

rhythms

two hierarchically structured populations
(short and long rhythmic patterns).
Genetic programming

Jacob, 1995

melody

the user trains critics that act as fitness functions

Schmidl, 2008

melody

the user trains critics that act as fitness functions

Putnam, 1994

melody

genetic programming

Ando & Iba, 2007

melody

genetic programming

MacCallum et al., 2012
(DarwinTunes)

melody

genetic programming

Kaliakatsos-Papakostas
et al., 2012

melody, 8-bit sound
synthesis

genetic programming

Hoover et al., 2012

acompaniment

uses CPPNs

McDermott & OReilly, 2011

interactive generative
music

similar to CPPNs

Ralley, 1995

melody

minimizes user input by clustering candidates

Unehara & Onisawa, 2001

melody

minimizes user input with elitism

Daz-Jerez, 2011

contemporary classical
music

minimizes user fatigue producing small, good
compositions

Beyls, 2003

melody

uses cellular automata; graphical representation

Moroni et al., 2000
(Vox Populi)

melody

complex graphical representation

Ventrella, 2008

melody

the whole population comprises the melody

Marques et al., 2010

melody

minimizes evolutionary iterations

Table 17: References for Section 3.5.2, in order of appearance.
directly impossible to define a formal fitness function. Because of these inconveniences,
many researchers have resorted to implement the fitness function with human evaluators.
A common term for describing this class of EAs is musical IGA (interactive genetic algorithm29 , MIGA for short). As MIGAs represent a substantial percentage of the total body
of work on EAs for algorithmic composition, this subsection is devoted to them.
The first MIGAs were implemented by composers intrigued by the concept of evolutionary computing, resulting in more or less peculiar architectures from the perspective
of common practice in evolutionary computing, but also by computer scientists exploring
29. Most research tagged as IGA does not use the binary genotypes commonly associated with the term
genetic algorithm, but the term is very common.

551

fiFernndez & Vico

the field. Hartmann (1990), inspired by Dawkins biomorphs, presented one of the first
applications of evolutionary computing to composition, a MIGA that he unfortunately described in a notoriously laconic and obscure language, resulting in a very low citation rate
for his work. Also inspired by the biomorphs, Nelson (1993) described a toy MIGA for
evolving short rhythms over a fixed melodic structure, with simple binary genotypes (each
bit simply denoted the presence or absence of sound). More formal models similar in scope
to Nelsons were designed by Horowitz (1994) and Pazos et al. (1999). They implemented
rhythm generators for multiple instruments, each one with its own independent rhythm
pattern encoded in the genotype (Horowitzs genotypes were parametric, while Pazos et
al. used more direct binary encodings). Degazio (1996) implemented a system in which
the genotype was a set of parameters (in later iterations, a mini-language to describe the
parameters) to instruct his CAAC software to generate melodies.
The best known MIGA may be GenJam, a system for generating jazz solos, developed
over several years. In its first incarnation (Biles, 1994), it was formulated as a MIGA with
two hierarchically structured populations: one of measures, and other of jazz phrases, constructed as sequences of measures. Given a chord progression and several other parameters,
jazz solos emerged by concatenating selected phrases during the evolutionary process, and
the fitness was integrated over time by accumulating fixed increments and decrements from
simple good/bad indications from the evaluator. Further iterations of the system included
the already discussed use of ANNs as fitness functions (Biles et al., 1996) and the possibility
to trade fours with a human performer, by dynamically introducing into the population the
music performed by the human (Biles, 1998). Tokui and Iba (2000) used a similar solution
for creating rhythms with multiple instruments: a population of short sequences specified
as list of notes, and another population of tree structures representing functions in a simple
macro language that used the short sequences as building blocks. Another example of hierarchical structuring of the MIGA is Jacobs (1995) system for general-purpose composition,
with three inter-dependent evolutionary processes: one involving the human user to train
ears to evaluate short musical sequences, another one to compose musical phrases using the
ears (filters) as fitness functions, and another also involving the human user to train an
arranger that reorders the resulting phrases into the final output of the system. Schmidl
(2008) implemented a similar system, but without a high-level arranger module, and with
ears automatically trained from a set of examples, in order to minimize user interaction and
enable real-time composition.
Genetic programming with interactive evaluation has been used several times. Putnam
(1994) implemented an early example: each individual coded for a set of functions that
generated a melody as the result of an iterated function system. Tokui and Ibas (2000)
example has been already cited. Ando and Iba (2007) implemented a fully interactive
system (not only the selection, but also the reproduction and mutation were user-guided),
where the genotype model was similar to Dahlstedts (2007). MacCallum et al. (2012) used
trees to encode Perl expressions that generated polyphonic short loops, but concentrated on
analyzing the interactive evolution from the point of view of theoretical biology. KaliakatsosPapakostas et al. (2012) used a rather different approach to generate 8-bit melodies: each
individual was a function composed of bitwise operators that generated a waveform by
iterating the function. In fact, that work might be described as sound synthesis over large
time scales, rather than music composition.
552

fiAI Methods in Algorithmic Composition

Some MIGAs with graph-based genetic representations also exist, as the implementation
based in CPPNs (Hoover et al., 2012) that was already cited in Section 3.4.2. McDermott
and OReilly (2011) used a similar paradigm: genotypes were sequences of integers that
indirectly encoded graphs, whose nodes represented functions, and their connections were
compositions of functions. The output nodes generated musical output in one or more
voices, which were modulated by user inputs.
A problem common to all MIGAs is user fatigue: candidate solution evaluation is a
comparatively slow and monotone task that rapidly leads to user fatigue. Even with small
population sizes and small numbers of generations, it remains a significant problem that has
been solved by many researchers in different ways. For example, Ralley (1995) used a binary
representation with relative pitch encoding for the genotypes, and classified the population
with a clustering algorithm, deriving similarity metrics from rudimentary spectral analysis of
the scores. The user was simply required to evaluate the closest composition to the centroid
of each cluster. A more exotic solution was employed by previously cited Tokui and Iba
(2000): training a neural network to filter out candidates with low fitness, thus presenting
to the user individuals of acceptable quality. Unehara and Onisawa (2001) presented just
10% of candidate melodies to the human user, and then parts of the genomes of the best
rated ones were dispersed in the population by horizontal gene transfer. McDermott and
OReilly (2011) also limited the number of candidates exposed to user rating, filtering out
the worst ones with heuristic functions. Another option to minimize user fatigue is to
produce small compositions that already are reasonably good. The Melomics system (see
last paragraph in Section 3.5.1) can be used in this way (Daz-Jerez, 2011).
Other common ways to manage the problem include low population sizes and/or hierarchical structuring of the algorithm (Biles, 1994), or providing statistical information and/or
rendering graphical representations of the compositions in order to make possible their
evaluation without actually listening to them (Degazio, 1996). Graphical representations
are also particularly useful if using generative methods as L-systems or cellular automata
(Beyls, 2003). Putnam (1994) used a web interface to reach out to more volunteers. Moroni
et al. (2000) tried to solve the problem using sophisticated GUI abstractions, with complex
non-linear mappings between the graphic controls and the parameters of the fitness function
and other aspects of the evolutionary process, to produce a highly modulable system for
real-time interactive composition of melodies. To mitigate user fatigue, Ventrella (2008)
presented a population of short melodies as a continuous stream of sound; fitness was obtained through a binary signal set by the user. Marques et al. (2010) limited user fatigue in
the generation of short, simple melodies by severely limiting the number of generations of
the algorithm, and generating a reasonably good starting population by drawing the notes
using Zipfs law.
3.5.3 Other Population-Based Methods
Finally, this subsection presents other methods that are also population-based. For example, the metaheuristic method Harmony Search is inspired in the improvisation process of
musicians, though in practice can be framed as an evolutionary method with a specific way
to structure candidate solutions and perform selection, crossover and mutation operations.
Geem and Choi (2007) used this method to harmonize Gregorian chants (i.e., to write or553

fiFernndez & Vico

Reference

Composition task

Comments

Geem & Choi, 2007

harmonize
Gregorian chants

harmony search

Geis & Middendorf, 2008

four-part
harmonization

multi-objective Ant Colony Optimization

Tominaga & Setomoto, 2008

polyphony,
counterpoint

artificial chemistry

Werner & Todd, 1997

melody

co-evolutionary algorithm, Markov chains used
as evolvable fitness functions

Bown & Wiggins, 2005

melody

individuals are Markov chains
that compose and evaluate music

Miranda, 2002

melody

individuals agree on a common set of
intonation patterns

Miranda et al., 2003,
sect. IV

melody

individuals are grammars that compose music

McCormack, 2003b

interactive soundscape

individuals indirectly compete for users attention

Dahlstedt & Nordahl, 2001

soundscape

music emerges from collective interactions

Beyls, 2007

soundscape

music emerges from collective interactions

Blackwell & Bentley, 2002

soundscape

music emerges from collective interactions

Eldridge & Dorin, 2009

soundscape,
sound synthesis

music emerges from collective interactions,
individuals exist in the frequency domain

Bown & McCormack, 2010

interactive soundscape,
sound synthesis

music emerges from collective interactions,
individuals exist in the frequency domain

Table 18: References for Section 3.5.3, in order of appearance.

ganum lines for the chants). Other methods are also population-based but not properly
evolutionary. An example is the use of Ant Colony Optimization (ACO) to solve constraint
harmonization problems (Geis & Middendorf, 2008), already mentioned in Section 3.2.3.
In ACO, the candidate solutions are represented as paths in a graph, and a population of
agents (ants) traverse the graph, cooperating to find the optimal path.
As a more exotic example, an Artificial Chemistry is a generative system consisting of
a multiset of strings of symbols. These strings (analogues of molecules) can react according
to a pre-specified set of rules (analogues of chemical reactions), generating new strings from
the existing ones. Tominaga and Setomoto (2008) used this method, encoding polyphonic
compositions in the strings and musical rules for counterpoint in the reaction rules of the
artificial chemistry: starting from a set of simple strings, the system generated progressively
more complex ones, though the aesthetical value of the resulting compositions varied widely.
A more popular method based on populations of individuals is the Artificial Ecosystem.
In an artificial ecosystem, compositions emerge from the interaction between individuals in
a simulation with evolutionary and/or cultural interactions, taking inspiration in the evolutionary origins of music in humans (Wallin & Merker, 2001). Frequently, the complexity
of the simulations is severely limited by the available computational power, and in some
cases the goal is not music composition per se, but the study of evolutionary dynamics, the
emergence of shared cultural traits and avant-garde artistic experimentation.
554

fiAI Methods in Algorithmic Composition

An early example by Werner and Todd (1997) investigated sexual evolutionary dynamics
in a population of males (small compositions) and females (Markov chains initially generated
from a corpus of songs) that evaluated how much the males deviated from their expectations.
However, most studies use just one kind of agent, as in the work of Bown and Wiggins (2005),
whose agents used Markov chains for both compose and analyze music. Miranda (2002)
and Miranda, Kirby, and Todd (2003, sect. IV) implemented models with a similar goal: to
study the emergence of common structures (shared cultural knowledge). In the first case a
population of agents strove to imitate each others intonation patterns (short sequences of
pitches); in the second case agents learned to compose music by inferring musical grammars
from other agents songs. Bosma (2005) extended Mirandas (2002) model, using neural
networks in the agents to learn and compose music, although with tiny population sizes. As
part of an art installation, McCormack (2003b) proposed a virtual ecosystem with evolving
agents able to compose music using a rule-based system, competing for resources that were
indirectly determined by the interest of human observers.
An alternative is that the music is not composed by the agents, but emerges as an
epiphenomenon of the whole ecosystem. The models of Dahlstedt and Nordahl (2001) and
Beyls (2007) used simple organisms in a two-dimensional space whose collective behavior
was mapped into complex compositions, while Blackwell and Bentleys (2002) model was
similar but three-dimensional, and the dynamics of the agents were inspired in swarm
and flocking simulations. While all these examples use either homogeneous or spatially
structured ecosystems, a recent trend is the use of sound as an environment in itself. In
Eldridge and Dorins (2009) model, the agents dwelt in the one-dimensional space of the
Fourier transform of a sample of ambient sound, feeding off and moving the energy across
frequencies. Bown and McCormack (2010) implemented a similar model, in which the
agents were neural networks that generated sound and competed for room in the space of
frequencies of ambient sound.
3.6 Self-Similarity and Cellular Automata
In the late 1970s, two notable results about music were reported by Voss and Clarke (1978).
The first was that, for music of many different styles, the spectral density of the audio
signal was (approximately) inversely proportional to its frequency; in other words, it approximately follows a 1/f distribution. This is not so surprising: many different data series
follow this property, from meteorological data to stock market prices; it is usually referred
to as 1/f noise or pink noise. The second result was that random compositions seemed
more musical and pleasing (for a wide range of evaluators, from unskilled people to professional musicians and composers) when the pitches were determined by a source of 1/f noise,
rather than other common random processes as white (uncorrelated) noise or Brownian motion (random walks). Although the first result has been since challenged30 , the second one
has been used by composers as a source of raw material. Bolognesi (1983) implemented an
early example influenced by Voss and Clarkes results, but composers used data series with
1/f noise as raw material even before these results, early in the 1970s (Doornbusch, 2002).
30. The main criticism is that the data samples used by Voss and Clarke were hours long, merging in each
sample many different compositions (and even non-musical sounds from a radio station). In view of their

555

fiFernndez & Vico

Reference

Composition task

Comments

Voss & Clarke, 1978

melody

first reference to 1/f noise in music

Bolognesi, 1983

melody

early deliberate use of 1/f noise in music

Doornbusch, 2002

melody

reference to early non-deliberate use of 1/f noise in music

Gogins, 1991

melody

iterated function systems

Pressing, 1988

melody,
sound synthesis

chaotic non-linear maps

Herman, 1993

melody

chaotic non-linear dynamical systems

Langston, 1989

melody

fractional Brownian motion

Daz-Jerez, 2000

melody

fractals and other self-similar systems

Bidlack, 1992

melody

various fractal and chaotic systems

Leach & Fitch, 1995
(XComposer)

melody, rhythm

uses various fractal and chaotic systems

Hinojosa-Chapel, 2003

melody

uses various fractal and chaotic systems to fill the

Coca et al., 2011

melody

uses chaotic systems to add variation

Table 19: References for Section 3.6, in order of appearance.
There remains the question of why 1/f noise produces more musical results that other
random processes. The consensus in the research and artistic communities is self-similarity:
the structure of 1/f noise is statistically similar across several orders of magnitude (Farrell
et al., 2006). Self-similarity is a common feature in classical music compositions (Hs &
Hs, 1991), and is also one of the defining features of fractals (in fact, 1/f noise also has
fractal characteristics). Because of this, fractals have been extensively used as a source
of inspiration and raw material for compositions and CAAC software. In general, selfsimilar musical patterns have multiple levels of structure, with pleasing regularities but
also dotted with sudden changes. Because these characteristics can be also present in the
output of chaotic systems (whose attractors are also fractal structures), these are also used
to generate musical patterns. Commonly used techniques to generate self-similar musical
patterns include chaotic systems such as iterated function systems (Gogins, 1991), nonlinear maps (Pressing, 1988) and non-linear dynamical systems (Herman, 1993), but also
fractional Brownian motion (Langston, 1989), cellular automata (discussed below) and Lsystems (already discussed in Section 3.1.1). More exotic methods are also possible, as
musical renderings of fractal images or number sequences with fractal characteristics (DazJerez, 2000). These methods are widely regarded as not suitable to produce melodies or
compositions in their own right, but as a source of inspiration or raw material (Bidlack,
1992). Because of this, no extensive review will be provided here.31 However, full-fledged
algorithmic composition methods can use them as part of the creative process, as in Leach
and Fitchs (1995) XComposer, where chaotic systems are used to fill the structures laid
critics, such as Nettheim (1992), these samples could not possibly be representative of single musical
pieces (see also the discussion in Daz-Jerez, 2000, pp. 136138).
31. Good (if somewhat outdated) reviews can be found in the work of Jones (1989), Daz-Jerez (2000) and
Nierhaus (2009). The list of composers using fractals and chaotic systems for CAAC is so long that it is
impractical to consistently describe all the existing relevant work.

556

fiAI Methods in Algorithmic Composition

down by a hierarchical model, or in Hinojosa-Chapels (2003) paradigm for interactive
systems, where they are also used as a source of musical material. They can also be used
to add complexity to compositions generated by other means.32
3.6.1 Cellular Automata
A cellular automaton (CA) is a discrete (in time, space and state) dynamic system composed
of very simple computational units (cells) usually arranged in an ordered n-dimensional (and
potentially unbounded) grid (or any other regular tiling). Each cell can be in one of a finite
number of states. In each discrete time step, each cells state is deterministically updated,
using a set of transition rules that take into account its own state and its neighbors states.
Although this definition can be generalized in multiple ways, it represents a good first
approximation. Cellular automata are used in many disciplines across Science and the
Humanities as dynamical models of complex spatial and temporal patterns emerging from
the local interaction of many simple units; music composition is just one of these disciplines.
Cellular automata can be used to generate fractal patterns and discrete versions of chaotic
dynamical systems, but they also represent an alternative computational paradigm to realize
algorithmic composition.33 Unfortunately, just like fractals and chaotic systems, CA also
tend to produce interesting but somewhat unmusical patterns that are used as inspiration
or raw material rather than directly as music compositions. Although CA are argued to be
better suited to sound synthesis than to algorithmic composition (Miranda, 2007), only the
latter application will be reviewed here.
Xenakis was known to be deeply interested in the application of CA to music. In his
orchestral composition Horos, released in 1986, he is widely regarded to have used a CA to
configure the structure of the composition, though it was then heavily edited by hand (Hoffmann, 2002). Early, better documented explorations of CA for music composition include
the implementations of Beyls (1989), Millen (1990), and Hunt et al. (1991), which mapped
the patterns generated by user-defined CA to MIDI output. Beyls (1989) presented CA as
a generative system for real-time composition of avant-garde music, exploring several ways
to complexify the generated musical patterns (as changing the transition rules according to
meta-rules), while Millen (1990) presented a minimalist CAAC system. Hunt et al. (1991)
implemented another CAAC system designed to give the composer more control over the
composition process. Echoing Beylss (1989) early work, Ariza (2007) proposed to bend the
transition rules in order to increase the space of parameters available to the composer for experimentation, by either randomly changing the state of some isolated cells or dynamically
changing the transition rules from one generation to the next.
CAMUS (Miranda, 1993) is a more known CA system for algorithmic composition with
an innovative design using two bidimensional CA: Conways Game of Life (used to determine
musical sequences) and Griffeaths Crystalline Growths (used to determine the instrumentation of the notes generated by the first CA). Each activated cell in the Game of Life was
mapped to a sequence of three notes, whose instrument was selected according to the corresponding cell in the second CA (the Crystalline Growths system). Unfortunately, according
to its own creator (Miranda, 2007), CAMUS did not produce very musical results: its out32. See, e.g., the description of the work by Coca et al. (2011) in Section 3.4.
33. For a more detailed survey, see e.g. the work of Burraston and Edmonds (2005).

557

fiFernndez & Vico

Reference

Composition task

Comments

Hoffmann, 2002

structure

reference to early use of CA in music (Xenakiss Horos)

Beyls, 1989

melody

early use of CA in music

Millen, 1990

melody

early use of CA in music

Hunt et al., 1991

melody

early use of CA in music

Ariza, 2007

melody

dynamically changing CA rules

Miranda, 1993
(CAMUS)

melody,
instrumentation

two CA: one for the melody,
other for the instrumentation

McAlpine et al., 1999
(CAMUS 3D)

melody, rhythm,
instrumentation

same as above, plus Markov chains to select rhythm

Bilotta & Pantano, 2001

melody

explores several mappings from CA to music events

Dorin, 2002
(Liquiprism)

rhythmic patterns

several interacting CA

Ball, 2005, Miljkovic, 2007

melody, rhythm

references to WolframTones

Phon-Amnuaisuk, 2010

melody

uses ANNs to learn CA rules

Beyls, 2003

melody

interactive evolutionary algorithm

Bilotta & Pantano, 2002

melody

extends Bilotta and Pantanos (2001) work
with an evolutionary algorithm

Lo, 2012

melody

evolutionary algorithm,
Markov chains used in the fitness function

Table 20: References for Section 3.6.1, in order of appearance.
put was more properly considered as raw material to be edited by hand. CAMUS was later
generalized, using a Markov chain to determine the note durations and three-dimensional
versions of the Game of Life and Crystalline Growths (McAlpine et al., 1999).
More recently, Bilotta and Pantano (2001) explored several different mappings to generate music from CA: local codes (mapping cells to pitches, the usual mapping in most
papers), global codes (mapping the entropy of the whole pattern in each generation to musical events) and mixed codes (mapping groups of cells to musical events). Dorin (2002) used
six bidimensional finite CA arranged in a cube (their edges connected), running at different speeds, to generate complex poly-rhythmic patterns.34 Finally, WolframTones35 (Ball,
2005) is a commercial application of CA to music composition, using a database of four
billions of transition rules for one-dimensional CA (all possible transition rules taking into
account five neighbors). WolframTones searches for rules that produce chaotic or complex
patterns. These patterns are mapped to musical events, and the system is able to search
for patterns whose musical mapping resembles one of a set of pre-defined musical styles
(Miljkovic, 2007).
Although CA are commonly used to generate musical material in a uncontrolled way
(i.e., the composer tunes the parameters of the CA by hand), it is possible to use other
methods to design the CA (states, transition rules, etc.). For example, Phon-Amnuaisuk
34. In Section 3.4.2, similar work (Dorin, 2000) with Boolean networks (a connectionist paradigm usually
seen as a generalization of CA) was mentioned.
35. http://tones.wolfram.com/

558

fiAI Methods in Algorithmic Composition

(2010) used artificial neural networks trained to learn the transition rules of a CA: given
a melody, its piano-roll notation was interpreted as the temporal pattern of a CA, and the
network was trained to learn the transition rules for that temporal pattern. Then, given
other initial conditions, the network produced new compositions in piano-roll notation.
Evolutionary algorithms are also used to design the parameters (transition rules, states,
etc.) of CA. In some cases, previous work with hand-designed CA is adapted to use an
evolutionary algorithm. This is the case of Beyls (2003), who used an interactive evolutionary algorithm to evolve the parameters of a CA, and Bilotta and Pantano (2002), who
adapted their previously discussed work (Bilotta & Pantano, 2001) to use an evolutionary
algorithm, although the fitness function was poorly described. Lo (2012) applied evolutionary algorithms to generate CA for algorithmic composition in a more comprehensive way,
experimenting with various fitness functions based on extracting statistical models from a
corpus of pre-existing compositions, including metrics based on Markov models and Zipfs
law.

4. Conclusions
In this survey, several hundreds of papers on algorithmic composition have been briefly reviewed. Obviously, none of them has been described in detail. Rather, this survey has been
intended as a short reference guide for the various methods commonly used for algorithmic
composition. As Pearce et al. (2002) noted, most papers on algorithmic composition do
not adequately (a) specify the precise practical or theoretical aims of research; (b) use a
methodology to achieve these aims; or (c) evaluate the results in a controlled, measurable
and repeatable way. Researchers of algorithmic composition have very diverse backgrounds,
and, in many cases, they do not present their work in a way that enables comparison with
others. Because of these considerations, we have presented the literature in a narrative
style, classifying the existing work in several broad categories, and providing brief descriptions of the papers in an approximately chronological order for each category.
4.1 About Creativity
Algorithmic composition automates (to varying degrees) the various tasks associated with
music composition, such as the generation of melodies or rhythms, harmonization, counterpoint and orchestration. These tasks can be applied in two ways: (a) to generate music
imitating a corpus of compositions or a specific style, and (b) to automate composition
tasks to varying degrees, from designing mere tools for human composers, to generating
compositions without human intervention:
Generating music imitating a corpus of compositions or a specific style. Most
instances of this kind of problem (including real-time improvisation systems that elaborate on input from human musicians) can be considered as solved: imitation problems
have been tackled with many different methods, in many cases with reasonable success
(such as Copes EMI, 1992, or Pachets Continuator, 2002). In fact, since the origins
of computational algorithmic composition, there has been a bias in the research community towards imitation problems (Nierhaus, 2009). This may be attributed to the
559

fiFernndez & Vico

difficulty to merge the mindset of computer science (clear-cut definitions, precise algorithms, straight methodologies) with the mindset of artistic work (intuition, vagueness,
cultural heritage and artistic influences). These two mindsets may be compared to
the once common cultural divide in Artificial Intelligence between neats and scruffies.
Unfortunately, while the neats reign supreme in Artificial Intelligence, they have yet
to gain the upper hand in Artificial Creativity.
Automating composition tasks to varying degrees. In the case of automated
systems for algorithmic composition intended to reproduce human creativity in some
way, there is the problem of evaluating their performance: the concept of artistic
creativity eludes a formal, unambiguous and effective definition. This makes it difficult
to evaluate these systems in a completely rigorous way. Certainly, many frameworks
have been proposed for assessing computational creativity36 , but not one can be easily
and uniformly applied to computers and humans alike, in a way that does not spark
controversy. It may seem simple to measure computational creativity against human
standards: we can simply ask people to listen to human and machine compositions,
and declare an algorithmic composition system as creative if these people cannot tell
apart its compositions from human ones. As Ariza (2009) noted, this kind of musical
Turing Test has been performed by many different researchers trying to validate their
systems, but they are valid if the algorithmic composition system just aspires to imitate,
not to be truly creative and create a truly innovative work of art.
There is also the view that systems for algorithmic composition cannot attain true creativity, even in principle. In fact, it has been suggested (Kugel, 1990) that no Turing-equivalent
formalism can truly simulate human creativity, i.e., musical creativity is not effectively computable, thus preventing computer systems from completely imitating human composers,
even in theory. This argument is not without merits, but it is open to debate, precisely
because it lacks a rigorous, unambiguous definition of creativity.
4.2 About the Methods
Regardless of these (more or less abstract) considerations about true creativity, this survey
has presented existing work on algorithmic composition, organized in several categories. As
described at the beginning of Section 3, these categories can be grouped in a few classes:
Symbolic AI (grammars and rule-based systems). Under this umbrella, we have
grouped very different techniques. These techniques can be used both for imitation (be
it the style of a specific composer, or more generally a musical style) and automation of
composition tasks. They have proved very effective, and they are very popular (at least,
by sheer volume of reviewed work), but in most cases, they are very labor-intensive,
because they require musical knowledge to be encoded and maintained in the symbolic
framework of choice. There has also been a clear trend towards more and more formal
systems, gradually moving from ad hoc rule systems to constraint satisfaction and other
various formalisms.
36. For example, Geros (2000), Pearce and Wigginss (2001), Ritchies (2007) and Bodens (2009).

560

fiAI Methods in Algorithmic Composition

Machine learning (Markov chains and artificial neural networks). Because of
their nature, machine learning techniques are used primarily for imitation, although
both Markov chains (and related statistical methods) and artificial neural networks
can be also used to automate composition tasks (such as harmonization). It should be
noted that some techniques described here as symbolic AI are also machine learning
(like Copes ATNs, rule learning or case-based reasoning).
Optimization techniques (evolutionary algorithms). As in the case of machine
learning, optimization techniques (mostly evolutionary algorithms) have been profusely
used for imitation, since it is natural to express the objective of the optimization (the
fitness function) as the distance to the musical style to be imitated. However, the
automation of composition tasks has also been explored, more so than in the case of
machine learning techniques.
Self-similarity and cellular automata. Strictly speaking, these techniques are not a
form of AI. As explained at the beginning of Section 3, they just represent a convenient
way to generate novel musical material without resorting to human musical knowledge,
but the problem is that musical material generated in this way is very rough; it is most
commonly used by human composers as raw material to build upon.
After reviewing the literature, it becomes apparent that there is no silver bullet: except for
strict, limited imitation of specific musical styles or real-time improvisation systems that
elaborate on input from human musicians, almost all approaches to algorithmic composition
seem to be unable to produce content which can be deemed on a par with professional
human composers, even without taking into account the problem of creativity as discussed
in Section 4.1. Very few examples stand out, and then only in some niche applications, such
as the contemporary classical music composed by Iamus (Ball, 2012).
As there is no silver bullet, one obvious way forward is the hybridization of two or
more methods. In fact, from our review of the existing work, it seems apparent that many
researchers are already following this route, but there are some hybridizations that have
rarely been explored. For example, the music material produced by systems based on
self-similarity and CA is commonly regarded as a mere source of inspiration for human
composers, rather than as a proper way to automate the composition of music, because
this music material generally lacks structure. However, it can be used as the first stage
in a process of algorithmic composition, to be modified and refined by subsequent stages,
probably based on some form of machine learning if the goal is to produce music in a specific
musical style, or some knowledge-based system (such as Leach and Fitchs XComposer,
1995). In the case of evolutionary algorithms, self-similarity systems may be used to seed
the initial population, or to introduce variety to avoid premature convergence, and CA may
be used as individuals to be evolved (such as in the work of Lo, 2012, which also features
machine learning techniques). More research is required to explore the potential of this
kind of approach, combining self-similarity and CA-based systems with other methods.
In the case of optimization techniques, the multi-objective paradigm has rarely been
used, at least in comparison with the traditional single-objective approach. Composing
music usually requires balancing a set of many different, sometimes conflicting objectives,
to configure the various aspects of the music, so multi-objective optimization seems a natural
561

fiFernndez & Vico

way to tackle this problem. All too often, researchers use a weighted sum of parameters
to conflate all these objectives into a single fitness function. Very few researchers use
multi-objective optimization, as do Geis and Middendorf (2008), Carpentier and Bresson
(2010), De Prisco et al. (2010), and Freitas and Guimares (2011). While multi-objective
optimization is harder (both conceptually and in practice), it represents a natural way of
dealing with the complexity of having many different objectives, and it should be explored
more by the research community.
Finally, in the specific case of evolutionary algorithms, the issue of encoding the individuals should also be examined. Looking at algorithmic composition as an optimization
problem, search spaces for musical compositions tend to be huge and high-dimensional.
Direct encodings (such as directly representing music as a sequence of pitches) make it
very difficult to explore the search space in an effective way, with problems of scalability
(the performance degrades significantly as the size of the problem increases) and solution
structure (the solutions generated by the algorithm tend to be unstructured, hard to adapt
and fragile). This problem is mitigated by indirect encodings, in which the genotype does
not directly represent the phenotype, but rather a list of instructions to build it. Many
different types of indirect encoding have been used in algorithmic composition, such as
L-systems, other types of grammars, or the various encoding styles used in genetic programming. However, other advanced techniques for indirect encoding have rarely been
applied to algorithmic composition, in order to overcome the aforementioned problems of
scalability and solution structure, such as those related to artificial embryogenies (Stanley
& Miikkulainen, 2003), which have been inspired by biological developmental processes.
Adding these to the evolutionary toolkit may be a way to enable more and more complex
compositional tasks to be tackled.
4.3 Final Thoughts
Computers have come to stay: the use of CAAC software is prevalent among many composers, and some artistic scenes (as generative music) embrace computer-generated music as
part of their identity. However, creativity is still in the hands of composers for the most part.
As argued in Section 4.1, creativity is an inherently subjective concept, and it is arguably
debatable the point at which a computational system may become truly creative. However,
even if a precise definition cannot be agreed upon, it is easy to see that the development
of algorithmic composition systems capable of independent creativity will radically change
the process of music composition, and consequently the market for music. This should not
be seen as yet another case of computers replacing humans in an ever more sophisticated
activity, but a potentially radical disruption in the way composers perform their work: just
like a pedagogical expert system does not supersedes the role of human teachers, but enable
new ways to do their work.
Being music one of the arts with a stronger mathematical background, it is not surprising
that most of the debate on whether machines can make original and creative works has
centered in this subfield of computational creativity. Hybridization of different techniques,
bioinspiration, and the use of high performance computing might bring about new realms
of (computer-) creativity. As science writer Philip Ball put it in his analysis of Melomics
562

fiAI Methods in Algorithmic Composition

music composition technology: . . . unfolding complex structure from a mutable core has
enabled the kind of dramatic invention found in biological evolution (Ball, 2012).

Acknowledgments
The authors wish to thank Ilias Bergstrom for his comments on a preliminary version of the
manuscript. Also, the critical review of our anonymous referees has greatly improved the
final version. This study was partially supported by a grant for the MELOMICS project
(IPT-300000-2010-010) from the Spanish Ministerio de Ciencia e Innovacin, and a grant for
the CAUCE project (TSI-090302-2011-8) from the Spanish Ministerio de Industria, Turismo
y Comercio. The first author was supported by a grant for the GENEX project (P09-TIC5123) from the Consejera de Innovacin y Ciencia de Andaluca. The first author also
wishes to thank his wife Elisa and his daughter Isabel for being there day after day, in spite
of the long hours spent writing this manuscript, and his family for the invaluable support
they have provided.

References
Adiloglu, K., & Alpaslan, F. N. (2007). A machine learning approach to two-voice counterpoint composition. Knowledge-Based Systems, 20 (3), 300309.
Aguilera, G., Galn, J. L., Madrid, R., Martnez, A. M., Padilla, Y., & Rodrguez, P. (2010).
Automated generation of contrapuntal musical compositions using probabilistic logic
in Derive. Mathematics and Computers in Simulation, 80 (6), 12001211.
Alfonseca, M., Cebrin, M., & Ortega, A. (2005). Evolving computer-generated music
by means of the normalized compression distance. In Proceedings of the WSEAS
International Conference on Simulation, Modelling and Optimization, pp. 343348,
Stevens Point, Wisconsin, USA.
Allan, M. (2002). Harmonising chorales in the style of Johann Sebastian Bach. Masters
thesis, University of Edinburgh.
Allombert, A., Assayag, G., Desainte-Catherine, M., & Rueda, C. (2006). Concurrent constraints models for interactive scores. In Proceedings of the Sound and Music Computing Conference.
Ames, C. (1987). Automated composition in retrospect: 1956-1986. Leonardo, 20 (2), 169
185.
Ames, C. (1989). The Markov process as a compositional model: A survey and tutorial.
Leonardo, 22 (2), 175187.
Ames, C., & Domino, M. (1992). Understanding music with AI, chap. Cybernetic composer:
an overview, pp. 186205. The MIT Press, Cambridge.
Amiot, E., Noll, T., Agon, C., & Andreatta, M. (2006). Fourier oracles for computer-aided
improvisation. In Proceedings of the International Computer Music Conference.
Anders, T. (2007). Composing Music by Composing Rules: Design and Usage of a Generic
Music Constraint System. Ph.D. thesis, Queens University Belfast.
563

fiFernndez & Vico

Anders, T., & Miranda, E. R. (2009). A computational model that generalises Schoenbergs
guidelines for favourable chord progressions. In Proceedings of the Sound and Music
Computing Conference.
Anders, T., & Miranda, E. R. (2011). Constraint programming systems for modeling music
theories and composition. ACM Computing Surveys, 43 (4), 30:130:38.
Ando, D., & Iba, H. (2007). Interactive composition aid system by means of tree representation of musical phrase. In Proceedings of the IEEE Conference on Evolutionary
Computation, pp. 42584265.
Ariza, C. (2005a). Navigating the landscape of computer aided algorithmic composition
systems: A definition, seven descriptors, and a lexicon of systems and research. In
Proceedings of the International Computer Music Conference.
Ariza, C. (2005b). An Open Design for Computer-Aided Algorithmic Music Composition:
athenaCL. Ph.D. thesis, New York University.
Ariza, C. (2006). Beyond the transition matrix: A language-independent, string-based input
notation for incomplete, multiple-order, static Markov transition values. Unpublished
manuscript.
Ariza, C. (2007). Automata bending: Applications of dynamic mutation and dynamic rules
in modular One-Dimensional cellular automata. Computer Music Journal, 31 (1),
2949.
Ariza, C. (2009). The interrogator as critic: The Turing test and the evaluation of generative
music systems. Computer Music Journal, 33 (2), 4870.
Ariza, C. (2011). Two pioneering projects from the early history of computer-aided algorithmic composition. Computer Music Journal, 35 (3), 4056.
Aschauer, D. (2008). Algorithmic composition. Masters thesis, Vienna University of Technology.
Assayag, G., & Dubnov, S. (2004). Using factor oracles for machine improvisation. Soft
Computing - A Fusion of Foundations, Methodologies and Applications, 8 (9), 604610.
Assayag, G., Rueda, C., Laurson, M., Agon, C., & Delerue, O. (1999). Computer-Assisted
composition at IRCAM: From PatchWork to OpenMusic. Computer Music Journal,
23 (3), 5972.
Baeten, J. C. M. (2005). A brief history of process algebra. Theoretical Computer Science,
335 (23), 131146.
Baggi, D. L. (1991). Neurswing: an intelligent workbench for the investigation of swing in
jazz. Computer, 24 (7), 6064.
Balaban, M., Ebciolu, K., & Laske, O. E. (1992). Understanding music with AI : perspectives on music cognition. The MIT Press, Cambridge.
Ball, P. (2005). Making music by numbers online. Nature News Online
(http://dx.doi.org/10.1038/050919-14).
Ball, P. (2012). Computer science: Algorithmic rapture. Nature, 488 (7412), 458.
564

fiAI Methods in Algorithmic Composition

Baroni, M., & Jacoboni, C. (1978). Proposal for a grammar of melody : The Bach chorales.
Les Presses de lUniversit de Montral.
Bel, B. (1992). Modelling improvisatory and compositional processes. Languages of Design,
Formalisms for Word, Image and Sound, 1, 1126.
Bellgard, M. I., & Tsang, C. P. (1992). Harmonizing music using a network of Boltzmann
machines. In Proceedings of the Annual Conference of Artificial Neural Networks and
their Applications, pp. 321332, France.
Berg, P. (2011). Using the AC Toolbox. Institute of Sonology, Royal Conservatory, The
Hague.
Beyls, P. (1989). The musical universe of cellular automata. In Proceedings of the International Computer Music Conference, pp. 3441.
Beyls, P. (2003). Selectionist musical automata: Integrating explicit instruction and evolutionary algorithms. In Proceedings of the Brazilian Symposium on Computer Music.
Beyls, P. (2007). Interaction and self-organisation in a society of musical agents. In Proceedings of the European Conference on Artificial Life.
Bidlack, R. (1992). Chaotic systems as simple (but complex) compositional algorithms.
Computer Music Journal, 16 (3), 3347.
Biles, J. A. (1994). GenJam: A genetic algorithm for generating jazz solos. In Proceedings
of the International Computer Music Conference.
Biles, J. A. (1998). Interactive GenJam: Integrating real-time performance with a genetic
algorithm. In Proceedings of the International Computer Music Conference.
Biles, J. A., Anderson, P., & Loggi, L. (1996). Neural network fitness functions for a
musical IGA. In Proceedings of the International Symposium on Intelligent Industrial
Automation and Soft Computing.
Bilotta, E., & Pantano, P. (2001). Artificial life music tells of complexity. In Proceedings of
the European Conference on Artificial Life.
Bilotta, E., & Pantano, P. (2002). Synthetic harmonies: An approach to musical semiosis
by means of cellular automata. Leonardo, 35 (2), 153159.
Birchfield, D. A. (2003). Evolving intelligent musical materials. Ph.D. thesis, Columbia
University, New York.
Biyikoglu, K. M. (2003). A Markov model for chorale harmonization. In Proceedings of the
Triennial ESCOM Conference.
Blackwell, T. M., & Bentley, P. (2002). Improvised music with swarms. In Proceedings of
the IEEE Conference on Evolutionary Computation, pp. 14621467.
Boden, M. A. (2009). Computer models of creativity. AI Magazine, 30 (3), 2334.
Boenn, G., Brain, M., De Vos, M., & Fitch, J. (2008). Automatic composition of melodic
and harmonic music by Answer Set Programming. In Proceedings of the International
Conference on Logic Programming, pp. 160174.
Bolognesi, T. (1983). Automatic composition: Experiments with self-similar music. Computer Music Journal, 7 (1), 2536.
565

fiFernndez & Vico

Bosma, M. (2005). Musicology in a virtual world: A bottom up approach to the study of
musical evolution. Masters thesis, University of Groningen and University of Plymouth.
Boulanger, R. C. (Ed.). (2000). The Csound Book: Perspectives in Software Synthesis,
Sound Design, Signal Processing, and Programming. The MIT Press.
Bown, O., & McCormack, J. (2010). Taming nature: tapping the creative potential of
ecosystem models in the arts. Digital Creativity, 21 (4), 215231.
Bown, O., & Wiggins, G. A. (2005). Modelling musical behaviour in a cultural-evolutionary
system. In Proceedings of the International Joint Conference on Artificial Inteligence.
Brooks, F. P., Hopkins, A. L., Neumann, P. G., & Wright, W. V. (1957). An experiment in
musical composition. IRE Transactions on Electronic Computers, EC-6 (3), 175182.
Browne, T. M., & Fox, C. (2009). Global Expectation-Violation as fitness function in evolutionary composition. In Proceedings of the Conference on Applications of Evolutionary
Computation, pp. 538546.
Bryden, K. (2006). Using a Human-in-the-Loop evolutionary algorithm to create DataDriven music. In Proceedings of the IEEE Conference on Evolutionary Computation,
pp. 20652071.
Bulley, J., & Jones, D. (2011). Variable 4: A dynamical composition for weather systems.
In Proceedings of the International Computer Music Conference.
Burns, K. (1994). The History and Development of Algorithms in Music Composition,
1957-1993. Ph.D. thesis, Ball State University.
Burraston, D., & Edmonds, E. (2005). Cellular automata in generative electronic music
and sonic art: a historical and technical review. Digital Creativity, 16 (3), 165185.
Burton, A. R. (1998). A Hybrid Neuro-Genetic Pattern Evolution System Applied to Musical
Composition. Ph.D. thesis, University of Surrey.
Burton, A. R., & Vladimirova, T. (1999). Generation of musical sequences with genetic
techniques. Computer Music Journal, 23 (4), 5973.
Buttram, T. (2003). DirectX 9 Audio Exposed: Interactive Audio Development, chap. Beyond Games: Bringing DirectMusic into the Living Room. Wordware Publishing Inc.
Carpentier, G., & Bresson, J. (2010). Interacting with symbol, sound, and feature spaces
in orchide, a computer-aided orchestration environment. Computer Music Journal,
34 (1), 1027.
Chemillier, M. (2004). Toward a formal study of jazz chord sequences generated by Steedmans grammar. Soft Computing - A Fusion of Foundations, Methodologies and Applications, 8 (9), 617622.
Chemillier, M., & Truchet, C. (2001). Two musical CSPs. In Proceedings of the International
Conference on Principles and Practice of Constraint Programming.
Chen, C. C. J., & Miikkulainen, R. (2001). Creating melodies with evolving recurrent neural
networks. In Proceedings of the International Joint Conference on Neural Networks,
pp. 22412246.
566

fiAI Methods in Algorithmic Composition

Chusid, I. (1999). Beethoven-in-a-box: Raymond scotts electronium. Contemporary Music
Review, 18 (3), 914.
Coca, A. E., Romero, R. A. F., & Zhao, L. (2011). Generation of composed musical structures through recurrent neural networks based on chaotic inspiration. In Proceedings
of the International Joint Conference on Neural Networks, pp. 32203226.
Coghlan, A. (2012).
215 (2872), 7.

Computer composer honours Turings centenary.

New Scientist,

Cohen, J. E. (1962). Information theory and music. Behavioral Science, 7 (2), 137163.
Collins, N. (2009). Musical form and algorithmic composition. Contemporary Music Review,
28 (1), 103114.
Conklin, D. (2003). Music generation from statistical models. In Proceedings of the Symposium on Artificial Intelligence and Creativity in Arts and Science.
Conklin, D., & Witten, I. (1995). Multiple viewpoint systems for music prediction. Journal
of New Music Research, 24 (1), 5173.
Cope, D. (1992). Computer modeling of musical intelligence in EMI. Computer Music
Journal, 16 (2), 6983.
Cope, D. (2000). The Algorithmic Composer. A-R Editions.
Cope, D. (2005). Computer Models of Musical Creativity. The MIT Press, Cambridge.
Courtot, F. (1990). A constraint-based logic program for generating polyphonies. In Proceedings of the International Computer Music Conference, pp. 292294.
Cruz-Alczar, P. P., & Vidal-Ruiz, E. (1998). Learning regular grammars to model musical style: Comparing different coding schemes. In Proceedings of the International
Colloquium on Grammatical Inference, pp. 211222.
Dahlstedt, P. (2007). Autonomous evolution of complete piano pieces and performances. In
Proceedings of the European Conference on Artificial Life.
Dahlstedt, P., & Nordahl, M. G. (2001). Living melodies: Coevolution of sonic communication. Leonardo, 34 (3), 243248.
Dalhoum, A. A., Alfonseca, M., Cebrin, M., Snchez-Alfonso, R., & Ortega, A. (2008).
Computer-generated music using grammatical evolution. In Proceedings of the MiddleEast Simulation Multiconference, pp. 5560.
Davismoon, S., & Eccles, J. (2010). Combining musical constraints with Markov transition
probabilities to improve the generation of creative musical structures. In Proceedings
of the European Conference on the Applications of Evolutionary Computation.
De Prisco, R., Zaccagnino, G., & Zaccagnino, R. (2010). EvoBassComposer: a multiobjective genetic algorithm for 4-voice compositions. In Proceedings of the Genetic
and Evolutionary Computation Conference.
Degazio, B. (1996). The evolution of musical organisms. Leonardo Music Journal, 7, 2733.
Daz-Jerez, G. (2000). Algorithmic Music Using Mathematical Models. Ph.D. thesis, Manhattan School of Music.
567

fiFernndez & Vico

Daz-Jerez, G. (2011). Composing with Melomics: Delving into the computational world
for musical inspiration. Leonardo Music Journal, 21, 1314.
Dobrian, C. (1993). Music and artificial intelligence. Unpublished manuscript. Available at
http://music.arts.uci.edu/dobrian/CD.music.ai.htm.
Doornbusch, P. (2002). A brief survey of mapping in algorithmic composition. In Proceedings
of the International Computer Music Conference.
Dorin, A. (2000). Boolean networks for the generation of rhythmic structure. In Proceedings
of the Australasian Computer Music Conference, pp. 3845.
Dorin, A. (2002). Liquiprism : Generating polyrhythms with cellular automata. In Proceedings of the International Conference on Auditory Display.
Drewes, F., & Hgberg, J. (2007). An algebra for tree-based music generation. In Proceedings
of the International Conference on Algebraic Informatics, pp. 172188.
Dubnov, S., Assayag, G., Lartillot, O., & Bejerano, G. (2003). Using machine-learning
methods for musical style modeling. Computer, 36 (10), 7380.
DuBois, R. L. (2003). Applications of Generative String-Substitution Systems in Computer
Music. Ph.D. thesis, Columbia University.
Duff, M. O. (1989). Backpropagation and Bachs 5th cello suite (Sarabande). In Proceedings
of the International Joint Conference on Neural Networks, p. 575.
Ebciolu, K. (1980). Computer counterpoint. In Proceedings of the International Computer
Music Conference.
Ebciolu, K. (1988). An expert system for harmonizing four-part chorales. Computer Music
Journal, 12 (3), 4351.
Edwards, M. (2011). Algorithmic composition: computational thinking in music. Communications of the ACM, 54 (7), 5867.
Eigenfeldt, A., & Pasquier, P. (2010). Realtime generation of harmonic progressions using controlled Markov selection. In Proceedings of the International Conference on
Computational Creativity.
Eldridge, A., & Dorin, A. (2009). Filterscape: Energy recycling in a creative ecosystem. In
Proceedings of the Conference on Applications of Evolutionary Computation.
Eno, B. (1996). Generative Music, speech at the Imagination Conference. Available at
http://www.inmotionmagazine.com/eno1.html.
Esp, D., Ponce de Len, P. J., Prez-Sancho, C., Rizo, D., nesta, J. I., Moreno-Seco, F., &
Pertusa, A. (2007). A cooperative approach to style-oriented music composition. In
Proceedings of the International Joint Conference on Artificial Inteligence.
Farbood, M., & Schoner, B. (2001). Analysis and synthesis of Palestrina-style counterpoint
using Markov chains. In Proceedings of the International Computer Music Conference.
Farnell, A. (2007). An introduction to procedural audio and itsapplication in computer
games. In Proceedings of the Audio Mostly Conference.
Farrell, S., Jan Wagenmakers, E., & Ratcliff, R. (2006). 1/f noise in human cognition: Is it
ubiquitous, and what does it mean?. Psychonomic Bulletin & Review, 13 (4), 737741.
568

fiAI Methods in Algorithmic Composition

Feulner, J., & Hrnel, D. (1994). MELONET: neural networks that learn harmony-based
melodic variations. In Proceedings of the International Computer Music Conference,
pp. 121124, San Francisco.
Fox, C. W. (2006). Genetic hierarchical music structures. In Proceedings of the International
Florida Artificial Research Society Conference.
Franklin, J. (2001). Multi-phase learning for jazz improvisation and interaction. In Proceedings of the Biennial Symposium on Arts and Technology.
Freitas, A., & Guimares, F. (2011). Melody harmonization in evolutionary music using
multiobjective genetic algorithms. In Proceedings of the Sound and Music Computing
Conference.
Fry, C. (1984). Flavors band: A language for specifying musical style. Computer Music
Journal, 8 (4), 2034.
Garay Acevedo, A. (2004). Fugue composition with counterpoint melody generation using
genetic algorithms. In Proceedings of the International Conference on Computer Music
Modeling and Retrieval, pp. 96106.
Gartland-Jones, A. (2002). Can a genetic algorithm think like a composer?. In Proceedings
of the Generative Art Conference.
Geem, Z. W., & Choi, J. Y. (2007). Music composition using harmony search algorithm.
In Proceedings of the Conference on Applications of Evolutionary Computation, pp.
593600.
Geis, M., & Middendorf, M. (2008). Creating melodies and baroque harmonies with ant
colony optimization. International Journal of Intelligent Computing and Cybernetics,
1 (2), 213218.
Gero, J. S. (2000). Computational models of innovative and creative design processes.
Technological Forecasting and Social Change, 64 (23), 183196.
Gibson, P. M., & Byrne, J. A. (1991). NEUROGEN, musical composition using genetic
algorithms and cooperating neural networks. In Proceedings of the International Conference on Artificial Neural Networks, pp. 309313.
Gill, S. (1963). A technique for the composition of music in a computer. The Computer
Journal, 6 (2), 129133.
Gillick, J., Tang, K., & Keller, R. M. (2009). Learning jazz grammars. In Proceedings of
the Sound and Music Computing Conference, pp. 125130.
Gjerdingen, R. (1988). Explorations in Music, the Arts, and Ideas: Essays in Honor of
Leonard B. Meyer, chap. Concrete musical knowledge and a computer program for
species counterpoint, pp. 199228. Pendragon Press.
Gogins, M. (1991). Iterated functions systems music. Computer Music Journal, 15 (1),
4048.
Gogins, M. (2006). Score generation in voice-leading and chord spaces. In Proceedings of
the International Computer Music Conference.
569

fiFernndez & Vico

Goldman, C., Gang, D., Rosenschein, J., & Lehmann, D. (1996). NETNEG: a hybrid
interactive architecture for composing polyphonic music in real time. In Proceedings
of the International Computer Music Conference, pp. 133140.
Grachten, M. (2001). JIG : jazz improvisation generator. In Proceedings of the Workshop on
Current Research Directions in Computer Music, pp. 16. Audiovisual Institute-UPF.
Gwee, N. (2002). Complexity and Heuristics in Rule-Based Algorithmic Music Composition.
Ph.D. thesis, Louisiana State University.
Hamanaka, M., Hirata, K., & Tojo, S. (2008). Melody morphing method based on GTTM.
In Proceedings of the International Computer Music Conference, pp. 155158.
Harris, R. (2008). Algorithmic composition of jazz. Masters thesis, University of Bath.
Hartmann, P. (1990). Natural selection of musical identities. In Proceedings of the International Computer Music Conference.
Haus, G., & Sametti, A. (1991). Scoresynth: a system for the synthesis of music scores
based on Petri nets and a music algebra. IEEE Computer, 24 (7), 5660.
Herman, M. (1993). Deterministic chaos, iterative models, dynamical systems and their
application in algorithmic composition. In Proceedings of the International Computer
Music Conference.
Herremans, D., & Sorensena, K. (2012). Composing first species counterpoint with a variable
neighbourhood search algorithm. Journal of Mathematics and the Arts, 6 (4), 169189.
Hild, H., Feulner, J., & Menzel, D. (1992). HARMONET: a neural net for harmonising
chorales in the style of J.S. Bach. In Proceedings of the Conference on Neural Information Processing Systems.
Hiller, L. A., & Isaacson, L. M. (1958). Musical composition with a High-Speed digital
computer. Journal of the Audio Engineering Society, 6 (3), 154160.
Hinojosa-Chapel, R. (2003). Realtime algorithmic music systems from fractals and chaotic
functions: Toward an active musical instrument. Masters thesis, Universitat Pompeu
Fabra.
Hirata, K., & Aoyagi, T. (1988). How to realize jazz feelings: a logic programming approach. In Proceedings of the International Conference on Fifth Generation Computer
Systems.
Hoffmann, P. (2002). Towards an "automated art": Algorithmic processes in xenakis compositions. Contemporary Music Review, 21 (2-3), 121131.
Holm, F. (1990). CESAM: A concept engine for synthesis of audio and music. In Proceedings
of the International Computer Music Conference.
Holtzman, S. R. (1981). Using generative grammars for music composition. Computer
Music Journal, 5 (1), 5164.
Hoover, A. K., Szerlip, P. A., Norton, M. E., Brindle, T. A., Merritt, Z., & Stanley, K. O.
(2012). Generating a complete multipart musical composition from a single monophonic melody with functional scaffolding. In Proceedings of the International Conference on Computational Creativity.
570

fiAI Methods in Algorithmic Composition

Hrnel, D., & Degenhardt, P. (1997). A neural organist improvising baroque-style melodic
variations. In Proceedings of the International Computer Music Conference, pp. 430
433.
Hrnel, D., & Ragg, T. (1996). A connectionist model for the evolution of styles of harmonization. In Proceedings of the International Conference on Music Perception and
Cognition.
Horner, A., & Ayers, L. (1995). Harmonization of musical progressions with genetic algorithms. In Proceedings of the International Computer Music Conference.
Horner, A., & Goldberg, D. E. (1991). Genetic algorithms and computer-assisted music
composition. In Proceedings of the International Conference on Genetic Algorithms,
pp. 337441.
Horowitz, M. D. (1994). Generating rhythms with genetic algorithms. In Proceedings of the
AAAI National Conference on Artificial intelligence, Menlo Park.
Horowitz, M. D. (1995). Representing musical knowledge. Ph.D. thesis, Columbia University.
Hs, K. J., & Hs, A. (1991). Self-similarity of the "1/f noise" called music. Proceedings of
the National Academy of Sciences of the United States of America, 88 (8), 35073509.
Hunt, A., Kirk, R., & Orton, R. (1991). Musical applications of a cellular automata workstation. In Proceedings of the International Computer Music Conference.
Jacob, B. L. (1995). Composing with genetic algorithms. In Proceedings of the International
Computer Music Conference.
Jensen, J. H. (2011). Evolutionary music composition: A quantitative approach. Masters
thesis, Norwegian University of Science and Technology.
Johanson, B., & Poli, R. (1998). GP-music: An interactice genetic programming system
for music generation with automated fitness raters. In Proceedings of the Annual
Conference on Genetic Programming, pp. 181186.
Johnson, M., Tauritz, D. R., & Wilkerson, R. (2004). Evolutionary computation applied to
melody generation. In Proceedings of the Artificial Neural Networks in Engineering
(ANNIE) Conference.
Jones, K. (1980). A space grammar for the stochastic generation of Multi-Dimensional
structures. In Proceedings of the International Computer Music Conference.
Jones, K. (1981). Compositional applications of stochastic processes. Computer Music
Journal, 5 (2), 4561.
Jones, K. (1989). Generative models in computer-assisted musical composition. Contemporary Music Review, 3 (1), 177196.
Kaliakatsos-Papakostas, M. A., Epitropakis, M. G., Floros, A., & Vrahatis, M. N. (2012).
Interactive evolution of 8-Bit melodies with genetic programming towards finding aesthetic measures for sound evolutionary and biologically inspired music, sound, art and
design. In Proceedings of the International Conference on Evolutionary and Biologically Inspired Music, Sound, Art and Design, pp. 141152.
571

fiFernndez & Vico

Keller, R. M., & Morrison, D. R. (2007). A grammatical approach to automatic improvisation. In Proceedings of the Sound and Music Computing Conference, pp. 330337.
Khalifa, Y. M. A., Khan, B. K., Begovic, J., Wisdom, A., & Wheeler, A. M. (2007). Evolutionary music composer integrating formal grammar. In Proceedings of the Genetic
and Evolutionary Computation Conference, pp. 25192526, New York.
Kippen, J., & Bel, B. (1989). The identification and modelling of a percussion language,
and the emergence of musical concepts in a machine-learning experimental set-up.
Computers and the Humanities, 23 (3), 199214.
Kirke, A., & Miranda, E. (2009). A survey of computer systems for expressive music
performance. ACM Computing Surveys, 42 (1), 3:13:41.
Kitani, K. M., & Koike, H. (2010). ImprovGenerator: Online grammatical induction for onthe-fly improvisation accompaniment. In Proceedings of the International Conference
on New Interfaces for Musical Expression.
Klinger, R., & Rudolph, G. (2006). Evolutionary composition of music with learned melody
evaluation. In Proceedings of the WSEAS International Conference on Computational
Intelligence, Man-Machine Systems and Cybernetics, pp. 234239, Stevens Point, Wisconsin, USA.
Kohonen, T., Laine, P., Tiits, K., & Torkkola, K. (1991). Music and Connectionism, chap.
A Nonheuristic Automatic Composing Method, pp. 229242. The MIT Press, Cambridge.
Kugel, P. (1990). Myhills Thesis: Theres more than computing in musical thinking. Computer Music Journal, 14 (3), 1225.
Laine, P. (2000). A Method for Generating Musical Motion Patterns. Ph.D. thesis, University of Helsinki.
Laine, P., & Kuuskankare, M. (1994). Genetic algorithms in musical style oriented generation. In Proceedings of the IEEE Conference on Evolutionary Computation, pp.
858862.
Langston, P. (1989). Six techniques for algorithmic music composition. In Proceedings of
the International Computer Music Conference.
Laurson, M., & Kuuskankare, M. (2000). Towards idiomatic instrumental writing: A constraint based approach. In Proceedings of the Annual Symposium on Systems Research
in the Arts.
Leach, J., & Fitch, J. (1995). Nature, music, and algorithmic composition. Computer Music
Journal, 19 (2), 2333.
Lerdahl, F., Jackendoff, R., & Jackendoff, R. S. (1983). A Generative Theory of Tonal
Music. The MIT Press, Cambridge.
Levitt, D. A. (1981). A melody description system for jazz improvisation. Masters thesis,
Massachusetts Institute of Technology.
Lewis, J. P. (1991). Music and Connectionism, chap. Creation by refinement and the problem of algorithmic music composition. The MIT Press, Cambridge.
572

fiAI Methods in Algorithmic Composition

Lidov, D., & Gabura, J. (1973). A melody writing algorithm using a formal language model.
Computer Studies in the Humanities and Verbal Behavior, 4 (34), 138148.
Lo, M. Y. (2012). Evolving Cellular Automata for Music Composition with Trainable Fitness
Functions. Ph.D. thesis, University of Essex.
Lo, M., & Lucas, S. M. (2006). Evolving musical sequences with N-Gram based trainable fitness functions. In Proceedings of the IEEE Conference on Evolutionary Computation,
pp. 601608.
Lthe, M. (1999). Knowledge based automatic composition and variation of melodies for
minuets in early classical style. In Proceedings of the Annual German Conference on
Artificial Intelligence, pp. 159170.
Loy, G., & Abbott, C. (1985). Programming languages for computer music synthesis, performance, and composition. ACM Computing Surveys, 17 (2), 235265.
Lozano, L., Medaglia, A. L., & Velasco, N. (2009). Generation of Pop-Rock chord sequences
using genetic algorithms and variable neighborhood search. In Proceedings of the
Conference on Applications of Evolutionary Computation, pp. 573578.
Lyon, D. (1995). Using stochastic Petri nets for real-time Nth-order stochastic composition.
Computer Music Journal, 19 (4), 1322.
MacCallum, R. M., Mauch, M., Burt, A., & Leroi, A. M. (2012). Evolution of music by
public choice. Proceedings of the National Academy of Sciences of the United States
of America, 109 (30), 1208112086.
Maddox, T., & Otten, J. (2000). Using an evolutionary algorithm to generate Four-Part
18th century harmony. In Proceedings of the WSEAS International Conference on
Mathematics and Computers in Business and Economics.
Manaris, B., Hughes, D., & Vassilandonakis, Y. (2011). Monterey mirror: Combining
Markov models, genetic algorithms, and power laws. In Proceedings of the IEEE
Conference on Evolutionary Computation.
Manaris, B., Roos, P., Machado, P., Krehbiel, D., Pellicoro, L., & Romero, J. (2007). A
corpus-based hybrid approach to music analysis and composition. In Proceedings of
the AAAI National Conference on Artificial intelligence, pp. 839845.
Manousakis, S. (2006). Musical L-Systems. Masters thesis, The Royal Conservatory, The
Hague.
Marques, V. M., Oliveira, V., Vieira, S., & Rosa, A. C. (2000). Music composition using genetic evolutionary algorithms. In Proceedings of the IEEE Conference on Evolutionary
Computation, pp. 714719.
Marques, V. M., Reis, C., & Machado, J. A. T. (2010). Interactive evolutionary computation
in music. In Proceedings of the IEEE International Conference on Systems, Man and
Cybernetics, pp. 35013507.
Martin, A., Jin, C. T., & Bown, O. (2012). Implementation of a real-time musical decisionmaker. In Proceedings of the Australasian Computer Music Conference.
573

fiFernndez & Vico

Martin, A., Jin, C. T., van Schaik, A., & Martens, W. L. (2010). Partially observable Markov
decision processes for interactive music systems. In Proceedings of the International
Computer Music Conference.
Mason, S., & Saffle, M. (1994). L-Systems, melodies and musical structure. Leonardo Music
Journal, 4, 3138.
Maurer, J. (1999). A brief history of algorithmic composition. Unpublished manuscript.
Available at https://ccrma.stanford.edu/~blackrse/algorithm.html.
McAlpine, K., Miranda, E., & Hoggar, S. (1999). Making music with algorithms: A CaseStudy system. Computer Music Journal, 23 (2), 1930.
McCartney, J. (2002). Rethinking the computer music language: SuperCollider. Computer
Music Journal, 26 (4), 6168.
McCormack, J. (1996). Grammar-Based music composition. Complexity International, 3,
320336.
McCormack, J. (2003a). The Application of L-systems and Developmental Models to Computer Art, Animation and Music Synthesis. Ph.D. thesis, Monash University.
McCormack, J. (2003b). Evolving sonic ecosystems. Kybernetes, 32 (12), 184202.
McDermott, J., & OReilly, U. M. (2011). An executable graph representation for evolutionary generative music. In Proceedings of the Genetic and Evolutionary Computation
Conference, pp. 403410, New York.
McGuire, K. (2006). ArpEgg: a rewriting grammar for complex arpeggios. In Proceedings
of the Generative Art Conference.
McIntyre, R. A. (1994). Bach in a box: the evolution of four part baroque harmony using the genetic algorithm. In Proceedings of the IEEE Conference on Evolutionary
Computation, pp. 852857.
Melo, A. F. (1998). A connectionist model of tension in chord progressions. Masters thesis,
University of Edinburgh.
Miljkovic, K. (2007). From Mathematica to live performance: Mapping simple programs to
music. In Proceedings of the International Conference on Mathematics and Computation in Music.
Millen, D. (1990). Cellular automata music. In Proceedings of the International Computer
Music Conference.
Miranda, E. R. (1993). Cellular automata music: An interdisciplinary project. Journal of
New Music Research, 22 (1), 321.
Miranda, E. R. (2002). Mimetic development of intonation. In Proceedings of the International Conference on Music and Artificial Intelligence.
Miranda, E. R. (2007). Evolutionary Computer Music, chap. Cellular Automata Music:
From Sound Synthesis to Musical Forms, pp. 170193. Springer-Verlag London.
Miranda, E. R., & Biles, J. A. (Eds.). (2007). Evolutionary computer music. Springer-Verlag
London.
574

fiAI Methods in Algorithmic Composition

Miranda, E. R., Kirby, S., & Todd, P. M. (2003). On computational models of the evolution of music: From the origins of musical taste to the emergence of grammars.
Contemporary Music Review, 22 (3), 91111.
Moorer, J. A. (1972). Music and computer composition. Communications of the ACM,
15 (2), 104113.
Morales, E., & Morales, R. (1995). Learning musical rules. In Proceedings of the International Joint Conference on Artificial Inteligence.
Morgan, N. (2007). Transformation and mapping of L-Systems data in the composition of a
large-scale instrumental work. In Proceedings of the European Conference on Artificial
Life.
Moroni, A., Manzolli, J., Zuben, F. V., & Gudwin, R. (2000). Vox Populi: An interactive
evolutionary system for algorithmic music composition. Leonardo Music Journal, 10,
4954.
Morris, D., Simon, I., & Basu, S. (2008). Exposing parameters of a trained dynamic model
for interactive music creation. In Proceedings of the AAAI National Conference on
Artificial intelligence, pp. 784791.
Mozer, M. (1991). Music and Connectionism, chap. Connectionist music composition based
on melodic, stylistic, and psychophysical constraints, pp. 195211. The MIT Press,
Cambridge.
Nelson, G. L. (1993). Sonomorphs: An application of genetic algorithms to the growth and
development of musical organisms. In Proceedings of the Biennial Symposium on Arts
and Technology, pp. 155169.
Nelson, G. L. (1996). Real time transformation of musical material with fractal algorithms.
Computers & Mathematics with Applications, 1, 109116.
Nettheim, N. (1992). On the spectral analysis of melody. Journal of New Music Research,
21 (2), 135148.
Nettheim, N. (1997). A bibliography of statistical applications in musicology. Musicology
Australia, 20 (1), 94106.
Nierhaus, G. (2009). Algorithmic Composition: Paradigms of Automated Music Generation.
Springer Berlin / Heidelberg.
Nishijimi, M., & Watanabe, K. (1993). Interactive music composer based on neural networks. Fujitsu Scientific Technical Journal, 29 (2), 189192.
North, T. (1991). A technical explanation of theme and variations: A computer music work
utilizing network compositional algorithms. Ex Tempore, 5 (2).
Olarte, C., Rueda, C., & Valencia, F. D. (2009). New Computational Paradigms for Computer Music, chap. Concurrent Constraint Calculi: a Declarative Paradigm for Modeling Music Systems. Editions Delatour France.
Olson, H. F. (1961). Aid to music composition employing a random probability system.
Journal of the Acoustical Society of America, 33, 11631170.
575

fiFernndez & Vico

Ortega, A., Snchez, R., & Alfonseca, M. (2002). Automatic composition of music by means
of grammatical evolution. In Proceedings of the Conference on APL.
Ovans, R., & Davison, R. (1992). An interactive Constraint-Based expert assistant for music
composition. In Proceedings of the Canadian Conference on Artificial Intelligence, pp.
7681.
zcan, E., & Eral, T. (2008). A genetic algorithm for generating improvised music. In
Proceedings of the International Conference on Artificial Evolution, pp. 266277.
Pachet, F. (2002). Interacting with a musical learning system: The Continuator. In Proceedings of the International Conference on Music and Artificial Intelligence, pp. 103108.
Pachet, F., & Roy, P. (1995). Mixing constraints and objects: a case study in automatic
harmonization. In Proceedings of the Conference on Technology of Object-Oriented
Languages and Systems.
Pachet, F., & Roy, P. (2001). Musical harmonization with constraints: A survey. Constraints,
6 (1), 719.
Pachet, F., Roy, P., & Barbieri, G. (2011). Finite-length Markov processes with constraints.
In Proceedings of the International Joint Conference on Artificial Inteligence.
Padberg, H. A. (1964). Computer-composed canon and free-fugue. Ph.D. thesis, Saint Louis
University, St. Louis.
Papadopoulos, G., & Wiggins, G. (1998). A genetic algorithm for the generation of jazz
melodies. In Proceedings of the Finnish Conference on Artificial Intelligence (STeP).
Papadopoulos, G., & Wiggins, G. (1999). AI methods for algorithmic composition: A survey,
a critical view and future prospects. In Proceedings of the Symposium on Musical
Creativity, pp. 110117.
Parikh, T. (2003). Iris: artificially intelligent real-time improvisation system. Masters
thesis, Emory University.
Pazos, A., Santos del Riego, A., Dorado, J., & Romero Caldalda, J. J. (1999). Genetic music
compositor. In Proceedings of the IEEE Conference on Evolutionary Computation, pp.
885890.
Pearce, M., Meredith, D., & Wiggins, G. (2002). Motivations and methodologies for automation of the compositional process. Music Scienti, 6 (2), 119147.
Pearce, M., & Wiggins, G. (2001). Towards a framework for the evaluation of machine
compositions. In Proceedings of the Symposium on Artificial Intelligence and Creativity
in Arts and Science, pp. 2232.
Peck, J. M. (2011). Explorations in algorithmic composition: Systems of composition and
examination of several original works. Masters thesis, State University of New York,
College at Oswego.
Pennycook, B. (1985). Computer-music interfaces: A survey. ACM Computing Surveys,
17 (2), 267289.
Pereira, F., Grilo, C., Macedo, L., & Cardoso, A. (1997). Composing music with case-based
reasoning. In Proceedings of the Conference on Computational Models of Creative
Cognition.
576

fiAI Methods in Algorithmic Composition

Pestana, P. (2012). Lindenmayer systems and the harmony of fractals. Chaotic Modeling
and Simulation, 1 (1), 9199.
Phon-Amnuaisuk, S. (2002). Control language for harmonisation process. In Proceedings of
the International Conference on Music and Artificial Intelligence, pp. 155167.
Phon-Amnuaisuk, S. (2010). Investigating music pattern formations from heterogeneous
cellular automata. Journal of New Music Research, 39 (3), 253267.
Phon-Amnuaisuk, S., Law, E. H., & Kuan, H. C. (2007). Evolving music generation with
SOM-fitness genetic programming. In Proceedings of the Conference on Applications
of Evolutionary Computation, pp. 557566.
Phon-Amnuaisuk, S., Tuson, A., & Wiggins, G. (1999). Evolving musical harmonisation.
In Proceedings of the International Conference on Artificial Neural Nets and Genetic
Algorithms.
Pinkerton, R. C. (1956). Information theory and melody. Scientific American, 194 (2),
7787.
Polito, J., Daida, J. M., & Bersano Begey, T. F. (1997). Musica ex machina: Composing
16th-Century counterpoint with genetic programming and symbiosis. In Proceedings
of the International Conference on Evolutionary Programming, pp. 113124.
Ponsford, D., Wiggins, G., & Mellish, C. (1999). Statistical learning of harmonic movement.
Journal of New Music Research, 28 (2), 150177.
Pope, S. T. (1986). Music notations and the representation of musical structure and knowledge. Perspectives of New Music, 24 (2), 156189.
Pope, S. T. (1991). A tool for manipulating expressive and structural hierarchies in music
(or: "T-R trees in the MODE: A tree editor based loosely on Freds theory"). In
Proceedings of the International Computer Music Conference.
Pope, S. T. (1993). Music Processing, chap. Music composition and editing by computer,
pp. 2572. Oxford University Press.
Pope, S. T. (1995). Fifteen years of computer-assisted composition. In Proceedings of the
Brazilian Symposium on Computer Music.
Pressing, J. (1988). Nonlinear maps as generators of musical design. Computer Music
Journal, 12 (2), 3546.
Prusinkiewicz, P. (1986). Score generation with L-systems. In Proceedings of the International Computer Music Conference, pp. 455457.
Prusinkiewicz, P., & Lindenmayer, A. (1990). The algorithmic beauty of plants. SpringerVerlag New York.
Puckette, M. (2002). Max at Seventeen. Computer Music Journal, 26 (4), 3143.
Putnam, J. (1994). Genetic programming of music. Tech. rep., New mexico institute of
mining and technology.
Quick, D. (2010). Generating music using concepts from Schenkerian analysis and chord
spaces. Tech. rep., Yale University.
577

fiFernndez & Vico

Rader, G. M. (1974). A method for composing simple traditional music by computer.
Communications of the ACM, 17 (11), 631638.
Ralley, D. (1995). Genetic algorithms as a tool for melodic development. In Proceedings of
the International Computer Music Conference, pp. 501502.
Ramalho, G., & Ganascia, J.-G. (1994). Simulating creativity in jazz performance. In
Proceedings of the AAAI National Conference on Artificial intelligence, pp. 108113,
Menlo Park.
Ramrez, R., & Peralta, J. (1998). A constraint-based melody harmonizer. In Proceedings
of the Workshop on Constraints for Artistic Applications.
Reddin, J., McDermott, J., & ONeill, M. (2009). Elevated pitch: Automated grammatical
evolution of short compositions applications of evolutionary computing. In Proceedings
of the Conference on Applications of Evolutionary Computation, pp. 579584.
Reisig, W. (1998). Elements of Distributed Algorithms: Modeling and Analysis with Petri
Nets. Springer.
Rennie, J. (2010). Ray Kurzweils slippery futurism. IEEE Spectrum, 47 (12), 2428.
Ribeiro, P., Pereira, F. C., Ferrand, M., & Cardoso, A. (2001). Case-based melody generation
with MuzaCazUza. In Proceedings of the Symposium on Artificial Intelligence and
Creativity in Arts and Science, pp. 6774.
Ricanek, K., Homaifar, A., & Lebby, G. (1993). Genetic algorithm composes music. In
Proceedings of the Southeastern Symposium on System Theory, pp. 223227.
Riecken, D. (1998). WOLFGANG: "emotions" and architecture which enable learning to
compose music. In Proceedings of the International Conference of the Society for
Adaptive Behavior.
Ritchie, G. (2007). Some empirical criteria for attributing creativity to a computer program.
Journal for Artificial Intelligence, Philosophy and Cognitive Science, 17 (1), 6799.
Roads, C. (1977). Composing grammars. In Proceedings of the International Computer
Music Conference.
Roads, C. (1979). Grammars as representations for music. Computer Music Journal, 3 (1),
4855.
Roads, C. (1985). Research in music and artificial intelligence. ACM Computing Surveys,
17 (2), 163190.
Roads, C. (Ed.). (1992). The Music Machine: Selected Readings from Computer Music
Journal. The MIT Press.
Roads, C. (2004). Microsound. The MIT Press.
Roads, C., & Strawn, J. (Eds.). (1985). Foundations of computer music. The MIT Press.
Ross, B. J. (1995). A process algebra for stochastic music composition. In Proceedings of
the International Computer Music Conference.
Rothgeb, J. (1968). Harmonizing the unfigured bass: A computational Study. Ph.D. thesis,
Yale University.
578

fiAI Methods in Algorithmic Composition

Rowe, R. (1992). Interactive Music Systems: Machine Listening and Composing. The MIT
Press, Cambridge.
Rueda, C., lvarez, G., Quesada, L. O., Tamura, G., Valencia, F., Daz, J. F., & Assayag,
G. (2001). Integrating constraints and concurrent objects in musical applications: A
calculus and its visual language. Constraints, 6 (1), 2152.
Rueda, C., Assayag, G., & Dubnov, S. (2006). A concurrent constraints factor oracle model
for music improvisation. In Proceedings of the Latin American Informatics Conference.
Rueda, C., Lindberg, M., Laurson, M., Bloch, G., & Assayag, G. (1998). Integrating constraint programming in visual musical composition languages. In Proceedings of the
Workshop on Constraints for Artistic Applications.
Sabater, J., Arcos, J., & Lpez de Mntaras, R. (1998). Using rules to support case-based
reasoning for harmonizing melodies. In Proceedings of the AAAI Spring Symposium
on Multimodal Reasoning, pp. 147151.
Snchez-Quintana, C., Moreno-Arcas, F., Albarracn-Molina, D., Fernndez, J. D., & Vico,
F. (2013). Melomics: A case-study of AI in Spain. AI Magazine, 34 (3), 99103.
Sandred, O. (2004). Interpretation of everyday gestures  composing with rules. In Proceedings of the Music and Music Science Conference.
Sandred, O. (2010). PWMC, a constraint-solving system for generating music scores. Computer Music Journal, 34 (2), 824.
Santos, A., Arcay, B., Dorado, J., Romero, J. J., & Rodrguez, J. A. (2000). Evolutionary
computation systems for musical composition. In Proceedings of the International
Conference Acoustic and Music: Theory and Applications.
Sastry, A. (2011). N-gram modeling of tabla sequences using variable-length hidden Markov
models for improvisation and composition. Masters thesis, Georgia Institute of Technology.
Scaletti, C. (2002). Computer music languages, Kyma, and the future. Computer Music
Journal, 26 (4), 6982.
Schmidl, H. (2008). Pseudo-Genetic algorithmic composition. In Proceedings of the International Conference on Genetic and Evolutionary Methods.
Schottstaedt, W. (1989). Current directions in computer music research, chap. Automatic
Counterpoint, pp. 199214. The MIT Press, Cambridge.
Schulze, W. (2009). A Formal Language Theory Approach To Music Generation. Ph.D.
thesis, Stellenbosch University.
Schwanauer, S. (1993). Machine models of music, chap. A learning machine for tonal composition, pp. 511532. The MIT Press, Cambridge.
Schwanauer, S. M., & Levitt, D. A. (1993). Machine Models of Music. The MIT Press,
Cambridge.
Shao, J., McDermott, J., ONeill, M., & Brabazon, A. (2010). Jive: A generative, interactive, virtual, evolutionary music system applications of evolutionary computation.
In Proceedings of the Conference on Applications of Evolutionary Computation, pp.
341350.
579

fiFernndez & Vico

Shibata, N. (1991). A neural network-based method for chord/note scale association with
melodies. NEC Research and Development, 32 (3), 453459.
Simoni, M., & Dannenberg, R. B. (2013). Algorithmic Composition: A Guide to Composing
Music with Nyquist. University of Michigan Press.
Soddell, F., & Soddell, J. (2000). Microbes and music. In Proceedings of the Pacific Rim
International Conference on Artificial Intelligence.
Sowa, J. F. (1956). A machine to compose music. Instruction manual for GENIAC, Oliver
Garfield Company, Inc.
Spangler, R. R. (1999). Rule-Based Analysis and Generation of Music. Ph.D. thesis, California Institute of Technology.
Spector, L., & Alpern, A. (1994). Criticism, culture, and the automatic generation of
artworks. In Proceedings of the AAAI National Conference on Artificial intelligence,
pp. 38, Menlo Park.
Spector, L., & Alpern, A. (1995). Induction and recapitulation of deep musical structure. In
Proceedings of the International Joint Conference on Artificial Inteligence, pp. 4148.
Stanley, K., & Miikkulainen, R. (2003). A taxonomy for artificial embryogeny. Artificial
Life, 9 (2), 93130.
Steedman, M. J. (1984). A generative grammar for jazz chord sequences. Music Perception:
An Interdisciplinary Journal, 2 (1), 5277.
Steels, L. (1979). Reasoning modeled as a society of communicating experts. Masters
thesis, Massachusetts Institute of Technology, Cambridge.
Steels, L. (1986). Learning the craft of musical composition. In Proceedings of the International Computer Music Conference.
Stieler, W. (2012). Die mozart-Maschine. Technology Review (German edition), 12/2012,
2634.
Supper, M. (2001). A few remarks on algorithmic composition. Computer Music Journal,
25 (1), 4853.
Thom, B. (2000). BoB: an interactive improvisational music companion. In Proceedings of
the International Conference on Autonomous Agents, pp. 309316, New York.
Thomas, M. T. (1985). Vivace: A rule based AI system for composition. In Proceedings of
the International Computer Music Conference, pp. 267274.
Thomas, M. T., Chatterjee, S., & Maimone, M. W. (1989). Cantabile: A rule-based system
for composing melody. In Proceedings of the International Computer Music Conference.
Thornton, C. (2009). Hierarchical Markov modelling for generative music. In Proceedings
of the International Computer Music Conference.
Thywissen, K. (1999). GeNotator: an environment for exploring the application of evolutionary techniques in computer-assisted composition. Organised Sound, 4 (2), 127133.
Tipei, S. (1975). MP1: a computer program for music composition. In Proceedings of the
Annual Music Computation Conference.
580

fiAI Methods in Algorithmic Composition

Todd, P. M. (1989). A connectionist approach to algorithmic composition. Computer Music
Journal, 13 (4), 2743.
Todd, P. M., & Loy, D. G. (1991). Music and Connectionism. The MIT Press, Cambridge.
Toiviainen, P. (1995). Modeling the target-note technique of bebop-style jazz improvisation:
an artificial neural network approach. Music Perception: An Interdisciplinary Journal,
12 (4), 399413.
Toiviainen, P. (2000). Readings in Music and Artificial Intelligence, chap. Symbolic AI
versus Connectionism in Music Research, pp. 4767. Harwood Academic Publishers.
Tokui, N., & Iba, H. (2000). Music composition with interactive evolutionary computation.
In Proceedings of the Generative Art Conference.
Tominaga, K., & Setomoto, M. (2008). An artificial-chemistry approach to generating
polyphonic musical phrases. In Proceedings of the Conference on Applications of
Evolutionary Computation, pp. 463472.
Towsey, M. W., Brown, A. R., Wright, S. K., & Diederich, J. (2001). Towards melodic
extension using genetic algorithms. Educational Technology & Society, 4 (2), 5465.
Trivio Rodrguez, J. L., & Morales-Bueno, R. (2001). Using multiattribute prediction
suffix graphs to predict and generate music. Computer Music Journal, 25 (3), 6279.
Truchet, C., Assayag, G., & Codognet, P. (2003). OMClouds, a heuristic solver for musical
constraints. In Proceedings of the International Conference on Metaheuristics.
Tsang, C. P., & Aitken, M. (1991). Harmonizing music as a discipline of constraint logic
programming. In Proceedings of the International Computer Music Conference.
Ulrich, J. W. (1977). The analysis and synthesis of jazz by computer. In Proceedings of the
International Joint Conference on Artificial Inteligence, pp. 865872.
Unehara, M., & Onisawa, T. (2001). Composition of music using human evaluation. In
Proceedings of the IEEE International Conference on Fuzzy Systems, pp. 12031206.
Ventrella, J. J. (2008). The Art of Artificial Evolution, chap. Evolving Structure in Liquid
Music, pp. 269288. Springer Berlin / Heidelberg.
Verbeurgt, K., Fayer, M., & Dinolfo, M. (2004). A hybrid Neural-Markov approach for
learning to compose music by example. In Proceedings of the Canadian Conference
on Advances in Artificial Intelligence, pp. 480484.
Visell, Y. (2004). Spontaneous organisation, pattern models, and music. Organised Sound,
9 (02), 151165.
Voss, R. F., & Clarke, J. (1978). 1/f noise in music: Music from 1/f noise. Journal of the
Acoustical Society of America, 63, 258263.
Walker, W. F. (1994). A conversation-based framework for musical improvisation. Ph.D.
thesis, University of Illinois.
Wallin, N. L., & Merker, B. (2001). The Origins of Music. The MIT Press.
Waschka, R. (1999). Avoiding the fitness bottleneck: Using genetic algorithms to compose
orchestral music. In Proceedings of the International Computer Music Conference, pp.
201203.
581

fiFernndez & Vico

Watson, L. A. (2008). Algorithmic composition for flute and accompaniment. Masters
thesis, University of Bath.
Werner, M., & Todd, P. M. (1997). Too many love songs: Sexual selection and the evolution
of communication. In Proceedings of the European Conference on Artificial Life.
Widmer, G. (1992). Qualitative perception modeling and intelligent musical learning. Computer Music Journal, 16 (2), 5168.
Wiggins, G. A. (1998). The use of constraint systems for musical composition. In Proceedings
of the Workshop on Constraints for Artistic Applications.
Wiggins, G. A. (2008). Computer models of musical creativity: A review of computer models
of musical creativity by David Cope. Literary and Linguistic Computing, 23 (1), 109
116.
Wilson, A. J. (2009). A symbolic sonification of L-systems. In Proceedings of the International Computer Music Conference, pp. 203206.
Wolkowicz, J., Heywood, M., & Keselj, V. (2009). Evolving indirectly represented melodies
with corpus-based fitness evaluation. In Proceedings of the Conference on Applications
of Evolutionary Computation, pp. 603608.
Wooller, R., & Brown, A. R. (2005). Investigating morphing algorithms for generative
music. In Proceedings of the International Conference on Generative Systems in the
Electronic Arts.
Worth, P., & Stepney, S. (2005). Growing music: Musical interpretations of L-Systems.
In Proceedings of the Conference on Applications of Evolutionary Computation, pp.
545550.
Yi, L., & Goldsmith, J. (2007). Automatic generation of four-part harmony. In Proceedings
of the Conference on Uncertainty in Artificial Intelligence.
Yilmaz, A. E., & Telatar, Z. (2010). Note-against-note two-voice counterpoint by means of
fuzzy logic. Knowledge-Based Systems, 23 (3), 256266.
Zicarelli, D. (1987). M and Jam factory. Computer Music Journal, 11 (4), 1329.
Zimmermann, D. (2001). Modelling musical structures. Constraints, 6 (1), 5383.

582

fiJournal of Artificial Intelligence Research 48 (2013) 305-346

Submitted 04/13; published 10/13

A Global Model for Concept-to-Text Generation
Ioannis Konstas
Mirella Lapata

IKONSTAS @ INF. ED . AC . UK
MLAP @ INF. ED . AC . UK

Institute for Language, Cognition and Computation,
School of Informatics, University of Edinburgh,
10 Crichton Street, EH8 9AB, Edinburgh UK

Abstract
Concept-to-text generation refers to the task of automatically producing textual output from
non-linguistic input. We present a joint model that captures content selection (what to say) and
surface realization (how to say) in an unsupervised domain-independent fashion. Rather than
breaking up the generation process into a sequence of local decisions, we define a probabilistic context-free grammar that globally describes the inherent structure of the input (a corpus of
database records and text describing some of them). We recast generation as the task of finding
the best derivation tree for a set of database records and describe an algorithm for decoding in this
framework that allows to intersect the grammar with additional information capturing fluency and
syntactic well-formedness constraints. Experimental evaluation on several domains achieves results competitive with state-of-the-art systems that use domain specific constraints, explicit feature
engineering or labeled data.

1. Introduction
Concept-to-text generation broadly refers to the task of automatically producing textual output from
non-linguistic input (Reiter & Dale, 2000). Depending on the application and the domain at hand,
the input may assume various representations including databases of records, expert system knowledge bases, simulations of physical systems and so on. Figure 1 shows input examples and their
corresponding text for three domains: air travel, sportscasting and weather forecast generation.
A typical concept-to-text generation system implements a pipeline architecture consisting of
three core stages, namely content planning (selecting the appropriate content from the input and
determining the structure of the target text), sentence planning (determining the structure and lexical content of individual sentences), and surface realization (rendering the specification chosen by
the sentence planner into a surface string). Traditionally, these components are hand-engineered in
order to generate high quality text, at the expense of portability and scalability. It is thus no surprise that recent years have witnessed a growing interest in automatic methods for creating trainable
generation components. Examples include learning which database records should be present in a
text (Duboue & McKeown, 2002; Barzilay & Lapata, 2005) and how these should be verbalized
(Liang, Jordan, & Klein, 2009). Besides concentrating on isolated components, a few approaches
have emerged that tackle concept-to-text generation end-to-end. Due to the complexity of the task,
most models simplify the generation process, e.g., by creating output that consists of a few sentences, thus obviating the need for content planning, or by treating sentence planning and surface
realization as one component. A common modeling strategy is to break up the generation process
into a sequence of local decisions, each learned separately (Reiter, Sripada, Hunter, & Davy, 2005a;
Belz, 2008; Chen & Mooney, 2008; Angeli, Liang, & Klein, 2010; Kim & Mooney, 2010).
c
2013
AI Access Foundation. All rights reserved.

fiKONSTAS & L APATA

Pass

Bad Pass

Turn Over

Database:

from
to
pink3 pink7

from
to
pink7 purple3

from
to
pink7 purple3

Text:

pink3 passes the ball to pink7
(a) ROBO C UP

Database:

Temperature

Cloud Sky Cover

time
min mean max
06:00-21:00 9 15 21

time
percent (%)
06:00-09:00
25-50
09:00-12:00
50-75

Wind Speed

Wind Direction

time
min mean max
06:00-21:00 15 20 30
Text:

time
mode
06:00-21:00
S

Cloudy, with temperatures between 10 and 20 degrees. South wind around 20 mph.
(b) W EATHER G OV

Database:

Text:

Flight

Day Number

Month

from
to
denver boston

number dep/ar
9
departure

month
dep/ar
august departure

Condition

Search

arg1
arg2 type
arrival time 16:00 <

type what
query flight

Give me the flights leaving Denver August ninth coming back to Boston before 4pm.
(c) ATIS

Figure 1: Input-output examples for (a) sportscasting, (b) weather forecast generation, and (c) query
generation in the air travel domain.

In this paper we focus on the problem of generating text from a database and describe an
end-to-end generation model which performs content selection and surface realization jointly. More
specifically, the input to our model is a set of database records and collocated textual descriptions.
Consider the example in Figure 1b. Here, the records provide a structured representation of the
weather for a specific time interval (e.g., the temperature, the wind speed and direction) and the
text renders some of this information in natural language. We formulate the task of creating text
corresponding to a database through the following generative process: the database consists of a
306

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

set of typed tuples (record, field, value), and our aim is to choose a subset of these to talk about.
This naturally decomposes into selecting a sequence of records, and a sequence of fields within
the record. Finally, for each field we generate a sequence of words according to the value of that
field. Central to our approach is to jointly optimize this process, rather than breaking up the various
decisions into local problems and greedily trying to solve each one of them.
To do this, we define a probabilistic context-free grammar (PCFG) that captures the structure
of the database and how it can be verbalized. Generation then boils down to finding the best string
output as captured by the best derivation tree licensed by our grammar. In order to ensure that
our generation output is coherent, we intersect our grammar with additional information capturing
fluency and syntactic well-formedness constraints. Specifically, we experiment with a n-gram language model and a dependency model based on the work of Klein and Manning (2004). We follow
Chiangs (2007) integration framework and show how it can be extended by intersecting a CFG
grammar with an arbitrary number of models (see Huang, 2008 for a similar proposal). Our work
is closest to that of Liang et al. (2009) who learn how to align database records and text segments
using a hierarchical hidden semi-Markov generative model (see Section 3.1 for details). We recast
their model as a PCFG and develop a decoding algorithm that allows us to go beyond alignments,
i.e., to generate multi-sentence text corresponding to database input.
Our model is conceptually simpler than previous approaches (e.g., Angeli et al., 2010; Kim &
Mooney, 2010); it encodes information about the domain and its structure globally, by considering
the input space simultaneously during generation. We thus need to train a single model (on a given
domain) once without having to separately optimize different content selection and surface realization components. More importantly, recasting generation into parsing allows us to optimize a joint
objective (hence finding the most likely grammar derivation that also yields a grammatical output
text) in a more principled manner, rather than approximating it with a greedy search over local decisions. Our only assumption is that the input must be a set of records essentially corresponding to
database-like tables whose columns describe fields of a certain type. Experimental evaluation on
three domains obtains results competitive to the state-of-the-art without using any domain specific
constraints, explicit feature engineering or labeled data.1
The remainder of this paper is structured as follows. Section 2 provides an overview of related
work. Section 3 presents our generation model; it defines the PCFG used in our experiments and
presents our decoding algorithm Section 4 discusses our experimental set-up and Section 5 presents
our results. Discussion of future work concludes the paper.

2. Related Work
The literature reveals many examples of generation systems that produce high quality text, almost
indistinguishable from human writing (Dale, Geldof, & Prost, 2003; Reiter, Sripada, Hunter, Yu,
& Davy, 2005b; Green, 2006; Turner, Sripada, & Reiter, 2009). Such systems often implement
a pipeline architecture and involve a great deal of manual effort. For instance, a typical content
selection module involves manually engineered rules based on the analysis of a large number of
texts from a domain-relevant corpus, and consultation with domain experts. Analogously, surface
1. A preliminary version of this work was published in the proceedings of NAACL 2012. The current article presents a
more general model, formulates explicitly our decoding algorithm and shows how to intersect a PCFG with an arbitrary number of external knowledge sources. In addition, we present several novel experiments, and a comprehensive
error analysis.

307

fiKONSTAS & L APATA

realization is often based on a grammar written by hand so as to cover the syntactic constructs and
vocabulary of the domain.
One of the earliest systems that exemplifies this approach is FOG (Goldberg, Driedger, & Kittredge, 1994), a weather forecast generator used by Environment Canada, the Canadian weather
service. FOG takes as input numerical simulations from meteorological maps and uses an expert
system to decide on the structure of the document with some optional human intervention via a
graphical interface. For sentence planning and surface realization, the generator uses a grammar
specific to the weather domain, as well as canned syntactic structures written by expert linguists
and encoded in Backus Naur Form (BNF). More recently, Reiter et al. (2005a) have developed
S UM T IME -M OUSAM, a text generator that produces marine weather forecasts for offshore oilrig applications. The content planner of the system is based on linear segmentation of the input
(i.e., time series data) and is informed by a pragmatic (Gricean) analysis of what should be communicated in weather forecasts (Sripada, Reiter, Hunter, & Yu, 2003). Sentence planning relies on rules
that select appropriate time phrases, based on an empirical study of human-written forecasts. Surface realization relies on special grammar rules that emulate the weather sub-language of interest,
again based on corpus analysis.
While existing generation systems can be engineered to obtain good performance on particular
domains, it is often difficult to adapt them across different domains. An alternative is to adopt a
data-driven approach and try to automatically learn the individual generation components or even
an end-to-end system. An example of this class of methods is described in the work of Barzilay
and Lapata (2005) who view content selection as an instance of collective classification. Given a
corpus of database records and texts describing some of them, they first use a simple anchor-based
alignment technique to obtain records-to-text alignments. Then, they use the alignments as training
data (records present in the text are positive labels, and all other records negative) and learn a content
selection model that simultaneously optimizes local label assignments and their pairwise relations.
Building on this work, Liang et al. (2009) present a hierarchical hidden semi-Markov generative
model that first determines which facts to discuss and then generates words from the predicates and
arguments of the chosen facts. Their model is decomposed into three tiers of HMMs that correspond
to chains of records, fields and words. They use Expectation Maximization (EM) for training and
dynamic programming for inference (see Section 3.1 for a more thorough description).
A few approaches have emerged more recently that combine content selection and surface realization. Kim and Mooney (2010) present a generator with a two-stage pipeline architecture: using
a generative model similar to the model in the work of Liang et al. (2009), they first decide what
to say and then verbalize the selected input with WASP1 , an existing generation system (Wong &
Mooney, 2007). In contrast, Angeli et al. (2010) propose a unified content selection and surface
realization model which also operates over the alignment output produced by the model of Liang
et al.. Their model decomposes into a sequence of discriminative local decisions. They first determine which records in the database to talk about, then which fields of those records to mention, and
finally which words to use to describe the chosen fields. Each of these decisions is implemented
as a log-linear model with features learned from training data. Their surface realization component
performs decisions based on automatically extracted templates that are filtered with domain-specific
constraints in order to guarantee fluent output.
Other related work has focused on mapping meaning representations (e.g., some logical form
or numeric weather data) to natural language, using explicitly aligned sentence/meaning pairs as
training data. For example, Wong and Mooney (2007) learn this mapping using a synchronous
308

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

context-free grammar (SCFG). They also integrate a language model with their SCFG and decode
the meaning representation input to text, using a left-to-right Early chart generator. Belz (2008)
creates a CFG by hand (using a set of template-based domain-specific rules) but estimates probabilities for rule application automatically from a development corpus. Ratnaparkhi (2002) uses a
dependency-style grammar of phrase fragments in the context of a dialogue system, incorporating
among others long-range dependencies. More recently, Lu and Ng (2011) propose in their work a
model that performs joint surface realization and lexical acquisition from input that is represented
in typed lambda calculus. They present a novel SCFG forest-to-string generation algorithm, that
captures the correspondence between natural language and logical form represented by hybrid
trees.
Similar to the work of Angeli et al. (2010), we also present an end-to-end system that performs
content selection and surface realization. However, rather than breaking up the generation task into
a sequence of local decisions, we optimize what to say and how to say simultaneously. We do not
learn mappings from a logical form, but rather focus on input which is less structured and possibly
more noisy. Our key insight is to convert the set of database records serving as input to our generator
into a PCFG that is neither hand crafted nor domain specific but simply describes the structure of
the input. During training, we estimate the weights of the grammar rules using the EM algorithm
and a dynamic program similar to the inside-outside algorithm (Li & Eisner, 2009). During testing
we are given only a set of database and search for the best derivation tree licensed by the grammar.
While searching, we intersect our grammar with external linguistically motivated models and create
k-best lists of derivations, thus optimizing what to say and how to say at the same time.

3. Problem Formulation
We assume our generator takes as input a set of database record tuples (r, f , v)  d and outputs a
text g that verbalizes some of these records. Each record token ri , with 1  i  |d|, has a type ri .t,
which can be thought of as the name of the table in a relational database schema. Note that the
total number of records |d| can vary between examples. Figure 1b illustrates instances of record
types such as Temperature, Wind Speed, and Wind Direction. Each record token also has a set of
fields ri .f associated with it. For example, a record of type Wind Direction has two fields, namely
windDir1 .time and windDir1 .mode. We will henceforth abbreviate fields to their names (e.g., time
and mode) when the record type is apparent from the context. Fields have different values fk .v; in
Figure 1b the value of the field mode is S. Fields also have an associated type fk .t, which defines the
range of possible values they can take; our model supports integer and categorical value types. For
example, the top right table in Figure 1b named Cloud Sky Cover (sc for short), corresponds to four
database record tuples: (sc1 , time, 06:00-09:00), (sc1 , percent, 25-50), (sc2 , time, 09:00-12:00)
and (sc2 , percent, 50-75). Both time and percent are of categorical type.
The training corpus consists of several scenarios, i.e., database records d paired with texts w2
like those shown in Figure 1. In the weather forecast domain, a scenario corresponds to weatherrelated measurements of temperature, wind, speed, and so on collected for a specific day and time
(e.g., day or night). In sportscasting, scenarios describe individual events in the soccer game
(e.g., passing or kicking the ball). In the air travel domain, scenarios comprise of flight-related
details (e.g., origin, destination, day, time).
2. We use w to denote the gold-standard text and g to refer to the string of words our system generates.

309

fiKONSTAS & L APATA

d

...

r1

...

r1 . f 1

w1

...

w

...

ri . f 1

w

...

ri

...

w

...

ri . f|f|

w

...

r|r|

w

r|r| . f|f|

w

...

wN

Figure 2: Graphical model representation of the generative alignment model of Liang et al. (2009).
Shaded nodes represent observed variables (i.e., the database d and the collocated text w), unshaded
nodes indicate latent variables. Arrows indicate conditional dependencies between variables. Starting from the database d, the model emits a sequence of records; then for each record it emits a
sequence of fields, specific to the type of the particular record. Finally, for each record it uniformly
selects a number c and emits words w1 . . . wc .

Our goal is to first define a model that naturally captures the (hidden) relations between the
database records d and the observed text w. Once trained, we can use this model to generate text g
corresponding to new records d. Our model is an extension of the hierarchical hidden semi-Markov
model of Liang et al. (2009) which we describe in detail in the next section. Our key idea is to recast
this model as a probabilistic context-free grammar, therefore reducing the tasks of content selection
and surface realization into a common parsing problem.3 Arguably, we could have implemented this
model using a finite-state representation. However, the conceptualization of generation as parsing,
allows us to use the well-known CYK algorithm (Kasami, 1965; Younger, 1967) in order to find
the best g licensed by the grammar. It also affords a wider range of extensions that go beyond the
expressivity of the cascade of HMMs in the model of Liang et al. We furthermore ensure that the
resulting text is fluent by intersecting our grammar with externally trained surface level models,
namely a n-gram language model and a dependency model. Thus, our model will generate the parse
and more importantly text deemed most likely by both the grammar and the surface models. In the
following, we first describe the approach of Liang et al. and then move on to describe our grammar
and decoding algorithm, i.e., our procedure for finding the best g for a given input d.
310

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

3.1 A Model of Inducing Alignments
Liang et al. (2009) present a generative semi-hidden Markov model that learns the correspondence
between a world state and an unsegmented string of text without, however, generating an output
string of words g describing the world state. As in our case, the world state is represented by a set
of database records, with their associated fields and values. Their model is defined by a generative
process that can be summarized in three steps:
1. Record choice. Choose a sequence of records r to describe. Consecutive records are selected
on the basis of their types.
2. Field choice. For each record ri emit a sequence of fields ri .f.
3. Word choice. For each chosen field ri . fk generate a number of words c, where c > 0 is chosen
uniformly.
This process is implemented as a hierarchy of Markov chains which correspond to records, fields,
and values of the input database. As captured by a Markov chain of records conditioned on record
types; given a record type, then a record is chosen uniformly from the set of records with this type.
In this way, their model essentially captures rudimentary notions of local coherence and salience,
respectively. More formally:
|r|

p(r | d) =  p(ri .t | ri1 .t)
i

1
|s(ri .t)|

(1)

where s(t) is defined as a function that returns the set of records with type t: s = {r  d : r.t = t}, and
r0 .t is the START record type. Liang et al. (2009) also include a special null record type, which
accounts for words that do not particularly align with any record present in the database. Field
choice is modeled analogously as a Markov chain of fields for a given record choice ri of type t:
|ri .f|

p(f | ri .t) =  p(ri . fk | ri . fk1 )

(2)

k

They also implement special start and stop fields to model transitions at the boundaries of the
corresponding phrase. Finally, for a chosen record ri , a field fk and a uniformly chosen number c,
with 0 < c < N, they emit words independently given the field value and type. Note that since
their model always observes the words, this simplistic representation at the surface level is adequate
(however, relaxing the independence assumption, e.g., by additionally conditioning on the previous
word(s), could potentially yield a more powerful model):
|w|

p(w |ri , ri . fk , ri . fk .t) =  p(w j | ri .t, ri . fk .v)

(3)

j

Their model supports three different types of fields, namely string, categorical and integer. For each
of those they adopt a specific generation strategy at the word level. For string-typed fields, they
3. An alternative would be to learn a SFCG between the database input and the accompanying text. However, this would
involve considerable overhead in terms of alignment (as the database and the text do not together constitute a clean
parallel corpus, but rather a noisy comparable corpus), as well as grammar training and decoding using state-of-the
art statistical machine translation (SMT) methods, which we manage to avoid with our simpler approach.

311

fiKONSTAS & L APATA

Events:
Fields:
Text:

skyCover1
percent=0-25
cloudy ,

k
N
withg

temperature1
time=6am-9pm
temperatures between

min=9
10gand

max=21
20 degrees .

kwindDir1
mode=S
N
southg
windg

kwindSpeed1
N
mean=20
aroundg
20 mph .

Figure 3: Example of alignment output for the model of Liang et al. (2009) on the weather domain.
Subscripts refer to record tokens (e.g., skyCover1 is the first record with type Cloud Sky Cover).
emit a single word from the (possibly) multi-word value, chosen uniformly. For categorical fields,
they maintain a separate multinomial distribution of words for each field value. Finally, for integer
fields, they wish to capture the intuition that a numeric quantity in the database can be rendered in
the text as a word which is possibly some other numerical value due to stylistic factors. So they
allow several ways generating a word given a field value. These include generating the exact value,
rounding up or rounding down to a multiple of 5, rounding off to the closest multiple of 5, and
adding or subtracting some unexplained noise + or  , respectively. Each noise is modeled as a
geometric distribution, the parameters of which are trained given the value ri . fk .v.
An example of the models output for the weather domain is shown in Figure 3. The top
row contains the database records selected by the model (subscripts correspond to record tokens;
e.g., temperature1 refers to the first record of type temperature in Figure 1b). The second row contains the selected fields for each record with their associated values. The special field null aligns
with words that do not directly refer to the values of the database records, such as with, wind and
around. Finally, the last row shows the segmentation and alignment of the original text w produced
by the model.
As it stands, Liang et al.s (2009) model generates an alignment between sequences of words and
facts in a database, falling short of creating a meaningful sentence or document. Kim and Mooney
(2010) address this problem by interfacing the alignments with WASP1 (Wong & Mooney, 2007).
The latter is a publicly available generation system which takes an alignment as input and finds the
most likely string using the widely popular noisy-channel model. Angeli et al. (2010) propose a
model different in spirit which nevertheless also operates over the alignments of Liang et al. Using
a template extraction method, they post-process the alignments in order to obtain a sequence of
records, fields, and words which are spanned by the chosen records and fields. The generation
process is then modeled as a series of local decisions, arranged hierarchically and each trained
discriminatively. For each record they choose to talk about, they then choose a subset of fields, and
finally a suitable template to render the chosen content. The same process repeats until it decides to
generate a special STOP record.
We do not treat the model of Liang et al. (2009) as a black box in order to obtain alignments.
Rather, we demonstrate how generation can be seamlessly integrated in their semi-hidden Markov
model by re-interpreting it as CFG rewrite rules and providing an appropriate decoding algorithm.
Our model simultaneously learns which records and fields to talk about, which textual units they
correspond to, and how to creatively rearrange them into a coherent document.
3.2 Grammar Definition
As mentioned earlier, we recast the model of Liang et al. (2009) as a series of CFG rewrite rules,
corresponding to the first two layers of the HMMs in Figure 2. We also include a set of grammar
rules that emit chains of words, rather than words in isolation. This can be viewed as an additional
312

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

1. S  R(start)

GCS

GSURF

2. R(ri .t)  FS(r j , start) R(r j .t)

[Pr = 1]
i
h
P(r j .t | ri .t)  |s(r1i .t)|

3. R(ri .t)  FS(r j , start)

h
i
P(r j .t | ri .t)  |s(r1i .t)|

4. FS(r, r. fi )  F(r, r. f j ) FS(r, r. f j )

[P( f j | fi )]

5. FS(r, r. fi )  F(r, r. f j )

[P( f j | fi )]

6. F(r, r. f )  W(r, r. f ) F(r, r. f )

[P(w | w1 , r, r. f )]

7. F(r, r. f )  W(r, r. f )

[P(w | w1 , r, r. f )]

8. W(r, r. f )  

[P( | r, r. f , f .t, f .v, f .t = {cat, null})]

9. W(r, r. f )  gen( f .v)

[P(gen( f .v).mode | r, r. f , f .t = int)
P( f .v | gen( f .v).mode)]

Table 1: Grammar rules for GGEN and their weights shown in square brackets.

HMM over words for each field in the original model. The modification is important for generation; since we only observe the set of database records d, we need a better informed model during
decoding that captures word-to-word dependencies more directly. We should also point out that our
PCFG does not extend the underlying expressivity of the model presented in Liang et al., namely it
also describes a regular language.
Our grammar GGEN is defined in Table 1 (rules (1)(9)) and contains two types of rules. GCS
rules perform content selection, whereas GSURF rules perform surface realization. Both types of
rules are purely syntactic (describing the intuitive relationship between records, records and fields,
fields and corresponding words), and could apply to any database with similar structure irrespectively of the semantics of the domain. Rule weights are governed by an underlying multinomial
distribution and are shown in square brackets. Non-terminal symbols are in capitals and denote intermediate states; the terminal symbol  corresponds to all words seen in the training set, and gen( f .v)
is a function for generating integer numbers given the value of a field f . All non-terminals, save
the start symbol S, have one or more features (shown in parentheses) which act as constraints, similar to number and gender agreement constraints in augmented syntactic rules. Figure 4 shows two
derivation trees licensed by our grammar for the sentence Cloudy, with temperatures between 10
and 20 degrees. (see the example in Figure 1b).
The first rule in the grammar denotes the expansion from the start symbol S to record R, which
has the special start record type (hence the notation R(start)). Rule (2) defines a chain between
two consecutive records, i.e., going from record ri to r j . Here, FS(r j , start) represents the set
of fields of record r j following record R(ri ). For example, in Figure 4a, the top branching rule
R(start)  FS(sc2 , start)R(sc2 .t) (sc stands for Cloud Sky Cover) can be interpreted as follows.
Given we are at the beginning of the document, hence the record R(start), we will talk about the
313

fiKONSTAS & L APATA

S
R(start)
R(sc2 .t)

FS(sc2 ,start)
F(sc2 ,%)

FS(sc2 ,%)

W(sc2 ,%)

F(sc2 ,null)

R(t1 .t)

FS(t1 ,start)
FS(t1 ,min)

F(t1 ,min)

W(sc2 ,null) W(t1 ,min)

F(t1 ,min)

W(t1 ,min)

FS(t1 ,max)

F(t1 ,max)

F(t1 ,min)

W(t1 ,min)

W(t1 ,max)

F(t1 ,null)

F(t1 ,max)

W(t1 ,max) W(t1 ,null)

F(t1 ,min)

W(t1 ,null)

W(t1 ,min)

Cloudy

,

10

between

temperatures

with

F(t1 ,null)

and

.

degrees

20

...

(a)
S
R(start)
R(sc2 .t)

FS(sc2 ,start)
F(sc2 ,%)

FS(sc2 ,%)

W(sc2 ,%)

F(sc2 ,null)

R(t1 .t)

FS(t1 ,start)
FS(t1 ,null)

F(t1 ,null)

W(sc2 ,null) W(t1 ,null)

F(t1 ,null)
W(t1 ,null)

FS(t1 ,min)

F(t1 ,min)
W(t1 ,min)

F(t1 ,max)

F(t1 ,min)

F(t1 ,max)

W(t1 ,min) W(t1 ,max)

W(t1 ,max)

F(t1 ,max)
W(t1 ,max)

F(t1 ,max)
W(t1 ,max)

Cloudy

,

with

temperatures

10

between

and

20

degrees

.

...

(b)

Figure 4: Two derivation trees using the grammar in Table 1 for the sentence Cloudy, with temperatures between 10 and 20 degrees.. We use sc as a shorthand for the record type Cloud Sky
Cover, and t for Temperature. Subscripts refer to record tokens (e.g., sc2 is the second Cloud Sky
Cover record, t1 is the first Temperature record, and so on).

314

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

part of the forecast that refers to Cloud Sky Cover, i.e., emit the set of fields spanned by the
non-terminal FS(sc2 , start). The field start in FS acts as a special boundary between consecutive
records. Note that in the input database of example 1b, there are two records of type Cloud Sky
Cover (see the second box in the example). Given that the value of the percent (%) field of the
second record is 50-75, it is more likely to lexicalize to the phrase Cloudy ,. In a different
scenario, if the equivalent phrase was Mostly sunny , the first record with value 25-50 would
have been more appropriate. Rule R(sc2 .t)  FS(t1 , start)R(t1 .t) (t stands for Temperature) is
interpreted similarly: once we talk about the sky coverage of the forecast we will move on to
describe the temperature outlook, via the field set spanned by the non-terminal FS(t1 , start) (see
the second sub-tree in Figure 4a). The weight of this rule is the bigram probability of two records
conditioned on their record type, multiplied with the normalization factor |s(r1i .t)| , where s(t) is a
function that returns the set of records with type t (Liang et al., 2009). We have also defined a null
record type i.e., a record that has no fields and acts as a smoother for words that may not correspond
to a particular record. Rule (3) is simply an escape rule, so that the parsing process (on the record
level) can finish.
Rule (4) is the equivalent of rule (2) at the field level, i.e., it describes the chaining of two
consecutive fields fi and f j . Non-terminal F(r, r. f ) refers to field f of record r. For example, in the
tree of Figure 4a, the rule FS(t1 , min)  F(t1 , max) FS(t1 , max) specifies that we should talk about
the field max of record t1 (i.e., temperature record), after talking about the field min. Analogously
to the record level, we have also included a special null field type for the emission of words that do
not correspond to a specific record field (e.g., see the emission of the two last tokens degrees . in
the end of the phrase in the derivation tree. Rule (6) defines the expansion of field F to a sequence
of (binarized) words W, with a weight equal to the bigram probability of the current word given
the previous word, the current record, and field. See the consecutive application of this rule on the
derivation tree in the emission of the phrase with temperatures between 10 .
Rules (8) and (9) are responsible for surface generation; they define the emission of words and
integers from W , given a field type and its value, and can thus be regarded as the lexical rules
of our grammar (see the pre-terminal expansions at the derivation tree of Figure 4a for examples).
Rule (8) emits a single word from the vocabulary of the training set. Its weight defines a multinomial
distribution over all seen words, for every value of field f , given that the field type is categorical
(denoted as cat in the grammar) or the special null field. Rule (9) is identical but for fields whose
type is integer. Function gen( f .v) generates an integer number given the field value, using either
of the following six ways (Liang et al., 2009): identical to the field value, rounding up or rounding
down to a multiple of 5, rounding off to the closest multiple of 5 and finally adding or subtracting
some unexplained noise + or  respectively. Each noise is modeled as a geometric distribution,
the parameters of which are trained given the value f .v. The weight is a multinomial over the six
integer generation function choices, given the record field f , times P( f .v | gen( f .v).mode), which is
set to the geometric distribution of noise + and  , or to 1 otherwise.
Naturally, our grammar can yield several derivation trees for a given input string. Notice the
difference between Figure 4a and Figure 4b in emitting the phrases with temperatures between 10 
and and 20 degrees .. In Figure 4a, the field min (whose record is Temperature) spans the entire
phrase, whereas in Figure 4b the phrase is split in two parts. The null field emits with temperatures
and the min field emits between 10 . Analogously, in the derivation tree in Figure 4a, the field max
emits the first three words, and 20 degrees, then the null emits the full-stop on its own null field
315

fiKONSTAS & L APATA

of the same record (very common situation in case of punctuation marks). In the derivation tree of
Figure 4b, however, the whole phrase is spanned by the field max.
3.3 Generation
So far we have defined a probabilistic grammar which captures the structure of a database d with
records and fields as intermediate non-terminals, and words w (from the associated text) as terminals. The mapping between d and w is unknown and thus the intermediate multinomials (see the rule
weights of GGEN in Table 1) define a distribution over hidden correspondences h between records,
fields and their values. Given an input scenario from a database d we can generate its corresponding
text using the grammar in Table 1.
On a high-level our generation procedure can be described as follows. We first select the length
N of the output text (we defer discussion on how we achieve this to Section 4.3). Then, we apply
our grammar to the empty document by building derivation trees in a bottom-up fashion, starting
from the lexical rules r  GSURF . For each word position in the document we emit a k-best list of
candidate words drawn from the corresponding distributions, given the values of the fields of the
records in d; then, we apply the rest of the rules r  GCS , keeping a list of k-best partial derivations
and partially generated text in each node4 , until we reach the root symbol S spanning the whole
document. Finally, we reconstruct the top-scoring generated string at the root of the tree, by following the pointers of the best derivation, down to the lexical rules that emit the words of the final
document. In order to guarantee the grammaticality of the final output text, we rescore the k-best
lists at each node by applying external linguistic knowledge, such as n-gram language models and
head dependency-style models, on the partially generated substrings.
In analogy to parsing, this procedure amounts to finding the most likely derivation, i.e., sequence
of rewrite rules for a given input. Note, that there is a subtle difference between syntactic parsing
and generation. In the former case, we observe a string of words and our goal is to find the most
probable syntactic structure, i.e., hidden correspondence h. In generation, however, as described
above, the string is not observed; instead, we must thus find the best text g, by maximizing both
over h and g (the latter is achieved with the use of external linguistic knowledge via rescoring),
where g = g1 . . . gN is a sequence of words licensed by GCS and GSURF . More formally:


g = f arg max P (g, h)
(4)
g,h

where f is a function that takes as input a derivation tree (g, h) and returns g. We use a modified
version of the CYK parser (Kasami, 1965; Younger, 1967) to find g. Optimizing over both h and g
is intractable, so we approximate f by pruning the search space as we explain in Section 3.5.
In the following, we we will use the framework of deductive proof systems (Shieber, Schabes,
& Pereira, 1995) in order to describe our decoder. We first present a basic adaptation of the CYK
algorithm to our task and give a concrete decoding procedure that generates text, using a chart data
structure (Section 3.4). We then extend the basic decoder into a k-best decoder, by integrating external linguistic knowledge in an attempt to improve the quality of the output. The basic decoder
naively only optimizes function f over h, whereas the extended version maximizes both h and g,
approximately. Note that the framework of deductive proof systems is used here for convenience. It
4. We use an efficient method that compresses the stored substrings considerably, following the work of Chiang (2007);
see equation (12) in Section 3.6.

316

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

Items:

[A, i, j]
R(A  B)
R(A  BC)

Axioms:

[W, i, i + 1] : s

W  gi+1 , gi+1  {, gen()}

Inference rules:
(1)
(2)
Goal:

R(A  B) : s [B, i, j] : s1
[A, i, j] : s  s1
R(A  B C) : s [B, i, k] : s1 [C, k, j] : s2
[A, i, j] : s  s1  s2

[S, 0, N]

Figure 5: The basic decoder deductive system. Productions A  B and A  B C can be any of the
GCS rules in Figure 1; features on grammar non-terminals are omitted for the sake of clarity.
provides a level of abstract generalization for a number of algorithms. Examples include the recogntion of a sentence according to a grammar, learning inside and outside weights, Viterbi search, and
in our case generating text (see Goodman, 1999 for more details).
3.4 Basic Decoder
Analogously to a parser, our decoder can be generally defined as a set of weighted items (some of
which are designated axioms and others are goals, i.e., items to be proven) and a set of inference
rules of the form:
I1 : s1 . . . Ik : sk

I:s
which can be interpreted as follows: if all items Ii (i.e., the antecedents) have been first proven with
weight (or score) si , then item I (i.e., the consequent) is provable, with weight s provided the side
condition  holds. The decoding process begins with the set of axioms, and progressively applies
the inference rules, in order to prove more items until it reaches one of the designated goals.
Our basic decoder is specified in Figure 5 and consists of four components, a class of items, a
set of axioms, a set of inference rules and a subclass of items, namely the goal items. Following the
work of Goodman (1999), items in our system take two forms: [A, i, j] indicates a generated span
from i to j, rooted at non-terminal A; R(A  B) or R(A  B C) corresponds to any of the content
selection production rules of GCS with one or two non-terminals on the right hand side. Axioms
correspond to each individual word generated by the surface realization grammar rules GSURF (see
(8) and (9) in Table 1). Our inference rules follow two forms, one for grammar production rules
with one non-terminal on the right hand side, and another one for rules with two non-terminals. For
example, inference rule (1) in Figure 5 combines two items, namely a rule of the form A  B with
weight s and a generated span [B, i, j] with weight s1 rooted at B, and results to a new generated
span [A, i, j] with weight s  s1 , rooted at A. Finally, our system has one goal, [S, 0, N], where S is the
root node of the grammar and N the (predicted) length of the generated text. The time complexity is
317

fiKONSTAS & L APATA

O(n3 ), as in the case of CYK algorithm. We could have converted our grammar rules in Chomsky
normal form (CNF) and implemented the original CYK algorithm. Note that our grammar is not
in CNF, since it contains unary productions of the type A  B, i.e., with non-terminal symbols on
the right-hand side as well. We chose to directly implement inference rules (1) and (2) instead (see
Figure 5), since we know that the arity of our grammar is at most 2 and were thus able to avoid a
blow-up in the number of derived rules.
Now that we have defined the parsing strategy, we need a way to find the most likely derivation;
the pseudocode of Figure 6 gives the generation algorithm for the basic decoder. It uses an array
chart[A, i, j], the cells of which get filled with sets of weights of items. It also uses an identical array
bp[A, i, j] that stores back-pointers to the antecedents of each item rooted at A, as well as the actual
generated words when processing the lexical rules r  GSURF (abusing somewhat the traditional
interpretation of a back-pointer array, as a storage of pointers to antecedent chart items). The size
of the chart and the back-pointer array are set to the pre-defined number of N words we want to
generate (Section 4.3). The procedure begins by first filling in the diagonal cells of the chart
with unary spans rooted at W , with the weights of the lexical rules r  GSURF . Equivalently, the
back-pointers array takes the corresponding generated word. Note that in a conventionial parsing
procedure, we always assume that the diagonal cells of the chart are already filled in with the
actual words of the underlying sentence. In our case, we only assume a fixed-size chart with an
empty diagonal, which gets filled in with the top scoring words emitted by the lexical rules of
our grammar. Next, items are visited and combined in order, i.e., smaller spans come before larger
spans. Given the way our grammar is constructed, items rooted in F (corresponding to fields) will
come before items rooted in R (records) and ultimately before S. At any particular point in the chart,
the algorithm considers all the antecedent items that can be proven given the rules of GCS and stores
the highest scoring combination. Finally, we can construct the resulting string g by recursively
visiting bp[S, 0, N]. We trace the back-pointers of each item to its antecedents down to the words gi
emitted by the axioms.
3.5 k-best Decoding
The basic decoder described so far will produce the best derivation tree of the input d given the
grammar GGEN which unfortunately may not correspond to the best generated text. In fact, the
output will often be poor as the model has no notion of what constitutes fluent language. The grammar encodes little knowledge with regard to syntactic well-formedness and grammatical coherence.
Essentially, surface realization boils down to the word bigram rules (6) and (7) and the lexical rules
in GSURF . The word bigram rules inject some knowledge about word combinations into the model,
but this kind of information is usually sparse and cannot capture longer range dependencies.
The generation process in Figure 6 picks the top scoring words emitted by the lexical production
rules (lines 35), in order to produce the best derivation at the root node S. Instead, it would be
preferable if we added to the chart a list of the top k words (as well as a list of the top k items [B, i, j],
[C, j, k] for each production rule r  GCS ), and thus produced a k-best list of derivations (with their
associated strings) at the root node. This can be done efficiently using the lazy algorithm found
in the work of Huang and Chiang (2005). Then, once the generation process is finished, we can
use a language model such as higher order n-grams, or head dependency-style rules to rescore the
k-best lists of generated strings directly (see also Charniak & Johnson, 2005 and Liang, BouchardCote, Klein, & Taskar, 2006 for application of a similar idea to parsing and machine translation,
318

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:

function D ECODE(GGEN ,d,N)
for i  0 . . . N do
for all r : W  gi+1  GSURF do
chart[W, i, i + 1]  [W, i, i + 1] : s
bp[W, i, i + 1]  gi+1
. store actual word gi+1
end for
end for
for l  2 . . . N do
for all i, k, j so that j  i = l and i < k < j do
for all items [B, i, j] or [B, i, k], [C, k, j] inferable from chart and rules r  GCS do
if r is of the form A  B then
chart[A, i, j]  max ([B, i, j] : s1  P(r))
bp[A, i, j]  argmax ([B, i, j] : s1  P(r))
end if
if r is of the form A  B C then
chart[A, i, j]  max (chart[B, i, k]  chart[C, k, j]  P(r))
bp[A, i, j]  argmax ([B, i, k] : s1  [C, k, j] : s2  P(r))
end if
end for
end for
end for
return chart[S, 0, N], bp[S, 0, N]
end function
Figure 6: Generation procedure for the basic decoder.

respectively). Although this method is fast, i.e., linear in k, we would practically have to set k very
high and search among exponentially many possible generations for a given input.
A better solution, which is common practice in machine translation, is to rescore the derivation
trees online. Chiang (2007) intersects a PCFG grammar with a weighted finite state automaton
(FSA), which represents a n-gram language model; the states of the FSA correspond to n  1 terminal symbols. The resulting grammar is also a PCFG that incorporates the FSA. Similarly, we can
intersect our grammar with an ensemble of external probabilistic models, provided that they express
a regular language. The most probable generation g is then calculated as:


g = f arg max p(g)  p( g, h | d)
(5)
g,h

where p(g, h | d) is the decoding likelihood for a sequence of words g = g1 . . . gN of length N and
the hidden correspondence h that emits it, i.e., the likelihood of our grammar for a given database
input scenario d. p(g) is a measure of the quality of each output and could for instance be provided
by a language model (see Section 4.2 for details on how we estimate p(g, h | d) and p(g)). In theory,
the function f above should optimize h and g jointly, thus admitting no search errors. In practice,
however, the resulting grammar after the intersection is prohibitively large, and calls for pruning of
the search space. In the following we show how to extend the basic generation decoder in Figure 5
by intersecting it (linearly) with an ensemble of external probabilistic models.
319

fiKONSTAS & L APATA

S
PP

ADVP
RB

NP

IN

PP

NP

NP

IN

NNS

NNS

QP
CD CC CD
Cloudy with temperatures between

10

and

20

CD
10

CC
and

degrees

(a)
ROOT

RB
Cloudy

IN
with

NNS
temperatures

IN
between

CD
20

NNS
degrees

(b)

Figure 7: Phrase structure tree and dependency graph for the same sentence.

In addition to n-gram language models which are routinely used as a means of ensuring lexical fluency and some rudimentary grammaticality, we also inject syntactic knowledge into our
generator. We represent syntactic information in the form of directed dependencies which could
potentially capture long range relationships beyond the horizon of a language model. Figure 7
shows a dependency-style representation for the sentence Cloudy with temperatures between 10
and 20 degrees and its corresponding phrase structure. The dependency graph in Figure 7b captures
grammatical relations between words via directed edges from syntactic heads to their dependents
(e.g., from a verb to its subject or from a noun to a modifying adjective). Edges can be labeled to
indicate the type of head-dependent relationship (e.g., subject or object) or unlabeled as shown in
the figure. Formally, a dependency structure D is a set of dependency pairs hwh , wa i of a head wh
and an argument word wa , respectively. In general, the argument is the modifier, object or complement; the head most of the times determines the behavior of the pair. In Figure 7b, cloudy is the
head of with, with is the head of temperature, and so on. D(wh ) returns a set of dependency pairs
whose head is wh , e.g., D(10) = {and, 20}.
Previous work (Ratnaparkhi, 2002) has incorporated dependency information into surface realization more directly by generating a syntactic dependency tree rather than a word sequence. The
underlying probabilistic model predicts each word by conditioning on syntactically related words
320

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

(i.e., parent, grandparent, and siblings). Importantly, this approach requires a corpus that has been
annotated with dependency tree structures. We obviate the need for manual annotation by considering dependency structures that have been induced automatically in an unsupervised fashion. For
this, we use the Dependency Model with Valence (DMV; Klein & Manning, 2004), however, there
is nothing inherent in our formulation that restricts us to this model. Any other unsupervised model
that learns dependency structures in a broadly similar fashion (e.g., captures the attachment likelihood of an argument to its head) could have been used instead with the proviso that it operates on
structures that are isomorphic to the derivation trees generated by our grammar. This is necessary
if the intersecting dependency model expresses (up to) a context-free language, since we formulate
our model also as a CFG5 .
Finally, note that although we work with two external information sources (i.e., language models
and dependencies), the framework we propose applies to an arbitrary number of models expressing
a regular language. For instance, we could incorporate models that capture dependencies relating to
content selection such as field n-grams, however we leave this to future work.
3.6 Extended Decoder
We begin by introducing some notation. We define two functions p and q which operate over M
surface-level models and strings a = a1 . . . al , of length l, with ai  V  {?}. V is the vocabulary
of the observed text w (obtained from the training corpus), and the ? symbol represents the elided
part of a string. Recall that our k-best decoder needs to keep a list of generated sub-strings a at
each node, for rescoring purposes. Note that these sub-strings are (potentially) different from the
observed text w; the top-scoring string on the root node essentially collapses to the final generated
text g. Storing lists of whole sub-strings generated so far at each node, would require considerable
amounts of memory. To avoid this we define a function q(a) that stores the essential minimum
string information needed for each of the surface-level models (the ? symbol stands for the omitted
parts of a string) at each step, in order to correctly compute the rescoring weight. Function p(a)
essentially calculates the rescoring weight for a given string, by linearly interpolating the scores of
each individual model mi with a weight i . Therefore applying p(a) in a bottom-up fashion (see the
extended decoder of Figure 8) on the output of q(a) allows us to correctly compute the rescoring
weight of each model for the whole document incrementally. More formally:
M

M

p(a) =  i pmi (a)
i

s.t.

 i = 1

(6)

i

In our setting, we make use of a language model (pm1 ) and a dependency model (pm2 ):
pm1 (a1 . . . al ) =

PLM (ai |ain+1 . . . ai1 )



(7)

nil
?{a
/ in+1 ,...,ai }


pm2 (a1 . . . al ) = PDEP D(ah ) , where ah  {a1 , . . . , al }

(8)

The function pm1 computes the LM probabilities for all complete n-grams in a string; PLM returns
the probability of observing a word given the previous n1 words. pm2 returns the probability of the
5. Intersecting two CFGs is undecidable, or PSPACE-complete if one CFG is finite (Nederhof & Satta, 2004).

321

fiKONSTAS & L APATA

a1 . . . al
mostly cloudy ,
with a
mostly cloudy ? cloudy , with a

pm1 (a1 . . . al )
PLM (,|mostly cloudy)
1
PLM (with|cloudy ,)  PLM (a|, with)

qm1 (a1 . . . al )
mostly cloudy ? cloudy ,
with a
mostly cloudy ? with a

Table 2: Example values for functions pm1 and qm1 for the phrase mostly cloudy, with a. We
assume a 3-gram language model.
dependency model on the dependency structure D headed by word ah . For a dependency structure D,
each word ah has dependants depsD (ah , le f t) that attach on its left and dependents depsD (ah , right)
that attach on its right. Equation (9) recursively defines the probability of the dependency D(ah )
rooted at ah (Klein & Manning, 2004):


PDEP D(ah ) =

 PSTOP (STOP|ah , dir, ad j)
dir[le f t,right] depsD (ah ,dir)

(9)


PCHOOSE (aa |ah , dir)PDEP D(aa )
PSTOP (STOP|ah , dir, ad j)

PSTOP is a binary multinomial indicating whether to stop attaching arguments to a head word ah
given their direction, i.e., left or right, and their adjacency, i.e., whether they are directly adjacent
to ah or not. PCHOOSE is a multinomial over all possible argument words given ah and the direction
of attachment. We next define function q(a) which returns a set of M strings, one for each model mi
(we will use it shortly to expand the lexical items [A, i, j] of the basic decoder in Figure 5).

q(a) = hqm1 (a), . . . , qmM (a)i

(10)
(11)

(
a1 . . . an1 ? aln+2 . . . al
qm1 (a1 . . . al ) =
a1 . . . al

if l  n
otherwise

(12)
(13)



al
if l = 1



q (a . . . a )
if pm2 (a1 . . . ak ) 
m2 1
k
qm2 (a1 . . . ak ak+1 . . . al ) =

pm2 (ak+1 . . . al )
1kl



q (a . . . a ) otherwise
m2 k+1
l

(14)

Function qm1 (a) compresses the string a, by eliding words when all their n-grams have been
recognized. We thus avoid storing the whole sub-generation string, produced by the decoder so far,
as mentioned earlier. Table 2 gives example values for pm1 (a) and qm1 (a) for the phrase mostly
cloudy, with a. Function qm2 (a) returns the head of the string a. As we progressively combine substrings (a1 . . . ak ) and (ak+1 . . . al ) together, for any 1  k  l, and their head words ah1  {a1 , . . . , ak }
and ah2  {ak+1 , . . . , al }, function qm2 (a) returns either ah1 or ah2 . The probability PDEP decides
whether ah1 attaches to ah2 or vice versa, thus augmenting D(ah1 ) with the pair hah1 , ah2 i or D(ah2 )
with hah2 , ah1 i, respectively.
322

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

j

Items:

[A, i, j; q(gi )]
R(A  B)
R(A  BC)

Axioms:

i+1
[W, i, i + 1; q(gi+1
i )] : s  p(gi )

W  gi+1 , gi+1  {, gen()}

Inference rules:
j

(1)

R(A  B) : s [B, i, j; q(gi )] : s1
j
j
[A, i, j; q(gi )] : s  s1  p(gi )

(2)

R(A  B C) : s [B, i, k; q(gki )] : s1 [C, k, j; q(gk )] : s2
j
j
[A, i, j; q(gi )] : s  s1  s2  p(gi )

j

Goal:

[S, 0, N; q(hsin1 gN0 h/si)]

Figure 8: Extended decoder using the rescoring function p(g). Productions A  B and A  B C
can be any of the GCS rules in Figure 1; features on grammar non-terminals are omitted for the sake
of clarity.
Note that equation (14) evaluates whether every word should attach to the left or right of every
other head word, and therefore essentially collapses to:

Pmdep = PDEP D(ah ) = PSTOP (STOP|ah , dir, ad j)PCHOOSE (aa |ah , dir)
(15)
PSTOP (STOP|ah , dir, ad j)
For example, in the case of pm2 (a1 . . . ak ), ah becomes one of a1 . . . ak , aa is one of ak+1 . . . al ,
dir = right and ad j is true if ah = ak and aa = ak+1 .
We are now ready to extend the basic decoder in Figure 5, so that it includes the rescoring funcj
tion p(gi ) over a generated sub-string gi . . . g j . The new deduction system is specified in Figure 8.
j
Items [A, i, j] become now [A, i, j; q(gi )]; they represent derivations from gi to g j rooted at the nonterminal A and augmented with model-specific strings as defined above; in other words, they include
the compressed sub-generations
 with elidedN parts and their head word. Analogously, our goal item
n1
N
now includes q hsi g0 h/si . Note that g0 is augmented with (n  1) start symbols hsi and an end
symbol h/si. This is necessary for correctly computing n-gram probabilities at the beginning and
end of the sentence. Figure 9 shows example instantiations of the inference rules of our extended
decoder.
The generation procedure is identical to the procedure described for the basic decoder in Figure 6, save the exponential more items that need to be deducted. Recall that the chart in Figure 6
stores at each cell chart[A, i, j] the set of combined weights of cells that correspond to the proved antecedents of item [A, i, j]. The new chart 0 for the extended decoder equivalently stores a set of lists
j
of weights at each cell position chart 0 [A, i, j]. The list contains the items [A, i, j; q(gi )] that have the
j
same root non-terminal A and span between i and j, but a different set q(gi ), sorted best-first. The
running time of integrating the LM and DMV models is O (N 3 |V |4(n1) |P|), where V is the output
vocabulary and P the vocabulary used in the DMV. When using a lexicalized dependency model,
323

fiKONSTAS & L APATA

R (R(skyCover1 .t)  FS(temp1 , start) R(temp1 .t)) : s
[FS(temp1 , start), 1, 2; hwith, INi] : s1 [R(temp1 .t), 2, 8; ha low ? 15 degrees, JJi] : s2
[R(skyCover1 .t), 1, 8; hwith a ? 15 degrees, JJi] : s  s1  s2  p(hwith a ? 15 degrees, JJi)
R (FS(windSpeed1 , min)  F(windSpeed1 , max) FS(windSpeed1 , max)) : s
[F(windSpeed1 , max), 3, 4; hhigh, JJi] : s1 [FS(windSpeed1 , max), 4, 5; h15, CDi] : s2
[FS(windSpeed1 , min), 3, 5; hhigh 15, JJi] : s  s1  s2
R (F(windDir1 , mode)  W(windDir1 , mode)) : s [W(windDir1 , mode), 3, 4; hsoutheast, JJi] : s1
[F(windDir1 , mode), 3, 4; hsoutheast, JJi] : s  s1
Figure 9: Inference rules in the extended decoder for productions (2), (4), and (7) from Table 1
(W EATHER G OV domain). The strings in h. . .i, correspond to the output of the functions qmlm
and qmdep . We adopt an unlexicalized dependency model, trained on POS tags derived from the
Penn Treebank project (Marcus et al., 1993). In the first example IN corresponds to the word with
and JJ to the word low, in the second example JJ corresponds to the word high and CD to the
number 15, whereas in the third example JJ corresponds to the word southeast.
P collapses to V , otherwise it contains the part-of-speech (POS) tags for every gi  V . Notice that
rule (2) in Figure 8 combines two items that contain at most 2(n  1) words, hence the exponent
4(n  2). This running time is too slow to use in practice, so as we explain below we must adopt
some form of pruning in order to be able to explore the search space efficiently.
3.7 Approximate Search
j

j

Consider the task of deriving a k-best list of items L([A, i, j; q(gi )]) for the deducted item [A, i, j; q(gi )]
j
of rule (2) in the extended decoder of Figure 8. An item Lm ([A, i, j; q(gi )]) at position m of the list,
j
with 1  m  k, takes the form [A, i, j; q(gm |i )]. An example of this procedure is shown in Figure 10.
j
The grid depicts all possible combinations of items [B, i, k; q(gki )] and [C, k, j; q(gk )] as inferred by
a rule of the form R(A  B C) with their corresponding weights. Any of the k2 combinations can
be used to create the resulting k-best list shown at the bottom of the figure, and store it on the cell
of chart 0 [A, i, j]. However, we only want to keep k items, so most of them are going to be pruned
away. In fact, the grid of the example can be in the worst case a cube, i.e., can hold up to two three
dimensions, one for all the rules A  B C with the same left hand-side non-terminal A, and two for
the corresponding items rooted on B and C6 ; this calls for the calculation of k3 combinations. A
better approach is to apply cube pruning (Chiang, 2007; Huang & Chiang, 2005), i.e., to compute
only a small corner of the grid and prune items out on the fly, thus obviating the costly computation
of all k3 combinations.
6. The deducted item [R(skyCover1 .t); q(g81 )] of Figure 10 can also be inferred by the rule R(R(skyCover1 .t) 
R(windSpeed1 .t) FS(windSpeed1 , start)) (and its corresponding antecedent items) or the rule R(R(skyCover1 .t) 
R(rainChance1 .t) FS(rainChance1 , start)), and so on. We illustrate only a slice of the cube, depicting the enumeration of k-best lists for a fixed grammar rule, for the sake of clarity.

324

fi[FS(temp1 , start), 1, 2; hwith, INi]

[FS(temp1 , start), 1, 2; ha, DTi]

[FS(temp1 , start), 1, 2; haround, RBi]

A G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

.95

.93

.91

[R(temp1 .t), 2, 8; ha low ? 15 degrees, JJi] .56

.40

.25

.20

[R(temp1 .t), 2, 8; hlow around ? 15 degrees, JJi] .54

.35

.30

.17

[R(temp1 .t), 2, 8; ha low ? around 17, RBi] .44

.15

.08

.10












[R(skyCover1 .t), 1, 8; hwith a ? 15 degrees, JJi
[R(skyCover1 .t), 1, 8; hwith low ? 15 degrees, JJi]
[R(skyCover1 .t), 1, 8; ha a ? 15 degrees, JJi]
[R(skyCover1 .t), 1, 8; haround low ? 15 degrees, RBi]
[R(skyCover1 .t), 1, 8; hwith a ? around 17, RBi]


: .40
: .35
: .25
: .17
: .15










Figure 10: Computing an exhaustive list for the deducted item [R(skyCover1 .t); q(g81 )] via application of inference rule (2) of the extended decoder in Figure 9. The antecedent items are
the rule R (R(skyCover1 .t)  R(temp1 .t) FS(temp1 , start)) and the items [R(temp1 .t), 2, 8; q(g82 )],
FS(temp1 , start), 1, 2; q(g21 )]. The figure shows a slice of the cube, for the particular rule; on each
side of the grid are the lists of the top three candidate items for each antecedent item, sorted bestfirst. Numbers in the grid represent the total score for each combination.

Consider Figure 11 as an example. Each side of the grid shows the lists of the top three items
for each antecedent item. Numbers on the grid represent the total score for each combination.
Figures 11b11d illustrate the enumeration of the top three combinations in best-first order. Cells
in gray represent the frontiers at each iteration; cells in black are the resulting top three items. The
basic intuition behind cube pruning is that for a pair of antecedent items u1 = [B, i, k; q(gki )], u2 =
j
[C, k, j; q(gk )] and their sorted k-best lists L(u1 ), L(u2 ), the best combinations should lie close to the
upper-left corner of the grid. In the example, the 3-best list of the nodes u1 = [R(temp1 .t), 2, 8; q(g82 )]
325

fi[FS(temp1 , start), 1, 2; hwith, INi]

[FS(temp1 , start), 1, 2; ha, DTi]

[FS(temp1 , start), 1, 2; haround, RBi]

[FS(temp1 , start), 1, 2; hwith, INi]

[FS(temp1 , start), 1, 2; ha, DTi]

[FS(temp1 , start), 1, 2; haround, RBi]

[FS(temp1 , start), 1, 2; hwith, INi]

[FS(temp1 , start), 1, 2; ha, DTi]

[FS(temp1 , start), 1, 2; haround, RBi]

KONSTAS & L APATA

.95

.93

.91

.95

.93

.91

.95

.93

.91

[R(temp1 .t), 2, 8; ha low ? 15 degrees, JJi] .56

.40

.25

.20

.40

.25

.20

.40

.25

.20

[R(temp1 .t), 2, 8; hlow around ? 15 degrees, JJi] .54

.35

.30

.17

.35

.30

.17

.35

.30

.17

[R(temp1 .t), 2, 8; ha low ? around 17, RBi] .44

.15

.08

.10

.15

.08

.10

.15

.08

.10

(a)

(b)

(c)

Figure 11:
Computing item combinations for u1 = [R(temp1 .t), 2, 8; q(g82 )] and
u2 = [FS(temp1 , start), 1, 2; q(g21 )] using cube pruning. In (a)(c) we enumerate the combinations of items in order to construct a resulting k-best list as described in the text.
and u2 = [FS(temp1 , start), 1, 2; q(g21 )] are:
h
i
L(u1 ) = ha low ? 15 degrees, JJi, hlow around ? 15 degrees, JJi, ha low ? around 17, RBi
h
i
L(u2 ) = hwith, INi, ha, DTi, haround, RBi
and intuitively the best combination should be the derivation on the top left corner7 :

 

L1 (u1 ), L1 (u2 ) = ha low ? 15 degrees, JJi, hwith, INi = hwith a ? 15 degrees, INi
In cases where the combination cost, i.e., the score of the grammar rule multiplied with the
rescoring weight p(g), is negligible, we could start enumerating item combinations in the order shown in Figures 11b11c, starting from (L1 (u1 ), L1 (u2 )) and stopping at k. Since the two
lists are sorted it is guaranteed that L2 (u1 ), i.e., the second item in the k-best list of u1 is either
(L1 (u1 ), L2 (u2 )) or (L2 (u1 ), L1 (u2 )) (in the example of Figure 11b it is the latter). We thus select
it and move on to compute its neighboring combinations, and so on.8 For the computation of the
k-best lists of the axioms [W, i, i + 1; q(gii+1 )], we enumerate the top-k terminal symbols gi+1 .
If we take into account the combination cost, the grid is non-monotonic, and therefore the bestfirst guarantee no longer holds as we enumerate neighbors in the fashion just described. Huang
and Chiang (2007) argue that the loss incurred by the search error is insignificant compared to the
speedup gained. In any case, to overcome this, we compute the resulting k-best list, by first adding
7. Note that the head of the sub-generation fragment has shifted to the head of L2 .
8. Contrary to Huang and Chiang (2007) we use probabilities instead of log scores in the computation of the item
combinations, hence we select the biggest scoring combinations.

326

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

the computed item combinations in a temporary buffer, and then resort it after we have enumerated
a total of k combinations.
3.8 Learning
We represent our grammar and each input scenario as a weighted hypergraph (Gallo, Longo, Pallottino, & Nguyen, 1993). We follow the procedure proposed by Klein and Manning (2001) which
allows to transform any CFG to a hypergraph. In order to learn the weights of the grammar rules
we directly estimate them on the hypergraph representation using the EM algorithm. Formally, the
objective we are trying to optimize factorizes into:
P(r, ri .f, w|d) =  P(ri |d)  P(ri . f j |ri )  P(w j |ri . f j , ri )
i

j

(16)

k

where r is the set of all record tokens ri . Given a training set of scenarios with database records d
and observed text w we maximize the marginal likelihood of the data, while summing out record
tokens ri and their fields ri .f, which can be regarded as latent variables:
arg max


  p(r, ri .f, w|d; ),

(17)

(w,d) r,ri .f

where  are the multinomial distributions or weights of GGEN . The EM algorithm alternates between
the E-step and the M-step. In the E-step we compute the expected counts for the rules using a
dynamic program similar to the inside-outside algorithm (Li & Eisner, 2009). Then in the M-step,
we optimise  by normalising the counts computed in the E-step. We initialise EM with a uniform
distribution for each multinomial distribution and applied add-0.001 smoothing to each multinomial
in the M-step. On average, EM converged for all datasets after 15 iterations. Note that the n-gram
language model and the dependency model are trained externally, hence their parameters are not
optimized alongside our model. The generation procedure for the extended decoder in Figure 8 is
implemented using dynamic programming. The choice of the hypergraph representation is merely
one of several alternatives. For example, we could have adopted a representation based on weighted
finite state transducers (de Gispert, Iglesias, Blackwood, Banga, & Byrne, 2010) since our model
describes a regular language both in terms of the PCFG and the surface level models we intersect
it with. It is also possible to represent our grammar as a pushdown automaton (Iglesias, Allauzen,
Byrne, de Gispert, & Riley, 2011) and intersect it with finite automata representing a language model
and dependency-related information, respectively. The choice of the hypergraph representation was
motivated by its compactness9 and the fact that it allows for future extensions of our PCFG with
rules which capture more global aspects of the generation problem (e.g., document planning) and
which unavoidably result in context-free languages.

4. Experimental Design
In this section we present our experimental setup for assessing the performance of our model. We
give details on the datasets we used, explain how our own model was trained, describe the models
used for comparison with our approach, and discuss how system output was evaluated.
9. Hypergraphs are commonly used in the machine translation literature to allow for compact encoding of SCFGs
even though in some cases they also describe regular languages. For example, this is true for the SCFGs employed
in hierarchical phrase-based SMT (Chiang, 2007) which assume a finite input language and do not permit infinite
recursions.

327

fiKONSTAS & L APATA

4.1 Data
We used our system to generate soccer commentaries, weather forecasts, and spontaneous utterances relevant to the air travel domain (examples are given in Figure 1). For the first domain we
used the dataset described in the work of Chen and Mooney (2008), which consists of 1,539 scenarios from the 20012004 Robocup game finals (henceforth ROBO C UP). Each scenario contains
on average |d| = 2.4 records, each paired with a short sentence (5.7 words). This domain has a
small vocabulary (214 words) and simple syntax (e.g., a transitive verb with its subject and object).
Records in this dataset were aligned manually to their corresponding sentences (Chen & Mooney,
2008). Given the relatively small size of this dataset, we performed cross-validation following previous work (Chen & Mooney, 2008; Angeli et al., 2010). We trained our system on three ROBO C UP
games and tested on the fourth, averaging over the four train/test splits.
For weather forecast generation, we used the dataset presented in the work of Liang et al. (2009),
which consists of 29,528 weather scenarios for 3,753 major US cities (collected over four days). The
vocabulary in this domain (henceforth W EATHER G OV) is comparable to ROBO C UP (345 words),
however, the texts are longer (N = 29.3) and more varied. On average, each forecast has 4 sentences
and the content selection problem is more challenging; only 5.8 out of the 36 records per scenario
are mentioned in the text which roughly corresponds to 1.4 records per sentence. We used 25,000
scenarios from W EATHER G OV for training, 1,000 scenarios for development and 3,528 scenarios
for testing. This is the same partition used in the work of Angeli et al. (2010).
For the air travel domain we used the ATIS dataset (Dahl, Bates, Brown, Fisher, Hunicke-Smith,
Pallett, Pao, Rudnicky, & Shriberg, 1994), consisting of 5,426 scenarios. These are transcriptions
of spontaneous utterances of users interacting with a hypothetical online flight booking system.
We used the dataset introduced in the work of Zettlemoyer and Collins (2007)10 and automatically converted their lambda-calculus expressions to attribute-value pairs following the conventions adopted in the study of Liang et al. (2009).11 Figure 1c shows the output of our conversion process from the original lambda expression x. f light(x)  f rom(x, denver)  to(x, boston) 
day number departure(x, 9)  month departure(x, august) < (arrival time(x), 16:00). Given
such an expression, we first create a record for each variable (e.g., x). We then assign record types
according to the corresponding class types (e.g., variable x has class type flight). Next, fields and
values are added from predicates with two arguments with the class type of the first argument matching that of the record type. The name of the predicate denotes the field, and the second argument
denotes the value (e.g., f rom(x, denver) is used to fill the record of type Flight, since the type of
the first argument is also f light). The name of the function becomes the field name, (i.e., from) and
the second argument is set as its value, (i.e., denver). Note that some functions have names such as
month departure, month arrival, day number arrival, day number departure and so on. In order
to reduce the resulting number of record types, we created aggregate record types which embed
the common information (i.e., departure, or arrival) to a special field. In the example, the function
day number departure is split into the value departure of the field dep/ar for the record Day, and
into the field number with value 9. We also defined special record types, such as Condition and
Search. The latter is introduced for every lambda operator and assigned the categorical field what
with value flight which refers to the record type of variable x.
10. The original corpus contains user utterances of single dialogue turns which would result in trivial scenarios. Zettlemoyer and Collins (2007) concatenate all user utterances referring to the same dialogue act, (e.g., book a flight), thus
yielding more complex scenarios with longer sentences.
11. See Konstas (2013) for the resulting dataset.

328

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

In contrast to the two previous datasets, ATIS has a much richer vocabulary (927 words); each
scenario corresponds to a single sentence (average length is 11.2 words) with 2.65 out of 19 record
types mentioned on average. Note that the original lambda expressions were created based on
the utterance, and thus contain all the necessary information conveyed in the meaning of the text.
As a result, all of the converted records in each scenario are mentioned in the corresponding text.
Following the work of Zettlemoyer and Collins (2007), we trained on 4,962 scenarios and tested on
ATIS NOV93 which contains 448 examples.
4.2 Model Training
Generation in our model amounts to finding the best derivation (g, h) that maximizes the product
of two likelihoods, namely p(g, h | d) and p(g) (see equation (5)). p(g, h | d) corresponds to the
rules of GGEN that generate the word sequence g, whereas p(g) is the likelihood of g independently
of d. We estimate p(g, h | d) as described in Section 3.8. Examples of the top scoring items of the
multinomial distributions for some of the grammar rules of GGEN are given in Table 3. We obtain
an estimate for p(g) by linearly interpolating the score of a language model and DMV (Klein &
Manning, 2004).
Specifically, our language models were trained with the SRI toolkit (Stolcke, 2002) using add-1
smoothing.12 For the ROBO C UP domain, we used a bigram language model given that the average
text length is relatively small. For W EATHER G OV and ATIS, we used a trigram language model.
We obtained an unlexicalized version of the DMV13 for each of our domains. All datasets were
tagged automatically using the Stanford POS tagger (Toutanova, Klein, Manning, & Singer, 2003)
and words were augmented with their part of speech, e.g., low becomes low/JJ, around becomes
around/RB and so on; words with several parts of speech were duplicated as many times as the
number of different POS tags assigned to them by the tagger. For example, the gust may act both
as a noun and a verb, given their context, hence we keep both augmented forms, i.e., gust/NNS and
gust/VBS. We initialized EM to uniform distributions where a small amount of noise14 was added
over all multinomials (i.e., PSTOP and PCHOOSE ) to break initial symmetry. Klein and Manning (2004)
use a harmonic distribution instead, where the probability of one word heading another is higher
if they appear closer to one another. Preliminary results on the development set showed that the
former initialization scheme was more robust across datasets.
Our model has two hyperparameters: the number of k-best derivations considered by the decoder and the vector  of weights for model integration. Given that we only interpolate two models whose weights should sum to one, we only need to modulate a single interpolation parameter 0  LM  1. When LM is 0, the decoder is only influenced by the DMV and conversely when
LM is 1 the decoder is only influenced by the language model. In the general case, we could learn
the interpolation parameters using minimum error rate training (Och, 2003), however this was not
necessary in our experiments. We performed a grid search over k and LM on held-out data taken
12. Adopting a more complex smoothing technique such as Good-Turing (Good, 1953) is usually not applicable in so
small vocabularies. The statistics for computing the so called count-of-counts, i.e., the number words occurring once,
twice and so on, are not sufficient and lead to poor smoothing estimates.
13. When trained on the WSJ-10 corpus, our implementation of the DMV obtained the same accuracy as reported in
the work of Klein and Manning (2004). WSJ-10 consists of 7,422 sentences with at most 10 words after removing
punctuation.
14. Repeated runs with different random noise on the WSJ-10 corpus yielded the same results; accuracy stabilized around
the 60th iteration (out of 100).

329

fiKONSTAS & L APATA

Weight Distribution
P( | pass, from, purple2)
P( | steal, null, NULL)
P( | turnover, null, NULL)

Top-5 scoring items
purple2, a, makes, pink10, short
ball, the, steals, from, purple8
to, the, ball, kicks, loses

(a) ROBO C UP

Weight Distribution
P(ri .t | temperature)
P(ri .t | windSpeed)
P(ri .t | skyCover)
P( fi | temperature.time)
P( fi | windSpeed.min)
P( fi | gust.max)
P( | skyCover, percent, 0-25)
P( | skyCover, percent, 25-50)
P( | rainChance, mode, Definitely)

Top-5 scoring items
windDir, sleetChance, windSpeed,
freezingRainChance, windChill
gust, null, precipPotential,
windSpeed, snowChance
temperature, skyCover, thunderChance,
null, rainChance
min, max, mean, null, time
max, time, percent, mean, null
min, mean, null, time, max
,, clear, mostly, sunny, mid
,, cloudy, partly, clouds, increasing
rain, of, and, the, storms

(b) W EATHER G OV

Weight Distribution
P(ri .t | search)
P(ri .t | flight)
P(ri .t | day)
P( | flight, to, mke)
P( | search, what, flight)
P( | search, type, query)

Top-5 scoring items
flight, search, when, day, condition
search, day, flight, month, condition
when, search, flight, month, condition
mitchell, general, international, takeoffs, depart
I, a, like, to, flight
list, the, me, please, show
(c) ATIS

Table 3: Top-5 scoring items of the multinomial distributions for record rules, field rules and the
categorical word rewrite rule of GGEN (see rules (2), (4), and (8) in Table 1, respectively). The first
column of each table shows the underlying multinomial distribution for the corresponding rule. For
example P( | pass, from, purple2), corresponds to the distribution of emitting word  given the
value purple2 of the field from of the record with type pass.

from W EATHER G OV, ROBO C UP, and ATIS, respectively. The optimal values for k and LM for the
three domains (when evaluating system performance with BLEU-4) are shown in Table 4.
We conducted two different tuning runs, one for a version of our model that only takes the LM
into account (k- BEST- LM; LM = 1) and another one where the LM and the DMV are integrated
(k- BEST- LM - DMV). As can be seen, optimal values for k are generally larger for k- BEST- LM - DMV.
This is probably due to noise introduced by the DMV; as a result, the decoder has to explore the
search space more thoroughly. In an effort to investigate the impact of the DMV further, we fixed
330

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

k- BEST- LM
ROBO C UP
W EATHER G OV
ATIS

k
25
15
40

(a) Interpolation with LM

k- BEST- LM - DMV
ROBO C UP
W EATHER G OV
ATIS

k
85
65
40

LM
0.9
0.3
0.6

(b) Interpolation with LM and DMV

Table 4: Optimal values for parameters k and LM calculated by performing grid search against
BLEU-4 on the development set. LM in Table (a) is set to 1.

LM = 0 on the development set and performed a grid search with the DMV on its own. Model
performance dropped significantly (by 58% BLEU points) which is not entirely surprising given
that the DMV alone cannot guarantee fluent output. Its contribution rather rests on capturing more
global dependencies outwith the local horizon of the language model.
4.3 Determining the Output Length
Unlike other generation systems that operate on the surface realization level with word templates,
we emit each word individually in a bottom-up fashion. Therefore, we need to decide on the number
of words N we wish to generate before beginning the decoding process. A common approach is to
fix N to the average text length of the training set (Banko, Mittal, & Witbrock, 2000). However, this
would not be a good choice in our case, since text length does not follow a normal distribution. As
shown in Figure 12 the distribution of N across domains is mostly skewed.
To avoid making unwarranted assumptions about our output, we trained a linear regression
model that determines the text length individually for each scenario. As input to the model, we
used a flattened version of the database, with features being record-field pairs. The underlying idea
is that if a scenario contains many records and fields, then we should use more words to express
them. In contrast, if the number of records and fields is small, then it is likely that the output is more
laconic. In an attempt to capture the number of words needed to communicate specific record-field
pairs, we experimented with different types of feature values, e.g., by setting a feature to its actual
value (categorical or numerical) or its frequency in the training data. The former scheme worked
better in denser datasets, such as W EATHER G OV and ROBO C UP whereas the latter was adopted
in ATIS which has a sparser database, as a means to smooth out infrequent values. When trained
on the training set and tested on the development set our regression model obtained a correlation
coefficient of 0.64 for ROBO C UP, 0.84 for W EATHER G OV, and 0.73 for ATIS (using Pearsons r).
4.4 System Comparison
We evaluated three configurations of our system. A baseline that uses the top scoring derivation in
each subgeneration (1- BEST) and two versions of our model that make better use of our decoding
algorithm. One version integrates the k-best derivations with a LM (k- BEST- LM), the other version additionally takes the DMV into account (k- BEST- LM - DMV). Preliminary experiments with a
model that integrates the k-best derivations with the DMV did not exhibit satisfactory results (see
Section 4.2) and we omit them here for the sake of brevity. We compared the output of our models to
331

fiKONSTAS & L APATA

6000

700
600
500
400
300
200
100

Frequency

Frequency

7000
5000
4000
3000
200
1000
3 5 7 9 11 13 15 17

9

(a) Text length N in ROBO C UP

21 33 45 57 69 81

(b) Text length N in W EATHER G OV

Frequency

2400
2000
1600
1200
800
400
2

6 10 14 18 22 26 30 34 38 44 48
(c) Text length N in ATIS

Figure 12: Text length distribution in ROBO C UP, W EATHER G OV, and ATIS (training set).
Angeli et al. (2010) whose approach is closest to ours and state-of-the-art on the W EATHER G OV.15
For ROBO C UP, we also compared against the best-published results (Kim & Mooney, 2010).
4.5 Evaluation
We evaluated system output automatically, using the BLEU-4 modified precision score (Papineni,
Roukos, Ward, & Zhu, 2002) with the human-written text as reference. In addition, we evaluated
the generated text via a judgment elicitation study. Participants were presented with a scenario and
its corresponding verbalization and were asked to rate the latter along two dimensions: fluency
(is the text grammatical and overall understandable?) and semantic correctness (does the meaning
conveyed by the text correspond to the database input?). The subjects used a five point rating scale
where a high number indicates better performance. We randomly selected 12 documents from the
test set (for each domain) and generated output with our models (1- BEST and k- BEST- LM - DMV) and
Angeli et al.s (2010) model. We also included the original text (H UMAN) as gold standard. We thus
15. We are grateful to Gabor Angeli for providing us with the code of his system.

332

fiF IXED

J OINT

A G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

System
1- BEST
k- BEST- LM
k- BEST- LM - DMV
1- BEST
k- BEST- LM
k- BEST- LM - DMV
A NGELI
K IM -M OONEY

BLEU
8.01.
24.88
23.14
10.79.
30.90
29.73
28.70
47.27.

System
1- BEST
k- BEST- LM
k- BEST- LM - DMV
A NGELI

BLEU
8.64.
33.70
34.18.
38.40.

(b) W EATHER G OV

System
1- BEST
k- BEST- LM
k- BEST- LM - DMV
A NGELI

BLEU
11.85.
29.30
30.37
28.70

(c) ATIS

(a) ROBO C UP

Table 5: BLEU-4 scores on ROBO C UP, W EATHER G OV, and ATIS ( : significantly different from
1- BEST;  : significantly different from A NGELI; . significantly different from k- BEST- LM;  : significantly different from k- BEST- LM - DMV;  : significantly different from K IM -M OONEY.
obtained ratings for 48 (12  4) scenario-text pairs for each domain. The study was conducted over
the Internet using Amazon Mechanical Turkand involved 305 volunteers (104 for ROBO C UP, 101
for W EATHER G OV, and 100 for ATIS), all self reported native English speakers. Our experimental
instructions are given in Appendix A.

5. Results
We conducted two experiments on the ROBO C UP domain. We first assessed the performance of
our generator on joint content selection and surface realization and obtained the results shown in
the upper half of Table 5a (see J OINT). In a second experiment we forced the generator to use the
gold-standard records from the database. This was necessary in order to compare with previous
work (Angeli et al., 2010; Kim & Mooney, 2010).16 Our results are summarized in lower half of
Table 5a (see F IXED).
Overall, our generator performs better than the 1- BEST baseline and comparably to Angeli et al.
(2010). k- BEST- LM - DMV is slightly worse than k- BEST- LM. This is due to the fact that sentences
in ROBO C UP are very short (their average length is 5.7 words) and as a result our model cannot
recover any meaningful dependencies. Using the Wilcoxon signed-rank test we find that differences
in BLEU scores among k- BEST- LM - DMV, k- BEST- LM and A NGELI are not statistically significant. Kim and Mooney (2010) significantly outperform these three models and the 1- BEST baseline
(p < 0.01). This is not entirely surprising, however, as their model requires considerable more
supervision (e.g., during parameter initialization) and includes a post-hoc re-ordering component.
Finally, we also observe a substantial increase in performance compared to the joint content selection and surface realization setting. This is expected as the generator is faced with an easier task
and there is less scope for error.
With regard to W EATHER G OV, our model (k- BEST- LM and k- BEST- LM - DMV) significantly improves over the 1- BEST baseline (p < 0.01) but lags behind Angeli et al. (2010) and the difference is
16. Angeli et al. (2010) and Kim and Mooney (2010) fix content selection both at the record and field level. We let our
generator select the appropriate fields, since these are at most two per record type and this level of complexity can be
easily tackled during decoding.

333

fiKONSTAS & L APATA

F1 (%)

BLEU-4 (%)

100
90
80
70
60
50
40
30
20
10
5 000 10 000 15 000 20 000 25 000
Number of training scenarios

50
45
40
35
30
25
20
15
10
5
5 000 10 000 15 000 20 000 25 000
Number of training scenarios

(a) Alignment

(b) Generation output

Figure 13: Learning curves displaying how the quality of the alignments and generated output vary
as a function of the size of the training data.

statistically significant (p < 0.01). Since our system emits words based on a language model rather
than a template, it displays more freedom in word order and lexical choice, and thus is likelier to
produce more creative output, sometimes even overly distinct compared to the reference. Dependencies seem to play a more important role here, yielding overall better performance.17 Interestingly,
k- BEST- LM - DMV is significantly better than k- BEST- LM in this domain (p < 0.01). Sentences in
W EATHER G OV are longer than in ROBO C UP and this allows the k- BEST- LM - DMV to learn dependencies that capture information complementary to the language model.
On ATIS, the k- BEST- LM - DMV model significantly outperforms the 1- BEST (p < 0.01) and
A NGELI (p < 0.05), whereas k- BEST- LM performs comparably. Furthermore, k- BEST- LM - DMV is
significantly better than k- BEST- LM (p < 0.01). The ATIS domain is the most challenging with
respect to surface realization. The vocabulary is larger than ROBO C UP by a factor of 4.3 and
W EATHER G OV by a factor of 2.7. Because of the increased vocabulary the model learns richer
dependencies which improve its fluency and overall performance.
We also examined the amount of training data required by our model. We performed learning
experiments on W EATHER G OV since it contains more training scenarios than ROBO C UP and ATIS
and is more challenging with regard to content selection. Figures 13(a) and (b) show how the number of training instances influnces the quality of the alignment and generation output, respectively.
We measure alignment F-score following the methodology outlined in the work of Liang et al.
(2009) using their gold alignments. The graphs show that 5,000 scenarios are enough for obtaining
reasonable alignments and generation output. A very small upward trend can be detected with increasing training instances, however it seems that considerably larger amounts would be required to
obtain noticeable improvements.
17. DMV is commonly trained on a sentence-by-sentence basis. In the ROBO C UP and ATIS datasets, each scenario-text
pair corresponds to a single sentence. In W EATHER G OV, however, the text may include multiple sentences. In
the latter case we trained the DMV on the multi-sentence text without presegmenting it into individual sentences.
This non-standard training regime did not seem to pose any difficulty in this domain, as we can safely assume that
all examples have the same elided root head, namely weather (e.g., The weather is mostly cloudy, with a low
around 30).

334

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

System
1- BEST
k- BEST- LM - DMV
A NGELI
H UMAN

ROBO C UP
F
SC

2.14
2.09

4.05
3.55

4.01
3.47
4.17
3.97

W EATHER G OV
F
SC

2.25
2.53

3.89
3.54

3.82
3.72
4.01
3.58

ATIS
F
2.40
3.96
3.86
4.16

SC
2.49
3.82
3.31
3.96

Table 6: Mean ratings for fluency (F) and semantic correctness (SC) on system output elicited by
humans on ROBO C UP, W EATHER G OV, and ATIS ( : significantly different from 1- BEST;  : significantly different from A NGELI;  : significantly different from k- BEST- LM - DMV;  : significantly
different from H UMAN).
The results of our human evaluation study are shown in Table 6. We report mean ratings for each
system and the gold-standard human authored text. Our experimental participants rated the output
on two dimensions, namely fluency (F) and semantic correctness (SC). We elicited judgments only
for k- BEST- LM - DMV as it generally performed better than k- BEST- LM in our automatic evaluation
(see Table 5). We carried out an Analysis of Variance (A NOVA) to examine the effect of system
type (1- BEST, k- BEST- LM - DMV, A NGELI, and H UMAN) on the fluency and semantic correctness
ratings. We used Tukeys Honestly Significant differences (HSD) test, as explained by Yandell
(1997) to assess whether means differences are statistically significant.
On all three domains our system (k- BEST- LM - DMV) is significantly better than the 1- BEST baseline (a < 0.01) in terms of fluency. Our output is indistinguishable from the gold-standard (H UMAN)
and A NGELI (pair-wise differences among k- BEST- LM - DMV, A NGELI and H UMAN are not statistically significant). With respect to semantic correctness, on ROBO C UP, k- BEST- LM - DMV is significantly better than 1- BEST (a < 0.01) but significantly worse than H UMAN (a < 0.01). Although
the ratings for k- BEST- LM - DMV are numerically higher than A NGELI, the difference is not statistically significant. A NGELI is also significantly worse than H UMAN (a < 0.01). On W EATHER G OV,
the semantic correctness of k- BEST- LM - DMV and A NGELI is not significantly different. These two
systems are also indistinguishable from H UMAN. On ATIS, k- BEST- LM - DMV is the best performing model with respect to semantic correctness. It is significantly better than 1- BEST and A NGELI
(a < 0.01) but not significantly different from H UMAN.
In sum, we observe that performance improves when k-best derivations are taken into account
(the 1- BEST system is consistently worse). Our results also show that taking dependency-based
information into account boosts model performance over and above what can be achieved with a
language model. Our model is on par with A NGELI on ROBO C UP and W EATHER G OV but performs
better on ATIS when evaluated both automatically and by humans. Error analysis suggests that a
reason for A NGELIs poorer performance on ATIS might be its inability to create good quality
surface templates. This is due to the lack of sufficient data and the fact that templates cannot
fully express the same database configurations in many different ways. This is especially true for
ATIS which consists of transcriptions of spontaneous spoken utterances and the same meaning can
be rendered in many different ways. For example, the phrases show me the flights, what are
the flights, which flights, and please can you give me the flights, all convey the exact same
meaning stemming from a Search record.
Our model learns domain specific conventions about how to say and what to say from data,
without any hand-engineering or manual annotation. Porting the system to a different domain is
335

fiKONSTAS & L APATA

Bad Pass
Input:
1- BEST:
k- BEST- LM - DMV:

from
to
pink11 purple5
pink11 pass purple5 purple5 pink11 pass purple5 purple5 purple5
pink11 made a pass that was intercepted by purple5

A NGELI:

pink11 made a bad pass that missed its target and was picked up by
purple5

H UMAN:

pink11 tries to pass but was intercepted by purple5
(a) ROBO C UP

Input:

1- BEST:
k- BEST- LM - DMV:

Temperature

Cloud Sky Cover

time
min mean max
06:00-21:00 32 39 46

time
percent (%)
06:00-21:00
75-100

Wind Speed

Wind Direction

time
min mean max
06:00-21:00 6
7
10

time
mode
06:00-21:00 SE

Near 46. Near 46. Near 46. Near 46. Near 46. With near 46. Southeast wind.
Mostly cloudy, with a high near 46. South southeast wind between 6 and 10 mph.

A NGELI :

A chance of rain or drizzle, with a high near 46. Southeast wind between 6
and 10 mph. mph. Chance of precipitation is 60%.

H UMAN:

Mostly cloudy, with a high near 46. South southeast wind between 6 and 10 mph.
(b) W EATHER G OV

Input:
1- BEST:
k- BEST- LM - DMV:

Flight

Day

Search

from
to
milwaukee phoenix

day
dep/ar/ret
saturday departure

type what
query flight

Milwaukee Phoenix on Saturday on Saturday on Saturday on Saturday
Show me the flights from Milwuakee to Phoenix on Saturday

A NGELI :

Show me the flights between Milwuakee and Phoenix on Saturday

H UMAN:

Milwuakee to Phoenix on Saturday
(c) ATIS

Figure 14: Example output on (a) sportscasting, (b) weather forecasting, and (c) air travel domains
with correct content selection.

straightforward, assuming a database and corresponding (unaligned) text. As long as the database
obeys the structure of the grammar GGEN , we need only retrain the model to obtain the weights of
the grammar rules; in addition, the system requires a domain specific language model and optionally
336

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

Gold:

Output:

Temperature

Cloud Sky Cover

Chance of Rain

time
min mean max
06:00-21:00 30 38 44

time
percent (%)
06:00-21:00
75-100

Time
Mode
06:00-21:00 Slight Chance

Wind Speed

Wind Direction

Precipitation Potential (%)

time
min mean max
06:00-21:00 6
6
7

time
mode
06:00-21:00 ENE

time
min mean max
06:00-21:00 9 20 35

A 40 percent chance of showers before 10am. Mostly cloudy, with a high
near 44. East northeast wind around 7 mph.
(a) Gold standard content selection and its verbalization

Content
Selection:

Output:

Temperature

Cloud Sky Cover

Chance of Rain

time
min mean max
06:00-21:00 30 38 44

time
percent (%)
06:00-21:00
75-100

time
mode
06:00-09:00 Chance

Wind Speed

Wind Direction

Chance of Thunderstorm

time
min mean max
06:00-21:00 6
6
7

time
mode
06:00-21:00 ENE

time
mode
06:00-13:00 -13:00-21:00 --

A chance of showers. Patchy fog before noon. Mostly cloudy, with a
high near 44. East wind between 6 and 7 mph.
(b) k- BEST- LM - DMV content selection

Content
Selection:

Output:

Temperature

Precipitation Potential (%)

Chance of Rain

time
min mean max
06:00-21:00 30 38 44

time
min mean max
06:00-21:00 9 20 35

time
mode
06:00-09:00 Chance

Wind Speed

Wind Direction

Chance of Thunderstorm

time
min mean max
06:00-21:00 6
6
7

time
mode
06:00-21:00 ENE

time
mode
06:00-21:00 --

A chance of showers. Patchy fog before noon. Mostly cloudy, with a high
near 44. East wind between 6 and 7 mph. Chance of precipitation is 35%
(c) A NGELI content selection

Figure 15: Example output on W EATHER G OV domain with incorrect content selection (in gray).

337

fiKONSTAS & L APATA

ROOT
on
on

show

on

me

on

from
Phoenix
Phoenix

show me the flights from Milwaukee to Phoenix on Saturday
Figure 16: Dependency structure for the sentence Show me the flights from Milwaukee to Phoenix
on Sunday as generated by k- BEST- LM - DMV (see Figure 14c). Intermediate nodes in the tree denote
the head words of each subtree.

information about heads and their dependents which the DMV learns in an unsupervised fashion.
In the latter case, we also need to tune the hyperparameter LM , and in both cases k. Note, that
fine-tuning k becomes less important when integrating with a language model only. As we explain
in Section 4.2, the DMV possibly introduces noise, therefore we have to modulate k more carefully
so as to allow the decoder to search in a bigger space.
Examples of system output with correct content selection at the record level are given in Figure 14. Note that in the case of ROBO C UP, content selection is fixed to the gold standard. As can
be seen, the generated text is close to the human authored text. Also note that the output of our
system improves considerably when taking k-best derivations into account (compare 1- BEST and
k- BEST- LM - DMV in the figure). Figure 15a shows examples with incorrect content selection at the
record level for the W EATHER G OV domain. Figure 15a shows the gold standard content selection
and its corresponding verbalization. Figures 15b and 15c show the output of the k- BEST- LM - DMV
system and A NGELI. Tables in black denote record selection identical to the gold standard, whereas
tables in grey denote false positive recall. k- BEST- LM - DMV identifies an incorrect value for the
Mode field in the Chance of Rain record; in addition, it fails to select the Precipitation Potential (%) record altogether. The former mistake does not affect the correctness of the generators
output, whereas the latter does (i.e., it fails to mention the exact likelihood of rain, 40% in the gold
standard and 35% in A NGELIs output). Finally, Figure 16 shows the dependency structure our
model produced for the sentence Show me the flights from Milwaukee to Phoenix on Saturday from
Figure 14c; notice the long range dependency between flights and on, which would otherwise be
inaccessible to a language model.
338

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

6. Conclusions
We have presented an end-to-end generation system that performs content selection and surface
realization simultaneously. Central to our approach is the encoding of generation as a parsing problem. We reformulate the input (a set of database records and text describing some of them) as a
PCFG and show how to approximately find the best generated string licensed by the grammar. We
evaluated our model on three domains (ROBO C UP, W EATHER G OV, ATIS) and showed that it is
able to obtain performance comparable or superior to the state-of-the-art. Our experiments were
also designed to assess several aspects of the proposed framework such as the use of k-best decoding and the intersection of our grammar with multiple information sources. We observed that k-best
decoding is essential to producing good quality output. Across domains, performance increases by
a factor of at least two when multiple derivations are taken into account. In addition, intersecting
the grammar with dependency-based information seems to capture syntactic information complementary to the language model. We argue that our approach is computationally efficient and viable
in practical applications. Outwith generation, we hope that some of the work described here might
be of relevance to other fields such as summarization or machine translation.
Future extensions are many and varied. An obvious extension concerns porting the framework
to more challenging domains with richer vocabulary and longer texts (e.g., product descriptions,
user manuals, sports summaries). A related question is how to extend the PCFG-based approach
advocated here so as to capture discourse-level document structure. Other future directions involve
exploiting the information available in the database more directly. Our model takes into account
the k-best derivations at decoding time, however inspection of these indicates that it often fails to
select the best one. Initial work (Konstas & Lapata, 2012) shows that the model presented here
can be adapted to use forest reranking, a technique that approximately reranks a packed forest of
exponentially many derivations (Huang, 2008). The reranker is essentially a structured perceptron
(Collins, 2002) enriched with local and non-local features. It therefore allows to explicitly model
dependencies across fields, records, and their interactions.
Finally, although not the focus of this paper, it is worth pointing out that the model described
here can also perform semantic parsing, i.e., convert text into a formal meaning representation. This
can be done trivially by modifying the grammar in Table 1. Instead of observing words as terminals
(rules (8) and (9)), we observe values of fields, given a particular word w, field, and record:
W(r, r. f )  f .v

[P( f .v | r, r. f , f .t, w)]

W(r, r. f )  gen(w)

[P(gen(w).mode | r, r. f , f .t=int)]

During decoding, the prior p(g) in equation (4) becomes p( f .v) and can be naively obtained by
creating an n-gram language model over the alignments between the meaning representations and
the text. Such alignments are in principle hidden but could be estimated using the model of Liang
et al. (2009).

Acknowledgments
We are grateful to the anonymous referees whose feedback helped to substantially improve the
present paper. Thanks to Luke Zettlemoyer and Tom Kwiatkowski for their help with the ATIS
dataset as well as Giorgio Satta and Frank Keller for helpful comments and suggestions. We also
339

fiKONSTAS & L APATA

thank the members of the Probabilistic Models reading group at the University of Edinburgh for their
feedback. A preliminary version of this work was published in the proceedings of NAACL 2012.

Appendix A. Experimental Instructions
A.1 Instructions
In this experiment you will be given tables that contain some facts about the weather (e.g., Temperature, Chance of Rain, Wind Direction, Cloud Coverage and so on) and their translation in
natural language. Example 1 below tabulates such weather related information and its translation as
Rainy with a high near 47. Windy, with an east wind between 5 and 15 mph.
Example 1
Category

Temperature

Fields

time: 17.0006.00(+1 day) min: 30

mean: 40 max: 47

Wind Direction time: 17.0006.00(+1 day) mode: SE
Cloud Sky Cover time: 17.0006.00(+1 day) percent: 2550
Chance of Rain time: 17.0021.00

mode: Likely

Rainy with a high near 47. Windy , with an east wind between 5 and 15 mph.
Each row in the table contains a different weather-related event. The first row talks about temperature, the second one about wind direction, etc. Different event types instantiate different fields.
For example, Temperature has four fields, time, min, mean, and max. Fields in turn have values,
which can be either numbers (e.g., 47 degrees Fahrenheit for the event Temperature), or words (e.g.,
Likely or Slight Chance for the event Chance of Rain).
More specifically, you should read the above table as follows. For Temperature, the field time
and its value 17.00-06.00(+1 day) refers to temperatures measured between 5pm and 6am of the
following day. The minimum temperature recorded for that time period is 30 degrees Fahrenheit
(field min), the maximum is 47 degrees (field max) and on average the temperature is 40 degrees
(field mean). For the same time period, the wind will blow from a south east direction (the mode of
Wind Direction is SE). 2550% of the sky will be covered with clouds (see field percent with value
25-50 in Cloud Sky Cover), which may be interpreted as a slightly cloudy outlook. Finally, from
5pm to 9pm it is likely to rain, as indicated by the mode field and its value Likely for the Chance
of Rain event.
Note that all temperature values are in the Fahrenheit scale. The Fahrenheit scale is an alternative
temperature scale to Celsius, proposed in 1724 by the physicist Daniel Gabriel Fahrenheit. The
formula that converts Fahrenheit degrees to Celsius is [F] = [C]  59 + 32. So, for instance, 1 C =
30 F. Also note, the measure of speed used throughout the experiment is miles per hour, mph for
short.
All natural language translations have been generated by a computer program. Your task is to
rate the translations on two dimensions, namely Fluency and Semantic Correctness on a scale from
340

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

1 to 5. As far as Fluency is concerned, you should judge whether the translation is grammatical and
in well-formed English or just gibberish. If the translation is grammatical, then you should rate it
high in terms of fluency. If there is a lot of repetition in the translation or if it seems like word salad,
then you should give it a low number.
Semantic Correctness refers to the meaning conveyed by the translation and whether it corresponds to what is reported in the tabular data. In other words, does the translation convey the same
content as the table or not? If the translation has nothing to do with the categories, fields or values
described in the table, you should probably give it a low number for Semantic Correctness. If the
translation captures most of the information listed in the table, then you should give it a high number. Bear in mind that slight numerical deviations are normal and should not be penalized (e.g., it is
common for weather forecasters to round wind speed values to the closest 5, i.e., 50 mph instead
of 47 mph).
A.2 Rating Examples
In Example 1, you would probably give the translation a high score for Fluency (e.g., 4 or 5), since
it is coherent and does not contain any grammatical errors. However, you should give it a low
score for Semantic Correctness (e.g., 13), because it conveys information that is not in the table.
For example, windy and wind between 5 and 15 mph  both relate to wind speed but are not
mentioned in the table. Let us now consider the following example:
Example 2
Category

Fields

Temperature

time: 17.0006.00(+1 day) min: 40

mean: 45 max: 50

Wind Direction time: 17.0006.00(+1 day) mode: S
Wind Speed

time: 17.00 06.00(+1 day) min: 5

mean: 7 max: 15

Cloud Sky Cover time: 17.0006.00(+1 day) percent: 025
Sunny, with a low around 40. South wind between 5 and 15 mph.
Here, you should give the translation high scores on both dimensions, namely Fluency and Semantic Correctness. The text is grammatical and succinctly describes the content of the table. For
example, 4 or 5 would be appropriate numbers.
Example 3
Category

Fields

Temperature

time: 17.0006.00(+1 day) min: 30

mean: 40 max:47

Wind Direction time: 17.0006.00(+1 day) mode: ESE
Around 40. Around 40. Around 40. East wind.
341

fiKONSTAS & L APATA

In example 3, the translation scores poorly on Fluency and Semantic Correctness. The text has
many repetitions and there is no clear correspondence between the translation and the table. around
40  probably refers to the temperature, but it is not at all clear from the context of the text. east
wind  again refers to wind direction, but it is missing a verb or a preposition that would relate it to
the weather outlook. Appropriate scores for both dimensions would be 1 or 2.
Finally, while judging the translation pay attention to the values of the fields in the table in
addition to the event categories. For example, you may have an event Chance of Rain with a value
None in the mode field. This means that it is not likely to rain, and you should penalize any mention
of rain in the text, unless there is another event Chance of Rain for a different time period with a
different value in the mode field.
A.3 Rating Procedure
Before you start the experiment below you will be asked to enter your personal details. Next, you
will be presented with 15 table-translation pairs to evaluate in the manner described above. You will
be shown one pair at a time. Once you finish with your rating, click the button at the bottom right
to advance to the next response.
Things to remember:
 If you are unsure how to rate a translation, click on the top right of your window the Help
link. You may also leave it open during the course of the experiment as a reference.
 Higher numbers represent a positive opinion of the translation and lower numbers a negative
one.
 Do not spend too long analyzing the translations; you should be able to rate them once you
have read them for the first time.
 There is no right or wrong answer, so use your own judgment when rating each translation.
A.4 Personal Details
As part of the experiment we will ask you for a couple of personal details. This information will
be treated confidentially and will not be made available to a third party. In addition, none of your
responses will be associated with your name in any way. We will ask you to supply the following
information.
 Your name and email address.
 Your age and sex.
 To specify, under Language Region, the place (city, region/state/province, country) where
you have learnt your first language.
 To enter the code provided at the end of the experiment into the Mechanical Turk HIT.
342

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

References
Amazon Mechanical Turk (2012). Retrieved from https://www.mturk.com..
Angeli, G., Liang, P., & Klein, D. (2010). A simple domain-independent probabilistic approach
to generation. In Proceedings of the 2010 Conference on Empirical Methods in Natural
Language Processing, pp. 502512, Cambridge, MA.
Banko, M., Mittal, V. O., & Witbrock, M. J. (2000). Headline generation based on statistical translation. In Proceedings of Association for Computational Linguistics, pp. 318325, Hong Kong.
Barzilay, R., & Lapata, M. (2005). Collective content selection for concept-to-text generation. In
Proceedings of Human Language Technology and Empirical Methods in Natural Language
Processing, pp. 331338, Vancouver, British Columbia.
Belz, A. (2008). Automatic generation of weather forecast texts using comprehensive probabilistic
generation-space models. Natural Language Engineering, 14(4), 431455.
Charniak, E., & Johnson, M. (2005). Coarse-to-fine n-best parsing and maxent discriminative
reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational
Linguistics, pp. 173180, Ann Arbor, Michigan.
Chen, D. L., & Mooney, R. J. (2008). Learning to sportscast: A test of grounded language acquisition. In Proceedings of International Conference on Machine Learning, pp. 128135,
Helsinki, Finland.
Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33(2), 201
228.
Collins, M. (2002). Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proceedings of the 2002 Conference on Empirical
Methods in Natural Language Processing, pp. 18, Philadelphia, Pennsylvania.
Dahl, D. A., Bates, M., Brown, M., Fisher, W., Hunicke-Smith, K., Pallett, D., Pao, C., Rudnicky,
A., & Shriberg, E. (1994). Expanding the scope of the ATIS task: the ATIS-3 corpus. In
Proceedings of the Workshop on Human Language Technology, pp. 4348, Plainsboro, New
Jersey.
Dale, R., Geldof, S., & Prost, J.-P. (2003). Coral: Using natural language generation for navigational
assistance. In Proceedings of the 26th Australasian Computer Science Conference, pp. 3544,
Adelaide, Australia.
de Gispert, A., Iglesias, G., Blackwood, G., Banga, E. R., & Byrne, W. (2010). Hierarchical phrasebased translation with weighted finite-state transducers and shallow-n grammars. Computational Linguistics, 36(3), 505533.
Duboue, P. A., & McKeown, K. R. (2002). Content planner construction via evolutionary algorithms
and a corpus-based fitness function. In Proceedings of International Natural Language Generation, pp. 8996, Ramapo Mountains, NY.
Gallo, G., Longo, G., Pallottino, S., & Nguyen, S. (1993). Directed hypergraphs and applications.
Discrete Applied Mathematics, 42, 177201.
Goldberg, E., Driedger, N., & Kittredge, R. (1994). Using natural-language processing to produce
weather forecasts. IEEE Expert, 9(2), 4553.
343

fiKONSTAS & L APATA

Good, I. J. (1953). The population frequencies of species and the estimation of population parameters. Biometrika, 40(3/4), pp. 237264.
Goodman, J. (1999). Semiring parsing. Computational Linguistics, 25(4), 573605.
Green, N. (2006). Generation of biomedical arguments for lay readers. In Proceedings of the 5th
International Natural Language Generation Conference, pp. 114121, Sydney, Australia.
Huang, L. (2008). Forest reranking: Discriminative parsing with non-local features. In Proceedings
of ACL-08: HLT, pp. 586594, Columbus, Ohio.
Huang, L., & Chiang, D. (2005). Better k-best parsing. In Proceedings of the 9th International
Workshop on Parsing Technology, pp. 5364, Vancouver, British Columbia.
Huang, L., & Chiang, D. (2007). Forest rescoring: Faster decoding with integrated language models.
In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,
pp. 144151, Prague, Czech Republic.
Iglesias, G., Allauzen, C., Byrne, W., de Gispert, A., & Riley, M. (2011). Hierarchical phrase-based
translation representations. In Proceedings of the 2011 Conference on Empirical Methods
in Natural Language Processing, pp. 13731383, Edinburgh, Scotland, UK. Association for
Computational Linguistics.
Kasami, T. (1965). An efficient recognition and syntax analysis algorithm for context-free languages. Tech. rep. AFCRL-65-758, Air Force Cambridge Research Lab, Bedford, Massachusetts.
Kim, J., & Mooney, R. (2010). Generative alignment and semantic parsing for learning from ambiguous supervision. In Proceedings of the 23rd Conference on Computational Linguistics,
pp. 543551, Beijing, China.
Klein, D., & Manning, C. (2004). Corpus-based induction of syntactic structure: Models of dependency and constituency. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, pp. 478485, Barcelona, Spain.
Klein, D., & Manning, C. D. (2001). Parsing and hypergraphs. In Proceedings of the 7th International Workshop on Parsing Technologies, pp. 123134, Beijing, China.
Konstas, I. (2013). ATIS dataset retrieved from http://homepages.inf.ed.ac.uk/ikonstas/
index.php?page=resources..
Konstas, I., & Lapata, M. (2012). Concept-to-text generation via discriminative reranking. In
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies, pp. 369378, Jeju, South Korea.
Li, Z., & Eisner, J. (2009). First- and second-order expectation semirings with applications to
minimum-risk training on translation forests. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing, pp. 4051, Suntec, Singapore.
Liang, P., Bouchard-Cote, A., Klein, D., & Taskar, B. (2006). An end-to-end discriminative approach to machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational
Linguistics, pp. 761768, Sydney, Australia.
344

fiA G LOBAL M ODEL FOR C ONCEPT- TO -T EXT G ENERATION

Liang, P., Jordan, M., & Klein, D. (2009). Learning semantic correspondences with less supervision.
In roceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language Processing of the AFNLP, pp. 9199,
Suntec, Singapore.
Lu, W., & Ng, H. T. (2011). A probabilistic forest-to-string model for language generation from
typed lambda calculus expressions. In Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, pp. 16111622, Edinburgh, Scotland, UK.
Marcus, M. P., Marcinkiewicz, M. A., & Santorini, B. (1993). Building a large annotated corpus of
English: the Penn treebank. Comput. Linguist., 19(2), 313330.
Nederhof, M.-J., & Satta, G. (2004). The language intersection problem for non-recursive contextfree grammars. Information and Computation, 192(2), 172  184.
Och, F. J. (2003). Minimum error rate training in statistical machine translation. In Proceedings
of the Annual Meeting on Association for Computational Linguistics, pp. 160167, Sapporo,
Japan.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for
Computational Linguistics, pp. 311318, Philadelphia, Pennsylvania.
Ratnaparkhi, A. (2002). Trainable approaches to surface natural language generation and their
application to conversational dialog systems. Computer Speech & Language, 16(3-4), 435
455.
Reiter, E., & Dale, R. (2000). Building natural language generation systems. Cambridge University
Press, New York, NY.
Reiter, E., Sripada, S., Hunter, J., & Davy, I. (2005a). Choosing words in computer-generated
weather forecasts. Artificial Intelligence, 167, 137169.
Reiter, E., Sripada, S., Hunter, J., Yu, J., & Davy, I. (2005b). Choosing words in computer-generated
weather forecasts. Artificial Intelligence, 167, 137169.
Shieber, S. M., Schabes, Y., & Pereira, F. C. N. (1995). Principles and implementation of deductive
parsing. Logic Programming, 24, 336.
Sripada, S. G., Reiter, E., Hunter, J., & Yu, J. (2003). Generating English summaries of time series
data using the gricean maxims. In Proceedings of the Ninth ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 187196. ACM Press.
Stolcke, A. (2002). SRILM  an extensible language modeling toolkit. In Hansen, J. H. L., &
Pellom, B. L. (Eds.), Proceedings of the 7th International Conference on Spoken Language
Processing, pp. 901904, Denver, Colorado. ISCA.
Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). Feature-rich part-of-speech tagging
with a cyclic dependency network. In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computational Linguistics on Human Language
Technology - Volume 1, pp. 173180, Edmonton, Canada.
Turner, R., Sripada, Y., & Reiter, E. (2009). Generating approximate geographic descriptions. In
Proceedings of the 12th European Workshop on Natural Language Generation, pp. 4249,
Athens, Greece.
345

fiKONSTAS & L APATA

Wong, Y. W., & Mooney, R. (2007). Generation by inverting a semantic parser that uses statistical
machine translation. In Proceedings of the Human Language Technology and the Conference
of the North American Chapter of the Association for Computational Linguistics, pp. 172
179, Rochester, NY.
Yandell, B. S. (1997). Practical Data Analysis for Designed Experiments. Chapman & Hall/CRC.
Younger, D. H. (1967). Recognition and parsing for context-free languages in time n3 . Information
and Control, 10(2), 189208.
Zettlemoyer, L., & Collins, M. (2007). Online learning of relaxed CCG grammars for parsing to
logical form. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural Language Learning, pp. 678687, Prague,
Czech Republic.

346

fiJournal of Artificial Intelligence Research 48 (2013) 115174

Submitted 11/12; published 10/13

Taming the Infinite Chase: Query Answering
under Expressive Relational Constraints
Andrea Cal

andrea@dcs.bbk.ac.uk

Department of Computer Science and Information Systems
University of London, Birkbeck College, UK

Georg Gottlob

georg.gottlob@cs.ox.ac.uk

Department of Computer Science
University of Oxford, UK

Michael Kifer

kifer@cs.stonybrook.edu

Department of Computer Science
Stony Brook University, USA

Abstract
The chase algorithm is a fundamental tool for query evaluation and for testing query
containment under tuple-generating dependencies (TGDs) and equality-generating dependencies (EGDs). So far, most of the research on this topic has focused on cases where the
chase procedure terminates. This paper introduces expressive classes of TGDs defined via
syntactic restrictions: guarded TGDs (GTGDs) and weakly guarded sets of TGDs (WGTGDs). For these classes, the chase procedure is not guaranteed to terminate and thus may
have an infinite outcome. Nevertheless, we prove that the problems of conjunctive-query
answering and query containment under such TGDs are decidable. We provide decision
procedures and tight complexity bounds for these problems. Then we show how EGDs
can be incorporated into our results by providing conditions under which EGDs do not
harmfully interact with TGDs and do not affect the decidability and complexity of query
answering. We show applications of the aforesaid classes of constraints to the problem of
answering conjunctive queries in F-Logic Lite, an object-oriented ontology language, and
in some tractable Description Logics.

1. Introduction
This paper studies a simple yet fundamental rule-based language for ontological reasoning
and query answering: the language of tuple-generating dependencies (TGDs). This formalism captures a wide variety of logics that so far were considered unrelated to each other:
the OWL-based languages EL (Baader, Brandt, & Lutz, 2005) and DL-Lite (Calvanese,
De Giacomo, Lembo, Lenzerini, & Rosati, 2007; Artale, Calvanese, Kontchakov, & Zakharyaschev, 2009) on the one hand and object-based languages like F-Logic Lite (Cal &
Kifer, 2006) on the other. The present paper is a significant extension of our earlier work
(Cal, Gottlob, & Kifer, 2008), which has since been applied in other contexts and gave rise
to the Datalog family (Cal, Gottlob, & Pieris, 2011) of ontology languages. The present
paper focuses on the fundamental complexity results underlying one of the key fragments
of this family. Subsequent work has focused on the study of various special cases of this
formalism (Cal, Gottlob, & Lukasiewicz, 2012a), their complexity, and extensions based on
other paradigms (Cal, Gottlob, & Pieris, 2012b).
c
2013
AI Access Foundation. All rights reserved.

fiCal, Gottlob & Kifer

Our work is also closely related to the work on query answering and query containment (Chandra & Merlin, 1977), which are central problems in database theory and knowledge representation and, in most cases, are reducible to each other. They are especially
interesting in the presence of integrity constraintsor dependencies, in database parlance.
In databases, query containment has been used for query optimization and schema integration (Aho, Sagiv, & Ullman, 1979; Johnson & Klug, 1984; Millstein, Levy, & Friedman,
2000), while in knowledge representation it is often used for object classification, schema
integration, service discovery, and more (Calvanese, De Giacomo, & Lenzerini, 2002; Li &
Horrocks, 2003).
A practically relevant instance of the containment problem was first studied by Johnson and Klug (1984) for functional and inclusion dependencies and later by Calvanese,
De Giacomo, and Lenzerini (1998). Several additional decidability results were obtained by
focusing on concrete applications. For instance, the work by Cal and Martinenghi (2010)
considers constraints arising from Entity-Relationship diagrams, while that by Cal and
Kifer (2006) considers constraints derived from a relevant subset of F-logic (Kifer, Lausen,
& Wu, 1995), called F-Logic Lite.
Some literature studies variants or subclasses of tuple-generating dependencies (TGDs)
for the purpose of reasoning and query answering. A TGD is a Horn-like rule with existentially-quantified variables in the head. Some early works on this subject dubbed the resulting
language Datalog with value invention (Mailharrow, 1998; Cabibbo, 1998). More formally,
a TGD XY(X, Y)  Z(X, Z) is a first-order formula, where (X, Y) and (X, Z)
are conjunctions of atoms, called body and head of the TGD, respectively. A TGD is satisfied by a relational instance B if whenever the body of the TGD is satisfied by B then
B also satisfies the head of the TGD. It is possible to enforce a TGD that is not satisfied
by adding new facts to B so that the head, and thus the TGD itself, will become satisfied.
These new facts will contain labeled null values (short: nulls) in the positions corresponding
to variables Z. Such nulls are similar to Skolem constants. The chase of a database D in
the presence of a set  of TGDs is the process of iterative enforcement of all dependencies
in , until a fixpoint is reached. The result of such a process, which we also call chase,
can be infinite and, in this case, this procedure cannot be used without modifications in
decision algorithms. Nevertheless, the result of a chase serves as a fundamental theoretical
tool for answering queries in the presence of TGDs (Cal, Lembo, & Rosati, 2003a; Fagin,
Kolaitis, Miller, & Popa, 2005) because it is representative of all models of D  .
In the present paper, we do not focus on a specific logical theory. Instead, we tackle
the common issue of the possibly non-terminating chase underlying several of the earlier
studies, including the works by Johnson and Klug (1984), by Cal and Martinenghi (2010),
and by Cal and Kifer (2006). All these works study constraints in the language of TGDs
and equality-generating dependencies (EGDs) using the chase technique, and all face the
problem that the chase procedure might generate an infinite result. We deal with this
problem in a much more general way by carving out a very large class of constraints for
which the infinite chase can be tamed, i.e., modified so that it would become a decision
procedure for query answering.
In Section 3, we define the notions of sets of guarded TGDs (GTGDs) and of weakly
guarded sets of TGDs (WGTGDs). A TGD is guarded if its body contains an atom called
116

fiTaming the Infinite Chase

guard that covers all variables occurring in the body. WGTGDs generalize guarded TGDs
by requiring guards to cover only the variables occurring at so-called affected positions
(predicate positions that may contain some labeled nulls generated during the chase). Note
that inclusion dependencies (or IDs) can be viewed as trivially guarded TGDs. The importance of guards lies in Theorem 3.5, which shows that there is a fixed set u of GTGDs plus
a single non-guarded TGD, such that query evaluation under u is undecidable. However,
we show that for WGTGDs the (possibly infinite) result of the chase has finite treewidth
(Theorem 3.14). We then use this result together with well-known results about the generalized tree-model property (Goncalves & Gradel, 2000; Gradel, 1999) to show that evaluating
Boolean conjunctive queries is decidable for WGTGDs (and thus also for GTGDs). Unfortunately, this result does not directly provide useful complexity bounds.
In Section 4, we show lower complexity bounds for conjunctive query answering under
weakly guarded sets of TGDs. We prove, by Turing machine simulations, that query evaluation under weakly guarded sets of TGDs is exptime-hard in case of a fixed set of TGDs,
and 2exptime-hard in case the TGDs are part of the input.
In Section 5, we address upper complexity bounds for query answering under weakly
guarded sets of TGDs. Let us first remark that showing D   |= Q is equivalent to
showing that the theory T = D    {Q} is unsatisfiable. Unfortunately, T is in general
not guarded because Q is not and because WGTGDs are generally non-guarded first-order
sentences (while GTGDs are). Therefore, we cannot (as one might think at first glance)
directly use known results on guarded logics (Goncalves & Gradel, 2000; Gradel, 1999) to
derive complexity results for query evaluation. We thus develop completely new algorithms
by which we prove that the problem in question is exptime-complete in case of bounded
predicate arities and, even in case the TGDs are fixed, 2exptime-complete in general.
In Section 6, we derive complexity results for reasoning with GTGDs. In the general
case, the complexity is as for WGTGDs but, interestingly, when reasoning with a fixed set
of dependencies (which is the usual setting in data exchange and in description logics), we
get much better results: evaluating Boolean queries is np-complete and is in ptime in case
the query is atomic. Recall that Boolean query evaluation is np-hard even in case of a
simple database without integrity constraints (Chandra & Merlin, 1977). Therefore, the
above np upper bound for general Boolean queries is optimal, i.e., there is no class of TGDs
for which query evaluation (or query containment) is more efficient.
In Section 7, we describe a semantic condition on weakly guarded sets of TGDs. We
prove that whenever a set of WGTGDs fulfills this condition, answering Boolean queries is
in np, and answering atomic queries, as well as queries of bounded treewidth, is in ptime.
Section 8 extends our results to the case of TGDs with multiple-atom heads. The
extension is trivial for all cases except for the case of bounded predicate arity.
Section 9 deals with equality generating dependencies (EGDs), a generalization of functional dependencies. Unfortunately, as shown in works by Chandra and Vardi (1985),
Mitchell (1983), Johnson and Klug (1984), Koch (2002), and Cal et al. (2003a), query answering and many other problems become undecidable in case we admit both TGDs and
EGDs. It remains undecidable even if we mix the simplest class of guarded TGDs, namely,
inclusion dependencies, with the simplest type of EGDs, namely functional dependencies,
and even key dependencies (Chandra & Vardi, 1985; Mitchell, 1983; Johnson & Klug, 1984;
Cal et al., 2003a). In Section 9, we present a sufficient semantic condition for decidabil117

fiCal, Gottlob & Kifer

BCQ type
GTGDs WGTGDs
general
2exptime 2exptime
atomic or fixed 2exptime 2exptime
Query answering for variable TGDs.
BCQ type
GTGDs
general
np
atomic or fixed
ptime
Query answering for fixed

WGTGDs
exptime
exptime
TGDs.

BCQ type
GTGDs WGTGDs
general
exptime
exptime
atomic or fixed exptime
exptime
Query answering for fixed predicate arity.
Figure 1: Summary of results. All complexity bounds are tight.
ity of query-answering under sets of TGDs and general EGDs. We call EGDs innocuous
when, roughly speaking, their application (i.e., enforcement) does not introduce new atoms,
but only eliminates atoms. We show that innocuous EGDs can be essentially ignored for
conjunctive query evaluation and query containment testing.
The TGD-based ontology languages in this paper are part of the larger family of ontology
languages called Datalog (Cal et al., 2011). Our results subsume the main decidability
and np-complexity result by Johnson and Klug (1984), the decidability and complexity
results on F-Logic Lite by Cal and Kifer (2006), and those on DL-Lite as special cases. In
fact, Section 10 shows that our results are even more general than that.
The complexity results of this paper, together with some of their immediate consequences, are summarized in Figure 1, where all complexity bounds are tight. Notice that
the complexity in the case of fixed queries and fixed TGDs is the so-called data complexity,
i.e., the complexity with respect to the data only, which is of particular interest in database
applications. The complexity for variable Boolean conjunctive queries (BCQs) and variable
TGDs is called combined complexity. It is easy to see (but we will not prove it formally
for all classes) that all complexity results for atomic or fixed queries extend to queries
of bounded width, where by width we mean treewidth or even hypertree width (Gottlob,
Leone, & Scarcello, 2002)see also the works by Adler, Gottlob, and Grohe (2007), and
by Gottlob, Leone, and Scarcello (2001).

2. Preliminaries
In this section we define the basic notions that we use throughout the paper.
2.1 Relations, Instances and Queries
A relational schema R is a set of relational predicates, each having an aritya non-negative
integer that represents the number of arguments the predicate takes. We write r/n to say
118

fiTaming the Infinite Chase

that a relational predicate r has arity n. Given an n-ary predicate r  R, a position r[k],
where 1 6 k 6 n, refers to the k-th argument of r. We will assume an underlying relational
schema R and postulate that all queries and constraints use only the predicates in R. The
schema R will sometimes be omitted when it is clear from the context or is immaterial.
We introduce the following pairwise disjoint sets of symbols: (i) A (possibly infinite) set
 of data constants, which constitute the normal domain of the databases over the schema
R; (ii) a set N of labeled nulls, i.e., fresh Skolem constants; and (iii) an infinite set V of
variables, which are used in queries and constraints. Different constants represent different
values (unique name assumption), while different nulls may represent the same value. We
also assume a lexicographic order on   N , with every labeled null in N following all
constant symbols in . Sets of variables (or sequences, when the order is relevant) will
be denoted by X, i.e., X = X1 , . . . , Xk , for some k. The notation X is a shorthand for
X1 . . . Xk , and similarly for X.
An instance of a relational predicate r/n is a (possibly infinite) set of atomic formulas (atoms) of the form r(c1 , . . . , cn ), where {c1 , . . . , cn }    N . Such atoms are also
called facts. When the fact r(c1 , . . . , cn ) is true, we say that the tuple hc1 , . . . , cn i belongs
to the instance of r (or just that it is in r, if confusion does not arise). An instance of
the relational schema R = {r1 , . . . , rm } is the set comprised of the instances of r1 , . . . , rm .
When instances are treated as first-order formulas, each labeled null is viewed as an existential variable with the same name, and relational instances with nulls correspond to
a conjunction of atoms preceded by the existential quantification of all the nulls. For instance, {r(a, z1 , z2 , z1 ), s(b, z2 , z3 )}, where {z1 , z2 , z3 }  N and {a, b}  , is expressed as
z1 z2 z3 r(a, z1 , z2 , z1 )  s(b, z2 , z3 ). In the following, we will omit these quantifiers.
A fact r(c1 , . . . , cn ) is said to be ground if ci   for all i  {1, . . . , n}. In such a case,
also the tuple hc1 , . . . , cn i is said to be ground. A relation or schema instance all of whose
facts are ground is said to be ground, and a ground instance of R is also called a database.
If A is a sequence of atoms ha1 , . . . , ak i or a conjunction of atoms a1  . . .  ak , we use
atoms(A) to denote the set of the atoms in A: atoms(A) = {a1 , . . . , ak }. Given a (ground or
non-ground) atom a, the domain of a, denoted by dom(a), is the set of all values (variables,
constants orSlabeled nulls) that appear as arguments in a. If A is a set of atoms, we define
dom(A) = aA dom(a). If A is a sequence or a conjunction of atoms then we define
dom(A) = dom(atoms(A)). If A is an atom, a set, a sequence, or a conjunction of atoms,
we write vars(A) to denote the set of variables in A.
Given an instance B of a relational schema R, the Herbrand Base of B, denoted HB (B),
is the set of all atoms that can be formed using the predicate symbols of R and arguments
in dom(B). Notice that this is an extension of the classical notion of Herbrand Base, which
includes ground atoms only.
An n-ary conjunctive query (CQ) over R is a formula of the form q(X1 , . . . , Xn )  (X),
where q is a predicate not appearing in R, all the variables X1 , . . . , Xn appear in X, and
(X), called the body of the query, is a conjunction of atoms constructed with predicates
from R. The arity of a query is the arity of its head predicate q. If q has arity 0, then the
conjunctive query is called Boolean (BCQ). For BCQs, it is convenient to drop the head
predicate and simply view the query as the set of atoms in (X). If not stated otherwise,
we assume that queries contain no constants, since constants can be eliminated from queries
by a simple polynomial time transformation. We will also sometimes refer to conjunctive
119

fiCal, Gottlob & Kifer

queries by just queries. The size of a conjunctive query Q is denoted by |Q|; it represents
the number of atoms in Q.
2.2 Homomorphisms
A mapping from a set of symbols S1 to another set of symbols S2 can be seen as a function
 : S1  S2 defined as follows: (i)  (the empty mapping) is a mapping; (ii) if  is a
mapping, then   {X  Y }, where X  S1 and Y  S2 is a mapping if  does not already
contain some X  Y  with Y 6= Y  . If X  Y is in a mapping , we write (X) = Y .
The notion of a mapping is naturally extended to atoms as follows. If a = r(c1 , . . . , cn )
is an atom and  a mapping, we define (a) = r((c1 ), . . . , (cn )). For a set of atoms,
A = {a1 , . . . , am }, (A) = {(a1 ), . . . , (am )}. The set of atoms (A) is also called image
of A with respect to . For a conjunction of atoms C = a1  . . .  am , (C) is a shorthand
for (atoms(C)), that is, (C) = {(a1 ), . . . , (am )}.
A homomorphism from a set of atoms A1 to another set of atoms A2 , with dom(A1 
A2 )    N  V is a mapping  from dom(A1 ) to dom(A2 ) such that the following
conditions hold: (1) if c   then (c) = c; (2) (A1 )  A2 , i.e., if an atom, a, is in A1 ,
then the atom (a) is in A2 . In this case, we will say that A1 maps to A2 via .
The answer to a conjunctive query Q of the form q(X1 , . . . , Xn )  (X) over an instance
B of R, denoted by Q(B), is defined as follows: a tuple t  (  N )n , is in Q(B) iff there
is a homomorphism  that maps (X) to atoms of B, and hX1 , . . . , Xn i to t. In this case,
by abuse of notation, we also write q(t)  Q(B). A Boolean conjunctive query Q has a
positive answer on B iff hi (the tuple with no elements) is in Q(B); otherwise, it is said to
have a negative answer.
2.3 Relational Dependencies
We now define the main type of dependencies used in this paper, the tuple-generating
dependencies, or TGDs.
Definition 2.1. Given a relational schema R, a TGD  over R is a first-order formula of
the form XY(X, Y)  Z(X, Z), where (X, Y) and (X, Z) are conjunctions of
atoms over R, called body and head of the TGD, respectively; they are denoted by body()
and head (). Such a dependency is satisfied in an instance B of R if, whenever there is a
homomorphism h that maps the atoms of (X, Y) to atoms of B, there exists an extension
h2 of h (i.e., h2  h) that maps the atoms of (X, Z) to atoms of B.
To simplify the notation, we will usually omit the universal quantifiers in TGDs. We
will also sometimes call TGDs rules because of the implication symbol in them. Notice
that, in general, constants of  can appear not only in the body, but also in the heads
of TGDs. For simplicity and without loss of generality, we assume that all constants that
appear in the the head of a TGDs also appear in the body of the same TGD.
The symbol |= will be used henceforth for the usual logical entailment, where sets of
atoms and TGDs are viewed as first-order theories. For such theories, we do not restrict
ourselves to finite models: we consider arbitrary models that could be finite or infinite. This
aspect is further discussed in Section 11.
120

fiTaming the Infinite Chase

2.4 Query Answering and Containment under TGDs
We now define the notion of query answering under TGDs. A similar notion is used in data
exchange (Fagin et al., 2005; Gottlob & Nash, 2006) and in query answering over incomplete
data (Cal et al., 2003a). Given a database that does not satisfy all the constraints in ,
we first define the set of completions (or repairssee Arenas, Bertossi, & Chomicki, 1999)
of that database, which we call solutions.
Definition 2.2. Consider a relational schema R, a set of TGDs , and a database D for
R. The set of instances {B | B |= D  } is called the set of solutions of D given , and
is denoted by sol(D, ).
The following is the definition of the problem, which we denote by CQAns, of answering
conjunctive queries under TGDs. The answers defined here are also referred to as certain
answers (see Fagin et al., 2005).
Definition 2.3. Consider a relational schema R, a set of TGDs , a database D for R,
and a conjunctive query Q on R. The answer to a conjunctive query Q on D given ,
denoted by ans(Q, D, ), is the set of tuples t such that for every B  sol(D, ), t  Q(B)
holds.
Notice that the components of t in the above definition are necessarily constants from
. When t  ans(Q, D, ), we also write D    {Q} |= q(t), where Q is represented as a
rule body(Q)  q(X).
Containment of queries over relational databases has long been considered a fundamental
problem in query optimization, especially query containment under constraints such as
TGDs. Below we formally define this problem, which we call CQCont.
Definition 2.4. Consider a relational schema R, a set  of TGDs on R, and two conjunctive
queries Q1 , Q2 expressed over R. We say that Q1 is contained in Q2 under , denoted by
Q1  Q2 , if for every instance B for R such that B |=  we have Q1 (B) is a subset of
Q2 (B).
2.5 The Chase
The chase was introduced as a procedure for testing implication of dependencies (Maier,
Mendelzon, & Sagiv, 1979), but later also employed for checking query containment (Johnson & Klug, 1984) and query answering on incomplete data under relational dependencies (Cal et al., 2003a). Informally, the chase procedure is a process of repairing a database
with respect to a set of dependencies, so that the result of the chase satisfies the dependencies. By chase we may refer either to the chase procedure or to its output. The chase
works on a database through the so-called TGD chase rule, which defines the result of the
applications of a TGD and comes in two flavors: oblivious and restricted.
Definition 2.5. [Oblivious Applicability] Consider an instance B of a schema R, and a
TGD  = (X, Y)  Z (X, Z) over R. We say that  is obliviously applicable to B if
there exists a homomorphism h such that h((X, Y))  B.
121

fiCal, Gottlob & Kifer

Definition 2.6. [Restricted Applicability] Consider an instance B of a schema R, and a
TGD  = (X, Y)  Z (X, Z) over R. We say that  is restrictively applicable to B if
there exists a homomorphism h such that h((X, Y))  B, but there is no extension h of
h|X such that h ((X, Z))  B.1
The oblivious form of applicability is called this way because it forgets to check
whether the TGD is already satisfied. In contrast, a TGD is restrictively applicable only if
it is not already satisfied.
Definition 2.7. [TGD Chase Rule] Let  be a TGD of the form (X, Y)  Z (X, Z)
and suppose that it is obliviously (resp., restrictively) applicable to an instance B via a
homomorphism h. Let h be an extension of h|X such that, for each Z  Z, h (Z) is a fresh
labeled null of N not occurring in B, and following lexicographically all those in B. The
result of the oblivious (resp., restricted ) application of  on B with h is B  = Bh ((X, Z)).
,h

,h

We write B O B  (resp., B R B  ) to denote that B  is obtained from B through a
single oblivious (resp., restricted) chase step.
The TGD chase rule, defined above, is the basic building block to construct the chase of
a database under a set of TGDs. Depending on the notion of applicability in useoblivious
or restrictedwe get the oblivious or the restricted chase. The formal definition of the
chase is given below.
Definition 2.8. [Oblivious and Restricted Chase] Let D be a database and  a set of
TGDs. An oblivious (resp., restricted) chase sequence of D with respect to  is a sequence
i ,hi

of instances B0 , B1 , B2 , . . . such that B0 = D and, for all i > 0, Bi  O Bi+1 (resp.,
i ,hi

Bi  R Bi+1 ) and i  . We also assume that in any chase sequence the same pair
hi , hi i is never applied more than once. The oblivious (resp., restricted) chase of D with
respect to , denoted Ochase(D, ) (resp., Rchase(D, )), is defined as follows:
 A finite oblivious (resp., restricted) chase of D with respect to  is a finite oblivious
i ,hi

i ,hi

(resp., restricted) chase sequence B0 , . . . , Bm such that Bi  O Bi+1 (resp., Bi  R
Bi+1 ) for all 0 6 i < m, and there is no    such that its application yields an
instance B  6= Bm . We define Ochase(D, ) = Bm (resp., Rchase(D, ) = Bm ).
i ,hi

 An infinite oblivious (resp., restricted) chase sequence B0 , B1 , . . ., where Bi  O Bi+1
i ,hi

(resp., Bi  R Bi+1 ) for all i > 0, is fair if whenever a TGD  = (X, Y) 
Z (X, Z) of  is obliviously (resp., restrictedly) applicable to Bi with homomorphism h, then there exists an extension h of h|X and k > 0 such that h (head ()) 
Bk . An infinite oblivious chase of D with respect to  is a fair infinite chase sequence
i ,hi

i ,hi

B0 , B1 , . . . such that Bi  O Bi+1 (resp., Bi  R Bi+1 ) for all i > 0. In this case,
we define Ochase(D, ) = limi Bi (resp., Rchase(D, ) = limi Bi ).
It is easy to see that the chase can be infinite, if the sequence of applications of the chase
rule is infinite. We remark that the chase was defined for databases of ground tuples. However, the definition straightforwardly applies also to arbitrary instances, possibly containing
1. h|X denotes the restriction of h to the set of variables of X.

122

fiTaming the Infinite Chase

labeled nulls. We assume a fair deterministic strategy for constructing chase sequences. We
use Ochase [i] (D, ) (resp., Rchase [i] (D, )) to denote the result of the i-th step of the oblivious (resp., restricted) chase of D with respect to . Notice that Ochase [i] (D, ) (resp.,
Rchase [i] (D, )) is called the oblivious (resp., restricted) chase of D with respect to  up
to the derivation level i, as in the work by Cal et al. (2012a).
Example 2.9. In this example, we show an oblivious chase procedure. Consider the following set  = {1 , 2 , 3 , 4 } of TGDs.
1 :
2 :
3 :
4 :

r3 (X, Y )
r1 (X, Y )
r1 (X, Y ), r2 (Y )
r1 (X, Y )






r2 (X)
Z r3 (Y, Z)
Z r1 (Y, Z)
r2 (Y )

and let D = {r1 (a, b)}. The chase procedure adds to D the following sequence of atoms:
r3 (b, z1 ) via 2 , r2 (b) via 4 , r1 (b, z2 ) via 3 , r3 (z2 , z3 ) via 2 , r2 (z2 ) via 4 , and so on.
2.6 Query Answering and the Chase
The problems of query containment and answering under TGDs are closely related to each
other and to the notion of chase, as explained below.
Theorem 2.10 (see Nash, Deutsch, & Remmel, 2006). Consider a relational schema R, a
database D for R, a set  of TGDs on R, an n-ary conjunctive query Q with head-predicate
q, and an n-ary ground tuple t (with values in ). Then t  ans(Q, D, ) iff there exists a
homomorphism h such that h(body(Q))  Rchase(D, ) and h(head (Q)) = q(t).
Notice that the fact that h(body(Q))  Rchase(D, ) and h(head (Q)) = q(t) is equivalent to saying that q(t)  Q(Rchase(D, )), or that Rchase(D, )  {Q} |= q(t). The
result of Theorem 2.10 is important, and it holds because the (possibly infinite) restricted
chase is a universal solution (Fagin et al., 2005), i.e., a representative of all instances in
sol(D, ). More formally, a universal solution for D under  is a (possibly infinite) instance
U such that, for every instance B  sol(D, ), there exists a homomorphism that maps U
to B. In the work by Nash et al. (2006) it is shown that the chase constructed with respect
to TGDs is a universal solution.
A freezing homomorphism for a query is a homomorphism that maps every distinct
variable in the query into a distinct labeled null in N . The following well known result is
a slight extension of a result by Chandra and Merlin (1977).
Theorem 2.11. Consider a relational schema R, a set  of TGDs on R, and two conjunctive queries Q1 , Q2 on R. Then Q1  Q2 iff (head (Q1 ))  Q2 (Rchase((body(Q1 )), )
for some freezing homomorphism  for Q1 .
From this and the results by Johnson and Klug (1984) and by Nash et al. (2006), we
easily obtain the following result, which is considered folklore.
Corollary 2.12. The problems CQAns and CQCont are mutually logspace-reducible.
123

fiCal, Gottlob & Kifer

2.7 Oblivious vs. Restricted Chase
As observed by Johnson and Klug (1984) in the case of functional and inclusion dependencies, things are more complicated if the restricted chase is used instead of the oblivious
one, since applicability of a TGD depends on the presence of other atoms previously added
to the database by the chase. It is technically easier to use the oblivious chase and it can
be used in lieu of the restricted chase because, as we shall prove now, a result similar to
Theorem 2.10 holds for the oblivious chase, i.e., it is also universal. This result, to the best
of our knowledge, has never been explicitly stated before. For the sake of completeness, we
present a full proof here.
Theorem 2.13. Consider a set  of TGDs on a relational schema R, and let D be
a database on R. Then there exists a homomorphism  such that (Ochase(D, )) 
Rchase(D, ).
Proof. The proof is by induction on the number m of applications of the TGD chase rule
in the construction of the oblivious chase Ochase(D, ). We want to prove that, for all m
with m > 0, there is a homomorphism from Ochase [m] (D, ) to Rchase(D, ).
Base case. In the base case, where m = 0, no TGD rule has yet been applied, so
Ochase [0] (D, ) = D  Rchase(D, ) and the required homomorphism is simply the identity homomorphism 0 .
Inductive case. Assume we have applied the TGD chase rule m times and obtained
Ochase [m] (D, ). By the induction hypothesis, there exists a homomorphism m that maps
Ochase [m] (D, ) into Rchase(D, ). Consider the (m + 1)-th application of the TGD chase
rule, for a TGD of the form (X, Y)  Z(X, Z). By definition of applicability of TGDs,
there is a homomorphism O that maps (X, Y) to atoms of Ochase(D, ) and that it can
be suitably extended to another homomorphism, O , such that O maps each of the variables
in Z to a fresh null in N not already present in Ochase [m] (D, ). As a result of the application of this TGD, all atoms in O ((X, Z)) are added to Ochase [m] (D, ), thus obtaining
Ochase [m+1] (D, ). Consider the homomorphism R = m  O , which maps (X, Y) to
atoms of Rchase(D, ). Since Rchase(D, ) satisfies all the dependencies in  (and so does
Ochase(D, )), there is an extension R of R that maps (X, Z) to tuples of Rchase(D, ).
Denoting Z = Z1 , . . . , Zk , we now define m+1 = m  {O (Zi )  R (Zi )}16i6k . To complete the proof, we now need to show that m+1 is indeed a homomorphism. The addition of O (Zi )  R (Zi ), with 1 6 i 6 k, is compatible with m because none of the
O (Zi ) appears in m . Therefore m+1 is a well-defined mapping. Now, consider an atom
r(X, Z) in (X, Z). Then the atom O (r(X, Z)) is added to Ochase(D, ) in the (m+1)-th
step and m+1 (r(X, Y)) = m+1 (r(O (X), O (Z))) = r(m+1 (O (X), m+1 (O (Z)). Notice that m+1 (O (X)) = m+1 (O (X)) = R (X) = R (X), and m+1 (O (Z)) = R (Z).
Therefore, m+1 (r(X, Z)) = r(R (X), R (Z)) = R (r(X, Z)), which is in Rchase(D, ), by
construction.
The desired homomorphism from Ochase(D, ) to Rchase(D, ) is therefore
S
= 

.
i=0 i
Corollary 2.14. Given a set  of TGDs over a relational schema R and a database D for
R, Ochase(D, ) is a universal solution for D under .
124

fiTaming the Infinite Chase

Corollary 2.15. Given a Boolean query Q over a schema R, a database D for R, and a
set of TGDs , Ochase(D, ) |= Q if and only if Rchase(D, ) |= Q.
In the following, unless explicitly stated otherwise, chase will mean the oblivious chase,
and chase(D, ) will stand for Ochase(D, ).
2.8 Decision Problems
Recall that, by Theorem 2.10, D   |= Q iff chase(D, ) |= Q. Based on this, we define
two relevant decision problems and prove their logspace-equivalence.
Definition 2.16. The conjunctive query evaluation decision problem CQeval is defined as
follows. Given a conjunctive query Q with n-ary head predicate q, a set of TGDs , a
database D and a ground n-tuple t, decide whether t  ans(Q, D, ) or, equivalently,
whether chase(D, )  {Q} |= q(t).
Definition 2.17. The Boolean conjunctive query evaluation problem BCQeval is defined as
follows. Given a Boolean conjunctive query Q, a set of TGDs , and a database D, decide
whether chase(D, ) |= Q.
The following result is implicit in the work of Chandra and Merlin (1977).
Lemma 2.18. The problems CQeval and BCQeval are logspace-equivalent.
Proof. Notice that BCQeval can be trivially made into a special instance of CQeval, e.g., by
adding a propositional atom as head atom. It thus suffices to show that CQeval polynomially
reduces to BCQeval. Let hQ, D, , q(t)i be an instance of CQeval, where q/n is the head
predicate of Q and t is a ground n-tuple. Assume the head atom of Q is q(X1 , . . . , Xn )
and t = hc1 , . . . , cn i. Then define Q to be the Boolean conjunctive query whose body is
body(Q)  q  (X1 , . . . , Xn ), where q  is a fresh predicate symbol not occurring in D, Q, or 
It is easy to see that q(t)  Q(chase(D, )) iff chase(D  {q  (c1 , . . . , cn )}, ) |= Q .
By the above lemma and by the well-known equivalence of the problem of query containment under TGDs with the CQeval problem (Corollary 2.12), the three following problems
are logspace-equivalent: (1) CQ-eval under TGDs, (2) BCQeval under TGDs, (3) query
containment under TGDs. Henceforth, we will consider only one of these problems, the
BCQ-eval problem. By the above, all complexity results carry over to the other problems.
Dealing with multiple head-atoms. It turns out that dealing with multiple atoms in
TGD heads complicates the proof techniques, so we assume that all TGDs have a single
atom in their head. After proving our results for single-headed TGDs, we will extend these
results to the case of multiple-atom heads in Section 8.
2.9 Tree Decomposition and Related Notions
We now introduce the required notions about tree decompositions. A hypergraph is a pair
H = hV, Hi, where V is the set of nodes and H  2V . The elements of H are thus subsets
of V ; they are called hyperedges. The Gaifman graph of a hypergraph H = hV, Hi, denoted
125

fiCal, Gottlob & Kifer

by GH , is an undirected graph where V is the set of nodes and an edge (v1 , v2 ) is in the
graph if v1 and v2 jointly occur in some hyperedge in H.
Given a graph G = hV, Ei, a tree decomposition of G is a pair hT, i, where T = hN, Ai
is a tree, and  a labeling function  : N  2V such that:
S
(i) for all v  V there is n  N such that v  (n); that is, (N ) = nN (n) = V ;
(ii) for every edge e = (v1 , v2 )  E there is n  N such that (n)  {v1 , v2 };
(iii) for every v  V , the set {n  N | v  (n)} induces a connected subtree in T .
The width of a tree decomposition hT, i is the integer value max{|(n)|  1 | n  N }.
The treewidth of a graph G = hV, Ei, denoted by tw(G), is the minimum width of all tree
decompositions of G. Given a hypergraph H, its treewidth tw(H) is defined as the treewidth
of its Gaifman graph: tw(H) = tw(GH ). Notice that the notion of treewidth immediately
extends to relational structures.

3. Guarded and Weakly-Guarded TGDs: Decidability Issues
This section introduces guarded TGDs (GTGDs) and weakly guarded sets of TGDs (WGTGDs), which enjoy several useful properties. In particular, we show that query answering
under these TGDs is decidable.
Definition 3.1. Given a TGD  of the form (X, Y)  (X, Z), we say that  is a (fully)
guarded TGD (GTGD) if there exists an atom in the body, called a guard, that contains all
the universally quantified variables of , i.e., all the variables X, Y that occur in (X, Y).
To define weakly guarded sets of TGDs, we first give the notion of an affected position
in a predicate of a relational schema, given a set of TGDs . Intuitively, a position  is
affected in a set of TGDs  if there exists a database D such that a labeled null appears
in some atom of chase(D, ) at position . The importance of affected positions for our
definitions is that no labeled null can appear in non-affected positions. We define this notion
below.
Definition 3.2. Given a relational schema R and a set of TGDs  over R, a position  of
a predicate p of R is affected with respect to  if either:
 (base case) for some   , an existentially quantified variable appears in  in head (),
or
 (inductive case) for some   , the variable appearing at position  in head () also
appears in body(), and only at affected positions.
Example 3.3. Consider the following set of TGDs:
1 : p1 (X, Y ), p2 (X, Y )  Z p2 (Y, Z)
2 : p2 (X, Y ), p2 (W, X)  p1 (Y, X)
Notice that p2 [2] is affected since Z is existentially quantified in 1 . The variable Y in 1
appears in p2 [2] (which is an affected position) and also in p1 [2] (which is not an affected
position). Therefore Y in 1 does not make the position p2 [1] an affected one. Similarly,
126

fiTaming the Infinite Chase

in 2 , X appears in the affected position p2 [2] and also in the non-affected position p2 [1].
Therefore, p1 [2] is not affected. On the other hand, Y in 2 appears in p2 [2] and nowhere
else. Since we have already established that p2 [2] is an affected position, this makes p1 [1]
also an affected position.
Definition 3.4. Consider a set of TGDs  on a schema R. A TGD    of the form
(X, Y)   (X, Z) is said to be weakly guarded with respect to  (W GT GD) if there
is an atom in body(), called a weak guard, that contains all the universally quantified
variables of  that appear in affected positions with respect to  and do not also appear
in non-affected positions with respect to . The set  is said to be a weakly guarded set of
TGDs if each TGD    is weakly guarded with respect to .
A GTGD or WGTGD may have more than one guard. In such a case, we will pick a
lexicographically first guard or use some other criterion for fixing the guard of a rule. The
actual choice will not affect our proofs and results.
The following theorem shows the undecidability of conjunctive query answering under
TGDs. This result, in its general form, follows from undecidability results for TGD implication (see Beeri & Vardi, 1981; Chandra, Lewis, & Makowsky, 1981b). We show here
that the CQ answering problem remains undecidable even in case of a fixed set  of singleheaded TGDs with a single non-guarded rule, and a ground atom as query. Our proof is
from first principles as it reduces the well-known halting problem for Turing machines to
query-answering under TGDs. More recently, Baget, Leclere, Mugnier, and Salvat (2011a)
showed that CQ answering is undecidable also in case  contains a single TGD, which,
however, contains multiple atoms in its head.
Theorem 3.5. There exists a fixed atomic BCQ Q and a fixed set of TGDs u , where all
TGDs in u are guarded except one, such that it is undecidable to determine whether for a
database D, D  u |= Q or, equivalently, whether chase(D, u ) |= Q.
Proof. The proof hinges on the observation that, with appropriate input facts D, using a
fixed set of TGDs that consists of guarded TGDs and a single unguarded TGD, it is possible
to force an infinite grid to appear in chase(D, u ). By a further set of guarded rules, one
can then easily simulate a deterministic universal Turing machine (TM) M, which executes
every deterministic TM with an empty input tape, whose transition table is specified in
the database D. This is done by using the infinite grid, where the i-th horizontal line of
the grid represents the tape content at instant i. We assume that transitions of the Turing
machine M are encoded into a relation trans of D, where for example, the ground atom
trans(s1 , a1 , s2 , a2 , right) means if the current state is s1 and symbol a1 is read, then switch
to state s2 , write a2 , and move to the right.
We show how the infinite grid is defined. Let D contain (among other initialization
atoms that specify the initial configuration of M) the atom index (0), which defines the
initial point of the grid. Also, we make use of three constants right, left, stay for encoding
the three types of moves. Consider the following TGDs:
index (X)  Y next(X, Y )
next(X, Y )  index (Y )
trans(T), next(X1 , X2 ), next(Y1 , Y2 )  grid (T, X1 , Y1 , X2 , Y2 )
127

fiCal, Gottlob & Kifer

where T stands for the sequence of argument variables S1 , A1 , S2 , A2 , M , as appropriate
for the predicate trans. Note that only the last of these three TGDs is non-guarded. The
above TGDs define an infinite grid whose points have co-ordinates X and Y (horizontal
and vertical, respectively) and where for each point its horizontal and vertical successors
are also encoded. In addition, each point appears together with each possible transition
rule. It is not hard to see that we can simulate the progress of our Turing machine M using
suitable initialization atoms in D and guarded TGDs. To this end, we need additional
predicates cursor (Y, X), meaning that the cursor is in position X at time Y , state(Y, S),
expressing that M is in state S at time Y , and content(X, Y, A), expressing that at time
Y , the content of position X in the tape is A. The following rule encodes the behavior of
M on all transition rules that move the cursor to the right:
grid (S1 , A1 , S2 , A2 , right, X1 , Y1 , X2 , Y2 ),
cursor (Y1 , X1 ), state(Y1 , S1 ), content(X1 , Y1 , A1 ) 
cursor (Y2 , X2 ), content(X1 , Y2 , A2 ), state(Y2 , S2 ), mark (Y1 , X1 )
Such a rule has also obvious sibling rules for left and stay moves. For the sake of
brevity only, the above rule contains multiple atoms in the head. This is not a problem, as
such rules have no existentially quantified variables in the head. Therefore, each TGD with
multiple head-atoms can be replaced by an equivalent set of TGDs with single-atom heads
and identical bodies.
Notice that the mark predicate in the head marks the tape cell that is modified at
instant Y1 . We now need additional inertia rules, which ensure that all other positions
in the tape are not modified between Y1 and the following time instant Y2 . To this end,
we use two different markings: keep f for the tape positions that follow the one marked
with mark , and keep p for the preceding tape positions. In this way, we are able, by making
use of guarded rules only, to ensure that, at every instant Y1 , every tape cell X, such that
keep p (Y1 , X) or keep f (Y1 , X) is true, keeps the same symbol at the instant Y2 following
Y1 . The rules below then propagate the aforementioned markings forward and backwards,
respectively, starting from the marked tape positions.
mark (Y1 , X1 ), grid (T, X1 , Y1 , X2 , Y2 )  keep f (Y1 , X2 )
keep f (Y1 , X1 ), grid (T, X1 , Y1 , X2 , Y2 )  keep f (Y1 , X2 )
mark (Y1 , X2 ), grid (T, X1 , Y1 , X2 , Y2 )  keep p (Y1 , X1 )
keep p (Y1 , X2 ), grid (T, X1 , Y1 , X2 , Y2 )  keep p (Y1 , X1 )
We also have inertia rules for all a  {a1 , . . . , a , }, where {a1 , . . . , a , } is the tape alphabet:
keep f (Y1 , X1 ), grid (T, X1 , Y1 , X2 , Y2 ), content(X1 , Y1 , a)  content(X1 , Y2 , a)
keep p (Y1 , X1 ), grid (T, X1 , Y1 , X2 , Y2 ), content(X1 , Y1 , a)  content(X1 , Y2 , a)
Notice that we use the constant a instead of a variable in the above rules in order to have
the guardedness property. We therefore need two rules as above for every tape symbol, that
is, 2 + 2 inertia rules altogether.
Finally, we assume, without loss of generality, that our Turing machine M has a single
halting state s0 which is encoded by the atom halt(s0 ) in D. We then add a guarded
128

fiTaming the Infinite Chase

rule state(Y, S), halt(S)  stop. It is now clear that the machine halts iff chase(D, u ) |=
stop, i.e., iff D  u |= stop. We have thus reduced the halting problem to the problem
of answering atomic queries over a database under u . The latter problem is therefore
undecidable.
Definition 3.6. [Guarded chase forest, restricted GCF] Given a set of WGTGDs  and a
database D, the guarded chase forest (GCF) for D and , denoted gcf(D, ), is constructed
as follows.
(a) For each atom (fact) d in D, add a node labeled with d.
(b) For every node v labeled with a  chase(D, ) and for every atom b obtained from
a (and possibly other atoms) by a one-step application of a TGD   , if a is the
image of the guard of  then add one node v  labeled with b and an arc going from v
to v  .
Assuming the chase forest gcf(D, ) is built inductively, following precisely the strategy of
a fixed deterministic chase procedure, the set of all non-root nodes of the chase forest is
totally ordered by a relation  that reflects their order of generation. The restricted GCF
for D and , denoted rgcf(D, ), is obtained from gcf(D, ) by eliminating each subtree
rooted in a node w whose label is a duplicate of an earlier generated node. Thus, if v and
w are nodes labeled by the same atom, and v  w, w and all nodes of the subtree rooted in
w are eliminated from gcf(D, ) so as to obtain rgcf(D, ). Note that in rgcf(D, ) each
label occurs only once, therefore we can identify the nodes with their labels and say, for
instance, the node a instead of the node v labeled by a.
Example 3.7. Consider again Example 2.9 on page 123. The corresponding (infinite)
guarded chase forest is shown in Figure 2. Every edge from an a-node to a b-node is labeled
with the TGD whose application causes the introduction of b. Notice that some atoms (e.g.,
r2 (b) or r2 (z2 )) label more than one node in the forest. The nodes belonging also to the
restricted GCF are shaded in the figure.
r1 (a, b)
2
r3 (b, z1 )

4

3

r2 (b)

r1 (b, z2 )
2

1
r2 (b)

3

4

r3 (z2 , z3 )

r2 (z2 )

r1 (z2 , z4 )
2

1


r2 (z2 )

4


3


Figure 2: Chase forest for Example 3.7.
The goal of the following material is to show that, for weakly guarded sets  of TGDs, the
possibly infinite set of atoms chase(D, ) has finite treewidth (Lemma 3.13). This will then
be used to show the decidability of query-answering under WGTGDs (Theorem 3.14). As
a first step towards proving that chase(D, ) has finite treewidth, we generalize the notion
129

fiCal, Gottlob & Kifer

of acyclicity of an instance, and then point out the relationship between this notion and
treewidth. We will then show that chase(D, ) enjoys (a specific version of) our generalized
form of acyclicity (Lemma 3.11), from which the finite treewidth result immediately follows.
Definition 3.8. Let B be a (possibly infinite) instance for a schema R and let S  dom(B).
 An [S]-join forest hF, i of B is an undirected labeled forest F = hV, Ei (finite or
infinite), whose labeling function  : V  B is such that:
(1)  is an epimorphism, i.e., (V ) = B;
(2) F is [S]-connected, i.e., for each c  dom(B)  S, the set {v  V
dom((v))} induces a connected subtree in F .

|

c 

 We say that B is [S]-acyclic if B has an [S]-join forest.
Notice that we are dealing with a relational instance, but the above definition works for
any relational structure, including queries. Definition 3.8 generalizes the classical notion of
hypergraph acyclicity (Beeri, Fagin, Maier, Mendelzon, Ullman, & Yannakakis, 1981) of an
instance or of a query: an instance or a query, seen as a hypergraph, is hypergraph-acyclic
(which is the same as -acyclic according to Fagin, 1983) if and only if it is []-acyclic .
The following Lemma follows from the definitions of [S]-acyclicity.
Lemma 3.9. Given an instance B for a schema R, and a set S  dom(B), if B is [S]acyclic, then tw(B) 6 |S| + w, where w is the maximum predicate arity in R and tw(B) is
the treewidth of B.
Proof. By hypothesis, B is [S]-acyclic and therefore has an [S]-join forest hF, i, where
F = hV, Ei. A tree decomposition hT, i with T = hN, Ai, is constructed as follows. First,
we take N = V  {n0 }, where n0 is an auxiliary node. Let Vr  V be the set of nodes that
are roots in the [S]-join forest F and let Ar be the set of edges from n0 to each node in Vr .
We define A = E  Ar . The labeling function is defined as follows: (n0 ) = S, and for all
nodes v 6= n0 , (v) = dom((v))  S. We now show that hT, i is a tree decomposition.
Recalling the definition of tree decompositions in Section 2.9, (i) holds trivially because F
is a join forest and (V ) = B. As for (ii), we notice that edges in the Gaifman graph of B
are such that for each atom d = r(c1 , . . . , cm ) in B there is a clique among nodes c1 , . . . , cm .
Since for the same atom there exists v  V such that (v) = d and (v)  dom((v)), (ii)
holds immediately. Finally we consider connectedness. Let us take a value c appearing in
B as argument. If c  S, the set {v  N | c  (v)} is the entire N , by construction, so
connectedness holds. If c 6 S, the set {v  N | c  (v)} induces a connected subtree in F
and therefore in T , since (v) = (v)  S. Therefore, (iii) holds. Notice also that the width
of such a tree decomposition is at most |S| + w by construction.
Definition 3.10. Let D be a database for a schema R, and HB (D) be the Herbrand Base
of D as defined in Section 2. We define:
 chase  (D, ) = chase(D, )  HB (D), and
 chase + (D, ) = chase(D, )  chase  (D, )
130

fiTaming the Infinite Chase

In plain words, chase  (D, ) is the finite set of all null-free atoms in chase(D, ). In
contrast, chase + (D, ) may be infinite; it is the set of all atoms in chase(D, ) that have
at least one null as an argument. Note that chase  (D, )  chase + (D, ) = chase(D, )
and chase  (D, )  chase + (D, ) = .
Lemma 3.11. If  is a weakly guarded set of TGDs and D a database, then chase + (D, )
is [dom(D)]-acyclic, and so is therefore chase(D, ).
In order to prove this result, we resort to an auxiliary lemma.
Lemma 3.12. Let D be a database and  a weakly guarded set of TGDs. Let as be a node
of rgcf(D, ) where the null value   N is first introduced, and let af be a descendant
node of as in rgcf(D, ) that has  as an argument. Then,  appears in every node (=atom)
on the (unique) path from as to af .
Proof. Let a1 = as , a2 , . . . , an = af be the path from as to af . By the definition of affected
positions,  appears only in affected positions in the atoms in the chase. Suppose, to the
contrary, that  does not appear in some intermediate atom in the above path. Then,
there is i, 2 6 i 6 n  1, such that  does not appear in ai , but appears in ai+1 . Since 
appears only in affected positions, in order to be in ai+1 it must either appear in ai or to
be invented when ai+1 was added. The first case is ruled out by the assumption, and the
second is impossible because  was first introduced in a1 , not in ai+1 a contradiction.
We now come back to the proof of Lemma 3.11.
Proof. The proof is constructive, by exhibiting a [dom(D)]-join forest F = hV, Ei for
chase(D, ). We take F as rgcf(D, ) and define, for each atom d  rgcf(D, ), the
labeling function  for F as (d) = d. Since every atom of chase(D, ) is covered by its
corresponding node of F , it only remains to show that chase(D, ) is [dom(D)]-connected.
Take a pair of distinct atoms a1 , a2 in rgcf(D, ) that both have the same value c  N in an
argument. The atoms a1 and a2 must have a common ancestor a in rgcf(D, ) where c was
first invented: if they do not, the value c would have to be introduced twice in chase(D, ).
By Lemma 3.12, c appears in all atoms on the paths from a to a1 and from a to a2 . It thus
follows that the set {v  V | c  (v)} induces a connected subtree in F .
Lemma 3.13. If  is a weakly guarded set of TGDs and D a database for a schema R,
then tw(chase(D, )) 6 |dom(D)| + w, where w is the maximum predicate arity in R.
Proof. The claim follows from Lemmas 3.9 and 3.11.
Theorem 3.14. Given a relational schema R, a weakly guarded set of TGDs , a Boolean
conjunctive query Q, and a database D for R, the problem of checking whether D   |= Q,
or equivalently chase(D, ) |= Q, is decidable.
Proof (sketch). We first remind a key result of Courcelle (1990), that generalizes an earlier
result of Rabin (1969). Courcelles result states that the satisfiability problem is decidable
for classes of first-order theories (more generally, theories of monadic second-order logic)
131

fiCal, Gottlob & Kifer

that enjoy the finite treewidth model property. A class C of theories has the finite-treewidth
model property if for each satisfiable theory T  C it is possible to compute an integer f (T )
such that T has a model of treewidth at most f (T )see also the works by Goncalves and
Gradel (2000) and by Gradel (1999), where a more general property, called the generalized
tree-model property, is discussed. We apply this to prove our theorem.
Let Q be the universal sentence obtained by negating the existentially quantified conjunctive query Q. For all classes of TGDs, D   |= Q iff chase(D, ) |= Q iff D    Q
is unsatisfiable. Trivially, deciding whether D   |= Q is equivalent under Turing reductions to deciding whether D   6|= Q. The latter holds iff D    {Q} is satisfiable
or, equivalently, iff chase(D, ) is a model of Q which, in turn, holds iff chase(D, ) is a
model of D    {Q}. By Lemma 3.13, for WGTGDs, chase(D, ) has finite treewidth.
Our decision problem thus amounts to checking whether a theory belonging to a class C 
of first-order theories (of the form D    {Q}) is satisfiable, where it is guaranteed
that whenever a theory in this class is satisfiable, then it has a model of finite treewidth
(namely, chase(D, )), and where C  therefore enjoys the finite treewidth model property.
Decidability thus follows from Courcelles result.
Determining the precise complexity of query answering under sets of guarded and weakly
guarded sets of TGDs will require new techniques, which are the subject of the next sections.

4. Complexity: Lower Bounds
In this section we prove several lower bounds for the complexity of the decision problem of
answering Boolean conjunctive queries under guarded and weakly guarded sets of TGDs.
Theorem 4.1. The problem BCQeval under WGTGDs is exptime-hard in case the TGDs
are fixed. The same problem is 2exptime-hard when the predicate arity is not bounded.
Both hardness results also hold for fixed atomic ground queries.
Proof. We start with the exptime-hardness result for fixed WGTGD sets . It is wellknown that apspace (alternating pspace, see Chandra, Kozen, & Stockmeyer, 1981a)
equals exptime. Notice that there are apspace-hard languages that are accepted by alternating polynomial-space machines that use at most n worktape cells, where n is the input
size, and where the input is initially placed on the worktape. (This is well-known and can
be shown by trivial padding arguments). To prove our claim, it thus suffices to simulate the
behavior of such a restricted linear space (linspace) Alternating Turing Machine (ATM)
M on an input bit string I by means of a weakly guarded set of TGDs  and a database
D. Actually, we will show a stronger result: that a fixed set  of WGTGDs can simulate
a universal ATM that in turn simulates every linspace ATM that uses at most n tape
cells on every input. Here both the ATM transition table and the ATM input string will be
stored in the database D. Then D   |= Q for some atomic ground query Q iff the ATM
accepts the given input.2
Without loss of generality, we can assume that the ATM M has exactly one accepting
state sa . We also assume that M never tries to read beyond its tape boundaries. Let M
2. This technique was proposed by Cal et al. (2008). It is similar to a technique later described by Hernich,
Libkin, and Schweikardt (2011) in the proof of undecidability of the existence of so-called CWA (closedworld assumption) universal solutions in data exchange.

132

fiTaming the Infinite Chase

be defined as
M = (S, , , , s0 , {sa })
where S is the set of states,  = {0, 1, } is the tape alphabet,  is the blank tape symbol, 
is the transition function, defined as  : S    (S    {, r, })2 ( denotes the stay
head move, while  and r denote left and right, respectively), s0  S is the initial state,
and {sa } is the singleton-set of accepting states. Since M is an alternating Turing machine
(ATM), its set of states S is partitioned into two sets: S and S (universal and existential
states, respectively). The general idea of the encoding is that configurations of M (except
for the initial configuration ) will be represented by fresh nulls vi , i > 1, that are generated
by the chase.
The relational schema. We now describe the predicates of the schema which we
use in the reduction. Notice that the schema is fixed and does not depend on the particular
ATM that we encode. The schema predicates are as follows.
(1) Tape. The ternary predicate symbol (a, c, v) denotes that in configuration v the cell
c contains the symbol a, with a  . Also, a binary predicate succ(c1 , c2 ) denotes the
fact that cell c1 follows cell c2 on the tape. Finally, neq(c1 , c2 ) says that two cells are
distinct.
(2) States. A binary predicate state(s, v) says that in configuration v the ATM M is in
state s. We use three additional unary predicates: existential , universal , and accept.
The atom existential (s) (resp., universal (s)) denotes that the state s is existential
(resp., universal), while accept(c) says that c is an accepting configuration, that is,
one whose state is the accepting state.
(3) Configurations. A unary predicate config(v) expresses the fact that the value v
identifies a configuration. A ternary predicate next(v, v1 , v2 ) is used to say that both
configurations v1 and v2 are derived from v. Similarly, we use follows(v, v  ) to say
that configuration v  is derived from v. Finally, a unary predicate init(v) states that
the configuration v is initial.
(4) Head (cursor). We use the fact cursor (c, v) to say that the head (cursor) of the
ATM is on cell c in configuration v.
(5) Marking. Similarly to what is done in the proof of Theorem 3.5, we use mark (c, v)
to say that a cell c is marked in a configuration v. Our TGDs will ensure that all
non-marked cells keep their symbols in a transition from one configuration to another.
(6) Transition function. To represent the transition function  of M, we use a single
8-ary predicate transition: for every transition rule (s, a) = ((s1 , a1 , m1 ), (s2 , a2 , m2 ))
we will have transition(s, a, s1 , a1 , m1 , s2 , a2 , m2 ).
The database D. The data constants of the database D are used to identify cells,
configurations, states and so on. In particular, we will use an accepting state sa and an
initial state s0 plus a special initial configuration . The database describes the initial
configuration of the ATM with some technicalities.
(a) We assume, without loss of generality, the n symbols of the input I to occupy the
cells numbered from 1 to n, i.e., c1 , . . . , cn . For technical reasons, in order to obtain
a simpler TGD set below, we also use the dummy cell constants c0 and cn+1 , that
intuitively represent border cells without symbols. For the i-th symbol ai of I, the
database has the fact symbol (a, ci , ), for all i  {1, . . . , n}.
133

fiCal, Gottlob & Kifer

(b) An atom state(s0 , ) specifies that M is in state s0 in its initial configuration .
(c) For every existential state sE and universal state sU , we have the facts existential (sE )
and universal (sU ). For the accepting state, the database has the fact accept(sa ).
(d) An atom cursor (c1 , ) indicates that, in the initial configuration, the cursor points
at the first cell.
(e) The atoms succ(c1 , c2 ), . . . , succ(cn1 , cn ) encode the fact that the cells c1 , . . . , cn
of the tape (beyond which the ATM does not operate) are adjacent. For technical
reasons, we also use the analogous facts succ(c0 , c1 ) and succ(cn , cn+1 ). Also, atoms
of the form neq(ci , cj ), for all i, j such that 1 6 i 6 n, 1 6 j 6 n and i 6= j, denote
the fact that the cells c1 , . . . , cn are pairwise distinct.
(f ) The atom config() says that  is a valid configuration.
(g) The database has atoms of the form transition(s, a, s1 , a1 , m1 , s2 , a2 , m2 ), which
encode the transition function , as described above.
The TGDs. We now describe the TGDs that define the transitions and the accepting
configurations of the ATM.
(a) Configuration generation. The following TGDs say that, for every configuration
(halting or non haltingwe do not mind having configurations that are derived from
a halting one), there are two configurations that follow it, and that a configuration
that follows another configurations is also a valid configuration:
config(V ),  V1 V2 next(V, V1 , V2 )
next(V, V1 , V2 )  config(V1 ), config(V2 )
next(V, V1 , V2 )  follows(V, V1 )
next(V, V1 , V2 )  follows(V, V2 )
(b) Configuration transition. The following TGD encodes the transition where the
ATM starts at an existential state, moves right in its first configuration and left in
the second. Here C denotes the current cell, C1 and C2 are the new cells in the first
and the second configuration (on the right and on the left of C, respectively), and
the constants r, , and  represent the right, the left, and the stay moves,
respectively.
transition(S, A, S1 , A1 , r, S2 , A2 , ), next(V, V1 , V2 ),
state(S, V ), cursor (C, V ), symbol (A, C, V ), succ(C1 , C), succ(C, C2 ) 
state(S1 , V1 ), state(S2 , V2 ), symbol (A1 , C1 , V1 ), symbol (A2 , C2 , V2 ),
cursor (C1 , V1 ), cursor (C2 , V2 ), mark (C, V ),
There are nine rules like the above one, corresponding to all the possible moves of
the head in the child configurations C1 and C2 . These other moves are encoded via
similar TGDs. These rules suitably mark the cells that are written by the transition
by means of the predicate mark . The cells that are not involved in the transition
must retain their symbols, which is specified by the following TGD:
config(V ), follows(V, V1 ), mark (C, V ), symbol (C1 , A, V ), neq(C1 , C)  symbol (C1 , A, V1 )
134

fiTaming the Infinite Chase

(c) Termination. The rule state(sa , V )  accept(V ) defines a configuration V to be
accepting if its state is the accepting state. The following TGDs state that, for an
existential state, at least one configuration derived from it must be accepting. For
universal states, both configurations must be accepting.
next(V, V1 , V2 ), state(S, V ), existential (S), accept(V1 )  accept(V )
next(V, V1 , V2 ), state(S, V ), existential (S), accept(V2 )  accept(V )
next(V, V1 , V2 ), state(S, V ), universal (S), accept(V1 ), accept(V2 )  accept(V )
Note that, for brevity, some of the TGDs we used have multiple atoms in the head.
However, these heads have no existentially quantified variables, so such multi-headed TGDs
can be replaced with sets of TGDs that have only one head-atom. Note also that the
database constants (r, , and , and sa ) appearing in some rules can be eliminated by
introducing additional predicate symbols and database atoms. For example, if we add
the predicate acceptstate to the signature and the fact acceptstate(sa ) to the database D,
the rule state(sa , V )  accept(V ) can be replaced by the equivalent constant-free rule
acceptstate(X), state(X, V )  accept(V ).
It is not hard to show that the encoding described above is sound and complete. That is,
M accepts the input I if and only if chase(D, ) |= accept(). It is also easy to verify that
the set of TGDs we have used is weakly guardedthis can be done by checking that each
variable appearing only in affected positions also appears in a guard atom. For instance,
take the above rule next(V, V1 , V2 ), state(S, V ), existential (S), accept(V1 )  accept(V ). It is
immediate to see that state[1] and existential [1] are non-affected (the TGDs never invent
new states), and that all variables appearing in affected positions only, namely V, V1 , V2 ,
appear in the guard atom next(V, V1 , V2 ). This proves the claim.
We now turn to the case where  is not fixed and has unbounded predicate arities.
For obtaining the 2exptime lower bound, it is sufficient to adapt the above proof so as
to simulate an ATM having 2n worktape cells, i.e., an aexpspace machine whose space is
restricted to 2n tape cells. Actually, to accommodate two dummy cells to the left and right
of the 2n effective tape cells, that are used for technical reasons, we will feature 2n+1 tape
cells instead of just 2n .
We will make sure that the input string is put on cells 1, . . . , n of the worktape. Given
that there are now many more than n worktape cells, we will fill all cells to the right of the
input string with the blank symbol .
This time, the WGTGD set  will not be fixed, but will depend on n. Since a much
stronger result will be shown in Section 6 (Theorem 6.2), we do not belabor all the details
in what follows, but just explain how the above proof for fixed sets of TGDs needs to be
changed.
Rather than representing each tape cell by a data constant, each tape cell is now represented by a vector (b0 , b1 , b2 , . . . , bn ) of Boolean values from {0, 1}. The database D is the
same as before, except for the following changes:
 D contains the additional facts bool (0), bool (1), zero(0), one(1).
 Each fact symbol (a, ci , ) is replaced by the fact symbol (a, b0 , b1 , b2 , . . . , bn , ), where
(b0 , b1 , b2 , . . . , bn ) is the Boolean vector of length n representing the integer i, with
0 6 i 6 n 6 2n+1 .
135

fiCal, Gottlob & Kifer

 The fact cursor (c1 , ) is replaced by the (n + 2)-ary fact cursor (0, 0,    , 0, 1, ).
 All succ and neq facts described under item (e) are eliminated. (Vectorized versions
of these predicates will be defined via Datalog rulessee below).
The TGD set from before is changed as follows. In all rules, each cell-variable C is
replaced by a vector C of n variables. For example, the atom succ(C1 , C) now becomes
succ(C1 , C) = succ(C10 , C11 , . . . C1n , C 0 , C 1 , . . . , C n ).
We add Datalog rules for n-ary succ and neq predicates. For example, the n-ary predicate succ can be implemented by the following rules:
bool (X0 ), . . . , bool (Xn1 )  succ(X0 , . . . , Xn1 , 0 , X0 , . . . , Xn1 , 1),
bool (X0 ), . . . , bool (Xn2 )  succ(X0 , . . . , Xn2 , 0, 1 , X0 , . . . , Xn2 , 1, 0),
..
.
bool (X0 ), . . . , bool (Xni )  succ(X0 , . . . , Xni , 0, 1 . . . 1 , X0 , . . . , Xni , 1, 0, . . . , 0),
..
.
 succ(0, 1, . . . , 1 , 1, 0, . . . , 0)
These rules contain constants which can be easily eliminated by use of the zero and
one predicates, which are extensional database (EDB) predicates. We further add simple Datalog rules that use the vectorized succ predicate to define vectorized versions for
the less than and the neq predicates. Using less than, we add a single rule that, for the
initial configuration , puts blanks into all tape cells beyond the last cell n of the input:
less than(n, C)  symbol (, C, ), where n is an n-ary binary vector representing the number n (i.e., the input size).
The resulting set of rules is weakly guarded and correctly simulates the aexpspace (alternating exponential space) Turing machine whose transition table is stored in the database
D. Our reduction is polynomial in time. Since aexpspace=2exptime, it immediately follows that when the arity is not bounded the problem is 2exptime-hard.

5. Complexity: Upper Bounds
In this section we present upper bounds for query answering under weakly guarded TGDs.
5.1 Squid Decompositions
We now define the notion of a squid decomposition, and prove a lemma called Squid
Lemma which will be a useful tool for proving our complexity results in the following
sub-sections.
Definition 5.1. Let Q be a Boolean conjunctive query with n body atoms over a schema
R. An R-cover of Q is a Boolean conjunctive query Q+ over R that contains in its body
all the body atoms of Q. In addition, Q+ may contain at most n other R-atoms.
Example 5.2. Let R = {r/2, s/3, t/3} and Q be the Boolean conjunctive query with
body atoms {r(X, Y ), r(Y, Z), t(Z, X, X)}. The following query Q+ is an R-cover of Q:
Q+ = {r(X, Y ), r(Y, Z), t(Z, X, X), t(Y, Z, Z), s(Z, U, U )}.
136

fiTaming the Infinite Chase

Lemma 5.3. Let B be an instance over a schema R and Q a Boolean conjunctive query
over B. Then B |= Q iff there exists an R-cover Q+ of Q such that B |= Q+ .
Proof. The only-if direction follows trivially from the fact that Q is an R-cover of itself. The
if direction follows straightforwardly from the fact that whenever there is a homomorphism
h : vars(Q+ )  dom(B), such that h(Q+ )  B, then, given that Q is a subset of Q+ , the
restriction h of h to vars(Q) is a homomorphism vars(Q)  dom(B) such that h (Q) =
h(Q)  B. Therefore B |= Q+ implies B |= Q.
Definition 5.4. Let Q be a Boolean conjunctive query over a schema R. A squid decomposition  = (Q+ , h, H, T ) of Q consists of an R-cover Q+ of Q, a mapping h : vars(Q+ ) 
vars(Q+ ), and a partition of h(Q+ ) into two sets H and T , with T = h(Q+ )  H, for
which there exists a set of variables V  h(vars(Q+ )) such that: (i) H = {a  h(Q+ ) |
vars(a)  V }, and (ii) T is [V ]-acyclic. If an appropriate set V is given together with a
squid decomposition  = (Q+ , h, H, T ), then, by a slight terminology overloading, we may
just speak about the squid decomposition (Q+ , h, H, T, V ).
Note that a squid decomposition  = (Q+ , h, H, T ) of Q does not necessarily define a
query folding (Chandra & Merlin, 1977; Qian, 1996) of Q+ , because h does not need to be
an endomorphism of Q+ ; in other terms, we do not require that h(Q+ )  Q+ . However, h
is trivially a homomorphism from Q+ to h(Q+ ).
Intuitively, a squid decomposition  = (Q+ , h, H, T, V ) describes a way how a query
Q may be mapped homomorphically to chase(D, ). First, instead of mapping Q to
chase(D, ), we equivalently map h(Q+ ) = H  T to chase(D, ). The set V specifies those variables of h(Q+ ) that ought to be mapped to constants, i.e., to elements of
dom(D). The atoms set H is thus mapped to ground atoms, that is, elements of the finite set chase  (D, ), which may be highly cyclic. The [V ]-acyclic atom set T shall be
mapped to the possibly infinite set chase + (D, ) which, however, is [dom(D)]-acyclic. The
acyclicities of chase + (D, ) and of T will be exploited for designing appropriate decision
procedures for determining whether chase(D, ) |= Q. All this will be made formal in the
sequel.
One can think of the set H in a squid decomposition  = (Q+ , h, H, T, V ) as the head of
a squid, and the set T as a join-forest of tentacles attached to that head. This will become
clear in the following example and the associated Figure 3.
Example 5.5. Consider the following Boolean conjunctive query:
Q = {r(X, Y ), r(X, Z), r(Y, Z),
r(Z, V1 ), r(V1 , V2 ), r(V2 , V3 ), r(V3 , V4 ), r(V4 , V5 ),
r(V1 , V6 ), r(V6 , V5 ), r(V5 , V7 ), r(Z, U1 ), s(U1 , U2 , U3 ),
r(U3 , U4 ), r(U3 , U5 ), r(U4 , U5 )}.
Let Q+ be the following Boolean query: Q+ = Q  {s(U3 , U4 , U5 )}. A possible squid
decomposition (Q+ , h, H, T, V ) can be based on the homomorphism h, defined as follows:
h(V6 ) = V2 , h(V4 ) = h(V5 ) = h(V7 ) = V3 , and h(X) = X for any other variable X in Q+ .
The result of the squid decomposition with V = {X, Y, Z} is the query shown in Figure 3.
137

fiCal, Gottlob & Kifer

Here the cyclic head H (encircled in the oval) is represented by its join graph,3 and the [V ]acyclic tentacle set T is depicted as a [V ]-join forest. Moreover, the forest representing
T is rooted in the bag of H-atoms, so that the entire decomposition takes on the shape
of a squid. Note that if we eliminated the additional atom s(U3 , U4 , U5 ), the original set
of atoms {r(U3 , U4 ), r(U3 , U5 ), r(U4 , U5 )} would form a non-[V ]-acyclic cycle, and therefore
they would not all be part of the tentacles.

r(X, Y )

r(X, Z)
head
r(Y, Z)

r(Z, V1 )

r(Z, U1 )

r(V1 , V2 )

s(U1 , U2 , U3 )

r(V2 , V3 )

s(U3 , U4 , U5 )

tentacles

r(V3 , V3 )

r(U3 , U4 )

r(U3 , U5 )

r(U4 , U5 )

Figure 3: Squid decomposition from Example 5.5. Atoms in h(Q+ ) are shown.
The following two lemmas are auxiliary technical results.
Lemma 5.6. Let Q be a Boolean conjunctive query and let U be a (possibly infinite) [A]acyclic instance, where A  dom(U ). Assume U |= Q, i.e., there is a homomorphism
f : dom(Q)  dom(U ) with f (Q)  U . Then:
(1) There is an [A]-acyclic subset W  U such that: (i) f (Q)  W and (ii) |W | < 2|Q|.
(2) There is a cover Q+ of Q such that |Q+ | < 2|Q|, and there is a homomorphism g
that extends f and g(Q+ ) = W .
Proof.
Part (1). By the assumption,4 U is [A]-acyclic and f : dom(Q)  dom(U ) is a homomorphism such that f (Q)  U . Since U is [A]-acyclic, it has a (possibly infinite) [A]-join
forest T = hhV, Ei, i. We assume, without loss of generality, that distinct vertices u, v of
T have different labels, i.e., (u) 6= (v). This assumption can be made by removing all
subforests rooted at nodes labeled by duplicate atoms. Let TQ be the finite subforest of T
3. The join graph of H has the atoms as nodes. An edge between two atoms exists iff the atoms share at
least one variable.
4. One may be tempted to conjecture that W = f (Q), but this does not work because acyclicity (and thus
also [A]-acyclicity) is not a hereditary property: it may well be the case that U is acyclic, while the
subset f (Q)  U is not. However, taking W = f (Q) works in case of arities at most 2.

138

fiTaming the Infinite Chase

that contains all ancestors in T of nodes s such that (s)  f (Q). Let F = hhV  , E  i,  i be
the forest obtained from T as follows.
 V  = {v  V | (v)  f (Q)}  K, where K is the set of all vertices of TQ that have at
least two children.
 If v, w  V  then there is an edge from v to w in E  iff w is a descendant of v in T ,
and if the unique shortest path from v to w in T does not contain any other node
from V  .
 Finally, for each v  V  ,  (v) = (v).
Let us define W = (V  ). We claim that the forest F is an [A]-join forest of W . Since
Condition (1) of Definition 3.8 ([S]-join forest) is immediately satisfied, it suffices to show
Condition (2), that is, that F satisfies the [A]-connectedness condition. Assume, for any
pair of distinct vertices v1 and v2 in F , that for some value b  dom(U )  A it holds
b  dom( (v1 ))  dom( (v2 )). In order to prove the aforementioned [A]-connectedness
condition, we need to show that there is at least one path in F between v1 and v2 (here
we view F as a undirected graph), and that for every node v  V  lying on each such
path we have b  dom( (v)). By construction of F , v1 and v2 are connected in T and v
lies on the (unique) path between v1 and v2 in T . Since T is an [A]-join forest, we have
b  dom((v)) = dom( (v)). Thus F is an [A]-join forest of W .
Moreover, by construction of F , the number of children of each inner vertex of F is
at least 2, and F has at most |Q| leaves. It follows that F has at most 2|Q|  1 vertices.
Therefore W is an [A]-acyclic set of atoms such that |W | 6 2|Q| and W  f (Q).
Part (2). Q can be extended to Q+ as follows. For each atom r(t1 , . . . , tk ) in W  f (Q),
add to Q a new query atom r(1 , . . . , k ) such that for each 1 6 i 6 k, i is a newly invented
variable. Obviously, W |= Q+ and thus there is a homomorphism g extending f such that
g(Q+ ) = W . Moreover, by construction |Q+ | < 2|Q|.
Lemma 5.7. Let G be an [A]-acyclic instance and let G be an instance obtained from G
by eliminating a set S of atoms where dom(S)  A. Then G is [A]-acyclic.
Proof. If T = hhV, Ei, i is an [A]-join forest for G then an [A]-join forest T  for G can
be obtained from G by repeatedly eliminating each vertex v from T where (v)  S. By
construction, each atom e eliminated from G in this way has the property that dom(e)  A.
Hence, for every value b  dom(G)  A, the node u  V such that (u) = e cannot belong
to the induced (connected) subtree {v  V | b  dom((v))}. We thus get that G enjoys
the [A]-connectedness property.
The following Lemma will be used as a main tool in the subsequent complexity analysis.
Lemma 5.8 (Squid Lemma). Let  be a weakly guarded set of TGDs on a schema R,
D a database for R, and Q a Boolean conjunctive query. Then chase(D, ) |= Q iff
there is a squid decomposition  = (Q+ , h, H, T ) and a homomorphism  : dom(h(Q+ )) 
dom(chase(D, )) such that: (i) (H)  chase  (D, ), and (ii) (T )  chase + (D, ).
Proof. If. If there is a squid decomposition  = (Q+ , h, H, T ) of Q and a homomorphism
 as described, then the composition   h is a homomorphism such that (  h)(Q+ ) =
139

fiCal, Gottlob & Kifer

(h(Q+ ))  chase(D, ). Hence, chase(D, ) |= Q+ and, by Lemma 5.3, chase(D, ) |=
Q.
Only if. Assume U = chase(D, ) |= Q. Then, there exists a homomorphism f :
vars(Q)  dom(U ) with f (Q)  chase(D, ). By Lemma 3.11, chase + (D, ) is [dom(D)]acyclic. By Lemma 5.6, it then follows that there is a Boolean query Q+ with < 2|Q| atoms,
such that all atoms of Q are contained in Q+ , and there is a homomorphism g : dom(Q+ ) 
dom(U ) with g(Q+ )  U , such that g(Q+ ) is [dom(D)]-acyclic.
Partition vars(Q+ ) into two sets vars  (Q+ ) and vars + (Q+ ) as follows:
 vars  (Q+ ) = {X  vars(Q+ ) | g(X)  dom(D)}
 vars + (Q+ ) = vars(Q+ )  vars  (Q+ ).
Define a mapping h : vars(Q+ )  vars(Q+ ) as follows. For each X  vars(Q+ ), let h(X)
be the lexicographically first variable in the set {Y  vars(Q+ ) | g(Y ) = g(X)}. Let
us define V as V = h(vars  (Q+ )). Moreover, let H be the set of all those atoms a of
h(Q+ ), such that vars(a)  V = h(vars  (Q+ )), and let T = h(Q+ )  H. Note that, by
definition of H, g(H)  chase  (D, ) and, by definition of T , g(T )  chase + (D, ). Let
 be the restriction of g to dom(h(Q+ )). Clearly, , h, H, and T fulfill the conditions (i)
and (ii) of the statement of this lemma. It thus remains to prove that  = (Q+ , h, H, T ) is
actually a squid decomposition of Q. For this, we only need to show that T is [V ]-acyclic.
To prove this, first observe that for each pair of variables X, Y in vars(Q+ ) such that
g(X) = g(Y ) we have h(X) = h(Y ). Therefore  is, by construction, a bijection between
h(dom(Q+ )) and dom((Q+ )). In particular, T  h(Q+ ) is isomorphic to (T ) via the
restriction T of  to dom(T ). Since T (T ) = (T ) is obtained from the [dom(D)]-acyclic
instance (Q+ ) by eliminating only atoms all of whose arguments are in dom(D) (namely
the atoms in (H)), by Lemma 5.7, T (T ) is itself [dom(D)]-acyclic and, therefore, trivially
also [dom(D)  dom((T ))]-acyclic. Now, since for every X  dom(T ) it holds that X  V
iff T (X)  dom(D), it immediately follows that, since T (T ) is [dom(D)]-acyclic, T is
[V ]-acyclic.
5.2 Clouds and the Complexity of Query Answering under WGTGDs
The goal of this subsection is to prove the following theorem:
Theorem 5.9. Let  be a weakly guarded set of TGDs, D a database for a schema R,
and Q a Boolean conjunctive query. The problem of determining whether D   |= Q or,
equivalently, whether chase(D, ) |= Q is in exptime in case of bounded arity, and in
2exptime in general.
For the general case (of unbounded arities), we first outline a short high-level proof
aimed at specialists in Computational Logic. This proof makes sophisticated use of previous
results. We will then give a much longer, self-contained proof, that works for both the
general case and the case of bounded arities. The self-contained proof also introduces some
concepts that will be used in the following sections.
High Level Proof Sketch of Theorem 5.9 (General Case). We transform the original problem
instance (D, , Q) into a guarded first-order theory  =  (D, , Q) such that chase(D, ) |=
140

fiTaming the Infinite Chase

Q iff  is unsatisfiable. The signature  of  uses  as the set of constants plus a constant
for each element of dom(D). Moreover,  includes all predicate symbols occurring in D, ,
or Q, plus a special nullary (i.e., propositional) predicate symbol q.
 contains all ground facts of D, plus all instances of each rule r   obtained from
r by replacing all variables of r that occur in non-affected positions with constants. Note
that the resulting rules are universally quantified guarded sentences. Moreover, for each
squid decomposition  = (Q+ , h, H, T, V ), and each possible replacement  of the set of
variables V by constants of the signature ,  contains a guarded sentence  obtained as
follows. Notice that Q := (H)  T is a Boolean acyclic conjunctive query. By the results
of Gottlob, Leone, and Scarcello (2003),5 Q can thus be rewritten (in polynomial time)
into an equivalent guarded sentence  . We define  to be (  q), which is obviously
guarded, too. Let  denote the sentences of  mentioned so far. From this construction
and the Squid Lemma (Lemma 5.8), it follows that chase(D, ) |= Q iff  |= q. Now let
 =   {q}. Obviously,  is unsatisfiable iff chase(D, ) |= Q.
Note that the reduction  is an arity-preserving exptime-reduction. Let t be an exponential upper bound on the runtime required by reduction  (and thus also on the size
of  (D, , Q)). A deterministic version of the algorithm in the work by Gradel (1999) for
deciding whether a guarded theory of unbounded arity is satisfiable or unsatisfiable runs in
w
double-exponential time O(2O(sw ) ), where s is the size of the theory and w is its maximum
predicate arity. Therefore, the overall runtime of first computing  =  (D, , Q) for an input (D, , Q) of size n and maximum arity w, and then checking whether  is unsatisfiable
w
is O(2O(t(n)w ) ), which is still only double-exponential. Deciding D   |= Q is thus in
2exptime.

Note that in case of bounded w, a similar proof does not provide an exptime bound,
w
as 2t(n)w would still be doubly exponential due to the exponential term t(n), even if w is
constant. Actually, as noted by Barany, Gottlob, and Otto (2010), evaluating non-atomic
conjunctive queries against guarded first-order theories of bounded predicate arity is in fact
2exptime-complete. Surprisingly, this remains true even for guarded theories D   where
D is a (variable) database and  a fixed guarded theory of a very simple form involving
disjunctions (Bourhis, Morak, & Pieris, 2013). We therefore needed to develop different
proof ideas.
In the rest of this section we present an independent and self-contained proof of Theorem 5.9 by developing tools for analyzing the complexity of query answering under WGTGDs. To this end we introduce the notion of a cloud of an atom a in the chase of a database
D under a set  of WGTGDs. Intuitively, the cloud of a is the set of atoms of chase(D, )
whose arguments belong to dom(a)  dom(D). In other words, the atoms in the cloud
cannot have nulls that do not appear in a. The cloud is important because we will show
that the subtree of gcf(D, ) rooted in a depends only on a and its cloud.
Definition 5.10. Let  be a weakly guarded set of TGDs on a schema R and D be a
database for R. For every atom a  chase(D, ) the cloud of a with respect to  and D is
the following set: cloud (D, , a) = {b  chase(D, ) | dom(b)  dom(a)  dom(D)}. Notice
5. See Theorem 3 in that paper, its proof, the remark after that proof, and Corollary 3.

141

fiCal, Gottlob & Kifer

that for every atom a  chase(D, ) we have D  cloud (D, , a). Moreover, we define
clouds(D, ) = {cloud (D, , a) | a  chase(D, )}
clouds + (D, ) = {(a, cloud (D, , a)) | a  chase(D, )}
Any subset S  cloud (D, , a) is called a subcloud of a (with respect to  and D). The
set of all subclouds of an atom a is denoted by subclouds(D, , a). Finally, we define
subclouds + (D, ) = {(a, C) | a  chase(D, ) and C  cloud (D, , a)}.
Definition 5.11. Let B be an instance (possibly with nulls) over a schema, R, and D be
a database over R. Let  and  be atoms from the Herbrand Base HB (B). We say that
 and  are D-isomorphic, denoted  D , or simply    in case D is understood, if
there is a bijective homomorphism6 f : dom()  dom() such that f () =  (and thus
also f 1 () = ). This definition extends directly to the cases when  and  are sets of
atoms or atom-set pairs (in a similar fashion as in clouds + (D, )).
Example 5.12. If {a, b}  dom(D) and {1 , 2 , 3 , 4 }  N , we have: p(a, 1 , 2 ) 
p(a, 3 , 4 ) and (p(a, 3 ), {q(a, 3 ), q(3 , 3 ), r(3 )})  (p(a, 1 ), {q(a, 1 ), q(1 , 1 ), r(1 )}). On
the other hand, p(a, 1 , 2 ) 6 p(a, 1 , 1 ) and p(a, 1 , 2 ) 6 p(3 , 1 , 2 ).
Lemma 5.13. Given a database D for a schema R and an instance B for R, the Disomorphism relation D on HB (B) (resp., 2HB (B) or HB (B)  2HB (B) , as in Definition 5.11) is an equivalence relation.
The above lemma follows directly from the definitions; it lets us define, for every set A
of atoms of HB (B), the quotiont set A/D with respect to the above defined equivalence
relation D . Such notion of quotient set naturally extends to sets of sets of atoms such as
clouds(D, ), or sequences (pairs, in particular) thereof.
Lemma 5.14. Let  be a weakly guarded set of TGDs and let D be a database for a schema
R. Let |R| denote the number of predicate symbols in R, and w be the maximum arity of
the symbols in R. Then:
(1) For every atom a  chase(D, ), we have |cloud (D, , a)| 6 |R|  (|dom(D)| + w)w .
Thus, cloud (D, , a) is polynomial in the size of the database D if the arity w is
bounded and exponential otherwise.
w
(2) For each atom a  chase(D, ), |subclouds(D, , a)| 6 2|R|(|dom(D)|+w) .
w
(3) |clouds(D, )/ | 6 2|R|(|dom(D)|+w) , i.e., there areup to isomorphismat most
exponentially many possible clouds or subclouds in a chase, if the arity w is bounded,
otherwise doubly exponentially many.
w
(4) |clouds + (D, )/ | 6 |subclouds + (D, )/ | 6 |R|(|dom(D)|+w)w 2|R|(|dom(D)|+w) .
Proof. The claims are proved by combinatorial arguments as follows.
(1) All distinct atoms in a cloud are obtained by placing the symbols of a, plus possibly
symbols from dom(D), in at most w arguments of some predicate symbol in R. For
each predicate in R, the number of symbols to be thus placed is |dom(D)| + w.
6. Recall that, by definition, the restriction of a homomorphism to dom(D) is the identity mapping.

142

fiTaming the Infinite Chase

(2) The different ways we can choose subclouds(D, , a) clearly determines the set of
all subsets of cloud (D, , a).
(3) It is easy to see that the size of the set of all non-pairwise-isomorphic clouds in the
chase is bounded by the number of possible subclouds of a fixed atom.
(4) Here, we are counting the number of all possible subclouds, each associated with
its generating atom. The inequality holds because, once we choose all non-pairwiseisomorphic clouds, each of their possible generating atoms can have as arguments only
|dom(D)| + w symbols with which to construct the subclouds.
Definition 5.15. Given a database D and a set of WGTGDs, let a be an atom in
chase(D, ). We define the following notions:
 a is the set of all atoms that label nodes of the subtrees of gcf(D, ) rooted in a;
 a = a  cloud (D, , a);
 if S is a subset of atoms in gcf(D, ), then gcf[a, S]7 is inductively defined as follows:
(i) S  {a}  gcf[a, S];
(ii) b  gcf[a, S] if b  a , and b is obtained via the chase rule applied using a TGD
with body  and head-atom , and a homomorphism , such that () = b and
()  gcf[a, S].
Theorem 5.16. If D is a database for a schema R,  is a weakly guarded set of TGDs,
and a  chase(D, ), then a = gcf[a, cloud (D, , a)].
Proof. By the definitions of a and gcf[a, cloud (D, , a)], we have gcf[a, cloud (D, , a)] 
a. It remains to show the converse inclusion: a  gcf[a, cloud (D, , a)]. Define
levela (a) = 0 and for each fact b  cloud (D, , a)  a we also define levela (b) = 0.
For every other atom c  a , levela (c) is defined as the distance (i.e., the length of the path)
from a to c in gcf(D, ).
We first show the following facts in parallel by induction on levela (b):
(1) If b  a then cloud (D, , b)  gcf[a, cloud (D, , a)].
(2) If b  a then b  gcf[a, cloud (D, , a)].
Statement (2) above is the converse inclusion we are after.
Induction basis. If levela (b) = 0, we have either (a) b  cloud (D, , a)  {a},
or (b) b = a. In case (a), cloud (D, , a)  gcf[a, cloud (D, , a)] and therefore b 
gcf[a, cloud (D, , a)], which proves (1). Moreover, since b  cloud (D, , a), b cannot contain more labeled nulls than a, so dom(b)  dom(D)  dom(a)  dom(D). Therefore
cloud (D, , b)  cloud (D, , a)  gcf[a, cloud (D, , a)], which proves (2). In case (b),
b = a and thus cloud (D, , a) = cloud (D, , b)  gcf[a, cloud (D, , a)], which proves (1).
Since b = a  gcf[a, cloud (D, , a)], (2) follows as well.
Induction step. Assume that (1) and (2) are satisfied for all c  a such that
levela (c) 6 i and assume levela (b) = i + 1, where i > 0. The atom b is produced by a TGD
whose guard g matches some atom b at level i, which is, by the induction hypothesis, in
gcf[a, cloud (D, , a)]. The body atoms of such a TGD then match atoms whose arguments
7. D and  are implicit here, to avoid clutter.

143

fiCal, Gottlob & Kifer

must be in cloud (D, , b) and thus also in gcf[a, cloud (D, , a)], again by the induction hypothesis. Therefore, (2) holds for b. To show (1), consider an atom b  cloud (D, , b). In
case dom(b )  dom(b ), we have cloud (D, , b )  cloud (D, , b )  gcf[a, cloud (D, , a)].
Otherwise, b contains at least one new labeled null that was introduced during the generation of b. Given that  is a weakly guarded set and each labeled null in N is introduced
only once in the chase, there must be a path from b to b in gcf(D, ) (and therefore also
in b). A simple additional induction on levelb (b ) shows that all the applications of TGDs
on that path must have been fired on elements of gcf[a, cloud (D, , a)] only. Therefore,
b  gcf[a, cloud (D, , a)], which proves (1).
The corollary below follows directly from the above theorem.
Corollary 5.17. If D is a database for a schema R,  is a weakly guarded set of TGDs,
a, b  chase(D, ), and (a, cloud (D, , a))  (b, cloud (D, , b)), then a  b.
Definition 5.18. Let D be a database and a an atom. The canonical renaming can a :
dom(a)  dom(D)  a  dom(D), where a = {1 , . . . , h }  N is a set of labeled nulls
not appearing in a, is a 1-1 substitution that maps each element of dom(D) into itself and
each null-argument of a to the first unused element i  a . If S  cloud (D, , a) then
can a (S) is well-defined and the pair (can a (a), can a (S)) will be denoted by can(a, S).
Example 5.19. Let a = g(d, 1 , 2 , 1 ) and S = {p(1 ), r(2 , 2 ), s(1 , 2 , b)}, where {d, b} 
dom(D) and {1 , 2 }  N . Then can a (a) = g(d, 1 , 2 , 1 ), and can a (S) = {p(1 ), r(2 , 2 ),
s(1 , 2 , b)}.
Definition 5.20. If D is a database for a schema R,  is a weakly guarded set of TGDs
on R, S is a set of atoms and a  S, then we write (D, , a, S) |= Q iff there exists a
homomorphism  such that (Q)  S  a .
The following result straightforwardly follows from Theorem 5.16 and the previous definitions.
Corollary 5.21. If D is a database for a schema R,  is a weakly guarded set of TGDs,
a  chase(D, ), and Q is a Boolean conjunctive query, then the following statements are
equivalent:
(1)
(2)
(3)
(4)

a |= Q
(D, , a, cloud (D, , a)) |= Q
(D, , can a (a), cana (cloud (D, , a))) |= Q
there is a subset S   cloud (D, , a) such that (D, , can a (a), can a (S  )) |= Q.

We will use the pair can(a, cloud (D, , a)) as a unique canonical representative of the
equivalence class {(b, cloud (D, , b)) | (b, cloud (D, , b))  (a, cloud (D, , a))} in
clouds + (D, ). Therefore, the set {can(a, cloud (D, , a)) | a  chase(D, )} and the
quotient set clouds + (D, )/ are isomorphic. Note that, by Lemma 5.14, these sets are
finite and have size exponential in |D| + || if the schema is fixed (and double exponential
otherwise).
Now, given a database D for a schema R, a weakly guarded set of TGDs  on R, and an
atomic Boolean conjunctive query Q, we describe an alternating algorithm Acheck(D, , Q)
144

fiTaming the Infinite Chase

that decides whether D |= Q. We assume that Q has the form Y1 , . . . , Y , q(t1 , t2 , . . . , tr ),
where the t1 , . . . , tr , with r > , are terms (constants or variables) in dom(D){Y1 , Y2 , . . . , Y }.
The algorithm Acheck returns true if it accepts some configuration, according to the
criteria explained below; otherwise, it returns false. Acheck uses tuples of the form
(a, S, S  , , b) as its basic data structures (configurations). Intuitively, each such configuration corresponds to an atom a derived at some step of the chase computation together with
a set S  of already derived atoms belonging the cloud of a. The informal meaning of the
parameters of a configuration is as follows.
(1) a is the root atom of the chase subtree under consideration.
(2) S  cloud (D, , a); S is intuitively a subcloud containing a set of atoms of cloud (D, , a)
that, while computing chase(D, ), are originally derived outside the subtree of the
guarded chase forest rooted in a (and are thus outside the subtree rooted in a of
rgcf(D, )). We expect these atoms to serve as side atoms (i.e., atoms matching
non-guard atoms of a TGD) when deriving the desired atom b starting at a.
(3) S  contains, at every step in the computation, the subset of cloud (D, , a) that has
been computed so far, or can be assumed to be valid, as it will be verified in another
branch of the computation.
(4)  is a total ordering of the atoms in S consistent with the order in which the atoms
of S are proved by the algorithm (by simulating the chase procedure).
(5) b is an atom that needs to be derived. In some cases (namely, on the main path
in the proof tree developed by Acheck), the algorithm will not try to derive a specific
atom, but will just match the query atom q(t1 , . . . , tr ) against the atoms of that path.
In that case, we use the symbol  in place of b.
We are now ready to describe the algorithm Acheck at a sufficiently detailed level. However,
we omit many low-level details.
Acheck first checks if D |= Q. If so, Acheck returns true and halts. Otherwise, the
algorithm attempts to guess a path, the so called main branch, that contains an atom q
that is an instance of Q. This is done as follows.
Initialization. The algorithm Acheck starts at D and guesses some atom a  D,
which it will expand into a main branch that will eventually lead to an atom q matching
the query Q. To this end, the algorithm guesses a set S  cloud (D, , a) and a total order
 on S, and then generates the configuration c0 = (a, S, S  , , ). The set S  is initialized
as S  = S.
Form of a configurationadditional specifications. In each configuration,
the set set S is implicitly partitioned into two sets S  and S + , where S   D and S + =
{a1 , a2 , . . . , ak } is disjoint from D. The total order  is such that all elements of S  precede
those of S + . On S + ,  is defined as a1  a2      a      ak .
Summary of tasks Acheck performs for each configuration. Assume the
Acheck algorithm generates a configuration c = (a, S, S  , , b), where b might be . Acheck
then performs the following tasks on c:
 Acheck verifies that the guessed set S of c is actually a subset of cloud (D, , a). This
is achieved by a massive universal branching that will be described below under the
145

fiCal, Gottlob & Kifer

heading Universal Branching. Let us, however, anticipate here how it works, as
this may contribute to the understanding of the other steps. Acheck will verify that
each of the atoms a1 , . . . , ak is in chase(D, ), where, for each i  {1, . . . , k}, the
proof of ai  chase(D, ) can use as premises only the atoms of S that precede ai ,
according to . The algorithm thus finds suitable atoms d1 , . . . , dk  D and builds
proof trees for a1 , . . . , ak . For each 1 6 i 6 k, it generates configurations of the
form (di , S, S   {a1 , a2 , . . . , ai1 }, , ai ). Each such configuration will be used as a
starting point in a proof of ai  chase(D, ) assuming that a1 , . . . , ai1  chase(D, )
has already been established. Acheck thus simulates a sequential proof of all atoms of
cloud (D, , a) that are in S via a parallel universal branching from c.
 Acheck tests whether c is a final configuration (i.e., an accepting or rejecting one).
This is described under the heading Test for final Configuration below.
 If c is not a final configuration of Acheck, this means that its first component a is
not yet the one that will be matched to b (or the query, if b = ). Acheck then
moves down the chase tree by one step by replacing a with a child of a. This step
is described under the heading Existential Branching.
In the following, let c = (a, S, S  , , b) be a configuration, where b may be .
Test for final configuration. If b  D, then Acheck accepts this configuration,
and does not expand it further. If b = , then Acheck checks (via a simple subroutine)
whether Q matches a, i.e., if a is a homomorphic image of the query atom q(t1 , . . . , tr ). If
so, Acheck accepts c (and thus returns true) and does not expand it further. If b 6= ,
Acheck checks whether a = b. If this is true, then Acheck accepts the configuration c and
does not expand it further. Otherwise, the configuration tree is expanded as described next.
Existential Branching. Acheck guesses a TGD    having body  and headatom , and whose guard g matches a via some substitution  (that is, (g) = a) such
that ()  S  . () then corresponds to a newly generated atom (possibly containing
some fresh labeled nulls in N ). Note that, if no such guess can be made, this existential
branching automatically fails and Acheck returns false. To define the configuration c1
that Acheck creates out of c, we first introduce an intermediate auxiliary configuration
 b), where:
c = (a, S, S  , ,
(a) a = () is the new atom generated by the application of  with the substitution .
(b) S contains a and each atom d of S such that dom(d)  dom(a)  dom(D). Thus, in
addition to the new atom a, S inherits all atoms that were in the subcloud S of the
parent configuration c that are compatible with a. In addition, S includes a set
newatoms(c) of new atoms that are guessed by the Acheck algorithm. All arguments
of each atom of newatoms(c) must be elements of the set dom(a)  dom(D).
(c) S  = S.
 is a total order on S  obtained from  by eliminating all atoms in S  S and by
(d) 
ordering the atoms from newatoms(c) after all the atoms from the set oldproven(c) =
S   S  (these are assumed to have already been proven at the parent configuration c).
(e) b is defined as b = b.
Next, Acheck constructs the configuration c1 out of c by canonicalization: c1 = can a (c),
 can a (b)), where can a ()
 is the total
that is c1 = (can a (a), can a (S), can a (S  ), can a (),


order on the atoms in can a (S ) derived from .
146

fiTaming the Infinite Chase

Intuitively, c1 is the main child of c on the way to deriving the query atom q(t1 , . . . , tr )
assuming that all atoms of the guessed subcloud S are derivable.
Universal Branching. In the above generated configuration c, the set S  is equal
to S. As already said, this means that it is assumed for that configuration that the set of
atoms S is derivable. To verify that this is indeed the case, Acheck generates in parallel,
using universal computation branching, a set of auxiliary configurations for proving that all
the guessed atoms in can a (newatoms(c)) are indeed derivable through the chase of D with
respect to .
 on S be a concateLet can a (newatoms(c)) = {n1 , . . . , nm } and let the linear order 

    n
 m . For each
nation of the order , restricted to oldproven(c), and the order n1 n2 
(i)
1 6 i 6 m, Acheck generates a configuration c2 defined as
(i)
 ni ).
c2 = (can a (a), can a (S), can a (oldproven(c))  {n1 , . . . , ni1 }, can a (),

This completes the description of the Acheck algorithm.
Theorem 5.22. The Acheck algorithm is correct and runs in exponential time in case of
bounded arities, and in double exponential time otherwise.
Proof.
Soundness. It is easy to see that the algorithm is sound with respect to the standard
chase, i.e., if Acheck(D, , Q) returns true, then chase(D, ) |= Q. In fact, modulo
variable renaming, which preserves soundness according to Corollary 5.21, the algorithm
does nothing but chasing D with respect to , even if the chase steps are not necessarily
in the same order as in the standard chase. Thus, each atom derived by Acheck occurs in
some chase. Since every chase computes a universal solution that is complete with respect
to conjunctive query answering, whenever Acheck returns true, Q is entailed by some
chase, and thus also by the standard chase, chase(D, ).
Completeness. The completeness of Acheck with respect to chase(D, ) can be shown
as follows. Whenever chase(D, ) |= Q, there is a finite proof of Q, i.e., a finite sequence
proof Q of generated atoms that ends with some atom q, which is an instance of Q. This
proof can be simulated by the alternating computation Acheck as follows: (i) steer the main
branch of Acheck towards (a variant of) q by choosing successively the same TGDs and
substitutions  (modulo the appropriate variable renamings) as those used in the standard
chase for the branch of q; (ii) whenever a subcloud S has to be chosen for some atom a by
Acheck, choose the set of atoms cloud (D, , a)  (D  atoms(proof Q )), modulo appropriate
variable renaming; (iii) for the ordering , always choose the one given by proof Q . The
fact that no Q-instance is lost when replacing configurations by their canonical versions is
guaranteed by Corollary 5.21.
Computational cost. In case of bounded arity, the size of each configuration c
is polynomial in D  . Thus, Acheck describes an alternating pspace (i.e., apspace)
computation. It is well-known that apspace = exptime. In case the arity is not bounded,
each configuration requires at most exponential space. The algorithm then describes a
computation in Alternating expspace, which is equal to 2exptime.

147

fiCal, Gottlob & Kifer

Corollary 5.23. Let  be a weakly guarded set of TGDs, and let D be a database over
a schema R. Then, computing chase  (D, ) can be done in exponential time in case of
bounded arity, and in double exponential time otherwise.
Proof. It is sufficient to start with an empty set A and then cycle over ground atoms b in
the Herbrand base HB (D) while checking whether chase(D, ) |= b. If this holds, we add
b to A. The result is chase  (D, ). The claimed time bounds follow straightforwardly.
We can now finally state our independent proof of Theorem 5.9.
Proof of Theorem 5.9. We construct an algorithm Qcheck such that Qcheck(D, , Q) outputs
true iff D   |= Q (i.e., iff chase(D, ) |= Q). The algorithm relies on the notion of squid
decompositions, and on Lemma 5.8; it works as follows.
(1) Qcheck starts by computing chase  (D, ).
(2) Qcheck nondeterministically guesses a squid decomposition  = (Q+ , h, H, T ) of Q
based on a set V  vars(h(Q+ )), where H = {a  h(Q+ ) | vars(a)  V } and T is
[V ]-acyclic. Additionally, Qcheck guesses a substitution 0 : V  dom(D) such that
0 (H)  chase  (D, ). Note that this is an np guess, because the number of atoms
in Q+ is at most twice the the number of atoms in Q.
(3) Qcheck checks whether 0 can be extended to a homomorphism  such that (T ) 
chase + (D, ). By Lemma 5.8, this is equivalent to check if chase(D, ) |= Q. Such
a  exists iff for each connected subgraph t of 0 (T ), there is a homomorphism t
such that t (t)  chase + (D, ). The Qcheck algorithm thus identifies the connected
components of 0 (T ). Each such component is a [dom(D)]-acyclic conjunctive query,
some of whose arguments may contain constants from dom(D). Each such component
can thus be represented as a [dom(D)]-join tree t. For each such join tree t, Qcheck
now tests whether there exists a homomorphism t such that t (t)  chase + (D, ).
This is done by the subroutine Tcheck, that takes the TGD set , the database D,
and a connected subgraph (i.e., a subtree) t of 0 (T ) as input. The inner workings of
Tcheck(D, , t) are described below.
(4) Qcheck outputs true iff the above check (3) gives a positive result.
The correctness of Qcheck follows from Lemma 5.8. Given that step (2) is nondeterministic, the complexity of Qcheck is in npX , i.e., np with an oracle in X, where X is
a complexity class that is sufficiently powerful for: (i) computing chase  (D, ), and (ii)
performing the tests Tcheck(D, , t).
We now describe the Tcheck subroutine.
General notions. Tcheck(D, , t) is obtained from Acheck via the following modifications. Each configuration of Tcheck maintains a pointer Tpoint to a vertex of t (an atom
aq ). Intuitively, this provides a link to the root of the subtree of t that still needs to be
matched by descendant configurations of c. In addition to the data structures carried by
each configuration of Acheck, each configuration of Tcheck also maintains an array subst
of length w, where w is the maximum predicate arity in R. Informally, subst encodes a
substitution that maps the current atom of t to (the canonicalized version of) the current
atom of chase(D, ).
148

fiTaming the Infinite Chase

Tcheck works like Acheck, but instead of nondeterministically constructing a main configuration path of the configuration tree such that eventually some atom matches the query,
it nondeterministically constructs a main configuration (sub)tree  of the configuration tree,
such that eventually all atoms of the join tree t get consistently translated into some vertices
of  . An important component of each main configuration c of Tcheck is its current atom a.
Initially, a is some nondeterministically chosen atom of D. For subsequent configurations
of the alternating computation tree, a will take on nodes of gcf(D, ).
Initialization. Similarly to Acheck, the computation starts by generating an initial
configuration (a, S, S, , , Tpoint, subst), where a is nondeterministically chosen from the
database D, Tpoint points to the root r of t, and subst is a homomorphic substitution
that subst(r) = a, if r is homomorphically mappable on a; otherwise subst is empty. This
configuration will now be the root of the main configuration tree.
In general, the pointer Tpoint of each main configuration c = (a, S, S  , , , Tpoint, subst)
points to some atom aq of t, which has not yet been matched. The algorithm attempts to
expand this configuration by successively guessing a subtree of configurations, mimicking a
suitable subtree of gcf(D, ) that satisfies the subquery of t rooted at aq .
Whenever Tcheck generates a further configuration, just as for Acheck, Tcheck generates
via universal branching a number of configurations whose joint task is to verify that all
elements of S are indeed provable. (We do not provide further details on how this branching
is done.)
Expansion. The expansion of a main configuration c = (a, S, S  , , , Tpoint, subst)
works as follows. For a configuration c, Tcheck first checks whether there exists a homomorphism  such that (subst(aq )) = a.
1. ( exists.) If  exists, we have two cases:
1.1. If aq is a leaf of t, then the current configuration turns into an accepting one.
1.2. If aq is not a leaf of t, then Tcheck nondeterministically guesses whether  is
a good match, i.e., one that contributes to a global query answer and can be
expanded to map the entire tree t into gcf(D, ).
1.2.1. (Good match). In case of a good match, Tcheck branches universally and
does the following for each child aqs of aq in t. It nondeterministically (i.e.,
via existential branching) creates a new configuration
cs = can as (as , Ss , Ss , s , , Tpoints , substs )
where Tpoints points to aqs , and where substs encodes the composition  
substs . The atom as is guessed, analogously to what is done in Acheck, by
guessing some TGD    having body  and head atom , such that
the guard atom g matches a via some homomorphism  (that is, (g) = a)
and where ()  S  . The cloud subsets Ss and Ss are chosen again as in
Acheck. Intuitively, here Tcheck, having found a good match of aq on a, tries
to match the children of aq in t to children (and, eventually, descendants)
of a in gcf(D, ). Finally, the function can as indicates that appropriate
canonizations are made to obtain cs from c (we omit the tedious details).
149

fiCal, Gottlob & Kifer

1.2.2. (No good match). In case no good match exists, a child configuration
cnew = cananew (anew , S, S  , , , Tpoint, subst)
of c is nondeterministically created, whose first component represents a child
anew of a, and where cnew inherits all of its remaining components from c.
Intuitively, after having failed at matching aq (to which, we remind, Tpoint
points) to a, Tcheck attempts at matching the same aq to some child of a in
gcf(D, ). By analogy with the previous case, anew is obtained by guessing
some TGD    having body  and head atom , such that the guard
atom g matches a via some homomorphism  (that is, (g) = a), ()  S  ,
and where anew := (). Again, the function term cananew indicates that
appropriate canonizations are applied (which we do not describe in detail).
2. ( does not exist.) In this case, Tcheck proceeds exactly as in case 1.2.2, namely, it
attempts at matching the same aq to some child (or eventually some descendant) of
a in gcf(D, ).
Correctness. The correctness of Tcheck can be shown along similar lines as for
Acheck. An important additional point to consider for Tcheck is that, given that the query
t is acyclic, it is actually sufficient to remember at each configuration c only the latest
atom substitution subst. The correctness of Qcheck then follows from the correctness of
Tcheck and from Lemma 5.8.
Computational cost. As for the complexity of Qcheck, note that in case the arity
is bounded, Tcheck runs in apspace = exptime, and computing chase  (D, ) is in exptime by Corollary 5.23. Thus, Qcheck runs in time npexptime = exptime. In case of
unbounded arities, both computing chase  (D, ) and running Tcheck are in 2exptime,
therefore Qcheck runs in time np2exptime = 2exptime.

By combining Theorems 4.1 and 5.9 we immediately get the following characterization
for the complexity of reasoning under weakly guarded sets of TGDs.
Theorem 5.24. Let  be a weakly guarded set of TGDs on a schema R, D a database for
R, and Q a Boolean conjunctive query. Determining whether D   |= Q or, equivalently,
whether chase(D, ) |= Q is exptime-complete in case of bounded predicate arities, even
if  is fixed and Q is atomic. In the general case of unbounded predicate arities, the same
problem is 2exptime-complete. The same completeness results hold for the problem of
query containment under weakly guarded sets of TGDs.
Generalization. The definition of WGTGDs can be generalized to classes of TGDs whose
unguarded positions are guaranteed to contain a controlled finite number of null-values
only. Let f be a computable integer function in two variables. Call a predicate position 
of a TGD set  f -bounded if no more than f (|D|, ||) null values appear in chase(D, ) as
arguments in position ; otherwise call  f -unbounded. A set  of TGDs is f -weakly guarded
if each each rule of  contains an atom in its body that covers all variables which occur
within this rule in f -unbounded positions only. By a very minor adaptation of the proof of
Theorem 3.14, it can be seen that CQ-answering for the class of f -weakly guarded TGDs
is decidable. Moreover, by a simple modification of the Qcheck and Tcheck procedures,
150

fiTaming the Infinite Chase

allowing a polynomial number of nulls to enter unguarded positions, it can be shown that
CQ-answering for fixed sets  of WGTGDs is exptime-complete in the worst case, where
the class of WGTGD sets is defined as follows. A set  of TGDs belongs to this class if
 is f -weakly guarded for some function f for which there exists a function g, such that
f (|D|, ||)| 6 |D|g(||) .

6. Guarded TGDs
We now turn our attention to GTGDs. We first consider the case of a variable database D
as input. Later, we prove part of the complexity bounds under the stronger condition of
fixed database.
6.1 ComplexityVariable Database
Theorem 6.1. Let  be a set of GTGDs over a schema R and D be a database for R. Let,
as before, w denote the maximum predicate arity in R and |R| the total number of predicate
symbols in R. Then:
(1) Computing chase  (D, ) can be done in polynomial time if both w and |R| are
bounded and, thus, also in case of a fixed set . The same problem is in exptime
(and thus exptime-complete) if w is bounded, and in 2exptime otherwise.
(2) If Q is an atomic or fixed Boolean query then checking whether chase(D, ) |= Q is
ptime-complete when both w and |R| are bounded. The same problem remains ptimecomplete even in case  is fixed. This problem is exptime-complete if w is bounded
and 2exptime-complete in general. It remains 2exptime-complete even when |R| is
bounded.
(3) If Q is a general conjunctive query, checking chase(D, ) |= Q is np-complete in
case both w and |R| are bounded and, thus, also in case of a fixed set . Checking
chase(D, ) |= Q is exptime-complete if w is bounded and 2exptime-complete in
general. It remains 2exptime-complete even when |R| is bounded.
(4) BCQ answering under GTGDs is np-complete if both w and |R| are bounded, even
in case the set  of GTGDs is fixed.
(5) BCQ answering under GTGDs is exptime-complete if w is bounded and 2exptimecomplete in general. It remains 2exptime-complete even when |R| is bounded.
Proof. First, note that items (4) and (5) immediately follow from the first three items,
given that chase(D, ) is a universal model. We therefore just need to prove items (1)-(3).
We first explain how the hardness results are obtained, and then deal with the matching
membership results.
Hardness Results. The ptime-hardness of checking chase(D, ) |= Q for atomic (and
thus also fixed) queries Q and for fixed  follows from the fact that ground atom inference
from a fixed fully guarded Datalog program over variable databases is ptime-hard. In fact,
in the proof of Theorem 4.4 in the work by Dantsin, Eiter, Gottlob, and Voronkov (2001)
it is shown that fact inference from a single-rule Datalog program whose body has a guard
atom that contains all variables is ptime-hard. The np-hardness in item (3) is immediately
derived from the hardness of CQ containment (which in turn is polynomially equivalent to
151

fiCal, Gottlob & Kifer

query answering) without constraints (Chandra & Merlin, 1977). The hardness results for
exptime and 2exptime are all derived via minor variations of the proof of Theorem 4.1.
For example, when |R| is unbounded and w is bounded, the tape cells of the polynomial
worktape are simulated by using polynomially many predicate symbols. For example, the
fact that in configuration v cell 5 contains symbol 1 can be encoded as S51 (v). We omit
further details, given that a much stronger hardness result will be established via a full
proof in Theorem 6.2.
Membership results. The membership results are proved exactly as those for weakly
guarded sets of TGDs, except that instead of using the concept of cloud, we now use a
similar concept of restricted cloud, which coincides with that of a type of an atom in the
work by Cal et al. (2012a). The restricted cloud rcloud (D, , a) of an atom a  chase(D, )
is the set of all atoms b  chase(D, ) such that dom(b)  dom(a). By a proof that
is almost identical to the one of Theorem 5.16, we can show that if D is a database, 
a set of GTGDs, and if a  chase(D, ), then r a = gcf[a, rcloud (D, , a)], where r a
is defined as r a = {a }  rcloud (D, , a). It follows that, for the main computational
tasks, we can use algorithms rAcheck, rQcheck, and rTcheck, which differ from the already
familiar Acheck, Qcheck, and Tcheck only in that restricted clouds instead of the ordinary
clouds are used. However, unlike the case when both |R| and w are bounded and a cloud
(or subcloud) can have polynomial size in |D  |, a restricted cloud rcloud (D, , a) has
a constant number of atoms, and storing its canonical version can a (rcloud (D, , a)) thus
requires logarithmic space only. In total, in case both |R| and w are bounded, due to the
use of restricted clouds (and subsets thereof) each configuration c of rAcheck and of rTcheck
only requires logarithmic space. Since alogspace = ptime, the ptime-results for atomic
queries in items (1) and (2) follow. Moreover, if both |R| and w are bounded, for general
(non-atomic and non-fixed) queries, the rQcheck algorithm decides if chase(D, ) |= Q in
np by guessing a squid decomposition (in nondeterministic polynomial time) and checking
(in alogspace=ptime) if there is a homomorphism from this squid decomposition into
chase(D, ). Thus, in this case, rQcheck runs in npptime = np, which proves the np upper
bound of Item (3). If, in addition, Q is fixed, then Q has only a constant number of squid
decompositions, and therefore rQcheck runs in ptimeptime = ptime, which proves the ptime
upper bound for fixed queries mentioned in item (2). The exptime and 2exptime upper
bounds are inherited from the same upper bounds for WGTGDs.
Note that one of the main results by Johnson and Klug (1984), namely, that query
containment under inclusion dependencies of bounded arities is np-complete, is a special
case of Item (3) of Theorem 6.1.
6.2 ComplexityFixed Database
The next result tightens parts of Theorem 6.1 by showing that the above exptime and
2exptime-completeness results hold even in case of a fixed input database.
Theorem 6.2. Let  be set of GTGDs on a schema R. As before, let w denote the
maximum arity of predicate in R and |R| be the total number of predicate symbols. Then,
for fixed databases D, checking whether chase(D, ) |= Q is exptime-complete if w is
152

fiTaming the Infinite Chase

bounded and 2exptime-complete for unbounded w. For unbounded w, this problem remains
2exptime-complete even when |R| is bounded.
Proof. First, observe that the upper bounds (i.e., the membership results for exptime and
2exptime) are inherited from Theorem 6.1, so it suffices to prove the hardness results for
the cases where Q is a fixed atomic query.
We start by proving that checking chase(D, ) |= Q is exptime-hard if w is bounded.
It is well-known that apspace (alternating pspace) equals exptime.
As already noted in the proof of Theorem 4.1, it is sufficient to simulate an linspace
alternating Turing machine (ATM) M that uses at most n worktape cells on every input
(bit string) I of size n, where the input string is initially present on the worktape. In
particular, we will show that M accepts the input I iff chase(D, ) |= Q.
Without loss of generality, we assume that (i) ATM M has exactly one accepting state,
a, which is also a halting state; (ii) the initial state of M is an existential state; (iii) M
alternates at each transition between existential and universal states; and (iv) M never
tries to read beyond its tape boundaries.
Let M be defined as M = (S, , , q0 , {sa }), where S is the set of states,  = {0, 1, }
is the tape alphabet,    is the blank tape symbol,  : S    (S    {, r, })2
is the transition function ( denotes the stay head move, while  and r denote left
and right respectively), q0  S is the initial state, and {sa } is the singleton set of final
(accepting) states. Since M is an alternating TM, its set of states S is partitioned into
two sets, S and S universal and existential states, respectively. The general idea of the
encoding is that the different configurations of M on input I of length n will be represented
by fresh nulls that are generated in the construction of the chase.
Let us now describe the schema R. First, for each integer 1 6 i 6 n, R contains the
predicate head i /1, such that head i (c) be true iff at configuration c the head of M is over
the tape cell i. R also has the predicates zero i /1, one i /1, and blank i /1, where zero i (c),
one i (c), and blank i (c) are true if in configuration c the tape cell i contains the symbol 0, 1,
or , respectively. Furthermore, for each state s  S, R has a predicate state s /1, such that
state s (c) is true iff the state of configuration c is s. R also contains: the predicate start/1,
where start(c) is true iff c is the starting configuration; the predicate config/1, which is true
iff its argument identifies a configuration; and the predicate next/3, where next(c, c1 , c2 )
is true if c1 and c2 are the two successor configurations of c. There are also predicates
universal /1 and existential /1, such that universal (c) and existential (c) are true if c is a
universal (respectively, existential) configuration. Finally, there is a predicate accepting/1,
where accepting(c) is true only for accepting configurations c, and a propositional symbol
accept, which is true iff the Turing Machine M accepts the input I.
We now describe a set (M, I) of GTGDs that simulates the behavior of M on input
I. The rules of (M, I) are as follows.
1. Initial configuration generation rules. The following rule creates an initial state: 
X init(X). We also add a rule init(X)  config(X), which says that the initial
configuration is, in fact, a configuration.
2. Initial configuration rules. The following set of rules encodes the tape content of the
initial configuration, that is, the input string I. For each 1 6 i 6 n, if the i-th cell
of the tape contains a 0, we add the rule init(X)  zero i (X); if it contains a 1, we
153

fiCal, Gottlob & Kifer

add init(X)  one i (X). We also add the rule init(X)  existential (X) in order
to say, without loss of generality, that the initial configuration is an existential one.
Moreover, we add the rules init(X)  head 1 (X) and init(X)  state s0 (X) to define
the initial values of the state and the head position of M on input I.
3. Configuration generation rules. We add a rule that creates two successor configuration
identifiers for each configuration identifier. Moreover, we add rules stating that these
new configuration identifiers indeed identify configurations:
config(X)  X1 ,X2 next(X, X1 , X2 ),
next(X, Y, Z)  config(Y ),
next(X, Y, Z)  config(Z).
4. Transition rules. We show by example how transition rules are generated for each
transition in the finite control. Assume, for instance, that the transition table contains
a specific transition of the form: (s, 0)  ( (s1, 1, r) , (s2, 0, ) ). Then we assert the
following rules, for 1 6 i 6 n:
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  state s1 (X1 )
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  state s2 (X2 ).
Moreover, for each 1 6 i < n we have these rules:
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  one i (X1 )
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  head i+1 (X1 ),
and for each 1 < i 6 n we add these rules:
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  zero i (X2 )
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  head i1 (X2 )
The other types of transition rules are constructed analogously. Note that the total
number of rules added is 6n times the number of transition rules. Hence it is linearly
bounded by the size n of the input string I to M.
5. Inertia rules. These rules state that tape cells in positions not under the head keep
their values. Thus, for each 1 6 i, j 6 n such that i 6= j we add the rules:
head i (X), zero j (X), next(X, X1 , X2 )  zero j (X1 )
head i (X), one j (X), next(X, X1 , X2 )  one j (X1 )
head i (X), blank j (X), next(X, X1 , X2 )  blank j (X1 ),
6. Configuration-type rules. These rules say that the immediate successor configurations
of an existential configuration are universal, and vice-versa:
existential (X), next(X, X1 , X2 )  universal (X1 )
existential (X), next(X, X1 , X2 )  universal(X2 )
universal (X), next(X, X1 , X2 )  existential (X1 )
universal (X), next(X, X1 , X2 )  existential (X2 ).
154

fiTaming the Infinite Chase

7. Acceptance rules. These recursive rules state when a configuration is accepting:
state sa (X)  accepting(X)
existential (X), next(X, X1 , X2 ), accepting(X1 )  accepting(X)
existential (X), next(X, X1 , X2 ), accepting(X2 )  accepting(X)
universal (X), next(X, X1 , X2 ), accepting(X1 ), accepting(X2 )  accepting(X)
init(X), accepting(X)  accept.
This completes the description of the set of TGDs (M, I). Note that this set is guarded,
has maximum predicate arity 3, can be obtained in logarithmic space from I and the
constant machine description of M. It faithfully simulates the behavior of the alternating
linear space machine M in input I. It follows that (M, I) |= accept iff M accepts input I.
Let D0 denote the empty database, and let Q0 be the ground-atom query accept. We then
have that (M, I)  D0 |= Q0 iff M accepts input I. This shows that answering ground
atom queries on fixed databases constrained by bounded arity GTGDs is exptime-hard.
Let us now illustrate how we obtain the 2exptime hardness result for guarded TGDs
when arities are unbounded, but when the number |R| of predicate symbols of the schema R
is bounded by a constant. Given that aexpspace=2exptime (aexpspace  alternating
aexpspace), our aim is now to simulate an aexpspace Turing machine. It is sufficient
to simulate one that uses no more than 2n worktape cells, since the acceptance problem
for such machines is already 2exptime-hard. In fact, by trivial padding arguments, the
acceptance problem for every aexpspace machine can be transformed in polynomial time
into the acceptance problem for one using at most 2n worktape cells.
The problem is, however, that now we can no longer construct a polynomial number of
rules that explicitly address each worktape cell i, or each pair of cells i, j, since now there
is an exponential number of worktape cells. The idea now is to encode tape cell indexes
as vectors of symbols (v1 , . . . , vk ) where vi  {0, 1}. As in the proof of Theorem 4.1, we
could define, with a polynomial number of rules, a successor relation succ that stores pairs
of indexes as succ(v1 , . . . , vk , w1 , . . . , wk ). However, there is a further difficulty: we now
have two different types of variables: the variables Vi , Wj that range over the bits vi , wi in
the above-described bit vectors, and the variables X, Y, Z that range over configurations.
A major difficulty is that, given that our rules are all guarded, we must make sure that
these two types of variables, whenever they occur elsewhere in a rule body, also occur in
some guard. To this end, we will use a fixed database D01 that contains the single fact
zeroone(0, 1), and we will construct a guard relation g such that for each vector v of
n bits and its binary successor w, and for each configuration x with its two successor
configurations y and z, the relation g contains a tuple g(v, w, x, y, z). We will use several
auxiliary relations to construct g.
For technical reasons, the first two arguments of some atoms below will be dummy
variables T0 and T1 that will always be forced to take the values 0 and 1, respectively.
This way, where convenient, we will have the values 0 and 1 available implicitly in form of
variables, and we will not need to use these constants explicitly in our rules.
Given that our database is now non-empty, we do not need to create the initial configuration identifier via an existential rule as before. We can simply take 0 as the identifier
155

fiCal, Gottlob & Kifer

of this initial configuration: zeroone(T0 , T1 )  init(T0 , T1 , T0 ). (Here, the first two arguments of init(T0 , T1 , T0 ) just serve, as explained, to carry the values 0 and 1 along.) We
also add: init(T0 , T1 , T0 )  config(T0 , T1 , T0 ) to assert that 0 is the identifier of the initial
configuration. Next we present the new configuration generation rules.
config(T0 , T1 , X)  Y, Z next(T0 , T1 , X, Y, Z),
next(T0 , T1 , X, Y, Z)  config(T0 , T1 , Y ),
next(T0 , T1 , X, Y, Z)  config(T0 , T1 , Z).
We use further rules to create a relation b such that each atom b(0, 1, v, x, y, z) contains
a tuple for each vector v of n bits, and for each configuration x. For better readability,
whenever useful, we will use superscripts for indicating the arity of vector variables: for
instance, V(n) denotes V1 , . . . , Vn . Moreover, 0(j) denotes the vector of j zeros and 1(j) the
vector of j ones. We start with the rule next(T0 , T1 , X, Y, Z)  b(T0 , T1 , T0 (n) , X, Y, Z),
which defines an atom b(0, 1, 0(n) , x, y, z), for each configuration x and its next-successors
y and z.
The following n rules, for 1 6 i 6 n, generate an exponential number of new atoms, for
each triple X, Y, Z, by swapping 0s to 1s in all possible ways. Eventually, the chase will
generate all possible prefixes of n bits.
b(T0 , T1 , U1 , . . . , Ui1 , T0 , Ui+1 , . . . , Un , X, Y, Z) 
b(T0 , T1 , U1 , . . . , Ui1 , T1 , Ui+1 , . . . , Un , X, Y, Z).
We are now ready to define the guard-relation g through another group of guarded rules.
For each 0 6 r < n, we add:
b(T0 , T1 , U(r) , T0 , T1 (nr1) , X, Y, Z)  g(U(r) , T0 , T1 (nr1) , U(r) , T1 , T0 (nr1) , X, Y, Z).
The above n rules define an exponential number of cell-successor pairs for each triple of
configuration identifiers X, Y, Z, where Y and Z are the next configurations following
X. In particular, the relation g contains precisely all tuples g(v, w, x, y, z), such that v is
an n-ary bit vector, w is its binary successor, x is a configuration identifier, y is its first
successor via the next relation, and z is its second successor via the next relation.
We are now ready to simulate an aexpspace Turing machine M over an input string
I by a set of GTGDs (M , I). Since this simulation is similar to the one presented in the
first part of this proof, we just sketch it and point out the main differences.
For the simulation, we use (in addition to the aforementioned auxiliary predicates)
predicates similar to the ones used earlier for the simulation of the exptime Turing machine
M. However, we only use a constant number of predicates. So, rather than using, atoms
head i (x), zero i (x) and so on, we use their vectorized versions head (v, x), zero(v, x) and so
on, where v is a bit vector of length n that takes the role of an exponential index. Thus,
for example, the equivalent of the earlier rule
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  one i (X1 )
is g(V, W, X, X1 , X2 ), head (V, X), zero(V, X), state(X, s)  one(V, X1 ). The earlier rule
head i (X), zero i (X), state s (X), next(X, X1 , X2 )  head i1 (X2 )
156

fiTaming the Infinite Chase

becomes g(V, W, X, X1 , X2 ), head (W, X), zero(W, X), state(X, s)  head (V, X2 ). It is
now straightforward to see how the initialization rules can be written. Informally, for
copying the input string I to the worktape, we place the n input bits of I on the tape by
writing a rule for each such bit. We then add rules that fill all positions from n + 1 to 2n
with blanks. As this can be done in a similar way as in the second part of the proof of
Theorem 4.1, we omit the details.
The only remaining issue is the specification of the inertia rules. These rules deal with
pairs i, j of different, not necessary adjacent, tape cell positions in our earlier simulation.
Here we have only adjacent cell positions available so far. The problem can be solved in
different ways. One possibility is described below.
We can simply modify the definition of the predicate b by adding a second vector of
n bits to the b-atoms so that b-atoms actually have the form b(T0 , T1 , v, u, x, y, z), where
v and u range over all possible distinct pairs of bit vectors of length n. This u vector is
then carried over to the g-atoms. We can thus assume that the g-atoms now have the form
g(v, w, u, x, y, z). The former inertia rule head i (X), zero j (X), next(X, X1 , X2 )  zero j (X1 )
would then become g(V, W, U, X, X1 , X2 ), head (W, X), zero(U, X)  zero(U, X1 ).
What remains to be defined are the configuration and the acceptance rules. The configuration rules are very similar to the ones used in the previous reduction, hence we leave
them as an exercise. The acceptance rules are as follows:
state(X, sa )  accepting(X)
existential (X), g(V, W, X, X1 , X2 ), accepting(X1 )  accepting(X)
existential (X), g(V, W, X, X1 , X2 ), accepting(X2 )  accepting(X)
universal (X), g(V, W, X, X1 , X2 ), accepting(X1 ), accepting(X2 )  accepting(X)
zeroone(T0 , T1 ), accepting(T0 )  accept.
This completes the description of the set of TGDs (M , I). Note that this set is
guarded and has a constant number of predicates. It can be obtained in logspace from I
and the constant machine description of M. It also faithfully simulates the behavior of the
alternating exponential space machine M on input I. It follows that (M , I) |= accept
iff M accepts input I. Let Q0 be the BCQ defined as Q0 = {accept}. We then have
D01  (M , I) |= Q0 iff M accepts input I. This shows that answering ground atomic
queries on fixed databases under guarded TGDs with a fixed number of predicate symbols
(but unbounded arity) is 2exptime-hard.

7. Polynomial Clouds Criterion
In the previous section we have seen that, in case of bounded arity, query answering under
weakly guarded sets of TGDs is exptime-complete, while query answering under GTGDs
is np-complete. Note that, for unrestricted queries and databases, np-completeness is the
best we can obtain. In fact, even in the absence of constraints, the BCQ answering problem
is np-complete (Chandra & Merlin, 1977).
In this section, we establish a criterion that can be used as a tool for recognizing relevant
cases where query answering is in np even for weakly guarded sets of TGDs that are not
fully guarded. Note that we consider both a setting where the weakly guarded set  of
157

fiCal, Gottlob & Kifer

TGDs is fixed and a setting where classes of TGD sets are considered. For these classes,
we require uniform polynomial bounds.
Definition 7.1. [Polynomial Clouds Criterion] A fixed weakly guarded set  of TGDs
satisfies the Polynomial Clouds Criterion (PCC ) if both of the following conditions hold:
1. There exists a polynomial () such that for each database D, |clouds(D, )/ | 6
(|D|). In other words, up to an isomorphism, there are only polynomially many
clouds.
2. There is a polynomial   () such that, for each database D and for each atom a:
 if a  D then cloud (D, , a) can be computed in time   (|D|, ||), and
 if a 6 D then cloud (D, , a) can be computed in time   (|D|, ||) starting with
D, a, and cloud (D, , b), where b is the predecessor of a in gcf(D, ).
We also say that  satisfies the PCC with respect to  and   . Note that in the
above, || is constant and can be omitted. However, the use of || is justified by the
following. A class C of weakly guarded TGD sets satisfies the PCC if there are fixed
polynomials  and   such that each TGD set in C satisfies the PCC uniformly with
respect to  and   (i.e., each TGD set in this class has ,   as a bound).
Theorem 7.2. Let  be a fixed weakly guarded set of TGDs over a schema R, such that 
enjoys the Polynomial Clouds Criterion. Then:
 Deciding for a database D and an atomic or fixed Boolean conjunctive query Q whether
D   |= Q (equivalently, whether chase(D, ) |= Q) is in ptime.
 Deciding for a database D and a general Boolean conjunctive query Q whether D |=
Q (equivalently, chase(D, ) |= Q) is in np.
Proof. A polynomial algorithm Acheck2 for atomic queries Q works as follows. We start
to produce the chase forest gcf(D, ) using the standard chase. In addition, immediately
after generating any node a and its cloud cloud (D, , a) (in polynomial time), we will store
can a (a, cloud (D, , a)) in a buffer, which we call cloud-store. Whenever a branch of the
forest reaches a vertex b such that can b (cloud (D, , b)) is already in the cloud-store, further
expansion of that branch b is blocked. Since there can be only a polynomial number of
pairs can a (a, cloud (D, , a)), the algorithm stops after a polynomial number of chase steps,
each step requiring only polynomial time. Now, by Corollary 5.17, the cloud-store already
contains all possible atoms of chase(D, ) and their clouds, up to isomorphism. To check
whether chase(D, ) |= Q holds for an atomic query Q, it is thus sufficient to test whether
every atom c that occurs in the cloud-store matches Q. In summary, Acheck2 runs in ptime.
The algorithm Qcheck2 for conjunctive queries works just like Qcheck, except that it
calls the algorithm Tcheck2 as a subroutine instead of Tcheck. The input to Tcheck2 is D,
Q, and also the cloud-store computed by Acheck2. We further assume that this cloud-store
identifies each entry e = can a (a, cloud (D, , a)) by a unique integer e# using O(log n) bits
only. Tcheck2 is an alternating algorithm that works essentially like Tcheck, except for the
following modifications:
 Tcheck always guesses the full cloud S = cloud (D, , a), instead of possibly guessing a
subcloud. In contrast, Tcheck2 just guesses the entry number e# of the corresponding
entry can a (a, cloud (D, , a)) of the cloud-store.
158

fiTaming the Infinite Chase

 Tcheck2 verifies correctness of the cloud guess in alogspace using D, a, e# , as well
as b and e# , where b is the main atom of the predecessor configuration and e is the
entry in the cloud-store featuring can b (b, cloud (D, , b)). Note that such verification
is effectively possible due to condition (2) of Definition 7.1.
 Tcheck2 only needs to compute the main configuration treethe one whose configurations contain . The algorithm does not compute the auxiliary branches, since they
are no longer necessary, as the correctness check S is done in a different way.
 The configurations of Tcheck2 do not need to guess or memorize linear orders  and
the set S + .
Given that Tcheck2 is an alogspace algorithm, Qcheck2 is an npalogspace procedure. Since
npalogspace = npptime = np, query answering is in np. In case of a fixed conjunctive query
Q, since Q has a constant number of squid decompositions, Qcheck2 runs in ptimeptime =
ptime.
Note that the Polynomial Clouds Criterion is not syntactic. Nevertheless, it is useful
for proving that query answering for some weakly guarded sets TGDs is in np, or even
in polynomial time for atomic queries. An application of this criterion is illustrated in
Section 10.
The following is a direct corollary of Theorem 6.1.
Theorem 7.3. (1) Every set  of GTGDs satisfies the PCC. (2) For any constant k, the
class of all GTGD sets of arity bounded by k satisfies the PCC.
The following result can be obtained by a minor adaptation of the proof of Theorem 7.2.
Theorem 7.4. Let  be a fixed weakly guarded set of TGDs that enjoys the Polynomial
Clouds Criterion, and let k be a constant. Then:
(1) For a database D and a Boolean conjunctive query of treewidth 6 k, deciding
whether D   |= Q (equivalently, chase(D, ) |= Q) is in ptime.
(2) The same tractability result holds for acyclic Boolean conjunctive queries.
By analogy to the PCC, one may define various other criteria based on other bounds.
In particular, we can define the Exponential Clouds Criterion (ECC) for classes of TGD
sets, which we will use in the next section, as follows:
Definition 7.5. [Exponential Clouds Criterion] Let C be a class of weakly guarded TGD
sets. C satisfies the Exponential Clouds Criterion (ECC) if both of the following conditions
are satisfied:
1. There is a polynomial () such that for every database D and any set of TGDs  in
C of size n, |clouds(D, )/ | 6 2(|D|+n) .
2. There exists a polynomial   () such that for every database D, any set of TGDs  in
C of size n, and any atom a:


 if a  D, then cloud (D, , a) can be computed in time 2 (|D|+n) , and

 if a 6 D, then cloud (D, , a) can be computed in time 2 (|D|+n) from D, a, and
cloud (D, , b), where b is the predecessor of a in gcf(D, ).
159

fiCal, Gottlob & Kifer

We have the following result on sets of TGDs enjoying the ECC:
Theorem 7.6. If  is a weakly guarded set of TGDs from a class C that enjoys the Exponential Clouds Criterion, then deciding for a database D and a Boolean conjunctive query
Q (atomic or not) whether D   |= Q is in exptime.
Proof (sketch). The proof is very similar to that for Theorem 7.2. The main difference is
that ptime and alogspace are replaced by exptime and apspace, respectively. We then
get that query answering for atomic queries is in apspace = exptime, and that answering
non-atomic queries is in npapspace = npexptime = exptime. Thus, in this case, there is no
difference between atomic and non-atomic query answering: both are in exptime.

8. TGDs with Multiple-Atom Heads
As mentioned in Section 2, all complexity results proved so far for single-headed TGDs also
carry over to the general case, where multiple atoms may appear in rule heads. We make
this claim more formal here.
Theorem 8.1. All complexity results derived in this paper for sets TGDs whose heads are
single-atoms are equally valid for sets of multi-atom head TGDs.
Proof (sketch). It suffices to show that the upper bounds carry over to the setting of TGDs
with multiple-atom heads. We exhibit a transformation from an arbitrary set of TGDs 
over a schema R to a set of single-headed TGDs  over a schema R that extends R with
some auxiliary predicate symbols.
The TGD set  is obtained from  by replacing each rule of the form r : body(X) 
head 1 (Y), head 2 (Y), . . . , head k (Y), where k > 1 and Y is the set of all the variables that
appear in the head, with the following set of rules:
body(X)  V (Y)
V (Y)  head 1 (Y)
V (Y)  head 2 (Y)
..
.
V (Y)  head k (Y),
where V is a fresh predicate symbol, having the same arity as the number of variables in
Y. Note that, in general, neither Y is contained in X not the other way around. It is
easy to see that, except for the atoms of the form V (Y), chase(D, ) and chase( , D)
coincide. The atoms of the form V (Y) have completely new predicates and thus do not
match any predicate symbol in the conjunctive query Q. Therefore, chase(D, ) |= Q iff
chase( , D) |= Q.
Obviously,  can be constructed in logspace from . Therefore, the extension of our
complexity results to the general case is immediate, except for the case of bounded arity.
Notice that the arity of each auxiliary predicate in the above construction depends on the
number of head-variables of the corresponding transformed TGD, which, in general, is not
bounded.
160

fiTaming the Infinite Chase

In case of bounded-arity WGTGDs, the exptime upper bound can still be derived
by the above transformation by showing that the class of TGD sets  obtained by that
transformation satisfies the Exponential Clouds Criterion of Section 7. To see that for each
database D and each such  there is only an exponential number of clouds, notice that
every large atom V (Y) is derived by a rule with a small weak guard g in its body,
i.e., a weak guard g of bounded arity. The cloud cloud (D,  , g) of this weak guard g
clearly determines everything below g in the guarded chase forest; in particular, the cloud
of V (Y). Thus the set clouds(D,  ) of all clouds of all atoms is only determined by the
clouds of atoms of bounded arity. For immediately verifiable combinatorial reasons, there
can be only singly-exponentially many such clouds. This shows that |clouds(D,  )/ | is
singly-exponentially bounded. Therefore, the first condition of Definition 7.5 is satisfied. It
is not too hard to verify the second condition of Definition 7.5, too. Thus, query-answering
based on bounded-arity WGTGDs is in exptime. Given that GTGDs are a subclass of
WGTGDs, the same exptime bound holds for bounded-arity GTGDs, as well.
A completely different proof of the above theorem follows directly from the results
by Gottlob, Manna, and Pieris (2013a) for the class of GTGDs, and from those by Gottlob,
Manna, and Pieris (2013b) for the class of WGTGDs.

9. EGDs
In this section we deal with equality generating dependencies (EGDs), a generalization of
functional dependencies, which, in turn, generalize key dependencies (Abiteboul, Hull, &
Vianu, 1995).
Definition 9.1. Given a relational schema R, an EGD is a first-order formula of the form
X(X)  X = Xk , where (X) is a conjunction of atoms over R, and X , Xk  X. Such
a dependency is satisfied in an instance B if, whenever there is a homomorphism h that
maps the atoms of (X) to atoms of B, we have h(X ) = h(Xk ).
It is possible to repair, or chase, an instance according to EGDs by analogy with the
chase based on TGDs. We start by defining the EGD chase rule.
Definition 9.2. [EGD Applicability] Consider an instance B of a schema R, and an EGD
 of the form (X)  Xi = Xj over R. We say that  is applicable to B if there is a
homomorphism h such that h((X))  B and h(Xi ) 6= h(Xj ).
Definition 9.3. [EGD Chase Rule] Let  be an EGD of the form (X)  Xi = Xj and
suppose that it is applicable to an instance B via a homomorphism h. The result of the
application of  on B with h is a failure if {h(Xi ), h(Xj )}   (because of the unique name
assumption). Otherwise, the result of this application is the instance B  obtained from B by
replacing each occurrence of h(Xj ) with h(Xi ) if h(Xi ) precedes h(Xj ) in lexicographical
order. If h(Xj ) precedes h(Xi ) then the occurrences of h(Xi ) are replaced with h(Xj )
,h

instead. We write B  B  to say that B  is obtained from B via a single EGD chase step.
Definition 9.4. [Chase sequence with respect to TGDs and EGDs] Let D be a database
and  = T  E , where T is a set of TGDs and E is a set of EGDs. A (possibly
infinite) chase sequence of D with respect to  is a sequence of instances B0 , B1 , . . . such
161

fiCal, Gottlob & Kifer

i ,hi

that Bi  Bi+1 , where B0 = D and i  T  E for all i > 0. A chase sequence is said
to be failing if its last step is a failure. A chase sequence is said to be fair if every TGD or
EGD that is applicable at a certain step is eventually applied.
In case a fair chase sequence happens to be finite, B0 , . . . , Bm , and no further rule application can change Bm , then the chase is well defined as Bm , and is denoted by chase(D, ).
For our purposes, the order of application of TGDs and EGDs is irrelevant. In the following
therefore, when saying the fair chase sequence, we will refer to any fair chase sequence,
chosen according to some order of application of the dependencies.
It is well-known (see Johnson & Klug, 1984) that EGDs cause problems when combined
with TGDs, because even for very simple types of EGDs, such as plain key constraints, the
implication problem for EGDs plus TGDs and the query answering problem are undecidable.
This remains true even for EGDs together with GTGDs. In fact, even though inclusion
dependencies are fully guarded TGDs, the implication problem, query answering, and query
containment are undecidable when keys are used as EGDs and inclusion dependencies as
TGDs (Chandra & Vardi, 1985; Mitchell, 1983; Cal et al., 2003a).
Moreover, while the result of an infinite chase using TGDs is well-defined as the limit of
an infinite, monotonically increasing sequence (or, equivalently, as the least fixed-point of a
monotonic operator), the sequence of sets obtained in the infinite chase of a database under
TGDs and EGDs is, in general, neither monotonic nor convergent. Thus, even though we
can define the chase procedure for TGDs plus EGDs, it is not clear how the result of an
infinite chase involving both TGDs and EGDs should be defined.
For the above reasons, we cannot hope to extend the positive results for weakly guarded
sets of TGDs, or even GTGDs, from the previous sections to include arbitrary EGDs.
Therefore, we are looking for suitable restrictions on EGDs, which would allow us to: (i)
use the (possibly infinite) chase procedure to obtain a query-answering algorithm, and
(ii) transfer the decidability results and upper complexity bounds derived in the previous
sections to the extended formalism.
A class that fulfills both desiderata is a subclass of EGDs, which we call innocuous
relative to a set of TGDs. These EGDs enjoy the property that query answering is insensitive
to them, provided that the chase does not fail. In other words, when  = T  E , where
T is a set of TGDs, E a set of EGDs, and E is innocuous relative to T , we can simply
ignore these EGDs in a non-failing chase sequence. This is possible because, intuitively, such
a non-failing sequence does not generate any atom that is not entailed by chase(D, T ).
More specifically, we start from the notion of innocuous application of an EGD. Intuitively, when making two symbols equal, an innocuous EGD application makes some atom
a equal to some other existing atom a0 ; this way, as the only consequence of the EGD
application, the original atom a is lost, but no new atom whatsoever is introduced. The
concept of innocuous EGD application is formally defined as follows.
Definition 9.5. [Innocuous EGD application] Consider a (possibly infinite) non-failing
chase sequence D = B0 , B1 , . . ., starting with a database D, with respect to a set  =
T  E , where T is a set of TGDs and E is a set of EGDs. We say that the EGD
,h

application Bi  Bi+1 , where   E and i > 0, is innocuous if Bi+1  Bi .
162

fiTaming the Infinite Chase

Notice that innocuousness is a semantic, not syntactic, property. It is desirable to have
innocuous EGD applications because such applications cannot trigger new TGD applications, i.e., TGD applications that were not possible before the EGD was applied.
Given that it might be undecidable whether a set of dependencies from a certain class
guarantees innocuousness of all EGD applications, one can either give a direct proof of
innocuousness for a concrete set of dependencies, as we will do in Section 10.2, or define
sufficient syntactic conditions that guarantee innocuousness of EGD applications for an
entire class of dependencies, as done, e.g., by Cal et al. (2012a).
Definition 9.6. Let  = T  E , where T is a set of TGDs and E a set of EGDs,
where  = T  E . E is innocuous for T if, for every database D such that the fair
chase sequence of D with respect to  is non-failing, each application of an EGD in such
sequence of D with respect to  is innocuous.
Theorem 9.7. Let  = T  E , where T is a set of TGDs and E a set of EGDs that is
innocuous for T . Let D be a database such that the fair chase sequence of D with respect
to  is non-failing. Then D   |= Q iff chase(D, T ) |= Q.
Proof. Consider the fair chase sequence B0 , B1 , . . . of D = B0 in the presence of , where
i ,hi

Bi  Bi+1 for i > 0 and   T  E . Let us define a modified chase procedure which
we call the blocking chase, denoted by blockchase(D, ). The blocking chase uses two sets:
a set C of blocked atoms and a set of (unblocked) atoms A. When started on a database
D such that D |= E (the case D 6|= E is not possible as this implies an immediate chase
failure), C is initialized to the empty set (C = ) and A is initialized to D. After the
initialization, the blocking chase attempts to apply the dependencies in T  E exactly
in the same way as in the standard fair chase sequence, with the following caveats. While
trying an application of hi , hi i:
 If i is a TGD, and if hi (body(i ))  C = , then apply hi , hi i and add the new atom
generated by this application to A.
 If i is a TGD and hi (body(i ))  C 6= , then the application of hi , hi i is blocked,
and nothing is done.
 If i is an EGD, then the application of hi , hi i proceeds as follows. Add to C all the
facts that in the standard chase disappear in that step (because Bi  Bi1 , due to the
innocuousness), i.e., add to C the set Bi  Bi1 . Thus, instead of eliminating tuples
from A, the blocking chase simply bans them from being used by putting them in C.
Note that, by the construction of blockchase(D, ), whenever the block chase encounters an
EGD i , hi , hi i is actually applicable, so blockchase(D, ) is well-defined. Let us use Ci and
Ai to denote the values of C and A at step i, respectively. Initially, C0 =  and A0 = D as
explained before. Observe that  = C0  C1  C2     and D = A0  A1  A2     are
monotonically increasing sequences that have least upper bounds C  = i Ci and A = i Ai ,
respectively. Clearly, (C  , A ) is the least fixpoint of the transformation performed by
blockchase(D, ) (with respect to component-wise set inclusion).
Now, let S be defined as S = A  C  . By the definition of S, we have: S |= .
Moreover, there is a homomorphism h that maps chase(D, T ) to S. Note that h is the
limit homomorphism of the sequence h1 , h2 , h3 , . . . (these hi s are the very homomorphisms
163

fiCal, Gottlob & Kifer

used while computing the block chase), and can be defined as the set of all pairs (x, y)
such that there exists an i > 0 such that hi (hi1 (   h1 (x))) = y and y is not altered by
any homomorphism hj for j > i. Note that for every instance B that contains D, we have
B |= D. In particular, S |= D. Putting everything together, we conclude that S |= D  .
It is also well-known (see Nash et al., 2006) that for any set of atoms M such that
M |= S  T , there is a homomorphism hM such that hM (chase(D, T ))  M . Now
assume D   |= Q. Then S |= Q and, because S  chase(D, T ), we also have that
chase(D, T ) |= Q. Conversely, if chase(D, T ) |= Q, then there is a homomorphism g,
such that g(Q)  chase(D, T ). Therefore, for any set of atoms M such that M |= D  ,
since hM (chase(D, T ))  M , we have hM (g(Q))  M . The latter means that M |= Q.
We now come to the problem of checking, given a database D and a set  = T  E ,
where T is set of WGTGDs and E are EGDs innocuous for T , whether the fair chase
,h

sequence (denoted B0 , B1 , . . .) of D with respect to  fails. Consider an application Bi 
Bi+1 , with   E of the form (X)  X = Xk . When this application causes the chase
to fail, we have that h(X ) and h(Xk ) are distinct values in dom(D). Notice that Bj exists
for j 6 i, while it does not exist for any j > i.
Lemma 9.8. Consider a database D and a set of dependencies  = T  E , where T
is a weakly guarded set of TGDs and E are EGDs that are innocuous for T . Then
the fair chase sequence of D with respect to  fails iff there is an EGD   E of the
form (X)  X = Xk and a homomorphism h such that h((X))  chase(D, T ),
h(X ) 6= h(Xk ), and {h(X ), h(Xk )}  dom(D).
Proof (sketch).
If. Let B0 , B1 , . . . be the fair chase sequence of D with respect to . First, it is not
difficult to show that, since E is innocuous relative to T , if the failure occurs at step 
i ,hi

then all EGD applications Bi  Bi+1 , such that i  E and i <   1, are innocuous
(see a similar proof by Cal, Console, & Frosini, 2013) in the sequence B0 , . . . , B1 . From
this, the if direction follows straightforwardly.
Only if. By assumption,  fails at some Bk , k > 1. Since applications of innocuous
EGDs can only remove tuples from the chase, it is easily seen that, if  is applicable to Bk via
an homomorphism h, then it is also applicable to chase(D, T ) via the same homomorphism
h, which settles the only-if part.
Theorem 9.9. Consider a database D and a set of dependencies  = T  E , where T
are GTGDs (resp., WGTGDs) and E are EGDs that are innocuous for T . Checking
whether the fair chase sequence of D with respect to  fails is decidable, and has the same
complexity as query answering for GTGDs (resp., WGTGDs) alone.
Proof (sketch). Let neq be a new binary predicate, which will serve as inequality. The
extension of neq is defined as dom(D)  dom(D)  {(d, d) | d  dom(D)} and can be
constructed in time quadratic in |dom(D)|. Now, for every EGD  of the form (X) 
X1 = X2 , where X1 , X2  X, we define the following Boolean conjunctive query (expressed
as a set of atoms): Q = (X)  {neq(X1 , X2 )}. Since, by construction, no new facts of
the form neq(1 , 2 ) are introduced in the chase, it is immediate to see, from Lemma 9.8,
164

fiTaming the Infinite Chase

that at least one of the above Q has a positive answer if and only if the fair chase sequence
of D with respect to  fails. By Theorem 9.7, answering the query Q can be done with
respect to the chase by T alone, which is decidable.
Let  = T  E be as in the above theorem, D be a database, and let Q be a query.
By the above theorem, we can check   D |= Q with the help of the following algorithm:
1. check whether the fair chase sequence of D with respect to  fails with the algorithm
described in Theorem 9.9;
2. if the fair chase sequence of D with respect to  fails, then return true and halt;
3. if D  T |= Q then return true; otherwise return false.
This gives us the following corollary:
Corollary 9.10. Answering general conjunctive queries under weakly guarded sets of TGDs
and innocuous EGDs is ptime reducible to answering queries of the same class under a
weakly guarded sets of TGDs alone, and thus has the same complexity.

10. Applications
In this section we discuss applications of our results on weakly guarded sets of TGDs to
Description Logic languages and object-oriented logic languages.
10.1 DL-Lite
DL-Lite (Calvanese et al., 2007; Artale et al., 2009) is a prominent family of ontology
languages that has tractable query answering. Interestingly, a restriction of GTGDs called
linear TGDs (which have exactly one body-atom and one head-atom) properly extends
most DL-Lite languages, as shown by Cal et al. (2012a). The complexity of query answering
under linear TGDs is lower than that of GTGDs, and we refer the reader to the work of Cal
et al. (2012a) for more details.
Furthermore, Cal et al. (2012a) also show that the language of GTGDs properly extends
the description logic EL as well as its extension ELf , which allows inverse and functional
roles. The fact that TGDs capture important DL-based ontology languages confirms that
TGDs are useful tools for ontology modeling and querying.
10.2 F-Logic Lite
F-Logic Lite is an expressive subset of F-logic (Kifer et al., 1995), a well-known formalism
introduced for object-oriented deductive languages. We refer the reader to the work by Cal
and Kifer (2006) for details about F-Logic Lite. Roughly speaking, compared to full FLogic, F-Logic Lite excludes negation and default inheritance, and allows only a limited
form of cardinality constraints. F-Logic Lite can be encoded by a set of twelve TGDs and
EGDs, below, which we denote by FLL :
1 : type(O, A, T ), data(O, A, V )  member(V, T ).
2 : sub(C1 , C3 ), sub(C3 , C2 )  sub(C1 , C2 ).
3 : member(O, C), sub(C, C1 )  member(O, C1 ).
165

fiCal, Gottlob & Kifer

4 : data(O, A, V ), data(O, A, W ), funct(A, O)  V = W .
Note that this is the only EGD in this axiomatization.
5 : mandatory(A, O)  V data(O, A, V ).
Note that this TGD has an existentially quantified variable in the head.
6 : member(O, C), type(C, A, T )  type(O, A, T ).
7 : sub(C, C1 ), type(C1 , A, T )  type(C, A, T ).
8 : type(C, A, T1 ), sub(T1 , T )  type(C, A, T ).
9 : sub(C, C1 ), mandatory(A, C1 )  mandatory(A, C).
10 : member(O, C), mandatory(A, C)  mandatory(A, O).
11 : sub(C, C1 ), funct(A, C1 )  funct(A, C).
12 : member(O, C), funct(A, C)  funct(A, O).
The results of this paper apply to the above set of constraints, since FLL is a weakly
guarded set, and the single EGD 4 is innocuous. The innocuousness of 4 is shown by
observing that, whenever the EGD is applied, it turns one atom into another; moreover,
all new data atoms created in the chase (see rule 5 ) have new labeled nulls exactly in the
position data[3], where the symbols to be equated also reside.
We now prove the relevant complexity results. We start by showing that BCQ answering
under F-Logic Lite is np-complete.
Theorem 10.1. Conjunctive query answering under F-Logic Lite rules is np-hard.
Proof (sketch). The proof is by reduction from the 3-colorability problem. Encode a
graph G = (V, E) as a conjunctive query Q which, for each edge (vi , vj ) in E, has two atoms
data(X, Vi , Vj ) and data(X, Vj , Vi ), where X is a unique variable. Let D be the database
D = {data(o, r, g), data(o, g, r), data(o, r, b), data(o, b, r), data(o, g, b), data(o, b, g)}. Then,
G is three-colorable iff D |= Q, which is the case iff D  FLL |= Q. The transformation
from G to (Q, D) is obviously polynomial, which proves the claim.
Theorem 10.2. Conjunctive query answering under F-Logic Lite rules is in np.
Proof (sketch). As mentioned before, we can ignore the only EGD in FLL since, being
innocuous, it does not interfere with query answering. Let FLL denote the set of TGDs
resulting from FLL by eliminating rule 4 , i.e., let FLL = FLL  {4 }. To establish
membership in np, it is sufficient to show that: (1) FLL is weakly guarded; (2) FLL enjoys
the PCC (see Definition 7.1). Under the above condition, the membership in np can be
proved by exhibiting the following. (i) An algorithm, analogous to Acheck, that constructs
all canonical versions of the atoms of the chase and their clouds (which are stored in a
cloud store), in polynomial time. Then the algorithm should check whether an atomic
(Boolean) query is satisfied by an atom in the cloud store. (ii) An algorithm, analogous
to Qcheck, that guesses (by calling an analogous version of Tcheck) entire clouds through
guessing the cloud index (a unique integer) in the cloud store. Then the algorithm should
check, in alternating logarithmic space (alogspace), the correctness of the cloud guess.
In that check, it can use only the cloud of the main atom of the predecessor configuration.
The complexity of running this algorithm is shown to be npalogspace = np.
(1) is easy: the affected positions are data[3], member[1], type[1], mandatory[2], funct[2]
and data[1]. It is easy to see that every rule of FLL is weakly guarded, and thus FLL is
weakly guarded.
166

fiTaming the Infinite Chase

Now let us sketch (2 ). We need to show that FLL satisfies the two conditions of
Definition 7.1. We prove that the first condition holds for FLL as follows. Let full
FLL =
FLL  {5 }. These are all full TGDs (no existentially-quantified variables) and their appli
cation does not alter the domain. We have chase(D, FLL ) = chase(chase(D, full
FLL ), FLL ).
full
Let us now have a closer look at D+ = chase(D, FLL ). Clearly, dom(D+ ) = dom(D). For
each predicate symbol p, let Rel (p) denote the relation consisting of all the p-atoms in D+ .
Let  be the family of all the relations that can be obtained from any of the relations Rel (p)
by performing an arbitrary selection followed by some projection (we forbid disjunctions in
the selection predicate). For example, let c, d  dom(D). Then  will contain the relations
1,2 ({1=c} Rel (data)), 2 ({1=d3=c} Rel (data)), and so on, where the numbers represent the
attributes to which selection is applied. Given that D+ is of size polynomial in D and that
the maximum arity of any relation Rel (p) is 3, the set  is of size polynomial in D+ and
thus polynomial in D. It can now be shown that  is preserved in a precise sense, when
going to the final result chase(D+ , FLL ): for each relation Rel  (p) corresponding to predicate p in the final chase result, when performing a selection on values outside of dom(D)
and projecting on the columns not used in the selection, the set of all tuples of dom(D)elements in the result is a relation in . For example, if v5 is a labeled null, then the set of
all T  dom(D), such that member(v5 , T ) is an element of the final result, is a relation in
. Similarly, if v7 and v8 are new values, the set of all values A, such that data(v7 , A, v8 )
is in the chase, is a relation in . From this it follows that FLL satisfies (2). In fact, all
possible clouds are determined by the polynomially many ways of choosing at most three
elements of  for each predicate. The proof of the preservation property can be done by
induction on the i-th new labeled null added. Roughly, for each such labeled null, created
by rule 5 , we just analyze which sets of values (or tuples) are attached to it via rules 4 ,
then 6 , 7 , 8 , 10 , and so on, and conclude that these sets were already present at the
next lower level, and thus, by induction hypothesis, are in .
The second condition of Definition 7.1 is proved by similar arguments.
From Theorems 10.1 and 10.2 we immediately get the following result.
Corollary 10.3. Conjunctive query answering under F-Logic Lite rules is np-complete for
general conjunctive queries, and in ptime for fixed-size or atomic conjunctive queries.

11. Conclusions and Related Work
In this paper we identified a large and non-trivial class of tuple-generating and equalitygenerating dependencies for which the problems of conjunctive query containment and answering are decidable, and provided the relevant complexity results. Applications of our
results span databases and knowledge representation. In particular, we have shown that
this class of constraints subsumes the classical work by Johnson and Klug (1984) as well as
more recent results from Cal and Kifer (2006). Moreover, we are able to capture relevant
ontology formalisms in the Description Logics (DL) family, in particular DL-Lite and EL.
The problem of query containment for non-terminating chase was addressed in the
database context by Johnson and Klug (1984), where the ontological theory contains inclusion dependencies and key dependencies of a particular form. The introduction of the
DL-Lite family of description logics in the works of Calvanese et al. (2007) and Artale et al.
167

fiCal, Gottlob & Kifer

(2009) was a significant leap forward in ontological query answering due to the expressiveness of DL-Lite languages and their tractable data complexity. Conjunctive query answering
in DL-Lite has the advantage of being first-order rewritable, i.e., any pair hQ, i, where Q
is a CQ and  is a DL-Lite ontology (TBox), can be rewritten as a first-order query Q
such that, for every database (ABox) D, the answer to Q against the logical theory D  
coincides with the answer to Q against D. Since each first-order query can be written in
SQL, in practical terms this means that a pair hQ, i can be rewritten as an SQL query
over the original database D.
Rewritability is widely adopted in ontology querying. The works by Cal, Calvanese,
De Giacomo, and Lenzerini (2001), and by Cal, Lembo, and Rosati (2003b) present query
rewriting techniques that deal with Entity-Relationship schemata and inclusion dependencies, respectively. The work by Perez-Urbina, Motik, and Horrocks (2010) presents a Datalog rewriting algorithm for the expressive DL ELHIO , which comprises a limited form of
concept and role negation, role inclusion, inverse roles, and nominals, i.e., concepts that are
interpreted as singletons. Conjunctive query answering in ELHIO is ptime-complete in
data complexity, and the proposed algorithm is also optimal for other ontology languages
such as DL-Lite. Optimizations of rewriting under linear TGDs (TGDs with exactly one
atom in the body) are presented by Gottlob, Orsi, and Pieris (2011), and by Orsi and Pieris
(2011). Gottlob and Schwentick (2012) showed that the rewriting of a conjunctive query
under a set of linear TGDs can be of polynomial size in the query and the TGD set.
Other rewriting techniques for ptime-complete languages (in data complexity) have been
proposed for the description logic EL (Rosati, 2007; Lutz, Toman, & Wolter, 2009; Krotzsch
& Rudolph, 2007). Another approach worth mentioning is a combination of rewriting and
of the chase (see Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2010); this technique
was introduced for DL-Lite in order to tackle the performance problems that arise when
the rewriting according to the ontology is too large.
Recent works concentrate on semantic characterization of sets of TGDs under which
query answering is decidable (Baget et al., 2011a). The notion of first-order rewritability is
tightly connected to that of finite unification set (FUS). A FUS is semantically characterized
as a set of TGDs that enjoy the following property: for every conjunctive query Q, the
rewriting Q of Q obtained by backward-chaining through unification, according to the
rules in , terminates. Another semantic characterization of TGDs is that of bounded
treewidth set (BTS), i.e., a set of TGDs such that the chase under such TGDs has bounded
treewidth. As seen in Section 3, every weakly guarded set of TGDs is a BTS. A finite
expansion set (FES) is a set of TGDs that guarantees, for every database, the termination
of the restricted chase, and therefore the decidability of query answering.
The Datalog family (Cal et al., 2011) has been proposed with the purpose of providing
tractable query answering algorithms for more general ontology languages. In Datalog , the
fundamental constraints are TGDs and EGDs. Clearly, TGDs are an extension of Datalog
rules. The absence of value invention (existential quantification in the head), thoroughly
discussed by Patel-Schneider and Horrocks (2007), is the main shortcoming of plain Datalog
in modeling ontologies and even conceptual data formalisms such as the Entity-Relationship
model (Chen, 1976). Sets of GTGDs or WGTGDs are Datalog ontologies. Datalog
languages easily extend the most common tractable ontology languages; in particular, the
168

fiTaming the Infinite Chase

main DL-Lite languages (see Cal et al., 2012a). The fundamental decidability paradigms
in the Datalog family are the following:
 Chase termination. When the chase terminates, a finite instance is produced; obviously, by Theorem 2.10, query answering in such a case is decidable. The most notable
syntactic restriction guaranteeing chase termination is weak acyclicity of TGDs, for
which we refer the reader to the milestone paper of Fagin et al. (2005). More general
syntactic restrictions are studied by Deutsch, Nash, and Remmel (2008), Marnette
(2009), Greco, Spezzano, and Trubitsyna (2011), Baget et al. (2011a), and Grau,
Horrocks, Krotzsch, Kupke, Magka, Motik, and Wang (2012). A semantic property
of TGDs, called parsimony, is introduced by Leone, Manna, Terracina, and Veltri
(2012). Parsimony ensures decidability of query answering by termination of a special
version of chase, called parsimonious chase.
 Guardedness. This is the paradigm we studied in this paper. A thorough study of
the data complexity of query answering under GTGDs and linear TGDs, a subset
of the guarded class, is found in the work by Cal et al. (2012a). The interesting
classes of frontier guarded (FGTGDs) and weakly frontier-guarded TGDs (WFGTGDs) were considered and studied by Baget et al. (2011a), Baget, Mugnier, Rudolph,
and Thomazo (2011b), and Krotzsch and Rudolph (2011). The idea underlying these
classes is that, to obtain decidability, it is sufficient to guard only frontier variables,
that is, variables that occur both in the body and in the head of a rule.8 WFGTGDs are syntactically more liberal and more succinct than WGTGDs, but conjunctive query answering under WFGTGDs is computationally more expensive in case of
bounded arities. It can be seen that querying under WFGTGDs is no more expressive
than querying under WGTGDs. In fact, for every WFGTGD set  and CQ Q, there
exists a WGTGD set  and a CQ Q such that for every database D, D   |= Q iff
D   |= Q . A generalization of WFGTGDs, called greedy bounded-treewidth TGDs,
was proposed by Baget et al. (2011b), together with a complexity analysis. The guardedness paradigm has been combined with acyclicity by Krotzsch and Rudolph (2011),
where a generalization of both WFGTGDs and weakly acyclic TGDs is proposed.
 Stickiness. The class of sticky sets of TGDs (or sticky Datalog , see Cal et al., 2012b)
is defined by means of syntactic restriction on the rule bodies, which ensure that each
sticky set of TGDs is first-order rewritable, being a FUS, according to Baget et al.
(2011a). Civili and Rosati (2012) have proposed an extension of sticky sets of TGDs.
The interaction between equality generating dependencies and TGDs has been the subject of several works, starting from the work of Johnson and Klug (1984), which deals with
functional and inclusion dependencies, proposing a class of inclusion dependencies called
key-based, which, intuitively, has no interaction with key dependencies thanks to syntactic
restrictions. The absence of interaction between EGDs and TGDs is captured by the notion
of separability, first introduced by Cal et al. (2003a) for key and inclusion dependencies,
and also adopted, though sometimes not explicitly stated, for instance, by Cal, Gottlob,
and Pieris (2012a), Artale et al. (2009) and Calvanese et al. (2007)see the work by Cal,
Gottlob, Orsi, and Pieris (2012b) for a survey on the topic.
8. FGTGDs were independently discovered by Mantas Simkus while working on his doctoral thesis.

169

fiCal, Gottlob & Kifer

As shown by Cal et al. (2012a), stratified negation can be added straightforwardly to
Datalog . More recently, guarded Datalog was extended by two versions of well-founded
negation (see Gottlob, Hernich, Kupke, & Lukasiewicz, 2012; Hernich, Kupke, Lukasiewicz,
& Gottlob, 2013).
In ontological query answering, normally both finite and infinite models of theories are
considered. In some cases, restricting the attention to finite solutions (models) only is not
always equivalent to the general approach. The property of equivalence between query
answering under finite models and query answering under arbitrary models (finite and
infinite) is called finite controllability, and it was proved for restricted classes of functional
and inclusion dependencies by Johnson and Klug (1984). Finite controllability was proved
for the class of arbitrary inclusion dependencies in a pioneering work by Rosati (2011). An
even more general result appears in the work of Barany et al. (2010), where it is shown that
finite controllability holds for guarded theories.
A related previous approach to guarded logic programming is guarded open answer set
programming (Heymans, Nieuwenborgh, & Vermeir, 2005). It is easy to see that a set of
GTGDs can be interpreted as a guarded answer set program, as defined by Heymans et al.
(2005), but guarded answer set programs are more expressive than GTGDs because they
allow negation.
Implementations of ontology-based data access systems take advantage of query answering techniques for tractable ontologies; in particular, we mention DLV (Leone et al., 2012),
Mastro (Savo, Lembo, Lenzerini, Poggi, Rodriguez-Muro, Romagnoli, Ruzzi, & Stella, 2010)
and NYAYA (De Virgilio, Orsi, Tanca, & Torlone, 2012).
Acknowledgments
This is the extended version of results by the same authors, published in the KR 2008 Conference and in the DL 2008 Workshop. Andrea Cal and Georg Gottlob are also affiliated
with the Oxford-Man Institute of Quantitative Finance, University of Oxford, UK. Andrea
Cal acknowledges support by the EPSRC project Logic-based Integration and Querying
of Unindexed Data (EP/E010865/1). Georg Gottlob acknowledges funding from the European Research Council under the European Communitys Seventh Framework Program
(FP7/2007-2013) / ERC grant agreement DIADEM no. 246858. Michael Kifer was partially supported by the NSF grant 0964196. The authors are grateful to Andreas Pieris,
Marco Manna, Michael Morak and the anonymous reviewers for their valuable comments
and suggestions to improve the paper.

References
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations of Databases. Addison-Wesley.
Adler, I., Gottlob, G., & Grohe, M. (2007). Hypertree width and related hypergraph invariants. Eur. Journal of Combinatorics, 28 (8), 21672181.
Aho, A., Sagiv, Y., & Ullman, J. D. (1979). Equivalence of relational expressions. SIAM
Journal of Computing, 8 (2), 218246.
Arenas, M., Bertossi, L. E., & Chomicki, J. (1999). Consistent query answers in inconsistent
databases. In Proc of PODS 1999, pp. 6879.
170

fiTaming the Infinite Chase

Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). The DL-lite family
and relations. J. Artif. Intell. Res., 36, 169.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL envelope. In Proc. of IJCAI 2005,
pp. 364369.
Baget, J.-F., Leclere, M., Mugnier, M.-L., & Salvat, E. (2011a). On rules with existential
variables: Walking the decidability line. Artif. Intell., 175 (910), 16201654.
Baget, J.-F., Mugnier, M.-L., Rudolph, S., & Thomazo, M. (2011b). Walking the complexity
lines for generalized guarded existential rules. In Proc. of IJCAI 2011, pp. 712717.
Barany, V., Gottlob, G., & Otto, M. (2010). Querying the guarded fragment. In Proc. of
LICS 2010, pp. 110.
Beeri, C., Fagin, R., Maier, D., Mendelzon, A. O., Ullman, J. D., & Yannakakis, M. (1981).
Properties of acyclic database schemes. In Proc. of STOC 1981, pp. 355362.
Beeri, C., & Vardi, M. Y. (1981). The implication problem for data dependencies. In
Proc. of ICALP 1981, pp. 7385.
Bourhis, P., Morak, M., & Pieris, A. (2013). The impact of disjunction on query answering
under guarded-based existential rules. In Proc. of IJCAI 2013.
Cabibbo, L. (1998). The expressive power of stratified logic programs with value invention.
Inf. Comput., 147 (1), 2256.
Cal, A., Calvanese, D., De Giacomo, G., & Lenzerini, M. (2001). Accessing data integration
systems through conceptual schemas. In Proc. of ER 2001, pp. 270284.
Cal, A., Console, M., & Frosini, R. (2013). On separability of ontological constraints.
Forthcoming.
Cal, A., Gottlob, G., & Kifer, M. (2008). Taming the infinite chase: Query answering under
expressive relational constraints. In Proc. of KR 2008, pp. 7080.
Cal, A., Gottlob, G., & Lukasiewicz, T. (2009). A general datalog-based framework for
tractable query answering over ontologies. In Proc. of PODS 2009, pp. 7786.
Cal, A., Gottlob, G., & Lukasiewicz, T. (2012a). A general datalog-based framework for
tractable query answering over ontologies. J. Web Semantics, 14, 5783. Extended
version of (Cal, Gottlob, & Lukasiewicz, 2009).
Cal, A., Gottlob, G., Orsi, G., & Pieris, A. (2012b). On the interaction of existential rules
and equality constraints in ontology querying. In Proc. of Correct Reasoning 2012,
pp. 117133.
Cal, A., Gottlob, G., & Pieris, A. (2011). New expressive languages for ontological query
answering. In Proc. of AAAI 2011.
Cal, A., Gottlob, G., & Pieris, A. (2012a). Ontological query answering under expressive
entity-relationship schemata. Inf. Syst., 37 (4), 320335.
Cal, A., Gottlob, G., & Pieris, A. (2012b). Towards more expressive ontology languages:
The query answering problem. Artif. Intell., 193, 87128.
Cal, A., & Kifer, M. (2006). Containment of conjunctive object meta-queries. In Proc. of
VLDB 2006, pp. 942952.
171

fiCal, Gottlob & Kifer

Cal, A., Lembo, D., & Rosati, R. (2003a). On the decidability and complexity of query
answering over inconsistent and incomplete databases. In PODS 2003, pp. 260271.
Cal, A., Lembo, D., & Rosati, R. (2003b). Query rewriting and answering under constraints
in data integration systems. In Proc. of IJCAI 2003, pp. 1621.
Cal, A., & Martinenghi, D. (2010). Querying incomplete data over extended er schemata.
TPLP, 10 (3), 291329.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning and efficient query answering in description logics: The DL-lite family. J.
Autom. Reasoning, 39 (3), 385429.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (2002). Description logics for information
integration. In Computational Logic: Logic Programming and Beyond, Vol. 2408 of
LNCS, pp. 4160. Springer.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998). On the decidability of query
containment under constraints. In Proc. of PODS 1998, pp. 149158.
Chandra, A. K., Kozen, D., & Stockmeyer, L. J. (1981a). Alternation. J. of the ACM,
28 (1), 114133.
Chandra, A. K., Lewis, H. R., & Makowsky, J. A. (1981b). Embedded implicational dependencies and their inference problem. In Proc. of STOC 1981, pp. 342354.
Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation of conjunctive queries in
relational data bases. In Proc. of STOC 1977, pp. 7790.
Chandra, A. K., & Vardi, M. Y. (1985). The implication problem for functional and inclusion
dependencies is undecidable. SIAM J. Comput., 14, 671677.
Chen, P. P. (1976). The entity-relationship model - toward a unified view of data. Trans.
Database Syst., 1 (1), 936.
Civili, C., & Rosati, R. (2012). A broad class of first-order rewritable tuple-generating
dependencies. In Proc. of Datalog 2.0 2012, pp. 6880.
Courcelle, B. (1990). The monadic second-order logic of graphs. I. recognizable sets of finite
graphs. Information and Computation, 85 (1), 1275.
Dantsin, E., Eiter, T., Gottlob, G., & Voronkov, A. (2001). Complexity and expressive
power of logic programming. ACM Computing Surveys, 33 (3), 374425.
De Virgilio, R., Orsi, G., Tanca, L., & Torlone, R. (2012). NYAYA: A system supporting
the uniform management of large sets of semantic data. In Proc. of ICDE 2012, pp.
13091312.
Deutsch, A., Nash, A., & Remmel, J. B. (2008). The chase revisited. In Proc. of PODS 2008,
pp. 149158.
Fagin, R. (1983). Degrees of acyclicity for hypergraphs and relational database schemes.
J. ACM, 30 (3), 514550.
Fagin, R., Kolaitis, P. G., Miller, R. J., & Popa, L. (2005). Data exchange: semantics and
query answering. Theor. Comput. Sci., 336 (1), 89124.
172

fiTaming the Infinite Chase

Goncalves, M. E., & Gradel, E. (2000). Decidability issues for action guarded logics. In
Proc. of DL 2000, pp. 123132.
Gottlob, G., Hernich, A., Kupke, C., & Lukasiewicz, T. (2012). Equality-friendly wellfounded semantics and applications to description logics. In Proc. of AAAI 2012.
Gottlob, G., Leone, N., & Scarcello, F. (2001). Hypertree decompositions: A survey. In
Proc. of MFCS 2001, pp. 3757.
Gottlob, G., Leone, N., & Scarcello, F. (2002). Hypertree decompositions and tractable
queries. J. Comp. Syst. Sci., 64 (3).
Gottlob, G., Leone, N., & Scarcello, F. (2003). Robbers, marshals, and guards: game theoretic and logical characterizations of hypertree width. J. Comput. Syst. Sci., 66 (4),
775808.
Gottlob, G., Manna, M., & Pieris, A. (2013a). Combining decidability paradigms for existential rules. To appear in TPLP.
Gottlob, G., Manna, M., & Pieris, A. (2013b). Querying hybrid fragments of existential
rules. Forthcoming.
Gottlob, G., & Nash, A. (2006). Data exchange: computing cores in polynomial time. In
Proc. of PODS 2006, pp. 4049.
Gottlob, G., Orsi, G., & Pieris, A. (2011). Ontological queries: Rewriting and optimization.
In Proc. of ICDE 2011, pp. 213.
Gottlob, G., & Schwentick, T. (2012). Rewriting ontological queries into small nonrecursive
datalog programs. In Proc. of KR 2012.
Gradel, E. (1999). On the restraining power of guards. J. Symb. Log., 64 (4), 17191742.
Grau, B. C., Horrocks, I., Krotzsch, M., Kupke, C., Magka, D., Motik, B., & Wang, Z.
(2012). Acyclicity conditions and their application to query answering in description
logics. In Proc. of KR 2012.
Greco, S., Spezzano, F., & Trubitsyna, I. (2011). Stratification criteria and rewriting techniques for checking chase termination. PVLDB, 4 (11), 11581168.
Hernich, A., Kupke, C., Lukasiewicz, T., & Gottlob, G. (2013). Well-founded semantics for
extended datalog and ontological reasoning. In Proc. of PODS 2013, pp. 225236.
Hernich, A., Libkin, L., & Schweikardt, N. (2011). Closed world data exchange. ACM
Trans. Database Syst., 36 (2), 1453.
Heymans, S., Nieuwenborgh, D. V., & Vermeir, D. (2005). Guarded open answer set programming. In Proc. of LPNMR 2005.
Johnson, D. S., & Klug, A. (1984). Testing containment of conjunctive queries under
functional and inclusion dependencies. J. Comp. Syst. Sci., 28, 167189.
Kifer, M., Lausen, G., & Wu, J. (1995). Logical foundations of object-oriented and framebased languages. J. ACM, 42, 741843.
Koch, C. (2002). Query rewriting with symmetric constraints. In Proc. of FoIKS 2002, pp.
130147.
173

fiCal, Gottlob & Kifer

Kontchakov, R., Lutz, C., Toman, D., Wolter, F., & Zakharyaschev, M. (2010). The combined approach to query answering in dl-lite. In Proc. of KR 2010.
Krotzsch, M., & Rudolph, S. (2007). Conjunctive queries for EL with composition of roles.
In Proc. of DL 2007.
Krotzsch, M., & Rudolph, S. (2011). Extending decidable existential rules by joining acyclicity and guardedness. In Proc. of IJCAI 2011, pp. 963968.
Leone, N., Manna, M., Terracina, G., & Veltri, P. (2012). Efficiently computable datalog;
programs. In Proc. of KR 2012.
Li, L., & Horrocks, I. (2003). A software framework for matchmaking based on semantic
web technology. In Proc. of WWW 2003.
Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering in the description
logic EL using a relational database system. In Proc. of IJCAI 2009, pp. 20702075.
Maier, D., Mendelzon, A. O., & Sagiv, Y. (1979). Testing implications of data dependencies.
Trans. Database Syst., 4 (4), 455469.
Mailharrow, D. (1998). A classification and constraint-based framework for configuration.
Artif. Intell. for Eng. Design, Anal. and Manuf., 12 (4), 383397.
Marnette, B. (2009). Generalized schema-mappings: from termination to tractability. In
Proc. of PODS 2009, pp. 1322.
Millstein, T., Levy, A., & Friedman, M. (2000). Query containment for data integration
systems. In PODS 2000.
Mitchell, J. C. (1983). The implication problem for functional and inclusion dependencies.
Inf. and Control, 56, 154173.
Nash, A., Deutsch, A., & Remmel, J. (2006). Data exchange, data integration, and chase.
Tech. rep. CS2006-0859, UCSD.
Orsi, G., & Pieris, A. (2011). Optimizing query answering under ontological constraints.
PVLDB, 4 (11), 10041015.
Patel-Schneider, P. F., & Horrocks, I. (2007). A comparison of two modelling paradigms in
the semantic web. J. Web Semantics, 5 (4), 240250.
Perez-Urbina, H., Motik, B., & Horrocks, I. (2010). Tractable query answering and rewriting
under description logic constraints. J. Appl. Logic, 8 (2), 186209.
Qian, X. (1996). Query folding. In Proc. of ICDE 1996, pp. 4855.
Rabin, M. O. (1969). Decidability of second-order theories and automata on infinite trees.
Trans. Am. Math. Soc., 141 (135), 4.
Rosati, R. (2007). On conjunctive query answering in EL. In Proc. of DL 2007.
Rosati, R. (2011). On the finite controllability of conjunctive query answering in databases
under open-world assumption. J. Comput. Syst. Sci., 77 (3), 572594.
Savo, D. F., Lembo, D., Lenzerini, M., Poggi, A., Rodriguez-Muro, M., Romagnoli, V.,
Ruzzi, M., & Stella, G. (2010). Mastro at work: Experiences on ontology-based data
access. In Proc. of Description Logics.

174

fiJournal of Artificial Intelligence Research 48 (2013) 23-65

Submitted 04/13; published 10/13

Learning Optimal Bayesian Networks:
A Shortest Path Perspective
Changhe Yuan

changhe.yuan@qc.cuny.edu

Department of Computer Science
Queens College/City University of New York
Queens, NY 11367 USA

Brandon Malone

brandon.malone@cs.helsinki.fi

Department of Computer Science
Helsinki Institute for Information Technology
Fin-00014 University of Helsinki, Finland

Abstract
In this paper, learning a Bayesian network structure that optimizes a scoring function
for a given dataset is viewed as a shortest path problem in an implicit state-space search
graph. This perspective highlights the importance of two research issues: the development
of search strategies for solving the shortest path problem, and the design of heuristic functions for guiding the search. This paper introduces several techniques for addressing the
issues. One is an A* search algorithm that learns an optimal Bayesian network structure
by only searching the most promising part of the solution space. The others are mainly
two heuristic functions. The first heuristic function represents a simple relaxation of the
acyclicity constraint of a Bayesian network. Although admissible and consistent, the heuristic may introduce too much relaxation and result in a loose bound. The second heuristic
function reduces the amount of relaxation by avoiding directed cycles within some groups
of variables. Empirical results show that these methods constitute a promising approach
to learning optimal Bayesian network structures.

1. Introduction
Bayesian networks are graphical models that represent uncertain relations between the
random variables in a domain compactly and intuitively. A Bayesian network is a directed
acyclic graph in which nodes represent random variables, and the arcs or lack of them
represent the dependence/conditional independence relations between the variables. The
relations are further quantified by a set of conditional probability distributions, one for
each variable conditioning on its parents. Overall, a Bayesian network represents a joint
probability distribution over the variables.
Applying Bayesian networks to real-world problems typically requires building graphical
representations of the problems. One popular approach is to use score-based methods to
find high-scoring structures for a given dataset (Cooper & Herskovits, 1992; Heckerman,
1998). Score-based learning has been shown to be NP-hard, however (Chickering, 1996).
Due to the complexity, early research in this area mainly focused on developing approximation algorithms such as greedy hill climbing approaches (Heckerman, 1998; Bouckaert,
1994; Chickering, 1995; Friedman, Nachman, & Peer, 1999). Unfortunately the solutions
found by these methods have unknown quality. In recent years, several exact learning algoc
2013
AI Access Foundation. All rights reserved.

fiYuan & Malone

rithms have been developed based on dynamic programming (Koivisto & Sood, 2004; Ott,
Imoto, & Miyano, 2004; Silander & Myllymaki, 2006; Singh & Moore, 2005), branch and
bound (de Campos & Ji, 2011), and integer linear programming (Cussens, 2011; Jaakkola,
Sontag, Globerson, & Meila, 2010; Hemmecke, Lindner, & Studeny, 2012). These methods
are guaranteed to find optimal solutions when able to finish successfully. However, their
efficiency and scalability leave much room for improvement.
In this paper, we view the problem of learning a Bayesian network structure that optimizes a scoring function for a given dataset as a shortest path problem. The idea is to
represent the solution space of a learning problem as an implicit state-space search graph,
such that the shortest path between the start and goal nodes in the graph corresponds to
an optimal Bayesian network. This perspective highlights the importance of two orthogonal
research issues: the development of search strategies for solving the shortest path problem,
and the design of admissible heuristic functions for guiding the search. We present several
techniques to address these issues. Firstly, an A* search algorithm is developed to learn an
optimal Bayesian network by focusing on searching the most promising parts of the solution
space. Secondly, two heuristic functions are introduced to guide the search. The tightness
of the heuristic determines the efficiency of the search algorithm. The first heuristic represents a simple relaxation of the acyclicity constraint of Bayesian networks such that each
variable chooses optimal parents independently. As a result, the heuristic estimate may
contain many directed cycles and result in a loose bound. The second heuristic, named
k-cycle conflict heuristic, is based on the same form of relaxation but tightens the bound
by avoiding directed cycles within some groups of variables. Finally, when traversing the
search graph, we need to calculate the cost for each arc being visited, which corresponds
to selecting optimal parents for a variable out of a candidate set. We present two data
structures for storing and querying the costs of all candidate parent sets. One is a set of
full exponential-size data structures called parent graphs that are stored as hash tables and
can answer each query in constant time. The other is a sparse representation of the parent
graph which only stores optimal parent sets to improve the space efficiency.
We empirically evaluated the A* algorithm empowered with different combinations of
the heuristic functions and parent graph representations on a set of UCI machine learning
datasets. The results show that even with the simple heuristic and full parent graph representation, A* can often achieve better efficiency and/or scalability than existing approaches
for learning optimal Bayesian networks. The k-cycle conflict heuristic and the sparse parent
graph representation further enabled the algorithm to achieve even greater efficiency and
scalability. The results indicate that our proposed methods constitute a promising approach
to learning optimal Bayesian network structures.
The remainder of the paper is structured as follows. Section 2 reviews the problem
of learning optimal Bayesian networks and reviews related work. Section 3 introduces the
shortest path perspective of the learning problem. The formulation of the search graph is
discussed in detail. Section 4 introduces two data structures that we developed to compute
and store optimal parent sets for all pairs of variables and candidate sets. The data structures are used to query the cost of each arc in the search graph. Section 5 presents the
A* search algorithm. We developed two heuristic functions for guiding the algorithm and
studied their theoretical properties. Section 6 presents empirical results for evaluating our
algorithm against several existing approaches. Finally, Section 7 concludes the paper.
24

fiLearning Optimal Bayesian Networks

2. Background
We first provide a brief summary of related work on learning Bayesian networks.
2.1 Learning Bayesian Network Structures
A Bayesian network is a directed acyclic graph (DAG) G that represents a joint probability
distribution over a set of random variables V = {X1 , X2 , ..., Xn }. A directed arc from Xi to
Xj represents the dependence between the two variables; we say Xi is a parent of Xj . We
use PAj to stand for the parent set of Xj . The dependence relation between Xj and PAj are
quantified using a conditional probability distribution, P (Xj |PAj ). The joint probability
distribution represented by G is factorized as the product
Q of all the conditional probability
distributions in the network, i.e., P (X1 , ..., Xn ) = ni=1 P (Xi |PAi ). In addition to the
compact representation, Bayesian networks also provide principled approaches to solving
various inference tasks, including belief updating, most probable explanation, maximum a
Posteriori assignment (Pearl, 1988), and most relevant explanation (Yuan, Liu, Lu, & Lim,
2009; Yuan, Lim, & Littman, 2011a; Yuan, Lim, & Lu, 2011b).
Given a dataset D = {D1 , ..., DN }, where each data point Di is a vector of values over
variables V, learning a Bayesian network is the task of finding a network structure that
best fits D. In this work, we assume that each variable is discrete with a finite number of
possible values, and no data point has missing values.
There are roughly three main approaches to the learning problem: score-based learning,
constraint-based learning, and hybrid methods. Score-based learning methods evaluate the
quality of Bayesian network structures using a scoring function and selects the one that has
the best score (Cooper & Herskovits, 1992; Heckerman, 1998). These methods basically
formulate the learning problem as a combinatorial optimization problem. They work well
for datasets with not too many variables, but may fail to find optimal solutions for large
datasets. We will discuss this approach in more detail in the next section, as it is the
approach we take. Constraint-based learning methods typically use statistical testings to
identify conditional independence relations from the data and build a Bayesian network
structure that best fits those independence relations (Pearl, 1988; Spirtes, Glymour, &
Scheines, 2000; Cheng, Greiner, Kelly, Bell, & Liu, 2002; de Campos & Huete, 2000; Xie &
Geng, 2008). Constraint-based methods mostly rely on results of local statistical testings,
so they can often scale to large datasets. However, they are sensitive to the accuracy of
the statistical testings and may not work well when there are insufficient or noisy data.
In comparison, score-based methods work well even for datasets with relatively few data
points. Hybrid methods aim to integrate the advantages of the previous two approaches and
use combinations of constraint-based and/or score-based methods for solving the learning
problem (Dash & Druzdzel, 1999; Acid & de Campos, 2001; Tsamardinos, Brown, & Aliferis,
2006; Perrier, Imoto, & Miyano, 2008). One popular strategy is to use constraint-based
learning to create a skeleton graph and then use score-based learning to find a high-scoring
network structure that is a subgraph of the skeleton (Tsamardinos et al., 2006; Perrier et al.,
2008). In this work, we do not consider Bayesian model averaging methods which aim to
estimate the posterior probabilities of structural features such as edges rather than model
selection (Heckerman, 1998; Friedman & Koller, 2003; Dash & Cooper, 2004).
25

fiYuan & Malone

2.2 Score-Based Learning
Score-based learning methods rely on a scoring function Score(.) in evaluating the quality of
a Bayesian network structure. A search strategy is used to find a structure G that optimizes
the score. Therefore, score-based methods have two major elements, scoring functions and
search strategies.
2.2.1 Scoring Functions
Many scoring functions can be used to measure the quality of a network structure. Some
of them are Bayesian scoring functions which define a posterior probability distribution
over the network structures conditioning on the data, and the structure with the highest
posterior probability is presumably the best structure. These scoring functions are best
represented by the Bayesian Dirichlet score (BD) (Heckerman, Geiger, & Chickering, 1995)
and its variations, e.g., K2 (Cooper & Herskovits, 1992), Bayesian Dirichlet score with
score equivalence (BDe) (Heckerman et al., 1995), and Bayesian Dirichlet score with score
equivalence and uniform priors (BDeu) (Buntine, 1991). Other scoring functions often have
the form of trading off the goodness of fit of a structure to the data and the complexity of
the structure. The goodness of fit is measured by the likelihood of the structure given the
data or the amount of information that can be compressed into a structure from the data.
Scoring functions belonging to this category include minimum description length (MDL)
(or equivalently Bayesian information criterion, BIC) (Rissanen, 1978; Suzuki, 1996; Lam
& Bacchus, 1994), Akaike information criterion (AIC) (Akaike, 1973; Bozdogan, 1987),
(factorized) normalized maximum likelihood function (NML/fNML) (Silander, Roos, Kontkanen, & Myllymaki, 2008), and the mutual information tests score (MIT) (de Campos,
2006). All of these scoring functions are decomposable, that is, the score of a network can
be decomposed into a sum of node scores (Heckerman, 1998).
The optimal structure G may not be unique because multiple Bayesian network structures may share the same optimal score1 . Two network structures are said to belong to the
same equivalence class (Chickering, 1995) if they represent the same set of probability distributions with all possible parameterizations. Score-equivalent scoring functions assign the
same score to structures in the same equivalence class. Most of the above scoring functions
are score equivalent.
We mainly use the MDL score in this work. Let ri be the number of states of Xi , Npai
be the number of data points consistent with PAi = pai , and Nxi ,pai be the number of data
points further constrained by Xi = xi . MDL is defined as follows (Lam & Bacchus, 1994).

M DL(G) =

X

M DL(Xi |PAi ),

i

1. That is why we often use an optimal instead of the optimal throughout this paper.

26

(1)

fiLearning Optimal Bayesian Networks

where
log N
K(Xi |PAi ),
2
X
Nxi ,pai
H(Xi |PAi ) = 
Nxi ,pai log
,
Npai
xi ,pai
Y
K(Xi |PAi ) = (ri  1)
rl .
Xl PAi

M DL(Xi |PAi ) = H(Xi |PAi ) +

(2)
(3)
(4)

The goal is then to find a Bayesian network that has the minimum MDL score. However,
our methods are by no means restricted to MDL; any other decomposable scoring function,
such as BIC, BDeu, or fNML, can be used instead without affecting the search strategy.
To demonstrate that, we will test BDeu in the experimental section. One slight difference
between MDL and the other scoring functions is that the latter scores need to be maximized
in order to find an optimal solution. But it is rather straightforward to translate between
maximization and minimization problems by simply changing the sign of the scores. Also,
we sometimes use costs to refer to the scores, as they also represent distances between the
nodes in our search graph.
2.2.2 Local Search Strategies
Given n variables, there are O(n2n(n1) ) directed acyclic graphs (DAGs). The size of
the solution space grows exponentially in the number of variables. It is not surprising that
score-based structure learning has been shown to be NP-hard (Chickering, 1996). Due to the
complexity, early research focused mainly on developing approximation algorithms (Heckerman, 1998; Bouckaert, 1994). Popular search strategies that were used include greedy hill
climbing, stochastic search, genetic algorithm, etc..
Greedy hill climbing methods typically begin with an initial network, e.g., an empty
network or a randomly generated structure, and repeatedly apply single edge operations,
including addition, deletion, and reversal, until finding a locally optimal network. Extensions to this approach include tabu search with random restarts (Glover, 1990), limiting
the number of parents or parameters for each variable (Friedman et al., 1999), searching
in the space of equivalence classes (Chickering, 2002), searching in the space of variable
orderings (Teyssier & Koller, 2005), and searching under the constraints extracted from
data (Tsamardinos et al., 2006). The optimal reinsertion algorithm (OR) (Moore & Wong,
2003) adds a different operator: a variable is removed from the network, its optimal parents
are selected, and the variable is then reinserted into the network with those parents. The
parents are selected to ensure the new network is still a valid Bayesian network.
Stochastic search methods such as Markov Chain Monte Carlo and simulated annealing
have also been applied to find a high-scoring structure (Heckerman, 1998; de Campos &
Puerta, 2001; Myers, Laskey, & Levitt, 1999). These methods explore the solution space
using non-deterministic transitions between neighboring network structures while favoring
better solutions. The stochastic moves are used in hope to escape local optima and find
better solutions.
Other optimization methods such as genetic algorithms (Hsu, Guo, Perry, & Stilson,
2002; Larranaga, Kuijpers, Murga, & Yurramendi, 1996) and ant colony optimization meth27

fiYuan & Malone

ods (de Campos, Fernndez-Luna, Gmez, & Puerta, 2002; Daly & Shen, 2009) have been
applied to learning Bayesian network structures as well. Unlike the previous methods which
work with one solution at a time, these population-based methods maintain a set of candidate solutions throughout their search. At each step, they create the next generation
of solutions randomly by reassembling the current solutions as in genetic algorithms, or
generating the new solutions based on information collected from incumbent solutions as in
ant colony optimization. The hope is to obtain increasingly better populations of solutions
and eventually find a good network structure.
These local search methods are quite robust in the face of large learning problems with
many variables. However, they do not guarantee to find an optimal solution. What is worse,
the quality of their solutions is typically unknown.
2.2.3 Optimal Search Strategies
Recently multiple exact algorithms have been developed for learning optimal Bayesian networks. Several dynamic programming algorithms are proposed based on the observation
that a Bayesian network has at least one leaf (Ott et al., 2004; Singh & Moore, 2005). A
leaf is a variable with no child variables in a Bayesian network. In order to find an optimal
Bayesian network for a set of variables V, it is sufficient to find the best leaf. For any leaf
choice X, the best possible Bayesian network is constructed by letting X choose an optimal
parent set PAX from V\{X} and letting V\{X} form an optimal subnetwork. Then the
best leaf choice is the one that minimizes the sum of Score(X, PAX ) and Score(V\{X})
for a scoring function Score(.). More formally, we have:
Score(V) = min {Score(V \ {X}) + BestScore(X, V \ {X})},
XV

(5)

where
BestScore(X, V \ {X}) =

min
Score(X, PAX ).
PAX V\{X}

(6)

Given the above recurrence relation, a dynamic programming algorithm works as follows. It first finds optimal structures for single variables, which is trivial. Starting with
these base cases, the algorithm builds optimal subnetworks for increasingly larger variable
sets until an optimal network is found for V. The dynamic programming algorithms can
find an optimal Bayesian network in O(n2n ) time and space (Koivisto & Sood, 2004; Ott
et al., 2004; Silander & Myllymaki, 2006; Singh & Moore, 2005). Recent algorithms have
improved the memory complexity by either trading longer running times for reduced memory consumption (Parviainen & Koivisto, 2009) or taking advantage of the layered structure
present within the dynamic programming lattice (Malone, Yuan, & Hansen, 2011b; Malone,
Yuan, Hansen, & Bridges, 2011a).
A branch and bound algorithm (BB) was proposed by de Campos and Ji (2011) for
learning Bayesian networks. The algorithm first creates a cyclic graph by allowing each
variable to obtain optimal parents from all the other variables. A best-first search strategy
is then used to break the cycles by removing one edge at a time. The algorithm uses an
approximation algorithm to estimate an initial upper bound solution for pruning. The
algorithm also occasionally expands the worst nodes in the search frontier in hope to find
28

fiLearning Optimal Bayesian Networks

Figure 1: An order graph of four variables.
better networks to update the upper bound. At completion, the algorithm finds an optimal
network structure that is a subgraph of the initial cyclic graph. If the algorithm ran out of
memory before finding the solution, it will switch to using a depth-first search strategy to
find a suboptimal solution.
Integer linear programming (ILP) has also been used to learn optimal Bayesian network
structures (Cussens, 2011; Jaakkola et al., 2010). The learning problem is cast as an integer
linear program over a polytope with an exponential number of facets. An outer bound
approximation to the polytope is then solved. If the solution of the relaxed problem is
integral, it is guaranteed to be the optimal structure. Otherwise, cutting planes and branch
and bound algorithms are subsequently applied to find the optimal structure. Recently a
similar method has been proposed to find an optimal structure by searching in the space of
equivalence classes (Hemmecke et al., 2012).
Several other methods can be considered optimal under the constraints that they enforce
on the network structure. For example, if optimal parents are selected for each variable, K2
finds an optimal network structure for a particular variable ordering (Cooper & Herskovits,
1992). The methods developed in (Ordyniak & Szeider, 2010; Kojima, Perrier, Imoto, &
Miyano, 2010) find an optimal network structure that must be a subgraph of a given super
graph.

3. A Shortest Path Perspective
This section introduces a shortest path perspective of the problem of learning a Bayesian
network structure for a given dataset.
3.1 Order Graph
The state space graph for learning Bayesian networks is basically a Hasse diagram containing
all of the subsets of the variables in a domain. Figure 1 visualizes the state space graph
for a learning problem with four variables. The top-most node with the empty set at layer
29

fiYuan & Malone

0 is the start search node, and the bottom-most node with the complete set at layer n is
the goal node, where n is the number of variables in a domain. An arc from U to U  {X}
represents generating a successor node by adding a new variable {X} to an existing set of
variables U; U is called a predecessor of U {X}. The cost of the arc is equal to the score of
selecting an optimal parent set for X out of U, i.e., BestScore(X, U). For example, the arc
{X1 , X2 }  {X1 , X2 , X3 } has a cost equal to BestScore(X3 , {X1 , X2 }). Each node at layer
i has ni successors as there are this many ways to add a new variable, and i predecessors as
there are this many leaf choices. We define expanding a node U as generating all successors
nodes of U.
With the search graph thus defined, a path from the start node to the goal node is defined
as a sequence of nodes such that there is an arc from each of the nodes to the next node
in the sequence. Each path also corresponds to an ordering of the variables in the order of
their appearance. For example, the path traversing nodes , {X1 }, {X1 , X2 }, {X1 , X2 , X3 },
{X1 , X2 , X3 , X4 } stands for the variable ordering X1 , X2 , X3 , X4 . That is why we also call
the search graph an order graph. The cost of a path is defined as the sum of the costs of
all the arcs on the path. The shortest path is then the path with the minimum total cost in
the order graph.
Given the shortest path, we can reconstruct a Bayesian network structure by noting
that each arc on the path encodes the choice of optimal parents for one of the variables
out of the preceding variables, and the complete path represents an ordering of all the
variables. Therefore, putting together all the optimal parent choices generates a valid
Bayesian network. By construction, the Bayesian network structure is optimal.
3.2 Finding the Shortest Path
Various methods can be applied to solve the shortest path problem. Dynamic programming
is considered to evaluate the order graph using a top down sweep of the order graph (Silander
& Myllymaki, 2006; Malone et al., 2011b). Layer by layer, dynamic programming finds an
optimal subnetwork for the variables contained in each node of the order graph based on
results from the previous layers. For example, there are three ways to construct a Bayesian
network for node {X1 , X2 , X3 }: using {X2 , X3 } as the subnetwork and X1 as the leaf, using
{X1 , X3 } as the subnetwork and X2 as the leaf, or using {X1 , X2 } as the subnetwork and X3
as the leaf. The top-down sweep makes sure that optimal subnetworks are already found
for {X2 , X3 }, {X1 , X3 }, and {X1 , X2 }. We only need to select optimal parents for the
leaves and identify the leaf that produces the optimal network for {X1 , X2 , X3 }. Once the
evaluation reaches the node in the last layer, a shortest path and, equivalently, an optimal
Bayesian network are found for the global variable set.
A drawback of the dynamic programming approach is its need to compute all the
BestScore(.) of all candidate parent sets for each variable. For n variables, there are
2n nodes in the order graph, and there are also 2n1 parent scores to be computed for each
variable, totally n2n1 scores. As the number of variables increases, computing and storing
the order and parent graphs quickly becomes infeasible.
In this paper, we propose to apply the A* algorithm (Hart, Nilsson, & Raphael, 1968)
to solve the shortest path problem. A* uses the heuristic function to evaluate the quality of
search nodes and only expand the most promising search node at each search step. Because
30

fiLearning Optimal Bayesian Networks

of the guidance of the heuristic functions, A* only needs to explore part of the search
graph in finding the optimal solution. However, in comparison to dynamic programming,
A* has the overhead of calculating heuristic values and maintaining a priority queue. The
actual relative performance between dynamic programming and A* thus depends on the
efficiency in calculating the heuristic values and the tightness of these values (Felzenszwalb
& McAllester, 2007; Klein & Manning, 2003).

4. Finding Optimal Parent Sets
Before introducing our algorithm for solving the shortest path problem, we first discuss how
to obtain the cost BestScore(X, U) for each arc U  U  {X} that we will visit in the
order graph. Recall that each arc involves selecting optimal parents for a variable from a
candidate set. We need to consider all subsets of the candidate set in finding the subset with
the best score. In this section, we introduce two data structures and related methods for
computing and storing optimal parent sets and scores for all pairs of variable and candidate
parent set.
All exact algorithms for learning Bayesian network structures need to calculate the
optimal parent sets and scores. We present a reasonable approach to the calculation in this
paper. Note, however, our approach is applicable to other algorithms, and vice versa.
4.1 Parent Graph
We use a data structure called parent graph to compute costs for the arcs of the order graph.
Each variable has its own parent graph. The parent graph for variable X is a Hasse diagram
consisting of all subsets of the variables in V \ {X}. Each node U stores the optimal parent
set PAX out of U which minimizes Score(X, PA X ) as well as BestScore(X, U) itself. For
example, Figure 2(b) shows a sample parent graph for X1 that contains the best scores of
all subsets of {X2 , X3 , X4 }. To obtain Figure 2(b), however, we first need to calculate the
preliminary graph in Figure 2(a) that contains the raw score of each subset U as the parent
set of X1 , i.e., Score(X1 , U). As Equation 3 shows, these scores can be calculated based on
the counts for particular instantiations of the parent and child variables.
We use an AD-tree (Moore & Lee, 1998) to collect all the counts from a dataset and
compute the scores. An AD-tree is an unbalanced tree structure that contains two types of
nodes, AD-tree nodes and varying nodes. An AD-tree node stores the number of data points
consistent with a particular variable instantiation; a varying node is used to instantiate the
state of a variable. A full AD-tree stores counts of data points that are consistent with
all partial instantiations of the variables. A sample AD-tree for two variables are shown in
Figure 3. For n variables with d states each, the number of AD-tree nodes in an AD-tree is
(d+1)n . It grows even faster than the size of an order or parent graph. Moore and Lee (1998)
also described a sparse AD-tree which significantly reduces the space complexity. Readers
are referred to that paper for more details. Our pseudo code assumes a sparse AD-tree is
used.
Given an AD-tree, we are ready to calculate the raw scores Score(X1 , .) for Figure 2(a).
There is an exponential number of scores in each parent graph. However, not all parent
sets can possibly be in the optimal Bayesian network; certain parent sets can be discarded
without ever calculating their values according to the following theorems by Tian (2000).
31

fiYuan & Malone

Figure 2: A sample parent graph for variable X1 . (a) The raw scores Score(X1 , .) for all
the parent sets. The first line in each node gives the parent set, and the second
line gives the score of using all of that set as the parents for X1 . (b) The optimal
scores BestScore(X1 , .) for each candidate parent set. The second line in each
node gives the optimal score using some subset of the variables in the first line as
parents for X1 . (c) The optimal parent sets and their scores. The pruned parent
sets are shown in gray. A parent set is pruned if any of its predecessors has a
better score.

X1 = *
X2 = *
C = 50
Vary
V
X1

Vary
V
X2

X1 = 0
X2 = *

X1 = 1
X2 = *

X1 = *
X2 = 0

X1 = *
X2 = 1

C = 20

C = 30

C = 25

C = 25

Vary
X2

Vary
X2

X1 = 0
X2 = 0

X1 = 0
X2 = 1

X1 = 1
X2 = 0

X1 = 1
X2 = 1

C = 15

C=5

C = 10

C = 20

Figure 3: An AD-tree.
We use these theorems to compute only the necessary MDL scores. Other scoring functions
such as BDeu also have similar pruning rules (de Campos & Ji, 2011). Algorithm 1 provides
the pseudo code for calculating the raw scores.
Theorem 1 In an optimal Bayesian network based on the MDL scoring function, each
2N
variable has at most log( log
N ) parents, where N is the number of data points.
32

fiLearning Optimal Bayesian Networks

Algorithm 1 Score Calculation Algorithm
Input: AD  sparse AD-tree of input data; V  input variables.
Output: Score(X, U) for each pair of X  V and U  V \ {X}
1: function calculateMDLScores(AD, V)
2:
for each Xi  V do
3:
calculateScores(Xi , AD)
4:
end for
5: end function
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:

function calculateScores(Xi, AD)
2N
for k  0 to log( log
 Prune due to Theorem 1
N ) do
for each U such that U  V \ {X}& |U| == k do
 All parent sets of size k
prune  f alse
for each Y  U do
if K(Xi |U) - Score(Xi , U \ {Y }) > 0 then
prune  true
 Prune due to Theorem 2
break
end if
end for
if prune ! = true then
Score(Xi , U)  log2 N K(Xi |U)
 Complexity term
for each instantiation xi , u of Xi , U do
 Log likelihood term
cF amily  GetCount({xi }  u,AD)
cP arents  GetCount(u, AD)
Score(Xi , U) Score(Xi , U) - cF amily  log cF amily
Score(Xi , U) Score(Xi , U) + cF amily  log cP arents
end for
end if
end for
end for
end function

Theorem 2 Let U and S be two candidate parent sets for X, U  S, and K(Xi |S) 
M DL(Xi |U) > 0. Then S and all supersets of S cannot possibly be optimal parent sets for
X.
After computing the raw scores, we compute the parent graph according to the following
theorem which has appeared in many earlier papers, e.g., see the work of Teyssier and
Koller (2005), and de Campos and Ji (2010). The theorem simply means that a parent set
is not optimal when a subset has a better score.
Theorem 3 Let U and S be two candidate parent sets for X such that U  S, and
Score(X, U)  Score(X, S). Then S is not the optimal parent set of X for any candidate set.
33

fiYuan & Malone

Algorithm 2 Computing parent graphs
Input: All necessary Score(X, U), X  V&U  V \ {X}
Output: Full parent graphs containing BestScore(X, U)
1: function calculateFullParentGraphs(V, Score(., .))
2:
for each X  V do
3:
for layer  0 to n do
 Propagate best scores down the graph
4:
for each U such that U  V \ {X}& |U| == layer do
5:
calculateBestScore(X, U, Score(., .))
6:
end for
7:
end for
8:
end for
9: end function
10:
11:
12:
13:
14:
15:
16:
17:

function calculateBestScore(X, U, Score(., .))
BestScore(X, U)  Score(X, U)
for each Y  U do
if BestScore(X, U \ {Y }) < BestScore(X, U) then
BestScore(X, U)  BestScore(X, U \ {Y })
end if
end for
end function

function getBestScore(X, U)
19:
return BestScore(X, U)
20: end function

 Propagate best scores

 Query BestScore(X, U)

18:

Therefore, when we generate a successor node U{Y } of U in the parent graph of X, we
check whether Score(X, U  {Y }) is smaller than BestScore(X, U). If so, we let the parent
graph node U{Y } record itself as the optimal parent set. Otherwise if BestScore(X, U) is
smaller, we propagate the optimal parent set in U to U{Y }. Because of such propagation,
we must have the following (Teyssier & Koller, 2005).
Theorem 4 Let U and S be two candidate parent sets for X such that U  S. We must
have BestScore(X, S)  BestScore(X, U).
A pseudo code for propagating the scores and computing the parent graph is outlined in
Algorithm 2. Figure 2(b) shows the parent graph with the optimal scores after propagating
the best scores from top to bottom.
During the search of the order graph, whenever we visit a new arc U  U  {X}, we
find its score by looking up the parent graph of variable X. For example, if we need to find
optimal parents for X1 out of {X2 , X3 }, we look up the node {X2 , X3 } in X1 s parent graph
to find the optimal parent set and its score. To make the look-ups efficient, we use hash
tables to organize the parent graphs so that the query can be answered in constant time.
34

fiLearning Optimal Bayesian Networks

parentsX1
scoresX1

{X2 , X3 }
5

{X3 }
6

{X2 }
8

{}
10

Table 1: Sorted scores and parent sets for X1 after pruning parent sets which are not
possibly optimal.
parentsX1
2
parentsX
X1
X3
parentsX1
4
parentsX
X1

{X2 , X3 }
1
1
0

{X3 }
0
1
0

{X2 }
1
0
0

{}
0
0
0

Table 2: The parentsX (Xi ) bit vectors for X1 . A 1 in line Xi indicates that the corresponding parent set includes variable Xi , while a 0 indicates otherwise. Note
that, after pruning, none of the optimal parent sets include X4 .

4.2 Sparse Parent Graphs
The full parent graph for each variable X exhaustively enumerates all subsets of V \ {X}
and stores BestScore(X, U) for all of those subsets. Naively, this approach requires storing
n2n1 scores and parent sets (Silander & Myllymaki, 2006). Because of Theorem 3, however,
the number of optimal parent sets is often far smaller than the full size. Figure 2(b) shows
that an optimal parent set may be shared by several candidate parent sets. The full parent
graph representation will allocate space for this repetitive information for all candidate sets,
resulting in waste of time and space.
To address these limitations, we introduce a sparse representation of the parent graphs
and related scanning techniques for querying optimal parent sets. As with the full parent
graphs, we begin by calculating and pruning scores as described in the last Section. Due
to Theorems 1 and 2, some of the parent sets can be pruned without being evaluated.
Therefore, we do not have to create the full parent graphs. Also, instead of creating the
Hasse diagrams, we sort all the optimal parent scores for each variable X in a list, and also
maintain a parallel list that stores the associated optimal parent sets. We call these sorted
lists scoresX and parentsX . Table 1 shows the sorted lists for the optimal scores in the
parent graph in Figure 2(b). In essence, this allows us to store and efficiently process only
the scores in Figure 2(c).
To find the optimal parent set for X out of a candidate set U, we can simply scan the
list of X starting from the beginning. As soon as we find the first parent set that is a subset
of U, we find the optimal parent score BestScore(X, U). This is trivially true due to the
following theorem.
Theorem 5 The first subset of U in parentsX is the optimal parent set for X out of U.
Scanning the lists to find optimal parent sets can be inefficient if not done properly.
Since we have to do the scanning for each arc visited in the order graph, any inefficiency in
the scanning can have a large impact on the search algorithm.
35

fiYuan & Malone

parentsX1
validX1
3
 parentsX
X1
new
validX1

{X2 , X3 }
1
0
0

{X3 }
1
0
0

{X2 }
1
1
1

{}
1
1
1

Table 3: The result of performing the bitwise operation to exclude all parent sets which
include X3 . A 1 in the validX1 bit vector means that the parent set does not
include X3 and can be used for selecting the optimal parents. The first set bit
indicates the best possible score and parent set.

parentsX1
validX1
3
 parentsX
X1
new
validX1

{X2 , X3 }
0
0
0

{X3 }
0
1
0

{X2 }
1
0
0

{}
1
1
1

Table 4: The result of performing the bitwise operation to exclude all parent sets which
include either X3 or X2 . A 1 in the validnew
X1 bit vector means that the parent
set includes neither X2 nor X3 . The initial validX1 bit vector had already excluded
X3 , so finding validnew
X1 only required excluding X2 .

To ensure the efficiency, we propose the following scanning technique. For each variable
X, we first initialize a working bit vector of length kscoresX k called validX to be all 1s. This
indicates that all the parent scores in scoresX are usable. Then, we create n  1 bit vectors
also of length kscoresX k, one for each variable in V \ {X}. The bit vector for variable Y is
denoted as parentsYX and contains 1s for all the parent sets that contain Y and 0s for others.
Table 2 shows the bit vectors for the example in Table 1. Then, to exclude variable Y as a
candidate parent, we perform the bit operation validnew
 validX &  parentsYX . The new
X
validX bit vector now contains 1s for all the parent sets that are subsets of V \ {Y }. The
first set bit corresponds to BestScore(X, V \ {Y }). Table 3 shows an example of excluding
X3 from the set of possible parents for X1 , and the first set bit in the new bit vector
corresponds to BestScore(X1 , V \ {X3 }). If we further want to exclude X2 as a candidate
parent, the new bit vector from the last step becomes the current bit vector for this step,
2
and the same bit operation is applied: validnew
 validX &  parentsX
X
X1 . The first set
bit of the result corresponds to BestScore(X1 , V \ {X2 , X3 }). Table 4 demonstrates this
operation. Also, it is important to note that we exclude one variable at a time. For example,
if, after excluding X3 , we wanted to exclude X4 rather than X2 , we could take validnew

X
4
validX &  parentsX
.
These
operations
are
described
in
the
createSparseParentGraph
and
X
getBestScore functions in Algorithm 3.
Because of the pruning of duplicate scores, the sparse representation requires much less
memory than storing all the possible parent sets and scores. As long as kscores(X)k <
C(n  1, n2 ), it also requires less memory than the memory-efficient dynamic programming
algorithm (Malone et al., 2011b).
Experimentally, we show that kscoresX k is almost
36

fiLearning Optimal Bayesian Networks

Algorithm 3 Sparse Parent Graph Algorithms
Input: All necessary Score(X, U), X  V&U  V \ {X}
Output: Sparse parent graphs containing optimal parent sets and scores
1: function createSparseParentGraph(X, Score(., .))
2:
for X  V do
3:
scorest , parentst sort(Score(X, ))
 Sort scores, preferring low cardinality
4:
scoresX , parentsX  
 Initialize possibly optimal scores
5:
for i = 0  |scorest | do
6:
prune  f alse
7:
for j = 0  |scoresX | do
 Check if a better subset pattern exists
8:
if contains(parentst(i), parentsX (j))&scoresX (i)  scorest (i) then
9:
prune  true
10:
Break
11:
end if
12:
end for
13:
if prune ! = true then
14:
Append scoresX , parentsX with parentst(i), parentst (i)
15:
end if
16:
end for
17:
for i = 0  |scoresX | do
 Set bit vectors for efficient querying
18:
for each Y  parentsX (i) do
19:
set(parentsYX (i))
20:
end for
21:
end for
22:
end for
23: end function
24:
25:
26:
27:
28:
29:
30:
31:

function getBestScore(X, U)
valid  allScoresX
for each Y  V \ U do
valid  valid&  parentsYX
end for
f sb  f irstSetBit(valid)
return scoresX [f sb]
end function

 Query BestScore(X, U)

 Return the first score with a set bit

always smaller than C(n  1, n2 ) by several orders of magnitude. So this approach offers
(usually substantial) memory savings compared to previous best approaches.
The sparse representation has an extra benefit of improving the time efficiency as well.
With the full representation, we have to create the complete exponential-size parent graphs,
even though many nodes in a parent graph share the same optimal parent choices. With the
sparse representation, we can avoid creating those nodes, which makes creating the sparse
parent graphs much more efficient.
37

fiYuan & Malone

5. An A* Search Algorithm
We are now ready to tackle the shortest path problem in the order graph. This section
presents our search algorithm as well as two admissible heuristic functions for guiding the
algorithm.
5.1 The Algorithm
We apply a well known state space search method, the A* algorithm (Hart et al., 1968), to
solve the shortest path problem in the order graph. The main idea of the algorithm is to
use an evaluation function f to measure the quality of search nodes and always expand the
one that has the lowest f cost during the exploration of the order graph. For a node U,
f (U) is decomposed as the sum of an exact past cost, g(U), and the estimated future cost,
h(U). The g(U) cost measures the shortest distance from the start node to U, while the
h(U) cost estimates how far away U is from the goal node. Therefore, the f cost provides
an estimated total cost of the best possible path which passes through U.
A* uses an open list (usually as a priority queue) to store the search frontier, and a
closed list to store the expanded nodes. Initially the open list only contains the start node,
and the closed list is empty. At each search step, the node with the lowest f -cost from the
open list, say U, is selected for expansion to generate its successor nodes. Before expanding
U, however, we need to first check whether it is the goal node. If yes, a shortest path to
the goal has been found; we can construct a Bayesian network from the path and terminate
the search.
If U is not the goal, we expand it to generate the successor nodes. Each successor
S considers one possible way of adding a new variable, say X, as a leaf to an existing
subnetwork over the variables in U, that is S = U  {X}. The g cost of S is calculated
as the sum of the g-cost of U and the cost of the arc U  S. The arc cost as well as the
optimal parent set PAX for X out of U are retrieved from Xs parent graph. The h cost of
S is computed from a heuristic function which we will describe shortly. We record in S the
following information2 : g cost, h cost, X, and PAX .
It is clear from the order graph that there are multiple paths to any node. We should
perform duplicate detection for S to see whether a node representing the same set of variables
has already been generated before. If we do not check for duplicates, the search space blows
up from an order graph with a size 2n to an order tree with a size n!. We first check whether
a duplicate already exists in the closed list. If so, we further check whether the duplicate
has a better g cost than S. If yes, we discard S immediately, as it represents a worse path.
Otherwise, we remove the duplicate from the closed list, and place S in the open list. What
happens is we have found a better path with a lower g cost, so we reopen the node for future
search.
If no duplicate is found in the closed list, we also need to check the open list. If no
duplicate is found, we will simply add S to the open list. Otherwise, we will compare the
g costs of the duplicate and S. If the duplicate has a lower g cost, S will be discarded.
Otherwise, we will replace the duplicate with S. Again, the lower g cost means a better
path is found.
2. We can also delay the calculation of h until after duplicate detection to avoid unnecessary calculations
for nodes that will be pruned.

38

fiLearning Optimal Bayesian Networks

Algorithm 4 A* Search Algorithm
Input: full or sparse parent graphs containing BestScore(X, U)
Output: an optimal Bayesian network G
1: function main(D)
2:
start  
3:
Score(start)  0 P
4:
push(open, start, Y V BestScore(Y, V \ {Y })
5:
while !isEmpty(open) do
6:
U pop(open)
7:
if U is goal then
 A shortest path is found
8:
print(The best score is  + Score(V))
9:
G  construct a network from the shortest path
10:
return G
11:
end if
12:
put(closed, U)
13:
for each X  V \ U do
 Generate successors
14:
g  BestScore(X, U) + Score(U)
15:
if contains(closed, U  {X}) then
 Closed list DD
16:
if g < Score(U  {X}) then
 reopen node
17:
delete(closed, U  {X})
18:
push (open, U  {X}, g + h)
19:
Score(U  {X})  g
20:
end if
21:
else
22:
if contains(open, U  {X}) & g < Score(U  {X}) then Open list DD
23:
update(open, U  {X}, g + h)
24:
Score(U  {X})  g
25:
end if
26:
end if
27:
end for
28:
end while
29: end function

After all the successor nodes have been generated, we will place node U in the closed
list, which indicates that node is already expanded. Expanding the top node in the open
list is called one search step. The A* algorithm performs the step repeatedly until the goal
node is selected for expansion. At that moment a shortest path from the start state to the
goal state has been found.
Once the shortest path is found, we can reconstruct the optimal Bayesian network
structure by starting from the goal node and tracing back the shortest path until reaching
the start node. Since each node on the path stores a leaf variable and its optimal parent set,
putting all the optimal parent sets together generates a valid Bayesian network structure.
A pseudo code of the A* algorithm is shown in Algorithm 4.
39

fiYuan & Malone

5.2 A Simple Heuristic Function
The A* algorithm provides different theoretical guarantees depending on the properties of
the heuristic function h. The function h is admissible if the h cost is never greater than
the true cost to the goal; in other words, it is optimistic. Given an admissible heuristic
function, the A* algorithm is guaranteed to find the shortest path once the goal node is
selected for expansion (Pearl, 1984). Let U be a node in the order graph. We first consider
the following simple heuristic function h.
Definition 1
h(U) =

X

BestScore(X, V\{X}).

(7)

XV\U

The heuristic function allows each remaining variable to choose optimal parents from all
the other variables. Its design reflects the principle that the exact cost of a relaxed problem
can be used as an admissible bound for the original problem (Pearl, 1984). In this case, the
original problem is to learn a Bayesian network that is a directed acyclic graph. Equation 7
relaxes the problem by ignoring the acyclicity constraint, so all directed cyclic graphs are
allowed. The heuristic function is easily proven admissible in the following theorem. The
proofs of all the theorems in this paper can be found in Appendix A.
Theorem 6 h is admissible.
It turns out that h has an even nicer property. A heuristic function is consistent if, for
any node U and a successor S, h(U)  h(S) + c(U, S), where c(U, S) stands for the cost
of the arc U  S. Given a consistent heuristic, the f cost is monotonically non-decreasing
following any path in the order graph. As a result, the f cost of any node is less than or
equal to the f cost of the goal node. It follows immediately that a consistent heuristic is
guaranteed to be admissible. With a consistent heuristic, the A* algorithm is guaranteed
to find the shortest path to any node U once U is selected for expansion. If a duplicate is
found in the closed list, the duplicate must have the optimal g cost, so the new node can be
discarded immediately. We show in the following that the simple heuristic in Equation 7 is
also consistent.
Theorem 7 h is consistent.
The heuristic may seem expensive to compute as it requires computing BestScore(X, V\
{X}) for each variable X. However, these scores can be easily found by querying the parent
graphs and are stored in an array for repeated use. It takes linear time to calculate the
heuristic for the start node. Any subsequent computation of h, however, only takes constant
time because we can simply subtract the best score of the newly added variable from the
heuristic value of the parent node.
5.3 An Improved Admissible Heuristic
The simple heuristic function defined in Equation 7, referred to as hsimple hereafter, relaxes
the acyclicity constraint of Bayesian networks completely. As a result, hsimple may introduce
many directed cycles and result in a loose bound. We introduce another heuristic in this
section to tighten the heuristic. We first use a toy example to motivate the new heuristic,
and then describe two specific approaches to computing the heuristic.
40

fiLearning Optimal Bayesian Networks

X1

X2

X3

X4

Figure 4: A directed graph representing the heuristic estimate for the start search node.

5.3.1 A Motivating Example
With hsimple , the heuristic estimate of the start node in an order graph allows each variable
to choose optimal parents from all the other variables. Suppose the optimal parent sets for
X1 , X2 , X3 , X4 are {X2 , X3 , X4 }, {X1 , X4 }, {X2 }, {X2 , X3 } respectively. These parent
choices are shown as the directed graph in Figure 4. Since the acyclicity constraint is
ignored, directed cycles are introduced, e.g., between X1 and X2 . However, we know the
final solution cannot have cycles; three cases are possible between X1 and X2 : (1) X2 is a
parent of X1 (so X1 cannot be a parent of X2 ), (2) X1 is a parent of X2 , or (3) neither of
the above is true. Based on Theorem 4, the third case cannot provide a better value than
the first two cases because one of the variables must have fewer candidate parents.
Between (1) and (2), it is unclear which one is better, so we take the minimum of them
to get a lower bound. Consider case (1). We have to delete the arc X1  X2 to rule out
X1 as a parent of X2 . Then we have to let X2 rechoose optimal parents from the remaining
variables {X3 , X4 }, that is, we must check all parent sets not including X1 . The deletion
of the arc alone cannot produce the new bound because the best parent set for X2 out of
{X3 , X4 } is not necessarily {X4 }. The total bound of X1 and X2 is computed by summing
together the original bound of X1 and the new bound of X2 . We call this total bound
b1 . Case (2) is handled similarly; we call that total bound b2 . Because the joint cost for
X1 and X2 , c(X1 , X2 ), must be optimistic, we compute it as the minimum of b1 and b2 .
Effectively we have considered all possible ways to break the cycle and obtained a tighter
heuristic value. The new heuristic is clearly admissible, as we still allow cycles among other
variables.
Often, hsimple introduces multiple cycles into a heuristic estimate. Figure 4 also has a
cycle between X2 and X4 . This cycle shares X2 with the earlier cycle between X1 and X2 ;
we say the cycles overlap. One way to break both cycles is to set the parent set of X2 to be
{X3 }; however, it introduces a new cycle between X2 and X3 . As described in more detail
shortly, we partition the variables into exclusive groups and only break cycles within each
group. In this example, if X2 and X3 are in different groups, we do not break the cycle.
41

fiYuan & Malone

5.3.2 The K-Cycle Conflict Heuristic
The above idea can be generalized to compute the joint cost for any variable group with
size up to k by avoiding cycles within the group. Then for any node U in the order graph,
we calculate its heuristic value by partitioning the variables V \ U into several exclusive
groups and sum their costs together. We name the resulting technique the k-cycle conflict
heuristic. Note that the simple heuristic hsimple is a special case of this new heuristic, as it
simply contains costs for the individual variables (k=1).
The new heuristic is an application of the additive pattern database technique (Felner,
Korf, & Hanan, 2004). Pattern databases (Culberson & Schaeffer, 1998) is an approach to
computing an admissible heuristic for a problem by solving a relaxed problem. Consider
the 15-puzzle problem. 15 square tiles numbered from 1 to 15 are randomly placed in a 4
by 4 box with one position left empty. Each such configuration of the tiles is called a state.
The goal is to slide the tiles one at a time into a destination configuration. A tile can slide
into the empty position only if it is beside that position. The 15 puzzle can be relaxed to
only contain the tiles 1-8 with the other tiles removed. Because of the relaxation, multiple
states of the original problem map to one state in the abstract state space of the relaxed
problem as they share the positions of the remaining tiles. Each abstract state is called
a pattern; the cost of the pattern is equal to the smallest cost for sliding the remaining
tiles into their destination positions. The cost provides a lower bound for any state in the
original state space which maps to that pattern. The costs of all patterns are stored in a
pattern database.
We can relax a problem in different ways and obtain multiple pattern databases. If
the solutions to several relaxed problems are independent, the problems are said to be
exclusive. For the 15-puzzle, we can also relax it to only contain tiles 9-15. This relaxation
can be solved independently from the previous one because they do not share any puzzle
movements. For any concrete state in the original state space, the positions of tiles 1-8
map it to a pattern in the first pattern database, and the positions of tiles 9-15 map it to a
different pattern in the second pattern database. The costs of these patterns can be added
together to obtain an admissible heuristic, hence the name additive pattern databases.
For our learning problem, a pattern is defined as a group of variables, and its cost is
the optimal joint cost of these variables while avoiding directed cycles between them. The
decomposability of the scoring function implies that the costs of two exclusive patterns can
be added together to obtain an admissible heuristic.
We do not have to explicitly break cycles in computing the cost of a pattern. The
following theorem offers a straightforward approach to doing so.
Theorem 8 The cost of the pattern U, c(U), is equal to the shortest distance from V \ U
to the goal node in the order graph.
Again consider the example in Figure 4. The cost of pattern {X1 , X2 } is equal to the
shortest distance between {X3 , X4 } and the goal in the order graph in Figure 1.
Furthermore, the difference between c(U) and the sum of the simple heuristic values of
all variables in U indicates the amount of improvement brought by avoiding cycles within
the pattern. The differential score, called h , can thus be used as a quality measure for
ordering the patterns and for choosing patterns that are more likely to result in a tighter
heuristic.
42

fiLearning Optimal Bayesian Networks

5.3.3 Dynamic K-Cycle Conflict Heuristic
There are two slightly different versions of the k-cycle conflict heuristic. In the first version
named dynamic k-cycle conflict heuristic, we compute the costs for all groups of variables
with size up to k and store them in a single pattern database. According to Theorem 8,
this heuristic can be computed by finding the shortest distances between all the nodes in
the last k layers of the order graph and the goal.
We compute the heuristic by using a breadth-first search to do a backward search in
the order graph for k layers. The search starts from the goal node and expands the order
graph backward layer by layer. A reverse arc U  {X}  U has the same cost as the arc
U  U  {X}, i.e., BestScore(X, U). The reverse g cost of U is updated whenever a new
path with a lower cost is found. Breadth-first search ensures that node U will obtain its
exact reverse g cost once the previous layer is expanded. The g cost is the cost of the pattern
V \ U. We also compute the differential score, h , for each pattern at the same time. A
pattern which does not have a better differential score than any of its subset patterns will be
discarded. The pruning can significantly reduce the size of a pattern database and improve
its query efficiency. The algorithm for computing the dynamic k-cycle conflict heuristic is
shown in Algorithm 5.
Once the heuristic is created, we can calculate the heuristic value for each search node
as follows. For node U, we partition the remaining variables V \ U into a set of exclusive
patterns, and sum their costs together as the heuristic value. Since we only prune superset
patterns, we can always find such a partition. However, there are potentially many ways of
partition. Ideally we want to find the one with the highest total cost, which represents the
tightest heuristic value. The problem of finding the optimal partition can be formulated
as maximum weighted matching problem (Felner et al., 2004). For k = 2, we can define an
undirected graph in which each vertex represents a variable, and each edge between two
variables represents the pattern containing the same variables and has a weight equal to
the cost of the pattern. The goal is to select a set of edges from the graph so that no two
edges share a vertex and the total weight of the edges is maximized. The matching problem
can be solved in O(n3 ) time, where n is the number of vertices (Papadimitriou & Steiglitz,
1982).
For k > 2, we have to add hyperedges to the matching graph for connecting up to
k vertices to represent larger patterns. The goal becomes to select a set of edges and
hyperedges to maximize the total weight. However, the three-dimensional or higher-order
maximum weighted matching problem is NP-hard (Garey & Johnson, 1979). That means
we have to solve an NP-hard problem when calculating each heuristic value.
To alleviate the potential inefficiency, we greedily select patterns based on their quality.
Consider node U with unsearched variables V \ U. We choose the pattern with the highest
differential cost from all the patterns that are subsets of V \ U. We repeat this step for the
remaining variables until all the variables are covered. The total cost of the chosen patterns
is used as the heuristic value for U. The hdynamic function of Algorithm 5 gives pseudocode
for computing the heuristic value.
The dynamic k-cycle conflict heuristic introduced above is an example of the dynamically partitioned pattern database (Felner et al., 2004) because the patterns are dynamically
selected during the search algorithm. We refer to it as dynamic pattern database for short.
43

fiYuan & Malone

Algorithm 5 Dynamic k-cycle Conflict Heuristic
Input: full or sparse parent graphs containing all BestScore(X, U)
Output: A pattern database P D with patterns up to size k
1: function createDynamicPD(k)
2:
P D0 (V)  0
3:
h (V)  0
4:
for l = 1  k do
 Perform BFS for k levels
5:
for each U  P Dl1 do
6:
expand(U, l)
7:
checkSave(U)
8:
P D(V \ U)  P Dl1 (U)
9:
end for
10:
end for
11:
for each X  P D \ save do
 Remove superset patterns with no improvement
12:
delete P D(X)
13:
end for
14:
sort(P D : h )
 Sort patterns in decreasing costs
15: end function
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:

function expand(U, l)
for each X  U do
g  P Dl1 (U) + BestScore(X, U \ {X})
if g < P Dl (U \ {X}) then P Dl (U \ {X})  g
end for
end function

 Duplicate detection

function checkSave(U)
P
h (U)  g  Y V\U BestScore(Y, V \ {Y })
for each X  V \ U do
 Check improvement over subset patterns
if h (U) > h (U  {X}) then save(U)
end for
end function
function hdynamic (U)
h0
RU
for each S  P D do
if S  R then
RR\S
h  h + P D(S)
end if
end for
return h
end function

 Calculate heuristic value for U

 Greedily find best subset pattern of R

44

fiLearning Optimal Bayesian Networks

A potential drawback of dynamic pattern databases is that, even with the greedy
method, computing a heuristic value is still much more expensive than the simple heuristic
in Equation 7. Consequently, the search time can be longer even though the tighter pattern
database heuristic results in more pruning and fewer expanded nodes.
5.3.4 Static K-Cycle Conflict Heuristic
To address the inefficiency of dynamic pattern database in computing heuristic values, we
introduce another version named static k-cycle conflict heuristic based on the statically
partitioned pattern database technique (Felner et al., 2004). The idea is to partition the
variables into several static exclusive groups, and create a separate pattern database for
each group. Consider a problem with variables {X1 , ..., X8 }. We divide the variables into
two groups, {X1 , ..., X4 } and {X5 , ..., X8 }. For each group, say {X1 , ..., X4 }, we create a
pattern database that contains the costs of all subsets of {X1 , ..., X4 } and store them as a
hash table. We refer to this heuristic as the static pattern database for short.S
We create static pattern databases as follows. For a static grouping V = i Vi , we need
to compute a pattern database for each group Vi that resembles an order graph containing
all subsets of Vi . We use a breadth first search to create the graph starting S
from the node
Vi . The cost for an arc U{X}  U in this graph is equal to BestScore(X, ( j6=i Vj )U),
which means that the variables in the other groups are valid candidate parents. To ensure
efficient retrieval, these static pattern databases are stored as hashtables; nothing is pruned
from them. Algorithm 6 gives pseudocode for creating static pattern databases.
It is much simpler to use static pattern databases to compute a heuristic value. Consider
the search node {X1 , X4 , X8 }; the unsearched variables are {X2 , X3 , X5 , X6 , X7 }. We simply
divide these variables into two patterns {X2 , X3 } and {X5 , X6 , X7 } according to the static
grouping, look them up in the respective pattern databases, and sum the costs together
as the heuristic value. Moreover, since each search step just processes one variable, only
one pattern is affected and requires a new score lookup. Therefore, the heuristic value can
be calculated incrementally. The hstatic function of Algorithm 6 provides pseudocode for
naively calculating this heuristic value.
5.3.5 Properties of The K-Cycle Conflict Heuristic
Both versions of the k-cycle conflict heuristic remain admissible. Although they can avoid
cycles within each pattern, they cannot prevent cycles across different patterns. The following theorem proves the result.
Theorem 9 The k-cycle conflict heuristic is admissible.
Understanding the consistency of the new heuristic is slightly more complex. We first
look at the static pattern database as it does not involve selecting patterns dynamically.
The following theorem shows that the static pattern database is still consistent.
Theorem 10 The static pattern database version of the k-cycle conflict heuristic remains
consistent.
In the dynamic pattern database, each search step needs to solve a maximum weighted
matching problem and select a set of patterns to compute the heuristic value. In the
45

fiYuan & Malone

Algorithm 6 Static k-cycle Conflict Heuristics
S
Input: full or sparse parent graphs containing BestScore(X, U), i Vi  a partition of V
Output: A full pattern database P D i for each Vi
1: function createStaticPD(Vi )
2:
P D0i ()  0 fi fi
3:
for l = 1  fiVi fi do
 Perform BFS over Vi
i
4:
for each U  P Dl1 do
5:
expand(U, l, Vi )
i (U)
6:
P D i (U)  P Dl1
7:
end for
8:
end for
9: end function
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:

function expand(U, l, Vi )
for each X  Vi \ U do
S
i (U) + BestScore(X, U
g  P Dl1
j6=i Vj )
i
i
if g < P Dl (U  X) then P Dl (U  X)  g
end for
end function
function hstatic (U)
h0
for each Vi  V do
h  h + P D i (U  Vi )
end for
return h
end function

 Duplicate detection

 Sum over each P D i separately

following, we show that the dynamic k-cycle conflict heuristic is also consistent by closely
following that of Theorem 4.1 in the work of Edelkamp and Schrodl (2012).
Theorem 11 The dynamic pattern database version of the k-cycle conflict heuristic remains consistent.
However, the above theorem assumes the use of the shortest distances between the nodes
in the abstract space. Because we use a greedy method to solve the maximum weighted
matching problem, we can no longer guarantee to find the shortest paths. As a result, we
may lose the consistency property of the dynamic pattern database. It is thus necessary for
A* to reopen a duplicate node in the closed list if a better path is found.

6. Experiments
We evaluated the A* search algorithm on a set of benchmark datasets from the UCI repository (Bache & Lichman, 2013). The datasets have up to 29 variables and 30, 162 data
points. We discretized all variables into two states using the mean values and deleted all
46

fiLearning Optimal Bayesian Networks

1.00E+10
1.00E+09

Full

Largest Layer

Sparse

1.00E+08
1.00E+07

Size

1.00E+06
1.00E+05
1.00E+04
1.00E+03
1.00E+02
1.00E+01
1.00E+00

Figure 5: The number of parent sets and their scores stored in the full parent graphs
(Full), the largest layer of the parent graphs in memory-efficient dynamic programming (Largest Layer), and the sparse representation (Sparse).

the data points with missing values. Our A* search algorithm is implemented in Java3 . We
compared our algorithm against the branch and bound (BB)4 (de Campos & Ji, 2011), dynamic programming (DP)5 (Silander & Myllymaki, 2006), and integer linear programming
(GOBNILP) algorithms6 (Cussens, 2011). We used the latest versions of these software or
source code at the time of the experiments as well as their default parameter settings; it
was version 1.1 for GOBNILP and 2.1.1 for SCIP. BB and DP do not calculate MDL, but
they use the BIC score, which uses an equivalent calculation as MDL. Our results confirmed
that the algorithms found Bayesian networks that either are the same or belong to the same
equivalence class. The experiments were performed on a 2.66 GHz Intel Xeon with 16GB
of RAM and running SUSE Linux Enterprise Server version 10.
6.1 Full vs Sparse Parent Graphs
We first evaluated the memory savings made possible by the sparse parent graphs in comparison to the full parent graphs. In particular, we compared the maximum number of
scores that have to be stored for all variables at once by each algorithm. A typical dynamic programming algorithm stores scores for all possible parent sets of all variables. The
memory-efficient dynamic programming (Malone et al., 2011b) stores all possible parent
sets only in one layer of the parent graphs for all variables, so the size of the largest layer of
3. A software package with source code named URLearning (You Are Learning) implementing the A*
algorithm can be downloaded at http://url.cs.qc.cuny.edu/software/URLearning.html.
4. http://www.ecse.rpi.edu/cvrl/structlearning.html
5. http://b-course.hiit.fi/bene
6. http://www.cs.york.ac.uk/aig/sw/gobnilp/

47

fiYuan & Malone

all parent graphs is an indication of its space requirement. The sparse representation only
stores the optimal parent sets for all variables.
Figure 5 shows the memory savings by the sparse representation on the benchmark
datasets. It is clear that the number of optimal parent scores stored by the sparse representation is typically several orders of magnitude smaller than the full representation.
Furthermore, due to Theorem 1, increasing the number of data points increases the maximum number of candidate parents. Therefore, the number of candidate parent sets increases
as the number of data points increases; however, many of the new parent sets are pruned
in the sparse representation because of Theorem 3. The number of variables also affects
the number of candidate parent sets. Consequently, the number of optimal parent scores
increases as a function of the number of data points and the number of variables. As the
results show, the amount of pruning is data-dependent, though, and not easily predictable.
In practice, we find the number of data points to affect the number of unique scores much
more than the number of variables.
6.2 Pattern Database Heuristics
The new pattern database heuristic has two versions: static and dynamic pattern databases;
each of them can be parameterized in different ways. We tested various parameterizations
of the new heuristics on the A* algorithm on two datasets named Autos and Flag. We chose
these two datasets because they have a large enough number of variables and can better
demonstrate the effect of pattern database heuristics. For the dynamic pattern database, we
varied k from 2 to 4. For the static pattern databases, we tried groupings 9-9-8 and 13-13 for
the Autos dataset and groupings 10-10-9 and 15-14 for the Flag dataset. We obtained the
groupings by simply dividing the variables in the datasets into several consecutive blocks.
The results based on the sparse parent graphs are shown in Figure 6. We did not show
the results of full parent graphs because A* ran out of memory on both datasets when
full parent graphs were used. With the sparse representations, A* achieved much better
scalability, and was able to solve both Autos with any heuristic and Flag with some of the
best heuristics when using sparse parent graphs. Hereafter our experiments and results
assume the use of sparse parent graphs.
Also, the pattern database heuristics improved the efficiency and scalability of A* significantly. A* with either the simple heuristic or the static pattern database with grouping
10-10-9 ran out of memory on the Flag dataset. The other pattern database heuristics enabled A* to finish successfully. The dynamic pattern database with k = 2 helped to reduce
the number of expanded nodes significantly on both datasets. Setting k = 3 helped even
more. However, further increasing k to 4 resulted in increased search time, and sometimes
even an increased number of expanded nodes (not shown). We believe that a larger k always
results in a better pattern database; the occasional increase in expanded nodes is because
the greedy strategy we used to choose patterns did not fully utilize the better heuristic. The
longer search time is more understandable though, because it is less efficient to compute
a heuristic value in larger pattern databases, and the inefficiency gradually overtook the
benefit. Therefore, k = 3 seems to be the best parametrization for the dynamic pattern
database in general. For the static pattern databases, we were able to test much larger
48

fiLearning Optimal Bayesian Networks

1.00E+04

Running Time

Size of Pattern Database

1.00E+05

1.00E+03
1.00E+02
1.00E+01
1.00E+00

500
450
400
350
300
250
200
150
100
50
0

Autos

1.00E+04

Running Time

Size of Pattern Database

1.00E+05

1.00E+03
1.00E+02
1.00E+01
1.00E+00

500
450
400
350
300
250
200
150
100
50
0

X

X

F lag
Figure 6: A comparison of A* enhanced with different heuristics (hsimple , hdynamic with k =
2, 3, and 4, and hstatic with groupings 9-9-8 and 13-13 for the Autos dataset and
groupings 10-10-9 and 15-14 for the Flag dataset). Size of Pattern Database
means the number of patterns stored. Running Time means the search time
(in seconds) using the indicated pattern database strategy. An X means out of
memory.

groups because we do not need to enumerate all groups up to a certain size. The results
suggest that fewer larger groups tend to result in tighter heuristic.
The sizes of the static pattern databases are typically much larger than the dynamic
pattern databases. However, the time needed to create the pattern databases is still negligible in comparison to the search time in all cases. It is thus cost effective to try to compute
larger but affordable-size static pattern databases to achieve better search efficiency. Our
results show that the best static pattern databases typically helped A* to achieve better
efficiency than the dynamic pattern databases, even when the number of expanded nodes
is larger. The reason is that calculating the heuristic values is much more efficient when
using static pattern databases.
49

fiYuan & Malone

10000
BB Scoring

DP Scoring

A* Scoring

Scoring Time

1000

100

10

1

0.1

Figure 7: A comparison of the scoring time of the BB, DP, and A* algorithms. Each label
of the X-axis consists of a dataset name, the number of variables, and the number
of data points.

6.3 A* with the Simple Heuristic
We first tested A* with the hsimple heuristic. Each competing algorithm has roughly two
phases, computing optimal parent sets/scores (scoring phase) and searching for a Bayesian
network structure (searching phase). We therefore compare the algorithms based on two
parts of running time: scoring time and search time. Figure 7 shows the scoring times
of BB, DP, and A*. GOBNILP was not included because it assumes the optimal scores
are provided as input. Each label in the horizontal axis shows a dataset, the number of
variables, and the number of data points. The results show that the AD-tree method used
in our A* algorithm seems to be the most efficient approach to computing the parent scores.
The scoring part of DP is often more than an order of magnitude slower than others. This
result is somewhat misleading, however. The scoring and searching parts of DP are more
tightly integrated than the other algorithms. As a result, most of the work in DP is done in
the scoring part; little work is left for the search. As we will show shortly, the search time
of DP is typically very short.
Figure 8(a) reports the search time of all the algorithms. Some of the benchmark
datasets are so difficult that some algorithms take too long or even fail to find the optimal
solutions. We therefore terminate an algorithm early if it runs for more than 7,200 seconds
on a dataset. The results show that BB only succeeded on two of the datasets, Voting and
Hepatitis, within the time limit. On both datasets, the A* algorithm is several orders of
magnitude faster than BB. The major difference between A* and BB is the formulation
of the search space. BB searches in the space of directed cyclic graphs, while A* always
maintains a directed acyclic graph during the search. The results indicate that it is better
to search in the space of directed acyclic graphs.
The results also show that the search time needed by the DP algorithm is often shorter
than A*. As we explained earlier, the reason is that all the heavy lifting in DP is done in
50

fiLearning Optimal Bayesian Networks

10000
BB

DP

GOBNILP

A*

Search Time

1000

100

10

1

X X

X

X

X

X

X

X

X X

X

(a)
10000

Total Running Time

DP Total Time

A* Total Time

1000

100

10

1

(b)
Figure 8: A comparison of the (a) search time (in seconds) for BB, DP, GOBNILP, and A*
and (b) total running time for DP and A*. An X means that the corresponding
algorithm did not finish within the time limit (7,200 seconds) or ran out of memory
in the case of A*.
.
the scoring part. If we add the scoring and search time together, as shown in Figure 8(b),
A* is several times faster than DP on all the datasets except Adult and Voting (Again,
GOBNILP is left out because it only has the search part). The main difference between A*
and DP is that A* only explores part of the order graph, while dynamic programming fully
evaluates the graph. However, each step of the A* search algorithm has some overhead
cost for computing the heuristic function and maintaining a priority queue. One step
51

fiYuan & Malone

of A* is more expensive than a similar dynamic programming step. If the pruning does
not outweigh its overhead, A* can be slower than dynamic programming. Both Adult
and Voting have a large number of data points, which makes the pruning technique in
Theorem 1 less effective. Although the DP algorithm does not perform any pruning, due
to its simplicity, the algorithm can be highly streamlined and optimized in performing all
its calculations. That is why the DP algorithm was faster than A* search on these two
datasets. However, our A* algorithm was more efficient than DP on all the other datasets.
For these datasets, the number of data points is not that large in comparison to the number
of variables. The pruning significantly outweighs the overhead of A*. As an example,
A* runs faster on the Mushroom dataset when comparing total running time even though
Mushroom has over 8,000 data points.
The comparison between GOBNILP and A* shows that they each has its own advantages. A* was able to find optimal Bayesian networks for all the datasets well within the
time limit. GOBNILP failed to learn optimal Bayesian networks for three of the datasets,
including Letter, Image, and Mushroom. The reason is that GOBNILP formulates the
learning problem as an integer linear program whose variables correspond to the optimal
parent sets of all variables. Even though these datasets do not have many variables, they
have many optimal parent sets, so the integer programs for them have too many variables to
be solvable within the time limit. On the other hand, the results also show that GOBNILP
was quite efficient on many of the other datasets. Even though a dataset may have many
variables, GOBNILP can solve it efficiently as long as the number of optimal parent sets is
small. It is much more efficient than A* on datasets such as Hepatitis and Heart, although
the opposite is true on datasets such as Adult and Statlog.
6.4 A* with Pattern Database Heuristics
Since static pattern databases seem to work better than dynamic pattern databases in most
cases, we tested A* with static pattern database (A*,SP) against A*, DP, and GOBNILP
on all the datasets used in Figure 8 as well as several larger datasets. We used the simple
static grouping of  n2    n2  for all the datasets, where n is the number of variables. The
results of BB are excluded because it did not solve any additional dataset. The results are
shown in Figure 9.
The benefits brought by the pattern databases for A* are rather obvious. For the
datasets on which A* was able to finish, A*,SP was typically up to an order of magnitude
faster. In addition, A*,SP was able to solve three larger datasets: Sensor, Autos, and Flag,
while A* failed on all of them. The running time on each of those datasets is pretty short,
which indicates that once the memory consumption of the parent graphs was reduced, A*
was able to use more memory for the order graph and solve the search problems rather
easily.
DP was able to solve one more dataset, Autos, which A* was not able to solve. It is
somewhat surprising given that A* has pruning capability. The explanation is that A*
stores all search information in RAM, so it will fail once the RAM is exhausted. The DP
algorithm described by Silander and Myllymaki (2006) stores its intermediate results as
computer files on hard disks, so it was able to scale to larger datasets than A*.
52

fiLearning Optimal Bayesian Networks

1000

Search Time

DP

GOBNILP

A*

A*, SP

100

10

1

X

X

X

XXX

X

X XX X X

Figure 9: A comparison of the search time (in seconds) for DP, GOBNILP, A*, and A*,SP.
An X means that the corresponding algorithm did not finish within the time
limit (7,200 seconds) or ran out of memory in the case of A*.

GOBNILP was able to solve Autos, Horse, and Flag, but failed on Sensors. The Sensors
dataset has 5, 456 data points. The number of optimal parent sets is too large, almost
106 as shown in Figure 5. GOBNILP begins to have difficulty solving datasets with more
than 8, 000 optimal parent scores in our particular computing environment. But again,
GOBNILP is quite efficient for datasets that it was able to solve such as Autos and Flag.
It is the only algorithm that can solve the Horse dataset. From Figure 5, it is clear that
the reason is the number of optimal parent sets is small for this dataset.
6.5 Pruning by A*
To gain more insight on the performance of A*, we also looked at the amount of pruning
by A* in different layers of an order graph. We plot in Figure 10 the detailed numbers
of expanded nodes versus the numbers of unexpanded nodes at each layer of the order
graph for two datasets: Mushroom and Parkinsons. We use these datasets because they are
the largest datasets that can be solved by both A* and A*,SP, but they manifest different
pruning behaviors. The top two figures show the results for the A* with the simple heuristic,
and the bottom two show the A*,SP algorithm.
On Mushroom, the plain A* only needed to expand a small portion of the search nodes in
each layer, which indicates the heuristic function is quite tight on this dataset. The effective
pruning started as early as in the 6th layer. For Parkinsons, however, the plain A* was not
as successful in pruning the nodes. In the first 13 layers, the heuristic function appeared to
be too loose. A* had to expand most nodes in these layers. The heuristic function became
tighter for the latter layers and enabled A* to prune an increasing percentage of the search
nodes. With the help of pattern database heuristic, however, A*,SP helped prune many
53

fi1.60E+06
Expanded

1.40E+06

Unexpanded

ExpandedvsUnexpandedNodes

ExpandedvsUnexpandedNodes

Yuan & Malone

1.20E+06
1.00E+06
8.00E+05
6.00E+05
4.00E+05
2.00E+05
0.00E+00
0

2

4

6

8

10

12 14
Layer

16

18

20

1.60E+06
Expanded

1.40E+06
1.20E+06
1.00E+06
8.00E+05
6.00E+05
4.00E+05
2.00E+05
0.00E+00
0

22

(a) A* on Mushroom

2

4

6

8

10 12 14
Layer

16

18

20

22

18

20

22

(b) A* on Parkinsons
1.60E+06

1.60E+06
Expanded

Unexpanded

ExpandedvsUnexpandedNodes

ExpandedvsUnexpandedNodes

Unexpanded

1.40E+06
1.20E+06
1.00E+06
8.00E+05
6.00E+05
4.00E+05
2.00E+05
0.00E+00
0

2

4

6

8

10 12
Layer

14

16

18

20

22

(c) A*,SP on Mushroom

Expanded

Unexpanded

1.40E+06
1.20E+06
1.00E+06
8.00E+05
6.00E+05
4.00E+05
2.00E+05
0.00E+00
0

2

4

6

8

10 12 14
Layer

16

(d) A*,SP on Parkinsons

Figure 10: The number of expanded and unexpanded nodes by A* at each layer of the order
graph on Mushroom and Parkinsons when using different heuristics.

more search nodes on Parkinsons; the pruning became effective as early as in the 6th layer.
The A*,SP also helped prune more nodes on Mushroom, although the benefit is not as clear
because A* was already quite effective on this dataset.
6.6 Factors Affecting Learning Difficulty
Several factors may affect the difficulty of a dataset for the Bayesian network learning
algorithms, including the number of variables, the number of data points, and the number
of optimal parent sets. We analyzed the correlation between those factors and the search
times of the algorithms. We replaced each occurrence of out of time with 7,200 in order
to make the analysis possible (we caution though that it may results in underestimation).
Figure 11 shows the results. We excluded the results of BB because it only finished on two
datasets. For DP, A*, and A*,SP, the most important factor in determining their efficiency
is the number of variables, as the correlations between their search time and the numbers
of variables were all greater than 0.58. However, there seems to be a negative correlation
between their search time with the number of data points. Intuitively, increasing the number
of data points should make a dataset more difficult. The explanation is that there is preexisting negative correlation between the number of data points and the number of variables
for the datasets we tested; our analysis shows that the correlation between them is 0.61.
54

fiLearning Optimal Bayesian Networks

1

Variables

Data!Records

Optimal!Parent!Sets

0.8

Correlation

0.6
0.4
0.2
0
0.2

DP

GOBNILP

A*

A*,!SP

0.4
0.6

Figure 11: The correlation between the search time of the algorithms and several factors
that may affect the difficulty of a learning problem, including the number of
variables, the number of data points in a dataset, and the number of optimal
parent sets.

Since the search time has a strong positive correlation with the number of variables, the
seemingly negative correlation between the search time and the number of data points
becomes less surprising.
In comparison, the efficiency of GOBNILP is most affected by the number of optimal
parent sets; their correlation is as high as close to 0.8. Also, there is a positive correlation
between the number of data points and its efficiency. It is because, as we explained earlier,
more data points often leads to more optimal parent sets. Finally, the correlation with the
number of variables is almost zero, which means the difficulty of a dataset for GOBNILP
is not determined by the number of variables.
These insights are quite important, as they provide a guideline for choosing a suitable
algorithm given the characteristic of a dataset. If there are many optimal parent sets but
not many variables, A* is the better algorithm; if the other way around is true, GOBNILP
is better.
6.7 Effect of Scoring Functions
Our analyses so far are based mainly on the MDL score. Other decomposable scoring
functions can also be used in the A* algorithm, as the correctness of the search strategies
and heuristic functions are not affected by the scoring function. However, different scoring
functions may have different properties. For example, Theorem 1 is a property of the MDL
score. We cannot use this pruning technique for other scoring functions. Consequently, the
number of optimal parent sets, the tightness of the heuristic, and the practical performance
of various algorithms may be affected.
To verify the hypothesis, we also tested the BDeu scoring function (Heckerman, 1998)
with the equivalent sample size set to be 1.0. Since the scoring phase is common for all
exact algorithms, we focus this experiment on comparing the number of optimal parent
sets resulted from the scoring functions, and the search time by A*,SP and GOBNILP
55

fiYuan & Malone

Optimal PS, MDL

Optimal PS, Bdeu

Size

10000000
1000000
100000
10000
1000
100
10
1

(a)
10000
GOBNILP, MDL

GOBNILP, BDeu

A*, MDL

A*, BDeu

Search Time

1000

100

10

1

XX

XX

X

XX

XX

X

(b)
Figure 12: A comparison of (a) the number of optimal parent sets, and (b) the search time
by A*,SP and GOBNILP on various datasets for two scoring functions, MDL
and BDeu.

on the datasets; Horse and Flag were not included because their optimal parent sets were
unavailable. Figure 12 shows the results.
The main observation is that the number of optimal parent sets does differ for MDL
and BDeu. BDeu score tends to allow for larger parent sets than MDL and results in a
larger number of optimal parent sets for most of the datasets. The difference was around
an order of magnitude on datasets such as Imports and Autos.
The comparison on the search time shows that A*,SP is not affected as much as GOBNILP. Because of the increase in the number of optimal parent sets, the efficiency in finding
an optimal parent set is affected, but A*,SP was only slowed down slightly on most of the
datasets. The only significant change is on the Mushroom dataset. It took A*,SP about 2
seconds to solve the dataset when using MDL, but 115 seconds using BDeu. In comparison,
GOBNILP was affected much more. It was able to solve datasets Imports and Autos effi56

fiLearning Optimal Bayesian Networks

ciently when using MDL, but failed to solve them within 3 hours using BDeu. It remained
unable to solve Letter, Image, Mushroom, and Sensors within the time limit.

7. Discussions and Conclusions
This paper presents a shortest-path perspective of the problem of learning optimal Bayesian
networks that optimize a given scoring function. It uses an implicit order graph to represent
the solution space of the learning problem such that the shortest path between the start
and goal nodes in the graph corresponds to an optimal Bayesian network. This perspective
highlights the importance of two orthogonal directions of research. One direction is to
develop search algorithms for solving the shortest path problem. The main contribution
we made on this line is an A* algorithm for solving the shortest path problem in learning
an optimal Bayesian network. Guided by heuristic functions, the A* algorithm focuses on
searching the most promising parts of the solution space in finding the optimal Bayesian
network.
The second equally important research direction is the development of search heuristics.
We introduced two admissible heuristics for the shortest path problem. The first heuristic
estimates the future cost by completely relaxing the acyclicity constraint of Bayesian networks. It is shown to be not only admissible but also consistent. The second heuristic, the
k-cycle conflict heuristic, is developed based on the additive pattern database technique.
Unlike the simple heuristic in which each variable is allowed to choose optimal parents independently, the new heuristic tightens the estimation by enforcing the acyclicity constraint
within some small groups of variables. There are two specific approaches to computing the
new heuristic. One approach named dynamic k-cycle conflict heuristic computes the costs
for all groups of variables with size up to k. During the search, we dynamically partition
remaining variables into exclusive patterns in calculating the heuristic value. The other
approach named static k-cycle conflict heuristic partitions the variables into several static
exclusive groups, and computes a separate pattern database for each group. We can sum
the costs of the static pattern databases to obtain an admissible heuristic. Both heuristics
remain admissible and consistent, although the consistency of the dynamic k-cycle conflict
may be sacrificed due to a greedy method we used to select the patterns.
We tested the A* algorithm empowered with different search heuristics on a set of UCI
machine learning datasets. The results show that both the pattern database heuristics
contributed to significant improvements in the efficiency and scalability of the A* algorithm. The results also show that our A* algorithm is typically more efficient than dynamic
programming that shares a similar formulation. In comparison to GOBNILP, an integer
programming algorithm, A* is less sensitive to the number of optimal parent sets, number
of data points, or scoring functions, but is more sensitive to the number of variables in the
datasets. With those advantages, we believe our methods represent a promising approach
to learning optimal Bayesian network structures.
Exact algorithms for learning optimal Bayesian networks are still limited to relatively
small problems. Further scaling up the learning is needed, e.g., by incorporating domain or
expert knowledge in the learning. It also means that approximation methods are still useful
in domains with many variables. Nevertheless, the exact algorithms are valuable because
they can serve as the basis to evaluate different approximation methods so that we have
57

fiYuan & Malone

some quality assurance. Also, it is a promising research direction to develop algorithms
that have the best properties of both approximation and exact algorithms, that is, they
can find good solutions quickly and, if given enough resources, can converge to an optimal
solution (Malone & Yuan, 2013).

Acknowledgments
This research was supported by NSF grants IIS-0953723, EPS-0903787, IIS-1219114 and
the Academy of Finland (Finnish Centre of Excellence in Computational Inference Research
COIN, 251170). Part of this research has previously been presented in IJCAI-11 (Yuan,
Malone, & Wu, 2011) and UAI-12 (Yuan & Malone, 2012).

Appendix A. Proofs
The following are the proofs of the theorems in this paper.
A.1 Proof of Theorem 5
Proof: Note that the optimal parent set for X out of U has to be a subset of U, and the
subset has to have the best score. Sorting all the unique parent scores makes sure that the
first found subset must satisfy both requirements stated in the theorem.

A.2 Proof of Theorem 6
Proof: Heuristic function h is clearly admissible, because it allows each remaining variable
to choose optimal parents from all the other variables in V. The chosen parent set must
be a superset of the parent set for the same variable in the optimal directed acyclic graph
consisting of the remaining variables. Due to Theorem 4, the heuristic results in a lower
bound cost.

A.3 Proof of Theorem 7
Proof: For any successor node S of U, let Y  S \ U. We have
X
h(U) =
BestScore(X, V\{X})
XV\U



X

BestScore(X, V\{X})

XV\U,X6=Y

+BestScore(Y, U)
= h(S) + c(U, S).
The inequality holds because fewer variables are used to select optimal parents for Y . Hence,
h is consistent.

A.4 Proof of Theorem 8
Proof: The theorem can be proven by noting that avoiding cycles between the variables
in U is equivalent to finding an optimal ordering of the variables with the best joint score.
58

fiLearning Optimal Bayesian Networks

The different paths from V \ U to the goal node correspond to the different orderings of
the variables, among which the shortest path hence corresponds to the optimal ordering. 
A.5 Proof of Theorem 9
Proof: For node U, assume the remaining variables V \ U are partitioned into exclusive
sets V1 , ..., Vp . Because of the decomposability of the scoring function, we have h(U) =
p
P
c(Vi ). When computing c(Vi ), we do not allow directed cycles within Vi . All the
i=1

variables in V \ Vi are valid candidate parents, however. The cost of each pattern, c(Vi ),
must be optimal by the definition of pattern databases. By the same argument used in the
proof of Theorem 6, the h(U) cost cannot be worse than the total cost of V \ U, that is, the
cost of the optimal directed acyclic graph consisting of these variables (with U as allowable
parents also). Otherwise, we can simply arrange the variables in the patterns in the same
order as in the optimal directed acyclic graph to get the same cost. Therefore, the heuristic
is still admissible.
Note that the previous argument only relies on the optimality of the pattern costs, not
on which patterns are chosen. The greedy strategy used in dynamic pattern database only
affects which patterns are selected. Therefore, this theorem holds for both dynamic and
static pattern databases.

A.6 Proof of Theorem 10
Proof: Recall that using static pattern databases with node partitions V = i Vi , the
heuristic value for a node U is as follows.
h(U) =

X

c((V \ U)  Vi ),

i

where (V \U) Vi is the pattern in the ith static pattern database. Then, for any successor
node S of U, let Y  S \ U. Without lost of generality, let Y  (V \ U)  Vj . The heuristic
value for node S is then
h(S) =

X

c((V \ U)  Vi ) + c((V \ U)  (Vj \ {Y })).

i6=j

Also, the cost between U and S is
c(U, S) = BestScore(Y, U).
From the definition of pattern database, we know that c((V\U)Vj ) is the best possible
joint score for the variables in the pattern after U are searched. Therefore, we have
c((V \ U)  Vj )  c(V \ U)  Vj \ {Y }) + BestScore(Y, (i6=j Vi )  (Vj \ (V \ U))
 c((V \ U)  (Vj \ {Y })) + BestScore(Y, U).
The last inequality holds because U  (i6=j Vi )  (Vj \ (V \ U)). The following then
immediately follows.
h(U)  h(S) + c(U, S).
59

fiYuan & Malone

Hence, the static k-cycle conflict heuristic is consistent.

A.7 Proof of Theorem 11
Proof: The heuristic values calculated from the dynamic pattern database can be considered as shortest distances between nodes in an abstract space. The abstract space consists
of the same set of nodes, i.e., all subsets of V. However, additional arcs are added between
a node and nodes with up to k additional variables.
Consider a shortest path p between any two nodes U and goal V in the original solution
space. The path remains a valid path, but may no longer be the shortest path between U
and V because of the additional arcs.
Let g (U, V) be the shortest distance between U and V in the abstract space. For any
successor node S of U, we must have the following.
g (U, V)  g (U, S) + g (S, V).

(8)

Now, recall that g (U, V) and g (S, V) are the heuristic values for the original solution
space, and g (U, S) is equal to the arc cost c(U, S) in the original space. We therefore have
the following.
h(U)  c(U, S) + h(S).
(9)
Hence, the dynamic k-cycle conflict heuristic is consistent.



References
Acid, S., & de Campos, L. M. (2001). A hybrid methodology for learning belief networks:
BENEDICT. International Journal of Approximate Reasoning, 27 (3), 235262.
Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle.
In Proceedings of the Second International Symposium on Information Theory, pp.
267281.
Bache, K., & Lichman, M.
http://archive.ics.uci.edu/ml.

(2013).

UCI

machine

learning

repository.

Bouckaert, R. R. (1994). Properties of Bayesian belief network learning algorithms. In
Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, pp.
102109, Seattle, WA. Morgan Kaufmann.
Bozdogan, H. (1987). Model selection and Akaikes information criterion (AIC): The general
theory and its analytical extensions. Psychometrika, 52, 345370.
Buntine, W. (1991). Theory refinement on Bayesian networks. In Proceedings of the seventh
conference (1991) on Uncertainty in artificial intelligence, pp. 5260, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Cheng, J., Greiner, R., Kelly, J., Bell, D., & Liu, W. (2002). Learning Bayesian networks
from data: an information-theory based approach. Artificial Intelligence, 137 (1-2),
4390.
60

fiLearning Optimal Bayesian Networks

Chickering, D. (1995). A transformational characterization of equivalent Bayesian network
structures. In Proceedings of the 11th annual conference on uncertainty in artificial
intelligence (UAI-95), pp. 8798, San Francisco, CA. Morgan Kaufmann Publishers.
Chickering, D. M. (1996). Learning Bayesian networks is NP-complete. In Learning from
Data: Artificial Intelligence and Statistics V, pp. 121130. Springer-Verlag.
Chickering, D. M. (2002). Learning equivalence classes of Bayesian-network structures.
Journal of Machine Learning Research, 2, 445498.
Cooper, G. F., & Herskovits, E. (1992). A Bayesian method for the induction of probabilistic
networks from data. Machine Learning, 9, 309347.
Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence,
14, 318334.
Cussens, J. (2011). Bayesian network learning with cutting planes. In Proceedings of the
Twenty-Seventh Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-11), pp. 153160, Corvallis, Oregon. AUAI Press.
Daly, R., & Shen, Q. (2009). Learning Bayesian network equivalence classes with ant colony
optimization. Journal of Artificial Intelligence Research, 35, 391447.
Dash, D., & Cooper, G. (2004). Model averaging for prediction with discrete Bayesian
networks. Journal of Machine Learning Research, 5, 11771203.
Dash, D. H., & Druzdzel, M. J. (1999). A hybrid anytime algorithm for the construction
of causal models from sparse data. In Proceedings of the Fifteenth Annual Conference
on Uncertainty in Artificial Intelligence (UAI99), pp. 142149, San Francisco, CA.
Morgan Kaufmann Publishers, Inc.
de Campos, C. P., & Ji, Q. (2011). Efficient learning of Bayesian networks using constraints.
Journal of Machine Learning Research, 12, 663689.
de Campos, C. P., & Ji, Q. (2010). Properties of Bayesian Dirichlet scores to learn Bayesian
network structures. In Fox, M., & Poole, D. (Eds.), AAAI, pp. 431436. AAAI Press.
de Campos, L. M. (2006). A scoring function for learning Bayesian networks based on
mutual information and conditional independence tests. Journal of Machine Learning
Research, 7, 21492187.
de Campos, L. M., Fernndez-Luna, J. M., Gmez, J. A., & Puerta, J. M. (2002). Ant colony
optimization for learning Bayesian networks. International Journal of Approximate
Reasoning, 31 (3), 291311.
de Campos, L. M., & Huete, J. F. (2000). A new approach for learning belief networks
using independence criteria. International Journal of Approximate Reasoning, 24 (1),
11  37.
61

fiYuan & Malone

de Campos, L. M., & Puerta, J. M. (2001). Stochastic local algorithms for learning belief
networks: Searching in the space of the orderings. In Benferhat, S., & Besnard, P.
(Eds.), ECSQARU, Vol. 2143 of Lecture Notes in Computer Science, pp. 228239.
Springer.
Edelkamp, S., & Schrodl, S. (2012). Heuristic Search - Theory and Applications. Morgan
Kaufmann.
Felner, A., Korf, R., & Hanan, S. (2004). Additive pattern database heuristics. Journal of
Artificial Intelligence Research, 22, 279318.
Felzenszwalb, P. F., & McAllester, D. A. (2007). The generalized A* architecture. Journal
of Artificial Intelligence Research, 29, 153190.
Friedman, N., & Koller, D. (2003). Being Bayesian about network structure: A Bayesian
approach to structure discovery in Bayesian networks. Machine Learning, 50 (1-2),
95125.
Friedman, N., Nachman, I., & Peer, D. (1999). Learning Bayesian network structure from
massive datasets: The sparse candidate algorithm. In Laskey, K. B., & Prade, H.
(Eds.), Proceedings of the Fifteenth Conference Conference on Uncertainty in Artificial
Intelligence (UAI-99), pp. 206215. Morgan Kaufmann.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the
Theory of NP-Completeness. W. H. Freeman & Co., New York, NY, USA.
Glover, F. (1990). Tabu search: A tutorial. Interfaces, 20 (4), 7494.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). A formal basis for the heuristic determination of minimum cost paths. IEEE Trans. Systems Science and Cybernetics, 4 (2),
100107.
Heckerman, D., Geiger, D., & Chickering, D. M. (1995). Learning Bayesian networks: The
combination of knowledge and statistical data. Machine Learning, 20, 197243.
Heckerman, D. (1998). A tutorial on learning with Bayesian networks. In Holmes, D., & Jain,
L. (Eds.), Innovations in Bayesian Networks, Vol. 156 of Studies in Computational
Intelligence, pp. 3382. Springer Berlin / Heidelberg.
Hemmecke, R., Lindner, S., & Studeny, M. (2012). Characteristic imsets for learning
Bayesian network structure. International Journal of Approximate Reasoning, 53 (9),
13361349.
Hsu, W. H., Guo, H., Perry, B. B., & Stilson, J. A. (2002). A permutation genetic algorithm
for variable ordering in learning Bayesian networks from data. In Langdon, W. B.,
Cant-Paz, E., Mathias, K. E., Roy, R., Davis, D., Poli, R., Balakrishnan, K., Honavar,
V., Rudolph, G., Wegener, J., Bull, L., Potter, M. A., Schultz, A. C., Miller, J. F.,
Burke, E. K., & Jonoska, N. (Eds.), GECCO, pp. 383390. Morgan Kaufmann.
62

fiLearning Optimal Bayesian Networks

Jaakkola, T., Sontag, D., Globerson, A., & Meila, M. (2010). Learning Bayesian network
structure using LP relaxations. In Proceedings of the 13th International Conference on
Artificial Intelligence and Statistics (AISTATS), pp. 358365, Chia Laguna Resort,
Sardinia, Italy.
Klein, D., & Manning, C. D. (2003). A* parsing: Fast exact Viterbi parse selection. In
Proceedings of the Human Language Conference and the North American Association
for Computational Linguistics (HLT-NAACL), pp. 119126.
Koivisto, M., & Sood, K. (2004). Exact Bayesian structure discovery in Bayesian networks.
Journal of Machine Learning Research, 5, 549573.
Kojima, K., Perrier, E., Imoto, S., & Miyano, S. (2010). Optimal search on clustered
structural constraint for learning Bayesian network structure. Journal of Machine
Learning Research, 11, 285310.
Lam, W., & Bacchus, F. (1994). Learning Bayesian belief networks: An approach based on
the MDL principle. Computational Intelligence, 10, 269293.
Larranaga, P., Kuijpers, C. M. H., Murga, R. H., & Yurramendi, Y. (1996). Learning
Bayesian network structures by searching for the best ordering with genetic algorithms. IEEE Transactions on Systems, Man, and Cybernetics, Part A, 26 (4), 487
493.
Malone, B., & Yuan, C. (2013). Evaluating anytime algorithms for learning optimal Bayesian
networks. In Proceedings of the 29th Conference on Uncertainty in Artificial Intelligence (UAI-13), pp. 381390, Seattle, Washington.
Malone, B., Yuan, C., Hansen, E., & Bridges, S. (2011a). Improving the scalability of optimal Bayesian network learning with frontier breadth-first branch and bound search. In
Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI-11),
pp. 479488, Barcelona, Catalonia, Spain.
Malone, B., Yuan, C., & Hansen, E. A. (2011b). Memory-efficient dynamic programming
for learning optimal Bayesian networks. In Proceedings of the 25th AAAI Conference
on Artificial Intelligence (AAAI-11), pp. 10571062, San Francisco, CA.
Moore, A., & Lee, M. S. (1998). Cached sufficient statistics for efficient machine learning
with large datasets. Journal of Artificial Intelligence Research, 8, 6791.
Moore, A., & Wong, W.-K. (2003). Optimal reinsertion: A new search operator for accelerated and more accurate Bayesian network structure learning. In International
Conference on Machine Learning, pp. 552559.
Myers, J. W., Laskey, K. B., & Levitt, T. S. (1999). Learning Bayesian networks from
incomplete data with stochastic search algorithms. In Laskey, K. B., & Prade, H.
(Eds.), Proceedings of the Fifteenth Conference Conference on Uncertainty in Artificial
Intelligence (UAI-99), pp. 476485. Morgan Kaufmann.
63

fiYuan & Malone

Ordyniak, S., & Szeider, S. (2010). Algorithms and complexity results for exact Bayesian
structure learning. In Gruwald, P., & Spirtes, P. (Eds.), Proceedings of the 26th
Conference Conference on Uncertainty in Artificial Intelligence (UAI-10), pp. 401
408. AUAI Press.
Ott, S., Imoto, S., & Miyano, S. (2004). Finding optimal models for small gene networks.
In Pacific Symposium on Biocomputing, pp. 557567.
Papadimitriou, C. H., & Steiglitz, K. (1982). Combinatorial optimization: algorithms and
complexity. Prentice-Hall, Inc., Upper Saddle River, NJ, USA.
Parviainen, P., & Koivisto, M. (2009). Exact structure discovery in Bayesian networks with
less space. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial
Intelligence, Montreal, Quebec, Canada. AUAI Press.
Pearl, J. (1984). Heuristics: intelligent search strategies for computer problem solving.
Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.
Pearl, J. (1988). Probabilistic reasoning in intelligent systems: networks of plausible inference. Morgan Kaufmann Publishers Inc.
Perrier, E., Imoto, S., & Miyano, S. (2008). Finding optimal Bayesian network given a
super-structure. Journal of Machine Learning Research, 9, 22512286.
Rissanen, J. (1978). Modeling by shortest data description. Automatica, 14, 465471.
Silander, T., & Myllymaki, P. (2006). A simple approach for finding the globally optimal Bayesian network structure. In Proceedings of the 22nd Annual Conference on
Uncertainty in Artificial Intelligence (UAI-06), pp. 445452. AUAI Press.
Silander, T., Roos, T., Kontkanen, P., & Myllymaki, P. (2008). Factorized normalized
maximum likelihood criterion for learning Bayesian network structures. In Proceedings
of the 4th European Workshop on Probabilistic Graphical Models (PGM-08), pp. 257
272.
Singh, A., & Moore, A. W. (2005). Finding optimal Bayesian networks by dynamic programming. Tech. rep. CMU-CALD-05-106, Carnegie Mellon University.
Spirtes, P., Glymour, C., & Scheines, R. (2000). Causation, prediction, and search (second
edition). The MIT Press.
Suzuki, J. (1996). Learning Bayesian belief networks based on the minimum description
length principle: An efficient algorithm using the B&B technique. In International
Conference on Machine Learning, pp. 462470.
Teyssier, M., & Koller, D. (2005). Ordering-based search: A simple and effective algorithm
for learning Bayesian networks. In Proceedings of the Twenty-First Annual Conference
on Uncertainty in Artificial Intelligence (UAI-05), pp. 584590. AUAI Press.
64

fiLearning Optimal Bayesian Networks

Tian, J. (2000). A branch-and-bound algorithm for MDL learning Bayesian networks. In
UAI 00: Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,
pp. 580588, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.
Tsamardinos, I., Brown, L., & Aliferis, C. (2006). The max-min hill-climbing Bayesian
network structure learning algorithm. Machine Learning, 65, 3178.
Xie, X., & Geng, Z. (2008). A recursive method for structural learning of directed acyclic
graphs. Journal of Machine Learning Research, 9, 459483.
Yuan, C., Lim, H., & Littman, M. L. (2011a). Most relevant explanation: Computational
complexity and approximation methods. Annals of Mathematics and Artificial Intelligence, 61, 159183.
Yuan, C., Lim, H., & Lu, T.-C. (2011b). Most relevant explanation in Bayesian networks.
Journal of Artificial Intelligence Research (JAIR), 42, 309352.
Yuan, C., Liu, X., Lu, T.-C., & Lim, H. (2009). Most Relevant Explanation: Properties,
algorithms, and evaluations. In Proceedings of 25th Conference on Uncertainty in
Artificial Intelligence (UAI-09), pp. 631638, Montreal, Canada.
Yuan, C., & Malone, B. (2012). An improved admissible heuristic for learning optimal
Bayesian networks. In Proceedings of the 28th Conference on Uncertainty in Artificial
Intelligence (UAI-12), pp. 924933, Catalina Island, CA.
Yuan, C., Malone, B., & Wu, X. (2011). Learning optimal Bayesian networks using A*
search. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI-11), pp. 21862191, Helsinki, Finland.

65

fi